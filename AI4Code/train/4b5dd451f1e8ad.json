{"cell_type":{"47d140df":"code","330ea026":"code","02ce18bc":"code","69455074":"code","8338bf9c":"code","d97b2779":"code","164cc12b":"code","fe487934":"code","67bbb584":"code","1e0d7a68":"code","de7a08c8":"code","ca10f399":"code","689cdf49":"code","6969814a":"code","081bc79e":"code","bd376fd4":"code","e688c4af":"code","2180ab8f":"code","420d928a":"code","92bf6a46":"code","edaf4ab0":"code","3e705733":"code","fcfdbcf9":"code","1063ec76":"code","30b4c68e":"code","37ae08d4":"code","f95c625b":"code","57e9fd35":"code","3b758c3c":"code","73773af2":"code","d8d6aa47":"code","bdfa5844":"code","36931251":"code","0fca288e":"code","67c098ad":"code","0efd990f":"code","ed18e3d0":"code","d14f345d":"code","088d160c":"code","2d8b1f00":"code","1adcbc90":"code","9f439647":"code","96c76397":"code","065a96ae":"code","03fdde9d":"code","038ae666":"code","0c2456f6":"code","4309106a":"code","11a0dc0f":"code","305f5e6d":"code","6f5db707":"code","7232b9b5":"code","2813c6b3":"code","5446b4c6":"code","eb802975":"code","5e90fc36":"code","b33af475":"code","7f08ba26":"code","a87b134c":"code","390a9ce9":"code","772700bf":"code","b44f783e":"code","63111f55":"code","58605510":"code","94aa56cc":"code","9b3185f5":"code","e3bbea82":"code","b5c3d444":"code","fe21a4ff":"code","319ea3ba":"code","4e52bef6":"code","8505dec8":"code","486a8f9b":"code","5eb8d3d2":"code","c9aa20c4":"code","698bcfed":"code","ce191e09":"code","8667f623":"code","09716241":"code","08529b5b":"code","ede533c8":"code","73372a55":"code","c85dbadc":"code","206651cd":"code","18889d4b":"code","58e28dde":"code","502d7d57":"code","a8dd19e7":"code","724c284d":"code","42072897":"code","446cb8ae":"code","0a7e18aa":"code","aa3be2e3":"code","935bec83":"code","7708b748":"code","ef1b613e":"code","b5c7b0bc":"code","ed1ffc16":"code","ff4989cb":"code","982e3281":"code","d2639806":"code","e6236ca4":"code","0b350352":"code","7c8074bd":"code","f9b8e676":"code","f81da374":"code","5d87cd5f":"code","c7015bc6":"code","c300636b":"code","4faf945a":"code","200b4e74":"code","08b5e0da":"code","5dc50dd6":"code","635bdba3":"code","9a915e90":"code","ad98a669":"code","9a84250d":"code","32e2e617":"code","31adc8a5":"code","2b941271":"code","7fad8048":"code","4e7e6253":"code","bdbc90c0":"code","957f5922":"code","c6de7e28":"code","040af1ca":"code","18b7b56e":"code","311c2e05":"code","c8263cd7":"code","15e6f5ff":"code","3be7985a":"code","de044083":"code","a2ec1a85":"code","aca5b483":"code","8af9e2af":"code","6478e875":"code","baaeb126":"code","0a3a0777":"code","4a2ab1de":"code","cd361765":"code","cca16528":"code","32a5b478":"code","5a757ac4":"code","23548578":"code","f107e291":"code","018ca695":"code","e1ba7b95":"code","1a53c0af":"code","d159b19f":"code","e157e34c":"code","81f1106c":"code","927b5eb7":"code","4d9ad224":"code","4ba5fb0a":"code","760670d5":"code","402fec42":"code","bf4fa45d":"code","39b0c9c3":"code","50802b73":"code","1b32aa54":"code","e7c5d23b":"code","30a32455":"code","e07c58bf":"code","178b8061":"code","2975addb":"code","577eab20":"code","80f99115":"code","36a3dbb5":"code","ecedaf77":"code","fb984276":"code","570c08ee":"code","04b52a97":"code","aa78eecd":"code","02f6d2a1":"code","e849111d":"code","d6a2642f":"code","51ef449e":"code","35b71437":"code","3534716b":"code","e1a7ff7e":"code","294d4d89":"code","ebe3f7a1":"code","eb41f2d9":"code","3709c4d7":"code","390f094f":"code","43edca61":"code","8cda1015":"code","66b69c58":"code","65d37815":"code","f39fcda2":"code","af704f9a":"code","85918e2d":"code","c51eae60":"code","6ec9d08f":"code","1bd7ddf7":"code","07d1ef1b":"code","b3d41386":"code","13bc7321":"code","6e8ad00b":"code","bdb0f385":"code","bc4afde1":"code","41b5ff47":"code","14a4793f":"code","e2390632":"code","66a05ec3":"code","96ff6439":"code","f643cd1f":"code","ca676b58":"code","ec6c7680":"code","b2ce1165":"code","def471dc":"code","1c0f8d72":"code","1b660d84":"code","4e9ea933":"code","f17b520d":"code","9e88c7f0":"code","9d90b827":"code","76755bfe":"code","06bc0e76":"code","60a8a64e":"code","b94a8ea0":"code","1a8c6fcd":"code","9c3325ce":"code","3d6eab34":"code","294f2171":"code","f9bef669":"code","c3a79d1e":"code","be9bfa3e":"code","06ee3b63":"code","c3ac13c6":"code","fcc77e96":"code","f970c918":"code","af9c9f4e":"code","1228fe1e":"code","4d8a7710":"code","26a1bbce":"code","18b6a2f8":"code","52392508":"code","78c506ec":"code","521f20a6":"code","b3ea5dfb":"code","803def1d":"code","52464666":"code","b8972306":"code","4b3ea70e":"code","5b1ea240":"code","fc73bd51":"code","673c99b6":"code","42787606":"markdown","9a1d911c":"markdown","baf32d71":"markdown","4c0aa895":"markdown","7823eae3":"markdown","4edf6a92":"markdown","b3018dc0":"markdown","c57bc57f":"markdown","69fa8430":"markdown","2d6a59e5":"markdown","07a57395":"markdown","3c08cd24":"markdown","647bace2":"markdown","6d9e05a1":"markdown","c97916dc":"markdown","f33154fc":"markdown","4e93a614":"markdown","ab1f72f7":"markdown","e278656a":"markdown","7aad5838":"markdown","7f7d069e":"markdown","8309c8d6":"markdown","23bee16d":"markdown","6d225f9a":"markdown","17bf5cb5":"markdown","aaf98456":"markdown","2c7911ba":"markdown","445bf977":"markdown","0b7f658c":"markdown","552fd056":"markdown","b104d45c":"markdown","a09923d9":"markdown","429198a9":"markdown","02b5e384":"markdown","c93d15dd":"markdown","86f36116":"markdown","db8ef4d5":"markdown","d83f80d4":"markdown","3c76a836":"markdown","de787989":"markdown","a69a0ada":"markdown","da7746c6":"markdown","0f58b727":"markdown","32d4d8bb":"markdown","4fadefc2":"markdown","ba514351":"markdown","eb73d1f5":"markdown","db7acb75":"markdown","d81cb71c":"markdown","836b41c6":"markdown","8dc59b87":"markdown","f999462d":"markdown","e4879cad":"markdown","7807f89b":"markdown","6acf05fc":"markdown","3b2e67e2":"markdown","69840e99":"markdown","3f4cdf0b":"markdown","95af856f":"markdown","ecc43fa1":"markdown","1360333a":"markdown","a7926824":"markdown","4b720158":"markdown","e8755c6c":"markdown","e9c48994":"markdown","6bb8d75f":"markdown","6dbb47e7":"markdown","afc1eddd":"markdown","08c8eee2":"markdown","f822e782":"markdown","e648b1c5":"markdown","c01743ee":"markdown","31086492":"markdown","6af2dbed":"markdown","64323164":"markdown","5997d083":"markdown","8b2d24ab":"markdown","27e1a11f":"markdown","ae5daec5":"markdown","42ca31a9":"markdown","9a47b110":"markdown","46bab6a9":"markdown","7d32fd56":"markdown","980a14a8":"markdown","d0c3fcf8":"markdown","a627aec7":"markdown","adabf257":"markdown","36d6d4b5":"markdown","bbed0e28":"markdown","2bdd47c2":"markdown","d3f1e210":"markdown","fbe32d9b":"markdown","fcbb32f0":"markdown","ee08a5e5":"markdown","f14b5b93":"markdown","2b6f0040":"markdown","71dd6664":"markdown","a0235f9f":"markdown","7afcbb35":"markdown","1131d3fe":"markdown","4d86f55c":"markdown","5e500742":"markdown","8b111121":"markdown","92dbf98b":"markdown","dbcc389e":"markdown","54893c42":"markdown","087a3092":"markdown","5876197c":"markdown","c4128e13":"markdown","e0d41061":"markdown","31c57469":"markdown","b4b6a50a":"markdown","bce15505":"markdown","610f4e0f":"markdown","8fc8c4ad":"markdown","26e20a62":"markdown","466eaf74":"markdown","32cf5b72":"markdown","be50cdab":"markdown","b33ed83b":"markdown","84843a6e":"markdown","94f0966f":"markdown","883de7ad":"markdown","cedfeca8":"markdown","9ded0389":"markdown","c2d3a760":"markdown","dc4a941b":"markdown","60229760":"markdown"},"source":{"47d140df":"!pip install contractions","330ea026":"import numpy as np\nimport pandas as pd\nimport sklearn as sk\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\nimport sys\nimport os\nimport re\nimport string\nimport scipy\nfrom scipy.stats import chi2_contingency\nfrom scipy.interpolate import interp1d\nfrom statsmodels.stats.multitest import fdrcorrection, multipletests\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom tqdm import tqdm\nimport contractions\nimport nltk\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.tokenize import word_tokenize \nfrom nltk.tag import pos_tag","02ce18bc":"nltk.download(\"stopwords\")\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","69455074":"print(\"python\", sys.version)\nfor module in np, pd, mpl, sbn, nltk, sk, nltk, re, scipy:\n    print(module.__name__, module.__version__)","8338bf9c":"np.random.seed(0)","d97b2779":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsample_submission = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","164cc12b":"pd.set_option('display.max_colwidth', None)\n\ntrain.head()","fe487934":"test.head()","67bbb584":"print(\"The training set has {} rows and {} columns.\".format(train.shape[0], train.shape[1]))","1e0d7a68":"print(\"The test set has {} rows and {} columns.\".format(test.shape[0], test.shape[1]))","de7a08c8":"print(\"The training set has {} duplicated rows.\".format(train.drop('id',axis=1).duplicated(keep=False).sum()))","ca10f399":"print(\"The test set has {} duplicated rows.\".format(test.drop('id',axis=1).duplicated(keep=False).sum()))","689cdf49":"train[(train.drop(['id', 'target'], axis=1).duplicated(keep=False)) & ~(train.drop(['id'], axis=1).duplicated(keep=False))]","6969814a":"train[train.text.str.contains('CLEARED:incident with injury:I-495')]","081bc79e":"test[(test.drop(['id'], axis=1).duplicated(keep=False))].iloc[:10,:]","bd376fd4":"train[(train['text'].duplicated(keep=False)) & ~(train.drop(['id','target'], axis=1).duplicated(keep=False))].sort_values(by=\"text\")[10:20]","e688c4af":"print(\"There are {} such tweets.\".format(train[(train['text'].duplicated(keep=False)) & ~(train.drop(['id','target'], axis=1).duplicated(keep=False))].shape[0]))","2180ab8f":"print(\"{}% of the locations are missing in the training set and {}% in the test set\".format(round(train.location.isnull().sum()\/train.shape[0]*100, 1), round(test.location.isnull().sum()\/test.shape[0]*100, 1)))\nprint(\"{}% of the keywords are missing in the training set and {}% in the test set\".format(round(train.keyword.isnull().sum()\/train.shape[0]*100, 2), round(test.keyword.isnull().sum()\/test.shape[0]*100, 2)))","420d928a":"zeros = round((train.target==0).sum()\/train.shape[0], 2)\nones = round(1-zeros, 2)\n\nsbn.barplot(x=[\"Non disasters\",\"Disasters\"], y= [zeros,ones], color='gray')\n\nplt.gca().set_ybound(0, 0.7)\nplt.gca().set_ylabel('Proportion of tweets')\nplt.gca().set_yticklabels([])\n\nplt.gca().tick_params(axis='x')\n\nplt.annotate(str(zeros)+'%', xy=(-0.1,zeros+0.01), size=15)\nplt.annotate(str(ones)+'%', xy=(0.9,ones+0.01), size=15)\nplt.suptitle('Distribution of disasters', size=15)\nplt.show()","92bf6a46":"remove_url = lambda x:re.sub(r\"https?:\\\/\\\/t.co\\\/[A-Za-z0-9]+\", \"\", x)\n\ntrain['original_text'] = train.text.copy()\ntrain['text'] = train.text.apply(remove_url)\n\ntest['original_text'] = test.text.copy()\ntest['text'] = test.text.apply(remove_url)","edaf4ab0":"train.loc[train.text!=train.original_text, ['original_text', 'text']].head()","3e705733":"def cleaning(data):\n  data = data.apply(lambda x: re.sub(r'\\x89\u00db\u00aa', '\\'', x))\n  data = data.apply(lambda x: re.sub(r'&;amp;', '&', x))\n  data = data.apply(lambda x: re.sub(r'&amp;', '&', x))\n  data = data.apply(lambda x: re.sub(r'&amp', '&', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00a2\u00e5\u00ca', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00d2\u00e5\u00ca', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db_', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00d2', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00d3', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00cf', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00f7', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00aa', '', x))\n  data = data.apply(lambda x: re.sub(r'\\x89\u00db\\x9d', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00db\u00a2', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00e5\u00c8', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00e5\u00ca', ' ', x))\n  data = data.apply(lambda x: re.sub(r'\u00e5\u00a8', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00e5\u00c7', '', x))\n  data = data.apply(lambda x: re.sub(r'\u00e5_', '', x))\n  return data\n\ntrain.text = cleaning(train.text)\ntest.text = cleaning(test.text)","fcfdbcf9":"train.loc[train.original_text.str.contains('&amp'), ['original_text', 'text']].head()","1063ec76":"vocabulary = set(train['text'].apply(lambda x: re.sub(r'[0-9]', '', x)).apply(lambda x:x.split()).sum())\nvocabulary_test = set(test['text'].apply(lambda x: re.sub(r'[0-9]', '', x)).apply(lambda x:x.split()).sum())\n\nprint(\"The tweets from the traing set contain {} unique words (after removing the URL and the figures).\".format(len(vocabulary)))\nprint(\"The tweets from the test set contain {} unique words (after removing the URL and the figures).\".format(len(vocabulary_test)))","30b4c68e":"contractions_detected = pd.DataFrame({word:[contractions.fix(word)] for word in vocabulary if word!=contractions.fix(word)}, index=['Corrections']).T\nprint(\"We detected {} differents contractions in the tweets from the traing set.\".format(contractions_detected.shape[0]))","37ae08d4":"contractions_detected[:10]","f95c625b":"def check_contractions(w):\n  if w in contractions_detected.index:\n    return contractions_detected.loc[w, 'Corrections']\n  else:\n    return w\n\ntrain.text = train.text.apply(lambda x: ' '.join([check_contractions(w) for w in x.split()]))\ntest.text = test.text.apply(lambda x: ' '.join([check_contractions(w) for w in x.split()]))","57e9fd35":"train.loc[train.original_text.str.contains('theres'), ['original_text', 'text']]","3b758c3c":"test.loc[test.original_text.str.contains('what\\'s'), ['original_text', 'text']].head()","73773af2":"train.loc[~train.keyword.isna(), 'keyword'] = train.loc[~train.keyword.isna(), 'keyword'].apply(lambda x: re.sub(r'%20', ' ', str(x)))\ntest.loc[~test.keyword.isna(), 'keyword'] = test.loc[~test.keyword.isna(), 'keyword'].apply(lambda x: re.sub(r'%20', ' ', str(x)))","d8d6aa47":"print(\"The training set contains {} keywords. The rarest appears in {} tweets and the least rare in {} tweets. The keyword variable also contains {} missing values.\".format(\n    train.keyword.value_counts().shape[0], train.keyword.value_counts().min(), train.keyword.value_counts().max(), train.keyword.isna().sum()))","bdfa5844":"groupby_keyword = train[['keyword', 'target']].groupby('keyword')['target'].agg(frequencies= 'mean', count = 'size').reset_index().sort_values(by='count', ascending=False)\n\nsbn.barplot(y='keyword', x='count', data=groupby_keyword.iloc[:20], color='gray')\nplt.gca().set_xlabel('Count')\nplt.gca().set_ylabel('Keywords')\nplt.suptitle(\"20 most occurring Keywords\", size=15)\nplt.show()","36931251":"groupby_keyword.sort_values(by='frequencies', ascending=False, inplace=True)\nsbn.barplot(y='keyword', x='frequencies', data=groupby_keyword.iloc[:20], color='gray')\nplt.gca().set_xlabel('Frequency of disasters')\nplt.gca().set_ylabel('Keywords')\nplt.suptitle(\"20 highest frequencies of disaster by keyword\", size=15)\nplt.show()","0fca288e":"print(\"The 20 keywords associated with the highest frequencies of disaster occur between {} and {} times with an average of {}.\".format(groupby_keyword[:20]['count'].min(), \n                                                                                                                                        groupby_keyword[:20]['count'].max(), \n                                                                                                                                        groupby_keyword[:20]['count'].mean()))","67c098ad":"print(\"{} samples have 'debris', 'wreckage' or 'derailment' for keyword.\".format(train.keyword.isin(['debris','wreckage', 'derailment']).sum()))","0efd990f":"sbn.barplot(y='keyword', x='frequencies', data=groupby_keyword.iloc[-20:], color='gray')\nplt.gca().set_xlabel('Frequency of disasters')\nplt.gca().set_ylabel('Keywords')\nplt.suptitle(\"20 lowest frequencies of disaster by keyword\", size=15)\nplt.show()","ed18e3d0":"print(\"The 20 keywords associated with the lowest frequencies of disaster occur between {} and {} times with an average of {}.\".format(groupby_keyword[-20:]['count'].min(), \n                                                                                                                                       groupby_keyword[-20:]['count'].max(), \n                                                                                                                                       groupby_keyword[-20:]['count'].mean()))","d14f345d":"groupby_location = train[['location', 'target']].groupby('location')['target'].agg(frequencies= 'mean', count = 'size').reset_index().sort_values(by='frequencies', ascending=False)\nx = groupby_location.frequencies.apply(lambda x:np.round(x,1)).value_counts().index\ny = groupby_location.frequencies.apply(lambda x:np.round(x,1)).value_counts()\ny = y\/np.sum(y)\ny*=100\n\nsbn.barplot(x=x, y=y, color='gray')\nplt.gca().set_xlabel('Frequency of disasters')\nplt.gca().set_ylabel('Proportion of locations')\nplt.gca().set_yticklabels([])\nplt.gca().set_xbound(-0.5, 11)\nplt.gca().set_ybound(0, 65)\n\nfor i in range(11):\n  plt.annotate(str(round(y.loc[i\/10], 1))+'%', xy=(i-0.4,y.loc[i\/10]+1), size=10)\n\nplt.suptitle(\"Proportion of locations by frequency of disasters\", size=15)\nplt.show()","088d160c":"x = groupby_location['count'].value_counts()[:10].index\ny = groupby_location['count'].value_counts().to_numpy()\ny = y[:10]\/np.sum(y)\ny *= 100\n\nsbn.barplot(x=x, y=y, color='gray')\nplt.gca().set_ylim([0, 100])\nplt.gca().set_xlabel('Number of occurrences')\nplt.gca().set_ylabel('Proportion of locations')\n\nfor i in range(10):\n  plt.annotate(str(round(y[i], 1))+'%', xy=(i-0.3,y[i]+2), size=10)\n\nplt.suptitle(\"Proportion of locations by number of occurrences in the training set\", size=15)\nplt.show()","2d8b1f00":"print(\"Besides, {}% of the locations appear more than 11 times in the training set.\".format(round(100-np.sum(y), 1)))","1adcbc90":"groupby_location[groupby_location['count']>=20]","9f439647":"keyword_location = train.copy()\nkeyword_location['keyword_location'] = keyword_location.keyword + '_' + keyword_location.location\npd.DataFrame(keyword_location.keyword_location.value_counts().reset_index().to_numpy(), columns=['(keyword, location) pairs', 'occurrences'])","96c76397":"keyword_location[keyword_location.keyword_location==\"sandstorm_USA\"]","065a96ae":"def ngram_occurrences(corpus=train.text, i=0, j=20, stop_words=None, ngram_range=(1, 1), tokenizer=None):\n  \n  \"\"\" Function to return a dataframe containing some chosen n-grams and, for each n-grams, the number of times it appear in the corpus. \n      The defaults values return a the barplot for the 20 most frequent n-grams.\n\n        Parameters\n        ----------\n        corpus : Series (default=train.text)\n            A Series containing the tweets.\n        i : Integer (default=0)\n            The minimum index of the n-grams to draw. The n-grams are sorted by number of occurrences (with the index starting at 0). So 0 stands for the most frequent n-gram, \n            1 for the second most frequent n-gram, etc.\n        j : Integer (default=20)\n            1 + the maximum index of the n-grams to draw. The n-grams are sorted by number of occurrences (with the index starting at 0). So j=20 stands for the 19th index, wich stands for the\n             20th most frequent n-gram.\n        stop_words : Iterable (default=None)\n            If not None, the stop words to remove from the tokens.\n        ngram_range : Tuple (min_n, max_n) (default=(1, 1))\n            The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used.\n            For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.\n        tokenizer : Tokenizer (default=None)\n            If not None, a tokenizer to use instead of the default tokenizer.\n\n        \"\"\"  \n  \n  vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=ngram_range, tokenizer=tokenizer).fit(corpus)\n  document_term_matrix = vectorizer.transform(corpus)\n  count = document_term_matrix.sum(axis=0) \n  ngram_count = [(word, count[0, id]) for word, id in vectorizer.vocabulary_.items()]\n  ngram_count = sorted(ngram_count, key = lambda x: x[1], reverse=True)\n  return pd.DataFrame(ngram_count[i:j], columns=['ngram', 'count'])","03fdde9d":"def plot_ngram_occurrences(corpus=train.text, i=0, j=20, stop_words=None, n=1, tokenizer=None, add_title= \"\"):\n\n  \"\"\" Function to display a barplot depicting the number of occurences for some chosen n-grams. The defaults values return a the barplot for the 20 most frequent n-grams.\n\n        Parameters\n        ----------\n        corpus : Series (default=train.text)\n            A Series containing the tweets.\n        i : Integer (default=0)\n            The minimum index of the n-grams to draw. The n-grams are sorted by number of occurrences (with the index starting at 0). So 0 stands for the most frequent n-gram, \n            1 for the second most frequent n-gram, etc.\n        j : Integer (default=20)\n            1 + the maximum index of the n-grams to draw. The n-grams are sorted by number of occurrences (with the index starting at 0). So j=20 stands for the 19th index, wich stands for the\n             20th most frequent n-gram.\n        stop_words : Iterable (default=None)\n            If not None, the stop words to remove from the tokens.\n        n : Integer (default=1)\n            The kind of n-grams to consider. For example, 1 stands for unigrams, 2 for bigrams and 3 for trigrams.\n        tokenizer : Tokenizer (default=None)\n            If not None, a tokenizer to use instead of the default tokenizer.\n        min_df : float in range [0.0, 1.0] or int (default=50)\n            When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. \n            If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n        add_title : String(default=\"\")\n            If not the empty string \"\", some string to add before the predefined title.\n        \n        \"\"\"    \n  \n  ngram_count = ngram_occurrences(corpus, i, j, stop_words, (n, n), tokenizer)\n\n  ylabel = 'Words'*int(n==1) + 'Bigrams'*(n==2) + 'Trigrams'*(n==3)\n\n  sbn.barplot(x='count', y = 'ngram', data=ngram_count, color='gray')\n\n  plt.yticks(size=12)\n  plt.gca().set_xlabel('Count')\n  plt.gca().set_ylabel(ylabel)\n\n  plt.suptitle(\"{} occurrences \".format(ylabel) + add_title, size=15)\n  plt.show()","038ae666":"plot_ngram_occurrences(add_title= \"in the training set before removing stopwords\")","0c2456f6":"stop_words = set(stopwords.words('english'))\nplot_ngram_occurrences(train.text, stop_words=stop_words, add_title=\"in the training set after removing stopwords\")","4309106a":"plot_ngram_occurrences(test.text, stop_words=stop_words, add_title=\"in the test set after removing stopwords\")","11a0dc0f":"plot_ngram_occurrences(train.loc[train.target==1 ,'text'], stop_words=stop_words, add_title=\"in the disaster tweets\")","305f5e6d":"plot_ngram_occurrences(train.loc[train.target==0,'text'], i=2, stop_words=stop_words, add_title=\"in the non-disaster tweets\")","6f5db707":"plot_ngram_occurrences(train.loc[train.target==1 ,'text'], stop_words=stop_words, n=2, add_title=\"in the disaster tweets\")","7232b9b5":"plot_ngram_occurrences(train.loc[train.target==0,'text'], stop_words=stop_words, n=2, add_title=\"in the non-disaster tweets\")","2813c6b3":"print(\"As an illustration, {} bigrams appear more than 25 times in disaster tweets, against only {} in non-disaster tweets.\".format(\n    (ngram_occurrences(train.loc[train.target==1,'text'], stop_words=stop_words, ngram_range=(2,2))['count']>25).sum(),\n    (ngram_occurrences(train.loc[train.target==0,'text'], stop_words=stop_words, ngram_range=(2,2))['count']>25).sum()))","5446b4c6":"plot_ngram_occurrences(train.loc[train.target==1,'text'], stop_words=stop_words, n=3, add_title=\"in the disaster tweets\")","eb802975":"plot_ngram_occurrences(train.loc[train.target==0,'text'], stop_words=stop_words, n=3, add_title=\"in the non-disaster tweets\")","5e90fc36":"print(\"As an illustration, {} trigrams appear more than 25 times in disaster tweets, against only {} in non-disaster tweets.\".format(\n    (ngram_occurrences(train.loc[train.target==1,'text'], j=None, stop_words=stop_words, ngram_range=(3,3))['count']>20).sum(),\n    (ngram_occurrences(train.loc[train.target==0,'text'], j=None, stop_words=stop_words, ngram_range=(3,3))['count']>20).sum()))","b33af475":"def disaster_frequency_by_ngram(corpus=train.text, i=0, j=20, stop_words=None, ngram_range=(1, 1), tokenizer=None, min_df=50):\n\n  \"\"\" Function to return a dataframe containing some chosen n-grams and, for each n-grams, the frequency of disaster among the tweets containing this n-gram. The defaults values return a dataframe \n      containing the n-grams associated to the 20 highest frequencies of disaster and their frequencies.\n\n        Parameters\n        ----------\n        corpus : Series (default=train.text)\n            A Series containing the tweets.\n        i : Integer (default=0)\n            The minimum index of the n-grams to draw. The n-grams are sorted by frequency of disaster (with the index starting at 0). So 0 stands for the n-gram with the highest frequency, \n            1 for one with the second highest frequency, etc.\n        j : Integer (default=20)\n            1 + the maximum index of the n-grams to draw. The n-grams are sorted by frequency of disaster (with the index starting at 0). So j=20 stands for the 19th index, wich stands for the\n             n-gram with the 20th highest frequency.\n        stop_words : Iterable (default=None)\n            If not None, the stop words to remove from the tokens.\n        ngram_range : Tuple (min_n, max_n) (default=(1, 1))\n            The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used.\n            For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.\n        tokenizer : Tokenizer (default=None)\n            If not None, a tokenizer to use instead of the default tokenizer.\n        min_df : float in range [0.0, 1.0] or int (default=50)\n            When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. \n            If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n        \n        \"\"\"\n\n  vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=ngram_range, tokenizer=tokenizer, min_df=min_df, binary=True).fit(corpus)\n  document_term_matrix = vectorizer.transform(corpus)\n  count = document_term_matrix.sum(axis=0) \n  frequency_by_ngram = document_term_matrix[train.target.to_numpy()==1,:].sum(axis=0)\/count \n  ngram_freq_count = [(word, frequency_by_ngram[0, id], count[0, id]) for word, id in vectorizer.vocabulary_.items()]\n  ngram_freq_count = sorted(ngram_freq_count, key = lambda x: x[1], reverse=True)\n  return pd.DataFrame(ngram_freq_count[i:j], columns=['ngram', 'disaster_frequency', 'count'])","7f08ba26":"def plot_disaster_frequency_by_ngram(corpus=train.text, i=0, j=20, stop_words=None, n=1, tokenizer=None, min_df=50, add_title= \"\"):\n  \n  \"\"\" Function to display a barplot depicting the frequency of disaster for some chosen n-grams. The defaults values return a the barplot for\n      the n-grams associated to the 20 highest frequencies of disaster.\n\n        Parameters\n        ----------\n        corpus : Series (default=train.text)\n            A Series containing the tweets.\n        i : Integer (default=0)\n            The minimum index of the n-grams to draw. The n-grams are sorted by frequency of disaster (starting at 0). So 0 stands for the n-gram with the highest frequency, \n            1 for one with the second highest frequency, etc.\n        j : Integer (default=20)\n            1 + the maximum index of the n-grams to draw. The n-grams are sorted by frequency of disaster (starting at 0). So j=20 stands for the 19th index, wich stands for the\n            n-gram with the 20th highest frequency.\n        stop_words : Iterable (default=None)\n            If not None, the stop words to remove from the tokens.\n        n : Integer (default=1)\n            The kind of n-grams to consider. For example, 1 stands for unigrams, 2 for bigrams and 3 for trigrams.\n        tokenizer : Tokenizer (default=None)\n            If not None, a tokenizer to use instead of the default tokenizer.\n        min_df : float in range [0.0, 1.0] or int (default=50)\n            When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. \n            If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n        add_title : String(default=\"\")\n            If not the empty string \"\", some string to add before the predefined title.\n        \n        \"\"\"  \n\n  ngram_count = disaster_frequency_by_ngram(corpus, i, j, stop_words, (n, n), tokenizer, min_df=min_df)\n\n  ylabel = 'Words'*int(n==1) + 'Bigrams'*(n==2) + 'Trigrams'*(n==3)\n\n  sbn.barplot(x='disaster_frequency', y = 'ngram', data=ngram_count, color='gray')\n  plt.yticks(size=12)\n  plt.gca().set_xlabel('Frequency of disaster tweets')\n  plt.gca().set_ylabel(ylabel)\n\n  plt.suptitle(add_title + \" frequencies of disaster by {} \".format(ylabel.lower()), size=15)\n  plt.show()","a87b134c":"plot_disaster_frequency_by_ngram(stop_words=stop_words, add_title=\"Highest\")","390a9ce9":"plot_disaster_frequency_by_ngram(i=-20, j=None, stop_words=stop_words, add_title=\"Lowest\")","772700bf":"plot_disaster_frequency_by_ngram(n=2, stop_words=stop_words, min_df=25, add_title=\"Highest\")","b44f783e":"plot_disaster_frequency_by_ngram(i=20, j=40, n=2, stop_words=stop_words, min_df=25, add_title=\"From 20 to 40 highest\")","63111f55":"plot_disaster_frequency_by_ngram(i=-20, j=None, n=2, stop_words=stop_words, min_df=25, add_title=\"Lowest\")","58605510":"plot_disaster_frequency_by_ngram(i=0, j=None, n=3, stop_words=stop_words, min_df=25, add_title=\"All\")","94aa56cc":"train['tweet_lengths'] = train.text.apply(lambda x:x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))) # Remove punctuation\ntrain['tweet_lengths'] = train['tweet_lengths'].apply(lambda x: len(x.split()))","9b3185f5":"def print_quick_stats(x, units):\n  \"\"\" Function to compute simple statistics on a feature x (given as the argument of the function). \"\"\"\n  \n  print(\"In the training set, the tweets contain from {} to {} {}, with an average of {} and a standard deviation equal to {}.\".format(train[x].min(), train[x].max(), units,\n                                                                                                                                       round(train[x].mean(), 1), round(train[x].std(), 1)))","e3bbea82":"x = 'tweet_lengths'\nunits = \"words\"\nprint_quick_stats(x, units)","b5c3d444":"def groupby_x(x):\n  \"\"\" Function that return a dataframe with two columns. The first one contains each unique value taken by a feature x (given as the argument of the function).\n      The second one contains the average frequency of disaster for each unique value of x. \"\"\"\n\n  return train[[x,'target']].groupby(x)['target'].agg(frequency= 'mean').reset_index()","fe21a4ff":"def plot_disaster_frequency_by_x(x, groupby_x, title=\"(with 95% confidence interval)\", vline=True, annotate=False, xlim=None, data=train):\n\n  \"\"\" Function to plot a linear interpolation of the frequencies of disaster for each value taken by a given feature x. \n      Besides, an horizontal line is drawn on top of this graph to indicate the average frequency of disaster through all the training set.\n\n        Parameters\n        ----------\n        x : String\n            The name of the feature according to which we compute the frequencies of disaster.\n        groupby_x : DataFrame\n            A dataframe containing the average frequency of disaster for each value of x.\n        title : String (default=\"(with 95% confidence interval)\")\n            A title that is used in addition to the suptitle of the graph.\n        vline : Boolean (default=True)\n            Whether to plot a vertical line at each intersection point between the interpolation curve of frequencies and the horizontal line equal to the average frequency among all the training set.\n        annotate : Boolean (default=False)\n            Whether to display the abscissa of the intersection point where the vertical lines are plotted.\n        xlim : Tuple (default=None)\n            The limits of the x-axis.\n        data : DataFrame (default=train)\n            The dataframe to which the feature x belongs.\n        \n        Display\n        -------\n        \n        - A linear interpolation of the frequencies of disaster for each value taken by a given feature x.\n        - An horizontal line indicating the average frequency of disaster through all the training set.\n        - Optionally : a vertical line at each intersection point between the interpolation curve of frequencies and the horizontal line\n        \n        \"\"\"\n\n  sbn.lineplot(x=x, y='target', data=data, color='gray')\n\n  z = groupby_x[x].to_numpy()\n  y = groupby_x.frequency.to_numpy()\n  args = np.linspace(z.min(), z.max(), 2000)\n  f = interp1d(z, y).__call__(args)\n  g = interp1d(z, data.target.mean()*np.ones(shape=z.shape)).__call__(args)\n  idx = np.argwhere(np.diff(np.sign(f - g))).flatten()\n\n  plt.axhline(y=data.target.mean(), color='red')\n  plt.plot(args[idx], f[idx], 'ro', markersize=4)\n\n  plt.gca().set_xlim(xlim)\n\n  locs, labels = plt.yticks()\n  norm_cst = min(np.max(locs), 1)\n\n  if vline:\n    if annotate:  \n      for i in idx:\n        plt.axvline(x=args[i], ymax=f[i]\/norm_cst, color='red', linestyle='dashed')\n        plt.annotate(str(round(args[i],1)), xy=(args[i]+0.05, -0.03), color='red')\n    else:\n      for i in idx:\n        plt.axvline(x=args[i], ymax=f[i]\/norm_cst, color='red', linestyle='dashed')\n\n  plt.gca().set_xlabel(\" \".join(x.split(sep='_')).capitalize())\n  plt.gca().set_ylabel('Frequency of disasters')\n  plt.suptitle('Frequency of disasters by ' + \" \".join(x.split(sep='_')), size=15)\n  plt.title(title)\n  plt.show()","319ea3ba":"plot_disaster_frequency_by_x(x=x, groupby_x=groupby_x(x))","4e52bef6":"def distribution(x, bins=None, data=train):\n\n  \"\"\" Function to plot an histogram depicting the distribution of a feature x of the training set (with a gaussian kernel density estimate).\n\n        Parameters\n        ----------\n        x : String\n            The name of the feature whose the distribution will be plotted.\n        bins : Integer (default=None)\n            The number of bins we want the histogram to have.\n        data : DataFrame (default=train)\n            The dataframe to which the feature x belongs.            \n        \"\"\"  \n\n  sbn.distplot(data[x], color='gray', kde=True, bins=bins)\n  plt.gca().set_xlabel(\" \".join(x.split(sep='_')).capitalize())\n  plt.gca().set_ylabel('Proportion')\n  plt.suptitle(\"Distribution of \" + \" \".join(x.split(sep='_')), size=15)\n  plt.title(\"(with a gaussian kernel density estimate)\")\n  plt.show()","8505dec8":"distribution(x, bins=31)","486a8f9b":"print(\"{}% of tweets contain less than 7 words or more than 22.\".format(round(100*train[(train.tweet_lengths<7) | (train.tweet_lengths>22)].shape[0]\/train.shape[0], 1)))","5eb8d3d2":"train[train.tweet_lengths<7][:20]","c9aa20c4":"train[train.tweet_lengths>22][:15]","698bcfed":"train[(train.tweet_lengths>7) & (train.tweet_lengths<22)][:15]","ce191e09":"x = 'tweet_lengths_without_stopwords'\nstop_words = set(stopwords.words('english'))\ntrain[x] = train.text.apply(lambda x:x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))) # Remove punctuation\ntrain[x] = train[x].apply(lambda x: len(set(x.lower().split()).difference(stop_words)))\n\ndistribution(x)","8667f623":"print(\"The {} tweets with a length superior to 22 have an average length equal to {} once the stop words are removed.\".format((train.tweet_lengths>22).sum(), train.loc[train.tweet_lengths>22, \n                                                                                                                              'tweet_lengths_without_stopwords'].mean()))","09716241":"plot_disaster_frequency_by_x(x, groupby_x(x))","08529b5b":"x = 'stopwords_count'\nunits = 'stop words'\nstop_words = set(stopwords.words('english'))\ntrain[x] = train.original_text.apply(lambda x: len(set(x.lower().split()).intersection(stop_words)))\n\nprint_quick_stats(x, units)","ede533c8":"plot_disaster_frequency_by_x(x=x, groupby_x=groupby_x(x), annotate=True)","73372a55":"def marginal_tweets_count(x, units, level):\n  print('Only {} tweets contain more than {} {}.'.format((train[x]>level).sum(), level, units))\n\nmarginal_tweets_count(x, units, 14)","c85dbadc":"distribution(x)","206651cd":"x = 'URL_count'\nunits = 'URL'\ntrain[x] = train.original_text.apply(lambda x : len(re.findall(\"https?:\\\/\\\/t.co\\\/[A-Za-z0-9]+\", x)))\n\nprint_quick_stats(x, units)","18889d4b":"def distribution_annotated(x, xaxis=range(train[x].max()+1), data=train):\n\n  \"\"\" Function to plot an histogram depicting the distribution of a feature x of the training set, with the values directly annotated on the bars.\n\n        Parameters\n        ----------\n        x : String\n            The name of the feature whose the distribution will be plotted.\n        xaxis : Iterable (default=train[x].max()+1)\n            The values of the x-axis.\n        data : DataFrame (default=train)\n            The dataframe to which the feature x belongs.            \n        \"\"\"    \n\n  groupby = data[[x, 'target']].groupby(x)['target'].agg(count= 'size').reset_index()\n  z = groupby.loc[groupby[x].isin(xaxis), x]\n  y = groupby.loc[groupby[x].isin(xaxis), 'count']\/groupby['count'].sum()\n  y*=100\n\n  sbn.barplot(x=z, y=y, color='gray')\n  plt.gca().set_yticklabels([])\n  plt.gca().tick_params(axis='x', labelsize=12)\n  plt.gca().set_ylim((0, max(y)+10))\n  plt.gca().set_xlabel(\" \".join(x.split(sep='_')).capitalize())\n  plt.gca().set_ylabel('Proportion of tweets')\n\n  for i in xaxis:\n    plt.annotate(str(round(y.loc[i], 1))+'%', xy=(i-0.4, y.loc[i]+1), size=10)\n  \n  plt.suptitle('Distribution of '+ \" \".join(x.split(sep='_')), size=15)\n  plt.show()","58e28dde":"distribution_annotated(x)","502d7d57":"plot_disaster_frequency_by_x(x=x, groupby_x=groupby_x(x))","a8dd19e7":"def cochran_criterion(crosstab):\n  \"\"\" Function taking as argument a contingency table and returning a boolean indicating whether the Cochran's criterion (which checks the validity for a chi-squared test) \n      is satisfied for this table. \"\"\"\n  N = crosstab.sum().sum()\n  E = [O_i*O_j\/N > 4 for O_i in crosstab.sum(axis=1) for O_j in crosstab.sum()]\n  criterion = (0 not in set(crosstab.to_numpy().reshape(-1))) & (np.mean(E)>=0.8)\n  return criterion\n\ndef chi2_test(X,Y):\n  \"\"\" Function taking two variables as arguments and returning a list of results about a chi-squared test of independence between these two variables. The list of results\n      contains a boolean indicating whether the Cochran's criterion is satisfied, the test statistic, the p-value of the test, and a boolean indicating whether the\n      test is statistically significant (i.e the Cochran's critetion is satisfied and the p-value is under 5%). \"\"\"\n  crosstab = pd.crosstab(X, Y)\n  criterion = cochran_criterion(crosstab)\n  chi2, p = chi2_contingency(crosstab)[:2]\n  statistically_significative = criterion & (p<0.5)\n  return [criterion, chi2, p, statistically_significative]\n\ndef cohen_d(x,y):\n    \"\"\" Function taking two variables as arguments and returning the Cohen's d computed between them as well as a string indicating the nature of the measured effect\n        (\"Positive\" or \"Negative\"). This string indicates which of the two variables x and y has the greatest average (\"Negative\" means it is x and \"Positive\" means it is y). \"\"\"\n    nx = len(x)\n    ny = len(y)\n    dof = nx + ny - 2\n    value = (np.mean(y) - np.mean(x)) \/ np.sqrt(((ny-1) * np.std(y, ddof=1)**2 + (nx-1) * np.std(x, ddof=1)**2) \/ dof)\n    effect = \"Positive\"*(np.sign(value)==1) + \"Negative\"*(np.sign(value)==-1)\n    return np.abs(value), effect\n\ndef chi2_test_with_effect_size(x, threshold=0):\n  \"\"\" Function taking as argument the name of a feature of the training set and a threshold. It returns the list of results provided by the cohen_d function appended to\n      the one provided by the chi2_test function, where both of these functions are feeded with the target variable and an indicator variable taking value 0 or 1\n      according to the exceeding of the given threshold by the given feature. \"\"\"\n  values = chi2_test(X = (train[x]>threshold).apply(int), Y = train.target)\n  values.extend(cohen_d(train[train[x]<=threshold].target, train[train[x]>threshold].target))\n  return values\n\nchi2_tests = pd.DataFrame(columns=['Cochran_criterion', 'Chi2', 'p_value', 'Statistically_significative', 'Cohen_d', 'Effect' ])\nchi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\nchi2_tests ","724c284d":"x = 'punctuation_marks_count'\nunits = 'punctuation marks'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in string.punctuation]))\n\nprint_quick_stats(x, units)","42072897":"distribution(x, bins=62)","446cb8ae":"marginal_tweets_count(x, units, 25)","0a7e18aa":"plot_disaster_frequency_by_x(x=x, groupby_x=groupby_x(x), xlim=(0,25), vline=False)","aa3be2e3":"punctuation_marks_count = {}\nfor p in string.punctuation:\n  punctuation_marks_count[p] = [train['text'].apply(lambda x: len([w for w in x if w in p])).sum(), train['text'].apply(lambda x: int(len([w for w in x if w in p])>0)).sum()]\n\npunctuation_marks_count = pd.DataFrame(punctuation_marks_count, index=['count', 'tweets_concerned']).sort_values(by='count', axis=1)\npunctuation_marks_count","935bec83":"x = 'dots_count'\nunits = 'dots'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '.']))\n\nprint_quick_stats(x, units)","7708b748":"distribution_annotated(x, xaxis=range(10))","ef1b613e":"marginal_tweets_count(x, units, 9)","b5c7b0bc":"plot_disaster_frequency_by_x(x=x, groupby_x=groupby_x(x), xlim=(0,9), annotate=True)","ed1ffc16":"train[train[x]==3].head()","ff4989cb":"x = 'at_least_3_dots'\nunits = 'at least 3 dots'\ntrain[x] = (train['dots_count']>=3).apply(int)","982e3281":"chi2_tests.loc[units] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","d2639806":"x = 'exclamation_marks_count'\nunits = 'exclamation marks'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '!']))\n\nprint_quick_stats(x, units)","e6236ca4":"distribution_annotated(x, xaxis=range(7))","0b350352":"marginal_tweets_count(x, units, 6)","7c8074bd":"def frequencies_by_x_presence(x, units, xticklabels='', threshold=0, data=train):\n\n  \"\"\" Function to display a barplot depicting the frequencies of disaster according to the exceeding of a threshold by a feature x from the train set. With the default\n      setting, this function displays the frequencies of disaster among two kinds of tweets : those containing zero unit of the feature x (x=0), \n      and those with at least 1 unit of x (x>0). Hence the name of the function.\n\n        Parameters\n        ----------\n        x : String\n            The name of the feature whose the distribution will be plotted.\n        units : String\n            What we want to check the presence. This string is used in the title and the x-ticks name.\n        threshold : Integer or Float (default=0)\n            The threshold that we check if x exceeds.\n        data : DataFrame (default=train)\n            The dataframe to which the feature x belongs.            \n        \"\"\"    \n\n  without_x = np.round_(100*np.mean(data[data[x]<=threshold].target))\n  with_x = np.round_(100*np.mean(data[data[x]>threshold].target))\n\n  sbn.barplot(x=['Tweets without {}'.format(units), 'Tweets with {} (at least one)'.format(units)], y=[without_x, with_x], color='gray')\n  plt.gca().set_ylabel('Frequency of disasters')\n  plt.gca().set_yticklabels([])  \n  plt.gca().set_ylim((0, max(without_x, with_x)+10))\n  plt.annotate(str(without_x)+'%', xy=(-0.1, without_x+1), size=15)\n  plt.annotate(str(with_x)+'%', xy=(0.9, with_x+1), size=15)\n  plt.suptitle('Frequencies of disasters by {} presence'.format(units), size=15)\n\n  if xticklabels!='':\n    plt.gca().set_xticklabels(xticklabels)\n\n  plt.show()","f9b8e676":"frequencies_by_x_presence(x, units, xticklabels=['Witouht \\\"!\\\"', 'With \\\"!\\\"'])","f81da374":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","5d87cd5f":"x = 'question_marks_count'\nunits = 'question marks'\ntrain['question_marks_count'] = train['text'].apply(lambda x: len([w for w in x if w in '?']))\nprint_quick_stats(x, units)","c7015bc6":"distribution_annotated(x, xaxis=range(10))","c300636b":"marginal_tweets_count(x, units, 9)","4faf945a":"frequencies_by_x_presence(x, units, xticklabels=['Tweets without \\\"?\\\"', 'Tweets with \\\"?\\\"'])","200b4e74":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","08b5e0da":"x = 'colons_count'\nunits = 'colons'\ntrain['colons_count'] = train['text'].apply(lambda x: len([w for w in x if w in ':']))\nprint_quick_stats(x, units)","5dc50dd6":"distribution_annotated(x, xaxis=range(8))","635bdba3":"marginal_tweets_count(x, units, 7)","9a915e90":"frequencies_by_x_presence(x, units)","ad98a669":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","9a84250d":"x = 'ampersands_count'\nunits = 'ampersands'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '&']))\nprint_quick_stats(x, units)","32e2e617":"distribution_annotated(x, xaxis=range(3))","31adc8a5":"marginal_tweets_count(x, units, 3)","2b941271":"frequencies_by_x_presence(x, units, xticklabels=['Tweets without \\\"&\\\"', 'Tweets with \\\"&\\\"'])","7fad8048":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","4e7e6253":"x = 'hyphen_count'\nunits = 'hyphens'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '-']))\nprint_quick_stats(x, units)","bdbc90c0":"distribution_annotated(x, xaxis=range(7))","957f5922":"marginal_tweets_count(x, units, 6)","c6de7e28":"frequencies_by_x_presence(x, units)","040af1ca":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","18b7b56e":"x = 'slashes_count'\nunits = 'slashes'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '\/']))\nprint_quick_stats(x, units)","311c2e05":"distribution_annotated(x, xaxis=range(5))","c8263cd7":"marginal_tweets_count(x, units, 4)","15e6f5ff":"frequencies_by_x_presence(x, units)","3be7985a":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","de044083":"x = 'asterisks_count'\nunits = 'asterisks'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '*']))","a2ec1a85":"train.loc[train[x]>0][['text', 'asterisks_count']].head()","aca5b483":"print_quick_stats(x, units)","8af9e2af":"distribution_annotated(x, xaxis=range(3))","6478e875":"marginal_tweets_count(x, units, 2)","baaeb126":"frequencies_by_x_presence(x, units)","0a3a0777":"print('Only {} tweets contain at least one asterisk.'.format((train[x]>0).sum()))","4a2ab1de":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","cd361765":"x = 'hashtags_count'\nunits = 'hashtags'\ntrain['hashtags_count'] = train['text'].apply(lambda x: len([w for w in x if w in '#']))\nprint_quick_stats(x, units)","cca16528":"distribution_annotated(x, xaxis=range(9))","32a5b478":"marginal_tweets_count(x, units, 8)","5a757ac4":"frequencies_by_x_presence(x, units, xticklabels=['Tweets without \\\"#\\\"', 'Tweets with \\\"#\\\"'])","23548578":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","f107e291":"x = 'mentions_count'\nunits = 'mentions'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '@']))\nprint_quick_stats(x, units)","018ca695":"distribution_annotated(x, xaxis=range(9))","e1ba7b95":"frequencies_by_x_presence(x, units)","1a53c0af":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","d159b19f":"x = 'underscores_count'\nunits = 'underscores'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '_']))\nprint_quick_stats(x, units)","e157e34c":"distribution_annotated(x, xaxis=range(5))","81f1106c":"frequencies_by_x_presence(x, units)","927b5eb7":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","4d9ad224":"x = 'apostrophes_count'\nunits = 'apostrophes'\ntrain[x] = train['text'].apply(lambda x: len([w for w in x if w in '\\'']))\nprint_quick_stats(x, units)","4ba5fb0a":"distribution_annotated(x, xaxis=range(6))","760670d5":"marginal_tweets_count(x, units, 5)","402fec42":"frequencies_by_x_presence(x, units)","bf4fa45d":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","39b0c9c3":"chi2_tests.sort_values(by='Cohen_d', ascending=False)","50802b73":"x = 'pos_tags'\nunits = 'pos tags'\ntrain[x] = train.text.apply(lambda x: pos_tag(word_tokenize(x)))","1b32aa54":"train[['text', x, 'target']].head()","e7c5d23b":"x = 'NNS_count'\nunits = 'NNS'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'NNS']))\nprint_quick_stats(x, units)","30a32455":"distribution_annotated(x, xaxis=range(6))","e07c58bf":"marginal_tweets_count(x, units, 5)","178b8061":"plot_disaster_frequency_by_x(x, groupby_x(x), xlim=(0,5), annotate=True)","2975addb":"frequencies_by_x_presence(x, units)","577eab20":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","80f99115":"x = 'NNP_count'\nunits = 'NNP'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'NNP']))\nprint_quick_stats(x, units)","36a3dbb5":"distribution(x)","ecedaf77":"marginal_tweets_count(x, units, 15)","fb984276":"plot_disaster_frequency_by_x(x, groupby_x(x), xlim=(0,15), annotate=True)","570c08ee":"frequencies_by_x_presence(x, units)","04b52a97":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","aa78eecd":"x = 'VBD_count'\nunits = 'VBD'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'VBD']))\nprint_quick_stats(x, units)","02f6d2a1":"distribution_annotated(x, xaxis=range(7))","e849111d":"marginal_tweets_count(x, units, 3)","d6a2642f":"plot_disaster_frequency_by_x(x, groupby_x(x), xlim=(0,3), annotate=True)","51ef449e":"frequencies_by_x_presence(x, units)","35b71437":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","3534716b":"x = 'VBN_count'\nunits = 'VBN'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'VBN']))\nprint_quick_stats(x, units)","e1a7ff7e":"distribution_annotated(x, xaxis=range(5))","294d4d89":"plot_disaster_frequency_by_x(x, groupby_x(x), vline=False)","ebe3f7a1":"frequencies_by_x_presence(x, units)","eb41f2d9":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","3709c4d7":"x = 'VBP_count'\nunits = 'VBP'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'VBP']))\nprint_quick_stats(x, units)","390f094f":"distribution_annotated(x, xaxis=range(6))","43edca61":"plot_disaster_frequency_by_x(x, groupby_x(x), vline=False)","8cda1015":"frequencies_by_x_presence(x, units)","66b69c58":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","65d37815":"x = 'MD_count'\nunits = 'MD'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'MD']))\nprint_quick_stats(x, units)","f39fcda2":"distribution_annotated(x, xaxis=range(5))","af704f9a":"plot_disaster_frequency_by_x(x, groupby_x(x), annotate=True)","85918e2d":"frequencies_by_x_presence(x, units)","c51eae60":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","6ec9d08f":"x = 'PRP_count'\nunits = 'PRP'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'PRP']))\nprint_quick_stats(x, units)","1bd7ddf7":"distribution_annotated(x, xaxis=range(7))","07d1ef1b":"marginal_tweets_count(x, units, 6)","b3d41386":"plot_disaster_frequency_by_x(x, groupby_x(x), xlim=(0,6), annotate=True)","13bc7321":"frequencies_by_x_presence(x, units)","6e8ad00b":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","bdb0f385":"x = 'PRP$_count'\nunits = 'PRP$'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'PRP$']))\nprint_quick_stats(x, units)","bc4afde1":"distribution_annotated(x, xaxis=range(7))","41b5ff47":"plot_disaster_frequency_by_x(x, groupby_x(x), vline=False)","14a4793f":"frequencies_by_x_presence(x, units)","e2390632":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","66a05ec3":"x = 'RB_count'\nunits = 'RB'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'RB']))\nprint_quick_stats(x, units)","96ff6439":"distribution_annotated(x, xaxis=range(8))","f643cd1f":"marginal_tweets_count(x, units, 4)","ca676b58":"plot_disaster_frequency_by_x(x, groupby_x(x), data=train, xlim=(0,4), annotate=True)","ec6c7680":"frequencies_by_x_presence(x, units)","b2ce1165":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","def471dc":"x = 'WRB_count'\nunits = 'WRB'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'WRB']))\nprint_quick_stats(x, units)","1c0f8d72":"distribution_annotated(x, xaxis=range(4))","1b660d84":"marginal_tweets_count(x, units, 2)","4e9ea933":"plot_disaster_frequency_by_x(x, groupby_x(x), data=train, xlim=(0,2), annotate=True)","f17b520d":"frequencies_by_x_presence(x, units)","9e88c7f0":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","9d90b827":"x = 'UH_count'\nunits = 'UH'\ntrain[x] = train.pos_tags.apply(lambda x : len([z for z in x if z[1] == 'UH']))\nprint_quick_stats(x, units)","76755bfe":"distribution_annotated(x, xaxis=range(3))","06bc0e76":"frequencies_by_x_presence(x, units)","60a8a64e":"chi2_tests.loc[units + ' presence'] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","b94a8ea0":"chi2_tests.iloc[13:,:].sort_values(by='Cohen_d', ascending=False)","1a8c6fcd":"x = 'uppercases_count'\nunits = 'capital letters'\nremove_mentions = lambda x:re.sub(r\"@[A-Za-z0-9]+\", \"\", x)\ntrain[x] = train.text.apply(remove_mentions).apply(lambda x : len([z for z in x if z.isupper()]))\n\nprint_quick_stats(x, units)","9c3325ce":"distribution(x)","3d6eab34":"plot_disaster_frequency_by_x(x, groupby_x(x), xlim=(0,20), vline=False)","294f2171":"x = 'more_than_3_uppercases'\ntrain[x] = (train.uppercases_count>3).apply(int)","f9bef669":"frequencies_by_x_presence(x, units='more than 3 capital letters', xticklabels=['< 3', '> 3'])","c3a79d1e":"chi2_tests.loc[x] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","be9bfa3e":"x = 'lowercases_count'\nunits = 'lowercase characters'\ntrain[x] = train.text.apply(remove_mentions).apply(lambda x : len([z for z in x if z.islower()]))\nprint_quick_stats(x, units)","06ee3b63":"distribution(x)","c3ac13c6":"plot_disaster_frequency_by_x(x, groupby_x(x), vline=False)","fcc77e96":"x = 'more_than_40_lowercase characters'\ntrain[x] = (train.lowercases_count>40).apply(int)","f970c918":"frequencies_by_x_presence(x, units='more than 40 lowercase characters', xticklabels=['< 40', '> 40'])","af9c9f4e":"chi2_tests.loc[x] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","1228fe1e":"x = 'characters_count'\nunits = 'characters'\ntrain[x] = train.text.apply(remove_mentions).apply(lambda x : len([z for z in x if z.islower()|z.isupper()])) # We do not just compute len(x) because it would consider the whitespaces as characters.\nprint_quick_stats(x, units)","4d8a7710":"distribution(x)","26a1bbce":"plot_disaster_frequency_by_x(x, groupby_x(x), vline=False)","18b6a2f8":"x = \"more_than_40_characters\"\nunits = \"more than 40 characters\"\ntrain[x] = (train.characters_count>40).apply(int)","52392508":"frequencies_by_x_presence(x, units='more than 40 characters', xticklabels=['< 40 characters', '> 40 characters'])","78c506ec":"chi2_tests.loc[x] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","521f20a6":"x = \"Start_with_capital_letter\"\nunits = \"Start with capital letter\"\ntrain[x] = train.text.apply(remove_mentions).apply(lambda x: x[0].isupper()).apply(int)","b3ea5dfb":"distribution_annotated(x, range(2))","803def1d":"frequencies_by_x_presence(x, units='first character in uppercase', xticklabels=[units, 'don\\'t ' + units])","52464666":"chi2_tests.loc[x] = chi2_test_with_effect_size(x)\npd.DataFrame(chi2_tests.iloc[-1,:]).T","b8972306":"chi2_tests.iloc[-4:,:].sort_values(by='Cohen_d', ascending=False)","4b3ea70e":"f, ax = plt.subplots(figsize=(30, 15))\nax = sbn.heatmap(train.corr('spearman'), cmap=plt.cm.gray)","5b1ea240":"correlations = pd.DataFrame({}, columns=['correlations'])\nfor i in range(train.corr('spearman').shape[0]-1):\n  for j in range(i+1, train.corr('spearman').shape[0]):\n    if (np.abs(train.corr('spearman').iloc[i,j]) > 0.5):\n      correlations.loc[train.corr('spearman').columns[i]+'_'+train.corr('spearman').columns[j]] = train.corr('spearman').iloc[i,j]","fc73bd51":"correlations.sort_values(by='correlations', ascending=False)","673c99b6":"train.to_csv('modified_train', index=False)\ntest.to_csv('modified_test', index=False)\ncontractions_detected.reset_index().rename(columns={'index':'Contractions'}).to_csv('contractions_detected', index=False)\nchi2_tests.reset_index().rename(columns={'index':'variables'}).sort_values(by='Cohen_d', ascending=False).to_csv('chi2_tests', index=False)\ncorrelations.reset_index().rename(columns={'index':'pairs of variables'}).sort_values(by='correlations', ascending=False).to_csv('correlations', index=False)","42787606":"Here are some examples of tweets before and after the URL removing.","9a1d911c":"# **V.6.7 Hyphens** <a id='V.6.7'><\/a>","baf32d71":"Short tweets generally describe a feeling or communicate a succint information. Examples of feelings are \"I love fruits\", \"Summer is lovely\", \"this is ridiculous....\", \"London is cool ;)\" or \"Love skiing\". An example of concise information is \"Wholesale Markets ablaze\". Besides, some short tweets can be also seen as communicating an information while depicting a feeling. An example is \"My car is so fast\". Although some tweets consisting in a succint information concern real disasters, tweets depicting feelings rarely concern real disasters.\nThus, overall, short tweets concern less frequently actual disaster.\n\nNow, let's take a look at tweets including more than 22 words.","4c0aa895":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Most of these bigrams appear in tweets dealing with the same topics. So these two previous charts inform us more about the topics of the disasters from our training set (a declaration of Barack Obama about a typhoon that devastated Saipan, the Malaysia Airlines Flight 370 that disappeared, more than 40 families affected by the fatal outbreak of Legionnaires, etc.) than about the words that characterize the disaster tweets in general.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Nevertheless, the exploration of the frequencies of disasters by bigrams give us another information. More bigrams appear often in disaster tweets than in non-disaster tweets. Indeed, the below graph prove that few bigrams are associated to a low frequency of disasters. For example, among the bigrams that appear at least 25 times in the training set, only 4 appear less than 10% of the time in disaster tweets while 35 appear more than 90% of the time in disaster tweets.<br>","7823eae3":"First, that is a consequence of the greater uniformity of words and expressions used in disaster tweets. <br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can deduce that, although some n-grams clearly characterize disaster tweets, few n-grams characterize non-disaster tweets. To simplify, the n-grams present in non-disaster tweets also appear in disaster tweets. But some n-grams appear almost exclusively in disaster tweets. <br>\nOf course, the last statement only consider the bigrams appearing at least 25 times. Some n-grams appear only in non-disaster tweets. But they occur too few times so that we can infer anything trustworthy from them.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The following chart shows all the trigrams which appear in at least 25 tweets. It is self-explanatory and it confirms even more clearly the previous observation.","4edf6a92":"# **V.3 Tweet lengths** <a id='V.3'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We will now explore the impact of the tweet length. The tweet length will be measured by the number of words by tweet. To be more precise, it will be measured by the number of tokens while the used tokenization process consist in removing punctuation and splitting the tokens on whitespaces.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Note that the tweet length is measured after removing the URL and the punctuation marks as the effects of the punctuation and the number of URL in tweets will be studied later.","b3018dc0":"Hence, it would be hard to decide if the impact of the stars presence is significative based only on the previous visualizations. In this case, to perform a statistical test of independence is even more justified than  previously.","c57bc57f":"# **V.6.9 Asterisks** <a id='V.6.9'><\/a>\n<br>\n\nOn tweeter, the asterisks can be used to emphasize words (with a font in a different style from the rest of the text).","69fa8430":"Hence, once the wtop words are removed, the tweets with a lentgh inferior to 7 have a low frequency and the others have a frequency above the average. After removing the stop words, we do not observe anymore the presence of long tweets with a low frequency. Those are now mixed with medium length tweets. This reduces sightly the higher frequencies observed among medium length tweets. <br>\n<br>\n\n# **V.4 Stop words** <a id='V.4'><\/a>\n<br>\n\nLet's now see what we can deduce from the number of stop words in the tweets.","2d6a59e5":"The amount of characters is linked to the number of words. Therefore, we could study the average number of characters by word in each tweet. I have achieved this (by dividing the character_count feature by the tweet_lengths feature), but the obtained variable has really no link with the frequency of disasters. That's why the results of this are not displayed here.","07a57395":"Consequently, overall, the link between the location and the frequency of disaster is not very meaningful.<br>\n\nAn example of this is the case of New York. The location named \"New York City\" occurs 10 times and is labeled as a disaster with frequency 60%. Besides, \"New York, NY\" appears 15 times and have a frequency of disaster equal to 47%. The location \"New York\" characterized 71 tweets whose 23% are disasters. Finally, \"NYC\" is present 12 times and have a frequency of disaster equal to 17%. This example lays stress on the variability of the empirical link between a location and its frequency of disaster when we have few tweets from this location in the training set. In other words, we should not place too much hope on a pattern concerning a location present few times in the training set.<br>\n\nHowever, some locations give more reliable indications. For instance, the location \"USA\" characterizes 104 tweets whose 64% are disasters. The more tweets a location characterizes, the more meaningful is the frequency of disasters among these tweets. Consequenly, we could for example aggregate all the tweets from New York, whatever the way the location is written.<br>\n\nAs an illustration, even if these values are not very meaningfull, below are a table presenting the locations that appear in at least 20 tweets.","3c08cd24":"The following chart displays a linear interpolation of the frequencies of disasters for each fixed length of tweet. <br>\nBesides, an horizontal line is drawn on top of this graph to indicate the average frequency of disaster through all the training set. In addition, vertical lines are drawn at each intersection point between the interpolation curve of frequencies and the horizontal line. They enable to distinguish for which tweet length the frequency of disasters is above or below the average frequency.<br>\nThereafter, we will study other charts like this one without explaining this again.","647bace2":"Both the training set and the test set contain duplicates.","6d9e05a1":"So the disaster tweets tend to contain the same trigrams, in contrast to non-disaster tweets.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; That suggests that the way the user of Tweeter talk about real disasters is more uniform. That is coherent with the assumption that, when people tweet about a real disaster, they pay probably more attention to the words they use in order to respect the pain of the victims and their loved ones. In addition, when the information of a disaster is confirmed by reliable media, it is tempting to reuse official terms (i.e unigrams) and expressions (i.e bigrams and trigrams) so as not to be imprecise.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; On the contrary, when people tweet about contingent disasters, or about something that has nothing to do with disasters, it is likely that each one express its own opinion with its own words. That would explain the diversity of the expressions used in non disaster tweets.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Moreover, it is likely that tweets about real disasters buzz more than others. Thus, numerous disaster tweets from our dataset deal with the same topics. Consequently, the vocabulary of these tweets appear more often. On the other hand, each non-disaster tweet can evoke a specific topic, associated to a specific vocabulary.<br>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Besides, the most common n-grams of the disaster tweets contain more past forms (as \"detonated\", \"devastated', \"razed\", \"confirmed\", etc.). The usage of past forms suggests the disasters actually happened.<br>\nOn the contrary, the non-disaster tweets evoke feelings and contingencies, particularly with the bigrams \"feel like\", \"looks like\".<br>\nWe also remark the presence of website names (\"ebay\", \"youtube\", \"reddit\") in the non-disaster tweets.<br>\n<br>\n\n\n# **V.2 Frequencies of disasters by n-gram** <a id='V.2'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The presence of words (or n-grams) in disaster tweets do not mean they characterize the disaster tweets because they can also appear often in non-disaster tweets as well. Moreover, there are not as many disaster tweets as there are than non-disaster tweets, what further complicates the interpretation of words occurrences. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A word characterizes the disaster tweets if it appears almost exclusively in disaster tweets. Consequently, for each word, we will compute the number of disaster tweets in which it appears divided by the total number of tweets in which it appears. For each word, the obtained value corresponds to the frequency of disaster tweets among all the tweets containing (at least one time) this particular word. Of course, this computation can only be done on the training set as we need to know which tweets are about real disasters to achieve it.<br>\n<br>\nWe first define two convenient functions.","c97916dc":"Empirically, the tweets with hashtags relate more often real disasters. That effect is statistically significative but small.<br>\n<br>\n\n# **V.6.11 Mentions** <a id='V.6.11'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; On Tweeter, the at (\"@\") is used to mention another person\u2019s username anywhere in the body of a tweet. [Here](https:\/\/help.twitter.com\/en\/using-twitter\/mentions-and-replies) is more information about the mentions on Tweeter.","f33154fc":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The tweet length goes from 1 to 32 words. In general, the tweets containing between 7 and 22 words deal more frequently with real disasters than the average. The ones with a length inferior to 7 or superior to 22 are less likely to concern real disasters.<br>\nThus, the tweets with medium length are more often about disasters than the short ones and the long ones.<br>\n<br>\nIn general, when somebody tweet about a disaster, he uses enough words to be precise while remaining concise.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Most of the tweets have a medium length (associated with a frequency of disasters a little higher than the average) and a small portion of tweets are particularly long or particularly short (and associated with a frequency of disasters much lower than the average). That is why the 95% confidence interval is thinner for medium lengths. This is illustrated by the distribution of the tweet lengths.","4e93a614":"There are few spelling mistakes able to damage the descriptive analysis we will perform. So we won't spellcheck the tweets. <br>\nIf we wanted to spellcheck the tweets, we could for example use the \"Speller\" function from the [autocorrect](https:\/\/github.com\/fsondej\/autocorrect) library, in order to automate as much as possible. Nevertheless, we should be careful with such automating spellchecker as they sometimes try to correct proper nouns, creating other errors. <br> \n<br>\nNow we will remove the contractions in the tweets by using the [contractions](https:\/\/github.com\/kootenpv\/contractions) package.","ab1f72f7":"Nonetheless, most of the locations occur just one time in the training set (that is also true if we consider only the location having a frequency of disasters either equal to 0 or to 1). ","e278656a":"# **VI General conclusion** <a id='VI'><\/a>\n<br>\n\nSeveral syntheses cover previous parts of this notebook. Here, we will try to synthesize these previous syntheses. So this conclusion is not exhaustive at all. Much more information is available in this notebook.<br>\n<br>\nHere are some observations that can summarize our analysis.<br>\n<br>\n*   Disaster tweets are generally written in a more formal language. They begin more often with a capital letter. They contain more characters (both minuscules and capital letters), colons, hyphens, and dots (particularly ellipsis).\n*   The disaster tweets tend to contains less pronouns and more proper nouns. When people tweet about a real disaster, they use proper noun to evoke the place, the name of somebody or something (like an airplane) implied in the disaster, the name of a speaker (as a president, for example) relating the disaster, the name of the disaster (natural disaster, like storm, often have a name).\n*   Disaster tweets contain more URL. The users dealing with disasters often back up their tweets with hyperlinks pointing to newspaper articles.\n*   Disaster tweets contain more hashtags.\n*   Unsurprisingly, the vocabulary of disaster tweets is darker (with words like \"bomb\", \"suicide\") than the one of non disaster tweets (which contains more joyful terms as \"love\" and neutral terms as \"day\").\n<br>\n\n*   The tweets expressing emotions are less likely to relate disasters. Emotions can be expressed by the use of a particular vocabulary (\"feel\", \"love\", \"like\", \"seem\", etc.) but also by the use of some punctuation marks as exclamation point, asterisks (by the focuse they imply on some part of the tweet) or question marks.\n*   Disaster tweets contain less modals. Modals are generally used to express uncertainty. Therefore, when a disaster is recognized, we usually do not use modals.<br>\n<br>\n\nTables resulting from our analysis are made available at the end of the notebook thanks to the following lines of code.","7aad5838":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One could want to relabel the mislabelled tweets. Nevertheless, when the same tweet is differently labelled on two different rows, we cannot know which are the true labels. Moreover, if the people who labelled them had different opinions about whether these tweeets were about real disasters, then we may want our models to take the existing ambiguity into account in order to be more effective. <br>\nIt is still worth noting the presence of these tweets because they can have a negative impact on the analysis. <br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In addition, it is likely that the same kind of mislabelling has been done on the test set. Thus, the scores on this competition could be evaluated with a dataset classifying differently identical rows (with all the predictors taking the same values). There is nothing we can do to overcome this difficulty since we cannot distinguish identical rows. This induces an irreducible error. <br>\n<br>\nBelow are examples of duplicated rows in the test set that could have been mislabelled.","7f7d069e":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tweets with more than 40 characters tend to relate more often real disasters. That is also true if we only consider the lowercase characters. Besides, the tweets beginning with a capital letter or those containing more than 3 capital letters are also more prone to deal with actual disasters.<br>\n<br>\n\n# **V.9 Correlations** <a id='V.9'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Here is a heatmap of the spearman correlations between the numerical variables of the training set after the previous analysis (so with all the features we created).<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Note that on this chart, the darker squares do not relate correlations equal to -1 (as we could expect) but the smaller correleation of our variables, that is slightly inferior to 0.4 (see the color scale on the right of the plot).","8309c8d6":"Next, we fix some errors that seem to be due to a change in the file format.","23bee16d":"To finish, here is the correction of some spaces wrongly rendered in the keyword feature.","6d225f9a":"The exploration of trigrams confirms the precedent observation.","17bf5cb5":"# **V.1 N-grams occurrences** <a id='V.1'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We will first extract n-grams. N-grams are overlapping groups of multiple (from 1 to N) consecutive items. In general, the items can be phonemes, syllables, letters, words or something else, according to the application. Here, we will extract word based n-grams.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We call tokenization the process of breaking up text into different units. These units can be words, word-roots, characters, numbers, acronyms, n-grams or symbols. They are called tokens. Here, the text will be tokenized into words.<br>\n<br>\n\nLet's define two functions to compute and visualize the occurrences of n-grams.","aaf98456":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The most common words are mainly neutral. Some are not very joyful. Examples are \"fire\", \"disaster\" or \"emergency\". Overall, these words could as well be used to talk about something harmless as to relate actual disasters. For instance, the word \"fire\" could be used to talk about candles, about the dismissal of an employee, or about a burning building.<br>\n<br>\nThe results are very similar in the test set.","2c7911ba":"# **V. Text analysis** <a id='V'><\/a>\n<br>\n\nLet's now explore the text variable.","445bf977":"# **VIII Bibliographic references** <a id='VIII'><\/a>\n<br>\n\n\nThis bibliography aims to point the reader to appropriate sources covering some concepts used in this notebook. They are provided with links to simplify the potential searches of the reader.<br>\n<br>\n\n* Books\n\n[All of statistics, by Larry Wasserman (Springer).](https:\/\/www.amazon.com\/All-Statistics-Statistical-Inference-Springer\/dp\/0387402721\/ref=sr_1_1?ie=UTF8&qid=1249141007&sr=8-1) This book is an introductory book on statistics which cover a broad range of topics. In particular, it covers the chi-squared test of independence I used (with examples) and others.<br>\n<br>\n[Deep Learning with Python, by Fran\u00e7ois Chollet (Manning).](https:\/\/www.manning.com\/books\/deep-learning-with-python)<br>\n<br>\n[The truthful art, by Alberto Cairo (New Riders).](https:\/\/www.amazon.com\/Truthful-Art-Data-Charts-Communication\/dp\/0321934075\/ref=sr_1_1?crid=37BCVGMGPJWAV&dchild=1&keywords=the+truthful+art+alberto+cairo&qid=1599306491&s=books&sprefix=the+truthful+art+al%2Cstripbooks-intl-ship%2C230&sr=1-1)<br>\n<br>\n[The visual display of quantitative information, by Edward Tufte.](https:\/\/www.amazon.com\/Visual-Display-Quantitative-Information\/dp\/0961392142\/ref=sr_1_1?crid=376B4YP1NAPB5&dchild=1&keywords=edward+tufte&qid=1599306664&s=books&sprefix=Edward+tufte%2Cstripbooks-intl-ship%2C239&sr=1-1)<br>\n<br>\n\n* Articles\n\n[Intelligent Signals : Visualising Data.](https:\/\/medium.com\/marax-ai\/intelligent-signals-visualising-data-df9152c10b00) <br>\n<br>\n[Ten Simple Rules for Better Figures.](https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1003833)<br>\n<br>\nSimply put: here are the Wikipedia articles about [Chi-squared tests](https:\/\/en.wikipedia.org\/wiki\/Pearson%27s_chi-squared_test) and [Effect size, and in particular Cohen's d](https:\/\/en.wikipedia.org\/wiki\/Effect_size#Cohen's_d). <br>\n<br>\n<br>\n<br>\nThanks for reading. I hope you have taken as pleasure by reading this notebook as I have taken by writing it.<br>\n<br>\nIf this notebook pleased you in any way, or learned you anything, you can upvote it. As I plan to write other notebooks in the future, you can also follow me to be informed when that will happen.","0b7f658c":"The frequent vocabulary of the disaster tweets is dark (\"suicide\", \"killed\", \"Hiroshima\", \"crash\", etc.). On another side, the vocabulary of the non-disaster tweets is more positive, or at least more neutral. It includes in particular the word \"love\".<br>","552fd056":"## **Table of content**\n<br>\n\n[Introduction](#introduction)<br>\n[I. Preliminaries](#I)<br>\n[II. Cleaning](#II)<br>\n[III Keywords analysis](#III)<br>\n[IV Locations analysis](#IV)<br>\n[V Text analysis](#V)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.1 N-grams occurrences](#V.1)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.2 Frequencies of disasters by n-grams](#V.2)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.3 Tweets lengths](#V.3)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.4 Stop words](#V.4)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.5 URL](#V.5)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.6 Punctuation marks](#V.5)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.1 All punctuation marks](#V.6.1)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.2 Dots](#V.6.2)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.3 Exclamation marks](#V.6.3)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.4 Question marks](#V.6.4)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.5 Colons](#V.6.5)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.6 Ampersands](#V.6.6)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.7 Hyphens](#V.6.7)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.8 Slashes](#V.6.8)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.9 Asterisks](#V.6.9)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.10 Hashtags](#V.6.10)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.11 Mentions](#V.6.11)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.12 Underscores](#V.6.12)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.13 Apostrophes](#V.6.13)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.6.14 Conclusion](#V.6.14)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.7 Part-of-speech tagging](#V.7)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.1 Plural common nouns](#V.7.1)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.2 Singular proper nouns](#V.7.2)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.3 Past tense verbs ](#V.7.3)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.4 Past participle verbs](#V.7.4)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.5 Non-3rd person singular present verbs](#V.7.5)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.6 Modals](#V.7.6)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.7 Personnal pronouns](#V.7.7)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.8 Possessive pronouns](#V.7.8)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.9 Adverbs](#V.7.9)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.10 Wh-adverbs](#V.7.10)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.11 Interjections](#V.7.11)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.7.12 Conclusion](#V.7.12)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.8 Characters](#V.8)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.8.1 Uppercases](#V.8.1)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.8.2 Lowercases](#V.8.2)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.8.3 All characters](#V.8.3)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.8.4 Start with uppercase](#V.8.4)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [V.8.5 Conclusion](#V.8.5)<br>\n&nbsp;&nbsp;&nbsp;&nbsp; [V.9 Correlations](#V.9)<br>\n[VI. General Conclusion](#VI)<br>\n[VII. Potential extensions](#VII)<br>\n[VIII. Bibliographic references](#VIII)<br>","b104d45c":"We create a dictionarry containing all","a09923d9":"<br>\n\n# **V.7.6 Modals** <a id='V.7.6'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"MD\" stands for modal auxiliary. Examples of words falling into this POS tags are \"can\", \"cannot\", \"could\", \"may\", \"might\", \"should\" and \"would\".","429198a9":"The impact of asterisks presence is great. Nevertheless, this impact has been computed on very few tweets (just 0.8% of the training set).","02b5e384":"Below are 10 examples of detected contractions.","c93d15dd":"To conclude, the frequency of disasters decreases when the count of stop words increases.<be>\n<br>\n<br>\n\n# **V.5 URL study** <a id='V.5'><\/a>","86f36116":"# **V.7.3 Past tense verbs** <a id='V.7.3'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"VBD\" stands for past tense verb.","db8ef4d5":"# **V.6.10 Hashtags** <a id='V.6.10'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; On tweeter, people use the hashtag symbol (#) before a relevant keyword or phrase in their tweets to categorize those tweets and help them show more easily in twitter search. You can find more information about the use of hashtags on Twitter [here](https:\/\/help.twitter.com\/en\/using-twitter\/how-to-use-hashtags).","d83f80d4":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We conclude the tweets with singular proper nouns, plural nouns, past tense verbs and past participle verbs are more prone to relate disasters. Those with personal pronouns, possessive pronouns, modals, adverbs, non-3rd person singular present verbs, interjections, and Wh-adverbs are less prone to relate disasters.<br>\n<br>\n\n# **V.8 Characters** <a id='V.8'><\/a>","3c76a836":"# **V.7.1 Plural common nouns** <a id='V.7.1'><\/a>\n<br>\n\nHere, we will study the influence of the number of words that are plural common nouns in tweets. <br>\n<br>\nIn the Penn Treebank tagset, the tag \"NNS\" stands for plural common nouns.","de787989":"First of all, let's take a look at the training and test sets.","a69a0ada":"Examples of corrected tweets.","da7746c6":"Roughly, the frequency of disaster tends to decrease when the usage of stop words increases.<br>\nBetween 0 and 5 stop words, the frequency of disaster is above the average. <br>\nBetween 5 and 7, it is approximately equal to the average.<br>\nBetween 7 and 14, it decreases a lot. <br>\nThe peak of frequency at 15 stop words is due to the fact it is computed on just 3 samples. So it is untrustworthy","0f58b727":"The interpretation is exactly the same as the latest one.<br>\n<br>\n\n# **V.7.5 Non-3rd person singular present verbs** <a id='V.7.5'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"VBP\" stands for non-3rd person singular present verbs.","32d4d8bb":"# **V.8.4 Start with a capital letter** <a id='V.8.4'><\/a>\n<br>\n\nA properly written tweet should start with a capital letter. Let's wonder if such tweets tend to relate real disasters more often than others.","4fadefc2":"For more visibility, the latest chart did not display the porportions of tweets having 10 or more dots. Indeed, few tweets contain more than 9 dots. The same visualization choice has been done later in the notebook without further explanation.","ba514351":"To check if the impact of the presence of at least 3 dots is due to sampling fluctuation, let's use a chi-squared test of independence.","eb73d1f5":"The tweets with less than 40 lowercase characters are generally less prone to relate real disasters. Those with more than 40 and less than 100 lowercase characters have a frequency of disasters above the average. The effect is less clear for larger amounts, but it seems the tweets with more than 100 lowercase characters are also less prone to relate real disasters. ","db7acb75":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The most common words are stopwords. A stopword is a word used so frequently that the information of its presence (or absence) in a sentence is not meaningful. They are typically the kind of words we do not use with search engine because they are not discriminant. Example of stopwords are \"the\" or \"a\".<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Hence, to distinguish the most common meaningful words, let's remove the stopwords. Below is the same graph as previously, except that the occurrences are counted after removing the stopwords. There is no universally used list of stop words. Here, we will use the one provided by the nltk module of python.<br>","d81cb71c":"The tweets with past tense verbs are slightly more prone to relate disasters.","836b41c6":"Although there are more non-disasters tweets, their most frequent words appear approximately as many times as in disaster tweets. As we will see next, this fact is not due to a greater number of words in the disaster tweets.<br>\n<br>\nNow let's explore the bigrams, that is to say pairs of successive words.","8dc59b87":"The precedent results are self explanatory.<br>\n<br>\n# **V.6.6 Ampersands** <a id='V.6.6'><\/a>","f999462d":"Initialisation of the random number generators.","e4879cad":"The frequency of disasters do not seem to be linked to the dots count. The frequency is approximately constant and equal to the average for 0, 1, 2 or 4 dots. The variations of the frequency are not reliably interpretable beyond 4 dots by tweets.<br>\nThe only exception appears for 3 dots. As illustrated below, generally, the three dots stand for an ellipsis.","7807f89b":"Below are examples of the use of asterisks in tweets.","6acf05fc":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To study the word occurences in disaster tweets and then in non-disaster tweets would not be efficient to measure the impact of the keyword predictor. For instance, a keyword appearing numerous times in disaster tweets could also appear even more times in non-disaster tweets. Similarly, a keyword could occur few times in disaster tweets but even fewer in non-disaster tweets (and we should not trust too much the frequencies computed with rare keywords). So we cannot deduce the influence of a keyword from from its number of occurences. Consequently, to quantify the impact of each keyword, it is more efficient to compute the frequency of tweets relating disasters among those having this keyword.<br>\n<br>\nThe 20 highest frequencies are given below.","3b2e67e2":"<br>\n\n# **V.7.10 Wh-adverbs** <a id='V.7.10'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"WRB\" stands for Wh-adverb. Examples of what is called Wh-adverbs in this context are : \"how\", \"however\", \"whence\", \"whenever\", \"where\", \"whereby\", \"whereever\", \"wherein\", \"whereof\", and \"why\".","69840e99":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The reliability of these results depends on the number of times each keyword occurs in the training set. \nIf, for example, a keyword appeared in only one row but was associated with a disaster, then it would have a frequency of disaster equal to 100%. Nevertheless, this result would bring few information (as it would be particularly subject to sampling fluctuation, since it would concern just one tweet).","3f4cdf0b":"<br>\n\n# **V.7.12 Conclusion** <a id='V.7.12'><\/a>\n<br>","95af856f":"That corroborates the hypothesis we made when we analysed the n-grams occurences. Nevertheless, the effect is particularly small.<br>\n<br>\nThe rest of this part is a bit repetive. So you can directly jump to the conclusion (part V.7.12) to have a summarize of the results.<br>\n<br>\n\n# **V.7.4 Past participle verbs** <a id='V.7.4'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"VBN\" stands for past participle verbs.","ecc43fa1":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Roughly, the frequency is equal to the average for the tweets with 0 to 11 punctuation marks. Beyond 11 punctuation marks, there is no real trend and there are not enough tweets to conclude anything reliable. The frequency is then volatile and untrustworthy (hence the width of the 95% confidence interval).<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It seems reasonable to think that tweets concerning real disasters are written with a better language level, paying more attention to punctuation, unlike most tweets which only use exclamation marks (!), ats (@) or hashtags (#) for punctuation.<br>\nConsequently, let's explore the relationships between disasters and some individual punctuation marks (like dots or exclamation marks). <br>\n<br>\nFirst, here are the counts of each punctuation mark in the training set.","1360333a":"Let's focuse on the correlations whose the absolute value is above 0.5.","a7926824":"![image.png](attachment:image.png)","4b720158":"Once the stop words removed, the tweet are all shorter.","e8755c6c":"Subsequently, we will study the n-grams occurences specific to disaster tweets and to non-disaster tweets (from the training set).","e9c48994":"We apply these corrections to the training and test set.","6bb8d75f":"# **V.7.2 Singular proper nouns** <a id='V.7.2'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"NNP\" stands for singular proper nouns.","6dbb47e7":"<br>\n\n# **V.7.7 Personnal pronouns** <a id='V.7.7'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"PRP\" stands for personal pronoun.","afc1eddd":"# **V.6.13 Apostrophes** <a id='V.6.13'><\/a>","08c8eee2":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This corroborates our previous observations as the words associated to the lowest frequencies of disasters relate feelings (\"love\", \"lol\", \"feel\", \"want\", \"good\") and contingencies (\"think\", \"god\"). \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Moreover, the words associated to the highest frequencies of disasters contain past forms (\"killed\", \"found\"), unlike the ones associated with the lowest frequencies (except \"let\" that can be a past form). In addition, the words associated with high frequencies of disasters (such as \"bomber\", \"atomic\", \"killed\", \"suicide\") are darker than the ones associated with low frequencies (such as \"full\", \"body\" or \"lol\", that are neutral or joyful).\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can also explore the frequency of disaster by bigram. However, even the most frequent bigrams remain rare. So we have to consider bigrams occurring in much less than 50 tweets to have something to explore.<br> \nThe chart below show the 20 bigrams with the highest frequencies of disaster, among the bigrams that appear in at least 25 tweets of the training set.","f822e782":"Here are some examples of corrections concerning the ampersands.","e648b1c5":"# **Introduction** <a id='introduction'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this competition, named [\"Real or Not? NLP with Disaster Tweets\"](https:\/\/www.kaggle.com\/c\/nlp-getting-started), we have a dataset of thousands of tweets hand classified as relating a disaster or not relating a disaster. The challenge is to predict which tweets are about real disasters.<br>\n<br>\nThis notebook consists in an exploratory data analysis of the tweets.<br>\n<br>\n<br>\nWhat will you find in this notebook ?<br>\n*   An automatic cleaning of contractions.\n*   An analysis of the keywords and locations related to disaster tweets and to non-disaster tweets. \n*   An analysis of the frequency of disaster by n-gram. Usually, people just look at n-gram occurences. But the fact a word appears in many disaster tweets do not mean it is linked to disasters as it can also appear in a lot of non-disaster tweets. Therefore, the frequency of disaster associated to each n-gram is an insightful metric.\n*   An analysis of the impact of the counts of words, characters, stop words, URL, parts-of-speech taggings, dots, question marks, exclamation marks, and any punctuation marks frequent enough.\n*   A look at the correlations of the precedent variables.\n*   Visualizations of each effect.\n*   Statistical tests and measures of effect sizes.\n*   Several functions you can reuse for you own projects (to visualize data, to analyze frequencies of disasters, to perform statistical tests, etc.).\n*   An explanation of some concepts of natural language processing, as tokenization, stop words, part-of-speech taggings, etc.\n*   Detailed explanations of each part of the analysis.\n*   A critical view of the analysis performed in this notebook.\n*   Bibliographic references.","c01743ee":"# **V.8.5 Conclusion** <a id='V.8.5'><\/a>","31086492":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The ranking given by the Cohen's d should not be taken literally. It is just one measure of effects size, among others. But it is coherent and helpful as it gives a rough idea of the effects. <br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We conclude the tweets with URL, colons, ellipsis (or more precisely with at least 3 dots), hyphens, hashtags and slashes are more prone to relate disasters. Those with question marks, exclamation marks, asterisks, mentions, ampersands and underscores are less prone to relate disasters.<br>\n<br>\n\n# **V.7 Part-of-speech tagging** <a id='V.7'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A part-of-speech (noted POS) is a category of words that have similar grammatical properties. Examples of POS are noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, numeral, article, and determiner.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Part-of-speech tagging is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this section, we will use part-of-speech tagging in order to study statistical relations between the propensity of tweets to relate disasters and the usage of words from particular part-of-speech.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A tagset is a set of part-of-speech tags. As an illustration, a tagset named Universal POS tags contains the following part-of-speech marks.<br>\n\n\\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}\\hline\\\\\n\\mathcal{POS\\>\\>tag} & {\\small ADJ} & {\\small ADP} & {\\small ADV} & {\\small AUX} & {\\small CCONJ} & {\\small DET} & {\\small INTJ} & {\\small NOUN} & {\\small NUM} & {\\small PART} & {\\small PRON} & {\\small PROPN} & {\\small PUNCT} & {\\small SCONJ} & {\\small SYM} & {\\small VERB} & {\\small X}\\\\ \\hline\\\\\n\\mathcal{Description} & {\\small Adjective} & {\\small Adposition} & {\\small Adverbe} & {\\small Auxiliary} & {\\small Coordinating\\\\ \\small conjunction} & {\\small Determiner} &{\\small Interjection} & {\\small Noun} & {\\small Numeral} & {\\small Particle} & {\\small Pronoun} & {\\small Proper\\>\\>noun} & {\\small Punctuation} & {\\small Subordinating\\\\ \\small conjunction} & {\\small Symbol} & {\\small Verb} & {\\small Other} \\\\ \\hline\n\\end{array}\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Universal POS tags uses 17 POS tags. It is relatively few. Others use more than 30 POS tags. Indeed, some tagset use different POS tags for singular and plural nouns, for comparative and superlative adjectives, etc. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Thus, we will use the [Penn Treebank tagset](https:\/\/www.ling.upenn.edu\/courses\/Fall_2003\/ling001\/penn_treebank_pos.html) which is more specific. For instance, it uses a POS tag for the past tense verb and another for present tense verb whereas the Universal POS tags only contain one POS tag for all the verbs. That particularity allows the analysis to be more precise. Maybe, the presence of verbs in the past tense do not have the same effect on the target variable than the presence of present tense verbs.<br>\n<br>\nThe below table provides the list of the part-of-speech tags used in the Penn Treebank project.","6af2dbed":"# **V.6.1 All punctuation marks** <a id='V.6.1'><\/a>","64323164":"The frequency of disaster clearly increases with the number of plural common nouns.<br>\n<br>\nAs more than half of the tweets do not have any plural common noun (at least, not one identified by our tagger), it is still meaningful to study the influence of the presence of plural common nouns.","5997d083":"# **V.8.3 All characters** <a id='V.8.3'><\/a>\n<br>\nAfter the uppercases and lowercases count, let's have a look at the total numbers of characters. This metric can be seen as another way to define the tweets lengths (that we previously define by the number of tokens).","8b2d24ab":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The p-value of the chi-squared test of independence is particularly low. In addition, the Cochran criterion is satisfied. So we conclude in a statistically significant way (at level 5%) that the URL presence impacts the propensity of tweets to relate real disasters.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Warning! Do not confuse statistical significance and practical significance. A statistically significant result may have a weak effect. In that case, the result is statistically significant but not practically significant. <br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An example of effect size measure is the [Cohen's d](https:\/\/en.wikipedia.org\/wiki\/Effect_size#Cohen's_d). It is defined as the difference between the two means divided by a weighted average of the standard deviations of each group (the formula is clear from the code). That makes sense since greater are the standard deviations of the frequencies in the two groups, more chance there is we observe an effect due to sampling fluctuation. <br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The previous table show that the effect size of the presence of URL, as measured by the Cohen's d, is equal to 51%. This Cohen's d can be interpreted as a medium measure of the effect size.<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Below is a table providing rough interpretations of orders of magnitude of Cohen's d values. ","27e1a11f":"# **V.8.2 Minuscules** <a id='V.8.2'><\/a>","ae5daec5":"Most of the correlations do not reveal anything we did not already know.<br>\n\n*   The link between the tweet length and the tweet length without stop words is obvious.<br>\n*   The relationship between the amount of words and the amount of characters is evident too.<br>\n*   Another obvious one is the link between the number of characters and the number of lowercase letters.<br>\n*   As proper nouns begin with a capital letter, the proper noun counts is linked to the uppercases count.<br>\n*   The stop words list we used contains some verbal forms as \"am\", \"is\", \"are\", \"has\" or \"does\" because they bring few information. Hence the correlation between the stop words count and the personnal pronouns count.<br>\n*   The relationship between the tweet length and the stop words count is not surprising because, generally, more words a tweet contains, more stop words it will contain. <br>\n*   It is expected that the amount of verbs increases with the use of personnal pronouns. So it is unsurprising that the use of non-3rd person singular present verbs increases with the use of personnal pronouns.<br>\n*   The tweets with mentions start less often with a capital letter. That is explained by the fact the mention are generally at the beginning of the tweets. Although we looked at the first character after having removed the mentions, the user of Tweeter generally do not use a capital letter as first character after a mention.<br>\n<br>\n\nAnother correlation is more meaningful.<br>\n\n*   The tweet length decreases when the URL count increases. Remember that the tweet length has been computed after removing the URL. Hence, this reveals that, generally, more a tweet contains URL, less it will contain text in addition.<br>","42ca31a9":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The tweets with 1 or 2 url tend to relate disasters more often than the ones without any URL. However, the confidence we have in the empirical frequencies computed for the tweets with 3 or 4 URL is low.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Hence, the frequencies of disasters computed for the tweets with 3 or 4 URL are not reliable. Consequently, instead of studying the relationship between the frequency and the number of URL, we can gather all the tweets with at least one URL in a single group and simply analyse the relationship between the frequency of disaster and the presence of URL in a tweet. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As many variables have this kind of distribution, this approach will be used many times later in this notebook, without explaining why again.<br>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  To check if the impact of the presence of URL is due to sampling fluctuation, we can use a chi-squared test of independence between the target variable and an indicator variable taking the value 1 for the tweets with URL and 0 for the others. I gave a detailed explanation of chi-squared tests of independence, adressing the Cochran's criterion and the multiple testing problem, in [this previous notebook](https:\/\/www.kaggle.com\/robinmunier\/categorical-feature-encoding-challenge-ii). So the reader is assumed to understand the following lines of code and the results (otherwise, just check my previous notebook).","9a47b110":"# **NLP - Deep EDA of Disaster Tweets**\n\nby Robin Munier\n\n---\n\n<br>\n","46bab6a9":"Besides, some tweets have the same content but different locations or keywords. Here are some examples.","7d32fd56":"Hence, for more visibility, the following chart does not display the tweets with more than 25 punctuation marks.","980a14a8":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To conclude, the tiny p-value of the test suggests it is very likely that the presence of exclamation marks negatively impact the frequency of disasters. On the other hand, the Cohen's d suggests this effect should not be huge.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The rest of this part is repetitive. It consists in the test of the impact of the presence of different punctuation marks. Indeed, as for exclamation marks, most of the punctuation marks are more often absent than present. So it is more judicious to study their presence than the frequency of disasters as a function of count values. Thus, you can directly jump to the conclusion <a id='V.5.14'><\/a>(section V.5.14) which gathers all these results. <br>\n<br>\n\n# **V.6.4 Question marks** <a id='V.6.4'><\/a>","d0c3fcf8":"Some punctuation marks are very rare, so we cannot extract reliable informations from their study. We will focuse on the others.<br>\n<br>\n\n# **V.6.2 Dots** <a id='V.6.2'><\/a>","a627aec7":"Appart from the keyword \"epicentre\", occuring 12 times, every other keyword on the previous figure occurs at least 32 times.","adabf257":"<br>\n\n# **V.7.8 Possessive pronouns** <a id='V.7.8'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"PRP$\" stands for possessive pronoun.","36d6d4b5":"# **II. Cleaning** <a id='II'><\/a>\n<br>\n\nBefore exploring the data, let's clean it up.<br>\n\nLet's remove the URL from the tweets. Of course, we keep a copy of the original text variable for further analysis.","bbed0e28":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not all the users of the application allow Tweeter to show the location they are tweeting from. So the missing values of this feature are unsurprising. Here is more information about the location feature in tweeter : https:\/\/help.twitter.com\/en\/using-twitter\/tweet-location <br>\n\n\nIn the training set, 43% of the tweets are about actual disasters.","2bdd47c2":"The next one shows the bigrams ranked from 20 to 40 according to this same criteria.","d3f1e210":"<br>\n\n# **V.6.3 Exclamation marks** <a id='V.6.3'><\/a>","fbe32d9b":"The last chart is self explanatory.<br>\nLet's check the influence of having more than 40 characters.","fcbb32f0":"Let's begin with unigrams, that is to say with single words. The following graph show the 20 most common words in the text variable of the traing set.","ee08a5e5":"Here are the 20 lowest frequencies.","f14b5b93":"# **IV. Locations** <a id='IV'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One could argue that the location is a discriminant predictor as more than 90% of the locations are associated  with a frequency of disaster equal either to 0 or 1.","2b6f0040":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Once more, the vocabulary of the disaster tweets is more violent, with the recurrence of the word \"bomb\" (or \"bomber\" and \"bombing\"), for instance. If we did not know wich chart described the distribution of bigrams among the disaster tweets, it would not be hard to guess (as an example, I showed the two previous graphs without titles and captions to a friend and she quickly guessed which one was about real disasters).<br>\n<br>\n\nFurthermore, overall, the bigrams counts are larger in disaster tweets (although there are more non-disaster tweets).","71dd6664":"# **V.6.8 Slashes** <a id='V.6.8'><\/a>","a0235f9f":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The apostrophe is an example of punctuation marks that has apparently no impact. The cochran citerion is satisfied so the test is meaningful. But the p-value is very high. Consequently, the test does not allow to reject the null hypothesis of independence between the apostrophe presence and the target variable.<br>\n<br>\n\n# **V.6.14 Conclusion** <a id='V.6.14'><\/a>\n<br>\n\nThe below table is sorted by Cohen's d values in order to highlight the punctuation marks whose the presence is the most impacting.","7afcbb35":"Generally, the tweets with less than 3 capital letters are less prone to relate real disasters. The frequency of disasters is above the average for tweets with more than 3 capital letters.<br>\n\nTherefore, let's test the impact of having more than 3 capital letters.","1131d3fe":"<br>\n\n# **V.7.9 Adverbs** <a id='V.7.9'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"RB\" stands for adverbs.","4d86f55c":"The nature of the effect is given in the last columns of the dataframe. \"Negative\" means the presence of exclamation marks has a negative impact on (or is negatively correlated to) the frequency of disasters.<br>\n<br>\n\n# **V.6 Punctuation marks** <a id='V.6'><\/a>","5e500742":"Generally, the tweets with question marks are less likely to relate real disasters. <br>\n<br>\n\n# **V.6.5 Colons** <a id='V.6.5'><\/a>","8b111121":"The training set contains some mislabellings. Indeed, some rows are differently labelled whereas they are identical. Some examples are available below.","92dbf98b":"# **III. Keywords** <a id='I'><\/a>","dbcc389e":"More generally, the uncertainty about these results increases with the number of stop words in the tweets. Indeed, few samples contain many stop words. That is illustrated with the distribution of stop words count in tweets. And the lower the number of samples used to compute the frequency, the greater the uncertainty.","54893c42":"Here, we got a rather regular tendence. The frequency tend to decrease with the use of non-3rd person singular present verbs.<br>\n<br>\nMost of the tweets have no VBP. So, as before, it is more appropriate to check the impact of the presence of VBP.","087a3092":"The tweets with at least one exclamation marks have a much lower frequency of disasters than the others. As the exclamation mark communicate a feeling, that corroborates our previous analysis.","5876197c":"The 20 keywords the most frequent in the training set are given below. They give an idea about the content of this feature.","c4128e13":"# **VII Potential extensions** <a id='VII'><\/a>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we will evoke some possible extensions of our analysis. The word \"extension\" should not be understood in the sense of \"what should we do next this EDA to produce a predictive model\" (what I will do in another notebook) but in the sense \"how could we improve the present EDA\".\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We could extend this EDA in many ways. We could for example use other tokenizers, other sets of stop words, other tagsets, other statistical tests, other effect size mesures, and other metrics to monitor. We could also apply other cleaning (like spell checking the text variable) and feature engineering. Furthermore, traning models in order to study their outputs, the kind of errors they make, and how they use each variable can be an efficient way to get a better understanding of the data.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An example of another metric to monitor could be the number of spelling mistakes. To compute this metric would require either to use a spellchecker, either to define a set of spelling mistakes to check for. Another metric could be the number of contractions, as corrected during the cleaning part of this notebook. Or the number of time a tweet is duplicated. <br>\n<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We could also apply different feature engineering techniques to the variables we created. In this notebook, we studied the POS tags occurences. Another metric could be the porportion of each POS tag in each tweet. For example, the proportion of plural common nouns in a tweet would be the number of plural common nouns divided by the number of words in this tweet.  Thus, we could analyze the frequency of disasters in term of the porportions instead of occurences.<br>\nIndeed, if the number of plural common nouns in tweets tend to be positively correlated with the tweet length, then the influence we associate to the number of plural common nouns could actually be only due to the fact tweets with numerous plural common nouns are the long ones. <br>\nAs we already studied the impact of the number of words, we don't want it to influence the analysis of the POS tags. That would be the rationale behind that choice. <br>\n\nNevertheless, there is some pitfalls with this approach.\n\n*   Firstly, even when the tweet length is positively correlated with the count of a particular POS tag count, the correlation is often low. An example is the correlation between the tweet length and the singular proper nouns count (the Spearman correlation is roughly equal to 10%). \n*   Secondly, the link between the tweet length and a particular POS tag count is sometimes not monotone, leading to a correlation close to zero. We can imagine that the user of Tweeter use more often some categories of words in short tweets than in longer tweets. \n\nHence, to study the POS tags counts grasps an information that is different than the one provided by the POS tags proportions.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The idea of divided the counts by the tweet length could also be done with other features, like the URL count or the stop words count. Furthermore, the particular punctuation marks (like question marks, exclamation marks, etc.) counts in each tweet could be divided by the total number of punctuation marks in the tweet. <br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The interactions could possibly be studied by analyzing tree-based algorithm (like gradient boosted trees). Maybe the simultaneous presence of particular a punctuation mark and a particular POS tag would explain well one of the characteristics of the disaster tweets.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The possible extensions presented here are just few ideas. The list is not exhaustive. But this notebook already go far beyond what is commonly done on Kaggle. So I let you find other interesting metrics for an data analysis.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I will soon publish a second notebook on this competition. Given that this notebook consist in an EDA, without anything about modeling, the next one will mainly consist in the implementation of a predictive model.<br>\n<br>","e0d41061":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; According to the distribution of exclamation marks count, the frequencies of disasters computed for the tweets with any fixed value of count superior to 1 woud be untrustworthy. On the other hand, more than 9% of the tweets contain at least one exclamation mark. So instead of studying the relationship between the frequency and the number of exclamation marks, we can gather all the tweets with at least one exclamation mark in a single group and simply analyse the relationship between the frequency and the presence of exclamation marks in a tweet.","31c57469":"# **V.6.12 Underscores** <a id='V.6.12'><\/a>","b4b6a50a":"Let's try to explain why the frequency of disaster tweets is lower among the tweets with particularly short or long lentghs. Below are examples of tweets including less than 7 words.","bce15505":"These last samples are self explanatory. The medium length tweets are more diverse. Moreover, as stated before, tweeters tend generally to write about disaster with medium length tweets. In general, they seem to be more serious and neutral than short tweets and long tweets.<br>\n<br>\nOur precedent computation of the tweet lengths considered the stop words. To remove the stop words and recompute the length lead to a similar interpretation.","610f4e0f":"# **V.8.1 Capital letters** <a id='V.8.1'><\/a>\n<br>\n\nHere, we will study the impact of the number of capital letters. But, before computing the amount of capital letters, we will remove the mentions. Indeed, they sometimes contain capital letters, so their presence could bias a little bit the analysis.","8fc8c4ad":"An explanation of why the long tweets concern less frequently real disasters than medium ones is that most of them are anecdotes or jokes. Some are also quotes of famous people. On another hand, some deal with real disasters with many words. But, generally, tweeters seem to use more words to talk about their own stories or to interject humour than to evoke disasters.\n\nFinally, here are examples of medium length tweets.","26e20a62":"Let's display the versions for reproducibility.","466eaf74":"# **I. Preliminaries** <a id='I'><\/a>\n<br>\n\nInstallation of some libraries.","32cf5b72":"Thus, care should be taken with the robustness of the previous results.<br>\n\nIt is still interesting to remark that all the tweets with the keywords \"debris\", \"wreckage\" or \"derailment\" are about actual disasters. This involves 115 rows.","be50cdab":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The presence of the same tweets several times could be due to retweets. A retweet is the republishing of a post that another Twitter user has written.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some duplicates could be caused by errors when collecting the data. Nevertheless, having no more information, we will keep all the duplicates (both duplicated rows or just duplicated tweets). Either way, this only involves a small part of the samples.<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Only the keyword and location features have missing values. Their porportion of missing values are respectively equal to 0.8% and 33.3% in the training set and to O.8% and 33.9% in the test set.","b33ed83b":"The frequency is small for the tweets without any NNP. For those with 1 to 9 NNP, it is slightly above the average. For those with more than 10 NNP, the frequency go down, but there are too few such tweets for us to be confident in this last statement. <br>\n<br>\nRoughly, we can summarise this tendency by saying that the tweets without any plural proper noun are less likely to relate real disasters.","84843a6e":"We restraint the abscissa of the following chart between 0 and 20 as the interpolation is not reliable for larger capital letters counts.","94f0966f":"So the tweets with an ellipsis tend to be linked with actual disasters. All the tweets with at least 3 dots can contain an ellipsis. So we can catch all the tweets with elllipsis this way. Of course, not all tweets with more than 2 dots have ellipsis. <br>","883de7ad":"<br>\n\n# **V.7.11 Interjections** <a id='V.7.11'><\/a>\n<br>\n\nIn the Penn Treebank tagset, the tag \"UH\" stands for interjections.","cedfeca8":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A word that appears in just one or two tweets can easily have a frequency of apparition in disaster tweets equal to 1. Nonetheless, such words are not relevant for our analysis as they bring no reliable information. Reliable information comes from recurrences. Thus, we only consider the words occurring in at least 50 tweets in the computations.","9ded0389":"Data import.","c2d3a760":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Furthermore, it is also possible to visualize the link between the (keyword, location) pairs and the target variable. However, most of the locations are rare and the (keyword, location) pairs are even rarer. It is therefore unlikely that we deduce anything useful from this.<br>\n\nFor example, the most represented (keyword, location) pair is \"sandstorm_USA\". As shown below, it is present 17 times only and the 17 concerned tweets have the same text. So it does not bring useful informations.<br>","dc4a941b":"Here, we create a new variable containing the list of the words of the tweets and the POS tags associated to each one (by the \"pos_tag\" tagger from the nltk module of python).","60229760":"![image.png](attachment:image.png)"}}