{"cell_type":{"29c69868":"code","cceee564":"code","c7966cfc":"code","52dd1cd8":"code","fda88469":"code","be972396":"code","1373fcd6":"code","8df3448c":"code","2f17bd8a":"code","b7e352ec":"code","f21ec59e":"code","2846e8a7":"code","29e647ec":"code","bb24ccc4":"code","0612e228":"code","b4b5170e":"code","31eba49d":"code","9958472b":"code","d591f963":"code","ba42413b":"code","61c3ec95":"code","ff62a2c3":"code","069c0b6b":"code","4b60e98e":"code","7e975945":"code","a7ea2560":"code","a18e1561":"code","89fb5006":"code","58580089":"code","7a3e6c4d":"code","0ef94e0c":"code","fae214c7":"code","f20e8839":"code","7385b9ac":"code","781f019c":"code","f4e3a1d8":"code","385ff3e4":"code","387e8815":"code","4c7f52bb":"code","377befd4":"code","45a602eb":"code","296e1a86":"code","04e838d4":"code","fa326c87":"code","e37c704d":"code","2e35a702":"code","bd3d2dd6":"code","ee156922":"code","dcc71c31":"code","a84164da":"code","3656a916":"code","08c93c9b":"markdown","88dd38fa":"markdown","a4117434":"markdown","e4178002":"markdown","fb941539":"markdown","d6372993":"markdown","61e23d4c":"markdown","2747d1cd":"markdown","c7ed729d":"markdown","83e00ca9":"markdown","cb2f9000":"markdown"},"source":{"29c69868":"import numpy as np\nimport pandas\nimport seaborn\nimport matplotlib.pyplot as plt","cceee564":"from tensorflow import keras","c7966cfc":"info = {0 : 'Normal', 1 : 'Pnuemonia'}","52dd1cd8":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import MaxPooling2D\n\nfrom keras import Input\nfrom keras.layers import Flatten","fda88469":"def conv_layer (filterx) :\n    \n    model = Sequential()\n    \n    model.add(Conv2D(filterx, (3,3), activation = 'relu', padding = 'same', kernel_regularizer = 'l2'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(MaxPooling2D((2,2), padding = 'valid'))\n    \n    return model","be972396":"def dens_layer (hiddenx) :\n    \n    model = Sequential()\n    \n    model.add(Dense(hiddenx, activation = 'relu', kernel_regularizer = 'l2'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    return model","1373fcd6":"def cnn (filter1, filter2, filter3, hidden1) :\n    \n    # create the cnn  model\n    model = Sequential()\n    model.add(Input(shape = (128, 128, 1,)))\n    \n    # add convolution layer\n    model.add(conv_layer(filter1))\n    model.add(conv_layer(filter2))\n    model.add(conv_layer(filter3))\n    \n    # flatten and hidden layer\n    model.add(Flatten())\n    model.add(dens_layer(hidden1))\n    \n    # output layer\n    model.add(Dense(1, activation = 'sigmoid'))\n    \n    # compile the model\n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","8df3448c":"train_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/'\ntest_path  = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/'\neval_path  = '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/'","2f17bd8a":"import os\nfrom sklearn.utils import shuffle\ndef give_set (path) :\n    \n    X = []\n    y = []\n    for label in os.listdir(path) :\n        for img in os.listdir(path+label + '\/') :\n\n            img_path = path + label + '\/' + img\n            image = keras.preprocessing.image.load_img(img_path, color_mode = 'grayscale', target_size = (128,128))\n    \n            X.append(keras.preprocessing.image.img_to_array(image))\n            y.append(1 if label == 'PNEUMONIA' else 0)\n\n    X = np.array(X, dtype = float)\n    y = np.array(y)\n    \n    return shuffle(X,y)","b7e352ec":"X_train, y_train = give_set(train_path)\nX_eval, y_eval = give_set(eval_path)\nX_test, y_test = give_set(test_path)","f21ec59e":"X_train \/= 255.0\nX_eval  \/= 255.0\nX_test  \/= 255.0","2846e8a7":"print(X_train.shape)\nprint(y_train.shape)","29e647ec":"fig = plt.figure(figsize = (7,5))\n\nplt.hist(y_train)\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('Distribution for training data')\nplt.show()","bb24ccc4":"print(X_eval.shape)\nprint(y_eval.shape)","0612e228":"fig = plt.figure(figsize = (7,5))\nplt.hist(y_eval)\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('Distribution for validation data')\nplt.show()","b4b5170e":"print(X_test.shape)\nprint(y_test.shape)","31eba49d":"fig = plt.figure(figsize = (7,5))\nplt.hist(y_test)\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('Distribution for testing data')\nplt.show()","9958472b":"print(y_train[:30])","d591f963":"plt.figure(figsize = (15,15))\nfor i in range(16) :\n    plt.subplot(4,4,i+1)\n    plt.imshow(X_train[i], 'gray')\n    plt.title(info[y_train[i]])\n    plt.axis('off')\nplt.show()","ba42413b":"print(y_train[y_train == 0].shape[0]\/y_train.shape[0])","61c3ec95":"from imblearn.over_sampling import SMOTE\n\nX_train = X_train.reshape(5216, 128*128*1)\nprint(X_train.shape)\nprint(y_train.shape)","ff62a2c3":"X_train, y_train = SMOTE(sampling_strategy = 'auto', k_neighbors = 5, random_state = 1).fit_resample(X_train, y_train)","069c0b6b":"print(X_train.shape)\nprint(y_train.shape)","4b60e98e":"X_train = X_train.reshape(7750, 128, 128, 1)","7e975945":"print(X_train.shape)\nprint(y_train.shape)","a7ea2560":"print(y_train[y_train == 0].shape[0]\/y_train.shape[0])","a18e1561":"plt.figure(figsize = (15,15))\nfor i in range(16) :\n    plt.subplot(4,4,i+1)\n    plt.imshow(X_train[-(i+100)], 'gray')\n    plt.title(info[y_train[-(i+100)]])\n    plt.axis('off')\nplt.show()","89fb5006":"fig = plt.figure(figsize = (7,5))\n\nplt.hist(y_train)\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('Distribution for training data')\nplt.show()","58580089":"from keras.preprocessing.image import ImageDataGenerator\ntrain_gen = ImageDataGenerator(zoom_range = [0.85,1.0], width_shift_range = 0.02, rotation_range = 5)","7a3e6c4d":"train_gen.fit(X_train)\nitr = train_gen.flow(X_train, y_train, batch_size = 32)","0ef94e0c":"trainX, trainy = itr.next()","fae214c7":"plt.figure(figsize=(15,15))\nfor i in range(16) :\n    plt.subplot(4,4,i+1)\n    plt.imshow(trainX[i], 'gray')\n    plt.title(info[trainy[i]])\n    plt.axis('off')\nplt.show()","f20e8839":"plt.figure(figsize=(15,15))\nfor i in range(16) :\n    plt.subplot(4,4,i+1)\n    plt.imshow(X_test[i], 'gray')\n    plt.title(info[y_test[i]])\n    plt.axis('off')\nplt.show()","7385b9ac":"model = keras.wrappers.scikit_learn.KerasClassifier(build_fn = cnn, verbose = 1)","781f019c":"from sklearn.model_selection import RandomizedSearchCV, KFold","f4e3a1d8":"param = {\n    'filter1' : [128, 200],\n    'filter2' : [32, 64],\n    'filter3' : [16, 32],\n    'hidden1' : [32, 64],\n}\ngrd = RandomizedSearchCV(estimator = model, param_distributions = param, cv = KFold(n_splits = 2, shuffle = True, random_state = 1), verbose = 1)","385ff3e4":"search = grd.fit(X_train, y_train, epochs = 50, batch_size = 32, verbose = 0)","387e8815":"print(search.best_params_)","4c7f52bb":"model = cnn(128, 32, 32, 64)\nprint(model.summary())","377befd4":"from keras.callbacks import ReduceLROnPlateau\nreduce = ReduceLROnPlateau(monitor = 'val_loss', patience  = 10)","45a602eb":"history = model.fit(train_gen.flow(X_train, y_train, batch_size = 32), epochs = 125, validation_data = (X_eval, y_eval), callbacks = [reduce], steps_per_epoch = len(X_train)\/32)","296e1a86":"fig = plt.figure(figsize = (15,5))\nplt.plot(history.history['accuracy'])                   # accuracy for the training set\nplt.plot(history.history['val_accuracy'])               # sccuracy for the validate set\nplt.legend(['training_accuracy', 'validation_accuracy'])\nplt.title('Accuracy on training set and validation set')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","04e838d4":"fig = plt.figure(figsize = (15,5))\nplt.plot(history.history['loss'])                       # loss for the training set\nplt.plot(history.history['val_loss'])                   # loss for the validate set\nplt.legend(['training_loss', 'validation_loss'])\nplt.title('Loss on training and validation set')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","fa326c87":"model.save('.\/pnue_model.h5')","e37c704d":"y_pred = model.predict(X_test)","2e35a702":"y_pred = np.array(y_pred.reshape(-1))","bd3d2dd6":"y_pred = np.around(y_pred)\ny_pred = np.array(y_pred, dtype= int)","ee156922":"print(y_pred[:10])\nprint(y_test[:10])","dcc71c31":"from sklearn.metrics import accuracy_score, classification_report","a84164da":"print('Accuarcy : ' + str(accuracy_score(y_test, y_pred)))\nprint(classification_report(y_test, y_pred, target_names = ['Negative for Pneumonia', 'Positive for pneumonia']))","3656a916":"from sklearn.metrics import confusion_matrix\ndata = confusion_matrix(y_test, y_pred)\ndf_cm = pandas.DataFrame(data, columns = np.unique(y_test), index = np.unique(y_test))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,10))\nseaborn.set(font_scale = 1.5)\nseaborn.heatmap(df_cm, cmap = 'Blues', annot = True, annot_kws = {'size' : 16}, xticklabels = ['Negative for Pneumonia', 'Positive for pneumonia'], yticklabels = ['Negative', 'Positive'])","08c93c9b":"# New generated samples","88dd38fa":"# Predict","a4117434":"# Class Distribution","e4178002":"# DATASET\n\n#### Structure\n<div style = \"text-align: justify\">The dataset is organized into three folders - train, val and test, each having two subfolders (for corresponding class) <b>NORMAL<\/b> and <b>PNEUMONIA<\/b>.<\/div>\n\n#### Source\n<div style = \"text-align: justify\">The chest X-ray images were taken from pedriatic patients from Guangzhou Women and Children\u2019s Medical Center, China. All chest radiographs were initially scanned for quality control by removing the low quality or unreadable scans.<\/div>\n\n#### Link for the dataset - [Kaggle - Chest X-ray Images](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia)","fb941539":"# Original training samples","d6372993":"# Layers\n#### Convolution layer\n<div style = \"text-align: justify\">Kernels or filters are applied on this layer, which are convolved with portions of images to capture specific features (some capture edges, others capture contrast, etc). This also assists in reducing image size. Filters can be considered as weights for images (which they are sort of).<\/div>\n\n#### BatchNormalization\n<div style = \"text-align: justify\">It happens that the cost function curve may thin out at some axis. So this normalizes the Inputs for faster training. This causes the cost curve to look something like the figure below.<\/div>\n\n![Image of cost function after normalization](https:\/\/i0.wp.com\/www.adeveloperdiary.com\/wp-content\/uploads\/2018\/11\/How-to-visualize-Gradient-Descent-using-Contour-plot-in-Python-adeveloperdiary.com-3.jpg?resize=640%2C480)\n\n#### DropOut Layer\n<div style = \"text-align: justify\">Asists in regularizing the weights by randomly deleting some units, so that the other nodes don't get to accustomed to the inputs and able to take variations into account.<\/div>\n\n#### Max Pooling Layer\n<div style = \"text-align: justify\">Move a window along the image to capture the dominant features in the image. Here the window size is (2,2).<\/div>","61e23d4c":"# CNN Model","2747d1cd":"# PNEUMONIA\n### Definition\n<div style = \"text-align: justify\">An infection in one or both lungs, caused by bacteria, virus or fungi. It involves inflammation of alveoli and causes difficulty in breathing. With Pneumonia, air sacs will fluid or pus. The disease can be life threatening, particularly to infants and people above 65 years of age.<\/div>\n\n### How to determine via Chest X-rays\n<div style = \"text-align: justify\">When interpreting the x-ray, the radiologist will look for white spots in the lungs (called infiltrates) that identify pneumonia.<\/div>","c7ed729d":"# Draw a **confusion matrix** to evaluate the performance of the model","83e00ca9":"# Dataset","cb2f9000":"# Data skewness\n#### *Will be handled by SMOTE (imblearn)*"}}