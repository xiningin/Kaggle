{"cell_type":{"fbc2a7f9":"code","a58baa1e":"code","4a2a89ab":"code","a9f63c7d":"code","15b1cabc":"code","0b884d6c":"code","2fcc8a66":"code","7d2fcf67":"code","c4e49966":"code","92434055":"code","cd543732":"code","4f91e79b":"code","05f5da1d":"code","e0a38c2b":"code","f98c15fa":"code","c6b6f1e4":"code","7d739a7d":"code","ee8930b1":"code","fa9cad03":"code","120ff788":"code","91816385":"markdown"},"source":{"fbc2a7f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a58baa1e":"train = pd.read_csv('\/kaggle\/input\/sejong-ai-termproject\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/sejong-ai-termproject\/test.csv')\nsubmit = pd.read_csv('\/kaggle\/input\/sejong-ai-termproject\/sample_submit.csv')","4a2a89ab":"label = train['\ucd5c\uadfc \uc804\ubc18\uc801\uc778 \uc0b6\uc758 \ub9cc\uc871\ub3c4']\n\ntrain = train.drop(['\ucd5c\uadfc \uc804\ubc18\uc801\uc778 \uc0b6\uc758 \ub9cc\uc871\ub3c4', '\uc790\ub8cc \uacf5\uac1c\uc77c','ID','\uad6d\uc801','\ub4f1\ub85d\uc7a5\uc560\uc778 \uc5ec\ubd80','\uc885\uad50','\ub9cc15\uc138\uc774\uc0c1 \uac00\uad6c\uc6d0\uc218','\uc131','\uc804\uccb4\uac00\uad6c\uc6d0\uc218','\uad6c\ucf54\ub4dc',\"\ucd9c\uc0dd\uc5f0\ub3c4\"], axis=1)\ntest = test.drop(['\uc790\ub8cc \uacf5\uac1c\uc77c','ID','\uad6d\uc801','\ub4f1\ub85d\uc7a5\uc560\uc778 \uc5ec\ubd80','\uc885\uad50','\ub9cc15\uc138\uc774\uc0c1 \uac00\uad6c\uc6d0\uc218','\uc131','\uc804\uccb4\uac00\uad6c\uc6d0\uc218','\uad6c\ucf54\ub4dc',\"\ucd9c\uc0dd\uc5f0\ub3c4\"], axis=1)","a9f63c7d":"train.info()","15b1cabc":"# \uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4 \ud569\uce58\uae30\ntrain['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4'] = (train['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uc911\uc559\uc815\ubd80'] + train['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uad11\uc5ed \uc9c0\uc790\uccb4'] + train['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uae30\ucd08 \uc9c0\uc790\uccb4']) \/ 3\ntest['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4'] = (test['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uc911\uc559\uc815\ubd80'] + test['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uad11\uc5ed \uc9c0\uc790\uccb4'] + test['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uae30\ucd08 \uc9c0\uc790\uccb4']) \/ 3\n\ntrain = train.drop(['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uc911\uc559\uc815\ubd80','\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uad11\uc5ed \uc9c0\uc790\uccb4','\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uae30\ucd08 \uc9c0\uc790\uccb4'], axis=1)\ntest = test.drop(['\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uc911\uc559\uc815\ubd80','\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uad11\uc5ed \uc9c0\uc790\uccb4','\uae30\uad00\ubcc4 \uc2e0\ub8b0\ub3c4_\uae30\ucd08 \uc9c0\uc790\uccb4'], axis=1)\n\n# \uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c \ud569\uce58\uae30\ntrain['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c'] = train['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c'] * train['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0\uc744 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c\uc758 \uc218']\ntest['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c'] = test['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c'] * test['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0\uc744 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c\uc758 \uc218']\n\ntrain = train.drop(['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0\uc744 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c\uc758 \uc218'], axis=1)\ntest = test.drop(['\uc5b4\ub824\uc6b8 \ub54c \ub3c4\uc6c0\uc744 \ubc1b\uc744 \uc218 \uc788\ub294 \uc0ac\ub78c\uc758 \uc218'], axis=1)\n\n# \uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd \ud569\uce58\uae30\ntrain['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd'] = (train['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub300\uae30'] + train['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc218\uc9c8'] + train['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ud1a0\uc591'] + train['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc18c\uc74c\/\uc9c4\ub3d9'] + train['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub179\uc9c0 \ud658\uacbd']) \/ 5\ntest['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd'] = (test['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub300\uae30'] + test['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc218\uc9c8'] + test['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ud1a0\uc591'] + test['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc18c\uc74c\/\uc9c4\ub3d9'] + test['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub179\uc9c0 \ud658\uacbd'])\/5\n\ntrain = train.drop(['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub300\uae30','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc218\uc9c8','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ud1a0\uc591','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc18c\uc74c\/\uc9c4\ub3d9','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub179\uc9c0 \ud658\uacbd'], axis=1)\ntest = test.drop(['\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub300\uae30','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc218\uc9c8','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ud1a0\uc591','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\uc18c\uc74c\/\uc9c4\ub3d9','\uc0b4\uace0 \uc788\ub294 \uc9c0\uc5ed \ud658\uacbd_\ub179\uc9c0 \ud658\uacbd'], axis=1)\n\n# \ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4 \ud569\uce58\uae30\ntrain['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4'] = (train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc790\uc5f0\uc7ac\ud574'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uac74\ucd95\ubb3c \ubc0f \uc2dc\uc124\ubb3c'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uad50\ud1b5\uc0ac\uace0'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ud654\uc7ac'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc815\ubcf4\ubcf4\uc548'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac']+ train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc2e0\uc885 \uc804\uc5fc\ubcd1']+ train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ubc94\uc8c4 \uc704\ud5d8'] + train['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc804\ubc18\uc801\uc778 \uc0ac\ud68c \uc548\uc804']) \/ 9\ntest['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4'] = (test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc790\uc5f0\uc7ac\ud574'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uac74\ucd95\ubb3c \ubc0f \uc2dc\uc124\ubb3c'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uad50\ud1b5\uc0ac\uace0'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ud654\uc7ac'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc815\ubcf4\ubcf4\uc548'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac']+ test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc2e0\uc885 \uc804\uc5fc\ubcd1']+ test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ubc94\uc8c4 \uc704\ud5d8'] + test['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc804\ubc18\uc801\uc778 \uc0ac\ud68c \uc548\uc804']) \/ 9\n\ntrain = train.drop(['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc790\uc5f0\uc7ac\ud574','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uac74\ucd95\ubb3c \ubc0f \uc2dc\uc124\ubb3c','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uad50\ud1b5\uc0ac\uace0','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ud654\uc7ac','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc815\ubcf4\ubcf4\uc548','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc2e0\uc885 \uc804\uc5fc\ubcd1','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ubc94\uc8c4 \uc704\ud5d8','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc804\ubc18\uc801\uc778 \uc0ac\ud68c \uc548\uc804'], axis=1)\ntest = test.drop(['\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc790\uc5f0\uc7ac\ud574','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uac74\ucd95\ubb3c \ubc0f \uc2dc\uc124\ubb3c','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uad50\ud1b5\uc0ac\uace0','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ud654\uc7ac','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc815\ubcf4\ubcf4\uc548','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uba39\uac70\ub9ac','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc2e0\uc885 \uc804\uc5fc\ubcd1','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\ubc94\uc8c4 \uc704\ud5d8','\ubd84\uc57c\ubcc4 \uc548\uc804\ub3c4_\uc804\ubc18\uc801\uc778 \uc0ac\ud68c \uc548\uc804'], axis=1)","0b884d6c":"print(train.shape)\nprint(test.shape)","2fcc8a66":"train.describe()","7d2fcf67":"def outlier_iqr(data):\n    q1, q3 = np.percentile(data, [25, 75])\n    iqr = q3-q1\n    lower = q1- (iqr*1.5)\n    upper = q3 + (iqr*1.5)  \n    return np.where((data > upper) | (data < lower))","c4e49966":"outlier0 = outlier_iqr(train['\uac00\uad6c\uc8fc\uc640\uc758 \uad00\uacc4'])[0]\n#outlier_index = set(np.concatenate([outlier0, outlier2, outlier4], axis=0))\noutlier_index = set(outlier0)\nprint(outlier_index)\nfor i in outlier_index:\n  train = train.drop(index=i, axis = 0)\n  label = label.drop(index=i, axis = 0)","92434055":"# null\uac12\uc744 0\uc73c\ub85c \ubcc0\ud658\ud574\uc90d\ub2c8\ub2e4.\n#from sklearn.impute import SimpleImputer\n#imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n#train = imp.fit_transform(train)\n#test = imp.transform(test)\nfor column in train.columns:\n    train[column] = train[column].fillna(train[column].mode()[0])\nfor column in test.columns:\n    test[column] = test[column].fillna(test[column].mode()[0])\n","cd543732":"# scaler\ub97c \uc0ac\uc6a9\ud574 \uc804\ucc98\ub9ac\ub97c \ud574\uc90d\ub2c8\ub2e4.\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\ntrain_sc = scaler.fit_transform(train)\ntest_sc = scaler.transform(test)","4f91e79b":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\n\ntorch.manual_seed(1)\nrandom.seed(1)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","05f5da1d":"X_train_sc = torch.FloatTensor(train_sc).to(device)\nX_test_sc = torch.FloatTensor(test_sc).to(device)\ny_train = torch.LongTensor(label).to(device)","e0a38c2b":"linear1 = nn.Linear(train.shape[1], 256, bias=True)\nlinear2 = nn.Linear(256,256, bias=True)\nlinear3 = nn.Linear(256,256, bias=True)\nlinear4 = nn.Linear(256, 11, bias=True)\n\nrelu = nn.ReLU()\ndropout = nn.Dropout()\n\nmodel = nn.Sequential(linear1, nn.BatchNorm1d(256), relu, dropout, \n                      linear2, nn.BatchNorm1d(256), relu, dropout, \n                      linear3, nn.BatchNorm1d(256), relu, dropout,\n                      linear4).to(device)","f98c15fa":"torch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_uniform_(linear4.weight)","c6b6f1e4":"optimizer = optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.CrossEntropyLoss().to(device)","7d739a7d":"model.train()\nepochs = 1000\nfor epoch in range(epochs + 1):\n    optimizer.zero_grad()\n    output = model(X_train_sc)\n    loss = loss_fn(output, y_train)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(\"Epoch: {:4d}, Cost: {:6f}\".format(epoch, loss.item()))","ee8930b1":"model.eval()\nwith torch.no_grad():\n    predict = model(X_test_sc)\n    predict_label = model(X_train_sc)\npredict = torch.argmax(predict, 1)\npredict_label = torch.argmax(predict_label, 1)\npredict = predict.cpu().numpy()","fa9cad03":"from sklearn.metrics import accuracy_score\naccuracy_score(predict_label.cpu().numpy(),label)","120ff788":"submit['\ucd5c\uadfc \uc804\ubc18\uc801\uc778 \uc0b6\uc758 \ub9cc\uc871\ub3c4'] = predict\nsubmit.to_csv(\"submission.csv\",index=False)","91816385":"\ub4dc\ub86d\uc544\uc6c3 0.3\uc73c\ub85c \uc124\uc815\uc2dc train \uc815\ud655\ub3c4\uac00 0.65  test\uc758 \uacbd\uc6b0 0.46283\n\nV9 iqr \uc9c4\ud589\uc804 52.74% 48.23%\nV10 iqr \uc9c4\ud589 \ud6c4 53.04% 47.856%\n->train accuracy\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc774 test\uc5d0\uc11c\uc758 \uc131\ub2a5\ud5a5\uc0c1\uc744 \uac00\uc838\uc624\uc9c0 \uc54a\uc74c\n->\uc804\ucc98\ub9ac\ub97c \ud1b5\ud55c train\/test\uac04\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \uc904\uc77c \ud544\uc694\uac00 \uc788\uc74c."}}