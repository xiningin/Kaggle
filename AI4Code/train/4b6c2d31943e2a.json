{"cell_type":{"af502f63":"code","2376d7bb":"code","10b04695":"code","f9df6821":"code","8b935238":"code","820625c7":"code","bb5afe32":"code","5ec615f5":"code","2a03ae62":"code","9694bf96":"code","3639c26f":"code","20ba7dd8":"code","54742bbb":"code","beb39219":"markdown","dbe02826":"markdown","734dcb61":"markdown","7f74cc17":"markdown","3175cf57":"markdown","44a28b9b":"markdown","e8b57feb":"markdown","e53bd6c1":"markdown","f906194e":"markdown","58a257f9":"markdown"},"source":{"af502f63":"import numpy as np\nimport math\nimport random\nimport os\nfrom PIL import Image\nimport cv2 as cv\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model, load_model\nfrom keras.layers import Input ,BatchNormalization , Activation \nfrom keras.layers.convolutional import Conv2D, UpSampling2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers \nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split","2376d7bb":"def Convolution(input_tensor,filters):\n    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x) \n    return x\n\ndef model(input_shape):\n    \n    inputs = Input((input_shape))\n    \n    conv_1 = Convolution(inputs,32)\n    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n    \n    conv_2 = Convolution(maxp_1,64)\n    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n    \n    conv_3 = Convolution(maxp_2,128)\n    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n    \n    conv_4 = Convolution(maxp_3,256)\n    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n    \n    conv_5 = Convolution(maxp_4,512)\n    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n    \n    conv_6 = Convolution(upsample_6,256)\n    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n    \n    upsample_7 = concatenate([upsample_7, conv_3])\n    \n    conv_7 = Convolution(upsample_7,128)\n    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n    \n    conv_8 = Convolution(upsample_8,64)\n    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n    \n    upsample_9 = concatenate([upsample_9, conv_1])\n    \n    conv_9 = Convolution(upsample_9,32)\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n    \n    model = Model(inputs=[inputs], outputs=[outputs]) \n    \n    return model","10b04695":"input_size = 240\nmodel = model(input_shape = (input_size, input_size, 1))\nmodel.load_weights(\"..\/input\/brain-tumour-segmentation\/BraTs2020.h5\")\nmodel.summary()","f9df6821":"path_to_training_studies = \"..\/input\/rsna-miccai-png\/train\/\"\ntraining_studies = os.listdir(path_to_training_studies)\nrandom.seed(24)\nstudies_to_view = random.choices(training_studies, k=3)","8b935238":"def prediction(img_path, save_folder=\"\"):\n    '''\n    resize the input image and run the prediction\n    while removing some noise and saving the mask if required\n    '''\n    \n    test_img = Image.open(img_path)\n    resized_img = np.array(test_img.resize((input_size, input_size)))\n    \n    result = model.predict(np.array([resized_img]))[0].transpose(2,0,1)[0]\n\n    #Remove some of the noise in the predicted mask\n    kernel = np.ones((10,10),np.uint8)\n    result = cv.morphologyEx(result, cv.MORPH_OPEN, kernel)\n    result = np.where(result > 0.9, 1, 0)\n    \n    if save_folder!=\"\":\n        save_path = img_path.replace(\"..\/input\/rsna-miccai-png\", save_folder)\n        save_path = save_path.replace(\".png\",\"-tumour-mask.png\").replace(\"\/T1w\",\"\")\n        save_folder = save_path.replace(save_path.split(\"\/\")[-1],\"\")\n        if not os.path.exists(save_folder):\n            os.mkdir(save_folder)\n        \n        resized_result = cv.resize(result.astype(\"float32\"), (512,512), interpolation = cv.INTER_AREA)\n        cv.imwrite(save_path, resized_result)\n    \n    return resized_img, result","820625c7":"def find_tumour(study_filename, save_folder=\"\", dataset=path_to_training_studies):\n    '''\n    Apply the model on all MRI slices and return the \n    slice with the greatest amount of pixels with tumour\n    '''\n    \n    max_detected = 0\n    tumour_slice = \"\"\n    MRI_slices = os.listdir(\"{}{}\/T1w\/\".format(dataset, study_filename))\n    \n    for MRI_slice_filename in MRI_slices:\n        path_to_slice = \"{}{}\/T1w\/{}\".format(dataset, study_filename, MRI_slice_filename)\n        formatted_img, result = prediction(path_to_slice, save_folder)\n        \n        tumour_pixel = len(result[result>0.5])\n        \n        if max_detected < tumour_pixel:\n            max_detected = tumour_pixel\n            tumour_slice = path_to_slice\n    return tumour_slice\n\ndef display(img, result):\n    plt.imshow(np.squeeze(img),cmap='gray')\n    plt.imshow(np.squeeze(result),alpha=0.6,cmap='Reds')\n    plt.show()","bb5afe32":"%%time\nMRI_slice_filename = find_tumour(studies_to_view[0])\nimg, result = prediction(MRI_slice_filename)\ndisplay(img, result)","5ec615f5":"%%time\nMRI_slice_filename = find_tumour(studies_to_view[1])\nimg, result = prediction(MRI_slice_filename)\ndisplay(img, result)","2a03ae62":"%%time\nMRI_slice_filename = find_tumour(studies_to_view[2])\nimg, result = prediction(MRI_slice_filename)\ndisplay(img, result)","9694bf96":"train_folder_content = os.listdir(path_to_training_studies)\nos.mkdir('..\/working\/rsna-miccai-tumour-mask')\nos.mkdir('..\/working\/rsna-miccai-tumour-mask\/train')\nos.mkdir('..\/working\/rsna-miccai-tumour-mask\/test')\nfor study_folder in train_folder_content:\n    if os.path.exists(\"{}{}\/T1w\".format(path_to_training_studies, study_folder)):\n        MRI_slice_filename = find_tumour(study_folder, save_folder=\"..\/working\/rsna-miccai-tumour-mask\", dataset=path_to_training_studies)","3639c26f":"path_to_test_studies = \"..\/input\/rsna-miccai-png\/test\/\"\ntest_folder_content = os.listdir(path_to_test_studies)\nfor study_folder in test_folder_content:\n    if os.path.exists(\"{}{}\/T1w\".format(path_to_test_studies, study_folder)):\n        MRI_slice_filename = find_tumour(study_folder, save_folder=\"..\/working\/rsna-miccai-tumour-mask\", dataset=path_to_test_studies)","20ba7dd8":"im = Image.open(\"..\/working\/rsna-miccai-tumour-mask\/test\/00114\/Image-13-tumour-mask.png\")\nplt.imshow(im)\nplt.show()","54742bbb":"#Just zipping all the images into a compressed folder so we can download the output easily\n!zip -r -qq rsna-miccai-tumour-mask.zip \"..\/working\/rsna-miccai-tumour-mask\/\"\n!rm -rf \"..\/working\/rsna-miccai-tumour-mask\/\"","beb39219":"Let's create the masks for the training set and save them.","dbe02826":"# Build the U-Net model trained by [arashmehrzadi](https:\/\/www.kaggle.com\/arashmehrzadi) in this [notebook](https:\/\/www.kaggle.com\/arashmehrzadi\/brain-tumor-segmentation-unet)","734dcb61":"This notebook is using an existing model for brain tumour segmentation in T1w MRI scans. This allows to detect the MRI slices with the largest tumourous areas, which could help to build solutions using attention or focus the training process on the right MRI slices. \nThe dataset is available [here](https:\/\/www.kaggle.com\/frlemarchand\/rsna-miccai-brain-tumour-mask) in case you want to use it. It contains the masks produced in the notebook, for all the studies that contained T1w MRIs scans.","7f74cc17":"We can now easily scan through the MRIs and highlight the MRI slice with the highest presence of tumour.","3175cf57":"Just a quick check to make sure the masks are correctly saved.","44a28b9b":"# Brain Tumour Segmentation in MRI slices","e8b57feb":"# Try the model on a few T1w MRI slices ","e53bd6c1":"The code is the cell below is taken from arashmehrzadi's notebook.","f906194e":"## Thanks for reading this notebook! If you found this notebook helpful, please give it an upvote. It is always greatly appreciated!","58a257f9":"And now, time to create the masks for the test set!"}}