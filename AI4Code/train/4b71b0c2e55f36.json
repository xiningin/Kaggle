{"cell_type":{"4500a9bb":"code","8111e1a9":"code","a123ba80":"code","4f066f5e":"code","63bde7bd":"code","91a7347d":"code","f3107353":"code","9cf639f0":"code","ba3bc377":"code","bed50a44":"code","065e1c32":"code","d798e2c1":"code","5038480e":"code","a6da5f33":"code","c1f188ec":"code","74e670bb":"code","48d6d1dd":"markdown"},"source":{"4500a9bb":" !pip install imutils","8111e1a9":"import argparse\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom imutils import paths\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.optimizers import SGD\nimport warnings\nwarnings.filterwarnings('ignore')\n","a123ba80":"import os\nimport cv2\nimport numpy as np\n\n\nclass SimpleDatasetLoader:\n    # Method: Constructor\n    def __init__(self, preprocessors=None):\n        \"\"\"\n        :param preprocessors: List of image preprocessors\n        \"\"\"\n        self.preprocessors = preprocessors\n\n        if self.preprocessors is None:\n            self.preprocessors = []\n\n    # Method: Used to load a list of images for pre-processing\n    def load(self, image_paths, verbose=-1):\n        \"\"\"\n        :param image_paths: List of image paths\n        :param verbose: Parameter for printing information to console\n        :return: Tuple of data and labels\n        \"\"\"\n        data, labels = [], []\n\n        for i, image_path in enumerate(image_paths):\n            image = cv2.imread(image_path)\n            label = int(image_path.split(os.path.sep)[-2])\n\n            if self.preprocessors is not None:\n                for p in self.preprocessors:\n                    image = p.preprocess(image)\n\n            data.append(image)\n            labels.append(label)\n\n            if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n                print('[INFO]: Processed {}\/{}'.format(i+1, len(image_paths)))\n\n        return (np.array(data), np.array(labels))\n\n\n\n","4f066f5e":"import cv2\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\n\nclass ImageToArray:\n    def __init__(self, data_format=None):\n        self.data_format = data_format\n\n    def preprocess(self, image):\n        image = img_to_array(image,data_format=self.data_format)\n        return image","63bde7bd":"import cv2\n\nclass ImageResize:\n    def __init__(self,width,height,inter=cv2.INTER_AREA):\n        self.width = width\n        self.height = height\n        self.inter = inter\n\n    def preprocess(self,image):\n        return cv2.resize(image,(self.width,self.height),interpolation=self.inter)","91a7347d":"from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization\nfrom tensorflow.keras.layers import MaxPool2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.models import Sequential\nfrom keras import backend as K\n\n\nclass MiniVGGNet:\n    @staticmethod\n    def build(width, height, depth, classes):\n        input_shape = (height, width, depth)\n        ch_dim = -1\n        if K.image_data_format() == \"channels_first\":\n            inputShape = (depth, height, width)\n            ch_dim = 1\n        model = Sequential()\n        model.add(Conv2D(32,(3,3),padding='same',input_shape=input_shape))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=ch_dim))\n\n        model.add(Conv2D(64, (3, 3), padding='same'))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=ch_dim))\n\n        model.add(MaxPool2D((2,2)))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(32, (3, 3), padding='same'))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=ch_dim))\n\n        model.add(Conv2D(64, (3, 3), padding='same'))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=ch_dim))\n\n        model.add(MaxPool2D((2, 2)))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(512))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=ch_dim))\n        model.add(Dropout(0.5))\n        model.add(Dense(classes))\n        model.add(Activation('softmax'))\n\n        return model\n\n\n\n\n\n","f3107353":"datasetpath = '..\/input\/flowers17\/17flowers\/jpg'\nmodel_output = 'kaggle\/working\/model'","9cf639f0":"imagepaths = list(paths.list_images(datasetpath))\n\nir = ImageResize(32,32)\niat = ImageToArray()\nlo = SimpleDatasetLoader([ir,iat])\n(data,labels)=lo.load(imagepaths,verbose=100)\n","ba3bc377":"image = cv2.imread(imagepaths[0])\nimgplot = plt.imshow(image)\nplt.show()","bed50a44":"train_X,test_X,train_y,test_y = train_test_split(data,labels,test_size=0.2,random_state=123)\n\ntrain_X = train_X.astype(\"float\") \/ 255.0\ntest_X = test_X.astype(\"float\") \/ 255.0","065e1c32":"print(train_X.shape)\n\nprint(train_y.shape)\n\nprint(test_X.shape)\nprint(test_y.shape)","d798e2c1":"model = MiniVGGNet.build(width=32,height=32,depth=3,classes=17)\n\n","5038480e":"model.compile(loss='sparse_categorical_crossentropy',optimizer=SGD(lr=0.01),metrics=['accuracy'])","a6da5f33":"\nmodel.summary()","c1f188ec":"H = model.fit(train_X,train_y,validation_data=(test_X,test_y),epochs=70,batch_size=32)","74e670bb":"\nplt.figure(figsize=(10,8))\nplt.plot(np.arange(0,70),H.history['accuracy'],label='Training accuracy')\n\nplt.plot(np.arange(0,70),H.history['loss'],label='Training loss')\n\n\nplt.plot(np.arange(0,70),H.history['val_accuracy'],label='validation accuracy')\n\n\nplt.plot(np.arange(0,70),H.history['val_loss'],label='Training accuracy')\n\nplt.xlabel('#Epochs')\nplt.ylabel('percentage')\nplt.legend()\nplt.show()","48d6d1dd":"## Model compiling"}}