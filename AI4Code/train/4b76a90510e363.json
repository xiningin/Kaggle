{"cell_type":{"c141dd7f":"code","7144892c":"code","579923d2":"code","7c809e41":"code","e25f9f36":"code","e44b3a34":"code","d3aa0fcb":"code","e90e08c7":"code","9b11223d":"code","f1d2f975":"code","8739207e":"code","0f8f9290":"code","fe28dd4c":"code","4d9ee725":"code","bb52f8f7":"code","a34cfd28":"markdown","8cb8ad2d":"markdown","08fc1901":"markdown","6a4324a9":"markdown","a0d490f7":"markdown","dbd84d1e":"markdown","d59cad9c":"markdown","a8121109":"markdown","a21d8173":"markdown","57610da7":"markdown","73df7b6d":"markdown","4f39ccee":"markdown"},"source":{"c141dd7f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7144892c":"# Importing libraries\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.neighbors import KNeighborsClassifier\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier","579923d2":"data_zoo=pd.read_csv('\/kaggle\/input\/zoo-animal-classification\/zoo.csv')\ndata_class=pd.read_csv('\/kaggle\/input\/zoo-animal-classification\/class.csv')\nprint(\"Zoo Animal count\",data_zoo.animal_name.value_counts().count())\nprint(\"Class type\",data_zoo.class_type.value_counts().count())","7c809e41":"display(data_zoo.head())\ndisplay(data_class)","e25f9f36":"X=data_zoo.iloc[:,1:-1]\ny=data_zoo.iloc[:,-1]\n\nscaler = MinMaxScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)","e44b3a34":"plt.figure(figsize = (12,8))\nplt.grid(True)\nax = sns.countplot(x='class_type', data=data_zoo, palette='Spectral_r')\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()+0.5))","d3aa0fcb":"corr_matirx=data_zoo.corr()\nplt.figure(figsize=(20,12))\nax = sns.heatmap(corr_matirx, annot = True, cmap=\"Set1\")\ntop, bottom = ax.get_ylim()\nax.set_ylim(top+0.5, bottom-0.5)","e90e08c7":"plt.figure(figsize=(25,10))\ndata_zoo.corr()['class_type'].sort_values(ascending = False).plot(kind='bar')\nplt.show()","9b11223d":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=.3,random_state=2,stratify=y)","f1d2f975":"model=SVC()\nmodel.fit(x_train,y_train)\nprint(f' Training Accuracy {model.score(x_train,y_train)}')\nf'Test Accuracy {model.score(x_test,y_test)}'","8739207e":"k = range(1,20)\ntrainingAccuracy = []\ntestAccuracy=[]\nfor i in k:\n    knn = KNeighborsClassifier(n_neighbors=i,n_jobs=15,p=1,weights='distance')\n    knn.fit(x_train,y_train)\n    trainingacc = knn.score(x_train,y_train)\n    trainingAccuracy.append(trainingacc)\n    testAccuracy.append(knn.score(x_test,y_test))\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10,4))\nplt.xlabel(\"value of K\")\nplt.ylabel(\"Accuracy of test and training\")\nplt.title(\"Select best value of k\")\nplt.plot(k,trainingAccuracy)\nplt.plot(k,testAccuracy)\n  #axes[0].legend(['loss','val_loss'])\naxes.legend([\"Training Accurracy\",\"Test Accuracy\"])\nprint(\"Best TrainAccuracy:- \", max(trainingAccuracy)) \nprint(\"Best TestAccuracy:- \", max(testAccuracy))","0f8f9290":"k_range = list(range(1,50))\nweight_options = [\"uniform\", \"distance\"]\npe=[1,2]\n\nparam_grid = dict(n_neighbors = k_range, weights = weight_options,p=pe)\nknn = KNeighborsClassifier()\n\nknngrid = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy',n_jobs=15)\nknngrid.fit(x_train,y_train)\n\nprint (\"Best score on 10 folds split Data on Train split:- \",knngrid.best_score_)\nprint (\"Best Param:- \",knngrid.best_params_)\nprint (\"Best KNN Metric:- \", knngrid.best_estimator_)\n\nprint(f' Training Accuracy {knngrid.score(x_train,y_train)}')\nf'Test Accuracy {knngrid.score(x_test,y_test)}'","fe28dd4c":"from sklearn.linear_model import LogisticRegression\nlog_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n\nlog_model.fit(x_train, y_train)\n\nprint(f' Training Accuracy {log_model.score(x_train,y_train)}')\nf'Test Accuracy {log_model.score(x_test,y_test)}'","4d9ee725":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\nparam_grid = [\n        {\n            'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n            'solver' : ['lbfgs', 'sgd', 'adam'],            \n        }\n       ]\nclf = GridSearchCV(MLPClassifier(), param_grid, cv=folds,\n                           scoring='accuracy',n_jobs=-1,verbose = 1,\n)\nclf.fit(x_train, y_train)\n\nprint(f' Training Accuracy {clf.score(x_train,y_train)}')\nf'Test Accuracy {clf.score(x_test,y_test)}'","bb52f8f7":"cv_results = pd.DataFrame(clf.cv_results_)\n\n#print the optimum value of hyperparameters\nprint('Best hyperparameters: ', clf.best_params_)\nprint (\"Best Estimator:- \", clf.best_estimator_)","a34cfd28":"### Using Neural Network","8cb8ad2d":"### Using Logistic Regression Modal","08fc1901":"### Splitting in to Train and Test","6a4324a9":"### Scaling down the feature using MinMax scalar","a0d490f7":"#### Finding out the Best KNN hyper tuning parameters","dbd84d1e":"### Building Support Vector Machine (SVM)","d59cad9c":"### Checking the correlation of features using Heat map","a8121109":"## Building Models","a21d8173":"### Visulizing the count of Animals in each class type","57610da7":"### Checking the Correlation on the Target variable using barchart","73df7b6d":"#### Choosing Best Param using Grid search CV","4f39ccee":"### Building Modal Using KNN"}}