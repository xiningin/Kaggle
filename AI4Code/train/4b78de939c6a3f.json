{"cell_type":{"dc6a05ba":"code","3da2a5e3":"code","7cad53cf":"code","4cbe3c12":"code","e15a5597":"code","36719373":"code","e506af20":"code","be0f7216":"code","d12ea74b":"markdown","b5d3921a":"markdown","665aeb52":"markdown","e6ab2f08":"markdown","4a7fd2f9":"markdown","99e9ae61":"markdown","97cafce8":"markdown","348fca64":"markdown"},"source":{"dc6a05ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3da2a5e3":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras","7cad53cf":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nX_test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nX_train, X_valid, y_train, y_valid = train_test_split(train.iloc[:,1:], train.iloc[:,0], test_size=0.1, random_state=42)\nX_train = X_train.values.reshape(-1,28,28,1) \/ 255.0\nX_valid = X_valid.values.reshape(-1,28,28,1) \/ 255.0\nX_test = X_test.values.reshape(-1,28,28,1) \/ 255.0","4cbe3c12":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"SAME\"),\n    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"SAME\"),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(units=64, activation='relu'),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(units=10, activation='softmax'),\n])","e15a5597":"model.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer = 'adam',\n    metrics=['accuracy']\n)","36719373":"history = model.fit(X_train,y_train,\n                   validation_data=(X_valid,y_valid),\n                   epochs=1)","e506af20":"pd.DataFrame(history.history).plot()","be0f7216":"pred = model.predict(X_test)\npred = np.argmax(pred,axis = 1)\nsubmissions = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmissions.Label = pred\nsubmissions.to_csv(\"submissions.csv\", index=False)","d12ea74b":"# **Plot the loss and accuracy curves**","b5d3921a":"# **Model compilation**","665aeb52":"# **Loading and scaling data**","e6ab2f08":"# **Train the model**","4a7fd2f9":"# **Generate and submit predictions**","99e9ae61":"# **Loading libraries**","97cafce8":"# **Loading data**","348fca64":"# **Model architecture**"}}