{"cell_type":{"b07cbf78":"code","358f6242":"code","63ef8285":"code","25127fff":"code","d1e0b16b":"code","f2c68460":"code","60f54aff":"code","7512f077":"code","2d554ed8":"code","5ee71898":"code","a78fd84d":"code","10c185a7":"code","0add9b5f":"code","816d7b3e":"code","0cf4a177":"code","51eb6ad5":"code","41c50104":"code","f61e6f4e":"code","a70f5395":"code","e0dcb031":"code","885b0339":"code","6a98d21d":"code","0f70dd5b":"markdown","438e71cb":"markdown","491ab103":"markdown","8bedfe26":"markdown","aec0b82c":"markdown","e4ed7048":"markdown"},"source":{"b07cbf78":"import matplotlib.patches as patches\n\nimport numpy as np \nimport pandas as pd\nfrom glob import glob\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport gc\nimport os\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","358f6242":"KAGGLE=False\nPATH=\"\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/\" if KAGGLE else \".\/\"","63ef8285":"train=pd.read_csv(PATH+'train.csv')\nsub=pd.read_csv(PATH+'sample_submission.csv')","25127fff":"train[train['class_id'] != 14].isnull().sum()","d1e0b16b":"train.class_name.unique()","f2c68460":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    if voi_lut:\n        #apply voi lookup table if possible\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n        \n    #fix monochrome issue\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data.astype(np.float)\n    \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    #modified pixel range on a greyscale (0-255)    \n    return data","60f54aff":"def get_rect_patch(x_min,y_min,x_max,y_max):\n    width=x_max-x_min\n    height=y_max-y_min\n    rect=patches.Rectangle((x_min,y_min),width,height,ec='r', fc='none', lw=2.)\n    return rect","7512f077":"for classname in train.class_name.unique():\n    fig,axs=plt.subplots(1,5,figsize=(20,15))\n    fig.subplots_adjust(hspace = .1, wspace=.1)\n\n    axs = axs.ravel()\n    \n    #sampling 3 images with corresponding disease\n    samples=train[train['class_name'] == classname].sample(n=5,random_state=353)\n    for i in range(5):\n        axs[i].imshow(read_xray(PATH+\"images\/train\/\"+samples.iloc[i]['image_id']+\".dicom\"),cmap='gray')\n\n        axs[i].set_title(str(classname))\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n        \n        if classname != \"No finding\":\n            x_min,y_min,x_max,y_max=samples.iloc[i]['x_min'],samples.iloc[i]['y_min'],samples.iloc[i]['x_max'],samples.iloc[i]['y_max']\n            rect=get_rect_patch(x_min,y_min,x_max,y_max)\n            \n            axs[i].add_patch(rect)\nplt.show()","2d554ed8":"#Normalizing Data\ndef convert(size, box):\n    #xmin,xmax,ymin,ymax\n    dw = 1.\/(size[0])\n    dh = 1.\/(size[1])\n    x = (box[0] + box[1])\/2.0 - 1\n    y = (box[2] + box[3])\/2.0 - 1\n    w = box[1] - box[0]\n    h = box[3] - box[2]\n    x = x*dw\n    w = w*dw\n    y = y*dh\n    h = h*dh\n    return (x,y,w,h)","5ee71898":"def convert_to_yolo(df,IsTrain=True):\n    folder=\"train\/\" if IsTrain else \"test\/\"\n    global PATH\n    \n    r=pd.DataFrame(index=range(df.shape[0]),columns=['image_id','class','x','y','w','h','img_width','img_height'])\n    for i,img_id in enumerate()\n        print(str(i)+\"\/\"+str(df.shape[0])+\"\\n\")\n        for idx,row in df.iterrows():\n            box=[row['x_min'],row['x_max'],row['y_min'],row['y_max']]\n            size=pydicom.read_file(PATH+\"images\/train\/\"+row['image_id']+\".dicom\").pixel_array.shape[::-1] \n            x,y,w,h=convert(size,box)\n            r.iloc[idx]['img_width'],r.iloc[idx]['img_height'],r.iloc[idx]['image_id'],r.iloc[idx]['class'],r.iloc[idx]['x'],r.iloc[idx]['y'],r.iloc[idx]['w'],r.iloc[idx]['h'] = size[0],size[1],row['image_id'],row['class_id'],x,y,w,h\n            gc.collect()\n            i+=1\n    return r","a78fd84d":"r=convert_to_yolo(train)\nr.to_csv('chest_xray.csv')","10c185a7":"r['image_id'].nunique()","0add9b5f":"dicom_imgs_path=PATH+\"train\/\"\n\ntrain_imgs_path=PATH+\"images\/train\/\"\ntrain_labels_path=PATH+\"labels\/train\/\"\n\ntest_imgs_path=PATH+\"images\/test\/\"","816d7b3e":"n_classes=14","0cf4a177":"#Creating .txt files in yolov5 format\nfor i in r.image_id.unique():\n    img=read_xray(PATH+train_imgs_path+i+\".dicom\")\n    cv2.imwrite(\".\/\" + train_imgs_path + i + \".jpg\" , img)\n    with open(PATH+train_labels_path+i+\".txt\",\"a\") as f:\n        f.seek(0)\n        img_df=r[r[\"image_id\"]== i]\n        found=False\n        nf_idxs=[]\n        for idx,row in img_df.iterrows():\n            if int(row['class']) == 14:\n                nf_idxs += idx\n                continue\n            else:\n                found=True\n                f.write(str(row['class']) + \" \" + str(row['x']) + \" \" + str(row[\"y\"]) + \" \" + str(row['w']) + \" \" + str(row['h']) + \"\\n\")\n        if found:\n            for idx in nf_idxs:\n                cv2.imwrite( \".\/\" + train_imgs_path + i + \"_NF_\" + str(idx) + \".jpg\" , img)\n                f = open( PATH + train_labels_path + i + \"_NF_\" + str(idx) + \".txt\" , \"x\" )\n        f.close()","51eb6ad5":"#Converting test images into JPG\nfor i in sub.image_id.unique():\n    img=read_xray(PATH+test_imgs_path+i+\".dicom\")\n    cv2.imwrite(\".\/\" + test_imgs_path + i + \".jpg\" , img)","41c50104":"test=sub.copy()\ntest['width']=test['height']=0\nfor idx,row in test.iterrows():\n    img = Image.open(PATH+test_imgs_path+row['image_id']+\".jpg\")\n    test.loc[idx,'width'],test.loc[idx,'height']=img.size[0],img.size[1]","f61e6f4e":"os.chdir(f\"{PATH}yolov5-master\")\n!python train.py --weights \".\/weights\/yolov5x.pt\" --data ..\/chest_xray.yaml --epochs 60","a70f5395":"!python detect.py --weights \".\/runs\/train\/exp4\/weights\/best.pt\" --save-txt --save-conf --sources \"..\/images\/test\/\" --img-size 640","e0dcb031":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes","885b0339":"image_ids = []\nPredictionStrings = []\n\nfor file_path in glob('runs\/detect\/exp\/labels\/*txt'):\n    image_id = file_path.split('\/')[-1].split('.')[0].split(\"\\\\\")[1]\n    w, h = int(test.loc[test.image_id==image_id]['width']),int(test.loc[test.image_id==image_id]['height'])\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))","6a98d21d":"test_df=test.copy().drop(\"PredictionString\",axis=1,inplace=False)\npred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nprint(sub_df)\nsub_df = sub_df.loc[:,['image_id', 'PredictionString']]\nsub_df.to_csv('submission.csv',index = False)\nsub_df.tail()","0f70dd5b":"**YOLO Format** is as follows:\n* One row per object\n* Each row is class x_center y_center width height format.\n* Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n* Class numbers are zero-indexed (start from 0).","438e71cb":"# Examples of diseases detection","491ab103":"note that this notebook has to be adapted to the working dir to be able to run,as i didn't prepare it for kaggle deployement","8bedfe26":"> The dataset comprises 18,000 postero-anterior (PA) CXR scans in DICOM format, which were de-identified to protect patient privacy. All images were labeled by a panel of experienced radiologists for the presence of 14 critical radiographic findings as listed below:\n\n0 - Aortic enlargement\n\n1 - Atelectasis\n\n2 - Calcification\n\n3 - Cardiomegaly\n\n4 - Consolidation\n\n5 - ILD\n\n6 - Infiltration\n\n7 - Lung Opacity\n\n8 - Nodule\/Mass\n\n9 - Other lesion\n\n10 - Pleural effusion\n\n11 - Pleural thickening\n\n12 - Pneumothorax\n\n13 - Pulmonary fibrosis\n\n14 - No finding","aec0b82c":"At this point i trained the model on a gpu cloud computing service ,namely : https:\/\/lambdalabs.com\/.\nFor faster training i used : \n> python train.py torch.distributed.launch --nproc_per_node 4 ***etc...***","e4ed7048":"**Columns**\n\n**image_id** - unique image identifier\n\n**class_name** - the name of the class of detected object (or \"No finding\")\n\n\n**class_id** - the ID of the class of detected object\n\n**rad_id** - the ID of the radiologist that made the observation\n\n**x_min** - minimum X coordinate of the object's bounding box\n\n**y_min** - minimum Y coordinate of the object's bounding box\n\n**x_max** - maximum X coordinate of the object's bounding box\n\n**y_max** - maximum Y coordinate of the object's bounding box"}}