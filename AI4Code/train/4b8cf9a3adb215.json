{"cell_type":{"4d65e044":"code","cbccab80":"code","ed5f8967":"code","c4ad2bcf":"code","fab4b407":"code","ffd9657d":"code","db4c977f":"code","7df08fe5":"code","e12eeb65":"code","24d1860b":"code","a258e943":"code","70196374":"code","ce0721d7":"code","2005b885":"code","79301daa":"code","7b82ccc1":"code","552b6074":"code","467a90d9":"code","e2e8fcd4":"code","9ba85ef3":"code","e63be3e7":"code","b2f34c38":"code","3190f887":"code","87bc7a80":"code","80b93c6e":"code","f85a3ffd":"code","2fce0787":"code","c4a66842":"code","06b0acbb":"code","19e246f3":"code","a0c09319":"code","769e531a":"code","8be4e56d":"code","d82434af":"code","45aac14b":"code","9580b58a":"code","34d50cb0":"code","7f2293e5":"code","430e751c":"code","1d43e220":"code","3c44e757":"code","5771c533":"code","98dbe8df":"code","0188e3a1":"code","79b20638":"code","7b0f7969":"code","3b9b5d0e":"code","0a0dfaaa":"code","9475a098":"code","4e4ab06b":"code","9780c14d":"code","e5a6f263":"code","2fb66767":"code","2e32c80a":"code","dfcd8ec8":"code","d94bdc9d":"code","daf9fa7a":"code","716057e6":"code","f2a3ab86":"code","ce2e1caf":"code","8235ffce":"code","b97b7a35":"code","0b6939e5":"code","8d4fdbda":"code","81a57c94":"code","637a8615":"code","82044a20":"code","c8217255":"code","877f9f58":"code","288c2280":"code","1dbd3681":"code","0becd697":"code","741715b9":"code","171ad414":"code","aec63d1d":"code","cf6f3f64":"code","9d283ad0":"code","c12861d3":"code","a12a5089":"code","b56158e7":"code","f9f4ef15":"code","fafaceb6":"code","8bbc3190":"code","0d036eac":"markdown","6c8aa2fe":"markdown","883b29c4":"markdown","0eccd691":"markdown","9f032da2":"markdown","879fd924":"markdown","2efe97e7":"markdown","eab1c528":"markdown","571d94eb":"markdown","b90d80c9":"markdown","8917ae17":"markdown","1d59ed4a":"markdown","53afb808":"markdown","65d32a1f":"markdown","02981150":"markdown","96c899f3":"markdown","f129fd15":"markdown","e2f8dfdc":"markdown","7e07b85c":"markdown","964a118e":"markdown","1daeab00":"markdown","f4ba2cde":"markdown","e076ad39":"markdown","884028a9":"markdown","ffd0da32":"markdown","1f843c9c":"markdown","7e7f3e1d":"markdown","315b8fd0":"markdown"},"source":{"4d65e044":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cbccab80":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","ed5f8967":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","c4ad2bcf":"#code taken from https:\/\/www.kaggle.com\/alexisbcook\/titanic-tutorial \n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","fab4b407":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nmsk = np.random.rand(len(df)) < 0.8\ntrain_data = df[msk]\ntest_data = df[~msk]","ffd9657d":"print (\"length of train data: \",len(train_data))\ntrain_data.head()","db4c977f":"print (\"length of test data: \",len(test_data))\ntest_data.head()","7df08fe5":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\n#only taking the features that has no missing values and no other errors. \n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",\"Embarked\",\"Fare\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)","e12eeb65":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score,f1_score\nconfusion_matrix(test_data[\"Survived\"], predictions)","24d1860b":"precision_score(test_data[\"Survived\"], predictions)","a258e943":"f1_score(test_data[\"Survived\"], predictions)","70196374":"recall_score(test_data[\"Survived\"], predictions)","ce0721d7":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","2005b885":"train_data.describe()","79301daa":"round((train_data.isnull().sum() * 100\/ len(train_data)),2).sort_values(ascending=False)","7b82ccc1":"import re\nprint(train_data['Cabin'].unique())\ntrain_data['Cabin'] = train_data['Cabin'].fillna(\"U0\")\ntrain_data['CabinNew']=train_data['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ntrain_data['CabinNew'].value_counts()","552b6074":"cabinNew={\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\ntrain_data['CabinNew'] = train_data['CabinNew'].map(cabinNew)\ntrain_data['CabinNew'] = train_data['CabinNew'].fillna(0)\ntrain_data['CabinNew'] = train_data['CabinNew'].astype(int)\ntrain_data = train_data.drop(['Cabin'], axis=1)","467a90d9":"import scipy.stats as stats\n\nmean = train_data[\"Age\"].mean()\nstd = train_data[\"Age\"].std()\nsumNull = train_data[\"Age\"].isnull().sum()\n#ages between 15 and 45 with same mean and std\ndist = stats.truncnorm((15 - mean) \/ std, (45 - mean) \/ std, loc=mean, scale=std)\nvalues = dist.rvs(sumNull)\n\ntempAge = train_data[\"Age\"].copy()\ntempAge[np.isnan(tempAge)] = values\ntrain_data[\"Age\"] = tempAge\ntrain_data[\"Age\"] = train_data[\"Age\"].astype(int)","e2e8fcd4":"popValue=train_data['Embarked'].value_counts().idxmax()\ntrain_data['Embarked'] = train_data['Embarked'].fillna(popValue)","9ba85ef3":"round((train_data.isnull().sum() * 100\/ len(train_data)),2).sort_values(ascending=False)","e63be3e7":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorrmat = train_data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\ng=sns.heatmap(train_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","b2f34c38":"from sklearn.ensemble import ExtraTreesClassifier\n\nmodel = ExtraTreesClassifier()\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\", \"Ticket\", \"Name\", \"Age\", \"CabinNew\"]\ntarget=[\"Survived\"]\nX = pd.get_dummies(train_data[features])  \ny = pd.get_dummies(train_data[target])\nmodel.fit(X,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","3190f887":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\", \"Ticket\", \"Name\", \"Age\", \"CabinNew\"]\ntarget=[\"Survived\"]\nX = pd.get_dummies(train_data[features])  \ny = pd.get_dummies(train_data[target])      \nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns) \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  \nprint(featureScores.nlargest(10,'Score'))","87bc7a80":"plt.figure(figsize=(10,7))\nsns.countplot(x='Sex',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","80b93c6e":"plt.figure(figsize=(10,7))\nsns.countplot(x='Embarked',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","f85a3ffd":"plt.figure(figsize=(10,7))\nsns.countplot(x='CabinNew',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","2fce0787":"plt.figure(figsize=(20,14))\nsns.countplot(x='Age',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","c4a66842":"plt.figure(figsize=(10,7))\nsns.countplot(x='Pclass',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","06b0acbb":"plt.figure(figsize=(10,7))\nsns.countplot(x='Parch',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","19e246f3":"plt.figure(figsize=(10,7))\nsns.countplot(x='SibSp',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","a0c09319":"plt.figure(figsize=(10,4))\nsns.scatterplot(x='Age',y='Sex',data=train_data, hue='Survived')\nplt.show()","769e531a":"plt.figure(figsize=(6,4))\nsns.swarmplot(x='Pclass',y='Sex',data=train_data, hue='Survived')\nplt.show()","8be4e56d":"plt.figure(figsize=(20,4))\nsns.swarmplot(x='Embarked',y='Survived',data=train_data, hue='Sex')\nplt.show()","d82434af":"plt.figure(figsize=(16,6))\nsns.swarmplot(x='SibSp',y='Parch',data=train_data, hue='Survived')\nplt.show()","45aac14b":"train_data.dtypes","9580b58a":"train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False).value_counts()","34d50cb0":"train_data['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","7f2293e5":"plt.figure(figsize=(20,7))\nsns.countplot(x='Title',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","430e751c":"sns.relplot(x='Title', y='Survived', kind=\"line\", aspect = 3.0, data=train_data);","1d43e220":"titles = {\"Uncommon\":1,\"Mr\": 2, \"Miss\": 3, \"Mrs\": 4, \"Master\": 5}\ntrain_data['Title'] = train_data['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Don','Sir', 'Jonkheer', 'Lady', 'Countess', 'Capt'], 'Uncommon')\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\ntrain_data['Title'] = train_data['Title'].map(titles)","3c44e757":"train_data = train_data.drop(['Name'], axis=1)","5771c533":"sex={\"male\":1, \"female\":2}\ntrain_data['Sex'] = train_data['Sex'].map(sex)","98dbe8df":"embarks = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain_data['Embarked'] = train_data['Embarked'].map(embarks)","0188e3a1":"train_data['Age'].describe()","79b20638":"train_data['Age'] = train_data['Age'].astype(int)\n\nages = [12, 18, 23, 28, 33, 40, 65]\nagesMap = [1, 2, 3, 4, 5, 6, 7]\n\ntrain_data.loc[ train_data['Age'] <= ages[0], 'Age'] = agesMap[0]\ntrain_data.loc[((ages[0] < train_data['Age']) & (train_data['Age'] <= ages[1])), 'Age'] = agesMap[1]\ntrain_data.loc[((ages[1] < train_data['Age']) & (train_data['Age'] <= ages[2])), 'Age'] = agesMap[2]\ntrain_data.loc[((ages[2] < train_data['Age']) & (train_data['Age'] <= ages[3])), 'Age'] = agesMap[3]\ntrain_data.loc[((ages[3] < train_data['Age']) & (train_data['Age'] <= ages[4])), 'Age'] = agesMap[4]\ntrain_data.loc[((ages[4] < train_data['Age']) & (train_data['Age'] <= ages[5])), 'Age'] = agesMap[5]\ntrain_data.loc[ train_data['Age'] > ages[5], 'Age'] = agesMap[6]","7b0f7969":"plt.figure(figsize=(20,7))\nsns.countplot(x='Age',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","3b9b5d0e":"plt.figure(figsize=(20,7))\nsns.countplot(x='Age',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","0a0dfaaa":"train_data['Fare'].describe()","9475a098":"plt.figure(figsize=(20,5))\nsns.histplot(train_data['Fare'],binwidth=1)\nplt.xlim(0, 50)\nplt.show()","4e4ab06b":"plt.figure(figsize=(20,5))\nsns.histplot(train_data['Fare'],binwidth=1)\nplt.xlim(50, 100)\nplt.ylim(0, 20)\nplt.show()","9780c14d":"plt.figure(figsize=(20,5))\nsns.histplot(train_data['Fare'],binwidth=1)\nplt.xlim(100, 250)\nplt.ylim(0, 10)\nplt.show()","e5a6f263":"train_data['Fare'] = train_data['Fare'].astype(int)\n\nfares = [7, 15, 32, 100, 250]\nfaresMap = [1, 2, 3, 4, 5, 6]\n\ntrain_data.loc[ train_data['Fare'] <= fares[0], 'Fare'] = faresMap[0]\ntrain_data.loc[((fares[0] < train_data['Fare']) & (train_data['Fare'] <= fares[1])), 'Fare'] = faresMap[1]\ntrain_data.loc[((fares[1] < train_data['Fare']) & (train_data['Fare'] <= fares[2])), 'Fare'] = faresMap[2]\ntrain_data.loc[((fares[2] < train_data['Fare']) & (train_data['Fare'] <= fares[3])), 'Fare'] = faresMap[3]\ntrain_data.loc[((fares[3] < train_data['Fare']) & (train_data['Fare'] <= fares[4])), 'Fare'] = faresMap[4]\ntrain_data.loc[ train_data['Fare'] > fares[4], 'Fare'] = faresMap[5]\n","2fb66767":"train_data['Fare'].value_counts()","2e32c80a":"train_data = train_data.drop(['Ticket'], axis=1)\ntrain_data = train_data.drop(['PassengerId'], axis=1)","dfcd8ec8":"train_data['Age_Class']= train_data['Age']* train_data['Pclass']","d94bdc9d":"train_data['Accompanies']= train_data['SibSp'] + train_data['Parch'] ","daf9fa7a":"plt.figure(figsize=(20,7))\ntrain_data['Survived'].groupby(train_data['Accompanies']).mean().plot(kind='bar')\n#sns.countplot(x='Accompanies',data = train_data, hue = 'Survived',palette='GnBu')\nplt.show()","716057e6":"train_data.dtypes","f2a3ab86":"model = ExtraTreesClassifier()\nfeatures = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"CabinNew\", \"Title\", \"Age_Class\", \"Accompanies\"]\ntarget=[\"Survived\"]\nX = pd.get_dummies(train_data[features])  \ny = pd.get_dummies(train_data[target])\nmodel.fit(X,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()\n","ce2e1caf":"msk = np.random.rand(len(train_data)) < 0.8\ntrain_data_val = train_data[msk]\ntest_data_val = train_data[~msk]\n\nprint (len(train_data_val))\nprint (len(test_data_val))","8235ffce":"y_train_data_val = train_data_val[\"Survived\"]\nx_train_data_val = train_data_val.drop(\"Survived\", axis=1)\n\nx_test_data_val = test_data_val.drop(\"Survived\", axis=1)\ny_test_data_val = test_data_val[\"Survived\"]\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nmodel.fit(x_train_data_val, y_train_data_val)\npredictions = model.predict(x_test_data_val)","b97b7a35":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score,f1_score, accuracy_score\nconfusion_matrix(y_test_data_val, predictions)","0b6939e5":"precision_score(y_test_data_val, predictions)","8d4fdbda":"recall_score(y_test_data_val, predictions)","81a57c94":"accuracy_score(y_test_data_val, predictions)","637a8615":"f1_score(y_test_data_val, predictions)","82044a20":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\nround((test_data.isnull().sum() * 100\/ len(test_data)),2).sort_values(ascending=False)","c8217255":"import re\nimport scipy.stats as stats\n\ntest_data['Cabin'] = test_data['Cabin'].fillna(\"U0\")\ntest_data['CabinNew']=test_data['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n\ncabinNew={\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\ntest_data['CabinNew'] = test_data['CabinNew'].map(cabinNew)\ntest_data['CabinNew'] = test_data['CabinNew'].fillna(0)\ntest_data['CabinNew'] = test_data['CabinNew'].astype(int)\ntest_data = test_data.drop(['Cabin'], axis=1)\n\n\nmean = train_data[\"Age\"].mean()\nstd = train_data[\"Age\"].std()\nsumNull = test_data[\"Age\"].isnull().sum()\ndist = stats.truncnorm((15 - mean) \/ std, (45 - mean) \/ std, loc=mean, scale=std)\nvalues = dist.rvs(sumNull)\n\ntempAge = test_data[\"Age\"].copy()\ntempAge[np.isnan(tempAge)] = values\ntest_data[\"Age\"] = tempAge\ntest_data[\"Age\"] = test_data[\"Age\"].astype(int)\n\ntest_data['Fare'] = test_data['Fare'].fillna(0)\n\nround((test_data.isnull().sum() * 100\/ len(test_data)),2).sort_values(ascending=False)\n\n\ntest_data['Title'] = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntitles = {\"Uncommon\":1,\"Mr\": 2, \"Miss\": 3, \"Mrs\": 4, \"Master\": 5}\ntest_data['Title'] = test_data['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Don', 'Dona', 'Sir', 'Jonkheer', 'Lady', 'Countess', 'Capt'], 'Uncommon')\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\ntest_data['Title'] = test_data['Title'].map(titles)\n\ntest_data['Title'] = test_data['Title'].astype(int)\n\ntest_data = test_data.drop(['Name'], axis=1)\n\nsex={\"male\":1, \"female\":2}\ntest_data['Sex'] = test_data['Sex'].map(sex)\n\nembarks = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntest_data['Embarked'] = test_data['Embarked'].map(embarks)\n\ntest_data['Age'] = test_data['Age'].astype(int)\n\nages = [12, 18, 23, 28, 33, 40, 65]\nagesMap = [1, 2, 3, 4, 5, 6, 7]\n\ntest_data.loc[ test_data['Age'] <= ages[0], 'Age'] = agesMap[0]\ntest_data.loc[((ages[0] < test_data['Age']) & (test_data['Age'] <= ages[1])), 'Age'] = agesMap[1]\ntest_data.loc[((ages[1] < test_data['Age']) & (test_data['Age'] <= ages[2])), 'Age'] = agesMap[2]\ntest_data.loc[((ages[2] < test_data['Age']) & (test_data['Age'] <= ages[3])), 'Age'] = agesMap[3]\ntest_data.loc[((ages[3] < test_data['Age']) & (test_data['Age'] <= ages[4])), 'Age'] = agesMap[4]\ntest_data.loc[((ages[4] < test_data['Age']) & (test_data['Age'] <= ages[5])), 'Age'] = agesMap[5]\ntest_data.loc[ test_data['Age'] > ages[5], 'Age'] = agesMap[6]\n\n\ntest_data['Fare'] = test_data['Fare'].astype(int)\n\nfares = [7, 15, 32, 100, 250]\nfaresMap = [1, 2, 3, 4, 5, 6]\n\ntest_data.loc[ test_data['Fare'] <= fares[0], 'Fare'] = faresMap[0]\ntest_data.loc[((fares[0] < test_data['Fare']) & (test_data['Fare'] <= fares[1])), 'Fare'] = faresMap[1]\ntest_data.loc[((fares[1] < test_data['Fare']) & (test_data['Fare'] <= fares[2])), 'Fare'] = faresMap[2]\ntest_data.loc[((fares[2] < test_data['Fare']) & (test_data['Fare'] <= fares[3])), 'Fare'] = faresMap[3]\ntest_data.loc[((fares[3] < test_data['Fare']) & (test_data['Fare'] <= fares[4])), 'Fare'] = faresMap[4]\ntest_data.loc[ test_data['Fare'] > fares[4], 'Fare'] = faresMap[5]\n\n\ntest_data = test_data.drop(['Ticket'], axis=1)\n\ntest_data['Age_Class']= test_data['Age'] * test_data['Pclass']\n\ntest_data['Accompanies']= test_data['SibSp'] + test_data['Parch'] \n\n","877f9f58":"y = train_data[\"Survived\"]\nX = train_data.drop(\"Survived\", axis=1)\n\ntest_data_df = test_data.copy(deep=True)\ntest_data = test_data.drop(\"PassengerId\", axis=1)\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(test_data)\n\noutput = pd.DataFrame({'PassengerId': test_data_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission2.csv', index=False)\nprint(\"Your submission was successfully saved!\")","288c2280":"train_data_copy = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data_copy = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","1dbd3681":"train_data['NameLen'] = train_data_copy['Name'].apply(lambda x: len(x))\ntrain_data['TicketLen'] = train_data_copy['Ticket'].apply(lambda x: len(x))","0becd697":"test_data['NameLen'] = test_data_copy['Name'].apply(lambda x: len(x))\ntest_data['TicketLen'] = test_data_copy['Ticket'].apply(lambda x: len(x))","741715b9":"plt.figure(figsize=(20,7))\ntrain_data['Survived'].groupby(train_data['NameLen']).mean().plot(kind='bar')\nplt.show()","171ad414":"plt.figure(figsize=(20,7))\ntrain_data['Survived'].groupby(train_data['TicketLen']).mean().plot(kind='bar')\nplt.show()","aec63d1d":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorrmat = train_data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\ng=sns.heatmap(train_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","cf6f3f64":"categories=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Title','Age_Class','Accompanies','NameLen','TicketLen']\ntrain_data_used=pd.DataFrame()\ntest_data_used=pd.DataFrame()\nfor category in categories:\n    train_data_used[category] = train_data[category]\n    test_data_used[category] = test_data[category]\n\ntrain_data_used.columns.values","9d283ad0":"test_data_used.columns.values","c12861d3":"train_data_used.columns.values","a12a5089":"categorical_columns = ['Sex','Pclass','Embarked','Title','Age','Fare', 'Age_Class']\n\nfor cat in categorical_columns:\n    train_data_used = pd.concat((train_data_used, pd.get_dummies(train_data_used[cat], prefix = cat)), axis = 1)\n    train_data_used.drop(cat, inplace=True, axis=1)\n    test_data_used = pd.concat((test_data_used, pd.get_dummies(test_data_used[cat], prefix = cat)), axis = 1)\n    test_data_used.drop(cat, inplace=True, axis=1)","b56158e7":"y = train_data[\"Survived\"]\nX = train_data_used.copy(deep=True)\n\ntest_data_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(test_data_used)\n\noutput = pd.DataFrame({'PassengerId': test_data_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission3.csv', index=False)\nprint(\"Your submission was successfully saved!\")","f9f4ef15":"categories=['Sex','Parch','Fare','Embarked','Title','Accompanies','NameLen']\ntrain_data_used=pd.DataFrame()\ntest_data_used=pd.DataFrame()\nfor category in categories:\n    train_data_used[category] = train_data[category]\n    test_data_used[category] = test_data[category]\n\ntrain_data_used.columns.values","fafaceb6":"categorical_columns = ['Sex','Embarked','Title','Fare']\n\nfor cat in categorical_columns:\n    train_data_used = pd.concat((train_data_used, pd.get_dummies(train_data_used[cat], prefix = cat)), axis = 1)\n    train_data_used.drop(cat, inplace=True, axis=1)\n    test_data_used = pd.concat((test_data_used, pd.get_dummies(test_data_used[cat], prefix = cat)), axis = 1)\n    test_data_used.drop(cat, inplace=True, axis=1)","8bbc3190":"y = train_data[\"Survived\"]\nX = train_data_used.copy(deep=True)\n\ntest_data_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(test_data_used)\n\noutput = pd.DataFrame({'PassengerId': test_data_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission4.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0d036eac":"Further visualizing using scatter plots and swarm plots.","6c8aa2fe":"# # Creating a simple model without feature selection or data preprocessing.","883b29c4":"# # Data preprocessing - handle missing values","0eccd691":"Check feature importance again.","9f032da2":"Cabin data will be convereted to numerical value with 0 for the missing values.\n\nMissing Age values will be replaced by the calculated Age values using existing values.\n\nMissing Embarked values will be replaced with the most frequent value.","879fd924":"Trying with all the features.","2efe97e7":"Visualizing relations in a finer level.","eab1c528":"# # Data Preprocessing - transform and normalize data","571d94eb":"Dropping unrelated features.","b90d80c9":"Try using all columns.","8917ae17":"# # Visualize data before transforming","1d59ed4a":"Finding most related features using heatmap, chi-squared statistic and extra tree classifier.","53afb808":"Mapping age into categories.","65d32a1f":"# # Applying same operations on test data","02981150":"Create new feature siblings + parents.","96c899f3":"# # Extra feature creation and selection","f129fd15":"Mapping two sex categories.","e2f8dfdc":"Add new features Name Lngth and Ticket Length","7e07b85c":"Dividing the training set and using it as the test data set and check how the model performed.","964a118e":"# # Update the features","1daeab00":"Check the correlation matrix again.","f4ba2cde":"# # Evaluating the training dataset ","e076ad39":"Following code is only to see how output saving works.","884028a9":"Predict again using only the correlated features.","ffd0da32":"Removing uncommon titles and mapping to integers.","1f843c9c":"Create a new feature age + class.","7e7f3e1d":"Mapping embarked categories.","315b8fd0":"Mapping Fare into categories."}}