{"cell_type":{"755a88bc":"code","bf219a1e":"code","5057a244":"code","19d2b6e0":"code","a85fee0c":"code","1dd39ed5":"code","7dad5d87":"code","154c9050":"code","c39e22ed":"code","cc44f20e":"code","fe40a77b":"code","ca9fd089":"code","77961585":"code","294e1e24":"code","43cadb24":"code","f7c139f5":"code","fc621f54":"code","3e065716":"code","d7f250d3":"code","8944ef08":"code","a6e01920":"markdown","222d373e":"markdown","35585d9e":"markdown","fb7f5728":"markdown","5ba6f70b":"markdown","8e30079b":"markdown","5ab34047":"markdown","687a2e21":"markdown","258a35e8":"markdown","946e7ed5":"markdown","9c095e6c":"markdown"},"source":{"755a88bc":"!ls \/kaggle\/input\/parkinsons-drawings\/spiral\/training\n\n!ls \/kaggle\/input\/parkinson-dataset\/spiral\/training\/healthy | wc -l \n!ls \/kaggle\/input\/parkinson-dataset\/spiral\/training\/parkinson | wc -l \n\n!ls \/kaggle\/input\/parkinson-dataset\/spiral\/testing\/healthy | wc -l \n!ls \/kaggle\/input\/parkinson-dataset\/spiral\/testing\/parkinson | wc -l ","bf219a1e":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.image as mpimg \nfrom keras.preprocessing import image\nfrom keras import models\nimport matplotlib.pyplot as plt\nimport math\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score","5057a244":"\ntrain_dir = \"\/kaggle\/input\/parkinson-dataset\/spiral\/training\/\"\ntest_dir  = \"\/kaggle\/input\/parkinson-dataset\/spiral\/testing\/\"\n\nIMG_WIDTH, IMG_HEIGHT = (300, 300)\nEPOCHS = 50\nBATCH_SIZE= 16\nCLASSES_NO = 2\nprint(\"EPOCHS = {}\".format(EPOCHS))\nprint(\"BATCH_SIZE = {}\".format(BATCH_SIZE))\nprint(\"CLASSES_NO = {}\".format(CLASSES_NO))","19d2b6e0":"train_datagen_aug = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    shear_range=0.1\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255\n)\n\ntrain = train_datagen_aug.flow_from_directory(\n    train_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\ntest = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n)","a85fee0c":"counter = 0\nfor input_batch, label in train:\n    print(label[0])\n    plt.imshow(input_batch[0])\n    plt.show()\n    counter += 1\n    if counter == 10:\n        break","1dd39ed5":"def build_model(reg=False):\n    \n    regularizers = keras.regularizers.l2(1e-3)\n    \n    model = keras.Sequential()\n\n    model.add(keras.layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n\n    model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_regularizer=regularizers))\n    model.add(keras.layers.MaxPooling2D((2, 2)))\n\n    model.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers))\n    model.add(keras.layers.MaxPooling2D((2, 2)))\n\n    model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_regularizer=regularizers))\n    model.add(keras.layers.MaxPooling2D(2, 2))\n\n    model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_regularizer=regularizers))\n    model.add(keras.layers.MaxPooling2D(2, 2))\n\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dense(128, activation=\"relu\"))\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dense(2, activation=\"softmax\"))\n\n    model.summary()\n    \n    return model\n\n\nmodel = build_model(reg=False)","7dad5d87":"model.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=\"adam\",\n    metrics=['acc']\n)","154c9050":"history = model.fit(\n    train,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    validation_data=test\n)","c39e22ed":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(acc, label=\"Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.legend()\nplt.show()\n\n\nplt.plot(loss, label=\"Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.legend()\nplt.show()","cc44f20e":"def load_sample(path):\n    \n    img_path =  path\n    \n    img = image.load_img(img_path, target_size=(300, 300))\n    img_tensor = image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor \/= 255.\n    print(img_tensor.shape)\n    \n    plt.imshow(img_tensor[0])\n    plt.show()\n    \n    return img_tensor","fe40a77b":"def get_grid_by_layers_activation(activation):\n    '''\n    activation.shape = (1, 298, 298, 32)\n\n    '''\n    image_per_row = 16\n    n_features = activation.shape[-1]\n    size = activation.shape[1]\n    n_cols = n_features \/\/ image_per_row\n    \n    display_grid = np.zeros((size * n_cols, image_per_row * size))\n    \n    for col in range(n_cols):\n        for row in range(image_per_row):\n            channel_image = activation[0, :, :, col * image_per_row + row]\n            channel_image -= channel_image.mean()\n            channel_image \/= channel_image.std()\n            \n            channel_image *= 64\n            channel_image += 128\n            \n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[\n                col * size : (col + 1) * size,\n                row * size : (row + 1) * size\n            ] = channel_image\n    \n    scale = 2.\/ size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0],\n                       ))\n    \n    plt.grid(False)\n    plt.imshow(display_grid, aspect=\"auto\", cmap='viridis')\n    plt.show()\n","ca9fd089":"def plot_channel(path, channel):\n    layer_outputs = [layer.output for layer in model.layers]\n    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n    \n    activations = activation_model.predict(\n        load_sample(path)\n    )\n    \n    for i in channel:\n        get_grid_by_layers_activation(activations[i])\n","77961585":"plot_channel(\n    \"..\/input\/parkinson-dataset\/spiral\/training\/parkinson\/12883_2018_1027_Fig1_HTML.png\",\n    [0, 2, 4, 6]\n)","294e1e24":"plot_channel(\n    \"..\/input\/parkinson-dataset\/spiral\/training\/healthy\/V01HE02.png\",\n    [0, 2, 4, 6]\n)","43cadb24":"from keras.applications import VGG16\n\n","f7c139f5":"\nconv_base = VGG16(\n    include_top=False,\n    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),\n    weights='imagenet'\n)\n\nconv_base.summary()","fc621f54":"new_model = keras.Sequential()\nnew_model.add(conv_base)\nnew_model.add(keras.layers.Flatten())\nnew_model.add(keras.layers.Dense(128, activation=\"relu\"))\nnew_model.add(keras.layers.Dense(2, activation='softmax'))\n\nconv_base.trainable = False\n\nnew_model.summary()","3e065716":"new_model.compile(\n    optimizer=RMSprop(lr=2e-5),\n    loss='binary_crossentropy',\n    metrics=['acc']\n)","d7f250d3":"new_hist = new_model.fit(\n    train,\n    epochs=20,\n    batch_size=BATCH_SIZE,\n    validation_data=test\n)\n","8944ef08":"acc = new_hist.history['acc']\nval_acc = new_hist.history['val_acc']\nloss = new_hist.history['loss']\nval_loss = new_hist.history['val_loss']\n\nplt.plot(acc, label=\"Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.legend()\nplt.show()\n\n\nplt.plot(loss, label=\"Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.legend()\nplt.show()","a6e01920":"## Load dataset","222d373e":"## Import Libs","35585d9e":"## Creating model","fb7f5728":"## Compile model","5ba6f70b":"## Exploring Augmented Dataset","8e30079b":"## Plot metrics\n\nAs you see, model has overfitted over training data.","5ab34047":"## Pretrained ConvNet","687a2e21":"## Train model","258a35e8":"## Define constants","946e7ed5":"## Create new model","9c095e6c":"## Visualizing"}}