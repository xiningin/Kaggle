{"cell_type":{"310e9538":"code","5f134b85":"code","6a6185ba":"code","049130ea":"code","d375ba1a":"code","12760590":"code","b7c5b463":"code","fbcc5cd0":"code","8ad10f31":"code","f4f4d507":"code","5ef73890":"markdown","ca908b16":"markdown"},"source":{"310e9538":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5f134b85":"import matplotlib.pyplot as plt#to visualize the data\n# Importing the dataset\ndataset=pd.read_csv('\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')\ndataset","6a6185ba":"#now first we will try simple linear regression to find the relationship between mbap (outcome variable) and degreep (predictor variable).\nX=dataset.iloc[:,7].values.reshape(-1,1)\nY=dataset.iloc[:,12].values.reshape(-1,1)\n# we have to use array.reshape(-1,1) whenever we our array have single feature otherwise it will throw an error\n#what it does is  it let numpy automatically reshape array.","049130ea":"X","d375ba1a":"Y","12760590":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=1\/3,random_state=0)","b7c5b463":"#Fitting simple learn regression to the training set\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\n\nregressor.fit(X_train,Y_train)\n\n#predicting the test set results\ny_pred=regressor.predict(X_test)","fbcc5cd0":"df = pd.DataFrame({'Actual': Y_test.flatten(), 'Predicted': y_pred.flatten()})\ndf","8ad10f31":"#visualizing the training set results\nplt.scatter(X_train,Y_train,color='red')\nplt.plot(X_train,regressor.predict(X_train),color='blue')\nplt.title('mbap (outcome variable) and degreep (predictor variable)(Training set)')\nplt.xlabel('degreep')\nplt.ylabel('mbap')\nplt.show()","f4f4d507":"#visualizing the test set results\nplt.scatter(X_test,Y_test,color='red')\nplt.plot(X_train,regressor.predict(X_train),color='blue')\nplt.title('mbap (outcome variable) and degreep (predictor variable)(Test set)')\nplt.xlabel('degreep')\nplt.ylabel('mbap')\nplt.show()","5ef73890":"Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output). Hence, the name is Linear Regression. If we plot the independent variable (x) on the x-axis and dependent variable (y) on the y-axis, linear regression gives us a straight line that best fits the data points, as shown in the figure below.\n![1_weGmaJTZewji5_9H2TZetA.png](attachment:1_weGmaJTZewji5_9H2TZetA.png)","ca908b16":"The equation of the above line is :\nY= mx + b\nWhere b is the intercept and m is the slope of the line. So basically, the linear regression algorithm gives us the most optimal value for the intercept and the slope (in two dimensions). The y and x variables remain the same, since they are the data features and cannot be changed. The values that we can control are the intercept(b) and slope(m). There can be multiple straight lines depending upon the values of intercept and slope. Basically what the linear regression algorithm does is it fits multiple lines on the data points and returns the line that results in the least error."}}