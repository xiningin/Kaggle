{"cell_type":{"842495d9":"code","fae1db61":"code","fa34fc70":"code","edb35460":"code","6c4f4612":"code","ed770f80":"code","43e46750":"code","b1895450":"code","af47ea05":"code","252b2147":"code","71ff7180":"code","2d91c1fe":"code","3da53efe":"code","272f6b8d":"code","770fd4d3":"code","a0fb86b3":"code","b4c353f2":"code","e65d65f1":"code","dabcb054":"code","19ad0b25":"code","0e2c3811":"code","5402734f":"code","3137fcdb":"code","6610b9d3":"code","5da2eeff":"code","4ed0d21c":"code","72652e83":"code","da0ee324":"code","c488efe5":"code","bfaf8673":"code","4366418d":"code","0ae3c7d1":"code","89161434":"code","e47b61c2":"code","e52d20af":"code","cb8d7c34":"code","91ef6b59":"code","5c7285df":"code","2d8a43b5":"markdown","1d27162f":"markdown","123a8eb4":"markdown","9bad0c40":"markdown","857da7f1":"markdown","e6478212":"markdown","11a68c94":"markdown","5933bbbd":"markdown","79f79d50":"markdown","11295493":"markdown","9ef5724a":"markdown","0d5cabf1":"markdown","c742a9e2":"markdown","a954e59c":"markdown","8888a70b":"markdown"},"source":{"842495d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fae1db61":"real_news = pd.read_csv('..\/input\/fake-and-real-news-dataset\/True.csv')","fa34fc70":"r_news = real_news.copy()","edb35460":"r_news.head()","6c4f4612":"r_news.tail()","ed770f80":"r_news","43e46750":"r_news.describe()","b1895450":"r_news.info()","af47ea05":"r_news.isna().sum()","252b2147":"def CleanHTMLText(Text):\n    Text = Text.str.replace('(<br\/>)', '')\n    Text = Text.str.replace('(<a).*(>).*(<\/a>)', '')\n    Text = Text.str.replace('(&amp)', '')\n    Text = Text.str.replace('(&gt)', '')\n    Text = Text.str.replace('(&lt)', '')\n    Text = Text.str.replace('(\\xa0)', '')\n    return Text","71ff7180":"r_news['title'] = CleanHTMLText(r_news['title'])\nr_news['text'] = CleanHTMLText(r_news['text'])","2d91c1fe":"emp_index = [index for index,text in enumerate(r_news.text.values) if str(text).strip() == '']\nprint(str(len(emp_index))+'  Rows in real news with empty text')","3da53efe":"r_news.iloc[emp_index]","272f6b8d":"r_news = r_news.drop(emp_index, axis=0)\ndel emp_index","770fd4d3":"r_news = r_news.drop_duplicates(subset = ['title','text'])","a0fb86b3":"from matplotlib import pyplot as plt\nimport seaborn as sns\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.pie(r_news.subject.value_counts(), labels = r_news.subject.unique(),autopct='%1.2f%%')\nplt.show()","b4c353f2":"r_news['subject'].value_counts()\nplt.figure(figsize = (5,10))\nsns.set_style(\"darkgrid\")\nsns.countplot(r_news['subject'])","e65d65f1":"from nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                 stopwords = stopwords.words('english'),\n                min_font_size = 10).generate(\" \".join(r_news.text))   \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","dabcb054":"r_news['label'] = r_news['subject'].map( \n                   {'politicsNews':0 ,'worldnews':1})","19ad0b25":"r_news['label']","0e2c3811":"r_news.date = pd.to_datetime(r_news.date, errors=\"coerce\")\nnews_grouped = r_news[[\"date\", \"subject\", \"label\"]].groupby([\"date\", \"label\"]).count().reset_index()\nfig, ax = plt.subplots(figsize=(16,10))\nsns.lineplot(x=\"date\", y=\"subject\", hue=\"label\", data=news_grouped, palette=\"Set2\", ax=ax)\nplt.title(\"News Articles Labelled Fake vs. Real\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Count\")","5402734f":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(r_news['title'],r_news['label'],test_size=0.2, random_state = 1)","3137fcdb":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nimport sklearn.metrics as metrics                                                 \nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport datetime","6610b9d3":"from sklearn.naive_bayes import MultinomialNB\na=datetime.datetime.now()\npip_ln = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB())\n])\nmodel = pip_ln.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('MultiNomial Naive Bayes Classifier')\nplt.show()\nb=datetime.datetime.now()\nb-a","5da2eeff":"from sklearn.ensemble import RandomForestClassifier\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   RandomForestClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('RandomForest Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","4ed0d21c":"from sklearn.svm import LinearSVC\na=datetime.datetime.now()\npip_ln = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', LinearSVC())\n])\nmodel = pip_ln.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('LinearSVC Classifier')\nplt.show()\nb=datetime.datetime.now()\nb-a","72652e83":"from sklearn.linear_model import LogisticRegression\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   LogisticRegression())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('LogisticRegression Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","da0ee324":"from sklearn.tree import DecisionTreeClassifier\na=datetime.datetime.now()\npip_ln = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',  DecisionTreeClassifier())\n])\nmodel = pip_ln.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('DecisionTree Classifier')\nplt.show()\nb=datetime.datetime.now()\nb-a","c488efe5":"from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\na=datetime.datetime.now()\npip_ln = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',  KNeighborsClassifier())\n])\nmodel = pip_ln.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('KNeighbors Classifier')\nplt.show()\nb=datetime.datetime.now()\nb-a","bfaf8673":"from sklearn.linear_model import PassiveAggressiveClassifier\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',  PassiveAggressiveClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('PassiveAggressive Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","4366418d":"from sklearn.linear_model import SGDClassifier\n\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   SGDClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('SGD Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","0ae3c7d1":"from sklearn.naive_bayes import BernoulliNB\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   BernoulliNB())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('BernoulliNB Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","89161434":"from sklearn.naive_bayes import ComplementNB\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   ComplementNB())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('ComplementNB Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","e47b61c2":"from sklearn.neighbors import NearestCentroid\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   NearestCentroid())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('NearestCentroid Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","e52d20af":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   AdaBoostClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('AdaBoost Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","cb8d7c34":" from sklearn.ensemble import GradientBoostingClassifier\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   GradientBoostingClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('GradientBoosting Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","91ef6b59":"from sklearn.tree import ExtraTreeClassifier\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   ExtraTreeClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('Extra Tree Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","5c7285df":"from sklearn.ensemble import BaggingClassifier\na=datetime.datetime.now()\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',   BaggingClassifier())\n])\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nscore = metrics.accuracy_score(y_test, prediction)\nscore_per = metrics.precision_score(y_test, prediction)\nscore_re = metrics.recall_score(y_test, prediction)\nscore_F1 = metrics.f1_score(y_test, prediction)\nprint(\"accuracy:    %0.3f\" % (score*100))\nprint(\"Precision:   %0.3f\" % (score_per*100))\nprint(\"Recall:      %0.3f\" % (score_re*100))\nprint(\"F1 Score:    %0.3f\" % (score_F1*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.suptitle('Bagging Classifier')\nplt.show()\nb=datetime.datetime.now()\nb - a","2d8a43b5":"##### THE END...","1d27162f":"### Clean HTML tags","123a8eb4":"#### We note that the data are balanced, meaning that the size of the data in both types is close, which is important because it ensures that there is no bias.","9bad0c40":"### Explore the dataset","857da7f1":"#### ","e6478212":"### Drop empty Rows","11a68c94":"#### In the word cloud, we notice the presence of an uppercase letter U, which is due to the omission of the letter S from the word U.S. , where S is among the stop words in the nltk library,But it will not affect the classification results","5933bbbd":"#### We will compare 6 performance measures together \" accuracy ,confusion_matrix ,Precision ,Recall ,F1 and the time required to implement \"","79f79d50":"### Create a new column to be used in the time series and in the classification process","11295493":"### wordcloud ","9ef5724a":"# news topics Classification using TF*IDF and 17 Machine learning classifiers","0d5cabf1":"### Drop duplicates rows","c742a9e2":"#### We note that worldnews was collected in the last 5 months, while politicsNews was collected over a period of 24 months, but we cannot delete these values because their number is large and deleting them will affect the balance of data and the classification process.","a954e59c":"### In the classification process, we will follow the 20\/80 rule, where we will give 80% for training classifiers and 20% for testing.","8888a70b":"### Data visualization"}}