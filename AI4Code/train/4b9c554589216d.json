{"cell_type":{"c1e44ab7":"code","940c01f2":"code","7a8c55d6":"code","fda41302":"code","4d963fce":"code","62a10889":"code","4145237d":"code","e16e784c":"code","7782fdc5":"code","16865415":"markdown","efd7c9af":"markdown","b0347579":"markdown","2a5a8fdd":"markdown","7f4d5988":"markdown"},"source":{"c1e44ab7":"import numpy as np\nimport pandas as pd\nimport itertools # advanced tools\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import KNNImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import ADASYN\nfrom sklearn.neural_network import MLPClassifier\nfrom datetime import datetime\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV","940c01f2":"#Read Dataset\ndf = pd.read_csv('..\/input\/water-potability\/water_potability.csv')\ndf.head()","7a8c55d6":"#Define imputer to replace missing value\nimputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n#Fit imputer on the dataset\nimputer.fit(df)\n#Define Transofrmed dataset\ndftrans = imputer.transform(df)\n#Buld New Dataframe with Imputed Missing Value\ndf1 = pd.DataFrame(dftrans, columns = ['ph', 'Hardness',\t'Solids',\t'Chloramines',\t'Sulfate',\t'Conductivity',\t'Organic_carbon',\t'Trihalomethanes',\t'Turbidity',\t'Potability'])\n#Convert All Value to Integer\ndf1 = df1.astype({\"ph\":'int', \"Hardness\":'int', \"Solids\":'int', \"Chloramines\":'int', \"Sulfate\":'int', \"Conductivity\":'int', \"Organic_carbon\":'int', \"Trihalomethanes\":'int', \"Turbidity\":'int', \"Potability\":'int'}) \nprint (df1.dtypes)","fda41302":"df1.head()","4d963fce":"#Summarizing cases\ncases = len(df)\npotabiliy_count = len(df[df.Potability == 1])\nnonpotability_count = len(df[df.Potability == 0])\nnonpotability_percentage = round(nonpotability_count\/cases*100, 2)\n\nprint('CASE COUNT')\nprint('--------------------------------------------')\nprint('Total number of cases are {}'.format(cases))\nprint('Number of potability cases are {}'.format(potabiliy_count))\nprint('Number of Non-potability cases are {}'.format(nonpotability_count))\nprint('Percentage of Non-potability cases is {}%'.format(nonpotability_percentage))\nprint('--------------------------------------------')","62a10889":"#Data Pre-Processing\n#Data Split\nx = df1.drop('Potability', axis = 1).values\ny = df1['Potability'].values\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = None)\n\n#Oversampling Data\nada = ADASYN(sampling_strategy='auto', random_state=None)\nx_train, y_train = ada.fit_resample(x_train, y_train)\n\n#Min-Max Data Scalling\nminmaxscaler = MinMaxScaler() \nx_train = minmaxscaler.fit_transform(x_train)\nx_test = minmaxscaler.transform(x_test)\n\n#Standarization\nscaler = StandardScaler() \nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","4145237d":"start = datetime.now()\n#Multi Layer Perceptron Classifier\nmlp = MLPClassifier(max_iter=100)\nmlp_parameter = {\n    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}\nmlp_tuned = GridSearchCV(mlp, mlp_parameter, n_jobs=-1, cv=3)\nmlp_tuned.fit(x_train, y_train)\nmlp_model = mlp_tuned.predict(x_test)\n\n# Best parameter set\nprint('Best parameters found:\\n', mlp_tuned.best_params_)\n\nend = datetime.now()\ntime_taken = end - start\nprint('Training Time: ',time_taken)","e16e784c":"start = datetime.now()\n\n#Conducting Final Model\nmlp_final = MLPClassifier(max_iter=10000, activation=mlp_tuned.best_params_['activation'], alpha=mlp_tuned.best_params_['alpha'], hidden_layer_sizes=mlp_tuned.best_params_['hidden_layer_sizes'], learning_rate=mlp_tuned.best_params_['learning_rate'], solver=mlp_tuned.best_params_['solver'])\nmlp_final.fit(x_train, y_train)\nfinal_model = mlp_final.predict(x_test)\n\nend = datetime.now()\ntime_taken = end - start\n\nprint('MLP Classifier Performance')\nprint('Precision {}'.format(precision_score(y_test, final_model)))\nprint('Recall {}'.format(recall_score(y_test, final_model)))\nprint('F1 Score {}'.format(f1_score(y_test, final_model)))\nprint('Accuracy {}'.format(accuracy_score(y_test, final_model)))\nprint('Training Time ',time_taken)","7782fdc5":"#Confusion Matrix\n#Defining the plot function\ndef plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n    title = 'Confusion Matrix of {}'.format(title)\n    if normalize:\n        cm = cm.astype(float) \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n#Compute confusion matrix for the models\nmlp_matrix = confusion_matrix(y_test, final_model, labels = [0, 1])\nplt.rcParams['figure.figsize'] = (6, 6)\nmlp_cm_plot = plot_confusion_matrix(mlp_matrix, \n                                classes = ['Negative(0)','Positive(1)'], \n                                normalize = False, title = 'the Classifier')\nplt.savefig('lr_cm_plot.png')\nplt.show()","16865415":"Data Cleansing & Transformation","efd7c9af":"Tuned Model","b0347579":"Model Building","2a5a8fdd":"Confusion Matrix","7f4d5988":"Data Pre-Processing"}}