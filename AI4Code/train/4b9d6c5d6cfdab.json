{"cell_type":{"fcf69410":"code","02a2e346":"code","6147009d":"code","db428be6":"code","e2b739c8":"code","2e90bcaa":"code","76680573":"code","189b5562":"code","1a77c3a9":"code","9b5b4ce5":"code","88a3ab22":"code","a6e2ee19":"code","e868a0d3":"code","ebd1d99a":"code","9da49993":"code","9556f591":"code","d34e81c1":"code","d429e812":"code","3b4fa2c6":"markdown"},"source":{"fcf69410":"import os\nimport gensim\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(os.listdir(\"..\/input\"))\n%matplotlib inline","02a2e346":"data = pd.read_json('..\/input\/train.json')\ntest = pd.read_json('..\/input\/test.json')","6147009d":"print('Training data shape: {}'.format(data.shape))\nprint('Test data shape: {}'.format(test.shape))","db428be6":"# Target variable \ntarget = data.cuisine","e2b739c8":"data['ingredient_count'] = data.ingredients.apply(lambda x: len(x))","2e90bcaa":"def flatten_lists(lst):\n    \"\"\"Remove nested lists.\"\"\"\n    return [item for sublist in lst for item in sublist]","76680573":"f = plt.figure(figsize=(14,8))\ngs = gridspec.GridSpec(2, 2)\n\nax1 = plt.subplot(gs[0, :])\ndata.ingredient_count.value_counts().hist(ax=ax1)\nax1.set_title('Recipe richness', fontsize=12)\n\nax2 = plt.subplot(gs[1, 0])\npd.Series(flatten_lists(list(data['ingredients']))).value_counts()[:20].plot(kind='barh', ax=ax2)\nax2.set_title('Most popular ingredients', fontsize=12)\n\nax3 = plt.subplot(gs[1, 1])\ndata.groupby('cuisine').mean()['ingredient_count'].sort_values(ascending=False).plot(kind='barh', ax=ax3)\nax3.set_title('Average number of ingredients in cuisines', fontsize=12)\n\nplt.show()","189b5562":"# Feed a word2vec with the ingredients\nw2v = gensim.models.Word2Vec(list(data.ingredients), size=350, window=10, min_count=2, iter=20)","1a77c3a9":"w2v.most_similar(['meat'])","9b5b4ce5":"w2v.most_similar(['chicken'])","88a3ab22":"def document_vector(doc):\n    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n    doc = [word for word in doc if word in w2v.wv.vocab]\n    return np.mean(w2v[doc], axis=0)","a6e2ee19":"data['doc_vector'] = data.ingredients.apply(document_vector)\ntest['doc_vector'] = test.ingredients.apply(document_vector)","e868a0d3":"lb = LabelEncoder()\ny = lb.fit_transform(target)","ebd1d99a":"X = list(data['doc_vector'])\nX_test = list(test['doc_vector'])","9da49993":"clf = LogisticRegression(C=100)","9556f591":"clf.fit(X, y)","d34e81c1":"y_test = clf.predict(X_test)\ny_pred = lb.inverse_transform(y_test)","d429e812":"test_id = [id_ for id_ in test.id]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('clf_output.csv', index=False)","3b4fa2c6":"Let's try some examples"}}