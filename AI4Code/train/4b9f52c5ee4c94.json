{"cell_type":{"a8b3010d":"code","fadeef52":"code","a3c2b43e":"code","06f0e61f":"code","1944b4f1":"code","80ddacbe":"code","a33659c0":"code","70da8ccb":"code","e78bb0ae":"code","200381a1":"code","06855d4a":"code","369694ba":"code","93537230":"code","54867dec":"code","c5840315":"code","23cac77e":"code","99bbc8f2":"code","8be27214":"code","fe43563f":"code","ff9653ed":"code","e7a32257":"code","625950c0":"code","120cea36":"code","a02c9437":"code","7786e8a5":"code","b6ef981a":"code","527e8b56":"code","1b8532fa":"code","4cab1469":"code","0d09fa18":"code","71e29415":"code","d45eaaee":"code","b5c434e7":"code","d85477c0":"code","b06e3a35":"code","e029208b":"code","08d707e7":"code","503ad672":"code","27cb7d93":"markdown","a1912e2d":"markdown","0facf9b1":"markdown","c36b8308":"markdown","a1aa4292":"markdown","1c8145c0":"markdown","c75cf04d":"markdown","641a842a":"markdown","3c91d2a8":"markdown","eb5bd614":"markdown","1fddb06d":"markdown","88cfdbb8":"markdown","4c84e3e7":"markdown","3c8eb886":"markdown","bf48f533":"markdown","eda46246":"markdown"},"source":{"a8b3010d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fadeef52":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, RandomizedSearchCV, train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler\nfrom scipy.stats import ttest_1samp, shapiro, levene, ttest_ind, mannwhitneyu, pearsonr, spearmanr, kendalltau, \\\n    f_oneway, kruskal","a3c2b43e":"!pip install xgboost\n!pip install lightgbm\n!pip install catboost","06f0e61f":"import warnings\nwarnings.simplefilter(action='ignore', category=Warning)","1944b4f1":"#Data okunmas\u0131n\u0131 kolayla\u015ft\u0131racak ayarlar\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 170)\npd.set_option('display.max_rows', 20)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","80ddacbe":"#Verinin okunmas\u0131\ndf = pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf.head()","a33659c0":"df.info()","70da8ccb":"df.shape","e78bb0ae":"df.describe().T","200381a1":"#Veri seti i\u00e7erisindeki kategorik, numerik de\u011fi\u015fkenlerin belirlenmesi\n    cat_cols = [col for col in df.columns if df[col].dtypes == \"O\"]\n    num_but_cat = [col for col in df.columns if df[col].nunique() < 10 and\n                   df[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in df.columns if df[col].nunique() > 20 and\n                   df[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    \n    num_cols = [col for col in df.columns if df[col].dtypes != \"O\"]\n\n    num_cols = [col for col in num_cols if col not in num_but_cat]","06855d4a":"print (cat_cols)","369694ba":"#Ayk\u0131r\u0131 De\u011ferlerin Saptanmas\u0131 ve \u00c7\u0131kar\u0131lmas\u0131\n\n#Ba\u011f\u0131ml\u0131 de\u011fi\u015fken Salary nin ayk\u0131r\u0131 de\u011ferlerinin grafik ile se\u00e7ilmesi\nsns.boxplot(x=df[\"Salary\"])\nplt.show()","93537230":"# Salary de\u011fi\u015fkeni i\u00e7indeki 1350 ve \u00fczerindeki ayk\u0131r\u0131 de\u011ferlerin silinmesi\ndf = df[(df['Salary'] < 1350) | (df['Salary'].isnull())]","54867dec":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","c5840315":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","23cac77e":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","99bbc8f2":"# Num_cols i\u00e7erisindeki ayk\u0131r\u0131 de\u011ferlerin bask\u0131lanmas\u0131\nfor col in num_cols:\n    if check_outlier(df, col):\n        replace_with_thresholds(df, col)","8be27214":"#Eksik De\u011ferlerin Yakalanmas\u0131 ve Silinmesi\ndf.isnull().sum()","fe43563f":"df.dropna(inplace=True)\ndf.isnull().sum()\n","ff9653ed":"df.shape","e7a32257":"#De\u011fi\u015fkenler aras\u0131 korelasyon \u0131s\u0131 haritas\u0131\nplt.figure(figsize=(14,12))\nsns.heatmap(df.corr(), annot=True, cmap=\"BuPu\");","625950c0":"test_stat, pvalue = shapiro(df[\"Salary\"])\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n#p-value de\u011feri 0.05 ten k\u00fc\u00e7\u00fck \u00e7\u0131kt\u0131, HO reddedildi, Normal da\u011f\u0131l\u0131m varsay\u0131m\u0131 sa\u011flanmaktad\u0131r reddedildi.\n\n","120cea36":"# Varsay\u0131m sa\u011flanmad\u0131\u011f\u0131 i\u00e7in spearman testi:\ndf.corr(method=\"spearman\")","a02c9437":"# De\u011fi\u015fken T\u00fcretme\ndf.columns = [col.upper() for col in df.columns]\ndf[\"NEW_ATBAT\/CATBAT\"] = df[\"ATBAT\"] \/ df[\"CATBAT\"] # T\u00fcm kariyerindeki sezonda vuru\u015f oran\u0131\ndf[\"NEW_HITS\/CHITS\"] = df[\"HITS\"] \/ df[\"CHITS\"] # T\u00fcm kariyerindeki sezonda isabetli vuru\u015f oran\u0131\ndf[\"NEW_HMRUN\/CHMRUN\"] = df[\"HMRUN\"] \/ df[\"CHMRUN\"] #T\u00fcm kariyerindeki sezonda en de\u011ferli vuru\u015f say\u0131s\u0131\ndf[\"NEW_HMRUN\/ATBAT\"] = df[\"HMRUN\"] \/ df[\"ATBAT\"]\ndf[\"NEW_CHMRUN\/CATBAT\"] = df[\"CHMRUN\"] \/ df[\"CATBAT\"]\ndf[\"NEW_RUNS\/CRUNS\"] = df[\"RUNS\"] \/ df[\"CRUNS\"] # T\u00fcm kariyerindeki sezonda kazand\u0131rd\u0131\u011f\u0131 say\u0131\ndf[\"NEW_RBI\/CRBI\"]= df[\"RBI\"]\/df[\"CRBI\"] # T\u00fcm kariyerindeki szeonda yapt\u0131rd\u0131\u011f\u0131 ko\u015fu say\u0131s\u0131\ndf[\"NEW_WALKS\/CWALKS\"] = df[\"WALKS\"] \/ df[\"CWALKS\"] # Kar\u015f\u0131 tak\u0131ma yapt\u0131r\u0131lan hata say\u0131s\u0131\ndf[\"NEW_HITS\/ATBAT\"] = df[\"HITS\"] \/ df[\"ATBAT\"] #Sezonda att\u0131\u011f\u0131 topun isabet etme oran\u0131\ndf[\"NEW_HMRUN\/RUNS\"] = df[\"HMRUN\"] \/ df['RUNS'] #Sezonda en de\u011ferli vuru\u015f say\u0131s\u0131n\u0131n kazand\u0131rd\u0131\u011f\u0131 say\u0131ya oran\u0131\ndf[\"NEW_CHITS\/CATBAT\"] = df[\"CHITS\"] \/ df[\"CATBAT\"] #Kariyeri boyunca topa vurma oran\u0131n\u0131n isabetli olmas\u0131 oran\u0131\ndf[\"NEW_CHMRUN\/CRUNS\"] = df[\"CHMRUN\"] \/ df[\"CRUNS\"] # Kariyeri boyunca tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131n\u0131n en de\u011ferli say\u0131 olma oran\u0131\ndf[\"NEW_ASSISTS\/ERRORS\"]= df[\"ASSISTS\"]\/df[\"ERRORS\"] # Sezonda yapt\u0131\u011f\u0131 asistin hata oran\u0131\ndf[\"NEW_ASSISTS_PUTOUTS\"]= df[\"ASSISTS\"]*df[\"PUTOUTS\"] #Asistleri tak\u0131m arkada\u015flar\u0131yla payla\u015fma\ndf[\"NEW_CHITS\/CRBI\"]= df[\"CHITS\"]\/df[\"CRBI\"] #T\u00fcm kariyerinde isabetli vuru\u015f yapt\u0131\u011f\u0131 kar\u015f\u0131ya yapt\u0131rd\u0131\u011f\u0131 ko\u015fuya oran\u0131\ndf[\"NEW_CRUNS\/CHITS\"]= df[\"CRUNS\"]\/df[\"CHITS\"]\ndf[\"NEW_ATBAT\/PUTOUTS\"]= df[\"ATBAT\"]\/df[\"PUTOUTS\"] #Sezonda topa vuru\u015f ile tak\u0131m arkada\u015flar\u0131yla yard\u0131mla\u015fma oran\u0131\ndf[\"NEW_WALKS\/YEARS\"]=df[\"WALKS\"]\/df[\"YEARS\"]\ndf[\"NEW_CATBAT\/YEARS\"] = df[\"CATBAT\"] \/ df[\"YEARS\"]\ndf[\"NEW_CHITS\/YEARS\"] = df[\"CHITS\"] \/ df[\"YEARS\"]\ndf[\"NEW_CHMRUN\/YEARS\"] = df[\"CHMRUN\"] \/ df[\"YEARS\"]\ndf[\"NEW_CRUNS\/YEARS\"] = df[\"CRUNS\"] \/ df[\"YEARS\"]\ndf[\"NEW_CRBI\/YEARS\"] = df[\"CRBI\"] \/ df[\"YEARS\"]\ndf[\"NEW_CWALKS\/YEARS\"] = df[\"CWALKS\"] \/ df[\"YEARS\"]\ndf[\"NEW_ATBAT\/ERRORS\"] = df[\"ATBAT\"] \/ df[\"ERRORS\"]\ndf[\"NEW_CAR\"]= (df[\"CHITS\"]+df[\"CRUNS\"]+df[\"CRBI\"]+df[\"CWALKS\"])\/df[\"YEARS\"]\ndf[\"NEW_BAT\"]=(df[\"HITS\"]+df[\"RUNS\"]+df[\"RBI\"]+df[\"ASSISTS\"]+df[\"WALKS\"]-df[\"ERRORS\"])\/df[\"ATBAT\"]","7786e8a5":"df.shape","b6ef981a":"#Eklenen yeni de\u011fi\u015fkenlerin eksik veya sonsuz de\u011ferlerinin temizlenmesi\ndf.isnull().sum().sum()\ndf.dropna(inplace=True)\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.isnull().sum().sum()","527e8b56":"#One-hot encoding\ndf = pd.get_dummies(df,drop_first=True)\ndf.head()","1b8532fa":"y=df[\"SALARY\"]\nX=df.drop(\"SALARY\", axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=13)\n\nmodels = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","4cab1469":"rf_model = RandomForestRegressor().fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\nlgb_model = LGBMRegressor().fit(X_train, y_train)\ny_pred = lgb_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\ncatboost_model = CatBoostRegressor(verbose=False).fit(X_train, y_train)\ny_pred = catboost_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\ndef plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                     ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n\n\nplot_importance(rf_model, X)\nplot_importance(lightgbm_model, X)\nplot_importance(catboost_model, X)\n\n\n","0d09fa18":"catboost_model = CatBoostRegressor(verbose=False)\n\ncatboost_random_params = {\"iterations\": [int(x) for x in np.linspace(start=100, stop=1500, num=10)],\n                          \"learning_rate\": [0.01, 0.1],\n                          \"depth\": np.random.randint(5, 50, 10)}\n\ncatboost_random = RandomizedSearchCV(estimator=catboost_model,\n                               param_distributions=catboost_random_params,\n                               n_iter=100,  \n                               cv=3,\n                               verbose=True,\n                               random_state=8,\n                               n_jobs=-1)\ncatboost_random.fit(X, y)","71e29415":"catboost_random.best_params_","d45eaaee":"catboost_model = CatBoostRegressor(random_state=8, verbose=False)\n\ncatboost_params = {\"iterations\": [1100, 1150, 1200],\n                   \"learning_rate\": [0.01],\n                   \"depth\": [7, 10, 12]}\n\ncatboost_best_grid = GridSearchCV(catboost_model, catboost_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)\n\ncatboost_final = catboost_model.set_params(**catboost_best_grid.best_params_, random_state=8).fit(X, y)\nnp.mean(np.sqrt(-cross_val_score(catboost_final, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","b5c434e7":"catboost_best_grid.best_params_","d85477c0":"rf_model = RandomForestRegressor(random_state=8)\n\nrf_random_params = {\"max_depth\": np.random.randint(5, 50, 10),\n                    \"max_features\": [5, 6, 7, \"auto\", ],\n                    \"min_samples_split\": np.random.randint(2, 50, 20),\n                    \"n_estimators\": [int(x) for x in np.linspace(start=100, stop=1500, num=10)]}\n\n\nrf_random = RandomizedSearchCV(estimator=rf_model,\n                               param_distributions=rf_random_params,\n                               n_iter=100,  \n                               cv=3,\n                               verbose=True,\n                               random_state=8,\n                               n_jobs=-1)\nrf_random.fit(X, y)","b06e3a35":"rf_random.best_params_","e029208b":"rf_model = RandomForestRegressor(random_state=8)\n\nrf_params = {\"max_depth\": [45, 46, 47, 48, 49 ],\n             \"max_features\": [4, 5, 6],\n             \"min_samples_split\": [2,3,5],\n             \"n_estimators\": [1000, 1010, 1020, 1030]}\n\nrf_best_grid = GridSearchCV(rf_model, rf_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)\n\nrf_final = rf_model.set_params(**rf_best_grid.best_params_, random_state=8).fit(X, y)\nnp.mean(np.sqrt(-cross_val_score(rf_final, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","08d707e7":"rf_best_grid.best_params_","503ad672":"voting_reg = VotingRegressor(estimators=[('RF', rf_final),\n                                         ('Catboost', catboost_final)])\n\n\nvoting_reg.fit(X, y)\n\n\nnp.mean(np.sqrt(-cross_val_score(voting_reg, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","27cb7d93":"Veri seti i\u00e7erisindeki de\u011fi\u015fkenler;\n\nAtBat: 1986-1987 sezonunda bir beyzbol sopas\u0131 ile topa yap\u0131lan vuru\u015f say\u0131s\u0131\n\nHits: 1986-1987 sezonundaki isabet say\u0131s\u0131\n\nHmRun: 1986-1987 sezonundaki en de\u011ferli vuru\u015f say\u0131s\u0131\n\nRuns: 1986-1987 sezonunda tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131\n\nRBI: Bir vurucunun vuru\u015f yapt\u0131g\u0131nda ko\u015fu yapt\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\n\nWalks: Kar\u015f\u0131 oyuncuya yapt\u0131r\u0131lan hata say\u0131s\u0131\n\nYears: Oyuncunun major liginde oynama s\u00fcresi (sene)\n\nCAtBat: Oyuncunun kariyeri boyunca topa vurma say\u0131s\u0131\n\nCHits: Oyuncunun kariyeri boyunca yapt\u0131\u011f\u0131 isabetli vuru\u015f say\u0131s\u0131\n\nCHmRun: Oyucunun kariyeri boyunca yapt\u0131\u011f\u0131 en de\u011ferli say\u0131s\u0131\n\nCRuns: Oyuncunun kariyeri boyunca tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131\n\nCRBI: Oyuncunun kariyeri boyunca ko\u015fu yapt\u0131rd\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\n\nCWalks: Oyuncun kariyeri boyunca kar\u015f\u0131 oyuncuya yapt\u0131rd\u0131\u011f\u0131 hata say\u0131s\u0131\n\nLeague: Oyuncunun sezon sonuna kadar oynad\u0131\u011f\u0131 ligi g\u00f6steren A ve N seviyelerine sahip bir fakt\u00f6r\n\nDivision: 1986 sonunda oyuncunun oynad\u0131\u011f\u0131 pozisyonu g\u00f6steren E ve W seviyelerine sahip bir fakt\u00f6r\n\nPutOuts: Oyun icinde tak\u0131m arkada\u015f\u0131nla yard\u0131mla\u015fma\n\nAssits: 1986-1987 sezonunda oyuncunun yapt\u0131\u011f\u0131 asist say\u0131s\u0131\n\nErrors: 1986-1987 sezonundaki oyuncunun hata say\u0131s\u0131\n\nSalary: Oyuncunun 1986-1987 sezonunda ald\u0131\u011f\u0131 maa\u015f(bin uzerinden)\n\nNewLeague: 1987 sezonunun ba\u015f\u0131nda oyuncunun ligini g\u00f6steren A ve N seviyelerine sahip bir fakt\u00f6r\n","a1912e2d":"# Korelasyon Analizi\n*Varsay\u0131m Kontrol\u00fc\n\n*Varsay\u0131m sa\u011flan\u0131yorsa pearson sa\u011flanm\u0131yorsa Spearman.\n\n*H0: Normal da\u011f\u0131l\u0131m varsay\u0131m\u0131 sa\u011flanmaktad\u0131r.\n\n*H1: Normal da\u011f\u0131l\u0131m varsay\u0131m\u0131 sa\u011flanmamaktad\u0131r. \n\n*p-value < ise 0.05 'ten HO RED.\n\n*p-value < de\u011filse 0.05 H0 REDDEDILEMEZ.","0facf9b1":"# Gerekli K\u00fct\u00fcphaneler","c36b8308":"## RF Hyperparameter Optimization","a1aa4292":"RandomizedSearchCV ile bulunan Catboost hiperparametrelerin GridSearchCV ile Catboost final modeli olu\u015fturulmas\u0131","1c8145c0":"RandomizedSearchCV ile RF hiperparametre aray\u0131\u015f\u0131","c75cf04d":"## Veri setini tan\u0131ma, betimsel istatistiklerine bakma","641a842a":"# De\u011fi\u015fken T\u00fcretme","3c91d2a8":"# Veri \u00d6ni\u015fleme\n\nYap\u0131lacak \u0130\u015flemler\n\n*Veri seti i\u00e7erisindeki kategorik, numerik de\u011fi\u015fkenlerin belirlenmesi\n\n*Ayk\u0131r\u0131 De\u011ferlerin Saptanmas\u0131 ve \u00c7\u0131kar\u0131lmas\u0131\n\n*Eksik De\u011ferlerin Saptanmas\u0131 ve Silinmesi\n\n*De\u011fi\u015fkenler Aras\u0131 Korelasyon Haritas\u0131n\u0131n \u00c7\u0131kar\u0131lmas\u0131\n\n*Korelasyon Analizi\n\n*Kategorik De\u011fi\u015fkenlerin 0-1 e d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi\n\n*Scaling i\u015flemleri\n\n*De\u011fi\u015fken T\u00fcretme\n","eb5bd614":"RandomizedSearchCV ile Catboost hiperparametre aray\u0131\u015f\u0131","1fddb06d":"# Stacking & Ensemble Learning (\u0130ki final modelin birle\u015ftirilmesi)","88cfdbb8":"## CATBOOST Hyperparameter Optimization","4c84e3e7":"# Encoding","3c8eb886":"RandomizedSearchCV ile bulunan RF hiperparametrelerin GridSearchCV ile RF final modeli olu\u015fturulmas\u0131","bf48f533":"# MODELLEME\n\n## Base Models","eda46246":"## Feature Importance"}}