{"cell_type":{"1a5020a2":"code","54fedab3":"code","78024cb8":"code","06f013de":"code","0b4712a7":"code","d23f3925":"code","3a23838a":"code","687b8b23":"code","987973a1":"code","e1d8ae64":"code","00336761":"code","97b15f6d":"code","7da77edc":"code","c3b43d29":"code","43053883":"code","ba67fd5d":"code","edde27ab":"code","c43b5a68":"code","83ef2972":"code","53537dde":"code","5dba6a18":"code","8b2e4d08":"code","e8c5d2c6":"code","247f1523":"code","ddcb9f83":"code","8f0149fa":"code","41599dd1":"code","a7c21b02":"code","80c909c9":"code","2bed8761":"code","067f6020":"code","9e31620a":"code","38b64ebd":"code","9840b057":"code","7da41c6b":"code","17f16a9e":"code","3322fe07":"code","bb202782":"code","d08aad2a":"code","e08f3961":"code","ad0af635":"code","aeca417d":"code","479cada8":"code","f49ee0ca":"code","15cb9293":"code","8b1f13a4":"code","c90d1dd4":"code","37103094":"code","1302a2c1":"code","7c129ad8":"code","bafa9229":"code","90c0fbec":"code","3cd31feb":"code","fa6f9f24":"code","0b60f2a7":"code","3c87594e":"code","fe880d43":"code","64729546":"code","afd39cfe":"code","7d58a42a":"code","c968d26b":"code","e53ed8e2":"code","e2135425":"code","343f07aa":"code","f5d2db8a":"code","1a2f8617":"code","257a0599":"code","0c69be05":"code","30b4477c":"code","ec39add5":"code","767976b6":"code","53d0ecfc":"code","aa611e89":"code","0c569eb7":"code","2bf7bf62":"code","1830efbe":"code","8cce62f0":"code","1e54deb5":"code","53700dd7":"code","994c0b24":"code","52cfde4d":"code","dfb02ceb":"code","135c5b87":"code","bd1839a3":"code","9a109de7":"code","4207f557":"code","06f83262":"code","b1da28a6":"code","5d5c27df":"code","946feb7f":"code","be88ca0b":"code","67d9beb4":"code","360e0a79":"code","d89ed0b6":"code","13610526":"code","7eeec938":"code","39f5b6e1":"code","7d200808":"code","dc0ced40":"code","b074ba86":"code","0b0d9c9a":"code","70a65542":"code","8409a1de":"code","9a4748de":"code","f88abd8d":"code","44db27c4":"code","a4730802":"code","1b36ae63":"code","276dc379":"markdown","17633169":"markdown","627ce4f2":"markdown","06f4994a":"markdown","51a2e285":"markdown","f42da978":"markdown","aeecb3ab":"markdown","9cfdadb3":"markdown","57908f08":"markdown","330bb732":"markdown","9b80a621":"markdown","e26cadc4":"markdown","ca3d4183":"markdown","dacb2fc6":"markdown","2080711d":"markdown","1fa36eac":"markdown","fe7cad6b":"markdown","ee9ccae1":"markdown","357bff12":"markdown","bb3c8c0c":"markdown","7d945902":"markdown","99dc6bee":"markdown","ddc849c3":"markdown","4cc496c2":"markdown","2aa511a0":"markdown","fc4b583a":"markdown","aebaeba9":"markdown","e4de141e":"markdown","f177a0ee":"markdown","d62dff2a":"markdown","ddd87eb6":"markdown","0080b040":"markdown","02a8b26f":"markdown","d6edb1aa":"markdown","dc2d3ab3":"markdown","6a7aa0f0":"markdown","6451b7f0":"markdown","f09904ef":"markdown","7636f090":"markdown","80669557":"markdown","d1e1a980":"markdown","9702d67e":"markdown","07f79d95":"markdown","8134b53d":"markdown","dfebbb3a":"markdown","717847dd":"markdown","37e1bc07":"markdown","b3f1fec6":"markdown","01cdecdf":"markdown","4ac2312f":"markdown","eb0939ea":"markdown","bfca3b80":"markdown","bf4c505e":"markdown","03cab3af":"markdown","13d86f51":"markdown","2d6592fe":"markdown","ae9abf10":"markdown","7a24e499":"markdown","0ef92804":"markdown","68d084d1":"markdown","35119941":"markdown","3547d15e":"markdown","bb446fca":"markdown","6e253e7c":"markdown","08ea3fc2":"markdown","6f85aa0a":"markdown","93d23eb5":"markdown","b4f99f89":"markdown","c36b3576":"markdown","936e6314":"markdown","f3c2e339":"markdown","4a5f0d59":"markdown","fdc1e776":"markdown","7d04aad9":"markdown","5dd0fc95":"markdown","3dd78595":"markdown","10b3f772":"markdown"},"source":{"1a5020a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","54fedab3":"import numpy as np #NumPy is the fundamental package for scientific computing with Python.\nimport pandas as pd #library written for the Python for data manipulation and analysis. In particular, \n                    #it offers data structures and operations for manipulating numerical tables and time series .\nimport matplotlib.pyplot as plt #plotting library  and numerical mathematics extends NumPy\nimport seaborn as sns  #Python data visualization library based on matplotlib.\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","78024cb8":"Train_Master = pd.read_csv('..\/input\/train.csv')\nTest_Master = pd.read_csv('..\/input\/test.csv')","06f013de":"print('*** About Training Data ---> \\n')\nprint('Dimensions: {} Rows and {} Columns \\n'.format(Train_Master.shape[0],Train_Master.shape[1]))\nprint('Column names are -> \\n{}\\n'.format(Train_Master.columns.values))\nTrain_Master.info()\nprint('\\n\\n\\n')\nprint('*** About Test Data ---> \\n')\nprint('Dimensions: {} Rows and {} Columns \\n'.format(Test_Master.shape[0],Test_Master.shape[1]))\nprint('Column names are -> \\n{}\\n'.format(Test_Master.columns.values))\nTest_Master.info()","0b4712a7":"Train_Master.describe()","d23f3925":"Train_Master.isnull().sum(axis=0)","3a23838a":"#Lets drop column \"Cabin\" from training set.\nTrain_Master.drop('Cabin', axis=1, inplace=True)\n#Lets fill null values of Age by mean of column values\nTrain_Master['Age'] = Train_Master['Age'].fillna(np.mean(Train_Master['Age']))","687b8b23":"# Still we have two null values in column Embarked.\nprint(Train_Master['Embarked'].describe())\nprint(Train_Master['Embarked'].mode())\n# Replacing null value with most ocurred value seems proper solution.","987973a1":"Train_Master['Embarked'] = Train_Master['Embarked'].fillna('S')\nTrain_Master.isnull().sum(axis=0)  # Re-validate Null value count","e1d8ae64":"Train_Master.columns.values","00336761":"Features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","97b15f6d":"y = Train_Master.Survived\nX = Train_Master[Features]","7da77edc":"y.head()","c3b43d29":"X.head()","43053883":"X.describe()","ba67fd5d":"from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state =1,test_size=0.30)","edde27ab":"from sklearn.tree import DecisionTreeClassifier\nML_101_DTC = DecisionTreeClassifier(random_state=1)\nML_101_DTC.fit(train_X, train_y)\npred_ML_101_DTC = ML_101_DTC.predict(val_X)","c43b5a68":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nprint(confusion_matrix(val_y,pred_ML_101_DTC))\nprint(classification_report(val_y, pred_ML_101_DTC))\nprint(accuracy_score(val_y, pred_ML_101_DTC))","83ef2972":"from sklearn.ensemble import RandomForestClassifier\nML_101_RFC = RandomForestClassifier(random_state=1)\nML_101_RFC.fit(train_X, train_y)\npred_ML_101_RFC = ML_101_RFC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_101_RFC))\nprint(classification_report(val_y, pred_ML_101_RFC))\nprint(accuracy_score(val_y, pred_ML_101_RFC))","53537dde":"#For test data test_X will be Test_Master[Features]\n#But Null values will give error for predict function.\n\nprint(Test_Master[Features].isnull().sum())\n# Fix Age as we did for Training Set and Fare to be filled with median of Fare\nTest_Master['Age'] = Test_Master['Age'].fillna(np.mean(Test_Master['Age']))\nTest_Master['Fare'] = Test_Master['Fare'].fillna(Test_Master['Fare'].median())\n\npred_ML_101_sub = ML_101_RFC.predict(Test_Master[Features])\n\n\n#test_ids = Test_Master.loc[:, 'PassengerId']\n#my_submission = pd.DataFrame(data={'PassengerId':test_ids, 'Survived':pred_ML_101_sub})\n\n#print(my_submission['Survived'].value_counts())\n\n#Export Results to CSV\n# my_submission.to_csv('submission.csv', index = False)   ---Exporting csv from Next Section","5dba6a18":"Train_Master = pd.read_csv('..\/input\/train.csv')\nTest_Master = pd.read_csv('..\/input\/test.csv')\nTrain_Master.sample(5)","8b2e4d08":"print(Train_Master.info())\nprint('*-*'*25)\nprint(Train_Master.describe())","e8c5d2c6":"fig, ax  = plt.subplots(1,2)\nfig.set_figheight(6)\nfig.set_figwidth(12)\nsns.heatmap(data=Train_Master.isnull(),cbar=False,yticklabels=False,cmap='cividis', ax=ax[0])\nax[0].set_title('Data Missingness for Training Data',fontsize=16)\nsns.heatmap(data=Test_Master.isnull(),cbar=False,yticklabels=False, cmap='cividis',ax=ax[1])\nax[1].set_title('Data Missingness for Test Data',fontsize=16)\nplt.show()","247f1523":"# Age\nprint('Total No of rows in training set: {} \\n'.format(len(Train_Master)))\nprint('Total No of  rows  in  test  set: {}\\n \\n '.format(len(Test_Master)))\n\nper_nan_age_train = ((Train_Master['Age'].isnull().sum())*100)\/(len(Train_Master))\nper_nan_age_test  = ((Test_Master['Age'].isnull().sum())*100)\/(len(Test_Master))\n\nprint('% of missing rows in training set: {0:0.2f} \\n'.format(per_nan_age_train))\nprint('% of missing  rows  in  test  set: {0:0.2f} \\n'.format(per_nan_age_test))","ddcb9f83":"Titanic_Master = Train_Master.append(Test_Master)","8f0149fa":"age_data = Train_Master['Age'].dropna().append(Test_Master['Age'].dropna())\nsns.distplot(age_data,bins = 50,color='blue')\nplt.show()","41599dd1":"Train_Master.corr()","a7c21b02":"sns.heatmap(Train_Master.corr(), cmap='rainbow', annot=True,cbar=False,linewidths=1, linecolor='black')\nplt.show()","80c909c9":"sns.boxplot(x='Pclass',y='Age',data=Train_Master)","2bed8761":"sns.scatterplot(x='Fare',y='Age',data=Train_Master,hue='Pclass',palette='rainbow')\nplt.show()","067f6020":"fig, ax  = plt.subplots(1,4)\nfig.set_figheight(8)\nfig.set_figwidth(20)\nsns.scatterplot(y='Age',x='Pclass',data=Train_Master,ax=ax[0])\nsns.scatterplot(y='Age',x='Fare',data=Train_Master,ax=ax[1])\nsns.scatterplot(y='Age',x='SibSp',data=Train_Master,ax=ax[2])\nsns.scatterplot(y='Age',x='Parch',data=Train_Master,ax=ax[3])\nplt.show()","9e31620a":"Titanic_Master.groupby(['Pclass'])['Age'].median()\nTitanic_Master[Titanic_Master.Pclass==1]['Age'].median()","38b64ebd":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass ==1:\n            return Titanic_Master[Titanic_Master.Pclass==1]['Age'].median()\n        elif Pclass ==2:\n            return Titanic_Master[Titanic_Master.Pclass==2]['Age'].median()\n        elif Pclass ==3:\n            return Titanic_Master[Titanic_Master.Pclass==3]['Age'].median()\n    else:\n        return Age","9840b057":"Train_Master['Age'] = Train_Master[['Age','Pclass']].apply(impute_age,axis=1)\nTest_Master['Age'] = Test_Master[['Age','Pclass']].apply(impute_age,axis=1)","7da41c6b":"print(Train_Master['Embarked'].isnull().sum())\nsns.countplot(data=Train_Master, x='Embarked')\nplt.show()","17f16a9e":"# Fill value of most occurred value\n\nTrain_Master['Embarked'] = Train_Master['Embarked'].fillna('S')","3322fe07":"Test_Master[Test_Master['Fare'].isnull()]","bb202782":"print('Min. of Fare: {}'.format(Titanic_Master.Fare.min()))\nprint('Max. of Fare: {}'.format(Titanic_Master.Fare.max()))\nprint('Average Fare: {}'.format(Titanic_Master.Fare.mean()))","d08aad2a":"Train_Master[Train_Master.Fare==0]","e08f3961":"sns.boxplot(x='Pclass', y='Fare', data=Titanic_Master)","ad0af635":"print('Mean of fare for Class-3:',end ='   ')\nprint(Titanic_Master[Titanic_Master.Pclass==3].Fare.mean())\nprint('Median of fare for whole dataset:',end ='   ')\nprint(Titanic_Master.Fare.median())\nprint('Mean Fare values after removing outliers:',end='   ')\nprint(Titanic_Master[Titanic_Master.Fare<500]['Fare'].mean())","aeca417d":"Test_Master['Fare'] = Test_Master['Fare'].fillna(Titanic_Master.Fare.median())","479cada8":"# Age\nprint('Total No of rows in training set: {} \\n'.format(len(Train_Master)))\nprint('Total No of  rows  in  test  set: {}\\n \\n '.format(len(Test_Master)))\nprint('-'*100)\nper_nan_cabin_train = ((Train_Master['Cabin'].isnull().sum())*100)\/(len(Train_Master))\nper_nan_cabin_test  = ((Test_Master['Cabin'].isnull().sum())*100)\/(len(Test_Master))\n\nprint('% of missing rows in training set: {0:0.2f} \\n'.format(per_nan_cabin_train))\nprint('% of missing  rows  in  test  set: {0:0.2f} \\n'.format(per_nan_cabin_test))","f49ee0ca":"Train_Master.drop('Cabin', axis=1, inplace=True)\nTest_Master.drop('Cabin', axis=1, inplace=True)","15cb9293":"fig, ax  = plt.subplots(1,2)\nfig.set_figheight(6)\nfig.set_figwidth(12)\nsns.heatmap(data=Train_Master.isnull(),cbar=False,yticklabels=False,cmap='cividis', ax=ax[0])\nax[0].set_title('Data Missingness for Training Data',fontsize=16)\nsns.heatmap(data=Test_Master.isnull(),cbar=False,yticklabels=False, cmap='cividis',ax=ax[1])\nax[1].set_title('Data Missingness for Test Data',fontsize=16)\nplt.show()","8b1f13a4":"fig, ax = plt.subplots(1,2)\nfig.set_figwidth(12)\n\nsns.countplot(x='Pclass',data=Train_Master,ax=ax[0])\nsns.countplot(x='Pclass',data=Train_Master, hue='Survived',palette=('red','green'),ax=ax[1])\nax[0].set_title('Passenger Count by Pclass')\nax[1].set_title('Survival Distribution of by Pclass')\n\nsns.factorplot(x='Pclass',y='Survived',hue='Sex',col='Embarked',data=Train_Master)\nplt.show()","c90d1dd4":"fig, ax = plt.subplots(1,2)\nfig.set_figwidth(12)\nsns.countplot(x='Sex',data=Train_Master, hue='Survived',palette=('red','green'),ax=ax[1])\nax[1].set_title('Survival Distribution of Male and Female')\n\nsns.countplot(x='Sex',data=Train_Master,ax=ax[0])\nax[0].set_title('Total Number of Male and Female of Titanic')\n\nplt.show()","37103094":"fig, ax = plt.subplots(1,2)\nfig.set_figwidth(12)\nsns.countplot(x='Embarked', hue='Survived',data=Train_Master,palette=('red','green'),ax=ax[1])\nax[0].set_title('Total No Embarked Passengers from given Location')\nsns.countplot(x='Embarked',data=Train_Master,ax=ax[0])\nax[1].set_title('Survival Distribution as per Embarked Status')\nplt.show()","1302a2c1":"Train_Master = pd.get_dummies(Train_Master, columns=['Sex','Pclass', 'Embarked'], drop_first=True)\nTrain_Master.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n\ntest_ids = Test_Master.loc[:, 'PassengerId']\nTest_Master = pd.get_dummies(Test_Master, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\nTest_Master.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)","7c129ad8":"Train_Master.head()","bafa9229":"Train_Master['FamilySize'] = Train_Master['SibSp'] + Train_Master['Parch']\nTest_Master['FamilySize'] = Test_Master['SibSp'] + Test_Master['Parch']","90c0fbec":"Train_Master.drop(columns=['SibSp','Parch'], axis=1, inplace =True)\nTest_Master.drop(columns=['SibSp','Parch'], axis=1, inplace =True)","3cd31feb":"y = Train_Master.Survived\nX = Train_Master.drop('Survived', axis=1)","fa6f9f24":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state =1,test_size=0.30)","0b60f2a7":"ML_102_DTC = DecisionTreeClassifier(random_state=1)\nML_102_DTC.fit(train_X, train_y)\npred_ML_102_DTC = ML_102_DTC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_102_DTC))\nprint(classification_report(val_y, pred_ML_102_DTC))\nprint(accuracy_score(val_y, pred_ML_102_DTC))","3c87594e":"ML_102_RFC = RandomForestClassifier(random_state=1,n_estimators =300)\nML_102_RFC.fit(train_X, train_y)\npred_ML_102_RFC = ML_102_RFC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_102_RFC))\nprint(classification_report(val_y, pred_ML_102_RFC))\nprint(accuracy_score(val_y, pred_ML_102_RFC))","fe880d43":"from sklearn.neighbors import KNeighborsClassifier\nML_102_KNN = KNeighborsClassifier(n_neighbors = 3)\nML_102_KNN.fit(train_X, train_y)\npred_ML_102_KNN = ML_102_KNN.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_102_KNN))\nprint(classification_report(val_y, pred_ML_102_KNN))\nprint(accuracy_score(val_y, pred_ML_102_KNN))","64729546":"ML_102_SVC = SVC(probability=True,random_state=1)\nML_102_SVC.fit(train_X, train_y)\npred_ML_102_SVC = ML_102_SVC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_102_SVC))\nprint(classification_report(val_y, pred_ML_102_SVC))\nprint(accuracy_score(val_y, pred_ML_102_SVC))","afd39cfe":"from sklearn.grid_search import GridSearchCV\nparam_grid = {'C':[0.1,1,10,100,1000,10000],'gamma':[1,0.1,0.01,0.001,0.0001,0.00001]}\ngrid = GridSearchCV(SVC(), param_grid,verbose=3)\ngrid.fit(train_X,train_y)","7d58a42a":"grid.best_params_","c968d26b":"grid.best_estimator_","e53ed8e2":"pred_ML_102_SVC_grid = grid.predict(val_X)\nprint(confusion_matrix(val_y,pred_ML_102_SVC_grid))\nprint(classification_report(val_y, pred_ML_102_SVC_grid))\nprint(accuracy_score(val_y, pred_ML_102_SVC_grid))","e2135425":"## Submitting Results of RFC....\n\n#pred_ML_102_sub = grid.predict(Test_Master)\n\n#my_submission = pd.DataFrame(data={'PassengerId':test_ids, 'Survived':pred_ML_102_sub})\n\n#print(my_submission['Survived'].value_counts())\n\n#Export Results to CSV\n#my_submission.to_csv('submission.csv', index = False)","343f07aa":"#Import Data\nTrain_Master = pd.read_csv('..\/input\/train.csv')\nTest_Master = pd.read_csv('..\/input\/test.csv')\n\n#Creating temperory dataset by appending Test set to Training Set\n#https:\/\/pandas.pydata.org\/pandas-docs\/stable\/merging.html\nTitanic_Master = Train_Master.append(Test_Master)\n\n#Impute Age - helper function\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass ==1:\n            return Titanic_Master[Titanic_Master.Pclass==1]['Age'].median()\n        elif Pclass ==2:\n            return Titanic_Master[Titanic_Master.Pclass==2]['Age'].median()\n        elif Pclass ==3:\n            return Titanic_Master[Titanic_Master.Pclass==3]['Age'].median()\n    else:\n        return Age\n#Imputing Age\n#Train_Master['Age'] = Train_Master[['Age','Pclass']].apply(impute_age,axis=1)\n#Test_Master['Age'] = Test_Master[['Age','Pclass']].apply(impute_age,axis=1)\n# commenting code for Age imputation, since later stages it was found that Age can be well estimated from Title of Person.\n#Impute Embark\nTrain_Master['Embarked'] = Train_Master['Embarked'].fillna('S')\n#Impute Fare\nTest_Master['Fare'] = Test_Master['Fare'].fillna(Titanic_Master.Fare.median())","f5d2db8a":"fig, ax  = plt.subplots(1,2)\nfig.set_figheight(6)\nfig.set_figwidth(12)\nsns.heatmap(data=Train_Master.isnull(),cbar=False,yticklabels=False,cmap='cividis', ax=ax[0])\nax[0].set_title('Data Missingness for Training Data',fontsize=16)\nsns.heatmap(data=Test_Master.isnull(),cbar=False,yticklabels=False, cmap='cividis',ax=ax[1])\nax[1].set_title('Data Missingness for Test Data',fontsize=16)\nplt.show()","1a2f8617":"Train_Master['Name'].sample(3)","257a0599":"#How to split name?\n'Strange, Dr. Steven (Doctor Strage)'.split(sep=',')[1].split(sep='.')[0]","0c69be05":"#However Train_Master['Name'] is series. Working text split for Series\n#https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.str.split.html\n\n#Train_Master['Name'].str.split(pat=\",\",expand=True)[1].str.split(pat='.',expand=True)[0]\n#Lets store title in new column called 'Title'\n\nTrain_Master['Title'] =Train_Master['Name'].str.split(pat=\",\",expand=True)[1].str.split(pat='.',expand=True)[0].str.strip()\nTest_Master['Title'] =Test_Master['Name'].str.split(pat=\",\",expand=True)[1].str.split(pat='.',expand=True)[0].str.strip()","30b4477c":"Titanic_Master['Title'] =Titanic_Master['Name'].str.split(pat=\",\",expand=True)[1].str.split(pat='.',expand=True)[0].str.strip()\nTitanic_Master.head()","ec39add5":"#Objective is to find out if there is relation between Title vs \"Social Status & Age of Person\".\nfig, ax  = plt.subplots(2,1)\nfig.set_figheight(8)\nfig.set_figwidth(15)\nfig.tight_layout()\nsns.countplot(x='Title',data=Titanic_Master,ax=ax[0])\nsns.boxplot(x='Title',y ='Age', data=Titanic_Master,ax=ax[1])\nplt.show()","767976b6":"print(Titanic_Master.Title.value_counts())\nprint(Titanic_Master.Title.unique())","53d0ecfc":"#Lets create mapping for the titles \nTitle_dict = {\n  'Mr': 'Mr',\n  'Mrs': 'Mrs',\n  'Miss': 'Miss',\n  'Master': 'Master',\n  'Don': 'Others_M',\n  'Rev': 'Rev',\n  'Dr': 'Dr',\n  'Mme': 'Others_F',\n  'Ms': 'Others_F',\n  'Major': 'Others_M',\n  'Lady': 'Others_F',\n  'Sir': 'Others_M',\n  'Mlle': 'Others_F',\n  'Col': 'Others_M',\n  'Capt': 'Others_M',\n  'the Countess': 'Others_F',\n  'Jonkheer': 'Others_M',\n  'Dona': 'Others_F',\n}","aa611e89":"#Updating Titles as per defined mapping\nTrain_Master['Title'] = Train_Master['Title'].map(Title_dict)\nTest_Master['Title'] = Test_Master['Title'].map(Title_dict)\nTitanic_Master['Title'] = Titanic_Master['Title'].map(Title_dict)","0c569eb7":"fig, ax  = plt.subplots(2,1)\nfig.set_figheight(8)\nfig.set_figwidth(12)\nfig.tight_layout()\nsns.countplot(x='Title',data=Titanic_Master,ax=ax[0])\nsns.boxplot(x='Title',y ='Age', data=Titanic_Master,ax=ax[1])\nplt.show()","2bf7bf62":"#Train_Master = pd.get_dummies(Train_Master, columns=['Title'], drop_first=True)\n#Test_Master = pd.get_dummies(Test_Master, columns=['Title'], drop_first=True)\n#Train_Master.head()\n# Skipping this part since we may need 'Title' to derive other features like 'Age'","1830efbe":"Titanic_Master.groupby(['Title'])['Age'].median()","8cce62f0":"titles = ['Dr', 'Mr', 'Master','Miss','Mrs','Others_F','Others_M','Rev']\ntitles","1e54deb5":"for title in titles: #['Dr', 'Master','Miss','Mrs','Others_F','Others_M']\n    Test_Master.loc[(Test_Master['Title'] == title) & (Test_Master['Age'].isnull()), 'Age'] = Titanic_Master[Titanic_Master['Title'] == title]['Age'].median()\n    Train_Master.loc[(Train_Master['Title'] == title) & (Train_Master['Age'].isnull()) , 'Age'] = Titanic_Master[Titanic_Master['Title'] == title]['Age'].median()\nprint('---'*25)","53700dd7":"# Distribution of Age\nsns.distplot(Titanic_Master.Age.dropna(), bins=50)","994c0b24":"#Till this point we have gained great insight over data, we can logically decide bins.\n# Min_age in our data = 0.92\n# Max_age in our data = 80\n \n# We have also seen there is relation between <code>Age<\/code> and <code>Title<\/code>\n#Titanic_Master.dropna().groupby(['Title'])['Age'].describe()\n#------------------------------------------------------------------------------------------\nTitanic_Master.dropna()['Age'].describe()","52cfde4d":"# mapping Age to bin \n#0  = <24\n#1  = >24 and  < 36\n#2  = >36 and <47\n#3  = >47\nTrain_Master.loc[ Train_Master['Age'] <= 24, 'Age'] = 0\nTrain_Master.loc[(Train_Master['Age'] > 24) & (Train_Master['Age'] <= 36), 'Age'] = 1\nTrain_Master.loc[(Train_Master['Age'] > 36) & (Train_Master['Age'] <= 47), 'Age'] = 2\nTrain_Master.loc[ Train_Master['Age'] > 47 , 'Age'] = 3\nTrain_Master['Age'] = Train_Master['Age'].astype(int)\n\nTest_Master.loc[ Test_Master['Age'] <= 24, 'Age'] = 0\nTest_Master.loc[(Test_Master['Age'] > 24) & (Test_Master['Age'] <= 36), 'Age'] = 1\nTest_Master.loc[(Test_Master['Age'] > 36) & (Test_Master['Age'] <= 47), 'Age'] = 2\nTest_Master.loc[ Test_Master['Age'] > 47 , 'Age'] = 3\nTest_Master['Age'] = Test_Master['Age'].astype(int)\n","dfb02ceb":"Train_Master = pd.get_dummies(Train_Master, columns=['Title'])\nTest_Master = pd.get_dummies(Test_Master, columns=['Title'])\nTrain_Master = pd.get_dummies(Train_Master, columns=['Age'])\nTest_Master = pd.get_dummies(Test_Master, columns=['Age'])  #, drop_first=True\nTest_Master.head()","135c5b87":"Titanic_Master = Train_Master.append(Test_Master)\nTitanic_Master.reset_index(inplace=True, drop=True)\nTitanic_Master.Fare.isnull().any()","bd1839a3":"\nmedian = np.median(Titanic_Master.Fare)\nupper_quartile = np.percentile(Titanic_Master.Fare, 75)\nlower_quartile = np.percentile(Titanic_Master.Fare, 25)\n\niqr = upper_quartile - lower_quartile\nupper_whisker = Titanic_Master['Fare'][Titanic_Master['Fare']<=upper_quartile+1.5*iqr].max()\nlower_whisker = Titanic_Master['Fare'][Titanic_Master['Fare']>=lower_quartile-1.5*iqr].min()\n","9a109de7":"fig, ax = plt.subplots(1,2)\nfig.set_figheight(6)\nfig.set_figwidth(16)\nsns.boxplot(y='Fare',data=Titanic_Master, ax=ax[0], color='green')\nsns.distplot(Titanic_Master.Fare, bins=100,ax=ax[1])\nplt.sca(ax[1])\nplt.xticks(np.arange(min(Titanic_Master.Fare), max(Titanic_Master.Fare), 50))\nplt.sca(ax[0])\nplt.yticks(np.arange(min(Titanic_Master.Fare), max(Titanic_Master.Fare), 50))\nfig.tight_layout()\nplt.axhline(y=upper_quartile,linewidth=2, color='b', linestyle='--')\nplt.axhline(y=upper_whisker,linewidth=2, color='b', linestyle='--')\nax[0].annotate('Upper Whisker', xy=(0,upper_whisker), xytext=(0,upper_whisker))\nplt.show()","4207f557":"fig, ax = plt.subplots()\nfig.set_figheight(4)\nfig.set_figwidth(8)\nsns.boxplot(y='Fare',data=Titanic_Master[Titanic_Master.Fare<upper_whisker], ax=ax, color='green')\nplt.axhline(y=53,linewidth=2, color='b', linestyle='--')\nplt.show()\nTitanic_Master[Titanic_Master.Fare<=53]['Fare'].describe()","06f83262":"print('Total No. of  Passengers , where Fare of individual is more than 50 is {}'.format(Titanic_Master[Titanic_Master.Fare>50]['Fare'].count()))\nprint('Total Fare paid by Passengers , where Fare of individual is more than 50 is {}'.format(Titanic_Master[Titanic_Master.Fare>50]['Fare'].sum()))\nprint('\\n')\nprint('Total No. of  Passengers , where Fare of individual is less  than 50 is {}'.format(Titanic_Master[Titanic_Master.Fare<=50]['Fare'].count()))\nprint('Total Fare paid by Passengers , where Fare of individual is less than 50 is {}'.format(Titanic_Master[Titanic_Master.Fare<=50]['Fare'].sum()))","b1da28a6":"Train_Master.loc[ Train_Master['Fare'] == 0.0 , 'Fare'] = 0\nTrain_Master.loc[(Train_Master['Fare'] > 0.0) & (Train_Master['Fare'] <= 7.85), 'Fare'] = 1\nTrain_Master.loc[(Train_Master['Fare'] > 7.85) & (Train_Master['Fare'] <= 12.2), 'Fare'] = 2\nTrain_Master.loc[(Train_Master['Fare'] > 12.2) & (Train_Master['Fare'] <= 24), 'Fare'] = 3\nTrain_Master.loc[(Train_Master['Fare'] > 24) & (Train_Master['Fare'] <= 53), 'Fare'] = 4\nTrain_Master.loc[ Train_Master['Fare'] > 53, 'Fare'] = 5\nTrain_Master['Fare'] = Train_Master['Fare'].astype(int)\n\nTest_Master.loc[ Test_Master['Fare'] == 0.0 , 'Fare'] = 0\nTest_Master.loc[(Test_Master['Fare'] > 0.0) & (Test_Master['Fare'] <= 7.85), 'Fare'] = 1\nTest_Master.loc[(Test_Master['Fare'] > 7.85) & (Test_Master['Fare'] <= 12.2), 'Fare'] = 2\nTest_Master.loc[(Test_Master['Fare'] > 12.2) & (Test_Master['Fare'] <= 24), 'Fare'] = 3\nTest_Master.loc[(Test_Master['Fare'] > 24) & (Test_Master['Fare'] <= 53), 'Fare'] = 4\nTest_Master.loc[ Test_Master['Fare'] > 53, 'Fare'] = 5\nTest_Master['Fare'] = Test_Master['Fare'].astype(int)","5d5c27df":"Train_Master = pd.get_dummies(Train_Master, columns=['Fare'], drop_first=True)\nTest_Master = pd.get_dummies(Test_Master, columns=['Fare'], drop_first=True)\nTest_Master.head()","946feb7f":"Titanic_Master = Train_Master.append(Test_Master)\nTitanic_Master.reset_index(inplace=True, drop=True)","be88ca0b":"Titanic_Master[['Name','Ticket', 'Pclass', 'Cabin']].head()","67d9beb4":"Cabin_t = []\nPclass_t = []\n\n# Split ticket for both type of ticket numbers as mentioned earlier.\n# We will create Cabin_t for text extracted from Ticket No\n# And Pclass_t for first digit of ticket number.\nfor i in range(len(Titanic_Master.Ticket.str.split(\" \", n = 1))):\n        if len(Titanic_Master.Ticket.str.split(\" \", n = 1)[i]) == 1:\n            Pclass_t.append(Titanic_Master.Ticket.str.slice(0,1)[i])\n            #Cabin_t.append(None)\n            Cabin_t.append('U')\n        elif len(Titanic_Master.Ticket.str.split(\" \", n = 1)[i]) == 2:\n            Pclass_t.append(Titanic_Master.Ticket.str.split(\" \", n = 1)[i][1][0])\n            #Cabin_t.append(Titanic_Master.Ticket.str.split(\" \", n = 1)[i][0][0])\n            Cabin_t.append(Titanic_Master.Ticket.str.split(\" \", n = 1)[i][0].replace( '.' , '' ).replace( '\/' , '' ))","360e0a79":"Titanic_Master['Cabin_t'] = Cabin_t\nTitanic_Master['Pclass_t'] = Pclass_t\nTitanic_Master['Cabin_t']= Titanic_Master['Cabin_t'].str.replace('\\d+', '')","d89ed0b6":"Titanic_Master[['Ticket', 'Cabin','Cabin_t','Pclass', 'Pclass_t']].sample(10)","13610526":"#Titanic_Master[(~Titanic_Master['Cabin'].isna()) & (~Titanic_Master['Cabin_t'].isna())][['Cabin','Ticket','Cabin_t','Pclass','Embarked']]\nTitanic_Master.Cabin_t.unique()","7eeec938":"Titanic_Master['Pclass'] = Titanic_Master['Pclass'].astype(str)\nTitanic_Master['Pclass_t'] = Titanic_Master['Pclass_t'].astype(str)\nfig, ax = plt.subplots(2,2)\nfig.tight_layout()\nfig.set_figheight(8)\nfig.set_figwidth(12)\nsns.countplot('Pclass_t',data=Titanic_Master[Titanic_Master.Pclass == Titanic_Master.Pclass_t], ax=ax[0,0])\nax[0,0].set_title('Pclas == Pclass_t')\n\nsns.scatterplot('Pclass', 'Pclass_t',data=Titanic_Master[Titanic_Master.Pclass == Titanic_Master.Pclass_t], ax=ax[0,1])\nsns.scatterplot('Pclass', 'Pclass_t', data=Titanic_Master[Titanic_Master.Pclass != Titanic_Master.Pclass_t],ax=ax[1,1])\nsns.countplot('Pclass_t',data=Titanic_Master[Titanic_Master.Pclass != Titanic_Master.Pclass_t], ax=ax[1,0])\nax[1,0].set_title('Pclas != Pclass_t')\nplt.show()","39f5b6e1":"Train_Master['FamilySize'] = Train_Master['SibSp'] + Train_Master['Parch'] + 1\nTest_Master['FamilySize'] = Test_Master['SibSp'] + Test_Master['Parch'] + 1\nTitanic_Master['FamilySize'] = Titanic_Master['SibSp'] + Titanic_Master['Parch'] + 1","7d200808":"sns.countplot(x='FamilySize', data=Titanic_Master)\nplt.show()","dc0ced40":"# 1     : Travelling Alone\n# 2,3,4 : Small Family\n# >5    : Large Family\n#{'1': 1, '2':'2', '3':'2', '4':'2', '5':'3', '6':'3', '7':'3', '8':'3', '11':'3'}\nTitanic_Master['FamilySize'] = Titanic_Master['FamilySize'].map({1:'1',2:'2',3:'2',4:'2',5:'3',6:'3',7:'3',8:'3',11:'3'})\nTrain_Master['FamilySize'] = Train_Master['FamilySize'].map({1:'1',2:'2',3:'2',4:'2',5:'3',6:'3',7:'3',8:'3',11:'3'})\nTest_Master['FamilySize'] = Test_Master['FamilySize'].map({1:'1',2:'2',3:'2',4:'2',5:'3',6:'3',7:'3',8:'3',11:'3'})","b074ba86":"Train_Master = pd.get_dummies(Train_Master, columns=['FamilySize']) #drop_first=True\nTest_Master = pd.get_dummies(Test_Master, columns=['FamilySize'])","0b0d9c9a":"Train_Master = pd.get_dummies(Train_Master, columns=['Sex'], drop_first=True)\nTest_Master = pd.get_dummies(Test_Master, columns=['Sex'], drop_first=True)\n\nTrain_Master = pd.get_dummies(Train_Master, columns=['Pclass'], drop_first=True)\nTest_Master = pd.get_dummies(Test_Master, columns=['Pclass'], drop_first=True)\n\nTrain_Master = pd.get_dummies(Train_Master, columns=['Embarked'], drop_first=True)\nTest_Master = pd.get_dummies(Test_Master, columns=['Embarked'], drop_first=True)","70a65542":"Train_Master['Cabin'].fillna('U', inplace=True)\nTest_Master['Cabin'].fillna('U', inplace=True)\n\nTrain_Master['Cabin'] = Train_Master['Cabin'].str[0]\nTest_Master['Cabin'] = Test_Master['Cabin'].str[0]\n\nTrain_Master = pd.get_dummies(Train_Master, columns=['Cabin']) #, drop_first=True\nTest_Master = pd.get_dummies(Test_Master, columns=['Cabin'])\n\nTrain_Master.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket'], inplace=True)\nTest_Master.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket'],inplace=True)\n#Train_Master.head()","8409a1de":"#Train_Master.head()\nTrain_Master.drop(columns=['Title_Rev', 'FamilySize_3', 'Cabin_U','Age_0'], inplace=True)\nTest_Master.drop(columns=['Title_Rev', 'FamilySize_3', 'Cabin_U','Age_0'],inplace=True)","9a4748de":"Train_Master.head()","f88abd8d":"fig, ax = plt.subplots()\nfig.tight_layout()\nfig.set_figheight(20)\nfig.set_figwidth(20)\nsns.heatmap(Train_Master.corr(), cbar=False,annot=True, ax=ax,linewidths=1, linecolor='black')\nplt.show()","44db27c4":"Corr = Train_Master.corr().iloc[0].to_frame().reset_index().rename(columns={\"index\": \"Feature\", \"Survived\": \"Corr_Coeff\"})\nfig, ax = plt.subplots()\nfig.tight_layout()\nfig.set_figheight(6)\nfig.set_figwidth(20)\ng= sns.barplot('Feature','Corr_Coeff', data=Corr,ax=ax,palette='rainbow')\ng.set_xticklabels(labels=xlabels, rotation=45)\nplt.show()","a4730802":"y = Train_Master.Survived\nX = Train_Master.drop('Survived', axis=1)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state =1,test_size=0.30)\n\nML_103_RFC = RandomForestClassifier(random_state=1,n_estimators =200,max_depth=10)\nML_103_RFC.fit(train_X, train_y)\npred_ML_103_RFC = ML_103_RFC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_103_RFC))\nprint(classification_report(val_y, pred_ML_103_RFC))\nprint(accuracy_score(val_y, pred_ML_103_RFC))\n\nTest_Master['Cabin_T'] = 0\npred_ML_103_sub = ML_103_RFC.predict(Test_Master)\nmy_submission = pd.DataFrame(data={'PassengerId':test_ids, 'Survived':pred_ML_103_sub})\n\nprint(my_submission['Survived'].value_counts())\n\n#Export Results to CSV\nmy_submission.to_csv('submission.csv', index = False)","1b36ae63":"ML_103_SVC = SVC(probability=True,random_state=1)\nML_103_SVC.fit(train_X, train_y)\npred_ML_103_SVC = ML_103_SVC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_103_SVC))\nprint(classification_report(val_y, pred_ML_103_SVC))\nprint(accuracy_score(val_y, pred_ML_103_SVC))\n\nfrom sklearn.grid_search import GridSearchCV\nparam_grid = {'C':[0.1,1,10,100,1000],'gamma':[1,0.1,0.01,0.001,0.0001]}\ngrid = GridSearchCV(SVC(), param_grid,verbose=3)\ngrid.fit(train_X,train_y)\n\npred_ML_103_SVC_grid = grid.predict(val_X)\nprint(confusion_matrix(val_y,pred_ML_103_SVC_grid))\nprint(classification_report(val_y, pred_ML_103_SVC_grid))\nprint(accuracy_score(val_y, pred_ML_103_SVC_grid))\n\n##===========================================================\nfrom sklearn.ensemble import GradientBoostingClassifier\nML_103_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.95, max_features=15, max_depth = 2, random_state = 0)\nML_103_GBC.fit(train_X, train_y)\npred_ML_103_GBC = ML_103_GBC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_103_GBC))\nprint(classification_report(val_y, pred_ML_103_GBC))\nprint(accuracy_score(val_y, pred_ML_103_GBC))\n##==================================================\nprint('BaggingClassifier---')\nfrom sklearn.ensemble import BaggingClassifier\nML_103_BC = BaggingClassifier(max_samples= 0.25, n_estimators= 300, max_features=10)\nML_103_BC.fit(train_X, train_y)\npred_ML_103_BC = ML_103_BC.predict(val_X)\n\nprint(confusion_matrix(val_y,pred_ML_103_BC))\nprint(classification_report(val_y, pred_ML_103_BC))\nprint(accuracy_score(val_y, pred_ML_103_BC))\nprint('*-*'*25)\n##==================================================\n\nprint('Submit Results for Best working model.')\npred_ML_103_sub = ML_103_RFC.predict(Test_Master)\nmy_submission = pd.DataFrame(data={'PassengerId':test_ids, 'Survived':pred_ML_103_sub})\n\nprint(my_submission['Survived'].value_counts())\n\n#Export Results to CSV\nmy_submission.to_csv('submission.csv', index = False)","276dc379":"**Current Accuracy : 65% & LeaderBoard Standing : Top 96% . ** ","17633169":"**Those are some crazy numbers, just 240 people paid almost 1.5 times total Fare compared to other 1069 people**    \nGrouping by Fare:\n\n    Group - 1 : Fare > 53\n    Group - 2 : <=53 and > 24\n    Group - 3 : <=24 and > 12.2\n    Group - 4 : <=12.2 and > 7.85\n    Group - 5 : <= 7.85\n   \nLet's map each passengers <code>Fare<\/code> to respective group\/bin as we did earlier for <code>Age<\/code>","627ce4f2":"**Training Data:**\nAge, Cabin, Embarked are missing\n\n**Test Data: **Age, Fare and Cabin are missing.\n\nThere seem to be huge percentage of data missing from Cabin column.","06f4994a":"## Predictive Modeling","51a2e285":"Cabin_t is not much useful as we expected. However, there is information hidden with this variable.   \n\" SOTONOQ\"  , \"CASOTON\", \"STONOQ\"  , \"SOTONO\" these all relate to Southampton. Common know abbreviation for Southampton is SOTON.\n \n \"SCParis\" must relate to Paris.\n \n But can we process this information in way to get useful output???","f42da978":"Both of above values are close to each other. I will choose to go with median value of Fare.","aeecb3ab":"## Step-2 : Know Your Data\n**Exploring our data sets:**","9cfdadb3":"After going through different MOOCs and lots of  online literature for Machine Learning, I decided to create this kernel.  I will go step by step through developing a prediction model for famous Titanic Dataset. Starting from very basic, that is taught by almost every online machine learning course\/tutorial(s).\n\nThere are many kernels on Kaggle created by experts in the field, but as someone new to this field initially I was overwhelmed going through them. That's why I decided to go bit by bit.\nThis kernel is divided into 3 major sections as below. \n\n<a href=\"#Machine-Learning-101---Beginner:-Implementing-Textbook-Lesson\" target=\"_self\"><span class=\"toc-section-number\">1<\/span> \"Machine Learning 101 - Beginner: Implementing Textbook Lesson\"<\/a>\n\n<a href=\"#MachineLearning-102---Intermediate-:-Working-on-Feature-Set\" target=\"_self\"><span class=\"toc-section-number\">2<\/span> \"MachineLearning 102 - Intermediate : Working on Feature Set\"<\/a>\n\n<a href=\"#Machine-Learning-103--Advanced:-Aim-Top-10%-on-Leaderboard \" target=\"_self\"><span class=\"toc-section-number\">3<\/span> \"Machine Learning 103- Advanced: Aim Top 10% on Leaderboard\"<\/a>\n","57908f08":"Some of these titles are very rarely occuring. Those can be put in seperate category altogether.     \nAlso it can be seen that for a given <code>Title<\/code> ,<code>Age<\/code> spectrum is well defined.    \nFor example, Master is title for children of age range around 0 to 16 years.\nNow we know that Null values in <code>Age<\/code> can be imputed by predicting those from <code>Title <\/code>of Person.","330bb732":"**Available techniques to ressolve categorical variable problem**\n* Replacing values\n* Encoding labels\n* One-Hot encoding\n* Binary encoding\n* Backward difference encoding\n* Miscellaneous features\n","9b80a621":"<code>SVC<\/code> seems to be working best for now. I have improved accuracy from 65 to 76.86 % by doing some simple manipulations with the feature set.\nStill there is lot space for improvement, Features like <code> 'Name', 'Cabin', 'Ticket' <\/code>can be used for optimization with some advanced feature engineering. ","e26cadc4":"**RandomForestClassifier**","ca3d4183":"# MachineLearning 102 - Intermediate : Working on Feature Set\n\n#### Want to know more about Titanic\nI found this really cool website.\n\nhttps:\/\/www.encyclopedia-titanica.org\/\n\nhttps:\/\/www.encyclopedia-titanica.org\/titanic-deckplans\/profile.html\n","dacb2fc6":"Importing Libraries","2080711d":"**Rarely Occuring  Title & Respective Gender: **\n<html>\n\t<head>\n\t\t<meta charset=\"UTF-8\">\n\t\t\t<title>Excel To HTML using codebeautify.org<\/title>\n\t\t<\/head>\n\t\t<body>\n\t\t\t<b>\n\t\t\t<\/b>\n\t\t\t<hr>\n\t\t\t\t<table cellspacing=0 border=1>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Title<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Gender<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Mlle <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Female<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Ms <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Female<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Major <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Male<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Dona <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Female<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>the Countess <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Female<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Sir <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Male<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Lady <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Female<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Don <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Male<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Capt <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Male<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Jonkheer <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Male<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Mme <\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Female<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t<\/table>\n\t\t\t\t<hr>\n\t\t\t\t<\/body>\n\t\t\t<\/html>","1fa36eac":"Looking at missing amount of data from 'Cabin' ... Lets drop column 'Cabin'","fe7cad6b":"Now we can drop <code>SibSp<\/code> and <code>Parch<\/code>.","ee9ccae1":"Min Fare is **Zero** ... ** Why? ** Lets have look into these passengers data.","357bff12":"Since, the column <code>Cabin<\/code> has 687\/891 values missing. Lets drop this column. However column <code>Age<\/code> is crucial for our analysis we need to proxy missing values by some method.","bb3c8c0c":"## Working with missing data","7d945902":"### 2. Age","99dc6bee":"## Step-6 : Submitting Result\nLets fit <code>RandomForestClassifer<\/code> results for Test data and submit.","ddc849c3":"# Machine Learning 101 - Beginner: Implementing Textbook Lesson","4cc496c2":"**3. Fare**\n\nAnother continuous  variable in our data is <code>Fare<\/code>.","2aa511a0":"## Step-5 : Fit Your Model, Predict & Know accuracy on Validation Set\nSince this is classification problem , Start by building decision tree model for prediction.","fc4b583a":"Looking at dependancies of <code>Age<\/code>, I have decided to impute null values with <code>Median<\/code> values for each <code>Pclass<\/code>","aebaeba9":"**5. SibSp and ParCh**","e4de141e":"Now we can treat Age as Categorical feature. Lets to variable encoding for age as we did earlier for other categorical variables.","f177a0ee":"**KNeighborsClassifier**","d62dff2a":"### Embarked column in training data","ddd87eb6":"Final Validation for Null values","0080b040":"We have reached the point there are no more columns which need preprocessing.\nLet's once more analyze correlation matrix for our training set.","02a8b26f":"**DecisionTreeClassifier**","d6edb1aa":"Lets try to find out best parameters for SVC using GridSearch","dc2d3ab3":"### Dealing with Cabin data","6a7aa0f0":"Let's first finish some routine tasks before diving deeper. ","6451b7f0":"** Selecting best method of imputation**\n\nLets first check out Age distribution across full dataset.","f09904ef":"## Step-1 : Importing Datasets\nTraining data and Test data\n\nTraining Data: Training Data is labeled data used to train your machine learning algorithms and increase accuracy. ML model learns by finding paterns, relations among various features of training data.\n\nTest Data: Once developed machine learning model needs to be tested in the real world to measure how accurate its predictions are.","7636f090":"Split data into training and validation data","80669557":"### Choosing the right estimator\n![SkLearn](http:\/\/scikit-learn.org\/stable\/_static\/ml_map.png)","d1e1a980":"I thought these people can be the crew of Titanic, however, their name and the title does not specify any such information. \nBut this should be considered in detail.\nWhen looked upon some peculiar titles like **Jonkheer**, it seems that  ticket was complimentary because of his position with the Holland America Line which was part of the International Mercantile Marine. [Jonkheer](https:\/\/www.encyclopedia-titanica.org\/titanic-victim\/johan-george-reuchlin.html) ","9702d67e":"[**One-Hot encoding**](https:\/\/www.datacamp.com\/community\/tutorials\/categorical-data#One-Hot encoding)\n\n   The basic strategy is to convert each category value into a new column and assign a 1 or 0 (True\/False) value to the column. This has the benefit of not weighting a value improperly.\n\n   There are many libraries out there that support one-hot encoding but the simplest one is using <code>pandas.get_dummies()<\/code>method.\n\n   This function is named this way because it creates dummy\/indicator variables (1 or 0). There are mainly three arguments important here, the first one is the DataFrame you want to encode on, second being the columns argument which lets you specify the columns you want to do encoding on, and third, the prefix argument which lets you specify the prefix for the new columns that will be created after  encoding.","07f79d95":"**5. Sex , Pclass and Embarked**","8134b53d":"**4. Ticket**    \nLet's view ticket combined with <code>Pclass<\/code> and <code>Cabin<\/code>.\nUpon first observation, I found for most of the ticket numbers the first digit of Ticket number is same s <code>Pclass<\/code> if that passenger.\nI want to first verify if that's true.\n\nThere are two types of ticket numbers in data.\n\n     A\/5 21171 # Starting with some sort of Class indicator (Maybe)\n     PC 17599\n     113803    #Simple number format ticket numbers.\n    \n    \nIf we can find some correlation between <code>Ticket<\/code> vs <code>Pclass<\/code> & <code>Cabin<\/code>.\n\nThis information might be very useful . Infact we can fill Null values in <code>Cabin<\/code> column , if any relation exists.\n\nLet's breakdown <code>Ticket<\/code> to gain more details.","dfebbb3a":"Missed manipulation of columns <code>SibSp<\/code>, <code>Parch<\/code>.\nLet's create new feature <code>FamilySize<\/code> derived from these two.","717847dd":"There are two types of variables you see in machine learning.\n    1. Continuous\n    2. Discrete (Categorical and Ordinal)\n  \n <code>Age<\/code> here belongs to first type. Machine Learning alsorithms understand second type of variables in a better way compared to first.\n That's why we need be careful while dealing with continuous features. \n \n[** Methods to deal with Continuous Variables**](https:\/\/www.analyticsvidhya.com\/blog\/2015\/11\/8-ways-deal-continuous-variables-predictive-modeling\/)\n\n**Binning The Variable:**\nBinning refers to dividing a list of continuous variables into groups. It is done to discover set of patterns in continuous variables, which are difficult to analyze otherwise. Also, bins are easy to analyze and interpret. But, it also leads to loss of information and loss of power. Once the bins are created, the information gets compressed into groups which later affects the final model. Hence, it is advisable to create small bins initially.\n\nThis would help in minimal loss of information and produces better results. However, There are cases where small bins doesn\u2019t prove to be helpful. In such cases, you must decide for bin size according to your hypothesis.We should consider distribution of data prior to deciding bin size.","37e1bc07":"## Let's do some more EDA","b3f1fec6":"Fare is strongly correlated with 'Pclass' . Lets visulaize how Ticket cost varies for each Passenger Class.","01cdecdf":"**SVC**","4ac2312f":"Even this is not much of progress. But let's stop here for this section. This can be definitely improved if other features like Sex, Embark, Name arec considered for building model.","eb0939ea":"### Age","bfca3b80":"For majority of <code>Ticket<\/code> numbers what we expected holds True. But on same side <code>Pclass_t<\/code> and <code>Pclass<\/code> are not same for almost 25% of Ticket Numbers. However trend follows for almost 1000 Tickets.","bf4c505e":"Survived is Output Variable (Prediction target).\n\nConsider numerical data columns as features. (Simplest way to simulate ML excercise). \nHence, Features will be \n\n    Pclass\t\n    Age\t\n    SibSp\t\n    Parch\t\n    Fare\nSince passangerId is inconsequential for building model. It is just another Index on our data. Hence, exclude it from feature set.","03cab3af":"How to use  <code>Name<\/code>  as feature in prediction model.\nLet's create dummy variables(Feature Encoding) for each of these titles. But for rarely occured values we will mark them all together in one seperate category.","13d86f51":"Now, The plan is to meet each column one by one, setting some serious meetings. Extract as much as information possible. ![image.png](attachment:image.png)","2d6592fe":"That is too much information to consume. Let's just have look at how these variables are impacting 'Survived' variable.","ae9abf10":"___","7a24e499":"Let's first deal with Null values in <code>Age<\/code>.\nSince we have clear idea that given the title passengers age lies in a particular range.\nWill now replace Null age values based on their title.","0ef92804":"## Step-4 : Define Model Parameters\n**Selecting Prediction Target and Feature Set**","68d084d1":"**Lets find out more about Training Set**","35119941":"**Current LeaderBoard Staning : Top 49% . That's great jump. At the end of previous section it was 96%. So looks like so far we are going in right direction.** ","3547d15e":"**Encoding Categorical Variable <code>Title<\/code>**","bb446fca":"'Age' seem to be significantly correlated with <code>'Pclass', 'SibSp', 'Parch'<\/code> and weakly correlated with <code>'Fare'<\/code>. Instead of dealing with<code> 'SipSp'<\/code> and <code> 'Parch' <\/code> individually, it seems logical to create<code> 'FamilySize'<\/code> derived from these two fields and find the correlation with other features.","6e253e7c":"**Updating Kernel...   :)** \n\n**If you like my work so far.. Please Upvote , Share your comments\/opinions...**","08ea3fc2":"**Yes...** This time  we are not dropping <code>Cabin<\/code> column. Lets derive some insights from this column.","6f85aa0a":"### Encoding Categorical Variables ","93d23eb5":"## Step-3 : Clean Your Data\n**Data Missingness:**","b4f99f89":"Looking at outliers in Class-1, it is obvious that mean of Fare is highly affected with these values. ","c36b3576":"** Let's Start with **\n ### 1. Name ","936e6314":"Not so impressive result. Try some other models.","f3c2e339":"We can extract some crucial information about passengers Age and Social Status from Title.\nLets extract unique titles in our dataset","4a5f0d59":"# Machine Learning 103- Advanced: Aim Top 10% on Leaderboard ","fdc1e776":"Finding Social Standing in the Title... \n\nThe word [lady](https:\/\/en.wikipedia.org\/wiki\/Lady) is a term of respect for a woman, the equivalent of gentleman. Once used to describe only women of a high social class or status, now it may refer to any adult woman. ...Source[Wikpedia]","7d04aad9":"### Fare column in Test Data","5dd0fc95":"### Split Train and test Data\n","3dd78595":"Let's check completeness of our Train and Test data","10b3f772":"<html>\n\t<head>\n\t\t<meta charset=\"UTF-8\">\n\t\t\t<title>Excel To HTML using codebeautify.org<\/title>\n\t\t<\/head>\n\t\t<body>\n\t\t\t<b>\n\t\t\t\t<u>What each column in data represents<\/u> \n\t\t\t<\/b>\n\t\t\t<hr>\n\t\t\t\t<table cellspacing=0 border=1>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Column Name<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Description<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Survived<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>1 = Survived , 0 = Died<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Pclass<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Passenger\u2019s class<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Name<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Passenger\u2019s name<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Sex<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Passenger\u2019s sex<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Age<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Passenger\u2019s age<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>SibSp<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Number of siblings\/spouses aboard<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Parch<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Number of parents\/children aboard<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Ticket<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Ticket number<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Fare<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Fare<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Cabin<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Cabin<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td style=min-width:50px>Embarked<\/td>\n\t\t\t\t\t\t<td style=min-width:50px>Port from where passenger embarked<\/td>\n\t\t\t\t\t<\/tr>\n\t\t\t\t<\/table>\n\t\t\t\t<hr>\n\t\t\t\t<\/body>\n\t\t\t<\/html>"}}