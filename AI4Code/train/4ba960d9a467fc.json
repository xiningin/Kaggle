{"cell_type":{"db01f6c3":"code","fe75e447":"code","8cfd2302":"code","e28247fd":"code","99d648fd":"code","814ef63c":"code","3044ddd4":"code","1520cd29":"code","b9666951":"code","ab8982d2":"code","d2155225":"code","aa3898d4":"code","26269c37":"code","99883393":"code","6a4d4904":"code","5b32ada1":"code","323f48ec":"code","8d41ba0a":"code","26be247e":"code","6e72ada7":"code","a5238c67":"code","f7daf8a0":"code","8e9ec297":"markdown","a2e285d8":"markdown","81751609":"markdown"},"source":{"db01f6c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe75e447":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport holoviews as hv\nfrom holoviews import opts\nfrom holoviews.operation.datashader import datashade, bundle_graph\n\nimport networkx as nx","8cfd2302":"hv.extension('bokeh')\n\ndefaults = dict(width=600, height=600, padding=0.1, yaxis=None, xaxis=None, show_frame=False)\nhv.opts.defaults(\n    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))","e28247fd":"people = pd.read_csv('..\/input\/startup-investments\/people.csv', index_col=0)\ndegrees = pd.read_csv('..\/input\/startup-investments\/degrees.csv', index_col=0)\n\ndf = people.merge(degrees, on='object_id')","99d648fd":"#Exploring the Data\n\ndf.info()","814ef63c":"df['full_name'] = df['first_name'].str.cat(df['last_name'],sep=\" \")\n\ndf['institution'] = df['institution'].replace('Harvard Business School' ,'Harvard University')\ndf['institution'] = df['institution'].replace('Stanford University Graduate School of Business' ,'Stanford University')","3044ddd4":"df = df[df['affiliation_name'] != 'Unaffiliated']","1520cd29":"df = df[['object_id', 'full_name', 'birthplace', 'institution', 'degree_type', 'subject', 'graduated_at', 'affiliation_name']]","b9666951":"def count_plots(df, col_count):\n    for i, col in enumerate(df.columns):\n        plt.figure(i, figsize=(10,5))\n        sns.countplot(x=col, data=df, order=pd.value_counts(df[col]).iloc[:col_count].index)\n        plt.xticks(rotation=70)\n        \ncount_columns = df[['institution', 'degree_type', 'subject', 'affiliation_name']]\n\ncount_plots(count_columns, 10)","ab8982d2":"def dual_degree_flag_generator(df):\n    group = df.groupby(['object_id', 'institution', 'graduated_at'], as_index=False)['full_name'].count()\n    group = group[group['full_name'] > 1]\n    object_ids = group['object_id']\n    \n    df['dual_degree_flag'] = np.where(df['object_id'].isin(object_ids), 1, 0)\n    \n    return df\n\ndf = dual_degree_flag_generator(df)","d2155225":"institution_occurance_count = df['institution'].value_counts()\nimportant_institutions = institution_occurance_count[institution_occurance_count >= 5].index.values\ndf = df[df['institution'].isin(important_institutions)]","aa3898d4":"# Dropping the null values\ndf = df.dropna()","26269c37":"df = df[:5000]","99883393":"# Create the graph object\nG = nx.Graph()","6a4d4904":"G = nx.from_pandas_edgelist(df, source='full_name', target='institution', \n                            edge_attr=['degree_type', 'subject'])","5b32ada1":"nx.set_node_attributes(G, pd.Series(df['affiliation_name'].values, index=df['full_name']).to_dict(), 'company')\nnx.set_node_attributes(G, pd.Series(np.nan, index=df['institution']).to_dict(), 'company')","323f48ec":"list(G.edges(data=True))[:5]","8d41ba0a":"list(G.nodes(data=True))[:5]","26be247e":"print(nx.info(G))","6e72ada7":"components = nx.connected_components(G)\nlargest_component = max(components, key=len)\nsubgraph = G.subgraph(largest_component)\ndiameter = nx.diameter(subgraph)\nprint(\"Network diameter of largest component:\", diameter)","a5238c67":"triadic_closure = nx.transitivity(G)\nprint(\"Triadic closure:\", triadic_closure)","f7daf8a0":"simple_graph = hv.Graph.from_networkx(G, positions=nx.spring_layout(G))\nsimple_graph.opts(title=\"Mapping of Network\", node_color='company', cmap='set3', edge_color='degree_type', edge_cmap='set3')","8e9ec297":"Data Exploration","a2e285d8":"1. Graph Analysis and Visualisation","81751609":"Introduction\n\nWhen it comes to Startup ecosystem there is a network of people which corresponds to each other, Let us analyse and Map the network of people involved in the startup ecosystem.\n\n"}}