{"cell_type":{"0ab0d8e1":"code","4fd5edac":"code","71badeb2":"code","4377cf14":"code","dfd763d3":"code","a11016a5":"code","3ce0b067":"code","3d5e9231":"code","00d24920":"code","91d32dfc":"code","9cbb3c7c":"code","868879c5":"code","f8bdec49":"code","ba220bd1":"code","67b8d2f1":"code","813753b4":"code","205386f0":"code","35cda3ef":"code","3843cdd6":"code","7e2424b3":"code","68c3d845":"code","b6cc3d3d":"code","5d7d04c8":"code","d732b185":"code","5d7b611b":"code","dc5a1256":"code","31fcc258":"code","e119d9ce":"code","ed2dfe03":"code","b8ad063e":"code","d0d98443":"code","f773cb13":"code","4bf267ab":"code","157e1773":"code","38cc5126":"code","882d35a5":"code","e08cb95e":"code","4eea18ea":"code","9b030380":"code","21c26702":"code","e1d82b6f":"code","04cca66f":"code","1116064f":"code","949c9249":"code","bf653ac4":"code","3c5c709e":"code","1c4c14db":"code","bde3665c":"code","0194aae8":"code","829df7c2":"code","425fa5a8":"code","5952e83e":"markdown","2a71dfff":"markdown","d544e9e6":"markdown","dc2c6199":"markdown","15e2a6e9":"markdown","23db72bc":"markdown","00e2f0a8":"markdown","48925f2c":"markdown","c2a60aa8":"markdown","b422a8aa":"markdown","0b34ee69":"markdown","411f3dde":"markdown","b0d643b4":"markdown","0b7e737c":"markdown","7d18c82b":"markdown","cc536f79":"markdown","589c867b":"markdown","77719163":"markdown","3d8e4e4b":"markdown","67d7b607":"markdown","afe63c9c":"markdown","dc499a32":"markdown","590919ed":"markdown","77e1e894":"markdown","e4e5908a":"markdown","87b6454a":"markdown","dc3a5642":"markdown","16bb73f4":"markdown","e69fd76e":"markdown","caf87ae6":"markdown","16b58052":"markdown","ca3a0545":"markdown","c7d1b88e":"markdown","36afe507":"markdown","4fd9d450":"markdown","55dfda49":"markdown","0d5f9d16":"markdown"},"source":{"0ab0d8e1":"# Code adapted from https:\/\/www.kaggle.com\/drcapa\/birdclef-2021-starter\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport soundfile as sf\nimport librosa\nimport librosa.display\nimport IPython.display as display\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import VGG19, VGG16, ResNet50\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4fd5edac":"path = '\/kaggle\/input\/birdclef-2021\/'\nos.listdir(path)","71badeb2":"def read_ogg_file(file,path=None):\n    \"\"\" Read ogg audio file and return numpay array and samplerate\"\"\"\n    if path :\n        data, samplerate = sf.read(path+file)\n    else:\n        data, samplerate = sf.read(file)\n    return data, samplerate\n\n\ndef plot_audio_file(data, samplerate,label=None):\n    \"\"\" Plot the audio data\"\"\"\n    \n    sr = samplerate\n    fig = plt.figure(figsize=(8, 4))\n    x = range(len(data))\n    y = data\n    plt.plot(x, y)\n    plt.plot(x, y, color='red')\n    plt.legend(loc='upper center')\n    plt.grid()\n    if label:\n        plt.title(label)\n    plt.show()\n    \ndef plot_spectrogram(data, samplerate,label=None):\n    \"\"\" Plot spectrogram with mel scaling \"\"\"\n    \n    sr = samplerate\n    spectrogram = librosa.feature.melspectrogram(data, sr=sr)\n    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n    librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n    if label:\n        plt.title(label)\n    plt.show()","4377cf14":"train_soundscape_labels = pd.read_csv(path+'train_soundscape_labels.csv')\ntrain_meta_short_audio = pd.read_csv(path+'train_metadata.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","dfd763d3":"print('Number train label samples:', len(train_soundscape_labels))\nprint('Number train meta samples:', len(train_meta_short_audio))\nprint('Number train short audio folders:', len(os.listdir(path+'train_short_audio')))\nprint('Number train audios:', len(os.listdir(path+'train_soundscapes')))\nprint('Number test samples:', len(test_data))","a11016a5":"cpt = sum([len(files) for r, d, files in os.walk(path+'train_short_audio')])\nprint(cpt)","3ce0b067":"os.listdir(path+'train_short_audio\/caltow')[:2]","3d5e9231":"train_soundscape_labels.head()","00d24920":"train_meta_short_audio.head()","91d32dfc":"# Code adapted from https:\/\/www.kaggle.com\/shahules\/bird-watch-complete-eda-fe\n\nimport plotly.graph_objects as go\n\n# Unique eBird codes\nspecies = train_meta_short_audio['primary_label'].value_counts()\n\n# Make bar chart\nfig = go.Figure(data=[go.Bar(y=species.values, x=species.index)],\n                layout=go.Layout(margin=go.layout.Margin(l=0, r=0, b=10, t=50)))\n\n# Show chart\nfig.update_layout(title='Number of traning samples per species')\nfig.show()","9cbb3c7c":"species = train_meta_short_audio['primary_label'].unique()[:5]\nprint(species)","868879c5":"species_sample_filenames = [list(train_meta_short_audio[(train_meta_short_audio.primary_label==each) & (train_meta_short_audio.secondary_labels=='[]')]['filename'])[0] for each in species]\nprint(species_sample_filenames)","f8bdec49":"# for label,filename in zip(species,species_sample_filenames):\n#     print(label)\n#     data, samplerate = sf.read(path+'train_short_audio\/'+label+'\/'+filename)\n#     print(data[:8])\n#     print(samplerate)\n#     plot_audio_file(data, samplerate,label)\n#     plot_spectrogram(data, samplerate,label)","ba220bd1":"# display.Audio(path+'train_short_audio\/'+label+'\/'+filename)","67b8d2f1":"species = 'acafly'\nspecies_sample_filenames = list(train_meta_short_audio[(train_meta_short_audio.primary_label==species) & (train_meta_short_audio.secondary_labels=='[]')]['filename'])[:5]\nprint(species_sample_filenames)","813753b4":"# label = species\n# for filename in species_sample_filenames:\n#     print(label)\n#     data, samplerate = sf.read(path+'train_short_audio\/'+label+'\/'+filename)\n#     print(data[:8])\n#     print(samplerate)\n#     plot_audio_file(data, samplerate,label)\n#     plot_spectrogram(data, samplerate,label)","205386f0":"train_soundscape_labels['audio_id'].unique()","35cda3ef":"train_soundscape_labels.groupby(by=['audio_id']).count()['birds'][:4]","3843cdd6":"print('original label:', train_soundscape_labels.loc[458, 'birds'])\nprint('split into list:', train_soundscape_labels.loc[458, 'birds'].split(' '))","7e2424b3":"labels = []\nfor row in train_soundscape_labels.index:\n    labels.extend(train_soundscape_labels.loc[row, 'birds'].split(' '))\nlabels = list(set(labels))\n\nprint('Number of unique bird labels:', len(labels))","68c3d845":"file = os.listdir(path+'train_soundscapes')[0]\nfile","b6cc3d3d":"data, samplerate = read_ogg_file(file,path+'train_soundscapes\/')\ndata.shape\n","5d7d04c8":"audio_id = file.split('_')[0]\nsite = file.split('_')[1]\nprint('audio_id:', audio_id, ', site:', site)","d732b185":"train_soundscape_labels[(train_soundscape_labels['audio_id']==int(audio_id)) & (train_soundscape_labels['site']==site) & (train_soundscape_labels['birds']!='nocall')]","5d7b611b":"sub_data = data[int(455\/5)*160000:int(460\/5)*160000]","dc5a1256":"plt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(sub_data, sr=samplerate)\nplt.grid()\nplt.show()","31fcc258":"display.Audio(sub_data, rate=samplerate)","e119d9ce":"species = 'caltow'\nfilename = os.listdir(path+ '\/train_short_audio\/' + species + '\/')[0]\nprint(filename)\ndata, samplerate = read_ogg_file(filename,path+'train_short_audio\/'+species+'\/')\nprint(data.shape)\ndisplay.Audio(data, rate=samplerate)","ed2dfe03":"train_meta_short_audio[train_meta_short_audio['filename']==filename]","b8ad063e":"# Removing the ones which have secondary labels and splitting the format into 5 second audio similar to the long soundscape format\n\nprimary_labels = train_meta_short_audio[train_meta_short_audio['secondary_labels']=='[]']['primary_label']\nfilenames = train_meta_short_audio[train_meta_short_audio['secondary_labels']=='[]']['filename']\n\nsplit_audio_ids = pd.DataFrame()\nall_seconds = []\nall_file_names = []\nall_labels = []\ncnt = 0\nfor primary_label,filename in zip(primary_labels,filenames):\n    fname = '\/train_short_audio\/' + primary_label + '\/' + filename\n    full_path = path + fname\n    # Removing this to reduce time taken for running the notebook\n#     audio_file, audio_sr = read_ogg_file(fname,path)\n#     len_audio_file = len(audio_file)\n#     chunk = list(range(0,len_audio_file,160000))\n#     for i in range(0,len(chunk)-1):\n    for i in range(0,1):\n#         audio_file_short = audio_file[chunk[i]:chunk[i+1]]\n        # Check if the 5 second slot has a bird call here & Remove if not valid (Later)\n        seconds = 5 * (i+1)\n        all_seconds.append(seconds)\n        all_file_names.append(fname)\n        all_labels.append(primary_label)\n    cnt = cnt + 1\n    if cnt % 10000 == 0:\n        print(f\"{cnt} done\")\n        \n# display.Audio(audio_file_short, rate=audio_sr)\nsplit_audio_ids = pd.DataFrame({'row_id':[\"\"]*len(all_file_names),'site':[\"\"]*len(all_file_names),'filename':all_file_names,'seconds':all_seconds,'birds':all_labels})\nprint(len(split_audio_ids))\nsplit_audio_ids.head()\n\n","d0d98443":"train_sounscapes_filenames = []\n\nfor row in train_soundscape_labels.iterrows():\n    audio_id = row[1]['audio_id']\n    site = row[1]['site']\n    prefix = str(audio_id)+'_'+ str(site)\n    file_list = [s for s in os.listdir(path+\"\/train_soundscapes\/\") if prefix in s]\n    file = \"\"\n    if len(file_list) > 0:\n        file = file_list[0]\n    train_sounscapes_filenames.append('\/train_soundscapes\/'+file)\n\ntrain_soundscape_cleaned = train_soundscape_labels\ntrain_soundscape_cleaned['filename']=train_sounscapes_filenames\ntrain_soundscape_cleaned = train_soundscape_cleaned[train_soundscape_cleaned['filename'] != \"\"]\ntrain_soundscape_cleaned.head()","f773cb13":"train_soundscapes_all  = pd.concat([train_soundscape_cleaned,split_audio_ids])\ntrain_soundscapes_all['birds_split'] = train_soundscapes_all['birds'].str.split().str.len()\ntrain_soundscapes_all = train_soundscapes_all[train_soundscapes_all['birds_split']==1]\nlabels = pd.get_dummies(train_soundscapes_all['birds'])\n\ntrain_soundscapes_all = pd.concat([train_soundscapes_all,labels],axis=1)\ntrain_soundscapes_all = train_soundscapes_all.reset_index()\nlist_IDs_train, list_IDs_val = train_test_split(list(train_soundscapes_all.index), test_size=0.33, random_state=2021)\nlist_IDs_test = list(samp_subm.index)\ntrain_soundscapes_all.head()","4bf267ab":"data_lenght = 160000\naudio_lenght = 5\nnum_labels = len(list(labels))\n","157e1773":"batch_size = 16\nlen(train_soundscapes_all)","38cc5126":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, data, batch_size,test=False):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.data = data\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n        self.test = test\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)\/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        X = X.reshape((self.batch_size, 100, 1600\/\/2))\n        return X, y\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, data_lenght\/\/2))\n        y = np.zeros((self.batch_size, num_labels))\n        for i, ID in enumerate(list_IDs_temp):\n            file = str(self.data.loc[ID, 'filename'])\n            if file == \"\":\n                # Dummy for missing test audio files\n                audio_file_fft = np.zeros((data_lenght\/\/2))\n            else:              \n                audio_file, audio_sr = read_ogg_file(file,self.path)\n                audio_file = audio_file[int((self.data.loc[ID, 'seconds']-5)\/audio_lenght)*data_lenght:int(self.data.loc[ID, 'seconds']\/audio_lenght)*data_lenght]\n                audio_file_fft = np.abs(np.fft.fft(audio_file)[: len(audio_file)\/\/2])\n                # scale data\n                audio_file_fft = (audio_file_fft-audio_file_fft.mean())\/audio_file_fft.std()\n            X[i, ] = audio_file_fft\n            if not self.test:\n                y[i, ] = self.data.loc[ID,self.data.columns[8:]].values\n        return X, y","882d35a5":"import random\ntrain_sample_size = 100000\nval_sample_size = 10000\n# list_IDs_train_sample = random.sample(list_IDs_train,train_sample_size)\n# list_IDs_val_sample = random.sample(list_IDs_val,val_sample_size)\nlist_IDs_train_sample = list_IDs_train\nlist_IDs_val_sample = list_IDs_val\ntrain_generator = DataGenerator(path, list_IDs_train_sample, train_soundscapes_all, batch_size)\nval_generator = DataGenerator(path, list_IDs_val_sample, train_soundscapes_all, batch_size)\n\n\n","e08cb95e":"epochs = 1\nlernrate = 2e-3","4eea18ea":"model = Sequential()\nmodel.add(Conv1D(64, input_shape=(100, 1600\/\/2,), kernel_size=5, strides=4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(pool_size=(4)))\nmodel.add(Conv1D(64, kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(num_labels, activation='sigmoid'))","9b030380":"model.compile(optimizer = Adam(lr=lernrate),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","21c26702":"model.summary()","e1d82b6f":"history = model.fit_generator(generator=train_generator, validation_data=val_generator, epochs = epochs, workers=4)","04cca66f":"fig, axs = plt.subplots(1, 2, figsize=(16, 4))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","1116064f":"# Code adapted from https:\/\/www.kaggle.com\/stefankahl\/birdclef2021-sample-submission\n\ndef list_files(path):\n    return [os.path.join(path, f) for f in os.listdir(path) if f.rsplit('.', 1)[-1] in ['ogg']]\ntest_audio = list_files(path + 'test_soundscapes')\n\nif len(test_audio) == 0:\n    print(\"Using train files...\")\n    test_audio = list_files(path + 'train_soundscapes')\n    \nprint('{} FILES IN TEST SET.'.format(len(test_audio)))","949c9249":"# Split into 5 second segments\n\ntest_seconds = []\ntest_file_names = []\n\ncnt = 0\n\nfor fname in test_audio:\n    audio_file, audio_sr = read_ogg_file(fname)\n    len_audio_file = len(audio_file)\n    chunk = list(range(0,len_audio_file,160000))\n    for i in range(0,len(chunk)-1):\n        seconds = 5 * (i+1)\n        test_seconds.append(seconds)\n        test_file_names.append(fname)\n    cnt = cnt + 1\n    if cnt % 1000 == 0:\n        print(f\"{cnt} done\")\n        \nsplit_test_audio_ids = pd.DataFrame({'row_id':[\"\"]*len(test_file_names),'site':[\"\"]*len(test_file_names),'audio_id':[\"\"]*len(test_file_names),'filename':test_file_names,'seconds':test_seconds,'birds':[\"\"]*len(test_file_names),'birds_split':[1]*len(test_file_names)})\nprint(len(split_test_audio_ids))\n\nsplit_test_audio_ids = split_test_audio_ids.reset_index()\nsplit_test_audio_ids.head()","bf653ac4":"data_lenght = 160000\naudio_lenght = 5\nnum_labels = len(list(labels))\n\nlist_IDs_test=list(split_test_audio_ids.index)\ntest_generator = DataGenerator(None, list_IDs_test, split_test_audio_ids, batch_size,True)\n","3c5c709e":"y_pred = model.predict_generator(test_generator)","1c4c14db":"y_test = np.where(y_pred > 0.5, 1, 0)","bde3665c":"print(y_test[:10])\nlabel_names = list(labels)\n","0194aae8":"row_ids = []\nlabels = []\nfor i in range(0,len(split_test_audio_ids[:len(y_test)])):\n    row_id = split_test_audio_ids.loc[i,'filename'].split(\"\/\")[-1].split(\"_\")[0]\n    site = split_test_audio_ids.loc[i,'filename'].split(\"\/\")[-1].split(\"_\")[1]\n    second = split_test_audio_ids.loc[i,'seconds']\n    row_ids.append(str(row_id)+\"_\"+str(site)+\"_\"+str(second))\n    string = ''\n    for col in range(0,len(y_test[i])):\n        if y_test[i][col] == 1:\n            if string == '':\n                string += label_names[col]\n            else:\n                string += ' ' + label_names[col]\n    if string == '':\n        string = 'nocall'\n    labels.append(string)\n\nsample_submission = pd.DataFrame({'row_id':row_ids,'birds':labels})\n\n# sample_submission['birds'].value_counts()","829df7c2":"output = sample_submission\noutput.to_csv('submission.csv', index=False)","425fa5a8":"output[:3]","5952e83e":"We focus on an example. The first audio file is named by","2a71dfff":"# Analyse Training","d544e9e6":"# Path","dc2c6199":"Loading the data from excel files","15e2a6e9":"# Visualizing Spectograms of bird calls from same species\nLets check the variation in spectrogram of bird calls from same species to see if their spectograms differ","23db72bc":"# Train, Val And Test Data","00e2f0a8":"Listen to the bird:","48925f2c":"# Analysis of Long Recordings in Train Soundscapes\nOur challenge is to identify which birds are calling in **long** recordings.\n\nThere are 20 long audio files in the folder train_soundscapes. And there are also 20 unique audio ids: ","c2a60aa8":"Load the data and samplerate and compare spectrograms:","b422a8aa":"Display the audio of the file:","0b34ee69":"# Helper Functions\n\n","411f3dde":"# Parameter\nBased on the EDA we define some parameters:","b0d643b4":"We extract all label of the train data:","0b7e737c":"# Analyzing the short Audio Files","7d18c82b":"# Libraries","cc536f79":"# Audio Data Generator\nWe use a Data Generator to load the data on demand.","589c867b":"# Data Consolidation across long and short Audios","77719163":"Plot the audio array:","3d8e4e4b":"Set all values greater than 0.5 to 1:","67d7b607":"## EDA on Train Soundscapes\nThe target label birds is a space delimited list of any bird songs present in the 5 second window. So we have to encode the labels. Therefor we look on an example with 3 different birds:","afe63c9c":"Each audio file consists of 120 birds with a lenth of 5 seconds.","dc499a32":"There are 397 short audio folders ie. 397 birds. There are 62874 short audio files present inside these folders which correspond to the entries in train_meta file","590919ed":"# Load Data","77e1e894":"# Predict Test Data","e4e5908a":"The numpy array has a lenght of 19,200,000. And we know there are 120 samples in each.So every sample consists of 160,000 values. These 160,000 values describes 5 seconds of the audio file.\n\nWe split the file name into the audio_id and site:","87b6454a":"# Export","dc3a5642":"So we have to split the long audio into 120 small audio.","16bb73f4":"For the Data Generator we want to define in the next step we need additional parameters:","e69fd76e":"# Define Model","caf87ae6":"We want to extract the first example with the id 1771. This bird we can here from 455 seconds to 460 seconds.  ","16b58052":"We load the data and samplerate:","ca3a0545":"# A brief Introduction\n\nUsing Stefan's great introduction to data here -> https:\/\/www.kaggle.com\/stefankahl\/birdclef2021-exploring-the-data\nWe already have the following details:\n\n1.     Dataset has 397 different bird species\n2.     There are less than 500 samples per bird call and some have less than 100. Dataset is highly imbalanced\n3.     Each short audio recording is about X mins long. And has multiple bird calls but one of them is prominent and sometimes others  can be heard in the background. The primary bird species is present in primary_label in train_metadata.csv. The secondary labels indicate the other birds heard in the background.\n4.     Data about bird calls - Bird species (primary) and secondary ones heard in background and also type of call\n5.     Data other than bird species - Date & time when it was spotted, location(given by lattitude and longitude), \n6.     Data - Rating indicating quality of the calls, Author or the contributor who recorded","c7d1b88e":"Test the Data Generator","36afe507":"# Visualizing Spectograms of different species\nLets compare different species to see how their spectograms differ","4fd9d450":"We focus on the samples with the label birds unequal to nocall. There are 4 samples","55dfda49":"# Overview","0d5f9d16":"Generate target label string:"}}