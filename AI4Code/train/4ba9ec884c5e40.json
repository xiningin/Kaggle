{"cell_type":{"73c1f4a5":"code","020508a3":"code","07651ec5":"code","91b46eb4":"code","d5d800a1":"code","50a2e4b4":"code","7a9c46d2":"code","b7174acc":"code","16464d35":"code","b762ec3f":"code","2a5406b2":"code","5fbac017":"code","5e3d29bd":"code","315d1fc4":"code","a384c894":"code","68850f2e":"code","09660b4e":"markdown","aac283f1":"markdown","88f23e8b":"markdown","30bca19a":"markdown","27e80244":"markdown","71a1274a":"markdown","bf0535c7":"markdown","461222f3":"markdown","c8b32584":"markdown","78476364":"markdown","d2a4df02":"markdown","557175f8":"markdown","b56c3123":"markdown"},"source":{"73c1f4a5":"# Ignore warnings :\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Handle table-like data and matrices :\nimport numpy as np\nimport pandas as pd\nimport math \nimport itertools\n\n\n\n# Modelling Algorithms :\n\n# Classification\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n\n#preprocessing :\nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler,  LabelEncoder\nfrom sklearn.impute import SimpleImputer\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport plotly.express as px\nimport seaborn as sns\nimport missingno as msno\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\n\n# Center all plots\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\");\n\n# Make Visualizations better\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplt.rcParams.update(params)","020508a3":"train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ndf = train.copy()\ndf_test = test.copy()","07651ec5":"df.head()","91b46eb4":"print('Train: ', df.shape)\nprint('Test: ', df_test.shape)","d5d800a1":"df.label.unique()","50a2e4b4":"# Train\ndf.isnull().any().sum()","7a9c46d2":"# Test\ndf_test.isnull().any().sum()","b7174acc":"# Mapping Classes\nclothing = {0 : 'T-shirt\/top',\n            1 : 'Trouser',\n            2 : 'Pullover',\n            3 : 'Dress',\n            4 : 'Coat',\n            5 : 'Sandal',\n            6 : 'Shirt',\n            7 : 'Sneaker',\n            8 : 'Bag',\n            9 : 'Ankle boot'}","16464d35":"fig, axes = plt.subplots(4, 4, figsize = (15,15))\nfor row in axes:\n    for axe in row:\n        index = np.random.randint(60000)\n        img = df.drop('label', axis=1).values[index].reshape(28,28)\n        cloths = df['label'][index]\n        axe.imshow(img, cmap='gray')\n        axe.set_title(clothing[cloths])\n        axe.set_axis_off()","b762ec3f":"df['label'].value_counts()","2a5406b2":"sns.factorplot(x='label', data=df, kind='count', size=3, aspect= 1.5)","5fbac017":"# Setting Random Seeds for Reproducibilty.\nseed = 66\nnp.random.seed(seed)","5e3d29bd":"from sklearn.model_selection import train_test_split\n\nX = train.iloc[:,1:]\nY = train.iloc[:,0]\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=seed)","315d1fc4":"from sklearn.metrics import accuracy_score\n\nClassifier = DecisionTreeClassifier(criterion = 'entropy',random_state = 0)\nClassifier.fit(x_train,y_train)\n\n\n#Predicting The Test Set Results \nY_pred = Classifier.predict(x_test)\naccuracy = accuracy_score(y_test, Y_pred)\nprint(\"Accuracy of Decision Tree Classifier: \",accuracy*100)","a384c894":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 10,criterion = 'entropy',random_state = 0)\nrf.fit(x_train,y_train)\n\n#Predicting The Test Set Results \nY_pred = rf.predict(x_test)\naccuracy = accuracy_score(y_test, Y_pred)\nprint(\"Accuracy of Random Forest Classifier: \",accuracy*100)","68850f2e":"knn = KNeighborsClassifier(n_neighbors = 5,metric = 'minkowski' ,p=2)\nknn.fit(x_train,y_train)\n\n#Predicting The Test Set Results \nY_pred = knn.predict(x_test)\n\naccuracy = accuracy_score(y_test, Y_pred)\nprint(\"Accuracy of  K-Nearest Neighbors (K-NN): \",accuracy*100)","09660b4e":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\"> Dimensions<\/h1><a id=0><\/a>","aac283f1":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\"> Visualizing the Dataset<\/h1><a id=0><\/a>","88f23e8b":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\"> Features<\/h1><a id=0><\/a>\n\n**Label**: The Target variable.\n\n**Pixels:** The smallest unit of a Digital Image or Graphic that can be displayed on Digital Display Device.\nWhere humans can see the objects due to the Light Receptors in their Eyes which send Signals via the Optic Nerve to the Primary Visual Cortex, where the input is processed ,\n\nComputers on the other hand, see the Image as 2-dimensional arrays of numbers, known as pixels. They Classify Images based on Boundaries and Curvatures of the Object (Represented by pixel values, either RGB or GrayScale) .","30bca19a":"**Labels** :\n* **0 - ** T-shirt\/top\n* **1 - ** Trouser\n* **2 - ** Pullover\n* **3 - ** Dress\n* **4 - ** Coat\n* **5 - ** Sandals\n* **6 - ** Shirt\n* **7 - ** Sneaker\n* **8 - ** Bag\n* **9 - ** Ankle Boots","27e80244":"##  Splitting Data into Train and Validation Set\nNow we are gonna split the training data into Train and Validation Set. Train set is used for Training the model and Validation set is used for Evaluating our Model's Performance on the Dataset.\n\nThis is achieved using the train_test_split method of scikit learn library.","71a1274a":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\"> Data PreProcessing<\/h1><a id=0><\/a>","bf0535c7":"* **We can see that all classes are equally Distributed.**\n* **So, there is no need for OverSampling or UnderSampling.**","461222f3":"##  Distribution of Labels\n**Let's look at the Distribution of labels to anaylze if there are any skewed classes.**","c8b32584":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\"> Examine NaN Values<\/h1><a id=0><\/a>","78476364":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\"> Decision Tree Classifier Model<\/h1><a id=0><\/a>","d2a4df02":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\">Random Forest Classifier Model<\/h1><a id=0><\/a>","557175f8":"##  Plotting Random Images","b56c3123":"<h1 style=\"background-color:black\n;font-family:newtimeroman;font-size:225%;text-align:left; color:#40E0D0\">K-Nearest Neighbors (K-NN) Model<\/h1><a id=0><\/a>"}}