{"cell_type":{"d69a0230":"code","d72091b8":"code","94a5a7d4":"code","a2ebc370":"code","0adc5a42":"code","6b08721d":"code","dc5515d6":"code","e298183d":"code","b67a0817":"code","8cd55bf2":"code","52d2e47c":"code","474690c7":"code","9638b957":"code","d1212106":"code","109e236e":"code","ce39d6f3":"code","f23477c7":"code","17356313":"code","65466464":"code","eec44b7e":"code","d820e7df":"code","746a3fc7":"code","227e1812":"code","7b3aca99":"code","6e1dbb59":"code","d2308647":"code","a1cf6609":"code","5bbb3f99":"code","b96b7ae8":"code","2d2ce21c":"code","e479f116":"code","784bef00":"code","73a713f0":"code","c02e8aa3":"code","305d8e4d":"code","6fb8f872":"code","fd61aeaa":"code","beb416f6":"code","0c24eabf":"code","e932b316":"code","31eab6e8":"code","6c9269f5":"code","0ad6e914":"code","a57c79f0":"code","051377a9":"markdown","62dc5e79":"markdown","4d841b2b":"markdown","d7c1547b":"markdown","8a14b27f":"markdown","7c114e4b":"markdown","b3cb7fa6":"markdown","3469f6f1":"markdown","e2adc82e":"markdown","48159a17":"markdown","68b9805a":"markdown","5c385135":"markdown","c25d5d7e":"markdown","190920c9":"markdown","703d56a3":"markdown","152f6e99":"markdown","9d231bce":"markdown","d36ce963":"markdown","4671c43d":"markdown","847f4b40":"markdown","f1232223":"markdown","305df389":"markdown","5e70063a":"markdown","5dd8fa69":"markdown","64c3c669":"markdown","68ab79b2":"markdown","30d9e6fe":"markdown","428dc336":"markdown","e5e6ac7f":"markdown","5a06a518":"markdown","fd2bec20":"markdown","fe6d4f9b":"markdown","8f77f667":"markdown","ebbff2ee":"markdown","996b2b4c":"markdown","27e39a8b":"markdown","c1a50541":"markdown","50640549":"markdown","e72a16ce":"markdown","1831a8f1":"markdown","64def6a4":"markdown","2e471171":"markdown","4184438c":"markdown","677a1f87":"markdown","ecf9dfce":"markdown","946f4203":"markdown","b38232ad":"markdown","71feb94b":"markdown","1ddd820c":"markdown","1a13011b":"markdown","11df18c6":"markdown","837089b8":"markdown","dda69fcc":"markdown","44c81617":"markdown","3cae81dd":"markdown","545b3525":"markdown","a4a4a70f":"markdown"},"source":{"d69a0230":"# data analysis and wrangling    \nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","d72091b8":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ncombine = [train_df, test_df]","94a5a7d4":"train_df.head(545)","a2ebc370":"train_df.info()\nprint('_'*40)\ntest_df.info()","0adc5a42":"train_df.describe()#for numerical features","6b08721d":"train_df.describe(include=['O'])#for others(non numerical features)","dc5515d6":"sns.factorplot(x=\"Pclass\", y =\"Survived\", data=train_df, kind=\"bar\", size=3)\nplt.show()","e298183d":"train_df[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean()","b67a0817":"train_df[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index=False).mean().sort_values(by='Survived', ascending=False)","8cd55bf2":"train_df[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index=False).mean().sort_values(by='Survived', ascending=False)","52d2e47c":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","474690c7":"train_df['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\nsns.heatmap(train_df[[\"Embarked\", \"Survived\"]].corr(), annot = True)\nplt.show()\ntrain_df['Embarked'].replace([0,1,2],['S','C','Q'],inplace=True)","9638b957":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","d1212106":"train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]","109e236e":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","ce39d6f3":"sns.countplot(train_df[\"Title\"])\nplt.xticks(rotation = 90)\nplt.show()","f23477c7":"for dataset in combine:\n    dataset['Title'].replace(['Mme','Ms','Mlle','Lady','Countess','Dona','Dr','Major','Sir','Capt','Don','Rev','Col', 'Jonkheer'],['Miss','Miss','Miss','Mrs','Mrs','Mrs','Mr','Mr','Mr','Mr','Mr','Other','Other','Other'], inplace=True)\nsns.factorplot(x=\"Title\", y =\"Survived\", data=train_df, kind=\"bar\", size=3)\nplt.show()","17356313":"\nfor dataset in combine:\n    dataset[\"Title\"].replace([\"Mr\",\"Mrs\",\"Miss\",\"Master\",\"Other\"], [1,2,2,3,1], inplace=True)\ntrain_df.head()","65466464":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]","eec44b7e":"for dataset in combine:\n    dataset['Family'] = dataset['SibSp'] + dataset['Parch']\nsns.factorplot(x=\"Family\", y =\"Survived\", data=train_df, kind=\"bar\", size=3)\nplt.show()","d820e7df":"for dataset in combine:\n    dataset[\"Alone\"] = [1 if i == 0 else 0 for i in dataset[\"Family\"]]\n    dataset[\"Family\"].replace([0,1,2,3,4,5,6,7,10], [0,1,1,1,0,2,0,2,2], inplace=True)\ntrain_df.head()","746a3fc7":"train_df = train_df.drop(['Parch', 'SibSp', 'Family'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'Family'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","227e1812":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","7b3aca99":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","6e1dbb59":"for dataset in combine:\n    dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(freq_port)\n","d2308647":"grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","a1cf6609":"guess_ages = np.zeros((2,3))\nguess_ages","5bbb3f99":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","b96b7ae8":"train_df['AgeBand']=pd.cut(train_df['Age'], 5)\ntrain_df.groupby(['AgeBand'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","2d2ce21c":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","e479f116":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","784bef00":"#it's done before\n#for dataset in combine:\n#    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\n#train_df.head()","73a713f0":"for dataset in combine:\n    dataset['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n\ntrain_df.head()","c02e8aa3":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","305d8e4d":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    #dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","6fb8f872":"test_df.head()","fd61aeaa":"test_df[test_df[\"Fare\"].isnull()]","beb416f6":"X_train = train_df.drop(\"Survived\", axis=1)\ny_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, y_train.shape, X_test.shape","0c24eabf":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nlog_reg = round(logreg.score(X_train, y_train) * 100, 2)\nlog_reg","e932b316":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nrf_reg = round(random_forest.score(X_train, y_train) * 100, 2)\nrf_reg","31eab6e8":"svc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nsvm_clsf = round(svc.score(X_train, y_train) * 100, 2)\nsvm_clsf","6c9269f5":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nknn_clsf = round(knn.score(X_train, y_train) * 100, 2)\nknn_clsf","0ad6e914":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest'],\n    'Score': [svm_clsf, knn_clsf, log_reg, \n              rf_reg]})\nmodels.sort_values(by='Score', ascending=False)","a57c79f0":"test_result = pd.Series(random_forest.predict(X_test), name = \"Survived\").astype(int)\nresults = pd.concat([test_df[\"PassengerId\"], test_result],axis = 1)\nresults.to_csv(\"titanic_submission.csv\", index = False)","051377a9":"# Understanding the domain of our problem\n ![ad006cb87fc226147ad451fdb9f5e48b.webp](attachment:ad006cb87fc226147ad451fdb9f5e48b.webp)\n- On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. Translated 32% survival rate.\n- One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew.\n- Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.","62dc5e79":"**observations.**\n- Infants (Age <=4) had high survival rate.\n- Oldest passengers (Age = 80) survived.\n- Large number of 15-25 year olds did not survive.\n- Most passengers are in 15-35 age range.\n\n**Decisions.**\n\n- We should consider Age (our assumption classifying #2) in our model training.\n- Complete the Age feature for null values (completing #1).\n- We should band age groups (creating #3).","4d841b2b":"<a id='7'><\/a><br>\n## 5-What are the data types for various features?\nHelping us during converting goal.\n\nObject\n1. Name        : \n1. Sex         : male and female\n1. Ticket      : ticket number\n1. Cabin       : cabin category\n1. Embarked    : port C, Q and S\n\nInt64\n1. PassengerId : unique id number\n1. Survived    : 0 -> died ,1-> survived\n1. Pclasss     : 1, 2 and 3 \n1. SibSp       : number of siblings\/spouse\n1. Parch       : number of parent\/children\n\nFloat64\n1. Age         : age of passenger\n1. Fare        : price of the ticket","d7c1547b":"###\u00a0Random Forest Regression","8a14b27f":"###\u00a0Logistic Regression","7c114e4b":"Now we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.","b3cb7fa6":"<a id='6'><\/a><br>\n## 4-Which features contain blank, null or empty values?","3469f6f1":"Let us drop Parch, SibSp, and Family features in favor of IsAlone.","e2adc82e":"<a id='20'><\/a><br>\n## 4-Result\n\nWe choose Random Forest model because it works best.","48159a17":"**observations.**\n\n- Embarked is associated with Survived.\n\n**Decisions.**\n\n- Complete and add Embarked feature to model training.","68b9805a":"<a id='2'><\/a><br>\n# Chapter2 : Analyze by describing data","5c385135":"<a id='4'><\/a><br>\n## 2-Which features are numerical?\n These values change from sample to sample. \n - Continous: Age, Fare. Discrete: SibSp, Parch.","c25d5d7e":"### Pclass-Survived\n","190920c9":"###\u00a0Embarked Fill Value\nEmbarked is not associated with any feature.","703d56a3":"<a id='9'><\/a><br>\n## Chapter3 : Assumtions based on data analysis\n\nWe arrive at following assumptions based on data analysis done so far. We may validate these assumptions further before taking appropriate actions.\n\n**Correlating.**\n\nWe want to know how well does each feature correlate with Survival. We want to do this early in our project and match these quick correlations with modelled correlations later in the project.\n\n**Completing.**\n\n1. We may want to complete Age feature as it is definitely correlated to survival.\n2. We may want to complete the Embarked feature as it may also correlate with survival or another important feature.\n\n**Correcting.**\n\n1. Ticket feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and there may not be a correlation between Ticket and survival.\n2. Cabin feature may be dropped as it is highly incomplete or contains many null values both in training and test dataset.\n3. PassengerId may be dropped from training dataset as it does not contribute to survival.\n4. Name feature is relatively non-standard, may not contribute directly to survival, so maybe dropped.\n\n**Creating.**\n\n1. We may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\n2. We may want to engineer the Name feature to extract Title as a new feature.\n3. We may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\n4. We may also want to create a Fare range feature if it helps our analysis.\n","152f6e99":"<a id='17'><\/a><br>\n##\u00a01-Train Test Split","9d231bce":"### Embarked - Survived","d36ce963":"<a id='15'><\/a><br>\n## 4-Converting features","4671c43d":"<a id='1'><\/a><br>\n# Chapter1 : Acquire training and testing data.\n We also combine these datasets to run certain operations on both datasets together.","847f4b40":"<a id='3'><\/a><br>\n## 1-Which features are categorical?\nThese values classify the samples into sets of similar samples.\n- Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.","f1232223":"- Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\n- Survived is a categorical feature with 0 or 1 values.\n- Around 38% samples survived representative of the actual survival rate at 32%. \n ### Review survived rate using `percentiles=[.61, .62]`\n- Most passengers (> 75%) did not travel with parents or children.\n### Review Parch distribution using `percentiles=[.75, .8]`\n- Nearly 30% of the passengers had siblings and\/or spouse aboard.\n### SibSp distribution `[.68, .69]`\n- Fares varied significantly with few passengers (<1%) paying as high as $512.\n- Few elderly passengers (<1%) within age range 65-80.\n#### Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`","305df389":"We can not remove the AgeBand feature.","5e70063a":"###\u00a0Name - Title","5dd8fa69":"### Sex","64c3c669":"<a id='12'><\/a><br>\n## 1-Correcting by dropping features\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.","68ab79b2":"### Embarked","30d9e6fe":"\n- Names are unique across the dataset (count=unique=891)\n- Sex variable as two possible values with 65% male (top=male, freq=577\/count=891).\n- Cabin values have several dupicates across samples. Alternatively several passengers shared a cabin.\n- Embarked takes three possible values. S port used by most passengers (top=S)\n- Ticket feature has high ratio (22%) of duplicate values (unique=681).","428dc336":"<a id='18'><\/a><br>\n##\u00a02-Classificaiton Methods\n\n\n* Logistic Regression\n* Random Forest Regression\n* Support Vector Machine (SVM)\n* K-Nearest Neighbors (KNN)","e5e6ac7f":"### Sex - Survived","5a06a518":"<a id='14'><\/a><br>\n## 3-Fill Missing Value","fd2bec20":"### Fare Band","fe6d4f9b":"<a id='13'><\/a><br>\n## 2-Creating new features extracting from existing","8f77f667":"**observations.**\n- Women (Sex=female) were more likely to have survived\n\n**Decisions.**\n- We decide to include this feature in our model.","ebbff2ee":"<a id='5'><\/a><br>\n## 3-Which features are mixed data types?\nNumerical, alphanumeric data within same feature. These are candidates for correcting goal.\n- Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric.","996b2b4c":"<a id='8'><\/a><br>\n## 6-What is the distribution of  feature values across the samples?\nThis helps us determine, among other early insights, how representative is the training dataset of the actual problem domain.","27e39a8b":"We can replace many titles with a more common name","c1a50541":"<a id='10'><\/a><br>\n## Chapter4 : Confirm our assumptions","50640549":"Let us replace Age with ordinals based on these bands.","e72a16ce":"###\u00a0Age Fill Value\n\n","1831a8f1":"###\u00a0Alone and Family \n* SibSp + Parch = family","64def6a4":"### Age - Survived","2e471171":"<a id='16'><\/a><br>\n## Chapter5: Modeling","4184438c":"# Content of The Titanic Exploratory Data Analysis\n1. [Chapter-1 : Acquire training and testing data.](#1)\n\n1. [Chapter-2 : Analyze by describing data](#2)\n    * [1-Which features are categorical?](#3)\n    * [2-Which features are numerical?](#4)\n    * [3-Which features are mixed data types?](#5)\n    * [4-Which features contain blank, null or empty values?](#6)\n    * [5-What are the data types for various features?](#7)\n    * [6-What is the distribution of feature values across the samples?](#8)\n    \n1. [Chapter-3 : Assumtions based on data analysis](#9)\n\n1. [Chapter-4 : Confirm our assumptions](#10)\n    \n1. [Chapter-5 : Wrangle data](#11)\n    * [1-Correcting by dropping features](#12)\n    * [2-Creating new features extracting from existing](#13)\n    * [3-Fill Missing Value](#14)\n    * [4-Converting  features](#15)\n    \n1. [Chapter-5 : Modeling](#16)\n    * [1-Train Test Split](#17)\n    * [2-Classificaiton Methods](#18)\n    * [3-Model evaluation](#19)\n    * [4-Result](#20)\n    \n    ","677a1f87":"### Age Band ","ecf9dfce":"# Problem Definition\n Knowing from a training set of samples listing passengers who survived or did not survive the Titanic disaster, can our model determine based on a given test dataset not containing the survival information, if these passengers in the test dataset survived or not.","946f4203":"### Support Vector Machine (SVM)","b38232ad":"We can convert the categorical titles to ordinal.","71feb94b":"###\u00a0Fare Fill Value","1ddd820c":"<a id='11'><\/a><br>\n## Chapter5 : Wrangle data\nLet us now execute our decisions and assumptions for correcting, creating, and completing goals.","1a13011b":"**observations.**\n- These features have zero correlation for certain values\n\n**Decisions.**\n- It may be best to derive a feature or a set of features from these individual features","11df18c6":" ### Fare - Survived","837089b8":"<a id='19'><\/a><br>\n##\u00a03- Model evaluation","dda69fcc":"###\u00a0KNN","44c81617":"**observations.**\n- We observe significant correlation (>0.6) among Pclass=1 and Survived.\n\n**Decisions.**\n- We decide to include this feature in our model.\n","3cae81dd":"**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.","545b3525":"These will require correcting.\n\n- Cabin > Age > Embarked features contain a number of null values in that order for the training dataset.\n- Cabin > Age are incomplete in case of test dataset.","a4a4a70f":"### Parch & SibSp - Survived"}}