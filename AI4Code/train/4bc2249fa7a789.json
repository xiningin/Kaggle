{"cell_type":{"81afeeb4":"code","73417779":"code","e0072f2c":"code","7f435426":"code","b812ca96":"code","f1f069a6":"code","199145a9":"code","8b3b78ad":"code","bfd6ef6d":"code","74ff82b1":"code","d7ee226a":"markdown","ea6f2870":"markdown","47717198":"markdown","2c3dd75e":"markdown","c60147b6":"markdown","683ffd5e":"markdown","119658d2":"markdown","d8de0192":"markdown","eb01625b":"markdown"},"source":{"81afeeb4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_rows', 100)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom scipy.stats import spearmanr\n\ndf_train = pd.read_csv(\"..\/input\/google-quest-challenge\/train.csv\")\ndf_test  = pd.read_csv(\"..\/input\/google-quest-challenge\/test.csv\")","73417779":"qtp = df_train[df_train[\"question_type_spelling\"] > 0][[\"question_body\", \"category\", \"question_type_spelling\", \"url\"]]\nprint(f\"{len(qtp)} \/ {len(df_train)} QAs\")\nqtp","e0072f2c":"indexs = []\nfor i in range(len(df_train)):\n    if df_train.iloc[i, 8] in qtp[\"url\"].values:\n        indexs.append(i)\ndf_train.iloc[indexs].sort_values(\"url\")[[\"qa_id\", \"question_body\", \"answer\", \"question_type_spelling\"]]","7f435426":"def count_spelling_feature(text):\n    symbols = [\"\u028a\", \"\u0259\", \"\u0279\", \"\u026a\", \"\u0292\", \"\u0251\", \"\u028c\", \"\u0254\", \"\u00e6\", \"\u02d0\", \"\u025c\",  \"adjective\", \"pronounce\"]\n    count = 0\n    for s in symbols:\n        count += text.count(s)\n    return count\n\ndf_train[df_train[\"question_body\"].apply(lambda x: count_spelling_feature(x)) > 0][[\"url\", \"question_body\", \"answer\",\"category\",\"question_type_spelling\"]]","b812ca96":"df_test[df_test[\"question_body\"].apply(lambda x: count_spelling_feature(x)) > 0][[\"url\", \"question_body\", \"answer\",\"category\"]]","f1f069a6":"cols = [\"answer_plausible\", \"question_not_really_a_question\", \"question_type_spelling\", \"answer_relevance\"]\nfor col in cols: \n    df_train[col].hist()\n    plt.title(col)\n    plt.show();","199145a9":"true_values = np.append(np.zeros(500), 1)\n\npred_values = np.append(1, np.zeros(500))\nsp = spearmanr(true_values, pred_values).correlation\nscore = (0.4 * 29 + sp) \/ 30\nprint(f\"correlation score of 1 column: {sp}, LB score: {score}\")","8b3b78ad":"pred_values = np.append(np.zeros(500), 1)\nsp = spearmanr(true_values, pred_values).correlation\nscore = (0.4 * 29 + sp) \/ 30\nprint(f\"correlation score of 1 column: {sp}, LB score: {score}\")","bfd6ef6d":"# If the ranking is correct but there is noise in the prediction\npred_values = np.append(np.zeros(500), 1)\npred_values = pred_values + np.random.normal(0, 1e-7, pred_values.shape[0])\nsp = spearmanr(true_values, pred_values).correlation\nscore = (0.4 * 29 + sp) \/ 30\nprint(f\"correlation score of 1 column: {sp}, LB score: {score}\")","74ff82b1":"# If 80% of the predicted value is unified at 0\npred_values = np.append(np.append(np.zeros(100) + np.random.normal(0, 1e-7, 100), np.zeros(400)), 1) \nsp = spearmanr(true_values, pred_values).correlation\nscore = (0.4 * 29 + sp) \/ 30\nprint(f\"correlation score of 1 column: {sp}, LB score: {score}\")","d7ee226a":"There are other columns with a skewed distribution.","ea6f2870":"If there is a solution you are doing, please comment on a discussion or this kernel. thank you.","47717198":"If one column is completely hit (1) and mistaken (0), a difference of about 0.04 is given to the LB score.","2c3dd75e":"Also, you can see that the tag attached to the same question as the question that was a positive value is different depending on the answer, such as 0, 0.33, 0.66 (depending on the difference of annotator?).","c60147b6":"There are only 11 out of 6079 lines in the training data that have a positive question_type_spelling value.","683ffd5e":"Since the number of samples is small, I checked whether it was related to spelling with a simple rule base. We used only the number of words that appeared in the training data, but the same thing as the train set did not match in the test set.","119658d2":"Since this is a small amount of test data, we can conclude that there is no or only a few data to take a positive question_type_spelling value in the first place, or that another phonetic symbol or word should be used.","d8de0192":"In my BERT model, the Spearman correlation coefficient of the `question_type_spelling` column was low (about 0.06 in CV), so I examined it.","eb01625b":"You should also pay attention to the difference in evaluation score when ranking is the same.\nIf there are many ties, you may want to set the lower prediction to 0."}}