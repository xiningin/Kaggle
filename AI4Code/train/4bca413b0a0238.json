{"cell_type":{"afd062d3":"code","019c5220":"code","1a1d7d22":"code","2e098314":"code","18dfd2a1":"code","9609ecb8":"code","6e8a8bef":"code","ad186c7c":"code","16675aa7":"code","8fa6a273":"code","420b6ac2":"code","4b315831":"code","5384c72e":"code","2f495476":"code","42befddf":"code","f14cf7f2":"code","eb4a7cff":"code","a83352b3":"code","493cc315":"code","6af83df2":"code","31e5faea":"code","a4d52a75":"code","0d825658":"markdown"},"source":{"afd062d3":"from PIL import Image \nimport os\n\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization,LeakyReLU, concatenate, Conv2DTranspose, Activation, MaxPool2D, UpSampling2D, Concatenate\nfrom tensorflow.keras.utils import Sequence, plot_model\nfrom tensorflow.keras.applications import vgg16\nimport tensorflow.keras.backend as K\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","019c5220":"MAIN_DIR = \"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/\"\nfish_classes = [name for name in os.listdir(MAIN_DIR) if os.path.isdir(os.path.join(MAIN_DIR, name))]\n","1a1d7d22":"#List all image files, image mask files and class of iamge files\nimage_files = []\nimage_classes = []\nimage_masks = []\nimport pdb\nfor f_class in fish_classes:\n    for files in os.listdir(os.path.join(MAIN_DIR,f_class,f_class)):\n        image_files.append(os.path.join(MAIN_DIR,f_class,f_class,files))\n        image_masks.append(os.path.join(MAIN_DIR,f_class,f_class+\" GT\",files))\n        image_classes.append(f_class)","2e098314":"#Scaled image size for modelling\nimg_size = (180, 180)","18dfd2a1":"def display_image(index):\n    image_path = image_files[index]\n    mask_path = image_masks[index] \n    orig_img = mpimg.imread(image_path)\n    mask_img = mpimg.imread(mask_path)\n    print(\"Original image:\",orig_img.shape)\n    print(\"Masked image:\",mask_img.shape)\n    plt.subplot(1, 2, 1)\n    plt.imshow(orig_img)\n    plt.subplot(1, 2, 2)\n    plt.imshow(mask_img)\n    plt.show()\n\n#Enter index \nindex = 12\ndisplay_image(index)","9609ecb8":"#Creating a sample image to be used in displaycallbacks function after every epoch\nimg_size = (180,180)\nsample_img = np.asarray(load_img(image_files[index],target_size=img_size))\nsample_mask = np.asarray(load_img(image_masks[index],target_size=img_size))","6e8a8bef":"class FishSketches(tf.keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.input_img_paths = input_img_paths\n        self.target_img_paths = target_img_paths\n\n    def __len__(self):\n        return len(self.target_img_paths) \/\/ self.batch_size\n\n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size\n        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, path in enumerate(batch_input_img_paths):\n            img = load_img(path, target_size=self.img_size+(3,))\n            x[j] = np.asarray(img) \/ 255.0\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        for j, path in enumerate(batch_target_img_paths):\n            img = load_img(path, target_size=self.img_size , color_mode = \"grayscale\")\n            y[j] = np.expand_dims(np.asarray(img)\/255, axis=2)\n        return x, y","ad186c7c":"def MyModel(img_size):\n    #Using VGG model weights in the decoder phase\n    VGG16 = vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=img_size+(3,))\n    last_layer = VGG16.output\n    \n    set_trainable = False\n    for layer in VGG16.layers:\n        if layer.name in ['block1_conv1']:\n            set_trainable = True\n        if layer.name in ['block1_pool','block2_pool','block3_pool','block4_pool','block5_pool']:\n            layer.trainable = False\n    \n    #Encoder phase      \n    model = Conv2DTranspose(256,(3,3),strides=(2, 2))(last_layer)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model)    \n    \n    concat_1 = concatenate([model,VGG16.get_layer(\"block5_conv3\").output])\n    \n    model = Conv2D(512,(3,3),strides=(1, 1),padding='same')(concat_1)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model)\n    \n    model = Conv2DTranspose(512,(3,3),strides=(2, 2),padding='same')(model)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model) \n    \n    concat_2 = concatenate([model,VGG16.get_layer(\"block4_conv3\").output])\n    \n    model = Conv2D(512,(3,3),strides=(1, 1),padding='same')(concat_2)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model)\n    \n    model = Conv2DTranspose(512,(3,3),strides=(2, 2))(model)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model) \n    \n    concat_3 = concatenate([model,VGG16.get_layer(\"block3_conv3\").output])\n    \n    model = Conv2D(256,(3,3),strides=(1, 1),padding='same')(concat_3)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model)\n    \n    model = Conv2DTranspose(256,(3,3),strides=(2, 2),padding='same')(model)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model) \n    \n    concat_4 = concatenate([model,VGG16.get_layer(\"block2_conv2\").output])\n    \n    model = Conv2D(128,(3,3),strides=(1, 1),padding='same')(concat_4)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model)\n    \n    model = Conv2DTranspose(128,(3,3),strides=(2, 2),padding='same')(model)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model) \n    \n    concat_5 = concatenate([model,VGG16.get_layer(\"block1_conv2\").output])\n    \n    model = Conv2D(64,(3,3),strides=(1, 1),padding='same')(concat_5)\n    model = LeakyReLU(0.1)(model)\n    model = BatchNormalization()(model)\n        \n    model = Conv2D(1,(3,3),strides=(1, 1),padding='same')(model)\n    model = LeakyReLU(0.1)(model)\n    \n    model = Model(VGG16.input,model)\n    return model","16675aa7":"import random\n\n# Split our img paths into a training and a validation set - 80% and 20% split\nval_samples = int(0.80 * len(image_files))\nrandom.Random(42).shuffle(image_files)\nrandom.Random(42).shuffle(image_masks)\nrandom.Random(42).shuffle(image_classes)\ntrain_input_img_paths = image_files[:val_samples]\ntrain_target_img_paths = image_masks[:val_samples]\nval_input_img_paths = image_files[val_samples:]\nval_target_img_paths = image_masks[val_samples:]\ntrain_classes = image_classes[:val_samples]\nval_classes = image_classes[val_samples:]\n\n# Instantiate data Sequences for each split\nbatch_size = 48\ntrain_gen = FishSketches(\n    batch_size, img_size, train_input_img_paths, train_target_img_paths\n)\nval_gen = FishSketches(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n","8fa6a273":"from collections import Counter\n#Checking distribution among classes\nprint(f\"Training set: {Counter(train_classes)}\\n\")\nprint(f\"Validation set: {Counter(val_classes)}\\n\")","420b6ac2":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n    plt.show()","4b315831":"display([sample_img, sample_mask])\n","5384c72e":"#Creating a custom callback which displays prediction end of every epoch for a given sample\nclass DisplayCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        display([sample_img, sample_mask, model.predict(sample_img[tf.newaxis, ...])[0]])\n        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n\n","2f495476":"K.clear_session()\nmodel = MyModel(img_size)\n#plot_model(model)","42befddf":"\ncheckpointer = ModelCheckpoint('saved_model-{epoch:02d}.h5', verbose=1,mode='auto', monitor='loss',save_best_only=False)\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")\n\nmodel.compile(optimizer=RMSprop(learning_rate=0.00001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model, doing validation at the end of each epoch.\nEPOCHS = 15\n\nmodel_history = model.fit(train_gen, epochs=EPOCHS,\n                          validation_data=val_gen,\n                          callbacks=[DisplayCallback(), checkpointer, tensorboard_callback])\n","f14cf7f2":"%reload_ext tensorboard\n","eb4a7cff":"%tensorboard --logdir logs\/","a83352b3":"plt.figure(figsize=(6, 4))\nplt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.ylim([0.5, 1])\nplt.legend(['train', 'test'], loc='upper left')","493cc315":"!ls\n#selected_model = MyModel(img_size)\n#selected_model.load_weights(\"saved_model-05.h5\")\n","6af83df2":"# Generate predictions for all images in the validation set\nval_gen = FishSketches(batch_size, img_size, val_input_img_paths, val_target_img_paths)\nval_preds = model.predict(val_gen)\n\n","31e5faea":"def show_prediction(index_list):\n    plt.figure(figsize=(20, 32))\n    image_number = 1 \n    for index in index_list:\n        title = ['Input Image', 'True Mask', 'Predicted Mask']\n        plt.subplot(len(index_list), 3, image_number)\n        plt.title(title[0])\n        plt.imshow(mpimg.imread(val_input_img_paths[index]))\n        image_number = image_number+1\n        plt.subplot(len(index_list), 3, image_number)\n        plt.title(title[1])\n        plt.imshow(mpimg.imread(val_target_img_paths[index]))\n        image_number = image_number+1\n        plt.subplot(len(index_list), 3, image_number)\n        plt.title(title[2])\n        plt.imshow(val_preds[index])\n        image_number = image_number+1       \n    plt.show()","a4d52a75":"#Prediction for Random 10 samples from validation set\nrandomlist = random.sample(range(10, 30), 10)\nshow_prediction(randomlist)","0d825658":"**Visualising model performance**"}}