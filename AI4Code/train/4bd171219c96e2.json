{"cell_type":{"5ca9254e":"code","2f6cebd7":"code","1ffada21":"code","3df09ee7":"code","2c60f50b":"code","4bcc6f80":"code","de203195":"code","13a4ee7b":"code","67e9ab43":"code","3e3971a9":"code","7e022306":"code","07612cd9":"code","83537d79":"code","84f501ff":"code","eed5e964":"code","a7e0a429":"code","f90b1101":"code","b88a3fb8":"code","03a76f6a":"code","febe15bd":"code","3e724460":"code","a13525ad":"code","8e5e40c5":"markdown","e3c2440f":"markdown","554f3677":"markdown","93dd8234":"markdown","755a60fa":"markdown","f8bcab21":"markdown","6a6f86bb":"markdown","7e0dcebe":"markdown","ee9133a1":"markdown","494b244f":"markdown","e5c5a531":"markdown","f07c49b5":"markdown","b1428fc0":"markdown"},"source":{"5ca9254e":"! rm -rf \/kaggle\/working\/*","2f6cebd7":"import random\nfrom shutil import copyfile\n\nimport os,sys\nimport zipfile\nimport shutil\nfrom os import path, getcwd, chdir\n\n## Bare minimum library requirement\nimport tensorflow as tf\nimport keras\n#Keras provide API for Augmentation helps in generation\nfrom tensorflow.keras.optimizers import RMSprop","1ffada21":"! cp -R \/kaggle\/input\/* \/kaggle\/working","3df09ee7":"#List down all directories in \"\/kaggle\/input\/\"\nfor dirName,_,fileName in os.walk(\"\/kaggle\/input\/microsoft-catsvsdogs-dataset\/\"):\n    print(dirName)","2c60f50b":"#List down all directories in \"\/kaggle\/working\/\"\nfor dirName,_,fileName in os.walk(\"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/\"):\n    count = 0\n    print(\"Directory:: \",dirName)","4bcc6f80":"! mkdir \/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/\n! mkdir \/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/Dog\/\n! mkdir \/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/Cat\/\n\n! mkdir \/kaggle\/working\/microsoft-catsvsdogs-dataset\/testing\/\n! mkdir \/kaggle\/working\/microsoft-catsvsdogs-dataset\/testing\/Dog\/\n! mkdir \/kaggle\/working\/microsoft-catsvsdogs-dataset\/testing\/Cat\/","de203195":"def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE,DESTINATION):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = SOURCE + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + \" has not enough pixels to represent it as an image, seems corrupted so ignoring.\")\n\n    training_length = int(len(files) * SPLIT_SIZE)\n    testing_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[0:training_length]\n    testing_set = shuffled_set[-testing_length:]\n\n    for filename in training_set:\n        this_file = SOURCE + filename\n        destination = TRAINING + filename\n        copyfile(this_file, destination)\n\n    for filename in testing_set:\n        this_file = SOURCE + filename\n        destination = TESTING + filename\n        copyfile(this_file, destination)\n\n#####################################################################################\n\nDESTINATION = \"\/kaggle\/working\"\n\nCAT_SOURCE_DIR = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/PetImages\/Cat\/\"\nDOG_SOURCE_DIR = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/PetImages\/Dog\/\"\n\nTRAINING_CATS_DIR = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/Cat\/\"\nTESTING_CATS_DIR = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/testing\/Cat\/\"\n\nTRAINING_DOGS_DIR = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/Dog\/\"\nTESTING_DOGS_DIR = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/testing\/Dog\/\"","13a4ee7b":"split_size = .9\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size,DESTINATION)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size,DESTINATION)","67e9ab43":"print(\"Total Cat iamge count :: \",len(os.listdir(TRAINING_CATS_DIR)))\nprint(\"Total Dog iamge count :: \",len(os.listdir(TRAINING_DOGS_DIR)))","3e3971a9":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.pyplot import imread, imshow, subplots, show\nCAT_TRAINING_DIR , DOG_TRAINING_DIR  =  TRAINING_CATS_DIR,TRAINING_DOGS_DIR\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\n# Index for iterating over images\npic_index = 0","7e022306":"try:\n    # Set up matplotlib fig, and size it to fit 4x4 pics\n    fig = plt.gcf()\n    fig.set_size_inches(ncols * 4, nrows * 4)\n    pic_index += 8\n\n    next_cat_pix = [os.path.join(CAT_TRAINING_DIR, fname) for fname in os.listdir('\/kaggle\/working\/microsoft-catsvsdogs-dataset\/PetImages\/Cat\/')[pic_index - 8:pic_index]]\n    next_dog_pix = [os.path.join(DOG_TRAINING_DIR, fname) for fname in os.listdir('\/kaggle\/working\/microsoft-catsvsdogs-dataset\/PetImages\/Dog\/')[pic_index - 8:pic_index]]\n\n    for i, img_path in enumerate(next_cat_pix + next_dog_pix):\n        # Set up subplot; subplot indices start at 1\n        sp = plt.subplot(nrows, ncols, i + 1)\n        sp.axis('On')  # Don't show axes (or gridlines)\n        img = mpimg.imread(img_path)\n        plt.imshow(img)\n\n    plt.show()\n\nexcept:\n    pass","07612cd9":"%matplotlib inline\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef plot(data_generator):\n    \"\"\"\n    Plots 4 images generated by an object of the ImageDataGenerator class.\n    \"\"\"\n    data_generator.fit(images)\n    image_iterator = data_generator.flow(images)\n    \n    #Plot the images given by the iterator\n    fig, rows = subplots(nrows=1, ncols=4, figsize=(18, 18))\n    for row in rows:\n        row.imshow(image_iterator.next()[0].astype('int'))\n        row.axis('on')\n    show()","83537d79":"def imageAugmentor():\n    data_generator = ImageDataGenerator(rotation_range=180)\n    plot(data_generator)\n\n    data_generator = ImageDataGenerator(featurewise_center=False,\n                                        width_shift_range=0.65)\n    plot(data_generator)\n\n    data_generator = ImageDataGenerator(featurewise_center=False,\n                                        width_shift_range=0.65)\n    plot(data_generator)\n\n    data_generator = ImageDataGenerator(vertical_flip=True,\n                                        zoom_range=[0.2, 0.9],\n                                        width_shift_range=0.2)\n    plot(data_generator)\n\n    data_generator = ImageDataGenerator(horizontal_flip=True,\n                                        zoom_range=[1, 1.5],\n                                        width_shift_range=0.2)\n    plot(data_generator)\n\n    data_generator = ImageDataGenerator(width_shift_range=[0.1, 0.5])\n    plot(data_generator)\n\n    data_generator = ImageDataGenerator(zoom_range=[1, 2], rotation_range=260)\n    plot(data_generator)","84f501ff":"pic_index += 8\nnext_pic = [\n    os.path.join(CAT_TRAINING_DIR, fname) for fname in os.listdir('\/kaggle\/input\/microsoft-catsvsdogs-dataset\/PetImages\/Cat\/')[pic_index - 8:pic_index]\n]\nimage = plt.imread(next_pic[0])\n# Creating a dataset which contains just one image.\nimages = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\nimshow(images[0])\nshow()","eed5e964":"imageAugmentor()","a7e0a429":"dict = {}\ntraining_data_path = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/\"\nfor directory in os.listdir(training_data_path):\n    count = 0\n    for fileName in os.listdir(training_data_path + directory):\n        count += 1\n\n    dict.update({\"{0}\".format(directory): count})\nprint(dict)","f90b1101":"class NeuralNet:\n    '''\n    Responsible for Neural net skeleton\n    '''\n    '''\n    Sequential design of layering to interconnect various layers.\n    Hawk eye view would be\n     ___________________________________________________\n    |conv-->pool-->conv-->pool-->flatten-->dense-->dense|\n     ---------------------------------------------------\n    \n    #Basic parameters to be passed on call \n    #1.training_data_path\n    #2.validation_data_path\n    #3.callback\n    #4.epochs\n    #5.batch_size\n    #6.learning_rate\n    '''\n    \n    def neuralModeling(self, training_data_path, validation_data_path,\n                       callback, epochs, batch_size, learning_rate):\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Conv2D(16, (3, 3),\n                                   activation='relu',\n                                   input_shape=(150, 150, 3)),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(512, activation='relu'),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n\n        #Model compilation\n        model.compile(\n            optimizer=RMSprop(lr=learning_rate),\n            loss='binary_crossentropy',\n            metrics=['accuracy']\n        )\n\n        #model summary\n        model.summary()\n\n        #Make datagen for Train generator\n        train_datagen = ImageDataGenerator(rescale=1.\/255)\n\n        #Train generator\n        train_generator = train_datagen.flow_from_directory(\n            training_data_path,\n            target_size=(150, 150),\n            batch_size=batch_size,\n            class_mode='binary')\n        \n        #Make datagen for validation generator\n        validation_datagen = ImageDataGenerator(rescale=1.\/255)\n\n        #validation generator\n        validation_generator = validation_datagen.flow_from_directory(\n            validation_data_path,\n            target_size=(150, 150),\n            batch_size=batch_size,\n            class_mode='binary')\n        logdir = \"\/kaggle\/working\/logs\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        \n        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n        \n        history = model.fit(train_generator,\n                            validation_data=validation_generator,\n                            epochs=epochs,\n                            verbose=1,\n                            callbacks = [tensorboard_callback]\n                            )\n\n        return history, model\n\n    '''\n    Constructor of the class    \n    '''\n    \n    def __init__(self):\n        print(\"Object getting created\")","b88a3fb8":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nfrom packaging import version\n\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        \n        if (type(logs.get('accuracy'))!= None and logs.get('accuracy') > 0.99):\n            print(\n                \"\\n\\n\\nGot accuracy above 0.99% so cancelling any further training! \\n\\nas it might cause Overfitting\\n\\n\"\n            )\n            self.model.stop_training = True\n\n\ncallback = myCallback()","03a76f6a":"#Training data\ntraining_data_path = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/training\/\"\nvalidation_data_path = \"\/kaggle\/working\/microsoft-catsvsdogs-dataset\/testing\/\"\n#Epochs\nepochs = 10\n#Batch size\nbatch_size=100\n#Learning Rate\nlearning_rate = 0.001","febe15bd":"''' #Basic parameters to be passed on call \n    #1.training_data_path\n    #2.validation_data_path\n    #3.callback\n    #4.epochs\n    #5.batch_size\n    #6.learning_rate\n'''\nnet = NeuralNet()\nhistory, model = net.neuralModeling(training_data_path, validation_data_path,callback, epochs, batch_size, learning_rate)","3e724460":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(len(acc))\nplt.figure(figsize=(17, 10))\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc=0)\nplt.show()","a13525ad":"import matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\nplt.figure(figsize=(17,10))\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc=0)\nplt.show()","8e5e40c5":"## Let's examine the scenario where augmentation before training can help better at prediction time","e3c2440f":"**Let's verify the data movement**","554f3677":"**Data set contains total of 12501 images and we will use Imagegenerator API of Keras so we need to restructure the directory accordingly.**","93dd8234":"## Model Training\n**Let's start the training the model and then run some image prediction directly from Google.com**","755a60fa":"**Few examples regarding how image augmentation looked like before going to model for training.**","f8bcab21":"Let's Do some basic augmentation and later we will apply various permutation and combination of these techniques. **Lets start with image rotation by few degrees so that features(Pixel values based on spatial arrangement) get affected and label unaffected.**","6a6f86bb":"* As kaggle does not allow us to do any create,delete or update within \"\/kaggle\/input\/\" let's copy the dataset to working directory.\n* Path of the working directory is \"\/kaggle\/working\" and it is easily doable via magic commands. :) ","7e0dcebe":"##### Dataset we are going to use in this experiment is to detect wether given image is a Cat or Dog","ee9133a1":"## What is Augmentation and how does it helps?\n**Data augmentation** is a technique to increase the size and variation in a given dataset.\nIt is a well known fact that **Deep Neural Nets** work best if Dataset is huge in both size and variety.\n\nOther Augumentation techniques which can be at root of such exploration is **SMOTE.**\n\n\nThis notebook will cover the aspect of Data Augumentation over Image Data.\nFocus will be on **Various techniques** to achieve **Data augmentation** \n\n\nwe will be using **Tensorflow** and **Keras** for implementation which will help us to understand the various aspect of the field.\n\nMore often when data is less in size of not having variety in it, Including **Data augmentation** in **Data preprocessing** steps, help producing larger amount of data with good amount of variety in it. \n","494b244f":"**Let's generate an UDF which would be helpful in plotting the various augmentated images from the source image.**","e5c5a531":"***Data augmentation does many changes on the fly in every image and makes a batch  before training to model.That is one of the prime reason that model training with data augmentation on is slower but effective.***\n\n","f07c49b5":"Imagine the situation that we have to assign a category to an image that it is a **cat** or **dog** is in the image.\nand in our sample data set, we have got such images where we have several cats and dogs lined up one after another.\n\nNow how can we play with such images on the fly before giving them to model to get trained on.\nBetter augment them on the fly and produce a batch of tensors.\n\nDoing the augmentation using **Keras** gives another upper hand to us, It doesn't modify or affect the original data source.","b1428fc0":"<br>\n<br>"}}