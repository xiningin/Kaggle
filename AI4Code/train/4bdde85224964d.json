{"cell_type":{"47517e4d":"code","4908f323":"code","e319c95e":"code","28432c56":"code","a2a4916f":"code","30c88fa7":"code","f55d82a1":"code","2a08222e":"code","286151a3":"code","1f323413":"code","76d0e41d":"code","b514de63":"code","43d953a7":"markdown","5b424f36":"markdown","091eaa4f":"markdown","9bb309b4":"markdown"},"source":{"47517e4d":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_validate\n\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4908f323":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        \ndata = pd.read_csv(path)\ndata.head()","e319c95e":"print(data.shape)","28432c56":"X = data.drop('class', axis=1)\nY = data['class']","a2a4916f":"def plot_col(col, hue=None,color=['red', 'lightgreen'], labels=None):\n    fig, ax = plt.subplots(figsize=(15, 7))\n    sns.countplot(col, palette=color, saturation=0.6, data=data, dodge=True, ax=ax)\n    ax.set(title = f\"Mushroom {col.title()} Quantity\", xlabel=f\"{col.title()}\", ylabel=\"Quantity\")\n    if labels!=None:\n        ax.set_xticklabels(labels)\n    if hue!=None:\n        ax.legend(('Poisonous', 'Edible'), loc=0)\n\n\nclass_dict = ('Poisonous', 'Edible')\nplot_col(col='class', labels=class_dict)","30c88fa7":"for column in X.columns:\n    tranformer = LabelEncoder()\n    X[column] = tranformer.fit_transform(X[column])","f55d82a1":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=26)","2a08222e":"models = {\n    \"SVC\":{\"model\":SVC() },\n    \"RandomForestClassifier\":{\"model\":RandomForestClassifier() },\n    \"Percepton\":{\"model\":Perceptron() },\n    \"MLPClassifier\":{\"model\":MLPClassifier() },\n    }","286151a3":"for name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train,cv = 10)\n    \n    # Mean accuracy and mean training time\n    mean_val_accuracy = round( sum(result['test_score']) \/ len(result['test_score']), 4)\n    mean_fit_time = round( sum(result['fit_time']) \/ len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['val_accuracy'] = mean_val_accuracy\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} accuracy : {mean_val_accuracy*100:.2f}% - mean training time {mean_fit_time} sec\")","1f323413":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['val_accuracy'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','val_accuracy','Training time (sec)'])\ndf_results.sort_values(by='val_accuracy', ascending=False, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","76d0e41d":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'val_accuracy', data = df_results)\nplt.title('Mean Validation Accuracy for each Model\\ny-axis between 0.8 and 1.0', fontsize = 15)\nplt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Accuracy',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()\n\nplt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","b514de63":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\nprint(f'## Best Model: {best_model[0]} with {accuracy_score(y_test,pred)*100} % accuracy on the test set')\n\nprint(classification_report(y_test,pred))\naccuracy_score(y_test,pred)\n\n# Display a confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (10,7))\nsns.heatmap(cf_matrix, annot=True, xticklabels = class_dict, yticklabels = class_dict,cbar=False)\nplt.title('Normalized Confusion Matrix', fontsize = 23)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nplt.show()","43d953a7":"## Conclusions\n\n* Perceptron was the fastest of all, but had the least accuracy. \n\n* MLPercepton and RandomForest had maximum accuracy, but RandomForest was more faster.","5b424f36":"## Data Preprocessing","091eaa4f":"## Model comparison using cross validation","9bb309b4":"## Prediction metrics of the best model using the test set"}}