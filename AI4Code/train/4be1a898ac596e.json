{"cell_type":{"7051ba08":"code","44f38fde":"code","53faaa4c":"code","658fab5e":"code","cb97685d":"code","4d21445d":"code","300422be":"code","143f444a":"code","f35c081f":"code","b3dc2626":"code","56015243":"markdown","8207130c":"markdown","53dbf7c3":"markdown","67520762":"markdown","b368e724":"markdown","b3ccee4b":"markdown","0be21d14":"markdown","85ece992":"markdown","d09b15af":"markdown","11efa95b":"markdown"},"source":{"7051ba08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44f38fde":"df_tweets = pd.read_csv(\"\/kaggle\/input\/indianeedsoxygen-tweets\/IndiaWantsOxygen.csv\")\nprint (df_tweets.shape)\ndf_tweets.head()","53faaa4c":"plt.figure(figsize=(14,8))\nsns.set(style='darkgrid')\nsns.countplot(y='user_location', data=df_tweets, order=df_tweets['user_location'].value_counts().index[:12], palette=\"Set2\")\nplt.xlabel(\"Number of Tweets\", weight='bold')\nplt.ylabel(\"User Location\", weight='bold')\nplt.show()","658fab5e":"dict_temp = dict(Counter(df_tweets['user_verified']))\ndict_temp['User Verified'] = dict_temp.pop(True)\ndict_temp['User Non-Verified'] = dict_temp.pop(False)\n\nplt.figure(figsize=(7,7))\nplt.pie(x=dict_temp.values(), labels=dict_temp.keys(), autopct='%1.1f%%', shadow=True, \n        startangle=0, explode = [0.1, 0])\nplt.show()","cb97685d":"dict_temp = df_tweets['source'].value_counts()[:3].to_dict()\ndict_temp['Others'] = 0\ndict_ = df_tweets['source'].value_counts().to_dict()\nfor key in dict_.keys():\n    if key not in dict_temp.keys():\n        dict_temp['Others'] += dict_[key]\n\nplt.figure(figsize=(7,7))\nplt.pie(x=dict_temp.values(), labels=dict_temp.keys(), autopct='%1.1f%%', shadow=True, \n        startangle=0)\nplt.show()","4d21445d":"plt.figure(figsize=(7,7))\nsns.heatmap(df_tweets[['user_followers', 'user_friends', 'user_favourites', 'user_verified']].corr(), center=0, annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()","300422be":"from datetime import datetime\ndf_tweets['date'] = pd.to_datetime(df_tweets['date'].str.split(' ', expand=True)[0], format='%Y-%m-%d')\n\nplt.figure(figsize=(14,8))\nsns.set(style='darkgrid')\nlist_ = [datetime.date(x) for x in df_tweets['date']]\nsns.countplot(x = list_, order=sorted(set(list_)), palette=\"Set2\")\nplt.xlabel(\"Date\", weight='bold')\nplt.ylabel(\"Number of Tweets\", weight='bold')\nplt.show()","143f444a":"import itertools\nfrom wordcloud import WordCloud\n\nlist_hashtags = df_tweets['hashtags'].dropna().str.lstrip('[').str.rstrip(']').str.replace(\"'\", \"\").str.split(', ').tolist()\nlist_hashtags = list(itertools.chain(*list_hashtags))\n\nwordcloud = WordCloud(background_color=\"black\", width=800, height=500, max_font_size=80, max_words=100, collocations = False, colormap='Set2').generate(\" \".join(list_hashtags))\nplt.figure(figsize=(16,12))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","f35c081f":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english') + list(punctuation))\ndf_temp = df_tweets[['text']].copy()\ndf_temp['text'] = df_temp['text'].str.lower()\ndf_temp['text'] = df_temp['text'].apply(word_tokenize)\ndf_temp['text'] = df_temp['text'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_temp['text'] = df_temp['text'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf_temp['text'] = df_temp['text'].apply(lambda x : [word for word in x if len(word) > 1])","b3dc2626":"list_text = df_temp['text'].tolist()\nlist_text = list(itertools.chain(*list_text))\n\nplt.figure(figsize=(16,12))\nwordcloud = WordCloud(background_color=\"black\", width=800, height=500, max_font_size=80, max_words=100, collocations = False, colormap='Set2').generate(' '.join(list_text))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","56015243":"# **Load the Dataset**","8207130c":"# **Feel free to <span style=\"color:red\"> Upvote <\/span> and give <span style=\"color:blue\"> Feedback <\/span>.**","53dbf7c3":"## **Heatmap (correlation) among different features**","67520762":"## **% of verified or non-verified accounts among the tweeters**","b368e724":"## **WordCloud of Hashtags**","b3ccee4b":"## **WordCloud of Tweets**","0be21d14":"## **Number of Tweets on each date**","85ece992":"# **EDA**","d09b15af":"## **Top 12 locations with highest number of Tweets**","11efa95b":"## **% of platform used for tweet**"}}