{"cell_type":{"bf7f8c1f":"code","14e74587":"code","ccd9d192":"code","404be547":"code","6661c804":"code","a1e7d6ad":"code","896a3860":"code","7248c261":"code","3f9458d9":"code","1080bc16":"code","d7d16497":"code","80bcf474":"code","e82d87f1":"code","bd7611f9":"code","d0493f85":"code","ee832ec6":"code","16582f26":"code","466e9c93":"code","10c50784":"code","7f2eeb3e":"code","25959af1":"code","ede85904":"code","503b7110":"code","462a459d":"code","c192c27d":"code","25539ed1":"code","1ce7d1f1":"code","25c97fc6":"code","e61f849e":"code","68f2bf49":"code","24a7d688":"code","d248d5d4":"code","0fe15583":"code","ccb6614f":"code","98c93a44":"code","a4f4fe95":"code","1133222e":"code","bb2ba68a":"code","e40193c9":"code","7a913266":"code","c8b45d41":"code","6d1b8309":"code","a7c70927":"code","7fb730a2":"code","d10b0f19":"code","44820359":"code","28a9de73":"code","47e8dfac":"code","c9fe3801":"code","d36ea002":"code","0a9a0a32":"code","81740e1f":"code","739948be":"code","33f5af34":"code","0096bc8c":"code","6a2a471d":"code","a5441593":"code","f29f981f":"code","37a8ebc6":"code","3951824e":"code","674923e8":"code","4e0c5cdf":"code","a9f3cd0a":"code","9df4dbf0":"code","0d0004d4":"code","a01900be":"code","37586846":"code","8b483921":"code","ec348045":"markdown"},"source":{"bf7f8c1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14e74587":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import scale\nfrom imblearn.over_sampling import SMOTE\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA","ccd9d192":"#Read the dataset\ndf = pd.read_csv('..\/input\/credit-card-customers\/BankChurners.csv')","404be547":"#Checkiing data size\ndf.shape","6661c804":"#Checking the top three rows of the df\ndf.head(3)","a1e7d6ad":"#now checking the bottom three rows\n\ndf.tail(3)","896a3860":"#dropping unwanted columns\ndf = df.drop(labels=['CLIENTNUM',\n                     'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n                     'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n                     axis=1)","7248c261":"#Checking data once more\ndf.head()","3f9458d9":"#Checking for NaN values\ndf.isna().sum()","1080bc16":"#Checking for Null values\ndf.isnull().sum()","d7d16497":"#Checking class distribution\nclass_counts = df.groupby('Attrition_Flag').size()\nprint(class_counts)","80bcf474":"print(float(class_counts['Attrited Customer']\/df.shape[0])*100)","e82d87f1":"print(df.skew(numeric_only=True))","bd7611f9":"colors = ['#DC3220','#40B0A6']\nclass_counts.plot(kind='pie',ylabel='Attrition_Flag',autopct='%1.1f%%',colors=colors)","d0493f85":"#Creating the attrited customers dataframe\ndf_att = df[df['Attrition_Flag']=='Attrited Customer']","ee832ec6":"#Creating the Existing customers dataframe\ndf_ext = df[df['Attrition_Flag']=='Existing Customer']","16582f26":"df.describe()","466e9c93":"def autolabels(ax):\n    rects = ax.patches\n    labels = [rects[i].get_height() for i in range(len(rects))]\n\n    for rect, label in zip(rects, labels):\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width() \/ 2, height + 5, label,\n                ha='center', va='bottom')","10c50784":"import matplotlib.patches as mpatches","7f2eeb3e":"# Creating proxy artists to use in Legend \next_patch = mpatches.Patch(color='#40B0A6', label='Existing Customer')\natt_patch = mpatches.Patch(color='#DC3220', label='Attrited Customer')","25959af1":"#Plotting Gender distribution\nax1 = df_ext.groupby('Gender').size().plot(kind='bar',color = '#40B0A6', rot = 0)\nautolabels(ax1)\nax2 = df_att.groupby('Gender').size().plot(kind='bar',color ='#DC3220', rot = 0)\nautolabels(ax2)\nplt.title(\"Gender\")\nplt.legend(handles=[ext_patch,att_patch],bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')","ede85904":"df_att.groupby('Gender')['Gender'].count()\/df_att.shape[0]","503b7110":"#Plotting Education Level distribution\nax1 = df_ext.groupby('Education_Level').size().plot(kind='bar',color = '#40B0A6', width=0.9, rot = 45)\nautolabels(ax1)\nax2 = df_att.groupby('Education_Level').size().plot(kind='bar',color ='#DC3220', width=0.9,rot = 45)\nautolabels(ax2)\nplt.title(\"Education Level\")\nplt.legend(handles=[ext_patch,att_patch],bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')","462a459d":"edu_PercAttr = (df_att.groupby('Education_Level').size()\/df_att.shape[0])*100\nedu_PercAttr","c192c27d":"#Plotting Marital_Status distribution\nax1 = df_ext.groupby('Marital_Status').size().plot(kind='bar',color = '#40B0A6', width=0.9, rot = 0)\nautolabels(ax1)\nax2 = df_att.groupby('Marital_Status').size().plot(kind='bar',color ='#DC3220', width=0.9,rot = 0)\nautolabels(ax2)\nplt.title(\"Marital Status\")\nplt.legend(handles=[ext_patch,att_patch],bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')","25539ed1":"#Plotting Income Category distribution\nax1 = df_ext.groupby('Income_Category').size().plot(kind='bar',color = '#40B0A6', width=0.9, rot = 45)\nautolabels(ax1)\nax2 = df_att.groupby('Income_Category').size().plot(kind='bar',color ='#DC3220', width=0.9,rot = 45)\nautolabels(ax2)\nplt.title(\"Income Category\")\nplt.legend(handles=[ext_patch,att_patch],bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')","1ce7d1f1":"#Which income groups show the highest level of attrition?\nincome_attr = (df_att.groupby('Income_Category').size()\/df_att.shape[0])*100\nprint(\"Attrited Customers - Income Category\",income_attr)","25c97fc6":"#Percentage distribution of Income Category in the original dataset\nprint((df.groupby('Income_Category').size()\/df.shape[0])*100)","e61f849e":"#Plotting Card Category distribution\nax1 = df_ext.groupby('Card_Category').size().plot(kind='bar',color = '#40B0A6', width=0.9, rot = 0)\nautolabels(ax1)\nax2 = df_att.groupby('Card_Category').size().plot(kind='bar',color ='#DC3220', width=0.9,rot = 0)\nautolabels(ax2)\nplt.title(\"Card Category\")\nplt.legend(handles=[ext_patch,att_patch],bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')","68f2bf49":"# What are the card categories of Attrited Customers\ncard_attr = (df_att.groupby('Card_Category').size()\/df_att.shape[0])*100\nprint(card_attr)","24a7d688":"#How much percentage of a certain card category has left?\ndf_att.groupby('Card_Category').size()\/df.groupby('Card_Category').size()","d248d5d4":"#Plotting Number of months inactive distribution\nax1 = df_ext.groupby('Months_Inactive_12_mon').size().plot(kind='bar',color = '#40B0A6', width=0.9, rot = 0)\nautolabels(ax1)\nax2 = df_att.groupby('Months_Inactive_12_mon').size().plot(kind='bar',color ='#DC3220', width=0.9,rot = 0)\nautolabels(ax2)\nplt.title(\"Months Inactive\")\nplt.legend(handles=[ext_patch,att_patch],bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')","0fe15583":"#Median months inactive by existing and attrited customers\ndf.groupby('Attrition_Flag')['Months_Inactive_12_mon'].median()","ccb6614f":"df.skew()","98c93a44":"(df.groupby('Card_Category')['Total_Trans_Amt'].sum()\/df['Total_Trans_Amt'].sum())*100","a4f4fe95":"df.groupby('Card_Category')['Total_Trans_Amt'].sum(),df['Total_Trans_Amt'].sum()","1133222e":"df.groupby('Attrition_Flag')['Months_Inactive_12_mon'].median()","bb2ba68a":"#Plotting Density plots\nfig, ax = plt.subplots(figsize=(14,10))\ndf.plot(kind='density',subplots = True, layout=(5,3),sharex=False, ax = ax)","e40193c9":"df.cov()","7a913266":"#Age distribution\nc={'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'}\ndf.groupby('Attrition_Flag')['Customer_Age'].plot.hist(color=c, alpha=0.5)\nplt.title(\"Customer Age - Histogram\")\nplt.legend()","c8b45d41":"#Months on book\nc={'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'}\ndf.groupby('Attrition_Flag')['Months_on_book'].plot.hist(color=c, alpha=0.5)\nplt.title('Months on Book - Histogram')\nplt.legend()","6d1b8309":"#Creating a df of transaction variables\ndf_trans = df[['Credit_Limit','Total_Revolving_Bal','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1','Avg_Utilization_Ratio','Attrition_Flag']]","a7c70927":"df_trans = df_trans.replace({'Attrited Customer':1,'Existing Customer':0})","7fb730a2":"correlations = df_trans.corr()","d10b0f19":"#plotting heatmap\nax = sns.heatmap(\n    correlations,\n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    annot=True,\n    fmt='.1g'\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation = 45,\nhorizontalalignment = 'right'\n);","44820359":"df_selected = df[['Total_Revolving_Bal','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1','Avg_Utilization_Ratio','Attrition_Flag']]","28a9de73":"sns.pairplot(df_selected, hue='Attrition_Flag',palette = {'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'})","47e8dfac":"#Box plot of Total Transactions\nsns.boxplot(x=df['Attrition_Flag'],y=df['Total_Trans_Ct'],\n            hue=df['Attrition_Flag'], palette={'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'}\n            )\nsns.despine(offset=10, trim=True)","c9fe3801":"df.groupby('Attrition_Flag')['Total_Trans_Ct'].describe()","d36ea002":"#Box plot of Total_Ct_Chng_Q4_Q1\nsns.boxplot(x=df['Attrition_Flag'],y=df['Total_Ct_Chng_Q4_Q1'],\n            hue=df['Attrition_Flag'], palette={'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'}\n            )\nsns.despine(offset=10, trim=True)","0a9a0a32":"df.groupby('Attrition_Flag')['Total_Ct_Chng_Q4_Q1'].describe()","81740e1f":"df[df['Total_Ct_Chng_Q4_Q1']==0]['Attrition_Flag']","739948be":"#Box plot of Avg_Utilization_Ratio\nsns.boxplot(x=df['Attrition_Flag'],y=df['Avg_Utilization_Ratio'],\n            hue=df['Attrition_Flag'], palette={'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'}\n            )\nsns.despine(offset=10, trim=True)","33f5af34":"df.groupby('Attrition_Flag')['Avg_Utilization_Ratio'].describe()","0096bc8c":"df.groupby('Attrition_Flag')['Avg_Utilization_Ratio'].median()","6a2a471d":"df_att['Avg_Utilization_Ratio'].mean()","a5441593":"#Box plot of Total_Revolving_Bal\nsns.boxplot(x=df['Attrition_Flag'],y=df['Total_Revolving_Bal'],\n            hue=df['Attrition_Flag'], palette={'Existing Customer':'#40B0A6','Attrited Customer':'#DC3220'}\n            )\nsns.despine(offset=10, trim=True)","f29f981f":"df.groupby('Attrition_Flag')['Total_Revolving_Bal'].describe()","37a8ebc6":"df.groupby('Attrition_Flag')['Total_Revolving_Bal'].median()","3951824e":"df_chosen = df[['Total_Trans_Ct', 'Total_Revolving_Bal',\n                'Avg_Utilization_Ratio', 'Attrition_Flag']]","674923e8":"# print description of selected features\nprint(\"Description of selected features: \\n\", df_chosen.describe())\n\n# print description of each selected variable split by Target\nprint(\"Total_Trans_Ct : \\n\", df.groupby(\n    'Attrition_Flag')['Total_Trans_Ct'].describe(), \"\\n\")\nprint(\"Total_Revolving_Bal: \\n\", df.groupby(\n    'Attrition_Flag')['Total_Revolving_Bal'].describe(), \"\\n\")\nprint(\"Avg_Utilization_Ratio: \\n\", df.groupby(\n    'Attrition_Flag')['Avg_Utilization_Ratio'].describe(), \"\\n\")","4e0c5cdf":"#Visualising the chosen dimensions - Scatterplot with Target shaded by colour\n\nsns.pairplot(df_chosen, hue='Attrition_Flag', diag_kind=\"hist\", palette={\n    'Existing Customer': '#40B0A6', 'Attrited Customer': '#DC3220'})\nplt.show()","a9f3cd0a":"# creating a list of chosen dimensions\nxl = list(df_chosen['Total_Trans_Ct'])\nyl = list(df_chosen['Total_Revolving_Bal'])\nzl = list(df_chosen['Avg_Utilization_Ratio'])\ndata_points = [(x, y, z) for x, y, z in zip(xl, yl, zl)]","9df4dbf0":"# setting Target colours\ncolors = ['#40B0A6' if flag == 'Existing Customer' else '#DC3220' for flag in list(\n    df_chosen['Attrition_Flag'])]","0d0004d4":"def plotter(data_points, title, xlabel, ylabel, zlabel):\n    fig = plt.figure(figsize=(12, 8))\n    ax = fig.add_subplot(111, projection='3d')\n\n    for data, color in zip(data_points, colors):\n        x, y, z = data\n        ax.scatter(x, y, z, alpha=0.9, c=color, edgecolors='white', s=30)\n\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_zlabel(zlabel)\n    ax.set_title(title)\n    plt.show()\n\n\ndef plotCumExplVar(ve, title):\n    plt.plot(ve.cumsum())\n    plt.title(title)\n    plt.xlabel('Principal Component')\n    plt.xticks(np.arange(0, 3, step=1), ['PC1', 'PC2', 'PC3'])\n    plt.ylabel('Cumulative Explained Variance')\n    plt.show()\n\n\nplotter(data_points, '3D Plot of chosen Dimensions \u2013 Target shaded by colour', 'Total_Trans_Ct',\n        'Total_Revolving_Bal', 'Avg_Utilization_Ratio')","a01900be":"# PCA on scaled data\n# Normalise dimensions to a zero mean and unit SD\nscaled_data = scale(data_points)  # Scales and centers the data\n\n# Do PCA on scaled data\npca_scaled = PCA(n_components=3)\nscaled_pc_data = pca_scaled.fit_transform(scaled_data)\nprint(\"Scenario 1: PCA on scaled data. Constructing PC Outputs...\")\nplotter(scaled_pc_data, 'PCA on scaled data - Scatter Plot', '1st eigenvector',\n        '2nd eigenvector', '3rd eigenvector')\n\n# Explained variance\n# Gives proportion of variance explained for each principal component\nvar_explained = pca_scaled.explained_variance_ratio_\nprint(\"PCA on scaled data - Explained Variance :\", var_explained)\nprint(\"Constructing Cumulative Explained Variance plot...\")\nplotCumExplVar(\n    var_explained, 'PCA on scaled data - Cumulative Explained Variance')\n\n# printing PCA components breakdown\nprint(\"PCA Components (Scaled data) : \", pca_scaled.components_)","37586846":"# Do PCA on unscaled data\npca_unscaled = PCA(n_components=3)\nunscaled_pc_data = pca_unscaled.fit_transform(data_points)\nprint(\"Scenario 2: PCA without scaling. Constructing PC Outputs...\")\nplotter(unscaled_pc_data, 'PCA on original data (without scaling) - Scatter Plot', '1st eigenvector',\n        '2nd eigenvector', '3rd eigenvector')\n\n# Explained variance\n# Gives proportion of variance explained for each principal component\nvar_explained = pca_unscaled.explained_variance_ratio_\nprint(\"PCA on original data (without scaling) - Explained Variance :\", var_explained)\nprint(\"Constructing Cumulative Explained Variance plot...\")\nplotCumExplVar(\n    var_explained, 'PCA on original data (without scaling) - Cumulative Explained Variance')\n# printing PCA components breakdown\nprint(\"PCA Components (Original data) : \", pca_unscaled.components_)","8b483921":"# using SMOTE to address class imbalance\n\nX = df_chosen.iloc[:, :-1]\nY = df_chosen.iloc[:, -1:]\n\nsm = SMOTE(sampling_strategy='auto', random_state=1234)\nx_sm, y_sm = sm.fit_resample(X, Y)\n\n# Checking class counts\nclass_counts = y_sm.groupby('Attrition_Flag').size()\nprint(class_counts)\n\n# Plotting class distribution\ncolors = ['#DC3220', '#40B0A6']\nclass_counts.plot(kind='pie', ylabel='Attrition_Flag',\n                  autopct='%1.1f%%', colors=colors)\nplt.show()\n\n# constructing a list of resampled datapoints\nxl = list(x_sm['Total_Trans_Ct'])\nyl = list(x_sm['Total_Revolving_Bal'])\nzl = list(x_sm['Avg_Utilization_Ratio'])\ndata_points = [(x, y, z) for x, y, z in zip(xl, yl, zl)]\n\n# Visualising the resampled data\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111, projection='3d')\n\n# Do PCA on re-sampled balanced data\npca_balanced = PCA(n_components=3)\nbalanced_pc_data = pca_balanced.fit_transform(data_points)\n\nprint(\"Scenario 3: PCA on balanced data (after SMOTE). Constructing PC Outputs...\")\n\ncolors = ['#40B0A6' if flag == 'Existing Customer' else '#DC3220' for flag in list(\n    y_sm['Attrition_Flag'])]\nfor data, color in zip(balanced_pc_data, colors):\n    x, y, z = data\n    ax.scatter(x, y, z, alpha=0.9, c=color, edgecolors='white', s=30)\n\nax.set_title('PCA on balanced data (after SMOTE) - Scatter Plot')\nax.set_xlabel('Total_Trans_Ct')\nax.set_ylabel('Total_Revolving_Bal')\nax.set_zlabel('Avg_Utilization_Ratio')\nplt.show()\n\n# Explained variance\n# Gives proportion of variance explained by each principal component\nvar_explained_balanced = pca_balanced.explained_variance_ratio_\nprint(\"PCA on balanced data (after SMOTE) - Explained Variance :\",\n      var_explained_balanced)\nprint(\"Constructing Cumulative Explained Variance plot...\")\nplotCumExplVar(\n    var_explained_balanced, 'PCA on balanced data (after SMOTE) - Cumulative Explained Variance')\n\n# printing PCA components breakdown\nprint(\"PCA Components (Balanced data) : \", pca_balanced.components_)","ec348045":"**Numerical Variables Analysis:**"}}