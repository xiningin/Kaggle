{"cell_type":{"bc00147b":"code","2a443b6a":"code","1de47dda":"code","a206d408":"code","07d3c815":"code","27d4a326":"code","6f2189cd":"code","0a3382e6":"code","52829b01":"code","f889b0b5":"code","6631a9e1":"code","e1a65a4e":"code","35bc4b3c":"code","40a84488":"code","0aeeecbe":"code","1ae051c8":"code","cae30afe":"code","41920ffb":"code","29de8b46":"code","91fe89a6":"code","dff0df48":"code","862ad4a8":"code","dea1a90e":"code","f0d32731":"markdown","5fadc341":"markdown","b414249a":"markdown","e0854c62":"markdown","04909df6":"markdown","d46fbae6":"markdown","2e012800":"markdown","606ae9c0":"markdown","e7f84b19":"markdown","0a745046":"markdown","99f73738":"markdown","0b4e4091":"markdown","392eca55":"markdown","ecde30c6":"markdown","1abb4d71":"markdown"},"source":{"bc00147b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2a443b6a":"path = '\/kaggle\/input\/g2net-gravitational-wave-detection\/'\nos.listdir(path)","1de47dda":"train_labels = pd.read_csv(path+'training_labels.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","a206d408":"print('Number train samples:', len(train_labels))\nprint('Number submission samples:', len(samp_subm))","07d3c815":"train_labels.head()","27d4a326":"def plot_data(data):\n    \"\"\" Plot 3 Detections of data array\"\"\"\n    \n    fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n    axs = axs.ravel()\n    for i in range(3):\n        x = range(len(data[i]))\n        y = data[i]\n        axs[i].plot(x, y)\n        axs[i].grid()\n        axs[i].set_title('Detection '+str((i+1)))","6f2189cd":"id_ = train_labels.loc[0, 'id']\nid_","0a3382e6":"path_in = '\/'.join([path, 'train', id_[0], id_[1], id_[2]])+'\/'\nfile = id_+'.npy'","52829b01":"data_array = np.load(path_in+file)\ndata_array.shape","f889b0b5":"plot_data(data_array)","6631a9e1":"list_IDs_train, list_IDs_val = train_test_split(list(train_labels.index), test_size=0.33, random_state=2021)\nlist_IDs_test = list(samp_subm.index)","e1a65a4e":"print('Number train samples:', len(list_IDs_train))\nprint('Number val samples:', len(list_IDs_val))\nprint('Number test samples:', len(list_IDs_test))","35bc4b3c":"batch_size = 64","40a84488":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, data, batch_size):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.data = data\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)\/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, 3, 4096))\n        y = np.zeros((self.batch_size, 1))\n        for i, ID in enumerate(list_IDs_temp):\n            id_ = self.data.loc[ID, 'id']\n            file = id_+'.npy'\n            path_in = '\/'.join([self.path, id_[0], id_[1], id_[2]])+'\/'\n            data_array = np.load(path_in+file)\n            data_array = (data_array-data_array.mean())\/data_array.std()\n            X[i, ] = data_array\n            y[i, ] = self.data.loc[ID, 'target']\n        return X, y","0aeeecbe":"train_generator = DataGenerator(path+'train\/', list_IDs_train, train_labels, batch_size)\nval_generator = DataGenerator(path+'train\/', list_IDs_val, train_labels, batch_size)\ntest_generator = DataGenerator(path+'test\/', list_IDs_test, samp_subm, batch_size)","1ae051c8":"epochs = 1\nlernrate = 2e-4","cae30afe":"model = Sequential()\nmodel.add(Conv1D(64, input_shape=(3, 4096,), kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","41920ffb":"model.compile(optimizer = Adam(lr=lernrate),\n              loss='binary_crossentropy',\n              metrics=['acc'])","29de8b46":"model.summary()","91fe89a6":"history = model.fit_generator(generator=train_generator, validation_data=val_generator, epochs = epochs, workers=4)","dff0df48":"predict = model.predict_generator(test_generator, verbose=1)","862ad4a8":"samp_subm['target'] = predict[:len(samp_subm)]","dea1a90e":"samp_subm.to_csv('submission.csv', index=False)","f0d32731":"# Load Data","5fadc341":"# Export","b414249a":"# Libraries","e0854c62":"# EDA\n*Coming Soon*","04909df6":"# Train, Val And Test Data","d46fbae6":"# Overview","2e012800":"# Path","606ae9c0":"Predict test data","e7f84b19":"# Focus On Example Sample\nWe consider the first example of the train data. To get familiar with npy-files we consider [this article](https:\/\/towardsdatascience.com\/what-is-npy-files-and-why-you-should-use-them-603373c78883).","0a745046":"# Data Generator\nWe define a data generator to define the data on demand.","99f73738":"Each data sample (npy file) contains 3 time series (1 for each detector) and each spans 2 sec and is sampled at 2,048 Hz.","0b4e4091":"# Intro\nWelcome to the [](https:\/\/www.kaggle.com\/c\/g2net-gravitational-wave-detection\/overview) compedition\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/23249\/logos\/header.png)\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","392eca55":"# Define Model","ecde30c6":"# Functions\nWe define some helper functions.","1abb4d71":"The first 3 characters are used for the path:"}}