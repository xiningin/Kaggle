{"cell_type":{"be5e7235":"code","69be28d8":"code","6366955b":"code","9a46b64e":"code","2025244f":"code","64a2f07c":"code","3ccf9f65":"code","dca84dd3":"code","41934268":"code","802d965c":"code","4c44c3fd":"code","5a04f95f":"code","e1aac543":"code","efa6660f":"code","36ca2af4":"code","3c22b1ce":"code","d391cac9":"code","c3e07db2":"code","37d95124":"code","b0b86bb5":"code","e5ae55a8":"code","a2cee410":"code","07b322f0":"code","3585b236":"code","39e4f15b":"code","8abaf579":"code","174f8c04":"code","2e0ed7ff":"code","7a13290e":"code","0ee2866d":"code","607fa1fb":"code","778afd93":"code","301f9b85":"code","73643f61":"code","ebc78c97":"code","aca116ab":"code","5eb59fc2":"code","33fd6125":"code","f154729a":"code","2b4e924b":"code","9eaf5065":"code","a33e21f6":"code","13b79420":"code","dba57801":"code","5bcc79a2":"code","8ed2606f":"markdown","b0667f69":"markdown","1988352e":"markdown","70025847":"markdown","1c316231":"markdown","42985972":"markdown","ef854a5a":"markdown","a0829cdd":"markdown","dae59e9c":"markdown","c09655cc":"markdown","1d2eb1d2":"markdown","7178a8b4":"markdown","e1395164":"markdown","48f6760e":"markdown","cd381816":"markdown","df06f65a":"markdown","e13228b4":"markdown","af3e10d6":"markdown","9caeb249":"markdown","80b2b2c8":"markdown","126f78c0":"markdown","b46ae500":"markdown","dbac970d":"markdown","1ad5279f":"markdown","b8196f3e":"markdown","60c1d11e":"markdown","0ce89d51":"markdown","71df4097":"markdown","907e7006":"markdown","11568ade":"markdown","834a6125":"markdown","273c7a23":"markdown","840f0310":"markdown","37f25cc3":"markdown","da7dd6fb":"markdown","1cc757e2":"markdown","13e22ead":"markdown","3d6126e8":"markdown","a0b27c39":"markdown","d2d1b307":"markdown","e64b1344":"markdown","5f396a1a":"markdown","64e64404":"markdown","cdc65d18":"markdown","3bcb4711":"markdown","838bf4bb":"markdown","a798862a":"markdown","f89f2b17":"markdown","e4d2227f":"markdown","302d87fd":"markdown","ba1e87c3":"markdown","06b5fd25":"markdown","86acf275":"markdown","9f61cb45":"markdown","1c03f288":"markdown","c8e8e480":"markdown","e435ca2b":"markdown","b5fcb2a6":"markdown","539f0035":"markdown","712cceba":"markdown","2ab0af69":"markdown","174edec5":"markdown","2dd6053d":"markdown","6ecae084":"markdown","aeaafb94":"markdown","b33bae59":"markdown","ce5ab213":"markdown","b284edb6":"markdown","78890ca9":"markdown","f2ce2ee4":"markdown","22151e04":"markdown","9762a53a":"markdown","d71d4ed8":"markdown","79816ea0":"markdown","9d7f65cc":"markdown","1e60ccc8":"markdown","ad9f355e":"markdown","7566bf91":"markdown","2a2ba5cd":"markdown","28786de1":"markdown","770e53ec":"markdown","1886f9f2":"markdown","355bc0cc":"markdown","5fcd0976":"markdown","e89e1969":"markdown","e6cc8933":"markdown","f6b4fe68":"markdown","4f9dcf5a":"markdown"},"source":{"be5e7235":"# Library for parsing Names\n!pip install nameparser -q","69be28d8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# To Trigger code autocompletion on Tab\n%config Completer.use_jedi = False\n\n# Titanic File Paths\nTRAIN_PATH = '..\/input\/titanic\/train.csv'\nTEST_PATH = '..\/input\/titanic\/test.csv'\n\nSEED = 42\nFOLDS = 10","6366955b":"# Load the files\ndf_train = pd.read_csv(TRAIN_PATH)\ndf_test = pd.read_csv(TEST_PATH)","9a46b64e":"df_train.info()","2025244f":"plt.figure(figsize = (8,6))\nplt.hist(df_train['Pclass'])\nplt.xticks([1,2,3])\nplt.xlabel('Pclass')\nplt.ylabel('Passenger Count')\nplt.title('Passenger Count vs Pclass')\nplt.show()","64a2f07c":"pd.crosstab(df_train.Survived, df_train.Pclass, normalize = 'columns').apply(lambda r:round(r*100,2), axis = 1).style.background_gradient(cmap='summer_r')","3ccf9f65":"for label_ in df_train['Survived'].unique():\n    plt.hist(df_train[df_train['Survived'] == label_]['Pclass'], label = label_ , alpha = 0.5)\nplt.xticks(range(1,4))\nplt.xlabel('Pclass')\nplt.ylabel('Passenger Count')\nplt.title('Passenger Count:Survived vs Pclass')\nplt.legend()\nplt.show()","dca84dd3":"from nameparser import HumanName\nsample_name = df_train.iloc[0].Name\nprint(sample_name)\n# Parse the name\nHumanName(sample_name)","41934268":"from nameparser import HumanName\n\ndef get_titles(name):\n    title = HumanName(name).title\n    if title:\n        return title\n    return np.nan\n\ndf_train['title'] = df_train.Name.map(get_titles)\n\ndf_test['title'] = df_test.Name.map(get_titles)\n\ndf_train['title'].value_counts()","802d965c":"for label_ in df_train['Survived'].unique():\n    plt.hist(df_train[df_train['Survived'] == label_]['Sex'], label = label_ , alpha = 0.5)\nplt.legend()\nplt.xlabel('Gender')\nplt.ylabel('Survival Count')\nplt.title('Survival Count vs Gender')\nplt.show()","4c44c3fd":"sns.catplot(x = 'Pclass', y = 'Survived', data = df_train, hue = 'Sex', kind = 'point', seed = SEED)\nplt.show()","5a04f95f":"sns.kdeplot(df_train['Age'], fill = True);","e1aac543":"palette ={0: \"#F93838\", 1: \"#0C66F7\"}\nsns.catplot(x = 'Sex', y = 'Age', hue = 'Survived', col = 'Pclass', data = df_train, kind = 'violin', split = True, palette=palette, seed = SEED)\nplt.ylim([0,110]);","efa6660f":"sns.kdeplot(df_train['SibSp'], fill = True);","36ca2af4":"sns.catplot(x = 'SibSp', y = 'Survived', kind = 'point', data = df_train, seed = SEED)\nplt.title('Survival vs SibSp');","3c22b1ce":"sns.catplot(x = 'Parch', y = 'Survived', kind = 'point', data = df_train, seed = SEED)\nplt.title('Number of Parents\/Children vs SibSp');","d391cac9":"sns.kdeplot('Fare', data = df_train, fill = True);","c3e07db2":"sns.catplot(x = 'Survived', y = 'Fare', data = df_train, kind = 'violin', palette = palette, seed = SEED)\nplt.title('Fare vs Survival');","37d95124":"df_train.sample(10, random_state =  SEED).Cabin","b0b86bb5":"sns.countplot(x = 'Embarked', data = df_train);","e5ae55a8":"sns.catplot(x = 'Embarked', y = 'Survived', data = df_train, kind = 'point', seed = SEED)\nplt.title('Survival vs Port of Embarkment');","a2cee410":"pd.crosstab(index = [df_train.Survived, df_train.Embarked], columns = df_train.Pclass).style.background_gradient(cmap='summer_r')","07b322f0":"df_train.info()","3585b236":"df_train.drop('Cabin', axis = 1, inplace = True)\ndf_test.drop('Cabin', axis = 1, inplace = True)","39e4f15b":"# Calculate mean ages across different titles\ntitles = ['Mr.','Miss.','Mrs.','Master.']\nmean_ages = dict()\nfor title in titles:\n    mean_ages[title] = round(np.mean(df_train[df_train['title'] == title]['Age']))\nprint(mean_ages)","8abaf579":"def fix_title(row):\n    title = row.title\n    gender = row.Sex\n    age = row.Age\n    # If missing age and title, default to 'Mr.' & 'Mrs.'\n    if not age and not title:\n        if gender == 'male':\n            row.title = 'Mr.'\n        else:\n            row.title = 'Mrs.'\n    # Select appropriate according to their age\n    else:\n        if age and (title not in mean_ages.keys()):\n            if gender == 'male':\n                row.title = 'Master.' if age <= mean_ages['Master.'] else 'Mr.'\n            else:\n                row.title = 'Miss.' if age <= mean_ages['Miss.'] else 'Mrs.'\n    return row\n\ndf_train = df_train.apply(fix_title, axis = 1)\n\n# Do the same for test\ndf_test = df_test.apply(fix_title, axis = 1)\n\nprint(df_train.title.isna().any())","174f8c04":"def fix_age(row):\n    if pd.isna(row.Age):\n        row.Age = mean_ages[row.title]\n    return row\n\ndf_train = df_train.apply(fix_age, axis = 1)\ndf_test = df_test.apply(fix_age, axis = 1)\n\nprint(df_train.Age.isna().any())","2e0ed7ff":"df_train[df_train.isna().any(axis = 1)]","7a13290e":"df_train.fillna({'Embarked' : 'S'}, inplace = True)\ndf_test.fillna({'Embarked' : 'S'}, inplace = True)","0ee2866d":"df_test[df_test.isna().any(axis = 1)]","607fa1fb":"df_test.fillna({'Fare' : np.mean(df_train['Fare'])}, inplace=True)","778afd93":"print(df_train.isna().any() | df_test.isna().any())","301f9b85":"# Set index to passenger id\ndf_train.set_index('PassengerId', inplace = True)\ndf_test.set_index('PassengerId', inplace = True)\n\ndf_train['family'] = df_train['SibSp'] + df_train['Parch']\ndf_test['family'] = df_test['SibSp'] + df_test['Parch']\n\n\ncolumns_to_drop = ['Name','Ticket','SibSp','Parch']\ndf_train.drop(columns_to_drop, axis = 1, inplace = True)\ndf_test.drop(columns_to_drop, axis = 1, inplace = True)\n\ndf_train.head()","73643f61":"sns.catplot(x = 'family', y = 'Survived', kind = 'point', data = df_train, seed = SEED);","ebc78c97":"def bin_family(df):\n    df['Alone'] = df['family'].map(lambda s: 1 if s == 0 else 0)\n    df['SmallF'] = df['family'].map(lambda s: 1 if s == 1 else 0)\n    df['MediumF'] = df['family'].map(lambda s: 1 if 2 <= s <= 3 else 0)\n    df['LargeF'] = df['family'].map(lambda s: 1 if s >= 4 else 0)\n    df.drop('family', inplace = True, axis = 1)\n    return df\n\ndf_train = bin_family(df_train)\ndf_test = bin_family(df_test)\n\ndf_train.head()","aca116ab":"farebins = 10\ndf_train['fare_grp'] = pd.qcut(df_train['Fare'], farebins, labels = range(farebins))\ndf_test['fare_grp'] = pd.qcut(df_test['Fare'], farebins, labels = range(farebins))\ndf_train.drop('Fare', inplace = True, axis = 1)\ndf_test.drop('Fare', inplace = True, axis = 1)\n\nplt.figure(figsize = (12,6))\nsns.countplot(x = 'fare_grp',hue='Survived', data = df_train)\nplt.xlabel('Fare Group')\nplt.ylabel('Count')\nplt.title('Survival Count vs Fare Groups');","5eb59fc2":"agebins = 5\ndf_train['age_grp'] = pd.cut(df_train['Age'], agebins, labels = range(agebins))\ndf_test['age_grp'] = pd.cut(df_test['Age'], agebins, labels = range(agebins))\ndf_train.drop('Age', inplace = True, axis = 1)\ndf_test.drop('Age', inplace = True, axis = 1)\n\nplt.figure(figsize = (12,6))\nsns.countplot(x = 'age_grp',hue='Survived', data = df_train)\nplt.xlabel('Age Group')\nplt.ylabel('Count')\nplt.title('Survival Count vs Age Groups');","33fd6125":"df_train.head()","f154729a":"def encode_and_bind(original_dataframe, feature_to_encode):\n    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n    res = pd.concat([original_dataframe, dummies], axis=1)\n    res = res.drop([feature_to_encode], axis=1)\n    return(res) \n\nto_encode = ['Sex','Embarked','title', 'fare_grp', 'age_grp']\n\nfor feature in to_encode:\n    df_train = encode_and_bind(df_train, feature)\n    df_test = encode_and_bind(df_test, feature)\n\ndf_train.head()","2b4e924b":"x = df_train.loc[:,df_train.columns != 'Survived']\ny = df_train.loc[:,'Survived']","9eaf5065":"from sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nmodel_scores = pd.DataFrame(columns=['Model Name','Score Mean','Score Stddev'])\n\nsgd_clf = make_pipeline(StandardScaler(), SGDClassifier(random_state = SEED))\nlin_svc = make_pipeline(StandardScaler(), LinearSVC(loss = 'hinge', random_state = SEED))\ndt_clf =  DecisionTreeClassifier(random_state = SEED)\nrf_clf = RandomForestClassifier(random_state = SEED)\ngb_clf = GradientBoostingClassifier(random_state = SEED)\n\nall_models = [sgd_clf, lin_svc, dt_clf, rf_clf, gb_clf]\nnames = ['SGDClassifier','LinearSVC','DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier']\n\nfor model,name in zip(all_models, names):\n    score = cross_validate(model, x, y, scoring = 'accuracy', cv = 10, n_jobs = -1)\n    mean_score = score['test_score'].mean()\n    std_score = score['test_score'].std()\n    model_scores = model_scores.append({'Model Name' : name,'Score Mean' : mean_score\n                                       ,'Score Stddev' : std_score}, ignore_index=True)\n\nmodel_scores.sort_values('Score Mean', ascending=False, inplace=True)\nmodel_scores.style.background_gradient(cmap='summer_r')","a33e21f6":"from sklearn.model_selection import GridSearchCV\n\ngs = True\n\nif gs:\n    param_grid = {\n        'n_estimators' : [1800],\n        'max_features' : [16],\n        'random_state' : [SEED],\n        'max_depth' :  [13],\n        'min_samples_split' : [2,4],\n        'min_samples_leaf' : [2,3]\n    }\n\n    grid_search_rf = GridSearchCV(rf_clf, param_grid, cv = 10, refit=True)\n    grid_search_rf.fit(x,y)\n    print(f'Best Parameters: {grid_search_rf.best_params_}')\n    print(f'Best Score: {grid_search_rf.best_score_}')","13b79420":"rf_clf = RandomForestClassifier(max_features=16, n_estimators=1800, random_state=SEED, max_depth = 13, min_samples_leaf = 2, min_samples_split = 2)\nrf_clf.fit(x, y)","dba57801":"predictions = rf_clf.predict(df_test)\noutput = pd.DataFrame({'PassengerId': df_test.index, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","5bcc79a2":"output.head()","8ed2606f":"## Age","b0667f69":"**We want to see how much role `Age, sex & Pclass` play role in determing survival of an individual.<br>\nWe will create a `catplot` spanning multiple plots for a specific category(Pclass).**","1988352e":"As visualized by the `Fare` graph in EDA, let's do binning to categorise the continuous variable `Fare`.<br>\n(For continuous variables, either **normalization** or **binning** can be done, For the purpose of this notebook, we'll do binning).<br>\nBinning is nothing but categorising a continuous variable into some buckets.<br>\n\nIn pandas you can use `pd.cut` or `pd.qcut`\n* `pd.cut` divides the continuous variable such that each bins's size would be same.A bin may be even empty\/not.<br>\n   If the range of a `variable` is `[0,100]` and `pd.cut(variable, bins = 5)` the 5 bins would be `0-19,20-39,40-59,60-79,80-99`.<br> Here the bins don't \n   depend on the distribution of `variable` and a bin may contain 0\/more examples.\n* `pd.qcut` divides the continuous variable such that each bin will have the the same amount of observations. Every bin will approximately contain the same      amount of examples. Simplest example would be the quantiles(25%,50%,75%) that are visible when performing `variable.describe()`, those are the simplest \n   example of `pd.qcut(variable, q = 4)`. **4 bins**.\n \nA detailed article [here](https:\/\/pbpython.com\/pandas-qcut-cut.html).\n<br><br>\nFor our purpose, we will use `pd.qcut` as we want the fare group to be divided according to the population to reflect the trend not the opposite.\nIf we use `pd.cut` it will not represent the distribution of the population.","70025847":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>Modelling<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","1c316231":"**Finally, no missing values\ud83d\ude80**","42985972":"**Number of siblings\/spouses present.**","ef854a5a":"We'll fill the `Nan` Ages with mean according to their `title`.","a0829cdd":"**It seems the female gender has a very high survival rate compared to the other gender.**","dae59e9c":"<h1><center>Titanic\ud83d\udea2 Approach & Modelling<\/center><\/h1>","c09655cc":"Seems people who started their journey from `Cherbourg` had a very high rate of survival. Let's investigate this further.","1d2eb1d2":"Most of the Fare lies between `0-50`.","7178a8b4":"### \ud83d\udca1 What can a name tell us? Let's use a parser to see what it can tell us","e1395164":"Now that we have did an EDA, let's clean the data and add\/remove some features.","48f6760e":"<h2 style=\"background-color:#44AF69; color:white;\"><center>SibSp<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","cd381816":"### It is evident from the plot that no matter what the `Pclass` was, the `female` gender had the highest survival ratio.<br>Infact the 1st Pclass females have almost `1.0 Survival Ratio`.","df06f65a":"1. [Prerequisites](#Prerequisites)\n2. [EDA of Each Feature](#EDA-of-Each-Feature)\n    - [PClass](#Pclass---Ticket-class)\n    - [Name](#Name)\n    - [Sex](#Sex)\n    - [Age](#Age)\n    - [SibSp](#SibSp)\n    - [Parch](#Parch)\n    - [Fare](#Fare)\n    - [Cabin](#Cabin)\n    - [Embarkment](#Embarkment)\n3. [Data Processing](#Data-Processing)\n4. [Feature Engineering](#Feature-Engineering)\n5. [Modelling](#Modelling)\n6. [Hyperparameter Tuning](#Hyperparameter-Tuning)\n7. [References](#References)","e13228b4":"#### **We can confirm the % from above in this plot.**","af3e10d6":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Cabin<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","9caeb249":"**There are a lot of titles, Let's restrict the titles just to `Mr., Miss., Mrs., Master.`<br>\nWe need this to fix the `Ages`.<br>\nReplace `Nan` `Titles` taking their age & gender into consideration.<br>\nIf no `age` & `title`, fill it according to `gender`.**","80b2b2c8":"**A good way to compare is to see how much % from each of the three classes survived and how many did not.<br>\nWe can do this using `pd.crosstab` - This is useful for counting\/performing operations across multiple features having categorical variables.**<br>\nIt is just like `value_counts()`, advantage is we can perform the operation across columns!","126f78c0":"**Only the `Pclass` variable is an ordinal feature, we need to one hot encode all the other features.**","b46ae500":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>References<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","dbac970d":"Where People Boarded\n* C - Cherbourg\n* Q - Queenstown\n* S - Southampton","1ad5279f":"<h1 style=\"background-color:#0353A4; color:white;\"><center>Thanks for reading! Do Upvote \ud83d\ude04 If you found it helpful<\/center><\/h1>\n","b8196f3e":"![image](https:\/\/user-images.githubusercontent.com\/45713796\/112266205-b507bc00-8c99-11eb-9012-ad307b8dc9bc.png)","60c1d11e":"## Embarked","0ce89d51":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Pclass - Ticket class<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","71df4097":"**We'll drop `Cabin` as not many values are there and `PClass` covers for that.**","907e7006":"From this plot, it is visible that as the fare increases there is a high chance of survival.","11568ade":"**Ordinal Features - `Pclass`** - Features has relative ordering<br>\n**Categorical Features - `Sex`, `Embarked`, `title`**<br>\n**Continuous Variables - `Age`,`Fare`,`family`**","834a6125":"**Seems there are 2 examples which are NaN, what can we do to fill this?**<br>\nWe will fill this with the majority Port of Embarkation - `Southampton(S)`.","273c7a23":"--------------------------------------------------------------------------------------------------------------------------------","840f0310":"### \ud83d\udca1 Let's See how it varies with attributes seen so far","37f25cc3":"### Title","da7dd6fb":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Name<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","1cc757e2":"### \ud83d\udca1 Let's correlate with whatever features that we have seen till now","13e22ead":"### \ud83d\udca1 Let's Check how gender affects Survival with various other features","3d6126e8":"### It can be interesting to see what other `titles` people have.","a0b27c39":"> ### The lowest class(**3rd**) has the highest number of passengers.","d2d1b307":"**Interesting, Cherbourg has the highest onboarding of passengers from 1st class who Survived!**<br>\n`Embarkment` will be a good feature in predicting `Survival`.","e64b1344":"Let's visualize the `family` feature","5f396a1a":"--------------------------------------------------------------------------------------------------------------------------------","64e64404":"**Need to fix them `NULL` Values.**","cdc65d18":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>Prerequisites<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","3bcb4711":"Number of Parents\/Siblings.","838bf4bb":"**As count of family members on board increases, the rate of survival seems to go down.**","a798862a":"**Cross validate on certain models.**","f89f2b17":"### Why this Plot & Interperation?\n* We have plotted a categorical plot for every `Pclass` separately.\n* We picked `Violin plot` because we have a continous variable on the Y-axis `Age`, plotting line plot won't make sense it will just connect mean age of each gender.\n* Violin plot is a mix of KDE + Box Plot.\n* Most of the passengers with `Age<20`(children) were saved(See the blue bumps near 0-20 y-axis), there are certain exceptions like `Pclass= 1, Female`(Less samples?).","e4d2227f":"### \ud83d\udca1 As we already know, The survival rate in `1st class` is already high, Let's check how `Fare` correlates with `Survival`","302d87fd":"**It has the same trend with the `SibSp`, however passengers having `> 3 members`, their survival seems to drastically decrease.**","ba1e87c3":"* **It is pretty evident from the plot that a very large portion of people with less fare were rescued less, while there were a lot of people with large fare who were rescued.**<br>\n* **It can be seen that all passengers whose Fares where `>300` were rescued. This is not directly evident from the distribution. Tree models can capture this information but will be difficult for other models. We can use binning to solve this.**\n","06b5fd25":" ### \ud83d\udca1 **Let's check How does the `Pclass` vary with who Survived and who did not?**","86acf275":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>Contents<\/center><\/h1>","9f61cb45":"**We'll pick `RandomForestClassifier` as our final model and for tuning.**","1c03f288":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>Hyperparameter Tuning<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","c8e8e480":"**The trend is same even after combining features, `family_size >= 4` have less chance of survival.**<br>\nIt would be useful to bin this. We will divide the family into 4 categories.","e435ca2b":"Most of the people started their journey from `Southampton`.","b5fcb2a6":"> Install a external library that we will need later","539f0035":"**Most of the passengers don't have siblings\/spouses on board.**","712cceba":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Embarkment<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","2ab0af69":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Parch<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","174edec5":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Age<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","2dd6053d":"**To know more about Seed & Folds \ud83d\udc47**","6ecae084":"--------------------------------------------------------------------------------------------------------------------------------","aeaafb94":"* There are some null values in some of the features.\n* Let's visualize & understand each and every column in depth.","b33bae59":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>Data Processing<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","ce5ab213":"* We will combine both the family features.\n* Drop `Ticket` & `Name` since it is not needed","b284edb6":"### Route of the Titanic","78890ca9":"### \ud83d\udca1 Let's add a `Pclass` variable to the `Sex` feature to see how it affects Survival.","f2ce2ee4":"### Let's do the same for the `Age` variable\nHere we want to use `pd.cut` to divide into age groups as we want each range to represent a certain age group. eg - kids(0,16)","22151e04":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Fare<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","9762a53a":"- [Titanic - Advanced Feature Engineering Tutorial](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)\n- [EDA To Prediction(DieTanic)](https:\/\/www.kaggle.com\/ash316\/eda-to-prediction-dietanic)\n ","d71d4ed8":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>Feature Engineering<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","79816ea0":"There are some NaN values in the Cabin Names.<br>\nAccording to [this](https:\/\/www.encyclopedia-titanica.org\/cabins.html) source, cabins are assigned based upon `Pclass`.\n* A-E -> 1st Class\n* D-F -> 2nd Class\n* D-G -> 3rd Class\nSince there is a lot of overlap of the cabin classes, NULL Values and we already have `Pclass`, We will not use this feature.","9d7f65cc":"<h1 style=\"background-color:#1E96FC; color:white;\"><center>EDA of Each Feature<\/center><\/h1>\n<a href=\"#Contents\">Back to Contents<\/a>","1e60ccc8":"<h2 style=\"background-color:#44AF69; color:white;\"><center>Sex<\/center><\/h2>\n<a href=\"#Contents\">Back to Contents<\/a>","ad9f355e":"- [SEED](https:\/\/stackoverflow.com\/questions\/21494489\/what-does-numpy-random-seed0-do)\n- [FOLDS](https:\/\/stackoverflow.com\/questions\/36063014\/what-does-kfold-in-python-exactly-do)","7566bf91":"Many different hyperparameters were tried to get the best performance. The ones listed in the `param_grid` are the picked ones. You can modify them as you please to get a better score.","2a2ba5cd":"**Looks like most of the `3rd class` Passengers did not make it and `1st class` were given priority while being rescued.<br>\nThis will be an important feature to predict the survival.**","28786de1":"## Fare\nWe'll also fill the NULL value in test set with the mean `Fare` from train.","770e53ec":"### **\ud83d\udca1 Let's plot a line plot to see how this variable varies with Survival**","1886f9f2":"**This is how our dataset currently looks now \ud83d\udc47**","355bc0cc":"**Let's interpret this plot**.\n* **The point plot is similar to a bar plot except all the levels are connected**.\n* **The dot is the mean of that particular Pclass**.\n* **The horizontal line is the 95% confidence interval calculated by bootstrapping.**","5fcd0976":"\ud83d\udca1 Let's plot a line plot to see how this variable varies with Survival","e89e1969":"**Most of the `Age` lie between `20-40.`**","e6cc8933":"### There are a quite a lot of titles.<br>\nSince we already have a `Sex` column, only use from here would be identifying gender from their honorfics.","f6b4fe68":"<h3 style=\"background-color:#C04CFD; color:white;\"><center>This is my first notebook on Kaggle. This notebook is a blend of explanations, inspirations derived out of experimenting on this dataset & ideas born out of referring some really good notebooks \ud83d\ude07. Open to feedback in the comments. \ud83d\udc4d<\/center><\/h1>","4f9dcf5a":"There are total three ticket classes.\n* 1st class\n* 2nd class\n* 3rd class\n\n### 1st class has the highest socio-economic status."}}