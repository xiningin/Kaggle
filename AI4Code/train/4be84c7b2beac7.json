{"cell_type":{"3ddfe241":"code","3e1dcdf4":"code","08d48824":"code","112a427c":"code","8ff392e6":"markdown","9792f640":"markdown","0b2f5ffd":"markdown","6e634153":"markdown","3d93649f":"markdown","4e57792c":"markdown"},"source":{"3ddfe241":"import pandas as pd\nfrom pathlib import Path\n\ndata_dir = Path('..\/input\/tabular-playground-series-sep-2021\/')\n\ndf_train = pd.read_csv(\n    data_dir \/ \"train.csv\",\n    index_col='id',\n    nrows=25000,  # comment this row to use the full dataset\n)\n\nFEATURES = df_train.columns[:-1]\nTARGET = df_train.columns[-1]\n\ndf_train.head()","3e1dcdf4":"from xgboost import XGBClassifier\n\nX = df_train.loc[:, FEATURES]\ny = df_train.loc[:, TARGET]\n\nmodel = XGBClassifier(\n    max_depth=3,\n    subsample=0.5,\n    colsample_bytree=0.5,\n    n_jobs=-1,\n    # Uncomment if you want to use GPU. Recommended for whole training set.\n    #tree_method='gpu_hist',\n    random_state=0,\n)","08d48824":"from sklearn.model_selection import cross_validate\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndef score(X, y, model, cv):\n    scoring = [\"roc_auc\"]\n    scores = cross_validate(\n        model, X, y, scoring=scoring, cv=cv, return_train_score=True\n    )\n    scores = pd.DataFrame(scores).T\n    return scores.assign(\n        mean = lambda x: x.mean(axis=1),\n        std = lambda x: x.std(axis=1),\n    )\n\nscores = score(X, y, model, cv=2)\n\ndisplay(scores)","112a427c":"# Fit on full training set\nmodel.fit(X, y)\n\nX_test = pd.read_csv(data_dir \/ \"test.csv\", index_col='id')\n\n# Make predictions\ny_pred = pd.Series(\n    model.predict(X_test),\n    index=X_test.index,\n    name=TARGET,\n)\n\n# Create submission file\ny_pred.to_csv(\"submission.csv\")","8ff392e6":"A \"neutral\" AUC is 0.5, so anything better than that means our model learned something useful.","9792f640":"\n# Evaluation #\n\nThe evaluation metric is AUC, which stands for \"area under curve\".  Run the next code cell to evaluate the model.","0b2f5ffd":"# Make Submission #\n\nOur predictions are binary 0 and 1, but you're allowed to submit probabilities instead. In scikit-learn, you would use the `predict_proba` method instead of `predict`.","6e634153":"# Welcome to the September 2021 Tabular Playground Competition! #\n\nIn this competition, we predict whether a customer will make an insurance claim.\n\n# Data #\n\nThe full dataset has almost one million rows. We'll use just a sample so we can explore the data more quickly.","3d93649f":"The target `'claim'` has binary outcomes: `0` for no claim and `1` for claim.","4e57792c":"# Model #\n\nLet's try out a simple XGBoost model. This algorithm can handle missing values, but you could try imputing them instead.  We use `XGBClassifier` (instead of `XGBRegressor`, for instance), since this is a classification problem."}}