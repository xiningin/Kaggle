{"cell_type":{"5402af4f":"code","e835a269":"code","4a3b3da3":"code","528d059a":"code","832dc46b":"code","fe99ddac":"code","1988f60f":"code","716e8324":"code","bd20a85e":"code","e33b1364":"code","5726e8d1":"code","a4ce0b7b":"code","7c9c65bb":"code","45a851d1":"code","c61967c0":"code","9d89df43":"code","50099581":"code","73e618a8":"code","2692336e":"code","7d397d6d":"code","26e9880e":"code","09e932f0":"code","fe72fdad":"code","98af4107":"code","7591e955":"markdown","9ab81b68":"markdown","d12c29d6":"markdown"},"source":{"5402af4f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette\n%matplotlib inline\n\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn import model_selection, metrics, linear_model\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999","e835a269":"ls ..\/input\/quora-insincere-questions-classification","4a3b3da3":"train_path = \"..\/input\/quora-insincere-questions-classification\/train.csv\"\ntest_path = \"..\/input\/quora-insincere-questions-classification\/test.csv\"\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)","528d059a":"print(f\"There are {train_data.shape[0]} Rows and {train_data.shape[1]} Columns inside train data\")\nprint(f\"There are {train_data.shape[0]} questions in total in the training dataset\")\nprint(f\"There are {test_data.shape[0]} Rows and {test_data.shape[1]} Columns inside test data\")\nprint(f\"There are {test_data.shape[0]} questions in total in the test dataset\")","832dc46b":"train_data.head(30)","fe99ddac":"test_data.head()","1988f60f":"target_count = train_data['target'].value_counts()\nprint(target_count)","716e8324":"# Data for barchart\nbarchart_data = go.Bar(\n    x=target_count.index,\n    y=target_count.values,\n    marker=dict(\n        color=target_count.values,\n        colorscale = 'Picnic',\n        reversescale = True\n    ),\n)\n# Layout with title\nlayout = go.Layout(\n    title='Target Count',\n    font=dict(size=18)\n)\n\nfig = go.Figure(data=[barchart_data], layout=layout)\npy.iplot(fig, filename=\"TargetCount\")","bd20a85e":"labels = (np.array(target_count.index))\nsizes = (np.array((target_count \/ target_count.sum())*100))\n\npiechart_trace = go.Pie(labels=labels, values=sizes)\nlayout = go.Layout(\n    title='Target Distribution',\n    font=dict(size=18),\n    width=600,\n    height=600,\n)\ndata = [piechart_trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"target_distribution\")","e33b1364":"from sklearn.utils import resample\n\nsincere_data = train_data[train_data[\"target\"] == 0]\ninsincere_data = train_data[train_data[\"target\"] == 1]\ntrain_sampled = pd.concat([resample(sincere_data, replace = True, n_samples = len(insincere_data)*4), insincere_data])\ntrain_sampled","5726e8d1":"y = train_sampled['target']\ny.value_counts().plot(kind='bar', rot=0)","a4ce0b7b":"# Word cloud\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=max_words,\n        max_font_size=max_font_size, \n        random_state=42,\n        width=800, \n        height=400,\n        mask=mask\n    )\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    plt.imshow(wordcloud)\n    plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train_data[\"question_text\"], title=\"Word Cloud of Questions\")","7c9c65bb":"# Word cloud for sincere questions\nplot_wordcloud(train_data[train_data[\"target\"] == 0][\"question_text\"], title=\"Word Cloud of Sincere Questions\")","45a851d1":"# Word cloud for insincere questions\nplot_wordcloud(train_data[train_data[\"target\"] == 1][\"question_text\"], title=\"Word Cloud of Insincere Questions\")","c61967c0":"import re\n\ndef clean_text(text):\n\n  # Remove HTML Tags\n  text = re.sub(re.compile('<.*?>'), '', text)\n\n  # Remove [\\], ['], [\"]\n  text = re.sub(r'\\\\', '', text)\n  text = re.sub(r'\\\"', '', text)\n  text = re.sub(r'\\'', '', text)\n\n  # Remove number\n  text = re.sub('[0-9]{5,}','#####', text)\n  text = re.sub('[0-9]{4,}','####', text)\n  text = re.sub('[0-9]{3,}','###', text)\n  text = re.sub('[0-9]{2,}','##', text)\n\n  ## Remove Roman words\n  roman = re.compile(r'^M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$')\n  text = roman.sub(r'', text)\n\n  # Convert all text to lowercase\n  text = text.strip().lower()\n\n  # Replace punctuation chars with spaces\n  filters = '!\"\\'#$%@&*()+_-;:<=>.?{}|`\\\\^\\t\\n'\n  translate_dict = dict((c, \" \") for c in filters)\n  translate_map = str.maketrans(translate_dict)\n  text = text.translate(translate_map)\n\n  return text","9d89df43":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words=\"english\",\n                             preprocessor=clean_text,\n                             ngram_range=(1, 3))\n\nX = vectorizer.fit_transform(train_sampled['question_text'])\nx = vectorizer.transform(test_data['question_text'])","50099581":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","73e618a8":"logistic = linear_model.LogisticRegression(solver='sag')\nlogistic.fit(X_train, y_train)","2692336e":"from sklearn.metrics import f1_score, accuracy_score, classification_report\n\ndef get_f1(model, name):\n  y_train_pred, y_pred = model.predict(X_train), model.predict(X_test)\n  print(classification_report(y_test, y_pred), '\\n')\n\n  print('{} model with F1 score = {}'.format(name, f1_score(y_test, y_pred)))\n\nget_f1(logistic, 'LogisticRegression')\n","7d397d6d":"# Prdiction on test data \ntest_preds = logistic.predict(x)","26e9880e":"# xgboost\nimport xgboost as xgb\nxgb = xgb.XGBClassifier()\nxgb.fit(X_train, y_train)\n","09e932f0":"get_f1(xgb, 'XGBClassifier')","fe72fdad":"model = xgb\ntest_preds = model.predict(x)","98af4107":"output = pd.DataFrame({\n    \"qid\":test_data[\"qid\"].values, \n    \"prediction\": test_preds\n}) \noutput.to_csv(\"submission.csv\", index=False)","7591e955":"## Preprocessing\nCleaning the questions\n","9ab81b68":"## Result","d12c29d6":"### Inference\n#### From here we can say that there is only 6.19 % of insincere questions\n#### This clearly tells us that the samples to predict from is pretty low i.e. a case of undersampling\n"}}