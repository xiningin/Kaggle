{"cell_type":{"cf30b550":"code","90f4f4e9":"code","1b19f927":"code","05a01bfa":"code","c28f03f3":"code","550787e5":"code","87370edf":"code","0d14c9ce":"code","8df91558":"code","b23a815f":"code","8cad8e85":"code","4b3079d2":"code","bfb208b2":"code","a95afa94":"code","ebb44413":"code","82ad1f4a":"code","d5a89baa":"code","050df7a8":"code","267f080b":"code","0900ea10":"code","45731517":"code","5aee8054":"code","dbe76c9c":"code","10c474e1":"code","ad6ae032":"code","5283ce78":"code","760a82ee":"code","5894fe48":"code","04109955":"code","5eb4868a":"code","9af587e3":"code","1214d2d6":"code","d4d30330":"code","55dc99f4":"code","07e98634":"code","6b523a40":"code","983a5dd4":"code","ed26beb4":"code","36a2e888":"code","a996e6dc":"code","2826a00c":"code","ae56596a":"code","2e0c1f62":"code","9ec9be3c":"code","6e3a88d6":"code","997971d5":"code","159836c5":"code","e5c91021":"code","00f1247a":"code","00889928":"code","d95ed1ee":"code","88824349":"code","b611f34d":"code","77174020":"code","4ad1d231":"code","50ae1b76":"code","e5e82f73":"code","ce31de07":"code","169202ea":"code","989f2e79":"code","be552e7b":"code","fd7db8e7":"code","77e43e59":"code","5f3cac9b":"code","ceef8720":"code","e61422a6":"code","3f29fccf":"code","25f0fe7f":"code","3f7f2f6d":"code","3a5678ad":"code","5b50d96e":"code","ef854aed":"code","0fe0107e":"code","44c336fe":"code","c2c00143":"code","2714a01c":"code","b1faeb5f":"code","8db9c6d1":"code","4a5d9df5":"code","b44b0a37":"code","0ef2a59c":"code","6d8a19fb":"code","4c2de7f6":"code","e131216a":"code","0d158232":"code","b8cb345e":"code","2041579e":"code","65e17cc5":"code","a105d714":"code","54981688":"code","740d3e90":"code","3c819253":"code","3e6dfe77":"code","72e422fb":"code","c95e4e5e":"code","09426f08":"code","501fd9f0":"code","ef9b38a7":"code","10ccbbd9":"code","a493c07b":"code","1a2b0323":"code","27aaabdd":"code","c9ea8b17":"code","2d548a54":"code","ffc33a98":"code","1495f76d":"code","3dd6ac48":"code","2d43757b":"code","b5dec0c5":"code","102795f2":"code","a2a1cb0e":"code","741767de":"code","2d2ecf3a":"code","f5967d14":"code","c5401db9":"code","7a7a3219":"code","5767c56a":"code","8bd3016c":"code","2309693d":"code","a4c7ea2c":"code","94176f64":"code","6e20cd60":"code","c4a07cfd":"code","ed53c5b6":"code","a514ec18":"code","21bb93ff":"code","7d8597d3":"markdown","7eff4af1":"markdown","a7ee132a":"markdown","b0334a8c":"markdown","b7577c74":"markdown","39a8cf21":"markdown","46ca67b0":"markdown","a8f87ef4":"markdown","57b36b97":"markdown","8f848f51":"markdown","8e86ea99":"markdown","934f8166":"markdown","75ebe150":"markdown","d205e48c":"markdown","9fbcd173":"markdown","de1443b5":"markdown","5e03fbd2":"markdown","578ed39b":"markdown","b3bce1e5":"markdown","e2b13603":"markdown","94402532":"markdown","786f352b":"markdown","774bab0c":"markdown","37c95db7":"markdown","0dc17a3a":"markdown","5e770f2a":"markdown","5d785b4e":"markdown","25576988":"markdown","ed6406d2":"markdown","bdb45505":"markdown","0634a88a":"markdown","0a56890e":"markdown","c5177094":"markdown","c9b33271":"markdown","623ea136":"markdown","2b3c950d":"markdown","7d18343d":"markdown","ac13a1de":"markdown","8bf5e7a2":"markdown","6e6d8ee5":"markdown","ab4f3684":"markdown"},"source":{"cf30b550":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90f4f4e9":"plt.style.available","1b19f927":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_PassengerId = test_df['PassengerId']","05a01bfa":"train_df.columns","c28f03f3":"train_df.info()","550787e5":"train_df.describe()","87370edf":"train_df.head()","0d14c9ce":"def bar_plot(variable):\n    \"\"\"\n    input: variable ex: 'Sex'\n    output: bar plot & value count\n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index,varValue.index.values)\n    plt.ylabel('Frequency')\n    plt.title(variable)\n    plt.show()\n    print('{}: \\n{}'.format(variable,varValue))\n","8df91558":"category1 = ['Survived','Sex','Pclass','Embarked','SibSp','Parch']\nfor c in category1:\n    bar_plot(c)","b23a815f":"category2 = ['Cabin','Name','Ticket']\nfor c in category2:\n    print('{} \\n'.format(train_df[c].value_counts()))","8cad8e85":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(train_df[variable],bins=50)\n    plt.xlabel(variable)\n    plt.ylabel('Frequency')\n    plt.title('{} distribution with histogram'.format(variable))\n    plt.show()\n","4b3079d2":"numericVar=['Fare','Age','PassengerId']\nfor n in numericVar:\n    plot_hist(n)","bfb208b2":"train_df[[\"Pclass\",\"Survived\"]]","a95afa94":"train_df[[\"Pclass\",\"Survived\"]].groupby(['Pclass'], as_index = False).mean()","ebb44413":"# Pclass - Survived\n\ntrain_df[[\"Pclass\",\"Survived\"]].groupby(['Pclass'], as_index = False).mean().sort_values(by='Survived',ascending = False)","82ad1f4a":"# Sex - Survived\n\ntrain_df[[\"Sex\",\"Survived\"]].groupby(['Sex'], as_index = False).mean().sort_values(by='Survived',ascending = False)","d5a89baa":"# SibSp - Survived\n\ntrain_df[[\"SibSp\",\"Survived\"]].groupby(['SibSp'], as_index = False).mean().sort_values(by='Survived',ascending = False)","050df7a8":"# Parch - Survived\n\ntrain_df[[\"Parch\",\"Survived\"]].groupby(['Parch'], as_index = False).mean().sort_values(by='Survived',ascending = False)","267f080b":"train_df.corr()","0900ea10":"# SibSp+Parch - Survived\n\ntrain_df2 = train_df.copy()\ntrain_df2['Relatives'] = train_df['SibSp'] + train_df['Parch']\ntrain_df2[[\"Relatives\",\"Survived\"]].groupby(['Relatives'], as_index = False).mean().sort_values(by='Survived',ascending = False)","45731517":"def outlier_detect(variable):\n    Q1 = train_df.describe()[[variable]].loc['25%'].values[0]\n    Q3 = train_df.describe()[[variable]].loc['75%'].values[0]\n    IQR = Q3 - Q1\n    lower_threshold = Q1 - 1.5*(Q3-Q1)\n    upper_threshold = Q3 + 1.5*(Q3-Q1)\n    filter1 = train_df[variable] < lower_threshold\n    filter2 = train_df[variable] > upper_threshold\n    return train_df[[variable]][filter1 | filter2]","5aee8054":"outlier_detect('Fare')","dbe76c9c":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        Q1 = np.percentile(df[c],25)\n        Q3 = np.percentile(df[c],75)\n        IQR = Q3-Q1\n        outlier_step = IQR * 1.5\n        outlier_list_col = df[(df[c] < (Q1 - outlier_step)) | (df[c] > (Q3 + outlier_step))].index\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    return multiple_outliers","10c474e1":"train_df.loc[detect_outliers(train_df,['Age','SibSp','Parch','Fare'])]","ad6ae032":"def detect_outliers2(df,features):\n    \"\"\"\n        More suitable for dataset includes Nan values\n        The function above cannot find an outlier for Age column because Age column returns nan and nan for Q1 and Q3, respectively.\n    \"\"\"\n    outlier_indices = []\n    for c in features:\n        outlier_list_col = outlier_detect(c).index\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    return multiple_outliers","5283ce78":"train_df.loc[detect_outliers2(train_df,['Age','SibSp','Parch','Fare'])]","760a82ee":"# dropping outliers\n\ntrain_df = train_df.drop(detect_outliers2(train_df,['Age','SibSp','Parch','Fare']),axis=0).reset_index(drop = True)","5894fe48":"train_df.loc[detect_outliers2(train_df,['Age','SibSp','Parch','Fare'])]#checking","04109955":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis=0).reset_index(drop = True)","5eb4868a":"train_df.columns[train_df.isnull().any()]","9af587e3":"train_df.isnull().sum()","1214d2d6":"# Embarked has 2 missing value\n\ntrain_df[train_df['Embarked'].isnull()]","d4d30330":"train_df.boxplot(column = 'Fare',by = 'Embarked')\nplt.show()","55dc99f4":"train_df['Embarked'] = train_df['Embarked'].fillna('C')\ntrain_df[train_df['Embarked'].isnull()]","07e98634":"test_df['Embarked'] = test_df['Embarked'].fillna('C')","6b523a40":"train_df[train_df['Fare'].isnull()]","983a5dd4":"np.mean(train_df[train_df['Pclass'] == 3]['Fare'])","ed26beb4":"train_df['Fare'] = train_df['Fare'].fillna(12.741219971469327)\ntrain_df[train_df['Fare'].isnull()]","36a2e888":"list1 = ['SibSp','Parch','Age','Fare','Survived']\nsns.heatmap(train_df[list1].corr(),annot = True,fmt = '.2f')","a996e6dc":"g = sns.factorplot(x = 'SibSp', y = 'Survived', data = train_df, kind = 'bar', size = 7)\ng.set_ylabels('Survived Probability')\nplt.show()","2826a00c":"g = sns.factorplot(x = 'Parch', y = 'Survived', data = train_df, kind = 'bar', size = 7)# line means standard deviation\ng.set_ylabels('Survived Probability')\nplt.show()","ae56596a":"g = sns.factorplot(x = 'Pclass', y = 'Survived', data = train_df, kind = 'bar', size = 7)# line means standard deviation\ng.set_ylabels('Survived Probability')\nplt.show()","2e0c1f62":"g = sns.FacetGrid(train_df, col = 'Survived')\ng.map(sns.distplot, 'Age', bins = 25)\nplt.show()","9ec9be3c":"g = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass')\ng.map(plt.hist,'Age',bins = 25)\ng.add_legend()\nplt.show()","6e3a88d6":"g = sns.FacetGrid(train_df, row = 'Embarked')\ng.map(sns.pointplot,'Pclass','Survived','Sex')\ng.add_legend()\nplt.show()","997971d5":"g = sns.FacetGrid(train_df, row = 'Embarked', col = 'Survived',size = 2.5)\ng.map(sns.barplot,'Sex','Fare')\ng.add_legend()\nplt.show()","159836c5":"train_df.isnull().sum()","e5c91021":"train_df[train_df['Age'].isnull()]","00f1247a":"sns.factorplot(x='Sex',y='Age',data=train_df,kind = 'box')\n# Sex is not informative for age prediction","00889928":"sns.factorplot(x='Sex',y='Age',hue = 'Pclass',data=train_df,kind = 'box')\n# Pclass is a good feature to predict Age.","d95ed1ee":"sns.factorplot(x='Parch',y='Age',hue = 'Pclass',data=train_df,kind = 'box')\nsns.factorplot(x='SibSp',y='Age',hue = 'Pclass',data=train_df,kind = 'box')\n","88824349":"train_df['New_sex'] = [1 if i == 'male' else 0 for i in train_df['Sex']]\n\n","b611f34d":"test_df['New_sex'] = [1 if i == 'male' else 0 for i in test_df['Sex']]","77174020":"sns.heatmap(train_df[['Age','New_sex','SibSp','Parch','Pclass']].corr(),annot = True, fmt = '.3f')\nplt.show()\n# Age is not correlated with Sex","4ad1d231":"index_nan_age = list(train_df.Age[train_df.Age.isnull()].index)\nprint(index_nan_age)","50ae1b76":"for i in index_nan_age:\n    age_pred = train_df['Age'][(train_df['SibSp'] == train_df.iloc[i]['SibSp']) & (train_df['Parch'] == train_df.iloc[i]['Parch']) & (train_df['Pclass'] == train_df.iloc[i]['Pclass'])].median","e5e82f73":"age_pred","ce31de07":"for i in index_nan_age:\n    age_pred = train_df['Age'][(train_df['SibSp'] == train_df.iloc[i]['SibSp']) & (train_df['Parch'] == train_df.iloc[i]['Parch']) & (train_df['Pclass'] == train_df.iloc[i]['Pclass'])].median()\n    age_med = train_df['Age'].median()\n    if not np.isnan(age_pred):\n        train_df['Age'].iloc[i] = age_pred\n    else:\n        train_df['Age'].iloc[i] = age_med","169202ea":"train_df.Age[index_nan_age]","989f2e79":"train_df['Name'].head(5)","be552e7b":"name = train_df['Name']\ntrain_df['Title'] = [i.split('.')[0].split(',')[1].strip() for i in name]","fd7db8e7":"test_df['Title'] = [i.split('.')[0].split(',')[1].strip() for i in test_df['Name']]","77e43e59":"train_df['Title'].head(5)","5f3cac9b":"sns.countplot(x='Title',data=train_df)\nplt.xticks(rotation=45)\nplt.show()","ceef8720":"# covert to categorical\n\ntrain_df['Title'] = train_df['Title'].replace(['Lady','the Countess','Capt','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'other')","e61422a6":"test_df['Title'] = test_df['Title'].replace(['Lady','the Countess','Capt','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'other')","3f29fccf":"sns.countplot(x='Title',data=train_df)\nplt.xticks(rotation=45)\nplt.show()","25f0fe7f":"train_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]","3f7f2f6d":"test_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in test_df[\"Title\"]]","3a5678ad":"sns.countplot(x='Title',data=train_df)\nplt.xticks(rotation=45)\nplt.show()","5b50d96e":"train_df[\"Title\"].head(20)","ef854aed":"g = sns.factorplot(x = 'Title', y = 'Survived', data = train_df, kind = 'bar')\ng.set_xticklabels(['Master','Mrs','Mr','Other'])# In order\ng.set_ylabels('Survival Probability')","0fe0107e":"train_df.drop(labels = ['Name'],axis=1,inplace=True)","44c336fe":"test_df.drop(labels = ['Name'],axis=1,inplace=True)","c2c00143":"train_df.head(6)","2714a01c":"train_df = pd.get_dummies(train_df,columns=['Title'])#dummy variable\ntrain_df.head()","b1faeb5f":"test_df = pd.get_dummies(test_df,columns=['Title'])#dummy variable","8db9c6d1":"train_df['Fsize'] = train_df['SibSp'] + train_df['Parch'] + 1#Family size including passenger","4a5d9df5":"test_df['Fsize'] = test_df['SibSp'] + test_df['Parch'] + 1","b44b0a37":"train_df.head(5)","0ef2a59c":"g = sns.factorplot(x='Fsize',y='Survived',data=train_df,kind='bar')\ng.set_ylabels('Survival')\nplt.show()","6d8a19fb":"train_df['family_size_category'] = ['alone' if i == 1 else 'small' if (i == 2 or i == 3 or i == 4) else 'big' if i > 4 else 'unknown' for i in train_df['Fsize']]# Alone, small family, big family","4c2de7f6":"test_df['family_size_category'] = ['alone' if i == 1 else 'small' if (i == 2 or i == 3 or i == 4) else 'big' if i > 4 else 'unknown' for i in test_df['Fsize']]","e131216a":"train_df.head(10)","0d158232":"g = sns.factorplot(x='family_size_category',y='Survived',data=train_df,kind='bar')\ng.set_ylabels('Survival')\nplt.show()","b8cb345e":"sns.countplot(x='family_size_category',data=train_df)\nplt.show()","2041579e":"train_df = pd.get_dummies(train_df,columns=['family_size_category'],prefix = 'FS')","65e17cc5":"test_df = pd.get_dummies(test_df,columns=['family_size_category'],prefix = 'FS')","a105d714":"train_df = pd.get_dummies(train_df, columns=['Embarked'])","54981688":"test_df = pd.get_dummies(test_df, columns=['Embarked'])","740d3e90":"train_df.head(10)","3c819253":"train_df.corr().iloc[:,0:3]","3e6dfe77":"train_df['Ticket'].head(20)","72e422fb":"ticket = []\nfor i in list(train_df['Ticket']):\n    if not i.isdigit():\n        ticket.append(i.replace('.','').replace('\/','').strip().split(' ')[0])\n    else:\n        ticket.append('x')\ntrain_df['Ticket'] = ticket","c95e4e5e":"ticket_t = []\nfor i in list(test_df['Ticket']):\n    if not i.isdigit():\n        ticket_t.append(i.replace('.','').replace('\/','').strip().split(' ')[0])\n    else:\n        ticket_t.append('x')\ntest_df['Ticket'] = ticket_t","09426f08":"train_df.head(20)","501fd9f0":"train_df['Ticket'].unique()","ef9b38a7":"train_df = pd.get_dummies(train_df,columns=['Ticket'], prefix = 'T')# use t instead of ticket word","10ccbbd9":"test_df = pd.get_dummies(test_df,columns=['Ticket'], prefix = 'T')","a493c07b":"train_df.head(20)","1a2b0323":"sns.countplot(x='Pclass',data=train_df)\nplt.show()","27aaabdd":"train_df['Pclass'] = train_df['Pclass'].astype('category')\ntrain_df = pd.get_dummies(train_df,columns=['Pclass'])\ntrain_df.head(20)","c9ea8b17":"test_df['Pclass'] = test_df['Pclass'].astype('category')\ntest_df = pd.get_dummies(test_df,columns=['Pclass'])","2d548a54":"train_df.columns","ffc33a98":"train_df.drop(axis=1,labels=['Sex','PassengerId','Cabin','Fsize'],inplace=True)","1495f76d":"test_df.drop(axis=1,labels=['Sex','PassengerId','Cabin','Fsize'],inplace=True)","3dd6ac48":"train_df.columns","2d43757b":"train_df.info()","b5dec0c5":"test_df.columns","102795f2":"for i in train_df.columns:\n    if i in test_df.columns:\n        pass\n    else:\n        test_df[i] = 0","a2a1cb0e":"test_df.info()","741767de":"test_df.columns","2d2ecf3a":"train_df = train_df.reindex(sorted(train_df.columns), axis=1)","f5967d14":"test_df = test_df.reindex(sorted(test_df.columns), axis=1)","c5401db9":"test_df.columns","7a7a3219":"train_df.columns","5767c56a":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","8bd3016c":"train_df.info()","2309693d":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","a4c7ea2c":"train = train_df[:train_df_len]\nx_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.33, random_state = 42)","94176f64":"log_reg = LogisticRegression()\nlog_reg.fit(x_train,y_train)\nacc_log_train = log_reg.score(x_train,y_train)\nacc_log_test = log_reg.score(x_test,y_test)\nprint('Train suitability : ',acc_log_train)\nprint('Test acc : ',acc_log_test)","6e20cd60":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state=random_state),\n             SVC(random_state=random_state),\n             RandomForestClassifier(random_state=random_state),\n             LogisticRegression(random_state=random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {'min_samples_split':range(10,500,20),\n                'max_depth':range(1,20,2)}\n\nsvc_param_grid = {'kernel':['rbf'],\n                 'gamma':[0.001,0.01,0.1,1],\n                 'C':[1,10,50,100,200,300,1000]}\n\nrf_param_grid = {'max_features':[1,3,10],\n                'min_samples_split':[2,3,10],\n                'min_samples_leaf':[1,3,10],\n                'bootstrap':[False],\n                'n_estimators':[100,300],\n                'criterion':['gini']}\n\nlogreg_param_grid = {'C':np.logspace(-3,3,7),\n                    'penalty':['l1','l2']}\n\nknn_param_grid = {'n_neighbors': np.linspace(1,19,10, dtype = int).tolist(),\n                 'weights':['uniform','distance'],\n                 'metric':['euclidean','manhattan']}\n\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]\n\n","c4a07cfd":"cv_results = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i],param_grid=classifier_param[i],cv = StratifiedKFold(n_splits = 10),scoring = 'accuracy', n_jobs = -1, verbose = 1)\n    clf.fit(x_train,y_train)\n    cv_results.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_results[i])","ed53c5b6":"cv_result = pd.DataFrame({'Cross Val Means': cv_results, 'ML models': ['DecisionTreeClassifier','SVM','RandomForestClassifier','LogisticRegression','KNeighborsClassifier']})\n\ng = sns.barplot('Cross Val Means','ML models',data = cv_result)\ng.set_xlabel('Mean Acc')\ng.set_title('Cross Val Scores')\nplt.show()","a514ec18":"votingC = VotingClassifier(estimators = [('dt',best_estimators[0]),('rf',best_estimators[2]),('logreg',best_estimators[3])],voting = 'soft', n_jobs = -1)# soft and hard\/ posibily, direct\n# Using models at the same time\nvotingC = votingC.fit(x_train,y_train)\nprint(accuracy_score(votingC.predict(x_test),y_test))","21bb93ff":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","7d8597d3":"## Logistic Regression","7eff4af1":"## Hyperparameter Tuning -- Grid Search -- Cross Validation","a7ee132a":"<a id = \"26\"><\/a><br>\n## Pclass","b0334a8c":"## Ensemble Modeling","b7577c74":"<a id = \"6\"><\/a><br>\n# Basic Data Analysis\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived\n","39a8cf21":"* Having a lot of SibSp have less chance to survive\n* If SibSp == 0 or 1 or 2, there is a higher chance to live\n* We can consider a new feature describing these categories","46ca67b0":"<a id = \"30\"><\/a><br>\n# Prediction","a8f87ef4":"<a id = \"8\"><\/a><br>\n# Missing Values\n\n\n\n\n","57b36b97":"<a id = \"2\"><\/a><br>\n# Variable Description\n\n1. PassengerId : unique id\n1. Survived : passanger survived(1) or died(0)\n1. Pclass : passanger class\n1. Name : name\n1. Sex : sex\n1. Age : age\n1. SibSp : number of siblings\/spouses\n1. Parch : number of parents\/children\n1. Ticket : ticket number\n1. Fare : money spent for the ticket\n1. Cabin : cabin category\n1. Embarked : port(C, Q, S)\n\n","8f848f51":"* Females have more chance\n* For Embarked = C, males have more chance\n* Embarked and Sex will be used for training","8e86ea99":"* age <= 10 has a high survival rate\n* oldest passengers (80) survived\n* large number of 20 years old ps did not survive\n* most passengers are in 15-35 age range\n* We can use age feature for training\n* We can use age distribution for missin value of age","934f8166":"<a id = \"11\"><\/a><br>\n# Visualisation","75ebe150":"<a id = \"12\"><\/a><br>\n## Correlation Between SibSp -- Parch -- Age -- Fare -- Survived","d205e48c":"# Introduction\n\nTitanic was a bad and famous ship accident. 1502 people died. An Iceberg was the reason of the accident. \n\n<font color = 'red'>\nContent:\n\n\n1.[Loading and Checking Data](#1)\n    \n2.[Varible Description](#2)\n<br>*[-Univariate Variable Analysis](#3)\n<br>*[--Categorical Variable Analysis](#4)\n<br>*[--Numerical Variable Analysis](#5)\n\n3.[Basic Data Analysis](#6)\n    \n4.[Outlier Detection](#7)\n    \n5.[Missing Values](#8)\n<br>*[-Finding Missing Values](#9)\n<br>*[-Filling Missing Values](#10)\n    \n6.[Visualsation](#11)\n<br>*[-Correlation Between SibSp -- Parch -- Age -- Fare -- Survived](#12)\n<br>*[-SibSp -- Survived](#13)\n<br>*[-Parch -- Survived](#14)\n<br>*[-Pclass -- Survived](#15)\n<br>*[-Age -- Survived](#16)\n<br>*[-Age -- Survived -- Pclass](#17)\n<br>*[-Embarked -- Sex -- Survived -- Pclass](#18)\n<br>*[-Embarked -- Sex -- Survived -- Fare](#19)\n\n7.[Filling Missing Age Feature](#20)\n\n8.[Feature Engineering](#21)\n<br>*[-Name -- Title](#22)\n<br>*[-FamilySize](#23)\n<br>*[-Embarked](#24)\n<br>*[-Ticket](#25)\n<br>*[-Pclass](#26)\n<br>*[-Drop Unnecessary Variables](#27)\n\n9.[Modelling](#28)\n<br>*[-Data Preparation and Other Steps](#29)\n\n10.[Prediction and Submission](#30)","9fbcd173":"* Passengers who paid higher fare had a better survival chance\n* Fare can be used as categorical for training","de1443b5":"<a id = \"24\"><\/a><br>\n## Embarked","5e03fbd2":"* Pclass is an important feature for training","578ed39b":"<a id = \"22\"><\/a><br>\n## Name -- Title","b3bce1e5":"<a id = \"10\"><\/a><br>\n## Filling Missing Values","e2b13603":"<a id = \"16\"><\/a><br>\n## Age -- Survived","94402532":"<a id = \"13\"><\/a><br>\n## SibSp -- Survived","786f352b":"<a id = \"1\"><\/a><br>\n# Loading and Checking Data","774bab0c":"<a id = \"14\"><\/a><br>\n## Parch -- Survived","37c95db7":"<a id = \"27\"><\/a><br>\n## Drop Unnecessary Variables","0dc17a3a":"<a id = \"20\"><\/a><br>\n# Filling Missing Age Feature","5e770f2a":"<a id = \"7\"><\/a><br>\n# Outlier Detection","5d785b4e":"<a id = \"18\"><\/a><br>\n## Embarked -- Sex -- Survived -- Pclass","25576988":"<a id = \"23\"><\/a><br>\n## FamilySize","ed6406d2":"* Small families have more chance to survive than alone passengers and big families****","bdb45505":"<a id = \"17\"><\/a><br>\n## Age -- Survived -- Pclass","0634a88a":"<a id = \"25\"><\/a><br>\n## Ticket","0a56890e":"<a id = \"28\"><\/a><br>\n# Modelling","c5177094":"<a id = \"5\"><\/a><br>\n## * Numerical Variable Analysis\n\n\n\n","c9b33271":"<a id = \"21\"><\/a><br>\n# Feature Engineering","623ea136":"* SibSp and Parch can be used for new feature extraction with th = 3\n* Small 'families' have more chance to survive\n* There is a std in survival of passenger with Parch = 3","2b3c950d":"<a id = \"3\"><\/a><br>\n# Univariate Variable Analysis\n\nCategorical variables : Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp, Parch\n\nNumerical variables : Fare, Age, PassengerId\n\n<a id = \"4\"><\/a><br>\n## * Categorical Variable Analysis\n\n\n\n\n\n\n\n\n\n","7d18343d":"<a id = \"15\"><\/a><br>\n## Pclass -- Survived","ac13a1de":"<a id = \"29\"><\/a><br>\n## Data Preparation","8bf5e7a2":"<a id = \"19\"><\/a><br>\n## Embarked -- Sex -- Survived -- Fare","6e6d8ee5":"Fare feauture seems to have correlation with survived feature (0.27).","ab4f3684":"<a id = \"9\"><\/a><br>\n## Finding Missing Values"}}