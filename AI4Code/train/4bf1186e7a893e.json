{"cell_type":{"cc54b63f":"code","7f89a26c":"code","dfab67fb":"code","fbb453fd":"code","58d9a2b5":"code","f79da49c":"code","b0f23e83":"code","9b338ffc":"code","466f42e1":"code","60460af1":"code","458bdd60":"code","2a211bcc":"code","7ff75794":"code","4a02e8bb":"code","2b7d64a3":"code","2ea6f632":"code","62e481a3":"code","481bbe01":"code","7ce7abaf":"code","a13d9e5a":"code","93f41ead":"markdown","7479c31b":"markdown","59e26101":"markdown","78722e7e":"markdown","2eec908d":"markdown","ae3ab40e":"markdown","24923e50":"markdown","09cfd028":"markdown","25931dbc":"markdown","e4a81097":"markdown"},"source":{"cc54b63f":"!pip install split-folders\n!pip install basic-image-eda","7f89a26c":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n%matplotlib inline","dfab67fb":"my_data_dir = r'\/kaggle\/input\/yoga-posture-cleaned\/Yoga_combined - removed some\/'","fbb453fd":"os.listdir(my_data_dir) ","58d9a2b5":"tree_example_dir = my_data_dir + r'\/tree\/00000000.jpg'\ntree_example_img = imread(tree_example_dir)\ntree_example_img.shape","f79da49c":"plt.imshow(tree_example_img)","b0f23e83":"# check for any corrupted images and delete them\n# code obtained from https:\/\/stackoverflow.com\/questions\/67505710\/pil-unidentifiedimageerror-cannot-identify-image-file-io-bytesio-object\nimport PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\n\npath = Path(my_data_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n        print(img_p) ","9b338ffc":"#Check number of images\ncategory = []\nnumber_images = []\nfor cat in os.listdir(my_data_dir):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(my_data_dir+'\/'+cat))))\n    category.append(cat)\n    number_images.append(len(os.listdir(my_data_dir+'\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images)))","466f42e1":"#Visualizing with pie chart\nplt.pie(number_images, labels = category, autopct='%.0f%%')\nplt.show()","60460af1":"#Making another copies of input data for EDA purpose\nfrom distutils.dir_util import copy_tree\ncopy_dir = r'\/kaggle\/working\/copy_images\/'\ncopy_tree(my_data_dir, copy_dir, verbose = 2)\nfrom IPython.display import clear_output\nclear_output(wait=True)\nprint(\"finished\")","458bdd60":"#Explore the average dimension of the images\nerror_image = []\nfor cat in os.listdir(copy_dir):\n    dim1 = []\n    dim2 = []\n    for image_filename in os.listdir(copy_dir+cat+'\/'):    \n        try:\n            img = imread(copy_dir+cat+'\/'+image_filename)\n        except:\n            print(\"Error reading file on \" + cat + \" %s\" %image_filename)\n            error_image.append(copy_dir + cat + '\/' + image_filename)\n            continue\n        if len(img.shape)==2: #Reshape some images with single color channel\n            img = img.reshape(img.shape[0],img.shape[1],1)\n        if len(img.shape)==0:\n            print(\"Image shape = 0 on \" + cat + \" %s\" %image_filename)\n            error_image.append(copy_dir + cat + '\/' + image_filename)\n        else:\n            d1,d2,colors = img.shape\n            dim1.append(d1)\n            dim2.append(d2)\n    p = sns.jointplot(dim1,dim2)\n    p.fig.suptitle(\"Dimensions of %s images\" %cat)\n    print(\"Mean of dim1 on \" + cat + \" is \"+ str(np.mean(dim1)))\n    print(\"Mean of dim2 on \" + cat + \" is \"+ str(np.mean(dim2)))","2a211bcc":"error_image","7ff75794":"for file in error_image:\n    os.remove(file)\nprint(\"Completed removing the files that have problems...\")","4a02e8bb":"#Spliting the data into train\/test\/validation folders\nimport splitfolders\nsplitfolders.ratio(copy_dir, output=\"output\", seed=1234, ratio=(.8, 0.1,0.1)) ","2b7d64a3":"splitted_dir = r'\/kaggle\/working\/output\/'\n\nimport PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\n\npath = Path(splitted_dir).rglob(\"*.jpg\")\ni = 0\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p) \n            os.remove(img_p) \n            i+=1\nprint('Removed total {} images'.format(i))","2ea6f632":"#Check number of images for three folders\nprint(\"Training folder : \")\ncategory = []\nnumber_images_train = []\nfor cat in os.listdir(splitted_dir + 'train'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'train' + '\/'+cat))))\n    category.append(cat)\n    number_images_train.append(len(os.listdir(splitted_dir + 'train' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_train)))\n\nprint(\"\\n\\nTesting folder : \")\ncategory = []\nnumber_images_test = []\nfor cat in os.listdir(splitted_dir + 'test'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'test' + '\/'+cat))))\n    category.append(cat)\n    number_images_test.append(len(os.listdir(splitted_dir + 'test' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_test)))\n\nprint(\"\\n\\nValidation folder : \")\ncategory = []\nnumber_images_valid = []\nfor cat in os.listdir(splitted_dir + 'train'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'val' + '\/'+cat))))\n    category.append(cat)\n    number_images_valid.append(len(os.listdir(splitted_dir + 'val' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_valid)))","62e481a3":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\ncat = os.listdir(splitted_dir + 'train')\nfor category in cat:\n    filenames = os.listdir(splitted_dir + 'train\/' + category)\n    image_files = []\n    for image in filenames:\n        image_files.append(splitted_dir + 'train\/' + category + '\/' + image)\n\n    datagen = ImageDataGenerator(shear_range=0.2, zoom_range=0.2, \n#                                  rotation_range = 20,\n#                                 width_shift_range=0.2, height_shift_range=0.2,\n                                 brightness_range =(0.2, 0.8),\n                                 fill_mode='nearest') \n    \n    for f in image_files:\n        img = load_img(f)  \n        x = img_to_array(img) \n        # Reshape the input image \n        x = x.reshape((1, ) + x.shape)  \n        i = 0\n\n        # generate 10 new augmented images \n        for batch in datagen.flow(x, batch_size = 1, \n                          save_to_dir = splitted_dir + 'train\/' + category,  \n                          save_prefix ='aug', save_format ='jpeg'):\n            i += 1\n            if i > 5: \n                break","481bbe01":"print(\"finished\")","7ce7abaf":"#Re-check number of images for three folders\nprint(\"Training folder : \")\ncategory = []\nnumber_images_train = []\nfor cat in os.listdir(splitted_dir + 'train'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'train' + '\/'+cat))))\n    category.append(cat)\n    number_images_train.append(len(os.listdir(splitted_dir + 'train' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_train)))\n\nprint(\"\\n\\nTesting folder : \")\ncategory = []\nnumber_images_test = []\nfor cat in os.listdir(splitted_dir + 'test'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'test' + '\/'+cat))))\n    category.append(cat)\n    number_images_test.append(len(os.listdir(splitted_dir + 'test' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_test)))\n\nprint(\"\\n\\nValidation folder : \")\ncategory = []\nnumber_images_valid = []\nfor cat in os.listdir(splitted_dir + 'train'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'val' + '\/'+cat))))\n    category.append(cat)\n    number_images_valid.append(len(os.listdir(splitted_dir + 'val' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_valid)))","a13d9e5a":"plt.figure(figsize=(20,10))\nplt.subplot(1,3,1)\nplt.pie(number_images_train, labels=category, autopct='%.0f%%')\nplt.title(f'Train - {sum(number_images_train)} files')\nplt.subplot(1,3,2)\nplt.pie(number_images_test, labels=category, autopct='%.0f%%')\nplt.title(f'Test - {sum(number_images_test)} files')\nplt.subplot(1,3,3)\nplt.pie(number_images_valid, labels=category, autopct='%.0f%%')\nplt.title(f'Valid - {sum(number_images_valid)} files')\nplt.show()","93f41ead":"# 2. EDA the image folders","7479c31b":"# 5. Rechecking the output split","59e26101":"# 3. Splitting the images into train\/test\/validation folders\nAs image augmentation before data splitting can be considered to have data leakage, we started splitting the train\/test\/validation folders in this step before doing any image augmenetation technique.","78722e7e":"# 4. Image Augmentation\nAs we have small number of trainig images, we apply image augmentation technique and save it to copy_images folder for further modelling.","2eec908d":"There are some corrupted files.  However, these files are in read-only Kaggle input folder, so we will treat them later in our working folder.","ae3ab40e":"# 1. Install required packages","24923e50":"We'll remove all files that show problem and resize the image to 600 x 600 pixels in image generating process.","09cfd028":"This is the 1st notebook of total 5 notebooks in this series listed as following:\n1. EDA and image augmentation note books >> https:\/\/www.kaggle.com\/suradechk\/01-eda-and-image-augmentation-v2\n2. Setting up a baseline model using CNN >> https:\/\/www.kaggle.com\/suradechk\/02-baseline-model-using-cnn-v2\n3. Keypoint generation using movenet >> https:\/\/www.kaggle.com\/suradechk\/03-keypoint-movenet-v2\n4. Classification keypoint output using classical ML >> https:\/\/www.kaggle.com\/suradechk\/04-classification-using-keypoints-output-v2\n5. Classification keypoint output using ANN >> https:\/\/www.kaggle.com\/suradechk\/05-classification-using-ann-v2","25931dbc":"# This is part of DAAN570 - Final Project - RSI Prevention by Yoga - Modelling notebook\n<br>Team: 11: Suradech Kongkiatpaiboon and Burq Latif\nCourse: DAAN 570 \u2013 Deep Learning (Fall, 2021) - Penn State World Campus\n\n> Problem statement : Repetitive stress injury is extremely prevalent for anyone who works at the same spot for a long length of time, especially with the development of COVID-19 and the increase in work from home trend. We've identified certain flaws in traditional RSI prevention software on the market, and we've noted that yoga's popularity is growing by the day. The reason for this is the numerous physical, mental, and spiritual advantages that yoga may provide. Many people are following this trend and practice yoga without the help of a professional. However, doing yoga incorrectly or without adequate instruction can lead to serious health problems such as strokes and nerve damage. As a result, adhering to appropriate yoga poses is a vital consideration.\nIn this work, we present a method for identifying the user's postures and providing visual guidance to the user. In order to be more engaging with the user, this procedure is done in real-time and utilizes the traditional webcam on the laptop\/desktop to run the application.\n\nKeywords : Yoga, posture, classification, movenet, keypoint\n\nData Collection:\nWe took some images from open source yoga posture dataset from three following sites and applied basic data cleaning manually (e.g. remove corrupted images, remove misclassified yoga posture images).\n1. Open source dataset from https:\/\/www.kaggle.com\/general\/192938\n2. 3D synthetic dataset from https:\/\/laurencemoroney.com\/2021\/08\/23\/yogapose-dataset.html\n3. Yoga-82 dataset from https:\/\/sites.google.com\/view\/yoga-82\/home","e4a81097":"It looks like we have a good train\/test\/valid split now."}}