{"cell_type":{"80d2708e":"code","99649419":"code","3f598db4":"code","4c1a2692":"code","0f0e4255":"code","f2e60ded":"code","8103bd28":"code","cc5471c1":"code","1dcef17c":"code","7e4faab4":"code","7200741d":"code","483e63b3":"code","338d77fa":"code","940b6f1e":"code","3ede3668":"code","4be9bacd":"code","5ca544f8":"code","c7ddb1ce":"code","b3fca02d":"code","40235628":"code","9a89a728":"code","48e7949a":"code","84092cdd":"code","a9af0467":"code","cf2fc9a2":"code","2f3f65e9":"code","57a64252":"code","25503926":"code","05c42d4a":"code","dcd8c736":"code","214c9f9a":"code","a9a3ae21":"code","452199f3":"code","0089faba":"code","39027d2c":"code","14ea9054":"code","91d53bef":"code","9da89a07":"code","60d7a53b":"code","3cd6dccd":"code","d63e69ad":"code","befa6b39":"code","a541afa4":"code","d89dab32":"code","a3ae1f11":"code","0001a299":"code","d781d279":"code","5cb52364":"code","b222e015":"markdown","b15393bc":"markdown","f5cb311f":"markdown","74f6b069":"markdown","c4324781":"markdown","4159c101":"markdown"},"source":{"80d2708e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99649419":"train = pd.read_csv(\"..\/input\/water-water-everywhere-not-a-drop-to-drink\/train.csv\")\ntest = pd.read_csv(\"..\/input\/water-water-everywhere-not-a-drop-to-drink\/test.csv\")","3f598db4":"import seaborn as sns\nimport matplotlib.pyplot as plt","4c1a2692":"train","0f0e4255":"train['result']","f2e60ded":"train.info()","8103bd28":"train['unit'].unique()","cc5471c1":"catcols = ['categoryA','categoryB','categoryC','categoryD','categoryE','categoryF']\nfor i in catcols:\n    train[i] = train[i].str[5:]\n    \ntrain[catcols] = train[catcols].astype(float)","1dcef17c":"train['categoryA'].unique()","7e4faab4":"train.columns","7200741d":"train.drop('id', axis=1 ,inplace=True)","483e63b3":"train['unit'] = train['unit'].str[5:]\ntrain['unit'] = train['unit'].astype(float)","338d77fa":"train['unit']","940b6f1e":"train.fillna(method='ffill',inplace=True)","3ede3668":"x_train=train.drop('result', axis = 1).values\ny_train=train['result'].values","4be9bacd":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","5ca544f8":"x_train = scaler.fit_transform(x_train)","c7ddb1ce":"train.shape","b3fca02d":"train.corr()","40235628":"plt.figure(figsize=(12,12))\ntrainplot = sns.heatmap(train.corr(), cmap=\"copper_r\", annot=False)\nplt.show()","9a89a728":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score\nfrom sklearn.metrics import r2_score","48e7949a":"X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size = 0.30, random_state = 25)","84092cdd":"rf = RandomForestRegressor()\nrf.fit(X_train, Y_train)\nxgb = XGBRegressor()\nxgb.fit(X_train, Y_train) \nlr = LinearRegression()\nlr.fit(X_train, Y_train)\nlr = LinearRegression()\nlr.fit(X_train, Y_train)","a9af0467":"rf_pred= rf.predict(X_test)\nrm_pred= rm.predict(X_test)\nlr_pred = lr.predict(X_test)\nxgb_pred = xgb.predict(X_test) ","cf2fc9a2":"rm_rmse=np.sqrt(mean_squared_error(Y_test,rm_pred))\nrf_rmse=np.sqrt(mean_squared_error(Y_test,rf_pred))\nlr_rmse=np.sqrt(mean_squared_error(Y_test,lr_pred))\nxgb_rmse = np.sqrt(mean_squared_error(Y_test,xgb_pred))","2f3f65e9":"model_ev = pd.DataFrame({'Model': ['Linear Regression','Ridge Regression','Random Forest Regression','XG Boost Regressor'], \n                         'RMSE': [lr_rmse,rm_rmse, rf_rmse,xgb_rmse]})\nmodel_ev","57a64252":"rf = RandomForestRegressor()\nrf.fit(x_train, y_train)","25503926":"rm = Ridge(alpha=1.0)\nrm.fit(x_train, y_train)","05c42d4a":"lr = LinearRegression()\nlr.fit(x_train, y_train)","dcd8c736":"xgb = XGBRegressor()\nxgb.fit(x_train, y_train) ","214c9f9a":"catcols = ['categoryA','categoryB','categoryC','categoryD','categoryE','categoryF']\nfor i in catcols:\n    test[i] = test[i].str[5:]\ntest[catcols] = test[catcols].astype(float)","a9a3ae21":"test['unit'] = test['unit'].str[5:]\ntest['unit'] = test['unit'].astype(float)","452199f3":"test['categoryF'].unique()","0089faba":"test.dropna()","39027d2c":"test.info()","14ea9054":"test_nonid = test.drop('id', axis = 1).values","91d53bef":"test_nonid = scaler.transform(test_nonid)","9da89a07":"test_nonid","60d7a53b":"test.columns","3cd6dccd":"x_test=test_nonid","d63e69ad":"x_test = pd.DataFrame(x_test, columns = ['categoryA', 'categoryB', 'categoryC', 'categoryD', 'categoryE',\n       'categoryF', 'featureA', 'featureB', 'featureC', 'featureD', 'featureE',\n       'featureF', 'featureG', 'featureH', 'featureI', 'compositionA',\n       'compositionB', 'compositionC', 'compositionD', 'compositionE',\n       'compositionF', 'compositionG', 'compositionH', 'compositionI',\n       'compositionJ', 'unit'])","befa6b39":"x_test.fillna(method='ffill',inplace=True)","a541afa4":"np.any(np.isnan(x_test))","d89dab32":"xgb_pred = xgb.predict(x_test)","a3ae1f11":"test.fillna(method='ffill',inplace=True)","0001a299":"x_test_id = test.pop('id')","d781d279":"sub = pd.DataFrame()\nsub['Id'] = x_test_id\nsub['Result'] = xgb_pred\nsub.to_csv('submission.csv',index=False)","5cb52364":"sub","b222e015":"## Train Model Preprocessing","b15393bc":"## Training the Model using Train Dataset","f5cb311f":"## Importing Libraries","74f6b069":"## Importing Dataset","c4324781":"## Preprocessing the Testing Dataset","4159c101":"## Validation Testing"}}