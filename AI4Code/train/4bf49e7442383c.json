{"cell_type":{"573087eb":"code","2a874901":"code","fd636a42":"code","7a016166":"code","304a346b":"code","675336f9":"code","4bb1a64d":"code","75a810f9":"code","53cd589d":"code","ca64e7da":"code","d15a80dc":"code","811d6eb2":"code","bed71347":"code","b227dc23":"code","ee719f90":"code","af13cabd":"code","282ddca5":"code","71f856c7":"code","bc4f1db5":"code","1414ee22":"code","7ad86846":"code","c1c8bf64":"code","2c4fd482":"code","31bedc00":"code","fd1ac40f":"code","29ded5a2":"code","345d677c":"code","320be6e8":"code","7eb6a303":"code","ef5d3ba8":"code","ec3e88ac":"code","1cb4d319":"code","f21fb182":"code","bbfd05a7":"code","373b4627":"markdown","ef76b74a":"markdown","9f94aa08":"markdown","46e4989b":"markdown","b137c5ae":"markdown","b82d0700":"markdown","6b75843e":"markdown","426119d0":"markdown","914f9db3":"markdown","c897be32":"markdown"},"source":{"573087eb":"#import all packages\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv\nfrom pathlib import Path\nimport warnings\nfrom skimage.feature import hog\nimport tqdm\n\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_columns = None","2a874901":"#define paths and read data\nroot = '..\/input\/fashion-product-images-small\/'\nstyle_file = 'styles.csv'\nimage_folder = root + '\/images\/'\nprint(root+style_file)\nstyles = pd.read_csv(Path(root+style_file),error_bad_lines=False)","fd636a42":"#style file\nprint(\"Style shape: \", str(styles.shape))\nstyles.head()","7a016166":"styles.nunique()","304a346b":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm\ncategories = ['gender','masterCategory','subCategory','season','usage']\nfor cat in categories:\n    df_cat = styles.groupby(cat,as_index=False).size().sort_values(ascending=False).head(10)\n    df_cat.plot(kind='bar',title = cat)\n    plt.show()","675336f9":"all_images = []\n#labels = []\n\ndef load_image(ids,path=image_folder):\n    img = cv.imread(image_folder+ids+'.jpg',cv.IMREAD_GRAYSCALE) #load at gray scale\n    #img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) #convert to gray scale\n    return img,ids\n\nfor ids in tqdm(list(styles.id)[:20000]):\n    img,ids = load_image(str(ids))\n    if img is not None:\n        all_images.append([img,int(ids)])\n    #labels.append(ids)\nlen(all_images)","4bb1a64d":"# np.array(all_images[0])","75a810f9":"def resize_image(img,ids):\n    return cv.resize(img, (60, 80),interpolation =cv.INTER_LINEAR)\n    \nall_images_resized = [[resize_image(x,y),y] for x,y in all_images]\nlen(all_images_resized)","53cd589d":"styles.head()","ca64e7da":"[styles.masterCategory.value_counts().index]","d15a80dc":"df_labels = pd.DataFrame(all_images_resized,columns=['image','id'])\n\ntarget = 'masterCategory'\ncategories = ['Apparel', 'Accessories', 'Footwear', 'Personal Care', 'Free Items']\ndf_train = styles[styles[target].isin(categories)][['id',target]]\n\ndf_labels = pd.merge(df_labels,df_train,how='left',on=['id'])\ndf_labels = df_labels.fillna('Others')\ndf_labels['class'] = pd.factorize(df_labels[target])[0]\nprint(\"Data Shape: \", str(df_labels.shape))\nprint(df_labels[target].value_counts())","811d6eb2":"#mapper for targets and labels\nmapper = df_labels[['class',target]].drop_duplicates()","bed71347":"for image in df_labels.image[:20]:\n    print(image.shape)\n    plt.imshow(image)\n    fast = cv.FastFeatureDetector_create(50)\n    kp = fast.detect(image,None)\n    img2 = cv.drawKeypoints(image, kp, None, color=(255,0,0))\n    # Print all default params\n    #print( \"Threshold: {}\".format(fast.getThreshold()) )\n    #print( \"neighborhood: {}\".format(fast.getType()) )\n    print( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)))\n    fast_image=cv.drawKeypoints(image,kp,image)\n    plt.imshow(fast_image);plt.title('FAST Detector')\n    plt.show()","b227dc23":"train_images = np.stack(df_labels.image.values,axis=0)\nn_samples = len(train_images)\ndata_images = train_images.reshape((n_samples, -1))","ee719f90":"ppcr = 8\nppcc = 8\nhog_images = []\nhog_features = []\nfor image in tqdm(train_images):\n    blur = cv.GaussianBlur(image,(5,5),0)\n    fd,hog_image = hog(blur, orientations=8, pixels_per_cell=(ppcr,ppcc),cells_per_block=(2,2),block_norm= 'L2',visualize=True)\n    hog_images.append(hog_image)\n    hog_features.append(fd)\n\nhog_features = np.array(hog_features)\n\nhog_features.shape","af13cabd":"for img in hog_images[:20]:\n    plt.imshow(img)\n    plt.show()","282ddca5":"edges = [cv.Canny(image,50,150,apertureSize = 3) for image in train_images]\nedges = np.array(edges)\nn_samples_edges = len(edges)\nedge_images = edges.reshape((n_samples, -1))\nedge_images.shape","71f856c7":"train_images.shape, hog_features.shape, edge_images.shape","bc4f1db5":"edge_hog = np.hstack([hog_features,edge_images])\nedge_hog.shape","1414ee22":"histr = [cv.calcHist([img],[0],None,[256],[0,256]) for img in train_images]\nhistr = np.array(histr)\nn_samples_histr = len(histr)\nimage_hist = histr.reshape((n_samples_histr, -1))\nimage_hist.shape","7ad86846":"edge_hog = np.hstack([hog_features,edge_images,image_hist])\nedge_hog.shape","c1c8bf64":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(hog_features,df_labels['class'],test_size=0.2,stratify=df_labels['class'])\nprint('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\nprint('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))","2c4fd482":"y_train.value_counts(),y_test.value_counts()","31bedc00":"from sklearn import datasets, svm, metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n# # Create a classifier: a support vector classifier\n# classifier = svm.SVC(gamma=0.001)\n# #fit to the trainin data\n# classifier.fit(X_train,y_train)","fd1ac40f":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\ntest_accuracy = []\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train)\n\nclassifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute')\nclassifier.fit(X_scaled, y_train)\ntest_accuracy = classifier.score(scaler.transform(X_test), y_test)\nprint(test_accuracy)\n\n# #FOR TUNING\n# print(search_params)\n# for p in tqdm(search_params):\n#     #classifier = svm.SVC(gamma=p)\n#     classifier = RandomForestClassifier(max_depth=8,n_estimators=600)\n\n#     classifier.fit(X_scaled, y_train)\n#     test_accuracy.append([p,classifier.score(scaler.transform(X_test), y_test)])\n\n# df_accuracy = pd.DataFrame(test_accuracy,columns =['gamma','accuracy'])\n# df_accuracy.index = df_accuracy.gamma\n# df_accuracy[['accuracy']].plot()\n# plt.show()","29ded5a2":"##PCA\n#from sklearn.decomposition import PCA\n# pca = PCA(.90)\n# principalComponents = pca.fit_transform(X = X_scaled)","345d677c":"mapper= mapper.reset_index(drop=True)","320be6e8":"y_pred = classifier.predict(scaler.transform(X_test))\n\ndf_result = pd.DataFrame(y_test)\ndf_result['id'] = df_result.index\ndf_result = df_result.rename(columns={'class':'actual'})\ndf_result['predicted'] = y_pred\ndf_result = df_result.reset_index(drop=True)\ndf_result = pd.merge(df_result,mapper,left_on='predicted',right_on = 'class',how='inner')\ndf_result = df_result.drop(columns=['class'],axis=1)\ndf_result = df_result.rename(columns={'gender':'predicted_category'})\n\ndf_result = pd.merge(df_result,mapper,left_on='actual',right_on = 'class',how='inner')\ndf_result = df_result.drop(columns=['class'],axis=1)\ndf_result.shape","7eb6a303":"#some references for debugging\nkd = df_result[df_result.actual!=df_result.predicted]\nprint(kd.shape)\nkd.head()","ef5d3ba8":"# image_id = styles[styles.index==2663]['id'].reset_index(drop=True)\n# k = str(image_id)\n# print(k)\n#print(image_folder+str(image_id)+'.jpg')\n\n#debug image with id\n##it is recommended not to use the image used for training. You can make a separate test folder and check the result\nimg = cv.imread(image_folder+str(7347)+'.jpg')\nimg = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nimg.shape\nplt.imshow(img)","ec3e88ac":"list_of_categories = categories +['Others']\n\nprint(\"Classification Report: \\n Target: %s \\n Labels: %s \\n Classifier: %s:\\n%s\\n\"\n      % (target,list_of_categories,classifier, metrics.classification_report(y_test, y_pred)))\n\ndf_report = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred),columns = list_of_categories )\ndf_report.index = [list_of_categories]\ndf_report","1cb4d319":"\n#test image with id\n##it is recommended to use different test images which were not used for training\ntest_data_location = image_folder\n\nimg = cv.imread(test_data_location+'2093.jpg',cv.IMREAD_GRAYSCALE) #load at gray scale\nimage = cv.resize(img, (60, 80),interpolation =cv.INTER_LINEAR)\n\nppcr = 8\nppcc = 8\nhog_images_test = []\nhog_features_test = []\n\nblur = cv.GaussianBlur(image,(5,5),0)\nfd_test,hog_img = hog(blur, orientations=8, pixels_per_cell=(ppcr,ppcc),cells_per_block=(2,2),block_norm= 'L2',visualize=True)\nhog_images_test.append(hog_img)\nhog_features_test.append(fd)\n\nhog_features_test = np.array(hog_features_test)\ny_pred_user = classifier.predict(scaler.transform(hog_features_test))\n#print(plt.imshow(hog_images_test))\nprint(y_pred_user)\nprint(\"Predicted MaterCategory: \", mapper[mapper['class']==int(y_pred_user)]['masterCategory'])","f21fb182":"#test image HOG\nplt.imshow(hog_img)\nplt.show()","bbfd05a7":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import NearestNeighbors\n\nscaler_global = MinMaxScaler()\nfinal_features_scaled = scaler_global.fit_transform(hog_features)\n    \nneighbors = NearestNeighbors(n_neighbors=20, algorithm='brute')\nneighbors.fit(final_features_scaled)\n\ndistance,potential = neighbors.kneighbors(scaler_global.transform(hog_features_test))\nprint(\"Potential Neighbors Found!\")\nneighbors = []\nfor i in potential[0]:\n    neighbors.append(i)\n\nrecommendation_list = list(df_labels.iloc[neighbors]['id'])\nrecommendation_list","373b4627":"Below is the script only for classification of 5 columns (masterCategory, subCategory, gender, usage and season.  In the next you will find script for an image recommendation as well. For any information other than the script please visit my [article](https:\/\/medium.com\/@anirban.malick_71287\/histogram-of-oriented-gradients-hog-for-multiclass-image-classification-and-image-recommendation-cf0ea2caaae8)","ef76b74a":"## Training with KNN","9f94aa08":"## Distribution of the columns","46e4989b":"## Check distribution of the classes","b137c5ae":"## Canny Edge","b82d0700":"## Resize Images","6b75843e":"## FAST detected Features","426119d0":"## For Debugging","914f9db3":"## Load Images","c897be32":"## Histogram"}}