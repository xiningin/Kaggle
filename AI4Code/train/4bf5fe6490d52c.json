{"cell_type":{"36a44406":"code","3ee5bb16":"code","4e2413d4":"code","d4c0cadd":"code","c3174770":"code","5dc04803":"code","1351ba7f":"code","f4efa9f2":"code","799fff7c":"code","7f337d8c":"code","d20d4715":"code","95aa9db2":"code","3b6e9e0a":"code","fe8c7111":"code","1d9c5542":"code","101bc141":"code","1762a240":"code","ffa365fb":"code","beafcce9":"code","967b1ed6":"code","72ac6c5d":"code","4eaf79ed":"code","c6a94dc7":"code","ceac68d0":"code","89a5c9cc":"code","942b7511":"code","8a6153fb":"code","18d5c0fd":"code","e5579d1c":"code","cea8018c":"code","83868dd8":"code","dca82ad3":"code","91c2ba51":"code","0b310872":"code","ba470701":"code","1516e72a":"code","1cb2ba7b":"code","edda2c55":"code","6a628ab2":"code","bf481d0c":"code","d76c0daa":"code","b9bdb035":"code","30e02463":"code","0b1dc449":"code","4539ada7":"code","00ac4dbf":"code","d354fe76":"code","db5a87d1":"code","6c6cae81":"code","eefb96ff":"code","3c582b4a":"code","6bbaa983":"code","e28cf505":"code","ae1d4bfe":"code","d07e84b0":"code","61b626f9":"code","fd223ca3":"code","a7ec6ef6":"code","805fe31c":"code","488f26ae":"markdown","55db6669":"markdown","f8be7352":"markdown","776e5c20":"markdown","8784dc30":"markdown","df7385f4":"markdown","4e425b41":"markdown","20c51d4d":"markdown","40d733e2":"markdown","94bd0e0e":"markdown","9006e2fd":"markdown","dba55b90":"markdown","c1353a7e":"markdown","e6409ea3":"markdown","453be73d":"markdown","cab52d3d":"markdown","f22607ae":"markdown","07eefe21":"markdown","fbe5125f":"markdown","03efa5cd":"markdown","cd375311":"markdown","0eeec061":"markdown","8d4243fb":"markdown","3040e971":"markdown","e423010e":"markdown","aced8890":"markdown","1ed512d0":"markdown","f16fc815":"markdown","75a758b8":"markdown","54c330d7":"markdown","649f3f36":"markdown","191592cf":"markdown"},"source":{"36a44406":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nimport scipy as stats","3ee5bb16":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest  = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","4e2413d4":"train.head()","d4c0cadd":"train.describe().T","c3174770":"train.info()","5dc04803":"corr= train.corr()['SalePrice'].sort_values(ascending=False)\ncorr","1351ba7f":"def missing_val(df):\n  miss=df.isnull().sum().sort_values(ascending=False) \n  total_miss = miss[miss != 0]\n  percent = round(total_miss \/ len(df)*100,2)\n  return pd.concat((total_miss , percent) , axis=1 , keys=['Total Miss' , 'Percentage'])","f4efa9f2":"missing_val(train)","799fff7c":"missing_val(test)","7f337d8c":"figure = plt.figure(figsize=(15,8))\nplt.subplot(1,3,1)\nsns.distplot(train['SalePrice'])\n\nfrom scipy import stats\nplt.subplot(1,3,2)\nstats.probplot(train['SalePrice'] , plot=plt)\n\nplt.subplot(1,3,3)\nsns.boxplot(train['SalePrice'] ,orient='v')","d20d4715":"print('Skewness of Saleprice is :-   ' , train['SalePrice'].skew()) \nprint('kurtoises of Saleprice is :   ' , train['SalePrice'].kurt())","95aa9db2":"train['SalePrice'] = np.log1p(train['SalePrice'])\n\nprint('Skewness of Saleprice is :-   ' , train['SalePrice'].skew()) \nprint('kurtoises of Saleprice is :   ' , train['SalePrice'].kurt())","3b6e9e0a":"fg = plt.figure(figsize=(15,8))\nplt.subplot(1,3,1)\nsns.distplot(train['SalePrice'])\n\n\nplt.subplot(1,3,2)\nstats.probplot(train['SalePrice'] , plot=plt)\n\nplt.subplot(1,3,3)\nsns.boxplot(train['SalePrice'], orient='v')","fe8c7111":"fg = plt.figure(figsize=(18,12))\nsns.heatmap(train.corr())","1d9c5542":"# EXplore correlation between features\ncorr = train.corr()['SalePrice'].sort_values(ascending =False)[:10]\nprint(corr)","101bc141":"st_corr=['OverallQual' , 'GrLivArea' ,'GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','YearBuilt','YearRemodAdd']\nprint(st_corr)\nfor i in st_corr:\n  plt.subplots(figsize=(12,8))\n  sns.scatterplot(x = train[i] , y=train['SalePrice'])\n#sns.scatterplot(x = train['OverallQual'] , y=train['SalePrice'])","1762a240":"numeric_data = train.select_dtypes(include = np.number).drop(['SalePrice'] , axis =1)\nitems = numeric_data.loc[ : , ['OverallQual','GrLivArea','GarageCars','TotalBsmtSF',\n                              'FullBath','YearBuilt','YearRemodAdd'  ]]","ffa365fb":" #visualize these itemes using Boxplot\nfig = plt.figure(figsize=(12,12))\nfor col in range(len(items.columns)) : \n    fig.add_subplot(3 , 3 , col+1)\n    sns.boxplot(y=items.iloc[: , col])\nplt.show()\n\n    # Visualize these items using multivariate analysis (SCatter plot)   \nfig = plt.figure(figsize=(16,12))\nfor col in range(len(items.columns)):\n    fig.add_subplot(3,3,col+1)\n    sns.scatterplot(items.iloc[ : , col] , train['SalePrice'])\nplt.show()","beafcce9":"  # Using Z-Score to identify outliers\nfrom scipy import stats\nz= np.abs(stats.zscore(items))\nprint(z)\nthreshold = 4\nprint(np.where(z > threshold))\n    # Remove outlier using z-score\ntrain.shape\ntrain = train[(z < threshold).all(axis=1)]\ntrain.shape","967b1ed6":"train.corr()['SalePrice'].sort_values(ascending=False)[:10]    # note that correlation of thesee features still strong","72ac6c5d":"dataset = pd.concat((train,test) , sort = False).reset_index(drop=True)\ndataset = dataset.drop(columns =['SalePrice'] , axis =1 )","4eaf79ed":"missing_val(dataset)","c6a94dc7":"missing_val(dataset)","ceac68d0":"dataset['totalSF'] =( dataset['TotalBsmtSF'] + dataset['1stFlrSF'] + dataset['2ndFlrSF']  )\ndataset['total_bathrooms'] = (dataset['BsmtFullBath'] + 0.5*dataset['BsmtHalfBath'] + dataset['FullBath'] + 0.5*dataset['HalfBath'])\ndataset['ageHouse'] = (dataset['YrSold'] - dataset['YearBuilt'] )\n","89a5c9cc":"dataset.drop(['Id','Utilities','PoolQC','MiscFeature','Alley','Fence','GarageYrBlt'] , axis=1 , inplace=True)\ndataset.drop(['TotalBsmtSF' , '1stFlrSF' ,'2ndFlrSF'] , axis = 1 , inplace =True)\ndataset.drop(['BsmtFullBath' , 'BsmtHalfBath' , 'FullBath' , 'HalfBath'] , axis=1 , inplace=True)\n","942b7511":"miss_mode =  ['MasVnrArea' , 'Electrical' , 'MSZoning' , 'SaleType','Exterior1st','Exterior2nd','KitchenQual']\nfor col in miss_mode:\n    dataset[col]  = dataset[col].fillna(dataset[col].mode()[0])\n    \nmissing_feat = ['GarageType','GarageCond','GarageQual','GarageFinish',\n                'BsmtExposure','BsmtFinType2','BsmtFinType1','BsmtCond','BsmtQual',\n                'FireplaceQu','MasVnrType']\nfor col in missing_feat:\n    dataset[col]=dataset[col].fillna('None')\n\ndataset['Functional'] = dataset['Functional'].fillna('Typ')\ndataset['LotFrontage'] = dataset['LotFrontage'].fillna(dataset['LotFrontage'].median())\n\nmiss_zero = ['total_bathrooms','totalSF','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','GarageArea','GarageCars' ]\nfor col in miss_zero:\n    dataset[col] = dataset[col].fillna(0)\n\n\n#check on misssing values\nmissing_val(dataset)","8a6153fb":"dataset.shape","18d5c0fd":"dataset.dropna(inplace=True)","e5579d1c":"dataset.shape","cea8018c":"missing_val(dataset)","83868dd8":"dataset['totalSF'].describe().T","dca82ad3":"dataset['ageHouse'].describe().T","91c2ba51":"neg_value = dataset[dataset['ageHouse'] < 0 ]\nneg_value","0b310872":"dataset.loc[dataset['YrSold'] < dataset['YearBuilt'], 'YrSold'] = 2009\ndataset['ageHouse'] = (dataset['YrSold'] - dataset['YearBuilt'] )\ndataset['ageHouse'].describe()","ba470701":"dataset['MSSubClass']   = dataset['MSSubClass'].astype(str)\n","1516e72a":"#check for duplicate rows \nduplicate= train[train.duplicated()]\nprint(duplicate) # there is no duplicate rows\ndataset.shape","1cb2ba7b":"final_features = pd.get_dummies(dataset).reset_index(drop=True)\nprint(final_features.shape)\nfinal_features.head()","edda2c55":"final_features =final_features.loc[:,~final_features.columns.duplicated()]","6a628ab2":"final_features.shape","bf481d0c":"y= train['SalePrice']\nX = final_features.iloc[: len(y) , :]\ndf_test  = final_features.iloc[len(y): , :]","d76c0daa":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nX = sc_x.fit_transform(X)\ny = sc_y.fit_transform(np.array(y).reshape(-1,1))","b9bdb035":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X , y)\ny_pred = lr.predict(df_test)\nprint(y_pred)","30e02463":"from sklearn.model_selection import KFold , cross_val_score\n#lr = LinearRegression()\ncv = KFold(shuffle= True , random_state=2 , n_splits=10)\nscores = cross_val_score(lr , X , y , cv =cv ,scoring = 'neg_mean_absolute_error' )\nprint(scores.mean())","0b1dc449":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nridge = Ridge(alpha = 400)\nridge.fit(X , y)\ntest_pred = ridge.predict(df_test)\nprint(test_pred)","4539ada7":"import pickle\nfilename = 'Ridge_model.pkl'\npickle.dump(ridge , open(filename , 'wb') )","00ac4dbf":"## create simple submission file \npred = pd.DataFrame(test_pred)\nsample_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nfinal_data = pd.concat([sample_df['Id'] , pred] , axis=1)\nfinal_data.columns=['Id' , 'SalePrice']\nfinal_data.to_csv('Ridge_model.csv' , index=False)","d354fe76":"from sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error , mean_absolute_error\nlasso = Lasso(alpha = 0.001 )\nlasso.fit(X , y)\ntest_pred = lasso.predict(df_test)\nprint(test_pred)","db5a87d1":"#save model \nimport pickle\nfilename = 'Lasso_model.pkl'\npickle.dump(lasso , open(filename , 'wb') )","6c6cae81":"## create simple submission file \npred = pd.DataFrame(test_pred)\nsample_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nfinal_data = pd.concat([sample_df['Id'] , pred] , axis=1)\nfinal_data.columns=['Id' , 'SalePrice']\nfinal_data.to_csv('Lasso_model.csv' , index=False)","eefb96ff":"from sklearn.linear_model import ElasticNet\nelastic = ElasticNet(alpha =0.0001 ,normalize= True)\nelastic.fit(X , y)\ntest_pred = elastic.predict(df_test)\nprint(test_pred)","3c582b4a":"#save model \nimport pickle\nfilename = 'Lasso_model.pkl'\npickle.dump(elastic , open(filename , 'wb') )","6bbaa983":"## create simple submission file \npred = pd.DataFrame(test_pred)\nsample_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nfinal_data = pd.concat([sample_df['Id'] , pred] , axis=1)\nfinal_data.columns=['Id' , 'SalePrice']\nfinal_data.to_csv('Elastic_model.csv' , index=False)","e28cf505":"X.shape","ae1d4bfe":"from keras import backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))","d07e84b0":"import keras\nfrom keras.models import Sequential \nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 100, kernel_initializer='he_uniform',activation='relu',input_dim = 292))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 50, kernel_initializer = 'he_uniform',activation='relu'))\n\n# Adding the third hidden layer\nclassifier.add(Dense(units = 25, kernel_initializer = 'he_uniform',activation='relu'))\n\n# Adding the forth hidden layer\nclassifier.add(Dense(units = 50, kernel_initializer = 'he_uniform',activation='relu'))\n\n# Adding the fifth hidden layer\nclassifier.add(Dense(units = 25, kernel_initializer = 'he_uniform',activation='relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'he_uniform'))\n\n# Compiling the ANN\nclassifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n\n# Fitting the ANN to the Training set\nmodel_history=classifier.fit(X, y,validation_split=0.20,epochs=1000, batch_size = 10)\n\n\n","61b626f9":"test_pred = classifier.predict(df_test)\nprint(test_pred)","fd223ca3":"\n## create simple submission file \npred = pd.DataFrame(test_pred)\nsample_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nfinal_data = pd.concat([sample_df['Id'] , pred] , axis=1)\nfinal_data.columns=['Id' , 'SalePrice']\nfinal_data.to_csv('ANN_model.csv' , index=False)\n","a7ec6ef6":"\nfrom sklearn.svm import SVR\nsvr  = SVR(kernel = 'linear')\nsvr.fit(X , y )\ny_pred = svr.predict(df_test)\nprint(y_pred)\n","805fe31c":"\n## create simple submission file \npred = pd.DataFrame(test_pred)\nsample_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nfinal_data = pd.concat([sample_df['Id'] , pred] , axis=1)\nfinal_data.columns=['Id' , 'SalePrice']\nfinal_data.to_csv('SVR_model.csv' , index=False)\n","488f26ae":"using Ridg","55db6669":"process Categorical Data","f8be7352":"using heatmap to show correlation between features","776e5c20":"#Preprocessing Step","8784dc30":"make submission for Ridge_model","df7385f4":"visualize features that has strong correlation with SalePrice","4e425b41":"using cross validation","20c51d4d":"#Fill Missing Values","40d733e2":"Explore Missing_values","94bd0e0e":"#Explore Data STEP","9006e2fd":"visualize Saleprice after log tranformation","dba55b90":"Using Lasso","c1353a7e":"#process Missing Values","e6409ea3":"drop Features","453be73d":"#using ANN","cab52d3d":"this house YearRmdAdd in 2009    sold in 2007   build in 2008\nso we will make yearSold in 2009 to make it sense","f22607ae":"import dataset","07eefe21":"merge train and test data ","fbe5125f":"Save model ","03efa5cd":"using ElasticNet","cd375311":"process outlier","0eeec061":"Explore y ['SalePrice']","8d4243fb":"Manage Skewness of Saleprice ","3040e971":"<a href=\"https:\/\/colab.research.google.com\/github\/mahmoud2571587\/House_price_prediction\/blob\/master\/House_price.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","e423010e":"import libraries","aced8890":"#Scaling Features","1ed512d0":"we notice that min for ageHouse is -1 and this ubnormal","f16fc815":"check on correlation after remove outliers \n","75a758b8":"Feature Engineering","54c330d7":"edit skewness for some features","649f3f36":"change type of some features","191592cf":"unsing Simple linear model "}}