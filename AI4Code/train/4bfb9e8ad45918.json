{"cell_type":{"abbc85bc":"code","0e2e600d":"code","582a2457":"code","1eb4631a":"code","8ea61c7d":"code","c2b6cce4":"code","6e6737b6":"code","b8477ca5":"code","75d2e93a":"code","df18509c":"code","1a7a0676":"code","5664ca3f":"code","1d0019d6":"code","58db391b":"code","2c2b0282":"code","9e7484d3":"code","4c5265aa":"code","288c336d":"code","061db70b":"code","73cf5c8a":"code","3e903856":"code","9431f04e":"code","87b72536":"code","1388159c":"code","bdfee086":"code","49008304":"code","10d859fa":"code","ebeb3ccc":"code","bba17e32":"code","2fed114b":"code","335c5be0":"code","8cf254f3":"code","4d2fb3a9":"code","09546342":"code","0a596b11":"code","fa171271":"code","d7ca65b7":"code","c3cd10be":"code","b974da93":"code","8701912b":"code","2aeca257":"code","8f38a999":"code","6e318edb":"code","702647aa":"code","11ba4d5e":"code","07c22844":"code","a3f4758a":"code","411696b4":"code","81ec531c":"code","614407a8":"code","d48ac3cd":"code","f722011e":"code","e72a650a":"code","8805e9d9":"code","f778ceb2":"code","33d157d9":"code","64865ef1":"code","1f45d70e":"code","618ef19b":"code","b4f5803a":"code","1b4aaf51":"code","9888df6f":"code","032f46f9":"code","0990e408":"code","e2fd6d49":"code","93b0c009":"code","b9d7f8b5":"code","601b0843":"markdown","8b993834":"markdown","4ea29ec7":"markdown","b699b845":"markdown","6f625dae":"markdown","0af63289":"markdown","bad50152":"markdown","4653c998":"markdown","a00ab1f8":"markdown","d26e94ef":"markdown","f13bb64d":"markdown","0151c7b7":"markdown","fa4831e4":"markdown","f4db09d8":"markdown","cab03c0e":"markdown","5b0857c5":"markdown","f967b652":"markdown","54c49ddb":"markdown","d30e3dd7":"markdown","806529c5":"markdown","cd46b2d9":"markdown","53efa839":"markdown","0a462284":"markdown","8eb87ce1":"markdown","4d5ea32c":"markdown","215600c8":"markdown","69694713":"markdown","b712b754":"markdown","5b26086e":"markdown","178631ce":"markdown","4fa756a3":"markdown","e1b62483":"markdown","d5c3dddb":"markdown","2b4f82b8":"markdown","f35f4efc":"markdown","655057e9":"markdown","accb3c3e":"markdown","258f2f03":"markdown","2091f90f":"markdown","7d363437":"markdown","81364cfb":"markdown"},"source":{"abbc85bc":"import numpy as np\nimport pandas as pd\n\nimport os\nimport random \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split","0e2e600d":"import zipfile\n\nwith zipfile.ZipFile('..\/input\/dogs-vs-cats\/test1.zip', 'r') as zip_ref:\n    \n    zip_ref.extractall('.\/')\n    \nwith zipfile.ZipFile('..\/input\/dogs-vs-cats\/train.zip', 'r') as zip_ref:\n    \n    zip_ref.extractall('.\/')","582a2457":"# Read input files to create training dataset\nfilenames = os.listdir('.\/train')\n\ncategories = []\n\nfor filename in filenames:\n    \n    category = filename.split('.')[0]\n    \n    if(category == 'dog'):\n        \n        categories.append('dog')\n        \n    else:\n        \n        categories.append('cat')\n        \n# create a dataframe\n\ndf = pd.DataFrame({\n        \n        'filename' : filenames,\n    \n        'category' : categories\n    \n    })","1eb4631a":"df.head()","8ea61c7d":"df.tail()","c2b6cce4":"df['category'].value_counts()","6e6737b6":"df['category'].value_counts().plot(kind = 'bar')","b8477ca5":"# sample image\n\nsample = random.choice(filenames)\n\nimage = image.load_img('.\/train\/' + sample)\n\nplt.imshow(image)","75d2e93a":"train_df, validate_df = train_test_split(df, test_size = 0.20, random_state = 42)\n\ntrain_df = train_df.reset_index(drop=True)\n\nvalidate_df = validate_df.reset_index(drop=True)","df18509c":"train_df.head()","1a7a0676":"validate_df.head()","5664ca3f":"train_df['category'].value_counts().plot(kind = 'bar')","1d0019d6":"validate_df['category'].value_counts().plot(kind = 'bar')","58db391b":"total_train = train_df.shape[0]\n\ntotal_validate = validate_df.shape[0]\n\nprint(\"Total number of example in training dataset : {0}\".format(total_train))\n\nprint(\"Total number of example in validation dataset : {0}\".format(total_validate))","2c2b0282":"from tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n\nfrom tensorflow.keras import optimizers","9e7484d3":"class Model:\n    \n    def __init__(self, IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS):\n        \n        self.IMG_WIDTH = IMG_WIDTH\n        \n        self.IMG_HEIGHT = IMG_HEIGHT\n               \n        self.IMG_CHANNELS = IMG_CHANNELS\n    \n    def create_model_one(self):\n        \n        model_one = Sequential()\n        \n        # Adding Layers to create a convolutional mask\/kernel that is wind with layers input which helps produce a tensor of outputs\n        \n        # Layer 1\n        model_one.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n        \n        model_one.add(MaxPooling2D((2,2)))\n        \n        # Layer 2\n        model_one.add(Conv2D(64, (3,3), activation = 'relu'))\n        \n        model_one.add(MaxPooling2D((2,2)))\n        \n        # Layer 3\n        model_one.add(Conv2D(128, (3,3), activation = 'relu'))\n        \n        model_one.add(MaxPooling2D((2,2)))\n               \n        # Layer 4\n        model_one.add(Conv2D(128, (3,3), activation = 'relu'))\n        \n        model_one.add(MaxPooling2D((2,2)))\n           \n        model_one.add(Flatten())\n                      \n        model_one.add(Dense(512, activation = 'relu'))\n        \n        model_one.add(Dense(1, activation = 'sigmoid'))\n                      \n        return model_one\n    \n    def create_model_two(self):\n        \n        model_two = Sequential()\n        \n        # Adding Layers to create a convolutional mask\/kernel that is wind with layers input which helps produce a tensor of outputs\n        \n        # Layer 1\n        model_two.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n        \n        model_two.add(MaxPooling2D((2,2)))\n        \n        # Layer 2\n        model_two.add(Conv2D(64, (3,3), activation = 'relu'))\n        \n        model_two.add(MaxPooling2D((2,2)))\n        \n        # Layer 3\n        model_two.add(Conv2D(128, (3,3), activation = 'relu'))\n        \n        model_two.add(MaxPooling2D((2,2)))\n               \n        # Layer 4\n        model_two.add(Conv2D(128, (3,3), activation = 'relu'))\n        \n        model_two.add(MaxPooling2D((2,2)))\n           \n        model_two.add(Flatten())\n        \n        # DropoutLayer for preventing model from overfitting\n        model_two.add(Dropout(0.5))\n                      \n        model_two.add(Dense(512, activation = 'relu'))\n        \n        model_two.add(Dense(1, activation = 'sigmoid'))\n                      \n        return model_two\n    \n        \n        ","4c5265aa":"IMG_WIDTH = 150\n\nIMG_HEIGHT = 150\n\nIMG_CHANNELS = 3\n\nmodel = Model(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)","288c336d":"model_1 = model.create_model_one()\n\nmodel_1.summary()","061db70b":"from keras import optimizers\n\nmodel_1.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr = 1e-4), metrics =['acc'])","73cf5c8a":"from keras.preprocessing.image import ImageDataGenerator","3e903856":"train_imgdatagen = ImageDataGenerator(rescale = 1.\/255)\n\nvalid_imgdatagen = ImageDataGenerator(rescale = 1.\/255)","9431f04e":"train_generator_m1 = train_imgdatagen.flow_from_dataframe(\n                    train_df,\n                    \n                    \".\/train\", \n                    \n                    x_col='filename',\n    \n                    y_col='category',\n                    \n                    target_size = (150, 150), # resize image to 150x150\n                    \n                    batch_size = 20,\n    \n                    class_mode = 'binary'\n                  )\n\n\nvalidation_generator_m1 = train_imgdatagen.flow_from_dataframe(\n                    validate_df,\n    \n                    \".\/train\", \n                    \n                    x_col='filename',\n    \n                    y_col='category',\n                    \n                    target_size = (150, 150), # resize image to 150x150\n                    \n                    batch_size = 20,\n    \n                    class_mode = 'binary'\n                  )\n","87b72536":"for data_batch, labels_batch in train_generator_m1:\n    \n    print('Data batch shape: {0}'. format(data_batch.shape))\n    \n    print('Labels batch shape: {0}'. format(labels_batch.shape))\n    \n    break","1388159c":"train_imgdatagen_m2 = ImageDataGenerator(\n                     rescale = 1.\/255,\n    \n                     rotation_range = 15,\n    \n                     width_shift_range = 0.1,\n    \n                     height_shift_range = 0.1,\n    \n                     shear_range = 0.1,\n    \n                     zoom_range = 0.2,\n    \n                     horizontal_flip = True\n                    )\n\nvalid_imgdatagen_m2 = ImageDataGenerator(\n                             rescale = 1.\/255\n                         )","bdfee086":"model_2 = model.create_model_two()\n\nmodel_2.summary()","49008304":"model_2.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr = 1e-4), metrics =['acc'])","10d859fa":"train_generator_m2 = train_imgdatagen_m2.flow_from_dataframe(\n                    train_df,\n                    \n                    \".\/train\", \n                    \n                    x_col='filename',\n    \n                    y_col='category',\n                    \n                    target_size = (150, 150), # resize image to 150x150\n                    \n                    batch_size = 32,\n    \n                    class_mode = 'binary'\n                  )\n\n\nvalidation_generator_m2 = valid_imgdatagen_m2.flow_from_dataframe(\n                    validate_df,\n    \n                    \".\/train\", \n                    \n                    x_col='filename',\n    \n                    y_col='category',\n                    \n                    target_size = (150, 150), # resize image to 150x150\n                    \n                    batch_size = 32,\n    \n                    class_mode = 'binary'\n                  )\n","ebeb3ccc":"from tensorflow.keras.applications import VGG16","bba17e32":"conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (150,150,3))\n\nconv_base.summary()","2fed114b":"model_3 = Sequential()\n\nmodel_3.add(conv_base)\n\nmodel_3.add(Flatten())\n\nmodel_3.add(Dense(256, activation = 'relu'))\n\nmodel_3.add(Dense(1, activation = 'sigmoid'))","335c5be0":"model_3.summary()","8cf254f3":"print(\"The number of trainable weights before freezing the conv base: \", len(model_3.trainable_weights))","4d2fb3a9":"conv_base.trainable = False\n\nprint(\"The number of trainable weights after freezing the conv base: \", len(model_3.trainable_weights))","09546342":"conv_base.trainable = True\n\nset_trainable = False\n\nfor layer in conv_base.layers:\n    \n    if layer.name == 'block5_conv1':\n        \n        set_trainable = True\n        \n    if set_trainable:\n        \n        layer.trainable = True\n        \n    else:\n        \n        layer.trainable = False","0a596b11":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau","fa171271":"earlystop = EarlyStopping(patience=10)","d7ca65b7":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","c3cd10be":"callbacks = [earlystop, learning_rate_reduction]","b974da93":"model_3.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr = 1e-5), metrics =['acc'])","8701912b":"from PIL import Image","2aeca257":"history_1 = model_1.fit(\n            train_generator_m1,\n    \n            epochs = 30,\n    \n            steps_per_epoch = 100,\n            \n            validation_data = validation_generator_m1,\n    \n            validation_steps = 50\n            )","8f38a999":"print(np.mean(history_1.history['acc']))","6e318edb":"print(np.mean(history_1.history['val_acc']))","702647aa":"model_1.save('model_1.h5')","11ba4d5e":"plt.plot(history_1.history['acc'], color = 'black')\n\nplt.plot(history_1.history['val_acc'], color = 'blue')\n\nplt.title('Training and validation accuracy of model 1')\n\nplt.xlabel('Epochs')\n\nplt.ylabel('Accuracy')\n\nplt.show()\n\nplt.plot(history_1.history['loss'], color = 'black')\n\nplt.plot(history_1.history['val_loss'], color = 'blue')\n\nplt.title('Training and validation loss of model 1')\n\nplt.xlabel('Epochs')\n\nplt.ylabel('Accuracy')\n\nplt.show()","07c22844":"history_2 = model_2.fit(\n            train_generator_m2,\n    \n            epochs = 100,\n    \n            steps_per_epoch = 100,\n            \n            validation_data = validation_generator_m2,\n    \n            validation_steps = 50,\n    \n            callbacks = [earlystop, learning_rate_reduction]\n            )","a3f4758a":"print(np.mean(history_2.history['acc']))","411696b4":"print(np.mean(history_2.history['val_acc']))","81ec531c":"model_2.save('model_2.h5')","614407a8":"plt.plot(history_2.history['acc'], color = 'black')\n\nplt.plot(history_2.history['val_acc'], color = 'blue')\n\nplt.title('Training and validation accuracy of model 2')\n\nplt.xlabel('Epochs')\n\nplt.ylabel('Accuracy')\n\nplt.show()\n\nplt.plot(history_2.history['loss'], color = 'black')\n\nplt.plot(history_2.history['val_loss'], color = 'blue')\n\nplt.title('Training and validation loss of model 2')\n\nplt.xlabel('Epochs')\n\nplt.ylabel('Accuracy')\n\nplt.show()","d48ac3cd":"history_3 = model_3.fit(\n            train_generator_m2,\n    \n            epochs = 30,\n    \n            steps_per_epoch = 100,\n            \n            validation_data = validation_generator_m2,\n    \n            validation_steps = 50,\n            \n            callbacks = callbacks\n            )","f722011e":"print(np.mean(history_3.history['acc']))","e72a650a":"print(np.mean(history_3.history['val_acc']))","8805e9d9":"model_3.save('model_3.h5')","f778ceb2":"plt.plot(history_3.history['acc'], color = 'black')\n\nplt.plot(history_3.history['val_acc'], color = 'blue')\n\nplt.title('Training and validation accuracy of model 3')\n\nplt.xlabel('Epochs')\n\nplt.ylabel('Accuracy')\n\nplt.show()\n\nplt.plot(history_3.history['loss'], color = 'black')\n\nplt.plot(history_3.history['val_loss'], color = 'blue')\n\nplt.title('Training and validation loss of model 3')\n\nplt.xlabel('Epochs')\n\nplt.ylabel('Accuracy')\n\nplt.show()","33d157d9":"from tensorflow.keras.models import load_model","64865ef1":"model = load_model('model_3.h5')","1f45d70e":"test_filenames = os.listdir('.\/test1')\n\ntest_df = pd.DataFrame(\n         {\n             'id' : test_filenames\n         } \n         )","618ef19b":"test_df.head()","b4f5803a":"test_gen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_generator = test_gen.flow_from_dataframe(    \n                    test_df,\n    \n                    \".\/test1\", \n                    \n                    x_col='id',\n    \n                    y_col=None,\n                    \n                    target_size = (150, 150), # resize image to 150x150\n                    \n                    batch_size = 20,\n    \n                    class_mode = None,\n    \n                    shuffle=False,\n    \n                    validate_filenames=False\n                  )","1b4aaf51":"predictions = model.predict(test_generator)","9888df6f":"pred = [1 if p > 0.5 else 0 for p in predictions]\n\ntest_df['category'] = pred","032f46f9":"test_df['category'].value_counts().plot.bar()","0990e408":"label_map = dict((v,k) for k,v in train_generator_m2.class_indices.items())\n\ntest_df['category'] = test_df['category'].replace(label_map)","e2fd6d49":"test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })","93b0c009":"test_df['category'].value_counts().plot.bar()","b9d7f8b5":"submission_df = test_df.copy()\n\nsubmission_df['id'] = submission_df['id'].str.split('.').str[0]\n\nsubmission_df['label'] = submission_df['category']\n\nsubmission_df.drop(['id', 'category'], axis=1, inplace=True)\n\nsubmission_df.to_csv('submission.csv', index=False)","601b0843":"MODEL 3","8b993834":"Using the same ImageGenerators of model 2","4ea29ec7":"MODEL 1","b699b845":"**Model 2 (Using Data augementation)**","6f625dae":"**MODEL 3**","0af63289":"MODEL 2","bad50152":"# **7. PREDICTING ON TESTING DATA** \ud83d\udcc8\ud83e\udd1e","4653c998":"# **2. PREPARING TRAINING DATA** \ud83d\udcc1","a00ab1f8":"We are done with the first step of creating a dataset. Now we have to split this dataset into training and validation dataset.","d26e94ef":"That's correct training data contains 20000 images with 2 classes and also validation data contains 5000 images with 2 classes.\n\nNow lets look at the output of these generators :","f13bb64d":"Saving the model","0151c7b7":"Adding a densely connected classifier on top of convolution base","fa4831e4":"# **3. SPLITTING DATASET INTO TRAINING AND VALIDATION SET** ","f4db09d8":"**But why pretrained model? \ud83e\udd37\u200d\u2642\ufe0f**\n\nBecause probability of learned features across different problems is a key advantage of deep learning compared to many olders, shallow-learning approaches and it makes deep learning very effective for small-data problems.","cab03c0e":"There are 20 samples in each batch.","5b0857c5":"# **6. PREPARE TESTING DATASET AND VISULAIZE IT** \ud83d\udcf7","f967b652":"<div class=\"alert alert-block alert-info\">\n\ud83d\udcccGenerators in Python -: \nA Python generator is an object that acts as an iterator. Generators are built using the yield operator.\n<\/div>","54c49ddb":"**See sample image** \ud83d\udc15","d30e3dd7":"`The final feature map has a shape (4, 4, 512). That's the feature on top of which we will stick densely connected classifier.","806529c5":"\ud83d\udccc In this approach we try to generate more training samples from existing training data, by augementing the samples through a number of random transformation that yields believable looking images. The goal of this approach is that our model should not see the exact same image at training time which as a result helps our model to more aspects of data and generalize better.\n\nBut how can we do that? \ud83e\uddd0\n\nThis can be done by configuring some random changes on images using **ImageDataGenerator**.","cd46b2d9":"**Visualizing Loss and accuracy during training \ud83d\udcca**","53efa839":"This dataset contains 25,000 images of dogs and cats (12,500 from each class).","0a462284":"First Model- Our first model will be the convnet which is stack of alternated conv2D(with relu activation) and MaxPooling2D layers.","8eb87ce1":"Compiling Model 1\n\nSince it is a two class classification problem, therefore using binary_crossentropy as loss and using RMSprop as optimizer because we ended the network with a single sigmoidal unit.","4d5ea32c":"# **5. FIT THE MODEL ONTO THE TRAINING DATA** \ud83d\udcc8","215600c8":"First thing first we need to create a dataset. Since the input is in file format.","69694713":"<h1><center><u>Dogs\ud83d\udc36 Vs Cats\ud83d\udc31<\/u><\/center><\/h1>\n\n<center>\n<img src =\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3362\/media\/woof_meow.jpg\">\n<\/center>\n    \n<u>Problem Statement :<\/u> \n    \n    Create an algorithm to classify whether images contain either dog or a cat.\n    \n<u>More Insights About PS : <\/u> \n    \n    Web services are often protected with a challenge that's supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). HIPs are used for many purposes, such as to reduce email and blog spam and prevent brute-force attacks on web site passwords.\n    \n<u>Application Area :<\/u>\n    \n    CAPTCHA Application \n\n\n*I am new in Computer Vision field any feedback is much appreciated !","b712b754":"If we use the below generator then we cant not completely get rid of overfitting","5b26086e":"To prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased","178631ce":"Callbacks","4fa756a3":"Freezing conv_base","e1b62483":"**Model 1**","d5c3dddb":"**VISUALIZING TRAINING DATASET** \ud83d\udcca","2b4f82b8":"**Can we get more accuracy? \ud83d\udcad**\n\nLet's try to build one more predictive model using a pretrained model.","f35f4efc":"# **1. IMPORTING NECESSARY LIBRARIES** \ud83d\udcda \u2b07","655057e9":"- Conv Layer -> The matrix representation of the input image is multiplied element-wise with the kernel(filter) to produce a                  feature map, also known as a convolved feature or an activation map.The aim of this step is to reduce the size                  of the image and make processing faster and easier.\n               \n               Output of this layer must be equal to:- shape = math.floor(((n+2p-f)\/s)+1, ((n+2p-f)\/s)+1)\n\n\n- Pooling Layer -> Pooling enables the CNN to detect features in various images irrespective of the difference in lighting in                      the pictures and different angles of the images.\n                   \n               Output of maxpooling layer :- shape = math.floor(((n-f)\/s)+1, ((n-f)\/s)+1)\n             \n             \n- Flattening -> Flattening involves transforming the entire pooled feature map matrix into a single column which is then fed to                 the neural network for processing.","accb3c3e":"Flow of this Notebook :\n\n    1. Import necessay libraries \n    \n    2. Prepare training dataset & Visualize it.\n    \n    3. Split dataset into training and validation set\n    \n    4. Build a predictive model\n    \n    5. Fit the predictive model onto the training data\n    \n    6. Prepare testing dataset & Visualize it.\n    \n    7. Predict on testing data\n    \n    8. Submission ","258f2f03":"Fine Tuning : Freezing layers of conv_base upto specific one\n\n<div class=\"alert alert-block alert-info\">\n\ud83d\udccc Fine-tuning consists of unfreezing a few of the top layers of frozen model base used for feature extraction and jointly training both the newly added part of the model(in this case, the FCC) and these top layers. This is called fine-tuning because it slightly adjusts the more abstract representations of the model being reused, in order to make them more relevant for the problem.\n<\/div>","2091f90f":"# **8. SUBMISSION** \u270c\ud83d\ude4c\ud83c\udf89","7d363437":"# **4. BUILD A PREDICTIVE MODEL** \ud83c\udfd7","81364cfb":"\ud83d\udccc Currently data is in in jpeg format, so in order to feed those images to Neural Network we need to do the following steps\n\nStep 1 - Read the image file\n\nStep 2 - Decode those JPEG content to RGB grids of pixels\n\nStep 3 - Convert these into floating-point tensors\n\nStep 4 - Rescale the pixel values from range [0-255] to [0-1] as NN prefers to deal with smaller input values."}}