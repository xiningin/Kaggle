{"cell_type":{"c3ba5fdb":"code","f717f683":"code","7289e222":"code","711084f2":"code","235e00f0":"code","4cce477a":"code","ece40d16":"code","60b33327":"code","cf664bb0":"code","fa0ea1ae":"code","28837de6":"code","550cc25f":"code","1d072583":"code","9bb959e2":"code","8da28f75":"code","4ef6b616":"code","ab70b7bd":"code","dd957ff1":"code","4beab33d":"code","c856b4e7":"code","b5df5a41":"code","f1cc6af6":"code","55587ed4":"code","b0c29a04":"code","e40d877a":"code","0b0e1cfc":"code","a7193ec2":"code","6b22f6c7":"code","d16fdf14":"code","51c4f12a":"code","dac1d5e8":"code","c1e6dbee":"code","c9bd93dd":"code","342a06da":"code","81b40c79":"code","c360ee1e":"code","f3a9b6a3":"code","4f102ae3":"code","f14bccbc":"code","0ec19817":"code","e0941984":"code","ef269e23":"code","79791dbe":"code","28c6fb14":"code","27c41241":"code","f8a787ac":"code","ffa95260":"code","2d7c94d3":"code","3cdc009b":"code","4af4292a":"code","6cef7494":"code","9cb08051":"code","52fb8262":"code","32a12b91":"code","cc22e53d":"code","be09da69":"code","982421f2":"code","151d1292":"code","d229cf53":"code","462a3e82":"code","47492665":"code","82b3ce06":"code","57678d61":"code","9da5ed35":"code","5a364e25":"code","f7fc1e58":"code","4f2a9554":"code","aafe669a":"code","8969b3f7":"code","7ce79b23":"code","4d6fb350":"code","975fe97c":"code","469c56a3":"code","31c3af54":"code","b092ae3b":"code","fc58c94a":"code","f76c4a04":"code","953e6c3c":"code","72ae03b8":"code","25a37b11":"code","29da10b5":"code","b96fed18":"code","594863f6":"code","d320865e":"code","7e01586e":"code","1d8287b5":"code","d288d4e6":"code","34bbf0da":"code","c9fcead1":"code","167d8e79":"code","e1495f76":"code","8306504a":"code","1e5aa4c7":"code","41ef99d4":"code","1fad2782":"code","7a4a9494":"code","2d40f6a8":"code","566c063c":"code","273e0a6a":"code","0db5f6b8":"code","65f7e30d":"code","5b6564fe":"code","92b55ffc":"code","0157e13e":"code","487c06d9":"code","c80333f8":"code","da83a7c3":"code","c8ddfdc2":"code","11fdce0e":"markdown","64fb7e24":"markdown","3aedaf93":"markdown","a9dfe146":"markdown","d541a641":"markdown","b4127f1f":"markdown","67794135":"markdown","c4bcf1aa":"markdown","abc1e0d1":"markdown","1f1f89a7":"markdown","46c419a5":"markdown","ed51f94e":"markdown","63fe67a4":"markdown","8d2a28e5":"markdown","3467f671":"markdown","c723c466":"markdown","64ca5952":"markdown","b23bd37c":"markdown","b70ee37c":"markdown","ca615ca0":"markdown","a67a6e0f":"markdown","42bf2f09":"markdown","6f27d7af":"markdown","5e88b7d3":"markdown","0231289c":"markdown","1a7de794":"markdown","8e62f203":"markdown","e9c9d1fe":"markdown","07cbce29":"markdown","98c0d280":"markdown","d438cad2":"markdown","654c6f7c":"markdown","5dfeadb4":"markdown","40ed137b":"markdown","cb899854":"markdown","b05e910b":"markdown","e96f39bc":"markdown","46fabc6c":"markdown","43a13ad1":"markdown","9576bed5":"markdown","d287d052":"markdown","f7c98e46":"markdown","d72f4ddb":"markdown","d998a668":"markdown","0c432bdc":"markdown","3cf05eb7":"markdown","7890d321":"markdown","76e21984":"markdown","17722ff8":"markdown","7818c052":"markdown","126fc442":"markdown","cc915915":"markdown","038637f2":"markdown","77b72c13":"markdown","e6d1e4c0":"markdown","ff75c84d":"markdown","a06db6d9":"markdown","40a601b8":"markdown","c6129e6f":"markdown","8669a391":"markdown","d26875d7":"markdown","16ef9900":"markdown","306595c0":"markdown","f994c34e":"markdown","75d80161":"markdown"},"source":{"c3ba5fdb":"def get_null(train):\n  columns = train.columns\n  values = []\n  features = []\n\n  for column in columns:\n    size = train[train[column].isnull()].shape[0]\n    if(size != 0):\n      features.append(column)\n      values.append(size)\n\n  return pd.DataFrame({\n                       'features': features,\n                       'values': values\n  })","f717f683":"def range_quantile(column):\n  q1 = train[column].quantile(0.25)\n  q2 = train[column].quantile(0.5)\n  q3 = train[column].quantile(0.75)\n  print(train[train[column] == q1]['isChurned'].value_counts())\n  print(train[(train[column] > q1) & (train[column] <= q2)]['isChurned'].value_counts())\n  print(train[(train[column] > q2) & (train[column] <= q3)]['isChurned'].value_counts())\n  print(train[train[column] > q3]['isChurned'].value_counts())\n  return q1, q2, q3","7289e222":"def corr_top(data, target, top):\n  ret = pd.DataFrame({\n      'features': data.corr()[target].sort_values(ascending=False)[1:top+1].index,\n      'corr': data.corr()[target].sort_values(ascending=False)[1:top+1].values\n  })\n  return ret","711084f2":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","235e00f0":"train = pd.read_csv('..\/input\/seleksidukungaib\/train.csv')\ntest = pd.read_csv('..\/input\/seleksidukungaib\/test.csv')\nprint(train.shape)\nprint(test.shape)","4cce477a":"train.head()","ece40d16":"test.head()","60b33327":"train.dtypes","cf664bb0":"train['isChurned'].value_counts()","fa0ea1ae":"train.describe()","28837de6":"test.describe()","550cc25f":"get_null(train)","1d072583":"get_null(test)","9bb959e2":"train.drop(columns=['idx'], inplace=True)\ntest.drop(columns=['idx'], inplace=True)","8da28f75":"print(train[train['userId'].duplicated()]['userId'].unique().shape[0])\nprint(test[test['userId'].duplicated()]['userId'].unique().shape[0])","4ef6b616":"ddc = train[['date_collected', 'date']]","ab70b7bd":"print(ddc.shape[0])\nprint(ddc[ddc.duplicated()].shape[0])","dd957ff1":"train.drop(columns=['date'], inplace=True)\ntest.drop(columns=['date'], inplace=True)","4beab33d":"train['userId'].value_counts()","c856b4e7":"duplicate = train[(train.duplicated(subset=['userId', 'date_collected'], keep=False))]\nnull_row = duplicate[(duplicate['max_recharge_trx'].isnull()) | (duplicate['average_topup_trx'].isnull()) | (duplicate['total_transaction'].isnull())]\ncount = 0\nfor i, el in null_row.iterrows():\n  temp_df = duplicate[(duplicate['userId'] == el['userId']) & (duplicate['date_collected'] == el['date_collected'])]\n  idx_recharge, idx_topup, idx_transaction = -1, -1, -1\n  for j, row in temp_df.iterrows():\n    if(~np.isnan(row['max_recharge_trx'])):\n      idx_recharge = j\n    if(~np.isnan(row['average_topup_trx'])):\n      idx_topup = j\n    if(~np.isnan(row['total_transaction'])):\n      idx_transaction = j\n\n  if(idx_recharge != -1):\n    train.at[i, 'max_recharge_trx'] = train.at[idx_recharge, 'max_recharge_trx']\n  if(idx_topup != -1):\n    train.at[i, 'average_topup_trx'] = train.at[idx_topup, 'average_topup_trx']\n  if(idx_transaction != -1):\n    train.at[i, 'total_transaction'] = train.at[idx_transaction, 'total_transaction']\n  count += 1\n  if(count % 1000 == 0): \n    print(count)","b5df5a41":"get_null(train)","f1cc6af6":"def update_max_recharge_trx(row):\n  if(np.isnan(row['max_recharge_trx'])):\n    row['max_recharge_trx'] = row['average_recharge_trx'] * 2 - row['min_recharge_trx'] \n  return row\n  \ntrain = train.apply(update_max_recharge_trx, axis=1)","55587ed4":"def update_average_topup_trx(row):\n  if(np.isnan(row['average_topup_trx'])):\n    if(row['num_topup_trx'] < 2):\n      row['average_topup_trx'] = row['min_topup_trx']\n    else:\n      row['average_topup_trx'] = (row['min_topup_trx'] + row['max_topup_trx'])\/2\n  return row\n\ntrain = train.apply(update_average_topup_trx, axis=1)","b0c29a04":"def update_num_transfer(x):\n  return x['num_transaction'] - x['num_topup_trx'] - x['num_recharge_trx']","e40d877a":"train['num_transfer_trx'] = train.apply(update_num_transfer, axis=1)\ntest['num_transfer_trx'] = test.apply(update_num_transfer, axis=1)","0b0e1cfc":"def update_average_trx(x):\n  if(x['num_transfer_trx'] == 0):\n    return 0\n  if(np.isnan(x['total_transaction'])):\n    return np.nan\n  topup = x['average_topup_trx'] * x['num_topup_trx']\n  recharge = x['average_recharge_trx'] * x['num_recharge_trx']\n  total = x['total_transaction']\n  return (total-topup-recharge)\/x['num_transfer_trx']","a7193ec2":"train['average_transfer_trx'] = train.apply(update_average_trx, axis=1)\ntest['average_transfer_trx'] = test.apply(update_average_trx, axis=1)","6b22f6c7":"train.head()","d16fdf14":"# Rumus dari total transaction adalah\n# average_topup * num_topup + average_recharge * num_recharge\n\ndef fill_total_transaction(x):\n  if(np.isnan(x['total_transaction'])):\n    if(np.isnan(x['average_transfer_trx'])):\n      return x\n    x['total_transaction'] = (\n        (x['average_topup_trx'] * x['num_topup_trx']) + \n        (x['average_recharge_trx'] * x['num_recharge_trx']) +\n        (x['average_transfer_trx'] * x['num_transfer_trx'])\n    ) \n  return x\n\ntrain = train.apply(fill_total_transaction, axis=1)","51c4f12a":"train[train['isActive'].isnull()]","dac1d5e8":"train.drop(train[train['isActive'].isnull()].index, inplace=True)","c1e6dbee":"test['premium'].value_counts()","c9bd93dd":"test['premium'] = test['premium'].fillna(False)","342a06da":"train['isUpgradedUser'].unique()","81b40c79":"train.drop(columns='isUpgradedUser', inplace=True)\ntest.drop(columns='isUpgradedUser', inplace=True)","c360ee1e":"train.drop(columns=['random_number'], inplace=True)\ntest.drop(columns=['random_number'], inplace=True)","f3a9b6a3":"# train.to_csv('cleaned_train.csv', index=False)\n# test.to_csv('cleaned_test.csv', index=False)","4f102ae3":"# train = pd.read_csv('cleaned_train.csv')\n# test = pd.read_csv('cleaned_test.csv')","f14bccbc":"print(train[train.duplicated()].shape[0])\nprint(train[train['total_transaction'].isnull()].shape[0])\nprint(train[train['average_transfer_trx'] < 0].shape[0])","0ec19817":"train.drop(train[train['average_transfer_trx'] < 0].index, inplace=True)","e0941984":"train.drop(train[train.duplicated()].index, inplace=True)","ef269e23":"train.drop(train[train['total_transaction'].isnull()].index, inplace=True)","79791dbe":"numerical_features = ['num_recharge_trx', 'num_topup_trx', 'num_transfer_trx', 'num_transaction']\nfix, ax = plt.subplots(2, 2, figsize=(15,6))\ntrain[train['isChurned'] == 0][numerical_features].hist(bins=20, color='blue', alpha=0.5, ax=ax)\ntrain[train['isChurned'] == 1][numerical_features].hist(bins=20, color='orange', alpha=0.5, ax=ax)\nplt.show()","28c6fb14":"fig, ax = plt.subplots(4, 2, figsize=(12, 12))\nbool_cols = ['isActive', 'isVerifiedPhone', 'isVerifiedEmail', 'blocked', 'premium', 'super', 'userLevel', 'pinEnabled']\n\ni, j = 0, 0\nsns.set(style='darkgrid')\nfor col in bool_cols:\n  sns.countplot(data=train, x=col, hue='isChurned', ax=ax[i][j])\n  j += 1\n  if(j == 2):\n    j = 0\n    i += 1\n\nplt.tight_layout()\nplt.show()","27c41241":"print(train[train['num_transfer_trx'] != 0]['isChurned'].value_counts())\nprint(train[train['num_transfer_trx'] == 0]['isChurned'].value_counts())","f8a787ac":"def update_transaction(x):\n  if(x['num_transaction'] != 0):\n    x['num_transaction'] -= x['num_transfer_trx']\n    x['total_transaction'] -= (x['average_transfer_trx'] * x['num_transfer_trx'])\n  if(x['total_transaction'] > -1e-8 and x['total_transaction'] < 1e-8):\n    x['total_transaction'] = 0\n  return x\n\ntrain = train.apply(update_transaction, axis=1)\ntest = test.apply(update_transaction, axis=1)","ffa95260":"train.drop(columns=['num_transfer_trx', 'average_transfer_trx', 'min_transfer_trx', 'max_transfer_trx'], inplace=True)\ntest.drop(columns=['num_transfer_trx', 'average_transfer_trx', 'min_transfer_trx', 'max_transfer_trx'], inplace=True)","2d7c94d3":"train['average_recharge_trx'] \/= 15000\ntrain['min_recharge_trx'] \/= 15000\ntrain['max_recharge_trx'] \/= 15000\ntrain['average_topup_trx'] \/= 15000\ntrain['min_topup_trx'] \/= 15000\ntrain['max_topup_trx'] \/= 15000\ntrain['total_transaction'] \/= 15000","3cdc009b":"test['average_recharge_trx'] \/= 15000\ntest['min_recharge_trx'] \/= 15000\ntest['max_recharge_trx'] \/= 15000\ntest['average_topup_trx'] \/= 15000\ntest['min_topup_trx'] \/= 15000\ntest['max_topup_trx'] \/= 15000\ntest['total_transaction'] \/= 15000","4af4292a":"train['total_recharge'] = train['average_recharge_trx'] * train['num_recharge_trx']\ntrain['total_topup'] = train['average_topup_trx'] * train['num_topup_trx']\ntest['total_recharge'] = test['average_recharge_trx'] * test['num_recharge_trx']\ntest['total_topup'] = test['average_topup_trx'] * test['num_topup_trx']","6cef7494":"train.columns","9cb08051":"cols = ['userId', \n        'date_collected', \n        'num_recharge_trx', \n        'average_recharge_trx',\n        'max_recharge_trx',\n        'min_recharge_trx',\n        'num_topup_trx',\n        'average_topup_trx',\n        'max_topup_trx',\n        'min_topup_trx',\n        'total_recharge',\n        'total_topup',\n        'num_transaction',\n        'total_transaction',\n        'isActive',\n        'isVerifiedPhone',\n        'isVerifiedEmail',\n        'blocked',\n        'premium',\n        'super',\n        'userLevel',\n        'pinEnabled',\n        'isChurned']\n\ntrain = train[cols]\ntest = test[cols[:-1]]","52fb8262":"from sklearn.preprocessing import LabelEncoder\nencode = ['premium', 'super', 'pinEnabled']\nlbl = LabelEncoder()\nfor col in encode:\n  train[col] = lbl.fit_transform(train[col].values)\n  test[col] = lbl.transform(test[col].values)","32a12b91":"matrix = np.triu(train.corr())\nplt.figure(figsize=(16,12))\nplt.title('Correlation')\nsns.heatmap(train.corr(), linewidth=.5, annot=True, cmap='BrBG', mask=matrix)\nplt.show()","cc22e53d":"train.drop(columns=[\n                    'userId',\n                    'date_collected',\n], inplace=True)\n\ntest.drop(columns=[\n                    'userId',\n                    'date_collected',\n], inplace=True)  ","be09da69":"no_dup_train = train.drop(train[train.duplicated()].index).copy()\ndup_index = no_dup_train[no_dup_train.drop(columns='isChurned').duplicated()].index","982421f2":"len(dup_index)","151d1292":"def get_same_row(index, data=train):\n  row = data.loc[index]\n  return train[(train['num_recharge_trx'] == row['num_recharge_trx']) &\n        (train['average_recharge_trx'] == row['average_recharge_trx']) &\n        (train['max_recharge_trx'] == row['max_recharge_trx']) &\n        (train['min_recharge_trx'] == row['min_recharge_trx']) &\n        (train['total_recharge'] == row['total_recharge']) &\n        (train['num_topup_trx'] == row['num_topup_trx']) &\n        (train['average_topup_trx'] == row['average_topup_trx']) &\n        (train['max_topup_trx'] == row['max_topup_trx']) &\n        (train['min_topup_trx'] == row['min_topup_trx']) &\n        (train['total_topup'] == row['total_topup']) &\n        (train['num_transaction'] == row['num_transaction']) &\n        (train['total_transaction'] == row['total_transaction']) &\n        (train['isActive'] == row['isActive']) &\n        (train['isVerifiedPhone'] == row['isVerifiedPhone']) &\n        (train['isVerifiedEmail'] == row['isVerifiedEmail']) &\n        (train['blocked'] == row['blocked']) &\n        (train['premium'] == row['premium']) &\n        (train['super'] == row['super']) &\n        (train['userLevel'] == row['userLevel']) &\n        (train['pinEnabled'] == row['pinEnabled'])]","d229cf53":"def update_row(threshold=0.3, dup_index=dup_index):\n  for a, i in enumerate(dup_index):\n    dup_row = get_same_row(i)\n    index = dup_row.index\n    zero, one = dup_row['isChurned'].value_counts()[0], dup_row['isChurned'].value_counts()[1]\n\n    if(min(zero, one) \/ (zero+one) <= threshold):\n      mode = dup_row.mode()['isChurned'][0]\n      for idx in index:\n        train.at[idx, 'isChurned'] = mode\n\n    if(a % 100 == 0):\n      print(a)","462a3e82":"train['isChurned'].value_counts()","47492665":"update_row()","82b3ce06":"train['isChurned'].value_counts()","57678d61":"print(train.shape)\nprint(test.shape)","9da5ed35":"df_x = train.drop(['isChurned'], axis=1)\ndf_y = train['isChurned']\nx = df_x\ny = df_y","5a364e25":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx = scaler.fit_transform(x)\nnew_test = scaler.transform(test)","f7fc1e58":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)","4f2a9554":"from sklearn.metrics import confusion_matrix, f1_score","aafe669a":"def train_model(models, x=x_train, y=y_train):\n  for key, model in models.items():\n    print(f'Currently Training {key}')\n    model.fit(x, y)","8969b3f7":"def preds(models, x_test=x_test, y_test=y_test, new_test=new_test):\n  preds = {\n      'models': [],\n      'val_f1_score': [],\n      'train_f1_score': [],\n      'confusion_matrix': [],\n      'prediction': []\n  }\n  for key, model in models.items():\n    preds['models'].append(key)\n    test_pred = model.predict(x_test)\n    train_pred = model.predict(x_train)\n    preds['val_f1_score'].append(f1_score(test_pred, y_test))\n    preds['train_f1_score'].append(f1_score(train_pred, y_train))\n    preds['confusion_matrix'].append(confusion_matrix(test_pred, y_test))    \n    preds['prediction'].append(model.predict(new_test))\n  \n  return pd.DataFrame(preds)","7ce79b23":"evaluation = []","4d6fb350":"from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier","975fe97c":"linear_models = {\n    'LogisticRegression': LogisticRegression(),\n    'Perceptron': Perceptron(),\n    'RidgeClassifier': RidgeClassifier(),\n    'SGDClassifier': SGDClassifier()\n}","469c56a3":"train_model(linear_models)","31c3af54":"evaluation.append(preds(linear_models))","b092ae3b":"from sklearn.naive_bayes import GaussianNB","fc58c94a":"naive_bayes = {\n    'GaussianNB': GaussianNB()\n}","f76c4a04":"train_model(naive_bayes)","953e6c3c":"evaluation.append(preds(naive_bayes))","72ae03b8":"from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier","25a37b11":"tree_model = {\n    'DecisionTree': DecisionTreeClassifier(),\n    'ExtraTree': ExtraTreeClassifier()\n}","29da10b5":"train_model(tree_model)","b96fed18":"evaluation.append(preds(tree_model))","594863f6":"!pip install catboost\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","d320865e":"boosting_model = {\n    'CatBoost': CatBoostClassifier(eval_metric='F1', logging_level='Silent'),\n    'XGBoost': XGBClassifier(),\n    'LGBM': LGBMClassifier(),\n    'AdaBoost': AdaBoostClassifier()\n}","7e01586e":"train_model(boosting_model)","1d8287b5":"evaluation.append(preds(boosting_model))","d288d4e6":"from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier","34bbf0da":"ensemble_model = {\n    'RandomForest': RandomForestClassifier(),\n    'ExtraTrees': ExtraTreesClassifier()\n}","c9fcead1":"train_model(ensemble_model)","167d8e79":"evaluation.append(preds(ensemble_model))","e1495f76":"eval = pd.concat(evaluation).sort_values('val_f1_score',ascending=False).reset_index(drop=True)\neval","8306504a":"for i in range(eval.shape[0]):\n  unique, counts = np.unique(eval.loc[i]['prediction'], return_counts=True)\n  print(eval.loc[i]['models'])\n  for el_unique, el_counts in zip(unique, counts):\n    print(f'{el_unique} {el_counts}')\n  print()","1e5aa4c7":"from sklearn.model_selection import GridSearchCV","41ef99d4":"params = {\n    'C': np.logspace(-2,2,20),\n    'solver': ['liblinear', 'lbfgs'],\n    'penalty': ['l2']\n}","1fad2782":"tuning_model = GridSearchCV(estimator = linear_models['LogisticRegression'],\n                            param_grid = params,\n                            verbose=True,\n                            scoring = 'f1',\n                            n_jobs=5)","7a4a9494":"tuning_model.fit(x, y)\npredict = pd.DataFrame(tuning_model.best_estimator_.predict(new_test))\npredict[0].value_counts()","2d40f6a8":"print(tuning_model.best_estimator_)\nprint(tuning_model.best_params_)","566c063c":"# first = pd.read_csv('1st_sub.csv')\n# second = pd.read_csv('2nd_sub.csv')","273e0a6a":"y_pred = predict[0]","0db5f6b8":"# comparison = pd.DataFrame({\n#     '1st_sub': first['isChurned'],\n#     '2nd_sub': second['isChurned'],\n#     'prediction': y_pred.astype(int)\n# })","65f7e30d":"def compare(col):\n  count_diff = 0\n  for i, row in comparison.iterrows():\n    if(row['prediction'] != row[col]):\n      count_diff += 1\n  return count_diff","5b6564fe":"# compare('1st_sub')","92b55ffc":"# compare('2nd_sub')","0157e13e":"idx = pd.read_csv('..\/input\/seleksidukungaib\/test.csv')['idx']","487c06d9":"submission = pd.DataFrame({\n    'idx': idx,\n    'isChurned': y_pred.astype(int)\n})","c80333f8":"submission['isChurned'].value_counts()","da83a7c3":"submission.to_csv('submission.csv', index=False)","c8ddfdc2":"!kaggle competitions submit -c seleksidukungaib -f submission.csv -m \"No Comment\"","11fdce0e":"# Checkpoint","64fb7e24":"## Combine Column","3aedaf93":"### Transaction","a9dfe146":"## Null Data","d541a641":"Dengan asumsi bahwa terdapat row duplicate, tetapi salah satu value dari kolomnya merupakan null values, akan dilakukan pengecekan terhadap beberapa userId","b4127f1f":"## Linear Model","67794135":"# Model","c4bcf1aa":"# Fitting the data","abc1e0d1":"# Visualization","1f1f89a7":"Setelah tidak terbukti asumsi tentang kolom transfernya, maka akan didrop kolom transfernya. Hal ini juga disebabkan karena kolom transfer didominasi oleh angka 0","46c419a5":"## Parameter Tuning","ed51f94e":"Dikarenakan data yang dipakai terhitung kecil, maka parameter tuning akan menggunakan GridSearchCV. Hal ini bertujuan untuk mencari parameter yang paling tepat untuk data yang diberikan. Dengan menggunakan GridSearchCV, akan dilakukan cross validasi sebanyak 5x dan mencoba semua kemungkinan dari parameter yang digunakan.","63fe67a4":"## Naive Bayes","8d2a28e5":"Didapatkan bahwa kolom average_transfer_trx terdapat value yang negatif, hal itu merupakan salah satu efek dari menggunakan asumsi distribusi normal saat mengisi kolom ```average_transfer_trx``` dan ```max_recharge_trx```. Maka dari itu, akan dilakukan tindak lanjut yaitu drop row yang memiliki nilai negatif","3467f671":"Terbukti kolom date dan date_collected duplicate, maka dari itu drop salah satu kolomnya","c723c466":"Untuk mempermudah model belajar, maka akan ditambah feature yaitu total_recharge dan total_topup yang rumusnya\n<br>\n```total = num * average```","64ca5952":"Ditemukan 403 unique row yang isChurnednya berbeda. Tindak lanjutnya adalah dengan merubah isChurnednya menjadi seragam dengan modus dari data row tersebut. Akan tetapi, ditemukan juga data yang perbandingannya hampir 1:1, padahal datanya sama persis. Maka dari itu, akan diberikan threshold sebesar 0.3. Jika di atas threshold, maka datanya tidak akan dirubah. Hal ini untuk mengurangi densitas dari persebaran jawaban 0 dan 1.","b23bd37c":"### max_recharge_trx","b70ee37c":"Dillihat terdapat userId yang memiliki 6 data, jika dilihat lebih lanjut, data tersebut adalah duplicate di bulan yang sama, maka dari itu dapat disimpulkan bahwa asumsi terdapat row duplicate yang beberapa kolomnya merupakan null values dapat diterima.\n\nSetelah ditemukan bahwa terdapat row yang duplicate, tetapi terdapat null pada kolom tertentu. Maka dari itu, akan diisi kolom row yang memiliki null value dengan value yang sebenarnya","ca615ca0":"### Boolean Column","a67a6e0f":"Dengan menggunakan asumsi bahwa jumlah setiap recharge adalah distribusi normal, maka digunakan rumus untuk mengisi max_recharge_trx\n```max_recharge_trx = 2 * average_recharge_trx - min_recharge_trx```","42bf2f09":"## idx","6f27d7af":"Di sini akan dibuktikan, asumsi bahwa user yang lebih sering melakukan transfer akan lebih cenderung tidak melakukan churn ","5e88b7d3":"# Feature Engineering","0231289c":"## Tree","1a7de794":"Pada tahap ini, feature dari data yang akan difeed ke dalam model sudahlah siap. Akan tetapi, terdapat beberapa anomali pada data yang akan ditrain, yaitu data yang sama, tetapi memiliki isChurned yang berbeda","8e62f203":"Dengan menggunakan asumsi bahwa jumlah setiap topup adalah distribusi normal, maka digunakan rumus untuk mengisi max_recharge_trx\n```average_topup_trx = (min_topup_trx + max_topup_trx) \/ 2```","e9c9d1fe":"## Dealing Null and Odd Values","07cbce29":"## date_collected & date","98c0d280":"Pada kolom test, terdapat null pada kolom premium, maka akan diisi dengan modusnya","d438cad2":"## Ensemble Method","654c6f7c":"# Utility Function","5dfeadb4":"### Transfer","40ed137b":"Ditemukan row yang memiliki null values. Akan tetapi hal ini tidak dapat diisi dengan value yang benar lagi. Maka dari itu, cara yang aman untuk menindaklanjutinya adalah dengan membuat data pada row tersebut","cb899854":"Didapatkan banyak sekali row yang diduplicate, maka dari itu akan didrop","b05e910b":"# Unnecessary Row","e96f39bc":"## Comparing with another submission","46fabc6c":"# Submission","43a13ad1":"## Removing Transfer","9576bed5":"Dilihat bahwa 10 baris tersebut memiliki null semua pada bagian boolean, maka dari itu dapat dilakukan drop rows ","d287d052":"Setelah dilihat, masih terdapat beberapa null values, maka dari itu perlu dilakukan tindak lanjut","f7c98e46":"# Anomaly Data","d72f4ddb":"Pada kolom isUpgradedUser, hanya terdapat 1 value, maka dari itu akan didrop saja","d998a668":"Dengan asumsi bahwa kolom idx adalah primary key dari dataset, maka akan dilakukan tindak lanjut yaitu drop kolom idx","0c432bdc":"# Explore all column","3cf05eb7":"Tidak dapat diambil info apapun pada kolom ini, lebih baik jika didrop saja","7890d321":"## userId","76e21984":"## random_number","17722ff8":"Untuk melihat keterhubungan tiap feature, maka akan dibuat heatmap correlation","7818c052":"### Logistic Regression","126fc442":"# Prediction Analysis","cc915915":"# Library","038637f2":"Dilihat salah satu kolom yang memiliki null values","77b72c13":"## isUpgradedUser","e6d1e4c0":"Dikarenakan mata uang yang dipakai dalam rupiah, akan dinormalisasi dahulu dengan merubahnya menjadi dollar. Hal ini bertujuan untuk mengurangi jarak dari min dan max suatu kolom.","ff75c84d":"### average_topup_trx","a06db6d9":"## Convert Money into Dollar","40a601b8":"Dilakukan pengecekan terhadap kolom date_collected dan date dikarenakan terdapat keganjilan di kedua kolom berikut","c6129e6f":"## Overview Data","8669a391":"Didapatkan kolom transfer terisi 0 semua, maka dari itu berdasarkan penjelasan bahwa kolom transaksi adalah penjumlahan dari kolom topup, recharge, dan transfer, maka kolom transfer dapat dibenahi valuenya\n<br>\n```num_transfer_trx = num_transaction - num_topup_trx - num_recharge_trx```\n<br>\n```average_transfer_trx = total_transaction - (average_topup_trx * num_topup_trx) - (average_recharge_trx * num_recharge_trx)```","d26875d7":"## Boosting","16ef9900":"Dikarenakan masih terdapat null value pada kolom total_transaction, maka null value tersebut akan disi dengan total dari topup, recharge, dan transfer","306595c0":"## Analysis Models","f994c34e":"# Exploratory Data","75d80161":"- MinMaxScaler cuma ngebuat datanya gak berjauhan, dia gak ngerubah distribusi datanya samsek\n- RobustScaler mengurangi efek dari outlier, dipakai waktu outliernya banyak dan efeknya bikin modelnya jadi jelek. (cleaning data di outlier lebih disarankan)\n- StandardScaler ngebuat distribusi menjadi relatif normal (performa model bakalan lebih bagus kalo distribusinya normal)\n\nBerdasarkan definisi yang saya simpulkan dari beberapa sumber, saya akan menggunakan StandardScaler untuk meng-standardize datanya."}}