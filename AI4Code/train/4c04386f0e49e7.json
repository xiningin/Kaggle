{"cell_type":{"ad9409ad":"code","2f2e7558":"code","172bd506":"code","524e7d42":"code","db5c5f8c":"code","8b0d2341":"code","149291b4":"code","82d1ecdb":"code","59588f82":"code","048a758c":"code","ebbc0580":"code","9fd0ee81":"code","9c122eb8":"code","f6eaca41":"code","4ac41a61":"code","6cb4403e":"code","75c4b2ab":"code","5625deee":"code","285388fc":"code","ee7447e8":"code","4968bc8f":"code","50f83bef":"code","ed35be57":"code","a7dbb7c1":"code","2c7997e8":"code","16ddc765":"code","850ca2c8":"code","69770de1":"code","b0c17054":"code","ef020aa5":"code","f5e879f2":"code","d3c64557":"code","691cc9d0":"code","5c643214":"code","79d65131":"code","50bb92f4":"code","f6a616a7":"code","d011527b":"code","21138f6e":"code","b7c5d9d5":"code","1426dbe3":"code","a1259132":"code","5e8c083a":"code","4e02f2b4":"code","2252ece9":"code","628e535b":"code","d0212f66":"code","50e9ec36":"code","e6612a2f":"code","0e3cf2e7":"code","7f9f428a":"code","06b5fc6a":"code","7b27e965":"code","51685ecb":"code","6f13e2d3":"code","469e0dd8":"code","03bf2951":"code","8e393a9e":"code","e9cc4348":"code","6f2db3dd":"code","b871839f":"code","8efbe5d5":"code","e8db1ba1":"code","b58324be":"code","5e425491":"code","abc0d8b4":"code","80051231":"code","10b26914":"code","ab140660":"code","2d45810d":"code","e4a84814":"code","00d3faa3":"code","b8973034":"code","720890af":"code","ddd02133":"code","831a94c8":"code","a51c682f":"code","94067fce":"code","49c4075f":"code","9be8d21d":"code","cd432943":"code","0a8a43ca":"code","7be07450":"code","69e2b245":"code","00d40ebb":"code","c41f2af8":"code","50704cfb":"code","a55582fb":"code","95291fc0":"code","8cfe2990":"code","3949ee7e":"code","8e0bcf85":"code","69daec55":"code","47ec2226":"code","3ae02278":"code","e4483d03":"code","1ae54a1b":"code","b8089565":"code","60273ae1":"code","9ed00db8":"code","3af8cfce":"code","1e55675d":"code","7dc427f3":"code","2570c33f":"code","f9f7168a":"code","bdd323d1":"code","5e909457":"code","75b14229":"code","4b6e6b11":"code","2aa4f1ad":"code","ad88041c":"code","3350be11":"code","0ea0bd6f":"code","aa669829":"code","3fc546f3":"code","639c6c8e":"code","3fbf2433":"code","8c043e03":"code","2e3cefdf":"code","4855f4e2":"code","429a99b1":"code","112018e1":"code","077f7008":"code","fdcd228a":"code","f300fc64":"code","82d244c2":"code","79fa60eb":"code","d6ecf39d":"code","a722b763":"code","414f27fb":"code","4db508d6":"code","40de548d":"code","52241284":"code","755dc682":"code","a5b769e9":"code","86ccfa03":"code","a5f7cade":"code","50f14f13":"code","c76f686e":"code","8fdaab88":"code","fe9733ed":"code","8e1fdb21":"code","8cfa5012":"code","c246cff2":"code","601f41f8":"code","19e7c06c":"code","f5f50608":"code","5c55e091":"code","8552033c":"code","301fcef7":"code","10e52795":"code","6d8e93ec":"code","b5ced732":"code","5ccee6ab":"code","c390bce7":"code","e832e907":"code","d4ecc0d7":"code","56b1c036":"code","8bcfea8e":"code","39217ae6":"code","274caf41":"code","43402238":"code","f0db384f":"code","abcea6b6":"code","d6110e41":"code","98144396":"code","bb5bba6c":"code","07ebef50":"code","7053c049":"code","3a5ee1d1":"markdown","92b4e7a0":"markdown","a8587f99":"markdown","6dc2b536":"markdown","361adb12":"markdown","cb7e448b":"markdown","5b12b2ac":"markdown","6b8ec100":"markdown","3e1cec12":"markdown","a257bc55":"markdown","c8afe1ec":"markdown","0175d66f":"markdown","13cb56ab":"markdown","e3c68492":"markdown","c4d4e173":"markdown","6d876c9c":"markdown","3438b8ea":"markdown","31f3f864":"markdown","a3968237":"markdown","50ec93a8":"markdown","f70c56ee":"markdown","b96e29ad":"markdown","99830ca5":"markdown","ca800c5b":"markdown","b5b5593d":"markdown","f294e1e5":"markdown","cfeb2252":"markdown","2782bd3b":"markdown","220e6879":"markdown","f219bfe1":"markdown","46ed908a":"markdown","e7e91726":"markdown","756526a3":"markdown","72b1712a":"markdown","d4adaee8":"markdown","a8ff368d":"markdown","eefff853":"markdown","c4645745":"markdown","dcf7d89c":"markdown","72be1721":"markdown","7d2f8172":"markdown","f927cf82":"markdown","fb62087c":"markdown","8b3f7be9":"markdown","323fa13b":"markdown","62c456ca":"markdown","b3f2812f":"markdown","e9716998":"markdown","2fac0251":"markdown","3e32324b":"markdown","1bac0c47":"markdown","4fde3db3":"markdown","b1eb5efe":"markdown","aa3c496b":"markdown","9f297e90":"markdown","abfc284e":"markdown","965d916d":"markdown","58c329dd":"markdown","aab26f15":"markdown","c7c73827":"markdown","f7d57782":"markdown","b482ed72":"markdown","35adf2c6":"markdown","b6fa5aed":"markdown","043a11a8":"markdown","551befc1":"markdown"},"source":{"ad9409ad":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.io\nfrom scipy import stats\nimport datetime\nfrom functools import reduce","2f2e7558":"import plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","172bd506":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","524e7d42":"# Performance measurement\nfrom sklearn.metrics import mean_absolute_error #MAE\nfrom sklearn.metrics import mean_squared_error #MSE\nfrom sklearn.metrics import mean_absolute_percentage_error #MAPE","db5c5f8c":"# Feature selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import mutual_info_regression","8b0d2341":"# Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler","149291b4":"import warnings\n\nwarnings.filterwarnings('ignore')","82d1ecdb":"listCompanies = ['MOBZ1','KAHZ1','TAIR1','TLIZ1','ZNDZ1','SAHD1','FIBR1','KRTI1','HPRZ1',\n'KSHJ1','AZIN1','IKCO1','DOSE1','MAPN1','SFKZ1','SSNR1','PNTB1','PNES1',\n'GTSH1','PSHZ1','SHHZ1','MRGN1','FKHZ1','MSMI1','GASZ1','GESF1','SINA1',\n'TBAS1','SGAZ1','MRJZ1','KBCZ1','ASAL1','DADE1','KARZ1','IDOC1','BANK1',\n'IKHR1','RSAP1','LSMD1','FAYF1','DARA1','NORI1']","59588f82":"AvailableData = []\ndf = pd.DataFrame()\nfor a in listCompanies:\n    try:\n        mat = scipy.io.loadmat(f'..\/\/input\/\/securities-and-exchange-iran\/\/{a}_a.mat')\n        AvailableData.append(a)\n        Temp = pd.DataFrame(mat['histtory'])\n        Temp['Compony'] = a\n        df = pd.concat([df, Temp], axis=0)\n    except:\n        continue","048a758c":"def Diff(li1, li2):\n    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n    return li_dif","ebbc0580":"Diff(AvailableData,listCompanies)","9fd0ee81":"cols = {0  : 'SolarHistory',1  : 'GregorianDate' ,2  : 'FirstPriceAd',3  : 'MaxPriceAd',\n4  : 'MinPriceAd',5  : 'LastPriceAd',6  : 'ClosePriceAd',7  : 'TradeValue',8  : 'TradeVolume',\n9  : 'TradeCount',10 : 'ClosePriceYesterday',11 : 'BuyCountTrue',12 : 'BuyCountLegal',13 : 'SaleCountTrue',\n14 : 'SaleCountLegal',15 : 'BuyVolumeTrue',16 : 'BuyVolumeLegal',17 : 'SaleVolumeTrue',18 : 'SaleVolumeLegal',\n19 : 'BuyValueTrue',20 : 'BuyValueLegal',21 : 'SaleValueTrue',22 : 'SaleValueLegal',23 : 'Slope',24 : 'dev',\n32 : 'FirstPriceRe',33 : 'MaxPriceRe',34 : 'MinPriceRe',35 : 'LastPriceRe',36 : 'ClosePriceRe'}","9c122eb8":"df.rename(columns=cols,inplace=True)","f6eaca41":"df","4ac41a61":"df[[25,26,27,28,29,30,31]].value_counts()","6cb4403e":"df.drop([25,26,27,28,29,30,31,'SolarHistory','FirstPriceRe',\n         'MaxPriceRe','MinPriceRe','LastPriceRe','ClosePriceRe'], axis=1,inplace=True)","75c4b2ab":"df = df[~df.isin([-999999.0]).any(axis=1)]","5625deee":"df.shape","285388fc":"def missing_zero_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = round(df.isnull().mean().mul(100),2)\n    mz_table = pd.concat([mis_val,mis_val_percent],axis=1)\n    mz_table = mz_table.rename(columns = {df.index.name:'col_name',0:'Missing Values',1:'% of Total Values'})\n    mz_table['Data_type']=df.dtypes\n    mz_table=mz_table.sort_values('% of Total Values',ascending=False)\n    print(\"Your selected dataframe has ** \"+str(df.shape[1])+\" ** columns and ** \"+str(df.shape[0])+\" ** Rows.\\n\"\n                 \"There are ** \"+str(mz_table[mz_table.iloc[:,1] != 0].shape[0])+\n                  \" ** columns that have missing values. \\n\")\n    return mz_table.reset_index()","ee7447e8":"missing_zero_values_table(df)","4968bc8f":"df['GregorianDate'] = pd.to_datetime(df['GregorianDate'], format='%Y%m%d').copy()","50f83bef":"df['Year'] = pd.DatetimeIndex(df.loc[:, ('GregorianDate')]).year\ndf['Month'] = pd.DatetimeIndex(df.loc[:, ('GregorianDate')]).month","ed35be57":"listYear = df.Year.unique()","a7dbb7c1":"df","2c7997e8":"variables = []\nfor c in df.Compony.unique():\n    locals()[\"df_\" + str(c)] = df[df.Compony==c].sort_values(by='GregorianDate' \n                                                              ,ascending=False).reset_index().copy().drop(['index']\n                                                              ,axis=1)\n    variables.append(\"df_\" + str(c))    ","16ddc765":"# Frame 10 Day\nvariablesTenDay = []\nfor var in variables:\n    locals()[\"Day10\" + str(var)] = globals()[var].rolling(10).mean()\n    globals()[\"Day10\" + str(var)].dropna(inplace=True)\n    variablesTenDay.append(\"Day10\" + str(var))    ","850ca2c8":"for var1,var2 in zip(variables,variablesTenDay):\n    if var1 == var2:\n        print(var1)","69770de1":"print(variables[:5],'\\n',variablesTenDay[:5])","b0c17054":"temp = {}\nfor var in variables:\n    temp[var] = globals()[var].shape[0]\n    \npd.DataFrame([temp]).T.rename(columns={0:'shape'}).style.background_gradient(cmap='Blues')","ef020aa5":"df_ZNDZ1.head() ","f5e879f2":"# ClosePrice - Yesterday Close Price\nfor var in variables:\n    globals()[var]['DailyProfit'] = globals()[var]['ClosePriceAd'] - globals()[var]['ClosePriceYesterday']","d3c64557":"for var in variablesTenDay:\n    globals()[var]['DailyProfit'] = globals()[var]['ClosePriceAd'] - globals()[var]['ClosePriceYesterday']","691cc9d0":"px.line(df_MSMI1,x='GregorianDate', y=\"DailyProfit\",title=\"Daily profit NICICO\",labels={'x':'Date','y':'Daily Profit'})","5c643214":"for var in variables:\n    globals()[var]['BPS'] = (globals()[var]['BuyValueTrue'] \/ globals()[var]['BuyCountTrue']) \/ (globals()[var]['SaleValueTrue'] \/ globals()[var]['SaleCountTrue'])","79d65131":"for var in variablesTenDay:\n    globals()[var]['BPS'] = (globals()[var]['BuyValueTrue'] \/ globals()[var]['BuyCountTrue']) \/ (globals()[var]['SaleValueTrue'] \/ globals()[var]['SaleCountTrue'])","50bb92f4":"px.line(df_MSMI1,x='GregorianDate', y=\"BPS\",title=\"BPS NICICO\",labels={'x':'Date','y':'BPS'})","f6a616a7":"for var in variables:\n    globals()[var]['BpsThreeDays'] = globals()[var]['BPS'].rolling(3).mean()","d011527b":"for var in variablesTenDay:\n    globals()[var]['BpsThreeDays'] = globals()[var]['BPS'].rolling(3).mean()","21138f6e":"#df_ZNDZ1.groupby(df_ZNDZ1.index \/\/ 3)['BPS'].mean()","b7c5d9d5":"px.line(df_MSMI1,x='GregorianDate', y=\"BpsThreeDays\",title=\"BpsThreeDays NICICO\",labels={'x':'Date','y':'BpsThreeDays'})","1426dbe3":"for var in variables:\n    globals()[var] = globals()[var].assign(cdf=lambda data: (1. * np.arange(len(data.ClosePriceAd)) \/ (len(data.ClosePriceAd) - 1)))","a1259132":"for var in variablesTenDay:\n    globals()[var] = globals()[var].assign(cdf=lambda data: (1. * np.arange(len(data.ClosePriceAd)) \/ (len(data.ClosePriceAd) - 1)))","5e8c083a":"# CDF of Normal Distribution\n# scipy.stats.norm.cdf","4e02f2b4":"for var in variables:\n    globals()[var]['CloseSubFirst'] = globals()[var]['ClosePriceAd'] - globals()[var]['FirstPriceAd']","2252ece9":"for var in variablesTenDay:\n    globals()[var]['CloseSubFirst'] = globals()[var]['ClosePriceAd'] - globals()[var]['FirstPriceAd']","628e535b":"for var in variables:\n    globals()[var]['CloseSubLast'] = globals()[var]['ClosePriceAd'] - globals()[var]['LastPriceAd']","d0212f66":"for var in variablesTenDay:\n    globals()[var]['CloseSubLast'] = globals()[var]['ClosePriceAd'] - globals()[var]['LastPriceAd']","50e9ec36":"for var in variables:\n    globals()[var]['MaxSubLast'] = globals()[var]['MaxPriceAd'] - globals()[var]['LastPriceAd']","e6612a2f":"for var in variablesTenDay:\n    globals()[var]['MaxSubLast'] = globals()[var]['MaxPriceAd'] - globals()[var]['LastPriceAd']","0e3cf2e7":"for var in variables:\n    globals()[var]['MaxSubClose'] = globals()[var]['MaxPriceAd'] - globals()[var]['ClosePriceAd']","7f9f428a":"for var in variablesTenDay:\n    globals()[var]['MaxSubClose'] = globals()[var]['MaxPriceAd'] - globals()[var]['ClosePriceAd']","06b5fc6a":"Day10df_MSMI1","7b27e965":"df_MSMI1","51685ecb":"# add one column  \n# subtraction Close Price today and Close Price yesterday\nfor var in variables:\n     globals()[var]['sub'] = np.abs(globals()[var]['ClosePriceAd'] -  globals()[var]['ClosePriceYesterday'])","6f13e2d3":"for var in variablesTenDay:\n     globals()[var]['sub'] = np.abs(globals()[var]['ClosePriceAd'] -  globals()[var]['ClosePriceYesterday'])","469e0dd8":"fig = go.Figure()\nfig.add_trace(go.Box(x=df_MSMI1['sub'],name='MSMI1',boxpoints='all'))\nfig.add_trace(go.Box(x=df_SAHD1['sub'],name='SAHD'))","03bf2951":"variablesIQR = []\nfor var in variables:\n    Q1 = globals()[var]['sub'].quantile(0.25)\n    Q3 = globals()[var]['sub'].quantile(0.75)\n    IQR = Q3 - Q1\n    locals()[str(var)+'_IQR'] = globals()[var][~((globals()[var]['sub'] < (Q1 - 1.5 * IQR)) |\n                                          (globals()[var]['sub'] > (Q3 + 1.5 * IQR)))]\n    variablesIQR.append(str(var)+'_IQR')  ","8e393a9e":"variablesIQRTenDay = []\nfor var in variablesTenDay:\n    Q1 = globals()[var]['sub'].quantile(0.25)\n    Q3 = globals()[var]['sub'].quantile(0.75)\n    IQR = Q3 - Q1\n    locals()[str(var)+'_IQR'] = globals()[var][~((globals()[var]['sub'] < (Q1 - 1.5 * IQR)) |\n                                          (globals()[var]['sub'] > (Q3 + 1.5 * IQR)))]\n    variablesIQRTenDay.append(str(var)+'_IQR')  ","e9cc4348":"for var1,var2 in zip(variablesIQR,variablesIQRTenDay):\n    if var1 == var2:\n        print(var1)","6f2db3dd":"print(variablesIQR[:5],'\\n',variablesIQRTenDay[:5])","b871839f":"fig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(\n    go.Scatter(x=df_MSMI1_IQR.GregorianDate, y=df_MSMI1_IQR['ClosePriceAd'],name='Close Price IQR'),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=df_MSMI1.GregorianDate, y=df_MSMI1['ClosePriceAd'],name='Close Price '),\n    row=1, col=2\n)\n\nfig.update_layout(title_text=\"Close Price IQR MSMI\")\nfig.show()","8efbe5d5":"values = list()\nfor shape1,shape2 in  zip(variables,variablesIQR):\n    values.append([shape1,shape2,globals()[shape1].shape[0],globals()[shape2].shape[0],globals()[shape1].shape[0]-globals()[shape2].shape[0]])\npd.DataFrame(values,columns=['DataFrame','Remove outliers','Size of rows Before removes',\n                             'Size of rows After removes','Subtraction ']).style.background_gradient(cmap='Reds')","e8db1ba1":"close = pd.DataFrame()\nfor c in variables:\n    temp  = globals()[c]['ClosePriceAd'].reset_index(drop=True).rename(c.split('_')[1])\n    close = pd.concat([close,temp],axis=1)","b58324be":"close.isna().sum().to_frame().rename(columns={0:'Sum Null'}).style.background_gradient(cmap='Greens')","5e425491":"close.dropna(inplace=True)","abc0d8b4":"plt.figure(figsize=(20,12))\nsns.heatmap(close.corr(),linewidths=2)","80051231":"for var1,var2 in zip(variablesIQR,variables):\n    globals()[var1]['Next_day_close'] = globals()[var1]['ClosePriceAd'].shift(+1)\n    globals()[var2]['Next_day_close'] = globals()[var2]['ClosePriceAd'].shift(+1)","10b26914":"for var1,var2 in zip(variablesIQRTenDay,variablesTenDay):\n    globals()[var1]['Next_10day_close'] = globals()[var1]['ClosePriceAd'].shift(+1)\n    globals()[var2]['Next_10day_close'] = globals()[var2]['ClosePriceAd'].shift(+1)","ab140660":"missing_zero_values_table(df_MSMI1_IQR).style.background_gradient(cmap='Greens')","2d45810d":"df_MSMI1_IQR[df_MSMI1_IQR.isna().any(axis=1)]","e4a84814":"(df_MSMI1_IQR[df_MSMI1_IQR['GregorianDate'] == '2015-01-24']['BuyValueTrue'] \/ df_MSMI1_IQR[df_MSMI1_IQR['GregorianDate'] == '2015-01-24']['BuyCountTrue']) \/ (df_MSMI1_IQR[df_MSMI1_IQR['GregorianDate'] == '2015-01-24']['SaleValueTrue'] \/ df_MSMI1_IQR[df_MSMI1_IQR['GregorianDate'] == '2015-01-24']['SaleCountTrue'])","00d3faa3":"df_MSMI1_IQR[df_MSMI1_IQR['GregorianDate'] == '2015-01-24']['SaleValueTrue']","b8973034":"for var1,var2,var3,var4 in zip(variablesIQR,variables,variablesIQRTenDay,variablesTenDay):\n    globals()[var1].dropna(subset=[\"Next_day_close\"],inplace=True)\n    globals()[var2].dropna(subset=[\"Next_day_close\"],inplace=True) \n    globals()[var1].fillna({'BPS':0,'BpsThreeDays':0},inplace=True)\n    globals()[var2].fillna({'BPS':0,'BpsThreeDays':0},inplace=True)\n    globals()[var3].dropna(subset=[\"Next_10day_close\"],inplace=True)\n    globals()[var4].dropna(subset=[\"Next_10day_close\"],inplace=True) \n    globals()[var3].fillna({'BPS':0,'BpsThreeDays':0},inplace=True)\n    globals()[var4].fillna({'BPS':0,'BpsThreeDays':0},inplace=True)","720890af":"df_MSMI1_IQR","ddd02133":"plt.figure(figsize=(20,12))\nsns.heatmap(df_MSMI1_IQR.corr(),linewidths=2,annot=True)","831a94c8":"features = [\"BpsThreeDays\", \"BPS\", \"DailyProfit\",'cdf','dev']\nsns.relplot(\n    x=\"value\", y=\"Next_day_close\", col=\"variable\", data=df_MSMI1_IQR.melt(id_vars=\"Next_day_close\", value_vars=features), \n    facet_kws=dict(sharex=False),\n);","a51c682f":"features = [\"Slope\", \"CloseSubFirst\", \"CloseSubLast\",'MaxSubLast','MaxSubClose']\nsns.relplot(\n    x=\"value\", y=\"Next_day_close\", col=\"variable\", data=df_MSMI1_IQR.melt(id_vars=\"Next_day_close\", value_vars=features), \n    facet_kws=dict(sharex=False),\n);","94067fce":"timeTemp = pd.DataFrame(columns={'compony','MaxDate','MinDate'})\nfor c in df.Compony.unique():\n    new_row = {'compony':c, \n               'MaxDate':df[df.Compony==c].GregorianDate.max(), \n               'MinDate':df[df.Compony==c].GregorianDate.min()}\n    #append row to the dataframe\n    timeTemp = timeTemp.append(new_row, ignore_index=True)\n    timeTemp['Diff'] = timeTemp['MaxDate'] - timeTemp['MinDate']\ntimeTemp.style.background_gradient(cmap='Reds')","49c4075f":"timeTemp.Diff.mean()","9be8d21d":"fig = go.Figure()\n\nfor year in df_MSMI1_IQR.Year.unique():\n    dataset = df_MSMI1_IQR[df_MSMI1_IQR.Year==year]\n    fig.add_trace(go.Scatter(x=dataset.Month.unique(),\n                             y=dataset.groupby('Month')['ClosePriceAd'].sum(),\n                             mode='lines+markers',\n                             name=f'Year {year}'))\n\nfig.update_yaxes(title_text = 'Total')\nfig.update_xaxes(title_text = \"Month\")\n    \nfig.show()","cd432943":"yearVariables = {}\nfor var1 in listYear:\n    temp = []\n    for var2 in variablesIQR:\n        locals()[str(var2)+'_'+str(var1)] = globals()[var2][globals()[var2].Year<=var1]\n        temp.append(str(var2)+'_'+str(var1))\n        yearVariables[var1] = temp","0a8a43ca":"df_MSMI1_IQR_2019","7be07450":"templenDf = {}\nfor key,values in yearVariables.items():\n    temp = {}\n    for i in values:\n        temp[i] = globals()[i].shape[0]\n        templenDf[key] = temp","69e2b245":"lenDfMean = {}\nfor key,values in templenDf.items():\n    res = 0\n    for value in values.values():\n        res += value\n    lenDfMean[key] = res\/40\npd.DataFrame([lenDfMean]).T.rename(columns={0:'Mean Len'}).style.background_gradient(cmap='Greens')","00d40ebb":"def join_string(list_string):\n    # Join the string based on '-' delimiter\n    string = '_'.join(list_string)\n    return string","c41f2af8":"testVariables = []\nfor var in variablesIQR:\n    locals()[\"test_\" +  str(join_string(var.split('_')[1:]))] = globals()[var][:30]\n    testVariables.append(\"test_\" +  str(join_string(var.split('_')[1:])))","50704cfb":"testVariablesTenDay = []\nfor var in variablesIQRTenDay:\n    locals()[\"test10Day_\" +  str(join_string(var.split('_')[1:]))] = globals()[var][:30]\n    testVariablesTenDay.append(\"test10Day_\" +  str(join_string(var.split('_')[1:])))","a55582fb":"for var1,var2 in zip(testVariables,testVariablesTenDay):\n    if var1==var2:\n        print(var1)","95291fc0":"print(testVariables[:5],'\\n',testVariablesTenDay[:5])","8cfe2990":"Xtestvariables = []\nytestvariables = []\nfor var in testVariables:\n    locals()[\"X\" + str(var)] = globals()[var].drop(['Next_day_close'],axis=1).copy()\n    locals()[\"y\" + str(var)] = globals()[var]['Next_day_close'].copy()\n    Xtestvariables.append(\"X\" + str(var))\n    ytestvariables.append(\"y\" + str(var))","3949ee7e":"XtestvariablesTenDay = []\nytestvariablesTenDay = []\nfor var in testVariablesTenDay:\n    locals()[\"X\" + str(var)] = globals()[var].drop(['Next_10day_close'],axis=1).copy()\n    locals()[\"y\" + str(var)] = globals()[var]['Next_10day_close'].copy()\n    XtestvariablesTenDay.append(\"X\" + str(var))\n    ytestvariablesTenDay.append(\"y\" + str(var))","8e0bcf85":"for var1,var2,var3,var4 in zip(Xtestvariables,XtestvariablesTenDay,ytestvariables,ytestvariablesTenDay):\n    if var1 == var2:\n        print(var1)\n    if var3 == var4:\n        print(var3)","69daec55":"print(Xtestvariables[:5],'\\n',XtestvariablesTenDay[:5],'\\n',\n      ytestvariables[:5],'\\n',ytestvariablesTenDay[:5])","47ec2226":"print(Xtest_MSMI1_IQR.shape)\nprint(ytest_MSMI1_IQR.shape)","3ae02278":"for test in testVariables:\n    if globals()[test].shape[0] != 30 or globals()['df_'+str(test.split('_')[1])].shape[0] < 30:\n        print('<<',test.split('_')[1],'>> has little test size.')\n        print('Total Size : ',globals()['df_'+str(test.split('_')[1])].shape[0],' rows.')","e4483d03":"trainVariables = []\nfor var in variablesIQR:\n    locals()[\"train_\" + str(join_string(var.split('_')[1:]))] = globals()[var][30:]\n    trainVariables.append(\"train_\" + str(join_string(var.split('_')[1:])))","1ae54a1b":"trainVariablesTenDay = []\nfor var in variablesIQRTenDay:\n    locals()[\"train10Day_\" + str(join_string(var.split('_')[1:]))] = globals()[var][30:]\n    trainVariablesTenDay.append(\"train10Day_\" + str(join_string(var.split('_')[1:])))","b8089565":"for var1,var2 in zip(trainVariables,trainVariablesTenDay):\n    if var1 == var2:\n        print(var1)","60273ae1":"Xtrainvariables = []\nytrainvariables = []\nfor var in trainVariables:\n    locals()[\"X\" + str(var)] = globals()[var].drop(['Next_day_close'],axis=1).copy()\n    locals()[\"y\" + str(var)] = globals()[var]['Next_day_close'].copy()\n    Xtrainvariables.append(\"X\" + str(var))\n    ytrainvariables.append(\"y\" + str(var))","9ed00db8":"XtrainvariablesTenDay = []\nytrainvariablesTenDay = []\nfor var in trainVariablesTenDay:\n    locals()[\"X\" + str(var)] = globals()[var].drop(['Next_10day_close'],axis=1).copy()\n    locals()[\"y\" + str(var)] = globals()[var]['Next_10day_close'].copy()\n    XtrainvariablesTenDay.append(\"X\" + str(var))\n    ytrainvariablesTenDay.append(\"y\" + str(var))","3af8cfce":"Xtrain_MSMI1_IQR.head()","1e55675d":"ytrain_MSMI1_IQR.head()","7dc427f3":"Xtrain10Day_MSMI1_IQR.head()","2570c33f":"ytrain10Day_MSMI1_IQR.head()","f9f7168a":"for keyX,keyY in zip(Xtrainvariables,ytrainvariables):\n    if globals()[keyX].shape[0] != globals()[keyY].shape[0]:\n        print(keyX)","bdd323d1":"Xtrain_MSMI1_IQR[Xtrain_MSMI1_IQR.isin(Xtest_MSMI1_IQR.GregorianDate).any(1)]","5e909457":"for keyXtrain,keyXtest in zip(Xtrainvariables,Xtestvariables):\n    globals()[keyXtrain].drop(['GregorianDate','Compony','Year','Month','sub'],axis=1,inplace=True)\n    globals()[keyXtest].drop(['GregorianDate','Compony','Year','Month','sub'],axis=1,inplace=True)","75b14229":"for keyXtrain,keyXtest in zip(XtrainvariablesTenDay,XtestvariablesTenDay):\n    globals()[keyXtrain].drop(['Year','Month','sub'],axis=1,inplace=True)\n    globals()[keyXtest].drop(['Year','Month','sub'],axis=1,inplace=True)","4b6e6b11":"!pip install xlrd","2aa4f1ad":"!pip install openpyxl ","ad88041c":"symbols = pd.read_excel('..\/input\/securities-and-exchange-iran\/Symbols-explanation Persian.xlsx',sheet_name='Sheet1')\nsymbols.rename(columns={'\u06a9\u062f 5\u0631\u0642\u0645\u06cc ':'DIGIT','\u0646\u0627\u0645 \u0634\u0631\u06a9\u062a':'NAME','\u0646\u0645\u0627\u062f':'symbol'},inplace=True)\nsymbols.head()","3350be11":"def LinearRegression_MAE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mae = mean_absolute_error(y_test,y_predict)\n    return lin_mae","0ea0bd6f":"def LinearRegression_MSE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mse = mean_squared_error(y_test,y_predict)\n    return lin_mse","aa669829":"def LinearRegression_RMSE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mse = mean_squared_error(y_test,y_predict)\n    lin_rmse = np.sqrt(lin_mse)\n    return lin_rmse","3fc546f3":"def LinearRegression_MARE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mare = np.mean(np.abs((y_predict - y_test) \/ y_test ))\n    return lin_mare","639c6c8e":"def LinearRegression_MSRE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_msre = np.mean(np.square(np.abs((y_predict - y_test) \/ y_test )))\n    return lin_msre","3fbf2433":"def LinearRegression_RMSRE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_msre = np.mean(np.square(np.abs((y_predict - y_test) \/ y_test )))\n    lin_rmsre = np.sqrt(lin_msre)\n    return lin_rmsre","8c043e03":"def LinearRegression_MAPE(x_train,y_train,x_test,y_test,more_info=0):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mape = mean_absolute_percentage_error(y_test,y_predict)\n    if more_info == 1:\n        return y_predict,lin_mape\n    else :\n        return lin_mape","2e3cefdf":"def LinearRegression_MSPE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mspe = np.mean(np.square(np.abs((y_predict - y_test) \/ y_test)))*100 \n    return lin_mspe","4855f4e2":"def LinearRegression_RMSPE(x_train,y_train,x_test,y_test):\n    lin_reg = LinearRegression()\n    lin_reg.fit(x_train,y_train)\n    y_predict = lin_reg.predict(x_test)\n    lin_mspe = np.mean(np.square(np.abs((y_predict - y_test) \/ y_test)))*100 \n    lin_rmspe = np.sqrt(lin_mspe)\n    return lin_rmspe","429a99b1":"pm = ['LinearRegression_MAE','LinearRegression_MSE','LinearRegression_RMSE',\n     'LinearRegression_MARE','LinearRegression_MSRE','LinearRegression_RMSRE',\n     'LinearRegression_MAPE','LinearRegression_MSPE','LinearRegression_RMSPE']","112018e1":"def MinMaxNormalize(df,showMore=0):\n    # train the normalization\n    scaler = MinMaxScaler(feature_range=(0,1))\n    scaler = scaler.fit(df)\n    normalized = scaler.transform(df)\n    if showMore == 1:\n        print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n        for i in range(5):\n            print(normalized[i])\n    return normalized","077f7008":"def StandardNormalize(df,showMore=0):\n    # train the normalization\n    scaler = StandardScaler()\n    scaler = scaler.fit(df)\n    normalized = scaler.transform(df)\n    if showMore == 1:\n        print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n        for i in range(5):\n            print(normalized[i])\n    return normalized","fdcd228a":"msmi0_0 = {}  \nfor p in pm:\n    msmi0_0[p.split('_')[1]] = globals()[p](MinMaxNormalize(Xtrain_MSMI1_IQR),ytrain_MSMI1_IQR,\n                                          MinMaxNormalize(Xtest_MSMI1_IQR),ytest_MSMI1_IQR)\nmsmi0_0 = pd.DataFrame(msmi0_0.items())\nmsmi0_0.rename(columns = {1:'Min Max Scaler'}, inplace = True)\nmsmi0_0","f300fc64":"msmi0_1 = {}\nfor p in pm:\n    msmi0_1[p.split('_')[1]] = globals()[p](StandardNormalize(Xtrain_MSMI1_IQR),ytrain_MSMI1_IQR,\n                                          StandardNormalize(Xtest_MSMI1_IQR),ytest_MSMI1_IQR)\nmsmi0_1 = pd.DataFrame(msmi0_1.items())\nmsmi0_1.rename(columns = {1:'Standard Scaler'}, inplace = True)\nmsmi0_1","82d244c2":"performance  = {}\nfor p in pm:\n    performance[p.split('_')[1]] = dict()\n    for x_train,y_train,x_test,y_test in zip(Xtrainvariables,ytrainvariables,Xtestvariables,ytestvariables):\n        if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n            performance[p.split('_')[1]][x_train.split('_')[1]] = np.nan\n        else :\n            performance[p.split('_')[1]][x_train.split('_')[1]] = globals()[p](MinMaxNormalize(globals()[(x_train)]),\n                                                                               globals()[y_train],\n                                                                               MinMaxNormalize(globals()[(x_test)]),\n                                                                               globals()[y_test]) ","79fa60eb":"performance = pd.DataFrame(performance)\nperformance.style.background_gradient(cmap='Blues')","d6ecf39d":"performance  = {}\nfor p in pm:\n    performance[p.split('_')[1]] = dict()\n    for x_train,y_train,x_test,y_test in zip(Xtrainvariables,ytrainvariables,Xtestvariables,ytestvariables):\n        if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n            performance[p.split('_')[1]][x_train.split('_')[1]] = np.nan\n        else :\n            performance[p.split('_')[1]][x_train.split('_')[1]] = globals()[p](StandardNormalize(globals()[(x_train)]),\n                                                                               globals()[y_train],\n                                                                               StandardNormalize(globals()[(x_test)]),\n                                                                               globals()[y_test]) ","a722b763":"performance = pd.DataFrame(performance)\nperformance.style.background_gradient(cmap='Greens')","414f27fb":"pd.set_option('display.float_format', lambda x: '%.5f' % x)","4db508d6":"msmi1_0 = {} \nfor p in pm:\n    msmi1_0[p.split('_')[1]] = globals()[p](Xtrain_MSMI1_IQR,ytrain_MSMI1_IQR,Xtest_MSMI1_IQR,ytest_MSMI1_IQR)\nmsmi1_0 = pd.DataFrame(msmi1_0.items())\nmsmi1_0.rename(columns = {1:'All Features'}, inplace = True)\nmsmi1_0","40de548d":"msmiTenDay1_0 = {} \nfor p in pm:\n    msmiTenDay1_0[p.split('_')[1]] = globals()[p](Xtrain10Day_MSMI1_IQR,ytrain10Day_MSMI1_IQR,Xtest10Day_MSMI1_IQR,ytest10Day_MSMI1_IQR)\nmsmiTenDay1_0 = pd.DataFrame(msmiTenDay1_0.items())\nmsmiTenDay1_0.rename(columns = {1:'All Features'}, inplace = True)\nmsmiTenDay1_0","52241284":"y_predict,performance = LinearRegression_MAPE(Xtrain_MSMI1_IQR,ytrain_MSMI1_IQR,Xtest_MSMI1_IQR,ytest_MSMI1_IQR,more_info=1)\npredict_values = {'Date': df_MSMI1_IQR.GregorianDate[:30],\n        'Predict': y_predict\n        }\ndfPredict = pd.DataFrame(predict_values, columns = ['Date', 'Predict'])","755dc682":"y10Day_predict,performance10Day = LinearRegression_MAPE(Xtrain10Day_MSMI1_IQR,ytrain10Day_MSMI1_IQR,Xtest10Day_MSMI1_IQR,\n                                              ytest10Day_MSMI1_IQR,more_info=1)","a5b769e9":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=df_MSMI1_IQR.GregorianDate[30:], y=ytrain_MSMI1_IQR,\n                    mode='lines',\n                    name='y_train'))\nfig.add_trace(go.Scatter(x=dfPredict.Date, y=dfPredict.Predict,\n                    mode='markers+lines',\n                    name='y_predict'))\n\nfig.add_trace(go.Scatter(x=df_MSMI1_IQR.GregorianDate[:30], y=ytest_MSMI1_IQR,\n                    mode='markers+lines',\n                    name='y_test'))\nfig.update_layout(title =  \"Linear Regression , MAPE = ~%.3f , Next Day , Test one month\"%performance)\nfig.update_yaxes(title_text = 'Close Price')\nfig.update_xaxes(title_text = \"Date\")","86ccfa03":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(y=ytrain10Day_MSMI1_IQR,\n                    mode='lines',\n                    name='y_train'))\nfig.add_trace(go.Scatter(y=y10Day_predict,\n                    mode='markers+lines',\n                    name='y_predict'))\n\nfig.add_trace(go.Scatter( y=ytest10Day_MSMI1_IQR,\n                    mode='markers+lines',\n                    name='y_test'))\nfig.update_layout(title =  \"Linear Regression , MAPE = ~%.3f , Next 10 Day , Test one month\"%performance10Day)\nfig.update_yaxes(title_text = 'Close Price')","a5f7cade":"performance  = {}\nfor p in pm:\n    performance[p.split('_')[1]] = dict()\n    for x_train,y_train,x_test,y_test in zip(Xtrainvariables,ytrainvariables,Xtestvariables,ytestvariables):\n        if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n            performance[p.split('_')[1]][x_train.split('_')[1]] = np.nan\n        else :\n            performance[p.split('_')[1]][x_train.split('_')[1]] = globals()[p](globals()[x_train],globals()[y_train],\n                                                                           globals()[x_test],globals()[y_test])  ","50f14f13":"performance = pd.DataFrame(performance)\nperformance.style.background_gradient(cmap='Greens')","c76f686e":"pd.merge(performance.reset_index().rename(columns={'index':'DIGIT'}), symbols[['DIGIT','symbol']], \n         on='DIGIT', how='outer').to_csv('performance.csv', index = True)","8fdaab88":"performance  = {}\nfor p in pm:\n    performance[p.split('_')[1]] = dict()\n    for x_train,y_train,x_test,y_test in zip(XtrainvariablesTenDay,ytrainvariablesTenDay,XtestvariablesTenDay,ytestvariablesTenDay):\n        if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n            performance[p.split('_')[1]][x_train.split('_')[1]] = np.nan\n        else :\n            performance[p.split('_')[1]][x_train.split('_')[1]] = globals()[p](globals()[x_train],globals()[y_train],\n                                                                           globals()[x_test],globals()[y_test])  ","fe9733ed":"performance = pd.DataFrame(performance)\nperformance.style.background_gradient(cmap='Blues')","8e1fdb21":"pd.merge(performance.reset_index().rename(columns={'index':'DIGIT'}), symbols[['DIGIT','symbol']], \n         on='DIGIT', how='outer').to_csv('performance10Day.csv', index = True)","8cfa5012":"# performance  = {}\n# for x_train,y_train,x_test,y_test in zip(Xtrainvariables,ytrainvariables,Xtestvariables,ytestvariables):\n#     performance[x_train.split('_')[1]] = dict()\n#     if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n#         for p in pm:\n#             performance[x_train.split('_')[1]][p.split('_')[1]] = np.nan\n#     else :\n#         for p in pm:\n#             performance[x_train.split('_')[1]][p.split('_')[1]] = globals()[p](globals()[x_train],globals()[y_train],\n#                                                                            globals()[x_test],globals()[y_test])    ","c246cff2":"def featureScores(X_train,y_train,score_func):\n    fs = SelectKBest(score_func=score_func, k='all')\n    fs.fit(X_train, y_train)\n    dfscores = pd.DataFrame(fs.scores_)\n    dfcolumns = pd.DataFrame(X_train.columns)\n    #concat two dataframes for better visualization \n    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n    featureScores.columns = ['Columns','Score']  #naming the dataframe columns\n    return featureScores\n\ndef scores(X_train,y_train,score_func):\n    if X_train.shape[0] < 30 or X_train.shape[0] ==0:\n        return np.nan\n    fs = SelectKBest(score_func=score_func, k='all')\n    fs.fit(X_train, y_train)\n    return fs.scores_","601f41f8":"def select_features(X_train, y_train, X_test,score_func):\n    # configure to select a subset of features\n    fs = SelectKBest(score_func=score_func, k=20)\n    # learn relationship from training data\n    fs.fit(X_train, y_train)\n    # transform train input data\n    X_train_fs = fs.transform(X_train)\n    # transform test input data\n    X_test_fs = fs.transform(X_test)\n    return X_train_fs, X_test_fs","19e7c06c":"featureScores(Xtrain_MSMI1_IQR, ytrain_MSMI1_IQR,mutual_info_regression).set_index('Columns').assign(percent=lambda x: x \/ x.sum())","f5f50608":"featureScores(Xtrain10Day_MSMI1_IQR, ytrain10Day_MSMI1_IQR,\n              mutual_info_regression).set_index('Columns').assign(percent=lambda x: x \/ x.sum())","5c55e091":"featureScores(Xtrain_MSMI1_IQR, ytrain_MSMI1_IQR,f_regression).set_index('Columns').assign(percent=lambda x: x \/ x.sum())","8552033c":"featureScores(Xtrain10Day_MSMI1_IQR, ytrain10Day_MSMI1_IQR,\n              f_regression).set_index('Columns').assign(percent=lambda x: x \/ x.sum())","301fcef7":"FeatureScores = {}\nFeatureScores['f_regression'] = dict()\nFeatureScores['mutual_info_regression'] = dict()\nfor x,y in zip(Xtrainvariables,ytrainvariables):\n    FeatureScores['f_regression'][x.split('_')[1]] = scores(globals()[x], globals()[y],f_regression)\n    FeatureScores['mutual_info_regression'][x.split('_')[1]] = scores(globals()[x], globals()[y],mutual_info_regression)","10e52795":"# pd.DataFrame(FeatureScores['f_regression'],\n#              index=Xtrain_TAIR1_IQR.columns).T.to_csv('Feature selection f_regression.csv', \n# index = True)","6d8e93ec":"temp = pd.DataFrame(FeatureScores['f_regression'],index=Xtrain_TAIR1_IQR.columns)\nfor col in temp.columns:\n    name = str(col)+'_percent'\n    temp = pd.concat([temp, \n                pd.DataFrame(temp[col]).apply(lambda x: x \/ x.sum()).rename(columns={col:name})], axis=1)\ntemp = temp.T\ntemp = temp.reset_index()\ntemp['DIGIT'] = temp['index'].apply(lambda x:x.split('_')[0])\ntemp.set_index('index',inplace=True)\npd.merge(temp,symbols[['DIGIT','symbol']],\n        on='DIGIT',how='outer').to_csv('Feature selection f_regression.csv', index = True)","b5ced732":"# pd.DataFrame(FeatureScores['mutual_info_regression'],\n#              index=Xtrain_TAIR1_IQR.columns).T.to_csv('Feature selection mutual_info_regression.csv',\n# index=True)","5ccee6ab":"temp = pd.DataFrame(FeatureScores['mutual_info_regression'],index=Xtrain_TAIR1_IQR.columns)\nfor col in temp.columns:\n    name = str(col)+'_percent'\n    temp = pd.concat([temp, \n                pd.DataFrame(temp[col]).apply(lambda x: x \/ x.sum()).rename(columns={col:name})], axis=1)\n\ntemp = temp.T\ntemp = temp.reset_index()\ntemp['DIGIT'] = temp['index'].apply(lambda x:x.split('_')[0])\ntemp.set_index('index',inplace=True)\npd.merge(temp,symbols[['DIGIT','symbol']],\n        on='DIGIT',how='outer').to_csv('Feature selection mutual_info_regression.csv', index = True)","c390bce7":"FeatureScores = {}\nFeatureScores['f_regression'] = dict()\nFeatureScores['mutual_info_regression'] = dict()\nfor x,y in zip(XtrainvariablesTenDay,ytrainvariablesTenDay):\n    FeatureScores['f_regression'][x.split('_')[1]] = scores(globals()[x], globals()[y],f_regression)\n    FeatureScores['mutual_info_regression'][x.split('_')[1]] = scores(globals()[x], globals()[y],mutual_info_regression)","e832e907":"temp = pd.DataFrame(FeatureScores['f_regression'],index=Xtrain_TAIR1_IQR.columns)\nfor col in temp.columns:\n    name = str(col)+'_percent'\n    temp = pd.concat([temp, \n                pd.DataFrame(temp[col]).apply(lambda x: x \/ x.sum()).rename(columns={col:name})], axis=1)\n\ntemp = temp.T\ntemp = temp.reset_index()\ntemp['DIGIT'] = temp['index'].apply(lambda x:x.split('_')[0])\ntemp.set_index('index',inplace=True)\npd.merge(temp,symbols[['DIGIT','symbol']],\n        on='DIGIT',how='outer').to_csv('Feature selection 10 Day f_regression.csv', index = True)","d4ecc0d7":"temp = pd.DataFrame(FeatureScores['mutual_info_regression'],index=Xtrain_TAIR1_IQR.columns)\nfor col in temp.columns:\n    name = str(col)+'_percent'\n    temp = pd.concat([temp, \n                pd.DataFrame(temp[col]).apply(lambda x: x \/ x.sum()).rename(columns={col:name})], axis=1)\ntemp = temp.T\ntemp = temp.reset_index()\ntemp['DIGIT'] = temp['index'].apply(lambda x:x.split('_')[0])\ntemp.set_index('index',inplace=True)\npd.merge(temp,symbols[['DIGIT','symbol']],\n        on='DIGIT',how='outer').to_csv('Feature selection 10 Day mutual_info_regression.csv', index = True)","56b1c036":"# feature selection mutual_info_regression\nX_train_fs, X_test_fs = select_features(Xtrain_MSMI1_IQR, ytrain_MSMI1_IQR, Xtest_MSMI1_IQR,mutual_info_regression)","8bcfea8e":"msmi1_1 = {}\nfor p in pm:\n    msmi1_1[p.split('_')[1]] = globals()[p](X_train_fs,ytrain_MSMI1_IQR,X_test_fs,ytest_MSMI1_IQR)\nmsmi1_1 = pd.DataFrame(msmi1_1.items())\nmsmi1_1.rename(columns = {1:'mutual_info_regression'}, inplace = True)\nmsmi1_1","39217ae6":"# feature selection f_regression\nX_train_fs, X_test_fs = select_features(Xtrain_MSMI1_IQR, ytrain_MSMI1_IQR, Xtest_MSMI1_IQR,f_regression)","274caf41":"msmi1_2 = {}\nfor p in pm:\n    msmi1_2[p.split('_')[1]] = globals()[p](X_train_fs,ytrain_MSMI1_IQR,X_test_fs,ytest_MSMI1_IQR)\nmsmi1_2 = pd.DataFrame(msmi1_2.items())\nmsmi1_2.rename(columns = {1:'f_regression'}, inplace = True)\nmsmi1_2","43402238":"msmis = [msmi0_0,msmi0_1,msmi1_0,msmi1_1,msmi1_2]\nreduce(lambda left,right: pd.merge(left,right,on=0), msmis).style.background_gradient(cmap='Blues')","f0db384f":"# (close today  - predict today ) \/ close yesterday\nPerformanceMeasurement = pd.DataFrame()\nPerformanceMeasurement['CloseToday']  = ytest_MSMI1_IQR\nPerformanceMeasurement['PredictToday']= y_predict\nPerformanceMeasurement['CloseYesterday'] = Xtest_MSMI1_IQR.ClosePriceYesterday\nPerformanceMeasurement['Measurement'] = (PerformanceMeasurement.CloseToday - PerformanceMeasurement.PredictToday)\/PerformanceMeasurement.CloseYesterday\nPerformanceMeasurement.style.bar(subset=['Measurement'], align='mid', color=['#d65f5f'])","abcea6b6":"performance  = {}\nfor p in pm:\n    performance[p.split('_')[1]] = dict()\n    for x_train,y_train,x_test,y_test in zip(Xtrainvariables,ytrainvariables,Xtestvariables,ytestvariables):\n        if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n            performance[p.split('_')[1]][x_train.split('_')[1]] = np.nan\n        else :\n            x_train_fs, x_test_fs = select_features(globals()[x_train],globals()[y_train],globals()[x_test],mutual_info_regression)\n            performance[p.split('_')[1]][x_train.split('_')[1]] = globals()[p](x_train_fs,globals()[y_train],\n                                                                               x_test_fs,globals()[y_test])  ","d6110e41":"performance = pd.DataFrame(performance)\npd.merge(performance.reset_index().rename(columns={'index':'DIGIT'}), symbols[['DIGIT','symbol']], \n         on='DIGIT', how='outer').style.background_gradient(cmap='Greens')","98144396":"pd.merge(performance.reset_index().rename(columns={'index':'DIGIT'}), symbols[['DIGIT','symbol']], \n         on='DIGIT', how='outer').to_csv('mutual_info_regression.csv', index = True)","bb5bba6c":"performance  = {}\nfor p in pm:\n    performance[p.split('_')[1]] = dict()\n    for x_train,y_train,x_test,y_test in zip(Xtrainvariables,ytrainvariables,Xtestvariables,ytestvariables):\n        if globals()[x_train].shape[0] < 30 or globals()[x_test].shape[0]<30:\n            performance[p.split('_')[1]][x_train.split('_')[1]] = np.nan\n        else :\n            x_train_fs, x_test_fs = select_features(globals()[x_train],globals()[y_train],globals()[x_test],f_regression)\n            performance[p.split('_')[1]][x_train.split('_')[1]] = globals()[p](x_train_fs,globals()[y_train],\n                                                                               x_test_fs,globals()[y_test])  ","07ebef50":"performance = pd.DataFrame(performance)\npd.merge(performance.reset_index().rename(columns={'index':'DIGIT'}), symbols[['DIGIT','symbol']], \n         on='DIGIT', how='outer').style.background_gradient(cmap='Blues')","7053c049":"pd.merge(performance.reset_index().rename(columns={'index':'DIGIT'}), symbols[['DIGIT','symbol']], \n         on='DIGIT', how='outer').to_csv('f_regression.csv', index = True)","3a5ee1d1":"# Outlier Detection ","92b4e7a0":"### 1.Model Built Using All Features","a8587f99":"This company, it's not in zip file","6dc2b536":"OK, we have outliers data  \nSolution : IQR","361adb12":"Mean Diff days : 3130   ","cb7e448b":"$$\n\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right|.\n$$","5b12b2ac":"one company","6b8ec100":"Divided everything to zero is infinite","3e1cec12":"I Drop 526665 Rows  \nand 13 Features :))","a257bc55":"## Max Price minus Close Price","c8afe1ec":"# Creating Features","0175d66f":"join dataFrames","13cb56ab":"# Prepare data for machine learning","e3c68492":"For all companies","c4d4e173":"# Correlation Between Companies","6d876c9c":"**Correlation (Pearson, spearman)**   \nFormula :\n$$\n((X[:, i] \u2014 mean(X[:, i])) * (y \u2014 mean_y)) \/ (std(X[:, i]) * std(y))\n$$","3438b8ea":"Just for MSMI company analysis","31f3f864":"Because I shift it 'next day close price' columns has one missing value   \nso I must drop it in all dataset   \nwhy BPS has null values let's find out why ","a3968237":"Lets analysis two companies MSMI1, SAHD","50ec93a8":"It's so clear, we have 27 columns for each variable :)","f70c56ee":"## Goal \nAnalysis and predict values for 40 companies  \nspecifically [NICICO Company](http:\/\/www.tsetmc.com\/Loader.aspx?ParTree=151311&i=35425587644337450)  \nFive Digit code of this company is MSMI1","b96e29ad":"OK, we don't have any unmatched size of x, y","99830ca5":"$$\n\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.\n$$","ca800c5b":"## 1.Calculate Daily profit","b5b5593d":"In 2010, I think we have a lot of size of test is zero","f294e1e5":"## Max price minus Last Price ","cfeb2252":"The standard score of a sample x is calculated as:  \n$$\n    z = (x - u) \/ s\n$$\n\nwhere u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False","2782bd3b":"**Mutual information**  \nFor more information, go to this [LINK](https:\/\/en.wikipedia.org\/wiki\/Mutual_information)","220e6879":"**Selection of twenty importance features, then measurement**","f219bfe1":"Sounds great \"next_day_close\" (model must be predicted) has powerful correlation with some features   \nin feature selection, I can use it","46ed908a":"## 2.BPS","e7e91726":"the first quartile (Q1) is equal to the median of the n smallest entries  \nthe third quartile (Q3) is equal to the median of the n largest entries  \nThe interquartile range (IQR), also called as midspread or middle 50%, or technically H-spread is the difference between the third quartile (Q3) and the first quartile (Q1). It covers the center of the distribution and contains 50% of the observations. IQR = Q3 \u2013 Q1","756526a3":"for all company","72b1712a":"Work in progress","d4adaee8":"Best score function for \"MSMI\" company is all features, but we have multiple companies we must check it in 40 companies then say is good for us or not","a8ff368d":"## 4.CDF","eefff853":"# Remove Unusable columns","c4645745":"Just for one company","dcf7d89c":"# Create Test Set","72be1721":"## Normalize ","7d2f8172":"I must convert Date column from object type to date time","f927cf82":"So delete these columns ","fb62087c":"ooooo","8b3f7be9":"MSMSI has powerful correlation with NORI,FAYF,IDOC,FKHJ,PNTD,SFKZ","323fa13b":"## Merge","62c456ca":"CDF of Random Distribution","b3f2812f":"For one company","e9716998":"## Correlation between features","2fac0251":"for all companies","3e32324b":"# Analysis by Date","1bac0c47":"$$\n\\text{MAPE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\frac{{}\\left| y_i - \\hat{y}_i \\right|}{max(\\epsilon, \\left| y_i \\right|)}\n$$","4fde3db3":"### 2. Model Built Using Correlation Features\n### 3. Model Built Using Mutual Information Features","b1eb5efe":"$$\nX_std = (X - X.min(axis=0)) \/ (X.max(axis=0) - X.min(axis=0))   \n$$  \n$$\nX_scaled = X_std * (max - min) + min\n$$","aa3c496b":"# Next Day","9f297e90":"## 3.BPS Three Days","abfc284e":"## Performance measurement\n1. MAE\n2. MSE\n3. RMSE\n4. MARE\n5. MSRE\n6. RMSRE\n7. MAPE\n8. MSPE\n9. RMSPE","965d916d":"## Close price minus First price","58c329dd":"I want to predict next day close price  \nit's important to predict next day close Securities ","aab26f15":"# LinearRegression ","c7c73827":"I want to be honest with you \n > In theory, regression is insensitive to standardization since any linear transformation of input data can be counteracted by adjusting model parameters.\n \nso in my opinion it must be better denormual and I just tested it for my curiosity","f7d57782":"Just for one company","b482ed72":"# Load Datasets","35adf2c6":"## Feature importance","b6fa5aed":"# Create Variables","043a11a8":"## Close Price minus Last Price","551befc1":"For all companies"}}