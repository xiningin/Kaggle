{"cell_type":{"f12409c0":"code","ce1002bb":"code","a8fe6162":"code","5089f109":"code","4c661106":"code","4973d69c":"code","225ff0a4":"code","ce31b191":"code","6c79494c":"code","f20eb1ba":"code","7f13ba74":"code","d2682573":"code","70f7e31d":"code","00628be7":"code","e7b5b523":"code","be068192":"code","a89ba302":"code","35f8be8d":"code","4293de3b":"code","52153883":"code","e3a18819":"code","e56a2c54":"code","0b82efc5":"code","b64803de":"code","e1fe9d73":"code","c71909fb":"code","3bd237c4":"code","644b5bfe":"code","ffab1079":"code","50aa9612":"code","aa940f98":"code","27a3a103":"code","33ed053c":"code","8b7e4d06":"code","dd2fc2a2":"code","30ebf3f6":"code","992f8d39":"code","c256f986":"markdown","7ab70e8a":"markdown","ef61c577":"markdown","0e8ee701":"markdown","35311557":"markdown","46f0659d":"markdown","3ea9fe26":"markdown","491c00ba":"markdown","159c0d8e":"markdown","45efe3d5":"markdown","ba628147":"markdown","f4a60b4e":"markdown","92d7dde9":"markdown","d321fb91":"markdown","25bf37cc":"markdown","e1a96300":"markdown","26a5d6b8":"markdown","37d65c02":"markdown","3dca2147":"markdown","e895cd53":"markdown","f652a0de":"markdown","081fddd8":"markdown","2ace824b":"markdown"},"source":{"f12409c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce1002bb":"import pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing \nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","a8fe6162":"df=pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","5089f109":"df.head()","4c661106":"df.info()","4973d69c":"df.isnull().sum()","225ff0a4":"sns.heatmap(df.isnull())","ce31b191":"df.describe()","6c79494c":"df.bmi.fillna(df.bmi.mean(),inplace=True)","f20eb1ba":"df.isnull().sum()","7f13ba74":"sns.heatmap(df.isnull())","d2682573":"df.columns","70f7e31d":"df.gender.unique()","00628be7":"df.ever_married.unique()","e7b5b523":"df.work_type.unique()","be068192":"df.Residence_type.unique()","a89ba302":"df.smoking_status.unique()","35f8be8d":"df.smoking_status = df.smoking_status.replace({\"Unknown\": df.smoking_status.mode()[0]})","4293de3b":"df.smoking_status.unique()","52153883":"df.info()","e3a18819":"label_encoder = preprocessing.LabelEncoder() \ndf['gender']= label_encoder.fit_transform(df['gender'])\ndf['ever_married']= label_encoder.fit_transform(df['ever_married'])\ndf['work_type']= label_encoder.fit_transform(df['work_type'])\ndf['Residence_type']= label_encoder.fit_transform(df['Residence_type'])\ndf['smoking_status']= label_encoder.fit_transform(df['smoking_status'])","e56a2c54":"df.head()","0b82efc5":"fig, ax = plt.subplots(figsize=(10,10))        \nsns.heatmap(df.corr(),annot=True, linewidths=.5, ax=ax)","b64803de":"del df['id']","e1fe9d73":"df.head()","c71909fb":"X = df.iloc[:,0:10]  #independent columns\ny = df.iloc[:,-1]","3bd237c4":"X","644b5bfe":"bestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Parameters','Score']  #naming the dataframe columns\nfeatureScores","ffab1079":"print(featureScores.nlargest(5,'Score'))","50aa9612":"df=df[['age','avg_glucose_level','heart_disease','hypertension','smoking_status']]\ndf.head()","aa940f98":"X_train,X_test,y_train,y_test=train_test_split(df.drop('smoking_status',axis=1),df['smoking_status'],test_size=0.30,random_state=101)","27a3a103":"logmodel=LogisticRegression(multi_class='multinomial', solver='lbfgs')","33ed053c":"logmodel.fit(X_train,y_train)","8b7e4d06":"predictions=logmodel.predict(X_test)","dd2fc2a2":"for i in predictions:\n    print(i)","30ebf3f6":"accuracy=accuracy_score(y_test,predictions)\naccuracy*100","992f8d39":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","c256f986":"Getting to know the data and the data types","7ab70e8a":"Label Encoding the Data ","ef61c577":"Plotting the graph of the null values","0e8ee701":"Splitting the Data Into Train and Test Split Data","35311557":"Importing the Libraries\n","46f0659d":"Understanding the data\n","3ea9fe26":"Getting the Classification Report ","491c00ba":"Calculating the accuracy of the model","159c0d8e":"Filled the NaN values with the mean score","45efe3d5":"Getting the Predictions","ba628147":"Deleting the ID Column","f4a60b4e":"Getting the know the count null values ","92d7dde9":"Getting to know the columns ","d321fb91":"Getting the stastical knowledge of the data for analysing the data ","25bf37cc":"Getting the Most Realted Features using Chi Square ","e1a96300":"Building the Multiclass Logistic Model","26a5d6b8":"Plotting the Correlation Matrix Graph","37d65c02":"Getting the knowledge of unique values in each column","3dca2147":"Reading the data ","e895cd53":"Replacing the **Unknown** value in Smoking the column with NaN","f652a0de":"The Chi-Squared test is a statistical hypothesis test that assumes (the null hypothesis) that the observed frequencies for a categorical variable match the expected frequencies for the categorical variable. The test calculates a statistic that has a chi-squared distribution, named for the Greek capital letter Chi (X) pronounced \u201cki\u201d as in kite.\nWe try to test the likelihood of test data(sample data) to find out whether the observed distribution of data set is a statistical fluke(due to chance ) or not. \u201cGoodness of fit\u201d statistic in the chi-square test, measures how well the observed distribution of data fits with the distribution that is expected if the variables are independent.\n\n![image.png](attachment:image.png)","081fddd8":"Label Encoding - Handling Categorical Data \nThis approach is very simple and it involves converting each value in a column to a number. Consider a dataset of bridges having a column names bridge-types having below values. Though there will be many more columns in the dataset, to understand label-encoding, we will focus on one categorical column only.\n\nConsider we have column values like: <br>\nArch <br>\nBeam <br>\nTruss <\/br>\nCantilever <br>\nTied Arch <br>\nSuspension <br>\nCable \n\n<img src=\"https:\/\/miro.medium.com\/max\/289\/1*VinegxkUYMzik9GpucWCFA.png\">\n\n\nWe choose to encode the text values by putting a running sequence for each text values like below:\nWith this, we completed the label-encoding of variable bridge-type. That\u2019s all label encoding is about. But depending upon the data values and type of data, label encoding induces a new problem since it uses number sequencing. The problem using the number is that they introduce relation\/comparison between them. Apparently, there is no relation between various bridge type, but when looking at the number, one might think that \u2018Cable\u2019 bridge type has higher precedence over \u2018Arch\u2019 bridge type. The algorithm might misunderstand that data has some kind of hierarchy\/order 0 < 1 < 2 \u2026 < 6 and might give 6X more weight to \u2018Cable\u2019 in calculation then than \u2018Arch\u2019 bridge type.\n\nLet\u2019s consider another column named \u2018Safety Level\u2019. Performing label encoding of this column also induces order\/precedence in number, but in the right way. Here the numerical order does not look out-of-box and it makes sense if the algorithm interprets safety order 0 < 1 < 2 < 3 < 4 i.e. none < low < medium < high < very high.\n\n<img src=\"https:\/\/miro.medium.com\/max\/294\/1*KdCvKnI9ATVPiozmuRindA.png\">","2ace824b":"Checking for reamining Null Values"}}