{"cell_type":{"31904835":"code","38f2b913":"code","1bfade89":"code","6d78ced9":"code","7009de46":"code","33d9e1fb":"code","a5a268f5":"code","fee35af3":"code","6ef7d22a":"code","1bdbe610":"code","594a5ed7":"code","fc39adb2":"code","95444929":"code","855ba9b6":"code","549a7680":"code","2333e4de":"code","bd6cdaac":"code","b1f1761f":"code","483f3690":"code","0b7d9524":"code","a96cc276":"code","6b39540d":"code","990ca4ea":"code","c4845985":"code","eca9cda2":"code","f39b99ed":"code","6e31a09a":"code","38700d92":"code","ebedf64f":"code","43a42406":"code","2e8158be":"markdown","07adc670":"markdown","bcab63e6":"markdown","e229d8de":"markdown","b350d6bb":"markdown","022a6e54":"markdown","47b80c79":"markdown","60236bc3":"markdown","1bca3d80":"markdown","a2a7e4a2":"markdown","4ac42c0b":"markdown","7ebeab7f":"markdown","a511fa3b":"markdown","2c632e9f":"markdown","2b545dbf":"markdown","71206073":"markdown","588464ca":"markdown","c78951a9":"markdown","2755ff70":"markdown","dcd50689":"markdown","f274d509":"markdown","89f11e71":"markdown","c1d41a61":"markdown","76f1ce7b":"markdown","6e584eb4":"markdown","3c567ff7":"markdown","b93fa76c":"markdown","8d4a60a3":"markdown","2281d9bd":"markdown","987824e0":"markdown","43ae2c17":"markdown","c4ad3f6b":"markdown","a229b48e":"markdown","d95f0df7":"markdown","3a5ed8de":"markdown","8a86cfe9":"markdown","c4909b21":"markdown","6e754059":"markdown","e37489f7":"markdown"},"source":{"31904835":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","38f2b913":"data_dir = \"..\/input\/victoria-road-crash-statistics\/\"\ndata = pd.read_csv(data_dir + \"Victoria road crashes 2012-2017.csv\")","1bfade89":"data.head()","6d78ced9":"numeric_features = data[[\n    \"INJ_OR_FATAL\",\"FATALITY\",\"MALES\",\n    \"FEMALES\",\"DRIVER\",\"PEDESTRIAN\",\n    \"OLD_DRIVER\",\"YOUNG_DRIVER\" ,\"UNLICENCSED\",\n    \"HEAVYVEHICLE\",\"PASSENGERVEHICLE\",\"MOTORCYCLE\"\n]]\ncategorical_features = data[[\n    \"ACCIDENT_TIME\",\"ACCIDENT_TYPE\",\"DAY_OF_WEEK\",\n    \"DCA_CODE\",\"HIT_RUN_FLAG\",\"LIGHT_CONDITION\",\n    \"ROAD_GEOMETRY\",\"SPEED_ZONE\"\n]]","7009de46":"data[\"ALCOHOL_RELATED\"].value_counts()","33d9e1fb":"data.describe()","a5a268f5":"alchohol_related_yes = data[data[\"ALCOHOL_RELATED\"]==\"Yes\"]\nalchohol_related_yes.describe()","fee35af3":"alchohol_related_no = data[data[\"ALCOHOL_RELATED\"]==\"No\"]\nalchohol_related_no.describe()","6ef7d22a":"numeric_features.describe()","1bdbe610":"numeric_features.hist(figsize=[20, 15])\nplt.suptitle(\"Numeric feature distribution\")\nplt.show()","594a5ed7":"sns.boxplot(x=\"ALCOHOL_RELATED\",y=\"INJ_OR_FATAL\",data=data)\nplt.suptitle(\"Number of injuries BoxPlot\")\nplt.show()\nsns.boxplot(x=\"ALCOHOL_RELATED\",y=\"YOUNG_DRIVER\",data=data)\nplt.suptitle(\"Number of young drivers BoxPlot\")\nplt.show()\nsns.boxplot(x=\"ALCOHOL_RELATED\",y=\"PASSENGERVEHICLE\",data=data)\nplt.suptitle(\"Number of passengers BoxPlot\")\nplt.show()","fc39adb2":"sns.histplot(data, x=\"INJ_OR_FATAL\", hue=\"ALCOHOL_RELATED\", element=\"poly\")\nplt.suptitle(\"Probability Density Function (PDF) for the number of injuries in relation to alcohol\")\nplt.show()","95444929":"counts_related, bin_edges_related = np.histogram(alchohol_related_yes[\"INJ_OR_FATAL\"], bins=10, density = True)\npdf_related = counts_related\/(sum(bin_edges_related))\ncdf_related = np.cumsum(pdf_related)\nplt.plot(bin_edges_related[1:], pdf_related)\nplt.plot(bin_edges_related[1:], cdf_related, label = \"Yes\")\nplt.xlabel(\"INJ_OR_FATAL\")\n\ncounts_not_related, bin_edges_not_related = np.histogram(alchohol_related_no[\"INJ_OR_FATAL\"], bins=10, density = True)\npdf_not_related = counts_not_related\/(sum(counts_not_related))\ncdf_not_related = np.cumsum(pdf_not_related)\nplt.plot(bin_edges_not_related[1:], pdf_not_related)\nplt.plot(bin_edges_not_related[1:], cdf_not_related, label = \"Not Alcohl Related\")\nplt.xlabel(\"INJ_OR_FATAL\")\n\nplt.legend()\nplt.suptitle(\"CDF of the number of injuries in relation to alcohol-related crashes\")\nplt.show()","855ba9b6":"counts = categorical_features[\"ACCIDENT_TYPE\"].value_counts()\npercent100 = categorical_features[\"ACCIDENT_TYPE\"].value_counts(normalize=True).mul(100).round(1).astype(str) + \"%\"\nlight_conditions = pd.DataFrame({\"counts\": counts, \"Percent\": percent100})\nprint(\"Crashes broken by types\")\nlight_conditions","549a7680":"counts = categorical_features[\"LIGHT_CONDITION\"].value_counts()\npercent100 = categorical_features[\"LIGHT_CONDITION\"].value_counts(normalize=True).mul(100).round(1).astype(str) + \"%\"\nlight_conditions = pd.DataFrame({\"counts\": counts, \"Percent\": percent100})\nprint(\"Crashes broken by types\")\nlight_conditions","2333e4de":"counts = categorical_features[\"DAY_OF_WEEK\"].value_counts()\npercent100 = categorical_features[\"DAY_OF_WEEK\"].value_counts(normalize=True).mul(100).round(1).astype(str) + \"%\"\nacc_day = pd.DataFrame({\"counts\": counts, \"Percent\": percent100})\nprint(\"Crashes broken by weekday\")\nacc_day","bd6cdaac":"sns.set_style(\"whitegrid\")\nsns.FacetGrid(data, hue = \"ALCOHOL_RELATED\" , height = 6).map(plt.scatter,\"INJ_OR_FATAL\",\"PEDESTRIAN\").add_legend()\nplt.suptitle(\"Number of injuries versus those towards pedestrians in relation to alcohol consumption\")\nplt.show()","b1f1761f":"selected_numeric_features = data[[\"INJ_OR_FATAL\",\"MOTORCYCLE\",\"ALCOHOL_RELATED\"]]\nsns.set_style(\"whitegrid\")\nsns.pairplot(selected_numeric_features, hue = \"ALCOHOL_RELATED\", height = 5)\nplt.suptitle(\"Number of injuries vs number motorcyclists involved in crashes in relation to alcohol consumption\")\nplt.show()","483f3690":"corr =  numeric_features.corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(240, 10, n=9)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\nplt.suptitle(\"Numeric features correlation\")\nplt.show()","0b7d9524":"from sklearn.preprocessing import LabelEncoder\n\n# drop na for simplicity\ncategorical_features_clean = categorical_features.dropna()\n\ncorr =  categorical_features_clean.apply(LabelEncoder().fit_transform).corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(240, 10, n=9)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\nplt.suptitle(\"Categorial Correlations\")\nplt.show()","a96cc276":"day_vs_acc_type = pd.crosstab(index=data[\"SPEED_ZONE\"], columns=data[\"ROAD_GEOMETRY\"]) \nday_vs_acc_type.plot(kind=\"bar\", figsize=(8,8),stacked=True)\nplt.suptitle(\"Crashes on different road geometry types with different speed limits\")\nplt.show()","6b39540d":"day_vs_acc_type = pd.crosstab(index=data[\"DAY_OF_WEEK\"], columns=data[\"ACCIDENT_TYPE\"])\nday_vs_acc_type.plot(kind=\"bar\", figsize=(8,8),stacked=True)\nplt.suptitle(\"Number of crashes for each day of week broken by accident type\")\nplt.show()","990ca4ea":"time_to_injury = pd.DataFrame({\n    # just the hour of day\n    \"ACCIDENT_TIME\": data[\"ACCIDENT_TIME\"].str[:2].astype(float),\n    \"INJ_OR_FATAL\": data[\"INJ_OR_FATAL\"],\n    \"ALCOHOL_RELATED\": data[\"ALCOHOL_RELATED\"],\n})\n\ntime_to_injury[\"ACCIDENT_TIME\"].fillna(value=time_to_injury[\"ACCIDENT_TIME\"].median(), inplace=True)\n\ntime_to_injury","c4845985":"time_to_injury[\"ACCIDENT_TIME\"].value_counts().sort_values(ascending=False)","eca9cda2":"sns.histplot(data=time_to_injury, x=\"ACCIDENT_TIME\")\nplt.show()","f39b99ed":"time_to_injury[\"INJ_OR_FATAL\"].value_counts()","6e31a09a":"sns.histplot(data=time_to_injury, x=\"INJ_OR_FATAL\")\nplt.show()","38700d92":"sns.jointplot(data=time_to_injury[time_to_injury[\"INJ_OR_FATAL\"] > 10], x=\"INJ_OR_FATAL\", y=\"ACCIDENT_TIME\", \n              kind=\"kde\", fill=True, cmap=\"Blues\")\nplt.suptitle(\"Contour plot for accident time versus number of injuries\")\nplt.show()","ebedf64f":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef scale(df):\n    scaler = StandardScaler()\n    return scaler.fit_transform(df)\n\ndef screeplot(pca, standardised_values, title=\"\"):\n    y = np.std(pca.transform(standardised_values), axis=0)**2\n    x = np.arange(len(y)) + 1\n    plt.plot(x, y, \"o-\")\n    plt.xticks(x, [\"Comp.\"+str(i) for i in x], rotation=60)\n    plt.ylabel(\"Variance\")\n    if title:\n        plt.suptitle(title)\n    plt.show()\n\nX = numeric_features\nstandardisedX = scale(X)\nstandardisedX = pd.DataFrame(standardisedX, index=X.index, columns=X.columns)\nstandardisedX.apply(np.std)\n\ndim_reduction = PCA(n_components=5)\nXc = dim_reduction.fit_transform(scale(X))\n\nscreeplot(dim_reduction, standardisedX, \"The variance of different PCA components\")","43a42406":"dim_reduction = PCA(n_components=2)\nXc = dim_reduction.fit_transform(scale(numeric_features))\ncolors = [\"navy\", \"darkorange\"]\ntarget_names = [\"non-Alcohol Related\",\"Alcohol Related\"]\nlw = 2\n\ny = data[\"ALCOHOL_RELATED\"].values\ny = pd.Series(np.where(data.ALCOHOL_RELATED.values == \"Yes\", 1, 0),data.index)\nprint(y.shape)\n\nfor color, i, target_name in zip(colors, [0, 1], target_names):\n    plt.scatter(Xc[y == i, 0], Xc[y == i, 1], color=color, alpha=.8, lw=lw,label=target_name)\nplt.suptitle(\"2 PCA components to represent 12 numeric features in relation to alcohol consumption\")\nplt.show()","2e8158be":"#### 2.1.4 Cumulative Distribution Function (CDF)\n\nCDF is the probability that a corresponding continuous random variable has a value less than or equal to a given value. It gives the area under the probability density function. It is a similar concept to a cumulative frequency table, where the frequency is the amount of times a particular number or item takes place. Below is the code to generate a plot for CDF to the INJ_OR_FATAL variable. ","07adc670":"Below is the description of the selected set of categorical features:\n\n- ACCIDENT_TIME - Accident Time\n- DAY_OF_WEEK - Day of week\n- DCA_CODE - Definition for Classifying Accident. Link to DCA Chart and Sub DCA Codes https:\/\/vicroads-public.sharepoint.com\/InformationAccess\/Shared%20Documents\/Road%20Safety\/Crash\/Accident\/DCA_Chart_and_Sub_DCA_Codes.PDF\n- HIT_RUN_FLAG - Indicates whether or not the crash was a hit-run accident.\n- LIGHT_CONDITION - Indicates the light condition or level of brightness at the time of the accident.\n- ROAD_GEOMETRY - Road geometry is a character field indicates the layout of the road where the accident occurred.\n- SPEED_ZONE - Speed zone is a character field indicates the speed zone at the location of the accident. The speed zone is generally assigned to the main vehicle involved.","bcab63e6":"It can also be useful if look at these statistics for each class individually for comparison","e229d8de":"Exploratory Data Analysis (EDA) is the most critical initial step for Data Scientists to analyze a new dataset, this guide describes simple & advanced techniques using Python.\n\n**How do I get started with a Data Science\/Machine learning project?**\n\n**What is the depth and breadth of the data?**\n\n**Is the data predictive enough for modeling?**\n\nIf you\u2019re looking for answers to the above questions, then this blog is for you. In one word, the answer is Exploratory Data Analysis (**EDA**). So, what is **EDA**?\n\n**EDA** is the process of performing initial investigations on data so as to:\n\n- Uncover underlying structure & patterns in the data\n- Identify important variables\n- Identify anomalies\n- Test a hypothesis\n- Check assumptions\n- Set the stage for model development\n\nExploratory Data Analysis is like listening to what the data can tell us before we start the actual modeling process for a head start. The outcome of this analysis is some insights presented by summarised statistics and graphical representations. Also, it is a good practice though to use multiple exploratory techniques to have more confidence in the conclusions reached about the data.\n\nGenerally speaking, any method of looking at data that does not include formal statistical modeling and inference may fall under the umbrella of exploratory data analysis. In fact, EDA can be considered the most critical step in analyzing data without which you may end up with less optimal, less interpretable and less accurate models.\n\n### Sample dataset\n\nFor the purpose of explaining the various EDA techniques, we utilize the Victorian road crashes [dataset](https:\/\/vicroadsopendata-vicroadsmaps.opendata.arcgis.com\/datasets\/74dd92127eea4404b0dad1d7e39bf0e3_1\/explore?location=-36.524750%2C145.281550%2C6.96). This dataset comprises crash-related information such as the time, location, conditions, crash type, road user type, object hit, etc. during the periods between ~~2010 to 2015~~ 2012 to 2017. One reason for car crashes is drinking and driving. Thus, for simplicity, let\u2019s suggest that the target of our analysis here is to predict if a given crash was due to alcohol consumption or not. [Here](https:\/\/data.vicroads.vic.gov.au\/metadata\/Crashes_Last_Five_Years%20-%20Open%20Data.html), you will find the textual descriptions for all fields in the dataset and the data types as well. We choose Python -the most widely acceptable machine learning adopted programming language to perform the analysis.","b350d6bb":"#### Insights\n\n1. The predictive power of the numeric features can not easily define a classifying pattern of whether a crash is due to alcohol consumption or not.\n2. This suggests the need for other supporting features (e.g. categorical features)or\n    - Add more features that were previously removed and perform some more feature engineering on them\n    - Utilize external data sources. \n","022a6e54":"#### 3.1.2 Correlation matrix \n\nA correlation matrix is *\u201csquare matrix\u201d* with the same variables shown in the rows and columns. The level of correlation between the variables is highlighted with different colour intensities. The numeric values for the correlation range from- 1 *\u201cnot correlated or negatively correlated\u201d* to 1 *\u201chighly correlated\u201d*.  Among the use cases of a correlation matrix is to summarize data to a more advanced analysis.  As a result, some key decisions can be made when creating a correlation matrix. One is the choice of relevent correlation statistics and the coding of the variables. Another is the treatment of the missing data and dropping highly correlated variables from feature sets is another use case.  Below, we plot the correlation heatmap for all pairs of numeric features. ","47b80c79":"#### 2.1.3 Probability Density Function (PDF)\n\nWe will start by visualizing the PDF for a single feature. As an example, we show the PDF of the number of inquiries in relation to crashes due to alcohol consumption. Below, we plot the PDF graph for the number of injuries. The x-axis represents the value ranges while the y-axis represents the percentage of data points for each target value.","60236bc3":"#### 3.2.2 Stacked Column Chart\n\nA stacked column plot can be useful in visualizing the relationship between two categorical variables. We can compare the percentages that each category from one variable contributes to a total across categories of the second variable.  Below is a stacked plot for comparing crashes taking place on different road geometries versus speed zone limits.","1bca3d80":"#### Insights\n\n1. Almost 95% of crashes not related to alcohol consumption result in less than 5 casualties","a2a7e4a2":"## A Guided Introduction to EDA by Yassien Shaalan\n\n- Original title: A Guided Introduction to Exploratory Data Analysis (EDA) using Python\n- Author: Yassien Shaalan\n- Published on: November 28, 2019\n- Published in: Data science\n- Read the original article from this [link](https:\/\/growingdata.com.au\/a-guided-introduction-to-exploratory-data-analysis-eda-using-python\/).\n\n**Disclaimer**: This notebook was only created to reproduce the output from the original blog post. I didn't have access to the original Victoria road crash dataset (2010-2015) so I'm using a much newer one (2012-2017). **All credits goes to the original author, Yassien Shaalan.**","4ac42c0b":"#### Insights\n\n1. High correlation is noticed between DCA codes (e.g. REAR END, VEHICLE OFF FOOTPATH STRIKES VEH ON CARRIAGEWAY) and Road Geometry  which totally make sense as road geometry has a say in the crash type.  \n2. Weak correlation is seen between accident time and lighting condition","7ebeab7f":"### 3.2 Categorical Features\n\n#### 3.2.1 Correlation matrix\n\nIn order to calculate the correlation matrix for pairs of categorical features, we need first to encode the textual values into numeric ones to be able to plot it. We can do so using SciKit\u2019s *\u201cLabelEncoder\u201d* for simplicity.","a511fa3b":"We can extract the numeric and categorical features in separate data frames for easier manipulation and vizualisation.","2c632e9f":"## Conclusion\n\nWe could see that it is difficult to actually understand the dataset and make conclusions without looking through the entire data set. In fact, we have shown that spending more time exploring the dataset is well invested time. It may be a tedious preliminary step to processing data, but it is a necessary evil. However, when you begin to actually see interesting insights you will appreciate every single minute invested in such a process. EDA enables Data scientists to immediately understand key issues in the data and be able to guide deeper analysis in the right directions. Successfully exploring the data ensures to stakeholders that they won\u2019t be missing out on opportunities to leverage their data. They can easily pinpoint risks including poor data quality, unreliable, poor feature engineering, and other uncertainties. In this article, we covered a range of useful introductory data exploratory\/data analysis methods and visualization techniques. The shown EDA guidelines should allow Data scientists to have insightful and deeper understanding of the problem at hand and decide on the next move confidently.","2b545dbf":"We can see that there is huge class imbalance which is a very important observation. This has great influence on how to select instances for training and testing. It is recommended to stratify the data when randomly selecting in order to keep the same distribution of classes in training and testing sets. In some cases techniques like oversampling or undersampling may need to be used to restore class balance for better model training. Moreover, this will even have an effect on choosing the classification model and whether it can deal with class imbalance appropriately or not.   ","71206073":"#### Insights\n\n1. The most obvious change in slope in the scree plot occurs at component 2, which is the \u201celbow\u201d of the scree plot which suggests that the first two components should be enough to retain.\n\nMoreover, PCA can give great insights about how the set of features collectively collaborate to describe the analysis outcome (target). Lets convert the 12 numerical features into 2 PCA components.","588464ca":"#### Insights\n\n1. The number of injuries over 10 is less likely to be due to alcohol consumption\n2. The more the passenger cars involved in crashes don\u2019t really affirm it is due to alcohol consumption\n3. Young drivers involved in crashes alcohol-related are between 1 and 2","c78951a9":"Another example for analyzing pair of variables is for looking at the accident types and the day of week. Below,is the stacked bar chart for such analysis:","2755ff70":"### 1.1 Import libraries & load dataset","dcd50689":"### 1.2 Data sample inspection","f274d509":"Histograms can still be used to show the distribution of variables of interest. You can even plot the distributions for multiple variables concurrently. This will give you a holistic view of all variables for better understanding. Below, we show all numeric feature distributions using the histogram (barplot). The x-axis represents the given values and the y-axis represents their frequencies.","89f11e71":"#### Insights\n\n1. Very low number of injuries related to motorcyclists being involved in crashes involving alcohol consumption","c1d41a61":"#### Insights\n\n1. More crashes at T-intersections on 60 km speed zones\n2. Crashes at higher speed zones of 100 km usually occur at roads with no intersection  ","76f1ce7b":"## 2. Univariate analysis\n\nThe simplest form of statistical analysis in the EDA process is univariate analysis. Only one variable is involved in this analysis. In fact, the main purpose of the analysis is to describe, understand the population distribution, detect outliers, summarize and find patterns for a single feature. Note, that this type of analysis is different toward numeric versus categorical features in terms of the characteristics of interest of data values. \n\n### 2.1 Numeric features\n\nThe main characteristics of numeric variables are the center, spread, outliers, modality (number of peaks in the probability density function), Cumulative Distribution Function, shape (including the heaviness of the tails). \n\n#### 2.1.1 Center & Spread\n\nThe most common & useful measures of central tendency are the statistics of the arithmetic mean, median, and sometimes mode. For any symmetrically shaped distribution, the mean is the point around which the symmetry holds. On the other hand, spread refers to the variability of data. It is an indicator of how far away from the center data values are likely to be found. The spread of a distribution can be described by some known measures including variance and standard deviation. As mentioned earlier statistics like mean, median, std, and percentiles can easily be calculated by pandas as shown below:","6e584eb4":"#### Insights\n\n1. Two car collisions is the dominant accident type at all times\n2. Collision with fixed object is highest on the weekend (especially Saturday)\n3. Less pedestrians are struck on weekends","3c567ff7":"### 2.2 Categorical Features\n\nThe characteristics of interest for a categorical variable are simply the range of values and the frequency of occurrence of each value. One form of useful such univariate analysis is the tabulation of the frequencies. Usually accompanying the frequences the calculation of the fraction (or %) of data that fall in each category. We should expect that the proportions add up to 1.00 (or 100%). This can be very helpful for finding mistakes and missing data. Below are the proportions of the unique variables for the three parameters of ACCIDENT_TYPE and LIGHT_CONDITION.","b93fa76c":"#### 2.1.2 Outliers\n\nThe definition of outliers is tricky, as there is no generally recognized one formal definition for outliers. Roughly, it refers to values that are outside the areas of a distribution that would commonly occur. In addition, another common definition considers any point away from the mean by more than a fixed number of standard deviations be an \"*outlier*\". In other words, we can consider data values corresponding to areas of the population with low density or probability as suspected outliers. The Boxplot is very good at presenting statistical information such as outliers. The plot consists of a rectangular box bounded above and below by \u201chinges\u201d that represent 75% and 25% quantiles respectively. We can view the \u201cmedian\u201d as the horizontal line through the box. You can also see the upper and lower \"*whiskers*\". The vertical axis is in the units of the quantitative variable. Data points above the upper whiskers and far away are the suspected \u201coutliers\u201d. The car crash dataset may not be the best to explain this feature. However, we will include just for completeness and coverage. Below is an example of plotting boxplot for three variables of (\u201dINJ_OR_FATAL\u201d, \u201cYOUNG_DRIVER\u201d, \u201cPASSENGERVEHICLE\u201d):","8d4a60a3":"### 1.3 Target class distribution","2281d9bd":"## 3. Bi-Variate analysis\n\n**Bivariate analysis** is another step in our EDA process, where the analysis takes place between two variables (features). The main purpose of such analysis is to explore the concept of the relationship between two variables. This covers the association, strength and whether there are differences and their significance.\n\n### 3.1 Numerical features\n\n#### 3.1.1 Scatter Plot\n\nA scatter plot can be a very useful representation to visualize the relationship between two numerical variables. In fact, it is most beneficial to plot it before fitting a regression model to inspect the potential linear correlation. The resulting pattern indicates the type (linear or non-linear) and strength of the relationship between two variables. We can add more information to the 2d scatter plot. For example, we may label points in relation to crashes due to alcohol-related or not. Below is the scatter plot of the number of injuries versus the number of pedestrians.","987824e0":"The numeric features selected are described below:\n\n- INJ_OR_FATAL - Total Casualties - Total Persons Killed or Injured\n- FATALITY - Number of persons killed in the crash.\n- MALES - Total males involved in the crash.\n- FEMALES - Total females involved in the crash.\n- DRIVER - Number of drivers involved in the crash.\n- PEDESTRIAN - Number of Vehicle pedestrians involved in the crash.\n- OLD_DRIVER - Number of 65 years and older drivers involved in the crash.\n- YOUNG_DRIVER - Number of 18-25 year old young drivers involved in the crash.\n- UNLICENSED - Unlicensed Drivers(road_user_type= driver & License Type =7 OR License Status< \/> 9 and V Valid and Not Applicable)\n- HEAVYVEHICLE - Number of heavy vehicles involved in the crash.\n- PASSENGERVEHICLE - Number of passenger vehicles involved in the crash.\n- MOTORCYCLE - Number of motorcycles involved in the crash.","43ae2c17":"## 4. Multivariate Analysis\n\nIn the process of EDA, sometimes, the inspection of single or pairs of variables won\u2019t suffice to rule out certain hypothesis (or outliers & anomalous cases) from your dataset. That\u2019s why multivariate analysis come in play. This type of analysis generally shows the relationship between two or more variables using some statistical techniques.  There comes the need for taking in consideration more variables at a time during analysis to reveal more insights in your data.\n\n### 4.1 Contour Plot\n\nA contour line or isoline of a function of two variables is a curve along which the function has a constant value. It is a cross-section of the three-dimensional graph of the function f(x, y) parallel to the x, y plane. Lets plot this graph between the number of injuries and the time of day crashes took place. The features in this dataset may not be the best to show the best visualization for such plot, but for completeness we will include it.","c4ad3f6b":"### 4.2 Principal Component Analysis (PCA)\n\nPCA is a statistical data transformation procedure. It employs an orthogonal transformation to convert a set of observations of correlated variables into a set of values of linearly uncorrelated variables called principal components. It is a very common way of speeding up a machine learning algorithm is which reduces the dimensionality of input features which more often is a reasonable choice. In fact, it can completely restructure the data, removing redundancies and ordering newly obtained components according to the amount of the original variance that they express. Lets reduce the 12 numerical features to 5 components to investigate whether we can capture most of the variation between samples using a smaller number of new variables. First, we need to standardize the variables under study using the scale() function which is necessary if the input variables have very different variances. Then, we perform the principal component analysis. In order to decide how many principal components should be retained, it is common to summarize the results by making by plotting the components against the variance as shown below.","a229b48e":"## 1. Understanding the Dataset\n\nThe first step of EDA is to understand how big the data is? how many features do we have? what is the outcome of our analysis? The crash dataset comprises of 74,908 observations described by 65 features. One is the dependent variable (target class) and the rest 64 are independent variables. The data types available in this dataset are floats (4), integers (27 features) and string (text) (32 features) which can be divided into free text-based features -out of the scope of this post- or categorical features. Numeric features refer to any feature with any form of numeric values (float, integer, double, long, etc). Categorical features refer to variables that can take on one of a limited, and usually fixed number of possible values. The floating values features are all co-ordinates values referring to the crash location. For simplicity, we chose only 12 numeric features and 8 categorical features; in fact, you can perform the analysis on features of choice and you may end up selecting a different set of features. ","d95f0df7":"#### Insights\n\n1. High correlation exists between number of males involved in the crash and the number of injuries\n2. Higher correlation is witnessed between number of young drivers involved in the crash and number of drivers. \n3. Weak correlation exists between number of motorcycles and number of passenger vehicles","3a5ed8de":"### 1.4 Primary statistics\n\nInterestingly, you can use the describe function from Pandas to print useful statistics such as count, mean, std, min, max, 25%,50% & 75% percentiles values for each column. For non-numeric features, these values may seem meaningless.","8a86cfe9":"#### Insights \n\n1. It is highly likely that crashes due to alcohol consumption results in more casualties\n2. Very limited overlapping is observed between the two PDFs, which tells us that the number of casualties are visually different in relation to alcohol consumption","c4909b21":"#### Insights\n\n1. The majority of crashes 63% occur due to collision with other moving vehicles while only 8% striking pedestrians.\n2. 65% of accidents take place during the day time and only 5% take place in streets with no light.\n3. Crashes on the weekend are lower than on weekdays while percentages get higher closer to the end of the week.\n","6e754059":"#### Insights\n\n1. The higher number of pedestrians being injured is not due to crashes involving alcohol consumption\n\nMoreover, we can plot pairs of variables for a better understanding of variables associations. Below, we plot the pair association for the number of injuries against the number of motorcyclists involved in the crash.","e37489f7":"#### Insights\n\n1. The darkest area or the highest in density in the context of this plot means the highest number of injuries take place in the afternoon around the times from 3 pm to to 8 pm.\n\nThis plot can also be visualized in 3D where it will show hill like structure where hill top has maximum density of point and density decreases as hill slope getting decreases."}}