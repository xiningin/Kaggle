{"cell_type":{"50195f50":"code","9ae24c60":"code","bc228a15":"code","0bcb63eb":"code","9d72c7e6":"code","40132979":"code","cc54d3af":"code","48bbf544":"code","daefee6a":"code","58d36809":"code","6c55ce6b":"code","4550f4f9":"code","ee0c229d":"code","97108d72":"code","49d80c23":"code","9192db5b":"code","29a7f240":"code","dc43c0ea":"code","3b99087d":"code","4d9174d5":"code","99e27354":"code","66d79c00":"code","b1518a3d":"markdown","4425615c":"markdown"},"source":{"50195f50":"!pip install pdfminer.six","9ae24c60":"!pip install PyPDF2","bc228a15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom wand.image import Image as Img\nimport io\nimport subprocess\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.pdfinterp import PDFPageInterpreter\nfrom pdfminer.pdfinterp import PDFResourceManager\nfrom pdfminer.pdfpage import PDFPage\nfrom tqdm import tqdm\nimport PyPDF2\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/cvpr2019\/CVPR2019\/\"))\n\n# Any results you write to the current directory are saved as output.","0bcb63eb":"Img(filename=\"..\/input\/cvpr2019\/CVPR2019\/papers\/Acuna_Devil_Is_in_the_Edges_Learning_Semantic_Boundaries_From_Noisy_CVPR_2019_paper.pdf\", resolution=300)","9d72c7e6":"!pdf2txt.py -o health.txt ..\/input\/cvpr2019\/CVPR2019\/papers\/Acuna_Devil_Is_in_the_Edges_Learning_Semantic_Boundaries_From_Noisy_CVPR_2019_paper.pdf","40132979":"pdfTxtFile = 'health.txt'\npdf_txt = open(pdfTxtFile, 'r', encoding='utf-8')\nstrn = ''\n# loop over all the lines\nfor line in pdf_txt:\n    strn += line","cc54d3af":"print(strn)","48bbf544":"!rm health.txt","daefee6a":"pdfFileObj = open(\"..\/input\/cvpr2019\/CVPR2019\/papers\/Acuna_Devil_Is_in_the_Edges_Learning_Semantic_Boundaries_From_Noisy_CVPR_2019_paper.pdf\", 'rb')\npdfReader = PyPDF2.PdfFileReader(pdfFileObj)","58d36809":"print(pdfReader.numPages)","6c55ce6b":"pageObj = pdfReader.getPage(0)\n# extracting text from page.\n# this will print the text you can also save that into String\nprint(pageObj.extractText())","4550f4f9":"pdfReader.getDocumentInfo()","ee0c229d":"pdfTxtFile = '..\/input\/cvpr2019\/CVPR2019\/abstracts\/Acuna_Devil_Is_in_the_Edges_Learning_Semantic_Boundaries_From_Noisy_CVPR_2019_paper.txt'\npdf_txt = open(pdfTxtFile, 'r', encoding='utf-8')\n\n# loop over all the lines\nfor line in pdf_txt:\n    print(repr(line))","97108d72":"papers = os.listdir('..\/input\/cvpr2019\/CVPR2019\/papers\/')","49d80c23":"data_dict = {'content': [], 'abstract': [], 'authors':[], 'title':[]}","9192db5b":"def pdf_to_text(path):\n    bashCommand = \"pdf2txt.py -o pap.txt \" + path\n    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n    output, error = process.communicate()\n    pdfTxtFile = 'pap.txt'\n    pdf_txt = open(pdfTxtFile, 'r', encoding='utf-8')\n    strn = ''\n    # loop over all the lines\n    for line in pdf_txt:\n        strn += line\n    return strn","29a7f240":"def read_txt(path):\n    abs_text = open(path, 'r', encoding='utf-8')\n    strn = ''\n    # loop over all the lines\n    for line in abs_text:\n        strn += line\n    return strn","dc43c0ea":"def read_a_paper(name):\n    if os.path.exists('..\/input\/cvpr2019\/CVPR2019\/abstracts\/' + name.split('.')[0] + '.txt'):\n        data_dict['content'].append(pdf_to_text('..\/input\/cvpr2019\/CVPR2019\/papers\/' + name))\n        data_dict['abstract'].append(read_txt('..\/input\/cvpr2019\/CVPR2019\/abstracts\/' + name.split('.')[0] + '.txt'))\n        pdfFileObj = open('..\/input\/cvpr2019\/CVPR2019\/papers\/' + name, 'rb')\n        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n        pdf_meta = pdfReader.getDocumentInfo()\n        data_dict['title'].append(pdf_meta['\/Title'])\n        data_dict['authors'].append(pdf_meta['\/Author'])","3b99087d":"for paper in tqdm(papers):\n    read_a_paper(paper)","4d9174d5":"len(data_dict['content'])","99e27354":"df = pd.DataFrame(data_dict)","66d79c00":"df.to_csv('cvpr2019.csv')","b1518a3d":"## Introduction\n**CVPR is the premier annual computer vision event comprising the main conference and several co-located workshops and short courses. With its high quality and low cost, it provides an exceptional value for students, academics and industry researchers.**\n\n\n<img src=\"http:\/\/cvpr2019.thecvf.com\/images\/CVPRLogo.png\"\n     alt=\"Markdown Monster icon\"\n     style=\"float: left; margin-right: 10px;\" \/>\n\n\nCVPR is one of the best conferences in machine learning and deep learning. The **CVPR 2019 Papers** contains all the paper presented in CVPR 2019. Now, I'll process and analyse the data throughly. But first our challenge is to get the data in a desired format. Currently, the is in PDF format and hence unsuitable for through analysis. Hence, In this kernel, I'll convert this pdf data set to desirable csv format for further processing. I analyse, clean and process the data in [Data cleaning, Data Processing & Data Analysis](https:\/\/www.kaggle.com\/hsankesara\/data-cleaning-data-processing-data-analysis). Check it out and leave your feedback.\n\n**Note:** I'm only intending to do text analysis and hence will not try to extract images or tables.","4425615c":"## Data Reading"}}