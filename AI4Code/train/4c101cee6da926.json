{"cell_type":{"c47ef5a9":"code","a2aa94a3":"code","07b91700":"code","6a3e499a":"code","103e5132":"code","32d7a3ba":"code","0b23b83c":"code","a7bddb8e":"code","4b4e841e":"code","9ac97c1c":"code","e6d8d42b":"code","5ecea698":"code","3d2c4f4b":"code","cc7b8aed":"code","f0ed152c":"code","30eb7e1c":"code","e4afdd33":"code","136945c6":"code","bdd38b55":"code","c491b96c":"code","12356125":"code","2cfef5cd":"code","c824df87":"markdown","83c8b14a":"markdown","14bdeb4f":"markdown","8365ea3f":"markdown"},"source":{"c47ef5a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a2aa94a3":"games = pd.read_csv('..\/input\/games.csv')\ngames.head()","07b91700":"print (games.shape)","6a3e499a":"# Target variable is Average Rating. So let us explore its variation.\nplt.hist(games['average_rating'])\nplt.xlabel('Average Rating')\nplt.ylabel('Frequency')","103e5132":"games.describe()","32d7a3ba":"# For a game with zero average rating, there are no users rated. \ngames[games['average_rating']==0].iloc[0]","0b23b83c":"# For a game with average rating >0, user have rated game. \ngames[games['average_rating']>0].iloc[0]","a7bddb8e":"games_cleaned = games[games['users_rated']>0]\ngames_cleaned = games_cleaned[games_cleaned['yearpublished']>1900]\ngames_cleaned = games_cleaned[games_cleaned['maxplaytime']<500]\n\n# Drop any row with no data\ngames_cleaned = games_cleaned.dropna(axis=0)","4b4e841e":"games_cleaned.describe()","9ac97c1c":"print (\"Percentage data filtered {:.2f}\".format((games.shape[0]-games_cleaned.shape[0])\/games.shape[0]*100)) # This is quite significant. ","e6d8d42b":"games_cleaned.corr()[\"average_rating\"]","5ecea698":"sns.pairplot(games_cleaned[['total_comments','yearpublished','playingtime','total_owners','minage','average_rating']])","3d2c4f4b":"df_year_mean  = games_cleaned.groupby(['yearpublished']).mean()\ndf_year_mean.reset_index(inplace=True)","cc7b8aed":"df_year_mean.head()","f0ed152c":"df_year_mean.plot.scatter('yearpublished','average_rating',alpha=0.6,sizes=(10, 100))\nplt.xlabel('Year Published')\nplt.ylabel('Mean Rating')","30eb7e1c":"y = games_cleaned['average_rating']\nX = games_cleaned.drop(['average_rating','type','name','id','bayes_average_rating'],axis=1)","e4afdd33":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=42)","136945c6":"print(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Validation set has {} samples.\".format(X_val.shape[0]))","bdd38b55":"# Linear Regression\nimport math\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nLinModel = LinearRegression()\nLinModel.fit(X_train,y_train)\ny_pred = LinModel.predict(X_val)\n\nerror = math.sqrt(mean_squared_error(y_pred,y_val))\nprint (f'Root mean squared error is {error}')\n\nprint ('Coefficients of the linear model are',LinModel.coef_)\nprint('Intercept of the model is',LinModel.intercept_)","c491b96c":"def report_coef(names,coef,intercept):\n    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n    r = r.sort_values(by=['coef'])\n    display(r)\n    print(\"Intercept: {}\".format(intercept))\n    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))\n    \ncolumn_names = X_train.columns.tolist()\nreport_coef(\n  column_names,\n  LinModel.coef_,\n  LinModel.intercept_)","12356125":"from sklearn.ensemble import RandomForestRegressor\nRF_model = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=1)\nRF_model.fit(X_train, y_train)\nRF_predictions = RF_model.predict(X_val)\nmean_squared_error(RF_predictions, y_val)","2cfef5cd":"import lightgbm as lgb\ntrain_data = lgb.Dataset(X_train,label=y_train)\ntest_data = lgb.Dataset(X_val,label=y_val)\nparam = {'num_leaves':131, 'num_trees':100, 'objective':'regression','metric':'rmse'}\nnum_round = 1000\nbst = lgb.train(param, train_data, num_round, valid_sets=[test_data])","c824df87":"**Some interesting observations**\n\n* Age : Very few people older than 50, play board games\n* Average rating: Right skewed distribution\n* Total number of comments and total number of owners are proportional which is expected.\n* More and more games are published yearly. Nearly with exponential rize. ","83c8b14a":"**Data Cleanup**\n\nFrom description of data it can be noted that there is data with negative years and very large play time. Let us filter out the data with negative year published, large playtime, and games with no ratings. ","14bdeb4f":"1. Average rating is closely correlated average weight and ids. Id probably due to age of the id created in the database of the games. Columns 'Bayes Average Rating' (~average rating), board game type and name are dropped from the features.","8365ea3f":"![](https:\/\/images.pexels.com\/photos\/776654\/pexels-photo-776654.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=1650)"}}