{"cell_type":{"55d6921e":"code","6778e438":"code","ffaab701":"code","a8c065c7":"code","66d3936c":"code","24d622bd":"code","6cf37b38":"code","eb5418c8":"code","14afa4f8":"code","61528dc4":"code","4922c027":"code","eca26bb2":"code","b1e3a575":"code","541c72dd":"code","585354c1":"code","ddbdfc47":"code","cece81a8":"code","182da63e":"code","491a7b33":"code","a91d04b2":"code","295f0a82":"code","aa50ff63":"code","8d436724":"code","ff7fefa4":"markdown","4467aea9":"markdown","9f61a1ac":"markdown","c0ca8126":"markdown","cc23cc5b":"markdown"},"source":{"55d6921e":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os","6778e438":"def load_data(path):\n    with np.load(path) as f:\n        x_train, y_train = f['x_train'], f['y_train']\n        x_test, y_test = f['x_test'], f['y_test']\n        return (x_train, y_train), (x_test, y_test)","ffaab701":"input_img = tf.keras.layers.Input(shape=(28, 28, 1)) # adapt this if using `channels_first` image data format\n\nx = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\nx = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(x)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\ndecoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = tf.keras.models.Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","a8c065c7":"# to train this model we will with original MNIST digits with shape (samples, 3, 28, 28) and we will just normalize pixel values between 0 and 1\n(x_train, _), (x_test, _) = load_data('..\/input\/mnist.npz')\n\nprint(x_train.shape)","66d3936c":"x_train = x_train.astype('float32') \/ 255.\nx_test = x_test.astype('float32') \/ 255.\nx_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\nx_test = np.reshape(x_test, (len(x_test), 28, 28, 1))","24d622bd":"#%load_ext tensorboard.note\n#%tensorboard --logdir .\/tmp\/autoencoder","6cf37b38":"autoencoder.fit(x_train, x_train, epochs=50, batch_size=128, shuffle=True, validation_data=(x_test, x_test), callbacks=[tf.keras.callbacks.TensorBoard(log_dir='.\/tmp\/autoencoder')])","eb5418c8":"decoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n","14afa4f8":" # we can also look at the 128-dimensional encoded representations. These representations are 8x4x4, so we reshape them to 4x32 in order to be able to display them as grayscale images\n \nn = 10\nencoder = tf.keras.models.Model(input_img, encoded)\nencoded_imgs = encoder.predict(x_test)\nplt.figure(figsize=(20, 8))\nfor i in range(n):\n     ax = plt.subplot(1, n, i + 1)\n     plt.imshow(encoded_imgs[i + 1].reshape(4, 4 * 8).T)\n     plt.gray()\n     ax.get_xaxis().set_visible(False)\n     ax.get_yaxis().set_visible(False)\nplt.show()","61528dc4":"# helper functions\n\n# reparameterization trick\n# instead of sampling from Q(z|X), sample eps = N(0,I)\n# z = z_mean + sqrt(var)*eps\ndef sampling(args):\n    z_mean, z_log_var = args\n    batch = tf.keras.backend.shape(z_mean)[0]\n    dim = tf.keras.backend.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n    \n    \ndef plot_results(models, data, batch_size=128, model_name=\"vae_mnist\"):\n    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n    # Arguments:\n        models (tuple): encoder and decoder models\n        data (tuple): test data and label\n        batch_size (int): prediction batch size\n        model_name (string): which model is using this function\n    \"\"\"\n\n    encoder, decoder = models\n    x_test, y_test = data\n    os.makedirs(model_name, exist_ok=True)\n\n    filename = os.path.join(model_name, \"vae_mean.png\")\n    # display a 2D plot of the digit classes in the latent space\n    z_mean, _, _ = encoder.predict(x_test,\n                                   batch_size=batch_size)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n    plt.colorbar()\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.savefig(filename)\n    plt.show()\n\n    filename = os.path.join(model_name, \"digits_over_latent.png\")\n    # display a 30x30 2D manifold of digits\n    n = 30\n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-4, 4, n)\n    grid_y = np.linspace(-4, 4, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            figure[i * digit_size: (i + 1) * digit_size,\n                   j * digit_size: (j + 1) * digit_size] = digit\n\n    plt.figure(figsize=(10, 10))\n    start_range = digit_size \/\/ 2\n    end_range = n * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.imshow(figure, cmap='Greys_r')\n    plt.savefig(filename)\n    plt.show()","4922c027":"#Import and preprocess DENSE\n(x_train, y_train), (x_test, y_test) = load_data('..\/input\/mnist.npz')\n\nimage_size = x_train.shape[1]\noriginal_dim = image_size * image_size\nx_train = np.reshape(x_train, [-1, original_dim])\nx_test = np.reshape(x_test, [-1, original_dim])\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255","eca26bb2":"#Network parameters DENSE\ninput_shape = (original_dim, )\nintermediate_dim = 512\nbatch_size = 128\nlatent_dim = 2\nepochs = 50","b1e3a575":"# build encoder model DENSE\ninputs = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\nx = tf.keras.layers.Dense(intermediate_dim, activation='relu')(inputs)\nz_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(x)\nz_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\nz = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = tf.keras.models.Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\n# tf.keras.utils.plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n\n# build decoder model\nlatent_inputs = tf.keras.layers.Input(shape=(latent_dim,), name='z_sampling')\nx = tf.keras.layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\noutputs = tf.keras.layers.Dense(original_dim, activation='sigmoid')(x)\n\n# instantiate decoder model\ndecoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\n# tf.keras.utils.plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n\n# instantiate VAE model\noutputs = decoder(encoder(inputs)[2])\nvae = tf.keras.models.Model(inputs, outputs, name='vae_mlp')\n\nmodels = (encoder, decoder)\ndata = (x_test, y_test)\n# reconstruction_loss = tf.keras.losses.mse(inputs, outputs)\nreconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, outputs)\n\nreconstruction_loss *= original_dim\n\nkl_loss = 1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var)\nkl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\nkl_loss *= -0.5\nvae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\nvae.add_loss(vae_loss)\nvae.compile(optimizer='adam')\nvae.summary()\n# tf.keras.utils.plot_model(vae, to_file='vae_mlp.png', show_shapes=True)","541c72dd":"vae.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))\nvae.save_weights('vae_mlp.mnist.h5')","585354c1":"# Because the VAE is a generative model, we can also use it to generate new digits! Here we will scan the latent plane, sampling latent points at regular intervals and generating the corresponding digit for each of these points. This gives us a visualization of the latent manifold that \"generates\" the MNIST digits.\nplot_results(models, data, batch_size=batch_size, model_name='vae_mlp')","ddbdfc47":"# helper functions\n\n# reparameterization trick\n# instead of sampling from Q(z|X), sample eps = N(0,I)\n# z = z_mean + sqrt(var)*eps\ndef sampling(args):\n    z_mean, z_log_var = args\n    batch = tf.keras.backend.shape(z_mean)[0]\n    dim = tf.keras.backend.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n    \n    \ndef plot_results(models, data, batch_size=128, model_name=\"vae_mnist\"):\n    \n    from IPython.display import FileLink\n\n    encoder, decoder = models\n    x_test, y_test = data\n    os.makedirs(model_name, exist_ok=True)\n\n    filename = os.path.join(model_name, \"vae_mean.png\")\n    FileLink(filename)\n    \n    # display a 2D plot of the digit classes in the latent space\n    z_mean, _, _ = encoder.predict(x_test,\n                                   batch_size=batch_size)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n    plt.colorbar()\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.show()\n    plt.savefig(filename)\n    \n    filename = os.path.join(model_name, \"digits_over_latent.png\")\n    FileLink(filename)\n    # display a 30x30 2D manifold of digits\n    n = 30\n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-2, 2, n)\n    grid_y = np.linspace(-2, 2, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            figure[i * digit_size: (i + 1) * digit_size,\n                   j * digit_size: (j + 1) * digit_size] = digit\n\n    plt.figure(figsize=(10, 10))\n    start_range = digit_size \/\/ 2\n    end_range = n * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.imshow(figure, cmap='Greys_r')\n    plt.savefig(filename)\n    plt.show()","cece81a8":"#Import and preprocess CONVOLUTIONAL\n(x_train, y_train), (x_test, y_test) = load_data('..\/input\/mnist.npz')\n\n\nimage_size = x_train.shape[1]\n#original_dim = image_size * image_size\nx_train = np.reshape(x_train, [-1,  image_size, image_size, 1])\nx_test = np.reshape(x_test, [-1,  image_size, image_size, 1])\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\n\n# Binarization\nx_train[x_train >= .5] = 1.\nx_train[x_train < .5] = 0.\nx_test[x_test >= .5] = 1.\nx_test[x_test < .5] = 0.\n\nprint(x_train.shape)\nprint(y_train.shape)","182da63e":"#Network parameters CONVOLUTIONAL\ninput_shape = (image_size, image_size, 1)\nbatch_size = 256\nlayers_number = 2\nkernel_size = 3\nfilters = 32\nlatent_dim = 2\ndense_density = 128\nkl_weight = -0.75\nepochs = 100\nopt = tf.keras.optimizers.Adam(lr=0.0015)\nload_weights = False","491a7b33":"#Encoder CONVOLUTIONAL\ninputs = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\nx = inputs\nfor i in range(layers_number):\n    filters *= 2\n    x = tf.keras.layers.Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               activation='relu',\n               strides=2,\n               padding='same')(x)\n\n# shape info needed to build decoder model\nshape = tf.keras.backend.int_shape(x)\n\n# generate latent vector Q(z|X)\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(dense_density , activation='relu')(x)\nz_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(x)\nz_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = tf.keras.models.Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()","a91d04b2":"#Decoder CONVOLUTIONAL\nlatent_inputs = tf.keras.layers.Input(shape=(latent_dim,), name='z_sampling')\nx = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\nx = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n\n# use Conv2DTranspose to reverse the conv layers from the encoder\nfor i in range(layers_number):\n    x = tf.keras.layers.Conv2DTranspose(filters=filters,\n                                        kernel_size=kernel_size,\n                                        activation='relu',\n                                        strides=2,\n                                        padding='same')(x)\n    filters \/\/= 2\n\noutputs = tf.keras.layers.Conv2DTranspose(filters=1,\n                                          kernel_size=kernel_size,\n                                          activation='sigmoid',\n                                          padding='same',\n                                          name='decoder_output')(x)\n\n# instantiate decoder model\ndecoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()","295f0a82":"#VAE model CONVOLUTIONAL\noutputs = decoder(encoder(inputs)[2])\nvae = tf.keras.models.Model(inputs, outputs, name='vae')\n\n#Loss = reconstruction + KL loss\nreconstruction_loss = tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(inputs), tf.keras.backend.flatten(outputs))\nreconstruction_loss *= image_size * image_size\n\nkl_loss = 1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var)\nkl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\nkl_loss *= kl_weight\n\nvae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\nvae.add_loss(vae_loss)\n#vae.compile(optimizer='rmsprop')\n#vae.compile(optimizer='adam')\nvae.compile(optimizer=opt)\nvae.summary()","aa50ff63":"#Fit model CONVOLUTIONAL\nif load_weights:\n    vae = vae.load_weights(args.weights)\nelse:\n    # train the autoencoder\n    vae.fit(x_train,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(x_test, None))\n    vae.save_weights('vae_cnn_mnist.h5')","8d436724":"#plot\nmodels = (encoder, decoder)\ndata = (x_test, y_test)\nplot_results(models, data, batch_size=batch_size, model_name='vae_cnn')","ff7fefa4":"**Variational Autoencoder (VAE)**\n\nVariational autoencoders are a slightly more modern and interesting take on autoencoding. It's a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you an generate new input data samples. VAE is a generative model.\n\n**How does it work?**\nFirst, an encoder network turns the input samples `x` into two parameters in a latent space, which we will note as `z_mean` and `z_log_sigma`. Then we randomly sample similar points `z` from the latent normal distribution that is assumed to generate the data, via `z = z_mean + exp(x_log_sigma) * epsilon`, where `epsilon` is a random normal tensor. Finally, a deocded network maps these latent space points back to the original input data.\n\nThe parameters of the model are trained via two loss functions: a reconstriction loss forcing the decoded samples to match the initial inputs (just like in our previous autoencoders), and the KL divergence between the learned latent distribution and the prior distribution, acting as a regulaization term. You could actually get rid of this latter term entirely, although it does help in learning well-formed latent spaces and reducing overfitting to the training data.","4467aea9":"**DENSE**","9f61a1ac":"**Importing some libraries**","c0ca8126":"**CONVOLUTIONAL**","cc23cc5b":"**Convolutional beauty**"}}