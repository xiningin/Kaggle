{"cell_type":{"95644590":"code","aa32ac29":"code","2b5ab6de":"code","1bf3c9c1":"code","c8df0647":"code","2a6d1694":"code","49895582":"code","26d8a7bb":"code","a0a6d56c":"code","3a616dcb":"markdown","345c276b":"markdown","6b9bc8ef":"markdown","034ec09b":"markdown","768e682a":"markdown","951cb09b":"markdown","64b8b499":"markdown","857e44f3":"markdown","f185f970":"markdown","6dcc5b2a":"markdown","368a479b":"markdown"},"source":{"95644590":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        df = os.path.join(dirname, filename)\n        print(df)\n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa32ac29":"breast_cancer_df =  pd.read_csv(df, usecols=[i for i in range(0, 32)],encoding='latin-1')  # costruisco il dataframe\nbreast_cancer_df.head(10) # stampa delle prime 10 righe del dataframe","2b5ab6de":"X = breast_cancer_df.drop(\"diagnosis\",axis=1).values # data set\ny = breast_cancer_df[\"diagnosis\"].values # features","1bf3c9c1":"y[y == 'B'] = 0 # benigno\ny[y == 'M'] = 1 # maligno","c8df0647":"X_training = X[:512] # training set\nX_validation = X[512:] # validation set\ny_training = y[:512] # training features\ny_validation = y[512:] # validation features","2a6d1694":"X_max = X_training.max(axis=0) # ritorna l'elemento piu' grande\nX_min = X_training.min(axis=0) # ritorna l'elemento piu' piccolo\n\nX_training = (X_training - X_min) \/ (X_max - X_min) # normalizzazione dei trainig set\nX_validation = (X_validation - X_min) \/ (X_max - X_min) # normalizzazione dei validation set","49895582":"import numpy as np\nclass NeuralNetwork:\n    \n# costruttore con il numero di neuroni dello strato nascosto\n    def __init__(self, hidden_layer_neurons=100): \n        self.hidden_layer_neurons=hidden_layer_neurons\n\n    \n# inizializzazione dei pesi della rete\n    def init_weights(self, input_size, hidden_neurons): # dimensione dell'input e taglia dello strato nascosto\n        self._w1 = np.random.randn(input_size, hidden_neurons) # arrai dei pesi [input_size * hidden_neurons]\n        self._b1 = np.zeros(hidden_neurons) # array bias\n        self._w2 = np.random.randn(hidden_neurons,1) # dimesione dello strato di output, ha un solo neurone\n        self._b2 = np.zeros(1) # array bias\n    \n# metodo per calcolare l'accuratezza della predizione\n    def accuracy(self, y_expected, y_prediction):  \n        return np.sum(y_expected==y_prediction)\/len(y_expected) # rapporto tra quanto atteso e quanto predetto\n    # sum mi permette di fare la vettorizzazione: creo un vettore che contiene 1 nelle posizioni ove y_expected e y_prediction coincidono; 0 altrimenti.\n    # dopodiche' sum fa la somma di tutti i valori all'interno del vettore\n    # al termine si divide per il numero di esempi\n    \n# metodo di costo (a supporto dell'accuracy)\n    def log_loss(self, y_expected, y_probability):\n        # uso i parametri y_expected per indicare i valori reali attesi dal modello, e y_probability per indicare la probabilita' di appartenenza alla classe positiva\n        return - np.sum(np.multiply(y_expected,np.log(y_probability.astype('float64')))+np.multiply((1-y_expected),np.log(1-y_probability.astype('float64'))))\/len(y_expected)\n\n### predizione:\n# funzione di attivazione: calcolata sugli strati nascosti\n    def relu(self, input_x):\n        return np.maximum(0, input_x)\n\n# funzione sigmoide: calcolata sugli strati di output\n    def sigmoid(self, y):\n        return 1\/(1+np.power(np.e,-y))\n\n# metodo di forwar_propagation\n    def forward_propagation(self, X):\n                     \n        z1 = np.dot(X,self._w1)+self._b1\n        o1 = self.relu(z1)\n        z2 = np.dot(o1,self._w2)+self._b2\n        o2 = self.sigmoid(z2)\n    \n        self.forward_cache = (z1, o1, z2, o2) # memorizzo i valori nella cache\n        return o2.ravel() # l'output finale della rete lo converto in una dimensione\n    \n # metodo di previsione: classifico\n    def prediction(self, X, yes_probabiliy): # yes_propability flag di utlita'\n        y_probability = self.forward_propagation(X) # il calcolo della probabilita' viene fatto nello strato di output, durante l'esecuzione della forward_propagation\n        y = np.zeros(X.shape[0], dtype=int)\n        y[y_probability>=0.5]=1\n        y[y_probability<0.5]=0\n        if(yes_probabiliy):\n            return (y, y_probability) # faccio ritornare sia il risultato della classificazione che la probabilita' originata dalla forward propagation \n        return y_probablity # faccio ritornare solo la probabilita'\n\n### addestramento\n # metodo di discesa del gradiente\n    def train_with_gradient_descendent(self, X, y, epochs=200, learning_rate=0.04):\n     \n        self.init_weights(X.shape[1], self.hidden_layer_neurons) # inizializzazione dei pesi del modello\n      \n    # metodo di discesa stocastica del gradiente: gradiente di un singolo training point scelto casualmente\n        for _ in range(epochs): # ciclo per n epochs\n            Y = self.forward_propagation(X) # preparo la rete\n            des_w1, des_b1, des_w2, des_b2 = self.back_propagation(X, y) # metodo che calcola le derivate parziali della funzione di costo\n            # setto correttamente i coefficienti della funzioni di costo che voglio minimizzare durante il training\n            self._w1 = self._w1-learning_rate*des_w1\n            self._b1 = self._b1-learning_rate*des_b1\n            self._w2 = self._w2-learning_rate*des_w2\n            self._b2 = self._b2-learning_rate*des_b2\n        \n# metodi di utilita' per back_propagation \n    def relu_derivative(self, Z):\n        dZ = np.zeros(Z.shape)\n        dZ[Z>0] = 1\n        return dZ\n\n# metodo che calcola le derivate parziali\n    def back_propagation(self, X, y):\n  \n        z1, o1, z2, o2 = self.forward_cache\n                   \n        m = o1.shape[1]\n    \n        # applico al chain rule\n        dZ2 = o2-y.reshape(-1,1) # reshape mi serve per far combiaciare la dimensione dei due vettori\n        dW2 = np.dot(o1.T, dZ2)\/m\n        dB2 = np.sum(dZ2, axis=0)\/m\n        dZ1 = np.dot(dZ2, self._w2.T)*self.relu_derivative(z1)\n        dW1 = np.dot(X.T, dZ1)\/m\n        dB1 = np.sum(dZ1, axis=0)\/m\n    \n        return dW1, dB1, dW2, dB2\n           \n# metodo di utilita' che esegue le predizioni, calcola le metriche e le ritorna          \n    def evaluate_output_net(self, X, y):\n        y_prediction, y_probability = self.prediction(X, yes_probabiliy=True)\n        accuracy = self.accuracy(y, y_prediction)\n        log_loss = self.log_loss(y, y_probability)\n        return (accuracy, log_loss, y_prediction)","26d8a7bb":"net = NeuralNetwork()\n# addestramento della Rete Neurale\nnet.train_with_gradient_descendent(X_training, y_training)\n# previsione della Rete Neurale\nprint(\"Risultati attesi dalla previsione della Rete Neurale:\")\nprint(y_validation)\naccuracy, log_loss, y_prediction = net.evaluate_output_net(X_validation, y_validation)\nprint(\"Previone della Rete Neurale:\") \nprint(y_prediction)\nprint(\"La previsione ha un'accuratezza di: \", round(accuracy* 100), \"%\")\nprint(\"La previsiona ha una perdita con probabilita' del: \", round(log_loss* 100), \"%\")","a0a6d56c":"import matplotlib.pyplot as plt # plot\n# disegno plot\n\nplt.rcParams['figure.figsize'] = [10, 5] # ridimensiono l'area di stampa del plot\n\nplt.xlabel('test')\nplt.ylabel('result test')\nplt.plot(range (512,569), y_validation, 'r--', color='red')\nplt.plot(range (512,569), y_prediction, 'o', color='purple')\nplt.legend(['valori reali esatti','valori predetti'], numpoints=1)\nplt.show()","3a616dcb":"<h1>Implementazione della classe NeuralNetwork<\/h1>","345c276b":"Sistemo le features per la classificazione: 0 se il il tumore e' benigno (B), altrimenti 1 se e' maligno (M).","6b9bc8ef":"Di seguito realizzo una Rete Neurale che ha come scopo quello di prevedere se il tumore al seno di una paziente e' benigno o maligno.","034ec09b":"<h1>Creazione del set di training e validation<\/h1>","768e682a":"Costruisco una classe `NeuralNetwork`, composta dai seguenti metodi:\n- ` __init__`: costruttore che contiene il numero di neuroni (`hidden_layer_neurons`) dello strato nascosto;\n- `init_weights`: inizializzazione dei pesi della Rete Neurale. I pesi andrebbero inizializzati a valori casuali ne' troppo grandi ne' troppo piccoli.\n   \n   Infatti:\n    1. se i pesi vengono inizializzati a valori troppo grandi, nel caso di una rete abbastanza profonda, il gradiente (usato in fase di apprendimento) diventerebbe ancora pi\u00f9 grande; a causa delle varie moltiplicazioni tra valori elevati alla quale e' soggetto, generando il Problema dell\u2019esplosione del Gradiente.\n    2. se i pesi vengono inizializzati a valori troppo piccoli, durante la Backpropagation, il gradiente verebbe calcolato eseguendo delle moltiplicazioni per valori molto piccoli, tendendo cosi' a ridursi a zero, generando il Problema della Scomparsa del Gradiente.\n    \n    Per ovviare a tutto questo seleziono i pesi da una semplice distribuzione normale, cio\u00e8 una distribuzione con media pari a 0 e deviazione standard pari a 1. Tale procedimento mi e' possibile perche' ho scelto di realizzare una Rete Neurale con un unico strato nascosto.\n- `accuracy`: metodo che ha l'obiettivo di ritornare un valore compreso tra 0 e 1, rappresentante la qualita' del modello della Rete Neurale. La formula che voglio usare e'<center>\n$\\frac{1}{N}\\sum_{i = 1}^N (y\\_expected_i == y\\_predicition_i)$ <\/center>\n\n    ove N rappresenta il numero di valori all'interno del modello, $y\\_expected$ il vettore dei valori reali e $y\\_prediction$ il vettore delle previsioni del modello.\n- `log_loss`: metodo a supporto di `accuracy`.  Sviluppa la metrica cross entropy (log loss), la quale tiene conto della probabilita' che una predizione sia corretta, in modo da differenziare i casi di errori, e da rappresentare la  funzione di perdita della bonta' della classificazione. Per fare questo la formula che voglio usare e' \n    <center>- $\\frac{1}{N}\\sum_{i = 1}^N (y\\_expected_i \\bullet log(y\\_probablity_i) + (1 - y\\_expected_i) \\bullet (1 - y\\_probablity_i))$ <\/center>\n    \nove N rappresenta il numero di valori all'interno del modello, $y\\_expected$ indica i valori reali attesi e $y\\_probability$ la probabilita' di appartenenza alla classe positiva. Un valore basso, generato da tale metrica, indica una migliore qualita' della previsione della Rete Neurale.\n- `relu`: metodo utile durante l'addestramento del modello per la minimizzazione degli errori del training set.\\\n    E' la funzione di attivazione per lo strato nascosto.\\\n    Ho deciso di usare, durante l'apprendimento la Discesa di Gradiente, nello specifico la sua versione stocastica. Mi e' per questo necessaria una funzione di attivazione che assomigli e si comporti come una funzione lineare; ma che in realt\u00e0 sia una funzione non lineare, capace di apprendere relazioni complesse nei dati. La funzione di attivazione che ho scelto, per questo compito, e' la lineare rettificata (relu), che restituisce il valore 0 se l'input \u00e8 0 o inferiore, altrimenti l'input stesso.\n- `sigmoid`: metodo utile durante l'addestramento del modello per la minimizzazione degli errori del training set.\\\n    E' la funzione di attivazione per lo strato di output. Uso la sigmoide, in quanto il mio obiettivo e' una classificazione binaria. La formula e'\n    <center>$\\sigma(z) = \\frac{1}{1+e^{-z}}$<\/center>\n- `forward_propagation`: metodo che implementa il processo di Forward propagation, in una Rete Neurale multistrato. Ovvero il cuore dell'apprendimento del modello.\\\n    Tale processo si svolge nel seguente modo:\n    1. gli input della rete (x) arrivano allo strato di input;\n    2. questi vengono moltiplicati per i pesi ($w_1$) dello strato nascosto e sommati al bias ($b_1$). In formula significa: $z_1 = w_1 \\bullet x + b_1$;\n    3. dopodiche' l'output dello strato nascosto ($o_1$) si ottiene con l'applicazione della funzione di attivazione relu, che diventera' l'input dello strato di output;\n    4. il processo si ripete anche per lo strato di output: $z_2 = w_2 \\bullet o_1 + b_2$, e applicando la funzione di attivazione sigmoid ottengo l'output della Rete Neurale ($o_2$).\n- `prediction`: metodo che svolge la previsione del modello.\\\n    Lo strato di output ritorna  la probabilita' che l'osservazione di input appartenga alla classe positiva. Per realizzare cio' ho definito la filosofia: \"quando ho un\u2019osservazione con una probabilit\u00e0 maggiore del 50% appartiene alla classe positiva; altrimenti quando ho un\u2019osservazione con probabilit\u00e0 minore del 50% appartiene alla classe negativa\".\n- `train_with_gradient_descendent`: metodo per addestrare il modello.\\\n   Per fare l'addestramento della Rete Neurale ho deciso di usare la Discesa di Gradiente. Tale algoritmo:\n   1. inizializza un vettore x random (`init_weights`);\n   2. calcola il valore di massima discesa, ovvero la derivata parziale attribuita a ogni coefficiente x della funzione di costo (`back_propagation`);\n   2. al valore di ogni coefficiente viene iterativamente sottratto il valore del gradiente, moltiplicato per il learning rate. Quest'ultima costante da il passo di discesa della funzione.\n   4. il procedimento viene ripetuto per epochs volte.\n- `relu_derivative`: metodo di utilita' usato durante il calcolo delle derivate.\n    Se il paramentro dato in input e' <=0 allora la sua derivata e' 0; altrimenti e' 1.\n- `back_propagation`: metodo utile durante l'addestramento del modello.\\\n    Il suo compito e' quello di calcolare le derivate parziali della funzione di costo, in modo da poter applicare la discesa di gradiente. Ho deciso di far ricorso a una proprieta' delle derivate, chiamata Chain Rule, ovvero se f(x) = f(g(x)) allora $\\frac{df}{dx} = \\frac{df}{dg} \\frac{dg}{dx}$. Difatti se uso questa proprieta', sono in grado di propagare il segnale all'indietro (back propagation) e calcolare le derivate parziali.\n    \n   Applicando la Chain Rule, ottengo le seguenti derivate parziali:\n   1. $ \\frac{dJ}{dz_2} = \\frac{o_2}{y}$ \n   2. $ \\frac{dJ}{db_2} = \\frac{1}{N}(o_2^T \\bullet \\frac{dJ}{dz_2})$\n   3. $ \\frac{dJ}{db_2} = \\frac{1}{N}(\\sum_{i=1}^N \\frac{dJ}{dz_2})$\n   4. $ \\frac{dJ}{dz_1} = \\frac{dJ}{dz_2}(w_2^T * relu\\_derivative(z_1))$\n   5. $ \\frac{dJ}{dw_1} = \\frac{1}{N}(x^T \\bullet \\frac{dJ}{dz_1})$\n   6. $ \\frac{dJ}{db_1} = \\frac{1}{N}(\\sum_{i=1}^N \\frac{dJ}{dz_1})$\n    \n    ove\\\n    -> y sono i valori reali attesi;\\\n    -> o$_2^T$ e' la matrice trasposta rispetto a o$_2$;\\\n    -> w$_2^T$ e' la matrice trasposta rispetto a w$_2$;\\\n    -> x$^T$ e' la matrice trasposta rispetto al training set x;\\\n    -> `relu_derivative` funzione di utilita'.\n- `evaluate_output_net`: funzione di utilita' della classe `NeuralNetwork`. Esegue la predizione e ritorna l'accuratezza della previsione con la previsione stessa.\n\n\n\n    \n\n    ","951cb09b":"<h1>Caso d'uso<\/h1>","64b8b499":"Suddivido i dati in di training e di validazione nel seguente modo: 569 esempi totali\n- circa l'80% (512) al training set, \n- la parte restante degli esempi (57) al validation set.","857e44f3":"Svolgo anche la normalizzazione dei dati, in modo che tutti gli esempi appartengano a un range, di valori, comune. Tale prassi tende a velocizzare la fase di addestramento di una Rete Neurale.\\\nPer eseguire una buona normalizzazione, nell'insieme dei valori di training e validazione (X), effettuo la sottrazione del valore minore e divido per la differenza tra il valore maggiore e il valore minore.\n<center> $X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$ <\/center>\n                                                         ","f185f970":"<h1>Creazione del dataframe breast_cancer<\/h1>","6dcc5b2a":"Di seguito definisco un semplice caso d'uso della Rete Neurale `NeuralNetwork`.\\\nAl termine produco un grafico che confronta la classificazione della Rete Neurale con i risultati reali attesi.","368a479b":"Come si puo' vedere, dal output della Rete e dal grafico sopra, la previsione che ottengo, sul validation set, ha una buona accuratezza (>=90% nel caso peggiore) con una perdita (inesattezza della classificazione che tiene conto della bonta', in probabilita', della stessa) che rimane a ogni esecuzione del sorgente molto bassa (<=15% nei casi peggiori)."}}