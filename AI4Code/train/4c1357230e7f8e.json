{"cell_type":{"ba15110d":"code","dc368eac":"code","39712bcc":"code","6e68e732":"code","49de82d1":"code","c645719f":"code","d5693ee4":"code","afd7cafc":"code","99ccbc25":"code","1a7247a6":"code","57e952fe":"code","531a84eb":"code","9262c1dc":"code","08de772b":"code","b03906a2":"code","751d9541":"code","9d0f5341":"code","8bd3036b":"code","d1792e56":"code","ee834940":"code","3ba84bb9":"code","0d7a09d3":"code","aaa7714c":"code","9ae8c406":"code","1517dde4":"code","1273fe9d":"code","ea2ea38e":"code","eafe5b46":"markdown","a788fb78":"markdown","f57b63b6":"markdown","4ec83389":"markdown","2e55b8aa":"markdown","cd626122":"markdown","af215cc2":"markdown","d105fad6":"markdown","a4266042":"markdown","43838687":"markdown","c745cc3b":"markdown"},"source":{"ba15110d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc368eac":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","39712bcc":"data=pd.read_csv(\"..\/input\/iris\/Iris.csv\")","6e68e732":"data.head()","49de82d1":"data.describe()","c645719f":"data.isnull().sum()       #Missing value","d5693ee4":"del data[\"Id\"]            # NO use while training","afd7cafc":"data","99ccbc25":"data['Species'].value_counts()","1a7247a6":"sns.pairplot(data,hue='Species')","57e952fe":"from sklearn.preprocessing import LabelEncoder\nnumber=LabelEncoder()\ndata['Species']= number.fit_transform(data['Species'].astype('str'))\ndata","531a84eb":"data['Species'].value_counts()","9262c1dc":"X=data.drop(['Species'],axis=1)","08de772b":"X","b03906a2":"y=data['Species']","751d9541":"y","9d0f5341":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 5)","8bd3036b":"X_train","d1792e56":"X_test","ee834940":"y_train","3ba84bb9":"y_test","0d7a09d3":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","aaa7714c":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score","9ae8c406":"# Support vector classifier\nfrom sklearn.svm import SVC\nsvc_classifier = SVC()\nsvc_classifier.fit(X_train, y_train)\ny_pred_scv = svc_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_scv)","1517dde4":"cm = confusion_matrix(y_test, y_pred_scv)\nplt.title('Heatmap of Confusion Matrix', fontsize = 15)\nsns.heatmap(cm, annot = True)\nplt.show()","1273fe9d":"print(classification_report(y_test, y_pred_scv))","ea2ea38e":"# Cross validation\nfrom sklearn.model_selection import cross_val_score\ncross_validation = cross_val_score(estimator =svc_classifier , X = X_train_sc,y = y_train, cv = 10)\nprint(\"Cross validation accuracy of XGBoost model = \", cross_validation)\nprint(\"\\nCross validation mean accuracy of XGBoost model = \", cross_validation.mean())","eafe5b46":"# Support Vector Classifier","a788fb78":"# Data Visualization","f57b63b6":"# Libraries loaded","4ec83389":"# ML Model Building","2e55b8aa":"# Split train test","cd626122":"# Business Problem:- We have to predict the species of plant by looking at the Id,SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm","af215cc2":"# Cross Validation","d105fad6":"# Feature Scalling","a4266042":"# Data Load","43838687":"# Classification report","c745cc3b":"# Confusion matrix"}}