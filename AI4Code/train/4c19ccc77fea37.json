{"cell_type":{"8e4755be":"code","1d9dacdb":"code","54627f66":"code","48726d6d":"code","b6fc11ef":"code","0eb71d4d":"code","eb940052":"code","bb94aa67":"markdown","9a66f273":"markdown","c2a565dc":"markdown","7dc5b0da":"markdown"},"source":{"8e4755be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np  #linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nfrom tqdm import tqdm\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\ndf=pd.read_csv('..\/input\/kepler-exoplanet-search-results\/cumulative.csv')\ndf.head","1d9dacdb":"df=df.replace(['FALSE POSITIVE'], 1)\ndf=df.replace(['CONFIRMED'], 2)\ndf=df.replace(['NOT DISPOSITIONED'], 3)\ndf=df.replace(['CANDIDATE'], 0)","54627f66":"cols=['koi_disposition','koi_score','koi_fpflag_nt','koi_fpflag_ss','koi_period','koi_prad']\ndata=df[cols]\ndata=data.dropna()\nprint(data)","48726d6d":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\n\n#Split the data into parameters and results, and afterwards splitting it into test and training.\nX=data[['koi_score','koi_fpflag_nt','koi_fpflag_ss','koi_period','koi_prad']]\ny=data[['koi_disposition']]\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=21)","b6fc11ef":"neighbors = np.arange(1, 20)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    # Setup a k-NN Classifier with k neighbors: knn\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    # Fit the classifier to the training data\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n\n    #Compute accuracy on the testing set\n    test_accuracy[i] = knn.score(X_test, y_test)\n\n# Generate plot\nplt.title('k-NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()","0eb71d4d":"knn=KNeighborsClassifier(n_neighbors=13)\nknn.fit(X,y)\nprint(knn.score(X_test, y_test))","eb940052":"import seaborn as sns\nsns.heatmap(data.corr(), square=True, cmap='RdYlGn')","bb94aa67":"We can see that, for roughly 13 neighbours, we get the best results. Therefore, we shall keep that as the number of neighbours. We shall proceed to analyze the KNN model with 13 neighbours.","9a66f273":"We shall now decide how many neighbours we need for the KNN. In order to do this, we shall plot a graph for several values of the number of neighbours, and afterwards we shall analyze the best result.","c2a565dc":"The KNN model with 13 neighbours has 78% accuracy in deducing the status of an observed object. Below, we shall use a correlation heatmap in order to observe which terms are most linked together. We can see clearly that the best predictor remains the score; however, nothing predicts the score too well, and this means that other data, which was disconsidered when we cleaned the data, was relevant.","7dc5b0da":"It is clear that the data needs some cleaning. We shall replace the term \"Candidate\" by 0, the term \"False Positive\" by 1, the term \"Confirmed\" by 2 and the term \"Not Dispositioned\" by 3. Afterwards, we shall cut off the parts of the data that aren't necessary. For this analysis, we consider the following quantities as relevant: the koi_disposition, which is the result (y), the koi_score, the koi_fpflag_nt, the koi_fpflag_ss, the koi_period,the koi_prad and the koi_smass. These shall be the most relevant aspects of our analysis. We shall use the KNN algorithm in order to split our data in the required categories. "}}