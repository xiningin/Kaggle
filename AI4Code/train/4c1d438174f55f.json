{"cell_type":{"615874dc":"code","a027f4fa":"code","a9c85232":"code","d5e22879":"code","cef25518":"code","42328e94":"code","3c56182c":"code","295ece68":"code","35e2627b":"code","d857af64":"code","5dd23739":"code","1a4aeae6":"code","e6ccd9d1":"code","9cf1ab0d":"code","4a427e33":"code","71fe2f18":"code","daf678b7":"code","1038317e":"code","a4b69935":"code","6c50a4dd":"code","0b326737":"code","ef1dcb82":"code","2746a7cc":"code","cca5260a":"code","3b0c1640":"code","085e9ceb":"code","03bca3fd":"markdown","698f1ffc":"markdown","5ce14d64":"markdown","8afdea5a":"markdown","171ffc37":"markdown","7937e86d":"markdown","e4600c8e":"markdown","0cd4354d":"markdown","9c850a09":"markdown","f6457a9a":"markdown","6b79a2ed":"markdown","5ffe1894":"markdown","659f352b":"markdown","2629450d":"markdown","e2aa8571":"markdown","58157b5d":"markdown","7004172f":"markdown","387fd18b":"markdown","18707392":"markdown","c8b0b2d4":"markdown","60408202":"markdown","53dc66dc":"markdown","9ea21985":"markdown","e76856a5":"markdown"},"source":{"615874dc":"\n%reset -f\nfrom sklearn.cluster import KMeans\n#For creating elliptical-shaped clusters\nfrom sklearn.datasets import make_blobs\n#OS related\nimport os\n#Data manipulation\nimport pandas as pd\nimport numpy as np\n\n#for math functions\nimport math\n\n# Data processing \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import normalize\n\n#Graphing\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go \nimport plotly.express as px\nfrom matplotlib.colors import LogNorm\nimport seaborn as sns\n#TSNE\nfrom sklearn.manifold import TSNE\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n\nfrom sklearn.mixture import GaussianMixture\n\nimport scipy","a027f4fa":"os.chdir(\"\/kaggle\/input\/ccdata\")\nos.listdir()            # List all files in the folder","a9c85232":"dfcc=pd.read_csv('CC GENERAL.csv')\ndfcc.head()\nprint(\"No of Customers:\",dfcc.shape[0])\nprint(\"No of Columns:\",dfcc.shape[1])","d5e22879":"dfcc.columns","cef25518":"#rename column names\ndfcc.columns = [i.lower() for i in dfcc.columns]\ndfcc.columns","42328e94":"#Drop cust_id..No use of This column\ndfcc.drop(columns = ['cust_id'], inplace = True)\n","3c56182c":"#Check null value\n\n#null_columns=dfcc.columns[dfcc.isnull().any()]\ndfcc.columns[dfcc.isnull().any()]\n#Two columns having Null values\n#Check how many Null Values\nprint(\"Number of Null Values:\\n\",dfcc[dfcc.columns[dfcc.isnull().any()]].isnull().sum())","295ece68":"#sns.distplot(dfcc.credit_limit)\n#sns.distplot(dfcc.minimum_payments)\nsns.kdeplot(dfcc.credit_limit, shade=True)\nsns.kdeplot(dfcc.minimum_payments, shade=True)","35e2627b":"values = {\n              'minimum_payments' :   dfcc['minimum_payments'].median(),\n                 'credit_limit'               :     dfcc['credit_limit'].median()\n               }\n\ndfcc.fillna(value = values, inplace = True)\n","d857af64":"ss =  StandardScaler()\ncc_ss= ss.fit_transform(dfcc)\ncc_ss = normalize(cc_ss)\ndf_out= pd.DataFrame(cc_ss, columns = dfcc.columns.values)\ndf_out\n","5dd23739":"\ndfSummary=dfcc.describe()\ndfSummary\ndfSummary=dfSummary.T\ndfSummary.plot(kind='bar',figsize = (20,8))\n#check details where purchases is max\ndfcc[dfcc.purchases == 49039.57]","1a4aeae6":"(1.00*dfcc['tenure'].value_counts().sort_index()\/len(dfcc)).plot(kind='barh')\nplt.title('Tenure Distribution')\nplt.xlabel('Distribution % ');\n","e6ccd9d1":"fig = px.box(dfcc,\n                y=\"balance\",\n                x=\"tenure\",\n                \n               title='Tenure Vs Balance',\n                hover_data=dfcc.columns\n               )\nfig.show()\n#Outlier values(Q3+1.5IQR) are more where Tenure is 12","9cf1ab0d":"px.histogram(data_frame =dfcc,\n                      x = 'tenure',\n                      y = 'purchases',\n                      marginal = 'violin',\n                      title='Tenure vs Purchases',\n                      histfunc = 'avg'\n                \n             )\n#Observation : Card holders having tenure 12 has done max purchase","4a427e33":"px.histogram(data_frame =dfcc,\n                      x = 'tenure',\n                      y = 'credit_limit',\n                      marginal = 'violin',\n                      title='Tenure vs credit_limit',\n                      histfunc = 'avg'\n                \n             )\n#Observation : Highest Avg credit limit : where tenure is 12","71fe2f18":"#Dist plot for all coulmns\nplt.figure(figsize=(15,18))\nnoofrows= math.ceil(df_out.shape[1]\/3)\nnoofrows\ndf_out_columns=df_out.columns.values\n\nfor i in range(df_out.shape[1]):\n  plt.subplot(noofrows,3,i+1)\n  sns.distplot(df_out[df_out_columns[i]])\n \n\nplt.tight_layout()\n\n#observation :  right skewed curve:ONEOFFPURCHASES,Installment purchase,Cash advance,payments,minimum_payments,balance","daf678b7":"#Correlation Map for all features\ndf_corr=df_out.corr()\nplt.figure(figsize = (15, 9))\nsns.heatmap(df_corr, linecolor = 'black', linewidth = 1, annot = True)\nplt.title('Correlation of credit card data\\'s features \\n Co Relation >0  means  poistive  co linear realtion \\n < 0 means opposite Relation ')\nplt.show()\n","1038317e":"sns.jointplot(df_out.purchases, df_out.oneoff_purchases, kind = 'reg') \n","a4b69935":"frequency_cols = [col for col in df_out.columns if 'frequency' in col]\nfor i,col in enumerate(frequency_cols):\n    g=sns.jointplot(df_out.credit_limit, df_out[col], kind = 'reg')\n    s = scipy.stats.linregress(x = df_out['credit_limit'],y = df_out[col])\n    g.fig.suptitle(\"Correlation coefficient : credit_limit Vs \" + col + \" : \" + str(s[2]) )\n    \n#Observation  correlation coefficient is < 0 : Both Variable in opposite Direction\n#Observation  correlation coefficient is > 0 : Both Variable in same Direction\n","6c50a4dd":"df_outnozeropurchase=df_out[df_out.purchases != 0]\nsns.kdeplot(df_outnozeropurchase['purchases'], shade=True)\nsns.kdeplot(df_outnozeropurchase['installments_purchases'], shade=True)\nsns.kdeplot(df_outnozeropurchase['oneoff_purchases'], shade=True)\nsns.kdeplot(df_outnozeropurchase['credit_limit'], shade=True)\nplt.title('Density Estimation Plot')\n#observation : Installments_purchase and oneoff_purchase has equal ratio where purchases are high\n#Credit Card limit does not have significant relation with purchases, installments_purchases,oneoff_purchases\n","0b326737":"#Array for aic & bic\nbic = []\naic = []\nfor i in range(16):\n    gm = GaussianMixture(\n                     n_components = i+1,\n                     n_init = 10,\n                     max_iter = 100)\n    gm.fit(df_out)\n    bic.append(gm.bic(df_out))\n    aic.append(gm.aic(df_out))\nfig = plt.figure()\n\n","ef1dcb82":"#Draw aic ,bic on plot to understand\nplt.plot(range(1,len(aic)+1), aic,marker=\"o\",label=\"aic\")\nplt.plot(range(1,len(bic)+1), bic,marker=\"o\",label=\"bic\")\nplt.legend()\nplt.show()\n","2746a7cc":"#Gussian Mixture\ngm = GaussianMixture(\n                     n_components = 2,\n                     n_init = 10,\n                     max_iter = 100)\ngm.fit(df_out)\n \n#Find tsne\ntsne = TSNE(n_components = 2,perplexity=40.0)\ntsne_out = tsne.fit_transform(df_out)\ntsne_out\n","cca5260a":"#draw TSNE\nplt.scatter(tsne_out[:, 0], tsne_out[:, 1],\n            marker='x',\n            s=10,              # marker size\n            linewidths=20,      # linewidth of marker edges\n            c=gm.predict(df_out)   # Colour as per gm\n            )","3b0c1640":"densities = gm.score_samples(df_out)\ndensity_threshold = np.percentile(densities,4)\nanomalies      =     df_out[densities < density_threshold]      # Data of anomalous customers\n# Unanomalous data\nunanomalous =  df_out[densities >= density_threshold]      # Data of unanomalous customers\ndf_anomaly     =  pd.DataFrame(anomalies, columns = df_out.columns.values)\ndf_unanomaly = pd.DataFrame(unanomalous, columns = df_out.columns.values)\ndf_anomaly.shape\ndf_unanomaly.shape","085e9ceb":"#@author : Ashok sir \n#few changes made by me\ndef densityplots(df1,df2, label1 = \"Anomalous\",label2 = \"Normal\"):\n    # df1 and df2 are two dataframes\n    # As number of features are 17, we have 20 axes\n    fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15,15))\n    ax = axes.flatten()\n    fig.tight_layout()\n    # Do not display 18th, 19th and 20th axes\n    #because we need only 17 axes\n    axes[3,3].set_axis_off()\n    axes[3,2].set_axis_off()\n    axes[3,4].set_axis_off()\n    for i,col in enumerate(df1.columns):\n        # https:\/\/seaborn.pydata.org\/generated\/seaborn.distplot.html\n        # For every i, draw two overlapping density plots in different colors\n        sns.distplot(df1[col],\n                     ax = ax[i],\n                     kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": label1},   # Density plot features\n                     hist_kws={\"histtype\": \"step\", \"linewidth\": 2,\"alpha\": 1, \"color\": \"g\"}) # Histogram features\n        sns.distplot(df2[col],\n                     ax = ax[i],\n                     kde_kws={\"color\": \"red\", \"lw\": 3, \"label\": label2},\n                     hist_kws={\"histtype\": \"step\", \"linewidth\": 2,\"alpha\": 1, \"color\": \"b\"})\ndensityplots(df_anomaly, df_unanomaly, label2 = \"Unanomalous\")","03bca3fd":"### Set Directory","698f1ffc":"#### Find out how many GMM clusters using 'bic' and 'aic'.","5ce14d64":"### Load Data","8afdea5a":"### Call libraries\n","171ffc37":"* ***Dataset summarizes the usage of 8950 Customers based on 18 behavioral variables***","7937e86d":"*Outlier values(Q3+1.5IQR) are more where Tenure is 12\n*Card holders having tenure of 11 & 12 has more balance","e4600c8e":"# Clustering of Credit Card Data using Gaussian Mixture Method (GMM)","0cd4354d":"* ***Data Dictionary for Credit Card dataset***\n * ***CUSTID :*** Identification of Credit Card holder (Categorical)\n * ***BALANCE :***  Balance amount left in their account to make purchases \n * ***BALANCEFREQUENCY :***  How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n * ***PURCHASES :*** Amount of purchases made from account\n * ***ONEOFFPURCHASES :*** Maximum purchase amount done in one-go\n * ***INSTALLMENTSPURCHASES :*** Amount of purchase done in installment\n * ***CASHADVANCE :*** Cash in advance given by the user\n * ***PURCHASESFREQUENCY :*** How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n * ***ONEOFFPURCHASESFREQUENCY :*** How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n * ***PURCHASESINSTALLMENTSFREQUENCY :*** How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n * ***CASHADVANCEFREQUENCY :*** How frequently the cash in advance being paid\n * ***CASHADVANCETRX :*** Number of Transactions made with \"Cash in Advanced\"\n * ***PURCHASESTRX :*** Numbe of purchase transactions made\n * ***CREDITLIMIT :*** Limit of Credit Card for user\n * ***PAYMENTS :*** Amount of Payment done by user\n * ***MINIMUM_PAYMENTS :*** Minimum amount of payments made by user\n * ***PRCFULLPAYMENT :*** Percent of full payment paid by user\n * ***TENURE :*** Tenure of credit card service for user\n * ****Anomalous clients vs Un-anomalous client :**** Anomalous clients ie with density less than 4%","9c850a09":"### Cleansing of Data","f6457a9a":"### *Data Processing:* Standardization  & Normalization\n * Standardization : StandardScaler() is for column-wise standardization.\n * Normalization:  normalize() is to normalize each observation(row-wise) \n","6b79a2ed":"##### *from above graphical representation.we will fix 2 clusters*","5ffe1894":"##### *We will see graphical behaviour of these two columns*","659f352b":"* Average Purchase is 1003, max purchase is 49039.57 .\n* 50% is 361.2800 .\n* Only one card holder has max value for each column.so we can due to that customer avg is high","2629450d":"##### *Fill NA values*","e2aa8571":"*We will fill na values with median","58157b5d":"### Clustering and Interpretation using Gaussian Mixture Method ","7004172f":"* Card holders having tenure 12 has highest Avg credit limit","387fd18b":"# Anomalous clients vs Un-anomalous clients","18707392":"\n* balance : Un-anamolous has slightly more balance\n* balance_frequency : Un-anamolous has more balance frequency\n* Purchases : Un-anamolous make more purchases\n* oneoff_purchases : Un-anamolous make more one-off purchases\n* installments_purchases : Un-anamolous slightly more installment purchases\n* cash advance : Un-anamolous cash advance is more\n* purchase frequency : Un-anamolous is bi-modal curve. Abnormal has significantly more purchase frequency\n* on-off purchase frequency : Un-anamolous has more on-off purchase frequency\n* installments frequency : Un-anamolous has bimodal curve and have more purchase installments frequency for lower frequencies. \n* For higher purchase installments frequency, abnormal occurrence is more\n* cash advance frequency : anamolous has more cash advance frequency\n* payments : Un-anamolous has signitficantly more payments\n* minimum payments : Un-anamolous has signitficantly more minimum payments\n* Tenure : Un-anamolous has slightly more tenure\n* cash_advanc_trx,purchase_trx,credit_limit,prc_full_payment : No significant difference","c8b0b2d4":"* Mostly card holders has tenure 12","60408202":"####  Introduction\n\n### ***Gaussian Mixture Method*** : It is a  probabilistic model which is used to represent normally distributed subpopulations within an overall population.In Mixture mode subpopulation assigment is unknown.It allows the model to learn the subpopulation automatically,so we can say it is unsupervised learning.Clusters are elliptical-shaped\n\n### ***About Data Set*** : Dataset has  one notebook which consist credit card usage behavior of customers  in the last 6 months.Customer segmentation to define marketing strategy.\n\n#### Contents of this workbook:\n * **Data Loading:** Load\/Read Data from file\n * **Cleansing of Data:** Rename columns,check Na values,fill\/drop na values\n * **Data Processing:** Standardization  & Normalization\n * **Plotting of Data:** Graphing of data\n * **Clustering and Interpretation using Gaussian Mixture Method :** How many GMM clusters using '*bic' and 'aic'*.Perform clustering\n * **TSNE Check :**  Check if your clusters do not overlap\n * **Anomalous clients vs Un-anomalous clients :** Anomalous clients where density less than 4%\n ","53dc66dc":"### Plotting of Data : Graphical representation  to find the relation between data","9ea21985":"# TSNE Check","e76856a5":"##### #Purchases and oneoff_purchases has highest co relation i.e .87. We will draw a graph to show "}}