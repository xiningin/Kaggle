{"cell_type":{"d36a744e":"code","f425f258":"code","af893d16":"markdown","f8332c7a":"markdown","968e7ff5":"markdown","c3e3d01e":"markdown","6b36d0e6":"markdown","d89d288f":"markdown","25984b22":"markdown"},"source":{"d36a744e":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import TimeSeriesSplit  \n\ndf=pd.read_csv('..\/input\/ntt-data-global-ai-challenge-06-2020\/COVID-19_and_Price_dataset.csv')  \n\nfig, axes = plt.subplots(5, 1, figsize=(15, 20))  \nfolds = TimeSeriesSplit(n_splits=5)  \nfor i, (train_index, test_index) in enumerate(folds.split(df)):  \n    sns.lineplot(data=df, x='Date', y='Price', ax=axes[i], label='no_use',color=\"0.8\")  \n    sns.lineplot(data=df.iloc[train_index], x='Date', y='Price', ax=axes[i], label='train',color=\"b\")  \n    sns.lineplot(data=df.iloc[test_index], x='Date', y='Price', ax=axes[i], label='Validation',color=\"r\")  \n\nplt.legend()  \nplt.show()  ","f425f258":"def rolling_time_series_split(df,splits):\n    n_samples = len(df)\n    folds = n_samples \/\/ splits\n    indices = np.arange(n_samples)\n\n    margin = 0\n    for i in range(splits): \n        start = i * folds  \n        stop = start + folds  \n        temp = int(0.8 * (stop - start)) + start #If you want to change the data ratio of train\/Validation, change the 0.8 part.\n        yield indices[start: temp], indices[temp + margin: stop]  \n\nfig, axes = plt.subplots(5, 1, figsize=(15, 20))  \nfor i, (train_index, test_index) in enumerate(rolling_time_series_split(df,5)):  \n    sns.lineplot(data=df, x='Date', y='Price', ax=axes[i], label='no_use',color=\"0.8\")  \n    sns.lineplot(data=df.iloc[train_index], x='Date', y='Price', ax=axes[i], label='train',color=\"b\")  \n    sns.lineplot(data=df.iloc[test_index], x='Date', y='Price', ax=axes[i], label='Validation',color=\"r\")  \n\nplt.legend()  \nplt.show()  ","af893d16":"Let's use it for the crude oil data we are given.","f8332c7a":"You can see that the amount of data is equal between folds.\n\n\nThis article has shown you a simple way to prevent leakage and increase generalization performance.  \nif you want to make it even more robust, you can use nested cv (double cross validation).\nIt is mainly used when you want to do further model evaluation after hyperparameter tuning.\nA little bit of writing on how to do it would be as follows.\nYou can set aside a dataset that will not be added to the fold, and only fold the other data and cross-validate the model by dividing it into The trained model is then asked to predict a preallocated dataset. The difference between the predictions and the actual values is used to evaluate the hyperparameters as a CV error.\n\n\n![image.png](attachment:image.png)\n\n\nThe following article on nested cv may be helpful.  \nhttps:\/\/towardsdatascience.com\/time-series-nested-cross-validation-76adba623eb9\n\nhttps:\/\/www.angioi.com\/time-nested-cv-with-sklearn\n\nhttps:\/\/www.mikulskibartosz.name\/nested-cross-validation-in-time-series-forecasting-using-scikit-learn-and-statsmodels\/","968e7ff5":"No future data is mixed in during training. And you can see that Validation data from another point in time is used.  \nThis allows us to create a robust validation schema.\n\nHowever, as time goes by, the amount of training data is increasing, and the amount of data is unbalanced between folds.  \nIn such a case, you can remove old data every time and equalize the amount of data between folds, as shown in the image below.","c3e3d01e":"Let's use the validation shema above for a given crude oil data.","6b36d0e6":"![image.png](attachment:image.png)","d89d288f":"![image.png](attachment:image.png)","25984b22":"Although cross validation is a common technique used to improve the general performance,   it is sometimes used in In case of series data,  \nyou should be careful.\nshuffle of time series data during cross validation. I think this is typical.  \n**By shuffling past and future data, the learner learns the future that it is not supposed to know.**  \nAs a result, the cross validation scores will be very good,\nbut when the time comes to use the learner to try to predict the real future, the results will be very bad.  \n**This is what is called leakage.**  \nTherefore, Except for non-chronological data, I can't recommend the following examples  \n\nfrom sklearn.model_selection import KFold  \nKFold(n_splits=3, shuffle=True)  \nStratifiedKFold(n_splits=2, shuffle=True)\n\nAlso, the train_test_split function provided in scikit-learn is The default setting is shuffle=True, so be careful when using it.  \nTo prevent leakage, It is better to set the old data as training set and the new data as validation set.  \nThere is a TimeSeriesSplit function in scikit-learn that does all of the above for you, and I'd like to introduce it in this article.  \nLook at the image below to see what kind of validation you can do.\nThe image is borrowed from the link below.  \nhttps:\/\/www.r-bloggers.com\/time-series-cross-validation-using-crossval\/"}}