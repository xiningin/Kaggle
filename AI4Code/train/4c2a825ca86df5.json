{"cell_type":{"be591a05":"code","41fa2d7e":"code","4972fe55":"code","cc4bcbd4":"code","c90648eb":"code","0bf40628":"code","4c365671":"code","b487f4b0":"code","dd0cc8bb":"code","1655d2ce":"code","661153f4":"code","c4a86816":"code","42155d7c":"code","78b139b4":"code","563a24f6":"code","32fe152a":"code","e0f264df":"code","513be53e":"code","f8869a94":"code","64343a29":"code","7e75568f":"code","7d68f00b":"code","353f83f7":"code","161df03a":"code","1976a166":"code","5ad4310e":"code","273de99f":"code","ac59dfdf":"code","e19a227e":"code","bff9026d":"markdown","efe459c9":"markdown"},"source":{"be591a05":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf \nimport random\n\n  \nimport warnings  \nwarnings.filterwarnings('ignore')","41fa2d7e":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier","4972fe55":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)","cc4bcbd4":"def binary_mean_encoding(data, test_data, cat_to_encode, target, nfolds):\n    \"\"\"\n        This function encode a categorical feature into some features related to the target.\n        Use this function for binary categorical targets (i.e. binary classification problems).\n        This function uses a StratifiedKFold regularization.\n    \"\"\"\n    kf = StratifiedKFold(n_splits=nfolds, shuffle=False)\n    for train_idx, val_idx in kf.split(data, data[target]):\n        X_train = data.iloc[train_idx,:]\n        X_val = data.iloc[val_idx,:]\n        mean_map = X_train.groupby(cat_to_encode)[target].mean()\n        data.loc[val_idx, 'Mean_enc_'+cat_to_encode] = data.loc[val_idx, cat_to_encode].map(mean_map)    \n        \n    # if some splits do not contain certain categories: we fill missing values with the global feature value\n    data['Mean_enc_'+cat_to_encode].fillna(data[target].mean(), inplace=True)\n    \n    # validating all values per category\n    value_map = data.groupby(cat_to_encode)['Mean_enc_'+cat_to_encode].mean()\n    data['Mean_enc_'+cat_to_encode] = data[cat_to_encode].map(value_map)\n    test_data['Mean_enc_'+cat_to_encode] = test_data[cat_to_encode].map(value_map)\n    test_data['Mean_enc_'+cat_to_encode].fillna(data[target].mean(), inplace=True)","c90648eb":"def getModel(seed):\n    \"\"\"\n        In this function, we define the model\n    \"\"\"\n    model = XGBClassifier(tree_method='gpu_hist',\n                          eval_metric='logloss',\n                          use_label_encoder=False,\n                          colsample_bytree= 0.6522,\n                          gamma= 0,\n                          learning_rate=0.005,\n                          max_delta_step=2.5706,\n                          max_depth = 9,\n                          min_child_weight = 6.9800,\n                          n_estimators = 5000,\n                          subsample = 0.65,\n                          random_state=(1+seed)\n                         )\n    return model","0bf40628":"def run_fold(train_df, test_df, fold_number, seed_number, output_size, eval_function, id_name='id', target_name='target', pred_proba=False):\n    seed_everything(seed_number)\n    \n    train_mask = train_df['kfold'] != fold_number\n    valid_idc = train_df.loc[~train_mask].index\n    \n    X_train = train_df.drop(columns=[id_name, target_name]).loc[train_mask].reset_index(drop=True)\n    y_train = train_df[target_name].loc[train_mask].reset_index(drop=True)\n\n    \n    X_val = train_df.drop(columns=[id_name, target_name]).loc[~train_mask].reset_index(drop=True)\n    y_val = train_df[target_name].loc[~train_mask].reset_index(drop=True)\n    \n    X_train.drop(columns=['kfold'], inplace=True)\n    X_val.drop(columns=['kfold'], inplace=True)\n    \n    oof = np.zeros((train_df.shape[0], output_size))\n    preds = np.zeros((test_df.shape[0], output_size))\n    \n    model = getModel(seed_number)\n    \n    model.fit(X_train, y_train) # we can add more parameters\n    \n    train_loss = eval_function(y_train, model.predict(X_train))\n    print(f\"Seed: {seed_number}, FOLD: {fold_number}, train_loss: {train_loss}\")\n    valid_preds = model.predict(X_val)\n    if pred_proba:\n        oof[valid_idc] = model.predict_proba(X_val).reshape((len(valid_preds),output_size))\n    else:\n        oof[valid_idc] = valid_preds.reshape((len(valid_preds),output_size))\n    valid_loss = eval_function(y_val, valid_preds)\n    print(f\"Seed: {seed_number}, FOLD: {fold_number}, val_loss: {valid_loss}\")\n    \n    # we can add model save \n    \n    if pred_proba:\n        preds = model.predict_proba(test_df[X_train.columns]).reshape((len(test_df), output_size))\n    else:\n        preds = model.predict(test_df[X_train.columns]).reshape((len(test_df), output_size))\n    \n    return oof, preds","4c365671":"def run_k_fold(train_df, test_df, seed_number, output_size, eval_function, id_name='id', target_name='target', pred_proba=False):\n    oof = np.zeros((train_df.shape[0], output_size))\n    predictions = np.zeros((test_df.shape[0], output_size))\n    \n    for fold in range(N_FOLDS):\n        oof_, preds_ = run_fold(train_df, test_df, fold, seed_number, output_size, eval_function, id_name, target_name, pred_proba)\n        \n        predictions += preds_ \/ N_FOLDS\n        oof += oof_ \n        \n    return oof, predictions","b487f4b0":"def execution(train_df, test_df, seeds, output_size, eval_function, id_name='id', target_name='target', pred_proba=False, stratification=False):\n    oof = np.zeros((train_df.shape[0], output_size))\n    preds = np.zeros((test_df.shape[0], output_size))\n    for seed in seeds:\n        if stratification:\n            kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n        else:\n            kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n            \n        train_df['kfold'] = np.zeros(len(train_df))\n        for f, (t_idx, v_idx) in enumerate(kf.split(train_df, train_df[target_name])) :\n            train_df.loc[v_idx, 'kfold'] = int(f)\n        train_df['kfold'] = train_df['kfold'].astype(int)\n        oof_, preds_ = run_k_fold(train_df, test_df, seed, output_size, eval_function, id_name, target_name, pred_proba) \n        oof += oof_ \/ len(seeds)\n        preds += preds_ \/ len(seeds)\n    if not pred_proba:\n        over_loss = eval_function(train_df[target_name], oof)\n        print(f\"The Loss is {over_loss}\")\n    return oof, preds ","dd0cc8bb":"tr_df = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ntr_df.head(2)","1655d2ce":"tt_df = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\ntt_df.head(2)","661153f4":"cat_cols = [c for c in tr_df.columns if c.startswith('cat')]\nnum_cols = [c for c in tr_df.columns if c.startswith('cont')]","c4a86816":"for col in cat_cols:\n    binary_mean_encoding(tr_df, tt_df, col, 'target', 5)","42155d7c":"tr_df.head(2)","78b139b4":"tt_df.head(2)","563a24f6":"encoders = []\nfor elt in cat_cols:\n    enc = LabelEncoder()\n    enc.fit(tr_df[elt])\n    enc_dict = dict(zip(enc.classes_, enc.transform(enc.classes_)))\n    tr_df['L_enc_'+elt] = tr_df[elt].apply(lambda x: enc_dict.get(x, -1))\n    tt_df['L_enc_'+elt] = tt_df[elt].apply(lambda x: enc_dict.get(x, -1))\n    encoders.append(enc)","32fe152a":"tr_df.head(2)","e0f264df":"tt_df.head(2)","513be53e":"for elt in cat_cols:\n    f_enc = tr_df.groupby(elt).size()\/len(tr_df)\n    tr_df['F_enc_'+elt] = tr_df[elt].map(f_enc)\n    tt_df['F_enc_'+elt] = tt_df[elt].map(f_enc)\n    tr_df['F_enc_'+elt].fillna(0, inplace=True)\n    tt_df['F_enc_'+elt].fillna(0, inplace=True)","f8869a94":"tr_df.head(2)","64343a29":"tt_df.head(2)","7e75568f":"WoE_encoders = []\nfor elt in cat_cols:    \n    c = tr_df.groupby(elt)['target'].mean().to_dict()\n    woe = {}\n    for k in c.keys():\n        woe[k] = np.log(c[k]\/(1-c[k]))*100\n    tr_df['WoE_enc_'+elt] = tr_df[elt].map(woe)\n    tt_df['WoE_enc_'+elt] = tt_df[elt].map(woe)\n    tr_df['WoE_enc_'+elt].fillna(0, inplace=True)\n    tt_df['WoE_enc_'+elt].fillna(0, inplace=True)\n    WoE_encoders.append(woe)","7d68f00b":"tr_df.to_csv('train.csv', index=False)\ntt_df.to_csv('test.csv', index=False)","353f83f7":"tr_df.drop(columns=cat_cols, inplace=True)\ntt_df.drop(columns=cat_cols, inplace=True)","161df03a":"N_FOLDS = 5\noof_, preds_ = execution(tr_df, tt_df, [0], 2, roc_auc_score, id_name='id', target_name='target', pred_proba=True, stratification=True)","1976a166":"preds = pd.DataFrame(preds_, columns=['p_0', 'p_1'])\npreds.head(2)","5ad4310e":"oof = pd.DataFrame(oof_, columns=['p_0', 'p_1'])\noof.head(2)","273de99f":"sub = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsub.head(2)","ac59dfdf":"sub['target'] = preds['p_1']\nsub.to_csv('submission.csv', index=False)","e19a227e":"oof.to_csv('folds.csv', index=False)","bff9026d":"Frequency Encoding","efe459c9":"Weight of evidence"}}