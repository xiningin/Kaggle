{"cell_type":{"83ad3411":"code","ddf4b6b3":"code","3393e245":"code","8fa163bf":"code","2c77955e":"code","f24a01b1":"code","9c0b1b08":"code","159c0b5f":"code","76ddbe82":"code","c99ceca2":"code","75209a46":"code","e0072926":"code","9b2c42e3":"code","2f55aef4":"code","e7d4430a":"code","e42a5bf8":"code","7d49cd9e":"code","93d00c2d":"code","f3f4d1c6":"code","8373e42e":"code","7b7e4171":"code","3c9cb42e":"code","c8d53547":"code","cb04c238":"code","d205e84c":"code","f251afb6":"code","d2ffe845":"code","37255e44":"code","08bac5bf":"code","434dd27a":"code","17057776":"code","9d5135e5":"code","b65d7e29":"code","77565f5e":"code","e4c2765f":"code","6005d8e7":"code","2ed1dcea":"code","e0f43d2f":"code","de96a381":"code","91fcfcd0":"code","d532869a":"code","4e61dfd1":"code","39f0b3eb":"markdown","f0815015":"markdown","c15dd673":"markdown","c70f7923":"markdown","783b08c5":"markdown","f72daaad":"markdown","962adcd8":"markdown","d37228aa":"markdown","1670076e":"markdown","4ce7f372":"markdown","da2c361e":"markdown","ee7f18cc":"markdown","04534558":"markdown","31a98e8a":"markdown","52214edd":"markdown","9afd2607":"markdown"},"source":{"83ad3411":"import numpy as np\nimport pandas as pd\nfrom pandas_datareader import data, wb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport math\nimport datetime\nimport plotly\nimport cufflinks as cf\ncf.go_offline()\n%matplotlib inline","ddf4b6b3":"start = datetime.datetime(2017, 7, 12)\nend = datetime.datetime(2020, 7, 12)","3393e245":"df = data.DataReader(\"BTC-USD\",'yahoo',start,end)\ndf.head()","8fa163bf":"df.tail()","2c77955e":"df.xs(key='Close',axis=1).max()","f24a01b1":"df.xs(key='Close',axis=1).iplot()","9c0b1b08":"plt.figure(figsize=(12,5))\ndf['Close'].loc['2019-07-12':'2020-07-12'].rolling(window=30).mean().plot(label='30 Day Moving Avg.')\ndf['Close'].loc['2019-07-12':'2020-07-12'].plot(label='Close')\nplt.legend()","159c0b5f":"df0 = df[['Open','High','Low','Close']].loc['2019-07-12':'2020-07-12']\ndf0.iplot(kind='candle')","76ddbe82":"df['Close'].loc['2019-07-10':'2020-07-10'].ta_plot(study='sma',periods=[9,18,27])","c99ceca2":"df1=df.reset_index()['Close']","75209a46":"df1","e0072926":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\ndf1=scaler.fit_transform(np.array(df1).reshape(-1,1))","9b2c42e3":"print(df1)","2f55aef4":"training_size=int(len(df1)*0.70)\ntest_size=len(df1)-training_size\ntrain_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]","e7d4430a":"training_size,test_size","e42a5bf8":"train_data","7d49cd9e":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, time_step=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-time_step-1):\n\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + time_step, 0])\n\treturn np.array(dataX), np.array(dataY)","93d00c2d":"# reshape into X=t,t+1,t+2,t+3 and Y=t+4\ntime_step = 100\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)","f3f4d1c6":"print(X_train.shape), print(y_train.shape)","8373e42e":"print(X_test.shape), print(y_test.shape)","7b7e4171":"# reshape input to be [samples, time steps, features] which is required for LSTM\nX_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","3c9cb42e":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM","c8d53547":"model=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')\n","cb04c238":"model.summary()","d205e84c":"model.summary()","f251afb6":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64,verbose=1)","d2ffe845":"train_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)","37255e44":"# Transformback to original form\ntrain_predict=scaler.inverse_transform(train_predict)\ntest_predict=scaler.inverse_transform(test_predict)","08bac5bf":"### Calculate RMSE performance metrics\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_train,train_predict))","434dd27a":"### Test Data RMSE\nmath.sqrt(mean_squared_error(y_test,test_predict))","17057776":"# shift train predictions for plotting\nlook_back=100\ntrainPredictPlot = np.empty_like(df1)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(df1)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(df1))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","9d5135e5":"len(test_data)","b65d7e29":"x_input=test_data[230:].reshape(1,-1)\nx_input.shape","77565f5e":"temp_input=list(x_input)\ntemp_input=temp_input[0].tolist()","e4c2765f":"temp_input","6005d8e7":"# demonstrate prediction for next 10 days\nfrom numpy import array\n\nlst_output=[]\nn_steps=100\ni=0\nwhile(i<30):\n    \n    if(len(temp_input)>100):\n        #print(temp_input)\n        x_input=np.array(temp_input[1:])\n        print(\"{} day input {}\".format(i,x_input))\n        x_input=x_input.reshape(1,-1)\n        x_input = x_input.reshape((1, n_steps, 1))\n        #print(x_input)\n        yhat = model.predict(x_input, verbose=0)\n        print(\"{} day output {}\".format(i,yhat))\n        temp_input.extend(yhat[0].tolist())\n        temp_input=temp_input[1:]\n        #print(temp_input)\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    else:\n        x_input = x_input.reshape((1, n_steps,1))\n        yhat = model.predict(x_input, verbose=0)\n        print(yhat[0])\n        temp_input.extend(yhat[0].tolist())\n        print(len(temp_input))\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    \n\nprint(lst_output)","2ed1dcea":"day_new=np.arange(1,101)\nday_pred=np.arange(101,131)","e0f43d2f":"len(df1)","de96a381":"plt.plot(day_new,scaler.inverse_transform(df1[997:]))\nplt.plot(day_pred,scaler.inverse_transform(lst_output))","91fcfcd0":"df3=df1.tolist()\ndf3.extend(lst_output)","d532869a":"df3=scaler.inverse_transform(df3).tolist()","4e61dfd1":"plt.plot(df3)","39f0b3eb":"#### Visualization (Closing Rate)","f0815015":"#### Let's Reset the Index to Close","c15dd673":"### Import the data using DataReader","c70f7923":"### Set Duration","783b08c5":"### Import the Libraries","f72daaad":"#### 30-day Moving Average for Close Price","962adcd8":"### Lets Predict","d37228aa":"**CONCLUSION:** Here, these predictions say that ","1670076e":"### Predictions for Next 30 Days","4ce7f372":"**Help me improve my Code if necessary. Thanks!**","da2c361e":"#### Splitting the Close data into Train and Test sets","ee7f18cc":"#### Maximum Closing Rate","04534558":"#### Using MinMaxScaler","31a98e8a":"### Stacked LSTM Model","52214edd":"### Exploratory Data Analysis","9afd2607":"### Let's Visualize the Predictions"}}