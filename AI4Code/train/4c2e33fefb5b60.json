{"cell_type":{"20d420ea":"code","34b090b1":"code","54c09d09":"code","68d3324f":"code","a483e13a":"code","223c2e07":"code","9c357371":"code","435febc2":"code","d9648aa9":"code","592d2261":"code","e03c961c":"code","37ae154f":"code","4d112026":"markdown","ae12e1a0":"markdown","a238306b":"markdown","3ccb4882":"markdown","25a405f5":"markdown","f6d45781":"markdown"},"source":{"20d420ea":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#Linear Algebra\nimport numpy as np\n#Data preprocessing\nimport pandas as pd\n\n#setting display options\npd.set_option('display.max_rows', 5000)\npd.set_option('display.max_columns', 500)\npd.set_option('max_colwidth', 500)\nnp.set_printoptions(linewidth =400)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n#Advance-style plotting\nimport seaborn as sns\ncolor =sns.color_palette()\nsns.set_style('darkgrid')\n\n#Ignore annoying warning from sklearn and seaborn\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn\n\n#other libraiaries\nimport os\nimport copy\nfrom collections import defaultdict\nfrom collections import Counter\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nimport re\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","34b090b1":"description = pd.read_csv('\/kaggle\/input\/widsdatathon2020\/WiDS Datathon 2020 Dictionary.csv'); description","54c09d09":"#read the data\ntrain = pd.read_csv('\/kaggle\/input\/widsdatathon2020\/training_v2.csv')\ntest  = pd.read_csv('\/kaggle\/input\/widsdatathon2020\/unlabeled.csv')","68d3324f":"train.columns","a483e13a":"print(train.shape , test.shape)","223c2e07":"#column 1 Unique identifier associated with a patient unit stay\nprint (train['encounter_id'].nunique() , test['encounter_id'].nunique())","9c357371":"#column 2 Unique identifier associated with a hospital\nprint (train['hospital_id'].nunique() , test['hospital_id'].nunique())","435febc2":"#column 3 Unique identifier associated with a patient\nprint (train['patient_id'].nunique() , test['patient_id'].nunique())","d9648aa9":"#column 4\nYes = len(train[train.hospital_death ==1])\nNo = len(train[train.hospital_death ==0])\nTotal = len(train)\nprint ('There are imbalanace datset with a %i\/%i ratio'%((No\/Total*100), (Yes\/Total*100)+1))","592d2261":"sns.catplot(x ='hospital_death', kind ='count',palette='pastel', data = train);","e03c961c":"#columnn 5\ntrain['age'].describe()","37ae154f":"#Hint: ensure all units of each columns are having relationship with respect to each other..","4d112026":"UNIVARIATE ANALYSIS - it takes the data (both train and test), summarizes the data (both train and test) and finds patterns in the data\nfor further analysis","ae12e1a0":"Comment\/Hint: Same as above (encounter id); every patient appear once in the data\n\nsummary: drop patient id","a238306b":"#Comment: its an imbalance data set but its still normal to work with; because there should be a low probaility of hospital death in the real sense. Except in some certains season\/country whereby high numbers of hospital death was recorded for a period of time of which such data point doesnt exist here...\n\n#Hint1: oversampling\/undersampling is not a good techniques for this task; kindly use a robust algorithm like xgboost, lightgbm etc\n#Hint2: also since there is a lot of missing data point... oversampling\/undersampling is not a good techniques for this task","3ccb4882":"Comment\/Hint : Since there the id's are unique across train and test data; they have no or little significant importance to our model; drop them to avoid noisy parameters when training your model.. but had it been the patient unit stay was diagnose for another ailment this might be a good feature \n\nsummary: drop encounter id","25a405f5":"#Comment\/Hints: there is a maximum age of 89 and a minimum of 16 age; classifying age into categories will enhance our model peformance\n#a patient diagnose of a chronic disease around old age will have a high probability of dying irrespectively of the hospital death record\n#define a function to classifiy age: it will be a good feature\n\n\n#code\n   if x >= 15 and x <= 24:\n        return 'igen'\n    elif x >= 25 and x <= 54:\n      return 'Prime_working_Age'\n    elif x >= 55 and x <= 64:\n        return 'Mature_working_Age'\n    else:\n        return 'Elderly_working_Age'\ntrain['Age_category'] = train['age'].apply(age_category)\nx =train[['age','Age_category']]\n\n","f6d45781":"#Comment: Since an Hospital id appear several times, definitely several patient has visited an hospital and might have been diagnosed of the disease that leads to hospital death. \n\n#Hint Generate new features fro these\nQuestion 1? how many hospital death was recorded when using an hospital with respect to some diseases like cirosis, aids\nQuestion 2? was hospital death common to an hospital id or not\n\n#create a new feature (frequency of hospital_id)\n\ntest['hospital_idcount']=test['hospital_id'].map(test['hospital_id'].value_counts().to_dict())"}}