{"cell_type":{"b9ed6fc8":"code","53b9050c":"code","bbaef224":"code","442a5a26":"code","dd8ba191":"code","81fe7b7c":"code","06137a77":"code","f754827f":"code","cf87bf08":"code","84a4bddd":"code","1c024a38":"code","49fd6f2e":"code","a26fc836":"code","21500def":"code","6ad4b8a9":"markdown"},"source":{"b9ed6fc8":"# Imports\r\nimport random\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\nimport seaborn as sns\r\nimport xgboost as xgb\r\nfrom imblearn.over_sampling import SMOTE\r\nfrom sklearn import metrics\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.model_selection import GridSearchCV","53b9050c":"# Data Parsing\r\nstroke_df: pd.DataFrame = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\r\ndisplay(stroke_df.head())\r\nprint(f'Total rows: {len(stroke_df)}')","bbaef224":"# NaN\/NA analysis\nprint('NA counts:')\ndisplay(stroke_df.isna().sum())\n# Fill bmi NaN with mean\nstroke_df.bmi.fillna(stroke_df.bmi.mean(), inplace=True)\nprint('NA counts:')\ndisplay(stroke_df.isna().sum())","442a5a26":"categorical_cols = [\r\n    'gender',\r\n    'hypertension',\r\n    'heart_disease',\r\n    'ever_married',\r\n    'work_type',\r\n    'Residence_type',\r\n    'smoking_status',\r\n]\r\n\r\n# Uniques\r\nprint('Categorical features uniques count:')\r\ndisplay(stroke_df[categorical_cols].nunique())\r\n\r\nplt.style.use('ggplot')\r\nfig, ax = plt.subplots(len(categorical_cols), 1, figsize=(16,4*len(categorical_cols)))\r\n\r\nfor ii, col in enumerate(categorical_cols):\r\n    ax[ii].set_title(col)\r\n    ax[ii].bar(x=stroke_df[col].astype(str).unique(), height=stroke_df[col].value_counts(), color='tab:blue')","dd8ba191":"numeric_cols = [\n    'age',\n    'avg_glucose_level',\n    'bmi',\n]\n\n# Plot inter-feature correlations\nprint('Inter-feature correlations:')\nplt.figure(figsize=(len(numeric_cols)\/1.5,len(numeric_cols)\/1.5))\ncorr = stroke_df[numeric_cols].corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, cmap=\"RdBu\", vmin=-1, vmax=1)\nsns.set(font_scale=1)\n\n# Plot numeric distributions (histograms)\nplt.style.use('ggplot')\nfig, ax = plt.subplots(len(numeric_cols), 1, figsize=(16,4*len(numeric_cols)))\nfor ii, col in enumerate(numeric_cols):\n    ax[ii].set_title(col)\n    ax[ii].hist(x=stroke_df[col], color='tab:blue')","81fe7b7c":"# Cleaning\nprint(f'Uncleaned row count: {len(stroke_df)}')\n\nclean_stroke_df = stroke_df.copy(deep=True)\n\n# Remove low count categories\n# clean_stroke_df = clean_stroke_df[clean_stroke_df.gender != 'Other']\n# clean_stroke_df = clean_stroke_df[clean_stroke_df.work_type != 'Never_worked']\n\n# Remove NA\nclean_stroke_df = clean_stroke_df.dropna()\n\n# Remove Outliers - set threshold to None to not remove\nextreme_outlier_thresholds = {\n    'age': None,\n    'avg_glucose_level': None,\n    'bmi': None\n}\nfor k, v in extreme_outlier_thresholds.items():\n    if v:\n        clean_stroke_df = clean_stroke_df[clean_stroke_df[k] <= v]\n\n# Reset index\nclean_stroke_df = clean_stroke_df.reset_index(drop=True)\n\nprint(f'Cleaned row count: {len(clean_stroke_df)}')","06137a77":"# Feature Engineering\nclean_stroke_df['age_stdised'] = (clean_stroke_df.age - clean_stroke_df.age.mean()) \/ clean_stroke_df.age.std()\nclean_stroke_df['bmi_stdised'] = (clean_stroke_df.bmi - clean_stroke_df.bmi.mean()) \/ clean_stroke_df.bmi.std()\nclean_stroke_df['gluc_stdised'] = (clean_stroke_df.avg_glucose_level - clean_stroke_df.avg_glucose_level.mean()) \/ clean_stroke_df.avg_glucose_level.std()\nclean_stroke_df['age_bmi'] = clean_stroke_df.age_stdised * clean_stroke_df.bmi_stdised\nclean_stroke_df['age_gluc'] = clean_stroke_df.age_stdised * clean_stroke_df.gluc_stdised\nclean_stroke_df['gluc_bmi'] = clean_stroke_df.gluc_stdised * clean_stroke_df.bmi_stdised\nclean_stroke_df['age_gluc_bmi'] = clean_stroke_df.age_stdised * clean_stroke_df.gluc_stdised * clean_stroke_df.bmi_stdised\n# One Hot Encoding\nprint('Unencoded Data:')\ndisplay(clean_stroke_df)\nenc_stroke_df = pd.get_dummies(clean_stroke_df, columns=categorical_cols)\nprint('One Hot Encoded Data:')\ndisplay(enc_stroke_df)","f754827f":"# Over sample minority class\r\nfeature_cols = [x for x in enc_stroke_df.columns if x not in {'stroke', 'id'}]\r\ntarget_col = 'stroke'\r\n\r\nsmote = SMOTE()\r\nx_smote, y_smote = smote.fit_resample(enc_stroke_df[feature_cols], enc_stroke_df[[target_col]])\r\n\r\nsmoted_df = pd.concat([x_smote, y_smote], axis=1)\r\n\r\nplt.style.use('ggplot')\r\nfig, ax = plt.subplots(2, 1, figsize=(16,10))\r\nax[0].bar(x=stroke_df[target_col].astype(str).unique(), height=stroke_df[target_col].value_counts(), color='tab:blue')\r\nax[0].set_title('Original')\r\nax[1].bar(x=smoted_df[target_col].astype(str).unique(), height=smoted_df[target_col].value_counts(), color='tab:blue')\r\nax[1].set_title('SMOTE')\r\n\r\nplt.show()","cf87bf08":"# Test train splits\r\ntrain_df, test_df = train_test_split(smoted_df, test_size=0.2)\r\n# Convert to numpy arrays\r\nx_train = train_df[feature_cols].to_numpy()\r\ny_train = train_df[target_col].to_numpy()\r\nx_test = test_df[feature_cols].to_numpy()\r\ny_test = test_df[target_col].to_numpy()\r\n\r\n# Initialise list to hold model f1 scores\r\nf1_results = list()\r\n\r\n# Boolean flag to perform grid search (True) or use predetermined parameters (False) \r\ngrid_search = False","84a4bddd":"# Define function for generating confusion matrix with Precision-Recall and ROC curves\r\ndef score_model(model,\r\n                train_label,\r\n                test_label,\r\n                train_pred,\r\n                test_pred,\r\n                train_pred_proba,\r\n                test_pred_proba):\r\n    for heading, label_actual, label_pred, label_pred_prob in zip(['TRAINING SET', 'TEST SET'], [train_label, test_label], [train_pred, test_pred], [train_pred_proba, test_pred_proba]):\r\n        print('\\n{:s}'.format(heading))\r\n        cm = metrics.confusion_matrix(label_actual, label_pred)\r\n        if len(cm) == 1:\r\n            cm = [[cm[0][0], 0], [0, 0]]\r\n        df_cm = pd.DataFrame(cm, index=['Actual no', 'Actual yes'], columns=['Predicted no', 'Predicted yes'])\r\n        display(df_cm)\r\n        print('Precision: {:,.1f}%'.format(metrics.precision_score(label_actual, label_pred) * 100))\r\n        print('Recall: {:,.1f}%'.format(metrics.recall_score(label_actual, label_pred) * 100))\r\n        print('ROC AUC: {:.2f}'.format(metrics.roc_auc_score(label_actual, label_pred_prob)))\r\n        print('Average Precision: {:.2f}'.format(metrics.average_precision_score(label_actual, label_pred_prob)))\r\n        print('')\r\n\r\n    fig, ax = plt.subplots(2, 1, figsize=(16,10))\r\n    # Plot Precision-Recall Curve\r\n    baseline_precision = len([x for x in y_test if x==1]) \/ len(y_test)\r\n    ax[0].plot([0, 1], [baseline_precision, baseline_precision], 'k', linestyle='--', label='Baseline (AP: {:.2f})'.format(baseline_precision))\r\n    metrics.plot_precision_recall_curve(model, x_train, y_train, color='b', ax=ax[0]);\r\n    metrics.plot_precision_recall_curve(model, x_test, y_test, color='r', ax=ax[0]);\r\n    ax[0].set_xlabel('Recall (True Positive Rate)', fontsize=12)\r\n    ax[0].set_ylabel('Precision', fontsize=12)\r\n    ax[0].set_title('Precision-Recall Curves', fontsize=14)\r\n    ax[0].set_xlim([-.05,1.05])\r\n    ax[0].set_ylim([-.05,1.05])\r\n    ax[0].tick_params(labelsize=10)\r\n\r\n    # Plot ROC curve\r\n    ax[1].plot([0, 1], [0, 1], 'k', linestyle='--', label='Baseline (ROC score: 0.5)')\r\n    train_fpr, train_tpr, _ = metrics.roc_curve(y_train, y_train_pred_proba)\r\n    test_fpr, test_tpr,  _ = metrics.roc_curve(y_test, y_test_pred_proba)\r\n    ax[1].plot(train_fpr, train_tpr, 'b', label='Train (ROC score: {:.2f})'.format(metrics.roc_auc_score(y_train, y_train_pred_proba)))\r\n    ax[1].plot(test_fpr, test_tpr,  'r', label='Test (ROC score: {:.2f})'.format(metrics.roc_auc_score(y_test, y_test_pred_proba)))\r\n    ax[1].legend()\r\n    ax[1].set_xlabel('False Positive Rate', fontsize=12)\r\n    ax[1].set_ylabel('True Positive Rate (Recall)', fontsize=12)\r\n    ax[1].set_title('ROC Curves', fontsize=14)\r\n\r\n    plt.show()","1c024a38":"# XgBoost Model\r\nprint('XgBoost Model')\r\n\r\nif grid_search:\r\n    param_grid = {\r\n        'learning_rate': [x \/ 10 for x in range(2, 9, 1)],\r\n        'max_depth': range(5, 30, 5),\r\n        'min_child_weight': range(1, 3, 1),\r\n        'subsample': [x \/ 10 for x in range(7, 11, 1)]\r\n    }\r\n\r\n    init_clf = xgb.XGBClassifier(\r\n        n_estimators=300,\r\n        use_label_encoder=False,\r\n        objective='binary:logistic',\r\n        n_jobs=-1, \r\n        verbosity=0\r\n    )\r\n\r\n    gscv = GridSearchCV(\r\n        estimator=init_clf,\r\n        param_grid=param_grid,\r\n        scoring='f1',\r\n        n_jobs=1,\r\n        refit=True,\r\n        cv=5,\r\n        verbose=4\r\n    )\r\n    gscv.fit(x_train, y_train)\r\n\r\n    bst = gscv.best_estimator_\r\n    print(f'Best Score (f1): {gscv.best_score_}')\r\n    print('Grid searched parameters:')\r\n    display(gscv.best_params_)\r\nelse:\r\n    bst = xgb.XGBClassifier(\r\n        n_estimators=300,\r\n        use_label_encoder=False,\r\n        objective='binary:logistic', \r\n        learning_rate=0.3,\r\n        max_depth=20,\r\n        min_child_weight=1,\r\n        subsample=0.8,\r\n        n_jobs=-1, \r\n        verbosity=1\r\n    )\r\n\r\n    bst.fit(x_train, y_train)\r\n\r\n# Prediction\r\ny_train_pred_proba = bst.predict(x_train)\r\ny_test_pred_proba = bst.predict(x_test)\r\ny_train_pred = [int(x > 0.5) for x in y_train_pred_proba]\r\ny_test_pred = [int(x > 0.5) for x in y_test_pred_proba]\r\n\r\ny_train = list(train_df[target_col])\r\ny_test = list(test_df[target_col])\r\n\r\nscore_model(bst, y_train, y_test, y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba)\r\n\r\nxgb.plot_importance(bst)\r\nf1_results.append(('XgBoost', metrics.f1_score(y_test, y_test_pred)))","49fd6f2e":"# Random Forest\r\nprint('Random Forest Model')\r\n\r\nif grid_search:\r\n    param_grid = {\r\n        'criterion': ['gini'],\r\n        'max_depth': range(15, 30, 5),\r\n        'min_samples_split': range(2, 5, 1),\r\n        'min_samples_leaf': range(1, 4, 1),\r\n        'max_features': ['sqrt', None],\r\n        'ccp_alpha': [x \/ 1000 for x in range(0, 25, 5)],\r\n        'max_samples': [0.9, None]\r\n    }\r\n\r\n    init_rfc = RandomForestClassifier(\r\n        n_estimators=300,\r\n        bootstrap=True,\r\n        n_jobs=-1,\r\n        verbose=0,\r\n        random_state=73\r\n    )\r\n\r\n    gscv = GridSearchCV(\r\n        estimator=init_rfc,\r\n        param_grid=param_grid,\r\n        scoring='f1',\r\n        n_jobs=1,\r\n        refit=True,\r\n        cv=5,\r\n        verbose=4\r\n    )\r\n    gscv.fit(x_train, y_train)\r\n\r\n    rfc = gscv.best_estimator_\r\n    print(f'Best Score (f1): {gscv.best_score_}')\r\n    print('Grid searched parameters:')\r\n    display(gscv.best_params_)\r\nelse:\r\n    rfc = RandomForestClassifier(\r\n        criterion='gini',\r\n        n_estimators=300,\r\n        max_depth=15,\r\n        min_samples_split=3,\r\n        min_samples_leaf=1,\r\n        max_features='sqrt',\r\n        bootstrap=True,\r\n        n_jobs=-1,\r\n        verbose=1,\r\n        ccp_alpha=0.0,\r\n        random_state=73\r\n    )\r\n    rfc.fit(x_train, y_train)\r\n\r\n# Prediction\r\ny_train_pred_proba = rfc.predict_proba(x_train)[:, 1]\r\ny_test_pred_proba = rfc.predict_proba(x_test)[:, 1]\r\ny_train_pred = rfc.predict(x_train)\r\ny_test_pred = rfc.predict(x_test)\r\n\r\ny_train = list(train_df[target_col])\r\ny_test = list(test_df[target_col])\r\n\r\nscore_model(rfc, y_train, y_test, y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba)\r\n\r\ndisplay(pd.DataFrame({\r\n    'Feature': feature_cols,\r\n    'Importance': rfc.feature_importances_\r\n}).sort_values(by='Importance', ascending=False, inplace=False))\r\n\r\nf1_results.append(('Random Forest', metrics.f1_score(y_test, y_test_pred)))","a26fc836":"# Logistic Regression\r\nprint('Logistic Regression Model')\r\n\r\nif grid_search:\r\n    param_grid = {\r\n        'tol': [0.00005, 0.0001, 0.00015],\r\n        'max_iter': range(100, 1100, 100)\r\n    }\r\n\r\n    init_clf = LogisticRegression(\r\n        n_jobs=-1,\r\n        verbose=0,\r\n        random_state=73\r\n    )\r\n\r\n    gscv = GridSearchCV(\r\n        estimator=init_clf,\r\n        param_grid=param_grid,\r\n        scoring='f1',\r\n        n_jobs=1,\r\n        refit=True,\r\n        cv=5,\r\n        verbose=4\r\n    )\r\n    gscv.fit(x_train, y_train)\r\n\r\n    clf = gscv.best_estimator_\r\n    print(f'Best Score (f1): {gscv.best_score_}')\r\n    print('Grid searched parameters:')\r\n    display(gscv.best_params_)\r\nelse:\r\n    clf = LogisticRegression(\r\n        tol=0.00005,\r\n        max_iter=800,\r\n        n_jobs=-1,\r\n        verbose=1,\r\n        random_state=73\r\n    )\r\n    clf.fit(x_train, y_train)\r\n\r\n# Prediction\r\ny_train_pred_proba = clf.predict_proba(x_train)[:, 1]\r\ny_test_pred_proba = clf.predict_proba(x_test)[:, 1]\r\ny_train_pred = clf.predict(x_train)\r\ny_test_pred = clf.predict(x_test)\r\n\r\ny_train = list(train_df[target_col])\r\ny_test = list(test_df[target_col])\r\n\r\nscore_model(clf, y_train, y_test, y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba)\r\n\r\ndisplay(clf.get_params())\r\n\r\ndisplay(pd.DataFrame({\r\n    'Feature': feature_cols,\r\n    'Coefficient': clf.coef_[0]\r\n}))\r\n\r\nf1_results.append(('Logistic Regression', metrics.f1_score(y_test, y_test_pred)))","21500def":"f1_results.sort(key=lambda x: x[1], reverse=True)\ndisplay(f1_results)","6ad4b8a9":"# Stroke Prediction Exploration\nDataset from Kaggle: https:\/\/www.kaggle.com\/fedesoriano\/stroke-prediction-dataset"}}