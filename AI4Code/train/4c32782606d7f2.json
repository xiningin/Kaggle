{"cell_type":{"55babd0e":"code","b5de5857":"code","9e65d53e":"code","eb026a50":"code","4e5da6a7":"code","bc3fb164":"code","666bd5a7":"code","1613fa47":"code","8c7b7c50":"code","b2bed964":"code","1e084a68":"code","fa20f152":"code","28148c7b":"code","b12460e7":"markdown","e2a22413":"markdown","ac3d5eaf":"markdown","07707d41":"markdown","67d62d60":"markdown","6c1cc7e3":"markdown","1ebfcf1d":"markdown"},"source":{"55babd0e":"from transformers import DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('\/kaggle\/input\/distilberttokenizerfast-tokenizer\/')","b5de5857":"import torch\nfrom transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nMODEL_PATH = '\/kaggle\/input\/huggingface-distilbertclassification-starter\/checkpoints\/'\nmodel = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH).to(device)","9e65d53e":"import pandas as pd\nimport os.path as osp\nfrom tqdm import tqdm","eb026a50":"INPUT_PATH = '\/kaggle\/input\/jigsaw-toxic-severity-rating\/'\n\nsample_submission = pd.read_csv(osp.join(INPUT_PATH, 'sample_submission.csv'))\nvalidation_data = pd.read_csv(osp.join(INPUT_PATH, 'validation_data.csv'))\ncomments_to_score = pd.read_csv(osp.join(INPUT_PATH, 'comments_to_score.csv'))\ncomments_to_score['score'] = 0\ncomments_to_score.head()","4e5da6a7":"validation_data","bc3fb164":"validation_data['correct'] = 0\n\nfor i in tqdm(range(len(validation_data))):\n    input = tokenizer.encode(validation_data.iloc[i]['less_toxic'], return_tensors=\"pt\").to(device)\n    output = model(input[:, :512])[0]\n    prediction_less = torch.softmax(output, dim=1)[0][1].item()\n    \n    input = tokenizer.encode(validation_data.iloc[i]['more_toxic'], return_tensors=\"pt\").to(device)\n    output = model(input[:, :512])[0]\n    prediction_more = torch.softmax(output, dim=1)[0][1].item()\n    validation_data.loc[i, 'correct'] = 1 if prediction_more > prediction_less else 0","666bd5a7":"print('Valid Score: ', round(validation_data['correct'].mean(), 3))","1613fa47":"x = 0\nfor i in tqdm(range(len(comments_to_score))):\n    input = tokenizer.encode(comments_to_score.iloc[i]['text'], return_tensors=\"pt\").to(device)\n    output = model(input[:, :512])[0]\n    predictions = torch.softmax(output, dim=1)\n    comments_to_score.loc[i, 'score'] = predictions[0][1].item()","8c7b7c50":"comments_to_score['score'] = comments_to_score['score'].rank(method='first')","b2bed964":"comments_to_score.sort_values('score')","1e084a68":"sample_submission['score'] = comments_to_score.sort_values('comment_id')['score']","fa20f152":"sample_submission","28148c7b":"sample_submission.to_csv('submission.csv', index=False)","b12460e7":"Upside is nontoxic text, downside is toxic text.","e2a22413":"# [Training Notebook : https:\/\/www.kaggle.com\/adldotori\/huggingface-distilbertclassification-starter](https:\/\/www.kaggle.com\/adldotori\/huggingface-distilbertclassification-starter)","ac3d5eaf":"## Tokenizer","07707d41":"# Load","67d62d60":"# Validation","6c1cc7e3":"## Model","1ebfcf1d":"# Inference"}}