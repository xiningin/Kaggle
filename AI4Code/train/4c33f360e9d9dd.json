{"cell_type":{"a52916a8":"code","cadf6ffa":"code","d22033cc":"code","30d46dbf":"code","7c1f7e04":"code","029e3b69":"code","b77a1c75":"code","45f58e3a":"code","99f07cf4":"code","ace5ac37":"code","00d21697":"code","c8ecc0e9":"code","6e1c20bd":"code","0a9508f0":"code","7b8a7d62":"code","09a6537a":"code","6a9de4d0":"code","76b9500a":"code","9411991c":"code","35a51f09":"code","e7ba1e9f":"code","5f33a132":"code","03ba3417":"markdown","fbebbe5f":"markdown","597b997d":"markdown","34f973fe":"markdown","fff767b5":"markdown","96660e9b":"markdown","5ec904ef":"markdown","4b315607":"markdown","e22022fc":"markdown","235c2775":"markdown","2877f566":"markdown","577ceb61":"markdown"},"source":{"a52916a8":"#Used IterativeImputer, able to jump 100 positions. Please upvote if you like. \n#Thanks to my team mate Yaswath for using his notebook \n#Thanks to Rob Mula for providing insight in Iterative Imputer","cadf6ffa":"#Import necessay libraries\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n#Preprocessing\nfrom sklearn import model_selection,metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler,RobustScaler\n#Model\nfrom sklearn.metrics import mean_squared_error,roc_auc_score\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor","d22033cc":"#import the data and shape\ntrain = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nsample=pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")\nprint(train.shape,test.shape)\ntrain.describe()\n","30d46dbf":"train.info()","7c1f7e04":"from sklearn.experimental import enable_iterative_imputer  \nfrom sklearn.impute import IterativeImputer\n# Drop Null values & ID as they are not useful\nimputer = IterativeImputer()\n\ntrain_temp = pd.DataFrame(imputer.fit_transform(train))\ntest_temp = pd.DataFrame(imputer.fit_transform(test))\n\ntrain_temp.columns = train.columns\ntest_temp.columns = test.columns\n\ntrain = train_temp\ntest = test_temp\n\n#print(train.isnull().sum())\n\n#print(test.isnull().sum())","029e3b69":"#Splliting  the kfold columns\ntrain['kfold'] = -1\n#distributing the data\nkfold = KFold(n_splits = 5,shuffle=True,random_state = 42)\nfor fold, (tr_i,va_i) in enumerate(kfold.split(X=train)):\n    train.loc[va_i,'kfold'] = fold\n    \nprint(train.kfold.value_counts())\ntrain.to_csv(\"folds_5.csv\",index=False)\nprint(\"successfully folds\")\n","b77a1c75":"train.isnull().sum()","45f58e3a":"df = pd.read_csv(\".\/folds_5.csv\")\n\n#features taken to train\nfeatures = [f for f in df.columns if f not in(\"id\",\"kfold\",\"song_popularity\")]\ntest= test[features]\n","99f07cf4":"#Since the columns are of different size we are scaling them\nlE = RobustScaler()\ndf[features] = lE.fit_transform(df[features])\ntest[features] = lE.transform(test[features])","ace5ac37":"df.head()","00d21697":"final_test_preds=[]\nfinal_valid_preds={}\nscores=[]\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    \n    ytrain=xtrain.song_popularity\n    yvalid=xvalid.song_popularity\n    \n    xtrain=xtrain[features]\n    xvalid=xvalid[features]\n    \n    #Model hyperparameter of XGboostRegressor\n    #lgb parameters\n    lgb_params={\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 3,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':5000,\n    'colsample_bytree':0.1107\n    }\n    \n    model =LGBMRegressor(**lgb_params)\n    model.fit(xtrain,ytrain,verbose=20)\n    \n    preds_valid=model.predict(xvalid)\n    preds_test=model.predict(xtest[features])\n    \n    final_test_preds.append(preds_test)\n    final_valid_preds.update(dict(zip(valid_id,preds_valid)))\n    \n    roc1= roc_auc_score(yvalid,preds_valid)\n    #Score \n    scores.append(roc1)\n    print(f\"fold|split:{fold},roc:{roc1}\")\n    \n    \nprint(np.mean(scores))\nfinal_valid_pred1=pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_pred1.columns=['id',\"preds_1\"]\nfinal_valid_pred1.to_csv('train_pred_1.csv',index=False)\n    \ny=np.mean(np.column_stack(final_test_preds),axis=1)\ntest_preds1=pd.DataFrame(y,columns=['test_preds1'])\ntest_preds1['id']=test_preds1.index\ntest_preds1.columns=['preds_1','id']\ntest_preds1.to_csv(\"test_preds1.csv\",index=False)\n    ","c8ecc0e9":"final_test_preds=[]\nfinal_valid_preds={}\nscores=[]\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    \n    ytrain=xtrain.song_popularity\n    yvalid=xvalid.song_popularity\n    \n    xtrain=xtrain[features]\n    xvalid=xvalid[features]\n    \n    #Model hyperparameter of XGboostRegressor\n    #lgb parameters\n    \n    xgb_params={'max_depth': 12,\n     'n_estimators': 14100,\n     'learning_rate': 0.044007386636126064,\n     'subsample': 0.6000000000000001,\n     'colsample_bytree': 0.8,\n     'colsample_bylevel': 0.2,\n     'min_child_weight': 1.8449117383488298,\n     'reg_lambda': 0.00011083907926362916,\n     'reg_alpha': 0.001115661040317592,\n     'gamma': 3.379722475408119}\n    model =XGBRegressor(**xgb_params)\n    model.fit(xtrain,ytrain,verbose=20)\n    \n    preds_valid=model.predict(xvalid)\n    preds_test=model.predict(xtest[features])\n    \n    final_test_preds.append(preds_test)\n    final_valid_preds.update(dict(zip(valid_id,preds_valid)))\n    \n    roc1= roc_auc_score(yvalid,preds_valid)\n    #Score \n    scores.append(roc1)\n    print(f\"fold|split:{fold},roc:{roc1}\")\n    \n    \nprint(np.mean(scores))\nfinal_valid_pred2=pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_pred2.columns=['id',\"preds_2\"]\nfinal_valid_pred2.to_csv('train_pred_2.csv',index=False)\n    \ny=np.mean(np.column_stack(final_test_preds),axis=1)\ntest_preds2=pd.DataFrame(y,columns=['test_preds1'])\ntest_preds2['id']=test_preds2.index\ntest_preds2.columns=['preds_2','id']\ntest_preds2.to_csv(\"test_preds2.csv\",index=False)\n    ","6e1c20bd":"final_test_preds=[]\nfinal_valid_preds={}\nscores=[]\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    \n    ytrain=xtrain.song_popularity\n    yvalid=xvalid.song_popularity\n    \n    xtrain=xtrain[features]\n    xvalid=xvalid[features]\n    \n    #Model hyperparameter of catboostRegressor\n    #cat parameters\n    \n    model= CatBoostRegressor()\n    model.fit(xtrain,ytrain,verbose=20)\n    \n    preds_valid=model.predict(xvalid)\n    preds_test=model.predict(xtest[features])\n    \n    final_test_preds.append(preds_test)\n    final_valid_preds.update(dict(zip(valid_id,preds_valid)))\n    \n    roc1= roc_auc_score(yvalid,preds_valid)\n    #Score \n    scores.append(roc1)\n    print(f\"fold|split:{fold},roc:{roc1}\")\n    \n    \nprint(np.mean(scores))\nfinal_valid_pred3=pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_pred3.columns=['id',\"preds_3\"]\nfinal_valid_pred3.to_csv('train_pred_3.csv',index=False)\n    \ny=np.mean(np.column_stack(final_test_preds),axis=1)\ntest_preds3=pd.DataFrame(y,columns=['test_preds3'])\ntest_preds3['id']=test_preds3.index\ntest_preds3.columns=['preds_3','id']\ntest_preds3.to_csv(\"test_preds3.csv\",index=False)\n    ","0a9508f0":"test['id']=test.index","7b8a7d62":"train1=pd.read_csv(\".\/train_pred_1.csv\")\ntrain2=pd.read_csv(\".\/train_pred_2.csv\")\ntrain3=pd.read_csv(\".\/train_pred_3.csv\")\n\ntest1=pd.read_csv(\".\/test_preds1.csv\")\ntest2=pd.read_csv(\".\/test_preds2.csv\")\ntest3=pd.read_csv(\".\/test_preds3.csv\")\n\n\ndf=df.merge(train1,on=\"id\",how=\"left\")\ndf=df.merge(train2,on=\"id\",how=\"left\")\ndf=df.merge(train3,on=\"id\",how=\"left\")\n\ntest=test.merge(test1,on=\"id\",how=\"left\")\ntest=test.merge(test2,on=\"id\",how=\"left\")\ntest=test.merge(test3,on=\"id\",how=\"left\")","09a6537a":"final_features=['preds_1','preds_2','preds_3']\ntarget=df['song_popularity']","6a9de4d0":"lgb_params={\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 3,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':5000,\n    'colsample_bytree':0.1107\n    }\n    \nfinal_model =LGBMRegressor(**lgb_params)\nfinal_model.fit(df[final_features],df['song_popularity'])","76b9500a":"final_preds=final_model.predict(test[final_features])","9411991c":"sub=pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")\nsub.head()","35a51f09":"sub.song_popularity=final_preds","e7ba1e9f":"sub.head()","5f33a132":"sub.to_csv(\"submission.csv\",index=False)","03ba3417":"## **Read the Data**","fbebbe5f":"# LGBM","597b997d":"Implementation of Iterative Imputer","34f973fe":"# Final model and features","fff767b5":"# Importing the libraries","96660e9b":"## **Applying lgbm_Imputers**","5ec904ef":"### Refer to the session by Rob mulla for more info about this imputation","4b315607":"# XGBoost","e22022fc":"## **Build_Model**","235c2775":"Used IterativeImputer, able to jump 100 positions. Please upvote if you like.\nThanks to my team mate Yaswath for using his notebook\nThanks to Rob Mula for providing insight in Iterative Imputer","2877f566":"# Catboost","577ceb61":"## **Feature Separation**"}}