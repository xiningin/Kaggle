{"cell_type":{"c343722b":"code","c4feab35":"code","a11fcbf7":"code","90ec3942":"code","f68f9fbf":"code","4ad4f985":"code","b988f189":"code","64756369":"code","c01040d0":"code","75614229":"code","5df9c057":"code","2f7db5be":"code","5e0e3ff9":"code","518f6f61":"code","07fdf117":"code","c3a1f549":"code","f0853ea7":"code","3902b919":"code","94fa3834":"code","66642686":"code","a4ce5546":"code","ae7bb450":"code","2deaa54d":"code","eb53b275":"code","3bfe0794":"code","c8eba086":"code","8a2898b8":"code","569a5afd":"code","bf1a5118":"code","e5684e75":"code","712dbe4d":"code","3f839bec":"code","3bd5f278":"code","84ae8354":"code","2cf0d0ee":"markdown","63aa27d3":"markdown","2fe1f753":"markdown","90bb4c53":"markdown","8f99e053":"markdown","c66ed0b1":"markdown","d3e44ccd":"markdown"},"source":{"c343722b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4feab35":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nsns.set()\nimport numpy as np\nfrom tensorflow.keras import layers\n","a11fcbf7":"df = pd.read_csv('http:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/ecg.csv', header=None)\ndf.head()","90ec3942":"#Now we will separate the data and labels so that it will be easy for us\ndata = df.iloc[:,:-1].values\nlabels = df.iloc[:,-1].values\nlabels","f68f9fbf":"pd.Series(labels).value_counts()","4ad4f985":"from sklearn.model_selection import train_test_split\ntrain_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = 0.2, random_state = 42)","b988f189":"# now lets normalise the data to bring them into a same range and it will make it comparable\n\n# we can use min_max scalar or we can use our own formula\n","64756369":"#Now lets Normalize the data\n#First we will calculate the maximum and minimum value from the training set \nimport tensorflow as tf\nmin = np.min(train_data)\nmax = np.max(train_data)\n\n#Now we will use the formula (data - min)\/(max - min)\ntrain_data_normalised = (train_data - min)\/(max - min)\ntest_data_normalised = (test_data - min)\/(max - min)\n","c01040d0":"# lets try other method of scaling \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_scaled = scaler.fit(train_data)\ntrain_data_norm = data_scaled.transform(train_data)\ntest_data_norm = data_scaled.transform(test_data)","75614229":"train_data_normalised","5df9c057":"# now lets change the labels into True and False and seperate anamoulous and normal ECG\n# note: we will only train Encoder-decoder model on the normal ECGs\n","2f7db5be":"train_labels, test_labels = train_labels.astype(bool), test_labels.astype(bool)","5e0e3ff9":"#Now let's separate the data for normal ECG from that of abnormal ones\n#Normal ECG data\nn_train_data = train_data_normalised[train_labels]\nn_test_data = test_data_normalised[test_labels]\n","518f6f61":"#Abnormal ECG data\nan_train_data = train_data[~train_labels]\nan_test_data = test_data[~test_labels]","07fdf117":"#Lets plot a normal ECG\nplt.plot(np.arange(140), n_train_data[0])\nplt.grid()\nplt.title('Normal ECG')\n\nplt.show()","c3a1f549":"#Lets plot one from abnormal ECG\nplt.plot(np.arange(140), an_train_data[0])\nplt.grid()\nplt.title('Abnormal ECG')\nplt.show()\n","f0853ea7":"#Now let's define the model!\n#Here I have used the Model Subclassing API (but we can also use the Sequential API)\n#The model has 2 parts : 1. Encoder and 2. Decoder\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf \nclass detector(Model):\n  def __init__(self):\n    super(detector, self).__init__()\n    self.encoder = tf.keras.Sequential([\n                                        layers.Dense(32, activation='relu'),\n                                        layers.Dense(16, activation='relu'),\n                                        layers.Dense(8, activation='relu')\n    ])\n    self.decoder = tf.keras.Sequential([\n                                        layers.Dense(16, activation='relu'),\n                                        layers.Dense(32, activation='relu'),\n                                        layers.Dense(140, activation='sigmoid')\n    ])\n\n  def call(self, x):\n    encoded = self.encoder(x)\n    decoded = self.decoder(encoded)\n    return decoded","3902b919":"#Let's compile and train the model!!\nautoencoder = detector()\nautoencoder.compile(optimizer='adam', loss='mae')\nautoencoder.fit(n_train_data, n_train_data, epochs = 60, batch_size=512, \n                validation_data=(n_test_data, n_test_data))","94fa3834":"#Now let's define a function in order to plot the original ECG and reconstructed ones and also show the error\ndef plot(data, n):\n  enc_img = autoencoder.encoder(data) # this will encode in lower dim\n  dec_img = autoencoder.decoder(enc_img) # this will decode or reconstruct\n  plt.plot(data[n], 'b')\n  plt.plot(dec_img[n], 'r')\n  plt.fill_between(np.arange(140), data[n], dec_img[n], color = 'lightcoral')\n  plt.legend(labels=['Input', 'Reconstruction', 'Error'])\n  plt.show()\n\nplot(n_test_data, 0) # here n shows the index of ecg samples\nplot(an_test_data, 0)","66642686":"test_data_normalised[0].shape","a4ce5546":"from tensorflow.keras import layers, losses\n\nreconstructed = autoencoder(n_train_data)\ntrain_loss = losses.mae(reconstructed, n_train_data).numpy()\n","ae7bb450":"plt.hist(train_loss, bins = 50)\nplt.show()","2deaa54d":"mean_error = np.mean(train_loss)\nmean_error","eb53b275":"std_error = np.std(train_loss)\nstd_error","3bfe0794":"threshold = mean_error + 5*std_error\nthreshold","c8eba086":"# lets test out our threshold\nreconstructed = autoencoder(an_test_data)\ntrain_loss_a = losses.mae(reconstructed, an_test_data).numpy()\nplt.hist(train_loss_a, bins = 50)\nplt.show()","8a2898b8":"plt.hist(train_loss, bins = 50, label = 'normal')\nplt.hist(train_loss_a, bins = 50, label = 'abnormal')\nplt.axvline(threshold, color = 'r', linewidth = 3, linestyle = 'dashed', label = '{:0.3f}'.format(threshold))\nplt.legend(loc = 'upper right')\nplt.show()\n","569a5afd":"print('mean error train normal',np.mean(train_loss))\nprint('man error train abnormal', np.mean(train_loss_a))","bf1a5118":"tf.math.less(train_loss, threshold).numpy() # values less than threshold","e5684e75":"preds = tf.math.less(train_loss, threshold).numpy()\n","712dbe4d":"# tf.math.count_nonzero(preds).numpy()\npreds.sum() # it will add all the true values\nprint('correctly classified as normal', preds.sum())\nprint('length of the data', len(preds))\nprint('wrongly classified',len(preds)-preds.sum())","3f839bec":"preds_anamoly = tf.math.greater(train_loss_a, threshold).numpy()\npreds_anamoly.sum()","3bd5f278":"len(train_loss_a)","84ae8354":"print('anamoly correctly classified', len(train_loss_a))\nprint('number of abnormal samples', len(train_loss_a))\n# here all correctly classified ","2cf0d0ee":"here according to our need we can set our threshold ","63aa27d3":"NOTE: See that in fit() both the data are same i.e. n_train_data, the reason is that we will be comparing the original ECG with the reconstructed one to calculate the reconstruction error. Autoencoders are unsupervised learning models but here we are training them using supervised method so its more like they are used as self-supervised","2fe1f753":"##### in this notebook we will look at anamoly detection using encode-decoder model","90bb4c53":"**This model uses an Autoencoder architecture for anomaly detection**\n\nAutoencoders are a specific type of feedforward neural network.It compresess the input into a so-called \"code\" of lower dimensionality and then tries to reconstruct the output from this code.It is an **unsupervised** learning model. \n\nIt consists of two parts:-\n1.Encoder\n2.Decoder\n\n\nSo in simple terms we provide an input to the autoencoder and it tries to re-create it.\n\nFor a detailed information refer to the article in link https:\/\/towardsdatascience.com\/applied-deep-learning-part-3-autoencoders-1c083af4d798\n\n**So how the model will detect anomaly ?**\n\nWe will create an encoder and a decoder using an ANN architecture.We are going to provide the ECG data as input and the model will try to reconstruct it. The error between the original data and reconstructed output will be called the **reconstruction error**.Based on this recostruction error we are going to classify an ECG as anomalous or not.In order to do this we are going to train the model only on the normal ECG data but it will be tested on the full test set, so that when an abnormal ECG is provided in the input the autoencoder will try to reconstruct it but since it has been only trained on normal ECG data the output will have a larger reconstruction error. We will also define a minimum threshold for the error i.e. if the reconstruction error is above the threshold then it will be categorised as anomalous. \n\nBefore we make the model another thing that I want to clarify is that I will be using the **Subclassing API** of keras for making the model.\nIn keras there are mainly 3 APIs for defining a model :-\n\n* 1.Sequential API\n\n* 2.Functional API\n\n* 3.Subclassing API\n\nThe reason I used Subclassing API is that it provides a good control over the model as compared to Sequential API because in sequential API the add funcion implicitly passes the output of one layer into the next and u just get the output from the final layer but in case  of subclassing API the forward pass is explicitly defined as you can see in the **call()** function. For this problem this api suits best. \n\nThe subclassing api is used to create a model class called **detector**(in this case) it inherits from the **Model** class of keras from which both sequential model and functional api also inherit. First using super() we pass the parameters to the parent class then we define out constructor which has the encoder and decoder. Then we implement the forward pass in the call() function. \n\nFor a better understanding refer to this article https:\/\/towardsdatascience.com\/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3","8f99e053":"### Improvement\n* we can use LSTM for further more accurate results\n* use CNN instead of DNN\n* threshold must be set by plottinng the histogram ","c66ed0b1":"As I mentioned earlier an ECG is anomalous if it is greater than a threshold. We can set the threshold in any way we want. Here I am going to set it to one standard deviation from the mean of normal training data.","d3e44ccd":"this data comes with 140 points and the values is given and the class is given at the last of the dataset at 140th columns \nif its 0 means normal otherwise abnormal"}}