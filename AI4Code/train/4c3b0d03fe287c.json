{"cell_type":{"dc7db28d":"code","ca28aae7":"code","55029578":"code","4d38ed44":"code","08277f9e":"code","77f8952e":"code","488f36ab":"code","3824dff2":"code","b1f15b32":"code","cffdde87":"code","56e5a212":"code","5d71dd0b":"code","b2ca4b44":"code","e953157f":"code","68aed301":"code","88cc3810":"code","cda8411c":"code","2e1104aa":"code","0ef62e39":"markdown","3fb93cb3":"markdown","dfb5c904":"markdown","b8c94f93":"markdown","d152faeb":"markdown","d1ef5ed3":"markdown"},"source":{"dc7db28d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca28aae7":"import seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","55029578":"df = pd.read_csv('\/kaggle\/input\/logistic-regression-heart-disease-prediction\/framingham_heart_disease.csv')\ndf.head()","4d38ed44":"df.head()","08277f9e":"df_d = df[['male', 'age','currentSmoker', 'cigsPerDay', 'BPMeds',\n       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n       'diaBP', 'BMI', 'heartRate', 'glucose','TenYearCHD']]","77f8952e":"df_d.head()","488f36ab":"sns.heatmap(df_d.corr())","3824dff2":"df_data = pd.get_dummies(df_d,columns = ['currentSmoker','prevalentHyp','diabetes'])\ndf_data.dropna(inplace = True)\n","b1f15b32":"df_data.head()","cffdde87":"def MaxStandr (col_list):\n    for col in col_list :\n        df_data[col] = df_data[col]\/df_data[col].max()\n        ","56e5a212":"MaxStandr(['cigsPerDay','totChol','sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose'])","5d71dd0b":"X = df_data[['cigsPerDay','totChol',\n       'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'currentSmoker_0',\n       'currentSmoker_1', 'prevalentHyp_0', 'prevalentHyp_1', 'diabetes_0',\n       'diabetes_1']]\ny = df_data['TenYearCHD']","b2ca4b44":"total = X['BMI'].count()\ntrain_count = int(round(total*0.8))\ntest_count = total-train_count ","e953157f":"X_train = X[:train_count]\nY_train = y[:train_count]\nX_test = X[train_count:]\nY_test = np.array(y[train_count:])","68aed301":"clf = LogisticRegression(solver='saga').fit(X_train, Y_train)\ny_hat = clf.predict(X_test)\n","88cc3810":"cnf_matrix = metrics.confusion_matrix(Y_test,y_hat)\ncnf_matrix","cda8411c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","2e1104aa":"print(\"Accuracy:\",metrics.accuracy_score(Y_test,y_hat))\nprint(\"Precision:\",metrics.precision_score(Y_test,y_hat))\nprint(\"Recall:\",metrics.recall_score(Y_test,y_hat))","0ef62e39":"This MaxStandr mathod stnadardizes the values using Max Values.","3fb93cb3":"Checking for any coorelation with the target varibale \"TenYearCHD\".From the heat map below we are not able find any variable that has a strong correlation with traget varibale.","dfb5c904":"Train and Test data splitting","b8c94f93":"Even though the accuracy is high model is not that much perfect for classifying heart attacks.","d152faeb":"Here I am coverting few variables to categorical varibales using dummies method.And also dropping the null values.","d1ef5ed3":"From the confusion matrix above we can see that the model is able to predict very accurately for False cases and very badly for True cases."}}