{"cell_type":{"cdaf279f":"code","20c466b2":"code","2dc6d551":"code","9ed8254c":"code","b4efd63b":"code","2c83616b":"code","26f8b3ed":"code","655a85cb":"code","4e68042d":"code","ee5593ec":"code","b9df0d00":"code","dc55593a":"code","a9b2294c":"code","24f675d4":"code","f044db64":"code","3707954c":"code","08c59b25":"code","63e4f0d1":"code","4855b448":"code","8335a7ed":"code","ceba5187":"code","9b77e7cc":"code","f466278a":"code","c11b4b28":"code","4b13f55b":"code","160d46c9":"code","34767c7a":"code","da1e2f29":"code","ee453e81":"code","278d07b1":"code","25ce9f2f":"code","b470086f":"code","c2832462":"code","5dc4c989":"code","0c353b12":"code","d6f6018c":"code","f425b1b3":"code","53a064df":"code","cedabae9":"code","228f1a84":"code","e1fcc85d":"code","cf04bf1d":"code","6d52f814":"code","9d82aad9":"code","7c82916c":"code","284b4152":"code","b2c1bcff":"code","e2012c36":"code","77dc0c6d":"code","60906e77":"code","b9267bf6":"code","fb652420":"code","d851f950":"code","df2fc479":"code","ace4fdf7":"code","73fbedc7":"code","211540b1":"code","79a56160":"code","130b2161":"code","d608bdd0":"code","d0fcc7d8":"code","8b8a40fb":"code","8615d3ab":"code","1331b3d7":"code","48b685c0":"code","c4c51552":"code","f617877e":"code","561c1d67":"code","ba04a909":"markdown","1179deec":"markdown","2718bc0d":"markdown","a5adcd9b":"markdown","005d2797":"markdown","ac0ddbae":"markdown","cd66f3f0":"markdown","73821dff":"markdown","e7456ea7":"markdown","0aa8c205":"markdown"},"source":{"cdaf279f":"#Let's import necessary headers\nimport pandas as pd\nimport matplotlib as plt\n%matplotlib inline\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier as DTC","20c466b2":"#Now let start import dataset's\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","2dc6d551":"#Let's check them out\ndf_train.head()","9ed8254c":"df_test.head()","b4efd63b":"#Let's create a full dataset by combining both\n#First let's check out columns in both dataset\nprint(df_train.columns)\nprint(df_test.columns)","2c83616b":"#Now to Create full dataset\ndf_AllData = pd.concat([df_train, df_test])","26f8b3ed":"df_AllData.columns","655a85cb":"#That's great,  Let's check number of rows in All Data\nlen(df_AllData)","4e68042d":"#Now let's create unique index\ndf_AllData['Pid'] = df_AllData['PassengerId']\ndf_AllData.set_index(['Pid'], inplace=True)","ee5593ec":"#First column to process - PCLASS\n#Let's check for any null values in the column\ndf_AllData.Pclass.isnull().sum()","b9df0d00":"#Great,  We don't have any null values in the field,  Let's now see what are the values in the field.\ndf_AllData.Pclass.value_counts().plot.bar();","dc55593a":"#Let's checkout which class people survived the most in train dataset.\ndf_train.groupby('Pclass')['Survived'].mean().plot.bar();","a9b2294c":"#Looks like class 1 people had more chance that 2 and 3.\n#Let's start our first modeling\nx_train = df_train[['Pclass']]\ny = df_train['Survived']\nx_test = df_test[['Pclass']]\ndtree = DTC()\ndtree.fit(x_train,y)\nprediction = dtree.predict(x_test)\n\n#Let's add prediction results to test dataset.\ndf_test['Survived'] = prediction","24f675d4":"#We just did the prediction,  Let's prepare submission dataset for Kaggle\n(df_test[['PassengerId', 'Survived']]).to_csv('TitaticSolution_v1.csv', index=False)\n#Scored - 0.65550","f044db64":"#Let's proceed further to process column - 'Sex'\n#Check for any null values\ndf_AllData.Sex.isnull().sum()","3707954c":"#Let's check how many of them each.\ndf_AllData.Sex.value_counts().plot.bar();","08c59b25":"#Looks like we got more male passengers than female.\n#Let cross check each group survivial percentage.\ndf_train.groupby('Sex')['Survived'].mean().plot.bar();","63e4f0d1":"#Well that made clear female had more survival chance than men. I wonder how would that percentage in present day ;)\n#Let's switch string values to number in order to do our modeling.\ndf_AllData['Sex'] = df_AllData['Sex'].map({'male':0, 'female':1})","4855b448":"#Let's check the transistion\ndf_AllData.Sex.value_counts()","8335a7ed":"#That's Great,  Let's split train and test dataset from All Data.\ndf_train = df_AllData.loc[1:891,:]\ndf_test = df_AllData.loc[892:1309,:]","ceba5187":"#That's Great,  Let's improve our prediction.\nx_train = df_train[['Pclass', 'Sex']]\ny = df_train['Survived']\nx_test = df_test[['Pclass', 'Sex']]\ndtree = DTC()\ndtree.fit(x_train, y)\nprediction = dtree.predict(x_test)","9b77e7cc":"#Let's add prediction results to test dataset.\ndf_test['Survived'] = prediction.astype(int)","f466278a":"#Let's prepare submission dataset for Kaggle\n(df_test[['PassengerId', 'Survived']]).to_csv('TitaticSolution_v2.csv', index=False)\n#Scored - 0.75598","c11b4b28":"#Well let's proceed further processing column - 'Parch'\n#Checking for any null values in the column\ndf_AllData['Parch'].isnull().sum()","4b13f55b":"#Checking for values present in the columns\ndf_train.Parch.value_counts().plot.bar();","160d46c9":"#Reviewing Parch and Survived columns\ndf_train.groupby('Parch')['Survived'].mean().plot.bar();","34767c7a":"#Again let's improve our prediction using Parch\nx_train = df_train[['Pclass','Sex','Parch']]\ny = df_train['Survived']\ny_train = df_test[['Pclass','Sex','Parch']]\ndtree.fit(x_train,y)\nprediction = dtree.predict(y_train)\n\n#Let's add prediction results to test dataset.\ndf_test['Survived'] = prediction.astype(int)","da1e2f29":"(df_test[['PassengerId', 'Survived']]).to_csv('TitaticSolution_v3.csv', index=False)","ee453e81":"#Let's start processing next column - 'Embarked'\n#Let's check for any null values in the field\ndf_AllData.Embarked.isnull().sum()","278d07b1":"#Let locate the null value rows\ndf_AllData[df_AllData.Embarked.isnull()]","25ce9f2f":"#Let's find some value close to the values in rows to replace this null value for Embarked\ndf_AllData.loc[(df_AllData.Sex == 1) & (df_AllData.Survived == 1) & (df_AllData.Pclass == 1) & (df_AllData.Parch == 0) ,'Embarked'].mode()","b470086f":"df_AllData.loc[(df_AllData.Fare>79) & (df_AllData.Fare < 85),'Embarked'].mode()","c2832462":"#Let's replace the null value\ndf_AllData['Embarked'] = df_AllData['Embarked'].fillna('C')","5dc4c989":"#Time to confirm\ndf_AllData.Embarked.isnull().any()","0c353b12":"#Now to replace category value in number value for modeling\ndf_AllData['Embarked'] = df_AllData['Embarked'].map({'S':0, 'C':'1', 'Q':2})","d6f6018c":"#Checking the data again\ndf_AllData.Embarked.value_counts()","f425b1b3":"#Now to split train and test datasets\ndf_train = df_AllData.loc[1:891,:]\ndf_test = df_AllData.loc[892:1309,:]","53a064df":"#Again let's improve our model and prediction\nx_train = df_train[['Pclass', 'Sex', 'Parch', 'Embarked']]\ny = df_train['Survived']\nx_test = df_test[['Pclass', 'Sex', 'Parch', 'Embarked']]\ndtree = DTC()\ndtree.fit(x_train, y)\nprediction = dtree.predict(x_test)\n\n#Let's add prediction results to test dataset.\ndf_test['Survived'] = prediction.astype(int)","cedabae9":"(df_test[['PassengerId', 'Survived']]).to_csv('TitanicSolution_v4.csv', index=False)","228f1a84":"#Next Column to Process - FARE\n#Checking for any null vaues in the column\ndf_AllData[df_AllData.Fare.isnull()]","e1fcc85d":"#Let try to predict value for missing fare\ndf_AllData.loc[(df_AllData.Age == 60) & (df_AllData.Sex == 0) & (df_AllData.Embarked == 0) ,'Fare'].mean()","cf04bf1d":"#Lets replace null value\ndf_AllData['Fare'] = df_AllData.Fare.fillna(32.775)","6d52f814":"#Spliting Training and Test Data\n\ndf_train = df_AllData.loc[1:891,:]\ndf_test = df_AllData.loc[892:1309, :]","9d82aad9":"#Again let's improve Model and predict results\n\nx_train = df_train[['Pclass', 'Sex', 'Parch', 'Embarked', 'Fare']]\ny = df_train['Survived']\nx_test = df_test[['Pclass', 'Sex', 'Parch', 'Embarked', 'Fare']]\ndtree.fit(x_train, y)\nprediction = dtree.predict(x_test)\n\n#Let's add prediction results to test dataset.\ndf_test['Survived'] = prediction.astype(int)","7c82916c":"(df_test[['PassengerId', 'Survived']]).to_csv('TitanicSolution_v5.csv', index=False)","284b4152":"#Let's keep going. Next column to process - 'Cabin'\n#Now to check for null values\ndf_AllData.Cabin.isnull().sum()","b2c1bcff":"#Well we got more null values to process.  Let investigate further.\ndf_AllData.Cabin.value_counts(dropna = False)","e2012c36":"#Lets try to group them\ndf_AllData.Cabin.str[0].value_counts(dropna=False).plot.bar();","77dc0c6d":"#Let's categorize null values as separate category\ndf_AllData['Cabin'] = df_AllData['Cabin'].fillna('X')","60906e77":"#Now to switch category value to numeric value\ndf_AllData['Cabin'] = df_AllData['Cabin'].str[0].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'T':7, 'X':8})","b9267bf6":"#Now to split train and test dataset from all data\ndf_train = df_AllData.loc[1:891,:]\ndf_test = df_AllData.loc[892:1309,:]","fb652420":"#Let's check against their survival\ndf_train.groupby(df_train.Cabin)['Survived'].mean().plot.bar();","d851f950":"#Time to add Cabin to our model and try to predict the output\nx_train = df_train[['Pclass', 'Sex', 'Parch', 'Embarked', 'Fare', 'Cabin']]\ny = df_train['Survived']\nx_test = df_test[['Pclass', 'Sex', 'Parch', 'Embarked', 'Fare', 'Cabin']]\ndtree = DTC()\ndtree.fit(x_train,y)\nprediction = dtree.predict(x_test)\n\n#Now to add prediction to our dataset\ndf_test['Survived'] = prediction.astype(int)","df2fc479":"#Prepare results for submission\n(df_test[['PassengerId', 'Survived']]).to_csv('TitanicSolution_v6.csv', index=False)","ace4fdf7":"#Check for any Null values\ndf_AllData.Name.isnull().sum()","73fbedc7":"#Great field doesn't have any null values.  Let's check the values in the column\ndf_AllData.Name.value_counts()","211540b1":"#Best way to make use of these names is by grouping them via their salutations\ndf_AllData['Salutation'] =  df_AllData.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","79a56160":"df_AllData.Salutation.value_counts().plot.bar();","130b2161":"df_AllData.Salutation.replace(to_replace=['Rev','Dr','Col','Major','Mlle','Ms','Countess','Capt','Dona','Don','Sir','Lady','Jonkheer','Mme'], value=0, inplace=True)\ndf_AllData.Salutation.replace('Mr', 1, inplace=True)\ndf_AllData.Salutation.replace('Miss', 2, inplace=True)\ndf_AllData.Salutation.replace('Mrs', 3, inplace=True)\ndf_AllData.Salutation.replace('Master', 4, inplace=True)","d608bdd0":"df_AllData.Salutation.value_counts(dropna=False).plot.bar();","d0fcc7d8":"#Let's split train and test datasets\ndf_train = df_AllData.loc[1:891,:]\ndf_test = df_AllData.loc[892:1309,:]","8b8a40fb":"#Again let's improve our model and prediction\nx_train = df_train[['Pclass', 'Sex', 'Parch', 'Salutation', 'Embarked', 'Fare']]\ny = df_train['Survived']\nx_test = df_test[['Pclass', 'Sex', 'Parch', 'Salutation', 'Embarked', 'Fare']]\ndtree = DTC()\ndtree.fit(x_train,y)\nprediction = dtree.predict(x_test)\n\ndf_test['Survived'] = prediction.astype(int)","8615d3ab":"(df_test[['PassengerId', 'Survived']]).to_csv('TitanicSolution_v7.csv', index=False)","1331b3d7":"#Moving on to next column - Age\n#Let's check for any null values\ndf_AllData.Age.isnull().sum()","48b685c0":"#Let's explore the values in the field\ndf_AllData.Age.value_counts(dropna=False)","c4c51552":"#Let's try to group these values, first round them up\ndf_AllData.Age = df_AllData.Age.round()","f617877e":"df_AllData.corr().Age","561c1d67":"x_test=df_AllData[['Fare','Parch', 'Sex', 'Salutation', 'Sibsp']]\ny = df_AllData.Age.dropna()","ba04a909":"# Score - 0.7558","1179deec":"# Score - 0.78468","2718bc0d":"# Well that gave a score of 0.65550.","a5adcd9b":"# Score - 0.77511","005d2797":"This work is inspired by Rafal Plis notebook.  Please check out -> https:\/\/www.kaggle.com\/rafalplis\/my-approach-to-titanic-competition","ac0ddbae":"# Score - 0.76076","cd66f3f0":"# Score - 0.77511","73821dff":"# Well there is no change in Score - 0.77511","e7456ea7":"# So Far,  We have done\n1. Imported necessary headers.\n2. Read train and test datasets.\n3. Created a consolidated dataset comprising both train and test dataset.\n\n## Let's get started with Modeling","0aa8c205":"# Next column to process - **Name**"}}