{"cell_type":{"f6fc74d2":"code","c51c8bf2":"code","6cb1d7c2":"code","923ec6fc":"code","a7d2973e":"code","545c6ccd":"code","28fdcf06":"code","04bb4d9f":"code","36cec6d0":"code","7beca0fc":"code","b683f0b1":"code","4b889ed3":"code","a4a212c3":"code","b89b2d58":"code","5f028168":"code","1e0cdf25":"code","46038e30":"code","7a104b5b":"code","ea1ea62c":"code","56f1cf97":"code","600787b3":"code","c6d7848d":"code","f589546e":"code","61251bf8":"code","3d05ee38":"code","7a815440":"code","7b71aa02":"markdown","464a45ac":"markdown","51a571f0":"markdown","be1fc965":"markdown","5eb55ca0":"markdown","323e1301":"markdown"},"source":{"f6fc74d2":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","c51c8bf2":"dim = 512 #1024, 256, 'original'\ntest_dir = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test'\n# weights_dir = '\/kaggle\/input\/vinbigdata-cxr-ad-yolov5-14-class-train\/yolov5\/runs\/train\/exp\/weights\/best.pt'\nweights_dir = f'\/kaggle\/input\/softnms\/best_softnms.pt'","6cb1d7c2":"test_df = pd.read_csv(f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test.csv')\ntest_df.head()","923ec6fc":"shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\n# shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '.\/yolov5')\n\nos.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","a7d2973e":"!python detect.py --weights $weights_dir\\\n--img 640\\\n--conf 0.15\\\n--iou 0.4\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok","545c6ccd":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs\/detect\/exp\/*png')\nfor _ in range(6):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","28fdcf06":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n#     print('bboxes',bboxes)\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes","04bb4d9f":"# image_ids = []\n# PredictionStrings = []\n\n# for file_path in tqdm(glob('runs\/detect\/exp\/labels\/*txt')):\n#     image_id = file_path.split('\/')[-1].split('.')[0]\n#     w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n#     f = open(file_path, 'r')\n#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n#     data = data[:, [0, 5, 1, 2, 3, 4]]\n    \n    \n#     list_classid_probility = data[:, :2]\n#     list_normalized_box = data[:, 2:]\n#     filtered_list_classid_probility=[]\n#     filtered_list_normalized_box=[]\n    \n#     for i in range(len(list_classid_probility)):\n#         if Hotmask_mid_value(list_classid_probility[i][0] , list_normalized_box[i])>0.1 or Hotmask_w_h_value(list_classid_probility[i][0] , list_normalized_box[i])>0.1 or list_classid_probility[i][0]==14:\n#             filtered_list_classid_probility.appendpend(list_classid_probility[i][0])\n#             filtered_list_normalized_box.appendpend(list_classid_probility[i][0])\n            \n#     bboxes = list(np.round(np.concatenate((filtered_list_classid_probility, np.round(yolo2voc(h, w, filtered_list_normalized_box))), axis =1).reshape(-1), 1).astype(str))\n#     print('data[:, 2:]',data[:, 2:])\n#     for idx in range(len(bboxes)):\n#         bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n#     image_ids.append(image_id)\n#     PredictionStrings.append(' '.join(bboxes))","36cec6d0":"import os \nos.getcwd()","7beca0fc":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\ndim = 512 #512, 256, 'original'\nfold = 4\n\ntrain_df = pd.read_csv(f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train.csv')\ntrain_df.head()\n\ntrain_df['x_min'] = train_df.apply(lambda row: (row.x_min)\/row.width, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)\/row.height, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)\/row.width, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)\/row.height, axis =1)\n\ntrain_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)\/2, axis =1)\ntrain_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)\/2, axis =1)\n\ntrain_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain_df['area'] = train_df['w']*train_df['h']\ntrain_df.head()\n\n","b683f0b1":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)","4b889ed3":"list_mid_gaussian_kde=[]\nfor i in range(14):\n    \n\n    train_df_0 = train_df[train_df.class_id==i]\n    x_val = train_df_0.x_mid\n    y_val = train_df_0.y_mid\n    print(len(x_val))\n\n    # Calculate the point density\n    xy = np.vstack([x_val,y_val])\n    z = gaussian_kde(xy)(xy)\n\n    fig, ax = plt.subplots(figsize = (10, 10))\n    # ax.axis('off')\n    ax.axis([0,1,1,0])\n    ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n    # ax.set_xlabel('x_mid')\n    # ax.set_ylabel('y_mid')\n    plt.show()\n\n    evalutor=gaussian_kde(xy)\n    # evalutor.evaluate([[0.6],[0.4]])\n    list_mid_gaussian_kde.append(evalutor)","a4a212c3":"list_w_h_gaussian_kde=[]\nfor i in range(14):\n    \n\n    train_df_0 = train_df[train_df.class_id==i]\n    x_val = train_df_0.w\n    y_val = train_df_0.h\n    print(len(x_val))\n\n    # Calculate the point density\n    xy = np.vstack([x_val,y_val])\n    z = gaussian_kde(xy)(xy)\n\n    fig, ax = plt.subplots(figsize = (10, 10))\n    # ax.axis('off')\n    ax.axis([0,1,1,0])\n    ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n    # ax.set_xlabel('x_mid')\n    # ax.set_ylabel('y_mid')\n    plt.show()\n\n    evalutor=gaussian_kde(xy)\n    # evalutor.evaluate([[0.6],[0.4]])\n    list_w_h_gaussian_kde.append(evalutor)","b89b2d58":"# https:\/\/www.pythonheidong.com\/blog\/article\/436765\/a0facf9464d9337dc1eb\/\nlist_area_gaussian_kde=[]\nfor i in range(14):\n    train_df_0 = train_df[train_df.class_id==i]\n    data = train_df_0.w\n\n    density = gaussian_kde(data)\n    xs = np.linspace(0,1,200)\n    plt.plot(xs,density(xs))\n    plt.show()\n    list_area_gaussian_kde.append(density)","5f028168":"print(density.evaluate(0.4))","1e0cdf25":"def Hotmask_mid_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_mid_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate([[normalized_xmid_ymid_w_h[0]],[normalized_xmid_ymid_w_h[1]]])\n    \n    return value\n\ndef Hotmask_w_h_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_w_h_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate([[normalized_xmid_ymid_w_h[2]],[normalized_xmid_ymid_w_h[3]]])\n    \n    return value\n\ndef Hotmask_area_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_area_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate(normalized_xmid_ymid_w_h[2]*normalized_xmid_ymid_w_h[3])\n    \n    return value","46038e30":"image_ids = []\nPredictionStrings = []\nsum_delte_on=0\n\n# threshold=0.001\nthreshold_mid=0.001\nthreshold_w_h=0.001\nthreshold_area=0.001\n\nfor file_path in tqdm(glob('runs\/detect\/exp\/labels\/*txt')):\n    delte_on=0\n    \n    image_id = file_path.split('\/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n#     print('data',data.type)\n    \n    list_classid_probility = data[:, :2]\n    list_normalized_box = data[:, 2:]\n    delte_sign=[]\n#     filtered_list_classid_probility=[]\n#     filtered_list_normalized_box=[]\n    \n#     print('data[:, :2]',data[:, :2]) \n    \n    for i in range(len(list_classid_probility)):\n        if (Hotmask_mid_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_mid and Hotmask_w_h_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_w_h and Hotmask_area_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_area) or list_classid_probility[i][0]==14:\n            delte_sign.append(True)\n        else:\n            delte_sign.append(False)\n            delte_on+=1\n            \n#             filtered_list_classid_probility.append(list_classid_probility[i][0])\n#             filtered_list_normalized_box.append(list_classid_probility[i].tolist())\n            \n#     prin**t('filtered_list_normalized_box',filtered_list_normalized_box) \n    \n    print('delte_sign',delte_sign) \n    bboxes = list(np.round(np.concatenate((data[:, :2][delte_sign], np.round(yolo2voc(h, w, data[:, 2:][delte_sign]))), axis =1).reshape(-1), 1).astype(str))\n#     bboxes = np.array(list(np.round(np.concatenate((filtered_list_classid_probility, np.round(yolo2voc(h, w, filtered_list_normalized_box))), axis =1).reshape(-1), 1).astype(str)),dtype=np.float32)\n#     print('data[:, 2:]',data[:, 2:])\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))\n    \n    if delte_on!=0:\n        sum_delte_on+=1","7a104b5b":"sum_delte_on","ea1ea62c":"# image_ids = []\n# PredictionStrings = []\n\n# for file_path in tqdm(glob('runs\/detect\/exp\/labels\/*txt')):\n#     image_id = file_path.split('\/')[-1].split('.')[0]\n#     w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n#     f = open(file_path, 'r')\n#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n#     data = data[:, [0, 5, 1, 2, 3, 4]]\n#     bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n# #     print('data[:, :2]',data[:, :2].type)\n#     for idx in range(len(bboxes)):\n#         bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n        \n#     print('after bboxes',bboxes)\n#     image_ids.append(image_id)\n#     PredictionStrings.append(' '.join(bboxes))","56f1cf97":"pred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df = sub_df[['image_id', 'PredictionString']]\n\nsub_df.loc[sub_df['PredictionString'] =='','PredictionString']=\"14 1 0 0 1 1\"\nsub_df.to_csv('\/kaggle\/working\/submission_softnms.csv',index = False)\nsub_df.tail()","600787b3":"# sub_df.tail()","c6d7848d":"# test_df = pd.read_csv(f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test.csv')\n# test_df.head()","f589546e":"# imagepaths = test_df['image_id'].unique()\n# imagepaths","61251bf8":"# for i, name in tqdm(enumerate(imagepaths)):\n#     path=os.path.join('..\/input\/vinbigdata-original-image-dataset\/vinbigdata\/train',name+'.jpg')\n#     img_array  = cv2.imread(path)\n#     print('name',name)\n#     print('shape',img_array.shape)","3d05ee38":"# train_data = np.array(sub_df)#np.ndarray()\n# train_x_list=train_data.tolist()#list\n# print(train_x_list)\n# print(type(train_x_list))","7a815440":"# shutil.rmtree('\/kaggle\/working\/yolov5')","7b71aa02":"# Plot","464a45ac":"# [Training Notebook](https:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class)\n* Select `GPU` as the **Accelerator**","51a571f0":"# Process Submission","be1fc965":"# Version\n\n* `v12`: Fold4\n* `v11`: Fold3\n* `v10`: Fold2\n* `v08`: Fold1\n* `v07`: Fold0\n","5eb55ca0":"# Inference","323e1301":"# YOLOv5 Stuff"}}