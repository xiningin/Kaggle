{"cell_type":{"ce90d927":"code","98d83ab9":"code","2099b5f1":"code","affc8733":"code","0be57ea4":"code","51d4348e":"code","effdc50a":"code","30901f08":"code","03c443b8":"code","05c4a638":"code","c534de0c":"code","48cbc619":"code","ee1ed404":"code","9ad4ddb5":"code","cad1a853":"code","ba9d2a48":"code","fcd829fe":"code","97eeca34":"code","c5a7721d":"markdown","883d01a5":"markdown","5078b94f":"markdown","05e4ecd6":"markdown","05055b87":"markdown","8a3dd783":"markdown","3d3135b4":"markdown","5de59714":"markdown","28679004":"markdown"},"source":{"ce90d927":"import torch\nimport torchvision\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\n\nimport copy\nimport time","98d83ab9":"torch.backends.cudnn.enabled","2099b5f1":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","affc8733":"import os\nos.listdir(\"\/kaggle\/\")","0be57ea4":"Num_CNN = 12\n\nn_epochs = 25\nbatch_size_train = 64\nbatch_size_test = 1000\nlearning_rate = 0.01\nmomentum = 0.5\nlog_interval = 100\n\nrandom_seed = 121\ntorch.manual_seed(random_seed)\n\nkaggle_input_data = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\nkaggle_input_validation = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\n\nkaggle_model_path = \"\/kaggle\/working\/model_id_%d.pth\"\nkaggle_optimizer_path = \"\/kaggle\/working\/optimizer_id_%d.pth\"\nprediction_path = \"\/kaggle\/working\/predictions_essemble.csv\"","51d4348e":"class Dataset(torch.utils.data.Dataset):\n    \n    def __init__(self, dataframe):\n        # initisalization\n        self.labels = dataframe[\"label\"].to_numpy()\n        self.dataframe = dataframe.loc[:,dataframe.columns != \"label\"]\n    \n    def __len__(self):\n        return self.dataframe.shape[0]\n    \n    def __getitem__(self, index):\n        # generate one sample of data - reshaping array to 28x28\n        X = torch.from_numpy(self.dataframe.iloc[index].values.reshape(1,28,28)).float()\n        y = self.labels[index]\n        \n        return X,y","effdc50a":"df_input = pd.read_csv(kaggle_input_data)\ndf_validation = pd.read_csv(kaggle_input_validation)\n\ndf_train, df_test = train_test_split(df_input, test_size  = 0.01)\n\n# training\ntraining_set = Dataset(df_train)\ntraining_generator = torch.utils.data.DataLoader(training_set, batch_size = batch_size_train,\n                                                shuffle = True)\n\n# test\ntest_set = Dataset(df_test)\ntest_generator = torch.utils.data.DataLoader(test_set, batch_size = batch_size_test,\n                                                shuffle = True)\n\n# validation \nkaggle_validation_set = torch.from_numpy(df_validation.to_numpy()).view(\n    df_validation.shape[0],-1,28,28).float()","30901f08":"examples = enumerate(test_generator)\nbatch_idx, (example_data, example_labels) = next(examples)\n\n\nfig = plt.figure(figsize = (10,5))\nfor i in range(6):\n    ax = fig.add_subplot(2,3, i+1)\n    ax.imshow(example_data[i][0], cmap = \"gray\", interpolation = \"none\")\n    ax.set_title(f\"Ground truth: {example_labels[i]}\")\n    ax.set_xticks([])\n    ax.set_yticks([])\nfig.tight_layout()\nfig.show()","03c443b8":"fig = plt.figure(figsize = (10, 5))\nfor i in range(6):\n    ax = fig.add_subplot(2,3, i+1)\n    ax.imshow(kaggle_validation_set[i][0], cmap = \"gray\", interpolation = \"none\")\n    ax.set_title(\"No label\")\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.suptitle(\"Validation set\")\nfig.show()","05c4a638":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler","c534de0c":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        # Conv 1\n        # size : input: 28x28x1 -> output : 26 x 26 x 32\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.batchnorm1 = nn.BatchNorm2d(32)\n        \n        # Conv 2\n        # size : input: 26x26x32 -> output : 24 x 24 x 32\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n        self.batchnorm2 = nn.BatchNorm2d(32)\n        \n        # Conv 3\n        # size : input: 24x24x32 -> output : 12 x 12 x 32\n        self.conv3 = nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n        self.batchnorm3 = nn.BatchNorm2d(32)\n        \n        # Conv 4\n        # size : input : 12 x 12 x 32 -> output : 8 x 8 x 64\n        self.conv4 = nn.Conv2d(32, 64, kernel_size=5)\n        self.batchnorm4 = nn.BatchNorm2d(64)\n        \n        # Conv 5\n        # size : input: 8x8x64 -> output : 4 x 4 x 64 -> Linearize = 1024\n        self.conv5 = nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n        self.batchnorm5 = nn.BatchNorm2d(64)\n        \n        # dropout layer \n        self.conv5_drop = nn.Dropout2d()\n        \n        # FC 1 \n        self.fc1 = nn.Linear(1024, 128)\n        \n        # FC 2\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.batchnorm1(F.relu(self.conv1(x)))\n        x = self.batchnorm2(F.relu(self.conv2(x)))\n        x = self.batchnorm3(F.relu(self.conv3(x)))\n        x = self.batchnorm4(F.relu(self.conv4(x)))\n        x = self.batchnorm5(F.relu(self.conv5(x)))\n        x = self.conv5_drop(x)\n        x = x.view(-1, 1024)\n        x = F.relu(self.fc1(x))\n        x = F.log_softmax(self.fc2(x), dim=1)\n        return x","48cbc619":"train_losses = []\ntrain_counter = []\n\ntest_losses = []\n\ntest_counter = [i*len(training_generator.dataset) for i in range(n_epochs + 1)]\n\n# only print on the last batch\nlog_interval = len(training_generator)\n\n# network_list \nnetwork_list = []\n\n# output tensor\nprediction_tensor = torch.zeros(kaggle_validation_set.shape[0],10)","ee1ed404":"def train(epoch, network, scheduler, network_id, device):\n    start_time = time.time()\n    \n    network.train()\n    for batch_idx, (data, target) in enumerate(training_generator):\n        data = data.to(device)\n        target = target.to(device)\n        \n        optimizer.zero_grad()\n        \n        output = network(data)\n        \n        loss = F.nll_loss(output, target)\n        loss.backward()\n        \n        optimizer.step()\n    \n    print('CNN : {},\\t Train Epoch: {} \\tLoss: {:.6f},\\t runtime: {:.2f}'.format(\n        network_id,\n        epoch, loss.item(), time.time()-start_time))\n    \n    train_losses.append(loss.item())\n    train_counter.append(epoch)\n\n    torch.save(network.state_dict(), kaggle_model_path%network_id)\n    torch.save(optimizer.state_dict(),kaggle_optimizer_path%network_id)\n    scheduler.step()\n\n\ndef test(network):\n    network.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_generator:\n            data = data.to(device)\n            target = target.to(device)\n            \n            output = network(data)\n            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(target.data.view_as(pred)).sum()\n            \n    test_loss \/= len(test_generator.dataset)\n    test_losses.append(test_loss)\n    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}\/{} ({:.5f}%)\\n'.format(\n                test_loss, correct, len(test_generator.dataset),\n                100. * correct \/ len(test_generator.dataset)))\n\n\ndef validation(network, validation_tensor, prediction_tensor):\n    \n    with torch.no_grad():\n        output = network(validation_tensor)\n    \n    prediction_tensor = prediction_tensor + output\n    \n    return prediction_tensor\n\n\n\ndef initialise_network(device):\n    network = Net().to(device)\n    optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum = momentum)\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.95)\n    \n    return network, optimizer, exp_lr_scheduler","9ad4ddb5":"validation_tensor = kaggle_validation_set.to(device)\nprediction_tensor = prediction_tensor.to(device)\n\n\nfor id_net in range(1, Num_CNN+1):\n    \n    network, optimizer, scheduler = initialise_network(device)\n    \n    for epoch in range(1, n_epochs+1):\n        train(epoch, network, scheduler, id_net, device)\n    test(network)\n    \n    prediction_tensor = validation(network, validation_tensor, prediction_tensor)\n    network_list.append(copy.deepcopy(network))","cad1a853":"# calculating the labels and moving prediciton to cpu\noutput_df = prediction_tensor.max(1)[1].to(\"cpu\")\n\noutput_df = pd.DataFrame(output_df.numpy(), columns = [\"Label\"])\n\noutput_df.index.name = \"ImageId\"\noutput_df.index = output_df.index + 1","ba9d2a48":"start_pos = 34\n\nfig = plt.figure()\nfor i in range(6):\n    ax = fig.add_subplot(2,3, i+1)\n    ax.imshow(kaggle_validation_set[start_pos+i][0], cmap = \"gray\", interpolation = \"none\")\n    ax.set_title(f\"Prediction : {output_df.iloc[start_pos+i][0]}\")\n    ax.set_xticks([])\n    ax.set_yticks([])","fcd829fe":"output_df","97eeca34":"output_df.to_csv(prediction_path)","c5a7721d":"# Saving the predictions","883d01a5":"# Build the network","5078b94f":"# Configs","05e4ecd6":"# Dataset","05055b87":"### Initialise the network and train","8a3dd783":"# Output predictions","3d3135b4":"## Validation examples","5de59714":"# Looking at some examples\n\n## Train examples","28679004":"## Train the model"}}