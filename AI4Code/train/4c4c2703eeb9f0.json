{"cell_type":{"5824e420":"code","b5493310":"code","aeff87ee":"code","cec35590":"code","17722fba":"code","df95bf7d":"code","704f096e":"code","24cbfe62":"code","c3a4a457":"code","a0c5a301":"markdown","0ba6cd2f":"markdown","2f867e68":"markdown","eaf5ff3b":"markdown","4241df14":"markdown","30d304e2":"markdown","3e9ea28c":"markdown"},"source":{"5824e420":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5493310":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import MaxPool2D,Convolution2D,Flatten,Dense,MaxPooling2D, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom PIL import Image\nimport cv2\nimport pickle","aeff87ee":"train_datagen= ImageDataGenerator(rescale = 1.\/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True)\ntest_datagen= ImageDataGenerator(rescale=1.\/255)","cec35590":"train_dataPath=\"..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/train\"\ntest_dataPath=\"..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\"\ntrain_generator= train_datagen.flow_from_directory(train_dataPath, target_size=(150,150), batch_size=32, class_mode=\"binary\")\ntest_generator= test_datagen.flow_from_directory(test_dataPath, target_size=(150,150), batch_size=32, class_mode= \"binary\")","17722fba":"len(set(train_generator.classes))","df95bf7d":"model=Sequential()\nmodel.add(Convolution2D(32, kernel_size=(3,3), activation= \"relu\", input_shape= (150,150,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(150, activation= \"relu\"))\nmodel.add(Dense(2, activation= \"softmax\"))\nmodel.summary()","704f096e":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","24cbfe62":"fitted_model = model.fit_generator(train_generator,\n                        epochs = 10,\n                        validation_data = test_generator)","c3a4a457":"plt.plot([i for i in range(10)],fitted_model.history['accuracy'], label=\"accuracy\")\nplt.plot([i for i in range(10)],fitted_model.history['loss'], label= \"loss\")\nplt.legend()","a0c5a301":"# Import Necessary Libraries","0ba6cd2f":"# Get dataset","2f867e68":"# Model compile and fit","eaf5ff3b":"# Create our model","4241df14":"# Plot accuracy and loss","30d304e2":"# Define classes","3e9ea28c":"# To include and convert dataset in the project"}}