{"cell_type":{"6f063d0a":"code","d8e92cc7":"code","6a58b3a2":"code","056245aa":"code","77073624":"code","9b50ddf8":"code","237dff45":"code","7da8a3a6":"code","8ad6ae10":"code","ea7037d5":"code","0a5cdaa8":"code","dee84eb8":"code","6a4dca8b":"code","6922a9cd":"markdown","fa67b6f3":"markdown","28b9c331":"markdown","ccbc10bf":"markdown","61dd3c0b":"markdown","3320eac0":"markdown","6221c3e9":"markdown","79370ab2":"markdown","bca34e4d":"markdown"},"source":{"6f063d0a":"import numpy as np\nimport pandas as pd\nimport os\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport cv2","d8e92cc7":"train = pd.read_csv('\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train.csv')\ntrain","6a58b3a2":"cols = [\n    'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', \n    'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', \n    'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', \n    'CVC - Normal', 'Swan Ganz Catheter Present'\n]\n\nfig = make_subplots(rows=4, cols=3)\n\ntraces = [\n    go.Bar(\n        x=[0, 1], \n        y=[\n            len(train[train[col]==0]),\n            len(train[train[col]==1])\n        ], \n        name=col,\n        text = [\n            str(round(100 * len(train[train[col]==0]) \/ len(train), 2)) + '%',\n            str(round(100 * len(train[train[col]==1]) \/ len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ) for col in cols\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i \/\/ 3) + 1, (i % 3)  +1)\n\nfig.update_layout(\n    title_text='Train columns',\n    height=1200,\n    width=1000\n)\n\nfig.show()","056245aa":"x = train[cols].sum(axis=0).sort_values().reset_index()\nx.columns = ['column', 'nonzero_records']\n\nfig = px.bar(\n    x, \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns and non zero samples', \n    height=800, \n    width=800\n)\n\nfig.show()","77073624":"data = train[cols].astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()\n\nfig = px.bar(\n    data, \n    y=data['row'], \n    x=\"count\", \n    title='Number of activations for every sample in training set', \n    width=800, \n    height=500\n)\n\nfig.show()","9b50ddf8":"data = train[cols].astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()\n\nfig = px.pie(\n    data, \n    values=round((100 * data['row'] \/ len(train)), 2), \n    names=\"count\", \n    title='Number of activations for every sample (Percent)', \n    width=800, \n    height=500\n)\n\nfig.show()","237dff45":"data = train[cols]\n\nf = plt.figure(\n    figsize=(12, 12)\n)\n\nplt.matshow(\n    data.corr(), \n    fignum=f.number\n)\n\nplt.xticks(\n    range(data.shape[1]), \n    data.columns, \n    fontsize=13, \n    rotation=70\n)\n\nplt.yticks(\n    range(data.shape[1]), \n    data.columns, \n    fontsize=13\n)\n\ncb = plt.colorbar()\n\ncb.ax.tick_params(\n    labelsize=13\n)","7da8a3a6":"f, plots = plt.subplots(5, 5, sharex='col', sharey='row', figsize=(17, 17))\nsamples = train.sample(n=25, random_state=666)['StudyInstanceUID'].values\n\nfor i in range(25):\n    plots[i \/\/ 5, i % 5].axis('off')\n    image = cv2.imread(os.path.join(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/\", f\"{samples[i]}.jpg\"))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plots[i \/\/ 5, i % 5].imshow(image)","8ad6ae10":"%%time\n\ncheck_dict = dict()\n\nfor filename in os.listdir(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/\"):\n    img = cv2.imread(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/\" + filename)\n    try:\n        check_dict[img.shape] += 1\n    except:\n        check_dict[img.shape] = 1","ea7037d5":"shapes_df = pd.DataFrame(check_dict.items(), columns=['shape', 'count'])\n\nx = shapes_df.sort_values(['count']).reset_index().drop(['index'], axis=1)\nx['shape'] = x['shape'].astype(str)\nx = x.tail(15)\n\nfig = px.bar(\n    x, \n    x='count', \n    y='shape', \n    orientation='h', \n    title='Top 15 shape by number of samples', \n    height=800, \n    width=800\n)\n\nfig.show()","0a5cdaa8":"train_annotations = pd.read_csv('\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train_annotations.csv')\ntrain_annotations","dee84eb8":"import ast\n\ndef plot_annotation():\n    sample = train_annotations.sample(n=1)['StudyInstanceUID'].values[0]\n    data = train_annotations[train_annotations['StudyInstanceUID'] == sample]['data'].values[0]\n    image_path = \"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/\" + sample + \".jpg\"\n    data = np.array(ast.literal_eval(data))\n    plt.figure(figsize=(10, 10))\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.scatter(data[:, 0], data[:, 1])","6a4dca8b":"plot_annotation()","6922a9cd":"Let's check some of our randomly selected images.","fa67b6f3":"Let's see how many records for every column in training set have non zero values.","28b9c331":"**train.csv** - contains image IDs, binary labels, and patient IDs.\n\n* StudyInstanceUID - unique ID for each image\n* ETT - Abnormal - endotracheal tube placement abnormal\n* ETT - Borderline - endotracheal tube placement borderline abnormal\n* ETT - Normal - endotracheal tube placement normal\n* NGT - Abnormal - nasogastric tube placement abnormal\n* NGT - Borderline - nasogastric tube placement borderline abnormal\n* NGT - Incompletely Imaged - nasogastric tube placement inconclusive due to imaging\n* NGT - Normal - nasogastric tube placement borderline normal\n* CVC - Abnormal - central venous catheter placement abnormal\n* CVC - Borderline - central venous catheter placement borderline abnormal\n* CVC - Normal - central venous catheter placement normal\n* Swan Ganz Catheter Present\n* PatientID - unique ID for each patient in the dataset","ccbc10bf":"### To be continued","61dd3c0b":"<a id=\"2\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>2. Image Overview<\/center><h2>","3320eac0":"Let's check image shapes for training set","6221c3e9":"<h1><center>RANZCR CLiP. Data Understanding.<\/center><\/h1>\n\n<center><img src=\"https:\/\/pbs.twimg.com\/profile_images\/1100562573001277440\/paTq0zKF_400x400.png\"><\/center>\n","79370ab2":"<a id=\"1\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>1. Basic Data Overview<\/center><h2>","bca34e4d":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h2>\n\n* [1. Basic Data Overview](#1)\n* [2. Image Overview](#2)"}}