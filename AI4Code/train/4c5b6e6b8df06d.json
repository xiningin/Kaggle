{"cell_type":{"b99e6cfa":"code","db178131":"code","9f3fa117":"code","c82aa6e9":"code","2b8575e1":"code","6e875380":"code","6d29a955":"code","2aec1550":"code","e19fc9b1":"code","60a8bf3b":"code","643e446a":"code","30aa90bc":"code","fa7153dd":"code","001075a8":"code","dfe97126":"code","ee9aeaa9":"code","ff45b5a0":"code","defe4d94":"code","323b7947":"code","679a890c":"code","62c94d6e":"code","f5cc8033":"code","bc3940ec":"code","19d6186b":"code","8a4a1366":"code","73ab211e":"code","e01042f2":"code","888b879a":"code","1f81dc6a":"code","c89f57d7":"code","8445e36b":"code","e467d6e5":"code","b061b12b":"code","de42724d":"code","49945dd5":"code","fa25b7ea":"code","cd9d4d56":"code","d8fc4b28":"code","1af7579a":"code","f3cb7911":"code","f5137dc8":"code","883e8767":"code","1bbe6f14":"code","34ad9214":"code","9a0bf48a":"code","861ad7f8":"code","1dab097f":"code","ae53bbd3":"code","0352b244":"code","58f2538c":"code","c0fa4eac":"code","7579be7d":"code","b4f6d9eb":"code","b4d766ae":"code","7ff59e66":"code","708b7423":"code","2b3776c4":"code","1d7eec02":"code","84699bb3":"code","b991d2c6":"code","97133de5":"code","3a3063f6":"code","859f46e4":"code","23cc98a7":"code","bb21d3f6":"code","1cc45fee":"code","2d80fa99":"code","f0504e1d":"code","c1c139b9":"code","f3ee755c":"code","961746a3":"code","a76f5f91":"code","037ab52e":"code","23df11b9":"code","e146651d":"code","ea6650ac":"code","858efc54":"code","a7667fee":"code","3bf8b28b":"code","4dca1d23":"code","c87f5ee2":"code","0340abfc":"code","ee736531":"code","2844b60d":"code","5c544e03":"code","d5ec0298":"code","acb5c1c4":"code","e270229f":"code","9a0858dd":"code","054d8a9f":"code","b05e081c":"code","c49b7a3c":"code","542abf47":"code","37656afc":"code","ee992788":"code","028ee6a3":"code","b6cb11e5":"code","cdfd197f":"code","fe18b5f6":"code","fa2dc4e1":"code","ac86bf69":"code","1dc0e57b":"code","a59c61f1":"code","c06b7b51":"code","313f1cdd":"code","40046dbf":"code","a90b91c0":"code","b81c00aa":"code","a00203ce":"code","fb0d158f":"code","20292a8a":"code","bf61c384":"code","f1cf2874":"code","ad2cc4b5":"code","24d71ca5":"code","8c4befe8":"code","d69868c5":"code","e16d0b94":"code","69cd62ec":"code","87a62dd7":"code","0d7e85da":"code","c3c6cbee":"code","e6e9133e":"code","05287999":"code","14c4cb80":"code","b330ae6c":"code","8acc0361":"markdown","b8c5cf95":"markdown","c384315f":"markdown","e1603477":"markdown","eee1a63a":"markdown","139417c5":"markdown","64144a82":"markdown","b1d33ee0":"markdown","b0015705":"markdown","7d7f7c25":"markdown","cef7ecb6":"markdown","ccb846d5":"markdown","6a5183c0":"markdown","1365a2da":"markdown","879c4062":"markdown","7372b191":"markdown","16fdf747":"markdown","9dbf53d8":"markdown","f7eb8a4f":"markdown","f33f772a":"markdown","d365f90c":"markdown","601a2f26":"markdown","4c39ce7c":"markdown","d4d26683":"markdown","e5615138":"markdown","7756dd8c":"markdown","92b5cf32":"markdown","b27b6fce":"markdown","df0bc004":"markdown","d9374a72":"markdown","2510bbfc":"markdown","f975a6b4":"markdown","eb850df2":"markdown","c31c0c56":"markdown"},"source":{"b99e6cfa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.figure_factory as ff\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport scipy.stats as stats\nimport sklearn\nsklearn.model_selection.RandomizedSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","db178131":"employee = pd.read_csv(\"\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","9f3fa117":"employee.head()","c82aa6e9":"employee.info()","2b8575e1":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nlayout = go.Layout(\n    title='Attrition \u00d6zelli\u011finin Genel Da\u011f\u0131l\u0131m\u0131 Grafi\u011fi',\n)\nfig = go.Figure([go.Bar(x=employee[\"Attrition\"].value_counts().index.values, y=employee[\"Attrition\"].value_counts().values)],layout=layout)\nfig.show()","6e875380":"from collections import Counter\ndef detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","6d29a955":"employee.loc[detect_outliers(employee,['Age','DailyRate','DistanceFromHome','HourlyRate','MonthlyIncome','MonthlyRate','PercentSalaryHike',\n                                                           'TotalWorkingYears','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager','NumCompaniesWorked',\n                                                           'Education','EnvironmentSatisfaction','JobInvolvement','JobLevel','JobSatisfaction','NumCompaniesWorked','PerformanceRating',\n                                                           'RelationshipSatisfaction','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance'])]\n","2aec1550":"# drop outliers\nemployee = employee.drop(detect_outliers(employee,['Age','DailyRate','DistanceFromHome','HourlyRate','MonthlyIncome','MonthlyRate','PercentSalaryHike',\n                                                           'TotalWorkingYears','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager','NumCompaniesWorked',\n                                                           'Education','EnvironmentSatisfaction','JobInvolvement','JobLevel','JobSatisfaction','NumCompaniesWorked','PerformanceRating',\n                                                           'RelationshipSatisfaction','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance']),axis = 0).reset_index(drop = True)","e19fc9b1":"employee.columns[employee.isnull().any()]","60a8bf3b":"# OLEYYYY","643e446a":"employee.nunique()","30aa90bc":"employee.drop(['EmployeeCount','Over18','StandardHours','EmployeeNumber'],axis=1,inplace=True)","fa7153dd":"numerical_employee=employee.drop(['Attrition','BusinessTravel','Department','Education','EducationField','EnvironmentSatisfaction','Gender','JobInvolvement','JobLevel','JobRole','JobSatisfaction','MaritalStatus','NumCompaniesWorked','OverTime','PerformanceRating','RelationshipSatisfaction','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance','DistanceFromHome','PercentSalaryHike'],axis=1)","001075a8":"numerical_employee.head()","dfe97126":"numerical_employee.info()","ee9aeaa9":"def datauret(a,numerical_employee):\n    x = [\"Yes\", \"No\"]\n    y = [numerical_employee[employee['Attrition']=='Yes'][a].mean(),numerical_employee[employee['Attrition']=='No'][a].mean()]\n    \n    trace = go.Bar(\n        name=a,\n        x=x,\n        y=y,\n    )\n    \n    return trace","ff45b5a0":"def datahist(a,numerical_employee):\n    \n    trace = go.Histogram(\n        name=a,\n        x=numerical_employee[a],\n        nbinsx=60,\n    )\n    \n    return trace","defe4d94":"data_numerical=list()\nrate=numerical_employee\nfor i in range(len(rate.columns)):\n    data_numerical.append(datahist(rate.columns[i],numerical_employee))\n    \n","323b7947":"\ndef visibleTF_s(number):\n    liste=list()\n    for i in range(len(data_numerical)):\n        liste.append(False)\n    liste[number]=True\n    return liste\n\ndef button(attribute,number):\n    return dict(label = attribute,method = 'update',args = [{'visible': visibleTF_s(number)},{'title': 'numerical-Attribute ili\u015fkisi'}])","679a890c":"layout = go.Layout(\n    barmode='stack',\n    width=700,\n    height=500,\n    autosize=False,\n    title='Numerical-Attribute relationship',\n        \n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            #text='x Axis',\n            font=dict(\n                family='Courier New, monospace',\n                size=18,\n                color='#7f7f6f'\n            )\n        )\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            #text='y Axis',\n            font=dict(\n                family='Courier New, monospace',\n                size=18,\n                color='#7f7f7f'\n            )\n        )\n    )\n)\nrate=numerical_employee\nupdatemenus = list([dict(active=-1,buttons=[button(rate.columns[i],i) for i in range(len(rate.columns))])])","62c94d6e":"# Create figure\nfig = go.Figure()\n\nfor i in range(len(numerical_employee.columns)):\n    fig.add_trace(data_numerical[i])   \n\nfig.update_layout(\n    updatemenus=updatemenus)\n\nfig.show()","f5cc8033":"import plotly.express as px\nfig = px.scatter_matrix(numerical_employee)\nfig.show()","bc3940ec":"numerical_employee.corr()","19d6186b":"numerical_employee[['Age','MonthlyIncome','TotalWorkingYears']].corr()","8a4a1366":"# PCA1--------------------------------Age---MonthlyIncome----TotalWorkingYears\n\nX = StandardScaler().fit_transform(numerical_employee[['Age','MonthlyIncome','TotalWorkingYears']])\npca = PCA(n_components=2)\npca.fit(X)\nX_pca=pca.transform(X)\nprint(pca.explained_variance_ratio_)\nsum(pca.explained_variance_ratio_)\n","73ab211e":"import matplotlib.pyplot as plt\npca=PCA(whiten=True).fit(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulat\u0131ve explained variance')\nplt.show()","e01042f2":"# from above graph , we found n=1\nX = StandardScaler().fit_transform(numerical_employee[['Age','MonthlyIncome','TotalWorkingYears']])\npca = PCA(n_components=1)\npca.fit(X)\nX_pca=pca.transform(X)\nnumerical_employee['PCA1']=X_pca\nnumerical_employee.drop(['Age','MonthlyIncome','TotalWorkingYears'],axis=1,inplace=True)\nemployee['PCA1']=X_pca\n","888b879a":"numerical_employee[['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion']].corr()","1f81dc6a":"X = StandardScaler().fit_transform(numerical_employee[['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion']])\npca = PCA(n_components=2)\npca.fit(X)\nX_pca=pca.transform(X)\nprint(pca.explained_variance_ratio_)\nsum(pca.explained_variance_ratio_)","c89f57d7":"pca=PCA(whiten=True).fit(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulat\u0131ve explained variance')\nplt.show()","8445e36b":"#We used PCA with 2 component as PCA2 and PCA3 feature\n\nX = StandardScaler().fit_transform(numerical_employee[['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole']])\npca = PCA(n_components=2)\npca.fit(X)\nX_pca=pca.transform(X)\nnumerical_employee['PCA2']=X_pca.T[0]\nnumerical_employee['PCA3']=X_pca.T[1]\nnumerical_employee.drop(['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion'],axis=1,inplace=True)\n\nemployee['PCA2']=X_pca.T[0]\nemployee['PCA3']=X_pca.T[1]\n#employee.drop(['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion'],axis=1,inplace=True)","e467d6e5":"numerical_employee.corr()","b061b12b":"#DailyRate Feature\nnumerical_employee['Attrition']=employee['Attrition']\n\nnumerical_employee[numerical_employee['Attrition']=='Yes']['DailyRate']\ny=np.array(numerical_employee[numerical_employee['Attrition']=='Yes']['DailyRate'])\nn=np.array(numerical_employee[numerical_employee['Attrition']=='No']['DailyRate'])\n\nhist_data = [y,n]\ngroup_labels = ['distplot_yes','distplot_no'] # name of the dataset\n\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,bin_size=25)\nfig.show()","de42724d":"# There is a tendency to quit before 830, after which the tendency to quit is less. So this value is the threshold value\nemployee[\"DailyRate\"] = [1 if i < 830 else 2 for i in employee[\"DailyRate\"]]","49945dd5":"#HourlyRate Feature \nnumerical_employee[numerical_employee['Attrition']=='Yes']['HourlyRate']\ny=np.array(numerical_employee[numerical_employee['Attrition']=='Yes']['HourlyRate'])\nn=np.array(numerical_employee[numerical_employee['Attrition']=='No']['HourlyRate'])\n\nhist_data = [y,n]\ngroup_labels = ['distplot_yes','distplot_no'] # name of the dataset\n\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,bin_size=25)\nfig.show()","fa25b7ea":"#There are 2 threshold value as 45 and 73\nemployee[\"HourlyRate\"] = [1 if i < 45 else 3 if i > 73 else 2 for i in employee[\"HourlyRate\"]]","cd9d4d56":"#MonthlyRate Feature\nnumerical_employee[numerical_employee['Attrition']=='Yes']['MonthlyRate']\ny=np.array(numerical_employee[numerical_employee['Attrition']=='Yes']['MonthlyRate'])\nn=np.array(numerical_employee[numerical_employee['Attrition']=='No']['MonthlyRate'])\n\nhist_data = [y,n]\ngroup_labels = ['distplot_yes','distplot_no'] # name of the dataset\n\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,bin_size=25)\nfig.show()","d8fc4b28":"#There is 2 threshold value as 8500 \nemployee[\"MonthlyRate\"] = [1 if i < 8500 else 2 for i in employee[\"MonthlyRate\"]]\n","1af7579a":"\n#HourlyRate, DailyRate, MonthlyRate features will be considered as categorical features","f3cb7911":"numerical_employee.drop(['HourlyRate', 'DailyRate', 'MonthlyRate','Attrition'],axis=1,inplace=True)","f5137dc8":"Categorical_employee=employee.drop(['Attrition','Age','MonthlyIncome','YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion','TotalWorkingYears','PCA1','PCA2','PCA3'],axis=1)","883e8767":"def percent_attritionbarplot(x,employee):\n    liste=employee.sort_values(by=x)[x].unique().tolist()\n    listepercentyes=[]\n    listepercentno=[]\n    genele_etki=[]\n    for i in range(len(liste)):\n        a=(len(employee[employee[x]==liste[i]][employee['Attrition']=='Yes'])\/len(employee[employee[x]==liste[i]]))*100\n        b=100-a\n        listepercentyes.append(a)\n        listepercentno.append(b)\n        geneleoran=len(employee[employee[x]==liste[i]])\/len(employee)\n        genele_etki.append(geneleoran*a)\n        \n    trace1 = go.Bar(\n        x=liste,\n        y=listepercentyes,\n        name='Yes',\n    )\n    \n    trace2 = go.Bar(\n        x=liste,\n        y=listepercentno,\n        name='No',\n    )\n\n    data = [trace1, trace2]\n    return data\n","1bbe6f14":"def attritionbarplot2(x,employee):\n    liste=employee.sort_values(by=x)[x].unique().tolist()\n    listyes=[]\n    for i in range(len(liste)):\n        #a=len(employee[employee[x]==liste[i]][employee['Attrition']=='Yes'])\n        a=len(employee[employee[x]==liste[i]])\n        listyes.append(a)\n    \n    trace1 = go.Bar(\n        x=liste,\n        y=listyes,\n        name='Yes',\n    )\n    \n    return trace1","34ad9214":"data_Categorical=list()\ndata_Categorical2=list()\nrate=Categorical_employee\nfor i in range(len(rate.columns)):\n    data_Categorical2.append(attritionbarplot2(rate.columns[i],employee))\n    for j in range(2):\n        data_Categorical.append(percent_attritionbarplot(rate.columns[i],employee)[j])\n","9a0bf48a":"def visibleTF(number):\n    liste=list()\n    for i in range(len(data_Categorical)+len(data_Categorical2)):\n        liste.append(False)\n    liste[3*number-3]=True\n    liste[3*number-2]=True\n    liste[3*number-1]=True\n    return liste","861ad7f8":"def button(attribute,number):\n    return dict(label = attribute,method = 'update',args = [{'visible': visibleTF(number)},{'title': 'Categorical-Attrition percent relationship'}])","1dab097f":"rate=Categorical_employee\nupdatemenus = list([dict(active=-1,buttons=[button(rate.columns[i],i+1) for i in range(len(rate.columns))])])","ae53bbd3":"# Create figure\nfig = go.Figure()\n\nfig = make_subplots(rows=1, cols=2,\n                    specs=[[{}, {}]],\n                    subplot_titles=(\"Related Feature bar graph\",\"Attrition percentage of feature \"))\n\nfor i in range(len(data_Categorical2)):\n    fig.add_trace(data_Categorical2[i],row=1, col=1) \n    fig.add_trace(data_Categorical[2*i],row=1, col=2)\n    fig.add_trace(data_Categorical[2*i+1],row=1, col=2)   \n\n\nfig.update_layout(\n    updatemenus=updatemenus)","0352b244":"rate=Categorical_employee\nfor i in range(len(rate.columns)):\n    employ_tablosu=pd.crosstab(employee[\"Attrition\"],employee[rate.columns[i]])\n    print(stats.chisquare(employ_tablosu, axis=None))","58f2538c":"# First of all, the necessary classification was made in the Features and divided into categories, then our data was finalized by converting to dummy by using above graphs","c0fa4eac":"employee_new=Categorical_employee\nemployee_new1=pd.DataFrame()      #Only used for check the meaningful difference of new grouping\n","7579be7d":"#Attrition Feature\nemployee_new[\"Attritionr\"] = [1 if i == 'Yes' else 0 for i in employee[\"Attrition\"]]\nemployee_new1[\"Attritionr\"] = employee_new[\"Attritionr\"]","b4f6d9eb":"#BusinessTravel Feature\nemployee_new1[\"BusinessTravel\"]=employee_new[\"BusinessTravel\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"BusinessTravel\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"BusinessTravel\",\"Attritionr\"]].groupby([\"BusinessTravel\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","b4d766ae":"#Department Feature\nemployee_new1[\"Department\"]=employee_new[\"Department\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"Department\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"Department\",\"Attritionr\"]].groupby([\"Department\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","7ff59e66":"#Education Feature\nemployee_new[\"Educationr\"] = [13 if i == 1 or i == 3 else 24 if i == 2 or i == 4 else 5 for i in employee_new[\"Education\"]]\nemployee_new.drop(labels = [\"Education\"], axis = 1, inplace = True)\nemployee_new1[\"Educationr\"]=employee_new[\"Educationr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"Educationr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"Educationr\",\"Attritionr\"]].groupby([\"Educationr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","708b7423":"#EducationField  Feature\nemployee_new[\"EducationFieldr\"] = ['Other' if i == 'Medical' or i == 'Life Sciences' or i == 'Other' else 'Human Resources' if i == 'Human Resources' else 'Marketing' if i == 'Marketing' else 'Technical Degree' for i in employee_new[\"EducationField\"]]\nemployee_new.drop(labels = [\"EducationField\"], axis = 1, inplace = True)\nemployee_new1[\"EducationFieldr\"]=employee_new[\"EducationFieldr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"EducationFieldr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"EducationFieldr\",\"Attritionr\"]].groupby([\"EducationFieldr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","2b3776c4":"#EnvironmentSatisfaction  Feature\nemployee_new[\"EnvironmentSatisfactionr\"] = [234 if i == 2 or i == 3 or i == 4 else 1 for i in employee_new[\"EnvironmentSatisfaction\"]]\nemployee_new.drop(labels = [\"EnvironmentSatisfaction\"], axis = 1, inplace = True)\nemployee_new1[\"EnvironmentSatisfactionr\"]=employee_new[\"EnvironmentSatisfactionr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"EnvironmentSatisfactionr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"EnvironmentSatisfactionr\",\"Attritionr\"]].groupby([\"EnvironmentSatisfactionr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","1d7eec02":"#Gender Feature\nemployee_new1[\"Gender\"]=employee_new[\"Gender\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"Gender\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"Gender\",\"Attritionr\"]].groupby([\"Gender\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","84699bb3":"#JobInvolvement Feature\nemployee_new1[\"JobInvolvement\"]=employee_new[\"JobInvolvement\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobInvolvement\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobInvolvement\",\"Attritionr\"]].groupby([\"JobInvolvement\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","b991d2c6":"#JobLevel  Feature\nemployee_new[\"JobLevelr\"] = [45 if i == 4 or i == 5 else 3 if i == 3 else 2 if i == 2 else 1 for i in employee_new[\"JobLevel\"]]\nemployee_new.drop(labels = [\"JobLevel\"], axis = 1, inplace = True)\nemployee_new1[\"JobLevelr\"]=employee_new[\"JobLevelr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobLevelr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobLevelr\",\"Attritionr\"]].groupby([\"JobLevelr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","97133de5":"#JobRole Feature\nemployee_new[\"JobRoler\"] = ['HMM' if i == 'Manufacturing Director' or i == 'Healthcare Representative' or i == 'Manager' else 'Sales Executive' if i == 'Sales Executive' else 'Research Scientist' if i == 'Research Scientist' else 'Sales Representative' if i == 'Sales Representative' else 'Laboratory Technician' if i == 'Laboratory Technician' else 'Research Director' if i == 'Research Director' else 'Human Resources' for i in employee_new[\"JobRole\"]]\nemployee_new.drop(labels = [\"JobRole\"], axis = 1, inplace = True)\nemployee_new1[\"JobRoler\"]=employee_new[\"JobRoler\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobRoler\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobRoler\",\"Attritionr\"]].groupby([\"JobRoler\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","3a3063f6":"#JobSatisfaction  Feature\nemployee_new[\"JobSatisfactionr\"] = [23 if i == 2 or i == 3 else 1 if i == 1 else 4  for i in employee_new[\"JobSatisfaction\"]]\nemployee_new.drop(labels = [\"JobSatisfaction\"], axis = 1, inplace = True)\nemployee_new1[\"JobSatisfactionr\"]=employee_new[\"JobSatisfactionr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobSatisfactionr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobSatisfactionr\",\"Attritionr\"]].groupby([\"JobSatisfactionr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","859f46e4":"# MaritalStatus Feature\nemployee_new1[\"MaritalStatus\"]=employee_new[\"MaritalStatus\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"MaritalStatus\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"MaritalStatus\",\"Attritionr\"]].groupby([\"MaritalStatus\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","23cc98a7":"# NumCompaniesWorked  Feature\n\nemployee_new[\"NumCompaniesWorkedr\"] = ['2or3or4' if i == 2 or i == 3 or i == 4 else 1 if i == 1 else 0 if i == 0 else '5betw9'  for i in employee_new[\"NumCompaniesWorked\"]]\nemployee_new.drop(labels = [\"NumCompaniesWorked\"], axis = 1, inplace = True)\nemployee_new1[\"NumCompaniesWorkedr\"]=employee_new[\"NumCompaniesWorkedr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"NumCompaniesWorkedr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"NumCompaniesWorkedr\",\"Attritionr\"]].groupby([\"NumCompaniesWorkedr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","bb21d3f6":"#OverTime\nemployee_new1[\"OverTime\"]=employee_new[\"OverTime\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"OverTime\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"OverTime\",\"Attritionr\"]].groupby([\"OverTime\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)\n","1cc45fee":"#RelationshipSatisfaction  Feature\nemployee_new[\"RelationshipSatisfactionr\"] = [234 if i == 2 or i == 3 or i == 4 else 1 for i in employee_new[\"RelationshipSatisfaction\"]]\nemployee_new.drop(labels = [\"RelationshipSatisfaction\"], axis = 1, inplace = True)\nemployee_new1[\"RelationshipSatisfactionr\"]=employee_new[\"RelationshipSatisfactionr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"RelationshipSatisfactionr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"RelationshipSatisfactionr\",\"Attritionr\"]].groupby([\"RelationshipSatisfactionr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","2d80fa99":"#WorkLifeBalance  Feature\nemployee_new[\"WorkLifeBalancer\"] = [1 if i == 1  else 2 if i == 2   else 34 for i in employee_new[\"WorkLifeBalance\"]]\nemployee_new.drop(labels = [\"WorkLifeBalance\"], axis = 1, inplace = True)\nemployee_new1[\"WorkLifeBalancer\"]=employee_new[\"WorkLifeBalancer\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"WorkLifeBalancer\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"WorkLifeBalancer\",\"Attritionr\"]].groupby([\"WorkLifeBalancer\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","f0504e1d":"#TrainingTimesLastYear Feature\nemployee_new[\"TrainingTimesLastYearr\"] = [0 if i == 0  else '1betw3' if i > 0 and i < 4 else 4 if i == 4 else 5 if i == 5 else 6 for i in employee_new[\"TrainingTimesLastYear\"]]\nemployee_new.drop(labels = [\"TrainingTimesLastYear\"], axis = 1, inplace = True)\nemployee_new1[\"TrainingTimesLastYearr\"]=employee_new[\"TrainingTimesLastYearr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"TrainingTimesLastYearr\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"TrainingTimesLastYearr\",\"Attritionr\"]].groupby([\"TrainingTimesLastYearr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","c1c139b9":"#StockOptionLevel Feature\nemployee_new[\"StockOptionLevelr\"] = [0 if i == 0 else '1or2or3' for i in employee_new[\"StockOptionLevel\"]]\nemployee_new.drop(labels = [\"StockOptionLevel\"], axis = 1, inplace = True)\nemployee_new1[\"StockOptionLevelr\"]=employee_new[\"StockOptionLevelr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"StockOptionLevelr\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"StockOptionLevelr\",\"Attritionr\"]].groupby([\"StockOptionLevelr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","f3ee755c":"#DistanceFromHome Feature\nemployee_new[\"DistanceFromHomer\"] = ['1betw8' if i < 9 else '9betw11' if i > 8 and i < 12 else '12up' for i in employee_new[\"DistanceFromHome\"]]\nemployee_new.drop(labels = [\"DistanceFromHome\"], axis = 1, inplace = True)\nemployee_new1[\"DistanceFromHomer\"]=employee_new[\"DistanceFromHomer\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"DistanceFromHomer\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"DistanceFromHomer\",\"Attritionr\"]].groupby([\"DistanceFromHomer\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","961746a3":"#PercentSalaryHike Feature\nemployee_new[\"PercentSalaryHiker\"] = [11 if i == 11  else '12betw17' if i > 11 and i < 18 else '18betw21' if i > 17 and i < 22 else '22betw25' for i in employee_new[\"PercentSalaryHike\"]]\nemployee_new.drop(labels = [\"PercentSalaryHike\"], axis = 1, inplace = True)\nemployee_new1[\"PercentSalaryHiker\"]=employee_new[\"PercentSalaryHiker\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"PercentSalaryHiker\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"PercentSalaryHiker\",\"Attritionr\"]].groupby([\"PercentSalaryHiker\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","a76f5f91":"#DailyRate Feature\nemployee_new1[\"DailyRate\"]=employee_new[\"DailyRate\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"DailyRate\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"DailyRate\",\"Attritionr\"]].groupby([\"DailyRate\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","037ab52e":"#HourlyRate Feature\nemployee_new1[\"HourlyRate\"]=employee_new[\"HourlyRate\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"HourlyRate\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"HourlyRate\",\"Attritionr\"]].groupby([\"HourlyRate\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","23df11b9":"#MonthlyRate Feature\nemployee_new1[\"MonthlyRate\"]=employee_new[\"MonthlyRate\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"MonthlyRate\"])\n#Yeni gruplaman\u0131n anlaml\u0131 farkl\u0131l\u0131\u011f\u0131n\u0131 kontrol edelim\nemployee_new1[[\"MonthlyRate\",\"Attritionr\"]].groupby([\"MonthlyRate\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","e146651d":"#PerformanceRating Feature is dropped\nemployee_new.drop(labels = [\"PerformanceRating\"], axis = 1, inplace = True)","ea6650ac":"\nemployee_new = pd.concat([employee_new, numerical_employee],axis=1)\nemployee_new","858efc54":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","a7667fee":"def machinelearning_modeling(X_train,y_train,cv_method):\n      \n    random_state = 42\n    classifier = [DecisionTreeClassifier(random_state = random_state),\n                 SVC(random_state = random_state, probability=True ),\n                 RandomForestClassifier(random_state = random_state),\n                 LogisticRegression(random_state = random_state),\n                 KNeighborsClassifier()]\n\n    dt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                    \"max_depth\": range(1,20,2)}\n\n    svc_param_grid = {\"kernel\" : [\"rbf\"],\n                     \"gamma\": [0.001, 0.01, 0.1, 1],\n                     \"C\": [1,10,50,100,200,300,1000],\n                     \"probability\" :[True]}\n\n    rf_param_grid = {\"max_features\": [1,3,10],\n                    \"min_samples_split\":[2,3,10],\n                    \"min_samples_leaf\":[1,3,10],\n                    \"bootstrap\":[False],\n                    \"n_estimators\":[100,300],\n                    \"criterion\":[\"gini\"]}\n\n    logreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                        \"penalty\": [\"l1\",\"l2\"]}\n\n    knn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                     \"weights\": [\"uniform\",\"distance\"],\n                     \"metric\":[\"euclidean\",\"manhattan\"]}\n    classifier_param = [dt_param_grid,\n                       svc_param_grid,\n                       rf_param_grid,\n                       logreg_param_grid,\n                       knn_param_grid]\n    \n    ML_Models=[\"dtc\",\"svm\",\"rfc\",\"lr\",\"knc\"]\n    \n    cv_result = []\n    global cv_results \n    best_estimators = []\n\n    if (cv_method=='GridSearchCV'):\n\n        for i in range(len(classifier)):\n            \n            clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n            clf.fit(X_train,y_train)\n            cv_result.append(clf.best_score_)\n            best_estimators.append(clf.best_estimator_)\n\n    elif (cv_method=='RandomizedSearchCV'):\n        \n        for i in range(len(classifier)):\n            clf = RandomizedSearchCV(classifier[i], param_distributions=classifier_param[i], cv = StratifiedKFold(n_splits = 10), n_iter = 10,random_state = 111,scoring = 'precision')\n            clf.fit(X_train,y_train)\n            cv_result.append(clf.best_score_)\n            best_estimators.append(clf.best_estimator_)\n\n    cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\"LogisticRegression\",\"KNeighborsClassifier\"]})\n    fig = px.bar(cv_results, x='Cross Validation Means', y='ML Models',color='ML Models')\n    fig.show()\n    \n    return best_estimators, cv_results","3bf8b28b":"#For Accuracy Score Table \n#* Data_type is inbalanced or balanced with some techniques\n#* Voting Algorithm' is added ML Algorithm column \n\ncolumns_name = ['Data_type','CV method','ML Algorithm','Accuracy_Score']\nData_type=list()\nCV_method=list()\nML_Algorithm=list()\nAccuracy_Score=list()","4dca1d23":"\nX_train = employee_new.drop(labels = \"Attritionr\", axis = 1)\ny_train = employee_new[\"Attritionr\"]","c87f5ee2":"### GridSearchCV","0340abfc":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\naccuracy_GSCV=machinelearning_modeling(X_train,y_train,'GridSearchCV')","ee736531":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_GSCV[0][1]),\n                                        (\"rfc\",accuracy_GSCV[0][2]),\n                                        (\"lr\",accuracy_GSCV[0][3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))\n\n\n","2844b60d":"for i in range(5):\n    Data_type.append('Inbalanced data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_GSCV[1]['ML Models'][i])\n\nData_type.append('Inbalanced data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_test),y_test))\n","5c544e03":"### RandomizedSearchCV","d5ec0298":"from sklearn.model_selection import RandomizedSearchCV\naccuracy_RSCV=machinelearning_modeling(X_train,y_train,'RandomizedSearchCV')","acb5c1c4":"votingC = VotingClassifier(estimators = [(\"knc\",accuracy_RSCV[0][4]),\n                                        (\"rfc\",accuracy_RSCV[0][2]),\n                                        (\"lr\",accuracy_RSCV[0][3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))\n","e270229f":"for i in range(5):\n    Data_type.append('Inbalanced data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_RSCV[1]['ML Models'][i])\n\nData_type.append('Inbalanced data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(KNC,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_test),y_test))","9a0858dd":"from sklearn.utils import resample\nemployee_no = employee_new[employee_new.Attritionr == 0]\nemployee_yes = employee_new[employee_new.Attritionr == 1]\n\nemployee_yes_up = resample(employee_yes,\n                                     replace = True,\n                                     n_samples = len(employee_no),\n                                     random_state = 111)\n\nemployee_up = pd.concat([employee_no, employee_yes_up])\nemployee_up['Attritionr'].value_counts()\n\nX_up = employee_up.drop('Attritionr', axis=1)\ny_up = employee_up['Attritionr']","054d8a9f":"### GridSearchCV","b05e081c":"X_up_train, X_up_test, y_up_train, y_up_test = train_test_split(X_up, y_up, test_size = 0.33, random_state = 42)\naccuracy_up_GSCV=machinelearning_modeling(X_up_train,y_up_train,'GridSearchCV')","c49b7a3c":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_up_GSCV[0][1]),\n                                        (\"rfc\",accuracy_up_GSCV[0][2]),\n                                        (\"knc\",accuracy_up_GSCV[0][4])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_up_train, y_up_train)\nprint(accuracy_score(votingC.predict(X_up_test),y_up_test))","542abf47":"for i in range(5):\n    Data_type.append('Balanced_up data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_up_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_up_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_up data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,KNC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_up_test),y_up_test))","37656afc":"###RandomizedSearchCV","ee992788":"accuracy_up_RSCV=machinelearning_modeling(X_up_train,y_up_train,'RandomizedSearchCV')","028ee6a3":"votingC = VotingClassifier(estimators = [(\"rfc\",accuracy_up_RSCV[0][2]),\n                                        (\"svm\",accuracy_up_RSCV[0][1])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_up_train, y_up_train)\nprint(accuracy_score(votingC.predict(X_up_test),y_up_test))","b6cb11e5":"for i in range(5):\n    Data_type.append('Balanced_up data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_up_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_up_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_up data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,RFC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_test),y_test))","cdfd197f":"employee_no_down = resample(employee_no,\n                                     replace = True,\n                                     n_samples = len(employee_yes),\n                                     random_state = 111)\n\nemployee_down = pd.concat([employee_yes, employee_no_down])\nemployee_down['Attritionr'].value_counts()\n\nX_down = employee_down.drop('Attritionr', axis=1)\ny_down = employee_down['Attritionr']","fe18b5f6":"## GridSearchCV","fa2dc4e1":"X_down_train, X_down_test, y_down_train, y_down_test = train_test_split(X_down, y_down, test_size = 0.33, random_state = 42)\naccuracy_down_GSCV=machinelearning_modeling(X_down_train,y_down_train,'GridSearchCV')","ac86bf69":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_down_GSCV[0][1]),\n                                        (\"rfc\",accuracy_down_GSCV[0][2]),\n                                        (\"lr\",accuracy_down_GSCV[0][3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_down_train, y_down_train)\nprint(accuracy_score(votingC.predict(X_down_test),y_down_test))","1dc0e57b":"for i in range(5):\n    Data_type.append('Balanced_down data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_down_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_down_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_down data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_down_test),y_down_test))","a59c61f1":"##RandomizedSearchCV","c06b7b51":"accuracy_down_RSCV=machinelearning_modeling(X_down_train,y_down_train,'RandomizedSearchCV')","313f1cdd":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_down_RSCV[0][1]),\n                                        (\"dtc\",accuracy_down_RSCV[0][0])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_down_train, y_down_train)\nprint(accuracy_score(votingC.predict(X_down_test),y_down_test))","40046dbf":"for i in range(5):\n    Data_type.append('Balanced_down data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_down_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_down_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_down data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,DTC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_down_test),y_down_test))","a90b91c0":"from imblearn.over_sampling import SMOTE\ny=employee_new['Attritionr']\nX = employee_new.drop('Attritionr', axis=1)\n\nsm = SMOTE(random_state=27)\nX_smote, y_smote = sm.fit_resample(X, y)\n\nemployee_smote = pd.concat([X_smote, y_smote],axis=1)\n\nX_smote = employee_smote.drop('Attritionr', axis=1)\ny_smote = employee_smote['Attritionr']","b81c00aa":"## GridSearchCV","a00203ce":"X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.33, random_state = 42)\naccuracy_smote_GSCV=machinelearning_modeling(X_smote_train,y_smote_train,'GridSearchCV')","fb0d158f":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_smote_GSCV[0][1]),\n                                        (\"rfc\",accuracy_smote_GSCV[0][2]),\n                                        (\"lr\",accuracy_smote_GSCV[0][3]),\n                                        (\"knc\",accuracy_smote_GSCV[0][4])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_smote_train, y_smote_train)\nprint(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","20292a8a":"for i in range(5):\n    Data_type.append('Balanced_smote data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_smote_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_smote_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_smote data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR,KNC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","bf61c384":"## RandomizedSearchCV","f1cf2874":"accuracy_smote_RSCV=machinelearning_modeling(X_smote_train,y_smote_train,'RandomizedSearchCV')","ad2cc4b5":"votingC = VotingClassifier(estimators = [(\"lr\",accuracy_smote_RSCV[0][3]),\n                                         (\"rfc\",accuracy_smote_RSCV[0][2]),\n                                        (\"svm\",accuracy_smote_RSCV[0][1])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_smote_train, y_smote_train)\nprint(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","24d71ca5":"for i in range(5):\n    Data_type.append('Balanced_smote data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_smote_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_smote_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_smote data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","8c4befe8":"from imblearn.over_sampling import ADASYN\ny=employee_new['Attritionr']\nX = employee_new.drop('Attritionr', axis=1)\n\nad = ADASYN()\nX_adasyn, y_adasyn = ad.fit_resample(X, y)\n\nemployee_adasyn = pd.concat([X_adasyn, y_adasyn],axis=1)\n\nX_adasyn = employee_adasyn.drop('Attritionr', axis=1)\ny_adasyn = employee_adasyn['Attritionr']","d69868c5":"##GridSearchCV","e16d0b94":"X_adasyn_train, X_adasyn_test, y_adasyn_train, y_adasyn_test = train_test_split(X_adasyn, y_adasyn, test_size = 0.33, random_state = 42)\naccuracy_adasyn_GSCV=machinelearning_modeling(X_adasyn_train,y_adasyn_train,'GridSearchCV')","69cd62ec":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_adasyn_GSCV[0][1]),\n                                        (\"rfc\",accuracy_adasyn_GSCV[0][2]),\n                                        (\"lr\",accuracy_adasyn_GSCV[0][3]),\n                                        (\"knc\",accuracy_adasyn_GSCV[0][4])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_adasyn_train, y_adasyn_train)\nprint(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))","87a62dd7":"for i in range(5):\n    Data_type.append('Balanced_adasyn data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_adasyn_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_adasyn_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_adasyn data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR,KNC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))","0d7e85da":"###RandomizedSearchCV","c3c6cbee":"accuracy_adasyn_RSCV=machinelearning_modeling(X_adasyn_train,y_adasyn_train,'RandomizedSearchCV')","e6e9133e":"votingC = VotingClassifier(estimators = [(\"rfc\",accuracy_adasyn_RSCV[0][2]),\n                                        (\"svm\",accuracy_adasyn_RSCV[0][1])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_adasyn_train, y_adasyn_train)\nprint(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))","05287999":"for i in range(5):\n    Data_type.append('Balanced_adasyn data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_adasyn_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_adasyn_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_adasyn data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,RFC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))\nAccuracy_Score=np.round(Accuracy_Score,4)","14c4cb80":"Results = pd.DataFrame({\"Data_type\":Data_type, \"CV_method\":CV_method,\"ML_Algorithm\":ML_Algorithm,\"Accuracy_Score\":Accuracy_Score})\n\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(Results.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[Results.Data_type,Results.CV_method,Results.ML_Algorithm,Results.Accuracy_Score],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()\n","b330ae6c":"Ascending_Score_best10=Results.sort_values('Accuracy_Score',ascending=False)\nAscending_Score_best10.head(10)\n\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(Ascending_Score_best10.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[Ascending_Score_best10.Data_type,Ascending_Score_best10.CV_method,Ascending_Score_best10.ML_Algorithm,Ascending_Score_best10.Accuracy_Score],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()","8acc0361":"<a id= '15'><\/a><br>\n<font color ='blue' >\n### Adasyn Dataset","b8c5cf95":"<a id= '13'><\/a><br>\n<font color ='blue' >\n###  Under-sampling Dataset","c384315f":"When PCA for the Age, MonthlyIncome and TotalWorkingYears features, We first found the value of n.","e1603477":"<a id= '2'><\/a><br>\n<font color ='blue' >\n# Variable Description","eee1a63a":"<a id= '11'><\/a><br>\n<font color ='blue' >\n### Inbalanced Dataset","139417c5":"#### YearsAtCompany--YearsInCurrentRole--YearsSinceLastPromotion--YearsWithCurrManager","64144a82":"<a id= '14'><\/a><br>\n<font color ='blue' >\n### Smote Dataset","b1d33ee0":"##### When I observed the correlation matrix and the graphs above,I will get new features by combining the highly related ones with PCA.","b0015705":"<a id= '3'><\/a><br>\n<font color ='blue' >\n# Outlier Detection","7d7f7c25":"<a id= '1'><\/a><br>\n<font color ='blue' >\n# Load and Check Data","cef7ecb6":"<a id= '8'><\/a><br>\n<font color ='blue' >\n# MODELING","ccb846d5":"Feature descriptions are below:\n\n    * AGE: Numerical Value\n    * ATTRITION: Employee leaving the company (0=no, 1=yes)\n    * BUSINESS TRAVEL: (1=No Travel, 2=Travel Frequently, 3=Tavel Rarely)\n    * DAILY RATE: Numerical Value - Salary Level\n    * DEPARTMENT: (1=HR, 2=R&D, 3=Sales)\n    * DISTANCE FROM HOME: Numerical Value - THE DISTANCE FROM WORK TO HOME\n    * EDUCATION: Numerical Value\n    * EDUCATION FIELD: (1=HR, 2=LIFE SCIENCES, 3=MARKETING, 4=MEDICAL SCIENCES, 5=OTHERS, 6= TEHCNICAL)\n    * ENVIROMENT SATISFACTION: Numerical Value - SATISFACTION WITH THE ENVIROMENT\n    * GENDER: (1=FEMALE, 2=MALE)\n    * HOURLY RATE: Numerical Value - HOURLY SALARY\n    * JOB INVOLVEMENT: Numerical Value - JOB INVOLVEMENT\n    * JOB LEVEL: Numerical Value - LEVEL OF JOB\n    * JOB ROLE: (1=HC REP, 2=HR, 3=LAB TECHNICIAN, 4=MANAGER, 5= MANAGING DIRECTOR, 6= REASEARCH DIRECTOR, 7= RESEARCH SCIENTIST, 8=SALES EXECUTIEVE, 9= SALES REPRESENTATIVE)\n    * JOB SATISFACTION: Numerical Value - SATISFACTION WITH THE JOB\n    * MARITAL STATUS: (1=DIVORCED, 2=MARRIED, 3=SINGLE)\n    * MONTHLY INCOME: Numerical Value - MONTHLY SALARY\n    * MONTHY RATE: Numerical Value - MONTHY RATE\n    * NUMCOMPANIES WORKED: Numerical Value - NO. OF COMPANIES WORKED AT\n    * OVERTIME: (1=NO, 2=YES)\n    * PERCENT SALARY HIKE: Numerical Value - PERCENTAGE INCREASE IN SALARY\n    * PERFORMANCE RATING: Numerical Value - ERFORMANCE RATING\n    * RELATIONS SATISFACTION: Numerical Value - RELATIONS SATISFACTION\n    * STOCK OPTIONS LEVEL: Numerical Value - STOCK OPTIONS\n    * TOTAL WORKING YEARS: Numerical Value - TOTAL YEARS WORKED\n    * TRAINING TIMES LAST YEAR: Numerical Value - HOURS SPENT TRAINING\n    * WORK LIFE BALANCE: Numerical Value - TIME SPENT BEWTWEEN WORK AND OUTSIDE\n    * YEARS AT COMPANY: Numerical Value - TOTAL NUMBER OF YEARS AT THE COMPNAY\n    * YEARS IN CURRENT ROLE: Numerical Value -YEARS IN CURRENT ROLE\n    * YEARS SINCE LAST PROMOTION: Numerical Value - LAST PROMOTION\n    * YEARS WITH CURRENT MANAGER: Numerical Value - YEARS SPENT WITH CURRENT MANAGER\n","6a5183c0":"\nInstead of deleting the features one by one according to their outlier, I deleted the outlier values \u200b\u200bof the features on the common lines.","1365a2da":"<a id= '12'><\/a><br>\n<font color ='blue' >\n### Over sampling Dataset","879c4062":"#### Dropped Feature\n\n Feature that has 1470 unique value\n    \n    * 'EmployeeNumber'\n    \n   \n Feature that has 1 unique value\n \n    * 'Over18'\n    * 'StandardHours' \n    * 'EmployeeCount'","7372b191":"#### HourlyRate, DailyRate, MonthlyRate\nThe p values of the HourlyRate, DailyRate, MonthlyRate features in the Ttest are around 0.05 or above. Therefore, there does not appear to be a significant difference in terms of continuous value. Nevertheless, I visualized these features and observed his behavior categorically about leaving the job.","16fdf747":"We are checking a null value. If there is, we will evaluate it and delete it or add it with an estimate.","9dbf53d8":"I looked at the number of unique values of each feature. We will also benefit from this information when determining the data type of the features.","f7eb8a4f":"<a id= '17'><\/a><br>\n<font color ='blue' >\n### Best 10 Value Score Table","f33f772a":"<a id= '10'><\/a><br>\n<font color ='blue' >\n## Ensemble modelling with inbalanced and balanced dataset\n","d365f90c":"When PCA for the YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion and YearsWithCurrManager features, We first found the value of n.","601a2f26":"<a id= '5'><\/a><br>\n<font color ='blue' >\n# Basic Data Analysis and Feature Engineering","4c39ce7c":"<a id= '16'><\/a><br>\n<font color ='blue' >\n## Accuracy Score Table","d4d26683":"<a id= '4'><\/a><br>\n<font color ='blue' >\n# Missing Value","e5615138":"#### Age-MonthlyIncome-TotalWorkingYears","7756dd8c":"<a id= '9'><\/a><br>\n<font color ='blue' >\n## Train - Test Split-- Hyperparameter Tuning -- Cross Validation Setings","92b5cf32":"<a id= '6'><\/a><br>\n<font color ='blue' >\n## Numerical Variable","b27b6fce":"Categorical Variable:\n\n    * 'BusinessTravel'\n    * 'Department'\n    * 'Education'\n    * 'EducationField'\n    * 'EnvironmentSatisfaction'\n    * 'Gender'\n    * 'JobInvolvement'\n    * 'JobLevel'\n    * 'JobRole'\n    * 'JobSatisfaction'\n    * 'MaritalStatus'\n    * 'NumCompaniesWorked'\n    * 'OverTime'\n    * 'PerformanceRating'\n    * 'RelationshipSatisfaction'\n    * 'StockOptionLevel'\n    * 'TrainingTimesLastYear'\n    * 'WorkLifeBalance'\n    * 'PercentSalaryHike'\n    * 'DistanceFromHome'\n    \nNumerical Variable:\n\n    * 'Age'\n    * 'DailyRate'\n    * 'YearsSinceLastPromotion'\n    * 'HourlyRate'\n    * 'MonthlyIncome'\n    * 'MonthlyRate'\n    * 'TotalWorkingYears'\n    * 'YearsAtCompany'\n    * 'YearsWithCurrManager'\n    * 'YearsInCurrentRole\n\n Target Variable:\n \n    * 'Attrition' \n","df0bc004":"We obtain the best_estimator, cv_result values of 5 machine learning algorithm  method with the following function","d9374a72":"# Introduction\n\n<font color ='blue' >\nContent:\n\n1. [Load and Check Data](#1)\n    \n2. [Variable Description](#2)\n    \n3. [Outlier Detection](#3)\n    \n4. [Missing Value](#4)\n    \n5. [Basic Data Analysis and Feature Engineering](#5)\n    \n  5.1. [Numerical Variable](#6)\n    \n  5.2. [Categorical Variable](#7)\n    \n6. [Modeling](#8)\n    \n  6.1 [Hyperparameter Tuning -- Cross Validation Setings](#9)\n    \n  6.2 [Ensemble modelling with inbalanced and balanced dataset](#10)\n        \n    6.2.1 [Inbalanced Dataset](#11)\n    \n    6.2.1 [Over sampling Dataset](#12)\n    \n    6.2.2 [Under sampling the Dataset](#13)\n    \n    6.2.3 [Smote Dataset](#14)\n    \n    6.2.4 [Adasyn Dataset](#15)\n    \n7. [Accuracy Score Table](#16)\n  7.1 [Best 10 Value Score Table](#17)\n    \n    \n    \n\n    ","2510bbfc":"<a id= '7'><\/a><br>\n<font color ='blue' >\n## Categorical Variable","f975a6b4":"We will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression\n\nWe use 2 cv types Grid and Search","eb850df2":"\n    * Dataset structure: 1470 sat\u0131r, 35 \u00f6zellik\n    * Data type: int64 ve object\n    * Imbalanced dataset: 1233 (84%) 'no' attrition and 237 (16%) 'yes' attrition\n\n","c31c0c56":"Using the \"IBM HR Analytics Employee Attrition & Performance\" dataset, what are the factors that affect the dismissal of IBM company?  I selected the 'Attrition' feature as my Target feature in our dataset, that is Target."}}