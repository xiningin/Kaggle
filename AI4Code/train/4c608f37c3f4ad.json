{"cell_type":{"769004da":"code","81a94466":"code","4844a0a5":"code","0699be03":"code","7515a1e0":"code","dc1ff9fe":"code","d1254a3b":"code","27f5f56f":"code","f1fad2f6":"code","fb64575d":"code","f558fd40":"code","d9098272":"code","c6862665":"code","6d084c87":"code","61494daf":"markdown","fe82de0d":"markdown","dd13f116":"markdown","2283fafe":"markdown","1e64a407":"markdown","39543052":"markdown"},"source":{"769004da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81a94466":"import gc\nimport random\n\nfrom IPython import display as ipd\nfrom tqdm import tqdm\nimport lightgbm as lgb\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\nfrom sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pandas_profiling import ProfileReport as profile\n\nimport pkg_resources as pkg\nprint( f\"pandas_profiling version: {pkg.get_distribution('pandas_profiling').version}\")","4844a0a5":"def seeding(SEED, use_tf=False):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    if use_tf:\n        tf.random.set_seed(SEED)\n    print('seeding done!!!')","0699be03":"RANDOM_SEED = 42\nDEBUG = True\n\n## easy EDA option\nPROFILE = False\n\nseeding(RANDOM_SEED)\n\ntrain = pd.read_csv('..\/input\/tabular-playground-series-feb-2022\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-feb-2022\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-feb-2022\/sample_submission.csv')","7515a1e0":"train.info()","dc1ff9fe":"## display missing data\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(10)","d1254a3b":"target = train.target\ntrain.drop(['target'], axis=1, inplace=True) ","27f5f56f":"encoder = LabelEncoder()\ntarget = pd.DataFrame(encoder.fit_transform(target), columns=['target'])\ntarget = target.astype(int)","f1fad2f6":"f, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.countplot(x='target', data=target)\nplt.title('Target', fontsize=15)\nplt.show()","fb64575d":"TOTAL_SPLITS = 4\nN_REPEATS = 2\nNUM_BOOST_ROUND = 600\nEARLY_STOPPING_ROUNDS = 50\nVERBOSE_EVAL = 100\n\ndef run_train(X, y, run_params, splits, num_boost_round, verbose_eval, early_stopping_rounds ):\n    scores = []\n    models = []\n    eval_results = {}  # to record eval results for plotting\n    folds = StratifiedKFold(n_splits=splits)\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print(f'Fold {fold_n+1} started')\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        model = lgb.train(\n            run_params, valid_names=[\"train\", \"valid\"], \n            train_set=lgb.Dataset(X_train, y_train ), \n            num_boost_round = num_boost_round,\n            valid_sets = [lgb.Dataset(X_valid, y_valid)],\n            callbacks=[lgb.log_evaluation(verbose_eval), \n               lgb.early_stopping(early_stopping_rounds, False, True),\n               lgb.record_evaluation(eval_result=eval_results)],\n        )\n\n        y_pred = model.predict(X_valid)\n        y_pred = y_pred.argmax(axis = 1)\n        score = f1_score(y_valid, y_pred, average='weighted')\n        print(f'F1 score: {score}')\n        \n        models.append(model)\n        scores.append(score)\n    return scores, models, eval_results\n\n\nrun_params = {\n    'verbosity': -1,\n    'num_class' : 10,\n    'boosting_type': 'dart', \n    'objective': 'multiclass', \n    'metric': ['multi_logloss'],\n    'force_col_wise' : True,\n    'eta': 0.099,\n}\n\n\nscores, models, eval_results = run_train(train, target, run_params, \n                    TOTAL_SPLITS, NUM_BOOST_ROUND, VERBOSE_EVAL, EARLY_STOPPING_ROUNDS)","f558fd40":"ax = lgb.plot_metric(eval_results, metric='multi_logloss')\nplt.show()","d9098272":"y_pred = models[0].predict(train)\ny_pred = y_pred.argmax(axis = 1)\nprint(classification_report(target, y_pred, target_names=encoder.classes_))","c6862665":"predicted = []\nfor model in models:\n    predicted.append(np.argmax(model.predict(test), axis=1))\n    \ntest_pred = np.mean(predicted, axis=0).astype(int)   ","6d084c87":"submission['target'] = encoder.inverse_transform(test_pred)\nsubmission.to_csv('submission.csv', index=False, float_format='%.6f')\nsubmission.head(20)","61494daf":"### Utils","fe82de0d":"### Classification Report","dd13f116":"### Model","2283fafe":"### Submit","1e64a407":"### Data load","39543052":"### Encode target"}}