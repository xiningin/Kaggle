{"cell_type":{"652e3ce4":"code","0c27b02d":"code","4a24da31":"code","ce3d1988":"code","3eb42c54":"code","1fe15361":"code","77f33c06":"code","b78d47b1":"code","4f5ffe4d":"markdown","47adf724":"markdown","bdf41e6b":"markdown","7d45161e":"markdown","664609db":"markdown"},"source":{"652e3ce4":"import os\n\nimport sys\nsys.path.append('..\/input\/renom-lib\/ReNom')\nsys.path.append('..\/input\/renom-lib\/ReNom\/renom')\nsys.path.append('..\/input\/renom-lib\/ReNom\/renom\/cuda')\n\nfrom xml.etree import ElementTree\nfrom itertools import product\n#import urllib.request as request\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom PIL import ImageDraw\nimport colorsys\nimport matplotlib.pyplot as plt\n#from keras.models import load_model, Model\n\n# ReNom version >= 2.3.0\nimport renom as rm\nfrom renom.cuda import set_cuda_active\nfrom renom.utility.trainer import Trainer\nfrom renom.algorithm.image.detection.yolo import build_truth, Yolo, apply_nms, box_iou\nfrom renom.utility.distributor import ImageDetectionDistributor\nfrom renom.utility.image import *\n\nset_cuda_active(True)","0c27b02d":"dataset_path = \"..\/input\/pascal-voc-2012\/VOC2012\/Annotations\"\n\ntrain_file_list = [path for path in sorted(os.listdir(dataset_path)) if not \"2012_\" in path]\ntest_file_list = [path for path in os.listdir(dataset_path) if \"2012_\" in path]\n\ntree = ElementTree.parse(os.path.join(dataset_path, train_file_list[-1]))","4a24da31":"def parse(node, indent=1):\n    print(\"{}{} {}\".format('    ' * indent, node.tag, node.text.strip()))\n    for child in node:\n        parse(child, indent + 1)\n        \nprint(\"\/\/\/ Contents of a XML file \/\/\/\")\nparse(tree.getroot())","ce3d1988":"label_dict = {}\nimg_size = (224*2, 224*2)\ncells = 7\n\ndef get_obj_coordinate(obj):\n    global label_dict\n    class_name = obj.find(\"name\").text.strip()\n    if label_dict.get(class_name, None) is None:\n        label_dict[class_name] = len(label_dict)\n    class_id = label_dict[class_name]\n    bbox = obj.find(\"bndbox\")\n    xmax = float(bbox.find(\"xmax\").text.strip())\n    xmin = float(bbox.find(\"xmin\").text.strip())\n    ymax = float(bbox.find(\"ymax\").text.strip())\n    ymin = float(bbox.find(\"ymin\").text.strip())\n    w = xmax - xmin\n    h = ymax - ymin\n    x = xmin + w\/2\n    y = ymin + h\/2\n    return class_id, x, y, w, h\n    \ndef get_img_info(filename):\n    tree = ElementTree.parse(filename)\n    node = tree.getroot()\n    file_name = node.find(\"filename\").text.strip()\n    img_h = float(node.find(\"size\").find(\"height\").text.strip())\n    img_w = float(node.find(\"size\").find(\"width\").text.strip())\n    obj_list = node.findall(\"object\")\n    objects = []\n    for obj in obj_list:\n        objects.append(get_obj_coordinate(obj))\n    return file_name, img_w, img_h, objects\n        ","3eb42c54":"train_data_set = []\ntest_data_set = []\n\nfor o in train_file_list:\n    train_data_set.append(get_img_info(os.path.join(dataset_path, o)))\n    \nfor o in test_file_list:\n    test_data_set.append(get_img_info(os.path.join(dataset_path, o)))","1fe15361":"# Example and class labels.\nprint(\"{}\".format(train_data_set[-1]))\nprint()\nprint(\"%-12s: number\"%(\"class name\"))\nprint(\"----------------------\")\nfor k, v in sorted(label_dict.items(), key=lambda x:x[1]):\n    print(\"%-12s: %d\"%(k, v))","77f33c06":"label_length = len(label_dict)\nlast_layer_size = cells*cells*(5*2+label_length)\n\ndef one_hot(label):\n    oh = [0]*label_length\n    oh[label] = 1\n    return oh\n\ndef create_detection_distributor(train_set=True):\n    label_data = []\n    img_path_list = []\n    label_list = []\n    if train_set:\n        file_list = train_file_list\n        data_set = train_data_set\n        # Augumentation Settngs\n        augmentatiion = DataAugmentation(\n            [\n                Flip(1),\n                Rotate(90),\n                # Resize(size=img_size),\n                Shift((20, 20)),\n                # ColorJitter(v=(1.0, 1.5)),\n                # Zoom(zoom_rate=(1.0, 1.1)),\n                Rescale(option=[-1, 1])\n            ],\n            random=True\n        )\n    else:\n        file_list = test_file_list\n        data_set = test_data_set\n        augmentatiion = DataAugmentation(\n            [Rescale(option=[-1, 1])],\n        )\n    for i in range(len(file_list)):\n        img_path = os.path.join(\"..\/input\/pascal-voc-2012\/VOC2012\/JPEGImages\", data_set[i][0])\n        \n        # obj[1]:X, obj[2]:Y, obj[3]:Width, obj[4]:Height, obj[0]:Class\n        objects = []\n        for obj in data_set[i][3]:\n            detect_label = {\"bndbox\":[obj[1], obj[2], obj[3], obj[4]],\n                            \"name\":one_hot(obj[0])}\n            objects.append(detect_label)\n        img_path_list.append(img_path)\n        label_list.append(objects)\n    class_list = [c for c, v in sorted(label_dict.items(), key=lambda x:x[1])]\n    return ImageDetectionDistributor(img_path_list,\n                                     label_list,\n                                     class_list,\n                                     imsize = img_size,\n                                     augmentation=augmentatiion)\n\ndef transform_to_yolo_format(label):\n    yolo_format = []\n    for l in label:\n        yolo_format.append(build_truth(l.reshape(1, -1), img_size[0], img_size[1], cells, label_length).flatten())\n    return np.array(yolo_format)\n\ndef draw_rect(draw_obj, rect):\n    cor = (rect[0][0], rect[0][1], rect[1][0], rect[1][1])\n    line_width = 3\n    for i in range(line_width):\n        draw_obj.rectangle(cor, outline=\"red\")  \n        cor = (cor[0]+1,cor[1]+1, cor[2]+1,cor[3]+1) \n\ntrain_detect_dist = create_detection_distributor(True)\ntest_detect_dist = create_detection_distributor(False)","b78d47b1":"sample, sample_label = train_detect_dist.batch(3, shuffle=True).__next__()\n\nfor Mth_img in range(len(sample)):\n    example_img = Image.fromarray(((sample[Mth_img]+1)*255\/2).transpose(1, 2, 0).astype(np.uint8))\n    dr = ImageDraw.Draw(example_img)\n\n    print(\"\/\/\/Objects\")\n    for i in range(0, len(sample_label[Mth_img]), 4+label_length):\n        class_label = np.argmax(sample_label[Mth_img][i+4:i+4+label_length])\n        x, y, w, h = sample_label[Mth_img][i:i+4]\n        if x==y==h==w==0:\n            break\n        draw_rect(dr, ((x-w\/2, y-h\/2), (x+w\/2, y+h\/2)))\n        print(\"obj:%d\"%(i+1),\n              \"class:{:7s}\".format([k for k, v in label_dict.items() if v==class_label][0]), \n              \"x:%3d, y:%3d width:%3d height:%3d\"%(x, y, w, h))\n\n    plt.figure(figsize=(4, 4))\n    plt.imshow(example_img)\n    plt.show()\n","4f5ffe4d":"# Load dataset","47adf724":"# Check Label Data","bdf41e6b":"# Import library","7d45161e":"# Getting the bounding box information","664609db":"# ReNom & YOLO Object detection\nThis notebook referred to the following website.<br\/>\nhttp:\/\/renom.jp\/notebooks\/tutorial\/image_processing\/yolo\/notebook.html"}}