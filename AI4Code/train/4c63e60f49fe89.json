{"cell_type":{"66e52c87":"code","a3b30c66":"code","a68845df":"code","6aa1125e":"code","9a305540":"code","5579b728":"markdown","61ed7b37":"markdown","2511dc9d":"markdown","3b0370d0":"markdown","97be374f":"markdown"},"source":{"66e52c87":"import pandas as pd\nimport json\nimport urllib3\nfrom time import sleep\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a3b30c66":"http = urllib3.PoolManager() \nmat_data = pd.DataFrame()\nperiods = [\"1\",\"2\"] # For the two innings in the match\npages = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"] # This refers to the no of requests for the inifinte scrolling\nleagueId=\"8048\" # League ID for IPL in espncricinfo\neventId=\"\" #match ID - will be populated from the URLs later\ndat_url = pd.read_csv(\"..\/input\/ipl-2019-match-data\/match_details.csv\") # match_details extracted using scrapy\n#All IPL 2019 URLs and match data in this file. Python script to extract this in my Github. Refer introduction\neventId_gp= [str(url).split(\"\/\")[6] for url in dat_url[\"url\"]] # Extracting indiviual match ids from the URL\nlen_url= len(eventId_gp)","a68845df":"for count in range(len_url):\n    eventId = eventId_gp[count]\n    for period in periods:\n        for page in pages:\n            sleep(15) # Espncricinfo recommends a scraping delay of 15 seconds\n            col_data = pd.DataFrame()\n            match_dat= http.request('GET', 'https:\/\/hsapi.espncricinfo.com\/v1\/pages\/match\/comments?lang=en&leagueId='+leagueId+'&eventId='+eventId+'&period=' +period+ '&page='+page+'&filter=full&liveTest=false')\n            if(len(match_dat.data)<100):\n                break\n            data = json.loads(match_dat.data)\n            df = pd.json_normalize(data['comments'])\n            bowler=[]\n            batsman=[]\n\n            for bat,bowl in zip(df[\"currentBatsmen\"],df[\"currentBowlers\"]):\n                batsman.append(bat[0][\"name\"])\n                bowler.append(bowl[0][\"name\"])\n\n            df[\"bowler\"]= bowler\n            df[\"batsman\"] = batsman\n            col_data = df.copy()    \n\n            if(period==\"1\"):               \n                df[\"innings\"]=1\n            else:\n                df[\"innings\"]=2\n\n            if(\"matchWicket.text\" in col_data.columns):\n                col_data[\"matchWicket.text\"].fillna(\"NA\",inplace=True)\n                col_data[\"run_out\"]= [\"Yes\" if \"run out\" in wicket_text else \"No\" for wicket_text in col_data[\"matchWicket.text\"]]\n            else:\n                col_data[\"matchWicket.text\"]=\"NA\"\n                col_data[\"run_out\"]=\"No\"\n                   \n         \n            col_data[\"match_id\"] = eventId        \n            mat_data = pd.concat([mat_data,col_data])   ","6aa1125e":"# we are dropping the extra columns below. you can remove columns from the below list which you think are useful\nmat_data.drop([\"id\",\"shortText\",\"text\",\"preText\",\"postText\",\"currentBatsmen\",\"currentBowlers\",\"currentInning.balls\",\"currentInning.runs\",\"currentInning.wickets\",\"matchOver.maiden\",\"matchOver.runs\",\"matchOver.wickets\",\"matchOver.totalRuns\",\"matchOver.totalWicket\",\"matchOver.runRate\",\"matchOver.requiredRunRate\",\"matchOver.batsmen\",\"matchOver.bowlers\",\"matchOver.teamShortName\",\"matchOver.remainingOvers\",\"matchOver.remainingBalls\",\"matchOver.remainingRuns\",\"matchWicket.id\",\"matchWicket.batsmanRuns\",\"matchWicket.batsmanBalls\",\"matchWicket.text\"],axis=1,inplace=True)\nmat_data.to_csv(\"score.csv\")\n","9a305540":"mat_data.head()","5579b728":"# Indian Premier League is back !!!\n\n![](https:\/\/english.cdn.zeenews.com\/sites\/default\/files\/2020\/08\/03\/876688-csk.jpg)\n[Source](https:\/\/english.cdn.zeenews.com\/sites\/default\/files\/2020\/08\/03\/876688-csk.jpg)\n\nWith the onset of IPL 2020, I am sure that we are going to have a lot of EDA and predictions coming our way for this season. Here I have created a small script that helps getting ball by ball details of an IPL match from espncricinfo.com.\n\nThere is another part to this script which uses [scrapy](https:\/\/scrapy.org) to scrape the match data for a particular series. Based on the data we get from that script here we are going to navigate and scrape the data.\n\nThe scrapy script can be accessed on my Github -> [Click here ](https:\/\/github.com\/ankursalunke\/Web-Scraper-Cricket#readme)\n\nThis is meant to be an introduction to web scraping. Here we have only used urllib3 and json since the data is available in json format for these espncricinfo web pages.\n\nIn the below image, if we inspect element in the commentary page we can see in the XML Httprequest we can get the ball by ball data in json format. Since there is infinite scrolling in this page, we will loop overall the pages and extract the data.\n\n![](https:\/\/i.ibb.co\/cT2vbqw\/scrn.png)\n\nIn case of any suggestions please share them in the comments. I hope that this would help kagglers create their datasets for analysis when IPL 2020 kicks off.","61ed7b37":"Initiating all the necessary objects","2511dc9d":"Cleaning up the dataset and exporting it to a CSV file which can be used for EDA and other kinds of analysis.","3b0370d0":"Importing the necessary libraries","97be374f":"We loop over the matches, innings and pages to extract the data and add it to a dataset. We process the data also to create new columns as required."}}