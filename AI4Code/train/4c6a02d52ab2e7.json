{"cell_type":{"535ca82d":"code","0edf7fde":"code","43e79f77":"code","6fc5a761":"code","d30a07a6":"code","e5fbbcb7":"code","45c8280d":"code","3db5a3c4":"code","beef7728":"code","0f90bc88":"code","13328aff":"code","59f1fa14":"code","643d1de3":"code","3d434ca0":"code","b3365c3d":"code","5605fa19":"code","8ffe33fa":"code","2c3a8325":"code","398f41ef":"code","40c815ed":"code","1c5343f2":"code","15599c86":"code","4e4bb919":"code","f1e7140e":"code","620916af":"code","cc02bac8":"code","5f85e97f":"code","3f81ba4d":"code","658895bb":"code","97554a5a":"code","c852c46c":"code","9477fadb":"code","f3a31b16":"code","96e7d04f":"code","6d6cc5d5":"code","09157765":"code","05a3592d":"code","f22985b4":"code","3665e629":"code","6a7fcf84":"code","454567b2":"code","696c322f":"code","3ba96d95":"code","52f859a7":"code","cd6e84b8":"code","b3ea9ef0":"code","a178dd40":"code","ea48a7c6":"code","a74c7602":"code","9b2523b5":"code","01163c91":"code","addaa250":"code","4529441b":"code","85784bfb":"code","b393783b":"code","15b48fab":"code","52d86aae":"markdown","c3867c76":"markdown","a69b05de":"markdown","cf780d38":"markdown"},"source":{"535ca82d":"from datetime import datetime\n\nprint(\"last update: {}\".format(datetime.now())) ","0edf7fde":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","43e79f77":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split,  GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier,  ExtraTreesClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, roc_auc_score\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMModel,LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom mlxtend.classifier import StackingCVClassifier\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nimport numpy as np\nnp.random.seed(0)","6fc5a761":"# Read the data\nX_original = pd.read_csv('\/kaggle\/input\/learn-together\/train.csv', index_col='Id')\nX_test = pd.read_csv('\/kaggle\/input\/learn-together\/test.csv', index_col='Id')\nX = X_original.drop('Cover_Type', axis = 1)\ny = X_original['Cover_Type']","d30a07a6":"X.tail()","e5fbbcb7":"X_test.head()","45c8280d":"print(X['Soil_Type7'].unique(), X['Soil_Type15'].unique())","3db5a3c4":"X.shape[0]","beef7728":"X.drop(['Soil_Type7', 'Soil_Type15'], axis = 1, inplace = True)\nX_test.drop(['Soil_Type7', 'Soil_Type15'], axis = 1, inplace = True)","0f90bc88":"#Create single soil field (reverse the one hot encoding)\nsoil_fields = [col for col in X if col.startswith('Soil_Type')]\ntrain_soil = X[soil_fields]\ntest_soil = X_test[soil_fields]\nX['Soil_Type'] = train_soil.idxmax(axis = 1).apply(lambda x: x.split('Type')[-1]).astype(int)\nX_test['Soil_Type'] = test_soil.idxmax(axis = 1).apply(lambda x: x.split('Type')[-1]).astype(int)\nX.drop(soil_fields, inplace = True, axis = 1)\nX_test.drop(soil_fields, inplace = True, axis = 1)\n#Create single wilderness area field (reverse the one hot encoding)\nWilderness_Area_Fields = [col for col in X if col.startswith('Wilderness_Area')]\n\ntrain_wilderness = X[Wilderness_Area_Fields]\ntest_wilderness = X_test[Wilderness_Area_Fields]\nX['Wilderness_Area'] = train_wilderness.idxmax(axis = 1).apply(lambda x: x.split('Area')[-1]).astype(int)\nX_test['Wilderness_Area'] = test_wilderness.idxmax(axis = 1).apply(lambda x: x.split('Area')[-1]).astype(int)\nX.drop(Wilderness_Area_Fields, inplace = True, axis = 1)\nX_test.drop(Wilderness_Area_Fields, inplace = True, axis = 1)\nX.head()\n","13328aff":"print(X['Soil_Type'].unique())\nlen(X['Soil_Type'].unique())","59f1fa14":"X_test.shape","643d1de3":"set(X['Soil_Type'].unique()) == set(X_test['Soil_Type'].unique()) ","3d434ca0":"# O stand for missing values\ndict = {}\nfor col in X_test.columns.tolist()[:10]:\n    dict[col] = X_test[X_test[col] == 0].shape[0]\ndict ","b3365c3d":"var = list(dict.keys())\nheight = list(dict.values())\nprint(var)\nprint(height)","5605fa19":"plt.figure(figsize = (15,7))\npos = np.arange(len(var))\nbars = plt.barh(pos, height)\nplt.yticks(pos, var)\nplt.xlabel(\"# of zeros values\")\nplt.title('check for zeros values')\nplt.tick_params(top = False, left = False, bottom = False, labelbottom = False)\n# remove frames\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\n\nfor bar in bars:\n    plt.gca().text(bar.get_width()+1.2, bar.get_y()+bar.get_height()\/2, str(int(bar.get_width())))\n    \n    \nbars[4].set_color('red')\nbars[3].set_color('gray')","8ffe33fa":"X[['Soil_Type', 'Wilderness_Area']] = X[['Soil_Type', 'Wilderness_Area']].astype(int)\nX_test[['Soil_Type', 'Wilderness_Area']] = X_test[['Soil_Type', 'Wilderness_Area']].astype(int)","2c3a8325":"X.dtypes","398f41ef":"import featuretools as ft\nfrom featuretools import selection\nfrom featuretools.primitives import make_trans_primitive\nfrom featuretools.variable_types import Numeric\nimport featuretools.variable_types as vtypes","40c815ed":"# Merge forest data\nforest = X.append(X_test, sort=False)","1c5343f2":"forest.head()","15599c86":"print(forest.shape)\nprint(f\"total rows:{X.shape[0] + X_test.shape[0]}\")","4e4bb919":"len(forest['Soil_Type'].unique())","f1e7140e":"def power(column):\n    return column**2\n\nPower = make_trans_primitive(function = power,\n                             input_types = [Numeric],\n                             return_type=Numeric)\n","620916af":"# Create an entity set\nes = ft.EntitySet(id='forest_data')","cc02bac8":"ID = ft.variable_types.Id","5f85e97f":"variable_types = {'Soil_Type': vtypes.Categorical, 'Wilderness_Area': vtypes.Categorical, 'Id': ID}","3f81ba4d":"es.entity_from_dataframe(entity_id = 'data', dataframe = forest.reset_index(),\n                         index = 'Id',variable_types = variable_types)","658895bb":"es['data']","97554a5a":"es.normalize_entity(base_entity_id= 'data',\n                    new_entity_id='Soil',\n                    index='Soil_Type')","c852c46c":"es['Soil'].df.shape","9477fadb":"es.normalize_entity(base_entity_id= 'data',\n                    new_entity_id='Wild_Area',\n                    index='Wilderness_Area')","f3a31b16":"es['Wild_Area'].shape","96e7d04f":"es.plot()","6d6cc5d5":"ft.list_primitives()['type'].value_counts()","09157765":"# Loop on differents aggregation primitives\n#pd.options.display.max_rows = 10\nfunc = ft.list_primitives()\nfunc[func['type'] == 'aggregation']","05a3592d":"# Loop on differents transformation primitives\n# import random  \nfrom random import sample \nfunc = ft.list_primitives()\nfunc[func['type'] == 'transform'].sample(10)","f22985b4":"trans_primitives = ['add_numeric', 'multiply_numeric']","3665e629":"# Run deep feature synthesis with transformation primitives\nfeature_matrix, feature_defs = ft.dfs(entityset = es, target_entity = 'data',\n                                      agg_primitives = ['median', 'std', 'mean', 'mode'],\n                                      trans_primitives = ['add_numeric'],\n                                      n_jobs = -1,\n                                     verbose = True)\n\nfeature_matrix.head()","6a7fcf84":"# Remove low information features\nfeature_matrix = selection.remove_low_information_features(feature_matrix)","454567b2":"feature_matrix.shape","696c322f":"from random import sample\nfeature_defs","3ba96d95":"# Check for missing values\nfeature_matrix.isnull().sum().sum()","52f859a7":"# Split data\ntrain_X = feature_matrix[:15120]\ntest_X = feature_matrix[15120:]","cd6e84b8":"# Remove specific columns\n#train_X.drop(['Soil_Type', 'Wilderness_Area'], axis = 1, inplace = True)\n#test_X.drop(['Soil_Type', 'Wilderness_Area'], axis = 1, inplace = True)","b3ea9ef0":"train_X.tail()","a178dd40":"test_X.head()","ea48a7c6":"# Check of dataframe\ntest_X.iloc[:,:10].equals(X_test.iloc[:,:10])","a74c7602":"from sklearn.multiclass import OneVsRestClassifier\n#xgb_clf = OneVsRestClassifier(XGBClassifier(learning_rate =0.05, n_estimators=1000, n_jobs = -1))","9b2523b5":"# Meta Classifier\nmeta_cls = XGBClassifier(learning_rate =0.05, n_estimators=1000)","01163c91":"from sklearn.neighbors import KNeighborsClassifier","addaa250":"list_estimators = [RandomForestClassifier(n_estimators=500, max_features = 'sqrt',\n                                random_state=1, n_jobs=-1), \n                   XGBClassifier(learning_rate =0.1, n_estimators=500, random_state=1, n_jobs=-1), \n                   LGBMClassifier(n_estimators=500,verbosity=0, random_state=1, n_jobs=-1),\n                   KNeighborsClassifier(n_jobs = -1),\n                  ExtraTreesClassifier(n_estimators=500, max_features = 'sqrt',random_state=1, n_jobs=-1)]\nbase_methods = [\"RandomForestClassifier\", \"XGBClassifier\", \"LGBMClassifier\", \"KNeighborsClassifier\", \"ExtraTreesClassifier\"]\n#base_methods ","4529441b":"y.shape","85784bfb":"from mlxtend.classifier import StackingCVClassifier\n\nstate = 1\nstack = StackingCVClassifier(classifiers=list_estimators,\n                             meta_classifier=meta_cls,\n                             cv=3,\n                             use_probas=True,\n                             verbose=1, \n                             random_state=state,\n                             n_jobs=-1)","b393783b":"stack.fit(train_X.values, y.values)","15b48fab":"preds_test = stack.predict(test_X.values)\n# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'Cover_Type': preds_test})\noutput.to_csv('submission.csv', index=False)","52d86aae":"## Automated Feature engineering","c3867c76":"## lot of zeros values","a69b05de":"## Stacking","cf780d38":"### Check index of train and test set"}}