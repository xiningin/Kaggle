{"cell_type":{"90ac07ee":"code","0f3397b4":"code","514ce119":"code","0e30878c":"code","fdec722f":"code","9e595991":"code","6a78e22c":"code","ca863a1d":"code","a6176970":"code","c5a23c5c":"code","e34111fe":"code","76c4ed1c":"code","e8cddeb7":"code","983227e5":"code","1c45f0e4":"code","f08253a3":"code","833d9c30":"markdown"},"source":{"90ac07ee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')","0f3397b4":"df = pd.read_csv('\/kaggle\/input\/wineuci\/Wine.csv',header=None)\n#df = pd.read_csv('\/kaggle\/input\/iris-dataset\/iris.data.csv',header=None)\n\ndf.columns = [  'name'\n                 ,'alcohol'\n             ,'malicAcid'\n             ,'ash'\n            ,'ashalcalinity'\n             ,'magnesium'\n            ,'totalPhenols'\n             ,'flavanoids'\n             ,'nonFlavanoidPhenols'\n             ,'proanthocyanins'\n            ,'colorIntensity'\n            ,'hue'\n             ,'od280_od315'\n             ,'proline'\n                ]\ndf.head()","514ce119":"df.describe()","0e30878c":"df.info()","fdec722f":"corr = df[df.columns].corr()\nsns.heatmap(corr, cmap=\"YlGnBu\", annot = True);","9e595991":"print(\"Perceptron Model:\\n\")\nprint(\"We will split the data into train and test.The model is trained with train dataset and \\\nweights and bias are estimated.This weight and bias is used to evaluate the test dataset\")\n","6a78e22c":"train,test = train_test_split(df,test_size=0.3)\n\nscaler = StandardScaler()\nencode = LabelEncoder()\n\nX= train.drop(['name','ash'], axis=1).values\nX = scaler.fit_transform(X)\n\ny = train.iloc[:,0].values\ny = encode.fit_transform(y)\n\nfinal_X=  test.drop(['name','ash'], axis=1).values\nfinal_X = scaler.fit_transform(final_X)\n\nfinal_y = test.iloc[:,0].values\nfinal_y = encode.fit_transform(final_y)","ca863a1d":"print(\"Activation function add non linearity to the function. It is required to make the network more\\\n    powerful and helps learn something complex.\")\n\nprint(\"\\nMost popular kinds of activation are :\")\n\nprint(\"\\n1. Sigmoid or Logistic - It is a S shaped curve with the formula : \\\n            \\n\\tf(x) = 1\/1 + exp(-x)\\\n        \\n\\tThe range is between 0 and 1\")\n\nprint(\"\\n2. Tanh\\\n        \\n\\tf(x) = 1 - exp(-2x) \/1 + exp(-2x)\\\n         \\n\\tThe range is between -1 and 1\")\n\nprint(\"\\n3. Relu - Rectified Linear Unit\\\n       \\n\\tR(x) = max(0,x) \\\n       \\n\\tThe values are 0 or x\")","a6176970":"# We are using Relu activation \ndef activation(t):\n     return(np.where(t>=0,t,0))","c5a23c5c":"print(\"Make prediction by calculating-\\\n        \\n\\t1. t = X*W + b\\\n        \\n\\t2. activation(t)\")","e34111fe":"def make_prediction(X,W,b):\n    return activation(np.dot(X,W) + b)","76c4ed1c":"print(\"Weights and bias are estimated for the training dataset using Stochastic Gradient Descent (SGD).\\\n\\nSGD uses two parameters- \\\n\\n1.learning rate:amount with which the weight & bias gets updated each time\\\n\\n2.epoch:number of loops to run though the training data while updating the weight & bias\\\n\\n\\tw = w + (pred - target) * learning rate * training data\\\n\\n\\tb = b + (pred - target) * learning rate\\\n\\nThe weights & bias are initialized to random small numbers or 0's and 1 respectively(as in our case)\")","e8cddeb7":"def train_weights(X,y,lr,epoch):\n    \n    W = np.zeros(X.shape[1])\n    b = np.ones(1)\n    \n    for _ in range(epoch):\n        for xi,target in zip(X,y):    \n            \n            y_pred = make_prediction(xi,W,b)\n        \n            adjustment = lr *(target - y_pred)\n\n            W += (adjustment * xi)\n            b += adjustment\n    return W,b","983227e5":"    print(\"Evaluate the model on test data using the weights and bias estimated in training process.\\\n    \\nCalculate the accuracy of the model\")","1c45f0e4":"def evaluate_model(X,y,W,b):\n    \n    y_true = make_prediction(X,W,b)\n    \n    y_true = np.round(y_true,0)\n    y_true = y_true.astype(int)\n    \n    count = 0\n    for i in range(len(y)):\n        if y_true[i] == y[i]:\n            count+=1\n    \n    return round((count\/len(y) * 100),2)","f08253a3":"W,b = train_weights(X,y,lr=0.01,epoch=1000)\n\nacc = evaluate_model(final_X,final_y,W,b)\n\nprint(\"Accuracy = \" + str(acc) + \"%\")","833d9c30":"![](http:\/\/users.ics.aalto.fi\/ahonkela\/dippa\/img191.gif)"}}