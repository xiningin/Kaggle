{"cell_type":{"0450e459":"code","12193a4f":"code","31031554":"code","888d23f9":"code","df5b99fb":"code","e96ab32b":"code","15dcadc3":"code","f807787c":"code","e5644f95":"code","787640a8":"code","b8ed2099":"code","4d8098e3":"code","b1db4d60":"code","6f445e0d":"code","499b2dd5":"code","5fb4d08d":"code","f5b627ec":"markdown"},"source":{"0450e459":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","12193a4f":"dataset = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\n\nprint(dataset)","31031554":"print(dataset.isnull().sum().sort_values(ascending=False))","888d23f9":"dataset.describe()","df5b99fb":"plt.figure(figsize = (16,10))\nsns_plot=sns.heatmap(dataset.corr(),annot= True)\nplt.show()\n# Saving\nsns_plot.figure.savefig(\"Heat Map.png\")","e96ab32b":"dataset","15dcadc3":"dataset = dataset.drop(['fbs'],axis=1)","f807787c":"dataset","e5644f95":"X = dataset.drop(['target'],1).values\ny = dataset.iloc[:, -1].values\n# splitting into test and train\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2,random_state =5 )\nX_train","787640a8":"# function to perform training with entropy\nclf = DecisionTreeClassifier(criterion = 'gini', random_state = 0, max_depth = 5, min_samples_leaf = 13)\nclf.fit(X_train, y_train)","b8ed2099":"import graphviz\nX = dataset.iloc[:, :-1]\nY = dataset.iloc[:, -1]\ndot_data = tree.export_graphviz(clf, out_file=None, \n                         feature_names = X.columns,  \n                         class_names = [\"yes\",\"no\"],  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph","4d8098e3":"y_pred_en = clf.predict(X_test)\nprint('Accuracy score : ', accuracy_score(y_test, y_pred_en)*100)","b1db4d60":"from sklearn.linear_model import LogisticRegression","6f445e0d":"X = dataset.drop(['target'],1).values\ny = dataset.iloc[:, -1].values\n# splitting into test and train\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,random_state =5 )\nX_train","499b2dd5":"l = LogisticRegression()\nl.fit(X_train, y_train)","5fb4d08d":"pred = l.predict(X_test)\nprint('Accuracy score : ', accuracy_score(y_test, pred)*100)","f5b627ec":"# **Logistic Regression**"}}