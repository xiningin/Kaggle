{"cell_type":{"37048e26":"code","08a791ae":"code","3265fe69":"code","5416dff2":"code","af9e841f":"code","55cdd657":"code","f15c3150":"code","5524b040":"code","a5564a64":"code","1bb3bb5b":"code","053c0dcd":"code","6dea61bb":"code","25dbeaf0":"code","8afe977d":"code","b49be346":"code","9b96c8bf":"code","820c65bb":"code","a9975ddf":"code","a5cad54c":"code","34d97197":"code","3d9b3fa3":"code","c3251295":"code","08a2857c":"code","53f789f4":"code","d4b9d70a":"code","52550db9":"code","156fb403":"code","3f3c6b3b":"code","ca494c40":"code","77a651f5":"code","d6def4a9":"code","b886b755":"code","276eda19":"code","239917f9":"code","06d3ce5f":"code","0c29322f":"code","169c7af8":"code","696b05cb":"code","d7d15c73":"code","5ee01c93":"code","801423d2":"code","325b28be":"code","5e1123ff":"code","88aa31bf":"code","5b3dece5":"code","c9865ac9":"code","f8b61909":"code","032a6b89":"code","ec242599":"code","07fe516b":"code","2f071fab":"markdown","4353d3f3":"markdown","fcc1d16b":"markdown","e2602485":"markdown","feae8e08":"markdown","3c6039d6":"markdown","a803eb0a":"markdown","5a44cb5f":"markdown","1798b3dd":"markdown","9c12fc6b":"markdown","b8d3c27e":"markdown","2a09cdab":"markdown","6dc112ac":"markdown","b7401c1a":"markdown","41f42477":"markdown","456102db":"markdown","3788ccc5":"markdown","eac793e2":"markdown","798ed704":"markdown","b13dbd84":"markdown","e357d147":"markdown","6fd91273":"markdown","d3f6c979":"markdown","c62bd94a":"markdown","7615bab5":"markdown","3f4b941b":"markdown","06321a0a":"markdown","da94d9c6":"markdown","02d69b01":"markdown","0ae50584":"markdown","4b49f496":"markdown","91956482":"markdown","039390ca":"markdown","12f48fa5":"markdown","d44d59c1":"markdown","0b577999":"markdown","91b01244":"markdown","3b27243e":"markdown","14f0e22e":"markdown","3d4d930f":"markdown","1a2173be":"markdown"},"source":{"37048e26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport matplotlib.pyplot as plt\nimport seaborn as sns","08a791ae":"df_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","3265fe69":"abs(df_train.corr()['SalePrice']).nlargest(10)","5416dff2":"plt.scatter(df_train['GrLivArea'], df_train['SalePrice'])\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')","af9e841f":"df_train = df_train[df_train[\"GrLivArea\"] < 4500]","55cdd657":"sns.distplot(df_train['SalePrice'])","f15c3150":"df_train['SalePrice'] = np.log1p(df_train['SalePrice'])","5524b040":"from scipy.stats import norm\nsns.distplot(df_train['SalePrice'], fit=norm)","a5564a64":"n = df_train.shape[0]\nfor col in df_train.columns:\n    missing_pct = sum(df_train[col].isnull())*100.0\/n\n    if missing_pct > 95.0:\n        print('{}: {:0.2f}%'.format(col, missing_pct))","1bb3bb5b":"df_train.drop(['PoolQC', 'MiscFeature'], axis=1, inplace=True)\ndf_test.drop(['PoolQC', 'MiscFeature'], axis=1, inplace=True)","053c0dcd":"df_train[df_train['Electrical'].isna()]","6dea61bb":"df_train = df_train[~df_train['Electrical'].isna()]","25dbeaf0":"cols = [\"MSSubClass\", \"YrSold\", 'MoSold']\ndf_train[cols] = df_train[cols].astype(str)\ndf_test[cols] = df_test[cols].astype(str)","8afe977d":"df_train.corr()['GarageArea']['GarageCars']","b49be346":"df_train.corr()['GarageArea']['SalePrice']","9b96c8bf":"df_train.corr()['GarageCars']['SalePrice']","820c65bb":"cname = 'GarageYrBlt'\ndf_train.corr()[cname][abs(df_train.corr()[cname]) > 0.65]","a9975ddf":"cname = 'GrLivArea'\ndf_train.corr()[cname][abs(df_train.corr()[cname]) > 0.65]","a5cad54c":"cname = 'TotalBsmtSF'\ndf_train.corr()[cname][abs(df_train.corr()[cname]) > 0.65]","34d97197":"col = ['GarageArea','1stFlrSF', '2ndFlrSF','TotRmsAbvGrd', 'GarageYrBlt']\ndf_train.drop(col, axis=1, inplace=True)\ndf_test.drop(col, axis=1, inplace=True)","3d9b3fa3":"def fill_missing_data(df):\n    df_data = df.copy()\n    categoricals = []\n    for cname,dtype in df_data.dtypes.items():\n        if dtype == 'object':\n            categoricals.append(cname)\n    # Fill 'None' for the Categorical attribute\n    df_data[categoricals] = df_data[categoricals].fillna('None')\n    \n    for cname in df_data.columns:\n        if cname not in categoricals:\n            df_data[cname] = df_data[cname].fillna(0) #Fill 0 for the Numeric attribute\n    return df_data","c3251295":"df_train = fill_missing_data(df_train)\ndf_test = fill_missing_data(df_test)","08a2857c":"df_train['TotalPorchSF'] = df_train['OpenPorchSF'] + df_train['EnclosedPorch'] + df_train['3SsnPorch'] + df_train['ScreenPorch']\ndf_test['TotalPorchSF'] = df_test['OpenPorchSF'] + df_test['EnclosedPorch'] + df_test['3SsnPorch'] + df_test['ScreenPorch']","53f789f4":"df_train['TotalBaths'] = df_train['BsmtFullBath'] + df_train['FullBath'] + 0.5*(df_train['BsmtHalfBath'] + df_train['HalfBath'])\ndf_test['TotalBaths'] = df_test['BsmtFullBath'] + df_test['FullBath'] + 0.5*(df_test['BsmtHalfBath'] + df_test['HalfBath'])","d4b9d70a":"df_train['TotalAreaSF'] = df_train['TotalBsmtSF'] + df_train['GrLivArea']\ndf_test['TotalAreaSF'] = df_test['TotalBsmtSF'] + df_test['GrLivArea']","52550db9":"df_train['Age'] = df_train['YrSold'].astype('int64') - df_train['YearBuilt']\ndf_test['Age'] = df_test['YrSold'].astype('int64') - df_test['YearBuilt']","156fb403":"def feature_engineering(df):\n    df_data = df.copy()\n    \n    feature = {\n        'categorical':{\n            'MSSubClass': ['20', '30', '40', '45', '50', '60', '70', '75', '80', '85', '90', '120', '150', '160', '180', '190'],\n            'MSZoning': ['A', 'C', 'FV', 'I', 'RH', 'RL', 'RP', 'RM'],\n            'Alley': ['Grvl', 'Pave', 'None'],\n            'LandContour': ['Lvl', 'Bnk', 'HLS', 'Low'],\n            'LotConfig': ['Inside', 'Corner', 'CulDSac', 'FR2', 'FR3'],\n            'Neighborhood': ['Blmngtn', 'Blueste', 'BrDale', 'BrkSide', 'ClearCr', 'CollgCr', 'Crawfor', 'Edwards', 'Gilbert', 'IDOTRR', 'MeadowV', 'Mitchel',\n                            'Names', 'NoRidge', 'NPkVill', 'NridgHt', 'NWAmes', 'OldTown', 'SWISU', 'Sawyer', 'SawyerW', 'Somerst', 'StoneBr', 'Timber', 'Veenker'],\n            'Condition1': ['Artery', 'Feedr', 'Norm', 'RRNn', 'RRAn', 'PosN', 'PosA', 'RRNe', 'RRAe'],\n            'Condition2': ['Artery', 'Feedr', 'Norm', 'RRNn', 'RRAn', 'PosN', 'PosA', 'RRNe', 'RRAe'],\n            'BldgType': ['1Fam', '2FmCon', 'Duplx', 'TwnhsE', 'TwnhsI'],\n            'HouseStyle': ['1Story', '1.5Fin', '1.5Unf', '2Story', '2.5Fin', '2.5Unf', 'SFoyer', 'SLvl'],\n            'RoofStyle': ['Flat', 'Gable', 'Gambrel', 'Hip', 'Mansard', 'Shed'],\n            'RoofMatl': ['ClyTile', 'CompShg', 'Membran', 'Metal', 'Roll', 'Tar&Grv', 'WdShake', 'WdShngl'],\n            'Exterior1st': ['AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard', 'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco',\n                           'VinylSd', 'Wd Sdng', 'WdShing'],\n            'Exterior2nd': ['AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard', 'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco',\n                           'VinylSd', 'Wd Sdng', 'WdShing'],\n            'MasVnrType': ['BrkCmn', 'BrkFace', 'CBlock', 'None', 'Stone'],\n            'Foundation': ['BrkTil', 'CBlock', 'PConc', 'Slab', 'Stone', 'Wood'],\n            'Heating': ['Floor', 'GasA', 'GasW', 'Grav', 'OthW', 'Wall'],\n            'Electrical': ['SBrkr', 'FuseA', 'FuseF', 'FuseP', 'Mix'],\n            'Functional': ['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Sal'],\n            'GarageType': ['2Types', 'Attchd', 'Basment', 'BuiltIn', 'CarPort', 'Detchd', 'None'],\n            'GarageFinish': ['Fin', 'RFn', 'Unf', 'None'],\n            'PavedDrive': ['Y', 'P', 'N'],\n            'MiscFeature': ['Elev', 'Gar2', 'Othr', 'Shed', 'TenC', 'None'],\n            'MoSold': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'],\n            'YrSold': ['2006', '2007', '2008', '2009', '2010'],\n            'SaleType': ['WD', 'CWD', 'VWD', 'New', 'COD', 'Con', 'ConLw', 'ConLI', 'ConLD', 'Oth'],\n            'SaleCondition': ['Normal', 'Abnorml', 'AdjLand', 'Alloca', 'Family', 'Partial']\n        },\n        'binary': {\n            'Street': ['Pave', 'Grvl'],\n            'CentralAir': ['Y', 'N']          \n        },\n        'ordinal': {\n            'LotShape': ['None', 'IR3', 'IR2', 'IR1', 'Reg'],\n            'Utilities': ['None', 'NoSeWa', 'NoSewr', 'AllPub'],\n            'LandSlope': ['None', 'Sev', 'Mod', 'Gtl'],\n            'ExterQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'ExterCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'BsmtQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'BsmtCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'BsmtExposure': ['None', 'No', 'Mn', 'Av', 'Gd'],\n            'BsmtFinType1': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n            'BsmtFinType2': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n            'HeatingQC': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'KitchenQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'FireplaceQu': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'GarageQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'GarageCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n            'Fence': ['None', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv'],\n            'PoolQC': ['None', 'Fa', 'Ta', 'Gd', 'Ex']\n        },\n    }\n    \n    selected = []\n    for cname in df_data.columns:\n        if cname in feature['binary']: # Convert the binary attributes to 0\/1\n            default_value = feature['binary'][cname][0]\n            feature_name = cname + \"_is_\" + default_value\n            selected.append(feature_name)\n            df_data[feature_name] = df_data[cname].apply(lambda x: int(x == default_value))\n        elif cname in feature['categorical']: # Convert Categorical attributes into One-hot vector\n            values = feature['categorical'][cname]\n            for val in values:\n                try:\n                    new_name = \"{}_{}\".format(cname, val)\n\n                    selected.append(new_name)\n                    df_data[new_name] = df_data[cname].apply(lambda x: int(x == val))\n                except Exception as err:\n                    print(\"One-hot encoding for {}_{}. Error: {}\".format(cname, val, err))\n        elif cname in feature['ordinal']: # Convert the Ordinal attributes to a number\n            new_name = cname + \"_ordinal\"\n            selected.append(new_name)\n            df_data[new_name] = df_data[cname].apply(lambda x: int(feature['ordinal'][cname].index(x)))\n        else: # The remaining attributes are numeric so they remain the same\n#             print(cname)\n            selected.append(cname)\n            \n    return df_data[selected]","3f3c6b3b":"df_train = feature_engineering(df_train)\ndf_test = feature_engineering(df_test)\ndf_train","ca494c40":"for col in df_train.columns:\n    if any(df_train[col]) == False:\n        df_train.drop([col], axis=1, inplace=True)\n        df_test.drop([col], axis=1, inplace=True)","77a651f5":"ids = df_test['Id']\ny = df_train['SalePrice']","d6def4a9":"df_train.drop(['Id', 'SalePrice'], axis=1, inplace=True)\ndf_test.drop(['Id'], axis=1, inplace=True)","b886b755":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df_train)\ntrain = scaler.transform(df_train)\ntest = scaler.transform(df_test)","276eda19":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.25, random_state=1)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)","239917f9":"from sklearn.metrics import mean_squared_error","06d3ce5f":"param_init = {\n    \"max_depth\": 5, # default: 3 only for depthwise\n    \"n_estimators\": 3000, # default: 500\n    \"learning_rate\": 0.01, # default: 0.05\n    \"subsample\": 0.5,\n    \"colsample_bytree\": 0.7,  # default:  1.0\n    \"min_child_weight\": 1.5,\n    \"reg_alpha\": 0.75,\n    \"reg_lambda\": 0.4,\n    \"seed\": 42,\n#     \"eval_metric\": \"rmse\"\n}","0c29322f":"import xgboost\nxgb_model = xgboost.XGBRegressor(**param_init)","169c7af8":"param_fit = {\n    \"eval_metric\": \"rmse\",\n    \"early_stopping_rounds\": 500, # default: 100\n    \"verbose\": 200,\n    \"eval_set\": [(X_val, y_val)]\n}","696b05cb":"xgb_model = xgb_model.fit(X_train, y_train, **param_fit)","d7d15c73":"y_pred_xgb = xgb_model.predict(X_test)","5ee01c93":"mean_squared_error(y_test, y_pred_xgb, squared=False)","801423d2":"from sklearn.tree import DecisionTreeRegressor  \n\nregressorTree = DecisionTreeRegressor(random_state = 0, min_samples_split=2, max_depth=6)  \nregressorTree.fit(X_train, y_train) ","325b28be":"y_pred_Tree = regressorTree.predict(X_test)\nmean_squared_error(y_test, y_pred_Tree, squared=False)","5e1123ff":"from sklearn.ensemble import GradientBoostingRegressor\n\nregressorGB = GradientBoostingRegressor(\n    max_depth=5,\n    n_estimators=10000,\n    learning_rate=0.25\n)\nregressorGB.fit(X_train, y_train)","88aa31bf":"y_pred_GB = regressorGB.predict(X_test)\nmean_squared_error(y_test, y_pred_GB, squared=False)","5b3dece5":"from sklearn.linear_model import Lasso\nregressorLasso = Lasso(alpha=0.0007)\nregressorLasso.fit(X_train, y_train)","c9865ac9":"y_pred_Lasso = regressorLasso.predict(X_test)\nmean_squared_error(y_test, y_pred_Lasso, squared=False)","f8b61909":"SalePrice_pred = xgb_model.predict(test)\n# Because it takes log () to train, it is necessary to take exp () the predicted result\nSalePrice_pred = np.exp(SalePrice_pred)","032a6b89":"submission = {'Id': ids, 'SalePrice': SalePrice_pred}","ec242599":"df_submission = pd.DataFrame(submission)\ndf_submission","07fe516b":"df_submission.to_csv('submission.csv', index=False)","2f071fab":"Since there is only one missing value, we will remove this data point instead of trying to fill the missing value.","4353d3f3":"# Feature Engineering","fcc1d16b":"# Split Train\/Test\/Validation","e2602485":"# Clean data","feae8e08":"The chart above shows that the distribution of `SalePrice` is disproportionate and is` Positive Skew`, so we need to handle it to make a more symmetric distribution. Here we handle by taking logarithm. *(In addition, the metric used in this problem is to get the logarithm of SalePrice of the two predicted values and actually values then calculate the **rmse** between these two values. Therefore, it is quite reasonable to take SalePrice's logarithm to get the father more symmetrically for better results)*","3c6039d6":"Next we will declare the function `fill_missing_data ()`, with the categorical attribute we will fill in the value 'None', with the numeric attribute we will fill in the value 0.","a803eb0a":"Next we need to return the appropriate value type for the attributes `MSSubClass`,` YrSold` and `MoSold` instead of the current numeric type (int64). The reason is because `MSSubClass` is categorical; `YrSold` and` MoSold` are numerical attributes, but we should consider them as categorical attributes which are more appropriate *(for example, with the `MoSold` attribute value 2 (corresponding to February) does not make sense is greater than value 1 (corresponding to January))*. Therefore, we return them to type str (instead of int64).","5a44cb5f":"Next we need to remove highly correlated attributes. As the `GarageArea` property is highly correlated with the` GarageCars` property, we will remove the `GarageArea` attribute and retain the` GarageCars` property since `GarageCars` has a higher correlation with` SalePrice`.","1798b3dd":"We see that `PoolQC` and` MiscFeature` have a large missing data rate, so we will drop these two attributes.","9c12fc6b":"## DecisionTreeRegressor","b8d3c27e":"Next we will declare the function `feature_engineering()` to convert categorical properties into one-hot vector, binary attributes into 0\/1 form and ordinal attributes into ordered numbers (large values carry meaning better than small values): *(Instead of using the get_dummies function)*","2a09cdab":"# Load data","6dc112ac":"From the above results show that `XGBRegressor` gives the best results. Therefore use `XGBRegressor` to predict.","b7401c1a":"We see with `XBGRegressor` the error of test set is` 0.11370`.","41f42477":"Apply for `df_train` and `df_test`:","456102db":"Consider the distribution of `SalePrice`:","3788ccc5":"## Lasso","eac793e2":"Total number of Bathrooms. There are 4 attributes pertaining to the bathroom:\n* BsmtFullBath\n* BsmtHalfBath\n* FullBath\n* HalfBath","798ed704":"Age of house from construction to sold:","b13dbd84":"XGBRegressor initialization parameters (hyperparameters have been selected to achieve good results):","e357d147":"Next, drop the `Id` and` SalePrice` columns before going to the following sections, which need to save the `Id` of the df_test and` SalePrice` of df_train:","6fd91273":"Total area:","d3f6c979":"Consider attributes with large missing data:","c62bd94a":"## GradientBoostingRegressor","7615bab5":"From the chart we can see that these two attributes are linearly related and have two outliers with a value of GrLivArea > 4500.We need to remove these two points::","3f4b941b":"Consider attributes that are highly correlated with `SalePrice`:","06321a0a":"Distribution of `SalePrice` after using logarithm:","da94d9c6":"Summary of attributes related to Porch:\n* OpenPorchSF\n* EnclosedPorch\n* 3SsnPorch\n* ScreenPorch","02d69b01":"# Modeling","0ae50584":"The `Electrical` attribute has only one missing value:","4b49f496":"We can see that the distribution of `SalePrice` is more proportionate (close to the standard distribution), not deviating as before processing.","91956482":"Therefore we will drop the attributes `GarageArea`,` 1stFlrSF`, `2ndFlrSF`,` TotRmsAbvGrd` and `GarageYrBlt`:","039390ca":"In this section we will run some regression model. Then choose the best model.","12f48fa5":"Similarly, we find `1stFlrSF` highly correlated with` TotalBsmtSF`; `2ndFlrSF` and` TotRmsAbvGrd` are highly correlated with `GrLivArea`; `GarageYrBlt` is highly correlated with` YearBuilt`:","d44d59c1":"## XGBRegressor","0b577999":"Use the scatter chart to show the linear relationship between `GrLivArea` and `SalePrice`:","91b01244":"Next we need to drop the columns that only contain the value 0 (these columns will not make much sense):","3b27243e":"# Scaler:","14f0e22e":"Use `XGBRegressor` to predict:","3d4d930f":"# Submission","1a2173be":"Split df_train into 3 parts: train (75%), test (12.5%), validation (12.5%)"}}