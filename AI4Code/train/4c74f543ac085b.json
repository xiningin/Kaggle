{"cell_type":{"4aa3f548":"code","de401247":"code","e0d8f10f":"code","ad1bd39b":"code","cd2ae27a":"code","8cb40bdf":"code","8b2e4611":"code","7ef8749d":"code","8a22765d":"code","06650cd1":"code","86448ddd":"code","7b554d54":"code","a7165af2":"markdown","6df4a6ca":"markdown"},"source":{"4aa3f548":"import numpy as np \nimport pandas as pd \nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom skimage.filters import threshold_otsu\nimport lightgbm as lgb\nimport gc\nfrom tqdm import tqdm\n\nSEED = 0","de401247":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\", index_col='id')\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\", index_col='id')","e0d8f10f":"features = [x for x in train.columns.values if x[0]==\"f\"]","ad1bd39b":"train['n_missing'] = train[features].isna().sum(axis=1)\ntrain['abs_sum'] = train[features].abs().sum(axis=1)\ntrain['sem'] = train[features].sem(axis=1)\ntrain['std'] = train[features].std(axis=1)\ntrain['avg'] = train[features].mean(axis=1)\ntrain['max'] = train[features].max(axis=1)\ntrain['min'] = train[features].min(axis=1)\n\ntest['n_missing'] = test[features].isna().sum(axis=1)\ntest['abs_sum'] = test[features].abs().sum(axis=1)\ntest['sem'] = test[features].sem(axis=1)\ntest['std'] = test[features].std(axis=1)\ntest['avg'] = test[features].mean(axis=1)\ntest['max'] = test[features].max(axis=1)\ntest['min'] = test[features].min(axis=1)\n","cd2ae27a":"# imputer = SimpleImputer(strategy=\"median\")\n# X = imputer.fit_transform(X)\n# X_test = imputer.transform(X_test)","8cb40bdf":"fill_value_dict = {\n    'f1': 'Mean', \n    'f2': 'Median', \n    'f3': 'Median', \n    'f4': 'Median', \n    'f5': 'Mode', \n    'f6': 'Mean', \n    'f7': 'Median', \n    'f8': 'Median', \n    'f9': 'Median', \n    'f10': 'Median', \n    'f11': 'Mean', \n    'f12': 'Median', \n    'f13': 'Mean', \n    'f14': 'Median', \n    'f15': 'Mean', \n    'f16': 'Median', \n    'f17': 'Median', \n    'f18': 'Median', \n    'f19': 'Median', \n    'f20': 'Median', \n    'f21': 'Median', \n    'f22': 'Mean', \n    'f23': 'Mode', \n    'f24': 'Median', \n    'f25': 'Median', \n    'f26': 'Median', \n    'f27': 'Median', \n    'f28': 'Median', \n    'f29': 'Mode', \n    'f30': 'Median', \n    'f31': 'Median', \n    'f32': 'Median', \n    'f33': 'Median', \n    'f34': 'Mean', \n    'f35': 'Median', \n    'f36': 'Mean', \n    'f37': 'Median', \n    'f38': 'Median', \n    'f39': 'Median', \n    'f40': 'Mode', \n    'f41': 'Median', \n    'f42': 'Mode', \n    'f43': 'Mean', \n    'f44': 'Median', \n    'f45': 'Median', \n    'f46': 'Mean', \n    'f47': 'Mode', \n    'f48': 'Mean', \n    'f49': 'Mode', \n    'f50': 'Mode', \n    'f51': 'Median', \n    'f52': 'Median', \n    'f53': 'Median', \n    'f54': 'Mean', \n    'f55': 'Mean', \n    'f56': 'Mode', \n    'f57': 'Mean', \n    'f58': 'Median', \n    'f59': 'Median', \n    'f60': 'Median', \n    'f61': 'Median', \n    'f62': 'Median', \n    'f63': 'Median', \n    'f64': 'Median', \n    'f65': 'Mode', \n    'f66': 'Median', \n    'f67': 'Median', \n    'f68': 'Median', \n    'f69': 'Mean', \n    'f70': 'Mode', \n    'f71': 'Median', \n    'f72': 'Median', \n    'f73': 'Median', \n    'f74': 'Mode', \n    'f75': 'Mode', \n    'f76': 'Mean', \n    'f77': 'Mode', \n    'f78': 'Median', \n    'f79': 'Mean', \n    'f80': 'Median', \n    'f81': 'Mode', \n    'f82': 'Median', \n    'f83': 'Mode', \n    'f84': 'Median', \n    'f85': 'Median', \n    'f86': 'Median', \n    'f87': 'Median', \n    'f88': 'Median', \n    'f89': 'Median', \n    'f90': 'Mean', \n    'f91': 'Mode', \n    'f92': 'Median', \n    'f93': 'Median', \n    'f94': 'Median', \n    'f95': 'Median', \n    'f96': 'Median', \n    'f97': 'Mean', \n    'f98': 'Median', \n    'f99': 'Median', \n    'f100': 'Mode', \n    'f101': 'Median', \n    'f102': 'Median', \n    'f103': 'Median', \n    'f104': 'Median', \n    'f105': 'Median', \n    'f106': 'Median', \n    'f107': 'Median', \n    'f108': 'Median', \n    'f109': 'Mode', \n    'f110': 'Median', \n    'f111': 'Median', \n    'f112': 'Median', \n    'f113': 'Mean', \n    'f114': 'Median', \n    'f115': 'Median', \n    'f116': 'Mode', \n    'f117': 'Median', \n    'f118': 'Mean'\n}\n\n\nfor col in tqdm(features):\n    if fill_value_dict.get(col)=='Mean':\n        fill_value = train[col].mean()\n    elif fill_value_dict.get(col)=='Median':\n        fill_value = train[col].median()\n    elif fill_value_dict.get(col)=='Mode':\n        fill_value = train[col].mode().iloc[0]\n    \n    train[col].fillna(fill_value, inplace=True)\n    test[col].fillna(fill_value, inplace=True)","8b2e4611":"X = train.drop([\"claim\"], axis=1)\nX_test = test\ny = train[\"claim\"]","7ef8749d":"scaler = RobustScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)","8a22765d":"del test, train, scaler\ngc.collect()","06650cd1":"# Model hyperparameters\nlgbm_params = {'objective': 'binary',\n                'boosting_type': 'gbdt',\n                'num_leaves': 148,\n                'max_depth': 4,\n                'learning_rate': 0.01,\n                'n_estimators': 37456,\n                'reg_alpha': 25.2,\n                'reg_lambda': 98.6,\n                'random_state': 0,\n                'bagging_seed': 0, \n                'feature_fraction_seed': 0,\n                'n_jobs': 4,\n                'subsample': 0.7,\n                'subsample_freq': 1,\n                'colsample_bytree': 0.98,\n                'min_child_samples': 99,\n                'min_child_weight': 152,\n                'metric': 'AUC',\n                'verbosity': -1\n              }","86448ddd":"%%time\n\nsplits = 5\nkf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=SEED)\n\npreds = np.zeros(len(X_test))\n\nfor train_idx, valid_idx in kf.split(X, y):    \n    lgb_train = lgb.Dataset(X[train_idx], y[train_idx], free_raw_data=False)\n    lgb_valid = lgb.Dataset(X[valid_idx], y[valid_idx], free_raw_data=False)\n    \n    print('#' * 40)\n\n    lgbm_params['learning_rate'] = 0.05\n    \n    model = lgb.train(lgbm_params,\n                      lgb_train,\n                      verbose_eval=-1,\n                      early_stopping_rounds=1500,\n                      valid_sets=[lgb_valid])\n    \n    lgbm_params['learning_rate'] = 0.01\n    \n    model = lgb.train(lgbm_params,\n                      lgb_train,\n                      init_model=model,\n                      verbose_eval=-1,\n                      early_stopping_rounds=1500,\n                      valid_sets=[lgb_valid])\n    \n    preds += model.predict(X_test) \/ splits\n    \n    gc.collect()","7b554d54":"submission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv', index_col='id')\nsubmission['claim'] = preds\nsubmission.to_csv('submission.csv')","a7165af2":"# Contributions\nPlease try out the following and let me know if it helps at all\n1. Trying new feature engineering combinations: None of the notebooks I've looked at have used abs()+sum(), or sem()\n\n![image.png](attachment:2f8d1cf0-2eb2-46f0-b5cd-0c896fbc9877.png)\n![image.png](attachment:30ec3830-9d45-401c-8686-be109661a809.png)\n\n2. Adjusting learning rate: You can save time as well as fine tune your models","6df4a6ca":"Idea taken from www.kaggle.com\/dlaststark\/tps-sep-single-xgboost-model\nI have modified the choices using the following rationale:\n1. Mean: normal distribution\n2. Median: unimodal and skewed\n3. Mode: all other cases"}}