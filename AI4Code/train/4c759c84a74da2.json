{"cell_type":{"3d6f902d":"code","9df0d625":"code","4fd5ac2f":"code","ba750e4d":"code","2806a327":"code","63df36e5":"code","f279e211":"code","52afb3d5":"code","4e67083e":"code","403072ef":"code","3a2d9220":"code","5fb5f14a":"code","087c91b9":"code","706a3742":"code","eebf1d3c":"code","7a62802e":"code","01ef4747":"code","338812fd":"code","a0e39c3e":"code","ef100aff":"code","81b6aa6d":"code","63c288f9":"code","fa50da2e":"markdown","76115015":"markdown","169fdbd6":"markdown"},"source":{"3d6f902d":"!pip install --upgrade \"tensorflow==1.14\" \"keras>=2.0\"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.datasets import mnist\n\nimport time\nfrom keras.models import Model\nfrom keras.layers import Input, Activation\nfrom keras.layers import Add, AveragePooling2D, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\nsns.set(style='white', context='notebook', palette='deep')","9df0d625":"def loss_acc_plot(model_eval):\n    '''\n    This methods returns the AUC Score when given the Predictions\n    and Labels\n    '''\n    \n    fig, ax = plt.subplots(2,1)\n    ax[0].plot(model_eval.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(model_eval.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(model_eval.history['accuracy'], color='b', label=\"Training accuracy\")\n    ax[1].plot(model_eval.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n\n# Draw a confusion matrix that can be used to observe high false positives\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plotImages(images_arr,labels):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img,label, ax in zip( images_arr,labels, axes):\n        ax.imshow(img)\n        ax.axis('off')\n        ax.set_title(label)\n    plt.tight_layout()\n    plt.show()\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1","4fd5ac2f":"def residual_block(inputs, filters, strides=1):\n    \"\"\"Residual block\n    \n    Shortcut after Conv2D -> ReLU -> BatchNorm -> Conv2D\n    \n    Arguments:\n        inputs (tensor): input\n        filters (int): Conv2D number of filterns\n        strides (int): Conv2D square stride dimensions\n\n    Returns:\n        x (tensor): input Tensor for the next layer\n    \"\"\"\n    y = inputs # Shortcut path\n    \n    # Main path\n    x = Conv2D(\n        filters=filters,\n        kernel_size=3,\n        strides=strides,\n        padding='same',\n    )(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(\n        filters=filters,\n        kernel_size=3,\n        strides=1,\n        padding='same',\n    )(x)\n    x = BatchNormalization()(x)\n    \n    # Fit shortcut path dimenstions\n    if strides > 1:\n        y = Conv2D(\n        filters=filters,\n        kernel_size=3,\n        strides=strides,\n        padding='same',\n        )(y)\n        y = BatchNormalization()(y)\n    \n    # Concatenate paths\n    x = Add()([x, y])\n    x = Activation('relu')(x)\n    \n    return x\n    \n    \ndef resnet(input_shape, num_classes, filters, stages):\n    \"\"\"ResNet \n    \n    At the beginning of each stage downsample feature map size \n    by a convolutional layer with strides=2, and double the number of filters.\n    The kernel size is the same for each residual block.\n    \n    Arguments:\n        input_shape (3D tuple): shape of input Tensor\n        filters (int): Conv2D number of filterns\n        stages (1D list): list of number of resiual block in each stage eg. [2, 5, 5, 2]\n    \n    Returns:\n        model (Model): Keras model\n    \"\"\"\n    # Start model definition\n    inputs = Input(shape=input_shape)\n    x = Conv2D(\n        filters=filters,\n        kernel_size=7,\n        strides=1,\n        padding='same',\n    )(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # Stack residual blocks\n    for stage in stages:\n        x = residual_block(x, filters, strides=2)\n        for i in range(stage-1):\n            x = residual_block(x, filters)\n        filters *= 2\n        \n    # Pool -> Flatten -> Classify\n    x = AveragePooling2D(4)(x)\n    x = Flatten()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(int(filters\/4), activation='relu')(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n    \n    # Instantiate model\n    model = Model(inputs=inputs, outputs=outputs)\n    return model \n\ndef train_model(epochs, filters, stages, batch_size):\n    \"\"\"Helper function for tuning and training the model\n    \n    Arguments:\n        epoch (int): number of epochs\n        filters (int): Conv2D number of filterns\n        stages (1D list): list of number of resiual block in each stage eg. [2, 5, 5, 2]\n        batch_size (int): size of one batch\n        visualize (bool): if True then plot training results \n    \n    Returns:\n        model (Model): Keras model\n    \"\"\"\n    # Create and compile model\n    model = resnet(\n        input_shape=X_train[0].shape,\n        num_classes=Y_train[0].shape[-1],\n        filters=filters, \n        stages=stages\n    )\n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0),\n        metrics=['accuracy']\n    )\n\n    # Define data generator\n    datagen = ImageDataGenerator(  \n        rotation_range=10,  \n        zoom_range=0.1, \n        width_shift_range=0.1, \n        height_shift_range=0.1\n    )\n    datagen.fit(X_train)\n\n    # Fit model\n    history = model.fit_generator(\n        datagen.flow(X_train, Y_train, batch_size=batch_size),\n        validation_data=(X_val, Y_val),\n        epochs=epochs, \n        verbose=1, \n        workers=12\n    )\n\n    return model","ba750e4d":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nprint ('train:',train.shape,'test:',test.shape)\n\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"], axis = 1) \n\n# train with additional public datasets fr the same task\n(x_train_external, y_train_external), (x_test_external, y_test_external) = mnist.load_data()\n\ntrain_external = np.concatenate([x_train_external, x_test_external], axis=0)\ny_train_external = np.concatenate([y_train_external, y_test_external], axis=0)\nY_train_external = y_train_external\nX_train_external = train_external.reshape(-1, 28*28)","2806a327":"# The distibution of classes\ng = sns.countplot(Y_train)","63df36e5":"# Normalize data to make CNN faster\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\nX_train_external = X_train_external \/ 255.0","f279e211":"# Reshape Picture is 3D array (height = 28px, width = 28px , canal = 1)\nX_train = np.concatenate((X_train.values, X_train_external))\nY_train = np.concatenate((Y_train, Y_train_external))\n\nX_train = X_train.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\nY_train = to_categorical(Y_train, num_classes = 10)","52afb3d5":"# Split dataset into training set and validation set\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","4e67083e":"\n# Draw an example of a data set to see\nprint(X_train[:4].shape, X_train[:4][:,:,:,0].shape)\nplotImages(X_train[:5][:,:,:,0],Y_train[:5])","403072ef":"model = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation = \"softmax\"))\n\n# Define Optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Compile model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n#model.summary()\n","3a2d9220":"# print out model look\n#from keras.utils import plot_model\n#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n#from IPython.display import Image\n#Image(\"model.png\")","5fb5f14a":"from tensorflow.keras.callbacks import EarlyStopping\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","087c91b9":"#Adjusting epochs and batch_size\nepochs = 55\nbatch_size = 128","706a3742":"#Data Augmentation \ndatagen = ImageDataGenerator(\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(X_train)\n\n#val_datagen = ImageDataGenerator(\n#        featurewise_center=True)  # randomly flip images\n#val_datagen.fit(X_val)\n#val_datagen.fit(test)","eebf1d3c":"#Prediction model\nlr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, \n                                            verbose=1, \n                                            factor=0.2, \n                                            min_lr=0.00001, cooldown=0)\nhistory = model.fit(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              ,callbacks=[lr_schedule])\n","7a62802e":"# Draw the loss and accuracy curves of the training set and the validation set.\n# Can judge whether it is under-fitting or over-fitting\nloss_acc_plot(history)","01ef4747":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","338812fd":"# Show some wrong results, and the difference between the predicted label and the real labe\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","a0e39c3e":"# Make predictions about test sets\nresults = model.predict(test)\n\n# Convert one-hot vector to number\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","ef100aff":"# Save the final result in cnn_mnist_submission.csv\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"mnist_restnet_submission.csv\",index=False)\n","81b6aa6d":"#simple_model = resnet(\n#    input_shape=X_train[0].shape, \n#    num_classes=Y_train[0].shape[-1], \n#    filters=64, \n#    stages=[2]\n#)\n#simple_architecture = plot_model(simple_model, show_shapes=True, show_layer_names=False)\n#simple_architecture.width = 600\n#simple_architecture","63c288f9":"# Train models\n#models = []\n#for i in range(1):\n#    print('-------------------------')\n#    print('Model: ', i+1)\n#    print('-------------------------')\n#    model = train_model(\n#        epochs=10,\n#        filters=64,\n#        stages=[5, 3, 3],\n#        batch_size=128\n#    )\n#    models.append(model)","fa50da2e":"# RestNet","76115015":"# Some Helper Functions","169fdbd6":"# RestNet Implementation\nbased on the implementation of https:\/\/www.kaggle.com\/jmosinski\/resnets-are-awesome-state-of-the-art\/notebook"}}