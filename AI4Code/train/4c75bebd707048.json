{"cell_type":{"4d180a89":"code","88d2d423":"code","03636993":"code","3c0ea010":"code","79edbccd":"code","77e42101":"code","fece36c7":"code","a69f0a72":"code","558e3ef4":"code","6b8dfc72":"code","4bc26f3b":"markdown","0ea4eca7":"markdown","7df38444":"markdown","a53fde67":"markdown","960a2354":"markdown","8bb3adcb":"markdown","c02dc263":"markdown","ff564d7f":"markdown"},"source":{"4d180a89":"import pandas as pd\nfrom tensorflow import keras as ks\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import LSTM, Input, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D, Flatten, RepeatVector\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, RMSprop, Adagrad\nfrom tensorflow.keras.callbacks import EarlyStopping \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer \nimport matplotlib.pyplot as plt\nfrom keras.models import load_model\nfrom keras.metrics import RootMeanSquaredError\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\n\n# Hack in order to make dictionary entries accessible as attributes (e.g. parameters.parameter)\nclass AttrDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(AttrDict, self).__init__(*args, **kwargs)\n        self.__dict__ = self\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\nrcParams['figure.figsize'] = 18, 8\nks.backend.clear_session()","88d2d423":"# features: \"air_temperature\", \"relative_humidity\", \"rainfall\", \"wind_speed\", \"wind_direction\", \"tide_obs\", \"tide_pred\", \"hour\"\nhyperparams = AttrDict({\n    \"num_of_epochs\": 300,\n    \"learning_rate\": 0.005,\n    \"batch_size\": 30,\n    \"loss_function\": \"mse\",\n    \"earlystopping_patience\": 12,\n    \"look_back\": 18,\n    \"look_back_skip\": 2,\n    \"optimizer\": Adagrad,\n    \"features\": [\"air_temperature\"],\n})","03636993":"# read dataset to pandas DataFrame\ndataset = pd.read_table(\n    #'\/kaggle\/input\/badetemperaturer\/badetemperaturer.csv', \n    #'\/kaggle\/input\/korsvika\/korsvika_water_air_hum.csv',\n    '\/kaggle\/input\/korsvika-multivariate\/interpolated_data-duplicates_removed.csv',\n    delimiter=\",\", \n    decimal=\".\", \n    dtype=np.float64, \n    parse_dates=[\"time\"],\n    index_col=\"time\"\n)\n\n# For inspiration:\n# https:\/\/www.tensorflow.org\/tutorials\/structured_data\/time_series#feature_engineering\n\ndataset[\"timestamp\"] = dataset.index.values.astype(\"int64\") \/ 1e9\ndataset[\"hour\"] = np.sin(2*np.pi * dataset[\"timestamp\"]\/(24*60*60)) # sine-like signal\ndataset[\"year\"] = np.sin(2*np.pi * dataset[\"timestamp\"]\/(365*24*60*60))\n\ndataset[\"month\"] = dataset.index.month.values.astype(\"int64\")\n\n# Engineer wind\ndataset[\"windx\"] = dataset[\"wind_speed\"] * np.cos(2*np.pi * dataset[\"wind_direction\"]\/360)\ndataset[\"windy\"] = dataset[\"wind_speed\"] * np.sin(2*np.pi * dataset[\"wind_direction\"]\/360)\n\n# Remove indoor winter warnings\n#dataset = dataset[:10081]\n\n# Use data from summer season only\ndataset = dataset[dataset.index.month.isin([4,5,6,7,8,9,10,11])]\n\nindex_between_years = 1\nwhile index_between_years < dataset.shape[0] and dataset.index[index_between_years].year == dataset.index[index_between_years-1].year: \n    index_between_years += 1    \nvalidation_data_non_scaled = dataset[:index_between_years]\ntraining_data_non_scaled = dataset[index_between_years:]\n\n# Skip every 2nd row to match weather API and use every 2nd row for validation data\n#training_data = dataset2020.iloc[::2, :]\n#validation_data = dataset2019.iloc[1::2, :]\n\n# Scale values for training\nscaler = MinMaxScaler(feature_range=(0, 1))\ntraining_data = pd.DataFrame(scaler.fit_transform(training_data_non_scaled),columns = dataset.columns)\nvalidation_data = pd.DataFrame(scaler.transform(validation_data_non_scaled),columns = dataset.columns)","3c0ea010":"# Plot all data over (about) three days\ndataset_sample = dataset.iloc[:72]\n\nsns.lineplot(x=dataset_sample.index, y=\"relative_humidity\", data=dataset_sample);\n#sns.lineplot(x=dataset_sample.index, y=\"rainfall\", data=dataset_sample);\nsns.lineplot(x=dataset_sample.index, y=\"wind_speed\", data=dataset_sample);\n#sns.lineplot(x=dataset_sample.index, y=\"wind_direction\", data=dataset_sample);\n#sns.lineplot(x=dataset_sample.index, y=\"tide_obs\", data=dataset_sample);\n#sns.lineplot(x=dataset_sample.index, y=\"tide_pred\", data=dataset_sample);\nsns.lineplot(x=dataset_sample.index, y=\"water_temperature\", data=dataset_sample);\nsns.lineplot(x=dataset_sample.index, y=\"air_temperature\", data=dataset_sample);\nsns.lineplot(x=dataset_sample.index, y=\"hour\", data=dataset_sample);\nsns.lineplot(x=dataset_sample.index, y=\"month\", data=dataset_sample);","79edbccd":"sns.lineplot(x=training_data.index, y=\"water_temperature\", data=training_data);\nsns.lineplot(x=training_data.index, y=\"air_temperature\", data=training_data);","77e42101":"trainx = training_data[hyperparams.features].values\ntrainy = training_data[\"water_temperature\"].values\n\nvalidx = validation_data[hyperparams.features].values\nvalidy = validation_data[\"water_temperature\"].values\n\ntrain_time_plot = training_data.index.values\nvalid_time_plot = validation_data.index.values\n\n# Convert using sliding window, like in https:\/\/datascience.stackexchange.com\/questions\/27533\/keras-lstm-with-1d-time-series\/27535#27535\ndef step_series(x, y, t, window_size, skip=1):\n    x_stepped = np.empty((x.shape[0]-window_size*skip, window_size, x.shape[1]))\n    y_stepped = np.empty(x.shape[0]-window_size*skip)\n    t_stepped = np.empty(x.shape[0]-window_size*skip)\n    for i in range(0, x.shape[0]-window_size*skip):\n        for j in range(0, window_size):\n            x_stepped[i,j,:] = x[i+j*skip]\n        y_stepped[i] = y[i+window_size*skip]\n        t_stepped[i] = t[i+window_size*skip]\n    return x_stepped, y_stepped, t_stepped\n\ntrainx_stepped, trainy_stepped, train_time_plot_stepped = step_series(trainx, trainy, train_time_plot, hyperparams.look_back, hyperparams.look_back_skip)\nvalidx_stepped, validy_stepped, valid_time_plot_stepped = step_series(validx, validy, valid_time_plot, hyperparams.look_back, hyperparams.look_back_skip)","fece36c7":"model = Sequential()\nmodel.add(Conv1D(\n    128, \n    kernel_size=3,\n    strides=1, padding=\"causal\",\n    activation=\"swish\",\n    input_shape=(trainx_stepped.shape[1], trainx_stepped.shape[2])))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Bidirectional(LSTM(64, activation=\"swish\", return_sequences=True)))\nmodel.add(Bidirectional(LSTM(64, activation=\"swish\")))\nmodel.add(Dense(1))\nmodel.compile(\n    loss=hyperparams.loss_function,\n    optimizer=(hyperparams.optimizer(learning_rate=hyperparams.learning_rate) if hyperparams.learning_rate is not None else hyperparams.optimizer()),\n    metrics=[RootMeanSquaredError()]\n)\nmodel.summary()\n\nearlystopping = EarlyStopping(monitor =\"val_loss\", mode =\"min\", patience=hyperparams.earlystopping_patience, restore_best_weights = True) \n\nhistory = model.fit(\n    trainx_stepped, \n    trainy_stepped, \n    epochs=hyperparams.num_of_epochs, \n    batch_size=hyperparams.batch_size, \n    callbacks=[earlystopping], \n    validation_data=(validx_stepped, validy_stepped), \n    shuffle=False\n)","a69f0a72":"plt.plot(history.history[\"loss\"], label=\"training loss\")\nplt.plot(history.history[\"val_loss\"], label=\"validation loss\")\nplt.legend()\nplt.show()","558e3ef4":"predy_stepped = model.predict(validx_stepped[::2, :, :])\n\npredict_matrix = np.zeros(shape=(len(predy_stepped), 14))\npredict_matrix[:,0] = predy_stepped[:,0]\npredy_stepped = scaler.inverse_transform(predict_matrix)\n\nvalid_matrix = np.zeros(shape=(len(validy_stepped), 14))\nvalid_matrix[:,0] = validy_stepped\nvalidy_stepped2 = scaler.inverse_transform(valid_matrix)\n     \nplt.plot(validation_data_non_scaled.index[36:], validy_stepped2[:, 0], label=\"Reelle m\u00e5linger\", color=\"lightskyblue\")\nplt.plot(validation_data_non_scaled.index[36::2], predy_stepped[:, 0], label=\"Predikerte verdier\", color=\"red\")\nplt.legend()\nplt.show()\n","6b8dfc72":"model.save(\"output\/model\")","4bc26f3b":"# Plot training and validation loss","0ea4eca7":"# Hyperparameter tuning","7df38444":"# Plotting\nPlotting raw data over a period, in addition to plotting air temperatures over water temperatures","a53fde67":"## Dataset and preprocessing","960a2354":"# Split data and convert to time series","8bb3adcb":"## Setup","c02dc263":"# Build and train model","ff564d7f":"# Visualize and compare predictions"}}