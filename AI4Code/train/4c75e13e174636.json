{"cell_type":{"afaf4b34":"code","56db3dc8":"code","bc0626df":"code","0de757e6":"code","ffa5c828":"code","913c1d0c":"code","98b38c3d":"code","329ba574":"code","5aa27b52":"code","4c6becad":"code","b078cf11":"markdown","8a049729":"markdown","e41394b1":"markdown","c11311cb":"markdown","06fe41f7":"markdown","f7b0f39b":"markdown","b91a31c3":"markdown","01e64ffd":"markdown","d54b41d3":"markdown","47796c1c":"markdown","77acf67c":"markdown","a180efd3":"markdown","aa3805ce":"markdown","37ef28b8":"markdown","61909d88":"markdown","68d7f21b":"markdown","e6aa3ee4":"markdown","aeb081e2":"markdown","f711f517":"markdown","3972c5aa":"markdown","8f17d5e2":"markdown","47edfe4d":"markdown","a0ba2628":"markdown","3634cf90":"markdown","4fa1c531":"markdown","f3734d01":"markdown","404d2857":"markdown","f39c0f66":"markdown","e5bf83d6":"markdown","c1aaac6f":"markdown","05c069c8":"markdown","2409b978":"markdown","a30bc928":"markdown","3bfae3df":"markdown","491cee13":"markdown","8d8d65cf":"markdown","d6c32e68":"markdown"},"source":{"afaf4b34":"# Import modules\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt # basic data visualization tools\nimport seaborn as sns # streamlined and extended data visualization, built on matplotlib\nimport sqlite3 # python integration for SQL commands using sqlite\nimport re # support for regular expressions\nfrom IPython.display import Image # support for displaying images in Jupyter Notebooks\n\nfrom matplotlib import cm\nimport warnings\n\n%matplotlib inline\n\n# Set display preferences for max number of rows and columns to display\npd.options.display.max_columns = 100","56db3dc8":"Image(filename = 'path\/filename') # input the path to your graphical abstract or other image files","bc0626df":"print(plt.style.available) # Check available style sheets for figures","0de757e6":"plt.style.use('seaborn-darkgrid') # use one of the available style sheets for the figures that follow","ffa5c828":"# Read data into a dataframe\noriginal_data_??? = pd.read_csv('\/path\/')","913c1d0c":"# First few rows of original data\noriginal_data_???.head(5)","98b38c3d":"# Original data's column names, number of null values, and data types\noriginal_data_???.info()","329ba574":"# Basic descriptive statistics of all columns in original data\noriginal_data_???.describe(include = 'all')","5aa27b52":"# Assess categorical groups within data of interest\nprint(original_data_???['categorical_column'].value_counts(), '\\n')\nprint('Number of null values in categorical_column: ',original_data_???['categorical_column'].isnull().sum())","4c6becad":"# Preparing required_data_field for merge\n\n# Initial format of required_data_field in original_data_???: value in units stored as data_type in 'column_initial'\n\n# Final format: value in units stored as data_type in 'column_final'","b078cf11":"## 3.2.6 Training Data","8a049729":"## 3.2.5 Features","e41394b1":"# Highlights\n- Think of them as the \"elevator pitch\" of your project. They consist of 3-5 short bullet points that capture novel results and any new methods that were used. \n- Help increase the discoverability of your project via search engines by including terms that your readers will be looking for online.\n- Don't try to capture all ideas, concepts or conclusions as highlights are meant to be short: 85 characters or fewer, including spaces.","c11311cb":"# 3.3 Learn\/Optimize\n---","06fe41f7":"### 3.1.3.4 Deal with missing values\n1. Find missing values (may be marked as np.NaN, \"None\", \"--\", etc.)  \n    DataFrame.isnull().sum()  \n    sns.heatmap(df.insull(), cbar = False)  \n    Look for patterns in missing data  \n2. Check for errors in data cleaning\/transformation\n3. Use data from additional sources to fill missing values\n4. Drop rows and\/or columns  \n    DataFrame.dropna(thresh = min_nonnull, axis=1)  \n    DataFrame.drop(columns_to_drop, axis=1)  \n5. Fill missing values with estimates based on the available data  \n\nResources: [Working with missing data in Pandas](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/missing_data.html)","f7b0f39b":"# 3.1 Explore\/Transform\n---\nQuestions of interest:\n- ???\n\nData required to answer questions of interest:\n- ???\n\nTo answer these questions, we will use data from ???","b91a31c3":"## 3.1.1 Data source\nDescribe any aspects of the following that could impact the quality of the input data, and how it may impact the quality of the data:\n- Data collection\n    - Instrumentation\n    - Logging\n    - Sensors\n    - External data\n    - User generated content\n- Movement\/Storage of data\n    - Reliable data flow\n    - Infrastructure\n    - Pipelines\n    - Extract, Transform, Load(ETL)\n    - Structured and unstructured data storage","01e64ffd":"# 3.2 Aggregate\/Label\n---","d54b41d3":"## 3.1.3 Cleaning the Data \n3.1.3.1 Transform columns and indexes into standard format in preparation for combination, adding columns when necessary  \n3.1.3.2 Combine all requisite data into a common analytical framework  \n3.1.3.3 Deal with duplicates  \n3.1.3.4 Deal with missing values  ","47796c1c":"Descriptions of data fields\n\n|Column|Description|\n|---|---|","77acf67c":"# Abstract\/Executive Summary\nOne concisely written paragraph that describes:\n- The purpose of the project.  \n- A very general description of methods.  \n- The most important result(s).  \n- Major conclusions.  ","a180efd3":"# References\n---","aa3805ce":"# 2. Results, Discussion, and Conclusions\n---\n**2.1 Summary: In 1-2 sentences, restate the initial goal, the main approach you took to reach that goal, and summarize the most important results\/conclusions.** This section may be broken down and re-used as the bullet points in your Highlights section.\n\n**2.2 RESULT: State the result concisely at the highest level of resolution.**  \n<u>Relevance:<\/u> State why this result matters. Avoid extensive citations and discussion of published literature.  \n<u>Key evidence:<\/u> Give the salient data supporting the conclusion.  \n<u>Interpretation Pitfalls:<\/u> Address any potentially misleading aspects of the data or its analysis. What are some limitations of the study? What alternative conclusions could be drawn from the data? What evidence speaks for or against each conclusion?  \n<u>Conclusion:<\/u> State any recommendations based on the result, especially with regard to the initial goal of the project.  \n<u>Next steps:<\/u> (optional) What additional data, analysis, or action would be necessary to attain the goal of the analysis? What new opportunities do these results suggest?  \n\n...\n\n**2.n RESULT section repeated as necessary to report all results. \n\n(Go back to introduction and ensure that it addresses the relevance of all of the important results.)","37ef28b8":"### 3.1.3.2 Combine all requisite data into a common analytical framework","61909d88":"## 3.2.1 Analytics","68d7f21b":"## 3.2.4 Aggregates","e6aa3ee4":"# Graphical Abstract\nOptional section. Draws more attention to your project.  \nSummarize the contents of the project in a concise, pictorial form designed to capture the attention of a wide readership.  \nThe rest of your figures and tables can be embedded in the relevant section of the project. Customize graphs with: https:\/\/www.dataquest.io\/blog\/making-538-plots\/. Give each figure a title and a brief description that includes explanation of all symbols and abbreviations used in the figure.","aeb081e2":"## 3.1.5 Data Preparation","f711f517":"### 3.1.3.3 Deal with duplicates\n1. Identify duplicates  \n    DataFrame.duplicated([col_1, col_2])  \n2. Remove duplicates  \n    DataFrame.drop_duplicates([col_1, col_2])","3972c5aa":"# Title\nConcise and informative. Titles are often used in information-retrieval systems. Avoid abbreviations and formulae where possible.  \nTry a task:purpose format (e.g. Task: \"Application of machine learning to electronic health record data\" Purpose: \"to predict novel uses of existing drugs.\" The purpose portion should tap into the reader's emotional motivations - this project will help them do a job they're interested in doing. ","8f17d5e2":"## 3.3.4 Deep Learning","47edfe4d":"## 3.3.2 Simple Machine Learning Algorithms","a0ba2628":"## 3.3.1 A\/B testing","3634cf90":"## 3.2.2 Metrics","4fa1c531":"This template was based on the following resources. Many parts of this template were copied directly from these sources, but quotation marks and in-text references have been omitted for the sake of readability and flow. \n- The submission guidelines for the peer-reviewed journal Intelligence-Based Medicine https:\/\/www.elsevier.com\/journals\/intelligence-based-medicine\/2666-5212\/guide-for-authors#txt25000\n- A style guide for data science proposed by Dataquest at https:\/\/www.dataquest.io\/blog\/data-science-project-style-guide\/. Accessed 7\/1\/2020\n- \"The AI Hierchy of Needs\" described by Monica Rogati on June 12th 2017, accessed at https:\/\/hackernoon.com\/the-ai-hierarchy-of-needs-18f111fcc007\n- The article \"How scientists fool themselves - and how they can stop\" by Regina Nuzzo https:\/\/www.nature.com\/news\/how-scientists-fool-themselves-and-how-they-can-stop-1.18517 Accessed 7\/9\/2020.\n- Feedback from Kaggle members listed in the Acknowledgements section","f3734d01":"## Acknowledgements\nThe template used to produce this project was created by Tim McLerran with input from members of the Kaggle community including . The [original template](https:\/\/www.kaggle.com\/precisionmed\/template-for-data-science-projects) is free for reuse and modification with the request that this acknowledgement be retained in the final product.","404d2857":"### 3.1.3.1 Transform columns and indexes into standard format in preparation for combination, adding columns when necessary\nResources:  \n[Vectorized string methods in Pandas](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/text.html)  \n[Regular expression (regex) operations](https:\/\/docs.python.org\/3.4\/library\/re.html)  ","f39c0f66":"## 3.1.4 Anomaly Detection","e5bf83d6":"# 3. Methods (AKA Code)\n---\nFollow the Python style guide: https:\/\/www.python.org\/dev\/peps\/pep-0008\/\n\nGeneral guidelines\n- Provide sufficient details to allow the work to be reproduced by an independent researcher\n- Methods that are already published should be summarized, indicated by a reference, and any modifications to the method as applied in this project should be clearly noted.\n- Alternate between code and markdown cells to lead the reader along\n- Break code into functional units separated by white space. Place a block comment above each unit describing what that functional unit does, even if it seems redundant.\n- Add in-line comments to describe what the code does in a level of abstraction above what the actual code is doing.\n- Name variables clearly, even if it takes extra typing\n- Import modules in the code cells where they are needed rather than importing them all at the beginning","c1aaac6f":"# Recommended Workflow\n\n- Section 3\n    - identify questions of interest and data necessary to answer these questions\n- Section 3.1.2\n    - specify path to original data file\n    - identify the way null values are stored in input data, and use na_values ='???' argument in pd.read_csv() function to convert all null values to NaN","05c069c8":"## 3.2.3 Segments","2409b978":"## 3.1.2 Data structure\nDescribe and demonstrate relevant aspects of the:\n- File format of input data\n- Dimensionality of the data\n- Descriptions of data fields (how many fields there are, what each field means)","a30bc928":"Resources for figures:  \n[Axes class documentation](https:\/\/matplotlib.org\/api\/axes_api.html#matplotlib.axes.Axes.scatter)  \n[matplotlib Pyplot function overview](https:\/\/matplotlib.org\/api\/pyplot_summary.html)  \n[Seaborn introduction](https:\/\/seaborn.pydata.org\/introduction.html)  ","3bfae3df":"# 1. Introduction\n---\nState the objectives of the work and provide an adequate background, avoiding a detailed literature survey or a summary of the results. ","491cee13":"Dear user,\n\nThis template is designed to help data scientists create projects with predictable flow and high quality. It is largely modeled after the publication guidelines for an academic journal, so following this format will reduce the work necessary to publish based on your project. Please share your feedback in the comments together with the name by which I should acknowledge you. I will include you in the acknowledgement statement if your comment leads to a revised version.\n\nCheers,  \nTim","8d8d65cf":"3.2.4 Resources  \n[pandas.DataFrame.groupby documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.groupby.html)  \n[pandas.pivot_table documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.pivot_table.html)  ","d6c32e68":"## 3.3.3 Artificial Intelligence"}}