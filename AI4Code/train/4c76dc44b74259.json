{"cell_type":{"fb509151":"code","4456f196":"code","d40454fc":"code","9c6cec4a":"code","22792c19":"code","e5e9324c":"code","c7519d8f":"code","060f3daf":"code","62c654f3":"code","80f4eaa5":"code","12446226":"code","20cd43e8":"code","1dfb443e":"code","515aa847":"code","cb50f374":"code","ec28b049":"code","0367a638":"markdown"},"source":{"fb509151":"#Below are all of the packages I imported for this notebook\n#My main goal was to classify the main research goals for Task 4 - Vaccines and Therapeutics using NLTK natural language processing\n#I focused my analysis on the Title and Abstract only, as I wanted to capture what the researcher was doing specifically without the noise of other citations etc in the body of a paper\n\nimport pandas as pd \nimport numpy as np\nfrom collections import Counter\nimport nltk\nimport string\nfrom collections import Counter\nfrom nltk.probability import FreqDist\nfrom io import StringIO\nimport datetime\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","4456f196":"covid = pd.read_csv('..\/input\/CORD-19-research-challenge\/metadata.csv', sep=',')\nprint(type(covid))\ncovid.head(2)","d40454fc":"#here I wanted to obtain specifically the First Author-main researcher and the Last Author- Professor so the user can see which labs are most active for a given topic \ncovid['first_author'] = covid['authors'].str.split(';').str[0]\ncovid['last_author'] = covid['authors'].str.split(';').str[-1]","9c6cec4a":"#the goal here was to create a new column called Text Analysis which would be used to train the language processor and perform searches\ncovid['text_analysis'] = covid['title'] + covid['abstract'] + covid['first_author'] + covid['last_author']\ncovid['text_analysis'] = covid['text_analysis'].str.lower()","22792c19":"#the purpose of below was to simplify the date format and also to tokenize the Text Analysis comment before applying stopwords\ncovid['date_format'] =  pd.to_datetime(covid['publish_time'])\ncovid['month_year'] = covid['date_format'].dt.to_period('M')\ncovid['text_analysis'] = covid['text_analysis'] .astype(str)\ncovid['text_tokenize'] = covid['text_analysis'].apply(nltk.word_tokenize)","e5e9324c":"string.punctuation\nuseless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\ncovid['clean_tokenize'] = covid['text_tokenize'].apply(lambda x: [item for item in x if item not in useless_words])\ncovid['clean_tokenize'] = covid['clean_tokenize'] .astype(str)","c7519d8f":"print('total papers', covid['title'].nunique())\nprint('unique first authors', covid['first_author'].nunique())\nprint('unique last authors', covid['last_author'].nunique())\nprint('unique PMCID', covid['pmcid'].nunique())","060f3daf":"covid['question1'] = covid['text_analysis'].str.contains('corona')&covid['text_analysis'].str.contains('inhibit')&covid['text_analysis'].str.contains('replication')\ncovid['question2'] = covid['text_analysis'].str.contains('antibody')&covid['text_analysis'].str.contains('vaccine')& covid['text_analysis'].str.contains('corona')\ncovid['question3'] = covid['text_analysis'].str.contains('trial')&covid['text_analysis'].str.contains('predict')\ncovid['question4'] = covid['text_analysis'].str.contains('therapeutics')&covid['text_analysis'].str.contains('antiviral')&covid['text_analysis'].str.contains('covid-19')\ncovid['unrelated'] = ~covid['text_analysis'].str.contains('covid-19') & ~covid['text_analysis'].str.contains('inhibit')& ~covid['text_analysis'].str.contains('replication') & ~covid['text_analysis'].str.contains('antibody') & ~covid['text_analysis'].str.contains('vaccine') & ~covid['text_analysis'].str.contains('corona')&~covid['text_analysis'].str.contains('therapeutics')&~covid['text_analysis'].str.contains('antiviral')&~covid['text_analysis'].str.contains('animal') & ~covid['text_analysis'].str.contains('predictive')&~covid['text_analysis'].str.contains('virus')& ~covid['text_analysis'].str.contains('sars')& ~covid['text_analysis'].str.contains('airborne')& ~covid['text_analysis'].str.contains('respitory')& ~covid['text_analysis'].str.contains('mers')& covid['publish_time'].str.contains('2018')& ~covid['text_analysis'].str.contains('nan')","62c654f3":"#Below changes resopnse from True\/False\ncovid['question1'] = np.where(covid['question1'], 'Question1', 'N')\ncovid['question2'] = np.where(covid['question2'], 'Question2', 'N')\ncovid['question3'] = np.where(covid['question3'], 'Question3', 'N')\ncovid['question4'] = np.where(covid['question4'], 'Question4', 'N')\ncovid['unrelated'] = np.where(covid['unrelated'], 'Unrelated', 'N')","80f4eaa5":"#The goal here is to factorize the questions into different categories for the NLTK\ncovid['not_question'] = covid['question1'].str.contains('N')& covid['question2'].str.contains('N') & covid['question3'].str.contains('N') & covid['question4'].str.contains('N') & covid['unrelated'].str.contains('N')\ncovid['category_id'] = covid[['question1','question2','question3','question4','unrelated']].max(axis=1)\ncovid['category_id_num'] = covid['category_id'].factorize()[0]","12446226":"#The final step is to create my training datafram\ntrain_df=covid[~covid['category_id'].str.contains('N')]\ncategory_id_df = train_df[['category_id', 'category_id_num']].drop_duplicates().sort_values('category_id_num')\ncategory_to_id = dict(category_id_df.values)\ntrain_df.head(2)","20cd43e8":"#Below is using a Scikit Learn to calculate a vector for each of the narratives\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\ntrain_df_features = tfidf.fit_transform(train_df['clean_tokenize']).toarray()\nlabels = train_df['category_id_num']\ntrain_df_features.shape","1dfb443e":"#Below obtains the most correlated unigrams and bigrams\nN = 2\nfor Product, category_id_num in sorted(category_to_id.items()):\n  features_chi2 = chi2(train_df_features, labels == category_id_num)\n  indices = np.argsort(features_chi2[0])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n ","515aa847":"#The final step is to train the Naive Bayes Classifier\nX_train, X_test, y_train, y_test = train_test_split(train_df['title'], train_df['category_id'], random_state = 0)\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nclf = MultinomialNB().fit(X_train_tfidf, y_train)","cb50f374":"#Paste title in the square brackets\nprint(clf.predict(count_vect.transform(['Long-Term Persistence of Robust Antibody and Cytotoxic T Cell Responses in Recovered Patients Infected with SARS Coronavirus'])))","ec28b049":"print(clf.predict(count_vect.transform(['Practical fluid therapy and treatment modalities for field conditions for horses and foals with gastrointestinal problems'])))","0367a638":"**Defining the questions**\n\nBecause the natural language processor is trained using a text sample, it is important to ensure what is being fed during training is as targeted as possible. Currently there aren't too many papers specifically targeted at COVID-19, however I expect this number exponentially grow with time, and the goal is to prevent the processor from capturing too many articles as being within scope. Below are the text filteres I used to filter journals for training.\n\nTask 4- \n**Question 1- Effectiveness of drugs being developed and tried to treat COVID-19 patients.\n**Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication.\n\n'corona','inhibit','replication'\n\n**Question 2- Methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients\n\n'antibody','vaccine','corona'\n\n**Question 3- Exploration of use of best animal models and their predictive value for a human vaccine\n\n'trial','predict'\n\n**Question 4- Capabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents.\n\n'therapeutics','antiviral','covid-19'\n\n**Unrelated- Papers which didn't include any of the above text filter, or anything related to COVID-19\n\n**Doesn't contain** \n'covid19','inhibit','replication','antibody','vaccine','corona','therapeutics','antiviral','animal','predictive','virus','sars','airborne','respitory','mers','nan', and papers for 2018 (to reduce the number)"}}