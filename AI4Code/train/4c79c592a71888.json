{"cell_type":{"95ff635d":"code","60055cbb":"code","ca9d56fc":"code","76e00774":"code","a324890d":"code","b45b66a9":"code","5dc8e3a8":"code","079c6c99":"code","a1072394":"code","d64c0655":"code","7018986f":"code","25f75376":"code","0663bc3c":"code","0055ed1e":"code","2b7cfa57":"code","1e55bcea":"code","fcbd0664":"markdown","56d430e9":"markdown","80dcf119":"markdown","825ba080":"markdown","009fb0a0":"markdown","7933d13d":"markdown","c730950e":"markdown"},"source":{"95ff635d":"import gc\n\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\nimport cudf\nfrom cuml.preprocessing import train_test_split, StandardScaler\nfrom cuml.svm import SVC\nfrom cuml.ensemble import RandomForestClassifier\n\nimport optuna","60055cbb":"BASE_DATA_DIR = \"..\/input\/tabular-playground-series-feb-2022\/\"\n!ls {BASE_DATA_DIR}","ca9d56fc":"df_train = cudf.read_csv(BASE_DATA_DIR + \"train.csv\")\ndf_test = cudf.read_csv(BASE_DATA_DIR + \"test.csv\")\ndf_sub = cudf.read_csv(BASE_DATA_DIR + \"sample_submission.csv\")","76e00774":"print(\"Train shape: \", df_train.shape)\nprint(\"Test shape: \", df_test.shape)","a324890d":"df_train.info()","b45b66a9":"idx_2_label = sorted(df_train[\"target\"].unique().values_host)\nlabel_2_idx = {label: idx for idx, label in enumerate(idx_2_label)}","5dc8e3a8":"df_train[\"target\"].value_counts().to_pandas().plot(kind=\"bar\", cmap=\"winter\")","079c6c99":"df_train[\"target\"] = df_train[\"target\"].map(label_2_idx)","a1072394":"def objective(trial):\n    classifier = trial.suggest_categorical('classifier', [\"RandomForestClassifier\"]) # \"SVC\", \"XGBoostClassifier\"\n    if classifier == \"SVC\":\n        svc_c = trial.suggest_float(\"C\", 1e-2, 1e2, log=True)\n        svc_gamma = trial.suggest_float(\"gamma\", 1e-2, 1e-2, log=True)\n        svc_kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\"])\n        clf = SVC(C=svc_c, kernel=svc_kernel, gamma=svc_gamma)\n    elif classifier == \"RandomForestClassifier\":\n        n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, log=True)\n        max_depth = trial.suggest_int(\"max_depth\", 10, 100, log=True)\n        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    elif classifier == \"XGBoostClassifier\":\n        pass\n    \n    X_train, X_val = train_test_split(df_train, test_size=0.2, random_state=42)\n    y_train = X_train[\"target\"].values\n    X_train = X_train.drop([\"row_id\", \"target\"], axis=1)\n\n    y_test = X_val[\"target\"].to_array()\n    X_val = X_val.drop([\"row_id\", \"target\"], axis=1)\n    clf.fit(X_train, y_train)\n    preds = clf.predict(X_val).to_array()\n    score = accuracy_score(y_test, preds)\n    gc.collect()\n    return score","d64c0655":"study = optuna.create_study(study_name=\"tps-feb-2022\", direction=\"maximize\")\nstudy.optimize(objective, n_trials=10)","7018986f":"trial = study.best_trial","25f75376":"print(\"  Best accuracy: \", study.best_value)\nprint(\"  Value: {}\".format(trial.value))\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n","0663bc3c":"del trial.params[\"classifier\"]","0055ed1e":"clf = RandomForestClassifier(**trial.params)\nX_train, X_val = train_test_split(df_train, test_size=0.2, random_state=42)\ny_train = X_train[\"target\"].values\nX_train = X_train.drop([\"row_id\", \"target\"], axis=1)\n\ny_test = X_val[\"target\"].to_array()\nX_val = X_val.drop([\"row_id\", \"target\"], axis=1)\nclf.fit(X_train, y_train)\npreds = clf.predict(X_val).to_array()","2b7cfa57":"df_test = df_test.drop([\"row_id\"], axis=1)\ny_sub = clf.predict(df_test)\npred_list = [idx_2_label[pred_idx] for pred_idx in y_sub.to_array()]","1e55bcea":"df_sub[\"target\"] = pred_list\ndf_sub.to_csv(\"submission.csv\", index=False)","fcbd0664":"# Submission File","56d430e9":"# Defining the objective function\n\nIn this example, we only consider the RandomForestClassifier as our predictive model. But feel free to use any other classifier algorithm from the cuML [documentation](https:\/\/docs.rapids.ai\/api\/cuml\/stable\/api.html#regression-and-classification).","80dcf119":"# Running the study","825ba080":"In this notebook, we will learn about:\n    \n- How can we optimize the hyperparameters of a predictive model,\n- How can we define an objective function that optuna can use,\n- GPU powered cuML classifiers\n\n**If you find this tutorial helpful for your studies, an upvote would be too much appreciated.**","009fb0a0":"### Retraining the classifier with the best params obtained in the previous step","7933d13d":"# Imports","c730950e":"# Prediction on test data"}}