{"cell_type":{"df6ce60e":"code","fc948069":"code","24200e54":"code","95192895":"code","4d14765f":"code","1310fc8e":"code","aff6ef8e":"code","b6bf27b1":"code","b110ed4f":"code","60fd3bf6":"code","5b7eba9e":"code","996bb7ef":"code","81678e27":"code","869f4670":"code","4eaae6fe":"code","53e2727b":"code","998af937":"code","995843e3":"code","21bb7281":"markdown","9dab1c5d":"markdown","9f5d7536":"markdown","00acbf36":"markdown","4ba0e49d":"markdown","f527b579":"markdown","86c3baea":"markdown"},"source":{"df6ce60e":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nimport torch.utils.data\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Subset\nfrom torch.utils.data import DataLoader\n\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES=True\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","fc948069":"train_data_path = \"..\/input\/cat-and-dog\/training_set\/training_set\"\ntest_data_path=\"..\/input\/cat-and-dog\/test_set\/test_set\"","24200e54":"#this is preprocessing step of images\nimg_transforms = transforms.Compose([\n#Because we have bunch of images of non similar aspect ratio\n#Scaling is necessary to improve processing performance\ntransforms.Resize(size=256),\ntransforms.CenterCrop(size=224),\ntransforms.ToTensor(),\n#normalization is necessary to prevent exploding gradient problem    \ntransforms.Normalize(mean=[0.4895, 0.4517, 0.4130],\nstd=[0.2587, 0.2506, 0.2514])\n#to get the normalizing tensor values comment above two lines and run the get_mean_std(loader) function\n])","95192895":"DATASET = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms)\nprint(len(DATASET))\nDATASET[0][0].shape","4d14765f":"def get_mean_std(loader):\n    # var[X] = E[X**2] - E[X]**2\n    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n\n    for data, _ in tqdm(DATASET):\n        channels_sum += torch.mean(data, dim=[1, 2])\n        channels_sqrd_sum += torch.mean(data ** 2, dim=[1,2])\n        num_batches += 1\n\n    mean = channels_sum \/ num_batches\n    std = (channels_sqrd_sum \/ num_batches - mean ** 2) ** 0.5\n\n    return mean, std\n\n\n#mean, std = get_mean_std(DATASET)\n#print(mean)\n#print(std)\n#------------------------------------------------------\n#Uncomment above three line to get normalization tensor values for this particular dataset","1310fc8e":"#dividing train data into train and validation data\ndef train_val_dataset(dataset, val_split=0.25):\n    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split,random_state=42)\n    datasets = {}\n    datasets['train'] = Subset(dataset, train_idx)\n    datasets['val'] = Subset(dataset, val_idx)\n    return datasets\n\ndatasets = train_val_dataset(DATASET)\nprint(len(datasets['train']))\nprint(len(datasets['val']))","aff6ef8e":"#test data must have same preprocessing step as train data\ntest_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_transforms)\n#loading data to feed into neural network\nbatch_size=64\ntrain_data_loader = DataLoader(datasets['train'], batch_size=batch_size)\nval_data_loader = DataLoader(datasets['val'], batch_size=batch_size)\ntest_data_loader = DataLoader(test_data, batch_size=batch_size)","b6bf27b1":"#Let's have a look on the tensor size for each batches \nfor image_batch, label_batch in train_data_loader:\n    print(image_batch.size(),label_batch.size())\n    break","b110ed4f":"#to normalize images\ndef image_convert(img):\n    img = img.clone().cpu().numpy()\n    img = img.transpose(1,2,0)\n    std = [0.5,0.5,0.5]\n    mean = [0.5,0.5,0.5]\n    img = img*std + mean\n    return img\n\ndef plot_10():\n        iter_ = iter(train_data_loader)\n        images,labels = next(iter_)\n        an_ = {'0':'cat','1':'dog'}# changing labels to be meaningful\n        \n        plt.figure(figsize=(20,10))\n        for idx in range(10):\n            plt.subplot(2,5,idx+1)\n            img = image_convert(images[idx])\n            label = labels[idx]\n            plt.imshow(img)\n            plt.title(an_[str(label.numpy())])\n        plt.show()\n        \nplot_10()","60fd3bf6":"class SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        #input is calculated as 224*224*3=150528\n        #other layers node are chosen arbitarily\n        self.fc1 = nn.Linear(150528, 240)\n        self.fc2= nn.Linear(240, 120)\n        self.fc3 = nn.Linear(120, 50)\n        #Output node must be 2 as it is 2 class classification problem\n        self.fc4 = nn.Linear(50,2)\n    def forward(self,x):\n        x = x.view(-1, 150528)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\nsimplenet = SimpleNet()","5b7eba9e":"#optimizer helps in finding the suitable weight values to yield minimum loss between prediction and ground values\n#small learning rate(lr) is preferable\noptimizer = optim.Adam(simplenet.parameters(), lr=0.0008)","996bb7ef":"#transfer to GPU if available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\") \nelse:\n    device = torch.device(\"cpu\")\n\nsimplenet.to(device)","81678e27":"def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n    for epoch in range(1, epochs+1):\n        training_loss = 0.0\n        valid_loss = 0.0\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            output = model(inputs)\n            loss = loss_fn(output, targets)\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.data.item() * inputs.size(0)\n        training_loss \/= len(train_loader.dataset)\n        \n        model.eval()\n        num_correct = 0 \n        num_examples = 0\n        for batch in val_loader:\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            output = model(inputs)\n            targets = targets.to(device)\n            loss = loss_fn(output,targets) \n            valid_loss += loss.data.item() * inputs.size(0)\n            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n            num_correct += torch.sum(correct).item()\n            num_examples += correct.shape[0]\n        valid_loss \/= len(val_loader.dataset)\n\n        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n        valid_loss, num_correct \/ num_examples))","869f4670":"train(simplenet, optimizer,torch.nn.CrossEntropyLoss(), train_data_loader,val_data_loader, epochs=5, device=device)","4eaae6fe":"labels = ['cat','dog']\n\nimg = Image.open(\"..\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.102.jpg\") \n\nimg = img_transforms(img).to(device)\nimg = torch.unsqueeze(img, 0)\n\nsimplenet.eval()\nprediction = F.softmax(simplenet(img), dim=1)\nprediction = prediction.argmax()\nprint(labels[prediction])","53e2727b":"img = Image.open(\"..\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.102.jpg\") \nplt.imshow(img)\nplt.title(str(labels[prediction]))\nplt.show()","998af937":"torch.save(simplenet, \"\/tmp\/simplenet\") \nsimplenet = torch.load(\"\/tmp\/simplenet\")","995843e3":"torch.save(simplenet.state_dict(), \"\/tmp\/simplenet\")    \nsimplenet = SimpleNet()\nsimplenet_state_dict = torch.load(\"\/tmp\/simplenet\")\nsimplenet.load_state_dict(simplenet_state_dict)","21bb7281":"<h1 id=\"save\" style=\"font-family:cursive;\"> \n    <center>6. Saving model\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/afiaibnath\/pytorch-cat-or-dog-classifier-from-scratch\/edit\">\u00b6<\/a>\n    <\/center>\n<\/h1>","9dab1c5d":"<h1 id=\"pred\" style=\"font-family:cursive;\"> \n    <center>5. Making prediction\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/afiaibnath\/pytorch-cat-or-dog-classifier-from-scratch\/edit\">\u00b6<\/a>\n    <\/center>\n<\/h1>","9f5d7536":"<h1 id=\"model\" style=\"font-family:cursive;\"> \n    <center>3. Building model to train data\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/afiaibnath\/pytorch-cat-or-dog-classifier-from-scratch\/edit\">\u00b6<\/a>\n    <\/center>\n<\/h1>\n","00acbf36":"# <center><span style=\"font-family:cursive;\"> \ud83d\ude38\ud83d\udc36A SIMPLE CAT\/DOG CLASSIFIER <\/span><\/center>\n\n\n\n<center><img src=\"https:\/\/storage.googleapis.com\/petbacker\/images\/blog\/2017\/dog-and-cat-cover.jpg\"><\/center>\n\n\n\n","4ba0e49d":"<h1 id=\"basics\" style=\"font-family:cursive;\"> \n    <center>1. Building Training,validation and test Dataset\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/afiaibnath\/pytorch-cat-or-dog-classifier-from-scratch\/edit\">\u00b6<\/a>\n    <\/center>\n<\/h1>","f527b579":"<h1 id=\"train\" style=\"font-family:cursive;\"> \n    <center>4. Finally!!Let's train our model \ud83d\ude04\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/afiaibnath\/pytorch-cat-or-dog-classifier-from-scratch\/edit\">\u00b6<\/a>\n    <\/center>\n<\/h1>\n","86c3baea":"<h1 id=\"visual\" style=\"font-family:cursive;\"> \n    <center>2. Visualizing data \ud83d\udc40\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/afiaibnath\/pytorch-cat-or-dog-classifier-from-scratch\/edit\">\u00b6<\/a>\n    <\/center>\n<\/h1>\n\n>Ref: https:\/\/www.kaggle.com\/marcosvafg\/pytorch-cat-and-dog-resnet50"}}