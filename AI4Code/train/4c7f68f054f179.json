{"cell_type":{"9c27242e":"code","f41c42f4":"code","8f237c90":"code","4b62aac4":"code","d5066449":"code","1c40072c":"code","a1ebe837":"code","aa61a08b":"code","ad645bc0":"code","ce51cf67":"code","d08907c0":"code","8be17625":"code","ff4d2ac5":"code","93d6d34f":"code","bc6eb041":"code","8c33325f":"code","4862032c":"code","a340d9ae":"code","7424f20c":"code","f674f6b7":"code","50d5d471":"code","fe501008":"code","1c65e856":"code","6ab1da29":"code","bc9a7bbb":"code","cf69594d":"code","d3f9adf0":"code","f3ca86db":"code","5b5c7285":"code","bdc925bf":"code","f1fdbba6":"code","72e9df21":"code","7418d331":"code","fee69e25":"code","a2a933db":"code","922e262a":"code","d377386c":"code","41be65d1":"code","aa970565":"code","3133afbe":"code","d40a06d9":"code","52899113":"code","6110e5c4":"code","34f6e49f":"code","c354783b":"code","eb66b046":"code","ceeea84f":"code","8ae35760":"markdown","a2be489f":"markdown","4bf98c2d":"markdown","121bed52":"markdown","c8432e46":"markdown","cd369539":"markdown","3e7ec558":"markdown","758b5bb3":"markdown","91fe10e7":"markdown","e1ff1e48":"markdown","49a07c26":"markdown"},"source":{"9c27242e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f41c42f4":"import pandas as pd\nhousing=pd.read_csv('..\/input\/shivhou\/shivhou.csv')\nhousing.head(5)","8f237c90":"housing.info()","4b62aac4":"housing['CHAS'].value_counts() # in this data value one or zero caluculet in CHAS col\n                               # this is acatgericl veliabal","d5066449":"housing.describe()","1c40072c":"%matplotlib inline\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50, figsize=(20,15))","a1ebe837":"from sklearn.model_selection import train_test_split # the shuffle and split is usid in sklearn model.\ntrain_set ,test_set = train_test_split(housing, test_size= 0.2, random_state=43)\nprint(f\"Row in train set: {len(train_set)}\\Row in test set:{len(test_set)}\\n\")","aa61a08b":"from sklearn.model_selection import StratifiedShuffleSplit \nsplit = StratifiedShuffleSplit(n_splits= 1 , test_size=0.2 , random_state=43)\nfor train_index,test_index in split.split(housing,housing['CHAS']):\n    strat_train_set =housing.loc[train_index]\n    strat_test_set =housing.loc[test_index]\n    ","ad645bc0":"strat_test_set['CHAS'].value_counts()","ce51cf67":"strat_train_set['CHAS'].value_counts()","d08907c0":"housing =strat_train_set.copy()","8be17625":"corr_matrix = housing.corr()\ncorr_matrix ['MEDV'].sort_values(ascending = False)# colearetion is 1 to -1 \n                                                    # 1 is the stroing     ","ff4d2ac5":"from pandas.plotting import scatter_matrix\nattributes = [\"MEDV\",\"RM\", \"ZN\",\"LSTAT\"]\nscatter_matrix(housing[attributes],figsize=(12,8))","93d6d34f":"housing.plot(kind= \"scatter\", x =\"RM\", y=\"MEDV\",alpha=(0.8))","bc6eb041":"housing[\"TAXRM\"] = housing[\"TAX\"]\/housing[\"RM\"]\nhousing.head()\n# new attribute set\n","8c33325f":"corr_matrix = housing.corr()\ncorr_matrix ['MEDV'].sort_values(ascending = False)","4862032c":"housing.plot(kind= \"scatter\", x =\"TAXRM\", y=\"MEDV\",alpha=(0.8))","a340d9ae":"housing= strat_train_set.drop('MEDV', axis=1)\nhousing_labels = strat_train_set['MEDV'].copy()","7424f20c":"a = housing.dropna(subset=[\"RM\"])  # potion 1\na.shape  #Get rid of the missing data points  ","f674f6b7":"housing.drop(\"RM\",axis=1).shape   # Note there is no RM collmn\n#Get rid of the Whole attribute # option 2","50d5d471":"median = housing[\"RM\"].median() # comput median for option \nmedian","fe501008":"housing[\"RM\"].fillna(median) #Set the value to same value (0,mean or mediam)","1c65e856":"housing.shape","6ab1da29":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = \"median\")\nimputer.fit(housing)","bc9a7bbb":"imputer.statistics_","cf69594d":"x = imputer.transform(housing)\nhousing_tr =pd.DataFrame(x,columns=housing.columns)\nhousing_tr.describe()","d3f9adf0":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nmy_pipeline = Pipeline([\n    ('inputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler',StandardScaler()),\n                      ])\n","f3ca86db":"housing_num_tr = my_pipeline.fit_transform(housing_tr)\nhousing_num_tr = my_pipeline.fit_transform(housing)\nhousing_num_tr \nhousing_num_tr.shape\n","5b5c7285":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n#model= DecisionTreeRegressor()\n#model = LinearRegression()\nmodel = RandomForestRegressor()\nmodel.fit(housing_num_tr , housing_labels)","bdc925bf":"some_data =housing .iloc[:5]","f1fdbba6":"some_datals =housing_labels.iloc[:5]","72e9df21":"prepared_data = my_pipeline.transform(some_data)","7418d331":"model.predict(prepared_data)","fee69e25":"list(some_datals)","a2a933db":"from sklearn.metrics import mean_squared_error\nhousing_predictctions = model.predict(housing_num_tr)\nmse = mean_squared_error(housing_labels, housing_predictctions)\nrmse = np.sqrt(mse)","922e262a":"rmse","d377386c":"mse","41be65d1":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(model, housing_num_tr,housing_labels , scoring =\"neg_mean_squared_error\",cv=10)\nrmse_scores = np.sqrt(-scores)","aa970565":"rmse_scores","3133afbe":"def print_scores(scores):\n    print(\"scores:\",scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","d40a06d9":"print_scores(rmse_scores)","52899113":"from joblib import dump,load\ndump(model, 'Shiv.joblib')","6110e5c4":"x_test =strat_test_set.drop('MEDV', axis=1)\ny_test =strat_test_set[\"MEDV\"].copy()\nx_test_prepared = my_pipeline.transform(x_test)\nfinal_predictions= model.predict(x_test_prepared)\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rnse = np.sqrt(final_mse)\nprint(final_predictions, list(y_test))","34f6e49f":"final_rnse","c354783b":"prepared_data[0]","eb66b046":"from joblib import dump,load\nimport numpy as np\nmodel= load( 'Shiv.joblib')","ceeea84f":"features= np.array([[0.4048055 ,  -0.88894949, -1.3932448 , -0.27288841, -1.29089824,\n        1.40244746, -1.24839122,  0.65332037, 20.85275281, 0.44492981,\n       -2.60558671,  10.42866779, -8.19447262]])\nmodel.predict(features)","8ae35760":"Train-Test Splitting","a2be489f":"Missing Attributes\n\n\n\nto take care of missing your have three option\n 1. Get rid of the missing data points\n 2. Get rid of the Whole attribute\n 3 Set the value to same value (0,mean or mediam)","4bf98c2d":"# selecting a desired model","121bed52":"problem of the model in in thist ex \"CHAS \" are valus is one and zero in case model used of the zero \nall value and othe vais model using all value is one aved this problem.","c8432e46":"# Using better evaluation technique - cross validat\n","cd369539":"# testing the model on test data","3e7ec558":"Trying Attribute Combinations","758b5bb3":"# Evaluation the Model","91fe10e7":"Looking for Correlations","e1ff1e48":"DecisionTreeRegresso\nMean: 4.883191127119578\nStandard deviation: 1.0379878308405717\n\u200b\nLinearRegression()\nMean: 5.06445346651407\nStandard deviation: 1.4554192632554648\n\u200b\nRandomForestRegressor()\nMean: 3.472643010877195\nStandard deviation: 1.0260471652050311\n","49a07c26":"# Scikit-Learn Design\n\nPrimarily three of objects\n\nEstimators - It estimates some parameter based on a dataset. Eg.imputer It has a fit method and transform method. fit method -fits the dataset and calculates internal parameters\n\nTransformers tarnsformers method takes input and returns output based on the learnigs form fit(). It also has a convenience function called fit_transform() which fits and then tarnsforms.\n\nPredictors linearRegression model in an eg. of predictor . fit() and predict()are two common functions . it also gives score()function which will evaluate the predictions.\n\n# Feature Scaling\n\nPrimarily, two types of feature Scaling methods\n\nmin-max scaling (Normalization) (value - main)\/(max - min) Sklearn provides a class called minmaxScaler for this\nStandardizatopn (value - mean)\/(std) Sklearn provides a class called Standardscaler for this\n\n\n# Creting a Pipeling"}}