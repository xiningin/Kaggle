{"cell_type":{"bd27b92d":"code","70990130":"code","49d3fb62":"code","7a38fbec":"code","12b936f7":"code","cc16355f":"code","2080c5d6":"code","d0cdbe80":"code","bd15f2e4":"code","c03cdbcd":"code","d765843b":"code","6cbfc7ea":"code","4c04b7ed":"code","0d4439fa":"code","59d7da33":"code","61477607":"code","6ddd1803":"code","fdb7f2e1":"code","afbd7581":"code","dcd9257b":"code","ea784d9d":"code","e2ce4a7f":"code","33097adc":"code","ba29713d":"code","b9017dd4":"code","b8177037":"code","d298d9f3":"code","90737a33":"code","23e7954c":"code","fdf91d99":"code","917fbc77":"code","50477c55":"markdown","0a04b2c2":"markdown","ee58b881":"markdown","3c45754b":"markdown"},"source":{"bd27b92d":"# Remove categorical variables\n# Take the log on sales price\n# Use decision Tree\n# Best depth with CV\n# only use columns \n# ['Id','LotArea', 'OverallQual','OverallCond','YearBuilt','TotRmsAbvGrd','GarageCars','WoodDeckSF',\n# 'PoolArea','SalePrice']\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","70990130":"columns_to_use = ['Id', 'LotArea', 'OverallQual','OverallCond','YearBuilt',\n                  'TotRmsAbvGrd','GarageCars','WoodDeckSF','PoolArea','SalePrice']\ncolumns_in_test = columns_to_use.copy()\ncolumns_in_test.remove(\"SalePrice\")\ncolumns_in_test","49d3fb62":"df = pd.read_csv(\"..\/input\/train.csv\", usecols=columns_to_use)\ndf.set_index('Id', inplace=True)\npd.options.display.max_rows=5","7a38fbec":"df","12b936f7":"df.isna().sum().sum()","cc16355f":"y = np.log(df.SalePrice)\nX = df.drop(['SalePrice'], 1)","2080c5d6":"from sklearn import tree","d0cdbe80":"from sklearn.model_selection import train_test_split","bd15f2e4":"X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(\n    X, y, test_size = 0.20, random_state = 1\n)","c03cdbcd":"print(f\"X_train_and_validate shape is {X_train_and_validate.shape}\")\nprint(f\"X_test shape is {X_test.shape}\")\n# print(f\"X_validate shape is {X_validate.shape}\")\nprint(f\"y_train_and_validate shape is {y_train_and_validate.shape}\")\n# print(f\"y_validate shape is {y_validate.shape}\")\nprint(f\"y_test shape is {y_test.shape}\")","d765843b":"from sklearn.metrics import mean_squared_error\ndef root_mean_squared_error(y_true, y_pred):\n    ''' Root mean squared error regression loss\n    \n    Parameters\n    ----------\n    y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\n    y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n    Estimated target values.\n    '''\n    return np.sqrt(mean_squared_error(y_true, y_pred))","6cbfc7ea":"from sklearn.model_selection import validation_curve\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import make_scorer","4c04b7ed":"rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)","0d4439fa":"pipe_tree = make_pipeline(tree.DecisionTreeRegressor(random_state=1))","59d7da33":"# make an array of depths to choose from, say 1 to 20\ndepths = np.arange(1, 21)\ndepths","61477607":"num_leafs = [1, 5, 10, 20, 50, 100]","6ddd1803":"from sklearn.model_selection import GridSearchCV","fdb7f2e1":"param_grid = [{'decisiontreeregressor__max_depth':depths,\n              'decisiontreeregressor__min_samples_leaf':num_leafs}]","afbd7581":"gs = GridSearchCV(estimator=pipe_tree, param_grid=param_grid, scoring=rmse_scorer, cv=10)","dcd9257b":"gs = gs.fit(X_train_and_validate, y_train_and_validate)","ea784d9d":"print(-gs.best_score_)","e2ce4a7f":"print(gs.best_params_)","33097adc":"my_model = gs.best_estimator_","ba29713d":"my_model.fit(X_train_and_validate, y_train_and_validate)","b9017dd4":"y_predicted = my_model.predict(X_test)\nroot_mean_squared_error(y_test, y_predicted)","b8177037":"# \u3053\u3053\u306b\u6765\u3066\u3001\u4ee5\u4e0b\u306e\u3059\u3079\u3066\u3092test\u3067\u306f\u306a\u304f\u3001submit\u3068\u547c\u3076\u3053\u3068\u306b\u3059\u308b\nsubmit = pd.read_csv('..\/input\/test.csv', usecols=columns_in_test)\nsubmit.set_index('Id', inplace=True)\n# Treat the test data in the same way as training data. In this case, pull same columns.\nsubmit_X = submit.replace(np.nan, 0)\n# submit_X = encoder.transform(submit_X)\n# test_X = test.replace(np.nan, 0, inplace=True)\n# test_X = test[predictor_cols]\n# Use the model to make predictions\npredicted_prices = my_model.predict(submit_X)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)","d298d9f3":"# Get the exponent of prices\n# The current predicted prices are the log of the prices\npredicted_prices = np.exp(predicted_prices)","90737a33":"my_submission = pd.DataFrame({'Id': submit_X.index, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('07_decisiontree_CV_maxdepth5.csv', index=False)","23e7954c":"import matplotlib.pyplot as plt","fdf91d99":"df.SalePrice.hist()","917fbc77":"np.log10(df.SalePrice).hist()","50477c55":"## \u4e00\u756a\u3044\u3044\u7d50\u679c\u306e\u4e2d\u8eab","0a04b2c2":"## max-depth\u3068min_samples_leaf\u3092\u6700\u9069\u5316\u3057\u305f\u3044\n- depths\u3068num_leafs \u5185\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u5bfe\u3057\u3001\u4e00\u756a\u3044\u3044\u3082\u306e\u304c\u3069\u308c\u304b\u3092\u6c7a\u5b9a\u3057\u305f\u3044\n- train \u3092CV\u3057\u3001\u5e73\u5747\u7684\u306b\u6700\u3082\u3044\u3044 hyper-parameter \u306e\u5024\u3092\u51fa\u3059","ee58b881":"## \u671f\u5f85\u3067\u304d\u308b\u30b9\u30b3\u30a2\u3092\u7b97\u51fa","3c45754b":"# \u63d0\u51fa\u7528"}}