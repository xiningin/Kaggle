{"cell_type":{"5af660d8":"code","f3297cdc":"code","c5cf6c5d":"code","d0c48aa5":"code","56fc6e30":"code","94e6ef38":"code","b06f9980":"code","9dd9f1a8":"code","c76ca7ad":"code","f5a6d852":"code","25a1f37d":"code","ca46ecbe":"code","b810497a":"code","3e63127a":"code","8a183ee1":"code","73e78dc8":"code","b2fbc2d9":"code","82138c70":"code","6de3b931":"code","77d95dfc":"markdown","f61dccaf":"markdown","d3ae82b3":"markdown","f19479da":"markdown","d7aa2162":"markdown","9abcabf0":"markdown","03a694af":"markdown","06d67659":"markdown","2989abf9":"markdown","d30fd68e":"markdown"},"source":{"5af660d8":"################## \uc2dc\ud5d8 \uc548\ub0b4 \ubb38\uad6c \ubc0f \ucf54\ub4dc ##################\n# \ucd9c\ub825\uc744 \uc6d0\ud558\uc2e4 \uacbd\uc6b0 print() \ud568\uc218 \ud65c\uc6a9\n# \uc608\uc2dc) print(df.head())\n\n# getcwd(), chdir() \ub4f1 \uc791\uc5c5 \ud3f4\ub354 \uc124\uc815 \ubd88\ud544\uc694\n# \ud30c\uc77c \uacbd\ub85c \uc0c1 \ub0b4\ubd80 \ub4dc\ub77c\uc774\ube0c \uacbd\ub85c(C: \ub4f1) \uc811\uadfc \ubd88\uac00\n\n# \ub2f5\uc548 \uc81c\ucd9c \ucc38\uace0\n# \uc544\ub798 \ucf54\ub4dc \uc608\uce21\ubcc0\uc218\uc640 \uc218\ud5d8\ubc88\ud638\ub97c \uac1c\uc778\ubcc4\ub85c \ubcc0\uacbd\ud558\uc5ec \ud65c\uc6a9\n# pd.DataFrame({'enrollee_id': X_test.enrollee_id, 'target': pred}).to_csv('003000000.csv', index=False)","f3297cdc":"import pandas as pd\n\nX_train = pd.read_csv(\"..\/input\/hr-data\/X_train.csv\")\ny_train = pd.read_csv(\"..\/input\/hr-data\/y_train.csv\")\nX_test = pd.read_csv(\"..\/input\/hr-data\/X_test.csv\")\n\nX_train.shape , y_train.shape , X_test.shape","c5cf6c5d":"X_train.head()","d0c48aa5":"y_train.head()","56fc6e30":"print(X_train.info())","94e6ef38":"print(\"##train##\")\nprint(X_train.isnull().sum())\nprint(\"\\n##test##\")\nprint(X_test.isnull().sum())","b06f9980":"y_train['target'].value_counts()","9dd9f1a8":"# training_hours\n\nimport numpy as np\nQ1 = np.percentile(X_train['training_hours'],25)\nQ3 = np.percentile(X_train['training_hours'],75)\nIQR = Q3 - Q1\noutdata1 = X_train[X_train['training_hours']<(Q1 - 1.5 * IQR)]\noutdata2 = X_train[X_train['training_hours']>(Q3 + 1.5 * IQR)]\nlen(outdata1), len(outdata2)\n\n# \uc0ad\uc81c\ud558\uae34 \ub9ce\uc74c","c76ca7ad":"# city_development_index \n\nQ1 = np.percentile(X_train['city_development_index'],25)\nQ3 = np.percentile(X_train['city_development_index'],75)\nIQR = Q3 - Q1\noutdata1 = X_train[X_train['city_development_index']<(Q1 - 1.5 * IQR)]\noutdata2 = X_train[X_train['city_development_index']>(Q3 + 1.5 * IQR)]\nlen(outdata1), len(outdata2)\n\n#\uc0ad\uc81c \uc608\uc815","f5a6d852":"# \ub370\uc774\ud130 \ud655\uc778\n\nobj_cols = np.array(X_train.columns[X_train.dtypes == object])\nfor col in obj_cols:\n    print(\"\\n##### : \",col)\n    print(X_train[col].value_counts())\nobj_cols","25a1f37d":"# object \uceec\ub7fc \uacb0\uce21\uce58 \ucc98\ub9ac\n\nX_train = X_train.fillna(\"X\")\nX_test = X_test.fillna(\"X\")","ca46ecbe":"# \uc774\uc0c1\uce58 \uc0ad\uc81c\n\nprint(X_train.shape)\nind = X_train[X_train['city_development_index']<(Q1 - 1.5 * IQR)].index\nX_train = X_train.drop(index=ind, axis=0)\ny_train = y_train.drop(index=ind, axis=0)\n\nprint(X_train.shape)","b810497a":"from sklearn.preprocessing import LabelEncoder\n\nall_df = pd.concat([X_train.assign(ind=\"train\"), X_test.assign(ind=\"test\")])\nle = LabelEncoder()\nall_df[obj_cols] = all_df[obj_cols].apply(le.fit_transform)\n\nX_train = all_df[all_df['ind'] == 'train']\nX_train = X_train.drop('ind',axis=1)\nX_train\n\nX_test = all_df[all_df['ind'] == 'test']\nX_test = X_test.drop('ind',axis=1)\nX_test","3e63127a":"# \uc2a4\ucf00\uc77c\ub9c1\n\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\n\nn_cols = ['city_development_index', 'training_hours']\nX_train[n_cols] = scaler.fit_transform(X_train[n_cols])\nX_test[n_cols] = scaler.transform(X_test[n_cols])\nX_train","8a183ee1":"# \ud559\uc2b5\uc6a9 \ub370\uc774\ud130\uc640 \uac80\uc99d\uc6a9 \ub370\uc774\ud130\ub85c \uad6c\ubd84\n# \ud559\uc2b5\uc5d0 \ub9ce\uc740 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574 \uac80\uc99d\uc740 \uc791\uac8c \uac00\uc838\uac10\n\nfrom sklearn.model_selection import train_test_split\n\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train['target'], test_size=0.1, random_state=2022)\nX_tr.shape, X_val.shape, y_tr.shape, y_val.shape","73e78dc8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nrf = RandomForestClassifier(random_state = 2022)\nrf.fit(X_tr, y_tr)\npred = rf.predict_proba(X_val)[:,1]\nprint(roc_auc_score(y_val, pred))","b2fbc2d9":"# Test\ub370\uc774\ud130\n\npred = rf.predict_proba(X_test)[:,1]","82138c70":"# csv\uc0dd\uc131\ucf54\ub4dc\n\npd.DataFrame({'enrollee_id': X_test.enrollee_id, 'target': pred}).to_csv('003001179.csv', index=False)","6de3b931":"import pickle\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\nwith open( \"..\/input\/hr-data\/answer.pickle\", \"rb\" ) as file:\n    ans = pickle.load(file)\n    ans = pd.DataFrame(ans)\nprint(roc_auc_score(ans['target'], pred))","77d95dfc":"# \uc81c\ucd9c\uc6a9","f61dccaf":"# \ub370\uc774\ud130 \uc804\ucc98\ub9ac","d3ae82b3":"# EDA","f19479da":"# \ub370\uc774\ud130 \ubd84\ub9ac","d7aa2162":"## \ucc44\uc810","9abcabf0":"# \ubaa8\ub378 \ud559\uc2b5 \ubc0f \ud3c9\uac00","03a694af":"## \ubaa8\uc758\uace0\uc0ac\n    # \uc774\uc9c4 \ubd84\ub958\n    # \uc774\uc9c1\ud560 \uc0ac\ub78c\uc744 \ucc3e\ub294 \ubb38\uc81c(\uc9c0\uc6d0\uc790\uac00 \uc77c\ud560 \ud655\ub960)\n## \ud3c9\uac00\n    # \ud655\ub960\uac12 \uc608\uce21\n    # \ud3c9\uac00 : ROC-AUC (\uc774\uc9c1\ud560 \ud655\ub960)\n## \uc608\uce21\n    # target: 0 \u2013 \uc774\uc9c1\ud560 \ub9c8\uc74c \uc5c6\uc74c, 1 \u2013 \uc774\uc9c1\ud560 \ud68c\uc0ac \ucc3e\uace0 \uc788\uc74c","06d67659":"# \ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1","2989abf9":"# \uc774\uc0c1\uce58IQR","d30fd68e":"# \ub77c\uc774\ube0c\ub7ec\ub9ac \ubc0f \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30"}}