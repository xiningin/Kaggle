{"cell_type":{"408c40de":"code","a765fc1b":"code","3c4ad56b":"code","757a4270":"code","568b1874":"code","2dbb7b2a":"code","13bd84c1":"code","8e382a9b":"code","3ae86176":"markdown"},"source":{"408c40de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.metrics import mean_squared_error as mse\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a765fc1b":"train_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-4\/train.csv\")\neval_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-4\/eval.csv\")","3c4ad56b":"train_data.head()\nprint(eval_data.shape)\ntrain_data.shape","757a4270":"X = train_data.iloc[:, 2:].to_numpy().reshape(-1, 28, 28, 1) \/ 255\ny = pd.get_dummies(train_data['label'].to_numpy())\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n\n\nX_eval = eval_data.iloc[:, 1:].to_numpy().reshape(-1, 28, 28, 1) \/ 255","568b1874":"# Building the model\nepochs = 30\nmodel = Sequential([\n    Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n    MaxPooling2D(2),\n    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(2),\n    Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(2),\n    Flatten(),\n    Dense(128, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(64, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(10, activation=\"softmax\")\n])\n\nadam = Adam(learning_rate=0.0001, decay=1e-6, amsgrad=True)\n\nmodel.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_split=0.20)\nmodel.summary()","2dbb7b2a":"print(str(model.evaluate(X_test, y_test)))\n\nprediction = np.argmax(model.predict(X_eval), axis=1)\nprint(prediction.shape)","13bd84c1":"output = pd.DataFrame({'id': eval_data['id'], 'label': prediction})\noutput.to_csv('submission.csv', index=False)\nprint(\"Output Successful\")","8e382a9b":"print(output.to_string())","3ae86176":"# Taniya Shaffer\n## CAP4611 HW4, Classifying Clothes"}}