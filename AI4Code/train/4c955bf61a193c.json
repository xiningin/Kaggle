{"cell_type":{"038ad007":"code","bbe304c4":"code","bcfec7b8":"code","5ab64318":"code","99a93bd6":"code","b4a0e708":"code","fd00453f":"code","00e189c4":"code","899f6b6f":"code","4db99371":"code","b8a18f22":"code","8036c944":"code","068e4ffb":"code","f9f282d7":"code","a13e7836":"code","a64429d3":"code","2eefd305":"code","f70ee873":"code","ff96337f":"code","92d23ffe":"code","ded16dca":"code","392a9141":"code","02faf2ba":"code","54085782":"code","b353df72":"code","a0411f7b":"code","59f040e3":"code","3641d035":"code","1167e5ad":"code","3b46e82d":"code","e3d59224":"code","c3a55a53":"code","b42c805c":"code","93946ac0":"code","334d5659":"code","6bed00ad":"code","c72eb391":"code","2465cbc7":"code","81c5bb68":"code","39df1a25":"code","e47abe77":"code","446d0459":"code","743d1f9c":"code","04acbc7a":"code","84deed12":"code","58285c5f":"code","271470d8":"code","a01b78fc":"code","acdf30f1":"code","28543352":"code","41d4326e":"code","f1842d87":"code","1a5b8225":"code","be52c59e":"code","382a848e":"code","7e093062":"code","ee1e73ee":"code","e9d5907c":"code","e292586e":"code","47a98428":"code","5f85dc28":"code","e0cd9d8e":"code","277f37e6":"code","4ec322a5":"code","0675c19d":"code","d42d7c18":"code","24ea7ac8":"code","ad2e63c3":"code","9c4097c1":"code","883b0722":"code","dec91548":"code","f47303a2":"code","41af0a24":"code","679f8490":"code","165c5e92":"code","9ad379ff":"code","7f456538":"code","ca2cdf79":"code","53efd7c7":"code","ca0d29f6":"code","23c96fa0":"code","66d37848":"code","66de3818":"code","cba16713":"code","5914adf9":"code","ec982aae":"code","7b2c74ef":"code","0d8b139c":"code","697179b3":"code","330602cf":"code","bd5d452b":"code","d7884c92":"code","ab49bc0c":"code","42ed5ecd":"code","25443404":"code","f2bc9a30":"code","f4083fab":"code","f12de51b":"code","4fb261fb":"code","10d4223f":"code","86dce17a":"code","ba257c8d":"code","74687355":"code","2c18baff":"code","8c0fcbe4":"code","4ffa6e5f":"code","cf0ef046":"code","f4e36580":"code","1caa8328":"code","6602619f":"code","d9ba7d6b":"code","8157172c":"code","1236bd9a":"code","86edd2dd":"code","c38bc9a1":"markdown","c0fe3833":"markdown","7ab67489":"markdown","9192ba4e":"markdown","468e2610":"markdown","8f8d310b":"markdown","7f10431c":"markdown","42301ae6":"markdown","e1e42189":"markdown","beaee06f":"markdown","e36dbfdc":"markdown","9c5f4971":"markdown","2d9c2468":"markdown","f7b2c681":"markdown","a017d96f":"markdown","1e99bd6e":"markdown"},"source":{"038ad007":"import numpy as np \nimport pandas as pd ","bbe304c4":"import yaml\n\nPATH = \"..\/input\/mymusicalprefrences\/\" \ntrain = pd.read_csv(f\"{PATH}train.csv\")\ntest = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\ndf = pd.concat([train,test]).reset_index(drop=True)\ntr_mask = ~df.Category.isna()","bcfec7b8":"df.describe()","5ab64318":"df","99a93bd6":"df.isnull().sum()","b4a0e708":"#cleans up the column names, so there is no whitespace in them\ndf.columns = [i.strip() for i in df.columns]\n\n#cat_features displays all the features that have no numerical value\ncat_features = {\"Artists\",\"Track\",\"Version\",\"Artists_Genres\",\"Album\",\"Album_type\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\n\n#con_features display featueres with numerical value\ncon_features = {\"Duration\",\"Release_year\",\"BPM\",\"Energy\",\"Dancebility\",\"Happiness\"}\n\ndisplay(df[cat_features].head())\ndisplay(df[con_features].head())","fd00453f":"df['Vocal'].unique()","00e189c4":"import seaborn as sns\npalette = ['#063970',\"#1e81b0\",\"#e28743\"]\nsns.palplot(palette)","899f6b6f":"df[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})\ndf[\"Category\"].head()\n\nimport plotly.graph_objects as go\n\ndef plot_commulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=palette[i])))\n    fig.show()","4db99371":"# Fills all the NaN with N for Neither\ndf['Vocal'] = df['Vocal'].fillna('N')\n\n#onehot vector to convert the values into binary code. F [1,0]; M [0,1]; N[1,1]\n#np.zeros creats an array with only 0 in it\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    x = df.iloc[i]['Vocal']\n    if x == 'F':\n        onehot[i] = [1,0]\n    elif x == 'M':\n        onehot[i] = [0,1]\n    elif x == 'N':\n        onehot[i] = [1,1]\n\n#creats two new catergories with the value of the onehot array\ndf[[\"Fem_voc\",\"Mal_voc\"]] = onehot\n\n#erases the Vocal catergory\ndf = df.drop('Vocal',axis=1)\ndf.head()","b8a18f22":"description['Release year']","8036c944":"import plotly.express as xp\nxp.scatter(df, x=\"Release_year\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=palette)","068e4ffb":"#converting the years from 2011 to 2010\ndf.loc[:,'Release_decade'] = df.loc[:,'Release_year']\/\/10 * 10\n#defining a function to summarize all the releases before 1990   ### MAYBE CHANGE TO 1980\ndef summarize(a_number):\n    if a_number < 1990:\n        return int(1990)\n    else:\n        return int(a_number)\ndf['Release_decade'] = df['Release_decade'].map(summarize)\n\n#groupby groups two columns together -> .count() puts the groups together, so it counts all the 1980s, 1990s etc.\n_df = df.groupby([\"Release_decade\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"Release_decade\", y=\"Track\",color=\"Category\",height=500, color_discrete_sequence=palette)","f9f282d7":"pd.crosstab(df[\"Category\"] ,df[\"Release_decade\"], normalize=True)","a13e7836":"df.drop(columns =[\"Release_year\"], inplace = True)","a64429d3":"df[['Happiness','Dancebility','Energy']].isnull().sum()\ndf[['Happiness','Dancebility','Energy']] = df[['Happiness','Dancebility','Energy']].fillna(0)\ndf[['Happiness','Dancebility','Energy']] = df[['Happiness','Dancebility','Energy']].apply(lambda x: x\/100)","2eefd305":"df[['Happiness','Dancebility','Energy']].head()","f70ee873":"df['BPM'].head()","ff96337f":"df['Key'].isnull().sum()","92d23ffe":"df.head()","ded16dca":"# new data frame with split value columns\nnew = df[\"Key\"].str.split(\" \", n = 1, expand = True)\n  \n# making separate first name column from new data frame\ndf[\"new_key\"]= new[0]\n  \n# making separate last name column from new data frame\ndf[\"is_Minor\"]= new[1]\n  \n# Dropping old Name columns\ndf.drop(columns =[\"Key\"], inplace = True)\n  \n# df display\ndf","392a9141":"df.new_key.unique()","02faf2ba":"def key_change(key):\n    if key == 'D\u266d':\n        return 'C#'\n    elif key == 'E\u266d':\n        return 'D#'\n    elif key == 'G\u266d':\n        return 'F#'\n    elif key == 'A\u266d':\n        return 'G#'\n    elif key == 'B\u266d':\n        return 'A#'\n    else:\n        return key\n\n_df.new_key = df.new_key.map(key_change)\n_df.new_key.unique()","54085782":"df.new_key = df.new_key.map(key_change)\ndf.new_key","b353df72":"df = pd.get_dummies(df, columns = ['new_key'])\ndf","a0411f7b":"df.is_Minor","59f040e3":"def is_Minor(a_str):\n    if a_str == 'Minor':\n        return 1\n    if a_str == 'Major':\n        return 0\ndf.is_Minor = df.is_Minor.map(is_Minor)\ndf.is_Minor","3641d035":"df.head()","1167e5ad":"#Categories: \n#Pop: ruspop, pop , kpop, \n#Film: films, soundtrack, classicalmasterpieces, classical\n#rock: rock, rusrock, hardrock, \n#rap: rap, foreignrap, rusrap, \n#electronic: house, prog, trance, dnb, industrial, dance\n#jazz: soul, jazz, blues,\n\nonehot = np.zeros((len(df),7))\nfor i in range(len(df)):\n    x = df.iloc[i]['Artists_Genres'].split('|')\n    if 'pop' in x or 'ruspop'in x or 'kpop' in x:\n        onehot[i] = [1,0,0,0,0,0,0]\n    elif 'films' in x or 'soundtrack' in x or 'classicalmasterpieces' in x or 'classical' in x:\n        onehot[i] = [0,1,0,0,0,0,0]\n    elif 'rock' in x or 'rusrock' in x or 'hardrock' in x:\n        onehot[i] = [0,0,1,0,0,0,0]\n    elif 'rap' in x or 'foreignrap' in x or 'rusrap' in x:\n        onehot[i] = [0,0,0,1,0,0,0]\n    elif 'house' in x or 'prog' in x or 'trance' in x or 'dnb' in x or 'industrial' in x or 'dance' in x:\n        onehot[i] = [0,0,0,0,1,0,0]\n    elif 'soul' in x or 'jazz' in x or 'blues' in x:\n        onehot[i] = [0,0,0,0,0,1,0]\n    else:\n        onehot[i] = [0,0,0,0,0,0,1]\n\ndf[[\"sum_pop\",\"sum_films\",'sum_rock','sum_rap','sum_house','sum_soul','sum_others']] = onehot\n__df = df[['Category',\"sum_pop\",\"sum_films\",'sum_rock','sum_rap','sum_house','sum_soul','sum_others']]\ndf = df.drop('Artists_Genres',axis=1)\ndf.head()","3b46e82d":"plot_commulative_onehot(__df)","e3d59224":"df.head()","c3a55a53":"#Don't know if the data is necessary\n\ndf = df.drop(\"Labels\", axis=1)\ndf","b42c805c":"df.Version.unique()\ndf.Version = df.Version.fillna('Other')\ndf.Version.isnull().sum()","93946ac0":"df = pd.get_dummies(df, columns = ['Version'])\ndf","334d5659":"df.Album_type = df.Album_type.fillna('Other')","6bed00ad":"df = pd.get_dummies(df, columns = ['Album_type'])\ndf","c72eb391":"__df = df[['Category','Album_type_Other','Album_type_compilation','Album_type_single']]\nplot_commulative_onehot(__df)","2465cbc7":"df.Country.unique()\n#df.Country.isnull().sum()","81c5bb68":"df.Country = df.Country.fillna('Other')","39df1a25":"df.Country.isnull().sum()","e47abe77":"onehot = np.zeros((len(df),4))\nfor i in range(len(df)):\n    x = df.iloc[i]['Country'].split('|')\n    if 'GB' in x:\n        onehot[i] = [1,0,0,0]\n    elif 'USA' in x:\n        onehot[i] = [0,1,0,0]\n    elif 'RUS' in x:\n        onehot[i] = [0,0,1,0]\n    else:\n        onehot[i] = [0,0,0,1]\n","446d0459":"df[[\"GB\",\"USA\",'RUS','other_country']] = onehot\n__df = df[['Category',\"GB\",\"USA\",'RUS','other_country']]\ndf.head()","743d1f9c":"plot_commulative_onehot(__df)","04acbc7a":"df = df.drop('Country',axis=1)","84deed12":"df","58285c5f":"df.head()","271470d8":"df.Duration.describe()","a01b78fc":"df","acdf30f1":"#df.Track.head()\ndf = df.drop('Track',axis=1)","28543352":"df.Artists = df.Artists.fillna(\"NA\")\n\nall_artists = []\nfor i in df.index:\n    all_artists.extend(df.loc[i, \"Artists\"].split(\"|\"))\n\nlen(set(all_artists))","41d4326e":"from collections import Counter\n\nother = Counter(all_artists)","f1842d87":"threshold = 3\nothers = Counter(all_artists)\nothers = [k for k in others if others[k]<=threshold]\n\na_others = Counter(others)","1a5b8225":"len(others)","be52c59e":"in_train, in_test = [], []\nfor i in df.loc[tr_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~tr_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","382a848e":"all_artists = list(set(all_artists) - set(others) - only_test - only_train)\nprint(len(all_artists))\nothers = set(others) | only_test | only_train\nprint(len(others))","7e093062":"res = []\ndef prune(x):\n    vector = np.zeros(len(all_artists)+1) #for others\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(all_artists)):\n        vector[i]=1 if all_artists[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    res.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists= pd.DataFrame(res, columns = all_artists+[\"Others\"], index=df.index)","ee1e73ee":"df[\"Other_Artists\"] = onehot_artists[\"Others\"]\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\nonehot_artists[\"Category\"] = df[\"Category\"]","e9d5907c":"from sklearn.cluster import KMeans\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\n\n__df = onehot_artists.drop('Category',axis=1)\n\npca = PCA(n_components = 2) \nX_principal = pca.fit_transform(__df) \nX_principal = pd.DataFrame(X_principal) \nX_principal.columns = ['P1', 'P2'] \n  \nX_principal.head()","e292586e":"import matplotlib.pyplot as plt\n\nsse = {}\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X_principal)\n    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","47a98428":"kmeans = KMeans(n_clusters=3)\nkmeans.fit(X_principal)","5f85dc28":"plt.scatter(X_principal['P1'], X_principal['P2'],  \n           c = KMeans(n_clusters = 3).fit_predict(X_principal), cmap =plt.cm.winter) \nplt.show() ","e0cd9d8e":"_a = pd.DataFrame(X_principal)","277f37e6":"df['kmean_artist_1'] = X_principal['P1']\ndf['kmean_artist_2'] = X_principal['P2']","4ec322a5":"df = df.drop('Artists',axis=1)","0675c19d":"df","d42d7c18":"df[\"Album\"] = df[\"Album\"].fillna(\"NA\")\nall_albums = []\nfor i in df.index:\n    all_albums.extend(df.loc[i, \"Album\"].split(\"|\"))\nlen(set(all_albums))","24ea7ac8":"other = Counter(all_albums)","ad2e63c3":"threshold = 3\nothers = Counter(all_albums)\nothers = [k for k in others if others[k]<=threshold]\nlen(others)\na_others = Counter(others)","9c4097c1":"in_train, in_test = [], []\nfor i in df.loc[tr_mask].index:\n    in_train.extend(df.loc[i, \"Album\"].split(\"|\"))\nfor i in df.loc[~tr_mask].index:\n    in_test.extend(df.loc[i, \"Album\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","883b0722":"all_albums = list(set(all_albums) - set(others) - only_test - only_train)\nprint(len(all_albums))\nothers = set(others) | only_test | only_train\nprint(len(others))","dec91548":"res = []\ndef prune(x):\n    vector = np.zeros(len(all_albums)+1) #for others\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(all_albums)):\n        vector[i]=1 if all_albums[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    res.append(vector)\n\ndf[\"Album\"].apply(prune)\nonehot_albums= pd.DataFrame(res, columns = all_albums+[\"Others\"], index=df.index)","f47303a2":"df[\"Other_Albums\"] = onehot_albums[\"Others\"]\nonehot_albums = onehot_albums.drop(\"Others\", axis=1)\nonehot_albums[\"Category\"] = df[\"Category\"]","41af0a24":"onehot_albums","679f8490":"__df = onehot_albums.drop('Category',axis=1)\n\npca = PCA(n_components = 2) \nX_principal = pca.fit_transform(__df) \nX_principal = pd.DataFrame(X_principal) \nX_principal.columns = ['P1', 'P2'] \n  \nX_principal.head()","165c5e92":"import matplotlib.pyplot as plt\n\nsse = {}\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X_principal)\n    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","9ad379ff":"kmeans = KMeans(n_clusters=3)\nkmeans.fit(X_principal)","7f456538":"plt.scatter(X_principal['P1'], X_principal['P2'],  \n           c = KMeans(n_clusters = 3).fit_predict(X_principal), cmap =plt.cm.winter) \nplt.show() ","ca2cdf79":"_a = pd.DataFrame(X_principal)","53efd7c7":"df['kmean_album_1'] = X_principal['P1']\ndf['kmean_album_2'] = X_principal['P2']","ca0d29f6":"df.head()","23c96fa0":"df = df.drop('Album',axis=1)","66d37848":"df","66de3818":"x, y = df.loc[tr_mask].iloc[:,2:], df.loc[tr_mask,\"Category\"]\ndeploy = df.loc[~tr_mask].iloc[:,2:]","cba16713":"deploy","5914adf9":"def zero_one(a_string):\n    if a_string == 'like':\n        return 1\n    else:\n        return 0\ny = y.map(zero_one)","ec982aae":"from sklearn import preprocessing","7b2c74ef":"min_max_scaler = preprocessing.MinMaxScaler()\nX_scale = min_max_scaler.fit_transform(x)\ndeploy_scale = min_max_scaler.fit_transform(deploy)","0d8b139c":"from sklearn.model_selection import train_test_split","697179b3":"X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3)","330602cf":"X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5) ","bd5d452b":"from keras.models import Sequential\nfrom keras.layers import Dense","d7884c92":"model = Sequential([\n    Dense(32, activation='relu', input_shape=(47,)),\n    Dense(32, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(1, activation='sigmoid'),\n])","ab49bc0c":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","42ed5ecd":"model.compile(optimizer='sgd',  #sgd\u2019 refers to stochastic gradient descent (over here, it refers to mini-batch gradient descent),\n              loss='binary_crossentropy', #The loss function for outputs that take the values 1 or 0 is called binary cross entropy.\n              metrics=['accuracy'])  #we want to track accuracy on top of the loss function.","25443404":"result = model.fit(X_train, Y_train,\n          batch_size=47, epochs=200, # these parameters can significantly change your accuracy.\n          validation_data=(X_val, Y_val))","f2bc9a30":"plt.plot(result.history['loss'])\nplt.plot(result.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","f4083fab":"from keras.layers import Dropout\nfrom keras import regularizers","f12de51b":"model_3 = Sequential([\n    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(47,)), # lambda sign\n    Dropout(0.2),\n    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    Dropout(0.2),\n    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)),\n])","4fb261fb":"model_3.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhist_3 = model_3.fit(X_train, Y_train,\n          batch_size=5, epochs=100,\n          validation_data=(X_val, Y_val))","10d4223f":"plt.plot(hist_3.history['loss'])\nplt.plot(hist_3.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.ylim(top=1.2, bottom=0)\nplt.show()","86dce17a":"plt.plot(hist_3.history['accuracy'])\nplt.plot(hist_3.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","ba257c8d":"errors = abs(np.array(hist_3.history['loss']) - np.array(hist_3.history['val_loss']))\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","74687355":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors \/ np.array(hist_3.history['loss']))\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')\npredictions_model_3 = model_3.predict(X_scale)","2c18baff":"from sklearn.metrics import accuracy_score\n\n","8c0fcbe4":"from xgboost import XGBRegressor\n\nmy_model = XGBRegressor()\n# Add silent=True to avoid printing out updates with each cycle\nmy_model.fit(X_train, Y_train, verbose=False)","4ffa6e5f":"# make predictions\npredictions = my_model.predict(X_test)\n\nfrom sklearn.metrics import mean_absolute_error\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, Y_test)))","cf0ef046":"my_model = XGBRegressor(n_estimators=1000)\nmy_model.fit(X_train, Y_train, early_stopping_rounds=5, \n             eval_set=[(X_test, Y_test)], verbose=False)","f4e36580":"print(predictions)","1caa8328":"predictions_y = [round(value) for value in predictions]\nprint(predictions_y)","6602619f":"deploy","d9ba7d6b":"sample = pd.read_csv(f\"{PATH}sample_submition.csv\")\nsample.head()","8157172c":"#sample[\"Category\"] = model.predict(deploy_scale).round().astype(int)\nsample[\"Category\"] = my_model.predict(deploy_scale).round().astype(int)\n\n#sample[\"Category\"] = (sample[\"Category\"]=='like').astype(int)\n","1236bd9a":"sample.to_csv(\"deploy.csv\", index=False)","86edd2dd":"sample.head(20)","c38bc9a1":"# **3.1 Track**","c0fe3833":"# **2.8 Album Type**","7ab67489":"# **2.4 Key**","9192ba4e":"# **2.6 Labels**","468e2610":"# **2.7 Version**","8f8d310b":"# **2.2 Release Year**","7f10431c":"# **3.3 Album**","42301ae6":"# **Actual Test**","e1e42189":"# **4.0 Modell**","beaee06f":"# **3.0 Duration**","e36dbfdc":"# **2.1 Vocals**","9c5f4971":"# XGBOOST","2d9c2468":"# **2.9 Country**","f7b2c681":"# **2.3 Happiness, Energy, Dancebility, BPM**","a017d96f":"# **2.5 Genres**","1e99bd6e":"# **3.2 Artists**"}}