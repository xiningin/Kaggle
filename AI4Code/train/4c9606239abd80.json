{"cell_type":{"1f2b35b9":"code","eac8292a":"code","fba5168e":"code","1130d24e":"code","8a9157bc":"code","1668ea49":"code","ada98706":"code","a3b6c170":"code","dac00f21":"code","df59786e":"code","dd1afae2":"code","216b46bb":"code","b514eae3":"code","18d626e6":"code","b7f07f62":"code","ce5537a1":"code","0bb329f3":"code","97bf2b8b":"code","3c52dfdd":"code","c67e5485":"code","5b1d0b24":"code","52e56e1d":"code","fad8b872":"markdown","2f5ca66f":"markdown","9883ad59":"markdown","7a0dfc72":"markdown","19d141b7":"markdown","c1c773db":"markdown","fd5ae392":"markdown","b4ded77e":"markdown","119937a2":"markdown"},"source":{"1f2b35b9":"import numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","eac8292a":"print(tf.__version__)","fba5168e":"PATH = '\/kaggle\/input\/stanford-dogs-dataset\/images\/Images\/'\nCATEGORIES = os.listdir(PATH)\nNUM_CLASSES = len(CATEGORIES)","1130d24e":"SIZE = 128\nBATCH_SIZE = 32\nEPOCHS = 30","8a9157bc":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=(SIZE,SIZE),\n    batch_size=BATCH_SIZE,\n    class_names=CATEGORIES,\n    label_mode='categorical',\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=(SIZE,SIZE),\n    batch_size=BATCH_SIZE,\n    class_names=CATEGORIES,\n    label_mode='categorical',\n)","1668ea49":"CATEGORIES = [category.split('-')[1] for category in CATEGORIES]\nprint(CATEGORIES)","ada98706":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(CATEGORIES[np.argmax(labels[i])])\n        plt.axis(\"off\")","a3b6c170":"train_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","dac00f21":"def make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n\n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(inputs)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=(SIZE, SIZE) + (3,), num_classes=NUM_CLASSES)","df59786e":"model.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(\n    train_ds, epochs=EPOCHS, validation_data=val_ds,\n)","dd1afae2":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nxepochs = [x for x in range (len(history.history['loss']))]\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy over time\", \"Loss over time\"))\n\nfor metric in ['accuracy', 'val_accuracy']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=1)\n\nfor metric in ['loss', 'val_loss']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=2)\n\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n\nfig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\nfig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n\nfig.show()","216b46bb":"val_samples = sum([y.shape[0] for [_, y] in val_ds])\nval_samples","b514eae3":"y_val = []\ny_val_pred = []\n\nfor images, targets in val_ds:\n    for image, target in zip(images, targets):\n        img_array = image.numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        y_val_pred.append(np.argmax(prediction))\n        y_val.append(np.argmax(target))","18d626e6":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_val, y_val_pred)","b7f07f62":"import plotly.express as px\n\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"Real\"),\n    x=CATEGORIES,\n    y=CATEGORIES\n)\n\nfig.update_layout(autosize=False, width=1300, height=1300)\n\nfig.update_xaxes(side=\"top\")\nfig.show()","ce5537a1":"# from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet import ResNet101\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\n# create the base pre-trained model\n# base_model = ResNet50(weights='imagenet', include_top=False)\nbase_model = ResNet101(weights='imagenet', include_top=False)\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.4)(x)\nx = Dense(1024, activation='relu')(x)\npredictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"],)\n\n# train the model on the new data for a few epochs\nhistory = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)","0bb329f3":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nxepochs = [x for x in range (len(history.history['loss']))]\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy over time\", \"Loss over time\"))\n\nfor metric in ['accuracy', 'val_accuracy']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=1)\n\nfor metric in ['loss', 'val_loss']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=2)\n\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n\nfig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\nfig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n\nfig.show()","97bf2b8b":"val_samples = sum([y.shape[0] for [_, y] in val_ds])\nval_samples","3c52dfdd":"y_val = []\ny_val_pred = []\n\nfor images, targets in val_ds:\n    for image, target in zip(images, targets):\n        img_array = image.numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        y_val_pred.append(np.argmax(prediction))\n        y_val.append(np.argmax(target))","c67e5485":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_val, y_val_pred)","5b1d0b24":"import plotly.express as px\n\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"Real\"),\n    x=CATEGORIES,\n    y=CATEGORIES\n)\n\nfig.update_layout(autosize=False, width=1300, height=1300)\n\nfig.update_xaxes(side=\"top\")\nfig.show()","52e56e1d":"plt.figure(figsize=(20, 10))\nfor images, labels in val_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        \n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        prediction_name = CATEGORIES[np.argmax(prediction)]\n        real_name = CATEGORIES[np.argmax(labels[i])]\n        \n        plt.imshow(img_array)\n        if prediction_name == real_name:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'g'})\n        else:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'r'})\n        \n        plt.axis(\"off\")","fad8b872":"## History","2f5ca66f":"## Confusion Matrix","9883ad59":"# Predictions","7a0dfc72":"# B. Transfer Learning: ResNet101 with ImageNet weights","19d141b7":"## Training","c1c773db":"## History","fd5ae392":"# Load data","b4ded77e":"# Confusion Matrix","119937a2":"# A. Convolutional Neural Network (XCeption)"}}