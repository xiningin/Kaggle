{"cell_type":{"5810fc08":"code","94837842":"code","f5960095":"code","120429df":"code","883dcb16":"code","7bdb69a4":"code","ed048fff":"code","d3388058":"code","7adaed45":"code","42858035":"code","9118c8b5":"code","3b010ef7":"code","12ebbe2a":"code","82dfd998":"code","0517fa83":"code","ba9d7e79":"code","2150eea1":"code","b4c37d4c":"code","573bbdb1":"code","68414b48":"code","ee279711":"code","71abf943":"code","d20ad36f":"code","d41c5281":"code","0199d897":"code","b0efbd59":"markdown","f282d157":"markdown","10e9523a":"markdown","0dba6099":"markdown","bfb31748":"markdown","6650fae9":"markdown","ce0e1621":"markdown","ba020dc7":"markdown","7b14688c":"markdown","1549b31d":"markdown","5a208c25":"markdown","463312d7":"markdown","6a3262b5":"markdown","cdba303f":"markdown","28e776d0":"markdown","b8062d4c":"markdown"},"source":{"5810fc08":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","94837842":"# helper function\ndef table_style(value):\n    if value > 0.5:\n        style = 'background-color: mediumseagreen'\n    else:\n        style = 'background-color: indianred'\n    return style","f5960095":"# reading files\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","120429df":"# columns list\ntrain.columns","883dcb16":"# first 5 rows of the train dataset\ntrain.head()","7bdb69a4":"# number of non-nulls in the train dataset\ntrain.info()","ed048fff":"# number of non-nulls in the test dataset\ntest.info()","d3388058":"# count of values\nfor i in train[['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']].columns:\n    print('\\n')\n    print(train[[i]].value_counts())","7adaed45":"# female x male\npd.pivot_table(train, values='Survived', index=['Sex']).style.applymap(table_style)","42858035":"plt.figure(figsize=(6, 5))\nsns.kdeplot(data=train, x='Age', hue='Survived', shade=True).set_title('Survived by Age');","9118c8b5":"plt.figure(figsize=(8, 6))\nsns.swarmplot(x='Sex', y='Age', hue='Survived', data=train).set_title('Survived by Sex and Age');","3b010ef7":"# female x male, per passenger class\npd.pivot_table(train, values='Survived', index=['Pclass'], columns='Sex').style.applymap(table_style)","12ebbe2a":"# female x male, per passenger class and port of embark\npd.pivot_table(train, values='Survived', index=['Embarked', 'Pclass'], columns='Sex').style.applymap(table_style)","82dfd998":"# female x male, per number of parents and children\npd.pivot_table(train, values='Survived', index=['Parch'], columns='Sex').style.applymap(table_style)","0517fa83":"# female x male, per number of siblings and spouses\npd.pivot_table(train, values='Survived', index=['SibSp'], columns='Sex').style.applymap(table_style)","ba9d7e79":"# dropping the two rows with null values in Embarked\ntrain.dropna(subset=['Embarked'], inplace=True)","2150eea1":"# creating a column that indicates if a passenger is male and young (Master title)\ntrain['Boy'] = (train.Name.str.split().str[1] == 'Master.').astype('int')\ntest['Boy'] = (test.Name.str.split().str[1] == 'Master.').astype('int')\n\n# creating a column that represents the total number of relatives onboard\ntrain['FamilySize'] = train['SibSp'] + train['Parch']\ntest['FamilySize'] = test['SibSp'] + test['Parch']","b4c37d4c":"# creating dummies for the categorical features\ntrain = pd.get_dummies(train, columns=['Sex', 'Embarked'])\ntest = pd.get_dummies(test, columns=['Sex', 'Embarked'])","573bbdb1":"# list of columns\ntrain.columns","68414b48":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(\n    train[['Boy', 'FamilySize', 'Sex_female', 'Pclass', 'Embarked_Q', 'Embarked_S']],\n    train[['Survived']],\n    test_size=0.2,\n    random_state=42)","ee279711":"# algorithms that will be tested\nclassifier = [\n    SVC(gamma='auto', probability=True),\n    RandomForestClassifier(n_estimators=200, max_depth=5),\n    LogisticRegression(),\n    KNeighborsClassifier(),\n    XGBClassifier(n_estimators=200, learning_rate=0.02, verbosity=0)]\n\n# SVC parameters\nsvc_param_grid = [\n    {'kernel': ['rbf'], 'C': [0.1, 0.5, 1, 1.5, 2, 3]},\n    {'kernel': ['linear'], 'C': [0.1, 0.5, 1, 1.5, 2, 3]},\n    {'kernel': ['poly'], 'degree': [2, 3, 4, 5], 'C': [0.1, 0.5, 1, 1.5, 2, 3]}]\n\n# Random Forest parameters\nrf_param_grid = {\n    'min_samples_split': [2, 3, 4],\n    'min_samples_leaf': [1, 2, 3]}\n\n# Logistic Regression parameters\nlr_param_grid = {\n    'C': np.logspace(-1, 3, 20),\n    'solver': ['liblinear', 'lbfgs']}\n\n# KNN parameters\nknn_param_grid = {\n    'n_neighbors': [3, 5, 7, 9],\n    'weights': ['uniform', 'distance'],\n    'metric': ['euclidean', 'manhattan', 'minkowski']}\n\n# XGB parameters\nxgb_param_grid = {\n    'gamma': [0.01, 0.1, 1],\n    'reg_alpha': [0.01, 0.1, 1],\n    'reg_lambda': [0.1, 1, 2]}\n\n# all parameters\nclassifier_param = [\n    svc_param_grid,\n    rf_param_grid,\n    lr_param_grid,\n    knn_param_grid,\n    xgb_param_grid]","71abf943":"# the results of the cross validation will be stored here\ncv_result = []\n# the best estimator of each algorithm will be stored here\nbest_estimators = []\n# algorithm names\nalg_names = ['SVC', 'Random Forest', 'Logistic Regression', 'KNN', 'XGB']\n\n# cross validation with the different parameters (printing training accuracy)\nfor i in range(len(classifier)):\n    clf = GridSearchCV(\n        classifier[i],\n        param_grid=classifier_param[i],\n        cv=StratifiedKFold(n_splits=5),\n        scoring='accuracy',\n        n_jobs=-1)\n    clf.fit(X_train, y_train.values.ravel())\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(alg_names[i] + ' accuracy:', cv_result[i])","d20ad36f":"# creating a voting classifier\nvoting = VotingClassifier(\n    estimators=[('svc', best_estimators[0]),\n                ('rf', best_estimators[1]),\n                ('lr', best_estimators[2]),\n                ('knn', best_estimators[3]),\n                ('xgb', best_estimators[4])],\n    voting='soft')\n\n# fitting the votes model (printing test accuracy)\nvoting = voting.fit(X_train, y_train.values.ravel())\nprint('Voting Classifier accuracy:',accuracy_score(voting.predict(X_test), y_test))","d41c5281":"# fitting the votes model to the entire train dataset\nvoting = voting.fit(\n    train[['Boy', 'FamilySize', 'Sex_female', 'Pclass', 'Embarked_Q', 'Embarked_S']],\n    train[['Survived']].values.ravel())\n\n# applying the voting classifier to the test dataset\npred = pd.Series(\n    voting.predict(test[['Boy', 'FamilySize', 'Sex_female', 'Pclass', 'Embarked_Q', 'Embarked_S']]),\n    name='Survived').astype(int)","0199d897":"# creating the submission file with the results\nsubmission = pd.concat([test['PassengerId'], pd.DataFrame(pred, columns=['Survived'])], axis=1)\nsubmission.to_csv('titanic.csv', index=False)","b0efbd59":"### **Missings**","f282d157":"## **2. Exploratory data analysis**","10e9523a":"### **Survival rates**","0dba6099":"### **Considerations**\nFemales have a much higher chance to survive.\n\nAge is important to determine the faith of a passenger. Kids have a higher survival rate, but the Age column has a lot of nulls. Instead of Age, it will be used the title Master from the Name to determine whether a man is young or not. It's not as important to determine if a woman is young, because they have a much higher survival rate anyway.\n\nCabin also has a lot of nulls. To reduce correlation, only one between Cabin, Ticket, Fare and Pclass will be used in the model, given that they are somewhat related. Pclass is going to be chosen because it's already well divided in three categories.\n\nFemale passengers from third class have a lower survival rate, as well as males from second and third.\n\nWoman from third class that embarked in Southampton have a much lower survival rate compared to others. And almost no man that embarked in Queenstown survived.\n\nPassengers traveling with larger families have a lower chance to survive.","bfb31748":"## **1. Introduction**\nIn 1912, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, some groups of people were more likely to survive than others.\n\nIn this notebook, I will build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (i.e. name, age, gender, socio-economic class, etc).","6650fae9":"### **Voting classifier**\nA voting classifier makes a prediction based on the average result of an ensemble of models.","ce0e1621":"> Content:\n> 1. Introduction\n> 2. Exploratory data analysis\n> 3. Pre-processing\n> 4. Model\n> 5. Submission","ba020dc7":"## **4. Model**","7b14688c":"## **Titanic Prediction**\nUsing machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","1549b31d":"### **Dummies**\nSome Machine Learning algorithms require transforming categorical attributes into numerical ones. Get_dummies creates a binary attribute for each unique value of the original attribute, but it is not necessary to use them all in the model. For example, if we know that [1, 0] represents male, we don't need another binary variable [0, 1] to represent female. We can use [1] for male and [0] for female.","5a208c25":"### **Feature Engineering**","463312d7":"Columns:\n* PassengerId: Passenger Id number.\n* Survived: Passenger survived (1) or not (0).\n* Pclass: Ticket class.\n* Name: Name and title.\n* Sex: Sex.\n* Age: Age in years.\n* SibSp: Number of siblings and spouses aboard the Titanic.\n* Parch: Number of parents and children aboard the Titanic.\n* Ticket: Ticket number.\n* Fare: Amount of money spent on ticket.\n* Cabin: Cabin number.\n* Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).","6a3262b5":"### **Prediction**","cdba303f":"## **5. Submission**","28e776d0":"## **3. Pre-processing**","b8062d4c":"Notice that the test accuracy was similar to the training accuracies, this indicates that there was no overfitting."}}