{"cell_type":{"5d5afd11":"code","6453d175":"code","98e531a6":"code","59ab03a8":"code","d70cce8d":"code","f0602cb9":"code","c12614f9":"code","79efd76e":"code","76504c80":"code","f499d7fc":"code","7283eace":"code","d38b9582":"markdown","83e03d05":"markdown","8e14b419":"markdown","e643f607":"markdown","eec32bfd":"markdown","2a4ca9c6":"markdown"},"source":{"5d5afd11":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow.keras as tf\nimport cv2\nfrom ast import literal_eval\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nimport glob\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6453d175":"def imreadandresffold(path, fileextension, sizeh, sizew, operation):\n  if operation is 'all':\n    imdata= np.stack([cv2.resize(cv2.imread(file)\/np.max(cv2.imread(file)), (sizeh,sizew), interpolation = cv2.INTER_NEAREST) for file in glob.glob(path + '*.' + fileextension)])\n  else:\n    imdata= np.stack([cv2.resize(cv2.imread(file)\/np.max(cv2.imread(file)), (sizeh,sizew), interpolation = cv2.INTER_NEAREST) for file in glob.glob(path + operation + '.' + fileextension)])\n  return imdata","98e531a6":"\npath = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/'\npathpne = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/'\nimdatanorm = imreadandresffold(path, 'jpeg', 128, 128, 'all')\nimdatapne_bac = imreadandresffold(pathpne, 'jpeg', 128, 128, 'person*_bacteria_*')\nimdatapne_vir = imreadandresffold(pathpne, 'jpeg', 128, 128, 'person*_virus_*')","59ab03a8":"imdatapne_vir.shape","d70cce8d":"plt.imshow(imdatapne_vir[0,...])","f0602cb9":"trainingdata = np.concatenate([imdatanorm, imdatapne_bac, imdatapne_vir])\nlabel = np.zeros((trainingdata.shape[0],3))\nlabel[0:imdatanorm.shape[0],0] = 1\nlabel[imdatanorm.shape[0]:(imdatanorm.shape[0]+imdatapne_bac.shape[0]),1] = 1\nlabel[(imdatanorm.shape[0]+imdatapne_bac.shape[0]):trainingdata.shape[0],2] = 1","c12614f9":"indexes = np.arange(trainingdata.shape[0])\nnp.random.shuffle(indexes)\ntrainindatashuff = trainingdata[indexes,...]\nlabelshuff = label[indexes]\nlabelshuff = labelshuff.astype(int)","79efd76e":"input_layer = tf.Input(shape=(128, 128, 3))\n\nx = tf.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(input_layer)\n#x = tf.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\nx = tf.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\nx = tf.layers.Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='relu')(x)\nx = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\n#x = tf.layers.MaxPool2D((2, 2), padding='same', strides=(1, 1))(x)\n#x = tf.layers.Lambda(lambda x: x**2)(x)\nx = tf.layers.Flatten()(x)\nx = tf.layers.Dense(128, activation='relu')(x)\nx = tf.layers.Dense(128, activation='relu')(x)\nx = tf.layers.Dense(3)(x)\n","76504c80":"initial_learning_rate = 0.01\nlr_schedule = tf.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10,\n    decay_rate=0.96,\n    staircase=True)\n# you can use lr_schedule if you want your learning rate to decay, but I am not using it right now \nmodel = tf.Model(input_layer, x)\n#losse = tf.losses.mse()\nmodel.compile(loss='mse', optimizer=tf.optimizers.Adam())\nmodel.fit(trainindatashuff[0:1000,...], labelshuff[0:1000,...], batch_size=50, epochs=10)","f499d7fc":"veri = trainindatashuff[1000:1500,...]\nveri = veri.reshape(500,128,128,3)\npredictions = model.predict(veri)","7283eace":"accuracy_score(np.argmax(predictions,axis=1),np.argmax(labelshuff[1000:1500,...],axis=1))","d38b9582":"Here we concataneta all images we read from above and we create label variable depending on their properties like normal or pneuomina with bacteria or virus","83e03d05":"Here we shuffle all the trainingdata and label exactly in the same way ","8e14b419":"Our Deep Learning Architecture part, you can change it or add your own design. ","e643f607":"## Here we import necessary libraries","eec32bfd":"This function reads either all images as operation='all' or specific bash format of the image names like operation = 'bla\\*\\_bacteria_*'. sizeh and sizew are the desired resized value of height and width of images  \n","2a4ca9c6":"specification of paths, which are from my colab directories. You can find the use of function here"}}