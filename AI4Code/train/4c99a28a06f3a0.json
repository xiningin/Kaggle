{"cell_type":{"9e583817":"code","d3bf9ae6":"code","4aa496c0":"code","22b63579":"code","bc2707fb":"code","b98a522c":"code","8966e575":"code","a6e44199":"code","0a9428ab":"code","9cd87f30":"code","2fc65d59":"code","7b0cab93":"code","727c6efe":"code","96835b15":"code","071817ff":"code","2a9aa298":"code","f79dceee":"markdown","8db41d81":"markdown"},"source":{"9e583817":"import warnings\nwarnings.filterwarnings('ignore')","d3bf9ae6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4aa496c0":"penguins_data = pd.read_csv('..\/input\/palmer-penguins-datasetalternative-iris-dataset\/penguins.csv')\npenguins_data.head()","22b63579":"penguins_data.info()","bc2707fb":"penguins_data.species.value_counts()","b98a522c":"penguins_data.isnull().sum()","8966e575":"for column_name in penguins_data.select_dtypes(include='float',exclude='object'):\n  penguins_data.loc[:,column_name].fillna(penguins_data.loc[:,column_name].mean(),axis=0,inplace=True)","a6e44199":"penguins_data.sex.fillna(method ='ffill', inplace = True)","0a9428ab":"sns.scatterplot(x='bill_length_mm',y='bill_depth_mm',hue='species',data=penguins_data,style='species');","9cd87f30":"from sklearn.preprocessing import LabelEncoder\n\nfor col in penguins_data[['sex','island']]:\n  penguins_data[col] = LabelEncoder().fit_transform(penguins_data[col])","2fc65d59":"from sklearn.preprocessing import StandardScaler\n\nfor col in penguins_data[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]:\n  penguins_data[col] = StandardScaler().fit_transform(penguins_data[[col]])","7b0cab93":"from sklearn.decomposition import PCA\n\nX = penguins_data.drop('species',axis=1)\nY = penguins_data['species']\n\nPCA_TR = PCA(n_components=3)\nX_train = PCA_TR.fit_transform(X)\n","727c6efe":"PCA_TR.explained_variance_ratio_","96835b15":"PCA_TR.components_","071817ff":"pd.DataFrame(PCA_TR.components_,columns=X.columns,index = ['PC-1','PC-2','PC-3'])","2a9aa298":"from sklearn.model_selection import StratifiedKFold,cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nLRM = LogisticRegression()\nDTC = DecisionTreeClassifier()\nRFC = RandomForestClassifier()\nKNC = KNeighborsClassifier()\nNBC = GaussianNB()\n\nSKF = StratifiedKFold(n_splits = 10, shuffle =True, random_state=10)\n\nprint(f'LogisticRegression : {round(cross_val_score(LRM,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\nprint(f'DecisionTreeClassifier : {round(cross_val_score(DTC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\nprint(f'RandomForestClassifier : {round(cross_val_score(RFC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\nprint(f'KNeighborsClassifier : {round(cross_val_score(KNC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\nprint(f'GaussianNB : {round(cross_val_score(NBC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')","f79dceee":"**'explained_variance_ratio_'** gives percentage of weighted new features that impact label","8db41d81":"# PCA\n\nPCA(Principle Component Analysis) is dimensionality reduction technique that helps in extracting only useful features from datasets by minizing information loss. This helps in model execution as ML model only have those features that impact labels.<br>\n\n\n![](https:\/\/drive.google.com\/uc?export=view&id=1ZDrpBQPKztR1Kc4FOrhPopzK2qWvBXkV)"}}