{"cell_type":{"afff6a59":"code","8be834ee":"code","8e00d72e":"code","e61fa780":"code","81e2b2a0":"code","afcce0e3":"code","b1ef401a":"code","f9af80f4":"code","477c2cb1":"code","ca97bb38":"code","29dc42f2":"code","50da1b79":"code","41166981":"code","98a8b117":"markdown","677cfa5d":"markdown","67a87bfe":"markdown"},"source":{"afff6a59":"from tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))\n\nsns.set_style({'xtick.bottom':False,\n               'ytick.left':False,\n               'axes.spines.bottom': False,\n               'axes.spines.left': False,\n               'axes.spines.right': False,\n               'axes.spines.top': False})","8be834ee":"im_list = [162+i for i in range(9)]\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15,15))\nfor i in enumerate(im_list):\n    img = plt.imread(\"..\/input\/cell_images\/cell_images\/Parasitized\/C100P61ThinF_IMG_20150918_144104_cell_\"+str(i[1])+\".png\")\n    ax=axes[i[0]\/\/3,i[0]%3]\n    ax.imshow(img)           ","8e00d72e":"fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,15))\nimg1 = plt.imread(\"..\/input\/cell_images\/cell_images\/Uninfected\/C100P61ThinF_IMG_20150918_144104_cell_128.png\")\nimg2 = plt.imread(\"..\/input\/cell_images\/cell_images\/Uninfected\/C100P61ThinF_IMG_20150918_144104_cell_131.png\")\nimg3 = plt.imread(\"..\/input\/cell_images\/cell_images\/Uninfected\/C100P61ThinF_IMG_20150918_144104_cell_21.png\")\nimg4 = plt.imread(\"..\/input\/cell_images\/cell_images\/Uninfected\/C100P61ThinF_IMG_20150918_144104_cell_34.png\")\n\nax = axes[0,0]\nax1 = axes[0,1]\nax2 = axes[1,0]\nax3 = axes[1,1]\n\nax.imshow(img1)\nax1.imshow(img2)\nax2.imshow(img3)\nax3.imshow(img4)       ","e61fa780":"datagen = ImageDataGenerator(rescale=1.\/255,\n                                      zoom_range=0.2,\n                                      horizontal_flip=True,\n                                      vertical_flip=True,\n                                      width_shift_range=0.2,\n                                      height_shift_range=0.2,\n                                      validation_split=0.2)\ntrain_data = datagen.flow_from_directory('..\/input\/cell_images\/cell_images',\n                                                     target_size=(128,128),\n                                                     batch_size=32,\n                                                     class_mode = 'binary',\n                                                     subset = 'training')\n\nvalidation_data = datagen.flow_from_directory('..\/input\/cell_images\/cell_images',\n                                                     target_size=(128,128),\n                                                     batch_size=32,\n                                                     class_mode = 'binary',\n                                                     subset = 'validation')","81e2b2a0":"accuracies_ =[]\n\ndef train(train_data,validation_data,optimizer,name,epochs=30):\n    classifier = Sequential([Conv2D(16,(3,3),input_shape=(128,128,3),activation='relu'),\n                        MaxPool2D(2,2),\n                        #2nd conv\n                        Conv2D(32,(3,3),activation='relu'),\n                        MaxPool2D(2,2),\n                        #Dropout(0.1),\n                        #3rd conv\n                        Conv2D(64,(3,3),activation='relu'),\n                        MaxPool2D(2,2),\n                        #Dropout(0.1),\n                        #4th conv\n                        Conv2D(128,(3,3),activation='relu'),\n                        MaxPool2D(2,2),\n                        #Dropout(0.1),\n                        \n                        Flatten(),\n                        Dense(1024,activation='relu'),\n                        Dropout(0.2),\n                        Dense(512,activation='relu'),\n                        Dense(1,activation='sigmoid')])\n\n    classifier.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    \n    accuracies = classifier.fit(train_data,\n                         steps_per_epoch = 100,\n                         epochs = epochs,\n                         validation_data=validation_data,\n                         validation_steps = 10,\n                         verbose=1)\n    \n    acc = pd.DataFrame.from_dict(accuracies.history)\n    acc = pd.concat([pd.Series(range(0,30),name='epochs'),acc],axis=1)\n    \n    fig,(ax,ax1) = plt.subplots(nrows=2,ncols=1,figsize=(16,16))\n    sns.lineplot(x='epochs',y='acc',data=acc,ax=ax,color='m')\n    sns.lineplot(x='epochs',y='val_acc',data=acc,ax=ax,color='c')\n    sns.lineplot(x='epochs',y='loss',data=acc,ax=ax1,color='m')\n    sns.lineplot(x='epochs',y='val_loss',data=acc,ax=ax1,color='c')\n    ax.legend(labels=['Test Accuracy','Training Accuracy'])\n    ax1.legend(labels=['Test Loss','Training Loss'])\n    plt.show()\n    \n    accuracies_.append((name,(\"Validation Accuracy\",accuracies.history['val_acc'][epochs-1]),(\"Training Accuracy\",accuracies.history['acc'][epochs-1])))\n    \n    return classifier","afcce0e3":"from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n#Adam\n\n\nadam_classifier = train(train_data,validation_data,Adam(),name='Adam',epochs=40)","b1ef401a":"# SGD\n\nsgd_classifier = train(train_data,validation_data,SGD(nesterov=True,momentum=0.02),name=\"SGD\",epochs=40)\n","f9af80f4":"#RMSprop\n\nrms_classifier = train(train_data,validation_data,RMSprop(),name=\"RMSprop\",epochs=40)","477c2cb1":"accuracies_","ca97bb38":"test_img = validation_data[0][0][0]","29dc42f2":"plt.imshow(test_img)","50da1b79":"validation_data[0][1]","41166981":"(rms_classifier.predict_classes(validation_data[0][0]))","98a8b117":"We got the better results using RMSprop optimizer","677cfa5d":"**UnInfected Image**","67a87bfe":"**Infected Images**"}}