{"cell_type":{"69776458":"code","6c32579c":"code","94d5aac2":"code","4ea86449":"code","a847794d":"code","9cdb4eaf":"code","d964ce2d":"code","15784ebb":"code","8b930a11":"code","d717ab61":"code","a3517279":"code","1488c10c":"code","73c61871":"code","f8f1ef4a":"code","75a094c4":"code","7e107c28":"code","387ea4f3":"code","9b811bcf":"code","037135f5":"code","a6ba8cdd":"code","db0d95a3":"code","41973c0f":"code","8f266fc1":"code","73856733":"code","dd656fde":"code","cb718b53":"code","1358f414":"code","b7301d75":"code","d3a251c6":"code","73ed4e82":"code","72776e9d":"code","468d7314":"code","0783e935":"code","6caba470":"code","dbcc79bb":"code","3b438647":"code","90492178":"code","e7ffd60f":"code","d840a056":"code","d667d6b8":"code","aba7b8eb":"code","40b4d094":"code","3afe6bf2":"code","fc7e8432":"code","6bf50e51":"code","4c51c8a0":"code","cd296508":"code","0c1416a2":"code","f616b291":"markdown","3c0677e7":"markdown","b40c621f":"markdown","3de18ce1":"markdown","742bf588":"markdown","d5c8fab0":"markdown","39b1991f":"markdown","d02df4e3":"markdown","18ba8ab8":"markdown","72f93aaf":"markdown","a593bde6":"markdown","db27eb63":"markdown","972e2090":"markdown","fede390e":"markdown"},"source":{"69776458":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c32579c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.style as style\n\nimport random\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport time\n\npd.options.display.max_columns = None","94d5aac2":"train = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntest = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\n\ntargets = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntargets_non = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\n\ntrain['dataset'] = 'train'\ntest['dataset'] = 'test'\n\nsample_submit = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')\n\nall_data = pd.concat([train, test])","4ea86449":"train.head()","a847794d":"test.head()","9cdb4eaf":"print('Number of rows in training set: ', train.shape[0])\nprint('Number of columns in training set: ', train.shape[1] - 1) # \u8ffd\u52a0\u3057\u305fdataset\u306e\u5206\u629c\u3044\u3066\u304a\u304f\n\nprint('')\n\nprint('Number of rows in test set: ', test.shape[0])\nprint('Number of columns in test set: ', test.shape[1] - 1) # \u8ffd\u52a0\u3057\u305fdataset\u306e\u5206\u629c\u3044\u3066\u304a\u304f","d964ce2d":"all_data.info()","15784ebb":"targets.head()","8b930a11":"targets_non.head()","d717ab61":"# \u63d0\u51fa\u3059\u308b\u30b5\u30f3\u30d7\u30eb\nsample_submit.head()","a3517279":"print('Number of rows in targets-data set: ', targets.shape[0])\nprint('Number of columns in targets-data set: ', targets.shape[1])","1488c10c":"# \u6b20\u640d\u5024\n\n# ----train-----\nmissing_train = train.isnull().sum()\nmissing_train = missing_train[missing_train > 0]\nmissing_train.sort_values(inplace=True)\n\n# ----test-----\nmissing_test = test.isnull().sum()\nmissing_test = missing_test[missing_test > 0]\nmissing_test.sort_values(inplace=True)\n\n# ----targets-----\nmissing_targets = targets.isnull().sum()\nmissing_targets = missing_targets[missing_targets > 0]\nmissing_targets.sort_values(inplace=True)","73c61871":"missing_train","f8f1ef4a":"missing_test","75a094c4":"missing_targets","7e107c28":"dataSet = all_data.groupby(['cp_type', 'dataset'])['sig_id'].count().reset_index()\ndataSet","387ea4f3":"dataSet.columns = ['cp_type', 'dataset', 'count']\ndataSet","9b811bcf":"fig = px.bar(\n    dataSet, \n    x='cp_type', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_type train\/test counts', \n    width=500,\n    height=400\n)\n\nfig.show()","037135f5":"dataSet = all_data.groupby(['cp_time', 'dataset'])['sig_id'].count().reset_index()\ndataSet","a6ba8cdd":"dataSet.columns = ['cp_time', 'dataset', 'count']\ndataSet","db0d95a3":"fig = px.bar(\n    dataSet, \n    x='cp_time', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_time train\/test counts', \n    width=500,\n    height=400\n)\n\nfig.show()","41973c0f":"dataSet = all_data.groupby(['cp_dose', 'dataset'])['sig_id'].count().reset_index()\ndataSet.columns = ['cp_dose', 'dataset', 'count']\n\nfig = px.bar(\n    dataSet, \n    x='cp_dose', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_dose train\/test counts', \n    width=500,\n    height=400\n)\n\nfig.show()","8f266fc1":"train_columns = train.columns.to_list()\ng_list = [column for column in train.columns if column.startswith('g-')]\nc_list = [column for column in train.columns if column.startswith('c-')]","73856733":"def plot_set_histograms(plot_list, title):\n    fig = make_subplots(rows=4, cols=3)\n    traces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in plot_list]\n\n    for i in range(len(traces)):\n        fig.append_trace(traces[i], (i \/\/ 3) + 1, (i % 3) + 1)\n\n    fig.update_layout(\n        title_text=title,\n        height=1000,\n        width=1000\n    )\n    fig.show()","dd656fde":"# gene features\nplot_list = [g_list[random.randint(0, len(g_list)-1)] for i in range(50)]\nplot_list = list(set(plot_list))[:12]\nplot_set_histograms(plot_list, 'Randomly selected gene expression features distributions')","cb718b53":"# cell feature\nplot_list = [c_list[random.randint(0, len(c_list)-1)] for i in range(50)]\nplot_list = list(set(plot_list))[:12]\nplot_set_histograms(plot_list, 'Randomly selected cell expression features distributions')","1358f414":"columns = g_list + c_list","b7301d75":"corrmat = train[columns].corr()\nf, ax = plt.subplots(figsize=(14,14))\nsns.heatmap(corrmat, square=True, vmax=.8);","d3a251c6":"# \u30e9\u30f3\u30c0\u30e0\nfor_correlation = list(set([columns[random.randint(0, len(columns)-1)] for i in range(200)]))[:40]\ndata = all_data[for_correlation]\n\nf = plt.figure(figsize=(19, 17))\nplt.matshow(data.corr(), fignum=f.number)\nplt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=50)\nplt.yticks(range(data.shape[1]), data.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=13)","73ed4e82":"cols = ['cp_time'] + columns # columns = g_list + c_list\nall_columns = []\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(train[cols[i]].corr(train[cols[j]])) > 0.9:\n            all_columns.append(cols[i])\n            all_columns.append(cols[j])","72776e9d":"all_columns = list(set(all_columns)) # \u91cd\u8907\u3059\u308b\u8981\u7d20\u304c\u9664\u5916\u3055\u308c\u3066\u4e00\u610f\u306a\u5024\u306e\u307f\u304c\u8981\u7d20\u3068\u306a\u308bset\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u751f\u6210\nprint('Number of columns: ', len(all_columns))","468d7314":"all_columns","0783e935":"# \u76f8\u95a2\u306e\u9ad8\u3044\u30da\u30a2\u540c\u58eb\u306e\u30d2\u30fc\u30c8\u30de\u30c3\u30d7\u56f3\ndata = all_data[all_columns]\n\nf = plt.figure(figsize=(19, 15))\nplt.matshow(data.corr(), fignum=f.number)\nplt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=50)\nplt.yticks(range(data.shape[1]), data.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","6caba470":"fig = make_subplots(rows=12, cols=3)\ntraces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in all_columns]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i \/\/ 3) + 1, (i % 3) + 1)\n\nfig.update_layout(\n    title_text='Highly correlated features',\n    height=1200\n)\nfig.show()","dbcc79bb":"print('Number of rows : ', targets.shape[0])\nprint('Number of cols : ', targets.shape[1])\n\ntargets.head()","3b438647":"# \u964d\u9806\nx = targets.drop(['sig_id'], axis=1).sum(axis=0).sort_values().reset_index()\nx.columns = ['column', 'nonzero_records']\nx","90492178":"# \u51fa\u73fe\u7387\u306e\u9ad8\u3044\u9806\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns with the higher number of positive samples (top 50)', \n    height=1000, \n    width=800\n)\n\nfig.show();","e7ffd60f":"# \u6607\u9806\nx = targets.drop(['sig_id'], axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['column', 'nonzero_records']\n\n# \u51fa\u73fe\u7387\u306e\u4f4e\u3044\u9806\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns with the lowest number of positive samples (top 50)', \n    height=1000, \n    width=800\n)\n\nfig.show();","d840a056":"x = targets.drop(['sig_id'], axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['column', 'count']\nx['count'] = x['count'] * 100 \/ len(targets)\n\nfig = px.bar(\n    x, \n    x='column', \n    y='count', \n    orientation='v', \n    title='Percent of positive records for every column in target', \n    height=800, \n    width=1200\n)\n\nfig.show()","d667d6b8":"# data\u3000207\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u3046\u3061\u3001\u4f55\u500b1\u304c\u3042\u308b\u304b\ndata = targets.drop(['sig_id'], axis=1).astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()","aba7b8eb":"data","40b4d094":"fig = px.bar(\n    data, \n    y=data['row'], \n    x=\"count\", \n    title='Number of activations in targets for every sample', \n    width=800, \n    height=500\n)\n\nfig.show()","3afe6bf2":"targets.describe()","fc7e8432":"correlation_matrix = pd.DataFrame()\nfor t_col in targets.columns:\n    corr_list = list()\n    if t_col == 'sig_id':\n        continue\n        \n        # columns = g_list + c_list\n    for col in columns:\n        res = train[col].corr(targets[t_col])\n        corr_list.append(res)\n    correlation_matrix[t_col] = corr_list","6bf50e51":"correlation_matrix['train_features'] = columns\ncorrelation_matrix = correlation_matrix.set_index('train_features')\ncorrelation_matrix","4c51c8a0":"maxCol=lambda x: max(x.min(), x.max(), key=abs)\nhigh_scores = correlation_matrix.apply(maxCol, axis=0).reset_index()\nhigh_scores.columns = ['column', 'best_correlation']\n\nfig = px.bar(\n    high_scores, \n    x='column', \n    y=\"best_correlation\", \n    orientation='v', \n    title='Best correlation with train columns for every target column', \n    width=1200,\n    height=800\n)\n\nfig.show()","cd296508":"col_df = pd.DataFrame()\ntr_cols = list()\ntar_cols = list()\nfor col in correlation_matrix.columns:\n    tar_cols.append(col)\n    tr_cols.append(correlation_matrix[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(1).values[0])\n\ncol_df['column'] = tar_cols\ncol_df['train_best_column'] = tr_cols\n\ntotal_scores = pd.merge(high_scores, col_df)\ntotal_scores","0c1416a2":"count_features = total_scores['train_best_column'].value_counts().reset_index().sort_values('train_best_column')\ncount_features.columns = ['column', 'count']\nfig = px.bar(\n    count_features.tail(33), \n    x='count', \n    y=\"column\", \n    orientation='h', \n    title='Columns from training set with number of high correlations with target columns', \n    width=800,\n    height=700\n)\n\nfig.show()","f616b291":"### \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306b\u3064\u3044\u3066\n* cp-type \u30fb\u30fb\u30fb ctl_vehicle < trt_cp\n* cp-time \u30fb\u30fb\u30fb 24 = 48 = 72 (\u307b\u307c)\n* cp-dose \u30fb\u30fb\u30fb D1 = D2 (\u307b\u307c)","3c0677e7":"#### cp-type feature (EDA)","b40c621f":"### \u5168\u4f53\u306e\u30c7\u30fc\u30bf\u578b\n* 872 float features\n* 1 integer (cp_time)\n* 3 categorical (sig_id, cp_type and cp_dose)","3de18ce1":"\u6700\u3082\u591a\u304f\u51fa\u73fe\u3059\u308b\u7279\u5fb4\u91cf(target)\u3067\u3055\u3048\u30013.5%","742bf588":"#### train features correlation","d5c8fab0":"#### targets analysis \u76ee\u7684\u5909\u6570","39b1991f":"#### Time to find pairs of features with high correlation. \u76f8\u95a2\u306e\u9ad8\u3044\u5909\u6570\u306e\u30da\u30a2\u3092\u898b\u3064\u3051\u308b","d02df4e3":"### DataSet\u306e\u4e2d\u8eab\n* sig_id\n\n* cp_type  # \u5316\u5408\u7269\u30b5\u30f3\u30d7\u30eb or \u5236\u5fa1\u6442\u52d5\u3055\u308c\u305f\u30b5\u30f3\u30d7\u30eb\n * trt_cp: samples treated with a compound \u5316\u5408\u7269\u3067\u51e6\u7406\u3055\u308c\u305f\u30b5\u30f3\u30d7\u30eb\n * ctl_vehicle: samples treated with a control perturbation \u5bfe\u7167\u6442\u52d5\u3067\u51e6\u7406\u3055\u308c\u305f\u30b5\u30f3\u30d7\u30eb\n\n* cp_time # treatment duration \u6cbb\u7642\u671f\u9593\n\n* cp_dose # treatment dose \u6cbb\u7642\u7dda\u91cf\n\n* g-  # signify gene expression data \u907a\u4f1d\u5b50\u767a\u73fe\u30c7\u30fc\u30bf\u3092\u610f\u5473\u3059\u308b\n\n* c-  # signify cell viability data \u7d30\u80de\u751f\u5b58\u7387\u30c7\u30fc\u30bf\u3092\u610f\u5473\u3059\u308b\n\n* ( dataset = train | test )","18ba8ab8":"* \u76f8\u95a2\u95a2\u4fc2\u306e\u9ad8\u3044\u7279\u5fb4\u91cf\u306e\u6570\n\n35\u500b\u306e\u7279\u5fb4\u91cf\u304c\u3001\u76f8\u95a2\u304c\u5c11\u306a\u304f\u3068\u30820.9\u4ee5\u4e0a\u306e\u9ad8\u3044\u30da\u30a2\u3067\u3042\u308b\u3002 \\\nIn total we have 35 columns that have correlation with at least another 1 higher than 0.9. Let's visualize them.","72f93aaf":"#### cp-time feature (EDA)","a593bde6":"#### cp-dose featue (EDA)","db27eb63":"#### Train & Targets correlations","972e2090":"# EDA","fede390e":"#### gene and cell features (EDA)"}}