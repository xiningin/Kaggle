{"cell_type":{"15895d18":"code","23f54ae1":"code","5b1b5d2f":"code","e4382492":"code","370b7699":"code","06526193":"code","c02083b8":"code","eb327e26":"code","69c9f558":"code","60d31468":"code","0d3eae33":"code","145bd4e0":"markdown","9b6faf66":"markdown","7775cb73":"markdown","d5ef455d":"markdown","fed2d7ae":"markdown"},"source":{"15895d18":"# Loading all necessary libraries and modules\nimport os\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom matplotlib import gridspec\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils.np_utils import to_categorical\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score, confusion_matrix","23f54ae1":"# Loading ResNet50 wit imagenet weights, include_top means that we loading model without last fully connected layers\nmodel = ResNet50(weights = 'imagenet', include_top = False)","5b1b5d2f":"# Read image\norig = cv.imread('..\/input\/food5k-image-dataset\/training\/food\/856.jpg')\n\n# Convert image to RGB from BGR (another way is to use \"image = image[:, :, ::-1]\" code)\norig = cv.cvtColor(orig, cv.COLOR_BGR2RGB)\n\n# Resize image to 224x224 size\nimage = cv.resize(orig, (224, 224)).reshape(-1, 224, 224, 3)\n\n# We need to preprocess imageto fulfill ResNet50 requirements\nimage = preprocess_input(image)\n\n# Extracting our features\nfeatures = model.predict(image)\n\nfeatures.shape","e4382492":"n_features = features.shape[-1]\n\nfig = plt.figure(figsize = (17, 8))\ngs = gridspec.GridSpec(1, 2, figure = fig)\nsub_gs = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs[1])\n\nax1 = fig.add_subplot(gs[0])\nax1.imshow(orig)\n\nfor i in range(3):\n    for j in range(3):\n        ax2 = fig.add_subplot(sub_gs[i, j])\n        plt.axis('off')        \n        plt.imshow(features[0, :, :, np.random.randint(n_features)], cmap = 'gray')  ","370b7699":"# Path to splits\npath = '..\/input\/food5k-image-dataset\/'\n\n# List of splts: ['training', 'validation', 'evaluation']\nsets = os.listdir(path)\n\n# Arrays to store data\ntrain_X, train_Y = ([], [])\nval_X, val_Y = ([], [])\neval_X, eval_Y = ([], [])\n\ndata = [(train_X, train_Y), (val_X, val_Y), (eval_X, eval_Y)]\n\n# Loop through all splits\nfor s, d in (zip(sets, data)):\n    # Defining path to categories ['non_food', 'food']\n    path_to_cat = os.path.join(path, s)\n    \n    # Loop through categories in split\n    for cat in os.listdir(path_to_cat):\n        # Defining path to images in category\n        path_to_images = os.path.join(path_to_cat, cat)\n        \n        # Defining labels\n        if cat == 'food':\n            label = 1\n        else:\n            label = 0\n        \n        # Loop through images in category\n        for i in os.listdir(path_to_images):\n            # Path to image\n            image_path = os.path.join(path_to_images, i)\n            \n            # Reading and preprocessing image\n            image = cv.imread(image_path)\n            image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n            image = cv.resize(image, (224, 224)).reshape(-1, 224, 224, 3)\n            image = preprocess_input(image)\n            \n            # Extracting features\n            features = model.predict(image).reshape(100352)\n            \n            # Store features and label in our lists\n            d[0].append(features)\n            d[1].append(label)","06526193":"# Shuffle data in each split\nrandom_state = 666\ntrain_X, train_Y = shuffle(train_X, train_Y, random_state = random_state)\nval_X, val_Y = shuffle(val_X, val_Y, random_state = random_state)\neval_X, eval_Y = shuffle(eval_X, eval_Y, random_state = random_state)","c02083b8":"# Convert data to numpy arrays\ntrain_X = np.array(train_X)\ntrain_Y = np.array(train_Y)\n\nval_X = np.array(val_X)\nval_Y = np.array(val_Y)\n\neval_X = np.array(eval_X)\neval_Y = np.array(eval_Y)","eb327e26":"# Creating model\n# Number of nodes were defined using rule: \n# take the square root of the previous number of nodes in the layer and then find the closest power of 2\n# (Before FC layers in ResNet50 we have 7*7*2048 = 100352 nodes (after flatten layer), so if we take square root from\n# this number we get 316.78 and closes power of 2 is 256, it's number of nodes in 1st FC layer in our network, \n# to define number of nodes in second layer we are getting swuare root from 256 = 16)\n# Number of nodes in last layer = 1, because it's binary classification problem and our labels have only two values 0 and 1\n\nmodel = Sequential()\nmodel.add(Dense(256, input_shape = (100352,), activation = 'relu', kernel_initializer = 'he_normal'))\nmodel.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal'))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# Checkpoint to save best model\ncheckpoint = ModelCheckpoint('best_model.hdf5', monitor = 'val_accuracy', verbose = 1, save_best_only = True)\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.fit(train_X, train_Y, batch_size = 64, epochs = 10, validation_data = [val_X, val_Y], callbacks = [checkpoint])","69c9f558":"# Plot losses and accuracies\nhistory = model.history.history\n\nfig = plt.figure(figsize = (8, 5))\nplt.plot(history['accuracy'], label = 'acc')\nplt.plot(history['val_accuracy'], label = 'val_acc')\nplt.plot(history['loss'], label = 'acc')\nplt.plot(history['val_loss'], label = 'acc')\nplt.grid()\nplt.legend()\nplt.show()","60d31468":"# Loading best model and evaluate it\n# Here I want to compare keras.evaluate and sklearn.accuracy_score methods, just for curiosity\nmodel.load_weights('best_model.hdf5')\nmodel.evaluate(eval_X, eval_Y)","0d3eae33":"# Making predictions using evaluation dataset\npreds = model.predict(eval_X)\n\n# If our prediction more than 0.5 - we round it to 1, else to 0\npreds = [1 if i > 0.5 else 0 for i in preds]\n\n# Calculating accuracy score\naccuracy = accuracy_score(eval_Y, preds)\nprint(f'Accuracy: {round(accuracy * 100, 4)}%')\n\n# Plotting confusion matrix\nl = ['non_food', 'food']\nconfusion = confusion_matrix(eval_Y, preds)\nsns.heatmap(confusion, square = True, fmt = 'd', xticklabels = l, yticklabels = l, annot = True)","145bd4e0":"This kernel was inspired by [this](https:\/\/www.pyimagesearch.com\/2019\/05\/27\/keras-feature-extraction-on-large-datasets-with-deep-learning\/) tutorial.\n\nThe task is simple: we need to train ANN that will be classify food and non_food pictures.\n\nTo achieve this goal there will be next steps:\n* Load pretrained ResNet50 without fully connected layers and use it as feature extractor\n* Preapare images, extract features from them using pretrained ANN and store these features in numpy arrays\n* Build small FC ANN and train it on these features\n\nLet's start.","9b6faf66":"On next step I want to prepare data for training and evaluation.","7775cb73":"Well, feature extraction with pretrained ANN like ResNet50 is a very powerfull technique - using it, instead of building new CNN for this task, we managed to train shallow and fast FC ANN that can classify food and non_food with about 99% accuracy.","d5ef455d":"Now \"features\" array contains 2048 feature maps wits 7x7 size.\n\nI want to plot random 9 features as example:","fed2d7ae":"I want to look how extracted features looks like, so I'll load one images and visualize it:"}}