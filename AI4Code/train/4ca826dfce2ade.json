{"cell_type":{"c1d1f642":"code","210de40f":"code","f5a971c3":"code","e5631db1":"code","ee7c219e":"code","c1b9993f":"code","92088945":"code","e962860c":"markdown","03ea1c1f":"markdown","71fedc6d":"markdown","e6ba82d1":"markdown","0be6c27d":"markdown"},"source":{"c1d1f642":"import gc\nimport math \nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd","210de40f":"# Load the data\ndf = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv').fillna(0)\n\n# Get a list of the feature columns\nFEATURES = [c for c in df.columns if 'feature' in c]\nTARGET   = 'resp'","f5a971c3":"# Scale the features in the data\nmeans = np.nanmean(df[FEATURES], axis=0)\nstds = np.nanstd(df[FEATURES], axis=0)\ndf[FEATURES] = (df[FEATURES] - means) \/ stds","e5631db1":"from tensorflow.keras.layers import Conv1D, Input, Add, Activation, Dropout\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.layers import LeakyReLU, ELU\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras import optimizers\n\n\ndef DC_CNN_Block(nb_filter, filter_length, dilation, l2_layer_reg):\n    def f(input_):        \n        residual =    input_        \n        layer_out =   Conv1D(filters=nb_filter, kernel_size=filter_length, \n                      dilation_rate=dilation, \n                      activation='linear', padding='causal', use_bias=False,\n                      kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, \n                      seed=42), kernel_regularizer=l2(l2_layer_reg))(input_)                    \n        layer_out =   Activation('selu')(layer_out)        \n        skip_out =    Conv1D(1,1, activation='linear', use_bias=False, \n                      kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, \n                      seed=42), kernel_regularizer=l2(l2_layer_reg))(layer_out)        \n        network_in =  Conv1D(1,1, activation='linear', use_bias=False, \n                      kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, \n                      seed=42), kernel_regularizer=l2(l2_layer_reg))(layer_out)                      \n        network_out = Add()([residual, network_in])        \n        return network_out, skip_out    \n    return f\n\n\ndef DC_CNN_Model(length, features):    \n    input = Input(shape=(length,features))    \n    l1a, l1b = DC_CNN_Block(32,2,1,0.001)(input)    \n    l2a, l2b = DC_CNN_Block(32,2,2,0.001)(l1a) \n    l3a, l3b = DC_CNN_Block(16,2,4,0.001)(l2a)\n    l4a, l4b = DC_CNN_Block(16,2,8,0.001)(l3a)\n    l5a, l5b = DC_CNN_Block(16,2,16,0.001)(l4a)\n    l6a, l6b = DC_CNN_Block(16,2,32,0.001)(l5a)\n    l6b = Dropout(0.8)(l6b) #dropout used to limit influence of earlier data\n    l7a, l7b = DC_CNN_Block(16,2,64,0.001)(l6a)\n    l7b = Dropout(0.8)(l7b) #dropout used to limit influence of earlier data\n    \n    l8 =   Add()([l1b, l2b, l3b, l4b, l5b, l6b, l7b])    \n    l9 =   Activation('relu')(l8)           \n    l21 =  Conv1D(1,1, activation='linear', use_bias=False, \n           kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, seed=42),\n           kernel_regularizer=l2(0.001))(l9)\n    model = Model(inputs=input, outputs=l21)    \n    adam = optimizers.Adam(lr=0.00075, beta_1=0.9, beta_2=0.999, epsilon=None, \n                           decay=0.0, amsgrad=False)\n    model.compile(loss='mae', optimizer=adam, metrics=['mse'])    \n    return model\n\nclass DataIterator(Sequence):\n\n    def __init__(self, df, batch_size):        \n        length = len(df)\n        self.x = df[FEATURES].values.reshape(1, length, len(FEATURES))\n        self.y = df[TARGET].values.reshape(1, length, 1)    \n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.floor(len(self.x[0]) \/ self.batch_size)\n\n    def __getitem__(self, idx):\n        batch_x = self.x[:, idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[:, idx * self.batch_size:(idx + 1) * self.batch_size]\n        gc.collect()\n        return batch_x, batch_y","ee7c219e":"# We cant fit all the data, so we chop it up in pieces\nBATCH_SIZE = 1000\n\n# Instantiate the model\nmodel = DC_CNN_Model(BATCH_SIZE, len(FEATURES))\nmodel.summary()","c1b9993f":"# Data generator. Can't fit it all in memory, so we chop it up\ngenerator = DataIterator(df=df, batch_size=BATCH_SIZE)\n\n# Train the model\nmodel.fit_generator(generator, epochs=2, workers=2, use_multiprocessing=True)","92088945":"def shiftArray(arr, fill_value=np.nan):\n    result = np.empty_like(arr)\n    result[:1] = fill_value\n    result[1:] = arr[:-1]\n    return result\n\nimport janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\n# Use last data for initial timeseries data\neval_data = df.iloc[-BATCH_SIZE:][FEATURES].values\n\n# Delete data\ndel df\ngc.collect()\n\n# Loop through the environment\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    \n    # Update evaluation data\n    eval_data = shiftArray(eval_data, fill_value=(test_df[FEATURES].values - means) \/ stds)\n    \n    # Prediction\n    pred = model(eval_data.reshape(1, BATCH_SIZE, len(FEATURES)), training=False)[0, -1, 0]\n    \n    # Submit prediction\n    sample_prediction_df.action = 1 if pred > 0 else 0\n    env.predict(sample_prediction_df)    ","e962860c":"# SeriesNet\nI'm quite fond of using dilated convolutional neural networks (especially [SeriesNet](https:\/\/github.com\/kristpapadopoulos\/seriesnet)) when it comes to forecasting tasks, so this notebook is dedicated to doing just that. The advantage of using dilated convolutions is that it allows for a very large receptive field (i.e. look far back into the past). This is a work in progress, and I expect it'll be heavily modified. The notebook may of course also be abandoned if it turns out this approach is stupid for the task at hand :)\n\nThe architecture for SeriesNet looks as follows:\n\n<img src=\"https:\/\/i.postimg.cc\/4xmbR8cH\/Screenshot-from-2020-11-24-09-20-56.png\" width=\"50%\" \/>\n\n[Taken from official GitHub](https:\/\/github.com\/kristpapadopoulos\/seriesnet\/blob\/master\/seriesnet-Krist-Papadopoulos-v1.pdf)","03ea1c1f":"# Data Prep\nWithout having investigated the data too much at this point, I'll just treat it as a simple multivariate timeseries with a matrix `[timesteps X features]`, and the `resp` as the target.","71fedc6d":"# Define Model\nSeriesNet is basically just a convolutional neural network with dilations, allowing for a big receptive field. And since it's a convolutional net, we can put in multiple features and their previous values as well. Adapted directly from [SeriesNet github](https:\/\/github.com\/kristpapadopoulos\/seriesnet\/blob\/master\/seriesnet.py)","e6ba82d1":"# Train Model","0be6c27d":"# Creating Submission\nFinally time for doing the predictions"}}