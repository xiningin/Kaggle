{"cell_type":{"ce7ae0b7":"code","699978a4":"code","efbcc5d2":"code","ee246cf0":"code","dee6d6f1":"code","afd9219c":"code","e2e38b09":"code","0b80961f":"code","00f3c39f":"code","f6738ae8":"code","55a2765d":"code","9551fd56":"code","f4ece257":"code","1f765cbc":"code","fbab998b":"code","57f014e9":"code","ee7ad453":"code","9e0ab5b5":"code","80a99cd6":"code","03bfb101":"code","61b3e23f":"code","8e10ca52":"code","6e40c4fc":"code","16a06ec6":"code","2b8899f2":"code","efcdca74":"code","fe67143d":"code","7a526222":"code","0009e959":"code","c5587093":"code","1d8894f9":"code","df1fcfc5":"code","2912c4b6":"code","bf07388f":"code","b461742f":"code","dbc3fdbb":"code","12ef64ca":"code","e0a372f1":"code","309b95bb":"markdown","d08664d4":"markdown","98eb6ae5":"markdown","267282fd":"markdown","ef1ba036":"markdown","bd923862":"markdown","8fa4db83":"markdown","a82d40ea":"markdown","2c1c20e6":"markdown","eb3031c3":"markdown","86491713":"markdown","fa57d4a4":"markdown","fb67aae8":"markdown","82467b96":"markdown","9f6fd69c":"markdown","27532b0a":"markdown","76c48d74":"markdown","32f2a5a0":"markdown","330b94fc":"markdown"},"source":{"ce7ae0b7":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","699978a4":"df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv',keep_default_na=False)\ndf.sample(5)","efbcc5d2":"df.describe()","ee246cf0":"df.info()","dee6d6f1":"sns.heatmap(df.isnull(), cbar=False, cmap=\"magma\")","afd9219c":"# Percentage of null values in each attribute\ndf.isnull().sum().sort_values(ascending = False).head(5) \/1460  * 100","e2e38b09":"# Checking for duplicate records\nsum(df.duplicated())","0b80961f":"#C heck for Zeroes\ndef check_zeros(col):\n    return len(df[col==0])\n\nzeroes = {}\nfor col in df.columns:\n    n = check_zeros(df[col])\n    if(n != 0):\n        zeroes[col] = n\nzeroes = sorted(zeroes.items(),key=lambda x: x[1], reverse=True)\n\nfor i in range(len(zeroes)):\n    print(f'There are {zeroes[i][1]} houses with zero in {zeroes[i][0]}')","00f3c39f":"corr = df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.color_palette(\"magma\", as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","f6738ae8":"corr = df.corr()\ncorr = corr[\"SalePrice\"]\ncorrDF = pd.DataFrame(corr, df.columns).dropna().transpose()\ncorrDF\nplt.subplots(figsize=(20,10))\n#sns.heatmap(, annot=True, fmt=\"g\", cmap='viridis')\nchart = sns.heatmap(corrDF,cmap = sns.color_palette(\"magma\", as_cmap=True), square =True, cbar_kws={\"shrink\": .5})\nchart.set_xticklabels(chart.get_xticklabels(), rotation=45)\nchart","55a2765d":"# make a copy of the original dataset\ndf_clean = df.copy()\ndf_clean = df_clean.drop(['Id'], axis=1)\ndf_clean.head()","9551fd56":"# Show non-numerical data\ndf_clean.select_dtypes(include=[object]).info()","f4ece257":"df_clean['LotFrontage'].value_counts().head(5)","1f765cbc":"# Assume that NA represents no Lot Frontage; Linear feet of street connected to property = 0\ndf_clean['LotFrontage'].replace('NA',0, inplace=True)\ndf_clean['LotFrontage'].value_counts().head(5)","fbab998b":"print(df_clean['MasVnrArea'].value_counts(), \"\\n------\\n\",\ndf_clean['MasVnrType'].value_counts())","57f014e9":"# For those particular attributes, NA represents NaN, not non-existent as other attributes, \n# since non-existent is represented by \"None\". Only 8 records have NaN values. They will\n# be dropped Also there's a discrepency, 864 houses have \"None\"\n#  for 'MasVnrArea' while only '861' houses have\n# area = 0. We will have to compare those values to decide which ones are incorrect\ndf_clean = df_clean[df_clean.MasVnrArea != 'NA']\ndf_clean = df_clean[df_clean.MasVnrType != 'NA']\nprint(df_clean['MasVnrArea'].value_counts(), \"\\n------\\n\",\ndf_clean['MasVnrType'].value_counts())","ee7ad453":"df_clean.loc[df_clean['MasVnrType'] == 'None']['MasVnrArea'].value_counts()","9e0ab5b5":"# Fixed, the other part of the condition was missing.\n# There's something buggy with the code, the rows won't drop. I will check it later.\n# the index is removed but the value remains?\n\n# 1 sq meter is most probably wrong, will drop rows\n# for the other three, it is apparent that they have area, \n# but the type is missing, will drop rows.\ndf_clean = df_clean[df_clean.MasVnrArea != 'NA']\ndf_test = df_clean.copy()\nrowIndices = []\nfor rowIndex in df_test.index:\n    if (((df_test['MasVnrType'][rowIndex] != 'None')& (df_test['MasVnrArea'][rowIndex] == '0'))\n       | ((df_test['MasVnrType'][rowIndex] == 'None')& (df_test['MasVnrArea'][rowIndex] != '0'))):\n        rowIndices.append(rowIndex)\nfor rowIndex in rowIndices:\n    df_test = df_test[df_test.index != rowIndex]\nprint(df_test['MasVnrArea'].value_counts(), \"\\n------\\n\",\ndf_test['MasVnrType'].value_counts())\ndf_clean = df_test\ndf_clean.shape","80a99cd6":"print(df_clean['GarageYrBlt'].value_counts(), \"\\n------\\n\",\ndf_clean['GarageType'].value_counts())","03bfb101":"# In ['GarageType'], there are 81 instances of 'NA', meaning 81 houses with no garage.\n# we can safely assume that 'NA' in ['GarageYrBlt'] also are the houses without garage.\n# will replace with zeroes\ndf_clean['GarageYrBlt'].replace('NA',0, inplace=True)\ndf_clean['GarageYrBlt'].value_counts().head(5)","61b3e23f":"## detecting then removing outliers using IQR","8e10ca52":"df_clean['ExterQual'].head(10)","6e40c4fc":"catAttributes = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', \n                 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\nranks = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n#df_clean = df_clean.replace(categories)\nfor attribute in catAttributes:\n    df_clean[attribute].replace(ranks, inplace=True)\ndf_clean['ExterQual'].head(10)","16a06ec6":"df_clean['BsmtExposure'].replace({'Gd': 4, 'Av': 3, 'Mn': 2, 'Mo': 1, 'NA': 0}, inplace=True)\ndf_clean['BsmtFinType1'].replace({'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3,\n                                  'LwQ': 2,'Unf': 1,'NA': 0}, inplace=True)\ndf_clean['BsmtFinType2'].replace({'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3,\n                                  'LwQ': 2,'Unf': 1,'NA': 0}, inplace=True)\ndf_clean['Electrical'].replace({'SBrkr': 5, 'FuseA': 4, 'FuseF': 3,\n                                'FuseP': 2, 'Mix': 1}, inplace=True)\ndf_clean['Functional'].replace({'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5,\n                                  'Maj1': 4,'Maj2': 3,'Sev': 2,'Sal': 1}, inplace=True)\ndf_clean['GarageFinish'].replace({'Fin': 3, 'RFn': 2, \n                                  'Unf': 1,'NA': 0}, inplace=True)\ndf_clean['Utilities'].replace({'AllPub': 4, 'NoSewr': 3, \n                                  'NoSeWa': 2,'ELO': 1}, inplace=True)\ndf_clean['LandSlope'].replace({'Gtl': 3, 'Mod': 2, \n                                  'Sev': 1}, inplace=True)\ndf_clean['CentralAir'].replace(('Y', 'N'), (1, 0), inplace=True)","2b8899f2":"df_clean.select_dtypes(include=[object]).info()","efcdca74":"df_postEncoding = df_clean.copy()\nfor col in df_clean.select_dtypes(include=[object]).columns:\n    y = pd.get_dummies(df_clean[col], prefix=col)\n    df_clean.drop(columns = col, inplace = True)\n    df_clean = pd.concat([df_clean,y], axis=1)\ndf_clean.head()\n","fe67143d":"y = pd.get_dummies(df_clean['MSSubClass'], prefix='MSSubClass')\ndf_clean.drop(columns = 'MSSubClass', inplace = True)\ndf_clean = pd.concat([df_clean,y], axis=1)\ndf_clean.head()","7a526222":"df_clean.shape","0009e959":"df_clean.select_dtypes(exclude=[int]).info()","c5587093":"# Todo : Generate the exploratory data analysis questions.\n# Tips to get some question ideas:\n# 1- Read the project description on Kaggle, also check the data fields available on the data tab.\n# 2- Use the IMDP-use Case example project that TA.Ali uploaded ,check the questions he used in the EDA section.","1d8894f9":"# Todo: start working on the regression model code, to use it as soon as the data is ready.\n# Tips:\n# 1- Start looking for the libraries that we are going to need, I think we will most probably use multivariate \n# regression since we have a lot of attributes, please check that point.\n# 2- Prepare the parts that do not require the data \"for now\", such as the regression function, regression plot curve...","df1fcfc5":"training_data = df_clean.sample(frac=0.8, random_state=25)\ntesting_data = df_clean.drop(training_data.index)\n\nprint(f\"No. of training examples: {training_data.shape[0]}\")\nprint(f\"No. of testing examples: {testing_data.shape[0]}\")\n","2912c4b6":"x_train = training_data.drop(['SalePrice'], axis = 1)\ny_train = training_data['SalePrice']\n\nx_test = testing_data.drop(['SalePrice'], axis = 1)\nx_test = np.ascontiguousarray(x_test)\ny_test = testing_data['SalePrice']\n","bf07388f":"import xgboost\nclassifier = xgboost.XGBRegressor()\nclassifier.fit(x_train,y_train)","b461742f":"y_predict = classifier.predict(x_test)","dbc3fdbb":"y_predict","12ef64ca":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nrms = sqrt(mean_squared_error(y_test, y_predict))\nrms","e0a372f1":"\nsns.histplot(data=df_clean, x=df_clean['SalePrice'])\ndf_clean['SalePrice'].std()\nprint(f\"Mean Sale Price: {df_clean['SalePrice'].mean()}\")\nprint(f\"Standard deviation of Sale Price: {df_clean['SalePrice'].std()}\")","309b95bb":"### 2.3 Data Cleaning\n1. There are no null values to replace. NA represents that a certain attribute is unapplicable or non-existent, Such as having pool area = 0 for appartments that have no pool or 0 Fireplaces for apartment that lack fire places. \n2. Zeroes are valid values, they are the same case with NA values. The difference is that they are in quantitative attributes. \n3. The Id column will be dropped.\n4. Categorical data, some of which are ordinal, will be transformed to be useful in the analysis.\n5. Dimentionality reduction using PCA","d08664d4":"### hot encoding MSSubClass","98eb6ae5":"## 3. Exploratory Data Analysis","267282fd":"<a id='intro'><\/a>\n## 1. Introduction\n### Overview\nThis dataset contains information about 1,460 houses, with around 79 explanatory variables describing every aspect of the houses. The goal is to create a regression model that could predict a house price from these variables. The model would be tested on a different data set \"test set\".\n\n### Questions\n## Todo: create a list of questions for the Exploratory data analysis stage, use the following questions as an example.\n<ul>\n<li><a href=\"#q1\">1. Example question 1<\/a><\/li>\n<\/ul>","ef1ba036":"#### I. Some of those attributes are quantitative, but have NA values. Each attribute will be dealt with separately.","bd923862":"### XGBoost\nIt is similar to decision trees. Data does not need to be normalized before regression.","8fa4db83":"### 2.1 Data Gathering and exploration","a82d40ea":"## 4. Regression Model","2c1c20e6":"#### III. Nominal Attributes\nAll that's left to encode are normal attributes, which will be one-hot encoded.\nAlso, the attribute 'MSSubClass' is nominal, but is label encoded. Will be one-hot encoded.\n","eb3031c3":"Since we are predicting continuous values, not categorical, testing for accuracy does not make sence. So that's why the root mean square was calculated. \nMeasuring the goodness of the model depends on the problem itself. For example, an rms of 15 is arguably very low for prediction of house rent prices between 500 to 1000 USD, but it is not when it comes to predicting the price of a family meal in a range between 10 to 25 USD.","86491713":"All attributes are encoded in numeric form, or already is a quantitative attribute.","fa57d4a4":"#### 2.3.3 Dropping the unnecessary Id Column","fb67aae8":"The database uses NA to represents an **inapplicability** of an attribute. For example, an **NA** value in the PoolQC column represents that the house has no pool, thus cannot be assigned to a quality category. That's why the line\n***keep_default_na=False***\nwas added, to avoid replacing them with **NaN**.\n","82467b96":"#### 2.3.4 Dimentionality reduction with PCA","9f6fd69c":"More categorical attributes that are ordinal in nature but have different ranking systems:","27532b0a":"## Project: House Price Prediction\n\n### Table of Contents\n<ul>\n<li><a href=\"#intro\">1. Introduction<\/a><\/li>\n<li><a href=\"#preprocessing\">2. Data Preprocessing<\/a><\/li>\n<li><a href=\"#eda\">3. Exploratory Data Analysis<\/a><\/li>\n<li><a href=\"#regression\">4. Regression Model<\/a><\/li>\n<li><a href=\"#conclusions\">5. Conclusions<\/a><\/li>\n<\/ul>","76c48d74":"#### 2.3.4 Transforming Categorical Data","32f2a5a0":"<a id='preprocessing'><\/a>\n## 2. Data Preprocessing\nIn this section, data will be preprocessed for EDA and regression analysis. Data will be checked for cleanliness and any necessary transformation or reduction will be carried out.","330b94fc":"#### II. Ordinal attributes\nThe rest are qualitative data, which can be nominal, ordinal or binary. Most of the ordinal data of these categories are represented in the following format:\n* Ex -> Excellent\n* Gd -> Good\n* TA -> Average\/Typical\n* Fa -> Fair\n* Po -> Poor\n* NA -> does not exist\n\nTo encode them, these strings will be replaced with a numberic rank:\n* Ex -> 5\n* Gd -> 4\n* TA -> 3\n* Fa -> 2\n* Po -> 1\n* NA -> 0"}}