{"cell_type":{"56f6a777":"code","a861bf7a":"code","64223703":"code","2ab7816c":"code","dbc8effe":"code","480a99b8":"code","ed8caa87":"code","65e4fefd":"code","14aa04af":"code","03dc3389":"code","2be49343":"code","f1e0f7bd":"code","6a538a75":"code","a8dea163":"code","24bdbfde":"code","076020ab":"code","9f6b8806":"code","4e017903":"code","8913dc5b":"code","d0971426":"code","3caa293e":"code","7efe91a5":"markdown","74e7f7ca":"markdown","bcc30b3a":"markdown"},"source":{"56f6a777":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport numpy\nimport pandas\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Dense ,Dropout,BatchNormalization\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a861bf7a":"df=pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")\n#changing names because previous names are little bit confusing\ndf=df.rename(index=str, columns={\"GRE Score\": \"GRE\", \"TOEFL Score\": \"TOEFL\", \"Chance of Admit \": \"Admission_Chance\"})\n#we donot need serial number so its good to drop it because its just a number\ndf=df.drop(\"Serial No.\",axis=1)\ndf.head(10)","64223703":"df.describe()","2ab7816c":"admit=np.asarray(df[\"Admission_Chance\"])\nlen(np.unique(admit))\n#we have 60 different values in the coloum [chance to predict]","dbc8effe":"import pandas as pd\nimport matplotlib.pyplot as plt\ncorr = df.corr()\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(df.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(df.columns)\nax.set_yticklabels(df.columns)\nplt.show()","480a99b8":"import seaborn as sns\ncorr = df.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","ed8caa87":"fig = plt.figure(figsize = (20, 25))\nj = 0\nfor i in df.columns:\n    plt.subplot(6, 4, j+1)\n    j += 1\n    sns.distplot(df[i][df['Admission_Chance']<0.72], color='r', label = 'Not Got Admission')\n    sns.distplot(df[i][df['Admission_Chance']>0.72], color='g', label = 'Got Admission')\n    plt.legend(loc='best')\nfig.suptitle('Admission Chance In University ')\nfig.tight_layout()\nfig.subplots_adjust(top=0.95)\nplt.show()","65e4fefd":"for column in df:\n    plt.figure()\n    sns.boxplot(x=df[column])","14aa04af":"for column_1st in df:\n    for coloum_2nd in df:\n        jet=plt.get_cmap('jet')\n        plt.figure(figsize=(15,5))\n        plt.scatter(df[column_1st], df[coloum_2nd], s=30, c=df['Admission_Chance'], vmin=0, vmax=1, cmap=jet)\n        plt.xlabel(column_1st,fontsize=40)\n        plt.ylabel(coloum_2nd,fontsize=40)\n        plt.colorbar()\n        plt.show()","03dc3389":"# define base model\ndef baseline_model():\n    # create model\n    model = Sequential()\n    \n    \n    \n    model.add(Dense(16, input_dim=7, activation='relu'))\n    \n    \n    model.add(Dense(8, input_dim=7, activation='relu'))\n    \n    \n    model.add(Dense(1))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model","2be49343":"X=np.asarray(df.drop(\"Admission_Chance\",axis=1))\nY=np.asarray(df[\"Admission_Chance\"])","f1e0f7bd":"X_train, X_test, y_train, y_test = train_test_split(\n     X,Y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler =  MinMaxScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)","6a538a75":"\nestimator = KerasRegressor(build_fn=baseline_model, epochs=30, batch_size=3, verbose=1)","a8dea163":"history=estimator.fit(X_train,y_train)","24bdbfde":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\n\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","076020ab":"from sklearn.metrics import accuracy_score\nprediction = estimator.predict(X_test)\n","9f6b8806":"\ntrain_error =  np.abs(y_test - prediction)\nmean_error = np.mean(train_error)\nmin_error = np.min(train_error)\nmax_error = np.max(train_error)\nstd_error = np.std(train_error)\n\n","4e017903":"print(\"std_error: \",std_error)\nprint(\"mean_error: \",mean_error)\nprint(\"min_error: \",min_error)\nprint(\"max_error: \",max_error)","8913dc5b":"#Visualising the Acutal and predicted Result\nplt.plot(y_test, color = 'green', label = 'Actual')\nplt.plot(prediction, color = 'blue', label = 'Predicted')\nplt.grid(alpha = 0.3)\nplt.xlabel('Number of Candidate')\nplt.ylabel('Score')\nplt.title('Actual vs Predicted')\nplt.legend()\nplt.show()","d0971426":"from sklearn.metrics import r2_score\nprint(\"r_square score: \", r2_score(y_test,prediction))\nprint(\"real value of y_test[1]: \" + str(y_test[1]) + \" -> the predict: \" + str(estimator.predict(X_test[[1],:])))\nprint(\"real value of y_test[2]: \" + str(y_test[2]) + \" -> the predict: \" + str(estimator.predict(X_test[[2],:])))\n\ntrain_prediction = estimator.predict(X_train)\nprint(\"r_square score (train dataset): \", r2_score(y_train,train_prediction))","3caa293e":"# Save the weights\nestimator.model.save_weights('model_weights.h5')\n\n# Save the model architecture\nwith open('model_architecture.json', 'w') as f:\n    f.write(estimator.model.to_json())","7efe91a5":"**For Checking our Model that it is not General we are using Kfolds**","74e7f7ca":"[kfold validation](https:\/\/machinelearningmastery.com\/evaluate-performance-deep-learning-models-keras\/)","bcc30b3a":"**thats good we have no outliers**"}}