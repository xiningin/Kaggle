{"cell_type":{"0140c9fd":"code","ef774b20":"code","2ef30a43":"code","8cbe254c":"code","8e3bb8f8":"code","61bd5709":"code","64c822b5":"code","e33cb44c":"code","3856048d":"code","7970176d":"code","2e288525":"code","f40bf1dc":"code","656fa882":"code","f9165159":"code","4e6d5d3f":"code","fbad8402":"code","32f28b66":"code","a95ef9be":"code","c1d2bf86":"code","e82a4bc7":"markdown","e940c095":"markdown","dc03a1e3":"markdown","dd9688ed":"markdown","03e7961e":"markdown","02fbb8a1":"markdown","0776d471":"markdown","196694bc":"markdown"},"source":{"0140c9fd":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random","ef774b20":"# Load dataset \n(x_train, y_train), (x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()","2ef30a43":"# Visualize a sample image\nplt.imshow(x_train[0], cmap='gray')","8cbe254c":"# check out the shape of the training data\nx_train.shape","8e3bb8f8":"# check out the shape of the testing data\nx_test.shape","61bd5709":"# Let's view some images!\ni = random.randint(1,60000)\nplt.imshow(x_train[i], cmap='gray')","64c822b5":"label = y_train[i]\nlabel","e33cb44c":"# view more images in a grid format\n# Define the dimensions of the plot grid \nW_grid = 15\nL_grid = 15\n\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n\nn_training = len(x_train) # get the length of the training dataset\n\n# Select a random number from 0 to n_training\nfor i in np.arange(0, W_grid*L_grid):\n    index = np.random.randint(0, n_training)\n    axes[i].imshow(x_train[index])\n    axes[i].set_title(y_train[index], fontsize=8)\n    axes[i].axis('off')\n\n","3856048d":"# normalize data\nx_train = x_train\/255\nx_test = x_test\/255","7970176d":"# add some noise\nnoise_factor = 0.3\nnoise_dataset = []\n\nfor img in x_train:\n    noisy_image = img + noise_factor* np.random.randn(*img.shape)\n    noisy_image = np.clip(noisy_image, 0, 1)\n    noise_dataset.append(noisy_image)","2e288525":"noise_dataset = np.array(noise_dataset)","f40bf1dc":"plt.imshow(noise_dataset[20], cmap='gray')","656fa882":"# add noise to testing dataset\nnoise_factor = 0.2\nnoise_test_dataset = []\n\nfor img in x_test:\n    noisy_image = img + noise_factor* np.random.randn(*img.shape)\n    noisy_image = np.clip(noisy_image, 0, 1)\n    noise_test_dataset.append(noisy_image)","f9165159":"noise_test_dataset = np.array(noise_test_dataset)","4e6d5d3f":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\nfrom tensorflow.keras import Model\n\ndef make_convolutional_autoencoder():\n    # encoding\n    inputs = Input(shape=(28, 28, 1))\n    x = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n    x = MaxPooling2D(padding='same')(x)\n    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n    x = MaxPooling2D(padding='same')(x)\n    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n    encoded = MaxPooling2D(padding='same')(x)    \n    \n    # decoding\n    x = Conv2D( 8, 3, activation='relu', padding='same')(encoded)\n    x = UpSampling2D()(x)\n    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n    x = UpSampling2D()(x)\n    x = Conv2D(16, 3, activation='relu')(x) # <= padding='valid'!\n    x = UpSampling2D()(x)\n    decoded = Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n    \n    # autoencoder\n    autoencoder = Model(inputs, decoded)\n    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n    return autoencoder\n\n# create a convolutional autoencoder\nautoencoder = make_convolutional_autoencoder()\n","fbad8402":"autoencoder.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.001))\nautoencoder.summary()","32f28b66":"autoencoder.fit(noise_dataset.reshape(-1, 28, 28, 1),\n               x_train.reshape(-1, 28, 28, 1),\n               epochs = 50,\n               batch_size = 128,\n               validation_data = (noise_test_dataset.reshape(-1, 28, 28, 1), x_test.reshape(-1, 28, 28, 1)))","a95ef9be":"predicted = autoencoder.predict(noise_test_dataset[:10].reshape(-1,28,28,1))","c1d2bf86":"fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\nfor images, row in zip([noise_test_dataset[:10], predicted], axes):\n    for img, ax in zip(images, row):\n        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)","e82a4bc7":"# BUILD AND TRAIN AUTOENCODER MODEL","e940c095":"# EVALUATE TRAINED MODEL PERFORMANCE","dc03a1e3":"#### Autoencoders are a type of artificial neural networks that are used to perform a task of data encoding (representation learning).\n#### We will feed in noisy images from the mnist-fashion dataset as input.\n#### The output will be clean (denoised) image\n","dd9688ed":"# OVERVIEW","03e7961e":"# DATA PREPROCESSING","02fbb8a1":"# DATA VISUALIZATION","0776d471":"# IMPORT LIBRARIES AND DATASET","196694bc":"- 0 = T-shirt\/top\n- 1 = Trouser\n- 2 = Pullover\n- 3 = Dress\n- 4 = Coat\n- 5 = Sandal\n- 6 = Shirt\n- 7 = Sneaker\n- 8 = Bag\n- 9 = Ankle boot"}}