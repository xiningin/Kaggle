{"cell_type":{"b0227732":"code","8fd5b5af":"code","27f6f554":"code","85d568d5":"code","aa17887e":"code","f1c22b11":"code","37c49161":"code","2ff13ff6":"code","fcd575af":"code","1ca92a1b":"code","972ff02d":"markdown","edc17e3a":"markdown","2a5d91e5":"markdown"},"source":{"b0227732":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, LSTM, Dense, Embedding\nfrom keras import layers,models\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fd5b5af":"df = np.load('\/kaggle\/input\/samples320\/data320.npy')\n# data = np.load('\/kaggle\/input\/samples320\/data320.npy')[1].reshape(1,125,2)","27f6f554":"# train data\n\ndt100 = df[:320,:100,:2] # first 100 samples of 320 trajectories\ndecoder_target_data = df[:320,100:,:2]  # last 25 samples\n\nprint(dt100.shape, decoder_target_data.shape)","85d568d5":"# dt = data[0][:100].reshape(1,100,2)\n# decoder_target_data = data[0][100:].reshape(1,25,2)","aa17887e":"plt.plot(dt100[1][:,0], dt100[1][:,1])\nplt.scatter(decoder_target_data[1][:,0], decoder_target_data[1][:,1], color='orange')\n","f1c22b11":"input_timesteps=100\ninput_features=2\noutput_timesteps=25\noutput_features=2\nunits=50\n\n#Input\nencoder_inputs = layers.Input(shape=(input_timesteps,input_features))\n\n#Encoder\nencoder = layers.LSTM(units, return_state=True, return_sequences=False)\n_, state_h, state_c = encoder(encoder_inputs)\n\n#Decoder\ndecoder_inputs = layers.RepeatVector(output_timesteps)(state_h)\ndecoder_lstm = layers.LSTM(units, return_sequences=True, return_state=False)\ndecoder = decoder_lstm(decoder_inputs, \n                       initial_state=[state_h, state_c])\n\n\n#Output\n# applies a same Dense (fully-connected) operation to every timestep of a 3D tensor\nout = layers.TimeDistributed(Dense(50))(decoder)\nout = layers.TimeDistributed(Dense(50))(out)\nout = layers.TimeDistributed(Dense(output_features))(out)\n\n\nmodel = models.Model(encoder_inputs, out)\n\n\ntf.keras.utils.plot_model(model, show_shapes=True)","37c49161":"model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n\nmodel.fit(dt100, decoder_target_data,\n          batch_size=64,\n          epochs=100)","2ff13ff6":"# predict a sample\nsample = 150  # sample to predict\nfrom1 = dt100 # sample that dataset belongs -->  (100,2) or (125,2)\n\npred = model.predict(from1[sample].reshape(1,from1.shape[1],2))\npred = pred.reshape(output_timesteps,output_features)","fcd575af":"plt.figure(figsize=(10,7))\nplt.scatter(pred[:,0], pred[:,1], color='orange')\nplt.plot(from1[sample][:,0], from1[sample][:,1])","1ca92a1b":"sample = 150  # sample to predict\nfrom2 = df # sample that dataset belongs -->  (100,2) or (125,2)\n\npred = model.predict(from2[sample].reshape(1,from2.shape[1],2))\npred = pred.reshape(output_timesteps,output_features)\n\nplt.figure(figsize=(10,7))\nplt.scatter(pred[:,0], pred[:,1], color='orange')\nplt.plot(from2[sample][:,0], from2[sample][:,1])","972ff02d":"## 1. Prediction of <font color='red'>Training Targets","edc17e3a":"## 2. Prediction of <font color='red'> Future Coordinates","2a5d91e5":"# Prediction"}}