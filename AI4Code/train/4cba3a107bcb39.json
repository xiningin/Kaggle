{"cell_type":{"fac3d644":"code","6929b607":"code","57a8c82d":"code","860e3e51":"code","21c9358f":"code","e13b12e6":"code","0bcc78d6":"code","1fc490c6":"code","e35a21bf":"code","585974c9":"code","83a10f96":"code","b03bda91":"code","b46a2740":"code","f63e7db0":"code","c16d83e9":"code","97fcbf12":"markdown","93e30867":"markdown","261041ab":"markdown","300b8512":"markdown","aaf01720":"markdown","c987d563":"markdown","ef2041a4":"markdown","5b5ebf53":"markdown","d347eb16":"markdown","3eadc1f4":"markdown","e9c7d839":"markdown","be947b03":"markdown","e6496abe":"markdown","5cb9716e":"markdown","9442e360":"markdown"},"source":{"fac3d644":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n\ndef xgboost_model(X_train, X_valid, y_train, y_valid, X_test, file_name): \n    print('XGBoost')\n    xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.05)\n    xgb_model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)\n    y_predict = xgb_model.predict(X_valid)\n    y_test = xgb_model.predict(X_test)\n#     plt.figure()\n#     sns.distplot(y_test)\n#     print('Average Expected Price =', y_test.mean())\n#     print('Standard Deviation =', y_test.std())\n    output = pd.DataFrame({'Id':X_test.index, 'SalePrice': y_test})\n    output.to_csv(file_name, index=False)\n    return int(mean_absolute_error(y_valid, y_predict))\n\nfrom sklearn.ensemble import RandomForestRegressor\ndef random_forest_model(X_train, X_valid, y_train, y_valid, X_test, file_name): \n    rf_model = RandomForestRegressor(n_estimators=200, random_state=1)\n    rf_model.fit(X_train, y_train)\n    y_predict = rf_model.predict(X_valid)\n    y_test = rf_model.predict(X_test)\n    output = pd.DataFrame({'Id':X_test.index, 'SalePrice': y_test})\n    output.to_csv(file_name, index=False)\n    return int(mean_absolute_error(y_valid, y_predict))\n\nfrom catboost import CatBoostRegressor\ndef catboost_model(X_train, X_valid, y_train, y_valid, X_test, file_name): \n    cb_model = CatBoostRegressor( \n        n_estimators = 200,\n        loss_function = 'MAE',\n        eval_metric = 'RMSE')\n    cb_model.fit( X_train, y_train, use_best_model=True, eval_set=(X_valid, y_valid), silent=True, plot=True )\n    y_predict = cb_model.predict(X_valid)\n    y_test = cb_model.predict(X_test)\n    output = pd.DataFrame({'Id':X_test.index, 'SalePrice': y_test})\n    output.to_csv(file_name, index=False)\n    return int(mean_absolute_error(y_valid, y_predict))\n\ndef check_correlaton(feat_data, label_data):\n    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n    for i, corr_method in enumerate(['pearson', 'spearman']):\n        coe = feat_data.join(label_data).corr(method=corr_method)\n        highly_corr = [col for col in coe.columns if (coe[col].abs()>0.8).sum()>1] # to hide columns correlation to themselves\n        high_coe = coe.loc[highly_corr, highly_corr].round(2)\n        sns.heatmap(high_coe, mask= np.triu(high_coe), square=True, annot=True, annot_kws={\"size\": 10}, cmap=\"BuPu\", ax=axes[i])\n        axes[i].set_title(corr_method, fontsize=18)\n    fig.tight_layout(pad=3.0)\n    \ndef k_fold_xgboost(X, y, X_test, file_name, k_folds):\n    print(f'XGBoost With {k_folds} Cross-Validation')\n    result = None\n    total_error = 0\n    valid_size = len(X)\/k_folds\n    for kf in range(k_folds):\n        valid_start = int(kf*valid_size)\n        valid_end = int(valid_start + valid_size)\n        X_valid = X.iloc[valid_start:valid_end]\n        y_valid = y.iloc[valid_start:valid_end]\n        X_train = X.drop(X[valid_start:valid_end].index)\n        y_train = y.drop(y[valid_start:valid_end].index)\n        xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.05)\n        xgb_model.fit(X_train, y_train, \n                 early_stopping_rounds=5, \n                 eval_set=[(X_valid, y_valid)], \n                 verbose=False)\n        y_predict = xgb_model.predict(X_valid)\n        total_error += mean_absolute_error(y_valid, y_predict)\n        y_test = xgb_model.predict(X_test)\n        if result is None:\n            result = y_test\n        else:\n            result += y_test\n    final_result = result \/ k_folds\n#     plt.figure()\n#     sns.distplot(final_result)\n#     print('Average Expected Price =', final_result.mean())\n#     print('Standard Deviation =', final_result.std())\n    output = pd.DataFrame({'Id':X_test.index, 'SalePrice': final_result})\n    output.to_csv(file_name, index=False)\n    return int(total_error\/k_folds)\n","6929b607":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\nX = train.drop(['SalePrice'], axis=1)\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n\n# Missing Data\n\nnum_imputer = SimpleImputer(strategy='mean')\nX_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_features]))\nX_valid_num = pd.DataFrame(num_imputer.transform(X_valid[num_features]))\nX_test_num = pd.DataFrame(num_imputer.transform(X_test[num_features]))\nX_train_num.columns = X_train[num_features].columns\nX_valid_num.columns = X_valid[num_features].columns\nX_test_num.columns = X_test[num_features].columns\nX_test_num.index = X_test[num_features].index\n\ncat_imputer = SimpleImputer(strategy='most_frequent')\nX_train_cat = pd.DataFrame(cat_imputer.fit_transform(X_train[cat_features]))\nX_valid_cat = pd.DataFrame(cat_imputer.transform(X_valid[cat_features]))\nX_test_cat = pd.DataFrame(cat_imputer.transform(X_test[cat_features]))\nX_train_cat.columns = X_train[cat_features].columns\nX_valid_cat.columns = X_valid[cat_features].columns\nX_test_cat.columns = X_test[cat_features].columns\nX_test_cat.index = X_test[cat_features].index\n\n\n# Cat to Num conversion\n\noh_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nX_train_encoded = pd.DataFrame(oh_encoder.fit_transform(X_train_cat))\nX_valid_encoded = pd.DataFrame(oh_encoder.transform(X_valid_cat))\nX_test_encoded = pd.DataFrame(oh_encoder.transform(X_test_cat))\nX_train_encoded.index = X_train_cat.index\nX_valid_encoded.index= X_valid_cat.index\nX_test_encoded.index= X_test_cat.index\n\n# put columns back together\n\nX_train_modified = X_train_num.join(X_train_encoded)\nX_valid_modified = X_valid_num.join(X_valid_encoded)\nX_test_modified = X_test_num.join(X_test_encoded)\n\n# check model score\n\nprint(xgb_model(X_train_modified, X_valid_modified, y_train, y_valid, X_test_modified, 'model_1.csv'))\n\nprint('Competition Score for this model is: 15170.35693')","57a8c82d":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\nX = train.drop(['SalePrice'], axis=1)\n\n# # Solve I\/O leakage\n# leaked_features = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition']\n# X.drop(leaked_features, axis=1, inplace=True)\n# X_test.drop(leaked_features, axis=1, inplace=True)\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n\n# for ordinal features, replace all Nan values with 'NA' ( which will be later converted to zero)\nfor col in ordinal_features:\n    X[col].fillna(value='NA', inplace=True)\n    X_test[col].fillna(value='NA', inplace=True)\n\n# for features to be one-hot encoded, will make all 'None' and 'NA' be Nan\nfor col in nominal_features:\n    X[col].replace(['None', 'NA'], pd.NA, inplace=True)\n    X_test[col].replace(['None', 'NA'], pd.NA, inplace=True)\n\n# Nan values that should be filled with zeros\nfeatures_nan_zero = ['MasVnrArea']\nfor col in features_nan_zero:\n    X[col].fillna(0, inplace=True)\n    X_test[col].fillna(0, inplace=True)\n\n# Nan filled with mean\nfeatures_nan_mean = ['LotFrontage', 'GarageYrBlt']\nfor col in features_nan_mean:\n    X[col].fillna(X[col].mean(), inplace=True)\n    X_test[col].fillna(X_test[col].mean(), inplace=True)\n\nfor col in ordinal_features:\n    X[col] = X[col].map(ordinal_mapping)\n    X_test[col] = X_test[col].map(ordinal_mapping)\n\n# covert remaining categorical features (one-hot-features) to number\nX_full = pd.concat([X[nominal_features], X_test[nominal_features]])\nX_full_dummies = pd.get_dummies(X_full[nominal_features], dtype=int)\nX_dummies = X_full_dummies.loc[0:1460].copy()\nX_test_dummies = X_full_dummies.loc[1460:].copy()\nX.drop(nominal_features, axis=1, inplace=True)\nX_test.drop(nominal_features, axis=1, inplace=True)\nX = X.join(X_dummies)\nX_test = X_test.join(X_test_dummies)\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_2.csv'))\n\n# # na_count = X.isnull().sum()\n# # na_count[na_count > 0].sort_values(ascending=False)\n\nprint('Competition Score for this model is: 15057.64597')","860e3e51":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\nX = train.drop(['SalePrice'], axis=1)\n\n# # Solve I\/O leakage\n# leaked_features = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition']\n# X.drop(leaked_features, axis=1, inplace=True)\n# X_test.drop(leaked_features, axis=1, inplace=True)\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n\n# for ordinal features, replace all Nan values with 'NA' ( which will be later converted to zero)\nfor col in ordinal_features:\n    X[col].fillna(value='NA', inplace=True)\n    X_test[col].fillna(value='NA', inplace=True)\n\n# for features to be one-hot encoded, will make all 'None' and 'NA' be Nan\nfor col in nominal_features:\n    X[col].replace(['None', 'NA'], pd.NA, inplace=True)\n    X_test[col].replace(['None', 'NA'], pd.NA, inplace=True)\n\n# here nan is because there is no data\nfeatures_nan_zero = ['MasVnrArea', 'GarageYrBlt']\nfor col in features_nan_zero:\n    X[col].fillna(0, inplace=True)\n    X_test[col].fillna(0, inplace=True)\n\n# there should be data, but was not recorded\nX['LotFrontage'].fillna(X['LotFrontage'].mean(), inplace=True)\nX_test['LotFrontage'].fillna(X['LotFrontage'].mean(), inplace=True)\n\nfor col in ordinal_features:\n    X[col] = X[col].map(ordinal_mapping)\n    X_test[col] = X_test[col].map(ordinal_mapping)\n\n# covert remaining categorical features (one-hot-features) to number\nX_full = pd.concat([X[nominal_features], X_test[nominal_features]])\nX_full_dummies = pd.get_dummies(X_full[nominal_features], dtype=int)\nX_dummies = X_full_dummies.loc[0:1460].copy()\nX_test_dummies = X_full_dummies.loc[1460:].copy()\nX.drop(nominal_features, axis=1, inplace=True)\nX_test.drop(nominal_features, axis=1, inplace=True)\nX = X.join(X_dummies)\nX_test = X_test.join(X_test_dummies)\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_3.csv'))\n\n# # na_count = X.isnull().sum()\n# # na_count[na_count > 0].sort_values(ascending=False)\n\n\nprint('Competition Score for this model is: 15039.19075')","21c9358f":"train_data = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\ntest_data = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain_data.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train_data['SalePrice']\ntrain_data.drop(['SalePrice'], axis=1, inplace=True)\n\nX_concat = pd.concat([train_data, test_data])\n\nnum_features = list(X_concat.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X_concat.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n\n# for ordinal features, replace all Nan values with 'NA' ( which will be later converted to zero)\nfor col in ordinal_features:\n    X_concat[col].fillna(value='NA', inplace=True)\n\n# for features to be one-hot encoded, will make all 'None' and 'NA' be Nan\nfor col in nominal_features:\n    X_concat[col].replace(['None', 'NA'], pd.NA, inplace=True)\n\n# here nan is because there is no data\nfor col in ['MasVnrArea', 'GarageYrBlt']:\n    X_concat[col].fillna(0, inplace=True)\n\n# there should be data, but was not recorded\nX_concat['LotFrontage'].fillna(X_concat['LotFrontage'].mean(), inplace=True)\n\nfor col in ordinal_features:\n    X_concat[col] = X_concat[col].map(ordinal_mapping)\n\n# covert remaining categorical features (one-hot-features) to number\nX_dummies = pd.get_dummies(X_concat[nominal_features], dtype=int)\nX_concat.drop(nominal_features, axis=1, inplace=True)\nX_concat = X_concat.join(X_dummies)\nX = X_concat.loc[0:1460].copy()\nX_test = X_concat.loc[1461:].copy()\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_4.csv'))\n\nprint('Competition Score for this model is: 15266.01175')","e13b12e6":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\nX = train.drop(['SalePrice'], axis=1)\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nnominal_features = [f for f in cat_features if f not in ordinal_features]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\n\n\n# for ordinal features, replace all Nan values with 'NA' ( which will be later converted to zero)\nX[ordinal_features].apply(lambda x: x.fillna(value='NA', inplace=True))\nX_test[ordinal_features].apply(lambda x: x.fillna(value='NA', inplace=True))\n\n# for features to be one-hot encoded, will make all 'None' and 'NA' be Nan\nX[nominal_features].apply(lambda x: x.replace(['None', 'NA'], pd.NA, inplace=True))\nX_test[nominal_features].apply(lambda x: x.replace(['None', 'NA'], pd.NA, inplace=True))\n\n# here nan is because there is no data\nfeatures_nan_zero = ['MasVnrArea', 'GarageYrBlt']\nX[features_nan_zero].apply(lambda x: x.fillna(0, inplace=True))\nX_test[features_nan_zero].apply(lambda x: x.fillna(0, inplace=True))\n\n# there should be data, but was not recorded\nX['LotFrontage'].fillna(X['LotFrontage'].mean(), inplace=True)\nX_test['LotFrontage'].fillna(X['LotFrontage'].mean(), inplace=True)\n\nX[ordinal_features] = X[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\nX_test[ordinal_features] = X_test[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n\n# covert remaining categorical features (one-hot-features) to number\nX_full = pd.concat([X[nominal_features], X_test[nominal_features]])\nX_full_dummies = pd.get_dummies(X_full[nominal_features])\nX_dummies = X_full_dummies.loc[0:1460].copy()\nX_test_dummies = X_full_dummies.loc[1460:].copy()\nX.drop(nominal_features, axis=1, inplace=True)\nX_test.drop(nominal_features, axis=1, inplace=True)\nX = X.join(X_dummies)\nX_test = X_test.join(X_test_dummies)\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_5.csv'))\n\nprint('Competition Score for this model is: 14909.98007')","0bcc78d6":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\nX = train.drop(['SalePrice'], axis=1)\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nnominal_features = [f for f in cat_features if f not in ordinal_features]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\n\nfor df in [X, X_test]:\n    # fixing na issue\n    df[ordinal_features].apply(lambda x: x.fillna(value='NA', inplace=True))\n    df[nominal_features].apply(lambda x: x.replace(['None', 'NA'], pd.NA, inplace=True))\n    df[['MasVnrArea', 'GarageYrBlt']].apply(lambda x: x.fillna(0, inplace=True))\n    df['LotFrontage'].fillna(df['LotFrontage'].mean(), inplace=True)\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n    # generating new features\n    df['total_surface_area'] = df['1stFlrSF'] + df['2ndFlrSF']\n    df['total_baths'] = df['FullBath'] + df['HalfBath']\n    df['total_bsmt_finish'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    df['total_bsmt_baths'] = df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['number_sold_same_month'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\n#     df['rolling'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold','number_sold_same_month'])['number_sold_same_month'].transform(lambda x: x.rolling(3).sum())\n#     print(df.sort_values(by=['Neighborhood', \"YrSold\", 'MoSold']).groupby(['Neighborhood', \"YrSold\", 'MoSold','number_sold_same_month'])[['Neighborhood', \"YrSold\", 'MoSold','number_sold_same_month','rolling']].head(10))\n#     for key, value in df.groupby(['Neighborhood', \"YrSold\", 'MoSold']):\n#         print(key.rolling(3))\n#         print(value[['number_sold_same_month','MoSold']])\n#     print(df.groupby(['Neighborhood', \"YrSold\"])[['MoSold','number_sold_same_month']].rolling(3).sum())\n#     print(df[['number_sold_same_month', \"YrSold\", 'MoSold']].sort_values(by=['MoSold']))\n\n# covert remaining categorical features (one-hot-features) to number\nX_full = pd.concat([X[nominal_features], X_test[nominal_features]])\nX_full_dummies = pd.get_dummies(X_full[nominal_features])\nX_dummies = X_full_dummies.loc[0:1460].copy()\nX_test_dummies = X_full_dummies.loc[1460:].copy()\nX.drop(nominal_features, axis=1, inplace=True)\nX_test.drop(nominal_features, axis=1, inplace=True)\nX = X.join(X_dummies)\nX_test = X_test.join(X_test_dummies)\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_6.csv'))\n\nprint('Competition Score for this model is: 14597.31148')","1fc490c6":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice'].copy()\nX = train.drop(['SalePrice'], axis=1).copy()\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\nnum_features.remove('MSSubClass')\n\ncat_features = list(X.select_dtypes(include=['object']).columns)\ncat_features.append('MSSubClass')\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nnominal_features = [f for f in cat_features if f not in ordinal_features]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\n\n# plt.figure(figsize=(14,12))\n# correlation = train[num_features].corr()\n# sns.heatmap(correlation, mask = correlation <0.8, linewidth=0.5, cmap='Blues')\n# print(list(train[num_features]))\n\nfor df in [X, X_test]:\n    # fixing na issue\n    df[ordinal_features].apply(lambda x: x.fillna(value='NA', inplace=True))\n    df[nominal_features].apply(lambda x: x.replace(['None', 'NA'], pd.NA, inplace=True))\n    df[['MasVnrArea', 'GarageYrBlt']].apply(lambda x: x.fillna(0, inplace=True))\n    df['LotFrontage'].fillna(df['LotFrontage'].mean(), inplace=True)\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n    # generating new features\n    df['total_surface_area'] = df['1stFlrSF'] + df['2ndFlrSF']\n    df['total_baths'] = df['FullBath'] + df['HalfBath']\n    df['total_bsmt_finish'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    df['total_bsmt_baths'] = df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['number_sold_same_month'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\n    \n    df['Proch_Deck'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch'] +df['WoodDeckSF']\n    df['Proch_Deck_bin'] = df['Proch_Deck'].apply(lambda x: 1 if x > 0 else 0)\n    df.drop(['Proch_Deck'], axis=1, inplace=True)\n\n# covert remaining categorical features (one-hot-features) to number\nX_full = pd.concat([X[nominal_features], X_test[nominal_features]])\nX_full_dummies = pd.get_dummies(X_full[nominal_features])\nX_dummies = X_full_dummies.loc[0:1460].copy()\nX_test_dummies = X_full_dummies.loc[1460:].copy()\nX.drop(nominal_features, axis=1, inplace=True)\nX_test.drop(nominal_features, axis=1, inplace=True)\nX = X.join(X_dummies)\nX_test = X_test.join(X_test_dummies)\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_7.csv'))\n\nprint('Competition Score for this model is: 14560.28803')","e35a21bf":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\nX_test = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\n\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice'].copy()\nX = train.drop(['SalePrice'], axis=1).copy()\n\nnum_features = list(X.select_dtypes(exclude=['object']).columns)\ncat_features = list(X.select_dtypes(include=['object']).columns)\n\n# Numerical features\ndisc_features = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                     'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\ncont_features = [f for f in num_features if f not in disc_features]\n\n# Categorical features\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley'\n                       ]\nnominal_features = [f for f in cat_features if f not in ordinal_features]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\n\nX_test.iloc[1132,58] = 2007\n\nfor df in [X, X_test]:\n    # fillna for numerical features\n    df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\n    for feat in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', \n                 'MasVnrArea', 'GarageYrBlt', 'GarageCars', 'GarageArea']:\n        df[feat] = df[feat].fillna(0)\n    # fillna for categorical features\n    for feat in ['MSZoning', 'Utilities', 'Exterior1st', 'Electrical']:\n        df[feat] = df.groupby('MSSubClass')[feat].transform(lambda x: x.fillna(x.mode()[0]))\n    for feat in ['KitchenQual', 'Functional', 'SaleType']:\n        df[feat].fillna(df[feat].mode()[0], inplace=True)\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.fillna(value='NA'))\n    # convert ordinal features to numerical features\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n    # generating new features\n    df['total_baths'] = df['FullBath'] + df['HalfBath']\n    df['total_bsmt_finish'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    df['total_bsmt_baths'] = df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['proch_deck_area'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\n    df['proch_deck_binary'] = df['proch_deck_area'].apply(lambda x: 1 if x > 0 else 0)\n    df['sold_same_month'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\n    df['num_months_passed'] = (df['YrSold'] - 2006)*12 + df['MoSold']\n\n# covert remaining categorical features (one-hot-features) to number\nX_full = pd.concat([X[nominal_features], X_test[nominal_features]])\nX_full_dummies = pd.get_dummies(X_full[nominal_features])\nX_dummies = X_full_dummies.loc[0:1460].copy()\nX_test_dummies = X_full_dummies.loc[1460:].copy()\nX.drop(nominal_features, axis=1, inplace=True)\nX_test.drop(nominal_features, axis=1, inplace=True)\nX = X.join(X_dummies)\nX_test = X_test.join(X_test_dummies)\n\n# check model score\nprint(f\"Validation Score: {k_fold_xgboost(X, y, X_test, 'model_8_with_cross_val.csv',3)}\\n\")\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n# print('Validation Score', xgboost_model(X_train, X_valid, y_train, y_valid, X_test, 'model_8.csv'))\n","585974c9":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\ntrain.drop(['SalePrice'], axis=1, inplace=True)\ntrain_test = pd.concat([train, test])\n\n# Distinguishing features\ntrain_test['MSSubClass'] = train_test['MSSubClass'].astype(str)\nnum_features = list(train_test.select_dtypes(exclude=['object']).columns)\ncat_features = list(train_test.select_dtypes(include=['object']).columns)\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley',\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n# correcting wrong values\ntrain_test.iloc[2592,58] = 2007\n\n# missing values in numerical features\ntrain_test['LotFrontage'] = train_test.groupby('MSSubClass')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))\nfor feat in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea', 'GarageYrBlt', 'GarageCars', 'GarageArea']:\n    train_test[feat].fillna(0, inplace=True)\n    \n# missing values in categorical features\nfor feat in ['MSZoning', 'Utilities', 'Exterior1st', 'Electrical']:\n    train_test[feat] = train_test.groupby('MSSubClass')[feat].transform(lambda x: x.fillna(x.mode()[0]))\nfor feat in ['KitchenQual', 'Functional', 'SaleType']:\n    train_test[feat].fillna(train_test[feat].mode()[0], inplace=True)\ntrain_test[ordinal_features] = train_test[ordinal_features].apply(lambda x: x.fillna('NA'))\n\n# convert ordinal features to numbers\ntrain_test[ordinal_features] = train_test[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n\n# convert nominal features to numbers\ndummies = pd.get_dummies(train_test[nominal_features])\ntrain_test = train_test.join(dummies)\n                                                                                        \n# generating new features\ntrain_test['total_surface_area'] = train_test['1stFlrSF'] + train_test['2ndFlrSF']\ntrain_test['total_baths'] = train_test['FullBath'] + train_test['HalfBath']\ntrain_test['total_bsmt_finish'] = train_test['BsmtFinSF1'] + train_test['BsmtFinSF2']\ntrain_test['total_bsmt_baths'] = train_test['BsmtFullBath'] + train_test['BsmtHalfBath']\ntrain_test['proch_deck_area'] = train_test['OpenPorchSF'] + train_test['EnclosedPorch'] + train_test['ScreenPorch'] +train_test['WoodDeckSF']\ntrain_test['proch_deck_binary'] = train_test['proch_deck_area'].apply(lambda x: 1 if x > 0 else 0)\ntrain_test['sold_same_month'] = train_test.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\ntrain_test['num_months_passed'] = (train_test['YrSold'] - 2006)*12 + train_test['MoSold']\n\n# drop unuseful features\ntrain_test.drop(nominal_features, axis=1, inplace=True)\n\nX = train_test.loc[0:1460]\nX_test = train_test.loc[1461:]\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_9.csv'))\n\nprint('Competition Score for this model is: ')","83a10f96":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\ny = train['SalePrice']\ntrain.drop(['SalePrice'], axis=1, inplace=True)\n\n# Distinguishing features\nfor df in [train, test]:\n    df['MSSubClass'] = df['MSSubClass'].astype(str)\n    \nnum_features = list(train.select_dtypes(exclude=['object']).columns)\ncat_features = list(train.select_dtypes(include=['object']).columns)\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley'\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n# correcting wrong values\ntest.iloc[1132,58] = 2007\n\n# missing values in numerical features\nfor df in [train, test]:\n    df['LotFrontage'] = df.groupby('MSSubClass')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))\n    for feat in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea', 'GarageYrBlt', 'GarageCars', 'GarageArea']:\n        df[feat] = df[feat].fillna(0)\n    \n    # missing values in categorical features\n    for feat in ['MSZoning', 'Utilities', 'Exterior1st', 'Electrical']:\n        df[feat] = df.groupby('MSSubClass')[feat].transform(lambda x: x.fillna(x.mode()[0]))\n    for feat in ['KitchenQual', 'Functional', 'SaleType']:\n        df[feat] = df[feat].fillna(df[feat].mode()[0])\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.fillna('NA'))\n\n    # convert ordinal features to numbers\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n                                                                                        \n    # generating new features\n    df['total_surface_area'] = df['1stFlrSF'] + df['2ndFlrSF']\n    df['total_baths'] = df['FullBath'] + df['HalfBath']\n    df['total_bsmt_finish'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    df['total_bsmt_baths'] = df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['proch_deck_area'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\n    df['proch_deck_binary'] = df['proch_deck_area'].apply(lambda x: 1 if x > 0 else 0)\n    df['sold_same_month'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\n    df['num_months_passed'] = (df['YrSold'] - 2006)*12 + df['MoSold']\n\n# convert nominal features to numbers\ntrain_test = pd.concat([train, test])\ndummies = pd.get_dummies(train_test[nominal_features])\ntrain_test = train_test.join(dummies)\ntrain_test = train_test.drop(nominal_features, axis=1)\n# single_val_cols = [col for col in train_test.columns if train_test[col].value_counts().max()\/len(train_test)>0.998]\n# train_test.drop(single_val_cols, axis=1, inplace=True)\n\n\nX = train_test.loc[0:1460]\nX_test = train_test.loc[1461:]\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint(xgb_model(X_train, X_valid, y_train, y_valid, X_test, 'model_10.csv'))\n\nprint('Competition Score for this model is: ')","b03bda91":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\n\ny = train['SalePrice']\ntrain.drop(['SalePrice'], axis=1, inplace=True)\n\n# Distinguishing features\nfor df in [train, test]:\n    df['MSSubClass'] = df['MSSubClass'].astype(str)\n    \nnum_features = list(train.select_dtypes(exclude=['object']).columns)\ncat_features = list(train.select_dtypes(include=['object']).columns)\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley'\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n# correcting wrong values\ntest.iloc[1132,58] = 2007\n\n# missing values in numerical features\nfor df in [train, test]:\n    df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\n    for feat in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea', 'GarageYrBlt', 'GarageCars', 'GarageArea']:\n        df[feat] = df[feat].fillna(0)\n    \n    # missing values in categorical features\n    for feat in ['MSZoning', 'Utilities', 'Exterior1st', 'Electrical']:\n        df[feat] = df.groupby('MSSubClass')[feat].transform(lambda x: x.fillna(x.mode()[0]))\n    for feat in ['KitchenQual', 'Functional', 'SaleType']:\n        df[feat] = df[feat].fillna(df[feat].mode()[0])\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.fillna('NA'))\n\n    # convert ordinal features to numbers\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n                                                                                        \n    # generating new features\n    df['total_surface_area'] = df['1stFlrSF'] + df['2ndFlrSF']\n    df['total_baths'] = df['FullBath'] + df['HalfBath']\n    df['total_bsmt_finish'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    df['total_bsmt_baths'] = df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['proch_deck_area'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\n    df['proch_deck_binary'] = df['proch_deck_area'].apply(lambda x: 1 if x > 0 else 0)\n    df['sold_same_month'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\n    df['num_months_passed'] = (df['YrSold'] - 2006)*12 + df['MoSold']\n\n# check_correlaton(train, y)\n    \n# convert nominal features to numbers\ntrain_test = pd.concat([train, test])\ndummies = pd.get_dummies(train_test[nominal_features])\ntrain_test = train_test.join(dummies)\ntrain_test = train_test.drop(nominal_features, axis=1)\n\nX = train_test.loc[0:1460]\nX_test = train_test.loc[1461:]\n\n# check model score\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint('XGBoost Score:', xgboost_model(X_train, X_valid, y_train, y_valid, X_test, 'model_11_xgb.csv'))\nprint('RandomForest Score:', random_forest_model(X_train, X_valid, y_train, y_valid, X_test, 'model_11_rf.csv'))\nprint('CatBoost Score:', catboost_model(X_train, X_valid, y_train, y_valid, X_test, 'model_11_cb.csv'))\n\n\nprint('Competition best Score for this model is: ')","b46a2740":"train = pd.read_csv('..\/input\/homedataformlcourse\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/homedataformlcourse\/test.csv', index_col=0)\ntrain.dropna(subset=['SalePrice'], axis=0, inplace=True)\n\ny = train['SalePrice']\ntrain.drop(['SalePrice'], axis=1, inplace=True)\n\n# Distinguishing features\nfor df in [train, test]:\n    df['MSSubClass'] = df['MSSubClass'].astype(str)\n    \nnum_features = list(train.select_dtypes(exclude=['object']).columns)\ncat_features = list(train.select_dtypes(include=['object']).columns)\nordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','BsmtExposure',\n                        'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Fence',\n                        'CentralAir', 'Street', 'Alley'\n                       ]\nordinal_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,                                # ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual','GarageCond', 'PoolQC']\n                   'Av':2, 'Mn':1, 'No':0,                                                        # ['BsmtExposure']\n                   'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1,                                            # ['LotShape']\n                   'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1,                                            # ['LandContour']\n                   'Pave':2, 'Grvl': 1,                                                           # ['Street', 'Alley']\n                   'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,                                   # ['Utilities']\n                   'Gtl':3, 'Mod':2, 'Sev':1,                                                     # ['LandSlope']\n                   'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1,                          # ['BsmtFinType1', 'BsmtFinType2']\n                   'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1,    # ['Functional']\n                   'Fin':3, 'RFn':2, 'Unf':1,                                                     # ['GarageFinish']\n                   'Y':3, 'P':2, 'N':1,                                                           # ['PavedDrive']\n                   'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1,                                      # ['Fence']\n                  }\nnominal_features = [f for f in cat_features if f not in ordinal_features]\n\n# correcting wrong values\ntest.iloc[1132,58] = 2007\n\n# missing values in numerical features\nfor df in [train, test]:\n    df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\n    for feat in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea', 'GarageYrBlt', 'GarageCars', 'GarageArea']:\n        df[feat] = df[feat].fillna(0)\n    \n    # missing values in categorical features\n    for feat in ['MSZoning', 'Utilities', 'Exterior1st', 'Electrical']:\n        df[feat] = df.groupby('MSSubClass')[feat].transform(lambda x: x.fillna(x.mode()[0]))\n    for feat in ['KitchenQual', 'Functional', 'SaleType']:\n        df[feat] = df[feat].fillna(df[feat].mode()[0])\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.fillna('NA'))\n\n    # convert ordinal features to numbers\n    df[ordinal_features] = df[ordinal_features].apply(lambda x: x.map(ordinal_mapping))\n                                                                                        \n    # generating new features\n    df['total_baths'] = df['FullBath'] + df['HalfBath']\n    df['total_bsmt_finish'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n    df['total_bsmt_baths'] = df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['sold_same_month'] = df.groupby(['Neighborhood', \"YrSold\", 'MoSold'])['MoSold'].transform('count')\n    df['num_months_passed'] = (df['YrSold'] - 2006)*12 + df['MoSold']\n    df['proch_deck_area'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['3SsnPorch'] + df['WoodDeckSF']\n    df['proch_deck_binary'] = df['proch_deck_area'].apply(lambda x: 1 if x > 0 else 0)\n    \n    # Drop unuseful columns\n    df.drop(['YrSold', 'MoSold', 'proch_deck_area'], axis=1, inplace=True)\n\n# check_correlaton(train, y)\n    \n# convert nominal features to numbers\ntrain_test = pd.concat([train, test])\ndummies = pd.get_dummies(train_test[nominal_features])\ntrain_test = train_test.join(dummies)\ntrain_test = train_test.drop(nominal_features, axis=1)\n\nX = train_test.loc[0:1460]\nX_test = train_test.loc[1461:]\n\n# check model score\nprint('original data Score:', k_fold_xgboost(X, y, X_test, 'model_12.csv',3))\nrand_perm = np.random.permutation(len(X))\nX_shufl = X.iloc[rand_perm].reset_index().drop(['Id'], axis=1)\ny_shufl = y.iloc[rand_perm].reset_index().drop(['Id'], axis=1)\nprint('shuffled data Score:', k_fold_xgboost(X_shufl, y_shufl, X_test, 'model_12_shuffled.csv',3))","f63e7db0":"# from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n# from sklearn.ensemble import GradientBoostingRegressor\n# from sklearn.svm import SVR\n# from sklearn.pipeline import make_pipeline\n# from sklearn.preprocessing import RobustScaler\n# from sklearn.model_selection import KFold, cross_val_score\n# from sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error\n# from mlxtend.regressor import StackingCVRegressor\n# from xgboost import XGBRegressor\n# from datetime import datetime\n\n# def xval_rmse_scoring(f_model, f_X, f_y, f_cv):\n#     \"\"\"\n#     Returns a machine learning model cross-validated score based on the Root Mean Squared Error (RMSE) metric.\n    \n#     Keyword arguments:\n    \n#     f_model     Machine learning model.\n#                 Object instance\n#     f_X_        Tensor containing features for modeling.\n#                 Pandas dataframe\n#     f_y         Tensor containing targets for modeling.\n#                 Pandas series\n#     f_cv        Cross-validation splitting strategy.\n#                 Please refer to scikit-learn's model_selection cross_val_score for further information.\n#     \"\"\"\n#     return np.sqrt(-cross_val_score(f_model, f_X, f_y,\n#                                     scoring='neg_mean_squared_error',\n#                                     cv=f_cv))\n\n\n\n\n# kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# elasticnet_alphas = [5e-5, 1e-4, 5e-4, 1e-3]\n# elasticnet_l1ratios = [0.8, 0.85, 0.9, 0.95, 1]\n# elasticnet = make_pipeline(RobustScaler(),\n#                            ElasticNetCV(max_iter=1e7, alphas=elasticnet_alphas,\n#                                         cv=kfolds, l1_ratio=elasticnet_l1ratios))\n\n# lasso_alphas = [5e-5, 1e-4, 5e-4, 1e-3]\n# lasso = make_pipeline(RobustScaler(),\n#                       LassoCV(max_iter=1e7, alphas=lasso_alphas,\n#                               random_state=42, cv=kfolds))\n\n# ridge_alphas = [13.5, 14, 14.5, 15, 15.5]\n# ridge = make_pipeline(RobustScaler(),\n#                       RidgeCV(alphas=ridge_alphas, cv=kfolds))\n\n# gradb = GradientBoostingRegressor(n_estimators=6000, learning_rate=0.01,\n#                                   max_depth=4, max_features='sqrt',\n#                                   min_samples_leaf=15, min_samples_split=10,\n#                                   loss='huber', random_state=42)\n\n# svr = make_pipeline(RobustScaler(),\n#                     SVR(C=20, epsilon=0.008, gamma=0.0003))\n\n# xgboost = XGBRegressor(learning_rate=0.01, n_estimators=6000,\n#                        max_depth=3, min_child_weight=0,\n#                        gamma=0, subsample=0.7,\n#                        colsample_bytree=0.7,\n#                        objective='reg:squarederror', nthread=-1,\n#                        scale_pos_weight=1, seed=27,\n#                        reg_alpha=0.00006, random_state=42)\n\n# stackcv = StackingCVRegressor(regressors=(elasticnet, gradb, lasso, \n#                                           ridge, svr, xgboost),\n#                               meta_regressor=xgboost,\n#                               use_features_in_secondary=True)\n\n# print('Individual model scoring on cross-validation\\n')\n# print(f'{\"Model\":<20}{\"RMSE mean\":>12}{\"RMSE stdev\":>12}\\n')\n\n# score = xval_rmse_scoring(elasticnet, X_train, y_train, kfolds)\n# print(f'{\"1. ElasticNetCV\":<20}{score.mean():>12.4f}{score.std():>12.4f}')\n\n# score = xval_rmse_scoring(lasso, X_train, y_train, kfolds)\n# print(f'{\"2. LassoCV\":<20}{score.mean():>12.4f}{score.std():>12.4f}')\n\n# score = xval_rmse_scoring(ridge, X_train, y_train, kfolds)\n# print(f'{\"3. RidgeCV\":<20}{score.mean():>12.4f}{score.std():>12.4f}')\n\n# score = xval_rmse_scoring(gradb, X_train, y_train, kfolds)\n# print(f'{\"4. GradientBoosting\":<20}{score.mean():>12.4f}{score.std():>12.4f}')\n\n# score = xval_rmse_scoring(svr, X_train, y_train, kfolds)\n# print(f'{\"5. SVR\":<20}{score.mean():>12.4f}{score.std():>12.4f}')\n\n# score = xval_rmse_scoring(xgboost, X_train, y_train, kfolds)\n# print(f'{\"6. XGBoost\":<20}{score.mean():>12.4f}{score.std():>12.4f}')\n\n# print('\\nFitting individual models to the training set\\n')\n# print(f'{\"1. ElasticNetCV...\":<20}')\n# elastic_fit = elasticnet.fit(X_train, y_train)\n# print(f'{\"2. LassoCV...\":<20}')\n# lasso_fit = lasso.fit(X_train, y_train)\n# print(f'{\"3. RidgeCV...\":<20}')\n# ridge_fit = ridge.fit(X_train, y_train)\n# print(f'{\"4. GradientBoosting...\":<20}')\n# gradb_fit = gradb.fit(X_train, y_train)\n# print(f'{\"5. SVR...\":<20}')\n# svr_fit = svr.fit(X_train, y_train)\n# print(f'{\"6. XGBoost...\":<20}')\n# xgb_fit = xgboost.fit(X_train, y_train)\n\n# print('\\nFitting the stacking model to the training set\\n')\n# print(f'{\"StackingCV...\":<20}')\n# stackcv_fit = stackcv.fit(np.array(X_train), np.array(y_train))\n\n# blend_weights = [0.11, 0.05, 0.00, 0.14, 0.43, 0.00, 0.27]\n\n# y_train = np.expm1(y_train)\n# y_pred = np.expm1((blend_weights[0] * elastic_fit.predict(X_train)) +\n#                   (blend_weights[1] * lasso_fit.predict(X_train)) +\n#                   (blend_weights[2] * ridge_fit.predict(X_train)) +\n#                   (blend_weights[3] * svr_fit.predict(X_train)) +\n#                   (blend_weights[4] * gradb_fit.predict(X_train)) +\n#                   (blend_weights[5] * xgb_fit.predict(X_train)) +\n#                   (blend_weights[6] * stackcv_fit.predict(np.array(X_train))))\n\n# rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n# rmsle = np.sqrt(mean_squared_log_error(y_train, y_pred))\n# mae = mean_absolute_error(y_train, y_pred)\n# print('\\nBlend model performance on the training set\\n')\n# print(f'{\"RMSE\":<7} {rmse:>15.8f}')\n# print(f'{\"RMSLE\":<7} {rmsle:>15.8f}')\n# print(f'{\"MAE\":<7} {mae:>15.8f}')\n\n# print('\\nGenerating submission')\n# submission = pd.read_csv('submission.csv')\n# submission.iloc[:, 1] = np.round_(np.expm1((blend_weights[0] * elastic_fit.predict(X_test)) +\n#                                            (blend_weights[1] * lasso_fit.predict(X_test)) +\n#                                            (blend_weights[2] * ridge_fit.predict(X_test)) +\n#                                            (blend_weights[3] * svr_fit.predict(X_test)) +\n#                                            (blend_weights[4] * gradb_fit.predict(X_test)) +\n#                                            (blend_weights[5] * xgb_fit.predict(X_test)) +\n#                                            (blend_weights[6] * stackcv_fit.predict(np.array(X_test)))))\n# submission.to_csv('..\/output\/submission_new.csv', index=False)\n# print('Submission saved')","c16d83e9":"# # (1)\n# # Analysis of 'LotArea' feature, and checking for outliers\n# feature = 'LotArea'\n# print('Mean =', int(train[feature].mean()))\n# print('Median =', int(train[feature].median()))\n# print('Mode =', int(train[feature].mode()))\n# fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n# sns.distplot(train[feature].dropna(), ax=axes[0, 0], kde=False)\n# sns.boxplot(train[feature].dropna(), ax=axes[0, 1])\n# sns.regplot(x=train[feature], y=train['SalePrice'], ax=axes[0, 2])\n# sns.scatterplot(x=train[feature], y=train['LotFrontage'], ax=axes[1,0])\n# sns.scatterplot(x=train[feature], y=train['TotalBsmtSF'], ax=axes[1,1])\n# sns.scatterplot(x=train[feature], y=train['1stFlrSF'], ax=axes[1,2])\n# sns.scatterplot(x=train[feature], y=train['GrLivArea'], ax=axes[2,0])\n# sns.scatterplot(x=train[feature], y=train['TotRmsAbvGrd'], ax=axes[2,1])\n# sns.scatterplot(x=train[feature], y=train['GarageArea'], ax=axes[2,2])\n# fig.tight_layout(pad=3.0)\n\n# conclusion, outliers (215245) probably is wrong data, and should be removed.\n\n# # (2)\n# feature = 'MoSold' \n# print('Mean =', int(train[feature].mean()))\n# print('Median =', int(train[feature].median()))\n# print('Mode =', int(train[feature].mode()))\n# print('Null values =', train[feature].isnull().sum())\n# # print('highest % of any value =', int(train[feature].value_counts()[0]\/len(train[feature])*100))\n# fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n# sns.distplot(train[feature].dropna(), ax=axes[0, 0], kde=False)\n# sns.boxplot(train[feature].dropna(), ax=axes[0, 1])\n# sns.regplot(x=train[feature], y=train['SalePrice'], ax=axes[0, 2])\n# # sns.scatterplot(x=train[feature], y=train['GarageCars'], ax=axes[1,0])\n# # sns.scatterplot(x=train[feature], y=train['1stFlrSF'], ax=axes[1,1])\n# fig.tight_layout(pad=3.0)\n\n# # (3)\n# feature = 'SaleType'\n# print('Null values =', train[feature].isnull().sum())\n# print('highest % of any value =', int(train[feature].value_counts()[0]\/len(train[feature])*100))\n# fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n# sns.countplot(train[feature], ax=axes[0])\n# sns.scatterplot(x=train[feature], y=train['SalePrice'], ax=axes[1])\n# fig.tight_layout(pad=3.0)\n\n# # (4)\n# total_height = 4*len(num_features)\n# fig, axes = plt.subplots(len(num_features), 3, figsize=(16, total_height))\n# for i, nf in enumerate(num_features):\n#     sns.distplot(train[nf].dropna(), ax=axes[i, 0], kde=False)\n#     sns.boxplot(y=train[nf].dropna(), ax=axes[i, 1])\n#     sns.regplot(x=train[nf], y=train['SalePrice'], ax=axes[i, 2])\n# fig.tight_layout()","97fcbf12":"# Notes\n* [18-aug-2020] I belive that after generating a new future that captures the year and month together, ['YrSold', 'MoSold']  features should be removed,  because when doing regression on months, you get wrong results, because month=2 in 2008 for example, should not be considered the same as month=2 in 2007. but when I did remove them, the result became worse, i though i should check other regression techniques to see what happens","93e30867":"# (2)\n# play with filling Nan","261041ab":"# (1)\n# Baseline Data","300b8512":"# (3)\n# Further improvement on the features","aaf01720":"# model_8","c987d563":"# Model_12\nadding cross validation","ef2041a4":"# Model_9","5b5ebf53":"# Charts","d347eb16":"# Model_11\nadding more algorithm","3eadc1f4":"# model_10","e9c7d839":"# (6)\n# Model_6\nAdding Features","be947b03":"# (4)\n# improvement on missings of nominal feature","e6496abe":"# Model_7","5cb9716e":"# (5)\n# Model 5","9442e360":"# Advanced regression"}}