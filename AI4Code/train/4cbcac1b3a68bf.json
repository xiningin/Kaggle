{"cell_type":{"cc3c1da9":"code","a0d44336":"code","2515f626":"code","b8687b90":"code","ad4b562b":"code","40fe30a0":"code","ea17d091":"code","5a9325c2":"code","4be0cdf0":"code","1f1b3051":"code","689993ae":"code","df032d2f":"code","a44324e1":"code","d44c47ed":"code","7884f359":"markdown","fa64e134":"markdown","5044a1fa":"markdown","7a8c48fe":"markdown"},"source":{"cc3c1da9":"# importing important libraries\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression","a0d44336":"# reading data\ndata = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndata.head()","2515f626":"# getting more info about data\ndata.info()","b8687b90":"# checking for null values\ndata.isna().sum()","ad4b562b":"# what is there in dignosis column\ndata['diagnosis'].unique()","40fe30a0":"data = data.drop(['id', 'Unnamed: 32'], axis=1)\n","ea17d091":"# splitting the data into dependent(dignosis) and independent variables and than splitting the data\ny = data['diagnosis'].copy()\nX = data.drop('diagnosis', axis=1).copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)","5a9325c2":"# standard scaling\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)","4be0cdf0":"X_train","1f1b3051":"n_components = 8\n\npca = PCA(n_components=n_components)\npca.fit(X_train)\n\npc_train = pd.DataFrame(pca.transform(X_train), columns=[\"PC\" + str(i + 1) for i in range(n_components)])\npc_test = pd.DataFrame(pca.transform(X_test), columns=[\"PC\" + str(i + 1) for i in range(n_components)])","689993ae":"pc_train","df032d2f":"plt.figure(figsize=(16, 10))\nsns.barplot(x=pca.explained_variance_ratio_, y=[\"PC\" + str(i + 1) for i in range(n_components)], orient='h', palette='husl')\nplt.xlim(0., 1.)\nplt.xlabel(\"Proportion of Variance in Original Data\")\nplt.title(\"Principal Component Variance\")\nplt.show()","a44324e1":"# On the original data\noriginal_model = LogisticRegression()\noriginal_model.fit(X_train, y_train)\n\nprint(\"Model Accuracy (Original Data): {:.5f}%\".format(original_model.score(X_test, y_test) * 100))","d44c47ed":"# On the principal components\npca_model = LogisticRegression()\npca_model.fit(pc_train, y_train)\n\nprint(\"Model Accuracy (PCA Data): {:.5f}%\".format(pca_model.score(pc_test, y_test) * 100))","7884f359":"# Training\/Results\n","fa64e134":"# ****Principal Component Analysis (Dimensionality Reduction)****\n","5044a1fa":"# Preprocessing","7a8c48fe":"**Breast Cancer Classification**\nGiven data about breast cancer in Wisconsin, let's try to predict if a given tumor is malignant.\n\nWe will use a logistic regression model to make our predictions. We will use principal component analysis to reduce the dimension of the data and show that the same results can be achieved with a smaller number of features."}}