{"cell_type":{"6469045c":"code","1a747bde":"code","5fac372b":"code","fa1c682c":"code","ce904d43":"code","a89b9e15":"code","37a2b40f":"code","3d0a02b2":"code","4383557a":"code","e0cab434":"code","f0a19f08":"code","cd3c445c":"code","3ca4e110":"code","fbbe20cf":"code","9587dd2b":"code","40b64408":"code","ddc2d600":"code","cf059586":"code","ae87f21d":"code","671e57c9":"code","d2717df7":"code","4d628670":"code","5dad2e5a":"code","2207dedd":"markdown","d7d8db1d":"markdown","5941e5a5":"markdown","52a76135":"markdown","ac738880":"markdown","9d52ec0f":"markdown","7ae16d51":"markdown"},"source":{"6469045c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n    \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a747bde":"pip install pandas_profiling","5fac372b":"import pandas as pd\nfrom pandas_profiling import ProfileReport\nimport numpy as ny \nimport seaborn as sns \nimport matplotlib.pyplot as plt","fa1c682c":"data = pd.read_csv(\"\/kaggle\/input\/wine-quality-dataset\/WineQT.csv\")\n","ce904d43":"data.head()","a89b9e15":"data.describe(include=\"all\")","37a2b40f":"data.isnull().sum()","3d0a02b2":"data.info()","4383557a":"data.shape","e0cab434":"prolife = ProfileReport(data)\n","f0a19f08":"prolife.to_file(\"data.html\")","cd3c445c":"data[\"best quality\"] = [1 if x>=6 else 0 for x in data.quality]","3ca4e110":"data.head()","fbbe20cf":"df = data.drop(\"Id\",axis=1)","9587dd2b":"df = new_df.drop(\"quality\",axis=1)","40b64408":"df.head()","ddc2d600":"x = df.drop(\"best quality\", axis=1)\ny = df[\"best quality\"]","cf059586":"y.head()","ae87f21d":"from sklearn.model_selection import train_test_split\nx_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.33, random_state=35)","671e57c9":"#importing module\nfrom sklearn.preprocessing import MinMaxScaler\n#creating normalization object \nnorm = MinMaxScaler()\n#fit data \nnorm_fit = norm.fit(x_train)\nnew_xtrain = norm_fit.transform(x_train)\nnew_xtest = norm_fit.transform(x_test)\n#display\nprint(new_xtrain)","d2717df7":"from sklearn import tree\n\n# creating constructor \nDTclf = tree.DecisionTreeClassifier()\n\n#fit data\nDTclf = DTclf.fit(new_xtrain,y_train)\n\n#predicting score\nDTscore = DTclf.score(new_xtest,y_test)\nprint(\"score of the model:\",DTscore)\n","4d628670":"from sklearn.ensemble import RandomForestClassifier\n\n# creating constructor \nRFclf = RandomForestClassifier()\n\n#fit data\nRFclf = RFclf.fit(new_xtrain,y_train)\n\n#predicting score\nRFscore = RFclf.score(new_xtest,y_test)\nprint(\"score of the model:\",RFscore)\n","5dad2e5a":"from sklearn.linear_model import LogisticRegression\n\n# creating constructor \nLRclf = LogisticRegression()\n\n#fit data\nLRclf = LRclf.fit(new_xtrain,y_train)\n\n#predicting score\nLRscore = LRclf.score(new_xtest,y_test)\nprint(\"score of the model:\",LRscore)\n","2207dedd":"# Machine learning ","d7d8db1d":"**Normalization**","5941e5a5":"1. **Decision Tree**\n1. **Logisitic regression**\n1. **Random forest**","52a76135":"# Applying Model","ac738880":"# Suggestions to improve my model are welcomed","9d52ec0f":"We do not have any null value ","7ae16d51":"\n# > **Importing necessary library for understanding data and for visualization**\n\n"}}