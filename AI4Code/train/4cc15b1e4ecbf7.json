{"cell_type":{"56745c91":"code","2e10769c":"code","77f40b98":"code","aeac061d":"code","54718a15":"code","73264f2c":"code","6842ae2a":"code","70c03170":"code","e63583dd":"code","397c5208":"code","6adf867e":"code","e5eca4d9":"code","199707ea":"code","5a85f4ff":"code","9899e320":"code","621cf836":"code","6a4a0ec4":"code","1fe81f74":"code","c74e4809":"code","040c8518":"code","f64d7dbf":"code","f615eb2f":"code","032ae6e4":"code","237a5bc1":"code","a555b4d7":"code","c294d636":"code","d036e45d":"code","9550f01c":"code","cb7fb61a":"code","aa8cb66d":"code","88072e39":"code","7ca1bb77":"code","5bc56e0e":"code","63a59bf5":"code","edb71c01":"code","90fd1dd6":"code","c1d78cd3":"code","3171ac35":"code","f8f61802":"code","45fc7f83":"code","156a4e88":"code","6da3ebc8":"code","618540d0":"code","69523143":"code","b6de80a9":"code","cc5255a6":"code","22d9467a":"code","fa6f569c":"code","8ec9b55e":"code","c7763e42":"code","a0c045a2":"code","a5f7875e":"code","4fcd437b":"code","cd039d82":"code","8c0aaf1f":"code","90aab84f":"code","4a2984da":"code","9ec391d2":"markdown","30bf5b1a":"markdown","1f39907d":"markdown","a54b75b9":"markdown","689cba3e":"markdown","870d3adb":"markdown","dab052e7":"markdown","41b8b851":"markdown","46f43443":"markdown"},"source":{"56745c91":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\nimport xgboost as xgb\n%matplotlib inline\n\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    GradientBoostingClassifier,\n    AdaBoostClassifier,\n    ExtraTreesClassifier\n)\nfrom sklearn.tree import (DecisionTreeClassifier)\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.model_selection import train_test_split","2e10769c":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nPassengerId = test['PassengerId']\n\ntrain.head(2)","77f40b98":"train.shape","aeac061d":"full_data = [train, test]\n# \u65b0\u3057\u3044\u7279\u5fb4\u91cf\u300c\u5ba2\u5ba4\u306e\u6709\u7121 Has_Cabin\u300d \u5ba2\u5ba4\u3092\u53d6\u3063\u3066\u3044\u308b\u5ba2\u3068\u53d6\u3063\u3066\u3044\u306a\u3044\u5ba2\u304c\u3044\u308b\ntrain['Has_Cabin'] = train['Cabin'].apply(lambda x:0 if type(x) == float else 1)\ntest['Has_Cabin'] = test['Cabin'].apply(lambda x:0 if type(x) == float else 1)\n\n# (lambda x:0 if type(x) == float else 1)\u306e\u4e2d\u8eab\n# a = np.nan\n# if(type(a) == float):\n#     print('NAN')\n# else:\n#     print('N')\n\n# \u6027\u5225\u3092\u30de\u30c3\u30d4\u30f3\u30b0\u3059\u308b\nfor dataset in full_data:\n    # \u5024\u306e\u629c\u3051\u3092\u5e73\u5747\u5024\u3067\u57cb\u3081\u308b\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n\n    # \u6027\u5225\u3092\u30de\u30c3\u30d4\u30f3\u30b0\n    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n    \n    dataset.loc[dataset['Age'] <= 16,'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32) ,'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48) ,'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64) ,'Age'] = 3\n    dataset.loc[dataset['Age'] > 64,'Age'] = 4;\n    \nfor dataset in full_data:\n    #\u5bb6\u65cf\u30b5\u30a4\u30ba\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1","54718a15":"train.head()","73264f2c":"drop_elements = ['PassengerId', 'Name', 'Ticket', 'Fare', 'Embarked', 'Cabin', 'SibSp', 'Parch']\n\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\ntrain.head()","6842ae2a":"# \u30d2\u30fc\u30c8\u30de\u30c3\u30d7\u3067\u76f8\u95a2\u95a2\u4fc2\u3092\u78ba\u8a8d\u3059\u308b\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14, 12))\nplt.title('Pearson Correlation of Feature', y=1.05, size=15)\n\n#train.corr() \u5404\u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u6307\u6570\u3092\u3060\u3059\u95a2\u6570\nsns.heatmap(train.astype(float).corr(), linewidth=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","70c03170":"ntrain = train.shape[0]\nntest = test.shape[0]\n\n# \u4e71\u6570\u306e\u56fa\u5b9a\u5024\nSEED = 0\n# \u4ea4\u5dee\u691c\u8a3c\u306e\u56de\u6570\nNFOLDS = 5\n#\u4ea4\u5dee\u691c\u8a3c\u3067\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u691c\u8a3c\u3057\u3066\u3001\u904e\u5b66\u7fd2\u304c\u8d77\u3053\u3089\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6c7a\u5b9a\u3059\u308b\nkf = KFold(n_splits=NFOLDS, random_state=SEED)\n\n# \u751f\u5b58\u3057\u305f\u304b\u3069\u3046\u304b\u306e\u30e9\u30d9\u30eb\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nX_train = train.values\nX_test = test.values","e63583dd":"forest = RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5)\nforest.fit(X_train, y_train)\nforest.score(X_train, y_train)","397c5208":"gbrt = GradientBoostingClassifier(random_state=0, n_estimators=500, max_depth=5)\ngbrt.fit(X_train, y_train)\n\ngbrt.score(X_train, y_train)","6adf867e":"svm = SVC(kernel='linear', C=0.025)\nsvm.fit(X_train, y_train)\nsvm.score(X_train, y_train)","e5eca4d9":"# \u30d8\u30eb\u30d1\u30fc\u95a2\u6570\nclass SklearnHelper(object):\n    def __init__(self, clf_model, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf_model = clf_model(**params)\n        \n    def train(self, X_train, y_train):\n        self.clf_model.fit(X_train, y_train)\n        \n    def predict(self, X):\n        return self.clf_model.predict(X)\n    \n    def fit(self, X, y):\n        self.clf_model.fit(X, y)\n        \n    def feature_importances(self, X, y):\n        return self.clf_model.fit(X, y).feature_importances_\n    \n    def print_feature_importances(self, X, y):\n        print(self.clf_model.fit(X, y).feature_importances_)\n        ","199707ea":"forest_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0 \n}\n\ngb_params = {\n    'n_estimators': 500,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'learning_rate': 0.1,\n    'verbose': 0\n}\n\nsvc_params = {\n    'kernel': 'linear',\n    'C': 0.025\n}\n\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# AdaBoost parameters\nada_params = {\n    'n_estimators': 500,\n    'learning_rate' : 0.75\n}","5a85f4ff":"forest_helper = SklearnHelper(clf_model=RandomForestClassifier, seed=SEED, params=forest_params)\ngb_helper = SklearnHelper(clf_model=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc_helper = SklearnHelper(clf_model=SVC, seed=SEED, params=svc_params)","9899e320":"forest_importances = forest_helper.feature_importances(X_train, y_train)\ngb_importances = gb_helper.feature_importances(X_train, y_train)\n\nfeature_dataframe = pd.DataFrame({\n    'features': train.columns.values,\n    'random forest': forest_importances,\n    'gb': gb_importances\n})\n\nfeature_dataframe.head()","621cf836":"# \u4ea4\u5dee\u691c\u8a3c\nforest_scores = cross_val_score(forest, X_train, y_train, cv=kf)\nforest_scores.mean()","6a4a0ec4":"gbrt_scores = cross_val_score(gbrt, X_train, y_train, cv=kf)\ngbrt_scores.mean()","1fe81f74":"svc_scores = cross_val_score(svm, X_train, y_train, cv=kf)\nsvc_scores.mean()","c74e4809":"def get_oof(clf_model, X_train, y_train, X_test):\n    # \u5f15\u6570\u306e\u5206\u306e\u30b5\u30a4\u30ba\u306e\u5024\u304c0\u306e\u914d\u5217\u3092\u751f\u6210\u3059\u308b\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    # \u672a\u521d\u671f\u5316\u306e\u914d\u5217\u3092\u751f\u6210\u3059\u308b\u3002\u3053\u306e\u5834\u5408\u306f[5, ntest\u306e\u6570]\u306e\u30b5\u30a4\u30ba\u306e\u914d\u5217\u3002\u5165\u3063\u3066\u3044\u308b\u5024\u306f\u30c7\u30bf\u30e9\u30e1\n    oof_test_skf = np.empty((NFOLDS, ntest))\n    \n    for i, (train_index, test_index) in enumerate(kf.split(train)):\n        x_tr = X_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = X_train[test_index]\n\n        clf_model.fit(x_tr, y_tr)\n        oof_train[test_index] = clf_model.predict(x_te)\n        oof_test_skf[i, :] = clf_model.predict(X_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","040c8518":"ar = np.array([[1,2,3], [4,5,6]])\nar[:,0]","f64d7dbf":"dtree = DecisionTreeClassifier(random_state=0)\ndtree.fit(X_train, y_train)","f615eb2f":"train_data, test_data, train_target, test_target = train_test_split(X_train, y_train, random_state=0)","032ae6e4":"dtree = DecisionTreeClassifier(random_state=0, max_depth=8)\ndtree.fit(X_train, y_train)\n\nada = AdaBoostClassifier(random_state=0, n_estimators=500, learning_rate=0.8)\nada.fit(X_train, y_train)\n\nex = ExtraTreesClassifier(random_state=0, n_estimators=500, max_depth=8)\nex.fit(X_train, y_train)","237a5bc1":"dtree_pre = dtree.predict(X_train).reshape(-1, 1)\ndtree_pre_test = dtree.predict(X_test).reshape(-1, 1)\n\nada_pre = ada.predict(X_train).reshape(-1, 1)\nada_pre_test = ada.predict(X_test).reshape(-1, 1)\n\nex_pre = ex.predict(X_train).reshape(-1, 1)\nex_pre_test = ex.predict(X_test).reshape(-1, 1)","a555b4d7":"forest_pre = forest.predict(X_train).reshape(-1, 1)\nforest_pre_test = forest.predict(X_test).reshape(-1, 1)\n\nsvm_pre = svm.predict(X_train).reshape(-1, 1)\nsvm_pre_test = svm.predict(X_test).reshape(-1, 1)","c294d636":"gb_pre = gbrt.predict(X_train).reshape(-1, 1)\ngb_pre_test = gbrt.predict(X_test).reshape(-1, 1)","d036e45d":"forest_rf_tr, forest_rf_te = get_oof(forest, X_train, y_train, X_test)\ngbrt_rf_tr, gbrt_rf_te = get_oof(gbrt, X_train, y_train, X_test)\nsvm_rf_tr, svm_rf_te = get_oof(svm, X_train, y_train, X_test)\ndtree_rf_tr, dtree_rf_te = get_oof(dtree, X_train, y_train, X_test)\nada_rf_tr, ada_rf_te = get_oof(ada, X_train, y_train, X_test)\nex_rf_tr, ex_rf_te = get_oof(ex, X_train, y_train, X_test)","9550f01c":"x_train = np.concatenate(\n    (\n        forest_rf_tr,\n        gbrt_rf_tr,\n        svm_rf_tr,\n        dtree_rf_tr,\n        ada_rf_tr,\n        ex_rf_tr\n    ),\n    axis=1\n)\n\nx_test = np.concatenate(\n    (\n        forest_rf_te,\n        gbrt_rf_te,\n        svm_rf_te,\n        dtree_rf_te,\n        ada_rf_te,\n        ex_rf_te\n    ),\n    axis=1\n)\n\n# x_train = x_train.reshape(-1, 1)\n# x_test = x_test.reshape(-1, 1)\n# y_train.reshape(-1, 1)\n\nxg = xgb.XGBClassifier(\n    n_estimators = 2000,\n    max_depth = 4,\n    min_child_weight = 2,\n    gamma = 0.9,\n    subsample = 0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic'\n)","cb7fb61a":"xg.fit(x_train, y_train)\nxg.score(x_train, y_train)","aa8cb66d":"predictions = xg.predict(x_test)","88072e39":"# StackingSubmission = pd.DataFrame({\n#     'PassengerID': PassengerId,\n#     'Survived': predictions\n# })\n\n# StackingSubmission.to_csv('StackingSubmission.csv', index = False)","7ca1bb77":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nPassengerId = test['PassengerId']\nfull_data = [train, test]\n\n\n# \u65b0\u3057\u3044\u7279\u5fb4\u91cf\u300c\u5ba2\u5ba4\u306e\u6709\u7121 Has_Cabin\u300d \u5ba2\u5ba4\u3092\u53d6\u3063\u3066\u3044\u308b\u5ba2\u3068\u53d6\u3063\u3066\u3044\u306a\u3044\u5ba2\u304c\u3044\u308b\ntrain['Has_Cabin'] = train['Cabin'].apply(lambda x:0 if type(x) == float else 1)\ntest['Has_Cabin'] = test['Cabin'].apply(lambda x:0 if type(x) == float else 1)\n\n# (lambda x:0 if type(x) == float else 1)\u306e\u4e2d\u8eab\n# a = np.nan\n# if(type(a) == float):\n#     print('NAN')\n#     x = 0\n# else:\n#     print('N')\n#     x = 1\n\n#\u4e57\u5ba2\u306e\u540d\u524d\u304b\u3089\u656c\u79f0(Mr.Ms\u306a\u3069)\u3092\u53d6\u5f97\u3059\u308b\u95a2\u6570\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    if title_search:\n        return title_search.group(1)\n    return\n\n#Create a new feature Title\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\n# \u6027\u5225\u3092\u30de\u30c3\u30d4\u30f3\u30b0\u3059\u308b\nfor dataset in full_data:\n    # \u5024\u306e\u629c\u3051\u3092\u5e73\u5747\u5024\u3067\u57cb\u3081\u308b\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n\n    # \u6027\u5225\u3092\u30de\u30c3\u30d4\u30f3\u30b0\n    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n    \n    dataset.loc[dataset['Age'] <= 16,'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32) ,'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48) ,'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64) ,'Age'] = 3\n    dataset.loc[dataset['Age'] > 64,'Age'] = 4;\n    \n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n    dataset['Title'] = dataset['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \nfor dataset in full_data:\n    #Mapping titles\n    title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    #\u5bb6\u65cf\u30b5\u30a4\u30ba\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \n    dataset['NameLen'] = dataset['Name'].apply(len)    \n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n    \n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \n    dataset.loc[dataset['Fare'] <= 7.9, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.9 ) & (dataset['Fare'] <= 15.8), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 15.8) & (dataset['Fare'] <= 23.7), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > 23.7) & (dataset['Fare'] <= 31.6), 'Fare'] = 3\n    dataset.loc[dataset['Fare'] > 31.6, 'Fare'] = 4;\n    \n    dataset['Fare'] = dataset['Fare'].astype(int)","5bc56e0e":"drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\n\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\ntrain.head()","63a59bf5":"# \u30d2\u30fc\u30c8\u30de\u30c3\u30d7\u3067\u76f8\u95a2\u95a2\u4fc2\u3092\u78ba\u8a8d\u3059\u308b\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14, 12))\nplt.title('Pearson Correlation of Feature', y=1.05, size=15)\n\n#train.corr() \u5404\u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u6307\u6570\u3092\u3060\u3059\u95a2\u6570\nsns.heatmap(train.astype(float).corr(), linewidth=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","edb71c01":"forest = RandomForestClassifier(random_state=0, n_estimators=500, max_depth=6, min_samples_leaf=2, verbose=0)\nforest.fit(X_train, y_train)\n\ngbrt = GradientBoostingClassifier(random_state=0, n_estimators=500, max_depth=8, verbose=0)\ngbrt.fit(X_train, y_train)\n\nsvm = SVC(kernel='linear', C=0.025)\nsvm.fit(X_train, y_train)\n\ndtree = DecisionTreeClassifier(random_state=0, max_depth=8)\ndtree.fit(X_train, y_train)\n\nada = AdaBoostClassifier(random_state=0, n_estimators=500, learning_rate=0.8)\nada.fit(X_train, y_train)\n\nex = ExtraTreesClassifier(random_state=0, n_estimators=500, max_depth=8, min_samples_leaf=2, verbose=0)\nex.fit(X_train, y_train)","90fd1dd6":"forest.score(X_train, y_train)","c1d78cd3":"fm = cross_val_score(forest, X_train, y_train, cv=kf)\nfm.mean()","3171ac35":"gbrt.score(X_train, y_train)","f8f61802":"gm = cross_val_score(gbrt, X_train, y_train, cv=kf)\ngm.mean()","45fc7f83":"svm.score(X_train, y_train)","156a4e88":"sm = cross_val_score(svm, X_train, y_train, cv=kf)\nsm.mean()","6da3ebc8":"dtree.score(X_train, y_train)","618540d0":"dm = cross_val_score(dtree, X_train, y_train, cv=kf)\ndm.mean()","69523143":"ada.score(X_train, y_train)","b6de80a9":"adam = cross_val_score(ada, X_train, y_train, cv=kf)\nadam.mean()","cc5255a6":"ex.score(X_train, y_train)","22d9467a":"exm = cross_val_score(ex, X_train, y_train, cv=kf)\nexm.mean()","fa6f569c":"# \u751f\u5b58\u3057\u305f\u304b\u3069\u3046\u304b\u306e\u30e9\u30d9\u30eb\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nX_train = train.values\nX_test = test.values","8ec9b55e":"forest_rf_tr, forest_rf_te = get_oof(forest, X_train, y_train, X_test)\ngbrt_rf_tr, gbrt_rf_te = get_oof(gbrt, X_train, y_train, X_test)\nsvm_rf_tr, svm_rf_te = get_oof(svm, X_train, y_train, X_test)\ndtree_rf_tr, dtree_rf_te = get_oof(dtree, X_train, y_train, X_test)\nada_rf_tr, ada_rf_te = get_oof(ada, X_train, y_train, X_test)\nex_rf_tr, ex_rf_te = get_oof(ex, X_train, y_train, X_test)","c7763e42":"x_train = np.concatenate(\n    (\n        forest_rf_tr,\n        gbrt_rf_tr,\n        svm_rf_tr,\n        dtree_rf_tr,\n        ada_rf_tr,\n        ex_rf_tr\n    ),\n    axis=1\n)\n\nx_test = np.concatenate(\n    (\n        forest_rf_te,\n        gbrt_rf_te,\n        svm_rf_te,\n        dtree_rf_te,\n        ada_rf_te,\n        ex_rf_te\n    ),\n    axis=1\n)\n\nxg = xgb.XGBClassifier(\n    n_estimators = 2000,\n    max_depth = 4,\n    min_child_weight = 2,\n    gamma = 0.9,\n    subsample = 0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic'\n)","a0c045a2":"xg.fit(x_train, y_train)\nxg.score(x_train, y_train)","a5f7875e":"xg = xgb.XGBClassifier(\n    n_estimators = 2000,\n    learning_rate =0.5,\n    max_depth = 8,\n    min_child_weight = 1,\n    gamma = 0.4,\n    subsample = 0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic',\n    nthread= -1,\n    scale_pos_weight = 1\n)","4fcd437b":"xg.fit(x_train, y_train)\nxg.score(x_train, y_train)","cd039d82":"gb = GradientBoostingClassifier(\n    n_estimators = 500,\n    max_features= 0.2,\n    max_depth= 5,\n    min_samples_leaf= 2,\n    verbose=0\n)","8c0aaf1f":"gb.fit(X_train, y_train)\ngb.score(X_train, y_train)","90aab84f":"score = cross_val_score(gb, X_train, y_train, cv=kf)\nscore.mean()","4a2984da":"predictions = xg.predict(x_test)\nStackingSubmission = pd.DataFrame({\n    'PassengerID': PassengerId,\n    'Survived': predictions\n})\n\nStackingSubmission.to_csv('StackingSubmission.csv', index = False)","9ec391d2":"## Step3 \u30c7\u30fc\u30bf\u306e\u628a\u63e1\u3001\u6574\u5f62\n\u7279\u5fb4\u91cf\u306f12 <br\/>\n1. PassengerId ID\n2. Survived \u751f\u5b58 0=No \/ 1=Yes\n3. PClass \u5ba2\u5ba4\u306e\u30b0\u30ec\u30fc\u30c9 1=1st \/ 2=2nd \/ 3=3rd\n4. Name \u540d\u524d\n5. Sex \u6027\u5225\n6. Age \u5e74\u9f62\n7. Sibsp \u4e57\u8239\u3057\u3066\u3044\u308b\u5144\u5f1f\u59c9\u59b9\u3001\u914d\u5076\u8005\u306e\u6570\n8. Parch \u4e57\u8239\u3057\u3066\u3044\u308b\u89aa\u3001\u5b50\u306e\u6570\n9. Ticket \u30c1\u30b1\u30c3\u30c8\u756a\u53f7\n10. Fare \u904b\u8cc3\n11. Cabin \u3000\u5ba2\u5ba4\u756a\u53f7\n12. Embarked \u4e57\u8239\u3057\u305f\u6e2f C = Cherbourg \/ Q = Queenstown \/ S = Southampton","30bf5b1a":"## Step4 \u30c7\u30fc\u30bf\u306e\u6f5c\u5728\u7684\u306a\u554f\u984c\u3092\u628a\u63e1\u3059\u308b","1f39907d":"## Step5 \u30e2\u30c7\u30eb\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u884c\u3059\u308b\n\u305d\u306e\u305f\u3081\u306bscikit-learn\u3092\u4f7f\u3044\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u306e\u30d8\u30eb\u30d1\u30fc\u30af\u30e9\u30b9\u3092\u7528\u610f\u3059\u308b\u3002<br>\n\u5b9f\u884c\u3059\u308b\u3060\u3051\u306a\u3089\u4e0d\u8981\u3060\u304c\u3001\u4eca\u5f8c\u306e\u8907\u96d1\u306a\u8a2d\u8a08\u3084\u4ed5\u69d8\u3092\u7528\u3044\u308b\u6642\u306b\u3053\u3046\u3044\u3063\u305f\u30d8\u30eb\u30d1\u30fc\u3092\u7528\u610f\u3059\u308b\u65b9\u6cd5\u3092\u77e5\u3063\u3066\u304a\u3044\u305f\u65b9\u304c\u5f79\u306b\u7acb\u3064\u305f\u3081\u3001\u7528\u610f\u3057\u3066\u304a\u304f\u3002<br>\n\n\u4eca\u56de\u306e\u624b\u9806\n1. \u307e\u305a\u306f\u66f8\u7c4d\u3067\u306e\u3084\u308a\u65b9\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\u57fa\u672c\u7684\u306a\u77e5\u8b58\u3084\u3084\u308a\u65b9\u306f\u3053\u3053\u304c\u30d9\u30fc\u30b9\u306a\u306e\u3067\u3001\u307e\u305a\u8a66\u3057\u3066\u307f\u308b\u3002\u8003\u3048\u3089\u308c\u308b\u3053\u3068\u3092\u8a66\u3057\u3066\u307f\u308b\u3002\n2. Kaggle\u306e\u624b\u6cd5\u3092\u53c2\u8003\u306b\u3059\u308b\u3002\n\n\u8a66\u3057\u3066\u3044\u304f\u306e\u306f\u3001\u66f8\u7c4d\u3067\u5b9f\u884c\u3057\u305f\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3001\u52fe\u914d\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u56de\u5e30\u6728\u3001\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30de\u30b7\u30f3\u306e\u4e09\u3064\u3002\n\u3068\u308a\u3042\u3048\u305a\u3053\u308c\u3067\u8a66\u3057\u3066\u307f\u308b\u3002","a54b75b9":"\u4ee5\u4e0b\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u6cbf\u3063\u3066\u5206\u6790\u3092\u884c\u3063\u3066\u3044\u304f\u3002<br \/>\nStep1 \u554f\u984c\u306e\u628a\u63e1<br \/>\nStep2 \u30c7\u30fc\u30bf\u306e\u53ce\u96c6<br \/>\nStep3 \u30c7\u30fc\u30bf\u306e\u628a\u63e1\u3001\u6574\u5f62<br \/>\nStep4 \u30c7\u30fc\u30bf\u306e\u6f5c\u5728\u7684\u306a\u554f\u984c\u3092\u628a\u63e1\u3059\u308b<br \/>\nStep5 \u30e2\u30c7\u30eb\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u884c\u3059\u308b<br \/>\nStep6 \u30c7\u30fc\u30bf\u30e2\u30c7\u30eb\u306e\u691c\u8a3c\u3059\u308b<br \/>\n\n## Step1 \u554f\u984c\u306e\u628a\u63e1\n\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u53f7\u306e\u4e57\u8239\u5ba2\u306e\u751f\u5b58\u8005\u3092\u4e88\u6e2c\u3059\u308b\n\n## Step2 \u30c7\u30fc\u30bf\u306e\u53ce\u96c6\n\u8a13\u7df4\u30c7\u30fc\u30bf\u306etrain.csv\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306etest.csv\u3092\u5229\u7528\u3059\u308b","689cba3e":"\u6574\u7406\u3057\u3066\u307f\u308b\u3068\u4ee5\u4e0b\u306e\u60c5\u5831\u304c\u751f\u5b58\u306b\u95a2\u308f\u3063\u3066\u3044\u308b\u306e\u3067\u306f\u306a\u3044\u304b<br>\n2. Survived \u751f\u5b58 0=No \/ 1=Yes\u3000\u91cf\u7684\u30c7\u30fc\u30bf\n3. PClass \u5ba2\u5ba4\u306e\u30b0\u30ec\u30fc\u30c9 1=1st \/ 2=2nd \/ 3=3rd\u3000\u91cf\u7684\u30c7\u30fc\u30bf\u3002\u6570\u5b57\u3067\u4f55\u3092\u8868\u3059\u306e\u304b\u308f\u304b\u308b\u306e\u3067\u5272\u308a\u632f\u308b\u5fc5\u8981\u306a\u3057\n5. Sex \u6027\u5225 \u8cea\u7684\u30c7\u30fc\u30bf\u3002\u91cf\u7684\u30c7\u30fc\u30bf\u3068\u3057\u3066\u6271\u3046\u305f\u3081\u306b\u30e9\u30d9\u30eb\u306e\u5272\u308a\u632f\u308a\u3092\u3059\u308b\u3002 0=Male \/ 1=Female\n6. Age \u5e74\u9f62 \u91cf\u7684\u30c7\u30fc\u30bf\n7. Sibsp \u4e57\u8239\u3057\u3066\u3044\u308b\u5144\u5f1f\u59c9\u59b9\u3001\u914d\u5076\u8005\u306e\u6570\u3000\u91cf\u7684\u30c7\u30fc\u30bf\n8. Parch \u4e57\u8239\u3057\u3066\u3044\u308b\u89aa\u3001\u5b50\u306e\u6570\u3000\u91cf\u7684\u30c7\u30fc\u30bf\n11. Cabin \u3000\u5ba2\u5ba4\u756a\u53f7 \u8cea\u7684\u30c7\u30fc\u30bf\u3000\u306a\u3044\u5834\u5408\u306f\u5ba2\u5ba4\u3092\u53d6\u3063\u3066\u3044\u306a\u3044\u4e57\u8239\u5ba2\u3068\u3044\u3046\u3053\u3068\u304b\u3082\n","870d3adb":"\u8a66\u3057\u305f\u306e\u306f\u3001\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3001\u52fe\u914d\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u56de\u5e30\u3001SVM\u3001Adaboost\u3001\u4f59\u5206\u6728\u3001\u6c7a\u5b9a\u6728\u3067\u4ea4\u5dee\u691c\u8a3c\u3082\u884c\u3044\u4e88\u6e2c\u3001\u305d\u308c\u3092\u4f7f\u3044\u3001\u7b2c\u4e8c\u30ec\u30d9\u30eb\u3067XGBClassifier\u3067\u5b66\u7fd2\u3057\u305f\u3002<br \/>\n\u3057\u304b\u3057\u3001\u305d\u308c\u3067\u306f\u3001\u6a21\u5199\u3057\u305f\u3082\u306e\u3088\u308a\u3082\u5236\u5ea6\u304c\u4f4e\u304b\u3063\u305f\u3001\u306a\u306e\u3067\u3001\u7279\u5fb4\u3092\u3082\u3046\u5c11\u3057\u5897\u3084\u3057\u3066\u4e88\u6e2c\u3092\u3059\u308b\u3002","dab052e7":"\u4e0a\u8a18\u306e\u5b9f\u884c\u7d50\u679c\u306f\u3001\n* \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u30fb\u30fb\u30fb84.5%\n* \u52fe\u914d\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u56de\u5e30\u6728\u30fb\u30fb\u30fb84.5%\n* SVM\u30fb\u30fb\u30fb78.6%\n\u3068\u3042\u307e\u308a\u3044\u3044\u7d50\u679c\u3067\u306f\u306a\u304b\u3063\u305f\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u3044\u3058\u3063\u3066\u308285%\u4ee5\u4e0a\u306b\u306f\u306a\u3089\u305a\u3001\u3053\u306e\u5206\u6790\u65b9\u6cd5\u3067\u306f\u9650\u754c\u304c\u3042\u308b\u3088\u3046\u3060\u3002","41b8b851":"\u3053\u306e\u3046\u3061\u3001\u5fc5\u8981\u306a\u60c5\u5831\u304b\u3001\u91cf\u7684\u30c7\u30fc\u30bf\u304b\u8cea\u7684\u30c7\u30fc\u30bf\u304b\u3092\u307f\u308b\u3002\u91cf\u7684\u30c7\u30fc\u30bf\u306e\u5834\u5408\u306f\u3001\u756a\u53f7\u306e\u30e9\u30d9\u30eb\u3092\u4f5c\u6210\u3057\u3066\u5272\u308a\u632f\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n1. PassengerId ID \u91cf\u7684\u30c7\u30fc\u30bf\u3002\u30c7\u30fc\u30bf\u4e0a\u306e\u7ba1\u7406\u756a\u53f7\u3067\u3057\u304b\u306a\u3044\u306e\u3067\u5206\u6790\u306b\u306f\u4f7f\u308f\u306a\u3044\u3002\n2. Survived \u751f\u5b58 0=No \/ 1=Yes\u3000\u91cf\u7684\u30c7\u30fc\u30bf\n3. PClass \u5ba2\u5ba4\u306e\u30b0\u30ec\u30fc\u30c9 1=1st \/ 2=2nd \/ 3=3rd\u3000\u91cf\u7684\u30c7\u30fc\u30bf\u3002\u6570\u5b57\u3067\u4f55\u3092\u8868\u3059\u306e\u304b\u308f\u304b\u308b\u306e\u3067\u5272\u308a\u632f\u308b\u5fc5\u8981\u306a\u3057\n4. Name \u540d\u524d \u8cea\u7684\u30c7\u30fc\u30bf\u3002\u540d\u524d\u3068\u751f\u5b58\u306e\u95a2\u4fc2\u6027\u306f\u7279\u306b\u306a\u3044\u3068\u601d\u308f\u308c\u308b\u306e\u3067\u3001\u9664\u5916\n5. Sex \u6027\u5225 \u8cea\u7684\u30c7\u30fc\u30bf\u3002\u91cf\u7684\u30c7\u30fc\u30bf\u3068\u3057\u3066\u6271\u3046\u305f\u3081\u306b\u30e9\u30d9\u30eb\u306e\u5272\u308a\u632f\u308a\u3092\u3059\u308b\u3002 0=Female \/ 1=Male\n6. Age \u5e74\u9f62 \u91cf\u7684\u30c7\u30fc\u30bf\n7. Sibsp \u4e57\u8239\u3057\u3066\u3044\u308b\u5144\u5f1f\u59c9\u59b9\u3001\u914d\u5076\u8005\u306e\u6570\u3000\u91cf\u7684\u30c7\u30fc\u30bf\n8. Parch \u4e57\u8239\u3057\u3066\u3044\u308b\u89aa\u3001\u5b50\u306e\u6570\u3000\u91cf\u7684\u30c7\u30fc\u30bf\n9. Ticket \u30c1\u30b1\u30c3\u30c8\u756a\u53f7\u3000\u6587\u5b57\u5217\u306e\u7b87\u6240\u3068\u6570\u5217\u306e\u7b87\u6240\u304c\u3042\u308b\u3002\u30c1\u30b1\u30c3\u30c8\u756a\u53f7\u306f\u751f\u5b58\u306b\u5f71\u97ff\u3059\u308b\u3068\u306f\u8003\u3048\u3065\u3089\u3044\u306e\u3067\u9664\u5916\n10. Fare \u904b\u8cc3 \u91cf\u7684\u30c7\u30fc\u30bf\u3000\u751f\u5b58\u306b\u5f71\u97ff\u3057\u3066\u3044\u308b\u3068\u306f\u8003\u3048\u305a\u3089\u3044\u3002\u3069\u3053\u307e\u3067\u3044\u304f\u304b\u3001\u30b0\u30ec\u30fc\u30c9\u306a\u3069\u306f\u3059\u3067\u306b\u3042\u308b\u306e\u3067\u9664\u5916\n11. Cabin \u3000\u5ba2\u5ba4\u756a\u53f7 \u8cea\u7684\u30c7\u30fc\u30bf\u3000\u30c7\u30fc\u30bf\u306e\u629c\u3051\u304c\u591a\u304f\u3001\u60c5\u5831\u91cf\u306f\u5c11\u306a\u3044\u3002\n12. Embarked \u4e57\u8239\u3057\u305f\u6e2f C = Cherbourg \/ Q = Queenstown \/ S = Southampton \u8cea\u7684\u30c7\u30fc\u30bf\u3000\u3069\u3053\u3067\u4e57\u8239\u3057\u305f\u304b\u304c\u751f\u5b58\u306b\u95a2\u308f\u3063\u3066\u304f\u308b\u3068\u306f\u3001\u73fe\u6bb5\u968e\u3067\u306f\u8003\u3048\u3089\u308c\u306a\u3044\u305f\u3081\u9664\u5916\u3059\u308b\u3002","46f43443":"\u5404\u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u306f\u3001\u9ad8\u3044\u3082\u306e\u3067Sibsp\u3068Parch\u306e0.41\u3001\u5168\u4f53\u7684\u306b\u5f37\u304f\u76f8\u95a2\u3057\u3066\u3044\u308b\u3068\u601d\u308f\u308c\u308b\u3082\u306e\u306f\u306a\u3044\u3002\n\u305d\u308c\u305e\u308c\u56fa\u6709\u306e\u60c5\u5831\u3092\u6301\u3063\u3066\u3044\u308b\u3068\u8a00\u3048\u308b\u3002"}}