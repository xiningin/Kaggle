{"cell_type":{"4c42d4ec":"code","7778fab4":"code","fd492a86":"code","a53a2956":"code","06060b28":"code","977a5b08":"code","fa095fff":"code","a86a34a3":"code","0ac1d3e3":"code","fc14f3c0":"markdown","37fc6de7":"markdown"},"source":{"4c42d4ec":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load in \n\nimport os\n# import gc\n# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n# !pip uninstall tensorflow --yes\n# !pip install tensorflow-gpu \n# The GPU id to use, usually either \"0\" or \"1\";\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n# # Input data files are available in the \"..\/input\/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","7778fab4":"test_files = glob.glob('\/kaggle\/input\/bengaliai-cv19\/test_image_data_*')\ntest_files.sort()\n# model = load_model('\/kaggle\/input\/resnet50\/ResNet50.hdf5')","fd492a86":"# test_files","a53a2956":"# dict_={\"row_id\":[],\"target\":[]}\n# testX = []\n# image_ids = []\n# batch_size=256\n# for file in test_files:\n    \n#     df = pd.read_parquet(file, engine='pyarrow')\n    \n#     for idx in range(len(df)):\n        \n#         img_name = df.iloc[idx]['image_id']\n#         image_ids.append(img_name)\n#         image = df.loc[df.index[idx]].values[1:].reshape(137,236)\n#         image = np.uint8(image)\n#         testX.append(np.repeat(image[..., np.newaxis], 3, -1))\n        \n#         if len(testX) >= batch_size:\n            \n#             grayscale_batch = np.array(testX)\n# #             rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)\n\n#             predictions = model.predict(grayscale_batch)\n\n#             for idx in range(len(image_ids)):\n#                 img_name = image_ids[idx]\n#                 for key,value in {0:\"grapheme_root\",1:\"vowel_diacritic\",2:\"consonant_diacritic\"}.items():\n#                     name  = img_name+'_'+value\n#                     val = np.argmax(predictions[key][idx])\n#                     dict_['row_id'].append(name)\n#                     dict_['target'].append(val)\n#             testX = []\n#             image_ids = []\n            \n            \n            \n            \n        \n        \n        \n#     if len(testX)>0:     \n#         grayscale_batch = np.array(testX)\n#     #     rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)\n\n#         predictions = model.predict(grayscale_batch)\n\n#         for idx in range(len(image_ids)):\n#             img_name = image_ids[idx]\n#             for key,value in {0:\"grapheme_root\",1:\"vowel_diacritic\",2:\"consonant_diacritic\"}.items():\n#                 name  = img_name+'_'+value\n#                 val = np.argmax(predictions[key][idx])\n#                 dict_['row_id'].append(name)\n#                 dict_['target'].append(val)\n#         testX = []\n#         image_ids = []\n    \n    ","06060b28":"dict_={\"row_id\":[],\"target\":[]}\ntestX = []\nfor file in test_files:\n    df = pd.read_parquet(file, engine='pyarrow')\n    for idx in range(len(df)):\n        img_name = df.iloc[idx]['image_id']\n        for key,value in {0:\"grapheme_root\",1:\"vowel_diacritic\",2:\"consonant_diacritic\"}.items():\n            name  = img_name+'_'+value\n            val = 0\n            dict_['row_id'].append(name)\n            dict_['target'].append(val)\n","977a5b08":"# dict_={\"row_id\":[],\"target\":[]}\n# df = pd.read_csv('..\/input\/submission\/submission.csv')\n# for index in range(len(df)):\n#     dict_['row_id'].append(df.iloc[index]['row_id'])\n#     dict_['target'].append(df.iloc[index]['target'])","fa095fff":"submission = pd.DataFrame(dict_)\nsubmission.to_csv('submission.csv',index=False)\n    ","a86a34a3":"submission.head()","0ac1d3e3":"len(submission)","fc14f3c0":"**Model Prediction Code**","37fc6de7":"**Read Csv From Input**"}}