{"cell_type":{"1590ddda":"code","630fcdf4":"code","da7c0ff7":"code","34e75ba2":"code","6b9be641":"code","78ed1ff2":"code","4fae37a8":"code","67bb44a7":"code","074cdcb2":"code","3a74dd36":"code","12351656":"code","4ad00abe":"code","684ae525":"code","9c73d57e":"code","8574589b":"code","a18662fe":"code","5deba0d6":"code","f78504c5":"code","3801b50a":"code","ac9ce471":"code","89058e3a":"code","01f7145a":"code","690e355a":"code","82456e4a":"code","25d7a5a8":"markdown","b045416d":"markdown","11cee375":"markdown","4485eb83":"markdown","8a582a0e":"markdown","226fa7ea":"markdown"},"source":{"1590ddda":"from IPython.display import clear_output\n!pip install keras\n!pip install tensorflow\nclear_output()","630fcdf4":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nos.listdir('..\/input\/cassava-leaf-disease-classification')","da7c0ff7":"train_img_path = '..\/input\/cassava-leaf-disease-classification\/train_images'\nimages = os.listdir(train_img_path)\n\nprint(\"Training images:\", len(images))","34e75ba2":"import json\nfile = open('..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json')\n\nclass_map = json.load(file)\nprint(json.dumps(class_map,indent=1))\nlis = json.dumps(class_map)","6b9be641":"import pandas as pd\n\ntrain_file = '..\/input\/cassava-leaf-disease-classification\/train.csv'\n\ntrain = pd.read_csv(train_file)\ntrain.head()","78ed1ff2":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nax = plt.figure(figsize=(14,6))\n\nax = sns.countplot(x = 'label',data=train, palette=\"pastel\")","4fae37a8":"samples = train[train['label']==0].sample(3).reset_index() #Reset index isn't necessary\nsamples","67bb44a7":"plt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('..\/input\/cassava-leaf-disease-classification\/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","074cdcb2":"samples = train[train['label']==1].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('..\/input\/cassava-leaf-disease-classification\/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","3a74dd36":"samples = train[train['label']==2].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('..\/input\/cassava-leaf-disease-classification\/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","12351656":"samples = train[train['label']==3].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('..\/input\/cassava-leaf-disease-classification\/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","4ad00abe":"samples = train[train['label']==4].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('..\/input\/cassava-leaf-disease-classification\/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","684ae525":"train.info()","9c73d57e":"# We need to convert labels to string ,label     21397 non-null  int64 \n\ntrain['label'] = train['label'].astype('str')\ntrain.info()","8574589b":"train.head(2)","a18662fe":"img = plt.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nimg.shape","5deba0d6":"classes = 5\nimg_rows, img_cols = 512, 512\nbatch_size = 32\n\nSTEPS_PER_EPOCH = len(train)*0.7 \/ batch_size\nVALIDATION_STEPS = len(train)*0.3 \/ batch_size","f78504c5":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '..\/input\/cassava-leaf-disease-classification\/train_images'\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range = 45,\n                                   zoom_range = 0.2,\n                                   width_shift_range = 0.3,\n                                   height_shift_range = 0.3,\n                                   shear_range = 0.2,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   fill_mode = 'nearest',\n                                   validation_split = 0.3)\n\ntrain_generator = train_datagen.flow_from_dataframe(train,\n                                                    TRAIN_DIR,\n                                                    subset='training',\n                                                    x_col = 'image_id',\n                                                    y_col = 'label',\n                                                    target_size=(img_rows, img_cols),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical')\n\nvalidation_datagen = ImageDataGenerator(validation_split = 0.3)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(train,\n                                                    TRAIN_DIR,\n                                                    subset='validation',\n                                                    x_col = 'image_id',\n                                                    y_col = 'label',\n                                                    target_size=(img_rows, img_cols),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical')","3801b50a":"epochs = 1","ac9ce471":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model\n\n\n# Re-loads the MobileNet model without the top or FC layers\nvgg16 = VGG16(weights = 'imagenet',include_top = False,input_shape = (img_rows, img_cols, 3))\n\nfor layer in vgg16.layers:\n    layer.trainable = False\n    \n\ndef addTopModelvgg16(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model\n\n\nnum_classes = classes\n\nFC_Head = addTopModelvgg16(vgg16, num_classes)\n\nmodel = Model(inputs = vgg16.input, outputs = FC_Head)","89058e3a":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \ncheckpoint = ModelCheckpoint(\".\/vgg19.h5\",\n                             monitor = \"val_loss\",\n                             mode = \"min\",\n                             save_best_only = True,\n                             verbose = 1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0.001, \n                          patience = 15,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.2,\n                              patience = 2,\n                              verbose = 1,\n                              min_delta = 0.0001,\n                              min_lr = 0.00000001)\n\n\ncallbacks = [checkpoint,earlystop,reduce_lr]\n\n\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = epochs,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = callbacks\n)","01f7145a":"result = pd.DataFrame(history.history)\nresult.plot(figsize=(10,8))","690e355a":"sample = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\nsample","82456e4a":"from PIL import Image\n\ntest_image = '..\/input\/cassava-leaf-disease-classification\/test_images'\npreds = []\n\nfor image_id in sample['image_id']:\n    image = Image.open(os.path.join(test_image, image_id))\n    image = image.resize((img_rows, img_cols))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n    \nsample['label'] = preds\nsample","25d7a5a8":"# Samples of \"2\": \"Cassava Green Mottle (CGM)\"","b045416d":"# Samples of \"4\": \"Healthy\"","11cee375":"# Samples of \"1\": \"Cassava Brown Streak Disease (CBSD)\"","4485eb83":"# Samples of \"3\": \"Cassava Mosaic Disease (CMD)\"****","8a582a0e":"***Image Data Generator***","226fa7ea":"# Samples of \"0\": \"Cassava Bacterial Blight (CBB)\""}}