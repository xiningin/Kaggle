{"cell_type":{"17631e48":"code","76f39200":"code","81d0dee7":"code","be853b17":"code","e2171d8e":"code","717c9bda":"code","de46b8aa":"code","e1798477":"code","8dd9b262":"code","b720387e":"code","f9f653ce":"code","b57b06a7":"code","e68b0f36":"code","0fa06fa1":"code","06ef1815":"code","aec6898b":"code","754b460d":"code","24dab96a":"code","3d0b3420":"code","845dace0":"code","af913075":"code","04c885f6":"code","7be96ba7":"code","f447775e":"code","80ea1888":"code","1fd53924":"code","ca04123e":"code","1c01364c":"code","e26c4d41":"code","53c2c033":"code","80a6aa33":"code","36f7fc4b":"code","e850ca6d":"code","754ecfcf":"code","080259fa":"code","8d7907d2":"markdown","745ddd94":"markdown","36b50f71":"markdown","21877e72":"markdown","f55fbde4":"markdown","fb712674":"markdown","0536b04f":"markdown","9f95a3c2":"markdown","68c0e61c":"markdown","518d52c2":"markdown","dd48fb67":"markdown","1804547d":"markdown","aba09839":"markdown","862b0881":"markdown","258ebfc4":"markdown","a136937c":"markdown","2b4bee10":"markdown","e6d7b3ad":"markdown","689265ed":"markdown","f47f623c":"markdown","ebd8b57d":"markdown","f453701f":"markdown","0c788be3":"markdown","fbe2df8e":"markdown","dc749d0f":"markdown","243a9f2c":"markdown","dadfe5f5":"markdown","229539db":"markdown","d8211be3":"markdown","17622b5a":"markdown","9e300afb":"markdown","47c35977":"markdown","216cd5a6":"markdown"},"source":{"17631e48":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nprint(\"libraries loaded successfully\")","76f39200":"data_train = pd.read_csv('\/kaggle\/input\/black-friday\/train.csv')\nprint(\"Data loaded successfully\")","81d0dee7":"#exploar data\nprint(\"data shape : \",data_train.shape)\ndata_train.describe()","be853b17":"print(\"Data columns\")\nprint(\"--------------------------------------------\")\nprint(pd.DataFrame(data_train.columns))\nprint(\"--------------------------------------------\")","e2171d8e":"data_train = data_train.drop(['User_ID','Product_ID'], axis=1)\nprint(\"User_ID and Product_ID columns droped successfully\")","717c9bda":"#get total count of data including missing data\ntotal = data_train.isnull().sum().sort_values(ascending=False)\n\n#get percent of missing data relevant to all data\npercent = (data_train.isnull().sum()\/data_train.isnull().count()).sort_values(ascending=False)\n\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(10)","de46b8aa":"data_train = data_train.drop('Product_Category_3', axis=1)\nprint(\"Product_Category_3 column droped successfully\")","e1798477":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(pd.DataFrame(data_train['Product_Category_2']))\ndata_train['Product_Category_2'] = imputer.transform(pd.DataFrame(data_train['Product_Category_2']))\ndata_train['Product_Category_2'] = np.round(data_train['Product_Category_2'])\n\nprint(\"Product_Category_2 column imputed successfully\")","8dd9b262":"#print max count number of null values\nprint('Number of missing values = ',data_train.isnull().sum().max())","b720387e":"data_train.dtypes","f9f653ce":"malesPurchaserData = data_train.loc[data_train['Gender'] == 'M']\nmalesPurchaseMean = np.mean(malesPurchaserData['Purchase'])\nprint(\"Purchase mean for male purchasers = \",malesPurchaseMean)\n\nfemalsPurchaserData = data_train.loc[data_train['Gender'] == 'F']\nfemalsPurchaseMean = np.mean(femalsPurchaserData['Purchase'])\nprint(\"Purchase mean for femal purchasers = \",femalsPurchaseMean)","b57b06a7":"labels=['males','femals']\nvalues = [malesPurchaseMean,femalsPurchaseMean]\n\nplt.bar(labels,values, width=.9, facecolor='b', edgecolor='g', alpha=.5)\nplt.text(-0.4,10800,'Average purchase in black friday based on gender')\n         \nplt.show()","e68b0f36":"print('Number of males purchaser = ',malesPurchaserData.shape[0])\nprint('Number of femals purchaser = ',femalsPurchaserData.shape[0])","0fa06fa1":"genderCountData = [malesPurchaserData.shape[0],femalsPurchaserData.shape[0]]\nlabels=['Males','Femals']\nplt.axis('equal')\n\nplt.pie(genderCountData, labels=labels,\n              explode=[0.1,0],\n              autopct='%1.1f%%',\n              shadow=True,\n              startangle=0,\n              labeldistance=1.1,\n              pctdistance=.6)\n\nplt.legend(labels)\nplt.title('Purchaser number in black friday based on gender')\nplt.show()","06ef1815":"list(data_train['Occupation'].sort_values().unique())","aec6898b":"labels = []\nvalues = []\n\nfor uniqueOccupationValue in data_train['Occupation'].sort_values().unique():\n    OccPurchaserData = data_train.loc[data_train['Occupation'] == uniqueOccupationValue]\n    OccPurchaserMean = np.mean(OccPurchaserData['Purchase'])\n    labels.append(uniqueOccupationValue)\n    values.append(OccPurchaserMean)\n    \n    print(\"When occupation = \",uniqueOccupationValue,\" mean purchase value = \",OccPurchaserMean)\n    print(\"------------------------------------------------------------\")\n","754b460d":"plt.bar(labels,values, width=.9, facecolor='b', edgecolor='w', alpha=.5)\nplt.text(-1,10800,'Average purchase in black friday based on Occupation')\n         \nplt.show()","24dab96a":"list(data_train['City_Category'].sort_values().unique())","3d0b3420":"labels = []\nvalues = []\ncityCatCount = []\n\nfor uniqueCityCategoryValue in data_train['City_Category'].sort_values().unique():\n    CityCatPurchaserData = data_train.loc[data_train['City_Category'] == uniqueCityCategoryValue]\n    CityCatPurchaserMean = np.mean(CityCatPurchaserData['Purchase'])\n    labels.append(uniqueCityCategoryValue)\n    values.append(CityCatPurchaserMean)\n    cityCatCount.append(CityCatPurchaserData.shape[0])\n    \n    print(\"When City_Category = \",uniqueCityCategoryValue,\" mean Purchase value = \",CityCatPurchaserMean)\n    print(\"------------------------------------------------------------------------------------------\")\n","845dace0":"plt.bar(labels,values, width=.9, facecolor='b', edgecolor='w', alpha=.5)\nplt.text(-0.7,10800,'Average purchase in black friday based on City_Category')\n         \nplt.show()","af913075":"for uniqueCityCategoryValue in data_train['City_Category'].sort_values().unique():\n    CityCatPurchaserData = data_train.loc[data_train['City_Category'] == uniqueCityCategoryValue]\n    print(\"Purchasers count who live in city of category \",uniqueCityCategoryValue,\" = \",CityCatPurchaserData.shape[0])\n    print(\"------------------------------------------------------------------------------------------\")","04c885f6":"values = cityCatCount\nlabels = ['A', 'B', 'C']\nplt.axis('equal')\n\nplt.pie(values, labels=labels,\n              explode=[0.1,0.05,0.05],\n              autopct='%1.1f%%',\n              shadow=True,\n              startangle=0,\n              labeldistance=1.1,\n              pctdistance=.6)\n\nplt.legend(labels)\nplt.title('Average purchase in black friday based on City_Category')\nplt.show()","7be96ba7":"list(data_train['Stay_In_Current_City_Years'].sort_values().unique())","f447775e":"data_train.loc[data_train['Stay_In_Current_City_Years'] == '4+','Stay_In_Current_City_Years'] = '4'\ndata_train['Stay_In_Current_City_Years'] = pd.to_numeric(data_train['Stay_In_Current_City_Years'])\nprint(\"Stay_In_Current_City_Years converted to int successfully\")","80ea1888":"labels = []\nvalues = []\nyearsCountData = []\n\nfor uniqueYearsValue in data_train['Stay_In_Current_City_Years'].sort_values().unique():\n    CityYearsPurchaserData = data_train.loc[data_train['Stay_In_Current_City_Years'] == uniqueYearsValue]\n    CityYearsPurchaserMean = np.mean(CityYearsPurchaserData['Purchase'])\n    labels.append(uniqueYearsValue)\n    values.append(CityYearsPurchaserMean)\n    yearsCountData.append(CityYearsPurchaserData.shape[0])\n    \n    if uniqueYearsValue != 4:\n        print(\"Mean purchase of people who stay \",uniqueYearsValue,\" years = \",CityYearsPurchaserMean)\n    elif uniqueYearsValue == 4:\n        print(\"Mean purchase of people who stay more than \",uniqueYearsValue,\" years = \",CityYearsPurchaserMean)\n\n","1fd53924":"plt.bar(labels,values, width=.9, facecolor='b', edgecolor='w', alpha=.5)\nplt.text(-0.7,10800,'Average purchase in black friday based on Stay In Current City Years')\n         \nplt.show()","ca04123e":"for uniqueYearsValue in data_train['Stay_In_Current_City_Years'].sort_values().unique():\n    CityYearsPurchaserData = data_train.loc[data_train['Stay_In_Current_City_Years'] == uniqueYearsValue]\n    if uniqueYearsValue != 4:\n        print(\"Number of purchasers who stay \",uniqueYearsValue,\" years = \",CityYearsPurchaserData.shape[0])\n    elif uniqueYearsValue == 4:\n        print(\"Number of purchasers who stay more than \",uniqueYearsValue,\" years = \",CityYearsPurchaserData.shape[0])\n\n    ","1c01364c":"values = yearsCountData\nlabels = list(data_train['Stay_In_Current_City_Years'].sort_values().unique())\nplt.axis('equal')\n\nplt.pie(values, labels=labels,\n              explode=[0,0.1,0,0,0],\n              autopct='%1.1f%%',\n              shadow=True,\n              startangle=0,\n              labeldistance=1.1,\n              pctdistance=.6)\n\nplt.legend(labels)\nplt.title('Number of purchasers in black friday based on Stay_In_Current_City_Years')\nplt.show()","e26c4d41":"list(data_train['Marital_Status'].unique())","53c2c033":"labels = []\nvalues = []\nmaritalStatusCount = []\n\nfor maritalStatusValue in data_train['Marital_Status'].unique():\n    maritalStatusPurchaserData = data_train.loc[data_train['Marital_Status'] == maritalStatusValue]\n    maritalStatusPurchaserMean = np.mean(maritalStatusPurchaserData['Purchase'])\n    labels.append(maritalStatusValue)\n    values.append(maritalStatusPurchaserMean)\n    maritalStatusCount.append(maritalStatusPurchaserData.shape[0])\n    \n    print(\"Mean purchase of people who marital Status is \",maritalStatusValue,\" = \",maritalStatusPurchaserMean)","80a6aa33":"plt.bar(labels,values, width=.9, facecolor='b', edgecolor='w', alpha=.5)\nplt.text(-0.7,10800,'Average purchase in black friday based on Marital_Status')\n         \nplt.show()","36f7fc4b":"for maritalStatusValue in data_train['Marital_Status'].unique():\n    maritalStatusPurchaserData = data_train.loc[data_train['Marital_Status'] == maritalStatusValue]\n    print(\"Number of purchasers who marital status is \",maritalStatusValue,\" = \",maritalStatusPurchaserData.shape[0])","e850ca6d":"values = maritalStatusCount\nlabels = list(data_train['Marital_Status'].unique())\nplt.axis('equal')\n\nplt.pie(values, labels=labels,\n              explode=[0,0.1],\n              autopct='%1.1f%%',\n              shadow=True,\n              startangle=0,\n              labeldistance=1.1,\n              pctdistance=.6)\n\nplt.legend(labels)\nplt.title('Number of purchasers in black friday based on Marital_Status')\nplt.show()","754ecfcf":"Product_Category_1_sum = data_train['Product_Category_1'].sum()\nProduct_Category_2_sum = data_train['Product_Category_2'].sum()\n\nprint(\"Profit from product of category 1 = \",Product_Category_1_sum)\nprint(\"Profit from product of category 2 = \",Product_Category_2_sum)","080259fa":"labels = ['Product_Category_1','Product_Category_2']\nvalues = [Product_Category_1_sum,Product_Category_2_sum]\n\nplt.bar(labels,values, width=.9, facecolor='b', edgecolor='w', alpha=.5)\nplt.text(-0.7,6000000,'Compar between number of boughts of category_1 and category_2 in black friday')\n         \nplt.show()","8d7907d2":"**Answer :** Profit from product of category 2 more than product of category 1.<br>\n**Decision :** We must take care of product of category 2 in the next marketing campaigns\n<hr>\n**At the end, I would like this kernel to be helpful for us. and any suggestions to improve this kernel will be much appreciated.**<br>\n\n**Good luck. \ud83d\udc4d**","745ddd94":"## Exploratory Data Analysis (Graphically) \ud83d\udcc8","36b50f71":"**Question 4 :** Are purchase value clear vary based on City Category ?\n### Exploratory Data Analysis (Numerically) \ud83d\udcb0","21877e72":"## Exploratory Data Analysis (Graphically) \ud83d\udcc8","f55fbde4":"### Exploratory Data Analysis (Graphically) \ud83d\udcc8","fb712674":"As we see in above \u261d output some columns not useful for our analysis like **User_ID** and **Product_ID** columns. So we will drop them. ","0536b04f":"**Question 8 :** Are people who married buy more than else ?\n## Exploratory Data Analysis (Numerically) \ud83d\udcb0","9f95a3c2":"### How to Handle Missing Data ? \ud83d\ude44\nOne of the most common problems I have faced in Data Cleaning\/Exploratory Analysis is handling the missing values.<br>\nThis is a picture that give us a guide to deal with missingg data \ud83d\udc47 <br>\n<img src='https:\/\/miro.medium.com\/max\/1528\/1*_RA3mCS30Pr0vUxbp25Yxw.png' width=\"550px\" style='float:left;'>\n<div style='clear:both'><\/div>\n<br>\nAs we see in above picture there are many ways to deal with Missing Data. In this **Kernel** i will use two of them on at each branch.<br><br>\nIn **Deletion** I will use **Deleting Columns** technique.<br>\n\nSometimes we can drop variables if the data is missing for more than 60% observations because these variables are useless.\n\nIn **Imputation** because our problem is a general problem I will use **simpelImputer** from **SKlearn** library<br>\n\nI will Delete the following Column **Product_Category_3** because missing data in this columns more than **60%** observations.<br>\n\nAnd impute **Product_Category_2** column because missing data in this columns less than **60%** observations.\n","68c0e61c":"**Answer :** No. Because Purchasers who live in city of category B has largest number of Purchasers than A and C.\n<hr>\nNow let's deal with Stay_In_Current_City_Years column \ud83d\udc47.\n## Stay_In_Current_City_Years \ud83c\udf14\nStay_In_Current_City_Years is a categorical column has unique values, **'0'**, **'1'**, **'2'**, and **'4+'**. It represent number of years a purchaser stay in a city.<br>Let's show it \ud83d\ude0a.","518d52c2":"# 3. Exploratory Data Analysis\nNow we will get each column from our columns and make our insights process on it. let's start with **Gender** column \ud83d\udc47.\n## Gender \ud83d\udc68\ud83d\udc69\n\n**Question 1 :** Are females buying higher value purchases than males ? \n\n### Exploratory Data Analysis (Numerically) \ud83d\udcb0","dd48fb67":"### Exploratory Data Analysis (Graphically) \ud83d\udcc8","1804547d":"**Answer :** No. Because purchasers who married or not, have almost same average of purchase.\n<hr>\n**Question 8 :** Do people who married have more action towards buying ?\n\n## Exploratory Data Analysis (Numerically) \ud83d\udcb0","aba09839":"**Question 6 :** Are people who stay more years buy less than people who stay less ? \n\n## Exploratory Data Analysis (Numerically) \ud83d\udcb0","862b0881":"# 2. Missing data \nNow let's deal with missing data \ud83d\udc47","258ebfc4":"**Answer :** Yes. Because 59% of purchasers are married.<br>\n**Decision :** We must take care of married than singles in the next marketing campaigns. where the ratio is 59 to 41 percent respectively.\n<hr>\n**Question 9 :** Are Profit from product of category 1 more or from product of category 2 ?  \n## Exploratory Data Analysis (Numerically) \ud83d\udcb0\n","a136937c":"# Beautiful Insights Into Black Friday Data\n![black friday](https:\/\/images.pexels.com\/photos\/5650050\/pexels-photo-5650050.jpeg)\n<br><br>\nWelcome all \ud83d\udc4b<br>\n\nIn this kernel we will go together into black friday data to discover some insights in it<br>\n\nWe will deal with our insights in a form of **question** \u27a1 **analysis** \u27a1 **answer** \u27a1 **decision (if available).** Our Analysis will devided into two ways \ud83d\udc47\n* **Exploratory Data Analysis (Numerically)**\n* **Exploratory Data Analysis (Graphically)**\n\nFirst We will import libraries and load data \ud83d\udc47\n","2b4bee10":"**Question 3 :** Are purchase value clear vary based on occupation value ?\n### Exploratory Data Analysis (Numerically) \ud83d\udcb0","e6d7b3ad":"## Exploratory Data Analysis (Graphically) \ud83d\udcc8","689265ed":"# 1. Data exploration\nNow let's take fast look at our data \ud83d\udc47","f47f623c":"Now we will convert **'4+'** value to 4 to can convert **Stay_In_Current_City_Years** column from string to int. \ud83d\udc47","ebd8b57d":"## Exploratory Data Analysis (Graphically) \ud83d\udcc8","f453701f":"### Exploratory Data Analysis (Graphically) \ud83d\udcc8","0c788be3":"**Answer :** Purchase value don't effect with occupation value. Because mean values of purchase at each occupation value nearest to each other.\n\n<hr>\nNow let's deal with **City_Category** column \ud83d\udc47.\n## City_Category \ud83c\udfe1\nCity_Category column is categorical column has unique values **A, B,** and **C**. I don't know the meaning of these values, But I guess that category **A** best than category **B** and category **B** best than category **C** according to city level. But let's show it \ud83d\ude0a.","fbe2df8e":"**Answer :** Purchase value doesn't big vary from one category to another. But we can say that people who live in city of category C purchase more than other peoples who live cities of category  A or B.\n\n<hr>\n\nAccording to above \u261d info<br>\n**Question 5 :** can we consider that Purchasers who live in city of category C more than other Purchasers who live cities of category  A or B ?\n\n### Exploratory Data Analysis (Numerically) \ud83d\udcb0","dc749d0f":"### Exploratory Data Analysis (Graphically) \ud83d\udcc8","243a9f2c":"## Exploratory Data Analysis (Graphically) \ud83d\udcc8","dadfe5f5":"**Moment of truth** \ud83d\ude27<br>\nNow let's know if our data contain any missing value","229539db":"### Exploratory Data Analysis (Graphically) \ud83d\udcc8","d8211be3":"**Answer :** Yes males buyers more than females buyers. Significantly.<br><br>\n**Decision :** We must take care of males than females in the next marketing campaigns. where the ratio is 75 to 25 percent respectively.<hr>\nNow let's deal with **Occupation** column \ud83d\udc47.\n## Occupation \ud83d\udcbc\nOccupation column is a numerical column has unique values from 0 to 20. I don't know the meaning of these values, But let's show it \ud83d\ude0a.","17622b5a":"Now let's get background about our cleaning data \ud83d\udcaa data types \ud83d\ude0a","9e300afb":"**Answer :** No, males buying higher value purchases than females ? But the difference not large.\n<hr>\n\n**Question 2 :** Are males buyers more than females buyers ?\n\n### Exploratory Data Analysis (Numerically) \ud83d\udcb0","47c35977":"**Answer :** No. Because people who stay longer in city have less action towards buying than others.\n**Decision :** We must take care of people who stay in range 1 year in city because they have more action towards buying than others.\n<hr>\n## Marital_Status \ud83d\udea9\nMarital_Status is a numerical column has two value **0** and **1**. This column describe if purchaser married or not. Let's show it \ud83d\ude0a","216cd5a6":"**Answer:** No. Because the mean purchases of people despite the varying years of stay very close\n<hr>\n**Question 7 :** Do people who stay longer in city have more action towards buying ?\n\n## Exploratory Data Analysis (Numerically) \ud83d\udcb0"}}