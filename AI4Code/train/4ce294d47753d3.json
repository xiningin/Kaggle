{"cell_type":{"f02eeeec":"code","ab3c24ab":"code","209f9408":"code","42efad2c":"code","139abb3a":"code","54d5ecbf":"code","7d508f54":"code","3a396206":"code","ea92da08":"code","1b8766b0":"code","71c9d784":"code","d9305fdb":"code","2a8006b1":"code","8c96e304":"code","76020e67":"code","1fb07da0":"code","ab6591fc":"code","e25bf893":"code","01461971":"code","e35fed1e":"code","36e62017":"markdown"},"source":{"f02eeeec":"#import the data\n#standardization\n#apply PCA","ab3c24ab":"from warnings import filterwarnings\nfilterwarnings('ignore')\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy as sp\nfrom sklearn.cluster import KMeans","209f9408":"df=pd.read_csv(\"..\/input\/usarrests\/USArrests.csv\").copy()\ndf.index = df.iloc[:,0]\ndf = df.iloc[:,1:5]\ndf.index.name = None\ndf.head()","42efad2c":"#standardization","139abb3a":"from sklearn.preprocessing import StandardScaler\ndf=StandardScaler().fit_transform(df)\ndf[0:5,0:5]","54d5ecbf":"from sklearn.decomposition import PCA\npca_fit=PCA(n_components=2).fit_transform(df)\npca_fit[0:5]","7d508f54":"#apply PCA (ex:1)","3a396206":"component_df=pd.DataFrame(data= pca_fit, columns=[\"1st Component\",\"2nd Component\"])\ncomponent_df[0:5]","ea92da08":"#Here,these 2 components represents 4 variables(Murder, Assault, UrbanPop,Rape)","1b8766b0":"from sklearn.decomposition import PCA\npca=PCA(n_components=2)\npca.fit_transform(df)\npca.explained_variance_ratio_","71c9d784":"#It means, first component explains 62% of data variation, second component explains 24% of data variation. \n#Totally, 86% of the data variation can be explained by these two components","d9305fdb":"#If we accept the risk of some error, we can reduce the number of variables(4) to 2(components) as it i seen. \n#We can apply this method to more complex datasets.","2a8006b1":"#apply PCA (ex:2)","8c96e304":"pca = PCA(n_components = 3)\npca_fit = pca.fit_transform(df)\ncomponent_df=pd.DataFrame(data= pca_fit, columns=[\"1st Component\",\"2nd Component\",\"3rd Component\"])\ncomponent_df[0:5]","76020e67":"pca.explained_variance_ratio_","1fb07da0":"#It means, first component explains 62% of data variation.\n#Second component explains 24% of data variation.\n#Third component explains 8% of data variation\n#Totally, 94% of the data variation can be explained by these three components","ab6591fc":"#How can we specify the number of components?\n#We can specify the number of components according to these explained variance ratio...","e25bf893":"pca=PCA().fit(df)","01461971":"plt.plot(np.cumsum(pca.explained_variance_ratio_))","e35fed1e":"#From this graph,\n#We can understand that less than 65% of the data can be explained by one component,\n#                       less than 90% of the data can be explained by two components,\n#                       more than 95% of the data can be explained by three components,\n#                                100% of the data can be explained by four components.","36e62017":"Thanks to https:\/\/github.com\/mvahit\/DSMLBC"}}