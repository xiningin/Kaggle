{"cell_type":{"fa1bb0b6":"code","bb0acf26":"code","3cdf0898":"code","b74140b8":"code","d555fc7b":"code","0b85f498":"code","4303785d":"code","248c1f63":"code","d4d5da12":"code","624c6841":"code","0508a865":"code","1877a5ce":"code","046d4d02":"code","56e1fa32":"code","500e930f":"code","f90c216a":"code","ad844850":"code","e6514c60":"code","882bf0a1":"code","19a0b7e2":"code","8b1f9b50":"code","417f7c78":"code","42296915":"code","7c11b39a":"code","88162338":"code","6982fbd2":"code","d3b62e1e":"code","4b5fee86":"code","0c7da7b1":"code","957c674f":"code","ff9f3559":"code","7a096ddc":"code","ac151f35":"code","d5d37b8d":"code","d3ff850a":"code","d884b2ac":"code","f7b0d7ce":"code","ec87165c":"code","2b43a157":"code","7823ab01":"code","94e2ab35":"code","18016851":"code","a315a12c":"code","abef4563":"code","0cf1936a":"code","a2fc0717":"code","55d364e9":"code","835dce95":"code","b9c92d14":"code","44e75495":"code","93c32bd1":"code","79b27693":"code","d55dec6d":"code","ed363acb":"code","bddf70ef":"code","4e593300":"code","d2681960":"code","a791c197":"code","90841f1a":"code","faa71db2":"code","465c941d":"code","14e6be1c":"code","ecedff3c":"code","a3183082":"code","d1cfd3de":"code","4ba35f4c":"code","77d84886":"code","c7f44267":"code","359fbfb7":"code","725dcd64":"code","a26cb552":"code","0647503c":"code","edca55f1":"code","14934ad7":"code","d991725d":"code","32ae8545":"markdown","ab4ddba8":"markdown","544fde27":"markdown","6a00dff9":"markdown","db455509":"markdown","f46bfb2b":"markdown","d078a78e":"markdown","3fb759c9":"markdown","06c59860":"markdown","9052a422":"markdown","0c197d65":"markdown","6a5c8e16":"markdown","cf105209":"markdown","c78241ab":"markdown","053e68d9":"markdown","918f5dc6":"markdown","a6312e7f":"markdown","16d917ee":"markdown","07be65cc":"markdown","f13bcaa4":"markdown","43abf44e":"markdown","e7ca519d":"markdown","d694a597":"markdown","16dd4046":"markdown","73ef1790":"markdown","45169166":"markdown","7bde041a":"markdown","90f5767b":"markdown","7a2985b4":"markdown"},"source":{"fa1bb0b6":"# Check paths for meta, train, test, saving, img_path","bb0acf26":"!pip install -U efficientnet\nimport albumentations as albu","3cdf0898":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\n\nimport tensorflow as tf\nfrom keras.utils import to_categorical\nimport cv2\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras\nimport efficientnet.keras as efn\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, GlobalAveragePooling2D \nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom skimage.transform import resize\nimport albumentations as albu\nimport seaborn as sns\nimport pickle\nimport joblib\n","b74140b8":"#function to open the files in the Python version of the dataset\ndef unpickle(file):\n    with open(file, 'rb') as f:\n        dict = pickle.load(f, encoding='latin1')\n    return dict","d555fc7b":"#Local Path\n# path = ''\n# path","0b85f498":"#Kaggle Path\nmetadata_path = '..\/input\/cifar100\/meta'\n#Local Path\n#metadata_path = path + 'Data\\\\' + 'meta'\nmetadata = unpickle(metadata_path)","4303785d":"pd.set_option('display.max_rows', 110)\nsub_category = pd.DataFrame(metadata['fine_label_names'], columns = ['Sub_category'])\nsub_category","248c1f63":"sub_category.to_csv(\"sub_categories.csv\")","d4d5da12":"super_category = pd.DataFrame(metadata['coarse_label_names'], columns = ['Super_Category'])\nsuper_category","624c6841":"super_category.to_csv(\"super_categories.csv\")","0508a865":"#Kaggle Path\ntrain_path = '..\/input\/cifar100\/train'\n#Local Path\n#train_path = path + 'Data\\\\' + 'train'\ntrain = unpickle(train_path)\ntrain.keys()","1877a5ce":"for keys in train:\n    print(keys, type(train[keys]))","046d4d02":"train['batch_label']","56e1fa32":"len(train['filenames'])","500e930f":"np.unique(train['fine_labels'])    ","f90c216a":"np.unique(train['coarse_labels'])","ad844850":"print(len(train['data']))\nprint(train['data'][0].shape) #or\n#print(len(train['data'][0]))","e6514c60":"#Kaggle Path\ntest_path = '..\/input\/cifar100\/test'\n\n#Local Path\n#test_path = path + 'Data\\\\' + 'test'\ntest = unpickle(test_path)\ntest.keys()\nfor keys in test:\n    print(keys, type(test[keys]))\n","882bf0a1":"len(test['filenames'])","19a0b7e2":"test['batch_label']","8b1f9b50":"np.unique(test['fine_labels'])","417f7c78":"np.unique(test['coarse_labels'])","42296915":"print(len(test['data']))\nprint(test['data'][0].shape)","7c11b39a":"X_train = train['data']\nprint(\"X_train: \",'\\n\\n', X_train, '\\n')\n# Verify\nprint(\"Length: \",len(X_train))","88162338":"X_test = test['data']\nprint(\"X_test: \",'\\n\\n', X_test, '\\n')\n# Verify\nprint(\"Length: \",len(X_test))","6982fbd2":"y_train = train['fine_labels']\n#y_train","d3b62e1e":"y_test = test['fine_labels']\n#y_test","4b5fee86":"#4D array input for building the CNN model using Keras\nX_train = X_train.reshape(len(X_train),3,32,32).transpose(0,2,3,1)\nX_train.shape","0c7da7b1":"#transforming the testing dataset\nX_test = test['data']\nX_test = X_test.reshape(len(X_test),3,32,32).transpose(0,2,3,1)\nX_test.shape","957c674f":"rand_img = np.random.randint(0, len(X_train))\nrand_img","ff9f3559":"#generating a random number to display a random image from the dataset along with the label's number and name\n\nrcParams['figure.figsize'] = 5,5\n\nimg = np.random.randint(0, len(X_train))\n\nplt.imshow(X_train[img])\n\nplt.axis('off')\n\nprint(\"Image Number Selected: {}\".format(img))\nprint(\"Image Shape: {}\".format(X_train[img].shape))\nprint(\"Image Super Category Number: {}\".format(train['coarse_labels'][img]))\nprint(\"Image SuperCategory Name: {}\".format(super_category.iloc[train['coarse_labels'][img]][0].capitalize()))\nprint(\"Image Sub-Category Number: {}\".format(train['fine_labels'][img]))\nprint(\"Image Sub-Category Name: {}\".format(sub_category.iloc[train['fine_labels'][img]][0]))\n\n# print(\"Shape of image : {}\".format(X_train[img].shape))\n# print(\"Image category number: {}\".format(train['coarse_labels'][img]))\n# print(\"Image category name: {}\".format(category.iloc[trainData['coarse_labels'][imageId]][0].capitalize()))\n# print(\"Image subcategory number: {}\".format(trainData['fine_labels'][imageId]))\n# print(\"Image subcategory name: {}\".format(subCategory.iloc[trainData['fine_labels'][imageId]][0].capitalize()))","7a096ddc":"rcParams['figure.figsize'] = 8,8\n\nnrow = 4\nncol = 4\n\nimg = np.random.randint(0, len(X_train), nrow*ncol)\n#img\n\nfig, axes = plt.subplots(nrow, ncol)\nplt.suptitle(\"Images with Labels\", fontsize = 16)\n\nfor i in range(0, nrow):\n    for j in range(0, ncol):\n        k = (i*ncol) + j \n        axes[i, j].imshow(X_train[img[k]])\n        axes[i, j].set_title(sub_category.iloc[train['fine_labels'][img[k]]][0].capitalize())\n        axes[i, j].axis(\"off\")\nplt.show()\n","ac151f35":"n_classes = 100\ny_train = to_categorical(y_train, n_classes)\n#y_train\n\ny_test = to_categorical(y_test, n_classes)\ny_test","d5d37b8d":"#resizing the images as per EfficientNetB0 to size (224, 224)\nheight = 224\nwidth = 224\nchannels = 3\n\nn_classes = 100\ninput_shape = (height, width, channels)\n\nepochs = 60\nbatch_size = 8","d3ff850a":"def resize_img(img, shape):\n    return cv2.resize(img, (shape[1], shape[0]), interpolation=cv2.INTER_CUBIC)","d884b2ac":"#---- https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/image\/resize\n# This method requires large memory\n\n# X_train_data = []\n# for i in range(49992 ,len(X_train)):\n#     X_train_data.append(tf.image.resize(X_train[i], #Image\n#                          [244,244], #size \n#                          method = ResizeMethod.BILINEAR, #Method\n#                          preserve_aspect_ratio = False, \n#                          antialias = False, \n#                          name = None))\n\n# X_train_data = np.asarray(X_train_data)","f7b0d7ce":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, images, labels = None, mode = 'fit', batch_size = batch_size, dim = (height, width), channels = channels, n_classes = n_classes, shuffle = True, augment = False):\n        \n        #initializing the configuration of the generator\n        self.images = images\n        self.labels = labels\n        self.mode = mode\n        self.batch_size = batch_size\n        self.dim = dim\n        self.channels = channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.augment = augment\n        self.on_epoch_end()\n   \n    #method to be called after every epoch\n    def on_epoch_end(self):\n        self.indexes = np.arange(self.images.shape[0])\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    #return numbers of steps in an epoch using samples and batch size\n    def __len__(self):\n        return int(np.floor(len(self.images) \/ self.batch_size))\n    \n    #this method is called with the batch number as an argument to obtain a given batch of data\n    def __getitem__(self, index):\n        #generate one batch of data\n        #generate indexes of batch\n        batch_indexes = self.indexes[index * self.batch_size:(index+1) * self.batch_size]\n        \n        #generate mini-batch of X\n        X = np.empty((self.batch_size, *self.dim, self.channels))\n        \n        for i, ID in enumerate(batch_indexes):\n            #generate pre-processed image\n            img = self.images[ID]\n            #image rescaling\n            img = img.astype(np.float32)\/255.\n            #resizing as per new dimensions\n            img = resize_img(img, self.dim)\n            X[i] = img\n            \n        #generate mini-batch of y\n        if self.mode == 'fit':\n            y = self.labels[batch_indexes]\n            \n            #augmentation on the training dataset\n            if self.augment == True:\n                X = self.__augment_batch(X)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n        \n        else:\n            raise AttributeError(\"The mode should be set to either 'fit' or 'predict'.\")\n            \n    #augmentation for one image\n    def __random_transform(self, img):\n        composition = albu.Compose([albu.HorizontalFlip(p = 0.5),\n                                   albu.VerticalFlip(p = 0.5),\n                                   albu.GridDistortion(p = 0.2),\n                                   albu.ElasticTransform(p = 0.2)])\n        return composition(image = img)['image']\n    \n    #augmentation for batch of images\n    def __augment_batch(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i] = self.__random_transform(img_batch[i])\n        return img_batch","ec87165c":"train_data_generator = DataGenerator(X_train, y_train, augment = True)\nvalid_data_generator = DataGenerator(X_test, y_test, augment = False)","2b43a157":"# datagen = ImageDataGenerator(rotation_range=10, # rotate the image 20 degrees\n#                              width_shift_range=0.20, # Shift the pic width by a max of 5%\n#                              height_shift_range=0.20, # Shift the pic height by a max of 5%\n#                              rescale=1\/255, # Rescale the image by normalzing it.\n#                              shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n#                              zoom_range=0.1, # Zoom in by 10% max\n#                              horizontal_flip=True, # Allo horizontal flipping\n#                              fill_mode='nearest', # Fill in missing pixels with the nearest filled value\n#                              featurewise_center=True,\n#                              featurewise_std_normalization=True,\n#                             )","7823ab01":"efnb0 = efn.EfficientNetB0(weights = 'imagenet', include_top = False, input_shape = input_shape, classes = n_classes)\n\nmodel = Sequential()\nmodel.add(efnb0)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes, activation = 'softmax'))\n\nmodel.summary()","94e2ab35":"optimizer = Adam(lr = 0.0001)\n\n#early stopping to monitor the validation loss and avoid overfitting\nearly_stop = EarlyStopping(monitor ='val_loss', mode = 'min', verbose = 1, patience = 10, restore_best_weights = True)\n\n#reducing learning rate on plateau\nrlrop = ReduceLROnPlateau(monitor ='val_loss', mode = 'min', patience = 5, factor = 0.5, min_lr = 1e-6, verbose = 1)","18016851":"#model compiling\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])","a315a12c":"model_history = model.fit(train_data_generator,\n                            validation_data = valid_data_generator,\n                            callbacks = [early_stop, rlrop],\n                            verbose = 1,\n                            epochs = epochs)","abef4563":"#saving the trained model as data file in .h5 format\n#model.save(path + 'Model\\\\' + 'CIFAR-100_model.h5')\n\n#Save Model on Kaggle\n#model.save('CIFAR-100_model.h5')","0cf1936a":"#saving the trained model weights as data file in .h5 format\n#model.save_weights(path + 'Model\\\\' + 'cifar-100_Weights.h5')\n\n# Save Weights on Kaggle\n#model.save_weights(\"CIFAR-100_model_weights.h5\")","a2fc0717":"# #Load Model Locally\n# model = load_model(path + 'Model\\\\' + 'CIFAR-100_model.h5')\n\n# #Load Model on Kaggle\n# #model = load_model('CIFAR-100_model.h5')","55d364e9":"#plot to visualize the loss and accuracy against number of epochs\nplt.figure(figsize=(18,8))\n\nplt.suptitle('Loss and Accuracy Plots', fontsize = 18)\n\nplt.subplot(1,2,1)\nplt.plot(model_history.history['loss'], label = 'Training Loss')\nplt.plot(model_history.history['val_loss'], label = 'Validation Loss')\nplt.legend()\nplt.xlabel('Number of epochs', fontsize = 15)\nplt.ylabel('Loss', fontsize = 15)\n\nplt.subplot(1,2,2)\nplt.plot(model_history.history['accuracy'], label = 'Train Accuracy')\nplt.plot(model_history.history['val_accuracy'], label ='Validation Accuracy')\nplt.legend()\nplt.xlabel('Number of epochs', fontsize = 14)\nplt.ylabel('Accuracy', fontsize = 14)\nplt.show()","835dce95":"valid_loss, valid_accuracy = model.evaluate_generator(generator = valid_data_generator, verbose = 1)\n\nprint('\\n')\nprint(\"Test or Validation Loss: \", round(valid_loss * 100, 2), '%')\nprint('Validation Accuracy: ', round((valid_accuracy * 100), 2), \"%\")\n","b9c92d14":"#Since model.evaluate_generator() is being deprecated","44e75495":"valid_loss, valid_accuracy = model.evaluate(valid_data_generator, verbose = 1)\n\nprint('\\n')\nprint(\"Test or Validation Loss: \", round(valid_loss * 100, 2), '%')\nprint('Validation Accuracy: ', round((valid_accuracy * 100), 2), \"%\")","93c32bd1":"y_pred = model.predict_generator(DataGenerator(X_test, mode = 'predict', augment = False, shuffle = False), verbose = 1)\ny_pred = np.argmax(y_pred, axis = 1)\n\ntest_accuracy = accuracy_score(np.argmax(y_test, axis = 1), y_pred) #sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\nprint('Test Accuracy: ', round((test_accuracy * 100), 2), \"%\")","79b27693":"#Since model.predict_genrator() is being deprecated","d55dec6d":"y_pred = model.predict(DataGenerator(X_test, mode = 'predict', augment = False, shuffle = False), verbose = 1)\ny_pred = np.argmax(y_pred, axis = 1)\n\ntest_accuracy = accuracy_score(np.argmax(y_test, axis = 1), y_pred) #tsklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\nprint('Test Accuracy: ', round((test_accuracy * 100), 2), \"%\")","ed363acb":"cm = confusion_matrix(np.argmax(y_test, axis = 1), y_pred)\nprint(cm)","bddf70ef":"#report to see which category has been predicted incorectly and which has been predicted correctly\ntarget = [\"Category {}\".format(i) for i in range(n_classes)]\nprint(classification_report(np.argmax(y_test, axis = 1), y_pred, target_names = target))","4e593300":"#dataframe of predictions\nprediction = pd.DataFrame(y_pred)\nprediction.head()","d2681960":"#generating a random number to display a random image from the dataset along with the true and predicted label\nimageId = np.random.randint(0, len(X_test))\n\nrcParams['figure.figsize'] = 2,2\n\nplt.imshow(X_test[imageId])\n\nplt.axis('off')\n\nprint(\"True Label: \" + str(sub_category.iloc[test['fine_labels'][imageId]][0].capitalize()))\nprint(\"Predicted Label: \" + str(sub_category.iloc[prediction.iloc[imageId]]).split()[2].capitalize())","a791c197":"#16 random images to display at a time along with their true and random labels\nrcParams['figure.figsize'] = 12,15\n\nnum_row = 4\nnum_col = 4\n\nimageId = np.random.randint(0, len(X_test), num_row * num_col)\n\nfig, axes = plt.subplots(num_row, num_col)\n\nfor i in range(0, num_row):\n    for j in range(0, num_col):\n        k = (i*num_col) + j\n        axes[i,j].imshow(X_test[imageId[k]])\n        axes[i,j].set_title(\"True: \" + str(sub_category.iloc[test['fine_labels'][imageId[k]]][0]).capitalize() \n                             + \"\\nPredicted: \" + str(sub_category.iloc[prediction.iloc[imageId[k]]]).split()[2].capitalize(), \n                            fontsize=14)\n        axes[i,j].axis('off')\n        fig.suptitle(\"Images with True and Predicted Labels\", fontsize = 18) \n\nplt.show()","90841f1a":"#function to resize the image\ndef resize_test_image(test_img):\n\n    img = cv2.imread(test_img)\n    #plt.imshow(img)\n    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #plt.imshow(img_RGB)\n    resized_img = cv2.resize(img_RGB, (224, 224))\n    #plt.imshow(resized_img)\n    resized_img = resized_img \/ 255.\n    #plt.imshow(resized_img)\n    return resized_img\n    \n#resize_test_image('orange.jpeg')","faa71db2":"#function to get prediction for test image from the model\ndef predict_test_image(test_img):\n    \n    resized_img = resize_test_image(test_img)\n    prediction = model.predict(np.array([resized_img]))\n    \n    return prediction\n\n#predict_test_image('orange.jpeg')","465c941d":"#function to get the sorted prediction\ndef sort_prediction_test_image(test_img):\n    \n    prediction = predict_test_image(test_img)\n    \n    index = np.arange(0,100)\n    \n    for i in range(100):\n        for j in range(100):\n            if prediction[0][index[i]] > prediction[0][index[j]]:\n                temp = index[i]\n                index[i] = index[j]\n                index[j] = temp\n                \n    return index\n\n#sort_prediction_test_image('orange.jpeg')","14e6be1c":"#function to get the dataframe for top 5 predictions\ndef df_top5_prediction_test_image(test_img):\n    \n    sorted_index = sort_prediction_test_image(test_img)\n    prediction = predict_test_image(test_img)\n    \n    subCategory_name = []\n    prediction_score = []\n    \n    k = sorted_index[:6] \n    \n    for i in range(len(k)):\n        subCategory_name.append(sub_category.iloc[k[i]][0])\n        prediction_score.append(round(prediction[0][k[i]], 2))\n        \n    df = pd.DataFrame(list(zip(subCategory_name, prediction_score)), columns = ['Label', 'Probability'])  \n    \n    return df\n\n#df_top5_prediction_test_image('orange.jpeg')","ecedff3c":"#function to get the plot for top 5 predictions \ndef plot_top5_prediction_test_image(test_img):\n    \n    try:\n    \n        fig, axes = plt.subplots(1, 2, figsize = (15,4))\n        fig.suptitle(\"Prediction\", fontsize = 18)\n\n        new_img = plt.imread(test_img)\n        axes[0].imshow(new_img)\n        axes[0].axis('off')\n\n        data = df_top5_prediction_test_image(test_img)\n        x = df_top5_prediction_test_image(test_img)['Label']\n        y = df_top5_prediction_test_image(test_img)['Probability']\n\n        axes[1] = sns.barplot(x = x, y = y, data = data, color =\"green\")\n\n        plt.xlabel('Label', fontsize=14)\n        plt.ylabel('Probability', fontsize=14)\n\n        plt.ylim(0,1.0)\n\n        axes[1].grid(False)\n        axes[1].spines[\"top\"].set_visible(False)\n        axes[1].spines[\"right\"].set_visible(False)\n        axes[1].spines[\"bottom\"].set_visible(False)\n        axes[1].spines[\"left\"].set_visible(False)\n\n        plt.show()\n    \n    except Exception as e:\n        print(\"Check file path or file name\")","a3183082":"#Local\n#img_path = ''\n\n#kaggle\nimg_path = '..\/input\/images\/Images\/'","d1cfd3de":"plot_top5_prediction_test_image(img_path + 'Skunk.jpeg')","4ba35f4c":"plot_top5_prediction_test_image(img_path + 'Keyboard.jpeg')","77d84886":"plot_top5_prediction_test_image(img_path + 'Sea.jpeg')","c7f44267":"plot_top5_prediction_test_image(img_path + 'Clock.jpeg')","359fbfb7":"plot_top5_prediction_test_image(img_path + 'Lion.jpeg')","725dcd64":"plot_top5_prediction_test_image(img_path + 'Bottle.jpeg')","a26cb552":"plot_top5_prediction_test_image(img_path + 'Cat.jpeg')","0647503c":"plot_top5_prediction_test_image(img_path + 'Orchid.jpeg')","edca55f1":"plot_top5_prediction_test_image(img_path + 'Orange.jpeg')","14934ad7":"#saving the trained model as data file in .h5 format\n#model.save(path + 'Model\\\\' + 'CIFAR100_EfficientNetB0_Model.h5')\n\n#save model on kaggle\nmodel.save('CIFAR100_EfficientNetB0_Model.h5')","d991725d":"#saving model Weights\n#model.save_weights(path + 'Model\\\\' + 'CIFAR100_EfficientNetB0_Model_Weights.h5')\n\n#save model Weights on kaggle\nmodel.save(\"CIFAR100_EfficientNetB0_Model_Weights.h5\")","32ae8545":"## Loading the CIFAR-100 Dataset","ab4ddba8":"[https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly](http:\/\/)","544fde27":"100 different fine labels for the images (0 to 99)","6a00dff9":"### Exploring Few images together","db455509":"## Installing Libraries","f46bfb2b":"### Custom Data Generator class","d078a78e":"10 different coarse labels for the images (0 to 9)","3fb759c9":"## Model Prediction","06c59860":"## Converting Class Vectors to Binary Class Metrics","9052a422":"## Path","0c197d65":"### Importing Libraries","6a5c8e16":"# Model\n------------------------------------\n### Using pre-trained EfficientNetB0","cf105209":"## Check Paths","c78241ab":"## Train Data","053e68d9":"## Transform","918f5dc6":"## Testing the Model","a6312e7f":"## Model Plots (History)","16d917ee":"## Saving Model","07be65cc":"##### [https:\/\/keras.io\/api\/applications\/efficientnet\/](http:\/\/)\n##### [https:\/\/keras.io\/examples\/vision\/image_classification_efficientnet_fine_tuning\/](http:\/\/)","f13bcaa4":"## Metadata\n#### Meta file has a dictionary of fine labels and coarse labels.","43abf44e":"## Train\/Test Data","e7ca519d":"## Visualizing the Predictions\n","d694a597":"## Explore Images in Dataset","16dd4046":"## Constants","73ef1790":"50000 images in the training dataset and each image is a 3 channel 32 32 pixel image (32 32 * 3 = 3072)","45169166":"## Test Data","7bde041a":"## Load Model","90f5767b":"## Confusion Matrix","7a2985b4":"## Image Manupulation \/ Image Data Generator"}}