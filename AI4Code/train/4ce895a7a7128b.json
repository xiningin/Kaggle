{"cell_type":{"472dda8d":"code","971d57df":"code","32a0895e":"code","c451b2e9":"code","1c1b1599":"code","4dfa4522":"code","90be40f8":"code","89c2b298":"code","58ba3e46":"code","7ca880a1":"code","f2aa68de":"code","a00912cc":"code","7f6d7963":"code","c3e848dc":"code","a193ad17":"code","edb41fc8":"code","77d06b81":"markdown","f1bfa8de":"markdown","46584bcb":"markdown"},"source":{"472dda8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","971d57df":"import pandas as pd\nimport random\n\nWeek_days = ['Monday', 'Tuesday','Wednesday','Thursday','Friday'] \nWeekend = ['Saturday','Sunday']\nHour = []\nDates = []\nnb_passengers = []\nweekday_yes = []\n\nvar = 0\ni = -1\n\nwhile var<100:  \n    if i < len(Week_days)-1:\n        i+=1\n    else : \n        i = 0\n    for j in range(15): \n        Dates.append(Week_days[i])\n        weekday_yes.append(1)\n        Hour.append(j+6)\n        if (j+6) in [7,8,17,18,19,20]: \n            nb_passengers.append(random.randint(100,200))\n        else: \n            nb_passengers.append(random.randint(50,100))\n    var += 1\n\n\nvar = 0\ni = -1\nwhile var<100:  \n    if i < len(Weekend)-1:\n        i+=1\n    else:\n        i=0\n    for j in range(15): \n        Dates.append(Weekend[i])\n        weekday_yes.append(0)\n        Hour.append(j+6)\n        if (j+6) in [7,8,17,18,19,20]: \n            nb_passengers.append(round(random.randint(100,200)\/2))\n        else: \n            nb_passengers.append(round(random.randint(50,100)\/2))\n    var += 1\n\ndf = list(zip(Hour,nb_passengers,weekday_yes,Dates))\ndata = pd.DataFrame(df, columns=[\"Hour\", \"nb_passengers\", \"weekday_yes\",\"Dates\"])\n","32a0895e":"data.shape","c451b2e9":"data.head(15)","1c1b1599":"from sklearn.utils import shuffle\nimport random\nrandom.seed(40)\ndata=shuffle(data)","4dfa4522":"data.to_csv('fakedata_bus.csv', header=True)","90be40f8":"data.head(20)","89c2b298":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nx = data.iloc[:,0]\ny = data.iloc[:,1]\nplt.scatter(x, y)\nplt.xlabel('hours')\nplt.ylabel('passengers');","58ba3e46":"X = data.drop(\"nb_passengers\", axis=1)\nY = data[\"nb_passengers\"]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.3)","7ca880a1":"X_train.head()","f2aa68de":"\ncat_features = []\ndense_features = []\nfor col in X_train.columns:\n    if X_train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(X_train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(X_train[col].unique()))\n","a00912cc":"\nimport tqdm\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')","7f6d7963":"# Encoding categorical data\ntrain_cat = X_train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","c3e848dc":"params = {'lambda_l1': 0.001, 'lambda_l2': 0.001,\n 'num_leaves': 40, 'feature_fraction': 0.4,\n 'subsample': 0.4, 'min_child_samples': 10,\n 'learning_rate': 0.01,\n 'num_iterations': 100, 'random_state': 42}","a193ad17":"from lightgbm import LGBMClassifier\nclass MultiLGBMClassifier():\n    def __init__(self, resolution, params):\n        ## smoothing size\n        self.resolution = resolution\n        ## initiarize models\n        self.models = [LGBMClassifier(**params) for _ in range(resolution)]\n        \n    def fit(self, x, y):\n        self.classes_list = []\n        for k in tqdm_notebook(range(self.resolution)):\n            ## train each model\n            self.models[k].fit(x, (y + k) \/\/ self.resolution)\n            ## (0,1,2,3,4,5,6,7,8,9) -> (0,0,0,0,0,1,1,1,1,1) -> (0,5)\n            classes = np.sort(list(set((y + k) \/\/ self.resolution))) * self.resolution - k\n            classes = np.append(classes, 999)\n            self.classes_list.append(classes)\n            \n    def predict(self, x):\n        pred199_list = []\n        for k in range(self.resolution):\n            preds = self.models[k].predict_proba(x)\n            classes = self.classes_list[k]\n            pred199s = self.get_pred199(preds, classes)\n            pred199_list.append(pred199s)\n        self.pred199_list = pred199_list\n        pred199_ens = np.mean(np.stack(pred199_list), axis = 0)\n        return pred199_ens\n    \n    def _get_pred199(self, p, classes):\n        ## categorical prediction -> predicted distribution whose length is 199\n        pred199 = np.zeros(199)\n        for k in range(len(p)):\n            pred199[classes[k] + 99 : classes[k+1] + 99] = p[k]\n        return pred199\n\n    def get_pred199(self, preds, classes):\n        pred199s = []\n        for p in preds:\n            pred199 = np.cumsum(self._get_pred199(p, classes))\n            pred199 = pred199\/np.max(pred199)\n            pred199s.append(pred199)\n        return np.vstack(pred199s)","edb41fc8":"def make_pred(test, sample, env, model):\n    test = preprocess(test)\n    test = drop(test)\n    test = test.drop(un_use_features, axis = 1)\n    \n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n#             print(\"------\")\n#             print(\"test have unseen label : col\")\n            if not ((col + \"__nan\") in categories):\n#                 print(\"not nan in train : \", col)\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n#                 print(\"nan seen in train : \", col)\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n#     test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n#     test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n\n    test_dense_players = np.reshape(test_dense_players, (len(test_dense_players), -1))\n    test_dense = np.hstack([test_dense_players, test_dense_game])\n    test_cat_players = np.reshape(test_cat_players, (len(test_cat_players), -1))\n    test_cat = np.hstack([test_cat_players, test_cat_game])\n    test_x = np.hstack([test_dense, test_cat])\n\n    test_inp = test_x\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)\n        pred += _pred\n    pred \/= len(models)\n    pred = np.clip(pred, 0, 1)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred\n","77d06b81":"PREDICTION","f1bfa8de":"MODEL","46584bcb":"![](http:\/\/)"}}