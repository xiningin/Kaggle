{"cell_type":{"a5494d33":"code","b5e781be":"code","0955c0ef":"code","ce326c7c":"code","9fab9451":"code","e7d5fa9b":"code","cbce6e75":"code","09e3b8fa":"code","87ea04cc":"code","d3661a7f":"code","765ce8f9":"code","64e59101":"code","2fe3d0b3":"code","70d4f0cf":"code","e4921ea3":"code","57856988":"code","82437e54":"code","e9804bd3":"code","695c825b":"code","1ee3b2e3":"code","ac102eca":"code","c33c6e37":"code","73a87ffb":"code","1abff54f":"code","f0a60338":"code","f8c4b309":"code","326506eb":"code","0b0a9923":"code","345cd3cf":"code","b086bff9":"code","50aca6d0":"code","8857b84a":"code","a92378f1":"code","4c974463":"code","89765a4f":"code","3afe3e3f":"code","5d1ec7c6":"code","71797651":"code","306b78f2":"code","c90926c6":"code","efc14f83":"code","c6fd19bf":"code","fcaf2692":"code","3857ecb6":"code","c2c702be":"code","5c2cc321":"code","c0ac7ddb":"markdown","736db5af":"markdown","97a40cc3":"markdown","4d3174c4":"markdown","ba59cdec":"markdown","90422ebe":"markdown","d24d77d6":"markdown","b736c9fb":"markdown","50703fff":"markdown","a4efd561":"markdown","12a0d3cd":"markdown","0c5532c1":"markdown","1be366f1":"markdown"},"source":{"a5494d33":"#Import all necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b5e781be":"#Import the Dataset\ndf=pd.read_csv('..\/input\/usa-housing\/USA_Housing.csv')","0955c0ef":"#Data Overview\ndf.head()","ce326c7c":"print('The Dataset has got {} rows and {} columns'.format(df.index.nunique(),df.columns.nunique()))","9fab9451":"df.info()","e7d5fa9b":"df.columns","cbce6e75":"#EDA\nplt.figure(figsize=(8,5),dpi=200)\nsns.pairplot(df)","09e3b8fa":"plt.figure(figsize=(8,5),dpi=150)\nsns.distplot(df['Price'],hist_kws=dict(edgecolor='yellow' ,linewidth=3),color='purple')\n","87ea04cc":"#df.corr()\nsns.heatmap(df.corr(), annot=True,cmap='Blues')","d3661a7f":"#Determine the Features & Target Variable\nX=df[['Avg. Area Income','Avg. Area House Age','Avg. Area Number of Rooms','Avg. Area Number of Bedrooms','Area Population']]\ny=df['Price']\n","765ce8f9":"#Split the Dataset to Train & Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","64e59101":"#Train the Model\nfrom sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\nmodel.fit(X_train, y_train)\npd.DataFrame(model.coef_ , X.columns ,columns=['coefcient'])","2fe3d0b3":"#predicting Test Data\ny_pred= model.predict(X_test)\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred})[:5]","70d4f0cf":"#Evaluating the Model\nfrom sklearn import metrics\nMAE_linear=metrics.mean_absolute_error(y_test , y_pred)\nMSE_linear=metrics.mean_squared_error(y_test , y_pred)\nRMSE_linear=np.sqrt(MSE_linear)\npd.DataFrame([MAE_linear,MSE_linear,RMSE_linear], index=['MAE_linear','MSE_linear','RMSE_linear'],columns=['Quantity'])","e4921ea3":"#Residuals:\ntest_residual=y_test-y_pred\nsns.scatterplot(x=y_test,y=y_pred,color='green' ,s=200)\nplt.ylabel('y_pred')\nplt.xlabel('y_test')\nplt.title('bias of y')","57856988":"sns.scatterplot(x=y_test,y=test_residual,s=200)\nplt.axhline(y=0,color='red',ls='--')","82437e54":"# Preprocessing\nfrom sklearn.preprocessing import PolynomialFeatures\npolynomial_converter=PolynomialFeatures(degree=2, include_bias=False)\npoly_features=polynomial_converter.fit(X)\npoly_features=polynomial_converter.transform(X)\n","e9804bd3":"# Split the Data to Train & Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n","695c825b":"# Train the Model\nfrom sklearn.linear_model import LinearRegression\npolymodel=LinearRegression()\npolymodel.fit(X_train, y_train)\n","1ee3b2e3":"# Predicting Test Data\ny_pred=polymodel.predict(X_test)\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred, 'Residuals':(y_test-y_pred) }).head(5)","ac102eca":"# Evaluating the Model\nfrom sklearn import metrics\nMAE_Poly = metrics.mean_absolute_error(y_test,y_pred)\nMSE_Poly = metrics.mean_squared_error(y_test,y_pred)\nRMSE_Poly = np.sqrt(MSE_Poly)\n\npd.DataFrame([MAE_Poly, MSE_Poly, RMSE_Poly], index=['MAE_Poly', 'MSE_Poly', 'RMSE_Poly'], columns=['metrics'])","c33c6e37":"# Adjusting Model Parameters\n# Train List of RMSE per degree\ntrain_RMSE_list=[]\n#Test List of RMSE per degree\ntest_RMSE_list=[]\n\nfor d in range(1,14):\n    \n    #Preprocessing\n    #create poly data set for degree (d)\n    polynomial_converter= PolynomialFeatures(degree=d, include_bias=False)\n    poly_features= polynomial_converter.fit(X)\n    poly_features= polynomial_converter.transform(X)\n    \n    #Split the dataset\n    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n    \n    #Train the Model\n    polymodel=LinearRegression()\n    polymodel.fit(X_train, y_train)\n    \n    #Predicting on both Train & Test Data\n    y_train_pred=polymodel.predict(X_train)\n    y_test_pred=polymodel.predict(X_test)\n    \n    #Evaluating the Model\n    \n    #RMSE of Train set\n    train_RMSE=np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n    \n    #RMSE of Test Set\n    test_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n    \n    #Append the RMSE to the Train and Test List\n    \n    train_RMSE_list.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)","73a87ffb":"pd.DataFrame({'train_RMSE_list': train_RMSE_list,'test_RMSE_list':test_RMSE_list})[:5]","1abff54f":"#**Plot the Polynomial degree VS RMSE**\n\nplt.plot(range(1,14), train_RMSE_list[:13], label='Train RMSE')\nplt.plot(range(1,14), test_RMSE_list[:13], label='Test RMSE')\n\nplt.xlabel('Polynomial Degree')\nplt.ylabel('RMSE')\nplt.legend()","f0a60338":"#Preprocessing\nfrom sklearn.preprocessing import PolynomialFeatures\npolynomial_converter= PolynomialFeatures(degree=1, include_bias=False)\npoly_features= polynomial_converter.fit_transform(X)\n","f8c4b309":"# Split the Data to Train & Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","326506eb":"# Scaling the Data\nfrom sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaler.fit(X_train)\nX_train= scaler.transform(X_train)\nX_test= scaler.transform(X_test)","0b0a9923":"#Regularization\n#1- Ridge Regression\n#Train the Model\nfrom sklearn.linear_model import Ridge\nridge_model= Ridge(alpha=10)\nridge_model.fit(X_train, y_train)\n","345cd3cf":"#predict Test Data\ny_pred= ridge_model.predict(X_test)","b086bff9":"#Evaluating the Model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nMAE= mean_absolute_error(y_test, y_pred)\nMSE= mean_squared_error(y_test, y_pred)\nRMSE= np.sqrt(MSE)\npd.DataFrame([MAE, MSE, RMSE], index=['MAE_Ridge', 'MSE_Ridge', 'RMSE_Ridge'], columns=['metrics'])","50aca6d0":"#Ridge Regression (Coosing an alpha value with Cross-Validation\n #Train the Model\nfrom sklearn.linear_model import RidgeCV\nridge_cv_model=RidgeCV(alphas=(0.1, 1.0, 10.0), scoring='neg_mean_absolute_error')\nridge_cv_model.fit(X_train, y_train)","8857b84a":"ridge_cv_model.alpha_","a92378f1":"#Predicting Test Data\ny_pred_ridge= ridge_cv_model.predict(X_test)","4c974463":"MAE_ridge= mean_absolute_error(y_test, y_pred_ridge)\nMSE_ridge= mean_squared_error(y_test, y_pred_ridge)\nRMSE_ridge= np.sqrt(MSE_ridge)\npd.DataFrame([MAE_ridge, MSE_ridge, RMSE_ridge], index=['MAE_ridge_CV', 'MSE_ridge_CV', 'RMSE_ridge_CV'], columns=['Ridge Metrics'])","89765a4f":"ridge_cv_model.coef_","3afe3e3f":"#2- Lasso Regression\nfrom sklearn.linear_model import LassoCV\nlasso_cv_model= LassoCV(eps=0.01, n_alphas=100, cv=5)\nlasso_cv_model.fit(X_train, y_train)\n","5d1ec7c6":"lasso_cv_model.alpha_","71797651":"y_pred_lasso= lasso_cv_model.predict(X_test)\nMAE_Lasso= mean_absolute_error(y_test, y_pred_lasso)\nMSE_Lasso= mean_squared_error(y_test, y_pred_lasso)\nRMSE_Lasso= np.sqrt(MSE_Lasso)\n","306b78f2":"pd.DataFrame([MAE_Lasso, MSE_Lasso, RMSE_Lasso], index=['MAE_Lasso', 'MSE_Lasso', 'RMSE_Lasso'], columns=['Lasso Metrics'])","c90926c6":"lasso_cv_model.coef_","efc14f83":"#3- Elastic Net\nfrom sklearn.linear_model import ElasticNetCV\nelastic_model= ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],cv=5, max_iter=100000)\nelastic_model.fit(X_train, y_train)\n\n","c6fd19bf":"elastic_model.l1_ratio_","fcaf2692":"y_pred_elastic=elastic_model.predict(X_test)","3857ecb6":"MAE_Elastic= mean_absolute_error(y_test, y_pred_elastic)\nMSE_Elastic= mean_squared_error(y_test, y_pred_elastic)\nRMSE_Elastic= np.sqrt(MSE_Elastic)","c2c702be":"pd.DataFrame([MAE_Elastic, MSE_Elastic, RMSE_Elastic], index=['MAE_Elastic', 'MSE_Elastic', 'RMSE_Elastic'], columns=['Elastic Metrics'])","5c2cc321":"elastic_model.coef_","c0ac7ddb":"The **Prise** has got normal distribution.","736db5af":"we predict a y quantity for each y_test data and then compare it with the real value of its label to understand how much the model is aqurated.","97a40cc3":"**Starting Linear Regressin model:**","4d3174c4":"The plot shows intenses are choosed accidently from all parts and doesnt have specific pattern so the model words well.","ba59cdec":" Starting Regularization:","90422ebe":"**Predicting Housing Prices for regions in the USA.**\nThe data contains the following columns:\n\n**'Avg. Area Income':** Avg. Income of residents of the city house is located in.\n\n**'Avg. Area House Age':** Avg Age of Houses in same city.\n\n**'Avg. Area Number of Rooms':** Avg Number of Rooms for Houses in same city.\n\n**'Avg. Area Number of Bedrooms':** Avg Number of Bedrooms for Houses in same city.\n\n**'Area Population':** Population of city house is located in.\n\n**'Price':** Price that the house sold at.\n\n**'Address':** Address for the house","d24d77d6":"**Starting Polynomial Model**","b736c9fb":"This shows relations are linear.","50703fff":"we split datas to a group of *features(X)* and a *label(y)*.","a4efd561":"So linear Regressin is the best Model ","12a0d3cd":"Metrics help us to figure out errors densitys.","0c5532c1":"The plot shows that Linear Regression is better than polynomial Regrassion","1be366f1":"This time we split Datas to train and test ,building a model on train datas and evaluating the model in test datas."}}