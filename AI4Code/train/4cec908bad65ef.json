{"cell_type":{"8b257f83":"code","cde3657c":"code","c7f6898b":"code","e6b6fa87":"code","adba1fde":"code","783581c1":"code","d165d6ec":"code","9739c151":"code","7c452276":"code","d6b6edc4":"code","ec26a1bb":"code","320e69dd":"code","1675452f":"code","06af7608":"code","fd2d7751":"code","8809f1a6":"code","ef51595c":"code","1b6c29e3":"code","d2204fc7":"code","85941e54":"code","ab6eab70":"code","98814f12":"code","d9cec141":"code","fe95d3b6":"code","214d4cda":"code","8a29d450":"code","4d605031":"code","5ec7e30e":"code","0ec25eff":"code","a95e8a98":"code","3e061f32":"markdown"},"source":{"8b257f83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory","cde3657c":"# import libraries \nimport fastai \nfrom fastai import * \nfrom fastai.text import * \nimport pandas as pd \nimport numpy as np \nfrom functools import partial \nimport io \nimport os","c7f6898b":"from sklearn.datasets import fetch_20newsgroups ","e6b6fa87":"dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove= \n                             ('headers', 'footers', 'quotes'))\n","adba1fde":"documents = dataset.data","783581c1":"df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})","d165d6ec":"df.shape","9739c151":"df = df[df['label'].isin([1,10])] \ndf = df.reset_index(drop = True)","7c452276":"df['label'].value_counts()","d6b6edc4":"df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")","ec26a1bb":"import nltk\nnltk.download('stopwords') \nfrom nltk.corpus import stopwords ","320e69dd":"stop_words = stopwords.words('english')","1675452f":"# tokenization \ntokenized_doc = df['text'].apply(lambda x: x.split()) ","06af7608":"# remove stop-words \ntokenized_doc = tokenized_doc.apply(lambda x:[item for item in x if \n                                    item not in stop_words]) ","fd2d7751":"# de-tokenization \ndetokenized_doc = [] ","8809f1a6":"for i in range(len(df)):\n    t =' '.join(tokenized_doc[i]) \n    detokenized_doc.append(t) ","ef51595c":"df['text'] = detokenized_doc","1b6c29e3":"from sklearn.model_selection import train_test_split ","d2204fc7":"# split data into training and validation set \ndf_trn, df_val = train_test_split(df, stratify = df['label'], \n                                  test_size = 0.4, \n                                  random_state = 12)","85941e54":"df_trn.shape, df_val.shape","ab6eab70":"# Language model data \ndata_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = \n                                  df_val, path = \"\") \n","98814f12":"# Classifier model data \ndata_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, \n                                      valid_df = df_val,  \n                                      vocab=data_lm.train_ds.vocab, \n                                      bs=32)","d9cec141":"learn = language_model_learner(data_lm, pretrained_model=URLs.WT103,  \n                               drop_mult=0.7)","fe95d3b6":"# train the learner object with learning rate = 1e-2 \nlearn.fit_one_cycle(3, 1e-2)","214d4cda":"learn.save_encoder('ft_enc')","8a29d450":"learn = text_classifier_learner(data_clas, drop_mult=0.7) \nlearn.load_encoder('ft_enc')","4d605031":"learn.fit_one_cycle(1, 1e-2)","5ec7e30e":"learn.unfreeze()\nlearn.fit_one_cycle(2, slice(2e-3\/100, 2e-3))","0ec25eff":"# get predictions \npreds, targets = learn.get_preds(DatasetType.Valid) \npredictions = np.argmax(preds, axis = 1) ","a95e8a98":"%matplotlib inline\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=2)\n#predictions = model.predict(X_test, batch_size=1000)\n\nLABELS = ['graphics','hockey'] \n\nconfusion_matrix = metrics.confusion_matrix(targets, predictions)\n\nplt.figure(figsize=(5, 5))\nsns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\", annot_kws={\"size\": 20});\nplt.title(\"Confusion matrix\", fontsize=20)\nplt.ylabel('True label', fontsize=20)\nplt.xlabel('Predicted label', fontsize=20)\nplt.show()","3e061f32":"https:\/\/mc.ai\/tutorial-on-text-classification-nlp-using-ulmfit-and-fastai-library-in-python\/"}}