{"cell_type":{"d20b9b62":"code","8c0b81fa":"code","f84e4c00":"code","819291f0":"code","55449ee5":"code","e372d2a7":"code","0048a224":"code","704ce0a1":"code","5c0acefb":"code","d091277a":"code","0edf1baf":"code","ef75f7bd":"code","534244be":"code","ab6544d8":"code","e2efc492":"code","f2e94b4e":"code","a9b51561":"code","cae442e8":"code","bceb5e0f":"code","c246fe73":"code","585558ad":"code","9f00aa91":"code","91204c89":"code","b5d5c283":"code","32a24394":"code","3a91ea95":"code","79e82a47":"code","3eddd19e":"code","515a5872":"code","2f121911":"code","90e8b51e":"code","901bc48d":"code","050916e3":"code","bcb7e71a":"code","20796088":"code","d13b048b":"code","31dffb24":"code","a7908864":"code","dd6bcbcd":"code","16fdea8b":"code","7feba0cb":"code","bbf21790":"code","b4173c33":"markdown","2d252af1":"markdown","229c5d87":"markdown","af7481cf":"markdown","f461bd5a":"markdown","c87e148a":"markdown","8a8b399d":"markdown","ae3f9fb0":"markdown","50befee5":"markdown","c3a5a7a8":"markdown","169822e7":"markdown","35c1033b":"markdown","422404d7":"markdown","02711608":"markdown"},"source":{"d20b9b62":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c0b81fa":"df = pd.read_csv(\"\/kaggle\/input\/google-data-historic-dataset\/GOOGL.csv\")","f84e4c00":"df.head()","819291f0":"#Shape : Dimensions of the dataset\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","55449ee5":"# descriptions\nprint('description de la base')\nprint(df.describe())","e372d2a7":"#info\ndf.info()","0048a224":"print(\"Total missing values:\", df.isna().sum().sum())","704ce0a1":"from matplotlib import pyplot\nimport matplotlib.pyplot as plt","5c0acefb":"#histograms: here we have the histograms of each variant\n# with fisize, we also customize the size of the figures\ndf.hist (figsize = (17,17))\nplt.show ()","d091277a":"# it is a matrix which presents all the relations between each two variables\npd.plotting.scatter_matrix (df, figsize = (17,17))\npyplot.show ()","0edf1baf":"# Making train and test data\ndata_train = df[df['Date']<'2019-01-01'].copy()\ndata_test = df[df['Date']>='2019-01-01'].copy()\ndata_training=data_train.copy()","ef75f7bd":"# Dropping 'Date' and 'Adj Close'\ndata_train = data_train.drop(['Date', 'Adj Close'], axis = 1)","534244be":"print(data_train.shape)\nprint(data_test.shape)","ab6544d8":"from sklearn.preprocessing import MinMaxScaler\n#from sklearn.preprocessing import StandardScaler # used for feature scaling\n\n# feature scaling\n#We use feature scaling to convert different scales \n#to a standard scale to make it easier for Machine Learning algorithms.\n# sc = StandardScaler()\nsc = MinMaxScaler()\ndata_train= sc.fit_transform(data_train)\ndata_train","e2efc492":"X_train = []\ny_train = []\n\nfor i in range(60, data_train.shape[0]):\n    X_train.append(data_train[i-60:i])\n    y_train.append(data_train[i, 0])\n    \nX_train, y_train = np.array(X_train), np.array(y_train)","f2e94b4e":"print(X_train.shape)\nprint(y_train.shape)","a9b51561":"# Importing the Keras libraries and packages\n\nfrom keras.models import Sequential  \nfrom keras.layers import Dense \nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout # it block to overfitting ","cae442e8":"# Initialising the RNN\nmodel1 = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nmodel1.add(SimpleRNN(units = 60,activation='relu', return_sequences = True, input_shape = (X_train.shape[1], 5)))\nmodel1.add(Dropout(0.2))\n# Adding a second RNN layer and some Dropout regularisation.\nmodel1.add(SimpleRNN(units = 60,activation='relu', return_sequences = True))\nmodel1.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation. \nmodel1.add(SimpleRNN(units = 80,activation='relu', return_sequences = True))\nmodel1.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation.\nmodel1.add(SimpleRNN(units = 120))\nmodel1.add(Dropout(0.2))\n\n# Adding the output layer\nmodel1.add(Dense(units = 1))","bceb5e0f":"model1.summary()","c246fe73":"# Compiling the RNN\nmodel1.compile(optimizer = 'adam', loss = 'mean_squared_error')","585558ad":"# Fitting the RNN to the Training set\nmodel1.fit(X_train, y_train, epochs =50, batch_size = 32)","9f00aa91":"#Prepare test data\ndata_test.head()","91204c89":"past_60_days = data_training.tail(60)\ndata_test = past_60_days.append(data_test, ignore_index = True)\n# Dropping 'Date' and 'Adj Close'\ndata_test = data_test.drop(['Date', 'Adj Close'], axis = 1)\ndata_test.head()","b5d5c283":"# Scaling test data\ndata_test = sc.transform(data_test)\ndata_test","32a24394":"X_test = []\ny_test = []\n\nfor i in range(60, data_test.shape[0]):\n    X_test.append(data_test[i-60:i])\n    y_test.append(data_test[i, 0])\n\nX_test, y_test = np.array(X_test), np.array(y_test)\nX_test.shape, y_test.shape","3a91ea95":"#predictions\ny_pred1 = model1.predict(X_test)\ny_pred1.shape","79e82a47":"sc.scale_","3eddd19e":"scale = 1\/8.18605127e-04\nscale","515a5872":"y_pred1 = y_pred1*scale\ny_test = y_test*scale","2f121911":"# Visualising the results\nplt.figure(figsize=(14,5))\nplt.plot(y_test, color = 'orange', label = 'Real Google Stock Price')\nplt.plot(y_pred1, color = \"c\", label = 'Predicted Google Stock Price, Simple RNN')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","90e8b51e":"from tensorflow.keras.layers import LSTM","901bc48d":"#Initializing the RNN\nmodel2 = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nmodel2.add(LSTM(units = 60, activation = 'relu', return_sequences = True, input_shape = (X_train.shape[1], 5)))\nmodel2.add(Dropout(0.2))\n# Adding a second RNN layer and some Dropout regularisation.\nmodel2.add(LSTM(units = 60, activation = 'relu', return_sequences = True))\nmodel2.add(Dropout(0.2))\n# Adding a third RNN layer and some Dropout regularisation. \nmodel2.add(LSTM(units = 80, activation = 'relu', return_sequences = True))\nmodel2.add(Dropout(0.2))\n# Adding a fourth RNN layer and some Dropout regularisation.\nmodel2.add(LSTM(units = 120, activation = 'relu'))\nmodel2.add(Dropout(0.2))\n# Adding the output layer\nmodel2.add(Dense(units = 1))","050916e3":"model2.summary()","bcb7e71a":"#Compiling the RNN\nmodel2.compile(optimizer = 'adam', loss = 'mean_squared_error')","20796088":"model2.fit(X_train, y_train, epochs = 50, batch_size = 32)","d13b048b":"X_test = []\ny_test = []\n\nfor i in range(60, data_test.shape[0]):\n    X_test.append(data_test[i-60:i])\n    y_test.append(data_test[i, 0])\n\nX_test, y_test = np.array(X_test), np.array(y_test)\nX_test.shape, y_test.shape","31dffb24":"#predictions\ny_pred2 = model2.predict(X_test)\ny_pred2.shape","a7908864":"sc.scale_","dd6bcbcd":"scale = 1\/8.18605127e-04\nscale","16fdea8b":"y_pred2 = y_pred2*scale\ny_test = y_test*scale","7feba0cb":"# Visualising the results\nplt.figure(figsize=(14,5))\nplt.plot(y_test, color = 'LimeGreen', label = 'Real Google Stock Price')\nplt.plot(y_pred2, color = 'Gold', label = 'Predicted Google Stock Price, LSTM')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","bbf21790":"# Visualising the results\nplt.figure(figsize=(14,5))\nplt.plot(y_test, color = 'LimeGreen',linestyle='dashed', label = 'Real Google Stock Price')\nplt.plot(y_pred1, color = 'c', label = 'Predicted Google Stock Price, Simple RNN')\nplt.plot(y_pred2, color = 'Gold', label = 'Predicted Google Stock Price, LSTM')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","b4173c33":"Importing keras libraries","2d252af1":"# Simple RNN","229c5d87":"*Splitting training_data into X_train and y_train*","af7481cf":"Importing keras libraries","f461bd5a":"**Data Preprocessing**","c87e148a":"**Data visualization**","8a8b399d":"Handling of Missing Data","ae3f9fb0":"**Importing the libraries**","50befee5":"Importing the Dataset","c3a5a7a8":"# Comparison between Simple RNN and LSTM","169822e7":"# LSTM","35c1033b":"Feature scaling","422404d7":"We are going to train the model on data of 60 days at a time. So the code mentioned below divides the data into chunks of 60 rows.","02711608":"Making the predictions and visualizing the results"}}