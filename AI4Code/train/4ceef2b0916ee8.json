{"cell_type":{"8166864b":"code","63c327fa":"code","11f6940f":"code","1185dd70":"code","e252e76d":"code","84052938":"code","5159ea22":"code","1ba2aaa2":"code","2a01fd12":"code","5ef4846a":"code","e1316423":"code","a5634149":"code","096477f7":"markdown","dd4bdbea":"markdown","385a5395":"markdown","081ca4e2":"markdown","8b86609d":"markdown","f8cc61c7":"markdown"},"source":{"8166864b":"import pandas as pd\n\n#First to load the csv file into the runtime\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_train.head()","63c327fa":"# Have a quick & basic understanding of the dataset\nprint ('Columns in the dataset:')\nprint (df_train.columns)\nprint ('')\nprint ('Shape of the dataset: ')\nprint (df_train.shape)\nprint ('')\nprint ('Quick stats of the prediction targe')\nprint (df_train['SalePrice'].describe())","11f6940f":"import seaborn as sns\n\n#Visualization of the distribtion of the prediction target\nsns.kdeplot(df_train['SalePrice'])","1185dd70":"import pandas as pd\n\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_test.head()","e252e76d":"# Have a quick & basic understanding of the Testing dataset\nprint ('Columns in the dataset:')\nprint (df_test.columns)\nprint ('')\nprint ('Shape of the dataset: ')\nprint (df_test.shape)","84052938":"print ('Training dataset with NULLs:')\nprint (df_train.isnull()\n        .sum()\n        .sort_values(ascending = False)\n        .loc[lambda x : x >0]) # only get those columns with NULL values\nprint ('')\nprint ('Test dataset with NULLs:')\nprint (df_test.isnull()\n        .sum()\n        .sort_values(ascending = False)\n        .loc[lambda x : x >0]) # only get those columns with NULL values","5159ea22":"df_train_cleaned = df_train.fillna('None')\ndf_train_cleaned.head()","1ba2aaa2":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ny = df_train_cleaned['SalePrice'] #Prediction Target\nfeature_names = [i for i in df_train_cleaned.columns if df_train_cleaned[i].dtype in [np.int64]]\nX = df_train_cleaned[feature_names].drop(columns=['Id','SalePrice'])\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmy_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n\nprint ('Traning completed')","2a01fd12":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())","5ef4846a":"from sklearn.metrics import mean_absolute_error\n# Train the model with the Features with high importance\n\ny = df_train_cleaned['SalePrice'] #Prediction Target\nfeature_names = ['FullBath',\n                'MoSold',\n                'HalfBath',\n                'OpenPorchSF',\n                'BsmtFinSF1',\n                'GarageArea',\n                'GarageCars']\n\n\nX = df_train_cleaned[feature_names]\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmy_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n\nprint ('MAE: ' + str(mean_absolute_error(val_y, my_model.predict(val_X))))","e1316423":"# Transform the results into desired format before exporting\nresult = my_model.predict(val_X)\ndf_result = pd.Series(result)\ndf_result = pd.concat([df_result, df_train['Id']], axis=1)\ndf_result.columns = ['SalePrice','Id']\ndf_result = (df_result[['Id', 'SalePrice']]\n             .set_index('Id')\n             .drop([1460])\n             .fillna(0)\n            )\n\ndf_result.head()","a5634149":"# Export the result as a csv file\nprint('result shape: ' + str(df_result.shape))\nprint('Exporting...')\ndf_result.to_csv(path_or_buf='submission.csv', index=False)\nprint('Exporting Complete!')","096477f7":"## Test dataset","dd4bdbea":"# Modelling (with RandomForestClassifier)","385a5395":"# Clean up the data before modelling","081ca4e2":"## Feature Importances ","8b86609d":"## Training data","f8cc61c7":"# Datasets exploration"}}