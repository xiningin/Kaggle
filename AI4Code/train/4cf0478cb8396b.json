{"cell_type":{"cf93ad26":"code","47cf153a":"code","6419085d":"code","81026473":"code","db83f1d6":"code","b0620c55":"code","69c5b84a":"code","378958eb":"code","68f06d9c":"code","535f00cd":"code","d2f1a428":"code","74d3bbd4":"code","48c5f1f9":"code","920091cf":"code","ebfb8377":"code","0e942a50":"code","0570324a":"code","a038b559":"code","9e0dd751":"code","a3691df0":"code","020d125a":"code","8169d7a3":"code","f930807e":"code","72f8a2c2":"code","754a7500":"code","d877732b":"code","04e1eca2":"code","e4ec3d67":"code","313c439b":"code","243c795d":"code","94304d28":"code","5d2818b7":"code","404358a7":"code","92fc2dc9":"code","00464f72":"code","58a270ea":"code","a9229ad7":"code","d0a31312":"code","06fee1ea":"code","4aac1336":"code","d037508a":"code","f732eb60":"code","a5ad9429":"code","776f2b18":"code","50621788":"code","18d0ccb9":"code","0b80a80e":"code","51b61fa5":"code","76737de8":"code","67c921e8":"code","fb969297":"code","0c86cb14":"code","56c84ac4":"markdown","d0a0bc8b":"markdown","f1efb4e4":"markdown","bb1f89af":"markdown","52775a4f":"markdown","fdfb7aea":"markdown","a743ba69":"markdown","a798b1cc":"markdown"},"source":{"cf93ad26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn .linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nimport warnings\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47cf153a":"warnings.filterwarnings('ignore')\n","6419085d":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.head()\n","81026473":"testData_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntestData_data.head()","db83f1d6":"train_data.isnull().sum()","b0620c55":"train_data[[\"Embarked\",\"Name\"]].groupby(by=[\"Embarked\"],as_index=True).count().sort_values(\"Name\",ascending=False)","69c5b84a":"most_repeated = \"S\"\ntrain_data.Embarked.replace(np.nan, most_repeated, inplace=True)\ntestData_data.Embarked.replace(np.nan, most_repeated, inplace=True)\nprint(\"the number of null value in Embarked Column =\",train_data.Embarked.isnull().sum())","378958eb":"Embarked_transform_dict = {\"S\":1, \"C\":2, \"Q\":3}\nfor value in Embarked_transform_dict:\n    train_data.Embarked.replace(value, Embarked_transform_dict.get(value), inplace=True)\n    testData_data.Embarked.replace(value, Embarked_transform_dict.get(value), inplace=True)\ntrain_data.head(5)","68f06d9c":"print(\"the number of null value in Cabin Column =\", train_data.Cabin.isnull().sum())\ntrain_data.drop(\"Cabin\", axis=1, inplace=True)\ntestData_data.drop(\"Cabin\", axis=1, inplace=True)\n\ntrain_data.head()","535f00cd":"print(\"Range of Fare column values = \", train_data.Fare.max() - train_data.Fare.min())\ntestData_data.Fare.replace(np.nan, testData_data.Fare.mean(), inplace=True)\nprint(\"Range of Fare column values = \", testData_data.Fare.max() - testData_data.Fare.min())","d2f1a428":"train_data.Fare = train_data.Fare.astype(\"int64\")\ntestData_data.Fare = testData_data.Fare.astype(\"int64\")\n\n# df_train.info()\ntestData_data.head()","74d3bbd4":"Sex_dict = {\"male\":1, \"female\":2}\nfor key, value in Sex_dict.items():\n    train_data.Sex.replace(key, value, inplace=True)\n    testData_data.Sex.replace(key, value, inplace=True)\ntrain_data.Sex = train_data.Sex.astype(\"int64\")\ntestData_data.Sex = testData_data.Sex.astype(\"int64\")\ntrain_data.head()","48c5f1f9":"age_surv_corr= train_data['Age'].corr(train_data['Survived'])\nage_surv_corr","920091cf":"class_surv_corr= train_data['Pclass'].corr(train_data['Survived'])\nclass_surv_corr","ebfb8377":"train_data['Sex'].value_counts()","0e942a50":"train_data[['Sex','Survived']].groupby(['Sex'],as_index = False).mean()","0570324a":"x_axis = ['Female','Male']\ny_axis = [0.74,0.19]\n\nplt.bar(x=x_axis, height=y_axis)\nplt.xlabel('Sex')\nplt.ylabel('Survived')\nplt.show()","a038b559":"train_data['Survived'].value_counts()","9e0dd751":"survived = 'survived'\nnot_survived = 'not survived'\n#Percentage of people that survived\nsurvived_per = train_data[train_data['Survived']==1]\nsurvived=float(round((len(survived)\/len(train_data))*100.0))\nprint(\"Survived:\",str(survived),'%')","a3691df0":"#Percentage of people that died\ndied= train_data[train_data['Survived']==0]\ndied =float(round((len(died)\/len(train_data))*100.0))\nprint(\"Died:\",str(died),'%')","020d125a":"train_data['Pclass'].value_counts().sort_index()","8169d7a3":"train_data[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean()","f930807e":"sns.barplot(x='Pclass', y='Survived', data=train_data)\n","72f8a2c2":"all_classes=pd.crosstab(train_data['Pclass'],train_data['Sex'])\nprint(all_classes)","754a7500":"all_classes =pd.crosstab(train_data['Pclass'],train_data['Survived'])\nprint(all_classes)","d877732b":"all_classes.div(all_classes.sum(1).astype(float),axis=0).plot(kind='barh',stacked=False)\nplt.ylabel('Pclass')\nplt.xlabel('Percentage')\nplt.title('The perentage of those who survived and died in the different coach classes')","04e1eca2":"freq_table = train_data['Age'].value_counts(bins=8).sort_index()\nfreq_table","e4ec3d67":"freq = pd.DataFrame(freq_table)\nfreq","313c439b":"train_data.Embarked.value_counts()","243c795d":"train_data[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean()","94304d28":"x_axis = ['C','Q','S']\ny_axis = [0.55,0.39,0.34]\n\nplt.bar(x=x_axis, height=y_axis)\nplt.xlabel('Embarked')\nplt.ylabel('Survived')\nplt.title('The ratio of people who Embarked and Survived')\nplt.show()","5d2818b7":"train_data.Parch.value_counts()","404358a7":"train_data[['Parch','Survived']].groupby(['Parch'],as_index=False).mean()","92fc2dc9":"x_axis = [0,1,2,3,4,5,6]\ny_axis = [0.34,0.55,0.50,0.60,0.0,0.2,0.0]\n\nplt.bar(x=x_axis, height=y_axis)\nplt.xlabel('Parch')\nplt.ylabel('Survived')\nplt.title('The ratio of Parch and Survived')\nplt.show()","00464f72":"train_data[['SibSp','Survived']].groupby(['SibSp'], as_index = False).mean()","58a270ea":"x_axis = [0,1,2,3,4,5,8]\ny_axis = [0.35,0.54,0.46,0.25,0.17,0.0,0.0]\nplt.bar(x=x_axis, height=y_axis)\nplt.xlabel('SibSp')\nplt.ylabel('Survived')\nplt.title('The ratio of SibSp and Survived')\nplt.show()","a9229ad7":"df_Age_train = train_data.loc[pd.notna(train_data.Age)]\ndf_Age_train.Age = df_Age_train.Age.astype(\"float64\")\ndf_Age_train.Age = (df_Age_train.Age - df_Age_train.Age.mean()) \/ df_Age_train.Age.std()\ndf_Age_train","d0a31312":"train_data.drop(\"Age\", axis=1, inplace=True)\ntestData_data.drop(\"Age\", axis=1, inplace=True)\ntrain_data.head()","06fee1ea":"bins_i = [-1, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\nlabels_i = [1,2,3,4,5,6,7,8,9,10,11]\n\ntrain_data['stage'] = 0\ntrain_data['stage'] = pd.cut(train_data.Fare, bins=bins_i, labels=labels_i)\n\ntestData_data['stage'] = 0\ntestData_data['stage'] = pd.cut(testData_data.Fare, bins=bins_i, labels=labels_i)\n\ntrain_data.stage.unique()","4aac1336":"train_data.Fare = train_data.stage.astype(\"int64\")\ntestData_data.Fare = testData_data.stage.astype(\"int64\")\ntrain_data.drop(\"stage\", axis=1, inplace=True)\ntestData_data.drop(\"stage\", axis=1, inplace=True)","d037508a":"train_data.head()","f732eb60":"data = [train_data, testData_data]\nfor dataset in data:\n    dataset['FamilySize'] = dataset['SibSp'] +  dataset['Parch'] + 1","a5ad9429":"for dataset in data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\nprint (train_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())","776f2b18":"columns = [\"Pclass\",\"Sex\", \"Fare\", \"Embarked\",\"IsAlone\"]\nX_train = train_data[columns]\nY_train = train_data[\"Survived\"]\nlen(Y_train)\n","50621788":"X_test = testData_data[columns]\nlen(X_test)","18d0ccb9":"Y_test =testData_data[columns]\nlen(Y_test)","0b80a80e":"random_forest = RandomForestClassifier(n_estimators=40, min_samples_leaf=2, max_features=0.1, n_jobs=-1)\nrandom_forest.fit(X_train, Y_train)\nY_pred_Random = random_forest.predict(X_test)\nprint(\"the train score of random_forest = \",round(random_forest.score(X_train, Y_train) *100, 2),\"%\")","51b61fa5":"logistic_regression = LogisticRegression(solver='liblinear',max_iter=1000)\nlogistic_regression.fit(X_train, Y_train)\nY_pred_Logistic = logistic_regression.predict(X_test)\nprint(\"the train score of logistic_regression = \",round(logistic_regression.score(X_train, Y_train) *100, 2),\"%\")","76737de8":"tree = DecisionTreeClassifier(random_state=25)\ntree.fit(X_train, Y_train)\nY_pred_Tree= tree.predict(X_test)\nprint(\"the score of prediction = \",round(tree.score(X_train, Y_train) * 100,2), \"%\")","67c921e8":"scores= cross_val_score(tree, X_train, Y_train, scoring=\"accuracy\", cv=100)\nscores.mean()","fb969297":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, Y_train)\nY_pred_KNN= knn.predict(X_test)\nprint(\"the score of prediction = \",round(knn.score(X_train, Y_train) * 100,2), \"%\")","0c86cb14":"submission = pd.DataFrame({\n        \"PassengerId\": testData_data[\"PassengerId\"],\n        \"Survived\": Y_pred_Logistic\n    })\nsubmission.to_csv('.\/submission.csv', index=False)","56c84ac4":"# EDA","d0a0bc8b":"549 people died and 342 people survived","f1efb4e4":"Data Cleaning","bb1f89af":"# Predictions","52775a4f":"# Random Forest","fdfb7aea":"# Logistic Regression","a743ba69":"the ages between 20 to 30 had the most passengers","a798b1cc":"there where 3 classes of tickets and 491 wich is class 3 had the highest passengers"}}