{"cell_type":{"9c5f905b":"code","e60a16cb":"code","872bc804":"code","5c25d75d":"code","2376c5c6":"code","f4b84057":"code","3419f0b8":"code","f2da5a7a":"code","a477c260":"code","f79f95be":"code","56fad10f":"code","fd064440":"code","505e40f4":"code","57365e2f":"code","d30acc69":"code","22f3dae7":"code","28e8ac41":"code","cb04d440":"code","ad589d32":"code","fb63da45":"code","e551c394":"code","4ee2a215":"code","51a6c1bf":"code","27b6172d":"code","375fb840":"code","4c32a026":"code","397ff00f":"code","e4f4310e":"code","953bf432":"code","89639920":"code","95f1f8b2":"code","db315033":"code","880e9976":"code","2cef4625":"code","b03c3f26":"code","77934ec7":"code","38cf71cf":"code","daee86ae":"code","ba4d50d3":"code","dc779968":"code","788b05d9":"code","3f4f6ef4":"code","e2cf678e":"code","8aa9de5c":"code","4d6e9d7c":"code","f0f5f8ba":"code","64dab080":"code","647cd0f4":"code","1c883bb8":"code","e11d26a0":"code","2fdd5793":"code","2c28b9af":"code","1788f704":"code","477dc923":"code","a2d66d64":"code","4e3fa0b5":"code","a34fd18b":"code","e7fab7fa":"code","07f84577":"code","31254f2b":"code","51b17182":"markdown","6124e94a":"markdown","2034b0a2":"markdown","c89f2bfe":"markdown","4b1ec329":"markdown","e6ce01aa":"markdown","45f8b496":"markdown","d354dc8a":"markdown","06c6841c":"markdown","b84ab3d6":"markdown","ceb4223f":"markdown","883c46f5":"markdown","60658275":"markdown","311f14f9":"markdown","dfc82805":"markdown","fe89cd9f":"markdown","413f5342":"markdown","4d094723":"markdown","49bfc919":"markdown","5fcfd8ae":"markdown","8797da12":"markdown"},"source":{"9c5f905b":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('darkgrid')","e60a16cb":"# do not show warning msgs\nimport warnings\nwarnings.filterwarnings(\"ignore\")","872bc804":"# showing all columns\npd.set_option('display.max_columns', None)","5c25d75d":"# loading the train and test Titanic data sets\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","2376c5c6":"train_data.head()","f4b84057":"train_data.shape","3419f0b8":"train_data.info()","f2da5a7a":"# checking for missing values\nfig = plt.figure(figsize=(15,15))\nax1 = fig.add_subplot(2,1,1)\nsns.heatmap(train_data.isnull(),yticklabels=False,cbar=False,cmap='viridis', ax = ax1)\nax1.tick_params(axis='x', labelsize=13, rotation = 45)\nax1.set_title('train data')\nax2 = fig.add_subplot(2,1,2)\nsns.heatmap(test_data.isnull(),yticklabels=False,cbar=False,cmap='viridis', ax = ax2)\nax2.tick_params(axis='x', labelsize=13, rotation = 45)\nax2.set_title('test data');","a477c260":"test_data[test_data.Fare.isnull()]","f79f95be":"test_data.Fare.fillna(test_data.groupby('Pclass').mean()['Fare'].loc[3], inplace = True)","56fad10f":"print(f'There are {train_data.Age.isnull().sum()} missing values in the \"Age\" column,\\n{train_data.Age.isnull().sum()} in \"Cabin\",\\nand {train_data.Embarked.isnull().sum()} in \"Embarked\"')","fd064440":"train_data.describe()","505e40f4":"train_data.groupby(['Survived']).describe()","57365e2f":"fig, axes = plt.subplots(1,2,figsize=(18,8))\nax1 = sns.countplot(x = 'Survived', data = train_data, ax = axes[0], palette=['tomato','steelblue'])\nax1.set_xticklabels(['No', 'Yes'])\nax1.set_title('Count of survivors\/non-survivors')\nax2 = (train_data.groupby(['Survived']).count() \/ len(train_data['Survived']))['PassengerId'].plot(kind='bar', width = 0.85, ax = axes[1], color = ['tomato', 'steelblue'])\nax2.set_title('Percentage of survivors\/non-survivors')\nax2.set_xticklabels(['No', 'Yes'], rotation = 'horizontal')\nax2.set_ylabel('Percentage %')\nax2.set_yticklabels(['{:.0%}'.format(x) for x in ax2.get_yticks()]);","d30acc69":"sur = len(train_data[train_data['Survived']==1])\/len(train_data['Survived'])*100\nnot_sur = len(train_data[train_data['Survived']==0])\/len(train_data['Survived'])*100\nprint(f'survived: {sur:.2f}%\\nnot-survived: {not_sur:.2f}%')","22f3dae7":"sex_v_survived = train_data.groupby('Sex')['Survived'].mean()\nsex_v_survived","28e8ac41":"fig = plt.figure(figsize=(10,8))\nsns.barplot(x = 'Sex', y = 'Survived', data = train_data, ci = False)\nplt.text(0.01, 0.2, f'{sex_v_survived.male*100:.2f}%')\nplt.text(0.94, 0.75, f'{sex_v_survived.female*100:.2f}%')\nplt.title('Sex v Survived');","cb04d440":"fig = plt.figure(figsize=(12,8))\ntrain_data[train_data.Survived==0]['Age'].hist(bins=35, alpha = 0.5, color='red', label = 'No')\ntrain_data[train_data.Survived==1]['Age'].hist(bins=35, alpha = 0.5, color='blue', label = 'Yes')\nplt.tick_params(axis='both', labelsize=13)\nplt.xlabel('Age (years)', fontsize = 14)\nplt.ylabel('Count', fontsize = 14)\nplt.title(\"Age distribution of RMS Titanic passengers\", fontsize = 16)\nplt.legend(title='Survived', fontsize=11, title_fontsize=12);","ad589d32":"fig = plt.figure(figsize=(12,5))\ntrain_data[train_data.Survived==0]['Fare'].hist(bins=35, alpha = 0.5, color='red', label = 'No')\ntrain_data[train_data.Survived==1]['Fare'].hist(bins=35, alpha = 0.5, color='blue', label = 'Yes')\nplt.tick_params(axis='both', labelsize=13)\nplt.xlabel('Age (years)', fontsize = 14)\nplt.ylabel('Count', fontsize = 14)\nplt.title(\"Fare distribution of RMS Titanic passengers\", fontsize = 16)\nplt.legend(title='Survived', fontsize=11, title_fontsize=12);","fb63da45":"fig = plt.figure(figsize=(12,5))\nsns.boxplot(x = 'Survived', y = 'Fare', data = train_data);","e551c394":"# we can notice some extreme values in the fare\n# lets try to remove those 3 standard deviations away from the mean, so we can read the graphs","4ee2a215":"mask = train_data['Fare'].apply(lambda x: False if np.abs(x - train_data['Fare'].mean()) > 3*train_data['Fare'].std() else True)\nfig = plt.figure(figsize=(12,5))\nsns.boxplot(x = 'Survived', y = 'Fare', data = train_data[mask]);","51a6c1bf":"no_fare_outliners = train_data[mask]","27b6172d":"fig = plt.figure(figsize=(12,5))\nno_fare_outliners[no_fare_outliners.Survived==0]['Fare'].hist(bins=35, alpha = 0.5, color='red', label = 'No')\nno_fare_outliners[no_fare_outliners.Survived==1]['Fare'].hist(bins=35, alpha = 0.5, color='blue', label = 'Yes')\nplt.tick_params(axis='both', labelsize=13)\nplt.xlabel('Age (years)', fontsize = 14)\nplt.ylabel('Count', fontsize = 14)\nplt.title(\"Fare distribution of RMS Titanic passengers\", fontsize = 16)\nplt.legend(title='Survived', fontsize=11, title_fontsize=12);","375fb840":"fig, axes = plt.subplots(1,2,figsize=(13,5))\nax1 = sns.barplot(x = 'Pclass', y = 'Survived', data = train_data, ax = axes[0],  ci = False)\nax1.set_title(\"Percentage of survivors per class\")\nax1.set_yticklabels(['{:.0%}'.format(x) for x in ax1.get_yticks()]);\nax2 = sns.countplot(x = 'Pclass', data = train_data, hue = 'Survived', ax = axes[1], palette = 'Paired_r')\nax2.legend(title='Survived', labels=['No','Yes'], fontsize=11, title_fontsize=12)\nax2.set_title('Counts of survivors and non-survivors per class');","4c32a026":"train_data","397ff00f":"fig, axes = plt.subplots(1,2,figsize=(13,5))\nsns.countplot(x = 'SibSp', hue = 'Survived',data = train_data,palette = 'Paired_r', ax=axes[0])\nsns.countplot(x = 'Parch', hue = 'Survived',data = train_data, palette = 'Paired_r', ax=axes[1]);","e4f4310e":"train_data.head()","953bf432":"# dummies for sex\ntrain_data = pd.get_dummies(train_data, columns = ['Sex'], drop_first = True)\ntest_data = pd.get_dummies(test_data, columns = ['Sex'], drop_first = True)","89639920":"# create a new binary variable, has Cabin\ntrain_data.Cabin.fillna(0, inplace=True)\ntest_data.Cabin.fillna(0, inplace=True)\ntrain_data['Has_cabin'] = train_data.Cabin.apply(lambda x : 0 if x == 0 else 1)\ntest_data['Has_cabin'] = train_data.Cabin.apply(lambda x : 0 if x == 0 else 1)","95f1f8b2":"# In order to fill the NA values of Age variable, we will use the name titles (Mr., Mrs., Miss etc) from the Name variable\n# notice that in every entry before the '.' there is the title of the name. \ntrain_data.Name.head()","db315033":"# So we can use the '.' as separator and choose the first element of the list.\ntrain_data.Name.head().apply(lambda x: x.split('.'))[0]","880e9976":"# now we can perform one more split and we will get the name title\ntrain_data.Name.head().apply(lambda x: x.split('.')[0].split()[1])","2cef4625":"# saving the titles to a new column\ntrain_data['Title'] = train_data.Name.apply(lambda x: x.split('.')[0].split(',')[1]) \ntrain_data['Title'] = train_data['Title'].apply(lambda x: x.strip())\ntest_data['Title'] = test_data.Name.apply(lambda x: x.split('.')[0].split(',')[1]) \ntest_data['Title'] = test_data.Title.apply(lambda x: x.strip())","b03c3f26":"train_data['Title'].value_counts()","77934ec7":"# we will assign the mean age of every title\nmean_age_by_title = train_data.groupby('Title').mean()['Age']\ntitle_age_dict = {'Mr': mean_age_by_title['Mr'], \n                  'Mrs': mean_age_by_title['Mrs'],\n                  'Ms': mean_age_by_title['Ms'],\n                 'Miss': mean_age_by_title['Miss'],\n                 'Master':mean_age_by_title['Master'],\n                 'Dr': mean_age_by_title['Dr']}","38cf71cf":"train_data.Age.fillna(train_data.Title.map(title_age_dict), inplace = True)\ntest_data.Age.fillna(test_data.Title.map(title_age_dict), inplace = True)","daee86ae":"print(train_data.Age.isnull().sum())\nprint(test_data.Age.isnull().sum())","ba4d50d3":"def titles(x):\n    if x in ['Ms','Mlle']:\n        return 'Miss'\n    if x in ['Mme','Lady','the Countess','Dona']:\n        return 'Mrs'\n    if x in ['Rev', 'Major', 'Col','Sir','Don','Jonkheer','Don']:\n        return 'high_rank_male'\n    if x == 'Capt':\n        return 'Mr'\n    else:\n        return x","dc779968":"train_data['Title'] = train_data.Title.apply(titles)\ntest_data['Title'] = test_data.Title.apply(titles)","788b05d9":"train_data = pd.get_dummies(train_data, columns = ['Title'], drop_first = True)\ntest_data = pd.get_dummies(test_data, columns = ['Title'], drop_first = True)","3f4f6ef4":"train_data = pd.get_dummies(train_data, columns = ['Embarked'], drop_first = True)\ntest_data = pd.get_dummies(test_data, columns = ['Embarked'], drop_first = True)","e2cf678e":"train_data.drop(columns = ['Name','Cabin','Ticket'], axis=1, inplace = True)\ntest_data.drop(columns = ['Name','Cabin','Ticket'], axis=1, inplace = True)","8aa9de5c":"X = train_data.drop(['Survived','PassengerId'], axis=1)\ny = train_data['Survived']","4d6e9d7c":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV","f0f5f8ba":"gb = GradientBoostingClassifier()\nparam_gb = {\n    'n_estimators': [100, 150, 200], \n    'max_depth': [5, 7, 11, 15],\n    'learning_rate': [0.01, 0.1, 1]\n}","64dab080":"gb_clf = GridSearchCV(gb, param_gb, cv=5)","647cd0f4":"cv_gb_fit = gb_clf.fit(X, y)\npd.DataFrame(cv_gb_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]","1c883bb8":"from sklearn.ensemble import RandomForestClassifier","e11d26a0":"forest =  RandomForestClassifier()\nparam_forest = {\n    'n_estimators': [100, 200, 500, 1000], \n    'max_depth': [5, 10, 90, None]\n}","2fdd5793":"rf_clf = GridSearchCV(forest, param_forest, cv=5, n_jobs=-1)","2c28b9af":"cv_rf_fit = rf_clf.fit(X, y)\npd.DataFrame(cv_rf_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]","1788f704":"from sklearn.linear_model import LogisticRegression","477dc923":"log_model = LogisticRegression()\nparam_log = {\n    'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n'C' : [100, 10, 1.0, 0.1, 0.01]\n}","a2d66d64":"log_clf = GridSearchCV(log_model, param_log, cv=5)","4e3fa0b5":"cv_log_fit = log_clf.fit(X, y)\npd.DataFrame(cv_log_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]","a34fd18b":"# fitting again the model with all the train data\nlog_final = LogisticRegression(C = 10, penalty = 'l2', solver = 'newton-cg')\nlog_final.fit(X, y)","e7fab7fa":"test_pred = log_final.predict(test_data.drop(['PassengerId'], axis = 1))","07f84577":"test_pred","31254f2b":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': test_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","51b17182":"From the graph above we can notice that the Sex was an important factor. About 2 out of 10 men survived while, 7 out of 10 women survived. ","6124e94a":"## Predictions","2034b0a2":"### Sex - Survived","c89f2bfe":"From the age distribution we notice that the most common age of passengers was from 20 to 30, while the majority of people who did not survive were within this age class.","4b1ec329":"### Gradient Boosting","e6ce01aa":"### Fare - Survived","45f8b496":"From the boxplots above we notice that, most of the survivors had paid higher fair, compared to non-survivors.","d354dc8a":"### Class - Survived","06c6841c":"The title column is categorical, \n\nThat means we have to transport it using dummy variables in order sklearn to undertsand it. However there are some titles which could be groupby together.","b84ab3d6":"## Training the model","ceb4223f":"### Age - Survived","883c46f5":"## Exploratory data analysis","60658275":"## Feautures Relationships","311f14f9":"### Siblings \/ Parch vs Survived","dfc82805":"## Logistic Regression","fe89cd9f":"From the graphs above we can easily notice that more people did not survived the accident. According to the precentages about 1 out of the 3 passengers survived the incident. ","413f5342":"## Data Engineering\n","4d094723":"## Random Forest","49bfc919":"We have a missing value in the \"Fare\" column in the test_data, we will fill it with the avarage fare paid by the particular 'Pclass'","5fcfd8ae":"It appears that the most of the non survivors had a fair of around 10 dollars. ","8797da12":"We have a missing value in the \"Fare\" column in the test_data, we will fill it with the avarage fare paid by the particular 'Pclass'"}}