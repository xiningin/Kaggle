{"cell_type":{"57e4e791":"code","bdf2f7a8":"code","5626cba8":"code","eb1ec8e7":"code","992a90f3":"code","c1cc55d6":"code","fdf85da5":"code","51b32b14":"code","e20c0ac5":"code","f1cc2db3":"code","ac593291":"code","c52cc92d":"code","f3557363":"code","5803d611":"code","171b32f8":"code","2bd45c05":"code","f49cb739":"code","3fb78e1a":"code","112f6a61":"code","bcce5665":"code","1dd55e49":"code","06cf5a5d":"code","64011d74":"code","8a6e52a6":"code","547032c4":"code","06568603":"code","54927978":"code","cc35d5d9":"code","c6c1e666":"code","278fd2c4":"code","5c5bccb7":"code","1e6af110":"markdown","92835790":"markdown","bd4a463b":"markdown","18fef6a8":"markdown","37c2e8d3":"markdown","0cd82d6f":"markdown","0a61edac":"markdown","c477f9ae":"markdown","ef5a3a56":"markdown","666f8627":"markdown","99d4f1d1":"markdown","7aa8b70b":"markdown"},"source":{"57e4e791":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import accuracy_score # accuracy score\nfrom sklearn.metrics import recall_score   # recall score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bdf2f7a8":"#loading the train data\ntrain = pd.read_csv(\"\/kaggle\/input\/novartis-data\/Train.csv\")\n#Shape of train\nprint(train.shape) #printing the shape of train\nprint(train.describe()) #printing the statistics of train\nprint(train.info()) #printing the information of train\nprint(train.head()) #printing the first five rows of the train data","5626cba8":"#loading the test data\ntest = pd.read_csv(\"\/kaggle\/input\/novartis-data\/Test.csv\")\n#Shape of train\nprint(test.shape) #printing the shape of train\nprint(test.describe())#printing the statistics of train\nprint(test.info()) #printing the information of train\nprint(test.head()) #printing the first five rows of the test data","eb1ec8e7":"#Dropping the Incident_ID and Date from train data\ntrain = train.drop(['INCIDENT_ID','DATE'], axis=1)\ntrain.info()","992a90f3":"#Verifying all the columns that has the null values in train data\nnull_columns=train.columns[train.isnull().any()]\ntrain[null_columns].isnull().sum()","c1cc55d6":"#Filled NaN values with \"0\" using fillna()\ntrain[\"X_12\"].fillna(0,inplace = True)\ntrain.isnull().sum()","fdf85da5":"#Verifying all the columns that has the null values in test data\nnull_columns=test.columns[test.isnull().any()]\ntest[null_columns].isnull().sum()","51b32b14":"#Filled NaN values with \"0\" using fillna()\ntest[\"X_12\"].fillna(0,inplace = True)\n#train[\"X_12\"].ffill(axis = \"rows\")\ntest.isnull().sum()","e20c0ac5":"train[\"X_12\"] = train[\"X_12\"].astype(np.int64)\ntrain.info()","f1cc2db3":"test[\"X_12\"] = test[\"X_12\"].astype(np.int64)\ntest.info()","ac593291":"#Removing the duplicated rows from train data\nprint(\"Train shape before removing the duplicates :\" , train.shape)\ntrain.drop_duplicates(keep='first', inplace=True)\nprint(\"Train shape After removing the duplicates :\" , train.shape)","c52cc92d":"#Skewness of the train data\ntrain.skew()","f3557363":"import matplotlib.pyplot as plt\nimport seaborn as sns\n#Skewness of train data\nsns.distplot(train.skew(),color='blue',axlabel ='Skewness')","5803d611":"f,ax = plt.subplots(1,1,figsize=(16,6))\nsns.violinplot(train['MULTIPLE_OFFENSE'])\nplt.show()\n#skewness and kurtosis\nprint(\"Skewness: {}\".format(train['MULTIPLE_OFFENSE'].skew()))\nprint(\"Kurtosis: {}\".format(train['MULTIPLE_OFFENSE'].kurt()))","171b32f8":"print(\"Number of training Mutiple Offence : {} \".format(len(train)))\nprint(\"Offense Rate {:.4}%\".format(train[\"MULTIPLE_OFFENSE\"].mean()*100))","2bd45c05":"#Creating Pie Chart for the target variable\nlabels = ['Hacked', 'Genuine']\nplt.title('Multiple Offense')\ntrain['MULTIPLE_OFFENSE'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.1f%%',shadow=True,labels=labels,fontsize=10)","f49cb739":"#histogram\ntrain.hist(figsize=(14,14))\nplt.show()","3fb78e1a":"#Boxplot \nplt.subplots(figsize=(15, 6))\nsns.boxplot(data = train, orient = 'v')","112f6a61":"# create a correlation heatmap\nsns.heatmap(train.corr(),annot=True, cmap='gist_ncar', linewidths=0.1)\nfig=plt.gcf()\nfig.set_size_inches(14,14)\nplt.show()","bcce5665":"#High Correlation of X_2 and X_3 using joint plot\nsns.jointplot(train['X_2'],train['X_3'], kind=\"reg\", color=\"b\")","1dd55e49":"X_train = train.iloc[:,:-1]\ny_train = train[\"MULTIPLE_OFFENSE\"]\n#Dropping the Incident_ID and Date from test data\nX_test = test.drop(['INCIDENT_ID','DATE'], axis=1)\nprint(\"Shape of X_train : \",X_train.shape)\nprint(\"Shape of y_train : \",y_train.shape)\nprint(\"Shape of X_test : \",X_test.shape)","06cf5a5d":"#Synthetic minority oversampling technique to balance the imbalanced data.\nprint('Before OverSampling, the shape of X_train: {}'.format(X_train.shape))\nprint('Before OverSampling, the shape of y_train: {} \\n'.format(y_train.shape))\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\nfrom imblearn.over_sampling import SMOTE\nsampler = SMOTE(sampling_strategy='minority')\nX_train_sm, y_train_sm = sampler.fit_sample(X_train, y_train)\nprint('After OverSampling, the shape of X_train: {}'.format(X_train_sm.shape))\nprint('After OverSampling, the shape of y_train: {} \\n'.format(y_train_sm.shape))\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_sm==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_sm==0)))","64011d74":"#Spltting the data into train and validation\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train_sm, y_train_sm ,test_size=0.3, random_state=10)","8a6e52a6":"#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_val_sc   = sc.transform(X_val)\nX_test_sc  = sc.transform(X_test)","547032c4":"# Support Vector Classification\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nsvc = SVC()\nsvc.fit(X_train_sc, y_train)\ny_pred = svc.predict(X_val_sc)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nrecall_svc = recall_score(y_pred, y_val)\nprint(\"Support Vector Classifier Accuracy Score:\",acc_svc)\nprint('Support Vector Classifier Recall Score:',recall_svc)","06568603":"#Gradient Boosting Classifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\ngbk = GradientBoostingClassifier()\ngbk.fit(X_train_sc, y_train)\ny_pred = gbk.predict(X_val_sc)\nacc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\nrecall_gbk = recall_score(y_pred, y_val)\nprint(\"Gradient Boosting Classifier Accuracy Score:\",acc_gbk)\nprint('Gradient Boosting Classifier Recall Score:',recall_gbk)","54927978":"#Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nrandomforest = RandomForestClassifier()\nrandomforest.fit(X_train_sc, y_train)\ny_pred = randomforest.predict(X_val_sc)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nrecall_randomforest = recall_score(y_pred, y_val)\nprint(\"Random Forest Classifier Accuracy Score:\",acc_randomforest)\nprint('Random Forest Classifier Recall Score:',recall_randomforest)","cc35d5d9":"#Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\ndecisiontree = DecisionTreeClassifier()\ndecisiontree.fit(X_train_sc, y_train)\ny_pred = decisiontree.predict(X_val_sc)\nacc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\nrecall_decisiontree = recall_score(y_pred, y_val)\nprint(\"Decision Tree Accuracy Score:\",acc_decisiontree)\nprint('Decision Tree Recall Score:',recall_decisiontree)","c6c1e666":"# KNN or k-Nearest Neighbors Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train_sc, y_train)\ny_pred = knn.predict(X_val_sc)\nacc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\nrecall_knn = recall_score(y_pred, y_val)\nprint(\"KNN Classifier Accuracy Score:\",acc_knn)\nprint('KNN Classifier Recall Score:',recall_knn)","278fd2c4":"models = pd.DataFrame({\n    'Model': ['Support Vector Machine', \n              'Random Forest', \n              'Decision Tree',\n              'Gradient Boosting Classifier',\n               'k-Nearest Neighbors Classifier'],\n    'Accuracy Score': [acc_svc,acc_gbk, acc_randomforest,acc_decisiontree,acc_knn],\n    'Recall Score'  :  [recall_svc,recall_gbk,recall_randomforest,recall_decisiontree,recall_knn]})\nmodels.sort_values(by='Accuracy Score', ascending=False)","5c5bccb7":"#I have chosen Gradient Boosting classifier amongst all classifiers\ny_pred = gbk.predict(X_test_sc)\nsubmission_df = pd.DataFrame({'INCIDENT_ID':test['INCIDENT_ID'], 'MULTIPLE_OFFENSE':y_pred})\nsubmission_df.to_csv('Sample Submission GBK v1.csv', index=False)","1e6af110":"We can view in the train and test info that X_12 is float64 let's convert it into int64","92835790":"# DATA MODELLING FOR PREDICTION :","bd4a463b":"In the above code we can cleary view that the target variable is well balanced.","18fef6a8":"# SMOTE:\n","37c2e8d3":"#Submission","0cd82d6f":"Let us visualize the Multiple Offense using pie chart","0a61edac":"# DATA MODELLING FOR PREDICTION :","c477f9ae":"# Novartis Data science challenge :\n\nTo predict whether the server is hacked or not.","ef5a3a56":"In the above correlation plot we can clearly say that X_2 and X_3 are highly correlated,this is to check correlation of X_1 to X_15 correlations along with Multiple Offense.","666f8627":"# Exploratory Data Analysis ON TRAIN DATA :","99d4f1d1":"Target Variable Distribution:\n\nOur first step in Machine Learning should always be analyzing the target variable. MULTIPLE_OFFENSE is our given target\/dependent variable. Let's analyse its distribution","7aa8b70b":"In the above code we can view that X_12 column has 182 null values,we will replace those null values with zero."}}