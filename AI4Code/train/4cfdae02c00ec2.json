{"cell_type":{"7866ca2f":"code","a68d1d6e":"code","29140128":"code","1169acdd":"code","440b2942":"code","0e9e0eaa":"code","80e0028d":"code","606fc21f":"code","c3910985":"code","02551acf":"code","a00d7c0a":"code","f27e4b89":"code","bf3a01ea":"code","44a8e2ee":"code","30da2934":"code","f6df66f7":"code","9b6a3cc4":"markdown","7d693156":"markdown","5748c10f":"markdown","97930de4":"markdown","d2db323a":"markdown","96030aae":"markdown","fefdd3a3":"markdown","017f9a8e":"markdown","ed616bb7":"markdown"},"source":{"7866ca2f":"# Imports\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\n# Load in the data\ndataset = pd.read_csv(\"\/kaggle\/input\/processed_movie_data.csv\")\nprint(\"Dataset rows: %s, \\nDataset columns: %s\" %(dataset.shape))","a68d1d6e":"# Example of undescriptive feature","29140128":"# Example of descriptive feature","1169acdd":"# Create a list of the most informative features' column names\ninformative_features = ['Director_Ratio', 'Keywords_Ratio', 'Studios_Ratio', 'Lead_Actor_Ratio', 'Budget']\n\n# Isolate the target feature's values\n\n\n# Create a new dataset, with only the most informative descriptive features\n","440b2942":"# Store target feature values in a numpy array (Originally in a 2d list)\n\n\n# Create a scaler\n\n\n# Fit the data to the scaler\n\n\n# Normalize our descriptive features to range [0,1]\n\n\n# Classifier\nclf = MLPClassifier(solver='adam', alpha=1e-5, random_state=1, max_iter=1000)","0e9e0eaa":"# Create a new 5-fold cross validator object\n\n# Give it the data to split up\n","80e0028d":"# Objects which will store performances among the 5 folds\n# These will be used to compute average performance overall\n\n# prediction_accuracies.\nconfusion_matrices = []\nclassification_accuracies = []\n\n# predictions.\nmodel_predictions = [] \ntarget_predictions = []","606fc21f":"for train_index, test_index in kf.split(X):\n    \n    # X = Descriptive features for each partition\n\n    \n    # Y = Target feature values for each partition\n\n\n    # Train the model using training sets\n\n    \n    # Get the predictions of the model\n\n    \n    # Get accuracy score of the model\n    # (comparing model's predictions of profitability to expected values in the data)\n    classification_accuracies.append(\n\n    )\n\n    # Get confusion matrix of the model\n    confusion_matrices.append(\n\n    )","c3910985":"print(classification_accuracies)","02551acf":"# Aggregate the 5 confusion matrices into a single one.\ntotals = np.array([[0, 0],[0, 0]])\nfor matrix in confusion_matrices:\n    for i in range(0, 2):\n        for j in range(0, 2):\n            totals[i][j] += matrix[i][j]\ntn, fp, fn, tp = totals.ravel()\n\n# Print confusion matrix\nprint(\"Confusion Matrix: \")\nfor s1, s2 in [['tp: '+ str(tp), 'fp: '+ str(fp)],\n               ['fn: '+ str(fn), 'tn: '+ str(tn)]]:\n    print(\"[%-8s | %-8s]\" %(s1, s2))","a00d7c0a":"# Classification accuracies\navg_classification_accuracy = sum(classification_accuracies)\/len(classification_accuracies)\nprint(\"Accuracy: %.9f %%\" %(avg_classification_accuracy*100))","f27e4b89":"# Calculate true positive rate\n\n\n# Calculate true negative rate\n\n\n# Calculate false positive rate\n\n\n# Calculate false negative rate\n\n\n# Print the outcomes\nfor key, value in [['True Positive Rate',tpr], \n                   ['True Negative Rate',tnr], \n                   ['False Positive Rate',fpr], \n                   ['False Negative Rate',fnr]]:\n    print(\"%s: %.4f\" %(key, value)) ","bf3a01ea":"# Calculate precision\n\n\n# Calculate recall\n\n\nfor key, value in [['Precision', precision],\n                   ['Recall', recall]]:\n    print(\"%s: %.4f\" %(key, value)) ","44a8e2ee":"# Select Avatar dataset\navatar = dataset.loc[dataset['Movie_Title']=='Avatar'][informative_features]\n# Predict whether it is successful or not\nout = clf.predict(scaler.transform(avatar.values))\n# Output\nprint(\"profitable\" if out[0] == 1 else \"unprofitable\")","30da2934":"# Select Avatar dataset\niron_man_3 = dataset.loc[dataset['Movie_Title']=='Iron Man 3'][informative_features]\n# Predict whether it is successful or not\nout = clf.predict(scaler.transform(iron_man_3.values))\n# Output\nprint(\"profitable\" if out[0] == 1 else \"unprofitable\")","f6df66f7":"# Predict whether it is successful or not\nhome_for_the_holidays = dataset.loc[dataset['Movie_Title']=='Home for the Holidays'][informative_features]\nout = clf.predict(scaler.transform(home_for_the_holidays.values))\n# Output\nprint(\"profitable\" if out[0] == 1 else \"unprofitable\")","9b6a3cc4":"### Movie Profitability Classification\n\nWe want to predict whether a movie is profitable or not.\n\nMy definition of profitable is as follows:\n* A movie is profitable if it's revenue is larger than 2x it's budget.\n\nI have already pre-processed a dataset, so we can get right to training our model!\n\nLet's look at data briefly...\n* Class 0 = Unprofitable\n* Class 1 = Profitable","7d693156":"Now, we set up our 5-fold cross validation for training and testing.\n* [5-fold cross validation example](https:\/\/miro.medium.com\/max\/2736\/1*rgba1BIOUys7wQcXcL4U5A.png)","5748c10f":"### Calculate some of the advanced metrics:\n* **Precision**\n    * % of positive predictions which are actually correct\n* **Recall**\n    * % of positive predictions which are found","97930de4":"Now, for each partition in the k-fold validation:\n* Split the descriptive features (X) and target feature (Y) into a test set and training set\n* Get the classification accuracy\n* Get the confusion matrix\n    ","d2db323a":"### Setup\nImports reference:\n* [os](https:\/\/docs.python.org\/3\/library\/os.html)\n    * Gives us access to file system to load in our data\n* [numpy](http:\/\/)\n    * Numerical python - Scientific computing with Python\n* [pandas](https:\/\/pandas.pydata.org\/)\n    * Dataframes - An open source data analysis and manipulation tool\n* [seaborn](https:\/\/seaborn.pydata.org\/)\n    * Open source statistical data visualization tool\n* [SKLearn](https:\/\/scikit-learn.org\/stable\/)\n    * Scikit-learn - An open source tool for machine learning and predictive data analysis","96030aae":"### Visualizing the data\n\nLet's look at an example of how we can identify whether a descriptive feature is informative about the target class.","fefdd3a3":"### Evaluating the model\n\nNow we will evaluate the models performance by using some commonly used performance measures","017f9a8e":"Time to prepare our data and scikit-learn classifier!","ed616bb7":"These are the most informative features in the dataset:\n* **Director Ratio**\n    * The average profit-budget ratio of the director's other films\n* **Keywords Ratio**\n    * The average profit-budget ratio of the keywords in the film's summary\n* **Studios Ratio**\n    * The average profit-budget ratio of the studio's other films\n* **Lead Actor Ratio**\n    * The average profit-budget ratio of the lead actor's other films\n* **Budget**\n    * The budget of the film\n    \nSo, lets create a dataset with only these features."}}