{"cell_type":{"b7eb7c33":"code","4e29f197":"code","3a264dd5":"code","c1872292":"code","b8df22fe":"code","9d07e356":"code","41e940c6":"code","94da357c":"code","d3139b8e":"code","f41811b3":"code","bcafac0a":"code","d5c8e5ee":"code","ce857421":"code","b2328618":"code","179c0b7d":"code","8dd0c68d":"code","6554aebf":"markdown","4d9e4ce8":"markdown","c47b08ee":"markdown","3542c58d":"markdown","be6e70cb":"markdown","565d2a10":"markdown","acfaa37a":"markdown"},"source":{"b7eb7c33":"import pandas as pd \nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torchaudio\nimport os\nimport IPython.display as ipd\nimport numpy as np\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\npd.set_option('display.max_columns', None)\n","4e29f197":"audio_files=[]\nfor root,_,files in os.walk(\"..\/input\/birdsong-recognition\/train_audio\"):\n    for f in files:\n        audio_files.append(os.path.join(root,f))","3a264dd5":"df=pd.read_csv(\"..\/input\/birdsong-recognition\/train.csv\")","c1872292":"df_bird_geo=pd.DataFrame()\ndf_bird_geo['Bird_Name']=df['species']\ndf_bird_geo['lattitude']=df['latitude']\ndf_bird_geo['longitude']=df['longitude']\ndf_bird_geo['country']=df['country']\ndf_bird_geo_1=df_bird_geo.drop_duplicates()","b8df22fe":"fig = px.scatter_geo(df_bird_geo_1, lat=\"lattitude\",lon=\"longitude\",\n                     color=\"Bird_Name\", # which column to use to set the color of markers\n                     hover_name=\"country\", # column added to hover information\n                     projection=\"natural earth\")\niplot(fig)","9d07e356":"plt.figure(figsize=(10,5))\nsns.countplot(df.ebird_code,order=df.ebird_code.value_counts().index).set_xticklabels(\" \")\nplt.savefig(\"output1.jpeg\")","41e940c6":"sns.distplot(df.ebird_code.value_counts(),bins=10)\n","94da357c":"fig, ax = plt.subplots()\nfig.set_size_inches(14, 5)\nx=(df.country.value_counts()[:10]).index \ny=(df.country.value_counts()[:10]).values\nsns.barplot(x=x,y=y,).set_yscale(\"log\") \nfig.savefig(\"outpu3.jpeg\")","d3139b8e":"import plotly.express as px\nfig = px.bar(df, x=df['species'])\niplot(fig)","f41811b3":"fig, ax = plt.subplots()\nfig.set_size_inches(14, 5)\nsns.countplot(df.length,order=df.length.value_counts(ascending=True).index)\nfig.savefig(\"outpu4.jpeg\")","bcafac0a":"fig, ax = plt.subplots()\nfig.set_size_inches(14, 5)\nsns.countplot(df.speed, order=df.speed.value_counts().index)\nfig.savefig(\"outpu5.jpeg\")","d5c8e5ee":"fig, ax = plt.subplots()\nfig.set_size_inches(14, 5)\nsns.countplot(df.rating)\nfig.savefig(\"outpu5.jpeg\")","ce857421":"filename = audio_files[0]\nwaveform, sample_rate = torchaudio.load(filename)\n\nprint(\"Shape of waveform: {}\".format(waveform.size()))\nprint(\"Sample rate of waveform: {}\".format(sample_rate))\nplt.figure(figsize=(15,5))\nplt.plot(waveform.t().numpy())\nipd.Audio(audio_files[0])\nfig.savefig(\"outpu6.jpeg\")","b2328618":"def convert_to_tensor(audio_file):\n    tensor, _= torchaudio.load(audio_file)\n    torch.save(tensor,'_tensor')\n    return tensor","179c0b7d":"convert_to_tensor(audio_files[0])","8dd0c68d":"np.shape(convert_to_tensor(audio_files[0]))","6554aebf":"# Birds Distribution Over The Globe\n","4d9e4ce8":"# Top Birds By Count","c47b08ee":"# Function To Conver Audio .mp3 \/ wav  -> Tensor ","3542c58d":"# Visualizing Audio Waveform","be6e70cb":"# Birds Count Distribution ","565d2a10":"# Top 10 Countries  by Number of Birds Observed ","acfaa37a":"# Audio Length Distribution over Dataset"}}