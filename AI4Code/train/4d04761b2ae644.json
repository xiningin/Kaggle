{"cell_type":{"7d45c128":"code","3cc465e1":"code","75e39840":"code","1705eabd":"code","1f999b10":"code","8fab4fc9":"code","d2e0c7be":"code","16798732":"code","cf2ec6fa":"code","7454ca74":"code","90fedbf3":"code","4c7b9185":"code","a64fcd1f":"code","1f8a6e41":"code","7c0910d5":"code","a83bb5d2":"markdown","9812d81b":"markdown","dd489a42":"markdown","adb41e30":"markdown","d103f56d":"markdown","99131b8f":"markdown","2d20edb6":"markdown","68088542":"markdown","641fe610":"markdown","2412ce11":"markdown","490c15b0":"markdown"},"source":{"7d45c128":"# Libraries\nimport os\nimport random\n\n# numpy\nimport numpy as np\n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Charts\nimport matplotlib.pyplot as plt\n\n# Image IO\nimport skimage.io\nimport skimage.transform\n\n# Deep learning\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow\n\n# Set random seed to make results reproducable\nnp.random.seed(21)\ntensorflow.set_random_seed(21)","3cc465e1":"# Parameters\ntraining_dataset_path = \"..\/input\/dataset\/dataset_updated\/training_set\"\ntest_dataset_path = \"..\/input\/dataset\/dataset_updated\/validation_set\"\n\n# categories to use\n# categories = ['drawings', 'engraving', 'iconography', 'painting']\ncategories = ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']\nn_categories = len(categories)\ncategory_embeddings = {\n    'drawings': 0,\n    'engraving': 1,\n    'iconography': 2,\n    'painting': 3,\n    'sculpture': 4\n}\n\n# After computing the mean image size, we can set a default width and a default height to resize the images\n# Warning : this is a convention that I decided to use\nwidth = 128 # 368\nheight = 128 # 352\nn_channels = 3","75e39840":"# training dataset metadata\nn_imgs = []\nfor cat in categories:\n    files = os.listdir(os.path.join(training_dataset_path, cat))\n    n_imgs += [len(files)]\n    \ncat_max_samples = max(n_imgs)\n    \nplt.bar([_ for _ in range(n_categories)], n_imgs, tick_label=categories)\nplt.show()","1705eabd":"fig, axes = plt.subplots(nrows=1, ncols=n_categories, figsize=(15, 3))\n\ncat_cpt=0\nfor cat in categories:\n    category_path = os.path.join(training_dataset_path, cat)\n    img_name = os.listdir(category_path)[0]\n    img = skimage.io.imread(os.path.join(category_path, img_name))\n    img = skimage.transform.resize(img, (width, height, n_channels), mode='reflect')\n    axes[cat_cpt].imshow(img, resample=True)\n    axes[cat_cpt].set_title(cat, fontsize=8)\n    cat_cpt += 1\n\nplt.show()","1f999b10":"training_data = []\nfor cat in categories:\n    files = os.listdir(os.path.join(training_dataset_path, cat))\n    for file in files:\n        training_data += [(os.path.join(cat, file), cat)]\n\ntest_data = []\nfor cat in categories:\n    files = os.listdir(os.path.join(test_dataset_path, cat))\n    for file in files:\n        test_data += [(os.path.join(cat, file), cat)]","8fab4fc9":"# Load all images to the same format (takes some time)\ndef load_dataset(tuples_list, dataset_path):\n    indexes = np.arange(len(tuples_list))\n    np.random.shuffle(indexes)\n    \n    X = []\n    y = []\n    n_samples = len(indexes)\n    cpt = 0\n    for i in range(n_samples):\n        t = tuples_list[indexes[i]]\n        try:\n            img = skimage.io.imread(os.path.join(dataset_path, t[0]))\n            img = skimage.transform.resize(img, (width, height, n_channels), mode='reflect')\n            X += [img]\n            y_tmp = [0 for _ in range(n_categories)]\n            y_tmp[category_embeddings[t[1]]] = 1\n            y += [y_tmp]\n        except OSError:\n            pass\n        \n        cpt += 1\n        \n        if cpt % 1000 == 0:\n            print(\"Processed {} images\".format(cpt))\n\n    X = np.array(X)\n    y = np.array(y)\n    \n    return X, y\n\nX_train, y_train = load_dataset(training_data, training_dataset_path)\nX_val, y_val = load_dataset(test_data, test_dataset_path)","d2e0c7be":"# creation of a keras image generator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    horizontal_flip=True)\n\ntrain_datagen.fit(X_train)","16798732":"# CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=5, input_shape=(width, height, n_channels), activation='relu'))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu', strides=(2, 2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(48, kernel_size=3, activation='relu'))\nmodel.add(Conv2D(48, kernel_size=3, activation='relu', strides=(2, 2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(n_categories, activation='softmax'))\n\n# Don't forget to compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","cf2ec6fa":"# fit using a train and a validation generator\n# train_generator = DataGenerator(training_data, training_dataset_path)\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n# test_generator = DataGenerator(test_data, test_dataset_path)\n\ntraining_result = model.fit_generator(generator=train_generator,\n                                      validation_data=(X_val, y_val),\n                                      epochs=20,\n                                      verbose=1,\n                                      steps_per_epoch=len(X_train) \/ 32)","7454ca74":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))\n\naxes[0].plot(training_result.history['loss'], label=\"Loss\")\naxes[0].plot(training_result.history['val_loss'], label=\"Validation loss\")\naxes[0].set_title('Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].legend()\n\n# Accuracy\naxes[1].plot(training_result.history['acc'], label=\"Accuracy\")\naxes[1].plot(training_result.history['val_acc'], label=\"Validation accuracy\")\naxes[1].set_title('Accuracy')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy')\naxes[1].legend()\nplt.tight_layout()\n\nplt.show()","90fedbf3":"# Let's look at more metrics\nfrom sklearn.metrics import classification_report\n\nX_test = []\ny_test = []\nfor t in test_data:\n    try:\n        img = skimage.io.imread(os.path.join(test_dataset_path, t[0]))\n        img = skimage.transform.resize(img, (width, height, n_channels), mode='reflect')\n        X_test += [img]\n        y_test += [category_embeddings[t[1]]]\n    except OSError:\n        pass\n\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\npred = model.predict(X_test, verbose=1)\n\ny_pred = np.argmax(pred, axis=1)\nprint(classification_report(y_test, y_pred))","4c7b9185":"from sklearn.metrics import confusion_matrix\n\nc_matrix = confusion_matrix(y_test, y_pred)\nplt.imshow(c_matrix, cmap=plt.cm.Blues)\nplt.title(\"Confusion matrix\")\nplt.colorbar()\nplt.show()\nprint(c_matrix)","a64fcd1f":"for cat in categories:\n    files = os.listdir(os.path.join(training_dataset_path, cat))\n    n_upsample = cat_max_samples - len(files)\n    files = os.listdir(os.path.join(training_dataset_path, cat))\n    for _ in range(n_upsample):\n        file = files[random.randint(0, len(files) - 1)]\n        training_data += [(os.path.join(cat, file), cat)]","1f8a6e41":"X_train, y_train = load_dataset(training_data, training_dataset_path)\nX_val, y_val = load_dataset(test_data, test_dataset_path)","7c0910d5":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# fit using a train generator\n# creation of a keras image generator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    horizontal_flip=True)\n\ntrain_datagen.fit(X_train)\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n\ntraining_result = model.fit_generator(generator=train_generator,\n                                      validation_data=(X_val, y_val),\n                                      epochs=20,\n                                      verbose=1,\n                                      steps_per_epoch=len(X_train) \/ 32)","a83bb5d2":"## Let's fix some parameters","9812d81b":"## Classification\nHere we will create and train a CNN thanks to the Keras API","dd489a42":"Let's recreate our training and validation data.","adb41e30":"Here we have an accuracy of about 83% for the 5-class problem (including sculptures). This is not too bad for a first small CNN. We could try to boost the accuracy by adding some data through data generation or by increasing a bit the size of the CNN. Moreover, I still need to study the results in depth : more metrics and class by class results to see if any improvements can be made\n","d103f56d":"Let's retrain our model. I recompile it before to reset it.","99131b8f":"### Let's look at some images","2d20edb6":"The main problems are with the two first classes. The two classes for which we had less training samples. Now, let's look at the confusion matrix.\nWe remark the same thing, the main problem is with the first two classes.","68088542":"## Training data\n\n### Image repartition\nHere we see that we have 3 big classes and 2 smaller ones. At first, we will try to use them like that.","641fe610":"# **Classifying art pieces**\n\nHere, we will visualize and try to classify pictures into 5 art categories with a simple CNN.","2412ce11":"## Preprocessing\nHere, we will create our training dataset i.e. a list of tuples (path_to_img, category) that will be used to read the images batch by batch","490c15b0":"Now, let's try to upsample the first two classes to boost a bit the accuracy. To do that, we will add samples of each class until we get the same number of images per category."}}