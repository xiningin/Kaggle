{"cell_type":{"68d580c6":"code","46d9c96c":"code","644e238d":"code","f64dd217":"code","42715bfe":"code","8c260bcd":"code","0a300f30":"code","deabfaf4":"code","2607e1c9":"markdown","78df7fa0":"markdown","56182398":"markdown","4837a732":"markdown"},"source":{"68d580c6":"import numpy as np\nimport sys\nfrom itertools import product","46d9c96c":"class TicTacToe:\n    \"\"\"\n    Game environment for Tic Tac Toe, to be played by a pair \n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def get_winner(self):\n        \"\"\"\n        Return the winner state.\n        \n        draw: -1\n        x wins: 0\n        o wins: 1\n        game still in session: None\n        \"\"\"\n        return self._winner\n    \n    def is_draw(self):\n        \"\"\"\n        Return true if game is a draw.\n        \"\"\"\n        return self._winner < 0\n    \n    def is_game_over(self):\n        \"\"\"\n        Return true if game is finished.\n        \"\"\"\n        return self._winner is not None\n    \n    def num_moves(self):\n        \"\"\"\n        Return the number of moves played in this game so far.\n        \"\"\"\n        return len(self._history) - 1\n        \n    def get_state(self, which):\n        \"\"\"\n        Return a string state code of this game for player valuation. \n        \n        The state is the concatenation of board values, S=self, O=other, .=nobody,\n            in order from top left to bottom right, going left to right, then top to bottom.\n        \n        which: for which player, 0=x, 1=o \n        \"\"\"\n        return self._convert_state(self._state, which)\n    \n    def get_history(self, which):\n        \"\"\"\n        Return a list of all states, in order, in the game so far for valuation by a player.\n        \n        The state is the concatenation of board values, S=self, O=other, .=nobody,\n            in order from top left to bottom right, going left to right, then top to bottom.\n        \n        which: for which player, 0=x, 1=o \n        \"\"\"\n        return [self._convert_state(s, which) for s in self._history]\n    \n    def get_turn(self):\n        \"\"\"\n        Whose turn is it?\n        \n        return: 0 for x, 1 for o, None for game over\n        \"\"\"\n        if self.is_game_over():\n            return None\n        if self._x_turn():\n            return 0\n        if self._o_turn():\n            return 1\n        return None\n    \n    def get_valid_moves(self, which):\n        \"\"\"\n        Return all valid moves available.\n        \n        Return: list of tuples, each tuple being (which, move, next_state)\n        which: 0=x, 1=o\n        move: (row, col) row, col each from 0 to 2 inclusive\n        next_state: unique state string of the resulting game position from which's point of view,\n            concatenation of board values, S=self, O=other, .=nobody,\n            in order from top left to bottom right, going left to right, then top to bottom.\n\n        \"\"\"\n        moves = []\n        for row, col in product(range(3), range(3)):\n            move = (row, col)\n            pos = self._move_to_pos(move)\n            if self._is_move_valid(which, pos):\n                next_state = self._convert_state(self._state[:pos] + \"xo\"[which] + self._state[pos+1:], which)\n                moves.append((which, move, next_state))\n        return moves\n\n    def play_random_move(self, which=None, verbose=0, moves=None):\n        \"\"\"\n        Play a random move.\n        \n        which: which player is moving, 0=x, 1=o.  Use default for whoever's turn it is (recommended).\n        verbose: nonnegative float.  higher numbers print more information. 0 for quiet.\n        moves: select only from this list of (which, move, state) triples as returned by get_valid_moves.\n            default is to choose randomly from every move available.        \n            \n        return:  0 if x wins with this move, 1 if o wins with this move, -1 if game is drawn, None if game\n            is not finished, and False in case of an error (printed if verbose>0)\n        \"\"\"\n        if which is None:\n            which = self.get_turn()\n        if moves is None:\n            moves = self.get_valid_moves(which)\n        index = np.random.randint(0, len(moves))\n        (w, move, s) = moves[index]\n        return self.play(which, move, verbose=verbose)\n    \n        \n    \n    def play(self, which=None, move=None, verbose=0):\n        \"\"\"\n        Play a specified move.\n        \n        which: which player is moving, 0=x, 1=o.  Use default for whoever's turn it is (recommended).\n        move: (row, col) to play.  If a list of (which, move, state) triples as returned by get_valid_moves, choose\n            randomly from one of these.  Default is to just play a random move.\n        verbose: nonnegative float.  higher numbers print more information. 0 for quiet.\n        \n        return:  0 if x wins with this move, 1 if o wins with this move, -1 if game is drawn, None if game\n            is not finished, and False in case of an error (printed if verbose>0)\n        \"\"\"\n        if move is None:\n            return self.play_random_move(which=which, verbose=verbose)\n        if hasattr(move, '__get_item__'):\n            return self.play_random_move(which=which, verbose=verbose, moves=move)\n        if which is None:\n            which = self.get_turn()\n        move_num = len(self._history)\n        pos = self._move_to_pos(move)\n        if self._winner is not None:\n            if verbose:\n                print(\"Error:\", \"Game has ended\")\n            return False        \n        if self._state[pos] != '.':\n            if verbose:\n                print(\"Error:\", \"Position already played\")\n            return False\n        if which == 0 and not self._x_turn():\n            if verbose:\n                print(\"Error:\", \"Not x's turn\")\n            return False\n        if which == 1 and not self._o_turn():\n            if verbose:\n                print(\"Error:\", \"Not o's turn\")\n            return False\n        self._state = self._state[:pos] + \"xo\"[which] + self._state[pos+1:]\n        self._history.append(self._state)\n        if which == 0 and self._x_won():\n            self._winner = 0\n            if verbose > 0:\n                print(move_num, \"x is the winner\")\n            return 0\n        if which == 1 and self._o_won():\n            self._winner = 1\n            if verbose > 0:\n                print(move_num, \"o is the winner\")\n            return 1\n        if self._board_full():\n            self._winner = -1\n            if verbose > 0:\n                print(move_num, \"game is drawn\")\n            return -1\n        if verbose > 1:\n            print(move_num, \"Move accepted, game continues\")\n        return None\n    \n    def reset(self):\n        \"\"\"\n        Reset the game to play it again.\n        \"\"\"\n        self._state = \".\"*9\n        self._history = [self._state]\n        self._winner = None\n    \n    def draw(self, file=sys.stdout):\n        \"\"\"\n        Draw the current tic tac toe board.\n        \n        file: where to print to.  Default is sys.stdout\n        \"\"\"\n        print(self._state[:3], file=file)\n        print(self._state[3:6], file=file)\n        print(self._state[6:], file=file)\n\n    def draw_history(self, per_row=10, from_=0, to=None, file=sys.stdout):\n        \"\"\"\n        Draw all boards so far.\n        \n        per_row: how many boards per row (default: 10 so all boards are on one row)\n        from_: starting board from 0 to 9 (default: 0=initial empty board)\n        to: ending board from 0 to 9 (default: last board played)\n        \n        file: where to print to.  Default is sys.stdout\n\n        >>> env = TicTacToe()\n        >>> env.play('x',1,1)\n        >>> env.play('o',2,2)\n        >>> env.play('x',2,0)\n        >>> env.play('o',0,2)\n        >>> env.play('x',1,2)\n        >>> env.play('o',1,0)\n        >>> env.play('x',0,1)\n        >>> env.play('o',2,1)\n        >>> env.play('x',0,0)\n        >>> env.draw_history()\n        ...   ...   ...   ...   ..o   ..o   ..o   .xo   .xo   xxo   \n        ...   .x.   .x.   .x.   .x.   .xx   oxx   oxx   oxx   oxx   \n        ...   ...   ..o   x.o   x.o   x.o   x.o   x.o   xoo   xoo\n        \"\"\"\n        if to is None:\n            to = len(self._history)\n        for i in range(from_, to, per_row):\n            for j in range(i, min(i+per_row, to)):\n                print(self._history[j][:3] + '   ', file=file, end='')\n            print(file=file)\n            for j in range(i, min(i+per_row, to)):\n                print(self._history[j][3:6] + '   ', file=file, end='')\n            print(file=file)\n            for j in range(i, min(i+per_row, to)):\n                print(self._history[j][6:] + '   ', file=file, end='')\n            print(file=file)\n            print(file=file)\n    \n    def self_won(self, converted_state):\n        \"\"\"\n        Return True if the state is that of its own player winning.\n        \n        Gives wrong answers for invalid states.\n        \"\"\"\n        if converted_state[:3] == 'SSS' or converted_state[3:6] == 'SSS' or converted_state[6:] == 'SSS':\n            return True\n        if converted_state[0] == 'S' and converted_state[3] == 'S' and converted_state[6] == 'S':\n            return True\n        if converted_state[1] == 'S' and converted_state[4] == 'S' and converted_state[7] == 'S':\n            return True\n        if converted_state[2] == 'S' and converted_state[5] == 'S' and converted_state[8] == 'S':\n            return True\n        if converted_state[0] == 'S' and converted_state[4] == 'S' and converted_state[8] == 'S':\n            return True\n        if converted_state[2] == 'S' and converted_state[4] == 'S' and converted_state[6] == 'S':\n            return True\n        return False\n    \n    def self_lost(self, converted_state):\n        \"\"\"\n        Return True if the state is that of its own player losing.\n        \n        Gives wrong answers for invalid states.\n        \"\"\"\n        if converted_state[:3] == 'OOO' or converted_state[3:6] == 'OOO' or converted_state[6:] == 'OOO':\n            return True\n        if converted_state[0] == 'O' and converted_state[3] == 'O' and converted_state[6] == 'O':\n            return True\n        if converted_state[1] == 'O' and converted_state[4] == 'O' and converted_state[7] == 'O':\n            return True\n        if converted_state[2] == 'O' and converted_state[5] == 'O' and converted_state[8] == 'O':\n            return True\n        if converted_state[0] == 'O' and converted_state[4] == 'O' and converted_state[8] == 'O':\n            return True\n        if converted_state[2] == 'O' and converted_state[4] == 'O' and converted_state[6] == 'O':\n            return True\n        return False\n    \n    def self_board_full(self, converted_state):\n        \"\"\"\n        Return True if the state is that of a full board.\n        \n        Gives wrong answers for invalid states.\n        \"\"\"\n        return '.' not in converted_state\n\n    \n    def _is_move_valid(self, which, pos):\n        \"\"\"\n        Return True if the proposed move is valid for the specified player.\n        \n        If it is not the player's turn or the game is over or the position is already\n            taken, return False.\n        \n        which: which player, 0=x, 1=o\n        pos: integer position = row*3 + col where move is (row, col), row, col from 0 to 2 inclusive.\n        \"\"\"\n        if self._winner is not None:\n            return False        \n        if self._state[pos] != '.':\n            return False\n        if which == 0 and not self._x_turn():\n            return False\n        if which == 1 and not self._o_turn():\n            return False\n        return True\n        \n    def _x_turn(self):\n        \"\"\"\n        Return True if it is x's turn.\n        \n        Does not check if game is over.\n        \"\"\"\n        return self._state.count('x') == self._state.count('o')\n    \n    def _o_turn(self):\n        \"\"\"\n        Return True if it is o's turn.\n        \n        Does not check if game is over.\n        \"\"\"\n        return self._state.count('x') == self._state.count('o') + 1\n        \n    def _x_won(self):\n        \"\"\"\n        Return True if x has won the game.        \n        \"\"\"\n        if self._state[:3] == 'xxx' or self._state[3:6] == 'xxx' or self._state[6:] == 'xxx':\n            return True\n        if self._state[0] == 'x' and self._state[3] == 'x' and self._state[6] == 'x':\n            return True\n        if self._state[1] == 'x' and self._state[4] == 'x' and self._state[7] == 'x':\n            return True\n        if self._state[2] == 'x' and self._state[5] == 'x' and self._state[8] == 'x':\n            return True\n        if self._state[0] == 'x' and self._state[4] == 'x' and self._state[8] == 'x':\n            return True\n        if self._state[2] == 'x' and self._state[4] == 'x' and self._state[6] == 'x':\n            return True\n        return False\n    \n    def _o_won(self):\n        \"\"\"\n        Return True if o has won the game.        \n        \"\"\"\n        if self._state[:3] == 'ooo' or self._state[3:6] == 'ooo' or self._state[6:] == 'ooo':\n            return True\n        if self._state[0] == 'o' and self._state[3] == 'o' and self._state[6] == 'o':\n            return True\n        if self._state[1] == 'o' and self._state[4] == 'o' and self._state[7] == 'o':\n            return True\n        if self._state[2] == 'o' and self._state[5] == 'o' and self._state[8] == 'o':\n            return True\n        if self._state[0] == 'o' and self._state[4] == 'o' and self._state[8] == 'o':\n            return True\n        if self._state[2] == 'o' and self._state[4] == 'o' and self._state[6] == 'o':\n            return True\n        return False\n        \n    def _board_full(self):\n        \"\"\"\n        Return true if board is currently full.\n        \"\"\"\n        return '.' not in self._state\n    \n    def _convert_state(self, state, which):\n        \"\"\"\n        Convert internal state to state from the point of view of a given player suitable for valuation.\n        \n        which: 0=x, 1=o\n        state: internal state: concatenation of board values, x, o, or .=nobody,\n            in order from top left to bottom right, going left to right, then top to bottom.\n        \n        returns: unique state string of the resulting game position from which's point of view,\n            concatenation of board values, S=self, O=other, .=nobody,\n            in order from top left to bottom right, going left to right, then top to bottom.\n        \"\"\"\n        if which == 0:\n            state = state.replace('x','S')\n            state = state.replace('o','O')\n        else:\n            state = state.replace('o','S')\n            state = state.replace('x','O')\n        return state\n    \n    def _move_to_pos(self, move):\n        \"\"\"\n        Convert a move=(row, col) to a position integer from 0 to 8 inclusive\n        \n        returns: row*3 + col\n        \"\"\"\n        return move[0]*3 + move[1]\n","644e238d":"class Agent:\n    \"\"\"\n    A player (one of two) of the game environment.\n    \n    >>> agent = Agent(win_value=1, lose_value=0, draw_value=0, unknown_value=0.5)\n    \n    create a new agent.\n    \n    win_value: value of a state in which this agent wins\n    lose_value: value of a state in which this agent loses\n    draw_value: value of a state in which the game is a draw\n    unknown_value: initial value for a state that has not yet been valuated\n    \"\"\"\n    def __init__(self, win_value=1, lose_value=0, draw_value=0, unknown_value=0.5):\n        self._values = dict()\n        self._win_value = win_value\n        self._lose_value = lose_value\n        self._draw_value = draw_value\n        self._unknown_value  = unknown_value\n        \n    def Play(self, env, which=0, epsilon=0.05, accuracy=0.000001, verbose=1):\n        moves = env.get_valid_moves(which)\n        if np.random.rand() <= epsilon:\n            return env.play_random_move(which=which, verbose=verbose)\n        best_value = 0\n        best_moves = []\n        for (w, move, next_state) in moves:\n            if np.abs(self.GetValue(env, next_state) - best_value) <= accuracy:\n                best_moves.append((w, move, next_state))\n            elif self.GetValue(env, next_state) > best_value:\n                best_value = self.GetValue(env, next_state)\n                best_moves = [(w, move, next_state)]\n        return env.play_random_move(which=which, verbose=verbose, moves=best_moves)   \n           \n    def GetValue(self, env, state):\n        if(state in self._values):\n            return self._values[state]\n        if env.self_won(state):\n            self._values[state] = self._win_value\n        elif env.self_lost(state):\n            self._values[state] = self._lose_value\n        elif env.self_board_full(state):\n            self._values[state] = self._draw_value\n        else:\n            self._values[state] = self._unknown_value\n        return self._values[state]        \n        \n    def UpdateValue(self, env, state, next_state, learning_rate=0.1):\n        self._values[state] = self.GetValue(env, state)*(1 - learning_rate) + self.GetValue(env, next_state)*learning_rate\n    \n    def UpdateAllValuesFromHistory(self, env, which, learning_rate=0.1):\n        history = env.get_history(which)\n        for i in range(len(history)-2,-1,-1):\n            s = history[i]\n            s1 = history[i+1]\n            self.UpdateValue(env, s, s1, learning_rate)        \n            ","f64dd217":"class Game:\n    def __init__(self, env_class, agent_class):\n        self._agents = [agent_class(), agent_class()]\n        self._environment = env_class()\n        self._last_iter=0\n\n    def ResetGame(self):\n        self._last_iter=0\n        \n    def PlayGame(self, num=1, update_agents=[0, 1], learning_rate=0.1, verbose=None, progress=1000, epsilon=0.05):\n        wins = [0,0]\n        if(verbose is None):\n            if num == 1:\n                verbose = 2\n            else:\n                verbose = 0.5\n        for iter in range(num):\n            if progress > 0 and (iter + 1) % progress == 0:\n                print(iter+1,\"games played\", end='\\r')                \n            self._environment.reset()\n            if(verbose >= 1):\n                print(\"Game\", self._last_iter + iter + 1)\n            while not self._environment.is_game_over():\n                which = self._environment.get_turn()\n                self._agents[which].Play(env=self._environment, which=which, verbose=verbose-1, epsilon=epsilon)\n                if which in update_agents:\n                    self._agents[which].UpdateAllValuesFromHistory(self._environment, which, learning_rate=learning_rate)\n                if 1 - which in update_agents:\n                    self._agents[1 - which].UpdateAllValuesFromHistory(self._environment, 1 - which, learning_rate=learning_rate)\n            if verbose>1:\n                self._environment.draw_history()\n            w = self._environment.get_winner()\n            if w in (0, 1):\n                wins[w] += 1\n        if verbose:\n            print(\"Played games\", self._last_iter+1, \"through\", self._last_iter + num, \"    wins:\", wins)\n            self._environment.draw_history()\n        self._last_iter += num\n    \n    ","42715bfe":"# create a new game manager using the tic tac toe environment class and agent class\ngame = Game(TicTacToe, Agent)","8c260bcd":"# play the game lots of times, updating both agents (0 and 1).  Last game is displayed in full along\n# with total wins for agent 0 (X) and agent 1(O) in that order.\ngame.PlayGame(100000, update_agents=[0,1], learning_rate=0.01, epsilon=0.01) ","0a300f30":"#Number of tic tac toe states discovered by agent 0 and agent 1\nlen(game._agents[0]._values), len(game._agents[1]._values)","deabfaf4":"## Breakdown of number of states by number of marks on tic-tac-toe board, checking both X and O reckonings\nfor i in range(10):\n    x_count = len([x for x in game._agents[0]._values if 9 - x.count('.') == i])\n    o_count = len([x for x in game._agents[1]._values if 9 - x.count('.') == i])\n    print(\"play:\", i, \"states for x:\", x_count, \"states for o:\", o_count)","2607e1c9":"# Reinforcement Learning: Tic Tac Toe\n\nWinning is valued at 1, losing and draw equally valued at 0\n(do not want to find an agent that never loses, but never wins either)\n\nTwo agents play each other many times essentially starting at random but learning to beat each other, at least some\nof the time.\n\nTen million trials discovered 5478 unique tic-tac-toe states, matching that found by:\n\n    Rod (https:\/\/math.stackexchange.com\/users\/116929\/rod), \n    Determining the number of valid TicTacToe board states \n    in terms of board dimension, URL (version: 2013-12-20): \n    https:\/\/math.stackexchange.com\/q\/613505","78df7fa0":"## An agent that will play in the game environment.","56182398":"## The game manager that pits two agents against each other in the environment and displays the results","4837a732":"## Tic Tac Toe game environment that the agents will play in"}}