{"cell_type":{"47570859":"code","0e7f057c":"code","8cbf842f":"code","056e9bc0":"code","d0d94c82":"code","8f1b1b2f":"code","6adc4f34":"code","26ce99fb":"code","9fd33b8f":"code","50569988":"code","d1f36b5d":"code","4ab7d746":"code","d6138d1f":"code","9d16b9d7":"code","3807e57f":"code","88af3b49":"code","829bea56":"code","e2f807c3":"code","50bf6355":"code","d6830a6d":"code","b30ffde7":"code","87a0fbd5":"code","f0ca480a":"code","ab2a9987":"code","f32ee44b":"code","84477dbf":"code","11e609b1":"code","50d869c2":"code","9e689a5d":"code","c69d4f4f":"code","ae3e6882":"code","4c61acb7":"code","e0206167":"code","3c377104":"code","2a309c9b":"code","871342cc":"markdown","d71f1f3d":"markdown","88a73656":"markdown","e525cf18":"markdown","3efd6cf3":"markdown","64b19225":"markdown","fa5da8bc":"markdown","63c74abd":"markdown","646cf682":"markdown"},"source":{"47570859":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e7f057c":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split,DataLoader,TensorDataset\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8cbf842f":"train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","056e9bc0":"test.head()","d0d94c82":"train.head()","8f1b1b2f":"len(train)","6adc4f34":"len(test)","26ce99fb":"train.shape","9fd33b8f":"test.shape","50569988":"# Target variable\nlabels=train.label","d1f36b5d":"# Independent variables\ntrain_ds=train.drop('label',axis=1)","4ab7d746":"train_ds.head()","d6138d1f":"plt.imshow(train_ds[1:2].values.reshape(28,28))\nplt.axis(\"off\")\nprint(labels[1])","9d16b9d7":"train_ds=train_ds.values\ntest_ds=test.values\nlabels=labels.to_numpy()             #labels was actually a pandas series","3807e57f":"train_ds=torch.tensor(train_ds)\ntest_ds =torch.tensor(test_ds)\nlabels = torch.tensor(labels)","88af3b49":"traiin_ds=TensorDataset(train_ds,labels)","829bea56":"traiin_ds[0:2]","e2f807c3":"train_ds , val_ds = random_split(traiin_ds,(32000,10000))","50bf6355":"train_loader=DataLoader(train_ds , batch_size=128, shuffle = True)\nval_loader=DataLoader(val_ds , batch_size=128, shuffle = False)","d6830a6d":"test_loader=DataLoader(test_ds , batch_size=128, shuffle = False)","b30ffde7":"# for each image\ninput_size = 784\nnum_class = 10","87a0fbd5":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n                                                                        \n        self.conv1 = nn.Conv2d(\n                                in_channels=1,\n                                out_channels=8,\n                                kernel_size=(3, 3),\n                                stride=(1, 1),\n                                padding=(1, 1)\n        )                                                                \n        \n        self.pool = nn.MaxPool2d(\n                                 kernel_size=(2, 2),\n                                 stride=(2, 2)\n        )                                                               \n                                                                        \n        \n        self.conv2 = nn.Conv2d(\n                                in_channels=8,\n                                out_channels=16,\n                                kernel_size=(3, 3),\n                                stride=(1, 1),\n                                padding=(1, 1),\n        )                                                            \n        \n        self.fc1 = nn.Linear(16 * 7 * 7, num_class)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))                                      # 8,28,28\n        x = self.pool(x)                                               # 8,14,14\n        x = F.relu(self.conv2(x))                                      # 16,14,14\n        x = self.pool(x)                                               #16,7,7\n        \n#         print(x.shape)\n        x = x.reshape(x.shape[0], -1)\n    \n        x = self.fc1(x)\n        return x\n    \nmodel = CNN().to('cuda')","f0ca480a":"#optimizer\nopt      = torch.optim.Adam\nopt = opt(model.parameters())","ab2a9987":"def fit(epochs,model,data):\n    \n    loss_fun = F.cross_entropy\n    hist = []\n    for Epoch in range(epochs):\n        for img,label in data:\n            img = img.reshape(img.shape[0],1,28,28)\n            img=img.to('cuda')\n            label= label.to('cuda')\n#             print(img.shape)\n            out = model(img\/255)\n            loss = loss_fun(out,label)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n            hist.append(loss)\n        \n        if (Epoch+1)%50==0:\n            print(f\"Epoch:[{Epoch+1}\/{epochs}] ; Loss : {loss:.4f}\")\n    return hist","f32ee44b":"hist=fit(500,model,train_loader)","84477dbf":"def acc(data):\n    accy=[]\n    for img ,label in data:\n        img = img.reshape(img.shape[0],1,28,28)\n        img,label = img.to('cuda'),label.to('cuda')\n        out=model(img\/255)\n#         out=F.softmax(out)\n        _,pred_index=torch.max(out,dim=1)\n        x=torch.sum(pred_index==label)\/len(pred_index)\n        x=x*100\n        x=x.to(\"cpu\").numpy()\n        accy.append(x)\n        \n        \n    return np.mean(accy)  ","11e609b1":"acc(val_loader)","50d869c2":"submission= pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission.head()","9e689a5d":"def prediction(data):\n    LABEL=[]\n    data = data.reshape(data.shape[0],1,28,28)\n    data=data.to('cuda')\n    out = model(data\/255)\n    out = F.softmax(out)     \n    _,pred_index =torch.max(out,dim=1)\n    LABEL.append(pred_index)   \n    return LABEL","c69d4f4f":"test_ds.shape","ae3e6882":"x=prediction(test_ds)\nlen(x[0])","4c61acb7":"x","e0206167":"x=x[0].to('cpu').numpy()","3c377104":"submission[\"Label\"]=x","2a309c9b":"submission.to_csv(\"submission.csv\",index=False)","871342cc":"## Reading files","d71f1f3d":"## converting the data to numpy arrays","88a73656":"## Train the model","e525cf18":"## import libraries","3efd6cf3":"## converting data into tensordataset","64b19225":"## UPVOTE","fa5da8bc":"## Cnn Model","63c74abd":"## convert data to tensor","646cf682":"## Define training and validation data"}}