{"cell_type":{"5e64747b":"code","9710fc10":"code","fb0ed9c6":"code","95eda02e":"code","36176e9b":"code","66d1397b":"code","707889a6":"code","e937f3a4":"code","1782c741":"code","a2c62d30":"code","f6e58113":"code","f8c40f9f":"code","b97f422a":"markdown","e83cd19c":"markdown","7f6a31ea":"markdown","0767bbb5":"markdown","f6347a94":"markdown","1b4cc03b":"markdown","1771d3f9":"markdown","50daacb9":"markdown","ab287e2a":"markdown"},"source":{"5e64747b":"#import libraries \nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.experimental import enable_iterative_imputer  \nfrom sklearn.impute import IterativeImputer\nfrom sklearn.model_selection import StratifiedKFold,train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\n","9710fc10":"#import data\ntrain=pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest=pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\n\n#feature engineering\ntrain=train[~((train['energy'].isna()) & (train['liveness'].isna()))].reset_index(drop=True)\ntrain=train[~((train['acousticness'].isna()) & (train['instrumentalness'].isna()))].reset_index(drop=True)\ntrain=train[~((train['loudness'].isna()) & (train['danceability'].isna()))].reset_index(drop=True)\n\ntrain['acousticness'] = train['acousticness'].apply(lambda x : x if x > 0 else 0)\ntrain['energy'] = train['energy'].apply(lambda x : x if x > 0 else 0)\n\ntrain.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)\n\n#defining x and y\nx=train.drop(['song_popularity'], axis=1)\ny=train['song_popularity'] ","fb0ed9c6":"#pipeline for imputation and transformation\npipeline = Pipeline([\n    ('imputer',IterativeImputer(max_iter=10,random_state = 42,add_indicator = False)),\n    ('transform_',QuantileTransformer())\n])","95eda02e":"#fit and transform\nx = pd.DataFrame(pipeline.fit_transform(x),columns = x.columns)\ntest = pd.DataFrame(pipeline.transform(test),columns = test.columns)","36176e9b":"#initialize stratified kfold cross validation\nskf = StratifiedKFold(n_splits = 10,shuffle = True, random_state=42)","66d1397b":"#creating new dataframes for storing OOF predictions\nvalid_df = pd.DataFrame()\ntest_df = pd.DataFrame()\nvalid_df['id'] = x.index\ntest_df['id'] = test.index","707889a6":"scores = []\ntest_preds = []\ntemp_dic = {}\ntemp_df = pd.DataFrame()\n\n#optuna tuned hyperparameters -- for each model\ncat_params = {\n             'random_state': 115,\n             'iterations': 19891,\n             'od_wait': 1433,\n             'learning_rate': 0.03154726555551773,\n             'reg_lambda': 0.03727585833158683,\n             'subsample': 0.8,\n             'random_strength': 9.153730231192617,\n             'depth': 10,\n             'grow_policy': 'Lossguide',\n             'min_child_samples': 46,\n             'border_count': 23,\n             'bagging_temperature': 0.10054652410589532\n        }\n\n#applying cross validation\nfor fold,(train_id,valid_id) in enumerate(skf.split(x,y)):\n    x_train,x_valid = x.iloc[train_id],x.iloc[valid_id]\n    y_train,y_valid = y[train_id],y[valid_id]\n    \n    cat = CatBoostRegressor(**cat_params)\n    \n    #model fit\n    cat.fit(x_train, y_train, eval_set=[(x_valid,y_valid)], \n              early_stopping_rounds=300, \n              verbose=False)\n    \n    #model predictions\n    valid_pred = cat.predict(x_valid)\n    test_pred = cat.predict(test)\n    \n    test_preds.append(test_pred)\n    \n    #update the dictionary with oof scores\n    temp_dic.update(dict(zip(valid_id,valid_pred)))\n    \n    #getting auc scores for each fold\n    score = roc_auc_score(y_valid, valid_pred)\n    scores.append(score)\n    \n    print(f'Fold:- {fold+1} Score:- {score}')\n    print('--'*25)\n\nprint(f'final score {np.mean(scores)}')\n\n#getting mean of auc score for all the test folds\ntest_df['pred_cat'] = np.mean(test_preds,axis =0)\n\n#creating dataframe of scores\ntemp_df = pd.DataFrame.from_dict(temp_dic,orient='index',columns=['pred_cat']).reset_index().rename(columns={'index':'id'})\n\n#merging the scores by id\nvalid_df = valid_df.merge(temp_df, on = 'id')","e937f3a4":"scores = []\ntest_preds = []\ntemp_dic = {}\ntemp_df = pd.DataFrame()\n\nparams = {\n             'boosting_type': 'gbdt',\n             'num_leaves': 4,\n             'max_depth': 289,\n             'learning_rate': 0.3829510464605295,\n             'n_estimators': 6997,\n             'min_child_weight': 4.574050270822746,\n             'min_child_samples': 84,\n             'colsample_bytree': 0.611170900733142,\n             'reg_alpha': 27.373249914471092,\n             'reg_lambda': 0.0013763607520821293,\n             'random_state': 87\n        }\n\nfor fold,(train_id,valid_id) in enumerate(skf.split(x,y)):\n    x_train,x_valid = x.iloc[train_id],x.iloc[valid_id]\n    y_train,y_valid = y[train_id],y[valid_id]\n    \n    lgbm = lgb.LGBMRegressor(**params, objective='binary')\n\n    lgbm.fit(x_train, y_train)\n    \n    valid_pred = lgbm.predict(x_valid)\n    test_pred = lgbm.predict(test)\n    \n    test_preds.append(test_pred)\n    \n    temp_dic.update(dict(zip(valid_id,valid_pred)))\n    \n    score = roc_auc_score(y_valid, valid_pred)\n    scores.append(score)\n    \n    print(f'Fold:- {fold+1} Score:- {score}')\n    print('--'*25)\n\nprint(f'final score {np.mean(scores)}')\n\ntest_df['pred_lgbm'] = np.mean(test_preds,axis =0)\ntemp_df =pd.DataFrame.from_dict(temp_dic,orient='index',columns=['pred_lgbm']).reset_index().rename(columns={'index':'id'})\nvalid_df = valid_df.merge(temp_df, on = 'id')","1782c741":"scores = []\ntest_preds = []\ntemp_dic = {}\ntemp_df = pd.DataFrame()\n\nparams_xgb = {\n                 'random_state': 7,\n                 'max_depth': 6,\n                 'n_estimators': 9300,\n                 'learning_rate': 0.012438021820056207,\n                 'subsample': 0.4,\n                 'colsample_bytree': 0.5,\n                 'colsample_bylevel': 0.30000000000000004,\n                 'reg_lambda': 1.2361572361481428,\n                 'reg_alpha': 6.1105330117704595,\n                 'gamma': 0.12033944481406948\n            }\n\nfor fold,(train_id,valid_id) in enumerate(skf.split(x,y)):\n    x_train,x_valid = x.iloc[train_id],x.iloc[valid_id]\n    y_train,y_valid = y[train_id],y[valid_id]\n    \n    xgb = XGBRegressor(**params_xgb,\n                            booster= 'gbtree',\n                            objective= 'binary:logistic',\n                            eval_metric = 'auc',\n                            tree_method= 'gpu_hist',\n                            predictor=\"gpu_predictor\",\n                            gpu_id=0,\n                            use_label_encoder=False)\n\n    xgb.fit(x_train, y_train, verbose=False, eval_set=[(x_valid,y_valid)], \n                      early_stopping_rounds=300)\n    \n    valid_pred = xgb.predict(x_valid)\n    test_pred = xgb.predict(test)\n    \n    test_preds.append(test_pred)\n    \n    temp_dic.update(dict(zip(valid_id,valid_pred)))\n    \n    score = roc_auc_score(y_valid, valid_pred)\n    scores.append(score)\n    \n    print(f'Fold:- {fold+1} Score:- {score}')\n    print('--'*25)\n\nprint(f'final score {np.mean(scores)}')\n\ntest_df['pred_xgb'] = np.mean(test_preds,axis =0)\ntemp_df =pd.DataFrame.from_dict(temp_dic,orient='index',columns=['pred_xgb']).reset_index().rename(columns={'index':'id'})\nvalid_df = valid_df.merge(temp_df, on = 'id')","a2c62d30":"scores = []\ntest_preds = []\ntemp_dic = {}\ntemp_df = pd.DataFrame()\n\nfor fold,(train_id,valid_id) in enumerate(skf.split(x,y)):\n    x_train,x_valid = x.iloc[train_id],x.iloc[valid_id]\n    y_train,y_valid = y[train_id],y[valid_id]\n    \n    rf = RandomForestRegressor(max_depth=50,\n                                 n_estimators=1000,\n                                 max_features='log2',\n                                 max_leaf_nodes=148,\n                                 min_samples_split=8,\n                                 min_samples_leaf=20,\n                                 random_state=146,n_jobs =-1)\n\n    rf.fit(x_train, y_train)\n    \n    valid_pred = rf.predict(x_valid)\n    test_pred = rf.predict(test)\n    \n    test_preds.append(test_pred)\n    \n    temp_dic.update(dict(zip(valid_id,valid_pred)))\n    \n    score = roc_auc_score(y_valid, valid_pred)\n    scores.append(score)\n    \n    print(f'Fold:- {fold+1} Score:- {score}')\n    print('--'*25)\n\nprint(f'final score {np.mean(scores)}')\n\ntest_df['pred_rf'] = np.mean(test_preds,axis =0)\ntemp_df =pd.DataFrame.from_dict(temp_dic,orient='index',columns=['pred_rf']).reset_index().rename(columns={'index':'id'})\nvalid_df = valid_df.merge(temp_df, on = 'id')","f6e58113":"scores = []\ntest_preds = []\n\nx_1 = valid_df.drop(['id'],axis = 1)\ntest_1 = test_df.drop(['id'], axis = 1)\n\nfor fold,(train_id,valid_id) in enumerate(skf.split(x_1,y)):\n    x_train,x_valid = x_1.iloc[train_id],x_1.iloc[valid_id]\n    y_train,y_valid = y[train_id],y[valid_id]\n    \n    lr = LinearRegression()\n\n    lr.fit(x_train, y_train)\n    \n    valid_pred = lr.predict(x_valid)\n    test_pred = lr.predict(test_1)\n    \n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)\n    scores.append(score)\n    \n    print(f'Fold:- {fold+1} Score:- {score}')\n    print('--'*25)\n\nprint(f'final score {np.mean(scores)}')\n\nfinal_pred =  np.mean(test_preds,axis =0)","f8c40f9f":"#creating submission file\nsubmission = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')\nsubmission['song_popularity'] = final_pred\nsubmission.to_csv('submission.csv',index = False)\nsubmission","b97f422a":"### lgbmregressor","e83cd19c":"## final_estimator","7f6a31ea":"### catboostregressor","0767bbb5":"# data read and preprocessing","f6347a94":"### xgboostregressor","1b4cc03b":"### linear_regression","1771d3f9":"# final submission","50daacb9":"# Stacking","ab287e2a":"### random_forest"}}