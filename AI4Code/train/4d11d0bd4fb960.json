{"cell_type":{"72cddfa0":"code","7e895f61":"code","76602bc9":"code","162e0b97":"code","b7357edf":"code","127419c0":"code","96790241":"code","5933b296":"code","32f05ced":"code","10439b7f":"code","26d321ca":"markdown","7bac5fa1":"markdown","0b700037":"markdown","3874d4df":"markdown","5ab9cde5":"markdown","29095b46":"markdown","33af6607":"markdown","6aedc354":"markdown","69c50bef":"markdown"},"source":{"72cddfa0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_colwidth', -1) \n\ndf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\n\n# feature columns\nprint(df.columns)\n\n# feature distribution\ndf.describe()","7e895f61":"df.corrwith(df.Class).plot.bar(title='corr with class', x= 'feature', y='corr (pearson)', grid=True, fontsize=12, rot=30, figsize=(15, 4))","76602bc9":"import seaborn as sn\nsn.set_style('white')\nf, ax = plt.subplots(figsize=(7, 7))\nmask = np.zeros_like(df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\ncmap = sn.diverging_palette(220, 10, as_cmap=True)\nsn.heatmap(df.corr(), mask=mask, cmap=\"YlGnBu\", vmax=.5, square=True)","162e0b97":"feature_cols = np.array(df.columns)\nfeature_cols = feature_cols[~np.isin(feature_cols, ['Class', 'Time', 'Amount'])]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf[feature_cols] = scaler.fit_transform(df[feature_cols])\n\ndf[feature_cols].describe()","b7357edf":"# blank values\ndf.isna().sum()","127419c0":"# oversampling a less represented group\ndf[df.Class == 1].shape\ndf = df.append([df[df.Class == 1]]*10, ignore_index=True)\ndf[df.Class == 1].shape","96790241":"# split train test\nX = df.iloc[:, df.columns.isin(feature_cols)]\ny = df.iloc[:, df.columns == 'Class']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","5933b296":"import tensorflow as tf\nfrom tensorflow.keras import Model, Sequential, backend as K\nfrom tensorflow.keras.layers import Input, Dense, Dropout\n\ninp = Input(shape=(len(X.columns),))\ndense_1 = Dense(100, activation='relu')(inp)\ndense_2 = Dense(50, activation='relu')(dense_1)\ndense_3 = Dense(100, activation='relu')(dense_2)\nout = Dense(1, activation='sigmoid')(dense_3)\nmodel = Model(inp, out)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, batch_size=200, epochs=500, verbose=0)\nscore = model.evaluate(X_test, y_test)","32f05ced":"y_pred = model.predict(X_test)\ny_pred = y_pred > 0.5\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, index=('Non-Fraud (Actual)', 'Fraud (Actual)'), columns=('Non-Fraud (Predicted)', 'Fraud (Predicted)'))\nsn.set_style('white')\nplt.figure(figsize = (7,7))\nsn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\")\nprint(df_cm)","10439b7f":"print(\"Backtest Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","26d321ca":"# Train Model\n\nPrior to modelling, I am going to split data into train by 80% and test by 20%.","7bac5fa1":"In the aforementioned matrix, you can understand the followings:\n* The model correctly classified 1096 transactions as fraud, while incorrectly 15 as non-fraud. (Percentage error = 1.36%)\n* The model correctly classified 56850 transactions as non-fraud, while incorrectly 25 as fraud. (Percentage error = 0.043%)","0b700037":"After pearson correlation matrix calculated, at a glance I can see there is no dominant feature over others in relation to if a transaction is fradulent. Note that last feature in x-axis is a column that indicates a fradulent one.","3874d4df":"# Backtest\n\nThe predictive model should be tested on historical data, and the predictions can be compared with the actual results to understand error rate. As part of backtesting, we predict with test data and compare its results with the actual. The results are visualised with confusion matrix which allows us to check 100% accurate prediction results as well as false-positive \/ true-negative ones at once.","5ab9cde5":"Quickly checking if there is any empty values.","29095b46":"The model that I uses is a feedforward neural network which doesn't have a cycle to update a model backward, and I am going to intentionally create a bottleneck in a architecture to reduce representation with less nodes then reconstruct back, so called an autoencoder. This helps to summarise representation in a model and better understand dominant events.","33af6607":"# Feature Scailing\n\nThe description table above shows that there are features in large scale - we are going to address them so as to be in similar scale. The normalisation is not only good for fast convergence performance during training but also contributes to precise convergence.","6aedc354":"# Credit Card Fraud Detection\n\nA fradulent transaction is the result of identity theft and involves the use of your debit or credit card for charges that a customer did not authorise. It is important that credit card companies are able to recognise fradulent credit card transactions so that customers are not charged for items that they did not purchase. The fradulent transaction is not only financial crime which can risk a company's reputation and trust with customers, but also results in inconvenicence for customers to dispute those transactions or potentially financial loss.\n\nIn this sense, it is fortunate that data scientists can help to detect abnormal transactions using machine learning, especially this project uses feedforward neural network. This network is the simplest type of neural network devised and the input information moves in only one direction, forward, from the input nodes through hidden nodes and to the output nodes. There are no cycles to give feedback backward unlike recurrent neural netoworks.\n\n![Feedforward Neural Network](https:\/\/ds055uzetaobb.cloudfront.net\/brioche\/uploads\/uzLXsnBLTI-fully_connected_mlp.png?width=1200)\n\n\n# EDA\n\nThe datasets contain transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occured in two days, where we have 492 frauds out of 284,807 transactiosn. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. Due to confidentiality issues, the original features are masked as V1,V2,...V28. The column 'Class' indicate if a transaction is fradulent as boolean. \n\nLooking at feature distributions below, I can find scales are within similar ranges for most of features. But, there are some to be addressed.","69c50bef":"# Oversampling\n\nThe fraudaulent transactions only takes 0.172% of total transactions in dataset, which results in unbalanced datasets. For that reason, I decide to ovesample a less represented group by replicating them in dataframe. Replicating by 10 times, the amount will be nearly 2% in total.\nIt is still not that much considering total but will see how it plays in a result."}}