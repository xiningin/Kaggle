{"cell_type":{"483d0881":"code","005395db":"code","f09ac283":"code","14ee2d1d":"code","e331e597":"code","e82dceaa":"code","a42b6fec":"code","ab402298":"code","cd653761":"code","64b15db0":"code","48ebd1c5":"code","4d7b824a":"code","cd943e01":"code","a0bb72cd":"code","50806b91":"code","a27b280d":"code","663544d2":"code","610640a9":"code","b9d1b26a":"markdown","5fc256c2":"markdown","8f9f3341":"markdown","e7375e05":"markdown","1d31ef33":"markdown","07248f14":"markdown","3dbcf753":"markdown","e0444f58":"markdown","eb5045c0":"markdown"},"source":{"483d0881":"!pip install autoviml","005395db":"import pandas as pd\nimport numpy as np","f09ac283":"data = pd.read_csv('..\/input\/twitter-sentiment-analysis\/train_2.csv')\n","14ee2d1d":"data.head()","e331e597":"from sklearn.model_selection import train_test_split\n\nfrom autoviml.Auto_NLP import Auto_NLP\n\ntrain, test = train_test_split(data, test_size=0.2)","e82dceaa":"input_feature, target = \"tweet\", \"label\"","a42b6fec":"train_x, test_x, final, predicted= Auto_NLP(input_feature, train, test,target,\n                                            score_type=\"balanced_accuracy\",\n                                            top_num_features=500,\n                                            modeltype=\"Classification\",\n                                            verbose=2,\n                                            build_model=True)","ab402298":"final.predict(test_x[input_feature])","cd653761":"testing = pd.read_csv('..\/input\/twitter-sentiment-analysis\/test_2.csv')","64b15db0":"final.predict(testing[input_feature])","48ebd1c5":"prediction = pd.read_csv('..\/input\/twitter-sentiment-analysis\/test_2.csv')","4d7b824a":"prediction['label'] = final.predict(testing[input_feature])","cd943e01":"prediction.to_csv('prediction.csv',index = False)","a0bb72cd":"final_prediction=prediction.copy()\nfinal_prediction['Prediction'] = prediction['label']\nfinal_prediction","50806b91":"Ground_truth=testing.copy()\nGround_truth['Ground_truth']=testing['label']\nGround_truth","a27b280d":"col = pd.DataFrame(final_prediction, columns=['tweet'])\ncol1 = pd.DataFrame(final_prediction, columns=['Prediction'])\ncol2 = pd.DataFrame(Ground_truth, columns=['Ground_truth'])\n\nresults = pd.concat([col,col1 , col2], axis=1)\nresults.to_csv('results.csv', index=False)\nresults","663544d2":"# The confusion matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nCM = confusion_matrix(results['Ground_truth'], results['Prediction'])\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(CM, annot=True, linewidth=0.7, linecolor='magenta', fmt='g', ax=ax, cmap=\"YlGnBu\")\nplt.title('Classification Confusion Matrix')\nplt.xlabel('Y predict')\nplt.ylabel('Y test')\nplt.show()","610640a9":"#importing confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(results['Ground_truth'], results['Prediction'])\nprint('Confusion Matrix\\n')\nprint(confusion)\n\n#importing accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(results['Ground_truth'], results['Prediction'])))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(results['Ground_truth'], results['Prediction'], average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(results['Ground_truth'], results['Prediction'], average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(results['Ground_truth'], results['Prediction'], average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(results['Ground_truth'], results['Prediction'], average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(results['Ground_truth'], results['Prediction'], average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(results['Ground_truth'], results['Prediction'], average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(results['Ground_truth'], results['Prediction'], average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(results['Ground_truth'], results['Prediction'], average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(results['Ground_truth'], results['Prediction'], average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(results['Ground_truth'], results['Prediction'], target_names=['Class 1', 'Class 2']))","b9d1b26a":"## 3. Usage\n","5fc256c2":"## 6. Prediction","8f9f3341":"## 5. Run AutoNLP\n","e7375e05":"# Reference :\n\n* https:\/\/github.com\/AutoViML\/Auto_ViML","1d31ef33":"## 1. Install autoviml","07248f14":"# Case Study","3dbcf753":"# What is AutoNLP?\n\n\n\n![image.png](attachment:d5b47a9b-73e2-4b62-b032-4e461b322c4a.png)\n\nAutoNLP is very similar to AutoML, it automates the process of EDA and text processing and helps data scientists to get the best model. AutoNLP is a function present in the AutoViML framework, built using scikit-learn, NumPy, pandas, and matplotlib. It is designed to build high-performance interpretable models with the fewest variables.\n\nAutoNLP guides a data scientist in:\n* Exploratory data analysis of text\n* Data Cleaning\n* Feature reduction\n* Variable Classification\n* Produces model performance results as graphs\n* Can easily handle text, date-time, structs, numeric, boolean, factor, and categorical variables\n* Allows use the featuretools library to do Feature Engineering\n\n```\nfrom autoviml.feature_engineering import feature_engineering\nprint(df[preds].shape)\ndfmod = feature_engineering(df[preds],['add'],'ID')\nprint(dfmod.shape)\n```\n\n","e0444f58":"## 2. Loading data\n","eb5045c0":"## 4. Specifying the Response and Predictor variables\n"}}