{"cell_type":{"966ff2c5":"code","337ea4ce":"code","73174772":"code","181ee332":"code","0b2ac4e5":"code","908a1ddb":"code","d4379d6f":"markdown","45d676b8":"markdown","158477ae":"markdown","87f4f8dd":"markdown","4c5436d6":"markdown","c3f06e1c":"markdown","3e53cb9a":"markdown","b3f0f901":"markdown"},"source":{"966ff2c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","337ea4ce":"train_filepath = '..\/input\/house-prices-data\/train.csv'\ntest_filepath = '..\/input\/house-prices-data\/test.csv'\n\ntrain_data = pd.read_csv(train_filepath, index_col='Id', parse_dates=True)\ntest_data = pd.read_csv(test_filepath, index_col='Id', parse_dates=True)","73174772":"# Select features\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n\n# Remove null columns\ntrain_data.dropna(axis=1, inplace=True)\n\ny = train_data.SalePrice\nX = train_data[features]\n\nX_test = test_data[features]\n\n# Inspect columns\nprint(f'Columns: {list(X.columns)}\\n')\n\n# Perform train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)","181ee332":"def get_mae_DTR(max_leaf_nodes, X_train, X_valid, y_train, y_valid):\n    '''\n    This function returns the mean absolute error for a given max_leaf_node,\n    using the DecisionTreeRegressor as the estimator.\n    '''\n    \n    # Define model type\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=2)\n    \n    # Train the model using training data\n    model.fit(X_train, y_train)\n    \n    # Predict values for validation and test\n    preds_y_valid = model.predict(X_valid)\n    \n    # Calculate mean absolute error\n    return (mean_absolute_error(preds_y_valid, y_valid))","0b2ac4e5":"%matplotlib inline\n\n# Generate a range from 0 to 500, with intervals of 1\nleaf_node_range = range(2, 501)\n\n# Calculate the mean_absolute_error for the validation data\nvalid_mae = [get_mae_DTR(num_leaf_nodes, X_train, X_valid, y_train, y_valid) for num_leaf_nodes in leaf_node_range]\n\n# Convert data into a pd.DataFrame\nresults = pd.DataFrame({'leaf_node': leaf_node_range,\n                       'valid_mae': valid_mae})\n\nprint(f\"Min. mean absolute error: {results['valid_mae'].min()}\\nMax. leaf nodes: {results['valid_mae'].idxmin()}\")\n\n# Plot the graph\nsns.lineplot(x='leaf_node', y='valid_mae', data=results, label='Validation')\nsns.set_style('whitegrid')\nsns.regplot(x=[results['valid_mae'].idxmin()], y=[results['valid_mae'].min()], label=f\"({results['valid_mae'].idxmin()}, {results['valid_mae'].min():.0f})\")\nplt.title('Mean absolute error against max. leaf nodes')\nplt.xlabel('Mean absolute error')\nplt.ylabel('Maximum leaf nodes')\nplt.legend()\nplt.show()","908a1ddb":"def get_mae_RFR(n_estimators, max_depth, X_train, X_valid, y_train, y_valid):\n    '''\n    This function returns the mean absolute error for a given max_leaf_node,\n    using the RandomForestRegressor as the estimator.\n    '''\n    \n    # Define model type\n    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=1)\n    \n    # Train the model using training data\n    model.fit(X_train, y_train)\n    \n    # Predict values for validation and test\n    preds_y_valid = model.predict(X_valid)\n    \n    # Calculate mean absolute error\n    return (mean_absolute_error(preds_y_valid, y_valid))","d4379d6f":"## Step 4: Test hyper-parameters","45d676b8":"## Useful pd.DataFrame and pd.Series methods\n```\npd.DataFrame\n    \u251c\u2500\u2500 to_csv(index_col==['colName'], parse_dates)\n    \u251c\u2500\u2500 select_dtypes(exclude=['dtype'], include=['dtype'])\n    \u251c\u2500\u2500 drop(['colName'], axis)\n    \u251c\u2500\u2500 dropna(axis)\n    \u251c\u2500\u2500 fillna(value\/method)\n    \u251c\u2500\u2500 isnull\n    \u2514\u2500\u2500 notnull \n```","158477ae":"## Step 5: Test ensemble model","87f4f8dd":"## Step 3: Build model and define model error","4c5436d6":"From the graph, the optimal number of leaf nodes is 46.","c3f06e1c":"## Step 1: Extract data to DataFrame (and explore data).","3e53cb9a":"## Step 2: Separate training and validation data","b3f0f901":"# Introduction to Machine Learning\n\nThe aim of this notebook is to practice running through the whole workflow for a introductory machine learning model.\n\n## Steps\n\n1. Extract data to DataFrame\n2. Split training and validation data\n3. Define function to calculate model error\n4. Experiment with hyper-parameters\n\n## Model components:\n```\n  sklearn\n    \u251c\u2500\u2500 tree\n    \u2502   \u2514\u2500\u2500 DecisionTreeRegressor\n    \u251c\u2500\u2500 metrics\n    \u2502   \u2514\u2500\u2500 mean_absolute_error\n    \u251c\u2500\u2500 model_selection\n    \u2502   \u2514\u2500\u2500 train_test_split\n    \u2514\u2500\u2500 ensemble\n        \u2514\u2500\u2500 RandomForestRegressor\n\nhttps:\/\/tree.nathanfriend.io\/?s=(%27opt0s!(%27fancy!true~fullPat2~trailingSlas2)~3(%273%27sklearn*tree4Decis0Tree.metrics4mean_absolute_error*model_select04train_test_split*ensemble4RandomForest.%27)~vers0!%271%27)*%5Cn--%20%20.Regressor*0ion2h!false3source!4*-%014320.-*\n```"}}