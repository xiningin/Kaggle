{"cell_type":{"e04de32c":"code","c1b9e2ec":"code","1df3ad11":"code","321bb737":"code","26529816":"code","e2d89547":"code","e7d95433":"code","2412397c":"code","40c64345":"markdown"},"source":{"e04de32c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # Seaborn for data visualization\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1b9e2ec":"# Load the data\ndf = pd.read_csv('..\/input\/spotify-music-data-to-identify-the-moods\/data_moods.csv')\ndf","1df3ad11":"# Checking null value in dataset\ndf.isnull().sum()","321bb737":"# Visualize number of data point for each class\nsns.countplot(df['mood'])","26529816":"# Feature engineering\nX = df.loc[:, 'popularity':'time_signature']\nX['length'] = X['length']\/max(X['length'])\n\n# Mapping class label to respected integer\ny = df['mood'].map({'Happy': 0, 'Sad': 1, 'Energetic': 2, 'Calm':3})\ntarget_names = ['Happy', 'Sad', 'Energetic', 'Calm']","e2d89547":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","e7d95433":"# Splitting training data and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","2412397c":"models = []\nmodels.append(('Random Forest Classifier',RandomForestClassifier()))\nmodels.append(('Gradient Boosting Classifier',GradientBoostingClassifier()))\nmodels.append(('XGB Classifier', XGBClassifier()))\nmodels.append(('Decision Tree Classifier', DecisionTreeClassifier()))\nmodels.append(('LGBM Classifier', LGBMClassifier()))\nmodels.append(('Support Vector Classifier', SVC()))\nmodels.append(('KNN Classifier', KNeighborsClassifier()))\n\nfor name, model in models:\n    model.fit(X_train, y_train)\n\n    predictions = model.predict(X_test)\n    accuracy = accuracy_score(predictions, y_test)\n\n    print('Accuracy for {} : {:3.3f}\\nClassification Report for {} : \\n{}'.format(name, accuracy_score(predictions, y_test), name, classification_report(predictions, y_test, target_names=target_names)))","40c64345":"# Data Preparation"}}