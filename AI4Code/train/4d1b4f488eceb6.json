{"cell_type":{"66615f0c":"code","2083a8e5":"code","608672c7":"code","7a700c92":"code","bcc339e1":"code","21b43e0b":"code","67c08c73":"code","e9ef5d26":"code","69aca39d":"code","465143b7":"code","e9d2862f":"code","c5c64dad":"code","e0c0c61b":"code","14960eb4":"code","0bec08c8":"code","90ef0ce4":"code","e9bd795b":"code","dfedb677":"code","fa351e0e":"code","eecca190":"code","0c1b84a8":"code","359312bf":"code","c26edddc":"code","3e529333":"code","c87327c7":"code","01e41c45":"code","695fa397":"code","5a0842fe":"code","a50598e8":"code","39cc4872":"code","0c2b97ad":"code","b2d1ba84":"code","2eea3e54":"code","a30ef6a9":"code","368415fd":"code","69b090e9":"code","e1122daf":"code","a77aabfb":"code","9a0aa08b":"code","7f4ddd0a":"code","99b63df7":"code","5bd997cb":"code","a86ec7bd":"code","e2fff8fe":"code","82e8b4e8":"code","f2238929":"code","5d6afbe0":"code","14fb88ad":"code","fc0158ca":"code","defe9707":"code","fd0e0b43":"code","ce124e4b":"code","36f5667b":"code","d61ec645":"code","0454f885":"code","a5238a82":"code","1ba5e07f":"code","3979a16b":"code","d20f5350":"code","0dd10106":"code","df18c529":"code","dd6bd51f":"code","ecfaa0e6":"code","bd543d08":"code","fca12499":"code","40e18138":"code","2e126539":"code","081cd891":"code","ad5ff01a":"code","7f3dd154":"code","0ffbbb93":"markdown","595d1de2":"markdown","fc2654c0":"markdown","9ca095f2":"markdown","3ebfb7c0":"markdown","919c20bf":"markdown","a8d0ee17":"markdown","7aad91d6":"markdown","9f93a60c":"markdown","768a6f7c":"markdown","604f7323":"markdown","a8b10935":"markdown","6758e1bd":"markdown","ce023307":"markdown","b6255158":"markdown","b36cc452":"markdown","c1d7dc85":"markdown","bfea1efa":"markdown","7b4ac116":"markdown","470bf599":"markdown","454fb820":"markdown","8eac9435":"markdown","375f92cb":"markdown","c2b0126d":"markdown","430faefb":"markdown","1a287a06":"markdown","abf45ba3":"markdown","4e9443d4":"markdown","3b4c2d7d":"markdown","1c2e518e":"markdown","3b13fed7":"markdown","7156a2ca":"markdown","bd1399f3":"markdown","4070bc33":"markdown","45452dce":"markdown","6d2a9304":"markdown","a425eafc":"markdown","342a9928":"markdown","166df860":"markdown","ace2f5d6":"markdown","014b5257":"markdown","dda1b14a":"markdown","f8fa5efa":"markdown","5c41ceb8":"markdown","d8cc8f3f":"markdown","f7f42f0e":"markdown","9c466f12":"markdown","e595caa4":"markdown","1a4ff271":"markdown","3db2fbec":"markdown","114f3088":"markdown","8204fe2a":"markdown","777c9b19":"markdown","27d5d53b":"markdown"},"source":{"66615f0c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sc\nimport matplotlib as mpl","2083a8e5":"import itertools","608672c7":"import warnings\nwarnings.filterwarnings('ignore')","7a700c92":"data = pd.read_csv('..\/input\/ulabox_orders_with_categories_partials_2017.csv')","bcc339e1":"data.head()","21b43e0b":"data.describe()","67c08c73":"data[data['discount%']<0].sort_values(by='discount%', ascending=True).head(10)","e9ef5d26":"indices = [56,2459,908,23632,1803,218,592,349]\ndata.iloc[indices, :]","69aca39d":"df = data.drop(['customer', 'order', 'hour'], axis=1)\nframe = data","465143b7":"from sklearn.decomposition import PCA","e9d2862f":"pca = PCA(n_components=11)\npca.fit(df.values)","c5c64dad":"def pca_2d_plot(pca, df):\n    fig = plt.figure(figsize=(10,10))\n    transformed_data = pca.transform(df.values)\n    data = pd.DataFrame(transformed_data, columns=['dim'+str(i) for i in range(1,12)])\n    sns.lmplot(x='dim1', y='dim2', data=data, size=12, fit_reg=False, scatter_kws={'s':8});\n    sns.lmplot(x='dim3', y='dim4', data=data, size=12, fit_reg=False, scatter_kws={'s':8});\n    plt.show()","e0c0c61b":"pca_2d_plot(pca, df)","14960eb4":"figure = plt.figure(figsize=(20,20))\nsns.pairplot(df);\nplt.show()","0bec08c8":"fig = plt.figure(figsize=(16,12))\nsns.distplot(df['total_items']);\nplt.show()","90ef0ce4":"df['total_items'] = np.log(df['total_items'])\nfig = plt.figure(figsize=(16,12))\nsns.distplot(df['total_items']);\nplt.show()","e9bd795b":"def turkey_outlier_detector(df, cols=None):\n    if cols  is None:\n        cols = [str(s) for s in df.describe().columns]\n        \n    q1 = {}\n    q3 = {}\n    iqd = {}\n    r_limit = {}\n    l_limit = {}\n    outlier_count = {}\n    outlier_indices = {}\n    for col in cols:\n        q1[col] = np.percentile(df[col].values, 25)\n        q3[col] = np.percentile(df[col].values, 75)\n        iqd[col] = q3[col] - q1[col]\n        r_limit[col] = q3[col] + 1.5*iqd[col]\n        l_limit[col] = q1[col] - 1.5*iqd[col]\n        data_outlier = df[~((df[col]<r_limit[col]).multiply(df[col]>l_limit[col]))]\n        outlier_count[col] = data_outlier.shape[0]\n        outlier_indices[col] = data_outlier.index\n        \n    for col in cols:\n        print('_'*25)\n        print(col+'-'*8+'>'+str(outlier_count[col]))\n        \n    return outlier_indices","dfedb677":"outlier_indices = turkey_outlier_detector(df)","fa351e0e":"df.drop(outlier_indices['total_items'], inplace=True)","eecca190":"frame.drop(outlier_indices['total_items'], inplace=True)","0c1b84a8":"from sklearn.cluster import KMeans","359312bf":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","c26edddc":"X = scaler.fit_transform(df.values)","3e529333":"clusters = range(3,31)\ninertia = []\nfor n in clusters:\n    kmeans = KMeans(n_clusters=n)\n    kmeans.fit(X)\n    inertia.append(kmeans.inertia_)\n    \nfig, ax = plt.subplots(figsize=(10,8))\nax.plot(clusters, inertia);\nplt.show()","c87327c7":"def plot_silhoutte_score(X, max_clusters=20):\n    from sklearn.cluster import KMeans\n    from sklearn.metrics import silhouette_score\n    num_clusters = range(2,max_clusters+1)\n    sil_score = []\n    for n in num_clusters:\n        kmeans = KMeans(n_clusters=n)\n        kmeans.fit(X)\n        preds = kmeans.predict(X)\n        sil_score.append(silhouette_score(X, preds))\n        \n    fig, ax = plt.subplots(figsize=(12,12))\n    ax.plot(num_clusters, sil_score)\n    plt.show()","01e41c45":"plot_silhoutte_score(X,30)","695fa397":"def under_partition_measure(X, k_max):\n    from sklearn.cluster import KMeans\n    ks = range(1,k_max+1)\n    UPM = []\n    for k in ks:\n        kmeans = KMeans(n_clusters=k)\n        kmeans.fit(X)\n        UPM.append(kmeans.inertia_)\n    return UPM","5a0842fe":"def over_partition_measure(X, k_max):\n    from sklearn.cluster import KMeans\n    from sklearn.metrics.pairwise import  pairwise_distances\n    ks = range(1,k_max+1)\n    OPM = []\n    for k in ks:\n        kmeans = KMeans(n_clusters=k)\n        kmeans.fit(X)\n        centers = kmeans.cluster_centers_\n        d_min = np.inf\n        for pair in list(itertools.combinations(centers, 2)):\n            d = pairwise_distances(pair[0].reshape(1,-1), pair[1].reshape(1,-1), metric='euclidean')\n            if d<d_min:\n                d_min = d\n        OPM.append(k\/d_min)\n    return OPM","a50598e8":"def validity_index(X, k_max):\n    UPM = under_partition_measure(X, k_max)\n    OPM = over_partition_measure(X, k_max)\n    UPM_min = np.min(UPM)\n    OPM_min = np.min(OPM)\n    UPM_max = np.max(UPM)\n    OPM_max = np.max(OPM)\n    norm_UPM = []\n    norm_OPM = []\n    for i in range(k_max):\n        norm_UPM.append((UPM[i]-UPM_min)\/(UPM_max-UPM_min))\n        norm_OPM.append((OPM[i]-OPM_min)\/(OPM_max-OPM_min))\n        \n    validity_index = np.array(norm_UPM)+np.array(norm_OPM)\n    fig, ax = plt.subplots(figsize=(12,12))\n    ax.plot(range(1,k_max+1), validity_index)\n    return validity_index","39cc4872":"_ = validity_index(X, 30)","0c2b97ad":"kmeans_10 = KMeans(n_clusters=10, random_state=42)\nkmeans_10.fit(X)\nframe['labels'] = kmeans_10.predict(X)","b2d1ba84":"frame[frame['labels']==0].head(10)","2eea3e54":"frame[frame['labels']==0].describe()","a30ef6a9":"frame.loc[frame['labels']==0, 'class'] = 'drink_buyers'","368415fd":"frame[frame['labels']==1].head(10)","69b090e9":"frame[frame['labels']==1].describe()","e1122daf":"frame.loc[frame['labels']==1, 'class'] = 'loyals_fresh'","a77aabfb":"frame[frame['labels']==2].head(10)","9a0aa08b":"frame[frame['labels']==2].describe()","7f4ddd0a":"frame.loc[frame['labels']==2, 'class'] = 'loyals_grocery'","99b63df7":"frame[frame['labels']==3].head(10)","5bd997cb":"frame[frame['labels']==3].describe()","a86ec7bd":"frame.loc[frame['labels']==3, 'class'] = 'beauty_concious'","e2fff8fe":"frame[frame['labels']==4].head(10)","82e8b4e8":"frame[frame['labels']==4].describe()","f2238929":"frame.loc[frame['labels']==4, 'class'] = 'health_concious'","5d6afbe0":"frame[frame['labels']==5].head(10)","14fb88ad":"frame[frame['labels']==5].describe()","fc0158ca":"frame.loc[frame['labels']==5, 'class'] = 'loyals'","defe9707":"frame[frame['labels']==6].head(10)","fd0e0b43":"frame[frame['labels']==6].describe()","ce124e4b":"frame.loc[frame['labels']==6, 'class'] = 'grocery_shoppers'","36f5667b":"frame[frame['labels']==7].head(10)","d61ec645":"frame[frame['labels']==7].describe()","0454f885":"frame.loc[frame['labels']==7, 'class'] = 'home_decorators'","a5238a82":"frame[frame['labels']==8].head(10)","1ba5e07f":"frame[frame['labels']==8].describe()","3979a16b":"frame.loc[frame['labels']==8, 'class'] = 'pet_lovers'","d20f5350":"frame[frame['labels']==9].head(10)","0dd10106":"frame[frame['labels']==9].describe()","df18c529":"frame.loc[frame['labels']==9, 'class'] = 'new_parents'","dd6bd51f":"def pca_2d_plot_labels(pca, df, frame):\n    plt.figure(figsize=(18,18));\n    transformed_data = pca.transform(df.values)\n    data = pd.DataFrame({'dim1':transformed_data[:,0], 'dim2':transformed_data[:,1], 'labels':frame['class'].values})\n    sns.lmplot(x='dim1',y='dim2',hue='labels',data=data, fit_reg=False, size=16);\n    data1 = pd.DataFrame({'dim2':transformed_data[:,1], 'dim3':transformed_data[:,2], 'labels':frame['class'].values})\n    sns.lmplot(x='dim2',y='dim3',hue='labels',data=data1, fit_reg=False, size=16);\n    plt.show()","ecfaa0e6":"pca_2d_plot_labels(pca, df, frame)","bd543d08":"frame.groupby('class')['total_items'].describe()","fca12499":"frame.groupby('class')['discount%'].describe()","40e18138":"frame['class'].value_counts().sort_values(ascending=False)","2e126539":"plt.figure(figsize=(9,9))\nframe['class'].value_counts().sort_values(ascending=False).plot.pie(autopct='%1.0f%%', labels=list(frame['class'].value_counts().sort_values(ascending=False).index))\nplt.show()","081cd891":"plt.figure(figsize=(9,9))\nframe[frame['discount%']<0]['class'].value_counts().sort_values(ascending=False).plot.pie(autopct='%1.0f%%', labels=frame[frame['discount%']<0]['class'].value_counts().sort_values(ascending=False).index)\nplt.show()","ad5ff01a":"frame[(frame['discount%']<0).multiply(frame['class']!='drink_buyers')].describe()","7f3dd154":"frame[frame['discount%']<0].shape[0]","0ffbbb93":"This distribution is skewed negatively, let's apply a log transformation.","595d1de2":"-> These are again very loyal customers who depend on ulabox for a lot of things.<br>\n-> They tend to buy grocery a little more, let's call them loyals grocery.","fc2654c0":"-> According to Turkey method a point is an outlier if it lies 1.5 times inter quartile distance to the right of third quartile or if it lies 1.5 times inter quartile distance to the left of first quartile.<br>\n-> For more info refer: https:\/\/en.wikipedia.org\/wiki\/Outlier","9ca095f2":"## 6) Are there clusters in the data, how many clusters?","3ebfb7c0":"-> Only 124 among 30k had to pay an extra charge, that's not a pain killer problem.","919c20bf":"#### Elbow Method","a8d0ee17":"-> From the 2d plot we see that clusters are nicely separated in space.","7aad91d6":"### 1) Importing required libraries and data","9f93a60c":"### 5) Outlier detection","768a6f7c":"The same has been implemented in the following functions.","604f7323":"-> The first method we are going to try is the elbow method.<br>\n-> In this method we plot the sum of distances of all the data points to the correspoding cluster centeroids vs number of clusters, for a range of number of clusters.<br>\n-> If there is a elbow in the plot the point at which elbow occured is the number of clusters present in the data.<br>\n-> We are lucky if we see an elbow in the plot, but in most cases the plot will just be smooth revealing no information about the number of clusters.<br>","a8b10935":"-> total_items is skewed, applying a log transformation will help the clustering.<br>\n-> when discount% increases total_items icreases which makes sense, people will buy more on discount.<br>\n-> below the 0 discount line only Drinks% has non zero percentage entries. Food%, Fresh% etc. have only zero percentage entries in negative discount area.<br>\n-> it makes sense that the plots in the right bottom are bound by the line x+y = 100, as the data is actually in percentage x+y <= 100.<br>\n-> the distribution plots are more and more skewed as we move towards the right bottom, as pet products, baby products and health products are brought by very less people.","6758e1bd":"### 2) Simple visualization","ce023307":"### Validity Index","b6255158":"-> 56 order seems to depend on ulabox for grocery, fresh food and drinks. <br>\n-> 2459 and 908 order seems to depend on ulabox for everything, probably most valuable customers. <br>\n-> 23632 order seems to buy a lot of drinks from ulabox in spite of the negative discount, which implies extra charges.<br>\n-> 1803 buys a lot of pet products, the order must be by a pet lover. <br>\n-> 218 buys a lot of home decoratory accessories. <br>\n-> 592 must be a woman, who would like her beauty products, to be delivered by ulabox at her door.<br>\n-> 349 seems to be parents, who newly had a baby.","b36cc452":"#### Turkey Outlier Detection","c1d7dc85":"##### Topics explored in the notebook","bfea1efa":"-> The customers who have placed orders on grocery have been seen to enjoy a lot of discount, may be there was a stock clearance sale or a promotional sale ulabox.","7b4ac116":"This again gives us a surety that, there are around 10 clusters.","470bf599":"All our analysis so far suggests there could be around 10 clusters in the data, let's now manually examine and try to interpret the meaning of these clusters.","454fb820":"-> These are the class of people who have ordered drinks a lot.<br>\n-> These people had to face a lot of extra charges for drink purchases.<br>\n-> They are potential customers, as we all know drinks can be addictive atleast in a teeny tiny level.","8eac9435":"1. customer is the unique customer id. <br>\n2. order is the unique order id. <br>\n3. total_items is the number of products bought in the order. <br>\n4. discount% is the amount of discount provided during the purchase, the negative values in discount stands for extra amount the customer paid to ulabox as delivery charge or any other mode of fee. <br>\n5. weekday is the day of the week in which the order was placed.<br>\n6. hour is the time in which the order is placed. <br>\n7. Food% is the amount of money spent on non fresh food in the purchase, it may include grocery products like sugar, coffee  powder, oats etc.<br>\n8. Fresh% is the amount of money spent on fresh food like milk, fruits, vegetables etc.<br>\n9. Drinks% is most probably the percentage of amount spent on alchohol like wine, vodka, scotch etc. There is a teeny tiny chance that these also include soft drinks.<br>\n10. Home% is the percentage of money spent in home accessories.<br>\n11. Beauty% is the percentage of amount spent in beauty products<br>\n12. Health% is the percentage of amount spent in medicine or health products like protein supplement, carb supplement etc.<br>\n13. Baby% is the percentage spent in baby products.<br>\n14. Pets% is the percentage spent in pet products like pedigree.","375f92cb":"Let's try and do pca of the features and see the explained variance and plots","c2b0126d":"Let's remove customer, order and hour features from the data","430faefb":"-> This is the class of people who had bought a lot of health products, let's call them health concious people","1a287a06":"-> Theese customers buy a lot of beauty products.<br>\n-> They also buy considerable amount of grocery and drinks.<br>\n-> Probably woman who shop for home.","abf45ba3":"We got lucky! There is somewhere around 10 clusters in the data.","4e9443d4":"#### Silhoutte Score","3b4c2d7d":"1) Importing required libraries and data<br>\n2) Simple visualization of the data and few  samples<br>\n3) Visualisation via pca and pairplot<br>\n4) Checking for dependent variables<br>\n5) Outlier detection and handling<br>\n6) Cluster analysis: Are there clusters, how many?<br>\n7) Clustering and interpretation<br>\n8) Deriving conclusions","1c2e518e":"-> These class of people have brought baby products a lot.<br>\n-> They must be couple with new babies, let's call them new parents.","3b13fed7":"This function accepts pca object and data frame as arguements and plots the scatter plot of first four principal components.","7156a2ca":"There may not be any relevant information in the hour in which the order was placed, but the weekday in which the order was placed may reveal some information about weekend buyers. Hece let's keep it.","bd1399f3":"-> This should be the class of orders that buy a lot of home utility products like floor cleaner, curtains, washing powder etc.<br>\n-> Let's call this people home decorators.","4070bc33":"### 7) Clustering and interpretation","45452dce":"That was nicely interpretable!","6d2a9304":"Now let's plot the pairplots and see the variations and distributions of features with respect to each other.","a425eafc":"-> The variation of total_items with class is not very sound, all classes of orders have similar number of total item counts.","342a9928":"In this notebook, we try to segment customers into different categories based on their purchasing behaviour. Conclusions from customer segmentation can give us bussiness insights and strategies. Feel free to fork the complete project here: https:\/\/github.com\/Hari365\/customer-segmentation-python. Which has a segmentation based on customers rather than just orders. There's also a model which classifies the customers based on purchasing behaviour.","166df860":"-> These customers buy all kinds of products from ulabox, fresh, drinks and food dominnantly.<br>\n-> These are the loyal customers of ulabox who depends on ulabox for everything. <br>\n-> Let's call them loyals. <br>","ace2f5d6":"That's better","014b5257":"-> This is the class of pet lovers, that's obvious from the data we see","dda1b14a":"-> When the number of clusters is less than the correct number of clusters then the data is under partitioned, if the number of clusters is more than the correct number of clusters then the data is over partitioned.<br>\n-> Sum of distances from the data points to the corresponding cluster centers is a measure of under partition.<br>\n-> Number of clusters devided by minimum distance between two clusters is a measure of over partition, it increases when the data is more over partitioned.<br>\n-> A normalized sum of these two can help finding the actual number of clusters.<br>\n-> This idea is published in this paper:http:\/\/armi.kaist.ac.kr\/korean\/files\/_2001______________________a_novel_validity_index_for_determination_of_the_optimal_number_of_clutters_.pdf","f8fa5efa":"This function takes df as an arguement and columns for which outlier detection has to be done, as an optional arguement. It returns a dictionary whose keys are column names and elements are indices of outlier points in the corresponding columns. It also prints the number of outliers in every column.","5c41ceb8":"### 3) Visualization via pca and pairplot","d8cc8f3f":"#### Selecting samples","f7f42f0e":"-> From the table we can say, even the people in other clusters who had to pay a negative discount have brought a lot drinks.<br>","9c466f12":"-> Our hypothesised loyal costomers are placed at the top when it comes to number of orders.<br>\n-> Our next hypothesis of drink buyers being potential customers is also subtantiated.<br>\n-> Pet lovers are very less in number, ulabox should buy less pet products accordingly.<br>\n-> When seeing the large discount enjoyed by grocery shoppers in the previous data frame and the less number of grocery shoppers here. They are supposedly customers who brought only on the discount sale.<br>\n-> ulabox can actually frame their buying strategies according to these numbers.<br>","e595caa4":"-> This class of orders buy a lot of Food, Fresh and Drinks. With Fresh being more dominant.<br>\n-> These orders might be a little valuable, as these orders cover Food%, Fresh%, Drinnks%, Home%.","1a4ff271":"-> The outliers in Health% and Pets% are due to the fact that, lot people don't buy these products and the entries are mostly 0.<br>\n-> The outliers in Food%, Fresh% etc. are due to the 0% and 100% entries which is a completely natural phenomenon in this scenerio.<br>\n-> The outliers in discount% is also due to 0% and 100% entries.<br>\n-> For these features let's acknoledge the fact that there are outliers and leave it there.<br>\n-> Let's remove the outliers in total_items.","3db2fbec":"### 8) Deriving Conclusions","114f3088":"-> a(i) is the sum of the sum of distances of the ith data point to the other data points in it's cluster.<br>\n-> Calculate the sum of distance of ith data point to the points in every other cluster.<br>\n-> b(i) is the sum of distances from ith data point to all points in a cluster, for which sum of distances is munimum.<br>\n-> silhoutte score, s(i) = 1-a(i)\/b(i)<br>\n-> If a data point is more similar to it's own cluster and very much different from other clusters, then \na(i)<<b(i), greater will be the silhoutte score.<br>\n-> The silhoutte score we plot is the average of it over all the data points.<br>","8204fe2a":"-> drinks% and negative discount are highly correlated, may be the company imposed a lot of inconvenience and transport charges on drinks.","777c9b19":"We plot number of clusters vs silhoutte score, the silhoutte score hits it's maximum at around 10 clusters.","27d5d53b":"-> This class of customers seem to buy non fresh food a lot, let's call them grocery shoppers.<br>\n-> These are probably monthly regular shopppers of the company."}}