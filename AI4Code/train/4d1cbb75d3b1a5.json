{"cell_type":{"dd90d922":"code","61e23dd6":"code","302b5e6e":"code","bfd8c9a2":"code","7efd4025":"code","a7ec58fd":"code","ab0eab07":"code","bbd6a5f7":"code","6461ffef":"code","7298c189":"code","ffa37b62":"code","6cf1a5df":"code","590b1fdd":"code","7a77bf6d":"code","4227f0de":"code","e8a0d6df":"code","c39d8f36":"code","6cc70511":"code","c63bd57a":"markdown","85517939":"markdown","ec33c5fd":"markdown","9a6649a2":"markdown","dfad3309":"markdown","a8901b05":"markdown","a34267b8":"markdown","02ec1c74":"markdown","b0312eac":"markdown","73d2132f":"markdown"},"source":{"dd90d922":"# loading libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom IPython.display import display\nfrom sklearn.tree import export_graphviz\nimport pydotplus\nimport random","61e23dd6":"# loading training data\ndf_clean = pd.read_csv('..\/input\/ALL_LEAGUESx90.csv', encoding=\"ISO-8859-1\", sep = ',')\ndf_clean['League'] = df_clean['League'].str.replace(\" \",\"\") #remove spaces\ndf_clean['Age now']= df_clean['Age now'] + 1 # Needed to uptdate the age since scraping took place in 2017\ndf_clean.iloc[0:5,:]","302b5e6e":"df_clean.shape","bfd8c9a2":"df_clean = df_clean[df_clean.Ratingf1 != 0]\ndf_clean = df_clean[df_clean.Mins > 1500]\n\nfig, axes = plt.subplots(ncols=2, figsize = (12,5))\nplt.subplot(1, 2, 1)\nboxplot = df_clean.boxplot(column='Ratingf1');\nplt.title('Boxplot of t+1 rating')\nplt.subplot(1, 2, 2)\ndf_clean.Classf1.hist();\nplt.title('Distribution of t+1 classes')\nplt.show()","7efd4025":"df_clean.Ratingf1.quantile([0.25,0.5,0.75,0.9])\n#All of this to classify the players based on their rating (done in excel)","a7ec58fd":"df_clean = df_clean[(df_clean.Position1 == \"F\")|(df_clean.Position2 == \"F\")|(df_clean.Position3 == \"F\")]\ndf_clean.shape\n# This is the dimension of the sample of strikers I'll use","ab0eab07":"# create design matrix X and target vector y\nX = np.array(df_clean.iloc[:,7:87])\ny1 = np.array(df_clean['Classf1'])\n\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(max_depth=8, random_state=0)\n\nclf.fit(X, y1)\nprint(\"Features sorted by their score:\")\nprint(sorted(zip(map(lambda x: round(x, 3), clf.feature_importances_),\n                 list(df_clean.iloc[:,7:87])), reverse=True))","bbd6a5f7":"dot_data = StringIO()\nexport_graphviz(clf, out_file=dot_data, \n                feature_names=list(df_clean.iloc[:,7:87]),\n                class_names=['top10%','top25%','top50%','top75%','bottom25%'],\n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ni = Image(graph.create_png())\ndisplay(i)\n# Double click on the tree to zoom in !","6461ffef":"print(\"The ratio of the correctly predicted data points to all the predicted data points is:\") \nprint(round(clf.score(X,y1),3))","7298c189":"df = pd.read_csv('..\/input\/ALL_LEAGUESx90.csv', encoding=\"ISO-8859-1\", sep = ',')\ndf = df[(df.Position1 == \"F\")|(df.Position2 == \"F\")|(df.Position3 == \"F\")]\ndf17 = df[df.Year == 17]\ndf17 = df17[df17.Mins>1500]\ndf17['League'] = df17['League'].str.replace(\" \",\"\") #remove spaces\ndf17['Age now']= df17['Age now'] + 1 # Needed to update the age","ffa37b62":"X_17 = np.array(df17.iloc[:,7:87])\npred = clf.predict(X_17)\nout_18 = pd.DataFrame({'Player':np.array(df17.iloc[:,0]),'Age':np.array(df17.iloc[:,1]),'Rating_17':np.array(df17.iloc[:,88]),'Predicted_performance':pred})\nout_18 = out_18.sort_values(by=['Predicted_performance'])","6cf1a5df":"fig, axes = plt.subplots(ncols=2, figsize = (12,5))\nplt.subplot(1, 2, 1)\nout_18.Predicted_performance.hist();\nplt.title('Distribution of predicted classes in 2017-2018')\nplt.subplot(1, 2, 2)\ndf_clean.Classf1.hist();\nplt.title('Distribution of classes in my sample')\nplt.show()","590b1fdd":"best18 = out_18[(out_18.Predicted_performance == 1)&(out_18.Rating_17 < 715)&(out_18.Age < 30)]\nbest18 = best18.iloc[:,0:3]\nbest18.iloc[:,:]","7a77bf6d":"### Checking what happened in 2017-2018:\n\n# I first import the dataset with 2017-2018 data and clean the data as before:\ndf_actual = pd.read_csv('..\/input\/ALL_LEAGUESx90_18.csv', encoding=\"ISO-8859-1\", sep = ',')\ndf_actual = df_actual[df_actual['Position1'].str.contains(\"F\")]\n\n# I now match the supposed talents with their real observation:\nsearchfor = best18['Player'].str[:11]\nbest18_actual = df_actual[df_actual['Player'].str.contains('|'.join(searchfor))]\nbest18_actual = best18_actual.iloc[:,[0,6,88]]\nout = best18.merge(best18_actual, how='outer')\nout = out.sort_values(by=['Player'])\nout['Player']= np.where(out['Year'] != 18, out['Player'] + \" (2017)\", out['Player']) \nout.rename(columns={'Rating': 'Rating_18'}, inplace=True)\nout.iloc[:,[0,1,2,4]]","4227f0de":"print(\"My group have average Rating in 2018:\",round(best18_actual[\"Rating\"].mean()))","e8a0d6df":"# Counterfactual: How good is my prediction actually?\n# a) I keep only the players who are 'reasonable' candidates:\nsubsample = df17[(df17['Rating'] > 650)&(df17.Rating < 715)&(df17['Age now'] < 30)]\n# b) Randomly getting 17 out of these gives us average Rating in 2018 of : \ntest18 = subsample.sample(n=17)\nsearchfor = test18['Player'].str[:12]\ntest18_actual = df_actual[df_actual['Player'].str.contains('|'.join(searchfor))]\ntest18_actual.iloc[:,[0,6,88]]\nprint(\"The random sample has average Rating in 2018:\",round(test18_actual[\"Rating\"].mean()))","c39d8f36":"# Cleaning the data:\ndf_actual = df_actual[df_actual.Mins>1500];\ndf_actual['League'] = df_actual['League'].str.replace(\" \",\"\") #remove spaces\n# Potential future talents, from least likely to most likely based on their 2017-2018 rating:\nX_18 = np.array(df_actual.iloc[:,7:87])\npred = clf.predict(X_18)\nout_19 = pd.DataFrame({'Player':np.array(df_actual.iloc[:,0]),'Age':np.array(df_actual.iloc[:,1]),'Rating_18':np.array(df_actual.iloc[:,88]),'Predicted_performance':pred})\nout_19 = out_19.sort_values(by=['Rating_18'])\nbest19 = out_19[(out_19.Predicted_performance == 1)&(out_19.Rating_18 < 715)&(out_19.Age < 30)]\nbest19.iloc[:,[0,1,2]]","6cc70511":"fig, axes = plt.subplots(ncols=2, figsize = (12,5))\nplt.subplot(1, 2, 1)\nout_19.Predicted_performance.hist();\nplt.title('Distribution of predicted classes in 2018-2019')\nplt.subplot(1, 2, 2)\ndf_clean.Classf1.hist();\nplt.title('Distribution of classes in my sample')\nplt.show()","c63bd57a":"As you can see here, the dataset is quite rich. I now keep only the strikers who have played more than 1500 minutes over the season and for whom I can match performance with the following season's rating (i.e. where Ratingf1 exists). \nLet's look at the distribution of Ratingf1:","85517939":"**6. CONCLUSION**\n\nThank you for taking the time to read through my first decision tree! I look forward to your thoughts, advice and suggestions.","ec33c5fd":"**3. DECISION TREE**\n\nI use the DecisionTreeClassifier from the sklearn package to fit my data. I chose to have 8 levels because 7 drops the performance significantly and 9 doesn't increase it much. I'd love to hear what you guys think of this.","9a6649a2":"To check how good my prediction actually is, I randomly select the same number of players and compare the groups' average rating:","dfad3309":"I filter to select the players with high potential, and *voil\u00e0!*","a8901b05":"**2. DATA PRESENTATION**\n\nEach row of my dataset represents the performance of a player over a specific season. All measures (except for Rating & Rank) are *per 90 minutes*.\n\nRank is on a League and season basis, and stems from the Rating. Rating is on a scale from 0 to 1000.\n\nRatingf1 and Ratingf2 link the player's performance to his Rating respectively one and two seasons later (done in Excel).\n\nClassf1 (also done in Excel) categorizes the players from their Rating percentile: 1 is for top 10% players, 2 for top 25% players, 3 for top 50% players, 4 for top 75% players and 5 for the bottom 25%.","a34267b8":"**5. FORECASTING THE 2018-2019 TALENTS**\n\nUsing the same decision tree, I use the 2017-2018 data to forecast the high potential players of the incoming season:","02ec1c74":"**1. INTRODUCTION**\n\nI've had for about a year now data on football performance of all players in the 5 'Big Leagues' (i.e. England, Spain, Italy, Germany & France) between 2009-2010 and 2016-2017 and I decided to try to fit a decision tree on the data and see how much I can predict future success. \n\nI focus for now on strikers, which appear to be much more homogeneous in terms of performance. \n\nMy goal is to find a way to predict which players are 'relatively' under the radar and become rated in the top 10% of their league the following season.\n\nI will first present my data, then map a decision tree to link period *t+1* rating with period *t* performance. I follow this by a concrete example of what my data predicts as the best 2018 strikers, and link this result to actual performance data. I finally wrap this up by forecasting the 2019 talents.\n\nPlease do comment and point me towards improvements !","b0312eac":"**4.  FORECASTING THE 2017-2018 TALENTS AND PERFORMANCE ANALYSIS**\n\nUsing the decision tree fitted on players from 2009-2010 to 2016-2017, I forecast which strikers are expected to shine in 2017-2018. My goal is to find players which are expected to be in the top 10% of their league in 2017-2018 but who were in 2016-2017 rated below 715 (i.e. *relatively* under the radar) and under 30. \n\nI then match this list of players with the players' actual performance and compare my sample to a randomly selected sample of the same size.","73d2132f":"Although my group average is well below the top 10% target (730), it seems like I am still picking up on valid characteristics and that the players do on average, ceteris paribus, very well. \n\nI encourage you to look into the disapointing players, and you'll often find interesting stories (e.g. Carrasco moved to China and Diony to Bristol after just a few months of the season)."}}