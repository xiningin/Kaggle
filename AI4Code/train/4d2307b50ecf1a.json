{"cell_type":{"9eab97a9":"code","bbc8979c":"code","82e8b5df":"code","e8a98091":"code","3adc4238":"code","ed8e0cec":"code","11b864a1":"code","8840c400":"code","cec27eae":"code","3d940755":"code","ab3ebb9e":"code","337052b2":"code","1e5183e6":"markdown","f97a2ef2":"markdown","b4e3f03c":"markdown","620be4ec":"markdown","d250452f":"markdown","24f3f8cf":"markdown","487f2291":"markdown","118e7272":"markdown","47363118":"markdown","a6a9500e":"markdown","cfbce112":"markdown"},"source":{"9eab97a9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport glob \n\nimport os\nprint('-------------------------')\nprint('all files:')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint('-------------------------')\n\ndata_foldername = '\/kaggle\/input\/bigger-is-better\/'\nall_filenames = glob.glob(os.path.join(data_foldername, '*.pickle'))\n\nprint('-------------------------')\nprint('files inside folder \"%s\":' %(data_foldername))\nfor k, filename in enumerate(all_filenames):\n    print('%3d: %s' %(k + 1, filename.split('\/')[-1]))\nprint('-------------------------')\n","bbc8979c":"teachers_folder = '..\/input\/bigger-is-better\/'\nfilename = 'FCN_LReLU_05_gauss_IO_norm_init__I-DxW-O__10-3x8-1__n_models_42__n_inits_30_fanin__n_iter_1200__seed_1234.pickle'\n\nteacher_filename = os.path.join(teachers_folder, filename)\n\nwith open(teacher_filename, \"rb\") as f:\n    teacher_training_results = pickle.load(f)\n    \nGT_model_name = teacher_filename.split('\/')[-1].split('__n_models')[0]\n\nprint('-----------------------------')\nprint('GT model name: \"%s\"' %(GT_model_name))\nprint('-----------------------------')\n\nprint('-----------------------------')\nall_model_names = list(teacher_training_results.keys())\nprint('all student model names:')\nfor model_name in all_model_names:\n    print('  ' + model_name)\nprint('-----------------------------')","82e8b5df":"\ndef get_learning_curves(teacher_filename, student_model_name, valid_index=1, percent_var_remaining=False):\n    with open(teacher_filename, \"rb\") as f:\n        teacher_training_results = pickle.load(f)\n        \n    student_model_results = teacher_training_results[student_model_name]\n\n    valid_loss = 'valid_%d_loss' %(valid_index)\n    valid_key = 'valid_%d' %(valid_index)\n    \n    # collect all learning curves for the same model in the same matrix\n    learning_curves = np.zeros((len(student_model_results['all learning curves']), student_model_results['all learning curves'][0][valid_loss].shape[0]))\n    for k, curr_learning_curves in enumerate(student_model_results['all learning curves']):\n        learning_curves[k, :] = curr_learning_curves[valid_loss]\n\n    training_steps = student_model_results['all learning curves'][0]['num_batches']\n\n    if percent_var_remaining:\n        baseline_mse = student_model_results['model_hyperparams_dict']['y_GT_stats_dict'][valid_key]['mse_0']\n        learning_curves = 100 * learning_curves \/ baseline_mse\n        \n    return training_steps, learning_curves\n\n\ndef get_baseline_mse(teacher_filename, student_model_name, valid_index=1):\n    with open(teacher_filename, \"rb\") as f:\n        teacher_training_results = pickle.load(f)\n        \n    student_model_results = teacher_training_results[student_model_name]\n    valid_key = 'valid_%d' %(valid_index)\n    baseline_mse = student_model_results['model_hyperparams_dict']['y_GT_stats_dict'][valid_key]['mse_0']\n\n    return baseline_mse\n\ndef get_student_depth_x_width(student_model_name):\n    \n    nn_depth = int(student_model_name.split('_stu')[0].split('DxW_')[-1].split('x')[0])\n    nn_width = int(student_model_name.split('_stu')[0].split('DxW_')[-1].split('x')[-1])\n    \n    return nn_depth, nn_width\n\n\ndef teacher_filename_from_depth_x_width_seed(depth, width, seed, teachers_folder='..\/input\/bigger-is-better\/glorot_uniform_init\/'):\n    teacher_filename = 'FCN_LReLU_05_gauss_IO_norm_init__I-DxW-O__10-%dx%d-1__n_models_42__n_inits_30_fanin__n_iter_1200__seed_%d.pickle' %(depth, width, seed)\n    return os.path.join(teachers_folder, teacher_filename)\n\n\ndef student_name_from_depth_x_width(depth, width):\n    return 'FCN_DxW_%dx%d_student' %(depth, width)\n","e8a98091":"teacher_depths = [1,3,5]\nteacher_widths = [16,16,16]\nteacher_seeds  = [1234, 1234, 1234]\nteacher_colors = ['green', 'orange', 'red']\n\nrequested_valid_index = 1\nrequested_train_step = 1200\nshow_percent_remaining = True\ndepth_lims = [1,32]\nwidth_lims = [1,256]\n\nshow_best = True\nshow_error_bars = False\n\nall_student_model_names = list(teacher_training_results.keys())\nall_short_student_model_names = [x.split('_stu')[0] for x in all_student_model_names]\n\n# filter the student models to display\ninds_to_keep = []\nfor k, student_model_name in enumerate(all_student_model_names):\n    nn_depth, nn_width = get_student_depth_x_width(student_model_name)\n    depth_OK = nn_depth >= depth_lims[0] and nn_depth <= depth_lims[1]\n    width_OK = nn_width >= width_lims[0] and nn_width <= width_lims[1]\n\n    if depth_OK and width_OK:\n        inds_to_keep.append(k)\n\nall_student_model_names       = [all_student_model_names[k] for k in inds_to_keep]\nall_short_student_model_names = [all_short_student_model_names[k] for k in inds_to_keep]\n\nbar_plot_x_axis = 1.0 * np.arange(len(all_short_student_model_names))\nbar_widths = 0.85 \/ len(teacher_depths)\n\n\nteacher_filename = teacher_filename_from_depth_x_width_seed(teacher_depths[0], teacher_widths[0], teacher_seeds[0], teachers_folder=teachers_folder)\nstudent_model_name = all_student_model_names[0]\n\ntraining_steps, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\ntraining_step_ind = np.argmin(np.abs(training_steps - requested_train_step))\nrequested_train_step_corrected = training_steps[training_step_ind]\n\n# extract all necessary results (for all teachers)\nvalues_dict = {}\nfor (t_depth, t_width, t_seed) in zip(teacher_depths, teacher_widths, teacher_seeds):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    depth_list = []\n    width_list = []\n\n    result_mean = []\n    result_std = []\n    result_best = []\n    result_80th_percentile = []\n\n    for student_model_name in all_student_model_names:\n        _, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\n        result_vec = learning_curves[:,training_step_ind]\n\n        depth_list.append(nn_depth)\n        width_list.append(nn_width)\n        result_mean.append(result_vec.mean())\n        result_std.append(result_vec.std())\n        result_best.append(result_vec.min())\n        result_80th_percentile.append(np.percentile(result_vec, 80))\n\n    result_mean = np.array(result_mean)\n    result_std = np.array(result_std)\n    result_best = np.array(result_best)\n    result_80th_percentile = np.array(result_80th_percentile)\n\n    values_dict[teacher_filename] = {}\n    values_dict[teacher_filename]['result_mean'] = result_mean\n    values_dict[teacher_filename]['result_std'] = result_std    \n    values_dict[teacher_filename]['result_best'] = result_best    \n    values_dict[teacher_filename]['result_80th_percentile'] = result_80th_percentile    \n    values_dict[teacher_filename]['baseline_mse'] = get_baseline_mse(teacher_filename, student_model_name, valid_index=requested_valid_index)    \n\n\n# display the figure\nplt.figure(figsize=(25,24));\nplt.subplots_adjust(left=0.06, bottom=0.06, right=0.94, top=0.96, hspace=0.33, wspace=0.1)\nplt.suptitle('%s \"valid_%d\" fitting patterns for various teachers' %('best' if show_best else 'mean', requested_valid_index), fontsize=24)\n\nplt.subplot(2,1,1);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_80th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%)', fontsize=24)\nplt.legend(fontsize=24)\n\n\nplt.subplot(2,1,2);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_80th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%) (log scale)', fontsize=24)\nplt.yscale('log')\nplt.legend(fontsize=24);\n","3adc4238":"teacher_depths = [4,4,4]\nteacher_widths = [4,10,16]\nteacher_seeds  = [1234, 1234, 1234]\nteacher_colors = ['green', 'orange', 'red']\n\nrequested_valid_index = 1\nrequested_train_step = 1200\nshow_percent_remaining = True\ndepth_lims = [1,32]\nwidth_lims = [1,256]\n\nshow_best = False\nshow_error_bars = False\n\nall_student_model_names = list(teacher_training_results.keys())\nall_short_student_model_names = [x.split('_stu')[0] for x in all_student_model_names]\n\n# filter the student models to display\ninds_to_keep = []\nfor k, student_model_name in enumerate(all_student_model_names):\n    nn_depth, nn_width = get_student_depth_x_width(student_model_name)\n    depth_OK = nn_depth >= depth_lims[0] and nn_depth <= depth_lims[1]\n    width_OK = nn_width >= width_lims[0] and nn_width <= width_lims[1]\n\n    if depth_OK and width_OK:\n        inds_to_keep.append(k)\n\nall_student_model_names       = [all_student_model_names[k] for k in inds_to_keep]\nall_short_student_model_names = [all_short_student_model_names[k] for k in inds_to_keep]\n\nbar_plot_x_axis = 1.0 * np.arange(len(all_short_student_model_names))\nbar_widths = 0.85 \/ len(teacher_depths)\n\n\nteacher_filename = teacher_filename_from_depth_x_width_seed(teacher_depths[0], teacher_widths[0], teacher_seeds[0], teachers_folder=teachers_folder)\nstudent_model_name = all_student_model_names[0]\n\ntraining_steps, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\ntraining_step_ind = np.argmin(np.abs(training_steps - requested_train_step))\nrequested_train_step_corrected = training_steps[training_step_ind]\n\n# extract all necessary results (for all teachers)\nvalues_dict = {}\nfor (t_depth, t_width, t_seed) in zip(teacher_depths, teacher_widths, teacher_seeds):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    depth_list = []\n    width_list = []\n\n    result_mean = []\n    result_std = []\n    result_best = []\n    result_80th_percentile = []\n\n    for student_model_name in all_student_model_names:\n        _, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\n        result_vec = learning_curves[:,training_step_ind]\n\n        depth_list.append(nn_depth)\n        width_list.append(nn_width)\n        result_mean.append(result_vec.mean())\n        result_std.append(result_vec.std())\n        result_best.append(result_vec.min())\n        result_80th_percentile.append(np.percentile(result_vec, 80))\n\n    result_mean = np.array(result_mean)\n    result_std = np.array(result_std)\n    result_best = np.array(result_best)\n    result_80th_percentile = np.array(result_80th_percentile)\n\n    values_dict[teacher_filename] = {}\n    values_dict[teacher_filename]['result_mean'] = result_mean\n    values_dict[teacher_filename]['result_std'] = result_std    \n    values_dict[teacher_filename]['result_best'] = result_best    \n    values_dict[teacher_filename]['result_80th_percentile'] = result_80th_percentile    \n    values_dict[teacher_filename]['baseline_mse'] = get_baseline_mse(teacher_filename, student_model_name, valid_index=requested_valid_index)    \n\n\n# display the figure\nplt.figure(figsize=(25,24));\nplt.subplots_adjust(left=0.06, bottom=0.06, right=0.94, top=0.96, hspace=0.33, wspace=0.1)\nplt.suptitle('%s \"valid_%d\" fitting patterns for various teachers' %('best' if show_best else 'mean', requested_valid_index), fontsize=24)\n\nplt.subplot(2,1,1);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_90th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%)', fontsize=24)\nplt.legend(fontsize=24)\n\n\nplt.subplot(2,1,2);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_90th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%) (log scale)', fontsize=24)\nplt.yscale('log')\nplt.legend(fontsize=24);\n","ed8e0cec":"teacher_depths = [1,3,8]\nteacher_widths = [4,8,16]\nteacher_seeds  = [1234, 1234, 1234]\nteacher_colors = ['green', 'orange', 'red']\n\n\nrequested_valid_index = 1\nrequested_train_step = 1200\nshow_percent_remaining = True\ndepth_lims = [1,32]\nwidth_lims = [1,256]\n\nshow_best = False\nshow_error_bars = False\n\nall_student_model_names = list(teacher_training_results.keys())\nall_short_student_model_names = [x.split('_stu')[0] for x in all_student_model_names]\n\n# filter the student models to display\ninds_to_keep = []\nfor k, student_model_name in enumerate(all_student_model_names):\n    nn_depth, nn_width = get_student_depth_x_width(student_model_name)\n    depth_OK = nn_depth >= depth_lims[0] and nn_depth <= depth_lims[1]\n    width_OK = nn_width >= width_lims[0] and nn_width <= width_lims[1]\n\n    if depth_OK and width_OK:\n        inds_to_keep.append(k)\n\nall_student_model_names       = [all_student_model_names[k] for k in inds_to_keep]\nall_short_student_model_names = [all_short_student_model_names[k] for k in inds_to_keep]\n\nbar_plot_x_axis = 1.0 * np.arange(len(all_short_student_model_names))\nbar_widths = 0.85 \/ len(teacher_depths)\n\n\nteacher_filename = teacher_filename_from_depth_x_width_seed(teacher_depths[0], teacher_widths[0], teacher_seeds[0], teachers_folder=teachers_folder)\nstudent_model_name = all_student_model_names[0]\n\ntraining_steps, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\ntraining_step_ind = np.argmin(np.abs(training_steps - requested_train_step))\nrequested_train_step_corrected = training_steps[training_step_ind]\n\n# extract all necessary results (for all teachers)\nvalues_dict = {}\nfor (t_depth, t_width, t_seed) in zip(teacher_depths, teacher_widths, teacher_seeds):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    depth_list = []\n    width_list = []\n\n    result_mean = []\n    result_std = []\n    result_best = []\n    result_80th_percentile = []\n\n    for student_model_name in all_student_model_names:\n        _, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\n        result_vec = learning_curves[:,training_step_ind]\n\n        depth_list.append(nn_depth)\n        width_list.append(nn_width)\n        result_mean.append(result_vec.mean())\n        result_std.append(result_vec.std())\n        result_best.append(result_vec.min())\n        result_80th_percentile.append(np.percentile(result_vec, 80))\n\n    result_mean = np.array(result_mean)\n    result_std = np.array(result_std)\n    result_best = np.array(result_best)\n    result_80th_percentile = np.array(result_80th_percentile)\n\n    values_dict[teacher_filename] = {}\n    values_dict[teacher_filename]['result_mean'] = result_mean\n    values_dict[teacher_filename]['result_std'] = result_std    \n    values_dict[teacher_filename]['result_best'] = result_best    \n    values_dict[teacher_filename]['result_80th_percentile'] = result_80th_percentile    \n    values_dict[teacher_filename]['baseline_mse'] = get_baseline_mse(teacher_filename, student_model_name, valid_index=requested_valid_index)    \n\n\n# display the figure\nplt.figure(figsize=(25,24));\nplt.subplots_adjust(left=0.06, bottom=0.06, right=0.94, top=0.96, hspace=0.33, wspace=0.1)\nplt.suptitle('%s \"valid_%d\" fitting patterns for various teachers' %('best' if show_best else 'mean', requested_valid_index), fontsize=24)\n\nplt.subplot(2,1,1);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_90th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%)', fontsize=24)\nplt.legend(fontsize=24)\n\n\nplt.subplot(2,1,2);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_90th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%) (log scale)', fontsize=24)\nplt.yscale('log')\nplt.legend(fontsize=24);\n","11b864a1":"#teacher_depths = [3, 3, 3, 3]\n#teacher_widths = [8, 8, 8, 8]\n\n#teacher_depths = [3, 3, 3, 3]\n#teacher_widths = [12, 12, 12, 12]\n\n#teacher_depths = [5, 5, 5, 5]\n#teacher_widths = [8, 8, 8, 8]\n\n#teacher_depths = [5, 5, 5, 5]\n#teacher_widths = [16, 16, 16, 16]\n\nteacher_depths = [8, 8, 8, 8]\nteacher_widths = [16, 16, 16, 16]\n\nteacher_seeds  = [1234, 4321, 1111, 1357]\nteacher_colors = ['green', 'limegreen', 'deepskyblue', 'orange', 'peru', 'red']\n\n\nrequested_valid_index = 1\nrequested_train_step = 1200\nshow_percent_remaining = True\ndepth_lims = [1,32]\nwidth_lims = [1,256]\n\nshow_best = False\nshow_error_bars = False\n\nall_student_model_names = list(teacher_training_results.keys())\nall_short_student_model_names = [x.split('_stu')[0] for x in all_student_model_names]\n\n# filter the student models to display\ninds_to_keep = []\nfor k, student_model_name in enumerate(all_student_model_names):\n    nn_depth, nn_width = get_student_depth_x_width(student_model_name)\n    depth_OK = nn_depth >= depth_lims[0] and nn_depth <= depth_lims[1]\n    width_OK = nn_width >= width_lims[0] and nn_width <= width_lims[1]\n\n    if depth_OK and width_OK:\n        inds_to_keep.append(k)\n\nall_student_model_names       = [all_student_model_names[k] for k in inds_to_keep]\nall_short_student_model_names = [all_short_student_model_names[k] for k in inds_to_keep]\n\nbar_plot_x_axis = 1.0 * np.arange(len(all_short_student_model_names))\nbar_widths = 0.85 \/ len(teacher_depths)\n\n\nteacher_filename = teacher_filename_from_depth_x_width_seed(teacher_depths[0], teacher_widths[0], teacher_seeds[0], teachers_folder=teachers_folder)\nstudent_model_name = all_student_model_names[0]\n\ntraining_steps, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\ntraining_step_ind = np.argmin(np.abs(training_steps - requested_train_step))\nrequested_train_step_corrected = training_steps[training_step_ind]\n\n# extract all necessary results (for all teachers)\nvalues_dict = {}\nfor (t_depth, t_width, t_seed) in zip(teacher_depths, teacher_widths, teacher_seeds):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    depth_list = []\n    width_list = []\n\n    result_mean = []\n    result_std = []\n    result_best = []\n    result_80th_percentile = []\n\n    for student_model_name in all_student_model_names:\n        _, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=requested_valid_index, percent_var_remaining=show_percent_remaining)\n        result_vec = learning_curves[:,training_step_ind]\n\n        depth_list.append(nn_depth)\n        width_list.append(nn_width)\n        result_mean.append(result_vec.mean())\n        result_std.append(result_vec.std())\n        result_best.append(result_vec.min())\n        result_80th_percentile.append(np.percentile(result_vec, 80))\n\n    result_mean = np.array(result_mean)\n    result_std = np.array(result_std)\n    result_best = np.array(result_best)\n    result_80th_percentile = np.array(result_80th_percentile)\n\n    values_dict[teacher_filename] = {}\n    values_dict[teacher_filename]['result_mean'] = result_mean\n    values_dict[teacher_filename]['result_std'] = result_std    \n    values_dict[teacher_filename]['result_best'] = result_best    \n    values_dict[teacher_filename]['result_80th_percentile'] = result_80th_percentile    \n    values_dict[teacher_filename]['baseline_mse'] = get_baseline_mse(teacher_filename, student_model_name, valid_index=requested_valid_index)    \n\n\n# display the figure\nplt.figure(figsize=(25,24));\nplt.subplots_adjust(left=0.06, bottom=0.06, right=0.94, top=0.96, hspace=0.33, wspace=0.1)\nplt.suptitle('%s \"valid_%d\" fitting patterns for various teachers' %('best' if show_best else 'mean', requested_valid_index), fontsize=24)\n\nplt.subplot(2,1,1);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_90th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%)', fontsize=24)\nplt.legend(fontsize=24)\n\n\nplt.subplot(2,1,2);\nfor k, (t_depth, t_width, t_seed) in enumerate(zip(teacher_depths, teacher_widths, teacher_seeds)):\n    teacher_filename = teacher_filename_from_depth_x_width_seed(t_depth, t_width, t_seed, teachers_folder=teachers_folder)\n\n    curr_result_mean            = values_dict[teacher_filename]['result_mean']    \n    curr_result_std             = values_dict[teacher_filename]['result_std']\n    curr_result_best            = values_dict[teacher_filename]['result_best']    \n    curr_result_80th_percentile = values_dict[teacher_filename]['result_80th_percentile']\n    t_baseline_mse              = values_dict[teacher_filename]['baseline_mse']\n    \n    curr_label = 'FCN_DxW__%dx%d__seed_%d (baseline_mse = %.4f)' %(t_depth, t_width, t_seed, t_baseline_mse)\n\n    if show_best:\n        result_zeros = np.zeros(curr_result_90th_percentile.shape)\n        y = curr_result_best\n        y_err = [result_zeros, curr_result_80th_percentile - curr_result_best]\n    else:\n        y = curr_result_best\n        y_err = curr_result_std\n    \n    if show_error_bars:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, yerr=y_err, color=teacher_colors[k], label=curr_label)\n    else:\n        plt.bar(bar_plot_x_axis + k * bar_widths, y, bar_widths, color=teacher_colors[k], label=curr_label)\n        \nplt.xticks(bar_plot_x_axis + bar_widths, all_short_student_model_names, rotation=90, fontsize=18);\nplt.ylabel('variance remaining (%) (log scale)', fontsize=24)\nplt.yscale('log')\nplt.legend(fontsize=24);\n","8840c400":"\ndef get_all_fitting_patterns(data_foldername, return_mean=True, requested_train_step=1200):\n    \n    all_full_filenames = glob.glob(os.path.join(data_foldername, '*.pickle'))\n    all_filenames = sorted([filename.split('\/')[-1].split('.p')[0] for filename in all_full_filenames])\n    num_rows = len(all_full_filenames)\n    \n    # build teacher_df\n    teacher_df = pd.DataFrame(index=range(num_rows), columns=['depth','width','init_method','seed'])\n    for k, filename in enumerate(all_filenames):\n        \n        curr_depth = int(filename.split('-O__')[-1].split('__n_models')[0].split('-')[1].split('x')[0])\n        curr_width = int(filename.split('-O__')[-1].split('__n_models')[0].split('-')[1].split('x')[1])\n        curr_seed  = int(filename.split('seed_')[-1])\n        curr_init  = filename.split('_init__')[0].split('LReLU_05_')[-1]\n        \n        teacher_df.loc[k,'depth'] = curr_depth\n        teacher_df.loc[k,'width'] = curr_width\n        teacher_df.loc[k,'seed'] = curr_seed\n        teacher_df.loc[k,'init_method'] = curr_init\n        \n    \n    # build all results dfs\n    with open(all_full_filenames[0], \"rb\") as f:\n        teacher_training_results = pickle.load(f)\n\n    all_student_model_names = list(teacher_training_results.keys())\n    all_short_student_model_names = [x.split('_stu')[0] for x in all_student_model_names]\n        \n    fitting_pattern_mean_df = pd.DataFrame(index=range(num_rows), columns=all_short_student_model_names)\n    fitting_pattern_std_df  = pd.DataFrame(index=range(num_rows), columns=all_short_student_model_names)\n    \n    fitting_pattern_best_df            = pd.DataFrame(index=range(num_rows), columns=all_short_student_model_names)\n    fitting_pattern_median_df          = pd.DataFrame(index=range(num_rows), columns=all_short_student_model_names)\n    fitting_pattern_80th_percentile_df = pd.DataFrame(index=range(num_rows), columns=all_short_student_model_names)\n    \n    training_steps, learning_curves = get_learning_curves(all_full_filenames[0], all_student_model_names[0], valid_index=1, percent_var_remaining=True)\n    training_step_ind = np.argmin(np.abs(training_steps - requested_train_step))\n    for k, teacher_filename in enumerate(all_full_filenames):\n        result_mean = []\n        result_std  = []\n        result_best            = []\n        result_median          = []\n        result_80th_percentile = []\n\n        for student_model_name in all_student_model_names:\n            _, learning_curves = get_learning_curves(teacher_filename, student_model_name, valid_index=1, percent_var_remaining=True)\n            result_vec = learning_curves[:,training_step_ind]\n\n            result_mean.append(result_vec.mean())\n            result_std.append(result_vec.std())\n            result_best.append(result_vec.min())\n            result_median.append(np.percentile(result_vec, 50))\n            result_80th_percentile.append(np.percentile(result_vec, 80))\n\n        fitting_pattern_mean_df.loc[k,:] = np.array(result_mean)\n        fitting_pattern_std_df.loc[k,:]  = np.array(result_std)\n        fitting_pattern_best_df.loc[k,:]            = np.array(result_best)\n        fitting_pattern_median_df.loc[k,:]          = np.array(result_median)\n        fitting_pattern_80th_percentile_df.loc[k,:] = np.array(result_80th_percentile)\n\n    if return_mean:\n        return teacher_df, fitting_pattern_mean_df, fitting_pattern_std_df\n    else:\n        return teacher_df, fitting_pattern_best_df, fitting_pattern_median_df, fitting_pattern_80th_percentile_df\n","cec27eae":"teacher_df, fitting_pattern_mean_df, fitting_pattern_std_df = get_all_fitting_patterns(data_foldername, return_mean=True)\n\nteacher_df, fitting_pattern_best_df, fitting_pattern_median_df, fitting_pattern_80th_percentile_df = get_all_fitting_patterns(data_foldername, return_mean=False)","3d940755":"plt.figure(figsize=(25,30));\nplt.subplots_adjust(left=0.06, bottom=0.14, right=0.94, top=0.96, hspace=0.12, wspace=0.1)\n\nall_short_student_model_names = fitting_pattern_mean_df.columns.tolist()\nx_axis = range(len(all_short_student_model_names))\n\nmax_depth_log2 = np.log2(teacher_df['depth'].max())\nmax_width_log2 = np.log2(teacher_df['width'].max())\n\ncurve_colors = []\ncurve_names = []\nfor k in range(teacher_df.shape[0]):\n    \n    nn_depth = teacher_df.loc[k,'depth']\n    nn_width = teacher_df.loc[k,'width']\n    \n    curr_curve_color = (np.log2(nn_depth) \/ max_depth_log2, 0.2, np.log2(nn_width) \/ max_width_log2)\n    curve_colors.append(curr_curve_color)\n    curve_names.append('FCN_DxW_%dx%d' %(nn_depth, nn_width))\n\nplt.subplot(5,1,1);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.plot(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('mean', fontsize=20)\nplt.xticks([], []); plt.legend(curve_names, ncol=8)\n\nplt.subplot(5,1,2);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.plot(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('std', fontsize=20)\nplt.xticks([], []);\n\nplt.subplot(5,1,3);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.plot(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('best', fontsize=20)\nplt.xticks([], [])\n\nplt.subplot(5,1,4);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.plot(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('median', fontsize=20)\nplt.xticks([], [])\n\nplt.subplot(5,1,5);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.plot(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('80th percentile', fontsize=20)\n\nplt.xticks(x_axis, all_short_student_model_names, rotation=90, fontsize=18);\n","ab3ebb9e":"plt.figure(figsize=(25,30));\nplt.subplots_adjust(left=0.06, bottom=0.14, right=0.94, top=0.96, hspace=0.12, wspace=0.1)\n\nall_short_student_model_names = fitting_pattern_mean_df.columns.tolist()\nx_axis = range(len(all_short_student_model_names))\n\nmax_depth_log2 = np.log2(teacher_df['depth'].max())\nmax_width_log2 = np.log2(teacher_df['width'].max())\n\ncurve_colors = []\ncurve_names = []\nfor k in range(teacher_df.shape[0]):\n    \n    nn_depth = teacher_df.loc[k,'depth']\n    nn_width = teacher_df.loc[k,'width']\n    \n    curr_curve_color = (np.log2(nn_depth) \/ max_depth_log2, 0.2, np.log2(nn_width) \/ max_width_log2)\n    curve_colors.append(curr_curve_color)\n    curve_names.append('FCN_DxW_%dx%d' %(nn_depth, nn_width))\n\nplt.subplot(5,1,1);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.semilogy(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('mean', fontsize=20)\nplt.xticks([], []); plt.legend(curve_names, ncol=8)\n\nplt.subplot(5,1,2);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.semilogy(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('std', fontsize=20)\nplt.xticks([], []);\n\nplt.subplot(5,1,3);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.semilogy(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('best', fontsize=20)\nplt.xticks([], [])\n\nplt.subplot(5,1,4);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.semilogy(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('median', fontsize=20)\nplt.xticks([], [])\n\nplt.subplot(5,1,5);\nfor k in range(fitting_pattern_mean_df.shape[0]):\n    plt.semilogy(fitting_pattern_mean_df.loc[k,:], c=curve_colors[k]); \nplt.title('80th percentile', fontsize=20)\n\nplt.xticks(x_axis, all_short_student_model_names, rotation=90, fontsize=18);\n","337052b2":"X = np.array(fitting_pattern_mean_df).astype(float)\n\nnum_components = 6\nmeanPCA_model = decomposition.PCA(n_components=num_components, whiten=True)\nmeanPCA_model.fit(X)\npattern_features = meanPCA_model.transform(np.log10(X))\n\ndepth = np.array(teacher_df['depth'])\nwidth = np.array(teacher_df['width'])\n\nfig, axs = plt.subplots(nrows=4, ncols=num_components, figsize=(25,13))\nfig.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, hspace=0.08, wspace=0.08)\nfor k in range(num_components):\n    \n    axs[0,k].scatter(pattern_features[:,k], depth + 0.5 * np.random.randn(depth.shape[0]))\n    axs[1,k].scatter(pattern_features[:,k], width + 0.5 * np.random.randn(width.shape[0]))\n    axs[2,k].scatter(pattern_features[:,k], width + 2 * depth + 0.5 * np.random.randn(width.shape[0]))\n    axs[3,k].scatter(pattern_features[:,k], width * depth)\n    \n    if k == 0:\n        axs[0,k].set_ylabel('depth', fontsize=20)\n        axs[1,k].set_ylabel('width', fontsize=20)\n        axs[2,k].set_ylabel('width + 2*depth', fontsize=20)\n        axs[3,k].set_ylabel('width * depth', fontsize=20)\n    axs[2,k].set_xlabel('PC %d' %(k+1), fontsize=20)\n\nfig.suptitle('PCA representation of fitting pattern vs network size', fontsize=20);","1e5183e6":"# Apply PCA on mean fitting pattern and plot firts components against depth","f97a2ef2":"# Get all fitting patterns","b4e3f03c":"# Show several different random seeds with same model sizes","620be4ec":"# Display fitting pattern for 3 different teachers (increasing teacher depth & width)","d250452f":"# Define a complicated data access function","24f3f8cf":"# Display all fitting patterns","487f2291":"# Data access helper functions","118e7272":"# Display fitting pattern for 3 different teachers (increasing teacher depth)","47363118":"# Load a single teacher model and display it's student model names","a6a9500e":"# Display fitting pattern for 3 different teachers (increasing teacher width)","cfbce112":"# Display all fitting patterns (log scale)"}}