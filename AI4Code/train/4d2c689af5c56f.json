{"cell_type":{"4b0035ee":"code","926dd16f":"code","0ff2eaf8":"code","2d4d8f52":"code","90554038":"code","c7d4cc7f":"code","a4e65cc4":"code","932b8f7b":"code","5937b4e7":"code","cc6318e1":"code","ac8bec2c":"code","75f1c153":"code","3ad752a8":"code","14a8a45a":"code","2a152c1b":"code","26dc52e0":"code","f69c29b1":"code","746d2f66":"markdown","fea57a54":"markdown","23d32037":"markdown","4bdeb27a":"markdown","9c0e4615":"markdown","54e962f1":"markdown","a397700f":"markdown","d8885c94":"markdown"},"source":{"4b0035ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","926dd16f":"data = pd.read_csv('..\/input\/fish-market\/Fish.csv')","0ff2eaf8":"data","2d4d8f52":"data.isnull().any()","90554038":"len(list(data['Species'].unique()))","c7d4cc7f":"encoder = LabelEncoder()\ndata['Species'] = encoder.fit_transform(data['Species'])\n\nfish_type = {index: type for index, type in enumerate(encoder.classes_)}\nfish_type","a4e65cc4":"plt.figure(figsize = (12, 10))\nsns.heatmap(data.corr(), annot = True)\nplt.show()","932b8f7b":"X = data.drop('Species', axis = 1)\ny = data['Species']","5937b4e7":"X","cc6318e1":"scaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)","ac8bec2c":"X","75f1c153":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7)","3ad752a8":"logistic_model = LogisticRegression()\nlogistic_model.fit(X_train, y_train)\n\nprint(str(logistic_model.score(X_test, y_test) * 100) + \"%\")","14a8a45a":"inputs = tf.keras.Input(shape = (6, ))\nx = tf.keras.layers.Dense(64, activation = 'relu')(inputs)\nx = tf.keras.layers.Dense(16, activation = 'relu')(x)\nx = tf.keras.layers.Dense(16, activation = 'relu')(x)\noutputs = tf.keras.layers.Dense(7, activation = 'softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nbatch_size = 32\nepochs = 150\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split = 0.2,\n    batch_size = batch_size,\n    epochs = epochs\n)","2a152c1b":"plt.figure(figsize = (14, 10))\n\nepochs_range = range(1, epochs + 1)\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs_range, train_loss, label = 'Training_loss')\nplt.plot(epochs_range, val_loss, label = 'Validation_loss')\n\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","26dc52e0":"np.argmin(val_loss)","f69c29b1":"model.evaluate(X_test, y_test)","746d2f66":"## Logistic Regression Model \ud83d\udccf","fea57a54":"### Loss Graph \ud83d\udcc8","23d32037":"## Neural Network Model \ud83e\udde0","4bdeb27a":"### Logistic Regression Score \ud83c\udfaf","9c0e4615":"# Model ","54e962f1":"# Importing Libraries \ud83d\udcd6","a397700f":"### Neural Network Score \ud83c\udfaf","d8885c94":"# Preprocessing \ud83d\udee0\ufe0f"}}