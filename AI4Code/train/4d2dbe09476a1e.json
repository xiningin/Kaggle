{"cell_type":{"142fd10a":"code","56df7494":"code","cf1276a9":"code","f674dd3b":"code","fdf608ed":"code","357d5c13":"code","a5b09f47":"code","df2c770a":"code","6254ec08":"code","4478ea79":"code","6afcebb4":"code","3c11547a":"code","d2f7d222":"code","0570a154":"code","1b896e9c":"code","4767d4dc":"code","d3a19991":"code","a7a12a2e":"code","093ba6fe":"code","4a79d1ee":"code","3b774d33":"code","df7d519a":"code","3b4dde60":"code","544270b4":"code","f5a2abad":"code","0cd1a05f":"code","17bce2d5":"code","b79d23e4":"markdown","e7cc632b":"markdown","f0037eaa":"markdown","eed8ea01":"markdown","5220d468":"markdown","35181ecd":"markdown","1f181d27":"markdown","f044acf5":"markdown","fc5abe74":"markdown","7b64a352":"markdown","4b050cdb":"markdown","d92460b6":"markdown","9eaae527":"markdown","9874ff35":"markdown","720b5fce":"markdown","c381940c":"markdown","96670794":"markdown","d3c6eb83":"markdown","0081e963":"markdown","7682f6bd":"markdown","c2337f18":"markdown"},"source":{"142fd10a":"#Import basic packages\nimport pandas as pd\nimport numpy as np\n#Import packages for preprocessing (data cleaning)\nfrom sklearn.preprocessing import RobustScaler, LabelEncoder\n#Import packages for data visualisation\nimport matplotlib.pyplot as plt\n#Import packages for model testing\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n#Import packages for modeling\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.pipeline import make_pipeline\n\n","56df7494":"#Import both training & testing set into Python. \ndf_train_ori = pd.read_csv('..\/input\/train.csv')\ndf_test_ori = pd.read_csv('..\/input\/test.csv')\n\n#Print the shape of both training & testing set. It makes sense as the target variable (SalePrice) is only available in training set.\nprint(df_train_ori.shape)\nprint(df_test_ori.shape)\n","cf1276a9":"df_test_ori['SalePrice'] = 0","f674dd3b":"#In this project, as we are predicting the SalePrice of a property, it is a common sense that there should be a linear relationsip\n#between the area of the property and the sale price of the property. (The area of the property is in cloumn 'GrLivArea')\n\n#We will use scatter plot to see if the relationship is linear. \nplt.scatter(x = df_train_ori['GrLivArea'], y = df_train_ori['SalePrice'])\nplt.ylabel('SalePrice')\nplt.xlabel('GrLivArea')\nplt.show()","fdf608ed":" df_train_ori = df_train_ori.drop(df_train_ori[(df_train_ori['GrLivArea']>4000) & (df_train_ori['SalePrice']<300000)].index)","357d5c13":"#Double check the shape of training set, in case we drop more points than expected. \nprint(df_train_ori.shape)\n#The result is as expected, only two points in the bottom right are dropped. ","a5b09f47":"#Combine the training&testing set\ndf_all = df_train_ori.append(df_test_ori)\n#Double check the shape with the combined dataset. \nprint(df_all.shape)","df2c770a":"#Check the info for the combined dataset. \nprint(df_all.info())","6254ec08":"#By looking at the training & testing set, the missing value in these columns should be filled with 'None'. \nfor i in ['Alley', 'MasVnrType','BsmtQual','BsmtCond','FireplaceQu', 'GarageType','GarageFinish','GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']:\n    df_all[i] = df_all[i].fillna('None')","4478ea79":"#The missing value in these columns should be filled with 0.\nfor i in ['MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF','GarageYrBlt', 'GarageCars','GarageArea']:\n    df_all[i] = df_all[i].fillna(0)","6afcebb4":"#The missing value in these columns should be filled with the mean of its corresponding feature.\ndf_all[\"LotFrontage\"] = df_all[\"LotFrontage\"].fillna(df_all[\"LotFrontage\"].mean())","3c11547a":"#The missing value in these columns should be filled with the most frequent number of its corresponding feature.\nfor i in ['MSZoning', 'Exterior1st','Exterior2nd','BsmtExposure','BsmtFinType1', 'BsmtFinType2', 'Electrical','BsmtFullBath', 'BsmtHalfBath','KitchenQual', 'Functional','SaleType']:\n    df_all[i] = df_all[i].fillna(df_all[i].mode()[0])","d2f7d222":"#The missing value in these columns should be filled with the most frequent category of its corresponding feature.\ndf_all[\"Functional\"] = df_all[\"Functional\"].fillna(\"Typ\")","0570a154":"df_all = df_all.drop(['Utilities'], axis = 1)","1b896e9c":"df_all['TotalAreaSF'] = df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']","4767d4dc":"print(df_all.info())","d3a19991":"#These variables are classified as categorical Variables with priority ranking\nencode = ['LotShape','LandSlope','Neighborhood', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n          'BsmtFinType2', 'HeatingQC', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', \n          'GarageCond', 'PavedDrive', 'PoolQC', 'Fence']\n#Use encode() method to assign different numeric values to each of the category in each of the variable, \nfor i in encode:\n    le = LabelEncoder() \n    le.fit(list(df_all[i].values)) \n    df_all[i] = le.transform(list(df_all[i].values))","a7a12a2e":"#These variables are classified as numeric variables\nnorm = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond','YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n        'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n        'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n        'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'TotalAreaSF']\n\n#Combine encode & norm to normalize all the numeric variables\nnorm_variables = norm + encode\ndf_all[norm_variables] = (df_all[norm_variables]-df_all[norm_variables].mean())\/(df_all[norm_variables].max()-df_all[norm_variables].min())","093ba6fe":"#These variables are classified as categorical Variables with equivalent ranking\ncat = ['MSZoning', 'Street', 'Alley','LandContour', 'LotConfig','Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', \n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir', 'GarageType', 'MiscFeature','SaleType',\n       'SaleCondition']\n\ndf_all_dummy = pd.get_dummies(df_all, drop_first = True)\n#This is the end of data cleaning process","4a79d1ee":"df_train_adj = df_all_dummy[df_all_dummy['SalePrice'] != 0]\ndf_test_adj = df_all_dummy[df_all_dummy['SalePrice'] == 0]","3b774d33":"#Training the data\ndata_to_train = df_train_adj.drop(['SalePrice','Id'], axis = 1)","df7d519a":"df_train_adj[\"SalePrice\"] = np.log1p(df_train_adj[\"SalePrice\"])\nlabels_to_use = df_train_adj['SalePrice']","3b4dde60":"#Build and fit the model\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0007, random_state=1))\nridge = make_pipeline(RobustScaler(), Ridge(alpha =20, random_state=42))","544270b4":"def evaluation(model):\n    result= np.sqrt(-cross_val_score(model, data_to_train, labels_to_use, cv = 5, scoring = 'neg_mean_squared_error'))\n    return(result)\n","f5a2abad":"score = evaluation(lasso)\nprint(\"Lasso score: {:.5f}\\n\".format(score.mean()))","0cd1a05f":"score = evaluation(ridge)\nprint(\"Ridge score: {:.5f} \\n\".format(score.mean()))","17bce2d5":"test_df_id = df_test_ori['Id']\ntest_df_x = df_test_adj.drop(['SalePrice', 'Id'], axis = 1)\n\nlasso.fit(data_to_train, labels_to_use)\ntest_df_y_log = lasso.predict(test_df_x)\ntest_df_y = np.exp(1)**test_df_y_log\n\n#Submission\nsubmission = pd.DataFrame({'ID': list(test_df_id), 'SalePrice': list(test_df_y)})\nsubmission.to_csv('submission.csv')","b79d23e4":"Encoding categorical variables with priority ranking","e7cc632b":"** Part III: Find the best fit model**\n\nNow that we have completed the data cleaning process, we can proceed to the next step: fittng the model. \nBefore that, we should split the combined dataset with training set & testing set. ","f0037eaa":"Ridge performance","eed8ea01":"**Evaluation on performance**","5220d468":"Categorize all the variables into different groups\n\nIn this dataset, as we are dealing with both numeric & categorical variables. We will have different approaches for different types of variables. After further exploration on the dataset, I manage to categorize all the variables into 3 different groups. \nGroup 1. Numeric Variables\n2. Categorical Variables with equally ranking \n3. Categorical Variables with priority ranking\n\ne.g.\ncolumn 'RoofStyle', it is a categorical variable which represents different types of the roof of the property. In this case, each of the category should be treated equally. \ncolumn 'ExterQual', it is a categorical variable which evaluates the quality of the material on the exterior. The categories are: 'Excellent', 'Good', 'Average\/Typical', 'Fair', 'Poor'; Each of the category should be treated differently as it contains information in terms of ordering. \n\n\nApproaches:\n1. Numeric Variables: Normalize all the numeric variables (both discrete and continuous) such that all the numeric variables would have the same weightage. \n2. Categorical Variables with equivalent ranking: Assign dummy variables (0\/1) to represent each of the category in each of the variables. \n3. Categorical Variables with priority ranking: Assign different values to represent each of the category in each of the variables. Use encode() method. \n\n","35181ecd":"Interation between the columns\n\nAfter some further exploration on the dataset & data exploration, the interation between column 'TotalBsmtSF', '1stFlrSF' and '2ndFlrSF' should be taken into consideration.  Create a new column of 'TotalAreaSF' and its value will be the sum of TotalBsmtSF + 1stFlrSF + 2ndFlrSF. ","1f181d27":"Lasso performance","f044acf5":"Normalize numeric variables","fc5abe74":"***Part I: Import packages and training & testing set ***","7b64a352":"Drop redundant columns\n\nNow we only left column 'Utilities'. \nBelow are some statistics. \nOriginal Training set: one entry for 'NoSeWa' and the rest are 'AllPub'\nOriginal Testing set: 2 entries for 'NaNs' and the rest are 'AllPub' \n\nGiven that the entry 'NoSeWa' is not available in testing set and there is no missing value in training set, this column is therefore redundant in forecasting the SalePrice of the property. Hence, we can drop the cloumn 'Utilities'. \n","4b050cdb":"**Compare the result**\n\nLasso Regression give a relatively lower score than Ridge Regression. We will then adopt Lasso Regression as our best fit model. ","d92460b6":"Final Check on the shape of the combined dataset \n\nThere is no longer NaNs in the combined dataset!","9eaae527":"After checking the shape of the dataset, I'm going to assign a new column of 'SalePrice' with value of 0 in testing set. In this case, when we combine the training & testing set together, it can be distinguished by the SalePrice. ","9874ff35":"Missing Values\n\nIn this project, we can see that there are some NaN in many of the columns. Basically there are mainly two approaches to deal with NaN. \n1. Drop all the columns with NaN and only use those columns without NaN for further analysis. \n2. Use 'fillna' method to fill up the missing values in a reasonbly manner (use your own judgement). \n\nIn this case, we will use the second approach. As if we use the first approach, many of the columns will be dropped and the result is expected to be less accurate. Once again, since I'm not proficient in Python,  I will have to a lot of manual work from now on. The data description provided by this project is very useful. \n\nBased on the data description, I manage to categorize all the features (with NaNs) as below; \n\n1. Replace 'NaN' with 'None'\n2. Replace 'NaN' with 0\n3. Replace 'NaN' with the most frequent number\/category of its corresponding feature. \n4. Replace 'NaN' with the mean\/median of its corresponding feature.\n\nThe result of analysis is subjective to individuals, you may have a even better result than mine if the categorize it differently. Nevertheless, let's continue. ","720b5fce":"**Summary**\n\nHere come to the end of the project. ","c381940c":"Assign dummy variable to categorical variables with equally ranking","96670794":"**Part II: Data Cleaning Process**\n\n","d3c6eb83":"***Introduction***","0081e963":"From scatter plot, the result is as expected. The SalePrice increases when the area of the property increases. We can also conclude that two points in the bottom right are definitely outliers. We can then remove the two points in the bottom right.","7682f6bd":"Hi guys, my name is Ivan. \nThis is my very first machine learning kernel and I've achieved a score of 0.12309. \nIn this kernel, I will mainly discuss on the fundamental concepts of machine learning with minimal codes. As I'm not a programmer, please let me know if there is a better alternative\/approach. Appreciate with that!\n\n**Here is the main content of this kernel:**\n* Import packages and training & testing set \n* Data Cleaning Process  \n      1. Remove outliers\n      2. Fille up missing values\n      3. Drop redundant variables\n      4. Categorize variables\n      5. Deal with interaction between the variables\n* Find the best fit model\n      1. Lasso Regression\n      2. Ridge Regression\n* Export the result","c2337f18":"Log the Target variable (SalePrice)\n\nInfo from evaluation: Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally."}}