{"cell_type":{"4bbb9e2b":"code","4a167020":"code","b7cf9755":"code","e17897f7":"code","65510f2f":"code","a27344f5":"code","c5b991e9":"code","d756e2f7":"code","28dd5c28":"code","9f298c8a":"code","42c591d5":"markdown","6a478e28":"markdown","9c81dd38":"markdown","b8722273":"markdown"},"source":{"4bbb9e2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a167020":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Dropout, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob\n\ntrain_path = '..\/input\/fruits\/fruits-360\/Training\/'\ntest_path = '..\/input\/fruits\/fruits-360\/Test\/'\n","b7cf9755":"\"\"\"img = load_img(train_path + 'Apple Braeburn\/0_100.jpg')\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\"\"\"","e17897f7":"x = img_to_array(img)\nprint(x.shape)\n\nclassName = glob(train_path + '\/*') # train path'deki t\u00fcm dosyalar\u0131 className'in i\u00e7ine at","65510f2f":"print(x.shape)\nnumofclass = len(className)\nprint(\"Number of Class:\", numofclass)  ","a27344f5":"model = Sequential() # model olu\u015fturuyoruz\n#filters = 32, 32 tane filtreden olu\u015fan, kernel_size = (3,3) olsun \nmodel.add(Conv2D(32, (3,3), padding = \"same\", activation = \"relu\", input_shape = x.shape )) # resmim 2 boyutlu oldu\u011fu i\u00e7in conv2d \nmodel.add(MaxPooling2D(pool_size=(2, 2))) # default 2x2\n\nmodel.add(Conv2D(64, (3,3), padding = \"same\", activation = \"relu\" )) # resmim 2 boyutlu oldu\u011fu i\u00e7in conv2d \nmodel.add(MaxPooling2D(pool_size=(2, 2))) # default 2x2\n\nmodel.add(Conv2D(128, (3,3), padding = \"same\", activation = \"relu\")) # resmim 2 boyutlu oldu\u011fu i\u00e7in conv2d \nmodel.add(MaxPooling2D(pool_size=(2, 2))) # default 2x2\n\nmodel.add(Conv2D(256, (3,3), padding = \"same\", activation = \"relu\")) # resmim 2 boyutlu oldu\u011fu i\u00e7in conv2d \nmodel.add(MaxPooling2D(pool_size=(2, 2))) # default 2x2\n\nmodel.add(Flatten()) # d\u00fczle\u015ftirdik\nmodel.add(Dense(1024, activation = \"relu\")) # 1024 neurondan olu\u015fan dense olsun\nmodel.add(Dropout(0.3)) # %50 sini kapat\nmodel.add(Dense(numofclass, activation = \"softmax\")) # output numofclass kadar olmas\u0131 gerekiyor\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"])\n\nbatch_size = 20 # her defas\u0131nda 20 tane resmimi train edece\u011fim\n","c5b991e9":"## Data generation farkl\u0131 imgler yarataca\u011f\u0131z\n\n# rescale ile rgb de\u011ferlerini normalize ediyoruz 0-1 aras\u0131nda, shear range %30 oran\u0131nda yana d\u00f6n\u00fcyor rastgel\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                   shear_range = 0.3,\n                   horizontal_flip = True,\n                   zoom_range = 0.3)  \n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(train_path,  # training datam\u0131z\u0131 de\u011fi\u015ftirerek ekleyerek data elde etttik farkl\u0131 farkl\u0131\n                                                    target_size = x.shape[:2],#100,100\n                                                    batch_size = batch_size, #20\n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\")\n\ntest_generator = test_datagen.flow_from_directory(test_path, # test datam\u0131z\u0131 de\u011fi\u015ftirerek ekleyerek data elde etttik farkl\u0131 farkl\u0131\n                                                  target_size = x.shape[:2],# 100,100\n                                                  batch_size = batch_size, #20\n                                                  color_mode = \"rgb\",\n                                                  class_mode = \"categorical\")","d756e2f7":"steps_for_epoch = 1000 \/\/ batch_size # 1000\/20 = 50 , bir epochda 80 kez verimi train edece\u011fim, \nepochs = 100\nvalidation_steps = 500 \/\/ batch_size\n\nhistory = model.fit_generator(generator = train_generator,\n                    steps_per_epoch = steps_for_epoch,\n                    epochs = epochs,\n                    validation_data = test_generator,\n                    validation_steps = validation_steps)","28dd5c28":"model.save_weights(\"evaluate.h5\")","9f298c8a":"print(history.history.keys())\nplt.plot(history.history[\"loss\"], label = \"Train Loss\")\nplt.plot(history.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()\nplt.show()\n\nplt.plot(history.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(history.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()","42c591d5":"# Model evaluation","6a478e28":"# Data generation","9c81dd38":"# CNN MODEL","b8722273":"# Fitting"}}