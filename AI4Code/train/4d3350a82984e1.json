{"cell_type":{"cddb5e8b":"code","8c4ea09a":"code","1f2976a9":"code","97cc3ac5":"code","01ff1e1c":"code","47bae41a":"code","b434cf67":"code","40062a42":"code","79a82cf7":"code","02fe343b":"code","e9d0e4dc":"code","51e2d0a8":"code","188e3fe0":"code","523d7967":"code","87e11159":"code","ea353f44":"code","d4090dcf":"code","9b62975d":"code","72c2ee15":"code","f916d2c9":"code","f45ff584":"code","750f9510":"code","cb1c7c56":"code","0a80956d":"code","31b9158d":"code","0d71798f":"code","2a16a69d":"code","75a4c7d5":"code","de7d0c4e":"code","6f5bbc00":"code","6a202f29":"code","4c531da7":"code","5650e167":"code","dd3fbd52":"code","241e6d58":"code","4e68f6ca":"code","acfad56d":"markdown","858a759d":"markdown","c3a86668":"markdown","ae47c651":"markdown","00bcfe01":"markdown","64d4bf41":"markdown","b3d9e895":"markdown","bc65dcd8":"markdown","1015501a":"markdown","f90910e9":"markdown","66dfc0c3":"markdown","236e16a1":"markdown","c5bf6ef6":"markdown","f8cc93e7":"markdown","4e548009":"markdown","8b08f2b3":"markdown","b14d964d":"markdown","76cb132f":"markdown","9526ae14":"markdown","8428964a":"markdown","fb44cb2f":"markdown","570e3904":"markdown","67af043c":"markdown","63fcb924":"markdown","545a9dd5":"markdown","08e1ca93":"markdown","52e1426b":"markdown","44a40b04":"markdown","e7417729":"markdown","3927bbb2":"markdown"},"source":{"cddb5e8b":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\n\n%matplotlib inline\nplt.style.use('seaborn-darkgrid')\npalette = plt.get_cmap('Set2')","8c4ea09a":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","1f2976a9":"train.head(10)","97cc3ac5":"test.head(10)","01ff1e1c":"train.info()","47bae41a":"msno.bar(train.iloc[:, :40])","b434cf67":"msno.bar(train.iloc[:, 40:])","40062a42":"train.iloc[:, :40].describe()","79a82cf7":"train.iloc[:, 40:-1].describe()","02fe343b":"pd.DataFrame(train['SalePrice'].describe())","e9d0e4dc":"plt.figure(figsize=(12, 7))\n\nsns.distplot(train['SalePrice']).set(ylabel=None, xlabel=None)\nplt.title('House price distribution histogram', fontsize=18)\nplt.show()","51e2d0a8":"train['SalePrice'] = np.log1p(train['SalePrice'])","188e3fe0":"plt.figure(figsize=(12, 7))\n\nsns.distplot(train['SalePrice'])\nplt.title('House price distribution histogram after fix', fontsize=18)\nplt.show()","523d7967":"corr_train = train.corr()\n\ncolormap = plt.cm.RdBu\n\nplt.figure(figsize=(14,12))\nplt.title('Pearson correlation matrix between features', y=1, size=15)\nsns.heatmap(corr_train, vmax=.8, square=True, cmap=colormap)\nplt.show()","87e11159":"train.head()","ea353f44":"highest_corr_features = corr_train.index[\n    abs(corr_train['SalePrice']) > 0.5\n    ]\n\nplt.figure(figsize=(14,12))\nplt.title('Pearson correlation matrix between features and \"SalePrice\"', y=1, size=15)\nsns.heatmap(train[highest_corr_features].corr(), linewidths=0.1, vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()","d4090dcf":"SalePrice = pd.DataFrame(corr_train['SalePrice'].sort_values(ascending=False))\nSalePrice","9b62975d":"features = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n\nsns.pairplot(train[features])\nplt.show()","72c2ee15":"y_train = train['SalePrice']\ntest_id = test['Id']\ndata = pd.concat([train, test], axis=0, sort=False)\ndata = data.drop(['Id', 'SalePrice'], axis=1)","f916d2c9":"Total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum() \/ data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([Total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","f45ff584":"data.drop((missing_data[missing_data['Total'] > 5]).index, axis=1, inplace=True)\nprint(data.isnull().sum().max())","750f9510":"# numeric data\nnumeric_missed = ['BsmtFinSF1',\n                  'BsmtFinSF2',\n                  'BsmtUnfSF',\n                  'TotalBsmtSF',\n                  'BsmtFullBath',\n                  'BsmtHalfBath',\n                  'GarageArea',\n                  'GarageCars']\n\nfor feature in numeric_missed:\n    data[feature].fillna(0, inplace=True)","cb1c7c56":"# categorical data\ncategorical_missed = ['Exterior1st',\n                  'Exterior2nd',\n                  'SaleType',\n                  'MSZoning',\n                   'Electrical',\n                     'KitchenQual']\n\nfor feature in categorical_missed:\n    data[feature].fillna(data[feature].mode()[0], inplace=True)","0a80956d":"data['Functional'].fillna('Typ', inplace=True)","31b9158d":"data.isnull().sum().max() ","0d71798f":"from scipy.stats import skew\nfrom sklearn.decomposition import PCA","2a16a69d":"numeric = data.dtypes[data.dtypes != 'object'].index\nskewed = data[numeric].apply(lambda col: skew(col)).sort_values(ascending=False)\nskewed = skewed[abs(skewed) > 0.5]\n\nfor feature in skewed.index:\n    data[feature] = np.log1p(data[feature])","75a4c7d5":"data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']","de7d0c4e":"data = pd.get_dummies(data)\ndata","6f5bbc00":"x_train = data[:len(y_train)]\nx_test = data[len(y_train):]","6a202f29":"x_valid = x_train[:1168]\ny_valid = y_train[:1168]","4c531da7":"from sklearn.metrics import make_scorer\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf","5650e167":"!pip install xgboost","dd3fbd52":"x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape","241e6d58":"model = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Flatten(input_shape=(221,)))\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nloss = tf.keras.losses.BinaryCrossentropy()\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nmodel.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=['mse'])\n\nhistory = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=150, batch_size=128)","4e68f6ca":"y_predict = np.floor(np.expm1(model.predict(x_test)))\n\nsub = pd.DataFrame()\nsub['Id'] = test_id\nsub['SalePrice'] = y_predict\nsub.to_csv('submission.csv',index=False)","acfad56d":"### Modeling and predicting","858a759d":"#### As we can see, we have a positive skew, we must fix it.","c3a86668":"#### As we can see there are a lot of missing values in some columns, not missing values do not exceed the mark of 30. We'll fix it after a while!","ae47c651":"#### Read train and test datasets","00bcfe01":"#### We see the relationship (correlation) between the features, but let's see the correlation between the \"Price of houses\" and features","64d4bf41":"#### display a graph of missing values","b3d9e895":"* #### Analysis the target\n* #### Filling missing values \n* #### Feature Engineering\n* #### Converting categorical to numerical\n* #### Modeling and predicting\n\n","bc65dcd8":"#### Let's build a Pearson correlation matrix","1015501a":"#### Display first 10 rows from train and test datasets","f90910e9":"### Feature Engineering","66dfc0c3":"#### Let's take only strongly related features","236e16a1":"### Good job! Now we know important features","c5bf6ef6":"#### Fix The Skewness in the other features","f8cc93e7":"* #### Saleprice is highly correlated with OverallQual\n* #### GarageArea logically has a great relationship with GarageCars\n* #### Have the smallest connection YearBuilt and TotRmsAbvGrd\n* #### Also highly correlated 1stFirSF and TotalBsmtSF\n* #### TotRmsAbvGrd is highly correlated with GrLivArea","4e548009":"#### its ok now","8b08f2b3":"#### Let's combine training and test datasets for convenience","b14d964d":"#### Display information on values in columns","76cb132f":"### Converting the categorical to numerical.","9526ae14":"### Let's find and fill in the missing data","8428964a":"## House sales predict","fb44cb2f":"### We will make a work plan","570e3904":"#### We can safely remove these features as they are not important and do not have a high correlation.","67af043c":"#### The simplest is to use the function pd.get_dummies()","63fcb924":"#### Import required libraries ","545a9dd5":"### Let's celebrate","08e1ca93":"##### first group","52e1426b":"### We cleaned the data very well, good job!","44a40b04":"Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.","e7417729":"#### Almost done! That is enough","3927bbb2":"#### Display the description of the values in the columns"}}