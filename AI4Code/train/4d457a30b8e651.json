{"cell_type":{"c8b37187":"code","89235f14":"code","cec03ae0":"code","eeb47ebe":"code","5e6d1e30":"code","e18205e8":"code","14482343":"code","fb97ab87":"code","275ea47c":"code","cdb69b5e":"code","d489f522":"code","3eb01499":"code","b2becc25":"code","930b4380":"code","96bda380":"code","b67edf09":"code","83d24385":"code","6c7cf804":"code","a1dbf24f":"code","6f6cc5b3":"code","d5f58602":"code","ff0c9e5e":"code","5a0f0108":"code","799fa12c":"markdown"},"source":{"c8b37187":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\n\nfrom keras.layers import Conv2D, Dense, Dropout, AveragePooling2D, MaxPool2D, BatchNormalization, Activation, Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.","89235f14":"train_dir = \"..\/input\/train\/\"\ntest_dir = \"..\/input\/test\/\"\n\nsample_submission = pd.read_csv(\"..\/input\/sample_submission.csv\")","cec03ae0":"# display the train image\ntrain_img_list = os.listdir(train_dir) \n\nprint(\"No of images = \"+str(len(train_img_list)))\n\nimg = plt.imread(train_dir+train_img_list[0])\nplt.imshow(img)\n#print(img.shape)","eeb47ebe":"# display the train image\ntest_img_list = os.listdir(test_dir) \n\nprint(\"No of images = \"+str(len(test_img_list)))\n\nimg = plt.imread(test_dir+test_img_list[0])\nplt.imshow(img)\n#print(img.shape)","5e6d1e30":"# train.csv\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\n\nprint(\"train.csv shape = \"+str(train_df.shape))\n\ntrain_df.head()","e18205e8":"# unique ids - also includes \"new values\" \nids = train_df[\"Id\"]\nids.value_counts().shape[0]","14482343":"# image preprocessing \ndef preprocessing(dir_name,image_list):\n    print(\"Preprocessing \"+dir_name)\n    m = len(image_list)\n    \n    X = np.zeros((m,100,100,3))\n    \n    count = 0\n    for img_name in image_list:\n        img = image.load_img(path=dir_name+img_name,target_size=(100,100,3)) #images may have different size hence compressing into same size\n        img = image.img_to_array(img)\n        img = preprocess_input(img)\n        X[count] = img\n    \n        \n        if count%1000 == 0:\n            print(\"Preprocessing \"+str(count))\n        count += 1\n    return X","fb97ab87":"x_train = preprocessing(train_dir,train_df[\"Image\"])\n# x_test = preprocessing(test_dir,sample_submission[\"Image\"])","275ea47c":"def label_preprocessing(y):\n    label_encoder = LabelEncoder() #to convert string labels to integer\n    label_encoder.fit(y)\n    labels_encoded = label_encoder.transform(y)\n    # print(labels_encoded.shape)\n    \n    one_hot_encoder = OneHotEncoder(sparse=False)\n    one_hot_encoder.fit(labels_encoded.reshape(-1,1))\n    one_hot_encoded = one_hot_encoder.transform(labels_encoded.reshape(-1,1))\n    \n    # print(one_hot_encoded.shape)\n    \n    y = one_hot_encoded\n    \n    return y, label_encoder","cdb69b5e":"label_encoder = None\ny_train, label_encoder = label_preprocessing(train_df[\"Id\"])","d489f522":"x_train = x_train\/255.0\n# x_test = x_test\/255.0","3eb01499":"model = Sequential()","b2becc25":"model.add(Conv2D(filters=32,kernel_size=(7,7),name=\"conv0\",input_shape=(100,100,3)))\nmodel.add(BatchNormalization(name=\"batch0\"))\nmodel.add(Activation(activation='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2),name=\"max0\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),name=\"conv1\"))\nmodel.add(Activation(activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(3,3),name=\"avg0\"))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=1000,activation=\"relu\",name=\"dense0\"))\nmodel.add(Dropout(rate=0.8))\nmodel.add(Dense(units=y_train.shape[1],activation=\"softmax\",name=\"dense1\"))","930b4380":"model.summary()","96bda380":"adam = Adam()\nmodel.compile(optimizer=adam,loss=\"categorical_crossentropy\",metrics=['accuracy'])","b67edf09":"history = model.fit(x_train,y_train,epochs=100, batch_size=100, verbose=1)","83d24385":"plt.plot(history.history['acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","6c7cf804":"x_test = preprocessing(test_dir,sample_submission[\"Image\"])","a1dbf24f":"x_test = x_test\/255.0","6f6cc5b3":"predictions = model.predict(np.array(x_test), verbose=1)","d5f58602":"col = ['Image']\ntest_df = pd.DataFrame(sample_submission[\"Image\"], columns=col)\ntest_df['Id'] = ''\nfor i, pred in enumerate(predictions):\n    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))","ff0c9e5e":"test_df.head(10)","5a0f0108":"test_df.to_csv(\"submission1.csv\",index=False)","799fa12c":"### Model - CNN"}}