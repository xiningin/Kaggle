{"cell_type":{"5a636f25":"code","caf443e5":"code","2476ba72":"code","01520bd6":"code","2d6ca054":"code","b6020cad":"code","12e2ebe3":"code","2509f3c2":"code","e1132264":"code","c32158ba":"code","6dbc2dc2":"code","0cf3c03b":"code","94175736":"code","7a1ad272":"code","16ed36b3":"code","76252943":"code","371a513c":"code","2dc1c52e":"code","48f17d40":"code","6811e6ad":"code","f4a55208":"code","26f2eb3d":"code","a80821e8":"code","69e4e984":"code","8294a30d":"code","ac61c790":"code","b3d4d631":"code","041c1a15":"code","66a676a1":"code","78247d64":"code","9daa3f11":"code","8afd9eba":"code","e56a691e":"code","c5a0b6a7":"code","4a4ee048":"code","2f5c6001":"code","437e2273":"code","4acccdcf":"code","64257853":"code","dfdeab6d":"code","84ffb0ee":"markdown","4029edfd":"markdown","b1306600":"markdown","e3061495":"markdown","30d5ba50":"markdown","01670a92":"markdown"},"source":{"5a636f25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","caf443e5":"# importing neccessary packages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport plotly.express as px\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","2476ba72":"data = pd.read_csv('\/kaggle\/input\/insurance-premium-prediction\/insurance.csv')\ndata.head()\n","01520bd6":"data.describe()","2d6ca054":"data.dtypes","b6020cad":"data.shape","12e2ebe3":"data.isnull().sum()","2509f3c2":"numerical_feature = [feature for feature in data.columns if data[feature].dtypes != 'O']\nprint(f\"Count : {len(numerical_feature)}\")\nprint(f\"Numerical feature : {numerical_feature}\")","e1132264":"categorical_feature = [feature for feature in data.columns if feature not in numerical_feature]\nprint(f\"Count : {len(categorical_feature)}\")\nprint(f\"Categorical feature : {categorical_feature}\")","c32158ba":"data.sex.value_counts()","6dbc2dc2":"for feature in numerical_feature:\n    plt.figure(figsize=(12,5))\n    \n    plt.subplot(1,3,1)\n    plt.title(feature)\n    sns.distplot(data[feature], bins=50)\n\n    plt.subplot(1,3,2)\n    plt.title(feature)\n    stats.probplot(data[feature], dist='norm', plot=plt)\n    \n    plt.subplot(1,3,3)\n    plt.title(feature)\n    sns.boxplot(data[feature])","0cf3c03b":"for feature in categorical_feature:\n    plt.figure(figsize=(12,6))\n    sns.violinplot(data=data, x=feature, y='expenses')\n    plt.title(feature)","94175736":"# to check density of which region has higher density\npx.density_heatmap(data_frame=data, x='region', y='expenses')","7a1ad272":"plt.figure(figsize=(10,5))\nsns.violinplot(data=data, x='sex',y='expenses', hue='smoker')\nplt.title('Compare smoker in male and female')\nplt.show()","16ed36b3":"plt.figure(figsize=(10,5))\nsns.violinplot(data=data, x='region',y='expenses', hue='smoker')\nplt.title('Compare smoker in Region')\nplt.show()","76252943":"sns.pairplot(data)","371a513c":"# using heatmap to find correlation\nplt.figure(figsize=(12,6))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","2dc1c52e":"for feature in categorical_feature:\n    print(data[feature].value_counts())","48f17d40":"# male - 0, female - 1\ndata['sex'] = np.where(data['sex']=='male', 0, 1)\n\n# yes - 0, no - 1\ndata['smoker'] = np.where(data['smoker']=='yes', 0, 1)\n\n# assing value by using dict method\ndict_region = {'southeast': 0,\n               'southwest': 1,\n               'northeast': 2,\n               'northwest': 3}\ndata['region'] = data.region.map(dict_region)","6811e6ad":"scaler = StandardScaler()\ndata[['expenses']] = scaler.fit_transform(data[['expenses']])\ndata[['age']] = scaler.fit_transform(data[['age']])\ndata[['bmi']] = scaler.fit_transform(data[['bmi']])","f4a55208":"data.head()","26f2eb3d":"X = data.drop(['expenses'], axis=1)\ny = data[['expenses']]","a80821e8":"# train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","69e4e984":"score = {}\ndef cv_score(estimator):\n    return np.mean(cross_val_score(estimator=estimator, X=X, y=y, cv=5))","8294a30d":"# linear regression\nlreg = LinearRegression()\nlreg.fit(X_train, y_train)\nlr_pred = lreg.predict(X_test)\nscore['Linear Regression'] = cv_score(LinearRegression())\n\n# Ridge regressor(L2 reguralization)\nridge = Ridge()\nridge.fit(X_train, y_train)\nridge_pred = ridge.predict(X_test)\nscore['Ridge Regression'] = cv_score(Ridge())\n\n# Lasso regression(L1 reguralization)\nlasso = Lasso()\nlasso.fit(X_train, y_train)\nlasso_pred = lasso.predict(X_test)\nscore['Lasso Regression'] = cv_score(Lasso())\n\n# RandomForest regression\nrfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)\nrfr_pred = rfr.predict(X_test)\nscore['RandomForest Regression'] = cv_score(RandomForestRegressor())\n\n# DecisionTree Regression\ndtr = DecisionTreeRegressor()\ndtr.fit(X_train, y_train)\ndtr_pred = dtr.predict(X_test)\nscore['DecisionTree Regression'] = cv_score(DecisionTreeRegressor())\n\n# AdaBoost Regression\nadr = AdaBoostRegressor()\nadr.fit(X_train, y_train)\nadr_pred = adr.predict(X_test)\nscore['AdaBoost Regression'] = cv_score(AdaBoostRegressor())\n\n# KNeighbors Regression\nknr = KNeighborsRegressor()\nknr.fit(X_train, y_train)\nknr_pred = knr.predict(X_test)\nscore['KNeighbour Regression'] = cv_score(KNeighborsRegressor())\n\n# GradientBoosting Regression\ngbr = GradientBoostingRegressor()\ngbr.fit(X_train, y_train)\ngbr_pred = gbr.predict(X_test)\nscore['GradientBoosting Regression'] = cv_score(GradientBoostingRegressor())\n\n# SVR\nsvr = SVR()\nsvr.fit(X_train, y_train)\nsvr_pred = svr.predict(X_test)\nscore['SupportVector Regression'] = cv_score(SVR())\n\n# ExtraTree Regression\netr = ExtraTreeRegressor()\netr.fit(X_train, y_train)\netr_pred = etr.predict(X_test)\nscore['ExtraTree Regression'] = cv_score(ExtraTreeRegressor())","ac61c790":"# print all scores using for loop\nfor x in score:\n    print(f\"{x} : {score[x]}\")","b3d4d631":"# Hyperparameter for GradientBoosting Regresssor\npara = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n        'learning_rate': [0.01,0.03,0.05,0.07,0.9, 0.1],\n        'n_estimators': [100, 1500, 10],\n        'criterion': ['friedman_mse', 'mse', 'mae'],\n        'min_samples_split': [1,20,2],\n        'min_samples_leaf': [0.5,20,1],\n        'max_depth': [3,1500, 10],\n        'random_state':[0,45,5]}","041c1a15":"# Using RandomSearchCV for hyperparameter tunning\nGBRegressor_grid = RandomizedSearchCV(GradientBoostingRegressor(),\n                            param_distributions=para, n_iter=100, cv=5)\n\nGBRegressor_grid.fit(X_train, y_train)\npred_gbr = GBRegressor_grid.predict(X_test)","66a676a1":"print(f\"RF Regressor : {r2_score(pred_gbr, y_test)}\")","78247d64":"GBRegressor_grid.best_params_","9daa3f11":"# Hypertunning parameter for RandomForestRegressor\npara = {'criterion': ['mae', 'mse'],\n        'max_depth': [ 2, 500, 5],\n        'max_features': ['auto', 'sqrt','log2', None],\n        'min_samples_leaf': [0, 0.5, 0.7, 1],\n        'min_samples_split' : [ 0, 1, 2],\n        'n_estimators' : [10, 50, 300, 750, 1200,1300,1500],\n        'random_state':[0,45,5]\n    }","8afd9eba":"RFRegressor_grid = RandomizedSearchCV(RandomForestRegressor(), param_distributions=para,\n                                    n_iter=100, cv=5)\nRFRegressor_grid.fit(X_train, y_train)\npred_rfr = RFRegressor_grid.predict(X_test)","e56a691e":"print(f\"RF Regressor : {r2_score(pred_rfr, y_test)}\")","c5a0b6a7":"RFRegressor_grid.best_params_","4a4ee048":"# Hyperparameter tunning for AdaBoostRegressor\npara = { 'n_estimators':[50, 500, 100], \n        'learning_rate':[0.01,0.03,0.05, 0.07, 0.09,1, 1.5], \n        'loss':['linear','square', 'exponential'],\n        'random_state': [0,45,5]}","2f5c6001":"Ada_grid = RandomizedSearchCV(AdaBoostRegressor(), param_distributions=para,\n                              n_iter=100, cv=5)\nAda_grid.fit(X_train, y_train)\npred_ada = Ada_grid.predict(X_test)","437e2273":"print(f\"ADA Regressor : {r2_score(pred_ada, y_test)}\")","4acccdcf":"# Hypertunning for SVR\npara = {'kernel':['linear', 'poly', 'rbf'],\n        'degree':[3],\n        'gamma': ['scale', 'auto'],\n        'C':[1, 200, 10]}","64257853":"svr_grid = RandomizedSearchCV(SVR(), param_distributions=para, n_iter=100, cv=5, random_state=0)\nsvr_grid.fit(X_train, y_train)\npred_svr = svr_grid.predict(X_test)","dfdeab6d":"print(f\"SVR : {r2_score(svr_grid, y_test)}\")","84ffb0ee":"**After performing Hyperparameter tunning using RandomSearchCV to optimize the algorithm, Getting some better results compare to before. Overall GradientBoost Regressor perform pretty well**","4029edfd":"##### Perform feature encoding","b1306600":"#### Feature engineering","e3061495":"#### EDA","30d5ba50":"#### Hyperparameter Tunning","01670a92":"#### Fit into Algorithm"}}