{"cell_type":{"a6589fce":"code","695bb60e":"code","1a0deb61":"code","93b173db":"code","cb0bdcd9":"code","ac78387d":"code","37ec2f0f":"code","15488919":"code","ac139184":"code","0a5efa81":"code","5caa4f81":"code","fe8bd08d":"code","2c1bda1d":"code","81c547ef":"code","29333779":"code","a721bed9":"code","d4c10bd1":"code","364eff74":"code","ce628835":"code","8b39cb58":"code","b5a35736":"code","c22623be":"code","d318d730":"code","14bd827f":"code","5826fff3":"code","047e4407":"code","eec34e84":"code","f7e948e4":"code","4d7e1ab1":"code","282e0cc2":"code","4e62c587":"code","8d61a5dd":"code","03830897":"code","66ad5e9f":"code","55f99e4e":"code","82fc5fe4":"markdown","d07e8bf8":"markdown","02ace1e4":"markdown","8cbeddf9":"markdown","b93d7424":"markdown","481baa5a":"markdown"},"source":{"a6589fce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/garbage classification\/Garbage classification\"))\nprint(os.listdir('..\/input\/garbage classification\/'))","695bb60e":"from __future__ import absolute_import, division, print_function\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt","1a0deb61":"import zipfile\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob, os, random","93b173db":"import numpy as np\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nbase_path = '..\/input\/garbage classification\/Garbage classification'\nimg_list = glob.glob(os.path.join(base_path, '*\/*.jpg'))\n\nfor i, img_path in enumerate(random.sample(img_list, 6)):\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img, dtype=np.uint8)\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img.squeeze())","cb0bdcd9":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.1\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    base_path,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    subset='training',\n    seed=0\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    base_path,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation',\n    seed=0\n)\n","ac78387d":"for image_batch, label_batch in train_generator:\n  break\nimage_batch.shape, label_batch.shape","37ec2f0f":"print (train_generator.class_indices)\n\nlabels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n\nwith open('labels.txt', 'w') as f:\n  f.write(labels)\n\n","15488919":"!ls","ac139184":"path = 'labels.txt'\nlabel = np.array(open(path).read().splitlines())","0a5efa81":"IMG_SHAPE = (224,224,3)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False, \n                                               weights='imagenet')","5caa4f81":"base_model.trainable = False","fe8bd08d":"#from tensorflow import keras\n#model = tf.keras.Sequential([\n#  base_model,\n#  keras.layers.GlobalAveragePooling2D(),\n#  keras.layers.Dense(6, activation='sigmoid')\n#])","2c1bda1d":"model = tf.keras.Sequential([\n  base_model,\n  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(6, activation='softmax')\n])","81c547ef":"# model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), \n#               loss='categorical_crossentropy', \n#               metrics=['accuracy'])\n\n#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","29333779":"model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), #Adam(), \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])","a721bed9":"batch_size = 32\nepochs = 50\nsteps_per_epoch = train_generator.n \/\/ batch_size\nvalidation_steps = validation_generator.n \/\/ batch_size\n\nhistory = model.fit_generator(train_generator, \n                              steps_per_epoch = steps_per_epoch,\n                              epochs=epochs, \n                              workers=4,\n                              validation_data=validation_generator, \n                              validation_steps=validation_steps)","d4c10bd1":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,max(plt.ylim())])\nplt.title('Training and Validation Loss')\nplt.show()","364eff74":"img_path = '..\/input\/garbage classification\/Garbage classification\/paper\/paper8.jpg'\n\nimg=np.array(img)\/255.0\nimg = image.load_img(img_path, target_size=(224, 224))\nimg = image.img_to_array(img, dtype=np.uint8)\nplt.imshow(img.squeeze())\np=model.predict(img[np.newaxis, ...])\nprint(p.shape)\npredicted_class = label[np.argmax(p[0][0], axis=-1)]\nprint(predicted_class)","ce628835":"base_model.trainable = True\n# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","8b39cb58":"#model.compile(loss='binary_crossentropy',\n #             optimizer = tf.keras.optimizers.RMSprop(lr=2e-5),\n  #            metrics=['accuracy'])\n#model.summary()","b5a35736":"model.compile(loss='categorical_crossentropy',\n              optimizer = tf.keras.optimizers.Adam(1e-5),\n              metrics=['accuracy'])","c22623be":"history_fine = model.fit_generator(train_generator, \n                                   steps_per_epoch = steps_per_epoch,\n                                   epochs=epochs, \n                                   workers=4,\n                                   validation_data=validation_generator, \n                                   validation_steps=validation_steps) ","d318d730":"acc += history_fine.history['acc']\nval_acc += history_fine.history['val_acc']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","14bd827f":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.9, 1])\nplt.plot([epochs-1,epochs-1], plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 0.2])\nplt.plot([epochs-1,epochs-1], plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","5826fff3":"#from tensorflow.contrib import lite\n#file = \"Garbage.h5\"\n#keras.models.save_model(model,file)\n#converter = lite.TocoConverter.from_keras_model_file(file)\n#tflite_model=conerter.convert()\n#open(\"garbage.tflite\",'wb').write(tflite_model)","047e4407":"#import tensorflow as tf\n#file = \"Garbage.h5\"\n#keras.models.save_model(model,file)\n#converter = tf.lite.TFLiteConverter.from_keras_model_file(file)\n#tflite_model=converter.convert()\n#open(\"garbage.tflite\",'wb').write(tflite_model)","eec34e84":"#tf.lite.TFLiteConverter.from_saved_model(\"saved_model\", input_shapes={(\"image_tensor\" : [1,300,300,3])})\n","f7e948e4":"saved_model_dir = '..\/'\ntf.saved_model.save(model, saved_model_dir)\n\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\ntflite_model = converter.convert()\n\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","4d7e1ab1":"from IPython.display import FileLinks\nFileLinks('.')","282e0cc2":"import PIL.Image as Image\n\n","4e62c587":"#img=Image.open(img_path).resize((224, 224))\n","8d61a5dd":"img_path = '..\/input\/garbage classification\/Garbage classification\/cardboard\/cardboard5.jpg'\n\nimg=np.array(img)\/255.0\nimg = image.load_img(img_path, target_size=(224, 224))\nimg = image.img_to_array(img, dtype=np.uint8)\nplt.imshow(img.squeeze())\np=model.predict(img[np.newaxis, ...])\nprint(p.shape)\npredicted_class = np.argmax(p[0], axis=-1)\nprint(predicted_class)","03830897":"#Model = tf.keras.models.load_model(file)","66ad5e9f":"#from keras import backend as K\n#K.clear_session()","55f99e4e":"#desired_batch_size=7\n#nb_samples = len(validation_generator)\n#p=model.predict_generator(validation_generator, np.ceil(nb_samples\/desired_batch_size))\n#K.clear_session()","82fc5fe4":"## Fine Tuning","d07e8bf8":"model.save(\"Garbge.h5\")","02ace1e4":"global graph,model\ngraph = tf.get_default_graph()\n\nwith graph.as_default():\n     y = model.predict(img[np.newaxis, ...])","8cbeddf9":"file = \"Garbage.h5\"\nkeras.models.save_model(model,file)\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(file)\ntflite_model=converter.convert()\nopen(\"garbage.tflite\",'wb').write(tflite_model)","b93d7424":"import keras\nimport tensorflow as tf\nmodel = keras.models.load_model(file)\nmodel._make_predict_function()\ngraph = tf.get_default_graph()\n\ndef some_route():\n\t...\n\tglobal graph\n\twith graph.as_default():\n\t\toutputs = model.predict(img)\n\t...","481baa5a":"model.save(\"Garbge.h5\")"}}