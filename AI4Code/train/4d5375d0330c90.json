{"cell_type":{"3a958471":"code","b9e72807":"code","4c9a9db0":"code","b5311149":"code","11a4e3be":"code","9be4080c":"code","35b8bbf7":"code","c8d4a2a3":"code","3f2b39bf":"code","886baf84":"code","b023e9cf":"code","cab88dc4":"code","fafa8b8d":"code","d1904f6d":"code","e2f35846":"code","06985cef":"code","6086773e":"code","9846342e":"code","46ec5d8d":"code","abc1fe9d":"code","fdcb85c2":"markdown","682d85cd":"markdown","2c11cda3":"markdown","16bfba20":"markdown","4668f2dc":"markdown","210e2281":"markdown","3b4348fb":"markdown","15a7404a":"markdown"},"source":{"3a958471":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_columns', 300)\n%matplotlib inline\n\nsns.set(style='white', context='notebook', palette='deep')\n\nmycols = [\"#66c2ff\", \"#5cd6d6\", \"#00cc99\", \"#85e085\", \"#ffd966\", \"#ffb366\", \"#ffb3b3\", \"#dab3ff\", \"#c2c2d6\"]\nsns.set_palette(palette = mycols, n_colors = 4)\nprint('My colors are set!')\n\nfrom sklearn.model_selection import StratifiedKFold\nprint('sklearn imported!')\n\nimport lightgbm as lgb\nprint('lightgbm imported!')","b9e72807":"train_set = pd.read_csv('..\/input\/train.csv')\ntest_set = pd.read_csv('..\/input\/test.csv')\n\nprint(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\nprint(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')","4c9a9db0":"#Let's take a look at target\ntarget = train_set['Target']\ntarget.value_counts(normalize=True)","b5311149":"#outlier in test set which rez_esc is 99.0\ntest_set.loc[test_set['rez_esc'] == 99.0 , 'rez_esc'] = 5","11a4e3be":"data_na = train_set.isnull().sum().values \/ train_set.shape[0] *100\ndf_na = pd.DataFrame(data_na, index=train_set.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_value_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_value_count} rows which have missing value in train set ')\ndf_na.head(6)","9be4080c":"data_na = test_set.isnull().sum().values \/ test_set.shape[0] *100\ndf_na = pd.DataFrame(data_na, index=test_set.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_value_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_value_count} rows which have missing value in test set ')\ndf_na.head(6)","35b8bbf7":"#Fill na\ndef repalce_v18q1(x):\n    if x['v18q'] == 0:\n        return x['v18q']\n    else:\n        return x['v18q1']\n\ntrain_set['v18q1'] = train_set.apply(lambda x : repalce_v18q1(x),axis=1)\ntest_set['v18q1'] = test_set.apply(lambda x : repalce_v18q1(x),axis=1)\n\ntrain_set['v2a1'] = train_set['v2a1'].fillna(value=train_set['tipovivi3'])\ntest_set['v2a1'] = test_set['v2a1'].fillna(value=test_set['tipovivi3'])","c8d4a2a3":"cols = ['edjefe', 'edjefa']\ntrain_set[cols] = train_set[cols].replace({'no': 0, 'yes':1}).astype(float)\ntest_set[cols] = test_set[cols].replace({'no': 0, 'yes':1}).astype(float)","3f2b39bf":"train_set['roof_waste_material'] = np.nan\ntest_set['roof_waste_material'] = np.nan\ntrain_set['electricity_other'] = np.nan\ntest_set['electricity_other'] = np.nan\n\ndef fill_roof_exception(x):\n    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n        return 1\n    else:\n        return 0\n    \ndef fill_no_electricity(x):\n    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n        return 1\n    else:\n        return 0\n\ntrain_set['roof_waste_material'] = train_set.apply(lambda x : fill_roof_exception(x),axis=1)\ntest_set['roof_waste_material'] = test_set.apply(lambda x : fill_roof_exception(x),axis=1)\ntrain_set['electricity_other'] = train_set.apply(lambda x : fill_no_electricity(x),axis=1)\ntest_set['electricity_other'] = test_set.apply(lambda x : fill_no_electricity(x),axis=1)","886baf84":"def owner_is_adult(x):\n    if x['age'] <= 18:\n        return 0\n    else:\n        return 1\n\ntrain_set['head<18'] = train_set.apply(lambda x : owner_is_adult(x),axis=1)\ntest_set['head<18'] = test_set.apply(lambda x : owner_is_adult(x),axis=1)","b023e9cf":"train_set['adult'] = train_set['hogar_adul'] - train_set['hogar_mayor']\ntrain_set['dependency_count'] = train_set['hogar_nin'] + train_set['hogar_mayor']\ntrain_set['dependency'] = train_set['dependency_count'] \/ train_set['adult']\ntrain_set['child_percent'] = train_set['hogar_nin']\/train_set['hogar_total']\ntrain_set['elder_percent'] = train_set['hogar_mayor']\/train_set['hogar_total']\ntrain_set['adult_percent'] = train_set['hogar_adul']\/train_set['hogar_total']\ntest_set['adult'] = test_set['hogar_adul'] - test_set['hogar_mayor']\ntest_set['dependency_count'] = test_set['hogar_nin'] + test_set['hogar_mayor']\ntest_set['dependency'] = test_set['dependency_count'] \/ test_set['adult']\ntest_set['child_percent'] = test_set['hogar_nin']\/test_set['hogar_total']\ntest_set['elder_percent'] = test_set['hogar_mayor']\/test_set['hogar_total']\ntest_set['adult_percent'] = test_set['hogar_adul']\/test_set['hogar_total']\n\ntrain_set['rent_per_adult'] = train_set['v2a1']\/train_set['hogar_adul']\ntrain_set['rent_per_person'] = train_set['v2a1']\/train_set['hhsize']\ntest_set['rent_per_adult'] = test_set['v2a1']\/test_set['hogar_adul']\ntest_set['rent_per_person'] = test_set['v2a1']\/test_set['hhsize']\n\ntrain_set['overcrowding_room_and_bedroom'] = (train_set['hacdor'] + train_set['hacapo'])\/2\ntest_set['overcrowding_room_and_bedroom'] = (test_set['hacdor'] + test_set['hacapo'])\/2\n\ntrain_set['no_appliances'] = train_set['refrig'] + train_set['computer'] + train_set['television']\ntest_set['no_appliances'] = test_set['refrig'] + test_set['computer'] + test_set['television']\n\ntrain_set['r4h1_percent_in_male'] = train_set['r4h1'] \/ train_set['r4h3']\ntrain_set['r4m1_percent_in_female'] = train_set['r4m1'] \/ train_set['r4m3']\ntrain_set['r4h1_percent_in_total'] = train_set['r4h1'] \/ train_set['hhsize']\ntrain_set['r4m1_percent_in_total'] = train_set['r4m1'] \/ train_set['hhsize']\ntrain_set['r4t1_percent_in_total'] = train_set['r4t1'] \/ train_set['hhsize']\ntest_set['r4h1_percent_in_male'] = test_set['r4h1'] \/ test_set['r4h3']\ntest_set['r4m1_percent_in_female'] = test_set['r4m1'] \/ test_set['r4m3']\ntest_set['r4h1_percent_in_total'] = test_set['r4h1'] \/ test_set['hhsize']\ntest_set['r4m1_percent_in_total'] = test_set['r4m1'] \/ test_set['hhsize']\ntest_set['r4t1_percent_in_total'] = test_set['r4t1'] \/ test_set['hhsize']\n\ntrain_set['rent_per_room'] = train_set['v2a1']\/train_set['rooms']\ntrain_set['bedroom_per_room'] = train_set['bedrooms']\/train_set['rooms']\ntrain_set['elder_per_room'] = train_set['hogar_mayor']\/train_set['rooms']\ntrain_set['adults_per_room'] = train_set['adult']\/train_set['rooms']\ntrain_set['child_per_room'] = train_set['hogar_nin']\/train_set['rooms']\ntrain_set['male_per_room'] = train_set['r4h3']\/train_set['rooms']\ntrain_set['female_per_room'] = train_set['r4m3']\/train_set['rooms']\ntrain_set['room_per_person_household'] = train_set['hhsize']\/train_set['rooms']\n\ntest_set['rent_per_room'] = test_set['v2a1']\/test_set['rooms']\ntest_set['bedroom_per_room'] = test_set['bedrooms']\/test_set['rooms']\ntest_set['elder_per_room'] = test_set['hogar_mayor']\/test_set['rooms']\ntest_set['adults_per_room'] = test_set['adult']\/test_set['rooms']\ntest_set['child_per_room'] = test_set['hogar_nin']\/test_set['rooms']\ntest_set['male_per_room'] = test_set['r4h3']\/test_set['rooms']\ntest_set['female_per_room'] = test_set['r4m3']\/test_set['rooms']\ntest_set['room_per_person_household'] = test_set['hhsize']\/test_set['rooms']\n\ntrain_set['rent_per_bedroom'] = train_set['v2a1']\/train_set['bedrooms']\ntrain_set['edler_per_bedroom'] = train_set['hogar_mayor']\/train_set['bedrooms']\ntrain_set['adults_per_bedroom'] = train_set['adult']\/train_set['bedrooms']\ntrain_set['child_per_bedroom'] = train_set['hogar_nin']\/train_set['bedrooms']\ntrain_set['male_per_bedroom'] = train_set['r4h3']\/train_set['bedrooms']\ntrain_set['female_per_bedroom'] = train_set['r4m3']\/train_set['bedrooms']\ntrain_set['bedrooms_per_person_household'] = train_set['hhsize']\/train_set['bedrooms']\n\ntest_set['rent_per_bedroom'] = test_set['v2a1']\/test_set['bedrooms']\ntest_set['edler_per_bedroom'] = test_set['hogar_mayor']\/test_set['bedrooms']\ntest_set['adults_per_bedroom'] = test_set['adult']\/test_set['bedrooms']\ntest_set['child_per_bedroom'] = test_set['hogar_nin']\/test_set['bedrooms']\ntest_set['male_per_bedroom'] = test_set['r4h3']\/test_set['bedrooms']\ntest_set['female_per_bedroom'] = test_set['r4m3']\/test_set['bedrooms']\ntest_set['bedrooms_per_person_household'] = test_set['hhsize']\/test_set['bedrooms']\n\ntrain_set['tablet_per_person_household'] = train_set['v18q1']\/train_set['hhsize']\ntrain_set['phone_per_person_household'] = train_set['qmobilephone']\/train_set['hhsize']\ntest_set['tablet_per_person_household'] = test_set['v18q1']\/test_set['hhsize']\ntest_set['phone_per_person_household'] = test_set['qmobilephone']\/test_set['hhsize']\n\ntrain_set['age_12_19'] = train_set['hogar_nin'] - train_set['r4t1']\ntest_set['age_12_19'] = test_set['hogar_nin'] - test_set['r4t1']    \n\ntrain_set['escolari_age'] = train_set['escolari']\/train_set['age']\ntest_set['escolari_age'] = test_set['escolari']\/test_set['age']\n\ntrain_set['rez_esc_escolari'] = train_set['rez_esc']\/train_set['escolari']\ntrain_set['rez_esc_r4t1'] = train_set['rez_esc']\/train_set['r4t1']\ntrain_set['rez_esc_r4t2'] = train_set['rez_esc']\/train_set['r4t2']\ntrain_set['rez_esc_r4t3'] = train_set['rez_esc']\/train_set['r4t3']\ntrain_set['rez_esc_age'] = train_set['rez_esc']\/train_set['age']\ntest_set['rez_esc_escolari'] = test_set['rez_esc']\/test_set['escolari']\ntest_set['rez_esc_r4t1'] = test_set['rez_esc']\/test_set['r4t1']\ntest_set['rez_esc_r4t2'] = test_set['rez_esc']\/test_set['r4t2']\ntest_set['rez_esc_r4t3'] = test_set['rez_esc']\/test_set['r4t3']\ntest_set['rez_esc_age'] = test_set['rez_esc']\/test_set['age']","cab88dc4":"train_set['dependency'] = train_set['dependency'].replace({np.inf: 0})\ntest_set['dependency'] = test_set['dependency'].replace({np.inf: 0})\n\nprint(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\nprint(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')","fafa8b8d":"df_train = pd.DataFrame()\ndf_test = pd.DataFrame()\n\naggr_mean_list = ['rez_esc', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco2',\n             'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12',\n             'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',]\n\nother_list = ['escolari', 'age', 'escolari_age']\n\nfor item in aggr_mean_list:\n    group_train_mean = train_set[item].groupby(train_set['idhogar']).mean()\n    group_test_mean = test_set[item].groupby(test_set['idhogar']).mean()\n    new_col = item + '_aggr_mean'\n    df_train[new_col] = group_train_mean\n    df_test[new_col] = group_test_mean\n\nfor item in other_list:\n    for function in ['mean','std','min','max','sum']:\n        group_train = train_set[item].groupby(train_set['idhogar']).agg(function)\n        group_test = test_set[item].groupby(test_set['idhogar']).agg(function)\n        new_col = item + '_' + function\n        df_train[new_col] = group_train\n        df_test[new_col] = group_test\n\nprint(f'new aggregate train set has {df_train.shape[0]} rows, and {df_train.shape[1]} features')\nprint(f'new aggregate test set has {df_test.shape[0]} rows, and {df_test.shape[1]} features')","d1904f6d":"df_test = df_test.reset_index()\ndf_train = df_train.reset_index()\n\ntrain_agg = pd.merge(train_set, df_train, on='idhogar')\ntest = pd.merge(test_set, df_test, on='idhogar')\n\n#fill all na as 0\ntrain_agg.fillna(value=0, inplace=True)\ntest.fillna(value=0, inplace=True)\nprint(f'new train set has {train_agg.shape[0]} rows, and {train_agg.shape[1]} features')\nprint(f'new test set has {test.shape[0]} rows, and {test.shape[1]} features')","e2f35846":"#According to data descriptions,ONLY the heads of household are used in scoring. \/\n#All household members are included in test + the sample submission, but only heads of households are scored.\ntrain = train_agg.query('parentesco1==1')","06985cef":"submission = test[['Id']]\n\n#Remove useless feature to reduce dimension\ntrain.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\ntest.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n\ncorrelation = train.corr()\ncorrelation = correlation['Target'].sort_values(ascending=False)\nprint(f'The most 20 positive feature: \\n{correlation.head(20)}')\nprint('*'*50)\n\nprint(f'The most 20 negative feature: \\n{correlation.tail(20)}')","6086773e":"y = train['Target']\n\ntrain.drop(columns=['Target'], inplace=True)\n\n#parameter value is copied from \nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='None', \n                             n_jobs=4, n_estimators=5000, class_weight='balanced',\n                             colsample_bytree =  0.93, min_child_samples = 95, num_leaves = 14, subsample = 0.96)","9846342e":"kfold = 5\nkf = StratifiedKFold(n_splits=kfold, shuffle=True)\n\npredicts_result = []\nfor train_index, test_index in kf.split(train, y):\n    print(\"###\")\n    X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n            early_stopping_rounds=400, verbose=100)\n    predicts_result.append(clf.predict(test))","46ec5d8d":"indices = np.argsort(clf.feature_importances_)[::-1]\nindices = indices[:75]\n\n# Visualise these with a barplot\nplt.subplots(figsize=(20, 15))\ng = sns.barplot(y=train.columns[indices], x = clf.feature_importances_[indices], orient='h', palette = mycols)\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=12)\ng.tick_params(labelsize=9)\ng.set_title(\"LightGBM feature importance\");","abc1fe9d":"submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\nsubmission.to_csv('submission.csv', index = False)","fdcb85c2":"It turns out orignial data lost one feature both for **roof** and **electricity**, so we manually add new feature","682d85cd":"## Feature Engineering\n\nReplace object value, because some labels were generated whenever continuous variables have 1 or 0. The rule is to have being 1 yes=1 and no=0","2c11cda3":"## Outlier\n\nI had a look into train and test set, it turned out there is only one outlier value **rez_esc** in test set, and acorrding to the answer from competition host(https:\/\/www.kaggle.com\/c\/costa-rican-household-poverty-prediction\/discussion\/61403), we can safely change the value to 5","16bfba20":"This public kernel is just intended to share my investigation on data exploratory. Since i have another private kernel to continue my work on tuning parameter and explorating more features, so this kernel is lack of visualizaton graph for now, i will try to add more explainations in upcoming commit......","4668f2dc":"## Model - LightGBM \nParameter values are just copied from [Misha Lisovyi](https:\/\/www.kaggle.com\/mlisovyi\/lighgbm-hyperoptimisation-with-f1-macro) for now","210e2281":"*  **rez_esc** represents \"years behind in school\", missing value could be filled as 0\n*  **meaneduc** represents \"average years of education for adults (18+)\", missing value could be filled as 0\n*  **v18q1** really depends on v18q\n*  **v2a1** depends on tipovivi3\n\nWe do not really need SQBxxxx features for polynomial in our case, and i will use fillna as 0 after at the last step of feature engineering","3b4348fb":"More feature engineering ","15a7404a":"## Missing Value"}}