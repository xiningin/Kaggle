{"cell_type":{"8894bbef":"code","c8db128e":"code","b1963150":"code","e4fa2c8d":"code","34011250":"code","e739625e":"code","0ef972a7":"code","44b44d10":"code","70700521":"code","d6ab9bfb":"code","f539d367":"code","98f32f5e":"code","8d5143c2":"code","cd1b0c00":"code","01041bb3":"code","5ba0f15f":"code","0da665b6":"code","71962142":"code","276f4739":"code","b6d49d6b":"code","2e8c46be":"code","808a9926":"code","d8ec1235":"code","1b316afd":"code","8ddc2c66":"code","ccc7f87e":"code","d33b835f":"code","873059a9":"code","9e9bb5d0":"code","a6a09e97":"code","b4412412":"code","0ad85066":"code","15eb6535":"code","3254f368":"code","c6ea5c3a":"code","0b409bfe":"code","8b3a46af":"code","68ec4d69":"code","94dad480":"code","cda60d24":"code","80057019":"code","77ee6e54":"code","30d9eea0":"code","29bc71d4":"code","c570665b":"code","2a95ee58":"code","6575bf53":"code","7c31402a":"code","10c1d094":"code","a783936f":"code","8bde4463":"code","c38d2ca7":"code","b0256387":"code","6d2cd6a9":"code","da2382f1":"code","aa571218":"code","57ecddd3":"code","1f866240":"code","7a2c687b":"code","f86e340c":"code","d99bd424":"code","9657be68":"code","dd326593":"code","95d258a7":"code","9ecfe7b2":"code","975d84b2":"code","e08ad554":"markdown","fdcc54dd":"markdown","c98ce84a":"markdown","47923df5":"markdown","4a652550":"markdown","69d5fd21":"markdown","c9139f2f":"markdown","461935f2":"markdown","cbda243a":"markdown","2bf74e62":"markdown","d01d3d9a":"markdown","41cf5d92":"markdown","a802bcb8":"markdown","b468f843":"markdown","1558200a":"markdown","09e78550":"markdown","b8873fd8":"markdown","ea42edae":"markdown","0055dc63":"markdown","3b944e1b":"markdown","80ac95c6":"markdown","6c8ba3c5":"markdown","42ef59e2":"markdown","9be48b71":"markdown","95c06d2a":"markdown","4fdc8fc9":"markdown","5fbebd5a":"markdown","f633f983":"markdown","9d984173":"markdown","f7a59978":"markdown","e47cfb64":"markdown","fe5298b4":"markdown","8524e74a":"markdown","7e6e40d3":"markdown"},"source":{"8894bbef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8db128e":"#!pip install jcopml","b1963150":"!pip install jcopml","e4fa2c8d":"from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score, cross_validate\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom time import time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom tqdm.auto import tqdm\nfrom jcopml.tuning.space import Integer, Real","34011250":"pd.set_option('display.max_columns', None)","e739625e":"random_state = 42","0ef972a7":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","44b44d10":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","70700521":"train_data.isna().sum()","d6ab9bfb":"test_data.isna().sum()","f539d367":"train_data[\"Train_data\"] = 1\ntest_data[\"Train_data\"] = 0\ntest_data[\"Survived\"] = np.nan\n\ndf = pd.concat([train_data, test_data], ignore_index=True)\ndf.head()","98f32f5e":"def extract_title(data):\n    titles = np.array([])\n    for x in data[\"Name\"]:\n        name_disected = x.split(\" \")\n        for part in name_disected:\n            if \".\" in part:\n                if len(part) > 2:\n                    titles= np.append(titles, part.rstrip(\".\"))\n                    \n    data[\"Title\"] = titles\n    print(titles)","8d5143c2":"extract_title(df)\ndf.head()","cd1b0c00":"title_survived = df.Title[(df.Train_data==1) & (df.Survived ==1)].value_counts()\ntitle_notsurvived = df.Title[(df.Train_data==1) & (df.Survived ==0)].value_counts()","01041bb3":"fig, ax = plt.subplots(figsize=(18,5))\nx = np.arange(len(title_survived.index))\nwidth = 0.35 \nplt.title('Frequency of Title Survived')\nax.bar(x + width\/2, title_survived.values, width=width)\nax.set_xticks(x)\nax.set_xticklabels(title_survived.index)\nplt.show()","5ba0f15f":"fig, ax = plt.subplots(figsize=(18,5))\nx = np.arange(len(title_notsurvived.index))\nwidth = 0.35  # the width of the bars\nplt.title('Frequency of Title not Survived')\nax.bar(x + width\/2, title_notsurvived.values, width=width, color = 'orange')\nax.set_xticks(x)\nax.set_xticklabels(title_notsurvived.index)\nplt.show()","0da665b6":"plt.figure(figsize=(22,5))\nplt.bar(df.Age.value_counts().index, df.Age.value_counts().values)\n# plt.xticks(df.Age.value_counts().index)\nplt.title('Frequency of Ages')\nplt.show()","71962142":"# grouping age refers to : https:\/\/www.scribd.com\/doc\/151484440\/Kategori-Umur-Menurut-Depkes-RI\n\ndef grouping_age(data):\n    age_group = np.array([])\n    for age in data[\"Age\"]:\n        if age <= 5:\n            age_group = np.append(age_group, \"Babies\")\n        elif age <= 11:\n            age_group = np.append(age_group, \"Child\")\n        elif age <= 25:\n            age_group = np.append(age_group, \"Youth\")\n        elif age <= 45:\n            age_group = np.append(age_group, \"Adult\")\n        elif age <= 65:\n            age_group = np.append(age_group, \"Old Adult\")\n        elif age > 65:\n            age_group = np.append(age_group, \"Senior\")\n        else:\n            age_group = np.append(age_group, np.nan)\n            \n    data[\"Age_group\"] = age_group\n    print(age_group)","276f4739":"grouping_age(df)\ndf.head()","b6d49d6b":"fig, ax = plt.subplots(figsize=(18,5))\nplt.title('Frequency of Age_group')\nx = np.arange(len(df.Age_group.value_counts().index))\nwidth = 0.35\nax.bar(x, df.Age_group.value_counts().values, width=width)\nax.set_xticks(x)\nax.set_xticklabels(df.Age_group[(df.Train_data==1)].value_counts().index)\nax.legend()\nplt.show()","2e8c46be":"fig, ax = plt.subplots(figsize=(18,5))\nplt.title('Frequency of Age_group')\nx = np.arange(len(df.Age_group[(df.Train_data==1)].value_counts().index))\nwidth = 0.35  # the width of the bars\nax.bar(x + width\/2, df.Age_group[(df.Train_data==1)].value_counts().values, width=width, label = 'Train Data')\nax.bar(x - width\/2, df.Age_group[(df.Train_data==0)].value_counts().values, width=width, label = 'Test Data')\nax.set_xticks(x)\nax.set_xticklabels(df.Age_group[(df.Train_data==1)].value_counts().index)\nax.legend()\nplt.show()","808a9926":"age_group_survived = df.Age_group[(df.Train_data==1) & (df.Survived ==1)].value_counts()\nage_group_notsurvived = df.Age_group[(df.Train_data==1) & (df.Survived ==0)].value_counts()","d8ec1235":"fig, ax = plt.subplots(figsize=(18,5))\nplt.title('Frequency of Age_group Survived')\nx = np.arange(len(age_group_survived.index))\nwidth = 0.35\nax.bar(x + width\/2, age_group_notsurvived.values, width=width, label = 'Not Survived', color='orange')\nax.bar(x - width\/2, age_group_survived.values, width=width, label = 'Survived')\nax.set_xticks(x)\nax.set_xticklabels(age_group_survived.index)\nax.legend()\nplt.show()","1b316afd":"pd.crosstab(df[\"Title\"][df.Survived==1], df[\"Age_group\"]).plot(kind=\"bar\", figsize=(18, 5));\nplt.title('Correlation between Title, Age_group and Survived');","8ddc2c66":"pd.crosstab(df[\"Title\"][df.Survived==0], df[\"Age_group\"]).plot(kind=\"bar\", figsize=(18, 5));\nplt.title('Correlation between Title, Age_group and Not Survived');","ccc7f87e":"#check missing value of Fare coloms\nprint('Missing : ', df.Fare.isnull().sum())\ndf[df.Fare.isnull()]","d33b835f":"#imoute using median\ndf.Fare[df.Fare.isnull()] = df.Fare.median()\ndf.iloc[1043,:]","873059a9":"plt.title('Frequency of Fare')\nplt.hist(df.Fare[(df[\"Train_data\"]==1)], color='g');\nplt.xlabel('Fare');","9e9bb5d0":"plt.title('Frequency of Fare Survived')\nplt.hist(df.Fare[(df[\"Train_data\"]==1)&(df.Survived == 1)]);\nplt.xlabel('Fare');","a6a09e97":"plt.title('Frequency of Fare not Survived')\nplt.hist(df.Fare[(df[\"Train_data\"]==1)&(df.Survived == 0)], color='orange');","b4412412":"def grouping_fare(data):\n    fare_group = np.array([])\n    for fare in data[\"Fare\"]:\n        if fare <= 150:\n            fare_group = np.append(fare_group, 1) #low\n        elif fare <= 350:\n            fare_group = np.append(fare_group, 2) #medium\n        elif fare > 350:\n            fare_group = np.append(fare_group, 3) #high\n        else:\n            fare_group = np.append(fare_group, fare)\n            \n    data[\"Fare_group\"] = fare_group\n    print(fare_group)","0ad85066":"grouping_fare(df)\ndf.head()","15eb6535":"fig, ax = plt.subplots(figsize=(18,5))\nplt.title('Frequency of Fare_group')\nx = np.arange(len(df.Fare_group[df.Train_data == 1].value_counts().index))\nwidth = 0.35\nax.bar(x, df.Fare_group.value_counts().values, width=width, label = 'Fare_group')\n# ax.bar(x - width\/2, df.Fare_group[(df.Train_data==0)].value_counts().values, width=width, label = 'Test Data')\nax.set_xticks(x)\nax.set_xticklabels(df.Fare_group[(df.Train_data==1)].value_counts().index)\nax.legend()\nax.set_xlabel('Fare_group')\nplt.show()","3254f368":"fare_group_survived = df.Fare_group[(df.Train_data==1) & (df.Survived ==1)].value_counts()\nfare_group_notsurvived = df.Fare_group[(df.Train_data==1) & (df.Survived ==0)].value_counts()","c6ea5c3a":"plt.title('Frequency of Fare_group Survived')\nplt.bar(fare_group_survived.index, fare_group_survived.values)\nplt.xticks(fare_group_survived.index)\nplt.show()","0b409bfe":"plt.title('Frequency of Fare_group not Survived')\nplt.bar(fare_group_notsurvived.index, fare_group_notsurvived.values, color='orange')\nplt.xticks(fare_group_notsurvived.index)\nplt.show()","8b3a46af":"fig, ax = plt.subplots(1, 3, figsize = (22, 7))\nfig.suptitle('Correlation between Fare_group and Title');\nax[0] = pd.crosstab(df.Fare_group[(df.Fare_group==1) & (df.Train_data ==1)], df[\"Title\"]).plot(kind=\"bar\", ax=ax[0])\nax[1] = pd.crosstab(df.Fare_group[(df.Fare_group==2) & (df.Train_data ==1)], df[\"Title\"]).plot(kind=\"bar\", ax=ax[1])\nax[2] = pd.crosstab(df.Fare_group[(df.Fare_group==3) & (df.Train_data ==1)], df[\"Title\"]).plot(kind=\"bar\", ax=ax[2]);","68ec4d69":"fig, ax = plt.subplots(1, 3, figsize = (22, 7))\nfig.suptitle('Correlation between Fare_group and Age_group');\nax[0] = pd.crosstab(df.Fare_group[(df.Fare_group==1) & (df.Train_data ==1)], df[\"Age_group\"]).plot(kind=\"bar\", ax=ax[0]);\nax[1] = pd.crosstab(df.Fare_group[(df.Fare_group==2) & (df.Train_data ==1)], df[\"Age_group\"]).plot(kind=\"bar\", ax=ax[1]);\nax[2] = pd.crosstab(df.Fare_group[(df.Fare_group==3) & (df.Train_data ==1)], df[\"Age_group\"]).plot(kind=\"bar\", ax=ax[2]);","94dad480":"#check missing value\nprint('Missing : ',df.Embarked.isnull().sum())\ndf[df.Embarked.isnull()]","cda60d24":"#impute using mode\nnan_embarked_idx = df[df.Embarked.isnull()].index\ndf.Embarked[df.Embarked.isnull()] = df.Embarked.mode()[0]\ndf.iloc[nan_embarked_idx, :]","80057019":"#label encoder to encode column to numeric\ndf.Sex = LabelEncoder().fit_transform(df.Sex)\ndf.head()","77ee6e54":"print('Missing : ', df.Age.isnull().sum())","30d9eea0":"df_age = df.drop(columns=['Age','Cabin', 'Fare', 'Name', 'PassengerId', 'Ticket', 'Survived', 'Train_data'])\ndf_age.head()","29bc71d4":"#one hot encoding and label endocing for categorical feature\ndf_age = pd.get_dummies(df_age, columns=['Embarked', 'Title'])\ndf_age.Age_group = LabelEncoder().fit_transform(df_age.Age_group)\ndf_age.head()","c570665b":"train_age = df_age[df_age.Age_group != 6] #Age group != nan\nX_test_age = df_age[df_age.Age_group == 6].drop(columns=['Age_group']) #Age group == nan\nX_train_age = train_age.drop(columns=['Age_group'])\ny_train_age = train_age.Age_group\nX_train_age.shape, y_train_age.shape","2a95ee58":"# 1 = Babies\n# 2 = Child\n# 3 = Old Adult\n# 4 = Senior\n# 5 = Youth\ny_train_age.value_counts()","6575bf53":"X_train_dump, X_test_dump, y_train_dump, y_test_dump = train_test_split(X_train_age, y_train_age, test_size=0.3, stratify=y_train_age, random_state=random_state)\nX_train_dump.shape, X_test_dump.shape, y_train_dump.shape, y_test_dump.shape","7c31402a":"params = {\n    'max_depth': Integer(low=1, high=10),\n    'learning_rate': Real(low=0.01, high=0.5, prior='uniform'),\n    'n_estimators': Integer(low=1, high=200),\n    'subsample': Real(low=0.25, high=0.75, prior='uniform'),\n}\n\nxgb = XGBClassifier(\n    eval_metric='logloss',\n    use_label_encoder=False,\n    random_state=random_state,\n)\n\nxgb = RandomizedSearchCV(xgb, params, cv=5, n_iter=30, random_state=random_state, return_train_score=True, verbose=1)\nxgb.fit(X_train_dump, y_train_dump)\nprint('Train cv score : ', xgb.cv_results_['mean_train_score'][np.argmax(xgb.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', xgb.best_score_)\nprint('Train score    : ', xgb.score(X_train_dump, y_train_dump))\nprint('Test score     : ', xgb.score(X_test_dump, y_test_dump))","10c1d094":"from sklearn.ensemble import RandomForestClassifier","a783936f":"params = {\n    'n_estimators': Integer(low=100, high=200),\n    'max_depth': Integer(low=20, high=80),\n    'max_features': Real(low=0.1, high=1, prior='uniform'),\n    'min_samples_leaf': Integer(low=1, high=20)\n}\n\nrf = RandomForestClassifier(random_state=random_state)\n\nrf = RandomizedSearchCV(rf, params, cv=5, n_iter=30, random_state=random_state, return_train_score=True, verbose=1)\nrf.fit(X_train_dump, y_train_dump)\nprint('Train cv score : ', rf.cv_results_['mean_train_score'][np.argmax(rf.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', rf.best_score_)\nprint('Train score    : ', rf.score(X_train_dump, y_train_dump))\nprint('Test score     : ', rf.score(X_test_dump, y_test_dump))","8bde4463":"from sklearn.svm import SVC","c38d2ca7":"params = {\n    'gamma': Real(low=-3, high=3, prior='log-uniform'),\n    'C': Real(low=-3, high=3, prior='log-uniform')\n}\n\nsvm = SVC()\n\nsvm = RandomizedSearchCV(svm, params, cv=5, n_iter=30, random_state=random_state, return_train_score=True, verbose=1)\nsvm.fit(X_train_dump, y_train_dump)\nprint('Train cv score : ', svm.cv_results_['mean_train_score'][np.argmax(svm.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', svm.best_score_)\nprint('Train score    : ', svm.score(X_train_dump, y_train_dump))\nprint('Test score     : ', svm.score(X_test_dump, y_test_dump))","b0256387":"from sklearn.neighbors import KNeighborsClassifier","6d2cd6a9":"params = {\n    'n_neighbors': Integer(low=1, high=40),\n    'weights': ['uniform', 'distance'],\n    'p': Real(low=1, high=2, prior='uniform')\n}\n\nknn = KNeighborsClassifier()\n\nknn = RandomizedSearchCV(knn, params, cv=5, n_iter=30, n_jobs=-1, random_state=random_state, return_train_score=True, verbose=1)\nknn.fit(X_train_dump, y_train_dump)\nprint('Train cv score : ', knn.cv_results_['mean_train_score'][np.argmax(knn.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', knn.best_score_)\nprint('Train score    : ', knn.score(X_train_dump, y_train_dump))\nprint('Test score     : ', knn.score(X_test_dump, y_test_dump))","da2382f1":"df_final = df.drop(columns=['Age','Cabin', 'Fare', 'Name', 'PassengerId', 'Ticket'])\ndf_final = pd.get_dummies(df_final, columns=['Embarked', 'Title'])\ndf_final.Age_group = LabelEncoder().fit_transform(df_final.Age_group)\ndf_final.head()","aa571218":"age_predict = xgb.predict(X_test_age)","57ecddd3":"df_final.Age_group[df_final.Age_group == 6] = age_predict","1f866240":"X_train = df_final[df_final.Train_data==1].drop(columns=['Train_data', 'Survived'])\ny_train = df_final.Survived[df_final.Train_data==1]\nX_test = df_final[df_final.Train_data==0].drop(columns=['Train_data', 'Survived'])\nX_train.shape, y_train.shape, X_test.shape","7a2c687b":"X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=random_state)\nX_train_split.shape, X_test_split.shape, y_train_split.shape, y_test_split.shape","f86e340c":"params = {\n    'max_depth': Integer(low=1, high=10),\n    'learning_rate': Real(low=0.01, high=0.5, prior='uniform'),\n    'n_estimators': Integer(low=1, high=200),\n    'subsample': Real(low=0.25, high=0.75, prior='uniform'),\n}\n\nxgb_final = XGBClassifier(\n    eval_metric='logloss',\n    use_label_encoder=False,\n    random_state=random_state,\n)\n\nxgb_final = RandomizedSearchCV(xgb_final, params, cv=5, n_iter=30, random_state=random_state, return_train_score=True)\nxgb_final.fit(X_train_split, y_train_split)\nprint('Train cv score : ', xgb_final.cv_results_['mean_train_score'][np.argmax(xgb_final.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', xgb_final.best_score_)\nprint('Train score    : ', xgb_final.score(X_train_split, y_train_split))\nprint('Test score     : ', xgb_final.score(X_test_split, y_test_split))","d99bd424":"params = {\n    'n_estimators': Integer(low=100, high=200),\n    'max_depth': Integer(low=20, high=80),\n    'max_features': Real(low=0.1, high=1, prior='uniform'),\n    'min_samples_leaf': Integer(low=1, high=20)\n}\n\nrf_final = RandomForestClassifier(random_state=random_state)\n\nrf_final = RandomizedSearchCV(rf_final, params, cv=5, n_iter=30, random_state=random_state, return_train_score=True)\nrf_final.fit(X_train_split, y_train_split)\nprint('Train cv score : ', rf_final.cv_results_['mean_train_score'][np.argmax(rf_final.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', rf_final.best_score_)\nprint('Train score    : ', rf_final.score(X_train_split, y_train_split))\nprint('Test score     : ', rf_final.score(X_test_split, y_test_split))","9657be68":"params = {\n    'gamma': Real(low=-3, high=3, prior='log-uniform'),\n    'C': Real(low=-3, high=3, prior='log-uniform')\n}\n\nsvm_final = SVC()\n\nsvm_final = RandomizedSearchCV(svm_final, params, cv=5, n_iter=30, n_jobs=-1, random_state=random_state, return_train_score=True)\nsvm_final.fit(X_train_split, y_train_split)\nprint('Train cv score : ', svm_final.cv_results_['mean_train_score'][np.argmax(svm_final.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', svm_final.best_score_)\nprint('Train score    : ', svm_final.score(X_train_split, y_train_split))\nprint('Test score     : ', svm_final.score(X_test_split, y_test_split))","dd326593":"params = {\n    'n_neighbors': Integer(low=1, high=40),\n    'weights': ['uniform', 'distance'],\n    'p': Real(low=1, high=2, prior='uniform')\n}\n\nknn_final = KNeighborsClassifier()\n\nknn_final = RandomizedSearchCV(knn_final, params, cv=5, n_iter=30, n_jobs=-1, random_state=random_state, return_train_score=True, verbose=1)\nknn_final.fit(X_train_split, y_train_split)\nprint('Train cv score : ', knn_final.cv_results_['mean_train_score'][np.argmax(knn_final.cv_results_['mean_test_score'])])\nprint('Val cv Score   : ', knn_final.best_score_)\nprint('Train score    : ', knn_final.score(X_train_split, y_train_split))\nprint('Test score     : ', knn_final.score(X_test_split, y_test_split))","95d258a7":"model = RandomForestClassifier(**rf_final.best_estimator_.get_params())\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.astype(int)})","9ecfe7b2":"# output","975d84b2":"output.to_csv('submission-rf.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e08ad554":"#### SVM","fdcc54dd":"# Final Training and Predict using XGBoost","c98ce84a":"From the picture above it can be seen that all passengers with high fares survived","47923df5":"#### Split Final Data","4a652550":"## Dealing with Age column","69d5fd21":"###### ","c9139f2f":"#### XGBoost","461935f2":"#### Impute Age from prediction","cbda243a":"# Modeling","2bf74e62":"# Import Data","d01d3d9a":"#### Create Final Training Data","41cf5d92":"## SVM","a802bcb8":"From the picture above, it can be seen that adults and youth with the titles of Mr have the highest not survived frequencies","b468f843":"#### Use XGBoost to predict Age","1558200a":"# Concat the Data","09e78550":"### Split dataset","b8873fd8":"# Dealing with Sex column","ea42edae":"### Classification and Hyper-parameter Tuning","0055dc63":"# Grouping Fare","3b944e1b":"### Create Dataset for predict Age","80ac95c6":"## Random Forest","6c8ba3c5":"# Dealing with Embarked column","42ef59e2":"From the picture above, it can be seen that adults and youth with the titles of Miss, Mr and Mrs have the highest survived frequencies","9be48b71":"From the picture above, it can be seen that the highest Fare frequency is between 0 to 150. High fare has a higher chance of surviving than low fare","95c06d2a":"#### Random Forest","4fdc8fc9":"## Extrack Title from Name columns","5fbebd5a":"# Dealing with Fare Column","f633f983":"# Import Common Packages","9d984173":"#### KNN","f7a59978":"## KNN","e47cfb64":"## Predict Age column to inpute missing values","fe5298b4":"### Grouping Age","8524e74a":"# Dealing missing value in column x","7e6e40d3":"# Quick EDA"}}