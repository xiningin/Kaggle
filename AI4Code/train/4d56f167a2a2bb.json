{"cell_type":{"74454cce":"code","cef1fdf4":"code","9780b6ef":"code","a2c5ae6e":"code","7a49dc69":"code","700b01b8":"code","4d9b82fa":"code","d36ad577":"code","fcef3a82":"code","9aeb9d1c":"code","b462f1f9":"code","5aadb624":"code","ae6da4ea":"code","3a989d2f":"code","4e97ad97":"code","115110da":"code","43ec13b8":"code","dbc74a83":"code","60b3efa4":"code","d4d2f313":"code","69b2bb47":"code","bbd038d3":"code","8ad57b09":"code","bbadc661":"code","db920689":"code","d85dd32d":"code","eda17979":"code","e3130ef3":"code","a2e2c3ba":"code","8b761808":"code","16b926ea":"code","ce21dc75":"code","5204507b":"code","23d7fca5":"code","5dcc0eb9":"code","b7bfa3f0":"code","ef2f745a":"code","72c1039c":"code","dc10b2d8":"code","ae0e071c":"code","3f5f34ba":"code","be4048c3":"code","976a3d39":"code","1b79ea51":"code","e8bf369c":"markdown","b39aa5b6":"markdown","2dc01de2":"markdown","cb0db9ac":"markdown","0b1f4423":"markdown","f80c2460":"markdown","1b80153c":"markdown","2f9d87f2":"markdown","3aceaebc":"markdown","4144cbc3":"markdown","246178f2":"markdown","dd34e9c5":"markdown","5a83df18":"markdown","d73903d9":"markdown","29ddc1f9":"markdown","026c322a":"markdown","2f233198":"markdown","e434ca05":"markdown","ed7a22f8":"markdown","a299a884":"markdown"},"source":{"74454cce":"import numpy as np\nimport pandas as pd","cef1fdf4":"# Reading Data\nmovies = pd.read_csv(\"..\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")\ncredits = pd.read_csv(\"..\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv\")","9780b6ef":"credits.columns","a2c5ae6e":"movies.head(2)","7a49dc69":"credits.head(2)","700b01b8":"# Merging movies and credits dataframe on title and storing in another dataframe\ndf = movies.merge(credits , on='title')","4d9b82fa":"df.info()","d36ad577":"''' For this project\n    We will be making a tags feature which we will use to make our model, \n    for this we will only take features with text like genres, overview, cast, crew'''\n\n# Selecting the features we want to use for our recommender system\n\n# genres\n# id\n# keywords\n# title\n# overview\n# cast\n# crew\n\ndf = df[['id','genres','keywords','title','overview','cast','crew']]\n","fcef3a82":"df.head(2)","9aeb9d1c":"# Checking for NULL Values\ndf.isnull().sum()","b462f1f9":"# Checking for Duplicated samples\ndf.duplicated().sum()","5aadb624":"# Dropping NULL Values\n# There are only 3 Null samples out of 4809 so we can simply drop them\ndf.dropna(inplace=True)","ae6da4ea":"df.iloc[0].genres","3a989d2f":"import ast # To convert the sting of list to list\n\ndef get_features(lst):\n    feat = []\n    for i in ast.literal_eval(lst):\n        feat.append(i['name'])\n    return feat\n","4e97ad97":"# Genres column after cleaning\ndf['genres'].apply(get_features)","115110da":"# Extracting genres and keywords from data and saving back in dataframe\n\ndf['genres'] = df['genres'].apply(get_features)\ndf['keywords'] = df['keywords'].apply(get_features)\ndf.head(2)\n","43ec13b8":"# Function to extract top 4 cast names\ndef get_cast(str):\n    cast = []\n    flag = 0\n    for i in ast.literal_eval(str):\n        if flag<4:\n            cast.append(i['name'])\n        flag = flag + 1\n    return cast","dbc74a83":"df['cast'] = df['cast'].apply(get_cast)\ndf.head(2)","60b3efa4":"# Function to extract director name\ndef get_director(str):\n    director = []\n    for i in ast.literal_eval(str):\n        if i['job'] == 'Director':\n            director.append(i['name'])\n    return director","d4d2f313":"df['crew'] = df['crew'].apply(get_director)\ndf.head(2)\n","69b2bb47":"'''There are spaces between elements of features,\n    like space between first name and last name of cast which can result in model taking them as different elements,\n    for that we have to remove space between them'''\n\n# Function to remove space between elements\ndef remove_space(feature):\n    new_feat = []\n    for i in feature:\n        new_feat.append(i.replace(\" \",\"\"))\n    return new_feat","bbd038d3":"df['cast'] = df['cast'].apply(remove_space)\ndf['crew'] = df['crew'].apply(remove_space)\ndf['genres'] = df['genres'].apply(remove_space)\ndf['keywords'] = df['keywords'].apply(remove_space)\ndf.head(2)","8ad57b09":"df['overview'].iloc[0]\n","bbadc661":"# Converting overview into list also\ndf['overview'] = df['overview'].apply(lambda x:x.split())\n\n# Making a new column 'tags' which is made by combining all features\ndf['tags'] = df['overview'] + df['genres'] + df['keywords'] + df['cast'] + df['crew']\n","db920689":"df.head(2)","d85dd32d":"# Making a final dataframe which will be used to train our model\nfinal_dataset = df[['id','title','tags']]","eda17979":"final_dataset.head()","e3130ef3":"final_dataset['tags'] = final_dataset['tags'].apply(lambda x: \" \".join(x))\nfinal_dataset.head()","a2e2c3ba":"# Converting all the tags to lowercase\nfinal_dataset['tags'] = final_dataset['tags'].apply(lambda x : x.lower())","8b761808":"from nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer()\n\ndef stemming(text):\n    stemmed_output = []\n    for i in text.split():\n        stemmed_output.append(stemmer.stem(i))\n    string = \" \".join(stemmed_output)\n    return string","16b926ea":"final_dataset['tags'] = final_dataset['tags'].apply(stemming)","ce21dc75":"final_dataset.head()","5204507b":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=7000,stop_words='english')","23d7fca5":"cv_vector = cv.fit_transform(final_dataset['tags']).toarray()","5dcc0eb9":"cv_vector.shape","b7bfa3f0":"from sklearn.metrics.pairwise import cosine_similarity\ncv_similarity_matrix = cosine_similarity(cv_vector)","ef2f745a":"cv_similarity_matrix.shape","72c1039c":"cv_similarity_matrix","dc10b2d8":"from sklearn.feature_extraction.text import TfidfVectorizer \n\ntf=TfidfVectorizer(stop_words=\"english\",max_features=7000)\ntf_vector= tf.fit_transform(final_dataset['tags']).toarray()\ntf_similarity_matrix = cosine_similarity(tf_vector)","ae0e071c":"from sklearn.feature_extraction.text import HashingVectorizer\n\nhv=HashingVectorizer(stop_words=\"english\",n_features=7000)\nhv_vector= hv.fit_transform(final_dataset['tags']).toarray()\nhv_similarity_matrix = cosine_similarity(hv_vector)\n","3f5f34ba":"def recommend(movie,vectorizer='tfidf'):\n    \n    index = final_dataset[final_dataset['title'] == movie].index[0]\n    \n    if(vectorizer=='tfidf'):\n        similarity_score = sorted(list(enumerate(tf_similarity_matrix[index])),reverse=True,key = lambda x: x[1])\n        \n    elif(vectorizer=='cv'):\n        similarity_score = sorted(list(enumerate(cv_similarity_matrix[index])),reverse=True,key = lambda x: x[1])\n        \n    elif(vectorizer=='hv'):\n        similarity_score = sorted(list(enumerate(hv_similarity_matrix[index])),reverse=True,key = lambda x: x[1])\n        \n    for i in similarity_score[1:6]:\n        print(final_dataset.iloc[i[0]].title)","be4048c3":"recommend('The Avengers','tfidf')","976a3d39":"recommend('The Avengers','cv')","1b79ea51":"recommend('The Avengers','hv')","e8bf369c":"## Conclustion\n**The predictions with different vectorization techniques is obtained. To check\nwhich recommendations are better we can deploy this model and check for\nmetrics like Customer Lifetime Value (CLTV), Click-Through Rate (CTR).**","b39aa5b6":"## Training Model","2dc01de2":"'\n[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]\n'\n\nWe have to extract genres from the list of dictionaries above\n It should be like : ['Action', 'Adventure', 'Fantasy', 'Science Fiction']\n\n","cb0db9ac":"As you can see with the get_features function we have successfully extracted genres\n\nNow we will apply the same to keywords column also and store them back in our dataframe","0b1f4423":"## Data Analysis","f80c2460":"# Movie Recommendation Systems \n\nMovies Recommendation Systems can be of two types\n- Content based\n- Collaborative\n\n**Content-Based Filtering:**\nThis filtration strategy is based on the data provided about the items. The algorithm recommends products that are similar to the ones that a user has liked in the past. This similarity (generally cosine similarity) is computed from the data we have about the items as well as the user\u2019s past preferences.\nFor example, if a user likes movies such as \u2018The Prestige\u2019 then we can recommend him the movies of \u2018Christian Bale\u2019 or movies with the genre \u2018Thriller\u2019 or maybe even movies directed by \u2018Christopher Nolan\u2019.So what happens here the recommendation system checks the past preferences of the user and find the film \u201cThe Prestige\u201d, then tries to find similar movies to that using the information available in the database such as the lead actors, the director, genre of the film, production house, etc and based on this information find movies similar to \u201cThe Prestige\u201d.\n\n\n\n**Collaborative Filtering:**\nThis filtration strategy is based on the combination of the user\u2019s behavior and comparing and contrasting that with other users\u2019 behavior in the database. The history of all users plays an important role in this algorithm. The main difference between content-based filtering and collaborative filtering that in the latter, the interaction of all users with the items influences the recommendation algorithm while for content-based filtering only the concerned user\u2019s data is taken into account.\nThere are multiple ways to implement collaborative filtering but the main concept to be grasped is that in collaborative filtering multiple user\u2019s data influences the outcome of the recommendation. and doesn\u2019t depend on only one user\u2019s data for modeling.\n\n\n","1b80153c":"## Predictions","2f9d87f2":"**We also have to do stemming of the tags.\nStemming is basically removing the suffix from a word and reduce it to its root word.\nThe main aim is to reduce the inflectional forms of each word into a common base word or root word or stem word.**","3aceaebc":"cv_similarity_matrix is 4806 x 4806 matrix,\n\nin which (i,j)th element is the similarity between i'th movie and j'th movie","4144cbc3":"**In this project we will be implementing Content based movie recommender. We will be making tags based on Genre, Cast, Director and storyline and then we will calculate similarity score based on tags using CosineSimilarity to make our recommendations based on the movie entered by user.**","246178f2":"##  Importing Libaries","dd34e9c5":"Predictions if **HashingVectorizer** is  used for vectorization","5a83df18":"![banner2.png](attachment:banner2.png)","d73903d9":"![Capture.PNG](attachment:Capture.PNG)","29ddc1f9":"## Data Cleaning","026c322a":"- For training model we first have to vectorize our tags which are in text format.\n- Then we will use CosineSimillarity to find similar vectors so that we make make recommendation\n- We will use 3 vectorization techniques(CountVectorizer, TfidfVectorizer, HashingVectorizer) and compare the results from them","2f233198":"Predictions if **TfidfVectorizer** is  used for vectorization","e434ca05":"### Cosine Similarity\n**To Find the similarity between movies, we using use cosine_similarity**\n\n**The cosine similarity helps overcome this fundamental flaw in the \u2018count-thecommon-words\u2019 or Euclidean distance approach. Mathematically, it measures\nthe cosine of the angle between two vectors projected in a multi-dimensional\nspace.**\n\n![cosineSimilarity.png](attachment:cosineSimilarity.png)\n\n**The cosine similarity is described mathematically as the division between the\ndot product of vectors and the product of the euclidean norms or magnitude of\neach vector**","ed7a22f8":"There are 4809 movies in this dataset\n\nFeatures which can be used for making recommendations:\n\n    - Budget\n    - Genres\n    - Keywords\n    - Original Language\n    - Overview \n    - Popularity\n    - Production Company\n    - Production countries\n    - Release data\n    - Revenue\n    - Vote Average\n    - Vote Count\n    - Cast\n    - Crew","a299a884":"Predictions if **CountVectorizer** is  used for vectorization"}}