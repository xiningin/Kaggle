{"cell_type":{"5a57e5ca":"code","2eb3e2b0":"code","8af5d8c4":"code","0fc919e4":"code","a5ac8047":"code","996d67c7":"code","c818cd91":"code","f00edbbe":"code","d6abef69":"code","78d8aa15":"code","beb5f870":"code","a1603c63":"code","36fc7004":"code","a89297ab":"code","fd9a4e57":"code","969e8bbe":"code","cc72dd3e":"code","a673f02d":"code","98a16b19":"code","1f0e0529":"code","f2dc3289":"code","8a0f782d":"code","dd250d1a":"code","c8d921f8":"code","d7c8d11e":"code","bd9dae8d":"code","5ea6e617":"code","6eff2653":"code","95e82ffa":"code","f35a216e":"markdown","f09484c8":"markdown","6c0d5a4f":"markdown","c6d4d306":"markdown","34ebe82a":"markdown","79fe7059":"markdown","e3b25215":"markdown","2f47e545":"markdown","18ddc817":"markdown","3faf3aaa":"markdown","a0a3dda9":"markdown","7e5386e4":"markdown","700f8337":"markdown","b481bcbd":"markdown","5a70b9ea":"markdown","02f752ca":"markdown","8923fa09":"markdown","6e8ebf97":"markdown"},"source":{"5a57e5ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gpxpy\nimport folium\nimport seaborn as sns\nfrom sklearn.cluster import DBSCAN\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2eb3e2b0":"gps1 = open('\/kaggle\/input\/criminal-location-tracking\/GPS_Data\/GPS 1.gpx', 'r')\ngps1 = gpxpy.parse(gps1)\n\ngps2 = open('\/kaggle\/input\/criminal-location-tracking\/GPS_Data\/GPS 2.gpx', 'r')\ngps2 = gpxpy.parse(gps2)","8af5d8c4":"gps_arr1 = []\ngps_arr2 = []\nfor data in gps1.waypoints:\n    gps_arr1.append([data.latitude, data.longitude, data.time])\n    \nfor data in gps2.waypoints:\n    gps_arr2.append([data.latitude, data.longitude, data.time])","0fc919e4":"gps1 = pd.DataFrame(gps_arr1, columns=['latitude', 'longitude', 'time'])\ngps2 = pd.DataFrame(gps_arr2, columns=['latitude', 'longitude', 'time'])\ngps1['suspect'] = 1\ngps2['suspect'] = 2","a5ac8047":"gps1.head()","996d67c7":"gps2.head()","c818cd91":"print(gps1.shape, gps2.shape)","f00edbbe":"data = pd.concat([gps1, gps2], axis=0)","d6abef69":"data['datetime'] = pd.to_datetime(data['time'])\ndata['date'] = data['datetime'].dt.date\ndata['time'] = data['datetime'].dt.time\ndata['hour'] = data['datetime'].dt.hour","78d8aa15":"data.shape","beb5f870":"data.sample(5)","a1603c63":"data.isna().sum()","36fc7004":"data.nunique()","a89297ab":"print(data['time'].min(), data['time'].max())","fd9a4e57":"dbscan = DBSCAN(eps=0.0005, min_samples=1)\nclusters = dbscan.fit_predict(data[['latitude', 'longitude']].values)\ndata['clusters'] = clusters\nlen(data['clusters'].unique())","969e8bbe":"grouped = data.groupby(['clusters', 'suspect'])['hour'].count().reset_index()\ngrouped.columns = ['clusters', 'suspect', 'total_suspect_app']","cc72dd3e":"c_1 = grouped[grouped['suspect']==1]\nc_2 = grouped[grouped['suspect']==2]\n\ngrouped = c_1.merge(c_2, on='clusters')\ndel c_1, c_2","a673f02d":"grouped","98a16b19":"cluster_more_than_1 = grouped['clusters']","1f0e0529":"data['more_than_1'] = data['clusters'].isin(cluster_more_than_1)","f2dc3289":"data = data[data['more_than_1']==True]","8a0f782d":"data.shape","dd250d1a":"for h in data['hour'].unique():\n    d = data[data['hour']==h]\n    suspect_list = d['suspect'].values.tolist()\n    if 1 in suspect_list and 2 in suspect_list:\n        print(\"Suspects tracing for hour \" + str(h))\n        plt.figure(figsize=(15,5))\n        sns.scatterplot(x='latitude', y='longitude', data=data[data['hour']==h], hue='clusters', style='suspect')\n        plt.show()\n    ","c8d921f8":"def mapping(x):\n    temp = data[data['hour']==x]\n    suspect1_trace = list(zip(temp[temp['suspect']==1]['latitude'].to_list(),temp[temp['suspect']==1]['longitude'].to_list()))\n    suspect2_trace = list(zip(temp[temp['suspect']==2]['latitude'].to_list(),temp[temp['suspect']==2]['longitude'].to_list()))\n    m = folium.Map(location=[temp['latitude'].mean(), temp['longitude'].mean()], zoom_start=15)\n    folium.PolyLine(suspect1_trace, color=\"red\", weight=5, opacity=1).add_to(m)\n    for row in temp[temp['suspect']==1].itertuples():\n        folium.Marker(\n            [row[1], row[2]], popup=\"Suspect 1 location @ time = \" + str(row[3]), icon=folium.Icon(color=\"red\"),\n        ).add_to(m)\n    folium.PolyLine(suspect2_trace, color=\"blue\", weight=5, opacity=1).add_to(m)\n    for row in temp[temp['suspect']==2].itertuples():\n        folium.Marker(\n            [row[1], row[2]], popup=\"Suspect 2 location @ time = \" + str(row[3]), icon=folium.Icon(color=\"blue\"),\n        ).add_to(m)\n        \n    display(m)","d7c8d11e":"mapping(15)","bd9dae8d":"mapping(16)","5ea6e617":"data[data['hour']==16]","6eff2653":"data[(data['hour']==16) & (data['clusters']==64)]","95e82ffa":"data[(data['hour']==16) & (data['clusters']==63)]","f35a216e":"### Examine the first five rows of each dataframe, to get a feel of the data","f09484c8":"### Divide the grouped data into dataframe for each suspect in order to merge and use for future filteration","6c0d5a4f":"### Iterate over the list of data in gps1 and gps2 and append it to list","c6d4d306":"### As you can see above, its either in cluster 64 or 63 when the were planning it, suspect 2 arrived first and waited for suspect 1","34ebe82a":"### Random 5 samples of the data","79fe7059":"### What we learned from the above figures is that\n* The only time when the two suspects must have met is between 3pm - 4pm\n* For figure with hour 15 (3pm) there is one location in the middle that looks possible\n* For figure with hour 16 (4pm) there is two location in the bottom left that looks possible\n\n### Next we will plot the movement and markers on map to see if the suspects actually met in these places","e3b25215":"### Filter data for clusters that have both suspects locations","2f47e545":"### It seems like the two suspects might have met at Hans Snoekfonter but if you were to click on the icons and see that the blue icon is moving fast towards the last point, its only a minute difference between the two points, so it seems like the suspects are still moving. So lets see the other map plot for 4pm","18ddc817":"# This is the point where the two suspects have met and planned the crime, it looks like the red suspect was waiting at the park for the blue suspect and once he arrived most probably the blue suspect turned his phone off so that he becomes untrackable that could be the reason why there is time gap, but this is the only place where the DBSCAN has clustered for both suspect and there are close and the place looks perfect for two people to meet. ","3faf3aaa":"<h1 id=\"step1\">\nStep 1 - Data Pre-processing\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/fadilparves\/finding-crime-suspect-meeting-location-dbscan\/notebook#step1\">\u00b6<\/a>\n<\/h1>\n\n### Load the gps data by using gpxpy library","a0a3dda9":"### Grouping the data into list of clusters and suspect and total appereance of the suspect in that cluster","7e5386e4":"### Pass the list to pandas dataframe function in order to create the dataframe from above data and add new column named suspect to respective suspect dataframes","700f8337":"<h1 id=\"step3\">\nStep 3 - Visualization\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/fadilparves\/finding-crime-suspect-meeting-location-dbscan\/notebook#step3\">\u00b6<\/a>\n<\/h1>\n\n * First we iterate each hours that is available in the dataframe after the clusters filter\n * Then we filter the data for the specific hour running in the current iteration\n * Then we get the list of suspects found in that hour\n * Followed by checking if both suspects are inside the current hour timeframe data\n * Then we plot the scatter plot of each suspects for each clusters based on the times","b481bcbd":"<h1 id=\"step2\">\nStep 2 - Clustering\n<a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/fadilparves\/finding-crime-suspect-meeting-location-dbscan\/notebook#step2\">\u00b6<\/a>\n<\/h1>\n\n### By using DBSCAN clustering, the idea is to group each of the latitude and longitude in the dataset, and the parameter for DBSCAN is chosen in a way that it will clusters points that are really close to each other and even assign a cluster label to group that only has one member, hence with the cluster we manage to get 180 cluster labels","5a70b9ea":"### Concatenate both dataframes into one single dataframe","02f752ca":"### Convert time column into datetime and then extract the date, time and hour of each row","8923fa09":"### As we can see below, the data starts from 8:54 am and ends at 5:30 pm, hence our suspects must have meet in that time frame","6e8ebf97":"### This is how the final grouped looks like, basically with this now we know which are the clusters that has both suspect locations"}}