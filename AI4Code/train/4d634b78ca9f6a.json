{"cell_type":{"b58af7fc":"code","2c6114fc":"code","29c871da":"code","a83b35c7":"code","784f2c27":"code","a188bcea":"code","58e50c75":"code","e9167086":"code","2aa4037d":"code","debba69f":"code","9734eb92":"code","665f0625":"code","a5ec8daf":"code","b723549c":"code","edf8d861":"code","6161e151":"code","6ba5783b":"code","3cf40926":"code","e9f5163b":"code","b2f1e2b5":"code","3bd561f8":"code","513aeb46":"code","dc083090":"code","eb1ea2b2":"code","71dea156":"code","2c018128":"code","937cfa17":"code","b82150a1":"code","2c0bf89c":"code","1e4ec0a6":"code","3dcb8cb8":"markdown","6fdc4c0f":"markdown","1cd738ec":"markdown","29898b2a":"markdown","668ae7c1":"markdown","6dd935a4":"markdown","f87b9282":"markdown","66f0dc69":"markdown","b9810bbd":"markdown","814dcd4b":"markdown","8a80dee8":"markdown","062b1818":"markdown","516409fa":"markdown","c7dfce16":"markdown","7f0e173b":"markdown","bec3cea7":"markdown","df96b94c":"markdown","55e2c0e1":"markdown","2d75c366":"markdown","59553d45":"markdown","56dc3c5b":"markdown","7b5f79e7":"markdown"},"source":{"b58af7fc":"\nimport cv2\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\n\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n\nfrom random import randint\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\nprint(tf.__version__)","2c6114fc":"BATCH_SIZE = 32\nEPOCHS = 10\nIMAGE_SIZE = (150, 150)\n\ntf.random.set_seed(0)","29c871da":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","a83b35c7":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)","784f2c27":"CLASSES = {'glacier': 0, 'mountain': 1, 'sea': 2, 'street': 3, 'forest': 4, 'buildings': 5}","a188bcea":"def shuffle_prune(df, BATCH_SIZE):\n    df = shuffle(df, random_state=42)\n    df.reset_index(drop=True, inplace=True)\n    df = df[ : df.shape[0] \/\/ BATCH_SIZE * BATCH_SIZE]\n    return df","58e50c75":"filenames = tf.io.gfile.glob('\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/*\/*')\nimage_path_df_train = pd.DataFrame(data={'filename': filenames, 'class': [x.split('\/')[-2] for x in filenames]})\nimage_path_df_train = shuffle_prune(image_path_df_train, BATCH_SIZE)\nimage_path_df_train['class'] = image_path_df_train['class'].map(CLASSES)\n\nprint('Train sample: ', len(image_path_df_train['class']), dict(image_path_df_train['class'].value_counts()))","e9167086":"filenames = tf.io.gfile.glob('\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/*\/*')\nimage_path_df_test = pd.DataFrame(data={'filename': filenames, 'class': [x.split('\/')[-2] for x in filenames]})\n\nprint('Test sample: ', len(image_path_df_test['class']), dict(image_path_df_test['class'].value_counts()))","2aa4037d":"image_path_df_test, image_path_df_val  = train_test_split(image_path_df_test, test_size=0.5, random_state=42, stratify=image_path_df_test['class'])\nimage_path_df_test = shuffle_prune(image_path_df_test, BATCH_SIZE)\nimage_path_df_test['class'] = image_path_df_test['class'].map(CLASSES)\n\nimage_path_df_val = shuffle_prune(image_path_df_val, BATCH_SIZE)\nimage_path_df_val['class'] = image_path_df_val['class'].map(CLASSES)\n\nprint('Test sample: ', len(image_path_df_test['class']), dict(image_path_df_test['class'].value_counts()))\nprint('Val  sample: ', len(image_path_df_val['class']), dict(image_path_df_val['class'].value_counts()))","debba69f":"filenames = tf.io.gfile.glob('\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\/*')\n\nimage_path_df_predict = pd.DataFrame(data={'filename': filenames, 'class': np.nan})\nprint(f'Number filenames: {len(image_path_df_predict)}')","9734eb92":"def get_images_and_labels_arrays(df):\n    images = []\n    for file in df['filename']:\n        image = cv2.imread(file)\n        image = cv2.resize(image,IMAGE_SIZE)\n        images.append(image)\n    images = np.array(images)\n    \n    labels = df.loc[:, 'class']\n    return images, labels","665f0625":"train_images, train_labels = get_images_and_labels_arrays(image_path_df_train)\n\nprint(f'Shape of train set: {train_images.shape}')\nprint(f'Shape of train set: {train_labels.shape}')","a5ec8daf":"val_images, val_labels = get_images_and_labels_arrays(image_path_df_val)\n\nprint(f'Shape of validation set: {val_images.shape}')\nprint(f'Shape of validation set: {val_labels.shape}')","b723549c":"test_images, test_labels = get_images_and_labels_arrays(image_path_df_test)\n\nprint(f'Shape of test set: {test_images.shape}')\nprint(f'Shape of test set: {test_labels.shape}')","edf8d861":"f,ax = plt.subplots(3,3) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,3,1):\n    for j in range(0,3,1):\n        rnd_number = randint(0,len(train_images))\n        ax[i,j].imshow(train_images[rnd_number])\n        ax[i,j].set_title([key for key, val in CLASSES.items() if val == train_labels[rnd_number]][0])\n        ax[i,j].axis('off')","6161e151":"def create_model():\n    \n    with tf.device('\/gpu:0'):\n    \n        input_layer = layers.Input(shape=(*IMAGE_SIZE, 3), name='input') \n        x = layers.BatchNormalization()(input_layer)\n\n        x = layers.Conv2D(filters=64, kernel_size=3, \n                          activation='relu', padding='same', \n                          name='conv2d_1')(x)\n        x = layers.MaxPool2D(pool_size=2, name='maxpool2d_1')(x)\n        x = layers.Dropout(0.1, name='dropout_1')(x)\n\n        x = layers.Conv2D(filters=128, kernel_size=3, \n                          activation='relu', padding='same', \n                          name='conv2d_2')(x)\n        x = layers.MaxPool2D(pool_size=2, name='maxpool2d_2')(x)\n        x = layers.Dropout(0.1, name='dropout_2')(x)\n\n        x = layers.Conv2D(filters=256, kernel_size=3, \n                          activation='relu', padding='same', \n                          name='conv2d_3')(x)\n        x = layers.MaxPool2D(pool_size=2, name='maxpool2d_3')(x)\n        x = layers.Dropout(0.1, name='dropout_3')(x)\n\n        x = layers.Conv2D(filters=512, kernel_size=3, \n                          activation='relu', padding='same', \n                          name='conv2d_4')(x)\n        x = layers.MaxPool2D(pool_size=2, name='maxpool2d_4')(x)\n        x = layers.Dropout(0.1, name='dropout_4')(x)\n\n        x = layers.Conv2D(filters=1024, kernel_size=3, \n                          activation='relu', padding='same', \n                          name='conv2d_5')(x)\n        x = layers.MaxPool2D(pool_size=2, name='maxpool2d_5')(x)\n        x = layers.Dropout(0.1, name='dropout_5')(x)\n        \n\n        x = layers.GlobalAveragePooling2D(name='global_average_pooling2d')(x)\n        x = layers.BatchNormalization()(x)\n       \n        x = layers.Dense(128,activation='relu')(x)\n        \n        output = layers.Dense(units=len(CLASSES), \n                              activation='softmax', \n                              name='output')(x)\n\n\n        model = Model (input_layer, output)    \n        model.compile(optimizer='adam', \n                      loss='sparse_categorical_crossentropy', \n                      metrics=['accuracy'])\n\n    return model\n\nmodel = create_model()\nmodel.summary()","6ba5783b":"init_time = datetime.datetime.now()\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)\n\ntrained = model.fit(\n                    train_images, train_labels,\n                    validation_data = (val_images, val_labels),\n                    batch_size = BATCH_SIZE, \n                    epochs=EPOCHS,\n                    callbacks=[learning_rate_reduction],\n    )\n\nrequared_time = datetime.datetime.now() - init_time\nprint(f'\\nRequired time:  {str(requared_time)}\\n')","3cf40926":"plt.plot(trained.history['accuracy'])\nplt.plot(trained.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(trained.history['loss'])\nplt.plot(trained.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","e9f5163b":"test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\nprint('\\naccuracy:', test_acc, '  loss: ',test_loss)","b2f1e2b5":"predict = np.argmax(model.predict(test_images), axis=1)\npredict","3bd561f8":"print(classification_report(test_labels, predict), '\\n')\ncm = confusion_matrix(test_labels, predict)\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.0f', cbar=False)\nplt.show()","513aeb46":"def create_model():\n    with tf.device('\/gpu:0'):\n        pretrained_model = tf.keras.applications.VGG19(\n            weights='imagenet',\n            include_top=False ,\n            input_shape=[*IMAGE_SIZE, 3]\n        )\n        pretrained_model.trainable = False\n\n        \n        \n        input_layer = layers.Input(shape=(*IMAGE_SIZE, 3), name='input') \n        \n        x = pretrained_model(input_layer)\n\n        x = layers.GlobalAveragePooling2D(name='global_average_pooling2d')(x)\n        x = layers.BatchNormalization()(x)       \n        x = layers.Dense(128,activation='relu')(x)\n\n        \n        output = layers.Dense(units=len(CLASSES), \n                              activation='softmax', \n                              name='output')(x)\n\n\n        model = Model (input_layer, output)    \n        model.compile(optimizer='adam', \n                      loss='sparse_categorical_crossentropy', \n                      metrics=['accuracy'])\n\n        return model\n\nmodel = create_model()\nmodel.summary()","dc083090":"init_time = datetime.datetime.now()\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)\n\ntrained = model.fit(\n                    train_images, train_labels,\n                    validation_data = (val_images, val_labels),\n                    batch_size = BATCH_SIZE, \n                    epochs=EPOCHS,\n                    callbacks=[learning_rate_reduction],\n    )\n\nrequared_time = datetime.datetime.now() - init_time\nprint(f'\\nRequired time:  {str(requared_time)}\\n')","eb1ea2b2":"plt.plot(trained.history['accuracy'])\nplt.plot(trained.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(trained.history['loss'])\nplt.plot(trained.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","71dea156":"test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\nprint('\\naccuracy:', test_acc, '  loss: ',test_loss)","2c018128":"predict = np.argmax(model.predict(test_images), axis=1)\npredict","937cfa17":"print(classification_report(test_labels, predict), '\\n')\ncm = confusion_matrix(test_labels, predict)\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.0f', cbar=False)\nplt.show()","b82150a1":"to_predict_images, to_predict_labels = get_images_and_labels_arrays(image_path_df_predict)\nprint(f'Shape of images set to prediction: {to_predict_images.shape}')","2c0bf89c":"predict = np.argmax(model.predict(to_predict_images), axis=1)\npredict","1e4ec0a6":"f,ax = plt.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,len(predict))\n        ax[i,j].imshow(to_predict_images[rnd_number])\n        ax[i,j].set_title([key for key, val in CLASSES.items() if val == predict[rnd_number]][0])\n        ax[i,j].axis('off')","3dcb8cb8":"# Thank you for your attention and curiosity ;)","6fdc4c0f":"# Let's predict unlabeled images","1cd738ec":"# Run model training","29898b2a":"# Let's check random images","668ae7c1":"# Get Test Sample","6dd935a4":"# Get device name (GPU)","f87b9282":"# Get Validation sample from test sample","66f0dc69":"# We have 6 classes in this work like this","b9810bbd":"# Define classes","814dcd4b":"# Evaluate the trained model","8a80dee8":"# Prediction","062b1818":"# Get arrays and labels","516409fa":"# Let's see the available folders","c7dfce16":"# Training process","7f0e173b":"# Let's try pretrained model for example VGG19","bec3cea7":"# Get files for prediction","df96b94c":"# Get Train Sample","55e2c0e1":"# Define CNN Keras model and compile","2d75c366":"# Intel Image Classification","59553d45":"# Classification report & confusion matrix","56dc3c5b":"# Classification report & confusion matrix","7b5f79e7":"# Prediction"}}