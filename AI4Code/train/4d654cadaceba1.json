{"cell_type":{"a77b5253":"code","14f9930f":"code","4354ba74":"code","ad28e24f":"code","f0eb12b5":"code","3a81f229":"code","2bef7b8b":"code","729c2976":"code","5951539b":"code","05edd8b9":"code","dc23d165":"code","4721ce56":"code","73a6d4fb":"code","21f0fa6a":"code","3e543cd3":"code","c6011d66":"code","ed25e6e1":"code","281b5d16":"markdown","1377f94d":"markdown","ce42adb3":"markdown","82206ed4":"markdown","c0ad36d6":"markdown","d615290d":"markdown","21ed1321":"markdown","c73ec69f":"markdown","c1920781":"markdown","33dfae23":"markdown","f7001f3d":"markdown","0d2db738":"markdown","dce7c25f":"markdown"},"source":{"a77b5253":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\n\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings('ignore')","14f9930f":"train_audio_dir = '..\/input\/birdsong-recognition\/train_audio'\ntrain = pd.read_csv('..\/input\/birdsong-recognition\/train.csv')","4354ba74":"base_dir = '..\/input\/birdsong-recognition\/train_audio\/'\ntrain['full_path'] = base_dir + train['ebird_code'] + '\/'+ train['filename']","ad28e24f":"train[train['ebird_code']== 'amered'].sample(1, random_state = 33)['full_path'].values[0]","f0eb12b5":"amered = train[train['ebird_code']== 'amered'].sample(1, random_state = 33)['full_path'].values[0]\npingro = train[train['ebird_code'] == \"pingro\"].sample(1, random_state = 33)['full_path'].values[0]\nvesspa = train[train['ebird_code'] == \"vesspa\"].sample(1, random_state = 33)['full_path'].values[0]\n\n\n","3a81f229":"audio_file, _ = librosa.effects.trim(y)\n\n# the result is an numpy ndarray\nprint('Audio File:', audio_file, '\\n')\nprint('Audio File shape:', np.shape(audio_file))","2bef7b8b":"ipd.Audio(amered)","729c2976":"audio_amered, sr = librosa.load(amered)","5951539b":"n_fft = 2048 # FFT window size\nhop_length = 512\n\nD_amered = np.abs(librosa.stft(audio_amered, n_fft = n_fft, hop_length = hop_length))\n","05edd8b9":"DB_amered = librosa.amplitude_to_db(D_amered, ref = np.max)\nlibrosa.display.specshow(DB_amered, sr = sr, hop_length = hop_length, x_axis = 'time', \n                         y_axis = 'log', cmap = 'cool')","dc23d165":"\nplt.Figure(figsize=(16,9))\nplt.title(('Sound waves'), fontsize=16)\n\nlibrosa.display.waveplot(y= audio_amered, sr = sr, color = \"#A300F9\")","4721ce56":"n0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(audio_amered[n0:n1])\nplt.grid()","73a6d4fb":"zero_amered = librosa.zero_crossings(audio_amered, pad=False)\nprint('change rate {}'.format(sum(zero_amered)))","21f0fa6a":"spectral_centroids = librosa.feature.spectral_centroid(audio_amered, sr=sr)[0]\n\n# Shape is a vector\nprint('Centroids:', spectral_centroids, '\\n')\nprint('Shape of Spectral Centroids:', spectral_centroids.shape, '\\n')\n\n# Computing the time variable for visualization\nframes = range(len(spectral_centroids))\n\n# Converts frame counts to time (seconds)\nt = librosa.frames_to_time(frames)\n\nprint('frames:', frames, '\\n')\nprint('t:', t)\n\n# Function that normalizes the Sound Data\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)","3e543cd3":"plt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(audio_amered, sr=sr, alpha=0.4, color = '#A300F9', lw=3)\nplt.plot(t, normalize(spectral_centroids), color='#FFB100', lw=2)\nplt.legend([\"Spectral Centroid\", \"Wave\"])\nplt.title(\"Spectral Centroid: Cangoo Bird\", fontsize=16);","c6011d66":"spectral_rolloff = librosa.feature.spectral_rolloff(audio_amered, sr=sr)[0]\n\n\nframes = range(len(spectral_rolloff))\n\nt = librosa.frames_to_time(frames)\n\n","ed25e6e1":"\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(audio_amered, sr=sr, alpha=0.4, color = '#A300F9', lw=3)\nplt.plot(t, normalize(spectral_rolloff), color='#FFB100', lw=3)\nplt.legend([\"Spectral Rolloff\", \"Wave\"])\nplt.title(\"Spectral Rolloff: Amered Bird\", fontsize=16);","281b5d16":" \u201cThe spectral centroid is a measure used in digital signal processing to characterise a spectrum. It indicates where the \u201ccenter of mass\u201d of the spectrum is located. Perceptually, it has a robust connection with the impression of \u201cbrightness\u201d of a sound\u201d\nSpectral Centroid tells us something about the timbre of a sound. Specifically, it gives us information about how bright a sound is. Visually, you can understand Spectral Centroid by imagining you have a frequency spectrum made out of solid object\n\nSpectra Centroid can be a nice feature if timbre is relevant to the thing you are trying to model.","1377f94d":"# Zero-Crossing","ce42adb3":"(https:\/\/medium.com\/@jehoshaphatia\/100-days-of-ml-code-day-034-985f64a73c)","82206ed4":"https:\/\/www.kaggle.com\/andradaolteanu\/birdcall-recognition-eda-and-audio-fe\n","c0ad36d6":"The roll-off is a measure of spectral shape useful for distinguishing voiced from unvoiced speech. The\nfrequency below which 85% of the magnitude distribution of the spectrum is concentrated is known as Roll-Off.","d615290d":"More to go...","21ed1321":"#  Spectrogram ","c73ec69f":"In speech processing, the zero-crossing counts can help distinguish between voiced and un-voiced speech.  \nUn-voiced sounds are very noise-like ('Shh' and 'Sss' for example). \nIn addition, zero-crossings could also be used to determine if your signal has a DC offset.  \nIf you signal is 'muted' and you are not seeing alot of zero-crossings might mean that your signal is offset from the zero-line","c1920781":"# #Let see Sound Waves\n","33dfae23":"#  Spectral Rolloff ","f7001f3d":"# spectral centroid","0d2db738":"the chirping sound occur at 0.6, 1.8(approx) amd 4","dce7c25f":"* Spectrogram tells....\n* Most of the energy is concenterated between above 2048 frequency and 8192 frequency.\n\n* Whenever vibration of sound becomes strong, the intensity get dark.\n\n* At 0.6s the intensity is strong, it means there is bird sound. Likewise at 2 and at 4.2s."}}