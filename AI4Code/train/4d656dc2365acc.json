{"cell_type":{"50c104c2":"code","f796990f":"code","5c17e737":"code","1761222f":"code","b4d377fb":"code","bd460a17":"code","f4435135":"code","0d7be4bb":"code","1524aa11":"code","2fbc5a54":"code","13d73dec":"code","cf93522e":"code","faf53908":"code","3e77ca88":"markdown","ab7eb30e":"markdown","57f49e17":"markdown","0ae6b42e":"markdown","34a4478d":"markdown","507398dd":"markdown","6308e0b7":"markdown","d2d1657d":"markdown","b54f4618":"markdown","a40e558d":"markdown"},"source":{"50c104c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f796990f":"files = [file for file in os.listdir(\"\/kaggle\/input\/sales-data-for-eda\/Sales_Data\")]\nall_months_data = pd.DataFrame()\nfor file in files:\n    df = pd.read_csv(\"\/kaggle\/input\/sales-data-for-eda\/Sales_Data\/\"+file)\n    all_months_data = pd.concat([all_months_data, df])\nall_months_data.to_csv(\"all_data.csv\", index=False)","5c17e737":"all_data = pd.read_csv(\"all_data.csv\")\nall_data.head()","1761222f":"all_data = all_data.dropna(how=\"all\")\nall_data = all_data[all_data[\"Order Date\"].str[0:2] != \"Or\"]","b4d377fb":"#making a new column called month and cleaning it and making it's values intergers \nall_data[\"Month\"] = all_data[\"Order Date\"].str[0:2]\nall_data[\"Month\"].dropna()\nall_data[\"Month\"] = all_data[\"Month\"].astype(\"int32\")\n#transforming values in Quantity Ordered and Price Each columns to a numeric\nall_data[\"Quantity Ordered\"] = pd.to_numeric(all_data[\"Quantity Ordered\"])\nall_data[\"Price Each\"] = pd.to_numeric(all_data[\"Price Each\"])\n\nall_data.head()","bd460a17":"all_data[\"Sales\"] = all_data[\"Quantity Ordered\"] * all_data[\"Price Each\"]\nall_data.head()","f4435135":"sale_month = all_data.groupby(\"Month\")[\"Sales\"].sum()\nmonths = range(1,13)\nplt.bar(months, sale_month)\nplt.xticks(months)\nplt.xlabel(\"Months\")\nplt.ylabel(\"Sales in million $\")\nplt.title(\"Sales for each month\")\nplt.legend()\nplt.show()","0d7be4bb":"#getting city and state from the Purchase Address column\ndef get_city(address):\n    return address.split(\",\")[1]\n\ndef get_state(address):\n    return address.split(\",\")[2][1:3]\n\nall_data[\"City\"] = all_data[\"Purchase Address\"].apply(lambda x: get_city(x) + \" \" + get_state(x))\n\nsales = all_data.groupby(\"City\")[\"Sales\"].sum()\nsales.plot.bar()\nplt.ylabel(\"Sales by million $\")\nsales","1524aa11":"#converting Order Date from a string type into a datetime type column\nall_data[\"Order Date\"] = pd.to_datetime(all_data[\"Order Date\"])\n#creating an hour column and getting it from the Order Date column\nall_data[\"Hour\"] = all_data[\"Order Date\"].dt.hour\n#creating an Minute column and getting it from the Order Date column\nall_data[\"Minute\"] = all_data[\"Order Date\"].dt.minute\n\n#Ploting to see when do sales go up \nhours = [hour for hour, df in all_data.groupby(\"Hour\")]\nplt.plot(hours, all_data.groupby(\"Hour\").count())\nplt.xticks(hours)\nplt.grid()\nplt.show()\nall_data.head()","2fbc5a54":"df =  all_data.loc[all_data[\"Order ID\"].duplicated(keep=False)]\ndf[\"Grouped\"] = df.groupby(\"Order ID\")[\"Product\"].transform(lambda x: \", \".join(x))\ndf = df[[\"Order ID\", \"Grouped\"]].drop_duplicates()\ndf.head()","13d73dec":"from itertools import combinations\nfrom collections import Counter\n\ncount = Counter()\n\nfor row in df[\"Grouped\"]:\n    row_list = row.split(\", \")\n    count.update(Counter(combinations(row_list, 2)))\n\ncount.most_common()","cf93522e":"product_quantity = all_data.groupby(\"Product\")[\"Quantity Ordered\"].sum()\nproducts = [product for product, df in all_data.groupby(\"Product\")]\nprices = all_data.groupby(\"Product\")[\"Price Each\"].mean()","faf53908":"fig, ax1 = plt.subplots()\nax2= ax1.twinx()\nax1.bar(products, product_quantity, color=\"g\", alpha=0.5)\nax2.plot(products, prices, \"b-\")\n\nax1.set_xlabel(\"Product Names\")\nax1.set_ylabel(\"Product Quantity\", color=\"g\")\nax2.set_ylabel(\"Prices\", color=\"b\")\nax1.set_xticklabels(products,rotation=\"vertical\", size=10)\nplt.show()","3e77ca88":"# Hours when sales go up","ab7eb30e":"# Reading all csv files and combining them in one csv file","57f49e17":"# Creating a sales column","0ae6b42e":"# Most sold products and their prices","34a4478d":"**We see that the most sold products (Batteries) have the lowest prices and the least sold products have the highest prices**","507398dd":"> San Francisco is the city with the highest sales","6308e0b7":"# Products that are sold in pairs","d2d1657d":"It appears that December is the month with the highest sales","b54f4618":"# City with the highest sales","a40e558d":"# Cleaning dataframe by droping Nan values"}}