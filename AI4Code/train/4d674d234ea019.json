{"cell_type":{"629b9c20":"code","e2261bf2":"code","524e24b9":"code","2afa77de":"code","00eac9c4":"code","edc7d5d4":"code","66373027":"code","75a20e3f":"code","f717d4d4":"code","97d48407":"code","e12ca44b":"code","56280bf3":"code","b19a496a":"markdown","9d30dc0e":"markdown","b1b2eefd":"markdown","37176a41":"markdown","5678b62b":"markdown","c4efbf1b":"markdown","b28089b9":"markdown","15d457f2":"markdown","57cfcc1a":"markdown","c568ed57":"markdown","54f19018":"markdown","338d2ae7":"markdown","d2ca8b2e":"markdown","77d9b0e3":"markdown"},"source":{"629b9c20":"import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats, optimize\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nsns.set(style=\"ticks\")","e2261bf2":"# import the data\ndf = pd.read_csv('..\/input\/BreadBasket_DMS.csv')","524e24b9":"# examine example data\ndf.head()","2afa77de":"# examine the entire set\ndf.info()","00eac9c4":"# parse the dates\ndf['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\ndf['date'] = pd.to_datetime(df['Date'])\n\n# deconstruct the dates\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\ndf['weekday'] = df['date'].dt.weekday\n\n# drop the date, time and transaction\ndf = df.drop(['Date', 'Time', 'Transaction'], axis=1)\n\n# examine the data\ndf.head()","edc7d5d4":"df2 = df.groupby(['date', 'year', 'month', 'day', 'weekday'], as_index = False).agg({'datetime': [pd.Series.nunique, 'count']})\ndf2.columns = ['date','year','month','day','weekday','transactions','items']\ndf2.head()","66373027":"x=df2['transactions']\ny=df2['items']\n\n# define a straight line fit with forced zero intercept\ndef lin_fit(x, y):\n    fitfunc = lambda params, x: params[0] * x\n    errfunc = lambda p, x, y: fitfunc(p, x) - y\n    init_p = np.array((1.0))\n    p1, success = optimize.leastsq(errfunc, init_p.copy(), args = (x, y))\n    f = fitfunc(p1, x)\n    return p1, success,  f  \n\n# fit the line\np, s, f = lin_fit(x,y)\ndf2['fit'] = f\n\n# print the fit parameter\nprint(\"Gradient = \", p[0])","75a20e3f":"data = []\nweekdayDict = {6:'Sunday', 0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday'}\n\n# construct plotly plot showing the relationship by day of sale,\ntrace = go.Scatter(x=df2['transactions'], y=df2['fit'], name = 'best fit')\ndata.append(trace)\nfor day in df2['weekday'].unique():\n    tmp = df2[df2['weekday'] == day]\n    trace = go.Scatter(x=tmp['transactions'], y=tmp['items'], mode='markers', name = weekdayDict[day])\n    data.append(trace)\nlayout = go.Layout(\n    xaxis=dict(title='Transactions made',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')),\n    yaxis=dict(title='Items sold',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')))\n\n# plot and embed in notebook\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","f717d4d4":"# construct plotly plot showing the relationship by day of sale,\ndata = []\ntrace = go.Scatter(x=df2['date'], y=df2['transactions'])\ndata.append(trace)\nlayout = go.Layout(\n    xaxis=dict(title='Date',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')),\n    yaxis=dict(title='Transactions made',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')))\n\n# plot and embed in notebook\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","97d48407":"# Create a new data frame with a row per date\ndf3 = pd.DataFrame()\ndf3['date'] = pd.date_range(start=df2['date'].min(), end=df2['date'].max())\n\n# Merge the two series to highlight any missing dates\ndf3 = pd.merge(df3,df2,how='left',on='date')\n\n# Set the index and interpolate across missing data to create a uniform time series\ndf3.set_index(['date'], inplace=True)\ndf3['transactions'].interpolate(inplace=True)","e12ca44b":"resA = sm.tsa.seasonal_decompose(df3['transactions'], freq=7, model = \"additive\")\nresM = sm.tsa.seasonal_decompose(df3['transactions'], freq=7, model = \"multiplicative\")\n\ndef plotseasonal(res, axes, col ):\n    res.observed.plot(ax=axes[0], legend=False, color=col)\n    axes[0].set_ylabel('Observed')\n    res.trend.plot(ax=axes[1], legend=False, color=col)\n    axes[1].set_ylabel('Trend')\n    res.seasonal.plot(ax=axes[2], legend=False, color=col)\n    axes[2].set_ylabel('Seasonal')\n    res.resid.plot(ax=axes[3], legend=False, color=col)\n    axes[3].set_ylabel('Residual')\n\nfig, axes = plt.subplots(ncols=2, nrows=4, sharex=True, figsize=(14,8))\nplotseasonal(resA, axes[:,0], 'r')\nplotseasonal(resM, axes[:,1], 'g')\n\nplt.tight_layout()\nplt.show()","56280bf3":"df3['add_seasonality'] = resA.seasonal\ndf3['mul_seasonality'] = resM.seasonal\n\ndf3['av_trans'] = df3['transactions'].mean()\ndf3['add_forecast'] = df3['transactions'].mean() + df3['add_seasonality']\ndf3['mul_forecast'] = df3['transactions'].mean()*df3['mul_seasonality']\n\n\ntrace1 = go.Scatter(x=df3.index, y=df3['transactions'], name = 'Observed')\ntrace2 = go.Scatter(x=df3.index, y=df3['add_forecast'], line=dict(color=('rgb(105, 12, 24)'),width=2,dash='dash'), name='Additive model forecast')\ntrace3 = go.Scatter(x=df3.index, y=df3['mul_forecast'], line=dict(color=('rgb(60, 179, 13)'),width=2,dash='dot'), name = 'Multiplicative model forecast')\ntrace4 = go.Scatter(x=df3.index, y=df3['av_trans'], name = 'Average')\ndata = [trace1, trace2, trace3, trace4]\nlayout = go.Layout(\n    xaxis=dict(title='Date',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')),\n    yaxis=dict(title='Transactions made',titlefont=dict(family='Courier New, monospace',size=18,color='#7f7f7f')))\n\n# plot and embed in notebook\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n\nprint(\"Additive median % accuracy\", 100.*(1-(abs(df3['transactions'] - df3['add_forecast'])\/df3['transactions']).median()))\nprint(\"Multiplicative median % accuracy\", 100.*(1-(abs(df3['transactions'] - df3['mul_forecast'])\/df3['transactions']).median()))","b19a496a":"# **Bakers dozen - predicting transactions** ==================================================","9d30dc0e":"Now, lets examine the timeseries of transactions to see if this pattern is evident...","b1b2eefd":"Hurrah, simply by measuring the seasonality we have been able to turn an average transaction day to a transaction forecast based on the given weekday, and it applying it across the data set, gives a median percentage accuracy of greater than 87%.","37176a41":"At this point, rather than concern ourselves with the items being sold in each transation we will instead first examine the number of items sold in each transaction and the number of transactions each day.","5678b62b":"<img src=\"https:\/\/www.rd.com\/wp-content\/uploads\/2017\/10\/this-is-why-there-are-13-in-a-baker-s-dozen_179437478_stevemart-1024x683.jpg\" width=\"400px\"\/>","c4efbf1b":"### --- Wrangle the data","b28089b9":"### --- Modelling the seasonality of transactions","15d457f2":"This shows that each transaction made equates to approximately 2.24 items sold.","57cfcc1a":"### --- Import and examine the data","c568ed57":"### --- Exploring transactions","54f19018":"Lets examine the relationship between transactions made each day and the number of items sold each day","338d2ae7":"### --- ** Let's get started!**","d2ca8b2e":"Clearly there is a strong seasonality in the data. In the next section we try to unpick it","77d9b0e3":"The figure above clearly shows that the linear fit captures the relationship between transactions and items sold reasonably well. Additionaly the figure shows that the number of transactions made is clearly a function of weekday with the most transactions clearly being made on Saturdays."}}