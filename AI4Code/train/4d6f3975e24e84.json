{"cell_type":{"b6f28658":"code","0a3f3c38":"code","7e63e542":"code","1156f4da":"code","465a60e3":"code","74828637":"code","e0c4e45b":"code","57dbe942":"code","cf1ff9c4":"code","78093d32":"code","f2e33954":"code","a3496fde":"code","962180ce":"code","5237044b":"code","134cda51":"code","8c1bfc86":"code","9244dbd1":"code","0f3fd0dc":"code","8c031565":"code","6ddb838a":"markdown","11ef488e":"markdown","7bdb65f3":"markdown","bcc5b023":"markdown","6e5c07a2":"markdown","36c5ba0e":"markdown"},"source":{"b6f28658":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0a3f3c38":"df = pd.read_csv(\"\/kaggle\/input\/inspiration\/train.csv\")","7e63e542":"df.head()","1156f4da":"y = df[\"% Silica Concentrate\"]\nx = df.drop(\"% Silica Concentrate\",axis=1)\nx = x.drop(\"date\",axis=1)","465a60e3":"x.head()","74828637":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y,test_size=0.2)","e0c4e45b":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=2)\nneigh.fit(X_train, y_train)","57dbe942":"from sklearn.metrics import mean_squared_error\n\npreds = neigh.predict(X_train)\n\nprint(\"Trainings Error\")\nprint(mean_squared_error(preds,y_train))","cf1ff9c4":"print(mean_squared_error(preds,y_train))","78093d32":"submission = pd.read_csv(\"\/kaggle\/input\/inspiration\/Submission.csv\")\nsubmission.head()","f2e33954":"x_test = pd.read_csv(\"\/kaggle\/input\/inspiration\/test.csv\")\nx_test = x_test.drop(\"date\",axis=1)","a3496fde":"X_train.head()\n","962180ce":"x_test.head()","5237044b":"preds = neigh.predict(x_test)","134cda51":"submission.head()\n","8c1bfc86":"submission[\"Expected\"].shape","9244dbd1":"preds.shape","0f3fd0dc":"submission.to_csv(\"submission_base_blend_top_Scale extremes2.csv\", index=False) ","8c031565":"sub =  pd.read_csv(\"\/kaggle\/input\/inspiration\/Submission.csv\")","6ddb838a":"![](https:\/\/yanirseroussi.files.wordpress.com\/2018\/07\/what-would-you-say-you-do-here.jpg?w=620)","11ef488e":"## Prepare and split data for training a model ( Virtual Sensor)\n","7bdb65f3":"* Learn to load data and clean it for further analysis\n* Visualize some key metrics\n* Implement a Virtual Sensor that can predict the % Silica Concentrate from given data\n* Test the Virtual Sensor on some unseen Data and evaluate its performance\n\n","bcc5b023":"#### Methods you can\/should use to clean and analyse the data:\n\n* df.describe()\n* df.head()\n* df.drop(\"COL-NAME-HERE\")\n* df.dropna()\n* df[\"COL-NAME-HERE\"].hist()\n","6e5c07a2":"# **Introduction**","36c5ba0e":"Loading the training dataset"}}