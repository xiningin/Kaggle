{"cell_type":{"4580af9b":"code","d1cfb304":"code","4ee89318":"code","58ca190b":"code","084c139f":"code","fa8c46de":"code","267bd6ad":"code","5cbeb0b5":"markdown"},"source":{"4580af9b":"from sys import argv\n\nimport numpy as np\nfrom timeit import default_timer as timer\n\nimport pickle\nimport torch\nimport os\nimport pandas as pd\n\nos.listdir('..\/input')","d1cfb304":"def normalize(points):\n    \"\"\"\n    Return the normalized version of a given vector of points.\n\n    For a given array of n-dimensions, normalize each dimension by removing the\n    initial offset and normalizing the points in a proportional interval: [0,1]\n    on y, maintining the original ratio on x.\n    \"\"\"\n    ratio = (points.x.max() - points.x.min()) \/ (points.y.max() - points.y.min()), 1\n    ratio = np.array(ratio) \/ max(ratio)\n    norm = points.apply(lambda c: (c - c.min()) \/ (c.max() - c.min()))\n    return norm.apply(lambda p: ratio * p, axis=1)\n\ndef generate_network(size):\n    \"\"\"\n    Generate a neuron network of a given size.\n\n    Return a vector of two dimensional points in the interval [0,1].\n    \"\"\"\n    return torch.from_numpy(np.random.rand(size, 2))\n\n\ndef select_closest(candidates, origin):\n    \"\"\"Return the index of the closest candidate to a given point.\"\"\"\n    _, ind = torch.min(euclidean_distance(candidates, origin),0)\n    return ind\n\ndef euclidean_distance(a, b):\n    \"\"\"Return the array of distances of two numpy arrays of points.\"\"\"\n    return torch.norm(a - b, p=2, dim=1)\n\ndef route_distance(cities):\n    \"\"\"Return the cost of traversing a route of cities in a certain order.\"\"\"\n    points = cities[['x', 'y']]\n    distances = euclidean_distance(points, np.roll(points, 1, axis=0))\n    return np.sum(distances)\n\ndef get_neighborhood(center, radix, domain):\n    \"\"\"Get the range gaussian of given radix around a center index.\"\"\"\n\n    # Impose an upper bound on the radix to prevent NaN and blocks\n    if radix < 1:\n        radix = 1\n\n    # Compute the circular network distance to the center\n    #deltas = np.absolute(center - np.arange(domain))\n    deltas = torch.abs(center.float().cuda() - torch.arange(domain).float().cuda())\n    #distances = np.minimum(deltas, domain - deltas)\n    deltas = deltas.cpu().numpy()\n    #print(deltas)\n    distances = torch.from_numpy(np.minimum(deltas, domain - deltas)).cuda()\n    # Compute Gaussian distribution around the given center\n    #return np.exp(-(distances*distances) \/ (2*(radix*radix)))\n    return torch.exp(-(distances*distances) \/ (2*(radix*radix)))","4ee89318":"def read_tsp(filename):\n    \"\"\"\n    Read a file in .tsp format into a pandas DataFrame\n\n    The .tsp files can be found in the TSPLIB project. Currently, the library\n    only considers the possibility of a 2D map.\n    \"\"\"\n    with open(filename) as f:\n        node_coord_start = None\n        dimension = None\n        lines = f.readlines()\n\n        # Obtain the information about the .tsp\n        i = 0\n        while not dimension or not node_coord_start:\n            line = lines[i]\n            if line.startswith('DIMENSION :'):\n                dimension = int(line.split()[-1])\n            if line.startswith('NODE_COORD_SECTION'):\n                node_coord_start = i\n            i = i+1\n\n        print('Problem with {} cities read.'.format(dimension))\n\n        f.seek(0)\n\n        # Read a data frame out of the file descriptor\n        cities = pd.read_csv(\n            f,\n            skiprows=node_coord_start + 1,\n            sep=' ',\n            names=['city', 'y', 'x'],\n            dtype={'city': str, 'x': np.float32, 'y': np.float32},\n            header=None,\n            nrows=dimension\n        )\n\n        # cities.set_index('city', inplace=True)\n\n        return cities\n    \ndef normalize(points):\n    \"\"\"\n    Return the normalized version of a given vector of points.\n\n    For a given array of n-dimensions, normalize each dimension by removing the\n    initial offset and normalizing the points in a proportional interval: [0,1]\n    on y, maintining the original ratio on x.\n    \"\"\"\n    ratio = (points.x.max() - points.x.min()) \/ (points.y.max() - points.y.min()), 1\n    ratio = np.array(ratio) \/ max(ratio)\n    norm = points.apply(lambda c: (c - c.min()) \/ (c.max() - c.min()))\n    return norm.apply(lambda p: ratio * p, axis=1)\n\n\nproblem = read_tsp(\"..\/input\/santa\/santa_test.tsp\")","58ca190b":"cities=torch.from_numpy(normalize(problem[['x','y']]).values).cuda()","084c139f":"n = cities.size()[0] * 8\nnetwork = generate_network(n).cuda()","fa8c46de":"iterations=1000\nlearning_rate=0.8\nfor i in range(iterations):\n    if not i % 100:\n        print('\\t> Iteration {}\/{}'.format(i, iterations), end=\"\\r\")\n    # Choose a random city\n    #print(\"=============\")\n    start = timer()\n    city=cities[np.random.randint(0,cities.size()[0]),:]\n    winner_idx = select_closest(network, city)\n    gaussian = get_neighborhood(winner_idx, n\/\/10, network.shape[0])\n    network += gaussian[:,np.newaxis] * learning_rate * (city - network)\n    end = timer()\n    print(end - start)\n    #print(\"=============\")\n\n    # Decay the variables\n    learning_rate = learning_rate * 0.99997\n    n = n * 0.9997\n\n    # Check for plotting interval\n    #if not i % 1000:\n    #    plot_network(cities, network, name='diagrams\/{:05d}.png'.format(i))\n\n    # Check if any parameter has completely decayed.\n    if n < 1:\n        print('Radius has completely decayed, finishing execution',\n        'at {} iterations'.format(i))\n        break\n    if learning_rate < 0.001:\n        print('Learning rate has completely decayed, finishing execution',\n        'at {} iterations'.format(i))\n        break\nelse:\n    print('Completed {} iterations.'.format(iterations))","267bd6ad":"def select_closest_np(candidates, origin):\n    \"\"\"Return the index of the closest candidate to a given point.\"\"\"\n    return euclidean_distance_np(candidates, origin).argmin()\n\ndef euclidean_distance_np(a, b):\n    \"\"\"Return the array of distances of two numpy arrays of points.\"\"\"\n    return np.linalg.norm(a - b, axis=1)\n\ndef route_distance_np(cities):\n    \"\"\"Return the cost of traversing a route of cities in a certain order.\"\"\"\n    points = cities[['x', 'y']]\n    distances = euclidean_distance_np(points, np.roll(points, 1, axis=0))\n    return np.sum(distances)\n\ndef get_route(problem,cities, network):\n    \"\"\"Return the route computed by a network.\"\"\"\n    problem[['x', 'y']] = cities\n    problem['winner'] = problem[['x', 'y']].apply(\n        lambda c: select_closest(network, torch.from_numpy(c)),\n        axis=1, raw=True)\n\n    return cities.sort_values('winner').index\nroute = get_route(problem,cities.cpu().numpy(), network.cpu().numpy())","5cbeb0b5":"**Original version: Solving the Traveling Salesman Problem using Self-Organizing Maps**\n\nBlog post explaining how it works:\nhttps:\/\/diego.codes\/post\/som-tsp\/\n\n\u4e2d\u6587\u7f51\u5740\uff1a\nhttps:\/\/mp.weixin.qq.com\/s\/O7UHeTFfcJ1FjNShVe9wtA\n\n- This turns the challenge into a ML-like problem\n- I've adapted it into a Pytorch version\n- Hyperparameters are not tuned."}}