{"cell_type":{"9857126e":"code","2e6475ea":"code","b0a95976":"code","c6ce2d60":"code","1105a1cc":"code","b6f604c3":"code","de9e527c":"code","055c378a":"code","d949bb97":"code","182cf702":"code","879e02d0":"code","d1899c1d":"code","05bde7f6":"code","c7244f1e":"code","a0d1d946":"code","1a40d504":"code","894c2990":"code","5329bd34":"code","1936d05b":"code","e986b399":"code","113ec0da":"code","1d3d56fc":"code","9e3a56b4":"code","abe46bf2":"code","e5dd0fbf":"code","8ec5d079":"code","97e2c541":"code","ea5b88c7":"markdown","a7f5ea8c":"markdown","bf26fb9e":"markdown","3f282196":"markdown","49d55131":"markdown","049da89e":"markdown","32cc77ad":"markdown","7ee0be43":"markdown","fcf7d170":"markdown","d376dbeb":"markdown","eadc4bea":"markdown","91d9c5b1":"markdown","b8071e7e":"markdown","2280e51e":"markdown","6f5b68e3":"markdown","1c89fd13":"markdown","2391ce89":"markdown","03f55147":"markdown"},"source":{"9857126e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport seaborn as sns\n","2e6475ea":"Train_data = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv')\nTest_data = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv')\ntrain_data = Train_data.copy()\ntest_data = Test_data.copy()","b0a95976":"train_data.head()","c6ce2d60":"train_date_index = train_data.set_index(pd.to_datetime(train_data['date']))","1105a1cc":"# Country = Finland, Store = KaggleMart, Product = 'Kaggle Mug'\nplt.figure(figsize = (30,10))\ntrain_Finland_KaggleMart_KaggleMug = train_date_index[(train_date_index['country'] == 'Finland') & (train_date_index['store'] == 'KaggleMart') & (train_date_index['product'] == 'Kaggle Mug')]\nsns.set()\nsns.lineplot(x = train_Finland_KaggleMart_KaggleMug.index, y = train_Finland_KaggleMart_KaggleMug['num_sold'].values)","b6f604c3":"def minmax_Year(series):\n    year = []\n    for i in series:\n        year.append((i - min(series)) \/ (max(series) - min(series)))\n    return year\na = [2015, 2016, 2017, 2018, 2019]\nb = minmax_Year(a)\n#Year\ndef split_Year(date):\n  return int(date.split('-')[0])\n\n#Month\ndef split_month(date):\n  return int(date.split('-')[1])\n\n#Day\ndef split_day(date):\n  return int(date.split('-')[2])\n\n#Weekend\ndef weekend(date):\n  import datetime\n  weekend = []\n  a = pd.to_datetime(date)\n  for i in range(len(a)):\n    if a.iloc[i].weekday() >= 5 :\n      weekend.append(1)\n    else:\n      weekend.append(0)\n  return weekend\n#Weekday\ndef weekday(date):\n    import datetime\n    weekday = []\n    a = pd.to_datetime(date)\n    for i in range(len(a)):\n        weekday.append(a.iloc[i].weekday())\n    return weekday","de9e527c":"train_data['Year'] = train_data['date'].apply(split_Year)\ntrain_data['Month'] = train_data['date'].apply(split_month)\ntrain_data['Day'] = train_data['date'].apply(split_day)\ntrain_data['Weekend'] = weekend(train_data['date'])\ntrain_data['Weekday'] = weekday(train_data['date'])\ntrainyear_minmax = []\nfor i in train_data['Year']:\n    trainyear_minmax.append(b[a.index(i)])\ntrain_data['Year'] = trainyear_minmax\ntrain_data = train_data.drop(columns = ['row_id', 'date', 'Year'])\n\n\ntest_data['Year'] = test_data['date'].apply(split_Year)\ntest_data['Month'] = test_data['date'].apply(split_month)\ntest_data['Day'] = test_data['date'].apply(split_day)\ntest_data['Weekend'] = weekend(test_data['date'])\ntest_data['Weekday'] = weekday(test_data['date'])\ntestyear_minmax = []\nfor i in test_data['Year']:\n    testyear_minmax.append(b[a.index(i)])\ntest_data['Year'] = testyear_minmax\ntest_data = test_data.drop(columns = ['row_id', 'date','Year'])","055c378a":"#Encoder the 'country', 'store', 'product'\n#Dummies the 'country', 'store', 'product'\ntrain_data_dum = pd.get_dummies(train_data[['country', 'store', 'product']])\ntest_data_dum = pd.get_dummies(test_data[['country', 'store', 'product']])\n\ntrain_data = pd.concat([train_data, train_data_dum],axis = 1)\ntest_data = pd.concat([test_data, test_data_dum],axis = 1)\n\ntrain_data = train_data.drop(columns = ['country', 'store', 'product'])\ntest_data = test_data.drop(columns = ['country', 'store', 'product'])","d949bb97":"train_data.info()","182cf702":"test_data.head()","879e02d0":"data = train_data.drop(columns = 'num_sold')\ntarget = train_data['num_sold']\n\nfrom sklearn.preprocessing import MinMaxScaler\nNormalize = MinMaxScaler()\ntarget = np.log(target)\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(data, target, train_size = 0.8, random_state = 5)\nx_train = Normalize.fit_transform(x_train)\nx_test = Normalize.transform(x_test)\n","d1899c1d":"from sklearn.tree import DecisionTreeRegressor\nsns.set()\nDTR = DecisionTreeRegressor(max_depth = 60, min_samples_leaf = 2).fit(x_train, y_train)\ny_pred_DTR = DTR.predict(x_test)\nplt.scatter(y_test, y_pred_DTR)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('DecisionTreeRegressor')\nplt.show()\nplt.clf()","05bde7f6":"from sklearn.ensemble import RandomForestRegressor\nsns.set()\nRFR = RandomForestRegressor(max_depth = 20, random_state = 5).fit(x_train, y_train)\ny_pred_RFR = RFR.predict(x_test)\nplt.scatter(y_test, y_pred_RFR)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('RandomFroestRegressor')\nplt.show()\nplt.clf()","c7244f1e":"from sklearn.ensemble import GradientBoostingRegressor\nsns.set()\nGBR = GradientBoostingRegressor(learning_rate=0.10, max_depth= 5,\n                                min_samples_leaf = 5,n_estimators = 500, random_state = 40,subsample = 0.3).fit(x_train, y_train)\ny_pred_GBR = GBR.predict(x_test)\nplt.scatter(y_test, y_pred_GBR)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('GradientBoostingRegressor')\nplt.show()\nplt.clf()\nprint(GBR.score(x_test, y_test))","a0d1d946":"from sklearn.svm import SVR\nsns.set()\nsvr_rbf = SVR(kernel = 'rbf').fit(x_train, y_train)\ny_pred_svr = svr_rbf.predict(x_test)\nplt.scatter(y_test, y_pred_svr)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('SVM_RBF')\nplt.show()\nplt.clf()","1a40d504":"from sklearn.svm import SVR\nsns.set()\nsvr_linear = SVR(kernel = 'linear').fit(x_train, y_train)\ny_pred_svr = svr_linear.predict(x_test)\nplt.scatter(y_test, y_pred_svr)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('SVM_Linear')\nplt.show()\nplt.clf()","894c2990":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nmodel = Sequential()\nmodel.add(Dense(512, input_shape = (x_train.shape[1], ), activation = 'sigmoid'))\nmodel.add(Dense(64,activation = 'sigmoid'))\nmodel.add(Dense(8))\nmodel.add(Dense(1))\nmodel.compile(loss = 'mse', optimizer = 'adam', metrics= 'mse')\nhistory = model.fit(x_train, y_train, batch_size = 128, epochs = 100 , validation_split= 0.2, verbose = 0)","5329bd34":"import seaborn as sns\nsns.set()\ndf_history = pd.DataFrame(history.history)\nsns.lineplot(x = df_history.index, y = df_history.loss)","1936d05b":"y_pred = model.predict(x_test)\nplt.scatter(y_test, y_pred)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.show()\nplt.clf()","e986b399":"from sklearn.neighbors import KNeighborsRegressor\nsns.set()\nKNN = KNeighborsRegressor(n_neighbors = 2, weights = 'distance').fit(x_train, y_train)\ny_pred_KNN = KNN.predict(x_test)\nplt.scatter(y_test, y_pred_KNN)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('KNeighborsRegressor')\nplt.show()\nplt.clf()","113ec0da":"import xgboost as xgb\nXG = xgb.XGBRegressor(objective ='reg:linear', learning_rate = 0.1, alpha = 6, n_estimators = 500).fit(x_train, y_train)\ny_pred_XG = XG.predict(x_test)\nplt.scatter(y_test, y_pred_XG)\nplt.plot([x for x in range(4, 10)], [x for x in range(4, 10)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('Xgboost Classifier')\nplt.show()\nplt.clf()\nprint(XG.score(x_test, y_test))","1d3d56fc":"from sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\ndef model_fit(x_train, x_test, y_train, y_test):\n\n  DTR = DecisionTreeRegressor(max_depth = 10, \n                              min_samples_leaf = 8).fit(x_train, y_train)\n\n  RFR = RandomForestRegressor(max_depth = 30).fit(x_train, y_train)\n    \n  GBR = GradientBoostingRegressor(learning_rate=0.10, max_depth= 6,\n                                min_samples_leaf = 5,n_estimators = 500, random_state = 40,subsample = 0.3).fit(x_train, y_train)\n\n  svr_rbf = SVR(kernel = 'rbf').fit(x_train, y_train)  \n\n  svr_linear = SVR(kernel = 'linear').fit(x_train, y_train)\n\n  KNN = KNeighborsRegressor(n_neighbors = 10).fit(x_train, y_train)\n    \n  XG = xgb.XGBRegressor(objective ='reg:linear', learning_rate = 0.1, alpha = 6, n_estimators = 500).fit(x_train, y_train)\n\n  return DTR, RFR, GBR, svr_rbf, svr_linear, KNN, XG","9e3a56b4":"Model = model_fit(x_train, x_test, y_train, y_test)\nML_model = ['DecisionTreeRegressor', 'RandomForestRegressor', 'GradientBoostingRegressor', 'svr_rbf', 'svr_linear', 'KNeighborsRegressor','Xgboost Classifier', 'DeepLearning']\nsns.set()\nfrom sklearn.metrics import r2_score\nR_square_num = []\nfor i in range(7):\n  R_square = r2_score(y_test, Model[i].predict(x_test))\n  R_square_num.append(R_square)\nR_square_num.append(r2_score(y_test, model.predict(x_test)))\nplt.figure(figsize = (10, 10))\nplt.xlabel('R Square Score')\nplt.ylabel('Model Type')\nplt.title('The R Square Score Comparsion')\nsns.barplot(x = R_square_num, y = ML_model)","abe46bf2":"Model = model_fit(x_train, x_test, y_train, y_test)\nML_model = ['DecisionTreeRegressor', 'RandomForestRegressor', 'GradientBoostingRegressor', 'svr_rbf', 'svr_linear', 'KNeighborsRegressor', 'Xgboost Classifier', 'DeepLearning']\nsns.set()\nfrom sklearn.metrics import mean_squared_error\nmse_num = []\nfor i in range(7):\n  mse = mean_squared_error(y_test, Model[i].predict(x_test))\n  mse_num.append(mse)\nmse_num.append(mean_squared_error(y_test, model.predict(x_test)))\nplt.figure(figsize = (10, 10))\nplt.xlabel('mean_square_error')\nplt.ylabel('Model Type')\nplt.title('The mean_square_error Comparsion')\nsns.barplot(x = mse_num, y = ML_model)","e5dd0fbf":"test_data = Normalize.transform(test_data)\nsubmission_target = np.exp(Model[6].predict(test_data))","8ec5d079":"submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\nsubmission['num_sold'] = submission_target\nsubmission.to_csv('submission.csv', index=False)","97e2c541":"submission","ea5b88c7":"## 3-8. Xgboost Classifier","a7f5ea8c":"## 3-3. GradientBoostingRegressor","bf26fb9e":"## 3-1. DecisionTreeRegressor","3f282196":"# **3. Seven Model Performance**\n","49d55131":"## 3-4. SVR rbf","049da89e":"## 3-2. RandomForestRegressor","32cc77ad":"## 4-2. Mean Square Root Comparsion","7ee0be43":"### Define the training data and training target","fcf7d170":"## 3-6. Deep Learning","d376dbeb":"## 4-1. R square score Comparsion","eadc4bea":"## 3-5. SVR Linear","91d9c5b1":"# **1. Read the Data**","b8071e7e":"# **2. Data Proprecessing**\n\n* I Split the 'date' column to 'Month' column and 'Day' column\n\n* I define the 'weekday' and 'weekend' columns from 'date' columns.\n\n* I dummies the 'country', 'store', 'product' columns.","2280e51e":"## 3-7. KNeighborsRegressor","6f5b68e3":"# **4. Eight Model Comparsion(R2_score and Mean squared error)**","1c89fd13":"# **6. Submission**","2391ce89":"# **7. Thanks for your view!**","03f55147":"# **5. Predict the Test_data**"}}