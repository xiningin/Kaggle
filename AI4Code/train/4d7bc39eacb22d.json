{"cell_type":{"a4c5b003":"code","90c8327a":"code","5f367b46":"code","894251c9":"code","0d44b844":"code","782284cc":"code","94376872":"code","f3b2fb8d":"code","488c767e":"code","691c03d6":"code","c3dfe226":"code","d4f2b688":"code","fa43c2f1":"code","9f4510a1":"code","4dcc7238":"code","a27044bd":"markdown","0b2d5b44":"markdown","1358eb5f":"markdown","2b942b56":"markdown","5c506d8b":"markdown","46166421":"markdown","ef8ddbad":"markdown"},"source":{"a4c5b003":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/input\/creditcardfraud'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90c8327a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot\n\nfrom pandas import read_csv, set_option\nfrom pandas.plotting import scatter_matrix","5f367b46":"df = pd.read_csv(\"..\/input\/d\/isaikumar\/creditcardfraud\/creditcard.csv\")","894251c9":"df.head()","0d44b844":"df.shape","782284cc":"df.info()","94376872":"#Count of Null Values\ndf.isnull().sum()","f3b2fb8d":"set_option('precision', 2)\ndf.describe()","488c767e":"\nset_option('precision', 2)\ndf.describe().T","691c03d6":"class_names = {0 :'fraud', 1:'not fraud'}\nprint(df.Class.value_counts().rename(index=class_names))","c3dfe226":"from sklearn.model_selection import train_test_split","d4f2b688":"y= df[\"Class\"]\nX = df.loc[:, df.columns != 'Class']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1\/3,random_state=42, stratify=y)","fa43c2f1":"from sklearn.metrics import accuracy_score","9f4510a1":"#Import Library for Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Initialize the Random Forest\nmodel = RandomForestClassifier()\n\n#Train the model using Training Dataset\nmodel.fit(X_train, y_train)\n\n# Prediction using test data\ny_pred = model.predict(X_test)\n\n# Calculate Model accuracy by comparing y_test and y_pred\nacc_rf = round( accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Accuracy of  Random Forest : ', acc_rf)","4dcc7238":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm\n       \n       \nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model, X_test, y_test)","a27044bd":"# Response Variable Analysis","0b2d5b44":"# Train Test Split","1358eb5f":"# Importing Libraries","2b942b56":"### EDA is the process of investigating the dataset to discover patterns, and anomalies (outliers), and form hypotheses based on our understanding of the dataset.","5c506d8b":"# Confusion Matrix\n","46166421":"# Data Modeling","ef8ddbad":"# Exploratory Data Analysis\n## Statistical Analysis of data"}}