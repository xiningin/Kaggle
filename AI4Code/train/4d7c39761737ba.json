{"cell_type":{"44388497":"code","8d71c0dc":"code","31e1e243":"code","3e948030":"code","9bea0a0c":"code","ebed2c0d":"code","04d80440":"code","26c75f07":"code","c75f8e6d":"code","6d33039d":"code","794f77fc":"code","2be38a38":"code","ba99c5e7":"code","c0527dee":"code","25f85b8c":"code","2e571589":"code","5991a1a3":"code","35fde9c6":"code","d9bcd9d2":"code","755c60a4":"code","affb0263":"code","f6958e50":"code","c75a3894":"code","e629f1c6":"markdown","16f3cb03":"markdown","d809e85e":"markdown","1a690bb2":"markdown","63434a4e":"markdown","75661e38":"markdown","536e620b":"markdown"},"source":{"44388497":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport seaborn as sns\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8d71c0dc":"#Load data\ndata_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","31e1e243":"data_train.head(3)","3e948030":"data_test.head(3)","9bea0a0c":"print(\"Shape of Train Data is \",data_train.shape)\nprint(\"Shape of Test Data is \",data_test.shape)","ebed2c0d":"print(data_train.isna().sum()[data_train.isna().sum()>0],'\\n','-------------------------------------')\nprint(data_test.isna().sum()[data_test.isna().sum()>0])","04d80440":"\nprint('Numeric Type Columns - Train Data\\n')\nprint(list(data_train._get_numeric_data().columns),'\\n\\n')\n\nprint('Categorical Type Columns - Train Data\\n')\nprint(list(set(data_train.columns)-set(data_train._get_numeric_data().columns)),'\\n\\n')\n\nprint('Numeric Type Columns - Test Data\\n')\nprint(list(data_test._get_numeric_data().columns),'\\n\\n')\n\nprint('Categorical Type Columns - Test Data\\n')\nprint(list(set(data_test.columns)-set(data_test._get_numeric_data().columns)),'\\n\\n')","26c75f07":"lst1 = data_train.columns[data_train.isna().any()].tolist()\nlst2 = data_test.columns[data_test.isna().any()].tolist()\n\nlst3=list(set(lst1 + lst2))\nresult = list(set(lst3) & set(list(data_train._get_numeric_data().columns)))\nprint(result)","c75f8e6d":"columns_to_fill = ['BsmtHalfBath', 'TotalBsmtSF', 'BsmtFinSF1', 'BsmtFullBath', 'LotFrontage', 'GarageCars', 'MasVnrArea', 'BsmtFinSF2', 'BsmtUnfSF', 'GarageArea', 'GarageYrBlt']\n\nfor i in columns_to_fill:\n    data_train[i] = data_train[i].fillna(value=data_train[i].mean())\n    data_test[i] = data_test[i].fillna(value=data_train[i].mean())\n    \ndata_test.fillna('Unknown',inplace=True)\ndata_train.fillna('Unknown',inplace=True)","6d33039d":"print(data_train.isna().sum()[data_train.isna().sum()>0],'\\n','-------------------------------------')\nprint(data_test.isna().sum()[data_test.isna().sum()>0])","794f77fc":"print(\"Training Data Description\\n\")\ndata_train.describe().transpose()","2be38a38":"print(\"Testing Data Description\\n\")\ndata_test.describe().transpose()","ba99c5e7":"train_data_numeric=list(data_train._get_numeric_data().columns)\ntrain_data_category=list(set(data_train.columns)-set(data_train._get_numeric_data().columns))\n\ntest_data_numeric=list(data_test._get_numeric_data().columns)\ntest_data_category=list(set(data_test.columns)-set(data_test._get_numeric_data().columns))\n\ntrain_data_numeric.remove('Id') # Remove id\ntrain_data_numeric.remove('MSSubClass') # Remove MSSubClass\ntrain_data_numeric.remove('SalePrice')\n\ntest_data_numeric.remove('Id') # Remove id\ntest_data_numeric.remove('MSSubClass') # Remove MSSubClass\n\ntrain_data_category.append('MSSubClass')\ntest_data_category.append('MSSubClass')\n\nprint(train_data_numeric==test_data_numeric, train_data_category==test_data_category)","c0527dee":"df = data_train\ndf['target'] = df['SalePrice']\ndf = df.drop(columns=['SalePrice','Id'])\ndf[train_data_numeric] = df[train_data_numeric].astype('float32')\ndf[train_data_category] = df[train_data_category].astype('str')\n\ntrain, val, test = np.split(df.sample(frac=1), [int(0.9*len(df)), int(0.95*len(df))])","25f85b8c":"def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n    df = dataframe.copy()\n    labels = df.pop('target')\n    df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(dataframe))\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(batch_size)\n    return ds","2e571589":"batch_size = 5\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\n[(train_features, label_batch)] = train_ds.take(1)\nprint('Every feature:', list(train_features.keys()))\nprint('A batch of ages:', train_features['MSSubClass'])\nprint('A batch of targets:', label_batch )","5991a1a3":"def get_normalization_layer(name, dataset):\n  # Create a Normalization layer for the feature.\n    normalizer = layers.Normalization(axis=None)\n\n  # Prepare a Dataset that only yields the feature.\n    feature_ds = dataset.map(lambda x, y: x[name])\n\n  # Learn the statistics of the data.\n    normalizer.adapt(feature_ds)\n\n    return normalizer\ndef get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n  # Create a layer that turns strings into integer indices.\n    if dtype == 'string':\n        index = layers.StringLookup(max_tokens=max_tokens)\n  # Otherwise, create a layer that turns integer values into integer indices.\n    else:\n        index = layers.IntegerLookup(max_tokens=max_tokens)\n\n  # Prepare a `tf.data.Dataset` that only yields the feature.\n    feature_ds = dataset.map(lambda x, y: x[name])\n\n  # Learn the set of possible values and assign them a fixed integer index.\n    index.adapt(feature_ds)\n\n  # Encode the integer indices.\n    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n\n  # Apply multi-hot encoding to the indices. The lambda function captures the\n  # layer, so you can use them, or include them in the Keras Functional model later.\n    return lambda feature: encoder(index(feature))\ndef plot_loss(history):\n    plt.plot(history.history['loss'], label='loss')\n    plt.plot(history.history['val_loss'], label='val_loss')\n    plt.ylim([0, 50000])\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)","35fde9c6":"batch_size = 64\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\ntest_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)","d9bcd9d2":"all_inputs = []\nencoded_features = []\n\n# Numerical features.\nfor header in train_data_numeric:\n    numeric_col = tf.keras.Input(shape=(1,), name=header)\n    normalization_layer = get_normalization_layer(header, train_ds)\n    encoded_numeric_col = normalization_layer(numeric_col)\n    all_inputs.append(numeric_col)\n    encoded_features.append(encoded_numeric_col)\n\n#Categorical features\ncategorical_cols = train_data_category\n\nfor header in categorical_cols:\n    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n    encoding_layer = get_category_encoding_layer(name=header,\n                                               dataset=train_ds,\n                                               dtype='string',\n                                               max_tokens=10)\n    encoded_categorical_col = encoding_layer(categorical_col)\n    all_inputs.append(categorical_col)\n    encoded_features.append(encoded_categorical_col)","755c60a4":"callback = []\ncallback.append(tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=100, restore_best_weights=True\n))\n\n\nall_features = tf.keras.layers.concatenate(encoded_features)\nx = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(all_features)\nx = tf.keras.layers.Dense(8, activation=\"relu\")(x)\noutput = tf.keras.layers.Dense(1)(x)\n\nmodel = tf.keras.Model(all_inputs, output)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(\n                learning_rate=0.06236280315181433),\n              loss='mae')\n\nhistory = model.fit(train_ds, epochs=2000, verbose=2, validation_data=val_ds, callbacks=callback)\nplot_loss(history)","affb0263":"sample = data_test.copy()\nsample[test_data_numeric] = sample[test_data_numeric].astype('float32')\nsample[test_data_category] = sample[test_data_category].astype('str')\nsample = sample.drop(columns=['Id'])\n\ndef test_df_to_dataset(dataframe, batch_size=64):\n    df = dataframe.copy()\n    df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n    ds = tf.data.Dataset.from_tensor_slices((dict(df), None))\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(batch_size)\n    return ds\n\nsample = test_df_to_dataset(sample)","f6958e50":"test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmission = pd.DataFrame({\n    'Id': test['Id'],\n    'SalePrice':model.predict(sample).flatten(),\n})","c75a3894":"submission.to_csv('submission.csv',index=False)","e629f1c6":"Look at data now","16f3cb03":"Prepare test data to predict","d809e85e":"# Discribe data","1a690bb2":"Save numeric and category columns w\/o id and add MSSubClass to categorical data","63434a4e":"Look at types of columns","75661e38":"Hyperparameters founded by Hyperband keras","536e620b":"Let's found numerical columns with nan in data to fill it with mean "}}