{"cell_type":{"79fa8b16":"code","86af3668":"code","f1e267e7":"code","bd95525e":"code","d6f401b3":"code","5e5285e4":"code","f05581c0":"code","261da841":"code","95662b3a":"code","f4ee471b":"code","2d6a57b6":"code","31dd3f7a":"code","ad9f1c51":"code","e40b06f5":"code","40edd163":"code","f6ca012d":"code","709b6b70":"code","4aa50136":"code","4838743c":"code","d7df25ee":"code","8067c1b7":"code","4e1be1fa":"code","acfec64a":"code","fccca632":"code","904a5df1":"code","cc287b54":"code","c8349c92":"code","a01c0ae3":"markdown","bdf303d6":"markdown"},"source":{"79fa8b16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.functional as F\nimport random\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86af3668":"train = pd.read_csv(\"\/kaggle\/input\/aiproject-crisislevel\/Trainsample.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/aiproject-crisislevel\/Testsample.csv\")\nsubmit_sample = pd.read_csv(\"\/kaggle\/input\/aiproject-crisislevel\/submit_sample.csv\")","f1e267e7":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ntorch.manual_seed(1)\nrandom.seed(1)\ntorch.cuda.manual_seed_all(1)","bd95525e":"train.head()","d6f401b3":"for i in train:\n    print(i)\n    print(train[i].unique)","5e5285e4":"train.info()","f05581c0":"train['year'] = train['date'].str.split(\"-\").str[0]\ntrain['month'] = train['date'].str.split(\"-\").str[1]\n#train['day'] = train['date'].str.split(\"-\").str[2]\n\ntest['year'] = test['date'].str.split(\"-\").str[0]\ntest['month'] = test['date'].str.split(\"-\").str[1]\n#test['day'] = test['date'].str.split(\"-\").str[2]","261da841":"train = train.drop(['date'], axis = 1)\ntest = test.drop(['date'], axis = 1)","95662b3a":"train['year'] = train['year'].astype('int')\ntrain['month'] = train['month'].astype('int')\n#train['day'] = train['day'].astype('int')\n\ntest['year'] = test['year'].astype('int')\ntest['month'] = test['month'].astype('int')\n#test['day'] = test['day'].astype('int')","f4ee471b":"from sklearn.preprocessing import LabelEncoder\n\ntestrain = pd.concat([train['variety_code'], test['variety_code']], axis = 0)\ntrans = LabelEncoder().fit(testrain)\ntrain['variety_code'] = trans.transform(train['variety_code'])\ntest['variety_code'] = trans.transform(test['variety_code'])","2d6a57b6":"test.info()\ntrain.info()","31dd3f7a":"ytrain = train['target']\nxtrain = train.drop(['target'], axis = 1)\nxtest = test","ad9f1c51":"train.variety_code.unique() # 0 ~ 5 \uae4c\uc9c0\uc758 \ud488\uc885","e40b06f5":"list_index = []\nlist_index_test = []\nfor i in range(6):\n    list_index.append(np.array(train.loc[train.variety_code == i].index))\n    list_index_test.append(np.array(test.loc[test.variety_code == i].index))\n\n#list_index[5] = np.array(train.loc[train.variety_code == 5].index)\n#list_index[4] = np.array(train.loc[train.variety_code == 4].index)\n#list_index[3] = np.array(train.loc[train.variety_code == 3].index)\n#list_index[2] = np.array(train.loc[train.variety_code == 2].index)\n#list_index[1] = np.array(train.loc[train.variety_code == 1].index)\n#list_index[0] = np.array(train.loc[train.variety_code == 0].index)","40edd163":"lens = len(list_index[0]) + len(list_index[1]) + len(list_index[2]) + len(list_index[3]) + len(list_index[4]) + len(list_index[5])  \nlens == len(xtrain.index)","f6ca012d":"from sklearn.preprocessing import StandardScaler\nstand = StandardScaler()\nfor i in range(6):\n    xtrain.loc[list_index[i],:] = stand.fit_transform(xtrain.loc[list_index[i],:])\n    xtest.loc[list_index_test[i],:] = stand.transform(xtest.loc[list_index_test[i],:])","709b6b70":"xtrain.iloc[:,3:9]","4aa50136":"xtrain = xtrain.drop(['variety_code'], axis = 1)\nxtest = xtest.drop(['variety_code'], axis = 1)","4838743c":"x_train = torch.FloatTensor(np.array(xtrain)).to(device)\ny_train = torch.LongTensor(ytrain).to(device)\nx_test = torch.FloatTensor(np.array(xtest)).to(device)","d7df25ee":"y_train = y_train -1\ny_train","8067c1b7":"class DNN_Model(torch.nn.Module):\n    def __init__(self):\n        super(DNN_Model, self).__init__()\n        \n        self.linear1 = nn.Linear(12, 256, bias = True)\n        self.linear2 = nn.Linear(256, 256, bias = True)\n        self.linear3 = nn.Linear(256, 256, bias = True)\n        self.linear4 = nn.Linear(256, 7)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p = 0.2)\n        self._init_param()\n    \n    def forward(self, train):\n        \n        out = self.linear1(train)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.linear2(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.linear3(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.linear4(out)\n        \n        return out\n    \n    def _init_param(self):\n        \n        nn.init.xavier_uniform_(self.linear1.weight)\n        nn.init.xavier_uniform_(self.linear2.weight)\n        nn.init.xavier_uniform_(self.linear3.weight)\n        nn.init.xavier_uniform_(self.linear4.weight)","4e1be1fa":"nb_epochs = 1000\nlearning_rate = 0.001\nbatch_size = 1000","acfec64a":"from torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\n\ndataset = TensorDataset(x_train, y_train)\ndataloader = DataLoader(dataset = dataset,\n                        batch_size = batch_size,\n                        shuffle = True)","fccca632":"model = DNN_Model().to(device)\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\nloss = nn.CrossEntropyLoss()","904a5df1":"for epoch in range(nb_epochs):\n    total_batch = len(dataloader)\n    avg_cost = 0.0\n    running_correct = 0\n    for X, Y in dataloader:\n        X = X.to(device)\n        Y = Y.to(device)\n        \n        hypothesis = model(X)\n        cost = loss(hypothesis, Y)\n        \n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n        \n        avg_cost += cost.item()\n        pred = torch.argmax(hypothesis, 1)\n        running_correct += (pred == Y).sum().item()\n    if epoch % 100 == 0:\n        avg_cost \/= total_batch\n        train_accuracy = 100.* running_correct\/len(dataloader.dataset)\n        print(f'Train Loss : {avg_cost:.4f}, Train Accuracy: {train_accuracy:.2f}')","cc287b54":"with torch.no_grad():\n    pred_hypo = model(x_test)\n    pred = torch.argmax(pred_hypo, 1)\n    pred = pred + 1\n    submit_sample['target'] = np.array(pred.cpu())","c8349c92":"submit = submit_sample.to_csv(\"submit_baseline.csv\", index = None)","a01c0ae3":"**Model**\n","bdf303d6":"* train\uacfc test \ub370\uc774\ud130\uc5d0\uc11c date \uc5f4 \ub370\uc774\ud130\ub294 '\uc5f0-\uc6d4-\uc77c'\uc774\ub2e4. \n* \uc989 \ubb38\uc790\uc5f4\uc5d0 '-'\uc774 \ud3ec\ud568\uc774 \ub418\uc5c8\uc73c\ubbc0\ub85c \uac01\uac01 '-'\ub97c \uae30\uc900\uc73c\ub85c \uc5f0, \uc6d4, \uc77c\uc744 \ub098\ub204\uace0 \uadf8 \uac12\ub4e4\uc744 \uc0c8\ub85c\uc6b4 column\uc744 \uc0dd\uc131\ud558\uc5ec \ucd94\uac00\ud55c\ub2e4."}}