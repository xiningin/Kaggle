{"cell_type":{"2e54a69c":"code","f0318233":"code","f584a118":"code","364ea694":"code","2e136b6d":"code","4411cb2a":"code","83208b37":"code","1084b143":"code","40aef88c":"code","d3ca82be":"code","0ae2b3fc":"code","3c715cef":"code","98131d78":"code","bf933a6b":"code","dbe6f117":"code","b7ed0ade":"code","8b05de40":"code","25184fff":"code","a0335fd4":"code","628b0cef":"code","b8a92019":"code","c5dcaed0":"code","d6fa23ac":"code","73fc12fa":"code","2b9ea3c0":"code","07f17f5c":"code","55271dfd":"code","2ac80711":"code","23aef2c4":"code","6e3209f3":"code","2bae2a0f":"code","06e2096d":"code","40cda2cc":"code","2bbeb601":"code","7d9a0660":"code","d14aad49":"code","1daecfcc":"code","f1cc5706":"code","79cc18a8":"code","75e34e86":"code","edc7761e":"code","7d9287f8":"code","bbc357ac":"code","f1ee5954":"code","055616a8":"code","b1a81508":"code","a13ea754":"code","97e39bea":"code","e66e87be":"code","babd58ed":"code","5e209178":"code","2296b75c":"code","e6a55a85":"code","f39ec105":"code","6c0d5a72":"code","de19cb56":"code","161773b8":"code","224db78c":"code","e8bd963f":"code","a5cacb1a":"code","a97a7825":"code","cc3be65c":"code","f0beb582":"code","14d1b757":"code","35a38e90":"code","888fac98":"code","6ef9770b":"code","5fda69de":"code","fc081294":"code","f21561cd":"code","e52450aa":"code","f12c389a":"code","48f20a4c":"code","97eab4a2":"code","e4ec33ef":"code","3d209096":"code","d72d3a54":"code","7b92676c":"code","6bd2c07f":"code","f30f15c4":"code","6bbd2138":"code","e14ea627":"code","2eb468a1":"code","56520211":"markdown","d217de7d":"markdown","ee55d2bf":"markdown","e27bce09":"markdown","a602f6aa":"markdown","408b0ead":"markdown","f1a07596":"markdown","11893b68":"markdown","fc30df64":"markdown","02d7ea9e":"markdown","42ffee4d":"markdown","5b140e63":"markdown","b775a894":"markdown"},"source":{"2e54a69c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0318233":"import plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","f584a118":"!pip install category-encoders","364ea694":"!pip install lightgbm","2e136b6d":"!pip install catboost","4411cb2a":"!pip install scikit-optimize","83208b37":"from skopt import BayesSearchCV\nfrom skopt.space import Real, Categorical, Integer  \nfrom sklearn.model_selection import RandomizedSearchCV","1084b143":"import category_encoders as ce\nfrom sklearn.preprocessing import QuantileTransformer,RobustScaler,StandardScaler\nfrom sklearn.linear_model import ElasticNet,LinearRegression\nfrom sklearn.model_selection import cross_val_score,cross_val_predict\nfrom sklearn.pipeline import Pipeline\nimport lightgbm as lgbm\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA,KernelPCA\nfrom catboost import CatBoostRegressor\nfrom sklearn.svm import SVR\nfrom h2o.estimators import H2OXGBoostEstimator\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import StackingRegressor,RandomForestRegressor","40aef88c":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.callbacks import EarlyStopping","d3ca82be":"import h2o\nh2o.init()","0ae2b3fc":"train_df=h2o.import_file('\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv')\ntest_df=h2o.import_file('\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv')","3c715cef":"train_df.shape","98131d78":"train_df.describe()","bf933a6b":"train_df.as_data_frame().isnull().sum()","dbe6f117":"test_df.as_data_frame().isnull().sum()","b7ed0ade":"train_df.as_data_frame().skew()","8b05de40":"fig=go.Figure()\n\nfig.add_trace(go.Histogram(x=train_df.as_data_frame()['target'],name='Train'))\nfig.show()","25184fff":"\"\"\"\ntrain_num=train_df.as_data_frame().select_dtypes(exclude='object')\n\ntrain_num=train_num[train_num.columns[1:-1]]\n\nfig=make_subplots(rows=7,cols=2,subplot_titles=(train_num.columns))\nindex=0\n\nfor i in range(1,8):\n    for j in range(1,3):\n        train_data=train_df.as_data_frame()[train_num.columns[index]]\n        test_data=test_df.as_data_frame()[train_num.columns[index]]\n        fig.add_trace(go.Histogram(x=train_data),row=i,col=j)\n        fig.add_trace(go.Histogram(x=test_data),row=i,col=j)\n        # Overlay both histograms\n        fig.update_layout(barmode='overlay')\n        # Reduce opacity to see both histograms\n        fig.update_traces(opacity=0.75)\n        index+=1\n        \nfig.update_layout(height=900,width=1250,title_text=\"Distribution of Training and Testing Data\")\nfig.show(\"notebook\")\n\"\"\"","a0335fd4":"train_df.as_data_frame().select_dtypes(include='object').shape","628b0cef":"train_df.as_data_frame().select_dtypes(include='object').columns","b8a92019":"\"\"\"\ntrain_cat=train_df.as_data_frame().select_dtypes(include='object')\n\nfig=make_subplots(rows=5,cols=2,subplot_titles=(train_cat.columns))\nindex=0\n\nfor i in range(1,6):\n    for j in range(1,3):\n        train_data=train_df.as_data_frame()[train_cat.columns[index]]\n        test_data=test_df.as_data_frame()[train_cat.columns[index]]\n        fig.add_trace(go.Histogram(x=train_data),row=i,col=j)\n        fig.add_trace(go.Histogram(x=test_data),row=i,col=j)\n        # Overlay both histograms\n        fig.update_layout(barmode='group')\n        index+=1\n        \nfig.update_layout(height=900,width=1250,title_text=\"Distribution of Categorical Training and Testing Data\")\nfig.show(\"notebook\")\n\"\"\"","c5dcaed0":"X=train_df[train_df.columns[1:-1]].as_data_frame()\ny=train_df[train_df.columns[-1]].as_data_frame()","d6fa23ac":"cat_encoder=ce.CatBoostEncoder(cols=list(train_df.as_data_frame().select_dtypes(include='object').columns))\nqt=QuantileTransformer(output_distribution='normal')\nrs=RobustScaler()\nen=ElasticNet(random_state=123)\npoly=PolynomialFeatures(include_bias=False,degree=2)\npca=PCA(n_components=0.99)","73fc12fa":"en_pipeline=Pipeline([('Cat_Encoder',cat_encoder),\n                  ('Quantile transformer',qt),\n                  ('Scaling',rs),\n                  ('Elastic Net',en)])","2b9ea3c0":"en_scores=cross_val_score(en_pipeline,X,y,cv=3,scoring='neg_mean_squared_error')","07f17f5c":"np.mean(np.sqrt(-en_scores))","55271dfd":"y_pred=cross_val_predict(en_pipeline,X,y,cv=3)","2ac80711":"en_pipeline.fit(X,y)\ny_pred=en_pipeline.predict(X)","23aef2c4":"#Below plot is not a straight line\n#px.scatter(x=np.ravel(y.values),y=y_pred) ","6e3209f3":"preprocess_pipe=Pipeline([('Cat_Encoder',cat_encoder),\n                  ('Quantile transformer',qt),\n                  ('Scaling',rs)])","2bae2a0f":"X_preprocessed=preprocess_pipe.fit_transform(X,y)","06e2096d":"X_preprocessed_df=pd.DataFrame(X_preprocessed,columns=X.columns)","40cda2cc":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif=[variance_inflation_factor(X_preprocessed_df.values,i) for i in range(X_preprocessed_df.shape[1])]","2bbeb601":"vif","7d9a0660":"lgb_reg =lgbm.LGBMRegressor(random_state=123)\nlgbm_pipeline=Pipeline([('Cat_Encoder',cat_encoder),\n                        ('pca',pca),\n                  ('lgbm',lgb_reg)])","d14aad49":"#lgbm_scores=cross_val_score(lgbm_pipeline,X,np.ravel(y),cv=3,scoring='neg_mean_squared_error')","1daecfcc":"#np.mean(np.sqrt(-lgbm_scores))","f1cc5706":"\"\"\"\nparam_test ={'lgbm__n_estimators':[1000,1500,2000,2500,3000,3500,4000],\n             'lgbm__max_depth':[1,2,3,4,5,6,7,8],\n             'lgbm__l2_leaf_reg': np.arange(2, 30,1)}\n\ntuned_lgbm=BayesSearchCV(lgbm_pipeline,param_test,cv=3,scoring='neg_mean_squared_error',random_state=123)\ntuned_lgbm.fit(X,np.ravel(y))\n\"\"\"","79cc18a8":"#np.sqrt(-tuned_lgbm.best_score_) ","75e34e86":"#tuned_lgbm.best_params_","edc7761e":"lgb_reg =lgbm.LGBMRegressor(random_state=123,l2_leaf_reg=20,max_depth=3,n_estimators=1000)\nlgbm_pipeline=Pipeline([('Cat_Encoder',cat_encoder),\n                        ('pca',pca),\n                  ('lgbm',lgb_reg)])","7d9287f8":"lgbm_scores=cross_val_score(lgbm_pipeline,X,np.ravel(y),cv=3,scoring='neg_mean_squared_error')","bbc357ac":"np.mean(np.sqrt(-lgbm_scores))","f1ee5954":"lgbm_pipeline.fit(X,np.ravel(y))","055616a8":"\ncat =CatBoostRegressor(random_state=123,cat_features=list(train_df.as_data_frame().select_dtypes(include='object').columns))\n\ncat_pipeline=Pipeline([('catboost',cat)])","b1a81508":"#cat_scores=cross_val_score(cat_pipeline,X,np.ravel(y),cv=3,scoring='neg_mean_squared_error')","a13ea754":"#np.mean(np.sqrt(-cat_scores))","97e39bea":"\"\"\"\nsearch_spaces = {'catboost__iterations': [1000,1500,2000,2500,3000,3500,4000],\n                 'catboost__depth': Integer(1, 8),\n                 #'catboost__learning_rate': Real(0.01, 1.0, 'log-uniform'),\n                 #'catboost__random_strength': Real(1e-9, 10, 'log-uniform'),\n                 #'catboost__bagging_temperature': Real(0.0, 1.0),\n                 #'catboost__border_count': Integer(1, 255),\n                 'catboost__l2_leaf_reg': Integer(2, 40)}\n\"\"\"                 ","e66e87be":"\"\"\"\ntuned_cat=BayesSearchCV(cat_pipeline,search_spaces,cv=3,scoring='neg_mean_squared_error',random_state=123)\ntuned_cat.fit(X,np.ravel(y))\n\"\"\"","babd58ed":"\ncat =CatBoostRegressor(random_state=123,\n                       iterations=3000,\n                       l2_leaf_reg=10,\n                       cat_features=list(train_df.as_data_frame().select_dtypes(include='object').columns))\n\ncat_pipeline=Pipeline([('catboost',cat)])             \n","5e209178":"cat_scores=cross_val_score(cat_pipeline,X,np.ravel(y),cv=3,scoring='neg_mean_squared_error')","2296b75c":"np.mean(np.sqrt(-cat_scores)) ","e6a55a85":"cat_pipeline.fit(X,np.ravel(y)) ","f39ec105":"y_lgbm=lgbm_pipeline.predict(X)\ny_cat=cat_pipeline.predict(X)","6c0d5a72":"en_df=pd.DataFrame()\nen_df['LGBM']=y_lgbm\nen_df['CAT']=y_cat\nen=ElasticNet(random_state=123)\npoly=PolynomialFeatures(include_bias=False,degree=2)","de19cb56":"ensemble_pipe=Pipeline([('poly_features',poly),('linear reg',en)])","161773b8":"ensemble_scores=cross_val_score(ensemble_pipe,en_df,np.ravel(y),scoring='neg_mean_squared_error',cv=3)  ","224db78c":"np.sqrt(-ensemble_scores.mean())","e8bd963f":"ensemble_pipe.fit(en_df,np.ravel(y))","a5cacb1a":"#estimators=[('lgbm', lgbm_pipeline),('catboost',cat_pipeline)]","a97a7825":"\"\"\"\nreg = StackingRegressor(estimators=estimators,\n                        final_estimator=lgbm.LGBMRegressor(random_state=123))\n\"\"\"                        ","cc3be65c":"#ensemble_scores=cross_val_score(reg,X,np.ravel(y),scoring='neg_mean_squared_error',cv=3)  ","f0beb582":"#np.sqrt(-ensemble_scores.mean()) #0.8439311919873552 with LGBM as final estimator","14d1b757":"#reg.fit(X,np.ravel(y)) ","35a38e90":"\"\"\"  \nann = Sequential()\nann.add(BatchNormalization())\nann.add(Dense(units=50,activation='selu',kernel_initializer='lecun_normal',input_dim=NN_in.shape[1]))\nann.add(Dropout(0.3,seed=0))\nann.add(BatchNormalization())\nann.add(Dense(units=100,activation='selu',kernel_initializer='lecun_normal'))\nann.add(Dropout(0.3,seed=0))\nann.add(BatchNormalization())\nann.add(Dense(units=50,activation='selu',kernel_initializer='lecun_normal'))\nann.add(Dropout(0.3,seed=0))\nann.add(BatchNormalization())\nann.add(Dense(units=1,activation='sigmoid',kernel_initializer='glorot_uniform'))\n\"\"\"","888fac98":"\"\"\"\nann.compile(optimizer='adam',loss='mean_squared_error')\n\n#early stopping to avoid overfitting\n\nes=EarlyStopping(monitor='val_mean_squared_error',patience=20,mode='min')\n\nmodel_history=ann.fit(NN_in,np.ravel(y),epochs=50,validation_split=0.1,callbacks=[es],batch_size=100)\n\"\"\"","6ef9770b":"\"\"\"\nfig=go.Figure()\n\nfig.add_trace(go.Scatter(x=[i for i in range(0,101)],y=model_history.history['loss'],mode='lines',name='Training Error'))\nfig.add_trace(go.Scatter(x=[i for i in range(0,101)],y=model_history.history['val_loss'],mode='lines',name='Validation Error'))\nfig.show()\n\"\"\"","5fda69de":"test_df.head()  ","fc081294":"X_test=test_df[test_df.columns[1:]].as_data_frame()","f21561cd":"\ny_lgbm=lgbm_pipeline.predict(X_test)\ny_cat=cat_pipeline.predict(X_test)\n","e52450aa":"en_df=pd.DataFrame()\nen_df['LGBM']=y_lgbm\nen_df['CAT']=y_cat","f12c389a":"en_df.shape","48f20a4c":"len(y_lgbm),len(y_cat)","97eab4a2":"y_ensemble=ensemble_pipe.predict(en_df)","e4ec33ef":"sub_df=pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')","3d209096":"sub_df.head()","d72d3a54":"sub_df.shape","7b92676c":"#sub_df['target']= y_cat","6bd2c07f":"sub_df['target']= (0.7*y_cat)+(0.3*y_lgbm)","f30f15c4":"sub_df.to_csv('submission.csv', index=False)","6bbd2138":"sub_df1=sub_df.copy()\nsub_df1['target']= (0.8*y_cat)+(0.2*y_lgbm)\nsub_df2=sub_df.copy()\nsub_df2['target']= (0.6*y_cat)+(0.2*y_lgbm)+(0.2*y_ensemble)\nsub_df3=sub_df.copy()\nsub_df3['target']= (0.7*y_cat)+(0.2*y_lgbm)+(0.1*y_ensemble)\nsub_df4=sub_df.copy()\nsub_df4['target']= (0.7*y_cat)+(0.1*y_lgbm)+(0.2*y_ensemble)","e14ea627":"sub_df1.to_csv('submission_df1.csv', index=False)\nsub_df2.to_csv('submission_df2.csv', index=False)\nsub_df3.to_csv('submission_df3.csv', index=False)\nsub_df4.to_csv('submission_df4.csv', index=False)","2eb468a1":"sub_df.head()","56520211":"### Ensemble","d217de7d":"No multicollinearity present but since there is no linearity present we cannot use Linear models.\n\n### LightGBM Pipeline\n\nLGBM can handle categorical features by changing the data types pf these features to \"category: however it is mentioned in the [documentation](http:\/\/lightgbm.readthedocs.io\/en\/latest\/Advanced-Topics.html) that for high cardinality datasets it is better to convert the categorical data as numeric\n\n0.86007457730236 as rmse with pca and 0.8589879204686376 as rmse with hyperparametertuning. ","ee55d2bf":"Adding polynomial features did not improve the performance","e27bce09":"### Test Data","a602f6aa":"Target has a left tail distribution. Transforming the target variable might help.","408b0ead":"Let's check the assumptions of linear regssion are met or not.","f1a07596":"\n![image.png](attachment:image.png)","11893b68":"### Outliers","fc30df64":"![image.png](attachment:image.png)\n\nI have commented the above code block as it takes up a lot of memory but I have attached the output graph as png in this cell.\n\n1. All features have different scales - Scaling is needed esp for linear and NN\n2. All the features have different distribution and none of them follow normal distrubtion\n3. Training and Testing distributions match for each feature","02d7ea9e":"### Catboost Pipeline\n\n0.8446898153043176 as rmse with just catboost.","42ffee4d":"### Getting the data","5b140e63":"### Elasticnet Pipeline\n\n1. Catboost encoder\n2. Quantile Transformation\n3. Robust Scaling \n4. Elastic Net Regression","b775a894":"### Missing Values\n\nThere are no missing values in both train and test."}}