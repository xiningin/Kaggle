{"cell_type":{"22e0203e":"code","816375f3":"code","bf2e23ed":"code","5a09194f":"code","6fb6d559":"code","5e0b4de4":"code","566cf8f8":"code","c9cc156d":"code","2b9eab5e":"code","785c938d":"code","d6a4b47d":"code","d2ec6402":"markdown","70bfbf2d":"markdown","a4871f0a":"markdown","fdc0a22c":"markdown","f35fbdb4":"markdown","af3a866b":"markdown","d01ef234":"markdown","5cd99a96":"markdown","08f99afb":"markdown"},"source":{"22e0203e":"import io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras","816375f3":"#Copying current content to new editable directory\n\n!cp -r \"..\/input\/asl-dataset\/asl_dataset\/\" \"\/kaggle\/working\/\"\n\n#Selecting dataset directory\n\nds_asl_dir = \"\/kaggle\/working\/asl_dataset\/asl_dataset\"\n\n#Generating a dataset\n\nasl_ds = tf.keras.preprocessing.image_dataset_from_directory(ds_asl_dir)","bf2e23ed":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"none\"\n\n#Listing directory. You can find the class names in the class_names attribute on these datasets. These correspond to the directory names in alphabetical order.\n\n!ls \"\/kaggle\/working\/asl_dataset\/asl_dataset\"\n\n#Showing index + class\n\npd.DataFrame(asl_ds.class_names)","5a09194f":"#Checking images and labels shapes (amount of images, height, width, color channels)\n\nfor image_batch, labels_batch in asl_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","6fb6d559":"#Displaying some picture\u00b4s size\n\nfrom PIL import Image\nimg =  Image.open(\"\/kaggle\/working\/asl_dataset\/asl_dataset\/0\/hand1_0_bot_seg_1_cropped.jpeg\")\nwidth, height = img.size\nprint(f\"Image sample with width={width} and height={height}.\")","5e0b4de4":"#Displaying image samples\n\nplt.figure(figsize=(10, 10))\nfor images, labels in asl_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","566cf8f8":"#Defining parameters for the loader\n\nbatch_size = 32\nimg_height = 64\nimg_width = 64\n\n#Filtering out corrupted images\n\nimport os\nnum_skipped = 0\nfor folder_name in (\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\"\n                    ,\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"):\n    folder_path = os.path.join(ds_asl_dir, folder_name)\n    for fname in os.listdir(folder_path):\n        fpath = os.path.join(folder_path, fname)\n        try:\n            fobj = open(fpath, \"rb\")\n            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n        finally:\n            fobj.close()\n        if not is_jfif:\n            num_skipped += 1\n            # Delete corrupted image\n            os.remove(fpath)\nprint(\"Deleted %d images\" % num_skipped)\n\n#Augmenting the images\n\nfrom keras.preprocessing.image import ImageDataGenerator\ndata_augmentation = ImageDataGenerator(rotation_range=15, rescale=1\/255, zoom_range=0.1, horizontal_flip=True,\n                                       width_shift_range=0.1, height_shift_range=0.1, validation_split=0.2)\n\n#Setting train\/test split\n\nasl_train_ds = data_augmentation.flow_from_directory(directory=ds_asl_dir, target_size=(img_height, img_width),\n                                                     class_mode=\"categorical\", batch_size=batch_size, subset=\"training\")\nasl_test_ds = data_augmentation.flow_from_directory(directory=ds_asl_dir, target_size=(img_height, img_width),\n                                                    class_mode=\"categorical\", batch_size=batch_size, subset=\"validation\")","c9cc156d":"from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense\n\n#Checking if the data format i.e the RGB channel is coming first or last so, whatever it may be, model will check first and then input shape will be feeded accordingly.\n\nfrom keras import backend as K\nif K.image_data_format() == \"channels_first\":\n    input_shape = (3, img_height, img_width)\nelse:\n    input_shape = (img_height, img_width, 3)\n\n#Creating a model\n\nmodel_dl = keras.Sequential()\nmodel_dl.add(Conv2D(16,(3,3),activation=\"relu\",input_shape=(input_shape)))\nmodel_dl.add(MaxPool2D(2,2))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Conv2D(32,(3,3),activation=\"relu\"))\nmodel_dl.add(MaxPool2D(2,2))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Conv2D(64,(3,3),activation=\"relu\"))\nmodel_dl.add(MaxPool2D(2,2))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Flatten())\nmodel_dl.add(Dense(128,activation=\"relu\"))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Dense(36,activation=\"softmax\"))","2b9eab5e":"#Compiling the neural network\n\nmodel_dl.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n#Fitting to the model\n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau #Import callback functions\nearlystop=EarlyStopping(patience=10) #Monitor the performance. If it dips, then stop training\nlearning_rate_reduce=ReduceLROnPlateau(monitor=\"val_acc\",min_lr=0.001) #Change learning rate if not performing good enough\ncallbacks=[earlystop,learning_rate_reduce]\n\nmodel_dl.fit(asl_train_ds, validation_data=asl_test_ds, callbacks=callbacks, epochs=40)","785c938d":"#Saving the model\n\nmodel_dl.save(\"model_dl.h5\")\n\n#Loading themodel\n\nmodel_dl = keras.models.load_model(\"model_dl.h5\") #look for local saved file","d6a4b47d":"#We\u00b4ll use any image sample from the Kaggle dataset to test it \n\nfrom keras.preprocessing import image\n\n#Creating a dictionary to map each of the indexes to the corresponding number or letter\n\ndict = {0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\",10:\"a\",11:\"b\",12:\"c\",13:\"d\",14:\"e\",15:\"f\",16:\"g\",\n        17:\"h\",18:\"i\",19:\"j\",20:\"k\",21:\"l\",22:\"m\",23:\"n\",24:\"o\",25:\"p\",26:\"q\",27:\"r\",28:\"s\",29:\"t\",30:\"u\",31:\"v\",32:\"w\",\n        33:\"x\",34:\"y\",35:\"z\"}\n\n#Predicting images\n\nimg = image.load_img(\"\/kaggle\/working\/asl_dataset\/asl_dataset\/a\/hand1_a_bot_seg_1_cropped.jpeg\", target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimage = np.vstack([x])\nclasses = model_dl.predict_classes(image, batch_size=batch_size)\nprobabilities = model_dl.predict_proba(image, batch_size=batch_size)\nprobabilities_formatted = list(map(\"{:.2f}%\".format, probabilities[0]*100))\n\nprint(classes) #displaying matrix prediction position\n\nprint(f'The predicted image corresponds to \"{dict[classes.item()]}\" with {probabilities_formatted[classes.item()]} probability.') #displaying matrix prediction position name (number or letter)","d2ec6402":"# 3. Data Collection","70bfbf2d":"# 4. Data Preliminary Exploration","a4871f0a":"# 2. Importing Basic Libraries","fdc0a22c":"# 9. Conclusions\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nWe were able to develop a neural netork model with 83% accuracy when identifying pictures of the American Sign Language, what hopefully could be further developed to help on communication for the hearing impaired communities.","f35fbdb4":"# 5. Data Preparation","af3a866b":"# 7. Deep Learning Algorithm Implementation & Assessment","d01ef234":"# 6. Data Modelling","5cd99a96":"# 8. Model Deployment","08f99afb":"# 1. Introduction: Business Goal & Problem Definition\n\nThis projects goal is developing a deep learning model able to identify American Sign photos, so in the future we can automatically identify those signs and help deaf people communicate. I\u00b4m using a Kaggle dataset containing 2515 photos showing all digits from 0 to 9 and all alphabet letters from a to z.\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!"}}