{"cell_type":{"3cf3a081":"code","2eb3929c":"code","e6dee2c8":"code","877a69c8":"code","94897e79":"code","af3edbc0":"code","7d07f0e0":"code","4bbcb88d":"markdown","005d0423":"markdown","9976d470":"markdown","890e64d1":"markdown","a6149398":"markdown","75f90f21":"markdown","f0067d1e":"markdown","8c947ce6":"markdown","0f98f951":"markdown"},"source":{"3cf3a081":"import sys\nsys.path.append('..\/input')\nfrom flight_revenue_simulator import simulate_revenue, score_me\n","2eb3929c":"import numpy as np","e6dee2c8":"def create_valuefunctions(remaining_days,remaining_tickets,min_demand_level,max_demand_level):\n    demand_levels_n = max_demand_level - min_demand_level\n    Q = np.zeros([remaining_days + 1,remaining_tickets + 1,demand_levels_n,remaining_tickets + 1])\n    V = np.zeros([remaining_days + 1,remaining_tickets + 1])\n    return Q,V\n\ndef make_base_step(Q,V,demand_range,remaining_tickets):\n    for tickets_left in range(1,remaining_tickets + 1):\n        for demand_level_i,demand_level  in enumerate(demand_range):\n            for tickets_sold in range(1, tickets_left + 1):\n                price = demand_level - tickets_sold\n                immediate_reward = tickets_sold * price\n                Q[1,tickets_left,demand_level_i,tickets_sold] = immediate_reward\n                \n        V[1,tickets_left] = Q[1,tickets_left,:,:].max(axis = 1).mean()\n    \n\ndef dynamic_programming_algorithm(Q,V,remaining_days,remaining_tickets,demand_range):\n    for days_left in range(2, remaining_days +1):\n        for tickets_left in range(1,remaining_tickets+1):\n            for demand_level_i,demand_level  in enumerate(demand_range):\n                for tickets_sold in range(1, tickets_left + 1):\n                    price = demand_level - tickets_sold\n                    immediate_reward = tickets_sold * price\n                    Q[days_left,tickets_left,demand_level_i,tickets_sold] = immediate_reward + V[days_left-1,tickets_left - tickets_sold]\n                \n                V[days_left,tickets_left] = Q[days_left,tickets_left,:,:].max(axis = 1).mean()\n    \n    return Q,V","877a69c8":"remaining_days = 200\nremaining_tickets = 150\nmin_demand_level = 100\nmax_demand_level = 200\n\ndemand_levels_n = max_demand_level - min_demand_level\ndemand_range = np.linspace(min_demand_level, max_demand_level,demand_levels_n , dtype = int)\n\nQ,V = create_valuefunctions(remaining_days, remaining_tickets, min_demand_level, max_demand_level)\nmake_base_step(Q,V,demand_range,remaining_tickets)\nQ,V = dynamic_programming_algorithm(Q,V,remaining_days,remaining_tickets,demand_range)\n   ","94897e79":"def pricing_function(days_left, tickets_left, demand_level):\n    \"\"\"Sample pricing function\"\"\"\n    demand_level_index = np.abs(demand_level - demand_range).argmin()\n    demand_level_index = demand_level_index\n    relevant_tickest_sold = Q[days_left, int(tickets_left), demand_level_index, :]\n    best_tickets_sold = relevant_tickest_sold.argmax()# armax is equal to formula from step 5\n    price = max(demand_level - best_tickets_sold,0)\n    return price","af3edbc0":"simulate_revenue(days_left=7, tickets_left=50, pricing_function=pricing_function, verbose=True)","7d07f0e0":"score_me(pricing_function)","4bbcb88d":"**Intro**\n\nAfter reading the problem, we can make a conclusion that it is an optimization problem because we need to maximize revenue, thus find the most optimal prices for each day from remaining period and tickets for those days. \nThe common way to solve it is to use the Bellman equation. \nWe can find more info in :\n1. Wiki: https:\/\/en.wikipedia.org\/wiki\/Bellman_equation\n2. From Google search. There are plenty of good links, but I have selected this one as a good one:\nhttps:\/\/medium.com\/datadriveninvestor\/math-of-q-learning-python-code-5dcbdc49b6f6","005d0423":"To see a small example of how your code works, test it with the following function:","9976d470":"You can try simulations for a variety of values.\n\nOnce you feel good about your pricing function, run it with the following cell to to see how it performs on a wider range of flights.","890e64d1":"# Intro\n\nData scientists tend to focus on **prediction** because that's where conventional machine learning excels. But real world decision-making involves both prediction and **optimization**.  After predicting what will happen, you decide what to do about it.\n\nOptimization gets less attention than it deserves. So this micro-challenge will test your optimization skills as you write a function to improve how airlines set prices.\n\n![Imgur](https:\/\/i.imgur.com\/AKrbLMR.jpg)\n\n\n# The Problem\n\nYou recently started Aviato.com, a startup that helps airlines set ticket prices. \n\nAviato's success will depend on a function called `pricing_function`.  This notebook already includes a very simple version of `pricing_function`.  You will modify `pricing_function` to maximize the total revenue collected for all flights in our simulated environment.\n\nFor each flight, `pricing_function` will be run once per (simulated) day to set that day's ticket price. The seats you don't sell today will be available to sell tomorrow, unless the flight leaves that day.\n\nYour `pricing_function` is run for one flight at a time, and it takes following inputs:\n- **Number of days until the flight**\n- **Number of seats they have left to sell**\n- **A variable called `demand_level` that determines how many tickets you can sell at any given price. **\n\nThe quantity you sell at any price is:\n> quantity_sold = demand_level - price\n\nTicket quantities are capped at the number of seats available.\n\nYour function will output the ticket price.\n\nYou learn the `demand_level` for each day at the time you need to make predictions for that day. For all days in the future, you only know `demand_level` will be drawn from the uniform distribution between 100 and 200.  So, for any day in the future, it is equally likely to be each value between 100 and 200.\n\nIn case this is still unclear, some relevant implementation code is shown below.\n\n# The Simulator\nWe will run your pricing function in a simulator to test how well it performs on a range of flight situations.  **Run the following code cell to set up your simulation environment:**","a6149398":"**STEP 1. Analyze mathematical model**\n\nAs a software developer, I combine mathematicians theory with technologies. My main point that software developer should not always deep dive in all math, just have enough understanding when the model is useful (solution space), model's constraints and be able to code it.\nAfter reading the materials and refreshing knowledge it is time to concentrate on the main findings for our model:\n1. Markov Decision Process (MDP) is an extension of the Markov chain and it is used to model complex environments. The model describes the possibility to make a choice at every state which is called an action. We also add a reward which is feedback from the environment for going from one state to another taking one action. \n2. Our optimization problem can be solved by the Bellman equation. We find the optimal solution for this equation using the Dynamic programming technique. Dynamic Programming is a smart brute force, which helps to find the best possible combinations that maximize or minimize something. You can find more info in this video or similar ones. https:\/\/www.youtube.com\/watch?v=Ad0DKl7HUwI","75f90f21":"---\n*This micro-challenge is from an exercise in an upcoming Optimization course on **[Kaggle Learn](https:\/\/www.kaggle.com\/Learn?utm_medium=website&utm_source=kaggle.com&utm_campaign=micro+challenge+2018)**.  If you enjoyed this challenge and want to beef up your data science skills, you might enjoy our other courses.*","f0067d1e":"# Discuss\nWant to discuss your solution or hear what others have done?  There is a [discussion thread](https:\/\/www.kaggle.com\/general\/62469) just for you.","8c947ce6":"In case you want to check your understanding of the simulator logic, here is a simplified version of some of the key logic (leaving out the code that prints your progress). If you feel you understand the description above, you can skip reading this code.\n\n```\ndef _tickets_sold(p, demand_level, max_qty):\n        quantity_demanded = floor(max(0, p - demand_level))\n        return min(quantity_demanded, max_qty)\n\ndef simulate_revenue(days_left, tickets_left, pricing_function, rev_to_date=0, demand_level_min=100, demand_level_max=200):\n    if (days_left == 0) or (tickets_left == 0):\n        return rev_to_date\n    else:\n        demand_level = uniform(demand_level_min, demand_level_max)\n        p = pricing_function(days_left, tickets_left, demand_level)\n        q = _tickets_sold(demand_level, p, tickets_left)\n        return _total_revenue(days_left = days_left-1, \n                              tickets_left = tickets_left-q, \n                              pricing_function = pricing_function, \n                              rev_to_date = rev_to_date + p * q,\n                              demand_level_min = demand_level_min,\n                              demand_level_max = demand_level_max\n                             )\n```\n\n# Your Code\n\nHere is starter code for the pricing function.  If you use this function, you will sell 10 tickets each day (until you run out of tickets).","0f98f951":"**STEP 2. Analyze the Bellman Equition in terms of our problem**\n1. The general Bellman formula from the article. The same on in the Wiki\n![Screen%20Shot%202019-09-19%20at%205.45.38%20PM.png](attachment:Screen%20Shot%202019-09-19%20at%205.45.38%20PM.png)\n\n2. From the fomula. The ![Screen%20Shot%202019-09-20%20at%207.38.47%20AM.png](attachment:Screen%20Shot%202019-09-20%20at%207.38.47%20AM.png)\n\nis a probability of transiting **from state 1 to state 2** taking an action a.\nIn our case there is only demand level is a random variable, but we know that it is a uniformly distributed, so taking this into account we can use **deterministic Bellman Equation**. Which is simpler for us\n![Screen%20Shot%202019-09-19%20at%205.49.52%20PM.png](attachment:Screen%20Shot%202019-09-19%20at%205.49.52%20PM.png)\n\n\nQ is a value funtion. It describes the value of an action taken in some state. It is the expected total reward we can get, starting from that state and taking that action. \n\n3. The first operand in the equation is an immediate reward.at the current state t taking the action t.The reward is the feedback from the environment that tells us how good we are doing. **In our case, the immediate reward is** the revenue for the current day and equals to (tickets that we sold today  *  price).The general formula is \n![Screen%20Shot%202019-09-19%20at%205.52.46%20PM.png](attachment:Screen%20Shot%202019-09-19%20at%205.52.46%20PM.png)\n\n4. The second operand is the state value function. This function is a way to measure the \u201cvalue\u201d, or how good some state is\n![Screen%20Shot%202019-09-19%20at%205.54.57%20PM.png](attachment:Screen%20Shot%202019-09-19%20at%205.54.57%20PM.png)\n\n5. In terms of the optimization problem, mathematicians will write the state function as below. So in order to find the optimal revenue, we have to find the best value for value function, a combination of state and actions. \n![Screen%20Shot%202019-09-19%20at%205.57.08%20PM.png](attachment:Screen%20Shot%202019-09-19%20at%205.57.08%20PM.png)\n\n6. We are going to use dynamic programming to solve this task. The suitable formula for dynamic programming is below. It clearly describes problems and subproblem. Problem - get max revenue today subproblem - get max revenue in the rest of days.\n![Screen%20Shot%202019-09-19%20at%205.58.35%20PM.png](attachment:Screen%20Shot%202019-09-19%20at%205.58.35%20PM.png)\n\n7. The ![Screen%20Shot%202019-09-20%20at%201.40.54%20PM.png](attachment:Screen%20Shot%202019-09-20%20at%201.40.54%20PM.png) is a decreasing factor for future rewards. Setting to 1 means that every reward is equally important. Setting to 0 mean to looking for the immediate reward at the first state. The values between 0 and 1 controls reward important from state to state. In our case, all rewards are equally important. So we set it to 1. \n\n8. In our problem **state (letter \"s\" in the formula) is (days left, tickets left, demand level )**. **Action (letter \"a\" in the formula) is a price that we set for tickets.**\n\n9. More explanation for the code lines:\n\na) Q = np.zeros([remaining_days + 1,remaining_tickets + 1,demand_levels_n,remaining_tickets + 1]). The first 3 parameters describe the state the 4th the action according to Bellman formula. In order to make code clear, I don't make index shiftings to 0, so added 1 in order to save days_left equal to 7.\n4th parameter action. It should be a price, but from the problem statement above we see how to calculate a price:\n\n> quantity_sold = demand_level - price\n>price = demand_level - quantity_sold\n\nSo it will be easier to store the quantity sold as the action and then restore a price for a demand_level.\n\nb) V = np.zeros([remaining_days + 1,remaining_tickets + 1]) - state function. The confusion is that the state should be days_left, tickets_left, and demand_level. However, in the problem description, we don't know the demand level for the next state. So we will store mean value for a demand level.\n\nc) def make_base_step - forward step in DP. We calculate a value for a base problem - find maximum revenue for a problem when we just have only 1 day left.\n\n10. Just code the Bellman equation from step 6."}}