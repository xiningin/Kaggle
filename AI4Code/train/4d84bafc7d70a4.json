{"cell_type":{"9d68e1b7":"code","ea65cec5":"code","32d296e9":"code","99f29184":"code","a43dd69b":"code","df682577":"code","17feaeef":"code","7ef52277":"code","b696db38":"code","f7089270":"code","22979fe7":"code","f611f6aa":"code","c0548926":"code","8f5b755d":"code","4cc232bb":"code","4165167a":"code","b0968e9a":"code","5ca45bdb":"code","ed6966f2":"code","08f140e8":"code","252d81ef":"code","236a02bb":"code","4cb3f09d":"code","45fb2e3c":"markdown","8623075b":"markdown"},"source":{"9d68e1b7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","ea65cec5":"disease_types=['COVID', 'non-COVID']\ndata_dir = '..\/input\/sarscov2-ctscan-dataset'\ntrain_dir = os.path.join(data_dir)","32d296e9":"train_data = []\nfor defects_id, sp in enumerate(disease_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), defects_id, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\ntrain.head()","99f29184":"SEED = 42\ntrain = train.sample(frac=1, random_state=SEED) \ntrain.index = np.arange(len(train)) # Reset indices\ntrain.head()","a43dd69b":"import pandas_profiling as pp\npp.ProfileReport(train)","df682577":"plt.hist(train['DiseaseID'])\nplt.title('Frequency Histogram of Species')\nplt.figure(figsize=(12, 12))\nplt.show()","17feaeef":"def plot_defects(defect_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    defect_files = train['File'][train['Disease Type'] == defect_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, defect_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\nplot_defects('COVID', 3, 3)","7ef52277":"def plot_defects(defect_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    defect_files = train['File'][train['Disease Type'] == defect_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, defect_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\nplot_defects('non-COVID', 3, 3)","b696db38":"IMAGE_SIZE = 64\ndef read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath)) # Loading a color image is the default flag\n# Resize image to target size\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)","f7089270":"X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    image = read_image(file)\n    if image is not None:\n        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n# Normalize the data\nX_Train = X_train \/ 255.\nprint('Train Shape: {}'.format(X_Train.shape))","22979fe7":"Y_train = train['DiseaseID'].values\nY_train = to_categorical(Y_train, num_classes=2)\nprint(Y_train.shape)","f611f6aa":"BATCH_SIZE = 64\n\n# Split the train and validation sets \nX_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.2, random_state=SEED)\n","c0548926":"print(f'X_train:',X_train.shape)\nprint(f'X_val:',X_val.shape)\nprint(f'Y_train:',Y_train.shape)\nprint(f'Y_val:',Y_val.shape)","8f5b755d":"fig, ax = plt.subplots(1, 3, figsize=(15, 15))\nfor i in range(3):\n    ax[i].set_axis_off()\n    ax[i].imshow(X_train[i])\n    ax[i].set_title(disease_types[np.argmax(Y_train[i])])","4cc232bb":"EPOCHS = 50\nSIZE=64\nN_ch=3","4165167a":"def build_resnet50():\n    resnet50 = ResNet50(weights='imagenet', include_top=False)\n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = resnet50(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(2,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","b0968e9a":"model = build_resnet50()\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.70, patience=5, verbose=1, min_lr=1e-4)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\n\ndatagen.fit(X_train)\n","5ca45bdb":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png') ","ed6966f2":"# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=1,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))","08f140e8":"#model = load_model('..\/output\/kaggle\/working\/model.h5')\nfinal_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","252d81ef":"Y_pred = model.predict(X_val)\n\nY_pred = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_val, axis=1)\n\ncm = confusion_matrix(Y_true, Y_pred)\nplt.figure(figsize=(12, 12))\nax = sns.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True, xticklabels=disease_types, yticklabels=disease_types)\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","236a02bb":"# accuracy plot \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","4cb3f09d":"from skimage import io\nfrom keras.preprocessing import image\nimg = image.load_img('..\/input\/sarscov2-ctscan-dataset\/COVID\/Covid (1014).png', grayscale=False, target_size=(64, 64))\nshow_img=image.load_img('..\/input\/sarscov2-ctscan-dataset\/COVID\/Covid (1014).png', grayscale=False, target_size=(200, 200))\ndisease_class=['Covid-19','Non Covid-19']\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\nx \/= 255\n\ncustom = model.predict(x)\nprint(custom[0])\n\nplt.imshow(show_img)\nplt.show()\n\na=custom[0]\nind=np.argmax(a)\n        \nprint('Prediction:',disease_class[ind])","45fb2e3c":"\n<h1 style='background-color:red; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;' > What is ResNet 50 model? <\/h1>\n\nResNet-50 is a convolutional neural network that is 50 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database . The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals,\nResNet is the short name for residual Network.\n\n\n<img src=\"https:\/\/i.ytimg.com\/vi\/mGMpHyiN5lk\/maxresdefault.jpg\" width=\"800px\">\n\n\n\n## Dataset in this link: \n\n[Here](https:\/\/www.kaggle.com\/plameneduardo\/sarscov2-ctscan-dataset)","8623075b":"<h1 style='background-color:red; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;' > Coronavirus Disease 2019 (COVID-19) <\/h1>\n\n\nCoronavirus disease 2019 (COVID-19) is defined as illness caused by a novel coronavirus now called severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2; formerly called 2019-nCoV), which was first identified amid an outbreak of respiratory illness cases in Wuhan City, Hubei Province, China.  It was initially reported to the WHO on December 31, 2019. On January 30, 2020, the WHO declared the COVID-19 outbreak a global health emergency.  On March 11, 2020, the WHO declared COVID-19 a global pandemic, its first such designation since declaring H1N1 influenza a pandemic in 2009.\n\n\n\n\n\n\n   <img src=\"https:\/\/www.pharmaceutical-technology.com\/wp-content\/uploads\/sites\/10\/2020\/04\/Malaysia_559007341-e1599478831476.jpg\" width=\"800px\">\n\n\n\n\n"}}