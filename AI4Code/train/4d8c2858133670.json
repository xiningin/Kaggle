{"cell_type":{"624ea37b":"code","658f9344":"code","a27ded31":"code","52df7a18":"code","a87c432d":"code","15fec7f5":"code","290f4aed":"code","65a09349":"code","21ecf77f":"code","146716e6":"code","4100b790":"code","ed4aa5a8":"code","0acef4c1":"code","dde1eff8":"code","aa4f9bf0":"code","52025dd0":"code","b970deaf":"code","f971eba2":"code","f1468634":"code","9d8232eb":"code","b33100c4":"code","2af518e5":"code","1d19e854":"code","ca95ec86":"code","d6779c9d":"code","1905f66e":"markdown","a5dc999b":"markdown","471316e4":"markdown","a9dcb941":"markdown","5334a08c":"markdown","efca8c82":"markdown","6e79dbdc":"markdown","31caecd5":"markdown","f5439807":"markdown","8bc23237":"markdown","6f027c89":"markdown","608ce5da":"markdown","5898eaab":"markdown","3e020d88":"markdown"},"source":{"624ea37b":"import pandas as pd\nimport numpy as np\nimport keras\nimport tensorflow as tf\nimport keras.layers as L\nimport keras.models as M\nimport keras.initializers as I\nimport keras.backend as K\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt","658f9344":"data=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndata.head()","a27ded31":"X=data.drop('label',axis=1).values\ny2=data['label'].values","52df7a18":"# Makign the squash function\ndef squash(vectors, axis=-1):\n    squared_norm=K.sum(K.square(vectors),axis,keepdims=True)\n    scale=squared_norm\/(1+squared_norm)\/(K.sqrt(squared_norm)+K.epsilon())\n    return scale*vectors\n    ","a87c432d":"img_shape=(28,28,1)\ninp=L.Input(img_shape,100)\n# Adding the first conv1 layer\nconv1=L.Conv2D(filters=256,kernel_size=(2,2),activation='relu',padding='valid')(inp)\n# Adding Maxpooling layer\nmaxpool1=L.MaxPooling2D(pool_size=(1,1))(conv1)\n# Adding second convulational layer\nconv2=L.Conv2D(filters=128,kernel_size=(9,9),activation='relu',padding='valid')(maxpool1)\n# Adding primary cap layer\nconv2=L.Conv2D(filters=8*16,kernel_size=(9,9),strides=2,padding='valid',activation=None)(conv2)\n# Adding the squash activation\nreshape2=L.Reshape([-1,8])(conv2)\nsquashed_output=L.Lambda(squash)(reshape2)","15fec7f5":"# Making capsule layer from scratch\nclass CapsuleLayer(L.Layer):\n    def __init__(self,num_capsule,dim_capsule,routing=3,kernel_initializer='glorot_uniform',**kwargs):\n        super(CapsuleLayer,self).__init__(**kwargs)\n        self.num_capsule=num_capsule\n        self.dim_capsule=dim_capsule\n        self.routing=routing\n        self.kernel_initializer=kernel_initializer\n    def build(self,input_shape):\n        assert len(input_shape) >= 3\n        self.input_num_capsule=input_shape[1]\n        self.input_dim_capsule=input_shape[2]\n        \n        #transforming the matrix\n        self.W= self.add_weight(shape=[self.num_capsule,self.input_num_capsule,self.dim_capsule,self.input_dim_capsule],initializer=self.kernel_initializer,name='w')\n        self.built=True\n    def call(self,inputs,training=None):\n        input_expand=tf.expand_dims(tf.expand_dims(inputs,1),-1)\n        inputs_tiled=K.tile(input_expand,[1,self.num_capsule,1,1,1])\n        input_hat=tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W,x),elems=inputs_tiled))\n        b=tf.zeros(shape=[inputs.shape[0],self.num_capsule,1,self.input_num_capsule])\n        assert self.routing > 0\n        for i in range(self.routing):\n            c=tf.nn.softmax(b,axis=1)\n            output=squash(tf.matmul(c,input_hat))\n            if i<self.routing-1:\n                b+=tf.matmul(output,input_hat,transpose_b=True)\n        return tf.squeeze(output)\n    def compute_output_shape(self,input_shape):\n        return tuple([None,self.num_capsule,self.dim_capsule])\n    def get_config(self):\n        config = {\n            'num_capsule': self.num_capsule,\n            'dim_capsule': self.dim_capsule,\n            'routings': self.routings\n        }\n        base_config = super(CapsuleLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n        ","290f4aed":"digitcaps = CapsuleLayer(num_capsule=10, dim_capsule=16, routing=3, name='digitcaps')(squashed_output)","65a09349":"class Length(L.Layer):\n    def call(self,inputs,**kwargs):\n        return tf.sqrt(tf.reduce_sum(tf.square(inputs),-1))\n    def compute_output_shape(self,input_shape):\n        return input_shape[:-1]\n    def get_config(self):\n        config = super(Length, self).get_config()\n        return config","21ecf77f":"# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n# If using tensorflow, this will not be necessary. :)\nout_caps = Length(name='capsnet')(digitcaps)","146716e6":"# Making the masking layer\nclass Mask(L.Layer):\n    def call(self,inputs,**kwargs):\n        if type(inputs) is list:\n            assert len(inputs)==2\n            inputs,mask=inputs\n        else:\n            x=tf.sqrt(tf.reduce_sum(tf.square(inputs),-1))\n            mask=tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n        masked=K.batch_flatten(inputs*tf.expand_dims(mask,-1))\n        return masked\n    def compute_output_shape(self, input_shape):\n        if type(input_shape[0]) is tuple:  # true label provided\n            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n        else:  # no true label provided\n            return tuple([None, input_shape[1] * input_shape[2]])\n\n    def get_config(self):\n        config = super(Mask, self).get_config()\n        return config","4100b790":"y = L.Input(shape=(10,))\nmasked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\nmasked = Mask()(digitcaps)","ed4aa5a8":"decoder = M.Sequential(name='decoder')\ndecoder.add(L.Dense(512, activation='relu', input_dim=16 * 10))\ndecoder.add(L.Dense(1024, activation='relu'))\ndecoder.add(L.Dense(np.prod((28,28,1)), activation='sigmoid'))\ndecoder.add(L.Reshape(target_shape=(28,28,1), name='out_recon'))","0acef4c1":"train_model = M.Model([inp, y], [out_caps, decoder(masked_by_y)])\neval_model = M.Model(inp, [out_caps, decoder(masked)])","dde1eff8":"def margin_loss(y_true, y_pred):\n    \"\"\"\n    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n    :param y_true: [None, n_classes]\n    :param y_pred: [None, num_capsule]\n    :return: a scalar loss value.\n    \"\"\"\n    # return tf.reduce_mean(tf.square(y_pred))\n    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n\n    return tf.reduce_mean(tf.reduce_sum(L, 1))","aa4f9bf0":"train_model.summary()","52025dd0":"X=np.array(X)\ny2=np.array(y2)\nX_train, X_test, y_train2, y_test2 = train_test_split(X, y2, test_size=0.1, random_state=42)\nx_train = X_train.astype('float32') \/ 255.\nx_train = x_train.reshape(-1,28,28,1)\ny_train = np.array(to_categorical(y_train2.astype('float32')))\n\nx_test = X_test.astype('float32') \/ 255.\nx_test = x_test.reshape(-1,28,28,1)\ny_test = np.array(to_categorical(y_test2.astype('float32')))\n\nx_output = x_train.reshape(-1,784)\nX_valid_output = x_test.reshape(-1,784)\n\nn_samples = 5\n\nplt.figure(figsize=(n_samples * 2, 3))\nfor index in range(n_samples):\n    plt.subplot(1, n_samples, index + 1)\n    sample_image = x_test[index].reshape(28, 28)\n    plt.imshow(sample_image, cmap=\"binary\")\n    plt.title(\"Label:\" + str(y_test2[index]))\n    plt.axis(\"off\")\n\nplt.show()","b970deaf":"m = 100\nepochs = 16\n# Using EarlyStopping, end training when val_accuracy is not improved for 10 consecutive times\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_capsnet_accuracy',mode='max',\n                                    patience=2,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 5 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_capsnet_accuracy',mode='max',factor=0.5,patience=4)\ntrain_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss=[margin_loss,'mse'],loss_weights = [1. ,0.0005],metrics=['accuracy'])\ntrain_model.fit([x_train, y_train],[y_train,x_train], batch_size = m, epochs = epochs, validation_data = ([x_test, y_test],[y_test,x_test]),callbacks=[early_stopping,lr_scheduler])","f971eba2":"label_predicted, image_predicted = train_model.predict([x_test[:4000], y_test[:4000]])\n","f1468634":"n_samples = 5\n\nplt.figure(figsize=(n_samples * 2, 3))\nfor index in range(n_samples):\n    plt.subplot(1, n_samples, index + 1)\n    sample_image = x_test[index].reshape(28, 28)\n    plt.imshow(sample_image, cmap=\"binary\")\n    plt.title(\"Label:\" + str(y_test2[index]))\n    plt.axis(\"off\")\n\nplt.show()\n\nplt.figure(figsize=(n_samples * 2, 3))\nfor index in range(n_samples):\n    plt.subplot(1, n_samples, index + 1)\n    sample_image = image_predicted[index].reshape(28, 28)\n    plt.imshow(sample_image, cmap=\"binary\")\n    plt.title(\"Predicted:\" + str(np.argmax(label_predicted[index])))\n    plt.axis(\"off\")\n\nplt.show()","9d8232eb":"test_file=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest_file.head()","b33100c4":"test_x=test_file.values\ntest_x=np.array(test_x)","2af518e5":"test_x = test_x.astype('float32') \/ 255.\ntest_x = test_x.reshape(-1,28,28,1)","1d19e854":"op=eval_model.predict(test_x)","ca95ec86":"predictions=[]\nfor i in op[0]:\n    predictions.append(np.argmax(i))","d6779c9d":"# Making the submission file\nsubmission=pd.DataFrame()\nsubmission['ImageId']=[i+1 for i in range(len(predictions))]\nsubmission['Label']=predictions\nsubmission.to_csv('Submission.csv',index=False)","1905f66e":"# Making squash function","a5dc999b":"# Training the model","471316e4":"# Making Capsule Layer","a9dcb941":"# Making the loss function","5334a08c":"# Final Training Model","efca8c82":"# Importing libraries","6e79dbdc":"# Making Submission File","31caecd5":"# Making the Masking layer","f5439807":"# Importing the data","8bc23237":"# Adding Input layer,convulational layers and primary capsule","6f027c89":"# Making length layer which will calculate the length of the vectors","608ce5da":"# Thank you","5898eaab":"# Making the decoder model","3e020d88":"# Making models"}}