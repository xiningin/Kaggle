{"cell_type":{"e95f97e0":"code","9c3611bc":"code","3e6ff25a":"code","148ae1a5":"code","f3addfdb":"code","ffe82a92":"code","b66d059c":"code","215ed23a":"code","931a4a02":"code","0abfadcb":"code","f5f1e16e":"code","560ac35c":"code","9a4fe344":"markdown"},"source":{"e95f97e0":"#########################################################\n# Imports\nimport pandas as pd\npd.options.mode.chained_assignment = None\npd.set_option('display.max_columns', 100)\n\nimport numpy as np\nimport random\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib as plt\n%matplotlib inline \n\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"..\/input\"))","9c3611bc":"\n#########################################################\n# Leitura dos dados\ntrain = pd.read_csv('..\/input\/dataset_treino.csv')\ntest = pd.read_csv('..\/input\/dataset_teste.csv')\nstore = pd.read_csv('..\/input\/lojas.csv')\n\n\n#########################################################\n# Dados com lojas abertas\ntrain = train[(train['Open'] == 1) & (train['Sales'] > 0)]\n\n\n#########################################################   \n# Open = 1 para os dados de teste\ntest.fillna(1, inplace=True)\n\n\n#########################################################\n# Merge\ntrain = train.merge(store, on = 'Store', how = 'left')\ntest = test.merge(store, on = 'Store', how = 'left')\n\n#########################################################   \n# StateHoliday\ntrain.loc[train['StateHoliday'] == 0, 'StateHoliday'] = '0'\n\n\n\nle = LabelEncoder()\nlst_promo_inter = list((train['PromoInterval'].append(test['PromoInterval'])).unique())\nfor ds in [train, test]:\n    #########################################################\n    # Coluna data\n    ds['Date'] = pd.to_datetime(ds['Date'], errors='coerce')\n    ds['Year'] = ds.Date.dt.year\n    ds['Month'] = ds.Date.dt.month\n    ds['Day'] = ds.Date.dt.day\n    ds['Week'] = ds.Date.dt.week\n    ds['WeekOfYear'] = ds.Date.dt.week\n    \n    #########################################################\n    # Categoricos\n    ds['StoreType'] = le.fit_transform(ds['StoreType'])\n    ds['Assortment'] = le.fit_transform(ds['Assortment'])\n    ds['StateHoliday'] = le.fit_transform(ds['StateHoliday'])\n    \n    \n    #########################################################\n    # CompetitionMonth\n    ds['CompetitionMonth'] = 12 * (train.Year - train.CompetitionOpenSinceYear) + (train.Month - train.CompetitionOpenSinceMonth)\n    ds['CompetitionMonth'] = ds.CompetitionMonth.apply(lambda x: x if x > 0 else 0)   \n    \n    \n    #########################################################\n    # PromoOpen\n    ds['PromoOpen'] = 12 * (ds.Year - ds.Promo2SinceYear) + (ds.WeekOfYear - ds.Promo2SinceWeek) \/ 4.0        \n    ds['PromoOpen'] = ds.PromoOpen.apply(lambda x: x if x > 0 else 0)\n    \n    \n    #########################################################\n    # PromoInterval\n    ds['PromoInterval'] = [lst_promo_inter.index(x) for x in ds['PromoInterval']]\n    \n    \n    #########################################################\n    # Prencher nulos\n    ds.fillna(-1, inplace=True)","3e6ff25a":"train.head(3)","148ae1a5":"#########################################################\n# RMSPE\ndef rmspe(y, yhat):\n    return np.sqrt(np.mean((yhat\/y-1) ** 2))\n\ndef rmspe_xg(yhat, y):\n    y = np.expm1(y.get_label())\n    yhat = np.expm1(yhat)\n    return \"rmspe\", rmspe(y,yhat)\n\n\n\n#########################################################\n# Features\nfeatures = ['Store',\n            'DayOfWeek', \n            'Promo', \n            'StateHoliday', \n            'SchoolHoliday', \n            'StoreType', \n            'Assortment',\n            'CompetitionDistance', \n            'CompetitionOpenSinceMonth', \n            'CompetitionOpenSinceYear', \n            'Promo2',\n            'Promo2SinceWeek', \n            'Promo2SinceYear', \n            'PromoInterval', \n            'Year',\n            'Month', \n            'Day',\n            #'Week', \n            'WeekOfYear'\n            #'CompetitionMonth',\n            #'PromoOpen'\n           ]\n\n\n#########################################################\n# Modelo\nparam = {\n    'objective': 'reg:linear', \n    \"booster\" : \"gbtree\",\n    'eta': 0.03,\n    'max_depth':10,\n    'subsample':0.9,\n    'colsample_bytree':0.7,\n    'silent' : 1  \n}\n\nX_train, X_test, y_train, y_test = train_test_split(train[features], np.log1p(train['Sales']), \n                                                    test_size = 50000, random_state = 2019)\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndvalid = xgb.DMatrix(X_test, y_test)\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]","f3addfdb":"#########################################################\n# Treinamento\ngbm = xgb.train(\n            param, \n            dtrain, \n            7000,\n            evals=watchlist,\n            early_stopping_rounds=100, \n            feval=rmspe_xg, \n            verbose_eval=100\n)","ffe82a92":"#########################################################\n# Predict treino\nyhat = gbm.predict(xgb.DMatrix(X_test))","b66d059c":"rmspe(np.expm1(y_test), np.expm1(yhat))","215ed23a":"#########################################################\n# Tabela com erro, ratio e ajuste de pesos\nres = pd.DataFrame(data = y_test)\nres['Prediction']=yhat\nres = pd.merge(X_test,res, left_index= True, right_index=True)\nres['Ratio'] = res.Prediction\/res.Sales\nres['Error'] =abs(res.Ratio-1)\nres['Weight'] = res.Sales\/res.Prediction\n\nres.head()","931a4a02":"#########################################################\n# Conceito: os scores de treino e valida\u00e7\u00e3o est\u00e3o bem pr\u00f3ximos, ajustanto os pesos do treino\n# eh provavel que o score da valida\u00e7\u00e3o seja melhor\n\nW=[(0.990+(i\/1000)) for i in range(20)]\nS =[]\nfor w in W:\n    error = rmspe(np.expm1(y_test), np.expm1(yhat*w))\n    #print('RMSPE for {:.3f}:{:.6f}'.format(w,error))\n    S.append(error)\nScore = pd.Series(S,index=W)\n#Score.plot()\nBS = Score[Score.values == Score.values.min()]\nprint ('Melhor ajuste de score:{}'.format(BS))\n","0abfadcb":"#########################################################\n# Score com ajuste\nrmspe(np.expm1(y_test), np.expm1(yhat*0.999))","f5f1e16e":"#########################################################\n# Predi\u00e7\u00e3o final\ntest_probs = gbm.predict(xgb.DMatrix(test[features]))","560ac35c":"#########################################################\n# Peso final ajustado por tentativa e erro no Score p\u00fablico\npeso_final = 0.9965\nsubmission = pd.DataFrame({\"Id\": test[\"Id\"], \"Open\": test[\"Open\"], \"Sales\":  np.expm1(test_probs * peso_final) })\nsubmission.loc[submission['Open'] == 0, 'Sales'] = 0\nsubmission.loc[submission['Sales'] < 0, 'Sales'] = 0\nsubmission = submission[['Id', 'Sales']]\n\n\nsubmission.to_csv(\"sub_final4.csv\", index=False)","9a4fe344":"**Author:** Allyson de Lima Medeiros     \n**Data:** 2019-04-05     \n**Contato:**https:\/\/www.linkedin.com\/in\/allysonlm\/     "}}