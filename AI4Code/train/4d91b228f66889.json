{"cell_type":{"69c1339b":"code","c96a810c":"code","0837c586":"code","cdab6b82":"code","68bdfe73":"code","bad0c7ea":"code","82172334":"code","e6e9dd70":"code","347fb939":"code","891478d0":"code","9ea98b03":"code","e3717c60":"code","1021ce53":"code","18f201b0":"code","d6b134dc":"code","f818a691":"markdown","65fdc6d6":"markdown","7b3a2838":"markdown","42c12141":"markdown","252abef1":"markdown","e3d61d97":"markdown","e58334b5":"markdown","af6ec811":"markdown","653434de":"markdown","5ca8cc9e":"markdown","67fbeaf3":"markdown","7b7040f8":"markdown","f8af4bf5":"markdown"},"source":{"69c1339b":"from pathlib import Path\nimport pandas as pd","c96a810c":"data_dir = Path(\"..\/input\/chaii-hindi-and-tamil-question-answering\/\")\ntrain_df = pd.read_csv(data_dir \/ \"train.csv\", encoding=\"utf8\")\ntest_df = pd.read_csv(data_dir \/ \"test.csv\", encoding=\"utf8\")\n\n\nprint(\"*\"*10)\nprint(\"Number of training samples: \", len(train_df))\nprint(\"Number of TAMIL samples: \", len(train_df[train_df.language=='tamil']))\nprint(\"Number of HINDI samples: \", len(train_df[train_df.language=='hindi']))\nprint(\"*\"*10)\nprint(\"Number of test samples: \", len(test_df))\n","0837c586":"train_df.head(10)","cdab6b82":"from google.cloud import translate_v2 as translate\ndef translate_text(target, text, translate_client):\n    try:\n        result = translate_client.translate(text, target_language=target)\n        translatedText = result[\"translatedText\"]\n        return translatedText\n    except Exception as e:\n        return ''\n    \ncredentials_path = \"..\/input\/google-credentials-key\/translation-322918-001a60851ad9.json\"\ntranslate_client = translate.Client.from_service_account_json(credentials_path)\n\nfor i in range(3):\n    print(\"*\"*10)\n    print(train_df.language[i])\n    print(translate_text(\"en\", train_df.question[i], translate_client))\n    print(translate_text(\"en\", train_df.answer_text[i], translate_client))","68bdfe73":"pd.set_option('display.float_format', lambda x: '%.0f' % x)\n\n#number of chars\ntrain_df['context_chars'] = train_df['context'].str.len()\ntrain_df['question_chars'] = train_df['question'].str.len()\ntrain_df['answer_chars'] = train_df['answer_text'].str.len()\n\n#number of words\ntrain_df['context_words'] = train_df['context'].str.split().map(lambda x: len(x))\ntrain_df['question_words'] = train_df['question'].str.split().map(lambda x: len(x))\ntrain_df['answer_words'] = train_df['answer_text'].str.split().map(lambda x: len(x))\n\ntamil_df = train_df[train_df.language=='tamil']\nhindi_df = train_df[train_df.language=='hindi']\n\ntrain_df.describe()","bad0c7ea":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20, 6))\nsns.kdeplot(train_df['context_words'],shade=True, color='#ff0000', ax=axes[0])\n\n\nsns.kdeplot(tamil_df['context_words'],shade=True, color='#00ff00', ax=axes[1])\nsns.kdeplot(hindi_df['context_words'],shade=True, color='#0000ff', ax=axes[2])\naxes[0].set_title('Context Word Count - Overall',fontdict= { 'fontsize': 12, 'fontweight':'bold'})\naxes[1].set_title('Context Word - Hindi',fontdict= { 'fontsize': 12, 'fontweight':'bold'})\naxes[2].set_title('Context Word - Tamil',fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n","82172334":"train_df.context_words.hist()","e6e9dd70":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20, 6))\nsns.kdeplot(train_df['answer_start'],shade=True, color='#ff0000', ax=axes[0])\n\nsns.kdeplot(tamil_df['answer_start'],shade=True, color='#00ff00', ax=axes[1])\nsns.kdeplot(hindi_df['answer_start'],shade=True, color='#0000ff', ax=axes[2])\naxes[0].set_title('Answer Start Position - Overall',fontdict= { 'fontsize': 12, 'fontweight':'bold'})\naxes[1].set_title('Answer Start Position - Hindi',fontdict= { 'fontsize': 12, 'fontweight':'bold'})\naxes[2].set_title('Answer Start Position - Tamil',fontdict= { 'fontsize': 12, 'fontweight':'bold'})","347fb939":"train_df.answer_start.hist()","891478d0":"display(hindi_df.tail(10))","9ea98b03":"a = 942\nprint(a)\nprint(\"Answer = \", hindi_df.answer_text[a])\nprint(\"Answer Start = \", hindi_df.answer_start[a])\nprint(\"*\"*10)\nprint(\"Context Text = \", hindi_df.context[a])","e3717c60":"display(tamil_df.tail(10))","1021ce53":"a = 5\nprint(a)\nprint(\"Answer = \", tamil_df.answer_text[a])\nprint(\"Answer Start = \", tamil_df.answer_start[a])\nprint(\"*\"*10)\nprint(\"Context Text = \", tamil_df.context[a])","18f201b0":"test_df.head()","d6b134dc":"#number of chars\ntest_df['context_chars'] = test_df['context'].str.len()\ntest_df['question_chars'] = test_df['question'].str.len()\n\n#number of words\ntest_df['context_words'] = test_df['context'].str.split().map(lambda x: len(x))\ntest_df['question_words'] = test_df['question'].str.split().map(lambda x: len(x))\n\ntest_df","f818a691":"# Answer Start Position Distribution","65fdc6d6":"# Hindi and Tamil Question Answering\n\n\nIn this competition, our goal is to predict answers to real questions about Wikipedia articles. \nPredicting answers to questions is a common NLU task, but not for Hindi and Tamil. Popular Natural Language Understanding (NLU) models perform worse with Indian languages compared to English and the intent of this competition is to bridge that gap","7b3a2838":"### ******** Insights from above *******\n1. A majority of answers start very early in the passage. However, we don't know if this is the case in the Test Data. It will be a interesting probe to make on the LB\n\n2. There are some answers that are very long(51 words). The Longest question is only 22 words","42c12141":"# Lets look at the Hindi Samples","252abef1":"# Looking at the test data","e3d61d97":"#### Lets look at one Hindi sample","e58334b5":"# Lets look at the Tamil Samples","af6ec811":"# Lets look at the data","653434de":"# Google Translate API - Lets translate some QA to get a sense\n<h4 style=\"background-color:DodgerBlue;\">THIS CAN BE VERY EXPENSIVE ! Please use with care if you decide to include your Google Credentials<\/h4>\n","5ca8cc9e":"# Wordcount Distribution","67fbeaf3":"# Google Translate API","7b7040f8":"# Thank you !! I will add more info as I do my own EDA over a cup of Chaii !","f8af4bf5":"## Lets understand the LENGTH of the context\/questions\/answers"}}