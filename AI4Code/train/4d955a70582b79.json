{"cell_type":{"e724479f":"code","1948fd60":"code","5bdbc70c":"code","64d612de":"code","2809cc93":"code","bca20871":"code","89df3492":"code","dfdd82bc":"code","c9b37dcc":"code","a961a4da":"code","e8b00f1a":"code","e3e34423":"code","17f6d94b":"code","b8cb9fe2":"code","2fa8c245":"code","e5773d4e":"code","29c3c11f":"markdown"},"source":{"e724479f":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1948fd60":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","5bdbc70c":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","64d612de":"pip install lofo-importance","2809cc93":"from sklearn.model_selection import KFold\nfrom lofo import LOFOImportance, FLOFOImportance, Dataset, plot_importance\n%matplotlib inline","bca20871":"train_data","89df3492":"lr = lgb.LGBMClassifier()\nlr.fit(X_test[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\" ,\"Age\", \"Fare\" , \"Embarked\"]], X_test[\"Survived\"])\n\nfi = FLOFOImportance(lr, X_test, [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\" ,\"Age\", \"Fare\" , \"Embarked\"], 'Survived', scoring=\"neg_mean_absolute_error\")\n\nimportances = fi.get_importance()\nimportances","dfdd82bc":"# define the validation scheme\ncv = KFold(n_splits=4, shuffle=False, random_state=0)\n\n# define the binary target and the features\ndataset = Dataset(df=sample_df, target=\"Survived\", features=[col for col in train_data.columns if col != target])\n\n# define the validation scheme and scorer. The default model is LightGBM\nlofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n\n# get the mean and standard deviation of the importances in pandas format\nimportance_df = lofo_imp.get_importance()\n\n# plot the means and standard deviations of the importances\nplot_importance(importance_df, figsize=(12, 20))","c9b37dcc":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error,r2_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\" ,\"Age\", \"Fare\" , \"Embarked\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = lgb.LGBMClassifier().fit(X, y)","a961a4da":"X","e8b00f1a":"params = {\"num_leaves\": [16,12,8,4],\n            \"learning_rate\": [0.4, 0.1, 0.8, 0.05],\n            \"max_depth\":[10,8,6,4],\n         \"feature_fraction\": [0.1, 0.3, 0.5, 0.8],\n         \"subsample\": [0.2, 0.5, 0.75]}","e3e34423":"from sklearn.model_selection import train_test_split , GridSearchCV\ncv_model = GridSearchCV(model , params, cv=10, verbose=2 , n_jobs=-1).fit(X , y)","17f6d94b":"cv_model.best_params_","b8cb9fe2":"model_tuned = lgb.LGBMClassifier(max_depth= 10, feature_fraction=0.1, learning_rate=0.1,\n                                    num_leaves= 16,\n                                    subsample= 0.2).fit(X , y)","2fa8c245":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfeature_imp = pd.Series(model.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y = feature_imp.index)\nplt.xlabel(\"Features Importance Scores\")\nplt.ylabel(\"Features\")\nplt.title(\"Feature Importances\")\nplt.show()        ","e5773d4e":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","29c3c11f":"## Model Tuning "}}