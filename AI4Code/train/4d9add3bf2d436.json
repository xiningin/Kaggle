{"cell_type":{"5f61d22f":"code","da3c6f5b":"code","058bc53b":"code","fc8c58f3":"code","1733e2c3":"code","3e3e417a":"code","83b0dd26":"code","8cc866b0":"code","a3009dfc":"code","77c724f6":"code","4597b244":"code","049da5ae":"code","48c1554b":"code","dc1345e0":"code","155faf5d":"code","1435a7b7":"code","d5cc0531":"code","6a4b167a":"code","7ccd266c":"code","790368f2":"code","c137aa77":"code","f84f5c2c":"code","f7adef26":"code","9b74b69d":"code","cf81e5df":"code","982b0f4e":"code","c7e5790b":"code","47525c50":"code","db60f02e":"code","e97fba5b":"code","e0653799":"code","410e4be7":"code","3d0597c6":"code","431fd6fd":"code","ce9644a0":"code","6f9b522d":"code","de343f67":"code","831f026b":"code","04a4eb58":"code","cd47d499":"code","4a8c16d4":"code","4bbb9ead":"code","33590245":"code","7f751834":"code","20180d70":"markdown","885889b2":"markdown","5a31252c":"markdown"},"source":{"5f61d22f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","da3c6f5b":"#Carregar os dados\ndf = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\ndf.shape","058bc53b":"#Olhar os dados\ndf.head(3).T","fc8c58f3":"#Visualiza\u00e7\u00e3o dados aleat\u00f3rios\ndf.sample(5).T","1733e2c3":"#Verificar o tipo dos dados e quantidade \ndf.info()","3e3e417a":"# Transformar o campo totalCharges para float\n\ndf['TotalCharges'] = df['TotalCharges'].str.replace(' ','0').astype(float)","83b0dd26":"#Vamos identificar os espa\u00e7os em branco\n#df[df['TotalCharges'].str.contains(' ')]","8cc866b0":"# Pra corrigir a coluna TotalCharges vamos trocar espa\u00e7o em branco por -1 e for\u00e7ar novamente a convers\u00e3o. \n#df['TotalCharges'] = df['TotalCharges'].str.replace(' ', '-1').astype(float)\n# df['TotalCharges'] = df['TotalCharges'].str.strip().replace('', '-1').astype(float)","a3009dfc":"# Criando variaveis dummy para a coluna gender\n\npd.get_dummies(df['gender']).iloc[:, 1:]","77c724f6":"#criando variaveis dummies da PaymentMethod \npd.get_dummies(df['PaymentMethod']).iloc[:, 1:]","4597b244":"#Guardar o dataframe original\ndf2 = df.copy()","049da5ae":"# Criando dummy para todas as colunas\n\ndf = pd.get_dummies(df, columns=['gender','Partner','Dependents','PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n                                'OnlineBackup','DeviceProtection', 'TechSupport', 'StreamingTV','StreamingMovies', 'Contract','PaperlessBilling',\n                                'PaymentMethod'])","48c1554b":"df.head().T","dc1345e0":"# Definindo as features \nfeats = [c for c in df.columns if c not in ['customerID','Churn']]","155faf5d":"# Separar o dataframe em treino, valida\u00e7\u00e3o e teste\n\n#Importando o train_test_split\nfrom sklearn.model_selection import train_test_split\n\n#Primeiro treino e teste\ntrain, test = train_test_split(df, test_size=0.20, random_state=42)\n\n#Treino e valida\u00e7\u00e3o\n\ntrain, valid = train_test_split(train, test_size=0.20, random_state=42)\n\ntrain.shape, valid.shape, test.shape\n","1435a7b7":"# Treinando o modelo\n#Importando o RandomForest \n\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Importando o modelo\nrf = RandomForestClassifier(n_estimators=200, random_state=42)","d5cc0531":"# Treinando o modelo\n\nrf.fit(train[feats], train['Churn'])","6a4b167a":"#Analisando o desempenho do modelo\n\n#Importando metricas\n\nfrom sklearn.metrics import accuracy_score","7ccd266c":"#Avaliando os dados de validacao\n\npreds_val = rf.predict(valid[feats])\n\naccuracy_score(valid['Churn'], preds_val)","790368f2":"#Avaliando os dados de teste\n\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['Churn'], preds_test)","c137aa77":"# Olhar o dataFrame  completo\ndf['Churn'].value_counts(normalize=True)","f84f5c2c":"#Continuando a aula\n# Usando a nova base(copia de df)\n\n\ndf2.info()","f7adef26":"#Exemplo de \n#Tipo category do pandas\n#.cat para acessar as categorias solicitadas de gender\n\n\ndf2['gender'].astype('category').cat.categories","9b74b69d":"# acessando os mapeamentos das categorias\ndf2['gender'].astype('category').cat.codes","cf81e5df":"#mais um caso\n\ndf2['PaymentMethod'].astype('category').cat.categories","982b0f4e":"#convertendo as colunas categoricas para numericas\n\nfor col in df2.columns:\n    if df2[col].dtypes == 'object':\n        df2[col] = df2[col].astype('category').cat.codes","c7e5790b":"# Separar a base em 3 train2, valid2, test2 \n\ntrain2, test2 = train_test_split(df2, test_size=0.2, random_state=42)\n\n#treino e valida\u00e7\u00e3o\ntrain2, valid2 = train_test_split(df2, test_size=0.2, random_state=42)\n\ntrain2.shape, valid2.shape, test2.shape","47525c50":"#\n\nfeats2 = [c for c in df2.columns if c not in['customerID', 'Churn']]","db60f02e":"rf2 = RandomForestClassifier(n_estimators=200, random_state=42)\n\n#treino\nrf2.fit(train2[feats2], train2['Churn'])","e97fba5b":"#Obter as previs\u00f5es da base de valida\u00e7\u00e3o\npreds2 = rf2.predict(valid2[feats2])\n\n#Verificar a acur\u00e1cia\naccuracy_score(valid2['Churn'], preds2)","e0653799":"# obter as previs\u00f5es dos dados de teste\npreds_test2 = rf2.predict(test2[feats2])\n\n#Verificar a acur\u00e1cia\naccuracy_score(test2['Churn'], preds_test2)","410e4be7":"#Avaliar a importancia de cada coluna ( variavel)\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(20, 10))\n\n#Primeiro modelo criado\n\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","3d0597c6":"# Segundo modelo criado\n\npd.Series(rf2.feature_importances_, index=feats2).sort_values().plot.barh()","431fd6fd":"# matriz de confus\u00e3o\n\n#importar biblioteca de matriz de confus\u00e3o\n\nimport scikitplot as skplt ","ce9644a0":"# Dados de valida\u00e7\u00e3o\n#comparar onde acertou ou n\u00e3o. Falsos positivos e falsos negativos\n\nskplt.metrics.plot_confusion_matrix(valid['Churn'], preds_val)","6f9b522d":"#Dados de teste | Matriz de confus\u00e3o\nskplt.metrics.plot_confusion_matrix(test['Churn'], preds_test)","de343f67":"#Testar o limitador de tamanho da \u00e1rvore\nrft = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=9)\nrft.fit(train[feats], train['Churn'])\npred_teste = rft.predict(valid[feats])\naccuracy_score(valid['Churn'], pred_teste)","831f026b":"#Testando aumentar o n\u00famero de estimadores\nrft = RandomForestClassifier(n_estimators=300, random_state=42)\nrft.fit(train[feats], train['Churn'])\npred_teste = rft.predict(valid[feats])\naccuracy_score(valid['Churn'], pred_teste)","04a4eb58":"#Testando limitar o n\u00famero de registros num n\u00f3 para  splitar\nrft = RandomForestClassifier(n_estimators=200, random_state=42, min_samples_split= 1000)\nrft.fit(train[feats], train['Churn'])\npred_teste = rft.predict(valid[feats])\naccuracy_score(valid['Churn'], pred_teste)\n","cd47d499":"#Separando os datasets novamente, dessa vez levando em considera\u00e7\u00e3o o desbalanceio, ou seja, estratificando os datasets de teste e valida\u00e7\u00e3o pela vari\u00e1vel alvo\n\ntrain, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Churn'])\n\ntrain, valid = train_test_split(train, test_size=0.2, random_state=42)\n\ntrain.shape, valid.shape, test.shape","4a8c16d4":"#Testando da maneira b\u00e1sica para compara\u00e7\u00e3o. Lembrando que a acur\u00e1cia foi de 0.7888198757763976 para o de valida\u00e7\u00e3o e 0.794889992902768 para teste\nrft = RandomForestClassifier(n_estimators=200, random_state=42)\nrft.fit(train[feats], train['Churn'])\npred_teste = rft.predict(valid[feats])\nprint(accuracy_score(valid['Churn'], pred_teste))\n\npred_teste_test = rft.predict(test[feats])\nprint(accuracy_score(test['Churn'], pred_teste_test))","4bbb9ead":"#Agora com op\u00e7\u00f5es\nrft= RandomForestClassifier(n_estimators=200, random_state=42, max_depth=9, min_samples_split= 10)\nrft.fit(train[feats], train['Churn'])\n\npred_teste = rft.predict(valid[feats])\nprint(accuracy_score(valid['Churn'], pred_teste))\n\npred_teste_test = rft.predict(test[feats])\nprint(accuracy_score(test['Churn'], pred_teste_test))","33590245":"df['Churn'].value_counts()\n","7f751834":"#Testando colocar pesos nas possibilidades de Churn para atacar o desbalanceio\nclass_weight = dict({'No':1, 'Yes':1.1})\nrdf = RandomForestClassifier(bootstrap=True,\n            class_weight=class_weight, \n            criterion='gini',\n            max_depth=8, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=4, min_samples_split=10,\n            min_weight_fraction_leaf=0.0, n_estimators=300,\n            oob_score=False,\n            random_state=42,\n            verbose=0, warm_start=False)\n\nrdf.fit(train[feats], train['Churn'])\n\npred_teste = rdf.predict(valid[feats])\nprint(accuracy_score(valid['Churn'], pred_teste))\n\npred_teste_test = rdf.predict(test[feats])\nprint(accuracy_score(test['Churn'], pred_teste_test))","20180d70":"* #  **Trabalho de F\u00e9rias!**","885889b2":"#####################################################################################################################","5a31252c":"# RandomForestClassifier\n\u00c8 um meta-estimador que se encaixa em v\u00e1rios classificadores de \u00e1rvore de decis\u00e3o em v\u00e1rias subamostras do conjunto de dados e usa a m\u00e9dia para melhorar a precis\u00e3o preditiva e controlar o ajuste excessivo."}}