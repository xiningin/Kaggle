{"cell_type":{"c297b72d":"code","b424ff88":"code","cd5d4645":"code","173259ea":"code","d0974814":"code","8e149c05":"code","191d7bd7":"code","9b64a906":"code","37431233":"code","665900fc":"code","43156f18":"code","efcbb838":"code","f59012b3":"code","c37b3dee":"code","1f95cc95":"code","d1dc101f":"code","1bf599df":"code","4890851b":"code","b267354f":"code","81017a67":"code","92e9782f":"code","5e3e428e":"code","fa8987a8":"code","38c150f1":"code","e8ff615b":"code","22d0fcc9":"code","7ac365aa":"code","aa6ef89c":"code","ccc9a907":"code","ec8e84a3":"code","92f9a867":"code","2621e6d3":"code","86de25d3":"code","49adee83":"markdown","b52eddbd":"markdown","a2b8c5e7":"markdown","4dc2fd6e":"markdown","9590941e":"markdown","eb6d7045":"markdown","0c9cb4b3":"markdown","e788a6a7":"markdown"},"source":{"c297b72d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b424ff88":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsample = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","cd5d4645":"train","173259ea":"train['PoolQC'].value_counts()","d0974814":"train.isna().sum()","8e149c05":"train.isnull().sum()","191d7bd7":"train.columns","9b64a906":"train.info()","37431233":"train=train.select_dtypes(include=[np.number])\ntest=test.select_dtypes(include=[np.number])","665900fc":"mean_train = np.mean(train)","43156f18":"mean_test = np.mean(test)","efcbb838":"train = train.fillna(mean_train)\ntest = test.fillna(mean_test)","f59012b3":"train.isna().sum()","c37b3dee":"sample.columns","1f95cc95":"Y = train['SalePrice']\nX = train.drop('SalePrice', axis = 1)","d1dc101f":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)","1bf599df":"X_train.head()","4890851b":"from sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression, Ridge,RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV","b267354f":"regressor = LinearRegression() \nregressor.fit(X_train, y_train)","81017a67":"y_pred = regressor.predict(X_test)\n","92e9782f":"plt.scatter(y_test, y_pred) \nplt.title('Ygt vs Yh') \nplt.xlabel('Y ground truth') \nplt.ylabel('Y hat') \nplt.show()","5e3e428e":"print(\"The mean squarred error: \",np.sqrt(mean_squared_error(y_test, y_pred)))","fa8987a8":"from sklearn.linear_model import SGDRegressor\nsgd = SGDRegressor()\nsgd.fit(X_train, y_train)\ny_sgd = sgd.predict(X_test)","38c150f1":"plt.scatter(y_test, y_sgd)\nplt.title('Ygt vs Yh') \nplt.xlabel('Y ground truth') \nplt.ylabel('Y hat')\nplt.show()","e8ff615b":"from keras import models\nfrom keras import layers","22d0fcc9":"model = models.Sequential()\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(1))\n\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n\nmodel.fit(X_train, y_train, batch_size=32, epochs=200)","7ac365aa":"y_200 = model.predict(X_test)","aa6ef89c":"plt.scatter(y_test, y_200)\nplt.title('Ygt vs Yh') \nplt.xlabel('Y ground truth') \nplt.ylabel('Y hat')\nplt.show()","ccc9a907":"model1 = models.Sequential()\nmodel1.add(layers.Dense(128, activation='relu'))\nmodel1.add(layers.Dense(64, activation='relu'))\nmodel1.add(layers.Dense(64, activation='relu'))\nmodel1.add(layers.Dense(1))\n\nmodel1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n\nmodel1.fit(X_train, y_train, batch_size=16, epochs=300)","ec8e84a3":"y_300 = model.predict(X_test)","92f9a867":"plt.scatter(y_test, y_300)\nplt.title('Ygt vs Yh') \nplt.xlabel('Y ground truth') \nplt.ylabel('Y hat')\nplt.show()","2621e6d3":"from sklearn.svm import SVR\n\nsvm = SVR(kernel='rbf', C=1000000, epsilon=0.001)\nsvm.fit(X_train, y_train)\n\ny_svm = svm.predict(X_test)","86de25d3":"plt.scatter(y_test, y_svm)\nplt.title('Ygt vs Yh') \nplt.xlabel('Y ground truth') \nplt.ylabel('Y hat')\nplt.show()","49adee83":"# Data is finally cleaned","b52eddbd":"## batch size 32 and 200 Epochs","a2b8c5e7":"## batch size 16 and 300 Epochs","4dc2fd6e":"### For the test.csv, there is no values for Y to test for so the training set was divided with ratio 80% to 20% for training and testing respectivilly","9590941e":"# SGDRegressor","eb6d7045":"# Support Vector Machine","0c9cb4b3":"# Data exploration and cleaning","e788a6a7":"# Linear Regression"}}