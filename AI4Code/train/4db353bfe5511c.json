{"cell_type":{"3ef6d3de":"code","1c26d628":"code","3f032688":"code","2824c2f2":"code","c704f630":"code","37e8c037":"code","9544ff96":"code","095e0545":"code","56b884db":"code","e5550c4f":"code","ea016e05":"code","d068f0fa":"code","3e599461":"code","ba56e8bd":"code","c2b7b21e":"code","5e671be3":"code","5a0da33d":"code","135f5525":"code","65c702bb":"code","164ee611":"code","0b3d3e42":"code","5adc1dd5":"code","a8eb8939":"code","d5c312e9":"code","705160a8":"code","612cba68":"code","4e114d24":"code","5cbab311":"code","233d292a":"code","3f4eb00b":"code","a6a2e0ca":"code","e80d5158":"code","eb4a0219":"code","9d271744":"code","046dc55c":"code","99343660":"code","d8a76650":"code","a6c52a9f":"code","31fca782":"code","ea42a2c4":"code","639cbac5":"code","8df5345b":"code","493433a0":"code","1b81828a":"code","4274c6b3":"code","3eb73915":"code","e793ff36":"code","4012b209":"code","a8ab81fa":"code","601edfa7":"code","48851ddf":"code","53893200":"code","abdaaf0e":"code","a7c8777b":"code","732bc321":"code","e140604d":"code","48ac3e26":"code","42ec5177":"code","e9c75b5f":"code","da1de776":"code","6d97f20c":"code","eed1bf76":"code","3eafceee":"code","4df2f7b5":"code","91e447f7":"code","72410535":"code","4b2c89e1":"code","b47fe995":"code","b1f00452":"code","2470da45":"code","e35e042c":"code","e97c5f75":"code","26318f64":"code","c2fb9d08":"code","b014eed4":"code","0195f989":"code","72a137fe":"code","f5587ee5":"code","3af1b56d":"code","9ec280c3":"code","d2edd978":"code","96317de7":"code","a7ed4659":"code","08f75648":"code","ce8908b4":"code","adb20144":"code","37efb830":"code","a5375cac":"code","d57a1c04":"code","f6b13d67":"code","91eb362b":"code","5f6c4a79":"code","ef000b71":"code","601a3911":"code","a3af1f61":"code","4ef9899c":"code","1022d6b6":"code","40939cae":"code","5989c01d":"code","a72826a4":"code","4b74cee9":"code","204bbd73":"code","e7bf6318":"code","82d6cf17":"code","c769e045":"code","3d837836":"code","63646bf1":"code","f6d2eaae":"code","4cd4991c":"code","47e71e0d":"code","8150cccf":"code","5dc86328":"code","d4544948":"code","980a1ce0":"code","9e4eb244":"code","5538bf3f":"code","65efa3b3":"code","ec806b31":"code","c92f6bb7":"code","58c183ef":"code","a6706324":"code","3afa4d4d":"code","bd8ee8f3":"code","7d99d142":"code","78ba65d7":"markdown","6c81f52b":"markdown","88637a24":"markdown","18c34670":"markdown","de3e6b5b":"markdown","93141f72":"markdown","351a2593":"markdown","2e4283b9":"markdown","27afc3db":"markdown","47ded7d1":"markdown","40fba9e2":"markdown","7ebd8a5b":"markdown","5ee54dec":"markdown","d98c1729":"markdown","4a8a7b69":"markdown","218c1706":"markdown","7d67942b":"markdown","5be18974":"markdown","d4337870":"markdown","dadd7b13":"markdown","eb5689f3":"markdown","8f3418bb":"markdown","d95f842d":"markdown","525dc52f":"markdown","54dad46d":"markdown","1c544a90":"markdown","c8a93fe7":"markdown","d206e24f":"markdown","743b4442":"markdown","d41d5a87":"markdown","bd6a9d91":"markdown","17c71c5b":"markdown","d660229e":"markdown","709cca4e":"markdown","01d8766e":"markdown","e7e91183":"markdown","085ef88e":"markdown","816a24e0":"markdown","5f254002":"markdown","6d4bdbc4":"markdown","05e1217b":"markdown","54b21864":"markdown","8e9eb45e":"markdown","dd116e94":"markdown","a8b76c0a":"markdown","dc1e17fd":"markdown","f132fa0b":"markdown","28465f15":"markdown","cdc22c2e":"markdown","ae95b408":"markdown","8162c2fb":"markdown","abc2fe0d":"markdown","0d2f4870":"markdown","c241eb24":"markdown","fb83faad":"markdown","fa0791f5":"markdown","a2b9fb12":"markdown","ce632b2f":"markdown","2056794e":"markdown","8bcd73e1":"markdown","72f07c5a":"markdown","773af02c":"markdown","f96447b6":"markdown","ec3267f6":"markdown","0bd55f12":"markdown","b22b1fd9":"markdown","d0365bbc":"markdown","a4a3d894":"markdown","078709e5":"markdown","b50c3afd":"markdown","fc0e7536":"markdown","f9deb29e":"markdown","833df296":"markdown","4a6ffa7e":"markdown","83697093":"markdown","3c836caa":"markdown","f1017940":"markdown","6e10b6f6":"markdown","5243f3ab":"markdown","2afddef5":"markdown","495d0667":"markdown","11f1279a":"markdown","14dc30dd":"markdown","c89749a1":"markdown","eae08664":"markdown","394787ff":"markdown","d931b865":"markdown","63270526":"markdown","0f19007c":"markdown","c384095f":"markdown","79655006":"markdown","faebd748":"markdown","70f92213":"markdown","8d678e1f":"markdown","0bf0edfa":"markdown","1769d1c6":"markdown","deb5f659":"markdown"},"source":{"3ef6d3de":"# import libaries\nimport numpy as np\nimport pandas as pd\nimport nltk, pprint\nimport matplotlib.pyplot as plt\nimport random\n\nimport gzip, os, pickle # gzip for reading the gz files, pickle to save\/dump trained model \nimport _pickle as cPickle\n\nimport sklearn\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# supress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n","1c26d628":"# read the first part of the dataset\n# each part (.gz file) contains train, validation and test sets, plus a dict\n\nfilename = '..\/input\/atis-data\/atis.fold0.pkl'\nf = open(filename, 'rb')\ntry:\n    train_set, valid_set, test_set, dicts = pickle.load(f, encoding='latin1')\nexcept:\n    train_set, valid_set, test_set, dicts = pickle.load(f)\nfinally:\n    f.close()\n","3f032688":"# type and size of the train set\nprint(type(train_set))\nprint()\n\n# types of the three elements in the tuple\nprint(type(train_set[0]), type(train_set[1]), type(train_set[2]))\nprint(len(train_set[0]), len(train_set[1]), len(train_set[2]))","2824c2f2":"# validation set\nprint(type(valid_set[0]), type(valid_set[1]), type(valid_set[2]))\nprint(len(valid_set[0]), len(valid_set[1]), len(valid_set[2]))\nprint()\n\n# test set\nprint(type(test_set[0]), type(test_set[1]), type(test_set[2]))\nprint(len(test_set[0]), len(test_set[1]), len(test_set[2]))","c704f630":"# first few elements in each list of the training set \npprint.pprint(train_set[0][:3])\nprint('#'*50)\npprint.pprint(train_set[1][:3])\nprint('#'*50)\npprint.pprint(train_set[2][:3])","37e8c037":"# storing the three elements of the tuple in three objects \n# The '_' is a conventional variable in python used to store non-useful\/dummy objects\ntrain_x, _, train_label = train_set\nval_x, _, val_label = valid_set\ntest_x, _, test_label = test_set","9544ff96":"# each list in the tuple is a numpy array (which us a complete sentence\/query)\n# printing first list in the tuple's first element\n# each element represents a word of the query\n# this translates to 'what flights leave atlanta ....'\ntrain_x[0]","095e0545":"# labels are stored in the third list train_label\ntrain_label[0]","56b884db":"# dicts to map numbers to words\/labels\nprint(type(dicts))\nprint(dicts.keys())","e5550c4f":"# each key:value pair is itself a dict\nprint(type(dicts['labels2idx']))\nprint(type(dicts['tables2idx']))\nprint(type(dicts['words2idx']))\n","ea016e05":"# storing labels and words in separate variables\n# we'll need only two of these dicts - words and labels\nwords = dicts['words2idx']\nlabels = dicts['labels2idx']\ntables = dicts['tables2idx']","d068f0fa":"# each key of 'words' is a word, each value its index\n# printing some random key:value pairs of 'words'\nrandom.sample(words.items(), 10)","3e599461":"# now, we can map the numeric values v in a sentence with the k,v in the dict\n# train_x contains the list of training queries; train_x[0] is the first query\n# this is the first query\n[k for val in train_x[0] for k,v in words.items() if v==val]","ba56e8bd":"# let's look at the first few queries\nsents = []\nfor i in range(30):\n    sents.append(' '.join([k for val in train_x[i] for k,v in words.items() if v==val]))\n\nsents","c2b7b21e":"# labels dict contains IOB (inside-out-beginning) labelled entities\n# printing some randomg k:v pairs \nrandom.sample(labels.items(), 25)","5e671be3":"# number of labels\nprint(len(labels.keys()))","5a0da33d":"# converting words_to_id to id_to_words\n# and labels_to_id to id_to_labels\nid_to_words = {words[k]:k for k in words}\nid_to_labels = {labels[k]:k for k in labels}","135f5525":"# takes in an integer index corresponding to a query \n# and returns a list of (word, label) pairs   \ndef print_query(index):\n    w = [id_to_words[id] for id in train_x[index]]\n    l = [id_to_labels[id] for id in train_label[index]]\n    return list(zip(w, l))","65c702bb":"# sample query\nprint_query(3900)","164ee611":"# example query: stopover city\nprint_query(3443)","0b3d3e42":"# run multiple times to see samples\n# randomly chosen sample IOB tagged queries from training data\ni=random.randrange(len(train_x))\nprint_query(i)","5adc1dd5":"# POS tagging sentences\n# takes in a list of sentences and returns a list of POS-tagged sentences\n# in the form (word, tag)\n\ndef pos_tag(sent_list):\n    pos_tags = []    \n    for sent in sent_list:\n        tagged_words = nltk.pos_tag([id_to_words[val] for val in sent])\n        pos_tags.append(tagged_words)\n    return pos_tags","a8eb8939":"# pos tagging train, validation and test sets\ntrain_pos = pos_tag(train_x)\nvalid_pos = pos_tag(val_x)\ntest_pos = pos_tag(test_x)","d5c312e9":"# looking at tags of some randomly chosen queries\n# notice that most cities after 'TO' are incorrectly tagged as VB\ni = random.randrange(len(train_pos))\ntrain_pos[i]","705160a8":"# function to create (word, pos_tag, iob_label) tuples for a given dataset\ndef create_word_pos_label(pos_tagged_data, labels):\n    iob_labels = []         # initialize the list of 3-tuples to be returned\n    \n    for sent in list(zip(pos_tagged_data, labels)):\n        pos = sent[0]       \n        labels = sent[1]    \n        zipped_list = list(zip(pos, labels)) # [(word, pos), label]\n        \n        # create (word, pos, label) tuples from zipped list\n        tuple_3 = [(word_pos_tuple[0], word_pos_tuple[1], id_to_labels[label]) \n                   for word_pos_tuple, label in zipped_list]\n        iob_labels.append(tuple_3)\n    return iob_labels","612cba68":"# printing some sample queries in the form (word, pos, label)\ntrain_labels = create_word_pos_label(train_pos, train_label)\ntrain_labels[4:6]","4e114d24":"# storing validation and test data as well as (word, pos, label)\nvalid_labels = create_word_pos_label(valid_pos, val_label)\ntest_labels = create_word_pos_label(test_pos, test_label)","5cbab311":"from nltk.corpus import conll2000\nfrom nltk import conlltags2tree, tree2conlltags\n\n# print a sample tree in tuple format\ntrain_labels[3]","233d292a":"# converting the sample sentence above to tree format\ntree = conlltags2tree(train_labels[3])\nprint(tree)","3f4eb00b":"# converting training, validation and test datasets to tree format\ntrain_trees = [conlltags2tree(sent) for sent in train_labels]\nvalid_trees = [conlltags2tree(sent) for sent in valid_labels]\ntest_trees = [conlltags2tree(sent) for sent in test_labels]","a6a2e0ca":"# print some sample training trees\ni=random.randrange(len(train_trees))\nprint(train_trees[i])","e80d5158":"# sample chunks \nprint(train_trees[3468])","eb4a0219":"# chunking example sentence\nsentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n            (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]","9d271744":"# define chunk grammar to identify noun phrase chunks\n# an optional determiner (DT), followed by any number of adjectives (JJ) \n# and then a noun (NN)\ngrammar = \"NP_chunk: {<DT>?<JJ>*<NN>}\"","046dc55c":"# parse the sentence\ncp = nltk.RegexpParser(grammar)\nresult = cp.parse(sentence)\nprint(result)","99343660":"# list form of the tree\ntree2conlltags(result)","d8a76650":"# baseline (dummy chunker)\n# assigns 'O' to each word\n\ngrammar = ''\n\n# initialise cp \ncp = nltk.RegexpParser(grammar)\n\n# evaluate results against actual IOB labels\nresult = cp.evaluate(train_trees)\nprint(result)","a6c52a9f":"# sample queries \nprint(train_trees[random.randrange(len(train_trees))])","31fca782":"# grammar for source and destination city chunks\ngrammar = '''\nfromloc.city_name: {<JJ>?<NN>}\ntoloc.city_name: {<VB><NN>?}\n'''\ncp = nltk.RegexpParser(grammar)\nresult = cp.evaluate(train_trees)\nprint(result)","ea42a2c4":"# unigram chunker\n\nfrom nltk import ChunkParserI\n\nclass UnigramChunker(ChunkParserI):    \n    def __init__(self, train_sents):\n        # convert train sents from tree format to tags\n        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] \n                      for sent in train_sents]\n        self.tagger = nltk.UnigramTagger(train_data)\n        \n    def parse(self, sentence):\n        pos_tags = [pos for (word, pos) in sentence]\n        tagged_pos_tags = self.tagger.tag(pos_tags)\n        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n        \n        # convert to tree again\n        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag) in zip(sentence, chunktags)]\n        return nltk.chunk.conlltags2tree(conlltags)\n        ","639cbac5":"# unigram chunker \nunigram_chunker = UnigramChunker(train_trees)\nprint(unigram_chunker.evaluate(valid_trees))","8df5345b":"# printing the most likely IOB tags for each POS tag\n\n# extract the list of pos tags\npostags = sorted(set([pos for sent in train_trees for (word, pos) in sent.leaves()]))\n\n# for each tag, assign the most likely IOB label\nprint(unigram_chunker.tagger.tag(postags))","493433a0":"# bigram tagger\n\nclass BigramChunker(ChunkParserI):    \n    def __init__(self, train_sents):\n        # convert train sents from tree format to tags\n        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] \n                      for sent in train_sents]\n        self.tagger = nltk.BigramTagger(train_data)\n        \n    def parse(self, sentence):\n        pos_tags = [pos for (word, pos) in sentence]\n        tagged_pos_tags = self.tagger.tag(pos_tags)\n        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n        \n        # convert to tree again\n        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag) in zip(sentence, chunktags)]\n        return nltk.chunk.conlltags2tree(conlltags)\n        ","1b81828a":"# unigram chunker \nbigram_chunker = BigramChunker(train_trees)\nprint(bigram_chunker.evaluate(valid_trees))","4274c6b3":"# reading a file containing list of US cities, states and counties\nus_cities = pd.read_csv(\"..\/input\/uscitystates\/us_cities_states_counties.txt\", sep=\"|\")\nus_cities.head()\n","3eb73915":"# storing cities, states and counties as sets\ncities = set(us_cities['City'].str.lower())\nstates = set(us_cities['State full'].str.lower())\ncounties = set(us_cities['County'].str.lower())","e793ff36":"print(len(cities))\nprint(len(states))\nprint(len(counties))","4012b209":"# define a function to look up a given word in cities, states, county\ndef gazetteer_lookup(word):\n    return (word in cities, word in states, word in counties)","a8ab81fa":"# sample lookups\nprint(gazetteer_lookup('washington'))\nprint(gazetteer_lookup('utah'))\nprint(gazetteer_lookup('philadelphia'))\n","601edfa7":"# extracts features for the word at index i in a sentence \ndef npchunk_features(sentence, i, history):\n    word, pos = sentence[i]\n    \n    # the first word has both previous word and previous tag undefined\n    if i == 0:\n        prevword, prevpos = \"<START>\", \"<START>\"\n    else:\n        prevword, prevpos = sentence[i-1]\n\n    # gazetteer lookup features (see section below)\n    gazetteer = gazetteer_lookup(word)\n\n    return {\"pos\": pos, \"prevpos\": prevpos, 'word':word,\n           'word_is_city': gazetteer[0],\n           'word_is_state': gazetteer[1],\n           'word_is_county': gazetteer[2]}","48851ddf":"# example sentence\nsent_pos = train_pos[0]\nsent_pos","53893200":"# features for sentence sent_pos\n# each word's features are stored in a dict\nfor i in range(len(sent_pos)):\n    print(npchunk_features(sent_pos, i, history=[]))\n    print(' ')","abdaaf0e":"class ConsecutiveNPChunkTagger(nltk.TaggerI): \n\n    def __init__(self, train_sents):\n        train_set = []\n        for tagged_sent in train_sents:\n            untagged_sent = nltk.tag.untag(tagged_sent)\n            history = []\n            # compute features for each word\n            for i, (word, tag) in enumerate(tagged_sent):\n                featureset = npchunk_features(untagged_sent, i, history) \n                train_set.append( (featureset, tag) )\n                history.append(tag)\n        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n\n    def tag(self, sentence):\n        history = []\n        for i, word in enumerate(sentence):\n            featureset = npchunk_features(sentence, i, history)\n            tag = self.classifier.classify(featureset)\n            history.append(tag)\n        return zip(sentence, history)\n\nclass ConsecutiveNPChunker(nltk.ChunkParserI): \n    def __init__(self, train_sents):\n        tagged_sents = [[((w,t),c) for (w,t,c) in\n                         nltk.chunk.tree2conlltags(sent)]\n                        for sent in train_sents]\n        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n\n    def parse(self, sentence):\n        tagged_sents = self.tagger.tag(sentence)\n        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n        return nltk.chunk.conlltags2tree(conlltags)","a7c8777b":"# training the chunker \nchunker = ConsecutiveNPChunker(train_trees)","732bc321":"# evaluate the chunker\nprint(chunker.evaluate(valid_trees))","e140604d":"# example of 'DIGITDIGITDIGIT'\ntrain_pos[1326]","48ac3e26":"# extracts features for a given word i in a given sentence \n# history refers to the previous POS tags in the sentence\ndef npchunk_features(sentence, i, history):\n    word, pos = sentence[i]\n    \n    # the first word has both previous word and previous tag undefined\n    if i == 0:\n        prevword, prevpos = \"<START>\", \"<START>\"\n    else:\n        prevword, prevpos = sentence[i-1]\n        \n    if i == len(sentence)-1:\n        nextword, nextpos = '<END>', '<END>'\n    else:\n        nextword, nextpos = sentence[i+1]\n\n    # gazetteer lookup features (see section below)\n    gazetteer = gazetteer_lookup(word)\n\n    # adding word_is_digit feature (boolean)\n    return {\"pos\": pos, \"prevpos\": prevpos, 'word':word, \n           'word_is_city': gazetteer[0],\n           'word_is_state': gazetteer[1],\n           'word_is_county': gazetteer[2],\n           'word_is_digit': word in 'DIGITDIGITDIGIT', \n           'nextword': nextword, \n           'nextpos': nextpos}","42ec5177":"# train and evaluate the chunker \nchunker = ConsecutiveNPChunker(train_trees)\nprint(chunker.evaluate(valid_trees))","e9c75b5f":"# most top-N informative features\nchunker.tagger.classifier.show_most_informative_features(15)","da1de776":"# Decision Tree Classifier\nclass ConsecutiveNPChunkTagger(nltk.TaggerI): \n\n    def __init__(self, train_sents):\n        train_set = []\n        for tagged_sent in train_sents:\n            untagged_sent = nltk.tag.untag(tagged_sent)\n            history = []\n            # compute features for each word\n            for i, (word, tag) in enumerate(tagged_sent):\n                featureset = npchunk_features(untagged_sent, i, history) \n                train_set.append( (featureset, tag) )\n                history.append(tag)\n        self.classifier = nltk.DecisionTreeClassifier.train(train_set)\n\n    def tag(self, sentence):\n        history = []\n        for i, word in enumerate(sentence):\n            featureset = npchunk_features(sentence, i, history)\n            tag = self.classifier.classify(featureset)\n            history.append(tag)\n        return zip(sentence, history)\n\nclass ConsecutiveNPChunker(nltk.ChunkParserI): \n    def __init__(self, train_sents):\n        tagged_sents = [[((w,t),c) for (w,t,c) in\n                         nltk.chunk.tree2conlltags(sent)]\n                        for sent in train_sents]\n        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n\n    def parse(self, sentence):\n        tagged_sents = self.tagger.tag(sentence)\n        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n        return nltk.chunk.conlltags2tree(conlltags)","6d97f20c":"# train and evaluate the decision tree chunker\ntree_chunker = ConsecutiveNPChunker(train_trees)\nprint(tree_chunker.evaluate(valid_trees))","eed1bf76":"pip install sklearn_crfsuite","3eafceee":"# import relevant libraries\nfrom itertools import chain\nimport sklearn\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelBinarizer\n\n# pip\/conda install sklearn_crfsuite\nimport sklearn_crfsuite\nfrom sklearn_crfsuite import metrics\nfrom sklearn_crfsuite import scorers\n","4df2f7b5":"# extract features from a given sentence\ndef word_features(sent, i):\n    word = sent[i][0]\n    pos = sent[i][1]\n    \n    # first word\n    if i==0:\n        prevword = '<START>'\n        prevpos = '<START>'\n    else:\n        prevword = sent[i-1][0]\n        prevpos = sent[i-1][1]\n    \n    # last word\n    if i == len(sent)-1:\n        nextword = '<END>'\n        nextpos = '<END>'\n    else:\n        nextword = sent[i+1][0]\n        nextpos = sent[i+1][1]\n    \n    # word is in gazetteer\n    gazetteer = gazetteer_lookup(word)\n    \n    # suffixes and prefixes\n    pref_1, pref_2, pref_3, pref_4 = word[:1], word[:2], word[:3], word[:4]\n    suff_1, suff_2, suff_3, suff_4 = word[-1:], word[-2:], word[-3:], word[-4:]\n    \n    return {'word':word,\n            'pos': pos, \n            'prevword': prevword,\n            'prevpos': prevpos,  \n            'nextword': nextword, \n            'nextpos': nextpos,\n            'word_is_city': gazetteer[0],\n            'word_is_state': gazetteer[1],\n            'word_is_county': gazetteer[2],\n            'word_is_digit': word in 'DIGITDIGITDIGIT',\n            'suff_1': suff_1,  \n            'suff_2': suff_2,  \n            'suff_3': suff_3,  \n            'suff_4': suff_4, \n            'pref_1': pref_1,  \n            'pref_2': pref_2,  \n            'pref_3': pref_3, \n            'pref_4': pref_4 }  ","91e447f7":"# example features: third word of the first training sentence\nword_features(train_labels[0], i=3)","72410535":"# structure of train\/validation data\ntrain_labels[0]","4b2c89e1":"# defining a few more functions to extract featrues, labels, words from sentences\n\ndef sent2features(sent):\n    return [word_features(sent, i) for i in range(len(sent))]\n\ndef sent2labels(sent):\n    return [label for token, postag, label in sent]\n\ndef sent2tokens(sent):\n    return [token for token, postag, label in sent]    ","b47fe995":" # create training, validation and test sets\nX_train = [sent2features(s) for s in train_labels]\ny_train = [sent2labels(s) for s in train_labels]\n\nX_valid = [sent2features(s) for s in valid_labels]\ny_valid = [sent2labels(s) for s in valid_labels]\n\nX_test = [sent2features(s) for s in test_labels]\ny_test = [sent2labels(s) for s in test_labels]","b1f00452":"# X_train is a list of sentences within which each feature has a corresponding dict of features\n# first few words (each word has a feature dict) of the first sentence in X_train\nX_train[0][:2]","2470da45":"# labels of the first sentence\ny_train[0]","e35e042c":"# fitting crf with arbitrary hyperparameters\ncrf = sklearn_crfsuite.CRF(\n    algorithm='lbfgs',\n    c1=0.01,\n    c2=0.1,\n    max_iterations=100,\n    all_possible_transitions=True\n)\ncrf.fit(X_train, y_train)","e97c5f75":"# remove 'O' from the labels\nlabels = list(crf.classes_)\n# labels.remove('O')\n# labels[:5]","26318f64":"# make predictions \ny_pred = crf.predict(X_valid)\nmetrics.flat_f1_score(y_valid, y_pred,\n                      average='weighted', labels=labels)","c2fb9d08":"# class-wise scores\nsorted_labels = sorted(\n    labels,\n    key=lambda name: (name[1:], name[0])\n)\nprint(metrics.flat_classification_report(\n    y_valid, y_pred, labels=sorted_labels, digits=3\n))","b014eed4":"# hyperparameter tuning\n\n# define fixed parameters and parameters to search\ncrf = sklearn_crfsuite.CRF(\n    algorithm='lbfgs',\n    max_iterations=100,\n    all_possible_transitions=True\n)\n\n# parameters to tune\nparams_space = {\n    'c1': [0.01, 0.1, 1],\n    'c2': [0.01, 0.1, 1]\n}\n\n# use the same metric for evaluation\nf1_scorer = scorers.make_scorer(metrics.flat_f1_score,\n                        average='weighted', labels=labels)","0195f989":"# instantiate a GridSearchCV object\nrs = GridSearchCV(crf, \n                  params_space,\n                  cv=3,\n                  verbose=1,\n                  n_jobs=-1,\n                  scoring=f1_scorer, \n                  return_train_score=True)\n# fit\nrs.fit(X_train, y_train)","72a137fe":"# store CV results in a DF\ncv_results = pd.DataFrame(rs.cv_results_)\ncv_results","f5587ee5":"# plotting CV results\n# for each value of c2, make a plot of c1 versus train and test f1-score\n\nplt.figure(figsize=(16,6))\n\nfor i, val in enumerate(params_space['c2']):\n   \n    # subplot 1\/3\/i\n    plt.subplot(1, 3, i+1)\n    c2_subset = cv_results[cv_results['param_c2']==val]\n\n    plt.plot(c2_subset[\"param_c1\"], c2_subset[\"mean_validation_score\"])\n    plt.plot(c2_subset[\"param_c1\"], c2_subset[\"mean_train_score\"])\n    plt.xlabel('c1')\n    plt.ylabel('Mean F-score')\n    plt.title(\"c2={0}\".format(val))\n    plt.ylim([0.80, 1])\n    plt.legend(['validation score', 'train score'], loc='upper left')\n    plt.xscale('log')","3af1b56d":"# building a model with optimal hyperparams\ncrf = sklearn_crfsuite.CRF(\n    algorithm='lbfgs',\n    c1=0.1,\n    c2=0.1,\n    max_iterations=100,\n    all_possible_transitions=True\n)\ncrf.fit(X_train, y_train)","9ec280c3":"# save the model to a pickle file\nimport _pickle as cPickle\n\nwith open('tuned_crf_classifier.pkl', 'wb') as clf:\n    try:\n        cPickle.dump(crf, clf)\n    except Exception as e:\n        print(e)\n    finally:\n        clf.close()   ","d2edd978":"# load the trained model\nimport _pickle as cPickle\n\nwith open('tuned_crf_classifier.pkl', 'rb') as fid:\n    crf = cPickle.load(fid)","96317de7":"# remove 'O' from the labels\nlabels =list(crf.classes_)\n\n\n# make predictions on validation data\ny_pred = crf.predict(X_valid)\nmetrics.flat_f1_score(y_valid, y_pred,\n                      average='weighted', labels=labels)","a7ed4659":"# class-wise scores on validation data\nsorted_labels = sorted(\n    labels,\n    key=lambda name: (name[1:], name[0])\n)\nprint(metrics.flat_classification_report(\n    y_valid, y_pred, labels=sorted_labels, digits=3\n))","08f75648":"# test data predictions\n# make predictions on validation data\ny_pred_test = crf.predict(X_test)\nmetrics.flat_f1_score(y_test, y_pred_test,\n                      average='weighted', labels=labels)","ce8908b4":"# look up more attributes and methods of sklearn crf\n# help(crf)","adb20144":"from collections import Counter\n\ndef print_transitions(trans_features):\n    for (label_from, label_to), weight in trans_features:\n        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n\nprint(\"Top likely transitions:\")\nprint_transitions(Counter(crf.transition_features_).most_common(20))\n\nprint(\"\\nTop unlikely transitions:\")\nprint_transitions(Counter(crf.transition_features_).most_common()[-20:])","37efb830":"# important features\ndef print_state_features(state_features):\n    for (attr, label), weight in state_features:\n        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n\nprint(\"Top positive:\")\nprint_state_features(Counter(crf.state_features_).most_common(30))\n\nprint(\"\\nTop negative:\")\nprint_state_features(Counter(crf.state_features_).most_common()[-30:])","a5375cac":"# tagging a sample sentence (first validation sentence)\ni = 0\nsample_sent = valid_labels[i]\nprint(' '.join(sent2tokens(sample_sent)), end='\\n')","d57a1c04":"# compare the predicted and actual labels for a query\nprint(\"Predicted:\", \"\\n\",' '.join(y_pred[0]))\nprint('\\n')\nprint(\"Correct:\", \"\\n\" ,' '.join(sent2labels(sample_sent)))","f6b13d67":"# function to create (word, pos_tag, predicted_iob_label) tuples for a given dataset\ndef append_predicted_tags(pos_tagged_data, labels):\n    iob_labels = []\n    for sent in list(zip(pos_tagged_data, labels)):\n        pos = sent[0]\n        labels = sent[1]\n        l = list(zip(pos, labels))\n        tuple_3 = [(word_pos[0], word_pos[1], label) for (word_pos, label) in l]\n        iob_labels.append(tuple_3)\n    return iob_labels","91eb362b":"# predictions of IOB tags on a sample validation sentence \nvalid_tags = append_predicted_tags(valid_pos, y_pred)\nvalid_tags[0]","5f6c4a79":"# create a tree using the assigned iob labels\nvalid_trees = [conlltags2tree(sent) for sent in valid_tags]\nprint(valid_trees[0])","ef000b71":"# append test data predicted tags\ntest_tags = append_predicted_tags(test_pos, y_pred_test)\ntest_trees = [conlltags2tree(sent) for sent in test_tags]\nprint(test_trees[0])","601a3911":"# choose a random predicted tree\ni = random.randrange(len(valid_trees))\n\n# print the string version of the chosen sentence\nchunked_tree = valid_trees[i]\nprint(' '.join([id_to_words[val] for val in val_x[i]]), '\\n')\n\n# traverse the tree and print labels of subtrees \nfor n in chunked_tree:\n    if isinstance(n, nltk.tree.Tree):\n        print(n.label(), n.leaves())","a3af1f61":"# correctly parsed complex queries - i= 771, 410, 25, 473, 23, 498, 893, 882, 694\n# ambiguous queries: not many so far\ni","4ef9899c":"# list all labels of train trees\ntree_labels = []\nfor tree in train_trees:\n    for n in tree:\n        if isinstance(n, nltk.tree.Tree):\n            tree_labels.append(n.label())","1022d6b6":"# training set has 78 unique labels\nlabel_set = set(tree_labels)\nlen(label_set)","40939cae":"# frequency of chunk types\/labels\n# from collections import Counter\nc = Counter(tree_labels)\npprint.pprint(c.most_common(10))","5989c01d":"# print the string version of the chosen sentence\ni = random.randrange(len(valid_trees))\n# i=408\nchunked_tree = valid_trees[i]\nprint(' '.join([id_to_words[val] for val in val_x[i]]), '\\n')\n\n# acceptable labels\nextract_labels = [\"fromloc.city_name\", \"toloc.city_name\", \"depart_date.day_name\", \n                 \"depart_time.period_of_day\", \"depart_date.day_number\", \"depart_date.month_name\",\n                 \"depart_time.time\", \"depart_time.time_relative\", \"depart_date.today_relative\"]\n\n# traverse the tree and print labels of subtrees \nfor n in chunked_tree:\n    if isinstance(n, nltk.tree.Tree) and \\\n     n.label() in extract_labels:\n        print(n.label(), n.leaves())","a72826a4":"# complex queries\n#i = 637, 255, 285\n\n# funny query: i=127 (the guy just wants to get away from dallas)\ni","4b74cee9":"# Useful flightstats URLs\n# https:\/\/developer.flightstats.com\/api-docs\/scheduledFlights\/v1\n# https:\/\/developer.flightstats.com\/api-docs\/\n# https:\/\/developer.flightstats.com\/api-docs\/how_to","204bbd73":"# querying flightstats API \napp_id = '9bed5b33'\napp_key = 'd7a448569ce9d0821da4fcc9f371e8cc'\n\nbase_url = 'https:\/\/api.flightstats.com\/flex\/schedules\/rest\/v1\/json\/from\/'\n\n# {departureAirportCode}\/to\/{arrivalAirportCode}\/departing\/{year}\/{month}\/{day}\n# JFK in new york to LAX in los angeles\n# make sure to enter a future date, else no data is returned\nextended_url = 'JFK\/to\/LAX\/departing\/2018\/7\/18'\n\n# credentials\ncreds = '?appId={0}&appKey={1}'.format(app_id, app_key)\n\n# complete url\nurl = base_url + extended_url + creds\nprint(url)","e7bf6318":"# request data from the API\nimport requests, json\ndata = requests.get(url).json()","82d6cf17":"# sample flight details\ndata['scheduledFlights'][1]","c769e045":"# number of flights returned\nlen(data['scheduledFlights'])","3d837836":"# data of all active airports\nbase_url = 'https:\/\/api.flightstats.com\/flex\/airports\/rest\/v1\/json\/active\/'\nurl = base_url + creds\ndata = requests.get(url)\nairports = data.json()\n\n# convert to df\nairports_df = pd.DataFrame(airports['airports'])\nairports_df.to_csv('airports.csv')","63646bf1":"airports_df = pd.read_csv(\"airports.csv\")\nairports_df.head()","f6d2eaae":"# looking up 'new york' in the airports dataframe\n# fs refers to 'flightstats code' of the airport\nairports_df[airports_df['city'].str.lower() =='new york']","4cd4991c":"# extract main airport codes from city name\ndef city_to_airport_code(city):\n    df = airports_df[(airports_df['city'].str.lower() == city) & \\\n                ((airports_df['classification'] == 1) | \\\n                 (airports_df['classification'] == 2))]['fs']\n    return list(df)\n","47e71e0d":"# samples\nprint(city_to_airport_code(\"new york\"))\nprint(city_to_airport_code(\"baltimore\"))\nprint(city_to_airport_code(\"chicago\"))\nprint(city_to_airport_code(\"pittsburgh\"))\n","8150cccf":"# i=776\ni","5dc86328":"## TODO:\n\n## Layer-1: \n# get list of entities from tree\n# get source and dest cities, dep date\n\ndef tree_to_dict(tree):\n    # traverse the tree and store the subtrees\/labels and leaves\n    labels = {}\n    for n in tree:\n        if isinstance(n, nltk.tree.Tree) and \\\n        n.label() in extract_labels:\n            leaf_str = ' '.join([leaf[0] for leaf in n.leaves()])\n            labels[n.label()] = leaf_str\n    \n    return(labels)\n    ","d4544948":"train_dicts = [tree_to_dict(tree) for tree in train_trees]\nvalid_dicts = [tree_to_dict(tree) for tree in valid_trees]\ntest_dicts = [tree_to_dict(tree) for tree in test_trees]","980a1ce0":"# depart_date.day_name\nday_names = [d.get(\"depart_date.day_name\") for d in train_dicts \\\n            if d.get(\"depart_date.day_name\") is not None]\nprint(\"day_names\\n\", set(day_names), '\\n')\n\n# depart_date.day_number\nday_numbers = [d.get(\"depart_date.day_number\") for d in train_dicts \n               if d.get(\"depart_date.day_number\") is not None]\nprint(\"day_numbers\\n\", set(day_numbers), '\\n')\n\n\n# depart_date.month_name\nmonth_names = [d.get(\"depart_date.month_name\") for d in train_dicts \n               if d.get(\"depart_date.month_name\") is not None]\nprint(\"month_name\\n\", set(month_names), '\\n')\n\n# depart_time.time_relative\ntime_relative = [d.get(\"depart_time.time_relative\") for d in train_dicts \n               if d.get(\"depart_time.time_relative\") is not None]\nprint(\"time_relative\\n\", set(time_relative), '\\n')\n\n# depart_time.time\ntime = [d.get(\"depart_time.time\") for d in train_dicts \n               if d.get(\"depart_time.time\") is not None]\nprint(\"time\\n\", set(time), '\\n')\n\n# depart_time.period_of_day\nperiod_of_day = [d.get(\"depart_time.period_of_day\") for d in train_dicts \n               if d.get(\"depart_time.period_of_day\") is not None]\nprint(\"period_of_day\\n\", set(period_of_day), '\\n')\n\n# depart_date.today_relative\ntoday_relative = [d.get(\"depart_date.today_relative\") for d in train_dicts \n               if d.get(\"depart_date.today_relative\") is not None]\nprint(\"today_relative\\n\", set(today_relative), '\\n')\n","9e4eb244":"# text2int\ndef text2int(textnum, numwords={}):\n    if not numwords:\n        units = [\n        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n        ]\n\n        tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n\n        scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n\n        numwords[\"and\"] = (1, 0)\n        for idx, word in enumerate(units):  numwords[word] = (1, idx)\n        for idx, word in enumerate(tens):       numwords[word] = (1, idx * 10)\n        for idx, word in enumerate(scales): numwords[word] = (10 ** (idx * 3 or 2), 0)\n\n    ordinal_words = {'first':1, 'second':2, 'third':3, 'fifth':5, 'eighth':8, 'ninth':9, 'twelfth':12}\n    ordinal_endings = [('ieth', 'y'), ('th', '')]\n\n    textnum = textnum.replace('-', ' ')\n\n    current = result = 0\n    for word in textnum.split():\n        if word in ordinal_words:\n            scale, increment = (1, ordinal_words[word])\n        else:\n            for ending, replacement in ordinal_endings:\n                if word.endswith(ending):\n                    word = \"%s%s\" % (word[:-len(ending)], replacement)\n\n            if word not in numwords:\n                raise Exception(\"Illegal word: \" + word)\n\n            scale, increment = numwords[word]\n        current = current * scale + increment\n        if scale > 100:\n            result += current\n            current = 0\n\n    return result + current","5538bf3f":"# examples\nprint(text2int(\"twenty\"))\nprint(text2int(\"first\"))\nprint(text2int(\"thirtieth\"))\nprint(text2int(\"twenty eighth\"))\nprint(text2int(\"twelfth\"))","65efa3b3":"# months: use the builtin calendar module\nimport calendar \nmonth2int = {v.lower():k for k,v in enumerate(calendar.month_name)}\nmonth2int    ","ec806b31":"# days\nday2int = {v.lower():k for k,v in enumerate(calendar.day_name)}\nday2int","c92f6bb7":"# return the date of the next day_name from today\nimport datetime\ndef next_weekday(d, weekday):\n    days_ahead = weekday - d.weekday()\n    if days_ahead <= 0: # Target day already happened this week\n        days_ahead += 7\n    return d + datetime.timedelta(days_ahead)\n\ntoday = datetime.date.today()\nnext_day = next_weekday(today, 1) # 0 = Monday, 1=Tuesday, 2=Wednesday...\nprint(\"date\", next_day)\nprint(\"year\", next_day.year)\nprint(\"month\", next_day.month)\nprint(\"day\", next_day.day)\n","58c183ef":"# extract integer dates etc from query tree\ndef extract_entities_from_tree(tree):\n    query_dict = tree_to_dict(tree)\n    entities = {}\n    \n    for key, val in query_dict.items():\n        \n        # get airport codes from city names as a list\n        if key == \"fromloc.city_name\" or key == \"toloc.city_name\":\n            entities[key] = city_to_airport_code(val)\n            \n        # strip the last 's' e.g. tuesdays from day of week\n        if key == \"depart_date.day_name\":\n            query_dict[key] = val[:-1] if val.endswith(\"s\") else val\n            \n            # get year, month, day of the next day_name\n            day_num = day2int[query_dict[key]]\n            today = datetime.date.today()\n            next_day = next_weekday(today, day_num) # 0 = Monday, 1=Tuesday, 2=Wednesday...\n            entities['day'] = next_day.day\n            entities['month'] = next_day.month\n            entities['year'] = next_day.year\n\n        # day number explicitly mentioned\n        if key == \"depart_date.day_number\":\n            entities['day'] = text2int(val)\n            today = datetime.date.today()\n            entities['month'] = today.month\n            entities['year'] = today.year\n            \n        # month explicitly mentioned\n        if key == \"depart_date.month_name\":\n            entities['month'] = month2int[val]\n            # assume today's date and year\n            today = datetime.date.today()\n            entities['day'] = today.day\n            entities['year'] = today.year\n        \n        # if day\/month\/year still not in dict, show tomorrow's flights\n        if ('day' not in entities.keys() or \n            'month' not in entities.keys() or \n            'year' not in entities.keys()):\n            today = datetime.date.today()\n            tom = today + datetime.timedelta(days=1)\n            entities['day'] = tom.day\n            entities['month'] = tom.month\n            entities['year'] = tom.year \n        \n    return query_dict, entities\n    \n    ","a6706324":"i = random.randrange(len(train_trees))\ni=2308\nprint(' '.join([id_to_words[t] for t in train_x[i]]), '\\n')\nq, d = extract_entities_from_tree(train_trees[i])\nprint(train_trees[i])\nprint(q)\nprint(d)","3afa4d4d":"# examples from train set\n# i=1285, 2438 , 3442, 3120, 1956, 2084\ni","bd8ee8f3":"# sample: predicting a new user generated query\ns = 'Can you please show me flights from new york to los angeles departing on monday after DIGIT pm'\n\n# tokenize and tag user query and create features for each token\ndef process_user_query(sent_string):\n    tokens = nltk.word_tokenize(sent_string)\n    pos_tags = nltk.pos_tag(tokens)\n    \n    # create features from words in query q\n    query_features = [word_features(pos_tags, i) for i in range(len(pos_tags))]      \n    return(pos_tags, query_features)\n\n# generate query features for sentence s\nquery_pos_tags, query_features = process_user_query(s)\n\n# predict tags of query\npredicted_labels = crf.predict([query_features])[0]\npredicted_labels","7d99d142":"# convert the predicted labels into standard (token, pos, label) format\nquery_tag_list = [(pos_tag[0], pos_tag[1], label) for pos_tag, label in list(zip(query_pos_tags, predicted_labels))]\n\n# convert into tree\nquery_tree = conlltags2tree(query_tag_list)\n\n# traverse the tree and print labels of subtrees \nfor n in query_tree:\n    if isinstance(n, nltk.tree.Tree):\n        label = n.label()\n        leaves = ' '.join(i[0] for i in n.leaves())\n        print(label,':', leaves)","78ba65d7":"We can also see the most informative features of the NLTK NB classifier.","6c81f52b":"Now that we can extract the chunks from any given user query, we need to decide which chunks  we actually need for our application and extract only those. \n\nFirstly, note that although there are a variety of labels\/chunk types, only a few occur in majority of user queries. \n\nSecondly, while building an application to make flight reservations, you may be using an API\/database to fetch the requested flight data, and the API\/database may only provide certain types of information. For e.g. if the API does not provide any info about *meals* in flights, there may be no use extracting the entity ```meal_description```.\n\nLet's look at both the variety and frequency of entities. ","88637a24":"To map the integers to words, we need to use the dictionaries provided. The dicts ```words2idx``` and ```labels2idx``` map the numeric ids to the actual words and labels respectively.","18c34670":"# Information Extraction \n\n**Information Extraction (IE)** refers to the task of extracting structured information from unstructured text data. In this case, we want to extract all pieces of information from a query which are useful in making a flight reservation, such as source and destination cities, date of travel, price range etc. \n\nOther examples of IE tasks are extracting information about stock market announcements from financial news (which could be useful for predicting stock prices etc.), extracting structured information from large corpora of documents such as encyclopedias, government documents etc. On wikipedia, for e.g., some structured information is shown on the right side of the pages:\n\n<br><br><hr>\n<img src='https:\/\/i.stack.imgur.com\/oJumb.png'>\n<br><br><hr>\n\nMost IE tasks start with the task of **Named Entity Recognition (NER)** - identifying mentions of *entities* in the text. Loosely speaking, entities refer to names of people, organizations (e.g. Air India, United Airlines), places\/cities (Mumbai, Chicago), dates and timepoints (May, Wednesday, morning flight), numbers of specific types (e.g. money - 5000 INR) etc.\n\nThe general process of information extraction is described below.\n","de3e6b5b":"Now, we **define a chunk grammar** to identify noun phrase chunks as follows: *A noun phrase chunk occurs when an optional determiner (DT) is followed by any number of adjectives (JJ) and then a noun (NN).*","93141f72":"### Creating 3-tuples of ```(word, pos, IOS_label)```\nTo train a model, we need the entity labels of each word along with the POS tags, for e.g. in this format:\n\n```\n('show', 'VB', 'O'),\n('me', 'PRP', 'O'),\n('the', 'DT', 'O'),\n('cheapest', 'JJS', 'B-cost_relative'),\n('round', 'NN', 'B-round_trip'),\n('trips', 'NNS', 'I-round_trip'),\n('from', 'IN', 'O'),\n('dallas', 'NN', 'B-fromloc.city_name'),\n('to', 'TO', 'O'),\n('baltimore', 'VB', 'B-toloc.city_name')\n```\n<hr>\n\nLet's convert the training, validation and test sentences to this form. Since we have already  done POS tagging of the queries, we'll write a function which takes queries in the form (word, pos_tag) and the labels as input, and returns the list of sentences in the form (word, pos_tag, iob_label).","351a2593":"### Making Predictions \n\nLet's now use the trained model to make predictions. ","2e4283b9":"Let's also look at what the unigram parser has learnt.","27afc3db":"Having tuned the model, we can now save (dump) it to a a pickle file so that we can simply import it and use later for predictions.","47ded7d1":"### Converting Predicted Labels to Trees and Traversing Them\n\nLet's now see how we can use the trained model to make predictions on unseen data and extract useful entities from it.\n\nOnce we predict the labels of a sentence, we want to extract useful entities from it. In the following code, we first append the predicted labels to the (word, pos) sentence to get tuples of (word, pos, predicted_label). Then we convert the list to tree format, as seen earlier, and traverse the tree to extract useful entities. \n\n","40fba9e2":"**Problems with the NLTK Tagger**\n\nNote that almost all city\/airport names that come after 'to\/TO' are tagges as verbs 'VB', which is clearly incorrect. This is because NLTK's built-in tagger is trained using the penntreebank dataset, and it takes 'to\/TO' as a strong signal for a 'VB'.\n\n\nIn general, the performance of a POS tagger depends a lot on the data used to train it. There are alternatives to it - one, you can try using an alternative tagger such as the Stanford tagger, Spacy etc. (though note that getting them up and running in python may take a bit of time in installing dependencies\/debugging etc.).\n\nThe other alternative (recommended as a quick fix) is to use a **backup tagger** within NLTK, i.e. manually specify a unigram\/bigram tagger to be used, and backed up by the standard NLTK tagger. You can <a href=\"https:\/\/stackoverflow.com\/questions\/5919355\/custom-tagging-with-nltk\/5922373#5922373\">learn how to do that here.<\/a>\n","7ebd8a5b":"Now, we define two classes ```ConsecutiveNPChunkTagger``` and ```ConsecutiveNPChunker```.\n\nThe ```__init__``` method of the ```ConsecutiveNPChunkTagger``` class creates the ```train_set``` which is a list of labelled training sentences. Each sentence is a list of tuples (featureset, tag) -  each tuple is the featureset (dict) of a word and its label. \n\nThe list ```history``` contains the list of previously predicted IOB tags, i.e. tags to the left of the target word. We can only use IOB tags to the left of the target word since that's all the tags we have at the time of prediction.\n\nThe ```__init__``` method takes in an IOB tagged list of train_sents and loops through them. It first untags the IOB tags to generate (word, pos_tag) tuples stored in ```untagged_sent```. These tuples are used to compute the word features.\n\nThen for each (word, IOB_tag) in ```tagged_sent```, it computes the word features and appends the feature dict and the tag to ```train_sents```. It further appends the IOB tag to ```history```.\n \nThe ```tag()``` method simply takes in a sentence as a list of words and predicts the IOB label of each word in the sentence.\n\nThe ```ConsecutiveNPChunker``` class does all the the uninteresting work of converting between tree-list-tree formats (since NLTK's builtin classifiers need the list format). It takes in a list of sentences as trees, converts each sentence to the list form, and then initialises its tagger using methods already defined in the ```ConsecutiveNPChunkTagger``` class. The ```parse``` method tags the sentence and returns it in the tree format since it is easier to print and read.\n\n","5ee54dec":"Now, let's convert the training data into a standard format - ```X_train``` is a list of sentences, where each sentence is a list of word_features (dicts). The list ```y_train``` is a list of sentences, each sentence further being a list of labels.","d98c1729":"Now that we have the queries in tree formats, we can build some models to extract entities.","4a8a7b69":"Now, when coming across a day name such as Monday, Tuesday etc. we'll simply use the date corresponding to the next Monday\/Tuesday. The following code returns the date of the next day_name.","218c1706":"Let's now build a CRF classifier. In sklearn, CRFs are implemented in the library ```sklearn_crfsuite```.","7d67942b":"Now we can extract entities in numeric format using these functions\/dicts. Given a query (tree), we'll extract source and destination cities, day (int), month (int) etc. If the day is specified as name e.g. Monday, we'll assume it is the next Monday and query that date. \n\nFor time and time modifiers such as before, after etc., we'll filter the 'arr\/dep time' attributes after we get the data from the API.","5be18974":"The plot above shows that at very low values of c_1, the model overfits, as shown by the difference in training and test performance. Also, the test score seems to be slightly higher for c_2 = 0.1.\n\nLet's thus choose c_1 = 0.1 and c_2 = 0.1. ","d4337870":"Now, after extracting the source and destination cities (the entities ```fromloc``` and ```toloc```), we can query the API to get the list of flights. We also have to parse the dates to get the year, month and day.","dadd7b13":"The first NP chunk is 'the little yellow dog' and the second one is 'the cat'. One can also print the list representation of this tree as follows:","eb5689f3":"## Probabilistic Models for Entity Recognition\n\nLet's experiment with a few different models for labelling words with named entities.\n","8f3418bb":"Let's add some of these features and see if the performance improves.","d95f842d":"Now we can print the words and corresponding labels simply by looking up the value of a numeric index of each word. Let's write a function which takes in an index and returns the corresponding query with its labels.","525dc52f":"# Models for Entity Recognition\n\nIn the following sections, we'll build a variety of models for entity recognition, i.e. to predict the sequence of IOB tag of words. We'll try the two broad approaches - **rule-based models** and **probabilistic models**. \n\nBefore that, we need to do some basic preprocessing of the data. \n\n## Part of Speech Tagging\n\nThe usual preprocessing steps are sentence segmentation, tokenisation and POS tagging, but since in this case the raw data is already split into sentences (queries) and words, we only need to do POS tagging.\n\nThe function below takes in a list of (encoded) sentences, uses the dict ```id_to_words``` to decode the numeric to the corresponding word, and returns the POS tagged list of sentences.","54dad46d":"It is easy to see that a common pattern is *from city_1 to city_2*. The POS tag of from is 'IN', to is 'TO'. However, there's an interesting flaw in the tagger - most cities (city_2) after TO are tagged as as verb 'VB' (the nltk tagger uses 'TO' as a string signal for a verb).\n\nNevertheless, the pattern is ```from\/IN city_1\/JJ city_1\/NN to\/TO city_2\/VB city_2\/NN``` (you can try looking at multiple sentences and verify).\n\nLet's define the grammar to identify the two types of chunks - ```fromloc.city_name``` and ```toloc.city_name```. The syntax is to simply write two regexes within the grammar, one for each, one after the other.","1c544a90":"The dict above shows the frequency of each chunk type in the training set. As expected, the most frequent ones are ```toloc.city_name```, ```fromloc.city_name```, ```depart_date.day_name``` etc.\n\nIn the section below, we will extract some common entities from a given sentence and use <a href=\"https:\/\/developer.flightstats.com\/\">the flightstats API<\/a> to query flight schedules data. \n\nFor now, we'll extract only ```fromloc.city_name```, ```toloc.city_name```, ```depart_date.day_name```, ```depart_time.period_of_day```, ```depart_date.day_number```, ```depart_date.month_name```, ```depart_time.time_relative```, ```depart_date.today_relative``` and ```depart_time.time```.","c8a93fe7":"An accuracy of 63.8% shows that about 63% words have the tag 'O', i.e. they do not fall in any chunk\/entity. The other metrics are 0 since we did not predict any chunks at all.\n\nLet's now look at a few sentences and try to identify patterns for the chunks ```fromloc.city_name``` and ```toloc.city_name``` (since these are the most common entities).","d206e24f":"Let's now write some functions to convert the training, validation and test datasets to the format required by the sklearn CRF classifier. The structure of the training sentences is as given below.","743b4442":"One can similarly make predictions on the test dataset and store them in tree format.","d41d5a87":"### Using a Gazetteer to Lookup Cities and States\n\nA gazetteer is a geographical directory which stores data regarding the names of geographical entities (cities, states, countries) and some other features related to the geographies. An example gazetteer file for the US is given below.\n\nData download URL: https:\/\/raw.githubusercontent.com\/grammakov\/USA-cities-and-states\/master\/us_cities_states_counties.csv\n\n\nWe'll write a simple function which takes a word as input and returns a tuple indicating **whether the word is a city, state or a county**.","bd6a9d91":"Now, let's look at some typical entries in day_number, month_name etc., so that we can process them correctly. For example, how are day and months typically written - *seventh, twenty third, September (or Sept?)* etc. ","17c71c5b":"The flightstats Schedules API provides multiple API call types (mentioned on <a href=\"https:\/\/developer.flightstats.com\/api-docs\/scheduledFlights\/v1\">this page<\/a>). Some of these are also mentioned below.\n\nHowever, we'll only use the following first type of API call, ```from dep_city to arr_city on dep_date```, since it covers the majority of query types.\n\n","d660229e":"## Building an Application","709cca4e":"### Chunking\n\nChunking is a way to identify meaningful sequences of tokens called chunks in a sentence. It is commonly used to identify sequences of nouns, verbs etc. For example, in the example sentence taken from the NLTK book: <br>\n\nS = *\"We saw the yellow dog\"*\n\nthere are two **noun phrase chunks** as shown below. Each outer box represents a chunk.\n\n<img src='https:\/\/www.nltk.org\/book\/tree_images\/ch07-tree-1.png'>\n\nThe corresponding **IOB representation** of the same is as follows:\n\n<img src='https:\/\/www.nltk.org\/images\/chunk-tagrep.png'>\n\n\n\nSimilarly, in our dataset, the following sentence contains chunks such as fromloc.city_name (san francisco), class_type (first class), depart_time.time (DIGITDIGIT noon) etc.\n","01d8766e":"Let's now fit a CRF with arbitrary hyperparameters. ","e7e91183":"We now use the ```nltk.RegexpParser``` to parse the given sentence. The output will be a tree which identifies the NP chunks.","085ef88e":"The first list contains the actual queries encoded by integers such as 554, 194, 268 ... and so on. For e.g. the first three integers 554, 194, 268 are encoded values of the words 'what', 'flights', 'leave' etc. \n\n\nThe second list is to be ignored.\n\nThe third list contains the (encoded) label of each word (how to do these mappings is explained in detail below). Since the actual words are encoded by numbers, we have to decode them using the dicts provided. Let's first store the three lists into separate objects so we don't have to worry about indexing the lists.\n","816a24e0":"The list above shows that New York has multiple airports and thus airport codes (you can check for other cities such as LA etc.). The main airports, however, have the value classification=1 or 2. \n\nLet's write a small function which takes in the city name and returns the codes of the main airports.","5f254002":"The unigram tagger has learnt that most pos tags are indeed an 'O', i.e. don't form an entity. Some interesting patterns it has learnt are:\n- JJR, JJS (relative adjectives), are most likely B-cost_relative (e.g. cheapest, cheaper)\n- NNP is most likely to be B-depart_time.time","6d4bdbc4":"Similarly, we can map the encoded values of each word's label using the ```labels``` dict.","05e1217b":"### Named Entity Recognition (NER)\n\nThe labels corresponding to each word\/token, as shown above, are of three types - I, O and B, which stand for inside, out and beginning (called **IOB tags**). This is a common way of labelling text data meant for NER tasks. The task of information extraction and named-entity recognition is explained in detail below. First, let's understand the task of NER and IOB labelling in detail.\n\nSome example IOB tagged words are shown below:\n","54b21864":"Now that we have converted the queries in the form (word, pos, label), we can convert them into a **tree format** and observe the actual entities more clearly (rather than IOB labels). \n\nIn general, IOB tagged sentences are represented in either of the two common formats - 1. The ```(word, pos, label)``` or the tagged list format or 2. The tree format. \n\nAs we will see later, some built-in models\/sequence taggers in NLTK need the data in the tree format.\n\n### Converting List to Tree Format\n\nLet's now convert the sentences into a tree format, which is needed by NLTK to train taggers. In NLTK, there are two main methods to convert between the two formats (the list of tags and tree) - ```conlltags2tree``` and ```tree2conlltags```.","8e9eb45e":"So now, for training, validation and test sets, we have the **encoded words and labels** stored in the lists (train_x, train_label), (val_x, val_label) and (test_x, test_label). The first list represents the actual words (encoded), and the other list contains their labels (again, encoded).\n\nLet's now understand the structure of the lists.","dd116e94":"The performance of decision trees is much better compared to the Naive Bayes classifier. We can of course also tune the decision tree hyperparameters (maxdepth, num_leaves, min_sample_split etc.), but we'll skip that for now.\n\nHaving tried some classification models, let us now try another extremely useful and popular model for sequence classification - **conditional random fields**.","a8b76c0a":"Let's now convert all queries in the train, validation and test trees to corresponding dicts.","dc1e17fd":"We'll define three functions below - ```sent2features()``` creates word features for each word in a given sentence while ```sent2labels``` extracts the label of each word in a given sentence.","f132fa0b":"We can see that in this dataset, queries are quite complex (large variety of labels, sentence structures etc.) and thus it is extremely hard write hand-written rules to extract useful entities.\n\nThus, we need to train probabilistic models such as CRFs, HMMs etc. to tag each word with its corresponding entity label.\n","28465f15":"### Bigram Chunker\n\nLet's try a bigram chunker as well - we just need to change the ```UnigramTagger``` to ```BigramTagger```. This works exactly like the unigram chunker, the only difference being that now the probability of a pos tag having a label is computed using the current and the previous POS tags, i.e. P(label | pos, prev_pos).","cdc22c2e":"Now let's build some **classifiers for NER**, i.e. classification models which take in each word (i.e. its features) as input and predicts its IOB label.","ae95b408":"There are 127 classes of labels (including the 'O' - tokens that do not fall into any entity).","8162c2fb":"The tree above shows three entities in the query - ```flight_mod earliest``` (earliest), ```fromloc.city_name``` (boston), ```toloc.city_name``` (atlanta).","abc2fe0d":"The training set is a tuple containing three lists of same lengths as shown above. Similarly, the validation and test sets contain three lists as well (shown below).","0d2f4870":"### Understanding the CRF Classifier\n\nLet's now understand what the classifier has learnt. The method ```crf.transition_features_``` returns a dict of key:value = (label-1, label-2):coef pairs - each key-val pair representing the transition coefficient from label-1 to label-2.\n\nThe ```Counter``` class from the collections module provides a convenient way of counting and printing the frequency of items (the top-N or bottom counts). Read the <a href=\"https:\/\/docs.python.org\/2\/library\/collections.html\">docs of Counter class here.<\/a>","c241eb24":"There are various techniques for building chunkers, such as regex based, unigram and bigram chunkers etc.\n\n### Regular Expression Based Chunkers\n\nRegex based chunkers define what is called a **chunk grammar**. A **chunk grammar is a pattern of POS tags** which are likely to form a particular chunk (and thus POS tagging is a necessary preprocessing step for such chunkers). \n\nThe example from the NLTK book defined a simple garmmar to identify noun phrase chunks:\n\n","fb83faad":"The overall f1-score is comparable to that on training (cross-validation) data (which was about 93% on the test folds and 97% on training folds). Let's look at class-wise metrics as well.","fa0791f5":"Let's define a function to extract features from a given sentence. This is similar to the ```npchunk_features()``` function defined above, but we'll add some new features as well such as the **suffix** of the word (upto the last 4 characters), **prefix** (upto first 4 characters) etc.\n\nThe list of features we'll extract is as follows:\n```\n{\n            'word':word,\n            'pos': pos, \n            'prevword': prevword,\n            'prevpos': prevpos,  \n            'nextword': nextword, \n            'nextpos': nextpos,\n            'word_is_city': gazetteer[0],\n            'word_is_state': gazetteer[1],\n            'word_is_county': gazetteer[2],\n            'word_is_digit': word in 'DIGITDIGITDIGIT',\n            'suff_1': suff_1,  \n            'suff_2': suff_2,  \n            'suff_3': suff_3,  \n            'suff_4': suff_4, \n            'pref_1': pref_1,  \n            'pref_2': pref_2,  \n            'pref_3': pref_3, \n            'pref_4': pref_4 \n\n}\n```\n\n","a2b9fb12":"Let's also make predictions on the test set and see the results. ","ce632b2f":"The classification report tells us that:\n- The overall f1-score (a weighted average of overall precision and recall) is 93.7%\n- The *important* classes, i.e. those with high frequency such as ```B-fromloc.city_name```, ```B-toloc.city_name```, ```B-depart_date.day_name``` etc. are performing well\n\nLet's now try tuning the hyperparameters of CRF using grid search CV.","2056794e":"Similarly, we can write rules to identify entities in the airlines dataset. Before building any useful chunkers, let's first make a **baseline chunker** - one which assigns the label 'O' to every word and see its evaluation metrics. We can then compare the eventual models with this one. ","8bcd73e1":"## Rule-Based Models for Entity Recognition\n\nThe most basic rule-based system can be written using regular expressions. The idea is to manually identify patterns which indicate occurence of entities we are interested in, such as source and destination cities, mentions of dates and time, names of organisations (in this case airlines such as united airlines, american airlines etc.) and write regular expressions to match them.\n","72f07c5a":"Now let's make predictions using the validation data and evaluate model performance. The metric we'll use for evaluation is ```flat_f1_score``` which is a weighed average of each class' f1-scores.","773af02c":"Now that we have a trained tagger and have looked at the overall metrics, let's zoom in and look at the actual and predicted labels of some sample sentences.","f96447b6":"\n## Information Extraction Pipeline\n\nMost IE pipelines start with the usual text preprocessing steps - sentence segmentation, word tokenisation and POS tagging. After preprocessing, the usual tasks are named entity recognition, and optionally relation recognition. \n\nNote that this is a generic pipeline, and you may make modifications according to the nature of your application. For example, you may add a 'spell check\/correction layer' as the first preprocessing step if you expect some input data to have spelling errors.\n\nA generic IE pipeline schema, taken from the official NLTK book, is shown below.\n\n<br><br><hr>\n<img src='https:\/\/www.nltk.org\/images\/ie-architecture.png'>\n<br><br><hr>\n\n### Preprocessing \n\nThe usual preprocessing steps are - if the raw input data is in the form of paragraphs, it is converted into sentences using a **sentence segmenter**, then broken down into tokens using **tokenisation**, and finally each token is **POS tagged**.\n\n","ec3267f6":"The results are although better than the baseline model, they are still quite unimpressive. Notice that now precision, recall and f-score are non-zero, indicating that the chunker is able to identify at least some chunks correctly (in this case ```fromloc.city_name``` and ```toloc.city_name```).\n\nWe can add more regex patterns for other chunk types as well.","0bd55f12":"<img src=\"api.png\">","b22b1fd9":"In the query above, there are two named entities (cities) - san francisco and denver. \n\nSince san francisco comprises of two words, the first one is tagged *B-* and the second as *I-*. On the other hand, denver is only one word, so there's no *I-* tag. All the other words are not entities and are thus marked *O* (outside any entity).\n\nThe **NER task** is to **predict the IOB labels** of each word.","d0365bbc":"## Conditional Random Fields (CRF)\n","a4a3d894":"Dealing with months is the easiest since there are just 12 varieties. Similarly, day names cab be looked up from a manully created dict ```{sunday, sundays, tuesday, tuesdays, ...}``` etc.\n\nFor converting day numbers to numerics, although there are some nice third-party libraries such as ```word2num```, they only handle simple cases such as 'one', 'thirty two' etc. but not words which ends in suffixes such as 'twentieth', 'thirty first' etc.\n\nCredits: <a href=\"https:\/\/stackoverflow.com\/questions\/493174\/is-there-a-way-to-convert-number-words-to-integers?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\">Stack Overflow<\/a>","078709e5":"Now, we can convert the predicted sentence labels to a tree format and traverse the tree to extarct useful entities.","b50c3afd":"### Pipeline: From Tree to Flight Data\n\nThe following pipeline shows the steps to process a given sentence tree (predicted using CRF), extract entities from it, generate a relevant API call, and apply additional constraints to filter the data.\n\nThere are roughly three layers in the application:\n1. Extracting structured entities from query tree\n2. Making the API call to get JSON data\n3. Applying additional constraints to the retreived data \n\n\nThe first layer processes the parsed tree and extracts structured entities so that we can make an API call. For e.g. queries mention dates as \"seventh may\" which needs to be passed to the API as integers (day=7, month=5). Similarly, a request for \"flight on Wednesday\" should query the API for a flight which departs on the closest upcoming Wednesday from the current data. \n\nThe second layer's task is to make the API call and fetch the data.\n\nThe third layer applies filters on arrival\/departure time, such as 'evening', 'early morning', 'after DIGIT pm' etc. to the retreived data and returns the filtered data to the user.\n","fc0e7536":"Now let's load the dumped model from the pkl file and use it for predictions.","f9deb29e":"We can also try other classifiers that come with NLTK - let's try building a **decision tree**.","833df296":"The results show that the transitions ```B-fromloc.airport_name -> I-fromloc.airport_name```, ```B-depart_date.month_name -> B-depart_date.day_number``` are very likely. You can also see the unlikely transitions.\n\nWe can also see the most useful (discriminative) features.","4a6ffa7e":"Let's now convert all training sentences to trees.","83697093":"Thus, we have the train, validation and test sets each containing three lists of different lengths. Now, let's understand the data stored in the three lists.","3c836caa":"The first step is to sign up and create an app ID and key. The example query below queries the Schedules API to get a list of all flights from airport_code_1 to airport_code_2 departing on a certain date (type-1 API call).","f1017940":"Also, some queries specify stopover cities, such as this.","6e10b6f6":"### Unigram Chunker\n\nLet's now try a **unigram chunker**. A unigram chunker assigns the IOB label that is most likely for each POS tag.\n\nThe following code defines a class ```UnigramChunker``` which (on initialisation) first converts the tree form of a sentence to the list form (word, pos, label), extracts the (pos, label) pairs and computes the unigram probabilities ```P(label | pos)``` for each POS tag. It then simply assigns the label that is most likely for the POS tag.\n\nThe ```parse()``` method of the class takes a sentence in the form (word, pos) as the input, extracts only the pos tag from it, and uses the unigram tagger to assign the IOB label to each word. It then returns the sentence after converting it to a tree format.\n\nNote that the unigram tagger, like the previous regex-based chunkers, *does not make use of the word itself but only the word's POS tag*.","5243f3ab":"Let's now look at word features of some example sentences.","2afddef5":"### Traversing a Chunked Tree\n\nNow that we have labelled the validation and test datasets, let's see how we can traverse the trees. The following code shows a sample predicted validation query and extracts all the 'chunks' from the tree.\n\nIn NLTK, trees are stored as objects of the ```Tree``` class, and each chunk of a tree is itself a subtree of the ```Tree``` class. Below, we traverse a sample tree, check whether a given object in the tree is an object  ```Tree``` (i.e. a chunk), and prints the *label* and the *leaves* of the chunk subtree.","495d0667":"# Understanding the Data \n\nLet's understand the structure of the training data. The dataset is provided in five folds, each fold having a training, validation, test set and a dict (explained later). All folds are structurally identical, so understanding one fold is enough to understand the entire set.\n","11f1279a":"The metrics have improved significantly from unigram to bigram, which is expected. However, there are still some major flaws in this approach to build chunkers, the main drawback being that the model *uses only the POS tag to assign the label, not the actual word itself*. \n\nIt is likely that if a model can make use of the word itself apart from the POS tag, it should be able to learn more complex patterns needed for this task. \n\nIn fact, apart from the word, we can extract a large number of other features, such as previous word, previous tag, whether the word is a numeric, whether the word is a city or an airline company etc.\n\nThus, in the following few sections, we'll extract a variety of features and build classifiers such as Naive Bayes using those features. \n\nOur first step in the direction of feature extraction will be to extract an feature which indicates whether a word is a city, state or county etc. Such features can be extracted by simply **looking up a gazetteer**.\n","14dc30dd":"The query above uses airport codes to request the data, but our parser extracts the names of cities (san franciso, new york etc.) rather than airport codes. \n\nThus, we need to convert the city names to flightstats airport codes. We can do that using another flightstats API - *airports*, which returns a list of all airports, their codes, and various other attributes.","c89749a1":"The accuracy, precision and recall have slightly improved compared to the previous regex-based  parser. ","eae08664":" ### Ignore - Processing a Sample User Generated Query","394787ff":"# ATIS Flight Reservations - Information Extraction\n\n\n<hr>\n\nTable of Contents:\n\n1. Understanding the Data\n2. Information Extraction \n    - Pipeline for Information Extraction Systems\n    - Named Entity Recognition (NER)\n3. Models for Entity Recognition\n    - Rule-based models\n        - Regular Expression Based Rules (ex)\n        - Chunking \n    - Probabilistic models\n        - Unigram and Bigram models\n        - Naive Bayes Classifier \n        - Conditional Random Fields (CRFs)\n\n<hr>\n\nThe ATIS (Airline Travel Information Systems) dataset consists of English language queries for booking (or requesting information about) flights in the US. \n\nEach word in a query (i.e. a request by a user) is labelled according to its **entity-type**, for e.g. in the query 'please show morning flights from chicago to new york', 'chicago' and 'new york are labelled as 'source' and 'destination' locations respectively while 'morning' is labelled as 'time-of-day' (the exact labelling scheme is a bit different, more on that later).\n\nSome example queries taken from the dataset are shown below:\n\n```\n{\n'what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco',\n 'what is the abbreviation for canadian airlines international',\n \"i 'd like to know the earliest flight from boston to atlanta\",\n 'show me the us air flights from atlanta to boston',\n 'show me the cheapest round trips from dallas to baltimore',\n \"i 'd like to see all flights from denver to philadelphia\"\n }\n ```\n\n### Objective\nOur objective is to **build an information extraction system** which can extract entities relevant for booking flights (such as source and destination cities, time, date, budget constraints etc.) in a **structured format** from a given user-generated query.\n\nA structured format could be a dictionary, a JSON, etc. - basically anything that can be parsed and used for looking up relevant flights from a database.\n\n\n### Dataset\nThe dataset is divided into five folds, each fold having a training, validation and test set.\n\n\n\n","d931b865":"We can see that some informative features are ```pos```, ```word```, ```word_is_digit``` etc.\n\nWhen pos=JJS (superlative adjective e.g. *\"cheapest\"*), the ratio of probability of the labels ```B-cost:O``` is about 14237:1. Similarly, the features ```word``` and ```word_is_digit``` are very strong indicators of the labels ```B-depa``` and ```I-depa``` (departure time e.g. *\"after DIGIT pm\"*).","63270526":"There are 78 types of labels\/entities in the training set (there might be some more in validation \/ test as well, though not many). Let's now look at the frequency of chunk types.","0f19007c":"Let's now remove the label 'O' from the list of labels (can be accessed through ```crf.classes_```). This is because we'll only measure the metrics for other less frequent classes.","c384095f":"Let's now read the first fold of the dataset. The data is in .gz files, so we'll need the gzip library as well. ","79655006":"#### Reversing the Dictionaries\n\nSince the dicts ```words``` and ```labels``` are key:value pairs of index:word\/label, let's reverse the dicts so that we don't have to do a reverse lookup everytime.","faebd748":"The results have improved significantly compared to the basic unigram\/bigram chunkers, and they may improve further if we create better features.\n\nFor example, if the word is 'DIGIT' (numbers are labelled as 'DIGIT' in this dataset), we can have a feature which indicates that (see example below). In this dataset, 4-digit numbers are encoded as 'DIGITDIGITDIGITDIGIT'.","70f92213":"## Classifiers for NER \n\nAs discussed above, IOB tagging is a **sequence classification task** - given a sequence of words and pos tags, predict the IOB label of the word. \n\nOne of the main advantages of classifier based chunkers is that we can use a variety of features which we think will be strong indicators of a word's IOB tag. \n\nFor e.g. if a word is a state\/city name such as 'boston', it is very likely an ```B-fromloc.city_name``` or ```B-toloc.city_name```. \n\nSimilarly, we can expect that the **previous word and the previous POS tag** could help predict the IOB labels of a word; that **if a word is the first or the last in the sentence** may strongly help predict the IOB label, etc. \n\nAlso, in all sequence classification tasks, one can use the **predicted labels of the previous words** as features (recall that HMMs compute transition probabilities).\n\n\nThe following code implements the Naive Bayes classifer which uses a variety of **word features** for classification. \n\nThe function ```npchunk_features()```  takes in a sentence and  the word whose features are to be extracted (defined by its index i in the sentence) as input and returns a dictionary of word features as output. It also takes a ```history``` argument - a list of already predicted previous tags to the left of the target word, which is useful if you are using them as features.\n\n","8d678e1f":"### NER as a Sequence-Labelling Task\n\nThe task of **training an NER system**, i.e. assigning an IOB label to each word, is a **sequence labelling task** similar to POS tagging. For sequence labelling, one can try rule-based models such as writing **regular-expression based rules** to extract entities, **chunking** patterns of POS tags into an 'entity chunk' etc. (we'll try some of these below)\n\nOne the other hand, one can use **probabilistic sequence labelling models** such as **HMMs**, the **Naive Bayes** classifier (classifying each word into one label class), **Conditional Random Fields (CRFs)** etc. \n\nOnce the IOB tags of each word are predicted, we can **evaluate the model** using the usual metrics for multi-class classification models (num_classes = number of IOB tags).\n\nIn the upcoming sections, we will try some of these approaches and compare their performance.","0bf0edfa":"The sections beyond this on building an application are totally optional. \n<hr><hr><hr>","1769d1c6":"### Querying Data from FlightStats API \n\nWe'll use the flightstats API for getting data of flight schedules. <a href=\"https:\/\/developer.flightstats.com\/api-docs\/\">The homepage of flightstats API<\/a> shows the list of all APIs they provide; we'll use <a href=\"https:\/\/developer.flightstats.com\/api-docs\/scheduledFlights\/v1\">the Schedules API<\/a>.","deb5f659":"The overall score does not give a detailed picture of how respective classes are performing. For e.g. we'd want to know how many ```fromloc.city_name``` and ```toloc.city_name``` are correctly identified. \n\nWe can see the class-wise evaluation metrics using sklearn's ```classification_report```. The metrics precision, recall and f1-score are as usual, while support represents the number of instances of the respective class in the training data."}}