{"cell_type":{"b17bfd3a":"code","05986c08":"code","4417c217":"code","aae5d7d6":"code","8d11b1ae":"code","58c21c63":"code","8040a443":"code","cc9a4c3b":"code","a2c7314c":"code","807d44b5":"code","fe28b8ec":"code","b81a5840":"code","acb2e4d2":"code","19540229":"code","4b976fc2":"code","d260f52f":"code","ab763c3e":"code","5dff1a51":"code","b03fd6c6":"code","8d10dde1":"code","eef5affe":"code","0f79e2a5":"code","24f476ee":"code","56955077":"code","54a8e850":"code","f42fbbf5":"code","6f3e18f5":"code","b39c0a86":"code","3eea906b":"code","5640a00b":"code","57150448":"code","414aadd7":"code","9d494fc8":"code","af1de6ce":"code","9af6703d":"code","1ff99563":"code","fb2e7d09":"code","ff021ace":"code","21a54769":"code","376e847a":"code","2a9d3248":"code","0925b1c3":"code","d8ccbf2b":"code","86db379b":"code","d87d9bd6":"code","e7adef99":"code","369c33da":"code","d30c2c64":"code","0da3dffa":"code","9876220c":"code","a8e5757b":"code","f6cd4ed6":"code","a3a83377":"code","1c54c2c4":"code","b38c9ff0":"code","67c8524e":"code","5331318d":"code","61c49cdc":"code","f6caaa6e":"code","e5f069f3":"code","0ab68d8e":"markdown","4e7668a9":"markdown","d891b191":"markdown","6ea09d4a":"markdown","7643e0d7":"markdown","de0905e6":"markdown","f88bd210":"markdown","177d6dd3":"markdown","2b2230d8":"markdown","9e796e19":"markdown","fc2799ec":"markdown","d0ffae75":"markdown","eadd0e4b":"markdown","6f6c9032":"markdown","79211798":"markdown","52dda0cf":"markdown","29d6edba":"markdown","4560455f":"markdown","966e61c2":"markdown","d21a2847":"markdown","35771304":"markdown"},"source":{"b17bfd3a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mp\n%matplotlib inline \nimport seaborn as sns","05986c08":"train = pd.read_csv(\"..\/input\/titanic-machine-learning-from-disaster\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic-machine-learning-from-disaster\/test.csv\")\ntrain.head()\ntest.head()","4417c217":"train.isnull().sum()","aae5d7d6":"train.drop(['PassengerId','Name','Ticket','Cabin'],axis='columns',inplace=True)\ntest.drop(['PassengerId','Name','Ticket','Cabin'],axis='columns')\ntrain.head(2)","8d11b1ae":"train.dtypes","58c21c63":"train.describe()","8040a443":"dict={}\nfor i in train.columns:\n    dict[i]=train[i].value_counts().shape[0]\npd.DataFrame(dict,index=['unique']).transpose()","cc9a4c3b":"fig = plt.figure(figsize=(20,12))\ngs = fig.add_gridspec(2,4)\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\n\nsns.countplot('Survived', data=train, ax=ax0).set(xlabel='Survived')\nsns.countplot('Parch', data=train, ax=ax1).set(xlabel='parch')\nsns.countplot('Embarked', data=train, ax=ax2).set(xlabel='Embarked')\nsns.countplot('SibSp', data=train, ax=ax3).set(xlabel='SibSp')\nsns.countplot('Sex', data=train, ax=ax4).set(xlabel='sex')\nsns.countplot('Pclass', data=train, ax=ax5).set(xlabel='Pclass')\n","a2c7314c":"fig=plt.figure(figsize=(15,12))\ngs=fig.add_gridspec(1,2)\naxA=fig.add_subplot(gs[0,0])\naxB=fig.add_subplot(gs[0,1])\n\nsns.kdeplot(train['Age'],data=train,ax=axA,fill=True,color='orange').set(xlabel='Age')\nsns.kdeplot(train['Fare'],data=train,ax=axB,fill=True,color='red').set(xlabel='Fare')\nplt.text(180, 0.0232,'Age curve is seems likely to have guassian curve whereas Fare curve isnt a guassian curve so we need to transform',fontsize='22')","807d44b5":"# blue is died and yellow is lived\nfig=plt.figure(figsize=(20,12))\ngs=fig.add_gridspec(2,3)\nax0=fig.add_subplot(gs[0,0])\nax1=fig.add_subplot(gs[0,1])\nax2=fig.add_subplot(gs[0,2])\nax3=fig.add_subplot(gs[1,0])\nax4=fig.add_subplot(gs[1,1])\nax5=fig.add_subplot(gs[1,2])\n\nsns.kdeplot(train['Age'],data=train,hue='Survived',ax=ax0,fill=True,color='red').set(xlabel='Age')\nsns.countplot('Sex',data=train,hue='Survived',ax=ax1).set(xlabel='Sex')\nsns.countplot('Parch',data=train,hue='Survived',ax=ax2).set(xlabel='Parch')\nsns.countplot('Embarked',data=train,hue='Survived',ax=ax3).set(xlabel='embarked')\nsns.countplot('Pclass',data=train,hue='Survived',ax=ax4).set(xlabel='pclass')\nsns.countplot('SibSp',data=train,hue='Survived',ax=ax5).set(xlabel='sibsp')","fe28b8ec":"# for heatmap withour confusion matrix we use this special feature which is .corr()\nmatrix=np.triu(train.corr()) # for half heatmap we use np.triu and use mask inside heatmap\nplt.figure(figsize=(15,9))\nsns.heatmap(train.corr(),annot=True,mask=matrix)","b81a5840":"fig = plt.figure(figsize=(18,10))\ngs = fig.add_gridspec(2,2)\ngs.update(wspace=0.5, hspace=0.25)\naxC = fig.add_subplot(gs[0,0])\n# axD = fig.add_subplot(gs[1,0])\naxA = fig.add_subplot(gs[0,1])\naxB = fig.add_subplot(gs[1,1])\n\nsns.boxenplot(x=\"Pclass\",y=\"Age\",data=train, palette=['#FD151B' ,'#97D2FB' ,'#F9C846' ,'#437F97'], ax=axA)\n\nsns.boxenplot(x=\"Survived\",y=\"Age\",data=train, palette=['#FD151B' ,'#97D2FB' ,'#F9C846' ,'#437F97'], ax=axB)\n\nsns.boxenplot(x='Sex',y='Age',data=train,palette=['#FD151B' ,'#97D2FB' ,'#F9C846' ,'#437F97'],ax=axC)","acb2e4d2":"test.describe()","19540229":"dict={}\nfor i in test.columns:\n    dict[i]=test[i].value_counts().shape[0]\npd.DataFrame(dict,index=['unique']).transpose()","4b976fc2":"test.isnull().sum()","d260f52f":"test.drop(['PassengerId','Ticket','Cabin','Name'],axis='columns',inplace=True)\ntest.head()","ab763c3e":"fig = plt.figure(figsize=(20,12))\ngs = fig.add_gridspec(2,4)\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\n\nsns.countplot('Parch', data=test, ax=ax1).set(xlabel='parch')\nsns.countplot('Embarked', data=test, ax=ax2).set(xlabel='Embarked')\nsns.countplot('SibSp', data=test, ax=ax3).set(xlabel='SibSp')\nsns.countplot('Sex', data=test, ax=ax4).set(xlabel='sex')\nsns.countplot('Pclass', data=test, ax=ax5).set(xlabel='Pclass')\n\n","5dff1a51":"fig=plt.figure(figsize=(15,12))\ngs=fig.add_gridspec(1,2)\naxA=fig.add_subplot(gs[0,0])\naxB=fig.add_subplot(gs[0,1])\n\nsns.kdeplot(test['Age'],data=test,ax=axA,fill=True,color='orange').set(xlabel='Age')\nsns.kdeplot(test['Fare'],data=test,ax=axB,fill=True,color='red').set(xlabel='Fare')","b03fd6c6":"print('training data')\nprint('median age for people who are in first class',train[train['Pclass']==1]['Age'].median())\nprint('median age for people who are in second class',train[train['Pclass']==2]['Age'].median())\nprint('median age for people who are in third class',train[train['Pclass']==3]['Age'].median())","8d10dde1":"print('testing data')\nprint('median age for people who are in first class',test[test['Pclass']==1]['Age'].median())\nprint('median age for people who are in second class',test[test['Pclass']==2]['Age'].median())\nprint('median age for people who are in third class',test[test['Pclass']==3]['Age'].median())","eef5affe":"def input_age_train(columns):\n    Age=columns[0]\n    Pclass=columns[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass==1:\n            return 37\n        elif Pclass==2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","0f79e2a5":"train['Age']=train[['Age','Pclass']].apply(input_age_train,axis=1)","24f476ee":"def input_age_test(columns):\n    Age=columns[0]\n    Pclass=columns[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass==1:\n            return 42\n        elif Pclass==2:\n            return 26\n        else:\n            return 24\n    else:\n        return Age","56955077":"test['Age']=test[['Age','Pclass']].apply(input_age_test,axis=1)","54a8e850":"test.isnull().sum()","f42fbbf5":"test[test['Fare'].isnull()]","6f3e18f5":"print('median of S class is ',test[test['Pclass']==3]['Fare'].mean())","b39c0a86":"test['Fare']=test['Fare'].fillna(12.46)","3eea906b":"test.isnull().sum()","5640a00b":"fig=plt.figure(figsize=(15,9))\ngs=fig.add_gridspec(1,2)\nax0=fig.add_subplot(gs[0,0])\nax1=fig.add_subplot(gs[0,1])\n\nsns.kdeplot(train['Fare'],data=train,ax=ax0,fill=True,color='red').set(xlabel='train_fare')\nsns.kdeplot(test['Fare'],data=test,ax=ax1,fill=True,color='orange').set(xlabel='train_fare')","57150448":"train[\"Fare\"] = train[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\ntest[\"Fare\"] = test[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","414aadd7":"fig=plt.figure(figsize=(10,5))\ngs=fig.add_gridspec(1,2)\nax0=fig.add_subplot(gs[0,0])\nax1=fig.add_subplot(gs[0,1])\n\nsns.kdeplot(train['Fare'],data=train,ax=ax0,fill=True,color='red').set(xlabel='train_fare')\nsns.kdeplot(test['Fare'],data=test,ax=ax1,fill=True,color='orange').set(xlabel='train_fare')","9d494fc8":"test.head()","af1de6ce":"print(test['Pclass'].unique())\nprint(test['SibSp'].unique())\nprint(test['Parch'].unique())\nprint(test['Embarked'].unique())","9af6703d":"train['Age']=pd.qcut(train['Age'],10,duplicates='drop')\ntest['Age']=pd.qcut(test['Age'],10,duplicates='drop')","1ff99563":"fig=plt.figure(figsize=(15,9))\ngs=fig.add_gridspec(1,1)\nax0=fig.add_subplot(gs[0,0])\n\nsns.countplot(train['Age'],data=train,hue='Survived',ax=ax0).set(xlabel='Age wrt survived')","fb2e7d09":"train['familysize']=train['SibSp']+train['Parch']+1\ntest['familysize']=test['SibSp']+test['Parch']+1","ff021ace":"train.loc[(train['familysize']==1),'familysize']=0 #alone\ntrain.loc[(train['familysize']>1) & (train['familysize']<=4),'familysize']=1 #samllfamily\ntrain.loc[(train['familysize']>4) & (train['familysize']<=6),'familysize']=2 #mediumfsmily\ntrain.loc[(train['familysize']>6),'familysize']=3 #largefsmily","21a54769":"test.loc[(test['familysize']==1),'familysize']=0 #alone\ntest.loc[(test['familysize']>1) & (test['familysize']<=4),'familysize']=1 #samllfamily\ntest.loc[(test['familysize']>4) & (test['familysize']<=6),'familysize']=2 #mediumfsmily\ntest.loc[(test['familysize']>6),'familysize']=3 #largefsmily","376e847a":"train.drop(['SibSp','Parch'],axis='columns',inplace=True)\ntest.drop(['SibSp','Parch'],axis='columns',inplace=True)","2a9d3248":"train.head()","0925b1c3":"from sklearn.preprocessing import LabelEncoder\ntrain['Age']=LabelEncoder().fit_transform(train['Age'])\ntest['Age']=LabelEncoder().fit_transform(test['Age'])","d8ccbf2b":"c=train[['Sex','Embarked']]\ndummies=pd.get_dummies(c)\ndummies.head(10)","86db379b":"dummies1=pd.get_dummies(train['Pclass'])\ndummies1.head()","d87d9bd6":"dummies2=pd.concat([dummies,dummies1],axis=1)\ndummies2.head()","e7adef99":"dummies2.rename(columns={1:'Pclass_1',2:'Pclass_2',3:'Pclass_3'},inplace=True)","369c33da":"dummies2.head()","d30c2c64":"train_new=pd.concat([dummies2,train],axis=1)\ntrain_new","0da3dffa":"train_new.drop(['Pclass','Sex','Embarked'],axis=1,inplace=True)\ntrain_new.head()","9876220c":"from sklearn.model_selection import train_test_split\nX=train_new.drop('Survived',axis=1)\ny=train_new['Survived']","a8e5757b":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","f6cd4ed6":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.transform(X_test)","a3a83377":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","1c54c2c4":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=34)\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)","b38c9ff0":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","67c8524e":"from sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","5331318d":"n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","61c49cdc":"from sklearn.model_selection import RandomizedSearchCV\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(X_train,y_train)","f6caaa6e":"rf_random.best_params_","e5f069f3":"rf_random.score(X_test,y_test)","0ab68d8e":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">Random Forest Classification<\/h1>\n\n<\/div>","4e7668a9":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">Logistic Regression<\/h1>\n\n<\/div>","d891b191":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">Reading Train and Test data from the datatset<\/h1>\n\n<\/div>","6ea09d4a":"**adding sibsp and parch in one column (family size)**","7643e0d7":"<div style=\"\n           border-radius:20px;\n           font-size:110%;\n           font-family:cursive;\n           letter-spacing:1px;\n           font-family:cursive\n           \">\n<center><img src = \"https:\/\/c.tenor.com\/VVOA7SCKgmkAAAAM\/test.gif\"><\/center>\n","de0905e6":"# **Introduction**\n<div style=\"\n           border-radius:20px;\n           font-size:110%;\n           font-family:cursive;\n           letter-spacing:1px;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">TITANIC PREDICTION<\/h1>\n<center><img src = \"https:\/\/c.tenor.com\/IjTPynungU8AAAAC\/titanic-breaks.gif\"><\/center>\n    \n <h2>Titanic<\/h2>\n <p>Titanic was a British passenger liner, operated by the White Star Line, which sank in the North Atlantic Ocean on 15 April 1912 after striking an iceberg during her maiden voyage from Southampton, UK, to New York City. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, which made the sinking possibly one of the deadliest for a single ship up to that time. It remains to this day the deadliest peacetime sinking of a superliner or cruise ship. The disaster drew much public attention, provided foundational material for the disaster film genre and has inspired many artistic works.\n\nRMS Titanic was the largest ship afloat at the time she entered service and the second of three Olympic-class ocean liners operated by the White Star Line. She was built by the Harland and Wolff shipyard in Belfast. Thomas Andrews, who was the chief naval architect of the shipyard at that time, died in the disaster.<\/p>\n\n\n\n\n\n<p>This Dataset contains the information about Titanic ship and included 891Rows and 12 columns.In this notebook I try to find the best ML model to predict which passengers survived the Titanic shipwreck.<\/p>\n\n    \n    \n<p>Variable Notes:<\/p>\n\n<ul>\n    \n<li>pclass: A proxy for socio-economic status (SES)(Ticket class) 1 = 1st, 2 = 2nd, 3 = 3rd<\/li>\n\n\n<li>1st = Upper<\/li>\n\n<li>2nd = Middle<\/li>\n\n<li>3rd = Lower<\/li>\n\n<li>age:Age in years<\/li>\n\n<li>Sibsp: The dataset defines family relations in this way...(number of siblings \/ spouses aboard the Titanic)<\/li>\n\n<li>Sibling = brother, sister, stepbrother, stepsister<\/li>\n\n<li>Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)<\/li>\n\n<li>Parch: The dataset defines family relations in this way...(number of parents \/ children aboard the Titanic)<\/li>\n\n<li>Parent = mother, father<\/li>\n\n<li>Child = daughter, son, stepdaughter, stepson<\/li>\n\n<li>Some children travelled only with a nanny, therefore parch=0 for them.<\/li>\n\n<li>Survival:0 = No, 1 = Yes<\/li>\n\n<li>Sex: Male , Female<\/li>\n\n<li>Ticket:Ticket number<\/li>\n\n<li>Fare:Passenger fare<\/li>\n\n<li>Cabin:Cabin number<\/li>\n\n<li>Embarked:Port of Embarkation(C = Cherbourg, Q = Queenstown, S = Southampton)<\/li>\n<\/ul>","f88bd210":"**Pclass 1 had people mostly had people aged between 30 and 50 years. It might be because the more aged people might have better jobs and finances to afford first class.**\n\n**Pclass 2 had people aged between 20-40 more**\n\n**Pclass 3 had more people age between 20-30**\n\n**Age column has significant outliers as observed from the plots**\n\n**Sex columns has significant outliers as observed from the plots**","177d6dd3":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">Univariate Analysis with respect to Survived Column(Target)<\/h1>\n\n<\/div>","2b2230d8":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">Dropping not so cordinating columns with survived column<\/h1>\n\n<\/div>","9e796e19":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">null values<\/h1>\n\n<\/div>","fc2799ec":"<div style=\"\n           border-radius:20px;\n           font-size:110%;\n           font-family:cursive;\n           letter-spacing:1px;\n           font-family:cursive\n           \">\n<center><img src = \"https:\/\/vatsalparsaniya.github.io\/ML_Knowledge\/_images\/gif.gif\"><\/center>\n","d0ffae75":"**people in range 20-24 of Age survived and died the most**","eadd0e4b":"\n**we need to change Sex and Embarked categorical columns into numeric colums**","6f6c9032":"**heatmap helps to corelate the features with each other**\n\n\n**Pclass has a good negative correlation with Fare. Its kinda obvious that as Pclass increases Fare will decrease(Third Class will cost less than First class).**\n\n**Fare also has minor positive correlation with Survived. Again people who paid more had more chances of survival.**\n\n**SibSp has good positive correlation with Parch. We can concatenate these together into a single family column later on**","79211798":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">HyperTuning of RandomForest<\/h1>\n\n<\/div>","52dda0cf":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">models<\/h1>\n\n<\/div>","29d6edba":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">Test Data<\/h1>\n\n<\/div>","4560455f":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">K-nearest neighbour<\/h1>\n\n<\/div>","966e61c2":"<div style=\"\n           border-radius:20px;\n           font-size:110%;\n           font-family:cursive;\n           letter-spacing:1px;\n           font-family:cursive\n           \">\n<h3 style=\"text-align:center;\">Random Forest Classififcation giving us the highest accuracy of 81.56%<\/h3>\n<center><img src = \"https:\/\/66.media.tumblr.com\/5dd57c2cb2e5801f662bf8c8a7fa91ab\/c073e7987cb0c13a-be\/s500x750\/4919f4c52044d0e2654f92f6fc28c190c1ac8f52.gif\"><\/center>\n","d21a2847":"**Categorical Features: Sex, Parch, Embarked**\n\n**Ordinal Features: Pclass**\n\n**Continous Features: age, fare**\n\n**Discrete Feature: SibSip**\n\n**Target Feature: Survived**\n\n**categorical feature= sex,parch,embarked,pclass,sibsp,survived**\n\n**continous feature=age,fare**","35771304":"<div style=\"color:white;\n           display:fill;\n           border-radius:30px;\n           font-size:100%;\n           font-family:cursive;\n           letter-spacing:2px;\n           background-color:pink;\n           color:Purple;\n           font-family:cursive\n           \">\n<h1 style=\"text-align:center;\">SVM<\/h1>\n\n<\/div>"}}