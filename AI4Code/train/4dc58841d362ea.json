{"cell_type":{"0371d72a":"code","7dcb6a83":"code","30e6a1d9":"code","1acab847":"code","a409e143":"code","038737f9":"code","048d1a73":"code","8c440ee6":"code","d8e497a6":"code","f4c29127":"code","c417d761":"code","f59d0965":"code","2f56e240":"code","2f04b70a":"code","c889b5e6":"code","e7d43eea":"code","60c3a996":"code","2d823933":"markdown","6ecdb7bc":"markdown","8250738e":"markdown","2ba776bd":"markdown","23020c3a":"markdown"},"source":{"0371d72a":"'''Load librarires'''\nimport pickle\nimport time\nimport random\nimport glob\nimport os\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom collections import defaultdict\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision\nfrom torchvision import models, transforms, utils\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, roc_auc_score","7dcb6a83":"class CFG:\n\n    '''Store all hyperparameters here.''' \n    \n#     DEBUG=False\n\n    SEED = 420\n#     TEST_SIZE = 0.2\n    VAL_SIZE = 0.1\n    CLASSES = None #Need to update manually\n    OUTPUT_FEATURES = None #Need to update manually\n    \n    #Transforms\n    TRAIN_TRANSFORMS = A.Compose([\n        A.Resize(224, 224),\n        ToTensorV2(),\n        ])\n    VAL_TRANSFORMS = A.Compose([\n        A.Resize(224, 224),\n        ToTensorV2(),\n    ])\n    TEST_TRANSFORMS = A.Compose([\n        A.Resize(224, 224),\n        ToTensorV2(),\n    ])\n    \n    #model\n    MODEL1 = {\n        'name': 'resnet18',\n        'transfer': True,\n        'architecture': models.resnet18(pretrained=True), # ResNet18\n        'criterion': nn.CrossEntropyLoss(),\n        'optimizer': optim.Adam,\n        'weight_decay': 1e-6,\n        'lr': 1e-4,\n        'history': None\n    }\n\n    BATCH_SIZE = 192\n    EPOCHS = 3\n    \n    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print('You are using ->', DEVICE)    ","30e6a1d9":"def seed_everything(seed):\n    '''Make the results reproducible'''\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True \n\nseed_everything(CFG.SEED)","1acab847":"train = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\nsub = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')","a409e143":"'''Store data paths and their labels in pandas dataframe. Will be used to create pytorch datasets. '''\n\ntrain_paths = glob.glob('..\/input\/seti-breakthrough-listen\/train\/*\/*' )\nmeta = pd.DataFrame(sorted(train_paths),columns=['path'])\n\n#assign id and target to from the train df\nmeta['id'], meta['target'] = train.id, train.target\n\n# get class mappings\nclasses = dict(enumerate(meta.target.astype('category').cat.categories))\nCFG.CLASSES = classes\nCFG.OUTPUT_FEATURES = len(CFG.CLASSES)\n\nmeta.head()","038737f9":"#get test data paths\ntest_paths = glob.glob('..\/input\/seti-breakthrough-listen\/test\/*\/*' )\ntest = pd.DataFrame(sorted(test_paths),columns=['path'])\ntest['target'] = 0 #dummy targets\n\ntest.head()","048d1a73":"'''Split data into train, validation and test sets'''\n\nX = list(meta.path)\ny = list(meta.target)\n\nX_train, X_val, y_train, y_val = train_test_split(X,\n                                                  y,\n                                                  test_size=CFG.VAL_SIZE,\n                                                  random_state=CFG.SEED,\n                                                  stratify=y) #stratified split\n\nX_test,y_test = test.path, test.target\n\n\nprint(f'Train length -> {len(X_train)}')\nprint(f'Val length -> {len(X_val)}')\nprint(f'Test length -> {len(X_test)}')","8c440ee6":"'''Custom pytorch dataset implementation.'''\nclass SETIDataset(Dataset):\n    def __init__(self,X,y, transform=None):\n        self.X = X\n        self.y = y\n        self.transform = transform\n\n        assert len(self.X) == len(self.y), f'X and y have different lengths -> {len(self.X)} != {len(self.y)} '\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self,idx):\n        img_path = self.X[idx]\n        img = np.load(img_path)\n        img = img.astype(np.float32)\n        img = np.vstack(img).transpose((1, 0))\n        if self.transform is not None:\n            img = self.transform(image=img)['image']\n        label = torch.tensor(self.y[idx],dtype=torch.long)\n        return (img, label)\n    \n    def show_img(self,idx):\n        '''Plot image'''\n        img,label = self.__getitem__(idx)\n        img = img.numpy().transpose((1, 2, 0))\n        plt.figure(figsize=(16, 8))\n        plt.axis('off')\n        plt.imshow(img)\n        plt.title(CFG.CLASSES[int(label)]) #using CFG.CLASSES dict\n        plt.pause(0.001)","d8e497a6":"'''Instantiate pytorch train, validation and test sets'''\nTRAIN = SETIDataset(X_train,y_train, CFG.TRAIN_TRANSFORMS)\nVAL = SETIDataset(X_val,y_val, CFG.VAL_TRANSFORMS)\nTEST = SETIDataset(X_test,y_test, CFG.TEST_TRANSFORMS)\n\n'''Instantiate Dataloaders'''\nTRAIN_LOADER = DataLoader(TRAIN,CFG.BATCH_SIZE)\nVAL_LOADER = DataLoader(VAL,CFG.BATCH_SIZE)\nTEST_LOADER = DataLoader(TEST,CFG.BATCH_SIZE)","f4c29127":"class Net(nn.Module):\n    '''\n    ========================\n          NEURAL NET\n    ========================\n    \n    Args:\n        model_dict(dict): configuration dict containing the model architecture\n        output_features(int): length of output tensor; for classification equals to number of classes\n    '''\n    def __init__(self, model_dict, output_features):\n        super().__init__()\n        self.__dict__.update(model_dict) #unpack model dict from CFG into this class\n        \n        if self.transfer:\n            model = self.architecture\n            #modify the last layer\n            num_ftrs = model.fc.in_features\n            model.fc = nn.Linear(num_ftrs, output_features)\n            #modify the input size to fit the grayscale images!\n            model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n            self.model = model\n        else:\n#             self.model = self.architecture\n            pass\n        self.output_features = output_features\n        #optimizer\n        self.optimizer = self.optimizer(self.model.parameters(),lr = self.lr, weight_decay = self.weight_decay,amsgrad=False)\n        #path where to save model\n        self.save_path = 'models'\n        \n    def forward(self, x):\n        return self.model(x)\n\n    def fit(self,\n            train_loader,\n            val_loader,\n            epochs = 5,\n            batch_size = 32,\n            device = 'cpu'):\n        '''\n        =============================\n            OPTIMIZATION LOOP\n        =============================\n\n        Args:\n            train_loader(torch dataloader)\n            val_loader(torch dataloader)\n            epochs(int)\n            batch_size(int)\n            device(str)\n\n            \n        Output style inspired by skorch fit() method\n        https:\/\/skorch.readthedocs.io\/en\/stable\/net.html?highlight=fit#skorch.net.NeuralNet.fit\n\n        '''\n        #may be changed if lrscheduler is used???\n        lr = deepcopy(self.lr)\n\n        #get model training history\n        history = self.history\n        if history == None:\n            history = defaultdict(list)\n        else:\n            pass\n        #get train and val sizes\n        train_size = len(train_loader.dataset)\n        val_size = len(val_loader.dataset)\n        #stuff for printing epoch metrics as a beautiful table\n        headers = ['epoch','train_loss','val_loss','val_acc','cp','lr','dur']\n        template = '{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}'\n        print(template.format(*headers))\n        print(template.replace(':', ':-').format('','','','','','',''))\n        cyan = \"\\033[96m{:<10}\\033[00m\" #cyan\n        purple = \"\\033[95m{:<10}\\033[00m\" #purple\n        green = \"\\033[92m{:<10}\\033[00m\" #green\n        white = \"\\033[0m{:<10}\\033[0m\" #white\n        #set model into train mode\n        self.model.train()\n        #send model to device\n        self.model.to(device)\n        #training loop\n        for epoch in range(epochs):\n            start_time = time.time()\n            train_loss = 0\n            val_loss, val_acc = 0, 0\n            #optimization  loop\n            time.sleep(.2)\n            for X,y in tqdm(train_loader, desc =\"Train batches\"):\n                #Send training data to device\n                X,y = X.to(device), y.to(device)\n                #Forward propagation\n                pred = self.model(X)\n                loss = self.criterion(pred,y)\n                #Backpropagation\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                #update loss\n                train_loss = loss.item()\n                \n            #validation loop\n            with torch.no_grad():\n                for X, y in tqdm(val_loader, desc='Validation Batches'):\n                    X,y = X.to(device),y.to(device)\n                    pred = self.model(X)\n                    val_loss = self.criterion(pred,y).item()\n                    val_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n            #calculate validation accuracy after the epoch\n            val_acc \/= val_size\n            #append epoch results\n            history['epoch'].append(epoch+1)\n            history['train_loss'].append(train_loss)\n            history['val_loss'].append(val_loss)\n            history['val_acc'].append(val_acc)\n            \n            #colorize epoch's output if it improves\n            colortemp = template.split(' ')\n            # colorize train loss if it decreases\n            if history['train_loss'][-1] == min(history['train_loss']):\n                colortemp[1] = cyan\n            else:\n                colortemp[1] = white\n            #colorize validation loss if it decreases\n            if history['val_loss'][-1] == min(history['val_loss']):\n                colortemp[2] = purple\n            else:\n                colortemp[2] = white\n            # colorize validation accuracy & save best weights if it increases\n            if history['val_acc'][-1] == max(history['val_acc']):\n                #colorize       \n                colortemp[3] = green\n                #checkpoint\n                cp = '+'\n                if not os.path.exists(self.save_path):\n                    os.mkdir(self.save_path)\n                torch.save(self.model.state_dict(), Path(self.save_path,f'best_{self.name}.pth'))\n            else:\n                colortemp[3] = white\n                cp = '-'\n            colortemp = ' '.join(colortemp)\n\n            #calculate epoch duration (in seconds)\n            end_time = time.time()\n            dur = end_time - start_time\n            #append the rest of epoch results\n            history['cp'].append(cp)\n            history['lr'].append(lr)\n            history['dur'].append(dur)\n            #display the epoch results\n            print(colortemp.format(*f'{epoch+1}\/{epochs} {train_loss:.4f} {val_loss:.4f} {val_acc:.2f} {cp} {lr} {dur:.2f}'.split(' ')))\n        #update epoch number of the entire training history\n        history['epoch'] = [e+1 for e in range(len(history['epoch']))]\n        #update model's training history\n        self.history = history\n        #save training history as csv\n        self.save_history()\n        \n    def predict(self,dataloader,device ='cpu'):\n        '''\n        ===============\n           Predict\n        ===============\n        '''\n        #set model to evaluation mode\n        self.model.eval()\n        #model to device, default cpu\n        self.model.to(device)\n\n        preds = []\n        with torch.no_grad():\n            for X, y in tqdm(dataloader):\n                X,y = X.to(device),y.to(device)\n                pred = self.model(X)\n                pred = pred.argmax(1)\n                preds.append(pred)\n        return preds\n    \n    def eval_model(self,dataloader,avg=None,device ='cpu'):\n        '''\n        ==================================\n           ACCURACY PRECISION RECALL F1\n        ==================================\n        '''\n        labels = [l for l in range(self.output_features)]\n        loader_size = len(dataloader)\n        dataset_size = len(dataloader.dataset)\n\n        acc = 0\n        precision = 0\n        recall = 0\n        f1 = 0\n        roc = 0\n\n        #set model to evaluation mode\n        self.model.eval()\n        #model to device, default cpu\n        self.model.to(device)\n\n        with torch.no_grad():\n            for X, y in tqdm(dataloader, desc = 'Evaluating the model'):\n                X,y = X.to(device),y.to(device)\n                pred = self.model(X)\n                #accuracy\n                acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n                pred = pred.argmax(1)\n                \n                # to int \n                pred,y = list(pred), list(y)\n                pred = [int(p) for p in pred]\n                y = [int(p) for p in y]\n\n                #precision\n                p = precision_score(y, pred, labels = labels, zero_division = 1, average = avg)\n                precision+=p\n                #recall\n                r = recall_score(y, pred, labels = labels, zero_division = 1,  average = avg)\n                recall+=r\n                #f1 score\n                f = f1_score(y, pred, labels = labels, zero_division = 1,  average = avg)\n                f1 += f\n                #roc\n                roc += roc_auc_score(y, pred)\n\n        acc \/= dataset_size\n        precision \/= loader_size\n        recall \/= loader_size\n        f1 \/= loader_size\n        roc \/= loader_size\n            \n            \n        print(f\" Accuracy: {(100*acc):>0.1f}%\")\n        print(f\"Precision: {(100*np.mean(precision)):>0.1f}%\")\n        print(f\"   Recall: {(100*np.mean(recall)):>0.1f}%\")\n        print(f\" F1 Score: {(100*np.mean(f1)):>0.1f}%\")\n        print(f\"      ROC: {(100*np.mean(f1)):>0.1f}%\")\n\n        \n    def plot_loss_history(self):\n        '''\n        Plot loss history\n        '''\n        assert self.history != None, 'No history to plot -> the model has not been trained yet!'\n        \n        df = pd.DataFrame(self.history)\n        fig = px.line(x = df.epoch,\n                    y = [df.train_loss, df.val_loss],\n                    title = 'Loss History',\n                    labels={'x':'epoch','value': 'loss', 'variable': 'loss'})\n        fig.data[0].name = 'train'\n        fig.data[1].name = 'val'\n        fig.show()\n\n    def save_history(self):\n        '''Save model's training history'''\n        assert self.history != None, 'No history to save -> the model has not been trained yet!'\n        #save as csv\n        pd.DataFrame(self.history).to_csv(Path(f'models\/{self.name}_history.csv')) \n        #save as pickle file\n        with open(Path(f'models\/{self.name}_history.pkl'), 'wb') as f:\n            pickle.dump(self.history, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n    def save_model(self):\n        torch.save(self.model.state_dict(), Path(self.save_path,f'latest_{self.name}.pth'))\n\n    def load_model(self,path = 'models', device = 'cpu'):\n        '''Load model'''\n        try:\n            #load model weights\n            p = Path(path,f'best_{self.name}.pth')\n            self.model.load_state_dict(torch.load(p, map_location=torch.device(device)))\n            #load model training history\n            with open(Path(path,f'{self.name}_history.pkl'), 'rb') as h: \n                self.history = pickle.load(h)\n        except:\n            print('No model to load!')","c417d761":"#instantiate model and send to device\nResnet18 = Net(CFG.MODEL1,CFG.OUTPUT_FEATURES)\nResnet18.load_model()","f59d0965":"Resnet18.fit(TRAIN_LOADER,\n             VAL_LOADER,\n             CFG.EPOCHS,\n             CFG.BATCH_SIZE,\n             CFG.DEVICE)","2f56e240":"Resnet18.plot_loss_history()","2f04b70a":"#evaluate best model's performance on the VAL set\nprint('Best Model:')\nprint('-'*20)\ntime.sleep(0.1)\nbest_model = deepcopy(Resnet18)\nbest_model.load_model(device = CFG.DEVICE)\nbest_model.eval_model(VAL_LOADER, avg = 'binary',device = CFG.DEVICE)\n#evaluate current model's performance on the VAL set\nprint()\nprint('Current Model:')\ntime.sleep(0.1)\nprint('-'*20)\nResnet18.eval_model(VAL_LOADER,avg = 'binary', device = CFG.DEVICE)","c889b5e6":"'''\n    Get predictions on the TEST set\n'''\n\nTEST_PREDS = Resnet18.predict(TEST_LOADER, CFG.DEVICE)\npreds = [int(i) for p in TEST_PREDS  for i in list(p)]\nsub.target = preds\nsub.to_csv('submission.csv', index=False)","e7d43eea":"sub.head()","60c3a996":"TEST_PREDS","2d823933":"## Inference","6ecdb7bc":"## Train","8250738e":"# Good Luck!","2ba776bd":"# Pytorch SETI Classifier","23020c3a":"## Metadata"}}