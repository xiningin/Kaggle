{"cell_type":{"4d7405fe":"code","f8ab3b66":"code","33e1375d":"code","6b08411f":"code","0a85fe77":"code","2dd69539":"code","62f24c61":"code","d9d4ea75":"code","bfdd263d":"code","72605e72":"code","75961cda":"code","0485edfb":"code","5c67f52c":"code","dcedd364":"code","1ac9c1d2":"code","6895a70b":"code","d89e6982":"code","42a0deff":"code","de0cbce3":"code","ad7c5265":"code","bf343e44":"code","efebde30":"code","d93fb6ff":"code","fa1cb679":"code","dac568e0":"code","ec1603b6":"code","9af799aa":"code","394794a5":"code","4b9ef7d8":"code","b819d9b0":"code","5de01863":"code","e5456bcc":"code","c1b748d2":"markdown","30ec1d2b":"markdown","17f3497c":"markdown","bf115e22":"markdown","ab5b022f":"markdown","241743f8":"markdown","cff00eac":"markdown","5cae6c69":"markdown","d3c4938e":"markdown","5b270a0b":"markdown","cb33f702":"markdown","3e7bb64b":"markdown"},"source":{"4d7405fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8ab3b66":"data = pd.read_csv('\/kaggle\/input\/telecom-users-dataset\/telecom_users.csv')\ndata.head()","33e1375d":"data.info()","6b08411f":"# Convert TotalCharges to numeric type\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')","0a85fe77":"# check for imbalance in data\nprint(data['Churn'].value_counts())\nplt.pie(data['Churn'].value_counts(), autopct='%1.1f%%', labels = ['No', 'Yes']);","2dd69539":"def plot_category(feature, figsize=None):\n    yes_count = data[data['Churn']=='Yes'].groupby([feature]).size()\n    no_count = data[data['Churn']=='No'].groupby([feature]).size()\n    labels = no_count.index\n\n    x = np.arange(len(labels)) # the label locations\n    width = 0.35  # the width of the bars\n\n    if figsize:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig, ax = plt.subplots()\n    rects1 = ax.bar(x-width\/2, round(yes_count*100\/data.groupby([feature]).size(), 2), \n                    width, label='Yes')\n    rects2 = ax.bar(x+width\/2, round(no_count*100\/data.groupby([feature]).size(), 2), \n                    width, label='No')\n\n    ax.set_ylabel('Count')\n    ax.set_title('Based on %s'%feature)\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels, rotation=80)\n    ax.legend();\n\n    ax.bar_label(rects1, padding=1)\n    ax.bar_label(rects2, padding=1)\n\n    fig.tight_layout()\n    plt.show()\n    \ndef plot_numerical(feature, figsize=None):\n    # Attrition vs Age Distribution\n    fig = plt.figure(figsize=(10,6))\n\n    sns.kdeplot(data[data['Churn']=='No'][feature])\n    sns.kdeplot(data[data['Churn']=='Yes'][feature])\n\n    fig.legend(labels=['Churn No', 'Churn Yes'])\n    plt.title('Based on %s'%feature)\n    plt.show()","62f24c61":"for feature in ['tenure']:\n    plot_numerical(feature)","d9d4ea75":"for feature in ['gender', 'SeniorCitizen', 'Partner', 'Dependents']:\n    plot_category(feature)","bfdd263d":"for feature in ['PhoneService', 'MultipleLines']:\n    plot_category(feature)","72605e72":"for feature in ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n                'TechSupport', 'StreamingTV', 'StreamingMovies']:\n    plot_category(feature)","75961cda":"for feature in ['Contract', 'PaperlessBilling', 'PaymentMethod']:\n    plot_category(feature)","0485edfb":"\nfor feature in ['MonthlyCharges', 'TotalCharges']:\n    plot_numerical(feature)","5c67f52c":"categorical_features = ['gender', 'SeniorCitizen', 'Partner',\n                       'Dependents', 'PhoneService', 'MultipleLines',\n                       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n                       'PaperlessBilling', 'PaymentMethod']\nnumerical_features = ['MonthlyCharges', 'TotalCharges', 'tenure']\n\nto_drop = ['customerID', 'Unnamed: 0'] # contain all unique values or not relevant","dcedd364":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport os\nimport joblib","1ac9c1d2":"df = data.copy()\npath = '\/kaggle\/working'\nfor i, feature in enumerate(categorical_features):\n    le = LabelEncoder()\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    \n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding\/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding\/le_{}_classes.sav\".format(feature)), 'wb'))","6895a70b":"# Bivariate Analysis Correlation plot with the Numeric variables\nplt.figure(figsize=(5, 5))\nsns.heatmap(round(data[numerical_features].corr(method='spearman'), 2), \n            annot=True, mask=None, cmap='GnBu')\nplt.show()","d89e6982":"# Bivariate Analysis Correlation plot with the Categorical variables\nplt.figure(figsize=(15, 15))\nsns.heatmap(round(df[categorical_features+numerical_features].corr(method='spearman'), 2), annot=True,\n            mask=None, cmap='GnBu')\nplt.show()","42a0deff":"from statsmodels.stats.outliers_influence import variance_inflation_factor","de0cbce3":"# Calculating VIF\nvif = pd.DataFrame()\ntemp = df.dropna()\nvif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['MonthlyCharges', 'tenure']]\nvif[\"VIF\"] = [variance_inflation_factor(temp[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\nprint(vif)","ad7c5265":"missingValueFeatures = pd.DataFrame({'missing %': data.isnull().sum()*100\/len(data)})\nmissingValueFeatures[missingValueFeatures['missing %']>0]","bf343e44":"# Impute TotalCharges as per Tenure Column\nprint('Before Imputation')\nprint(data['TotalCharges'].describe())\n\ndata.sort_values('tenure', inplace=True)\n# use back fill to replace nan values\ndata['TotalCharges'].fillna(method='bfill', inplace=True)\n\nprint('\\nAfter Imputation')\nprint(data['TotalCharges'].describe())","efebde30":"df = data.copy()\npath = '\/kaggle\/working'\nfor i, feature in enumerate(categorical_features):\n    \n    le = LabelEncoder()\n    ohe = OneHotEncoder(sparse=False)\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding\/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding\/le_{}_classes.sav\".format(feature)), 'wb'))\n    # load classes\n    columns = joblib.load(\n        open(os.path.join(path, \"TextEncoding\/le_{}_classes.sav\".format(feature)), 'rb'))\n\n    if len(le.classes_)>2:\n        # perform one hot encoding\n        ohe.fit(df[[feature]])\n        # save the encoder\n        joblib.dump(ohe, \n                    open(os.path.join(path, \"TextEncoding\/ohe_{}.sav\".format(feature)), 'wb'))\n\n        # transfrom training data\n        # removing first column of encoded data to elude from dummy variable trap\n        tempData = ohe.transform(df[[feature]])[:, 1:]\n\n        # create Dataframe with columns as classes\n        tempData = pd.DataFrame(tempData, columns=columns)\n    else:\n        tempData = df[[feature]]\n    \n    # create dataframe with all the label encoded categorical features along with hot encoding\n    if i==0:\n        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n    else:\n        encodedData = pd.concat([encodedData, tempData], axis=1)","d93fb6ff":"# merge numerical features and categorical encoded features\ndf = df[numerical_features+['Churn']]\ndf = pd.concat([df, encodedData], axis=1)\ndf.info()","fa1cb679":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.svm import SVC","dac568e0":"train_data = df.copy()\nfeature_cols = [feature for feature in train_data.columns if feature not in(['Churn'])]\n\n''' Rescaling to [0,1] '''\nscaler = MinMaxScaler()\nscaler.fit(train_data[feature_cols])\ntrain_data[feature_cols] = scaler.transform(train_data[feature_cols])","ec1603b6":"X = train_data[feature_cols]\ny = train_data['Churn'].map({'No':0, 'Yes':1})\n\nvalidation_size = 0.25\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, \n                                                    random_state=4, stratify=y)","9af799aa":"model = LogisticRegression(class_weight={0:1, 1:10})\nmodel.fit(X_train, y_train)","394794a5":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","4b9ef7d8":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Churn'] * n\n    pred = ['prediction Churn'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(y, y_pred),['No','Yes'])\n\ndisplay(df_matrix)\nprint(classification_report(y, y_pred))","b819d9b0":"model = SVC(class_weight={0: 1, 1: 10})\nmodel.fit(X_train, y_train)","5de01863":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Test metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","e5456bcc":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Churn'] * n\n    pred = ['prediction Churn'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(y, y_pred),['No','Yes'])\n\ndisplay(df_matrix)\nprint(classification_report(y, y_pred))","c1b748d2":"# Label encoding categorical features for correlation","30ec1d2b":"# EDA\n* customerID - customer id\n* gender - client gender (male \/ female)\n* SeniorCitizen - is the client retired (1, 0)\n* Partner - is the client married (Yes, No)\n* tenure - how many months a person has been a client of the company\n* PhoneService - is the telephone service connected (Yes, No)\n* MultipleLines - are multiple phone lines connected (Yes, No, No phone service)\n* InternetService - client's Internet service provider (DSL, Fiber optic, No)\n* OnlineSecurity - is the online security service connected (Yes, No, No internet service)\n* OnlineBackup - is the online backup service activated (Yes, No, No internet service)\n* DeviceProtection - does the client have equipment insurance (Yes, No, No internet service)\n* TechSupport - is the technical support service connected (Yes, No, No internet service)\n* StreamingTV - is the streaming TV service connected (Yes, No, No internet service)\n* StreamingMovies - is the streaming cinema service activated (Yes, No, No internet service)\n* Contract - type of customer contract (Month-to-month, One year, Two year)\n* PaperlessBilling - whether the client uses paperless billing (Yes, No)\n* PaymentMethod - payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit * card (automatic))\n* MonthlyCharges - current monthly payment\n* TotalCharges - the total amount that the client paid for the services for the entire time\n* Churn - whether there was a churn (Yes or No)","17f3497c":"# Handling Missing Values","bf115e22":"**Observations:**\n* Tenure - TotalCharges\n* Contract - Tenure\n* MonthlyCharges - TotalCharges","ab5b022f":"**Columns that are contributing towards churn:**\n* Drop **customerID** as all values are unique\n* gender - not much\n* SeniorCitizen - yes\n* Partner - No partner\n* Dependents - No dependents\n* tenure < 20 months\n* InternetService - fibre optic & DSL.\n* Users who do not take **OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV or StreamingMovies** services have higher churn from users who do. While users with no internet service have least churn\n* Contract - Month-to-Month\n* PaperlessBilling - Yes\n* PaymentMethod - Electronic Check\n* MonthlyCharges > 60\n* TotalCharges < 2000","241743f8":"# Handling Categorical Features (Label Encoding & One Hot Encoding)","cff00eac":"# Training Model","5cae6c69":"# Model 2: SVM","d3c4938e":"As we are more interested in finding the customers who will leave and hence we will give more weights to class 1","5b270a0b":"As TotalCharges is highly correlated with tenure, we will update the null values as per the tenure","cb33f702":"# CORRELATION","3e7bb64b":"# Model 1: Logistic Regression"}}