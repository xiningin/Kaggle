{"cell_type":{"1fdc6542":"code","66c13e46":"code","38b9d375":"code","e093d535":"code","9e06a029":"code","93f437d8":"code","ba04a4f6":"code","1e86085d":"code","1712ae93":"code","5e21a317":"code","d7cde3b4":"code","b14d3657":"code","2e6072fd":"code","97feee2b":"code","852224dd":"code","79df3eb1":"code","8a341737":"code","4406823d":"code","f068d8c1":"code","d66d840d":"code","96c65d0c":"markdown","497ae24a":"markdown","50f9d53d":"markdown","1c859745":"markdown","e43155f9":"markdown","09d4d66e":"markdown","0622098b":"markdown","10e43b15":"markdown","506434d0":"markdown","a2614126":"markdown","ce2e6d23":"markdown","8bfafeb5":"markdown","1bf3a34e":"markdown","dc8bef50":"markdown","848e9c52":"markdown","8d261d13":"markdown","65b650fc":"markdown","16d04c0f":"markdown","90313733":"markdown","c2937963":"markdown","7bc244ee":"markdown","38928e77":"markdown","7d55529b":"markdown","78e7e452":"markdown","0f11a116":"markdown","77227d85":"markdown","452d6186":"markdown"},"source":{"1fdc6542":"#Loading of Dataset and required Libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n\ndt= pd.read_csv(\n    \"\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv\",\n    encoding=\"utf_8\")\n\nimport warnings  \nwarnings.filterwarnings('ignore')","66c13e46":"#to check few rows\ndt.head()","38b9d375":"#to check the number of column & rows\nprint(\"dimensions are : \", dt.shape)","e093d535":"#to check the columns names, data type and null values (if any)\n\nprint(dt.info())","9e06a029":"print(dt.isna().sum())","93f437d8":"print(\"Before drop, total rows are: \", dt.shape[0])\n\n#drop the null values\ndt.dropna(inplace=True)\n\nprint(\"After drop, total rows are: \", dt.shape[0])\n\nprint(dt.isna().sum())","ba04a4f6":"#rename the columns\ndt = dt.rename(columns={'Order Number': 'Order_Number',\"Order Status\":\"Order_Status\", \"Book Name\":\"Book_Name\",\"Order Date & Time\":\"Date_Time\",\"Payment Method\":\"Payment_Method\",\"Total items\":\"Total_Items\",\"Total weight (grams)\":\"Weight(g)\"})\nprint(\"After rename, column names are: \", \"\\n\", \"\\n\" , dt.columns)","1e86085d":"#change the type of \"Date_Time\" columns\ndt['Date_Time'] = pd.to_datetime(dt['Date_Time'])\nprint(dt.info())\n\n#Date (Days, Week) and Time from Date Column\ndt['Years'] = dt[\"Date_Time\"].dt.year\ndt['Months_Name'] = dt[\"Date_Time\"].dt.month_name()\ndt['Months'] = dt[\"Date_Time\"].dt.month\ndt['Days'] = dt[\"Date_Time\"].dt.day\ndt['DaysName'] = dt[\"Date_Time\"].dt.day_name()\ndt['Weeks'] = dt[\"Date_Time\"].dt.week\ndt['Date'] = dt[\"Date_Time\"].dt.date\ndt[\"Month_Year\"]=dt[\"Months_Name\"] + \"-\" + dt[\"Years\"].astype(str)\n#Confirm Extracted Columns","1712ae93":"\n\n#to separate, from multiple to single book title per line\n\n#print('No of rows BEFORE splitting : ',dt.shape[0])\n\nscol = dt['Book_Name'].str.split('\/', expand=True).stack()\nscol.index = scol.index.droplevel(-1) \nscol.name = 'Book_Name' \ndt = dt.drop(columns='Book_Name').join(scol)\n\n#print('No of rows AFTER splitting : ',dt.shape[0])\n\n#manually rename some urdu books names to english\ndt['Book_Name'] = dt['Book_Name'].replace('\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba','Internet Sy Pysy Kamaen')\ndt['Book_Name'] = dt['Book_Name'].replace('\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba\u061f- \u0645\u0633\u062a\u062d\u0642\u06cc\u0646 \u0632\u06a9\u0648\u0627\u0629','Internet Sy Pysy Kamaen')\ndt['Book_Name'] = dt['Book_Name'].replace('\u0688\u06cc\u0679\u0627 \u0633\u0627\u0626\u0646\u0633','Data Science')\ndt['Book_Name'] = dt['Book_Name'].replace('\u0688\u06cc\u0679\u0627 \u0633\u0627\u0626\u0646\u0633 \u06d4 \u0627\u06cc\u06a9 \u062a\u0639\u0627\u0631\u0641','Data Science')\ndt['Book_Name'] = dt['Book_Name'].replace('\u0645\u0634\u06cc\u0646 \u0644\u0631\u0646\u0646\u06af','Machine Learning')\ndt['Book_Name'] = dt['Book_Name'].replace('(C++) ++\u0633\u06cc','(C++)')\ndt['Book_Name'] = dt['Book_Name'].replace(\"\u0627\u06cc\u06a9 \u062a\u06be\u0627 \u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645\",'Ak Tha Algorithm')\n\n\n#extracting top 20 books for fuzzywuzzy\ntop_bks=dt[\"Book_Name\"].value_counts().head(20).reset_index()\ntop_bks.columns=['Book_Name','Sold_Qty']\nall_bks = dt[\"Book_Name\"].unique()\n\n#renaming the books name to close matching using fuzzywuzzy\nfrom fuzzywuzzy import process\n\nfor bks in top_bks['Book_Name']:\n    matches = process.extract(bks, all_bks , limit = len(all_bks))\n    for potential_match in matches:\n        if potential_match[1] > 90:\n                dt.loc[dt['Book_Name'] == potential_match[0],\"Book_Name\"] = bks\n    \ndt.reset_index(drop=True, inplace=True)\nprint(\"Top 10 unique Books are: \\n\",dt[\"Book_Name\"].value_counts().head(10))","5e21a317":"dt['City'] = dt['City'].replace(['karachi','KARACHI'],'Karachi')\ndt['City'] = dt['City'].replace('FSD','Faisalabad')\ndt['City'] = dt['City'].replace(['lahore','LAHORE'],'Lahore')\n\n#extracting top 20 cities for fuzzywuzzy\n\nfuzz_top_City=dt[\"City\"].value_counts().head(20).reset_index()\nfuzz_top_City.columns=['City','Sold_Qty']\nfuzz_all_City = dt[\"City\"].unique()\n\n#removing the typo mistake in books name\n\nfrom fuzzywuzzy import process\nfor city in fuzz_top_City['City']:\n    matches = process.extract(city, fuzz_all_City , limit = len(fuzz_all_City))\n    for potential_match in matches:\n        if potential_match[1] > 90:\n                dt.loc[dt['City'] == potential_match[0],\"City\"] = city\n                \nprint(\"Top 20 Cities are: \\n\",dt[\"City\"].value_counts().head(20))","d7cde3b4":"dt['Payment_Method'] = dt['Payment_Method'].replace('Cash on Delivery (COD)','Cash on delivery')\nprint(\"Unique Payment Methods are: \\n\",dt['Payment_Method'].unique())","b14d3657":"fig, ax = plt.subplots()\nax=sns.countplot(x=\"Order_Status\",data=dt)\nfig.set_size_inches(18,9)\nax.set_title('Total Orders for Different Order Status',fontsize=20)\nax.set_xlabel(\"Order Status\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \n#plt.xticks(rotation=90)\nplt.show()","2e6072fd":"fig, ax = plt.subplots()\nax=sns.countplot(x=\"Payment_Method\",data=dt,hue=\"Order_Status\")\nfig.set_size_inches(18,9)\nax.set_title('Relation between Payment Method & Order Status',fontsize=20)\nax.set_xlabel(\"Payment Method(s)\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \n#plt.xticks(rotation=90)\nplt.show()","97feee2b":"fig, ax = plt.subplots()\nax=sns.countplot(x=\"Years\",data=dt,hue=\"Order_Status\")\nfig.set_size_inches(18,9)\nax.set_title('Yearly Orders Status (Frequency)',fontsize=20)\nax.set_xlabel(\"Years\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \n#plt.xticks(rotation=90)\nplt.show()","852224dd":"fig, ax = plt.subplots()\n\nMonths = ['January', 'February', 'March','April', 'May', 'June', 'July', 'August', 'September','October', 'November', 'December']\nax=sns.countplot(x=\"Months_Name\",data=dt,hue=\"Order_Status\", order=Months)\nfig.set_size_inches(18,9)\n#plt.rcParams[\"axes.labelsize\"] = 25\nax.set_title('Monthly Orders Status (Frequency)',fontsize=20)\nax.set_xlabel(\"Months\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \n#plt.xticks(rotation=90)\nplt.show()","79df3eb1":"\nfig, ax = plt.subplots()\nax=sns.countplot(x=\"Month_Year\",data=dt,hue=\"Order_Status\" )\nfig.set_size_inches(18,9)\nax.set_title('Monthly Orders Status (Frequency)',fontsize=20)\nax.set_xlabel(\"Months\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \nplt.xticks(rotation=90)\nplt.show()","8a341737":"fig, ax = plt.subplots()\nax=sns.countplot(x=\"Days\",data=dt,hue=\"Order_Status\")\nfig.set_size_inches(18,9)\nax.set_title('Day wise Orders Status (Frequency)',fontsize=20)\nax.set_xlabel(\"Days of Month\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \nplt.xticks(rotation=90)\nplt.show()","4406823d":"fig, ax = plt.subplots()\norder=['Monday','Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday','Sunday']\nax=sns.countplot(x=\"DaysName\",data=dt,hue=\"Order_Status\", order=order)\nfig.set_size_inches(18,9)\nax.set_title('Orders Status on each day of week',fontsize=20)\nax.set_xlabel(\"Days of the Week\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \nplt.xticks(rotation=90)\nplt.show()","f068d8c1":"cty = dt['City'].value_counts().iloc[:20]\n#bks = dt['Book_Name'].value_counts().iloc[:10]\n\n#tcb=top 10 cities and top 10 books\n\n\n#tcb=tcb[tcb[\"Book_Name\"].isin(bks.index)]\ntcb=dt[dt[\"City\"].isin(cty.index)]\n\ntcb=dt.groupby([\"City\",\"Order_Status\"])[\"Order_Number\"].count().reset_index().sort_values(\"Order_Number\", ascending=False)\n\n#to add another column for Province against each city\nprov = {'Karachi': \"Sindh\", 'Lahore': \"Punjab\", 'Islamabad': \"Islamabad\", 'Rawalpindi': \"Punjab\", 'Faisalabad': \"Punjab\",'Peshawar': \"KPK\", 'Multan': \"Punjab\", 'Gujranwala': \"Punjab\", 'Sialkot': \"Punjab\", 'Hyderabad': \"Sindh\",'Quetta':\"Baluchistan\", 'Bahawalpur':\"Punjab\", 'Sargodha':\"Punjab\", 'Abbottabad': \"KPK\", 'Sahiwal':\"Punjab\",'Okara':\"Punjab\",'Sheikhupura':\"Punjab\",'Gujrat':\"Punjab\", 'Sukkur':\"Sindh\", 'Chakwal':\"Punjab\"}\ntcb[\"Province\"] = tcb[\"City\"].map(prov)\ntcb.columns=['City','Order_Status','Total_Order','Province']\n\nx=tcb.groupby([\"Province\",\"Order_Status\"])[\"Total_Order\"].sum().reset_index().sort_values(\"Total_Order\", ascending=False)\n\nfig, ax = plt.subplots()\nax=sns.barplot(x=\"Province\",y=\"Total_Order\",data=x,hue=\"Order_Status\" , ci=None)\nfig.set_size_inches(18,9)\nax.set_title('Province wise Order Status',fontsize=20)\nax.set_xlabel(\"Province\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \nplt.xticks(rotation=90)\nplt.show()","d66d840d":"#cty = dt['City'].value_counts().iloc[:20]\nbks = dt['Book_Name'].value_counts().iloc[:20]\n\n#tcb=top 10 cities and top 10 books\ntcb=dt.groupby([\"Book_Name\",\"Order_Status\"])[\"Order_Number\"].count().reset_index().sort_values(\"Order_Number\", ascending=False)\n\ntcb=tcb[tcb[\"Book_Name\"].isin(bks.index)]\n#tcb=tcb[tcb[\"City\"].isin(cty.index)]\n\nfig, ax = plt.subplots()\nax=sns.barplot(x=\"Book_Name\",y=\"Order_Number\",data=tcb,hue=\"Order_Status\" )\nfig.set_size_inches(18,9)\nax.set_title('Top Books wise Status (Frequency)',fontsize=20)\nax.set_xlabel(\"Top Book Title(s)\",fontsize=18)\nax.set_ylabel(\"Number of Order(s)\",fontsize=18) \nplt.xticks(rotation=90)\nplt.show()","96c65d0c":"**Data shows that January 2021 has the highest sale. Followed by Dec 20 and Aug 20**","497ae24a":"so data contains 19239 rows and 8 columns","50f9d53d":"The \"City\" column contains many typos. lets fix it.","1c859745":"**\"Date_Time\" columns has \"object\" type, we will change it to datetime64 type. also Extract the Year, Month, Days..etc,**","e43155f9":"# Loading data","09d4d66e":"\"Non-Null Count\" of few columns shows the presence of null values","0622098b":"**Data shows that maximum orders are completed and a fewer were returned or cancelled**","10e43b15":"Three columns contains the missing values. we will drop these.","506434d0":"**Data is clear. we are ready to visualize it.**","a2614126":"# **Handling Inconsistent Data**","ce2e6d23":"**in this graph we can see top 20 books that were ordered. Please note that for the ease of understanding data is based on top 20 books**","8bfafeb5":"# **Thanks for viewing my notebook, you are welcome to give any comments\/suggestions to further improve my work.**","1bf3a34e":"**Creating new dataset**","dc8bef50":"\"Book_Name\" column contains more than one book name. lets split it.","848e9c52":"**This graph shows the day wise total orders. It doesn\u2019t looks any relation between day of month and Order Status.**","8d261d13":"now data doesnt contains any missing values","65b650fc":"**Rename the columns to more appropriate**","16d04c0f":"# Basic Data Exploration","90313733":"**Data shows that highest no of orders are process in January. It is important to note that in this graph data is grouped for all the years. so January includes data from Jan 2020 and Jan 20221, next graph will further elaborate.**","c2937963":"**Handling missing values.**","7bc244ee":"**Data shows that maximum order were received from Punjab followed by Sindh, Islamabad, KPK and Baluchistan\nPlease note that for the ease of understanding data is taken from top 20 cities.**","38928e77":"# Data cleaning","7d55529b":"**Task Details**\nWe like to find out the impact of order size (items numbers), order date and time, payment method on order status.\n\n**Expected Submission**\nTell us what's the co-relation between\n\nreturn orders and any other given variable\ncompleted orders and any other given variables\ncancelled orders and any other given variables\nIt would help if you can break it down to cities as well\n\n**Evaluation**\nWe are looking for easy to understand graphs and clear insights backed by data","78e7e452":"**Data shows an interesting relationship that if payment mode is COD, the order is likely to be completed**","0f11a116":"**This graph shows the correlation between total orders  and days of the week. Weekend (Saturday\/Sunday) has the maximum orders.**","77227d85":"**Data shows that Guftugu did top sale in 2020. we can\u2019t say with guarantee, as only last 3 month from 2019 and 1st month from 2021 is included in data. which for 2020, whole year is included.**","452d6186":"Removing typos error in \"Payment Method\" Column"}}