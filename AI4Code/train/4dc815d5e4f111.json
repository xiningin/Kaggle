{"cell_type":{"e798fbc2":"code","053c88ad":"code","d344a8de":"code","b12c4148":"code","80de6934":"code","7fd69b6f":"code","0b468f98":"code","70108fde":"code","f8413401":"code","e977cfc4":"code","9f57a065":"code","85dae91b":"code","70796c70":"code","8a4a2928":"code","fea7a752":"code","e87b1bea":"code","7e8de180":"code","f37a2de9":"code","8553aca8":"code","d809e354":"code","3fc5bc47":"code","59d4a42d":"code","73b4dc9b":"code","d50c9b03":"code","c0a60e71":"code","c25ae418":"code","907de5d3":"code","8e197097":"code","11aae330":"code","492e6437":"code","8d7eb0d7":"code","3fd5a920":"code","29678283":"code","336989a9":"code","dff51fdb":"code","b9c406b4":"code","7f400d6b":"code","24db1849":"code","73713366":"code","6e5c6889":"code","feee34de":"code","fe93baab":"code","16e63af1":"code","aebdc932":"code","8dbcc75c":"code","eeb8f2d5":"code","8e1528ce":"code","baf8de23":"code","7bd0b006":"code","95d70b98":"code","cd30014b":"code","bf26ed9e":"code","9151b43f":"code","1b542135":"code","81ae15e0":"code","ea285a58":"code","127e6632":"code","543a637a":"code","ba6c1c73":"code","885078a7":"code","a158d0b2":"code","ffb1a34e":"code","2a15e0dc":"markdown","597f2d52":"markdown","a1aa0b73":"markdown"},"source":{"e798fbc2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas import DataFrame\nimport re\nimport matplotlib.pyplot as plt\ntry:\n    import seaborn as sns\nexcept:\n    !pip install seaborn\n    import seaborn as sns\n%matplotlib inline","053c88ad":"sns.set_style('whitegrid')","d344a8de":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# Any results you write to the current directory are saved as output.","b12c4148":"train_file_path = '..\/input\/GiveMeSomeCredit\/cs-training.csv'\ntest_file_path = '..\/input\/GiveMeSomeCredit\/cs-test.csv'\ntrain_data = pd.read_csv(train_file_path)\ntest_data = pd.read_csv(test_file_path)","80de6934":"train_data.head()","7fd69b6f":"train_data.columns = train_data.columns.str.replace('-', '_').str.replace(': ', '')","0b468f98":"train_data.columns","70108fde":"def format_vertical_headers(df):\n    \"\"\"Display a dataframe with vertical column headers\"\"\"\n    styles = [dict(selector=\"th\", props=[('width', '40px')]),\n              dict(selector=\"th.col_heading\",\n                   props=[(\"writing-mode\", \"vertical-rl\"),\n                          ('transform', 'rotateZ(180deg)'), \n                          ('height', '290px'),\n                          ('vertical-align', 'top')])]\n    return (df.fillna('').style.set_table_styles(styles))","f8413401":"format_vertical_headers(train_data.head())","e977cfc4":"test_data.columns","9f57a065":"test_data.columns = test_data.columns.str.replace('-', '_').str.replace(': ', '')\ntest_data.columns","85dae91b":"format_vertical_headers(test_data.head())","70796c70":"print(train_data.info())\nprint(\"\\n=======================================\\n\")\nprint(test_data.info())","8a4a2928":"format_vertical_headers(train_data.describe())","fea7a752":"format_vertical_headers(test_data.describe())","e87b1bea":"#define function to draw boxplots of train and test data\ndef draw_boxplots_tran_test(df_train, df_test, column):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n    sns.boxplot(x=train_data[column], ax=ax1)\n    ax1.set_title(\"Train\", fontsize=18)\n    sns.boxplot(x=test_data[column], color=\"green\", ax=ax2)\n    ax2.set_title(\"Test\", fontsize=18)\n    plt.show()\n    return ","7e8de180":"#let's visualize data for each data column","f37a2de9":"draw_boxplots_tran_test(train_data,test_data,'RevolvingUtilizationOfUnsecuredLines')","8553aca8":"draw_boxplots_tran_test(train_data,test_data,'NumberOfTime30_59DaysPastDueNotWorse')","d809e354":"draw_boxplots_tran_test(train_data,test_data,'DebtRatio')","3fc5bc47":"draw_boxplots_tran_test(train_data,test_data,'MonthlyIncome')","59d4a42d":"fig = plt.figure(figsize=(8, 5))\nax = fig.add_subplot(111)\n\ntrain_data[(train_data.MonthlyIncome.notnull())].MonthlyIncome.hist(bins=100, ax=ax)\nplt.xlabel('MonthlyIncome')\nplt.ylabel('Numper of people')\nplt.title('Histogram of MonthlyIncome')","73b4dc9b":"draw_boxplots_tran_test(train_data,test_data,'NumberOfOpenCreditLinesAndLoans')","d50c9b03":"draw_boxplots_tran_test(train_data,test_data,'NumberOfTimes90DaysLate')","c0a60e71":"draw_boxplots_tran_test(train_data,test_data,'NumberRealEstateLoansOrLines')","c25ae418":"draw_boxplots_tran_test(train_data,test_data,'NumberOfTime60_89DaysPastDueNotWorse')","907de5d3":"draw_boxplots_tran_test(train_data,test_data,'NumberOfDependents')","8e197097":"#the number of people who returned the credit\nsns.countplot(x='SeriousDlqin2yrs',data=train_data)","11aae330":"#Most peoplt did not have serious due diligence in 2 years","492e6437":"def draw_heatmaps(df_train,df_test):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,8))\n    sns.heatmap(df_train.isnull(), cmap='coolwarm', yticklabels=False, cbar=False, ax=ax1)\n    ax1.set_title(\"Train\", fontsize=18)\n    sns.heatmap(df_test.isnull(), cmap='coolwarm', yticklabels=False, cbar=False, ax=ax2)\n    ax1.set_title(\"Test\", fontsize=18)\n    return","8d7eb0d7":"#lets look at the number of missing data using a heatmap\ndraw_heatmaps(train_data,test_data)","3fd5a920":"train_data = train_data[train_data.RevolvingUtilizationOfUnsecuredLines < 15000]\ntest_data = test_data[test_data.RevolvingUtilizationOfUnsecuredLines < 15000]\ndraw_boxplots_tran_test(train_data,test_data,'RevolvingUtilizationOfUnsecuredLines')","29678283":"train_data = train_data[(train_data.age >= 40) & (train_data.age < 65)]\ntest_data = test_data[(test_data.age >= 40) & (test_data.age < 65)]\ndraw_boxplots_tran_test(train_data,test_data,'age')","336989a9":"train_data = train_data[train_data.NumberOfTime30_59DaysPastDueNotWorse < 18]\ntest_data = test_data[test_data.NumberOfTime30_59DaysPastDueNotWorse < 18]\ndraw_boxplots_tran_test(train_data,test_data,'NumberOfTime30_59DaysPastDueNotWorse')","dff51fdb":"train_data = train_data[train_data.DebtRatio < 7500]\ntest_data = test_data[test_data.DebtRatio < 7500]\ndraw_boxplots_tran_test(train_data,test_data,'DebtRatio')","b9c406b4":"train_data = train_data[train_data.DebtRatio < 7500]\ntest_data = test_data[test_data.DebtRatio < 7500]\ndraw_boxplots_tran_test(train_data,test_data,'DebtRatio')","7f400d6b":"train_data = train_data[train_data.MonthlyIncome < 10000]\ntest_data = test_data[test_data.MonthlyIncome < 10000]\ndraw_boxplots_tran_test(train_data,test_data,'MonthlyIncome')","24db1849":"train_data = train_data[train_data.NumberOfOpenCreditLinesAndLoans < 20]\ntest_data = test_data[test_data.NumberOfOpenCreditLinesAndLoans < 20]\ndraw_boxplots_tran_test(train_data,test_data,'NumberOfOpenCreditLinesAndLoans')","73713366":"train_data = train_data[train_data.NumberOfTimes90DaysLate < 20]\ntest_data = test_data[test_data.NumberOfTimes90DaysLate < 20]\ndraw_boxplots_tran_test(train_data,test_data,'NumberOfTimes90DaysLate')","6e5c6889":"train_data = train_data[train_data.NumberRealEstateLoansOrLines < 5]\ntest_data = test_data[test_data.NumberRealEstateLoansOrLines < 5]\ndraw_boxplots_tran_test(train_data,test_data,'NumberRealEstateLoansOrLines')","feee34de":"train_data = train_data[train_data.NumberOfTime60_89DaysPastDueNotWorse < 20]\ntest_data = test_data[test_data.NumberOfTime60_89DaysPastDueNotWorse < 20]\ndraw_boxplots_tran_test(train_data,test_data,'NumberOfTime60_89DaysPastDueNotWorse')","fe93baab":"train_data = train_data[train_data.NumberOfDependents < 10]\ntest_data = test_data[test_data.NumberOfDependents < 10]\ndraw_boxplots_tran_test(train_data,test_data,'NumberOfDependents')","16e63af1":"#let's see how data look after removing outliners\nformat_vertical_headers(train_data.describe())","aebdc932":"format_vertical_headers(test_data.describe())","8dbcc75c":"draw_heatmaps(train_data,test_data)","eeb8f2d5":"#specify the target variable\ntrain_y = train_data.SeriousDlqin2yrs\ntest_y = test_data.SeriousDlqin2yrs","8e1528ce":"#create list of features\nfeature_names = ['RevolvingUtilizationOfUnsecuredLines', 'age',\n       'NumberOfTime30_59DaysPastDueNotWorse', 'DebtRatio',\n       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n       'NumberRealEstateLoansOrLines', 'NumberOfTime60_89DaysPastDueNotWorse']\n#create data corresponding to the features\ntrain_X = train_data[feature_names]\ntest_X = test_data[feature_names]","baf8de23":"#split train data into train and test set. I am not sure if this is necessary, \n#because we have a train test separately, but I am not sure why my attempts to use it fail.\n#So I am just trying to work by example form other notebooks\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_X, train_y, test_size = 0.3, random_state = 0)","7bd0b006":"from sklearn.linear_model import LogisticRegression\n#specify the model, set any numeric valye as parameter to ensure reproducibility \ncredit_model = LogisticRegression(random_state=1)\n\n#fit the model\ncredit_model.fit(x_train,y_train)","95d70b98":"#make predictions\npredictions_train = credit_model.predict(x_train)\ny_pred = credit_model.predict(x_test)","cd30014b":"#this section investigates resulting data, I had to do this because confusion matrix was throwing errors\nprint(predictions_train)\nprint(y_pred)\nprint(y_pred.shape)\nprint(y_pred.dtype)\nprint(y_test.shape)\nprint(y_test.dtype)","bf26ed9e":"#conver float to int\ny_predi = y_pred.astype(int)","9151b43f":"#create confuson matrics in text view\nfrom sklearn.metrics import confusion_matrix\ntn, fp, fn, tp = confusion_matrix( y_test,y_predi).ravel()\n(tn, fp, fn, tp)","1b542135":"#create consusion matrix and plot\nimport scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test,y_predi,figsize=(6,6))","81ae15e0":"from sklearn import metrics\n#calculate ROC\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_predi)\nprint(fpr)\nprint(fpr.shape)\nprint(tpr)\nprint(tpr.shape)\nprint(thresholds)","ea285a58":"from sklearn import metrics\n#calculate AUC\nroc_auc = metrics.auc(fpr, tpr)\nprint(roc_auc)","127e6632":"# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","543a637a":"#calculate F1 score\nfrom sklearn.metrics import f1_score\nf1_score(y_test, y_predi) #do we need to use average=None as the third param?","ba6c1c73":"#accuracy score\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_predi) #do we need to use normalize=False as the third param?","885078a7":"#precision\nfrom sklearn.metrics import precision_score\nprecision_score(y_test, y_predi)","a158d0b2":"#recall\nfrom sklearn.metrics import recall_score\nrecall_score(y_test, y_predi)","ffb1a34e":"#cost-sensitive accuracy\nfp_cost = 1\nfn_cost = 0\ncost_sensitive_accuracy = (tp + tn) \/ (tp + tn + fp*fp_cost + fn*fn_cost)\nprint(cost_sensitive_accuracy)","2a15e0dc":"**DATA EXPLORATION**","597f2d52":"**DATA CLEANING**","a1aa0b73":"**Remove Outliners**"}}