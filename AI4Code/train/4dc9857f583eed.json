{"cell_type":{"aa16a7f9":"code","8ae9b92b":"code","a68ed1d8":"code","c4f42eec":"code","4ea4b102":"code","70042993":"code","36fcacff":"code","7befab77":"code","38516af2":"code","78567e20":"code","0b5da66f":"code","79211bef":"markdown","c7f2b00d":"markdown","cbe04f3c":"markdown","674c95a1":"markdown"},"source":{"aa16a7f9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nimport math\nimport cv2\n\ntf.logging.set_verbosity(tf.logging.WARN)","8ae9b92b":"IMG_SIZE = 28\ndf = pd.read_csv('..\/input\/train.csv') #df.head()\nlabels = df['label'].values\nfeatures = df.drop(['label'], axis=1).values.reshape((-1, IMG_SIZE, IMG_SIZE)) \/ 255.","a68ed1d8":"df['label'].plot.hist(bins=10);","c4f42eec":"def train_generator(features, imgs_per_batch=10):\n    while True:\n        for i in range(0, len(features), imgs_per_batch):\n            yield features[i:i+imgs_per_batch], features[i:i+imgs_per_batch]\n            \ndef steps_per_epoch(epoch_size, batch_size):\n    return int(math.ceil(epoch_size\/batch_size))\n\ndef make_cae(latent_size, normalize_latent=False):\n    encoder = tf.keras.models.Sequential()\n    encoder.add(tf.keras.layers.InputLayer((IMG_SIZE,IMG_SIZE,)))\n    encoder.add(tf.keras.layers.Reshape((IMG_SIZE,IMG_SIZE,1)))\n    encoder.add(tf.keras.layers.ZeroPadding2D(padding=2))\n    for n in [32,64,128,128,128]:\n        encoder.add(tf.keras.layers.Conv2D(n, kernel_size=3, padding='same'))\n        encoder.add(tf.keras.layers.Activation('relu'))\n        encoder.add(tf.keras.layers.BatchNormalization())\n        encoder.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n    encoder.add(tf.keras.layers.Flatten())\n    encoder.add(tf.keras.layers.Dense(latent_size))\n    encoder.add(tf.keras.layers.Activation('relu'))\n    if (normalize_latent):\n        encoder.add(tf.keras.layers.BatchNormalization())\n    encoder.summary()\n\n    decoder = tf.keras.models.Sequential()\n    decoder.add(tf.keras.layers.InputLayer((latent_size,)))\n    decoder.add(tf.keras.layers.Dense(128))\n    decoder.add(tf.keras.layers.Reshape((1,1,128)))\n    for n in [128,128,64,32,1]:\n        decoder.add(tf.keras.layers.UpSampling2D(size=2))\n        decoder.add(tf.keras.layers.Conv2D(n, kernel_size=3, padding='same'))\n        decoder.add(tf.keras.layers.Activation('relu'))\n        decoder.add(tf.keras.layers.BatchNormalization())\n    decoder.add(tf.keras.layers.Conv2D(1, kernel_size=3, padding='same'))\n    decoder.add(tf.keras.layers.Activation('sigmoid'))\n    decoder.add(tf.keras.layers.Cropping2D(cropping=2))\n    decoder.add(tf.keras.layers.Reshape((IMG_SIZE,IMG_SIZE,)))\n    decoder.summary()\n\n    cae = tf.keras.models.Sequential([tf.keras.layers.InputLayer((IMG_SIZE,IMG_SIZE,)), encoder, decoder])\n    cae.summary()\n    return encoder, decoder, cae","4ea4b102":"LATENT_SPACE_SIZE=10\nencoder, decoder, cae = make_cae(LATENT_SPACE_SIZE, True) # normlize lantent space to easily sweep through the space for visualization ","70042993":"cae.compile(optimizer='adam', loss='mse', metrics=[])\nIMGS_PER_BATCH = 50\nEPOCHS=50\ncae.fit_generator(train_generator(features, IMGS_PER_BATCH),\n                             epochs=EPOCHS,\n                             steps_per_epoch=steps_per_epoch(len(features), IMGS_PER_BATCH),\n                             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss',\n                                                                         min_delta=0,\n                                                                         patience=2,\n                                                                         verbose=0, \n                                                                         mode='auto')\n                                       ],\n                             verbose=2)","36fcacff":"def predict_generator(features, imgs_per_batch=10):\n    while True:\n        for i in range(0, len(features), imgs_per_batch):\n            yield features[i:i+imgs_per_batch]\n\npredicted = cae.predict_generator(predict_generator(features[:10]), steps=steps_per_epoch(len(features[:10]), IMGS_PER_BATCH))\n\nplt.subplots(figsize=(30,5))\nfor i in range(10):\n    plt.subplot(2,10, 1+i)\n    plt.imshow(features[i], 'gray', vmin=0, vmax=1)\n    plt.subplot(2,10, 11+i)\n    plt.imshow(predicted[i], 'gray', vmin=0, vmax=1)","7befab77":"generated = decoder.predict_on_batch(np.eye(LATENT_SPACE_SIZE)*-0.5)\n    \nplt.subplots(figsize=(LATENT_SPACE_SIZE,21))\nfor i, x in enumerate(np.arange(-1., 1.1, 0.1)):\n    generated = decoder.predict_on_batch(np.eye(LATENT_SPACE_SIZE)*x)\n    for j, g in enumerate(generated):\n        plt.subplot(21,LATENT_SPACE_SIZE, 1+LATENT_SPACE_SIZE*i+j)\n        plt.imshow(g, 'gray', vmin=0, vmax=1)","38516af2":"## Unfortunately, TSNE is too slow.\n#encoded = encoder.predict(features)\n#encoded_tsne = TSNE(n_components=2).fit_transform(encoded)\n#encoded_tsne_t = encoded_tsne.T\n#plt.scatter(encoded_tsne_t[0], encoded_tsne_t[1], c=y)","78567e20":"start, end = encoder.predict_on_batch(features[:2])\nsteps = 20\ndelta = (end-start)\/steps\ngenerated = decoder.predict_on_batch(np.array([start+i*delta for i in range(steps+1)]))\n    \nplt.subplots(figsize=(steps,1))\nfor i, g in enumerate(generated):\n    plt.subplot(1,steps+1, 1+i)\n    plt.imshow(g, 'gray', vmin=0, vmax=1)","0b5da66f":"encoder, decoder, cae = make_cae(2, False)\ncae.compile(optimizer='adam', loss='mse', metrics=[])\n\nepochs=50\ncae.fit(features, features, \n        epochs=epochs,\n        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss',\n                                                    min_delta=0,\n                                                    patience=2,\n                                                    verbose=0, \n                                                    mode='auto')\n                                       ],\n        verbose=2)\n\nencoded = encoder.predict(features)\nencoded_tranpose = encoded.T\nplt.scatter(encoded_tranpose[0], encoded_tranpose[1], c=labels);\n\nplt.figure(figsize=(10,2))\nX_pred = cae.predict(features[:10])\nfor i in range(10):\n        plt.subplot(2,10,i+1)\n        plt.imshow(features[i], cmap='gray')\n        plt.axis('off')\nfor i in range(10):\n        plt.subplot(2,10,10+i+1)\n        plt.imshow(X_pred[i], cmap='gray')\n        plt.axis('off')","79211bef":"### Interpolating Latent Space","c7f2b00d":"## CAE with 2 latent space","cbe04f3c":"## CAE with size 10 latent space","674c95a1":"### Visualizing Latent Space\n\nGenerally speaking, latent space in CAE is meaningless and is not smooth.  There are gaps in the space where the generated images are random. Variational autoencoder can solve the issue."}}