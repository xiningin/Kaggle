{"cell_type":{"4719ac5e":"code","c7dd97d7":"code","96bcd564":"code","64fd3d19":"code","4f41bf0c":"code","ad94ab79":"code","cbda5173":"code","73d6f130":"code","d876c38d":"code","1847b78b":"code","9725270d":"markdown"},"source":{"4719ac5e":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport os\nfrom torchvision import datasets, transforms","c7dd97d7":"data_dir = r'\/kaggle\/input\/flowers-recognition\/flowers\/flowers'\nos.listdir(data_dir)","96bcd564":"flower_classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']","64fd3d19":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import DataLoader\n\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ntransform = transforms.Compose([transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,))\n                               ])\ndataset = datasets.ImageFolder(data_dir, transform = transform)\nnum = len(dataset)\ntest_size = 0.3\nindices = list(range(num))\nnp.random.shuffle(indices)\nsplit = int(np.floor(test_size * num))\ntrain_idx, test_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\ntest_sampler = SubsetRandomSampler(test_idx)\n\ntrain_loader = DataLoader(dataset, batch_size = 32, sampler = train_sampler)\ntest_loader = DataLoader(dataset, batch_size = 32, sampler = test_sampler)","4f41bf0c":"images, labels = next(iter(train_loader))\n# any 10 random images\nfig, ax = plt.subplots(5, 2)\nfig.set_size_inches(15, 20)\nidx = 0\nfor i in range(5):\n    for j in range(2):\n#         Convert to numpy for display\n        image = images[idx].numpy()\n#       Denormalize for display\n        image = image \/ 2 + 0.5\n        ax[i, j].set_axis_off()\n        ax[i, j].imshow(image.transpose(1,2,0))\n        ax[i, j].set_title('Flower: ' + flower_classes[labels[idx]])\n        idx = idx + 1","ad94ab79":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        #         ->224x224x3\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n        #         ->112x112x32\n        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n        #         ->56x56x64\n        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n        #         ->28x28x128\n        self.conv4 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1)\n        #         ->14x14x256\n        self.conv5 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 1)\n        #         ->7x7x512\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.fc1 = nn.Linear(7 * 7 * 512, 500)\n        self.fc2 = nn.Linear(500, 5)\n        self.dropout = nn.Dropout(p = 0.25)\n        \n    def forward(self, X):\n        X = self.pool(F.relu(self.conv1(X)))\n        X = self.pool(F.relu(self.conv2(X)))\n        X = self.pool(F.relu(self.conv3(X)))\n        X = self.pool(F.relu(self.conv4(X)))\n        X = self.pool(F.relu(self.conv5(X)))\n\n        X = X.view(-1, 7 * 7* 512)\n        X = self.dropout(X)\n        X = F.relu(self.fc1(X))\n        X = self.dropout(X)\n        X = self.fc2(X)\n        return X","cbda5173":"model = Classifier()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nmodel.to(device)","73d6f130":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)","d876c38d":"n_epochs = 20\nfor epoch in range(1, n_epochs + 1):\n    train_loss = 0\n    for X_Train, Y_Train in train_loader:\n        X_Train, Y_Train = X_Train.to(device), Y_Train.to(device)\n        out = model(X_Train)\n        \n        optimizer.zero_grad()\n        loss = criterion(out, Y_Train)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * X_Train.shape[0]\n    train_loss = train_loss\/len(train_loader.sampler)\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n        epoch, train_loss))","1847b78b":"batch_size = 32\ntest_loss = 0\nclass_correct = list(0. for i in range(5))\nclass_total = list(0. for i in range(5))\nmodel.eval()\nfor X_Test, Y_Test in test_loader:\n    X_Test, Y_Test = X_Test.to(device), Y_Test.to(device)\n    out = model(X_Test)\n    test_loss += criterion(out, Y_Test).item() * X_Test.shape[0]\n    top_p, top_class = torch.max(out, dim = 1)\n    correct_tensor = top_class.eq(Y_Test.data.view_as(top_class))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n    for i in range(Y_Test.size(0)):\n        label = Y_Test.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\ntest_loss = test_loss\/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\nfor i in range(5):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            flower_classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","9725270d":"### Load the dataset\n\n**Type of flowers in our dataset -**\n\n* Daisy\n* Dandelion\n* Rose\n* Sunflower\n* Tulip"}}