{"cell_type":{"4ae3b1c4":"code","9a8340e3":"code","664849cc":"code","041693b2":"code","24f39c33":"code","34ef5329":"code","b9581dd9":"code","8a97e502":"code","4da5816c":"code","dc4b2e1a":"code","b76c0f2b":"code","23cb2cd8":"code","a26d205a":"code","4072ad9c":"code","f6a8b500":"code","10078216":"code","f2ab8845":"code","80d3312a":"code","c2138b41":"code","9e91a28a":"code","18119c62":"code","123b64bc":"code","1ff72458":"code","ea7573c0":"code","77a67bea":"code","6bf6298d":"code","b482b71e":"code","39df1ef4":"code","5cf29e3c":"code","d35feb6b":"code","c60e301d":"code","dfb2875c":"code","a9f9963d":"code","af3193de":"code","4dc5b0c7":"code","c33dc07c":"code","a814c67f":"markdown","e68bcb94":"markdown","032a7638":"markdown","93c6acc4":"markdown","5ce5e448":"markdown","31e2950f":"markdown","9786c5cd":"markdown","eb6ae770":"markdown","899f47a0":"markdown","41ab1dbf":"markdown","60793fa2":"markdown","9266346e":"markdown","c64ba91e":"markdown","8bac3b8f":"markdown","08a4985b":"markdown","cb712ffd":"markdown"},"source":{"4ae3b1c4":"#Import dependencies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","9a8340e3":"#Load the data\ndata = pd.read_csv('..\/input\/wine-quality\/winequalityN.csv')","664849cc":"data.head()","041693b2":"data.describe()","24f39c33":"data.info()","34ef5329":"data.shape","b9581dd9":"vals = data.isna().sum().sort_values(ascending=False).values\ncols = list(data.isna().sum().sort_values(ascending=False).index)\n\npd.DataFrame(data=vals, index=cols, columns=['values']).T","8a97e502":"#target class distribution \n(data.quality.value_counts() \/ len(data))*100","4da5816c":"#plot target class distribution \nplt.figure(figsize=(16,3))\nsns.countplot(data=data, x='quality')","dc4b2e1a":"data.type.value_counts()","b76c0f2b":"num_vars = data.select_dtypes(include=float).columns","23cb2cd8":"def distplot(col, data): \n    plt.figure(figsize=(16,2))\n    \n    plt.subplot(1,3,1)\n    mean = data[col].mean()\n    sns.distplot(data[col], bins=88)\n    plt.axvline(mean, 0,1, color='black')\n    \n    plt.subplot(1,3,2)\n    sns.boxplot(x=col, data=data)\n    \n    plt.subplot(1,3,3)\n    sns.violinplot(x='quality',y=col,data=data, hue='type',split=True)\n","a26d205a":"for col in num_vars:\n    distplot(col, data)","4072ad9c":"data=data.dropna()","f6a8b500":"#data.isna().sum()","10078216":"cat_vars = ['type']\nenc_cat_vars = pd.get_dummies(data[cat_vars])","f2ab8845":"data.drop('type', axis=1, inplace=True)","80d3312a":"data = pd.concat([enc_cat_vars, data], axis=1)\ndata.head()","c2138b41":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(data.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);","9e91a28a":"X = data.drop('quality', axis=1)\ny = data['quality']","18119c62":"from imblearn.over_sampling import SMOTE","123b64bc":"over_sample = SMOTE(k_neighbors=4)\nX, y = over_sample.fit_resample(X,y)","1ff72458":"from collections import Counter\ncounter = Counter(y)\nfor k,v in counter.items():\n    dist = (v\/len(y))*100\n    print(f'class={k}, n={v} ({dist}%)')","ea7573c0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2)","77a67bea":"from sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, GridSearchCV, RandomizedSearchCV,cross_validate\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.pipeline import make_pipeline\n\nfrom sklearn.metrics import confusion_matrix, classification_report,f1_score, recall_score, precision_score, make_scorer, accuracy_score","6bf6298d":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.svm import SVC\nimport xgboost  as xgb","b482b71e":"models_dict = {\n\n'RFC_model' : make_pipeline(\n                            SelectKBest(f_classif, k=13),\n                            RandomForestClassifier(random_state=0, n_jobs=-1)),\n\n'DTC_model' : make_pipeline(\n                            SelectKBest(f_classif, k=13),\n                            AdaBoostClassifier(DecisionTreeClassifier(),algorithm='SAMME')),\n\n'SVC_model' : make_pipeline(\n                            StandardScaler(),\n                            SelectKBest(f_classif, k=13),\n                            SVC(C=5,kernel='rbf',gamma=5,degree=3,coef0=1)),\n\n'NB_model'  : make_pipeline(\n                            SelectKBest(f_classif, k=13), \n                            GaussianNB()),\n\n'DTC_model' : make_pipeline(\n                            SelectKBest(f_classif, k=13), \n                            DecisionTreeClassifier()),\n\n'XGB_model' : make_pipeline(\n                            SelectKBest(f_classif, k=13), \n                            xgb.XGBClassifier(objective='multi:softmax',num_class=7))\n    \n}","39df1ef4":"def cross_validation_score(model):\n    \n    cv = StratifiedKFold(3)\n    scores = cross_val_score(model, X_train,y_train, n_jobs=-1, cv=cv, scoring='f1_micro')\n    scores = scores.mean()\n    return scores\n","5cf29e3c":"for mod_n, mod in models_dict.items():\n    print('{}: Validation score  {}'.format(mod_n, cross_validation_score(mod)))","d35feb6b":"RFC_model = make_pipeline(SelectKBest(f_classif, k=13),\n                          RandomForestClassifier(random_state=0, n_jobs=-1))","c60e301d":"def RandomizedSearchCV_(model, param_grid) :\n    \n    cv = StratifiedKFold(3)\n    randomSCV = RandomizedSearchCV(model, param_grid, n_iter=30, cv=5, scoring='f1_micro', random_state=42)\n\n    randomSCV.fit(X_train, y_train)\n    model_best_params = randomSCV.best_estimator_\n    \n    print('best score :', randomSCV.best_score_ )\n    print('best params :', randomSCV.best_params_ )\n    \n    return model_best_params","dfb2875c":"RFC_model.get_params().keys()","a9f9963d":"param_grid = {\n    \n    'selectkbest__k':np.arange(5,14,1),\n    'randomforestclassifier__max_depth':np.arange(100,300,50),\n    'randomforestclassifier__n_estimators':np.arange(300,500,50)\n}\n\n#Tunning Hyperparameters\nRFC_model_best_hyp = RandomizedSearchCV_(RFC_model, param_grid)","af3193de":"RFC_model_best_hyp.fit(X_train, y_train)\n\ny_pred = RFC_model_best_hyp.predict(X_test)","4dc5b0c7":"cm = sns.light_palette(\"green\", as_cmap=True) \n  \nct = pd.crosstab(y_test, y_pred)\nct.style.background_gradient(cmap=cm).set_precision(2)\n","c33dc07c":"print(classification_report(y_test, y_pred,labels=[3,4,5,6,7,8,9]))","a814c67f":"## Handling Umbalanced Data","e68bcb94":"### Correlation Matrix","032a7638":"## Data Preprocessing","93c6acc4":"###  Continuous Variables \n#### Univariate Analysis & Bivariate Analysis","5ce5e448":"### Split the data into Train and test set","31e2950f":"## Random Forest Classifier","9786c5cd":"## Target variable","eb6ae770":"### Encoding categorial variables:","899f47a0":"### Categorical variables","41ab1dbf":"## The Distribution of Independent Variables ","60793fa2":"\n## Split the data","9266346e":"## Evaluate the Model:","c64ba91e":"## Modeling\n","8bac3b8f":"## Exploratory Data Analysis","08a4985b":"### Handling NaN  :","cb712ffd":"# Wine quality"}}