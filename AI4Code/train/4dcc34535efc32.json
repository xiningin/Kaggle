{"cell_type":{"6bbfbce6":"code","e52ed7bb":"code","241bf8d1":"code","a224da75":"code","e43fcc1b":"code","d84606fd":"code","5262b850":"code","b6721202":"code","9340b02a":"code","fb66b143":"code","129dfc9b":"code","05159f91":"code","8dee9d80":"code","241e427b":"code","4402f01f":"code","975143d6":"markdown","44054182":"markdown","264bd75d":"markdown"},"source":{"6bbfbce6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e52ed7bb":"df = pd.read_csv(\"\/kaggle\/input\/mercedes-benz-greener-manufacturing\/train.csv.zip\", compression='zip')\nprint(df.shape)\nprint(df.info())\ndf.head()","241bf8d1":"from sklearn.model_selection import train_test_split\n\ntrain_set, valid_set = train_test_split(df, test_size=0.2, random_state=42)\n\nprint(train_set.shape)\nprint(valid_set.shape)","a224da75":"# train set\nX_train_cat = train_set.select_dtypes(include='object').copy()\nX_train_num = train_set.select_dtypes(include='int64').copy()\nX_train_num.drop('ID', axis=1, inplace=True)\n\n# valid set\nX_valid_cat = valid_set.select_dtypes(include='object').copy()\nX_valid_num = valid_set.select_dtypes(include='int64').copy()\nX_valid_num.drop('ID', axis=1, inplace=True)\n\n# label\ny_train = train_set['y'].values\ny_valid = valid_set['y'].values","e43fcc1b":"import tensorflow as tf\n\nclass OneHotEncodingLayer(tf.keras.layers.Layer):\n    def __init__(self, vocab, num_oov_buckets=1,  **kwargs):\n        super().__init__()\n        self.vocab = vocab\n        self.num_oov_buckets = num_oov_buckets\n        \n    def adapt(self, data):\n        indices = tf.range(len(self.vocab), dtype=tf.int64)\n        table_init = tf.lookup.KeyValueTensorInitializer(self.vocab, indices)\n        self.table = tf.lookup.StaticVocabularyTable(table_init, self.num_oov_buckets)\n        \n    def call(self, inputs):\n        cat_indices = self.table.lookup(inputs)\n        one_hot =  tf.one_hot(cat_indices, depth=len(self.vocab)+self.num_oov_buckets)\n        return tf.squeeze(one_hot, axis=1)\n    \n    def get_config(self):\n        base_config = super().get_config()\n        return {**base_config, \"vocab\":self.vocab, \"num_oov_buckets\":self.num_oov_buckets}","d84606fd":"# categorical features one hot encoding\none_hot_encoders = [OneHotEncodingLayer(vocab=np.unique(data.values).tolist()) for col, data in X_train_cat.iteritems()]\n\nfor encoder, (col, data) in zip(one_hot_encoders, X_train_cat.iteritems()):\n    encoder.adapt(data.values)\n    \ncat_inputs = [tf.keras.Input(shape=(1,), dtype=tf.string) for _ in X_train_cat.iteritems()]\nencoder_outs = [encoder(cat_input) for encoder, cat_input in zip(one_hot_encoders, cat_inputs)]\n\n# concatenate categorical features\nconcat = tf.keras.layers.concatenate(encoder_outs, axis=-1)\n\n# numerical features are binary\nnum_inputs = tf.keras.Input(shape=(X_train_num.shape[1]),)\n\n# concatenate all features\nconcat_all = tf.keras.layers.concatenate([concat, num_inputs], axis=-1)\n\n# build DNN\ndense1 = tf.keras.layers.Dense(300, activation='relu')(concat_all)\ndense2 = tf.keras.layers.Dense(200, activation='relu')(dense1)\ndense3 = tf.keras.layers.Dense(100, activation='relu')(dense2)\noutputs = tf.keras.layers.Dense(1)(dense3)\n\nmodel = tf.keras.models.Model(inputs=[cat_inputs, num_inputs], outputs=outputs)","5262b850":"K = tf.keras.backend\n\nclass ExponentialLearningRate(tf.keras.callbacks.Callback):\n    def __init__(self, factor):\n        self.factor = factor\n        self.rates = []\n        self.losses = []\n    def on_batch_end(self, batch, logs):\n        self.rates.append(K.get_value(self.model.optimizer.lr))\n        self.losses.append(logs[\"loss\"])\n        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)","b6721202":"tf.keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\n\ntrain_cat_in = [data.values for col, data in X_train_cat.iteritems()]\nvalid_cat_in = [data.values for col, data in X_valid_cat.iteritems()]\n\nexpon_lr =  ExponentialLearningRate(factor=1.005)\n\nmodel.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), metrics=['mae'])\n\nmodel.fit([train_cat_in, X_train_num.values], y_train, epochs=10, validation_data=((valid_cat_in, X_valid_num.values), y_valid), callbacks=[expon_lr])","9340b02a":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.plot(expon_lr.rates, expon_lr.losses)\nplt.gca().set_xscale('log')\nplt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\nplt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\nplt.grid()\nplt.title('Exponential Sceduling (per batch)')\nplt.xlabel(\"Learning rate\")\nplt.ylabel(\"Loss\")\nplt.show()","fb66b143":"tf.keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10)\n\nmodel.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['mae'])\n\nmodel.fit([train_cat_in, X_train_num.values], y_train, epochs=100, \n          validation_data=((valid_cat_in, X_valid_num.values), y_valid), callbacks=[early_stopping_cb])","129dfc9b":"model.evaluate((valid_cat_in, X_valid_num.values), y_valid)","05159f91":"test = pd.read_csv(\"\/kaggle\/input\/mercedes-benz-greener-manufacturing\/test.csv.zip\", compression='zip')\ntest.head()","8dee9d80":"X_test_cat = test.select_dtypes(include='object').copy()\nX_test_num = test.select_dtypes(include='int64').copy()\nX_test_num.drop('ID', axis=1, inplace=True)\n\ntest_cat_in = [data.values for col, data in X_test_cat.iteritems()]\n\ntest['y'] = model.predict((test_cat_in, X_test_num.values))\ntest['y'].values","241e427b":"submission = test[['ID', 'y']]\nsubmission.head()","4402f01f":"submission.to_csv('submission.csv', index=False)","975143d6":"# Make Predictions","44054182":"# keras Functional API","264bd75d":"# Preprocessing"}}