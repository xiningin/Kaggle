{"cell_type":{"702aded3":"code","d44c2317":"code","770414f0":"code","68e8bc67":"code","854cc286":"code","ef710940":"code","8ed69609":"code","c53e1f1b":"code","de43aafd":"code","85704f54":"code","c7b0a09c":"code","060396b5":"code","59ea7211":"code","a8c2a12d":"markdown","6bc70235":"markdown","fb314fc7":"markdown","261503cc":"markdown","6b597a97":"markdown","b9c4edb3":"markdown","7fcb946d":"markdown","3de56e3e":"markdown","45cb44fd":"markdown","52f6998c":"markdown","967b5f72":"markdown","9803ca67":"markdown","cfcbb413":"markdown","552a3219":"markdown","59aed444":"markdown","b6573462":"markdown","ac80b011":"markdown","7a43edb8":"markdown"},"source":{"702aded3":"!pip install -q quick-ml","d44c2317":"import tensorflow as tf\nimport quick_ml\n\nprint(\"quick_ml Version -> \", quick_ml.__version__)","770414f0":"from quick_ml.begin_tpu import define_tpu_strategy, get_training_dataset, get_validation_dataset, get_test_dataset","68e8bc67":"strategy, tpu = define_tpu_strategy()","854cc286":"from kaggle_datasets import KaggleDatasets\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('cats-dogs-tfrecords-192x192')\n\nprint(GCS_DS_PATH)\n\ntrain_tfrec_path = '\/train.tfrecords'\nval_tfrec_path = '\/val.tfrecords'\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nEPOCHS = 5\nSTEPS_PER_EPOCH = 14961 \/\/ BATCH_SIZE\nprint(\"STEPS PER EPOCH -> \", STEPS_PER_EPOCH)\n\ndictionary_labeled = \"{'image_raw' : tf.io.FixedLenFeature([], tf.string), 'label' : tf.io.FixedLenFeature([], tf.int64)}\"\nIMAGE_SIZE = \"192,192\"\n\nfrom quick_ml.begin_tpu import get_labeled_tfrecord_format\nget_labeled_tfrecord_format(dictionary_labeled, IMAGE_SIZE)","ef710940":"from quick_ml.augments import define_augmentations","8ed69609":"define_augmentations(flip_left_right = True, hue = 0.3, contrast= (0.1,0.4), brightness= 0.4)","c53e1f1b":"from quick_ml.augments import define_callbacks\n\ndefine_callbacks(lr_scheduler = 'rampup')","de43aafd":"models_list = ['VGG16', 'EfficientNetB0', 'EfficientNetB1', 'InceptionV3', 'DenseNet201']","85704f54":"from quick_ml.augments import get_models_training_report","c7b0a09c":"df = get_models_training_report(models_list, tpu, 1, GCS_DS_PATH, train_tfrec_path, STEPS_PER_EPOCH, EPOCHS, BATCH_SIZE, val_tfrec_path, input_shape = [192,192,3], activation = 'sigmoid', optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = 'accuracy')","060396b5":"df","59ea7211":"df.to_csv('output.csv', index = False)","a8c2a12d":"Please ensure the order of imports. <br>\n* Import Tensorflow then quick_ml\n* After successful import, you must receive an output message indicating the status of \"Tensorflow import & the latest version\" supported by quick_ml","6bc70235":"If the GCS_DS_PATH was printed sucessfully, mention the relative path (relative to the GCS_DS_PATH's folder directory) of the tfrec files.","fb314fc7":"get_labeled_tfrecord_format is used to define the format of the TFRecords dataset to be used for model trianing. Learn more [here](https:\/\/antoreepjana.wixsite.com\/quick-ml\/begin-working-w-tpu)","261503cc":"Please Note :- Callbacks for Training with Augmentation need to be by defined by the following method. Callbacks without augmentation need to be called by using the quick_ml.callbacks. See Here -> [Model Training w\/ Callbacks](https:\/\/www.kaggle.com\/superficiallybot\/quick-ml-model-training-w-callbacks)","6b597a97":"### Define the Parameters","b9c4edb3":"#### Necesaary Imports","7fcb946d":"## Get TPU Strategy & Load the datasets","3de56e3e":"### Installation","45cb44fd":"#### Define the Augmentations","52f6998c":"define_tpu_strategy is used to instantiate the TPU strategy (if TPU present) & tpu instance (if TPU present).\nLearn more [here](https:\/\/antoreepjana.wixsite.com\/quick-ml\/begin-working-w-tpu)","967b5f72":"## Model Training Report","9803ca67":"#### Define the models list and begin Model Training Report","cfcbb413":"## Official Website => [quick_ml](http:\/\/antoreepjana.wixsite.com\/quick-ml)","552a3219":"quick_ml's Data Augmentation methods give your the option to generate new data by applying the augmentation each epoch rather than once before the model begins to train (traditional method). <br>\nTo get started, you need to define the set of augmentations needed by importing **define_augmentations**. Learn more [here](https:\/\/antoreepjana.wixsite.com\/quick-ml\/copy-of-models-training-report).","59aed444":"#### Define callbacks (For Training w\/ Augmentation)","b6573462":"Note:- Please mention the full name of the dataset as an argument in get_gcs_path() rather than leaving it empty. In presence of more than one dataset, it would cause conflict. However, in the presence of single dataset, it's a good practice to mention the full name of the dataset as an argument in the get_gcs_path().","ac80b011":"## Summary -> <br>\nIn this notebook, we'll learn how to perform Data Augmentation using quick_ml. We'll be training multiple models in this particular notebook and therefore, Training Report will be generated. Let's begin to observe how quick_ml can simplify your **multiple model training** with **Data Augmentation**.","7a43edb8":"This where the most interesting part happens. Just like the regular models training report, you can use **get_models_training_report** to get your multi model training started. This is not to be confused with [Model trainings Report without Data Augmentations](https:\/\/antoreepjana.wixsite.com\/quick-ml\/models-training-report)"}}