{"cell_type":{"d68f1786":"code","e529efe4":"code","aa906d97":"code","a55c7c85":"code","bbc71f07":"code","bfe72564":"code","6fb1a7dd":"code","8c5ddb34":"code","d03c7d8c":"code","4ed0ce49":"code","a43e3767":"code","539da51d":"code","c5536494":"code","9074c7a8":"code","371260c5":"code","067b28f9":"code","d7028b04":"code","5a57c358":"code","c707a30b":"code","26db6af6":"code","8fcbd14c":"code","0bf2be8d":"code","bb9adecb":"code","c009902f":"code","f7491e22":"code","6e9d764d":"code","d38bbaea":"code","33b4c4f5":"code","ccc8b8b5":"code","f794461c":"code","b6dc917b":"code","b03aa5fb":"code","9042b3aa":"code","0b7d91cf":"code","bf259940":"code","417337f6":"markdown","64650cda":"markdown","d5e3dafa":"markdown","93f2c6a1":"markdown","148fc357":"markdown","f2c1b7e2":"markdown"},"source":{"d68f1786":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e529efe4":"\nimport pandas as pd  #data processing and data level operation\nimport numpy as np  # Linear Algebra\nimport os, re\nimport string\nimport nltk \nfrom nltk.corpus import stopwords\n\n#Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud,STOPWORDS\n\n%matplotlib inline\n###For downlaod the nltk\n########nltk.download()","aa906d97":"#Current working directory\nprint('current workind directory ==== ',os.getcwd())\n\n#Loading data\ntrain = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip',delimiter = '\\t')\ntest = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/testData.tsv.zip',delimiter = '\\t')\n\ntrain.shape, test.shape","a55c7c85":"train.head()","bbc71f07":"test.head()","bfe72564":"print (\"number of rows for sentiment 1: {}\".format(len(train[train.sentiment == 1])))\nprint ( \"number of rows for sentiment 0: {}\".format(len(train[train.sentiment == 0])))","6fb1a7dd":"train.groupby('sentiment').describe().transpose()","8c5ddb34":"#Creating a new col\ntrain['length'] = train['review'].apply(len)\ntrain.head()","d03c7d8c":"#Histogram of count of letters\ntrain['length'].plot.hist(bins = 100)","4ed0ce49":"train.length.describe()","a43e3767":"train.hist(column='length', by='sentiment', bins=100,figsize=(12,4))","539da51d":"from bs4 import BeautifulSoup\n\n#Creating a function for cleaning of data\ndef clean_text(raw_text):\n    # 1. remove HTML tags\n    raw_text = BeautifulSoup(raw_text).get_text() \n    \n    # 2. removing all non letters from text\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_text) \n    \n    # 3. Convert to lower case, split into individual words\n    words = letters_only.lower().split()                           \n    \n    # 4. Create variable which contain set of stopwords\n    stops = set(stopwords.words(\"english\"))                  \n    \n    # 5. Remove stop word & returning   \n    return [w for w in words if not w in stops]","c5536494":"#Cleaning review and also adding a new col as its len count of words\ntrain['clean_review'] = train['review'].apply(clean_text)\ntrain['length_clean_review'] = train['clean_review'].apply(len)\ntrain.head()","9074c7a8":"train.describe()","371260c5":"#Checking the smallest review\nprint(train[train['length_clean_review'] == 4]['review'].iloc[0])\nprint('------After Cleaning------')\nprint(train[train['length_clean_review'] == 4]['clean_review'].iloc[0])","067b28f9":"#Plot wordcloud\nword_cloud = WordCloud(width = 1000, height = 500, stopwords = STOPWORDS, background_color = 'red').generate(\n                        ''.join(train['review']))\n\nplt.figure(figsize = (15,8))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.show()\n\n#word_cloud.to_file('aa.png')   #for saving file","d7028b04":"from sklearn.feature_extraction.text import CountVectorizer","5a57c358":"# Might take awhile...\nbow_transform = CountVectorizer(analyzer=clean_text).fit(train['review'])  #bow = bag of word\n\n# Print total number of vocab words\nprint(len(bow_transform.vocabulary_))","c707a30b":"review1 = train['review'][1]\nprint(review1)","26db6af6":"bow1 = bow_transform.transform([review1])\nprint(bow1)\nprint(bow1.shape)","8fcbd14c":"print(bow_transform.get_feature_names()[71821])\nprint(bow_transform.get_feature_names()[72911])","0bf2be8d":"#Creating bag of words for our review variable\nreview_bow = bow_transform.transform(train['review'])","bb9adecb":"print('Shape of Sparse Matrix: ', review_bow.shape)\nprint('Amount of Non-Zero occurences: ', review_bow.nnz)","c009902f":"sparsity = (100.0 * review_bow.nnz \/ (review_bow.shape[0] * review_bow.shape[1]))\nprint('sparsity: {}'.format(sparsity))","f7491e22":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer = TfidfTransformer().fit(review_bow)\ntfidf1 = tfidf_transformer.transform(bow1)\nprint(tfidf1)","6e9d764d":"print(tfidf_transformer.idf_[bow_transform.vocabulary_['war']])\nprint(tfidf_transformer.idf_[bow_transform.vocabulary_['book']])","d38bbaea":"review_tfidf = tfidf_transformer.transform(review_bow)\nprint(review_tfidf.shape)","33b4c4f5":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train['review'], train['sentiment'], test_size=0.22, random_state=101)\n\nlen(X_train), len(X_test), len(X_train) + len(X_test)","ccc8b8b5":"from sklearn.metrics import classification_report\n#Predicting & Stats Function\ndef pred(predicted,compare):\n    cm = pd.crosstab(compare,predicted)\n    TN = cm.iloc[0,0]\n    FN = cm.iloc[1,0]\n    TP = cm.iloc[1,1]\n    FP = cm.iloc[0,1]\n    print(\"CONFUSION MATRIX ------->> \")\n    print(cm)\n    print()\n    \n    ##check accuracy of model\n    print('Classification paradox :------->>')\n    print('Accuracy :- ', round(((TP+TN)*100)\/(TP+TN+FP+FN),2))\n    print()\n    print('False Negative Rate :- ',round((FN*100)\/(FN+TP),2))\n    print()\n    print('False Postive Rate :- ',round((FP*100)\/(FP+TN),2))\n    print()\n    print(classification_report(compare,predicted))","f794461c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', LogisticRegression(random_state=101)),  # train on TF-IDF vectors w\/ Naive Bayes classifier\n])\n\npipeline.fit(X_train,y_train)\npredictions = pipeline.predict(X_train)\npred(predictions,y_train)","b6dc917b":"#Test Set Result\npredictions = pipeline.predict(X_test)\npred(predictions,y_test)","b03aa5fb":"#Saving Output\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\npipeline_logit = Pipeline([\n    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', LogisticRegression(random_state=101)),  # train on TF-IDF vectors w\/ Naive Bayes classifier\n])\n\npipeline_logit.fit(train['review'],train['sentiment'])\ntest['sentiment'] = pipeline_logit.predict(test['review'])","9042b3aa":"test.head(5)","0b7d91cf":"output = test[['id','sentiment']]\nprint(output)","bf259940":"output.to_csv( \"sentiment.csv\", index=False, quoting=3 )","417337f6":"**Modeling Part**","64650cda":"**Vectorization**","d5e3dafa":"**Word Cloud**","93f2c6a1":"**Result Function**","148fc357":"**TF-IDF**","f2c1b7e2":"**\nTraining Model,\nLogistic Regression**"}}