{"cell_type":{"dd9b346c":"code","e776e5ac":"code","9f9a1855":"code","dcb157c7":"code","3bc7d98d":"code","f36d907f":"code","93f5644f":"code","2d39d2e2":"code","c9248cd6":"code","3b971c4a":"code","4bee725c":"code","3aecb846":"code","907c78b6":"code","657a2762":"code","adc73e54":"code","03a6f207":"code","d3992fce":"code","864e6d2c":"code","35408a51":"code","78fa3705":"code","ab1f6614":"code","c1cb2c33":"code","19e5a796":"code","fb5b4999":"code","19669640":"code","faca470d":"code","6534d55d":"code","59e558b8":"code","650cff56":"code","08101372":"markdown","efab9875":"markdown","4ff341c1":"markdown","3740d19b":"markdown","abdb68af":"markdown","c2ab0aaa":"markdown","666451e2":"markdown","0455cd6e":"markdown","e9252a2e":"markdown","98a2a49b":"markdown","0c274d54":"markdown","ee44ff64":"markdown","f502cb82":"markdown","3594ac03":"markdown","fe6b15c0":"markdown"},"source":{"dd9b346c":"import h5py\nimport os","e776e5ac":"class HDF5DatasetWriter:\n    def __init__(self, dims, outputPath, dataKey=\"images\",bufSize=1000):\n    # check to see if the output path exists, and if so, raise\n    # an exception\n        if os.path.exists(outputPath):\n            raise ValueError(\"The supplied \u2018outputPath\u2018 already \"\n         \"exists and cannot be overwritten. Manually delete \"\n         \"the file before continuing.\", outputPath)\n\n         # open the HDF5 database for writing and create two datasets:\n         # one to store the images\/features and another to store the\n         # class labels\n        self.db = h5py.File(outputPath, \"w\")\n        self.data = self.db.create_dataset(dataKey, dims,dtype=\"float\")\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],),dtype=\"int\")\n\n         # store the buffer size, then initialize the buffer itself\n         # along with the ind\n        self.bufSize = bufSize\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n    def add(self, rows, labels):\n        # add the rows and labels to the buffer\n        self.buffer[\"data\"].extend(rows)\n        self.buffer[\"labels\"].extend(labels)\n        \n        # check to see if the buffer needs to be flushed to disk\n        if len(self.buffer[\"data\"]) >= self.bufSize:\n            self.flush()\n    def flush(self):\n        # write the buffers to disk then reset the buffer\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}\n    def storeClassLabels(self, classLabels):\n        # create a dataset to store the actual class label names,\n        # then store the class labels\n        dt = h5py.special_dtype()\n        labelSet = self.db.create_dataset(\"label_names\",\n        (len(classLabels),), dtype=dt)\n        labelSet[:] = classLabels\n    def close(self):\n         # check to see if there are any other entries in the buffer\n         # that need to be flushed to disk\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n        \n         # close the dataset\n        self.db.close()","9f9a1855":"# Config file \n\n## Dataset paths\nanimal_dataset_path = '..\/input\/animal-image-datasetdog-cat-and-panda\/'\nflower_dataset_path = '..\/input\/flowers17\/17flowers\/jpg'\ncaltech101_path = '..\/input\/caltech-101\/caltech101'\n\n## output Paths to save the extracted features file i.e. '.hdf5 file'\n\nanimal_hdf5_path = 'animal_features.hdf5'\nflowers_hdf5_path= 'flowers_features.hdf5'\ncaltech_hdf5_path = 'caltech_features.hdf5'\n\n\n#Batch size \n\nbatch_size = 32\n\nbuffer = 1000\n\n","dcb157c7":"! pip install imutils\n! pip install  progressbar","3bc7d98d":"import numpy as np\nimport random\nfrom imutils import paths\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import imagenet_utils\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom sklearn.preprocessing import LabelEncoder\nimport progressbar\nimport os\n\n","f36d907f":"print(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(animal_dataset_path))\nrandom.shuffle(imagePaths)\n","93f5644f":"# extract the class labels from the image paths then encode the\n# labels\nlabels = [p.split(os.path.sep)[-2] for p in imagePaths]\nle = LabelEncoder()\nlabels = le.fit_transform(labels)","2d39d2e2":"print(\"[INFO] loading network...\")\nmodel = VGG16(weights=\"imagenet\", include_top=False)","c9248cd6":"# initialize the HDF5 dataset writer, then store the class label\n# names in the dataset\ndataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7),animal_hdf5_path, dataKey=\"features\")\n\n\nwidgets = [\"Extracting Features: \", progressbar.Percentage(), \" \",\nprogressbar.Bar(), \" \", progressbar.ETA()]\npbar = progressbar.ProgressBar(maxval=len(imagePaths),widgets=widgets).start()\n\n# loop over the images in patches\nfor i in np.arange(0, len(imagePaths), batch_size):\n# extract the batch of images and labels, then initialize the\n# list of actual images that will be passed through the network\n# for feature extraction\n    batchPaths = imagePaths[i:i + batch_size]\n    batchLabels = labels[i:i + batch_size]\n    batchImages = []\n    # loop over the images and labels in the current batch\n    for (j, imagePath) in enumerate(batchPaths):\n      # load the input image using the Keras helper utility\n      # while ensuring the image is resized to 224x224 pixels\n        image = load_img(imagePath, target_size=(224, 224))\n        image = img_to_array(image)\n\n        # preprocess the image by (1) expanding the dimensions and\n        # (2) subtracting the mean RGB pixel intensity from the\n        # ImageNet dataset\n        image = np.expand_dims(image, axis=0)\n        image = imagenet_utils.preprocess_input(image)\n\n        # add the image to the batch\n        batchImages.append(image)\n    batchImages = np.vstack(batchImages)\n    features = model.predict(batchImages, batch_size=batch_size)\n    # reshape the features so that each image is represented by\n    # a flattened feature vector of the \u2018MaxPooling2D\u2018 outputs\n    features = features.reshape((features.shape[0], 512 * 7 * 7))\n    \n    # add the features and labels to our HDF5 dataset\n    dataset.add(features, batchLabels)\n    pbar.update(i)\n# close the dataset\ndataset.close()\npbar.finish()\n\n","3b971c4a":"print(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(flower_dataset_path))\nrandom.shuffle(imagePaths)\n","4bee725c":"# extract the class labels from the image paths then encode the\n# labels\nlabels = [p.split(os.path.sep)[-2] for p in imagePaths]\nle = LabelEncoder()\nlabels = le.fit_transform(labels)","3aecb846":"# initialize the HDF5 dataset writer, then store the class label\n# names in the dataset\ndataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7),flowers_hdf5_path, dataKey=\"features\")\n#dataset.storeClassLabels(le.classes_)\n\nwidgets = [\"Extracting Features: \", progressbar.Percentage(), \" \",\nprogressbar.Bar(), \" \", progressbar.ETA()]\npbar = progressbar.ProgressBar(maxval=len(imagePaths),widgets=widgets).start()\n\n# loop over the images in patches\nfor i in np.arange(0, len(imagePaths), batch_size):\n# extract the batch of images and labels, then initialize the\n# list of actual images that will be passed through the network\n# for feature extraction\n    batchPaths = imagePaths[i:i + batch_size]\n    batchLabels = labels[i:i + batch_size]\n    batchImages = []\n    # loop over the images and labels in the current batch\n    for (j, imagePath) in enumerate(batchPaths):\n      # load the input image using the Keras helper utility\n      # while ensuring the image is resized to 224x224 pixels\n        image = load_img(imagePath, target_size=(224, 224))\n        image = img_to_array(image)\n\n        # preprocess the image by (1) expanding the dimensions and\n        # (2) subtracting the mean RGB pixel intensity from the\n        # ImageNet dataset\n        image = np.expand_dims(image, axis=0)\n        image = imagenet_utils.preprocess_input(image)\n\n        # add the image to the batch\n        batchImages.append(image)\n    batchImages = np.vstack(batchImages)\n    features = model.predict(batchImages, batch_size=batch_size)\n    # reshape the features so that each image is represented by\n    # a flattened feature vector of the \u2018MaxPooling2D\u2018 outputs\n    features = features.reshape((features.shape[0], 512 * 7 * 7))\n    \n    # add the features and labels to our HDF5 dataset\n    dataset.add(features, batchLabels)\n    pbar.update(i)\n# close the dataset\ndataset.close()\npbar.finish()","907c78b6":"print(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(caltech101_path))\nrandom.shuffle(imagePaths)\n","657a2762":"# extract the class labels from the image paths then encode the\n# labels\nlabels = [p.split(os.path.sep)[-2] for p in imagePaths]\nle = LabelEncoder()\nlabels = le.fit_transform(labels)","adc73e54":"# initialize the HDF5 dataset writer, then store the class label\n# names in the dataset\ndataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7),caltech_hdf5_path, dataKey=\"features\")\n#dataset.storeClassLabels(le.classes_)\n\nwidgets = [\"Extracting Features: \", progressbar.Percentage(), \" \",\nprogressbar.Bar(), \" \", progressbar.ETA()]\npbar = progressbar.ProgressBar(maxval=len(imagePaths),widgets=widgets).start()\n\n# loop over the images in patches\nfor i in np.arange(0, len(imagePaths), batch_size):\n# extract the batch of images and labels, then initialize the\n# list of actual images that will be passed through the network\n# for feature extraction\n    batchPaths = imagePaths[i:i + batch_size]\n    batchLabels = labels[i:i + batch_size]\n    batchImages = []\n    # loop over the images and labels in the current batch\n    for (j, imagePath) in enumerate(batchPaths):\n      # load the input image using the Keras helper utility\n      # while ensuring the image is resized to 224x224 pixels\n        image = load_img(imagePath, target_size=(224, 224))\n        image = img_to_array(image)\n\n        # preprocess the image by (1) expanding the dimensions and\n        # (2) subtracting the mean RGB pixel intensity from the\n        # ImageNet dataset\n        image = np.expand_dims(image, axis=0)\n        image = imagenet_utils.preprocess_input(image)\n\n        # add the image to the batch\n        batchImages.append(image)\n    batchImages = np.vstack(batchImages)\n    features = model.predict(batchImages, batch_size=batch_size)\n    # reshape the features so that each image is represented by\n    # a flattened feature vector of the \u2018MaxPooling2D\u2018 outputs\n    features = features.reshape((features.shape[0], 512 * 7 * 7))\n    \n    # add the features and labels to our HDF5 dataset\n    dataset.add(features, batchLabels)\n    pbar.update(i)\n# close the dataset\ndataset.close()\npbar.finish()","03a6f207":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nimport argparse\nimport pickle\nimport h5py","d3992fce":"animal_hdf5_path =  'animal_features.hdf5'\nflowers_hdf5_path = 'flowers_features.hdf5'\ncaltech101_hdf5_path ='caltech_features.hdf5'\n\nmodel_animal_path = 'animal_model01.cpickel'\n\nmodel_flowers_path = 'flowers_model01.cpickel'\n\nmodel_caltech_path = 'caltech_model01.cpickel'\n ","864e6d2c":"# open the HDF5 database for reading then determine the index of\n# the training and testing split, provided that this data was\n# already shuffled *prior* to writing it to disk\ndb = h5py.File(animal_hdf5_path, \"r\")\ni = int(db[\"labels\"].shape[0] * 0.75)","35408a51":"# define the set of parameters that we want to tune then start a\n# grid search where we evaluate our model for each value of C\nprint(\"[INFO] tuning hyperparameters...\")\nparams = {\"C\": [0.1, 1.0, 10.0]}\nmodel = GridSearchCV(LogisticRegression(), params, cv=3,\nn_jobs=-1)\nmodel.fit(db[\"features\"][:i], db[\"labels\"][:i])\nprint(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n\n","78fa3705":"# evaluate the model\nprint(\"[INFO] evaluating...\")\npreds = model.predict(db[\"features\"][i:])\nprint(classification_report(db[\"labels\"][i:], preds))","ab1f6614":"# serialize the model to disk\nprint(\"[INFO] saving model...\")\nf = open(model_animal_path, \"wb\")\nf.write(pickle.dumps(model.best_estimator_))\nf.close()\n\n# close the database\ndb.close()","c1cb2c33":"# open the HDF5 database for reading then determine the index of\n# the training and testing split, provided that this data was\n# already shuffled *prior* to writing it to disk\ndb = h5py.File(flowers_hdf5_path, \"r\")\ni = int(db[\"labels\"].shape[0] * 0.75)","19e5a796":"# define the set of parameters that we want to tune then start a\n# grid search where we evaluate our model for each value of C\nprint(\"[INFO] tuning hyperparameters...\")\nparams = {\"C\": [0.1, 1.0]}\nmodel = GridSearchCV(LogisticRegression(), params, cv=3,\nn_jobs=-1)\nmodel.fit(db[\"features\"][:i], db[\"labels\"][:i])\nprint(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n\n","fb5b4999":"# evaluate the model\nprint(\"[INFO] evaluating...\")\npreds = model.predict(db[\"features\"][i:])\nprint(classification_report(db[\"labels\"][i:], preds))","19669640":"# serialize the model to disk\nprint(\"[INFO] saving model...\")\nf = open(model_flowers_path, \"wb\")\nf.write(pickle.dumps(model.best_estimator_))\nf.close()\n\n# close the database\ndb.close()","faca470d":"# open the HDF5 database for reading then determine the index of\n# the training and testing split, provided that this data was\n# already shuffled *prior* to writing it to disk\ndb = h5py.File(caltech101_hdf5_path, \"r\")\ni = int(db[\"labels\"].shape[0] * 0.75)","6534d55d":"# define the set of parameters that we want to tune then start a\n# grid search where we evaluate our model for each value of C\n# print(\"[INFO] tuning hyperparameters...\")\n# params = {\"C\": [1.0]}\n# model = GridSearchCV(LogisticRegression(), params, cv=3,\n# n_jobs=-1)\n# model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n# print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n\nmodel = LogisticRegression(C=0.1)\nmodel.fit(db[\"features\"][:i], db[\"labels\"][:i])\n\n\n","59e558b8":"# evaluate the model\nprint(\"[INFO] evaluating...\")\npreds = model.predict(db[\"features\"][i:])\nprint(classification_report(db[\"labels\"][i:], preds))","650cff56":"# serialize the model to disk\nprint(\"[INFO] saving model...\")\nf = open(model_caltech_path, \"wb\")\nf.write(pickle.dumps(model))\nf.close()\n\n# close the database\ndb.close()","08101372":"## Results on Animal Dataset","efab9875":"## Extracting Features From CALTECH-101","4ff341c1":"## Training a Classifier on Extracted Features of Animal dataset","3740d19b":"## What is HDF5?\n\n<div>\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/a\/a0\/HDF_logo.svg\/1200px-HDF_logo.svg.png\" width=\"200\"\/>\n<\/div><br>\n<p>\n    <ul>HDF : Hierarchical data format<\/ul>\n<b>HDF5 is binary data format created by the HDF5 to store gigantic numerical datasets<\/b> on\ndisk (far too large to store in memory) while facilitating easy access and computation on the rows of\nthe datasets.<\/p>\n<p>Data in HDF5 is stored hierarchically, similar to how a file system stores data. Data is\nfirst defined in groups,<br>where a group is a container-like structure which can hold datasets and other\ngroups.<br> Once a group has been defined, a dataset can be created within the group.<br>A dataset can be\nthought of as a multi-dimensional array (i.e., a NumPy array) of a homogeneous data type (integer,\nfloat, unicode, etc.)\n<\/p>\n\n<p>An example of an HDF5 file containing a group with multiple datasets is\ndisplayed in Figure 3.2.<\/p\n","abdb68af":"## Content\n\n*  What Is HDF5? \n*  Code to Write Features to an HDF5 Dataset \n*  Extracting Features From Animals\n*  Extracting Features From Flowers-17\n*  Extracting Features From CALTECH-101\n*  Training a Classifier on Extracted Features \n*  Results on Animals \n*  Results on CALTECH-101 \n*  Results on Flowers-17","c2ab0aaa":"## Results on Caltech Dataset","666451e2":"## Extracting Features with a Pre-trained CNN\n\n![](data:image\/png;base64,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)\n\n\n","0455cd6e":"![image.png](attachment:image.png)\nAn example of a HDF5 file with three datasets. The first dataset contains the\nlabel_names for CALTECH-101. We then have labels, which maps the each image to its\ncorresponding class label. Finally, the features dataset contains the image quantifications extracted by the CNN.","e9252a2e":"## Extracting Features From Animals","98a2a49b":"## Results on Animal Dataset","0c274d54":"## Code to Write Features to an HDF5 Dataset ","ee44ff64":"## Training a Classifier on Extracted Features of Caltech","f502cb82":"* Importing  necessary packages","3594ac03":"## Training a Classifier on Extracted Features of Flowers","fe6b15c0":"## Extracting Features From Flowers-17"}}