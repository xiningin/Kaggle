{"cell_type":{"aa1f478e":"code","1a4c9371":"code","8110057b":"code","fce92285":"code","7c028889":"code","bc8bf805":"code","ecbc3c9f":"code","8921c284":"code","74427451":"code","03009ab3":"code","39ac4c4d":"code","390b03e2":"code","a11702ea":"code","ac4f9a5d":"code","d06ee36e":"code","aa3dcdf7":"code","65ef6a4b":"code","82a883f6":"code","bc0a041b":"code","90ebbcd6":"code","900817c5":"code","7cba99c2":"code","470574f5":"markdown"},"source":{"aa1f478e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom kaggle_datasets import KaggleDatasets\nimport os","1a4c9371":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","8110057b":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync  # Perfect batch size for speed and performance\n# IMAGE_SIZE = [256, 256]\n# IMAGE_RESIZE = [150, 150]\n\nIMAGE_SIZE = 800","fce92285":"def format_path(st):\n    return GCS_PATH + '\/images\/' + st + '.jpg'","7c028889":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\ntrain.head()","bc8bf805":"train_paths = train['image_id'].apply(format_path).values\ntest_paths = test['image_id'].apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n# print(train_paths[: 3])\n# print(train_labels[: 3])","ecbc3c9f":"from sklearn.model_selection import train_test_split\n\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, train_labels, test_size=0.15, random_state=2020)","8921c284":"def decode_image(image, label=None):\n    image = tf.io.read_file(image)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n\n    return image if label is None else (image, label)","74427451":"def data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    return image if label is None else (image, label)","03009ab3":"def get_training_dataset():\n    return (\n        tf.data.Dataset\n            .from_tensor_slices((train_paths, train_labels))\n            .map(decode_image, num_parallel_calls=AUTOTUNE)\n            .cache()\n            .map(data_augment, num_parallel_calls=AUTOTUNE)\n            .repeat()\n            .shuffle(512)\n            .batch(BATCH_SIZE)\n            .prefetch(AUTOTUNE)\n        )\n\ndef get_validation_dataset(ordered=False):\n    return (\n        tf.data.Dataset\n            .from_tensor_slices((valid_paths, valid_labels))\n            .map(decode_image, num_parallel_calls=AUTOTUNE)\n            .cache()\n            .batch(BATCH_SIZE)\n            .prefetch(AUTOTUNE)\n    )\n\ndef get_test_dataset(ordered=False):\n    return (\n        tf.data.Dataset\n            .from_tensor_slices(test_paths)\n            .map(decode_image, num_parallel_calls=AUTOTUNE)\n            .map(data_augment, num_parallel_calls=AUTOTUNE)\n            .batch(BATCH_SIZE)\n    )","39ac4c4d":"train_dataset = get_training_dataset()\nvalid_dataset = get_validation_dataset()","390b03e2":"def build_model():\n    \n    base_model = tf.keras.applications.Xception(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n\n    base_model.trainable = True\n#     set_trainable = False\n\n#     for layer in base_model.layers:\n#         if layer.name == 'block13_sepconv1':\n#             set_trainable = True\n#             layer.trainable = True\n#         if set_trainable:\n#             layer.trainable = True\n#         else:\n#             layer.trainable = False\n    \n    model = keras.models.Sequential([\n        base_model,\n        keras.layers.Dropout(0.5),\n        keras.layers.BatchNormalization(),\n        keras.layers.GlobalMaxPooling2D(),\n        keras.layers.Dense(4, activation='softmax'),\n    ])\n\n    model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001), \n                  loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n    \n    return model","a11702ea":"with strategy.scope():  \n    model = build_model()","ac4f9a5d":"NUM_TRAINING_IMAGES = 0\nNUM_VALIDATION_IMAGES = 0\nfor temp_path in os.listdir('..\/input\/plant-pathology-2020-fgvc7\/images'):\n    if temp_path.startswith('Train'):\n        NUM_TRAINING_IMAGES += 1\n        \nNUM_VALIDATION_IMAGES = int(NUM_TRAINING_IMAGES * 0.15)\n        \nprint(NUM_TRAINING_IMAGES)\nprint(NUM_VALIDATION_IMAGES)","d06ee36e":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES \/\/ BATCH_SIZE","aa3dcdf7":"early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True)","65ef6a4b":"history = model.fit(\n    train_dataset, epochs=100,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    validation_steps=VALID_STEPS,\n    callbacks=[early_stopping_cb],\n    verbose=1\n)","82a883f6":"epochs = len(history.history['loss'])\nepochs","bc0a041b":"y1 = history.history['loss']\ny2 = history.history['val_loss']\nx = np.arange(1, epochs+1)\n\nplt.plot(x, y1, y2)\nplt.legend(['loss', 'val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.tight_layout()","90ebbcd6":"y1 = history.history['categorical_accuracy']\ny2 = history.history['val_categorical_accuracy']\nx = np.arange(1, epochs+1)\n\nplt.plot(x, y1, y2)\nplt.legend(['categorical_accuracy', 'val_categorical_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('categorical_accuracy')\nplt.tight_layout()","900817c5":"res = model.evaluate(valid_dataset, batch_size=VALID_STEPS)","7cba99c2":"test_dataset = get_test_dataset()\n\nprobs = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","470574f5":"# Model Architecture"}}