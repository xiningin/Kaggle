{"cell_type":{"00fb5b7b":"code","914c0eda":"code","12631d72":"code","b3244fb5":"code","0a93d220":"code","498aee13":"code","85f0ccd6":"code","730d90eb":"code","25aec51c":"code","2446603f":"code","0d4d28c4":"code","e18c172f":"code","65846c32":"code","8c4c7ca8":"code","2e6c68ff":"code","fc3080f0":"markdown","258df5cd":"markdown","357171ec":"markdown","a1286421":"markdown","e6a0f184":"markdown","c382cb3f":"markdown","61cc86dc":"markdown","cf8eb32a":"markdown"},"source":{"00fb5b7b":"# prerequisites\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras.layers import Input, Dense, Lambda\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import objectives\nfrom scipy.stats import norm","914c0eda":"# data load\nfashion_mnist = keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n# (x_tr, y_tr), (x_te, y_te) = fashion_mnist.load_data()\nx_train, x_test = train_images.astype('float32')\/255., test_images.astype('float32')\/255.\nx_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)\nprint(x_train.shape, x_test.shape)\n\n# network parameters\nbatch_size, n_epoch = 100, 50\nn_hidden, z_dim = 256, 2","12631d72":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","b3244fb5":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()","0a93d220":"# encoder\nx = Input(shape=(x_train.shape[1:]))\nx_encoded = Dense(n_hidden, activation='relu')(x)\nx_encoded = Dense(n_hidden\/\/2, activation='relu')(x_encoded)\n\nmu = Dense(z_dim)(x_encoded)\nlog_var = Dense(z_dim)(x_encoded)","498aee13":"# sampling function\ndef sampling(args):\n    mu, log_var = args\n    eps = K.random_normal(shape=(batch_size, z_dim), mean=0., stddev=1.0)\n    return mu + K.exp(log_var) * eps\n\nz = Lambda(sampling, output_shape=(z_dim,))([mu, log_var])","85f0ccd6":"z_decoder1 = Dense(n_hidden\/\/2, activation='relu')\nz_decoder2 = Dense(n_hidden, activation='relu')\ny_decoder = Dense(x_train.shape[1], activation='sigmoid')\n\nz_decoded = z_decoder1(z)\nz_decoded = z_decoder2(z_decoded)\ny = y_decoder(z_decoded)","730d90eb":"# loss\nreconstruction_loss = objectives.binary_crossentropy(x, y) * x_train.shape[1]\nkl_loss = 0.5 * K.sum(K.square(mu) + K.exp(log_var) - log_var - 1, axis = -1)\nvae_loss = reconstruction_loss + kl_loss\n\n# build model\nvae = Model(x, y)\nvae.add_loss(vae_loss)\nvae.compile(optimizer='rmsprop')\nvae.summary()","25aec51c":"# train\nvae.fit(x_train,\n       shuffle=True,\n       epochs=n_epoch,\n       batch_size=batch_size,\n       validation_data=(x_test, None), verbose=1)","2446603f":"# build encoder\nencoder = Model(x, mu)\nencoder.summary()","0d4d28c4":"# Plot of the digit classes in the latent space\nx_test_latent = encoder.predict(x_test, batch_size=batch_size)\nplt.figure(figsize=(6, 6))\nplt.scatter(x_test_latent[:, 0], x_test_latent[:, 1], c=test_labels)\nplt.colorbar()\nplt.show()","e18c172f":"# build decoder\ndecoder_input = Input(shape=(z_dim,))\n_z_decoded = z_decoder1(decoder_input)\n_z_decoded = z_decoder2(_z_decoded)\n_y = y_decoder(_z_decoded)\ngenerator = Model(decoder_input, _y)\ngenerator.summary()","65846c32":"# display a 2D manifold of the digits\nn = 15 # figure with 15x15 digits\ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n\ngrid_x = norm.ppf(np.linspace(0.05, 0.95, n)) \ngrid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]])\n        x_decoded = generator.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n\nplt.figure(figsize=(10, 10))\nplt.imshow(figure, cmap='Greys_r')\nplt.show()","8c4c7ca8":"preview = vae.predict(x_train, batch_size=batch_size)","2e6c68ff":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(preview[i].reshape(28, 28), cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()","fc3080f0":"### Plot the dataset","258df5cd":"### Plot the latente distribution","357171ec":"### Training model","a1286421":"### Enconder part","e6a0f184":"### Decoder part","c382cb3f":"### Reconstruction plot","61cc86dc":"### Plot the prediction generator","cf8eb32a":"# Variational Autoenconder"}}