{"cell_type":{"11b4258a":"code","6e78a458":"code","b36f88ff":"code","1e84a23e":"code","d8922b47":"code","d0a03c54":"code","a89a09c0":"code","bb79dc4f":"code","3a6b1bee":"code","a3770d9e":"code","dc7d8adb":"code","34c4d2f3":"code","1cf3040d":"code","dda02c59":"code","08f5e0ce":"code","ae59d31a":"code","1f83d2a0":"code","da6653fe":"code","b4c46b89":"code","aac1cc85":"code","b1d4013c":"code","5fc694db":"code","23fec14e":"code","a4e87ea0":"code","6385b2ad":"code","d8cf1944":"code","e9f657e0":"code","412cbe5b":"code","095c553e":"code","d43f6392":"code","ba2ddb45":"code","0bdebd99":"code","dfa08793":"code","0732dbd6":"code","51ec9701":"code","83973fc7":"code","e94856a1":"code","0fb0f5e8":"code","cb6641ae":"code","45637b72":"code","824e6975":"code","c2d7bf74":"code","90f161ab":"code","4467b60d":"code","25d9db12":"code","b059f381":"code","0b21b382":"code","e06d94b0":"code","87bf5c7b":"markdown","993fcc89":"markdown","baf0865f":"markdown","c94fe843":"markdown","6c565c34":"markdown","39fef936":"markdown","bfd41d59":"markdown","8dc5f67b":"markdown","c6bb71b1":"markdown","9a8d9e4e":"markdown","8e70fe96":"markdown","4861a69c":"markdown","4549b0b4":"markdown","b67f10db":"markdown","dd363bb6":"markdown","46336063":"markdown","e8de779b":"markdown","1ef76770":"markdown","23c60be7":"markdown","6a826fdd":"markdown","aa6ef009":"markdown","64e9bde5":"markdown","847f598e":"markdown","aa3e389f":"markdown","9c65df87":"markdown","617c3f95":"markdown","52c81f1e":"markdown","9b0ee15e":"markdown","6689f138":"markdown","f96489ab":"markdown","3ecd041a":"markdown","decbc1c5":"markdown","b54a9e3b":"markdown","9e569f92":"markdown","dde9b1e7":"markdown","ffcfe7f8":"markdown","06c72f64":"markdown"},"source":{"11b4258a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_selection import RFE","6e78a458":"train_label = pd.read_csv('..\/input\/bigcontest2019\/train_label.csv')\nprint(\"train_lable shape: {}\".format(train_label.shape))","b36f88ff":"train_act = pd.read_csv('..\/input\/bigcontest2019\/train_activity.csv')\ntest1_act = pd.read_csv('..\/input\/bigcontest2019\/test1_activity.csv')\ntest2_act = pd.read_csv('..\/input\/bigcontest2019\/test2_activity.csv')\n\nprint(\"train_activity shape: {}\".format(train_act.shape))\nprint(\"test1_activity shape: {}\".format(test1_act.shape))\nprint(\"test2_activity shape: {}\".format(test2_act.shape))\n\ntrain_act['Train_or_Test'] = \"Train\"\ntest1_act['Train_or_Test'] = \"Test1\"\ntest2_act['Train_or_Test'] = \"Test2\"\n\nall_act = pd.concat([train_act,test1_act,test2_act],axis= 0)","1e84a23e":"train_trade = pd.read_csv('..\/input\/bigcontest2019\/train_trade.csv')\ntest1_trade = pd.read_csv('..\/input\/bigcontest2019\/test1_trade.csv')\ntest2_trade = pd.read_csv('..\/input\/bigcontest2019\/test2_trade.csv')\n\nprint(\"train_trade shape: {}\".format(train_trade.shape))\nprint(\"test1_trade shape: {}\".format(test1_trade.shape))\nprint(\"test2_trade shape: {}\".format(test2_trade.shape))\n\ntrain_trade['Train_or_Test'] = \"Train\"\ntest1_trade['Train_or_Test'] = \"Test1\"\ntest2_trade['Train_or_Test'] = \"Test2\"\n\nall_trade = pd.concat([train_trade, test1_trade, test2_trade], axis=0)","d8922b47":"train_combat = pd.read_csv('..\/input\/bigcontest2019\/train_combat.csv')\ntest1_combat = pd.read_csv('..\/input\/bigcontest2019\/test1_combat.csv')\ntest2_combat = pd.read_csv('..\/input\/bigcontest2019\/test2_combat.csv')\n\nprint(\"train_combat.csv: {}\".format(train_combat.shape))\nprint(\"test1_combat.csv: {}\".format(test1_combat.shape))\nprint(\"test2_combat.csv: {}\".format(test2_combat.shape))\n\ntrain_combat['Train_or_Test'] = \"Train\"\ntest1_combat['Train_or_Test'] = 'Test1'\ntest2_combat['Train_or_Test'] = 'Test2'\n\nall_combat = pd.concat([train_combat,test1_combat,test2_combat])","d0a03c54":"train_pledge = pd.read_csv('..\/input\/bigcontest2019\/train_pledge.csv')\ntest1_pledge = pd.read_csv('..\/input\/bigcontest2019\/test1_pledge.csv')\ntest2_pledge = pd.read_csv('..\/input\/bigcontest2019\/test2_pledge.csv')\n\nprint(\"train_pledge shape: {}\".format(train_pledge.shape))\nprint(\"test1_pledge shape: {}\".format(test1_pledge.shape))\nprint(\"test2_pledge shape: {}\".format(test2_pledge.shape))\n\ntrain_pledge['Train_or_Test'] = 'Train'\ntest1_pledge['Train_or_Test'] = 'Test1'\ntest2_pledge['Train_or_Test'] = 'Test2'\n\nall_pledge = pd.concat([train_pledge,test1_pledge,test2_pledge])","a89a09c0":"train_pay = pd.read_csv('..\/input\/bigcontest2019\/train_payment.csv')\ntest1_pay = pd.read_csv('..\/input\/bigcontest2019\/test1_payment.csv')\ntest2_pay = pd.read_csv('..\/input\/bigcontest2019\/test2_payment.csv')\n\nprint(\"train payment shape : {}\".format(train_pay.shape))\nprint(\"test1 payment shape : {}\".format(test1_pay.shape))\nprint(\"test2 payment shape : {}\".format(test2_pay.shape))\n\ntrain_pay['Train_or_Test'] = 'Train'\ntest1_pay['Train_or_Test'] = 'Test1'\ntest2_pay['Train_or_Test'] = 'Test2'\n\nall_pay = pd.concat([train_pay,test1_pay,test2_pay])","bb79dc4f":"validation_acc = pd.read_csv('..\/input\/bigcontest2019\/train_valid_user_id.csv')","3a6b1bee":"def make_week_variable(df):\n    df['week'] = np.nan\n    df['week'][df['day'] <= 7] = 1\n    df['week'][(df['day']>7) & (df['day'] <= 14)] = 2\n    df['week'][(df['day']>14) & (df['day'] <= 21)] = 3\n    df['week'][df['day'] > 21] = 4\n    print(\"Create Week Variable in DataFrame\")","a3770d9e":"for i,name in enumerate([train_act,train_trade,train_combat,train_pledge,train_pay]):\n    make_week_variable(name)\n    print(\"No. {} Train DataFrame Success\".format(i+1))\n    print(\"\\n\")\n\nfor i,name in enumerate([test1_act,test1_trade,test1_combat,test1_pledge,test1_pay]):\n    make_week_variable(name)\n    print(\"No. {} Test1 DataFrame Success\".format(i+1))\n    print(\"\\n\")\n    \nfor i,name in enumerate([test2_act,test2_trade,test2_combat,test2_pledge,test2_pay]):\n    make_week_variable(name)\n    print(\"No. {} Test2 DataFrame Success\".format(i+1))\n    print(\"\\n\")","dc7d8adb":"train = train_act.groupby(['acc_id','server','char_id']).day.count().reset_index().groupby('acc_id').day.max().reset_index()\ntrain.columns  =['acc_id','total_day']\ntrain = pd.merge(train, train_label, on = 'acc_id', how = 'inner')\n\ntest1 = test1_act.groupby(['acc_id','server','char_id']).day.count().reset_index().groupby('acc_id').day.max().reset_index()\ntest1.columns = ['acc_id','total_day']\nprint(test1.shape)\n\ntest2 = test2_act.groupby(['acc_id','server','char_id']).day.count().reset_index().groupby('acc_id').day.max().reset_index()\ntest2.columns = ['acc_id','total_day']\nprint(test2.shape)","34c4d2f3":"total_char_id = train_act[['acc_id','server','char_id']].drop_duplicates().groupby('acc_id').char_id.count().reset_index()\ntotal_char_id.columns = ['acc_id','total_char']\ntrain = pd.merge(train, total_char_id, on ='acc_id', how='left')\n\ntotal_char_id = test1_act[['acc_id','server','char_id']].drop_duplicates().groupby('acc_id').char_id.count().reset_index()\ntotal_char_id.columns = ['acc_id', 'total_char']\ntest1 = pd.merge(test1, total_char_id, on = 'acc_id', how = 'left')\n\ntotal_char_id = test2_act[['acc_id','server','char_id']].drop_duplicates().groupby('acc_id').char_id.count().reset_index()\ntotal_char_id.columns = ['acc_id','total_char']\ntest2 = pd.merge(test2, total_char_id, on = 'acc_id', how = 'left')","1cf3040d":"playtime_by_day = train_act.groupby(['day','acc_id']).playtime.sum().reset_index().groupby('acc_id').agg({'playtime':['std','mean']})\nplaytime_by_day.columns = ['std_playtime','avg_playtime']\ntrain = pd.merge(train, playtime_by_day, on='acc_id', how='left')\ntrain = train.fillna(0)\n\nplaytime_by_day = test1_act.groupby(['day','acc_id']).playtime.sum().reset_index().groupby('acc_id').agg({'playtime':['std','mean']})\nplaytime_by_day.columns = ['std_playtime','avg_playtime']\ntest1 = pd.merge(test1, playtime_by_day, on='acc_id', how='left')\ntest1 = test1.fillna(0)\n\nplaytime_by_day = test2_act.groupby(['day','acc_id']).playtime.sum().reset_index().groupby('acc_id').agg({'playtime':['std','mean']})\nplaytime_by_day.columns = ['std_playtime','avg_playtime']\ntest2 = pd.merge(test2, playtime_by_day, on='acc_id', how='left')\ntest2 = test2.fillna(0)","dda02c59":"def make_variable_about_week(df,col,target_df):\n    change = df[['acc_id','server','char_id',col,'week']].drop_duplicates().groupby(['acc_id','week'])[col].sum().unstack()\n    change = change.fillna(0)\n    change.columns = ['{}_week{}'.format(col,i+1) for i in range(4)]\n    target_df = pd.merge(target_df, change, on = 'acc_id', how = 'left')\n    \n    return target_df.head()","08f5e0ce":"party_exp_change = train_act[['acc_id','server','char_id','party_exp','week']].drop_duplicates().groupby(['acc_id','week']).party_exp.sum().unstack()\nparty_exp_change = party_exp_change.fillna(0)\nparty_exp_change.columns = ['party_exp_week{}'.format(i+1) for i in range(4)]\ntrain = pd.merge(train, party_exp_change, on = 'acc_id',how = 'left')\n\nparty_exp_change = test1_act[['acc_id','server','char_id','party_exp','week']].drop_duplicates().groupby(['acc_id','week']).party_exp.sum().unstack()\nparty_exp_change = party_exp_change.fillna(0)\nparty_exp_change.columns = ['party_exp_week{}'.format(i+1) for i in range(4)]\ntest1 = pd.merge(test1, party_exp_change, on = 'acc_id', how = 'left')\n\nparty_exp_change = test2_act[['acc_id','server','char_id','party_exp','week']].drop_duplicates().groupby(['acc_id','week']).party_exp.sum().unstack()\nparty_exp_change = party_exp_change.fillna(0)\nparty_exp_change.columns = ['party_exp_week{}'.format(i+1) for i in range(4)]\ntest2 = pd.merge(test2, party_exp_change, on = 'acc_id', how = 'left')","ae59d31a":"train['change_party_exp'] = (train['party_exp_week4']+train['party_exp_week3'])\/(train['party_exp_week2']+train['party_exp_week1'])\ntrain.replace([np.inf, -np.inf], np.nan,inplace = True)\ntrain = train.fillna(0)\ntrain[['party_exp_week4','party_exp_week3','party_exp_week2','party_exp_week1','change_party_exp']].head()\n\ntest1['change_party_exp'] = (test1['party_exp_week4']+test1['party_exp_week3'])\/(test1['party_exp_week2']+test1['party_exp_week1'])\ntest1.replace([np.inf, -np.inf],np.nan,inplace = True)\ntest1 = test1.fillna(0)\n\ntest2['change_party_exp'] = (test2['party_exp_week4']+test2['party_exp_week3'])\/(test2['party_exp_week2']+test2['party_exp_week1'])\ntest2.replace([np.inf, -np.inf],np.nan,inplace = True)\ntest2 = test2.fillna(0)","1f83d2a0":"death_change = train_act[['acc_id','server','char_id','death','week']].drop_duplicates().groupby(['acc_id','week']).death.sum().unstack()\ndeath_change = death_change.fillna(0)\ndeath_change.columns = ['death_cnt_week{}'.format(i+1) for i in range(4)]\ntrain = pd.merge(train,death_change, on = 'acc_id', how = 'left')\n\ndeath_change = test1_act[['acc_id','server','char_id','death','week']].drop_duplicates().groupby(['acc_id','week']).death.sum().unstack()\ndeath_change = death_change.fillna(0)\ndeath_change.columns = ['death_cnt_week{}'.format(i+1) for i in range(4)]\ntest1 = pd.merge(test1, death_change, on = 'acc_id', how = 'left')\n\ndeath_change = test2_act[['acc_id','server','char_id','death','week']].drop_duplicates().groupby(['acc_id','week']).death.sum().unstack()\ndeath_change = death_change.fillna(0)\ndeath_change.columns = ['death_cnt_week{}'.format(i+1) for i in range(4)]\ntest2 = pd.merge(test2, death_change, on = 'acc_id', how ='left')","da6653fe":"train['change_death_cnt'] = (train['death_cnt_week4']+train['death_cnt_week3'])\/(train['death_cnt_week2']+train['death_cnt_week1'])\ntrain.replace([np.inf, -np.inf], np.nan,inplace = True)\ntrain = train.fillna(0)\ntrain[['death_cnt_week4','death_cnt_week3','death_cnt_week2','death_cnt_week1','change_death_cnt']].head()\n\ntest1['change_death_cnt'] = (test1['death_cnt_week4']+test1['death_cnt_week3'])\/(test1['death_cnt_week2']+test1['death_cnt_week1'])\ntest1.replace([np.inf, -np.inf], np.nan,inplace = True)\ntest1 = test1.fillna(0)\n\ntest2['change_death_cnt'] = (test2['death_cnt_week4']+test2['death_cnt_week3'])\/(test2['death_cnt_week2']+test2['death_cnt_week1'])\ntest2.replace([np.inf, -np.inf], np.nan,inplace = True)\ntest2 = test2.fillna(0)","b4c46b89":"adena_change = train_act[['acc_id','server','char_id','game_money_change','week']].drop_duplicates().groupby(['acc_id','week']).game_money_change.sum().unstack()\nadena_change = adena_change.fillna(0)\nadena_change.columns = ['adena_change_week{}'.format(i+1) for i in range(4)]\ntrain = pd.merge(train, adena_change, on = 'acc_id', how = 'left')\n\nadena_change = test1_act[['acc_id','server','char_id','game_money_change','week']].drop_duplicates().groupby(['acc_id','week']).game_money_change.sum().unstack()\nadena_change = adena_change.fillna(0)\nadena_change.columns = ['adena_change_week{}'.format(i+1) for i in range(4)]\ntest1 = pd.merge(test1,adena_change, on = 'acc_id', how = 'left')\n\nadena_change = test2_act[['acc_id','server','char_id','game_money_change','week']].drop_duplicates().groupby(['acc_id','week']).game_money_change.sum().unstack()\nadena_change = adena_change.fillna(0)\nadena_change.columns = ['adena_change_week{}'.format(i+1) for i in range(4)]\ntest2 = pd.merge(test2, adena_change, on = 'acc_id', how = 'left')","aac1cc85":"train['change_adena'] = (train['adena_change_week4']+train['adena_change_week3'])\/(train['adena_change_week2']+train['adena_change_week1'])\ntrain.replace([np.inf, -np.inf], np.nan,inplace = True)\ntrain = train.fillna(0)\ntrain[['adena_change_week4','adena_change_week3','adena_change_week2','adena_change_week1','change_adena']].head()\n\ntest1['change_adena'] = (test1['adena_change_week4']+test1['adena_change_week3'])\/(test1['adena_change_week2']+test1['adena_change_week1'])\ntest1.replace([np.inf, -np.inf], np.nan, inplace = True)\ntest1 = test1.fillna(0)\n\ntest2['change_adena'] = (test2['adena_change_week4']+test2['adena_change_week3'])\/(test2['adena_change_week2']+test2['adena_change_week1'])\ntest2.replace([np.inf, -np.inf], np.nan, inplace = True)\ntest2 = test2.fillna(0)","b1d4013c":"revive_change = train_act[['acc_id','server','char_id','revive','week']].drop_duplicates().groupby(['acc_id','week']).revive.sum().unstack()\nrevive_change = revive_change.fillna(0)\nrevive_change.columns = ['revive_change_week{}'.format(i+1) for i in range(4)]\ntrain = pd.merge(train, revive_change, on = 'acc_id', how = 'left')\n\nrevive_change = test1_act[['acc_id','server','char_id','revive','week']].drop_duplicates().groupby(['acc_id','week']).revive.sum().unstack()\nrevive_change = revive_change.fillna(0)\nrevive_change.columns = ['revive_change_week{}'.format(i+1) for i in range(4)]\ntest1 = pd.merge(test1, revive_change, on = 'acc_id', how = 'left')\n\nrevive_change = test2_act[['acc_id','server','char_id','revive','week']].drop_duplicates().groupby(['acc_id','week']).revive.sum().unstack()\nrevive_change = revive_change.fillna(0)\nrevive_change.columns = ['revive_change_week{}'.format(i+1) for i in range(4)]\ntest2 = pd.merge(test2, revive_change, on ='acc_id', how = 'left')","5fc694db":"train['change_revive'] = (train['revive_change_week4']+train['revive_change_week3'])\/(train['revive_change_week2']+train['revive_change_week1'])\ntrain.replace([np.inf, -np.inf], np.nan,inplace = True)\ntrain = train.fillna(0)\ntrain[['revive_change_week4','revive_change_week3','revive_change_week2','revive_change_week1','change_revive']].head()\n\ntest1['change_revive'] = (test1['revive_change_week4']+test1['revive_change_week3'])\/(test1['revive_change_week2']+test1['revive_change_week1'])\ntest1.replace([np.inf, -np.inf], np.nan,inplace = True)\ntest1 = test1.fillna(0)\n\ntest2['change_revive'] = (test2['revive_change_week4']+test2['revive_change_week3'])\/(test2['revive_change_week2']+test2['revive_change_week1'])\ntest2.replace([np.inf, -np.inf], np.nan,inplace = True)\ntest2 = test2.fillna(0)","23fec14e":"private_change = train_act[['acc_id','server','char_id','private_shop','week']].drop_duplicates().groupby(['acc_id','week']).private_shop.sum().unstack()\nprivate_change = private_change.fillna(0)\nprivate_change.columns = ['private_shop_change_week{}'.format(i+1) for i in range(4)]\ntrain = pd.merge(train,private_change, on = 'acc_id', how ='left')\n\nprivate_change = test1_act[['acc_id','server','char_id','private_shop','week']].drop_duplicates().groupby(['acc_id','week']).private_shop.sum().unstack()\nprivate_change = private_change.fillna(0)\nprivate_change.columns = ['private_shop_change_week{}'.format(i+1) for i in range(4)]\ntest1 = pd.merge(test1,private_change, on = 'acc_id', how ='left')\n\nprivate_change = test2_act[['acc_id','server','char_id','private_shop','week']].drop_duplicates().groupby(['acc_id','week']).private_shop.sum().unstack()\nprivate_change = private_change.fillna(0)\nprivate_change.columns = ['private_shop_change_week{}'.format(i+1) for i in range(4)]\ntest2 = pd.merge(test2,private_change, on = 'acc_id', how ='left')","a4e87ea0":"test1.head()","6385b2ad":"train['change_private_shop'] = (train['private_shop_change_week4']+train['private_shop_change_week3'])\/(train['private_shop_change_week2']+train['private_shop_change_week1'])\ntrain.replace([np.inf, -np.inf], np.nan,inplace = True)\ntrain = train.fillna(0)\ntrain[['private_shop_change_week4','private_shop_change_week3','private_shop_change_week2','private_shop_change_week1','change_private_shop']].head()\n\ntest1['change_private_shop'] = (test1['private_shop_change_week4']+test1['private_shop_change_week3'])\/(test1['private_shop_change_week2']+test1['private_shop_change_week1'])\ntest1.replace([np.inf, -np.inf], np.nan,inplace = True)\ntest1 = test1.fillna(0)\n\ntest2['change_private_shop'] = (test2['private_shop_change_week4']+test2['private_shop_change_week3'])\/(test2['private_shop_change_week2']+test2['private_shop_change_week1'])\ntest2.replace([np.inf, -np.inf], np.nan,inplace = True)\ntest2 = test2.fillna(0)","d8cf1944":"del party_exp_change, death_change, adena_change, revive_change, private_change","e9f657e0":"all_trade['hour'] = all_trade['time'].str.split(':',expand = True)[0]\n\ntrade_buy = all_trade.copy()\ntrade_sell = all_trade.copy()\n\ntrade_buy['trade_type'] = 'Buy'\ntrade_sell['trade_type'] = 'Sell'\n\ntrade_buy.drop(['source_acc_id','source_char_id'], axis = 1, inplace= True)\ntrade_sell.drop(['target_acc_id','target_char_id'], axis = 1, inplace = True)\n\ntrade_buy = trade_buy.rename(columns = {'target_acc_id':'acc_id','target_char_id':'char_id'})\ntrade_sell = trade_sell.rename(columns = {'source_acc_id':'acc_id','source_char_id':'char_id'})","412cbe5b":"item_type_buy = pd.crosstab(trade_buy.loc[trade_buy['Train_or_Test']=='Train']['acc_id'], trade_buy.loc[trade_buy['Train_or_Test']=='Train']['item_type'])\nitem_type_buy.rename(columns = {'accessory':'get_accessory','adena':'get_adena',\n                               'armor':'get_armor','enchant_scroll':'get_enchant_scroll',\n                               'etc':'get_etc','spell':'get_spell','weapon':'get_weapon'},inplace= True)\ntrain = pd.merge(train, item_type_buy, on = 'acc_id',how = 'left')\n\n\nitem_type_sell = pd.crosstab(trade_sell.loc[trade_buy['Train_or_Test']=='Train']['acc_id'], trade_sell.loc[trade_buy['Train_or_Test']=='Train']['item_type'])\nitem_type_sell.rename(columns = {'accessory':'put_accessory','adena':'put_adena',\n                               'armor':'put_armor','enchant_scroll':'put_enchant_scroll',\n                               'etc':'put_etc','spell':'put_spell','put':'put_weapon'},inplace=True)\ntrain = pd.merge(train, item_type_sell, on = 'acc_id',how = 'left')\n\ntrain = train.fillna(0)\ntrain.head()\n\n######################################################################\n\nitem_type_buy = pd.crosstab(trade_buy.loc[trade_buy['Train_or_Test']=='Test1']['acc_id'], trade_buy.loc[trade_buy['Train_or_Test'] == 'Test1']['item_type'])\nitem_type_buy.rename(columns = {'accessory':'get_accessory','adena':'get_adena',\n                               'armor':'get_armor','enchant_scroll':'get_enchant_scroll',\n                               'etc':'get_ect','spell':'get_spell','weapon':'get_weapon'},inplace= True)\ntest1 = pd.merge(test1, item_type_buy, on = 'acc_id', how = 'left')\n\nitem_type_sell = pd.crosstab(trade_sell.loc[trade_buy['Train_or_Test']=='Test1']['acc_id'], trade_sell.loc[trade_buy['Train_or_Test']=='Test1']['item_type'])\nitem_type_sell.rename(columns = {'accessory':'put_accessory','adena':'put_adena',\n                               'armor':'put_armor','enchant_scroll':'put_enchant_scroll',\n                               'etc':'put_etc','spell':'put_spell','put':'put_weapon'},inplace=True)\ntest1 = pd.merge(test1, item_type_sell, on = 'acc_id',how = 'left')\n\ntest1 = test1.fillna(0)\n#\nitem_type_buy = pd.crosstab(trade_buy.loc[trade_buy['Train_or_Test']=='Test2']['acc_id'], trade_buy.loc[trade_buy['Train_or_Test'] == 'Test2']['item_type'])\nitem_type_buy.rename(columns = {'accessory':'get_accessory','adena':'get_adena',\n                               'armor':'get_armor','enchant_scroll':'get_enchant_scroll',\n                               'etc':'get_ect','spell':'get_spell','weapon':'get_weapon'},inplace= True)\ntest2 = pd.merge(test2, item_type_buy, on = 'acc_id', how = 'left')\n\nitem_type_sell = pd.crosstab(trade_sell.loc[trade_buy['Train_or_Test']=='Test2']['acc_id'], trade_sell.loc[trade_buy['Train_or_Test']=='Test2']['item_type'])\nitem_type_sell.rename(columns = {'accessory':'put_accessory','adena':'put_adena',\n                               'armor':'put_armor','enchant_scroll':'put_enchant_scroll',\n                               'etc':'put_etc','spell':'put_spell','put':'put_weapon'},inplace=True)\ntest2 = pd.merge(test2, item_type_sell, on = 'acc_id',how = 'left')\n\ntest2 = test2.fillna(0)\n\n","095c553e":"char_level = train_combat.groupby(['acc_id']).agg({'level': 'mean'})\nchar_level.columns = ['mean_level']\ntrain = pd.merge(train, char_level, on = 'acc_id', how = 'left')\n\nchar_level = test1_combat.groupby(['acc_id']).agg({'level':'mean'})\nchar_level.columns = ['mean_level']\ntest1 = pd.merge(test1, char_level, on ='acc_id', how = 'left')\n\nchar_level = test2_combat.groupby(['acc_id']).agg({'level':'mean'})\nchar_level.columns = ['mean_level']\ntest2 = pd.merge(test2, char_level, on ='acc_id', how = 'left')","d43f6392":"class_by_user = train_combat[['acc_id','server','char_id','class']].drop_duplicates().groupby(['acc_id','class']).char_id.count().unstack()\nclass_by_user = class_by_user.fillna(0)\nclass_by_user.columns = ['class{}'.format(i) for i in range(8)]\ntrain = pd.merge(train, class_by_user, on = 'acc_id', how = 'left')\n\nclass_by_user = test1_combat[['acc_id','server','char_id','class']].drop_duplicates().groupby(['acc_id','class']).char_id.count().unstack()\nclass_by_user = class_by_user.fillna(0)\nclass_by_user.columns = ['class{}'.format(i) for i in range(8)]\ntest1 = pd.merge(test1, class_by_user, on='acc_id', how='left')\n\nclass_by_user = test2_combat[['acc_id','server','char_id','class']].drop_duplicates().groupby(['acc_id','class']).char_id.count().unstack()\nclass_by_user = class_by_user.fillna(0)\nclass_by_user.columns = ['class{}'.format(i) for i in range(8)]\ntest2 = pd.merge(test2, class_by_user, on='acc_id', how='left')","ba2ddb45":"random_df = train_combat.groupby('acc_id').agg({'random_attacker_cnt':'sum','random_defender_cnt':'sum'})\nrandom_df.columns = ['total_random_attacker_cnt','total_random_defender_cnt']\ntrain = pd.merge(train, random_df, on='acc_id', how='left')\n\nrandom_df = test1_combat.groupby('acc_id').agg({'random_attacker_cnt':'sum','random_defender_cnt':'sum'})\nrandom_df.columns = ['total_random_attacker_cnt','total_random_defender_cnt']\ntest1 = pd.merge(test1, random_df, on='acc_id', how='left')\n\nrandom_df = test2_combat.groupby('acc_id').agg({'random_attacker_cnt':'sum','random_defender_cnt':'sum'})\nrandom_df.columns = ['total_random_attacker_cnt','total_random_defender_cnt']\ntest2 = pd.merge(test2, random_df, on='acc_id', how='left')","0bdebd99":"temp_df = train_combat[['acc_id','server','char_id','temp_cnt','week']].drop_duplicates().groupby(['acc_id','week']).temp_cnt.sum().unstack()\ntemp_df.columns = ['temp_cnt_week{}'.format(i+1) for i in range(4)]\ntemp_df = temp_df.fillna(0)\ntrain = pd.merge(train,temp_df, on = 'acc_id', how = 'left')\n\ntemp_df = test1_combat[['acc_id','server','char_id','temp_cnt','week']].drop_duplicates().groupby(['acc_id','week']).temp_cnt.sum().unstack()\ntemp_df.columns = ['temp_cnt_week{}'.format(i+1) for i in range(4)]\ntemp_df = temp_df.fillna(0)\ntest1 = pd.merge(test1, temp_df, on = 'acc_id', how = 'left')\n\ntemp_df = test2_combat[['acc_id','server','char_id','temp_cnt','week']].drop_duplicates().groupby(['acc_id','week']).temp_cnt.sum().unstack()\ntemp_df.columns = ['temp_cnt_week{}'.format(i+1) for i in range(4)]\ntemp_df = temp_df.fillna(0)\ntest2 = pd.merge(test2, temp_df, on = 'acc_id', how = 'left')","dfa08793":"pledge_df = train_combat[['acc_id','server','char_id','pledge_cnt','week']].drop_duplicates().groupby(['acc_id','week']).pledge_cnt.sum().unstack()\npledge_df.columns = ['pledge_cnt_week{}'.format(i+1) for i in range(4)]\npledge_df = pledge_df.fillna(0)\ntrain = pd.merge(train,pledge_df, on = 'acc_id', how = 'left')\n\npledge_df = test1_combat[['acc_id','server','char_id','pledge_cnt','week']].drop_duplicates().groupby(['acc_id','week']).pledge_cnt.sum().unstack()\npledge_df.columns = ['pledge_cnt_week{}'.format(i+1) for i in range(4)]\npledge_df = pledge_df.fillna(0)\ntest1 = pd.merge(test1, pledge_df, on = 'acc_id', how = 'left')\n\npledge_df = test2_combat[['acc_id','server','char_id','pledge_cnt','week']].drop_duplicates().groupby(['acc_id','week']).pledge_cnt.sum().unstack()\npledge_df.columns = ['pledge_cnt_week{}'.format(i+1) for i in range(4)]\npledge_df = pledge_df.fillna(0)\ntest2 = pd.merge(test2, pledge_df, on = 'acc_id', how = 'left')","0732dbd6":"etc_df = train_combat[['acc_id','server','char_id','etc_cnt','week']].drop_duplicates().groupby(['acc_id','week']).etc_cnt.sum().unstack()\netc_df.columns = ['etc_cnt_week{}'.format(i+1) for i in range(4)]\netc_df = etc_df.fillna(0)\ntrain = pd.merge(train,etc_df, on = 'acc_id', how = 'left')\n\netc_df = test1_combat[['acc_id','server','char_id','etc_cnt','week']].drop_duplicates().groupby(['acc_id','week']).etc_cnt.sum().unstack()\netc_df.columns = ['etc_cnt_week{}'.format(i+1) for i in range(4)]\netc_df = etc_df.fillna(0)\ntest1 = pd.merge(test1, etc_df, on = 'acc_id', how = 'left')\n\netc_df = test2_combat[['acc_id','server','char_id','etc_cnt','week']].drop_duplicates().groupby(['acc_id','week']).etc_cnt.sum().unstack()\netc_df.columns = ['etc_cnt_week{}'.format(i+1) for i in range(4)]\netc_df = etc_df.fillna(0)\ntest2 = pd.merge(test2, etc_df, on = 'acc_id', how = 'left')","51ec9701":"combat_pledge_df = pd.merge(train_combat,train_pledge, on = ['day','acc_id','char_id','server'], how = 'left')\npledge_level_df = combat_pledge_df.groupby(['pledge_id','server']).agg({'level':'mean'})\npledge_level_df = pledge_level_df.fillna(0)\npledge_level_df.columns = ['pledge_mean_level']\ntrain_pledge = pd.merge(train_pledge,pledge_level_df, on = 'pledge_id', how = 'left')\n\ncombat_pledge_df = pd.merge(test1_combat,test1_pledge, on = ['day','acc_id','char_id','server'], how = 'left')\npledge_level_df = combat_pledge_df.groupby(['pledge_id','server']).agg({'level':'mean'})\npledge_level_df = pledge_level_df.fillna(0)\npledge_level_df.columns = ['pledge_mean_level']\ntest1_pledge = pd.merge(test1_pledge,pledge_level_df, on = 'pledge_id', how = 'left')\n\ncombat_pledge_df = pd.merge(test2_combat,test2_pledge, on = ['day','acc_id','char_id','server'], how = 'left')\npledge_level_df = combat_pledge_df.groupby(['pledge_id','server']).agg({'level':'mean'})\npledge_level_df = pledge_level_df.fillna(0)\npledge_level_df.columns = ['pledge_mean_level']\ntest2_pledge = pd.merge(test2_pledge,pledge_level_df, on = 'pledge_id', how = 'left')","83973fc7":"pledge_level_df = train_pledge.groupby('acc_id').agg({'pledge_mean_level':'mean'})\ntrain = pd.merge(train,pledge_level_df, on = 'acc_id', how = 'left')\ntrain = train.fillna(0)\n\npledge_level_df = test1_pledge.groupby('acc_id').agg({'pledge_mean_level':'mean'})\ntest1 = pd.merge(test1,pledge_level_df, on = 'acc_id', how = 'left')\ntest1 = test1.fillna(0)\n\npledge_level_df = test2_pledge.groupby('acc_id').agg({'pledge_mean_level':'mean'})\ntest2 = pd.merge(test2,pledge_level_df, on = 'acc_id', how = 'left')\ntest2 = test2.fillna(0)","e94856a1":"train['pledge_belonging'] = train.mean_level \/ train.pledge_mean_level\ntrain.replace([np.inf, -np.inf], np.nan,inplace = True)\ntrain = train.fillna(0)\n\ntest1['pledge_belonging'] = test1.mean_level \/ test1.pledge_mean_level\ntest1.replace([np.inf,-np.inf], np.nan, inplace= True)\ntest1 = test1.fillna(0)\n\ntest2['pledge_belonging'] = test2.mean_level \/ test2.pledge_mean_level\ntest2.replace([np.inf, -np.inf], np.nan, inplace = True)\ntest2 = test2.fillna(0)","0fb0f5e8":"amount_by_acc_id = train_pay.groupby('acc_id').agg({'amount_spent':['max','median','sum']})\namount_by_acc_id.columns = ['max_amount','median_amount','total_amount']\ntrain = pd.merge(train, amount_by_acc_id, on='acc_id', how='left')\ntrain = train.fillna(0)\n\namount_by_acc_id = test1_pay.groupby('acc_id').agg({'amount_spent':['max','median','sum']})\namount_by_acc_id.columns = ['max_amount','median_amount','total_amount']\ntest1 = pd.merge(test1, amount_by_acc_id, on='acc_id', how='left')\ntest1 = test1.fillna(0)\n\namount_by_acc_id = test2_pay.groupby('acc_id').agg({'amount_spent':['max','median','sum']})\namount_by_acc_id.columns = ['max_amount','median_amount','total_amount']\ntest2 = pd.merge(test2, amount_by_acc_id, on='acc_id', how='left')\ntest2 = test2.fillna(0)","cb6641ae":"amount_by_acc_id = train_pay[['acc_id','week','amount_spent']].drop_duplicates().groupby(['acc_id','week']).amount_spent.sum().unstack()\namount_by_acc_id.columns = ['amount_spent_week{}'.format(i+1) for i in range(4)]\ntrain = pd.merge(train, amount_by_acc_id, on = 'acc_id',how = 'left')\ntrain = train.fillna(0)\n\namount_by_acc_id = test1_pay[['acc_id','week','amount_spent']].drop_duplicates().groupby(['acc_id','week']).amount_spent.sum().unstack()\namount_by_acc_id.columns = ['amount_spent_week{}'.format(i+1) for i in range(4)]\ntest1 = pd.merge(test1, amount_by_acc_id, on = 'acc_id', how = 'left')\ntest1 = test1.fillna(0)\n\namount_by_acc_id = test2_pay[['acc_id','week','amount_spent']].drop_duplicates().groupby(['acc_id','week']).amount_spent.sum().unstack()\namount_by_acc_id.columns = ['amount_spent_week{}'.format(i+1) for i in range(4)]\ntest2 = pd.merge(test2, amount_by_acc_id,on = 'acc_id',how = 'left')\ntest2 = test2.fillna(0)","45637b72":"train.to_csv('Train.csv',index = False)\ntest1.to_csv('Test1.csv',index = False)\ntest2.to_csv('Test2.csv',index = False)","824e6975":"train_index = validation_acc[validation_acc.set == 'Train'].acc_id\nvalid_index = validation_acc[validation_acc.set == 'Validation'].acc_id\n\ntrain_set = train[train['acc_id'].isin(train_index)]\nvalid_set = train[train['acc_id'].isin(valid_index)]\n\nprint('Train set:',train_set.shape)\nprint('Valid set:',valid_set.shape)","c2d7bf74":"def survival64(y_pred, dataset):\n    y_true = dataset.get_label()\n    y_pred = np.array([64 if x > 64 else x for x in y_pred])\n    y_pred = np.array([0 if x < 0 else x for x in y_pred])\n    y_pred = np.round(y_pred)\n    error = np.sqrt(mean_squared_error(y_true, y_pred))\n    return 'error', error, False","90f161ab":"lgb_params = {'n_estimators': 1000,\n             'seed': 123}\n\nlgb_train_amount = lgb.Dataset(train_set.drop(['acc_id','amount_spent','survival_time'],axis = 1),\n                              train_set.amount_spent)\nlgb_train_survival = lgb.Dataset(train_set.drop(['acc_id','amount_spent','survival_time'],axis = 1),\n                                train_set.survival_time)","4467b60d":"lgb_amount = lgb.train(lgb_params,\n                      lgb_train_amount,\n                      feval = survival64,\n                      valid_sets = [lgb_train_amount],\n                      verbose_eval=100)\n\nlgb_amount_pred = lgb_amount.predict(valid_set.drop(['acc_id','amount_spent','survival_time'], axis=1))\nlgb_amount_pred = pd.Series(lgb_amount_pred).apply(lambda x: 0 if x < 0 else x)","25d9db12":"lgb_survival = lgb.train(lgb_params,\n                        lgb_train_survival,\n                        feval =survival64,\n                        valid_sets = [lgb_train_survival],\n                        verbose_eval = 100)\n\nlgb_survival_pred = lgb_survival.predict(valid_set.drop(['acc_id','amount_spent','survival_time'], axis=1))\nlgb_survival_pred = pd.Series(lgb_survival_pred).apply(lambda x: 64 if x > 64 else x)\nlgb_survival_pred = lgb_survival_pred.apply(lambda x: 0 if x < 0 else x).round()","b059f381":"lgb_pred_df = pd.DataFrame({'acc_id':valid_set.acc_id.values,\n                           'survival_time':lgb_survival_pred,\n                           'amount_spent':lgb_amount_pred})\nprint('lgb_pred_df shape: ',lgb_pred_df.shape)","0b21b382":"def score_function(predict, actual):\n    \n    # predict = pd.read_csv(predict_label, engine='python') # \uc608\uce21 \ub2f5\uc548 \ud30c\uc77c \ubd88\ub7ec\uc624\uae30\n    # actual = pd.read_csv(actual_label,engine='python') # \uc2e4\uc81c \ub2f5\uc548 \ud30c\uc77c \ubd88\ub7ec\uc624\uae30\n\n\n    predict.acc_id = predict.acc_id.astype('int')\n    predict = predict.sort_values(by =['acc_id'], axis = 0) # \uc608\uce21 \ub2f5\uc548\uc744 acc_id \uae30\uc900\uc73c\ub85c \uc815\ub82c \n    predict = predict.reset_index(drop = True)\n    actual.acc_id = actual.acc_id.astype('int')\n    actual = actual.sort_values(by =['acc_id'], axis = 0) # \uc2e4\uc81c \ub2f5\uc548\uc744 acc_id \uae30\uc900\uc73c\ub85c \uc815\ub82c\n    actual =actual.reset_index(drop=True)\n    \n    if predict.acc_id.equals(actual.acc_id) == False:\n        print('acc_id of predicted and actual label does not match')\n        sys.exit() # \uc608\uce21 \ub2f5\uc548\uc758 acc_id\uc640 \uc2e4\uc81c \ub2f5\uc548\uc758 acc_id\uac00 \ub2e4\ub978 \uacbd\uc6b0 \uc5d0\ub7ec\ucc98\ub9ac \n    else:\n            \n        S, alpha, L, sigma = 30, 0.01, 0.1, 15  \n        cost, gamma, add_rev = 0,0,0 \n        profit_result = []\n        survival_time_pred = list(predict.survival_time)\n        amount_spent_pred = list(predict.amount_spent)\n        survival_time_actual = list(actual.survival_time)\n        amount_spent_actual = list(actual.amount_spent)    \n        for i in range(len(survival_time_pred)):\n            if survival_time_pred[i] == 64 :                 \n                cost = 0\n                optimal_cost = 0\n            else:\n                cost = alpha * S * amount_spent_pred[i]                    #\ube44\uc6a9 \uacc4\uc0b0\n                optimal_cost = alpha * S * amount_spent_actual[i]          #\uc801\uc815\ube44\uc6a9 \uacc4\uc0b0 \n            \n            if optimal_cost == 0:\n                gamma = 0\n            elif cost \/ optimal_cost < L:\n                gamma = 0\n            elif cost \/ optimal_cost >= 1:\n                gamma = 1\n            else:\n                gamma = (cost)\/((1-L)*optimal_cost) - L\/(1-L)              #\ubc18\uc751\ub960 \uacc4\uc0b0\n            \n            if survival_time_pred[i] == 64 or survival_time_actual[i] == 64:\n                T_k = 0\n            else:\n                T_k = S * np.exp(-((survival_time_pred[i] - survival_time_actual[i])**2)\/(2*(sigma)**2))    #\ucd94\uac00 \uc0dd\uc874\uae30\uac04 \uacc4\uc0b0\n                \n            add_rev = T_k * amount_spent_actual[i]                         #\uc794\uc874\uac00\uce58 \uacc4\uc0b0\n    \n           \n            profit = gamma * add_rev - cost                                #\uc720\uc800\ubcc4 \uae30\ub300\uc774\uc775 \uacc4\uc0b0\n            profit_result.append(profit)\n            \n        score = sum(profit_result) \n    return score","e06d94b0":"lgb_valid_score = score_function(lgb_pred_df, valid_set[['acc_id','survival_time','amount_spent']])\nprint('Light GBM score: ',lgb_valid_score)","87bf5c7b":"### Combat\n- \uad00\uce21 \uae30\uac04\ub3d9\uc548 \ud574\ub2f9 \uc720\uc800\uc758 \ud3c9\uade0 \uce90\ub9ad\ud130 \ub808\ubca8\n- \ud574\ub2f9 \uc720\uc800\uac00 \uac00\uc9c4 \uce90\ub9ad\ud130\uc758 \ud074\ub798\uc2a4 \ubd84\ud3ec\n","993fcc89":"# Load Dataset","baf0865f":"- \uc8fc\ucc28\ubcc4 \ubcc0\uc218 \uc0dd\uc131\ud568\uc218","c94fe843":"### \ud574\ub2f9 \uc720\uc800\uc758 \uc544\ub370\ub098 \ubcc0\ub3d9\ub7c9 (change_adena)","6c565c34":"### \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ucc28\ubcc4 \uc8fd\uc740 \ud69f\uc218(death_cnt_week{n})","39fef936":"### \uc720\uc800\ubcc4 \ub9c9\ud53c\uc5d0 \ub300\ud55c \ucd1d \uacf5\uaca9 \ud69f\uc218, \ubc29\uc5b4 \ud69f\uc218(total random_attacker & defender count)","bfd41d59":"** Reducing share of memeory **","8dc5f67b":"### Combat","c6bb71b1":"### Trade","9a8d9e4e":"# Data Preprocessing\n- 1. Pledge\ub97c \uc81c\uc678\ud55c \ubaa8\ub4e0 \ub370\uc774\ud130\ub294 \uc720\uc800\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \ub2f4\uace0\uc788\ub294 \uac83\uc774 \uc544\ub2cc, \uce90\ub9ad\ud130\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\ub2e4. \ub530\ub77c\uc11c \uce90\ub9ad\ud130\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uc720\uc800 \uc815\ubcf4\ub85c \ubcc0\uacbd\ud574\uc57c\ud55c\ub2e4.  \n- 2. Pledge\ub294 \ud608\ub9f9\uc5d0 \ub300\ud55c \uc815\ubcf4\uc774\uae30 \ub54c\ubb38\uc5d0, pledge_id\ub97c \uae30\uc900\uc73c\ub85c \ub370\uc774\ud130\ub97c \uc815\ub9ac \ud560 \ud544\uc694\uac00 \uc788\ub2e4.","8e70fe96":"** Define Function **","4861a69c":"### Week","4549b0b4":"### max_amount & median_amount& total_amount","b67f10db":"### Payment","dd363bb6":"### \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ubcc4 \uac1c\uc778 \uc0c1\uc810 \uc6b4\uc601\uc2dc\uac04 (private_shop_change_week{n})","46336063":"### Trade","e8de779b":"### \uc8fd\uc740 \ud69f\uc218\uc758 \ubcc0\ud654 \uc815\ub3c4 (change_death_cnt)","1ef76770":"### LGB","23c60be7":"### \ubd80\ud65c \ud69f\uc218\uc758 \ubcc0\ud654 \uc815\ub3c4 (change_revive)","6a826fdd":"## Payment","aa6ef009":"### Activity","64e9bde5":"### \ud30c\ud2f0 \ud68d\ub4dd \uacbd\ud5d8\uce58 \ubcc0\ud654 \uc815\ub3c4(change_party_exp)","847f598e":"### \uc18c\uc18d\uac10\n\uc18c\uc18d\ub41c \ud608\ub9f9\uc758 \ud608\ub9f9\uc6d0 \ud3c9\uade0 \ub808\ubca8\uacfc \ud574\ub2f9 \uc720\uc800\uc758 \ub808\ubca8 \ucc28\uc774\uac00 \ub108\ubb34 \ub9ce\uc774 \ub098\uba74, \uc990\uae30\ub294 \ucee8\ud150\uce20\uc758 \ucc28\uc774\uac00 \uc874\uc7ac\ud558\uae30 \ub54c\ubb38\uc5d0 \uc798 \uc5b4\uc6b8\ub9ac\uc9c0 \ubabb\ud560 \uac83\uc774\ub2e4. \n- \ud574\ub2f9 \uc720\uc800\uc758 \ud3c9\uade0\ub808\ubca8 \/ \uc18c\uc18d\ub41c \ud608\ub9f9\uc758 \ud608\ub9f9\uc6d0 \ud3c9\uade0 \ub808\ubca8","aa3e389f":"### \ud574\ub2f9 \uc720\uc800\uac00 \uac00\uc9c4 \uce90\ub9ad\ud130\uc758 \ud074\ub798\uc2a4 \ubd84\ud3ec (class_n)","9c65df87":"### Label ","617c3f95":"### Pledge","52c81f1e":"### \ud574\ub2f9 \uc720\uc800\ubcc4 \uac1c\uc778 \uc0c1\uc810 \uc6b4\uc601\uc2dc\uac04 \ubcc0\ud654 \uc815\ub3c4 (change_private_shop)","9b0ee15e":"## Activity\n- \uc720\uc800\ubcc4 \uc811\uc18d\ud55c \ub0a0\uc758 \ud569\n- \uc720\uc800\ubcc4 \ucd1d \uce90\ub9ad\ud130 \uc218\n- \uc720\uc800\ubcc4 \ud50c\ub808\uc774 \uc2dc\uac04\uc758 \ud3c9\uade0\n- \uc720\uc800\ubcc4 \ud50c\ub808\uc774 \uc2dc\uac04\uc758 \ud45c\uc900 \ud3b8\ucc28\n- \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ubcc4 \ud30c\ud2f0 \uacbd\ud5d8\uce58 \ud68d\ub4dd\ub7c9\n- \ud574\ub2f9 \uc720\uc800\uc758 \ud30c\ud2f0 \uacbd\ud5d8\uce58 \ud68d\ub4dd \ubcc0\ud654 \uc815\ub3c4\n- \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ubcc4 \uc8fd\uc740 \ud69f\uc218\n- \ud574\ub2f9 \uc720\uc800\uc758 \uc8fd\uc740 \ud69f\uc218\uc758 \ubcc0\ud654 \uc815\ub3c4\n- \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ubcc4 \uc544\ub370\ub098 \ubcc0\ub3d9\ub7c9\n- \ud574\ub2f9 \uc720\uc800\uc758 \uc544\ub370\ub098 \ubcc0\ub3d9\ub7c9 \ubcc0\ud654 \uc815\ub3c4\n","6689f138":"### \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ubcc4 \ubd80\ud694 \ud69f\uc218 (revive_change_week{n})","f96489ab":"# Feature Engineering ","3ecd041a":"### \ud574\ub2f9 \uc720\uc800\uc758 \uc8fc\ucc28\ubcc4 \uc544\ub370\ub098 \ubcc0\ub3d9\ub7c9 (adena_change_week{n})","decbc1c5":"### Pledge\n- \ud608\ub9f9 \ud3c9\uade0 \ub808\ubca8","b54a9e3b":"# Import Module ","9e569f92":"### \uc8fc\ucc28\ubcc4 \ud30c\ud2f0 \ud68d\ub4dd \uacbd\ud5d8\uce58(party_exp_week{n})","dde9b1e7":"### \uc720\uc800\ubcc4 \ud50c\ub808\uc774 \uc2dc\uac04\uc758 \ud3c9\uade0, \ud45c\uc900 \ud3b8\ucc28 (avg_playtime, std_playtime)","ffcfe7f8":"### \uc720\uc800\ubcc4 \uc811\uc18d\ud55c \ub0a0\uc758 \ud569 (total_day)","06c72f64":"\ubcf8 \ucee4\ub110\uc740 TooTouch\ub2d8\uc758 [Baseline Part 2](\"https:\/\/www.kaggle.com\/heojaeh\/baseline-part-2\") \ucee4\ub110\uacfc MOON HYEONJONG\ub2d8\uc758 [baseline1]('https:\/\/www.kaggle.com\/moonhyeonjong\/baseline1')\ucee4\ub110\uc744 \ucc38\uace0\ud558\uc5ec \ub9cc\ub4e4\uc5c8\uc74c\uc744 \ubbf8\ub9ac \uc54c\ub824\ub4dc\ub9bd\ub2c8\ub2e4. "}}