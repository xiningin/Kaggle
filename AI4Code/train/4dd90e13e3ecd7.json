{"cell_type":{"c655c97a":"code","435e2e1f":"code","48c4e3fd":"code","811283d5":"code","6bbee220":"code","2e83f4d6":"code","a68b464e":"code","0d650322":"code","75eed485":"code","3d5d9843":"code","bbfed5c9":"code","ef50de41":"markdown","42f33d18":"markdown","372f81b2":"markdown","9b732f54":"markdown","3438f1b5":"markdown","7060907a":"markdown"},"source":{"c655c97a":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","435e2e1f":"#Load data\ndata = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\n\ndata.text = data.text.apply(str)\ndata.head(5)","48c4e3fd":"#split data in test and train data set\nx_train,x_test,y_train,y_test = train_test_split(data['text'], data.sentiment, test_size=0.3, random_state=2020, stratify= data.sentiment)","811283d5":"#Use LogisticRegression Model\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"LogisticRegression Model accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","6bbee220":"#Get preadiction from model\nmodel.predict(pd.Series(['this is so sad', 'This is good bro!', 'can you help me?']))","2e83f4d6":"#Use LogisticRegression Model\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model',  LinearSVC())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"LinearSVC accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","a68b464e":"#Get preadiction from model\nmodel.predict(pd.Series(['this is so sad', 'This is good bro!', 'can you help me?']))","0d650322":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', BernoulliNB())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"BernoulliNB accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","75eed485":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', GradientBoostingClassifier(loss = 'deviance',\n                                                   learning_rate = 0.01,\n                                                   n_estimators = 5,\n                                                   max_depth = 500,\n                                                   random_state=55))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"GradientBoostingClassifier accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","3d5d9843":"#Use DecisionTreeClassifier\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model',  DecisionTreeClassifier(max_depth=150))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"DecisionTreeClassifier accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","bbfed5c9":" # We got max accuracy of 69.07% with LogisticRegression Model","ef50de41":"# DecisionTreeClassifier","42f33d18":"# BernoulliNB","372f81b2":"# GradientBoostingClassifier","9b732f54":"# Here only Text column is used for prediction","3438f1b5":"# LogisticRegression Model","7060907a":"# LinearSVC(Support Vector Classifier) Model"}}