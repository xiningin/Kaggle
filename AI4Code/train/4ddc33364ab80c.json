{"cell_type":{"c7d9e079":"code","157b3794":"code","ee3916e4":"code","eac02e5a":"code","c48e4dea":"code","4bbf9616":"code","d5d9f876":"code","dc98209a":"code","dd02c6bd":"code","c5c3c155":"code","40a583b6":"code","012b3b5d":"code","403a4474":"code","72e53a73":"code","d2a7d3be":"code","5d8b7ff6":"code","6d7326be":"code","a03bc81c":"code","af0fe9be":"code","45cb134c":"code","243c0a37":"code","f878c426":"code","e08cb888":"code","261edc9b":"code","1414ee94":"code","511b9157":"code","d9466973":"code","8d1b7313":"code","e340cf7d":"code","fadbdfcc":"code","8ac94a48":"code","68cdfaf5":"code","a0f7a20b":"code","b761cff1":"code","b86d31e4":"code","e7f68b99":"code","7c921854":"code","03f9b732":"code","4ea1e7a6":"markdown","d3957c0d":"markdown","fd8226a5":"markdown","b8216533":"markdown","dddb5456":"markdown","93f5d897":"markdown","26da09a4":"markdown","14ef82e6":"markdown","8c4d0adf":"markdown","d2a6bc6b":"markdown","eceb89f8":"markdown","cf8d9226":"markdown","9eb22020":"markdown","92534e52":"markdown","be009135":"markdown","8a2fac27":"markdown","92e72f22":"markdown","4396472f":"markdown","5b0ea729":"markdown","a58c2e6e":"markdown","ae7e3fe7":"markdown","ce2f8394":"markdown","3dca3587":"markdown"},"source":{"c7d9e079":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","157b3794":"data=pd.read_csv('..\/input\/googleplaystore.csv')\ndata","ee3916e4":"data.Category.unique()","eac02e5a":"data.isnull().sum()","c48e4dea":"dataframeArtDesign=data.loc[data[\"Category\"]==\"ART_AND_DESIGN\"]\navrArtDesign=dataframeArtDesign[\"Rating\"].mean()\nprint(avrArtDesign)\ndataframeAutoVehicles=data.loc[data[\"Category\"]==\"AUTO_AND_VEHICLES\"]\navrAutoVehicles=dataframeAutoVehicles[\"Rating\"].mean()\nprint(avrAutoVehicles)\ndataframeBeauty=data.loc[data[\"Category\"]==\"BEAUTY\"]\navrBeauty=dataframeBeauty[\"Rating\"].mean()\nprint(avrBeauty)\n\ndataframeBooksReference=data.loc[data[\"Category\"]==\"BOOKS_AND_REFERENCE\"]\navrBooksReference=dataframeBooksReference[\"Rating\"].mean()\nprint(avrBooksReference)\ndataframeBusiness=data.loc[data[\"Category\"]==\"BUSINESS\"]\navrBusiness=dataframeBusiness[\"Rating\"].mean()\nprint(avrBusiness)\ndataframeComics=data.loc[data[\"Category\"]==\"COMICS\"]\navrComics=dataframeComics[\"Rating\"].mean()\nprint(avrComics)\ndataframeCommunication=data.loc[data[\"Category\"]==\"COMMUNICATION\"]\navrCommunication=dataframeCommunication[\"Rating\"].mean()\nprint(avrCommunication)\ndataframeDating=data.loc[data[\"Category\"]==\"DATING\"]\navrDating=dataframeDating[\"Rating\"].mean()\nprint(avrDating)\ndataframeEducation=data.loc[data[\"Category\"]==\"EDUCATION\"]\navrEducation=dataframeEducation[\"Rating\"].mean()\nprint(avrEducation)\ndataframeEntertainment=data.loc[data[\"Category\"]==\"ENTERTAINMENT\"]\navrEntertainment=dataframeEntertainment[\"Rating\"].mean()\nprint(avrEntertainment)\ndataframeEvents=data.loc[data[\"Category\"]==\"EVENTS\"]\navrEvents=dataframeEvents[\"Rating\"].mean()\nprint(avrEvents)\ndataframeFinance=data.loc[data[\"Category\"]==\"FINANCE\"]\navrFinance=dataframeFinance[\"Rating\"].mean()\nprint(avrFinance)\ndataframeFoodDrink=data.loc[data[\"Category\"]==\"FOOD_AND_DRINK\"]\navrFoodDrink=dataframeFoodDrink[\"Rating\"].mean()\nprint(avrFoodDrink)\ndataframeHealthFitness=data.loc[data[\"Category\"]==\"HEALTH_AND_FITNESS\"]\navrHealthFitness=dataframeHealthFitness[\"Rating\"].mean()\nprint(avrHealthFitness)\ndataframeHouseHome=data.loc[data[\"Category\"]==\"HOUSE_AND_HOME\"]\navrHouseHome=dataframeHouseHome[\"Rating\"].mean()\nprint(avrHouseHome)\ndataframeLibrariesDemo=data.loc[data[\"Category\"]==\"LIBRARIES_AND_DEMO\"]\navrLibrariesDemo=dataframeLibrariesDemo[\"Rating\"].mean()\nprint(avrLibrariesDemo)\ndataframeLifestyle=data.loc[data[\"Category\"]==\"LIFESTYLE\"]\navrLifestyle=dataframeLifestyle[\"Rating\"].mean()\nprint(avrLifestyle)\ndataframeGame=data.loc[data[\"Category\"]==\"GAME\"]\navrGame=dataframeGame[\"Rating\"].mean()\nprint(avrGame)\ndataframeFamily=data.loc[data[\"Category\"]==\"FAMILY\"]\navrFamily=dataframeFamily[\"Rating\"].mean()\nprint(avrFamily)\ndataframeMedical=data.loc[data[\"Category\"]==\"MEDICAL\"]\navrMedical=dataframeMedical[\"Rating\"].mean()\nprint(avrMedical)\ndataframeSocial=data.loc[data[\"Category\"]==\"SOCIAL\"]\navrSocial=dataframeSocial[\"Rating\"].mean()\nprint(avrSocial)\ndataframeShopping=data.loc[data[\"Category\"]==\"SHOPPING\"]\navrShopping=dataframeShopping[\"Rating\"].mean()\nprint(avrShopping)\ndataframePhotography=data.loc[data[\"Category\"]==\"PHOTOGRAPHY\"]\navrPhotography=dataframePhotography[\"Rating\"].mean()\nprint(avrPhotography)\ndataframeSports=data.loc[data[\"Category\"]==\"SPORTS\"]\navrSports=dataframeSports[\"Rating\"].mean()\nprint(avrSports)\ndataframeTravelLocal=data.loc[data[\"Category\"]==\"TRAVEL_AND_LOCAL\"]\navrTravelLocal=dataframeTravelLocal[\"Rating\"].mean()\nprint(avrTravelLocal)\ndataframeTools=data.loc[data[\"Category\"]==\"TOOLS\"]\navrTools=dataframeTools[\"Rating\"].mean()\nprint(avrTools)\ndataframePersonalization=data.loc[data[\"Category\"]==\"PERSONALIZATION\"]\navrPersonalization=dataframePersonalization[\"Rating\"].mean()\nprint(avrPersonalization)\ndataframeProductivity=data.loc[data[\"Category\"]==\"PRODUCTIVITY\"]\navrProductivity=dataframeProductivity[\"Rating\"].mean()\nprint(avrProductivity)\ndataframeParenting=data.loc[data[\"Category\"]==\"PARENTING\"]\navrParenting=dataframeParenting[\"Rating\"].mean()\nprint(avrParenting)\ndataframeWeather=data.loc[data[\"Category\"]==\"WEATHER\"]\navrWeather=dataframeWeather[\"Rating\"].mean()\nprint(avrWeather)\ndataframeVideoPlayers=data.loc[data[\"Category\"]==\"VIDEO_PLAYERS\"]\navrVideoPlayers=dataframeVideoPlayers[\"Rating\"].mean()\nprint(avrVideoPlayers)\ndataframeNewsMagazines=data.loc[data[\"Category\"]==\"NEWS_AND_MAGAZINES\"]\navrNewsMagazines=dataframeNewsMagazines[\"Rating\"].mean()\nprint(avrNewsMagazines)\ndataframeMapsNavigation=data.loc[data[\"Category\"]==\"MAPS_AND_NAVIGATION\"]\navrMapsNavigation=dataframeMapsNavigation[\"Rating\"].mean()\nprint(avrMapsNavigation)","4bbf9616":"data.dtypes","d5d9f876":"dataframeforType=data['Type']\nindices=np.where(dataframeforType.isna())\nprint(indices)\ndata=data.drop(data.index[9148])\ndata.isnull().sum()","dc98209a":"data.dtypes\ndata['Reviews']=data[\"Reviews\"].convert_objects(convert_numeric=True)\ndata.dtypes","dd02c6bd":"data=data[data[\"Reviews\"]>50]\ndata.isnull().sum()","c5c3c155":"data.index = range(len(data))","40a583b6":"booleanfornull=data[\"Rating\"].isnull()\nfor counter in range(len(data)):\n    if booleanfornull[counter]:\n        if data[\"Category\"].iloc[counter]==\"ART_AND_DESIGN\":\n            data.Rating.fillna(avrArtDesign,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"AUTO_AND_VEHICLES\":\n            data.Rating.fillna(avrAutoVehicles,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"BEAUTY\":\n            data.Rating.fillna(avrBeauty,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"BOOKS_AND_REFERENCE\":\n            data.Rating.fillna(avrBooksReference,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"BUSINESS\":\n            data.Rating.fillna(avrBusiness,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"COMICS\":\n            data.Rating.fillna(avrComics,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"COMMUNICATION\":\n            data.Rating.fillna(avrCommunication,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"DATING\":\n            data.Rating.fillna(avrDating,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"EDUCATION\":\n            data.Rating.fillna(avrEducation,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"ENTERTAINMENT\":\n            data.Rating.fillna(avrEntertainment,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"EVENTS\":\n            data.Rating.fillna(avrEvents,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"FINANCE\":\n            data.Rating.fillna(avrFinance,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"FOOD_AND_DRINK\":\n            data.Rating.fillna(avrFoodDrink,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"HEALTH_AND_FITNESS\":\n            data.Rating.fillna(avrHealthFitness,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"HOUSE_AND_HOME\":\n            data.Rating.fillna(avrHouseHome,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"LIBRARIES_AND_DEMO\":\n            data.Rating.fillna(avrLibrariesDemo,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"LIFESTYLE\":\n            data.Rating.fillna(avrLifestyle,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"GAME\":\n            data.Rating.fillna(avrGame,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"FAMILY\":\n            data.Rating.fillna(avrFamily,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"MEDICAL\":\n            data.Rating.fillna(avrMedical,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"SOCIAL\":\n            data.Rating.fillna(avrSocial,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"SHOPPING\":\n            data.Rating.fillna(avrShopping,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"PHOTOGRAPHY\":\n            data.Rating.fillna(avrPhotography,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"SPORTS\":\n            data.Rating.fillna(avrSports,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"TRAVEL_AND_LOCAL\":\n            data.Rating.fillna(avrTravelLocal,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"TOOLS\":\n            data.Rating.fillna(avrTools,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"PERSONALIZATION\":\n            data.Rating.fillna(avrPersonalization,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"PRODUCTIVITY\":\n            data.Rating.fillna(avrProductivity,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"PARENTING\":\n            data.Rating.fillna(avrParenting,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"WEATHER\":\n            data.Rating.fillna(avrWeather,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"VIDEO_PLAYERS\":\n            data.Rating.fillna(avrVideoPlayers,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"NEWS_AND_MAGAZINES\":\n            data.Rating.fillna(avrNewsMagazines,inplace=True)\n        elif data[\"Category\"].iloc[counter]==\"MAPS_AND_NAVIGATION\":\n            data.Rating.fillna(avrMapsNavigation,inplace=True)\n        ","012b3b5d":"data.isnull().sum()","403a4474":"dataframeforC_Ver=data[\"Current Ver\"]\nindices = np.where(dataframeforC_Ver.isna())\nprint(indices)\ndataframeforC_Ver=dataframeforC_Ver.fillna(dataframeforC_Ver.mode().iloc[0])\n\ndataframeforAnd_Ver=data['Android Ver']\nindices=np.where(dataframeforAnd_Ver.isna())\nprint(indices)\nprint(dataframeforAnd_Ver.values[4490])\ndataframeforAnd_Ver=dataframeforAnd_Ver.fillna(dataframeforAnd_Ver.mode().iloc[0])\ndataframeforAnd_Ver.isnull().sum()","72e53a73":"processeddata=data.iloc[:,:11]\nfinaldataframe=pd.concat([processeddata,dataframeforC_Ver,dataframeforAnd_Ver],axis=1).reset_index()\nfinaldataframe.isnull().sum()\n","d2a7d3be":"for t in range(len(finaldataframe)):\n    if (finaldataframe[\"Rating\"][t]>4.5) and (finaldataframe[\"Rating\"][t]<=5):\n        finaldataframe[\"Rating\"][t]=\"Between 5 and 4.5\"\n    elif (finaldataframe[\"Rating\"][t]>4) and (finaldataframe[\"Rating\"][t]<=4.5):\n        finaldataframe[\"Rating\"][t]=\"Between 4.5 and 4\"\n    elif (finaldataframe[\"Rating\"][t]>3.5) and (finaldataframe[\"Rating\"][t]<=4):\n        finaldataframe[\"Rating\"][t]=\"Between 4 and 3.5\"\n    elif (finaldataframe[\"Rating\"][t]>3) and (finaldataframe[\"Rating\"][t]<=3.5):\n        finaldataframe[\"Rating\"][t]=\"Between 3.5 and 3\"\n    elif (finaldataframe[\"Rating\"][t]>2.5) and (finaldataframe[\"Rating\"][t]<=3):\n        finaldataframe[\"Rating\"][t]=\"Between 3 and 2.5\"\n    elif (finaldataframe[\"Rating\"][t]>2) and (finaldataframe[\"Rating\"][t]<=2.5):\n        finaldataframe[\"Rating\"][t]=\"Between 2.5 and 2\"\n    else:\n        finaldataframe[\"Rating\"][t]=\"Lower than 2\"","5d8b7ff6":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nle=LabelEncoder()\nohe=OneHotEncoder(categorical_features='all')","6d7326be":"categoriesofApps=finaldataframe.iloc[:,2:3].values\ncategoriesofApps[:,0]=le.fit_transform(categoriesofApps[:,0])\ncategoriesofApps=ohe.fit_transform(categoriesofApps).toarray()","a03bc81c":"sizesofApps=finaldataframe.iloc[:,5:6].values\nsizesofApps[:,0]=le.fit_transform(sizesofApps)","af0fe9be":"installsofApps=finaldataframe.iloc[:,6:7].values\ninstallsofApps[:,0]=le.fit_transform(installsofApps[:,0])\nnp.unique(installsofApps)\ninstallsofApps=ohe.fit_transform(installsofApps).toarray()","45cb134c":"paysofApps=finaldataframe.iloc[:,7:9]\nfor counter in range(len(paysofApps)):\n    if(paysofApps[\"Type\"][counter]==\"Free\"):\n        paysofApps[\"Price\"][counter]=\"Free\"\npaymentsofApps=paysofApps.iloc[:,1:2].values\npaymentsofApps[:,0]=le.fit_transform(paymentsofApps[:,0])","243c0a37":"contentRatingsofApps=finaldataframe.iloc[:,9:10].values\ncontentRatingsofApps[:,0]=le.fit_transform(contentRatingsofApps[:,0])\nnp.unique(contentRatingsofApps)\ncontentRatingsofApps=ohe.fit_transform(contentRatingsofApps).toarray()","f878c426":"lastUpdatesofApps=finaldataframe.iloc[:,10:11].values\nlastUpdatesofApps[:,0]=le.fit_transform(lastUpdatesofApps[:,0])","e08cb888":"androidVersionsofApps=finaldataframe.iloc[:,12:13].values\nandroidVersionsofApps[:,0]=le.fit_transform(androidVersionsofApps[:,0])\n\ncurrentVersionsofApps=finaldataframe.iloc[:,11:12].values\ncurrentVersionsofApps[:,0]=le.fit_transform(currentVersionsofApps[:,0])\n\nfinaldataframe.dtypes\n\n","261edc9b":"\ndf_categories=pd.DataFrame(data=categoriesofApps,index=range(len(finaldataframe)))\ndf_sizes=pd.DataFrame(data=sizesofApps,index=range(len(finaldataframe)))\ndf_installs=pd.DataFrame(data=installsofApps,index=range(len(finaldataframe)))\ndf_payments=pd.DataFrame(data=paymentsofApps,index=range(len(finaldataframe)))\ndf_contentRatings=pd.DataFrame(data=contentRatingsofApps,index=range(len(finaldataframe)))\ndf_lastUpdates=pd.DataFrame(data=lastUpdatesofApps,index=range(len(finaldataframe)))\ndf_androidVersions=pd.DataFrame(data=androidVersionsofApps,index=range(len(finaldataframe)))\ndf_currentVersions=pd.DataFrame(data=currentVersionsofApps,index=range(len(finaldataframe)))\nencoded_df=pd.concat([df_categories,df_sizes,df_installs,df_payments,df_contentRatings,df_lastUpdates,df_androidVersions,df_currentVersions],axis=1)","1414ee94":"ratingsofApps=finaldataframe[\"Rating\"]\nlabels=pd.DataFrame(data=ratingsofApps,index=range(len(finaldataframe)))\n\n\n","511b9157":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nencoded_df=sc.fit_transform(encoded_df)\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(encoded_df,labels,test_size=0.33,random_state=42)\n","d9466973":"from sklearn.metrics import accuracy_score\n","8d1b7313":"from sklearn.metrics import confusion_matrix","e340cf7d":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=10,criterion='entropy')\nrfc.fit(x_train,y_train)\npredictions=rfc.predict(x_test)\ncm=confusion_matrix(y_test,predictions)\nprint(cm)\n\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(y_test, predictions, normalize=True, sample_weight=None))\n","fadbdfcc":"y_numpy=finaldataframe.iloc[:,3].values\n\n\nimport collections\ncollections.Counter(y_numpy)","8ac94a48":"# smote\n\nfrom imblearn.over_sampling import SMOTE\nsm=SMOTE(random_state=2)\nencoded_df, y_numpy=sm.fit_sample(encoded_df,y_numpy.ravel())","68cdfaf5":"import collections\ncollections.Counter(y_numpy)\n","a0f7a20b":"# Besides, there are too many features after encoding. It is hard to learn for machine\n# PCA scales features\n\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=43)\npca.fit(encoded_df)\n\nencoded_df = pca.transform(encoded_df)\nprint(pca.explained_variance_ratio_.cumsum())\n#That will return a vector x such that x[i] returns\n                                                \n#the cumulative variance explained by the first i+1 dimensions.","b761cff1":"#split train and test sets\n\n\n#from collections import Counter\n#from sklearn.datasets import make_classification\n\nfrom sklearn.model_selection import train_test_split\nsmoted_x_train,smoted_x_test,smoted_y_train,smoted_y_test=train_test_split(encoded_df,y_numpy,test_size=0.3,random_state=0)\n\n","b86d31e4":"from sklearn.neighbors import KNeighborsClassifier\n\nknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski')\nknn.fit(smoted_x_train,smoted_y_train)\npredictions=knn.predict(smoted_x_test)\ncm=confusion_matrix(smoted_y_test,predictions)\nprint(cm)\n\n\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(smoted_y_test, predictions, normalize=True, sample_weight=None))\n","e7f68b99":"from sklearn.svm import SVC \nsvc=SVC(kernel='linear')\nsvc.fit(smoted_x_train,smoted_y_train)\npredictions=svc.predict(smoted_x_test)\ncm=confusion_matrix(smoted_y_test,predictions)\nprint(cm)\n\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(smoted_y_test, predictions, normalize=True, sample_weight=None))\n\nprint(\"-----------------------------------------------\")\n\nsvc=SVC(kernel='rbf')\nsvc.fit(smoted_x_train,smoted_y_train)\npredictions=svc.predict(smoted_x_test)\ncm=confusion_matrix(smoted_y_test,predictions)\nprint(cm)\n\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(smoted_y_test, predictions, normalize=True, sample_weight=None))\n\nprint(\"-----------------------------------------------\")\n\n\nsvc=SVC(kernel='poly')\nsvc.fit(smoted_x_train,smoted_y_train)\npredictions=svc.predict(smoted_x_test)\ncm=confusion_matrix(smoted_y_test,predictions)\nprint(cm)\n\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(smoted_y_test, predictions, normalize=True, sample_weight=None))\n\nprint(\"-----------------------------------------------\")\n\n","7c921854":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier(criterion='entropy')\ndtc.fit(smoted_x_train,smoted_y_train)\npredictions=dtc.predict(smoted_x_test)\ncm=confusion_matrix(smoted_y_test,predictions)\nprint(cm)\n\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(smoted_y_test, predictions, normalize=True, sample_weight=None))\n","03f9b732":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=10,criterion='entropy')\nrfc.fit(smoted_x_train,smoted_y_train)\npredictions=rfc.predict(smoted_x_test)\ncm=confusion_matrix(smoted_y_test,predictions)\nprint(cm)\nprint(\"Accuracy of this algorithm is: \" ,accuracy_score(smoted_y_test, predictions, normalize=True, sample_weight=None))\n\n\n","4ea1e7a6":"Eventually, we handle missing values on Current Version and Android Version column. We put mode of these column because they carries string variables.","d3957c0d":"Finally, we have a dataframe which is encoded and also has no missing value. Owing to the fact that we will use supervised algorithms for estimating, we have to split y and x. Y refers to out or label (in this project it Rating) and x is other attributes. We should do normalization on x set to gain more consistent result.","fd8226a5":"Let's start with handling missing values on 'Type' column. To examine Type column for handling missing value it can be splitted from the other columns. Then use a  function to detect which row carry missing value at Type column. The answer is 9148.\nWhen 9148th row of the csv file, it is recognized that the data in this column has been shifted. So, we can delete this row because deleting one of about 10 thousands data will not cause any problems for anything. After deleting this row there is no row which carry missing value on Type column.\n","b8216533":"Let's take a overview at our data first.\nData set consist of 10841 data (rows) and 13 column (attributes of our data).\nOne of the attributes which exists in dataset is ratings of apps. Since purpose of the project is estimating interval rating of Google Play Store Application, these predictions have made by supervised algorithms. 'Rating' is our label or output. ","dddb5456":"It is very helpful code. We can see all of the unique variable which belong to category column","93f5d897":"Even in Random Trees, which is one of the most efficient algorithms for classification, no efficient results were obtained. This result was derived from the distribution in the confusion matrix and the value \"accuracy\". When looking carefully at the Confusion matrix, it is observed that a certain class group has been estimated. There may be a reason for that, and the data is unstable. Due to the fact that the data is unbalanced, the test set always has the density of data from a class, which causes the machine to create a model for that class. Smote technology was used as a solution. Smote balances the data by creating \"artificial data\". The new and old values of the data numbers for each class are expressed in the following codes.","26da09a4":"You can see the improvement of accuracy after Smote and PCA.","14ef82e6":"You can see changing datatypes of Review.","8c4d0adf":"When you see the rows with a value of 'null' in the rating column, it is possible to see that some lines are '0' in the Review column. If an average score is given to each missing value, there will be some lines with a rating and no review. To avoid this, a limit to be examined is determined. For example, delete data that has fewer than 50 views. It was known that the review column had object values. First of all, it needs to be converted from object variables to integer variables.","d2a6bc6b":"\nThe Confusion Matrix gives us information on the efficiency of our estimates in the classification. For beginners, it can be said. The matrix's diagonal shows the number of predicted correctly. The Matrix is \u200b\u200bthe square matrix and the number of edges is the number of different classes in the result.","eceb89f8":"To start with data preprocessing is a good choice. Let's try to handle missing values. For do this, 'Rating' column can be evaluated firstly. Rating column has numeric variables, so we can put average of this column at rows which carry missing value. But, there is a better idea than this. If we calculate average of each category of apps, we can put average rating of category which has missing value rows. Let's calculate average rating of each category.","cf8d9226":"Then we concat all of the sub-dataframes which have no missing values. ","9eb22020":"The table shows number of missing value at each column below. ","92534e52":"We continue with convert to string from float numbers because purpose of the project is estimating \"interval\" of ratings of apps. For doing this, we can use loop.","be009135":"In this codes we put average of categories on null values. Firstly we created a numpy array which shows a particular rows has null value or not. After that we typed a loop for that if there is a null value on that row, if condition will trigger and putting average of categories will occured by if-else if structure.","8a2fac27":"We will continue with encoding string variables. There are 2 sections in this project: Label Encoder and One Hot Encoder. If there are much unique variables in any column, we will use label encoder otherwise we will use one hot encoding.","92e72f22":"Defining basic software libraries for starting the project have to be defined.","4396472f":"After that, our dataset is ready to be used for supervised algorithms.","5b0ea729":"For handling missing values, we should consider datatypes of each column. It is useful to identify operation for handling missing values.","a58c2e6e":"Finally, we have stronger dataset to using classification algorithms before.","ae7e3fe7":"Finally, we eliminated rows which whose Review column carry less than 50.","ce2f8394":"We have to re-design indexes of dataframe.","3dca3587":"As you can see, the data set is now stable."}}