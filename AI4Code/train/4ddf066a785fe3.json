{"cell_type":{"2f7bf9a0":"code","0b7edf8b":"code","ff8c620e":"code","75ce9eee":"code","af78ffb4":"code","28074d8f":"code","11c2dcb7":"code","4d50c946":"code","67430b49":"code","29f564ba":"markdown"},"source":{"2f7bf9a0":"import numpy as np\nimport pandas as pd\nimport os\nimport pathlib\nimport PIL\nimport PIL.Image\nimport librosa\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import layers","0b7edf8b":"data_dir = \"\/kaggle\/input\/cornell-bird-sounds-preprocessing\"\ndata_path = pathlib.Path(data_dir)\n\n## total images\ntotal_images = len(list(data_path.glob(\"*\/*.png\")))","ff8c620e":"## loading images for model\n\nBATCH_SIZE = 32\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nSEED = np.random.randint(100)\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.1,\n  subset=\"training\",\n  seed=SEED,\n  image_size=(IMG_HEIGHT, IMG_WIDTH),\n  batch_size=BATCH_SIZE)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.1,\n  subset=\"validation\",\n  seed=SEED,\n  image_size=(IMG_HEIGHT, IMG_WIDTH),\n  batch_size=BATCH_SIZE)","75ce9eee":"cache_train_ds = train_ds.cache().prefetch(tf.data.experimental.AUTOTUNE)\ncache_val_ds = val_ds.cache().prefetch(tf.data.experimental.AUTOTUNE)","af78ffb4":"num_classes = 264\n\nmodel = tf.keras.Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","28074d8f":"epochs = 50\n\nhistory = model.fit(\n  cache_train_ds,\n  validation_data=val_ds,\n  shuffle=True,\n  epochs=epochs\n)","11c2dcb7":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","4d50c946":"model.save(\".\/model_backup.h5\")\nnp.save(\"class_indices.npy\", np.array(train_ds.class_names))","67430b49":"for x, y in cache_val_ds.take(1):\n    predicts = model.predict(x)\n    for index, y_real in enumerate(y):\n        y_pred = predicts[index]\n        score = tf.nn.softmax(y_pred)\n        print(f'Class: {train_ds.class_names[y_real]} -  Predict as {train_ds.class_names[np.argmax(y_pred)]} with score {np.max(score) * 100}%')","29f564ba":"## Model Creation and Training\n\nHello everyone, \n\nThe competition has just ended, thank you everyone for sharing public notebooks that helps me to learn more and more. I would love to share my model. I hope it would help everyone to get some insights and please also help to give me feedbacks to improve this model. "}}