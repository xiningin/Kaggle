{"cell_type":{"fe1ad3f2":"code","d899a41a":"code","9a3adb3f":"code","789e9227":"code","e2a16233":"code","71bc73bf":"code","47e93e7e":"code","048ffd0d":"code","d1dfc189":"code","b624fbb9":"markdown","e71e341d":"markdown","41c9d7dd":"markdown","c18ad8fe":"markdown","59f5e643":"markdown","59a70970":"markdown"},"source":{"fe1ad3f2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \n\n# set seaborn\nsns.set()","d899a41a":"iris = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\niris.head()","9a3adb3f":"iris.shape","789e9227":"dataset = iris.drop(['Species','Id'],axis = 1)\ndataset.head()","e2a16233":"from sklearn.preprocessing import StandardScaler\n\nstandard = StandardScaler()\ncleanDataSet = pd.DataFrame(standard.fit_transform(dataset))\ncleanDataSet.head()","71bc73bf":"!pip install minisom\n","47e93e7e":"from minisom import MiniSom    \nfrom matplotlib.gridspec import GridSpec\n\nsom = MiniSom(7, 7, 4, sigma=0.25,neighborhood_function='gaussian') \nsom.train_random(cleanDataSet.to_numpy(), 30000) # trains the SOM with 100 iterations","048ffd0d":"target = iris.Species.astype('category').cat.codes\nlabels_map = som.labels_map(cleanDataSet.to_numpy(), target)\nlabel_names = np.unique(target)\n\nplt.figure(figsize=(7, 7))\nthe_grid = GridSpec(7, 7)\n\nfor position in labels_map.keys():\n    label_fracs = [labels_map[position][l] for l in label_names]\n    plt.subplot(the_grid[6-position[1], position[0]], aspect=1)\n    patches, texts = plt.pie(label_fracs)\nplt.legend(patches, label_names, bbox_to_anchor=(0, 1.5), ncol=3)\n\nplt.show()","d1dfc189":"plt.figure(figsize=(7, 7))\nfrequencies = np.zeros((7, 7))\nfor position, values in som.win_map(cleanDataSet.to_numpy()).items():\n    frequencies[position[0], position[1]] = len(values)\nplt.pcolor(frequencies, cmap='Blues')\nplt.colorbar()\nplt.show()","b624fbb9":"thank a lot for Abhinav Ralhan,\nall the data is from- https:\/\/towardsdatascience.com\/self-organizing-maps-ff5853a118d4 ","e71e341d":"![alt text](https:\/\/miro.medium.com\/max\/1310\/1*QG7afWQKjY3IpezhNQMzBg.png)","41c9d7dd":"The Algorithm:\n\n1. Each node\u2019s weights are initialized.\n2. A vector is chosen at random from the set of training data.\n3. Every node is examined to calculate which one\u2019s weights are most like the input vector. The winning node is commonly known as the Best Matching Unit (BMU).\n4. Then the neighbourhood of the BMU is calculated. The amount of neighbors decreases over time.\n5. The winning weight is rewarded with becoming more like the sample vector. The nighbors also become more like the sample vector. The closer a node is to the BMU, the more its weights get altered and the farther away the neighbor is from the BMU, the less it learns.\n6. Repeat step 2 for N iterations.","c18ad8fe":"# Self organizing map","59f5e643":"What happend in the model? - Each data point in the data set recognizes themselves by competeting for representation. SOM mapping steps starts from initializing the weight vectors. From there a sample vector is selected randomly and the map of weight vectors is searched to find which weight best represents that sample. Each weight vector has neighboring weights that are close to it. The weight that is chosen is rewarded by being able to become more like that randomly selected sample vector. The neighbors of that weight are also rewarded by being able to become more like the chosen sample vector. This allows the map to grow and form different shapes. Most generally, they form","59a70970":"What is it? - is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional)"}}