{"cell_type":{"b2a92bf2":"code","d96ebdd7":"code","4835e83b":"code","63922901":"code","f1ad7a10":"code","a9d4e642":"code","c1e35c86":"code","1ce8714f":"code","5330a330":"code","ee4da615":"code","b7b12c46":"code","c732a142":"code","69c4dc1b":"code","92f37ec8":"code","d71b96aa":"code","bf9eacae":"code","e1276ffd":"code","5d4c675d":"code","3cd0c2bf":"code","6236c951":"code","39fd813b":"code","c1613081":"code","a265bd4a":"code","81421fcf":"code","c41630e1":"code","9abe1167":"code","d0137c6b":"code","5b08859b":"code","f32c265b":"code","172200ac":"code","2a4ccfc8":"code","12494353":"code","b5e1dfc8":"code","a9dde1ef":"code","8cbe0cb3":"code","f611b8e8":"code","a8097045":"code","7817b0d3":"code","78ccb3db":"code","90bd467c":"code","619d97eb":"code","c4e95809":"code","fea5ee96":"code","9d02d9a9":"code","df85b00e":"code","8179b8bc":"code","e9bea2c9":"markdown","c4840b94":"markdown","48ad063f":"markdown","07e59c59":"markdown"},"source":{"b2a92bf2":"# Importing modules \nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","d96ebdd7":"class_names = ['cups', 'plates', 'spoons']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","4835e83b":"def load_data():\n    \"\"\"\n        Load the data:\n            - 32 images to train the network.\n            - 15 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_train', '..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","63922901":"(train_images, train_labels), (test_images, test_labels) = load_data()","f1ad7a10":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","a9d4e642":"n_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","c1e35c86":"import pandas as pd\n\n_, train_counts = np.unique(train_labels, return_counts=True)\n_, test_counts = np.unique(test_labels, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'test': test_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()","1ce8714f":"plt.pie(train_counts,\n        explode=(0, 0, 0,) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","5330a330":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","ee4da615":"train_images = train_images \/ 255.0 \ntest_images = test_images \/ 255.0","b7b12c46":"display_random_image(class_names, train_images, train_labels)","c732a142":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Display 10 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(10):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","69c4dc1b":"display_examples(class_names, train_images, train_labels)","92f37ec8":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","d71b96aa":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","bf9eacae":"# Model Summary\nmodel.summary()","e1276ffd":"history = model.fit(train_images, train_labels, batch_size=96, epochs=15, validation_split = 0.2)","5d4c675d":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","3cd0c2bf":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","6236c951":"# Evaluating model on validation data\nevaluate = model.evaluate(test_images,test_labels)\nprint(evaluate)","39fd813b":"train_dir = '..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_train'\ntest_dir = '..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_test'","c1613081":"\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimage_gen = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True)\ntrain_data_gen = image_gen.flow_from_directory(batch_size=96,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size = (150,150))\n","a265bd4a":"sample_training_images, _ = next(train_data_gen)","81421fcf":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","c41630e1":"plotImages(sample_training_images[:5])","9abe1167":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","d0137c6b":"plotImages(augmented_images)","5b08859b":"image_gen = ImageDataGenerator(rescale=1.\/255, rotation_range=45)","f32c265b":"train_data_gen = image_gen.flow_from_directory(batch_size=96,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(150,150))\n","172200ac":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","2a4ccfc8":"plotImages(augmented_images)","12494353":"# zoom_range from 0 - 1 where 1 = 100%.\nimage_gen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.5) #\n\ntrain_data_gen = image_gen.flow_from_directory(batch_size=96,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(150,150))","b5e1dfc8":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","a9dde1ef":"plotImages(augmented_images)","8cbe0cb3":"\"\"\"# putting it all together\"\"\"\n\nimage_gen_train = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=45,\n                    width_shift_range=.15,\n                    height_shift_range=.15,\n                    horizontal_flip=True,\n                    zoom_range=0.5\n                    )","f611b8e8":"train_data_gen = image_gen_train.flow_from_directory(batch_size=96,\n                                                     directory=train_dir,\n                                                     shuffle=True,\n                                                     target_size=(150,150),\n                                                     class_mode='categorical')","a8097045":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","7817b0d3":"plotImages(augmented_images)","78ccb3db":"\"\"\"# create validator data generator\"\"\"\n\nimage_gen_val = ImageDataGenerator(rescale=1.\/255)\n\nval_data_gen = image_gen_val.flow_from_directory(batch_size=96,\n                                                 directory=test_dir,\n                                                 target_size=(150,150),\n                                                 class_mode='categorical')","90bd467c":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","619d97eb":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","c4e95809":"history = model.fit(train_images, train_labels, batch_size=96, epochs=15, validation_split = 0.2)","fea5ee96":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']","9d02d9a9":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(15)","df85b00e":"plt.figure(figsize=(30, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')","8179b8bc":"plt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","e9bea2c9":"Randomly rotate the image","c4840b94":"Zoom augmentation","48ad063f":"Applying horizontal flip","07e59c59":"Data Augmentation"}}