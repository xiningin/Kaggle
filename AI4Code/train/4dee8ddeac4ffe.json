{"cell_type":{"ad2a8ad1":"code","8850dc75":"code","7f6a3b6b":"code","0e1302b5":"code","50e3a44f":"code","e6294242":"code","876f9771":"code","f71a296b":"code","30d43201":"code","5ec9a94f":"code","b33b4a6f":"code","7a22e4f8":"code","bb4834e2":"code","5d2e59d0":"code","730d9f77":"code","04ef5e6d":"code","6b2279f4":"code","974a34af":"code","031ccb37":"code","f886c1b3":"code","b8ae80bf":"code","e6508eb7":"code","0fc97cc0":"code","3a72329c":"code","d0e81aa6":"code","53f3125f":"code","4bb3b2df":"code","cd3193a6":"markdown","3254b180":"markdown","0cd0b2c2":"markdown","08a0825d":"markdown","b9f82f9d":"markdown","0138fc54":"markdown","1c744980":"markdown","c2fc9b46":"markdown","6b30e8ff":"markdown","f861fa30":"markdown","54f3fe92":"markdown","093611c2":"markdown","2db5932d":"markdown","9ce770e0":"markdown","c378fc9b":"markdown","01bb6014":"markdown"},"source":{"ad2a8ad1":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport cv2\nimport os\nimport gc\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom keras import callbacks\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.optimizers import adam\nfrom keras.models import load_model\n\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"..\/input\"))\n\nfrom numpy.random import seed\nseed(2019)\nfrom tensorflow import set_random_seed\nset_random_seed(2019)","8850dc75":"# define the path for loading .jpg images\npath = \"..\/input\/train\/images\"\n\ntrain_files = pd.read_csv('..\/input\/train\/train.csv', \n                          dtype={'image': 'object', 'category': 'int8'})\n\ntest_files = pd.read_csv('..\/input\/test_ApKoW4T.csv')","7f6a3b6b":"train_files.head()","0e1302b5":"test_files.head()","50e3a44f":"# display missing categories in train\ntrain_files[train_files.isnull().any(axis=1)]","e6294242":"# dictionary ship encoding \nship = {'Cargo': 1, \n        'Military': 2, \n        'Carrier': 3, \n        'Cruise': 4, \n        'Tankers': 5}\n\n# reverse the ship type dictionary\nship = dict([[v,k] for k,v in ship.items()])","876f9771":"# Create test labels for interpretability\ntrain_files['ship'] = train_files['category'].map(ship).astype('category')\nlabels = list(train_files['ship'].unique())","f71a296b":"# display count of ship types\nplt.title('Count of each ship type')\nsns.countplot(y=train_files['ship'].values)\nplt.show()\ngc.collect()","30d43201":"train_files['ship'].value_counts(normalize=False)","5ec9a94f":"train_files['ship'].value_counts(normalize=True)","b33b4a6f":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(dtype='int8', sparse=False)\ny_train = ohe.fit_transform(train_files['category'].values.reshape(-1,1))","7a22e4f8":"# Since most pre-trained models have a specific input dimension,\n# we will need to set the target_size to match the pre-trained model input shape.\n# Increasing shape of the images requires more RAM.\ndef load(what='train', target_size=(224,224)):\n    array = []\n    if what =='train':\n        for file in tqdm(train_files['image'].values):\n            img = load_img(os.path.join(path, file), target_size=target_size)\n            img = img_to_array(img)\/255. # normalize image tensor\n            array.append(img)\n    elif what =='test':\n        for file in tqdm(test_files['image'].values):\n            img = load_img(os.path.join(path, file), target_size=target_size)\n            img = img_to_array(img)\/255. # normalize image tensor\n            array.append(img)\n    gc.collect()\n    return np.asarray(array)","bb4834e2":"# Load Train and Test\nX_train = load()\ntest = load('test')\nprint(f'train dtype: {X_train.dtype}')\nprint(f'test dtype: {test.dtype}')\nprint(f'train shape: {X_train.shape}')\nprint(f'test shape: {test.shape}')","5d2e59d0":"# visualize the top 28 train images\nplt.figure(figsize=(12,24))\n\nfor i in range(1,29):\n    plt.subplot(7,4,i)\n    plt.title(f'{train_files[\"ship\"].values[i]}')\n    plt.imshow(X_train[i])\n    plt.axis('off')\nplt.show()\ngc.collect()","730d9f77":"# visualize the top 28 test images\nplt.figure(figsize=(12,24))\n\nfor i in range(1,29):\n    plt.subplot(7,4,i)\n    plt.imshow(test[i])\n    plt.axis('off')\nplt.show()\ndel test # free up space for training\ngc.collect()","04ef5e6d":"class printf1(callbacks.Callback):\n    def __init__(self, X_train, y_train):\n        super(printf1, self).__init__()\n        self.bestf1 = 0\n        self.X_train = X_train\n        self.y_train = y_train\n        \n    def on_epoch_end(self, epoch, logs={}):\n        pred = np.argmax(self.model.predict(np.array(self.X_train)), axis=1)\n        f1 = f1_score(np.argmax(self.y_train, axis=1), pred, average='weighted')\n        print(\"Train F1 Score: {:.4f}\".format(f1))\n        pred = np.argmax(self.model.predict(self.validation_data[0]), axis=1)\n        f1 = f1_score(np.argmax(self.validation_data[1], axis=1), pred, average='weighted')\n        print(\"Valid F1 Score: {:.4f}\".format(f1))\n        return","6b2279f4":"# to plot training\/validation history object\ndef plt_dynamic(x, vy, ty, ax, colors=['b'], title=''):\n    ax.plot(x, vy, 'b', label='Validation Loss')\n    ax.plot(x, ty, 'r', label='Train Loss')\n    plt.legend()\n    plt.grid()\n    plt.title(title)\n    fig.canvas.draw()\n    plt.show()\n    gc.collect()","974a34af":"# https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Greens):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    fig, ax = plt.subplots(figsize=(6,6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=0)\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    plt.show()\n    gc.collect()","031ccb37":"# make sure internet is enabled in the settings tab to the right\n# do not include the last Fully Connected(FC) layer\nfrom keras.applications.xception import Xception\nmodel = Xception(include_top=False, input_shape=(224,224,3))","f886c1b3":"from keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\n\nx = GlobalAveragePooling2D()(model.output)\n#x = Dense(6, activation='relu')(x)\noutput = Dense(5, activation='softmax')(x)\n\n# define new model\nmodel = Model(model.inputs, output)\nmodel.save('model.hdf5')\n#model.summary()","b8ae80bf":"# visualize the Xception model architecture\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","e6508eb7":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, \n                                                    stratify=y_train,\n                                                    random_state=2019,\n                                                    test_size=0.2)","0fc97cc0":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\ngc.collect()","3a72329c":"# use ImageDataGenerator to augment training data\nfrom keras.preprocessing.image import ImageDataGenerator\nbatch_size = 8\nepochs = 50\n\n# make sure to keep learning rate low when fine-tuning\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n              optimizer=adam(lr=0.0001))\n\ndatagen = ImageDataGenerator(rotation_range=45, \n                             horizontal_flip=True, \n                             width_shift_range=0.5, \n                             height_shift_range=0.5, \n                             dtype='float32')\n\ndatagen.fit(X_train, augment=True, rounds=1, seed=2019)\ntrain_generator = datagen.flow(X_train, y_train, \n                               batch_size=batch_size, \n                               seed=2019)\n\nf1 = printf1(X_train, y_train)\ncp = ModelCheckpoint('best.hdf5', monitor='val_loss', save_best_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-4 * 0.95 ** x)\n\nhistory = model.fit_generator(generator=train_generator, \n                              steps_per_epoch=len(X_train)\/batch_size, \n                              validation_data=[X_test, y_test], \n                              callbacks=[cp,f1,annealer],\n                              epochs=epochs)","d0e81aa6":"# printout competition metric - F1 score \ntrue = np.argmax(y_test, axis=1)\nbest = load_model('best.hdf5')\nvalid_pred_best = np.argmax(best.predict(X_test), axis=1)\nbest_f1_score = f1_score(true, valid_pred_best, average=\"weighted\")\nprint(f'Best model weighted F1 Score: {best_f1_score:.4f}')\n\nvalid_pred = np.argmax(model.predict(X_test), axis=1)\nf1_score = f1_score(true, valid_pred, average=\"weighted\")\nprint(f'weighted F1 Score: {f1_score:.4f}')\n\n# visualize training loss\nfig, ax = plt.subplots(1,1)\nvy = history.history['val_loss']\nty = history.history['loss']\nax.set_xlabel('Epoch')\nx = list(range(1,epochs+1))\nax.set_ylabel('Categorical Crossentropy Loss')\nplt_dynamic(x,vy,ty,ax, title='Training History - Xception')\n\n#plot confusion matrix\nplot_confusion_matrix(true, valid_pred, normalize=True, \n                      classes=labels, title='Confusion Matrix')","53f3125f":"test = load('test')\nsub = pd.read_csv('..\/input\/sample_submission_ns2btKE.csv')\n\n# use the better performing model\nif best_f1_score >= f1_score:\n    sub['category'] = np.argmax(best.predict(test), axis=1) + 1\nelse:\n    sub['category'] = np.argmax(model.predict(test), axis=1) + 1 \nsub.to_csv('submission.csv', index=False)\nsub.head()","4bb3b2df":"sub['category'].map(ship).value_counts(normalize=True)","cd3193a6":"There are black and white images mixed in with color images. Some images are old. Some images contain steam\/smoke coming out of the smokestacks. Some images contain multiple ships. Some contain clouds and others contain various background scenery. Some contain a lengthwise display and others contain a display of the front of head of a ship. Some images are low contrast.\n\nIn order to address some of these concerns, such as grayscale, rotation, noise, etc. We will need to perform data augmentation to create a more robust training set for our Neural Network to learn from. This may help better generalize into testing dataset as well as help the network from overfitting to some extent.\n\nJust looking at the top 28 ship images from train and test, it is not possible to tell how many edge cases there are, but on first glance, train and test appear to be fairly uniform. That is to say, validation scores should reflect test scores, unless you overfit the model.","3254b180":"As you can see confusion matrix, the Neural Network is having a little trouble differentiating between _Cargos_ and _Tankers_. Xception is converging to minima quite nicely. There is over-fitting but not by much.","0cd0b2c2":"# Load Train\/Test Files","08a0825d":"# Make Test Predictions","b9f82f9d":"# Analytics Vidhya - Game of Deep Learning | Computer Vision Hackathon\n\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/game-of-deep-learning\/\n\nHackthon Timeframe: Friday May 24, 2019 - Sunday June 09, 2019\n\n#### Problem Statement\n\nShip or vessel detection has a wide range of applications, in the areas of maritime safety,  fisheries management, marine pollution, defence and maritime security, protection from piracy, illegal migration, etc.\n\nKeeping this in mind, a Governmental Maritime and Coastguard Agency is planning to deploy a computer vision based automated system to identify ship type only from the images taken by the survey boats. You have been hired as a consultant to build an efficient model for this project.\n\n#### Dataset Description\nThere are 6252 images in train and 2680 images in test data. The categories of ships and their corresponding codes in the dataset are as follows -\n\nThere are 5 classes of ships to be detected which are as follows: <br>\n\n1: Cargo <br>\n2: Military <br>\n3: Carrier <br>\n4: Cruise <br>\n5: Tankers\n\nVariable\t| Definition\n--- | ---\nimage\t| Name of the image in the dataset (ID column)\ncategory |\tShip category code\n<br>\n#### Evaluation Metric\nThe Evaluation metric for this competition is weighted F1 Score.\n\n#### Misc Rules\n- Use of external dataset is not allowed, however, transfer learning can be used to build the solution","0138fc54":"# End Notes\nThis concludes my solution to the Analytics Vidhya Computer Vision Hackathon. While this notebook is fairly basic, it gives a good template to work off and learn from, especially for beginners to image classification. There is certainly a lot more that can be added, such as balancing the classes through oversampling, data augmentation via external libraries\/scripts and much more. With that being said, this notebook was able to achieve 95%+ in both public and private leaderboards. 5-fold CV certainly adds another percentage increase. Finally, due to memory constraints oversampling and 5-fold CV were not shown in this notebook.","1c744980":"No missing values.","c2fc9b46":"# View Some Train Images","6b30e8ff":"Since there are class imbalances in training set, we will need to display a confusion matrix visualize to where the neural network classifier is having trouble. We will also stratify train_test_split in order to maintain the class distributions in both train and test.","f861fa30":"# Custom Callbacks for F1 Score\nWe need to create a custom callbacks function that calculates f1 score after every epoch to gauge model performance.","54f3fe92":"# Load Pre-trained network and weights (Xception)\nUtilize Keras pre-trained model and weights for faster and more accurate image classification models. Weights were loaded from training on Imagenet dataset.","093611c2":"# Basic EDA","2db5932d":"# View Some Test Images","9ce770e0":"# Fine-tune Entire Pre-trained Xception Model","c378fc9b":"# Encode Train Labels","01bb6014":"Because no external data was allowed for this competition, it was crucial to modify (augment) the existing image dataset through the use of a data generator. Data augmentation may hurt or improve model performance so care must be taken at this step. Data augmentation needs to be considered case-by-case. So adding a vertical flip when none of the ships are flipped upside-down will likely decrease model generaliziblity to testing data.\n\nAdaptive learning rates can help models converge to the optimal solution much better."}}