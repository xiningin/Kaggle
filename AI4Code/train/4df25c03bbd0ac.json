{"cell_type":{"4e3b08b0":"code","7a8c4d54":"code","03a565df":"code","ddb0fabf":"code","1199981f":"code","9a04349e":"code","de309f8c":"code","0ee8af47":"code","7c808e00":"code","d0e41fb6":"code","fe16ef3a":"code","39050271":"code","5bbc60c5":"code","2a978f9d":"code","5aa5cc5e":"code","6b16822b":"code","990b1c26":"code","b11c1571":"code","4caca253":"code","b16cc71e":"code","23a445f7":"code","a21f8d23":"code","ef8ecb48":"code","3d48faf2":"markdown","f1058591":"markdown","00e70206":"markdown","d59dd691":"markdown","89d21e31":"markdown"},"source":{"4e3b08b0":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For visualize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training model\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import KFold\n\n# For Prediction\nfrom sklearn.metrics import mean_squared_error\n\n# Os Import\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Info        \nimport warnings\n\n# Set\npd.set_option('display.width', 100)\npd.set_option('display.max_rows', 25)\npd.set_option('display.max_columns', 25)\n\n# Print\nprint('='*100)\nprint('Ready To Launch !!!!')\nprint('='*100)","7a8c4d54":"# Load the training and test data\ntrain = pd.read_csv(\"\/kaggle\/input\/30-days-of-ml\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/30-days-of-ml\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/30-days-of-ml\/sample_submission.csv\")\n\n# Make a backup from data\ntrain_copy = train.copy(deep=True)\ntest_copy = test.copy(deep=True)\nsub_copy = sub.copy(deep=True)","03a565df":"# Checking train data\ntrain","ddb0fabf":"# Checking the type of data\ntrain.dtypes.to_frame()","1199981f":"# Checking the null value\ntrain.isna().mean().to_frame()","9a04349e":"# Looking for categorical data\nobjectColTrain = train.loc[:, ['cat0', 'cat1', \n                               'cat2', 'cat3', \n                               'cat4', 'cat5', \n                               'cat6', 'cat7', \n                               'cat8', 'cat9']]\n\nobjectColTrain.head()","de309f8c":"# Let's have a look at how many labels each variables has\nfor col in objectColTrain:\n    print(f'{col} : {len(objectColTrain[col].unique())} labels')","0ee8af47":"# Checking the first 5 rows\ntrain.head()","7c808e00":"# Coefficient of Target\ncovTarget = ((train['target'].std()\/train['target'].mean()) * 100)\nprint(f'Coefficient Of Variation Target : {covTarget}%')","d0e41fb6":"# Checking train data\ntest","fe16ef3a":"# Checking the type of data\ntest.dtypes.to_frame()","39050271":"# Checking the null value\ntrain.isna().mean().to_frame()","5bbc60c5":"# Looking for categorical data\nobjectColTest = test.loc[:, ['cat0', 'cat1', \n                             'cat2', 'cat3', \n                             'cat4', 'cat5', \n                             'cat6', 'cat7', \n                             'cat8', 'cat9']]\n\nobjectColTest.head()","2a978f9d":"# Let's have a look at how many labels each variables has\nfor col in objectColTest:\n    print(f'{col} : {len(objectColTest[col].unique())} labels')","5aa5cc5e":"# Checking the first 5 rows\ntest.head()","6b16822b":"y = train.target\n\ntrain.drop(['target', 'id'], axis = 1, inplace = True)\ntest.drop(['id'], axis = 1, inplace = True)\n\ntrain.head()","990b1c26":"print(\"Train shape: \", train.shape, \"\\nTest shape: \", test.shape)","b11c1571":"cat_cols = [col for col in train.columns if 'cat' in col]\n\nX = train.copy()\nX_test = test.copy()\n\nenc = OrdinalEncoder()\n\nX[cat_cols] = enc.fit_transform(train[cat_cols])\nX_test[cat_cols] = enc.transform(test[cat_cols])","4caca253":"X","b16cc71e":"# xgb_params = {'colsample_bytree': 0.31426530319123525,\n#             'gamma': 0.45519212869187453,\n#             'learning_rate': 0.06211498484648224,\n#             'max_depth': 6,\n#             'min_child_weight': 1.0,\n#             'n_estimators': 10000,\n#             'reg_alpha': 21.0,\n#             'reg_lambda': 0.9277740406539857,\n#             'subsample': 0.6254798229473668,\n#             'booster': 'gbtree', \n#             'random_state': 42,\n#             'seed': 91,\n#             'n_jobs': -1}\n\nxgb_params = {\n    'booster': 'gbtree',\n    'n_estimators': 12000,\n    'learning_rate': 0.05,\n    'reg_lambda': 0.001,\n    'reg_alpha': 25.5,\n    'subsample': 0.78,\n    'colsample_bytree': 0.12,\n    'max_depth': 3,\n    'random_state': 91 \n}","23a445f7":"#Setting the kfold parameters\nkf = KFold(n_splits = 7, shuffle = True, random_state = 42)\n\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\nmean_rmse = 0\n\nfor num, (train_id, valid_id) in enumerate(kf.split(X)):\n    X_train, X_valid = X.loc[train_id], X.loc[valid_id]\n    y_train, y_valid = y.loc[train_id], y.loc[valid_id]\n    \n    model = XGBRegressor(**xgb_params, tree_method='gpu_hist')\n    model.fit(X_train, y_train,\n             verbose = False,\n             eval_set = [(X_train, y_train), (X_valid, y_valid)],\n             eval_metric = \"rmse\",\n             early_stopping_rounds = 50)\n    \n    #Mean of the predictions\n    preds += model.predict(X_test) \/ 7 # Splits\n    \n    #Mean of feature importance\n    model_fi += model.feature_importances_ \/ 7 #splits\n    \n    #Out of Fold predictions\n    oof_preds[valid_id] = model.predict(X_valid)\n    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_id]))\n    print(f\"Fold {num} | RMSE: {fold_rmse}\")\n    \n    mean_rmse += fold_rmse \/ 7\n    \nprint(f\"\\nOverall RMSE: {mean_rmse}\")","a21f8d23":"sub.target = preds\nsub.head()","ef8ecb48":"sub.to_csv(\"submission_2.csv\", index = False)\nprint(\"sending\")","3d48faf2":"# **Train Check, Clean,  Encode**","f1058591":"# **Test Check, Clean, Encode**","00e70206":"Overall, the data Train and Test is quitely same","d59dd691":"# **Encode**","89d21e31":"# **Train Data**"}}