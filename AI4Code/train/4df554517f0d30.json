{"cell_type":{"ceb6d202":"code","1503cd97":"code","2be6440a":"code","c422c204":"code","f4c2d36c":"code","d25c0be5":"code","9fd81ca0":"code","f6ea7935":"code","556788ed":"code","89c25354":"code","9244b24d":"code","613cab7c":"code","4f41d22e":"code","77768518":"code","b013b01a":"code","1a6f7997":"code","82d1be1b":"code","2ea8d063":"code","8d5a4eac":"code","70da5440":"code","072d3fa5":"markdown","5e712a39":"markdown","bc81c700":"markdown","d11bc060":"markdown","f0f4bcde":"markdown","6345fc9b":"markdown"},"source":{"ceb6d202":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom random import randrange\n\nfrom matplotlib import pyplot as plt\nimport PIL\nimport cv2\n\nimport torch \nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn","1503cd97":"train_df = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\n#test_df = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","2be6440a":"train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)","c422c204":"def show_img_from_df(df, ind):\n    plt.imshow(np.reshape(np.array(df.iloc[ind,1:]), (28,28)), cmap=\"gray\")\n","f4c2d36c":"show_img_from_df(train_df, 2)","d25c0be5":"new_size = 90\n\ndf = train_df\nind = randrange(1000)\n\nimg = np.reshape(np.array(df.iloc[ind,1:]), (28,28))\n\n\nnew_img = np.zeros((new_size, new_size))\n\n# randomly select a bottom left corner to use for img\nx_min, y_min = randrange(new_size - img.shape[0]), randrange(new_size - img.shape[0])\nx_max, y_max = x_min + img.shape[0], y_min + img.shape[0]\n\nx_center = x_min + (x_max-x_min)\/2\ny_center = y_min + (y_max-y_min)\/2\n\n\nnew_img[x_min:x_max, y_min:y_max] = img\nnew_img = cv2.rectangle(new_img, (y_max, x_min), (y_min, x_max), 255, 1)\nplt.imshow(new_img, cmap=\"gray\")\n\nplt.plot(y_center, x_center, \"og\", markersize=10)\nplt.show()","9fd81ca0":"x_center, y_center","f6ea7935":"class CustomMnistDataset_OL(Dataset):\n    \n    def __init__(self, df, test=False):\n        '''\n        df is a pandas dataframe with 28x28 columns for each pixel value in MNIST\n        '''\n        self.df = df\n        self.test = test\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if self.test:\n            image = np.reshape(np.array(self.df.iloc[idx,:]), (28,28)) \/ 255.\n        else:\n            image = np.reshape(np.array(self.df.iloc[idx,1:]), (28,28)) \/ 255.\n        \n        # create the new image\n        new_img = np.zeros((90, 90)) # images will be 90x90\n        # randomly select a bottom left corner to use for img\n        x_min, y_min = randrange(90 - image.shape[0]), randrange(90 - image.shape[0])\n        x_max, y_max = x_min + image.shape[0], y_min + image.shape[0]\n        \n        x_center = x_min + (x_max-x_min)\/2\n        y_center = y_min + (y_max-y_min)\/2\n        \n        # try normalizing this part of the output\n        x_center = x_center #\/ 90.\n        y_center = y_center #\/ 90.\n        \n\n        new_img[x_min:x_max, y_min:y_max] = image\n        \n        #NEW\n        new_img = np.reshape(new_img, (1,90,90))\n        \n        label = [int(self.df.iloc[idx,0]), np.array([x_center, y_center]).astype('float32')] # the label consists of the digit and the center of the number\n        sample = {\"image\": new_img, \"label\": label}\n        \n        return sample['image'], sample['label']","556788ed":"trainingData = CustomMnistDataset_OL(train_df)\nvalData = CustomMnistDataset_OL(val_df)\n\ntrain_dataloader = DataLoader(trainingData, batch_size=64, shuffle=True)\nval_dataloader = DataLoader(valData, batch_size=64, shuffle=True)","89c25354":"cx = next(iter(train_dataloader))","9244b24d":"indx = randrange(63)\n\nplt.imshow(np.reshape(cx[0][indx], (90,90)))\nprint(\"Image shape: \" + str(list(cx[0][indx].shape)))\nprint(\"Digit: \" + str(int(cx[1][0][indx])))\nprint(\"Center: ({},{})\".format(str(int(cx[1][1][indx][0])), str(int(cx[1][1][indx][1]))))","613cab7c":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","4f41d22e":"class NeuralNetwork_OL_v2(nn.Module):\n    '''\n    New convolutional model (v2)\n    '''\n    def __init__(self):\n        super(NeuralNetwork_OL_v2, self).__init__()\n        \n        self.conv0 = nn.Conv2d(1, 16, 3, padding=(2,2)) # 3x3 filters w\/ same padding\n        self.pool0 = nn.MaxPool2d(2, stride=2)\n        self.conv1 = nn.Conv2d(16, 16, 3, padding=(3,3)) # 3x3 filters w\/ same padding\n        self.pool1 = nn.MaxPool2d(2, stride=2)\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(16*25*25, 256), \n             nn.ReLU(),\n#             nn.Dropout(p=0.2),\n#             nn.Linear(256, 256), \n#             nn.ReLU(),\n#             nn.Dropout(p=0.5),\n#             nn.Linear(256, 256), \n#             nn.ReLU()\n        )\n        self.linear = nn.Linear(256, 10)\n        self.linear_x = nn.Linear(256, 1)\n        self.linear_y = nn.Linear(256, 1)\n        self.linear_all = nn.Linear(256, 2)\n        \n        \n    \n    def forward(self, x):\n        x = self.conv0(x)\n#         print(x.shape)\n        x = F.relu(self.pool0(x))\n#         print(x.shape)\n        x = self.conv1(x)\n#         print(x.shape)\n        x = F.relu(self.pool1(x))\n#         print(x.shape)\n        x = self.flatten(x)\n        x = self.linear_relu_stack(x)\n        logits = self.linear(x)\n#         x_cent = self.linear_x(x)\n#         y_cent = self.linear_y(x)\n        centr = self.linear_all(x)\n        return logits, centr#logits, x_cent, y_cent\n\nmodel = NeuralNetwork_OL_v2().to(device)\nprint(model)","77768518":"loss_fn = nn.CrossEntropyLoss()\nloss_mse = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)#torch.optim.SGD(model.parameters(), lr=1e-3)\nalpha = 100\nbeta = 1","b013b01a":"def train(dataloader, model, loss_fn, loss_mse, optimizer, alpha, beta):\n    model.train() # very important... This turns the model back to training mode\n    size = len(train_dataloader.dataset)\n    \n    loss_dig_list = []\n    loss_center_list = []\n    \n    for batch, (X, y) in enumerate(dataloader):\n\n        X, y0, y1 = X.to(device), y[0].to(device), y[1].to(device)\n\n        y0_pred, y1_pred = model(X.float())\n        \n        loss = alpha*loss_fn(y0_pred, y0) + beta*loss_mse(y1_pred, y1.float())\n        loss_dig = loss_fn(y0_pred, y0)\n        loss_center = loss_mse(y1_pred, y1.float())\n        \n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch*len(X)\n            \n            loss_dig = loss_dig.item()\n            loss_center = loss_center.item()\n            \n            loss_dig_list.append(loss_dig)\n            loss_center_list.append(loss_center)\n            \n            print(f\"MAIN loss: {loss:>7f}  [{current:>5d}\/{size:>5d}]\")\n            print(f\"Digit prediction loss: {loss_dig:>7f}  [{current:>5d}\/{size:>5d}]\")\n            print(f\"Coordinate prediction loss: {loss_center:>7f}  [{current:>5d}\/{size:>5d}]\")\n            print(\"-----------\")\n            ","1a6f7997":"# TODO: make this work for three outputs....\n\ndef test(dataloader, model, loss_fn, loss_mse, alpha=alpha, beta=beta):\n    size = len(dataloader.dataset)\n    model.eval()\n    test_loss, test_loss_y0, test_loss_y1, correct = 0, 0, 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y0, y1 = X.to(device), y[0].to(device), y[1].to(device)\n            y0_pred, y1_pred = model(X.float())\n            test_loss += alpha*loss_fn(y0_pred, y0).item() + beta*loss_mse(y1_pred, y1.float()).item()\n            test_loss_y0 += loss_fn(y0_pred, y0).item()\n            test_loss_y1 += loss_mse(y1_pred, y1.float()).item()\n            \n            correct += (y0_pred.argmax(1) == y0).type(torch.float).sum().item() # only for digit predictions\n            \n    # average the loss and accuracy among all records used in the dataset\n    test_loss \/= size\n    test_loss_y0 \/= size\n    test_loss_y1 \/= size\n    correct \/= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg digit loss: {test_loss_y0:>8f}, Avg coordinate loss: {test_loss_y1:>8f} \\n\")","82d1be1b":"epochs = 10\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, loss_mse, optimizer, alpha=alpha, beta=beta)\n    test(val_dataloader, model, loss_fn, loss_mse, alpha=alpha, beta=beta)\nprint(\"Done!\")","2ea8d063":"(X, y) = next(iter(val_dataloader))","8d5a4eac":"indx = randrange(63)\ny_center_actual, x_center_actual = int(y[1][indx][0]), int(y[1][indx][1])\n\ndigit_pred, center_pred = model(X.to(device).float())\n\npredicted_digit = np.argmax(digit_pred[indx].cpu().detach().numpy())\n\npredicted_x = int(center_pred[indx][0])\npredicted_y = int(center_pred[indx][1])","70da5440":"indx = randrange(63)\ny_center_actual, x_center_actual = int(y[1][indx][0]), int(y[1][indx][1])\n\ndigit_pred, center_pred = model(X.to(device).float())\n\npredicted_digit = np.argmax(digit_pred[indx].cpu().detach().numpy())\n\npredicted_x = int(center_pred[indx][0])\npredicted_y = int(center_pred[indx][1])\n\n\nplt.imshow(np.reshape(X[indx].cpu().numpy(), (90,90)), cmap=\"gray\")\n# plot the actual center in green\nplt.plot(x_center_actual, y_center_actual, \"og\", markersize=10)\n# plot the predicted center in orange\nplt.plot(predicted_y, predicted_x, \"oy\", markersize=10)\nplt.show()\n\nprint(\"Image shape: \" + str(list(X[indx].cpu().numpy().shape)))\nprint(\"Digit: \" + str(int(y[0][indx])))\nprint(\"True Center (in green): ({},{})\".format(y_center_actual, x_center_actual))\nprint(\"-------------------------------\")\nprint(\"Predicted Digit: \"+str(predicted_digit))\nprint(\"Predicted Center (in yellow): ({},{})\".format(str(predicted_x), str(predicted_y)))\n","072d3fa5":"# Randomly place the digit within a larger sized picture\n\n(Later we want to create MNist images with borders and work on object detection)","5e712a39":"# All of the predicted centers appear to verry close to the center of the image....","bc81c700":"# Test a training example out","d11bc060":"The below code works great for predicting digits when we only use the cross entropy loss (alpha=1, beta=0)\n\nAnd also works great for predicting the center of the digit when we only use the MSE (alpha=0, beta=1)\n\nBut works horrible when combining the two losses....\n\n\nQuestion:\nShould we be doing a two-headed network?\nIf we should have the prediction all be a single output, how will we structure the loss function? Should we use MSE for predicting digits too?","f0f4bcde":"# Very basic object localization\nAndrew Ng's lecture: https:\/\/www.youtube.com\/watch?v=GSwYGkTfOKk&list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs","6345fc9b":"# For digits + center"}}