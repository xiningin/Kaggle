{"cell_type":{"c2e8dcb0":"code","65269831":"code","31157012":"code","a4601edf":"code","842e5b75":"code","706748e1":"markdown"},"source":{"c2e8dcb0":"import numpy as np, sys,os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.io import loadmat\nimport wfdb\nimport tarfile\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.preprocessing.sequence import pad_sequences\nimport math\nimport warnings\nimport os\nfrom keras.layers import Conv1D\nfrom keras.layers import Input\nfrom keras.layers import Activation\nfrom keras.layers import Flatten\nfrom keras.layers import Conv1DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Reshape\nfrom keras.initializers import RandomNormal\nfrom keras.layers import GlobalAveragePooling1D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import UpSampling1D\nfrom keras.layers import Bidirectional\nfrom keras.layers import LSTM\nfrom keras.layers import Permute\nfrom keras.layers import Dropout\nfrom keras.layers import MaxPool1D\nfrom keras.layers import Embedding\nfrom keras.models import Model\nfrom numpy import hstack\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import rand\nfrom numpy.random import randn\nfrom keras.models import Sequential\nfrom keras.layers import Dense","65269831":"def load_challenge_data(filename):\n    x = loadmat(filename)\n    data = np.asarray(x['val'], dtype=np.float64)\n    new_file = filename.replace('.mat','.hea')\n    input_header_file = os.path.join(new_file)\n    with open(input_header_file,'r') as f:\n        header_data=f.readlines()\n    return data, header_data\n\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()","31157012":"X_exp_train = []\ncount = 0\nfor ecgfilename in sorted(os.listdir(\"..\/input\/china-physiological-signal-challenge-in-2018\/Training_WFDB\/\")):\n    if ecgfilename.endswith(\".mat\"):\n        data = load_challenge_data(\"..\/input\/china-physiological-signal-challenge-in-2018\/Training_WFDB\/\" + ecgfilename)[0]\n        ecg = pad_sequences(data, maxlen=5000, truncating='post',padding=\"post\")\n        ecg_new = ecg.reshape(5000,12)\n        X_exp_train.append(ecg_new)\n        count = count +1\n        if count == 1000:\n            break\nX_exp_train = np.asarray(X_exp_train)","a4601edf":"def define_discriminator_old():\n    model = Sequential()\n    model.add(Input(shape=(5000,12)))\n    model.add(Conv1D(filters=36,kernel_size=5, strides=2))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(Conv1D(filters=24,kernel_size=3, strides=2))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(Conv1D(filters=12,kernel_size=3, strides=2))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(GlobalAveragePooling1D())\n    #model.add(Dense(25, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\ndef define_discriminator():\n    model = Sequential()\n    model.add(Input(shape=(5000,12)))\n    model.add(Conv1D(filters=32, kernel_size=16, strides=1, padding='same'))\n    model.add(LeakyReLU())\n    model.add(Conv1D(filters=64, kernel_size=16, strides=1, padding='same'))\n    model.add(LeakyReLU())\n    model.add(MaxPool1D(pool_size=2))\n    model.add(Conv1D(filters=128, kernel_size=16, strides=1, padding='same'))\n    model.add(LeakyReLU())\n    model.add(Conv1D(filters=256, kernel_size=16, strides=1, padding='same'))\n    model.add(LeakyReLU())\n    model.add(MaxPool1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\ndef define_generator(latent_dim):\n    init = RandomNormal(stddev=0.02)\n    model = Sequential()\n    model.add(Input(shape=(latent_dim,)))\n    model.add(Dense(5000, kernel_initializer=init, input_dim=latent_dim))\n    model.add(Reshape((5000,1)))\n    model.add(Bidirectional(LSTM(24, return_sequences=True,activation='tanh'), merge_mode='sum'))\n    model.add(Dropout(0.5, noise_shape=None, seed=None))\n    model.add(Dense(12, activation='tanh'))\n    return model\n \n# define the combined generator and discriminator model, for updating the generator\ndef define_gan(generator, discriminator):\n    # make weights in the discriminator not trainable\n    discriminator.trainable = False\n    # connect them\n    model = Sequential()\n    # add generator\n    model.add(generator)\n    # add the discriminator\n    model.add(discriminator)\n    # compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n    return model\n \n# generate n real samples with class labels\ndef generate_real_samples(ecgsignal,n):\n    # generate inputs in [-0.5, 0.5]\n    X = ecgsignal[np.random.choice(ecgsignal.shape[0],n)]\n    # generate class labels\n    y = ones((n, 1))\n    return X, y\n \n# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n):\n    # generate points in the latent space\n    x_in = randn(latent_dim*n).reshape(n,latent_dim)\n    # reshape into a batch of inputs for the network\n    return x_in\n \n# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(latent_dim,generator,n):\n    # generate points in latent space\n    x_input = generate_latent_points(latent_dim,n)\n    # predict outputs\n    X = generator.predict(x_input)\n    # create class labels\n    y = zeros((n, 1))\n    return X, y\n \n# evaluate the discriminator and plot real and fake points\ndef summarize_performance(epoch, generator, discriminator, latent_dim, ecgsignal, n=1):\n    # prepare real samples\n    x_real, y_real = generate_real_samples(ecgsignal,n)\n    # evaluate discriminator on real examples\n    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n    # prepare fake examples\n    x_fake, y_fake = generate_fake_samples(latent_dim, generator,n)\n    # evaluate discriminator on fake examples\n    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n    # summarize discriminator performance\n    print(epoch, acc_real, acc_fake)\n    # scatter plot real and fake data points\n    plt.plot(x_fake.reshape(12,5000)[1], color=\"red\")\n    plt.plot(x_real.reshape(12,5000)[1], color=\"green\")\n    plt.savefig(\"model_after{}epocs.png\".format(epoch))\n    plt.show()\n \n\ndef train(g_model, d_model, gan_model, ecg_sig, latent_dim,n_epochs=100, n_batch=128, n_eval=10):\n    # determine half the size of one batch, for updating the discriminator\n    half_batch = int(n_batch \/ 2)\n    # manually enumerate epochs\n    for i in range(n_epochs):\n        # prepare real samples\n        x_real, y_real = generate_real_samples(ecg_sig,half_batch)\n        # prepare fake examples\n        x_fake, y_fake = generate_fake_samples(latent_dim,g_model,half_batch)\n        # update discriminator\n        d_model.train_on_batch(x_real, y_real)\n        d_model.train_on_batch(x_fake, y_fake)\n        # prepare points in latent space as input for the generator\n        x_gan = generate_latent_points(latent_dim,n_batch)\n        # create inverted labels for the fake samples\n        y_gan = ones((n_batch, 1))\n        # update the generator via the discriminator's error\n        gan_model.train_on_batch(x_gan, y_gan)\n        # evaluate the model every n_eval epochs\n        if (i+1) % n_eval == 0:\n            summarize_performance(i, g_model, d_model, latent_dim, ecg_sig)","842e5b75":"# size of the latent space\nlatent_dim = 100\n# create the discriminator\ndiscriminator = define_discriminator()\n# create the generator\ngenerator = define_generator(latent_dim)\n# create the gan\ngan_model = define_gan(generator, discriminator)\n# train model\ntrain(generator, discriminator, gan_model, (X_exp_train.reshape(1000,5000,12)\/1000),latent_dim, n_epochs=100, n_batch=128, n_eval=10)","706748e1":"# <center>GAN on ECG<\/center>\n## <center>In this experiment GAN is used to create synthetic ECGs by comparint them with 12 Lead ECGs from China Physiological Signal Challenge<\/center>"}}