{"cell_type":{"33912438":"code","a8dbc116":"code","ca52d153":"code","daff7c7f":"code","abb58800":"code","8984a704":"code","9380fb8b":"code","ea9f90e1":"code","2f069832":"code","3170562a":"code","7e3f694c":"code","42ae16f1":"code","31dd102a":"code","b10b60df":"code","3751e108":"code","0a033dd2":"code","9958d8f8":"code","eb0da592":"code","e3212237":"code","7ff68d13":"code","a1533438":"code","1ce16a57":"code","2cec15fe":"code","2cac88d9":"code","c7d8a2e2":"code","3fb4cfb4":"code","6ab3f204":"code","3476291c":"code","0361e7e1":"code","0b74b378":"code","4755fb58":"code","c55f46ff":"code","4db3a416":"code","89f2c54d":"code","40e3a2a3":"markdown","ef1e98bc":"markdown","e5a2848a":"markdown","87d36fea":"markdown","de5b33c0":"markdown","8ec80e6e":"markdown","65b7b0f7":"markdown","034eb37d":"markdown","4cb49f81":"markdown"},"source":{"33912438":"!pip install torchsummary\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport random\nimport os\nfrom PIL import Image\n\nimport torch\nfrom torchsummary import summary\nfrom torch import nn, optim\nfrom torch.functional import F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torch.autograd import Variable","a8dbc116":"plt.style.use('seaborn-whitegrid')\nplt.rcParams['lines.linewidth'] = 2\nplt.rcParams['font.sans-serif'] = 'Arial'\nplt.rcParams['text.color'] = 'black'\nplt.rcParams['axes.labelcolor']= 'black'\nplt.rcParams['xtick.color'] = 'black'\nplt.rcParams['ytick.color'] = 'black'\nplt.rcParams['font.size']=12","ca52d153":"SEED = 1234\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","daff7c7f":"data_dir = '..\/input\/dog-breed-identification\/'\nlabels = pd.read_csv(os.path.join(data_dir, 'labels.csv'))\nassert(len(os.listdir(os.path.join(data_dir, 'train'))) == len(labels))","abb58800":"labels.head()","8984a704":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabels.breed = le.fit_transform(labels.breed)\nlabels.head()","9380fb8b":"X = labels.id\ny = labels.breed\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size=0.4, random_state=SEED, stratify=y)\nX_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=SEED, stratify=y_valid)","ea9f90e1":"class Dataset_Interpreter(Dataset):\n    def __init__(self, data_path, file_names, labels=None, transforms=None):\n        self.data_path = data_path\n        self.file_names = file_names\n        self.labels = labels\n        self.transforms = transforms\n        \n    def __len__(self):\n        return (len(self.file_names))\n    \n    def __getitem__(self, idx):\n        img_name = f'{self.file_names.iloc[idx]}.jpg'\n        full_address = os.path.join(self.data_path, img_name)\n        image = Image.open(full_address)\n        label = self.labels.iloc[idx]\n        \n        if self.transforms is not None:\n            image = self.transforms(image)\n            \n        return np.array(image), label","2f069832":"def plot_images(images):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure(figsize=(20,10))\n    for i in range(rows*cols):\n        ax = fig.add_subplot(rows, cols, i+1)\n        ax.set_title(f'{le.inverse_transform([images[i][1]])}')\n        ax.imshow(np.array(images[i][0]))\n        ax.axis('off')\n        ","3170562a":"N_IMAGES = 9\n\ntrain_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_train, labels=y_train)\nimages = [(image, label) for image, label in [train_data[i] for i in range(N_IMAGES)]] \nplot_images(images)","7e3f694c":"normalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\ntransforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\ntrain_transforms = transforms.Compose([transforms.Resize(32),\n                               transforms.CenterCrop(32),\n                               transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n                               transforms.RandomHorizontalFlip(p=0.5),\n                               transforms.RandomVerticalFlip(p=0.5),\n                               transforms.RandomGrayscale(p=0.1), \n                               transforms.ToTensor(),\n                               normalize])\ntest_transforms = transforms.Compose([transforms.Resize(32),\n                               transforms.CenterCrop(32),\n                               transforms.ToTensor(),\n                               normalize])\n\ntrain_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_train, labels=y_train, transforms=train_transforms)\nvalid_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_valid, labels=y_valid, transforms=test_transforms)\ntest_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_test, labels=y_test, transforms=test_transforms)","42ae16f1":"print(f'Number of training examples: {len(train_data)}')\nprint(f'Number of validation examples: {len(valid_data)}')\nprint(f'Number of testing examples: {len(test_data)}')","31dd102a":"BATCH_SIZE = 64\n\ntrain_iterator = DataLoader(train_data, shuffle=True, batch_size= BATCH_SIZE)\nvalid_iterator = DataLoader(valid_data, batch_size=BATCH_SIZE)\ntest_iterator = DataLoader(test_data, batch_size = BATCH_SIZE)","b10b60df":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time \/ 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\ndef calculate_accuracy(y_pred, y):\n    top_pred = y_pred.argmax(1, keepdim = True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() \/ y.shape[0]\n    return acc","3751e108":"class LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5), #stride=1, padding=0 is a default\n            nn.ReLU(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n            nn.ReLU(),\n            nn.AvgPool2d(kernel_size=2, stride=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(16*5*5, 120),\n            nn.ReLU(),\n            nn.Linear(120, 84),\n            nn.ReLU(),\n            nn.Linear(84, 120)   #num_classes = 120\n        )\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        x = self.features(x)\n        x = x.view(batch_size, -1)\n        x = self.classifier(x)\n        \n        return x\nmodel = LeNet().to(device)\nsummary(model, (3, 32, 32))","0a033dd2":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel= LeNet().to(device)\nloss_criterion = nn.CrossEntropyLoss().to(device)\noptimizer=optim.Adam(model.parameters())\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","9958d8f8":"def train(model, iterator, optimizer, criterion, device):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.train()\n    \n    for (x, y) in iterator:\n        \n        x = Variable(torch.FloatTensor(np.array(x))).to(device)\n        y = Variable(torch.LongTensor(y)).to(device)\n        \n        optimizer.zero_grad()\n                \n        y_pred = model(x)\n        \n        loss = criterion(y_pred, y)\n        \n        acc = calculate_accuracy(y_pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n    return epoch_loss \/ len(iterator), epoch_acc \/ len(iterator)","eb0da592":"def evaluate(model, iterator, criterion, device):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        \n        for (x, y) in iterator:\n\n            x = Variable(torch.FloatTensor(np.array(x))).to(device)\n            y = Variable(torch.LongTensor(y)).to(device)\n        \n            y_pred = model(x)\n\n            loss = criterion(y_pred, y)\n\n            acc = calculate_accuracy(y_pred, y)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss \/ len(iterator), epoch_acc \/ len(iterator)","e3212237":"def fit_model(model, model_name, train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs):\n    \"\"\" Fits a dataset to model\"\"\"\n    best_valid_loss = float('inf')\n    \n    train_losses = []\n    valid_losses = []\n    train_accs = []\n    valid_accs = []\n    \n    for epoch in range(epochs):\n    \n        start_time = time.time()\n    \n        train_loss, train_acc = train(model, train_iterator, optimizer, loss_criterion, device)\n        valid_loss, valid_acc = evaluate(model, valid_iterator, loss_criterion, device)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        train_accs.append(train_acc*100)\n        valid_accs.append(valid_acc*100)\n    \n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n            torch.save(model.state_dict(), f'{model_name}.pt')\n    \n        end_time = time.time()\n\n        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n        \n    return pd.DataFrame({f'{model_name}_Training_Loss':train_losses, \n                        f'{model_name}_Training_Acc':train_accs, \n                        f'{model_name}_Validation_Loss':valid_losses, \n                        f'{model_name}_Validation_Acc':valid_accs})","7ff68d13":"train_stats_LeNet = fit_model(model, 'LeNet', train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs=20)","a1533438":"def plot_training_statistics(train_stats, model_name):\n    \n    fig, axes = plt.subplots(2, figsize=(15,15))\n    axes[0].plot(train_stats[f'{model_name}_Training_Loss'], label=f'{model_name}_Training_Loss')\n    axes[0].plot(train_stats[f'{model_name}_Validation_Loss'], label=f'{model_name}_Validation_Loss')\n    axes[1].plot(train_stats[f'{model_name}_Training_Acc'], label=f'{model_name}_Training_Acc')\n    axes[1].plot(train_stats[f'{model_name}_Validation_Acc'], label=f'{model_name}_Validation_Acc')\n    \n    axes[0].set_xlabel(\"Number of Epochs\"), axes[0].set_ylabel(\"Loss\")\n    axes[1].set_xlabel(\"Number of Epochs\"), axes[1].set_ylabel(\"Accuracy in %\")\n    \n    axes[0].legend(), axes[1].legend()","1ce16a57":"plot_training_statistics(train_stats_LeNet, 'LeNet')","2cec15fe":"from torchvision import models\nmodel = models.resnet18(pretrained=True).to(device)\nprint(model)","2cac88d9":"for name, param in model.named_parameters():\n    if(\"bn\" not in name):\n        param.requires_grad = False","c7d8a2e2":"model.fc = nn.Linear(model.fc.in_features,120).to(device)\noptimizer = optim.Adam(model.parameters(), lr = 1e-2)","3fb4cfb4":"normalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\ntransforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\ntrain_transforms = transforms.Compose([transforms.Resize(224),\n                               transforms.CenterCrop(224),\n                               transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n                               transforms.RandomHorizontalFlip(p=0.5),\n                               transforms.RandomVerticalFlip(p=0.5),\n                               transforms.RandomGrayscale(p=0.1), \n                               transforms.ToTensor(),\n                               normalize])\ntest_transforms = transforms.Compose([transforms.Resize(224),\n                               transforms.CenterCrop(224),\n                               transforms.ToTensor(),\n                               normalize])\n\ntrain_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_train, labels=y_train, transforms=train_transforms)\nvalid_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_valid, labels=y_valid, transforms=test_transforms)\ntest_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_test, labels=y_test, transforms=test_transforms)\n\nBATCH_SIZE = 64\n\ntrain_iterator = DataLoader(train_data, shuffle=True, batch_size= BATCH_SIZE)\nvalid_iterator = DataLoader(valid_data, batch_size=BATCH_SIZE)\ntest_iterator = DataLoader(test_data, batch_size = BATCH_SIZE)","6ab3f204":"train_stats_ResNet18 = fit_model(model, 'ResNet18', train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs=20)","3476291c":"plot_training_statistics(train_stats_ResNet18, 'ResNet18')","0361e7e1":"from torchvision import models\nmodel = models.resnet34(pretrained=True).to(device)\nprint(model)","0b74b378":"for name, param in model.named_parameters():\n    if(\"bn\" not in name):\n        param.requires_grad = False","4755fb58":"model.fc = nn.Linear(model.fc.in_features,120).to(device)\noptimizer = optim.Adam(model.parameters(), lr = 1e-2)","c55f46ff":"normalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\ntransforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\ntrain_transforms = transforms.Compose([transforms.Resize(224),\n                               transforms.CenterCrop(224),\n                               transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n                               transforms.RandomHorizontalFlip(p=0.5),\n                               transforms.RandomVerticalFlip(p=0.5),\n                               transforms.RandomGrayscale(p=0.1), \n                               transforms.ToTensor(),\n                               normalize])\ntest_transforms = transforms.Compose([transforms.Resize(224),\n                               transforms.CenterCrop(224),\n                               transforms.ToTensor(),\n                               normalize])\n\ntrain_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_train, labels=y_train, transforms=train_transforms)\nvalid_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_valid, labels=y_valid, transforms=test_transforms)\ntest_data = Dataset_Interpreter(data_path=data_dir+'train\/', file_names=X_test, labels=y_test, transforms=test_transforms)\n\nBATCH_SIZE = 64\n\ntrain_iterator = DataLoader(train_data, shuffle=True, batch_size= BATCH_SIZE)\nvalid_iterator = DataLoader(valid_data, batch_size=BATCH_SIZE)\ntest_iterator = DataLoader(test_data, batch_size = BATCH_SIZE)","4db3a416":"train_stats_ResNet34 = fit_model(model, 'ResNet34', train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs=20)","89f2c54d":"plot_training_statistics(train_stats_ResNet34, 'ResNet34')","40e3a2a3":"## Importing Modules and Fixing Seeds","ef1e98bc":"## Training on LeNet-5 From Scratch","e5a2848a":"## Training on ResNet-18 with Transfer Learning","87d36fea":"## Training on ResNet-34 with Transfer Learning","de5b33c0":"![image.png](attachment:image.png)","8ec80e6e":"You might not want to freeze the BatchNorm layers in a model, as they will be trained to approximate the mean and standard deviation of the dataset that the model was originally trained on, not the dataset that you want to fine-tune on. Some of the signal from your data may end up being lost as BatchNorm corrects your input. You can look at the model structure and freeze only layers that aren\u2019t BatchNorm like this:","65b7b0f7":"## Getting Data Ready For Deep Learning","034eb37d":"# Fine Grained Image Classification","4cb49f81":"## Looking at The Data and Creating The Dataset For Deep Learning"}}