{"cell_type":{"fdeeb1df":"code","70fb74cc":"code","73ece0ce":"code","1c8826e5":"code","84363882":"code","857405c9":"code","12955db6":"code","51de9fea":"code","263b2525":"code","abeca71e":"code","f4588123":"code","a64e1d8c":"code","3e22b785":"code","43f94e40":"code","a574483f":"code","1df85ffb":"code","5198602f":"code","25c98f3e":"code","08deea64":"code","42c8a008":"code","116f310a":"code","477efbfb":"code","48a92b22":"code","34f68de8":"code","24191ca6":"code","a568f990":"code","7127d43d":"code","023020db":"code","91c3d35c":"code","bf213c1b":"code","263a9dd4":"code","8247d613":"code","9cace36d":"code","7af6bc5a":"code","84f16a5d":"code","62dfea60":"code","2a8d4fcc":"code","91add020":"code","6248b6a3":"code","1800c01e":"code","6f01a1b1":"code","01693808":"code","8942aacf":"code","aedd608c":"code","af8b2892":"code","07c708e4":"code","7dc1ce92":"code","0ce985ff":"code","8797d9a8":"code","e9d4fe1c":"code","c0f2d712":"code","257b485e":"code","e2f79a4e":"code","cfd91ad8":"code","2d8343ac":"code","69049813":"code","0270c613":"code","9b75cb6b":"code","ef7ecec7":"code","98f87d11":"markdown","11389cdd":"markdown","41977bae":"markdown","0c4a172d":"markdown","2a85f840":"markdown","0d849d1a":"markdown","e27fffbc":"markdown","c4ef5806":"markdown","94451e5f":"markdown","e4ea06a9":"markdown","c6697b30":"markdown","dbc8d179":"markdown","63cb47f5":"markdown","dd74fff3":"markdown","3b214b00":"markdown","df090e29":"markdown","3240ea4c":"markdown","174ce46d":"markdown","253cfc38":"markdown","35f65b2f":"markdown","be2ed51b":"markdown","0c036674":"markdown","35953754":"markdown","545d7b97":"markdown","f14c8a57":"markdown","6e9f004e":"markdown","a6cc1bfe":"markdown","29daf47b":"markdown","c8c18452":"markdown","2d651653":"markdown","473979d9":"markdown"},"source":{"fdeeb1df":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nfrom tqdm import tqdm","70fb74cc":"pd.set_option('display.max_colwidth',200)","73ece0ce":"train_dir='..\/data\/train\/audio'\nSAMPLE_RATE=16000\nN_FFT = 512\nHOP_LENGTH=128","1c8826e5":"def load_train_data(path):\n    tmp_list=[]\n    for (dirpath, dirnames, filenames) in os.walk(path):\n        for file in filenames:\n            if file.endswith('.wav'):\n                tmp_path=os.path.join(dirpath, file)\n                class_label = tmp_path.split('\/')[-2]\n                data,_ = librosa.load(tmp_path,sr=SAMPLE_RATE)\n                tmp_list.append([tmp_path,class_label,data])\n            else:\n                continue\n    return  pd.DataFrame(tmp_list,columns=['file_path','class_label','data'])","84363882":"train_df = load_train_data(train_dir)\ntrain_df","857405c9":"noise_records_index = train_df.loc[train_df.class_label=='_background_noise_'].index\nnoise_df = train_df.iloc[noise_records_index].reset_index(drop=True)\ntrain_df = train_df.drop(noise_records_index).reset_index(drop=True)\ndel noise_records_index","12955db6":"validation_labels =  'yes, no, up, down, left, right, on, off, stop, go'.split(', ')","51de9fea":"tmp = [col for col in train_df.class_label.unique() if col not in validation_labels]\nprint(tmp)","263b2525":"# train_df.loc[~train_df.class_label.isin(validation_labels),'class_label'].count()\/len(tmp)\nnot_val_records_increas_selec = pd.DataFrame(columns=['file_path','class_label','data'])\nfor label in tmp:\n    selected_label_records = train_df.loc[train_df.class_label == label]\n    resempled = selected_label_records.sample(n=2350,replace=True,axis=0)\n    not_val_records_increas_selec = pd.concat([not_val_records_increas_selec,resempled], ignore_index=True)\n    del selected_label_records, resempled\nnot_val_records_increas_selec","abeca71e":"# unknown records indexes\n# unknown_record_index = [indx for indx in train_df.index if train_df.loc[indx,'class_label'] not in validation_labels]\n# unknown_record_index = train_df.loc[train_df.class_label.isin(validation_labels)].index","f4588123":"train_df = train_df.drop(train_df.loc[~train_df.class_label.isin(validation_labels)].index).reset_index(drop=True)\ntrain_df.class_label.value_counts()","a64e1d8c":"train_df = pd.concat([train_df,not_val_records_increas_selec], ignore_index=True)\ndisplay(train_df.head(3))\ndisplay(train_df.class_label.value_counts())","3e22b785":"train_df.loc[train_df.loc[~train_df.class_label.isin(validation_labels)].index,'class_label'] = 'unknown'\ndisplay(train_df.class_label.value_counts())","43f94e40":"def make_silence_records(noise_df):\n    silence_df = pd.DataFrame(columns=['file_path','class_label','data'])\n    for indx in noise_df.index:\n        record = noise_df.loc[indx,'data']\n        record_length = len(record)\n        duration = int(record_length\/SAMPLE_RATE)\n        zeros = np.zeros(SAMPLE_RATE)\n        for i in range(duration*7):\n            random_sample = np.random.choice(record,SAMPLE_RATE)\n            silence_df = silence_df.append(\n                pd.Series([noise_df.loc[indx,'file_path'],'silence',  random_sample],\n                          index=['file_path','class_label','data']),\n                ignore_index=True,)  \n            silence_df = silence_df.append(\n                pd.Series(['own_made_silence','silence',\n                           zeros],\n                          index=['file_path','class_label','data']),\n                ignore_index=True,)\n#         silence_df = silence_df.sample(frac=1).reset_index(drop=True)\n    return silence_df","a574483f":"silence_df = make_silence_records(noise_df)\nsilence_df.tail()","1df85ffb":"def pad_records_length(df):\n    smaller=0\n    bigger =0\n    df = df.copy()\n    SAMPLES_PER_TRACK= 16000\n    for indx in df.index:\n        record = df.loc[indx,'data']\n        if len(record)<SAMPLES_PER_TRACK:\n            smaller+=1\n            tmp = np.zeros(SAMPLES_PER_TRACK)\n            tmp[:record.shape[0]]=record\n            df.loc[indx,'data']= tmp\n            del tmp\n        elif len(record)>SAMPLES_PER_TRACK:\n            bigger+=1\n            df.loc[indx,'data']= record[:SAMPLES_PER_TRACK]   \n    print(f'Record {bigger} - bigger than 1s\\nRecords smaller then 1s = {smaller}')\n    return df","5198602f":"train_df = pad_records_length(train_df)","25c98f3e":"def center_records(data,sr=16000):\n    df = data.copy()\n    df['centered'] = None\n    half = sr\/\/2\n    for indx in tqdm(df.index):\n        data = df.loc[indx,'data']\n        center = np.argmax(data)\n        if center<half:\n            shift = int(half-center)\n            centered_data = np.roll(data, shift)\n        elif center>half:\n            shift = int(half-center)\n            centered_data = np.roll(data, shift)\n        df.at[indx,'centered'] = centered_data\n    return df","08deea64":"train_df=center_records(train_df)\ntrain_df.head(2)","42c8a008":"def is_bad_audio(df,column_name = 'data'):\n    df = df.copy()\n    df['is_bad'] = None\n    for indx in df.index:\n        data = df.loc[indx,column_name]\n        features=librosa.feature.spectral_centroid(y=data,sr=16000,n_fft=512,hop_length=128)[0]\n        m = np.mean(features)\n        t = np.std(features)\n        if  t < 80:\n            # silent\n            df.loc[indx,'is_bad']='silent'\n        elif (m > 2550 and t < 300):\n            # noisy\n            df.loc[indx,'is_bad']='noise'\n        elif (m > 3500 and t > 1200):\n            # distorted\n            df.loc[indx,'is_bad']='distorted'\n        else:\n            df.loc[indx,'is_bad']='good'\n    return df","116f310a":"train_df = is_bad_audio(train_df)\ndisplay(train_df.head(1))\ndisplay(train_df.is_bad.value_counts())","477efbfb":"#  changing noise records to silent class all distorted to unknown and dropping silent \ndistorted_indx = train_df.loc[train_df.is_bad=='distorted'].index\nnoise_indx = train_df.loc[train_df.is_bad=='noise'].index\nsilent_indx = train_df.loc[train_df.is_bad=='silent'].index","48a92b22":"train_df.loc[[*distorted_indx,*silent_indx],'class_label'] = 'unknown'\ntrain_df.loc[noise_indx,'class_label'] = 'silence'\n# train_df = train_df.drop(silent_indx).reset_index(drop=True)","34f68de8":"train_df.class_label.value_counts()","24191ca6":"# selected manually\nsilent = \"..\/data\/train\/audio\/stop\/1fd85ee4_nohash_0.wav\"\n\nwrong_words = ['..\/data\/train\/audio\/right\/46a153d8_nohash_4.wav',\n               '..\/data\/train\/audio\/down\/c9b653a0_nohash_1.wav',\n               '..\/data\/train\/audio\/dog\/94de6a6a_nohash_0.wav']\n\nbad_records = ['..\/data\/train\/audio\/on\/99b05bcf_nohash_0.wav',\n               '..\/data\/train\/audio\/up\/a13e0a74_nohash_0.wav',\n               '..\/data\/train\/audio\/no\/e5dadd24_nohash_0.wav']","a568f990":"train_df.loc[train_df.file_path.isin([*wrong_words,*bad_records]),'class_label'] = 'unknown'\ntrain_df.loc[train_df.file_path=='silent','class_label'] = 'silence'","7127d43d":"merged_df = pd.concat([train_df,silence_df], ignore_index=True)\nmerged_df.head(2)","023020db":"# change records  with none values in centered column to data column values\ncentered_nan_index = merged_df.loc[merged_df.centered.isna()==True].index\nmerged_df.loc[centered_nan_index,'centered'] = merged_df.loc[centered_nan_index,'data']\nmerged_df.tail()","91c3d35c":"def create_mel_spec_features(data,column_name = 'data'):\n    df = data.copy()\n    df['mel_spec'] = None\n    for indx in tqdm(df.index):\n        mel_spec = librosa.feature.melspectrogram(df.loc[indx,column_name],sr=16000,n_fft=512,hop_length=128,n_mels=90)\n        log_mel_spec = librosa.power_to_db(mel_spec)\n        df.loc[indx,'mel_spec'] = [log_mel_spec]\n    return df","bf213c1b":"merged_df_with_mel =create_mel_spec_features(merged_df)","263a9dd4":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(merged_df_with_mel, test_size=0.3,random_state=21)","8247d613":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nencoder = LabelEncoder()","9cace36d":"X_train = np.array([rec for rec in train['mel_spec']])","7af6bc5a":"y_train = train.class_label.values\ny_train = encoder.fit_transform(y_train)\n\nclasses_encoded = encoder.classes_\nnum_classes = len(classes_encoded)\nprint(num_classes)","84f16a5d":"y_train = to_categorical(y_train,num_classes = num_classes)","62dfea60":"X_test = np.array([rec for rec in test['mel_spec']])\ny_test = test.class_label.values\ny_test = encoder.transform(y_test)\ny_test = to_categorical(y_test,num_classes = num_classes)","2a8d4fcc":"# Reshape for mel spec features\nX_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\nX_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],X_test.shape[2],1))","91add020":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D,AveragePooling2D, MaxPooling2D,Flatten,Dropout,BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","6248b6a3":"model = Sequential()\nmodel.add(Conv2D(8, 2, padding='valid',activation='relu', input_shape=X_train.shape[1:]))\nfor i in range(2):\n    model.add(MaxPooling2D((2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(8, 2, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(16, 3, activation='relu'))\nmodel.add(AveragePooling2D((2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","1800c01e":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","6f01a1b1":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)","01693808":"model.fit(X_train,y_train, batch_size=64, epochs=25, validation_data=(X_val,y_val),callbacks=[es, mc]) ","8942aacf":"from keras.models import load_model\nsaved_model = load_model('best_model.h5')","aedd608c":"# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = saved_model.evaluate(X_test, y_test, batch_size=128)\nprint(\"test loss, test acc:\", results)","af8b2892":"prediction = saved_model.predict(X_test)","07c708e4":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","7dc1ce92":"pred = [classes_encoded[np.argmax(p)] for p in prediction]\ntrue_val = [classes_encoded[np.argmax(p)] for p in y_test]","0ce985ff":"print(classification_report(true_val, pred, target_names=classes_encoded))","8797d9a8":"from my_module import plot_confusion_matrix\nplot_confusion_matrix(confusion_matrix(true_val, pred),classes_encoded,normalize=False)","e9d4fe1c":"test_dir = '..\/data\/test'\ndef load_test_data(path):    \n    tmp_list=[]\n    for (dirpath, dirnames, filenames) in os.walk(path):\n        for file in filenames:\n            if file.endswith('.wav'):\n                tmp_path=os.path.join(dirpath, file)\n                data,_ = librosa.load(tmp_path,sr=SAMPLE_RATE)\n                tmp_list.append([file,data])\n            else:\n                continue\n    return  pd.DataFrame(tmp_list,columns=['file_path','data'])","c0f2d712":"test_data = load_test_data(test_dir)","257b485e":"test_data = pad_records_length(test_data)","e2f79a4e":"test_data = center_records(test_data)","cfd91ad8":"test_data = create_mel_spec_features(test_data, column_name='centered')","2d8343ac":"X_sub = np.array([rec for rec in test_data.mel_spec])\nX_sub = np.reshape(X_sub,(X_sub.shape[0],X_sub.shape[1],X_sub.shape[2],1))","69049813":"prediction_for_sub = saved_model.predict(X_sub)","0270c613":"fname = test_data.file_path.values","9b75cb6b":"classes_encoded = 'down go left no off on right silence stop unknown up yes'.split()\nsub_prediction =[classes_encoded[np.argmax(p)] for p in prediction_for_sub]","ef7ecec7":"submission_df = pd.DataFrame(list(zip(fname,sub_prediction)),columns=['fname','label'])\nsubmission_df.to_csv('submission.csv',index=False)","98f87d11":"## Changing class labels","11389cdd":"* Silence records wasn't centered that's why there are have not in centered column and thats should be changed because in future i'll use it.","41977bae":"# Train validation test split","0c4a172d":"* Merge increased non validation records and validation records","2a85f840":"* increasing selection","0d849d1a":"![%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202021-10-11%20%D0%B2%2010.40.49.png](attachment:%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202021-10-11%20%D0%B2%2010.40.49.png)","e27fffbc":"### Working with not matched records","c4ef5806":"* Reshapping features data","94451e5f":"* Load submission data","e4ea06a9":"## Finding records that do not match their class","c6697b30":"# Data Augmentation","dbc8d179":"# Building model","63cb47f5":"## separating noisy recordings from the rest\n**noisy records** - records in folder **\"_background_noise_\"**","dd74fff3":"# Defining feature and target variables","3b214b00":"## Making silence records\ngenerating new records from records in  **\"_background_noise_\"** folder","df090e29":"# Importing libraries","3240ea4c":"* Mel Spectrograms","174ce46d":"# Create features","253cfc38":"* make pandas dataframe and save to csv file","35f65b2f":"* preprocess","be2ed51b":"## Making all records of the same length\n* Due to some records have a duration less than 1s. I should to pad them to the same length of 1s.","0c036674":"* Loading best saved model","35953754":"* Test","545d7b97":"* Train","f14c8a57":"* Making test prediction","6e9f004e":"# Preprocessing train data","a6cc1bfe":"* center records","29daf47b":"# Submition predition","c8c18452":"# Loading train data","2d651653":"# Merge silence dataframe and train dataframe","473979d9":"* Confusion matrix"}}