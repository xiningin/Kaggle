{"cell_type":{"663898bf":"code","bd63daaf":"code","7532eaed":"code","130649f2":"code","0ecd6f1d":"code","c50ae240":"code","b27261d0":"code","4f877142":"code","1bc1fbe9":"code","5fca571c":"code","6f046143":"code","6df90312":"code","253ce080":"code","9583cfec":"code","9e7ea3f0":"code","4d17ce31":"code","93d090a6":"code","e3722e1c":"code","9d427696":"code","6bef1e5c":"code","18a4ff4e":"code","34eda943":"code","a4ddc83d":"code","40c9cafb":"code","212783f5":"code","8d313fc7":"code","8208cddb":"code","e4f30f2c":"code","6a9f3573":"code","3409d55b":"markdown","169296bc":"markdown","7e1e6bf7":"markdown","96eb00cc":"markdown","c526bb60":"markdown","2ef2d645":"markdown","e1e3edea":"markdown","333c9708":"markdown","66e3b599":"markdown","1631fe39":"markdown","50cc064e":"markdown","b9b99eec":"markdown","db3fa65d":"markdown","3c9b9999":"markdown","f93d5434":"markdown","2f8b05b9":"markdown","304e009c":"markdown"},"source":{"663898bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb\nimport shap\n\nfrom numpy import interp\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc, classification_report, precision_recall_curve\nfrom sklearn.impute import SimpleImputer\nfrom termcolor import colored\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom statsmodels.stats.contingency_tables import mcnemar\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bd63daaf":"# Function to plot a histogram that shows the number of NaN values for each column.\ndef plot_hist_nan(df):\n    \n    nan_df = pd.DataFrame(df.isna().sum().tolist(), df.columns.tolist()).reset_index()\n    nan_df.columns = ['column_name', 'total_nan']\n    nan_df['nan_perc'] = 100*round(nan_df['total_nan']\/len(df),3)\n    nan_df = nan_df.sort_values('total_nan', ascending=False)\n    \n    plt.figure(figsize=(20,15))\n    step = 25\n    j = 0\n    t_plots = math.ceil(len(nan_df) \/ step)\n\n    fig, axes = plt.subplots(t_plots, 1, figsize=(20,20))\n\n    for i in range(0,len(nan_df), step):\n        sns.barplot(x=\"nan_perc\", y=\"column_name\", data=nan_df[i:i+step], ax=axes[j])    \n        axes[j].set_ylabel('Columns', fontsize = 15)\n        axes[j].set_xlabel('NaN %', fontsize = 15)\n        axes[j].set_xticks([0,10,20,30,40,50,60,70,80,90,100], minor=False)\n        j = j + 1    \n        if j == t_plots:\n            break","7532eaed":"# Function to plot a chart that shows the class distribution.\ndef plot_class_distribution(df: pd.DataFrame):\n    \n    values = df.groupby('SARS-Cov-2 exam result')['SARS-Cov-2 exam result'].count()\n    n_samples = df.shape[0]\n    \n    plt.figure(figsize=(10,6))\n    labels = ['Negative', 'Positive']\n    explode = (0, 0.2) \n    colors = ['#66b3ff','#ff9999']\n\n    plt.pie(values, colors = colors, autopct='%1.1f%%',\n        startangle=90, pctdistance=0.85, explode=explode)\n\n    plt.legend(labels,loc=1)\n\n    centre_circle = plt.Circle((0,0),0.20,fc='white')\n    fig = plt.gcf()\n    fig.gca().add_artist(centre_circle)  \n    plt.tight_layout()\n\n    fig.text(0.42, 0.5, \"{} samples\".format(n_samples), style='italic', fontsize=10)\n    plt.show()","130649f2":"# Function to plot a chart that shows ROC Curve.\ndef plot_roc_curve(results):\n        \n    plt.figure(figsize=(10,8))\n    mean_fpr = np.linspace(0, 1, 100)\n    tprs = []\n    i = 0\n    \n    colors = ['r','b','g']\n    \n    for idx,result in enumerate(results):\n    \n        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n        mean_tpr = np.mean(result.tprs, axis=0)\n        mean_tpr[-1] = 1.0\n        mean_auc = auc(mean_fpr, mean_tpr)\n        std_auc = np.std(result.aucs)\n        \n        plt.plot(mean_fpr, mean_tpr, color=colors[idx], label=result.model_name + ' (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n        \n        std_tpr = np.std(result.tprs, axis=0)\n        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n        \n        if i == 0:\n            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[idx], alpha=.2)\n        else:\n            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[idx], alpha=.2)\n        i = i + 1\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Chance', alpha=.8)\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate', size=12)\n    plt.ylabel('True Positive Rate', size=12)\n    plt.title('ROC CURVE')\n    plt.legend(loc=\"lower right\")    \n    plt.show()","0ecd6f1d":"# Function to plot the confusion matrix.\ndef plot_confusion_matrix(results):\n        \n    sns.set(font_scale = 1.6)\n    plt.figure(figsize=(12,10))\n    threshold = 0.5\n    index = 0\n        \n    for result in results:\n                            \n        cm = confusion_matrix(result.y_pred, result.y_test)\n        \n        labels = ['Negative', 'Positive']\n        ax = plt.subplot(2, 2, index+1)\n        sns.set_palette(\"PuBuGn_d\")\n        \n        if index == 0 or index == 2:\n            show_scale = False\n        else:\n            show_scale = True\n            \n        sum_0 =  cm.sum(axis=1)[0]\n        sum_1 = cm.sum(axis=1)[1]\n        \n        cm_aux = np.zeros((2,2))\n\n        cm_aux[0][0] = (cm[1][1]) #\/ sum_1\n        cm_aux[0][1] = (cm[1][0])\n        cm_aux[1][0] = (cm[0][1])\n        cm_aux[1][1] = (cm[0][0])\n        \n        sns.heatmap(cm_aux, annot=True, ax = ax, fmt=\"\", cmap=\"Blues\", cbar=False)\n        #sns.heatmap(cm_aux, annot=True, ax = ax, cmap=\"Blues\", cbar=False)\n        \n        ax.set_title(result.model_name)\n        ax.yaxis.set_ticklabels(['Positive', 'Negative'])\n        ax.xaxis.set_ticklabels(['Positive', 'Negative'])\n        \n        if index == 0 or index == 1:\n            ax.set_xlabel('');\n        else:\n            ax.set_xlabel('Predicted labels');\n            \n        if index == 1 or index == 3:\n            ax.set_ylabel(''); \n        else:\n            ax.set_ylabel('True labels')\n            \n        index = index + 1\n    \n    plt.show()","c50ae240":"# Function to create a balanced dataset.\ndef create_balanced_dataset(df: pd.DataFrame, percent):\n    # Class count\n    count_class_0, count_class_1 = df['SARS-Cov-2 exam result'].value_counts() * percent\n    count_class_0 = int(count_class_0)\n    count_class_1 = int(count_class_1)\n\n    # Divide by class\n    df_class_0 = df[df['SARS-Cov-2 exam result'] == 0]\n    df_class_1 = df[df['SARS-Cov-2 exam result'] == 1]\n    \n    df_class_1 = df_class_1.sample(count_class_1, random_state=1)\n    \n    df_class_0_under = df_class_0.sample(count_class_1, random_state=1)\n    df_balanced = pd.concat([df_class_0_under, df_class_1], axis=0)\n    \n    return df_balanced","b27261d0":"def evaluate_model(model, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.DataFrame, y_test: pd.DataFrame):\n    \"\"\"\n    Used to evaluate a given model. Just an API wrapper.    \n    Returns the fitted model along with the predictions generated for the test set\n    \"\"\"\n    model.fit(X_train, y_train)\n    y_preds = model.predict(X_test)\n    y_preds_proba = model.predict_proba(X_test)\n    return model, y_preds, y_preds_proba","4f877142":"def generate_performance_stats(y_test, y_pred):    \n    target_names = ['Negative', 'Positive'] \n    cm = confusion_matrix(y_test, y_pred)        \n    print(\"Accuracy: {}\\n\".format(metrics.accuracy_score(y_test,y_pred)))\n    print(\"Confusion Matrix: \\n{}\\n\".format(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])))\n    print(\"Classification Report: \\n{}\\n\".format(classification_report(y_test, y_pred, target_names=target_names)))","1bc1fbe9":"# Function to perform K-fold Cross Validation.\ndef permoform_cv(df: pd.DataFrame, target: pd.DataFrame, models):\n        \n    results = []\n    mean_fpr = np.linspace(0, 1, 100)\n    models_predictions = {}\n\n    for model_alias in models:\n    \n        print(\"Model: {}\\n\".format(model_alias))\n        tprs = []\n        aucs = []\n        thresholds = []\n        y_preds = []\n        y_preds_prob = []\n        y_tests = []\n        model = models[model_alias]\n\n        i = 0\n        kf = KFold(n_splits=n_folds, random_state=13, shuffle=True)\n        model_predicted = []\n        model_gt = []\n    \n        for index in kf.split(df):\n\n            print(\"Fold[{}]\\n\".format(i+1))\n\n            X_train, X_test, y_train, y_test = df.iloc[index[0]], df.iloc[index[1]], target.iloc[index[0]], target.iloc[index[1]]            \n            model_fit, y_pred, y_pred_proba = evaluate_model(model, X_train, X_test, y_train, y_test)\n            \n            y_pred = y_pred_proba[:,1] > thresh\n            y_pred = y_pred.astype(int)  \n            model_predicted = np.concatenate((np.array(model_predicted),y_pred))\n            model_gt = np.concatenate((np.array(model_gt),y_test))\n            \n            generate_performance_stats(y_test, y_pred)                    \n\n            # Compute ROC curve and area the curve\n            fpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\n            prec, rec, tre = precision_recall_curve(y_test, y_pred_proba[:,1])\n            \n            tprs.append(interp(mean_fpr, fpr, tpr))\n            tprs[-1][0] = 0.0\n            roc_auc = auc(fpr, tpr)\n            aucs.append(roc_auc)\n            thresholds.append(threshold)\n            \n            y_preds = np.append(y_preds, y_pred)\n            y_preds_prob = np.append(y_preds_prob, y_pred_proba[:,1])\n            y_tests = np.append(y_tests, y_test)\n            \n            i = i + 1\n    \n        generate_performance_stats(model_gt, model_predicted)\n\n        result = RESULT(model_alias, tprs, aucs, thresholds, y_preds, y_preds_prob, y_tests)\n        results.append(result)\n        models_predictions[model_alias] = (model_predicted,model_gt)\n        print(\"########################################################\\n\")\n    \n    return results, models_predictions","5fca571c":"class RESULT(object):\n    \n    def __init__(self, model_name, tprs, aucs, thresholds, y_pred, y_pred_prob, y_test):\n        self.model_name = model_name\n        self.tprs = tprs\n        self.aucs = aucs\n        self.thresholds = thresholds\n        self.y_pred = y_pred\n        self.y_pred_prob = y_pred_prob\n        self.y_test = y_test","6f046143":"# Importing raw dataset\ndf_all = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')","6df90312":"print(\"The dataset has {} many rows and {} columns\".format(df_all.shape[0], df_all.shape[1]))","253ce080":"# Look at the data\ndf_all.head(5)","9583cfec":"plot_hist_nan(df_all)","9e7ea3f0":"df = df_all.loc[:, df_all.isnull().mean() <= .9]","4d17ce31":"# Class distribution for the SARS-Cov-2 exam result\nplot_class_distribution(df)","93d090a6":"# Drop the target columns related to task 2\ncols_task2 = ['Patient addmited to regular ward (1=yes, 0=no)', 'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n              'Patient addmited to intensive care unit (1=yes, 0=no)']\n\ndf = df.drop(cols_task2, axis = 1)","e3722e1c":"# Let's check the data type of predictive features.\ndf.info(verbose=True)","9d427696":"# The new dataset will only have numerical features. The target feature is converted to 0 or 1.\ndf_numeric = df.copy()\ndf_numeric['SARS-Cov-2 exam result'][df_numeric['SARS-Cov-2 exam result'] == 'negative'] = 0\ndf_numeric['SARS-Cov-2 exam result'][df_numeric['SARS-Cov-2 exam result'] == 'positive'] = 1\ndf_numeric['SARS-Cov-2 exam result'] = df_numeric['SARS-Cov-2 exam result'].astype(str).astype(int)","6bef1e5c":"percent = 0.8\ndf_balanced = create_balanced_dataset(df_numeric, percent)\nprint(\"The balanced dataset has {} many rows and {} columns\".format(df_balanced.shape[0], df_balanced.shape[1]))","18a4ff4e":"df_test = df[(~df['Patient ID'].isin(df_balanced['Patient ID']))]\nprint(\"The unbalanced dataset (test) has {} many rows and {} columns\".format(df_test.shape[0], df_test.shape[1]))","34eda943":"# Predictive models\nmodels = {\n    'XGBoost': XGBClassifier(),\n    'RF': RandomForestClassifier(n_estimators=100,criterion='gini'),\n    'Logistic': LogisticRegression(),\n}","a4ddc83d":"df_balanced_num = df_balanced.select_dtypes(include=['float64', 'int64'])","40c9cafb":"cols = df_balanced_num.columns\ndf_balanced_num[cols] = df_balanced_num.filter(cols).fillna(df_balanced_num.mode().iloc[0])","212783f5":"# Getting the target column and drop 'Patient ID' column\ny_train = df_balanced_num['SARS-Cov-2 exam result']\ndf_balanced_num = df_balanced_num.drop(['SARS-Cov-2 exam result'], axis = 1)","8d313fc7":"#K-Fold parameters\nthresh = 0.5\nk_fold_seed = 13\nn_folds = 10\nresults, models_predictions = permoform_cv(df_balanced_num, y_train, models)","8208cddb":"# Performance stats for models\nfor result in results:\n    print(\"Model: {}\\n\".format(result.model_name))\n    generate_performance_stats(result.y_pred, result.y_test)\n    print(\"###########################################################\\n\")","e4f30f2c":"plot_roc_curve(results)","6a9f3573":"plot_confusion_matrix(results)","3409d55b":"### ROC curve plot","169296bc":"For task 1, the dataset is unbalanced, with 90.1% of negative cases and 9.9% of positive cases. ","7e1e6bf7":"### Class distribution for the SARS-Cov-2 exam result","96eb00cc":"### Confusion Matrix plot","c526bb60":"The charts and metric values shows that the Xgboost and Random Forest models presents a better predictive power. There are several detais to be consider to improove the results, like:\n* include non-numerical features\n* Use other inputation methods\n* Ensemble models\n* ...","2ef2d645":"## Exploratory Data Analysis <a id='eda'><\/a>","e1e3edea":"# CONTENTS\n* [Imports](#imports)\n* [Functions Definition](#functions_definition)\n* [Exploratory Data Analysis](#eda)\n* [K-Fold Cross Validation using Balanced DataSet](#kfold_cv_baldata)","333c9708":"### Get the Balanced Dataset\nThe *percent* variable defines the percentual of the minority class samples (positive) will be used to create a balanced dataset. The remaining samples will be used afterwards like the unbalanced dataset. ","66e3b599":"Most of the predictive models to be created do not handle missing values. Therefore, it will be used the simple inputation method.","1631fe39":"## Functions definition <a id='functions_definition'><\/a>","50cc064e":"Several variable are the \"object\" type and mostlikely have a categorical domain. As the first experiment, it will be used only numerical features.","b9b99eec":"## Imports <a id='imports'><\/a>","db3fa65d":"## K-Fold Cross Validation using Balanced Dataset<a id='kfold_cv_baldata'><\/a>","3c9b9999":"The histogram above shows that only the target features e \"Patient age quantile\" feature do not have NaN values. Therefore, we can observe that 94% of the features have more than 70% of the missing values. It will be maintaned the features with less than 90% of the missing values.","f93d5434":"### Get the Unbalanced Dataset - Test","2f8b05b9":"It seems there are several features with NaN values. It will be checked the amount of missing data in each column.","304e009c":"### Perform k-fold cross validation"}}