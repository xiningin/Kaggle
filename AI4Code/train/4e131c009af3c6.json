{"cell_type":{"d2279d92":"code","13321b1b":"code","6d1b9b66":"code","16836d09":"code","84b4686d":"code","ddbb3c95":"code","3f82600e":"code","a53d1756":"code","c59408e1":"code","a1494f96":"code","41529439":"code","7827430f":"code","69899d5d":"code","7f6126d9":"code","d7f68797":"code","2c33c238":"code","629087ba":"code","1ea247c0":"code","b75c1c38":"code","2370df3d":"code","1054be9c":"code","4983c20c":"code","ba4d5f5b":"code","5583e931":"code","9969172e":"code","6f448373":"code","1945d62e":"code","2361b2d5":"code","4f99a94b":"code","0522e3ef":"code","c552567e":"markdown","dcecb940":"markdown","e92376ec":"markdown","8ece809b":"markdown","9fd48c56":"markdown","0f149b10":"markdown","f520f131":"markdown","553f5d7b":"markdown"},"source":{"d2279d92":"import datetime as dt\nimport os\nimport random\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as torchdata\nimport seaborn as sns\n\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom catalyst.core import Callback, CallbackOrder, IRunner\nfrom catalyst.dl import SupervisedRunner\nfrom sklearn.metrics import roc_auc_score, average_precision_score, f1_score, recall_score, precision_score, confusion_matrix\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm.notebook import tqdm\n\n\nwarnings.simplefilter(\"ignore\")\n\npd.set_option(\"max_columns\", 100)","13321b1b":"tracking = pd.read_csv(\"..\/input\/nfl-impact-tracking-animation\/train_player_tracking_annotated.csv\")\ntracking.head()","6d1b9b66":"tracking[\"event\"].unique()","16836d09":"tracking[\"event\"] = tracking[\"event\"].fillna(\"\")\nevents_to_id = {\n    \"\": 0,\n    \"ball_snap\": 1,\n    \"handoff\": 2,\n    \"tackle\": 3,\n    \"first_contact\": 4,\n    \"out_of_bounds\": 5,\n    \"play_action\": 6,\n    \"pass_forward\": 7,\n    \"pass_arrived\": 8,\n    \"pass_outcome_caught\": 9,\n    \"run\": 10,\n    \"touchdown\": 11,\n    \"penalty_flag\": 12\n}","84b4686d":"tracking[\"event_id\"] = tracking[\"event\"].map(events_to_id)\ntracking","ddbb3c95":"def prepare_relative_distances(df: pd.DataFrame):\n    distances = []\n    orientation_difference = []\n    x = df[\"x\"].values\n    y = df[\"y\"].values\n    o = df[\"o\"].values\n    for i in range(len(df)):\n        other_row_indices = np.argwhere(np.arange(len(df)) != i).reshape(-1)\n        x_others = x[other_row_indices]\n        y_others = y[other_row_indices]\n        o_others = o[other_row_indices]\n        distance_between_players = np.sqrt((x_others - x[i]) ** 2 + (y_others - y[i]) ** 2)\n        distances.append(distance_between_players)\n        \n        abs_orientation_diff = np.abs(o_others - o[i])\n        orientation_difference.append(abs_orientation_diff)\n    distances_matrix = np.stack(distances)\n    orientation_diff_matrix = np.stack(orientation_difference)\n    relative_distance_df = pd.concat([\n        df[[\"index\"]].reset_index(drop=True),\n        pd.DataFrame(distances_matrix, columns=[f\"dist{i}\" for i in range(distances_matrix.shape[1])]),\n        pd.DataFrame(orientation_diff_matrix, columns=[f\"od{i}\" for i in range(orientation_diff_matrix.shape[1])])\n    ], axis=1)\n    return relative_distance_df","3f82600e":"relative_distances = []\nfor (game_key, play_id, time), df in tqdm(tracking.groupby([\"gameKey\", \"playID\", \"time\"])):\n    relative_distances.append(prepare_relative_distances(df))\n    \nrelative_distances_df = pd.concat(relative_distances, axis=0).reset_index(drop=True)","a53d1756":"relative_distances_df.head()","c59408e1":"tracking = tracking.merge(relative_distances_df, on=\"index\", how=\"left\")","a1494f96":"def prepare_relative_speed_and_acceleration(df: pd.DataFrame):\n    distance_columns = [f\"dist{i}\" for i in range(21)]\n    od_columns = [f\"od{i}\" for i in range(21)]\n    diff_df = df[distance_columns].diff().fillna(0).reset_index(drop=True)\n    diff_df.columns = [f\"speed{i}\" for i in range(21)]\n    \n    acceleration_df = diff_df.diff().fillna(0).reset_index(drop=True)\n    acceleration_df.columns = [f\"acc{i}\" for i in range(21)]\n    \n    od_diff_df = df[od_columns].diff().fillna(0).reset_index(drop=True)\n    od_diff_df.columns = [f\"od_diff{i}\" for i in range(21)]\n    relative_speed_and_acceleration = pd.concat([\n        df[[\"index\"]].reset_index(drop=True),\n        diff_df,\n        acceleration_df,\n        od_diff_df\n    ], axis=1)\n    return relative_speed_and_acceleration","41529439":"relative_speeds = []\nfor (game_key, play_id, player), df in tqdm(tracking.groupby([\"gameKey\", \"playID\", \"player\"])):\n    relative_speeds.append(prepare_relative_speed_and_acceleration(df))\n    \nrelative_speed_df = pd.concat(relative_speeds, axis=0).reset_index(drop=True)","7827430f":"tracking = tracking.merge(relative_speed_df, on=\"index\", how=\"left\")","69899d5d":"distance_columns = [f\"dist{i}\" for i in range(21)]\nspeed_columns = [f\"speed{i}\" for i in range(21)]\nacceleration_columns = [f\"acc{i}\" for i in range(21)]\nod_columns = [f\"od{i}\" for i in range(21)]\nod_diff_columns = [f\"od_diff{i}\" for i in range(21)]\ntracking[distance_columns]","7f6126d9":"tracking[\"relative_distance\"] = tracking[distance_columns].min(axis=1)\nmin_value_indices = tracking[distance_columns].idxmin(axis=1).map(\n    lambda x: distance_columns.index(x)).reset_index()\n\nspeed_values = tracking[speed_columns].values\nacceleration_values = tracking[acceleration_columns].values\nod_values = tracking[od_columns].values\nod_diff_values = tracking[od_diff_columns].values\n\ntracking[\"relative_speed\"] = min_value_indices.apply(lambda row: speed_values[row[\"index\"], row[0]], axis=1)\ntracking[\"relative_acceleration\"] = min_value_indices.apply(lambda row: acceleration_values[row[\"index\"], row[0]], axis=1)\ntracking[\"relative_orientation_difference\"] = min_value_indices.apply(lambda row: od_values[row[\"index\"], row[0]], axis=1)\ntracking[\"relative_orientation_difference_diff\"] = min_value_indices.apply(lambda row: od_diff_values[row[\"index\"], row[0]], axis=1)","d7f68797":"tracking = tracking.merge(min_value_indices, left_index=True, right_on=\"index\")","2c33c238":"tracking","629087ba":"X = tracking[[\n    \"index\", \"gameKey\", \"playID\", \"player\",\n    \"x\", \"y\", \"s\", \"a\", \"dis\", \"o\", \"dir\",\n    \"relative_distance\", \"relative_speed\", \"relative_acceleration\", \n    \"relative_orientation_difference\", \"relative_orientation_difference_diff\",\n    \"event_id\",\n    \"impact\"\n]]\nX.head()","1ea247c0":"ss = StandardScaler()\ncolumns = [\"x\", \"y\", \"s\", \"a\", \"dis\", \"o\", \"dir\", \"relative_distance\", \"relative_speed\", \"relative_acceleration\",\n           \"relative_orientation_difference\", \"relative_orientation_difference_diff\"]\ncategoricals = [\"event_id\"]\ntransformed = ss.fit_transform(X[columns])\nX[columns] = transformed","b75c1c38":"X.head()","2370df3d":"class LSTMDataset(torchdata.Dataset):\n    def __init__(self, X: pd.DataFrame, columns, maxlen=103):\n        self.X_list = list(X.groupby([\"gameKey\", \"playID\", \"player\"]))\n        self.maxlen = maxlen\n        self.columns = columns\n        \n    def __len__(self):\n        return len(self.X_list)\n    \n    def __getitem__(self, idx: int):\n        (game_key, play_id, player), df = self.X_list[idx]\n        impact = df[\"impact\"].values.reshape(-1).astype(np.float32)\n        impact_long = np.zeros(self.maxlen, dtype=np.float32)\n        impact_long[:len(impact)] = impact\n\n        x = df[self.columns].values.astype(np.float32)\n        x_long = np.zeros((self.maxlen, x.shape[1]), dtype=np.float32)\n        x_long[:len(x), :] = x\n        \n        mask = np.zeros(self.maxlen, dtype=bool)\n        mask[:len(impact)] = True\n        \n        index = df[\"index\"].values.reshape(-1)\n        indices = np.zeros(self.maxlen, dtype=int)\n        indices[:len(x)] = index\n        return {\n            \"game_key\": game_key,\n            \"play_id\": play_id,\n            \"player\": player,\n            \"index\": indices,\n            \"mask\": mask,\n            \"targets\": impact_long,\n            \"x\": x_long\n        }","1054be9c":"class BiLSTMModel(nn.Module):\n    def __init__(self, input_size: int, hidden_size: int, num_layers: int, n_categories: int, n_emb: int):\n        super().__init__()\n        self.embedding = nn.Embedding(n_categories, n_emb)\n        self.lstm = nn.LSTM(input_size=input_size + n_emb,\n                            hidden_size=hidden_size,\n                            num_layers=num_layers,\n                            batch_first=True,\n                            bidirectional=True)\n        self.classifier = nn.Sequential(\n            nn.Linear(2 * hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, 1))\n        \n    def forward(self, x):\n        batch_size = x.size(0)\n        cat_cols = x[:, :, -1].long()\n        emb_out = self.embedding(cat_cols)\n        x = torch.cat([x[:, :, :-1], emb_out], dim=2)\n        seq, _ = self.lstm(x)\n        return self.classifier(seq).sigmoid().view(batch_size, -1)","4983c20c":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","ba4d5f5b":"class F1Callback(Callback):\n    def __init__(self,\n                 input_key: str=\"targets\",\n                 output_key: str=\"logits\",\n                 threshold: float = 0.5,\n                 prefix: str = \"f1\"):\n        super().__init__(CallbackOrder.Metric)\n        \n        self.input_key = input_key\n        self.output_key = output_key\n        self.threshold = threshold\n        self.prefix = prefix\n        \n    def on_loader_start(self, state: IRunner):\n        self.prediction = []\n        self.target = []\n        \n    def on_batch_end(self, state: IRunner):\n        targ = state.input[self.input_key].detach().cpu().numpy()\n        out = state.output[self.output_key].detach().cpu().numpy()\n        \n        targ = targ.reshape(-1)\n        out = out.reshape(-1)\n        \n        self.prediction.append(out)\n        self.target.append(targ)\n        \n        if targ.sum() == 0:\n            score = 1.0\n        else:\n            score = f1_score(y_true=targ, y_pred=(out > self.threshold).astype(int))\n        state.batch_metrics[self.prefix] = score\n        \n    def on_loader_end(self, state: IRunner):\n        y_pred = np.concatenate(self.prediction, axis=0)\n        y_true = np.concatenate(self.target, axis=0)\n        score = f1_score(y_true=y_true, y_pred=(y_pred > self.threshold).astype(int))\n        if state.is_valid_loader:\n            state.epoch_metrics[state.valid_loader + \"_epoch_\" + self.prefix] = score\n        else:\n            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score\n            \n            \nclass AUCCallback(Callback):\n    def __init__(self,\n                 input_key: str=\"targets\",\n                 output_key: str=\"logits\",\n                 prefix: str = \"auc\"):\n        super().__init__(CallbackOrder.Metric)\n        \n        self.input_key = input_key\n        self.output_key = output_key\n        self.prefix = prefix\n        \n    def on_loader_start(self, state: IRunner):\n        self.prediction = []\n        self.target = []\n        \n    def on_batch_end(self, state: IRunner):\n        targ = state.input[self.input_key].detach().cpu().numpy()\n        out = state.output[self.output_key].detach().cpu().numpy()\n        \n        targ = targ.reshape(-1)\n        out = out.reshape(-1)\n        \n        self.prediction.append(out)\n        self.target.append(targ)\n        \n        if targ.sum() == 0:\n            score = 1.0\n        else:\n            score = roc_auc_score(y_true=targ, y_score=out)\n        state.batch_metrics[self.prefix] = score\n        \n    def on_loader_end(self, state: IRunner):\n        y_pred = np.concatenate(self.prediction, axis=0)\n        y_true = np.concatenate(self.target, axis=0)\n        score = roc_auc_score(y_true=y_true, y_score=y_pred)\n        if state.is_valid_loader:\n            state.epoch_metrics[state.valid_loader + \"_epoch_\" + self.prefix] = score\n        else:\n            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score","5583e931":"device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")","9969172e":"X[\"group\"] = X[\"gameKey\"].map(str) + \"_\" + X[\"playID\"].map(str)\n\noof = pd.DataFrame()\nscores = 0.0\n\nset_seed(42)\n\nnew_columns = columns + [\"event_id\"]\n\ngkf = GroupKFold(n_splits=5)\nfor fold, (trn_idx, val_idx) in enumerate(gkf.split(X, groups=X[\"group\"])):\n    print(\"*\" * 100)\n    print(f\"Fold: {fold}\")\n    \n    X_trn = X.loc[trn_idx, :].reset_index(drop=True)\n    X_val = X.loc[val_idx, :].reset_index(drop=True)\n    \n    trn_dataset = LSTMDataset(X_trn, columns=new_columns)\n    val_dataset = LSTMDataset(X_val, columns=new_columns)\n    \n    trn_loader = torchdata.DataLoader(trn_dataset, batch_size=128, shuffle=True)\n    val_loader = torchdata.DataLoader(val_dataset, batch_size=256, shuffle=False)\n    \n    loaders = {\n        \"train\": trn_loader,\n        \"valid\": val_loader\n    }\n    \n    model = BiLSTMModel(input_size=len(columns), hidden_size=64, num_layers=1, n_categories=13, n_emb=8)\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n    callbacks = [\n        AUCCallback(input_key=\"targets\",\n                    prefix=\"auc\"),\n        F1Callback(input_key=\"targets\",\n                   threshold=0.1,\n                   prefix=\"f1_at_01\"),\n        F1Callback(input_key=\"targets\",\n                   threshold=0.3,\n                   prefix=\"f1_at_03\")\n    ]\n    \n    runner = SupervisedRunner(device=device,\n                              input_key=\"x\",\n                              input_target_key=\"targets\")\n    runner.train(\n        model=model,\n        criterion=criterion,\n        loaders=loaders,\n        optimizer=optimizer,\n        scheduler=scheduler,\n        num_epochs=50,\n        verbose=False,\n        logdir=f\"fold{fold}\",\n        callbacks=callbacks,\n        main_metric=\"epoch_auc\",\n        minimize_metric=False)\n    \n    # oof\n    batch_predict = []\n    batch_targets = []\n    batch_indices = []\n    for batch in val_loader:\n        mask = batch[\"mask\"]\n        index = batch[\"index\"][mask].numpy()\n        batch_indices.append(index)\n        \n        targets = batch[\"targets\"]\n        batch_targets.append(targets[mask].numpy())\n        \n        x = batch[\"x\"].to(device)\n        with torch.no_grad():\n            out = model(x).detach().cpu()\n            \n        batch_predict.append(out[mask].numpy())\n        \n    batch_predictions_array = np.concatenate(batch_predict)\n    batch_targets_array = np.concatenate(batch_targets)\n    batch_indices_array = np.concatenate(batch_indices)\n    \n    oof = oof.append(pd.DataFrame({\n        \"pred\": batch_predictions_array,\n        \"targets\": batch_targets_array,\n        \"index\": batch_indices_array}))","6f448373":"score = roc_auc_score(y_score=oof[\"pred\"], y_true=oof[\"targets\"])\nprint(f\"AUC: {score:.5f}\")\n\nscore = f1_score(y_pred=(oof[\"pred\"] > 0.1), y_true=oof[\"targets\"])\nprint(f\"F1@0.1: {score:.5f}\")\n\nscore = f1_score(y_pred=(oof[\"pred\"] > 0.3), y_true=oof[\"targets\"])\nprint(f\"F1@0.3: {score:.5f}\")","1945d62e":"oof = oof.sort_values(by=\"index\")\nX_ = pd.concat([\n    X.merge(oof, on=\"index\").reset_index(drop=True),\n    tracking[[\"time\"]].reset_index(drop=True)\n], axis=1)\n\ntime_level_prediction = X_.groupby([\"gameKey\", \"playID\", \"time\"]).agg({\n    \"targets\": \"max\",\n    \"pred\": \"max\"\n})","2361b2d5":"time_level_prediction","4f99a94b":"score = roc_auc_score(y_score=time_level_prediction[\"pred\"], y_true=time_level_prediction[\"targets\"])\nprint(f\"AUC: {score:.5f}\")\n\nscore = f1_score(y_pred=(time_level_prediction[\"pred\"] > 0.1), y_true=time_level_prediction[\"targets\"])\nprint(f\"F1@0.1: {score:.5f}\")\n\nscore = f1_score(y_pred=(time_level_prediction[\"pred\"] > 0.08), y_true=time_level_prediction[\"targets\"])\nprint(f\"F1@0.08: {score:.5f}\")","0522e3ef":"labels = [\"0\", \"1\"]\ncm = confusion_matrix(y_pred=(time_level_prediction[\"pred\"] > 0.06),\n                      y_true=time_level_prediction[\"targets\"],\n                      normalize=\"all\")\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(cm, xticklabels=labels, yticklabels=labels, cmap='Blues', annot=True, lw=0.5)\nax.set_xlabel('Predicted Label')\nax.set_ylabel('True Label')\nax.set_aspect('equal')","c552567e":"## Data Loading","dcecb940":"## Evaluation","e92376ec":"## Model","8ece809b":"## Feature Engineering","9fd48c56":"## Datasets","0f149b10":"## Training Utilities","f520f131":"## 5fold training","553f5d7b":"## Libraries"}}