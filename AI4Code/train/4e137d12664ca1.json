{"cell_type":{"c5d43fd7":"code","b913b5ce":"code","4aa4fddf":"code","cf376791":"code","b2fdbc29":"code","1ce0395a":"code","4ad479ae":"code","2c645e69":"code","c4bfe8b5":"code","318141cb":"code","b1be2a9e":"code","bfb72b33":"code","79ce5111":"code","7adaf57d":"code","5345202d":"code","a2578ee7":"code","e3506ee8":"code","8695ad01":"code","dfed41a9":"code","2829ab49":"code","e1023ce2":"code","18c49961":"code","af6b0a69":"code","f5b255d8":"code","f6da4642":"code","1f7c89fa":"code","244b6f10":"code","81978e56":"code","26ea8f8b":"code","10fc4a6d":"code","e284c8d4":"code","a34230dd":"code","900a1101":"code","664ce216":"code","14e6c026":"code","4a1ae427":"code","c6eb81fb":"code","33083426":"code","45b34f34":"code","340e15eb":"code","e21e1e6e":"code","9c6404de":"code","92e5a7c4":"code","54d15185":"code","e0cd99ec":"code","0ab422e1":"code","3170b911":"code","1b23cb20":"code","3644d285":"code","057e484b":"code","c366b28c":"code","28f4f89b":"code","fb0b18ee":"markdown","9679f585":"markdown","6e5cb9ce":"markdown","ac976da5":"markdown","07f20db2":"markdown","75e3e838":"markdown","19854428":"markdown","242b95ec":"markdown","23d5692b":"markdown","7df1d3ee":"markdown","0add9317":"markdown","2c96b316":"markdown","edd7b9af":"markdown","b1099d28":"markdown","acd59e8a":"markdown","e55bbd87":"markdown","93c547d4":"markdown","005a77dd":"markdown","ce32a971":"markdown","77362683":"markdown","4d82ed0a":"markdown","3a6ef677":"markdown","bbf85461":"markdown","87c13265":"markdown","10aaf924":"markdown","b50988ad":"markdown","c415479e":"markdown","c2a3781b":"markdown","957f1c74":"markdown","03624661":"markdown","904abb8e":"markdown","22c13e08":"markdown","795d2471":"markdown","a25b39d7":"markdown","609ed885":"markdown","1d0b6a82":"markdown","28339dde":"markdown","d9aeb500":"markdown","a10492e6":"markdown","7d60f5da":"markdown","74171905":"markdown","dc8e6342":"markdown","cdb45d9b":"markdown","2ff12e7b":"markdown","883749af":"markdown","82abfd00":"markdown","bfdfb0ee":"markdown","a145f933":"markdown","1f658ea8":"markdown","4c3e30bf":"markdown","386733fd":"markdown"},"source":{"c5d43fd7":"# an\u00e1lise e prepara\u00e7\u00e3o de dados\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualiza\u00e7\u00e3o\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","b913b5ce":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')","4aa4fddf":"combine = [train_df, test_df]","cf376791":"train_df.columns.values","b2fdbc29":"train_df.head()","1ce0395a":"train_df.tail()","4ad479ae":"train_df.describe()","2c645e69":"train_df.describe(include=['O'])","c4bfe8b5":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","318141cb":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","b1be2a9e":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","bfb72b33":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","79ce5111":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","7adaf57d":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","5345202d":"# grid = sns.FacetGrid(train_df, col='Embarked')\ngrid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","a2578ee7":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","e3506ee8":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\nprint(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","8695ad01":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","dfed41a9":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","2829ab49":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()","e1023ce2":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","18c49961":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","af6b0a69":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')\ngrid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","f5b255d8":"guess_ages = np.zeros((2,3))\nguess_ages","f6da4642":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","1f7c89fa":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","244b6f10":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","81978e56":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","26ea8f8b":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","10fc4a6d":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","e284c8d4":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","a34230dd":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","900a1101":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","664ce216":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","14e6c026":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","4a1ae427":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","c6eb81fb":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","33083426":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","45b34f34":"test_df.head(10)","340e15eb":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","e21e1e6e":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","9c6404de":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","92e5a7c4":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","54d15185":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","e0cd99ec":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","0ab422e1":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","3170b911":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","1b23cb20":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","3644d285":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","057e484b":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred_random = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","c366b28c":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","28f4f89b":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred_random\n    })\nsubmission.to_csv('titanic.csv', index=False)","fb0b18ee":"No aprendizado de m\u00e1quina, os classificadores Naive Bayes s\u00e3o uma fam\u00edlia de classificadores probabil\u00edsticos simples, baseados na aplica\u00e7\u00e3o do teorema de Bayes com fortes (ing\u00eanuas) suposi\u00e7\u00f5es de independ\u00eancia entre os recursos. Os classificadores Naive Bayes s\u00e3o altamente escal\u00e1veis, exigindo v\u00e1rios par\u00e2metros lineares no n\u00famero de vari\u00e1veis (caracter\u00edsticas) em um problema de aprendizagem. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Naive_Bayes_classifier).\n\nA precis\u00e3o do modelo \u00e9 o menor entre os modelos avaliados at\u00e9 o momento.","9679f585":"### Criando novos conjuntos de dados, a partir dos dados pr\u00e9 existentes\n\nQueremos analisar se o recurso Name pode ser utilizado para extrair os titulos e testar a correla\u00e7\u00e3o entre t\u00edtulos e sobreviv\u00eancia, antes de remover os recursos Name e PassengerId.\n\nNo c\u00f3digo a seguir, extra\u00edmos o conjunto Title usando express\u00f5es regulares. O padr\u00e3o RegEx `(\\w+\\.)` Corresponde \u00e0 primeira palavra que termina com um caractere de ponto no recurso Name. O atributo `expand = False` retorna um DataFrame.\n\n**Observa\u00e7\u00f5es.**\n\nQuando plotamos Title, Age e Survived, obtemos as seguintes observa\u00e7\u00f5es:\n\n- A maioria dos t\u00edtulos agrupa faixas et\u00e1rias com precis\u00e3o. Por exemplo: o t\u00edtulo de Master tem uma m\u00e9dia de idade de 5 anos.\n- A sobreviv\u00eancia entre as faixas et\u00e1rias em rela\u00e7\u00e3o aos t\u00edtulos extra\u00eddos varia um pouco.\n- Certos t\u00edtulos sobreviveram principalmente (Mme, Lady, Sir) ou n\u00e3o (Don, Rev, Jonkheer).\n\n**Decis\u00e3o.**\n\n- Decidimos manter o novo recurso T\u00edtulo para o treinamento do modelo.","6e5cb9ce":"### Avalia\u00e7\u00e3o dos modelos\n\nAgora podemos classificar nossa avalia\u00e7\u00e3o de todos os modelos para escolher o melhor para o nosso problema.","ac976da5":"### Concluindo e convertento conjuntos num\u00e9ricos\n\nAgora podemos completar o conjunto Fare para um \u00fanico valor ausente no conjunto de dados de teste usando o modo para obter o valor que ocorre com mais freq\u00fc\u00eancia para esse recurso. Fazemos isso em uma \u00fanica linha de c\u00f3digo.\n\nObserve que n\u00e3o estamos criando um novo recurso intermedi\u00e1rio ou fazendo qualquer an\u00e1lise adicional para correla\u00e7\u00e3o para adivinhar o recurso ausente, pois estamos substituindo apenas um \u00fanico valor. O objetivo \u00e9 facilitar a cria\u00e7\u00e3o do modelo, para que ele possa trabalhar apenas baseado em valores n\u00e3o-nulos.\n\nTamb\u00e9m podemos arredondar a tarifa para duas casas decimais, pois ele representa valores monet\u00e1rios.","07f20db2":"Podemos usar a regress\u00e3o log\u00edstica para validar nossas suposi\u00e7\u00f5es e decis\u00f5es. Isso pode ser feito calculando o coeficiente de correla\u00e7\u00e3o de cada conjunto de dados.\n\nCoeficientes positivos aumentam as chances logar\u00edtmicas da resposta, e coeficientes negativos diminuem as chances logar\u00edtmicas da resposta.\n\n- O sexo \u00e9 o conjunto com maior coeficiente. Ou seja, \u00e0 medida que o valor do sexo aumenta (masculino: 0 para feminino: 1), a probabilidade de aumenta.\n- Inversamente, \u00e0 medida que a Pclass aumenta, a probabilidade de sobreviv\u00eancia diminui.\n- Dessa forma, o conjunto AgeClass \u00e9 um bom recurso artificial para modelar, pois tem a segunda maior correla\u00e7\u00e3o negativa com Survived.\n- O t\u00edtulo \u00e9 a segunda maior correla\u00e7\u00e3o positiva.","75e3e838":"Vamos come\u00e7ar preparando uma matriz vazia para conter valores de idade calculados com base nas combina\u00e7\u00f5es Pclass x G\u00eanero.","19854428":"**Qual a distribui\u00e7\u00e3o dos valores categ\u00f3ricos entre as amostras?**\n\n- Names \u00e9 um coluna que contem apenas valores sem repeti\u00e7\u00e3o (count=unique=891)\n- Sex \u00e9 uma coluna com duas possibilidades de valores com 65% do tipo male (top=male, freq=577\/count=891).\n- Cabin \u00e9 uma coluna com diversos valores duplicados entre as amostras. Muitos passageiros compartilhavam cabines.\n- Embarked \u00e9 uma coluna com tr\u00eas possibilidades de valores. A classe S \u00e9 a mais comum entre as amostras (top=S).\n- Ticket \u00e9 uma coluna com alta taxa de valores duplicados (22%) (unique=681).","242b95ec":"Vamos substituir o conjunto Age por valores ordinais com base nesses conjuntos.","23d5692b":"**Qual \u00e9 a distribui\u00e7\u00e3o dos valores num\u00e9ricos entre as amostras?**\n\nIsso nos ajuda a determinar, entre outros insights iniciais, qu\u00e3o representativo \u00e9 o conjunto de dados de treinamento do dom\u00ednio real do problema.\n\n- A amostra total \u00e9 de 891 ou seja 40% do n\u00famero total de passageiros dentro do Titanic (2,224).\n- Survived \u00e9 uma coluna categ\u00f3rica que recebe 1 para sobrevivente e 0 para n\u00e3o sobrevivente.\n- Cerca de 38% dos passageiros da amostra sobreviveram, comparados a 32% do valor real.\n- A maioria dos passageiros (> 75%) n\u00e3o viajaram com pais ou filhos.\n- Aproximadamente 30% dos passageiros tinham irm\u00e3os ou conjugues a bordo.\n- As tarifas variaram siguinificativamente com alguns passageiros (<1%), pagando at\u00e9 $512.\n- Haviam poucos passageiros idosos (<1%) dentre 65-80 anos.","7df1d3ee":"## Visualiza\u00e7\u00e3o dos dados\n\nAgora podemos continuar confirmando algumas de nossas suposi\u00e7\u00f5es usando visualiza\u00e7\u00f5es para analisar os dados.\n\n### Correlacionando conjuntos num\u00e9ricos\n\nVamos come\u00e7ar entendendo as correla\u00e7\u00f5es entre os conjuntos num\u00e9ricos e nossa taxa de sobreviv\u00eancia.\n\nUm gr\u00e1fico de histograma \u00e9 \u00fatil para analisar vari\u00e1veis num\u00e9ricas cont\u00ednuas, como Idade, em que faixas ou faixas ajudar\u00e3o a identificar padr\u00f5es \u00fateis. O histograma pode indicar a distribui\u00e7\u00e3o de amostras usando compartimentos definidos automaticamente ou faixas igualmente variadas. Isso nos ajuda a responder perguntas relacionadas a faixas espec\u00edficas (os beb\u00eas tiveram melhor taxa de sobreviv\u00eancia?)\n\nObserve que o eixo x nas visualiza\u00e7\u00f5es do historograma representa a contagem de amostras ou passageiros.\n\n**Observa\u00e7\u00f5es.**\n\n- Beb\u00eas (Age <= 4) tiveram alta taxa de sobreviv\u00eancia.\n- Passageiros mais velhos (Age = 80) sobreviveram.\n- Grande n\u00famero de jovens de 15 a 25 anos n\u00e3o sobreviveu.\n- A maioria dos passageiros tem entre 15 e 35 anos.\n\n**Decis\u00f5es.**\n\nEssa an\u00e1lise simples confirma nossas suposi\u00e7\u00f5es como decis\u00f5es para os est\u00e1gios subsequentes do fluxo de trabalho.\n\n- Devemos considerar o recurso Age em nosso modelo de treinamento.\n- Completar o conjunto Age para valores nulos.\n- Dever\u00edamos agrupar faixas et\u00e1rias.","0add9317":"## Refer\u00eancias\n\nEste notebook foi criado com base no excelente trabalho realizado para solucionar a competi\u00e7\u00e3o do Titanic.\n\n- [Exploring Survival on the Titanic](https:\/\/www.kaggle.com\/mrisdal\/exploring-survival-on-the-titanic)\n- [Titanic Data Science Solutions](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions)\n- [A journey through Titanic](https:\/\/www.kaggle.com\/omarelgabry\/titanic\/a-journey-through-titanic)\n- [Getting Started with Pandas: Kaggle's Titanic Competition](https:\/\/www.kaggle.com\/c\/titanic\/details\/getting-started-with-random-forests)\n- [Titanic Best Working Classifier](https:\/\/www.kaggle.com\/sinakhorami\/titanic\/titanic-best-working-classifier)","2c96b316":"Esse modelo usa uma \u00e1rvore de decis\u00e3o como modelo preditivo, que mapeia recursos (galhos de \u00e1rvores) para conclus\u00f5es sobre o valor alvo (folhas de \u00e1rvores). Os modelos de \u00e1rvore em que a vari\u00e1vel de destino pode receber um conjunto finito de valores s\u00e3o chamados de \u00e1rvores de classifica\u00e7\u00e3o; nessas estruturas em \u00e1rvore, as folhas representam r\u00f3tulos de classe e os ramos representam conjun\u00e7\u00f5es de recursos que levam a esses r\u00f3tulos de classe. As \u00e1rvores de decis\u00e3o nas quais a vari\u00e1vel de destino pode assumir valores cont\u00ednuos (geralmente n\u00fameros reais) s\u00e3o chamadas de \u00e1rvores de regress\u00e3o. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Decision_tree_learning).\n\nO \u00edndice de precis\u00e3o do modelo \u00e9 o mais alto entre os modelos avaliados at\u00e9 o momento.","edd7b9af":"**Quais recursos s\u00e3o tipos de dados mistos?**\n\nDados que misturam valores num\u00e9ricos e alfanum\u00e9ricos dentro do mesmo campo.\n\n- O campo Ticket \u00e9 uma mistura de tipos de dados num\u00e9ricos e alfanum\u00e9ricos.\n- O campo Cabin \u00e9 do tipo alfanum\u00e9rico.\n\n**Quais recursos podem conter erros ou erros de digita\u00e7\u00e3o?**\n\nIsso \u00e9 mais dif\u00edcil de revisar para um grande conjunto de dados, no entanto, revisar algumas amostras de um conjunto de dados menor pode nos dizer diretamente, quais recursos podem exigir corre\u00e7\u00e3o.\n\n- O campo Name pode conter erros ou erros de digita\u00e7\u00e3o, pois existem v\u00e1rias maneiras de descrever um nome, incluindo t\u00edtulos, colchetes e aspas usadas para nomes alternativos ou abreviados.","b1099d28":"\n\n## Defini\u00e7\u00f5es do problema\n\nSites de competi\u00e7\u00e3o como o Kaggle definem problemas a serem resolvidos ou perguntas a serem feitas, fornecendo os conjuntos de dados para treinar seu modelo de ci\u00eancia de dados e testar os resultados do modelo em um conjunto de dados de teste. A defini\u00e7\u00e3o do problema para a competi\u00e7\u00e3o Titanic Survival \u00e9 [descrita aqui em Kaggle](https:\/\/www.kaggle.com\/c\/titanic).\n\nTamb\u00e9m podemos desenvolver um entendimento inicial sobre o dom\u00ednio do nosso problema. Isso est\u00e1 descrito na [p\u00e1gina de descri\u00e7\u00e3o da competi\u00e7\u00e3o Kaggle](https:\/\/www.kaggle.com\/c\/titanic). Aqui est\u00e3o os destaques a serem observados.\n\n- Em 15 de abril de 1912, durante sua viagem inaugural, o Titanic afundou ap\u00f3s colidir com um iceberg, matando 1502 de 2224 passageiros e tripulantes. Taxa de sobreviv\u00eancia de 32%.\n- Uma das raz\u00f5es pelas quais o naufr\u00e1gio levou a tal perda de vidas foi que n\u00e3o havia botes salva-vidas suficientes para os passageiros e a tripula\u00e7\u00e3o.\n- Embora houvesse algum elemento de sorte envolvido na sobreviv\u00eancia do naufr\u00e1gio, alguns grupos de pessoas eram mais propensos a sobreviver do que outros, como mulheres, crian\u00e7as e a classe alta.","acd59e8a":"Agora podemos remover o conjunto AgeBand","e55bbd87":"Vamos combinar os datasets de treino e teste em um array para facilitar na hora de manipular os dados.","93c547d4":"Podemos substituir muitos t\u00edtulos por um nome mais comum ou classific\u00e1-los como `Rare`.","005a77dd":"# Aplicando Data Science no caso Titanic","ce32a971":"A regress\u00e3o log\u00edstica \u00e9 um modelo \u00fatil para ser executado no in\u00edcio do fluxo de trabalho. A regress\u00e3o log\u00edstica \u00e9 uma t\u00e9cnica estat\u00edstica que tem como objetivo produzir, a partir de um conjunto de observa\u00e7\u00f5es, um modelo que permita a predi\u00e7\u00e3o de valores tomados por uma vari\u00e1vel categ\u00f3rica, frequentemente bin\u00e1ria, a partir de uma s\u00e9rie de vari\u00e1veis explicativas cont\u00ednuas e\/ou bin\u00e1rias. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Logistic_regression).\n\nDevemos observar a precis\u00e3o para definir o modelo que melhor se relaciona a nossa taxa de sobreviv\u00eancia","77362683":"Para simplificar o problema, criaremos um conjunto FareBand para agrupar os valores de tarifas","4d82ed0a":"O perceptron \u00e9 um algoritmo para aprendizado supervisionado de classificadores bin\u00e1rios (fun\u00e7\u00f5es que podem decidir se uma entrada, representada por um vetor de n\u00fameros, pertence a alguma classe espec\u00edfica ou n\u00e3o). \u00c9 um tipo de classificador linear, isto \u00e9, um algoritmo de classifica\u00e7\u00e3o que faz suas previs\u00f5es com base em uma fun\u00e7\u00e3o preditora linear que combina um conjunto de pesos com o vetor de caracter\u00edstica. O algoritmo permite o aprendizado online, na medida em que processa elementos no conjunto de treinamento, um de cada vez. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Perceptron).","3a6ef677":"## Data Science\n\n### O que \u00e9 Data Science?\n\nCi\u00eancia de dados, como \u00e9 conhecida em portugu\u00eas, \u00e9 o processo que extrai dados de diversas fontes, em diferentes velocidades, processando grandes quantidades (big data) e gerando valor. De modo algum pode ser entendida como uma ferramenta, mas sim como um conjunto de m\u00e9todos, assim como big data e o business intelligence.\n\nGeralmente o processo de data science \u00e9 composto por:\n\n* Quest\u00f5es\n* Prepara\u00e7\u00e3o\n* Explora\u00e7\u00e3o\n* Conclus\u00f5es\n* Comunica\u00e7\u00e3o\n\n[O que \u00e9 Data Science?](https:\/\/www.datageeks.com.br\/o-que-e-data-science\/)\n\n### O que \u00e9 Machine Learning?\n\nO aprendizado de m\u00e1quina (em ingl\u00eas, machine learning) \u00e9 um m\u00e9todo de an\u00e1lise de dados que automatiza a constru\u00e7\u00e3o de modelos anal\u00edticos. \u00c9 um ramo da intelig\u00eancia artificial baseado na id\u00e9ia de que sistemas podem aprender com dados, identificar padr\u00f5es e tomar decis\u00f5es com o m\u00ednimo de interven\u00e7\u00e3o humana.\n\n[Machine Learning - O que \u00e9 e qual sua import\u00e2ncia?](https:\/\/www.sas.com\/pt_br\/insights\/analytics\/machine-learning.html)","bbf85461":"O algoritmo k-Nearest Neighbors (ou k-NN) \u00e9 um m\u00e9todo n\u00e3o param\u00e9trico usado para classifica\u00e7\u00e3o e regress\u00e3o. Uma amostra \u00e9 classificada pelo voto da maioria de seus vizinhos, sendo a amostra atribu\u00edda \u00e0 classe mais comum entre os k vizinhos mais pr\u00f3ximos (k \u00e9 um n\u00famero inteiro positivo, geralmente pequeno). Se k = 1, o objeto \u00e9 simplesmente atribu\u00eddo \u00e0 classe do \u00fanico vizinho mais pr\u00f3ximo. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm).\n\nA precis\u00e3o do modelo KNN \u00e9 melhor que a regress\u00e3o log\u00edstica, mas pior que o SVM.","87c13265":"### Pressupostos baseados na an\u00e1lise dos dados\n\nChegamos \u00e0s seguintes premissas com base na an\u00e1lise de dados feita at\u00e9 agora e devemos validar ainda mais essas premissas antes de tomar as a\u00e7\u00f5es apropriadas.\n\n**Correla\u00e7\u00e3o.**\n\nQueremos saber at\u00e9 que ponto o conjunto de dados se correlaciona com a taxa de sobreviv\u00eancia. Devemos fazer isso no in\u00edcio do nosso projeto e combinar essas correla\u00e7\u00f5es r\u00e1pidas com as correla\u00e7\u00f5es modeladas posteriormente no projeto.\n\n**Conclus\u00e3o.**\n\n1. Podemos concluir que o conjunto Age est\u00e1 definitivamente relacionado \u00e0 taxa de sobreviv\u00eancia.\n2. Podemos desejar concluir o recurso Embarked, pois ele tamb\u00e9m pode estar relacionado \u00e0 sobreviv\u00eancia ou a outro recurso importante.\n\n**Corre\u00e7\u00e3o.**\n\n1. O conjunto Ticket pode ser retirado de nossa an\u00e1lise, pois cont\u00e9m uma alta taxa de duplicatas (22%) e pode n\u00e3o haver uma correla\u00e7\u00e3o entre o ticket e a taxa de sobreviv\u00eancia.\n2. O conjunto de cabine pode ser descartado, pois \u00e9 altamente incompleto ou cont\u00e9m muitos valores nulos no conjunto de dados de treinamento e teste.\n3. O PassengerId pode ser retirado do conjunto de dados de treinamento, pois n\u00e3o contribui para a sobreviv\u00eancia.\n4. O conjunto Name \u00e9 relativamente fora do padr\u00e3o e pode n\u00e3o contribuir diretamente para a sobreviv\u00eancia, ent\u00e3o talvez seja descartado.\n\n**Cria\u00e7\u00e3o.**\n\n1. Podemos criar um novo conjunto chamado Family, baseado em Parch e SibSp, para obter a contagem total de membros da fam\u00edlia a bordo.\n2. Podemos usar o conjunto Name para extrair a abrevia\u00e7\u00e3o (Titulo) como um novo conjunto.\n3. Podemos criar um novo conjunto para faixas et\u00e1rias. Isso transforma um recurso num\u00e9rico cont\u00ednuo em um recurso categ\u00f3rico ordinal.\n4. Tamb\u00e9m podemos criar um recurso de faixa de tarifa se isso ajudar nossa an\u00e1lise.\n\n**Classifica\u00e7\u00e3o.**\n\nTamb\u00e9m podemos adicionar nossas suposi\u00e7\u00f5es com base na descri\u00e7\u00e3o do problema observada anteriormente.\n\n1. As mulheres (Sex = female) tiveram maior probabilidade de sobreviver.\n2. As crian\u00e7as (idade <?) Tiveram maior probabilidade de sobreviver.\n3. Os passageiros da classe alta (Pclass = 1) tiveram maior probabilidade de sobreviver.","10aaf924":"### Criando novos conjuntos combinando os conjuntos existentes\n\nPodemos criar um novo conjunto FamilySize que combina Parch e SibSp. Isso nos permitir\u00e1 remover Parch e SibSp de nossos conjuntos de dados.","b50988ad":"## Vari\u00e1veis num\u00e9ricas e categ\u00f3ricas\n\nPodemos diferenciar vari\u00e1veis pelo tipo de dado. Em estat\u00edstica consideramos dois tipos de vari\u00e1veis: **N\u00famericas** e **Categ\u00f3ricas**.\n\n![](https:\/\/static.imasters.com.br\/wp-content\/uploads\/2017\/06\/01-2.png)\n\n**Quais recursos s\u00e3o categ\u00f3ricos?**\n\nS\u00e3o dados decorrentes da observa\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas,ou seja, aqueles que identificam para cada caso uma categoria.As categorias podem ser derivadas de vari\u00e1veis qualitativas (nominais ou ordinais) ou quantitativas. Entre outras coisas, isso nos ajuda a selecionar os gr\u00e1ficos e visualiza\u00e7\u00f5es apropriadas para visualiza\u00e7\u00e3o.\n\n- Categ\u00f3ricos: Survived, Sex, e Embarked.\n- Ordin\u00e1rios: Pclass.\n\n[Descri\u00e7\u00e3o de dados categ\u00f3ricos](https:\/\/www.ibilce.unesp.br\/Home\/Departamentos\/CiencCompEstatistica\/Adriana\/a6--teste-quiquadrado.pdf)\n\n**Quais recursos s\u00e3o num\u00e9ricos?**\n\nS\u00e3o as caracter\u00edsticas que podem ser medidas em uma escala quantitativa, ou seja, apresentam valores num\u00e9ricos que fazem sentido. Podem ser cont\u00ednuas ou discretas. Esses valores mudam de amostra para amostra. Dentro dos recursos num\u00e9ricos, os valores s\u00e3o discretos, cont\u00ednuos ou baseados em s\u00e9ries temporais? Entre outras coisas, isso nos ajuda a selecionar os gr\u00e1ficos apropriados para visualiza\u00e7\u00e3o.\n\n[Vari\u00e1veis, Estat\u00edstica e Machine Learning](https:\/\/imasters.com.br\/desenvolvimento\/variaveis-estatistica-e-machine-learning)\n\n- Cont\u00ednuos: Age e Fare.\n- Discretos: SibSp e Parch.","c415479e":"A seguir, modelamos usando Support Vector Machines (SVM), que s\u00e3o modelos de aprendizado supervisionado com algoritmos de aprendizado associados que analisam dados usados para an\u00e1lise de classifica\u00e7\u00e3o e regress\u00e3o. Dado um conjunto de amostras de treinamento, cada uma marcada como pertencente a uma ou outra de **duas categorias**, um algoritmo de treinamento SVM constr\u00f3i um modelo que atribui novas amostras de teste a uma categoria ou a outra. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Support_vector_machine).\n\nObserve que o modelo gera uma precis\u00e3o maior que o modelo de Regress\u00e3o Log\u00edstica.","c2a3781b":"### Convertendo conjuntos categ\u00f3ricos em num\u00e9ricos\n\nAgora podemos converter o conjunto EmbarkedFill criando um novo conjunto num\u00e9rico Port.","957f1c74":"Agora, iteramos sobre Sex (0 ou 1) e Pclass (1, 2, 3) para calcular os valores da idade para as seis combina\u00e7\u00f5es.","03624661":"## Organizando dados\n\nReunimos v\u00e1rias suposi\u00e7\u00f5es e decis\u00f5es sobre nossos conjuntos de dados e requisitos de solu\u00e7\u00e3o. At\u00e9 agora, n\u00e3o tivemos que alterar um \u00fanico conjunto ou valor para chegar a eles. Vamos agora executar nossas decis\u00f5es e suposi\u00e7\u00f5es para corrigir, criar e concluir o objetivo.\n\n### Removendo conjuntos de dados\n\nEsse \u00e9 um bom ponto de inicio. Ao eliminar os recursos, estamos lidando com menos pontos de dados. Isso acelera nosso c\u00f3digo e facilita a an\u00e1lise do problem\n\nCom base em nossas suposi\u00e7\u00f5es e decis\u00f5es, queremos descartar os conjuntos de Cabin e Ticket.\n\nAo realizar uma opera\u00e7\u00e3o de remo\u00e7\u00e3o de dados, devemos faze-la nos conjuntos de dados de treinamento e teste juntos para manter a consist\u00eancia do problema.","904abb8e":"Vamos criar faixas et\u00e1rias e determinar correla\u00e7\u00f5es com o conjunto Survived.","22c13e08":"### Completando conjuntos de dados num\u00e9ricos e continuos\n\nAgora devemos come\u00e7ar a estimar e concluir os conjuntos com valores ausentes ou nulos. Primeiro, faremos isso para o conjunto Age.\n\nPodemos considerar tr\u00eas m\u00e9todos para completar um conjunto num\u00e9rico cont\u00ednuo.\n\n1. Uma maneira simples \u00e9 gerar n\u00fameros aleat\u00f3rios entre a m\u00e9dia e o [desvio padr\u00e3o] (https:\/\/en.wikipedia.org\/wiki\/Standard_deviation).\n\n2. Uma maneira mais precisa de adivinhar valores ausentes \u00e9 usar outros recursos correlacionados. No nosso caso, observamos correla\u00e7\u00e3o entre Idade, G\u00eanero e Classe. Podemos completar o conjunto Age usando os valores de [mediana] (https:\/\/en.wikipedia.org\/wiki\/Median) para as combina\u00e7\u00f5es dos conjuntos Class e Gender. Ent\u00e3o, mediana de Age para Class = 1  e Gender = 0, Class = 1 e Gender = 1, e assim por diante...\n\n3. Combinamos os m\u00e9todos 1 e 2. Portanto, em vez de adivinhar os valores da idade com base na mediana, usamos n\u00fameros aleat\u00f3rios entre m\u00e9dia e desvio padr\u00e3o, com base em conjuntos de combina\u00e7\u00f5es de classe e g\u00eanero.\n\nOs m\u00e9todos 1 e 3 introduzir\u00e3o ru\u00eddo aleat\u00f3rio em nossos modelos. Os resultados de v\u00e1rias execu\u00e7\u00f5es podem variar de uma forma desequilibrada. Por esse motivo preferimos utilizar o m\u00e9todo 2.","795d2471":"## Obten\u00e7\u00e3o dos dados\n\nNessa etapa utilizaremos a biblioteca Pandas para importar os dados utilizados durante a an\u00e1lise.","a25b39d7":"### Correlacionando conjuntos num\u00e9ricos e ordinais\n\nPodemos combinar v\u00e1rios conjuntos para identificar correla\u00e7\u00f5es usando um \u00fanico gr\u00e1fico. Isso pode ser feito com conjuntos num\u00e9ricos e categ\u00f3ricos que possuem valores num\u00e9ricos.\n\n**Observa\u00e7\u00f5es.**\n\n- Pclass = 3 teve a maioria dos passageiros, por\u00e9m a maioria n\u00e3o sobreviveu.\n- Principalmente os passageiros infantis da Pclass = 2 e Pclass = 3 sobreviveram.\n- A maioria dos passageiros da Pclass = 1 sobreviveu.\n- Pclass varia em termos de distribui\u00e7\u00e3o et\u00e1ria dos passageiros.\n\n**Decis\u00f5es.**\n\n- Devemos considerar o conjunto Pclass para o treinamento do modelo.","609ed885":"Podemos criar outro conjunto chamado IsAlone.","1d0b6a82":"### Convertendo os conjuntos categ\u00f3ricos\n\nAgora podemos converter recursos que cont\u00eam cadeias de caracteres em valores num\u00e9ricos. Isso \u00e9 exigido pela maioria dos algoritmos de modelo.\n\nVamos come\u00e7ar convertendo o conjunto Sex para um novo recurso chamado Gender, onde female = 1 e male = 0.","28339dde":"O pr\u00f3ximo modelo Random Forests \u00e9 um dos mais populares. Random forests ou random decision forests \u00e9 um m\u00e9todo de aprendizado conjunto para classifica\u00e7\u00e3o, regress\u00e3o e outras tarefas, que operam construindo uma infinidade de \u00e1rvores de decis\u00e3o (n_estimators = 100) no momento do treinamento e gerando a classe que \u00e9 o modo das classes (classifica\u00e7\u00e3o) ou previs\u00e3o m\u00e9dia (regress\u00e3o) das \u00e1rvores individuais. Refer\u00eancia [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Random_forest).\n\nO \u00edndice de confian\u00e7a do modelo \u00e9 o mais alto entre os modelos avaliados at\u00e9 o momento.","d9aeb500":"O conjunto FamilySize n\u00e3o se mostrou eficiente na busca de um padr\u00e3o de sobreviventes, portanto vamos remover os conjuntos Parch, SibSp e FamilySize e manter o conjunto IsAlone.","a10492e6":"### Correlacionando conjuntos categ\u00f3ricos\n\nAgora podemos correlacionar os conjuntos categ\u00f3ricos com nossa taxa de sobreviv\u00eancia.\n\n**Observa\u00e7\u00f5es.**\n\n- As passageiras tiveram uma taxa de sobreviv\u00eancia muito melhor que os homens.\n- Exce\u00e7\u00e3o em Embarked = C, onde os homens tiveram maior taxa de sobreviv\u00eancia. Esta poderia ser uma correla\u00e7\u00e3o entre Pclass e Embarked e, por sua vez, Pclass e Survived, n\u00e3o necessariamente correla\u00e7\u00e3o direta entre Embarked e Survived.\n- Os homens apresentaram melhor taxa de sobreviv\u00eancia na Pclass = 3 quando comparados \u00e0 Pclass = 2 nos pontos C e Q.\n- Os pontos de embarque t\u00eam taxas de sobreviv\u00eancia variadas para Pclass = 3 e entre passageiros do sexo masculino.\n\n**Decis\u00f5es.**\n\n- Adicionar o conjunto Sex ao modelo de treinamento.\n- Completar e adicionar o conjunto Embarked ao modelo de treinamento.","7d60f5da":"## Kaggle\n\n### O Que \u00e9 o Kaggle?\n\nO Kaggle \u00e9 uma das mais conhecidas plataformas para competi\u00e7\u00f5es de Data Science. A plataforma foi fundada em 2010 por Anthony Goldbloom e em 2017 foi adquirida pelo Google (Alphabet).\n\n### Como Funciona o Kaggle?\n\nResumidamente, o Kaggle dentro da sua plataforma pode hospedar competi\u00e7\u00f5es de Data Science p\u00fablicas, privadas e acad\u00eamicas. As competi\u00e7\u00f5es patrocinadas por empresas oferecem pr\u00eamios em dinheiro pela melhor solu\u00e7\u00e3o. Tamb\u00e9m existem competi\u00e7\u00f5es de aprendizado (disponibilizadas pelo pr\u00f3prio Kaggle ou por empresas para treinamento de habilidades). A plataforma tamb\u00e9m armazena e disponibiliza dados sobre assuntos diversos (chamados datasets) e possui f\u00f3runs para troca de conhecimentos entre seus usu\u00e1rios.\n\n[Kaggle \u2013 O que \u00e9? Como Funciona?](http:\/\/tirandolicoesdetudo.com.br\/kaggle-o-que-e-como-funciona\/)","74171905":"Tamb\u00e9m podemos criar um conjunto artificial combinando Pclass e Age.","dc8e6342":"E o dataset de test.","cdb45d9b":"### Modelar, prever e resolver\n\nAgora estamos prontos para treinar um modelo e prever a solu\u00e7\u00e3o necess\u00e1ria. Existem mais de 60 algoritmos de modelagem preditiva para escolher. Precisamos entender o tipo de problema e o requisito da solu\u00e7\u00e3o para restringir a alguns poucos modelos que podemos avaliar. Nosso problema \u00e9 do tipo classifica\u00e7\u00e3o e regress\u00e3o. Queremos identificar a rela\u00e7\u00e3o entre a sa\u00edda (Survived) com outras vari\u00e1veis ou caracter\u00edsticas (Gender, Age, Port ...). Tamb\u00e9m estamos desenvolvendo uma categoria de Machine Learning chamada aprendizado supervisionado, enquanto treinamos nosso modelo com um determinado conjunto de dados. Com esses dois crit\u00e9rios - Aprendizado supervisionado mais Classifica\u00e7\u00e3o e regress\u00e3o, podemos restringir nossa escolha de modelos a alguns. Esses incluem:\n\n- Logistic Regression\n- KNN ou k-Nearest Neighbors\n- Support Vector Machines\n- Naive Bayes classifier\n- Decision Tree\n- Random Forrest\n- Perceptron\n- Artificial neural network\n- RVM or Relevance Vector Machine","2ff12e7b":"### Concluindo um conjunto de dados categ\u00f3ricos\n\nO conjunto Embarked aceita valores S, Q, C com base no porto de embarque. Nosso conjunto de dados de treinamento tem dois valores ausentes. N\u00f3s simplesmente os preencheremos com a ocorr\u00eancia mais comum.","883749af":"Agora, podemos descartar com seguran\u00e7a o conjunto Name dos conjuntos de dados de treinamento e teste. Tamb\u00e9m n\u00e3o precisamos do conjunto PassengerId.","82abfd00":"Podemos converter os t\u00edtulos categ\u00f3ricos em valores ordinais. Isso nos ajudar\u00e1 na hora da cria\u00e7\u00e3o do nosso modelo.","bfdfb0ee":"### Correlacionando conjuntos categ\u00f3ricos e num\u00e9ricos\n\nTamb\u00e9m podemos correlacionar recursos categ\u00f3ricos (com valores n\u00e3o num\u00e9ricos) e recursos num\u00e9ricos. Podemos considerar correlacionar Embarked (categ\u00f3rico n\u00e3o num\u00e9rico), Sex (categ\u00f3rico n\u00e3o num\u00e9rico), Fare (cont\u00ednuo num\u00e9rico), com Survived (categ\u00f3rico num\u00e9rico).\n\n**Observa\u00e7\u00f5es.**\n\n- Passageiros com tarifa mais alta tiveram melhor taxa de sobreviv\u00eancia. \n- O ponto de embarque se correlaciona com as taxas de sobreviv\u00eancia\n\n**Decis\u00f5es.**\n\n- Considerar o conjunto Fare.","a145f933":"\n## Objetivos\n\nO fluxo de trabalho das solu\u00e7\u00f5es de ci\u00eancia de dados resolve sete objetivos principais:\n\n**Classifica\u00e7\u00e3o.** Classifica\u00e7\u00e3o \u00e9 o processo de tomar algum tipo de entrada e atribuir um r\u00f3tulo a ela. Sistemas de classifica\u00e7\u00e3o s\u00e3o usados \u200b\u200bgeralmente quando as previs\u00f5es s\u00e3o de natureza distinta, ou seja, um simples \u201csim ou n\u00e3o\u201d. Podemos classificar ou categorizar nossas amostras. Tamb\u00e9m podemos entender as implica\u00e7\u00f5es ou correla\u00e7\u00f5es de diferentes classes com nosso objetivo de solu\u00e7\u00e3o.\n\n**Correla\u00e7\u00e3o.** \u00c9 poss\u00edvel aproximar o problema com base nos recursos dispon\u00edveis no conjunto de dados de treinamento. Quais recursos do conjunto de dados contribuem significativamente para nosso objetivo de solu\u00e7\u00e3o? Estatisticamente falando, existe uma [correla\u00e7\u00e3o](https:\/\/en.wikiversity.org\/wiki\/Correlation) entre um recurso e a nossa solu\u00e7\u00e3o? \u00c0 medida que os valores dos recursos mudam, o estado da solu\u00e7\u00e3o tamb\u00e9m muda e vice-versa?. Isso pode ser testado para recursos num\u00e9ricos e categ\u00f3ricos no conjunto de dados fornecido. Tamb\u00e9m podemos determinar a correla\u00e7\u00e3o entre outros recursos que n\u00e3o a sobreviv\u00eancia para objetivos subsequentes e est\u00e1gios do fluxo de trabalho. Correlacionar certos recursos pode ajudar na cria\u00e7\u00e3o, conclus\u00e3o ou corre\u00e7\u00e3o de recursos.\n\n**Conver\u00e7\u00e3o.** Para o est\u00e1gio de modelagem, \u00e9 necess\u00e1rio preparar os dados. Dependendo da escolha do algoritmo do modelo, pode-se exigir que todos os recursos sejam convertidos em valores num\u00e9ricos equivalentes. Por exemplo, convertendo valores categ\u00f3ricos de texto em valores num\u00e9ricos.\n\n**Conclus\u00e3o.** A prepara\u00e7\u00e3o dos dados tamb\u00e9m pode exigir que calculemos quaisquer valores ausentes em um recurso. Os algoritmos de modelo podem funcionar melhor quando n\u00e3o h\u00e1 valores ausentes.\n\n**Corre\u00e7\u00e3o.** Tamb\u00e9m podemos analisar o conjunto de dados de treinamento fornecido para erros ou valores possivelmente imprecisos nos recursos e tentar corrigir esses valores ou excluir as amostras que cont\u00eam os erros. Uma maneira de fazer isso \u00e9 detectar discrep\u00e2ncias entre nossas amostras ou recursos. Tamb\u00e9m podemos descartar completamente um recurso se ele n\u00e3o estiver contribuindo para a an\u00e1lise ou se distorcerem significativamente os resultados.\n\n**Cria\u00e7\u00e3o.** Podemos criar novos recursos com base em um recurso existente ou em um conjunto de recursos, de modo que o novo recurso siga os objetivos de correla\u00e7\u00e3o, convers\u00e3o e integridade.\n\n**Visualiza\u00e7\u00e3o.** Como selecionar os gr\u00e1ficos e as visualiza\u00e7\u00f5es corretas, dependendo da natureza dos dados e dos objetivos da solu\u00e7\u00e3o.","1f658ea8":"## An\u00e1lise descritiva dos dados\n\nO Pandas tamb\u00e9m ajuda a descrever os recursos que nos ajudam a responder \u00e0s perguntas a seguir, afim de obtermos uma solu\u00e7\u00e3o para nosso problema.\n\n**Quais recursos est\u00e3o dispon\u00edveis no conjunto de dados?**\n\nObservando os nomes dos recursos para manipul\u00e1-los ou analis\u00e1-los diretamente. Esses nomes de recursos s\u00e3o descritos na p\u00e1gina de dados do Kaggle [aqui](https:\/\/www.kaggle.com\/c\/titanic).","4c3e30bf":"## Correla\u00e7\u00e3o de dados\n\nPara confirmar algumas de nossas observa\u00e7\u00f5es e suposi\u00e7\u00f5es, podemos analisar rapidamente nossas correla\u00e7\u00f5es dos dados, alternando recursos entre si. S\u00f3 podemos fazer isso nesta fase para recursos que n\u00e3o possuem valores vazios. Tamb\u00e9m faz sentido faz\u00ea-lo apenas para recursos do tipo categ\u00f3rico (Sex), ordinal (Pclass) ou discreto (SibSp, Parch).\n\n- **Pclass** Observamos correla\u00e7\u00e3o significativa (> 0,5) entre Pclass = 1 e Survived. Decidimos incluir esse recurso em nosso modelo.\n- **Sex** Confirmamos a observa\u00e7\u00e3o durante a defini\u00e7\u00e3o do problema de que Sex = female teve uma taxa de sobreviv\u00eancia muito alta em 74%.\n- **SibSp e Parch** Esses recursos t\u00eam correla\u00e7\u00e3o zero para determinados valores. Talvez seja melhor fazer um agrupamento desse conjunto de dados.","386733fd":"Tendo o novo conjunto FareBand converteremos o conjunto de dados Fare para valores ordinais.\nE com isso finalizamos o tratamento dos dados, obtendo o dataset de treino."}}