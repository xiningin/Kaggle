{"cell_type":{"069ae0ae":"code","afde8445":"code","d9b3c2b8":"code","2e8ac4ed":"code","0aa5ea41":"code","ab9fb518":"code","94594768":"code","60f24212":"code","2f033042":"code","65e0bc04":"code","3705f38c":"code","93d29c6d":"code","a80655e4":"code","519c233b":"code","b22e877c":"code","e3f1a90a":"code","1a60fa77":"code","943c695b":"code","8bf61cc0":"code","8f274dc4":"code","31483a84":"code","da305cc8":"code","70689c9b":"code","65bacbb6":"code","22f7b6c1":"code","ae24135b":"code","eb611bbd":"code","ab24c6f9":"code","d383f555":"code","4d2bbd6d":"markdown","d6e6d522":"markdown","e59a1d7a":"markdown","1410b9a6":"markdown"},"source":{"069ae0ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","afde8445":"data = pd.read_csv('..\/input\/pokemon.csv')","d9b3c2b8":"data.info()","2e8ac4ed":"data.head()","0aa5ea41":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed)\/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later","ab9fb518":"#Let s look at the frequency of pokemons feature\nprint (data['Type 1'].value_counts(dropna=False)) #also nan values are counted by dropna=False","94594768":"data.boxplot(column='Attack',by = 'Legendary')\nplt.xlabel('Legendary')\nplt.ylabel('Attack')\n#plt.title('Boxplot of Attack-Legendary')\nplt.show()","60f24212":"data_new = data.head()    # I only take 5 rows into new data\ndata_new","2f033042":"melted=pd.melt(frame=data_new, id_vars='Name',value_vars=['Attack','Defense'])\nmelted","65e0bc04":"#reverse melting\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","3705f38c":"# CONCATENATING DATAFRAMES\ndata1 = data.head()\ndata2= data.tail()\nconc_data = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 (horizontal) : adds row by row \nconc_data","93d29c6d":"data1 = data['Speed'].head()\ndata2= data['Defense'].head()\nconc_data_v = pd.concat([data1,data2],axis =1) # axis = 1 (vertical) : adds column by column \nconc_data_v","a80655e4":"data.dtypes #show us colums type","519c233b":"#some example\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","b22e877c":"data.dtypes","e3f1a90a":"data.info()# as you can see 1 null in the name, 386 null value of Type 2 ","1a60fa77":"data[\"Type 2\"].value_counts(dropna =False)#count all of type 2 and 386 nan(null) value","943c695b":"data1=data   \ndata1[\"Type 2\"].dropna(inplace = True)#drop nan values","8bf61cc0":"data[\"Type 2\"].fillna('empty',inplace = True)","8f274dc4":"assert  data['Type 2'].notnull().all()# if this statement> data1['Type 2'].notnull().all() is wrong than retrun false \n#but if it is true returns nothing because we drop nan values","31483a84":"# data frames from dictionary\n#ste by step we can see  whats happening.\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nprint (type(list_label))\n\nlist_col = [country,population]\nprint (list_col)\nprint (type(list_col))\n\nzipped = list(zip(list_label,list_col))\nprint (zipped)\nprint (type(zipped))\n\ndata_dict = dict(zipped)\nprint(data_dict)\nprint (type(data_dict))\n\ndf = pd.DataFrame(data_dict)\nprint (type(df))\ndf","da305cc8":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","70689c9b":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","65bacbb6":"data.head()","22f7b6c1":"data1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]#show us overleapping 3 column grafics\ndata1.plot()","ae24135b":"# subplots\ndata1.plot(subplots = True)#differentiate by the subplots\nplt.show()","eb611bbd":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","ab24c6f9":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True)#normed(boolean): normalize or not","d383f555":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)#cumulative(boolean): compute cumulative distribution\nplt.savefig('graph.png')\nplt","4d2bbd6d":"**MELTED**\n\nWhatever you want to do with columns  which is combine into one column diffirent 2 or 3 columns but watch out id_vars point out the singular(primary key)","d6e6d522":"**NOTE**\n\nWith assert statement we can check a lot of thing. For example\n \nassert data.columns[1] == 'Name'\n\n assert data.Speed.dtypes == np.int\n \n","e59a1d7a":"**PANDAS FOUNDATION**\n\n single column = series\n \nNaN = not a number\n\ndataframe.values = numpy","1410b9a6":"object(string) - to - Category --https:\/\/www.tutorialspoint.com\/python_pandas\/python_pandas_categorical_data.htm\nfloat - to - int"}}