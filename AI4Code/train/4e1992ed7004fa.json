{"cell_type":{"de444795":"code","7546544e":"code","9ea8c470":"code","f5bc47b2":"code","d0f44931":"code","57774b7d":"code","f5527c22":"code","a9946e02":"code","71c3bf64":"code","963df781":"code","6e44e1d8":"code","a9a0f893":"code","3fcb8bc4":"code","18b7782a":"code","f1495246":"code","6420a9fe":"code","42f58273":"code","d9b71dd3":"code","c26e7e46":"code","f3d31ec5":"code","04192a0c":"code","5195707c":"code","814e8d52":"markdown","868b53a6":"markdown","44e23b72":"markdown","58487f48":"markdown","54fa3694":"markdown","9a8a0f8c":"markdown","f9f7c8a4":"markdown","e4ece33f":"markdown","2da9ac45":"markdown","f81ab809":"markdown","c1cbfbc0":"markdown","8af03353":"markdown","4f8bfc8b":"markdown","4ce5b080":"markdown","d9d30049":"markdown","c9544622":"markdown","fc0cc65e":"markdown","b11ab648":"markdown","c3a7d88a":"markdown"},"source":{"de444795":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import datasets,models,transforms\nfrom PIL import Image\nfrom sklearn.model_selection import StratifiedShuffleSplit\ntorch.version","7546544e":"os.listdir(\"..\/input\")","9ea8c470":"all_labels_df=pd.read_csv(\"..\/input\/labels.csv\")\nall_labels_df.head()","f5bc47b2":"breeds=all_labels_df.breed.unique()\nbreed2idx=dict((breed,idx) for idx,breed in enumerate(breeds))\nidx2breed=dict((idx,breed) for idx,breed in enumerate(breeds))\nprint(len(breeds))   # \u8fd9\u4e2a\u6570\u636e\u6709120\u4e2a\u7c7b\u522b","d0f44931":"all_labels_df[\"label_idx\"]=[breed2idx[b] for b in all_labels_df.breed]\nall_labels_df.head()","57774b7d":"class DogDataset(Dataset):\n    def __init__(self,label_df,img_path,transform=None):\n        self.label_df=label_df\n        self.img_path=img_path\n        self.transform=transform\n        \n    def __len__(self):\n        \"\"\"\u653e\u56de\u6570\u636e\u96c6\u7684\u957f\u5ea6\"\"\"\n        return self.label_df.shape[0]\n    \n    def __getitem__(self,idx):\n        \"\"\"\u8bfb\u53d6\u56fe\u7247\u548c\u6807\u7b7e\"\"\"\n        label=self.label_df.label_idx[idx]\n        id_img=self.label_df.id[idx]\n        img_P=os.path.join(self.img_path,id_img)+\".jpg\"\n        img=Image.open(img_P)\n        \n        if self.transform:\n            img=self.transform(img)\n            \n        return img,label","f5527c22":"IMG_SIZE=224   # resnet50\u7684\u8f93\u5165\u662f224\u7684\uff0c\u6240\u4ee5\u9700\u8981\u5c06\u56fe\u7247\u7edf\u4e00\u5927\u5c0f\nBATCH_SIZE=256   # \u6bcf\u4e2a\u6279\u6b21\u8f93\u5165\u7684\u56fe\u7247\u7684\u6570\u91cf\nIMG_MEAN=[0.485,0.456,0.406]\nIMG_STD=[0.229,0.224,0.225]\nCUDA=torch.cuda.is_available()\nDEVICE=torch.device(\"cuda\" if CUDA else \"cpu\")","a9946e02":"train_transform=transforms.Compose([\n    transforms.Resize(IMG_SIZE),   # \u6539\u53d8\u56fe\u7247\u5927\u5c0f\n    transforms.RandomResizedCrop(IMG_SIZE),  # \u9996\u5148\u968f\u673a\u88c1\u51cf\uff0c\u7136\u540e\u5728\u8f6c\u6362\u6210\u89c4\u5b9a\u56fe\u7247\u5927\u5c0f\n    transforms.RandomHorizontalFlip(),  # \u4ee50.5\u7684\u6982\u7387\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\n    transforms.RandomRotation(30),  # \u65cb\u8f6c\n    transforms.ToTensor(),  # \u8f6c\u6362\u6210\u5f20\u91cf\n    transforms.Normalize(IMG_MEAN,IMG_STD)  # \u6807\u51c6\u5316\n])\n\nval_transform=transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(IMG_MEAN,IMG_STD)\n])","71c3bf64":"# \u4f7f\u7528\u5206\u5c42\u62bd\u6837\u5207\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\ndataset_name=[\"train\",\"valid\"]\nstra_splt=StratifiedShuffleSplit(n_splits=1,test_size=0.1,random_state=0)\ntrain_index,val_index=next(iter(stra_splt.split(all_labels_df.id,all_labels_df.breed)))\ntrain_df=all_labels_df.iloc[train_index,:].reset_index()\nval_df=all_labels_df.iloc[val_index,:].reset_index()\nprint(len(train_df))\nprint(len(val_df))","963df781":"image_tarnsforms={\"train\":train_transform,\"valid\":val_transform}\n\ntrain_dataset=DogDataset(train_df,\"..\/input\/train\",transform=image_tarnsforms[\"train\"])\nvalid_dataset=DogDataset(val_df,\"..\/input\/train\",transform=image_tarnsforms[\"valid\"])\nimage_dataset={\"train\":train_dataset,\"valid\":valid_dataset}\n\nimage_dataloader={x:DataLoader(image_dataset[x],batch_size=BATCH_SIZE,shuffle=True,num_workers=0) for x in dataset_name}\ndatasize={x:len(image_dataset[x]) for x in dataset_name}","6e44e1d8":"model_ft=models.resnet50(pretrained=True) # \u81ea\u52a8\u4e0b\u8f7d\u5b98\u65b9\u7684\u9884\u8bad\u7ec3\u6a21\u578b\n# \u5c06\u6240\u6709\u7684\u5c42\u90fd\u5148\u51bb\u7ed3\nfor param in model_ft.parameters():\n    param.requires_grad=False\n\n# \u6253\u5370\u5168\u8fde\u63a5\u5c42\u7684\u4fe1\u606f\nprint(model_ft.fc)\nnum_fc_ftr=model_ft.fc.in_features  # \u83b7\u53d6\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165\nmodel_ft.fc=nn.Linear(num_fc_ftr,len(breeds))  # \u5b9a\u4e49\u4e00\u4e2a\u65b0\u7684\u5168\u8fde\u63a5\u5c42\nmodel_ft=model_ft.to(DEVICE)  # \u5c06\u7f51\u7edc\u653e\u5230\u8bbe\u5907\u4e2d\nprint(model_ft)  # \u6700\u540e\u6253\u5370\u4e00\u4e0b\u6a21\u578b","a9a0f893":"criterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam([{\"params\":model_ft.fc.parameters()}],lr=0.001)  # \u6307\u5b9a\u65b0\u52a0\u7684fc\u5c42\u7684\u5b66\u4e60\u7387","3fcb8bc4":"for data in image_dataloader[\"train\"].dataset:\n    x,y=data\n    plt.imshow(x)\n    plt.title(y)\n    break","18b7782a":"def train(model,device,train_loader,epoch):\n    model.train()\n    for batch_idx,data in enumerate(train_loader):\n        x,y=data\n        x=x.to(device)\n        y=y.to(device)\n        optimizer.zero_grad()\n        y_hat=model(x)\n        loss=criterion(y_hat,y)\n        loss.backward()\n        optimizer.step()\n    print ('Train Epoch: {}\\t Loss: {:.6f}'.format(epoch,loss.item()))","f1495246":"def test(model,device,test_loader):\n    model.eval()\n    test_loss=0\n    correct=0\n    with torch.no_grad():\n        for i,data in enumerate(test_loader):\n            x,y=data\n            x=x.to(device)\n            y=y.to(device)\n            optimizer.zero_grad()\n            y_hat=model(x)\n            test_loss+=criterion(y_hat,y).item()\n            pred=y_hat.max(1,keepdim=True)[1]\n            correct+=pred.eq(y.view_as(pred)).sum().item()\n    test_loss\/=len(test_loader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(valid_dataset),\n        100. * correct \/ len(valid_dataset)))","6420a9fe":"for epoch in range(1,9):\n    %time train(model_ft,DEVICE,image_dataloader[\"train\"],epoch)\n    test(model_ft,DEVICE,image_dataloader[\"valid\"])","42f58273":"# hook\nin_list=[]  # \u5b58\u653e\u6240\u6709\u7684\u8f93\u51fa\ndef hook(module,input,output):\n    for i in range(input[0].size(0)):\n        in_list.append(input[0][i].cpu().numpy())","d9b71dd3":"model_ft.avgpool.register_forward_hook(hook)","c26e7e46":"%%time\nwith torch.no_grad():\n    for batch_idx,data in enumerate(image_dataloader[\"train\"]):\n        x,y=data\n        x=x.to(DEVICE)\n        y=y.to(DEVICE)\n        y_hat=model_ft(x)","f3d31ec5":"features=np.array(in_list)","04192a0c":"np.save(\"\/kaggle\/working\/features\",features)","5195707c":"features.shape","814e8d52":"\u628a\u7c7b\u522b\u6807\u53f7\u6dfb\u52a0\u5230\u539f\u59cb\u8868\u683c\u4e2d","868b53a6":"\u6211\u4eec\u8fd9\u91cc\u5207\u527210%\u7684\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u65f6\u7684\u9a8c\u8bc1\u6570\u636e","44e23b72":"\u7531\u4e8e\u6211\u4eec\u7684\u6570\u636e\u96c6\u662f\u5b98\u65b9\u6307\u5b9a\u7684\u683c\u5f0f\uff0c\u6240\u4ee5\u6211\u4eec\u81ea\u5df1\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6","58487f48":"\u5b9a\u4e49\u6570\u636e\u548c\u56fe\u7247\u53d8\u6362\u89c4\u5219","54fa3694":"## \u5fae\u8c03\u5b9e\u4f8b","9a8a0f8c":"\u5b9a\u4e49\u6d4b\u8bd5\u51fd\u6570","f9f7c8a4":"\u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570","e4ece33f":"\u8bbe\u7f6e\u8bad\u7ec3\u53c2\u6570","2da9ac45":"\u5b9a\u4e49\u4e24\u4e2a\u5b57\u5178","f81ab809":"## \u6ce8\u610f\u4e8b\u9879","c1cbfbc0":"\u8bad\u7ec39\u6b21\uff0c\u770b\u770b\u6548\u679c","8af03353":"\u6211\u4eec\u6bcf\u6b21\u90fd\u9700\u8981\u5c06\u4e00\u5f20\u56fe\u7247\u5728\u5168\u90e8\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97\uff0c\u800c\u4e14\u6bcf\u6b21\u7ed3\u679c\u90fd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u6837\u6d6a\u8d39\u4e86\u5f88\u591a\u8ba1\u7b97\u8d44\u6e90\u3002\u4e0b\u9762\u6211\u4eec\u5c06\u8fd9\u4e9b\u4e0d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u6216\u8005\u8bf4\u4e0d\u66f4\u65b0\u53c2\u6570\u5c42\u7684\u8ba1\u7b97\u7ed3\u679c\u4fdd\u5b58\u4e0b\u6765\uff0c\u8fd9\u6837\u6211\u4eec\u4ee5\u540e\u4f7f\u7528\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u76f4\u63a5\u5c06\u8fd9\u4e9b\u7ed3\u679c\u8f93\u5165\u5230\u4ee5\u8fd9\u4e9b\u7ed3\u679c\u6784\u5efa\u7684\u65b0\u7684\u7f51\u7edc\u5c42\u4e2d\uff0c\u7701\u53bb\u4e86\u8ba1\u7b97\u65f6\u95f4\uff0c\u8fd9\u6837\u5982\u679c\u53ea\u8bad\u7ec3\u5168\u8fde\u63a5\u5c42\uff0ccpu\u5c31\u80fd\u5b8c\u6210\u4e86\u3002","4f8bfc8b":"\u914d\u7f6e\u6211\u4eec\u7684\u7f51\u7edc\uff0c\u7531\u4e8eImageNet\u8bc6\u522b\u7684\u662f1000\u4e2a\u7c7b\u522b\uff0c\u800c\u6211\u4eec\u7684\u6570\u636e\u96c6\u53ea\u6709100\u4e2a\u7c7b\u522b\u3002","4ce5b080":"1.\u65b0\u6570\u636e\u96c6\u548c\u539f\u59cb\u6570\u636e\u96c6\u7c7b\u4f3c\uff0c\u90a3\u4e48\u76f4\u63a5\u53ef\u4ee5\u5fae\u8c03\u6700\u540e\u4e00\u4e2aFC\u5c42\u6216\u8005\u91cd\u65b0\u6307\u5b9a\u4e00\u4e2a\u5206\u7c7b\u5668\uff1b<p>\n2.\u5982\u679c\u5dee\u5f02\u6bd4\u8f83\u5927\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u7684\u4e2d\u90e8\u5f00\u59cb\u8bad\u7ec3\uff0c\u53ea\u5bf9\u6700\u540e\u51e0\u5c42\u8fdb\u884cfine_tuning\uff1b<p>\n3.\u5982\u679c\u5dee\u5f02\u6bd4\u8f83\u5927\uff0c\u5e76\u4e14\u4e0a\u9762\u7684\u65b9\u6cd5\u4e0d\u53ef\u884c\uff0c\u6700\u597d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u5c06\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u4f5c\u4e3a\u65b0\u6a21\u578b\u7684\u4e00\u4e2a\u521d\u59cb\u5316\u6570\u636e\uff1b<p>\n4.\u65b0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u4e00\u5b9a\u8981\u4e0e\u539f\u59cb\u6570\u636e\u96c6\u76f8\u540c<p>\n5.\u5982\u679c\u6570\u636e\u96c6\u5927\u5c0f\u4e0d\u76f8\u540c\u7684\u8bdd\uff0c\u53ef\u4ee5\u5728\u6700\u540e\u7684fc\u5c42\u4e4b\u524d\u6dfb\u52a0\u5377\u79ef\u6216\u8005pool\u5c42\uff0c\u4f46\u662f\u8fd9\u6837\u505a\u4f1a\u4f7f\u5f97\u7cbe\u5ea6\u5927\u5e45\u5ea6\u4e0b\u964d\uff1b<p>\n6.\u5bf9\u4e8e\u4e0d\u540c\u7684\u5c42\u53ef\u4ee5\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff1b<p>","d9d30049":"## \u56fa\u5b9a\u5c42\u7684\u5411\u91cf\u5bfc\u51fa","c9544622":"# Fine Tuning","fc0cc65e":"\u5b9a\u4e49\u8bad\u7ec3\u51fd\u6570","b11ab648":"\u8fd9\u6837\uff0c\u6211\u4eec\u5c31\u53ea\u9700\u8981\u5c06\u8fd9\u4e2a\u6570\u636e\u8bfb\u51fa\u6765\uff0c\u518d\u8f93\u5165\u5230\u6211\u4eec\u4e4b\u540e\u7684\u5206\u7c7b\u5668\u4e2d\u5c31\u53ef\u4ee5\uff0c\u6216\u8005\u66f4\u9ad8\u7ea7\u7684\u5206\u7c7b\u5668\uff0c\u5982SVM\u4e2d\u3002","c3a7d88a":"\u4f7f\u7528\u5b98\u65b9\u7684dataloader\u8f7d\u5165\u6570\u636e"}}