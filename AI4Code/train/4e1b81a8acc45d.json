{"cell_type":{"a54ec3df":"code","7709e4cb":"code","84cbcfbc":"code","ab5ff6ae":"code","5424e0d1":"code","fb8e7ff5":"code","fb573aca":"code","f71632d4":"markdown","1eb9ca2e":"markdown","1d37495f":"markdown","d1269a3c":"markdown","d41ffc88":"markdown","35bcf03a":"markdown","3ff66530":"markdown","aff60aa0":"markdown"},"source":{"a54ec3df":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import ExtraTreesClassifier as Classifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.pipeline import Pipeline","7709e4cb":"target = 'Cover_Type'\ncols_to_drop = [\"Soil_Type7\", \"Soil_Type15\"]","84cbcfbc":"preprocessor = ColumnTransformer(\n    remainder='passthrough',                  # keep all columns\n    transformers=[\n        ('drop', 'drop', cols_to_drop),       # except these\n        # Could possibly use `FunctionTransformer` (as many as needed ) for feature engineering\n    ])","ab5ff6ae":"model = Classifier(n_jobs=-1, random_state=0)\npipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])","5424e0d1":"train = pd.read_csv('..\/input\/learn-together\/train.csv', index_col='Id')  # 15120 records\nX, y = train.drop([target], axis=1), train[target]","fb8e7ff5":"cv = StratifiedKFold(n_splits=3, random_state=0)\nparam_grid = {\n    \"model__random_state\": [0],   # [0, 1, 2, 3, 4],\n    \"model__n_estimators\": [360], # [320, 340, 360, 380, 400],\n    \"model__max_depth\": [32]      # [25, 30, 32, 34, 38, 45]\n}\nsearchCV = GridSearchCV(estimator=pipeline, scoring='accuracy', cv=cv, param_grid=param_grid, verbose=True)\n\n# WARNING: This could take some time to run.\nsearchCV.fit(X, y)\n\nprint('Best index:', searchCV.best_index_)\nprint('Best score:', searchCV.best_score_)\nprint('Best params:', searchCV.best_params_)","fb573aca":"X_test = pd.read_csv('..\/input\/learn-together\/test.csv', index_col='Id')  # 565892 records\ntest_preds = searchCV.predict(X_test)\noutput = pd.DataFrame({'Id': X_test.index, 'Cover_Type': test_preds})\noutput.to_csv('submission.csv', index=False)","f71632d4":"Define target column as well as the ones we want to drop. All other columns will be preserved in the pipeline. Categorical columns are already one-hot encoded (one column per category) so we don't need to worry about transforming any of the columns.","1eb9ca2e":"## Load Training Data\nThe `Id` column will be identified as the `index_col`. As such, it won't be used for training the model. Also, the data won't be split into train\/validation sets as the `GridSearchCV` will do this (several times, stratified) for cross validation.","1d37495f":"## GridSearchCV","d1269a3c":"Set up a preprocessor that will do data transformations on data sources before using it in a model. For example, each time data is split during cross validation or before the test data is used for final predictions.\n\nFor now, it'll only be used to remove unwanted columns. Later, it can be used for feature engineering.","d41ffc88":"# Predict\n\nThe model has been automatically refitted with the best parameters from the grid search","35bcf03a":"# Tuning\n## The Pipeline\n\nFirst, set up a pipeline that will preprocess the data set and then feed it into the model. We'll set up a moel to use all available cores and some `random_state` for reproducible output. The rest of the parameters will be fed in via `GridSearchCV`","3ff66530":"I was able to get a score of `0.79198` on the public leaderboards using an `extraTrees` classifier in R and wanted to see if I could do better with SciKit. My first attempt at using `ExtraTreesClassifier` yielded a score of `0.75771` on the public leaderboards.","aff60aa0":"`GridSearchCV` uses \"brute force\" to exhaustively try all combinations of configured parameters. It can also do cross validation, so I'll set up a cross validator.\n\nBy default, `GridSearchCV` would use a `StratifiedKFold` CV anyway, since the target column is multi-class (contains more than two discrete values, is not a sequence of sequences, and is 1d or a column vector) but I want to be able to control its `random_state` which by default is `None`. I'll use `3` splits for now since the training data is not that large (15120 observtions). `5` might also be reasonable."}}