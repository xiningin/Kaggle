{"cell_type":{"5f6e1e47":"code","5fd2198a":"code","17fbd332":"code","32800451":"code","55ab05a8":"code","82e37a6f":"code","62461a61":"code","87885eb4":"code","f77dd04f":"code","383bc0b6":"code","4fcf7f18":"code","6bdd49ec":"code","d5d2710f":"code","10d1b827":"code","ae95e46c":"code","3fa5ac82":"code","d8a924eb":"code","b5a658c1":"code","aae82b0c":"code","113724c0":"code","b47d843d":"code","40b60d75":"code","5588a3cc":"code","f607f7eb":"code","ff9d6654":"code","033c1871":"code","93a4463f":"code","4f2eead6":"code","b5bd2b2d":"code","1e08316a":"code","4035862e":"code","38319bf4":"code","e0ff03eb":"code","bfda1081":"code","03585e2b":"code","973a3338":"code","e030c572":"code","69389b70":"code","35951b66":"code","2e6214c5":"code","5f8de1b0":"code","be8a9ab1":"code","e1ab8355":"code","ca2e2421":"code","678e63db":"code","0a3eb7a2":"code","a68848de":"code","41ba7837":"code","da9480b4":"code","07de4d6f":"code","fc71d21e":"code","d526e8e3":"code","b4a46978":"code","4e50e0e2":"code","1c233184":"code","64b85201":"code","9d675169":"code","bbf0a68c":"code","39beca10":"code","9953400a":"code","45699f2d":"code","1bb8babc":"code","d2fb7ad2":"code","756e59b6":"code","099c76dd":"code","9c9502d3":"code","b7576ca4":"code","22e63790":"code","dfb7c74d":"code","a5b20744":"markdown","f9d340ce":"markdown","7992989c":"markdown","37cfff0c":"markdown","7a327c66":"markdown","6fd3a268":"markdown","8ca5a787":"markdown","09b7768b":"markdown","19e690a3":"markdown","d4090e4c":"markdown","38beec19":"markdown","4e53568a":"markdown","0193ac49":"markdown","d9b03232":"markdown","0f39272f":"markdown","f482bf58":"markdown","598ad6c1":"markdown","82e47c1b":"markdown","a0477da2":"markdown","8d6ee675":"markdown","a858447d":"markdown","40566802":"markdown","95ebbc91":"markdown","3d15f639":"markdown","605b6767":"markdown","36029a73":"markdown","c25cbb16":"markdown","fb258e84":"markdown","535e7afa":"markdown","d3cf3514":"markdown","a56f11fc":"markdown","c29f02ce":"markdown","1820dd04":"markdown","66e7733d":"markdown","e35bb1e2":"markdown","73edd0f6":"markdown","548548ae":"markdown","264e9350":"markdown","218b10d3":"markdown","40c2d95b":"markdown","4f019299":"markdown","e9ea84ff":"markdown","9241d5af":"markdown","be7ea193":"markdown","9bed30d2":"markdown","c6f6479d":"markdown","b2246129":"markdown","84dd3f52":"markdown"},"source":{"5f6e1e47":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom decimal import Decimal, ROUND_HALF_UP\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time","5fd2198a":"train_data=pd.read_csv('..\/input\/train.csv')\ntest_data=pd.read_csv('..\/input\/test.csv')\npassengerId=test_data['PassengerId']\ncombine=[train_data,test_data]","17fbd332":"pd.unique(train_data['SibSp'])","32800451":"train_data.head()","55ab05a8":"test_data.head()","82e37a6f":"train_data.info()\nprint('**'*20)\ntest_data.info()","62461a61":"train_data.describe()","87885eb4":"train_data.describe(include=['O'])","f77dd04f":"train_data[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived',ascending=False)","383bc0b6":"train_data.groupby(['Pclass'],as_index=False)['Pclass','Survived'].mean().sort_values(by='Survived',ascending=False)","4fcf7f18":"train_data.groupby(['SibSp'],as_index=False)['SibSp','Survived'].mean().sort_values(by='Survived',ascending=False)","6bdd49ec":"train_data.groupby(['Parch'],as_index=False)['Parch','Survived'].mean().sort_values(by='Survived',ascending=False)","d5d2710f":"train_data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar()","10d1b827":"g = sns.FacetGrid(train_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","ae95e46c":"train_data.groupby(['Pclass'])['Pclass','Survived'].mean().plot.bar()","3fa5ac82":"g=sns.FacetGrid(train_data,col='Survived',row='Pclass')\ng.map(plt.hist,'Age',bins=20,alpha=.7)","d8a924eb":"grid = sns.FacetGrid(train_data, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","b5a658c1":"for dataset in combine:\n    dataset['Title']=dataset.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n\npd.crosstab(train_data['Title'],train_data['Sex'])","aae82b0c":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_data.groupby(['Title'])[['Title','Survived']].mean()","113724c0":"train_data.head()","b47d843d":"guess_ages=np.zeros((2,3))\nguess_ages","40b60d75":"for dataset in combine:\n    for i,s in zip((0,1),('female','male')):\n        for j in range(0,3):\n            no_null_age=dataset[(dataset['Sex']==s) & (dataset['Pclass']==j+1)]['Age'].dropna()\n            median_age=no_null_age.median()\n            # \u5c06\u5e74\u9f84\u8fdb\u884c\u56db\u820d\u4e94\u5165\u8f6c\u4e3a\u6574\u6570\n            guess_ages[i,j] = Decimal(median_age).quantize(Decimal('0'), rounding=ROUND_HALF_UP)\n    for i,s in zip((0,1),('female','male')):\n        for j in range(0,3):\n            \"\"\" \u8fd9\u91cc\u6ce8\u610f \u8981\u52a0\u4e0a 'Age' \u4e0d\u7136\u5b9a\u4f4d\u5230\u7684\u662f\u4e00\u6574\u5217\u8fdb\u884c\u66ff\u6362\u4e86\uff0c\u540c\u65f6Age\u662f\u5199\u5728loc\u91cc\u9762\"\"\"\n            dataset.loc[(dataset['Age'].isnull()) & (dataset['Sex']==s) & (dataset['Pclass']==j+1),'Age']=guess_ages[i,j]\n    dataset.Age=dataset.Age.astype(int)\n\ntrain_data.head()","5588a3cc":"for dataset in combine:\n    dataset['Agecut']=pd.cut(dataset['Age'],5)\ntrain_data[['Agecut','Survived']].groupby(['Agecut'],as_index=False).mean().sort_values(by='Survived',ascending=False)","f607f7eb":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ntrain_data['Age']=le.fit_transform(train_data['Agecut'])\ntest_data['Age']=le.fit_transform(test_data['Agecut'])\ntrain_data.head()","ff9d6654":"train_data.drop('Agecut',axis=1,inplace=True)\ntest_data.drop('Agecut',axis=1,inplace=True)\n\ncombine = [train_data, test_data]","033c1871":"test_data['Fare']=test_data['Fare'].fillna(test_data['Fare'].mode()[0])","93a4463f":"for dataset in combine:\n    dataset['Farecut']=pd.cut(dataset['Fare'],4)\n    \ntrain_data[['Farecut','Survived']].groupby(['Farecut'],as_index=False).mean().sort_values(by='Survived',ascending=False)","4f2eead6":"for dataset in combine:\n    dataset['Farecut']=le.fit_transform(dataset['Farecut'])","b5bd2b2d":"for dataset in combine:\n    dataset['Fare']= dataset['Farecut']\n    \ntrain_data[['Fare','Survived']].groupby(['Fare'],as_index=False).mean().sort_values(by='Survived',ascending=False)","1e08316a":"train_data.drop('Farecut',axis=1,inplace=True)\ntest_data.drop('Farecut',axis=1,inplace=True)\ncombine=[train_data,test_data]","4035862e":"data_df = train_data.append(test_data) # The entire data: train + test.","38319bf4":"data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']\n\n# Substituting Age values in TRAIN_DF and TEST_DF:\ntrain_data['Family_Size'] = data_df['Family_Size'][:891]\ntest_data['Family_Size'] = data_df['Family_Size'][891:]","e0ff03eb":"data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\ndata_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n\nDEFAULT_SURVIVAL_VALUE = 0.5\ndata_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n\n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin==0.0):\n                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n      data_df.loc[data_df['Family_Survival']!=0.5].shape[0])","bfda1081":"for _, grp_df in data_df.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin==0.0):\n                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n                        \nprint(\"Number of passenger with family\/group survival information: \" \n      +str(data_df[data_df['Family_Survival']!=0.5].shape[0]))\n\n# # Family_Survival in TRAIN_DF and TEST_DF:\ntrain_data['Family_Survival'] = data_df['Family_Survival'][:891]\ntest_data['Family_Survival'] = data_df['Family_Survival'][891:]","03585e2b":"train_data.drop('Name',axis=1,inplace=True)\ntest_data.drop('Name',axis=1,inplace=True)\ncombine = [train_data, test_data]","973a3338":"print(\"\u5904\u7406\u524d\", train_data.shape, test_data.shape, combine[0].shape, combine[1].shape)\n\ntrain_data = train_data.drop(['Ticket', 'Cabin','PassengerId'], axis=1)\ntest_data = test_data.drop(['Ticket', 'Cabin','PassengerId'], axis=1)\n\n\ncombine = [train_data, test_data]\n\nprint(\"\u5904\u7406\u540e\", train_data.shape, test_data.shape, combine[0].shape, combine[1].shape)","e030c572":"# train_data = train_data.drop(['Parch', 'SibSp', 'Familysize'], axis=1)\n# test_data = test_data.drop(['Parch', 'SibSp', 'Familysize'], axis=1)\n\ntrain_data = train_data.drop(['Parch', 'SibSp'], axis=1)\ntest_data = test_data.drop(['Parch', 'SibSp'], axis=1)\n\ncombine = [train_data, test_data]\n\ntrain_data.head()","69389b70":"train_data['Embarked']=train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])","35951b66":"train_data.head()","2e6214c5":"test_data.head()","5f8de1b0":"train = pd.get_dummies(train_data)\ntest = pd.get_dummies(test_data)","be8a9ab1":"test.head()","e1ab8355":"train.head()","ca2e2421":"warnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","678e63db":"from sklearn.model_selection import KFold\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics","0a3eb7a2":"ntrain=train_data.shape[0]\nntest=test_data.shape[0]\nnsplits=10\nrandom_seed=0\n\ncv_split =KFold(n_splits=nsplits,shuffle=False,random_state=random_seed)\n# cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) \n\nprint('ntrain: ',ntrain)\nprint('ntest: ',ntest)","a68848de":"oof_test_skf = np.empty((nsplits, ntest))\noof_test_skf.shape","41ba7837":"# from sklearn.preprocessing import StandardScaler\n\n# std_scaler = StandardScaler()\n# x_train = std_scaler.fit_transform(train.drop('Survived',axis=1))\n# x_test = std_scaler.transform(test)","da9480b4":"y_train=train['Survived']\nx_train=train.drop('Survived',axis=1)\nx_test=test","07de4d6f":"MLA=[\n    # Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.RandomForestClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    \n    # Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    # GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    # Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #SVM\n    svm.LinearSVC(),\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    \n    # Trees\n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    # Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n    \n    # Xgboost\n    XGBClassifier()\n    \n    \n]","fc71d21e":"tt=pd.DataFrame(columns=['p'])\ntt['p']=ensemble.AdaBoostClassifier().get_params()\ntt","d526e8e3":"type(train_data[['Survived']].head())","b4a46978":"type(train_data['Survived'].head())","4e50e0e2":"MLA_columns=['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare=pd.DataFrame(columns=MLA_columns)\n\n# 1\u3001\u4e4b\u524d\u8fd9\u91cc\u6ca1\u6709\u52a0deepcopy\uff0c\u5728 MLA_predict[MLA_name]=alg.predict(x_train) \u8fd9\u6b65\u4e2d\u76f4\u63a5\u4fee\u6539\u4e86 y_train\u7684\u6570\u636e\uff0c\u56e0\u4e3a\u4e4b\u524d\u6211\u4eec\u7684y_train\u4e5f\u662f\u7b49\u4e8etrain_data['Survived']\n# 2\u3001train_data[['Survived']] \u548c train_data['Survived'] \u8f93\u51fa\u7684\u7ed3\u679c\u662f\u4e0d\u540c\u7684\uff0c\n# type(train_data[['Survived']].head())\u662fdf\uff0ctype(train_data['Survived'].head())\u662fserise\n\nMLA_predict=train_data[['Survived']].copy(deep=True)\n\n\nfor row_index,alg in enumerate(MLA):\n#     print('row_index: ',row_index)\n    MLA_name=alg.__class__.__name__\n    MLA_compare.loc[row_index,'MLA Name']=MLA_name\n    ''' alg.get_params() type \u662f\u4e00\u500b\u5b57\u5178 \u6211\u4eec\u5c06\u5176\u8f6c\u5316\u4e3astr\uff0cdf\u884c\u4e2d\u4e2d\u4e0d\u80fd\u76f4\u63a5\u5b58\u50a8dict\uff0c\u5b57\u5178\u4e2d\u7684\u6bcf\u4e00\u4e2ak,v\u4f1a\u5b58\u50a8\u4e00\u884c'''\n    MLA_compare.loc[row_index,'MLA Parameters']=str(alg.get_params())\n    cv_result=model_selection.cross_validate(alg,x_train,y_train,cv=cv_split)\n\n#     print(cv_result['test_score'])\n    MLA_compare.loc[row_index,'MLA Test Accuracy Mean']=cv_result['test_score'].mean()    \n    MLA_compare.loc[row_index,'MLA Test Accuracy 3*STD']=cv_result['test_score'].std()*3   \n    MLA_compare.loc[row_index,'MLA Time']=cv_result['fit_time'].mean()\n    \n    alg.fit(x_train,y_train)\n    # \u56e0\u4e3a\u8fd9\u6837\u6211\u4eec\u8981\u65b0\u5efa\u4e00\u5217\u6a21\u578b\u9884\u6d4b\u7684\u6570\u636e\uff0c\u6240\u4ee5\u6211\u4eec\u5fc5\u987b\u8981\u5728\u4e0a\u9762\u7684train_data[['Survived']] \u4e2d\u8bb0\u5f97\u8fd9\u662f\u4e00\u4e2a\u53cc\u62ec\u53f7\uff0c\n    # \u5426\u5219\u90a3\u4e48\u6211\u4eec\u5c31\u662f\u5728series\u4e2d\u62fc\u63a5,\u5176\u5b9e\u662f\u62fc\u4e0d\u8fdb\u53bb\u7684\n    MLA_predict[MLA_name]=alg.predict(x_train)\n\nMLA_compare.sort_values(by='MLA Test Accuracy Mean',ascending=False,inplace=True)\nMLA_compare","1c233184":"MLA_predict.head()","64b85201":"# \u8981\u8bbe\u7f6esns\u7684\u753b\u5e03\u5927\u5c0f\uff0c\u8981\u5728\u6700\u524d\u9762\u5b9a\u4e49\u597dplt.figure(figsize)\nplt.figure(figsize=(15,12))\nsns.barplot(x='MLA Test Accuracy Mean',y='MLA Name',data=MLA_compare,color='m')\n\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","9d675169":"dtree=tree.DecisionTreeClassifier(random_state=0)\nbase_results=model_selection.cross_validate(dtree,x_train,y_train,cv=cv_split)\ndtree.fit(x_train,y_train)\n\nprint('BEFORE DT Parameters: ',dtree.get_params())\n\nprint('BEFORE DT Test w\/bin score mean: {:.2f}'.format(base_results['test_score'].mean()*100))\nprint('BEFORE DT Test w\/bin score 3*std: +\/- {:.2f}'.format(base_results['test_score'].std()*3))\nprint('\\n')\n\nparam_grid={'criterion':['gini','entropy'],\n            'max_depth':[2,4,6,8,10,None],\n            'random_state':[0]}\n\ntune_model=model_selection.GridSearchCV(estimator=dtree,param_grid=param_grid,scoring='roc_auc',cv=cv_split)\ntune_model.fit(x_train,y_train)\n\nprint('AFTER DT Parameters: ',tune_model.best_params_)\n'''[mean_train_score,mean_test_score,std_test_score] \u8fd9\u4e9b\u952e\u90fd\u662f\u5728 cv_results_ \u4e2d\u7684key\uff0c\n\u901a\u8fc7\u540e\u9762\u8ddf[tune_model.best_index_]\u7d22\u5f15\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u76f8\u5e94key\u7684values'''\n\nprint('AFTER DT Test w\/bin score mean: {:.2f}'.format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint('AFTER DT Test w\/bin score 3*std: +\/- {:.2f}'.format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))","bbf0a68c":"print('BEFORE DT Shape: ',x_train.shape)\n# print('BEFORE DT Columns: ',x_train.columns)\n\n\nprint('BEFORE DT Test w\/bin score mean: {:.2f}'.format(base_results['test_score'].mean()*100))\nprint('BEFORE DT Test w\/bin score 3*std: +\/- {:.2f}'.format(base_results['test_score'].std()*3))\nprint('\\n')\n\n\ndtree_rfe=feature_selection.RFECV(dtree,step=1,scoring='accuracy',cv=cv_split)\ndtree_rfe.fit(x_train,y_train)\n\n# \u91cd\u8981\u7684\u7279\u5f81\u4f1a\u5728\u8fd9\u4e2a\u7279\u5f81\u7684\u6240\u5728\u4f4d\u7f6e\u6807\u5fd7\u4e3aTrue\uff0c\u4e0d\u91cd\u8981\u7684\u6807\u5fd7False\nx_rfe=x_train.columns.values[dtree_rfe.get_support()]\nrfe_result=model_selection.cross_validate(dtree,x_train[x_rfe],y_train,cv=cv_split)\n\nprint('AFTER  DT REF Shape: ',x_train[x_rfe].shape)\nprint('AFTER  DT REF Columns: ',x_rfe)\n\n\nprint('AFTER  DT REF Test w\/bin score mean: {:.2f}'.format(rfe_result['test_score'].mean()*100))\nprint('AFTER  DT REF Test w\/bin score 3*std: +\/- {:.2f}'.format(rfe_result['test_score'].std()*3))\nprint('\\n')\n\n\n# \u6700\u4f18\u5316\u53c2\u6570\nrfe_tune_model=model_selection.GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='roc_auc',cv=cv_split)\nrfe_tune_model.fit(x_train[x_rfe],y_train)\n\nprint('AFTER  DT REF Tune Shape: ',x_train[x_rfe].shape)\nprint('AFTER  DT REF Tune Columns: ',x_rfe)\n\n\nprint('AFTER  DT REF Tune Test w\/bin score mean: {:.2f}'.format(rfe_tune_model.cv_results_['mean_test_score'][rfe_tune_model.best_index_]*100))\nprint('AFTER  DT REF Tune Test w\/bin score 3*std: +\/- {:.2f}'.format(rfe_tune_model.cv_results_['std_test_score'][rfe_tune_model.best_index_]*100))","39beca10":"reduce_feature=x_train[x_rfe]","9953400a":"dtree_p=rfe_tune_model.predict(x_test[x_rfe])","45699f2d":"submit_data=pd.DataFrame({'passengerId':passengerId,'Survived':dtree_p})\nsubmit_data.to_csv(\"StackingSubmission.csv\", index=False)\nsubmit_data[submit_data['Survived']==0].count()","1bb8babc":"def correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)","d2fb7ad2":"correlation_heatmap(MLA_predict)","756e59b6":"vote_est = [\n    \n    #Ensemble Methods: http:\/\/scikit-learn.org\/stable\/modules\/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n\n    #Gaussian Processes: http:\/\/scikit-learn.org\/stable\/modules\/gaussian_process.html#gaussian-process-classification-gpc\n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    \n    #GLM: http:\/\/scikit-learn.org\/stable\/modules\/linear_model.html#logistic-regression\n    ('lr', linear_model.LogisticRegressionCV()),\n    \n    #Navies Bayes: http:\/\/scikit-learn.org\/stable\/modules\/naive_bayes.html\n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gsb', naive_bayes.GaussianNB()),\n    \n    #Nearest Neighbor: http:\/\/scikit-learn.org\/stable\/modules\/neighbors.html\n    ('knn', neighbors.KNeighborsClassifier()),\n    \n    #SVM: http:\/\/scikit-learn.org\/stable\/modules\/svm.html\n    ('svc', svm.SVC(probability=True)),\n    \n    #xgboost: http:\/\/xgboost.readthedocs.io\/en\/latest\/model.html\n   ('xgb', XGBClassifier())\n\n]","099c76dd":"grid_n_estimators=[1,10,50,100,300,500]\ngrid_ratio=[.01,.1,.25,.50,.75,1.0]\ngrid_learn = [.001,.01, .03, .05, .1, .25]\ngrid_max_depth = [2, 4, 6, 8, 10, None]\ngrid_min_samples = [5, 10, .03, .05, .10]\ngrid_criterion = ['gini', 'entropy']\ngrid_bool = [True, False]\ngrid_seed = [0]\ngrid_min_samples_leaf=[1,2,3,4,6]\n\n\ngrid_params=[\n    [{\n        # AdaboostClassifier() https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.AdaBoostClassifier.html\n        # The beast parameter for AdaBoostClassifier is {'learning_rate': 0.25, 'n_estimators': 50, 'random_state': 0} with runtime of 34.45 secounds\n        'n_estimators': [100],\n        'learning_rate': [0.25],\n        # algorithm \uff1a {'SAMME'\uff0c'SAMME.R'}\uff0c\u53ef\u9009\uff08\u9ed8\u8ba4='SAMME.R'\uff09 \u9009\u62e9\u4f7f\u7528\u4ec0\u4e48\u7b97\u6cd5\n        'algorithm':['SAMME.R'],       # 'algorithm':['SAMME','SAMME.R'],\n        'random_state':grid_seed\n    }],\n    \n    [{\n        # BaggingClassifier() https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.BaggingClassifier.html\n#         The beast parameter for BaggingClassifier is {'max_features': 1.0, 'max_samples': 0.75, 'n_estimators': 300, 'random_state': 0} with runtime of 176.11 secounds\n        'n_estimators':[300],\n        # max_samples \uff1a int\u6216float\uff0coptional\uff08default = 1.0\uff09\u4eceX\u4e2d\u62bd\u53d6\u7684\u6837\u672c\u6570\u91cf\uff0c\u7528\u4e8e\u8bad\u7ec3\u6bcf\u4e2a\u57fa\u672c\u4f30\u7b97\u5668\u3002float\u767e\u5206\u6bd4\u548cint\u6837\u672c\u4e2a\u6570\n        'max_samples':[0.75],\n        # \u4eceX\u4e2d\u7ed8\u5236\u4ee5\u8bad\u7ec3\u6bcf\u4e2a\u57fa\u672c\u4f30\u7b97\u5668\u7684\u7279\u5f81\u6570\u3002\n        'max_features':[1.0],\n        'random_state':grid_seed\n    }],\n    \n    [{\n        # ExtraTreesClassifier() https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.ExtraTreesClassifier.html\n#       The beast parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 6, 'max_features': 1.0, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': 0} with runtime of 473.37 secounds\n        'n_estimators': [100],\n        # Supported criteria are \u201cgini\u201d for the Gini impurity and \u201centropy\u201d for the information gain. \u57fa\u5c3c\u7cfb\u6570\u548c\u4fe1\u606f\u71b5\n        'criterion': ['entropy'],\n        'max_depth': [6],\n        # \u6700\u5927\u7279\u5f81\u4e2a\u6570 \u522b\u8d85\u8fc7\u73b0\u6709\u7279\u5f81\u6570\n        'max_features': [1.0],\n        'min_samples_split': [2],\n        'min_samples_leaf': [3],\n        'random_state': grid_seed\n    }],\n    \n    [{\n        # GradientBoostingClassifier () https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingClassifier.html\n        # The beast parameter for GradientBoostingClassifier is \n        # {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with runtime of 336.92 secounds\n#         The beast parameter for GradientBoostingClassifier is {'learning_rate': 0.1, 'max_depth': 8, 'max_features': 0.1, 'min_samples_leaf': 3, 'n_estimators': 50, 'random_state': 0} with runtime of 0.84 secounds\n        'n_estimators': [300],\n        'learning_rate': [0.1],\n#         'criterion':['friedman_mse','mse','mae'] , # default friedman_mse\n        'max_depth': [2],      \n        'random_state': grid_seed,\n        'max_features': [.1],        #'max_features': [.1, .3, 1.0],\n        'min_samples_leaf': [3],\n    }],    \n    \n        [{\n        # RandomForestClassifier () https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html\n#         The beast parameter for RandomForestClassifier is {'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 100, 'random_state': 0} with runtime of 111.59 secounds\n        'n_estimators': [100],\n#         'criterion': grid_criterion,     # default=\u201dgini\u201d\n        'max_depth': [6],\n        'random_state': grid_seed,\n        'min_samples_leaf':[2],\n        'max_features':['sqrt'],        # 'max_features':['sqrt','log2'],\n\n    }],    \n    \n    [{\n        # GaussianProcessClassifier () https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.gaussian_process.GaussianProcessClassifier.html\n        # The beast parameter for GaussianProcessClassifier is {'copy_X_train': True, 'max_iter_predict': 10, 'n_restarts_optimizer': 0, 'random_state': 0, 'warm_start': True} with runtime of 153.60 secounds\n\n        # max_iter_predict \u725b\u987f\u65b9\u6cd5\u4e2d\u7528\u4e8e\u8fd1\u4f3c\u9884\u6d4b\u671f\u95f4\u540e\u9a8c\u7684\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002\u8f83\u5c0f\u7684\u503c\u5c06\u4ee5\u66f4\u5dee\u7684\u7ed3\u679c\u4e3a\u4ee3\u4ef7\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002\n        'max_iter_predict': [10],\n        'n_restarts_optimizer':[0],\n        'warm_start':[True],\n        'copy_X_train':[True],\n        'random_state': grid_seed\n    }],    \n    \n    [{\n        # LogisticRegressionCV - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegressionCV.html\n#         The beast parameter for LogisticRegressionCV is {'fit_intercept': True, 'max_iter': 50, 'random_state': 0, 'solver': 'saga'} with runtime of 28.37 secounds\n        # fit_intercept \u6307\u5b9a\u662f\u5426\u5e94\u5c06\u5e38\u91cf\uff08\u4e5f\u79f0\u4e3a\u504f\u5dee\u6216\u622a\u8ddd\uff09\u6dfb\u52a0\u5230\u51b3\u7b56\u51fd\u6570\u4e2d\u3002\n        'fit_intercept': [True], #default: True\n        'penalty': ['l1','l2'],\n        # solver \u7528\u4e8e\u4f18\u5316\u95ee\u9898\u7684\u7b97\u6cd5\u3002\n        'solver': ['saga'], #default: lbfgs , 'solver': 'newton-cg', 'lbfgs', 'sag', 'saga']\n#         'penalty': ['l1','l2','elasticnet'],\n        'max_iter':[50],\n#         'multi_class':['ovr','multinomial','auto'],\n        'random_state': grid_seed\n     }],\n\n\n        [{\n        # BernoulliNB - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.naive_bayes.BernoulliNB.html\n        'fit_prior':grid_bool,\n        # alpha \uff08\u62c9\u666e\u62c9\u65af\/ Lidstone\uff09\u5e73\u6ed1\u53c2\u6570\uff080\u8868\u793a\u65e0\u5e73\u6ed1\uff09\u3002\n        'alpha': grid_ratio, #default: 1.0\n     }],\n\n\n        # GaussianNB  \n        [{}],\n\n        [{\n        #KNeighborsClassifier - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html\n#       The beast parameter for KNeighborsClassifier is {'algorithm': 'brute', 'leaf_size': 1, 'n_neighbors': 5, 'weights': 'uniform'} with runtime of 49.16 secounds\n        'leaf_size':[1],\n        'n_neighbors': [5], # default: 5 \u9ed8\u8ba4\u60c5\u51b5\u4e0bkneighbors\u67e5\u8be2\u4f7f\u7528\u7684\u90bb\u5c45\u6570\u3002\n        'weights': ['uniform'], # default = \u2018uniform\u2019\u7528\u4e8e\u9884\u6d4b\u7684\u6743\u91cd\u51fd\u6570 'weights': ['uniform', 'distance']\n        'algorithm': ['brute'] # \u7528\u4e8e\u8ba1\u7b97\u6700\u8fd1\u90bb\u5c45\u7684\u7b97\u6cd5\uff1a'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'] \n    }],\n\n\n        [{\n        #SVC - http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html\n        #http:\/\/blog.hackerearth.com\/simple-tutorial-svm-parameter-tuning-python-r\n#         The beast parameter for SVC is {'C': 1, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'probability': True, 'random_state': 0, 'shrinking': True} with runtime of 5.04 secounds\n#         'C': [1,2,3,4,5], #default=1.0 \u60e9\u7f5a\u53c2\u6570\n        'C': [2], #default=1.0 \u60e9\u7f5a\u53c2\u6570\n        'gamma': [0.0001], # default: auto \n#         'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n        'decision_function_shape': ['ovo'], #default:ovr\n        'probability': [True], # \u662f\u5426\u542f\u7528\u6982\u7387\u4f30\u8ba1 default\uff1aFalse\n        'shrinking':[True],\n        'random_state': grid_seed\n     }],\n\n\n    [{\n        #XGBClassifier - http:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html\n        # {'colsample_bytree': 1.0, 'learning_rate': 0.25, 'max_depth': 8, 'n_estimators': 100, 'seed': 0, 'subsample': 0.3} with runtime of 2127.47 secounds\n        'learning_rate': [0.25], #default: .3\n        'max_depth': [8], #default 2\n        'n_estimators': grid_n_estimators, \n        'subsample':[.3],\n        'colsample_bytree':[1.0],\n        'seed': grid_seed  \n     }]   \n    \n]","9c9502d3":"MLA_columns2=['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare2=pd.DataFrame(columns=MLA_columns2)\n\n# 1\u3001\u4e4b\u524d\u8fd9\u91cc\u6ca1\u6709\u52a0deepcopy\uff0c\u5728 MLA_predict[MLA_name]=alg.predict(x_train) \u8fd9\u6b65\u4e2d\u76f4\u63a5\u4fee\u6539\u4e86 y_train\u7684\u6570\u636e\uff0c\u56e0\u4e3a\u4e4b\u524d\u6211\u4eec\u7684y_train\u4e5f\u662f\u7b49\u4e8etrain_data['Survived']\n# 2\u3001train_data[['Survived']] \u548c train_data['Survived'] \u8f93\u51fa\u7684\u7ed3\u679c\u662f\u4e0d\u540c\u7684\uff0c\n# type(train_data[['Survived']].head())\u662fdf\uff0ctype(train_data['Survived'].head())\u662fserise\n\nMLA_predict2=train_data[['Survived']].copy(deep=True)\n\nstart_time=time.perf_counter()\n\nfor row_index,(clf,params) in enumerate(zip(vote_est,grid_params)):\n    one_model_start_time=time.perf_counter()\n    \n    best_model=model_selection.GridSearchCV(estimator=clf[1],param_grid=params,scoring='roc_auc',cv=cv_split)\n    \n    \"\"\"\u9009\u62e9\u662f\u5426\u4f7f\u7528\u7279\u5f81\u9009\u62e9\u4e4b\u540e\u7684\u7279\u5f81\"\"\"\n    best_model.fit(x_train,y_train)\n#     best_model.fit(reduce_feature,y_train)\n\n    end_time=time.perf_counter()-one_model_start_time\n    best_params=best_model.best_params_\n    print('The beast parameter for {} is {} with runtime of {:.2f} secounds'.format(clf[1].__class__.__name__,best_params,end_time))\n    \n    # *********************************************\n    MLA_name=clf[1].__class__.__name__\n    MLA_compare2.loc[row_index,'MLA Name']=MLA_name\n    ''' alg.get_params() type \u662f\u4e00\u500b\u5b57\u5178 \u6211\u4eec\u5c06\u5176\u8f6c\u5316\u4e3astr\uff0cdf\u884c\u4e2d\u4e2d\u4e0d\u80fd\u76f4\u63a5\u5b58\u50a8dict\uff0c\u5b57\u5178\u4e2d\u7684\u6bcf\u4e00\u4e2ak,v\u4f1a\u5b58\u50a8\u4e00\u884c'''\n    MLA_compare2.loc[row_index,'MLA Parameters']=str(clf[1].get_params())\n    \n    \"\"\"\u9009\u62e9\u662f\u5426\u4f7f\u7528\u7279\u5f81\u9009\u62e9\u4e4b\u540e\u7684\u7279\u5f81\"\"\"\n    cv_result2=model_selection.cross_validate(clf[1],x_train,y_train,cv=cv_split)\n#     cv_result2=model_selection.cross_validate(clf[1],reduce_feature,y_train,cv=cv_split)\n\n\n\n#     print(cv_result['test_score'])\n    MLA_compare2.loc[row_index,'MLA Test Accuracy Mean']=cv_result2['test_score'].mean()    \n    MLA_compare2.loc[row_index,'MLA Test Accuracy 3*STD']=cv_result2['test_score'].std()*3   \n    MLA_compare2.loc[row_index,'MLA Time']=cv_result2['fit_time'].mean()\n    \n    \"\"\"\u9009\u62e9\u662f\u5426\u4f7f\u7528\u7279\u5f81\u9009\u62e9\u4e4b\u540e\u7684\u7279\u5f81\"\"\"\n    clf[1].fit(x_train,y_train)\n#     clf[1].fit(reduce_feature,y_train)\n\n    # \u56e0\u4e3a\u8fd9\u6837\u6211\u4eec\u8981\u65b0\u5efa\u4e00\u5217\u6a21\u578b\u9884\u6d4b\u7684\u6570\u636e\uff0c\u6240\u4ee5\u6211\u4eec\u5fc5\u987b\u8981\u5728\u4e0a\u9762\u7684train_data[['Survived']] \u4e2d\u8bb0\u5f97\u8fd9\u662f\u4e00\u4e2a\u53cc\u62ec\u53f7\uff0c\n    # \u5426\u5219\u90a3\u4e48\u6211\u4eec\u5c31\u662f\u5728series\u4e2d\u62fc\u63a5,\u5176\u5b9e\u662f\u62fc\u4e0d\u8fdb\u53bb\u7684\n    \n    \"\"\"\u9009\u62e9\u662f\u5426\u4f7f\u7528\u7279\u5f81\u9009\u62e9\u4e4b\u540e\u7684\u7279\u5f81\"\"\"\n    MLA_predict2[MLA_name]=clf[1].predict(x_train)\n#     MLA_predict2[MLA_name]=clf[1].predict(reduce_feature)\n\n    # **********************************************\n\n    # \u6700\u91cd\u8981\u7684\u4e00\u6b65\uff0c\u8bbe\u7f6e\u6a21\u578b\u53c2\u6570\u4e3a\u6700\u4f18\u53c2\u6570\n    clf[1].set_params(**best_params)\n    \ntotal_time=time.perf_counter()-start_time\nprint('Total optimization time was {:.2f} minutes'.format(total_time\/60))\n\nMLA_compare2.sort_values(by='MLA Test Accuracy Mean',ascending=False,inplace=True)\nMLA_compare2","b7576ca4":"grid_hard = ensemble.VotingClassifier(estimators = vote_est  , voting = 'hard')\ngrid_hard_cv = model_selection.cross_validate(grid_hard, x_train,y_train, cv  = cv_split)\ngrid_hard.fit(x_train,y_train)\n\n\nprint(\"Hard Voting w\/Tuned Hyperparameters Test w\/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting w\/Tuned Hyperparameters Test w\/bin score 3*std: +\/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\nprint('-'*10)\n\n#Soft Vote or weighted probabilities w\/Tuned Hyperparameters\ngrid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\ngrid_soft_cv = model_selection.cross_validate(grid_soft, x_train,y_train, cv  = cv_split)\ngrid_soft.fit(x_train,y_train)\n\n\nprint(\"Soft Voting w\/Tuned Hyperparameters Test w\/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting w\/Tuned Hyperparameters Test w\/bin score 3*std: +\/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\nprint('-'*10)","22e63790":"predictions= grid_hard.predict(x_test)\nsubmit_data=pd.DataFrame({'passengerId':passengerId,'Survived':predictions})\nsubmit_data[submit_data['Survived']==0].count()","dfb7c74d":"submit_data.to_csv(\"StackingSubmission.csv\", index=False)","a5b20744":"__Age__ __Pclass__ \u548c __Survived__ \u7684\u5173\u7cfb\u5c55\u793a\u56fe","f9d340ce":"\u8bad\u7ec3\u6570\u636e\u4e2d __Embarked__ \u5b58\u5728 2\u4e2a \u7f3a\u5931\u503c\uff0c\u6211\u4eec\u9009\u62e9\u6700\u5e38\u89c1\u7684\u503c\u8fdb\u884c\u586b\u5145","7992989c":"#### \u9009\u62e9\u4e00\u4e9b\u6a21\u578b\u8fdb\u884c\u521d\u59cb\u5316","37cfff0c":"### \u4f7f\u7528\u521d\u59cb\u5316\u53c2\u6570\uff0c\u8fdb\u884c\u6a21\u578b\u9884\u6d4b\uff0c\u67e5\u770b\u6a21\u578b\u7684\u51c6\u786e\u7387","7a327c66":"__Age__ \u548c __Survived__ \u7684\u5173\u7cfb\u5c55\u793a\u56fe","6fd3a268":"\u5220\u9664 __Ticket__\u3001__Cabin__\uff0c__PassengerId__ \u4e09\u4e2a\u7279\u5f81\uff0c\u56e0\u4e3a\u7968\u53f7\u6ca1\u6709\u5b9e\u9645\u7684\u610f\u4e49\uff0c\u6211\u4eec\u5df2\u7ecf\u7528\u5b83\u6765\u5e2e\u52a9\u6211\u4eec\u63a8\u7406\u4e86 __Family_Survival__ ,\u8fd9\u91cc\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u5220\u9664\uff0c\u540c\u65f6\u56e0\u4e3a __Cabin__ \u7684\u7f3a\u5931\u503c\u592a\u591a\uff0c\u6211\u4eec\u8fd9\u91cc\u4e0d\u6253\u7b97\u8fdb\u884c\u8865\u5145\uff0c\u5982\u679c\u5f3a\u884c\u501f\u7528\u6d4b\u8bd5\u96c6\u6570\u636e\u8865\u5145\u53ef\u80fd\u6216\u9020\u6210\u6570\u636e\u6cc4\u9732","8ca5a787":"\u63a5\u4e0b\u6765\u6211\u4eec\u5c06__SibSp__ \u548c __Parch__ \u8fd92\u4e2a\u7279\u5f81\u5220\u9664","09b7768b":"#### df.describe(include=['O']) \u53ef\u4ee5\u5e2e\u6211\u4eec\u8ba1\u7b97\u51fa\u975e\u6570\u5b57\u5217\u7684\u4e00\u4e9b\u5185\u5bb9","19e690a3":"__Parch__ \u548c __Survived__ \u4e4b\u95f4\u7684\u5173\u7cfb","d4090e4c":"### \u53ef\u89c6\u5316\u5c55\u793a\u7279\u5f81\u548cSurviced\u4e4b\u95f4\u7684\u5173\u7cfb","38beec19":"# \u7279\u5f81\u5de5\u7a0b\n\n\u8bf7\u6ce8\u610f\uff0c\u5728\u9002\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u540c\u65f6\u5bf9\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u6267\u884c\u64cd\u4f5c\u4ee5\u4fdd\u6301\u4e00\u81f4\u3002","4e53568a":"### \u6295\u7968\u9884\u6d4b","0193ac49":"\u63a5\u4e0b\u6765\u6211\u4eec\u5c06 __Age__ \u8fdb\u884c\u5207\u5206\uff0c\u56e0\u4e3a\u6211\u4eec\u60f3\u5230\u8fbe\u5230\u7684\u6548\u679c\u662f\uff1a \u662f\u5426\u4f1a\u968f\u7740\u5e74\u7eaa\u7684\u589e\u52a0\u5f71\u54cd\u5b58\u6d3b\u7387\uff0c\u6240\u4ee5\u6211\u4eec\u6ca1\u6709\u5fc5\u8981\u4fdd\u7559\u539f\u6765\u7684\u503c\uff0c\u4fdd\u7559\u7684\u8bdd\u6070\u6070\u4f1a\u7559\u4e0b\u566a\u97f3","d9b03232":"\u63a5\u4e0b\u6765\u540c\u6837\u8fdb\u884c\u7f16\u7801","0f39272f":"#### \u67e5\u770b\u6570\u636e\u7684\u57fa\u672c\u4fe1\u606f\n    \n    \u6211\u4eec\u53ef\u4ee5\u770b\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u7684 Age\uff0cCabin,Embarked \u5b58\u5728\u7f3a\u5931\u503c\n    \n    \u8bad\u6d4b\u8bd5\u636e\u4e2d\u7684 Age\uff0cCabin,Fare \u5b58\u5728\u7f3a\u5931\u503c","f482bf58":"\u589e\u52a0\u65b0\u7684\u7279\u5f81 __Family_size__ \u548c __Family_Survival__","598ad6c1":"\u5220\u9664 __Farecut__ \u7279\u5f81","82e47c1b":"### \u521d\u59cb\u5316\u6a21\u578b","a0477da2":"\u6309\u7167 __Ticket\uff08\u7968\u53f7\uff09__ \u8fdb\u884c\u8bbe\u7f6e __Family_Survival__ \u7684\u53d6\u503c,\u56e0\u4e3a\u6211\u4eec\u6000\u7591\u5b58\u6d3b\u7387\u548c\u7968\u53f7\u6709\u5173 __\u6709\u7684\u4eba\u62e5\u6709\u76f8\u540c\u7684\u7968\u53f7__","8d6ee675":"\u65b0\u7684\u7279\u5f81 __Family_size__ \u4f7f\u7528  Parch + SibSp","a858447d":"__Pclass__ \u548c __Survived__ \u7684\u5173\u7cfb\u5c55\u793a\u56fe","40566802":"\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u8bed\u4e49\u76f8\u8fd1\u7684\u5934\u8854\u8fdb\u884c\u5408\u5e76,\u67e5\u770b\u5934\u8854\u548c\u751f\u5b58\u7387\u4e4b\u95f4\u5b58\u5728\u7684\u5173\u7cfb","95ebbc91":"### \u901a\u8fc7GridSearchCV\u5bfb\u627e\u6700\u4f18\u5316\u53c2\u6570","3d15f639":"\u5220\u9664 __Name__ \u7279\u5f81","605b6767":"# \u96c6\u6210\u6a21\u578b & \u5806\u53e0\u6a21\u578b","36029a73":"\u63a5\u7740\u6211\u4eec\u5c06Fare\u5212\u5206\u4e3a4\u4e2a\u7b49\u7ea7\uff0c\u76ee\u7684\u4e5f\u662f\u4e3a\u4e86\u964d\u566a,\u53ef\u4ee5\u8bd5\u4e00\u4e0b\u5206\u4e3a\u4e94\u4e2a\u7b49\u7ea7\uff0c\u6211\u4eec\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u4f1a\u6709\u4e00\u9879 Farecut \u7684 Survived \u4e3a Nan","c25cbb16":"__Sex__ \u548c __Survived__ \u4e4b\u95f4\u7684\u5173\u7cfb","fb258e84":"### \u7279\u5f81\u9009\u62e9\n    \u4ee5DT\u4e3a\u4f8b\u8fdb\u884c\u7279\u5f81\u9009\u62e9","535e7afa":" The beast parameter for AdaBoostClassifier is {'learning_rate': 0.05, 'n_estimators': 300, 'random_state': 0} with runtime of 39.97 secounds\n\n The beast parameter for BaggingClassifier is {'max_samples': 0.1, 'n_estimators': 300, 'random_state': 0} with runtime of 35.60 secounds\n\n The beast parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 300, 'random_state': 0} with runtime of 80.14 secounds\n\n The beast parameter for GradientBoostingClassifier is {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with runtime of 336.92 secounds\n\n The beast parameter for RandomForestClassifier is {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 300, 'random_state': 0} with runtime of 82.48 secounds\n\n The beast parameter for GaussianProcessClassifier is {'max_iter_predict': 10, 'random_state': 0} with runtime of 22.09 secounds\n\nThe beast parameter for LogisticRegressionCV is {'fit_intercept': True, 'random_state': 0, 'solver': 'newton-cg'} with runtime of 8.14 secounds\n\nThe beast parameter for BernoulliNB is {'alpha': 0.75} with runtime of 0.24 secounds\n\n The beast parameter for GaussianNB is {} with runtime of 0.05 secounds\n\n The beast parameter for KNeighborsClassifier is {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'} with runtime of 8.13 secounds\n\n The beast parameter for SVC is {'C': 1, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'probability': True, 'random_state': 0} with runtime of 35.65 secounds\n\n The beast parameter for XGBClassifier is {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 100, 'seed': 0} with runtime of 156.16 secounds\n \nTotal optimization time was 32.75 minutes","d3cf3514":"#### \u63a5\u4e0b\u6765\u5bf9 SibSp \u548c Parch  \u8fdb\u884c\u64cd\u4f5c\n\u63a5\u4e0b\u6765\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 __Familysize__ \u7279\u5f81\u7528\u4e8e\u8868\u793a\u4e58\u8239\u4e58\u5ba2\u5e26\u7684\u5bb6\u5c5e\u6570\u91cf\uff0c\u4ece\u800c\u66ff\u4ee3 __SibSp__\uff08\u6cf0\u5766\u5c3c\u514b\u53f7\u4e0a\u7684\u5144\u5f1f\u59d0\u59b9\/\u914d\u5076\uff03\uff09 \u548c __Parch__\uff08\u6cf0\u5766\u5c3c\u514b\u53f7\u4e0a\u7684\u7236\u6bcd\/\u5b69\u5b50\u4eec\uff09 \u8fd9\u4e24\u4e2a\u7279\u5f81\n    \n    SibSp \u548c Parch \u5bf9Surviced\u6709\u65e0\u5173\u7cfb\uff1f\u8fd9\u91cc\u6211\u4eec\u770b\u5230\u5f53 Familysize \u503c\u5bf9 Survived \u9020\u6210\u7684\u5f71\u54cd\u597d\u50cf\u662f\u968f\u673a\u7684\u3002","a56f11fc":"#### \u63a5\u4e0b\u6765\u6211\u4eec\u9700\u8981\u5c06\u540d\u5b57\u7b80\u5316\u6210\u59d3\u6c0f\uff0c\u56e0\u4e3a\u6211\u4eec\u4e5f\u6000\u7591\u8fd9\u4e2a\u548c\u5b58\u6d3b\u7387\u6709\u5173\uff0c\u56e0\u4e3a\u540d\u5b57\u57fa\u672c\u4e0a\u90fd\u4e0d\u540c\u6240\u4ee5\u5982\u679c\u4e0d\u5904\u7406\u7684\u8bdd\u5c06\u4f1a\u6709\u5f88\u591a\u566a\u97f3\n\n   \u8fd9\u91cc\u7684 for dataset in combine \u5176\u5b9e\u53ea\u662f\u5faa\u73af\u4e86\u4e24\u6b21\uff0c\u7b2c\u4e00\u6b21\u662ftrain_data \u7b2c\u4e8c\u6b21\u662ftest_data\u6570\u636e\uff0c\u8fd9\u6837\u5176\u5b9e\u4fee\u6539\u7684\u5c31\u662f\u6211\u4eectrain_data\u548ctest_data","c29f02ce":"\u521a\u5f00\u59cb\u9ed8\u8ba4\u8bbe\u7f6e __Family_Survival__ = 0.5\uff0c\u7136\u540e\u6309\u7167 \u5bb6\u5ead(\u59d3\u6c0f)\u8fdb\u884c\u8bbe\u7f6e __Family_Survival__ \u7684\u53d6\u503c,\u56e0\u4e3a\u6211\u4eec\u6000\u7591\u5b58\u6d3b\u7387\u548c\u5bb6\u5ead\u6709\u5173","1820dd04":"\u4e4b\u540e\u6211\u4eec\u5c31\u53ef\u4ee5\u5c06 __Agecut__ \u8fd9\u4e2a\u7279\u5f81\u5220\u9664\u4e86","66e7733d":"__Sex__ \u548c __Survived__ \u4e4b\u95f4\u7684\u5173\u7cfb\u5c55\u793a\u56fe\n\n    .plot.bar() \u8fd9\u91cc\u6211\u4eec\u4e0d\u80fd\u5c06as_index\u8bbe\u4e3aFalse \u4e86","e35bb1e2":"__SibSp__ \u548c __Survived__ \u4e4b\u95f4\u7684\u5173\u7cfb","73edd0f6":"#### \u63a5\u4e0b\u6765\u6211\u4eec\u5bf9 Age\uff0c\u8fdb\u884c\u5206\u7c7b\u64cd\u4f5c\uff0c\u76ee\u7684\u4e5f\u662f\u4e3a\u4e86\u51cf\u5c0f\u566a\u97f3\uff0c\u4f46\u662f\u64cd\u4f5c\u4e4b\u524d\u56e0\u4e3aAge\u5b57\u6bb5\u5b58\u5728\u7f3a\u5931\u503c\uff0c\u6211\u4eec\u5148\u8865\u5145\u7f3a\u5931\u503c\n\n    \u731c\u6d4b\u7f3a\u5931\u503c\u7684\u66f4\u51c6\u786e\u65b9\u6cd5\u662f\u4f7f\u7528\u5176\u4ed6\u76f8\u5173\u7279\u5f81\u3002 \u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u6ce8\u610f\u5230Age\uff0cSex\u548cPclass\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002 ","548548ae":"#### \u5bfb\u627e\u6700\u4f18\u53c2\u6570","264e9350":"#### \u5b9a\u4e49\u597d\u4ea4\u53c9\u9a8c\u8bc1\u51fd\u6570","218b10d3":"\u6d4b\u8bd5\u6570\u636e\u4e2d __Fare__ \u5b58\u5728 1\u4e2a \u7f3a\u5931\u503c\uff0c\u6211\u4eec\u9009\u62e9\u6700\u5e38\u89c1\u7684\u503c\u8fdb\u884c\u586b\u5145","40c2d95b":"__Age__ __Pclass__ __Sex__ \u548c __Survived__ \u7684\u5173\u7cfb\u5c55\u793a\u56fe","4f019299":"#### \u5b9a\u4e49\u53c2\u6570\u8303\u56f4\uff0c\u4f7f\u7528GridSearchCV\u8fdb\u884c\u53c2\u6570\u8c03\u4f18","e9ea84ff":"# \u6570\u636e\u63a2\u7d22","9241d5af":"__Pclass__ \u548c __Survived__ \u4e4b\u95f4\u7684\u5173\u7cfb","be7ea193":"#### \u5bf9\u65e0\u5e8f\u7279\u5f81\u8fdb\u884conehot\u7f16\u7801","9bed30d2":"### \u67e5\u770b\u6a21\u578b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\n    \u53ef\u4ee5\u5b9a\u4e49\u4e00\u4e2a\u70ed\u56fe\u51fd\u6570","c6f6479d":"### \u63a5\u4e0b\u6765\u63a2\u7d22\u7279\u5f81\u548c\u5b58\u6d3b\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\n    \n    as_index=False \u65f6\u4f1a\u81ea\u52a8\u521b\u5efaindex\uff0c\u5426\u5219\u4f7f\u7528\u7b2c\u4e00\u5217\u4f5c\u4e3aindex","b2246129":"#### df\u76f4\u63a5\u5b58\u50a8dict\u7684\u7ed3\u679c","84dd3f52":"\u540e\u9762\u6211\u4eec\u4f1a\u5220\u9664 __Name__ \u8fd9\u4e2a\u7279\u5f81"}}