{"cell_type":{"78fba1c6":"code","e8d2f2cb":"code","e01f4016":"code","91e357f6":"code","021dcd4b":"code","8c2d1819":"code","25460ba4":"code","ed27b67f":"code","fd08b95d":"code","f9b04786":"code","b5e68352":"code","be45c3e2":"code","32b5104a":"code","a814ab6e":"code","1c016015":"code","b50b2105":"code","4a5692e7":"code","75ce0a51":"code","255fda94":"code","1c91cacc":"code","3e8e6fb1":"code","16111593":"code","a45aabd4":"code","17d5cb67":"code","685a3337":"code","ea35a51b":"code","34b6fec7":"code","7bf46dfb":"code","ffedcbc5":"code","b2a3b935":"code","57b808d3":"code","a219208c":"code","3987d615":"code","8d135dc0":"code","0ee09a7f":"markdown","90eb345b":"markdown","495102cc":"markdown","79e65c4c":"markdown","2b6cac47":"markdown","0f559ca3":"markdown","a62b49e4":"markdown","a0c1202d":"markdown","86233d39":"markdown","67ab1694":"markdown"},"source":{"78fba1c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8d2f2cb":"#import the data with the link using pandas library\n\ndata = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","e01f4016":"data.head() #visualizing the first 5 rows of the data in a table","91e357f6":"#getting more information about the data\ndata.info()\n\n#all columns are filled and gender column has the object data","021dcd4b":"# using the describe to get other numerical infromation about the data\n\ndata.describe()\n# we might need to scale the data later","8c2d1819":"import seaborn as sns\nimport matplotlib.pyplot as plt #libraries for visualization","25460ba4":"fig = plt.figure(figsize = (6,5))\n\n# using boxplot gives quick information about the medain, upper&lower quartile,and even outliers in the data\nfor x in data.select_dtypes(np.number).columns:\n    sns.boxplot(x=data[x])\n    plt.show()","ed27b67f":"# for the object column(gender), count plot to sure there isnt bias in the data\n\nsns.countplot(data['Gender'])","fd08b95d":"sns.heatmap(data.corr(), annot= True) #for the numerical correlation\/dependence of a feature and another\n\n#no clear dependence\/correlation of one column on the other","f9b04786":"\nplt.figure(figsize= (10,7))\nsns.scatterplot( x =data['Annual Income (k$)'], y =data['Spending Score (1-100)'],\n                  hue = data[\"Gender\"]) #scatterplot to visualize the relationship between the annual income and the spending score\n","b5e68352":"#scaling the dataset to ensure we are working on the same scale\nfrom sklearn.preprocessing import StandardScaler\n\ndf = data.copy() #creating a copy of the original dataset\ndf_num = df.select_dtypes(np.number) #selecting columns with numerical value\n\nscaler = StandardScaler()\nscaled_df = scaler.fit_transform(df_num) #calling fit transform on the numerical columns of the data. \n#It joins the fit() and transform() method for the transformation of the dataset.\nscaled_df = pd.DataFrame(scaled_df, columns= df_num.columns) #fit_transforming gives back the data in an array,\n#hence you have to make it a dataframe back by calling pd.Dataframe\nscaled_df","be45c3e2":"# converting the gender column to numerical value\n\ndf['Gender'] = df['Gender'].astype('category').cat.codes","32b5104a":"processed_df = pd.concat([scaled_df, df['Gender']], axis=1) #rejoin the two separate columns\nprocessed_df","a814ab6e":"#we will drop the id column as it doesnt really give any use to the model\n\nprocessed_df = processed_df.drop('CustomerID', axis = 1) #axis has to be set to one so it can look for it in the column and not the row","1c016015":"from sklearn.cluster import KMeans\n\n# Create and fit a range of models\nkm_list = list()\n\nfor clust in range(1,11):\n    km = KMeans(n_clusters = clust, random_state=42)\n    km = km.fit(processed_df) #fit the model on the dataset\n    \n    km_list.append(pd.Series({'clusters': clust, \n                              'inertia': km.inertia_,\n                              'model': km}))","b50b2105":"plot_data = (pd.concat(km_list, axis=1)\n             .T\n             [['clusters','inertia']]\n             .set_index('clusters'))\n\nax = plot_data.plot(marker='o',ls='-')\nax.set_xticks(range(0,11,2))\nax.set_xlim(0,11) #the limit of the labels on x_axis\nax.set(xlabel='Cluster', ylabel='Inertia');","4a5692e7":"from scipy.cluster.hierarchy import linkage, dendrogram #import the dendogram and linkage from scipy library\n\n\nplt.figure(figsize= (15,7))\nmerg = linkage(processed_df, method = \"ward\", metric='euclidean')#ward is a type of clustering method,\n#euclidean distance as metrics for clustering\ndendrogram(merg, truncate_mode='lastp')\nplt.xlabel(\"Data Point\")\nplt.ylabel(\"Euclidean Distance\")","75ce0a51":"X = processed_df.drop('Gender', axis = 1)","255fda94":"from sklearn.cluster import AgglomerativeClustering\n\nhc = AgglomerativeClustering(n_clusters = 6, affinity = \"euclidean\", linkage = \"ward\")\ncluster = hc.fit_predict(X) #fit agglom model on the data set\n\nX[\"Label\"] = cluster\n\nsns.scatterplot(X['Annual Income (k$)'], X['Spending Score (1-100)'], hue = X['Label'])","1c91cacc":"def calculate_wcss(X):\n        wcss = []\n        for n in range(2, 21):\n            kmeans = KMeans(n_clusters=n)\n            kmeans.fit(X=X)\n            wcss.append(kmeans.inertia_)\n    \n        return wcss\n","3e8e6fb1":"def optimal_number_of_clusters(wcss):\n    x1, y1 = 2, wcss[0]\n    x2, y2 = 20, wcss[len(wcss)-1]\n\n    distances = []\n    for i in range(len(wcss)):\n        x0 = i+2\n        y0 = wcss[i]\n        numerator = np.abs((y2-y1)*x0 - (x2-x1)*y0 + x2*y1 - y2*x1)\n        denominator = np.sqrt((y2 - y1)**2 + (x2 - x1)**2)\n        distances.append(numerator\/denominator)\n    \n    return distances.index(max(distances)) + 2","16111593":"# calculating the within clusters sum-of-squares for  cluster amounts\nsum_of_squares = calculate_wcss(scaled_df)\n    \n    # calculating the optimal number of clusters\nn = optimal_number_of_clusters(sum_of_squares)\nn","a45aabd4":"# final model with k=6\nkmeans = KMeans(n_clusters = 6, max_iter = 100, random_state = 42)\n\nkmeans.fit(processed_df) #fit the model with 6 clusters on the data","17d5cb67":"# assign the label\ndf['cluster_id'] = kmeans.labels_\ndf.head()","685a3337":"print(df['cluster_id'].value_counts()) #print the amount of samples that belong to each cluster\n\nsns.countplot(df['cluster_id']) #visualize it","ea35a51b":"# plot to visualize the distribution of age of each cluster\nplt.title('Age')\nsns.boxplot(x='cluster_id', y='Age', data = df)\nplt.show()","34b6fec7":"# plot to visualize the distribution of annual income of each cluster\nplt.title('Annual Income (k$)')\nsns.boxplot(x='cluster_id', y='Annual Income (k$)', data = df)\nplt.show()","7bf46dfb":"# plot to visualize the distribution of spending score of each cluster\nplt.title('Spending Score (1-100)')\nsns.boxplot(x='cluster_id', y='Spending Score (1-100)', data= df)\nplt.show()","ffedcbc5":"sns.countplot(data = df , hue ='Gender', x ='cluster_id')","b2a3b935":"#scatter plot gdpp-child_mort\nimport plotly.express as px\n\nfig = px.scatter(df, x =\"Spending Score (1-100)\", y = \"Age\", color = \"cluster_id\") #spending score vs Age of each cluster\nfig.show()","57b808d3":"#scatter plot \n\nfig = px.scatter(df, x =\"Spending Score (1-100)\", y =\"Annual Income (k$)\", color =\"cluster_id\")\n#spending score vs annual income of each cluster\nfig.show()","a219208c":"#scatter plot \n\nfig = px.scatter(df, x = \"Annual Income (k$)\", y =\"Age\", color =\"cluster_id\") #spending annual income vs Age of each cluster\nfig.show()","3987d615":"grouped = df.groupby('cluster_id') #group the dataframe by clusterid\n\ngrouped['Age', 'Annual Income (k$)','Spending Score (1-100)'].mean().sort_values(\n        by = ['Age', 'Annual Income (k$)','Spending Score (1-100)'], ascending=[True, True, True])","8d135dc0":"# cluster 5 customers have the lowest average age(young), lowest average income but have highest spending average\n\n# cluster 0 belongs to mostly aged people with average income and average spending score\n\n#cluster 1 belongs to mid aged people with high income and high spending score\n\n#cluster 4 belongs to mid aged people with high income and low spending score\n\n#cluster 3 belongs to aged people with low income and low spending score\n\n#cluster 2 belongs to young people with high income and medium spending score\n","0ee09a7f":"**Dendogram**","90eb345b":"**Agglomerative clustering**","495102cc":"![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*9J7Wnh5L0eIcHXBeWlzvNA.png)","79e65c4c":"**Modelling the data with the optimum cluster of 6**","2b6cac47":"**Visualization of dataset**","0f559ca3":"##**CONCLUSION**","a62b49e4":"**Preprocessing**","a0c1202d":"**Importing and reading the dataset** **(EDA)**","86233d39":"**Creating clusters with Kmeans**","67ab1694":"**Confirming optimum number of clusters**"}}