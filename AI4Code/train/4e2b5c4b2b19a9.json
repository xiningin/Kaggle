{"cell_type":{"29f97733":"code","07cb317f":"code","48b98da0":"code","750ddddd":"code","b1aca80b":"code","8181be14":"code","a04e1693":"code","e567a44a":"code","0f90b30e":"code","4751dd93":"code","d6d85df9":"code","992c80e2":"markdown","7d3bce11":"markdown","92f20327":"markdown","ede2886c":"markdown","c62692f6":"markdown","8ad7ce45":"markdown"},"source":{"29f97733":"import os\nimport requests\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\n\nfrom keras.optimizers import Adam\nfrom keras.models import Model,load_model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Dense,Input,GlobalMaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau","07cb317f":"batch_size = 24\nnum_classes = 928 # this many classes of Pokemon in the dataset\n\ndata_generator = ImageDataGenerator(rescale=1.\/255,\n                                    horizontal_flip=True,\n                                    vertical_flip=False,\n                                    brightness_range=(0.5,1.5),\n                                    rotation_range=10,\n                                    validation_split=0.2) # use the `subset` argument in `flow_from_directory` to access\n\ntrain_generator = data_generator.flow_from_directory('..\/input\/complete-pokemon-image-dataset\/pokemon',\n                                                    target_size=(160,160), # chosen because this is size of the images in dataset\n                                                    batch_size=batch_size,\n                                                    subset='training')\n\nval_generator = data_generator.flow_from_directory('..\/input\/complete-pokemon-image-dataset\/pokemon',\n                                                    target_size=(160,160),\n                                                    batch_size=batch_size,\n                                                    subset='validation')","48b98da0":"# import the base model and pretrained weights\ncustom_input = Input(shape=(160,160,3,))\nbase_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=custom_input, input_shape=None, pooling=None, classes=num_classes)","750ddddd":"x = base_model.layers[-1].output # snag the last layer of the imported model\n\nx = GlobalMaxPooling2D()(x)\nx = Dense(1024,activation='relu')(x) # an optional extra layer\nx = Dense(num_classes,activation='softmax',name='predictions')(x) # our new, custom prediction layer\n\nmodel = Model(input=base_model.input,output=x)\n# new model begins from the beginning of the imported model,\n# and the predictions come out of `x` (our new prediction layer)\n\n# let's train all the layers\nfor layer in model.layers:\n    layer.training = True","b1aca80b":"model = load_model('..\/input\/inceptionv3-pokemon-modelweights\/InceptionV3_Pokemon.h5')","8181be14":"# these are utilities to maximize learning, while preventing over-fitting\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=12, cooldown=6, rate=0.6, min_lr=1e-18, verbose=1)\nearly_stop = EarlyStopping(monitor='val_loss', patience=24, verbose=1)","a04e1693":"# compile and train the network\nmodel.compile(optimizer=Adam(1e-8),loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit_generator(train_generator,\n                    validation_data=val_generator,\n                    steps_per_epoch=2000\/\/batch_size,\n                    validation_steps=800\/\/batch_size,\n                    epochs=1, # increase this if actually training\n                    shuffle=True,\n                    callbacks=[reduce_lr,early_stop],\n                    verbose=0)","e567a44a":"# here's how to save the model after training. Use ModelCheckpoint callback to save mid-training.\nmodel.save('InceptionV3_Pokemon.h5')","0f90b30e":"# preprocessing and predicting function for test images:\ndef predict_this(this_img):\n    im = this_img.resize((160,160)) # size expected by network\n    img_array = np.array(im)\n    img_array = img_array\/255 # rescale pixel intensity as expected by network\n    img_array = np.expand_dims(img_array, axis=0) # reshape from (160,160,3) to (1,160,160,3)\n    pred = model.predict(img_array)\n    return np.argmax(pred, axis=1).tolist()[0]\n\nclasses = [_class for _class in os.listdir('..\/input\/complete-pokemon-image-dataset\/pokemon\/')]\nclasses.sort() # they were originally converted to number when loaded by folder, alphabetically","4751dd93":"url = 'https:\/\/i.imgur.com\/5Nycvcx.jpg'\nresponse = requests.get(url)\nimg_1 = Image.open(BytesIO(response.content))\n\nprint(\"A wild {} appears!\".format(classes[predict_this(img_1)]))\ndisplay(img_1)","d6d85df9":"# the same thing, as a reusable function\ndef identify(url):\n    response = requests.get(url)\n    _img = Image.open(BytesIO(response.content))\n    print(\"A wild {} appears!\".format(classes[predict_this(_img)]))\n    display(_img)\n\nidentify(\"https:\/\/bit.ly\/2VQ32fd\")","992c80e2":"# Transfer Learning\n[Keras Applications](https:\/\/keras.io\/applications\/) provides a variety of popular network architectures with pre-trained weights. Even though the weights are for detecting objects different from ours, starting from here (rather than some systematic [initialization](https:\/\/keras.io\/initializers\/)) saves a lot of time. After all, a tree is visually more similar to a spatula than to whiteness.","7d3bce11":"### Optional: load pretrained model\/weights\n[This](https:\/\/www.kaggle.com\/kwisatzhaderach\/inceptionv3-pokemon-modelweights) is this model and dataset, pretrained.","92f20327":"# Go forth, and catch them all!","ede2886c":"# Prepare a data pipeline\nThe objective here is to load the images from the `pokemon` folder. [Image data generators](https:\/\/keras.io\/preprocessing\/image\/#imagedatagenerator-class) make this especially easy. They also provide quick access to many simple data augmentation options, like randomly flipping or rotating images. This helps simulate a larger dataset than we actually have, and thereby yields a higher-performing network.  \n  \nFortunately, this dataset's folder structure is already in a great format to feed into Keras. It's something like this:  \n```\n..\/complete-pokemon-image-dataset\/pokemon\/\n                                        Phanpy\/\n                                            Phanpy_1.jpg\n                                            Phanpy_2.jpg\n                                            ...\n                                        Charmander\/\n                                            Charmander_1.jpg\n                                            Charmander_2.jpg\n                                            ...\n                                        ...\n```\n","c62692f6":"Like our custom input, we need a few layers on the end. First, we need to collapse dimensions, which can be done with a global [pooling](https:\/\/keras.io\/layers\/pooling\/) layer, or a `Flatten()` layer, and then cap it off with a prediction layer.","8ad7ce45":"# You must catch them all.\n**A code-focused introduction to neural networks, with Pokemon.**  \n\n- This tutorial demonstrates how to implement [transfer-learning](https:\/\/en.wikipedia.org\/wiki\/Transfer_learning) to quickly train an image recognition network with Keras.  \n- We'll use the magnificently curated [Complete Pokemon Image Dataset.](https:\/\/www.kaggle.com\/mrgravelord\/complete-pokemon-image-dataset)  \n- At the end of this notebook, you'll have a Pokemon-recognizing network ready to use on any `.jpg` or `.png` image."}}