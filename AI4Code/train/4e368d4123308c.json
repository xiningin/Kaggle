{"cell_type":{"2e855f0f":"code","af562dbf":"code","2db94dda":"code","129cd795":"code","2d6ac503":"code","0f3f4ed6":"code","05bc8e1e":"code","89c69c52":"markdown","8bee4b42":"markdown","0a118b5c":"markdown","2fa53d2a":"markdown","eb69c08d":"markdown","87f11226":"markdown","def25035":"markdown","5c3e615f":"markdown"},"source":{"2e855f0f":"import os\nimport numpy as np\nimport math\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import FashionMNIST as mnist\nfrom torchvision.utils import save_image, make_grid\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output","af562dbf":"def imshow(img,size=10):\n  img = img \/ 2 + 0.5     \n  npimg = img.numpy()\n  plt.figure(figsize=(size, size))\n  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n  plt.show()\n\ndef to_img(x):    \n    x = x.view(x.size(0), 1, 28, 28)\n    return x","2db94dda":"epochs = 100\nbatch_size = 64\nlearning_rate = 1e-3","129cd795":"img_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ndataset = mnist('.\/data', download=True, transform=img_transform)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\ndataiter = iter(dataloader)\nimages, labels = dataiter.next()\nimshow(make_grid(images, nrow=8))","2d6ac503":"class Autoencoder(nn.Module):\n  def __init__(self):\n    super(Autoencoder, self).__init__()\n    self.encoder = nn.Sequential(\n      nn.Linear(28 * 28, 128),\n      nn.ReLU(True),\n      nn.Linear(128, 64),\n      nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n    self.decoder = nn.Sequential(\n      nn.Linear(3, 12),\n      nn.ReLU(True),\n      nn.Linear(12, 64),\n      nn.ReLU(True),\n      nn.Linear(64, 128),\n      nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n\n  def forward(self, x):\n    x = self.encoder(x)\n    x = self.decoder(x)\n    return x","0f3f4ed6":"model = Autoencoder()\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=learning_rate, weight_decay=1e-5)","05bc8e1e":"for epoch in range(epochs):\n  for data in dataloader:\n    x_img, _ = data\n    x_img = x_img.view(x_img.size(0), -1)\n    x_img = Variable(x_img)\n    # ===================forward=====================\n    y_pred = model(x_img)\n    loss = loss_fn(y_pred, x_img)\n    # ===================backward====================\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n  # ===================log========================\n  clear_output()\n  print(f'epoch [{epoch}\/{epochs}], loss:{loss.data:.4f}')\n  pic = to_img(y_pred.cpu().data)\n  imshow(make_grid(pic))","89c69c52":"Load Data","8bee4b42":"Image Helper Functions","0a118b5c":"Autoencoder","2fa53d2a":"<a href=\"https:\/\/colab.research.google.com\/github\/cxbxmxcx\/GenReality\/blob\/master\/GEN_2_autoencoder.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","eb69c08d":"Training","87f11226":"Hyperparameters","def25035":"Imports\n","5c3e615f":"Model, Loss Function and Optimizer"}}