{"cell_type":{"0c342b88":"code","e4619472":"code","009aeef7":"code","acee15f3":"code","1bf31cb0":"code","7aad6497":"code","f25f55aa":"code","ac0b265d":"code","25da07d4":"code","f0410941":"code","4e776217":"code","f4de4a66":"code","8977239b":"code","6e5c3775":"code","f636066b":"code","05a19f67":"code","6971fa12":"code","48a25d48":"code","c83ed5e7":"code","2d1fa445":"code","dbbfd99d":"code","e2a6099f":"code","5f625c50":"code","c47993d4":"code","ff18b9d2":"code","aea751e9":"code","415e6fc6":"markdown","07df611f":"markdown","7af6d768":"markdown","b66793ca":"markdown"},"source":{"0c342b88":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport multiprocessing\n\n# Any results you write to the current directory are saved as output.","e4619472":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\nprint('Done!')\n\ncpu_count = 2*multiprocessing.cpu_count()-1\nprint('Number of CPUs: {}'.format(cpu_count))","009aeef7":"(market_train_df, news_train_df) = env.get_training_data()","acee15f3":"print(\"Size of Stock Data: \",market_train_df.shape)\nprint(\"Size of News Data: \",news_train_df.shape)","1bf31cb0":"market_train_df.head(3)","7aad6497":"news_train_df.head(3)","f25f55aa":"print(news_train_df.groupby(['headlineTag']).assetName.value_counts().sort_values(ascending = False))","ac0b265d":"# See the different news sources\nnews_train_df['provider'].value_counts().head(10)","25da07d4":"# Get count headline tags ( type of news) in the news data set\n(news_train_df['headlineTag'].value_counts() \/ 1000)[:10].plot('barh');\nplt.title('headlineTag counts (thousands)');","f0410941":"dfsent = pd.DataFrame(news_train_df.groupby('assetName').sentimentClass.mean()).reset_index(level=['assetName'])\ndfsent['sentimentClass'] = dfsent['sentimentClass']*10\ndfsent[:5]","4e776217":"from matplotlib import pyplot as plt\nax = plt.subplot(111)\nnews_train_df[news_train_df['assetName']=='Naugatuck Valley Financial Corp'][:10].sentimentClass.plot(ax = ax, kind='bar',title='Sentiment Score for Naugatuck Valley Financial Corp', edgecolor = \"black\", color=(0, 0.8, 0,1))\n#ax.get_xaxis().set_visible(False)\nax.set_xlabel('Time the news came out')\nax.set_xticklabels(news_train_df[news_train_df['assetName'] == 'Naugatuck Valley Financial Corp'][:10].sourceTimestamp, rotation=-30, ha = 'left')\nplt.show()\n","f4de4a66":"dfsent1 = pd.concat([dfsent[dfsent['sentimentClass']>8].sample(4),dfsent[dfsent['sentimentClass']<-8].sample(5),dfsent[dfsent['sentimentClass']<2].sample(6)], axis = 0)\ndfsent1.sort_values(by = 'sentimentClass', ascending = False, inplace = True)\ndfsent1.reset_index(inplace = True)\ndfsent1","8977239b":"for i, j in zip([-1, 0, 1], ['negative', 'neutral', 'positive']):\n    df_sentiment = news_train_df.loc[news_train_df['sentimentClass'] == i, 'assetName']\n    print(f'Top mentioned companies for {j} sentiment are:')\n    print(df_sentiment.value_counts().head(5))\n    print('')","6e5c3775":"# plot histogram of sentiment by company\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\nax = plt.subplot(111)\nk = 15\ndfsent1.sentimentClass.plot(ax=ax, kind='barh',title='AVERAGE SENTIMENT SCORE', edgecolor = \"black\", color=(0, 0.8, 1,1))\nxmin, xmax = -11, 11\nymin, ymax = -1, 15\nX = [[.7, .5], [.7, .5]]\n\nax.imshow(X,interpolation='bicubic', cmap=plt.cm.Reds, extent=(xmin, xmax, ymin, ymax), alpha=1)\n#ax.set_xlim(-1, 1)\nax.get_yaxis().set_visible(False)\nfor i, x in enumerate(dfsent[:k].assetName):\n    ax.text(-12.2, i-0.3, x, ha='right', fontsize='large')","f636066b":"print(\"Number of Unique Companies in the News Dataset: \",len(news_train_df['assetName'].unique()))\nprint(\"Number of Unique Companies in the Stock Prices Dataset: \",len(market_train_df['assetCode'].unique()))","05a19f67":"news_train_df['time'] = pd.to_datetime(news_train_df['time'])\nnews_train_df['time'].describe()","6971fa12":"# select some Pharma companies and plot their stock trends\npharmalist = ['ABT.N', 'PFE.N', 'MRK.N','MDT.N','NVO.N','TEVA.N','CELG.N']\ndfpharma = market_train_df[market_train_df['assetCode'].isin(pharmalist)]\ndfpharma = dfpharma[~(dfpharma['assetName'] == 'Unknown')]\ndfpharma.shape","48a25d48":"dfpharma[:2]","c83ed5e7":"market_train_df[:2]","2d1fa445":"# See Stock price trends for selected Pharma Companies\nmarket_train_df['time'] = pd.to_datetime(market_train_df['time'], errors='coerce')\ndata = []\nfor asset in dfpharma.assetName.unique():\n    asset_df = market_train_df[(market_train_df['assetName'] == asset)]\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","dbbfd99d":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] \/ market_train_df['open'])\nmarket_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n\n\nmarket_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby(['time']).agg({'price_diff': ['std', 'min']}).reset_index()\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * np.round(g['price_diff']['min'], 2)).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values * 5,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","e2a6099f":"# code mostly takes from this kernel: https:\/\/www.kaggle.com\/ashishpatel26\/bird-eye-view-of-two-sigma-xgb\n# do a bit of feature engineering and merge market and news data\ndef data_prep(market_df,news_df):\n    market_df['time'] = market_df.time.dt.date\n    market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] \/ market_df['volume']\n    market_df['close_to_open'] = market_df['close'] \/ market_df['open']\n    market_df['volume_to_mean'] = market_df['volume'] \/ market_df['volume'].mean()\n    news_df['sentence_word_count'] =  news_df['wordCount'] \/ news_df['sentenceCount']\n    news_df['time'] = news_df.time.dt.hour\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['headlineLen'] = news_df['headline'].apply(lambda x: len(x))\n    news_df['assetCodesLen'] = news_df['assetCodes'].apply(lambda x: len(x))\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['asset_sentence_mean'] = news_df.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    lbl = {k: v for v, k in enumerate(news_df['headlineTag'].unique())}\n    news_df['headlineTagT'] = news_df['headlineTag'].map(lbl)\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n\n    lbl = {k: v for v, k in enumerate(market_df['assetCode'].unique())}\n    market_df['assetCodeT'] = market_df['assetCode'].map(lbl)\n    \n    market_df = market_df.dropna(axis=0)\n    \n    return market_df\n\n# market_train.drop(['price_diff', 'assetName_mean_open', 'assetName_mean_close'], axis=1, inplace=True)\nmarket_train = data_prep(market_train_df, news_train_df)\n\nprint(market_train.shape)\nup = market_train.returnsOpenNextMktres10 >= 0\n\nfcol = [c for c in market_train.columns if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'assetCodeT',\n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider',\n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) \/ rng)","5f625c50":"np.bincount(up)","c47993d4":"from sklearn import model_selection\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=99)\n\nimport lightgbm as lgb\n# xgb_up = XGBClassifier(n_jobs=4,\n#                        n_estimators=300,\n#                        max_depth=3,\n#                        eta=0.15,\n#                        random_state=42)\nparams = {'learning_rate': 0.01, 'max_depth': 12, 'boosting': 'gbdt', 'objective': 'binary'\n          , 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=up_train), num_boost_round=20,\n                  valid_sets=[lgb.Dataset(X_train, label=up_train), lgb.Dataset(X_test, label=up_test)],\n                  early_stopping_rounds=100)","ff18b9d2":"df = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf.sort_values(by = ['imp'], ascending = False,inplace = True)\ndf","aea751e9":"def generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: np.random.randint(0, 255), range(3)))\n    return color\n\ndf = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndata = [df]\nfor dd in data:  \n    colors = []\n    for i in range(len(dd)):\n         colors.append(generate_color())\n\n    data = [\n        go.Bar(\n        orientation = 'h',\n        x=dd.imp,\n        y=dd.col,\n        name='Features',\n        textfont=dict(size=20),\n            marker=dict(\n            color= colors,\n            line=dict(\n                color='#000000',\n                width=0.5\n            ),\n            opacity = 0.87\n        )\n    )\n    ]\n    layout= go.Layout(\n        title= 'Feature Importance of LGB',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis=dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n\n    py.iplot(dict(data=data,layout=layout), filename='horizontal-bar')","415e6fc6":"## Exploring Stock Data","07df611f":"## Plot News Sentiment","7af6d768":"# Modelling","b66793ca":"## Feature Importance"}}