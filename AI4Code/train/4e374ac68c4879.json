{"cell_type":{"1bfcc192":"code","97e7f708":"code","05ee4607":"code","d7762d56":"code","81d0fcd4":"code","8f143ceb":"code","d23af505":"code","23355d92":"code","8a975fd2":"code","eaeefbdc":"code","e41e372a":"code","ac1da72c":"code","f23fdcc6":"code","a4e57dee":"code","f60ac2c9":"code","96507975":"code","46a4f474":"code","c48e7c5a":"code","a2229df6":"code","e63d97a9":"code","e2136398":"code","bd768761":"code","5bb17b8a":"code","f88ff2ec":"code","38efdd80":"code","ea6d0f68":"code","f8cef1a4":"code","e096bdfd":"code","fbf3fe9d":"code","90a9d418":"code","4ffa0be4":"code","4677ce3c":"code","60a4376d":"code","25cf7a02":"code","2b326407":"code","9ef4b810":"code","f690dc56":"code","01cf7112":"code","0c66a48c":"code","1b52b41c":"markdown","3a343878":"markdown","7c97ae7a":"markdown","ccd8b7e1":"markdown","f8c122c7":"markdown","d60f61f8":"markdown","56b77597":"markdown","b417c6d7":"markdown","00036c8b":"markdown","1177f4a0":"markdown","c3f79c1a":"markdown","cee3e9d2":"markdown"},"source":{"1bfcc192":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","97e7f708":"import fastai\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nimport cv2\n\nimport pandas as pd\nimport matplotlib.pyplot as plt","05ee4607":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/tmp\/.cache\/torch\/checkpoints\/'):\n        os.makedirs('\/tmp\/.cache\/torch\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'","d7762d56":"import os\nos.listdir('..\/input')","81d0fcd4":"print('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","8f143ceb":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 1667\nseed_everything(SEED)","d23af505":"def get_2015_df():\n    base_image_dir = os.path.join('..', 'input\/resized-2015-2019-blindness-detection-images\/')\n    train_dir = os.path.join(base_image_dir,'resized train 15\/')\n    df = pd.read_csv(os.path.join(base_image_dir, 'labels\/trainLabels15.csv'))\n    df.columns = ['image', 'diagnosis']\n    #df = df[df['diagnosis'] != 0]\n    df['path'] = df['image'].map(lambda x: os.path.join(train_dir,'{}.jpg'.format(x)))\n    df = df.drop(columns=['image'])\n    df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    return df\n\n#df_2015 = get_2015_df()","23355d92":"def get_df_2019():\n    base_image_dir = os.path.join('..', 'input\/resized-2015-2019-blindness-detection-images\/')\n    train_dir = os.path.join(base_image_dir,'resized train 19\/')\n    df = pd.read_csv(os.path.join(base_image_dir, 'labels\/trainLabels19.csv'))\n    df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.jpg'.format(x)))\n    df = df.drop(columns=['id_code'])\n    df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    test_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\n    return df, test_df\n\n#df_2019, test_df = get_df_2019()","8a975fd2":"#df = pd.concat([df_2015, df_2019])","eaeefbdc":"base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\ntrain_dir = os.path.join(base_image_dir,'train_images\/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['id_code'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head(10)","e41e372a":"len_df = len(df)\nprint(f\"There are {len_df} images\")","ac1da72c":"df['diagnosis'].hist(figsize = (10, 5))","f23fdcc6":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","a4e57dee":"IMG_SIZE = 256 #512\n\ndef _load_format(path, convert_mode, after_open)->Image:\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), 10) ,-4 ,128)\n                    \n    return Image(pil2tensor(image, np.float32).div_(255)) #return fastai Image format\n\nvision.data.open_image = _load_format\n    \nsrc = (ImageList.from_df(df=df,path='.\/',cols='path') #get dataset from dataset\n        .split_by_rand_pct(0.2, seed=42) #Splitting the dataset\n        #.split_by_idx(valid_idx=range(35126,38788))\n        .label_from_df(cols='diagnosis',label_cls=FloatList) #obtain labels from the level column\n      )\nsrc","f60ac2c9":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0, max_lighting=0.2)\ndata = (\n    src.transform(tfms,size=128)\n    .databunch()\n    .normalize(imagenet_stats)\n)","96507975":"from sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')","46a4f474":"learn = cnn_learner(data, base_arch=models.resnet50 ,metrics=[quadratic_kappa],model_dir='\/kaggle',pretrained=True)","c48e7c5a":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","a2229df6":"learn.fit_one_cycle(3, 1e-2)","e63d97a9":"# progressive resizing\nlearn.data = data = (\n    src.transform(tfms,size=256)\n    .databunch()\n    .normalize(imagenet_stats)\n)\nlearn.lr_find()\nlearn.recorder.plot()","e2136398":"lr = 1e-2\nlearn.fit_one_cycle(5, lr)","bd768761":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()","5bb17b8a":"learn.fit_one_cycle(10, slice(1e-6,1e-4))","f88ff2ec":"learn.export()\nlearn.save('resnet_old_image_weight')","38efdd80":"#copying weighst to the local directory \n#!mkdir models\n#!cp '..\/input\/old-image-weight\/stage-2.pth' 'models'","ea6d0f68":"# loading the weights and replacing the data\n#learn.load('stage-2') \n#learn.data = data","f8cef1a4":"#learn.freeze()\n#learn.fit_one_cycle(4)","e096bdfd":"#learn.unfreeze()\n#learn.lr_find()\n#learn.recorder.plot(suggestion=True)","fbf3fe9d":"#learn.fit_one_cycle(15, max_lr=slice(1e-6, 1e-3))","90a9d418":"#learn.recorder.plot_losses()\n#learn.recorder.plot_metrics()","4ffa0be4":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","4677ce3c":"valid_preds = learn.get_preds(ds_type=DatasetType.Valid)","60a4376d":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","25cf7a02":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","2b326407":"optR = OptimizedRounder()\noptR.fit(valid_preds[0],valid_preds[1])","9ef4b810":"coefficients = optR.coefficients()\nprint(coefficients)","f690dc56":"from fastai.core import *\nfrom fastai.basic_data import *\nfrom fastai.basic_train import *\nfrom fastai.torch_core import *\ndef _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset\n    old = ds.tfms\n    aug_tfms = [o for o in learn.data.train_ds.tfms]\n    try:\n        pbar = master_bar(range(num_pred))\n        for i in pbar:\n            ds.tfms = aug_tfms\n            yield get_preds(learn.model, dl, pbar=pbar)[0]\n    finally: ds.tfms = old\n\nLearner.tta_only = _tta_only\n\ndef _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10, with_loss:bool=False) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"\n    preds,y = learn.get_preds(ds_type)\n    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n    avg_preds = torch.stack(all_preds).mean(0)\n    if beta is None: return preds,avg_preds,y\n    else:            \n        final_preds = preds*beta + avg_preds*(1-beta)\n        if with_loss: \n            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n            return final_preds, y, loss\n        return final_preds, y\n\nLearner.TTA = _TTA","01cf7112":"sample_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\nsample_df.head()","0c66a48c":"learn.data.add_test(ImageList.from_df(sample_df,'..\/input\/aptos2019-blindness-detection',folder='test_images',suffix='.png'))\npreds,y = learn.get_preds(ds_type=DatasetType.Test)\ntest_predictions = optR.predict(preds, coefficients)\nsample_df.diagnosis = test_predictions.astype(int)\nsample_df.head()\nsample_df.to_csv('submission.csv',index=False)","1b52b41c":"## Fine Tune","3a343878":"## Optimize the Metric\n\nOptimizing the quadratic kappa metric was an important part of the top solutions in the previous competition. Thankfully, @abhishek has already provided code to do this for us. We will use this to improve the score.","7c97ae7a":"## TTA\n\nTest-time augmentation, or TTA, is a commonly-used technique to provide a boost in your score, and is very simple to implement. Fastai already has TTA implemented, but it is not the best for all purposes, so I am redefining the fastai function and using my custom version.","ccd8b7e1":"## Submission\nLet's now create a submission","f8c122c7":"**Training:**\n\nWe use transfer learning, where we retrain the last layers of a pretrained neural network. I use the ResNet50 architecture trained on the ImageNet dataset, which has been commonly used for pre-training applications in computer vision. Fastai makes it quite simple to create a model and train:","d60f61f8":"The images are actually quite big. We will resize to a much smaller size.","56b77597":"Let's look at an example image:","b417c6d7":"## Training (Transfer learning)","00036c8b":"## Reading data and Basic EDA\n\nHere I am going to open the dataset with pandas, check distribution of labels.","1177f4a0":"The Kaggle competition used the Cohen's quadratically weighted kappa so I have that here to compare. This is a better metric when dealing with imbalanced datasets like this one, and for measuring inter-rater agreement for categorical classification (the raters being the human-labeled dataset and the neural network predictions). Here is an implementation based on the scikit-learn's implementation, but converted to a pytorch tensor, as that is what fastai uses.","c3f79c1a":"The dataset is highly imbalanced, with many samples for level 0, and very little for the rest of the levels.","cee3e9d2":"This is actually very small. The [previous competition](https:\/\/kaggle.com\/c\/diabetic-retinopathy-detection) had ~35k images, which supports the idea that pretraining on that dataset may be quite beneficial."}}