{"cell_type":{"04dd4173":"code","778d727b":"code","71a237df":"code","77b1c6f1":"code","46cd6e85":"code","c1bfe795":"code","46e8e845":"code","4930429c":"code","cc2baea3":"code","967fc36c":"code","ced93a7a":"code","4e3152b4":"markdown","13dc60ff":"markdown","ef437a5a":"markdown","fd8cccb4":"markdown","f75306a2":"markdown","36cd98db":"markdown","341d2f0b":"markdown","2accee7a":"markdown","09791f57":"markdown","02879b58":"markdown"},"source":{"04dd4173":"#Data manipulation\nimport pandas as pd\nimport numpy as np\n\n#Data visualization\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\n\npd.set_option('max_columns', 50)","778d727b":"# Read in the data\nINPUT_DIR = '..\/input\/m5-forecasting-accuracy'\ncalendar = pd.read_csv(f'{INPUT_DIR}\/calendar.csv')\nsales_train_validation = pd.read_csv(f'{INPUT_DIR}\/sales_train_validation.csv')\nsample_sub = pd.read_csv(f'{INPUT_DIR}\/sample_submission.csv')\nsell_prices = pd.read_csv(f'{INPUT_DIR}\/sell_prices.csv')","71a237df":"# Printing shapes\n\nprint('The sell prices size is:',sell_prices.shape)\nprint('The calendar size is:',calendar.shape)\nprint('The sales_train_validation size is:',sales_train_validation.shape)","77b1c6f1":"# Head of the data\n\nsell_prices.head()","46cd6e85":"calendar.head()","c1bfe795":"sales_train_validation.head()","46e8e845":"# fig, ax = plt.subplots()\n# ax.pie(pd.DataFrame(sales_train_validation.groupby('cat_id').id.count()).reset_index(drop=True))\n","4930429c":"\n# First, let's gather all time data\ntime = [column for column in sales_train_validation.columns if 'd_' in column]\n\n# Lets plot everything\nsns.set(rc={'figure.figsize':(22.7,12.27)})\nsns.set_style('whitegrid')\nsns.set_context('talk')\nplt.xticks(np.arange(min(calendar['date'].index), max(calendar['date'].index)+1, 150.0))\nsns.lineplot(data = pd.concat([pd.DataFrame(sales_train_validation.loc[sales_train_validation['id'] == 'HOBBIES_1_004_CA_1_validation',\n                                time].T.reset_index()).rename(columns={3: 'sales'}), calendar['date']], axis=1),\n             x='date', y='sales').set(title='Time series from id HOBBIES_1_004_CA_1_validation')\nplt.xticks(rotation=45)","cc2baea3":"categories = pd.DataFrame(sales_train_validation.groupby('cat_id')[time].sum().T.reset_index()).columns[1:]\n\nfor i in categories:\n    # Lets plot everything\n    sns.set(rc={'figure.figsize':(22.7,12.27)})\n    sns.set_style('whitegrid')\n    sns.set_context('talk')\n    plt.xticks(np.arange(min(calendar['date'].index), max(calendar['date'].index)+1, 150.0))\n    sns.lineplot(data = pd.concat([pd.DataFrame(sales_train_validation.groupby('cat_id')[time].sum().T.reset_index()), calendar['date']], axis=1),\n                 x='date', y=i).set(title='Categories time series')\n    plt.xticks(rotation=45)\n    plt.legend(labels=categories.values)","967fc36c":"#Let's take a look at the same graphic but separated by states!\n\ncategories = pd.DataFrame(sales_train_validation.groupby(['cat_id', 'state_id'])[time].sum().T.reset_index()).columns[1:]\n\nfor i in range(len(categories)):\n    # Lets plot everything\n    sns.set(rc={'figure.figsize':(22.7,16.27)})\n    sns.set_style('whitegrid')\n    sns.set_context('talk')\n    plt.xticks(np.arange(min(calendar['date'].index), max(calendar['date'].index)+1, 150.0))\n    sns.lineplot(data = pd.concat([pd.DataFrame(sales_train_validation.groupby(['cat_id', 'state_id'])[time].sum().T.reset_index()), calendar['date']], axis=1),\n                 x='date', y=categories[i]).set(title='Categories time series')\n    plt.xticks(rotation=45)\n    plt.legend(labels=categories.values)\n","ced93a7a":"# #Can we see how stores are performing in each state?\n# #Let's take a look at the same graphic but separated by states!\n\n# categories = pd.DataFrame(sales_train_validation.groupby(['cat_id'])[time].sum().T.reset_index()).columns[1:]\n# states = pd.DataFrame(sales_train_validation.groupby(['state_id'])[time].sum().T.reset_index()).columns[1:]\n# stores = pd.DataFrame(sales_train_validation.groupby(['store_id'])[time].sum().T.reset_index()).columns[1:]\n\n\n# for i in range(len(categories)):\n#     # Lets plot everything\n#     sns.set(rc={'figure.figsize':(22.7,16.27)})\n#     sns.set_style('whitegrid')\n#     sns.set_context('talk')\n#     plt.subplot(3,1,)\n#     plt.xticks(np.arange(min(calendar['date'].index), max(calendar['date'].index)+1, 150.0))\n#     sns.lineplot(data = pd.concat([pd.DataFrame(sales_train_validation.groupby(['cat_id', 'state_id'])[time].sum().T.reset_index()), calendar['date']], axis=1),\n#                  x='date', y=categories[i]).set(title='Categories time series')\n#     plt.xticks(rotation=45)\n#     plt.legend(labels=categories.values)\n","4e3152b4":"# File 1: \u201ccalendar.csv\u201d \nContains information about the dates the products are sold.\n* date: The date in a \u201cy-m-d\u201d format.\n* wm_yr_wk: The id of the week the date belongs to.\n* weekday: The type of the day (Saturday, Sunday, \u2026, Friday).\n* wday: The id of the weekday, starting from Saturday.\n* month: The month of the date.\n* year: The year of the date.\n* event_name_1: If the date includes an event, the name of this event.\n* event_type_1: If the date includes an event, the type of this event.\n* event_name_2: If the date includes a second event, the name of this event.\n* event_type_2: If the date includes a second event, the type of this event.\n* snap_CA, snap_TX, and snap_WI: A binary variable (0 or 1) indicating whether the stores of CA, TX or WI allow SNAP1 purchases on the examined date. 1 indicates that SNAP purchases are allowed.\n    \n# File 2: \u201csell_prices.csv\u201d\nContains information about the price of the products sold per store and date.\n* store_id: The id of the store where the product is sold. \n* item_id: The id of the product.\n* wm_yr_wk: The id of the week.\n* sell_price: The price of the product for the given week\/store. The price is provided per week (average across seven days). If not available, this means that the product was not sold during the examined week. Note that although prices are constant at weekly basis, they may change through time (both training and test set).  \n\n# File 3: \u201csales_train.csv\u201d \nContains the historical daily unit sales data per product and store.\n* item_id: The id of the product.\n* dept_id: The id of the department the product belongs to.\n* cat_id: The id of the category the product belongs to.\n* store_id: The id of the store where the product is sold.","13dc60ff":"Get our data","ef437a5a":"You can access the following link to read more about the competition, it's the competitors guide: https:\/\/mofc.unic.ac.cy\/m5-competition\/","fd8cccb4":"The behaviour seems much like what we already see in daily data. Let's bring a aggregated data","f75306a2":"Turns out to be difficult to see, the dfferences between states are big, and it seems that CA is the biggest one in sales volume","36cd98db":"# M5 Challenge - Accuracy \n<img src=\"https:\/\/asset.barrons.com\/public\/resources\/images\/ON-CJ684_quizgr_B620_20171229134559.jpg\" width=\"500\" height=\"300\" \/>\n\nThis notebook is a simple EDA for the M5 challenge accuracy competition, updated regularly.\n\nThings to get in consideration:\n- There are two parallel competitions: **Accuracy** and **Uncertainty**, both based in different metrics measurements\n- The data, covers stores in three US States (California, Texas, and Wisconsin).\n- The data are divided in the following three csv's:","341d2f0b":"There's a different behaviour here, apparently a seasonalized drop of sales, strange.","2accee7a":"Let's load our packages","09791f57":"First of all, let's take a look at what we are handling here","02879b58":"# Time series visualizations"}}