{"cell_type":{"4ce2ea84":"code","cc38a6f6":"code","94ffe22f":"code","8534f848":"code","84ab674c":"code","f8444d04":"code","1fa16eea":"code","16cfdcbd":"code","e814821f":"code","982fed42":"code","18d7eff5":"code","962ebf52":"code","fce7b9d5":"code","24314439":"code","b1c47461":"code","d8d5dc0d":"code","b959b572":"code","0ccf5dac":"code","823073bb":"code","f6fd6a45":"code","acce45b1":"code","1e9be6b1":"code","dea24b9a":"code","de71b4c9":"code","d77581de":"code","a674b83b":"code","986859bc":"code","e300a5b9":"code","ea2abedf":"code","0930564a":"code","a2da221b":"code","8b9feba5":"code","8931c659":"code","1fc49be8":"code","4610cd49":"code","0f9c6c73":"markdown","73d25e0d":"markdown","20ab0e11":"markdown","3697ca6b":"markdown","ef328a56":"markdown","c96b2ec8":"markdown","771a38e4":"markdown","30d8cd41":"markdown","223d9f61":"markdown","17a66f58":"markdown","94ffc15a":"markdown","e43501a4":"markdown","7fc64c4b":"markdown","94cf5bd0":"markdown","d3799a62":"markdown","c88571fa":"markdown","36db26aa":"markdown","f9e2bff3":"markdown","0c6348df":"markdown","c2e2fa3b":"markdown","6131c177":"markdown","892dfc57":"markdown","198b4d07":"markdown","902d65d2":"markdown","36f3a11c":"markdown"},"source":{"4ce2ea84":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\n\nimport torchvision\nimport torchvision.transforms as transforms","cc38a6f6":"# We'll use this class to control the things :\nclass InvalidDatasetException(Exception):\n    \n    def __init__(self, len_of_paths, len_of_labels):\n        super().__init__(\n            f\"Number of path ({len_of_paths}) is not compatible with number of labels ({len_of_labels})\"\n        )","94ffe22f":"transform = transforms.Compose([transforms.ToTensor()])","8534f848":"class AnimalDataset(Dataset):\n    \n    def __init__(self, img_paths, img_labels, size_of_images):\n        self.img_paths = img_paths\n        self.img_labels = img_labels\n        self.size_of_images = size_of_images\n        if len(self.img_paths) != len(self.img_labels):\n            raise InvalidDatasetException(self.img_paths, self.img_labels)\n            \n    # We need to override __len__ special method\n    def __len__(self):\n        return len(self.img_paths)\n    \n    # Also we need to override __getitem__ special method\n    # This method should return the image and its label from index given.\n    def __getitem__(self, index):\n        PIL_IMAGE = Image.open(self.img_paths[index]).resize(self.size_of_images)\n        # In PyTorch we use torch tensors. ToTensor transform transforms the PIL image To Torch tensor.\n        TENSOR_IMAGE = transform(PIL_IMAGE)\n        label = self.img_labels[index]\n        return TENSOR_IMAGE, label","84ab674c":"paths = []\nlabels = []\nlabel_map = {\n    0:'Cat',\n    1:'Dog',\n    2:'Wild'\n}\n\nfor cat_path in glob('..\/input\/animal-faces\/afhq\/train\/cat\/*') + glob('..\/input\/animal-faces\/afhq\/val\/cat\/*'):\n    paths.append(cat_path)\n    labels.append(0)\n    \nfor dog_path in glob('..\/input\/animal-faces\/afhq\/train\/dog\/*') + glob('..\/input\/animal-faces\/afhq\/val\/dog\/*'):\n    paths.append(dog_path)\n    labels.append(1)\n    \nfor wild_path in glob('..\/input\/animal-faces\/afhq\/train\/wild\/*') + glob('..\/input\/animal-faces\/afhq\/val\/wild\/*'):\n    paths.append(wild_path)\n    labels.append(2)\n\nprint(len(paths))\nprint(len(labels))","f8444d04":"dataset = AnimalDataset(paths, labels, (250,250))","1fa16eea":"from sklearn.model_selection import train_test_split\n\n# dataset_indices = [0,1,2,3, ..len(dataset)-1]\ndataset_indices = list(range(0,len(dataset)))\n\ntrain_indices, test_indices = train_test_split(dataset_indices, test_size=0.2, random_state=42)\nprint('Number of train samples : ', len(train_indices))\nprint('Number of test samples : ', len(test_indices))","16cfdcbd":"train_sampler = SubsetRandomSampler(train_indices)\ntest_sampler = SubsetRandomSampler(test_indices)","e814821f":"train_sampler","982fed42":"BATCH_SIZE = 128\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)","18d7eff5":"dataset[1][0].shape","962ebf52":"images, labels = next(iter(train_loader))","fce7b9d5":"images.shape","24314439":"labels.shape","b1c47461":"type(labels)","d8d5dc0d":"fig, axis = plt.subplots(3, 5, figsize=(15,10))\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        npimg = images[i].numpy()\n        npimg = np.transpose(npimg, (1,2,0))\n        label = label_map[int(labels[i])]\n        ax.imshow(npimg)\n        ax.set(title=f\"{label}\")","b959b572":"class CNN(nn.Module):\n    \n    def __init__(self):\n        super(CNN, self).__init__()\n        # First we'll define our layers\n        self.conv1 = nn.Conv2d(3, 32,  kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(32,64,  kernel_size=3, stride=2, padding=1)\n        self.batchnorm1 = nn.BatchNorm2d(64)\n        \n        self.conv3 = nn.Conv2d(64,128, kernel_size=3, stride=2, padding=1)\n        self.batchnorm2 = nn.BatchNorm2d(128)\n        \n        self.conv4 = nn.Conv2d(128,256,kernel_size=3, stride=2, padding=1)\n        self.batchnorm3 = nn.BatchNorm2d(256)\n        \n        self.maxpool = nn.MaxPool2d(2,2)\n        \n        self.fc1 = nn.Linear(256*2*2, 512)\n        self.fc2 = nn.Linear(512, 3)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.batchnorm1(x)\n        x = self.maxpool(x)\n        \n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.batchnorm2(x)\n        x = self.maxpool(x)\n        \n        x = self.conv4(x)\n        x = F.relu(x)\n        x = self.batchnorm3(x)\n        x = self.maxpool(x)\n        \n        x = x.view(-1, 256*2*2)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        \n        x = F.log_softmax(x, dim=1)\n        \n        return x\n        ","0ccf5dac":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","823073bb":"device","f6fd6a45":"model = CNN().to(device)","acce45b1":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(model.parameters(), lr=1e-4)","1e9be6b1":"from tqdm import tqdm ","dea24b9a":"EPOCH_NUMBER = 3\nTRAIN_LOSS = []\nTRAIN_ACCURACY = []\n\nfor epoch in range(1, EPOCH_NUMBER+1):\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    for data_, target_ in tqdm(train_loader):\n        # We have to one hot encoder our labels:\n        target_ = target_.to(device)\n        data_ = data_.to(device)\n        \n        # Cleaning the cached gradients if there are:\n        optimizer.zero_grad()\n        \n        # Getting train decisions and computing loss:\n        outputs = model(data_)\n        loss = criterion(outputs, target_)\n        \n        # Backpropagation and optimizing:\n        loss.backward()\n        optimizer.step()\n        \n        # Computing statistics:\n        epoch_loss = epoch_loss + loss.item()\n        _, pred = torch.max(outputs, dim=1)\n        correct = correct + torch.sum(pred == target_).item()\n        total += target_.size(0)\n        \n    # Appending stats to the lists.\n    TRAIN_LOSS.append(epoch_loss)\n    TRAIN_ACCURACY.append(100*correct \/ total)\n    print(f\"Epoch {epoch}: Accuracy: {100*correct\/total}, Loss: {epoch_loss}\")","de71b4c9":"TRAIN_LOSS","d77581de":"TRAIN_ACCURACY","a674b83b":"for epoch in range(1, 3):\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    for data_, target_ in tqdm(train_loader):\n        # We have to one hot encoder our labels:\n        target_ = target_.to(device)\n        data_ = data_.to(device)\n        \n        # Cleaning the cached gradients if there are:\n        optimizer.zero_grad()\n        \n        # Getting train decisions and computing loss:\n        outputs = model(data_)\n        loss = criterion(outputs, target_)\n        \n        # Backpropagation and optimizing:\n        loss.backward()\n        optimizer.step()\n        \n        # Computing statistics:\n        epoch_loss = epoch_loss + loss.item()\n        _, pred = torch.max(outputs, dim=1)\n        correct = correct + torch.sum(pred == target_).item()\n        total += target_.size(0)\n        \n    # Appending stats to the lists.\n    TRAIN_LOSS.append(epoch_loss)\n    TRAIN_ACCURACY.append(100*correct \/ total)\n    print(f\"Epoch {epoch}: Accuracy: {100*correct\/total}, Loss: {epoch_loss}\")","986859bc":"loss","e300a5b9":"TRAIN_LOSS","ea2abedf":"TRAIN_ACCURACY","0930564a":"EPOCH_NUMBER = 5","a2da221b":"plt.subplots(figsize=(6,4))\nplt.plot(range(EPOCH_NUMBER), TRAIN_LOSS, color='blue', label='Loss')\nplt.legend()\nplt.show()\n\nplt.subplots(figsize=(6,4))\nplt.plot(range(EPOCH_NUMBER), TRAIN_ACCURACY, color='green', label='Accuracy')\nplt.legend()\nplt.show()","8b9feba5":"total_val_loss = 0.0\ntotal_true = 0\ntotal = len(test_sampler)\n\n# When we're not working with gradients and backpropagation we use torch.no_grad() utility.\nwith torch.no_grad():\n    model.eval()\n    for data_, target_ in tqdm(validation_loader):\n        data_ = data_.to(device)\n        target_ = target_.to(device)\n        \n        outputs = model(data_)\n        loss = criterion(outputs, target_).item()\n        _, preds = torch.max(outputs, dim=1)\n        total_val_loss += loss\n        true = torch.sum(preds == target_).item()\n        total_true += true\n        \nvalidation_accuracy = round(100*total_true\/total, 2)\nprint(f\"Validation Accuracy : {validation_accuracy}%\")\nprint(f\"Validation Loss : {round(total_val_loss,2)}%\")","8931c659":"for param_tensor in model.state_dict():\n    print(param_tensor, '\\t', model.state_dict()[param_tensor].size())","1fc49be8":"torch.save(model.state_dict(), 'model.pt')","4610cd49":"loaded_model = CNN()\nloaded_model.load_state_dict(torch.load('model.pt'))","0f9c6c73":"**We've trained our model, and now we can take a look at the stats and after that we can evaluate our model by using test set.**","73d25e0d":"## Introduction\n\nHey people, welcome to this kernel. In this kernel I'm gonna show you how to build a convolutional neural network using PyTorch.\n\nI used to work with Tensorflow, but recently I decided to change my main deep learning library as PyTorch. I've researched both Tensorflow and PyTorch (really) detailed and PyTorch seems better for me.\n\nSo let's start!","20ab0e11":"## Step 1. Preparing Dataset\n\nPyTorch offers advanced tools for reading, batching and preparing image data and today we'll use those tolls.\n\nIn general, preparing data in PyTorch have 3 mini-steps.\n1. Preparing Dataset Class\n2. Preparing Sampler\n3. Preparing Data Loader\n\n","3697ca6b":"And as you guess, we can just save and load this state dict.","ef328a56":"Let's create our object.","c96b2ec8":"Also as you know, in deep learning we use an optimization algorithm to apply gradients and a loss function to compute gradients. In this kernel we're going to use cross entropy loss and RMSProp optimizer","771a38e4":"> This kernel and all of idea in it are a copy of [PyTorch Animal Face Classification - CNNs - by Mehmet-lauda-Tekman](https:\/\/www.kaggle.com\/mehmetlaudatekman\/pytorch-animal-face-classification-cnns).\nThank you for nice reference","30d8cd41":"..two more epoch","223d9f61":"- Now we can create our model object.\n- But before we need to create our GPU variable, we'll send our model to the gpu that way.","17a66f58":"If we want briefly explain what does this class do, it reads the image and convert it to a Torch tensor. Then it returns the image and the label of the image.","94ffc15a":"## Step 5. Save A PyTorch Model","e43501a4":"# Animal Face Classification with PyTorch","7fc64c4b":"And now all we need to do is giving these indices lists to our samplers.","94cf5bd0":"Now our model is ready to use!","d3799a62":"And in order to load model we need to create a new object from the class and load the state dict.","c88571fa":"### 1-c. preparing data loader objects\nEverything is ready to combine. We have a dataset we can read images and labels. We have samplers which will help us to randomly choose samples. And now we need a data loader which will create batches using the dataset and samplers.","36db26aa":"## Step 2. Neural Network Modeling\nOur dataset is ready, now we can build our deep convolutional network. In PyTorch, when we build a model, we create a class inherited PyTorch's nn.Module abstract class.\n\nThen we need to write forward function which includes forward propagation.","f9e2bff3":"### 1-a. Preparing Dataset Class\nFirst, we'll create a dataset class by inheriting our class PyTorch's abstract Dataset class. There are some special functions we must override. We'll see them in the code","0c6348df":"```\nStep 1. Preparing Dataset\n     1-a. Preparing Dataset Class\n     1-b. Preparing Sampler Objects\n     1-c. Preparing Data Loader Objects\nStep 2. Neural Network Modeling\nStep 3. Training Model\nStep 4. Final Test\nStep 5. Save a PyTorch Model\n```","c2e2fa3b":"## Step 4. Final Test\nAnd now we'll test our model using our test loader.","6131c177":"## Step 3. Training Model\nOur model and dataset are ready, now we can train our model.","892dfc57":"### 1-b. preparing sampler objects","198b4d07":"We trained our model and we might want to use it in our real life. And in order to use it regularly we need to save it.\n\nThere are lots of way to save a model in PyTorch but today we'll use the best way: saving state dict\n\nState dictionary is a python dictionary which includes layer names as keys and layer weights as items. If we take a look at the state dict we can fully understand it.","902d65d2":"Everything is ready about data. Let's move on to the neural network modeling.\n\nBut before, let's take a look at our images.","36f3a11c":"- We've completed the hardest part of preparing data. Now we'll create our sampler object.\n- Basically sampler shows how we'll choose the data.\n- We'll create two random samplers: Train Random Sampler and Test Random Sampler.\n- These random samplers will randomly choose indices from the list given. You'll definitely understance when you see.\n\nLet's code it"}}