{"cell_type":{"699e049c":"code","1d54dbe7":"code","26402e20":"code","d4bcc54a":"code","5fe289b1":"code","15d75901":"code","7bab35a5":"code","1ae101b3":"code","565ff305":"code","e199ea12":"code","d21f1ad6":"code","5d4ea82e":"code","4b9a659c":"code","fff5a0f0":"code","522bf864":"code","d99643d7":"code","01905521":"code","ab593715":"code","3f57c69f":"code","13af9fbe":"code","b5f19f9d":"code","5a445b4a":"code","651fea81":"markdown","b740c6cf":"markdown","4bb74ee5":"markdown","4e40c6bd":"markdown","2747a247":"markdown","49d7d730":"markdown","00cc6ef3":"markdown","ff97486a":"markdown","ccd8390d":"markdown","32cb15c4":"markdown","735b69ff":"markdown","8e8237cc":"markdown","ab312255":"markdown"},"source":{"699e049c":"import numpy as np\nimport pandas as pd\n\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', 999)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport itertools\n","1d54dbe7":"!pip install pystan==2.19.1.1\n!pip install prophet\n\nfrom prophet import Prophet","26402e20":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntrain['date'] = pd.to_datetime(train.date)\nprint(train.info())\ntrain.head()","d4bcc54a":"test = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\ntest['date'] = pd.to_datetime(test.date)\nprint(test.info())\ntest.head()","5fe289b1":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","15d75901":"sns.relplot(data=train, x='date', y='num_sold', row='country', col='store', hue='product',\n            aspect=3, height=2.5, kind='line')","7bab35a5":"val = train[train.date >= '2018-01-01'].copy()\nval.reset_index(drop=True, inplace=True)\n\ntrain = train[train.date < '2018-01-01'].copy()\ntrain.reset_index(drop=True, inplace=True)\n\ntrain.rename({'date':'ds', 'num_sold':'y'}, axis=1, inplace=True)\nval.rename({'date':'ds', 'num_sold':'y'}, axis=1, inplace=True)\ntest.rename({'date':'ds'}, axis=1, inplace=True)\n\nprint('Train', train.shape, '| Start', train.ds.min(), '| End', train.ds.max())\nprint('Val', val.shape, '| Start', val.ds.min(), '| End', val.ds.max())\nprint('Test', test.shape, '| Start', test.ds.min(), '| End', test.ds.max())","1ae101b3":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet()\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = train_preds.yhat.values\n            val.loc[val_idx, 'yhat'] = val_preds.yhat.values\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","565ff305":"new_year = pd.DataFrame({\n  'holiday': 'new_year',\n  'ds': pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01']),\n  'lower_window': -1,\n  'upper_window': 0,\n})\n\neaster = pd.DataFrame({\n  'holiday': 'easter',\n  'ds': pd.to_datetime(['2015-04-05', '2016-03-27', '2017-04-16', '2018-04-01', '2019-04-21']),\n  'lower_window': 0,\n  'upper_window': 7,\n})\n\nholidays = pd.concat((new_year, easter))\nholidays","e199ea12":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(holidays=holidays)\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = train_preds.yhat.values\n            val.loc[val_idx, 'yhat'] = val_preds.yhat.values\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","d21f1ad6":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = train_preds.yhat.values\n            val.loc[val_idx, 'yhat'] = val_preds.yhat.values\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","5d4ea82e":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = np.round(train_preds.yhat.values, 0)\n            val.loc[val_idx, 'yhat'] = np.round(val_preds.yhat.values, 0)\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","4b9a659c":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = np.ceil(train_preds.yhat.values)\n            val.loc[val_idx, 'yhat'] = np.ceil(val_preds.yhat.values)\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","fff5a0f0":"all_train = pd.concat([train, val], axis=0, ignore_index=True).reset_index(drop=True)\n\nfor country in all_train.country.unique():\n    for store in all_train.store.unique():\n        for product in all_train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = all_train[(all_train.country==country) & \n                                  (all_train.store==store) &\n                                  (all_train['product']==product)].index\n            \n            train_sub = all_train.loc[train_idx].copy()\n            \n            test_idx = test[(test.country==country) & \n                            (test.store==store) &\n                            (test['product']==product)].index\n            \n            test_sub = test.loc[test_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            test_preds = model.predict(test_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            all_train.loc[train_idx, 'yhat'] = np.round(train_preds.yhat.values, 0)\n            test.loc[test_idx, 'yhat'] = np.round(test_preds.yhat.values, 0)\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(all_train.y.values, all_train.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","522bf864":"# growth='linear',\n# holidays=holidays,\n# n_changepoints=10,\n# changepoint_range=0.4,\n# yearly_seasonality=True,\n# weekly_seasonality=True,\n# daily_seasonality=False,\n# seasonality_mode='additive',\n# seasonality_prior_scale=25,\n# holidays_prior_scale=100,\n# changepoint_prior_scale=0.01,\n# interval_width=0.5,\n# uncertainty_samples=False","d99643d7":"# from prophet.diagnostics import cross_validation\n# from prophet.diagnostics import performance_metrics\n\n# all_data = pd.concat([train, val], axis=0, ignore_index=True).reset_index(drop=True)\n\n# df = all_data[(all_data.country=='Finland') & \n#               (all_data.store=='KaggleMart') &\n#               (all_data['product']=='Kaggle Mug')].copy()\n\n# param_grid = {  \n#     'changepoint_prior_scale': [0.001, 0.01, 0.1],\n#     'seasonality_prior_scale': [0.01, 0.1, 1, 10, 25],\n#     'holidays_prior_scale':[0.01, 0.1, 1, 10],\n#     'changepoint_range':[0.7, 0.8, 0.9],\n#     'holidays':[holidays]\n# }\n\n# cutoffs = pd.to_datetime(['2015-12-31', '2016-12-31', '2017-12-31'])\n\n# # Generate all combinations of parameters\n# all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n# print(len(all_params))\n# smapes = []  # Store the RMSEs for each params here","01905521":"# # Use cross validation to evaluate all parameters\n# for params in all_params:\n#     m = Prophet(**params).fit(df)  # Fit model with given params\n#     df_cv = cross_validation(m, initial=1095, cutoffs=cutoffs, horizon='365 days', parallel=\"processes\")\n#     df_p = performance_metrics(df_cv, rolling_window=1)\n#     smapes.append(df_p['smape'].values[0])\n\n# # Find the best parameters\n# tuning_results = pd.DataFrame(all_params)\n# tuning_results['smape'] = smapes","ab593715":"# tuning_results.sort_values('smape', ascending=False).head(50)","3f57c69f":"submission = test[['row_id', 'yhat']].copy()\nsubmission.rename({'yhat':'num_sold'}, axis=1, inplace=True)\nsubmission['num_sold'] = np.ceil(submission.num_sold)\nsubmission.describe()","13af9fbe":"submission.head()","b5f19f9d":"submission.tail()","5a445b4a":"submission.to_csv('submission.csv', index=False)","651fea81":"# Competition Metric\nhttps:\/\/www.kaggle.com\/cpmpml\/smape-weirdness","b740c6cf":"# Train Test Val Split","4bb74ee5":"# Load the data","4e40c6bd":"# Submission","2747a247":"# Base Prophet","49d7d730":"# Libraries","00cc6ef3":"# Summary","ff97486a":"# Final Training","ccd8390d":"## Add Holidays\nhttps:\/\/www.kaggle.com\/gunesevitan\/tabular-playground-series-jan-2022-prophet","32cb15c4":"## Tuned Parameters\nhttps:\/\/www.kaggle.com\/gunesevitan\/tabular-playground-series-jan-2022-prophet","735b69ff":"# Ceiling","8e8237cc":"# Tunning Parameters","ab312255":"# Rounding"}}