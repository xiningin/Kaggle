{"cell_type":{"d65f07aa":"code","918efa50":"code","72531ade":"code","049bed8e":"code","101da4a7":"code","4ae78dc9":"code","32aa4e81":"code","fd23465d":"code","789ea64b":"code","686d5fbc":"code","fbdf792b":"code","33dd479b":"code","c720cf74":"code","50aef429":"code","e1b78a65":"code","54eebe0a":"code","bdfb7399":"code","aa096cfc":"code","e4a6632d":"markdown","ccde5914":"markdown","675c4139":"markdown","be4224e1":"markdown","47d49cd7":"markdown","d6972932":"markdown","b722dd81":"markdown","bc44dc57":"markdown","e31c352e":"markdown","5c275b38":"markdown","cb509915":"markdown","40de1822":"markdown","2e854964":"markdown","e8881dfc":"markdown"},"source":{"d65f07aa":"# Bibliotecas\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\nfrom keras.optimizers import Adam\nimport csv\nfrom keras.models import Model, load_model","918efa50":"def runSeed():\n    global seed\n    seed=12\n    os.environ['PYTHONHASHSEED']=str(12)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()","72531ade":"learning_rate = 0.001\nweight_decay = 0.0001\nNUM_EPOCHS = 15\nMAX_EPOCH = 20\nRAW_IMG_SIZE = (256, 256)\nIMG_SIZE = (224, 224)\nINPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\nBATCH_SIZE = 32\nFOLDS = 5\nSTOPPING_PATIENCE = 32\nLR_PATIENCE = 16\nINITIAL_LR = 0.0001","049bed8e":"#------------- Par\u00e2metros ViT-Base -------------------------\npatch_size = 16  # Tamanho dos patches para serem extraidos.\nnum_patches = (224 \/\/ patch_size) ** 2\nprojection_dim = 64\nnum_heads = 12\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  \n\n# Tamanho das camadas de transforma\u00e7\u00e3o.\ntransformer_layers = 12\nmlp_head_units = [2048, 1024]","101da4a7":"IMG_DIRECTORY = '\/kaggle\/input\/deepweeds\/images\/'\nLABEL_DIRECTORY = '\/kaggle\/input\/deepweeds\/labels\/'\nOUTPUT_DIRECTORY = '.\/'","4ae78dc9":"CLASSES_STR = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\nCLASSES = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n\nCLASS_NAMES = ['Chinee Apple',\n               'Lantana',\n               'Parkinsonia',\n               'Parthenium',\n               'Prickly Acacia',\n               'Rubber Vine',\n               'Siam Weed',\n               'Snake Weed',\n               'Negatives']\nNUM_CLASSES=9","32aa4e81":"def crop(img, size):\n    (h, w, c) = img.shape\n    x = int((w - size[0]) \/ 2)\n    y = int((h - size[1]) \/ 2)\n    return img[y:(y + size[1]), x:(x + size[0]), :]\n\ndef crop_generator(batches, size):\n    while True:\n        batch_x, batch_y = next(batches)\n        (b, h, w, c) = batch_x.shape\n        batch_crops = np.zeros((b, size[0], size[1], c))\n        for i in range(b):\n            batch_crops[i] = crop(batch_x[i], (size[0], size[1]))\n        yield (batch_crops, batch_y)","fd23465d":"from keras.preprocessing.image import ImageDataGenerator\n\nfor k in range(FOLDS):\n        # Prepare training, validation and testing labels for kth fold\n        train_label_file = \"{}train_subset{}.csv\".format(LABEL_DIRECTORY, k)\n        val_label_file = \"{}val_subset{}.csv\".format(LABEL_DIRECTORY, k)\n        test_label_file = \"{}test_subset{}.csv\".format(LABEL_DIRECTORY, k)\n        train_dataframe = pd.read_csv(train_label_file)\n        val_dataframe = pd.read_csv(val_label_file)\n        test_dataframe = pd.read_csv(test_label_file)\n        train_image_count = train_dataframe.shape[0]\n        val_image_count = train_dataframe.shape[0]\n        test_image_count = test_dataframe.shape[0]\n        train_dataframe['Label'] = train_dataframe.Label.astype(str)\n        val_dataframe['Label'] = val_dataframe.Label.astype(str)\n        test_dataframe['Label'] = test_dataframe.Label.astype(str)\n\n        # Training image augmentation\n        train_data_generator = ImageDataGenerator(\n            rescale=1. \/ 255,\n            fill_mode=\"constant\",\n            shear_range=0.2,\n            zoom_range=(0.5, 1),\n            horizontal_flip=True,\n            rotation_range=360,\n            channel_shift_range=25,\n            brightness_range=(0.75, 1.25))\n\n        # Validation image augmentation\n        val_data_generator = ImageDataGenerator(\n            rescale=1. \/ 255,\n            fill_mode=\"constant\",\n            shear_range=0.2,\n            zoom_range=(0.5, 1),\n            horizontal_flip=True,\n            rotation_range=360,\n            channel_shift_range=25,\n            brightness_range=(0.75, 1.25))\n\n        # No testing image augmentation (except for converting pixel values to floats)\n        test_data_generator = ImageDataGenerator(rescale=1. \/ 255)\n\n        # Load train images in batches from directory and apply augmentations\n        train_data_generator = train_data_generator.flow_from_dataframe(\n            train_dataframe,\n            IMG_DIRECTORY,\n            x_col='Filename',\n            y_col='Label',\n            target_size=RAW_IMG_SIZE,\n            batch_size=BATCH_SIZE,\n            #classes=CLASSES,\n            class_mode='categorical')\n\n        # Load validation images in batches from directory and apply rescaling\n        val_data_generator = val_data_generator.flow_from_dataframe(\n            val_dataframe,\n            IMG_DIRECTORY,\n            x_col=\"Filename\",\n            y_col=\"Label\",\n            target_size=RAW_IMG_SIZE,\n            batch_size=BATCH_SIZE,\n            #classes=CLASSES,\n            class_mode='categorical')\n\n        # Load test images in batches from directory and apply rescaling\n        test_data_generator = test_data_generator.flow_from_dataframe(\n            test_dataframe,\n            IMG_DIRECTORY,\n            x_col=\"Filename\",\n            y_col=\"Label\",\n            target_size=IMG_SIZE,\n            batch_size=BATCH_SIZE,\n            shuffle=False,\n            #classes=CLASSES,\n            class_mode='categorical')\n        \n        # Crop augmented images from 256x256 to 224x224\n        train_data_generator = crop_generator(train_data_generator, IMG_SIZE)\n        val_data_generator = crop_generator(val_data_generator, IMG_SIZE)","789ea64b":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x","686d5fbc":"class Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","fbdf792b":"class PatchEncoder(layers.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = layers.Dense(units=projection_dim)\n        self.position_embedding = layers.Embedding(\n            input_dim=num_patches, output_dim=projection_dim\n        )\n\n    def call(self, patch):\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        encoded = self.projection(patch) + self.position_embedding(positions)\n        return encoded","33dd479b":"def create_vit_classifier():\n    inputs = layers.Input(shape=INPUT_SHAPE)\n    # Criacao de patches\n    patches = Patches(patch_size)(inputs)\n    # Encode  dos patches.\n    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n\n    # Camadas do block transformer (range \u00e9 limite de camadas)\n    for _ in range(transformer_layers):\n        # Layer normalization 1.\n        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n        # Camada MLP\n        attention_output = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n        )(x1, x1)\n        # Skip connection 1.\n        x2 = layers.Add()([attention_output, encoded_patches])\n        # Layer normalization 2.\n        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n        # MLP.\n        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n        # Skip connection 2.\n        encoded_patches = layers.Add()([x3, x2])\n\n    # Cria um Tensor [batch_size, projection_dim].\n    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n    representation = layers.Flatten()(representation)\n    representation = layers.Dropout(0.5)(representation)\n    # Adiciona MLP.\n    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n    # Classifica.\n    logits = layers.Dense(NUM_CLASSES,activation=\"sigmoid\")(features)\n    # Cria o modelo Keras.\n    model = keras.Model(inputs=inputs, outputs=logits)\n    return model\n","c720cf74":"# Callbacks\n\nmodel_checkpoint = ModelCheckpoint(OUTPUT_DIRECTORY + \"lastbest-0.hdf5\",save_weights_only=True, verbose=1, save_best_only=True)\nearly_stopping = EarlyStopping(patience=STOPPING_PATIENCE, restore_best_weights=True)\ntensorboard = TensorBoard(log_dir=OUTPUT_DIRECTORY, histogram_freq=0, write_graph=True, write_images=False)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.5, patience=LR_PATIENCE, min_lr=0.000003125)\ncsv_logger = CSVLogger(OUTPUT_DIRECTORY + \"training_metrics.csv\")","50aef429":"model = create_vit_classifier()\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=INITIAL_LR), metrics=['categorical_accuracy'])\n\nglobal_epoch = 0\nrestarts = 0\nlast_best_losses = []\nlast_best_epochs = []\nwhile global_epoch < MAX_EPOCH:\n    history = model.fit(\n        train_data_generator,\n        steps_per_epoch=train_image_count \/\/ BATCH_SIZE,\n        epochs=MAX_EPOCH - global_epoch, #alterar depois\n        validation_data=val_data_generator,\n        validation_steps=val_image_count \/\/ BATCH_SIZE,\n        callbacks=[tensorboard, model_checkpoint, early_stopping, reduce_lr, csv_logger],\n        shuffle=False)\n    if early_stopping.stopped_epoch == 0:\n        print(\"Completed training after {} epochs.\".format(MAX_EPOCH))\n        break\n    else:\n        global_epoch = global_epoch + early_stopping.stopped_epoch - STOPPING_PATIENCE + 1\n        print(\"Early stopping triggered after local epoch {} (global epoch {}).\".format(\n            early_stopping.stopped_epoch, global_epoch))\n        print(\"Restarting from last best val_loss at local epoch {} (global epoch {}).\".format(\n            early_stopping.stopped_epoch - STOPPING_PATIENCE, global_epoch - STOPPING_PATIENCE))\n        restarts = restarts + 1\n        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INITIAL_LR \/ 2 ** restarts),\n                      metrics=['categorical_accuracy'])\n        model_checkpoint = ModelCheckpoint(OUTPUT_DIRECTORY + \"lastbest-{}.hdf5\".format(restarts),\n                                           monitor='val_loss',save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n\n# Save last best model info\n# with open(OUTPUT_DIRECTORY + \"last_best_models.csv\", 'w', newline='') as file:\n#     writer = csv.writer(file, delimiter=',')\n#     writer.writerow(['Model file', 'Global epoch', 'Validation loss'])\n#     for i in range(restarts + 1):\n#         writer.writerow([\"lastbest-{}.hdf5\".format(i), last_best_epochs[i], last_best_losses[i]])","e1b78a65":"model.save_weights('.\/checkpoints\/ViT_base_weights')\nmodel_weight_save = ModelCheckpoint(OUTPUT_DIRECTORY + \"model_best_weights.hdf5\",save_weights_only=True, verbose=1, save_best_only=True)","54eebe0a":"from sklearn.metrics import confusion_matrix, classification_report\nfrom keras.models import Model, load_model\n\n# model_load = create_vit_classifier()\n# model_load.load_weights('.\/checkpoints\/ViT_base_weights')\n\n# # Evaluate model on test subset for kth fold\n# predictions = model_load.predict(test_data_generator, test_image_count \/\/ BATCH_SIZE + 1)\n# y_true = test_data_generator.classes\n# y_pred = np.argmax(predictions, axis=1)\n# y_pred[np.max(predictions, axis=1) < 1 \/ 9] = 8  # Assign predictions worse than random guess to negative class\n\n# Evaluate model on test subset for kth fold\n# predictions = model.predict(test_data_generator, test_image_count \/\/ BATCH_SIZE + 1)\n# y_true = test_data_generator.classes\n# y_pred = np.argmax(predictions, axis=1)\n# y_pred[np.max(predictions, axis=1) < 1 \/ 9] = 8  # Assign predictions worse than random guess to negative class","bdfb7399":"predictions = model.predict_generator(test_data_generator, test_image_count \/\/ BATCH_SIZE + 1)\ny_true = test_data_generator.classes\ny_pred = np.argmax(predictions, axis=1)\ny_pred[np.max(predictions, axis=1) < 1 \/ 9] = 8\n\n# Generate and print classification metrics and confusion matrix\nprint(classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES))\nreport = classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES, output_dict=True)\nwith open('classification_report.csv', 'w') as f:\n    for key in report.keys():\n        f.write(\"%s,%s\\n\" % (key, report[key]))\nconf_arr = confusion_matrix(y_true, y_pred, labels=CLASSES)\nprint(conf_arr)\n\n#Get the confusion matrix\ncm = conf_arr\n\n#Now the normalize the diagonal entries\ncm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n#The diagonal entries are the accuracies of each class\ncm.diagonal()","aa096cfc":"print(y_pred)","e4a6632d":"# Declarando a cria\u00e7\u00e3o de patches como uma camada da rede","ccde5914":"## Construindo o modelo do ViT\n\nO modelo ViT consiste de m\u00faltiplos blocos Transformer, onde usamos o `layer.MultiHeadAttetion` como camada de self-attention, aplicando em uma sequ\u00eancia de patches. Os blocos Transformers produzem um tensor: `[batch_size,num_patches,projection_dim]`, que ser\u00e1 processado via uma cabe\u00e7a classificadora, com um softmax para produzir as probabilidades de sa\u00edda.","675c4139":"# Compilando, treinando e avaliando o modelo.","be4224e1":"# Implementando a camada de Patch Encoding\n\nA camada de `PatchEncoder` ir\u00e1 realizar a transforma\u00e7\u00e3o linear de um patch, fazendo a proje\u00e7\u00e3o em um vetor de tamanho `projection_dim`. Junto, ir\u00e1 realizar a adi\u00e7\u00e3o da posi\u00e7\u00e3o de embedding para o vetor projetado.","47d49cd7":"## Setup","d6972932":"# Preparando os Dados","b722dd81":"## Metricas por Classe","bc44dc57":"#  Trabalhando o modelo","e31c352e":"## Introdu\u00e7\u00e3o\n\nUsando o ViT: [Vision Transformer (ViT)](https:\/\/arxiv.org\/abs\/2010.11929)\nmodel por Alexey Dosovitskiy et al. para classifica\u00e7\u00e3o de ervas daninhas no cultivo da soja.\n\nEsse modelo ViT aplica a Arquitetura Transformer com auto-aten\u00e7\u00e3o para sequ\u00eancias de patches de imagens, **SEM** utiliza\u00e7\u00e3o de camadas de convolu\u00e7\u00e3o.\n\nSer\u00e1 necess\u00e1rio o uso do TF Addons:\n[TensorFlow Addons](https:\/\/www.tensorflow.org\/addons\/overview),","5c275b38":"# M\u00e9tricas por Classe","cb509915":"# Implementando a Percep\u00e7\u00e3o de Multi Camada - Multi Layer Perception (MLP)","40de1822":"# Configurando os HyperParameters","2e854964":"# Setando os Dataframes","e8881dfc":"# Implementa\u00e7\u00e3o de uma ViT\n\nAuthor: Lucas Silva"}}