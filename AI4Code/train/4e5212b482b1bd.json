{"cell_type":{"0cbce07b":"code","da00b7e6":"code","8abd22d9":"code","11bf33a7":"code","cc1fafb6":"code","de806e48":"code","7a4e4f16":"code","59cc19f9":"code","6a8a86d1":"code","4cd89c92":"code","9800eeeb":"code","82606519":"code","6af1f789":"code","bc0aa988":"markdown","dd976933":"markdown","843b57f1":"markdown","3ddea2c5":"markdown","c9e2dd22":"markdown","0a584498":"markdown","5274837b":"markdown","012a0af9":"markdown"},"source":{"0cbce07b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/mushroom\"))\n\n# Any results you write to the current directory are saved as output.","da00b7e6":"# Reading dataset\nimport pandas as pd\nimport cv2\nimport numpy as np\nmushroom_info = pd.read_json('..\/input\/mushroom\/mushroom_imgs.json', lines=True)\n\ndef get_images():\n    img_dict = {}\n    for i, path in enumerate(mushroom_info['file_path']):\n        img_dict[i] = cv2.imread('..\/input\/mushroom\/'+path, -1)\n    return img_dict\n# Reading images from the dataset and saving them in a dictionary\nimg_dict = get_images() \nprint(len(img_dict))","8abd22d9":"def resize(img):\n    desired_size = 320\n\n    old_size = img.shape[:2]  \n    ratio = float(desired_size) \/ max(old_size)\n    new_size = tuple([int(x * ratio) for x in old_size])\n\n    img = cv2.resize(img, (new_size[1], new_size[0]))\n\n    delta_w = desired_size - new_size[1]\n    delta_h = desired_size - new_size[0]\n    top, bottom = delta_h \/\/ 2, delta_h - (delta_h \/\/ 2)\n    left, right = delta_w \/\/ 2, delta_w - (delta_w \/\/ 2)\n\n    color = [0, 0, 0]\n    new_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n    return new_img","11bf33a7":"# Resizing all images\nfor img in img_dict:\n    img_dict[img] = resize(img_dict[img])","cc1fafb6":"import matplotlib.pyplot as plt\ndef print_image(index, data=mushroom_info):\n    name = data.iloc[index].name_latin\n    edibility = data.iloc[index].edibility\n    im = img_dict[index]\n    plt.imshow(im)\n    plt.title(name + \" edible= \" + edibility)\n    plt.show()\n    \nprint_image(10)","de806e48":"mushroom_info.edibility.value_counts()","7a4e4f16":"labels = mushroom_info.edibility.isin((\"edible\", \"edible and good\", \"edible and excellent\"))\nlabels = 1*labels\nX = []\ny = []\nfor i in range(len(labels)):\n    y.append(labels[i])\n    X.append(img_dict[i])\n\nX = np.stack(X)\ny = pd.Series(y)\n\n# Now X has all the image matrices, and y has all the labels","59cc19f9":"# Flatten images to pass into the ELM\nflat = X.flatten().reshape(536,307200)","6a8a86d1":"def activation(x):\n    return x * (x>0)#1 \/ (1 + np.exp(-x))\n\ndef MPInverse(h):\n    return np.linalg.pinv(h)\n\nno_of_features = 307200\nno_of_hidden_nodes1 = 200\nno_of_output = 1\n\ninput_data = flat\n\noutput = y\nnp.random.seed(2018)\nbase_bias = 2* np.random.random((1, no_of_hidden_nodes1)) -1\nweight01 = 2 * np.random.random((no_of_features, no_of_hidden_nodes1)) - 1\n\n\ninput_layer = input_data\nbias = np.array([base_bias[0],]*input_data.shape[0])\nH = activation(np.dot(input_layer, weight01) + bias)\nB = np.dot(MPInverse(H),output)\nprint(\"Model Trained\")","4cd89c92":"images = []\nground_truth = np.loadtxt(\"..\/input\/mushroom\/test_img\/gt.txt\")\nfor file in sorted(os.listdir('..\/input\/mushroom\/test_img')):\n    if file.endswith('.jpg'):\n        print(file)\n        img = cv2.imread('..\/input\/mushroom\/test_img\/'+file,-1)\n        if img is not None:\n            images.append(img)\n\nprint(\"Ground truth\")\nprint(ground_truth)","9800eeeb":"def print_image2(img,prediction,actual):\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    title = \"P(edible)= \" + str(prediction) + \" Actual = \" + str(actual)\n    plt.title(title)\n    plt.show()","82606519":"def predict(test_input,g_t):\n    test_img = test_input.flatten().reshape(1,307200)\n    bias_test = np.array([base_bias[0],]*test_img.shape[0])\n    \n    H_test = activation(np.dot(test_img, weight01) + bias_test)\n    T_test = activation(np.dot(H_test,B))\n    \n    print_image2(test_input,T_test,g_t)","6af1f789":"for test,g_t in zip(images,ground_truth):\n    test = resize(test)\n    predict(test,g_t)","bc0aa988":"Predict edibility for test images","dd976933":"Changing labels to binary,\n(edible, edible and good, edible and excellent) = 1\n\n(inedible , poisonous, lethally poisonous, edible when cooked) = 0\n","843b57f1":"Utility function to print results","3ddea2c5":"As dimensions of all input images is not the same, Resizing all images to 320x320 and extra boundries are padded by zeros, Keeping the same aspect ratio","c9e2dd22":"**Preparing dataset**\n\nReading dataset","0a584498":"Fetching test images and ground truth","5274837b":"Function to print image from database","012a0af9":"**Extreme Learning Machine**"}}