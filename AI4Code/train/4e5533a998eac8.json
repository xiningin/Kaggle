{"cell_type":{"c954a0e0":"code","556f9cde":"code","38178897":"code","d8c022c2":"code","4eccc84e":"code","8fb30b72":"code","a46b0496":"code","b55c37df":"code","7d5840ff":"code","f84cd82f":"code","bcd31762":"code","40b011b8":"code","72b0594b":"code","0f45feff":"code","4c3e6864":"code","d2972614":"code","3ba9e2db":"code","968e3292":"code","dab5ebcc":"code","c178b4d3":"code","60e80abf":"code","b083abe6":"code","292a3584":"code","95371d59":"markdown","14372a91":"markdown","f566a03e":"markdown","96f33940":"markdown","246b1894":"markdown","1e083aca":"markdown","8d587cd9":"markdown","9a9b4357":"markdown"},"source":{"c954a0e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nimport math\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","556f9cde":"df = pd.read_csv(\"\/kaggle\/input\/anomaly-detection\/creditcard.csv\")","38178897":"df_train = df[df['Class'] == 0]\ndf_anamoly = df[df['Class'] == 1].reset_index().drop(columns = 'index')\ndf_test = df_anamoly.iloc[:int(len(df_anamoly)\/2),:]\ndf_val = df_anamoly.iloc[int(len(df_anamoly)\/2+1):,:]","d8c022c2":"Mean_Value_list = []\nfor col in df_train.columns:\n    if(col != 'Class' ):\n        Mean_Value_list.append(df_train[col].mean())\nMean_Value_array = np.asarray(Mean_Value_list)","4eccc84e":"Vari_Value_list = []\nfor col in df_train.columns:\n    if(col != 'Class' ):\n        Vari_Value_list.append(df_train[col].var())\nVari_Value_array = np.asarray(Vari_Value_list)","8fb30b72":"X_Val = np.array(df_val.iloc[:,:30])\nY_Val = np.array(df_val.iloc[:,30:31])","a46b0496":"def probaDis (X_test,mu_array,sigma2_array):\n    probaDis_lst = []\n    from scipy.stats import norm\n    pdfs_array = norm.pdf(X_test,mu_array,sigma2_array**0.5)\n    for pdf in pdfs_array :\n        probaDis_lst.append(np.prod(pdf))              \n    return np.array(probaDis_lst)        ","b55c37df":"probaDis_array = probaDis(X_Val,Mean_Value_array,Vari_Value_array)","7d5840ff":"Best_eps = np.max(probaDis_array)\/1000\nY_pred =probaDis_array<Best_eps\nf1_score(Y_Val,Y_pred)","f84cd82f":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix \nsns.heatmap(confusion_matrix(Y_Val,Y_pred),annot = True,fmt=\"d\")","bcd31762":"X_test = np.array(df_test.iloc[:,:30])\nY_test = np.array(df_test.iloc[:,30:31])","40b011b8":"probaDis_test_array = probaDis(X_test,Mean_Value_array,Vari_Value_array)","72b0594b":"Y_pred_test =probaDis_test_array<Best_eps\nf1_score(Y_test,Y_pred_test)","0f45feff":"sns.heatmap(confusion_matrix(Y_test,Y_pred_test),annot = True,fmt=\"d\")","4c3e6864":"TrainingData = df_train.loc[:,:'Amount']\nTrainingData =np.array(TrainingData)","d2972614":"CovarianceMatrix = np.cov(TrainingData,rowvar= False)","3ba9e2db":"def est_gaus_par(X):\n    mu = np.mean(X,axis=0)\n    sig = np.std(X,axis=0)\n    return mu,sig\n\n\ndef est_mult_gaus(X,mu,sigma):\n    m = len(mu)\n    sigma2 = np.diag(sigma)\n    X = X-mu.T\n    p = 1\/((2*np.pi)**(m\/2)*np.linalg.det(sigma2)**(0.5))*np.exp(-0.5*np.sum(X.dot(np.linalg.pinv(sigma2))*X,axis=1))\n\n    return p\n\nmu,sigma = est_gaus_par(X_Val)\np_val_array = est_mult_gaus(X_Val, mu, sigma)","968e3292":"#stepsize = (np.max(p_val_array) - np.min(p_val_array))\/1000\n#epsVec = np.arange(np.min(p_val_array), np.max(p_val_array), stepsize)","dab5ebcc":"#F1score = 0\n#BesEps = 0\n#for eps in epsVec :\n    #Y_predt =p<eps\n    #if(f1_score(Y_Val,Y_predt)>F1score) :\n        #BesEps= eps\n        \n#print(BesEps)\n#print(F1score)","c178b4d3":"Best_threhold = p_val_array.max()\/1000","60e80abf":"Y_predt =p_val_array<Best_threhold\nprint('F1Score : ',f1_score(Y_Val,Y_predt))\nprint('PrecisionScore : ',precision_score(Y_Val,Y_predt))\nprint('RecallScore : ',recall_score(Y_Val,Y_predt))","b083abe6":"mu,sigma = est_gaus_par(X_test)\np_test = est_mult_gaus(X_test, mu, sigma)","292a3584":"Y_pred_test =p_test<Best_threhold\nprint('F1Score : ',f1_score(Y_test,Y_pred_test))\nprint('PrecisionScore : ',precision_score(Y_test,Y_pred_test))\nprint('RecallScore : ',recall_score(Y_test,Y_pred_test))","95371d59":"# UniVariate Gaussion Distribution","14372a91":"Pic Credits : Andrew Ng","f566a03e":"# MultiVariate Gaussian Distribution","96f33940":"Pic Credits : Andrew Ng","246b1894":"I am little bit skiptical about process of  chossing the threshold value of probability through which a example can be classsified as anamoly.\nI have tried differents methods could not one that shows some result.\nIf any please let me know in the comments.","1e083aca":"# Thank You","8d587cd9":"![image.png](attachment:image.png)","9a9b4357":"![image.png](attachment:image.png)"}}