{"cell_type":{"cdd00252":"code","7d548e77":"code","58e6584a":"code","23a34a34":"code","33fd8c93":"code","0bc36d36":"code","9cf3c5d5":"code","e0248923":"code","d6b40ca6":"code","b58b65e7":"code","b0140a4b":"code","f10bda28":"code","92034ad0":"code","06a899c0":"code","50cf4182":"code","9e8607cf":"code","424f1b5f":"code","3621dc8d":"code","5a81983b":"code","8e74ac65":"code","e8e09473":"markdown","d6c854a2":"markdown","72ca4a79":"markdown","00baa722":"markdown","ce25bd8b":"markdown","5d9573f4":"markdown","79f7a635":"markdown","77c2f654":"markdown","9596bc87":"markdown","01040fd8":"markdown","1e2468b7":"markdown","c5e1ee9e":"markdown"},"source":{"cdd00252":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d548e77":"# Additional packages\nimport category_encoders as encoders\nfrom sklearn.preprocessing import StandardScaler\nfrom pandas.api.types import is_numeric_dtype\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn import model_selection, metrics, naive_bayes\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC ","58e6584a":"# Read the data\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')","23a34a34":"print(df_train.info())\nprint('Size of Train data set = {}'.format(df_train.shape))","33fd8c93":"# Delete columns with unique identifiers\ncol_lst = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ndf_train.drop(col_lst, axis = 1, inplace=True)\nprint(df_train.info())","0bc36d36":"df_train.isnull().sum()","9cf3c5d5":"df_train['Sex'].value_counts()","e0248923":"#fare_median = df_train[(df_train['Fare']>0) & (df_train['Fare'].isnull() == False)]['Fare'].median()\nage_median = df_train[(df_train['Age']>0) & (df_train['Age'].isnull() == False)]['Age'].median()\nprint('Median = {}'.format(age_median))\nprint('No. of records with non-null Age = {}'.format(df_train[(df_train['Age']>0) & (df_train['Age'].isnull() == False)]['Age'].count()))\nprint('===={} of Median {} with {} Null Records===='.format('Age', age_median, df_train[(df_train['Age'].isnull() == True)]['Survived'].count()))\ndf_train['Age'].fillna(age_median, inplace=True)","d6b40ca6":"numerical = ['Age', 'SibSp', 'Parch', 'Fare']\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfor col in numerical:\n    if is_numeric_dtype(df_train[col]) == True:\n        df_train[df_train[col]>0][col].plot.hist(bins=50, grid=True, legend=None)\n        plt.title(col)\n        plt.show()","b58b65e7":"CATBoostENCODE = encoders.CatBoostEncoder()\ncategorical = ['Pclass', 'Sex', 'Embarked']\n\n# Cast teh Pclass from integer to string so that we can apply the categorical encoding later\ndf_train['Pclass'] = df_train['Pclass'].astype(str)\n\ndf_target = df_train['Survived'].astype(str)\n\n# Use CatBoost to encode the categorical values\nencoder_cat = CATBoostENCODE.fit_transform(df_train[categorical], df_target)\nencoded_cat = pd.DataFrame(encoder_cat)\nprint(encoded_cat.head(10))","b0140a4b":"df_model_data = df_train.copy()\ndf_model_data.drop(categorical, axis = 1, inplace=True)\ndf_model_data = pd.concat([df_model_data, encoded_cat], axis=1)\ndf_model_data.info()","f10bda28":"def get_oversample (training, testing):\n\n    smote = SMOTE()\n\n    X_train, X_test, Y_train, Y_test = model_selection.train_test_split(training, testing, test_size=0.3)\n    X_smote, Y_smote = smote.fit_resample(X_train, Y_train)\n    print(\"length of original data is \",len(training))\n    print(\"Proportion of True data in original data is \",len(Y_train[Y_train['Survived']==1])\/len(Y_train))\n    print(\"Proportion of False data in original data is \",len(Y_train[Y_train['Survived']==0])\/len(Y_train))\n    print(\"length of oversampled data is \",len(X_smote))\n    print(\"Proportion of True data in oversampled data is \",len(Y_smote[Y_smote['Survived']==1])\/len(Y_smote))\n    print(\"Proportion of False data in oversampled data is \",len(Y_smote[Y_smote['Survived']==0])\/len(Y_smote))\n   \n    return X_smote, Y_smote, X_train, X_test, Y_train, Y_test","92034ad0":"Y = df_model_data.iloc[:,0:1]\nX = df_model_data.iloc[:,1:]\nX_smote, Y_smote, X_train, X_test, Y_train, Y_test = get_oversample(X, Y)","06a899c0":"# parameter list\np_cv = 5\np_score = 'accuracy'","50cf4182":"# Maximum number of depth in each tree:\nmax_depth = [7,8,9,10]\n# Minimum number of samples to consider at each leaf node:\nmin_samples_leaf = [10,12,15]## Decision Tree\n# Minimum number of samples to consider to split a node:\nmin_samples_split = [10,12,15]\n# No. of estimators\nestimators = [50, 100, 150]","9e8607cf":"clf = RandomForestClassifier()\n\nforest_params_grid={'n_estimators':estimators,\n           'max_depth':max_depth,\n           'min_samples_split':min_samples_split,\n           'min_samples_leaf':min_samples_leaf  }\n\ncv = model_selection.StratifiedKFold(n_splits=p_cv, random_state=5463, shuffle=True)\n\nmodel = model_selection.GridSearchCV(clf, forest_params_grid, cv=cv, scoring=p_score, n_jobs=-1, verbose=1)","424f1b5f":"model.fit(X_smote, Y_smote.values.ravel())\nprint(model.best_params_)\nprint(model.best_estimator_)","3621dc8d":"predicted_test = pd.DataFrame(model.predict(X_test))\npredicted_train = pd.DataFrame(model.predict(X_train))\nprint('=============================================')\nprint('Scoring Metrics for Random Forest (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for Random Forest (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","5a81983b":"# Read the data\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_id = df_test.iloc[:,0:1]\n\n# Delete columns with unique identifiers\ncol_lst = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ndf_test.drop(col_lst, axis = 1, inplace=True)\n\n# Replace null age with median \ndf_test['Age'].fillna(age_median, inplace=True)\ndf_test['Fare'].fillna(0, inplace=True)\n\n# Convert the data type of Pclass from ingeter to string value\ndf_test['Pclass'] = df_test['Pclass'].astype(str)\n\n# Categorical variable encoding\nencoder_cat = CATBoostENCODE.transform(df_test[categorical])\nencoded_cat = pd.DataFrame(encoder_cat, columns =categorical)\n\n# Prepare the dataset\ndf_test.drop(categorical, axis = 1, inplace=True)\ndf_test = pd.concat([df_test, encoded_cat], axis=1)  \n","8e74ac65":"# Prediction\np_model = model.predict(df_test)\ndf_rst = pd.concat([df_id, pd.DataFrame(p_model, columns = ['Survived'])], axis = 1)\ndf_rst.to_csv(\"submission.csv\",index=False)\nprint('Done!')","e8e09473":"# Oversampling","d6c854a2":"# Explortory Data Analysis","72ca4a79":"This notebook is for submission to the Titanic. This is my first notebook to join Kaggle competition. There may be some incorrection, feel free to comment and give me advice.\n\n## Summary\nCheck if there are any null values in the features.  If do so, fill the missing value with median of the features.\nReview the distribution of variables\nUse the Catboost to encode the categorical features into numerical representation based on its distribution to the target.\nApply oversampling to equalize the size of true and false cases\nUse GridSearchCV to hyperparameterize the Random Forest\nGet the optimal hyperparameters for cross-validation and data submission\n","00baa722":"# Introduction","ce25bd8b":"## Check if there is any missing values","5d9573f4":"## Prepare data for modelling","79f7a635":"# Data encoding","77c2f654":"## Distribution of numerical variables","9596bc87":"# Model - Random Forest","01040fd8":"# Training and validation data","1e2468b7":"## Fill the null value with Median","c5e1ee9e":"# Data Submission"}}