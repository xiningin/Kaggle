{"cell_type":{"61f23a16":"code","05222b68":"code","acac9010":"code","fe135e44":"code","d4033060":"code","68618613":"code","b8259c04":"code","26ac4436":"code","6191db2e":"markdown","7904b836":"markdown"},"source":{"61f23a16":"import numpy as np\nfrom scipy.spatial.distance import cdist\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans","05222b68":"# calculate Euclidean distance\ndef euclDistance(vector1, vector2):\n    return np.sqrt(np.sum(np.power(vector2 - vector1, 2)))","acac9010":"# init centroids with random samples  \ndef initCentroids(dataSet, k):\n    numSamples, dim = dataSet.shape\n    index = np.random.uniform(0, numSamples, k).astype(int)\n    centroids = dataSet[index]\n    return centroids","fe135e44":"# show your cluster (only available with 2-D data) \ndef showCluster(dataSet, k, centroids, clusterAssment):  \n    numSamples, dim = dataSet.shape\n    if dim != 2:\n        print (\"Sorry! I can not draw because the dimension of your data is not 2!\")  \n        return 1  \n  \n    mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']  \n    if k > len(mark):\n        print (\"Sorry! Your k is too large!\")  \n        return 1\n\n    # draw all samples\n    for i in range(numSamples):\n        # assign colors for samples\n        markIndex = int(clusterAssment[i, 0])\n        plt.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex])\n\n    mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '<b', 'pb']  \n    # draw the centroids\n    for i in range(k):\n        plt.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize = 12)  \n\n    plt.show()","d4033060":"# k-means cluster\ndef kmeans(dataSet, k):  \n    numSamples = dataSet.shape[0]\n    # store which cluster this sample belongs to\n    clusterAssment = np.zeros([numSamples, 1])\n    clusterChanged = True\n\n    ## step 1: init centroids\n    centroids = initCentroids(dataSet, k)\n\n    epoch = 0\n    while clusterChanged:\n        clusterChanged = False\n        ## for each sample\n        for i in range(numSamples):\n            minDist  = float('inf')\n            minIndex = 0\n            # for each centroid\n            # step 2: find the centroid who is closest  \n            for j in range(k):  \n                distance = euclDistance(centroids[j, :], dataSet[i, :])  \n                if distance < minDist:  \n                    minDist  = distance  \n                    minIndex = j  \n              \n            ## step 3: update its cluster \n            if clusterAssment[i, 0] != minIndex:\n                clusterChanged = True\n                clusterAssment[i, :] = minIndex\n\n        ## step 4: update centroids\n        for j in range(k):\n            pointsInCluster = dataSet[np.nonzero(clusterAssment[:, 0] == j)[0], :]\n            centroids[j, :] = np.mean(pointsInCluster, axis=0)\n        \n        if epoch < 5:\n            print('epoch: ' + str(epoch))\n            showCluster(dataSet, k, centroids, clusterAssment)\n        epoch = epoch + 1\n        \n    print ('Congratulations, cluster complete!')\n    return centroids, clusterAssment","68618613":"# k-means cluster\ndef kmeans_simple(dataSet, k):\n    numSamples = dataSet.shape[0]\n    clusterChanged = True\n    clusterAssment = np.zeros([numSamples, 1])\n    \n    ## step 1: init centroids\n    centroids = initCentroids(dataSet, k)\n\n    while clusterChanged:\n        clusterChanged = False\n        # calculate pairwise distance\n        distance = cdist(dataSet, centroids)\n\n        # find the closest centroid for each sample\n        tmpIndex = np.reshape(np.argmin(distance, 1), [-1, 1])\n        \n        # if any index changes, continue\n        if (tmpIndex != clusterAssment).any():\n            clusterChanged = True\n\n        # update clusterAssment\n        clusterAssment = tmpIndex\n\n        # update centroids\n        for j in range(k):\n            pointsInCluster = dataSet[np.nonzero(clusterAssment == j)[0], :]\n            centroids[j, :] = np.mean(pointsInCluster, 0)\n\n    print ('Congratulations, cluster complete!')  \n    return centroids, clusterAssment","b8259c04":"def customReadFile(fileName):\n    fileIn = open(fileName, 'r')\n    dataSet = []\n    for line in fileIn.readlines():\n        temp=[]\n        lineArr = line.strip().split('\\t')\n        temp.append(float(lineArr[0]))\n        temp.append(float(lineArr[1]))\n        dataSet.append(temp)\n    fileIn.close()\n    return np.mat(dataSet)","26ac4436":"## step 1: load data\nfileIn = '..\/input\/testSet.txt'\nprint ('Step 1: Load data ' + fileIn + '...')\ndataSet = customReadFile(fileIn)\nprint('Number of samples: ' + str(dataSet.shape[0]))\n\n## step 2: clustering...  \nprint (\"Step 2: clustering...\"  )\nk = 4\ncentroids, clusterAssment = kmeans(dataSet, k)\n# centroids, clusterAssment = kmeans_simple(dataSet, k)\n# clusteringResult = KMeans(n_clusters=k).fit(dataSet)\n# clusterAssment = np.reshape(clusteringResult.labels_, [-1, 1])\n# centroids = clusteringResult.cluster_centers_\n\n## step 3: show the result\nprint (\"Step 3: show the result...\"  )\nshowCluster(dataSet, k, centroids, clusterAssment)","6191db2e":"# PlayGround\nhttp:\/\/stanford.edu\/class\/ee103\/visualizations\/kmeans\/kmeans.html\n# Code\nhttps:\/\/github.com\/wojiushimogui\/kmeans","7904b836":"# Kmeans\nSource: http:\/\/stanford.edu\/~cpiech\/cs221\/handouts\/kmeans.html\n\nK-Means is one of the most popular \"clustering\" algorithms.K-Means finds the best centroids by alternating between (1) assigning data points to clusters based on the current centroids (2) chosing centroids (points which are the center of a cluster) based on the current assignment of data points to clusters.\n## The Algorithm\nIn the clustering problem, we are given a training set $x^{(1)},...,x^{(m)}$, and want to group the data into a few cohesive \"clusters.\" Here, we are given feature vectors for each data point $x^{(i)}\u2208R^n$ as usual; but no labels $y^{(i)}$ (making this an unsupervised learning problem). Our goal is to predict $k$ centroids and a label $c^{(i)}$ for each datapoint. The k-means clustering algorithm is as follows:\n1. Initial cluster centroids ${u_1},...,{u_k}\u2208R^n$ randomly.\n2. Repeat until Convergence:\n    \n    (1) For every $i$, set $c^{(i)}:=arg{min}_j{||x^{(i)}-u_j||}^2$\n    \n    (2) For each $j$, set $u_j:=\\frac{\\sum_{i=1}^m {1{(c^{(i)}=j)}x^{(i)}}}{\\sum_{i=1}^m {1{(c^{(i)}=j)}}}$"}}