{"cell_type":{"2c93776f":"code","00a9782b":"code","2c1c9f01":"code","d204cc40":"code","e6a04ea1":"code","12e95c5a":"code","6036f28f":"code","7d714b3d":"code","a994251f":"code","2c417eef":"code","4fc0b620":"code","a5546df0":"code","8c462d74":"code","249cd268":"code","07c9c505":"code","510269bf":"code","fa330330":"code","90c93979":"code","51240b8e":"code","6ffb1ca5":"code","55d9687b":"code","59527a77":"code","adbff4d2":"code","02f2f54e":"code","7b06003c":"code","8418a974":"code","f6bfd37b":"code","5a2f5986":"code","dfc0b2be":"markdown","456ca9c0":"markdown","5157e2c4":"markdown","678ab6e7":"markdown"},"source":{"2c93776f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00a9782b":"import seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.impute import KNNImputer\nfrom sklearn.ensemble import RandomForestClassifier\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\nfrom sklearn.model_selection import GridSearchCV","2c1c9f01":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","d204cc40":"def get_num_pass_fare(data):\n    \n    num_pass = data.groupby('Ticket').agg({'PassengerId': 'count'}).reset_index()\n    num_pass.rename(columns = {'PassengerId': 'num_pass_per_ticket'}, inplace=True)\n    data = data.merge(num_pass, how = 'inner', on = 'Ticket')\n    data['fare_percap'] = data['Fare']\/data['num_pass_per_ticket']\n    data['surv_fare_percap'] = ''\n    data.loc[ data.num_pass_per_ticket == 1, 'surv_fare_percap'] = 1\n    data.loc[ (data.num_pass_per_ticket >1) & (data.num_pass_per_ticket <= 4), 'surv_fare_percap'] = 2\n    data.loc[ (data.num_pass_per_ticket == 5) & (data.num_pass_per_ticket == 6), 'surv_fare_percap'] = 3\n    data.loc[ data.num_pass_per_ticket >= 7, 'surv_fare_percap'] = 4\n    \n    return data\ntrain_data = get_num_pass_fare(train_data)\ntest_data = get_num_pass_fare(test_data)","e6a04ea1":"axes = sns.factorplot('surv_fare_percap','Survived', \n                      data=train_data, aspect = 2.5, )","12e95c5a":"## Get deck\n\ndef get_deck(data):\n    index = list(data[data.Cabin.notna()]['Cabin'].index)\n    data['deck'] = '' \n    for i in index:\n        deck = data['Cabin'].iloc[i][0]\n        data['deck'].iloc[i] = deck\n    data.deck.replace({ \"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, 'T':8, \"U\": 9,'':10}, inplace=True)\n    data.drop('Cabin',1, inplace=True)\n    data.deck = data.deck.astype(int)\n    \n    return data\ntrain_data = get_deck(train_data)\ntest_data = get_deck(test_data)","6036f28f":"train_data.deck.value_counts()","7d714b3d":"axes = sns.factorplot('deck','Survived', \n                      data=train_data, aspect = 2.5, )","a994251f":"axes = sns.factorplot('Embarked','Survived', \n                      data=train_data, aspect = 2.5, )","2c417eef":"def encode_embarked_and_sex(data):\n    data.Embarked.replace({'S':0,'C':1,'Q':2}, inplace=True)\n    data.Sex.replace({'male':1,'female':2}, inplace=True)\n    data.Embarked.fillna(0,inplace=True)\n    data.Embarked = data.Embarked.astype(int)\n    data['interaccion_embarked_sex'] = data.Embarked*data.Sex \n    \n    return data\ntrain_data = encode_embarked_and_sex(train_data)\ntest_data = encode_embarked_and_sex(test_data)","4fc0b620":"train_data.info()","a5546df0":"train_data.drop(['PassengerId', 'Ticket'], axis=1, inplace=True)\ntest_data.drop(['Ticket'], axis=1, inplace=True)","8c462d74":"train_data.surv_fare_percap.replace({'':3}, inplace=True)\ntest_data.surv_fare_percap.replace({'':3}, inplace=True)\n","249cd268":"def obtainTitle(name):\n    return name[name.find(',')+2:name.find('.')]\ntrain_data['Title'] = ''\ntest_data['Title'] = ''\ntrain_data['Title_group'] = ''\ntest_data['Title_group'] = ''\n\ndef genTitle(data):\n    for i in range(len(data)):\n        if data[\"Name\"][i] != None:\n            data['Title'][i] = obtainTitle(data[\"Name\"][i])\n        else:\n            data['Title'][i] = None\n            \n    data['Title'] = np.where(data['Title']==\"Mlle\", \"Miss\", data['Title'])\n    data['Title'] = np.where(data['Title']==\"Ms\", \"Miss\", data['Title'])\n    data['Title'] = np.where(data['Title']==\"Mme\", \"Mrs\", data['Title'])\n    data['Title'] = np.where(data['Title']==\"Dona\", \"Mrs\", data['Title'])\n    data['Title'] = np.where(data['Title']==\"Don\", \"Mr\", data['Title'])\n    for i in range(len(data)):\n        if data['Title'][i] == \"Miss\":\n            data['Title_group'][i] = 0\n        elif data['Title'][i] == \"Mrs\":\n            data['Title_group'][i] = 1\n        elif data['Title'][i] == \"Mr\":\n            data['Title_group'][i] = 2\n        elif data['Title'][i] == None:\n            data['Title_group'][i] = None\n        else:\n            data['Title_group'][i] = 3    \n    \ngenTitle(train_data)\ngenTitle(test_data)","07c9c505":"train_data.drop(['Name', 'Title'], axis=1, inplace=True)\ntest_data.drop(['Name', 'Title'], axis=1, inplace=True)","510269bf":"train_data.info()","fa330330":"## Impute missings Age with KNN, k = 5 nearest neighbours\nimputer = KNNImputer(n_neighbors=5)\ntest_data.iloc[:, :] = imputer.fit_transform(test_data)\ntrain_data.iloc[:, :] = imputer.fit_transform(train_data)","90c93979":"def get_grupo_etario(data):\n    data.dropna(0, inplace=True)\n    data['age_group'] = ''\n    data.loc[data.Age <=10, 'age_group' ] = 1\n    data.loc[(data.Age >10) & (data.Age <=18) , 'age_group' ] = 2\n    data.loc[(data.Age >18) & (data.Age <= 28) , 'age_group' ] = 3\n    data.loc[(data.Age >28) & (data.Age <= 40) , 'age_group' ] = 4\n    data.loc[(data.Age >40) & (data.Age <= 48) , 'age_group' ] = 5\n    data.loc[(data.Age >48) & (data.Age <= 65) , 'age_group' ] = 6\n    data.loc[(data.Age >65) , 'age_group' ] = 7\n    \n    data.drop('Age', 1, inplace=True)\n    data.age_group = data.age_group.astype(float)\n    data['interaccion_age_sex'] = data.age_group * data.Sex\n    data['interaccion_age_sex'] = data['interaccion_age_sex'].astype(float)\n    \n    return data\n\ntrain_data = get_grupo_etario(train_data)\ntest_data = get_grupo_etario(test_data)","51240b8e":"axes = sns.factorplot('age_group','Survived', \n                      data=train_data, aspect = 2.5, )","6ffb1ca5":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.histplot(data=train_data, x=\"num_pass_per_ticket\", hue = 'Survived')","55d9687b":"train_data.info()","59527a77":"## Heat map for our features\ndataplot = sns.heatmap(train_data.corr(), cmap=\"YlGnBu\", annot=True)\n  \n# displaying heatmap\nplt.show()","adbff4d2":"def scale_data_minmax(data):\n    from sklearn.preprocessing import MinMaxScaler\n    # perform a robust scaler transform of the dataset\n    trans = MinMaxScaler()\n    data = trans.fit_transform(data)\n\n    return data\n\ndef scale_data_standard(data):\n    from sklearn.preprocessing import StandardScaler\n    # perform a robust scaler transform of the dataset\n    trans = StandardScaler()\n    data = trans.fit_transform(data)\n\n    return data\n","02f2f54e":"def get_test_train(tran_data, test_data, scale = False, minmax = False):\n    \n    train_data.Pclass = train_data.Pclass.astype(object)\n    test_data.Pclass = test_data.Pclass.astype(object)\n\n    features = ['Sex', 'Pclass', 'Embarked', 'surv_fare_percap','fare_percap', 'deck', 'interaccion_embarked_sex', 'age_group', 'interaccion_age_sex', 'Title_group']\n\n    y_train = train_data['Survived']\n    \n    X = pd.get_dummies(train_data[features])\n    X_test = pd.get_dummies(test_data[features])\n    \n    if scale:\n        if minmax:\n            X = scale_data_minmax(X)\n            X_test = scale_data_minmax(X_test)\n        else:\n            X = scale_data_standard(X)\n            X_test = scale_data_minmax(X_test)\n\n\n    return X, X_test, y_train\n\n","7b06003c":"X, X_test_final, y_train = get_test_train(train_data, test_data, scale = True, minmax = True)\nprint(y_train.shape, X.shape, X_test_final.shape)","8418a974":"X_train_split, X_test_split, y_train_split, y_test_split = train_test_split( X, y_train, test_size=0.25, stratify = y_train, random_state=42)\n","f6bfd37b":"import catboost as cb\nmodel_cb = cb.CatBoostClassifier(loss_function='Logloss',  \n                              eval_metric='Accuracy')\ngrid = {'learning_rate': [0.03, 0.1],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5],\n        'iterations': [50, 100, 150, 200, 300]}\nmodel_cb.grid_search(grid, X, y_train, cv=5, partition_random_seed=3,stratified=True)","5a2f5986":"predictions = model_cb.predict(X_test_final)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.PassengerId = output.PassengerId.astype(int)\noutput.Survived = output.Survived.astype(int)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","dfc0b2be":"# Data Transformation","456ca9c0":"# EDA","5157e2c4":"# Model Training","678ab6e7":"# Submission file"}}