{"cell_type":{"d57b63ac":"code","5425ba0e":"code","434d55b0":"code","4cb6e15a":"code","525d5573":"code","8eeb0781":"code","f0e670af":"code","59740fe3":"code","e44a875d":"code","acf30342":"code","978cc7fb":"code","c7a27b58":"code","c35b1ab8":"code","6ec691f4":"code","04a67fcb":"code","7bb14061":"code","099a32a9":"code","ee597eee":"code","0ab2a4df":"code","a11ea124":"code","e38ea7c4":"code","6b21264b":"code","47031e60":"code","01be55cf":"code","88f5b851":"code","5b7ff261":"code","5faa64a6":"code","52d8f618":"code","605df52e":"code","804a24c5":"code","24506566":"code","40a7dbf1":"code","3b13a822":"code","1545e122":"code","3a80a4d7":"code","021cb3fc":"code","0392c072":"code","ee25afd2":"code","990c1826":"code","d2f0f433":"code","c0e19dab":"code","a3a21aca":"code","324348c7":"code","b592fd82":"code","a7845fbf":"code","afdf5b33":"code","e3782ee3":"code","99c16285":"code","0647583d":"code","346138e5":"code","f5b9451e":"code","21bbf5d1":"code","71ef566c":"markdown","d837adf0":"markdown","78bff9f2":"markdown","113b85f7":"markdown","864871b1":"markdown","02ed90db":"markdown","d608f113":"markdown","f03d4ce6":"markdown","76cb8c48":"markdown","2d1db04f":"markdown","c6742a33":"markdown","3893f926":"markdown","5f78743b":"markdown","cc6c000f":"markdown","6ff09afd":"markdown","ce0014e2":"markdown","fe454db2":"markdown","64b21945":"markdown"},"source":{"d57b63ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5425ba0e":"# \u6839\u636e\u6253\u5370\u51fa\u7684\u6587\u4ef6\u8def\u5f84\uff0c\u5c06\u6587\u4ef6\u8bfb\u53d6\u8fdb\u5185\u5b58\nsample_submission = pd.read_csv('\/kaggle\/input\/california-house-prices\/sample_submission.csv')\ntrain_data = pd.read_csv('\/kaggle\/input\/california-house-prices\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/california-house-prices\/test.csv')","434d55b0":"# \u6211\u4eec\u5148\u770b\u4e00\u4e0b\u8fd9\u4e09\u4e2a\u6570\u636e\u957f\u4ec0\u4e48\u6837\nsample_submission.shape, train_data.shape, test_data.shape","4cb6e15a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\nplt.rcParams['font.sans-serif'] = ['SimHei']  # \u7528\u6765\u6b63\u5e38\u663e\u793a\u4e2d\u6587\u6807\u7b7e\nplt.rcParams['axes.unicode_minus'] = False    # \u7528\u6765\u6b63\u5e38\u663e\u793a\u8d1f\u53f7\npd.set_option('display.max_columns', None)    # \u663e\u793a\u6240\u6709\u5217\npd.set_option('display.max_rows', 200)        # \u6700\u591a\u663e\u793a200\u884c","525d5573":"train_copy = train_data.copy()\ntest_copy = test_data.copy()","8eeb0781":"train_copy[:20]","f0e670af":"train_nan = pd.DataFrame(train_data.isnull().sum(), columns=['nan_sum'])\ntrain_nan['percentage %'] = train_nan['nan_sum'] \/ train_data.shape[0] * 100\ntrain_nan","59740fe3":"# test data missing\ntest_nan = pd.DataFrame(test_data.isnull().sum(), columns=['nan_sum'])\ntest_nan['percentage %'] = test_nan['nan_sum'] \/ test_data.shape[0] * 100\ntest_nan","e44a875d":"colormap = plt.cm.viridis\nplt.figure(figsize = (20,20))\nsns.heatmap(train_copy.drop(['Id','Zip'],axis=1).corr(), square = True, cmap = colormap, \n            linecolor = 'white', annot = True)\nplt.show()","acf30342":"train_copy['City'].value_counts()[:20]","978cc7fb":"## city factorize\ntrain_copy['city id'] = pd.factorize(train_copy['City'])[0]\n\nplt.figure(figsize = (20, 6))\nsns.scatterplot(data = train_copy, x = 'city id', y = 'Sold Price')\nplt.show()","c7a27b58":"## \u63d0\u53d6bedrooms \u9664\u53bb\u5b57\u7b26\u4e32\u4e4b\u5916\u7684bedrooms\u5206\u5e03\n## \u53d1\u73b0 \u5367\u5ba4\u4e2a\u6570 \u5747\u503c\u4e3a3\ntrain_copy['bedroom num'] = train_copy['Bedrooms'].fillna(24)\ntrain_copy['bedroom num'] = train_copy['bedroom num'].replace('[a-zA-Z]', 24, regex=True)\ntrain_copy['bedroom num'] = pd.Series(train_copy['bedroom num'], dtype=np.int)\ntrain_bed_df = train_copy[train_copy['bedroom num'] != 24]\ntrain_bed_df['bedroom num'].describe()","c35b1ab8":"plt.figure(figsize = (20,5))\nsns.boxplot(x = train_bed_df['bedroom num'])\nplt.show()","6ec691f4":"plt.figure(figsize=(12,6))\nsns.scatterplot(data=train_bed_df, x='bedroom num', y='Sold Price')\nplt.show()","04a67fcb":"train_bed_df[['bedroom num', 'Sold Price']].corr()","7bb14061":"## \u63a5\u4e0b\u6765\u628atrain data\u4e0a\u7684bedroom_num==24\u7684\u66ff\u6362\u4e3a3\ntrain_copy['bedroom num'] = train_copy['bedroom num'].replace(24, 3)\ntrain_copy[['bedroom num','Sold Price']].corr()","099a32a9":"# price per bedroom\ntrain_copy['price per bedroom'] = train_copy['Listed Price'] \/ (train_copy['bedroom num'] + 1)\n\n# price per bathroom\ntrain_copy['price per bathroom'] = train_copy['Listed Price'] \/ (train_copy['Bathrooms'] + 1)\n\n# price per full bathrooms\ntrain_copy['price per fullbath'] = train_copy['Listed Price'] \/ (train_copy['Full bathrooms'] + 1)\n\n# total room\ntrain_copy['total room'] = train_copy['bedroom num'] + train_copy['Bathrooms']\n\n# price per room\ntrain_copy['price per room'] = train_copy['Listed Price'] \/ (train_copy['total room'] + 1)\n\n# \u67e5\u770b\u76f8\u5173\u7cfb\u6570\ntrain_copy[['Sold Price','price per bedroom','price per bathroom','price per fullbath','total room','price per room']].corr()","ee597eee":"train_copy['listed on year'] = train_copy['Listed On'].str.extract(r'(\\d{4})')\ntrain_copy['listed on year']","0ab2a4df":"figure, ax = plt.subplots(1,2,figsize = (20,6))\nsns.scatterplot(data = train_copy, x = 'listed on year', y = 'Sold Price', ax = ax[0])\nsns.boxplot(data = train_copy, x = 'listed on year', y = 'Sold Price', ax = ax[1])\nplt.show()","a11ea124":"# train_copy['listed on month'] = train_copy['Listed On'].str.extract(r'\\d{4}-(\\d{2})-\\d{2}')\n# train_copy['listed on month']","e38ea7c4":"# train_copy['listed on day'] = train_copy['Listed On'].str.extract(r'\\d{4}-\\d{2}-(\\d{2})')\n# train_copy['listed on day']","6b21264b":"# \u586b\u8865\u4e4b\u524d\u76f8\u5173\u6027\ntrain_copy['score sum'] = train_copy['Elementary School Score'] + train_copy['Middle School Score'] + train_copy['High School Score']\ntrain_copy[['score sum', 'Sold Price']].corr()","47031e60":"train_copy['score sum'].describe()","01be55cf":"## use random forest model to fill missing values\nfrom sklearn.ensemble import RandomForestRegressor\n\nscore_df = train_copy[['score sum','Elementary School Score','Middle School Score','High School Score']]\nscore_notnull_df = score_df.loc[(score_df['score sum'].notnull())]\nscore_isnull_df = score_df.loc[(score_df['score sum'].isnull())]\nscore_X = score_notnull_df.values[:, 1:]\nscore_Y = score_notnull_df.values[:, 0]\n\nfor col in ['Elementary School Score','Middle School Score','High School Score']:\n    score_isnull_df[col] = score_isnull_df[col].fillna(score_isnull_df[col].median())\n\nrf = RandomForestRegressor(n_estimators = 100)\nrf.fit(score_X, score_Y)\nscore_pred = rf.predict(score_isnull_df.values[:, 1:])\ntrain_copy.loc[train_copy['score sum'].isnull(), ['score sum']] = score_pred","88f5b851":"# \u586b\u8865\u4e4b\u540e\u7684\u76f8\u5173\u6027\ntrain_copy[['score sum', 'Sold Price']].corr()","5b7ff261":"## \u6548\u679c\u4e0d\u4f73\uff0c\u4e0d\u52a0\u5165\ntrain_copy['Year built'] = train_copy['Year built'].fillna(1920)\ntrain_copy['time interval'] = train_copy['listed on year'].astype('int') - train_copy['Year built']\ntrain_copy[['Sold Price', 'time interval']].corr()","5faa64a6":"## ==========\u62fc\u63a5train \u548c test==============\ntarget = train_data['Sold Price']\ntest_id = test_data['Id']\ntrain_data = train_data.drop(['Id','Sold Price'], axis = 1)\ntest_data = test_data.drop('Id', axis = 1)\n\ntrain_test = pd.concat([train_data, test_data], axis = 0, sort = False)","52d8f618":"features = ['Listed Price', 'Last Sold Price', 'Tax assessed value', 'Garage spaces','Bedrooms','Listed On','Type','Bathrooms','Full bathrooms',\n            'Total interior livable area', 'Year built', 'Lot', 'Annual tax amount','City','Zip',\n            'Elementary School','Middle School','High School','Elementary School Score','Middle School Score','High School Score',\n            'Elementary School Distance','Middle School Distance','High School Distance',\n            'Heating','Cooling','Parking']\n\n# \u7279\u5f81\u9009\u62e9\ntrain_test = train_test[features]","605df52e":"# features = ['Listed Price', 'Last Sold Price','Tax assessed value','listed on year',\n#             'Total interior livable area','Year built','Lot','Annual tax amount',\n#             'High School','Middle School','Elementary School',\n#             'bedroom num','total room num','price per room','score sum']\n\n## =============\u586b\u8865\u7f3a\u5931\u503c================\n# bathrooms\ntrain_test['Bathrooms'] = train_test['Bathrooms'].fillna(2)\n\n# Garage spaces\ntrain_test['Garage spaces'] = train_test['Garage spaces'].fillna(0)\ntrain_test['Garage spaces'] = train_test['Garage spaces'].replace('[a-zA-Z]', 1, regex=True)\ntrain_test['Garage spaces'] = train_test['Garage spaces'].apply(lambda x: 0 if x < 1 else x)\ntrain_test['Garage spaces'] = train_test['Garage spaces'].apply(lambda x: 10 if x > 10 else x)\n\n# Lot\ntrain_test['Lot'] = train_test['Lot'].fillna(train_test['Lot'].median())\n\n# Year built\ntrain_test['Year built'] = train_test['Year built'].fillna(train_test['Year built'].mode())\n\n## =============\u6784\u9020\u65b0\u7684\u7279\u5f81===============\n# bedroom num\ntrain_test['bedroom num'] = train_test['Bedrooms'].fillna(3)\ntrain_test['bedroom num'] = train_test['bedroom num'].replace('[a-zA-Z]', 3, regex=True)\ntrain_test['bedroom num'] = train_test['bedroom num'].astype('int')\n\n# total room\ntrain_test['total room num'] = train_test['bedroom num'] + train_test['Bathrooms']\ntrain_test['total room num'] = train_test['total room num'].apply(lambda x: 3 if x == 0 else x)\n\n# price per room\ntrain_test['price per room'] = train_test['Listed Price'] \/ train_test['total room num']\ntrain_test['price per room'] = train_test['price per room'].fillna(train_test['price per room'].median())\n\n# price per bedroom\ntrain_test['price per bedroom'] = train_test['Listed Price'] \/ (train_test['bedroom num'] + 1)\n\n# # price per bathroom\n# train_test['price per bathroom'] = train_test['Listed Price'] \/ (train_test['Bathrooms'] + 1)\n\n# listed on year\ntrain_test['listed on year'] = train_test['Listed On'].str.extract(r'(\\d{4})')\ntrain_test['listed on year'] = train_test['listed on year'].astype('int')\n\n# # listed on month\n# train_test['listed on month'] = train_test['Listed On'].str.extract(r'\\d{4}-(\\d{2})-\\d{2}')\n# train_test['listed on month'] = train_test['listed on month'].astype('int')\n\n# # listed on day\n# train_test['listed on day'] = train_test['Listed On'].str.extract(r'\\d{4}-\\d{2}-(\\d{2})')\n# train_test['listed on day'] = train_test['listed on day'].astype('int')\n\n# score sum\ntrain_test['score sum'] = train_test['Elementary School Score'] + train_test['Middle School Score'] + train_test['High School Score']\n\n# # city id\n# train_test['city id'] = pd.factorize(train_test['City'])[0]\n\n# zip str \ntrain_test['zip str'] = train_test['Zip'].astype('str')\ntrain_test = train_test.drop(['Zip'], axis = 1)\n\n# # zip id\n# train_test['zip id'] = pd.factorize(train_test['zip str'])[0]\n\n# # time interval\n# train_test['time interval'] = train_test['listed on year'] - train_test['Year built']\n\n## ============Sold Price \u53d6\u5bf9\u6570\u5904\u7406==============\ntarget_log = np.log1p(target)\n\n## ============print==================\nprint('Process : missing value')","804a24c5":"## ============= new type =============\n# \u6784\u9020map\ntype_map = {\n    'Condo': 'Condo',\n    'Townhouse': 'Townhouse',\n    'Unknown': 'Unknown',\n    'MultiFamily': 'MultiFamily',\n    'MobileManufactured': 'MobileManufactured',\n    'VacantLand': 'VacantLand'\n}\ntype_map.update(dict.fromkeys(['SingleFamily','Single Family'],'SingleFamily'))\n\n# map\u5904\u7406\ntrain_test['new type'] = train_test['Type'].map(type_map)\nnew_types_set = ['SingleFamily','Condo','Townhouse','Unknown','MultiFamily','MobileManufactured','VacantLand']\ntrain_test['new type'] = train_test['new type'].apply(lambda x: 'Other' if x not in new_types_set else x)\n\n# get dummy\ntype_dummy_df = pd.get_dummies(train_test['new type'], prefix = 'type')\ntrain_test = pd.concat([train_test, type_dummy_df], axis = 1)\ntrain_test = train_test.drop(['Type','new type'], axis = 1)\ntrain_test = train_test.drop(['type_Condo','type_Townhouse','type_Unknown','type_MultiFamily','type_MobileManufactured','type_VacantLand','type_Other'], axis = 1)\n\n## ============print==================\nprint('Process : type')","24506566":"## ================================ parking ============================\n# \u6784\u9020set\npark_garage = ['Garage']\npark_attached = ['Garage - Attached','Attached','Attached Carport']\npark_detached = ['Garage - Detached']\npark_driveway = ['Driveway']\npark_coverd = ['Covered']\nno_park = ['0 spaces','No Garage']\n\ntrain_test['Parking'] = train_test['Parking'].astype('str')\n\ntrain_test['park_garage'] = train_test['Parking'].apply(lambda x: 1 if (set(x.split(',')) & set(park_garage)) else 0)\ntrain_test['park_attached'] = train_test['Parking'].apply(lambda x: 1 if (set(x.split(',')) & set(park_attached)) else 0)\ntrain_test['park_detached'] = train_test['Parking'].apply(lambda x: 1 if (set(x.split(',')) & set(park_detached)) else 0)\ntrain_test['park_driveway'] = train_test['Parking'].apply(lambda x: 1 if (set(x.split(',')) & set(park_driveway)) else 0)\ntrain_test['park_coverd'] = train_test['Parking'].apply(lambda x: 1 if (set(x.split(',')) & set(park_coverd)) else 0)\ntrain_test['no_park'] = train_test['Parking'].apply(lambda x: 1 if (set(x.split(',')) & set(no_park)) else 0)\n\n## ============print==================\nprint('Process : parking')","40a7dbf1":"## ================================ heating ============================\n# \u6784\u9020set\nheat_cen_forced_air = ['Central Forced Air - Gas','Central Forced Air']\nheat_forced_air = ['Forced air','Forced Air','Forced Air - Gas','Forced Air - Elec','Forced Air-Gas','Forced - Electric']\nheat_cen_air = ['Central']\nheat_gas = ['Gas','Natural Gas']\nheat_other = ['Other']\n\ntrain_test['Heating'] = train_test['Heating'].astype('str')\n\ntrain_test['heat_cen_forced_air'] = train_test['Heating'].apply(lambda x: 1 if (set(x.split(',')) & set(heat_cen_forced_air)) else 0)\ntrain_test['heat_forced_air'] = train_test['Heating'].apply(lambda x: 1 if (set(x.split(',')) & set(heat_forced_air)) else 0)\ntrain_test['heat_cen_air'] = train_test['Heating'].apply(lambda x: 1 if (set(x.split(',')) & set(heat_cen_air)) else 0)\ntrain_test['heat_gas'] = train_test['Heating'].apply(lambda x: 1 if (set(x.split(',')) & set(heat_gas)) else 0)\ntrain_test['heat_other'] = train_test['Heating'].apply(lambda x: 1 if (set(x.split(',')) & set(heat_other)) else 0)\n\n## ============print==================\nprint('Process : heating')","3b13a822":"## ================================ cooling ============================\n# \u6784\u9020set\ncool_cen_air = ['Central AC','Central Air','Central','Air Conditioning','AC Central','2 Ac Central Units']\ncool_win_wall = ['Window Unit','Wall\/Window Unit(s)','Window Unit(s)','Window \/ Wall Unit','Wall\/Window','Wall Unit(s)','Wall']\ncool_fan = ['Whole House \/ Attic Fan','Ceiling Fan(s)','Whole House Fan','Ceiling Fans','Ceiling Fans Pre-Wired','Attic Fan']\ncool_nan = ['nan']\n# cool_evap = ['Evaporative Cooling','Evaporative Cooler','Evaporative','Evap Central']\n# cool_refg = ['Refrigerator']\n# no_cool = ['None','No Air Conditioning']\n# cool_other = ['Other']\n\ntrain_test['Cooling'] = train_test['Cooling'].astype('str')\n\ntrain_test['cool_cen_air'] = train_test['Cooling'].apply(lambda x: 1 if (set(x.split(',')) & set(cool_cen_air)) else 0)\ntrain_test['cool_win_wall'] = train_test['Cooling'].apply(lambda x: 1 if (set(x.split(',')) & set(cool_win_wall)) else 0)\ntrain_test['cool_fan'] = train_test['Cooling'].apply(lambda x: 1 if (set(x.split(',')) & set(cool_fan)) else 0)\ntrain_test['cool_nan'] = train_test['Cooling'].apply(lambda x: 1 if (set(x.split(',')) & set(cool_nan)) else 0)\n\n## ============print==================\nprint('Process : cooling')","1545e122":"## =============full bathrooms=============\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\nfullbath_df = train_test[['Full bathrooms','Bathrooms']]\nfullbath_notnull_df = fullbath_df.loc[(fullbath_df['Full bathrooms'].notnull())]\nfullbath_isnull_df = fullbath_df.loc[(fullbath_df['Full bathrooms'].isnull())]\nfullbath_X = fullbath_notnull_df.values[:, 1:]\nfullbath_Y = fullbath_notnull_df.values[:, 0]\n\nlgbm_fullbath = LGBMRegressor(objective='regression',learning_rate=0.05,n_estimators=500,max_depth=4,subsample=1)\nlgbm_fullbath.fit(fullbath_X, fullbath_Y)\nfullbath_pred = lgbm_fullbath.predict(fullbath_isnull_df.values[:,1:])\ntrain_test.loc[train_test['Full bathrooms'].isnull(), ['Full bathrooms']] = fullbath_pred\n\n# rf_fullbath = RandomForestRegressor(n_estimators = 200)\n# rf_fullbath.fit(fullbath_X, fullbath_Y)\n# fullbath_pred = rf_fullbath.predict(fullbath_isnull_df.values[:,1:])\n# train_test.loc[train_test['Full bathrooms'].isnull(), ['Full bathrooms']] = fullbath_pred\n\n## ============print==================\nprint('Process : full bathrooms')","3a80a4d7":"# \u586b\u8865full bathroom \u7684\u7f3a\u5931\u503c\u4e4b\u540e\uff0c\u518d\u6784\u9020\u65b0\u7279\u5f81 price per bathroom\n# price per full bathrooms\ntrain_test['price per fullbath'] = train_test['Listed Price'] \/ (train_test['Full bathrooms'] + 1)\nprint('Process : price per fullbath')","021cb3fc":"## ===============total livable area===================\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\nlivearea_df = train_test[['Total interior livable area','Full bathrooms','Listed Price']]\nlivearea_notnull_df = livearea_df.loc[(livearea_df['Total interior livable area'].notnull())]\nlivearea_isnull_df = livearea_df.loc[(livearea_df['Total interior livable area'].isnull())]\nlivearea_X = livearea_notnull_df.values[:, 1:]\nlivearea_Y = livearea_notnull_df.values[:, 0]\n\nlgbm_livearea = LGBMRegressor(objective='regression',learning_rate=0.05,n_estimators=500,max_depth=5,subsample=1)\nlgbm_livearea.fit(livearea_X, livearea_Y)\nlivearea_pred = lgbm_livearea.predict(livearea_isnull_df.values[:,1:])\ntrain_test.loc[train_test['Total interior livable area'].isnull(), ['Total interior livable area']] = livearea_pred\n\n# rf_livearea = RandomForestRegressor(n_estimators = 200)\n# rf_livearea.fit(livearea_X, livearea_Y)\n# livearea_pred = rf_livearea.predict(livearea_isnull_df.values[:,1:])\n# train_test.loc[train_test['Total interior livable area'].isnull(), ['Total interior livable area']] = livearea_pred\n\n## ============print==================\nprint('Process : total livable area')","0392c072":"## ======= score sum ===========\n## use random forest model to fill missing values\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\nscore_df_new = train_test[['score sum','Elementary School Score','Middle School Score','High School Score']]\nscore_notnull_df_new = score_df_new.loc[(score_df_new['score sum'].notnull())]\nscore_isnull_df_new = score_df_new.loc[(score_df_new['score sum'].isnull())]\nscore_X_new = score_notnull_df_new.values[:, 1:]\nscore_Y_new = score_notnull_df_new.values[:, 0]\n\nfor col in ['Elementary School Score','Middle School Score','High School Score']:\n    score_isnull_df_new[col] = score_isnull_df_new[col].fillna(score_isnull_df_new[col].median())\n\nlgbm_score = LGBMRegressor(objective='regression',learning_rate=0.05,n_estimators=500,max_depth=5,subsample=1)\nlgbm_score.fit(score_X_new, score_Y_new)\nscore_pred_new = lgbm_score.predict(score_isnull_df_new.values[:,1:])\ntrain_test.loc[train_test['score sum'].isnull(), ['score sum']] = score_pred_new\n\n# rf = RandomForestRegressor(n_estimators = 200)\n# rf.fit(score_X_new, score_Y_new)\n# score_pred_new = rf.predict(score_isnull_df_new.values[:,1:])\n# train_test.loc[train_test['score sum'].isnull(), ['score sum']] = score_pred_new\n\n## ============print==================\nprint('Process : score sum')","ee25afd2":"## \u6b63\u5f0f\u586b\u8865school score\u7f3a\u5931\u503c\nfor col in ['High School Score','Middle School Score','Elementary School Score']:\n    train_test[col] = train_test[col].fillna(train_test[col].median())","990c1826":"## ===========Tax assessed value===========\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\ntax_df = train_test[['Tax assessed value','Bathrooms','Listed Price']]\ntax_notnull_df = tax_df.loc[(tax_df['Tax assessed value'].notnull())]\ntax_isnull_df = tax_df.loc[(tax_df['Tax assessed value'].isnull())]\ntax_X = tax_notnull_df.values[:, 1:]\ntax_Y = tax_notnull_df.values[:, 0]\n\nlgbm_tax = LGBMRegressor(objective='regression',learning_rate=0.05,n_estimators=500,max_depth=5,subsample=1)\nlgbm_tax.fit(tax_X, tax_Y)\ntax_pred = lgbm_tax.predict(tax_isnull_df.values[:, 1:])\ntrain_test.loc[train_test['Tax assessed value'].isnull(), ['Tax assessed value']] = tax_pred\n\n# rf_tax = RandomForestRegressor(n_estimators = 200)\n# rf_tax.fit(tax_X, tax_Y)\n# tax_pred = rf_tax.predict(tax_isnull_df.values[:, 1:])\n# train_test.loc[train_test['Tax assessed value'].isnull(), ['Tax assessed value']] = tax_pred\n\n## ============print==================\nprint('Process : tax assessed value')","d2f0f433":"## ==============Annual tax amount==============\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\nantax_df = train_test[['Annual tax amount','Tax assessed value']]\nantax_notnull_df = antax_df.loc[(antax_df['Annual tax amount'].notnull())]\nantax_isnull_df = antax_df.loc[(antax_df['Annual tax amount'].isnull())]\nantax_X = antax_notnull_df.values[:, 1:]\nantax_Y = antax_notnull_df.values[:, 0]\n\nlgbm_antax = LGBMRegressor(objective='regression',learning_rate=0.05,n_estimators=500,max_depth=4,subsample=1)\nlgbm_antax.fit(antax_X, antax_Y)\nantax_pred = lgbm_antax.predict(antax_isnull_df.values[:, 1:])\ntrain_test.loc[train_test['Annual tax amount'].isnull(), ['Annual tax amount']] = antax_pred\n\n# rf_antax = RandomForestRegressor(n_estimators = 200)\n# rf_antax.fit(antax_X, antax_Y)\n# antax_pred = rf_antax.predict(antax_isnull_df.values[:, 1:])\n# train_test.loc[train_test['Annual tax amount'].isnull(), ['Annual tax amount']] = antax_pred\n\n## ============print==================\nprint('Process : annual tax amout')","c0e19dab":"# =============last sold price===========\n# use random forest model to fill missing values\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nlast_price_df = train_test[['Last Sold Price','Listed Price','Bathrooms','bedroom num','score sum',\n                            'Annual tax amount','Tax assessed value','Total interior livable area']]\nlast_price_notnull = last_price_df.loc[(last_price_df['Last Sold Price'].notnull())]\nlast_price_isnull = last_price_df.loc[(last_price_df['Last Sold Price'].isnull())]\nlast_price_X = last_price_notnull.values[:, 1:]\nlast_price_Y = last_price_notnull.values[:, 0]\n\nlgbm_price = LGBMRegressor(objective='regression',learning_rate=0.05,n_estimators=1000,max_depth=7,subsample=0.9)\nlgbm_price.fit(last_price_X, last_price_Y)\nlastprice_pred = lgbm_price.predict(last_price_isnull.values[:, 1:])\ntrain_test.loc[train_test['Last Sold Price'].isnull(), ['Last Sold Price']] = lastprice_pred\n\n# rf_lastprice = RandomForestRegressor(n_estimators = 200)\n# rf_lastprice.fit(last_price_X, last_price_Y)\n# lastprice_pred = rf_lastprice.predict(last_price_isnull.values[:, 1:])\n# train_test.loc[train_test['Last Sold Price'].isnull(), ['Last Sold Price']] = lastprice_pred\n\n## ============print==================\nprint('Process : last sold price')","a3a21aca":"## =============high school===============\nfrom sklearn.ensemble import RandomForestClassifier\n\nhigh_df = train_test[['High School','High School Score']]\nhigh_notnull_df = high_df.loc[(high_df['High School'].notnull())]\nhigh_isnull_df = high_df.loc[(high_df['High School'].isnull())]\nhigh_X = high_notnull_df.values[:, 1:]\nhigh_Y = high_notnull_df.values[:, 0]\n\nrf_high = RandomForestClassifier(n_estimators = 100)\nrf_high.fit(high_X, high_Y)\nhigh_pred = rf_high.predict(high_isnull_df.values[:, 1:])\ntrain_test.loc[train_test['High School'].isnull(), ['High School']] = high_pred\n\n## ============print==================\nprint('Process : high school')","324348c7":"## =============middle school===============\nfrom sklearn.ensemble import RandomForestClassifier\n\nmiddle_df = train_test[['Middle School','Middle School Score']]\nmiddle_notnull_df = middle_df.loc[(middle_df['Middle School'].notnull())]\nmiddle_isnull_df = middle_df.loc[(middle_df['Middle School'].isnull())]\nmiddle_X = middle_notnull_df.values[:, 1:]\nmiddle_Y = middle_notnull_df.values[:, 0]\n\nrf_middle = RandomForestClassifier(n_estimators = 100)\nrf_middle.fit(middle_X, middle_Y)\nmiddle_pred = rf_middle.predict(middle_isnull_df.values[:, 1:])\ntrain_test.loc[train_test['Middle School'].isnull(), ['Middle School']] = middle_pred\n\n## ============print==================\nprint('Process : middle school')","b592fd82":"## =============Elementary school===============\nfrom sklearn.ensemble import RandomForestClassifier\n\nElementary_df = train_test[['Elementary School','Elementary School Score']]\nElementary_notnull_df = Elementary_df.loc[(Elementary_df['Elementary School'].notnull())]\nElementary_isnull_df = Elementary_df.loc[(Elementary_df['Elementary School'].isnull())]\nElementary_X = Elementary_notnull_df.values[:, 1:]\nElementary_Y = Elementary_notnull_df.values[:, 0]\n\nrf_Elementary = RandomForestClassifier(n_estimators = 100)\nrf_Elementary.fit(Elementary_X, Elementary_Y)\nElementary_pred = rf_Elementary.predict(Elementary_isnull_df.values[:, 1:])\ntrain_test.loc[train_test['Elementary School'].isnull(), ['Elementary School']] = Elementary_pred\n\n## ============print==================\nprint('Process : elementary school')","a7845fbf":"## \u820d\u5f03\u4e0d\u7528\u7684\u7279\u5f81\ndrop_features = ['Bedrooms','Listed On','Elementary School Score','Middle School Score','High School Score','Heating','Cooling','Parking']\ntrain_test = train_test.drop(drop_features, axis = 1)","afdf5b33":"## \u518d\u628atrain_test\u5206\u5f00\uff0c\u8fd8\u539f\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\ntraining_data_set = train_test[0:47439]\ntesting_data_set = train_test[47439:]","e3782ee3":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n\n# Creation of the RMSE metric:\nkf = KFold(n_splits=10, random_state=42, shuffle=True)\n\ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model):\n    rmse = np.sqrt(-cross_val_score(model, training_data_set, target_log, scoring=\"neg_mean_squared_error\", cv=kf))\n    return (rmse)\n\n## ============print==================\nprint('Define Loss function')","99c16285":"from sklearn.model_selection import train_test_split\nfrom category_encoders import TargetEncoder\n\nX_train,X_val,y_train,y_val = train_test_split(training_data_set,target_log,test_size = 0.1,random_state = 23)\n\nX_train.columns","0647583d":"# CatBoost\n## category variable : city \/ elementary school \/ middle school\/ high school\/ zip str\nprint('CatBoost working...')\n\nfrom catboost import CatBoostRegressor, Pool\n\ncategory_features_ind = [10,11,12,13,23]\n\ncat = CatBoostRegressor(iterations = 950,\n                        learning_rate = 0.05,\n                        depth = 10,\n                        subsample = 0.7,\n                        random_seed = 0,\n                        cat_features = category_features_ind)\n\ntrain_pool = Pool(X_train, y_train, cat_features = category_features_ind)\ncat.fit(train_pool, verbose = 0)\ncat_pred = cat.predict(X_val)\ncat_score = rmse(y_val, cat_pred)\ncat_score","346138e5":"feat_importances = pd.Series(cat.feature_importances_, index = cat.feature_names_).sort_values()\nplt.figure(figsize=(16, 9))\nplt.title('feature importance')\nfeat_importances.plot(kind = 'barh')\nplt.show()","f5b9451e":"# Test CSV Submission\n\ntest_pred = cat.predict(testing_data_set)\nsubmission = pd.DataFrame(test_id, columns = ['Id'])\ntest_pred = np.expm1(test_pred)\nsubmission['Sold Price'] = test_pred \nsubmission.head()","21bbf5d1":"# Saving the results in a csv file\n\nsubmission.to_csv(\"submission.csv\", index = False, header = True)","71ef566c":"## \u6784\u9020\u5173\u4e8e\u201c\u623f\u95f4\u4ef7\u683c\u201d\u7684\u65b0\u7279\u5f81\n- price per bedroom \u6bcf\u4e2a\u5367\u5ba4\u7684\u4ef7\u683c\n- price per bathroom \u6bcf\u4e2a\u536b\u751f\u95f4\u7684\u4ef7\u683c\n- price per fullbath \u6bcf\u4e2afull bathroom\u7684\u4ef7\u683c\uff08full bathroom\uff1a\u674e\u6c90\u8001\u5e08\u8bf4\u662f\u201c\u5e26\u6709\u6d74\u5ba4\u7684\u536b\u751f\u95f4\u201d\uff09\n- total room \u5367\u5ba4\u548c\u536b\u751f\u95f4\u7684\u603b\u548c\n- price per room \u6bcf\u4e2a\u623f\u95f4\u7684\u4ef7\u683c\n\np.s. \u4e3a\u4e86\u9632\u6b62\u5206\u6bcd\u4e3a0\u7684\u60c5\u51b5\uff0c\u6240\u4ee5\u5206\u6bcd\u90fd\u52a01","d837adf0":"# \u603b\u4f53\u601d\u8def\n- \u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff08EDA\uff09\n    - \u76f8\u5173\u5206\u6790\n        - \u53ef\u4ee5\u627e\u51fa\u660e\u663e\u4e0esold price\u5177\u6709\u76f8\u5173\u5173\u7cfb\u7684\u6570\u503c\u7279\u5f81\u3002\u5176\u4f59\u4e0d\u660e\u663e\u7684\u4e5f\u4e0d\u8981\u9a6c\u4e0a\u5220\u3002\u7b49\u8dd1\u4e86\u51e0\u6b21\u6a21\u578b\u4e4b\u540e\uff0c\u901a\u8fc7\u67e5\u770b\u7279\u5f81\u91cd\u8981\u6027\u6392\u540d\uff0c\u518d\u628a\u4e0d\u76f8\u5173\u7684\u7279\u5f81\u5254\u9664\u3002\n        - bathroom\/full bathroom\/livable area\/elementary school score\/middle school score\/high school score\/assessed tax\/annul tax\/listed price\/last sold price\n    - \u6570\u503c\u7279\u5f81\n    - \u6587\u672c\u7279\u5f81\n- \u7279\u5f81\u5de5\u7a0b\n    - \u586b\u8865\u7f3a\u5931\u503c(1)\n        - bathroom: \u5747\u503c\u586b\u8865\n        - garage spaces: \u75280\u586b\u8865\n        - lot\uff1a\u4e2d\u4f4d\u6570\u586b\u8865\n        - year built\uff1a\u4f17\u6570\u586b\u8865\n    - \u6784\u9020\u65b0\u7279\u5f81\n        - \u6570\u503c\u7279\u5f81\n            - bedroom num\uff1a\u628astr\u6570\u636e\u7528\u5747\u503c\u66ff\u4ee3\n            - total room = bathroom + bedroom\n            - price per room = listed price \/ total room\n            - price per bedroom = listed price \/ bedroom\n            - price per fullbath = listed price \/ full bathroom\n            - listed on year\uff1alisted on \u7684\u5e74\u4efd\u63d0\u53d6\u51fa\u6765\n            - score sum = \u4e09\u4e2a\u5b66\u6821score\u4e4b\u548c\n            - zip str\uff1a\u628a\u90ae\u7f16\u8f6c\u6362\u4e3astr\u7c7b\u578b\uff0c\u8ba9catboost\u5904\u7406\n            - sold price \u53d6\u5bf9\u6570\u5904\u7406\n        - \u6587\u672c\u7279\u5f81\n            - new type\n            - heating\n            - cooling\n            - parking\n    - \u586b\u8865\u7f3a\u5931\u503c(2)\n        - \u6570\u503c\u7279\u5f81\n            - \u9009\u62e9\u4e0e\u88ab\u586b\u8865\u7279\u5f81\u76f8\u5173\u7684\u7279\u5f81\uff0c\u8bad\u7ec3lightGBM\uff0c\u7528\u9884\u6d4b\u503c\u586b\u8865\n            - full bathrooms\n            - total livable area\n            - score sum\n            - Tax assessed value\n            - Annual tax amount\n            - last sold price\n        - \u6587\u672c\u7279\u5f81\n            - \u90fd\u7528random forest\u9884\u6d4b\u503c\u586b\u8865\n            - elementary school\/middle school\/high school\n- catboost\u5efa\u6a21\n    - \u8c03\u53c2\uff08\u4e0d\u592a\u4f1a\u8c03\uff0c\u8c03\u51fa\u4e00\u4e2a\u4e0d\u9519\u7684\u53c2\u6570\u7ec4\u5408\u4e4b\u540e\uff0c\u5c31\u57fa\u672c\u6ca1\u53d8\u4e86\u3002random search\u3001grid search\u592a\u6162\u4e86\uff09\n    - \u8bad\u7ec3\u6a21\u578b\n    - \u67e5\u770bvalidation set\u7ed3\u679c\n    - \u770b\u7279\u5f81\u91cd\u8981\u6027\n- \u63d0\u4ea4","78bff9f2":"# \u52a0\u5dde\u623f\u4ef7\u9884\u6d4b","113b85f7":"# Submission","864871b1":"## \u76f8\u5173\u5206\u6790","02ed90db":"# \u63a2\u7d22\u6027\u6570\u636e\u5206\u6790EDA\n\n\u7279\u5f81\u5de5\u7a0b\u4e4b\u524d\u7684\u6570\u636e\u5206\u6790\u662f\u975e\u5e38\u91cd\u8981\u7684\u73af\u8282\uff0c\u51b3\u5b9a\u4e86\u540e\u7eed\u7684\u7279\u5f81\u5de5\u7a0b\u3002\n\n\u539f\u5148\u7684EDA\u5206\u6790\u592a\u591a\u592a\u4e71\uff0c\u6240\u4ee5\u8fd9\u91cc\u53ea\u653e\u4e86\u51e0\u4e2a\u7279\u5f81\u3002\n\n- city\n- bedroom num\n- \u6784\u9020\u5173\u4e8e\u201c\u623f\u95f4\u4ef7\u683c\u201d\u7684\u65b0\u7279\u5f81\n- \u63d0\u53d6listed on\u7684\u5e74\u4efd\n- score sum\n- \u6784\u9020\u65b0\u7279\u5f81 time interval","d608f113":"\u7531\u76f8\u5173\u7cfb\u6570\u70ed\u529b\u56fe\uff08pearson\u76f8\u5173\u7cfb\u6570\uff09\u53ef\u4ee5\u770b\u51fa\uff0c\u4e0e\u9884\u6d4b\u76ee\u6807sold price\u5177\u6709\u660e\u663e\u3010\u7ebf\u6027\u76f8\u5173\u5173\u7cfb\u3011\u7684\u7279\u5f81\u6709\uff1a\n- bathrooms\/full bathrooms\n- 3\u4e2a school score \u770b\u6765\u7f8e\u56fd\u4eba\u4e70\u623f\u5b50\u4e5f\u662f\u8981\u770b\u5468\u56f4\u5b66\u6821\u7684\n- 2\u4e2a tax\n- listed price \u6302\u724c\u4ef7\u683c\n- last sold price \u4e0a\u6b21\u6210\u4ea4\u4ef7\u683c\n\n\u8fd9\u51e0\u4e2a\u7279\u5f81\u80af\u5b9a\u5c31\u662f\u540e\u7eed\u5efa\u6a21\u9700\u8981\u7684\u7279\u5f81\u3002","f03d4ce6":"## city","76cb8c48":"## train data missing value\n\u53ef\u4ee5\u770b\u4e00\u4e0b\u5404\u4e2a\u7279\u5f81\u7684\u7f3a\u5931\u503c\u60c5\u51b5\uff0c\u5982\u679c\u7f3a\u5931\u503c\u6bd4\u4f8b\u975e\u5e38\u5927\uff08\u8d85\u8fc730%\uff09\uff0c\u5728\u540e\u7eed\u5206\u6790\u8003\u8651\u662f\u5426\u76f4\u63a5\u820d\u5f03\u3002","2d1db04f":"## test data missing ","c6742a33":"## bedroom num","3893f926":"## score sum\n\u7531\u4e4b\u524d\u7684\u76f8\u5173\u7cfb\u6570\u70ed\u529b\u56fe\u53ef\u4ee5\u770b\u51fa\uff0c\u4e09\u4e2aschool score\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u5f88\u5f3a\uff0c\u5982\u679c\u628a\u4e09\u4e2ascore\u90fd\u52a0\u5165\uff0c\u53ef\u80fd\u5b58\u5728\u5171\u7ebf\u6027\u7684\u95ee\u9898\u3002\n\n\u6240\u4ee5\u628a\u4e09\u4e2aschool score\u6c47\u603b\u6210\u4e00\u4e2a\u7279\u5f81score sum\u3002","5f78743b":"## \u6784\u9020\u65b0\u7279\u5f81 time interval\n\u6839\u636eyear built\uff08\u5efa\u9020\u5e74\u4efd\uff09\u60f3\u5230\u6784\u9020\u8fd9\u4e2a\u8ddd\u79bb\u6302\u724c\u65f6\u95f4\u957f\u77ed\u7684\u7279\u5f81\u3002\n\ntime interval = year built - listed on year\n\n\u4f46\u662f\u76f8\u5173\u6027\u5e76\u4e0d\u5f3a\uff0c\u6240\u4ee5\u6700\u540e\u6ca1\u6709\u52a0\u5165\u8fd9\u4e2a\u7279\u5f81\u3002","cc6c000f":"## \u63d0\u53d6listed on\u7684\u5e74\u4efd\nlisted on\u7684year\/month\/day\u90fd\u5c1d\u8bd5\u63d0\u53d6\u8fc7\uff0c\u4f46\u6548\u679c\u6700\u597d\u7684\u662fyear\uff0c\u6240\u4ee5\u8fd9\u91cc\u53ea\u5c55\u793ayear\u548csold price\u7684\u5173\u7cfb","6ff09afd":"# Modeling","ce0014e2":"# Feature Engineering","fe454db2":"# \u52a0\u8f7d\u6570\u636e\/\u67e5\u770b\u7f3a\u5931\u503c","64b21945":"## first 20 rows"}}