{"cell_type":{"908814a6":"code","aed30090":"code","22890bb9":"code","2ce6860b":"code","f96d2e2b":"code","d174afea":"code","5af51f8a":"code","1b3fbf1d":"code","48f69989":"code","046b6a41":"code","bd357e30":"code","9f2db2d4":"code","b79fdc8f":"code","7755c559":"code","bbecc9b5":"code","4a35a87e":"code","65a86d31":"markdown","a5b3b0ad":"markdown","e7f35424":"markdown","5aac26e7":"markdown","0f92e1bf":"markdown"},"source":{"908814a6":"# first load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf\nimport os\nimport math\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n\nimport albumentations","aed30090":"\ndef datagen(features, labels, batch_size, p=1):\n    aug = albumentations.Compose([\n          albumentations.GaussianBlur(p=0.01),\n          albumentations.ShiftScaleRotate(p=0.5),\n          albumentations.Rotate(limit=20, p=0.5),\n          albumentations.OpticalDistortion(p=0.1),\n          albumentations.ImageCompression(p=0.05)], p=p)\n    \n    batch_features = np.zeros((batch_size, features.shape[1], features.shape[2], features.shape[3]))\n    batch_labels = np.zeros((batch_size, labels.shape[1]))\n    batches = 0\n    finish = len(features) \/ batch_size\n    while True:\n        # Fill arrays of batch size with augmented data taken randomly from full passed arrays\n        indexes = random.sample(range(len(features)), batch_size)\n        # Perform the exactly the same augmentation for X and y\n        random_augmented_images = [aug(image=x.reshape(28,28,1))['image'] for x in features[indexes]]\n        random_augmented_labels = [x for x in labels[indexes]]\n        batch_features[:,:,:,:] = random_augmented_images\n        batch_labels[:,:] = random_augmented_labels\n        \n        yield batch_features, batch_labels","22890bb9":"# for reproducible results :\ndef seed_everything(seed=13):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_KERAS'] = '1'\n    random.seed(seed)\n    \nseed_everything(42)","2ce6860b":"# load data\ndf_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","f96d2e2b":"# split our data into features & target\nX_train = df_train.drop('label', axis=1).values\ny_train = df_train['label'].values.reshape(-1,1)\n\nX_test = df_test.values","d174afea":"# rescale variables\nX_train = X_train.astype('float32') \/ 255\nX_test = X_test.astype('float32') \/ 255","5af51f8a":"# check first few images\nAUGMENTATIONS = albumentations.Compose([\n                albumentations.GaussianBlur(p=0.01),\n                albumentations.ShiftScaleRotate(p=0.5),\n                albumentations.Rotate(limit=20, p=0.5),\n                albumentations.OpticalDistortion(p=0.1),\n                albumentations.ImageCompression(p=0.05)], p=1)\n\nplt.figure(figsize=(15,15))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    im = AUGMENTATIONS(image=X_train[i].reshape(28,28,1))['image']\n#     im = X_train[i]\n#     print(im)\n    plt.imshow(im.reshape(28,28), cmap='gray')\n    plt.title('Number:' + str(y_train[i][0]))\n    plt.axis('off')","1b3fbf1d":"# reshape features for tensorflow\nX_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\n\n# one hot encode for target variable\ny_train = to_categorical(y_train)\ntarget_count = y_train.shape[1]\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)","48f69989":"print(X_train.shape)\nprint(y_train.shape)","046b6a41":"train_gen = datagen(X_train, y_train, 128, p=1)\nvalid_gen = datagen(X_val, y_val, 128, p=0)","bd357e30":"initializer = tf.keras.initializers.GlorotUniform()\n\ninputs = tf.keras.Input(shape=(28, 28, 1))\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)(inputs)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.BatchNormalization()(x)\n\ny1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(1,1), padding='same', activation='relu', kernel_initializer=initializer)(inputs)\ny1 = tf.keras.layers.BatchNormalization()(y1)\nx = tf.keras.layers.Add()([x, y1])\n\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='valid', strides=(2,2), activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.Dropout(0.25)(x)\nsecond_block = tf.keras.layers.BatchNormalization()(x)\n\nx = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.BatchNormalization()(x)\n\ny1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(1,1), padding='same', activation='relu', kernel_initializer=initializer)(second_block)\ny1 = tf.keras.layers.BatchNormalization()(y1)\nx = tf.keras.layers.Add()([x, y1])\n\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(256, activation='relu', kernel_initializer=initializer)(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.BatchNormalization()(x)\noutputs = tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer)(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n        \noptimizer = RMSprop(learning_rate=0.01,rho=0.99)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","9f2db2d4":"# callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, verbose=1,patience=2, min_lr=0.0000001)\nmc = ModelCheckpoint('best_model.h5', monitor = 'val_loss' , mode = 'min', verbose = 1 , save_best_only = True)\ncallback = EarlyStopping(monitor='loss', patience=5)","b79fdc8f":"from tensorflow.keras.utils import plot_model\n# model.summary()\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","7755c559":"model.fit(\n    train_gen,\n    steps_per_epoch=int(len(X_train)\/128),\n    epochs=50,\n    validation_data=valid_gen,\n    validation_steps=int(len(X_val)\/128),\n    callbacks=[callback, reduce_lr, mc])","bbecc9b5":"model.load_weights('best_model.h5')\ny_test_hat = model.predict(X_test).argmax(axis=1)\n\ndf_submission = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\ndf_submission['Label'] = y_test_hat.astype('int32')\ndf_submission.to_csv('submission.csv', index=False)\nprint('Submission saved!')","4a35a87e":"import gc\ndel model\ngc.collect()","65a86d31":"# Fitting","a5b3b0ad":"# This is Resudual Convolution Neural Network, this concept using in ResNet50\/101\/151 models","e7f35424":"# Visualize augmentation","5aac26e7":"# for reproducible results","0f92e1bf":"# Use \"albumentations\" package for faster augmentation of images"}}