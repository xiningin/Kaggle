{"cell_type":{"f1cdff34":"code","8ae45a8b":"code","f99c15d2":"code","51104494":"code","a099ba9b":"code","581287b4":"code","e444c167":"code","ac0c6dcb":"code","12312380":"code","5909c80f":"code","b373e97e":"code","f5e22e54":"code","af499233":"code","c026d004":"code","aaa8ea7e":"code","ea30e6cc":"code","7551eef2":"markdown","834d5187":"markdown","e59de479":"markdown","569f385c":"markdown","c2a9d50f":"markdown","f3e0dc46":"markdown","25100b97":"markdown","8a791356":"markdown"},"source":{"f1cdff34":"# install pycaret\n!pip install pycaret","8ae45a8b":"# utilities\nimport os\nimport sys\nfrom tqdm import tqdm\nimport random\n\n# data manipulation\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport matplotlib.pyplot as plt\n\n# pycaret\nfrom pycaret.classification import *\n\n# scipy\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom scipy.signal import butter,filtfilt\nfrom scipy.signal import cwt\nfrom scipy.signal import hilbert\nfrom scipy.signal import resample\nfrom scipy.signal import decimate\nfrom scipy.signal import spectrogram\nfrom scipy.signal.windows import get_window\n\n# Set seed for reproducibility\nseed_value= 32 \nos.environ['PYTHONHASHSEED']=str(seed_value)\nrandom.seed(seed_value)\nnp.random.seed(seed_value)\n\n# set variables\nROOT = '..\/input\/coughvid-wav\/public_dataset\/'\nclass_names = ['healthy','COVID-19','symptomatic']\naudio_length = 22050\n\n# load coughvid meta\ndata_raw = pd.read_csv(ROOT+'metadata_compiled.csv')\ndata_raw.head(3)","f99c15d2":"data_raw.status.value_counts()","51104494":"def split_by_physicians(df):\n    column_names = ['uuid', 'datetime', 'cough_detected', 'SNR', 'latitude', 'longitude', \n                    'age', 'gender', 'respiratory_condition', 'fever_muscle_pain', 'status', \n                    'quality', 'cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', \n                    'congestion', 'nothing', 'diagnosis', 'severity' ]\n    physician_01 = df.iloc[:, 0:21]\n    physician_01 = physician_01[physician_01.quality_1.notna()].reset_index(drop=True)\n    physician_01.columns = column_names\n\n    physician_02 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 21:31]], axis=1)\n    physician_02 = physician_02[physician_02.quality_2.notna()].reset_index(drop=True)\n    physician_02.columns = column_names\n\n    physician_03 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 31:41]], axis=1)\n    physician_03 = physician_03[physician_03.quality_3.notna()].reset_index(drop=True)\n    physician_03.columns = column_names\n\n    physician_04 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 41:51]], axis=1)\n    physician_04 = physician_04[physician_04.quality_4.notna()].reset_index(drop=True)\n    physician_04.columns = column_names\n    return physician_01, physician_02, physician_03, physician_04\n    \ndef process_csv(df):\n    #split by physicians\n    physician_01, physician_02, physician_03, physician_04 = split_by_physicians(df)\n    # combine into one dataframe\n    df = pd.concat([physician_01,physician_02,physician_03,physician_04]).reset_index(drop=True)  \n    # drop null status\n    df = df[df.status.notna()]\n    # drop cough_detected < 0.8\n    df = df[df.cough_detected >= 0.8 ]\n    # select good and ok quality\n    df = df[df.quality == 'good']\n    # shuffle\n    df = df.sample(frac=1).reset_index(drop=True) \n    df = df[['uuid', 'status','cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', 'congestion', 'severity']]\n    return df","a099ba9b":"processed_df = process_csv(data_raw)\nprocessed_df.head(3)","581287b4":"def segment_cough(x,fs, cough_padding=0.2,min_cough_len=0.2, th_l_multiplier = 0.1, th_h_multiplier = 2):\n    #Preprocess the data by segmenting each file into individual coughs using a hysteresis comparator on the signal power                \n    cough_mask = np.array([False]*len(x))\n    \n    #Define hysteresis thresholds\n    rms = np.sqrt(np.mean(np.square(x)))\n    seg_th_l = th_l_multiplier * rms\n    seg_th_h =  th_h_multiplier*rms\n\n    #Segment coughs\n    coughSegments = []\n    padding = round(fs*cough_padding)\n    min_cough_samples = round(fs*min_cough_len)\n    cough_start = 0\n    cough_end = 0\n    cough_in_progress = False\n    tolerance = round(0.01*fs)\n    below_th_counter = 0\n    \n    for i, sample in enumerate(x**2):\n        if cough_in_progress:\n            if sample<seg_th_l:\n                below_th_counter += 1\n                if below_th_counter > tolerance:\n                    cough_end = i+padding if (i+padding < len(x)) else len(x)-1\n                    cough_in_progress = False\n                    if (cough_end+1-cough_start-2*padding>min_cough_samples):\n                        coughSegments.append(x[cough_start:cough_end+1])\n                        cough_mask[cough_start:cough_end+1] = True\n            elif i == (len(x)-1):\n                cough_end=i\n                cough_in_progress = False\n                if (cough_end+1-cough_start-2*padding>min_cough_samples):\n                    coughSegments.append(x[cough_start:cough_end+1])\n            else:\n                below_th_counter = 0\n        else:\n            if sample>seg_th_h:\n                cough_start = i-padding if (i-padding >=0) else 0\n                cough_in_progress = True\n    \n    return coughSegments, cough_mask\n\ndef extract_features(audio_data, sample_rate):\n\n    features = []\n    stft = np.abs(librosa.stft(audio_data))\n\n    mfcc = np.mean(librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40).T,axis=0)\n    features.extend(mfcc) # 40 = 40\n\n    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n    features.extend(chroma) # 12 = 52\n\n    mel = np.mean(librosa.feature.melspectrogram(audio_data, sr=sample_rate).T,axis=0)\n    features.extend(mel) # 128 = 180\n\n    fmin_val = 0.5 * sample_rate * 2**(-6)\n    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate, fmin=fmin_val).T,axis=0)\n    features.extend(contrast) # 7 = 187\n\n    return np.array(features)\n\n\ndef load_features(df):\n    all_data, all_fname = [], []\n    for idx in tqdm(range(len(df))):\n        fname = df.uuid.iloc[idx]\n        path = ROOT+fname+'.wav' \n\n        # load sound sample\n        audio, sample_rate = librosa.load(path, mono=True)\n\n        # Segment each audio into individual coughs using a hysteresis comparator on the signal power\n        cough_segments, cough_mask = segment_cough(audio, sample_rate, min_cough_len=0.1, cough_padding=0.1, th_l_multiplier = 0.1, th_h_multiplier = 2)\n\n        # For each segment, resize to the same length(11025)\n        if len(cough_segments) > 0 :\n            i = 0\n            for audio in cough_segments:\n                i+=1\n                if len(audio) > 8000:\n                    if len(audio) < audio_length:\n                        audio_pad = librosa.util.pad_center(audio, audio_length)\n                    else:\n                        audio_pad = audio[:audio_length]  \n\n                feature = extract_features(audio_pad, sample_rate)\n                #print(len(feature))\n                all_data.append(feature)\n                all_fname.append(fname)\n    \n    return np.array(all_fname), np.array(all_data)","e444c167":"# This may take some time, so go watch some Korean dramas first.\nuuid, X = load_features(processed_df)","ac0c6dcb":"# Store each features in different dataframe so you can choose to train all features or individual\nX_mfcc = X[:, 0:40]\nX_chroma = X[:, 40:52]\nX_mel = X[:, 52:180]\nX_contrast = X[:, 180:]\n\n# mfcc only\nuuid_df = pd.DataFrame({'uuid':uuid})\nmfcc_df = pd.DataFrame(X_mfcc)\nmfcc_df.columns=[\"mfcc\"+str(i) for i in range(1, X_mfcc.shape[1]+1)]\nall_mfcc_df = pd.concat([uuid_df, mfcc_df], axis=1)\n\n# mel spectogram only\nmel_df = pd.DataFrame(X_mel)\nmel_df.columns=[\"mel\"+str(i) for i in range(1, X_mel.shape[1]+1)]\nall_mel_df = pd.concat([uuid_df, mel_df], axis=1)\n\n# chroma only\nchroma_df = pd.DataFrame(X_chroma)\nchroma_df.columns=[\"chr\"+str(i) for i in range(1, X_chroma.shape[1]+1)]\nall_chroma_df = pd.concat([uuid_df, chroma_df], axis=1)\n\n# contrast only\ncontrast_df = pd.DataFrame(X_contrast)\ncontrast_df.columns=[\"con\"+str(i) for i in range(1, X_contrast.shape[1]+1)]\nall_contrast_df = pd.concat([uuid_df, contrast_df], axis=1)\n\n# all features\nall_df = pd.concat([uuid_df, mfcc_df, mel_df, chroma_df, contrast_df ], axis=1)\nall_df.head(3)","12312380":"# Instead of predicting the status (healthy\/covid\/symptomatic), we train a model to to identify the cough type (dry\/wet)\n\n# Select what you would like to predict ('status', 'cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', 'congestion', 'severity')\nlabel_df = processed_df[['uuid', 'cough_type']].reset_index(drop=True)\n\n# merge features and label to train\ndataset = pd.merge(all_df, label_df, on='uuid')\n\n# remove null columns\ndataset = dataset[dataset.cough_type != 'unknown']\ndataset.head(3)","5909c80f":"dataset.cough_type.value_counts()","b373e97e":"# Fix imbalance\ndataset = dataset.groupby('cough_type').sample(n=2185)","f5e22e54":"exp_clf102 = setup(\n    data = dataset, \n    target = 'cough_type',\n    normalize = True, \n    transformation = True, \n    silent = True,\n    ignore_features=['uuid']\n)","af499233":"compare_models()","c026d004":"xgboost = create_model('xgboost')","aaa8ea7e":"plot_model(xgboost)","ea30e6cc":"plot_model(xgboost, plot = 'confusion_matrix')","7551eef2":"### Evaluate Model Performance","834d5187":"## Data Pre-processing\n\nGiven the size of the dataset and its varied quality, it was initially filtered as follows.\n- Only data that has been observed by physicians\n- Remove data without status\n- Select only cough_detected > 0.8\n- Select only data that has been reviewed as good quality by physicians","e59de479":"## Setup pycaret environment\n\nPyCaret is a Python open source machine learning library designed to make performing standard tasks in a machine learning project easy. We will use pycaret to sweep all algorithm for a quick comparison.\n\nhttps:\/\/pycaret.org\/","569f385c":"### Build Model","c2a9d50f":"### Ideas to improve model performance\n* Hyperparameter tuning\n* Data augmentation - time masking, frequency masking, remove noise, add noise\n* Aggresive data cleaning\n* Ensemble model (bagging\/boosting\/stack)\n\n### Part 3 | Training using neural network","f3e0dc46":"## Machine Learning and Artificial Neural Network approach for COVID-19 Early Detection From Audio Recording | Part 2\nby Nasrul Hakim\n\nPart 1 : https:\/\/www.kaggle.com\/nasrulhakim86\/covid-19-screening-from-audio-part-1\n\n### Import Libraries","25100b97":"## Load Audio Data & Feature Extraction\nBefore feeding the audio data into the model for training, a few transformations were made to it for feature extraction.\n- Normalize, lowpass filter, and downsample cough samples\n- Select only the cough portion in the audio\n- Remove short segments\n- Make all audio segments the same size.\n- Rescale the data into [-1,1]","8a791356":"### Compare Model"}}