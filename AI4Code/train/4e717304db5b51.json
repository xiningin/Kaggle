{"cell_type":{"26a8d705":"code","255e9a9a":"code","0f077147":"code","1f7cbb0e":"code","bc3c67a6":"code","52256d37":"code","0e4cde93":"code","84f4f2d0":"code","18b2d13c":"code","0b6f33d5":"code","f5e3dcf2":"code","3b322f6f":"code","7a4b8780":"code","fb3d09cb":"code","c1ad38c3":"code","4725e29b":"code","22c7672e":"code","3dab5c7b":"code","aa17d96c":"markdown","056eca2b":"markdown","507cafc6":"markdown","659b0946":"markdown","5642edf8":"markdown","da0f9fe8":"markdown","d2b51deb":"markdown","caec87eb":"markdown","4960b289":"markdown","f6b89184":"markdown","719fc217":"markdown"},"source":{"26a8d705":"import numpy as np\nimport pandas as pd\nimport time\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import log_loss","255e9a9a":"%%time\ndf_train = pd.read_csv('..\/input\/predicting-outliers-to-improve-your-score\/train_clean.csv')\ndf_test = pd.read_csv('..\/input\/predicting-outliers-to-improve-your-score\/test_clean.csv')","0f077147":"df_train = df_train[df_train['outliers'] == 0]\ntarget = df_train['target']\ndel df_train['target']\nfeatures = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\ncategorical_feats = [c for c in features if 'feature_' in c]","1f7cbb0e":"param = {'objective':'regression',\n         'num_leaves': 31,\n         'min_data_in_leaf': 25,\n         'max_depth': 7,\n         'learning_rate': 0.01,\n         'lambda_l1':0.13,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\":0.85,\n         'bagging_freq':8,\n         \"bagging_fraction\": 0.9 ,\n         \"metric\": 'rmse',\n         \"verbosity\": -1,\n         \"random_state\": 2333}","bc3c67a6":"%%time\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2333)\noof = np.zeros(len(df_train))\npredictions = np.zeros(len(df_test))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n    print(\"fold {}\".format(fold_))\n    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n\n    num_round = 10000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval= 100, early_stopping_rounds = 200)\n    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))","52256d37":"model_without_outliers = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\nmodel_without_outliers[\"target\"] = predictions","0e4cde93":"%%time\ndf_train = pd.read_csv('..\/input\/predicting-outliers-to-improve-your-score\/train_clean.csv')\ndf_test = pd.read_csv('..\/input\/predicting-outliers-to-improve-your-score\/test_clean.csv')","84f4f2d0":"target = df_train['outliers']\ndel df_train['outliers']\ndel df_train['target']","18b2d13c":"features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month']]\ncategorical_feats = [c for c in features if 'feature_' in c]","0b6f33d5":"param = {'num_leaves': 31,\n         'min_data_in_leaf': 30, \n         'objective':'binary',\n         'max_depth': 6,\n         'learning_rate': 0.01,\n         \"boosting\": \"rf\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 11,\n         \"metric\": 'binary_logloss',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1,\n         \"random_state\": 2333}","f5e3dcf2":"%%time\nfolds = KFold(n_splits=5, shuffle=True, random_state=15)\noof = np.zeros(len(df_train))\npredictions = np.zeros(len(df_test))\nfeature_importance_df = pd.DataFrame()\n\nstart = time.time()\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n    print(\"fold n\u00b0{}\".format(fold_))\n    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n\n    num_round = 10000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))","3b322f6f":"### 'target' is the probability of whether an observation is an outlier\ndf_outlier_prob = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\ndf_outlier_prob[\"target\"] = predictions\ndf_outlier_prob.head()","7a4b8780":"# if the test set has the same ratio of outliers as training set, \n# then the numbuer of outliers in test is about: (1.06% outliers in training set)\n123623*0.0106","fb3d09cb":"# In case missing some predictable outlier, we choose top 25000 with highest outliers likelyhood.\noutlier_id = pd.DataFrame(df_outlier_prob.sort_values(by='target',ascending = False).head(25000)['card_id'])","c1ad38c3":"best_submission = pd.read_csv('..\/input\/predicting-outliers-to-improve-your-score\/3.695.csv')","4725e29b":"most_likely_liers = best_submission.merge(outlier_id,how='right')\nmost_likely_liers.head()","22c7672e":"%%time\nfor card_id in most_likely_liers['card_id']:\n    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target']\\\n    = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values","3dab5c7b":"model_without_outliers.to_csv(\"combining_submission.csv\", index=False)","aa17d96c":"## parameters","056eca2b":"## training model","507cafc6":"## parameters","659b0946":"# Combining your model with a model without outlier","5642edf8":"# Part 1 Training Model Without Outliers","da0f9fe8":"## filtering out outliers","d2b51deb":"## using outliers column as labels instead of target column","caec87eb":"# Part 3 Combining Submission:\nSo far so good !\nWe now have three dataset:\n\n1. Best Submission\n2. Prediction Using Model Without Outliers\n3. Probability of Outliers In Test set\n","4960b289":"## training model","f6b89184":"Assuming that you have already finished your feature engineering and you have two dataset:\n\n- ***train_clean.csv***\n- ***test_clean.csv***\n\nIn train_clean.csv, there's an **'outlier' column with values 1\/0. **\n\nBesides, you have your best LB submission:\n- ***3.695.csv*** (thanks  **Ashish Patel(\u963f\u5e0c\u4ec0)** My original model can't rich this score, so I try to use the idea to improve your submission to get better LB socre.\uff09\n\nThe flows of this pipline is as follows:\n1. Training a model using a training set without outliers. (we get: **Model_1**)\n2. Training a model to classify outliers. (we get: **Model_2**)\n3. Using **Model_2** to predict whether an card_id in test set is an outliers. (we get:**Outlier_Likelyhood**)\n4. Spliting out the card_id from **Outlier_Likelyhood** with top 10% (or some other ratio) score. (we get:**Outlier_ID**)\n5. Combining your submission using your **best submission (that is, your best model)** to predict **Outlier_ID** in test set and using **Model_1** to predict the rest of the test set.\n\nThe  basic idea behind this pipline is:\n1. Training model without outliers make the model more accurate for non-outliers.\n2. A great proportion of the error is caused by outliers, so we need to use a model training with outliers to predict them. How to find them out? build a classifier!","719fc217":"# Part 2 Training Model For Outliers Classification"}}