{"cell_type":{"6cbfddd1":"code","0b6fb87c":"code","99be6751":"code","a8699ca1":"code","b0f4d99f":"code","0e36d22e":"code","6a46496f":"code","7d1d2ad2":"code","03423832":"code","32e3d4ad":"code","395c9672":"code","7ebb17a0":"code","3ab243bc":"code","f69c638a":"code","2ea9116d":"code","d64f3076":"code","c8f84613":"code","452ffec7":"code","94ec7416":"code","cb9f6161":"code","858688c0":"code","72be52d8":"code","ba730704":"code","d22f0dc2":"code","be29942a":"markdown","95f3924f":"markdown","514d6147":"markdown","f4931351":"markdown","9fc1d29e":"markdown"},"source":{"6cbfddd1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.regularizers import l1\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import backend as K\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","0b6fb87c":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","99be6751":"all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n                      test.loc[:,'MSSubClass':'SaleCondition']))","a8699ca1":"all_data.info()","b0f4d99f":"all_data.head()","0e36d22e":"# Categorical Feature\ncat_feats = all_data.dtypes[all_data.dtypes == \"object\"].index\ncat_feats","6a46496f":"all_data[cat_feats].head()","7d1d2ad2":"# Numeric Feature\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\nnumeric_feats","03423832":"all_data[numeric_feats].head()","32e3d4ad":"# Ordinal Feature\nordinal_features = ['YrSold']","395c9672":"#log transform skewed numeric features:\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\nprint(skewed_feats)\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])","7ebb17a0":"#log transform the target:\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])","3ab243bc":"# One Hot Encoder\nall_data = pd.get_dummies(all_data)","f69c638a":"#filling NA's with the mean of the column:\nall_data = all_data.fillna(all_data.mean())","2ea9116d":"#creating matrices for sklearn:\nX_train = all_data[:train.shape[0]]\nX_test = all_data[train.shape[0]:]\ny = train.SalePrice","d64f3076":"X_train = StandardScaler().fit_transform(X_train)\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y, random_state = 3)\nX_tr.shape","c8f84613":"X_tr","452ffec7":"X_val","94ec7416":"#Model1\nmodel = Sequential()\n#model.add(Dense(256, activation=\"relu\", input_dim = X_train.shape[1]))\nmodel.add(Dense(1, input_dim = X_train.shape[1], W_regularizer=l1(0.001)))\n\nmodel.compile(loss = \"mse\", optimizer = \"adam\")","cb9f6161":"#Model2\nmodel = Sequential()\nBatchNormalization()\nmodel.add(Dense(1028,input_dim=288,activation='relu'))\nBatchNormalization()\nmodel.add(Dense(1028,input_dim=288,activation='relu'))\nBatchNormalization()\n#Dropout(0.2)\nmodel.add(Dense(100,input_dim=288,activation='relu'))\nBatchNormalization()\n#Dropout(0.2)\nmodel.add(Dense(50))\nBatchNormalization()\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam',loss='mse',metrics=['accuracy'])","858688c0":"model.summary()","72be52d8":"hist = model.fit(X_tr, y_tr, validation_data = (X_val, y_val))","ba730704":"scores = np.sqrt(model.evaluate(X_val,y_val,verbose=0))\nscores","d22f0dc2":"pd.Series(model.predict(X_val)[:,0]).hist()","be29942a":"## Model","95f3924f":"## Training & Test","514d6147":"## Preprocessing","f4931351":"Todo\n1. 5 Dense layers with a BatchNormalization each, followed by Dropout(0.2).","9fc1d29e":"Reference\n1. https:\/\/www.kaggle.com\/vishnus\/regression-using-keras\n1. https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models"}}