{"cell_type":{"ddb09ff2":"code","6632a2da":"code","c5061045":"code","3d3f7875":"code","4e0e1c37":"code","d83b56e5":"code","ac5f7e74":"code","52216ed2":"code","a5c47a6d":"code","59be6cda":"code","1a834c82":"code","a9c98282":"code","29595a1f":"code","f7628c6a":"code","705347fd":"code","5b43a7d1":"code","e34802ba":"code","025bcb8e":"code","0e894745":"code","920ff6e3":"code","e7049df1":"code","8a2084d8":"code","ad33fe85":"code","1bdd35bc":"code","f4e0c32e":"markdown","d5012857":"markdown","7158df61":"markdown","d1ffa6bd":"markdown","bf847bc8":"markdown","62d738cd":"markdown","85d91960":"markdown","384d9907":"markdown","8cac21a0":"markdown","eb8586b0":"markdown","d5c5df81":"markdown","bb599249":"markdown","3168faae":"markdown"},"source":{"ddb09ff2":"import pandas as pd\nimport matplotlib.pyplot as plt\n","6632a2da":"bmd_data = pd.read_csv('..\/input\/bmd-data\/bmd.csv')\nbmd_data.head()","c5061045":"bmd_data.fracture.unique()","3d3f7875":"pd.get_dummies(bmd_data.fracture,prefix='Con_').join(bmd_data.fracture).sample(frac=1.0).head()","4e0e1c37":"from sklearn.preprocessing import OneHotEncoder","d83b56e5":"OHE = OneHotEncoder()\npd.DataFrame(OHE.fit_transform(bmd_data[['fracture']]).toarray(),columns=['OHE_fracture','OHE_no_fracture']).join(bmd_data.fracture).sample(frac=1.0).head()","ac5f7e74":"OHE.categories_","52216ed2":"pokemon_data = pd.read_csv('..\/input\/pokemon\/PokemonData.csv')\npokemon_data.head()","a5c47a6d":"pokemon_data.Generation.unique()","59be6cda":"Generation_dict = {1 : 'Gen 1',2 : 'Gen 2',3 : 'Gen 3',4 : 'Gen 4',5 : 'Gen 5',6 : 'Gen 6'}","1a834c82":"pokemon_data['Generation_map'] = pokemon_data.Generation.map(Generation_dict)","a9c98282":"pokemon_data[['Generation','Generation_map']].sample(frac=1.0).head()","29595a1f":"from sklearn.preprocessing import LabelEncoder","f7628c6a":"LE = LabelEncoder()\npd.DataFrame(LE.fit_transform(pokemon_data['Type1']),columns=['LE Type 1']).join(pokemon_data['Type1']).sample(frac=1.0).head()","705347fd":"for i,Type_Class in enumerate(LE.classes_):\n  print(Type_Class , i)","5b43a7d1":"from sklearn.preprocessing import OrdinalEncoder","e34802ba":"pokemon_data.Generation_map.unique()","025bcb8e":"OE = OrdinalEncoder(categories =[['Gen 6','Gen 5','Gen 4','Gen 3','Gen 2','Gen 1']] )\npd.DataFrame(OE.fit_transform(pokemon_data[['Generation_map']]),columns=['Generation_OE']).join(pokemon_data.Generation_map).sample(frac=1.0).head()","0e894745":"OE.categories_","920ff6e3":"views = pd.DataFrame([1295, 25, 19000, 5, 1, 300], columns=['views'])\nviews","e7049df1":"import seaborn as sns\n\nsns.distplot(views);","8a2084d8":"from sklearn.preprocessing import StandardScaler\n\nSS = StandardScaler()\nviews['z-score'] = SS.fit_transform(views[['views']])\nviews","ad33fe85":"from sklearn.preprocessing import MinMaxScaler\n\nMMS=MinMaxScaler()\nviews['minmax']=MMS.fit_transform(views[['views']])\nviews","1bdd35bc":"from sklearn.preprocessing import RobustScaler\n\nRS=RobustScaler()\nviews['RobustScale']=RS.fit_transform(views[['views']])\nviews","f4e0c32e":"## Robust Scaler\n--\nThe **disadvantage of min-max scaling is that often the presence of outliers affects the scaled values for any feature**. Robust scaling tries to use specific statistical measures to scale features without being affected by outliers.\n \nMathematically this scaler can be represented as\n\n![formaulae Robust scalar](https:\/\/drive.google.com\/uc?id=1FwIr7l-yskuuj2X2jXc5DJRoXlEwe25a 'formulae_robust_scalar')\n\n\nwhere we scale each value of feature X by subtracting the median of X and dividing the resultant by the **IQR also known as the Inter-Quartile Range** of X which is the range (difference) between the **first quartile (25th %ile) and the third quartile (75th %ile)**.\n","d5012857":"# Encoding Categorical Data\n\nSome ML model only understands numeric data. So it is essential for us to convert any categorical data to numeric.\n\n","7158df61":"## OneHotEncoder\n\n","d1ffa6bd":"# Scaling Numerical Data\n\nML model can be biased towards numerical data that have large values. We will see some example to scale numerical data. ","bf847bc8":"## StandardScaler\n\n![formaulae standard scalar](https:\/\/drive.google.com\/uc?id=1PBGU5qKDpC2L30wKPKYmgHLqmE3paSlf 'formulae_standard_scalar')\n\nwhere each value in feature `X` is subtracted by the mean `\u03bcX` and the resultant is divided by the standard deviation `\u03c3X`.\n\nThis is also popularly known as `Z-score scaling`.\n\nShould be avoided when there are outliers","62d738cd":"## Get Dummies","85d91960":"## LabelEncoder\n\nUsed for encoding 1-D array or target variables that are in no particular order. ","384d9907":"In above fracture column we can see that we have 2 categorical value as 'no fracture' and 'fracture'.","8cac21a0":"## Min-Max Scaler\n\nWith min-max scaling, we can transform and scale our feature values such that each value is within the range of [0, 1].\n\n![formaulae minMax scalar](https:\/\/drive.google.com\/uc?id=1YokMGzpHTlCKNqqFYS9QnfQvbdt_BDP9 'formulae_minMax_scalar')\n\nShould be avoided when there are outliers.","eb8586b0":"## Using asmap()","d5c5df81":"## OrdinalEncoder\n\nUsed for encoding 2-D array or feature variables that are in particular order. ","bb599249":"From above new columns we can see that new 2 columns has been generated that corresponds to fracture column values This work can be done by using OneHotEncoder class.","3168faae":"# Sklearn\n\nIn this notebook we will be learning some Sklearn functionality that will help in our ML journey."}}