{"cell_type":{"333cdb5a":"code","992e898a":"code","cadd9c82":"code","af0750ff":"code","cfcf3789":"code","c388a2b5":"code","ab3e7275":"code","4cc0b488":"code","33ca74c9":"code","c69aacad":"code","e1f74e28":"code","fb7c9a9d":"code","c4c25e9b":"code","6b7e2e20":"code","20745bb6":"code","a0d09549":"code","55e78bdd":"code","a5e14a00":"code","07a4a1a6":"code","8f6cda54":"code","dae0b91b":"code","27633671":"code","10741753":"code","cdfb083c":"markdown","9ea8f213":"markdown","d55fee7a":"markdown","4b82245b":"markdown"},"source":{"333cdb5a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","992e898a":"users=pd.read_csv('\/kaggle\/input\/bookcrossing-dataset\/Book reviews\/BX-Users.csv',sep=';',encoding='latin')\nusers.head()","cadd9c82":"i_cols = ['isbn', 'book_title' ,'book_author','year_of_publication', 'publisher', 'img_s', 'img_m', 'img_l']\nbooks = pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX-Books.csv', sep=';', names=i_cols, encoding='latin-1',low_memory=False)\nbooks.head()","af0750ff":"ratings=pd.read_csv('\/kaggle\/input\/bookcrossing-dataset\/Book reviews\/BX-Book-Ratings.csv',sep=';',encoding='latin')\nratings=ratings.rename(columns={'ISBN':'isbn'})\nratings.head()","cfcf3789":"user=pd.merge(users,ratings,on='User-ID')\ndataset=pd.merge(user,books,on='isbn')\ndataset.head()","c388a2b5":"location=dataset.Location.str.split(', ',n=2,expand=True)\nlocation.columns=['City','State','Country']\ndataset['City']=location['City']\ndataset['State']=location['State']\ndataset['Country']=location['Country']\ndataset.head()","ab3e7275":"data=dataset.drop(columns=['Age','Location','img_s','img_m','img_l'],axis=1)\ndata.head()","4cc0b488":"data['Reviews']=np.where(data['Book-Rating']>4,1,0)\ndata.head()","33ca74c9":"data['Book_title_City_Reviewed']=data[['book_title','City','State']].apply(lambda x:','.join(x),axis=1)\ndata.head()","c69aacad":"new_data=data[data['Country']!='n\/a']\nnew_data.head()","e1f74e28":"sns.pairplot(data)\nplt.show()","fb7c9a9d":"print('Average Of Reviews with not good Remarks', len(data.loc[data['Reviews']==0])\/len(data.loc[data['Reviews']]))\nprint('Average Of Reviews with  good Remarks', len(data.loc[data['Reviews']==1])\/len(data.loc[data['Reviews']]))     ","c4c25e9b":"good_remarks=[len(x) for x in data.loc[data['Reviews']==1,'book_title']]              \nnotgood_remarks=[len(x) for x in data.loc[data['Reviews']==0,'book_title']] \nprint('Average length of Book Title for good remarks',np.mean(good_remarks))\nprint('Average length of Book Title for not good remarks',np.mean(notgood_remarks))","6b7e2e20":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import MultinomialNB\nX=new_data['Book_title_City_Reviewed']\ny=new_data['Reviews']\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\nvect=CountVectorizer(min_df=5,ngram_range=(1,2)).fit(X_train)","20745bb6":"X_train_trans=vect.transform(X_train)\nlr=MultinomialNB(alpha=0.1).fit(X_train_trans,y_train)\npredict=lr.predict(vect.transform(X_test))\nnames=np.array(vect.get_feature_names())\ncoeff=lr.coef_[0].argsort()","a0d09549":"print('roc_auc_score {:.2%}'.format(metrics.roc_auc_score(y_test,predict)))\n","55e78bdd":"largest=names[coeff[:-11:-1]]\nsmallest=names[coeff[:10]]\nnot_good_remarks=pd.DataFrame(coeff[:10],index=smallest,columns=['Count'])\ngood_remarks=pd.DataFrame(coeff[:-11:-1],index=largest,columns=['Count'])\n","a5e14a00":"not_good_remarks.head()","07a4a1a6":"print('Average Frequency titles' ,np.mean(not_good_remarks['Count']))","8f6cda54":"good_remarks.head()","dae0b91b":"print('Average Frequency of titles',np.mean(good_remarks['Count']))","27633671":"plt.plot(not_good_remarks['Count'])\nplt.xticks(rotation=45)\nplt.xlabel('Titles')\nplt.ylabel('Frequency')\nplt.title('NotGood_Remarks Title with its Frequency')\nplt.show()","10741753":"plt.plot(good_remarks['Count'])\nplt.xticks(rotation=45)\nplt.xlabel('Titles')\nplt.ylabel('Frequency')\nplt.title('Good_Remarks Title with its Frequency')\nplt.show()","cdfb083c":"Creating Dataframes of book title frequency for respective reviews","9ea8f213":"Removing Rows with Country as (n\/a)","d55fee7a":"Merging of Datasets","4b82245b":"Training of Model"}}