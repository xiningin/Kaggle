{"cell_type":{"0bfaa576":"code","b8e2500b":"code","266ed510":"code","b63a5fc4":"code","845656e1":"code","88b3a62d":"code","eb4f895a":"code","ce6826b2":"code","9480c553":"code","257df43b":"code","d7487bb4":"code","cf042dae":"code","0b35782d":"code","4dcae37d":"code","af80a9fd":"code","28f564c4":"code","8a709c26":"code","db2ef729":"code","a2677b91":"code","047aa22e":"code","9bb49de6":"code","bd2155d1":"code","be4eefcf":"code","c8c0e114":"code","57d132a5":"code","035c942e":"code","5fd8d1ea":"code","21d98e3f":"code","f350dea6":"code","3a5e6e28":"code","ea54ce15":"code","020239b3":"markdown","70d32d1e":"markdown","c7548387":"markdown","74a87e31":"markdown","f7a645a9":"markdown","202a3893":"markdown","444841c6":"markdown","094ac6bf":"markdown","cb832357":"markdown","f650103d":"markdown","0f345d46":"markdown","a2b978ee":"markdown"},"source":{"0bfaa576":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b8e2500b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Conv2D,MaxPool2D\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","266ed510":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntrain.head()","b63a5fc4":"y=train['label']\nX=train.drop(['label'],1)","845656e1":"X=np.array(X)\nX.shape","88b3a62d":"y=np.array(y)\ny.shape","eb4f895a":"def plot_images(X,y):\n    for i in range(20):\n        plt.subplot(5,4,i+1)\n        plt.tight_layout()\n        plt.imshow(X[i].reshape(28,28),cmap='gray')\n        plt.title('Digit:{}'.format(y[i]))\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","ce6826b2":"plot_images(X,y)","9480c553":"trainX,valX,trainY,valY=train_test_split(X,y,test_size=0.1,random_state=42)","257df43b":"print(trainX.shape)\nprint(trainY.shape)","d7487bb4":"print(valX.shape)\nprint(valY.shape)","cf042dae":"trainX=trainX\/255\nvalX=valX\/255","0b35782d":"trainX=trainX.reshape(trainX.shape[0],28,28,1)\nvalX=valX.reshape(valX.shape[0],28,28,1)","4dcae37d":"trainY=to_categorical(trainY)\nvalY=to_categorical(valY)","af80a9fd":"model=Sequential([\n    Conv2D(filters=96,kernel_size=(5,5),padding='same',activation='relu',input_shape=(28,28,1)),\n    MaxPool2D(strides=2),\n    Conv2D(filters=128,kernel_size=(5,5),padding='valid',activation='relu'),\n    MaxPool2D(strides=2),\n    Conv2D(filters=128,kernel_size=(3,3),padding='valid',activation='relu'),\n    MaxPool2D(strides=2),\n    Flatten(),\n    Dense(256,activation='relu'),\n    Dense(128,activation='relu'),\n    Dense(10,activation='softmax')\n])","28f564c4":"model.summary()","8a709c26":"adam=tf.optimizers.Adam(lr=5e-4)\nmodel.compile(loss='categorical_crossentropy',\n             metrics=['accuracy'],\n             optimizer=adam)","db2ef729":"reduce_lr=ReduceLROnPlateau(monitor='val_acc',\n                           patience=3,\n                           varbose=1,\n                           factor=0.2,\n                           min_lr=1e-4)\n","a2677b91":"history=model.fit(trainX,trainY,\n                 steps_per_epoch=len(trainX)\/100,\n                 epochs=30,\n                 validation_data=(valX,valY),\n                 callbacks=[reduce_lr])","047aa22e":"score=model.evaluate(valX,valY,batch_size=32)\nscore","9bb49de6":"EPOCH=range(1,31)\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nplt.figure(figsize=(10,6))\nplt.plot(EPOCH,acc,'b--',label='Training Accuracy')\nplt.plot(EPOCH,val_acc,'b',label='Validation Accurayc')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","bd2155d1":"loss=history.history['loss']\nval_loss=history.history['val_loss']\nplt.figure(figsize=(10,6))\nplt.plot(EPOCH,loss,'b--',label='Training Loss')\nplt.plot(EPOCH,val_loss,'b',label=\"validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","be4eefcf":"test=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest.head()","c8c0e114":"testX=np.array(test)\ntestX.shape","57d132a5":"testX=testX\/255","035c942e":"testX=testX.reshape((testX.shape[0],28,28,1))\ntestX.shape","5fd8d1ea":"testY=model.predict(testX)","21d98e3f":"testY=np.argmax(testY,axis=1)\ntestY[:5]","f350dea6":"df_out=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\ndf_out.head()","3a5e6e28":"df_out['Label']=testY\ndf_out.head()","ea54ce15":"df_out.to_csv('out.csv',index=False)","020239b3":"# Preprocessing","70d32d1e":"# Plot Digits","c7548387":"**Reshaping pixels from (,784) into (,28,28,1) #(,width,height,channel)**","74a87e31":"# CNN Architecture","f7a645a9":"**Set a learning rate annealer**","202a3893":"**Converting into One-Hot Vector**","444841c6":"**Normalizing Data**","094ac6bf":"# Create submission file","cb832357":"# Plotting Loss and Accuracy","f650103d":"**Splitting Dataset into training and validation dataset with validation size of 10%**","0f345d46":"# Load Data\n","a2b978ee":"# Let's predict test data"}}