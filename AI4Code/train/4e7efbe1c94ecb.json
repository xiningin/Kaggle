{"cell_type":{"8993bae0":"code","e3b98ca9":"code","3ba91349":"code","919e033e":"code","d9cdc0ed":"code","87b46d4c":"code","f049e838":"code","b077a398":"code","93603587":"markdown","4172211e":"markdown"},"source":{"8993bae0":"#Import all required library\nimport io\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds","e3b98ca9":"#download dataset from IMBD\ndataset, info = tfds.load('imdb_reviews\/subwords8k', with_info=True,\n                          as_supervised=True)","3ba91349":"#assigne the training & test dataset\ntrain_dataset, test_dataset = dataset['train'],dataset['test']\n\nencoder = info.features['text'].encoder\n\nBUFFER_SIZE = 10000\nBATCH_SIZE = 64\n\npadded_shapes = ([None],())\n\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,\n                                                               padded_shapes=padded_shapes)\ntest_dataset = test_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,\n                                                               padded_shapes=padded_shapes)\n","919e033e":"#Prepare some helper functions in advances\ndef pad_to_size(vec, size):\n    zeros = [0]*(size-len(vec))\n    vec.extend(zeros)\n    return vec\n\ndef sample_predict(sentence, pad, model):\n    encoded_sample_pred_text = encoder.encode(sentence)\n    if pad:\n        encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n    predictions = model.predict(tf.expand_dims(encoded_sample_pred_text,0))\n    \n    return predictions","d9cdc0ed":"\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(encoder.vocab_size,64),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')])\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=tf.keras.optimizers.Adam(1e-4),\n             metrics=['accuracy'])\n\n# This is going to take 5 minutes\nhistory = model.fit(train_dataset, epochs=5, validation_data = test_dataset,\n                  validation_steps=30)\n","87b46d4c":"# Let's see the prediction accuracy with 4 layers\n\nsample_text = ('This movie was super awesome. The acting was incredible. higly recommend to all comedic lovers ')\npredictions = sample_predict(sample_text, pad=True, model=model) * 100\nprint('probability of positive review %.2f' % predictions)\n\n\nsample_text = ('This movie was so so. The acting was medicore.')\npredictions = sample_predict(sample_text, pad=True, model=model) * 100\nprint('probability of positive review %.2f' % predictions)","f049e838":"new_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(encoder.vocab_size,64),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n    #new layer with LSTM(32)\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    #new layer with Dropout, prevent overfitting\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')])\n\nnew_model.compile(loss='binary_crossentropy',\n             optimizer=tf.keras.optimizers.Adam(1e-4),\n             metrics=['accuracy'])\n\n#this will take 6.5 mintues\nhistory =new_model.fit(train_dataset, epochs=5, validation_data = test_dataset,\n                  validation_steps=30)\n\n\n","b077a398":"# Let's see the prediction accuracy with 6 layers\n\nsample_text = ('This movie was super awesome. The acting was incredible. higly recommend to all comedic lovers ')\npredictions = sample_predict(sample_text, pad=True, model=new_model) * 100\nprint('probability of positive review %.2f' % predictions)\n\n\nsample_text = ('This movie was so so. The acting was medicore.')\npredictions = sample_predict(sample_text, pad=True, model=new_model) * 100\nprint('probability of positive review %.2f' % predictions)","93603587":"## Kick start the first NLP with Tensorflow2\nThis is based on the youtube video course from freeCodeCamp (https:\/\/www.youtube.com\/watch?v=B2q5cRJvqI8&t=3688s). This code shows additional neural network layers help improving sentiment detection accuracy.\n\n*This notebook will 15 mintues to run.*\n\n**Please use GPU accelerator** (instead of TPU) for faster network building! ","4172211e":"### Let's make a model with **few layers**, and see how is the prediction performance"}}