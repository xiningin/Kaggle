{"cell_type":{"2933e716":"code","93a29dac":"code","f02bc5ad":"code","ca48ec98":"code","e867a633":"code","50ad18ee":"code","2e183373":"code","82c81808":"code","fc466e58":"code","0761d75c":"code","7e640799":"code","f016ae1a":"markdown","553a4c63":"markdown","33b2aa63":"markdown","fa4336f9":"markdown"},"source":{"2933e716":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV, train_test_split \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport re,string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.tokenize import word_tokenize","93a29dac":"resturant_df = pd.read_csv(\"\/kaggle\/input\/restaurant-reviews\/Restaurant_Reviews.tsv\",sep='\\t')\nresturant_df.head()               ","f02bc5ad":"resturant_df.Liked.value_counts()","ca48ec98":"def clean_data(data):\n    sw= stopwords.words('english')\n    sw.remove('not')\n    sw.remove(\"don't\")\n    sw.remove(\"shouldn't\")\n    sw.remove(\"wouldn't\")\n    lemma=WordNetLemmatizer()\n    ps = PorterStemmer()\n    \n    re.sub(r\"http\\S+|www.*\", \"\", data)#remove url links\n    data = word_tokenize(data.lower())#lowercase and tokenize the words\n    data = [word for word in set(data) if word.isalpha() and word not in string.punctuation and word!='\\n' and len(word) > 2 and word not in sw]\n    \n    #data = [lemma.lemmatize(word, pos='v') for word in data]\n    #data = [ps.stem(word) for word in data]\n    return \" \".join(data)\n\nresturant_df['Review_clean']=resturant_df['Review'].apply(clean_data)\nresturant_df['Review_clean'].head()","e867a633":"cv = CountVectorizer(max_features= 2000)\nX= cv.fit_transform(resturant_df['Review_clean']).toarray()\ny= resturant_df['Liked']\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,stratify=y,random_state=4)","50ad18ee":"print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)","2e183373":"print(\"***Naive Bayes Model***\")\ngnb_model = GaussianNB()\ngnb_model.fit(x_train,y_train)\ny_pred = gnb_model.predict(x_test)\ngnb_acc_score= accuracy_score(y_test,y_pred)\nprint(\"Accuracy Score:\", round(gnb_acc_score * 100,2),\"%\")\nprint(\"Confusion Matrix\")\ngnb_cm = confusion_matrix(y_test, y_pred)\nprint(gnb_cm)\n","82c81808":"print(\"***RandomForest Classifier Model***\")\nrfc_model = RandomForestClassifier(n_estimators=1000,criterion='entropy')\nrfc_model.fit(x_train,y_train)\ny_pred = rfc_model.predict(x_test)\nrfc_acc_score= accuracy_score(y_test,y_pred)\nprint(\"Accuracy Score:\", round(rfc_acc_score * 100,2),\"%\")\nprint(\"Confusion Matrix\")\nrfc_cm = confusion_matrix(y_test, y_pred)\nprint(rfc_cm)","fc466e58":"print(\"***Logistic Regression Model***\")\nlr_model = LogisticRegression()\nlr_model.fit(x_train,y_train)\ny_pred = lr_model.predict(x_test)\nlr_acc_score= accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy Score:\", round(lr_acc_score * 100,2),\"%\")\nprint(\"Confusion Matrix\")\nlr_cm = confusion_matrix(y_test, y_pred)\nprint(lr_cm)","0761d75c":"print(\"***GradientBoosting ClassifierModel***\")\ngb_model = GradientBoostingClassifier()\ngb_model.fit(x_train,y_train)\ny_pred = gb_model.predict(x_test)\n\ngb_acc_score= accuracy_score(y_test,y_pred)\nprint(\"Accuracy Score:\", round(gb_acc_score * 100,2),\"%\")\nprint(\"Confusion Matrix\")\ngb_cm = confusion_matrix(y_test, y_pred)\nprint(gb_cm)","7e640799":"data = {'Model':['Naive Bayes','RandomForest','Logistic Regression','GradientBoosting'],'Accuracy Score':[gnb_acc_score,rfc_acc_score,lr_acc_score,gb_acc_score]}\n\ncomparision_table=pd.DataFrame(data)                               \nprint(comparision_table)","f016ae1a":"# Importing the dataset","553a4c63":"# Logistic Regression seems to be the winner in this case!!","33b2aa63":"# Import the libraries","fa4336f9":"# **Basic example for bag of words model**"}}