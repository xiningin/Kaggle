{"cell_type":{"69f6b241":"code","f99d2f81":"code","115708a5":"code","b07c05d1":"code","51106b1c":"code","1ff5dfd6":"code","ce5703c4":"code","aab85122":"code","c0a838f3":"code","776ae794":"code","76e7585a":"code","043ea97d":"code","d6ecda01":"code","108d1eff":"code","5b43937b":"code","0f3a2c9e":"code","e561c80c":"code","7144e260":"code","3844d87e":"code","3bb1ba6e":"code","fd97d231":"code","418f8e95":"code","0d02df12":"code","e944ca3a":"code","da2846fe":"code","ae04bd82":"code","e0080153":"code","eb2c3ef7":"code","4b4058fc":"code","547021dd":"code","870e0788":"code","3db8a086":"code","35dfe61c":"code","4c066280":"code","a97f1474":"code","cfdca308":"code","c59bef32":"code","6b5ae945":"code","c9d1e5c9":"code","e6cefc1d":"code","60552b5e":"code","c49ceda5":"code","a1bf486e":"code","98640244":"code","cdbcf35e":"markdown","50d62ecc":"markdown","b87be627":"markdown","16de4fff":"markdown","7ccb2874":"markdown","071d4267":"markdown"},"source":{"69f6b241":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f99d2f81":"data = pd.read_csv(\"..\/input\/pakistans-largest-ecommerce-dataset\/Pakistan Largest Ecommerce Dataset.csv\", index_col =\"Customer ID\")","115708a5":"data.head()","b07c05d1":"data.info()","51106b1c":"#data.loc[:, 'Unnamed: 21' : 'Unnamed: 25']\ndata.drop([ 'Unnamed: 22', 'Unnamed: 23','Unnamed: 24'], inplace = True, axis=1)\ndata.drop('item_id', axis=1, inplace = True)\n","1ff5dfd6":"data.info()","ce5703c4":"data.isnull().sum()","aab85122":"data.increment_id.describe()","c0a838f3":"# Increment id, item_id and customer ID are same.\ndata.drop('increment_id', axis=1, inplace =True)","776ae794":"data.info()","76e7585a":"# have a look on SKU\ndata.sku.describe()\ndata.sku.head(15)\n#useless for me\ndata.drop('sku', axis=1, inplace = True)","043ea97d":"# Sales commission is also useless.\nprint(data['sales_commission_code'].describe())\ndata.drop('sales_commission_code', axis= 1, inplace= True)\n\n\n","d6ecda01":"# working date, created date, year, Month, M-Y, FY  are same columns\nprint(data[['Working Date','created_at','Year', 'Month', 'M-Y', 'FY']])","108d1eff":"#so let me make new feature \ndata['Date'] = data['Working Date']\n#now lets remove other\ndata.drop(['Working Date','created_at','Year', 'Month', 'M-Y', 'FY'], axis=1, inplace = True)","5b43937b":"data.info()","0f3a2c9e":"data.head(10)","e561c80c":"# Unnamed: 21; Unnamed: 25; MV, which is equal to price; BI status, Customer Since are not usefull features so lets remove them.\ndata.drop(['Unnamed: 21', 'Unnamed: 25', 'BI Status', 'Customer Since'], axis=1, inplace = True)","7144e260":"print(data[' MV '].describe())\ndata.drop(' MV ', axis= 1, inplace = True)","3844d87e":"data.head()","3bb1ba6e":"#lets have a look on status\n#data.info()\nprint(data['status'].describe())\ndata['status'].unique()","fd97d231":"data['Satisfiction'] = data.status","418f8e95":"data.Satisfiction = data.Satisfiction.replace({\"order_refunded\": \"not-satisfy\", \"canceled\": \"not-satisfy\",\"refund\": \"not-satisfy\",\n                                               \"closed\": \"not-satisfy\", \"fraud\": \"not-satisfy\", \"pending_paypal\": \"not-satisfy\"})","0d02df12":"data.Satisfiction = data.Satisfiction.replace({\"\\\\N\": \"not-satisfy\",'cod':'not-satisfy','pending':'not-satisfy','nan':'not-satisfy','processing':'Satisfy',\n                                               'payment_review':'Satisfy','paid':'Satisfy','exchange': 'Satisfy', 'holded':'Satisfy','received':'Satisfy','complete':'Satisfy' })","e944ca3a":"data.Satisfiction.head(10)\ndata.rename(columns={'Satisficton':'Satisfaction'}, inplace = True)","da2846fe":"data.head()","ae04bd82":"# this is my final DataFrame, now lets explore each feature and make it perfect for our visualization.\nprint(data.count())\ndata.isnull().sum()","e0080153":"# dropping all row which all element are null\ndata.dropna(how='all', inplace = True)\n","eb2c3ef7":"#now see, how many null values are avaliable.\ndata.isnull().sum()\n\n","4b4058fc":"# now lets focuse on status, Satisfaction and category_name_1\ndata.status.describe()\ndata.status.mode()\n# lets fill status and satisfaction  with mode value\ndata.status.fillna(str(data.status.mode()), inplace = True)","547021dd":"data.Satisfiction.fillna(str(data.Satisfiction.mode()), inplace = True)\ndata.isnull().sum()\n","870e0788":"data.head()","3db8a086":"# lets look category_name_1\ndata['category_name_1'].unique()","35dfe61c":"data['category_name_1'].mode()\n# it think, filling with mode would be find.\ndata['category_name_1'].fillna(str(data['category_name_1'].mode()), inplace = True)","4c066280":"# finally data is completely find.\ndata.isnull().sum()","a97f1474":"data.head()","cfdca308":"cat = data.groupby('category_name_1')\nhpc= cat['price'].agg(np.sum)\nbsc= cat['qty_ordered'].agg(np.sum)\n\nprint(\"Best Selling Category\\n\", bsc)","c59bef32":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(20 ,8))\nplt.plot(bsc, linestyle='--', marker='o', ms=10, mec='r', color='k',mew=5)\nplt.xticks(rotation = 90)\nplt.title('Best selling category', size =20)\nplt.ylabel('total no of order', size= 20)\nplt.show()","6b5ae945":"v = data.groupby('Satisfiction')\nlevel = v['qty_ordered'].agg(np.sum)\nlevel","c9d1e5c9":"status = data.groupby('status')\nno_of_order = status['qty_ordered'].agg(np.sum)\nno_of_order","e6cefc1d":"fig, (a, b) = plt.subplots(1,2, figsize=(20,7), sharey = True)\na.plot(level, linestyle='--', marker='o', ms=10, mec='b', color='k',mew=5)\na.set_xlabel('level of satisfaction')\n\nb.plot(no_of_order,linestyle='--', marker='o', ms=10, mec='r', color='k',mew=5 )\nb.tick_params(labelrotation=90)\nb.set_xlabel('status of Orders')\na.set_ylabel('No of Orders')","60552b5e":"data.head()","c49ceda5":"data.discount_amount.value_counts()\nplt.boxplot(data.discount_amount)\n# lets drop some big bugs\noutlier_IDs = data.loc[data.discount_amount > 20000].index\ndata.drop(outlier_IDs, inplace = True)\n","a1bf486e":"d = data.groupby('status')\ndis= d['discount_amount'].agg(np.mean)","98640244":"plt.figure(figsize=(15,6))\nplt.plot(dis, ls=\"--\", marker='o', mec='r',ms=10, mfc='r', color = 'k')\nplt.xticks(rotation= 'vertical')\nplt.title('Shows that, after getting Discount what was the reaction of customers')\nplt.show()","cdbcf35e":" # **Cleaning Data and Transformation of Data**","50d62ecc":"# **Insights** :","b87be627":"## Those people who got discount, did they buy the product and what was the status?","16de4fff":"## Status of orders and their  satisfaction level w.r.t No of Orders","7ccb2874":"# **EDA**","071d4267":"## \u2022 What is the best-selling category?\n"}}