{"cell_type":{"2561b3c7":"code","42fbdc45":"code","9e00ce11":"code","4284f33c":"code","b344118b":"code","4c1dd1f7":"code","dacad9e7":"code","5eaeabb5":"code","8312216f":"code","a92c28f6":"code","2d14f3c6":"code","8e9e0644":"code","9ab2b21f":"code","13ae4ad0":"markdown","0d5c7513":"markdown","3cae4a08":"markdown","a647e00b":"markdown","3354188a":"markdown","08bb7db3":"markdown","d3414480":"markdown","6bd6cbe6":"markdown","63fa08a5":"markdown","998e17ab":"markdown","b536f46a":"markdown","886e21ee":"markdown"},"source":{"2561b3c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42fbdc45":"# example of loading the fashion mnist dataset\nfrom matplotlib import pyplot\nfrom keras.datasets import fashion_mnist","9e00ce11":"# load dataset\n(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n# summarize loaded dataset\nprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\nprint('Test: X=%s, y=%s' % (testX.shape, testy.shape))","4284f33c":"# plot first few images\nfor i in range(9):\n    pyplot.subplot(330 + 1 + i)\n    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n# show the figure\npyplot.show()","b344118b":"from tensorflow.keras.utils import to_categorical\n# reshape dataset to have a single channel\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\n\n# one hot encode target values\ntrainy = to_categorical(trainy)\ntesty = to_categorical(testy)","4c1dd1f7":"# convert from integers to floats\ntrain_norm = trainX.astype('float32')\ntest_norm = testX.astype('float32')\n# normalize to range 0-1\ntrain_norm = train_norm \/ 255.0\ntest_norm = test_norm \/ 255.0\n\ntrain_norm_y = trainy.astype('float32')\ntest_norm_y = testy.astype('float32')\n# normalize to range 0-1\ntrain_norm_yy = train_norm_y \/ 255.0\ntest_norm_yy = test_norm_y \/ 255.0","dacad9e7":"# scale pixels\ndef prep_pixels(train, test):\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    train_norm = train_norm \/ 255.0\n    test_norm = test_norm \/ 255.0\n    return train_norm, test_norm","5eaeabb5":"prep_pixels(train_norm, train_norm_y);","8312216f":"from sklearn.model_selection import KFold\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom tensorflow.keras.optimizers import SGD","a92c28f6":"def define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(10, activation='softmax'))\n    # compile model\n    opt = SGD(learning_rate=0.01, momentum=0.9)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","2d14f3c6":"define_model()","8e9e0644":"def evaluate_model(dataX, dataY, n_folds=5):\n    scores, histories = list(), list()\n    # prepare cross validation\n    kfold = KFold(n_folds, shuffle=True, random_state=1)\n    # enumerate splits\n    for train_ix, test_ix in kfold.split(dataX):\n        # define model\n        model = define_model()\n        # select rows for train and test\n        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n        # fit model\n        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n        # evaluate model\n        _, acc = model.evaluate(testX, testY, verbose=0)\n        print('> %.3f' % (acc * 100.0))\n        # append scores\n        scores.append(acc)\n        histories.append(history)\n    return scores, histories","9ab2b21f":"evaluate_model(train_norm, train_norm_y)","13ae4ad0":"# We get a glimpse of how our data looks like","0d5c7513":"# We Split the data into training and testing","3cae4a08":"# We Now Evaluate our model","a647e00b":"# After encoding thte values we cast them into floats for further processing","3354188a":"# We load the data here","08bb7db3":"# We prepare the pixels in array form","d3414480":"# After defining our loss function and optimizer as categorical_crossentropy and opt as its fashion dataset and categorical encoding needs to be cross checked for the gradient to be accurate","6bd6cbe6":"# Different Aspects of the fashion dataset","63fa08a5":"# We define our model with 5 layers and softmax activiation and he_uniform intializer to ensure our model trains all fitted values","998e17ab":"# pixels done","b536f46a":"# As shown we achieved 90% above accuracy due to data being completely sorted and minium use of computing power required\n* We could have used other loss fucntions for better performances\n* Used gradient Descent\n* transformed our data to greater extents before testing and training splits","886e21ee":"# We import accuracy metrics and modelling algorithms of Deep learning"}}