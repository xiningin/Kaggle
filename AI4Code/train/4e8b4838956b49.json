{"cell_type":{"cb9e7f62":"code","d08f14f9":"code","b3c8176e":"code","ea479e4d":"code","835263cc":"code","32fce12e":"code","359d7236":"code","d54bba01":"code","80652e5e":"code","bf09bb47":"code","a86ff133":"code","a5ff9289":"code","a49854f5":"code","a7f7cb2d":"code","c325bd08":"code","5dc119fc":"code","a53a39bc":"code","89de9cd2":"code","8dce614b":"code","d7c0d721":"code","221cfd0a":"code","0c637412":"code","bc741ab3":"code","3ee9ea74":"code","db4d72be":"markdown","ba0da923":"markdown","e853dca3":"markdown","8282833b":"markdown","8ad58c8d":"markdown","1d48d45c":"markdown","742d3762":"markdown","08736654":"markdown","deecad41":"markdown","d89322be":"markdown","310ed43e":"markdown","e3b26af7":"markdown","e76fec0c":"markdown","62619c8d":"markdown","5f2fcdb3":"markdown","fb28db0e":"markdown","fd67c1dc":"markdown","b1a0d2d1":"markdown","f107131f":"markdown","1256a154":"markdown","0c629c7d":"markdown","9e598f9e":"markdown","dfd81ac0":"markdown","9737f566":"markdown","d312b6a8":"markdown","8338fad8":"markdown","3972986f":"markdown","7aec65f5":"markdown","a9a0c908":"markdown","eed0c95c":"markdown","98a6f872":"markdown","f77873f8":"markdown","9ae36a26":"markdown","e055b69c":"markdown","8c0978a9":"markdown","7ab57b02":"markdown","6882589c":"markdown","5ee64309":"markdown","6b96d1e5":"markdown","146bfedc":"markdown"},"source":{"cb9e7f62":"!pip install scikit-learn-intelex\n!pip install scikit-learn==1.0.1\n!pip install sympy","d08f14f9":"#@title\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearnex import patch_sklearn\npatch_sklearn()\nfrom sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nimport os\nimport pprint\nimport pickle\nfrom tensorflow.keras.layers import Activation , LeakyReLU, PReLU, ThresholdedReLU\nfrom tensorflow.keras.activations import sigmoid, elu, gelu, linear, relu, selu, softmax, softplus, softsign\nfrom tensorflow.keras.constraints import max_norm, min_max_norm,non_neg, unit_norm, radial_constraint\nfrom tensorflow.keras.layers import LayerNormalization ,BatchNormalization\nfrom tensorflow.keras.layers import Dropout, GaussianDropout, AlphaDropout\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback\nfrom tensorflow.keras import mixed_precision\nfrom sklearn.utils import parallel_backend\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport logging\nimport gc\nfrom tensorflow.keras import backend as k\nfrom tensorflow.keras.regularizers import l1, l2, l1_l2\nfrom sklearn.experimental import enable_halving_search_cv\nfrom sklearn.model_selection import HalvingGridSearchCV\nfrom sympy import divisors","b3c8176e":"dataset = 'https:\/\/raw.githubusercontent.com\/plotly\/datasets\/master\/diabetes.csv'","ea479e4d":"df = pd.read_csv(dataset)","835263cc":"print(df.head())","32fce12e":"print(df.shape)","359d7236":"print(df.info())","d54bba01":"df.columns = df.columns.str.capitalize()","80652e5e":"num_cols = df.select_dtypes('number').columns.tolist()","bf09bb47":"sc = MinMaxScaler()\ndf2 = df.iloc[:,:-1]\nnum_features = num_cols[:-1]\ndf2[num_features] = sc.fit_transform(df2[num_features])","a86ff133":"features = df2.columns\ntarget = df.columns[-1]\nX = df2\nY = df[target]\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\ntrain_indecies = list(sss.split(X,y=Y))\ntrain_index, test_index = train_indecies[0][0], train_indecies[0][1]\nX_train, X_test = X.loc[train_index], X.loc[test_index]\ny_train, y_test = Y.loc[train_index], Y.loc[test_index]\nX_train, X_test = np.float32(X_train), np.float32(X_test)\ny_train, y_test = np.float32(y_train), np.float32(y_test)","a5ff9289":"print(df.describe())","a49854f5":"df['Age'].hist(bins=5);","a7f7cb2d":"x = df['Age']\ny = df['Bmi']\nplt.scatter(x,y)\nplt.xlabel('Age')\nplt.ylabel('Bmi');","c325bd08":"sns.countplot(data=df, x='Pregnancies',order=df['Pregnancies'].value_counts().index);","5dc119fc":"sns.boxplot(y=df['Pregnancies'], x=df['Bmi'],order=df['Pregnancies'].value_counts().index);","a53a39bc":"sns.pairplot(df[num_cols], plot_kws=dict(alpha=.1, edgecolor='none'));","89de9cd2":"sns.heatmap(df[num_cols]);","8dce614b":"corr = df.corr()\nmask = np.triu(corr)\nsns.heatmap(corr, mask=mask, cmap='Wistia', center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},  annot= True);","d7c0d721":"fe = ExtraTreesRegressor(n_estimators=10)\nfe.fit(X, Y)\nfedf = pd.DataFrame({'Feature':features,'Feature_importance %' : fe.feature_importances_ * 100})\nfedf = fedf.sort_values(by=['Feature_importance %'], ascending=False)\nprint(fedf)\nfedf.plot.bar(x='Feature',y='Feature_importance %');","221cfd0a":"try:\n    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n    mixed_precision.set_global_policy('mixed_bfloat16')\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\nexcept ValueError:\n    tpu_resolver = None\n    gpus = tf.config.experimental.list_logical_devices(\"GPU\") # GPU detection\n    mixed_precision.set_global_policy('mixed_float16')\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n\n# Select appropriate distribution strategy\nif tpu_resolver:\n    tf.config.experimental_connect_to_cluster(tpu_resolver)\n    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n    print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\nelif len(gpus) > 1:\n    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\nelif len(gpus) == 1:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    print('Running on single GPU ', gpus[0].name)\nelse:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    print('Running on CPU')\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n    print(\"Number of accelerators: \", strategy.num_replicas_in_sync)","0c637412":"checkpoint = ModelCheckpoint('gridsearchnnmodel.hdf5', monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n\nclass CleanMemory(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        gc.collect()\n        k.clear_session()\n\nclean_memory = CleanMemory()\n\n\n# batch_size=1024 # 128*8 for a TPU with 8 cores\n# steps_per_execution=64 # 8 per core\n# cls_loss = [\"binary_crossentropy\",\"categorical_crossentropy\",\"sparse_categorical_crossentropy\",\"poisson\",\"kl_divergence\"]\n# reg_loss = [\"mean_squared_error\",\"mean_absolute_error\",\"mean_absolute_percentage_error\",\"mean_squared_logarithmic_error\",\"cosine_similarity\",\"huber_loss\"]\n\n\n\nA = divisors(X_train.shape[0])[1:-1]\nsteps_per_epoch= A[:len(A)\/\/2]\nbatch_size = A[len(A)\/\/2:][1:]\nepochs = [30,50,100]\noptimizer = ['sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam','ftrl']\ninit_mode = ['constant','glorot_normal','glorot_uniform','he_normal','he_uniform','identity','lecun_normal','lecun_uniform','ones','orthogonal','random_normal','random_uniform','truncated_normal','variance_scaling','zeros']\nactivations = [sigmoid,elu,gelu,linear,relu,selu,softmax,softplus,softsign,LeakyReLU(), PReLU(), ThresholdedReLU()]\nweight_constraints = np.array([0,1,2,3,4,5])\nregularizations = [Dropout, GaussianDropout, AlphaDropout]\nnormalizations = [LayerNormalization(),BatchNormalization()]\nkernel_constraints = [max_norm, min_max_norm, non_neg, unit_norm, radial_constraint]\ndropout_rates = np.array([0.1*i for i in range(0,10)])\nneurons = np.array([2**i for i in range(4,11)])\nhidden_layers = np.array([1])\nregularizers = [l1, l2, l1_l2]\nreg_coef = [10**i for i in range(-2,-5,-1)]\nregularizer_with_coef = [i(j) if i in [l1,l2] else i(j,k) for i in regularizers for j in reg_coef for k in reg_coef]\nregularizer_with_coef = regularizer_with_coef[0:18:3] + regularizer_with_coef[18:]\nlosses=[\"binary_crossentropy\",\"categorical_crossentropy\",\"sparse_categorical_crossentropy\",\"poisson\",\"kl_divergence\"]\nparam_grid = dict(optimize=optimizers,imode=init_modes,\n                  afunc=activations,\n                  wconstraint=weight_constraints, \n                  regularize=regularizations,normalize=normalizations,\n                  kconstraint=kernel_constraints,\n                  drate=dropout_rates,neurons=neurons,hiddenlayers=hidden_layers,\n                  regularizer_with_coef=regularizer_with_coef,\n                  lossfunc=losses,\n                  epochs=epochs,steps_per_epoch=steps_per_epoch,batch_size=batch_size)\n\n\ndef create_model(optimize='adam', imode='uniform', afunc=sigmoid,\n                 wconstraint=0, regularize=Dropout,\n                 normalize=BatchNormalization(), kconstraint=max_norm,\n                 drate=0.5, neurons=2, hiddenlayers=1, regularizer_with_coef=l1(0.0001),  lossfunc='binary_crossentropy'):\n    with strategy.scope():\n        model = Sequential()\n        model.add(InputLayer(input_shape=(X_train.shape[1],)))\n        for n_inner in range(hiddenlayers):\n            model.add(normalize)\n            model.add(Dense(neurons, kernel_initializer=imode, activation=afunc,\n            kernel_regularizer=regularizer_with_coef,\n            bias_regularizer=regularizer_with_coef,\n            activity_regularizer=regularizer_with_coef,\n            kernel_constraint=kconstraint(wconstraint)))\n            model.add(regularize(drate))\n        model.add(Dense(1, activation='sigmoid'))\n        model.compile(loss=lossfunc, optimizer=optimize, metrics=['accuracy'])\n        return model\n\n\nestimator = KerasClassifier(build_fn=create_model,verbose=1)\ngrid = GridSearchCV(cv=2,estimator=estimator,param_grid=param_grid,n_jobs=-1,refit=True,error_score=0,\n                           return_train_score=False,verbose=1)# ,aggressive_elimination=True,factor=2,min_resources=X_train.shape[0]); for HalvingGridSearchCV\ngrid_result = grid.fit(X_train, y_train,callbacks=[checkpoint,clean_memory],shuffle=True);","bc741ab3":"print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\npred = grid_result.predict(X_test)\nmodels=[]\ntest_scores=[]\nmodels.append('gridsearchnnmodel')\ntest_scores.append(accuracy_score(y_test,pred))\nprint(accuracy_score(y_test,pred))","3ee9ea74":"# Compare Algorithms\nresults_df = pd.DataFrame({'Model':models, 'Test_Scores': test_scores})\nresults_df = results_df.sort_values(by=['Test_Scores'], ascending=False)\nprint(results_df[['Test_Scores','Model']])\nsns.barplot(data=results_df, x='Test_Scores', y='Model', orient = 'h');\nplt.title('Algorithm Comparison');","db4d72be":"Correlation between Age and BMI","ba0da923":"correlation plot of numerical features","e853dca3":"Distribution of Age for patients","8282833b":"* Glucose level in the blood is main factor in deciding the patient have diabities\n* DNN Classifier with GridSearch is very expensive to train","8ad58c8d":"Summary Statistics for Numerical columns","1d48d45c":"**Summary Key Findings and Insights**","742d3762":"Capitalize column names","08736654":"## Recommendations","deecad41":"## Exploratory Data Analysis (EDA)","d89322be":"1. numpy\n2. pandas\n3. matplotlib\n4. seaborn\n5. sklearn\n6. tensorflow\n7. sympy","310ed43e":"**Brief description of the data set you chose and a summary of its attributes**","e3b26af7":"Feature Importance","e76fec0c":"Features Encoding","62619c8d":"**Actions taken for data cleaning and feature engineering**","5f2fcdb3":"heatmap of numerical features","fb28db0e":"reading the dataset into dataframe","fd67c1dc":"sampling the data","b1a0d2d1":"Distribution of Pregnancies for each BMI category","f107131f":"The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, \nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.It has a total of 768 rows and 9 columns\n\n| S No. | Column | Description| Data Type | Category| Type\n| --- | --- | --- | --- | --- | --- |\n|1 | Pregnancies | Number of times pregnant | Int | Discrete | Variable |\n|2 | Glucose | Plasma glucose concentration a 2 hours in an oral glucose tolerance test | Int | Discrete | Variable |\n|3 | Blood pressure | Diastolic blood pressure (mm Hg) | Int | Discrete | Variable |\n|4 |Skin thickness | Triceps skin fold thickness (mm) | Int | Discrete | Variable |\n|5 | Insulin | 2-Hour serum insulin (mu U\/ml) | Int | Discrete | Variable |\n|6 | BMI | Body mass index (weight in kg\/(height in m)^2) | Float | Continuous | Variable |\n|7 | DiabetesPedigreeFunction | Diabetes pedigree function| Float | Continuous | Variable |\n|8 | Age | Age (years) | Int | Discrete | Variable |\n|9 | Outcome | Class variable (0 or 1)| Int | Discrete | Target |","1256a154":"number of rows and coulmns in dataset","0c629c7d":"Pair plot of numerical features","9e598f9e":" Split the data into test and train","dfd81ac0":"dataset information","9737f566":"we will be training deep neural networks from the Tensorflow library and the comparing them according to accuracy on the testing dataset\nExpected runtime: 9 Hours","d312b6a8":"Visual Exploration of Categorical columns","8338fad8":"## Modeling","3972986f":"Classifying columns as Numerical or Categorical","7aec65f5":"train classification model on the dataset to detect if the patient have diabeties or not","a9a0c908":"## Load the dataset","eed0c95c":"location of dataset","98a6f872":"Visual Exploration of Numerical Columns","f77873f8":"## Load the libraries","9ae36a26":"**Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.**","e055b69c":"**Modelling  Task Details**\n\n| S No. | Description| Category| Type |\n| --- | --- | --- | --- | \n|1 | Data being used| Structured | Categorical |\n|2 | Machine learning problem | Classification |  Binary-class |\n|3 | Relevant ML and DL models | Deep Learning | DNNs |\n|4 | Technical metrics | Accuracy | Percentage (the higher the better) |\n|5 | Hyperparameter optimization techniques | Grid search | Specified Dictionary |\n|6 | Computation method | Cloud | CPU | \n|7 | Additional Features | Callback | Checkpoint for accuracy | ","8c0978a9":"**Plan for Data Exploration, Feature Engineering and Modelling**","7ab57b02":"1. scikit-learn latest version\n2. sympy","6882589c":"The steps in solving the Regression Problem are as follows:\n1. Packages to be installed\n2. Load the libraries\n3. Load the dataset\n4. General information about the dataset\n5. Exploratory Data Analysis (EDA)\n6. Modeling\n7. Recommendations","5ee64309":"Count No. of pregnancies","6b96d1e5":"## Packages to be installed","146bfedc":"## General information about the dataset"}}