{"cell_type":{"5e5273dd":"code","70a17d0c":"code","ae38b186":"code","74f726bf":"code","0d977a47":"code","be9f3366":"code","10944f09":"code","e4fda2ed":"code","798b2a41":"code","c3c7ac7b":"code","d2612dbc":"code","d02d5ae4":"code","baade295":"code","06473635":"code","086c0864":"code","199bf0d4":"code","4c1add1b":"code","ffce9ebb":"code","77695211":"code","efab14c3":"code","da36f1ac":"markdown","a55084c5":"markdown"},"source":{"5e5273dd":"import tensorflow as tf\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport cv2\nfrom tensorflow.keras import layers\nimport time\nfrom IPython import display","70a17d0c":"tf.__version__","ae38b186":"class cfg:\n    BATCH_SIZE = 64\n    EPOCHS = 500\n    NOISE_DIM = 250\n    NUM_EXAMPLES_TO_GENERATE = 16","74f726bf":"dirs = ['neutral', 'fear', 'angry', 'surprise', 'disgust']\ntrain_images = []\n\nfor folder in dirs:\n    directory = '..\/input\/fer2013\/train\/{}\/'.format(folder)\n    for image_name in os.listdir(directory):\n        if image_name.endswith('.jpg'):\n            image_path = os.path.join(directory, image_name)\n            image = cv2.imread(image_path, 0)\n            image = np.expand_dims(image, 2)\n            image = (image - 127.5)\/127.5\n            train_images.append(image)\n        \ndataset = tf.data.Dataset.from_tensor_slices(train_images)\ndataset = dataset.batch(cfg.BATCH_SIZE)","0d977a47":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(6*6*cfg.BATCH_SIZE, use_bias=False, input_shape=(cfg.NOISE_DIM,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((6, 6, cfg.BATCH_SIZE)))\n    assert model.output_shape == (None, 6, 6, cfg.BATCH_SIZE)  # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 12, 12, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 24, 24, 32)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 48, 48, 1)\n\n    return model","be9f3366":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[48, 48, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","10944f09":"#noisy labels.\ndef discriminator_loss(real_output, fake_output):\n    real_truths = tf.random.uniform(real_output.shape, minval=0.0, maxval=0.1, dtype=tf.dtypes.float32, seed=42)\n    fake_truths = tf.random.uniform(fake_output.shape, minval=0.9, maxval=1.0, dtype=tf.dtypes.float32, seed=42)\n#     real_loss = cross_entropy(tf.zeros_like(real_output), real_output)\n#     fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n    real_loss = cross_entropy(real_truths, real_output)\n    fake_loss = cross_entropy(fake_truths, fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","e4fda2ed":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef generator_loss(fake_output):\n    return cross_entropy(tf.zeros_like(fake_output), fake_output)","798b2a41":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(4e-4)","c3c7ac7b":"generator = make_generator_model()\ndiscriminator = make_discriminator_model()","d2612dbc":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","d02d5ae4":"seed = tf.random.normal([cfg.NUM_EXAMPLES_TO_GENERATE, cfg.NOISE_DIM])","baade295":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([cfg.BATCH_SIZE, cfg.NOISE_DIM])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n        print(gen_loss, disc_loss)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","06473635":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # Produce images for the GIF as you go\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n    # Save the model every 15 epochs\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  # Generate after the final epoch\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)","086c0864":"def generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n    predictions = (predictions * 127) + 127\n\n    fig = plt.figure(figsize=(4, 4))\n\n    for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n      plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","199bf0d4":"tf.config.run_functions_eagerly(True)","4c1add1b":"train(dataset, cfg.EPOCHS)","ffce9ebb":"im = generator(seed, training=False)","77695211":"i = (im[0]*127)+127","efab14c3":"plt.imshow(i)","da36f1ac":"## Import the libraries","a55084c5":"Gans Model are data hungry.\n\nIn gans two models compete to improve themselves. If one model reaches the improvement faster than the other then the other model will fail to improve itself.\n\nKeep the filter dim in the gen high. Keep the model arch simple. "}}