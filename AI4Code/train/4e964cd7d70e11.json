{"cell_type":{"e4f48f65":"code","e7c6b764":"code","cabd59c2":"code","112ab072":"code","c7d841b3":"code","497527d4":"code","3acc9552":"code","21cb1bc9":"code","02004485":"code","7baae093":"code","2ea15e47":"code","51c9a198":"code","1ffab291":"code","9d84fa19":"code","7d376645":"code","f706aaf1":"code","aa4193b7":"code","ecf3b8d4":"code","babcc708":"code","f67f3f3e":"markdown","6b55fd1c":"markdown","f0e50d61":"markdown","31531496":"markdown","b3201550":"markdown","6b4805b1":"markdown","7a95709c":"markdown","1021b5a7":"markdown","38ac9e56":"markdown","6fb20f81":"markdown","a4358723":"markdown","e85f87ce":"markdown","da5ad73e":"markdown","98c339a9":"markdown","4e8722fc":"markdown","675df28e":"markdown"},"source":{"e4f48f65":"####################### Loading the required libraries ###############################\n\nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Avoid Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n#Common model helpers\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, r2_score, accuracy_score\nfrom sklearn.model_selection import (GridSearchCV, KFold, train_test_split, cross_val_score)\n\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn import svm\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier\n","e7c6b764":"################################ Read in water_potability file #########################################\n\nwaterDf = pd.read_csv('..\/input\/water-potability\/water_potability.csv')\n\n################################ Make a copy ################################################\n\nwaterData = waterDf.copy()","cabd59c2":"############################# About the data ###################################\n\nprint('The water-potability file has')\nprint('   Rows      Columns')\nprint('   {}         {}\\n' .format(waterData.shape[0], waterData.shape[1]))\n\nprint( waterData.info())\n","112ab072":"print('Information about features\\n')\nprint(waterData.describe())","c7d841b3":"################################ How does the data look like? ############################\nprint('How does the water-potability data look like?\\n')\nprint(waterData.head())","497527d4":"###################### We work on the missing data ##############################\nprint('There are missing values within the data.\\n')\nprint('The nature of the missing values within the features are as follows:\\n')\nprint(waterData.isna().sum())","3acc9552":"##################################### Imputing 'ph' value #####################################\n\nphMean_0 = waterData[waterData['Potability'] == 0]['ph'].mean(skipna=True)\nwaterData.loc[(waterData['Potability'] == 0) & (waterData['ph'].isna()), 'ph'] = phMean_0\nphMean_1 = waterData[waterData['Potability'] == 1]['ph'].mean(skipna=True)\nwaterData.loc[(waterData['Potability'] == 1) & (waterData['ph'].isna()), 'ph'] = phMean_1\n\n##################################### Imputing 'Sulfate' value #####################################\n\nSulfateMean_0 = waterData[waterData['Potability'] == 0]['Sulfate'].mean(skipna=True)\nwaterData.loc[(waterData['Potability'] == 0) & (waterData['Sulfate'].isna()), 'Sulfate'] = SulfateMean_0\nSulfateMean_1 = waterData[waterData['Potability'] == 1]['Sulfate'].mean(skipna=True)\nwaterData.loc[(waterData['Potability'] == 1) & (waterData['Sulfate'].isna()), 'Sulfate'] = SulfateMean_1\n\n################################ Imputing 'Trihalomethanes' value #####################################\n\nTrihalomethanesMean_0 = waterData[waterData['Potability'] == 0]['Trihalomethanes'].mean(skipna=True)\nwaterData.loc[(waterData['Potability'] == 0) & (waterData['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_0\nTrihalomethanesMean_1 = waterData[waterData['Potability'] == 1]['Trihalomethanes'].mean(skipna=True)\nwaterData.loc[(waterData['Potability'] == 1) & (waterData['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_1\n","21cb1bc9":"########################################## Check ####################################\nprint('Checking to see any more missing data \\n')\nwaterData.isna().sum()","02004485":"######################### Convert 'Potability' to Category #######################\n\nwaterData['Potability'] = waterData['Potability'].astype('category')\nwaterData.info()","7baae093":"print('Distribution of Target Variable within the sample data')\n\nfig, ax = plt.subplots(ncols=2, nrows=1, figsize=(16,6))\n\nwaterData.Potability.value_counts().plot(kind='bar', color=['orange', 'steelblue'], rot=0, ax=ax[0])\n# Iterrating over the bars one-by-one\nfor bar in ax[0].patches:\n    ax[0].annotate(format(bar.get_height(), 'd'), (bar.get_x() + bar.get_width() \/ 2, bar.get_height()),\n                                                    ha='center', va='center', size=15, xytext=(0, -10),\n                                                    textcoords='offset points')\nax[0].tick_params(left=False, labelleft=False)\nax[0].xaxis.set_tick_params(labelsize=20)\n\nlabels = list(waterData['Potability'].unique())\n## use the wedgeprops and textprops arguments to style the wedges and texts, respectively\nax[1].pie(waterData['Potability'].value_counts(), labels=labels, autopct = '%1.1f%%',\n          colors=['orange', 'steelblue'], explode = [0.005]*len(labels),\n          textprops={'size': 'x-large'},\n         wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'})\n\nplt.show()","2ea15e47":"######################################### Correlation Matrix #############################################\n\nCorrmat = waterData.corr()\nplt.subplots(figsize=(7,7))\nsns.heatmap(Corrmat, cmap=\"YlGnBu\", square = True, annot=True, fmt='.2f')\nplt.show()","51c9a198":"print('Boxplot and density distribution of different features by Potability\\n')\n\nfig, ax = plt.subplots(ncols=2, nrows=9, figsize=(14, 28))\n\nfeatures = list(waterData.columns.drop('Potability'))\ni=0\nfor cols in features:\n    sns.kdeplot(waterData[cols], fill=True, alpha=0.4, hue = waterData.Potability, \n                palette=('indianred', 'steelblue'), multiple='stack', ax=ax[i,0])\n    \n    sns.boxplot(data= waterData, y=cols, x='Potability', ax=ax[i, 1],\n               palette=('indianred', 'steelblue'))\n    ax[i,0].set_xlabel(' ')\n    ax[i,1].set_xlabel(' ')\n    ax[i,1].set_ylabel(' ')\n    ax[i,1].xaxis.set_tick_params(labelsize=14)\n    ax[i,0].tick_params(left=False, labelleft=False)\n    ax[i,0].set_ylabel(cols, fontsize=16)\n    i=i+1\n      \nplt.show()","1ffab291":"print('Correlation of Potability with feature variables:')\nfeatures = list(waterData.columns.drop('Potability'))\n\nCorr = list()\nfor cols in features:\n    Corr.append(waterData[cols].corr(waterData['Potability']))\n\ncorrDf = pd.DataFrame({'Features' : features, 'Corr' : Corr})\ncorrDf['Corr'] = corrDf['Corr'].abs()\ncorrDf.sort_values(by='Corr', ascending = True)\n","9d84fa19":"##################### Preparing the Data for Modelling ######################\n\nX = waterData.drop('Potability', axis = 1).copy()\ny = waterData['Potability'].copy()\n\n############################# Train-Test split ############################\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n\n########################## Synthetic OverSampling ###########################\nprint('Balancing the data by SMOTE - Oversampling of Minority level\\n')\nsmt = SMOTE()\ncounter = Counter(y_train)\nprint('Before SMOTE', counter)\nX_train, y_train = smt.fit_resample(X_train, y_train)\ncounter = Counter(y_train)\nprint('\\nAfter SMOTE', counter)\n\n################################# Scaling #################################\nssc = StandardScaler()\n\nX_train = ssc.fit_transform(X_train)\nX_test = ssc.transform(X_test)\n\nmodelAccuracy = list()","7d376645":"model = [LogisticRegression(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier(), ExtraTreesClassifier(),\n        svm.LinearSVC(), XGBClassifier(), CatBoostClassifier()]\ntrainAccuracy = list()\ntestAccuracy = list()\nkfold = KFold(n_splits=10, random_state=7, shuffle=True)\n\nfor mdl in model:\n    trainResult = cross_val_score(mdl, X_train, y_train, scoring='accuracy', cv=kfold)\n    trainAccuracy.append(trainResult.mean())\n    mdl.fit(X_train, y_train)\n    y_pred = mdl.predict(X_test)\n    testResult = metrics.accuracy_score(y_test, y_pred)\n    testAccuracy.append(testResult)","f706aaf1":"print('The comparision\\n')\nmodelScore = pd.DataFrame({'Model' : model, 'Train_Accuracy' : trainAccuracy, 'Test_Accuracy' : testAccuracy})\nmodelScore","aa4193b7":"########################################## RandomForestClassfier #############################\nprint('Random Forest Classifier\\n')\nRfc = RandomForestClassifier()\nRfc.fit(X_train, y_train)\n\ny_Rfc = Rfc.predict(X_test)\nprint(metrics.classification_report(y_test, y_Rfc))\nprint(modelAccuracy.append(metrics.accuracy_score(y_test, y_Rfc)))\n\nsns.heatmap(confusion_matrix(y_test, y_Rfc), annot=True, fmt='d')\nplt.show()","ecf3b8d4":"#################################### XGB Classifier() #######################\nprint('XGB Classifier\\n')\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\ny_xgb = xgb.predict(X_test)\nprint(metrics.classification_report(y_test, y_xgb))\nprint(modelAccuracy.append(metrics.accuracy_score(y_test, y_xgb)))\n\nsns.heatmap(confusion_matrix(y_test, y_xgb), annot=True, fmt='d')\nplt.show()\n","babcc708":"#################################### CatBoostClassifier() #######################\nprint('CatBoostClassifier\\n')\ncat = CatBoostClassifier(verbose=False)\ncat.fit(X_train, y_train)\n\ny_cat = cat.predict(X_test)\nprint(metrics.classification_report(y_test, y_cat))\nprint(modelAccuracy.append(metrics.accuracy_score(y_test, y_cat)))\n\nsns.heatmap(confusion_matrix(y_test, y_cat), annot=True, fmt='d')\nplt.show()\n","f67f3f3e":"The Correlation graph shows absence of multicollinearity. ","6b55fd1c":"All 10 variables of the data are numerical. The target variable takes binary values 0 and 1. \nThe feature variables are real numbers.","f0e50d61":"# PREPARING THE DATA FOR MODELLING","31531496":"# DATA MODELLING","b3201550":"# **DRINKING WATER POTABILITY - EDA and PREDICTION**","6b4805b1":"CatBoostClassifier is giving a good accuracy score of 81%.\nThe accuracy score can be further increased by fine tuning of model hyperparameters.\nI leave that to you to proceed further from here after forking the kernel.\nPlease upvote if you find this kernel useful and leave a comment.\nThank You for scrolling","7a95709c":"After applying 10 folds Cross Validation, we get more than 78% accuracy by RandomForestClassifier, CatBoostClassifier and XGBClassifier.\n\nLet's look at the confusion matrix for each one of them","1021b5a7":"From the kdeplots there seems to be very less difference in mean values of the features among the levels of Potability.","38ac9e56":"# INFORMATION ON WATER-POTATBILITY DATA","6fb20f81":"We shall be using the following algorithms to model the data and then find the accuracy on test data.\n\n'LogisticRegression', 'DecisionTreeClassifier', 'NaiveBayesClassifier', 'RandomForestClassifier',\n'ExtraTreesClassifier, 'SupportVactorClassifier', 'xgbClassifier', 'CatBoostClassifier'.","a4358723":"# RESULTS","e85f87ce":"# CONCLUSION","da5ad73e":"There are 491, 781 and 162 missing data in 'ph', 'Sulphate', and 'Trihalomethanes' respectively. \nWe shall impute the missing values with the mean of the respective features by grouping them w.r.t 'Potability'.","98c339a9":"There are 1998 data with Potability=1 and 1278 with Potability=0. \nHence the data is imbalanced. We shall balance the data through SMOTE.\n\nLet's look at the correlation matrix of the features.","4e8722fc":"# LOADING REQUIRED LIBRARIES","675df28e":"# EXPLORING DATA THROUGH VISUALS"}}