{"cell_type":{"17a99f06":"code","c061a4c2":"code","f476664f":"code","eddfb09f":"code","0846af56":"code","47cfc72e":"code","60f1ba9b":"code","9233b7fc":"code","f037c6d7":"code","61a79547":"code","a4c3d1c4":"code","46ca8215":"code","f5ca64b2":"code","9dc92aef":"code","88448587":"markdown","7deab349":"markdown","a2278d26":"markdown","f0674f2f":"markdown","ebda4d08":"markdown","95e01ccc":"markdown"},"source":{"17a99f06":"import numpy as np\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c061a4c2":"import zipfile\n\nimport zipfile\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\"kaggle\/input\/test_1\")","f476664f":"train= zipfile.ZipFile('..\/input\/dogs-vs-cats\/train.zip')\ntrain.extractall()","eddfb09f":"import pathlib\nimport os\nimport shutil\n\n\npath = pathlib.Path(\"train\")\nnew_dir = pathlib.Path(\"train_validation\")\n\ndef seperating(subset_name, start, end):\n    category = \"cat\"\n    dir = new_dir \/ subset_name \/ category\n    try:\n        os.makedirs(dir)\n    except OSError:\n        print(f\"This file {dir} exist.\")\n        \n    fnames = [f\"{category}.{i}.jpg\" for i in range(start, end)]\n    for fname in fnames:\n        shutil.copyfile(src=path \/ fname,\n                        dst=dir \/ fname)\n\nseperating(\"validation\", start=0, end=4000)\nseperating(\"train\", start=4000, end=12499)","0846af56":"def seperating(subset_name, start, end):\n    category = \"dog\"\n    dir = new_dir \/ subset_name \/ category\n    try:\n        os.makedirs(dir)\n    except OSError:\n        print(f\"This file {dir} exist.\")\n        \n    fnames = [f\"{category}.{i}.jpg\" for i in range(start, end)]\n    for fname in fnames:\n        shutil.copyfile(src=path \/ fname,\n                        dst=dir \/ fname)\n\nseperating(\"validation\", start=0, end=4000)\nseperating(\"train\", start=4000, end=12499)\n","47cfc72e":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\n\ninputs = keras.Input(shape=(224, 224, 3))\n\ndata = Rescaling(1.\/255)(inputs)\n\n# chose relu, it is also most common, \n# 'cause  and if the input value (x) is negative, then a value 0.0 is returned, otherwise, the value is returned.\n\ndata = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(data)\ndata = layers.MaxPooling2D(pool_size=2)(data)\ndata = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(data)\ndata = layers.MaxPooling2D(pool_size=2)(data)\ndata = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(data)\ndata = layers.MaxPooling2D(pool_size=2)(data)\ndata = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(data)\ndata = layers.MaxPooling2D(pool_size=2)(data)\ndata = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(data)\ndata = layers.Flatten()(data)\n\n# sigmoid is okay for Binary Classification and Multilabel Classification\n\noutput = layers.Dense(1, activation=\"sigmoid\")(data)\n\n\nmodel = keras.Model(inputs=inputs, outputs=output)","60f1ba9b":"model.summary()\n","9233b7fc":"from tensorflow.keras import optimizers\n\nmodel.compile(loss=\"binary_crossentropy\",optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=[\"accuracy\"])","f037c6d7":"from tensorflow.keras.preprocessing  import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_set = image_dataset_from_directory(\n    new_dir \/ \"train\",\n    image_size=(224, 224),\n    batch_size=32)\nvalidation_set = image_dataset_from_directory(\n    new_dir \/ \"validation\",\n    image_size=(224, 224),\n    batch_size=32)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_set = test_datagen.flow_from_directory( \".\/kaggle\/input\/test_1\",\n                                             target_size=(224,224),\n                                             batch_size=32,class_mode='input')\n","61a79547":"import numpy as np\nimport tensorflow as tf\nrandom_numbers = np.random.normal(size=(1000, 16))\ndataset = tf.data.Dataset.from_tensor_slices(random_numbers)","a4c3d1c4":"for i, element in enumerate(dataset):\n    print(element.shape)\n    if i >= 2:\n        break","46ca8215":"\nreshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\nfor i, element in enumerate(reshaped_dataset):\n    print(element.shape)\n    if i >= 2:\n        break\n        \n        \nfor data_batch, labels_batch in train_set:\n    print(\"data batch shape:\", data_batch.shape)\n    print(\"labels batch shape:\", labels_batch.shape)\n    break","f5ca64b2":"callbacks = [\n    keras.callbacks.ModelCheckpoint(\n        filepath=\"convnet_from_scratch.keras\",\n        save_best_only=True,\n        monitor=\"val_loss\")\n]\n\nhist = model.fit(\n    train_set,\n    epochs=20,\n    validation_data=validation_set,\n    callbacks=callbacks)","9dc92aef":"import matplotlib.pyplot as plt\n\nloss = hist.history[\"loss\"]\nval_loss = hist.history[\"val_loss\"]\nacc = hist.history[\"accuracy\"]\nval_acc = hist.history[\"val_accuracy\"]\n\n\nepoch = range(1, len(acc) + 1)\n\n\nplt.plot(epoch, loss, \"--g\", label=\"Training loss\")\nplt.plot(epoch, val_loss, \"g\", label=\"Validation loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.figure()\n\nplt.plot(epoch, acc, \"-r\", label=\"Training accuracy\")\nplt.plot(epoch, val_acc, \"r\", label=\"Validation accuracy\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"epoch\")\n\nplt.legend()\nplt.figure()\n\nplt.show()","88448587":"**So we have validation, train and test sets.**","7deab349":"# **PLEASE CHECK THIS NOTEBOOK: I FIXED OVERFITTING.**\n    \nhttps:\/\/www.kaggle.com\/zehranrgi\/cnn-cats-vs-dogs-vgg16","a2278d26":"**I welcome your comments for any corrections and improvements.**\n\n**Thanks**!","f0674f2f":"Short note: \n\nWhy 224 224 : \nVGG-16 Network Architecture. Output channels have shrinking dimensions (h x w). [Source: https:\/\/bit.ly\/36tOKUC]\n\nVGGNET is succesful with max pooling. Pooling is for changing the dimesions. LeNet was successful with average pooling etc. \n![image.png](attachment:f734325b-2c91-43ed-b371-8cf83a8e7609.png)","ebda4d08":"Mostly, during I compiled code with these sources:\nhttps:\/\/machinelearningmastery.com and Chollet's DL book.  \n\nI run with GPU. Because of this 95% accuracy level, I didn't use vgg16 or feature extraction. \n\n[When I wanted to use test sets, keras is not okay with reading \" 1.jpg, 2.jpg...\" names. Error was \"Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string\". So I solved it with this code: => \"zip_ref.extractall(\"kaggle\/input\/test_1\")\". ]\n\n","95e01ccc":"**Unzip file with using the kaggle path.**"}}