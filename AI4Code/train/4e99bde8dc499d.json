{"cell_type":{"14db7931":"code","7eb925b8":"code","e9dcda36":"code","bf00863c":"code","4e75eaa4":"code","7761b30a":"code","62d892ff":"code","cdb0df61":"code","6de8d76e":"code","b3dff9e2":"code","fe1ca4c5":"code","5de654f8":"code","cfd463a5":"code","9ddb8622":"code","007c00a9":"code","4c835ac6":"code","3b0847b3":"code","5c4a4ccd":"code","a2dd518b":"code","412d986c":"code","8d401423":"markdown","d1d45b85":"markdown","4734b2c3":"markdown","88047ab5":"markdown","c950b849":"markdown","1d631672":"markdown","e2a1d4ef":"markdown","2f1cdc5c":"markdown","901d6da9":"markdown","2cbbf330":"markdown","6b14397b":"markdown"},"source":{"14db7931":"import tensorflow as tf\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","7eb925b8":"train_dataframe=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_dataframe=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","e9dcda36":"train_dataframe['label'].value_counts()","bf00863c":"train_dataframe.head(10)","4e75eaa4":"train_dataframe.shape","7761b30a":"train_label = train_dataframe.label.to_numpy()\ntrain_image=train_dataframe.to_numpy()[0:,1:].reshape(42000,28,28,1)\ntest_image = test_dataframe.to_numpy().reshape(28000,28,28,1)","62d892ff":"train_image = train_image.astype(float) \/ 255.0\ntest_image = test_image.astype(float) \/ 255.0","cdb0df61":"fig = plt.figure(figsize=(10, 7))\n  \n# setting values to rows and column variables\nrows = 2\ncolumns = 2\n  \n# reading images\nImage1 = train_image[1]\nImage2 = train_image[2]\nImage3 = train_image[3]\nImage4 = train_image[4]\n  \n# Adds a subplot at the 1st position\nfig.add_subplot(rows, columns, 1)\n  \n# showing image\nplt.imshow(Image1.squeeze())\nplt.axis('off')\nplt.title(\"First\")\n  \n# Adds a subplot at the 2nd position\nfig.add_subplot(rows, columns, 2)\n  \n# showing image\nplt.imshow(Image2.squeeze())\nplt.axis('off')\nplt.title(\"Second\")\n  \n# Adds a subplot at the 3rd position\nfig.add_subplot(rows, columns, 3)\n  \n# showing image\nplt.imshow(Image3.squeeze())\nplt.axis('off')\nplt.title(\"Third\")\n  \n# Adds a subplot at the 4th position\nfig.add_subplot(rows, columns, 4)\n  \n# showing image\nplt.imshow(Image4.squeeze())\nplt.axis('off')\nplt.title(\"Fourth\")","6de8d76e":"with tpu_strategy.scope():\n    model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding = 'Same', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.25),\n#     tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n    #tf.keras.layers.Dropout(0.25),\n    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n    #tf.keras.layers.MaxPooling2D(2,2),\n    #tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding = 'Same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n    from keras.losses import SparseCategoricalCrossentropy\n    from tensorflow.keras.optimizers import Adam\noptimizer = Adam(learning_rate=0.001)\n\nmodel.compile(loss=SparseCategoricalCrossentropy(from_logits=True),\n              optimizer = optimizer,\n              metrics=['accuracy'])\nepochs = 50\nbatch_size = 16","b3dff9e2":"model.summary()","fe1ca4c5":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(train_image,train_label,test_size=0.2,random_state=42)","5de654f8":"history = model.fit(x_train,y_train,batch_size=64,epochs=15,validation_data=(x_val,y_val),shuffle=True)","cfd463a5":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","9ddb8622":"val_pred = model.predict(x_val)","007c00a9":"val_pred1 = np.argmax(val_pred, axis=1)","4c835ac6":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfig, ax = plt.subplots(figsize=(12, 12))\ncm = confusion_matrix(y_val,val_pred1, normalize='true')\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [0,1,2,3,4,5,6,7,8,9])\ndisp = disp.plot(ax=ax,cmap=plt.cm.Blues)\nax.set_title(\"Confusion Matrix\")\nplt.show()","3b0847b3":"predictions = model.predict(test_image)","5c4a4ccd":"subs = []\nfor p in predictions:\n    subs.append(p.argmax())","a2dd518b":"submission = pd.DataFrame({'ImageId' : range(1,28001), 'Label' : list(subs)})\nsubmission.head(10)\nsubmission.shape","412d986c":"submission.to_csv(\"submission1.csv\", index = False)","8d401423":"# ****Splitting Train data to train_label and train_image****","d1d45b85":"# Importing test and train data","4734b2c3":"# Creating Submission file","88047ab5":"# ****Fitting data into model****","c950b849":"# ****Displaying the confusion Matrix****","1d631672":"# Thank you! Please upvote if you like my work.","e2a1d4ef":"# Plotting Results","2f1cdc5c":"# ****Train-Validation split using sklearn****","901d6da9":"# **Importing Important Libraries and connecting TPU**","2cbbf330":"****Plotting some samples:****","6b14397b":"# ****Connecting TPU and building 2D CNN Model****"}}