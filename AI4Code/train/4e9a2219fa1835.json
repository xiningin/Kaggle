{"cell_type":{"81d5785b":"code","f5105c17":"code","84c90e4b":"code","d603d792":"code","0f727528":"code","dec973cb":"code","5d79e61d":"code","2fe38574":"code","885909b8":"code","c4d5ec94":"code","cce6b7e0":"code","0b758f9b":"code","c90bc20c":"code","0c1b5f60":"code","968c4279":"code","e67ab2bd":"code","ff781c1f":"code","01b092d6":"code","22fa8066":"code","c021bd1a":"code","92d96810":"markdown","eb4d475e":"markdown","f4df96d8":"markdown","26d550fd":"markdown"},"source":{"81d5785b":"# Importing packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom wordcloud import WordCloud    #library to visualize text data\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer   #Transform text to vectors.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_curve,classification_report,precision_score,recall_score","f5105c17":"# Reading dataset\ndf_train = pd.read_csv('..\/input\/emotions-dataset-for-nlp\/train.txt', delimiter = ';', names = ['text', 'label'])\ndf_val = pd.read_csv('..\/input\/emotions-dataset-for-nlp\/val.txt', delimiter = ';', names = ['text', 'label'])\n\nprint(df_train.shape)\nprint(df_val.shape)","84c90e4b":"df = pd.concat([df_train,df_val])    #Merging two datasets\ndf.reset_index(inplace = True, drop = True)\n\nprint(df.shape) \ndf.sample(5)   #Selects random sample","d603d792":"sns.countplot(df.label)","0f727528":"#converting labels to manual encoder\n\ndef manual_encoder(df):\n    df.replace(to_replace = \"surprise\", value = 1, inplace = True)\n    df.replace(to_replace = \"love\", value = 1, inplace = True)\n    df.replace(to_replace = \"joy\", value = 1, inplace = True)\n    df.replace(to_replace = \"sadness\", value = 0, inplace = True)\n    df.replace(to_replace = \"anger\", value = 0, inplace = True)\n    df.replace(to_replace = \"fear\", value = 0, inplace = True)","dec973cb":"manual_encoder(df['label'])","5d79e61d":"df.sample(5)","2fe38574":"sns.countplot(df.label)","885909b8":"lm = WordNetLemmatizer()","c4d5ec94":"def data_prep(df):\n    corpus = []\n    for i in df:\n        item = re.sub(\"[^A-Za-z]\",\" \",str(i))\n        item = item.lower() \n        item = item.split()\n        item = [lm.lemmatize(word) for word in item if word not in set(stopwords.words('english'))]\n        corpus.append(' '.join(str(x) for x in item))\n    return corpus\n    \n    ","cce6b7e0":"corpus = data_prep(df['text'])\ncorpus[:10]","0b758f9b":"cv = CountVectorizer(ngram_range=(1,2))\ntraindata = cv.fit_transform(corpus)\nx = traindata\ny = df['label']","c90bc20c":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)","0c1b5f60":"nv = MultinomialNB()","968c4279":"nv.fit(x_train, y_train)","e67ab2bd":"ypred = nv.predict(x_test)","ff781c1f":"print('###### confusion matrix ######\\n')\nprint(confusion_matrix(y_test, ypred))\nprint('\\n###### classification report ######\\n')\nprint(classification_report(y_test, ypred))\nprint('\\n accuracy score :', accuracy_score(y_test, ypred))\nprint('\\n precision score :', precision_score(y_test, ypred))\nprint('\\n recall score :', recall_score(y_test, ypred))","01b092d6":"df_test=pd.read_csv('..\/input\/emotions-dataset-for-nlp\/test.txt', delimiter=';', names = ['text','label'])\ndf_test.sample(4)","22fa8066":"manual_encoder(df_test['label'])\ncorpus = data_prep(df_test['text'])\ntestdata = cv.transform(corpus)\npred = nv.predict(testdata)","c021bd1a":"print('###### confusion matrix ######\\n')\nprint(confusion_matrix(df_test['label'], pred))\nprint('\\n###### classification report ######\\n')\nprint(classification_report(df_test['label'], pred))\nprint('\\n accuracy score :', accuracy_score(df_test['label'], pred))\nprint('\\n precision score :', precision_score(df_test['label'], pred))\nprint('\\n recall score :', recall_score(df_test['label'], pred))","92d96810":"## <---> love, surprise, joy = positive statement\n## <---> sadness, anger, fear = negative statement","eb4d475e":"# Data Preprocessing","f4df96d8":"## Bag of words","26d550fd":"plt.figure(figsize=(20,8))\nword_cloud=\"\"\nfor rows in corpus:\n    for words in corpus:\n        word_cloud += \" \".join(words)\nwordcloud = WordCloud().generate(word_cloud)\nplt.imshow(wordcloud)"}}