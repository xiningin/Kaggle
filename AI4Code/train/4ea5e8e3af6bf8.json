{"cell_type":{"c14b26e1":"code","5a514212":"code","064f56c7":"code","86952356":"code","1a4c912b":"code","39aefbb1":"code","1c6d9d5c":"code","d0f8f7ac":"code","ccdc7840":"code","682d80f2":"code","2722a34b":"code","ea336ab2":"code","19bdd073":"code","41e9911f":"markdown","b9d53013":"markdown","bdf756e6":"markdown","b3f0ae24":"markdown","bebf5b21":"markdown","6c60bd1a":"markdown"},"source":{"c14b26e1":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n#keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n#viz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px","5a514212":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nprint(train.shape)\ntrain.head()","064f56c7":"Y_train = train[\"label\"]\n# Drop 'label' column\nX_train = train.drop(\"label\",axis = 1) ","86952356":"px.pie(Y_train,names='label',title='Distribution Of Train Lables')","1a4c912b":"fig,ax=plt.subplots(3,3,figsize=(15,10))\n\nfor i in range(3):\n    for j in range(3):\n        select=np.random.randint(0,len(train))\n        img = train.iloc[select,1:].values\n        img = img.reshape((28,28))\n        ax[i][j].imshow(img,cmap='jet')\n        ax[i][j].set_title(train.iloc[select,0],fontsize=20)","39aefbb1":"X_train = X_train \/ 255.0\ntest = test \/ 255.0\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nY_train = to_categorical(Y_train, num_classes = 10)\n","1c6d9d5c":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=314)","d0f8f7ac":"model = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","ccdc7840":"history = model.fit(X_train,Y_train,epochs = 2, validation_data = (X_val,Y_val))","682d80f2":"plt.figure(figsize=(18,11))\nplt.plot(history.history['val_loss'], label=\"validation loss\",lw=2)\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","2722a34b":"Y_pred = model.predict(X_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"jet\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","ea336ab2":"all_target = model.predict(test)\nY_pred_classes = np.argmax(all_target,axis = 1) \nY_pred_classes","19bdd073":"predictions = pd.DataFrame({\"ImageId\": np.arange(1, len(Y_pred_classes)+1), \"Label\": Y_pred_classes})\npredictions = predictions.set_index(\"ImageId\")\npredictions.to_csv(\"output.csv\")","41e9911f":"# Data Preprocessing","b9d53013":"# Sequantial Model","bdf756e6":"# Loading The Data","b3f0ae24":"# Train Test Split","bebf5b21":"### We have a uniform distribution of target lables","6c60bd1a":"# Model Prediction And Evaluation"}}