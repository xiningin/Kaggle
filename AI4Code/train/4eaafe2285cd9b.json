{"cell_type":{"2c1777e5":"code","b68679c8":"code","eeda00f9":"code","9b4ca5af":"code","ddbe483a":"code","e0d167df":"code","08682a80":"code","d6bc2119":"code","2f998def":"code","c3f74186":"code","e966b4b2":"code","c45d3f2e":"code","9bf60e0d":"code","72358856":"code","1faa5a80":"code","03a60223":"code","8291ebf3":"code","5bb94855":"code","cb3738dd":"code","e2ea8262":"code","6f955502":"code","d5cb1ab6":"code","17c32568":"code","217bb332":"code","a7d8ff34":"code","f23cacf2":"code","aeffe58c":"code","0e7be82b":"code","d03fdb14":"code","1f730da0":"code","af5468ed":"code","7618c025":"code","ca111191":"code","0d4951f4":"code","c4424ca0":"code","5182e4bb":"code","c0e1429f":"code","d4dd55cb":"code","28c5d9b5":"code","52ff9440":"markdown","6ac91e63":"markdown"},"source":{"2c1777e5":"from fastai.basics import *\nfrom fastai.callback.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\n\nimport pydicom\nimport matplotlib.image as immg\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches","b68679c8":"# Handy fast.ai function to pull all DICOM file names into a list\n#items = get_dicom_files(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\") #full images\nitems = get_image_files('..\/input\/vinbigdata-resized-image-512\/train') #using the 512 images\nitems[0:5]","eeda00f9":"# another handy fast.ai funciton to split items randomly...\ntrn,val = RandomSplitter()(items)","9b4ca5af":"#xray_sample.pixel_array, xray_sample.pixel_array.shape","ddbe483a":"#xray_sample.show()","e0d167df":"%%time \n# takes 7-8 minutes, so load from pickle\n'''dicom_dataframe = pd.DataFrame.from_dicoms(items, window=dicom_windows.lungs, px_summ=False)\n\ndicom_dataframe.to_pickle('dicom_dataframe_pickle.pkl')\ndicom_dataframe.shape'''","08682a80":"# long time to extract the DICOM information, so extracted into pickle for easy loading\ndicom_dataframe = pd.read_pickle('..\/input\/vinbigdata-chest-xray-dicom-data-frame\/dicom_dataframe_pickle.pkl')\ndicom_dataframe.shape # should be 15k by 29","d6bc2119":"dicom_dataframe.head()","2f998def":"df = pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv')\nimg_dim = pd.read_csv('..\/input\/vinbigdata-resized-image-512\/train_meta.csv')\ntr_img_dir = Path('..\/input\/vinbigdata-resized-image-512\/train')\nts_img_dir = Path('..\/input\/vinbigdata-resized-image-512\/test')","c3f74186":"tr_df = df.merge(img_dim,on='image_id',how='left')\ntr_df.head()","e966b4b2":"# Create a df without class 14, the no finding class\ntr_df1 = tr_df[tr_df['class_id']!=14].copy()\ntr_df1.head()","c45d3f2e":"# Rescale bounding boxes to use the resized images\ntr_df1['x_min'] = tr_df1['x_min']*512\/tr_df['dim1']\ntr_df1['x_max'] = tr_df1['x_max']*512\/tr_df['dim1']\ntr_df1['y_min'] = tr_df1['y_min']*512\/tr_df['dim0']\ntr_df1['y_max'] = tr_df1['y_max']*512\/tr_df['dim0']","9bf60e0d":"# Creating a group by dataframe to pass the images in later\ndf_grp = tr_df1.groupby(['image_id'])\ndf_grp.head()","72358856":"# taking a look at the values of one image, and the different classes in them\ndf_grp.get_group('f8c4ffc718ece871a52ab5f63b04b41c')","1faa5a80":"# take a look at one image from the training set with bounding boxes\nb_fea = ['x_min', 'y_min', 'x_max', 'y_max']\nname = '9a5094b2563a1ef3ff50dc5c7ff71345'\nloc = '..\/input\/vinbigdata-resized-image-512\/train\/'+name+'.png'\naaa = df_grp.get_group(name)\nbbx = aaa.loc[:,b_fea] #get x and y coordinates for all rows\nimg = immg.imread(loc) # tensor representation for the image\nfig,ax = plt.subplots(figsize=(18,10))\nax.imshow(img,cmap='binary')\n\n# Find how many lines there are for an image in the df\n# Draw a box for each time\nfor i in range(len(bbx)): \n    box = bbx.iloc[i].values\n    x,y,w,h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n    rect = patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none',)\n    ax.text(*box[:2], aaa['class_name'].iloc[i], verticalalignment='top', color='white', fontsize=12, weight='bold')\n    ax.add_patch(rect)\nplt.show()\n\n# thanks again: https:\/\/www.kaggle.com\/robertlangdonvinci\/vinbigdata-chest-abnormalities-detection-fastai","03a60223":"#tr_df1.head()\nnofinding_df = tr_df[tr_df['class_id']==14].copy()\n","8291ebf3":"tr_df1.head()","5bb94855":"values = {'x_min': 0, 'y_min':0, 'x_max':1, 'y_max':1}\nnofinding_df.fillna(value=values, inplace = True)\n\n\nframes = [nofinding_df, tr_df1]\ntr_df2= pd.concat(frames)\ntr_df2.tail()\nnofinding_df.head()","cb3738dd":"def get_lbl_img(train):\n    chest2bbox = {}\n    grp = train.image_id.unique()\n    tr_gr = train.groupby(['image_id'])\n    from tqdm.notebook import tqdm\n    for i in tqdm(range(len(grp))):\n        name = str(grp[i])+'.png'\n        bbox = []\n        lbls = []\n        temp_b = []\n        temp = tr_gr.get_group(grp[i])\n        tt = temp.loc[:, (['class_id','x_min', 'y_min', 'x_max', 'y_max'])].values\n        for j in range(len(temp)):\n            lbls.append(tt[j][0].astype(int))\n            b = list(np.round(tt[j][1:]))   # x,y, width, height\n            # Currently our coordinates are x,w,l,h and we want x1,y1,x2,y2\n            # To convert it, we need to add our width and height to the respective x and y.\n            t1 = [b[1],b[0],b[3],b[2]]\n\n            temp_b.append(t1)\n        bbox.append(temp_b)\n        bbox.append(lbls)\n        chest2bbox[name] = bbox\n    return chest2bbox","e2ea8262":"chest2bbox = get_lbl_img(tr_df2)","6f955502":"coco_source = untar_data(URLs.COCO_TINY)\nimages, lbl_bbox = get_annotations(coco_source\/'train.json')\nimg2bbox = dict(zip(images, lbl_bbox))\nimg2bbox","d5cb1ab6":"chest2bbox","17c32568":"getters = [lambda o: '..\/input\/vinbigdata-resized-image-512\/train'\/o, lambda o: chest2bbox[o][0], lambda o: chest2bbox[o][1]]\nxray_dblk = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n                      get_items=get_image_files,\n                      splitter=RandomSplitter(),\n                      #getters = getters,\n                      get_y=[lambda o: chest2bbox[o.name][0], lambda o: chest2bbox[o.name][1]],\n                      #get_y = lambda o: chest2bbox[Path(o).name] ,\n                      item_tfms=Resize(128),\n                      batch_tfms=aug_transforms(),\n                 n_inp=1)","217bb332":"dls = xray_dblk.dataloaders('..\/input\/vinbigdata-resized-image-512\/train')\ndls.show_batch(max_n=9)","a7d8ff34":"!git clone https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0.git\n%cd \"Practical-Deep-Learning-for-Coders-2.0\/Computer Vision\"","f23cacf2":"from imports import *","aeffe58c":"encoder = create_body(resnet34, pretrained=True)","0e7be82b":"get_c(dls) #how many classes","d03fdb14":"arch = RetinaNet(encoder, get_c(dls), final_bias=-4)","1f730da0":"create_head(124, 4)","af5468ed":"arch.smoothers","7618c025":"arch.classifier","ca111191":"arch.box_regressor","0d4951f4":"ratios = [1\/2,1,2]\nscales = [1,2**(-1\/3), 2**(-2\/3)]\ncrit = RetinaNetFocalLoss(scales=scales, ratios=ratios)","c4424ca0":"def _retinanet_split(m): return L(m.encoder,nn.Sequential(m.c5top6, m.p6top7, m.merges, m.smoothers, m.classifier, m.box_regressor)).map(params)","5182e4bb":"learn = Learner(dls, arch, loss_func=crit, splitter=_retinanet_split)","c0e1429f":"learn.freeze()","d4dd55cb":"%cd -","28c5d9b5":"#learn.fit_one_cycle(10, slice(le-5, le-4))\nlearn.lr_find()","52ff9440":"## And the data loader is working!\n\nThe above code blocks are way messy, will clean it up later.\n\n\n## I'm having trouble working through the learner... \n\nBounding boxes are a bit complex, so I was trying to get the code from the below tutorial working, but no luck so far. Hoping to have some more time over the weekend (Feb 27-28), so hopefully I can get the below code working.\n\nhttps:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0\/blob\/master\/Computer%20Vision\/06_Object_Detection.ipynb","6ac91e63":"This notebook is just me working my way through fast.ai v2 courses. \n\nSpecifically:\n* The medical imaging tutorial https:\/\/docs.fast.ai\/tutorial.medical_imaging.html\n* The bounding boxes tutorial: https:\/\/docs.fast.ai\/tutorial.datablock.html#Bounding-boxes\n* useful: https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0\/blob\/master\/Computer%20Vision\/06_Object_Detection.ipynb\n* https:\/\/www.kaggle.com\/muellerzr\/fastai2-starter-kernel\n\nShout out to this notebook who did it in Fastai v1. I copied a bunch of code from it\nhttps:\/\/www.kaggle.com\/robertlangdonvinci\/vinbigdata-chest-abnormalities-detection-fastai\n<br>(If you can give me an upvote give him an up-vote too...)"}}