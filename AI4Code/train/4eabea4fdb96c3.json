{"cell_type":{"c6452856":"code","e28efe8d":"code","857a3644":"code","0aa33d74":"code","cdb8d9c2":"code","9043f04c":"code","2540119a":"code","f52b39f9":"code","bf4a13c1":"code","9f5983b4":"code","042d36bd":"code","492b192b":"code","a3c80923":"markdown","69bce79f":"markdown","d83b21f6":"markdown","82c51648":"markdown","cab53f3d":"markdown","a22c3b5f":"markdown","a663b66c":"markdown","9c05dc37":"markdown"},"source":{"c6452856":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.utils import data\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\n\nprint(os.listdir(\"..\/input\"))\nprint(f'\\nPyTorch version {torch.__version__}\\n')\nprint('cuda' if torch.cuda.is_available() else 'cpu')","e28efe8d":"print(os.listdir('..\/input\/oxford-102-flower-pytorch\/flower_data\/flower_data\/'))","857a3644":"#try data_dir = '..\/input\/flower_data\/flower_data\/'\ndata_dir = '..\/input\/oxford-102-flower-pytorch\/flower_data\/flower_data\/'\n\nclass TestDataset(data.Dataset):\n    '''\n    Custom dataset class for test dataset which contains uncategorized images.\n    The category index is set to 0 for all images (we don't need it).\n    It also returns the filename of each image.\n    '''\n    def __init__(self, path, transform=None):\n        self.path = path\n        self.files = []\n        for (dirpath, _, filenames) in os.walk(self.path):\n            for f in filenames:\n                if f.endswith('.jpg'):\n                    p = {}\n                    p['img_path'] = dirpath + '\/' + f\n                    self.files.append(p)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img_path = self.files[idx]['img_path']\n        img_name = img_path.split('\/')[-1]\n        image = pil_loader(img_path)\n        if self.transform:\n            image = self.transform(image)\n        return image, 0, img_name\n    \n    \ndef pil_loader(path):\n    with open(path, 'rb') as f:\n        img = Image.open(f)\n        return img.convert('RGB')\n    \n    \n# Image transformations\ndata_transforms = transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                            std=[0.229, 0.224, 0.225])])\n\n# Validation dataset\nval_dataset = datasets.ImageFolder(data_dir + 'valid', transform=data_transforms)\n\n# Test dataset\ntest_dataset = TestDataset(data_dir + 'test', transform=data_transforms)\n\n# Create the dataloaders\nbatch_size = 32\nval_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","0aa33d74":"def imshow(image):\n    if isinstance(image, torch.Tensor):\n        image = image.numpy().transpose((1, 2, 0))\n    else:\n        image = np.array(image).transpose((1, 2, 0))\n    # Unnormalize\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n    image = np.clip(image, 0, 1)\n    # Plot\n    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n    plt.imshow(image)\n    ax.axis('off') \n        \n    # Make a grid from batch\nimages, _, _ = next(iter(test_loader))\nout = torchvision.utils.make_grid(images, nrow=8)\nimshow(out)","cdb8d9c2":"# Change the classifier to the one you used.\ndef classifier(n_ftrs):\n    return nn.Sequential(nn.Linear(n_ftrs, 102),                           \n                         nn.LogSoftmax(dim=1))","9043f04c":"def load_checkpoint(checkpoint_path):\n    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n    \n    # Here put the pretrained model that you used (in my case it's densenet161).\n    model = models.densenet161(pretrained=False)\n    \n    # We freeze all the layers since we are not training the model here.\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    try:\n        n_ftrs = model.classifier.in_features\n        model.classifier = classifier(n_ftrs)\n    except AttributeError:\n        n_ftrs = model.fc.in_features\n        model.fc = classifier(n_ftrs)\n                              \n    model.load_state_dict(checkpoint['model_state_dict'])  # your checkpoint's key may differ (e.g.'state_dict')\n    model.eval()\n    \n    return model\n\nmodel = load_checkpoint('..\/input\/checkpoint\/checkpoint_ft_0_.pth')  # use your path to checkpoint file\nprint(model.classifier)","2540119a":"def comp_accuracy(model, dataloader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    model.to(device)\n    model.eval()\n    \n    with torch.no_grad():\n        running_acc = 0.0\n        for ii, (images, labels) in enumerate(dataloader, start=1):\n            if ii % 5 == 0:\n                print('Batch {}\/{}'.format(ii, len(dataloader)))\n            images, labels = images.to(device), labels.to(device)\n            logps = model(images)\n            ps = torch.exp(logps)  # in my case the outputs are logits so I take the exp()\n            equals = ps.topk(1)[1].view(labels.shape) == labels          \n            running_acc += equals.sum().item()\n        acc = running_acc\/len(dataloader.dataset) \n        print(f'\\nAccuracy: {acc:.5f}') \n        \n    return acc","f52b39f9":"comp_accuracy(model, val_loader)","bf4a13c1":"# The prediction of our model is an index which we need to convert back to the class label.\n# For this, we will use the following mapping\nidx_to_class = {val: key for key, val in val_dataset.class_to_idx.items()}\nprint(idx_to_class)","9f5983b4":"def predict(model, dataloader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    model.to(device)\n    model.eval()\n    \n    predictions = {}   \n    with torch.no_grad():\n        for ii, (images, _, img_names) in enumerate(dataloader, start=1):\n            if ii % 5 == 0:\n                print('Batch {}\/{}'.format(ii, len(dataloader)))\n            images = images.to(device)\n            logps = model(images)\n            ps = torch.exp(logps)\n            \n            # Top indices\n            _, top_indices = ps.topk(1)\n            top_indices = top_indices.detach().cpu().numpy().tolist()\n    \n            # Convert indices to classes\n            top_classes = [idx_to_class[idx[0]] for idx in top_indices]\n            \n            for i, img_name in enumerate(img_names):\n                predictions[img_name] = top_classes[i]\n            \n        print('\\nCompleted')\n\n    return predictions","042d36bd":"predictions = predict(model, test_loader)","492b192b":"submission = pd.DataFrame(list(predictions.items()), columns=['file_name', 'id'])\nsubmission.to_csv('submission.csv', index=False)\nprint(submission)","a3c80923":"---------------------------------------\nNow that we have loaded our trained model, let's check its performance on the validation dataset.","69bce79f":"Let's plot a batch of test images to check if the test dataloader works properly.","d83b21f6":"# Imports\nImport all the required modules.","82c51648":"# Overview\nThis kernel demonstrates how to test a flower classifier (trained elsewhere, loaded from a saved checkpoint file) for the final project of the Udacity's PyTorch FB Challenge.\n\nThe data originally comes from http:\/\/www.robots.ox.ac.uk\/~vgg\/data\/flowers\/102\/. There are 102 flower categories, and the test dataset contains 819 test images. For this competition the labels of the test dataset are not provided.\n\nSubmitted to: https:\/\/www.kaggle.com\/c\/oxford-102-flower-pytorch","cab53f3d":"Finally. let's get the predictions on the test dataset flower images and write them to the csv file ready for the submission.\nThe submission csv file has two columns, one with the image filenames and one with the id's of the predicted flower category.","a22c3b5f":"# Load the data\nHere we create the data loaders for the validation and test datasets. We will use the validation dataset to check if our model works by computing the total accuracy on this dataset (for which the labels are provided). Then, we make the predictions on the unlabelled data from the test dataset, which will be submited for the competition.\n\nThe validation dataloader is created with [ImageFolder](https:\/\/pytorch.org\/docs\/stable\/_modules\/torchvision\/datasets\/folder.html#ImageFolder) class. This is possible because the folder 'valid' has the required structure: category subfolders containing images of the corresponding category. However, for the test dataset we cannot use ImageFolder because the 'test' folder contains images from different categories, not categorized in subfolders. If we try it, it will throw the error 'RuntimeError: Found 0 files in subfolders of...'. Therefore, to create the test dataloader, we will use a custom dataset class which inherits from the data.Dataset.","a663b66c":"# Submit your predictions\nRun the notebook (after first forking the kernel) and commit. The submition.csv will be stored on the Output folder (if you go back by pressing << on the upper-left corner, you will see the Output tab is on the left sidebar). Press the Output tab and then \"Submit to Competition\" button.\n\n![](https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/102106\/242233\/subm.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1547190677&Signature=alcL%2FMz1z2TqAtZR9lHe%2FrhKeA4PJRqJg4yEW4nmL2%2FEVmUT%2FQ2CD7mWzH7dyzRnE39eNKIfK%2BVHES8CbPCvO7vy%2FD5g7nYNrZj475SRwCg7W9XoqPrBT5Kk0CWlgA2Y0GqRhxUE0O5kuH9v24q1CUn7jrk3Iov%2FUa3jVR3z%2BsGLv70ZU4griFZ6V7JJbvSjdToiLuHW3GhpuYmCG67DoTrpQ9tI42B3SO7IVxC9y5z0I5yKzc4NfcVr4ZohpxCVEMbvRR44rqg79I7WDhNtviyTl%2BC8p1%2B3QQIGbm%2FESAfYxjBVm7z2P0xX0Dihu13AwMIb5PDuFP2dtPtj2kqfYA%3D%3D)\n\n","9c05dc37":"# Load the model from a checkpoint\nHere we load our pretrained model (the state dict) from a checkpoint file which should be first uploaded to the 'input' folder by clicking on **+Add Data** (Draft Environment tab on the right). \nNote that in the following code there are 4 things that you may need to change:\n* the pretrained model (in my case densenet161)\n* the classifier\n* the checkpoint's key to the state dict\n* the checkpoint's path and filename."}}