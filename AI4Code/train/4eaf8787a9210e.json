{"cell_type":{"faff524d":"code","9cfae111":"code","34bdabb9":"code","cd675d7c":"code","e26d9354":"code","0ad0a8b0":"code","769458fe":"code","99d96ce1":"code","75faa975":"code","9804016b":"code","8e4f93ea":"code","d381357f":"code","522c0a74":"code","13f9545a":"code","541cdec8":"code","b822f902":"code","27dcabf6":"code","3e9e5543":"code","c8fd400f":"code","0b8d435c":"code","11a6d493":"code","e545ecc3":"code","3576064c":"code","43f88f44":"code","5e28fcee":"code","cd153a2c":"code","feba9408":"code","a814cf03":"code","79064f44":"code","9b63c088":"code","45ae6a9c":"code","e81289f4":"code","6f9a53f9":"code","a7ff8159":"code","a9b21e55":"code","b3f217ee":"code","66bd5d76":"code","6c1a2287":"code","2bc24559":"code","f1e60568":"code","1ab70078":"code","671e0587":"code","4fbb91ab":"code","d716d6a4":"code","daa0043a":"code","e5c5864b":"code","8e0f6fb2":"code","7749c888":"code","977135b4":"code","4cf110bd":"code","0fdc4da3":"code","30a8d1ec":"code","d945da50":"code","e86b8c57":"code","62968b1e":"code","07bfa19f":"code","2d5dd77b":"code","5e3e7ecf":"code","39777786":"code","890b4877":"code","3bf0b77d":"code","4112eff8":"code","fd2b521f":"code","fbdc389a":"code","5e9c468d":"code","f76de36e":"code","790e6a88":"code","c31d613d":"code","7ecb2e11":"code","c6d44ade":"code","fdfcfbb0":"code","1125272e":"markdown","9e98cd5a":"markdown","0dabedb8":"markdown","299cf6c0":"markdown","197d909c":"markdown","77260a45":"markdown","42a15151":"markdown","bab6a4e9":"markdown"},"source":{"faff524d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cfae111":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_sub = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","34bdabb9":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go","cd675d7c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC","e26d9354":"from sklearn.model_selection import train_test_split","0ad0a8b0":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report","769458fe":"train.head()","99d96ce1":"train.info()","75faa975":"train.isna().sum()","9804016b":"train[train.Embarked.isna()]","8e4f93ea":"sns.countplot(x='Embarked', data=train, hue='Survived')","d381357f":"# Since the majority of those who embarked at 'S' did not survive (and the same for 'Q', although fewer)\n# we will impute the two missing embark locations to C\n\n# train.info()\ntrain[train.Embarked.isna()]\ntrain['Embarked']=train['Embarked'].fillna(\"C\")\ntrain.info()","522c0a74":"train.Age.value_counts()","13f9545a":"print(train.Age.mean(), train.Age.median())","541cdec8":"train.Parch.value_counts()","b822f902":"sns.pairplot(train, hue='Survived');","27dcabf6":"train_df = train.copy()\ntest_df = test.copy()\ntrain_df.drop('PassengerId', axis=1, inplace=True)\ntest_df.drop('PassengerId', axis=1, inplace=True)","3e9e5543":"cat_cols = [col for col in train_df.columns if train_df[col].dtype == 'object']\ncat_cols","c8fd400f":"cat_cols = cat_cols[1:]\ncat_cols","0b8d435c":"train_cat = train_df[cat_cols]\nfor col in cat_cols:\n    sns.countplot(x = col, data=train_df, hue = 'Survived')\n    plt.show()","11a6d493":"print(train_df.Ticket.value_counts(), train_df.Cabin.value_counts())","e545ecc3":"train_df.drop(['Cabin', 'Ticket'], axis=1, inplace=True)\ntest_df.drop(['Cabin', 'Ticket'], axis=1, inplace=True)\nprint(train_df.shape, test_df.shape)","3576064c":"train_df.head()\ntrain_df.info()","43f88f44":"train_df.drop('Name', axis=1, inplace=True)\ntest_df.drop('Name', axis=1, inplace=True)","5e28fcee":"print(train_df.shape, test_df.shape)\ntrain_train = train_df.iloc[:, 1:]\ntrain_y = train_df.iloc[:, 0]\n\ntrain_train.head()","cd153a2c":"# change remaining two categorical features to numeric before applying ML models\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_train = LabelEncoder()\ntrain_train['Sex'] = labelencoder_train.fit_transform(train_train['Sex'])\ntrain_train['Embarked'] = labelencoder_train.fit_transform(train_train['Embarked'])\n\ntrain_train.info()","feba9408":"labelencoder_test = LabelEncoder()\ntest_df['Sex'] = labelencoder_test.fit_transform(test_df['Sex'])\ntest_df['Embarked'] = labelencoder_test.fit_transform(test_df['Embarked'])\n\ntest_df.info()","a814cf03":"plt.style.use('ggplot')\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer","79064f44":"np.random.seed(43)\n\n# look at the distribution using StandardScaler\nscaler = StandardScaler()\nscaled_df = scaler.fit_transform(train_train)\nscaled_df = pd.DataFrame(scaled_df, columns=train_train.columns)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\nax1.set_title('Before Scaling')\nfor col in range(len(train_train.columns)):\n    sns.kdeplot(train_train.iloc[:,col], ax=ax1)\n\nax2.set_title('After Standard Scaler')\nfor col in range(len(scaled_df.columns)):\n    sns.kdeplot(scaled_df.iloc[:,col], ax=ax2)\n\nplt.show()","9b63c088":"np.random.seed(43)\n\n# look at the distribution using MinMaxScaler\nscaler = MinMaxScaler()\nscaled_df = scaler.fit_transform(train_train)\nscaled_df = pd.DataFrame(scaled_df, columns=train_train.columns)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\nax1.set_title('Before Scaling')\nfor col in range(len(train_train.columns)):\n    sns.kdeplot(train_train.iloc[:,col], ax=ax1)\n\nax2.set_title('After Min-Max Scaling')\nfor col in range(len(scaled_df.columns)):\n    sns.kdeplot(scaled_df.iloc[:,col], ax=ax2)\n\nplt.show()","45ae6a9c":"np.random.seed(43)\n\n# look at the distribution using RobustScaler\nscaler = RobustScaler()\nscaled_df = scaler.fit_transform(train_train)\nscaled_df = pd.DataFrame(scaled_df, columns=train_train.columns)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\nax1.set_title('Before Scaling')\nfor col in range(len(train_train.columns)):\n    sns.kdeplot(train_train.iloc[:,col], ax=ax1)\n\nax2.set_title('After Robust Scaling')\nfor col in range(len(scaled_df.columns)):\n    sns.kdeplot(scaled_df.iloc[:,col], ax=ax2)\n\nplt.show()","e81289f4":"scaled_df.isna().sum()","6f9a53f9":"examine_ages = train_train.copy()\nexamine_ages.Age.value_counts()","a7ff8159":"num_ages = examine_ages.Age.value_counts()\nnum_ages > 1","a9b21e55":"age_counts = examine_ages.Age.value_counts().rename('age_counts')\nage_counts\ntop_ages = examine_ages.merge(age_counts.to_frame(),\n                              left_on='Age',\n                              right_index=True)\ntop_ages","b3f217ee":"sns.heatmap(top_ages.drop('Fare', axis=1));","66bd5d76":"top_ages = top_ages[top_ages.age_counts >= 20]\ntop_ages.head()","6c1a2287":"# get statistics of age of each group of counts\ntop_ages.groupby('age_counts')[['Age', 'age_counts', 'Pclass']].agg(['min', 'max', 'mean', 'median']).sort_index()","2bc24559":"train_train.groupby('Pclass')['Age'].mean()","f1e60568":"# make dictionary of mean ages from each class\nage_dict = dict(train_train.groupby('Pclass')['Age'].mean())\nage_dict","1ab70078":"# fill the na's with mean ages from each class\ntrain_train['Age'] = train_train.Age.fillna(train_train.Pclass.map(age_dict))","671e0587":"train_train.info()","4fbb91ab":"np.random.seed(43)\n\n# scale train_train with MinMaxScaler\nscaler = MinMaxScaler()\nscaled_df = scaler.fit_transform(train_train)\ntrain_train_scaled = pd.DataFrame(scaled_df, columns=train_train.columns)\ntrain_train_scaled.head()","d716d6a4":"# preprocess the test data the same way\ntest_df.groupby('Pclass')['Age'].mean()","daa0043a":"# make dictionary of mean ages from each class\ntest_age_dict = dict(test_df.groupby('Pclass')['Age'].mean())\n# fill the na's with mean ages from each class\ntest_df['Age'] = test_df.Age.fillna(test_df.Pclass.map(test_age_dict))\ntest_df.info()","e5c5864b":"test_df[test_df.isna().any(axis=1)]","8e0f6fb2":"fares = test_df.groupby(['Pclass', 'Embarked'])['Fare'].mean()\nfare = fares.loc[(3,2)]\nfare","7749c888":"test_df['Fare'] = test_df['Fare'].fillna(fare)\ntest_df.info()","977135b4":"X_train, X_valid, y_train, y_valid = train_test_split(train_train, train_y, test_size = 0.3, random_state=43)","4cf110bd":"# Logistic regression:\n# instantiate, fit, predict\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_preds = lr.predict(X_valid)","0fdc4da3":"# Linear discriminant analysis:\n# instantiate, fit, predict\nld = LinearDiscriminantAnalysis()\nld.fit(X_train, y_train)\nld_preds = ld.predict(X_valid)","30a8d1ec":"# K neighbors classifier:\n# instantiate, fit, predict\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_preds = knn.predict(X_valid)","d945da50":"# Naive Bayes:\n# instantiate, fit, predict\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nnb_preds = nb.predict(X_valid)","e86b8c57":"# Decision Tree:\n# instantiate, fit, predict\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_preds = dt.predict(X_valid)","62968b1e":"# SVC:\n# instantiate, fit, predict\nsvc = SVC(kernel='linear', C=1.0)\nsvc.fit(X_train, y_train)\nsvc_preds = svc.predict(X_valid)","07bfa19f":"y_valid.shape","2d5dd77b":"svc_preds.shape","5e3e7ecf":"# evaluate models\npredictions = [lr_preds, ld_preds, knn_preds, nb_preds, dt_preds, svc_preds]\n\nfor preds in predictions:\n    print(accuracy_score(y_valid, preds))","39777786":"for preds in predictions:\n    print(confusion_matrix(y_valid, preds))","890b4877":"for preds in predictions:\n    print(classification_report(y_valid, preds))","3bf0b77d":"nb_test_preds = nb.predict(test_df)","4112eff8":"nb_test_preds","fd2b521f":"len(nb_test_preds)","fbdc389a":"len(test)","5e9c468d":"test.head()","f76de36e":"test_id = test.PassengerId\ntest_id.head()","790e6a88":"print(type(nb_test_preds), type(test_id))","c31d613d":"type(test_id.values)","7ecb2e11":"sub = pd.DataFrame(zip(test_id.values, nb_test_preds), columns=['PassengerId', 'Survived'])","c6d44ade":"sub","fdfcfbb0":"sub.to_csv(\"submission.csv\", index=False)","1125272e":"Dropping two more columns for simplicity","9e98cd5a":"Try to figure out if missing ages are from children or adults and if it might make a difference to their survival.","0dabedb8":"I think I may just use mean ages from each class.","299cf6c0":"It looks like larger families tended to not survive, and unsurprisingly (and sadly), class and fare seem to be the most influential.","197d909c":"Now we can try to make ticket and cabin more useful, or just drop them.","77260a45":"Now let's see where most survivors embarked.  That is what we will impute these two passengers to.","42a15151":"Hmmm...one missing fare","bab6a4e9":"I believe I can extract some useful information from 'Name\", but I'll save that for a more advanced look at the data.  For now I'll just drop the column."}}