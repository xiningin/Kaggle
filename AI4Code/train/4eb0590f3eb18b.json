{"cell_type":{"aa34b687":"code","3a5bfbd0":"code","b0c9cef4":"code","132879fd":"code","a55c6e83":"code","4bde4706":"code","98133ae8":"code","cd957faa":"code","968c45d2":"code","c960f421":"code","f8aa0286":"code","82910218":"code","d3fbbc27":"code","b9310a45":"code","b4b2dc7d":"code","833b22af":"code","dd57ad53":"code","3546b8fc":"code","38018ae6":"code","1dbcef52":"code","ebd4014f":"code","da129fae":"code","224ad497":"code","541d1af7":"code","2a946183":"code","c9c973e3":"code","4a782b07":"code","65c1cddf":"code","9a15eda0":"code","a4dc6c4a":"code","904abaa0":"code","1316afde":"code","616fca00":"code","e69ae3c2":"code","19c122f3":"code","4b56cf74":"code","06191468":"code","b4f4abe3":"code","da321e71":"code","625c05b0":"code","f7404ae0":"code","12242102":"code","d3e973a6":"code","c5d15cb4":"code","d4fabbde":"code","0c41965e":"code","0bf2476b":"code","49161978":"code","f026fcdb":"code","c12bce76":"code","289f3128":"code","51273cf3":"code","11dbbc68":"markdown","5fac23b9":"markdown","dcc07f4d":"markdown","ede6e5d9":"markdown","73def841":"markdown","a4326168":"markdown","09429d4f":"markdown","4a15833c":"markdown","217619a1":"markdown","d8130a35":"markdown","2b6e8988":"markdown","36ba32a7":"markdown","a9c5ef80":"markdown","f2e12715":"markdown","b263090a":"markdown","108421d4":"markdown","51342409":"markdown"},"source":{"aa34b687":"# Obtendo os dados\n!mkdir data; cd data; wget -c https:\/\/ti.arc.nasa.gov\/m\/project\/prognostic-repository\/CMAPSSData.zip; unzip -o CMAPSSData.zip; rm CMAPSSData.zip","3a5bfbd0":"!ls data","b0c9cef4":"!head -n5 data\/train_FD001.txt","132879fd":"!head -n5 data\/test_FD001.txt","a55c6e83":"!head -n5 data\/RUL_FD001.txt","4bde4706":"# definindo os nomes das colunas\ncols_index = ['UnitNumber', 'Cycle']\ncols_settings = ['OpSetting1', 'OpSetting2', 'OpSetting3']\ncols_sensors = ['Sensor'+str(i) for i in range(1, 22)]\ncols = cols_index + cols_settings + cols_sensors\nprint(cols)","98133ae8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","cd957faa":"# l\u00ea somente as 26 primeiras colunas do arquivo FD001 (s\u00e3o as que a gente sabe o que \u00e9 pelas informa\u00e7\u00f5es do readme.txt)\n# FD001 \u00e9 o experimento que simula falhas no compressor \u00e0 n\u00edvel do mar, conforme o arquivo readme.txt\ntrain = pd.read_csv('data\/train_FD001.txt', header=None, sep=\" \").iloc[:,:26]\ntest = pd.read_csv('data\/test_FD001.txt', header=None, sep=\" \").iloc[:,:26]\ntrain.columns = cols\ntest.columns = cols","968c45d2":"train.head()","c960f421":"test.head()","f8aa0286":"# H\u00e1 colunas com Nans?\ncols_nan = train.columns[train.isna().any()].tolist()\nprint('Colunas com tudo NANs: \\n' + str(cols_nan) + '\\n')","82910218":"# H\u00e1 colunas com valores constantes?\ncols_const = [ col for col in train.columns if len(train[col].unique()) <= 2 ]\nprint('Colunas com valores constantes: \\n' + str(cols_const) + '\\n')","d3fbbc27":"# Quantas unidades temos neste arquivo de Treinamento?\nnumber_of_units = train['UnitNumber'].drop_duplicates().values.size\nprint(number_of_units)","b9310a45":"# Qual \u00e9 o ciclo m\u00e1ximo de cada unidade?\nmax_cycle = train.groupby('UnitNumber')['Cycle'].max().values\nmax_cycle","b4b2dc7d":"# Qual \u00e9 o tempo para falha de cada um dos ciclos desta unidade?4\ncol_target = 'RemainingUsefulLife'\ntrain[col_target] = max_cycle[train['UnitNumber']-1] - train['Cycle']\ntrain.head()","833b22af":"# Como os dados de setting operacional se relacionam com o target?\nexplore = sns.PairGrid(data=train.query('UnitNumber < 15') ,\n                 x_vars=col_target,\n                 y_vars=cols_settings,\n                 hue=\"UnitNumber\", height=2, aspect=3)\nexplore = explore.map(plt.scatter, alpha=0.5)\nexplore = explore.set(xlim=(400,0))\nexplore = explore.add_legend()","dd57ad53":"# Como os dados de setting operacional se relacionam com o target?\nexplore = sns.PairGrid(data=train.query('UnitNumber < 15') ,\n                 x_vars=col_target,\n                 y_vars=cols_sensors,\n                 hue=\"UnitNumber\", height=2, aspect=3)\nexplore = explore.map(plt.scatter, alpha=0.5)\nexplore = explore.set(xlim=(400,0))\nexplore = explore.add_legend()","3546b8fc":"# H\u00e1 colunas com valores constantes?\ncols_const = [ col for col in train.columns if len(train[col].unique()) <= 2 ]\nprint('Columns com valores Constantes: \\n' + str(cols_const) + '\\n')","38018ae6":"# Qual \u00e9 a correla\u00e7\u00e3o entre as colunas?\ntrain_corr = train[[x for x in cols if x not in cols_const]].corr(method='pearson')\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(train_corr, linewidths=.5)","1dbcef52":"# Quais s\u00e3o as features mais correlacionadas?\nTHRESHOLD = 0.8\ntrain_corr = train.corr(method='pearson')\ndf_corr = pd.DataFrame(np.tril(train_corr.values), columns=train_corr.columns, index = train_corr.index)\n\ncorrelating = []\nfor col in [x for x in df_corr.columns if x not in cols_const]:\n    ser = df_corr[col]\n    idx = np.logical_or(-THRESHOLD > ser,  ser > THRESHOLD)\n    for i, c in zip(ser[idx].index, ser[idx].values):\n        if (i, col, c) not in correlating and i != col:\n            correlating.append((col, i, c))\n\nprint('Medidas com correla\u00e7\u00e3o alta:')\nfor c in correlating:\n    print(f'{c[0]} x {c[1]} : {c[2]}')","ebd4014f":"# Quais s\u00e3o as features mais importantes (segundo a RandomForest)?\n\nfrom sklearn import ensemble\n\nrf = ensemble.RandomForestRegressor(n_estimators = 200, max_depth = 15)\n# escolhe as colunas que n\u00e3o s\u00e3o \u00edndice nem settings operacionais\naux_cols = [x for x in cols if x in train.columns and x not in cols_index and x not in cols_settings]\n\n# treina o modelo\nX_train = train[aux_cols]\ny_train = train[col_target]\nrf.fit(X_train, y_train)\n\n# Plota as feature importances\nfeature_importance = rf.feature_importances_\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\nsorted_idx = sorted_idx[len(feature_importance) - 50:]\npos = np.arange(sorted_idx.shape[0]) + .5\n\nplt.figure(figsize=(10,5))\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X_train.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","da129fae":"cols_not_important = ['Sensor1', 'Sensor19', 'Sensor5', 'Sensor18', 'Sensor10', 'Sensor16', 'Sensor6']","224ad497":"# Qual \u00e9 a varia\u00e7\u00e3o na condi\u00e7\u00e3o de in\u00edcio dos motores?\n\nmeans = []\nvariances = []\ndf_start = train.loc[train['Cycle'] < 10.0].copy()\ncols_data = [col for col in train.columns if col.startswith('Sensor')]\n\nfor nr, df_tmp in df_start.groupby('UnitNumber'):\n    means.append(df_tmp[cols_data].mean())\n    variances.append(df_tmp[cols_data].var())\ndf_means = pd.DataFrame(means)\ndf_vars = pd.DataFrame(variances)\n\ndc2 = {}\nax = df_means.plot(subplots=True, figsize=(12, 12))\nplt.xlabel('UnitNumber')\nplt.show()\n\ndf_table = pd.DataFrame({\n    'vari\u00e2ncia das m\u00e9dias entre unidades (em %)': df_means.var() \/ df_means.mean() * 100,\n    'mean': df_means.mean(),\n    'var': df_means.var(),\n    'max': df_means.max(),\n    'min': df_means.min()\n})\nfrom IPython.core.display import HTML\ndisplay(HTML(df_table.to_html()))\n\ndf_perc = pd.DataFrame(\n    {\n        'Raz\u00e3o \"vari\u00e2ncia das m\u00e9dias entre unidades\" pelas m\u00e9dias': df_means.var() \/ df_means.mean(),\n    })\nax2 = (df_perc * 100).plot.bar(figsize=(12, 4))\ntxt = plt.gca().set_ylabel('variancia da m\u00e9dia sobre a m\u00e9dia (varia\u00e7\u00e3o percentual 0...100%)')","541d1af7":"cols_to_drop = list(cols_index)\ncols_to_drop.extend(cols_settings)\ncols_to_drop.extend([col_target])\nprint(f'Colunas que vazam dados para o treinamento: {cols_to_drop}')","2a946183":"# vamos retirar as features que tem valor constante\ncols_const = [ col for col in train.columns if len(train[col].unique()) <= 2 ]\ncols_to_drop.extend(cols_const)\nprint(f'Colunas com valores constantes: {cols_const}')","c9c973e3":"# vamos considerar desconsiderar features que n\u00e3o tem muita importancia\ncols_to_drop.extend(cols_not_important)\nprint(f'Colunas com pouca import\u00e2ncia de acordo com a RandomForest: {cols_not_important}')","4a782b07":"cols_selected = [x for x in train.columns if x not in cols_to_drop]\nprint(f'Colunas selecionadas: {cols_selected}')","65c1cddf":"# vamos adicionar features do moving average dos sensores de 2 a 5 passos\nfor aux_col in [x for x in cols_selected if x.startswith('Sensor')]:\n    for i in range(2, 6): #windows sizes\n        train['MA_'+aux_col+'_'+str(i)] = train.groupby('UnitNumber')[aux_col].rolling(i).mean().reset_index(0,drop=True).fillna(method='backfill')","9a15eda0":"# vamos adicionar features das series mais correlacionadas.\n#for i, j in [(4,11), (4,12), (7, 11), (7, 12), (8, 14), (9, 14), (11, 12)]:\n#    train[f'Sensor_x_{i}x{j}'] = train['Sensor'+str(i)] * train['Sensor'+str(j)]","a4dc6c4a":"train.head(10)","904abaa0":"cols_selected = [x for x in train.columns if x not in cols_to_drop]\nprint(f'Colunas selecionadas: {cols_selected}')","1316afde":"# parametros de treinamento\nN_SPLITS = 5\nSEED = 1234","616fca00":"X_test = test[aux_cols]","e69ae3c2":"from sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nfrom sklearn import model_selection\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\n# cria os conjuntos de treino e valida\u00e7\u00e3o\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)\ncv = model_selection.KFold(N_SPLITS)","19c122f3":"# cria o modelo e os folds \nlr = LinearRegression()\n\n# cria o pipeline de modelagem\npipeline_lr = Pipeline(steps=[\n    ('standardize', preprocessing.StandardScaler()),\n    ('model', lr)\n])\n\n# Usa grid-search nos par\u00e2metros para tunar o modelo\nparams_lr = {\n    'model__fit_intercept' : [True, False]\n}\n\n# Encontra os melhores parametros (ver em https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html)\noptimized_lr = GridSearchCV(estimator = pipeline_lr,\n                            cv = cv,\n                            param_grid = params_lr,\n                            scoring = 'neg_mean_squared_error',\n                            verbose = 1,\n                            n_jobs = -1,\n                            refit = True\n                           )\n_ = optimized_lr.fit(X_train, y_train)","4b56cf74":"pd.DataFrame(optimized_lr.cv_results_)[['rank_test_score', 'params','mean_test_score']]","06191468":"# show the best model estimators\nprint(f'Estes foram os parametros do melhor modelo treinado {optimized_lr.best_estimator_}')","b4f4abe3":"# evaluate metrics on holdout\ny_pred = optimized_lr.predict(X_valid)\nprint(\"Linear Regression Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_valid, y_pred)))\nprint(\"Linear Regression Mean Absolute Error: \", mean_absolute_error(y_valid, y_pred))\nprint(\"Linear Regression r-squared: \", r2_score(y_valid, y_pred))","da321e71":"# plot actual vs predicted Remaining Useful Life for the best model (GBM)\nfig, ax = plt.subplots()\nax.scatter(y_valid, y_pred, edgecolors=(0, 0, 0))\nax.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'k--', lw=4)\nax.set_xlabel('Actual RUL')\nax.set_ylabel('Predicted RUL')\nax.set_title('Remaining Useful Life Actual vs. Predicted')\nplt.show()","625c05b0":"# cria o modelo e os folds \nrr = Ridge()\n\n# cria o pipeline de modelagem\npipeline_rr = Pipeline(steps=[\n    ('standardize', preprocessing.StandardScaler()),\n    ('model', rr)\n])\n\n# Usa grid-search nos par\u00e2metros para tunar o modelo\nparams_rr = {\n    'model__fit_intercept' : [True, False],\n    'model__alpha' : [0, .1, .5, 1, 5, 10, 100, 200, 300, 500, 1000]\n}\n\n# Encontra os melhores parametros (ver em https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html)\noptimized_rr = GridSearchCV(estimator = pipeline_rr,\n                            cv = cv,\n                            param_grid = params_rr,\n                            scoring = 'neg_mean_squared_error',\n                            verbose = 1,\n                            n_jobs = -1,\n                            refit = True\n                           )\n_ = optimized_rr.fit(X_train, y_train)","f7404ae0":"pd.DataFrame(optimized_rr.cv_results_)[['rank_test_score', 'params','mean_test_score']]","12242102":"# show the best model estimators\nprint(f'Estes foram os parametros do melhor modelo treinado {optimized_rr.best_estimator_}')","d3e973a6":"# evaluate metrics on holdout\ny_pred = optimized_rr.predict(X_valid)\nprint(\"Ridge Regression Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_valid, y_pred)))\nprint(\"Ridge Regression Mean Absolute Error: \", mean_absolute_error(y_valid, y_pred))\nprint(\"Ridge Regression r-squared: \", r2_score(y_valid, y_pred))","c5d15cb4":"# plot actual vs predicted Remaining Useful Life for the best model (GBM)\nfig, ax = plt.subplots()\nax.scatter(y_valid, y_pred, edgecolors=(0, 0, 0))\nax.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'k--', lw=4)\nax.set_xlabel('Actual RUL')\nax.set_ylabel('Predicted RUL')\nax.set_title('Remaining Useful Life Actual vs. Predicted')\nplt.show()","d4fabbde":"# cria o modelo e os folds \nrf = ensemble.RandomForestRegressor(n_estimators = 100)\n\n# cria o pipeline de modelagem\npipeline_rf = Pipeline(steps=[\n    #('standardize', preprocessing.StandardScaler()),\n    ('model', rf)\n])\n\n\n# Usa grid-search nos par\u00e2metros para tunar o modelo\nparams_rf = {\n    'model__min_samples_leaf' : [2, 10, 25, 50, 100],\n    'model__max_depth' : [3, 5, 7, 9, 11, 13]\n}\n\n# Encontra os melhores parametros (ver em https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html)\noptimized_rf = GridSearchCV(estimator = pipeline_rf,\n                            cv = cv,\n                            param_grid = params_rf,\n                            scoring = 'neg_mean_squared_error',\n                            verbose = 1,\n                            n_jobs = -1,\n                            refit=True\n                           )\noptimized_rf.fit(X_train, y_train)\n\n# show the best model estimators\nprint(f'Estes foram os parametros do melhor modelo treinado {optimized_rf.best_estimator_}')","0c41965e":"pd.DataFrame(optimized_rf.cv_results_)[['rank_test_score', 'params','mean_test_score']]","0bf2476b":"# evaluate metrics on holdout\ny_pred = optimized_rf.predict(X_valid)\nprint(\"Random Forest Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_valid, y_pred)))\nprint(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_valid, y_pred))","49161978":"# plot actual vs predicted Remaining Useful Life for the best model (GBM)\nfig, ax = plt.subplots()\nax.scatter(y_valid, y_pred, edgecolors=(0, 0, 0))\nax.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'k--', lw=4)\nax.set_xlabel('Actual RUL')\nax.set_ylabel('Predicted RUL')\nax.set_title('Remaining Useful Life Actual vs. Predicted')\nplt.show()","f026fcdb":"from lightgbm import LGBMRegressor\n\n# cria o modelo e os folds \nlg = LGBMRegressor(n_estimators = 100)\n\n# cria o pipeline de modelagem\npipeline_lg = Pipeline(steps=[\n    ('standardize', preprocessing.StandardScaler()),\n    ('model', lg)\n])\n\n\n# Usa grid-search nos par\u00e2metros para tunar o modelo\nparams_lg = {\n    'model__min_child_samples' : [2, 10, 20, 30, 50, 100],\n    'model__max_depth' : [3, 4, 5, 6, 7, 9, 11, 13]\n}\n\n# Encontra os melhores parametros (ver em https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html)\noptimized_lg = GridSearchCV(estimator = pipeline_lg,\n                            cv = cv,\n                            param_grid = params_lg,\n                            scoring = 'neg_mean_squared_error',\n                            verbose = 1,\n                            n_jobs = -1,\n                            refit=True\n                           )\noptimized_lg.fit(X_train, y_train)\n\n# show the best model estimators\nprint(f'Estes foram os parametros do melhor modelo treinado {optimized_lg.best_estimator_}')","c12bce76":"pd.DataFrame(optimized_lg.cv_results_)[['rank_test_score', 'params','mean_test_score']]","289f3128":"# evaluate metrics on holdout\ny_pred = optimized_lg.predict(X_valid)\nprint(\"Random Forest Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_valid, y_pred)))\nprint(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_valid, y_pred))","51273cf3":"# plot actual vs predicted Remaining Useful Life for the best model (GBM)\nfig, ax = plt.subplots()\nax.scatter(y_valid, y_pred, edgecolors=(0, 0, 0))\nax.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'k--', lw=4)\nax.set_xlabel('Actual RUL')\nax.set_ylabel('Predicted RUL')\nax.set_title('Remaining Useful Life Actual vs. Predicted')\nplt.show()","11dbbc68":"## \"\u00c9 melhor prevenir do que remediar.\"\n\nEntender quando um equipamento ir\u00e1 falhar *antes* de que ele realmente falhe \u00e9 valioso em v\u00e1rias ind\u00fastrias:\n* Na avia\u00e7\u00e3o comercial: prever quando partes importantes do avi\u00e3o - como o motor, por exemplo - ir\u00e3o falhar pode prevenir desastres, salvar vidas e mitigar problemas como ter que refazer a agenda de v\u00e1rios pilotos e comiss\u00e3rios de bordo por mudan\u00e7as nos planos de v\u00f4o ocasionado pelas condi\u00e7\u00f5es falhas das aeronaves.\n* Na \u00e1rea financeira: pagamentos, saques, transa\u00e7\u00f5es de diversas naturezas precisam funcionar na hora certa. A volatilidade do mercado pode fazer com que parar a opera\u00e7\u00e3o mesmo que s\u00f3 por alguns minutos se torne um problema bastante caro para organiza\u00e7\u00e3o financeira e seus clientes.\n\nE mais: com o avan\u00e7o da Internet das Coisas - ou IoT, na sigla em ingl\u00eas - modelos anal\u00edticos que extraem padr\u00f5es dos dados produzidos por sensores est\u00e3o tornando estes cases cada vez mais frequentes no mundo todo.","5fac23b9":"## An\u00e1lise dos Dados","dcc07f4d":"### Refer\u00eancias:\n* [Predict equipment failure using IoT sensor data (IBM Developer Youtube Channel)](https:\/\/www.youtube.com\/watch?v=bFxdPUOYMiA)\n* [Building Predictive Maintenance Solutions with Azure Machine Learning (Microsoft Azure Videos)](https:\/\/azure.microsoft.com\/pt-br\/resources\/videos\/building-predictive-maintenance-solutions-with-azure-machine-learning\/)\n* [Predictive Maintenance ML (IIoT)](https:\/\/www.kaggle.com\/billstuart\/predictive-maintenance-ml-iiot)\n* [Turbofan Engine Degradation Simulation Data Set (NASA Ames)](https:\/\/ti.arc.nasa.gov\/tech\/dash\/groups\/pcoe\/prognostic-data-repository\/#turbofan)\n* [TobiasGlaubach\/python-ml-turbofan](https:\/\/github.com\/TobiasGlaubach\/python-ml-turbofan\/blob\/master\/Explorative_analysis.ipynb)","ede6e5d9":"## Quando \u00e9 que uma m\u00e1quina em funcionamento vai falhar?\n\nA quest\u00e3o que vamos resolver aqui \u00e9 \"Quando \u00e9 que uma m\u00e1quina em funcionamento vai falhar?\". Para suportar esta apresenta\u00e7\u00e3o vamos usar os dados da NASA, sobre motores de avi\u00e3o, dispon\u00edveis [este link](https:\/\/ti.arc.nasa.gov\/tech\/dash\/groups\/pcoe\/prognostic-data-repository\/#turbofan). Entretanto os m\u00e9todos que mostramos aqui s\u00e3o adapt\u00e1veis a diversas situa\u00e7\u00f5es nas quais dados de diversos sensores, no formato de s\u00e9ries temporais est\u00e3o dispon\u00edveis.\n\n<div style=\"text-align:center\">\n    <img alt=\"Pessoas Reparando um Motor de Avi\u00e3o\" src=\"https:\/\/www.imperial.ac.uk\/ImageCropToolT4\/imageTool\/uploaded-images\/jetEngineInspection--tojpeg_1449680951791_x2.jpg\" width=\"400px\"\/>\n    <font size=\"1\">Photo by [imperial.ac.uk](https:\/\/www.imperial.ac.uk\/non-destructive-evaluation\/research\/inspection-and-monitoring\/development-of-an-internal-robotic-inspection-system-for-jet-engines\/)<\/font>\n<\/div>\n\nH\u00e1 diversas fases envolvidas no processo de manuten\u00e7\u00e3o preventiva com an\u00e1lise de dados e machine learning. Desde a aquisi\u00e7\u00e3o dos dados \u00e0 o quais s\u00e3o as a\u00e7\u00f5es planejadas para fazermos dado uma situa\u00e7\u00e3o de aviso ou falha. Neste notebook, vamos considerar apenas a etapa de modelagem dos dados para responder \u00e0 pergunta acima com uma predi\u00e7\u00e3o com o tempo at\u00e9 a falha. Consideramos que os dados j\u00e1 foram capturados, e que os resultados do modelo ser\u00e3o usados da forma necess\u00e1ria. ","73def841":"Conforme consta no arquivo _readme.txt_:\n\n* S\u00e3o **4 datasets**, com **simula\u00e7\u00f5es com parametros variados**: 2 tipos de falha (s\u00f3 compressor, compressor e h\u00e9lice) e 2 tipos de condi\u00e7\u00f5es gerais (n\u00edvel do mar e outro)   \n* Os datasets **s\u00e3o s\u00e9ries de tempo** multivariadas.\n* Cada dataset \u00e9 dividido em subconjunto de **treino e teste**\n* Cada dataset \u00e9 de um motor diferente, mas **todos os motores s\u00e3o do mesmo tipo**.\n* Cada **motor inicia** varia\u00e7\u00f5es de desgate e manufatura que \u00e9 desconhecido pelo usu\u00e1rio, mas \u00e9 considerado **normal** (n\u00e3o \u00e9 considerado em uma condi\u00e7\u00e3o de falha).\n* Existem **tr\u00eas condi\u00e7\u00f5es operacionais** que tem grande impacto na performance do motor.\n* Os **dados est\u00e3o contaminados** com _sensor noise_.\n\nAinda:\n* Cada motor est\u00e1 operando normalmente no in\u00edcio da s\u00e9rie temporal e desenvolve uma falha em algum ponto da s\u00e9rie.\n* No conjunto de **treinamento a falha aumenta em magnitude at\u00e9 a falha do sistema**.\n* No conjunto de **teste a s\u00e9rie termina algum tempo antes da falha do sistema**.\n* Tamb\u00e9m s\u00e3o providos vetores com a vida \u00fatil restante (Remaining Useful Life, RUL) para o dado de teste.\n\n\nOs dados est\u00e3o em arquivos de texto com 26 colunas de n\u00fameros, separados por espa\u00e7os:\n\n* Cada linha \u00e9 uma 'foto' do dado tirada de uma vez, durante um \u00fanico ciclo operacional.\n* cada coluna \u00e9 uma vari\u00e1vel diferente, e correspondem \u00e0:\n<br\/>&nbsp;&nbsp;&nbsp;1. N\u00famero da unidade\n<br\/>&nbsp;&nbsp;&nbsp;2. Tempo, em ciclos\n<br\/>&nbsp;&nbsp;&nbsp;3. Setting operacional 1\n<br\/>&nbsp;&nbsp;&nbsp;4. Setting operacional 2\n<br\/>&nbsp;&nbsp;&nbsp;5. Setting operacional 3\n<br\/>&nbsp;&nbsp;&nbsp;6. Medida do sensor 1\n<br\/>&nbsp;&nbsp;&nbsp;7. Medida do sensor 2\n<br\/>&nbsp;&nbsp;&nbsp;...\n<br\/>&nbsp;&nbsp;&nbsp;26.\tMedida do sensor  26","a4326168":"Se n\u00e3o tirarmos as colunas constantes, elas aparecer\u00e3o cinza neste gr\u00e1fico.","09429d4f":"### Treinando uma LGBM para Regress\u00e3o","4a15833c":"### Treinando uma Regress\u00e3o Ridge","217619a1":"### Quais S\u00e3o os Dados?\n\nOs dados vieram do _CoE Prognostics_ da NASA Ames, e s\u00e3o resultados de simula\u00e7\u00f5es de degrada\u00e7\u00e3o de motores obtidos usando o C-MAPSS e podem ser obtidos a partir [deste link](https:\/\/ti.arc.nasa.gov\/tech\/dash\/groups\/pcoe\/prognostic-data-repository\/#turbofan).\n\nQuatro conjuntos de dados foram simulados em diferentes combina\u00e7\u00f5es de condi\u00e7\u00f5es operacionais e modos de falha.\n\nA evolu\u00e7\u00e3o at\u00e9 as falhas s\u00e3o caracterizadas a partir do registro de canais de sensores.\n\nA descri\u00e7\u00e3o de como estes dados foram obtidos est\u00e1 detalhada no artigo _\"Damage propagation modeling for aircraft engine run-to-failure simulation\"_ de Saxena, A. e colaboradores, publicado na _International Conference on Prognostics and Health Management_ em 2018, disponibilizado junto com o set de dados.","d8130a35":"### Treinando uma Regress\u00e3o Linear","2b6e8988":"## Engenharia de Features","36ba32a7":"# Manuten\u00e7\u00e3o Preventiva de Equipamentos\nby Peterson Katagiri Zilli <peterson.zilli@gmail.com>","a9c5ef80":"### Construindo e Validando o Modelo","f2e12715":"## Setup para An\u00e1lise","b263090a":"### Qual \u00e9 o Problema?\nO pedido inicial que chegou at\u00e9 n\u00f3s \u00e9 \"Quando \u00e9 que uma m\u00e1quina em funcionamento vai falhar?\".\nEntretanto, existem v\u00e1rias formas de reformular esta quest\u00e3o para que se tornem problemas de modelagem. Algumas delas s\u00e3o:\n* *Regress\u00e3o*: Predizer quanto tempo resta at\u00e9 a falha (_time to fail_) ou o tempo de vida \u00fatil (_remaining useful life_)\n* *Classifica\u00e7\u00e3o bin\u00e1ria*: Predizer se uma m\u00e1quina vai ou n\u00e3o falhar em alguma janela de tempo (1 janela de 10 dias, por exemplo)\n* *Classifica\u00e7\u00e3o multiclasse*: Dividir o tempo em $n$ janelas de tempo e predizer se a m\u00e1quina vai falhar em alguma delas ($n$ janelas de 10 dias, sequenciais, por exemplo).\n\nA escolha de qual destas que vamos entregar \u00e9 geralmente tomada de acordo com o contexto do problema, com os dados e o comportamento dos modelos sobre eles, com o conhecimento do cientista, com o setup que est\u00e1 dispon\u00edvel para a implanta\u00e7\u00e3o do modelo (o modelo tem que rodar l\u00e1 no avi\u00e3o ou vai rodar em um datacenter?), com outras v\u00e1riaveis que dependem do contexto todo do problema.\n\nEntender o problema \u00e9 mais do que s\u00f3 receber a pergunta.\n\nNota: Aqui, vamos supor prematuramente que o melhor setup para este experimento \u00e9 o de *regress\u00e3o* e vamos tomar o caminho de *predizer quanto tempo resta at\u00e9 a falha*.\nFazemos isso com o objetivo de deixar este exemplo o mais simples poss\u00edvel. Entretanto, na sua empresa, \u00e9 melhor que voc\u00ea escolha o setup baseado em resultados sobre os dados da sua aplica\u00e7\u00e3o real.  ","108421d4":"### Treinando uma Random Forest para Regress\u00e3o","51342409":"\u00c9 seguro assumir que todas as m\u00e1quinas do dataset tem estados e condi\u00e7\u00f5es iniciais similares, uma vez que os valores variam no m\u00e1ximo 1,4% entre as diferentes unidades."}}