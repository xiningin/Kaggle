{"cell_type":{"af5b00d3":"code","4c2bd4f8":"code","c1caf519":"code","65261b9b":"code","617061ad":"code","c6c195cf":"code","8c93a03f":"code","a19644d4":"code","20f96ffe":"code","39892700":"code","26110376":"code","ee0cad7d":"code","6dc87efa":"code","686f2642":"code","1ee862d3":"code","53849a26":"code","9b5e44b4":"code","1ede44f4":"code","c9382be9":"code","3dee00f2":"code","b724d228":"code","9d54177d":"code","7c15d86f":"code","638bd85a":"code","e3ffef56":"code","be43363d":"code","09c4e5d0":"code","df16f2d9":"markdown","3e61ae60":"markdown","2cc50f63":"markdown","c79140e9":"markdown","0572b6c9":"markdown","effd9f9e":"markdown","9d7d59fe":"markdown"},"source":{"af5b00d3":"#Clear memory\n%reset -f\n\n# Calling Libraries\n\n# Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Data manipulation library\nimport pandas as pd\nimport numpy as np\nimport re\nfrom scipy.stats import kurtosis, skew\n\n# Plotting library\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\n\n# Data transformation libraries\nfrom sklearn.preprocessing import StandardScaler as ss\nfrom sklearn.preprocessing import OneHotEncoder as onehot\nfrom sklearn.preprocessing import RobustScaler as rs\nfrom category_encoders import TargetEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Pipelines libraries\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer \nfrom sklearn.metrics import accuracy_score\n\n# 1.5 RandomForest modeling\nfrom sklearn.ensemble import RandomForestClassifier as rf\n\n# os related\nimport os","4c2bd4f8":"# Display multiple outputs from a jupyter cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","c1caf519":"# Set numpy options to display wide array\nnp.set_printoptions(precision = 3,          # Display upto 3 decimal places\n                    threshold=np.inf        # Display full array\n                    )","65261b9b":"# Seting display options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)","617061ad":"# os.chdir(\"E:\\HPS\\Finance & Accounts\\One time activity\\SS\\Python for analytics\\Class Notes & Recordings\\Class-18_26-07-20\\Assignment\")\n# os.listdir()","c6c195cf":"# Reading dataset\ndf_caravan = pd.read_csv(\"..\/input\/caravaninsurancechallenge\/caravan-insurance-challenge.csv\")","8c93a03f":"df_caravan.shape","a19644d4":"# Checking Null values in data set\ndf_caravan.info()","20f96ffe":"df_caravan.dtypes.value_counts()","39892700":"df_caravan.nunique()","26110376":"# Dropping object from the data set\ndf1 = df_caravan.drop([\"ORIGIN\"], axis = 1)\ndf1.head()","ee0cad7d":"#checking for column wise standard deviation and finding if std dev of any column is zero\n# And droping that column in case stddev is zero\ns = []\nfor i in df1.columns:\n    s.append(df1[i].std())  \n    \ns\n0 in s\n# None of the column has std dev zero","6dc87efa":"ct = pd.crosstab(df_caravan.ORIGIN, df_caravan.CARAVAN)\nct","686f2642":"ct.sum(0) # sum(0) for column wise sum and sum(1) for row wise sum ","1ee862d3":"# Splitting dataset\n\n#Training Data\ndf_train = df_caravan[df_caravan[\"ORIGIN\"]==\"train\"]\n#drop ORIGIN col from train_data\ndf_train.drop(['ORIGIN'],axis=1,inplace=True)\n\n#Testing Data\ndf_test = df_caravan[df_caravan[\"ORIGIN\"]==\"test\"]\n#drop ORIGIN col from test_data\ndf_test.drop(['ORIGIN'],axis=1,inplace=True)","53849a26":"df_train.head()\ndf_test.head()","9b5e44b4":"df_train['CARAVAN'].value_counts()","1ede44f4":"# Copy the target Column to a new variable and drop from the dataframe\n\ny = df_train.pop('CARAVAN')\ndf_train.head()\ny.head()","c9382be9":"df_train.describe()","3dee00f2":"df_test.describe()","b724d228":"# Both training & testing data set have matching properties","9d54177d":"# Create of numerical and Categorical columns\n\nnum_columns = df_train.columns[df_train.nunique() > 6]\ncat_columns = df_train.columns[df_train.nunique() <= 6]\nlen(num_columns)\nlen(cat_columns)","7c15d86f":"# Observing distribution\nplt.figure(figsize=(15,15))\nsns.distributions._has_statsmodels=False\n\nfor i in range(len(num_columns)):\n    abc = plt.subplot(11,5,i+1)\n    out = sns.distplot(df_train[num_columns[i]])\n    \nplt.tight_layout()","638bd85a":"# Column Transformer\nct = ColumnTransformer([\n                        ('rs',rs(),num_columns),\n                        ('onehot',onehot(handle_unknown='ignore'),cat_columns),\n                     ],\n    remainder=\"passthrough\"\n                    )\ndx = ct.fit_transform(df_train)\ndx[:5,:5]\nX = df_train","e3ffef56":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30)","be43363d":"pipe = Pipeline([('ct',ct),\n                 ('rf',rf())\n                 ])\npipe.fit(X_train, y_train)","09c4e5d0":"y_pred = pipe.predict(X_test)\nnp.sum(y_pred == y_test)\/len(y_test)","df16f2d9":"Create pipeline, apply Random Forest Classifier on the fit & transformed train data","3e61ae60":"# <font color=blue>Assignment:<\/font>\n### <font color = green>Identify potential purchasers of caravan insurance policies<\/font>\n\nThis data set used in the CoIL 2000 Challenge. It contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes.The data was collected to answer the following question: <br>\n#### <font color = orange>Can you predict who would be interested in buying a caravan insurance policy and give an explanation.<\/font>\n\nRandomForest technique is used here to develop a model to identify potential customers.\n\n<i> Note: Dataset, a single table, contains both train and test data. We will first separate the two to carry out the analysis.The first column 'ORIGIN' indicates which rows are 'train' and which are 'test'. After separating the two, we need to drop this column from both train and test data. The last column of the dataset 'CARAVAN' is the target column.<\/i>","2cc50f63":"Most of the variables has outliers.  \nWe will use robust scaler rather than a standard scaler num columns.  \nWe will use ohe for cat columns","c79140e9":"Split data in 70:30","0572b6c9":"### <font color=blue>Loading, Exploring & Cleaing Dataset:<\/font>","effd9f9e":"Pedict test data & find accuracy","9d7d59fe":"### <font color=blue>Observations:<\/font>\n1. Only 6% (586\/9822) of the population are TRUE POSITIVES.\n2. 94% (9236\/9822) of the population are TRUE NEGATIVES.\n3. There are no NULL data\n4. None of the columns have zero std dev \n5. Majority of the variables are categorical"}}