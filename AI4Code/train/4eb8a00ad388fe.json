{"cell_type":{"864beeed":"code","19e240b4":"code","a8bc37bb":"code","d559ff39":"code","9af00370":"code","a2bf5105":"code","3ef0f2a3":"code","8f003439":"code","273311d7":"code","9d19de8e":"code","05fdbd6e":"code","77328475":"code","70e87fff":"code","f2885e4d":"code","292bf75c":"code","1aff59a7":"code","d60c0e58":"code","b2066b56":"code","abb2a149":"code","9f301f93":"code","277e7041":"code","a871dadd":"code","1f891975":"code","7479a96d":"code","4f6999a0":"code","2146408b":"code","a0ca9a3f":"code","52a0a3eb":"code","68d9a338":"code","ea6efa33":"code","3b13d5e1":"code","5fd01265":"code","239fc8f7":"code","36f220c6":"code","0308b628":"code","6321799d":"code","6fea7ef4":"markdown","d778261e":"markdown","706c7e24":"markdown","9bae0e6d":"markdown","3ebc640b":"markdown"},"source":{"864beeed":"# IMPORTING ALL THE NECESSARY LIBRARIES AND PACKAGES\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport math\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV\n%matplotlib inline","19e240b4":"data = pd.read_csv('\/kaggle\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')","a8bc37bb":"data.head()","d559ff39":"data = data.drop('Unnamed: 0',1)","9af00370":"data.head()","a2bf5105":"# Number of Columns and rows\ndata.shape","3ef0f2a3":"#----------------------Basic Statistics and Data Types-------------------------#\n","8f003439":"# Information on counts, columns, column data types, memory usage, etc\ndata.info()","273311d7":"# Descriptive Statistics for all columns \ndata.describe(include='all')","9d19de8e":"# Descriptive Statistics for numeric columns \ndata.describe()","05fdbd6e":"# Column names\nprint(\"Column names:\")\nprint(data.columns)\n# Datatypes of each column\nprint(\"Datatype of each column:\")\nprint(data.dtypes)","77328475":"#Unique counts of records for each column\nprint(\"Unique Counts for each column:\")\nprint(data.nunique())","70e87fff":"# UNIQUE COUNTS OF NAN\/NULL EACH COLUMN\nprint(\"Unique Counts of nan\/null for each column:\")\nprint(data.isnull().sum())","f2885e4d":"#Remove nan\/null form review column \ndata = data.dropna(subset=['Review Text'])","292bf75c":"#-----------------------------'Review Text' Analysis along with Data visualization---------------------------#","1aff59a7":"data['Text_length'] = data['Review Text'].apply(len)\ndata.head()","d60c0e58":"Bar_plot = [\"Rating\",\"Recommended IND\"]\nadds = 0\nf, ax = plt.subplots(1,len(Bar_plot), figsize=(14,4), sharex=False)\nfor i in range(len(Bar_plot)):\n    sns.countplot(x=Bar_plot[adds], data=data,order=data[Bar_plot[adds]].value_counts().index, ax=ax[i])\n    ax[i].set_title(\"Histogram - Distribution for\\n{}\".format(Bar_plot[adds]))\n    ax[i].set_ylabel(\"Counts\")\n    ax[i].set_xlabel(\"{}\".format(Bar_plot[adds]))\n    adds += 1\nax[1].set_ylabel(\"\")\nplt.show()","b2066b56":"Bar_plot = [\"Division Name\",\"Department Name\"]\nadds = 0\nf, ax = plt.subplots(1,len(Bar_plot), figsize=(14,4), sharex=False)\nfor i in range(len(Bar_plot)):\n    sns.countplot(x=Bar_plot[adds], data=data,order=data[Bar_plot[adds]].value_counts().index, ax=ax[i])\n    ax[i].set_title(\"Histogram - Distribution for\\n{}\".format(Bar_plot[adds]))\n    ax[i].set_ylabel(\"Counts\")\n    ax[i].set_xlabel(\"{}\".format(Bar_plot[adds]))\n    adds += 1\nax[1].set_ylabel(\"\")\nplt.show()","abb2a149":"# Distribution Plot for 'Age'\nsns.distplot(data['Age'], color=\"red\")\nplt.show()\nsns.distplot(data['Recommended IND'], color=\"red\")\nplt.show()\n","9f301f93":"sns.jointplot(data=data,x='Age', y='Rating',kind='kde')","277e7041":"sns.jointplot(data=data,x='Age', y='Positive Feedback Count',kind='kde')","a871dadd":"#------------------------------Converting all the ratings into just 2 classes------------------------#\nclassification = [\n    (data['Rating'] <= 3),\n    (data['Rating'] > 3)]\nmeaning = ['Utmost_3','Greater_than_3']\ndata['Rating_Class'] = np.select(classification, meaning)","1f891975":"\n# if the rating are more than 3 stars then the Rating_Class_Ind is given as 1, or else if the stars \n# are less than or equal to 3 it is given as 0\n\ndata['Rating_Class_Ind'] = data['Rating_Class'].apply(lambda x: 0 if x=='Utmost_3' else 1)","7479a96d":"data.head()","4f6999a0":"#---------------------------Model Development-----------------------------------#","2146408b":"from wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom plotly import tools\nimport xgboost\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a0ca9a3f":"# Data Classification based on 'Rating_Class_Ind'\ndata_classes = data[(data['Rating_Class_Ind']==1) | (data['Rating_Class_Ind']==0)]\ndata_classes.head()\nprint(data_classes.shape)\n\n# Seperate the dataset into X and Y for prediction\nx = data_classes['Review Text']\ny = data_classes['Rating_Class_Ind']\nprint(x.head())\nprint(y.head())","52a0a3eb":"# Fucntion analyzer to remove stop words and non english words\ndef text_process(text):\n    nopunc = [char for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","68d9a338":"vocab = CountVectorizer(analyzer=text_process).fit(x)","ea6efa33":"# Sparse matrix from vocab for indicating each occurence of the word\nx = vocab.transform(x)","3b13d5e1":"# train and test split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)","5fd01265":"LR = LogisticRegression()\nLR.fit(x_train,y_train)\nLR_Pred = LR.predict(x_test)\nprint(\"Confusion Matrix for Logistic Regression:\")\nprint(confusion_matrix(y_test,LR_Pred))\nprint(\"Score: \",round(accuracy_score(y_test,LR_Pred)*100,2))\nprint(\"ROC_AUC Score:\", round(roc_auc_score(y_test,LR_Pred)*100,2))\nprint(\"Classification Report:\")\nprint(classification_report(y_test,LR_Pred))\nlr_cm=confusion_matrix(y_test.values, LR_Pred)\nplt.figure(figsize=(10,8))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\nplt.subplot(2,2,1)\nplt.title(\"Logistic Regression\")\nsns.heatmap(lr_cm, annot = True, cmap=\"Greens\",cbar=False);","239fc8f7":"xgb = XGBClassifier()\nxgb.fit(x_train,y_train)\npredxgb = xgb.predict(x_test)\nprint(\"Confusion Matrix for XGBoost Classifier:\")\nprint(confusion_matrix(y_test,predxgb))\nprint(\"Score: \",round(accuracy_score(y_test,predxgb)*100,2))\nprint(\"ROC_AUC Score:\", round(roc_auc_score(y_test,predxgb)*100,2))\nprint(\"Classification Report:\")\nprint(classification_report(y_test,predxgb))\nxgb_cm=confusion_matrix(y_test.values, predxgb)\nplt.figure(figsize=(10,8))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\nplt.subplot(2,2,1)\nplt.title(\"XGBoost Classifier\")\nsns.heatmap(xgb_cm, annot = True, cmap=\"Greens\",cbar=False);\n","36f220c6":"mlp = MLPClassifier()\nmlp.fit(x_train,y_train)\npredmlp = mlp.predict(x_test)\nprint(\"Confusion Matrix for Multilayer Perceptron Classifier:\")\nprint(confusion_matrix(y_test,predmlp))\nprint(\"Score:\",round(accuracy_score(y_test,predmlp)*100,2))\nprint(\"ROC_AUC Score:\", round(roc_auc_score(y_test,predmlp)*100,2))\nprint(\"Classification Report:\")\nprint(classification_report(y_test,predmlp))","0308b628":"mlp_cm=confusion_matrix(y_test.values, predmlp)\nplt.figure(figsize=(10,8))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\nplt.subplot(2,2,1)\nplt.title(\"MLP Classifier\")\nsns.heatmap(mlp_cm, annot = True, cmap=\"Greens\",cbar=False);","6321799d":"nb = MultinomialNB() \nnb.fit(x_train,y_train)\nprednb = nb.predict(x_test)\nprint(\"Confusion Matrix for MultinomialNB Classifier:\")\nprint(confusion_matrix(y_test,prednb))\nprint(\"Score: \",round(accuracy_score(y_test,prednb)*100,2))\nprint(\"ROC_AUC Score:\", round(roc_auc_score(y_test,prednb)*100,2))\nprint(\"Classification Report:\")\nprint(classification_report(y_test,prednb))\nnb_cm=confusion_matrix(y_test.values, prednb)\nplt.figure(figsize=(10,8))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\nplt.subplot(2,2,1)\nplt.title(\"MultinomialNB Classifier\")\nsns.heatmap(nb_cm, annot = True, cmap=\"Greens\",cbar=False);","6fea7ef4":"**Multinomial Naive Bayes Classifier**","d778261e":"**Multilayer Perceptron Classifier**","706c7e24":"Now we got that the majority of the reviewers are at the age of 25 to 65 (roughly).  ","9bae0e6d":"**XGBoost Classifier**","3ebc640b":"**Logistic Regression**"}}