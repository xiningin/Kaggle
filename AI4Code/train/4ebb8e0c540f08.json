{"cell_type":{"bf7d963a":"code","a5e1e442":"code","9316b559":"code","d59a5d62":"code","1fa64915":"code","6e9eb4ed":"code","a88e5f5d":"code","277e9673":"code","76f6f2cc":"code","b6db015c":"code","cb23615b":"code","93fba270":"code","2a0e052e":"code","170a2d05":"code","7f174c18":"code","19c7d213":"code","7b97f2b9":"code","df13200c":"code","2f1f989a":"code","2df1db83":"code","fdfa10a0":"code","fa2df962":"code","7eddb25a":"code","b4196da0":"code","53f57c6a":"code","9ddb9358":"code","fddbb3a0":"code","f6ba3766":"code","3983fffc":"code","5b1d951d":"code","d46992b5":"code","b7ed0562":"code","a307ffb2":"code","f5f4c5b7":"code","91232e33":"code","07beb948":"code","2f8fc78d":"code","67dcfa1c":"code","26316314":"code","fd963e6a":"code","dee2e408":"code","3bcfb0e8":"code","2a64c080":"code","d572b26c":"code","f9ea8ae0":"code","8f15448c":"code","4ff154b7":"code","41d9701e":"code","12b0a032":"code","ce86be40":"code","b0d5d809":"code","a20f9359":"code","9f4dd906":"code","ec55dd82":"code","809465e0":"code","f3a907f3":"code","3719fd46":"code","921c4664":"code","21f611ae":"code","ee932edb":"code","9203c7bf":"code","3fce0658":"code","b584cf3e":"code","8f6173f1":"code","7bb8356b":"code","2d985bc9":"code","5e59c2e7":"code","fb502cf8":"code","52aa767f":"code","4776768d":"code","10079ffe":"code","c6f573c9":"code","ec6c4c6e":"code","cf00050d":"code","6ae4da5c":"code","a05254d2":"code","aa208c82":"code","02a8c550":"markdown","3e2ef1f2":"markdown","649b9531":"markdown","f7b5c941":"markdown","4f4ccb22":"markdown","81add2cb":"markdown","2d8ab166":"markdown","69c88c83":"markdown","e40b8b9e":"markdown","6747619b":"markdown"},"source":{"bf7d963a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nprint(os.listdir(\"..\/input\"))","a5e1e442":"train_df = pd.read_csv('..\/input\/petfinder-adoption-prediction\/train\/train.csv')\ntrain_df.info()","9316b559":"test_df = pd.read_csv('..\/input\/petfinder-adoption-prediction\/test\/test.csv')\ntest_df.info()","d59a5d62":"train_df.head()","1fa64915":"breed_label = pd.read_csv('..\/input\/petfinder-adoption-prediction\/breed_labels.csv')\nbreed_label.head()","6e9eb4ed":"train_df['Mixed_Breed'] = train_df.apply(lambda x: 0 if x.Breed2==0 and x.Breed1!=307 else 1, axis=1)\ntest_df['Mixed_Breed'] = test_df.apply(lambda x: 0 if x.Breed2==0 and x.Breed1!=307 else 1, axis=1)","a88e5f5d":"color_label = pd.read_csv('..\/input\/petfinder-adoption-prediction\/color_labels.csv')\ncolor_label","277e9673":"train_df['Num_Color'] = train_df.apply(lambda x:  3-sum([y==0 for y in [x.Color1, x.Color2, x.Color3]]), axis=1)\ntest_df['Num_Color'] = test_df.apply(lambda x:  3-sum([y==0 for y in [x.Color1, x.Color2, x.Color3]]), axis=1)","76f6f2cc":"state_label = pd.read_csv('..\/input\/petfinder-adoption-prediction\/state_labels.csv')\nstate_label","b6db015c":"train_df['Description'].fillna(\"\", inplace=True)\ntest_df['Description'].fillna(\"\", inplace=True)","cb23615b":"train_df['Description_Length'] = train_df.Description.map(len)\ntest_df['Description_Length'] = test_df.Description.map(len)","93fba270":"plt.figure(figsize=(20,10))\nsns.boxplot(x='AdoptionSpeed', y='Description_Length', data=train_df, showfliers=False)","2a0e052e":"sentiment_list = os.listdir('..\/input\/petfinder-adoption-prediction\/train_sentiment')","170a2d05":"sentiment_list[0]","7f174c18":"example_text = pd.read_json('..\/input\/petfinder-adoption-prediction\/train_sentiment\/{}'.format(sentiment_list[1000]), orient='index', typ='series')","19c7d213":"example_text","7b97f2b9":"def get_desc_stats(desc_json):\n    example = pd.read_json('..\/input\/petfinder-adoption-prediction\/train_sentiment\/{}'.format(desc_json), orient='index', typ='series')\n    result = {}\n    \n    result['num_sentences'] = len(example.sentences)\n    result['num_entities'] = len(example.entities)\n    result['magnitude'] = example.documentSentiment['magnitude']\n    result['score'] = example.documentSentiment['score']\n    \n    return result","df13200c":"sentiment = {}\nfor x in sentiment_list:\n    sentiment[x[:9]] = get_desc_stats(x)","2f1f989a":"sentiment_df = pd.DataFrame.from_dict(sentiment).transpose()","2df1db83":"train_df = train_df.join(sentiment_df, on='PetID')","fdfa10a0":"train_df.magnitude.fillna(-1, inplace=True)\ntrain_df.score.fillna(-1, inplace=True)\ntrain_df.num_sentences.fillna(-1, inplace=True)\ntrain_df.num_entities.fillna(-1, inplace=True)","fa2df962":"sentiment_list_test = os.listdir('..\/input\/petfinder-adoption-prediction\/test_sentiment')\ndef get_desc_stats_test(desc_json):\n    example = pd.read_json('..\/input\/petfinder-adoption-prediction\/test_sentiment\/{}'.format(desc_json), orient='index', typ='series')\n    result = {}\n    \n    result['num_sentences'] = len(example.sentences)\n    result['num_entities'] = len(example.entities)\n    result['magnitude'] = example.documentSentiment['magnitude']\n    result['score'] = example.documentSentiment['score']\n    \n    return result\n\nsentiment_test = {}\nfor x in sentiment_list_test:\n    sentiment_test[x[:9]] = get_desc_stats_test(x)\nsentiment_df_test = pd.DataFrame.from_dict(sentiment_test).transpose()\ntest_df = test_df.join(sentiment_df_test, on='PetID')\ntest_df.magnitude.fillna(-1, inplace=True)\ntest_df.score.fillna(-1, inplace=True)\ntest_df.num_sentences.fillna(-1, inplace=True)\ntest_df.num_entities.fillna(-1, inplace=True)","7eddb25a":"from sklearn.feature_extraction.text import TfidfVectorizer","b4196da0":"import re\npattern = re.compile('[\\W_]+', re.UNICODE)\ntexts = [pattern.sub(' ', x) for x in train_df.Description]\ntexts_test = [pattern.sub(' ', x) for x in test_df.Description]","53f57c6a":"Tfidf = TfidfVectorizer(stop_words='english',ngram_range=(1,3), max_features=20000,max_df=0.95,min_df=5)","9ddb9358":"train_x_tfidf_full = Tfidf.fit_transform(texts)\ntest_x_tfidf = Tfidf.transform(texts_test)","fddbb3a0":"from sklearn.decomposition import TruncatedSVD","f6ba3766":"svd = TruncatedSVD(n_components=100, random_state=42)\ntrain_x_svd = svd.fit_transform(train_x_tfidf_full)","3983fffc":"train_df = train_df.join(pd.DataFrame(train_x_svd, columns=['svd_'+str(x) for x in np.arange(100)]))","5b1d951d":"test_x_svd = svd.transform(test_x_tfidf)\ntest_df = test_df.join(pd.DataFrame(test_x_svd, columns=['svd_'+str(x) for x in np.arange(100)]))","d46992b5":"from sklearn.feature_extraction.text import CountVectorizer","b7ed0562":"cv = CountVectorizer(stop_words='english',ngram_range=(1,3), max_features=20000,max_df=0.95,min_df=5)","a307ffb2":"train_x_cv = cv.fit_transform(texts)\ntest_x_cv = cv.transform(texts_test)","f5f4c5b7":"train_x_cv","91232e33":"# create a dataframe from a word matrix\ndef wm2df(wm, feat_names):\n    \n    # create an index for each row\n    \n    df = pd.DataFrame(data=wm.toarray(),\n                      columns=feat_names)\n    return(df)","07beb948":"# retrieve the terms found in the corpora\ntokens = cv.get_feature_names()\n\n# create a dataframe from the matrix\nwm2df(train_x_cv, tokens).head()","2f8fc78d":"svd_cv = TruncatedSVD(n_components=100, random_state=42)\ntrain_x_svd_cv = svd_cv.fit_transform(train_x_cv)\ntrain_df = train_df.join(pd.DataFrame(train_x_svd_cv, columns=['svd_cv_'+str(x) for x in np.arange(100)]))\ntest_x_svd_cv = svd_cv.transform(test_x_cv)\ntest_df = test_df.join(pd.DataFrame(test_x_svd_cv, columns=['svd_cv_'+str(x) for x in np.arange(100)]))","67dcfa1c":"train_df.head()","26316314":"def isChinese(s):\n    if len(re.findall(u'[\\u4e00-\\u9fff]', s)) > 0:\n        return 1\n    else:\n        return 0","fd963e6a":"train_df['contains_chinese'] = train_df.Description.map(isChinese)\ntest_df['contains_chinese'] = test_df.Description.map(isChinese)","dee2e408":"train_df.contains_chinese.value_counts()","3bcfb0e8":"photo_list = os.listdir('..\/input\/petfinder-adoption-prediction\/train_metadata')","2a64c080":"profile_photo = [x for x in photo_list if \"-1.\" in x]","d572b26c":"def get_dominant_color(photo_json):\n    example = pd.read_json('..\/input\/petfinder-adoption-prediction\/train_metadata\/{}'.format(photo_json), orient='index', typ='series')\n    max_index = np.argmax([x['pixelFraction'] for x in example.imagePropertiesAnnotation['dominantColors']['colors']])\n    result = example.imagePropertiesAnnotation['dominantColors']['colors'][max_index]['color']\n    result['score'] = example.imagePropertiesAnnotation['dominantColors']['colors'][max_index]['score']\n    result['pixelFraction'] = example.imagePropertiesAnnotation['dominantColors']['colors'][max_index]['pixelFraction']\n    try:\n        result['image_description'] = example.labelAnnotations[0]['description']\n        result['image_description_score'] = example.labelAnnotations[0]['score']\n        \n    except AttributeError:\n        result['image_description'] = -1\n        result['image_description_score'] = -1\n        \n    result['image_confidence'] = example.cropHintsAnnotation['cropHints'][0]['confidence']\n    try:\n        result['image_importanceFraction'] = example.cropHintsAnnotation['cropHints'][0]['importanceFraction']\n    except KeyError:\n        result['image_importanceFraction'] = -1\n    return result","f9ea8ae0":"dominant_color_train = {}\nfor x in profile_photo:\n    dominant_color_train[x[:9]] = get_dominant_color(x)","8f15448c":"dominant_color_df = pd.DataFrame(dominant_color_train).transpose()\ndominant_color_df.columns = ['photo_'+x for x in dominant_color_df.columns]\ntrain_df = train_df.join(dominant_color_df, on='PetID', rsuffix='_color')","4ff154b7":"train_df[pd.DataFrame(dominant_color_df).columns.tolist()] = train_df[pd.DataFrame(dominant_color_df).columns.tolist()].fillna(-1)","41d9701e":"photo_list_test = os.listdir('..\/input\/petfinder-adoption-prediction\/test_metadata')\nprofile_photo_test = [x for x in photo_list_test if \"-1.\" in x]\n\ndef get_dominant_color_test(photo_json):\n    example = pd.read_json('..\/input\/petfinder-adoption-prediction\/test_metadata\/{}'.format(photo_json), orient='index', typ='series')\n    max_index = np.argmax([x['pixelFraction'] for x in example.imagePropertiesAnnotation['dominantColors']['colors']])\n    result = example.imagePropertiesAnnotation['dominantColors']['colors'][max_index]['color']\n    result['score'] = example.imagePropertiesAnnotation['dominantColors']['colors'][max_index]['score']\n    result['pixelFraction'] = example.imagePropertiesAnnotation['dominantColors']['colors'][max_index]['pixelFraction']\n    try:\n        result['image_description'] = example.labelAnnotations[0]['description']\n        result['image_description_score'] = example.labelAnnotations[0]['score']\n        \n    except AttributeError:\n        result['image_description'] = -1\n        result['image_description_score'] = -1\n        \n    result['image_confidence'] = example.cropHintsAnnotation['cropHints'][0]['confidence']\n    try:\n        result['image_importanceFraction'] = example.cropHintsAnnotation['cropHints'][0]['importanceFraction']\n    except KeyError:\n        result['image_importanceFraction'] = -1\n    return result","12b0a032":"dominant_color_test = {}\nfor x in profile_photo_test:\n    dominant_color_test[x[:9]] = get_dominant_color_test(x)","ce86be40":"dominant_color_df_test = pd.DataFrame(dominant_color_test).transpose()\ndominant_color_df_test.columns = ['photo_'+x for x in dominant_color_df_test.columns]\ntest_df = test_df.join(dominant_color_df_test, on='PetID', rsuffix='_color')\n\ntest_df[pd.DataFrame(dominant_color_df_test).columns.tolist()] = test_df[pd.DataFrame(dominant_color_df_test).columns.tolist()].fillna(-1)","b0d5d809":"photo_image_description = {}\nfor i,x in enumerate(pd.concat([train_df.photo_image_description, test_df.photo_image_description]).value_counts().index):\n    photo_image_description[x] = i\n    \ntrain_df.photo_image_description = train_df.photo_image_description.map(lambda x: photo_image_description[x])\ntest_df.photo_image_description = test_df.photo_image_description.map(lambda x: photo_image_description[x])","a20f9359":"dog_cat = [photo_image_description[x] for x in ['dog',\n 'dog breed',\n 'dog like mammal',\n 'dog breed group',\n 'pug',\n 'bull terrier',\n 'siberian husky',\n 'beagle',\n 'street dog',\n 'boston terrier',\n 'pomeranian',\n 'harrier',\n 'czechoslovakian wolfdog',\n 'basset hound',\n 'volpino italiano']]","9f4dd906":"cat_cat = [photo_image_description[x] for x in ['cat',\n 'small to medium sized cats',\n 'cat like mammal',\n 'black cat']]","ec55dd82":"def main_category(x):\n    if x in dog_cat:\n        return 1\n    elif x in cat_cat:\n        return 2\n    elif x == photo_image_description[-1]:\n        return 0\n    else:\n        return 3","809465e0":"train_df['photo_category'] = train_df.photo_image_description.map(main_category)\ntest_df['photo_category'] = test_df.photo_image_description.map(main_category)","f3a907f3":"image_stat_train = pd.read_csv('..\/input\/image-statistics-for-petfinder\/train_image.csv')\nimage_stat_train.info()","3719fd46":"image_stat_test = pd.read_csv('..\/input\/image-statistics-for-petfinder\/test_image.csv')\nimage_stat_test.info()","921c4664":"image_stat_train['PetID'] = image_stat_train.image.map(lambda x: x[:9])\nimage_stat_test['PetID'] = image_stat_test.image.map(lambda x: x[:9])","21f611ae":"image_stat_train = image_stat_train.set_index('PetID')\nimage_stat_test = image_stat_test.set_index('PetID')","ee932edb":"train_df = train_df.join(image_stat_train, on='PetID', rsuffix='_image')\ntest_df = test_df.join(image_stat_test, on='PetID', rsuffix='_image')","9203c7bf":"import lightgbm as lgb","3fce0658":"train_df.columns","b584cf3e":"features = [x for x in train_df.columns if x not in ['Name', 'Type','RescuerID','AdoptionSpeed','Description','PetID','image','dullness_whiteness','temp_size','photo_image_description']]","8f6173f1":"df_train, df_val = train_test_split(train_df, test_size=0.3, random_state=420)","7bb8356b":"df_train.columns","2d985bc9":"from sklearn.metrics import cohen_kappa_score","5e59c2e7":"def kappa_scorer(pred, train_data):\n    length = len(train_data.get_label())\n    pred_results = [[pred[x], pred[x+length*1], pred[x+length*2], pred[x+length*3], pred[x+length*4]] for x in np.arange(length)]\n    \n    return 'kappa', cohen_kappa_score([np.argmax(x) for x in pred_results],train_data.get_label(), weights='quadratic'), True","fb502cf8":"d_train = lgb.Dataset(df_train[features], label=df_train['AdoptionSpeed'],feature_name=features, \n                      categorical_feature=['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'State','Mixed_Breed','photo_category','contains_chinese'])\nd_val = lgb.Dataset(df_val[features], label=df_val['AdoptionSpeed'], reference=d_train,feature_name=features, \n                    categorical_feature=['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'State', 'Mixed_Breed','photo_category','contains_chinese'])\n\nparams = {\"objective\" : \"multiclass\",\n              \"num_class\": 5,\n              \"metric\" : \"None\",\n              \"learning_rate\" : 0.1,\n              \"feature_fraction_seed\" : 420,          \n              \"feature_fraction\" : 0.4,\n              \"early_stopping_rounds\": 200\n             }\n\nevals_result = {}\nmodel = lgb.train(params, d_train, num_boost_round=2000, valid_sets=[d_train, d_val], feval=kappa_scorer, evals_result=evals_result, verbose_eval=50)","52aa767f":"d_train = lgb.Dataset(df_train[features], label=df_train['AdoptionSpeed'],feature_name=features, \n                      categorical_feature=['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'State','Mixed_Breed','photo_category','contains_chinese'])\n\ncv_dict = lgb.cv(params, d_train, num_boost_round=1000, feval=kappa_scorer, verbose_eval=50)","4776768d":"from sklearn.dummy import DummyClassifier\n\ndummy_model = DummyClassifier(random_state=1)\ndummy_model.fit(df_train[features], df_train['AdoptionSpeed'])\ncohen_kappa_score(dummy_model.predict(df_val[features]), df_val['AdoptionSpeed'])","10079ffe":"fig, ax = plt.subplots(figsize=(10,100))\nlgb.plot_importance(model, height=0.8, ax=ax)\nax.grid(False)\nplt.ylabel('Feature', size=12)\nplt.xlabel('Importance', size=12)\nplt.title(\"Importance of the Features of LightGBM Model\", fontsize=15)\nplt.show()","c6f573c9":"pred_test = model.predict(test_df[features], num_iteration=model.best_iteration)","ec6c4c6e":"submission = pd.concat([test_df.PetID,pd.DataFrame(pred_test, columns=['A','B','C','D','E'])],axis=1)","cf00050d":"submission['AdoptionSpeed'] = submission.apply(lambda x: np.argmax([x.A,x.B,x.C,x.D,x.E]), axis=1)","6ae4da5c":"submission = submission[['PetID','AdoptionSpeed']]\nsubmission.head()","a05254d2":"submission.to_csv('submission.csv',index=False)","aa208c82":"submission.AdoptionSpeed.value_counts()","02a8c550":"## Add Tfidf features","3e2ef1f2":"## Photo Metadata","649b9531":"Some missing values","f7b5c941":"## Image Statistics","4f4ccb22":"## Description Statistics","81add2cb":"## Description Sentiment","2d8ab166":"## LGB Model","69c88c83":"## Word Count statistics","e40b8b9e":"## Prediction","6747619b":"Some missing values"}}