{"cell_type":{"a11611d5":"code","beabd93b":"code","f77e87e2":"code","7e2670d0":"code","7d897e63":"code","203c8c7a":"code","61c2da9a":"code","2a17efe2":"code","78158820":"code","66d884f2":"code","addb1a36":"code","73a23c56":"code","513ecd0d":"code","a83c097f":"code","a4c919fd":"code","c1f2cd43":"code","e765cc39":"code","560f8e21":"code","ca459cb5":"code","ae6a2c4c":"code","f24058c2":"code","2219f34b":"code","9f749035":"code","5fe32c55":"code","1cd19488":"code","43ba014e":"code","4ddea4ea":"code","f128391d":"code","cdab0eb1":"code","731cfbc0":"code","27a20571":"code","50575b6e":"code","1bf312e6":"code","44d85ac1":"code","484b7e55":"code","fbb14979":"code","b798c4dd":"code","2f6db055":"code","9aeb23fe":"code","41109b9d":"code","5979817b":"code","e954841d":"code","2d73d4ac":"code","f98f0eec":"code","ec83c497":"code","3ebfda62":"code","15626043":"code","1264db57":"code","535d56a8":"code","474b296d":"code","ae48a630":"code","f8535bd2":"code","21e04ee8":"code","482a8a6b":"code","ebb6c525":"code","fa0fc12f":"code","26474777":"code","fdc3c827":"code","88eb5c23":"code","4654bc50":"code","aaafd51e":"code","ed53fb6f":"code","18791cf1":"code","96b9a303":"code","7fbea9e1":"code","1722be6f":"code","1d284eb0":"code","d24d65b7":"code","104bec8a":"code","5c06afb3":"code","4935dc4e":"code","0ccb577a":"code","543ba917":"code","0303ca14":"code","d1a8a179":"code","5f00b8b4":"code","b37273fe":"code","cdea0763":"code","6272e786":"code","e84fe5f1":"code","88637c4e":"code","b98c2dd5":"code","12c66afc":"code","8b646efd":"code","7bc29677":"code","99732eb8":"code","d3f2d8e6":"code","946e07b3":"code","92791e1b":"code","8d691370":"code","8340a241":"code","0d15bdbd":"code","9e6b4341":"code","83c113db":"code","f35c902f":"code","ad378a73":"code","04f49b56":"code","3efcd176":"markdown","d653874e":"markdown","1dee079e":"markdown","38aaeaef":"markdown","66a9c2d8":"markdown","5d168057":"markdown","64f04330":"markdown","e02c4a85":"markdown","54785f66":"markdown","40629fe8":"markdown","665a51c6":"markdown","dfada0aa":"markdown","b820d52d":"markdown","68aa0f91":"markdown","18d85386":"markdown","066fe042":"markdown","14150782":"markdown","e973b111":"markdown","cae2e27e":"markdown","934675d1":"markdown","b6cdb1e1":"markdown","6be48471":"markdown","96daf438":"markdown","44b0bf5f":"markdown","e0c7dbfa":"markdown","21474759":"markdown","367fc8ef":"markdown","4060f1ca":"markdown","eae1bc43":"markdown","412862ba":"markdown","2818f587":"markdown","dfbe2186":"markdown","ed429b81":"markdown","64f3c6c5":"markdown","a69c4df0":"markdown","3d3f95d3":"markdown","78743073":"markdown","c4d3bf33":"markdown","76847c36":"markdown","6ff9a295":"markdown","bc3b3ffc":"markdown","b1789b07":"markdown","0c8d7c6c":"markdown","9ccda752":"markdown","1a59a25f":"markdown","b939656e":"markdown","20a8ae21":"markdown","63cdca13":"markdown","9802b5e3":"markdown","dbb92eaa":"markdown","1e080e82":"markdown","c62e58d4":"markdown","d52a4cb8":"markdown","f6189527":"markdown","6a8217d5":"markdown","f43a979b":"markdown","a38e2a07":"markdown","47fba767":"markdown","adf73804":"markdown","92dd375a":"markdown","dcbe9554":"markdown","0b773cb8":"markdown"},"source":{"a11611d5":"import os\nimport gc\nimport random\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\n\nfrom datetime import datetime\nfrom scipy import sparse\nfrom scipy.sparse import csr_matrix\nfrom ipywidgets import interact\nfrom IPython.display import Image\n\n# Surprise Imports\nfrom surprise import Reader, Dataset\nfrom surprise import BaselineOnly \nfrom surprise import KNNBaseline\nfrom surprise import SVD\nfrom surprise import SVDpp\n\n# Scikit-Learn Imports\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Configuration\n# matplotlib.use('nbagg')\n# plt.rcParams.update({'figure.max_open_warning': 0})\nsns.set_style('whitegrid')","beabd93b":"# To find the running time of the entire notebook with the saved files\nglobalstart = datetime.now()","f77e87e2":"start = datetime.now()\nif not os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/data.csv'):\n    # Create a file 'data.csv' before reading it\n    # Read all the files in the dataset and store them in one big file ('data.csv')\n    # We're reading from each of the four files and appending each rating to a global file 'data.csv'\n    data = open('data.csv', mode='w')\n    \n    row = list()\n    files = [\n        '..\/input\/netflix-prize-data\/combined_data_1.txt',\n        '..\/input\/netflix-prize-data\/combined_data_2.txt', \n        '..\/input\/netflix-prize-data\/combined_data_3.txt', \n        '..\/input\/netflix-prize-data\/combined_data_4.txt'\n    ]\n    for file in files:\n        print(\"Reading ratings from {}\\n\".format(file))\n        with open(file) as f:\n            for line in f: \n                line = line.strip()\n                if line.endswith(':'):\n                    # All below are ratings for this movie, until another movie appears.\n                    movie_id = line.replace(':', '')\n                else:\n                    row = [x for x in line.split(',')]\n                    row.insert(0, movie_id)\n                    data.write(','.join(row))\n                    data.write('\\n')\n    data.close()\nprint('Time taken :', datetime.now() - start)","7e2670d0":"# print(\"Creating the dataframe from data.csv file\")\ndf = pd.read_csv('..\/input\/d\/elemento\/netflix-prize-data\/data.csv', sep=',', \n    names=['movie', 'user', 'rating', 'date'])\ndf.date = pd.to_datetime(df.date)\n\n# We are arranging the ratings according to time-stamp(s)\nprint('Sorting the dataframe by Date')\ndf.sort_values(by='date', inplace=True)\nprint('Done')","7d897e63":"df.head()","203c8c7a":"df.describe()['rating']","61c2da9a":"# Just to make sure that all Nan containing rows are deleted\nprint(\"No of Nan values in our dataframe: \", sum(df.isnull().any()))","2a17efe2":"# By considering all columns, including timestamp\ndup_bool = df.duplicated(['movie','user','rating'])\ndups = sum(dup_bool) \nprint(\"There are {} duplicate rating entries in the data\".format(dups))","78158820":"total_users = len(np.unique(df.user))\ntotal_movies = len(np.unique(df.movie))\n\nprint(\"Total No of Ratings:\", df.shape[0])\nprint(\"Total No of Users  :\", total_users)\nprint(\"Total No of movies :\", total_movies)\n\n# Removing the original dataframe from RAM\ndel df\ngc.collect()","66d884f2":"if not os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/train.csv'):\n    # Creating the separator\n    sep = int(df.shape[0] * 0.80)\n    # Create the dataframe and store it in the disk for offline purposes\n    train_df = df.iloc[:sep]\n    train_df.to_csv(\"train.csv\", index=False)\n\nif not os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/test.csv'):\n    # Creating the separator\n    sep = int(df.shape[0] * 0.80)\n    # Create the dataframe and store it in the disk for offline purposes\n    test_df = df.iloc[sep:]\n    test_df.to_csv(\"test.csv\", index=False)\n\ntrain_df = pd.read_csv(\"..\/input\/d\/elemento\/netflix-prize-data\/train.csv\", parse_dates = ['date'])\ntest_df = pd.read_csv(\"..\/input\/d\/elemento\/netflix-prize-data\/test.csv\")\n\n# Removing data.csv\ntry: os.remove(\"data.csv\")\nexcept: print(\"data.csv file is not there\")","addb1a36":"print(\"Total no of Ratings:\", train_df.shape[0])\nprint(\"Total No of Users  :\", len(np.unique(train_df.user)))\nprint(\"Total No of movies :\", len(np.unique(train_df.movie)))","73a23c56":"print(\"Total no of Ratings:\", test_df.shape[0])\nprint(\"Total No of Users  :\", len(np.unique(test_df.user)))\nprint(\"Total No of movies :\", len(np.unique(test_df.movie)))","513ecd0d":"# Method to make y-axis more readable\ndef human(num, units = 'M'):\n    units = units.lower()\n    num = float(num)\n    if units == 'k':\n        return str(num\/10**3) + \" K\"\n    elif units == 'm':\n        return str(num\/10**6) + \" M\"\n    elif units == 'b':\n        return str(num\/10**9) +  \" B\"","a83c097f":"fig, ax = plt.subplots(figsize = (10, 6))\nplt.title('Distribution of Ratings over Training Dataset', fontsize=15)\nsns.countplot(x = train_df.rating)\nticks_loc = ax.get_yticks().tolist()\nax.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\nax.set_yticklabels([human(item, 'M') for item in ax.get_yticks()])\nplt.xlabel('Ratings')\nplt.ylabel('Number of Ratings')\nplt.show()","a4c919fd":"# We will be calculating memory usage,so we will create a function to save some resources.\ndef mem_usage(pandas_obj):\n    if isinstance(pandas_obj, pd.DataFrame):\n        usage_b = pandas_obj.memory_usage(deep=True).sum()\n    # We assume if not a df it's a series\n    else:\n        usage_b = pandas_obj.memory_usage(deep=True)\n        \n    # Convert bytes to megabytes\n    usage_mb = usage_b \/ 1024 ** 2 \n    return \"{:03.2f} MB\".format(usage_mb)","c1f2cd43":"# Acquiring the day-name(s) & ratings for analysis.\nday_names = train_df.date.dt.day_name()\nratings = train_df['rating']\n\n# Need to clear the RAM in order to run the next few code cells\ndel train_df\ndel test_df\ngc.collect()","e765cc39":"fig, ax = plt.subplots(figsize = (12, 6))\nsns.countplot(x=day_names, ax=ax)\nplt.title('No of ratings on each day')\nplt.ylabel('Total no of Ratings')\nplt.xlabel('')\nticks_loc = ax.get_yticks().tolist()\nax.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\nax.set_yticklabels([human(item, 'M') for item in ax.get_yticks()])\nplt.show()","560f8e21":"start = datetime.now()\nfig = plt.figure(figsize = (12, 6))\nsns.boxplot(y=ratings, x=day_names)\nplt.show()\nprint(datetime.now() - start)","ca459cb5":"data = {\n    'day_of_week': day_names,\n    'rating': ratings\n}\n\ndel day_names\ndel ratings\ngc.collect()\n\ntemp_df = pd.DataFrame(data)\ndel data","ae6a2c4c":"avg_week_df = temp_df.groupby(by=['day_of_week'])['rating'].mean()\nprint(\"Average Ratings\")\nprint(\"-\"*30)\nprint(avg_week_df)\nprint(\"\\n\")","f24058c2":"# Removing the list from the RAM\ndel temp_df\ngc.collect()\n\n# Reloading the test and train dataframes in the RAM\ntrain_df = pd.read_csv(\"..\/input\/d\/elemento\/netflix-prize-data\/train.csv\", parse_dates = ['date'])\ntest_df = pd.read_csv(\"..\/input\/d\/elemento\/netflix-prize-data\/test.csv\")","2219f34b":"plt.figure(figsize = (10, 6))\nax = train_df.resample('m', on='date')['rating'].count().plot()\nax.set_title('No of Ratings\/Month (Training data)')\nplt.xlabel('Month')\nplt.ylabel('No of Ratings\/Month')\nticks_loc = ax.get_yticks().tolist()\nax.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\nax.set_yticklabels([human(item, 'M') for item in ticks_loc])\nplt.show()","9f749035":"no_of_rated_movies_per_user = train_df.groupby(by = 'user')['rating'].count().sort_values(ascending=False)\nno_of_rated_movies_per_user.head()","5fe32c55":"fig = plt.figure(figsize= (11, 5))\n\nax1 = plt.subplot(121)\nsns.kdeplot(no_of_rated_movies_per_user, shade=True, ax=ax1)\nplt.xlabel('No of ratings by user')\nplt.title(\"PDF\")\n\nax2 = plt.subplot(122)\nsns.kdeplot(no_of_rated_movies_per_user, shade=True, cumulative=True,ax=ax2)\nplt.xlabel('No of ratings by user')\nplt.title('CDF')\n\nplt.show()","1cd19488":"no_of_rated_movies_per_user.describe()","43ba014e":"quantiles = no_of_rated_movies_per_user.quantile(np.arange(0,1.01,0.01), interpolation='higher')","4ddea4ea":"plt.figure(figsize = (12, 6))\nplt.title(\"Quantiles and their Values\")\nquantiles.plot()\n\n# Quantiles with 0.05 difference\nplt.scatter(x=quantiles.index[::5], y=quantiles.values[::5], c='orange', \n    label=\"Quantiles with 0.05 intervals\")\n\n# Quantiles with 0.25 difference\nplt.scatter(x=quantiles.index[::25], y=quantiles.values[::25], c='m', \n    label=\"Quantiles with 0.25 intervals\")\n\nplt.ylabel('No of ratings by user')\nplt.xlabel('Value at the quantile')\nplt.legend(loc='best')\n\n# Annotate the 25th, 50th, 75th and 100th percentile values\nfor x,y in zip(quantiles.index[::25], quantiles[::25]):\n    plt.annotate(text=\"({} , {})\".format(x,y), xy=(x,y), xytext=(x-0.05, y+500), fontweight='bold')\n\nplt.show()","f128391d":"# Printing the Quantile values  \nprint(quantiles[::5])\nprint('\\nNo of ratings at last 5 percentile : {}\\n'.format(sum(no_of_rated_movies_per_user>= 749)))\n\n# From the below numbers, we can see that 5% of our users, have rated more than 749 movies\n# And this is a pretty huge number. We will leverage this and other similar kind of conclusions\n# while performing feature engineering. ","cdab0eb1":"no_of_ratings_per_movie = train_df.groupby(by='movie')['rating'].count().sort_values(ascending=False)\n\nfig = plt.figure(figsize = (12, 6))\nax = plt.gca()\nplt.plot(no_of_ratings_per_movie.values)\nplt.title('# Ratings\/Movie')\nplt.xlabel('Movie')\nplt.ylabel('No of Users who rated a movie')\nax.set_xticklabels([])\n\nplt.show()","731cfbc0":"start = datetime.now()\nif os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/train_sparse_matrix.npz'):\n    print(\"It is present in your pwd, getting it from the disk!\")\n    train_sparse_matrix = sparse.load_npz('..\/input\/d\/elemento\/netflix-prize-data\/train_sparse_matrix.npz')\n    print(\"Done\")\nelse: \n    print(\"We are creating sparse_matrix from the dataframe!\")\n    # Create sparse_matrix and store it for after usage.\n    # csr_matrix(data_values, (row_index, col_index), shape_of_matrix)\n    # It should be in such a way that, MATRIX[row, col] = data\n    train_sparse_matrix = sparse.csr_matrix((\n        train_df.rating.values, (train_df.user.values,train_df.movie.values)\n    ))\n    \n    print('Done. It\\'s shape is : (user, movie) : ',train_sparse_matrix.shape)\n    print('Saving it into disk for furthur usage!')\n    sparse.save_npz(\"train_sparse_matrix.npz\", train_sparse_matrix)\n    print('Done\\n')\nprint(datetime.now() - start)","27a20571":"# The Sparsity of Train Sparse Matrix\nus,mv = train_sparse_matrix.shape\nelem = train_sparse_matrix.count_nonzero()\nprint(\"Sparsity of Train Matrix: {} % \".format(  (1-(elem\/(us*mv))) * 100) )","50575b6e":"start = datetime.now()\nif os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/test_sparse_matrix.npz'):\n    print(\"It is present in your pwd, getting it from disk!\")\n    test_sparse_matrix = sparse.load_npz('..\/input\/d\/elemento\/netflix-prize-data\/test_sparse_matrix.npz')\n    print(\"Done\")\nelse: \n    print(\"We are creating sparse_matrix from the dataframe!\")\n    # Create sparse_matrix and store it for after usage.\n    # csr_matrix(data_values, (row_index, col_index), shape_of_matrix)\n    # It should be in such a way that, MATRIX[row, col] = data\n    test_sparse_matrix = sparse.csr_matrix(\n        (test_df.rating.values, (test_df.user.values, test_df.movie.values))\n    )\n    \n    print('Done. It\\'s shape is : (user, movie) : ',test_sparse_matrix.shape)\n    print('Saving it into disk for furthur usage!')\n    sparse.save_npz(\"test_sparse_matrix.npz\", test_sparse_matrix)\n    print('Done\\n')\nprint(datetime.now() - start)","1bf312e6":"# The Sparsity of Test data Matrix\nus,mv = test_sparse_matrix.shape\nelem = test_sparse_matrix.count_nonzero()\nprint(\"Sparsity of Test Matrix : {} % \".format(  (1-(elem\/(us*mv))) * 100) )","44d85ac1":"# Get the user averages in dictionary (key: user_id\/movie_id, value: avg rating)\ndef get_average_ratings(sparse_matrix, of_users):\n    # Average ratings of user\/movies\n    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    # Boolean matrix of ratings (whether a user rated that movie or not)\n    is_rated = (sparse_matrix != 0)\n    # No of ratings for each user\/movie\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    # max_user and max_movie ids in sparse matrix \n    u, m = sparse_matrix.shape\n    # Create a dictonary of users and their average ratings\n    average_ratings = {i : sum_of_ratings[i] \/ no_of_ratings[i]\n         for i in range(u if of_users else m) if no_of_ratings[i] != 0}\n\n    # Return that dictionary of average ratings\n    return average_ratings","484b7e55":"train_averages = dict()\ntrain_global_average = train_sparse_matrix.sum()\/train_sparse_matrix.count_nonzero()\ntrain_averages['global'] = train_global_average\nprint(train_averages)","fbb14979":"train_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)\nprint('\\nAverage rating of user 10:',train_averages['user'][10])","b798c4dd":"train_averages['movie'] =  get_average_ratings(train_sparse_matrix, of_users=False)\nprint('\\n Average rating of movie 15:',train_averages['movie'][15])","2f6db055":"start = datetime.now()\n\n# Draw PDfs for average rating per user and average\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\nfig.suptitle('Avg Ratings per User and per Movie', fontsize=15)\n\n# Get the list of average user ratings from the averages dictionary\nax1.set_title('Users-Avg-Ratings')\nuser_averages = [rat for rat in train_averages['user'].values()]\nsns.kdeplot(user_averages, ax=ax1, cumulative=True, label='CDF')\nsns.kdeplot(user_averages, ax=ax1, label='PDF')\n\n# Get the list of movie_average_ratings from the dictionary\nax2.set_title('Movies-Avg-Rating')\nmovie_averages = [rat for rat in train_averages['movie'].values()]\nsns.kdeplot(movie_averages, ax=ax2, cumulative=True, label='CDF')\nsns.kdeplot(movie_averages, ax=ax2, label='PDF')\n\nplt.show()\nprint(datetime.now() - start)","9aeb23fe":"users_train = len(train_averages['user'])\nnew_users = total_users - users_train\n\nprint('\\nTotal number of Users:', total_users)\nprint('Number of Users in Train data:', users_train)\nprint(\"Number of Users that didn't appear in train data: {} ({} %) \\n \".format(new_users,\n    np.round((new_users\/total_users)*100, 2)))\n\nmovies_train = len(train_averages['movie'])\nnew_movies = total_movies - movies_train\n\nprint('\\nTotal number of Movies  :', total_movies)\nprint('Number of Users in Train data :', movies_train)\nprint(\"Number of Movies that didn't appear in train data: {} ({} %)\".format(new_movies,\n    np.round((new_movies\/total_movies)*100, 2)))","41109b9d":"# Need to clear the RAM in order to run the next few code cells\ndel train_df\ndel test_df\ngc.collect()","5979817b":"def compute_user_similarity(sparse_matrix, compute_for_few=False, top = 100, verbose=False, \n    verb_for_n_rows = 20, draw_time_taken=True):\n    no_of_users, _ = sparse_matrix.shape\n    # Get the indices of  non-zero rows (users) from our sparse matrix\n    row_ind, col_ind = sparse_matrix.nonzero()\n    # Sorting is not necessary\n    row_ind = sorted(set(row_ind))\n    # Time taken for finding similar users for an user\n    time_taken = list() \n    \n    # We create rows, cols, and data lists, that can be used to create sparse matrices.\n    rows, cols, data = list(), list(), list()\n    if verbose: print(\"Computing top\", top, \" similar users for each user\")\n    \n    start = datetime.now()\n    temp = 0\n    \n    for row in row_ind[:top] if compute_for_few else row_ind:\n        temp = temp+1\n        prev = datetime.now()\n        \n        # Get the similarity row for this user with all other users\n        sim = cosine_similarity(sparse_matrix.getrow(row), sparse_matrix).ravel()\n        # We will get only the top ''top'' most similar users and ignore the rest of them.\n        top_sim_ind = sim.argsort()[-top:]\n        top_sim_val = sim[top_sim_ind]\n        \n        # Add them to our rows, cols and data\n        rows.extend([row]*top)\n        cols.extend(top_sim_ind)\n        data.extend(top_sim_val)\n        time_taken.append(datetime.now().timestamp() - prev.timestamp())\n        if verbose:\n            if temp%verb_for_n_rows == 0:\n                print(\"Computing done for {} users [  time elapsed : {}  ]\"\n                      .format(temp, datetime.now()-start))\n            \n    # Let's create a sparse matrix out of these and return it\n    if verbose: print('Creating Sparse matrix from the computed similarities')\n    \n    if draw_time_taken:\n        plt.plot(time_taken, label = 'Time taken for each user')\n        plt.plot(np.cumsum(time_taken), label='Total time')\n        plt.legend(loc='best')\n        plt.xlabel('User')\n        plt.ylabel('Time (seconds)')\n        plt.show()\n        \n    return sparse.csr_matrix((data, (rows, cols)), shape=(no_of_users, no_of_users)), time_taken      ","e954841d":"start = datetime.now()\nu_u_sim_sparse, _ = compute_user_similarity(train_sparse_matrix, compute_for_few=True, top = 100,\n    verbose=True)\nprint(\"Time taken:\", datetime.now()-start)","2d73d4ac":"# gc.collect()\n# start = datetime.now()\n\n# # Initialize the algorithm with some parameters..\n# # All of them are default except n_components. n_itr is for Randomized SVD solver.\n# netflix_svd = TruncatedSVD(n_components=500, algorithm='randomized', random_state=15)\n# trunc_svd = netflix_svd.fit_transform(train_sparse_matrix)\n\n# print(datetime.now()-start)","f98f0eec":"# expl_var = np.cumsum(netflix_svd.explained_variance_ratio_)","ec83c497":"# fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(.5))\n\n# ax1.set_ylabel(\"Variance Explained\", fontsize=15)\n# ax1.set_xlabel(\"# Latent Facors\", fontsize=15)\n# ax1.plot(expl_var)\n\n# # Annote some (latentfactors, expl_var) to make it clear\n# ind = [1, 2, 4, 8, 20, 60, 100, 200, 300, 400, 500]\n# ax1.scatter(x = [i-1 for i in ind], y = expl_var[[i-1 for i in ind]], c='#ff3300')\n# for i in ind:\n#     ax1.annotate(s =\"({}, {})\".format(i,  np.round(expl_var[i-1], 2)), xy=(i-1, expl_var[i-1]),\n#         xytext = (i+20, expl_var[i-1] - 0.01), fontweight='bold')\n\n# change_in_expl_var = [expl_var[i+1] - expl_var[i] for i in range(len(expl_var)-1)]\n# ax2.plot(change_in_expl_var)\n# ax2.set_ylabel(\"Gain in Var_Expl with One Additional LF\", fontsize=10)\n# ax2.yaxis.set_label_position(\"right\")\n# ax2.set_xlabel(\"# Latent Facors\", fontsize=20)\n\n# plt.show()","3ebfda62":"# for i in ind:\n#     print(\"({}, {})\".format(i, np.round(expl_var[i-1], 2)))","15626043":"# # Let's project our Original U_M matrix into into 500 Dimensional space\n# start = datetime.now()\n# trunc_matrix = train_sparse_matrix.dot(netflix_svd.components_.T)\n# print(datetime.now()- start)\n# print(type(trunc_matrix), trunc_matrix.shape)","1264db57":"# Let's convert this to actual sparse matrix and store it for future purposes\nif not os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/trunc_sparse_matrix.npz'):\n    # Create that sparse matrix\n    trunc_sparse_matrix = sparse.csr_matrix(trunc_matrix)\n    # Save this truncated sparse matrix for later usage\n    sparse.save_npz('trunc_sparse_matrix', trunc_sparse_matrix)\nelse:\n    trunc_sparse_matrix = sparse.load_npz('..\/input\/d\/elemento\/netflix-prize-data\/trunc_sparse_matrix.npz')\n    \nprint(trunc_sparse_matrix.shape)","535d56a8":"gc.collect()\nstart = datetime.now()\ntrunc_u_u_sim_matrix, _ = compute_user_similarity(trunc_sparse_matrix, compute_for_few=True, top=50, \n      verbose=True, verb_for_n_rows=10)\nprint(\"Time:\",datetime.now()-start)","474b296d":"# Freeing up the RAM\ndel u_u_sim_sparse\ndel trunc_sparse_matrix\ndel trunc_u_u_sim_matrix\ndel _\ngc.collect()","ae48a630":"start = datetime.now()\nif not os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/m_m_sim_sparse.npz'):\n    print(\"It seems you don't have that file. Computing movie_movie similarity\")\n    start = datetime.now()\n    m_m_sim_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output=False)\n    print(\"Done\")\n    # Store this sparse matrix in disk before using it. For future purposes.\n    print(\"Saving it to disk without the need of re-computing it again\")\n    sparse.save_npz(\"m_m_sim_sparse.npz\", m_m_sim_sparse)\n    print(\"Done\")\nelse:\n    m_m_sim_sparse = sparse.load_npz(\"..\/input\/d\/elemento\/netflix-prize-data\/m_m_sim_sparse.npz\")\n    print(\"Done\")\n\nprint(\"It's a \", m_m_sim_sparse.shape,\" dimensional matrix\")\nprint(datetime.now() - start)","f8535bd2":"movie_ids = np.unique(m_m_sim_sparse.nonzero()[1])","21e04ee8":"start = datetime.now()\nsimilar_movies = dict()\nfor movie in movie_ids:\n    # Get the top similar movies and store them in the dictionary\n    sim_movies = m_m_sim_sparse[movie].toarray().ravel().argsort()[::-1][1:]\n    similar_movies[movie] = sim_movies[:100]\nprint(datetime.now() - start)\n\n# Just testing similar movies for movie_15\nsimilar_movies[15]","482a8a6b":"# First let's load the movie details into soe dataframe\n# Movie details are in 'netflix\/movie_titles.csv'\n\nmovie_titles = pd.read_csv(\"..\/input\/netflix-prize-data\/movie_titles.csv\", sep=',', header = None,\n    names=['movie_id', 'year_of_release', 'title'], verbose=True, index_col = 'movie_id', encoding = \"ISO-8859-1\")\nmovie_titles.head()","ebb6c525":"# Similar Movies for 'Vampire Journals'\nmv_id = 67\nprint(\"Movie - \", movie_titles.loc[mv_id].values[1])\nprint(\"It has {} ratings from users.\".format(train_sparse_matrix[:,mv_id].getnnz()))\nprint(\"We have {} movies which are similar to this  and we will get only top most\".format(m_m_sim_sparse[:,mv_id].getnnz()))","fa0fc12f":"similarities = m_m_sim_sparse[mv_id].toarray().ravel()\nsimilar_indices = similarities.argsort()[::-1][1:]\nsimilarities[similar_indices]\n\n# It will sort and reverse the array and ignore its similarity (ie.,1) \n# and return it's indices(movie_ids)\nsim_indices = similarities.argsort()[::-1][1:] ","26474777":"plt.plot(similarities[sim_indices], label='All the ratings')\nplt.plot(similarities[sim_indices[:100]], label='top 100 similar movies')\nplt.title(\"Similar Movies of {}(movie_id)\".format(mv_id), fontsize=20)\nplt.xlabel(\"Movies (Not Movie_Ids)\", fontsize=15)\nplt.ylabel(\"Cosine Similarity\",fontsize=15)\nplt.legend()\nplt.show()","fdc3c827":"# Top 10 similar movies\nmovie_titles.loc[sim_indices[:10]]\n\n# Similarly, we can ___find similar users___ and compare how similar they are. ","88eb5c23":"Image(\"..\/input\/d\/elemento\/netflix-prize-data\/images\/models.jpg\")","4654bc50":"def get_sample_sparse_matrix(sparse_matrix, no_users, no_movies, path, verbose = True):\n    \"\"\"\n    It will get it from the ''path'' if it is present  or it will create \n    and store the sampled sparse matrix in the path specified.\n    \"\"\"\n    \n    # Get (row, col) and (rating) tuple from sparse_matrix.\n    row_ind, col_ind, ratings = sparse.find(sparse_matrix)\n    users = np.unique(row_ind)\n    movies = np.unique(col_ind)\n\n    print(\"Original Matrix: (users, movies) -- ({} {})\".format(len(users), len(movies)))\n    print(\"Original Matrix: Ratings -- {}\\n\".format(len(ratings)))\n\n    # It's just to make sure to get same sample everytime we run this program & pick without replacement\n    np.random.seed(15)\n    sample_users = np.random.choice(users, no_users, replace=False)\n    sample_movies = np.random.choice(movies, no_movies, replace=False)\n    \n    # Get the boolean mask of these sampled_items in originl row\/col_inds.\n    mask = np.logical_and(np.isin(row_ind, sample_users), np.isin(col_ind, sample_movies))\n    \n    sample_sparse_matrix = sparse.csr_matrix((ratings[mask], (row_ind[mask], col_ind[mask])),\n         shape=(max(sample_users)+1, max(sample_movies)+1))\n\n    if verbose:\n        print(\"Sampled Matrix : (users, movies) -- ({} {})\".format(len(sample_users), len(sample_movies)))\n        print(\"Sampled Matrix : Ratings --\", format(ratings[mask].shape[0]))\n\n    print('Saving it into disk for furthur usage!')\n    # save it into disk\n    sparse.save_npz(path, sample_sparse_matrix)\n    if verbose:\n            print('Done')\n    \n    return sample_sparse_matrix","aaafd51e":"start = datetime.now()\npath = \"..\/input\/d\/elemento\/netflix-prize-data\/sample_train_sparse_matrix.npz\"\nif os.path.isfile(path):\n    print(\"It is present in your pwd, getting it from disk!\")\n    # Just get it from the disk instead of computing it\n    sample_train_sparse_matrix = sparse.load_npz(path)\n    print(\"Done\")\nelse: \n    # Get 10k users and 1k movies from available data \n    sample_train_sparse_matrix = get_sample_sparse_matrix(train_sparse_matrix, no_users=10000, \n        no_movies=1000, path = path)\nprint(datetime.now() - start)","ed53fb6f":"start = datetime.now()\npath = \"..\/input\/d\/elemento\/netflix-prize-data\/sample_test_sparse_matrix.npz\"\nif os.path.isfile(path):\n    print(\"It is present in your pwd, getting it from disk!\")\n    # Just get it from the disk instead of computing it\n    sample_test_sparse_matrix = sparse.load_npz(path)\n    print(\"Done\")\nelse:\n    # Get 5k users and 500 movies from available data \n    sample_test_sparse_matrix = get_sample_sparse_matrix(test_sparse_matrix, no_users=5000, \n        no_movies=500, path = path)\nprint(datetime.now() - start)","18791cf1":"sample_train_averages = dict()","96b9a303":"# Get the global average of ratings in our train set.\nglobal_average = sample_train_sparse_matrix.sum()\/sample_train_sparse_matrix.count_nonzero()\nsample_train_averages['global'] = global_average\nprint(sample_train_averages)","7fbea9e1":"sample_train_averages['user'] = get_average_ratings(sample_train_sparse_matrix, of_users=True)\nprint('Average rating of user 1515220:', sample_train_averages['user'][1515220])","1722be6f":"sample_train_averages['movie'] =  get_average_ratings(sample_train_sparse_matrix, of_users=False)\nprint('Average rating of movie 15153:', sample_train_averages['movie'][15153])","1d284eb0":"print('No of ratings in Our Sampled train matrix is : {}\\n'.format(sample_train_sparse_matrix.count_nonzero()))\nprint('No of ratings in Our Sampled test  matrix is : {}\\n'.format(sample_test_sparse_matrix.count_nonzero()))","d24d65b7":"# Get users, movies and ratings from our samples train sparse matrix\nsample_train_users, sample_train_movies, sample_train_ratings = sparse.find(sample_train_sparse_matrix)","104bec8a":"start = datetime.now()\nif os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/reg_train.csv'):\n    print(\"File already exists you don't have to prepare again!\")\nelse:\n    print('Preparing {} tuples for the dataset'.format(len(sample_train_ratings)))\n    with open('reg_train.csv', mode='w') as reg_data_file:\n        count = 0\n        for (user, movie, rating)  in zip(sample_train_users, sample_train_movies, sample_train_ratings):\n            st = datetime.now()\n            # =============================================\n            # Ratings of \"movie\" by similar users of \"user\"\n            # =============================================\n            \n            # Compute the similar Users of the \"user\"        \n            user_sim = cosine_similarity(sample_train_sparse_matrix[user], sample_train_sparse_matrix).ravel()\n            # We are ignoring 'The User' from its similar users\n            top_sim_users = user_sim.argsort()[::-1][1:] \n            # Get the ratings of most similar users for this movie\n            top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n            # We will make it's length \"5\" by adding movie averages to the rest of the cells.\n            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n\n            # ==============================================\n            # Ratings by \"user\"  to similar movies of \"movie\"\n            # ==============================================\n            \n            # Compute the similar movies of the \"movie\"        \n            movie_sim = cosine_similarity(sample_train_sparse_matrix[:,movie].T, sample_train_sparse_matrix.T).ravel()\n            # We are ignoring 'The Movie' from its similar movies.\n            top_sim_movies = movie_sim.argsort()[::-1][1:] \n            # Get the ratings of most similar movie rated by this user\n            top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n            # We will make it's length \"5\" by adding user averages to the rest of the cells\n            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n    \n            # ======================================\n            # Prepare the row to be stores in a file\n            # ======================================\n            \n            row = list()\n            row.append(user)\n            row.append(movie)\n            # Now add the other features to this data; First Feature\n            row.append(sample_train_averages['global']) \n            # Next 5 features are similar_users \"movie\" ratings\n            row.extend(top_sim_users_ratings)\n            # Next 5 features are \"user\" ratings for similar_movies\n            row.extend(top_sim_movies_ratings)\n            # Avg_user rating\n            row.append(sample_train_averages['user'][user])\n            # Avg_movie rating\n            row.append(sample_train_averages['movie'][movie])\n\n            # Finally, the actual rating of this user-movie pair\n            row.append(rating)\n            count = count + 1\n\n            # Add rows to the file opened\n            reg_data_file.write(','.join(map(str, row)))\n            reg_data_file.write('\\n')        \n            if (count)%10000 == 0:\n                print(\"Done for {} rows - {}\".format(count, datetime.now() - start))\n\nprint(datetime.now() - start)","5c06afb3":"# Reading from the file to make a Train_dataframe\nreg_train = pd.read_csv('..\/input\/d\/elemento\/netflix-prize-data\/reg_train.csv', names = ['user', 'movie', 'GAvg', 'sur1', \n    'sur2', 'sur3', 'sur4', 'sur5','smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating'], \n    header=None\n)\nreg_train.head()","4935dc4e":"# Get users, movies and ratings from the Sampled Test \nsample_test_users, sample_test_movies, sample_test_ratings = sparse.find(sample_test_sparse_matrix)","0ccb577a":"sample_train_averages['global']","543ba917":"start = datetime.now()\nif os.path.isfile('..\/input\/d\/elemento\/netflix-prize-data\/reg_test.csv'):\n    print(\"It is already created!\")\nelse:\n    print('Preparing {} tuples for the dataset..\\n'.format(len(sample_test_ratings)))\n    with open('reg_test.csv', mode='w') as reg_data_file:\n        count = 0 \n        for (user, movie, rating)  in zip(sample_test_users, sample_test_movies, sample_test_ratings):\n            st = datetime.now()\n            # =============================================\n            # Ratings of \"movie\" by similar users of \"user\"\n            # =============================================\n            \n            try:\n                # Compute the similar Users of the \"user\"        \n                user_sim = cosine_similarity(sample_train_sparse_matrix[user], sample_train_sparse_matrix).ravel()\n                # We are ignoring 'The User' from its similar users.\n                top_sim_users = user_sim.argsort()[::-1][1:] \n                # Get the ratings of most similar users for this movie\n                top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n                # We will make it's length \"5\" by adding movie averages to .\n                top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n                top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n\n            except (IndexError, KeyError):\n                # It is a new User or new Movie or there are no ratings for given user for top similar movies\n                # Cold STart Problem\n                top_sim_users_ratings.extend([sample_train_averages['global']]*(5 - len(top_sim_users_ratings)))\n            except:\n                # We just want KeyErrors to be resolved. Not every Exception...\n                print(user, movie)\n                raise\n\n            # ==============================================\n            # Ratings by \"user\"  to similar movies of \"movie\"\n            # ==============================================\n\n            try:\n                # Compute the similar movies of the \"movie\"        \n                movie_sim = cosine_similarity(sample_train_sparse_matrix[:,movie].T, sample_train_sparse_matrix.T).ravel()\n                # We are ignoring 'The Movie' from its similar movies.\n                top_sim_movies = movie_sim.argsort()[::-1][1:] \n                # Get the ratings of most similar movie rated by this user\n                top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n                # We will make it's length \"5\" by adding user averages to the rest of the cells\n                top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n                top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n            except (IndexError, KeyError):\n                top_sim_movies_ratings.extend([sample_train_averages['global']]*(5-len(top_sim_movies_ratings)))\n            except :\n                raise\n\n            # =======================================\n            # Prepare the row to be stores in a file\n            # =======================================\n            \n            row = list()\n            # Add user and movie name first\n            row.append(user)\n            row.append(movie)\n            # First feature\n            row.append(sample_train_averages['global']) \n            # Next 5 features are similar_users \"movie\" ratings\n            row.extend(top_sim_users_ratings)\n            # Next 5 features are \"user\" ratings for similar_movies\n            row.extend(top_sim_movies_ratings)\n            # Avg_user rating\n            try:\n                row.append(sample_train_averages['user'][user])\n            except KeyError:\n                row.append(sample_train_averages['global'])\n            except:\n                raise\n            # Avg_movie rating\n            try:\n                row.append(sample_train_averages['movie'][movie])\n            except KeyError:\n                row.append(sample_train_averages['global'])\n            except:\n                raise\n            # Finally, the actual rating of this user-movie pair\n            row.append(rating)\n            count = count + 1\n\n            # Add rows to the file opened\n            reg_data_file.write(','.join(map(str, row)))\n            reg_data_file.write('\\n')        \n            if (count)%1000 == 0:\n                print(\"Done for {} rows - {}\".format(count, datetime.now() - start))\n    print(\"\",datetime.now() - start)  ","0303ca14":"# Reading from the file to make a test dataframe\nreg_test_df = pd.read_csv('..\/input\/d\/elemento\/netflix-prize-data\/reg_test.csv', names = ['user', 'movie', 'GAvg', 'sur1', 'sur2',\n'sur3', 'sur4', 'sur5', 'smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating'], header=None)\nreg_test_df.head(4)","d1a8a179":"# It is to specify how to read the dataframe.\n# For our dataframe, we don't have to specify anything extra\nreader = Reader(rating_scale=(1, 5))\n\n# Create the traindata from the dataframe\ntrain_data = Dataset.load_from_df(reg_train[['user', 'movie', 'rating']], reader)\n\n# Build the trainset from traindata, it is of dataset format from surprise library\ntrainset = train_data.build_full_trainset() ","5f00b8b4":"testset = list(zip(reg_test_df.user.values, reg_test_df.movie.values, reg_test_df.rating.values))\ntestset[:3]","b37273fe":"models_evaluation_train = dict()\nmodels_evaluation_test = dict()\nmodels_evaluation_train, models_evaluation_test","cdea0763":"# Utility functions for running regression models\n\n# To get rmse and mape given actual and predicted ratings\ndef get_error_metrics(y_true, y_pred):\n    rmse = np.sqrt(np.mean([ (y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ]))\n    mape = np.mean(np.abs( (y_true - y_pred)\/ y_true )) * 100\n    return rmse, mape\n\n# It will return train_results and test_results\ndef run_xgboost(algo,  x_train, y_train, x_test, y_test, verbose=True):\n    # Dictionaries for storing train and test results\n    train_results = dict()\n    test_results = dict()\n    \n    # Fit the model\n    print('Training the model')\n    start = datetime.now()\n    algo.fit(x_train, y_train, eval_metric = 'rmse')\n    print('Done. Time taken : {}'.format(datetime.now()-start))\n\n    # From the trained model, get the predictions\n    print('Evaluating the model with TRAIN data')\n    start = datetime.now()\n    y_train_pred = algo.predict(x_train)\n    # Get the RMSE and MAPE of train data\n    rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n    if verbose:\n        print('-'*15)\n        print('Train Data')\n        print('-'*15)\n        print(\"RMSE: {}\\nMAPE: {}\".format(rmse_train, mape_train))\n    \n    # Store the results in train_results dictionary\n    train_results = {'rmse': rmse_train, 'mape' : mape_train, 'predictions' : y_train_pred}\n    \n    # Get the test data predictions and compute RMSE and MAPE\n    print('Evaluating Test data')\n    y_test_pred = algo.predict(x_test) \n    rmse_test, mape_test = get_error_metrics(y_true=y_test.values, y_pred=y_test_pred)\n    # Store them in our test results dictionary\n    test_results = {'rmse': rmse_test, 'mape' : mape_test, 'predictions':y_test_pred}\n    if verbose:\n        print('-'*15)\n        print('Test Data')\n        print('-'*15)\n        print('RMSE: ', rmse_test)\n        print('MAPE: ', mape_test)\n        \n    # Return these train and test results\n    return train_results, test_results","6272e786":"# Utility functions for Surprise modes\n\n# It is just to makesure that all of our algorithms should produce same results everytime they run\nmy_seed = 15\nrandom.seed(my_seed)\nnp.random.seed(my_seed)\n\n# Get  (actual_list , predicted_list) ratings given list of predictions \n# (Prediction is a class in Surprise).    \ndef get_ratings(predictions):\n    actual = np.array([pred.r_ui for pred in predictions])\n    pred = np.array([pred.est for pred in predictions])\n    return actual, pred\n\n# Get RMSE and MAPE, given list of prediction objecs \ndef get_errors(predictions, print_them=False):\n    actual, pred = get_ratings(predictions)\n    rmse = np.sqrt(np.mean((pred - actual)**2))\n    mape = np.mean(np.abs(pred - actual)\/actual)\n    return rmse, mape*100\n\n# It will return predicted ratings, RMSE and MAPE of both train and test data\ndef run_surprise(algo, trainset, testset, verbose=True): \n    '''\n    return train_dict, test_dict\n    It returns two dictionaries, one for train and the other is for test\n    Each of them have 3 key-value pairs, which specify RMSE, MAPE and `predicted ratings`.\n    '''\n    \n    start = datetime.now()\n    # Dictionaries that stores metrics for train and test\n    train = dict()\n    test = dict()\n    \n    # Train the algorithm with the trainset\n    st = datetime.now()\n    print('Training the model')\n    algo.fit(trainset)\n    print('Done. Time taken: {}'.format(datetime.now()-st))\n    \n    # Evaluating train data\n    st = datetime.now()\n    print('Evaluating the model with train data')\n    # Get the train predictions (list of prediction class inside Surprise)\n    train_preds = algo.test(trainset.build_testset())\n    # Get predicted ratings from the train predictions\n    train_actual_ratings, train_pred_ratings = get_ratings(train_preds)\n    # Get RMSE and MAPE from the train predictions\n    train_rmse, train_mape = get_errors(train_preds)\n    print('Time taken: {}'.format(datetime.now()-st))\n    \n    if verbose:\n        print('-'*15)\n        print('Train Data')\n        print('-'*15)\n        print(\"RMSE: {}\\nMAPE: {}\".format(train_rmse, train_mape))\n    \n    # Store them in the train dictionary\n    if verbose:\n        print('Adding train results in the dictionary')\n    train['rmse'] = train_rmse\n    train['mape'] = train_mape\n    train['predictions'] = train_pred_ratings\n    \n    # Evaluating Test data\n    st = datetime.now()\n    print('Evaluating for test data')\n    # Get the predictions (list of prediction classes) of test data\n    test_preds = algo.test(testset)\n    # Get the predicted ratings from the list of predictions\n    test_actual_ratings, test_pred_ratings = get_ratings(test_preds)\n    # Get error metrics from the predicted and actual ratings\n    test_rmse, test_mape = get_errors(test_preds)\n    print('Time taken: {}'.format(datetime.now()-st))\n    \n    if verbose:\n        print('-'*15)\n        print('Test Data')\n        print('-'*15)\n        print(\"RMSE : {}\\nMAPE : {}\".format(test_rmse, test_mape))\n    # Store them in test dictionary\n    if verbose:\n        print('storing the test results in test dictionary...')\n    test['rmse'] = test_rmse\n    test['mape'] = test_mape\n    test['predictions'] = test_pred_ratings\n    \n    print('\\n'+'-'*45)\n    print('Total time taken to run this algorithm: ', datetime.now() - start)\n    \n    # Return two dictionaries train and test\n    return train, test","e84fe5f1":"# Prepare Train data\nx_train = reg_train.drop(['user','movie','rating'], axis=1)\ny_train = reg_train['rating']\n\n# Prepare Test data\nx_test = reg_test_df.drop(['user','movie','rating'], axis=1)\ny_test = reg_test_df['rating']\n\n# Initialize Our first XGBoost model\nfirst_xgb = xgb.XGBRegressor(silent=False, n_jobs=13, random_state=15, n_estimators=100)\ntrain_results, test_results = run_xgboost(first_xgb, x_train, y_train, x_test, y_test)\n\n# Store the results in models_evaluations dictionaries\nmodels_evaluation_train['first_algo'] = train_results\nmodels_evaluation_test['first_algo'] = test_results\n\nxgb.plot_importance(first_xgb)\nplt.show()","88637c4e":"# Options are to specify, how to compute those user and item biases.\nbsl_options = {'method': 'sgd', 'learning_rate': .001}\nbsl_algo = BaselineOnly(bsl_options = bsl_options)\n\n# Run this algorithm, it will return the train and test results\nbsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=True)\n\n# Just store these error metrics in our models_evaluation datastructure\nmodels_evaluation_train['bsl_algo'] = bsl_train_results \nmodels_evaluation_test['bsl_algo'] = bsl_test_results","b98c2dd5":"# Updating Train Data\n# Add our baseline_predicted value as our feature\nreg_train['bslpr'] = models_evaluation_train['bsl_algo']['predictions']\nreg_train.head(2) ","12c66afc":"# Updating Test Data\n# Add that baseline predicted ratings with Surprise to the test data as well\nreg_test_df['bslpr']  = models_evaluation_test['bsl_algo']['predictions']\nreg_test_df.head(2)","8b646efd":"# Prepare train data\nx_train = reg_train.drop(['user', 'movie','rating'], axis=1)\ny_train = reg_train['rating']\n\n# Prepare Test data\nx_test = reg_test_df.drop(['user','movie','rating'], axis=1)\ny_test = reg_test_df['rating']\n\n# Initialize our first XGBoost model\nxgb_bsl = xgb.XGBRegressor(silent=False, n_jobs=13, random_state=15, n_estimators=100)\ntrain_results, test_results = run_xgboost(xgb_bsl, x_train, y_train, x_test, y_test)\n\n# Store the results in models_evaluations dictionaries\nmodels_evaluation_train['xgb_bsl'] = train_results\nmodels_evaluation_test['xgb_bsl'] = test_results\n\nxgb.plot_importance(xgb_bsl)\nplt.show()","7bc29677":"# We specify, how to compute similarities and what to consider with sim_options to our algorithm\nsim_options = {'user_based' : True, 'name': 'pearson_baseline', 'shrinkage': 100, 'min_support': 2}\n\n# We keep other parameters like regularization parameter and learning_rate as default values.\nbsl_options = {'method': 'sgd'} \n\nknn_bsl_u = KNNBaseline(k=40, sim_options = sim_options, bsl_options = bsl_options)\nknn_bsl_u_train_results, knn_bsl_u_test_results = run_surprise(knn_bsl_u, trainset, testset, verbose=True)\n\n# Just store these error metrics in our models_evaluation datastructure\nmodels_evaluation_train['knn_bsl_u'] = knn_bsl_u_train_results \nmodels_evaluation_test['knn_bsl_u'] = knn_bsl_u_test_results","99732eb8":"# We specify, how to compute similarities and what to consider with sim_options to our algorithm\n# 'user_based' : False; This considers the similarities of movies instead of users\nsim_options = {'user_based' : False, 'name': 'pearson_baseline', 'shrinkage': 100, 'min_support': 2}\n\n# We keep other parameters like regularization parameter and learning_rate as default values\nbsl_options = {'method': 'sgd'}\n\nknn_bsl_m = KNNBaseline(k=40, sim_options = sim_options, bsl_options = bsl_options)\nknn_bsl_m_train_results, knn_bsl_m_test_results = run_surprise(knn_bsl_m, trainset, testset, verbose=True)\n\n# Just store these error metrics in our models_evaluation datastructure\nmodels_evaluation_train['knn_bsl_m'] = knn_bsl_m_train_results \nmodels_evaluation_test['knn_bsl_m'] = knn_bsl_m_test_results","d3f2d8e6":"# Preparing Train data\n# Add the predicted values from both knns to this dataframe\nreg_train['knn_bsl_u'] = models_evaluation_train['knn_bsl_u']['predictions']\nreg_train['knn_bsl_m'] = models_evaluation_train['knn_bsl_m']['predictions']\nreg_train.head(2)","946e07b3":"# Preparing Test data\nreg_test_df['knn_bsl_u'] = models_evaluation_test['knn_bsl_u']['predictions']\nreg_test_df['knn_bsl_m'] = models_evaluation_test['knn_bsl_m']['predictions']\nreg_test_df.head(2)","92791e1b":"# Prepare the train data\nx_train = reg_train.drop(['user', 'movie', 'rating'], axis=1)\ny_train = reg_train['rating']\n\n# Prepare the test data\nx_test = reg_test_df.drop(['user','movie','rating'], axis=1)\ny_test = reg_test_df['rating']\n\n# Declare the model\nxgb_knn_bsl = xgb.XGBRegressor(n_jobs=10, random_state=15)\ntrain_results, test_results = run_xgboost(xgb_knn_bsl, x_train, y_train, x_test, y_test)\n\n# Store the results in models_evaluations dictionaries\nmodels_evaluation_train['xgb_knn_bsl'] = train_results\nmodels_evaluation_test['xgb_knn_bsl'] = test_results\n\nxgb.plot_importance(xgb_knn_bsl)\nplt.show()","8d691370":"# Initialize the model\nsvd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\nsvd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=True)\n\n# Just store these error metrics in our models_evaluation datastructure\nmodels_evaluation_train['svd'] = svd_train_results \nmodels_evaluation_test['svd'] = svd_test_results","8340a241":"# Initialize the model\nsvdpp = SVDpp(n_factors=50, random_state=15, verbose=True)\nsvdpp_train_results, svdpp_test_results = run_surprise(svdpp, trainset, testset, verbose=True)\n\n# Just store these error metrics in our models_evaluation datastructure\nmodels_evaluation_train['svdpp'] = svdpp_train_results \nmodels_evaluation_test['svdpp'] = svdpp_test_results","0d15bdbd":"# Preparing Train data\n# Add the predicted values from both knns to this dataframe\nreg_train['svd'] = models_evaluation_train['svd']['predictions']\nreg_train['svdpp'] = models_evaluation_train['svdpp']['predictions']\nreg_train.head(2) ","9e6b4341":"# Preparing Test data\nreg_test_df['svd'] = models_evaluation_test['svd']['predictions']\nreg_test_df['svdpp'] = models_evaluation_test['svdpp']['predictions']\nreg_test_df.head(2) ","83c113db":"# Prepare x_train and y_train\nx_train = reg_train.drop(['user', 'movie', 'rating',], axis=1)\ny_train = reg_train['rating']\n\n# Prepare test data\nx_test = reg_test_df.drop(['user', 'movie', 'rating'], axis=1)\ny_test = reg_test_df['rating']\n\nxgb_final = xgb.XGBRegressor(n_jobs=10, random_state=15)\ntrain_results, test_results = run_xgboost(xgb_final, x_train, y_train, x_test, y_test)\n\n# Store the results in models_evaluations dictionaries\nmodels_evaluation_train['xgb_final'] = train_results\nmodels_evaluation_test['xgb_final'] = test_results\n\nxgb.plot_importance(xgb_final)\nplt.show()","f35c902f":"# Prepare train data\nx_train = reg_train[['knn_bsl_u', 'knn_bsl_m', 'svd', 'svdpp']]\ny_train = reg_train['rating']\n\n# Test data\nx_test = reg_test_df[['knn_bsl_u', 'knn_bsl_m', 'svd', 'svdpp']]\ny_test = reg_test_df['rating']\n\nxgb_all_models = xgb.XGBRegressor(n_jobs=10, random_state=15)\ntrain_results, test_results = run_xgboost(xgb_all_models, x_train, y_train, x_test, y_test)\n\n# Store the results in models_evaluations dictionaries\nmodels_evaluation_train['xgb_all_models'] = train_results\nmodels_evaluation_test['xgb_all_models'] = test_results\n\nxgb.plot_importance(xgb_all_models)\nplt.show()","ad378a73":"# Saving our TEST_RESULTS into a dataframe so that you don't have to run it again\npd.DataFrame(models_evaluation_test).to_csv('small_sample_results.csv')\nmodels = pd.read_csv('..\/input\/d\/elemento\/netflix-prize-data\/small_sample_results.csv', index_col=0)\nmodels.loc['rmse'].sort_values()","04f49b56":"print(\"Total time taken to run this entire notebook (With saved files) is: \", datetime.now()-globalstart)","3efcd176":"#### 3.3.7.3 Finding average rating\/movie","d653874e":"### 3.3.5 Analysis of ratings of a movie given by a user","1dee079e":"### 3.1.3 Removing Duplicates","38aaeaef":"### 3.2.2 Basic Statistics in Test data (#Ratings, #Users, and #Movies)","66a9c2d8":"### 3.1.2 Checking for NaN values","5d168057":"### 3.2.1 Basic Statistics in Train data (#Ratings, #Users, and #Movies)","64f04330":"### 3.3.7 Finding Global average of all movie ratings, Average rating per user, & Average rating per movie","e02c4a85":"## 3.2 Spliting data into Train and Test (80:20)\n- Since, the data that we have been given has a **temporal structure**, i.e., the ratings given to the movies by the users change over time, hence, we will prefer time-based splitting over random splitting. \n- Thankfully, we have been given the timestamp(s), so, we have arranged our data in increasing order of timestamp(s), and now, we will take the first 80% of the data, and make it the training set, and the rest 20%, we will make it the test set.","54785f66":"### 4.4.5 XGBoost with initial 13 features + Surprise Baseline predictor + KNNBaseline predictor\n- First we will run XGBoost with predictions from both KNN's ( that uses User\\_User and Item\\_Item similarities along with our previous features.\n- Then we will run XGBoost with just predictions form both knn models and preditions from our baseline model. \n\n","40629fe8":"### 4.2.2 Finding Average rating per User","665a51c6":"### 4.2.1 Finding Global Average of all movie ratings","dfada0aa":"### 3.3.3 Number of Ratings\/Month\n- In this plot, we can observe that we have data ranging from mid 1999 to mid 2005.\n- And we can see, that the number of ratings that we have, increases sharply from around 2003. This is an indication of the growth of Netflix as a company itself.\n- And since, we have taken the latest 20% of the ratings in the test data, we can conclude that the test data would be spanning over a very short window of time.","b820d52d":"- __GAvg__ : Average rating of all the ratings \n- __Similar users rating of this movie__:\n    - sur1, sur2, sur3, sur4, sur5 (Top 5 similar users who rated that movie)\n- __Similar movies rated by this user__:\n    - smr1, smr2, smr3, smr4, smr5 (Top 5 similar movies rated by this movie)\n- __UAvg__ : User AVerage rating\n- __MAvg__ : Average rating of this movie\n- __rating__ : Rating of this movie by this user.","68aa0f91":"- This is taking more time for each user than the original one. From the above plot, it took almost **12.18s** for computing simlilar users for **one user**.\n- We have **405041 users** with us in training set.\n- ${ 405041 \\times 12.18 == 4933399.38 \\sec } ==  82223.323 \\min == 1370.388716667 \\text{ hours}\n== 57.099529861 \\text{ days}$\n- Even we run on 4 cores parallelly (a typical system now a days), It will still take almost __(14 - 15) __ days.\n  \n  \n- **Why did this happen?** Just think about it, it's not that difficult.\n- The reason is because of the differences between Sparse and Dense Matrices. The original matrix was a sparse matrix, and hence computation was much faster for it, but after we used Truncated SVD, though, we got a reduced dimensional matrix, but it was a dense matrix.\n\n\n- Is there any other way to compute user user similarity?\n- An alternative is to compute similar users for a particular user,  whenenver required (**ie., Run time**)\n- We maintain a binary vector for users, which tells us whether we already computed for it or not\n- **If not**: \n    - Compute top (let's just say, 1000) most similar users for this given user, and add this to our datastructure, so that we can just access it (similar users) without recomputing it again.\n- **If it is already computed**:\n    - Just get it directly from our datastructure, which has that information.\n    - In production time, we might have to recompute similarities, if it is computed a long time ago. Because user preferences changes over time. If we could maintain some kind of timer, which when expires, we have to update it (recompute it). \n- **Which datastructure to use**:\n    - It is purely implementation dependent \n    - One simple method is to maintain a **Dictionary Of Dictionaries**.\n        - **key**  : *userid* \n        - **value**: *Again a dictionary*\n            - **key**  : *Similar User*\n            - **value**: *Similarity Value*\n                  \n### 3.4.2 Computing Movie-Movie Similarity matrix ","18d85386":"#### 3.3.6.2 Creating sparse matrix from test data frame\n- In the below code cells, we can see that the sparsity of the test dataset is around 99.95%, which means that only about 0.05% of the cells in the test dataset are filled.","066fe042":"# 5. Further Extensions\n1. Instead of using 10K users and 1K movies to train the above models, use 25K users and 3K movies (or more) to train all of the above models. Report the RMSE and MAPE on the test data using larger amount of data and provide a comparison between various models as shown above.\n2. Tune hyperparameters of all the XgBoost models above to improve the RMSE\n\n**NOTE**: Please be patient as some of the code snippets may take many hours to complete execution.","14150782":"### 4.2.3 Finding Average rating per Movie","e973b111":"## 4.1 Sampling Data\n### 4.1.1 Build sample train data from the train data ","cae2e27e":"### 4.4.7 XgBoost with 13 features + Surprise Baseline + Surprise KNNbaseline + MF Techniques","934675d1":"### 3.3.2 Number of ratings on each day of the week\n- In the below plot, we can see that the number of ratings given are greater on days like Monday, Tuesday and Wednesday, and are smaller on days like Friday, Saturday and Sunday.\n- This may be attributed to the fact that people in US generally perform outdoor activities like trekking, camping, etc, on weekends and\/or go in parties.","b6cdb1e1":"### 3.3.4 Analysis on the Ratings given by user\n- From the below code cell, we can observe that the maximum number of movies rated by a single user as per our dataset is **17112**, which is pretty huge. So, we got a bit curious, and tried to inspect it a bit more!","6be48471":"### 4.3.1 Featurizing data for regression problem\n#### 4.3.1.1 Featurizing train data","96daf438":"## 4.5 Comparision between all models","44b0bf5f":"# Installing & Importing Packages","e0c7dbfa":"### 4.3.2 Transforming data for Surprise models\n#### 4.3.2.1 Transforming train data\n- We can't give raw data (movie, user, rating) to train the model in Surprise library.\n- They have a separate format for TRAIN and TEST data, which will be useful for training the models like SVD, KNNBaseLineOnly, etc, in Surprise.\n- We can form the trainset from a file, or from a Pandas  DataFrame. \nhttp:\/\/surprise.readthedocs.io\/en\/stable\/getting_started.html#load-dom-dataframe-py ","21474759":"### 4.4.8 XgBoost with Surprise Baseline + Surprise KNNbaseline + MF Techniques","367fc8ef":"### 4.4.2 Suprise BaselineModel\n\n**Predicted_rating: (Baseline Prediction)**\n-  http:\/\/surprise.readthedocs.io\/en\/stable\/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly \n- $   \\large {\\hat{r}_{ui} = b_{ui} =\\mu + b_u + b_i} $\n- $\\pmb \\mu $ : Average of all trainings in training data.\n- $\\pmb b_u$ : User bias\n- $\\pmb b_i$ : Item bias (movie biases) \n\n\n**Optimization function (Least Squares Problem)**\n- http:\/\/surprise.readthedocs.io\/en\/stable\/prediction_algorithms.html#baselines-estimates-configuration \n- $ \\large \\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - (\\mu + b_u + b_i)\\right)^2 +\n\\lambda \\left(b_u^2 + b_i^2 \\right).\\text {        [mimimize } {b_u, b_i]}$ ","4060f1ca":"![netflix-q.jpg](attachment:decaf5be-1bea-431c-be1f-123979b744dc.jpg)","eae1bc43":"### 3.4.3 Finding most similar movies using similarity matrix\n- Does Similarity really works as the way we expected? \n- Let's pick some random movie and check for its similar movies.","412862ba":"- There is something interesting going on with the quantiles here, as we can see from the above numbers. \n- We observed that there was a huge upsurge from the 75% quantile range to the 100% quantile range. So, we tried to visualize this particular range. ","2818f587":"## 4.3 Featurizing data","dfbe2186":"#### 4.3.1.2 Featurizing test data","ed429b81":"### 3.1.4 Basic Statistics (#Ratings, #Users, and #Movies)","64f3c6c5":"#### 3.4.1.2 Trying with reduced dimensions (Using TruncatedSVD for dimensionality reduction of user vector)\n- We have  **405,041 users** in out training set and computing similarities between them(**17K dimensional vector**) is time-consuming.\n- From above plot, it took roughly **8.88 sec** for computing simlilar users for **one user**\n- We have **405,041 users** with us in training set.\n- ${ 405041 \\times 8.88 = 3596764.08  \\sec } =  59946.068 \\min = 999.101133333 \\text{ hours}\n= 41.629213889 \\text{ days}...$\n    - Even if we run on 4 cores parallelly (a typical system now a days), It will still take almost __10 and 1\/2__ days.\n    \nIDEA:  Instead, we will try to reduce the dimentsions using SVD, so that **it might** speed up the process.","a69c4df0":"### 4.4.4 Surprise KNNBaseline predictor \n- KNN Baseline: http:\/\/surprise.readthedocs.io\/en\/stable\/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline \n- Pearson Baseline Similarity: http:\/\/surprise.readthedocs.io\/en\/stable\/similarities.html#surprise.similarities.pearson_baseline \n- Shrinkage: *2.2 Neighborhood Models* in http:\/\/courses.ischool.berkeley.edu\/i290-dm\/s11\/SECURE\/a1-koren.pdf \n    \n    \n- Predicted Rating: (Based on User-User similarity)\n\\begin{align} \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{v \\in N^k_i(u)}\n\\text{sim}(u, v) \\cdot (r_{vi} - b_{vi})} {\\sum\\limits_{v \\in\nN^k_i(u)} \\text{sim}(u, v)} \\end{align}\n- $\\pmb{b_{ui}}$ -  Baseline prediction of (user, movie) rating\n- $ \\pmb {N_i^k (u)}$ - Set of K similar users (neighbours) of user (u) who rated movie(i)  \n- sim (u, v): Similarity between users u and v  \n    - Generally, it will be cosine similarity or Pearson correlation coefficient. \n    - But we use **Shrunk Pearson-baseline correlation coefficient**, which is based on the Pearson Baseline similarity (We take base line predictions instead of mean rating of user\/item)\n       \n       \n- **Predicted Rating** (Based on Item Item similarity ):\n \\begin{align} \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{j \\in N^k_u(i)}\\text{sim}(i, j) \\cdot (r_{uj} - b_{uj})} {\\sum\\limits_{j \\in N^k_u(j)} \\text{sim}(i, j)} \\end{align}\n-  Notations follows same as above (user-user based predicted rating)\n      \n#### 4.4.4.1 Surprise KNNBaseline with user user similarities","3d3f95d3":"# 4. Machine Learning Models","78743073":"- __GAvg__ : Average rating of all the ratings \n- __Similar users rating of this movie__:\n    - sur1, sur2, sur3, sur4, sur5 (Top 5 similar users who rated that movie)\n- __Similar movies rated by this user__:\n    - smr1, smr2, smr3, smr4, smr5 (Top 5 similar movies rated by this movie)\n- __UAvg__ : User's Average rating\n- __MAvg__ : Average rating of this movie\n- __rating__ : Rating of this movie by this user.","c4d3bf33":"- Even though we have similarity measure of each movie, with all other movies, We generally don't care much about least similar movies.\n- Most of the times, only top_xxx similar items matters. It may be 10 or 100.\n- We take only those top similar movie ratings and store them  in a saperate dictionary.","76847c36":"#### 3.3.6.1 Creating sparse matrix from train data frame\n- In the below code cells, we can see that the sparsity of the training dataset is around 99.82%, which means that only about 0.18% of the cells in the training dataset are filled.","6ff9a295":"#### 4.4.4.2 Surprise KNNBaseline with movie movie similarities","bc3b3ffc":"- We think 500 dimensions is good enough \n- By just taking **(20 to 30)** latent factors, explained variance that we could get is **20%**. \n- To take it to **60%**, we have to take **almost 400 latent factors**. It is not fair.\n- It basically is the **gain of variance explained**, if we **add one additional latent factor to it**.\n- By adding one by one latent factors to it, the **gain in expained variance** with that addition is decreasing. (Obviously, because they are sorted that way).\n\n\n- ***LHS Graph***:\n    - **x** - No of latent factos ,\n    - **y** - The variance explained by taking x latent factors\n- **More decrease in the line (RHS graph)**:\n    - We  are getting more expained variance than before.\n- **Less decrease in the line (RHS graph)**:\n    - We are not getting any benefit from adding latent factors further. This is what is shown in the plots.\n- ***RHS Graph***:\n    - **x** - No of latent factors,\n    - **y** - Gain in Expl_Var by taking one additional latent factor","b1789b07":"# Netflix Prize Data\n- Hola amigos, this notebook covers my code for the **Netflix Prize Data** dataset, which can be found [here](https:\/\/www.kaggle.com\/netflix-inc\/netflix-prize-data).","0c8d7c6c":"### 3.3.1 Distribution of Ratings\n- In this plot, we can observe that the most common rating that users give is 4\n- Also, the second most common rating is 3. & based on these, we can conclude that users tend to give higher ratings.","9ccda752":"#### 3.3.7.1 Finding global average of all the ratings","1a59a25f":"#### 3.3.7.4 PDF's & CDF's of Avg.Ratings of Users & Movies (In Train Data)\n- Since the average ratings of users are in the form of a vector, and since the average ratings of movies are in the form of a vector, hence, we have tried to plot the PDF and CDF for both of them, to get a better sense of them.","b939656e":"## 4.2 Finding Global Average of all movie ratings, Average rating per User, and Average rating per Movie (from sampled train)","20a8ae21":"### 4.4.1 XGBoost with initial 13 features ","63cdca13":"### 4.4.6 Matrix Factorization Techniques\n#### 4.4.6.1 SVD Matrix Factorization User Movie Interactions\n\nhttp:\/\/surprise.readthedocs.io\/en\/stabl\/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD \n\n- Predicted Rating:\n    - $ \\large  \\hat r_{ui} = \\mu + b_u + b_i + q_i^Tp_u $\n    - $\\pmb q_i$ - Representation of item(movie) in latent factor space\n    - $\\pmb p_u$ - Representation of user in new latent factor space\n\n\n- A Basic Matrix Factorization Model in  https:\/\/datajobs.com\/data-science-repo\/Recommender-Systems-[Netflix].pdf\n- Optimization problem with user item interactions and regularization (To avoid overfitting)\n    - $\\large \\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - \\hat{r}_{ui} \\right)^2 +\n\\lambda\\left(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2\\right) $","9802b5e3":"- It is very skewed, just like the number of ratings given per user.\n- There are some movies (which are very popular) which are rated by huge number of users.\n- But most of the movies(like 90%) got some hundreds of ratings only.","dbb92eaa":"- Now, we try to see if the day of the week is an important feature to predict the ratings.\n- For that, we plotted the boxplots of the ratings across the 7 days of the week, and we found that the boxplots are more or less overlapping.\n- In other words, we can say that the day-of-week is not a very useful feature in predicting the ratings. \n- Just to be a bit more sure, we even calculated the average ratings given by users on each of the days, and we found that, they are more or less the same.\n- Remember, in Data Science, we perform a lot of experiments and about 90% of them tend of fail. This is why it has the word \"Science\" in it, i.e., we need to perform a lot of experiments.","1e080e82":"## 4.4 Applying Machine Learning models\n-  Global dictionary that stores rmse and mape for all the models.\n    - It stores the metrics in a dictionary of dictionaries\n    - **keys** : model names(string)\n    - **value**: dict(**key** : metric, **value** : value) ","c62e58d4":"### 4.4.3 XGBoost with initial 13 features + Surprise Baseline predictor ","d52a4cb8":"#### 3.3.7.2 Finding average rating\/user","f6189527":"Here,\n- $\\sum \\longleftarrow$ (netflix\\_svd.**singular\\_values\\_** )\n- $\\bigvee^T \\longleftarrow$ (netflix\\_svd.**components_**)\n- $\\bigcup$ is not returned. instead **Projection_of_X** onto the new vectorspace is returned. \n- It uses **randomized svd** internally, which returns **all 3 of them separately**. Use that instead.","6a8217d5":"### 4.1.2 Build sample test data from the test data","f43a979b":"### 3.3.8 Cold Start problem\n- **Cold Start problem** is something that could seriously hamper our recommendation system. It basically refers to the issue when we encounter new users\/movies in our test set, corresponding to which, we don't have the ratings in our training set.\n\n<br>\n\n#### 3.3.8.1 Cold Start problem with Users\n- We might have to handle **75148 new users** who didn't appear in train data.\n- We might have to handle **346 new movies** (smaller comparatively) in test data.","a38e2a07":"#### 4.4.6.2 SVD Matrix Factorization with implicit feedback from user ( user rated movies )\n- 2.5 Implicit Feedback in http:\/\/courses.ischool.berkeley.edu\/i290-dm\/s11\/SECURE\/a1-koren.pdf\n- Predicted Rating:\n    - $ \\large \\hat{r}_{ui} = \\mu + b_u + b_i + q_i^T\\left(p_u +\n    |I_u|^{-\\frac{1}{2}} \\sum_{j \\in I_u}y_j\\right) $ \n    - $ \\pmb{I_u}$ - the set of all items rated by user u\n    - $\\pmb{y_j}$ - Our new set of item factors that capture implicit ratings.  \n\n\n- Optimization problem with user item interactions and regularization (to avoid overfitting)\n    - $ \\large \\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - \\hat{r}_{ui} \\right)^2 +\n\\lambda\\left(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2 + ||y_j||^2\\right) $ ","47fba767":"### 3.3.6 Creating Sparse matrix from Data Frame\n![Screenshot from 2021-10-21 17-15-12.png](attachment:370159be-5762-48b1-853e-b1b7e716a857.png)","adf73804":"## 3.4 Computing Similarity matrices\n### 3.4.1 Computing User-User Similarity matrix\n- Calculating User User Similarity_Matrix is **not very easy** (unless you have huge computing power and lots of time) because of the number of users being there.\n- You can try if you want to. Your system could crash or the program will stop with **Memory Error**.\n\n#### 3.4.1.1 Trying with all dimensions (17k dimensions per user) ","92dd375a":"# 1. Business Problem\n## 1.1 Problem Description\n\nNetflix is all about connecting people to the movies they love. To help customers find those movies, they developed world-class movie recommendation system: CinematchSM. Its job is to predict whether someone will enjoy a movie based on how much they liked or disliked other movies. Netflix use those predictions to make personal movie recommendations based on each customer\u2019s unique tastes. And while **Cinematch** is doing pretty well, it can always be made better. <br> <br>\nNow there are a lot of interesting alternative approaches to how Cinematch works that netflix haven\u2019t tried. Some are described in the literature, some aren\u2019t. We\u2019re curious whether any of these can beat Cinematch by making better predictions. Because, frankly, if there is a much better approach it could make a big difference to our customers and our business. <br> <br>\nCredits: https:\/\/www.netflixprize.com\/rules.html\n\n## 1.2 Problem Statement\nNetflix provided a lot of anonymous rating data, and a prediction accuracy bar that is 10% better than what Cinematch can do on the same training data set. (Accuracy is a measurement of how closely predicted ratings of movies match subsequent actual ratings.) \n\n## 1.3 Sources\n- https:\/\/www.netflixprize.com\/rules.html\n- https:\/\/www.kaggle.com\/netflix-inc\/netflix-prize-data\n- **Netflix Blog**: https:\/\/medium.com\/netflix-techblog\/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429 (very nice blog)\n- **Surprise Library**: http:\/\/surpriselib.com\/ (We use many models from this library)\n- **Surprise Library doc**: http:\/\/surprise.readthedocs.io\/en\/stable\/getting_started.html (We use many models from this library)\n- **Installing Surprise**: https:\/\/github.com\/NicolasHug\/Surprise#installation\n- **Research paper**: http:\/\/courses.ischool.berkeley.edu\/i290-dm\/s11\/SECURE\/a1-koren.pdf (Most of our work was inspired by this paper)\n- **SVD Decomposition**: https:\/\/www.youtube.com\/watch?v=P5mlg91as1c\n\n## 1.4 Real world\/Business Objectives and constraints \n**Objectives**:\n1. Predict the rating that a user would give to a movie that he ahs not yet rated.\n2. Minimize the difference between predicted and actual rating (RMSE and MAPE)\n<br>\n\n**Constraints**:\n1. Some form of interpretability.\n2. Some of us might think that latency should be a constraint, but since an average user doesn't watch more than a single item in one day, therefore, Netflix can pre-compute the recommendations, on some regular basis, for instance, nightly basis and so on. This will ensure that we have room for a higher latency, and still, the user will be shown the recommendations as soon as he\/she logs in.\n\n# 2. Machine Learning Problem\n## 2.1 Data \n### 2.1.1 Data Overview\n\nGet the data from : https:\/\/www.kaggle.com\/netflix-inc\/netflix-prize-data\/data\n\nData files : \n\n- combined_data_1.txt \n- combined_data_2.txt \n- combined_data_3.txt\n- combined_data_4.txt\n- movie_titles.csv\n\n<pre>  \nThe first line of each file [combined_data_1.txt, combined_data_2.txt, combined_data_3.txt, combined_data_4.txt] contains the movie id followed by a colon. Each subsequent line in the file corresponds to a rating from a customer and its date in the following format:\n\nCustomerID,Rating,Date\n\nMovieIDs range from 1 to 17770 sequentially.\nCustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\nRatings are on a five star (integral) scale from 1 to 5.\nDates have the format YYYY-MM-DD.\n<\/pre>\n\n### 2.1.2 Example Data point\n<pre>\n1:\n1488844,3,2005-09-06\n822109,5,2005-05-13\n885013,4,2005-10-19\n30878,4,2005-12-26\n823519,3,2004-05-03\n893988,3,2005-11-17\n124105,4,2004-08-05\n1248029,3,2004-04-22\n1842128,4,2004-05-09\n2238063,3,2005-05-11\n1503895,4,2005-05-19\n2207774,5,2005-06-06\n<\/pre>\n\n## 2.2 Mapping the real world problem to a Machine Learning Problem\n### 2.2.1 Type of Machine Learning Problem\n\n<pre>\nFor a given movie and user, we need to predict the rating that would be given by him\/her to the movie. \nThe given problem is a Recommendation problem, for which we will use techniques like Matrix Factorization (MF), Singular Value Decomposition (SVD), user-user similarity, movie-movie similarity, etc.\nIt can also be seen as a Regression problem, for which, we will use XgBoost intensively\n<\/pre>\n\n### 2.2.2 Performance metric\n- Mean Absolute Percentage Error: https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_percentage_error\n- Root Mean Square Error: https:\/\/en.wikipedia.org\/wiki\/Root-mean-square_deviation\n\n### 2.2.3 Machine Learning Objective and Constraints\n1. Minimize RMSE.\n2. Try to provide some interpretability.\n\n# 3. Exploratory Data Analysis\n## 3.1 Preprocessing\n### 3.1.1 Converting \/ Merging whole data to required format: u_i, m_j, r_ij","dcbe9554":"## 3.3 Exploratory Data Analysis on Train data","0b773cb8":"#### 4.3.2.2 Transforming test data\n- Testset is just a list of (user, movie, rating) tuples. (Order in the tuple is impotant) "}}