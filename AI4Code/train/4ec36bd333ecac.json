{"cell_type":{"12678e7b":"code","a8df3054":"code","99866aaf":"code","9bc4da1d":"code","abe53028":"code","b2c3b138":"code","85fb4d29":"code","c290c7dc":"code","8c386bba":"code","716b99e3":"code","003eb7d7":"code","842fcd70":"code","eb7a0706":"code","ad89483f":"code","8f786b07":"code","eefc9f4f":"code","23f90a8e":"code","63a9e354":"code","7aceda50":"code","5f9bdd6b":"code","bee69bb6":"code","a64e6ca7":"code","721f9235":"code","47a450d9":"code","eb6e957c":"code","c82c79c1":"code","45a0f1d6":"code","2c8d4f52":"code","2f276145":"code","9141330d":"code","513b8ccb":"code","fd4e0718":"code","27a33cea":"code","a4351ab3":"code","940d7572":"code","e9163816":"code","ac1b4f1a":"code","3b129c03":"code","f446a4e1":"code","8b694558":"code","47e326e3":"code","eabf2ee5":"code","eb968f86":"code","b2da1277":"code","7f6bf7b2":"code","753418c3":"code","bd9dd55a":"code","afd3b245":"code","336198e7":"code","9da1109a":"code","2a3fefb8":"code","084d0b94":"code","7a58b4b6":"code","92a02bab":"code","2bd85960":"code","d7b06394":"code","1d3cd736":"code","1af42995":"code","38beb81d":"code","1fdab531":"code","d52ee521":"code","abb9d7d6":"code","c860fbe2":"code","217c9df4":"markdown","c3f2a2e6":"markdown","2d18f38e":"markdown","33ebe101":"markdown","02d1b82f":"markdown","c252401d":"markdown","6db6ca35":"markdown","3cc6371e":"markdown","1c98b353":"markdown","c7c8e3fc":"markdown","af4377b7":"markdown","7d820fef":"markdown"},"source":{"12678e7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a8df3054":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n#Loading libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn.metrics as metrics\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics.pairwise import pairwise_distances\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport re\nimport seaborn as sns\nimport surprise\nfrom surprise import KNNWithMeans\nfrom surprise import Dataset\nfrom surprise import accuracy\nfrom surprise.model_selection import train_test_split\nData = pd.read_csv('..\/input\/amazon-electronics-rating-datasetrecommendation\/ratings_Electronics.csv')","99866aaf":"# Take the 10% Data as the Data is Huge and was cluttering the memory\nData =  Data.iloc[:782448]","9bc4da1d":"#read the Dataset\nData = pd.read_csv('..\/input\/amazon-electronics-rating-datasetrecommendation\/ratings_Electronics.csv',names=['userId', 'productId','Rating','timestamp'])","abe53028":"Data.dtypes","b2c3b138":"Data.head()","85fb4d29":"Data.shape","c290c7dc":"# Take the 10% Data as the Data is Huge and was cluttering the memory\nData =  Data.iloc[:782448]","8c386bba":"# Drop the Timestamp feature as it doesnt add much value to the model\n\nData = Data.drop(['timestamp'], axis = 1)","716b99e3":"Data.shape","003eb7d7":"# find minimum and maximum ratings\nprint('The minimum rating is: %d' %(Data['Rating'].min()))\nprint('The maximum rating is: %d' %(Data['Rating'].max()))","842fcd70":"Data.groupby('userId')['Rating'].mean().sort_values(ascending=False).head(10)  ","eb7a0706":"# check the Rating distribution in the range 1-5 for the Data given \n\nwith sns.axes_style('white'):\n    g = sns.factorplot(\"Rating\", data=Data, aspect=2.0,kind='count')\n    g.set_ylabels(\"Total number of ratings\")","ad89483f":"print(\"Total data \")\nprint(\"*\"*50)\nprint(\"\\nTotal no of ratings :\",Data.shape[0])\nprint(\"Total No of Users   :\", len(np.unique(Data.userId)))\nprint(\"Total No of products  :\", len(np.unique(Data.productId)))","8f786b07":"#Keep the users where the user has rated more than 50 \n\ncounts1 = Data['userId'].value_counts()\n#print(counts1)\nData_new = Data[Data['userId'].isin(counts1[counts1 >= 50].index)]\n#counts1","eefc9f4f":"#highest rated products from the selected records. \n\nData_new.groupby('productId')['Rating'].mean().sort_values(ascending=False) ","23f90a8e":"#Calculate the density of the rating matrix\n\nfinal_ratings_matrix = Data_new.pivot(index = 'userId', columns ='productId', values = 'Rating').fillna(0)\nprint('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)\n\ngiven_num_of_ratings = np.count_nonzero(final_ratings_matrix)\nprint('given_num_of_ratings = ', given_num_of_ratings)\npossible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\nprint('possible_num_of_ratings = ', possible_num_of_ratings)\ndensity = (given_num_of_ratings\/possible_num_of_ratings)\ndensity *= 100\nprint ('density: {:4.2f}%'.format(density))","63a9e354":"final_ratings_matrix.head()","7aceda50":"# Matrix with one row per 'Product' and one column per 'user' for Item-based CF\nfinal_ratings_matrix_T = final_ratings_matrix.transpose()\nfinal_ratings_matrix_T.head()","5f9bdd6b":"#Count of user_id for each unique product as recommendation score \nData_new_grouped = Data_new.groupby('productId').agg({'userId': 'count'}).reset_index()\nData_new_grouped.rename(columns = {'userId': 'score'},inplace=True)\nData_new_grouped.head()","bee69bb6":"#Sort the products on recommendation score \ntrain_data_sort = Data_new_grouped.sort_values(['score', 'productId'], ascending = [0,1]) \n      \n#Generate a recommendation rank based upon score \ntrain_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first') \n          \n#Get the top 5 recommendations \npopularity_recommendations = train_data_sort.head(5) \npopularity_recommendations ","a64e6ca7":"# Use popularity based recommender model to make predictions\ndef recommend(user_id):     \n    user_recommendations = popularity_recommendations \n          \n    #Add user_id column for which the recommendations are being generated \n    user_recommendations['userId'] = user_id \n      \n    #Bring user_id column to the front \n    cols = user_recommendations.columns.tolist() \n    cols = cols[-1:] + cols[:-1] \n    user_recommendations = user_recommendations[cols] \n          \n    return user_recommendations ","721f9235":"find_recom = [15,21,53]   # This list is user choice.\nfor i in find_recom:\n    print(\"Here is the recommendation for the userId: %d\\n\" %(i))\n    print(recommend(i))    \n    print(\"\\n\") ","47a450d9":"no_of_ratings_per_product = Data_new.groupby(by='productId')['Rating'].count().sort_values(ascending=False)\n\nfig = plt.figure(figsize=plt.figaspect(.5))\nax = plt.gca()\nplt.plot(no_of_ratings_per_product.values)\nplt.title('# RATINGS per Product')\nplt.xlabel('Product')\nplt.ylabel('No of ratings per product')\nax.set_xticklabels([])\n\nplt.show()","eb6e957c":"# Top 30 recommendations for the users\n\npopular_products = pd.DataFrame(Data_new.groupby('productId')['Rating'].count())\nmost_popular = popular_products.sort_values('Rating', ascending=False)\nmost_popular.head(30).plot(kind = \"bar\")\n","c82c79c1":"from surprise import KNNWithMeans\nfrom surprise import Dataset\nfrom surprise import accuracy\nfrom surprise import Reader\nimport os\nfrom surprise.model_selection import train_test_split\nfrom collections import defaultdict","45a0f1d6":"#Reading the dataset\nreader = Reader(rating_scale=(1, 5))\ndata1 = Dataset.load_from_df(Data_new,reader)\ndata1","2c8d4f52":"#Splitting the dataset\ntrainset, testset = train_test_split(data1, test_size=0.3,random_state=10)","2f276145":"trainset.ur","9141330d":"# Use user_based true\/false to switch between user-based or item-based collaborative filtering\nalgo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\nalgo.fit(trainset)","513b8ccb":"# run the trained model against the testset\ntest_pred = algo.test(testset)","fd4e0718":"test_pred","27a33cea":"def get_top_n(predictions, n=5):\n    # First map the predictions to each user.\n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # Then sort the predictions for each user and retrieve the k highest ones.\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n\n    return top_n","a4351ab3":"top_n = get_top_n(test_pred, n=5)","940d7572":"top_n","e9163816":"# Print the recommended items for each user\nfor uid, user_ratings in top_n.items():\n    print(uid, [iid for (iid, _) in user_ratings])","ac1b4f1a":"uid = \"A11D1KHM7DVOQK\"  # raw user id (as in the ratings file). They are **strings**!\niid = \"B000059L44\"  # raw item id (as in the ratings file). They are **strings**!\n\n# get a prediction for specific users and items.\npred = algo.predict(uid, iid, r_ui=0.0, verbose=True)","3b129c03":"pred = pd.DataFrame(test_pred)\npred[pred['uid'] == 'A11D1KHM7DVOQK'][['iid', 'r_ui','est']].sort_values(by = 'est',ascending = False).head(10)","f446a4e1":"# get RMSE\nprint(\"User-based Model : Test Set\")\naccuracy.rmse(test_pred, verbose=True)","8b694558":"from collections import defaultdict\nfrom surprise import SVD\nfrom surprise import Dataset","47e326e3":"data1 = Dataset.load_from_df(Data_new,reader)\ndata1\ntrainset, testset = train_test_split(data1, test_size=.15)","eabf2ee5":"trainset.ur","eb968f86":"algo = SVD(n_factors=5,biased=False)\nalgo.fit(trainset)","b2da1277":"# Than predict ratings for all pairs (u, i) that are NOT in the training set.\ntestset = trainset.build_anti_testset()","7f6bf7b2":"testset","753418c3":"predictions = algo.test(testset)","bd9dd55a":"predictions","afd3b245":"top_n = get_top_n(predictions, n=5)","336198e7":"top_n","9da1109a":"# Print the recommended items for each user\nfor uid, user_ratings in top_n.items():\n    print(uid, [iid for (iid, _) in user_ratings])","2a3fefb8":"# compute RMSE\naccuracy.rmse(predictions)","084d0b94":"#User-based Collaborative Filtering\n# Matrix with row per 'user' and column per 'item' \npivot_df = Data_new.pivot(index = 'userId', columns ='productId', values = 'Rating').fillna(0)\npivot_df.shape\npivot_df.head()","7a58b4b6":"pivot_df['user_index'] = np.arange(0, pivot_df.shape[0], 1)\npivot_df.head()","92a02bab":"pivot_df.set_index(['user_index'], inplace=True)\n\n# Actual ratings given by users\npivot_df.head()","2bd85960":"from scipy.sparse.linalg import svds\n# Singular Value Decomposition\nU, sigma, Vt = svds(pivot_df, k = 10)\n# Construct diagonal array in SVD\nsigma = np.diag(sigma)","d7b06394":"all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n\n# Predicted ratings\npreds_df = pd.DataFrame(all_user_predicted_ratings, columns = pivot_df.columns)\npreds_df.head()","1d3cd736":"# Recommend the items with the highest predicted ratings\n\ndef recommend_items(userID, pivot_df, preds_df, num_recommendations):\n      \n    user_idx = userID-1 # index starts at 0\n    \n    # Get and sort the user's ratings\n    sorted_user_ratings = pivot_df.iloc[user_idx].sort_values(ascending=False)\n    #sorted_user_ratings\n    sorted_user_predictions = preds_df.iloc[user_idx].sort_values(ascending=False)\n    #sorted_user_predictions\n\n    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)\n    temp.index.name = 'Recommended Items'\n    temp.columns = ['user_ratings', 'user_predictions']\n    \n    temp = temp.loc[temp.user_ratings == 0]   \n    temp = temp.sort_values('user_predictions', ascending=False)\n    print('\\nBelow are the recommended items for user(user_id = {}):\\n'.format(userID))\n    print(temp.head(num_recommendations))","1af42995":"#Enter 'userID' and 'num_recommendations' for the user #\nuserID = 20\nnum_recommendations = 5\nrecommend_items(userID, pivot_df, preds_df, num_recommendations)","38beb81d":"# Predicted ratings \npreds_df.head()","1fdab531":"# Average PREDICTED rating for each item\npreds_df.mean().head()","d52ee521":"rmse_df = pd.concat([final_ratings_matrix.mean(), preds_df.mean()], axis=1)\nrmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\nprint(rmse_df.shape)\nrmse_df['item_index'] = np.arange(0, rmse_df.shape[0], 1)\nrmse_df.head()","abb9d7d6":"RMSE = round((((rmse_df.Avg_actual_ratings - rmse_df.Avg_predicted_ratings) ** 2).mean() ** 0.5), 5)\nprint('\\nRMSE SVD Model = {} \\n'.format(RMSE))","c860fbe2":"# Enter 'userID' and 'num_recommendations' for the user #\nuserID = 20\nnum_recommendations = 5\nrecommend_items(userID, pivot_df, preds_df, num_recommendations)","217c9df4":"# collaborative Filtering using SVD","c3f2a2e6":"# Try manual way of SVD (optional)\u00b6","2d18f38e":"# #Build Popularity Recommender model. (Non-personalised)\u00b6","33ebe101":"Try with an example of USER id from the above list and see if it matches the same results. ","02d1b82f":"Since this is a popularity-based recommender model, recommendations remain the same for all users which we have given in the input\n\nWe predict the products based on the popularity. It is not personalized to particular user\n","c252401d":"1) Trainset is no longer a pandas dataframe. Rather, it's a specific datatypes defined by the Surprise library\n\n2) UserID and product ID in the pandas dataframe can contain any value (either string\/integer etc). However, Trainset convert these raw ids into numeric indexes called as \"inner id\"\n","6db6ca35":"Domain \u200b- \u200bE-commerce  \n\nContext \u200b- \u200bEveryday a million products are being recommended to users based on popularity and other metrics on e-commerce websites. The most popular e-commerce website boosts average order value by 50%, increases revenues by 300%, and improves conversion. In addition to being a powerful tool for increasing revenues, product recommendations are so essential that customers now expect to see similar features on all other eCommerce sites. \n \nData Description\u200b - Data columns-  First three columns are \u200buserId, productId, and ratings\u200b and the fourth column is timestamp. You can discard the timestamp column as in this case you may not need to use it. \n\n\n Source \u200b- \u200b \u200bAmazon Reviews data (http:\/\/jmcauley.ucsd.edu\/data\/amazon\/)  The repository has several datasets. For this case study, we are using the Electronics dataset.  \n \n Objective \u200b- \u200bTo make a recommendation system that recommends at least five(5) new products based on the user's habits. \n ","3cc6371e":"Model-based Collaborative Filtering is a personalised recommender system, the recommendations are based on the past behavior of the user and it is not dependent on any additional information.\n\nThe Popularity-based recommender system is non-personalised and the recommendations are based on frequecy counts, which may be not suitable to the user.You can see the differance above for the user id 12 & 20, The Popularity based model has recommended the same set of 5 products to both but Collaborative Filtering based model has recommended entire different list based on the user past purchase history\n\nWe will go with the KNN with means recommender system if we have got user rating avaialable and popularity based in case of cold start\n","1c98b353":"# ****collaborative Filtering using KNN****","c7c8e3fc":"#If we see all the recommendations for all the users are the same.. it is not user dependent for one which\n#look for recommendations.\n#The user iD level recommendation and the general recommedation are the same","af4377b7":"Summarise Findings.\n\nModel predicts average rating wherever estimation is not possible\n\nModel-based Collaborative Filtering is a personalised recommender system, the recommendations are based on the past behavior of the user and it is not dependent on any additional information.\n\nThe Popularity-based recommender system is non-personalised and the recommendations are based on frequecy counts, which may be not suitable to the user.\n\nRMSE score for the KNN with Means is better than the SVD model , So we will go with the KNN with means\n\nEstimates Rating of the KNN with means were better than the SVD model\n","7d820fef":"Below is the top 5 recommendations from we got above functions. We can check if this is coming same below A11D1KHM7DVOQK ['B000059L44', 'B00001ZWRV', 'B00000J1G6', 'B00008RS96', 'B00004T8R2']"}}