{"cell_type":{"6f1604a2":"code","7bef19c9":"code","242f6274":"code","955c8eef":"code","eb05846a":"code","00b35894":"code","574e35ed":"code","dccdccca":"code","9bb36ef3":"code","014fea1e":"code","57cf8fdf":"code","252dd836":"code","559569da":"code","4da44ac2":"code","a32958ad":"code","d651b607":"code","003ff0b4":"code","dbf9348c":"code","e7845b88":"code","55fd72d4":"code","ea10d429":"code","8e433b0c":"code","bbac481d":"code","00710a7e":"code","c35cb769":"code","79e73821":"code","2a3e6b80":"code","20d05d88":"code","05629f02":"code","6c4117d3":"code","d54b2393":"code","de0cdcc5":"code","696a6f55":"code","b2d18b02":"code","fc6e7bf8":"code","8e2e8c4a":"code","500c810a":"code","bd4d373a":"code","6d42ef6b":"code","15c8e87f":"code","7faa57ba":"code","ee79ac23":"code","d6dfa63c":"code","1d0a5395":"code","6d85039b":"code","2921744e":"code","e6b7b669":"code","d1e76f2e":"code","0c6fc395":"code","58afd58f":"code","4f507222":"code","bda44a3e":"code","227ead8c":"code","add97903":"code","c61fff6a":"code","be4efa85":"code","cf6c319f":"code","c116ce56":"code","0dd9c4b2":"code","0fa24db1":"code","2f5f85a5":"code","61dd64fd":"code","af859f3a":"code","8f098dfa":"code","f3fce8b3":"code","439cb532":"code","85b68224":"code","a397a901":"code","0833a145":"code","e0ee2bcd":"code","c4c60eac":"code","4e431e27":"code","04775c44":"code","a3a685f2":"code","be5736bd":"code","ca04de79":"code","2919afc9":"code","c43f0529":"code","27d96e5a":"code","bb8c2f61":"code","105fa736":"markdown","80e01522":"markdown","60a455a6":"markdown","6dd4170f":"markdown","b3987787":"markdown","34b2d562":"markdown","1f481b24":"markdown","7792b4a1":"markdown","ee4f0568":"markdown","be6c41c5":"markdown","c9e2bfc8":"markdown","f0f947e3":"markdown","fd7582b4":"markdown","cbbc7274":"markdown","33f6ce7b":"markdown","ae09969c":"markdown","23905270":"markdown","718fde01":"markdown","3e3b7518":"markdown","4202cfc3":"markdown","f56231ce":"markdown","e52cb14c":"markdown","3a81429a":"markdown","3dc5a6b9":"markdown","25533210":"markdown","b2b8bcd5":"markdown","1deee67f":"markdown","791ff49c":"markdown","01bb8e7a":"markdown","e96c1f22":"markdown","3c884ae3":"markdown","12401d74":"markdown","43e5e6b0":"markdown","17b8e1cd":"markdown","05e36455":"markdown","702d1007":"markdown","a24a4430":"markdown","521806f3":"markdown","2cbaa689":"markdown","98ef90cc":"markdown","34604a89":"markdown","3a82a48b":"markdown","ebf93277":"markdown","082909d8":"markdown","ad845f46":"markdown","999e227e":"markdown","e6fa1433":"markdown","cfce9664":"markdown","39b7173c":"markdown","712afbd2":"markdown","b33a2215":"markdown","2d30951a":"markdown","e2c4e8b1":"markdown","910fea9c":"markdown","a355fc9c":"markdown","2deca112":"markdown","f0fad8b2":"markdown","d7e7c434":"markdown"},"source":{"6f1604a2":"!nvidia-smi","7bef19c9":"!nvcc --version","242f6274":"import sys\n!rsync -ah --progress ..\/input\/rapids\/rapids.0.14.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!rsync -ah --progress \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","955c8eef":"import cudf; print('cuDF Version:', cudf.__version__)","eb05846a":"column = cudf.Series([10, 11, 12, 13])\ncolumn","00b35894":"print(column)","574e35ed":"print(column.index)","dccdccca":"new_column = column.set_index([5, 6, 7, 8]) \nprint(new_column)","9bb36ef3":"df = cudf.DataFrame()\nprint(df)","014fea1e":"import numpy as np; print('NumPy Version:', np.__version__)\n\n\n# here we create two columns named \"key\" and \"value\"\ndf['key'] = [0, 1, 2, 3, 4]\ndf['value'] = np.arange(10, 15)\nprint(df)","57cf8fdf":"from datetime import datetime, timedelta\n\n\nids = np.arange(5)\nt0 = datetime.strptime('2018-10-07 12:00:00', '%Y-%m-%d %H:%M:%S')\ntimestamps = [(t0+ timedelta(seconds=x)) for x in range(5)]\ntimestamps_np = np.array(timestamps, dtype='datetime64')","252dd836":"df = cudf.DataFrame()\ndf['ids'] = ids\ndf['timestamp'] = timestamps_np\nprint(df)","559569da":"df = cudf.DataFrame({'id': ids, 'timestamp': timestamps_np})\nprint(df)","4da44ac2":"import pandas as pd; print('Pandas Version:', pd.__version__)\n\n\npandas_df = pd.DataFrame({'a': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n                          'b': [0.0, 0.1, 0.2, None, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]})\nprint(pandas_df)","a32958ad":"df = cudf.from_pandas(pandas_df)\n# df = cudf.DataFrame.from_pandas(pandas_df)  # alternative\nprint(df)","d651b607":"column1 = cudf.Series([1, 2, 3, 4])\ncolumn2 = cudf.Series([5, 6, 7, 8])\ncolumn3 = cudf.Series([9, 10, 11, 12])\ndf = cudf.DataFrame({'a': column1, 'b': column2, 'c': column3})\nprint(df)","003ff0b4":"df = cudf.DataFrame({'a': np.arange(0, 100), 'b': np.arange(100, 0, -1)})","dbf9348c":"df","e7845b88":"print(df)","55fd72d4":"print(df.head())","ea10d429":"print(df.columns)","8e433b0c":"df.columns = ['c', 'd']\nprint(df.columns)","bbac481d":"print(df.dtypes)","00710a7e":"df['c'] = df['c'].astype(np.float32)\ndf['d'] = df['d'].astype(np.int32)\nprint(df.dtypes)","c35cb769":"print(type(df['c']))\nprint(df['c'])","79e73821":"df.index","2a3e6b80":"print(df[df.index == 2])","20d05d88":"pandas_df = df.to_pandas()\nprint(type(pandas_df))","05629f02":"numpy_array = df.to_pandas().values\nprint(type(numpy_array))","6c4117d3":"df.to_pandas().to_csv('.\/dataset.csv', index=False)","d54b2393":"df = cudf.read_csv('.\/dataset.csv')\nprint(df)","de0cdcc5":"df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.float32), \n                     'b': np.arange(100, 0, -1).astype(np.float32)})","696a6f55":"print(df[0:5])","b2d18b02":"print(df['a'])\n# print(df.a)  # alternative","fc6e7bf8":"print(df[['a', 'b']])","8e2e8c4a":"print(df.loc[0:5, ['a']])\n# print(df.loc[0:5, ['a', 'b']])  # to select multiple columns, pass in multiple column names","500c810a":"df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.float32), \n                     'b': np.arange(100, 0, -1).astype(np.float32), \n                     'c': np.arange(100, 200).astype(np.float32)})","bd4d373a":"df['d'] = np.arange(200, 300).astype(np.float32)\n\nprint(df)","6d42ef6b":"data = np.arange(300, 400).astype(np.float32)\ndf.add_column('e', data)\n\nprint(df)","15c8e87f":"df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.float32), \n                     'b': np.arange(100, 0, -1).astype(np.float32), \n                     'c': np.arange(100, 200).astype(np.float32)})","7faa57ba":"df.drop_column('a')\nprint(df)","ee79ac23":"df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.float32), \n                     'b': np.arange(100, 0, -1).astype(np.float32), \n                     'c': np.arange(100, 200).astype(np.float32)})","d6dfa63c":"new_df = df.drop('a')\n\nprint('Original DataFrame:')\nprint(df)\nprint(79 * '-')\nprint('New DataFrame:')\nprint(new_df)","1d0a5395":"new_df = df.drop(['a', 'b'])\n\nprint('Original DataFrame:')\nprint(df)\nprint(79 * '-')\nprint('New DataFrame:')\nprint(new_df)","6d85039b":"df = cudf.DataFrame({'a': [0, None, 2, 3, 4, 5, 6, 7, 8, None, 10],\n                     'b': [0.0, 0.1, 0.2, None, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], \n                     'c': [0.0, 0.1, None, None, 0.4, 0.5, None, 0.7, 0.8, 0.9, 1.0]})\nprint(df)","2921744e":"df['c'] = df['c'].fillna(999)\nprint(df)","e6b7b669":"new_df = df.fillna(-1)\nprint(new_df)","d1e76f2e":"df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                     'b': np.random.randint(2, size=100).astype(np.int32), \n                     'c': np.arange(0, 100).astype(np.int32), \n                     'd': np.arange(100, 0, -1).astype(np.int32)})","0c6fc395":"mask = df['a'] == 3\nmask","58afd58f":"df[mask]","4f507222":"df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                     'b': np.random.randint(2, size=100).astype(np.int32), \n                     'c': np.arange(0, 100).astype(np.int32), \n                     'd': np.arange(100, 0, -1).astype(np.int32)})\nprint(df.head())","bda44a3e":"print(df.sort_values('d').head())","227ead8c":"print(df.sort_values('c', ascending=False).head())","add97903":"print(df.sort_values(['a', 'b']).head())","c61fff6a":"print('Sort with all columns specified descending:')\nprint(df.sort_values(['a', 'b'], ascending=False).head())\nprint(79 * '-')\nprint('Sort with both a descending and b ascending:')\nprint(df.sort_values(['a', 'b'], ascending=[False, True]).head())","be4efa85":"df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                     'b': np.random.randint(2, size=100).astype(np.int32), \n                     'c': np.arange(0, 100).astype(np.int32), \n                     'd': np.arange(100, 0, -1).astype(np.int32)})","cf6c319f":"df['a'].sum()","c116ce56":"print(df.sum())","0dd9c4b2":"df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                     'b': np.random.randint(2, size=100).astype(np.int32), \n                     'c': np.arange(0, 100).astype(np.int32), \n                     'd': np.arange(100, 0, -1).astype(np.int32)})","0fa24db1":"def add_ten_to_x(x):\n    return x + 10\n\nprint(df['c'].applymap(add_ten_to_x))","2f5f85a5":"df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                     'b': np.random.randint(2, size=100).astype(np.int32), \n                     'c': np.arange(0, 100).astype(np.int32), \n                     'd': np.arange(100, 0, -1).astype(np.int32)})","61dd64fd":"result = df['a'].value_counts()\nprint(result)","af859f3a":"df1 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                      'b': np.random.randint(2, size=100).astype(np.int32), \n                      'c': np.arange(0, 100).astype(np.int32), \n                      'd': np.arange(100, 0, -1).astype(np.int32)})\ndf2 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                      'b': np.random.randint(2, size=100).astype(np.int32), \n                      'c': np.arange(0, 100).astype(np.int32), \n                      'd': np.arange(100, 0, -1).astype(np.int32)})","8f098dfa":"df = cudf.concat([df1, df2], axis=0)\ndf","f3fce8b3":"df1 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                      'b': np.random.randint(2, size=100).astype(np.int32), \n                      'c': np.arange(0, 100).astype(np.int32), \n                      'd': np.arange(100, 0, -1).astype(np.int32)})\ndf2 = cudf.DataFrame({'e': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                      'f': np.random.randint(2, size=100).astype(np.int32), \n                      'g': np.arange(0, 100).astype(np.int32), \n                      'h': np.arange(100, 0, -1).astype(np.int32)})","439cb532":"df = cudf.concat([df1, df2], axis=1)\ndf","85b68224":"df1 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                      'b': np.random.randint(2, size=100).astype(np.int32), \n                      'c': np.arange(0, 100).astype(np.int32), \n                      'd': np.arange(100, 0, -1).astype(np.int32)})\ndf2 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                      'b': np.random.randint(2, size=100).astype(np.int32), \n                      'e': np.arange(0, 100).astype(np.int32), \n                      'f': np.arange(100, 0, -1).astype(np.int32)})","a397a901":"df = df1.merge(df2)\nprint(df.head())","0833a145":"df = df1.merge(df2, on=['a'])\nprint(df.head())","e0ee2bcd":"df = df1.merge(df2, on=['a', 'b'])\nprint(df.head())","c4c60eac":"df = cudf.merge(df1, df2)\nprint(df.head())","4e431e27":"df = cudf.merge(df1, df2, on=['a'])\nprint(df.head())","04775c44":"df = cudf.merge(df1, df2, on=['a', 'b'])\nprint(df.head())","a3a685f2":"df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n                     'b': np.random.randint(2, size=100).astype(np.int32), \n                     'c': np.arange(0, 100).astype(np.int32), \n                     'd': np.arange(100, 0, -1).astype(np.int32)})\nprint(df.head())","be5736bd":"grouped_df = df.groupby('a')\nprint(grouped_df)","ca04de79":"aggregation = grouped_df.sum()\nprint(aggregation)","2919afc9":"aggregation = df.groupby(['a', 'b']).sum()\nprint(aggregation)","c43f0529":"categories = [0, 1, 2, 3]\ndf = cudf.DataFrame({'a': np.repeat(categories, 25).astype(np.int32), \n                     'b': np.arange(0, 100).astype(np.int32), \n                     'c': np.arange(100, 0, -1).astype(np.int32)})\nprint(df.head())","27d96e5a":"result = df.one_hot_encoding('a', prefix='a_', cats=categories)\nprint(result.head())\nprint(result.tail())","bb8c2f61":"result = df.one_hot_encoding('a', prefix='a_', cats=[0, 1, 2])\nprint(result.head())\nprint(result.tail())","105fa736":"We see that our `Series` object has four rows with values 10, 11, 12, and 13. We also see that the type of this data is `int64`. There are several ways to represent data using cuDF. The most common formats are `int8`, `int32`, `int64`, `float32`, and `float64`.\n\nWe also see a column of values on the left hand side with values 0, 1, 2, 3. These values represent the index of the `Series`. ","80e01522":"#### Applymap Operations\n\nWhile cuDF allows us to define new columns in interesting ways, we often want to work with more complex functions. We can define a function and use the `applymap` method to apply this function to each value in a column in element-wise fashion. While the below example is simple, it can be very easily extended to more complex workflows.","60a455a6":"#### One Hot Encoding\n\nData scientists often work with discrete data such as integers or categories. However, this data can be represented using a One Hote Encoding format.\n\ncuDF allows us to convert these discrete datas to a One Hot Encoding format using the `one_hot_encoding` method. We can pass this method the column name to convert, a prefix with which to prepend to each newly created column, and the categories of data to create new columns for. We can pass in all the categories in the discrete data or a subset - cuDF will flexibly handle both and only create new columns for the categories specified.","6dd4170f":"<a id=\"series\"><\/a>\n## cuDF Series Basics\n\nFirst, let's load the cuDF library.","b3987787":"We can also select multiple columns by passing in a list of column names.","34b2d562":"We can also specify which of those columns should be sorted in ascending or descending order by passing in a list of boolean values, where each boolean value maps to each column, respectively.","1f481b24":"#### Writing and Loading CSV Files\n\nAt this time, there is no direct way to use to cuDF to write directly to CSV. However, we can conver the cuDF DataFrame to a Pandas DataFrame and then write it directly to a CSV.","7792b4a1":"<a id=\"setup\"><\/a>\n## Setup and install RAPIDs\n\n","ee4f0568":"#### Defining New Columns\n\nWe often want to define new columns from existing columns.","be6c41c5":"A second way to inspect a cuDF DataFrame is to wrap the object in a Python `print` function. This results in showing the rows and columns of the dataframe.","c9e2bfc8":"We can use the index values to subset the `DataFrame`.","f0f947e3":"#### Series\n\ncuDF DataFrames are composed of rows and columns. Each column is represented using an object of type `Series`. For example, if we subset a cuDF DataFrame using just one column we will be returned an object of type `cudf.dataframe.series.Series`.","fd7582b4":"#### Converting a cudf DataFrame to Other Data Formats\n\nWe can also convert a cuDF DataFrame to other data formats. \n\nFor more information, see the documentation: https:\/\/docs.rapids.ai\/api\/cudf\/stable\/api.html#dataframe","cbbc7274":"#### Selecting Rows or Columns\n\nWe can select rows from a cuDF DataFrame using slicing syntax. ","33f6ce7b":"#### Groupbys\n\nA useful operation when working with datasets is to group the data using a specific key and aggregate the values mapping to those keys. For example, we might want to aggregate multiple temperature measurements taken during a day from a specific sensor and average those measurements to find avergage daily temperature at a specific geolocation.\n\ncuDF allows us to perform such an operation using the `groupby` method. This will create an object of type `cudf.groupby.groupby.Groupby` that we can operate on using aggregation functions such as `sum`, `var`, or complex aggregation functions defined by the user.\n\nWe can also specify multiple columns to group on by passing a list of column names to the `groupby` method.","ae09969c":"Next, let's see what CUDA version we have:","23905270":"Next, we can create two columns named `key` and `value` by using the bracket notation with the cuDF DataFrame and storing either a list of Python values or a NumPy array into that column.","718fde01":"#### Boolean Indexing\n\nWe previously saw how we can select certain rows from our dataset by using the bracket `[]` notation. However, we may want to select rows based on a certain criteria - this is called boolean indexing. We can combine the indexing notation with an array of boolean values to select only certain rows that meet this criteria.","3e3b7518":"#### Missing Data\n\nSometimes data is not as clean as we would like it - often there wrong values or values that are missing entirely. cuDF DataFrames can represent missing values using the Python `None` keyword.","4202cfc3":"#### Sorting Data\n\nData is often not sorted before we start to work with it. Sorting data is is very useful for optimizing operations like joins and aggregations, especially when the data is distributed.\n\nWe can sort data in cuDF using the `sort_values` method and passing in which column we want to sort by. ","f56231ce":"We can also specify if the column we're sorting should be sorted in ascending or descending order by using the `ascending` argument and passing in `True` or `False`.","e52cb14c":"<a id=\"io\"><\/a>\n## Input\/Output\n\nBefore we process data and use it in machine learning models, we need to be able to load it into memory and write it after we're done using it. There are several ways to do this using cuDF.","3a81429a":"#### Creating a cudf DataFrame from a Pandas DataFrame\n\nPandas DataFrames are a first class citizen within cuDF - this means that we can create a cuDF DataFrame from a Pandas DataFrame and vice versa.","3dc5a6b9":"<a id=\"dataframes\"><\/a>\n## cuDF DataFrame Basics\n\nAs we showed in the previous tutorial, cuDF DataFrames are a tabular structure of data that reside on the GPU. We interface with these cuDF DataFrames in the same way we interface with Pandas DataFrames that reside on the CPU - with a few deviations.\n\nIn the next several sections, we'll show how to create and manipulate cuDF DataFrames. For more information on using cuDF DataFrames, check out the documentation: https:\/\/docs.rapids.ai\/api\/cudf\/stable\/","25533210":"#### Statistical Operations\n\nThere are several statistical operations we can use to aggregate our data in meaningful ways. These can be applied to both `Series` and `DataFrame` objects.","b2b8bcd5":"<a id=\"introduction\"><\/a>\n## Introduction to cuDF\n#### by Paul Hendricks\n#### modified by Beniel Thileepan \n-------\n\nThis work is modified inorder to run in Kaggle with additional rapids dataset.\n\nIn this notebook, we will show how to work with cuDF DataFrames in RAPIDS.\n\n**Table of Contents**\n\n* [Introduction to cuDF](#introduction)\n* [Setup](#setup)\n* [cuDF Series Basics](#series)\n* [cuDF DataFrame Basics](#dataframes)\n* [Input\/Output](#io)\n* [cuDF API](#cudfapi)\n* [Conclusion](#conclusion)","1deee67f":"We can modify the columns of a cuDF DataFrame by modifying the `columns` attribute. We can do this by setting that attribute equal to a list of strings representing the new columns.","791ff49c":"Perhaps one of the most common ways to create cuDF DataFrames is by loading a table that is stored as a file on disk. cuDF provides a lot of functionality for reading in a variety of different data formats. Below, we show how easy it is to read in a CSV file:","01bb8e7a":"#### Joins \/ Merges\n\nMultiple dataframes can be joined together using a single (or multiple) column(s). There are two syntaxes for performing joins:\n\n* One can use the `DataFrame.merge` method and pass in another dataframe to join, or\n* One can use the `cudf.merge` function and pass in which dataframes to join.\n\nBoth syntaxes can also be passed a list of column names to an additional keyword argument `on` - this will specify which columns the dataframes should be joined on. If this keyword is not specified, cuDF will by default join using column names that appear in both dataframes.","e96c1f22":"There are two main data structures in cuDF: a `Series` object and a `DataFrame` object. Multiple `Series` objects are used as columns for a `DataFrame`. We'll first explore the `Series` class and build upon that foundation to later introduce how to work with objects of type `DataFrame`.\n\nWe can create a `Series` object using the `cudf.Series` class.","3c884ae3":"<a id=\"conclusion\"><\/a>\n## Conclusion\n\nIn this notebook, we showed how to work with cuDF DataFrames in RAPIDS.\n\nTo learn more about RAPIDS, be sure to check out: \n\n* [Open Source Website](http:\/\/rapids.ai)\n* [GitHub](https:\/\/github.com\/rapidsai\/)\n* [Press Release](https:\/\/nvidianews.nvidia.com\/news\/nvidia-introduces-rapids-open-source-gpu-acceleration-platform-for-large-scale-data-analytics-and-machine-learning)\n* [NVIDIA Blog](https:\/\/blogs.nvidia.com\/blog\/2018\/10\/10\/rapids-data-science-open-source-community\/)\n* [Developer Blog](https:\/\/devblogs.nvidia.com\/gpu-accelerated-analytics-rapids\/)\n* [NVIDIA Data Science Webpage](https:\/\/www.nvidia.com\/en-us\/deep-learning-ai\/solutions\/data-science\/)","12401d74":"We can create a new column with a different index by using the `set_index` method.","43e5e6b0":"Indexes are useful for operations like joins and groupbys.","17b8e1cd":"#### Inspecting a cuDF DataFrame\n\nThere are several ways to inspect a cuDF DataFrame. The first method is to enter the cuDF DataFrame directly into the REPL. This shows us information about the type of the object, and metadata such as the number of rows or columns.","05e36455":"#### Creating a cuDF DataFrame from cuDF Series\n\nWe can create a cuDF DataFrame from one or more cuDF Series objects by passing the Series objects in a dictionary mapping each Series object to a column name.","702d1007":"#### Data Types\n\nWe can also inspect the data types of the columns of a cuDF DataFrame using the `dtypes` attribute.","a24a4430":"We can sort by multiple columns by passing in a list of column names. ","521806f3":"There are several ways to select a column from a cuDF DataFrame.","2cbaa689":"#### Converting a cudf DataFrame to a Pandas DataFrame\n\nWe can convert a cuDF DataFrame back to a Pandas DataFrame using the `to_pandas` method.","98ef90cc":"#### Concatenations\n\nIn everyday data science, we typically work with multiple sources of data and wish to combine these data into a single more meaningful representation. These operations are often called concatenations and joins. We can concatenate two or more dataframes together row-wise or column-wise by passing in a list of the dataframes to be concatenated into the `cudf.concat` function and specifying the axis along which to concatenate these dataframes.\n\nIf we want to concatenate the dataframes row-wise, we can specify `axis=0`. To concatenate column-wise, we can specify `axis=1`.","34604a89":"#### Columns\n\ncuDF DataFrames store metadata such as information about columns or data types. We can access the columns of a cuDF DataFrame using the `.columns` attribute.","3a82a48b":"#### Converting a cudf DataFrame to a NumPy Array\n\nOften we want to work with NumPy arrays. We can convert a cuDF DataFrame to a NumPy array by first converting it to a Pandas DataFrame using the `to_pandas` method followed by accessing the `values` attribute of the Pandas DataFrame.","ebf93277":"#### Index\n\nLike `Series` objects, each `DataFrame` has an index attribute.","082909d8":"We can modify the data types of the columns of a cuDF DataFrame by passing in a cuDF Series with a modified data type. Be warned that silent errors may be introduced from nonsensical type conversations - for example, changing a float to an integer or vice versa.","ad845f46":"We can use the `cudf.from_pandas` or `cudf.DataFrame.from_pandas` functions to create a cuDF DataFrame from a Pandas DataFrame.","999e227e":"#### Histogramming\n\nWe can access the value counts of a column using the `value_counts` method. Note that this is typically used with columns representing discrete data i.e. integers, strings, categoricals, etc. We may not be as interested in the value counts of numerical data e.g. how often the value 2.1 appears. The results of the `value_counts` method can be used with Python plotting libraries like Matplotlib or Seaborn to generate visualizations such as histograms.","e6fa1433":"We see from the output that `column` is an object of type `cudf.Series` and has 4 rows.\n\nAnother way to inspect a `Series` is to use the Python `print` statement.","cfce9664":"<a id=\"cudfapi\"><\/a>\n## cuDF API\n\nThe cuDF API is pleasantly simple and mirrors the Pandas API as closely as possible. In this section, we will explore the cuDF API and show how to perform common data manipulation operations.","39b7173c":"For very large dataframes, we often want to see the first couple rows. We can use the `head` method of a cuDF DataFrame to view the first N rows.","712afbd2":"If we want to remove a column without modifying the original DataFrame, we can use the `drop` method. This method will return a new DataFrame without that column (or columns).","b33a2215":"#### Dropping Columns\n\nAlternatively, we may want to remove columns from our `DataFrame`. We can do so using the `drop_column` method. Note that this method removes a column in-place - meaning that the `DataFrame` we act on will be modified.","2d30951a":"Alternatively, we can create a dictonary of key-value pairs, where each key in the dictionary represents a column name and each value associated with the key represents the values that belong in that column.","e2c4e8b1":"We can also fill in these missing values with another value using the `fillna` method. Both `Series` and `DataFrame` objects implement this method.","910fea9c":"We can also pass in a list of column names to drop.","a355fc9c":"#### Creating a cudf DataFrame using lists\n\nThere are several ways to create a cuDF DataFrame. The easiest of these is to instantiate an empty cuDF DataFrame and then use Python list objects or NumPy arrays to create columns. Below, we create an empty cuDF DataFrame.","2deca112":"CSV files come in many flavors and cuDF tries to be as flexible as possible, mirroring the Pandas API wherever possible. For more information on possible parameters for working with files, see the cuDF IO documentation: \n\nhttps:\/\/rapidsai.github.io\/projects\/cudf\/en\/stable\/api.html#cudf.io.csv.read_csv","f0fad8b2":"#### Creating a cudf DataFrame using a list of tuples or a dictionary\n\nAnother way we can create a cuDF DataFrame is by providing a mapping of column names to column values, either via a list of tuples or by using a dictionary. In the below examples, we create a list of two-value tuples; the first value is the name of the column - for example, `id` or `timestamp` - and the second value is a list of Python objects or Numpy arrays. Note that we don't have to constrain the data stored in our cuDF DataFrames to common data types like integers or floats - we can use more exotic data types such as datetimes or strings. We'll investigate how such data types behave on the GPU a bit later.","d7e7c434":"We can select specific rows and columns using the slicing syntax as well as passing in a list of column names."}}