{"cell_type":{"b4d5fde9":"code","12dd752c":"code","cdb06a48":"code","9ed61437":"code","3378ec64":"code","ba100066":"code","87f5060f":"code","bdbb3c69":"code","80752e93":"code","ef0af72f":"code","5728e430":"code","c219f9b8":"code","9f58d56e":"code","0f5b738c":"code","24ac2015":"code","45bee83d":"code","c43c60f1":"code","0ce86b35":"code","71543da2":"code","58680484":"code","e5ed2063":"code","7eddb2c2":"code","318a2934":"code","f67db1f2":"code","26863a1d":"code","a3e3d461":"code","6ca05e76":"code","ef83f37d":"code","d02e31a1":"code","3233b53f":"code","5aa95443":"code","8f7e073c":"code","3ace2e43":"code","fc674942":"code","6bb29d0b":"code","4fcb70b8":"code","e6585d7a":"code","7b763136":"code","04f39634":"code","3b5052a8":"code","d258532a":"code","5af6a87a":"code","698da9a4":"code","85806aa2":"code","b3d0716a":"code","e4cf1b02":"code","83813cb3":"code","b7baae65":"code","16b623a9":"code","79e9cadd":"code","fae192a9":"code","20d456fd":"code","5d58dab7":"code","a10c1557":"code","c7bfab82":"code","826af51e":"code","485e5212":"markdown"},"source":{"b4d5fde9":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n  print('Not connected to a GPU')\nelse:\n  print(gpu_info)","12dd752c":"from psutil import virtual_memory\nram_gb = virtual_memory().total \/ 1e9\nprint('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n\nif ram_gb < 20:\n  print('Not using a high-RAM runtime')\nelse:\n  print('You are using a high-RAM runtime!')","cdb06a48":"import cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","9ed61437":"from google.colab import drive\ndrive.mount('\/content\/drive')","3378ec64":"! mkdir datasets\n! cp \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/data.zip\" \"\/content\/datasets\"","ba100066":"! unzip 'datasets\/data.zip'","87f5060f":"base_path = 'data\/'\ntrain_image_gen = ImageDataGenerator(rescale=1.\/255., rotation_range=30, shear_range=0.2, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, fill_mode=\"nearest\")\nvalid_data_gen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 32\n\ntrain_flow = train_image_gen.flow_from_directory(\n    base_path + 'train\/',\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True\n)\n\nvalid_flow = valid_data_gen.flow_from_directory(\n    base_path + 'valid\/',\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True\n)","bdbb3c69":"vgg_model = VGG16(weights=None, include_top=False, input_shape = (224,224,3))\n\nlast_layer = vgg_model.get_layer('block5_pool').output\nflat_layer = Flatten(name='flatten')(last_layer)\nfc1 = Dense(4096, activation='relu', name='fc1')(flat_layer)\ndropout1 = Dropout(0.5, name='dropout1')(fc1)\nfc2 = Dense(4096, activation='relu', name='fc2')(dropout1)\ndropout2 = Dropout(0.5, name='dropout2')(fc2)\ndense = Dense(1, activation='sigmoid', name='dense')(dropout2)\n\nmodel = Model(vgg_model.input, dense)","80752e93":"model.compile(\n    optimizer=Adam(learning_rate=0.00001), \n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","ef0af72f":"model.summary()","5728e430":"filepath = \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/checkpoints\/vgg16-checkpoint-loss.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=False, mode='min', save_freq='epoch')","c219f9b8":"train_steps = 14400\/\/batch_size\nvalid_steps = 3600\/\/batch_size","9f58d56e":"history = model.fit(\n    train_flow,\n    epochs=50,\n    steps_per_epoch=train_steps,\n    validation_data=valid_flow,\n    validation_steps=valid_steps,\n    callbacks=[checkpoint]\n)","0f5b738c":"model.save('vgg16-small-epochs=50', save_format='tf')\n! cp -r \"vgg16-small-epochs=50\" \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/trained-models\"","24ac2015":"def plot_loss(epochs, loss, val_loss):\n    plt.plot(epochs, loss, 'bo', label='Training Loss')\n    plt.plot(epochs, val_loss, 'orange', label = 'Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    plt.show()","45bee83d":"def plot_accuracy(epochs, acc, val_acc):\n    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'orange', label = 'Validation accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n    plt.show()","c43c60f1":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","0ce86b35":"plot_loss(range(1, len(loss) + 1), loss, val_loss)","71543da2":"plot_accuracy(range(1, len(loss) + 1), acc, val_acc)","58680484":"history2 = model.fit(\n    train_flow,\n    epochs=100,\n    initial_epoch=50,\n    steps_per_epoch=train_steps,\n    validation_data=valid_flow,\n    validation_steps=valid_steps,\n    callbacks=[checkpoint]\n)","e5ed2063":"model.save('vgg16-small-epochs=100', save_format='tf')\n! cp -r \"vgg16-small-epochs=100\" \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/trained-models\"","7eddb2c2":"acc2 = history2.history['accuracy']\nval_acc2 = history2.history['val_accuracy']\nloss2 = history2.history['loss']\nval_loss2 = history2.history['val_loss']","318a2934":"plot_loss(range(1, len(loss2) + 1), loss2, val_loss2)","f67db1f2":"plot_accuracy(range(1, len(loss2) + 1), acc2, val_acc2)","26863a1d":"history3 = model.fit(\n    train_flow,\n    epochs=125,\n    initial_epoch=100,\n    steps_per_epoch=train_steps,\n    validation_data=valid_flow,\n    validation_steps=valid_steps,\n    callbacks=[checkpoint]\n)","a3e3d461":"model.save('vgg16-small-epochs=125', save_format='tf')\n! cp -r \"vgg16-small-epochs=125\" \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/trained-models\"","6ca05e76":"acc3 = history3.history['accuracy']\nval_acc3 = history3.history['val_accuracy']\nloss3 = history3.history['loss']\nval_loss3 = history3.history['val_loss']","ef83f37d":"plot_loss(range(1, len(loss3) + 1), loss3, val_loss3)","d02e31a1":"plot_accuracy(range(1, len(loss3) + 1), acc3, val_acc3)","3233b53f":"base_path = 'data\/'\ntrain_image_gen = ImageDataGenerator(rescale=1.\/255., rotation_range=30, shear_range=0.2, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, fill_mode=\"nearest\")\nvalid_data_gen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 32\n\ntrain_flow = train_image_gen.flow_from_directory(\n    base_path + 'train\/',\n    target_size=(299, 299),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True\n)\n\nvalid_flow = valid_data_gen.flow_from_directory(\n    base_path + 'valid\/',\n    target_size=(299, 299),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True\n)","5aa95443":"base_model = InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=None)\nx = layers.Flatten()(base_model.output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense(1, activation='sigmoid')(x)\nmodel = Model(base_model.input, x, name='inception_v3')","8f7e073c":"model.compile(\n    optimizer=RMSprop(learning_rate=0.0001), \n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","3ace2e43":"model.summary()","fc674942":"filepath = \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/checkpoints\/inceptionv3-checkpoint-loss.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=False, mode='min', save_freq='epoch')","6bb29d0b":"train_steps = 14400\/\/batch_size\nvalid_steps = 3600\/\/batch_size","4fcb70b8":"history = model.fit(\n    train_flow,\n    epochs=50,\n    steps_per_epoch=train_steps,\n    validation_data=valid_flow,\n    validation_steps=valid_steps,\n    callbacks=[checkpoint]\n)","e6585d7a":"model.save('inceptionv3-small-epochs=50', save_format='tf')\n! cp -r \"inceptionv3-small-epochs=50\" \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/trained-models\"","7b763136":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","04f39634":"plot_loss(range(1, len(loss) + 1), loss, val_loss)","3b5052a8":"plot_accuracy(range(1, len(loss) + 1), acc, val_acc)","d258532a":"history2 = model.fit(\n    train_flow,\n    epochs=75,\n    initial_epoch=50,\n    steps_per_epoch=train_steps,\n    validation_data=valid_flow,\n    validation_steps=valid_steps,\n    callbacks=[checkpoint]\n)","5af6a87a":"model.save('inceptionv3-small-epochs=75', save_format='tf')\n! cp -r \"inceptionv3-small-epochs=75\" \"\/content\/drive\/My Drive\/Kaggle\/fake-image-classification-challenge\/trained-models\"","698da9a4":"acc2 = history2.history['accuracy']\nval_acc2 = history2.history['val_accuracy']\nloss2 = history2.history['loss']\nval_loss2 = history2.history['val_loss']","85806aa2":"plot_loss(range(1, len(loss2) + 1), loss2, val_loss2)","b3d0716a":"plot_accuracy(range(1, len(loss2) + 1), acc2, val_acc2)","e4cf1b02":"! mkdir models\n\n# fetching the saved model from gdrive\n! cp -r \"\/content\/drive\/MyDrive\/Kaggle\/fake-image-classification-challenge\/checkpoints\/inceptionv3-checkpoint-loss-0.0773-0.9713.h5\" \"\/content\/models\/\"\n! cp -r \"\/content\/drive\/MyDrive\/Kaggle\/fake-image-classification-challenge\/checkpoints\/vgg16-checkpoint-loss-0.1963-0.9241.h5\" \"\/content\/models\/\"\n\n# loading the saved model\nloaded_model_1 = tf.keras.models.load_model('\/content\/models\/inceptionv3-checkpoint-loss-0.0773-0.9713.h5')\nloaded_model_2 = tf.keras.models.load_model('\/content\/models\/vgg16-checkpoint-loss-0.1963-0.9241.h5')","83813cb3":"valid_data_gen = ImageDataGenerator(rescale=1.\/255)","b7baae65":"valid_flow_1 = valid_data_gen.flow_from_directory(\n    base_path + 'valid\/',\n    target_size=(299, 299),\n    batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary'\n)","16b623a9":"y_pred_1 = loaded_model_1.predict(valid_flow_1)\ny_test = valid_flow_1.classes\nprint(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred_1))\nprint(\"AP Score:\", metrics.average_precision_score(y_test, y_pred_1))\nprint(metrics.classification_report(y_test, y_pred_1 >= 0.5))","79e9cadd":"valid_flow_2 = valid_data_gen.flow_from_directory(\n    base_path + 'valid\/',\n    target_size=(224, 224),\n    batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary'\n)","fae192a9":"y_pred_2 = loaded_model_2.predict(valid_flow_2)\nprint(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred_2))\nprint(\"AP Score:\", metrics.average_precision_score(y_test, y_pred_2))\nprint(metrics.classification_report(y_test, y_pred_2 >= 0.5))","20d456fd":"y_pred = (y_pred_1 + y_pred_2) \/ 2\nprint(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\nprint(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\nprint(metrics.classification_report(y_test, y_pred >= 0.5))","5d58dab7":"test_data_gen = ImageDataGenerator(rescale=1.\/255)","a10c1557":"test_flow_1 = test_data_gen.flow_from_directory(\n    base_path,\n    classes=['test'],\n    class_mode=None,\n    shuffle=False,\n    target_size=(299, 299)\n)","c7bfab82":"test_flow_2 = test_data_gen.flow_from_directory(\n    base_path,\n    classes=['test'],\n    class_mode=None,\n    shuffle=False,\n    target_size=(224, 224)\n)","826af51e":"preds_1 = loaded_model_1.predict(test_flow_1)\npreds_2 = loaded_model_2.predict(test_flow_2)\npreds = (preds_1 + preds_2) \/ 2\npredicted_class = np.where(preds >= 0.5, \"real\", \"fake\")\ntest_data=pd.read_csv(base_path + \"test.csv\")\ntest_data['label'] = predicted_class\ntest_data.to_csv(\"Data Alchemists.csv\", index=False)","485e5212":"#### Link to original notebook: https:\/\/colab.research.google.com\/drive\/14ZAJPkeb-f6cp8TjYERGLWlzRrXfnObe?usp=sharing"}}