{"cell_type":{"59e3bb92":"code","9939171e":"code","b1c128ab":"code","cb7741b5":"code","361bc1a4":"code","5f6247e5":"code","71ed22f8":"code","11067fe7":"code","bccfe2bb":"code","11fa3af0":"code","3c3bc505":"code","b04c02e4":"code","9d477ae4":"code","3c9973a8":"code","2a1cea7f":"code","c01c7513":"code","f04e2a43":"code","781962a6":"code","dcfbb627":"code","83bc4c0a":"code","b3a456f5":"code","c799f971":"code","8e78413d":"code","39912944":"markdown","54914d7d":"markdown","1658315c":"markdown","f031d339":"markdown","3fe547ad":"markdown","f36da526":"markdown","7076ac3b":"markdown","4a2b3568":"markdown","7dd7b9f5":"markdown","3df5d1cc":"markdown","256ea19f":"markdown","323d4053":"markdown","2036bfb9":"markdown","5c9f3667":"markdown","db8d9827":"markdown","20ade778":"markdown","976bc908":"markdown","9fc25d06":"markdown","69f0babf":"markdown","cee6e0c4":"markdown","4e297927":"markdown","1e27d071":"markdown","0241b1fd":"markdown","e867486a":"markdown","21665309":"markdown","38547731":"markdown"},"source":{"59e3bb92":"# Importing the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom textblob import TextBlob  \nfrom bs4 import BeautifulSoup\nimport re\nfrom wordcloud import WordCloud, STOPWORDS\nimport networkx as nx          \nimport nltk\nfrom nltk.corpus import stopwords\nimport itertools\nimport collections\nfrom nltk import bigrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.cluster import KMeans\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/demonetization-tweets.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9939171e":"tweets = pd.read_csv('..\/input\/demonetization-tweets.csv', encoding = \"ISO-8859-1\")\ntweets.head()","b1c128ab":"tweets.shape","cb7741b5":"display(tweets.text.head(10))","361bc1a4":"print(tweets['retweetCount'])","5f6247e5":"def clean(x):\n    #Remove Html  \n    x=BeautifulSoup(x).get_text()\n    \n    #Remove Non-Letters\n    x=re.sub('[^a-zA-Z]',' ',x)\n    \n    #Convert to lower_case and split\n    x=x.lower().split()\n    \n    #Remove stopwords\n    stop=set(stopwords.words('english'))\n    words=[w for w in x if not w in stop]\n    \n    #join the words back into one string\n    return(' '.join(words))\ntweets['text']=tweets['text'].apply(lambda x:clean(x))","71ed22f8":"# tweets.head()\ndisplay(tweets.text.head(10))","11067fe7":"words_in_tweet = [tweets.lower().split() for tweets in tweets.text]\nwords_in_tweet[0]","bccfe2bb":"stop_words = set(stopwords.words('english'))\n\n# View a few words from the set\nlist(stop_words)[0:10]\n","11fa3af0":"tweets_nsw = [[word for word in tweet_words if not word in stop_words]\n              for tweet_words in words_in_tweet]\ntweets_nsw[0]","3c3bc505":"all_words_nsw = list(itertools.chain(*tweets_nsw))\n\ncounts_nsw = collections.Counter(all_words_nsw)\n\ncounts_nsw.most_common(15)","b04c02e4":"clean_tweets_nsw = pd.DataFrame(counts_nsw.most_common(15),\n                             columns=['words', 'count'])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot horizontal bar graph\nclean_tweets_nsw.sort_values(by='count').plot.barh(x='words',\n                      y='count',\n                      ax=ax,\n                      color=\"green\")\n\nax.set_title(\"Common Words Found in Tweets (Without Stop Words)\")\n\nplt.show()","9d477ae4":"collection_words = ['rt', 'co', 'http', 'https', 'j', 'k']\ntweets_nsw_nc = [[w for w in word if not w in collection_words]\n                 for word in tweets_nsw]\ntweets_nsw_nc[0]","3c9973a8":"terms_bigram = [list(bigrams(tweet)) for tweet in tweets_nsw_nc]\nterms_bigram[0]","2a1cea7f":"# Flatten list of bigrams in clean tweets\nbigrams = list(itertools.chain(*terms_bigram))\n\n# Create counter of words in clean bigrams\nbigram_counts = collections.Counter(bigrams)\n\nbigram_counts.most_common(20)","c01c7513":"#Top 20 most common bigrams\nbigram_df = pd.DataFrame(bigram_counts.most_common(20),\n                             columns=['bigram', 'count'])\nbigram_df","f04e2a43":"d = bigram_df.set_index('bigram').T.to_dict('records')\nG = nx.Graph()\n# Create connections between nodes\nfor k, v in d[0].items():\n    G.add_edge(k[0], k[1], weight=(v * 3))\n\nfig, ax = plt.subplots(figsize=(12, 10))\n\npos = nx.spring_layout(G, k=4)\n\n# Plot networks\nnx.draw_networkx(G, pos,\n                 font_size=11,\n                 fontweight='bold',\n                 width=2,\n                 edge_color='grey',\n                 node_color='green',\n#                  edge_length = 10,\n                 with_labels = False,\n                 ax=ax)\n\n# Create offset labels\nfor key, value in pos.items():\n    x, y = value[0]+.00167, value[1]+.045\n    ax.text(x, y,\n            s=key,\n            bbox=dict(facecolor='orange', alpha=0.5),\n            horizontalalignment='center', fontsize=10)\n    \nplt.show()","781962a6":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nfrom nltk.corpus import stopwords\nfrom nltk import tokenize\n\nsid = SentimentIntensityAnalyzer()\n\ntweets['sentiment_compound_polarity']=tweets.text.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweets['sentiment_neutral']=tweets.text.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweets['sentiment_negative']=tweets.text.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweets['sentiment_pos']=tweets.text.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweets['sentiment_type']=''\ntweets.loc[tweets.sentiment_compound_polarity>0,'sentiment_type']='Positive'\ntweets.loc[tweets.sentiment_compound_polarity==0,'sentiment_type']='Neutral'\ntweets.loc[tweets.sentiment_compound_polarity<0,'sentiment_type']='Negative'\ntweets.head(3)","dcfbb627":"tweets.sentiment_type.value_counts()","83bc4c0a":"# fig = plt.figure()\n# fig.savefig('Sentiment_bar_plot.pdf')\ncolors = ['green', 'yellow', 'red']\ntweets.sentiment_type.value_counts().plot(kind='bar',figsize=(9, 7),edgecolor='k',title=\"Twitter Sentiment Analysis- Demonetisation (Bar Graph)\", color=colors)\n# plt.savefig('Sentiment_bar_plot.png', dpi=100)","b3a456f5":"colors = ['green', 'yellow', 'red']\nexplode = (0, 0.08, 0.1)\ntweets.sentiment_type.value_counts().plot(kind='pie', figsize=(9, 7), title=\"Twitter Sentiment Analysis- Demonetisation (Pie Graph)\", colors=colors, explode=explode,autopct='%1.1f%%', shadow=False)\n# plt.savefig('Sentiment_pie_plot.png', dpi=100)","c799f971":"tweets['statusSource_new'] = ''\nfor i in range(len(tweets['statusSource'])):\n    m = re.search('(?<=>)(.*)', tweets['statusSource'][i])\n    try:\n        tweets['statusSource_new'][i]=m.group(0)\n    except AttributeError:\n        tweets['statusSource_new'][i]=tweets['statusSource'][i] \n#print(tweets['statusSource_new'].head())   \ntweets['statusSource_new'] = tweets['statusSource_new'].str.replace('<\/a>', ' ', case=False)\ntweets['statusSource_new2'] = ''\n\nfor i in range(len(tweets['statusSource_new'])):\n    if tweets['statusSource_new'][i] not in ['Twitter for Android ','Twitter Web Client ','Twitter for iPhone ']:\n        tweets['statusSource_new2'][i] = 'Others'\n    else:\n        tweets['statusSource_new2'][i] = tweets['statusSource_new'][i] \nprint(tweets['statusSource_new2']) \n\ntweets_by_type2 = tweets.groupby(['statusSource_new2'])['retweetCount'].sum()\ntweets_by_type2.rename(\"\",inplace=True)\nexplode = (0, 0, 0.09, 0)\ntweets_by_type2.transpose().plot(kind='pie',figsize=(9, 7),autopct='%1.1f%%',shadow=False,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=6, borderaxespad=0.)\nplt.title('Number of retweetcount by Source bis', bbox={'facecolor':'0.8', 'pad':5})","8e78413d":"tweets['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweets.text]       \n####\nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweets['text_lem'].str.upper())\nprint(\"Shape of X is: \", X.shape, '\\n')\nprint(\"Clusters are: \", '\\n')\nkm = KMeans(n_clusters=100,init='k-means++',max_iter=200,n_init=1)\nkm.fit(X)\nterms = vectorizer.get_feature_names()\norder_centroids = km.cluster_centers_.argsort()[:,::-1]\nfor i in range(100):\n    print(\"cluster %d:\" %i, end='')\n    for ind in order_centroids[i,:10]:\n        print(' %s' % terms[ind], end='')\n    print() ","39912944":"## Remove some other words which are occuring in almost every tweets","54914d7d":"On 9 November 2016, the Government of India announced the demonetization of all \u20b9500 and \u20b91,000 banknotes of the Mahatma Gandhi Series. It also announced the issuance of new \u20b9500 and \u20b92,000 banknotes in exchange for the demonetised banknotes.The announcement was made by the Prime Minister of India Narendra Modi in an unscheduled live televised address to the nation at 20:15 Indian Standard Time (IST) the same day. In the announcement, Modi declared circulation of all \u20b9500 and \u20b91000 banknotes of the Mahatma Gandhi Series as invalid and announced the issuance of new \u20b9500 and \u20b92000 banknotes of the Mahatma Gandhi New Series in exchange for the old banknotes. This analysis is done on the available twitter dataset from open source. ","1658315c":"## Counting total number of tweets for each category of sentiment\n>> ### We can see numer of tweets having Positive sentiment is 6771, neutral sentiment is 4233 and negative sentiment is 3936","f031d339":"## Source of tweets\n>> ### We can see the source of tweets corresponding to each index of all 14940 tweets\n>> ### From the below pie chart it's clearly visible that, Top 3 of Source: 1 - Twitter For Android 2 - Twitter for Iphones 3 - Twitter for Web Client and finally !","3fe547ad":"## Creating a dataframe for visualization of bigrams","f36da526":"# More yet to come...","7076ac3b":"## Number of retweets for each of the given 14940 tweets with their indexes","4a2b3568":"> # Part 1: Exploratory Analysis and Preprocessing of Data","7dd7b9f5":"## Counting and display top 20 common bi-grams","3df5d1cc":"## For additional clean-up, as to remove words that do not add meaningful information to the text you are trying to analysis. These words referred to as \u201cstop words\u201d and include commonly appearing words such as who, what, you, etc.","256ea19f":"> > # Part 2: Sentiment Analysis","323d4053":"## Visualizing network of bi-grams using networkx package of python","2036bfb9":"## Clusterig using K-means algorithm \n>> ### We can see the shape of X and 100 clusters generated usig above K-means algorithm","5c9f3667":"## Bar Plot for Sentiment Analyis\n>>### We can see Positive sentiment is higher than negative sentiment ","db8d9827":"## Some of the tweet phrases from the dataset without cleaning","20ade778":"## Exploring some co-occuring words usinf bi-grams","976bc908":"## Number of rows and column in the taken dataset","9fc25d06":"## Again, i'm creatig a counter to return the most commonly used words and the number of times that they are used in the tweet","69f0babf":"## Some of the tweets phrases after cleaning ","cee6e0c4":"# ** Part 0: For the analysis we are going firstly to import all of packages and dataset **","4e297927":"## Sentiment plot in forms of Pie chart","1e27d071":"## Now clean the dataset by removing HTML tags using BeautifulSoup, removing non letters present in the tweets and after doing this, split the text and remove the stowords present in the tweets and then rejoin the tweets ","0241b1fd":"## Analysing Positive, Negative and Neutral sentiment","e867486a":"## Create a list of lists containing lowercase words for each tweet","21665309":"## Plotting the word frequencies after removing the stop words","38547731":"## Let's Display our dataset"}}