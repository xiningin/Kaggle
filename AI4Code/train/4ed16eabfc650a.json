{"cell_type":{"12fbb02c":"code","271989a7":"code","5237d095":"code","4a345aa5":"code","0350675b":"code","7cdcc633":"code","6541ffee":"code","4e18368e":"code","d5eca52e":"code","f6f639ed":"code","1df772d8":"code","42c27847":"code","ff9fc137":"code","0f41a4f6":"code","e1f4ef95":"markdown","090c2535":"markdown","fcf62922":"markdown","33b39f93":"markdown","861c893e":"markdown","bf111551":"markdown","2986a8d3":"markdown","e90041d3":"markdown","38bf74f3":"markdown"},"source":{"12fbb02c":"# Libraries\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport itertools\n\nimport seaborn as sns\n\n# Reading dataset\nX =  pd.read_csv(\"..\/input\/train.csv\")\nX_test_main =  pd.read_csv(\"..\/input\/test.csv\")\n\n# Extract label info\ny = X[\"label\"]\n\nX = X.drop(['label'],axis = 1)\n\n# Reshape image matrix\nX = X.values.reshape(-1, 28, 28, 1).astype('float32')\nX_test_main = X_test_main.values.reshape(-1, 28, 28, 1).astype('float32')\n\ny = y.values\n","271989a7":"# Input shape\nX.shape","5237d095":"# Plot label info\n#plt = sns.countplot(y)","4a345aa5":"plt.figure()\nplt.imshow( X[1][:,:,0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","0350675b":"X = X \/ 255.0\nX_test_main = X_test_main \/ 255.0","7cdcc633":"# Train and test dataset split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42,stratify=y)","6541ffee":"model = Sequential()\n    \n# CONV 1\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", strides=(1,1), padding=\"valid\"))\n#model.add(Activation=\"relu\")\n# MAX POOL 1\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding=\"valid\"))\n# NORM 1\nmodel.add(BatchNormalization())\n\n\n# CONV 2\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", strides=(1,1), padding=\"valid\"))\n#model.add(Activation=\"relu\")\n# MAX POOL 2\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding=\"valid\"))\n# NORM 2\nmodel.add(BatchNormalization())\n\n\n# CONV 3\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", strides=(1,1), padding=\"valid\"))\n#model.add(Activation=\"relu\")\n# MAX POOL 3\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding=\"valid\"))\n# NORM 3\nmodel.add(BatchNormalization())\n\n\n# Flatten\nmodel.add(Flatten())\n\n# FC 1\nmodel.add(Dense(units=512, activation=\"relu\"))\n#model.add(Dropout=0.2)\n\n# FC 2\nmodel.add(Dense(units=120, activation=\"relu\"))\n#model.add(Dropout=0.2)\n\n# FC 3\nmodel.add(Dense(units=10, activation = \"softmax\"))","4e18368e":"sgd = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=sgd, metrics=[\"sparse_categorical_accuracy\"])\n\n# ReduceLROnPlateau is a function from keras.callbacks.\n# The following line of code reduces the learning rate by 0.5 if accuracy does not improve after 3 epochs.\nlrr = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","d5eca52e":"# The following traing is based on splitted test and train dataset\n\nresult = model.fit(X_train, \n                   y_train, \n                   batch_size=70, \n                   epochs=20, \n                   verbose=2, \n                   validation_split=0.25, \n                   callbacks=[lrr],\n                   shuffle=True)\n\n'''\nresult = model.fit(X, \n                   y, \n                   batch_size=70, \n                   epochs=3, \n                   verbose=2, \n                   validation_split=0.25, \n                   callbacks=[lrr],\n                   shuffle=True)\n'''","f6f639ed":"# Visualize model summary\nmodel.summary()","1df772d8":"y_pred = model.predict(X_test, verbose = 2)\n#y_pred = model.predict(X_test_main, verbose = 2)\n\ny_pred[:,0]","42c27847":"# Loss and accuracy\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint('Test accuracy:', test_acc)","ff9fc137":"# Plot training and validation accuracy\nacc = result.history['sparse_categorical_accuracy']\nval_acc = result.history['val_sparse_categorical_accuracy']\nepochs = range(len(acc))\nplt.plot(epochs, acc, 'r', label='Training')\nplt.plot(epochs, val_acc, 'b', label='Validation')\nplt.title('Training and validatio set accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","0f41a4f6":"# Before saving output for submission, the model needs to be trained on the full training dataset (not splitted train dataset).\n# Also the predict method needs to be run on X_test_main dataset.\ny_pred = np.argmax(y_pred,axis = 1)\ny_pred = pd.Series(y_pred,name=\"Label\")\ns = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),y_pred],axis = 1)\ns.to_csv(\"output.csv\",index=False)","e1f4ef95":"**Sample train image plotting:**","090c2535":"**2. DESIGNING CNN ARCHITECTURE**\n<br>\nThe CNN architecture is designed using 3 convolution layers and 3 fully connected (FC) layers. The summary of the architecture is given bellow:\n<br>\n<br>\n***CONV 1***\n<br>\n***MAX POOLING 1***\n<br>\n***NORMALIZATION 1***\n<br>\n<br>\n***CONV 2***\n<br>\n***MAX POOLING 2***\n<br>\n***NORMALIZATION 2***\n<br>\n<br>\n***CONV 3***\n<br>\n***MAX POOLING 3***\n<br>\n***NORMALIZATION 3***\n<br>\n<br>\n***FC 1***\n<br>\n***FC 2***\n<br>\n***FC 3 (Softmax)***","fcf62922":"**Data Normalization:**\n<br>\nThe type of pixel value is integer and the range is in between 0 to 255. In order to convert the value 0 to 1 range, we will divide it by 255.","33b39f93":"**4. PREDICT ON TEST DATA**","861c893e":"**Compile the sequential model:**\n<br>\nThe following hyper parameter values are used to compile the generated model.\n<br>\n<br>\nlearning rate=0.001<br>\nweight decay=1e-6<br>\nmomentum=0.9","bf111551":"**3. TRAINING THE NETWORKS**\n<br>\nThe following hyper parameter values are used to train the neural networks:\n<br>\n<br>\nbatch_size=40\n<br>\nepochs=20\n<br>\nverbose = 2\n<br>\nvalidation_split=0.25","2986a8d3":"**PROBLEM OVERVIEW:**\n<br>\nThe Digit Recognizer is a multi-class classification problem. The data files train.csv and test.csv contain 28*28 pixels gray scale images.\nWe will approach the problem in six major steps: \n1. Dataset import and pre-processing\n2. Designing CNN architecture\n3. Training the networks\n4. Predict on test dataset\n5. Plotting necessary diagrams\n6. Saving output\n\n<br>\n**1. DATASET IMPORT AND PRE-PROCESSING**","e90041d3":"**5. PLOTTING**","38bf74f3":"**6. SAVE OUTPUT**"}}