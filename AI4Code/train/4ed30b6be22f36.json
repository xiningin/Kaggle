{"cell_type":{"5f299ffb":"code","64c5d37f":"code","da08837f":"code","db0fa0fd":"code","6b11153a":"code","2ebe5100":"code","888f3f7c":"code","e7af95c9":"code","fa8bef21":"code","5d82d028":"code","8e83794b":"code","b4921b26":"code","96a44233":"code","bd95b514":"code","64ec7dd9":"code","dd8d48ed":"code","29e1c6ca":"code","2119ff40":"markdown","50fd3a60":"markdown","62133279":"markdown","89793f19":"markdown","b3bc4ec7":"markdown","7d3efadb":"markdown","9907467f":"markdown","727b3006":"markdown","12678753":"markdown","865b2904":"markdown","5410eeb4":"markdown","ee50febc":"markdown","069879c9":"markdown","978ec600":"markdown","9898126b":"markdown","5d18b4cc":"markdown","c21ec618":"markdown","8c11b13f":"markdown","fe24d501":"markdown"},"source":{"5f299ffb":"!pip install -U -t \/kaggle\/working\/ git+https:\/\/github.com\/Kaggle\/learntools.git\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning.ex_tpu import *\nstep_1.check()","64c5d37f":"from petal_helper import *","da08837f":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","db0fa0fd":"ds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","6b11153a":"print(\"Number of classes: {}\".format(len(CLASSES)))\n\nprint(\"First five classes, sorted alphabetically:\")\nfor name in sorted(CLASSES)[:5]:\n    print(name)\n\nprint (\"Number of training images: {}\".format(NUM_TRAINING_IMAGES))","2ebe5100":"print(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())","888f3f7c":"print(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","e7af95c9":"one_batch = next(iter(ds_train.unbatch().batch(20)))\ndisplay_batch_of_images(one_batch)","fa8bef21":"with strategy.scope():\n#     pretrained_model = tf.keras.applications.VGG16(\n#         weights='imagenet',\n#         include_top=False ,\n#         input_shape=[*IMAGE_SIZE, 3]\n#     )\n    pretrained_model =   tf.keras.applications.Xception(\n            include_top=False, weights='imagenet', input_shape=[*IMAGE_SIZE, 3]\n        )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    model.compile(\n        optimizer='adam',\n        loss = 'sparse_categorical_crossentropy',\n        metrics=['sparse_categorical_accuracy'],\n    )\n\nmodel.summary()","5d82d028":"# Define the batch size. This will be 16 with TPU off and 128 with TPU on\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\n# Define training epochs for committing\/submitting. (TPU on)\nEPOCHS = 12\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","8e83794b":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","b4921b26":"cmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T \/ cmat.sum(axis=1)).T # normalize","96a44233":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","bd95b514":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","64ec7dd9":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","dd8d48ed":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","29e1c6ca":"print('Generating submission.csv file...')\n\n# Get image ids from test set and convert to integers\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n\n# Write the submission file\nnp.savetxt(\n    'submission.csv',\n    np.rec.fromarrays([test_ids, predictions]),\n    fmt=['%s', '%d'],\n    delimiter=',',\n    header='id,label',\n    comments='',\n)\n\n# Look at the first few predictions\n!head submission.csv","2119ff40":"# Dataset summary\n\nWe're classifying 104 types of flowers based on their images drawn from five different public datasets. Some classes are very narrow, containing only a particular sub-type of flower (e.g. pink primroses) while other classes contain many sub-types (e.g. wild roses).\n\nThe dataset contains imperfections - images of flowers in odd places, or as a backdrop to modern machinery. We need to build a classifier than can see past all that, to the flowers at the heart of the images.","50fd3a60":"## Test Predictions ##\n\nCreate predictions to submit to the competition.","62133279":"# Going Further #\n\nNow that you've joined the **Petals to the Metal** competition, why not try your hand at improving the model and see if you can climb the ranks! If you're looking for ideas, the *original* flower competition, [Flower Classification with TPUs](https:\/\/www.kaggle.com\/c\/flower-classification-with-tpus), has a wealth of information in its notebooks and discussion forum. Check it out!","89793f19":"Peek at training data.","b3bc4ec7":"Examine training curves.","7d3efadb":"## Explore the Data ##","9907467f":"## Define Model #","727b3006":"# TPU 101\n\nTPUs read data from Google Cloud Storage (GCS) buckets.","12678753":"## Validation ##\n\nCreate a confusion matrix.","865b2904":"# Introduction\n\nIt\u2019s difficult to fathom just how vast and diverse our natural world is.\n\nThere are over 5,000 species of mammals, 10,000 species of birds, 30,000 species of fish \u2013 and astonishingly, over 400,000 different types of flowers.\n\nIn this competition, we\u2019re challenged to build a machine learning model that identifies the 104 types of flowers in a dataset of images.\n\nWe will use this competition as a 101 kaggle notebook to perform transfer learning using TPU. ","5410eeb4":"## Loading the Competition Data ##","ee50febc":"---\n**[Deep Learning Home Page](https:\/\/www.kaggle.com\/learn\/deep-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/161321) to chat with other Learners.*","069879c9":"## Create Distribution Strategy ##","978ec600":"# Acknowledgments\n\nThank you to everyone in the discussion forum : https:\/\/www.kaggle.com\/c\/tpu-getting-started\/discussion","9898126b":"# Objective\nWe have to predict the type of flower. The predictions are evaluated using [macro F1 score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.f1_score.html). ","5d18b4cc":"Look at examples from the dataset, with true and predicted classes.","c21ec618":"Examine the shape of the data.","8c11b13f":"We have 12753 training images, 3712 validation images, 7382 unlabeled test images","fe24d501":"## Train Model ##"}}