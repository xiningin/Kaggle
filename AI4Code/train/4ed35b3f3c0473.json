{"cell_type":{"69170c0b":"code","8d4bd63a":"code","c9253b26":"code","7903479f":"code","da188076":"code","4a83a8f4":"code","3ef53e4e":"code","e2115237":"code","5cdbf5d6":"code","1253b381":"code","a970de78":"code","c73427af":"code","f9d9ad5a":"code","3a039660":"code","6e2215b5":"code","3cc22616":"code","c4b15ae1":"code","c0d866d1":"markdown","c5b50e90":"markdown","158119b6":"markdown","c8733d0b":"markdown","74385cd6":"markdown","1f0e16bc":"markdown","f81f8fba":"markdown","ba556133":"markdown","b2c1794a":"markdown","ec34dca6":"markdown","7648b7e3":"markdown"},"source":{"69170c0b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\npd.set_option('display.max_columns', 50)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8d4bd63a":"train_df = pd.read_csv(\"..\/input\/tmu-inclass-competition\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/tmu-inclass-competition\/test.csv\")\nsub_df = pd.read_csv(\"..\/input\/tmu-inclass-competition\/sample_submission.csv\")","c9253b26":"print(f\"{len(train_df)} {len(test_df)}\")","7903479f":"from sklearn.preprocessing import LabelEncoder\n\ncat_list = [\"jurisdiction_names\", \"country_code\", \"smart_location\", \"property_type\", \"host_id\", \"host_response_time\", \"room_type\"]\n\ndef preprocess(train_df, test_df):\n    new_df = pd.concat([train_df, test_df]).reset_index(drop=True)\n\n    d = {}\n    for s in new_df[\"calendar_updated\"].value_counts().index:\n        if s == \"today\":\n            d[s] = 0\n        elif s == \"yesterday\":\n            d[s] = 1\n        elif s == \"a week ago\" or s == \"1 week ago\":\n            d[s] = 7\n        elif s == \"never\":\n            d[s] = 9999\n        elif s[-len(\"months ago\"):] == \"months ago\":\n            d[s] = int(s[:-len(\"months ago\")]) * 30\n        elif s[-len(\"weeks ago\"):] == \"weeks ago\":\n            d[s] = int(s[:-len(\"weeks ago\")]) * 7\n        elif s[-len(\"days ago\"):] == \"days ago\":\n            d[s] = int(s[:-len(\"days ago\")])\n        else:\n            print(s)\n            print(\"Error\")\n            break\n\n    oldest = min(pd.to_datetime(new_df[\"host_since\"]))\n    newest = max(pd.to_datetime(new_df[\"host_since\"]))\n    dt = newest - oldest\n\n    processed_train_df = train_df.select_dtypes(\"number\").drop(\"listing_id\", axis=1)\n    processed_train_df[\"host_since\"] = pd.to_datetime(train_df[\"host_since\"])\n    processed_train_df[\"host_since\"] = processed_train_df[\"host_since\"].apply(lambda x: (x - oldest)\/dt * 100)\n    processed_train_df[\"calendar_updated\"] = train_df[\"calendar_updated\"].apply(lambda x: d[x])\n    processed_train_df[\"host_response_rate\"] = train_df[\"host_response_rate\"].fillna(\"0%\").apply(lambda x: int(x[:-1]))\n    processed_train_df = pd.concat([processed_train_df, pd.get_dummies(train_df[\"bed_type\"])], axis=1, join='inner')\n    processed_train_df = pd.concat([processed_train_df, pd.get_dummies(train_df[\"cancellation_policy\"])], axis=1, join='inner')\n    \n\n    processed_test_df = test_df.select_dtypes(\"number\").drop(\"listing_id\", axis=1)\n    processed_test_df[\"host_since\"] = pd.to_datetime(test_df[\"host_since\"])\n    processed_test_df[\"host_since\"] = processed_test_df[\"host_since\"].apply(lambda x: (x - oldest)\/dt * 100)\n    processed_test_df[\"calendar_updated\"] = test_df[\"calendar_updated\"].apply(lambda x: d[x])\n    processed_test_df[\"host_response_rate\"] = test_df[\"host_response_rate\"].fillna(\"0%\").apply(lambda x: int(x[:-1]))\n    processed_test_df = pd.concat([processed_test_df, pd.get_dummies(test_df[\"bed_type\"])], axis=1, join='inner')\n    processed_test_df = pd.concat([processed_test_df, pd.get_dummies(test_df[\"cancellation_policy\"])], axis=1, join='inner')\n\n    # one-hot\n    for col in [\"host_is_superhost\", \"host_has_profile_pic\", \"host_identity_verified\", \"is_location_exact\", \"has_availability\", \"requires_license\"\\\n                , \"instant_bookable\", \"is_business_travel_ready\", \"require_guest_profile_picture\", \"require_guest_phone_verification\"]:\n        processed_train_df[col] = train_df[col].apply(lambda x: 1 if x == \"t\" else 0)\n        processed_test_df[col] = test_df[col].apply(lambda x: 1 if x == \"t\" else 0)\n\n    train_df[\"host_verifications\"] = train_df[\"host_verifications\"].apply(lambda x: x.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"'\", \"\").replace(\",\", \"\"))\n    test_df[\"host_verifications\"] = test_df[\"host_verifications\"].apply(lambda x: x.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"'\", \"\").replace(\",\", \"\"))\n\n    vers = [\"email\", \"phone\", \"facebook\", \"google\", \"weibo\", \"sent_id\" , \"reviews\", \"kba\", \"jumio\", \"government_id\", \"offline_government_id\", \"selfie\", \"identity_manual\", \"sesame\", \"sesame_offline\", \"work_email\"]\n    for v in vers:\n        processed_train_df[v] = train_df[\"host_verifications\"].apply(lambda x: 1 if v in x.split() else 0)\n        processed_test_df[v] = test_df[\"host_verifications\"].apply(lambda x: 1 if v in x.split() else 0)\n\n    # label encoding\n    for col in cat_list:\n        le = LabelEncoder()\n        train_df[col] = train_df[col].fillna(\"NAN\")\n        test_df[col] = test_df[col].fillna(\"NAN\")\n        le = le.fit(pd.concat([train_df[col], test_df[col]]))\n        processed_train_df[col] = le.transform(train_df[col])\n        processed_test_df[col] = le.transform(test_df[col])\n\n    # feature engineering\n    processed_train_df[\"col1\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df[\"accommodates\"]\n    processed_train_df[\"col2\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df[\"accommodates\"]\n    processed_train_df[\"col3\"] = processed_train_df[\"beds\"] \/ processed_train_df[\"bedrooms\"]\n    processed_train_df[\"col4\"] = processed_train_df[\"bedrooms\"] + processed_train_df[\"bathrooms\"]\n    processed_train_df[\"col5\"] = processed_train_df[\"bedrooms\"] + processed_train_df[\"bathrooms\"] + processed_train_df[\"accommodates\"] + processed_train_df[\"beds\"]\n    processed_train_df[\"col6\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['host_id'])['bedrooms'].transform('std')\n    processed_train_df[\"col7\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['host_id'])['bedrooms'].transform('mean')\n    processed_train_df[\"col8\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['property_type'])['bedrooms'].transform('std')\n    processed_train_df[\"col9\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['property_type'])['bedrooms'].transform('mean')\n    processed_train_df[\"col10\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['smart_location'])['bedrooms'].transform('std')\n    processed_train_df[\"col11\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['smart_location'])['bedrooms'].transform('mean')\n    processed_train_df[\"col12\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['room_type'])['bedrooms'].transform('std')\n    processed_train_df[\"col13\"] = processed_train_df[\"bedrooms\"] \/ processed_train_df.groupby(['room_type'])['bedrooms'].transform('mean')\n    processed_train_df[\"col14\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['host_id'])['bathrooms'].transform('std')\n    processed_train_df[\"col15\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['host_id'])['bathrooms'].transform('mean')\n    processed_train_df[\"col16\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['property_type'])['bathrooms'].transform('std')\n    processed_train_df[\"col17\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['property_type'])['bathrooms'].transform('mean')\n    processed_train_df[\"col18\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['smart_location'])['bathrooms'].transform('std')\n    processed_train_df[\"col19\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['smart_location'])['bathrooms'].transform('mean')\n    processed_train_df[\"col20\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['room_type'])['bathrooms'].transform('std')\n    processed_train_df[\"col21\"] = processed_train_df[\"bathrooms\"] \/ processed_train_df.groupby(['room_type'])['bathrooms'].transform('mean')\n    processed_train_df[\"col22\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['host_id'])['accommodates'].transform('std')\n    processed_train_df[\"col23\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['host_id'])['accommodates'].transform('mean')\n    processed_train_df[\"col24\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['property_type'])['accommodates'].transform('std')\n    processed_train_df[\"col25\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['property_type'])['accommodates'].transform('mean')\n    processed_train_df[\"col26\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['smart_location'])['accommodates'].transform('std')\n    processed_train_df[\"col27\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['smart_location'])['accommodates'].transform('mean')\n    processed_train_df[\"col28\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['room_type'])['accommodates'].transform('std')\n    processed_train_df[\"col29\"] = processed_train_df[\"accommodates\"] \/ processed_train_df.groupby(['room_type'])['accommodates'].transform('mean')\n    \n    processed_test_df[\"col1\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df[\"accommodates\"]\n    processed_test_df[\"col2\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df[\"accommodates\"]\n    processed_test_df[\"col3\"] = processed_test_df[\"beds\"] \/ processed_test_df[\"bedrooms\"]\n    processed_test_df[\"col4\"] = processed_test_df[\"bedrooms\"] + processed_test_df[\"bathrooms\"]\n    processed_test_df[\"col5\"] = processed_test_df[\"bedrooms\"] + processed_test_df[\"bathrooms\"] + processed_test_df[\"accommodates\"] + processed_test_df[\"beds\"]\n    processed_test_df[\"col6\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['host_id'])['bedrooms'].transform('std')\n    processed_test_df[\"col7\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['host_id'])['bedrooms'].transform('mean')\n    processed_test_df[\"col8\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['property_type'])['bedrooms'].transform('std')\n    processed_test_df[\"col9\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['property_type'])['bedrooms'].transform('mean')\n    processed_test_df[\"col10\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['smart_location'])['bedrooms'].transform('std')\n    processed_test_df[\"col11\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['smart_location'])['bedrooms'].transform('mean')\n    processed_test_df[\"col12\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['room_type'])['bedrooms'].transform('std')\n    processed_test_df[\"col13\"] = processed_test_df[\"bedrooms\"] \/ processed_test_df.groupby(['room_type'])['bedrooms'].transform('mean')\n    processed_test_df[\"col14\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['host_id'])['bathrooms'].transform('std')\n    processed_test_df[\"col15\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['host_id'])['bathrooms'].transform('mean')\n    processed_test_df[\"col16\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['property_type'])['bathrooms'].transform('std')\n    processed_test_df[\"col17\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['property_type'])['bathrooms'].transform('mean')\n    processed_test_df[\"col18\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['smart_location'])['bathrooms'].transform('std')\n    processed_test_df[\"col19\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['smart_location'])['bathrooms'].transform('mean')\n    processed_test_df[\"col20\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['room_type'])['bathrooms'].transform('std')\n    processed_test_df[\"col21\"] = processed_test_df[\"bathrooms\"] \/ processed_test_df.groupby(['room_type'])['bathrooms'].transform('mean')\n    processed_test_df[\"col22\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['host_id'])['accommodates'].transform('std')\n    processed_test_df[\"col23\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['host_id'])['accommodates'].transform('mean')\n    processed_test_df[\"col24\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['property_type'])['accommodates'].transform('std')\n    processed_test_df[\"col25\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['property_type'])['accommodates'].transform('mean')\n    processed_test_df[\"col26\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['smart_location'])['accommodates'].transform('std')\n    processed_test_df[\"col27\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['smart_location'])['accommodates'].transform('mean')\n    processed_test_df[\"col28\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['room_type'])['accommodates'].transform('std')\n    processed_test_df[\"col29\"] = processed_test_df[\"accommodates\"] \/ processed_test_df.groupby(['room_type'])['accommodates'].transform('mean')\n\n    return processed_train_df, processed_test_df\nprocessed_train_df, processed_test_df = preprocess(train_df, test_df)","da188076":"processed_train_df.head()","4a83a8f4":"processed_test_df.head()","3ef53e4e":"def rmsle(y_true, y_pred):\n    assert len(y_true) == len(y_pred)\n    return np.sqrt(np.mean(np.power(np.log1p(y_true + 1) - np.log1p(y_pred + 1), 2)))\n\ndef rmsle_lgb(preds, data):\n    y_true = np.array(data.get_label())\n    result = rmsle(preds, y_true)\n    return 'RMSLE', result, False","e2115237":"import lightgbm as lgb\nfrom sklearn.model_selection import KFold\n\n# optimized params using optuna\n# https:\/\/github.com\/pfnet\/optuna\n\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmsle',\n    'max_depth': 20,\n    'max_bin': 200,\n    'num_leaves': 97,\n    'min_data_in_leaf': 10,\n    'learning_rate': 0.0022,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 10,\n    'min_sum_hessian_in_leaf': 10,\n    'lambda_l1': 0.01,\n    'lambda_l2': 0.01,\n    'verbose': 0,\n    'metric': 'rmse'\n}","5cdbf5d6":"y = processed_train_df[\"price\"].values\nX = processed_train_df.drop(\"price\", axis=1).values\nfeatures = processed_train_df.drop(\"price\", axis=1).columns\nX_test = processed_test_df.values\n\ncols = processed_train_df.drop(\"price\", axis=1).columns.values\ncategorical_cols = cat_list[:]\n\nfeature_importance_df = pd.DataFrame()\n\nN = 5\noof = np.zeros(len(X))\ntest_preds = np.zeros(len(test_df))\nkf = KFold(n_splits=N, shuffle=True, random_state=1)\ncv_score = []\n\nfor fold_, (train_idx, val_idx) in enumerate(kf.split(X), start=1):\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n    lgb_train = lgb.Dataset(X_train, y_train, feature_name=processed_train_df.drop(\"price\", axis=1).columns.tolist(), categorical_feature=categorical_cols)\n    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train, feature_name=processed_train_df.drop(\"price\", axis=1).columns.tolist(), categorical_feature=categorical_cols)\n    lgb_reg = lgb.train(params,\n            lgb_train,\n            num_boost_round=20000,\n            valid_sets=lgb_eval,\n            early_stopping_rounds=100,\n            verbose_eval=500,\n            feval = rmsle_lgb)\n    y_pred = lgb_reg.predict(X_val, num_iteration=lgb_reg.best_iteration)\n    oof[val_idx] = lgb_reg.predict(X_val, num_iteration=lgb_reg.best_iteration)\n    test_preds += lgb_reg.predict(X_test, num_iteration=lgb_reg.best_iteration) \/ N\n    cv_score.append(rmsle(y_val, y_pred))\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = lgb_reg.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    print(f\"fold{fold_}: {cv_score[-1]}\\n\\n\")\n    sns.residplot(y_pred, y_val, lowess=True, color='g')\n    plt.show()\n    \nprint(f\"CV RMSLE Score: {sum(cv_score)\/len(cv_score)}\")","1253b381":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:40].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(10,10), dpi=200)\nsns.barplot(x=\"importance\",\n            y=\"feature\",\n            data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()","a970de78":"sub_df[\"price\"] = test_preds\nsub_df.to_csv(f\"submission{sum(cv_score)\/len(cv_score)}.csv\", index=False)","c73427af":"rmsle(y, oof)","f9d9ad5a":"# drop outlier index\nl = []\nfor idx, (true, pred) in enumerate(zip(y, oof)):\n    l.append([np.power(np.log1p(true + 1) - np.log1p(pred + 1), 2), idx])\nl.sort(reverse=True)\nl_idx = [x[1] for x in l[:len(l)\/\/20]]\nl_idx.sort()\nidx = []\nj = 0\nfor i in range(len(l)):\n    if i == l_idx[j]:\n        if j < len(l_idx) - 1:\n            j += 1\n    else:\n        idx.append(i)\ny = processed_train_df[\"price\"].values\nX = processed_train_df.drop(\"price\", axis=1).values\nX = X[idx]\ny = y[idx]","3a039660":"X","6e2215b5":"N = 5\noof = np.zeros(len(X))\ntest_preds = np.zeros(len(test_df))\nkf = KFold(n_splits=N, shuffle=True, random_state=1)\ncv_score = []\n\nfor fold_, (train_idx, val_idx) in enumerate(kf.split(X), start=1):\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n    lgb_train = lgb.Dataset(X_train, y_train, feature_name=processed_train_df.drop(\"price\", axis=1).columns.tolist(), categorical_feature=categorical_cols)\n    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train, feature_name=processed_train_df.drop(\"price\", axis=1).columns.tolist(), categorical_feature=categorical_cols)\n    lgb_reg = lgb.train(params,\n            lgb_train,\n            num_boost_round=20000,\n            valid_sets=lgb_eval,\n            early_stopping_rounds=100,\n            verbose_eval=500,\n            feval = rmsle_lgb)\n    y_pred = lgb_reg.predict(X_val, num_iteration=lgb_reg.best_iteration)\n    oof[val_idx] = lgb_reg.predict(X_val, num_iteration=lgb_reg.best_iteration)\n    test_preds += lgb_reg.predict(X_test, num_iteration=lgb_reg.best_iteration) \/ N\n    cv_score.append(rmsle(y_val, y_pred))\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = lgb_reg.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    print(f\"fold{fold_}: {cv_score[-1]}\\n\\n\")\n    sns.residplot(y_pred, y_val, lowess=True, color='g')\n    plt.show()\n    \nprint(f\"CV RMSLE Score: {sum(cv_score)\/len(cv_score)}\")","3cc22616":"sub_df[\"price\"] = test_preds\nsub_df.to_csv(f\"v2_submission{sum(cv_score)\/len(cv_score)}.csv\", index=False)","c4b15ae1":"# #pseudo labeling\n# X_test = processed_test_df.values\n# processed_test_df[\"price\"] = test_preds\n# processed_train_df = pd.concat([processed_train_df, processed_test_df]).reset_index(drop=True)\n# y = processed_train_df[\"price\"].values\n# X = processed_train_df.drop(\"price\", axis=1).values\n# features = processed_train_df.drop(\"price\", axis=1).columns\n\n\n# cols = processed_train_df.drop(\"price\", axis=1).columns.values\n# categorical_cols = cat_list[:]\n\n# feature_importance_df = pd.DataFrame()\n\n# N = 5\n# test_preds = np.zeros(len(test_df))\n# kf = KFold(n_splits=N, shuffle=True, random_state=1)\n# cv_score = []\n\n# for fold_, (train_idx, val_idx) in enumerate(kf.split(X), start=1):\n#     X_train, X_val = X[train_idx], X[val_idx]\n#     y_train, y_val = y[train_idx], y[val_idx]\n#     lgb_train = lgb.Dataset(X_train, y_train, feature_name=processed_train_df.drop(\"price\", axis=1).columns.tolist(), categorical_feature=categorical_cols)\n#     lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train, feature_name=processed_train_df.drop(\"price\", axis=1).columns.tolist(), categorical_feature=categorical_cols)\n#     lgb_reg = lgb.train(params,\n#             lgb_train,\n#             num_boost_round=10000,\n#             valid_sets=lgb_eval,\n#             early_stopping_rounds=100,\n#             verbose_eval=100,\n#             feval = rmsle_lgb)\n#     y_pred = lgb_reg.predict(X_val, num_iteration=lgb_reg.best_iteration)\n#     test_preds += lgb_reg.predict(X_test, num_iteration=lgb_reg.best_iteration) \/ N\n#     cv_score.append(rmsle(y_val, y_pred))\n\n#     fold_importance_df = pd.DataFrame()\n#     fold_importance_df[\"feature\"] = features\n#     fold_importance_df[\"importance\"] = lgb_reg.feature_importance(importance_type='gain')\n#     fold_importance_df[\"fold\"] = fold_ + 1\n#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n#     sns.residplot(y_pred, y_val, lowess=True, color='g')\n#     plt.show()\n#     print(f\"fold{fold_}: {cv_score[-1]}\\n\\n\")\n# print(f\"CV RMSLE Score: {sum(cv_score)\/len(cv_score)}\")","c0d866d1":" ## Clean Data and Few Feature Engineering","c5b50e90":"## Pseudo labeling\n\nIt doesn't work in this task.\n\nMaybe it will work with Hold-out validation.","158119b6":"## Visualize Feature Importance","c8733d0b":"## Validate Model with 5-fold Cross Validation","74385cd6":"## Load LightGBM Model","1f0e16bc":"## Drop Some Rows from Train Data","f81f8fba":"## Make Submit File","ba556133":"# TMU InClass Competition\n## Import Library","b2c1794a":"## Define RMSLE Metric","ec34dca6":"## Load data","7648b7e3":"Drop some rows which has big difference between true value and predicted value.\n\nPublic LB score is better than CV score. Maybe test data has less outlier value than train data."}}