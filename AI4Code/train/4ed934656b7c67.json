{"cell_type":{"50d6526c":"code","6422fc33":"code","14a648a1":"code","222b903d":"code","266d563a":"code","1ac2df89":"code","47f4a076":"code","ccc3520e":"code","3cba1078":"code","5abf0de3":"code","8d4bbee1":"code","571ec25b":"code","a6d0d792":"code","336e05e7":"code","515264d4":"code","f259f80d":"code","f8782d54":"code","de92520d":"code","608e9d57":"code","d245c545":"markdown","8819072e":"markdown","61c31630":"markdown","36dd25dd":"markdown","984e21a5":"markdown","8c9bea49":"markdown","67e87e42":"markdown","ef1720d2":"markdown","8f57b439":"markdown","8f26dc0c":"markdown","a0f7eeeb":"markdown","85727ca9":"markdown","2e1cc959":"markdown","6dde286b":"markdown","65684805":"markdown","38e36004":"markdown","0ae61b26":"markdown"},"source":{"50d6526c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport time\n%matplotlib inline","6422fc33":"dataset_wdbc=pd.read_csv('..\/input\/breast-cancer-diagnostic-data-set\/wdbc.data')","14a648a1":"dummy=pd.DataFrame(dataset_wdbc.columns).T\ndataset_wdbc.columns=range(0,dataset_wdbc.shape[1])\ndataset_wdbc=pd.concat([dataset_wdbc,dummy],axis=0)\ndataset_wdbc.reset_index(inplace=True,drop=True)","222b903d":"cols=[ 'radius' ,'texture','perimeter','area','smoothness' ,'compactness' ,'concavity','concave_points' , 'symmetry' ,'fractal_dimension']\ncols=cols*3\ncol_names=[f'{i}_mean' for i in cols[:10]]\ncol_names=col_names+[f'{i}_se' for i in cols[10:20]]\ncol_names=col_names+[f'{i}_worst' for i in cols[20:]]\ncol_names=['ID','Target']+col_names","266d563a":"dataset_wdbc.columns=col_names\nfor col in dataset_wdbc.columns[2:]:\n    dataset_wdbc[col]=dataset_wdbc[col].astype(float)\n    ","1ac2df89":"dataset_wdbc.head()","47f4a076":"dataset_wdbc.info()","ccc3520e":"plt.figure(figsize=(10,10))\nsns.heatmap(dataset_wdbc.iloc[:,2:12].corr(), annot=True, square=True, cmap='coolwarm')\nplt.show()","3cba1078":"features_mean= list(dataset_wdbc.columns[2:12])\nbins = 12\nplt.figure(figsize=(15,15))\nfor i, feature in enumerate(features_mean):\n    rows = int(len(features_mean)\/2)\n    \n    plt.subplot(rows, 2, i+1)\n    \n    sns.distplot(dataset_wdbc[dataset_wdbc['Target']=='M'][feature], bins=bins, color='red', label='M');\n    sns.distplot(dataset_wdbc[dataset_wdbc['Target']=='B'][feature], bins=bins, color='blue', label='B');\n    \n    plt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()","5abf0de3":"X = dataset_wdbc.iloc[:,2:]\ny = dataset_wdbc.loc[:, 'Target']\n\n#Encoding categorical data values\n\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_Y = LabelEncoder()\nY = labelencoder_Y.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n","8d4bbee1":"#Feature Scaling , standardising values into gaussian format\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","571ec25b":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","a6d0d792":"##the accuracy score\nY_pred=classifier.predict(X_test)\naccuracy_score(Y_pred, y_test)","336e05e7":"##confusion matrix of logistic regression predictions\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, Y_pred)\ncm=pd.DataFrame(cm)\ncm.index=['Actual_Benign','Actual_Malignant']\ncm.columns=['Predicted_Benign','Predicted_Malignant']\ncm","515264d4":"from sklearn.ensemble import RandomForestClassifier","f259f80d":"classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\nprediction = classifier.predict(X_test)","f8782d54":"accuracy_score(prediction, y_test)","de92520d":"cm = confusion_matrix(y_test, prediction)\ncm=pd.DataFrame(cm)\ncm.index=['Actual_Benign','Actual_Malignant']\ncm.columns=['Predicted_Benign','Predicted_Malignant']\ncm","608e9d57":"from sklearn.metrics import roc_curve, auc,roc_auc_score\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(2):\n    fpr[i], tpr[i], _ = roc_curve(y_test, prediction)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nprint(roc_auc_score(y_test, prediction))\nplt.figure()\nplt.plot(fpr[1], tpr[1])\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.show()","d245c545":"#### Random Forest Classifier","8819072e":"## Visualising data","61c31630":"The data has been loaded and cleaned","36dd25dd":"The model skill can be got by taking area under the AUC curve","984e21a5":"####  Logistic Regression","8c9bea49":"We are using forest model to check whether there is improvement over the basic model","67e87e42":"Heatmap for all mean features ","ef1720d2":"We can see high correlation between features like \n1. concave points mean and concavity mean\n2. area mean and perimeter mean\n3. concave points mean and compactness mean","8f57b439":"The model is not over or under fit","8f26dc0c":"#### Loading and cleaning the data","a0f7eeeb":"### Wisconsin Diagnostic Breast Cancer (WDBC) ","85727ca9":"ROC Curves summarize the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.","2e1cc959":"Distribution plot of mean of features","6dde286b":"There are no missing or null values","65684805":"### Machine learning model ","38e36004":"This is a simple binary classification problem so we will use a logistic regression model for initial analysis","0ae61b26":"We come to the conclusion that logistic model is best model for our classification"}}