{"cell_type":{"6cccf3bc":"code","e2563900":"code","386788b5":"code","37bb358a":"code","18521bb1":"code","ec6696e2":"code","5d5bd45c":"code","3cd40cfb":"code","bfb90898":"code","fa88189f":"code","6167e764":"code","6f7ef127":"code","e00c4207":"code","5b597356":"code","a3a71c2b":"code","d035cba5":"code","cf9f95df":"code","270ca548":"code","b3b776d0":"markdown","371042e5":"markdown","70862c24":"markdown","4c9558ad":"markdown","ef149d18":"markdown","ae0b8f7f":"markdown","423a0ef3":"markdown","ce22ec0a":"markdown","40c840da":"markdown","83e9c4d5":"markdown"},"source":{"6cccf3bc":"!pip install -q addict","e2563900":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision import models\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport numpy as np\nimport os\nimport random\nfrom addict import Dict\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport logging","386788b5":"def seed_everything(seed:int=42) -> None:\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n\ndef get_optimizer(model:torch.nn.Module, name:str=\"SGD\", parameters:dict={}) -> torch.optim.Optimizer:\n    optimizers = {\n        \"SGD\": torch.optim.SGD,\n        \"AdamW\": torch.optim.AdamW,\n        \"Adam\": torch.optim.Adam,\n        \"RMSprop\": torch.optim.RMSprop,\n    }\n    \n    instance = optimizers.get(name, \"SGD\")     \n    optimizer = instance(model.parameters(), **parameters)\n    \n    return optimizer\n\n\ndef get_scheduler(optimizer:torch.optim.Optimizer, name:str, parameters:dict):\n    schedulers = {\n        \"ReduceLROnPlateau\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n        \"LambdaLR\": torch.optim.lr_scheduler.LambdaLR,\n        \"StepLR\": torch.optim.lr_scheduler.StepLR,\n        \"ExponentialLR\": torch.optim.lr_scheduler.ExponentialLR,\n        \"MultiplicativeLR\": torch.optim.lr_scheduler.MultiplicativeLR,\n        \"MultiStepLR\": torch.optim.lr_scheduler.MultiStepLR,\n    }\n    \n    instance = schedulers[name]     \n    scheduler = instance(optimizer, **parameters)\n    \n    return scheduler\n\n\n\ndef accuracy_score(predictions:torch.Tensor, targets:torch.Tensor) -> torch.Tensor:\n    amount = (predictions == targets).sum()\n    accuracy = amount \/ targets.size(0)\n    \n    return accuracy\n\n\n\ndef hide_spines(ax, spines=[\"top\", \"right\", \"left\", \"bottom\"]):\n    for spine in spines:\n        ax.spines[spine].set_visible(False)\n        \ndef plot_images(rows, cols, indexes, class_=0):\n    min_index = min(indexes)\n    max_index = max(indexes)\n    fig = plt.figure(figsize=(3*cols, 3*rows))\n    for i in range(*indexes):\n        item = train_dataset[i]\n        image = item.image\n        label = item.label\n\n        if label == class_:\n            ax = fig.add_subplot(rows, cols, (i - min_index)+1)\n            ax.imshow(image.permute(1, 2, 0))\n            ax.xaxis.set_visible(False)\n            ax.yaxis.set_visible(False)\n\n    fig.text(s=f\"{train_dataset.labels[class_]} leaves\", x=0.125, y=0.9, fontweight=\"bold\", fontfamily=\"serif\", fontsize=20)\n    fig.show()\n    \n    \ndef get_logger(name:str=__name__, format:str=\"[%(asctime)s][%(levelname)s]: %(message)s\") -> logging.Logger:\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    formatter = logging.Formatter(format)\n\n    file_handler = logging.FileHandler(name)\n    file_handler.setLevel(logging.INFO)\n    file_handler.setFormatter(formatter)\n\n    stream_handler = logging.StreamHandler()\n    stream_handler.setLevel(logging.INFO)\n    stream_handler.setFormatter(formatter)\n\n    logger.addHandler(stream_handler)\n    logger.addHandler(file_handler)\n    \n    logger.propagate = False\n    \n    return logger","37bb358a":"config = Dict({\n    \"train_path\": \"..\/input\/plant-disease-recognition-dataset\/Train\/Train\",\n    \"test_path\": \"..\/input\/plant-disease-recognition-dataset\/Test\/Test\",\n    \"validation_path\": \"..\/input\/plant-disease-recognition-dataset\/Validation\/Validation\"\n})\n\ntrain_config = Dict({\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"epochs\": 5,\n    \"seed\": 2021,\n    \"image_shape\": (128, 128),\n    \"image_channels\": 3,\n    \"num_workers\": 0,\n    \"batch_size\": 32, \n\n    \"augmentations\": A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        #A.Blur(p=1),\n        ToTensorV2(),\n    ]),\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"parameters\": {\n            \"lr\": 0.001,\n            \"weight_decay\": 0.01,\n        }\n    },\n    \n    \"scheduler\": {\n        \"type\": \"ReduceLROnPlateau\",\n        \"parameters\": {\n            \"patience\": 2,\n            \"mode\": \"min\",\n            \"factor\": 0.1,\n        }\n    }\n})\n\n\nseed_everything(train_config.seed)","18521bb1":"class PlantDiseaseDataset(Dataset):\n    def __init__(self, path, augmentations=None, image_shape=(256, 256), channels=\"RGB\"):\n        self.__images_labels = []\n        self.image_shape = image_shape\n        self.channels = channels\n        self.augmentations = augmentations\n        \n        if os.path.exists(path):\n            self.labels = os.listdir(path)\n            for label in self.labels:\n                label_path = os.path.join(path, label)\n                if os.path.isdir(label_path):\n                    files = os.listdir(label_path)\n                    for file in files:\n                        if file.endswith(\"jpg\") or file.endswith(\"png\"):\n                            image_path = os.path.join(label_path, file)\n                            self.__images_labels.append((image_path, label))\n                        else:\n                            pass\n                else:\n                    pass\n                \n        else:\n            pass\n        \n    def _load(self, path, channels=\"RGB\"):\n        width, height = self.image_shape\n        loader = A.Compose([\n            A.Resize(width=width, height=height),\n            ToTensorV2(),\n        ])\n        \n        image_array = np.array(Image.open(path).convert(channels))\n        return loader(image=image_array)[\"image\"]\n    \n    def __len__(self):\n        return len(self.__images_labels)\n    \n    def __getitem__(self, index):\n        path, label = self.__images_labels[index]\n        image = self._load(path)\n        \n        if self.augmentations is not None:\n            image = image.permute(1, 2, 0).numpy()\n            image = self.augmentations(image=image)[\"image\"]\n            \n        label = self.labels.index(label)\n        \n        return Dict({\n            \"image\": image,\n            \"label\": label,\n        })\n    \n    \ndef collate_fn(batch):\n    all_images, all_labels = [], []\n    for item in batch:\n        image = item.image\n        label = item.label\n        \n        all_images.append(item.image.tolist())\n        all_labels.append(label)\n        \n    return { \n        \"images\": torch.tensor(all_images),\n        \"labels\": torch.tensor(all_labels, dtype=torch.int8)\n    }\n        ","ec6696e2":"train_dataset = PlantDiseaseDataset(path=config.train_path, \n                                    image_shape=train_config.image_shape, \n                                    channels=train_config.image_channels)","5d5bd45c":"label_pathes = [os.path.join(config.train_path, label) for label in train_dataset.labels]\nlabel_files = [os.listdir(path) for path in label_pathes]\namount = [len(files) for files in label_files]\n\npalette = sns.color_palette([\"#5FB924\", \"#AB4800\", \"#B2BBAC\"])\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot()\nax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\nsns.barplot(x=train_dataset.labels, y=amount, palette=palette,  ec=\"#000\", linewidth=1.5, zorder=2, ax=ax)\nax.xaxis.set_tick_params(labelsize=14, size=0, pad=10)\nax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\nax.set_yticks(list(range(0, 450, 50)))\nax.set_title(f\"Classes Distribution\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.01)\nax.set_xlabel(\"Classes\", fontsize=15, fontfamily=\"serif\", labelpad=5)\nax.set_ylabel(\"Count\", fontsize=15, fontfamily=\"serif\", labelpad=5)\nhide_spines(ax)\nfig.show()","3cd40cfb":"plot_images(rows=5, cols=5, indexes=(0, 25), class_=0)","bfb90898":"plot_images(rows=5, cols=5, indexes=(500, 525), class_=1)","fa88189f":"plot_images(rows=5, cols=5, indexes=(len(train_dataset)-25, len(train_dataset)), class_=2)","6167e764":"train_dataset = PlantDiseaseDataset(path=config.train_path, \n                                    augmentations=train_config.augmentations,\n                                    image_shape=train_config.image_shape, \n                                    channels=train_config.image_channels)\n\nvalidation_dataset = PlantDiseaseDataset(path=config.validation_path, \n                                         augmentations=train_config.augmentations,\n                                         image_shape=train_config.image_shape, \n                                         channels=train_config.image_channels)\n\ntest_dataset = PlantDiseaseDataset(path=config.test_path, \n                                   augmentations=train_config.augmentations,\n                                   image_shape=train_config.image_shape, \n                                   channels=train_config.image_channels)","6f7ef127":"train_loader = DataLoader(dataset=train_dataset, \n                          batch_size=train_config.batch_size, \n                          num_workers=train_config.num_workers, \n                          pin_memory=True, \n                          shuffle=True, \n                          collate_fn=collate_fn)\n\nvalidation_loader = DataLoader(dataset=validation_dataset, \n                               batch_size=train_config.batch_size*2, \n                               num_workers=train_config.num_workers, \n                               pin_memory=True, \n                               shuffle=False, \n                               collate_fn=collate_fn)\n\ntest_loader = DataLoader(dataset=test_dataset, \n                         batch_size=train_config.batch_size*2, \n                         num_workers=train_config.num_workers, \n                         pin_memory=True, \n                         shuffle=False, \n                         collate_fn=collate_fn)","e00c4207":"class PlantDiseaseModel(nn.Module):\n    def __init__(self, classes=2):\n        super(PlantDiseaseModel, self).__init__()\n        self.model = models.resnet34(pretrained=True)\n        \n        for parameter in self.model.parameters():\n            parameter.require_grad = False\n        \n        in_features = self.model.fc.in_features\n        self.model.fc = nn.Sequential(\n            nn.Linear(in_features=in_features, out_features=classes),\n            nn.Softmax(dim=1)\n        )\n        \n    def forward(self, image):\n        output = self.model(image)\n        return output","5b597356":"class Trainer:\n    def __init__(self, model, criterion, optimizer,  metric, scheduler=None, logger=None, device=\"cpu\"):\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.logger = logger\n        self.device = torch.device(device)\n        self.best_validation_loss = 0\n        self.metric = metric\n        self.history = Dict({})\n        \n    def __log(self, logs):\n        for k, v in logs.items():\n            if k not in self.history:\n                self.history[k] = []\n                \n            self.history[k].append(v)\n            \n    def evaluate(self, loader):\n        loss, score, length = 0, 0, len(loader)\n            \n        self.model.to(self.device)\n        with torch.no_grad():\n            loop = tqdm(loader, position=0, colour=\"BLACK\", desc=f\"Evaluating: \", leave=True)\n            for batch in loop:\n                if self.device.type != \"cpu\": torch.cuda.empty_cache()\n                self.model.eval()\n\n                images = batch[\"images\"].float().to(self.device)\n                labels = batch[\"labels\"].long().to(\"cpu\")\n\n                probabilities = self.model(images).float().to(\"cpu\")\n                predictions = torch.argmax(probabilities, dim=1).detach()\n\n                batch_loss = self.criterion(probabilities, labels)\n                loss += batch_loss.item()\n                \n                batch_score = self.metric(predictions, labels).item()\n                score += batch_score\n\n            loss \/= length\n            score \/= length\n        \n        return loss, score\n        \n\n\n    def fit(self, train_loader, validation_loader=None, epochs=10):\n        self.model.to(self.device)\n        train_length = len(train_loader)\n        \n        for epoch in range(epochs): \n            epoch_loss, epoch_score = 0, 0\n            \n            loop = tqdm(train_loader, position=0, colour=\"BLACK\", leave=True, desc=f\"Epoch [{epoch+1}\/{epochs}]: \")\n            for batch in loop:\n                if self.device.type != \"cpu\": torch.cuda.empty_cache()\n                self.optimizer.zero_grad()\n                self.model.train()\n                \n                images = batch[\"images\"].float().to(self.device)\n                labels = batch[\"labels\"].long().to(\"cpu\")\n\n                probabilities = self.model(images).float().to(\"cpu\")\n                predictions = torch.argmax(probabilities, dim=1).detach()\n                \n                batch_loss = self.criterion(probabilities, labels)\n                epoch_loss += batch_loss.item()\n                \n                batch_score = self.metric(predictions, labels).item()\n                epoch_score += batch_score\n                \n                batch_loss.backward()\n                self.optimizer.step()\n                \n            epoch_loss \/= train_length\n            epoch_score \/= train_length\n            \n            self.__log({\"train_losses\": epoch_loss, \"train_scores\": epoch_score})\n            if self.logger is not None: self.logger.info(f\"Epoch [{epoch+1}\/{epochs}]: Loss: {epoch_loss} | Metric: {epoch_score}\")\n                \n            if validation_loader is not None:\n                validation_loss, validation_score = self.evaluate(validation_loader)\n                self.__log({\"validation_losses\": validation_loss, \"validation_scores\": validation_score})\n                if self.logger is not None: self.logger.info(f\"Validation Epoch [{epoch+1}\/{epochs}]: Loss: {validation_loss} | Metric: {validation_score}\")\n            \n\n\n                if self.scheduler is not None:\n                    if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n                        self.scheduler.step(validation_loss)\n                    else:\n                        self.scheduler.step()\n\n                    if self.logger is not None:\n                        lr = self.optimizer.param_groups[0][\"lr\"]\n                        self.logger.info(f\"Epoch [{epoch+1}\/{epochs}] Learning Rate: {lr}\")","a3a71c2b":"model = PlantDiseaseModel(classes=len(train_dataset.labels))\ncriterion = nn.CrossEntropyLoss()\noptimizer = get_optimizer(model=model, \n                          name=train_config.optimizer.type, \n                          parameters=train_config.optimizer.parameters)\n\nif \"scheduler\" in train_config:\n    scheduler = get_scheduler(optimizer=optimizer, \n                              name=train_config.scheduler.type, \n                              parameters=train_config.scheduler.parameters)\n    \ntrainer_logger = get_logger(\"trainer\")\ntrainer = Trainer(model=model, \n                  criterion=criterion,\n                  metric=accuracy_score,\n                  optimizer=optimizer, \n                  scheduler=scheduler,\n                  logger=trainer_logger,\n                  device=train_config.device)","d035cba5":"trainer.fit(train_loader=train_loader, \n            validation_loader=validation_loader, \n            epochs=train_config.epochs)","cf9f95df":"epochs_ = range(1, train_config.epochs+1)\nfig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\nax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\nsns.lineplot(x=epochs_, y=trainer.history.train_losses, color=\"red\", marker=\"o\", label=\"Train Loss\", zorder=2, ax=ax)\nsns.lineplot(x=epochs_, y=trainer.history.validation_losses, color=\"blue\", marker=\"o\", label=\"Validation Loss\", zorder=2, ax=ax)\nax.set_title(\"Train & Validation Losses\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.05)\nhide_spines(ax)\nax.xaxis.set_tick_params(labelsize=12, size=0, pad=10)\nax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\nax.set_xlabel(\"Epochs\", fontsize=15, fontfamily=\"serif\", labelpad=10)\nax.set_ylabel(\"Loss\", fontsize=15, fontfamily=\"serif\", labelpad=5)\nax.legend()\nfig.show()","270ca548":"fig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\nax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\nsns.lineplot(x=epochs_, y=trainer.history.train_scores, color=\"red\", marker=\"o\", label=\"Train Accuracy\", zorder=2, ax=ax)\nsns.lineplot(x=epochs_, y=trainer.history.validation_scores, color=\"blue\", marker=\"o\", label=\"Validation Accuracy\", zorder=2, ax=ax)\nax.set_title(\"Train & Validation Accuracy\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.05)\nhide_spines(ax)\nax.xaxis.set_tick_params(labelsize=12, size=0, pad=10)\nax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\nax.set_xlabel(\"Epochs\", fontsize=15, fontfamily=\"serif\", labelpad=10)\nax.set_ylabel(\"Accuracy\", fontsize=15, fontfamily=\"serif\", labelpad=5)\nax.legend()\nfig.show()","b3b776d0":"<img src=\"https:\/\/images.theconversation.com\/files\/288176\/original\/file-20190815-136190-cn8sg3.jpg?ixlib=rb-1.1.0&rect=0%2C793%2C5515%2C2753&q=45&auto=format&w=1356&h=668&fit=crop\">","371042e5":"# Modelling","70862c24":"<link rel=\"preconnect\" href=\"https:\/\/fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https:\/\/fonts.gstatic.com\" crossorigin>\n<link href=\"https:\/\/fonts.googleapis.com\/css2?family=Inter:wght@500&display=swap\" rel=\"stylesheet\">\n\n\n<h1 style=\"font-size: 30px; font-family: 'Inter', sans-serif;\">Introducing to the Plant Disease Recognition Dataset<\/h1>\n<p style=\"font-size: 17px; font-family: 'Inter', sans-serif;\">This dataset contains three labels: <b>Healthy<\/b>, <b>Powdery<\/b>, <b>Rust<\/b> referring to plant conditions. There is a total of 1530 images divided into train, test, and validation sets.<\/p>\n\n<h3 style=\"font-size: 25px; font-family: 'Inter', sans-serif;\">Rusts<\/h3>\n<p style=\"font-size: 17px; font-family: 'Inter', sans-serif;\">\n    \nRusts are plant diseases caused by pathogenic fungi of the order Pucciniales (previously known as Uredinales).\n\nAn estimated 168 rust genera and approximately 7,000 species, more than half of which belong to the genus Puccinia, are currently accepted.[1] Rust fungi are highly specialized plant pathogens with several unique features. Taken as a group, rust fungi are diverse and affect many kinds of plants. However, each species has a very narrow range of hosts and cannot be transmitted to non-host plants. In addition, most rust fungi cannot be grown easily in pure culture.\n\nA single species of rust fungi may be able to infect two different plant hosts in different stages of its life cycle, and may produce up to five morphologically and cytologically distinct spore-producing structures viz., spermogonia, aecia, uredinia, telia, and basidia in successive stages of reproduction.[2] Each spore type is very host specific, and can typically infect only one kind of plant.\n\nRust fungi are obligate plant pathogens that only infect living plants. Infections begin when a spore lands on the plant surface, germinates, and invades its host. Infection is limited to plant parts such as leaves, petioles, tender shoots, stem, fruits, etc. Plants with severe rust infection may appear stunted, chlorotic (yellowed), or may display signs of infection such as rust fruiting bodies. Rust fungi grow intracellularly, and make spore-producing fruiting bodies within or, more often, on the surfaces of affected plant parts. Some rust species form perennial systemic infections that may cause plant deformities such as growth retardation, witch's broom, stem canker, galls, or hypertrophy of affected plant parts.\n\nRusts get their name because they are most commonly observed as deposits of powdery rust-coloured or brown spores on plant surfaces. The Roman agricultural festival Robigalia (April 25) has ancient origins in combating wheat rust.<\/p>\n\n<img src=\"https:\/\/www.gardeningknowhow.com\/wp-content\/uploads\/2020\/11\/plant-rust-disease.jpg\" width=\"500px\" height=\"300px\">\n\n\n<h3 style=\"font-size: 25px; font-family: 'Inter', sans-serif;\">Powdery<\/h3>\n\n<p style=\"font-size: 17px; font-family: 'Inter', sans-serif;\">\n\nPowdery mildew is a fungal disease that affects a wide range of plants. Powdery mildew diseases are caused by many different species of fungi in the order Erysiphales. Powdery mildew is one of the easier plant diseases to identify, as its symptoms are quite distinctive. Infected plants display white powdery spots on the leaves and stems. The lower leaves are the most affected, but the mildew can appear on any above-ground part of the plant. As the disease progresses, the spots get larger and denser as large numbers of asexual spores are formed, and the mildew may spread up and down the length of the plant.\n\nPowdery mildew grows well in environments with high humidity and moderate temperatures. Greenhouses provide an ideal moist, temperate environment for the spread of the disease. This causes harm to agricultural and horticultural practices where powdery mildew may thrive in a greenhouse setting. In an agricultural or horticultural setting, the pathogen can be controlled using chemical methods, bio organic methods, and genetic resistance. It is important to be aware of powdery mildew and its management as the resulting disease can significantly reduce important crop yields.\n<\/p>\n\n<img src=\"https:\/\/media.istockphoto.com\/photos\/grapevine-diseases-downy-mildew-is-a-fungal-disease-that-affects-a-picture-id1161364148?k=6&m=1161364148&s=612x612&w=0&h=BzE8nsZHyGD3y7r1wvKIYDrvqLQcJdk_efFCUNB3134=\" width=\"500px\" height=\"300px\">","4c9558ad":"<h1 style=\"font-size: 30px; font-family: 'Inter', sans-serif;\">References<\/h1>\n<ul style=\"font-size: 15px; font-family: 'Inter', sans-serif;\">\n<li><a href=\"https:\/\/arxiv.org\/abs\/1512.03385\">Resnet50 - https:\/\/arxiv.org\/abs\/1512.03385<\/a>\n<li><a href=\"https:\/\/arxiv.org\/abs\/1711.05101\">Adam - https:\/\/arxiv.org\/abs\/1512.03385<\/a>\n<li><a href=\"https:\/\/machinelearningmastery.com\/cross-entropy-for-machine-learning\/\">Cross Entropy Loss - https:\/\/machinelearningmastery.com\/cross-entropy-for-machine-learning\/<\/a>\n<\/ul>","ef149d18":"# Functions","ae0b8f7f":"# Dataset","423a0ef3":"# Preprate the Datasets & Data Loaders","ce22ec0a":"# Exploratory Data Analysis","40c840da":"# Configs","83e9c4d5":"# Import requirements"}}