{"cell_type":{"ef655922":"code","42593162":"code","b6308ba2":"code","676a6f9e":"code","ef9bf70d":"code","e21db24e":"code","95370532":"markdown","92504e62":"markdown","8979776c":"markdown","4400f355":"markdown","24e1fab5":"markdown","7f7f9e9a":"markdown"},"source":{"ef655922":"#Basic Libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","42593162":"#Basic Libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n#Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n#glob\nimport glob\nimport cv2\nfrom pathlib import Path\n## tensorflow & Keras\nimport tensorflow as tf\n#others\nsns.set(style='white', context='notebook', palette='deep')\nnp.random.seed(64)","b6308ba2":"#1# CSV Dataset\ntrain_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntest_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\n#--------------------------------------------------\n#2# images\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\ntest_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/test')\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n#--------------------------------------------------\n#3# Check data\n#print(train_images_paths.head())\n#print(test_images_paths.head())","676a6f9e":"#1# Data preparation\n#--------------------------------------------------\n#1.1# Data Exploration\nimg_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n# fig, ax = plt.subplots(4, 7, figsize=(12, 8))\ni = 0\nfor row in range(4):\n    for col in range(7):\n#         plt.sca(ax[row, col])\n#         plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n#         plt.imshow(img)\n#         plt.axis('off')\n        i+=1\n#print('Number of Instances in train_set =>', len(train_images_paths))\n#print('Number of Instances in train_labels =>', len(train_labels))\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\n#print('shape of each Image is =>', img.shape)\n#--------------------------------------------------\n#1.2# Data preprocessing\ntrain_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\nfor idx, path in enumerate(train_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    train_full_set[idx] = img\n# print('train_full_set.shape =>', train_full_set.shape)\n# print('train_full_labels.shape =>', train_full_labels.shape)\n#--------------------------------------------------\n#1.3# Split data\nX_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, test_size=0.2, shuffle=True, random_state=64)\nprint('X_train.shape = ', X_train.shape)\nprint('X_valid.shape = ', X_valid.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('y_valid.shape = ', y_valid.shape)\n#--------------------------------------------------\n#1.4# Model\n# model = tf.keras.models.Sequential([\n#     tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n#     tf.keras.layers.MaxPooling2D(pool_size=1),    \n#     tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n#     tf.keras.layers.MaxPooling2D(pool_size=1),    \n#     tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n#     tf.keras.layers.MaxPooling2D(pool_size=1),    \n#     tf.keras.layers.GlobalAveragePooling2D(),\n#     tf.keras.layers.Dense(29, activation='softmax')])\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n    tf.keras.layers.MaxPooling2D(pool_size=1),    \n    tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=1),    \n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n    tf.keras.layers.MaxPooling2D(pool_size=1),    \n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Flatten(),   \n    tf.keras.layers.Dense(128,activation='relu') ,    \n    tf.keras.layers.Dense(64,activation='relu') ,\n    tf.keras.layers.Dense(29, activation='softmax')])\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())\nhistory = model.fit(X_train, y_train, epochs=256,batch_size=8,verbose=1)\n# early_stopp = tf.keras.callbacks.EarlyStopping(patience=128, restore_best_weights=True)\n# history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=64, batch_size=2, callbacks=[early_stopp])\n#--------------------------------------------------\n#1.5# Model evaluation\nloss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels)\nprint('loss_all_data = ', loss_all_data)\nprint('acc_all_data = ', acc_all_data)","ef9bf70d":"test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\nfor idx, path in enumerate(test_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    test_full_set[idx] = img   \n#print('test_full_set.shape =>', test_full_set.shape)\ny_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)\ntest_labels['label'] = y_preds_classes","e21db24e":"test_labels[['id', 'label']].to_csv('\/kaggle\/working\/submission.csv', index=False)","95370532":"# Submission","92504e62":"# Test model","8979776c":"# Train model","4400f355":"# End","24e1fab5":"# libraries","7f7f9e9a":"# Dataset path"}}