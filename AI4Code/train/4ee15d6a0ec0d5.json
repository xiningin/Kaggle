{"cell_type":{"f34159a3":"code","e4f90299":"code","6808eaee":"code","4980afaf":"code","5f0efe48":"code","1d07ae5f":"code","8b734ef1":"code","7090b8e6":"code","d3c0fd04":"code","b7cce5f7":"code","6c9cb1ef":"code","2f3ad381":"code","03ce0459":"code","a98d8939":"code","ab30ee23":"code","05b8b395":"code","981877aa":"code","2556ea75":"code","fff03cb1":"code","9ffb7cec":"code","c4caf315":"code","67d1f194":"code","c75da0a3":"code","40729635":"code","46eef09e":"code","4cebca93":"code","00d9c7cc":"code","330f4dc0":"code","6e26f5e5":"code","853a829a":"code","56704a4b":"code","8a0a4ce2":"code","351311ed":"code","dc89c7e5":"code","c8bbb981":"code","21369768":"code","17f73746":"code","b184ce97":"code","f7782cbb":"code","63167090":"code","50b0ee13":"code","644e50f1":"code","a919994c":"code","a7f6e811":"code","9f40664d":"code","b31c67c1":"code","8b566ec1":"code","c3df474e":"code","1db9aa82":"code","90a2735f":"code","a02b8f01":"code","c616eb06":"code","a13d23c3":"markdown","f3a44ea4":"markdown"},"source":{"f34159a3":"import numpy as np # linear algebra\nimport pandas as pd ","e4f90299":"np.random.seed(0)","6808eaee":"train = pd.read_csv(\"\/kaggle\/input\/eval-lab-2-f464\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/eval-lab-2-f464\/test.csv\")","4980afaf":"pd.set_option('display.max_rows', 5400)\n# \"The maximum width in characters of a column\"","5f0efe48":"train.head(120)","1d07ae5f":"train.info()","8b734ef1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt","7090b8e6":"df_tr = train\n#TODO\nfrom sklearn.preprocessing import MinMaxScaler\nm = MinMaxScaler()\n#m.fit_transform(df_tr)\nX = df_tr.drop(['class'],axis=1)\ny = train['class'].tolist()","d3c0fd04":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","b7cce5f7":"#y=train['class']\n#x=train.drop('class',axis=1)\n##Oversampling\n#from imblearn.over_sampling import SMOTE\n#from imblearn.over_sampling import ADASYN\n#import random\n\n#oversampler=SMOTE(kind='regular',k_neighbors=3,random_state=random.randint(1,100000))\n\n#x_resampled, y_resampled = oversampler.fit_resample(x, y)","6c9cb1ef":"import xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom datetime import datetime","2f3ad381":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","03ce0459":"import xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom datetime import datetime","a98d8939":"param_test5={'booster':['gbtree'],\n'eta':[0,0.02,0.04,0.06],\n'gamma':np.arange(0,0.6,0.1),\n'learning_rate':np.arange(0.01,0.07,0.01),\n'n_estimators':[120,140,160,180],\n'max_depth':range(3,7,1),\n'min_child_weight':range(1,6,2),\n'objective':['multi:softprob','multi:softmax'] }\n\ngsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(), \n param_grid = param_test5, cv = 3, n_jobs = -1,verbose=2)\ngsearch1.fit(X,y)\ngsearch1.best_params_","ab30ee23":"from xgboost import XGBClassifier\n# fit model no training data\nmodel = xgb.XGBClassifier(booster='gbtree',eta=0,gamma=0.4,learning_rate =0.03, max_depth=4,\n min_child_weight=3,n_estimators=140,objective='multi:softprob')\nmodel.fit(X, y)\n","05b8b395":"# make predictions for test data\ny_pred = model.predict(X_test)\nprint(y_pred)\npredictions = [round(value) for value in y_pred]\nprint(predictions)","981877aa":"y_pred = model.predict(test)\ny_ans = [round(value) for value in y_pred]","2556ea75":"import pandas as pd\nc1=pd.DataFrame(test, columns=['id'])\nc2 = pd.DataFrame(y_ans, columns = ['class'])\nc2 = c2.astype(int)\ndata_frame = pd.merge(c1, c2, right_index=True, left_index=True)\ndata_frame","fff03cb1":"y_ans","9ffb7cec":"data_frame.to_csv('submission.csv',columns=['id','class'],index=False)","c4caf315":"import numpy as np\nimport pandas as pd","67d1f194":"pd.set_option('display.max_rows', 5400)\n# \"The maximum width in characters of a column\",to ensure we can see all data via .head() function\n","c75da0a3":"train = pd.read_csv(\"\/kaggle\/input\/eval-lab-2-f464\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/eval-lab-2-f464\/test.csv\")","40729635":"train.isnull().values.any()","46eef09e":"test.isnull().values.any()","4cebca93":"train.info()","00d9c7cc":"test.info()","330f4dc0":"train = train.drop(['id'], axis=1)\ntester = test.drop(['id'],axis=1)","6e26f5e5":"#y=train['class']\n#x=train.drop('class',axis=1)\n##Oversampling\n#from imblearn.over_sampling import SMOTE\n#from imblearn.over_sampling import ADASYN\n#import random\n\n#oversampler=SMOTE(kind='regular',k_neighbors=3,random_state=random.randint(1,100000))\n\n#x_resampled, y_resampled = oversampler.fit_resample(x, y)","853a829a":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\nX_lda = lda.fit_transform(train.drop(['class'],axis=1), train['class'])","56704a4b":"afterLDATransform = pd.DataFrame(lda.transform(tester))\ntester['lda_0'] = afterLDATransform[0]\ntester['lda_1'] = afterLDATransform[1]\ntester['lda_2'] = afterLDATransform[2]\ntester['lda_3'] = afterLDATransform[3]\ntester['lda_4'] = afterLDATransform[4]","8a0a4ce2":"tester.head()","351311ed":"new_features = pd.DataFrame(lda.transform(train.drop(['class'],axis=1)))\ntrain['lda_0'] = new_features[0]\ntrain['lda_1'] = new_features[1]\ntrain['lda_2'] = new_features[2]\ntrain['lda_3'] = new_features[3]\ntrain['lda_4'] = new_features[4]","dc89c7e5":"train.head()","c8bbb981":"train['factor'] = (train['chem_3']*train['attribute']*train['chem_4'])\ntester['factor'] = (tester['chem_3']*tester['attribute']*tester['chem_4'])","21369768":"X = train.drop(['class'],axis=1)\ny = train['class']","17f73746":"import matplotlib.pyplot as plt\nimport seaborn as sns\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = train.corr()\nsns.heatmap(corr, center=0)","b184ce97":"import matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute the correlation matrix\ncorr = train.corr(method=\"kendall\")\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0.5,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot=True)\n\nplt.show()","f7782cbb":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\nX_lda = lda.fit_transform(X, y)","63167090":"#Constructing a scatter plot of the data\nplt.scatter(X_lda[:,0],X_lda[:,1],c=y,cmap='rainbow',alpha=0.7,edgecolors='g')","50b0ee13":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrainScaled = train.copy()\ntestScaled = tester.copy()\ncolumns = tester.columns\ntrainScaled[columns]=scaler.fit_transform(train[columns])\ntestScaled[columns]=scaler.transform(tester[columns])","644e50f1":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\nX_lda = lda.fit_transform(X, y)\nplt.xlabel('row0')\nplt.ylabel('row1')\nplt.scatter(X_lda[:,0],X_lda[:,1],c=y,cmap='rainbow',alpha=0.7,edgecolors='g')","a919994c":"trainScaled.head()","a7f6e811":"testScaled.head()","9f40664d":"from sklearn.decomposition import PCA\n\nmodel=PCA(n_components=2)\nfittedData = model.fit(trainScaled.drop('class',axis=1)).transform(trainScaled.drop('class',axis=1))","b31c67c1":"plt.figure(figsize=(10,8))\nplt.xlabel('row0')\nplt.ylabel('row1')\nplt.legend()\nplt.scatter(fittedData[:,0],fittedData[:,1],label = train['class'],c=train['class'])\nplt.show()","8b566ec1":"x = trainScaled.drop(['class'],axis=1)\ny = trainScaled['class']","c3df474e":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)","1db9aa82":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score\n\nclf = ExtraTreesClassifier(n_estimators=1000, random_state=42, class_weight=\"balanced\")\nclf.fit(x_train,y_train)\ny_ans = clf.predict(x_test)\naccuracy_score(y_test, y_ans)","90a2735f":"clf = ExtraTreesClassifier(n_estimators=1000, random_state=42, class_weight=\"balanced\")\nclf.fit(x,y)\ntest['class'] = clf.predict(testScaled)\ndata_frame = test[['id','class']]\ndata_frame.info()","a02b8f01":"data_frame.head(120)","c616eb06":"data_frame.to_csv('submission.csv',columns=['id','class'],index=False)","a13d23c3":"# Oversampling via imblearn","f3a44ea4":"# Second Python Notebook"}}