{"cell_type":{"3935c4f5":"code","73e902ad":"code","c216e9bd":"code","24f0d520":"code","346b7c67":"code","08fd506f":"code","a03ced81":"code","1d59b254":"code","fd56b941":"code","d179d493":"code","b4697eb1":"code","85d824d0":"code","0f86fd9c":"code","0176835e":"code","99737842":"code","b6ea7486":"code","23625be6":"code","f02fb9f2":"code","adb6d244":"code","1d2673f0":"code","a7e65a22":"code","4fd64a2f":"code","d232213d":"code","dd62638c":"code","b278ac28":"code","aa0fb7ff":"code","f984f903":"code","b8fc47b2":"code","24d89908":"code","d09c741a":"code","c43786f9":"code","9c69545d":"code","c3071348":"markdown","b4d96925":"markdown","f880a774":"markdown","d4188561":"markdown","912537f8":"markdown","f704e838":"markdown","d78e23b4":"markdown","58797080":"markdown","ffe03a1b":"markdown","03399349":"markdown","3c22a730":"markdown","eb113805":"markdown"},"source":{"3935c4f5":"import os\nimport pywt\nimport time\nimport random\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.svm import SVC\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import resample\nfrom keras.models import Sequential\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.pipeline import make_pipeline\nfrom keras.layers import Dense, Activation\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,MaxPooling1D,GlobalAveragePooling1D\n\ntf.random.set_seed(42)\nnp.random.seed(42)","73e902ad":"# view all files in the dataset\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c216e9bd":"# import MIT-BIH Arrhythmia Data\ndata_train = pd.read_csv('..\/input\/heartbeat\/mitbih_train.csv',header=None)\ndata_test = pd.read_csv('..\/input\/heartbeat\/mitbih_test.csv',header=None)","24f0d520":"# check class labels of BIH dataset\nprint(\"BIH train class label: \" + str(list(data_train[data_train.columns[-1]].unique())))\nprint(\"BIH test class label: \" + str(list(data_test[data_test.columns[-1]].unique())))","346b7c67":"# shuffle the DataFrame rows \ndata_train = data_train.sample(frac = 1)\ndata_test = data_test.sample(frac = 1)","08fd506f":"print(\"Training dataset shape:\")\nprint(data_train.shape)\nprint(\"Test dataset shape:\")\nprint(data_test.shape)","a03ced81":"data_train.describe()","1d59b254":"# plot two randomly selected ECG data from the training set\nplt.figure(figsize=(15,4))\nplt.subplot(211)\nplt.plot(data_train.iloc[random.randint(0,len(data_train)),:187])\nplt.gca().axes.get_xaxis().set_ticks([])\nplt.subplot(212)\nplt.plot(data_train.iloc[random.randint(0,len(data_train)),:187])\nplt.show()","fd56b941":"# plot ECG data belonging to each class label\nlabel = [\"Non-ecotic beats\",\"Supraventricular ectopic beats\",\"Ventricular ectopic beats\",\n         \"Fusion Beats\",\"Unknown Beats\"]\ncolor = ['blue','red','green','orange','purple','black']\nfig, ax = plt.subplots(5, 1, sharex=True, sharey=True,figsize=(20,12))\nfor i, row in enumerate(ax):\n    row.plot((data_train[data_train[187] == i].iloc[0])[:-1], label=label[i], color=color[i])\n    row.legend(fontsize=12)\nfig.text(0.5, 0.04, 'Amplitude', va='center', ha='center', fontsize=15)\nfig.text(0.04, 0.5, 'Time (ms)', va='center', ha='center', rotation='vertical', fontsize=15)\n\nplt.show()","d179d493":"# display number of records in each category\ndata_train[data_train.columns[-1]].value_counts()","b4697eb1":"# plot number of records in each category\nplt.figure(figsize=(15,7.5))\nplt.pie(data_train[187].value_counts(), labels=['Non-ecotic beats','Unknown Beats','Ventricular ectopic beats',\n                                                'Supraventricular ectopic beats','Fusion Beats'],\n        colors=['yellowgreen','khaki','paleturquoise','slategrey','thistle'],autopct='%2.1f%%')\np=plt.gcf()\np.gca().add_artist(plt.Circle( (0,0), 0.7, color='white'))\nplt.show()","85d824d0":"steps = [('o', SMOTE(sampling_strategy=0.5)), ('u', RandomUnderSampler(sampling_strategy=0.7))]\npipeline = Pipeline(steps=steps)","0f86fd9c":"def balance(train,df_0):\n    data, label = [0] * len(set(list(train[train.columns[-1]]))), [0] * len(set(list(train[train.columns[-1]])))\n    for i in set(list(train[train.columns[-1]])):\n        if i == 0.0:\n            continue\n        else:\n            df = train[train[train.columns[-1]] == i]\n\n        train_df = pd.concat([df_0,df])\n        X = train_df[train_df.columns[:-1]]\n        y = train_df[train_df.columns[-1]]\n        # transform the dataset\n        X, y = pipeline.fit_resample(X, y)\n        \n        data[int(i)] = X[y==i]\n        label[int(i)] = y[y==i]\n    return data, label, X, y\n\ndf_0 = data_train[data_train[data_train.columns[-1]] == 0].sample(n=20000,random_state=42)\ntemp, temp_l, X, y = balance(data_train,df_0)","0176835e":"X_train = X[y==0]\ny_train = y[y==0]\nfor i in range(1,len(temp)):\n    X_train = pd.concat([X_train,temp[i]])\n    y_train = pd.concat([y_train,pd.Series(np.array(temp_l[i]))])","99737842":"X_train.shape, y_train.shape","b6ea7486":"# display number of records in each category\ny_train.value_counts()","23625be6":"# plot number of records in each category\nplt.figure(figsize=(15,7.5))\nplt.pie(y_train.value_counts(),labels=['Non-ecotic beats','Unknown Beats','Ventricular ectopic beats',\n                                       'Supraventricular ectopic beats','Fusion Beats'],\n        colors=['yellowgreen','khaki','paleturquoise','slategrey','thistle'],autopct='%2.1f%%')\np=plt.gcf()\np.gca().add_artist(plt.Circle( (0,0), 0.7, color='white'))\nplt.show()","f02fb9f2":"X_test = data_test[data_test.columns[:-1]]\ny_test = data_test[data_test.columns[-1]]\nX_test, y_test = shuffle(X_test, y_test)\nX_test.shape, y_test.shape","adb6d244":"start_time = time.time()\nmodel = make_pipeline(StandardScaler(), SVC(gamma='auto'))\nmodel.fit(X_train, y_train)\nPipeline(steps=[('standardscaler', StandardScaler()),('svc', SVC(gamma='auto'))])","1d2673f0":"y_pred = model.predict(X_test)\nprint(\"Accuracy: \",sum(y_test == y_pred)\/len(y_test)*100,'%')\nprint(\"Execution time: \", (time.time() - start_time)\/60,'minutes')","a7e65a22":"# run a deep feed forward neural network\nstart_time = time.time()\nscaler = StandardScaler()\n\ndef create_model():\n    model = keras.models.Sequential([\n        keras.layers.Dense(100, input_shape=(187,), kernel_initializer=\"he_normal\"),\n        keras.layers.PReLU(),\n        keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n        keras.layers.PReLU(),\n        keras.layers.Dense(200, kernel_initializer=\"he_normal\"),\n        keras.layers.PReLU(),\n        keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n        keras.layers.PReLU(),\n        keras.layers.Dense(50, kernel_initializer=\"he_normal\"),\n        keras.layers.PReLU(),\n        keras.layers.Dense(5, activation=\"softmax\")\n    ])\n    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    return model\n\ncallbacks = [EarlyStopping(monitor='val_loss', patience=5),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\n# wrap the model using the function you created\nclf = KerasClassifier(create_model, epochs=40, callbacks=callbacks, batch_size=32)\n\npipeline = Pipeline([('preprocess',scaler),('clf',clf)])\n\npipeline.fit(X_train, y_train)","4fd64a2f":"y_pred = pipeline.predict(X_test)\nprint(\"Accuracy: \",sum(y_test == y_pred)\/len(y_test)*100,'%')\nprint(\"Execution time: \", (time.time() - start_time)\/60,'minutes')","d232213d":"# convert labels to one hot encoded values\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","dd62638c":"# frame the training and test data a 3D matrix\nX_train = np.asarray(X_train)\nX_train = X_train.reshape(len(X_train), X_train.shape[1],1)\nX_test = np.asarray(X_test)\nX_test = X_test.reshape(len(X_test), X_test.shape[1],1)","b278ac28":"print(\"X_train\", X_train.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"X_test\", X_test.shape)\nprint(\"y_test\", y_test.shape)","aa0fb7ff":"# run a convolution neural network\nstart_time = time.time()\n\nmodel = Sequential()\nmodel.add(Convolution1D(32, (6), activation='relu', input_shape=(X_train.shape[1],1)))\nmodel.add(MaxPooling1D(pool_size=(3), strides=(2), padding=\"same\"))\nmodel.add(Convolution1D(64, (3), activation='relu'))\nmodel.add(MaxPooling1D(pool_size=(2), strides=(2), padding=\"same\"))\nmodel.add(Convolution1D(32, (2), activation='relu'))\nmodel.add(MaxPooling1D(pool_size=(2), strides=(2), padding=\"same\"))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n    \nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \ncallbacks = [EarlyStopping(monitor='val_loss', patience=5),\n             ModelCheckpoint(filepath='cnn_best_model.h5', monitor='val_loss', save_best_only=True)]\n\nhistory=model.fit(X_train, y_train,epochs=40,callbacks=callbacks, batch_size=32)\nmodel.load_weights('cnn_best_model.h5')","f984f903":"print('Test accuracy is: %.2f%%' %(model.evaluate((X_test),y_test)[1]*100))\nprint(\"Execution time: \", (time.time() - start_time)\/60,'minutes')","b8fc47b2":"model.summary()","24d89908":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test.argmax(axis=1), model.predict(X_test).argmax(axis=1))\nnp.set_printoptions(precision=2)\ncnf_matrix","d09c741a":"# Plot non-normalized confusion matrix\ndef plot_confusion_matrix(cm, classes,normalize=False,cmap=\"YlGnBu\"):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    acc = \"{:.2f}\".format(np.trace(cnf_matrix)\/np.sum(cnf_matrix)*100)\n    plt.title('Confusion matrix \\n Classification accuracy is: ' + str(acc)+'%')\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=label,normalize=False)\nplt.show()","c43786f9":"y_pred = model.predict(X_test)","9c69545d":"y_temp = np.argmax(y_pred, axis=1)\ny_real = np.argmax(y_test, axis=1)\nprecision,recall,fscore,support = precision_recall_fscore_support(y_real, y_temp, average='weighted')\nprint('Precision : %.3f%%' % (precision*100))\nprint('Recall : %.3f%%' % (recall*100))\nprint('F1 score : %.3f%%' % (fscore*100))","c3071348":"## **Load Data**","b4d96925":"## **Dealing with imbalanced data**","f880a774":"Several methods have been proposed in the past to automatically classify heartbeats from ECG signals, these includes Fourier transform, principle component analysis, wavelet transform, and the hidden Markov method. Moreover, machine learning methods, such as artificial neural networks (ANNs), support vector machines (SVMs), least squares support vector machines (LS-SVMs), particle swarm optimization support vector machines (PSO-SVMs), particle swarm optimization radial basis functions (PSO-RBFs), and extreme learning machines (ELMs), have also been developed for the accurate classification of heartbeats.\n\nHowever, there are some drawbacks to these classification methods. For example, expert systems require a large amount of prior knowledge, which may vary for different patients. Another problem lies in the manual feature selection of the heartbeat signal for some machine learning methods. ECG feature extraction is a key technique for heartbeat recognition, which is used to select a representative feature subset from the raw ECG signal. However, manual selection may result in the loss of information. Moreover, methods like the PCA and Fourier transform may increase the complexity and computational time required to identify a solution. As the number of patients increases, the classification accuracy will decrease due to the large variation in the patterns of the ECG signals among different patients.","d4188561":"# **In *silico* categorization of arrhythmia subtypes from ECG recordings.**","912537f8":"## Baseline model","f704e838":"The challenge of working with imbalanced datasets is that most machine learning techniques will ignore, and in turn have poor performance on, the minority class, although typically it is the performance on the minority class that is most important.\n\nOne approach to address this problem is to oversample the examples in the minority class. The simplest approach involves duplicating examples from the minority class in the training dataset prior to fitting a model. This can balance the class distribution but does not provide any additional information to the model. An improvement on duplicating examples from the minority class is to synthesize new examples from the minority class. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique (SMOTE). This technique was described by **Nitesh Chawla, et al.** in their 2002 paper *\u201cSMOTE: Synthetic Minority Over-sampling Technique.\u201d*\n\nSMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line. Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbours for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space.\n\nA general downside of the approach is that synthetic examples are created without considering the majority class, possibly resulting in ambiguous examples if there is a strong overlap for the classes.\n\nRefer: https:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/","d78e23b4":"## **Exploratory analysis**","58797080":"## **Model preparation and training**","ffe03a1b":"From the figure above it can be observed that all recordings are not of the same length, and are zero padded.","03399349":"### **Why a convolution neural network over feed forward neural network?**\nConvolutional neural networks (CNN) are useful tools that have been used in pattern recognition applications, such as the classification of handwriting and object recognition in large archives. The connectivity between neurons in a CNN is similar to the organization of the visual cortex in animals, which makes CNNs superior to other methods in the recognition of the pattern and structure of items. CNN also provide a number of advantages over conventional classification techniques in biomedical applications. They are a specialized type of neural network with an inherent grid-like topology for processing input data in which nearby entries are correlated.\n\nA CNN is able to successfully capture the spatial and temporal dependencies in an image through the application of relevant filters. The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights. In other words, the network can be trained to understand the sophistication of the image better.","3c22a730":"## BIH-Arrhythmia Dataset\nTwenty-three recordings were chosen at random from a set of 4000 24-hour ambulatory ECG recordings collected from a mixed population of inpatients (about 60%) and outpatients (about 40%) at Boston's Beth Israel Hospital; the remaining 25 recordings were selected from the same set to include less common but clinically significant arrhythmias that would not be well-represented in a small random sample.\n\n* **Number of Samples:** 109446\n* **Number of Categories:** 5\n* **Sampling Frequency:** 125Hz\n* **Data Source:** Physionet's MIT-BIH Arrhythmia Dataset (https:\/\/physionet.org\/content\/mitdb\/1.0.0\/)\n* **Classes:**\n    *     Non-ecotic beats (normal beat) ('N'): 0\n    *     Supraventricular ectopic beats ('S'): 1\n    *     Ventricular ectopic beats ('V'): 2\n    *     Fusion Beats ('F'): 3\n    *     Unknown Beats ('Q'): 4","eb113805":"Each feature values ranges between zero and one. The last column contains the class label."}}