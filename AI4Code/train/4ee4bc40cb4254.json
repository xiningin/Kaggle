{"cell_type":{"ae624c3b":"code","696c9924":"code","052fa6b1":"code","f3d313e0":"code","4667f03e":"code","a4427d02":"code","aad7e417":"code","204aa15e":"code","a935b5ca":"code","3994d678":"code","a121d0e6":"code","0db06fcb":"code","aa449a57":"code","22334e46":"code","9f35d910":"code","1cd83a0c":"code","a6a1f55b":"code","76b38b69":"code","6e385861":"code","303d3a25":"code","d38b9af7":"code","422608e2":"code","fb3ade7a":"code","b46cc59f":"code","fb78c216":"code","ae739ac7":"code","39c72b97":"code","1577fa3f":"code","94c9901f":"code","ddae1f18":"code","868443fb":"code","ba73276e":"code","625f2d78":"code","bf24dfc7":"code","40e2a9b5":"code","95aa1b60":"code","9809eb10":"code","b2fb1e78":"code","4729a56d":"code","b0b95b62":"code","27370bc2":"code","c8bec647":"code","f4c50cfd":"code","381110f8":"code","6ca4b8c6":"code","655b7489":"code","ea729bc9":"code","c1aa5946":"code","f9e44d18":"code","86899bca":"code","83c02cbc":"code","a9c6f1d8":"code","3217d90a":"code","7a7c484c":"code","4029270e":"code","ccef4ef1":"code","3eafc8aa":"code","41b74e2e":"code","915a7fa2":"code","2cf3eded":"code","6d006d52":"code","6a506662":"code","09c1b742":"code","17313797":"code","f59edbb5":"code","c6425405":"code","1e994670":"code","7dc5f2ee":"code","1f05ce7a":"code","416d1d73":"code","ee34acc3":"code","95db78e6":"code","a966e461":"code","a3f6fa93":"code","254900f1":"code","189e4695":"code","180cfd32":"code","bea36dee":"code","e2df2bbe":"code","230cb9eb":"code","a749b832":"code","11dba0c4":"code","9c761f7b":"code","a17cf2a1":"code","d4fd8b9a":"code","bccd98af":"code","906e6a0d":"code","9c166d4d":"code","7d342065":"code","7f2bfe1d":"code","dc151e61":"code","d0114fd7":"code","03722639":"code","8868c942":"code","e10ddceb":"code","f8ec6937":"code","09b0c03e":"code","9534e27b":"code","96956771":"code","d33f9853":"code","d1fa604c":"code","e1a48364":"code","7d16651b":"markdown","14c75301":"markdown","c0005b20":"markdown","319f82d7":"markdown","60be6cbf":"markdown","10f16e00":"markdown","3b6efa86":"markdown","bd3fbde9":"markdown","52c6c8cb":"markdown","22552788":"markdown","46104a57":"markdown","755023b6":"markdown","5f1f58c1":"markdown","808cdec6":"markdown","a817234f":"markdown","036af32a":"markdown","5a5169a0":"markdown","28aa986e":"markdown","5518ecc2":"markdown","b5d5dbb0":"markdown","94f3c943":"markdown","809af556":"markdown","e5aa53be":"markdown","f3b395a2":"markdown","a124df54":"markdown","a925c484":"markdown","171241b2":"markdown","44c38d1c":"markdown","02b2e8c1":"markdown","0eb55118":"markdown","6c7d6e93":"markdown","0e0f8da5":"markdown","6be70f18":"markdown","044cbb09":"markdown","8f2a7b63":"markdown","d5a717a7":"markdown","0039d1b5":"markdown","5a2ec1e2":"markdown","58142437":"markdown","7bf1e3f5":"markdown","eb11a435":"markdown","708b5dae":"markdown","37514d9d":"markdown","b469b680":"markdown","e092c8d0":"markdown","9b4bf7d7":"markdown","7460f016":"markdown","b0f2212c":"markdown","36e6369d":"markdown","20c0d31e":"markdown","18e87963":"markdown","c263f0ee":"markdown","7308b238":"markdown","c80b92c4":"markdown","dcf433e2":"markdown","497d6f96":"markdown","b187ae3c":"markdown","3778ef38":"markdown","eea671e3":"markdown"},"source":{"ae624c3b":"import os\nimport re\nimport string","696c9924":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","052fa6b1":"import nltk\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\n\nfrom nltk.util import ngrams","f3d313e0":"# Vectorizers\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","4667f03e":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report","a4427d02":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aad7e417":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","204aa15e":"train.head()","a935b5ca":"train.shape","3994d678":"train.isna().sum()","a121d0e6":"train.target.unique()","0db06fcb":"test.shape","aa449a57":"test.head()","22334e46":"text = train.text\ntarget = train.target","9f35d910":"def text_to_lowercase(text):\n    \"\"\"\n    Convert text to lowercase\n    \"\"\"\n    return str(text).lower()\n\ndef remove_number(text):\n    \"\"\"\n    Remove numbers\n    \"\"\"\n    result = re.sub(r'\\d+', '', text)\n    return result\n\ndef remove_punctuations(text):\n    \"\"\"\n    Remove punctuation\n    \"\"\"\n    for punctuation in string.punctuation:\n        text = text.replace(punctuation, '')\n    return text\n\ndef remove_whitespaces(text):\n    \"\"\"\n    Remove whitespaces\n    To remove leading and ending spaces\n    \"\"\"\n    return text.strip()\n\ndef base_preparation(text):\n    new_text = text_to_lowercase(text)\n    new_text = remove_number(new_text)\n    new_text = remove_punctuations(new_text)\n    new_text = remove_whitespaces(new_text)\n    return new_text","1cd83a0c":"# base text preparation\n\ntext = text.apply(base_preparation)\ntest.text = test.text.apply(base_preparation)","a6a1f55b":"# Tokenization\n\ntext = text.apply(word_tokenize)\ntest.text = test.text.apply(word_tokenize)","76b38b69":"# Remove stop words\n\nstop_words = set(stopwords.words('english'))\n\ndef remove_stop_words(text):\n    return [i for i in text if not i in stop_words]\n\ntext = text.apply(remove_stop_words)\ntest.text = test.text.apply(remove_stop_words)","6e385861":"# Lemmatizer\n\nwordnet_lemmatizer = WordNetLemmatizer()\n\ndef lemma(word_list):\n    return [wordnet_lemmatizer.lemmatize(w) for w in word_list]\n\ntext = text.apply(lemma)\ntest.text = test.text.apply(lemma)","303d3a25":"def do_nothing(tokens):\n    return tokens\n\n# TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(\n    tokenizer=do_nothing, \n    preprocessor=None,\n    lowercase=False,\n    # ngram_range=(1, 2)\n)","d38b9af7":"text_counts = tfidf_vectorizer.fit_transform(text)","422608e2":"X_train, X_test, y_train, y_test = train_test_split(\n    text_counts, \n    target, \n    test_size=0.3, \n    random_state=1\n)","fb3ade7a":"print(\"X train shape: {0}\".format(X_train.shape))\nprint(\"Y train shape: {0}\".format(y_train.shape))\nprint(\"X test shape: {0}\".format(X_test.shape))\nprint(\"Y test shape: {0}\".format(y_test.shape))","b46cc59f":"from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.neighbors import RadiusNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import RidgeClassifierCV","fb78c216":"from sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier","ae739ac7":"def model_scoring(clf, X_test, y_test):\n    predicted= clf.predict(X_test)\n    print(classification_report(y_test, predicted))","39c72b97":"%%time\n# BernoulliNB\n\nclf = BernoulliNB().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_bernouli_nb = round(clf.score(X_test, y_test) * 100, 2)","1577fa3f":"%%time\n# DecisionTreeClassifier\n\nclf = DecisionTreeClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_decision_tree = round(clf.score(X_test, y_test) * 100, 2)","94c9901f":"%%time\n# ExtraTreesClassifier\n\nclf = ExtraTreesClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_extra_tree = round(clf.score(X_test, y_test) * 100, 2)","ddae1f18":"%%time\n# KNeighborsClassifier\n\nclf = KNeighborsClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_knn = round(clf.score(X_test, y_test) * 100, 2)","868443fb":"%%time\n# LinearSVC  (setting multi_class=\u201dcrammer_singer\u201d)\n\nclf = LinearSVC(multi_class=\"crammer_singer\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_linear_svc = round(clf.score(X_test, y_test) * 100, 2)","ba73276e":"%%time\n# LogisticRegressionCV(setting multi_class=\u201dmultinomial\u201d)\n\nclf = LogisticRegressionCV(multi_class=\"multinomial\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_logistic_cv = round(clf.score(X_test, y_test) * 100, 2)","625f2d78":"%%time\n# MLPClassifier\n\nclf = MLPClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_mlp = round(clf.score(X_test, y_test) * 100, 2)","bf24dfc7":"%%time\n# RandomForestClassifier()\n\nclf = RandomForestClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_random_forest = round(clf.score(X_test, y_test) * 100, 2)","40e2a9b5":"%%time\n# RidgeClassifier\n\nclf = RidgeClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_ridge = round(clf.score(X_test, y_test) * 100, 2)","95aa1b60":"%%time\n# RidgeClassifierCV\n\nclf = RidgeClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_ridge_cv = round(clf.score(X_test, y_test) * 100, 2)","9809eb10":"%%time\n# SVC\n\nclf = SVC().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_svc = round(clf.score(X_test, y_test) * 100, 2)","b2fb1e78":"%%time\n# GradientBoostingClassifier\n\nclf = GradientBoostingClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_gbc = round(clf.score(X_test, y_test) * 100, 2)","4729a56d":"%%time\n# LinearSVC\n\nclf = LinearSVC(multi_class = \"ovr\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_linear_svc2 = round(clf.score(X_test, y_test) * 100, 2)","b0b95b62":"%%time\n# LogisticRegression multi_class=\u201dovr\u201d\n\nclf = LogisticRegression(multi_class=\"ovr\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_logistic_reg = round(clf.score(X_test, y_test) * 100, 2)","27370bc2":"%%time\n# SGDClassifier\n\nclf = SGDClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_sgd = round(clf.score(X_test, y_test) * 100, 2)","c8bec647":"%%time\n# Perceptron\n\nclf = Perceptron().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_perceptron = round(clf.score(X_test, y_test) * 100, 2)","f4c50cfd":"%%time\n# PassiveAggressiveClassifier\n\nclf = PassiveAggressiveClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_pac = round(clf.score(X_test, y_test) * 100, 2)","381110f8":"# evaluation\n\nmodel_results = pd.DataFrame({\n    'Models': [\n        'BernoulliNB',\n        'Decision Tree',\n        'Extra Tree',\n        'KNN',\n        'Linear SVC',\n        'Logistic Regression CV',\n        'MLP',\n        'Random Forest',\n        'Ridge',\n        'Ridge CV',\n        'SVC',\n        'GBC',\n        'Linear SVC 2',\n        'Logistic Regression',\n        'SGDC',\n        'Perceptron',\n        'PAC'\n    ],\n    'Scores': [\n        acc_bernouli_nb,\n        acc_decision_tree,\n        acc_extra_tree,\n        acc_knn,\n        acc_linear_svc,\n        acc_logistic_cv,\n        acc_mlp,\n        acc_random_forest,\n        acc_ridge,\n        acc_ridge_cv,\n        acc_svc,\n        acc_gbc,\n        acc_linear_svc2,\n        acc_logistic_reg,\n        acc_sgd,\n        acc_perceptron,\n        acc_pac\n    ]\n})\nmodel_results.sort_values(by='Scores', ascending=False)","6ca4b8c6":"the_best_clf = BernoulliNB().fit(text_counts, target)","655b7489":"submition_example = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')\nsubmition_example.head()","ea729bc9":"test_vectors = tfidf_vectorizer.transform(test.text)","c1aa5946":"def submission(submission_file_path,model,test_vectors):\n    sample_submission = pd.read_csv(submission_file_path)\n    sample_submission[\"target\"] = model.predict(test_vectors)\n    sample_submission.to_csv(\"submission.csv\", index=False)","f9e44d18":"submission_file_path = \"..\/input\/nlp-getting-started\/sample_submission.csv\"\nsubmission(submission_file_path,the_best_clf,test_vectors)","86899bca":"import gensim\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument","83c02cbc":"import multiprocessing\ncores = multiprocessing.cpu_count()","a9c6f1d8":"from tqdm import tqdm\ntqdm.pandas(desc=\"progress-bar\")","3217d90a":"from sklearn import utils","7a7c484c":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","4029270e":"# base text preparation\n\ntrain.text = train.text.apply(base_preparation)\ntest.text = test.text.apply(base_preparation)","ccef4ef1":"# Tokenization\n\ntrain.text = train.text.apply(word_tokenize)\ntest.text = test.text.apply(word_tokenize)","3eafc8aa":"# Remove stop words\n\nstop_words = set(stopwords.words('english'))\n\ndef remove_stop_words(text):\n    return [i for i in text if not i in stop_words]\n\ntrain.text = train.text.apply(remove_stop_words)\ntest.text = test.text.apply(remove_stop_words)","41b74e2e":"# Lemmatizer\n\nwordnet_lemmatizer = WordNetLemmatizer()\n\ndef lemma(word_list):\n    return [wordnet_lemmatizer.lemmatize(w) for w in word_list]\n\ntrain.text = train.text.apply(lemma)\ntest.text = test.text.apply(lemma)","915a7fa2":"train_text, test_text = train_test_split(train, test_size=0.3, random_state = 42)","2cf3eded":"train_tagged = train_text.apply(\n    lambda r: TaggedDocument(words=r['text'], tags=[r.target]), axis=1)\ntest_tagged = test_text.apply(\n    lambda r: TaggedDocument(words=r['text'], tags=[r.target]), axis=1)","6d006d52":"# Building a Vocabulary\n\nmodel_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\nmodel_dbow.build_vocab([x for x in tqdm(train_tagged.values)])","6a506662":"%%time\nfor epoch in range(10):\n    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n    model_dbow.alpha -= 0.002\n    model_dbow.min_alpha = model_dbow.alpha","09c1b742":"# Buliding the final vector feature for the classifier\n\ndef vec_for_learning(model, tagged_docs):\n    sents = tagged_docs.values\n    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n    return targets, regressors","17313797":"y_train, X_train = vec_for_learning(model_dbow, train_tagged)\ny_test, X_test = vec_for_learning(model_dbow, test_tagged)","f59edbb5":"print(\"X train shape: {0}\".format(np.array(X_train).shape))\nprint(\"Y train shape: {0}\".format(np.array(y_train).shape))\nprint(\"X test shape: {0}\".format(np.array(X_test).shape))\nprint(\"Y test shape: {0}\".format(np.array(y_test).shape))","c6425405":"%%time\n# BernoulliNB\n\nclf = BernoulliNB().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_bernouli_nb = round(clf.score(X_test, y_test) * 100, 2)","1e994670":"%%time\n# DecisionTreeClassifier\n\nclf = DecisionTreeClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_decision_tree = round(clf.score(X_test, y_test) * 100, 2)","7dc5f2ee":"%%time\n# ExtraTreesClassifier\n\nclf = ExtraTreesClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_extra_tree = round(clf.score(X_test, y_test) * 100, 2)","1f05ce7a":"%%time\n# KNeighborsClassifier\n\nclf = KNeighborsClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_knn = round(clf.score(X_test, y_test) * 100, 2)","416d1d73":"%%time\n# LinearSVC  (setting multi_class=\u201dcrammer_singer\u201d)\n\nclf = LinearSVC(multi_class=\"crammer_singer\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_linear_svc = round(clf.score(X_test, y_test) * 100, 2)","ee34acc3":"%%time\n# LogisticRegressionCV(setting multi_class=\u201dmultinomial\u201d)\n\nclf = LogisticRegressionCV(multi_class=\"multinomial\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_logistic_cv = round(clf.score(X_test, y_test) * 100, 2)","95db78e6":"%%time\n# MLPClassifier\n\nclf = MLPClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_mlp = round(clf.score(X_test, y_test) * 100, 2)","a966e461":"%%time\n# RandomForestClassifier()\n\nclf = RandomForestClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_random_forest = round(clf.score(X_test, y_test) * 100, 2)","a3f6fa93":"%%time\n# RidgeClassifier\n\nclf = RidgeClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_ridge = round(clf.score(X_test, y_test) * 100, 2)","254900f1":"%%time\n# RidgeClassifierCV\n\nclf = RidgeClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_ridge_cv = round(clf.score(X_test, y_test) * 100, 2)","189e4695":"%%time\n# SVC\n\nclf = SVC().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_svc = round(clf.score(X_test, y_test) * 100, 2)","180cfd32":"%%time\n# GradientBoostingClassifier\n\nclf = GradientBoostingClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_gbc = round(clf.score(X_test, y_test) * 100, 2)","bea36dee":"%%time\n# LinearSVC\n\nclf = LinearSVC(multi_class = \"ovr\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_linear_svc2 = round(clf.score(X_test, y_test) * 100, 2)","e2df2bbe":"%%time\n# LogisticRegression multi_class=\u201dovr\u201d\n\nclf = LogisticRegression(multi_class=\"ovr\").fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_logistic_reg = round(clf.score(X_test, y_test) * 100, 2)","230cb9eb":"%%time\n# SGDClassifier\n\nclf = SGDClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_sgd = round(clf.score(X_test, y_test) * 100, 2)","a749b832":"%%time\n# Perceptron\n\nclf = Perceptron().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_perceptron = round(clf.score(X_test, y_test) * 100, 2)","11dba0c4":"%%time\n# PassiveAggressiveClassifier\n\nclf = PassiveAggressiveClassifier().fit(X_train, y_train)\nmodel_scoring(clf, X_test, y_test)\n\nacc_pac = round(clf.score(X_test, y_test) * 100, 2)","9c761f7b":"model_results = pd.DataFrame({\n    'Models': [\n        'BernoulliNB',\n        'Decision Tree',\n        'Extra Tree',\n        'KNN',\n        'Linear SVC',\n        'Logistic Regression CV',\n        'MLP',\n        'Random Forest',\n        'Ridge',\n        'Ridge CV',\n        'SVC',\n        'GBC',\n        'Linear SVC 2',\n        'Logistic Regression',\n        'SGDC',\n        'Perceptron',\n        'PAC'\n    ],\n    'Scores': [\n        acc_bernouli_nb,\n        acc_decision_tree,\n        acc_extra_tree,\n        acc_knn,\n        acc_linear_svc,\n        acc_logistic_cv,\n        acc_mlp,\n        acc_random_forest,\n        acc_ridge,\n        acc_ridge_cv,\n        acc_svc,\n        acc_gbc,\n        acc_linear_svc2,\n        acc_logistic_reg,\n        acc_sgd,\n        acc_perceptron,\n        acc_pac\n    ]\n})\nmodel_results.sort_values(by='Scores', ascending=False)","a17cf2a1":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","d4fd8b9a":"from sklearn.preprocessing import LabelBinarizer, LabelEncoder","bccd98af":"from tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.preprocessing import text, sequence\nfrom keras import utils\nimport tensorflow as tf","906e6a0d":"df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","9c166d4d":"df.text = df.text.apply(base_preparation)","7d342065":"train_size = int(len(df) * .7)\nprint (\"Train size: %d\" % train_size)\nprint (\"Test size: %d\" % (len(df) - train_size))","7f2bfe1d":"train_posts = df.text[:train_size]\ntrain_tags = df.target[:train_size]\n\ntest_posts = df.text[train_size:]\ntest_tags = df.target[train_size:]","dc151e61":"max_words = 10000\ntokenize = text.Tokenizer(num_words=max_words, char_level=False)","d0114fd7":"tokenize.fit_on_texts(train_posts) # only fit on train\nx_train = tokenize.texts_to_matrix(train_posts)\nx_test = tokenize.texts_to_matrix(test_posts)","03722639":"encoder = LabelEncoder()\nencoder.fit(train_tags)\ny_train = encoder.transform(train_tags)\ny_test = encoder.transform(test_tags)","8868c942":"num_classes = np.max(y_train) + 1\ny_train = utils.to_categorical(y_train, num_classes)\ny_test = utils.to_categorical(y_test, num_classes)","e10ddceb":"print('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\nprint('y_train shape:', y_train.shape)\nprint('y_test shape:', y_test.shape)","f8ec6937":"batch_size = 32\nepochs = 10","09b0c03e":"# Build the model\nmodel = Sequential()\nmodel.add(Dense(512, input_shape=(max_words,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","9534e27b":"model.summary()","96956771":"history = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_split=0.1)","d33f9853":"loss, accuracy = model.evaluate(x_train, y_train, verbose=1)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\nloss, accuracy = model.evaluate(x_test, y_test, verbose=1)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","d1fa604c":"def plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    x = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, 'b', label='Training acc')\n    plt.plot(x, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, 'b', label='Training loss')\n    plt.plot(x, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()","e1a48364":"plot_history(history)","7d16651b":"### 5.10. Ridge Classifier","14c75301":"### 5.5. KNeighbors Classifier","c0005b20":"### 6.16. SVC","319f82d7":"### 5.3. Decision Tree Classifier","60be6cbf":"### 6.11. Logistic RegressionCV","10f16e00":"# Real or Not? NLP with Disaster Tweets\n**Predict which Tweets are about real disasters and which ones are not**\n\n![twitter](https:\/\/static01.nyt.com\/images\/2019\/12\/23\/opinion\/twitter-activism-1577394747095\/twitter-activism-1577394747095-videoSixteenByNineJumbo1600.jpg)","3b6efa86":"# Content\n\n1. [Import](#1.-Import)\n2. [Read data](#2.-Read-data)\n3. [Data research](#3.-Data-research)\n4. [Data preparation](#4.-Data-preparation)\n    * [4.1. Text preparation functions](#4.1.-Text-preparation-functions)\n    * [4.2. Text preparation](#4.2.-Text-preparation)\n    * [4.3. Split test and train data](#4.3.-Split-test-and-train-data)\n5. [Modeling](#5.-Modeling)\n    * [5.1. Modeling import](#5.1.-Modeling-import)\n    * [5.2. BernoulliNB](#5.2.-BernoulliNB)\n    * [5.3. Decision Tree Classifier](#5.3.-Decision-Tree-Classifier)\n    * [5.4. Extra Trees Classifier](#5.4.-ExtraTreesClassifier)\n    * [5.5. KNeighbors Classifier](#5.5.-KNeighbors-Classifier)\n    * [5.6. LinearSVC](#5.6.-LinearSVC)\n    * [5.7. Logistic RegressionCV](#5.7.-LogisticRegressionCV)\n    * [5.8. MLPClassifier](#5.8.-MLPClassifier)\n    * [5.9. Random Forest Classifier](#5.9.-Random-Forest-Classifier)\n    * [5.10. Ridge Classifier](#5.10.-Ridge-Classifier)\n    * [5.11. RidgeClassifierCV](#5.11.-RidgeClassifierCV)\n    * [5.12. SVC](#5.12.-SVC)\n    * [5.13. Gradient Boosting Classifier](#5.13.-Gradient-Boosting-Classifier)\n    * [5.14. LinearSVC](#5.14.-LinearSVC)\n    * [5.15. LogisticRegression](#5.15.-LogisticRegression)\n    * [5.16. SGDClassifier](#5.16.-SGDClassifier)\n    * [5.17. Perceptron](#5.17.-Perceptron)\n    * [5.18. Passive Aggressive Classifier](#5.18.-Passive-Aggressive-Classifier)\n    * [5.19. Model evaluation](#5.19.-Model-evaluation)\n    * [5.20. Use the best model for submiting](#5.20.-Use-the-best-model-for-submiting)","bd3fbde9":"Twitter is not only space with memes. \n\n![meme](https:\/\/i.pinimg.com\/originals\/83\/eb\/d8\/83ebd8ae3985a37b070f70ccafe8409e.jpg)\n\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they\u2019re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n\nBut, it\u2019s not always clear whether a person\u2019s words are actually announcing a disaster. Take this example:\n\n![example](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/tweet_screenshot.png)","52c6c8cb":"### 6.7. Decision Tree Classifier","22552788":"# 6. Modeling with Doc2Vec","46104a57":"### 5.6. LinearSVC","755023b6":"### 6.22. Passive Aggressive Classifier","5f1f58c1":"# 3. Data research","808cdec6":"### 5.11. RidgeClassifierCV","a817234f":"### 5.2. BernoulliNB","036af32a":"### 6.8. Extra Trees Classifier","5a5169a0":"### 6.20. SGDClassifier","28aa986e":"### 6.17. Gradient Boosting Classifier","5518ecc2":"# 1. Import","b5d5dbb0":"### 6.4. Text preparation with Doc2Vec","94f3c943":"### 5.7. LogisticRegressionCV","809af556":"### 5.1. Modeling import","e5aa53be":"### 6.1. Import","f3b395a2":"### 6.14. Ridge Classifier","a124df54":"# 7. Artificial neural network","a925c484":"### 5.17. Perceptron","171241b2":"# 4. Data preparation","44c38d1c":"### 6.2. Text preparation","02b2e8c1":"### 6.5. Pretrain gensim model","0eb55118":"### 5.13. Gradient Boosting Classifier","6c7d6e93":"### 5.20. Use the best model for submiting","0e0f8da5":"### 6.21. Perceptron","6be70f18":"### 5.18. Passive Aggressive Classifier","044cbb09":"### 6.18. LinearSVC","8f2a7b63":"### 7.2. Text preparation for ANN","d5a717a7":"### 5.4. ExtraTreesClassifier","0039d1b5":"### 5.19. Model evaluation","5a2ec1e2":"### 5.16. SGDClassifier","58142437":"### 6.23. Model evaluation","7bf1e3f5":"### 6.12. MLPClassifier","eb11a435":"### 5.14. LinearSVC","708b5dae":"### 5.15. LogisticRegression","37514d9d":"### 6.9. KNeighbors Classifier","b469b680":"### 6.19. LogisticRegression","e092c8d0":"### 4.1. Text preparation functions","9b4bf7d7":"### 5.12. SVC","7460f016":"### 6.6. BernoulliNB","b0f2212c":"### 4.3. Split test and train data","36e6369d":"# 2. Read data","20c0d31e":"### 6.13. Random Forest Classifier","18e87963":"### Work in progress...","c263f0ee":"# 5. Modeling","7308b238":"### 5.9. Random Forest Classifier","c80b92c4":"### 5.8. MLPClassifier","dcf433e2":"### 6.3. Train and test data spliting","497d6f96":"### 7.1. Import for ANN","b187ae3c":"### 6.15. RidgeClassifierCV","3778ef38":"### 4.2. Text preparation","eea671e3":"### 6.10. LinearSVC"}}