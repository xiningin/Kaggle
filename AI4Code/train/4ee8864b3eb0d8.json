{"cell_type":{"3d045fd9":"code","d6356cec":"code","15e86baf":"code","b130c455":"code","b2b53b19":"code","f1a9493b":"code","6b24039c":"code","1820c699":"code","dff9b726":"code","88eb78e8":"code","28cdab50":"code","a78ef4cc":"code","7dedabdc":"markdown","0a6847a1":"markdown","92c16024":"markdown"},"source":{"3d045fd9":"# Importing the Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport string\nimport pandas as pd\n\n\n# In[2]:\n\n\n# Deep Learning Imports\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, add,MaxPooling2D, concatenate,Reshape, Bidirectional, LSTM,GRU, Dense, Lambda, Activation, BatchNormalization, Dropout,Concatenate\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad\n","d6356cec":"# from tensorflow.keras import mixed_precision\n\n\n# policy = mixed_precision.experimental.Policy('mixed_float16')\n# mixed_precision.set_global_policy(policy)\n\n# os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n# In[3]:\ntimestamps=64\nchar=string.ascii_uppercase+\".\/-0123456789\"\n\n# char=string.ascii_lowercase\ntest_dir=\"..\/input\/20k-synthetic-ocr-dataset\/files\/20k test\"\ntrain_dir=\"..\/input\/20k-synthetic-ocr-dataset\/files\/20k train\"\n# Preparing the Data\n\n\n### check train and test set distribution\n\nfor d,c in zip([test_dir, train_dir],[\"..\/input\/20k-synthetic-ocr-dataset\/test.csv\",\"..\/input\/20k-synthetic-ocr-dataset\/train.csv\"]):\n\n    print(c.split(\".\")[0]+\"set distribution\")\n    filename=[os.path.join(d,i) for i in os.listdir(d)]\n\n    track=dict(zip(char,[0]*len(char)))\n    data=pd.read_csv(c)\n    for file in data[\"label\"]:\n        for l in file:\n            track[l]+=1\n    print(track)\n    print(\"====\"*20)\n","15e86baf":"def num2label(num):\n ret = \"\"\n for ch in num:\n     if ch == -1:  # CTC Blank\n         break\n     else:\n         ret+=alphabets[ch]\n return ret\n\n\n\n# In[4]:\n\n\n# Custom Data Generator\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self,batch_size=256,image_size=16,max_str_len=20,channels=3,path_to_img_dir=train_dir,shuffle=True,timestamps=timestamps,data=\"..\/input\/20k-synthetic-ocr-dataset\/train.csv\"):\n        self.info_csv=pd.read_csv(data)\n        self.batch_size = batch_size\n        self.image_size=image_size\n        self.channels=channels\n        self.shuffle = shuffle\n#         self.on_epoch_end()\n        self.alphabets=char\n        self.max_str_len=max_str_len\n        self.num_characters=len(self.alphabets)+1\n        self.num_timestamps=timestamps\n        self.path=path_to_img_dir\n        self.num_examples=len(os.listdir(self.path))\n        self.indices =list(range(self.num_examples))\n        self.images_path=[os.path.join(self.path,i) for i in self.info_csv[\"image name\"]]\n        self.label=self.info_csv[\"label\"]\n        self.n = 0\n        self.max = self.__len__()\n\n    def __len__(self):\n        return len(self.indices) \/\/ self.batch_size\n\n    def __getitem__(self, index):\n        inds = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n#         batch = [self.indices[k] for k in index]\n        \n        X,y,label_len,output_len,output = self.__get_data(inds)\n        \n        return [X,y,output_len,label_len],output\n\n    def label_to_num(self,label):\n        label_num = []\n        for ch in label:\n            label_num.append(self.alphabets.find(ch))\n\n        return np.array(label_num)\n\n\n    def on_epoch_end(self):\n        self.index = np.arange(len(self.indices))\n        if self.shuffle == True:\n            np.random.shuffle(self.index)\n            \n    def create_labels(self,raw_labels,batch):\n        num_examples=len(batch)\n        y = np.ones([num_examples,self.max_str_len]) * -1\n        label_len = np.zeros([num_examples, 1])\n        output_len = np.ones([num_examples,1]) * (self.num_timestamps-2)\n        output = np.zeros([num_examples])\n\n        for i in range(num_examples):\n            label_len[i] = len(raw_labels[i])\n            y[i, 0:len(raw_labels[i])]= self.label_to_num(raw_labels[i])\n\n        return y,label_len,output_len,output\n\n    def preprocess(self,imgPath):\n        img=cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)\n        img=cv2.resize(img,(256,64))\n    \n        (h, w) = img.shape\n        \n        final_img = np.ones([64, 256])*255 # blank white image\n        \n        # crop\n        if w > 256:\n            img = img[:, :256]\n            \n        if h > 64:\n            img = img[:64, :]\n        \n        \n        final_img[:h, :w] = img\n        train_x=cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)\/255.\n\n        return train_x\n\n    def preprocess_data(self,batch):\n        images_array=[]\n        labels=[]\n        \n        batch_images=[self.images_path[i] for i in batch]\n        lbls=[self.label[i] for i in batch]\n        for single_image_path,label in zip(batch_images,lbls):\n\n            img=self.preprocess(single_image_path)\n            images_array.append(np.expand_dims(img,axis=0))\n            \n            labels.append(label)\n            \n        train_x=np.vstack(images_array)\n        \n        return np.array(train_x).reshape(-1, 256, 64, 1) ,np.array(labels)\n\n    def __get_data(self, batch):\n        input_images,input_labels=self.preprocess_data(batch)\n        \n        input_y,input_label_len,input_output_len,input_output=self.create_labels(input_labels,batch)\n            \n        return input_images, input_y,input_label_len,input_output_len,input_output\n    \n    def __next__(self):\n        if self.n >= self.max:\n           self.n = 0\n        result= self.__getitem__(self.n)\n        self.n += 1\n        return result\n\n\n# In[5]:","b130c455":"train_dg=DataGenerator()\nval_dg=DataGenerator(path_to_img_dir=test_dir,data=\"..\/input\/20k-synthetic-ocr-dataset\/test.csv\")\n\nx,y=next(val_dg)","b2b53b19":"\n# Preparing Labels for CTC Loss\nimages=os.listdir(train_dir)\n\nalphabets = char\n\nmax_str_len=20\n\nnum_of_characters=len(alphabets)+1\n\nnum_of_timestamps=timestamps\n\n\n## verify data\n\n# for i in range(10):\n#     plt.imshow(x[0][i])\n#     word=num2label(x[1][i].astype(\"int\"))\n#     print(word)\n#     plt.show()\n\n\ninput_data = Input(shape=(256, 64, 1), name='input')\n\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = Conv2D(64, (3, 3), padding='same', name='conv2_1', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\ninner = Dropout(0.5)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = Conv2D(128, (3, 3), padding='same', name='conv3_1', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\ninner = Dropout(0.7)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\ninner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n## RNN\ninner = Bidirectional(GRU(256, return_sequences=True), name = 'lstm1')(inner)\ninner = Bidirectional(GRU(256, return_sequences=True), name = 'lstm2')(inner)\n\n## OUTPUT\ninner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\n# model.summary()\n\n\n\n\n\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n","f1a9493b":"\nlabels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, labels, input_length, label_length],outputs=ctc_loss)\n","6b24039c":"model_final.summary()","1820c699":"## Defining Model Callbacks\nsave_best=tf.keras.callbacks.ModelCheckpoint(filepath=\"GRU_uppercase.h5\",save_best_only=True,save_weights_only=True,verbose=True)\nreduce_lr=tf.keras.callbacks.ReduceLROnPlateau(min_lr_rate=0.00000000000001,factor=0.3,patience=10,verbose=True)\n","dff9b726":"\n## Defining Model Callbacks\nsave_best=tf.keras.callbacks.ModelCheckpoint(filepath=\"GRU_uppercase.h5\",save_best_only=True,save_weights_only=True,verbose=True)\nreduce_lr=tf.keras.callbacks.ReduceLROnPlateau(min_lr_rate=0.00000000000001,factor=0.3,patience=10,verbose=True)","88eb78e8":"# model.load_weights(\"Lstm_uppercase.h5\")\n## In[ ]:\n\n# opt=tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name=\"Adadelta\")\n## the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr=0.0001))\n\nmodel_final.fit(train_dg, \n                validation_data=val_dg,\n                epochs=200,callbacks=[save_best,reduce_lr],workers=8)\n\n\n","28cdab50":"model.save('20k_synthetic_ocr_dataset.h5')","a78ef4cc":"\nbatch_size=len(os.listdir(\"..\/input\/20k-synthetic-ocr-dataset\/files\/20k test\"))\ntest_dg=DataGenerator(path_to_img_dir=test_dir,data=\"..\/input\/20k-synthetic-ocr-dataset\/test.csv\",batch_size=batch_size)\n\nX,y=next(test_dg)\nprint(X[0].shape)\n# Checking the Performance of the Model on Testing Set\npreds = model.predict(X[0])\n\nprint(preds)\ndecoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=True)[0][0])\n\nprediction = []\nfor i in decoded:\n    prediction.append(num2label(i))\n\ngt = []\nfor i in X[1].astype(\"int\"):\n    gt.append(num2label(i))\n\n\n# In[47]:\n\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\n\nwrong_preds=[]\nfor i in range(X[0].shape[0]):\n    pr = prediction[i]\n    tr = gt[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr :\n        correct += 1\n\n    elif pr!=tr:\n        wrong_preds.append(i) \n    \nprint('Correct characters predicted : %.2f%%' %(correct_char*100\/total_char))\nprint('Correct words predicted      : %.2f%%' %(correct*100\/X[0].shape[0]))\n\n##\n### In[48]:\n##\n##\n\ndef preprocess(imgPath):\n        img=cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)\n        img=cv2.resize(img,(256,64))\n    \n        (h, w) = img.shape\n        \n        final_img = np.ones([64, 256])*255 # blank white image\n        \n        # crop\n        if w > 256:\n            img = img[:, :256]\n            \n        if h > 64:\n            img = img[:64, :]\n        \n        \n        final_img[:h, :w] = img\n        train_x=cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)\/255.\n\n        return train_x\n\ntest_images=np.vstack([preprocess(os.path.join('..\/input\/20k-synthetic-ocr-dataset\/files\/real_images',i)) for i in os.listdir(\"..\/input\/20k-synthetic-ocr-dataset\/files\/real_images\")])\n\ntest_array=np.array(test_images).reshape(-1, 256, 64, 1)\n\n\n\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(10):\n    ax = plt.subplot(2, 5, i+1)\n    rand_int=np.random.choice(wrong_preds)\n    image=X[0][rand_int]\n    gt=X[1][rand_int]\n    plt.imshow(np.rot90(image))\n    \n    pred = model.predict(np.expand_dims(image,axis=0))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    print(decoded)\n\n    print(num2label(gt.astype(\"int\")),\"predicted label is --->\",num2label(decoded[0]))\n    plt.title(num2label(decoded[0]), fontsize=14)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=0.8)\n\nplt.show()\n\n\n\nfor i in range(20):\n    ax = plt.subplot(2, 10, i+1)\n    rand_int=np.random.randint(0,len(test_array))\n    image=test_array[rand_int]\n    plt.imshow(np.rot90(image))\n    \n    pred = model.predict(np.expand_dims(image,axis=0))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    print(decoded)\n\n    print(\"predicted label is --->\",num2label(decoded[0]))\n    plt.title(num2label(decoded[0]), fontsize=14)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=0.8)\n\nplt.show()","7dedabdc":"# References","0a6847a1":"Models Predict the labels very well. Apart from the first Character in predictions.","92c16024":"Thanks to Aurthor for sharing this data and its code."}}