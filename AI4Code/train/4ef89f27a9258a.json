{"cell_type":{"173a34e7":"code","742eb8b8":"code","9f73796b":"code","b60b656a":"code","143dc33a":"code","5adb307a":"code","11604d88":"code","f0a2fa46":"code","4a24902f":"code","a871c893":"code","7405e59a":"code","36e579af":"code","ce1e3b17":"code","7cf11206":"code","3cb4e732":"code","a1f2221b":"code","f21c9e36":"code","adf596b1":"code","e1bdb15b":"code","8e94af0e":"code","1f1a0d76":"code","b65f09c6":"code","63686696":"code","ff275d29":"code","dfe35f3c":"code","0f39ceff":"code","612bde22":"code","36a35a73":"code","954765a6":"code","f2fd8420":"code","ef3e2356":"code","85a8ca61":"code","53cf9363":"code","7e6475a2":"code","be9f61e0":"code","bf1135d5":"code","59d4f75b":"code","ba74ffea":"code","0d33d2b0":"code","d440f0e9":"code","b5b2cfc1":"code","2683741c":"code","0c03a62c":"code","4e5e4681":"code","95b75a19":"code","1fd624c7":"code","083752f7":"code","cc52640b":"code","0cf798ea":"code","89b60f44":"code","f7d79c07":"code","5b9ccb04":"code","23618f02":"code","c8ec78b7":"code","ad459be4":"code","efd1330c":"code","03b75ca9":"code","e39b6a29":"markdown","b42034c4":"markdown","b336630e":"markdown","275c0eef":"markdown","25f81927":"markdown","64a68286":"markdown","b000194b":"markdown"},"source":{"173a34e7":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline","742eb8b8":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","9f73796b":"print(train.shape)\nprint(test.shape)","b60b656a":"# Visualize some pictures\neg_digit_image = train.iloc[10000, 1:].values.reshape(28, 28)\neg_digit_label = train.iloc[10000, 0]\nplt.imshow(eg_digit_image, cmap = mpl.cm.binary, interpolation = 'nearest')\nplt.axis('off')\nplt.show()\nprint(eg_digit_label)","143dc33a":"# shuffle train data\nfrom sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(train.iloc[:, 1:].values, train.iloc[:, 0].values, test_size = 0.2, random_state = 777)\nshuffle_index = np.random.permutation(x_train.shape[0])\nx_train, y_train = x_train[shuffle_index], y_train[shuffle_index]","5adb307a":"y_train_5 = (y_train == 5)\ny_valid_5 = (y_valid == 5)","11604d88":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state = 42)\nsgd_clf.fit(x_train, y_train_5)","f0a2fa46":"some_digits = train[train['label'] == 5].drop(columns = 'label').values\nsgd_clf.predict(some_digits)","4a24902f":"# DIY cross validation\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import clone","a871c893":"skfolds = StratifiedKFold(n_splits = 3, random_state = 42)\nfor train_index, test_index in skfolds.split(x_train, y_train_5):\n    clone_clf = clone(sgd_clf)\n    x_train_folds = x_train[train_index]\n    y_train_folds = y_train_5[train_index]\n    x_test_fold = x_train[test_index]\n    y_test_fold = y_train_5[test_index]\n    \n    clone_clf.fit(x_train_folds, y_train_folds)\n    y_pred = clone_clf.predict(x_test_fold)\n    n_correct = sum(y_pred == y_test_fold)\n    print(n_correct \/ len(y_pred))","7405e59a":"# use cross_val_score\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, x_train, y_train_5, cv = 3, scoring = 'accuracy')","36e579af":"# cross_val_predict, confusion_matrix, precision and recall\nfrom sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, x_train, y_train_5, cv = 3)","ce1e3b17":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train_5, y_train_pred)","7cf11206":"from sklearn.metrics import precision_score, recall_score, f1_score\nprint('Precision: ', precision_score(y_train_5, y_train_pred))\nprint('Recall: ', recall_score(y_train_5, y_train_pred))\nprint('F1: ', f1_score(y_train_5, y_train_pred))","3cb4e732":"recall_score(y_train_5, y_train_pred)","a1f2221b":"y_scores = sgd_clf.decision_function([some_digits[0]])\ny_scores\nthreshold = 200000\ny_some_digits_pred = (y_scores > threshold)\ny_some_digits_pred","f21c9e36":"y_scores = cross_val_predict(sgd_clf, x_train, y_train_5, cv = 3, method = 'decision_function')","adf596b1":"from sklearn.metrics import precision_recall_curve\nprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--', label = 'Precision')\n    plt.plot(thresholds, recalls[:-1], 'g-', label = 'Recall')\n    plt.xlabel('Threshold')\n    plt.legend(loc = 'center left')\n    plt.ylim([0, 1])\n\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)","e1bdb15b":"precisions","8e94af0e":"plt.plot(recalls, precisions)\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.ylim([0, 1])\nplt.xlim([0, 1])","1f1a0d76":"# roc curve\nfrom sklearn.metrics import roc_curve\nfpr, tpr, threshold = roc_curve(y_train_5, y_scores)\n\ndef plot_roc_curve(fpr, tpr, label = None):\n    plt.plot(fpr, tpr, linewidth = 2, label = label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n\nplot_roc_curve(fpr, tpr)","b65f09c6":"# AUC\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_train_5, y_scores)","63686696":"# compare RF to SDG\nfrom sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(random_state = 42)\ny_probas_forest = cross_val_predict(forest_clf, x_train, y_train_5, cv = 3, method = 'predict_proba')","ff275d29":"y_scores_forest = y_probas_forest[:, 1]\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)","dfe35f3c":"plt.plot(fpr, tpr, 'b:', label = 'SGD')\nplot_roc_curve(fpr_forest, tpr_forest, 'Random Forest')\nplt.legend(loc = 'lower right')","0f39ceff":"y_label_forest = cross_val_predict(forest_clf, x_train, y_train_5, cv = 3)\nprint('AUC: ', roc_auc_score(y_train_5, y_scores_forest))\nprint('Precision: ', precision_score(y_train_5, y_label_forest))\nprint('Recall: ', recall_score(y_train_5, y_label_forest))","612bde22":"# use binary classifier for multiclass classification - sklearn automatically detects this\nsgd_clf.fit(x_train, y_train)\nsgd_clf.predict([some_digits[0]])","36a35a73":"sgd_clf.decision_function([some_digits[0]])","954765a6":"sgd_clf.classes_","f2fd8420":"# force SGD to use OvO strategy\nfrom sklearn.multiclass import OneVsOneClassifier\novo_clf = OneVsOneClassifier(SGDClassifier(random_state = 42))\novo_clf.fit(x_train, y_train)\novo_clf.predict([some_digits[0]])","ef3e2356":"len(ovo_clf.estimators_)","85a8ca61":"# random forest\nforest_clf.fit(x_train, y_train)\nforest_clf.predict([some_digits[0]])","53cf9363":"forest_clf.predict_proba([some_digits[0]])","7e6475a2":"# evaluate the classifiers\ncross_val_score(sgd_clf, x_train, y_train, cv = 3, scoring = 'accuracy')","be9f61e0":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train.astype(np.float64))\ncross_val_score(sgd_clf, x_train_scaled, y_train, cv = 3, scoring = 'accuracy')","bf1135d5":"# error analysis\ny_train_pred = cross_val_predict(sgd_clf, x_train_scaled, y_train, cv = 3)","59d4f75b":"conf_mx = confusion_matrix(y_train, y_train_pred)\nconf_mx","ba74ffea":"plt.matshow(conf_mx, cmap = plt.cm.gray)","0d33d2b0":"row_sums = conf_mx.sum(axis = 1, keepdims = True)\nnorm_conf_mx = conf_mx \/ row_sums","d440f0e9":"np.fill_diagonal(norm_conf_mx, 0)\nplt.matshow(norm_conf_mx, cmap = plt.cm.gray)","b5b2cfc1":"from sklearn.neighbors import KNeighborsClassifier\n\ny_train_large = (y_train >= 7)\ny_train_odd = (y_train % 2 == 1)\ny_multilabel = np.c_[y_train_large, y_train_odd]\n\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(x_train, y_multilabel)","2683741c":"knn_clf.predict([some_digits[0]])","0c03a62c":"y_train_knn_pred = cross_val_predict(knn_clf, x_train, y_multilabel, cv = 3)\nf1_score(y_multilabel, y_train_knn_pred, average = 'macro')","4e5e4681":"f1_score(y_multilabel, y_train_knn_pred, average = 'weighted')","95b75a19":"noise = np.random.randint(0, 100, (len(x_train), 784))\nx_train_mod = x_train + noise\nnoise = np.random.randint(0, 100, (len(x_valid), 784))\nx_valid_mod = x_valid + noise\ny_train_mod = x_train\ny_valid_mod = x_valid","1fd624c7":"x_train_mod[0].shape","083752f7":"plt.imshow(x_train_mod[0].reshape(28, 28), cmap = mpl.cm.binary, interpolation = 'nearest')\nplt.axis('off')","cc52640b":"plt.imshow(x_train[0].reshape(28, 28), cmap = mpl.cm.binary, interpolation = 'nearest')\nplt.axis('off')","0cf798ea":"plt.imshow(x_valid[0].reshape(28, 28), cmap = mpl.cm.binary, interpolation = 'nearest')\nplt.axis('off')","89b60f44":"knn_clf.fit(x_train_mod, y_train_mod)\nclean_digit = knn_clf.predict([x_valid_mod[0]])\nplt.imshow(clean_digit.reshape(28, 28), cmap = mpl.cm.binary, interpolation = 'nearest')\nplt.axis('off')","f7d79c07":"xTrain = train.iloc[:, 1:]\nyTrain = train.iloc[:, 0]","5b9ccb04":"xTrainScaled = scaler.fit_transform(xTrain)","23618f02":"xTestScaled = scaler.transform(test)","c8ec78b7":"knn = KNeighborsClassifier(weights = 'distance', n_neighbors = 4)\nknn.fit(xTrainScaled, yTrain)","ad459be4":"testPred = knn.predict(xTestScaled)","efd1330c":"result = pd.concat([pd.DataFrame(np.arange(0, len(test)) + 1), pd.DataFrame(testPred)], axis = 1)\nresult.columns = ['ImageId', 'Label']\nresult.to_csv('digit_recognizer_20200705.csv', index = False)","03b75ca9":"result","e39b6a29":"Based on what's covered in this chapter, I just want to create a really simple submission and serve as a benchmark for improvements in later submissions.","b42034c4":"## Multilabel classification","b336630e":"## Multioutput classification","275c0eef":"## Multiclass classification","25f81927":"## Binary classification on digit 5","64a68286":"## Explore data","b000194b":"This is a learning notebook. Just want to type along when reading Chapter 3 of the book Hands-On Machine Learning cited below.\n<br>\nCredit of codes below: Aurlien Gron. 2017. Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (1st. ed.). O\u2019Reilly Media, Inc."}}