{"cell_type":{"6d8f64ec":"code","330caa15":"code","18942d1c":"code","111bf8f7":"code","caa6b9b6":"code","2f03b52a":"code","f1c2408b":"code","f41d5c81":"code","70dae4f3":"code","fdbb79c3":"code","11a70da5":"code","379573ba":"code","8f8b4215":"code","8e6c2c67":"code","dedbec1f":"code","6d9077dd":"code","4726c150":"code","e197be47":"code","c40720b1":"code","7befe0e6":"code","9b50cc18":"code","a766779e":"code","96d9da53":"code","2b73106d":"code","9ec5e54b":"code","1f467638":"code","bc5a5014":"markdown","07300de9":"markdown","3936f83d":"markdown","4c41fad9":"markdown","839acfae":"markdown","9b6a17c9":"markdown","934255c0":"markdown","6839517c":"markdown","e3971d8a":"markdown","6f4f3be2":"markdown","7f085233":"markdown","b99bfade":"markdown"},"source":{"6d8f64ec":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","330caa15":"df = pd.read_csv('..\/input\/pizza-price-prediction\/pizza_v2.csv')","18942d1c":"df.head()","111bf8f7":"# understanding number of uniques\n{col: df[col].nunique() for col in df.columns}\n\n'''One-hot encoding generally does not perform well\nif the categorical variable takes on a large number\nof values (i.e., you generally won't use it for variables\ntaking more than 15 different values)'''","caa6b9b6":"# extracting just numbers of price\ndf['price'] = df.price_rupiah.str.extract('(\\d+\\,\\d+)')[0].str.replace(',','').astype('int64')","2f03b52a":"# extracting just numbers of diameter\ndf['diameter_inch'] = df.diameter.str.extract('(\\d+)')[0].astype('int64')","f1c2408b":"df.head()","f41d5c81":"# Verifying number of null values\ndf.isna().sum()","70dae4f3":"# understanding data, verifying outliers and distribution.\n\nx1 = df.price.index\ny1 = df.price.values\n\nx2 = df.diameter_inch.index\ny2 = df.diameter_inch.values\n\nfig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\nax1.boxplot(y1, patch_artist= True, boxprops={\"facecolor\": \"red\"})\nax1.set_xlabel('price')\nax2.boxplot(y2, patch_artist=True)\nax2.set_xlabel('diameter')\nfig.show()","fdbb79c3":"top_price = df.groupby('topping')['price'].mean().sort_values()\n\nfig, ax = plt.subplots(figsize= (10,5))\nax.bar(x = top_price.index, height = top_price.values)\nplt.xticks(rotation = 90)\nax.set_title('Mean price of toppings', fontdict = {'fontsize':20})\nfig.show()","11a70da5":"comp_price = df.groupby('company')['price'].mean().sort_values()\n\nfig, ax = plt.subplots(figsize=(10,5))\nax.bar(x = comp_price.index, height = comp_price.values, color = ['r','g','b','y','C4'])\nax.set_title('Mean pizza price per company', fontdict={'fontsize':20})\nplt.xticks(rotation = 90)\nfig.show()","379573ba":"extras = pd.get_dummies(df[['extra_sauce','extra_cheese','extra_mushrooms']]).sum().sort_values()\n\nfig, ax = plt.subplots(figsize=(10,5))\nax.bar(x = extras.index, height = extras.values, color = ['C' + str(c) for c in range(1,6)])\nplt.xticks(rotation = 90)\nax.set_title('The most required extra', fontdict = {'fontsize':20})\nfig.show()","8f8b4215":"size_sales = df.groupby('diameter_inch').price.count()\n\nfig, ax = plt.subplots(figsize=(10,8))\nax.pie(x = size_sales.values, labels= [str(s)+' inch'for s in size_sales.index])\nax.set_title('Best seller sizes', fontdict={'fontsize':20})\nfig.show()","8e6c2c67":"# Encoding some categorical features\nfrom sklearn.preprocessing import OrdinalEncoder\n\noe = OrdinalEncoder()\noe.fit(df[['extra_sauce']])\ndf.extra_sauce = oe.transform(df[['extra_sauce']])\n\noe.fit(df[['extra_cheese']])\ndf.extra_cheese = oe.transform(df[['extra_cheese']])\n\noe.fit(df[['extra_mushrooms']])\ndf.extra_mushrooms = oe.transform(df[['extra_mushrooms']])","dedbec1f":"# Encoding company column\nfrom sklearn.preprocessing import OneHotEncoder\n\noh = OneHotEncoder(sparse=False)\n\noh.fit(df[['company']])\ncats_transformed = oh.transform(df[['company']])\n\ncats = pd.DataFrame(cats_transformed, columns = ['company_A','company_B','campany_C','company_D','company_E'])","6d9077dd":"# This is the result of company column transformation\ncats.head()","4726c150":"# One hot encoding topping column\noh.fit(df[['topping']])\ntopping_transformed = oh.transform(df[['topping']])\n\n# Getting columns names\ncolumns = oh.get_feature_names()\n\n# Creating a data frame of toppings\ntops = pd.DataFrame(topping_transformed, columns = columns)\n\ntops.head()","e197be47":"# Joining company columns and toppings columns transformed to the first data frame.\ndf = df.join(cats,how = 'left')\ndf = df.join(tops,how = 'left')\n\ndf","c40720b1":"# Excluding columns won't be used and categorical with more than 15 categories.\n# Because we have 6 sizes and 8 diameter values, size column was excluded.\n\ndf.drop(['company','price_rupiah','diameter','variant','topping','size'], axis = 1, inplace = True)\n\ndf","7befe0e6":"# Scaling price and diameter columns between 0 and 1 as the other columns\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range= (0,1))\nscaler.fit(df[['price']])\nprice = scaler.transform(df[['price']])\n\nscaler.fit(df[['diameter_inch']])\ndiameter = scaler.transform(df[['diameter_inch']])\n\ndf.price = price\ndf.diameter_inch = diameter\n\ndf","9b50cc18":"# Separating features and target\n\ny = df.price\nx = df.drop('price', axis = 1)","a766779e":"#Spliting train dataset and test dataset\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","96d9da53":"# Defining model\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(random_state = 0)\nrf.fit(x_train, y_train)","2b73106d":"# Making predictions\n\npreds = rf.predict(x_test)","9ec5e54b":"# Evaluating model with metrics\n\nfrom sklearn.metrics import mean_absolute_error, r2_score\nprint(f'model MAE: {mean_absolute_error(y_test, preds):.2f}\\nmodel R2: {r2_score(y_test, preds):.2f}')","1f467638":"#Creating a dict with feature importances. the higher, the more important the feature.\n\nimp_dict = {feature:round(score,3) for feature, score in zip(x.columns, rf.feature_importances_)}\ndf_imp = pd.DataFrame(imp_dict.values(), index = imp_dict.keys())\n\n# Plotting feature importances\n\nfig, ax = plt.subplots(figsize = (10,5))\nax.bar(x = df_imp.index, height = df_imp[0])\nax.set_title('Feature importances', fontdict = {'fontsize':20})\nplt.xticks(rotation = 90)\nfig.show()","bc5a5014":"## Exploratory data analysis","07300de9":"## Importing libraries","3936f83d":"## Understanding feature importance","4c41fad9":"## Which is the most expensive topping?","839acfae":"## Model MAE: 0.05\n## Model R2: 0.77","9b6a17c9":"# Pizza price project\n\n**In this project I worked to make a prediction for pizza prices and understand which feature is more significant to increase or decrease prices**","934255c0":"## Which company has the higher price","6839517c":"## Which is the best seller size?","e3971d8a":"## Preprocessing data","6f4f3be2":"## Making predictions","7f085233":"## Which extra is more required?","b99bfade":"## Loading data"}}