{"cell_type":{"d1711550":"code","28d69ddb":"code","faf0473a":"code","1a8f1634":"code","e042de3e":"code","d2db8194":"code","ca4a2710":"code","80153fb2":"code","0b90641e":"code","75d2553d":"markdown","a1a81c30":"markdown","0cf95aeb":"markdown","f5adb88d":"markdown","55bb1481":"markdown","8d46dca1":"markdown","3bb2cfff":"markdown","62485e46":"markdown","f6a4997f":"markdown","64fdbc1b":"markdown","ffa380db":"markdown","d70344be":"markdown","a6c78103":"markdown"},"source":{"d1711550":"from math import log\nfrom random import random\nfrom sklearn.metrics import log_loss\nimport scipy.stats as st\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#Begin by importing these modules, which help with the analysis","28d69ddb":"Labels = []\nProbs = []\namount = 10000\n\nfor i in range(amount):\n  p = random()\n  y = round(random())\n  Labels.append(y)\n  Probs.append([1-p,p])\n\nprint(log_loss(Labels,Probs))","faf0473a":"Labels = []\nProbs = []\namount = 10000\n\nfor i in range(amount):\n  p1 = random()\n  p2 = random()\n  Labels.append(p1 > p2)\n  Probs.append([1-p1,p1])\n\nprint(log_loss(Labels,Probs))","1a8f1634":"#Define our custom distribution\nclass my_pdf(st.rv_continuous):\n    def _pdf(self,x):\n      return alpha*((x-beta)**2)\n    def _cdf(self,x):\n      return (alpha\/3)*((x-beta)**3 + (beta-0)**3)\n    def _ppf(self,x):\n      q =  (3*x \/ alpha) - ((beta)**3)\n      return np.sign(q)*(np.abs(q)**(1\/3)) + beta\n\nbeta = 1\/2\nalpha = 12\nuQuad = my_pdf(a=0, b=1, name='U-Quad')\n\nsamples = uQuad.rvs(size=100000)\nplt.hist(samples,bins=100);","e042de3e":"amount = 10000\nLabels = []\nProbs = []\n\nfor i in range(amount):  \n  p1 = uQuad.rvs()\n  p2 = random()\n  Labels.append(int(p1 > p2))\n  Probs.append([1-p1,p1])\n\nprint(log_loss(Labels,Probs))","d2db8194":"p = 0.99 #our confidence in our answers. Try changing it around.\namount = 1000\nLabels = [random() > 0.5 for _ in range(amount)]\nProbs = list(map({True : [1-p,p], False: [p,1-p]}.get, Labels))\n\nmaxErrors = amount\nLogLosses = [0]*maxErrors\nfor i in range(maxErrors):\n    LogLosses[i] = log_loss(Labels,Probs)\n    #On the next itteration, we'll have 1 new mistake:\n    Labels[i] = not Labels[i] \n\nplt.plot(LogLosses)\nplt.title('Error Graph')\nplt.xlabel('# Mistakes')\nplt.ylabel('LogLoss Error')\n\nprintErrorAt = [0,1,2,10,20,50,100,250,999]\n\nfor i in printErrorAt:\n    print('Error with {} mistakes: {}'.format(i,LogLosses[i]))","ca4a2710":"ExpectedHumanError = 1\/100 #how often do we believe an unforseeable error will occur?\nepsilon = 0.00001 #if the above variable is made too small, you may need to decrease epsilon\nerrors = np.array([-log(p)*(1-ExpectedHumanError) - log(1-p)*(ExpectedHumanError) \\\n          for p in np.arange(epsilon,1-epsilon,epsilon)])\n\nminima = np.argmin(errors)*epsilon\n#plot the region near the global minima\nmask = (np.arange(epsilon,1-epsilon,epsilon) >= minima - 5*(1-minima)) \\\n     & (np.arange(epsilon,1-epsilon,epsilon) <= minima + 5*(1-minima))\nplt.plot(np.arange(epsilon,1-epsilon,epsilon)[mask],errors[mask])\n\nprint('Best error: {}\\nat p = {}'.format(min(errors),minima))","80153fb2":"epsilon = 0.00001\nrnge = np.arange(epsilon,1-epsilon,epsilon)\nplt.plot(rnge,[-log(1-h)*(1-h)-log(h)*h for h in rnge])\nplt.title('Hypothetical Optimal Score')\nplt.xlabel('Expected Mislabels')\nplt.ylabel('LogLoss Error');","0b90641e":"h = 1\/10000\nprint(-log(1-h)*(1-h)-log(h)*h)","75d2553d":"But in our problem, we deal with far less randomness, where clear cases exist for both pass and fail, and a small to moderate amount of cases fall in a mid probability region. What if we change the probability distribution we sample from to be bimodal with peaks at 0 and 1? Consider a [U-quadratic distribution](https:\/\/en.wikipedia.org\/wiki\/U-quadratic_distribution) in (0,1). Run the following two blocks to see how the error reduces as the shape of our pdf is more u shaped.\n","a1a81c30":"What if we were incredibly certain in all of our choices (e.g. we pick p = 0.99, and 0.01 only) over a large amount of trials. What does our score look like if we make M mistakes?","0cf95aeb":"Solving for an exact analytic solution here is left as an excercise to the reader (the author was too lazy to compute it.)","f5adb88d":"It is simple enough to get closed form solution for both the optimal $p$ value, and optimal error given how often we expect there to be a mislabeling in test data (denote this by $h$).\n\n$$\\min\\quad -log(p)\\cdot(1-h) - log(1-p)\\cdot h$$\nWe evaluate the derivative at 0.\n$$-\\frac{1-h}{p} + \\frac{h}{1-p} = 0 \\implies p = 1-h$$\n\nTherefore our expected optimal score is $-log(1-h)\\cdot(1-h) - log(h)\\cdot h$.\n\nLets plot this out now.","55bb1481":"The very first question I had when starting this competition was what a reasonable lower bound for log loss should be. It's unclear whether 0.1, 0.01, 0.001, etc are reasonable floors for how well the given data can predict the likelihood of passing, so I figured the best way to gain insight would be to actually analyze the behavior of the scoring function. And what better way to do that than to put it together into a small kernel.","8d46dca1":"What if we however had perfect knowledge of the probability that we pass? That is to say, we select $p_1$, $p_2$ from $\\text{Uniform}(0,1)$, our truth label becomes $p_1 > p_2$, and then we use $p_1$ as our guess. In such a system, with only knowledge of $p_1$, it is always the optimal guess! Try the code below to see how well we can do optimally.","3bb2cfff":"Begin by considering random labels, and random probabilities assigned to them. Try running the following code block to see what it converges too.","62485e46":"Clearly here error grows linerally with the number of mistakes. With absolutely no mistakes, our performance is bounded bellow by $log(p_1)$. But even mislabeling 2% of cases is enough to lose an entire magnitude of accuracy (0.01 to 0.1), and mislabeling 25% of cases does worse than even randomly guessing would!\n\nThis observation has led to the conclussion that we can do no better than the expected likelihood of human errors, and variances between the training data and test data. For instance, if we believe that there is a 1\/1000 chance that a human mislabeling error occurs, then any prediction we make needs to assume that it will be penalised at least once in 1000 trials. We can optimize this!","f6a4997f":"What do you think is the best reasonably attainable score?","64fdbc1b":"None of this analysis has actually touched the data, and it doesn't really give a numeric value for a hypothetical floor. Still i'd wager that the mislabeling rate is no better than 1\/10,000, which by the above calculation yields ~0.001 as a lower bound on how well we can perform.","ffa380db":"It's easy to see why the hypothetical score decreases near 0, but why does it decrease as we get closer to 1 as well? The reason for this is that we assumed that we have perfect knowledge of the labels, and we have aprori knowledge of the mislabeling rate. So at high mislabeling rates, our guesses would all just be flipped. At 0.5 mislabeling rate (the highest\/worst possible score), everything is random, and the score is just -log(0.5).","d70344be":"The result should come out to about 1, but why? We can show that it actually does tend to 1 (in the long run), by evaluating the expected value of log loss: \\\\(-(y \\log(p) + (1-y)\\log(1-p))\\\\), with our chosen parameters:\n\n$$E\\Big{[}\\text{LogLoss}\\quad \\Big{|} \\quad p \\in \\text{Uniform}(0,1), \\quad y \\in \\operatorname{Bern} \\left({\\frac{1}{2}}\\right)\\Big{]} $$\n$$ = -\\int_{0}^{1} \\frac{\\log(p)}{2}  \\mathrm{dp} -\\int_{0}^{1} \\frac{\\log(1-p)}{2} \\mathrm{dp}  = -\\int_{0}^{1} \\log(p) \\mathrm{dp} = 1 $$","a6c78103":"So it turns out that here, we tend to 0.5! Proof:\n\n$$E\\Big{[}\\text{LogLoss}\\quad \\Big{|} \\quad p_1, p_2 \\in \\text{Uniform}(0,1), \\quad y = (p_1 > p_2) \\Big{]} $$\n\n$$ = \\int_0^1 \\int_0^{p_1} \\log(p_1) \\mathrm{dp_2} + \\int_{p_1}^1 \\log(1-p_1) \\mathrm{dp_2} \\mathrm{dp_1} = \\frac{1}{2}$$\n\n(Excercise: What if instead of being given $p_1$, we were given $p_2$? Could we achieve the same, or even better performance?)\n\n\n"}}