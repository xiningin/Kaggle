{"cell_type":{"06c99283":"code","192250a6":"code","46fe5c02":"code","a3c00aa8":"code","b2efad29":"code","1df007f0":"code","f8e6ae4a":"code","b006a48e":"code","19c7cbd8":"code","05e4e67a":"code","5eb5cdd7":"code","63f556a3":"code","502e8245":"code","89ad9825":"code","1ae5ff00":"code","ae80d72e":"code","6c00b472":"code","82b46b65":"code","b4ef5f38":"code","5f1e2a6e":"code","4dbbe127":"code","4fb0beee":"code","5f96c6ba":"code","a8060f07":"code","8579e64f":"code","b44ebacb":"code","c08a8abe":"code","642a671b":"code","41aff872":"code","fbb37881":"code","ea79aa2d":"code","d9b885dc":"code","376b8e76":"code","505c5816":"markdown","dee76375":"markdown","ce8e5a3e":"markdown","2b9a4c00":"markdown","68345672":"markdown","770f2c6e":"markdown","d6e40612":"markdown","a78d5ebc":"markdown","0d5f6802":"markdown","f7ba0390":"markdown","51da0d2b":"markdown","28859344":"markdown","7eb080eb":"markdown","4b53c82a":"markdown","02f57f14":"markdown","031cd59c":"markdown","393f3840":"markdown","a2795328":"markdown","ed595de1":"markdown","b8bdde5a":"markdown","7481dced":"markdown","2c73f386":"markdown","d4694599":"markdown","ce958272":"markdown","35338c25":"markdown","3279bd40":"markdown","95728d8c":"markdown","01426fc4":"markdown","b3ae75b0":"markdown","4eb8d095":"markdown"},"source":{"06c99283":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n!pip install chart_studio\n!pip install textstat\n\nimport numpy as np \nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport chart_studio.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom plotly.offline import iplot\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\nimport seaborn as sns\n%matplotlib inline\n\n# Word Cloud\nfrom wordcloud import WordCloud\n\n# sklearn \nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Pandas Profiling\nfrom pandas_profiling import ProfileReport\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')","192250a6":"df = pd.read_csv(\"..\/input\/scl-2021-ds\/train.csv\")\nvalidation = pd.read_csv(\"..\/input\/scl-2021-ds\/test.csv\")","46fe5c02":"df.head()","a3c00aa8":"validation.head()","b2efad29":"df[['POI', 'street']] = df['POI\/street'].str.split('\/', 1, expand=True)\ndf['POI\/street'].replace('\/', np.nan, inplace=True)\ndf['POI'].replace('', np.nan, inplace=True)\ndf['street'].replace('', np.nan, inplace=True)\ndf.head()","1df007f0":"def missing_value_of_data(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percentage = round(total\/data.shape[0]*100,2)\n    return pd.concat([total,percentage], axis=1, keys=['Total','Percentage'])","f8e6ae4a":"missing_value_of_data(df)","b006a48e":"def duplicated_values_data(data):\n    dup=[]\n    columns=data.columns\n    for i in data.columns:\n        dup.append(sum(data[i].duplicated()))\n    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])","19c7cbd8":"df_cleaned = df.dropna()\nduplicated_values_data(df_cleaned)","05e4e67a":"ProfileReport(df, title='Pandas Profiling Report', explorative=True)","5eb5cdd7":"qmarks = np.mean(df['raw_address'].apply(lambda x: '?' in x))\nfullstop = np.mean(df['raw_address'].apply(lambda x: '.' in x))\ncomma = np.mean(df['raw_address'].apply(lambda x: ',' in x))\ncapital_first = np.mean(df['raw_address'].apply(lambda x: x[0].isupper()))\ncapitals = np.mean(df['raw_address'].apply(lambda x: max([y.isupper() for y in x])))\nnumbers = np.mean(df['raw_address'].apply(lambda x: max([y.isdigit() for y in x])))\n\nprint('Address with question marks: {:.2f}%'.format(qmarks * 100))\nprint('Address with full stops: {:.2f}%'.format(fullstop * 100))\nprint('Address with comma: {:.2f}%'.format(comma * 100))\nprint('Address with capital letters: {:.2f}%'.format(capitals * 100))\nprint('Address with numbers: {:.2f}%'.format(numbers * 100))","63f556a3":"lens = df.raw_address.str.split().apply(lambda x: len(x))\nprint(lens.describe())","502e8245":"df['text_len'] = df['raw_address'].astype(str).apply(len)\ndf['text_word_count'] = df['raw_address'].apply(lambda x: len(str(x).split()))\ndf.head()","89ad9825":"df['text_len'].iplot(\n    kind='hist',\n    bins=100,\n    xTitle='text length',\n    linecolor='black',\n    color='red',\n    yTitle='count',\n    title='Text Length Distribution')","1ae5ff00":"df['text_word_count'].iplot(\n    kind='hist',\n    bins=50,\n    xTitle='text length',\n    linecolor='black',\n    color='red',\n    yTitle='count',\n    title='Text word count')","ae80d72e":"pal = sns.color_palette()\ntrain = df['raw_address'].apply(len)\nvalid = validation['raw_address'].apply(len)\n\nplt.figure(figsize=(15, 10))\nplt.hist(train, bins=180, range=[0, 180], color=pal[2], label='train')\nplt.hist(valid, bins=180, range=[0, 180], color=pal[1], alpha=0.5, label='test')\nplt.title('Character Count', fontsize=15)\nplt.legend()\nplt.xlabel('Number of characters', fontsize=15)\nplt.ylabel('Probability', fontsize=15);","6c00b472":"train = df['raw_address'].apply(lambda x: len(x.split(' ')))\nvalid = validation['raw_address'].apply(lambda x: len(x.split(' ')))\n\nplt.figure(figsize=(15, 10))\nplt.hist(train, bins=40, range=[0, 40], color=pal[2], label='train')\nplt.hist(valid, bins=40, range=[0, 40], color=pal[1], alpha=0.5, label='valid')\nplt.title('Word Count', fontsize=15)\nplt.legend()\nplt.xlabel('Number of words', fontsize=15)\nplt.ylabel('Probability', fontsize=15);","82b46b65":"def get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","b4ef5f38":"unigrams = get_top_n_words(df['raw_address'], 20)\ndf1 = pd.DataFrame(unigrams, columns = ['Text', 'count'])\n\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Unigrams (Raw Address)',orientation='h')","5f1e2a6e":"df_cleaned = df.dropna()\nunigrams = get_top_n_words(df_cleaned['POI'], 20)\ndf2 = pd.DataFrame(unigrams, columns = ['Text', 'count'])\n\ndf2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Unigrams (POI)',orientation='h')","4dbbe127":"unigrams = get_top_n_words(df_cleaned['street'], 20)\ndf2 = pd.DataFrame(unigrams, columns = ['Text', 'count'])\n\ndf2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Unigrams (street)',orientation='h')","4fb0beee":"def get_top_n_gram(corpus,ngram_range,n=None):\n    vec = CountVectorizer(ngram_range=ngram_range).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","5f96c6ba":"bigrams = get_top_n_gram(df['raw_address'],(2,2),20)\ndf1 = pd.DataFrame(bigrams, columns = ['Text', 'count'])\n\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Bigrams (raw_street)',orientation='h')","a8060f07":"bigrams = get_top_n_gram(df_cleaned['POI'],(2,2),20)\ndf2 = pd.DataFrame(bigrams, columns = ['Text', 'count'])\n\ndf2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Bigrams (POI)',orientation='h')","8579e64f":"bigrams = get_top_n_gram(df_cleaned['street'],(2,2),20)\ndf3 = pd.DataFrame(bigrams, columns = ['Text', 'count'])\n\ndf3.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Bigrams (street)',orientation='h')","b44ebacb":"trigrams = get_top_n_gram(df['raw_address'],(3,3),20)\ndf1 = pd.DataFrame(trigrams, columns = ['Text' , 'count'])\n\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Trigrams (raw_address)',orientation='h')","c08a8abe":"trigrams = get_top_n_gram(df_cleaned['POI'],(3,3),20)\ndf2 = pd.DataFrame(trigrams, columns = ['Text' , 'count'])\ndf2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Trigrams (POI)',orientation='h')","642a671b":"trigrams = get_top_n_gram(df_cleaned['street'],(3,3),20)\ndf3 = pd.DataFrame(trigrams, columns = ['Text' , 'count'])\n\ndf3.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', xTitle='Count', linecolor='black',color='red', title='Top 20 Trigrams (street)',orientation='h')","41aff872":"def get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","fbb37881":"top_words = get_top_n_words(df['raw_address'])\nx = [x[0] for x in top_words[:30]]\ny = [x[1] for x in top_words[:30]]","ea79aa2d":"fig = go.Figure([go.Bar(x=x, y=y, text=y)])\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide', title_text='Most Common Words')","d9b885dc":"def plot_cloud(wordcloud):\n    plt.figure(figsize=(10, 8)) # Set figure size\n    plt.imshow(wordcloud) # Display image\n    plt.axis(\"off\"); # No axis details","376b8e76":"raw_address_cloud = WordCloud(width = 3000, height = 2000, random_state=42, background_color='black', \n                    colormap='Wistia', collocations=False).generate(\" \".join(df['raw_address']))\n\nplot_cloud(raw_address_cloud)","505c5816":"Results of this calculation establish that text length is short (average length of 7 words).","dee76375":"[Table of Contents](#top)\n<a id=\"9\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>9. Word Cloud<center><h2>","ce8e5a3e":"[Table of Contents](#top)\n<a id=\"5\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>5. Top Unigram Distribution<center><h2>","2b9a4c00":"<a id=\"0\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>IMPORTANT: Indonesian Addresses<center><h2>","68345672":"[Table of Contents](#top)\n<a id=\"4\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>4. Text Length Analysis<center><h2>","770f2c6e":"<a id=\"1\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>1. Data Preparation<center><h2>","d6e40612":"[Table of Contents](#top)\n<a id=\"3\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>3. Semantic Analysis<center><h2>","a78d5ebc":"## Text Word Count","0d5f6802":"## Comparing Training and Validation Data","f7ba0390":"[Table of Contents](#top)\n<a id=\"7\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>7. Top Trigram Distribution<center><h2>","51da0d2b":"[Table of Contents](#top)\n<a id=\"8\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>8. Most Common Words<center><h2>","28859344":"## Missing Values\nWe will replace all '\/' or empty string with NaN and then we will count all of the missing values in the training set. At the end, if you want, you can remove all the rows with missing values in both POI and street columns.","7eb080eb":"## Extract POI and Street","4b53c82a":"## Components\nIn order to get useful insights from the visualization below, I recommend you to understand the components in an Indonesian address.\n   \nFrom the highest to the lowest:\n* **Provinsi** \u2014 Province\n* **Kota** or **Kabupaten** \u2014 Regency\n* **Kecamatan** \u2014 District\n* **Kelurahan** or **Desa** \u2014 Village\n* **RW**, an abbrev. of Rukun Warga (Neighborhood Unit)\n* **RT**, an abbrev. of Rukun Tetangga (Community Unit)\n\nThe last two are subdivisions of a Village, and normally use numbers.","02f57f14":"# EDA + Visualizations \ud83c\udfa8\nQuick Exploratory Data Analysis for [Shopee Code League - Address Elements Extraction](https:\/\/www.kaggle.com\/c\/scl-2021-ds).\n\n![](https:\/\/mir-s3-cdn-cf.behance.net\/project_modules\/max_1200\/38648740180181.5774ef3930adc.jpg)","031cd59c":"## Text Length Distribution","393f3840":"## Import Libraries","a2795328":"## Example 1 \nJl.janaka Rt 1 Rw 1 krajan Wringinanom Sambit Kabupaten Ponorogo Jawa Timur\n* Jl Janaka \u2014 street name\n* RT 1, RW 1 \u2014 as explained above\n* Krajan \u2014 Village\n* Wringinanom \u2014 District\n* Kabupaten Ponorogo \u2014 Regency\n* Jawa Timur \u2014 Province","ed595de1":"## Common abbreviation\n* gg\/gg.\/gang referes to an alley.\n* jl\/jln\/jalan\/jl.\/jln. refers to Jalan (Street)\n* no.\/nomor\/no refers to number\n* kec.\/kecamatan\/kec refers to Kecamatan\n* kel.\/kelurahan\/kel refers to Kelurahan\n* kab.\/kabupaten\/kab refers to Kabupaten","b8bdde5a":"If there are any suggestions\/changes you would like to see in this notebook, please let me know. Appreciate every ounce of help!\n\n* https:\/\/www.kaggle.com\/parulpandey\/eda-and-preprocessing-for-bert\n* https:\/\/www.kaggle.com\/thiagopanini\/e-commerce-sentiment-analysis-eda-viz-nlp\n* https:\/\/www.kaggle.com\/anokas\/data-analysis-xgboost-starter-0-35460-lb\n* https:\/\/www.quora.com\/How-do-you-enter-Indonesian-shipping-addresses-for-USPS-when-they-are-too-long\n* https:\/\/www.kaggle.com\/raenish\/cheatsheet-text-helper-functions\n* https:\/\/towardsdatascience.com\/simple-wordcloud-in-python-2ae54a9f58e5","7481dced":"We will take a look at the different punctuation in addresses.","2c73f386":"<a id=\"2\"><\/a>\n[Table of Contents](#top)\n<h2 style='background:#FFA500; border:0; color:white'><center>2. Basic Data Exploration<center><h2>","d4694599":"We calculate the number of words in each address and look at the length distribution.","ce958272":"## Duplicate Values","35338c25":"## Dataset Preparation","3279bd40":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:#FFA500; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [IMPORTANT: Indonesian Addresses](#0)\n* [1. Data Preparation](#1)\n* [2. Basic Data Exploration](#2)\n* [3. Semantic Analysis](#3)\n* [4. Text Length Analysis](#4)\n* [5. Top Unigram Distribution](#5)\n* [6. Top Brigram Distribution](#6)\n* [7. Top Triagram Distribution](#7)\n* [8. Most Common Words](#8)\n* [9. Word Cloud](#9)\n* [References](#10)","95728d8c":"## Glimpse of Data","01426fc4":"## Example 2\nJalan Candi Panggung Barat. No 16 . RT 01 RW 18. Kelurahan Mojolangu, Kecamatan Lowokwaru Malang City , East Java\n* Jalan Candi Panggung Barat. No 16 \u2014 street name and number\n* RT 01, RW 18 \u2014 as explained above\n* Kelurahan Mojolangu \u2014 Village\n* Kecamatan Lowokwaru \u2014 District\n* Malang City \u2014 Regency\n* East Java (Jawa Timur) \u2014 Province","b3ae75b0":"[Table of Contents](#top)\n<a id=\"6\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>6. Top Bigram Distribution<center><h2>","4eb8d095":"[Table of Contents](#top)\n<a id=\"10\"><\/a>\n<h2 style='background:#FFA500; border:0; color:white'><center>References<center><h2>"}}