{"cell_type":{"fb3bc329":"code","d9cc619f":"code","7c3b661a":"code","bd0e925e":"code","19d09583":"code","1e7b4d81":"code","c3677636":"code","06a10d75":"code","31d24892":"code","238015cc":"code","56ecb8b9":"code","d65e7c3a":"code","49cff543":"code","44dc0ca2":"markdown","615ec875":"markdown","bd5c245f":"markdown","726af7de":"markdown","67ce6750":"markdown","34084fd0":"markdown","eae08f3c":"markdown","d54df841":"markdown","c8297afb":"markdown","8147c0f2":"markdown","6f14b99c":"markdown"},"source":{"fb3bc329":"import os, cv2, json\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import EfficientNetB6\nfrom tensorflow.keras.applications import InceptionV3\n\nfrom tensorflow.keras.applications import ResNet50\n\nfrom tensorflow.keras.optimizers import Adam\n\nfrom PIL import Image\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D","d9cc619f":"train= pd.read_csv(\"..\/input\/tomato-diseases-dataset-csvimages\/train.csv\")","7c3b661a":"from sklearn.model_selection import train_test_split\ndf_train, df_validate, y_train, y_test = train_test_split(train, train.label, \n                                                    train_size=0.8, \n                                                    random_state=42,\n                                                    stratify=train.label)","bd0e925e":"df_train = df_train.reset_index(drop=True)\ndf_validate = df_validate.reset_index(drop=True)","19d09583":"sample = df_train[df_train.label == 3].sample(3)\nplt.figure(figsize=(15, 5))\nfor ind, (img, label) in enumerate(zip(sample.img, sample.label)):\n    plt.subplot(1, 3, ind + 1)\n    img = cv2.imread(os.path.join(\"..\/input\/tomato-diseases-dataset-csvimages\/Tomato_images\/Tomato_images\", img))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","1e7b4d81":"# Main parameters\nBATCH_SIZE = 16\nSTEPS_PER_EPOCH = len(train)*0.8 \/ BATCH_SIZE\nVALIDATION_STEPS = len(train)*0.2 \/ BATCH_SIZE\nEPOCHS =60 #\nIMG_WIDTH= 256\nIMG_HEIGHT= 256\ntrain_dir = \"..\/input\/tomato-diseases-dataset-csvimages\/Tomato_images\/Tomato_images\"","c3677636":"df_train.label = df_train.label.astype('str')\ndf_validate.label = df_validate.label.astype('str')","06a10d75":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                               shear_range = 0.2,\n                               zoom_range = 0.2,\n                               rotation_range = 180,\n                               vertical_flip = True,\n                               horizontal_flip = True)\n# our train_datagen generator will use the following transformations on the images\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\n\ntrain_generator = train_datagen.flow_from_dataframe(df_train, \n                                                    train_dir,\n                                                    target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                    batch_size=BATCH_SIZE,\n                                                    x_col='img',\n                                                    y_col='label',\n                                                    class_mode = 'categorical')\n\n# generator = ImageDataGenerator(*args).flow_from_dataframe(dataframe, directory, target_size,\n# batch_size, x_col, y_col, class_mode)\n# your dataframe shoudl be in the format such that x_col = features, y_col = class\/label\n# binary class mode since output is either 0(dog) or 1(cat)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(df_validate, \n                                                   train_dir,\n                                                    target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                    x_col='img',\n                                                    y_col='label',\n                                                    class_mode='categorical', \n                                                  batch_size=BATCH_SIZE)","31d24892":"def create_model():\n    efficientnet_layers = InceptionV3(weights='imagenet', \n                                         include_top=False, \n                                         input_shape = (IMG_WIDTH, IMG_HEIGHT, 3),\n                                         pooling='avg')\n\n    model = Sequential()\n    model.add(efficientnet_layers)\n    model.add(Dense(10, activation=\"softmax\"))\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"categorical_crossentropy\",\n                  metrics = [\"acc\"])\n\n    return model\n","238015cc":"model = create_model()\nmodel.summary()","56ecb8b9":"from keras.utils import plot_model\nmodel.summary()\n# plot model architecture\nplot_model(model, show_shapes=True, to_file='naive_inception_module.png')","d65e7c3a":"model_save = ModelCheckpoint('.\/InceptionV3_256.h5', \n                             save_best_only = True, \n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 10, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = [model_save, early_stop, reduce_lr]\n)","49cff543":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, label = \"Training acc\")\nax1.plot(epochs, val_acc,  label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss,  label = \"Training loss\")\nax2.plot(epochs, val_loss, label = \"Validation loss\")\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","44dc0ca2":"# Creating Model","615ec875":"# Tomato Leaf Disease Detection 0.998 [Training]","bd5c245f":"# Training","726af7de":"# Visualizing Results","67ce6750":"# Loading Data","34084fd0":"# importing Libraries","eae08f3c":"# Parameters","d54df841":"# Splitting DataSet","c8297afb":"### Hi kagglers, This is `training` notebook using `Keras`.\n\n> \n>  [Tomato Leaf Disease Detection 0.998 [inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/tomato-leaf-disease-detection-0-998-inference)\n\n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","8147c0f2":"# Data Generator","6f14b99c":"# Visualizing Data"}}