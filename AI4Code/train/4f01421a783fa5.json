{"cell_type":{"0e848e6f":"code","6acaebd0":"code","1f010506":"code","aff81378":"code","9e555a81":"code","355ed6d9":"code","52c4b572":"code","951ac95b":"code","bf2d5e5a":"code","77439b73":"code","a626aadd":"code","025e5cde":"code","80e66632":"code","c9e3444f":"code","3564cff5":"code","859d173c":"code","9da1f026":"code","380d92e8":"code","7071765d":"code","7bcf3c81":"code","3bcabb71":"code","d9b72c55":"code","cc727959":"code","3e41ac0a":"code","0c733abd":"code","90f0ccb4":"code","24d2ba54":"code","b05ad586":"code","ff0a784d":"code","6b6bdcca":"code","08fb1638":"code","9a409a82":"code","59f9eff4":"code","5dd66aff":"code","b89c49f8":"code","00060513":"code","72729c1a":"code","a752ab25":"code","ebd1eca5":"code","33fdaa83":"code","ea3a55cd":"code","33e6dc7e":"code","59f9f5a6":"code","f26512d9":"code","fc15b220":"code","7d493a71":"code","9b4cdf2c":"code","bf260f62":"code","678b6421":"code","fd8512ce":"code","000f1b75":"code","dadd0b34":"code","43359a0a":"code","1708d70d":"code","d7a1636d":"code","7634ae50":"code","e998900a":"code","980c054a":"code","bc9253a4":"code","ed8412c4":"code","64644fc4":"code","62954326":"code","ad189b45":"code","6348a446":"code","3f96b523":"code","18bcdfc4":"code","3cb27529":"code","5f2cd727":"code","432583b0":"code","6ddeb95f":"code","b1fa5d67":"code","28eaba44":"code","efde552a":"code","fc8ff2a9":"code","f6a6afc1":"code","7895fb4c":"code","627e7190":"code","565b3ffa":"code","e390e5ce":"code","ed77bea0":"code","e3898824":"code","bb0e65f3":"code","82709c85":"code","45015bdd":"code","b1bafb2b":"code","3d3ba1ab":"code","51f10397":"code","0c15d9c8":"code","6b182c58":"code","37b1fc96":"code","35a29b92":"code","fdf018f6":"code","43abb92f":"code","cb423cb1":"code","8e9b601e":"code","2e0c2e80":"code","c224fa8e":"code","3953402d":"code","70f03aca":"code","13dcf60b":"code","b962a0a4":"code","31726617":"code","b5f9732d":"code","d1b2e514":"code","f98a129b":"code","a0eda1f5":"code","7259d387":"code","9f3fee44":"code","46391f64":"code","5873b064":"code","6c67bd94":"code","07d38662":"code","c5de7564":"code","46133959":"code","1e27e8b3":"code","a5a66525":"code","a4a10b35":"code","880eeb78":"code","abffdedf":"code","63717b70":"code","aa93b383":"code","4088454b":"code","3865592c":"code","82b0f76a":"code","8c66cf69":"code","ebf17511":"code","bb0f7b06":"code","37cf84bf":"code","c84dae69":"code","2b924166":"code","26651ce6":"code","b071b6e1":"code","13d308a3":"code","f3addb9e":"code","28587c6e":"code","fc7d9c38":"code","d65d4fae":"code","01de4be2":"code","828329aa":"code","bb1d818d":"code","b55ae4e1":"code","1f7c8b7a":"code","d680b25a":"code","5c64193e":"code","9601b681":"code","f7c54730":"code","31331ce4":"code","76e4c5b7":"code","2b9ba0d1":"code","700a7f02":"code","08b8283d":"code","5ea30223":"code","6cb9319e":"code","7111ef0f":"code","2febd3c1":"code","03a4746e":"code","e5235c16":"code","73a14850":"code","bf272f2b":"code","dfa6fffc":"code","1e2a87dd":"code","d76739e2":"code","038e91da":"markdown","aa2b3765":"markdown","63ad9b45":"markdown","136dcd07":"markdown","3970eb52":"markdown","1bf47f2a":"markdown","efd52835":"markdown","f30ec33f":"markdown","a9fb9531":"markdown","a1450868":"markdown","1d59406f":"markdown","8b23973d":"markdown","3f4c8f92":"markdown","3daca526":"markdown","6dd55262":"markdown","c864d7dd":"markdown","2615e148":"markdown","02d60750":"markdown","fed0cff1":"markdown","ca63a6f5":"markdown","c5fb6014":"markdown","a24d4137":"markdown","36d09753":"markdown","a72fc47e":"markdown","06e66958":"markdown","144a915f":"markdown","e6983bf4":"markdown","9ae67a5b":"markdown","93b47841":"markdown","76c7577e":"markdown","a7ff168f":"markdown","ae62ca26":"markdown","eb8f31af":"markdown","f2e9a41e":"markdown","a74aa0d6":"markdown","d29cf040":"markdown","8ddc08e0":"markdown","377cdaf3":"markdown","08bcceb5":"markdown","b5bed399":"markdown","d2df7f26":"markdown","f0c60984":"markdown","91e29dde":"markdown","c8e13f0c":"markdown"},"source":{"0e848e6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6acaebd0":"# Importing libraries for this project \n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PowerTransformer\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nimport time\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom imblearn import over_sampling\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score, recall_score,f1_score,classification_report\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter # counter takes values returns value_counts dictionary\nfrom sklearn.datasets import make_classification","1f010506":"df=pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","aff81378":"df.head()","9e555a81":"print(df.shape)\nprint(df.dtypes)\nprint(df[['Time','Amount','Class']].describe())\nprint(df.isnull().sum().max())","355ed6d9":"\nprint(df['Class'].value_counts())\nprint('\\n')\nprint(df['Class'].value_counts(normalize=True))\n\nsns.countplot(df['Class'])","52c4b572":"\nplt.figure(figsize=(12,8))\nplt.subplot(1,2,1)\nsns.scatterplot(data=df, x=\"Class\", y=\"Amount\")\nplt.subplot(1,2,2)\nsns.scatterplot(data=df, x=\"Class\", y=\"Time\")\nplt.show()\n","951ac95b":"plt.figure(figsize=(12,8))\n\nsns.lmplot(data=df, x=\"Amount\", y=\"Time\",hue='Class')","bf2d5e5a":"\nsns.boxplot(x='Amount',data=df)","77439b73":"\nplt.title('Pearson Correlation Matrix')\nsns.heatmap(df[['Time', 'Amount','Class']].corr(),linewidths=0.25,vmax=0.7,square=True,cmap=\"winter\",\n            linecolor='w',annot=True);","a626aadd":"# Removing unwanted column\n\ndf.drop(['Time'],axis=1,inplace=True)","025e5cde":"# Splitting the data set into train and test data\n# using stratify here so that all fraud data is equally stratified.\n\nX=df.drop(['Class'],axis=1)\ny=df['Class']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .30,stratify=y,shuffle=True,random_state=100)","80e66632":"# Plot the distribution of variables (to check the skewness)\ndf.hist(figsize = (25,25))\nplt.show()","c9e3444f":"# Let's treat skewness by using power transformer by making it gausian\n# Also scaling the Amount column\n\npt=PowerTransformer(method='yeo-johnson',standardize=True,copy=False)\nX_train = pt.fit_transform(X_train)\nX_test = pt.transform(X_test)","3564cff5":"print(np.sum(y))\nprint(np.sum(y_train))\nprint(np.sum(y_test))","859d173c":"# instantiate the model\n\nlogreg=LogisticRegression(random_state=100)\n","9da1f026":"# Hyperparamter Tuning and Cross validation\n\n# #specify number of folds for k-fold CV\n# C=np.logspace(-5,8,15)\n# penalty=['l1','l2']\n\n\n# param_grid=dict(C=C,penalty=penalty)\n# # parameters to build the model on\n# # parameters = {'max_depth': range(2, 20, 5)}\n\n\n\n# # fit tree on training data\n# logreg_cv = GridSearchCV(logreg, param_grid, \n#                     cv=3, n_jobs=-1,scoring='roc_auc')\n\n# start_time=time.time()\n# random_result=logreg_cv.fit(X_train, y_train)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","380d92e8":"clf=LogisticRegression(C=0.006105402296585327,dual=False,penalty='l2',random_state=100)\nclf.fit(X_train,y_train)","7071765d":"# Predictions on train data\n\ny_predd=clf.predict(X_train)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_train))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_train , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_train , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_train , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_train , y_predd)))\nprint(metrics.classification_report(y_train, y_predd))\nprint(metrics.confusion_matrix(y_train,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_train, y_predd)\n\nauc = metrics.roc_auc_score(y_train, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()\n\n\n","7bcf3c81":"## Predictions on Test data\n\ny_pred=clf.predict(X_test)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()\n\n","3bcabb71":"feature_importance = abs(clf.coef_[0])\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure(figsize=(15,10))\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()","d9b72c55":"df1=[[81.099,62.209,77.356,54.730,'V14,V4,V12']]\nlr=pd.DataFrame(df1,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nlr","cc727959":"lr[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","3e41ac0a":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state=100)","0c733abd":"# # Let's do hyperparameter tuning \n\n\n# # GridSearchCV to find optimal max_depth\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [10,15],\n#     'min_samples_leaf' : [15,25],\n#     'min_samples_split': [15,25],\n#     'n_estimators': [300,500]\n# #    \n# }\n# # Create a based model\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1,verbose = 1,scoring='roc_auc',return_train_score=True)\n\n","90f0ccb4":"# start_time=time.time()\n# grid_search.fit(X_train, y_train)\n\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","24d2ba54":"# print('We can get roc_auc of',grid_search.best_score_,'using',grid_search.best_params_)\n","b05ad586":"clf = RandomForestClassifier(     max_depth=15,\n                                  min_samples_leaf=15, \n                                  min_samples_split=15,\n                                  n_estimators=500 ,\n                                  n_jobs = -1,\n                                  random_state=100\n                                                                   \n                                  )","ff0a784d":"clf.fit(X_train, y_train)","6b6bdcca":"# Predictions on train data\n\ny_predd=clf.predict(X_train)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_train))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_train , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_train , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_train , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_train , y_predd)))\nprint(metrics.classification_report(y_train, y_predd))\nprint(metrics.confusion_matrix(y_train,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_train, y_predd)\n\nauc = metrics.roc_auc_score(y_train, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()\n\n\n","08fb1638":"## Predictions on Test data\n\ny_pred=clf.predict(X_test)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","9a409a82":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","59f9eff4":"df2=[[89.094,78.198,85.465,70.946,'V14,V4,V12']]\nrf=pd.DataFrame(df2,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nrf\n","5dd66aff":"rf[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","b89c49f8":"# Importing decision tree classifier from sklearn library\nfrom sklearn.tree import DecisionTreeClassifier\n\ndt= DecisionTreeClassifier(random_state=100)","00060513":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [5,10],\n#     'min_samples_leaf' : [15,25],\n#     'min_samples_split': [15,25],\n#     'criterion': [\"entropy\", \"gini\"]\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# dtree = DecisionTreeClassifier()\n# grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_train, y_train)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","72729c1a":"clf = DecisionTreeClassifier(max_depth=5,criterion='entropy', min_samples_leaf= 25, min_samples_split= 15,random_state=100)\nclf.fit(X_train, y_train)","a752ab25":"# Predictions on train data\n\ny_predd=clf.predict(X_train)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_train))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_train , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_train , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_train , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_train , y_predd)))\nprint(metrics.classification_report(y_train, y_predd))\nprint(metrics.confusion_matrix(y_train,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_train, y_predd)\n\nauc = metrics.roc_auc_score(y_train, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()\n\n\n","ebd1eca5":"## Predictions on Test data\n\ny_pred=clf.predict(X_test)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","33fdaa83":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","ea3a55cd":"df3=[[88.656,77.326,86.814,73.649,'V17,V14,V10']]\ndt=pd.DataFrame(df3,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\ndt\n","33e6dc7e":"dt[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","59f9f5a6":"!pip install xgboost","f26512d9":"\nfrom xgboost import XGBClassifier\n","fc15b220":"model = XGBClassifier(random_state=100)","7d493a71":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [6,12],\n#     'n_rounds' : [100,200],\n#     'gamma'  : [0,5]\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# xg = XGBClassifier()\n# grid_search = GridSearchCV(estimator = xg, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_train, y_train)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time)))","9b4cdf2c":"clf=XGBClassifier(gamma= 5, max_depth= 12, n_rounds= 100,random_state=100)\nclf.fit(X_train,y_train)","bf260f62":"# Predictions on train data\n\ny_predd=clf.predict(X_train)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_train))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_train , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_train , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_train , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_train , y_predd)))\nprint(metrics.classification_report(y_train, y_predd))\nprint(metrics.confusion_matrix(y_train,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_train, y_predd)\n\nauc = metrics.roc_auc_score(y_train, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n","678b6421":"## Predictions on Test data\n\ny_pred=clf.predict(X_test)\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","fd8512ce":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","000f1b75":"df4=[[93.895,87.791,88.507,77.027,'V17,V14,V10']]\nxg=pd.DataFrame(df4,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nxg","dadd0b34":"xg[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","43359a0a":"from collections import Counter # counter takes values returns value_counts dictionary\nfrom sklearn.datasets import make_classification","1708d70d":"print('Original dataset shape %s' % Counter(y))\n\nrus = RandomUnderSampler(random_state=100)\nX_res, y_res = rus.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))","d7a1636d":"# #specify number of folds for k-fold CV\n# C=np.logspace(-5,8,15)\n# dual=[True,False]\n\n# penalty=['l1','l2']\n\n\n# param_grid=dict(dual=dual,C=C,penalty=penalty)\n# # parameters to build the model on\n# # parameters = {'max_depth': range(2, 20, 5)}\n\n# # instantiate the model\n# logregg1 = LogisticRegression(random_state=100,solver='saga',warm_start=True,fit_intercept=True)\n\n\n# # fit tree on training data\n# logreg_cv = GridSearchCV(logregg1, param_grid, \n#                     cv=3, n_jobs=-1,scoring='roc_auc')\n\n# start_time=time.time()\n# random_result=logreg_cv.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","7634ae50":"clf=LogisticRegression(C=0.05179474679231213,dual=False,penalty='l1',random_state=100,solver='saga',warm_start=True,fit_intercept=True)\nclf.fit(X_res, y_res)\n","e998900a":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","980c054a":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","bc9253a4":"feature_importance = abs(clf.coef_[0])\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure(figsize=(15,10))\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=12)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()","ed8412c4":"data=[[94.186,90.698,92.674,87.162,'V14,V4,V12']]\nLr_rus=pd.DataFrame(data,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nLr_rus","64644fc4":"Lr_rus[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","62954326":"print('Original dataset shape %s' % Counter(y))\n\nsmote = SMOTE(random_state=100)\nX_res, y_res = smote.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))\n","ad189b45":"# # specify number of folds for k-fold CV\n# C=np.logspace(-5,8,15)\n\n# penalty=['l1','l2']\n\n\n# param_grid=dict(dual=dual,C=C,penalty=penalty)\n# # # parameters to build the model on\n# # # parameters = {'max_depth': range(2, 20, 5)}\n\n# # # instantiate the model\n# logregg1 = LogisticRegression(random_state=100,solver='saga',dual=False,warm_start=True,fit_intercept=True)\n\n\n# # # fit tree on training data\n# logreg_cv = GridSearchCV(logregg1, param_grid, \n#                     cv=3, n_jobs=-1,scoring='roc_auc')\n\n# start_time=time.time()\n# random_result=logreg_cv.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","6348a446":"clf=LogisticRegression(C=19306.977288832535,dual=False,penalty='l1',random_state=100,solver='saga',warm_start=True,fit_intercept=True)\nclf.fit(X_res, y_res)","3f96b523":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","18bcdfc4":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","3cb27529":"feature_importance = abs(clf.coef_[0])\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure(figsize=(15,10))\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=12)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()","5f2cd727":"data1=[[94.912,92.619,93.243,89.189,'V4,V10,V14']]\nlr_sm=pd.DataFrame(data1,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features']\n                  )\nlr_sm","432583b0":"lr_sm[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","6ddeb95f":"print('Original dataset shape %s' % Counter(y))\n\nadasyn = ADASYN(random_state=100)\n\nX_res, y_res = adasyn.fit_resample(X_train, y_train)\nprint('Resampled dataset shape %s' % Counter(y_res))","b1fa5d67":"# # specify number of folds for k-fold CV\n# C=np.logspace(-5,8,15)\n# dual=[True,False]\n\n# penalty=['l1','l2']\n\n\n# param_grid=dict(dual=dual,C=C,penalty=penalty)\n# # # parameters to build the model on\n# # # parameters = {'max_depth': range(2, 20, 5)}\n\n# # # instantiate the model\n# logregg1 = LogisticRegression(random_state=100,solver='saga',warm_start=True,fit_intercept=True)\n\n\n# # # fit tree on training data\n# logreg_cv = GridSearchCV(logregg1, param_grid, \n#                     cv=3, n_jobs=-1,scoring='roc_auc')\n\n# start_time=time.time()\n# random_result=logreg_cv.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","28eaba44":"clf=LogisticRegression(C=0.0007196856730011522,dual=False,penalty='l1',random_state=100,solver='saga',warm_start=True,fit_intercept=True)\nclf.fit(X_res, y_res)\n","efde552a":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","fc8ff2a9":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","f6a6afc1":"feature_importance = abs(clf.coef_[0])\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure(figsize=(15,10))\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=12)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()","7895fb4c":"data=[[89.249,87.037,92.392,93.243,'V4,V14,V10']]\nLr_ad=pd.DataFrame(data,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nLr_ad","627e7190":"Lr_ad[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","565b3ffa":"from collections import Counter # counter takes values returns value_counts dictionary\nfrom sklearn.datasets import make_classification\n\nprint('Original dataset shape %s' % Counter(y))\n\nrus = RandomUnderSampler(random_state=100)\nX_res, y_res = rus.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))","e390e5ce":"# # Let's Try hyperparameter tuning\n\n# # GridSearchCV to find optimal max_depth\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.ensemble import RandomForestClassifier\n\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [5,10],\n#     'min_samples_leaf' : [5,15,25],\n#     'min_samples_split': [5,15, 25],\n#     'n_estimators': [100,200]\n# #     'max_features': [10,15,20]\n# }\n# # Create a based model\n# rf = RandomForestClassifier(random_state=0)\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1,verbose = 1,scoring='roc_auc',return_train_score=True)\n\n","ed77bea0":"# start_time=time.time()\n# grid_search.fit(X_res, y_res)\n\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')\n# print('We can get roc_auc of',grid_search.best_score_,'using',grid_search.best_params_)\n","e3898824":"clf = RandomForestClassifier(     max_depth=10,\n                                  min_samples_leaf=5, \n                                  min_samples_split=5,\n                                  n_estimators=200 ,\n                                   n_jobs = -1,\n                                  random_state =100                                  \n                                  )\nclf.fit(X_res, y_res)","bb0e65f3":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","82709c85":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","45015bdd":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","b1bafb2b":"data3=[[96.948,94.767,92.558,87.838,'V14,V10,V4']]\nrf_rus=pd.DataFrame(data3,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nrf_rus\n","3d3ba1ab":"rf_rus[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","51f10397":"print('Original dataset shape %s' % Counter(y))\n\nsmote = SMOTE(random_state=100)\nX_res, y_res = smote.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))","0c15d9c8":"# # Let's Try hyperparameter tuning\n\n# # GridSearchCV to find optimal max_depth\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [10,15],\n#     'min_samples_leaf' : [25,50],\n#     'min_samples_split': [25, 50],\n#     'n_estimators': [500,700]\n# #     'max_features': [10,15,20]\n# }\n# # Create a based model\n# rf = RandomForestClassifier(random_state=42)\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1,verbose = 1,scoring='roc_auc',return_train_score=True)\n\n","6b182c58":"# start_time=time.time()\n# grid_search.fit(X_res, y_res)\n\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')\n# print('We can get roc_auc of',grid_search.best_score_,'using',grid_search.best_params_)","37b1fc96":"clf = RandomForestClassifier(     max_depth=10,\n                                  min_samples_leaf=25, \n                                  min_samples_split=25,\n                                  n_estimators=700 ,\n                                  oob_score = True, n_jobs = -1,\n                                  random_state =100                                  \n                                  )\nclf.fit(X_res, y_res)","35a29b92":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","fdf018f6":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","43abb92f":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","cb423cb1":"data4=[[99.176,98.511,92.819,85.811,'V14,V10,V4']]\nrf_sm=pd.DataFrame(data4,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nrf_sm","8e9b601e":"rf_sm[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","2e0c2e80":"print('Original dataset shape %s' % Counter(y))\n\nadasyn = ADASYN(random_state=100)\n\nX_res, y_res = adasyn.fit_resample(X_train, y_train)\nprint('Resampled dataset shape %s' % Counter(y_res))","c224fa8e":"# # Let's Try hyperparameter tuning\n\n# # GridSearchCV to find optimal max_depth\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [10,15],\n#     'min_samples_leaf' : [25,50],\n#     'min_samples_split': [25, 50],\n#     'n_estimators': [500,700]\n# #     'max_features': [10,15,20]\n# }\n# # Create a based model\n# rf = RandomForestClassifier(random_state=100)\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1,verbose = 1,scoring='roc_auc',return_train_score=True)\n\n","3953402d":"# start_time=time.time()\n# grid_search.fit(X_res, y_res)\n\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')\n# print('We can get roc_auc of',grid_search.best_score_,'using',grid_search.best_params_)\n","70f03aca":"clf = RandomForestClassifier(     max_depth=10,\n                                  min_samples_leaf=25, \n                                  min_samples_split=25,\n                                  n_estimators=700 ,\n                                  oob_score = True, n_jobs = -1,\n                                  random_state =100                                 \n                                  )\nclf.fit(X_res, y_res)","13dcf60b":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","b962a0a4":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","31726617":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","b5f9732d":"data5=[[99.275,99.631,93.057,87.162,'V4,V14,V17']]\nrf_ad=pd.DataFrame(data5,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nrf_ad\n","d1b2e514":"rf_ad[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","f98a129b":"from collections import Counter # counter takes values returns value_counts dictionary\nfrom sklearn.datasets import make_classification\n\nprint('Original dataset shape %s' % Counter(y))\n\nrus = RandomUnderSampler(random_state=100)\nX_res, y_res = rus.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))","a0eda1f5":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [6,12],\n#     'n_rounds' : [50,100],\n#     'gamma': [0,5],\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# xg = XGBClassifier(random_state=100)\n# grid_search = GridSearchCV(estimator = xg, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time)))","7259d387":"clf=XGBClassifier(gamma= 5, max_depth= 6, n_rounds= 50,random_state=100)\nclf.fit(X_res,y_res)","9f3fee44":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","46391f64":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","5873b064":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","6c67bd94":"data6=[[97.384,95.640,92.060,87.838,'V14,V10,V4']]\nxg_rus=pd.DataFrame(data6,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nxg_rus\n","07d38662":"xg_rus[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","c5de7564":"print('Original dataset shape %s' % Counter(y))\n\nsmote = SMOTE(random_state=100)\nX_res, y_res = smote.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))\n","46133959":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [6,12,18],\n#     'n_rounds' : [100,200,300]\n    \n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# xg = XGBClassifier(random_state=100,gamma=5)\n# grid_search = GridSearchCV(estimator = xg, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time)))","1e27e8b3":"clf=XGBClassifier(gamma= 5, max_depth= 6,learning_rate=0.2,random_state=100, n_rounds= 100,min_child_weight=1,colsample_bytree=0.7)\nclf.fit(X_res,y_res)","a5a66525":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","a4a10b35":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","880eeb78":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","abffdedf":"data7=[[99.988,01.000,92.528,85.135,'V14,V10,V4']]\nxg_sm=pd.DataFrame(data6,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nxg_sm","63717b70":"xg_sm[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","aa93b383":"print('Original dataset shape %s' % Counter(y))\n\nadasyn = ADASYN(random_state=100)\n\nX_res, y_res = adasyn.fit_resample(X_train, y_train)\nprint('Resampled dataset shape %s' % Counter(y_res))","4088454b":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [6,12],\n#     'n_rounds' : [100,300],\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# xg = XGBClassifier(random_state=100,gamma=5)\n# grid_search = GridSearchCV(estimator = xg, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time)))","3865592c":"clf=XGBClassifier(gamma= 5, max_depth= 12,learning_rate=0.2,random_state=100, n_rounds= 100,min_child_weight=1,colsample_bytree=0.7)\nclf.fit(X_res,y_res)","82b0f76a":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","8c66cf69":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","ebf17511":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","bb0f7b06":"data8=[[99.996,100.000,90.848,81.757,'V4,V14,V10']]\nxg_ad=pd.DataFrame(data8,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\nxg_ad\n","37cf84bf":"xg_ad[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","c84dae69":"print('Original dataset shape %s' % Counter(y))\n\nrus = RandomUnderSampler(random_state=100)\nX_res, y_res = rus.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))","2b924166":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [5,10],\n#     'min_samples_leaf' : [5,25,45],\n#     'min_samples_split': [5,25,45],\n#     'criterion': [\"entropy\", \"gini\"]\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# dtree = DecisionTreeClassifier()\n# grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","26651ce6":"clf = DecisionTreeClassifier(max_depth=5,criterion='gini', min_samples_leaf= 5, min_samples_split= 45,random_state=100)\nclf.fit(X_res, y_res)","b071b6e1":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","13d308a3":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","f3addb9e":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","28587c6e":"data9=[[95.203,93.314,90.759,87.162,'V14,V4,V7']]\ndt_rus=pd.DataFrame(data9,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\ndt_rus","fc7d9c38":"dt_rus[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","d65d4fae":"print('Original dataset shape %s' % Counter(y))\n\nsmote = SMOTE(random_state=100)\nX_res, y_res = smote.fit_resample(X_train, y_train)\n\nprint('Resampled dataset shape %s' % Counter(y_res))\n","01de4be2":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [5,10,15],\n#     'min_samples_leaf' : [5,25,50],\n#     'min_samples_split': [5,25,50],\n#     'criterion': [\"entropy\", \"gini\"]\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# dtree = DecisionTreeClassifier()\n# grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","828329aa":"clf = DecisionTreeClassifier(max_depth=15,criterion='entropy', min_samples_leaf= 50, min_samples_split= 25,random_state=100)\nclf.fit(X_res, y_res)","bb1d818d":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","b55ae4e1":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","1f7c8b7a":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","d680b25a":"data10=[[99.345,99.545,91.767,84.459,'V14,V4,V12']]\ndt_sm=pd.DataFrame(data10,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\ndt_sm\n","5c64193e":"dt_sm[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","9601b681":"print('Original dataset shape %s' % Counter(y))\n\nadasyn = ADASYN(random_state=100)\n\nX_res, y_res = adasyn.fit_resample(X_train, y_train)\nprint('Resampled dataset shape %s' % Counter(y_res))","f7c54730":"# # GridSearchCV to find optimal n_estimators\n# from sklearn.model_selection import KFold\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import RandomizedSearchCV\n# import time\n\n\n\n# param_grid = {\n#     'max_depth': [5,10,15],\n#     'min_samples_leaf' : [5,25,50],\n#     'min_samples_split': [5,25,50],\n#     'criterion': [\"entropy\", \"gini\"]\n# }\n\n# n_folds = 3\n\n# # Instantiate the grid search model\n# dtree = DecisionTreeClassifier(random_state=100)\n# grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n#                           cv = n_folds, verbose = 1,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n\n# start_time=time.time()\n# random_result=grid_search.fit(X_res, y_res)\n\n# print('Best: %f using %s' % (random_result.best_score_,random_result.best_params_))\n# print('Execution time: ' + str((time.time()-start_time))+'seconds')","31331ce4":"clf = DecisionTreeClassifier(max_depth=5,criterion='gini', min_samples_leaf= 50, min_samples_split= 5,random_state=100)\nclf.fit(X_res, y_res)","76e4c5b7":"y_predd=clf.predict(X_res)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_predd , y_res))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_res , y_predd)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_res , y_predd)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_res , y_predd)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_res , y_predd)))\nprint(metrics.classification_report(y_res, y_predd))\nprint(metrics.confusion_matrix(y_res,y_predd))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_res, y_predd)\n\nauc = metrics.roc_auc_score(y_res, y_predd)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","2b9ba0d1":"y_pred=clf.predict(X_test)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred , y_test))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred)))\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n# plot ROC Curve\n\nplt.figure(figsize=(8,6))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nprint(\"AUC - \",auc,\"\\n\")\n\nplt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\n\nplt.plot([0,1], [0,1], 'k--' )\n\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Predicting a credit card fraud detection')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.show()","700a7f02":"pd.concat((pd.DataFrame(X.columns,columns=['Variable']),\n           pd.DataFrame(clf.feature_importances_,columns=['importance'])),axis=1).sort_values(by='importance',ascending=False)","08b8283d":"data11=[[92.762,93.512,90.009,87.838,'V4,V14,V7']]\ndt_ad=pd.DataFrame(data11,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'])\ndt_ad\n","5ea30223":"dt_ad[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')\n","6cb9319e":"\nfinal1=[[81.099,62.209,77.356,54.730,'V14,V4,V12'],[89.094,78.198,85.465,70.946,'V14,V4,V12'],[88.656,77.326,86.814,73.649,'V17,V14,V10'],[93.895,87.791,88.507,77.027,'V17,V14,V10']]\ndata_imbalanced=pd.DataFrame(final1,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'],index =['Logisticreg', 'RandomForest', 'DecisionTree', 'XGBOOST'])\ndata_imbalanced","7111ef0f":"plt.figure(figsize=(25,10))\n\ndata_imbalanced[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","2febd3c1":"## Checking all models of logistic regression and choosing the best one \n\ndataa1=[[81.099,62.209,77.356,54.730,'V14,V4,V12'],[94.186,90.698,92.674,87.162,'V14,V4,V12'],[94.912,92.619,93.243,89.189,'V4,V10,V14'],[89.249,87.037,92.392,93.243,'V4,V14,V10']]\nLr_final=pd.DataFrame(dataa1,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'],index =['imbalanced', 'Randomundersampler', 'SMOTE', 'ADASYN'])\nLr_final","03a4746e":"Lr_final[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","e5235c16":"## Checking all models of Random Forest and choosing the best one \n\ndataa2=[[89.094,78.198,85.465,70.946,'V14,V4,V12'],[96.948,94.767,92.558,87.838,'V14,V10,V4'],[99.176,98.511,92.819,85.811,'V14,V10,V4'],[99.275,99.631,93.057,87.162,'V4,V14,V17']]\nrf_final=pd.DataFrame(dataa2,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'],index =['imbalanced', 'Randomundersampler', 'SMOTE', 'ADASYN'])\nrf_final\n","73a14850":"rf_final[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","bf272f2b":"dataa3=[[88.656,77.326,86.814,73.649,'V17,V14,V10'],[95.203,93.314,90.759,87.162,'V14,V4,V7'],[99.345,99.545,91.767,84.459,'V14,V4,V12'],[92.762,93.512,90.009,87.838,'V4,V14,V7']]\ndt_final=pd.DataFrame(dataa3,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'],index =['imbalanced', 'Randomundersampler', 'SMOTE', 'ADASYN'])\ndt_final","dfa6fffc":"dt_final[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","1e2a87dd":"dataa4=[[93.895,87.791,88.507,77.027,'V17,V14,V10'],[97.384,95.640,92.060,87.838,'V14,V10,V4'],[99.988,100.000,92.528,85.135,'V14,V10,V4'],[99.996,100.000,90.848,81.757,'V4,V14,V10']]\nxg_final=pd.DataFrame(dataa4,columns=['AUC Train','Recall Train','AUC Test','Recall Test','Top 3 Features'],index =['imbalanced', 'Randomundersampler', 'SMOTE', 'ADASYN'])\nxg_final\n","d76739e2":"xg_final[['AUC Train','Recall Train','AUC Test','Recall Test']].plot(kind='bar')","038e91da":"#### It looks like that no features are highly correlated with any other features.\n\n","aa2b3765":"## FINAL RESULTS","63ad9b45":"##### Results for LR with Imbalanced data :\n - AUC on Train data : 0.81099  and AUC on Test Data : 0.77356\n - Recall on Train data :0.62209 and on Test Data :  0.54730\n - Top 3 features are \n     1. V14 \n     2. V4 \n     3. V12","136dcd07":"### Observing the distribution of classes [non - fraudulent and fraudulent]\n","3970eb52":"### Decision Tree-\n\n     - imbalanced : 86 AUC on test data \n     - Top 3 Features : v17,v14,v10   \n##### Best Model after balancing : \n     - dt using smote with 91.767 AUC for test data \n     - Top 3 features : V14,V4,v12","1bf47f2a":"### Load Dataset","efd52835":"##### Highlights:\n\n#### - Majority of Fraud transaction is less than thousand dollars.\n#### -There is a presence of outliers in non fraud transaction data.So we can consider removing.\n#### - We need to make sure while removing outlier we don't remove a fraud data as already data is highly imbalanced.\n#### - Not getting any insights from time feature\n","f30ec33f":"### Logistic Regression using SMOTE with 93.243 AUC for test data \n### Top 3 features : V4,V10,V14","a9fb9531":"## BALANCED DATA\nNow we would be applying 3 Balancing techniques on imbalanced data and check the results :\n    \n### Balancing Techniques :\n        - Random Under Sampling\n        - SMOTE\n        - ADASYN\n        \n### Machine Learning Algorithm :\n        - Logistic Regression\n        - Random Forest\n        - XGBOOST\n","a1450868":"## Random Undersampling - Decision Tree","1d59406f":"## XGBOOST","8b23973d":"## SMOTE-Decision Tree","3f4c8f92":"##### Results for Decision Tree with Imbalanced data :\n - AUC on Train data : 0.88656  and AUC on Test Data : 0.86814\n - Recall on Train data :0.77326 and on Test Data : 0.73649\n - Top 3 features are \n     1. V17 \n     2. V14 \n     3. V10","3daca526":"## SMOTE - XGBOOST","6dd55262":"##### Results for XGBOOST with Imbalanced data :\n - AUC on Train data : 0.93895  and AUC on Test Data : 0.88507\n - Recall on Train data :0.87791 and on Test Data : 0.77027\n - Top 3 features are \n     1. V17 \n     2. V14 \n     3. V10","c864d7dd":"............................................................................................","2615e148":"## Random Under Sampling - Random Forest","02d60750":"##### Highlights:\n\n#### - Tried removing outliers by quantile till 95 but can see while removing we are also losing 50 something fraud transactions.\n####  -As we can't afford to remove fraud data so we  won't be treating outliers here.","fed0cff1":"##### Highlights \n     \n     \n####     - Dataset contains details of 284807 transactions with 31 features.\n     \n####     - Apart from \u2018time\u2019 and \u2018amount\u2019, all the other features (V1, V2, V3, up to V28) are the principal components obtained using PCA.\n     \n####     -Class is our dependent variable which represents class labelling, and it takes the value 1 in cases of fraud and 0 in others.\n     \n####     -There is no missing values.","ca63a6f5":"## BEST MODEL","c5fb6014":"## SMOTE - Random Forest ","a24d4137":"## Random Forest ","36d09753":"### Logistic Regression -\n\n     - imbalanced : 77 AUC on test data \n     - Top 3 Features : v14,v4,v12   \n##### Best Model after balancing : \n     - LR using SMOTE with 93.243 AUC for test data \n     - Top 3 features : V4,V10,V14","a72fc47e":"### Checking for Outliers\n","06e66958":"## ADASYN- XGBOOST","144a915f":"## ADASYN- Decision Tree","e6983bf4":"## Model Building \n","9ae67a5b":"## SMOTE - Logistic Regression","93b47841":"## Random Under Sampling - XGBOOST ","76c7577e":"\n\n\n### Correlation amongst raw data wrt class\n","a7ff168f":"## ADASYN - Random Forest","ae62ca26":"### XGBOOST-\n\n     - imbalanced : 88.507 AUC on test data \n     - Top 3 Features : v17,v14,v10   \n##### Best Model after balancing : \n     - dt using smote with 92.528 AUC for test data \n     - Top 3 features : V14,V10,v4","eb8f31af":"#### Top model for imbalanced data is XGBOOST with AUC 88.5% and Recall 77% \n#### Top 3 Features = V17,V14,V10","f2e9a41e":"## Logistic Regression","a74aa0d6":"##### Highlights:\n\nThis dataset has 492 frauds out of 284,315 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. Most of the transactions are non-fraud.","d29cf040":"### Random Forest-\n\n     - imbalanced : 85 AUC on test data \n     - Top 3 Features : v14,v4,v12   \n##### Best Model after balancing : \n     - rf using adasyn with 93.057 AUC for test data \n     - Top 3 features : V4,V14,v17","8ddc08e0":"## IMBALANCED DATA\nWe Will be first building different model using various machine learning algorithm on imbalanced Data\n1. Logistic Regression\n2. Random Forest\n3. Decision Tree\n4. XGBOOST ","377cdaf3":"##### Results for Random Forest with Imbalanced data :\n - AUC on Train data : 0.89094  and AUC on Test Data : 0.85465\n - Recall on Train data :0.78198 and on Test Data : 0.70946\n - Top 3 features are \n     1. V17 \n     2. V12 \n     3. V14","08bcceb5":"### Primary checks on data first","b5bed399":"## Decision Tree","d2df7f26":"## ADASYN - Logistic Regression ","f0c60984":"### Distribution of Amount and Time wrt Class\n","91e29dde":"* # Credit Card Fraud Detection\n\n##### - To predict fraudulent credit card transactions with the help of machine learning models.\n##### - The data set includes credit card transactions made by European cardholders over a period of two days in September 2013.\n","c8e13f0c":"   ## Random under Sampling - Logistic Regression"}}