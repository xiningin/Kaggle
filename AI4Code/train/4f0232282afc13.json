{"cell_type":{"f28f4edb":"code","62214295":"code","0cc1d59e":"code","25bf846f":"code","afb91e61":"code","87b6ca48":"code","f36573cb":"code","c4ecc9fa":"code","153b80f3":"code","219176f9":"code","4481085c":"code","140bc11f":"markdown","243af246":"markdown","8a4d8dc5":"markdown","837aabd9":"markdown"},"source":{"f28f4edb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n#del train,test\n#train=pd.read_csv(\"..\/input\/train.csv\")\n#test=pd.read_csv(\"..\/input\/test.csv\")\n\n","62214295":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndef kodeer(dfdir):\n    \n    mtrain=pd.read_csv(dfdir).reset_index()\n    if 'experiment' in mtrain.columns:\n        print('train experiment \/n',mtrain.groupby('experiment').count())\n    else:\n        print('event',mtrain.groupby('event').count())\n    \n                \n    features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]\n\n    mtrain['pilot'] = 100 * mtrain['seat'] + mtrain['crew']\n    print(\"Number of pilots : \", len(mtrain['pilot'].unique()))\n    \n    pilots=mtrain['pilot'].unique()\n    for pilot in pilots:\n        ids = mtrain[mtrain[\"pilot\"] == pilot].index\n        scaler = MinMaxScaler()\n        mtrain.loc[ids, features_n] = scaler.fit_transform(mtrain.loc[ids, features_n])    \n    \n    mtrain=mtrain.drop('experiment',axis=1)\n    \n    if 'event' in mtrain.columns:\n        lbl = LabelEncoder()\n        mtrain['event']=lbl.fit_transform(list(mtrain['event'].values))\n        lblevent=lbl\n        print( list(lblevent.classes_) )\n    else:\n        lblevent=[]\n\n    mtrain['groep']=np.round( mtrain.index.values\/256,0 )  # 256 measurements per second = grouping per second !\n    trainSD=mtrain.groupby(['groep','crew']).std()  #,'seat'\n    trainMA=mtrain.groupby(['groep','crew']).mean() #,'seat'\n    trainSD=trainSD.reset_index().sort_values(['crew','index']) #,'seat'\n    trainMA=trainMA.reset_index().sort_values(['crew','index']) #,'seat'\n\n    return trainSD,trainMA,lblevent,mtrain[['groep','crew']] #,'seat'\n\ntestsd,testma,lbl_event,test=kodeer(\"..\/input\/test.csv\")\ntrainsd,trainma,lbl_event,train=kodeer(\"..\/input\/train.csv\")\n\n\nprint(trainsd.shape,testsd.shape,test.shape)","0cc1d59e":"\ndef SVD_tree_predict(e_,mtrain,mtest,veld,idvld):\n    velden=[v for v in e_.columns if v not in [veld,idvld]]\n    label = mtrain[veld].astype('int')\n    mtrain[veld]=label\n    print(e_.shape,velden)\n    e_=e_.loc[:,velden]\n\n    print(e_.shape)\n    ncomp=e_.shape[1]-3\n    # SVD\n    from sklearn.decomposition import TruncatedSVD\n    svd = TruncatedSVD(n_components=ncomp, n_iter=7, random_state=42)\n    e_=svd.fit_transform(e_.fillna(0))\n    print(e_[:len(mtrain)].shape,mtrain[veld].values.shape)\n    \n    xtrain=pd.DataFrame(e_[:len(mtrain)])\n    xtrain[veld]=label\n    xtest=pd.DataFrame(e_[len(mtrain):])\n    #New_features=e_[:len(mtrain)]\n    #Test_features=e_[len(mtrain):]\n    pd.DataFrame(e_[:len(mtrain)]).plot.scatter(x=0,y=1,c=label,colormap='winter')\n    from sklearn.ensemble import RandomForestClassifier, VotingClassifier,ExtraTreesClassifier,GradientBoostingRegressor, AdaBoostClassifier\n    from sklearn.multiclass import OneVsRestClassifier\n    clf=OneVsRestClassifier(ExtraTreesClassifier(n_estimators=10))\n    \n    fit=clf.fit(e_[:len(mtrain)],label)\n    pred=fit.predict(e_[:len(mtrain)])\n    from sklearn.metrics import accuracy_score\n    print('accuracy',accuracy_score(mtrain[veld].astype('int'),pred)*100)\n    #predict\n    sub = pd.DataFrame(fit.predict_proba(e_[len(mtrain):]))\n    for ci in mtest.columns:\n        sub[ci]=mtest[ci]\n    \n    sub.to_csv('submission.csv', index=False)\n    # prepare second method\n    import lightgbm as lgb\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import confusion_matrix, log_loss\n\n    train_df, val_df = train_test_split(mtrain, test_size=0.2, random_state=420)\n    print(f\"Training on {train_df.shape[0]} samples.\")    \n    features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]\n    features = [\"crew\", \"seat\"] + features_n\n    features =[x for x in mtrain.columns if x !=veld]  \n    def run_lgb(df_train, df_test):\n    \n        params = {\"objective\" : \"multiclass\",\n                  \"num_class\": 4,\n                  \"metric\" : \"multi_error\",\n                  \"num_leaves\" : 30,\n                  \"min_child_weight\" : 50,\n                  \"learning_rate\" : 0.1,\n                  \"bagging_fraction\" : 0.7,\n                  \"feature_fraction\" : 0.7,\n                  \"bagging_seed\" : 420,\n                  \"verbosity\" : -1\n                 }\n    \n        lg_train = lgb.Dataset(df_train[features], label=(df_train[veld]))\n        lg_test = lgb.Dataset(df_test[features], label=(df_test[veld]))\n        model = lgb.train(params, lg_train, 1000, valid_sets=[lg_test], early_stopping_rounds=50, verbose_eval=100)\n    \n        return model\n    \n    model = run_lgb(train_df, val_df)\n    pred_val = model.predict(val_df[features], num_iteration=model.best_iteration)\n    print( confusion_matrix(np.argmax(pred_val, axis=1), val_df[veld].values) )\n    pred_test = model.predict(mtest[features], num_iteration=model.best_iteration) #mtest[features]\n    submission = pd.DataFrame(np.concatenate((np.arange(len(mtest))[:, np.newaxis], pred_test), axis=1), columns=['id', 'A', 'B', 'C', 'D'])\n    submission['id'] = submission['id'].astype(int)\n    \n    return sub,submission","25bf846f":"trainMS=trainma.merge(trainsd,left_index=True,right_index=True)\ntestMS=testma.merge(testsd,left_index=True,right_index=True)\ntrainma['event']=trainma['event']+0.249 #*2\ntrainma['event']=trainma['event'].map(round)\n\ntrainma.groupby('event').count(),trainma.shape,testma.shape,trainMS.shape,testMS.shape","afb91e61":"trainMS","87b6ca48":"#subx=SVD_tree_predict(trainMS.append(testMS).drop(['index_x','index_y','id_x','id_y','pilot_x','pilot_y','time_x','time_y','event_y','groep_y','event_x','crew_x','crew_y','seat_x','seat_y'],axis=1), trainma,testma,'event','groep')\ndropveld=['index_x','index_y','id_x','id_y','pilot_x','pilot_y','time_x','time_y','event_y','groep_x','groep_y','event_x','crew_x','crew_y','seat_x','seat_y']\ndropveld1=['index_x','index_y','pilot_x','pilot_y','time_x','time_y','groep_x','groep_y','crew_x','crew_y','seat_x','seat_y','event_y']\n\ndropveld2=['index_x','index_y','pilot_x','pilot_y','time_x','time_y','groep_x','groep_y','crew_x','crew_y','seat_x','seat_y']\n\n#subx,subg=SVD_tree_predict(trainma.append(testma).drop(['index','id','pilot','time','groep','event','crew','seat'],axis=1), trainma,testma,'event','groep')\nsubx,subg=SVD_tree_predict(trainMS.append(testMS).drop(dropveld,axis=1), trainMS.drop(dropveld1,axis=1),testMS.drop(dropveld2,axis=1),'event_x','groep')\n","f36573cb":"subx #[['groep','crew','seat']]\nsubg","c4ecc9fa":"sub2=subx.iloc[:,:7]\nsub2.columns=['A','B','C','D','groep','crew','seat']\nsub2.head()","153b80f3":"#sub2=subx.groupby('groep').median()\n#sub2=subx[:int(len(subx)\/2)]\ntest","219176f9":"#testSD=testSD.merge(subx,left_on='groep',right_on='groep')\n#testSD['event']=lblevent.inverse_transform(testSD['event_x'])\n\n\n#test=pd.read_csv(\"..\/input\/test.csv\")\n#test['groep']=np.round( test.index.values\/200,0 )\n#test2=test.merge(sub2,how='left',left_on=['groep','crew'],right_on=['groep','crew']) #','seat'\ntest2=test.merge(subg,how='left',left_on=['groep'],right_on=['id']) #','seat'\n#test2.groupby('event_x').count()\n#test2=test2.drop(['groep','crew','seat'],axis=1)  #,'seat'\ntest2=test2.drop(['groep','id','crew'],axis=1)  #,'seat'\ntest2.index.names = ['id']\ntest2=test2.reset_index()\n\ntest2","4481085c":"test2.to_csv('submission.csv', index=False)","140bc11f":"# prepare Train data\n* create index\n* set extra index\n* labelencode all constants\n* regroup by STD, MEAN\n* SD\n*  work with functions to free maximum the memory","243af246":"# Trying to forecast\n","8a4d8dc5":"# prepare cluster methods","837aabd9":"# Question:\nthe test experiment field only contains 'loft'"}}