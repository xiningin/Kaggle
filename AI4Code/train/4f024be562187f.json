{"cell_type":{"3157c9fd":"code","0f4a41de":"code","ea6b94b7":"code","feb6046e":"code","e50e4573":"code","69da6875":"code","f80313df":"code","e128ccb3":"code","dbfd1c67":"code","c1eb17fb":"code","24294f41":"code","a232b29a":"code","26076208":"code","c331265d":"code","9ebe8acc":"code","8aaa5110":"code","0f29dda1":"code","ef6a87d4":"code","2eb8ea20":"code","548a0083":"markdown","e5c10bd9":"markdown","d15f56a0":"markdown","2dc064dc":"markdown","0ce56e10":"markdown","9fd116c0":"markdown","1f1202e6":"markdown","44faed98":"markdown","7101272f":"markdown","5a4289c7":"markdown"},"source":{"3157c9fd":"# importing the packages\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport sys\n%load_ext autoreload\n%autoreload 2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np","0f4a41de":"# Creating a keras generator object.\nimage_gen = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = image_gen.flow_from_directory(directory='..\/input', \n                                                target_size=(256,256),  \n                                                batch_size=20, \n                                                shuffle=True, \n                                                seed=42)","ea6b94b7":"# Showing some examples in the dataset.\nbatch = next(train_generator)\nbatch_images = np.array(batch[0])\nbatch_labels = np.array(batch[1])\nlsun_classes = ['dog', 'wolf']\n\nplt.figure(figsize=(16,10))\nfor i in range(10):\n    ax = plt.subplot(4, 5, i+1)\n    plt.imshow(batch_images[i])\n    plt.title(lsun_classes[np.where(batch_labels[i] == 1.)[0][0]])\n    plt.axis('off')","feb6046e":"# Reset the training generator\ntrain_generator = image_gen.flow_from_directory(directory='..\/input', \n                                                target_size=(256,256),  \n                                                batch_size=20, \n                                                shuffle=True, \n                                                seed=42)","e50e4573":"# Creating a simple DL model.\ndef get_model(input_shape):\n    \"\"\"\n    This function should build and compile a CNN model according to the above specification,\n    using the functional API. Your function should return the model.\n    \"\"\"\n    input_layer = Input(input_shape)\n    h = Conv2D(filters=8, kernel_size=(8,8), padding='SAME', activation='relu')(input_layer)\n    h = MaxPool2D((2,2))(h)\n    h = Conv2D(4, (4,4), padding='SAME', activation='relu')(h)\n    h = MaxPool2D((2,2))(h)\n    Flatten_layer = Flatten()(h)\n    h = Dense(16, activation='relu')(Flatten_layer)\n    output_layer = Dense(2, activation='softmax')(h)\n    model = Model(inputs= input_layer, outputs = output_layer)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n    model.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.CategoricalAccuracy(name='accuracy')])\n    return model\n\nmodel = get_model((256, 256, 3))\nmodel.summary()","69da6875":"#train the model for 10 epochs.\nmodel.fit_generator(train_generator, epochs=10)","f80313df":"# function for decoding and resizing the image for feeding in the model.\ndef decode_and_resize_image(dir, expand_dim=True):\n    img = tf.keras.preprocessing.image.load_img(path=dir, target_size=(256,256))\n    input_arr = tf.keras.preprocessing.image.img_to_array(img)\n    input_arr = input_arr\/255.\n    if expand_dim is True:\n        return tf.expand_dims(input_arr, axis=0)\n    else:\n        return input_arr\n# let's load one image of the husky from the internet.   \n!wget https:\/\/vetstreet-brightspot.s3.amazonaws.com\/a9\/f54ad0a80611e0a0d50050568d634f\/file\/Siberian-Husky-4-645mk062811.jpg\nimg1 = decode_and_resize_image('.\/Siberian-Husky-4-645mk062811.jpg')\nimg2 = decode_and_resize_image('.\/Siberian-Husky-4-645mk062811.jpg', False)","e128ccb3":"# helper function for prediction\ndef pred(model, img):\n    acc_list = model.predict(img)[0]\n    if np.argmax(acc_list) ==0:\n        pred = 'Husky'\n        acc = acc_list[0]\n    else:\n        pred = 'Wolf'\n        acc = acc_list[1]\n    print(f'Prediction of the model is {pred} with an accuracy of {acc}')","dbfd1c67":"# Predicting the Husky image\nplt.imshow(img2)\npred(model, img1)","c1eb17fb":"!wget https:\/\/i.ibb.co\/3yqC8Zy\/Whats-App-Image-2020-12-31-at-1-46-15-PM-1.jpg","24294f41":"img3 = decode_and_resize_image('.\/Whats-App-Image-2020-12-31-at-1-46-15-PM-1.jpg')\nimg4 = decode_and_resize_image('.\/Whats-App-Image-2020-12-31-at-1-46-15-PM-1.jpg', False)\n\nplt.imshow(img4)\npred(model, img3)","a232b29a":"# Importing the lime framework\nimport lime\n# lime_image is the function of lime\n# for explaining classifiers that use Image data.\nfrom lime import lime_image","26076208":"# creating the explainer object \nexplainer = lime_image.LimeImageExplainer()","c331265d":"%%time\n# Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, \n# the superpixel will be replaced by the average of its pixels\nexplanation = explainer.explain_instance(img4, model.predict\n                                         , top_labels=5, \n                                         hide_color=0, num_samples=1000)","9ebe8acc":"from skimage.segmentation import mark_boundaries","8aaa5110":"# We can see the top 5 superpixels that are most positive towards the class with the rest of the image hidden\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp, mask))","0f29dda1":"# Or with the rest of the image present:\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nplt.imshow(mark_boundaries(temp, mask))","ef6a87d4":"# We can also see the 'pros and cons' (pros in green, cons in red)\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], \n                                            positive_only=False, \n                                            num_features=10,\n                                            hide_rest=False)\nplt.imshow(mark_boundaries(temp, mask))","2eb8ea20":"#Alternatively, we can also plot explanation weights onto \n# a heatmap visualization. The colorbar shows the values of the weights.\n\n\n#Select the same class explained on the figures above.\nind =  explanation.top_labels[0]\n\n#Map each explanation weight to the corresponding superpixel\ndict_heatmap = dict(explanation.local_exp[ind])\nheatmap = np.vectorize(dict_heatmap.get)(explanation.segments) \n\n#Plot. The visualization makes more sense if a symmetrical colorbar is used.\nplt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\nplt.colorbar()","548a0083":"Let's try to understand what goes wrong with the help of LIME (Local Interpretable Model-Agnostic Explanations) framework.","e5c10bd9":"Most of the ML practioners looks at the smaller picture of Data science project Cycle.\n\nFor them the smaller picture is this:\n![WhatsApp%20Image%202020-12-31%20at%205.55.31%20PM.jpeg](attachment:WhatsApp%20Image%202020-12-31%20at%205.55.31%20PM.jpeg)\n\n\n\n\nBut in reality the the Bigger picture is this:\n![](https:\/\/miro.medium.com\/max\/798\/1*aZTemyGpu92RX2OedsBzsw.jpeg)\n\nWe'll know that the Deep Learning Models are Black Box models.\\\nAnd in this notebook i'm going to talk about Machine Learning Interpretibilaty\\\nwhich is a very crucial part of the Data science project cycle.\\\nBut most often ignored by most of the DataScientists.","d15f56a0":"### Now we can understand that our model is not a \"Wolf vs Husky\" classifier but rather than  \"Snow vs no Snow Classifier\"","2dc064dc":"### What is a Black Box model and what is machine Learning Interpretibilaty?\nThe black box model refers to  behaviourism,\\\nand typically refers to a system for which we can only observe the inputs and\\\noutputs, but not the internal workings.\n\nAnd ML Interpretability refers to the ability to determine cause and effect from a machine learning model.\nOr in leman terms we can define Interpretibilaty as visulasing which features in the data according to model is important to the ML model in taking a decision.","0ce56e10":"Cool our model correctly predict the image of Husky with a pretty goog accuracy.\\\n**Really?**\\\nNow, what I'm going to do is to place the same previous Husky in snow background.","9fd116c0":"Now I'm going to demonstrate this with the help of classical ML intepretaibily\\ example \"The wolf vs Husky\".\\\nFirst let's make an image classifier to classify Wolf and Husky images.\\\nI'm going to use TensorFlow for this.","1f1202e6":"![](http:\/\/media.giphy.com\/media\/NlXJKUUSnkN5BsOtl0\/giphy.gif)\n\n**Wait a minute what happened just now. The model which is previously predicting husky correctly is failing to predict the husky with different background.**","44faed98":"###  <span style=\"color:red\">If you like this kernel then please upvote. It'll motivate me for making more kernels like this.<\/span>","7101272f":"# Why I trust you?\n![](https:\/\/media.giphy.com\/media\/3osxYgrrUziE80aGzK\/giphy.gif)","5a4289c7":"I've puplished the version 1 of the notebook on 1st jan 2021. If you're seeing this\\\ntoday wish me Happy New Year 2021 in the comment section.\n![](https:\/\/media.giphy.com\/media\/a9abUMKDX4G9CNPfA6\/giphy.gif)"}}