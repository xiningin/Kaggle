{"cell_type":{"7aeb8d72":"code","3fe42f6b":"code","7b912394":"code","37f2dc2c":"code","55501f24":"code","3cacff2c":"code","721df038":"code","70c099eb":"code","4cb03d1f":"code","dc7dc1ea":"code","a6d6e5d4":"code","c833a578":"code","55f771fb":"code","bf160208":"code","2f9d83e3":"markdown","4c2d9d13":"markdown","6660fec7":"markdown","5b665943":"markdown","c554a789":"markdown","091ef4ef":"markdown","f79a9c23":"markdown","b63ce794":"markdown","82b712ad":"markdown","50ad1f28":"markdown","c4e2702f":"markdown","45b9d6a4":"markdown"},"source":{"7aeb8d72":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3fe42f6b":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,initializers","7b912394":"np.random.seed(20200422)\ntf.random.set_seed(20200422)","37f2dc2c":"sample_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","55501f24":"sample_submission.head()","3cacff2c":"train.shape","721df038":"train.head()","70c099eb":"test.shape","4cb03d1f":"test.head()","dc7dc1ea":"train_labels = tf.keras.utils.to_categorical(train['label'],10)\ntrain.drop('label',axis=1,inplace=True)\n\ntrain_images = train\/255\ntest_images = test\/255","a6d6e5d4":"model = models.Sequential()\nmodel.add(layers.Reshape((28,28,1),input_shape=(28*28,),name='reshape'))\nmodel.add(layers.Conv2D(32,(5,5),padding='same',\n                        kernel_initializer=initializers.TruncatedNormal(),\n                        use_bias=True,activation='relu',name='conv_filter1'))\nmodel.add(layers.MaxPooling2D((2,2),name='max_pooling1'))\nmodel.add(layers.Conv2D(64,(5,5),padding='same',\n                        kernel_initializer=initializers.TruncatedNormal(),\n                        use_bias=True,activation='relu',name='conv_filter2'))\nmodel.add(layers.MaxPooling2D((2,2),name='max_pooling2'))\nmodel.add(layers.Flatten(name='flatten'))\nmodel.add(layers.Dense(1024,activation='relu',\n                      kernel_initializer=initializers.TruncatedNormal(),\n                      name='hidden'))\nmodel.add(layers.Dropout(rate=0.5,name='dropout'))\nmodel.add(layers.Dense(10,activation='softmax',name='softmax'))\n\nmodel.summary()","c833a578":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\nhistroy = model.fit(train_images,train_labels,batch_size=128,epochs=10)","55f771fb":"pd.DataFrame({'acc':histroy.history['acc'],'loss':histroy.history['loss']}).plot()","bf160208":"predict_value = model.predict(test_images)\npredict_index = np.argmax(predict_value,axis=1)\n\nsample_submission['Label'] = predict_index\nsample_submission.to_csv('submission.csv',index=False)","2f9d83e3":"# Import Libraries","4c2d9d13":"# Construct Learning Model","6660fec7":"# Set Seeds","5b665943":"# Predict With Test Images and Submit","c554a789":"# Confirm Data \nCheck the initial parts and the shapes of the datasets.","091ef4ef":"Check the fluctuation of accuracy and loss function.","f79a9c23":"# Prepare For Using CNN\nSeparate images and labels, and normalize pixel value of images.","b63ce794":"# Load Sample Submission and MNIST","82b712ad":"# Check Files ","50ad1f28":"# Model Compile and Fit\nSet optimization algorithm and loss function, and run the learning process.","c4e2702f":"'Train' has 42000 rows and 785 columns.\n\nIt means there are 42000 images and each of them has 784 pixel information(1 column is 'Label').","45b9d6a4":"'Test' has 28000 rows and 784 columns."}}