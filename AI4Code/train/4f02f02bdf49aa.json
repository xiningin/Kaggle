{"cell_type":{"cdbd7504":"code","cae7ee07":"code","260810fb":"code","76ff612f":"code","8af49fb5":"code","8e8f99d0":"code","bb5ecdb0":"code","50a72bb7":"code","031f2cbb":"code","ce25fca7":"code","56e77c83":"code","78a4ec3b":"code","6781196e":"code","f753544f":"code","76bc99d0":"code","f83d0272":"code","80c29dc1":"code","9f35aef9":"code","73fdfc31":"code","99e938e1":"code","5aa9b91e":"code","1ee0d44e":"code","6452dd08":"code","a8588fdd":"code","7d429fd5":"code","9656b2e1":"code","ff40e51f":"code","f0ccabf1":"code","bf580044":"code","7162d193":"code","6a81a3e1":"code","9323bec6":"code","f145861c":"code","3639e7ad":"code","7a00dbd1":"code","7cff759b":"code","0b1c7d68":"code","33bc4413":"code","6bd673a3":"code","1656060d":"code","66418acc":"code","4443313d":"code","91a5472f":"code","286608be":"code","0ab722fd":"code","f4eda11c":"code","af8886d8":"code","ff282004":"code","9e4dacaa":"code","e84a31bf":"code","6c5d9e72":"code","52869f71":"code","c05c102e":"code","6c5d70c2":"code","56aa350c":"markdown","016b6212":"markdown","50e75cc2":"markdown","f1fc2a3f":"markdown","469be5a3":"markdown","d4306eee":"markdown","74468fc8":"markdown","c0cf822b":"markdown","74a3760a":"markdown","520650a5":"markdown","84d9bef4":"markdown","43247540":"markdown","53c78cd1":"markdown","a3c2553a":"markdown","de3f4036":"markdown","696d2901":"markdown","af11fb6b":"markdown","137168e4":"markdown","a7d414d1":"markdown","6902d9b8":"markdown","1e76b42e":"markdown","43c49070":"markdown","90bb15e2":"markdown","794864bb":"markdown","35e7d950":"markdown","e6b1eb3c":"markdown","6cc189ff":"markdown","2566aecb":"markdown","252ea641":"markdown","85b73553":"markdown","12f2dd8b":"markdown","0cdf7997":"markdown","3e3eb41c":"markdown","556f57ac":"markdown","f3bf174d":"markdown","a3def9e7":"markdown"},"source":{"cdbd7504":"# Data Processing\nimport numpy as np \nimport pandas as pd \n\n# Data Visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style='whitegrid')\n\n# Modeling\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import RandomizedSearchCV","cae7ee07":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","260810fb":"df_train","76ff612f":"df_test","8af49fb5":"b = sns.countplot(x='Survived', data=df_train)\nb.set_title(\"Survived Distribution\");","8e8f99d0":"b = sns.countplot(x='Pclass', data=df_train)\nb.set_title(\"Pclass Distribution\");","bb5ecdb0":"pd.crosstab(df_train['Survived'], df_train['Pclass']).plot(kind=\"bar\", figsize=(10,6))\n\nplt.title(\"Survived distribution for Pclass\")\nplt.xlabel(\"0 = Not Survived, 1 = Survived\")\nplt.ylabel(\"Count\")\nplt.legend([\"Pclass 1\", \"Pclass 2\", \"Pclass 3\"])\nplt.xticks(rotation=0);","50a72bb7":"b = sns.countplot(x='Sex', data=df_train)\nb.set_title(\"Sex Distribution\");","031f2cbb":"pd.crosstab(df_train['Survived'], df_train['Sex']).plot(kind=\"bar\", figsize=(10,6))\n\nplt.title(\"Survived distribution for Sex\")\nplt.xlabel(\"0 = Not Survived, 1 = Survived\")\nplt.ylabel(\"Count\")\nplt.legend([\"male\", \"female\"])\nplt.xticks(rotation=0);","ce25fca7":"b = sns.distplot(df_train['Age'])\nb.set_title(\"Age Distribution\");","56e77c83":"b = sns.boxplot(y = 'Age', data = df_train)\nb.set_title(\"Age Distribution\");","78a4ec3b":"b = sns.boxplot(y='Age', x='Survived', data=df_train);\nb.set_title(\"Age Distribution for Survived\");","6781196e":"b = sns.countplot(x='SibSp', data=df_train)\nb.set_title(\"SibSp Distribution\");","f753544f":"pd.crosstab(df_train['Survived'], df_train['SibSp']).value_counts()","76bc99d0":"df_train['Parch'].value_counts()","f83d0272":"b = sns.countplot(x='Parch', data=df_train)\nb.set_title(\"Parch Distribution\");","80c29dc1":"pd.crosstab(df_train['Survived'], df_train['Parch']).value_counts()","9f35aef9":"b = sns.distplot(df_train['Fare'])\nb.set_title(\"Fare Distribution\");","73fdfc31":"b = sns.boxplot(y = 'Fare', data = df_train)\nb.set_title(\"Fare Distribution\");","99e938e1":"b = sns.boxplot(y='Fare', x='Survived', data=df_train);\nb.set_title(\"Fare Distribution for Survived\");","5aa9b91e":"df_train['Embarked'].value_counts()","1ee0d44e":"b = sns.countplot(x='Embarked', data=df_train)\nb.set_title(\"Parch Distribution\");","6452dd08":"pd.crosstab(df_train['Survived'], df_train['Embarked']).plot(kind=\"bar\", figsize=(10,6))\n\nplt.title(\"Survived distribution for Embarked\")\nplt.xlabel(\"0 = Not Survived, 1 = Survived\")\nplt.ylabel(\"Count\")\nplt.legend([\"C\", \"Q\", \"S\"])\nplt.xticks(rotation=0);","a8588fdd":"df_train.isna().sum()","7d429fd5":"df_test.isna().sum()","9656b2e1":"df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\ndf_test['Age'] = df_test['Age'].fillna(df_test['Age'].mean())","ff40e51f":"df_train['Cabin'] = df_train['Cabin'].fillna(\"Missing\")\ndf_test['Cabin'] = df_test['Cabin'].fillna(\"Missing\")","f0ccabf1":"df_train = df_train.dropna()","bf580044":"df_test['Fare'] = df_test['Fare'].fillna(df_test['Fare'].mean())","7162d193":"df_train.isna().sum()","6a81a3e1":"df_test.isna().sum()","9323bec6":"df_train.shape","f145861c":"df_test.shape","3639e7ad":"df_train.head()","7a00dbd1":"df_test.head()","7cff759b":"df_train = df_train.drop(columns=['Name'], axis=1)\ndf_test = df_test.drop(columns=['Name'], axis=1)","0b1c7d68":"sex_mapping = {\n    'male': 0,\n    'female': 1\n}\n\ndf_train.loc[:, \"Sex\"] = df_train['Sex'].map(sex_mapping)\ndf_test.loc[:, \"Sex\"] = df_test['Sex'].map(sex_mapping)","33bc4413":"df_train = df_train.drop(columns=['Ticket'], axis=1)\ndf_test = df_test.drop(columns=['Ticket'], axis=1)","6bd673a3":"df_train = df_train.drop(columns=['Cabin'], axis=1)\ndf_test = df_test.drop(columns=['Cabin'], axis=1)","1656060d":"df_train.head()","66418acc":"df_test.head()","4443313d":"df_test['Embarked'].value_counts()","91a5472f":"df_train = pd.get_dummies(df_train, prefix_sep=\"__\",\n                              columns=['Embarked'])\ndf_test = pd.get_dummies(df_test, prefix_sep=\"__\",\n                              columns=['Embarked'])","286608be":"df_train.head()","0ab722fd":"df_test.head()","f4eda11c":"# Everything except target variable\nX = df_train.drop(\"Survived\", axis=1)\n\n# Target variable\ny = df_train['Survived'].values","af8886d8":"# Random seed for reproducibility\nnp.random.seed(42)\n\n# Split into train & test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) ","ff282004":"# Put models in a dictionary\nmodels = {\"KNN\": KNeighborsClassifier(),\n          \"Logistic Regression\": LogisticRegression(max_iter=10000), \n          \"Random Forest\": RandomForestClassifier(),\n          \"SVC\" : SVC(probability=True),\n          \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n          \"AdaBoostClassifier\" : AdaBoostClassifier(),\n          \"GradientBoostingClassifier\" : GradientBoostingClassifier(),\n          \"GaussianNB\" : GaussianNB(),\n          \"LinearDiscriminantAnalysis\" : LinearDiscriminantAnalysis(),\n          \"QuadraticDiscriminantAnalysis\" : QuadraticDiscriminantAnalysis()}\n\n# Create function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n    \"\"\"\n    Fits and evaluates given machine learning models.\n    models : a dict of different Scikit-Learn machine learning models\n    X_train : training data\n    X_test : testing data\n    y_train : labels assosciated with training data\n    y_test : labels assosciated with test data\n    \"\"\"\n    # Random seed for reproducible results\n    np.random.seed(42)\n    # Make a list to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(X_train, y_train)\n        # Predicting target values\n        y_pred = model.predict(X_test)\n        # Evaluate the model and append its score to model_scores\n        #model_scores[name] = model.score(X_test, y_test)\n        model_scores[name] = roc_auc_score(y_test, y_pred)\n    return model_scores","9e4dacaa":"model_scores = fit_and_score(models=models,\n                             X_train=X_train,\n                             X_test=X_test,\n                             y_train=y_train,\n                             y_test=y_test)\nmodel_scores","e84a31bf":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)","6c5d9e72":"y_pred = gbc.predict(df_test)","52869f71":"y_pred","c05c102e":"sub = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsub.head()","6c5d70c2":"sub['Survived'] = y_pred\nsub.to_csv(\"results_titanic.csv\", index=False)\nsub.head()","56aa350c":"Let's get rid of `Cabin` for now:","016b6212":"<h1 style=\"text-align:center\">My Titanic Approach (Top 5%)<\/h1>","50e75cc2":"# Modeling","f1fc2a3f":"<div style=\"text-align:center;\"><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/6e\/St%C3%B6wer_Titanic.jpg\" \/><\/div>","469be5a3":"**Where do we have NaN values?**","d4306eee":"Let's map `Sex` to 0 for `male` and 1 for `female`:","74468fc8":"### Target Value: Survived","c0cf822b":"**Let's replace the NaN values in `Age` with the mean value.**","74a3760a":"### Pclass","520650a5":"**Let's check if there are any NaN values left.**","84d9bef4":"**Let's replace the NaN value in `Fare` in `df_test` with the mean value.**","43247540":"We can see that the majority of female passenger survived and the majority of male passenger died.","53c78cd1":"**Context:** \n> The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\n**About the Data:**\n\n<ul>\n    <li>survival:\tSurvival<\/li>\n        <ul>\n            <li>0 = No<\/li>\n            <li>1 = Yes <\/li>\n        <\/ul>\n    <li>pclass: A proxy for socio-economic status (SES)<\/li>\n        <ul>\n            <li>1 = 1st (Upper)<\/li>\n            <li>2 = 2nd (Middle)<\/li>\n            <li>3 = 3rd (Lower)<\/li>\n        <\/ul>\n    <li>sex: Sex<\/li>\n    <li>age: Age in years. Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<\/li>\n    <li>sibsp: # of siblings \/ spouses aboard the Titanic. The dataset defines family relations in this way:<\/li>\n        <ul>\n            <li>Sibling = brother, sister, stepbrother, stepsister<\/li>\n            <li>Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)<\/li>\n        <\/ul>\n    <li>parch: # of parents \/ children aboard the Titanic. The dataset defines family relations in this way:<\/li>\n        <ul>\n            <li>Parent = mother, father<\/li>\n            <li>Child = daughter, son, stepdaughter, stepson<\/li>\n            <li>Some children travelled only with a nanny, therefore parch=0 for them.<\/li>\n        <\/ul>\n    <li>ticket: Ticket number<\/li>\n    <li>fare:\tPassenger fare<\/li>\n    <li>cabin: Cabin number<\/li>\n    <li>embarked: Port of Embarkation<\/li>\n        <ul>\n            <li>C = Cherbourg<\/li>\n            <li>Q = Queenstown<\/li>\n            <li>S = Southampton<\/li>\n        <\/ul>\n<\/ul> \n","a3c2553a":"# Exploring the data","de3f4036":"Let's use one-hot-encoding for `Embarked` since those are nominal variables:","696d2901":"Here, we can see that more of Pclass 1 survived than died and a lot more passengers of Pclass 3 died than survived. Pclass 2 is distributed relatively even.","af11fb6b":"**Let's replace the NaN values in `Cabin` with \"Missing\".**","137168e4":"### Parch","a7d414d1":"### Fare","6902d9b8":"# Overview","1e76b42e":"Let's get rid of `Ticket` for now:","43c49070":"Let's get rid of the `Name` column for now:","90bb15e2":"**It looks like everything worked!**","794864bb":"### SibSp","35e7d950":"## Handling NaN values","e6b1eb3c":"# Cleaning the data","6cc189ff":"# Getting the data","2566aecb":"`GradientBoostingClassifier` has the best score.","252ea641":"**Let's get rid of columns with NaN in `Embarked`in `df_train`.**","85b73553":"### Sex","12f2dd8b":"Let's check if everything worked:","0cdf7997":"# Predict for df_test","3e3eb41c":"### Embarked","556f57ac":"### Age","f3bf174d":"**Work in Progress**","a3def9e7":"# Imports"}}