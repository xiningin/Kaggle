{"cell_type":{"31226de2":"code","ba17d96b":"code","695d5b78":"code","12771649":"code","7b619557":"code","ae8d70c1":"code","e3378dc3":"code","480b2df6":"code","1531267f":"code","89cc6c00":"code","2f0101f9":"code","6067045a":"code","11a17776":"code","34e7e701":"code","2bf00cbd":"code","b1fdd047":"code","e92568ca":"code","17e20f01":"code","5ad19220":"code","9733e419":"code","825f14ec":"code","eede8933":"code","5e45b42a":"code","1bb72a65":"code","9a35e626":"code","23f7620d":"code","84f3cbea":"code","df7a2170":"code","c48ace58":"code","85ee6af9":"code","2c85c14e":"code","5be07a96":"markdown","98a225de":"markdown","5f75138b":"markdown","cb2dd34d":"markdown","b0e22df2":"markdown","a9c7c361":"markdown","a126e96b":"markdown","76c25704":"markdown","fd5c0155":"markdown","9fd53f5d":"markdown","d4239aa5":"markdown","279a1315":"markdown","047cc35f":"markdown","ada1e519":"markdown","74266f43":"markdown","13f9c0da":"markdown","2dd284ef":"markdown"},"source":{"31226de2":"import pandas as pd\nimport os","ba17d96b":"text_files = os.listdir('\/kaggle\/input\/feedback-prize-2021\/train')","695d5b78":"len(text_files)","12771649":"train_df = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv')","7b619557":"train_df.info()","ae8d70c1":"train_df.describe()","e3378dc3":"train_df.head(15)","480b2df6":"def print_text(text_id):\n    with open(f'\/kaggle\/input\/feedback-prize-2021\/train\/{text_id}.txt') as f:\n        lines = f.readlines()\n    print(''.join(lines))\n    \nprint_text('423A1CA112E2')","1531267f":"from termcolor import colored\ndef color_text(text_id, train_df, color_scheme = None):\n    if not color_scheme:\n        color_scheme = {\n        'Lead': 'green',\n        'Position': 'red',\n        'Claim': 'blue',\n        'Counterclaim': 'magenta',\n        'Rebuttal': 'yellow',\n        'Evidence': 'cyan',\n        'Concluding Statement': 'grey'\n    } \n    with open(f'\/kaggle\/input\/feedback-prize-2021\/train\/{text_id}.txt') as f:\n        lines = f.readlines()\n    text = ''.join(lines)\n    \n    annot_df = train_df[train_df.id == text_id]\n    blocks = [(int(row['discourse_start']),int(row['discourse_end']), color_scheme[row['discourse_type']]) for k, row in annot_df.iterrows()]\n    blocks.sort()\n    i = 0\n    last_symbol = -1\n    while i < len(blocks):\n        if blocks[i][0] > last_symbol + 1:\n            blocks.insert(i, (last_symbol+1, blocks[i][0] - 1, None))\n        last_symbol = blocks[i][1]\n        i += 1\n    if last_symbol < len(text):\n        blocks.append((last_symbol+1, len(text) - 1, None))\n\n    colored_text = ''.join([colored(text[x[0]:x[1]+1], x[2]) for x in blocks])\n    return colored_text\n    \nprint(color_text('423A1CA112E2', train_df))","89cc6c00":"print(color_text('A8445CABFECE', train_df))","2f0101f9":"print(color_text('6B4F7A0165B9', train_df))","6067045a":"# let's load all textst\n\ntexts = []\nfor file in text_files:\n    with open(f'\/kaggle\/input\/feedback-prize-2021\/train\/{file}') as f:\n        lines = f.readlines()\n    texts.append({'id': file[:-4], 'text': ''.join(lines)})\ntexts_df = pd.DataFrame(texts)","11a17776":"texts_df.head()","34e7e701":"texts_df['len'] = texts_df['text'].apply(len)","2bf00cbd":"texts_df['len'].hist(bins = 50, figsize = (20,10))\nprint(texts_df['len'].min(), texts_df['len'].max())","b1fdd047":"texts_df['words_num'] = texts_df['text'].apply(lambda x: len(x.split(' ')))","e92568ca":"texts_df['words_num'].hist(bins = 100, figsize = (20,10))\nprint(texts_df['words_num'].min(), texts_df['words_num'].max())","17e20f01":"train_df['discourse_type'].value_counts()","5ad19220":"train_df['discourse_words_num'] = train_df['discourse_text'].apply(lambda x: len(x.split(' ')))","9733e419":"avg_len_dict = {}\nfor d in train_df['discourse_type'].unique():\n    temp_df = train_df[train_df['discourse_type'] == d]\n    print(d, temp_df['discourse_words_num'].min(), temp_df['discourse_words_num'].mean(), temp_df['discourse_words_num'].max())\n    avg_len_dict[d] = int(temp_df['discourse_words_num'].mean())","825f14ec":"train_df['first_word'] = train_df['discourse_text'].apply(lambda x: x.split(' ')[0].lower())","eede8933":"top_first_words = {}\nfor d in train_df['discourse_type'].unique():\n    temp_df = train_df[train_df['discourse_type'] == d]\n    print(d)\n    display(temp_df['first_word'].value_counts().head(10))\n    top_first_words[d] = temp_df['first_word'].value_counts().head(10).keys()","5e45b42a":"stop_words = {'the', 'i', 'in', '', 'it', 'this', 'if', 'they', 'to'}\n\nfor k, v in top_first_words.items():\n    top_first_words[k] = set([x for x in v if x not in stop_words])\ntop_first_words","1bb72a65":"top_first_words = {\n    'Claim': {'another', 'students'},\n     'Evidence': {},\n     'Position': {'there'},\n     'Concluding Statement': {'so'},\n     'Lead': {'driverless', 'imagine'},\n     'Counterclaim': {'although','but','however,'},\n     'Rebuttal': {'but,', 'while'}\n    }","9a35e626":"avg_len_dict","23f7620d":"def predict(text_id, path = '\/kaggle\/input\/feedback-prize-2021\/train\/', top_first_words=top_first_words, avg_len_dict=avg_len_dict):\n    with open(f'{path}{text_id}.txt') as f:\n        lines = f.readlines()\n    text = ''.join(lines)\n    words = text.split(' ')\n    preds = []\n    for i,word in enumerate(words):\n        for k,v in top_first_words.items():\n            if word in v:\n                preds.append({'id': text_id, 'class': k, 'predictionstring': ' '.join([str(x) for x in range(i,i+avg_len_dict[k])])})\n    return preds","84f3cbea":"predict('423A1CA112E2')","df7a2170":"test_files = os.listdir('\/kaggle\/input\/feedback-prize-2021\/test')","c48ace58":"sub = []\nfor file in test_files:\n    sub += predict(file[:-4], '\/kaggle\/input\/feedback-prize-2021\/test\/')","85ee6af9":"sub_df = pd.DataFrame(sub)\nsub_df","2c85c14e":"sub_df.to_csv('submission.csv', index = False)","5be07a96":"If we ignore some stop words we can see that some words are very popular for particular target types.\nLet's use this data for our baseline.","98a225de":"This notebook contains a simple initial data analysis for the [Feedback Prize - Evaluating Student Writing](https:\/\/www.kaggle.com\/c\/feedback-prize-2021) competition.","5f75138b":"# Data overview","cb2dd34d":"We obviously have too many false positives but it is just a dummy baseline, so let's make some predictions using it.","b0e22df2":"# Texts overview","a9c7c361":"Texts have lenghts from 691 to 18k symbols with most of them around 1-3k symbols.","a126e96b":"I am introducing a straightforward rule-based baseline (it most probably can be beaten by transformers fit\/predict).\nWe compute the average length discourse element for each target class.\nWe create lists of the most popular first words for each target class.\nIf we see one of these words in the text, we predict that the following avg_len words are discourse element with corresponding classes.\n","76c25704":"Side note: you can see that one line starts with ',' in the very beginning. It may signify some data quality issues (but I am not sure). We need to be very careful with data cleaning and words <-> tokens transformation to get results aligned with annotation.","fd5c0155":"Number of words in each text is around 500-1000 on average, with some outliers.","9fd53f5d":"`train.csv` contains 10 rows with annotation for this file. Each row corresponds to one discourse element and contains the following information (source: https:\/\/www.kaggle.com\/c\/feedback-prize-2021\/data):\n\n* id - ID code for essay response\n* discourse_id - ID code for discourse element\n* discourse_start - character position where discourse element begins in the essay response\n* discourse_end - character position where discourse element ends in the essay response\n* discourse_text - text of discourse element\n* discourse_type - classification of discourse element\n* discourse_type_num - enumerated class label of discourse element\n* predictionstring - the word indices of the training sample, as required for predictions\n\nAs you can see we have both symbol and words level annotation (we can use any of them in model but need the word level one for submission).","d4239aa5":"Let's look at the first text and its annotation.","279a1315":"Differen target classes are anequally distributed, claims and evidences are most popular ones. ","047cc35f":"Let's just manually remove duplicates and clean up is a bit (giving priority to the more popular classes):","ada1e519":"# Baseline","74266f43":"We can make annotations more clear if we print texts using different colors.","13f9c0da":"Training data consists of 16k texts and 144k lines of annotations (~9 discourses per text). Annotations are presented in the `train.csv` file. Let's look at its structure.","2dd284ef":"# Target analysis"}}