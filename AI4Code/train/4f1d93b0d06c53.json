{"cell_type":{"d9c97ad6":"code","df1748e5":"code","5a517235":"code","c6fa1652":"code","2f0c479a":"code","057a23d4":"code","9e3a4337":"code","0229fa7d":"code","f8721c6d":"code","72505480":"code","90f85cf5":"code","90e1f311":"code","2b54f490":"code","6ebd6498":"code","cdd0ddea":"code","f6a9a696":"code","734b3226":"code","fcba74d2":"code","10e745ac":"code","c6a2b622":"code","c9d9a2d5":"code","3f4bdb2c":"code","0810439f":"code","0752fc13":"code","3dd54e0f":"code","c5159461":"code","d104da66":"code","08d484a1":"code","d89bf680":"code","3812acd8":"code","5dbdc1c6":"code","d88ac59b":"code","1f01f281":"code","55aba7b3":"code","aff26514":"markdown","d77ddc63":"markdown","093d7878":"markdown","f86e0b31":"markdown","5041bec0":"markdown","72a4ee56":"markdown","b628425e":"markdown","2f728a93":"markdown","dfba51aa":"markdown","9f655af0":"markdown","ea2b830b":"markdown","a040a49a":"markdown","e9881322":"markdown","973bc330":"markdown","eb73da85":"markdown","e2b78df8":"markdown","d9e4d181":"markdown","8c90e200":"markdown"},"source":{"d9c97ad6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","df1748e5":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.under_sampling import NearMiss\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, KFold\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nimport random\nfrom sklearn.svm import SVC\nimport sklearn.metrics as sk\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\n%matplotlib inline","5a517235":"df = pd.read_csv(\"\/kaggle\/input\/bank-marketing\/bank-additional-full.csv\", sep = \";\")","c6fa1652":"# Converting categorical into boolean using get_dummies \n# Getting the predicted values in terms of 0 and 1\nY = (df['y'] == 'yes')*1","2f0c479a":"df.shape","057a23d4":"df.columns","9e3a4337":"df.describe()","0229fa7d":"df.info()","f8721c6d":"sns.distplot(df['age'], hist = True, color = \"#07247D\", hist_kws = {'edgecolor':'black'})","72505480":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\n\n# Familienstand\nsns.countplot(x = \"marital\", data = df, ax = ax1)\nax1.set_title(\"marital status distribution\", fontsize = 13)\nax1.set_xlabel(\"Marital Status\", fontsize = 12)\nax1.set_ylabel(\"Count\", fontsize = 12)\n\n# Bildungsstand\nsns.countplot(x = \"education\", data = df, ax = ax2)\nax2.set_title(\"Education distribution\", fontsize = 13)\nax2.set_xlabel(\"Education level\", fontsize = 12)\nax2.set_ylabel(\"Count\", fontsize = 12)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation = 70)","90f85cf5":"# Verteilung der Jobs\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,5)\nsns.countplot(x = \"job\", data = df)\nax.set_xlabel('Job', fontsize = 12)\nax.set_ylabel('Count', fontsize = 12)\nax.set_title(\"Job Count Distribution\", fontsize = 13)","90e1f311":"# 1. Housing\nfig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\nsns.countplot(x = \"housing\", data = df, ax = ax1, order = ['yes', 'no', 'unknown'])\nax1.set_title(\"Housing Loan distribution\")\nax1.set_xlabel(\"Housing Loan\")\nax1.set_ylabel(\"Count\")\n\n# 2. Pers\u00f6nlich\nsns.countplot(x = \"loan\", data = df, ax = ax2, order = ['yes', 'no', 'unknown'])\nax2.set_title(\"Personal Loan Distribution\")\nax2.set_xlabel(\"Personal Loan\")\nax2.set_ylabel(\"Count\")","2b54f490":"# 1. Kreditschulden\nprint(\"Anzahl der Personen mit Kreditschulden: \", df[df['default'] == 'yes']['default'].count())\nprint(\"Anzahl der Personen ohne Kreditschulden: \", df[df['default'] == 'no']['default'].count())\nprint(\"ANzahl der Personen mit unbekannten Kreditschulden: \", df[df['default'] == 'unknown']['default'].count())\n\n\n\n","6ebd6498":"# 2. Wohnbaudarlehen\nprint(\"Anzahl der Personen mit Wohnbaudarlehen: \", df[df['housing'] == 'yes']['housing'].count())\nprint(\"Anzahl der Personen ohne Wohnbaudarlehen: \", df[df['housing'] == 'no']['housing'].count())\nprint(\"Anzahl der Personen mit unbekanntem Wohnbaudarlehen: \", df[df['housing'] == 'unknown']['housing'].count())","cdd0ddea":"# 3. Privatkredit\nprint(\"Anzahl der Personen mit Privatkredit: \", df[df['loan'] == 'yes']['loan'].count())\nprint(\"Anzahl der Personen ohne Privatkredit: \", df[df['loan'] == 'no']['loan'].count())\nprint(\"Anzahl der Personen mit unbekanntem Privatkredit: \", df[df['loan'] == 'unknown']['loan'].count())","f6a9a696":"min_duration = df['duration'].min()\nmax_duration = df['duration'].max()\nmedian_duration = df['duration'].mean()\nstandard_dev_duration = df[\"duration\"].std()\n\nprint(\"Min call duration: \", min_duration)\nprint(\"Max call duration: \", max_duration)\nprint(\"Median call duration: \", round(median_duration, 2))\nprint(\"Standard diveation in call duration: \", round(standard_dev_duration, 2))","734b3226":"# Visualisation in Bezug auf \"Kontakt, Monat, Tag\"\nfig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\n\n\n\nsns.countplot(x = 'contact', data = df, ax = ax1)\nax1.set_xlabel(\"Contact Method\")\nax1.set_ylabel(\"Count\")\nax1.set_title(\"Count of Contact Methods\")\n\nsns.countplot(df['day_of_week'], ax = ax2)\nax2.set_xlabel(\"Days of the week\")\nax2.set_ylabel(\"Count\")\nax2.set_title(\"Count of Calls made on Days of the week\")","fcba74d2":"# For Months\nfig, ax = plt.subplots(figsize = (15, 5))\nsns.countplot(x = 'month', data = df, order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\nax.set_xlabel(\"Months\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Count of contacts made in each month\")","10e745ac":"fig, ax = plt.subplots(figsize = (15, 5))\nsns.boxplot(x = \"job\", y = \"duration\", data = df, orient = 'v')\nax.set_xlabel(\"Jobs\")\nax.set_ylabel(\"Duration\")\nax.set_yscale(\"log\")\nax.set_title(\"log(Duration) vs Jobs\")","c6a2b622":"fig, ax = plt.subplots(figsize = (15, 5))\nsns.boxplot(x = \"education\", y = \"duration\", data = df, orient = 'v')\nax.set_xlabel(\"Education\")\nax.set_ylabel(\"Duration\")\nax.set_yscale(\"log\")\nax.set_title(\"log(Duration) vs Education\")","c9d9a2d5":"fig, ax = plt.subplots(figsize = (15, 5))\nsns.boxplot(x = \"education\", y = \"duration\", data = df, orient = 'v')\nax.set_xlabel(\"Education\")\nax.set_ylabel(\"Duration\")\nax.set_yscale(\"log\")\nax.set_title(\"log(Duration) vs Education\")","3f4bdb2c":"#Removing non-relevant variables\ndf1=df.drop(columns=['day_of_week','month','contact','poutcome','pdays'],axis=1)\ndf1","0810439f":"#Replacing all the binary variables to 0 and 1\ndf1.y.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.default.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.housing.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.loan.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1","0752fc13":"#creating Dummies for categorical variables\ndf2 = pd.get_dummies(df1)\ndf2.head()","3dd54e0f":"#Removing extra dummy variables & checking descriptive stats\ndf3=df2.drop(columns=['job_unknown','marital_divorced','education_unknown',],axis=1)\ndf3.describe().T","c5159461":"#Correlation plot\nplt.figure(figsize=(14,8))\ndf3.corr()['y'].sort_values(ascending = False).plot(kind='bar')","d104da66":"#Creating binary classification target variable\ndf_target=df3[['y']].values\ndf_features=df3.drop(columns=['y'],axis=1).values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.3, random_state = 0)","08d484a1":"sc = StandardScaler()\nx1_train = sc.fit_transform(x1_train)\nx1_test = sc.transform(x1_test)","d89bf680":"#Entropy Model\neclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\neclassifier.fit(x1_train, y1_train)\n\n#Applying k-Fold Cross Validation\naccuracies = cross_val_score(estimator = eclassifier, X = x1_train, y = y1_train, cv = 5)\nmean_dt_e=accuracies.mean()\nstd_dt_e=accuracies.std()\n\n#After using 5 fold cross validation\nprint('After 5 fold cross validation:')\nprint('Mean of Accuracies: ',mean_dt_e*100,end='\\n')\nprint('Standard deviation of Accuracies',std_dt_e*100,end='\\n')\n\n#predict y\ny_pred = eclassifier.predict(x1_test)\n\n#Confusion Matrix\nprint('Test Output:')\nprint('Confusion Matrix:')\nprint(sk.confusion_matrix(y1_test, y_pred))\nprint('Classification Report:')\nprint(sk.classification_report(y1_test, y_pred))\nprint('Accuracy: ',sk.accuracy_score(y1_test,y_pred))","3812acd8":"#Pruning the better tree - Entropy Tree\nparameters = [{'criterion': ['entropy'],'min_samples_leaf':[5,10,20,50,100],'max_depth':[5,10,20,50,100]}] \ngrid_search = GridSearchCV(estimator = eclassifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search = grid_search.fit(x1_train, y1_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\n\nprint('Accuracy: ',best_accuracy,end='\\n')\nprint('Best Parameters: ',best_parameters,end='\\n')","5dbdc1c6":"#Linear SVM\nprint('Linear Model',end='\\n')\nlsvclassifier = SVC(kernel='linear')\nlsvclassifier.fit(x1_train, y1_train.ravel())\n\n#Applying k-Fold Cross Validation\naccuracies = cross_val_score(estimator = lsvclassifier, X = x1_train, y = y1_train.ravel(), cv = 5)\nmean_svm_linear=accuracies.mean()\nstd_svm_linear=accuracies.std()\n\n#After using 5 fold cross validation\nprint('After 5 fold cross validation:')\nprint('Mean of Accuracies: ',mean_svm_linear*100,end='\\n')\nprint('Standard deviation of Accuracies',std_svm_linear*100,end='\\n')\n\n#Predict SVM\ny_predl = lsvclassifier.predict(x1_test)\n\n#Confusion Matrix\nprint('Test Output:')\nprint('Confusion Matrix:')\nprint(sk.confusion_matrix(y1_test,y_predl))\nprint('Classification Report:')\nprint(sk.classification_report(y1_test,y_predl))\nprint('Accuracy: ',sk.accuracy_score(y1_test, y_predl, normalize=True, sample_weight=None))","d88ac59b":"#Polynomial SVM\nprint('Polynomial Model',end='\\n')\npsvclassifier = SVC(kernel='poly')\npsvclassifier.fit(x1_train, y1_train.ravel())\n\n#Applying k-Fold Cross Validation\naccuracies = cross_val_score(estimator = psvclassifier, X = x1_train, y = y1_train.ravel(), cv = 5)\nmean_svm_poly=accuracies.mean()\nstd_svm_poly=accuracies.std()\n\n#After using 5 fold cross validation\nprint('After 5 fold cross validation:')\nprint('Mean of Accuracies: ',mean_svm_poly*100,end='\\n')\nprint('Standard deviation of Accuracies',std_svm_poly*100,end='\\n')\n\n#Predict SVM\ny_predp = psvclassifier.predict(x1_test)\n\n#Confusion Matrix\nprint('Test Output:')\nprint('Confusion Matrix:')\nprint(sk.confusion_matrix(y1_test,y_predp))\nprint('Classification Report:')\nprint(sk.classification_report(y1_test,y_predp))\nprint('Accuracy: ',sk.accuracy_score(y1_test, y_predp, normalize=True, sample_weight=None))","1f01f281":"#RBF SVM\nprint('RBF Model',end='\\n')\nrsvclassifier = SVC(kernel='rbf')\nrsvclassifier.fit(x1_train, y1_train.ravel())\n\n#Applying k-Fold Cross Validation\naccuracies = cross_val_score(estimator = rsvclassifier, X = x1_train, y = y1_train.ravel(), cv = 5)\nmean_svm_rbf=accuracies.mean()\nstd_svm_rbf=accuracies.std()\n\n#After using 5 fold cross validation\nprint('After 5 fold cross validation:')\nprint('Mean of Accuracies: ',mean_svm_rbf*100,end='\\n')\nprint('Standard deviation of Accuracies',std_svm_rbf*100,end='\\n')\n\n#Predict SVM\ny_predr = rsvclassifier.predict(x1_test)\n\n#Confusion Matrix\nprint('Test Output:')\nprint('Confusion Matrix:')\nprint(sk.confusion_matrix(y1_test,y_predr))\nprint('Classification Report:')\nprint(sk.classification_report(y1_test,y_predr))\nprint('Accuracy: ',sk.accuracy_score(y1_test, y_predr, normalize=True, sample_weight=None))","55aba7b3":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","aff26514":"Mittelwert, Standardabweichung, Minimum, Maximum f\u00fcr die Laufzeit","d77ddc63":"**Visualisierung des Datensatzes**","093d7878":"Ausgabe von Zeilen und Spalten","f86e0b31":"**Kreditverteilung**\n1. Kredit f\u00fcr das Wohnen\n2. Pers\u00f6nliche Kredite","5041bec0":"**Wohnbaudarlehen**","72a4ee56":"Import Library","b628425e":"**Test**","2f728a93":"# **SVM**","dfba51aa":"**Privatkredit**","9f655af0":"**Jobverteilung innerhalb des Datensatzes**","ea2b830b":"**Kreditschulden**","a040a49a":"**Alterspyramide**\n* Altersverteilung innerhalb des Datensatzes\n","e9881322":"**Studierende: Tom Neumann & Luca Paaschen**\n\n**Datensatz: Bank-Marketing**","973bc330":"Datensatz einlesen","eb73da85":"**Visualisierung Familienstand, Bildungsstand**\n1. Grafik: Familienstand der Personen innerhalb des Datensatzes\n2. Grafik: Verteilung des Bildungsstands innerhalb des Datensatzes","e2b78df8":"Anzeige aller Spalten der Tabelle","d9e4d181":"Informationen des Dataframes mit den zugeh\u00f6rigen Datentypen\n* Integer\n* Object\n* float\n","8c90e200":"# **Decision Tree**"}}