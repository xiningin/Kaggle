{"cell_type":{"f0f6f1ba":"code","e7db92d1":"code","a1f54db6":"code","13dde1b1":"code","55c2de0e":"code","3bc70b2f":"code","58a65743":"code","454815ae":"code","74b23cb9":"code","98474c4c":"code","a4d9a41e":"code","fdb3fd9b":"code","1cdff0c0":"code","74fe12cc":"code","6dca764a":"code","69ebdd0b":"code","7a412c4b":"code","19cc9664":"code","3635757e":"code","e52a9b62":"code","b9d1d810":"code","a07b6187":"code","3c112f85":"code","fe0712f5":"code","19128b0b":"code","1806ffce":"code","3ca839df":"code","a766b4d4":"code","8aa0e624":"code","663aeda3":"code","5f1a16e4":"code","f340da72":"code","0098614c":"code","0844174f":"code","21c9c954":"code","3f230f69":"code","db1b5480":"code","feb4d175":"code","1b289efe":"code","fdefcf88":"code","811192ab":"code","0399b275":"code","0f2e8543":"code","d56c6496":"code","2ace5af8":"code","b426cd38":"code","fa8eca07":"code","d4836cde":"code","2c858c78":"code","b7e3e2f3":"code","7dbf3d5d":"code","a085f869":"code","7c652263":"code","7e0983f1":"code","428da0d1":"code","e66d2d29":"code","82b70176":"code","9563f802":"code","fc17943a":"code","e484cc48":"code","7c1462a3":"code","7ecc7407":"code","6024123f":"code","e034c772":"code","85a2c83d":"code","89838891":"code","f66f9b9f":"code","14b49047":"code","0b17a25d":"code","449962b5":"code","b23dc9bb":"code","51d1e106":"code","380688da":"code","fec6314a":"code","0bbc0ad1":"code","2dfae577":"code","f1259151":"code","2d8952a0":"code","c1b441bc":"code","71ec5472":"code","95053bf8":"code","ccb236bd":"code","e70bf70c":"code","c5c5ba5b":"markdown","f12bf7e5":"markdown","1f0cc3da":"markdown","5aa12533":"markdown","1d333fd1":"markdown","daf6ec2c":"markdown","19b0e8f1":"markdown","29bd1d1a":"markdown","fcc1dff9":"markdown","a5ebfb5a":"markdown","6775791c":"markdown","ab3e8100":"markdown","231d4497":"markdown","07a219ab":"markdown","cac3d3b3":"markdown","16f2ebe0":"markdown","3c36e2e0":"markdown","24cf9f27":"markdown","69caa296":"markdown","954407e4":"markdown","b5258737":"markdown","4488b1a2":"markdown","68a4b5f5":"markdown","571d3310":"markdown"},"source":{"f0f6f1ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7db92d1":"# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom catboost import CatBoostClassifier, Pool, cv\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","a1f54db6":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest= pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ngender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ntrain.head()","13dde1b1":"train.describe()","55c2de0e":"train.columns","3bc70b2f":"len(train)","58a65743":"missingno.matrix(train, figsize=(16,5))","454815ae":"train.isnull().sum()","74b23cb9":"train.dtypes","98474c4c":"fig = plt.figure(figsize=(10,1))   \nsns.countplot(y='Survived', data=train)","a4d9a41e":"print(train.Survived.value_counts())            # 0 not survived and 1 is survived ","fdb3fd9b":"df_bin = pd.DataFrame() # for discretised continuous variables\ndf_con = pd.DataFrame() # for continuous variables","1cdff0c0":"df_bin['Survived'] = train['Survived']\ndf_con['Survived'] = train['Survived']","74fe12cc":"df_bin.head()\n","6dca764a":"df_con.head()","69ebdd0b":"sns.distplot(train.Pclass)","7a412c4b":"df_bin['Pclass'] = train['Pclass']\ndf_con['Pclass'] = train['Pclass']","19cc9664":"df_bin.head()","3635757e":"train.Pclass.isnull().sum()        # check missing values in this feature ","e52a9b62":"train.Name.value_counts()","b9d1d810":"train.columns","a07b6187":"plt.figure(figsize = (10,1))\nsns.countplot(y=train.Sex, data=train)","3c112f85":"print(train.Sex.value_counts())","fe0712f5":"import plotly.express as px\nimport plotly.graph_objects as go\n#fig = go.Figure()\n#fig.add_trace(go.Bar(x=train.Sex, marker_color='rgb(55, 83, 109)'))\n#fig.show()\n\npx.bar(x= train.Sex)","19128b0b":"train.Sex.isnull().sum()   # check missing values ","1806ffce":"df_bin['Sex'] = train['Sex']","3ca839df":"df_bin.head()","a766b4d4":"df_bin['Sex'] = np.where(df_bin['Sex'] == 'female' ,1,0)          # make catagorical data to binary data","8aa0e624":"df_bin.head()","663aeda3":"df_con['Sex'] = train['Sex']\ndf_con.head()","5f1a16e4":"fig = plt.figure(figsize=(10, 10))\nsns.distplot(df_bin.loc[df_bin['Survived'] == 1]['Sex'], kde_kws={'label': 'Survived'});\nsns.distplot(df_bin.loc[df_bin['Survived'] == 0]['Sex'], kde_kws={'label': 'Did not survive'});","f340da72":"train.Age.isnull().sum()         # check missing values","0098614c":"# Once the Age values have been fixed up, we can add them to our sub dataframes.\n# df_bin['Age'] = pd.cut(train['Age'], 10) # bucketed\/binned into different categories\n# df_con['Age'] = train['Age'] # non-bucketed","0844174f":"# How many missing values does SibSp have?\ntrain.SibSp.isnull().sum()","21c9c954":"# What values are there?\ntrain.SibSp.value_counts()","3f230f69":"# Add SibSp to subset dataframes\ndf_bin['SibSp'] = train['SibSp']\ndf_con['SibSp'] = train['SibSp']","db1b5480":"def plot_count_dist(data, bin_df, label_column, target_column, figsize=(20, 5), use_bin_df=False):\n    \"\"\"\n    Function to plot counts and distributions of a label variable and \n    target variable side by side.\n    ::param_data:: = target dataframe\n    ::param_bin_df:: = binned dataframe for countplot\n    ::param_label_column:: = binary labelled column\n    ::param_target_column:: = column you want to view counts and distributions\n    ::param_figsize:: = size of figure (width, height)\n    ::param_use_bin_df:: = whether or not to use the bin_df, default False\n    \"\"\"\n    if use_bin_df: \n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=bin_df);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={\"label\": \"Did not survive\"});\n    else:\n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=data);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={\"label\": \"Did not survive\"});","feb4d175":"# Visualise the counts of SibSp and the distribution of the values\n# against Survived\nplot_count_dist(train, \n                bin_df=df_bin, \n                label_column='Survived', \n                target_column='SibSp', \n                figsize=(20, 10))","1b289efe":"# How many missing values does Parch have?\ntrain.Parch.isnull().sum()","fdefcf88":"# What values are there?\ntrain.Parch.value_counts()","811192ab":"# Add Parch to subset dataframes\ndf_bin['Parch'] = train['Parch']\ndf_con['Parch'] = train['Parch']","0399b275":"# Visualise the counts of Parch and the distribution of the values\n# against Survived\nplot_count_dist(train, \n                bin_df=df_bin,\n                label_column='Survived', \n                target_column='Parch', \n                figsize=(20, 10))\n","0f2e8543":"train.head()","d56c6496":"df_con.head()","2ace5af8":"# How many missing values does Ticket have?\ntrain.Ticket.isnull().sum()","b426cd38":"# How many kinds of ticket are there?\nsns.countplot(y=\"Ticket\", data=train);","fa8eca07":"# How many kinds of ticket are there?\ntrain.Ticket.value_counts()","d4836cde":"# How many unique kinds of Ticket are there?\nprint(\"There are {} unique Ticket values.\".format(len(train.Ticket.unique())))\n","2c858c78":"# How many missing values does Fare have?\ntrain.Fare.isnull().sum()","b7e3e2f3":"# How many different values of Fare are there?\nsns.countplot(y=\"Fare\", data=train);","7dbf3d5d":"# What kind of variable is Fare?\ntrain.Fare.dtype","a085f869":"# How many unique kinds of Fare are there?\nprint(\"There are {} unique Fare values.\".format(len(train.Fare.unique())))","7c652263":"# Add Fare to sub dataframes\ndf_con['Fare'] = train['Fare'] \ndf_bin['Fare'] = pd.cut(train['Fare'], bins=5) # discretised","7e0983f1":"# What do our Fare bins look like?\ndf_bin.Fare.value_counts()\n","428da0d1":"# Visualise the Fare bin counts as well as the Fare distribution versus Survived.\nplot_count_dist(data=train,\n                bin_df=df_bin,\n                label_column='Survived', \n                target_column='Fare', \n                figsize=(20,10), \n                use_bin_df=True)","e66d2d29":"train.head()","82b70176":"# feature data types\ntrain.info()","9563f802":"train.fillna(-999, inplace=True)\ntest.fillna(-999, inplace=True)","fc17943a":"X_train = train.drop('Survived', axis=1)\ny_train = train.Survived","e484cc48":"null_value_stats = train.isnull().sum(axis=0)\nnull_value_stats[null_value_stats != 0]","7c1462a3":"from catboost import CatBoostClassifier, Pool, cv\nfrom sklearn.metrics import accuracy_score","7ecc7407":"# Define the categorical features for the CatBoost model\ncat_features = np.where(X_train.dtypes != np.float)[0]\ncat_features","6024123f":"# Use the CatBoost Pool() function to pool together the training data and categorical feature labels\ntrain_pool = Pool(X_train, \n                  y_train,\n                  cat_features)","e034c772":"y_train.head()","85a2c83d":"model = CatBoostClassifier(\n    custom_loss=['Accuracy'],\n    random_seed=42,\n    logging_level='Silent', \n    iterations=5000,\n    loss_function ='Logloss'\n)","89838891":"model.fit(\n    train_pool,\n    plot=True, \n    logging_level='Verbose'  # you can uncomment this for text output\n)","f66f9b9f":"# CatBoost accuracy\ncatboost_accuracy = round(model.score(X_train, y_train) * 100, 2)\ncatboost_accuracy","14b49047":"# How long will this take?\nstart_time = time.time()\n\n# Set params for cross-validation as same as initial model\ncv_params = model.get_params()\n\n# Run the cross-validation for 10-folds \ncv_data = cv(train_pool,\n             cv_params,\n             fold_count=10,\n             plot=True)\n\n# How long did it take?\ncatboost_time = (time.time() - start_time)\n","0b17a25d":"# CatBoost CV results save into a dataframe (cv_data), let's withdraw the maximum accuracy score\ncv_catboost_accuracy = round(np.max(cv_data['test-Accuracy-mean']) * 100, 2)\ncv_catboost_accuracy","449962b5":"# Feature Importance\ndef feature_importance(model, data):\n    \"\"\"\n    Function to show which features are most important in the model.\n    ::param_model:: Which model to use?\n    ::param_data:: What data to use?\n    \"\"\"\n    imp_feature = pd.DataFrame({'imp': model.feature_importances_, 'col': data.columns})\n    imp_feature = imp_feature.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\n    _ = imp_feature.plot(kind='barh', x='col', y='imp', figsize=(20, 10))\n    return imp_feature\n    #plt.savefig('catboost_feature_importance.png') ","b23dc9bb":"# Plot the feature importance scores\nfeature_importance(model, X_train)","51d1e106":"# Print out the CatBoost model metrics\nprint(\"-CatBoost Metrics-\")\nprint(\"Accuracy: {}\".format(catboost_accuracy))\nprint(\"Accuracy cross-validation 10-Fold: {}\".format(cv_catboost_accuracy))\nprint(\"Running Time: {}\".format(datetime.timedelta(seconds=catboost_time)))","380688da":"metrics = ['Precision', 'Recall', 'F1', 'AUC']\n\neval_metrics = model.eval_metrics(train_pool,\n                                           metrics=metrics,\n                                           plot=True)\nfor metric in metrics:\n    print(str(metric)+\": {}\".format(np.mean(eval_metrics[metric])))\n\n","fec6314a":"X_train.head()","0bbc0ad1":"test.head()","2dfae577":"# Make a prediction using the CatBoost model on the wanted columns\npredictions = model.predict(test)","f1259151":"# Our predictions array is comprised of 0's and 1's (Survived or Did Not Survive)\npredictions[:50]","2d8952a0":"# Create a submisison dataframe and append the relevant columns\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = predictions # our model predictions on the test dataset\nsubmission.head()","c1b441bc":"# What does our submission have to look like?\ngender_submission.head()","71ec5472":"# Let's convert our submission dataframe 'Survived' column to ints\n#submission['Survived'] = submission['Survived'].astype(int)\n#print('Converted Survived column to integers.')","95053bf8":"# Are our test and submission dataframes the same length?\nif len(submission) == len(test):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","ccb236bd":"# Convert submisison dataframe to csv for submission to csv \n# for Kaggle submisison\nsubmission.to_csv('submission.csv', index=False)\nprint('Submission CSV is ready!')","e70bf70c":"# Check the submission csv to make sure it's in the right format\nsubmissions_check = pd.read_csv(\"submission.csv\")\nsubmissions_check.head()","c5c5ba5b":"# Feature : Sibsp\n\n- Out of a total 891 rows, that's almost one quarter of the dataset.\n\n- What would you do with these missing values?\n\n- Could replace them with the average age? What's the pro's and con's of doing this?\n\n- Or would you get rid of them completely?\n\n- We won't answer these questions in our initial EDA but this is something we would definitely revisit at a later date.","f12bf7e5":"# Feature Importance\nWhich features of the model were most important for making predictions?","1f0cc3da":"# Feature : Age \n","5aa12533":"# Submission","1d333fd1":"## Precision and Recall\n\nPrecision and recall are two metrics which are used for cases where you have have an imbalanced classification problem.\nFor example, you may have 100,000 people and only 1 of them gets a certain disease. If your model predicts that all people don't have the disease, it only misses 1 in 100,000 so its accuracy is 99.999%. But this isn't really helpful.\n\nThis is where precision an recall come in.\n\n- **Recall** = a metric which measures a models ability to find all the relevant cases in a dataset.\n\nRecall would be the models ability to find the 1 person in 100,000 who has the disease.\n\n- **Precision** = a metric which measures a models ability to correctly identify only relevant instances.\n\nIn our example, Precision would be if the model found the 1 person who had the disease, did they actually have the disease.\nCombining the precision and recall, gives an **F1 score.**\nThese metrics will all fall between 0 and 1, with a higher value being better.\nAlthough, they don't necessarily need to come into play for our Titantic problem, they're worth remembering for your future work.","daf6ec2c":"# **Importing libraries**","19b0e8f1":"# Feature: Ticket","29bd1d1a":"This shows that columns **[age and cabin ]** have missing values","fcc1dff9":"# Feature: Fare","a5ebfb5a":"# Building Model using Catboost ","6775791c":"# **Now explore features one by one**","ab3e8100":"# Feature: SEX","231d4497":"# CatBoost cross-validation","07a219ab":"# Catboost","cac3d3b3":"We need our submission dataframe to look like the gender_submisison dataframe, so we'll turn the Survived column into integers.","16f2ebe0":"Let's plot the distribution\nWe will look at the distribution of each feature first so that we understand what kind of spread there is across the dataset. let say if there are values which are completely outside of the distribution, we may not want to include them in our model.","3c36e2e0":"\n# Data Descriptions\n\n- Survival: 0 = No, 1 = Yes\n- pclass (Ticket class): 1 = 1st, 2 = 2nd, 3 = 3rd\n\n- sex: Sex\n\n- Age: Age in years\n\n- sibsp: number of siblings\/spouses aboard the Titanic\n\n- parch: number of parents\/children aboard the Titanic\n\n- ticket: Ticket number\n\n- fare: Passenger fare\n\n- cabin: Cabin number\n\n- embarked: Port of Embarkation, C = Cherbourg, Q = Queenstown, S = Southampton","24cf9f27":"- Recall is low, this means there's a higher amount of false negatives (predicting did not survive when it was actually Survived).\n\n- Precision is higher therefore there's less false positives (predicting Survived, when it was actually did not survive).","69caa296":"# Missing Values ","954407e4":"- There are 681 unique Ticket values.\n- 681 unique values is too many for now. So we won't use Ticket in our subset dataframes.\n\n- There may be some way to reduce this down.\n\n- Challenge: How could you reduce the Ticket feature? Is it even possible?\n\n- Hint: It may be similar to what you could do with Name.","b5258737":"This shows we can drop name and PassengerId features for this model","4488b1a2":"# Feature: Parch","68a4b5f5":"## Function to create count and distribution visualisations","571d3310":"# Feature Pclass\n\n- Description: The ticket class of the passenger.\n\nKey: 1 = 1st, 2 = 2nd, 3 = 3rd"}}