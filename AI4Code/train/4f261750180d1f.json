{"cell_type":{"ee441a5c":"code","77d3c3cc":"code","35550f83":"code","46848a0b":"code","c6b168dc":"code","ef206c97":"code","9169db0a":"code","45d408fb":"code","3d67dfe3":"code","3f14d0b6":"code","081fa70c":"code","9816df92":"code","516435ed":"code","1ac16f78":"code","0b3671ce":"code","40dba751":"code","b4f2a3a6":"code","0d775949":"code","4d78e800":"code","9077ad66":"code","f35ec0c7":"code","324c5954":"code","946ab92c":"code","70623024":"code","a93ccf36":"code","3b577b39":"code","0391b245":"code","b64e930b":"code","23b59936":"code","7cf2777e":"code","bf33d73e":"code","5ed8f400":"code","30478da8":"code","be10a2c4":"code","bc5210cb":"code","1afd7ffb":"code","be0a45a2":"code","7c82f487":"code","6cb7f3ba":"code","ec42b2f1":"code","86e2c0c1":"code","58113ab6":"code","564fda5c":"code","60643ad2":"code","9c67f746":"code","4f7c4b50":"markdown","ed3e7e62":"markdown","8843fc5b":"markdown","be8a3b9e":"markdown","94714bcd":"markdown","36b3a9b6":"markdown","11bfce33":"markdown","f60c2c9c":"markdown","1d06c8c1":"markdown","d5a36707":"markdown","1b9797a4":"markdown","818b1a3b":"markdown","5422d097":"markdown","c447e142":"markdown","f4df3c10":"markdown","f05ce80b":"markdown","1203721b":"markdown","aa4aa981":"markdown","3b7624a8":"markdown","294e7a8d":"markdown","a943b666":"markdown","96c15317":"markdown","7680b081":"markdown","d06dc6d6":"markdown"},"source":{"ee441a5c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77d3c3cc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","35550f83":"# importing the dataset into pandas dataframe(df) to understand its contents\n\ndf = pd.read_csv('..\/input\/d\/raghavendratapas\/covid19-age-risk-factor\/dataset.csv')\ndf.head()","46848a0b":"df = df.reindex(columns=['Case', 'Age', 'Sex', 'Nationality', 'Transmission', 'Status'])\ndf.head()","c6b168dc":"# Checking for null values in the dataset\n\ndf.isna().sum()","ef206c97":"# How many samples?\nlen(df)","9169db0a":"df.dtypes","45d408fb":"print(df['Nationality'].value_counts())","3d67dfe3":"df = df.replace(['None'],'Others')\ndf = df.replace(['Chinese'],'Others')\ndf = df.replace(['American'],'Others')\ndf = df.replace(['British'],'Others')\ndf = df.replace(['Chinese, Taiwanese'],'Others')\ndf","3f14d0b6":"print(df['Nationality'].value_counts())","081fa70c":"df.head()","9816df92":"print(df['Sex'].value_counts())","516435ed":"sns.scatterplot(x = df.Status, y = df.Age, data = df);","1ac16f78":"print(df['Status'].value_counts())","0b3671ce":"print(df['Transmission'].value_counts())","40dba751":"df.info()","b4f2a3a6":"plt.style.use(\"ggplot\")\nfig, axes = plt.subplots(2, 2, figsize=(10,7))\n\naxes[0,0].set_title(\"Distribution of Age\")\naxes[0,0].hist(df['Age'], bins=5);\naxes[0,1].set_title(\"Distribution of Sex\")\naxes[0,1].hist(df['Sex'], bins=7);\naxes[1,0].set_title(\"Distribution of Nationality\")\naxes[1,0].hist(df['Nationality'], bins=5);\naxes[1,1].set_title(\"Distribution of Transmission\")\naxes[1,1].hist(df['Transmission'], bins=6);","0d775949":"fig, axs = plt.subplots(1, 2)\nfig.set_size_inches(15, 2.5)\n\nsns.scatterplot(ax = axs[0], x = \"Age\", y =\"Sex\", hue='Status', data = df)\naxs[0].set_title(\"Age vs Sex\")\n\nsns.scatterplot(ax = axs[1], x = \"Age\", y =\"Transmission\", hue='Status', data = df)\naxs[1].set_title(\"Age vs Transmission\");","4d78e800":"sns.scatterplot(x = \"Age\", y =\"Nationality\", hue='Status', data = df);","9077ad66":"# Cardinality \/ distinct count for all columns in pandas dataframe\n\ndf.apply(pd.Series.nunique)","f35ec0c7":"df.head(3)","324c5954":"# To find out the co-relation between the features, we need to convert strings to integers\n# df1 should not be used to feed to the machine learning models as the features nationality, Status, Transmission are all nominal variables.\ndf1 = df.replace(['Female'], 0)\ndf1 = df1.replace(['Male'], 1)\n\ndf1 = df1.replace(['Others'], 0)\ndf1 = df1.replace(['Filipino'], 1)\n\ndf1 = df1.replace(['Local'], 0)\ndf1 = df1.replace(['Imported'],1)\n\ndf1 = df1.replace(['Deceased'], 0)\ndf1 = df1.replace(['Recovered'], 1)\ndf1.head()","946ab92c":"print(df1['Nationality'].value_counts())","70623024":"sns.heatmap(df1.corr(method='pearson'), annot=True, cmap='coolwarm');","a93ccf36":"df1 = df\ndf1.head()","3b577b39":"df1 = df1.drop('Case', axis = 1)\ndf1 = df1.drop('Sex', axis = 1)\ndf1 = df1.drop('Nationality', axis = 1)\ndf1 = df1.drop('Transmission', axis = 1)\ndf1.head()","0391b245":"# Create dummy columns\ndummies = pd.get_dummies(df1[['Status']])\n\n# Merge with dataframe\nmerged_df = pd.concat([df1, dummies], axis = 'columns')\n\n# Drop status and deceased column\n# Simple_df signifies that it is a dataframe of simple model ignoring other features\n\nsimple_df = merged_df.drop(['Status','Status_Deceased'], axis = 'columns')\n","b64e930b":"merged_df.head()","23b59936":"# deceased = 0 and recovered = 1\n\nsimple_df.rename(columns = {'Status_Recovered':'Status'}, inplace = True)\nsimple_df","7cf2777e":"from sklearn.linear_model import SGDClassifier\nnp.random.seed(1)\n\n# Assign x = age\nx = simple_df.drop('Status', axis = 1)\n\n# Assign y = status (deceased or recovered)\ny = simple_df.Status\n\n# Split the dataset into two parts ( 70 % training set, 30 % testing set)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n\nsgd = SGDClassifier()\nsgd.fit(x_train, y_train)\n\n# score\nsgd.score(x_test, y_test)","bf33d73e":"from sklearn.metrics import confusion_matrix\ny_predicted = sgd.predict(x_test)\ncm = confusion_matrix(y_test, y_predicted)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","5ed8f400":"from sklearn.kernel_approximation import RBFSampler\nfrom sklearn.linear_model import SGDClassifier\nimport random\nrandom.seed(1)\n\nx = simple_df.drop('Status', axis = 1)\ny = simple_df.Status\n\n# Split the dataset into two parts ( 70 % training set, 30 % testing set)\n# from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n\nrbf_feature = RBFSampler()\nx_train = rbf_feature.fit_transform(x_train)\nx_test = rbf_feature.fit_transform(x_test)\n\nkernel = SGDClassifier()\nkernel.fit(x_train, y_train)\n\n# score\nkernel.score(x_test, y_test)","30478da8":"y_predicted = kernel.predict(x_test)\ncm = confusion_matrix(y_test, y_predicted)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","be10a2c4":"from sklearn.ensemble import RandomForestClassifier  \nnp.random.seed(1)\n\nx = simple_df.drop('Status', axis = 1)\ny = simple_df.Status\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)\n\nrfc = RandomForestClassifier(n_estimators = 50)\nrfc.fit(x_train, y_train)\n\n\nrfc.score(x_test, y_test)","bc5210cb":"y_preds = rfc.predict(x_test)\nconfusion_matrix(y_test, y_preds)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","1afd7ffb":"df.head()","be0a45a2":"# Hot Encoding\n\n# Create dummy columns\n\ndummies1 = pd.get_dummies(df[['Sex']])\ndummies2 = pd.get_dummies(df[['Nationality']])\ndummies3 = pd.get_dummies(df[['Transmission']])\ndummies4 = pd.get_dummies(df[['Status']])\n\n# Merge with dataframe, model2_df includes other features\nmerged_df = pd.concat([df, dummies1, dummies2, dummies3, dummies4], axis = 'columns')\n\n# Drop Case, Sex, Nationality, Transmission, Status....and all the first columns\nmodel2_df = merged_df.drop(['Case', 'Sex', 'Nationality', 'Transmission', 'Status', 'Sex_Female', 'Nationality_Filipino', 'Transmission_Imported', 'Status_Deceased'], axis = 1)\nmodel2_df","7c82f487":"from sklearn.linear_model import SGDClassifier\nnp.random.seed(2)\n\n# x = Features\nx = model2_df.drop('Status_Recovered', axis = 1)\n\n# Assign y = status column\ny = model2_df.Status_Recovered\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.3)\n\nsgd = SGDClassifier()\nsgd.fit(x_train, y_train)\n\nsgd.score(x_test, y_test)","6cb7f3ba":"from sklearn.metrics import confusion_matrix\ny_predicted = sgd.predict(x_test)\ncm = confusion_matrix(y_test, y_predicted)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","ec42b2f1":"from sklearn.kernel_approximation import RBFSampler\nfrom sklearn.linear_model import SGDClassifier\nimport random\nrandom.seed(1)\n\n# x = Features\nx = model2_df.drop('Status_Recovered', axis = 1)\n\n# Assign y = status column\ny = model2_df.Status_Recovered\n\n# Split the dataset into two parts ( 70 % training set, 30 % testing set)\n# from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n\nrbf_feature = RBFSampler()\nx_train = rbf_feature.fit_transform(x_train)\nx_test = rbf_feature.fit_transform(x_test)\n\nkernel = SGDClassifier()\nkernel.fit(x_train, y_train)\n\n# score\nkernel.score(x_test, y_test)","86e2c0c1":"y_predicted = kernel.predict(x_test)\ncm = confusion_matrix(y_test, y_predicted)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","58113ab6":"from sklearn.kernel_approximation import RBFSampler\nfrom sklearn.linear_model import SGDClassifier\nimport random\nrandom.seed(1)\n\n# x = Features\nx = model2_df.drop('Status_Recovered', axis = 1)\n\n# Assign y = status column\ny = model2_df.Status_Recovered\n\n# Split the dataset into two parts ( 70 % training set, 30 % testing set)\n# from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n\nrbf_feature = RBFSampler()\nx_train = rbf_feature.fit_transform(x_train)\nx_test = rbf_feature.fit_transform(x_test)\n\nkernel = SGDClassifier()\nkernel.fit(x_train, y_train)\n\n# score\nkernel.score(x_test, y_test)","564fda5c":"y_predicted = kernel.predict(x_test)\ncm = confusion_matrix(y_test, y_predicted)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","60643ad2":"from sklearn.ensemble import RandomForestClassifier  \nnp.random.seed(1)\n\n# x = Features\nx = model2_df.drop('Status_Recovered', axis = 1)\n\n# Assign y = status column\ny = model2_df.Status_Recovered\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)\n\nrfc = RandomForestClassifier(n_estimators = 50)\nrfc.fit(x_train, y_train)\n\n\nrfc.score(x_test, y_test)","9c67f746":"y_preds = rfc.predict(x_test)\nconfusion_matrix(y_test, y_preds)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","4f7c4b50":"#### Confusion Matrix","ed3e7e62":"### Random Forest Classifier","8843fc5b":"### Attempt 3: Random Forest Classifier\n\nRandom Forest is a `low bias` and `high variance` model. But the majority voting reduces the variance of the model.\n\n* Import RandomForestClassifier class\n* Setup random seeding = 3\n* Create Feature Matrix (x)\n* Create Labels (y)\n* Split the data\n* Instantiate RandomForestClassifier\n* Fit the model\n* Evaluate RandomForestClassifier","be8a3b9e":"# Age as a Risk Factor of COVID-19 Mortality in the Philippines\n\nWork by: Raghavendra Tapas\n\nPlease raise issues or feel free to start a discussion in-case there are any corrections that you feel need to be done.\n\nDataset Source: https:\/\/www.kaggle.com\/saurabhshahane\/covid19-age-risk-factor\n\nExcel dataset with the following columns: Case No., Age, Sex, Nationality, Status, Transmission. \n\nData were extracted from https:\/\/endcov.ph\/cases\/\n\n<b> Acknowledgements <\/b>\n\nMedina, Michael Arieh (2020), \u201cData for: Age as a Risk Factor of COVID-19 Mortality in the Philippines\u201d, Mendeley Data, V2, doi: 10.17632\/gxxnmgcfnd.2\n\n`Brief Disclaimer:` It is to be noted here that this study was only meant for educational purposes. The conclusions or observations drawn were not meant to hurt any nationality, any individual, group.\n\n<b> Question: Given the age, find out the chances of recovery. <\/b>","94714bcd":"## Data Exploration","36b3a9b6":"<b> Side note:<\/b>  The dataset was in \"dataset`.xlsx`\" format which was converted to \"dataset`.csv`\". Importing CSV files can be much faster, and it also consumes less memory.","11bfce33":"#### Confusion Matrix","f60c2c9c":"### Kernel Approximation","1d06c8c1":"## Model 2 - Including other features","d5a36707":"#### Confusion Matrix","1b9797a4":"#### Confusion Matrix","818b1a3b":"### Kernel Approximation\n\nRadial Basis Function - rbf","5422d097":"- To simplify the computation, we need to simplify the cardinality of the Nationality feature. So we classify the data into two categories\n\n- Filipino and Others","c447e142":"Map of choosing the right model: https:\/\/scikit-learn.org\/stable\/tutorial\/machine_learning_map\/index.html\n\n* Are we predicting a category? \n\n    * `Yes` Given the age, we are trying to predict if the person will recover or not.\n\n* Do we have labeled data?\n\n    * `Yes`\n\n* Do we have 100k+ samples?\n\nAnswer: `No`\n\n    * Attempt 1: Try Stochastic Gradient Descent (SGD) Classifier","f4df3c10":"### SGD Classifier","f05ce80b":"## Choosing the Right machine learning model","1203721b":"<b>Initial Observations<\/b>\n\n- The given dataset is not balanced for the feature \"Sex\" as it contains more 'Male'.\n- The given dataset is not balanced for the feature \"Nationality\" as `Filipino` in the nationality feature dominates.\n- It seems that more people died than getting recoverd from COVID.\n- Scatterplot suggests that people who died were beyond the age 30. So, it seems like the chances of getting recovered for the age below 30 is extremely high.\n- The transmission is more local than imported. \n- It is also important to explore more about how the data collection was done as the dataset contains more `filipino` data when compared to other nationalities.\n- Age seems to be ~60% negatively co-related with Status. There is little to no co-relation between any of the pairs except 'Age and Status'","aa4aa981":"## Model 1 - Ignoring All other features except Age\n- Dropping case, sex, nationality, transmission\n- One hot encoding the status","3b7624a8":"## Dealing with Categorical Variables\n\nThe text is never understood by machines.\n\nThere are three common approaches for converting ordinal and categorical variables to numerical values. They are:\n\n    1. Ordinal Encoding - Typically used in \"Place\" variables such as \"first\", \"second\" and \"third\". We know 1>2>3. There exists a numerical relationship between the cateogories.\n    \n    2. One-Hot Encoding - Typically used in \u201ccolor\u201d variables with the values: \u201cred\u201c, \u201cgreen\u201d and \u201cblue\u201c, where there exists no natural relationship between red, green and blue. Red !(=, > or <) Green...\n    3. Dummy Variable Encoding\n\n----------| Nominal  | Ordinal\n----------|-------- | --------\nExample| Town 01,02,03.. | Satisfied, neutral, dis-satisfied\nExample| Male, female | High, medium low\nExample| Green, blue, red | graduate, masters, phd\n\n    * Nominal Variable (Categorical): Variable comprises a finite set of discrete values with no relationship between values.\n    * Ordinal Variable: Variable comprises a finite set of discrete values with a ranked ordering between values.\n    \n![title](Encoding-Map2.png)\n\nSource: Feature Labs","294e7a8d":"## Co-Relation Heatmap","a943b666":"#### Confusion Matrix","96c15317":"### SGD Classifier","7680b081":"## Dependencies or Libraries\n\n- Importing useful libraries like numpy, pandas, matplotlib and seaborn\n- `% matplotlib` is a magic function that renders the figure in a notebook (instead of displaying a dump of the figure object).","d06dc6d6":"#### Confusion Matrix"}}