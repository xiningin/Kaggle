{"cell_type":{"47bf6e1a":"code","fb015988":"code","10dcdae9":"code","c47725e1":"code","4b26a8ab":"code","2c61a9f5":"code","5ec4e0a6":"code","b8524717":"code","28245db2":"code","27cb28f7":"code","b6e55378":"code","846eed22":"markdown"},"source":{"47bf6e1a":"# 2nd attempt at the MNIST challenge. Previously, I tried a WRN, which turned out to be much too complex \n# for the dataset and extremely overfit. This time, a simpler CNN will suffice.\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport keras\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fb015988":"df = pd.read_csv('\/kaggle\/input\/train.csv')\ndf.head(5)","10dcdae9":"df.values.shape","c47725e1":"x = df.drop(['label'],1)\nx.head()","4b26a8ab":"y = df['label']\ny.head()","2c61a9f5":"from keras.utils import to_categorical\nX = x.values.reshape(x.values.shape[0],28,28,1)\nY = to_categorical(y.values,10)\nprint(Y.shape)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.15)\n\nprint(x_train.shape,x_test.shape)","5ec4e0a6":"# Define model\nfrom keras import layers, models\n\nnetwork_input = layers.Input((28,28,1))\nconv1 = layers.Conv2D(16, kernel_size=(4,4))(network_input)\nb1 = layers.BatchNormalization()(conv1)\na1 = layers.Activation('relu')(b1)\nd1 = layers.Dropout(0.1)(a1)\nconv2 = layers.Conv2D(32, kernel_size=(4,4), strides = 2)(d1)\nb2 = layers.BatchNormalization()(conv2)\na2 = layers.Activation('relu')(b2)\nd2 = layers.Dropout(0.1)(a2)\nconv3 = layers.Conv2D(64, kernel_size=(4,4), strides = 2)(d2)\nb3 = layers.BatchNormalization()(conv3)\na3 = layers.Activation('relu')(b3)\ndrop = layers.Dropout(0.2)(a3)\nflat = layers.Flatten()(drop)\noutput = layers.Dense(10, activation='softmax')(flat)\n\nmodel = models.Model(network_input, output)\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\nmodel.summary()\n\nfrom keras.callbacks import *\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n    ModelCheckpoint('mnist.h5', monitor='val_loss', save_best_only=True, verbose=0),\n]\nmodel.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_test,y_test),callbacks=callbacks)","b8524717":"model = models.load_model('mnist.h5')","28245db2":"# Load test values and make predictions\npredict_x = pd.read_csv('\/kaggle\/input\/test.csv')\npredict_x = predict_x.values.reshape(predict_x.values.shape[0],28,28,1)\nprint(predict_x.shape)\npredictions = np.argmax(model.predict(predict_x),axis=1)\nprint(predictions.shape)","27cb28f7":"# Visualize predictions\nimport random\nimport matplotlib.pyplot as plt\nchoice = random.randint(0,predict_x.shape[0])\nplt.imshow(predict_x[choice][:,:,0],cmap='gray')\nprint(\"Prediction: \",predictions[choice])","b6e55378":"# Encode our data into comma separated values for submission\ntext = [\"ImageId,Label\\n\"]\nfor index, prediction in enumerate(predictions):\n    string = str(index+1)+','+str(prediction)\n    if index != 27999: string += \"\\n\" # We do this to make sure there's not an empty row at the end.\n    text.append(string)\nwith open(\"submission.csv\",\"w+\") as writer:\n    writer.writelines(text)","846eed22":"Aaand we're done!"}}