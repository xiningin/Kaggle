{"cell_type":{"cec5b11e":"code","0044c0ce":"code","7b554554":"code","7519ba8e":"code","563fa278":"code","7fd53079":"code","5f1df862":"code","eb06ed0e":"code","e0c44bb1":"code","80253c91":"code","8d0ee14f":"code","2a980ef9":"code","adc25c58":"code","8f42ebdd":"code","468188af":"code","522e3a6c":"code","e026a372":"code","e52d45c7":"code","a0d40792":"code","b79e941e":"code","bb2f62e2":"code","2059e92b":"code","a2564556":"code","4d2f89c3":"code","9f486027":"code","53053d81":"code","4488ac06":"code","ba239b8f":"code","b46794c2":"code","e7a8cf01":"code","b67383da":"code","ba321321":"code","261402d9":"code","11c2a45a":"code","e1fdf96b":"code","1613b4c3":"code","4412f833":"code","c256b40d":"code","8cdf2e0b":"code","1e5e5694":"code","029bb1d2":"code","96f983c1":"code","489f0620":"code","0642b5ee":"code","d7478b80":"code","019d6ca8":"code","de9d96cd":"code","f44d2e3c":"code","7f43bde5":"code","11d565f3":"code","efa3fbce":"code","db797d89":"code","9d01abeb":"code","fb6f2142":"code","e386b590":"code","d264eab0":"code","319d6678":"code","38107c78":"markdown","63b6333b":"markdown","15ef3fc9":"markdown","3fc97342":"markdown","265535d8":"markdown","03b909c3":"markdown","13c37c19":"markdown","221765ca":"markdown","a3246dae":"markdown","04a603a9":"markdown","a23785d3":"markdown","425f7d17":"markdown","c86a14d6":"markdown","2f4b979c":"markdown","b7b9d201":"markdown","c9da6bb1":"markdown","6147141d":"markdown","43178c83":"markdown","64d6927f":"markdown","e01a90f1":"markdown","1d5a27e4":"markdown","3556da07":"markdown","de2be09f":"markdown","1f4cadc1":"markdown","31996180":"markdown","da3ef547":"markdown","58dad40c":"markdown"},"source":{"cec5b11e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom surprise import Reader, Dataset, SVD, SVDpp, NMF, KNNBaseline, evaluate, accuracy\nfrom surprise.model_selection import KFold, train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\n\n\nr_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\nratings = pd.read_csv('..\/input\/ml-100k\/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n\nm_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url','unknown', 'Action', 'Adventure',\\\n          'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy','Film-Noir', 'Horror',\\\n          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\nmovies = pd.read_csv('..\/input\/ml-100k\/u.item', sep='|', names=m_cols, encoding='latin-1')\n\nu_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\nusers = pd.read_csv('..\/input\/ml-100k\/u.user', sep='|', names=u_cols, encoding='latin-1', parse_dates=True)","0044c0ce":"ratings['unix_timestamp'] = ratings['unix_timestamp'].apply(datetime.fromtimestamp)\nratings.columns = ['user_id', 'movie_id', 'rating', 'time']\nratings.head(10)","7b554554":"ratings['rating'].hist(bins=9)","7519ba8e":"movies['release_date'] = pd.to_datetime(movies['release_date'])\nmovies.head(10)","563fa278":"for i in users['occupation'].unique():\n    users[i] = users['occupation'] == i\nusers.drop('occupation', axis=1, inplace=True)\nusers.head(10)","7fd53079":"ratings_movie_summary = ratings.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\nratings_movie_summary.head(10)","5f1df862":"ratings_user_summary = ratings.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\nratings_user_summary.head(10)","eb06ed0e":"ratings_movie_summary.sort_values(by='count')['count'].hist(bins=20)","e0c44bb1":"ratings_movie_summary.sort_values(by='mean')['mean'].hist(bins=20)","80253c91":"ratings_user_summary.sort_values(by='count')['count'].hist(bins=20)","8d0ee14f":"ratings_user_summary.sort_values(by='mean')['mean'].hist(bins=20)","2a980ef9":"ratings_p = pd.pivot_table(ratings, values='rating', index='user_id', columns='movie_id')\nratings_p.iloc[:10, :10]","adc25c58":"mean = ratings_p.stack().mean()\nstd = ratings_p.stack().std()","8f42ebdd":"#trainset, testset = train_test_split(ratings, test_size=0.15, random_state=0)\n\nreader = Reader()\ndata = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n#data.split(n_folds=3)\n\nsvd = SVD()\nevaluate(svd, data, measures=['RMSE', 'MAE'])","468188af":"trainset = data.build_full_trainset()\ntestset = trainset.build_testset()\npredictions = svd.test(testset)\nmodel_pred = pd.DataFrame([[i.uid, i.iid, i.est] for i in predictions], columns=['user_id', 'movie_id', 'svd'])\nmodel_pred.shape","522e3a6c":"anti_testset = trainset.build_anti_testset()\nanti_predictions = svd.test(anti_testset)\nmodel_pred_anti = pd.DataFrame([[i.uid, i.iid, i.est] for i in anti_predictions], columns=['user_id', 'movie_id', 'svd'])\nmodel_pred = pd.concat([model_pred, model_pred_anti], ignore_index=True)\nmodel_pred.shape","e026a372":"svd_p = pd.pivot_table(model_pred, values='svd', index='user_id', columns='movie_id')\nsvd_p.iloc[:10, :10]","e52d45c7":"svd_p = np.array(svd_p)\nu, s, vt = np.linalg.svd(svd_p, full_matrices=False)\nsigma = np.diag(s)\nprint(u.shape, sigma.shape, vt.shape)\npd.DataFrame(sigma[:10, :10])","a0d40792":"pd.DataFrame(np.matmul(u, np.matmul(sigma, vt))).iloc[:10, :10]","b79e941e":"#from surprise.model_selection import GridSearchCV\n#from surprise.model_selection import cross_validate\n\n#param_grid = {'n_factors': [110, 120, 140, 160], 'n_epochs': [90, 100, 110], 'lr_all': [0.001, 0.003, 0.005, 0.008],\n#              'reg_all': [0.08, 0.1, 0.15]}\n#gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n#gs.fit(data)\n#algo = gs.best_estimator['rmse']\n#print(gs.best_score['rmse'])\n#print(gs.best_params['rmse'])\n#cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","bb2f62e2":"param_grid = {'n_factors': [70, 80, 90, 100, 110, 120, 130, 140, 150, 160], 'n_epochs': [100], 'reg_all': [0.1]}\ngs_svd = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\ngs_svd.fit(data)\nsvd = gs_svd.best_estimator['rmse']\nprint(gs_svd.best_score['rmse'])\nprint(gs_svd.best_params['rmse'])","2059e92b":"cv_results_svd = pd.DataFrame(gs_svd.cv_results)\nfig = plt.figure(figsize=(15, 6))\nplt.subplot(121)\nplt.plot(cv_results_svd['mean_test_rmse'])\nplt.xticks(np.arange(10), np.arange(70, 170, 10), fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('number of latent factors', fontsize=16)\nplt.ylabel('Root Mean Square Error (RMSE)', fontsize=16)\nplt.grid()\nplt.legend()\nplt.subplot(122)\nplt.plot(cv_results_svd['mean_test_mae'])\nplt.xticks(np.arange(10), np.arange(70, 170, 10), fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('number of latent factors', fontsize=16)\nplt.ylabel('Mean Absolute Error (MAE)', fontsize=16)\nplt.grid()\nplt.legend()\nplt.show()","a2564556":"eval_svd = evaluate(svd, data, measures=['RMSE', 'MAE'])\ntrainset = data.build_full_trainset()\nsvd.fit(trainset)","4d2f89c3":"df_196 = ratings[ratings['user_id'] == 196]\ndf_196 = df_196.set_index('movie_id')\ndf_196 = df_196.join(movies)['title']\nprint(df_196.sort_index())","9f486027":"user_196_svd = movies[['movie_id', 'title', 'release_date']]\nuser_196_svd['Estimate_Score'] = user_196_svd['movie_id'].apply(lambda x: svd.predict('196', x).est)\nuser_196_svd = user_196_svd.drop('movie_id', axis = 1)\nuser_196_svd = user_196_svd.sort_values('Estimate_Score', ascending=False)\nprint(user_196_svd.head(10))","53053d81":"svdpp = SVDpp()\nevaluate(svdpp, data, measures=['RMSE', 'MAE'])","4488ac06":"param_grid = {'lr_all': [0.001, 0.003, 0.005, 0.007, 0.009], 'reg_all': [0.005, 0.01, 0.015, 0.02, 0.025]}\ngs_svdpp = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3)\ngs_svdpp.fit(data)\nsvdpp = gs_svdpp.best_estimator['rmse']\nprint(gs_svdpp.best_score['rmse'])\nprint(gs_svdpp.best_params['rmse'])","ba239b8f":"cv_results_svdpp = pd.DataFrame(gs_svdpp.cv_results)\nsvdpp_rmse = np.array(cv_results_svdpp['mean_test_rmse']).reshape(5,5)\nsvdpp_mae = np.array(cv_results_svdpp['mean_test_mae']).reshape(5,5)\nfig = plt.figure(figsize=(15,6))\nax1 = plt.subplot(121)\nim1 = ax1.imshow(svdpp_rmse)\ncbar = ax1.figure.colorbar(im1, ax=ax1)\nax1.set_xticks(np.arange(5))\nax1.set_yticks(np.arange(5))\nax1.set_xticklabels(param_grid['lr_all'], fontsize=13)\nax1.set_yticklabels(param_grid['reg_all'], fontsize=13)\nfor i in range(5):\n    for j in range(5):\n        text = ax1.text(j, i, round(svdpp_rmse[i][j], 4), ha=\"center\", va=\"center\", color=\"w\")\nax1.set_xlabel('reg_all', fontsize=16)\nax1.set_ylabel('lr_all', fontsize=16)\nax1.set_title('Root Mean Square Error (RMSE)', fontsize=16)\nax2 = plt.subplot(122)\nim2 = ax2.imshow(svdpp_mae)\ncbar = ax2.figure.colorbar(im2, ax=ax2)\nax2.set_xticks(np.arange(5))\nax2.set_yticks(np.arange(5))\nax2.set_xticklabels(param_grid['lr_all'], fontsize=13)\nax2.set_yticklabels(param_grid['reg_all'], fontsize=13)\nfor i in range(5):\n    for j in range(5):\n        text = ax2.text(j, i, round(svdpp_mae[i][j], 4), ha=\"center\", va=\"center\", color=\"w\")\nax2.set_xlabel('reg_all', fontsize=16)\nax2.set_ylabel('lr_all', fontsize=16)\nax2.set_title('Mean Absolute Error (MAE)', fontsize=16)\nplt.show()","b46794c2":"eval_svdpp = evaluate(svdpp, data, measures=['RMSE', 'MAE'])","e7a8cf01":"nmf = NMF()\nevaluate(nmf, data, measures=['RMSE', 'MAE'])","b67383da":"param_grid = {'n_factors': [1,2,3,4,5,6,7,8,9,10], 'n_epochs': [100], 'biased': [True], 'reg_bu': [0.1], 'reg_bi': [0.1]}\ngs_nmfb = GridSearchCV(NMF, param_grid, measures=['rmse', 'mae'], cv=3)\ngs_nmfb.fit(data)\nnmfb = gs_nmfb.best_estimator['rmse']\nprint(gs_nmfb.best_score['rmse'])\nprint(gs_nmfb.best_params['rmse'])","ba321321":"cv_results_nmfb = pd.DataFrame(gs_nmfb.cv_results)\nfig = plt.figure(figsize=(15, 6))\nplt.subplot(121)\nplt.plot(cv_results_nmfb['mean_test_rmse'])\nplt.xticks(np.arange(10), np.arange(1, 11), fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('number of latent factors', fontsize=16)\nplt.ylabel('Root Mean Square Error (RMSE)', fontsize=16)\nplt.grid()\nplt.legend()\nplt.subplot(122)\nplt.plot(cv_results_nmfb['mean_test_mae'])\nplt.xticks(np.arange(10), np.arange(1, 11), fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('number of latent factors', fontsize=16)\nplt.ylabel('Mean Absolute Error (MAE)', fontsize=16)\nplt.grid()\nplt.legend()\nplt.show()","261402d9":"eval_nmfb = evaluate(nmfb, data, measures=['RMSE', 'MAE'])","11c2a45a":"param_grid = {'n_factors': [200, 220, 240], 'n_epochs': [90, 100, 110]}\ngs_nmf = GridSearchCV(NMF, param_grid, measures=['rmse', 'mae'], cv=3)\ngs_nmf.fit(data)\nnmf = gs_nmf.best_estimator['rmse']\nprint(gs_nmf.best_score['rmse'])\nprint(gs_nmf.best_params['rmse'])","e1fdf96b":"eval_nmf = evaluate(nmf, data, measures=['RMSE', 'MAE'])","1613b4c3":"knnb = KNNBaseline(k=50)\nevaluate(knnb, data, measures=['RMSE', 'MAE'])","4412f833":"knnb_1 = KNNBaseline(k=60, sim_options = {'user_based': False})\neval_knnb_1 = evaluate(knnb_1, data, measures=['RMSE', 'MAE'])","c256b40d":"param_grid = {'k': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'sim_options': {'user_based': [True, False]},\\\n              'bsl_options': {'method': ['als', 'sgd']}}\ngs_knn = GridSearchCV(KNNBaseline, param_grid, measures=['rmse', 'mae'], cv=3)\ngs_knn.fit(data)\nprint(gs_knn.best_score['rmse'])\nprint(gs_knn.best_params['rmse'])","8cdf2e0b":"cv_results_knn = pd.DataFrame(gs_knn.cv_results)\nindex = np.arange(0, 40, 4)\nfig = plt.figure(figsize=(15, 6))\nplt.subplot(121)\nplt.plot(cv_results_knn.loc[index, 'mean_test_rmse'].tolist(), label='user_based_als')\nplt.plot(cv_results_knn.loc[index+1, 'mean_test_rmse'].tolist(), label='user_based_sgd')\nplt.plot(cv_results_knn.loc[index+2, 'mean_test_rmse'].tolist(), label='item_based_als')\nplt.plot(cv_results_knn.loc[index+3, 'mean_test_rmse'].tolist(), label='item_based_sgd')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index, 'mean_test_rmse'].tolist(), cv_results_knn.loc[index, 'std_test_rmse'].tolist(), capsize=8, label='user_based_als')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index+1, 'mean_test_rmse'].tolist(), cv_results_knn.loc[index+1, 'std_test_rmse'].tolist(), capsize=8, label='user_based_sgd')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index+2, 'mean_test_rmse'].tolist(), cv_results_knn.loc[index+2, 'std_test_rmse'].tolist(), capsize=8, label='item_based_als')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index+3, 'mean_test_rmse'].tolist(), cv_results_knn.loc[index+3, 'std_test_rmse'].tolist(), capsize=8, label='item_based_sgd')\nplt.xticks(np.arange(10), np.arange(10, 110, 10), fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('number of neighbors (k)', fontsize=16)\nplt.ylabel('Root Mean Square Error (RMSE)', fontsize=16)\nplt.grid()\nplt.legend()\nplt.subplot(122)\nplt.plot(cv_results_knn.loc[index, 'mean_test_mae'].tolist(), label='user_based_als')\nplt.plot(cv_results_knn.loc[index+1, 'mean_test_mae'].tolist(), label='user_based_sgd')\nplt.plot(cv_results_knn.loc[index+2, 'mean_test_mae'].tolist(), label='item_based_als')\nplt.plot(cv_results_knn.loc[index+3, 'mean_test_mae'].tolist(), label='item_based_sgd')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index, 'mean_test_mae'].tolist(), cv_results_knn.loc[index, 'std_test_mae'].tolist(), capsize=8, label='user_based_als')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index+1, 'mean_test_mae'].tolist(), cv_results_knn.loc[index+1, 'std_test_mae'].tolist(), capsize=8, label='user_based_sgd')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index+2, 'mean_test_mae'].tolist(), cv_results_knn.loc[index+2, 'std_test_mae'].tolist(), capsize=8, label='item_based_als')\n#plt.errorbar(np.arange(10), cv_results_knn.loc[index+3, 'mean_test_mae'].tolist(), cv_results_knn.loc[index+3, 'std_test_mae'].tolist(), capsize=8, label='item_based_sgd')\nplt.xticks(np.arange(10), np.arange(10, 110, 10), fontsize=13)\nplt.yticks(fontsize=13)\nplt.xlabel('number of neighbors (k)', fontsize=16)\nplt.ylabel('Mean Absolute Error (MAE)', fontsize=16)\nplt.grid()\nplt.legend()\nplt.show()","1e5e5694":"knnb = KNNBaseline(k=70, sim_options = {'user_based': False}, bsl_options = {'method': 'sgd', 'n_epochs': 100})\neval_knnb = evaluate(knnb, data, measures=['RMSE', 'MAE'])","029bb1d2":"### All models after grid search.\nsvd = SVD(n_factors=140, n_epochs=100, reg_all=0.1)\neval_svd = evaluate(svd, data, measures=['RMSE', 'MAE'])\nsvdpp = SVDpp(lr_all=0.005, reg_all=0.015)\neval_svdpp = evaluate(svdpp, data, measures=['RMSE', 'MAE'])\nnmfb = NMF(n_factors=3, n_epochs=100, biased=True, reg_bu=0.1, reg_bi=0.1)\neval_nmfb = evaluate(nmfb, data, measures=['RMSE', 'MAE'])\nnmf = NMF(n_factors=240, n_epochs=90)\neval_nmf = evaluate(nmf, data, measures=['RMSE', 'MAE'])\nknnb_1 = KNNBaseline(k=60, sim_options = {'user_based': False})\neval_knnb_1 = evaluate(knnb_1, data, measures=['RMSE', 'MAE'])\nknnb = KNNBaseline(k=70, sim_options = {'user_based': False}, bsl_options = {'method': 'sgd', 'n_epochs': 100})\neval_knnb = evaluate(knnb, data, measures=['RMSE', 'MAE'])","96f983c1":"from sklearn.svm import SVR\n\nmovie_mean = np.ones(ratings_p.shape)\nmovie_mean = pd.DataFrame(movie_mean * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nX = np.array(ratings_p*0) + movie_mean\nsvm = SVR(gamma=1, C=1)\npred_svm = ratings_p.copy()\nfor i in range(ratings_p.shape[0]):\n    svm.fit(np.array(X.iloc[i].dropna()).reshape(-1,1), ratings_p.iloc[i].dropna())\n    pred_svm.iloc[i] = svm.predict(np.array(movie_mean.iloc[0]).reshape(-1,1))\nscore_svm = abs(np.array(ratings_p) - pred_svm)\nscore_2_svm = score_svm ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_svm.stack().mean())))\nprint('MAE: {:.4f}'.format(score_svm.stack().mean()))","489f0620":"trainset = data.build_full_trainset()\ntestset = trainset.build_testset()\npred = ratings[['user_id', 'movie_id', 'rating']]\nl = [svd, svdpp, nmf, nmfb, knnb, knnb_1]\nfor i in range(len(l)):\n    predictions = l[i].test(testset)\n    model_pred = pd.DataFrame([[i.uid, i.iid, i.est] for i in predictions], columns=['user_id', 'movie_id', str(i)])\n    pred = pd.merge(pred, model_pred, how='left', left_on=['user_id', 'movie_id'], right_on=['user_id', 'movie_id'])\npred.columns = pred.columns[:3].tolist() + ['svd', 'svdpp', 'nmf', 'nmfb', 'knnb', 'knnb_1']\n#pred = pd.merge(pred, users, on='user_id')\n#pred = pd.merge(pred, movies, on='movie_id')\n#pred['sex'] = pred['sex'].replace(['F', 'M'], [1, 0])\n#pred.drop(['release_date', 'video_release_date', 'imdb_url', 'title', 'zip_code'], axis=1, inplace=True)","0642b5ee":"pred['svm'] = np.zeros(pred.shape[0])\nfor i in pred.index:\n    pred.loc[i, 'svm'] = pred_svm.loc[pred.loc[i, 'user_id'], pred.loc[i, 'movie_id']]\npred.head()","d7478b80":"linreg = LinearRegression().fit(pred.iloc[:, 3:], pred['rating'])\n\nprint('linear model coeff (w): {}'\n     .format(linreg.coef_))\nprint('linear model intercept (b): {:.3f}'\n     .format(linreg.intercept_))\npred['pred'] = linreg.predict(pred.iloc[:, 3:])\nprint('RMSE: {:.4f}'.format(np.sqrt(((pred['pred'] - pred['rating']) ** 2).mean())))\nprint('MAE: {:.4f}'.format(abs(pred['pred'] - pred['rating']).mean()))","019d6ca8":"kf = KFold(n_splits=5, random_state=13)\nl = [svd, svdpp, nmf, nmfb, knnb, knnb_1]\npredCV = ratings[['user_id', 'movie_id', 'rating']]\npredCV_train = ratings[['user_id', 'movie_id', 'rating']]\nfor trainset, testset in kf.split(data):\n    for i in range(len(l)):\n        l[i].fit(trainset)\n        predictions = l[i].test(testset)\n        model_pred = pd.DataFrame([[i.uid, i.iid, i.est] for i in predictions], columns=['user_id', 'movie_id', str(i)])\n        predCV = pd.merge(predCV, model_pred, how='outer', left_on=['user_id', 'movie_id'], right_on=['user_id', 'movie_id'])\n        testset_train = trainset.build_testset()\n        predictions = l[i].test(testset_train)\n        model_pred_train = pd.DataFrame([[i.uid, i.iid, i.est] for i in predictions], columns=['user_id', 'movie_id', str(i)])\n        predCV_train = pd.merge(predCV_train, model_pred_train, how='outer', left_on=['user_id', 'movie_id'], right_on=['user_id', 'movie_id'])\npredCV.columns = ['user_id', 'movie_id', 'rating', 'svd_1', 'svdpp_1', 'nmf_1', 'nmfb_1', 'knnb_1', 'knnb_1_1',\\\n                  'svd_2', 'svdpp_2', 'nmf_2', 'nmfb_2', 'knnb_2', 'knnb_1_2',\\\n                  'svd_3', 'svdpp_3', 'nmf_3', 'nmfb_3', 'knnb_3', 'knnb_1_3',\\\n                  'svd_4', 'svdpp_4', 'nmf_4', 'nmfb_4', 'knnb_4', 'knnb_1_4',\\\n                  'svd_5', 'svdpp_5', 'nmf_5', 'nmfb_5', 'knnb_5', 'knnb_1_5']\npredCV_train.columns = ['user_id', 'movie_id', 'rating', 'svd_1', 'svdpp_1', 'nmf_1', 'nmfb_1', 'knnb_1', 'knnb_1_1',\\\n                        'svd_2', 'svdpp_2', 'nmf_2', 'nmfb_2', 'knnb_2', 'knnb_1_2',\\\n                        'svd_3', 'svdpp_3', 'nmf_3', 'nmfb_3', 'knnb_3', 'knnb_1_3',\\\n                        'svd_4', 'svdpp_4', 'nmf_4', 'nmfb_4', 'knnb_4', 'knnb_1_4',\\\n                        'svd_5', 'svdpp_5', 'nmf_5', 'nmfb_5', 'knnb_5', 'knnb_1_5']\npredCV_train.head()","de9d96cd":"index = pd.DataFrame(predCV['svd_1'])\nindex['svd_2'] = predCV['svd_2']\nindex['svd_3'] = predCV['svd_3']\nindex['svd_4'] = predCV['svd_4']\nindex['svd_5'] = predCV['svd_5']\nindex = index*0+1\nindex.columns = [1,2,3,4,5]\n\nrmse_svm = []\nmae_svm = []\nfold = 0\nmovie_mean = pd.DataFrame(np.ones(ratings_p.shape) * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nprint('Evaluating RMSE, MAE of the Baseline_SVM Model. \\n')\nprint('-'*12)\nfor i in index.columns:\n    train = ratings.copy()\n    test = ratings.copy()\n    train['rating'] = train['rating']*(index[i].isna())\n    train['rating'].replace(0, np.NaN, inplace=True)\n    test['rating'] = test['rating']*index[i]\n    train_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\n    train_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\n    train_p = pd.pivot_table(train, values='rating', index='user_id', columns='movie_id', dropna=False)\n    test_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n    train_mean = pd.DataFrame(np.ones(ratings_p.shape) * np.array(train_movie_summary['mean']).reshape(1,1682))\n    X = np.array(train_p*0) + train_mean\n    pred = ratings_p.copy()\n    for j in range(ratings_p.shape[0]):\n        svm.fit(np.array(X.iloc[j].dropna()).reshape(-1,1), train_p.iloc[j].dropna())\n        pred.iloc[j] = svm.predict(np.array(movie_mean.iloc[0]).reshape(-1,1))\n    predCV['svm_'+str(i)] = np.zeros(predCV.shape[0])\n    for x in predCV.index:\n        predCV.loc[x, 'svm_'+str(i)] = pred.loc[predCV.loc[x, 'user_id'], predCV.loc[x, 'movie_id']]\n    predCV['svm_'+str(i)] = index[i] * predCV['svm_'+str(i)]\n    predCV_train['svm_'+str(i)] = np.zeros(predCV.shape[0])\n    for x in predCV_train.index:\n        predCV_train.loc[x, 'svm_'+str(i)] = pred.loc[predCV_train.loc[x, 'user_id'], predCV_train.loc[x, 'movie_id']]\n    predCV_train['svm_'+str(i)] = (index[i].isna()) * predCV_train['svm_'+str(i)]\n    predCV_train.replace(0, np.NaN, inplace=True)\n    score = abs(np.array(test_p) - pred)\n    score_2 = score ** 2\n    rmse_svm += [np.sqrt(score_2.stack().mean())]\n    mae_svm += [score.stack().mean()]\n    fold += 1\n    print('Fold', fold)\n    print('RMSE: {:.4f}'.format(np.sqrt(score_2.stack().mean())))\n    print('MAE: {:.4f}'.format(score.stack().mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_svm)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_svm)))\nprint('-'*12)\nprint('-'*12)","f44d2e3c":"columns=['user_id', 'movie_id', 'rating', 'svd_1', 'svdpp_1', 'nmf_1', 'nmfb_1', 'knnb_1', 'knnb_1_1', 'svm_1',\\\n         'svd_2', 'svdpp_2', 'nmf_2', 'nmfb_2', 'knnb_2', 'knnb_1_2', 'svm_2',\\\n         'svd_3', 'svdpp_3', 'nmf_3', 'nmfb_3', 'knnb_3', 'knnb_1_3', 'svm_3',\\\n         'svd_4', 'svdpp_4', 'nmf_4', 'nmfb_4', 'knnb_4', 'knnb_1_4', 'svm_4',\\\n         'svd_5', 'svdpp_5', 'nmf_5', 'nmfb_5', 'knnb_5', 'knnb_1_5', 'svm_5']\npredCV=predCV.reindex(columns=columns)\npredCV_train=predCV_train.reindex(columns=columns)\ncoef = linreg.coef_\nfor i in range(1, 6):\n    predCV['fold_'+str(i)] = coef[0] * predCV['svd_'+str(i)] + coef[1] * predCV['svdpp_'+str(i)] +\\\n                             coef[2] * predCV['nmf_'+str(i)] + coef[3] * predCV['nmfb_'+str(i)] +\\\n                             coef[4] * predCV['knnb_'+str(i)] + coef[5] * predCV['knnb_1_'+str(i)] +\\\n                             coef[6] * predCV['svm_'+str(i)] + linreg.intercept_\npredCV.head()","7f43bde5":"rmse_ult = []\nmae_ult = []\nprint('Evaluating RMSE, MAE of the Ultimate Model. \\n')\nprint('-'*12)\nfor fold in range(1, 6):\n    print('Fold', fold)\n    rmse_ult += [np.sqrt(((predCV['fold_'+str(fold)] - predCV['rating']) ** 2).mean())]\n    mae_ult += [abs(predCV['fold_'+str(fold)] - predCV['rating']).mean()]\n    print('RMSE: {:.4f}'.format(np.sqrt(((predCV['fold_'+str(fold)] - predCV['rating']) ** 2).mean())))\n    print('MAE: {:.4f}'.format(abs(predCV['fold_'+str(fold)] - predCV['rating']).mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_ult)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_ult)))\nprint('-'*12)\nprint('-'*12)","11d565f3":"predCV_1 = predCV.copy()\nfor i in range(5):\n    s = predCV_train.iloc[:, 7*i+3:7*(i+1)+3]\n    s['rating'] = predCV_train['rating']\n    s.dropna(inplace=True)\n    linreg = LinearRegression().fit(s.drop('rating', axis=1), s['rating'])\n    coef = linreg.coef_\n    predCV_1['fold_'+str(i+1)] = coef[0] * predCV['svd_'+str(i+1)] + coef[1] * predCV['svdpp_'+str(i+1)] +\\\n                                 coef[2] * predCV['nmf_'+str(i+1)] + coef[3] * predCV['nmfb_'+str(i+1)] +\\\n                                 coef[4] * predCV['knnb_'+str(i+1)] + coef[5] * predCV['knnb_1_'+str(i+1)] +\\\n                                 coef[6] * predCV['svm_'+str(i+1)] + linreg.intercept_","efa3fbce":"rmse_ult = []\nmae_ult = []\nprint('Evaluating RMSE, MAE of the Ultimate Model. \\n')\nprint('-'*12)\nfor fold in range(1, 6):\n    print('Fold', fold)\n    rmse_ult += [np.sqrt(((predCV_1['fold_'+str(fold)] - predCV_1['rating']) ** 2).mean())]\n    mae_ult += [abs(predCV_1['fold_'+str(fold)] - predCV_1['rating']).mean()]\n    print('RMSE: {:.4f}'.format(np.sqrt(((predCV_1['fold_'+str(fold)] - predCV_1['rating']) ** 2).mean())))\n    print('MAE: {:.4f}'.format(abs(predCV_1['fold_'+str(fold)] - predCV_1['rating']).mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_ult)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_ult)))\nprint('-'*12)\nprint('-'*12)","db797d89":"surprise_results = {'SVD': [np.mean(eval_svd['rmse']), np.mean(eval_svd['mae'])], 'SVDpp': [np.mean(eval_svdpp['rmse']), np.mean(eval_svdpp['mae'])],\\\n                    'NMF': [np.mean(eval_nmf['rmse']), np.mean(eval_nmf['mae'])], 'Biased_NMF': [np.mean(eval_nmfb['rmse']), np.mean(eval_nmfb['mae'])],\\\n                    'kNN_SGD': [np.mean(eval_knnb['rmse']), np.mean(eval_knnb['mae'])], 'kNN_ALS': [np.mean(eval_knnb_1['rmse']), np.mean(eval_knnb_1['mae'])],\\\n                    'Baseline_SVM': [np.mean(rmse_svm), np.mean(mae_svm)], 'Ultimate': [np.mean(rmse_ult), np.mean(mae_ult)]}\nsurprise_results = pd.DataFrame(surprise_results, index=['RMSE', 'MAE']).T\nsurprise_results","9d01abeb":"fig = plt.figure(figsize=(10, 6))\nax = plt.subplot(111)\nax.set_axisbelow(True)\nplt.bar(np.arange(1, 3*surprise_results.shape[0], 3), surprise_results['RMSE']-0.7, width=1, label='RMSE')\nplt.bar(np.arange(2, 3*surprise_results.shape[0], 3), surprise_results['MAE']-0.7, width=1, label='MAE')\nplt.xticks(np.arange(1.5, 3*surprise_results.shape[0], 3), surprise_results.index)\nplt.yticks(np.arange(0, 0.4, 0.1), [0.7, 0.8, 0.9, 1.0])\nplt.grid()\nplt.legend()\nplt.show()","fb6f2142":"a = ratings.copy()\na['pred'] = np.zeros(ratings.shape[0])\nfor i in range(1, 6):\n    a['pred'] = a['pred'] + predCV_1['fold_'+str(i)].replace(np.NaN, 0)\npred_1 = a[a['rating']==1]\npred_2 = a[a['rating']==2]\npred_3 = a[a['rating']==3]\npred_4 = a[a['rating']==4]\npred_5 = a[a['rating']==5]","e386b590":"fig = plt.figure(figsize=(10, 6))\nax = plt.subplot(111)\nhist_4 = plt.hist(pred_4['pred'], bins=100, alpha=0.5, label='4')\nhist_3 = plt.hist(pred_3['pred'], bins=100, alpha=0.5, label='3')\nhist_5 = plt.hist(pred_5['pred'], bins=100, alpha=0.5, label='5')\nhist_2 = plt.hist(pred_2['pred'], bins=100, alpha=0.5, label='2')\nhist_1 = plt.hist(pred_1['pred'], bins=100, alpha=0.5, label='1')\nhandles, labels = ax.get_legend_handles_labels()\nhandles = [handles.pop(2)]+handles\nplt.legend(handles=handles[::-1], title='True Values')\nplt.ylabel('Number of Ratings', fontsize=16)\nplt.xlabel('Prediction Values', fontsize=16)\nplt.title('Prediction Distribution by True Values', fontsize=16)\nplt.xlim(0, 6)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.show()","d264eab0":"fake_1 = pred[pred['rating']==1]\nfake_2 = pred[pred['rating']==2]\nfake_3 = pred[pred['rating']==3]\nfake_4 = pred[pred['rating']==4]\nfake_5 = pred[pred['rating']==5]","319d6678":"fig = plt.figure(figsize=(10, 6))\nax = plt.subplot(111)\nhist_4 = plt.hist(fake_4['pred'], bins=100, alpha=0.5, label='4')\nhist_3 = plt.hist(fake_3['pred'], bins=100, alpha=0.5, label='3')\nhist_5 = plt.hist(fake_5['pred'], bins=100, alpha=0.5, label='5')\nhist_2 = plt.hist(fake_2['pred'], bins=100, alpha=0.5, label='2')\nhist_1 = plt.hist(fake_1['pred'], bins=100, alpha=0.5, label='1')\nhandles, labels = ax.get_legend_handles_labels()\nhandles = [handles.pop(2)]+handles\nplt.legend(handles=handles[::-1], title='True Values')\nplt.ylabel('Number of Ratings', fontsize=16)\nplt.xlabel('Prediction Values', fontsize=16)\nplt.title('Prediction Distribution by True Values (Without Train Test Split)', fontsize=16)\nplt.xlim(0, 6)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.show()","38107c78":"---","63b6333b":"Use the CV best model to recommend movies for user 196.","15ef3fc9":"kNN with SGD baseline.\n\nStochastic Gradient Descent (SGD)\n\n---\n\nGrid Search on kNN","3fc97342":"- **Ultimate Model**\n\n**We can improve all these by combine all models together.**\n\nFirst let's collect the prediction results in a data frame.","265535d8":"Cross-Validation for SVD.","03b909c3":"- **SVD Model**\n\nHere is the Singular Value Decomposition method using the surprise package.","13c37c19":"For each movie we count how many ratings it got, and what's the mean and standard deviation.","221765ca":"We create a pivot table for ratings and store the total mean and standard deviation values.","a3246dae":"Item_based kNN model","04a603a9":"NMF model with biased term. (Similar to SVD)\n\nReduce n_factors to avoid over-fitting.","a23785d3":"Here is the case when we update the coefficient for each fold.","425f7d17":"NMF model after grid search.","c86a14d6":"- **SVD++ Model**\n\nImproved SVD model with implicit terms.","2f4b979c":"For each user, we count how many ratings he or she gives, and the mean and standard deviation as well.","b7b9d201":"Import our Baseline_SVM model from the Baseline notebook","c9da6bb1":"Here we can see how ratings distributed.","6147141d":"- **kNN Model**\n\nK-Nearest Neighbour model with ALS baseline prediction.\n\nAlternating Least Square (ALS)","43178c83":"- **NMF Model**\n\nNon-Negative Matrix Factoraization.","64d6927f":" Import packages and Data","e01a90f1":"Cross-Validation result","1d5a27e4":"So far we will only use the movie title from this DataFrame. We may need the types of the movie later in our model.","3556da07":"Cross Validation\n\nWe start by collect prediction values for 5 folds.","de2be09f":"---\nnumpy.linalg.svd experiment","1f4cadc1":"Add the results from Baseline_SVM into the DataFrame","31996180":"Grid Search on SVDpp model","da3ef547":"Then we apply all this into a linear regression to see the weight we should put on each model.\n\nHere we can also see the RMSE and MAE score before train test split.","58dad40c":"And here is the CV best model's proformance."}}