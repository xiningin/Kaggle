{"cell_type":{"b20a37b1":"code","d3405914":"code","66e3ecd5":"code","b5691fdb":"code","249b956c":"code","86e01540":"code","06cea84c":"code","608094b5":"code","d9ea0d9c":"code","4be36778":"code","84ed2f2c":"code","6afe3356":"code","6508f16e":"code","047d3ede":"code","af9618a4":"code","9c8806e2":"code","8a0228cd":"code","a5f0a0d6":"code","e1f55a20":"code","12c60a7c":"code","b8120e52":"code","2bc57607":"code","dae623d7":"code","9239cc7a":"code","f4b0fe5e":"code","bc5ed766":"code","9dc3a7e7":"code","bcc75d47":"code","074973a9":"code","4f10a934":"markdown","9d648d72":"markdown","44b6d63c":"markdown","3112406c":"markdown","b71071c0":"markdown","16aed260":"markdown","1a15edf3":"markdown","d1f9e28d":"markdown","3e94a03f":"markdown","a4a662a6":"markdown","42a03900":"markdown","bd4fd7f1":"markdown","1504782f":"markdown","66e18579":"markdown","eaba1ad8":"markdown","2ec7bc09":"markdown","95b14be5":"markdown","33924a54":"markdown","c11a644e":"markdown"},"source":{"b20a37b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3405914":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import RobustScaler,StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn import ensemble\nfrom sklearn.metrics import mean_squared_error,r2_score\n","66e3ecd5":"df = pd.read_csv('\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv')\ndf.head()","b5691fdb":"df.shape","249b956c":"df['average_score'] = (df['math score'] + df['reading score'] + df['writing score'])\/3\ndf['average_score']","86e01540":"df['gender'].value_counts()","06cea84c":"df['race\/ethnicity'].value_counts()","608094b5":"df['parental level of education'].value_counts()","d9ea0d9c":"f, ax = plt.subplots(3, 2, figsize=(16, 12))\n\nsns.countplot(x = df['gender'], ax = ax[0][0])\nax[0][0].set_title('Gender', fontsize = 14)\n\nsns.countplot(x = df['race\/ethnicity'], ax = ax[0][1])\nax[0][1].set_title('race\/ethnicity', fontsize = 14)\n\nsns.countplot(x = df['parental level of education'], ax = ax[1][0])\nax[1][0].set_title('parental level of education', fontsize = 14)\n\nsns.countplot(x = df['lunch'], ax = ax[1][1])\nax[1][1].set_title('Lunch', fontsize = 14)\n\nsns.countplot(x = df['test preparation course'], ax = ax[2][0])\nax[2][0].set_title('test preparation course', fontsize = 14)","4be36778":"f, ax = plt.subplots(1, 3, figsize = (24, 6))\n\nsns.barplot(x=df['gender'], y=df['average_score'], ax = ax[0])\nax[0].set_title(\"average score vs gender\")\n\nsns.stripplot(x=df['gender'], y=df['average_score'], ax = ax[1])\nax[1].set_title(\"average score vs gender\")\n\nsns.violinplot(x=df['gender'], y=df['average_score'], ax=ax[2])\nax[2].set_title(\"average score vs gender\")\n\nplt.show()","84ed2f2c":"f, ax = plt.subplots(1, 3, figsize = (24, 6))\n\nsns.barplot(x=df['race\/ethnicity'], y=df['average_score'], ax = ax[0])\nax[0].set_title(\"average score vs race\/ethnicity\")\n\nsns.stripplot(x=df['race\/ethnicity'], y=df['average_score'], ax = ax[1])\nax[1].set_title(\"average score vs race\/ethnicity\")\n\nsns.violinplot(x=df['race\/ethnicity'], y=df['average_score'], ax=ax[2])\nax[2].set_title(\"average score vs race\/ethnicity\")\n\nplt.show()","6afe3356":"f, ax = plt.subplots(1, 3, figsize = (24, 6))\n\nsns.barplot(x=df['parental level of education'], y=df['average_score'], ax = ax[0])\nax[0].set_title(\"average score vs parental level of education\")\n\nsns.stripplot(x=df['parental level of education'], y=df['average_score'], ax = ax[1])\nax[1].set_title(\"average score vs parental level of education\")\n\nsns.violinplot(x=df['parental level of education'], y=df['average_score'], ax=ax[2])\nax[2].set_title(\"average score vs parental level of education\")\n\nplt.show()","6508f16e":"f, ax = plt.subplots(1, 3, figsize = (24, 6))\n\nsns.barplot(x=df['lunch'], y=df['average_score'], ax = ax[0])\nax[0].set_title(\"average score vs lunch\")\n\nsns.stripplot(x=df['lunch'], y=df['average_score'], ax = ax[1])\nax[1].set_title(\"average score vs lunch\")\n\nsns.violinplot(x=df['lunch'], y=df['average_score'], ax=ax[2])\nax[2].set_title(\"average score vs lunch\")\n\nplt.show()","047d3ede":"f, ax = plt.subplots(1, 3, figsize = (24, 6))\n\nsns.barplot(x=df['test preparation course'], y=df['average_score'], ax = ax[0])\nax[0].set_title(\"average score vs test preparation course\")\n\nsns.stripplot(x=df['test preparation course'], y=df['average_score'], ax = ax[1])\nax[1].set_title(\"average score vs test preparation course\")\n\nsns.violinplot(x=df['test preparation course'], y=df['average_score'], ax=ax[2])\nax[2].set_title(\"average score vs test preparation course\")\n\nplt.show()","af9618a4":"df.head()","9c8806e2":"df['gender'].replace({'male':1, 'female':0}, inplace=True)\ndf['race\/ethnicity'].replace({'group A':0, 'group B':1, 'group C':2, 'group D':3, 'group E':4}, inplace=True)\ndf['parental level of education'].replace({'some college':0, \"associate's degree\":1, 'high school':2, 'some high school':3, \"bachelor's degree\":4, \"master's degree\":5},inplace=True)\ndf['lunch'].replace({'standard':0, 'free\/reduced':1}, inplace=True)\ndf['test preparation course'].replace({'none':0, 'completed':1}, inplace=True)","8a0228cd":"df.drop(['math score', 'reading score', 'writing score'], axis=1, inplace=True)","a5f0a0d6":"df.head()","e1f55a20":"plt.figure(figsize = (6, 6))\nsns.distplot(df['average_score'])\nplt.title('average_score distribution')\nplt.show()","12c60a7c":"df['average_score'].skew()","b8120e52":"df['average_score'] = (df['average_score'] - df['average_score'].mean()) \/ df['average_score'].std()","2bc57607":"df.head()","dae623d7":"X = df.drop('average_score', axis=1)\ny = df['average_score']\nX = RobustScaler().fit_transform(X)\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","9239cc7a":"lr = LinearRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\nprint(\"Linear regression score : \", lr.score(X_test, y_test) )\nprint(\"Linear regression Mean squared error : \" , mean_squared_error(y_pred, y_test))","f4b0fe5e":"dt = DecisionTreeRegressor()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nprint(\"Decison tree regressor score : \", dt.score(X_test, y_test) )\nprint(\"Decision tree regressor Mean squared error : \" , mean_squared_error(y_pred, y_test) )","bc5ed766":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\n\nprint(\"Random forest regressor score : \", rf.score(X_test, y_test) )\nprint(\"Random forest regressor Mean squared error : \" , mean_squared_error(y_pred, y_test) )","9dc3a7e7":"rd = Ridge()\nrd.fit(X_train,y_train)\ny_pred = rd.predict(X_test)\n\nprint(\"Ridge regression score : \", rd.score(X_test, y_test) )\nprint(\"Ridge regression Mean squared error : \" , mean_squared_error(y_pred, y_test))","bcc75d47":"params = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}\ngb = ensemble.GradientBoostingRegressor(**params)\ngb.fit(X_train, y_train)\n\nmse = mean_squared_error(y_test, gb.predict(X_test))\n\nprint(\"Gradient boosting regressor score : \", gb.score(X_test, y_test) )\nprint(\"Gradient Boosting regressor Mean squared error : \" , mean_squared_error(y_pred, y_test))","074973a9":"ls = Lasso()\nls.fit(X_train, y_train)\ny_pred = ls.predict(X_test)\n\nprint(\"Lasso regressor score : \", ls.score(X_test, y_test) )\nprint(\"Lasso regressor Mean squared error : \" , mean_squared_error(y_pred, y_test))","4f10a934":"Let's see how our data looks like","9d648d72":"**Linear Regression**","44b6d63c":"**Random forest regressor**","3112406c":"Split into train and test","b71071c0":"**Gneder and average_score**","16aed260":"Female's avearge_score is little bit higher than male.","1a15edf3":"Convert into standard distribution","d1f9e28d":"**test preparation course and average_score**","3e94a03f":"**Decison tree regressor**","a4a662a6":"**We found less mean squared error(0.76) in Linear regression, Ridge and Gradient boosting regressor we can say that this are best model.**","42a03900":"**race\/ethnicity and average_score**","bd4fd7f1":"**lunch and average_score**","1504782f":"Drop math score, reading score and writing score","66e18579":"**Lasso regression**","eaba1ad8":"average_score is negative skewed","2ec7bc09":"**parental level of education and average_score**","95b14be5":"**Ridge regression**","33924a54":"**Gradient boosting regressor**","c11a644e":"Convert categorical to numeric"}}