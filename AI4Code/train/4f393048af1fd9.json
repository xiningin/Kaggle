{"cell_type":{"009eabb4":"code","605273f7":"code","3965227d":"code","8bcac709":"code","fb0fdf7b":"code","1e9fee64":"code","a8381330":"markdown"},"source":{"009eabb4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","605273f7":"import shutil\nimport os\n\nclass BaseLine:\n    def __init__(self):\n        self.input_images_path = '\/kaggle\/input\/physdl-201920-second-challenge\/images\/images'\n        self.csv = '\/kaggle\/input\/physdl-201920-second-challenge\/train.csv'\n        \n        self.input_path = '\/kaggle\/input\/physdl-201920-second-challenge'\n        self.train_path = '\/kaggle\/train'\n        self.test_path = '\/kaggle\/test'\n        self.valid_path = '\/kaggle\/validation'\n\n    \n    def folder_generator(self):\n        import pandas as pd\n        import logging as log\n        import os\n        \n        csv_labels = pd.read_csv(self.csv)\n        \n        images_paths = list(csv_labels['file'])\n        images_paths = [path.replace('images\/', '') for path in images_paths]\n        \n        images_labels = list(csv_labels['is_tiger'])\n        counter = 1\n        \n        tiger_path_train = os.path.join(self.train_path, 'tiger')\n        not_tiger_path_train = os.path.join(self.train_path, 'not_tiger')\n        \n        tiger_path_val = os.path.join(self.valid_path, 'tiger')\n        not_tiger_path_val = os.path.join(self.valid_path, 'not_tiger')\n        \n        test_unknown_path = os.path.join(self.test_path, 'unknown')\n        \n        os.mkdir(self.train_path)\n        os.mkdir(tiger_path_train)\n        os.mkdir(not_tiger_path_train)\n\n        os.mkdir(self.valid_path)\n        os.mkdir(tiger_path_val)\n        os.mkdir(not_tiger_path_val)\n        \n        os.mkdir(self.test_path)\n        os.mkdir(test_unknown_path)\n        \n        #Handling Train Images\n        print('###Handling Train Images')\n        for image_name, image_label in zip(images_paths, images_labels):\n            print('Coping image: {}, with label: {}'.format(image_name, image_label))    \n            if image_name.split('_')[0] == 'train' and counter % 5 != 0:\n                if image_label == 1:\n                    source_dir = os.path.join(self.input_images_path, image_name) \n                    dest_dir = os.path.join(tiger_path_train, image_name)\n                    shutil.copy(source_dir, dest_dir)\n                    counter += 1\n                    print('Coped image: {} to {}'.format(image_name, tiger_path_train))\n                else:\n                    source_dir = os.path.join(self.input_images_path, image_name) \n                    dest_dir = os.path.join(not_tiger_path_train, image_name)\n                    shutil.copy(source_dir, dest_dir)\n                    counter += 1\n                    print('Coped image: {} to {}'.format(image_name, not_tiger_path_train))\n            else:\n                if image_label == 1:\n                    source_dir = os.path.join(self.input_images_path, image_name) \n                    dest_dir = os.path.join(tiger_path_val, image_name)\n                    shutil.copy(source_dir, dest_dir)\n                    counter += 1\n                    print('Coped image: {} to {}'.format(image_name, tiger_path_val))\n                else:\n                    source_dir = os.path.join(self.input_images_path, image_name) \n                    dest_dir = os.path.join(not_tiger_path_val, image_name)\n                    shutil.copy(source_dir, dest_dir)\n                    counter += 1\n                    print('Coped image: {} to {}'.format(image_name, not_tiger_path_val))\n            \n        #Handling Test Images\n        print('###Handling Test Images')\n        list_of_images = os.listdir(self.input_images_path)\n        for image_name in list_of_images:\n            if image_name.split('_')[0] == 'test':\n                source_dir = os.path.join(self.input_images_path, image_name) \n                dest_dir = os.path.join(test_unknown_path, image_name)\n                shutil.copy(source_dir, dest_dir)\n                print('Coped image: {} to {}'.format(image_name, test_unknown_path))\n                      \n        print('Number of All train images: {}'.format(len(os.listdir(tiger_path_train)) + len(os.listdir(not_tiger_path_train))))\n        print('Number of All validation images: {}'.format(len(os.listdir(tiger_path_val)) + len(os.listdir(not_tiger_path_val))))\n        \n        print('Number of All test images: {}'.format(len(os.listdir(self.test_path))))\n        \n        print('Tiger Labels: {}'.format(len([label for label in images_labels if label == 1])))\n        print('NotTiger Labels: {}'.format(len([label for label in images_labels if label != 1])))\n    \n    def data_loader(self):\n        import torch\n        import torchvision\n        from torchvision import transforms\n        #ImageFolder\n        #Augementation for train and valid images\n        train_transforms = transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n\n        val_transforms = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(), \n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n\n        train_dataset = torchvision.datasets.ImageFolder(self.train_path, train_transforms)\n        validation_dataset = torchvision.datasets.ImageFolder(self.valid_path, val_transforms)\n        \n        #DataLoader\n        batch_size = 16\n        train_dataloader = torch.utils.data.DataLoader(\n            train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n        )\n\n        validation_dataloader = torch.utils.data.DataLoader(\n            validation_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n        )\n        print(len(train_dataset), len(validation_dataset))\n        print(len(train_dataloader), len(validation_dataloader))\n        return train_dataloader, validation_dataloader\n    \n    def show_images(self, train_dataloader):\n        import numpy as np\n        import matplotlib.pyplot as plt\n        X_batch, y_batch = next(iter(train_dataloader))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([[0.229, 0.224, 0.225]])\n        for index in range(5):\n            plt.title(y_batch[index])\n            plt.imshow(X_batch[index].permute(1,2,0).numpy() * std + mean, )\n            plt.show()\n    \n    def model(self):\n        from torchvision import models\n        import torch\n        model = models.resnet50(pretrained=True)\n        \n        #Disable grad for all conv layers\n        for param in model.parameters():\n            param.requires_grard = False \n    \n        model.fc = torch.nn.Linear(model.fc.in_features, 2)\n        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        model.to(device)\n        \n        loss = torch.nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(),amsgrad=True, lr=1.0e-3)\n        \n        #Declay LR by a factor of 0.1 every 7th epoch\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n        return model, loss, optimizer, scheduler, device\n    \n    def train_model(self, model, loss, optimizer, scheduler, train, validation, device, num_epochs):\n        import torch\n        from tqdm import tqdm\n        for epoch in range(num_epochs):\n            print('Epoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    dataloader = train\n                    scheduler.step()\n                    model.train()  # Set model to training mode\n                else:\n                    dataloader = validation\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.\n                running_acc = 0.\n\n                # Iterate over data.\n                for inputs, labels in tqdm(dataloader):\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    optimizer.zero_grad()\n\n                    # forward and backward\n                    with torch.set_grad_enabled(phase == 'train'):\n                        preds = model(inputs)\n                        loss_value = loss(preds, labels)\n                        preds_class = preds.argmax(dim=1)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss_value.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss_value.item()\n                    running_acc += (preds_class == labels.data).float().mean()\n\n                epoch_loss = running_loss \/ len(dataloader)\n                epoch_acc = running_acc \/ len(dataloader)\n\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n\n        return model\n\n    \n    def run(self):\n        #Processing data\n        Job = BaseLine()\n        Job.folder_generator()\n        train_dataloader, validation_dataloader = Job.data_loader()\n        Job.show_images(train_dataloader)\n        \n        #Define model\n        model, loss, optimizer, scheduler, device = Job.model()\n        #print(model, loss, optimizer, scheduler)\n        #Train model \n        trained_model = Job.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader, device, num_epochs=5)\n        return trained_model","3965227d":"model = BaseLine().run()","8bcac709":"import numpy as np\nimport torch\nimport torchvision\n\nfrom torchvision import transforms\nfrom tqdm import tqdm\n\nclass ImageFolderWithPath(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPath, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n\ntest_dir = '\/kaggle\/test'\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\nbatch_size = 16     \ntest_dataset = ImageFolderWithPath(test_dir, val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size\n)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","fb0fdf7b":"import matplotlib.pyplot as plt\n\ninputs, labels, paths = next(iter(test_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([[0.229, 0.224, 0.225]])\n\ndef show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","1e9fee64":"import pandas as pd\nfiles = [path.replace('\/kaggle\/test\/unknown\/', 'images\/') for path in test_img_paths]\nsubmission_df = pd.DataFrame.from_dict({'file': files, 'is_tiger': test_predictions})\nsubmission_df.to_csv('submission.csv', index=False)","a8381330":"# PyTorch pipeline\n\n#### Code can be executed without any chanegs. Following will happen:\n1. Created folders:\n - '\/kaggle\/train'\n - \/kaggle\/train\/tiger\n - \/kaggle\/train\/not_tiger\n \n - '\/kaggle\/validation'\n - '\/kaggle\/validation\/tiger'\n - '\/kaggle\/validation\/not_tiger'\n \n - '\/kaggle\/test'\n - '\/kaggle\/test\/unknown'\n \n2. From `\/kaggle\/input\/physdl-201920-second-challenge\/images\/images` images will be copied to folders \n    according to the following principle and using labels train.csv file:\n     - Train\n        - Tiger\n        - NotTiger\n     - Validation (each 5th image if not test according the class)\n        - Tiger\n        - NotTiger\n     - Tets\n        - Unknown\n        \n3. DataLoader will return processed images in format of train_dataloader, validation_dataloader, consist of batches for training and validation.\n4. Show Images function will show few images from prepared batch (cropped, flipped images)\n5. Define Model \n6. Taring and evaluate\n7. ImageFolderWithPath <- redefined PyTorch IamgeFolder to return triple(with path) instead of usual tuple\n8. Make test_dataloader, before apply val_transorms for data\n9. Predict with test data. Observe the results\n\n# So what you can do improve the results: \n1. Use your's choise pretrained model\n```bash\ndef model(self):\n        from torchvision import models\n        import torch\n        model = `models.resnet50(pretrained=True)`\n```\n\n2. Define last layer\/layers as u would like, but unnecessary\n```bash\ndef model(self):\n...\nmodel.fc = torch.nn.Linear(model.fc.in_features, 2)\n```\n\n3. Define yours optimizer and scheduler behaviour\n```bash\ndef model(self):\n...\noptimizer = torch.optim.Adam(model.parameters(),amsgrad=True, lr=1.0e-3)        \nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n```\n\n4. Add ur's augumentation. If so, dont forget to apply val_transforms for test data. \n```bash\ntrain_transforms = transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n\n        val_transforms = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(), \n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n```\n5. Change number of epochs\n```bash\ntrained_model = Job.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader, device, `num_epochs=5`)\n```\n# Caveat\n If you will execute class BaseLine more than 1 time, you will get error:\n `directory already exists`\n Prevent that: comment following line:\n```bash\ndef run(self):\n        #Processing data\n        Job = BaseLine()\n        `Job.folder_generator()`<-- this line. It will each time recreate folders and copy data there. \n        train_dataloader, validation_dataloader = Job.data_loader()\n        Job.show_images(train_dataloader)\n        \n        #Define model\n        model, loss, optimizer, scheduler, device = Job.model()\n        #print(model, loss, optimizer, scheduler)\n        #Train model \n        trained_model = Job.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader, device, num_epochs=1000)\n        return trained_model\n```"}}