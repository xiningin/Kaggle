{"cell_type":{"41aa61cc":"code","30dae0c3":"code","1913baac":"code","272950e2":"code","87f0b04a":"code","33aa96e9":"code","3d5fff3b":"code","d790fc25":"code","13eb889d":"code","debb5ad0":"markdown","af0d849c":"markdown","9c22bec5":"markdown","77007ff3":"markdown","9a66db17":"markdown","6b61f624":"markdown"},"source":{"41aa61cc":"import os\nimport requests\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport Levenshtein\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\npd.options.display.max_colwidth = 500","30dae0c3":"BASE_DIR = \"\/kaggle\/input\/muis-challenge\/\"\ndf_submission = pd.read_csv(f\"{BASE_DIR}\/submission.csv\")\ndf_train = pd.read_csv(f\"{BASE_DIR}\/train.csv\")\ndf_test = pd.read_csv(f\"{BASE_DIR}\/test.csv\")\ndf_synset_meaning = pd.read_csv(f\"{BASE_DIR}\/synset_meaning.csv\")\ndf_synset_meaning[\"word_len\"] = df_synset_meaning.word.apply(len)\nprint(df_train.shape, df_test.shape, df_submission.shape, df_synset_meaning.shape,)","1913baac":"import collections\ndict_synset_meaning = collections.defaultdict(dict)\n\"\"\"\nword : {\n    id1: meaning\n    id2: meaning\n}\n\"\"\"\nfor row in df_synset_meaning.itertuples():\n    dict_synset_meaning[row.word][row.synset_id] = row.meaning.lower()\n# dict_synset_meaning","272950e2":"unique_synset = set(df_synset_meaning.word.unique().tolist())\n\ndef find_closest(query_token):\n    if query_token in unique_synset:\n        return query_token\n    \n    best = float(\"inf\")\n    best_syn = None\n    for syn in unique_synset:\n        d = Levenshtein.distance(query_token, syn)\n        if d < best:\n            best_syn = syn\n            best = d\n    return best_syn\n\ndef find_closest_meaning(text, best_syn):\n    best = float(\"inf\")\n    best_idx = None\n    best_meaning = None\n    for idx, meaning in dict_synset_meaning[best_syn].items():\n        d = Levenshtein.distance(text, meaning)\n        if d < best:\n            best_idx = idx\n            best_meaning = meaning\n            best = d\n    return best_idx, best_meaning","87f0b04a":"oofs = []\nfor i, row in tqdm(df_train.iterrows(), total=df_train.shape[0]):\n    text = row.text.lower()\n    tokens = text.split(\" \")\n    query_tokens = [tok for tok in tokens if row.text_id[1:] in tok]\n    assert len(query_tokens) == 1\n    query_token = query_tokens[0].split(\"#\")[0]\n\n    # find closest synset\n    best_syn = find_closest(query_token)\n    best_idx, best_meaning = find_closest_meaning(text, best_syn)\n    oofs.append((text, query_token, best_syn, best_idx, best_meaning))\n    \ndf_oof = pd.DataFrame(oofs, columns=[\"text\",\"query\", \"pred_synset\", \"synset_id\", \"meaning\"])\ndf_oof.sample(5)","33aa96e9":"print(accuracy_score(df_train.synset_id.values, df_oof.synset_id.values))","3d5fff3b":"predictions = []\nfor i, row in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n    text = row.text.lower()\n    tokens = text.split(\" \")\n    query_tokens = [tok for tok in tokens if row.text_id[1:] in tok]\n    assert len(query_tokens) == 1\n    query_token = query_tokens[0].split(\"#\")[0]\n    # find closest synset\n    best_syn = find_closest(query_token)\n    \n    best_idx, best_meaning = find_closest_meaning(text, best_syn)\n    predictions.append((query_token, best_syn, best_idx, best_meaning))","d790fc25":"df_predictions = pd.DataFrame(predictions, columns=[\"query\", \"pred_synset\", \"synset_id\", \"meaning\"])\ndf_predictions.head()","13eb889d":"df_submission[\"synset_id\"] = df_predictions.synset_id\ndf_submission.to_csv(\"submission.csv\", index=False)\npd.read_csv(\"submission.csv\").sample(5)","debb5ad0":"## Submit \u0445\u0438\u0439\u0445","af0d849c":"## \u04e8\u0433\u04e9\u0433\u0434\u0441\u04e9\u043d label-\u0438\u0439\u043d dictionary \u04af\u04af\u0441\u0433\u044d\u0445","9c22bec5":"## \u0410\u0448\u0438\u0433\u043b\u0430\u0433\u0434\u0430\u0445 \u0441\u0430\u043d\u0433\u0443\u0443\u0434","77007ff3":"## \u0414\u0430\u0442\u0430\u0433\u0430\u0430 \u0443\u043d\u0448\u0438\u0436 \u0430\u0432\u0430\u0445","9a66db17":"## \u0422\u0435\u0441\u0442 \u0434\u0430\u0442\u0430 \u0434\u044d\u044d\u0440 \u0442\u0430\u0430\u043c\u0430\u0433\u043b\u0430\u0445","6b61f624":"## \u0425\u044f\u043b\u0431\u0430\u0440 \u0442\u0430\u0430\u043c\u0430\u0433\u043b\u0430\u043b \u0445\u0438\u0439\u0445\n\u041c\u0430\u043d\u0430\u0439 \u0445\u0430\u0439\u0436 \u0431\u0430\u0439\u0433\u0430\u0430 (`\u0441\u0430\u0440#00000`) \u04af\u0433\u0442\u044d\u0439 \u0445\u0430\u043c\u0433\u0438\u0439\u043d \u043e\u0439\u0440\u0445\u043e\u043d synset-\u0438\u0439\u043d meaning-\u04af\u04af\u0434\u044d\u044d\u0441 \u043c\u0430\u043d\u0430\u0439 \u0442\u0435\u043a\u0441\u0442\u0442\u044d\u0439 \u0445\u0430\u043c\u0433\u0438\u0439\u043d \u0431\u0430\u0433\u0430 Levenstein distance-\u0442\u0430\u0439\u0433 \u043c\u0430\u043d\u0430\u0439 \u0445\u0430\u0440\u0438\u0443 \u0433\u044d\u0436 \u04af\u0437\u044c\u0435."}}