{"cell_type":{"eae39a55":"code","c03ea73c":"code","3c032982":"code","759e5b41":"code","d7227174":"code","972c5b2b":"code","6d6acdd7":"code","bc584be6":"code","32cc75fd":"code","dea1fde4":"code","a32af1b0":"code","28b7aa2a":"code","98ecf672":"code","ee334557":"code","1b99d0f8":"code","0397859f":"code","fbee5126":"code","d7db5c15":"code","8f3a1858":"code","f1df1e7a":"code","5a9eee3f":"code","38e2fb1c":"code","911342fd":"markdown","cccbbb40":"markdown","acd44470":"markdown","6efa465a":"markdown","273803d6":"markdown","592a6889":"markdown","1ae4a2b5":"markdown","46043ca2":"markdown","19e1f7c5":"markdown","5074bf28":"markdown","2f3ea57c":"markdown","d86c6a36":"markdown","a3e7a445":"markdown","96b34f94":"markdown","437b941a":"markdown","73a57f7f":"markdown"},"source":{"eae39a55":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd","c03ea73c":"BASE_PATH = '..\/input\/siim-isic-melanoma-classification'\n#list of images with hair\nhair_images =['ISIC_0078712','ISIC_0080817','ISIC_0082348','ISIC_0109869','ISIC_0155012','ISIC_0159568','ISIC_0164145','ISIC_0194550','ISIC_0194914','ISIC_0202023','ISIC_0083035','ISIC_0068279','ISIC_0109703','ISIC_0149527']","3c032982":"size=1024\nfor img in hair_images:\n    image = cv2.imread(BASE_PATH + '\/jpeg\/train\/' + img + '.jpg')\n    image_resize = cv2.resize(image,(size,size))\n    image_resize = cv2.cvtColor(image_resize,cv2.COLOR_BGR2RGB)\n    plt.imshow(image_resize)\n    plt.show()","759e5b41":"lower_limit = 20# the value that I found helpful\n\n#*********#*********PROCEDURE*********#*********#*********#\n###################################\ngrayScale = cv2.cvtColor(image_resize, cv2.COLOR_RGB2GRAY)\n\n# Kernel for the morphological filtering\nkernel = cv2.getStructuringElement(1,(17,17))\n\n# Perform the blackHat filtering on the grayscale image to find the hair countours\nblackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n\n# intensify the hair countours  \n_ ,threshold = cv2.threshold(blackhat,20,255,cv2.THRESH_BINARY)\n#######################################\nthreshold = cv2.bitwise_not(threshold)\nplt.imshow(threshold,cmap = 'gray')\n","d7227174":"def img(image_name,lower_limit=20):    \n    '''\n    Helper Function to help us iterate with our code!!   \n    \n    \n    '''\n\n    image = cv2.imread(BASE_PATH + '\/jpeg\/train\/' + image_name + '.jpg')\n    image_resize = cv2.resize(image,(size,size))\n   \n    grayScale = cv2.cvtColor(image_resize, cv2.COLOR_RGB2GRAY)\n\n    # Kernel for the morphological filtering\n    kernel = cv2.getStructuringElement(1,(17,17))\n\n    # Perform the blackHat filtering on the grayscale image to find the hair countours\n    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n\n    # intensify the hair countours in preparation for the inpainting \n    _ ,threshold = cv2.threshold(blackhat,lower_limit,255,cv2.THRESH_BINARY)\n    \n    # inpaint the original image depending on the mask\n    final_image = cv2.inpaint(image_resize,threshold,1,cv2.INPAINT_TELEA)\n    \n    threshold = cv2.bitwise_not(threshold)\n    image_resize = cv2.cvtColor(image_resize,cv2.COLOR_BGR2RGB)\n    final_image = cv2.cvtColor(final_image,cv2.COLOR_BGR2RGB)\n    \n    return image_resize,threshold,final_image","972c5b2b":"image_1,_,_ = img(hair_images[0]) ","6d6acdd7":"plt.title('The second image')\nplt.imshow(image_1)\nplt.show()","bc584be6":"image_2,hair_mask_2,_ = img(hair_images[1])","32cc75fd":"plt.title('The second image')\nplt.imshow(image_2)\nplt.show()","dea1fde4":"plt.title('The hair mask of the second image')\nplt.imshow(hair_mask_2,cmap = 'binary_r')\nplt.show()","a32af1b0":"plt.title('image 1 after the hair mask of the secong image on it')\nplt.imshow(cv2.bitwise_and(image_1,image_1,mask = hair_mask_2))","28b7aa2a":"for i,img_name in enumerate(hair_images) :\n    _,hair_mask,_ = img(img_name)\n    plt.title(f'{i},{img_name}')\n    plt.imshow(cv2.bitwise_and(image_1,image_1,mask = hair_mask))\n    plt.show()","98ecf672":"possible_cands = [0,1,3,4,6,9,13]# possible candidates ","ee334557":"all_hair_masks = []","1b99d0f8":"for i,img_id in enumerate(possible_cands):\n    _,hair_masks,_ = img(hair_images[img_id])\n    all_hair_masks.append(hair_masks) \n    cv2.imwrite(f'image_{i}.jpg',hair_masks)\n    print(len(all_hair_masks))","0397859f":"all_hair_masks = np.array(all_hair_masks)","fbee5126":"np.save('hair_array.npy',all_hair_masks.astype(np.uint8))","d7db5c15":"import albumentations as albu\nimport tensorflow as tf","8f3a1858":"#loading the hairs\nhairs = np.load('..\/input\/really-realistic-hair-augmentations\/hair_array.npy')\n#the random transformations we want to apply on the masks\nhair_trans = albu.Compose([\n    albu.ShiftScaleRotate(rotate_limit=[-45,45],scale_limit=[-0.1,0.1],\n                          shift_limit=[-0.1,0.15],border_mode=3,value=0,p=1.)])\n\n#our augmenter\nfrom numpy.random import choice\ndef hair_mask(hairs,IMAGE_SIZE,p = 0.3):\n    chance = np.random.uniform(0,1,1)\n    if chance <= p:\n        mask_to_chose = choice(np.arange(7), 1,p=[0.2,0.2,0.22,0.15,0.14,0.06,0.03])[0]\n        mask = hairs[mask_to_chose]\n        \n        mask = hair_trans(image = mask)['image']\n        mask = cv2.resize(mask\/255,(IMAGE_SIZE,IMAGE_SIZE),cv2.INTER_CUBIC)\n        mask[mask == 1.] =  255\n        mask[mask != 255.] = 0\n        \n        \n    else:\n        mask = np.ones((IMAGE_SIZE,IMAGE_SIZE))\n    return mask","f1df1e7a":"msk = hair_mask(hairs,IMAGE_SIZE=256,p=1.).astype(np.uint8)\nplt.imshow(msk,cmap = 'binary_r')","5a9eee3f":"img = cv2.imread('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/ISIC_0015719.jpg')\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nimg = cv2.resize(img,(256,256))\n\nplt.imshow(cv2.bitwise_and(img,img,mask= msk))","38e2fb1c":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, filelist_x, targets, batch_size=128, shuffle=False, augment=False, labels=True): \n\n        self.filelist_x = filelist_x\n        self.targets = targets\n        self.augment = augment\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.labels = labels\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.filelist_x) \/\/ self.batch_size\n        ct += int((len(self.filelist_x) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self,index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        if self.augment: X = self.__augment_batch(X)\n        if self.labels: return X, y\n        else: return X\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange( len(self.filelist_x) )\n        if self.shuffle: np.random.shuffle(self.indexes)\n\n    def __data_generation(self,indexes):\n        'Generates data containing batch_size samples'   \n\n        X = np.array([lycon.load(self.filelist_x[indexes][i]) for i in range(len(indexes))])\n        y = self.targets[indexes]\n        \n        return X, y\n \n    def __random_transform(self, img):\n        composition = albu.Compose([\n            albu.OneOf([\n                albu.ShiftScaleRotate(rotate_limit=[-90,90],scale_limit=[-0.42,0.35],shift_limit=0,border_mode=0,value=0,p=0.5),\n                albu.CoarseDropout(max_holes=16,max_height=200\/\/10,max_width=200\/\/10,fill_value=0,p=0.5)\n            ], p=0.5),\n            albu.ShiftScaleRotate(rotate_limit=0, scale_limit=0., shift_limit=0.15, border_mode=0, value=0, p=0.5)\n        ])\n        image = composition(image=img)['image']\n        ##############################################################}\n        mask =  hair_mask(hairs,IMAGE_SIZE,p = 0.3).astype(np.uint8)##} This area!!\n        image = cv2.bitwise_and(image,image,mask = mask)##############}\n        ##############################################################}\n        return image\n    \n    def __augment_batch(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i, ] = self.__random_transform(img_batch[i, ])\n        return img_batch","911342fd":"## Let's look for the best quality hair(s) for later use","cccbbb40":"## STEP 2) getting the second image and it's hair mask","acd44470":"## STEP 3) applying the hair mask of image 2 one on image 1","6efa465a":"# Extracting hair masks from images","273803d6":"### selecting the possible candidates for hairs that can be used for our images","592a6889":"# Import Libraries","1ae4a2b5":"## STEP 1) getting the first image","46043ca2":"# viewing the images","19e1f7c5":"1) in your kernel click on '+Add data'\n\n2) Click on 'Kernel Output Files'\n\n3) Search for \"Really Realistic Hair Augmentations\"\n\n4) If you see my kernel, add it\n\n5) then do the following :--","5074bf28":"### and use it in your data loader!!\n## Example\njust find the place where i implemented it!!","2f3ea57c":"### looks good to me!!","d86c6a36":"## How to use them??","a3e7a445":"## Note: We save the hairs as an array as there is often loss of info with images","96b34f94":"## Enjoy!!","437b941a":"* Experiment with `lower_limit` to get hair with removed noise\n* Note that `lower_limit` is the sensitivity of the threshold of obtaining the mask.. too low value can lead to addition of noise and too high value can lead to loss of info of hair","73a57f7f":"changes every time when run if blank then don't worry!!(only when you change the prob!!)"}}