{"cell_type":{"75a4bfc3":"code","90081dc6":"code","f392af83":"code","5a70cc37":"code","86da3f16":"code","f35e686b":"code","a616f2ca":"code","d8ced483":"code","a44afba8":"code","1ce8b1a8":"code","ef2ff947":"code","ca84fd46":"code","71c1df7d":"code","cbb440ac":"code","fd92c3eb":"code","5db35209":"code","6807a3bc":"code","b96e0a27":"code","da8537df":"code","563e94cc":"code","6b9a0d09":"code","78f7c342":"code","e17d8c62":"code","6d880266":"code","dcc3b58e":"code","e8908f8c":"code","cf8fb8e2":"code","ddb97437":"code","ef2b664b":"code","b7826731":"code","3e8662fb":"code","282026c9":"code","6a300f9d":"code","6aba25bb":"code","65771492":"code","5ec22083":"code","268439eb":"code","166276f3":"code","02f51313":"code","b84967cb":"code","e12bd888":"markdown","03bbf3ef":"markdown","6758ee3a":"markdown","4d961460":"markdown","74608ad7":"markdown","c43c6602":"markdown","1958322b":"markdown","185b48f2":"markdown","28a3b704":"markdown","df0aab76":"markdown","ac5a4cc4":"markdown"},"source":{"75a4bfc3":"import os\nfrom skimage.io import imread # for reading images\nimport matplotlib.pyplot as plt # for showing plots\nfrom skimage.filters import median # for filtering the data\nfrom skimage.measure import label # for labeling bubbles\nfrom skimage.morphology import disk # for morphology neighborhoods\nfrom skimage.morphology import erosion, dilation, opening # for disconnecting bubbles\nimport numpy as np # for matrix operations and array support\nfrom skimage.util import montage as montage2d\nfrom skimage import img_as_float","90081dc6":"%matplotlib inline\nimport matplotlib.pyplot as plt # setup plots nicely\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})","f392af83":"image_path = '..\/input\/training.tif'\nem_image = imread(image_path)\nprint(\"Data Loaded, Dimensions\", em_image.shape)","5a70cc37":"%matplotlib inline\n\nem_idx = np.random.permutation(range(em_image.shape[0]))[0]\nem_slice = em_image[em_idx]\nprint(\"Slice Loaded, Dimensions\", em_slice.shape)\n# show the slice and histogram\nfig, (ax1, ax2) = plt.subplots(1,2, figsize = (8, 4))\nax1.imshow(em_slice, cmap = 'gray')\nax1.axis('off')\nax2.hist(em_slice.ravel()) # make it 1d to make a histogram\nax2.set_title('Intensity Histogram')","86da3f16":"%matplotlib inline\n# create the basic coordinates\nxx, yy = np.meshgrid(np.linspace(-1,1, em_slice.shape[1]), \n                    np.linspace(-1,1, em_slice.shape[0]))\ndef _make_slope(scale, ang_min = -np.pi, ang_max = np.pi):\n    x_angle = np.random.uniform(ang_min, ang_max)\n    return scale*(np.cos(x_angle)*xx+np.sin(x_angle)*yy)\n\ndef _make_periodic_slope(scale_h, scale_w, escale = 2):\n    x_angle = np.random.uniform(-0.2,0.2)\n    n_x = scale_w*(np.cos(x_angle)*xx+np.sin(x_angle)*yy)\n    return scale_h*np.exp(escale*np.sin(n_x))\n\ndef _make_periodic_artifact(scale_h, scale_w, scale_w2):\n    x_angle = np.random.uniform(-0.2,0.2)\n    n_xx = xx + np.random.uniform(-0.01, 0.01, size = xx.shape)\n    n_yy = yy + np.random.uniform(-0.01, 0.01, size = xx.shape)\n    n_x = (np.cos(x_angle)*n_xx+np.sin(x_angle)*n_yy)\n    n_sx = np.abs(0.5*(np.sin(scale_w*n_x)+np.sin(scale_w2*n_x)))-0.5\n    return 1+scale_h*n_sx\n\ndef _make_gaussian_bump(width, height, depth):\n    x_cent, y_cent = np.random.uniform(-1,1, size = 2)\n    return depth*np.exp(-(np.power((xx-x_cent)\/width, 2)+\n                                 np.power((yy-y_cent)\/height,2)\n                                )\n                       )\ndef _make_bumps(count, depth, min_width = 0.1, max_width = 0.8):\n    out_img = None\n    for _ in range(count):\n        out_bump = _make_gaussian_bump(np.random.uniform(min_width, max_width),\n                                      np.random.uniform(min_width, max_width),\n                                      depth)\n        out_img = out_bump if out_img is None else out_img+out_bump\n    return out_img\nfig, m_axs = plt.subplots(2,3, figsize = (9,6))\nfor c_bump_ax, c_img_ax in m_axs.T:\n    s_bumps = _make_periodic_slope(1.0, 30,1)\n    \n    s_bumps = _make_periodic_artifact(0.5, 30, 35)\n    a_bumps = _make_bumps(6, 15, 0.2, 0.9)\n    c_bump = 60*s_bumps + a_bumps\n    c_bump_ax.imshow(c_bump, cmap = 'magma')\n    c_bump_ax.axis('off')\n    c_bump_ax.set_title('Bump Map')\n    c_bump_slice = (s_bumps*em_slice+a_bumps).clip(0,255).astype(np.uint8)\n    c_img_ax.imshow(c_bump_slice, cmap='gray')\n    c_img_ax.axis('off')\n    c_img_ax.set_title('Slice w\/BG')","f35e686b":"# create a library of test images from one slice\n%matplotlib inline\nX_train = np.stack([(em_slice*_make_periodic_artifact(0.5, 30, 35)+_make_bumps(6, 15, 0.2, 0.9)).clip(0,255).astype(np.uint8) for i in range(9)],0)\nplt.imshow(montage2d(X_train), cmap = 'gray')","a616f2ca":"from skimage import img_as_float\n\nfrom skimage.morphology import reconstruction\nfrom skimage.filters import gaussian, median, rank\n\nfrom skimage.morphology import disk\n\ndef rolling_ball_background(in_image, radius):\n    bg_image = rank.mean(in_image, disk(radius))\n    out_image = img_as_float(in_image) - img_as_float(bg_image)\n    return out_image","d8ced483":"fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (12, 4))\nax1.imshow(em_slice, cmap = 'gray')\nax1.set_title('Original Image')\nax2.imshow(X_train[0], cmap = 'gray')\nax2.set_title('Image w\/BG')\nax3.imshow(median(X_train[0], disk(3)), cmap = 'gray')\nax3.set_title('Background Corrected')","a44afba8":"radii = np.linspace(1, 300, 8)\nmse = []\nfor i, radius in enumerate(radii):\n    mse += [ np.mean(np.power((\n        median(img_as_float(X_train[0]), disk(radius))-img_as_float(em_slice)\n                              ).ravel()\n                               ,2))]\nplt.plot(radii,mse)","1ce8b1a8":"fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (12, 4))\nax1.imshow(em_slice, cmap = 'gray')\nax1.set_title('Original Image')\nax2.imshow(X_train[0], cmap = 'gray')\nax2.set_title('Image w\/BG')\nax3.imshow(rolling_ball_background(X_train[0], 100), cmap = 'gray')\nax3.set_title('Background Corrected')","ef2ff947":"radii = np.linspace(20, 220, 8)\nmse = []\nfor i, radius in enumerate(radii):\n    mse += [ np.mean(np.power((rolling_ball_background(X_train[0], radius)-\n                               img_as_float(em_slice) # convert the ground truth to a float as well\n                              ).ravel()\n                               ,2))]\nplt.plot(radii,mse)","ca84fd46":"%%time\nfrom itertools import product\ntrain_idx = np.random.choice(range(em_image.shape[0]),size=8)\naug_count = 8\nX_train = np.stack([(em_image[i]*_make_periodic_artifact(0.5, 30, 35)+\n                     _make_bumps(6, 15, 0.2, 0.9)).clip(0,255).astype(np.uint8) for i, _ in \n                    product(train_idx,range(aug_count))],0)\n\nY_train = np.stack([em_image[i] for i, _ in product(train_idx,range(aug_count))],0)\n\n# convert to float\nX_train = np.expand_dims(img_as_float(X_train),-1) \nY_train = np.expand_dims(img_as_float(Y_train),-1) \n\nmean_x_val = X_train.mean()\nmean_y_val = Y_train.mean()\nprint('X_offset', mean_x_val, 'Y_offset', mean_y_val)\nX_train -= mean_x_val\nY_train -= mean_y_val\n\n_, x_wid, y_wid, c_wid = Y_train.shape\nprint('train', X_train.shape)","71c1df7d":"import keras.backend as K\nK.set_image_dim_ordering('tf')\nfrom keras.models import Sequential, Model, Input\nfrom keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, BatchNormalization, concatenate, merge, Conv2DTranspose\nfrom keras.optimizers import SGD, Adam\nDEFAULT_OPT = Adam(lr=6e-3)\nOUT_ACT = 'tanh'\nsmooth = 0.5\ndef dice_coef(y_true, y_pred):\n    #y_true_f = K.flatten(y_true)\n    #y_pred_f = K.flatten(y_pred)\n    y_true_f = K.batch_flatten(y_true)\n    y_pred_f = K.batch_flatten(y_pred)\n    return (2. * K.dot(y_true_f, K.transpose(y_pred_f)) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\ndef compile_model(i_model):\n    i_model.compile(optimizer = DEFAULT_OPT, loss = 'mse', metrics = ['mse', dice_coef])","cbb440ac":"def _build_one_model(in_shape, out_chan, kernel_size=1):\n    raw_img = Input(shape = in_shape, name = 'InputImage')\n    simple_filter = Convolution2D(filters=out_chan,\n                                  kernel_size=(kernel_size,kernel_size), \n                                  padding='same', \n                                  name = '{0}x{0}Filter'.format(kernel_size),\n                                  activation=OUT_ACT)(raw_img)\n    one_cnn_model = Model(inputs = [raw_img], outputs=[simple_filter])\n    compile_model(one_cnn_model)\n    return one_cnn_model\n\none_cnn_model = _build_one_model((x_wid, y_wid, c_wid), 1)\n# andrej says 4e-3 but that seems too high\nloss_history = []\none_cnn_model.summary()","fd92c3eb":"%matplotlib inline\nim_args = dict(cmap='gray', vmin=-1,vmax=1)\ndef show_prediction(c_model = one_cnn_model, show_idx = 0):\n    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (9, 3))\n    im_args = dict(cmap='gray', vmin=-1,vmax=1)\n    ax1.imshow(X_train[show_idx,:,:,0],**im_args)\n    ax1.axis('off')\n    ax1.set_title('Noisy Input')\n    ax2.imshow(c_model.predict(X_train[show_idx:(show_idx+1)])[0,:,:,0], **im_args)\n    ax2.set_title('Filter Output')\n    ax2.axis('off')\n    ax3.imshow(Y_train[show_idx,:,:,0],**im_args)\n    ax3.axis('off')\n    ax3.set_title('Ground Truth')\n\ndef show_validations(c_model = one_cnn_model, show_idx = 2):\n    fig, m_axs = plt.subplots(show_idx,3, figsize = (9, 3*show_idx))\n    im_args = dict(cmap='gray', vmin=-1,vmax=1)\n    for (ax1, ax2, ax3) in m_axs:\n        v_idx = np.random.choice(range(em_image.shape[0]),size=1)\n        gt_img = em_image[v_idx]\n        in_img = (gt_img*_make_periodic_artifact(0.5, 30, 35)+\n                     _make_bumps(6, 15, 0.2, 0.9)).clip(0,255).astype(np.uint8) \n\n        in_img=np.expand_dims(img_as_float(in_img),-1)-mean_x_val\n        gt_img = img_as_float(gt_img)-mean_y_val\n        print(gt_img.shape)\n        ax1.imshow(in_img[0,:,:,0],**im_args)\n        ax1.axis('off')\n        ax1.set_title('Validiting Input')\n        ax2.imshow(c_model.predict(in_img)[0,:,:,0], **im_args)\n        ax2.set_title('Filter Output')\n        ax2.axis('off')\n        ax3.imshow(gt_img[0],**im_args)\n        ax3.axis('off')\n        ax3.set_title('Ground Truth')","5db35209":"loss_history += [one_cnn_model.fit(X_train, Y_train, epochs = 1)]\nshow_prediction()","6807a3bc":"loss_history += [one_cnn_model.fit(X_train, Y_train, epochs = 10, shuffle = True, verbose = False)]\nshow_prediction()","b96e0a27":"from scipy.ndimage import gaussian_filter\nlarge_one_cnn_model = _build_one_model((x_wid, y_wid, c_wid), 1, kernel_size=65)\n# initialize more intelligently\n[w, b] = large_one_cnn_model.layers[-1].get_weights()\nw = 5e-2*np.random.uniform(-1, 1, size=w.shape)\nw[32, 32] = 1.5\n# smooth out the weights\nw[:, :, 0, 0] = gaussian_filter(w[:, :, 0, 0], 1.25)\n# add smaller noise on top of it\nw+=5e-3*np.random.uniform(-1, 1, size=w.shape)\nlarge_one_cnn_model.layers[-1].set_weights([w, b])\nlarge_one_cnn_model.compile(optimizer=Adam(3e-4), loss='mse', metrics=['mse', dice_coef])\nloss_history = []\nlarge_one_cnn_model.summary()\nshow_validations(large_one_cnn_model)","da8537df":"loss_history += [large_one_cnn_model.fit(X_train, Y_train, epochs=5)]\nshow_prediction(large_one_cnn_model)","563e94cc":"cnn_weights = large_one_cnn_model.layers[-1].get_weights()[0][:,:, 0, 0]\nmax_val = np.percentile(np.abs(cnn_weights), 100)\nplt.colorbar(\n    plt.matshow(\n        cnn_weights,\n        cmap='RdBu',\n        vmin=-max_val,\n        vmax=max_val\n    )\n)","6b9a0d09":"loss_history += [large_one_cnn_model.fit(X_train, Y_train, epochs=25, shuffle=True, verbose=False)]\nshow_validations(large_one_cnn_model)","78f7c342":"cnn_weights = large_one_cnn_model.layers[-1].get_weights()[0][:,:, 0, 0]\nmax_val = np.percentile(np.abs(cnn_weights), 100)\nplt.colorbar(\n    plt.matshow(\n        cnn_weights,\n        cmap='RdBu',\n        vmin=-max_val,\n        vmax=max_val\n    )\n)","e17d8c62":"def _build_mult_model(in_shape, out_chan, layers = 2, kernel_size=3):\n    raw_img = Input(shape = in_shape, name = 'InputImage')\n    last_img = raw_img\n    for i in range(2):\n        last_img = Convolution2D(filters=np.power(2,i+1),\n                                      kernel_size=(kernel_size,kernel_size), \n                                 padding='same', \n                                 name = '{0}x{0}Filter_{1}'.format(kernel_size, i),\n                                      activation='relu')(last_img)\n    \n    last_img = concatenate([raw_img, last_img])\n    \n    last_filter = Convolution2D(filters=out_chan,\n                                  kernel_size=(1,1), padding='valid', name = '1x1Filter_Out',activation=OUT_ACT)(last_img)\n    \n    mult_1x1_model = Model(inputs = [raw_img], outputs=[last_filter])\n    compile_model(mult_1x1_model)\n    return mult_1x1_model\n\nmult_1x1_model = _build_mult_model((x_wid, y_wid, c_wid), 1)\n# andrej says 4e-3 but that seems too high\nloss_history = []\nmult_1x1_model.summary()","6d880266":"from keras.utils.vis_utils import model_to_dot\nfrom IPython.display import SVG\n# Define model\nvmod = model_to_dot(mult_1x1_model, show_shapes=True)\nvmod.write_svg('mult_model.svg')\nSVG('mult_model.svg')","dcc3b58e":"loss_history += [mult_1x1_model.fit(X_train, Y_train, epochs = 10, shuffle = True, batch_size=8)]\nshow_prediction(mult_1x1_model)","e8908f8c":"mult_33x33_model = _build_mult_model((x_wid, y_wid, c_wid), 1, kernel_size=33)\n# andrej says 4e-3 but that seems too high\nloss_history = []\nmult_33x33_model.summary()","cf8fb8e2":"loss_history += [mult_33x33_model.fit(X_train, Y_train, epochs = 10, shuffle = True, batch_size=16)]\nshow_prediction(mult_33x33_model)","ddb97437":"# DeepConCat Model\ndef _build_concat_model(in_shape, out_chan, layers = 2, blocks = 4, use_deconv = False):\n    raw_img = Input(shape = in_shape, name = 'InputImage')\n    start_img = raw_img\n    last_img = raw_img\n    for k in range(blocks):\n        ds_fact = np.power(2,k)\n        clayers = layers if (ds_fact == 1) or (not use_deconv) else layers - 1\n        if ds_fact>1:\n            last_img = MaxPooling2D(pool_size=(ds_fact, ds_fact), name = 'Pooling_B{}'.format(k))(last_img)\n        for i in range(clayers):\n            last_img = Convolution2D(filters=np.power(2,i+1)+k,\n                                          kernel_size=(3,3), \n                                     padding='same', \n                                     name = '3x3Filter_B{}_L{}'.format(k,i),\n                                          activation='relu')(last_img)\n        if ds_fact>1:\n            if not use_deconv:\n                last_img = UpSampling2D(size=(ds_fact, ds_fact), name = 'UpSampling_B{}'.format(k))(last_img)\n            else:\n                last_img = Conv2DTranspose(filters = np.power(2,layers)+k, kernel_size = (ds_fact, ds_fact), \n                                       padding='same',\n                                      strides = (ds_fact, ds_fact), activation = 'relu', \n                                       data_format = K.image_data_format(),name= 'Deconvolution_B{}'.format(k))(last_img)\n        last_img = concatenate([start_img, last_img])\n        start_img = last_img\n    last_img = concatenate([raw_img, last_img])\n    last_filter = Convolution2D(filters=out_chan,\n                                  kernel_size=(1,1), \n                                padding='valid', \n                                name = '1x1Filter_Out',\n                                activation=OUT_ACT)(last_img)\n    \n    deep_cc_model = Model(inputs = [raw_img], outputs=[last_filter])\n    compile_model(deep_cc_model)\n    return deep_cc_model\n\ndcc_model = _build_concat_model((x_wid, y_wid, c_wid), 1)\n# andrej says 4e-3 but that seems too high\nloss_history = []\ndcc_model.summary()","ef2b664b":"from keras.utils.vis_utils import model_to_dot\nfrom IPython.display import SVG\n# Define model\nvmod = model_to_dot(dcc_model, show_shapes=True)\nvmod.write_svg('deepcc_model.svg')\nSVG('deepcc_model.svg')","b7826731":"loss_history += [dcc_model.fit(X_train, Y_train, epochs = 10, shuffle = True, batch_size=1)]\nshow_prediction(dcc_model)","3e8662fb":"from skimage.util import montage as montage2d\n#plt.cm.R\nmt_args = dict(cmap='gray', vmin=-0.5, vmax = 0.5)\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (20,9))\nax1.imshow(montage2d(X_train[:,:,:,0]), **mt_args)\nax2.imshow(montage2d(dcc_model.predict(X_train, batch_size = 2)[:,:,:,0]), **mt_args)\nax3.imshow(montage2d(Y_train[:,:,:,0]), **mt_args)","282026c9":"%matplotlib inline\nepich = np.cumsum(np.concatenate([np.linspace(0.5,1,len(mh.epoch)) for mh in loss_history]))\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (20,5))\n_ = ax1.plot(epich,np.concatenate([mh.history['loss'] for mh in loss_history]),'b-')\n           # epich,np.concatenate([mh.history['val_loss'] for mh in loss_history]),'r-')\nax1.legend(['Training', 'Validation'])\nax1.set_title('Loss')\n\n\n_ = ax3.semilogy(epich,np.concatenate([mh.history['mean_squared_error'] for mh in loss_history]),'b-')\n    #epich,np.concatenate([mh.history['val_mean_squared_error'] for mh in loss_history]),'r-')\nax3.legend(['Training', 'Validation'])\nax3.set_title('MSE')\n\n_ = ax2.plot(epich,np.concatenate([mh.history['dice_coef'] for mh in loss_history]),'b-')\n    #epich,np.concatenate([mh.history['val_dice_coef'] for mh in loss_history]),'r-')\nax2.legend(['Training', 'Validation'])\nax2.set_title('Dice Coefficient')","6a300f9d":"fig_cnt = int(np.sqrt(len(dcc_model.weights)))\nfig, c_axs = plt.subplots(fig_cnt, fig_cnt, figsize = (20, 20))\nim_settings = {'vmin': -0.25, 'vmax': 0.25, 'cmap': 'RdBu', 'interpolation': 'none'}\nfor n_weight, n_weight_tensor, c_ax in zip(dcc_model.get_weights(), dcc_model.weights, c_axs.flatten()):\n    c_mat = n_weight.squeeze()\n    #print(c_mat.shape)\n    if len(c_mat.shape) == 1:\n        ind = np.array(range(len(c_mat)))\n        c_ax.bar(ind, c_mat)\n    elif len(c_mat.shape) == 2:\n        c_ax.imshow(c_mat, **im_settings)\n    elif len(c_mat.shape) == 3:\n        print(c_mat.shape)\n        c_ax.imshow(montage2d(c_mat), **im_settings)\n    elif len(c_mat.shape) == 4:\n        c_ax.imshow(montage2d(np.stack([montage2d(c_layer) for c_layer in c_mat],0)), **im_settings)\n    c_ax.set_title('{}\\n{}'.format(n_weight_tensor.name, c_mat.shape))\n    c_ax.axis('off')","6aba25bb":"# deep residual Model\nfrom keras.layers import add, Activation\ndef _build_resnet_model(in_shape, out_chan, \n                        layers = 2, blocks = 5, \n                        start_block = 0,\n                        use_deconv = False,\n                       always_conv_skip = False,\n                       max_depth = 16):\n    raw_img = Input(shape = in_shape, name = 'InputImage')\n    start_img = raw_img\n    last_img = raw_img\n    layer_depth = lambda i,k: np.clip(np.power(2,i+k+1-start_block),1,max_depth)\n    for k in range(start_block,blocks):\n        ds_fact = np.power(2,k)\n        \n        clayers = layers if (ds_fact == 1) or (not use_deconv) else layers - 1\n        if ds_fact>1:\n            last_img = MaxPooling2D(pool_size=(ds_fact, ds_fact), name = 'Pooling_B{}'.format(k))(last_img)\n        for i in range(clayers):\n            last_img = Convolution2D(filters=layer_depth(i,k),\n                                          kernel_size=(3,3), \n                                     padding='same', \n                                     name = '3x3_Filter_B{}_L{}'.format(k,i),\n                                          activation='linear')(last_img)\n            last_img = BatchNormalization(name = 'BN_B{}_L{}'.format(k,i))(last_img)\n            if i<(layers-1):\n                last_img = Activation('relu')(last_img)\n        if ds_fact>1:\n            if not use_deconv:\n                last_img = UpSampling2D(size=(ds_fact, ds_fact), name = 'UpSampling_B{}'.format(k))(last_img)\n            else:\n                last_img = Conv2DTranspose(filters = layer_depth(layers-1,k), \n                                           kernel_size = (ds_fact, ds_fact), \n                                       padding='same',\n                                      strides = (ds_fact, ds_fact), activation = 'linear', \n                                       data_format = K.image_data_format(),name= 'Deconvolution_B{}'.format(k))(last_img)\n        \n        cur_depth = layer_depth(layers-1,k)\n        if (start_img._keras_shape[-1]!=cur_depth) or (always_conv_skip):\n            # only perform the convolution on the last input if necessary\n            start_img_match = Convolution2D(filters=cur_depth,\n                                          kernel_size=(1,1), \n                                     padding='same', \n                                     name = '1x1_Filter_B{}_L{}'.format(k,i),\n                                          activation='linear')(start_img)\n        else:\n            start_img_match = start_img\n            \n        last_img = add([start_img_match, last_img], name = 'Add_B{}'.format(k))\n        last_img = Activation('relu')(last_img)\n        start_img = last_img\n    last_filter = Convolution2D(filters=out_chan,\n                                  kernel_size=(1,1), \n                                padding='valid', \n                                name = '1x1Filter_Out',\n                                activation=OUT_ACT)(last_img)\n    \n    deep_res_model = Model(inputs = [raw_img], outputs=[last_filter])\n    compile_model(deep_res_model)\n    return deep_res_model\n\nrs_model = _build_resnet_model((x_wid, y_wid, c_wid), 1, \n                               blocks = 6,\n                               start_block = 0)\nloss_history = []\nrs_model.summary()","65771492":"from keras.utils.vis_utils import model_to_dot\nfrom IPython.display import SVG\n# Define model\nvmod = model_to_dot(rs_model, show_shapes=True)\nvmod.write_svg('deepres_model.svg')\nSVG('deepres_model.svg')","5ec22083":"from IPython.display import clear_output\nfor i in range(5):\n    clear_output()\n    loss_history += [rs_model.fit(X_train, Y_train, epochs = 4, shuffle = True, batch_size=1)]\n    plt.close('all')\n    show_prediction(rs_model)","268439eb":"show_validations(rs_model, 4)","166276f3":"fig_cnt = int(np.sqrt(len(rs_model.weights)))\nfig, c_axs = plt.subplots(fig_cnt, fig_cnt, figsize = (25, 25))\nim_settings = {'vmin': -0.25, 'vmax': 0.25, 'cmap': 'RdBu', 'interpolation': 'none'}\nfor n_weight, n_weight_tensor, c_ax in zip(rs_model.get_weights(), rs_model.weights, c_axs.flatten()):\n    try:\n        c_mat = n_weight.transpose([2,3,0,1])\n    except:\n        c_mat = n_weight#.swapaxes(0,-1)\n    #print(c_mat.shape)\n    if len(c_mat.shape) == 1:\n        ind = np.array(range(len(c_mat)))\n        c_ax.bar(ind, c_mat)\n    elif len(c_mat.shape) == 2:\n        c_ax.imshow(c_mat, **im_settings)\n    elif len(c_mat.shape) == 3:\n        print(c_mat.shape)\n        c_ax.imshow(montage2d(c_mat), **im_settings)\n    elif len(c_mat.shape) == 4:\n        c_ax.imshow(montage2d(np.stack([montage2d(c_layer) for c_layer in c_mat],0)), **im_settings)\n    c_ax.set_title('{}\\n{}'.format(n_weight_tensor.name, c_mat.shape))\n    c_ax.axis('off')","02f51313":"def small_tile_gen(tile_x, tile_y):\n    while True:\n        slice_idx = np.random.choice(train_x.shape[0])\n        x_pos = np.random.choice(range(0, train_x.shape[1]-tile_x))\n        y_pos = np.random.choice(range(0, train_x.shape[2]-tile_y))\n        yield (train_x[slice_idx:slice_idx+1, x_pos:(x_pos+tile_x), y_pos:(y_pos+tile_y)],\n              train_y[slice_idx:slice_idx+1, x_pos:(x_pos+tile_x), y_pos:(y_pos+tile_y)])","b84967cb":"fig, m_ax = plt.subplots(2, 4)\n[iax.axis('off') for iax in m_ax.flatten()]\n(ax_in, ax_out) = m_ax\nfor c_iax, c_oax, (c_x, c_y) in zip(ax_in, ax_out, small_tile_gen(96, 96)):\n    c_iax.imshow(c_x[0,:,:,0], **im_args)\n    c_iax.set_title('In')\n    c_oax.imshow(c_y[0,:,:,0], **im_args)\n    c_oax.set_title('Out')","e12bd888":"# Applying Simple CNNs","03bbf3ef":"# ResNet\nHere we build a deep resent model\n![ResNet](https:\/\/raw.githubusercontent.com\/torch\/torch.github.io\/master\/blog\/_posts\/images\/resnets_1.png)","6758ee3a":"# Much Deeper Concatenation","4d961460":"Here we show the convolutional kernel the model learned","74608ad7":"### Larger Convolution\nTry learning a larger kernel ","c43c6602":"### Concatenate with Larger Kernel Size","1958322b":"# Rolling Ball\nHere we use a rolling ball background subtraction to improve the image","185b48f2":"# Using Small Tiles","28a3b704":"# Overview\nBackground correction is a difficult problem, here we synthetically add common problems like non-flatfield background and noise to determine which approaches work best","df0aab76":"### Larger Concatenation Models","ac5a4cc4":"# Median Filter\nHere we apply a simple median filter to remove the background noise"}}