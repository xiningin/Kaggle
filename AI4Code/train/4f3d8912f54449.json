{"cell_type":{"179f4d41":"code","83f4a8a6":"code","58feaec8":"code","cbe4a8bd":"code","f37737ac":"code","c843ffbb":"code","52781334":"code","f688bb8d":"code","49cf810b":"code","ca9ffca7":"code","6170d55e":"code","91dda14d":"code","bd558561":"code","a20f77c1":"code","34d4c99a":"code","e8424d0e":"code","9d682ea6":"code","a4af56da":"code","25dc54bc":"code","2002e259":"code","d2cfb140":"code","be38ab1a":"code","7e55c42a":"code","7e6bc3c7":"code","d2ff291d":"code","a6eada3e":"code","f8dcf3c4":"code","4593f64c":"code","cbe40d63":"code","ab330b37":"code","f1202af6":"code","584bad6b":"code","7cf56c40":"code","e4367234":"code","93e11003":"markdown","956951a0":"markdown","64b0d9d0":"markdown","473a8ee4":"markdown","dc7ed49f":"markdown","3ee45fc9":"markdown","434838c2":"markdown","f546d224":"markdown","d057c6bf":"markdown","f27739a8":"markdown"},"source":{"179f4d41":"import numpy as np \nimport pandas as pd\nimport seaborn as sb    \nimport matplotlib.pylab as plt\nimport sklearn\nfrom statistics import mode as m\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","83f4a8a6":"#Cargando los dataset\ndf_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndf_gender = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","58feaec8":"df_train.head()","cbe4a8bd":"df_train.describe()","f37737ac":"#Cuadr\u00edcula de m\u00faltiples histogramas para trazar relaciones condicionales.\ngraph1 = sb.FacetGrid(df_train, col='Survived')\ngraph1.map(plt.hist,'Age')","c843ffbb":"#Analizando por sexo\nsex_graph = sb.countplot(x=\"Survived\", hue=\"Sex\", data=df_train)","52781334":"#Graficando sobrevivientes por Classe de Pasajero\nsb.countplot(x='Survived',data= df_train,hue='Pclass')","f688bb8d":"#Graficando sobrevivientes por valor de tarifa\ngraph2 = sb.FacetGrid(df_train, col='Survived')\ngraph2.map(plt.hist,'Fare')","49cf810b":"#comprobando el tipo de datos de cada columna\ndf_train.isnull().sum()","ca9ffca7":"#comprobando los valores \u00fanicos por columna\ndf_train.nunique()","6170d55e":"def grupos_edad(df):\n    df[\"Early_childhood\"]= df[\"Age\"].apply(lambda x: 1 if x in range(0,6) else 0)\n    df[\"Childhood\"]= df[\"Age\"].apply(lambda x: 1 if x in range(6,12) else 0)\n    df[\"Adolescence\"]= df[\"Age\"].apply(lambda x: 1 if x in range(12,19) else 0)\n    df[\"Youth\"]= df[\"Age\"].apply(lambda x: 1 if x in range(19,27) else 0)\n    df[\"Adulthood\"]= df[\"Age\"].apply(lambda x: 1 if x in range(27,60) else 0)\n    df[\"Old_age\"]= df[\"Age\"].apply(lambda x: 1 if x >= 60 else 0)\n    df.drop(\"Age\", axis='columns', inplace=True)\n    return df\n\ndef PreprocessingPipeline(df):\n    #Seleccionando \u00fanicamnete las features con valores nulos menor al 25% y por valores \u00fanicos.\n    columns_to_drop = [\"Name\", \"PassengerId\", \"Ticket\", \"Cabin\"]\n    dataframe = df.drop(columns_to_drop, axis='columns')\n    \n    #Tratando los missing values en columnas Age y Embarked\n    fare_mean = dataframe['Fare'].mean()\n    age_mean = dataframe['Age'].mean()\n    moda_value = m(dataframe['Embarked'])\n    \n    dataframe['Age']=dataframe['Age'].fillna(age_mean)\n    dataframe['Fare']=dataframe['Fare'].fillna(fare_mean)\n    dataframe['Embarked']=dataframe['Embarked'].fillna(moda_value)\n    \n    #Creando nuevas features \n    ##Rangos de Edad\n    dataframe = grupos_edad(dataframe)\n    \n    #Encodeando valores de texto\n    #dataframe = pd.get_dummies(dataframe) #Empleando get_dummies inicialmente\n    dataframe[\"Sex_male\"]= dataframe[\"Sex\"].apply(lambda x: 1 if x==\"male\" else 0)\n    dataframe[\"Sex_female\"]= dataframe[\"Sex\"].apply(lambda x: 1 if x==\"female\" else 0)\n    dataframe[\"Embarked_C\"]= dataframe[\"Embarked\"].apply(lambda x: 1 if x==\"C\" else 0)\n    dataframe[\"Embarked_Q\"]= dataframe[\"Embarked\"].apply(lambda x: 1 if x==\"Q\" else 0)\n    dataframe[\"Embarked_S\"]= dataframe[\"Embarked\"].apply(lambda x: 1 if x==\"S\" else 0)\n    dataframe = dataframe.drop([\"Sex\", \"Embarked\"], axis='columns')\n    return dataframe","91dda14d":"df_train_processed = PreprocessingPipeline(df_train)","bd558561":"df_train_processed.head(10)","a20f77c1":"#Preparando los sub-dataframes de entrenamiento y prueba\ny = df_train_processed['Survived']\nX = df_train_processed.drop('Survived', axis='columns')\n\n#En lugar de hacer partici\u00f3n es recomendable entrenar en todo el dataset de Train para obtener un mejor score final en kaggle.\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=66)\n\nX_train = X\ny_train = y","34d4c99a":"#Importando los modelos necesarios\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\n#Otros\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix","e8424d0e":"# RandomForest model\nn_estimators = [100, 300, 500]\nmax_depth = [5, 8, 15]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 5] \n\nparameters = dict(n_estimators = n_estimators, max_depth = max_depth,  \n                  min_samples_split = min_samples_split, \n                  min_samples_leaf = min_samples_leaf)\n\nrandom_forest_model = RandomForestClassifier(n_estimators=100)\n\ngrid_forest = GridSearchCV(random_forest_model, parameters, scoring='roc_auc', cv = 3, verbose = 1, \n                      n_jobs = -1)\n\ngrid_forest = grid_forest.fit(X_train, y_train)","9d682ea6":"#Obteniendo las predicciones\nrandom_forest_model = grid_forest.best_estimator_\n#rfm_predictions = random_forest_model.predict(X_test)\nrfm_predictions = random_forest_model.predict(X_train)","a4af56da":"#Evaluaci\u00f3n del Random Forest Model\nprint(\"Accuracy: \", accuracy_score(y_train, rfm_predictions))\nprint(\"ROUC AUC SCORE: \", roc_auc_score(y_train, rfm_predictions))","25dc54bc":"#Tomando una funci\u00f3n de utilidad de https:\/\/github.com\/DTrimarchi10\/confusion_matrix \n\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()\/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) \/ float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] \/ sum(cf[:,1])\n            recall    = cf[1,1] \/ sum(cf[1,:])\n            f1_score  = 2*precision*recall \/ (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sb.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","2002e259":"rf_cm = confusion_matrix(y_train, rfm_predictions)\n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['No Sobrevivi\u00f3', 'Sobrevivi\u00f3']\nmake_confusion_matrix(rf_cm, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","d2cfb140":"xgb_parameters = {\"max_depth\":[2,5],\n              \"n_estimators\":[25,50,100],\n              \"learning_rate\":[0.05, 0.01, 0.5]}","be38ab1a":"xgb_model = XGBClassifier(use_label_encoder = False)\n\ngrid_xgb = GridSearchCV(xgb_model, xgb_parameters, scoring='roc_auc', cv = 3, verbose = 1, n_jobs = -1)\n\ngrid_xgb = grid_xgb.fit(X_train, y_train)","7e55c42a":"xgb_model = grid_xgb.best_estimator_","7e6bc3c7":"#xgb_predictions =  xgb_model.predict(X_test)\nxgb_predictions =  xgb_model.predict(X_train)","d2ff291d":"xb_cm = confusion_matrix(y_train, xgb_predictions)\n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['No Sobrevivi\u00f3', 'Sobrevivi\u00f3']\nmake_confusion_matrix(xb_cm, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","a6eada3e":"svc_parameters = {\"C\":[1,10,100],\n                  \"kernel\":['linear','gaussian']}","f8dcf3c4":"svc_model = SVC(gamma='auto')\ngrid_svc = GridSearchCV(svc_model, svc_parameters, scoring='roc_auc', cv = 3, verbose = 1, n_jobs = -1)\ngrid_svc = grid_svc.fit(X_train, y_train)","4593f64c":"svc_model = grid_svc.best_estimator_\n#svc_predictions = svc_cmodel.predict(X_test)\nsvc_predictions = svc_model.predict(X_train)","cbe40d63":"svc_cm = confusion_matrix(y_train, svc_predictions)\n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['No Sobrevivi\u00f3', 'Sobrevivi\u00f3']\nmake_confusion_matrix(svc_cm, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","ab330b37":"voting_model = VotingClassifier(estimators=[('random_forest', random_forest_model), \n                                            ('xgboost', xgb_model), \n                                            ('SVM', svc_model)], voting='hard',weights=[1,2,1])\nvoting_model = voting_model.fit(X_train, y_train)","f1202af6":"voting_predictions = voting_model.predict(X_train)","584bad6b":"voting_cm = confusion_matrix(y_train, voting_predictions)\n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['No Sobrevivi\u00f3', 'Sobrevivi\u00f3']\nmake_confusion_matrix(voting_cm, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","7cf56c40":"passengers = df_test['PassengerId']\ntest_data = PreprocessingPipeline(df_test)\npredictions = xgb_model.predict(test_data)","e4367234":"output = pd.DataFrame({ 'PassengerId' : passengers, 'Survived': predictions })\noutput.to_csv('titanic-predictions.csv', index = False)\noutput.head()","93e11003":"# Creando archivo de evaluaci\u00f3n de Kaggle","956951a0":"# Creando un modelo de Voting Ensamble","64b0d9d0":"Las columnas \"PassangerId\", \"Name\" presentan valores \u00fanicos por cada registro por lo cual se descarta para entrenamiento.  \nTicket tambi\u00e9n presenta muchos valores \u00fanicos pero se considerar\u00e1 a futuro extraer alguna informaci\u00f3n \u00fatil.","473a8ee4":"# Data preprocessing","dc7ed49f":"| Variable | Definici\u00f3n                                 | Valor                                          |\n|----------|--------------------------------------------|------------------------------------------------|\n| survival | Supervivencia                              | 0 = No, 1 = Si                                 |\n| pclass   | Clase de Ticket                            | 1 = 1ra, 2 = 2da, 3 = 3ra                      |\n| sex      | Sexo                                       |                                                |\n| Age      | Edad en a\u00f1os                               |                                                |\n| sibsp    | # de hermanos\/c\u00f3nyuges a bordo del Titanic |                                                |\n| parch    | # de padres \/ hijos a bordo del Titanic    |                                                |\n| ticket   | N\u00famero de ticke                            |                                                |\n| fare     | Tarifa de pasaje                           |                                                |\n| cabin    | N\u00famero de Cabi                             |                                                |\n| embarked | Puerto de Embarque                         | C = Cherbourg, Q = Queenstown, S = Southampton |","3ee45fc9":"## XGBOOST","434838c2":"## Random Forest","f546d224":"# Supported Vector Machines","d057c6bf":"# Explorative Data Analysis","f27739a8":"# Entrenando los modelos"}}