{"cell_type":{"258ecc8b":"code","8a63d9b7":"code","e02dd7bb":"code","012690c8":"code","234437a1":"code","99ee7514":"code","4175bc0e":"code","3594e0ab":"code","b9d72e0d":"code","29225dae":"code","073cd030":"code","4fc8af9c":"code","1676f845":"markdown","3129c714":"markdown","36952aaf":"markdown","bdb27a71":"markdown","9cdcc0ee":"markdown","96843971":"markdown","cadeddea":"markdown","0f8ee5ac":"markdown","fb6c2660":"markdown","36b90fde":"markdown"},"source":{"258ecc8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8a63d9b7":"X_train = pd.read_csv(\"..\/input\/train.csv\")\n\nX_train.count()","e02dd7bb":"fig = plt.figure(figsize =(18,6))\nplt.subplot2grid((2,3),(0,0))\nX_train.Survived.value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Survived\")\nplt.subplot2grid((2,3),(0,1))\nplt.scatter(X_train.Survived, X_train.Age, alpha = 0.1)\nplt.title(\"Survived wrt Age\")\nplt.subplot2grid((2,3),(0,2))\nX_train.Pclass.value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Class\")\n\nplt.subplot2grid((2,3),(1,0), colspan =2)\nfor x in [1,2,3]:\n    X_train.Age[X_train.Pclass==x].plot(kind='kde')\nplt.title(\"Age wrt Class\")\nplt.legend((\"1st\",\"2nd\",\"3rd\"))\n\nplt.subplot2grid((2,3),(1,2))\nX_train.Embarked.value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Embarked\")\nplt.show()","012690c8":"fig = plt.figure(figsize =(18,6))\nplt.subplot2grid((2,3),(0,0))\nX_train.Survived.value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Survived\")\n\nplt.subplot2grid((2,3),(0,1))\nX_train.Survived[X_train.Sex=='male'].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Men Survived\")\n\nplt.subplot2grid((2,3),(0,2))\nX_train.Survived[X_train.Sex =='female'].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Women Survived\")\n\nplt.subplot2grid((2,3),(1,0))\nX_train.Sex[X_train.Survived==1].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Gender of Survived\")\nplt.subplot2grid((2,3),(1,1), colspan =2)\nfor x in [1,2,3]:\n    X_train.Survived[X_train.Pclass==x].plot(kind='kde')\nplt.title(\"Class wrt Survived\")\nplt.legend((\"1st\",\"2nd\",\"3rd\"))\n\nplt.show()","234437a1":"fig = plt.figure(figsize =(18,6))\nplt.subplot2grid((2,2),(0,0))\nX_train.Survived[(X_train.Sex=='male')& (X_train.Pclass==1)].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Rich Men Survived\")\n\nplt.subplot2grid((2,2),(0,1))\nX_train.Survived[(X_train.Sex=='male')& (X_train.Pclass==3)].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Poor Men Survived\")\n\nplt.subplot2grid((2,2),(1,0))\nX_train.Survived[(X_train.Sex=='female')& (X_train.Pclass==1)].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Rich Women Survived\")\n\nplt.subplot2grid((2,2),(1,1))\nX_train.Survived[(X_train.Sex=='female')& (X_train.Pclass==3)].value_counts(normalize = True).plot(kind =\"bar\", alpha = 0.5)\nplt.title(\"Poor Women Survived\")","99ee7514":"trains = pd.read_csv(\"..\/input\/train.csv\")\ntrains.shape\ntrains [\"hyp\"] = 0\ntrains.loc[trains.Sex == \"female\", \"hyp\"]=1\ntrains[\"result\"]=0\ntrains.loc[trains.Survived==trains[\"hyp\"], \"result\"]=1\nprint (trains[\"result\"].value_counts(normalize = True))","4175bc0e":"trains[\"Fare\"] = trains[\"Fare\"].fillna(trains[\"Fare\"].median())\nW_avg = (trains.loc[trains.Sex=='female']).mean()\nprint (W_avg.Age)\ntrains.loc[trains.Sex=='female'] = trains.loc[trains.Sex=='female'].fillna(W_avg.Age)\nM_avg = (trains.loc[trains.Sex=='male']).mean()\nprint(M_avg)\ntrains.loc[trains.Sex=='male'] = trains.loc[trains.Sex == 'male'].fillna(M_avg.Age)\ntrains.count()","3594e0ab":"fig = plt.figure(figsize=(20,8))\nplt.subplot2grid((2,3),(0,0))\ntrains.Survived[(trains.Age<=27) & (trains.Sex=='female')].value_counts(normalize=True).plot(kind='bar', alpha = 0.7)\nplt.title(\"Young Women\")\n\nplt.subplot2grid((2,3),(0,1))\ntrains.Survived[(trains.Age>27) & (trains.Sex=='female')].value_counts(normalize=True).plot(kind='bar', alpha = 0.7)\nplt.title(\"Old Women\")\n\nplt.subplot2grid((2,3),(1,0))\ntrains.Survived[(trains.Age<=27) & (trains.Sex=='male')].value_counts(normalize=True).plot(kind='bar', alpha = 0.7)\nplt.title(\"Young Men\")\n\n\nplt.subplot2grid((2,3),(1,1))\ntrains.Survived[(trains.Age>27) & (trains.Sex=='male')].value_counts(normalize=True).plot(kind='bar', alpha = 0.7)\nplt.title(\"Old Men\")\n\nplt.show()","b9d72e0d":"trains.loc[trains[\"Sex\"]=='male','Sex'] = 0\ntrains.loc[trains[\"Sex\"]=='female','Sex'] = 1\n\ntrains[\"Embarked\"] = trains[\"Embarked\"].fillna(\"S\")\ntrains.loc[trains[\"Embarked\"]=='S','Embarked'] = 0\ntrains.loc[trains[\"Embarked\"]=='C','Embarked'] = 1\ntrains.loc[trains[\"Embarked\"]=='Q','Embarked'] = 2\n","29225dae":"from sklearn import linear_model\ntarget = trains [\"Survived\"].values\nfeatures = trains[[\"Pclass\",\"Age\",\"Sex\",\"Parch\",\"Fare\",\"SibSp\"]].values\nclassifier = linear_model.LogisticRegression()\nclassif = classifier.fit(features,target)\nprint (classif.score(features,target))","073cd030":"from sklearn.naive_bayes import MultinomialNB\n\nclassifier2 = MultinomialNB().fit(features,target)\nprint(classifier2.score(features,target))","4fc8af9c":"from sklearn.tree import DecisionTreeClassifier\nclassifier3 = DecisionTreeClassifier(max_leaf_nodes = 5, random_state = 0)\nclassifier3.fit(features,target)\nprint(classifier3.score(features,target))","1676f845":"***plotting and finding more correlation***","3129c714":"***We see that Naive Bayes Multinomial gave a bad accuracy***","36952aaf":"***Using Linear Regression for starters***","bdb27a71":"***Using Naive Bayes Classifier to check if it Improves***","9cdcc0ee":"***Data Cleaning : From Categorical to Numerical***","96843971":"***Filling in the NA data in Age by taking means of Females and Males separately and filling them using .fillna() method*** ","cadeddea":"***Crude Algorithm***\n\nAssumption from the above observations that females having the maximum chances for Survival.","0f8ee5ac":"***Using Decision Tree Classfier***","fb6c2660":"The rights to this data set are reserved with the owner. ","36b90fde":"***Using Random Forest to check if the model can be tuned further***\n"}}