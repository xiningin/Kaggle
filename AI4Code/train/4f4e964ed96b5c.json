{"cell_type":{"5175fa73":"code","01798e0e":"code","00b82eb0":"code","1f048652":"code","d3eb6fea":"code","2c7a9551":"code","fc04433a":"code","69a76bca":"code","26f44aaa":"code","9cf49093":"code","4d2a4f75":"code","622f4f5e":"code","9e9ac2cc":"code","73ff4eaa":"code","d9c78221":"code","19207742":"code","7ae77bd4":"code","e5c7f501":"code","07e1fb0e":"code","ab68e2f3":"code","e7a4fc99":"code","04b81d55":"code","ad4b3a58":"code","a54796a3":"code","994cc66d":"code","1f7e20be":"code","747aa055":"code","d4e5fd75":"code","5991186a":"code","b975a807":"code","7daa6e3b":"code","ab8a655e":"code","e4be0d02":"code","8443532c":"code","7226a7b7":"code","9208f399":"code","c826752a":"code","3c9d6049":"code","e2b8583f":"code","2d6b66fd":"code","68d62b33":"code","d471921d":"code","72aaab02":"code","f325df76":"code","55236a1d":"code","12e58039":"code","785c9568":"code","5d43f3a4":"code","2742d5d4":"code","d4be40d5":"code","fb06a56e":"code","daabd1e1":"code","684c2838":"code","a02f4f4a":"code","d98413f0":"code","9dc6a4ed":"code","a9e25549":"code","4126218c":"code","6334a039":"code","4e569117":"code","ca30f777":"code","bb17a7e4":"code","924c6b09":"code","f136dbab":"code","78976478":"code","8ac448e9":"code","03fa9ce3":"code","d24296f3":"code","a8029df6":"code","be0c3e62":"code","106a2f71":"code","a890dca3":"code","cc369beb":"code","bd678b7a":"code","ac5d2bbf":"code","467141bb":"code","f9a87c34":"markdown","1bbb4a1c":"markdown","34db7279":"markdown","d42e9e52":"markdown","d922a1c1":"markdown","9f4b12d8":"markdown","2fdff1d7":"markdown","e9cffdbd":"markdown","b1a593e5":"markdown","328d7ac5":"markdown","56b69eeb":"markdown","cf74ce1b":"markdown","5aaa9134":"markdown","c1146478":"markdown","bfd02b26":"markdown","da21d55b":"markdown","2f1b181f":"markdown","b5b08f8e":"markdown","4ee7d904":"markdown","75bedf51":"markdown","d2f834fe":"markdown","9c598e36":"markdown","5df36f1b":"markdown","b6a9326a":"markdown","6793d5b2":"markdown","a4a5c5b1":"markdown","f975c741":"markdown","63809469":"markdown","3db640af":"markdown","4debc65e":"markdown","455555e7":"markdown","569d98e6":"markdown","0cbf31f6":"markdown","2cd1fcc0":"markdown","a680f904":"markdown","0f2e2ece":"markdown","fb80ae23":"markdown","5bfb92e2":"markdown"},"source":{"5175fa73":"#importing the necessary libraries\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nimport cv2\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import backend as K\nfrom matplotlib import pyplot as plt \n\nimport scipy\nimport IPython\nimport keras \nimport sklearn.metrics as Metric_tools\nfrom sklearn.model_selection import train_test_split\n\n\n%load_ext autoreload\n%autoreload 2\n\n","01798e0e":"# Reading the folder architecture of Kaggle to get the dataset path.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","00b82eb0":"# Reading the Train and Test Datasets.\ntrain_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","1f048652":"# Let's see the shape of the train and test data\nprint(train_data.shape, test_data.shape)","d3eb6fea":"print(\"Training Data : \")\ntrain_data.head(3).iloc[:,:17]","2c7a9551":"print(\"Testing Data : \")\ntest_data.head(3).iloc[:,:17]","fc04433a":"print(\"Description of the training : \")\ndisc_train = train_data.describe().T\ndisc_train.iloc[1:10, :]","69a76bca":"print(\"Description of the testing : \")\ndisc_test = test_data.describe().T\ndisc_test.iloc[:10, :]","26f44aaa":"fig, ax_arr = plt.subplots(1, 2, figsize=(14, 4))\nfig.subplots_adjust(wspace=0.25, hspace=0.025)\n\nax_arr = ax_arr.ravel()\n\nsets = iter([(disc_train, \"training\"), (disc_test, \"testing\")])\nfor i, ax in enumerate(ax_arr):\n    set_ = next(sets)\n    ax.plot(set_[0].loc[:, \"mean\"], label=\"Mean\")\n    ax.set_title(\"Mean of the {} features.\".format(set_[1]))\n    ax.set_xlabel('Pixels')\n    ax.set_ylabel('Mean')\n    ax.set_xticks([0, 120, 250, 370, 480, 600, 720])\n    ax.legend(loc=\"upper left\", shadow=True, frameon=True, framealpha=0.9)\n    ax.set_ylim([0, 150])\nplt.show()","9cf49093":"train_data_norm = train_data.iloc[:, 1:] \/ 255.0\ntest_data_norm = test_data \/ 255.0","4d2a4f75":"disc_train = train_data_norm.describe().T\ndisc_test = test_data_norm.describe().T","622f4f5e":"fig, ax_arr = plt.subplots(1, 2, figsize=(14, 4))\nfig.subplots_adjust(wspace=0.25, hspace=0.025)\n\nax_arr = ax_arr.ravel()\n\nsets = iter([(disc_train, \"training\"), (disc_test, \"testing\")])\nfor i, ax in enumerate(ax_arr):\n    set_ = next(sets)\n    ax.plot(set_[0].loc[:, \"mean\"], label=\"Mean\")\n    ax.set_title(\"Mean of the {} features.\".format(set_[1]))\n    ax.set_xlabel('Pixels')\n    ax.set_ylabel('Mean')\n    ax.set_xticks([0, 120, 250, 370, 480, 600, 720])\n    ax.legend(loc=\"upper left\", shadow=True, frameon=True, framealpha=0.9)\n    ax.set_ylim([0, 150])\nplt.show()","9e9ac2cc":"rand_indices = np.random.choice(train_data_norm.shape[0], 64, replace=False)\nexamples = train_data_norm.iloc[rand_indices, :]\n\nfig, ax_arr = plt.subplots(8, 8, figsize=(6, 5))\nfig.subplots_adjust(wspace=.025, hspace=.025)\n\nax_arr = ax_arr.ravel()\nfor i, ax in enumerate(ax_arr):\n    ax.imshow(examples.iloc[i, :].values.reshape(28, 28), cmap=\"gray\")\n    ax.axis(\"off\")\n    \nplt.show()    ","73ff4eaa":"plt.figure(figsize=(10, 5))\nplt.hist(train_data.iloc[:, 0], bins=10, edgecolor=\"black\", facecolor=\"lightblue\")\nplt.xlabel('Number in the output.')\nplt.ylabel('Frequency.')\nplt.title('Distribution of numbers.')\nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nplt.xlim([0, 9])\npass","d9c78221":"num_examples_train = train_data.shape[0]\nnum_examples_test = test_data.shape[0]\nn_h = 32\nn_w = 32\nn_c = 3","19207742":"Train_input_images = np.zeros((num_examples_train, n_h, n_w, n_c))\nTest_input_images = np.zeros((num_examples_test, n_h, n_w, n_c))","7ae77bd4":"for example in range(num_examples_train):\n    Train_input_images[example,:28,:28,0] = train_data.iloc[example, 1:].values.reshape(28,28)\n    Train_input_images[example,:28,:28,1] = train_data.iloc[example, 1:].values.reshape(28,28)\n    Train_input_images[example,:28,:28,2] = train_data.iloc[example, 1:].values.reshape(28,28)\n    \nfor example in range(num_examples_test):\n    Test_input_images[example,:28,:28,0] = test_data.iloc[example, :].values.reshape(28,28)\n    Test_input_images[example,:28,:28,1] = test_data.iloc[example, :].values.reshape(28,28)\n    Test_input_images[example,:28,:28,2] = test_data.iloc[example, :].values.reshape(28,28)","e5c7f501":"for example in range(num_examples_train):\n    Train_input_images[example] = cv2.resize(Train_input_images[example], (n_h, n_w))\n    \nfor example in range(num_examples_test):\n    Test_input_images[example] = cv2.resize(Test_input_images[example], (n_h, n_w))","07e1fb0e":"Train_labels = np.array(train_data.iloc[:, 0])","ab68e2f3":"print(\"Shape of train input images : \", Train_input_images.shape)\nprint(\"Shape of test input images : \", Test_input_images.shape)\nprint(\"Shape of train labels : \", Train_labels.shape)","e7a4fc99":"from keras.preprocessing.image import ImageDataGenerator\n\nimage_generator = ImageDataGenerator(\n    rotation_range=27,\n    width_shift_range=0.3,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=False,\n    samplewise_center=True,\n    samplewise_std_normalization=True\n)\nvalidation_datagen = ImageDataGenerator()","04b81d55":"pretrained_model = keras.applications.resnet50.ResNet50(input_shape=(n_h, n_w, n_c),\n                                                        include_top=False, weights='imagenet')\n\nmodel = keras.Sequential([\n    pretrained_model,\n    keras.layers.Flatten(),\n    keras.layers.Dense(units=60, activation='relu'),\n    keras.layers.Dense(units=10, activation='softmax')\n])","ad4b3a58":"model.summary()","a54796a3":"Optimizer = 'RMSprop'\n\nmodel.compile(optimizer=Optimizer, \n                loss='sparse_categorical_crossentropy',\n                metrics=['accuracy'])","994cc66d":"train_images, dev_images, train_labels, dev_labels = train_test_split(Train_input_images, \n                                                                      Train_labels,\n                                                                      test_size=0.1, train_size=0.9,\n                                                                      shuffle=True,\n                                                                      random_state=44)\ntest_images = Test_input_images","1f7e20be":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen  = ImageDataGenerator(\n    rotation_range=27,\n    width_shift_range=0.3,\n    height_shift_range=0.2,\n    shear_range=0.3,\n    zoom_range=0.2,\n    horizontal_flip=False)\n\nvalidation_datagen = ImageDataGenerator()","747aa055":"class myCallback(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get('accuracy') > 0.999999):\n            print(\"Stop training!\")\n            self.model.stop_training = True","d4e5fd75":"callbacks = myCallback()","5991186a":"EPOCHS = 5\nbatch_size = 212\n\nhistory = model.fit_generator(train_datagen.flow(train_images,train_labels, batch_size=batch_size),\n                         steps_per_epoch=train_images.shape[0] \/ batch_size, \n                         epochs=EPOCHS,   \n                         validation_data=validation_datagen.flow(dev_images,dev_labels,\n                                                                 batch_size=batch_size),\n                         validation_steps=dev_images.shape[0] \/ batch_size,\n                         callbacks=[callbacks])","b975a807":"plt.style.use('ggplot')  \n \nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']  \nloss = history.history['loss'] \nval_loss = history.history['val_loss'] \n\nepochs = range(len(acc))\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 5))\nfig.subplots_adjust(wspace=0.15, hspace=0.025)\nax = ax.ravel()\n\nax[0].plot(epochs, acc, 'r', label='Training accuracy')\nax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\nax[0].set_title('Training and validation accuracy')\nax[0].legend(loc=\"upper left\", shadow=True, frameon=True, fancybox=True, framealpha=0.9)\n\nax[1].plot(epochs, loss, 'r', label='Training Loss')\nax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\nax[1].set_title('Training and validation loss')\nax[1].legend(loc=\"upper right\", shadow=True, frameon=True, fancybox=True, framealpha=0.9)\n\nplt.show()","7daa6e3b":"# submission = pd.read_csv('..\/input\/digit-recognizer-submission\/submission.csv')\n# submission.to_csv('digit_submission.csv', index=False)","ab8a655e":"# Reading the folder architecture of Kaggle to get the dataset path.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e4be0d02":"# Reading the Train and Test Datasets.\nmnist_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nmnist_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","8443532c":"# Let's see the shape of the train and test data\nprint(mnist_train.shape, mnist_test.shape)","7226a7b7":"mnist_train.info()","9208f399":"mnist_test.info()","c826752a":"# Looking at a few rows from the data isn't a bad idea.\nmnist_train.head()","3c9d6049":"# and yeah, here you will see the basic statistical insights of the numerical features of train data.\nmnist_train.describe()","e2b8583f":"mnist_train.columns[mnist_train.isnull().any()]","2d6b66fd":"# dividing the data into the input and output features to train make the model learn based on what to take in and what to throw out.\nmnist_train_data = mnist_train.loc[:, \"pixel0\":]\nmnist_train_label = mnist_train.loc[:, \"label\"]\n\n# Notmailzing the images array to be in the range of 0-1 by dividing them by the max possible value. \n# Here is it 255 as we have 255 value range for pixels of an image. \nmnist_train_data = mnist_train_data\/255.0\nmnist_test = mnist_test\/255.0","68d62b33":"# Let's make some beautiful plots.\ndigit_array = mnist_train.loc[6, \"pixel0\":]\narr = np.array(digit_array) \n\n#.reshape(a, (28,28))\nimage_array = np.reshape(arr, (28,28))\n\ndigit_img = plt.imshow(image_array, cmap=plt.cm.binary)\nplt.colorbar(digit_img)\nprint(\"IMAGE LABEL: {}\".format(mnist_train.loc[3, \"label\"]))\n","d471921d":"from sklearn.preprocessing import StandardScaler\n\nstandardized_scalar = StandardScaler()\nstandardized_data = standardized_scalar.fit_transform(mnist_train_data)\nstandardized_data.shape","72aaab02":"cov_matrix = np.matmul(standardized_data.T, standardized_data)\ncov_matrix.shape","f325df76":"from scipy.linalg import eigh\n\nlambdas, vectors = eigh(cov_matrix, eigvals=(782, 783))\nvectors.shape","55236a1d":"vectors = vectors.T\nvectors.shape","12e58039":"new_coordinates = np.matmul(vectors, standardized_data.T)\nprint(new_coordinates.shape)\nnew_coordinates = np.vstack((new_coordinates, mnist_train_label)).T","785c9568":"df_new = pd.DataFrame(new_coordinates, columns=[\"f1\", \"f2\", \"labels\"])\ndf_new.head()","5d43f3a4":"sns.FacetGrid(df_new, hue=\"labels\", size=6).map(plt.scatter, \"f1\", \"f2\").add_legend()\nplt.show()","2742d5d4":"from sklearn import decomposition\n\npca = decomposition.PCA()\npca.n_components = 2\npca_data = pca.fit_transform(standardized_data)\npca_data.shape","d4be40d5":"pca_data = np.vstack((pca_data.T, mnist_train_label)).T","fb06a56e":"df_PCA = pd.DataFrame(new_coordinates, columns=[\"f1\", \"f2\", \"labels\"])\ndf_PCA.head()","daabd1e1":"sns.FacetGrid(df_new, hue=\"labels\", size=12).map(plt.scatter, \"f1\", \"f2\").add_legend()\nplt.savefig(\"PCA_FacetGrid.png\")\nplt.show()","684c2838":"pca.n_components = 784\npca_data = pca.fit_transform(standardized_data)\npercent_variance_retained = pca.explained_variance_ \/ np.sum(pca.explained_variance_)\n\ncum_variance_retained = np.cumsum(percent_variance_retained)","a02f4f4a":"plt.figure(1, figsize=(10, 6))\nplt.clf()\nplt.plot(cum_variance_retained, linewidth=2)\nplt.axis(\"tight\")\nplt.grid()\nplt.xlabel(\"number of compoments\")\nplt.ylabel(\"cumulative variance retained\")\nplt.savefig(\"pca_cumulative_variance.png\")\nplt.show()","d98413f0":"# Converting dataframe into arrays\nmnist_train_data = np.array(mnist_train_data)\nmnist_train_label = np.array(mnist_train_label)","9dc6a4ed":"# Reshaping the input shapes to get it in the shape which the model expects to recieve later.\nmnist_train_data = mnist_train_data.reshape(mnist_train_data.shape[0], 28, 28, 1)\nprint(mnist_train_data.shape, mnist_train_label.shape)","a9e25549":"# But first import some cool libraries before getting our hands dirty!! \n# TensorFlow is Google's open source AI framework and we are using is here to build model.\n# Keras is built on top of Tensorflow and gives us\n# NO MORE GEEKY STUFF, Know more about them here:  https:\/\/www.tensorflow.org     https:\/\/keras.io\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D\nfrom tensorflow.keras.optimizers import Adadelta\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import LearningRateScheduler","4126218c":"# Encoding the labels and making them as the class value and finally converting them as categorical values.\nnclasses = mnist_train_label.max() - mnist_train_label.min() + 1\nmnist_train_label = to_categorical(mnist_train_label, num_classes = nclasses)\nprint(\"Shape of ytrain after encoding: \", mnist_train_label.shape)","6334a039":"# Warning!!! Here comes the beast!!!\n\ndef build_model(input_shape=(28, 28, 1)):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = input_shape))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n    return model\n\n    \ndef compile_model(model, optimizer='adam', loss='categorical_crossentropy'):\n    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n    \n    \ndef train_model(model, train, test, epochs, split):\n    history = model.fit(train, test, shuffle=True, epochs=epochs, validation_split=split)\n    return history","4e569117":"# Training the model using the above function built to build, compile and train the model\ncnn_model = build_model((28, 28, 1))\ncompile_model(cnn_model, 'adam', 'categorical_crossentropy')\n\n# train the model for as many epochs as you want but I found training it above 80 will not help us and eventually increase overfitting.\nmodel_history = train_model(cnn_model, mnist_train_data, mnist_train_label, 80, 0.2)","ca30f777":"def plot_model_performance(metric, validations_metric):\n    plt.plot(model_history.history[metric],label = str('Training ' + metric))\n    plt.plot(model_history.history[validations_metric],label = str('Validation ' + metric))\n    plt.legend()\n    plt.savefig(str(metric + '_plot.png'))","bb17a7e4":"plot_model_performance('accuracy', 'val_accuracy')","924c6b09":"plot_model_performance('loss', 'val_loss')","f136dbab":"# reshaping the test arrays as we did to train images above somewhere.\nmnist_test_arr = np.array(mnist_test)\nmnist_test_arr = mnist_test_arr.reshape(mnist_test_arr.shape[0], 28, 28, 1)\nprint(mnist_test_arr.shape)","78976478":"# Now, since the model is trained, it's time to find the results for the unseen test images.\npredictions = cnn_model.predict(mnist_test_arr)","8ac448e9":"# Finally, making the final submissions assuming that we have to submit it in any comptition. P)\npredictions_test = []\n\nfor i in predictions:\n    predictions_test.append(np.argmax(i))","03fa9ce3":"submission =  pd.DataFrame({\n        \"ImageId\": mnist_test.index+1,\n        \"Label\": predictions_test\n    })\n\nsubmission.to_csv('my_first_submission.csv', index=False)","d24296f3":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras import models, layers, utils\nfrom tensorflow.keras import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, MaxPool2D\n\n","a8029df6":"x_train, x_val, y_train, y_val = train_test_split(mnist_train_data, mnist_train_label, test_size = 0.2, random_state = 2)","be0c3e62":"def define_model():\n    model = Sequential()\n    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    \n    model.add(MaxPooling2D((2, 2)))\n    model.add(layers.BatchNormalization())\n    model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n    \n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n    model.add(layers.BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3,3), activation=\"relu\"))\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n    model.add(Flatten())\n    model.add(layers.BatchNormalization())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    \n    return model","106a2f71":"model = define_model()\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])","a890dca3":"model.summary()","cc369beb":"model.fit(x_train, y_train , epochs=30)","bd678b7a":"# Now, since the model is trained, it's time to find the results for the unseen test images.\npredictions = model.predict(mnist_test_arr)","ac5d2bbf":"# Finally, making the final submissions assuming that we have to submit it in any comptition. P)\npredictions_test = []\n\nfor i in predictions:\n    predictions_test.append(np.argmax(i))","467141bb":"submission =  pd.DataFrame({\n        \"ImageId\": mnist_test.index+1,\n        \"Label\": predictions_test\n    })\n\nsubmission.to_csv('my_second_submission.csv', index=False)","f9a87c34":"d) Calculate unit vectors U1=V1 and new coordinates","1bbb4a1c":"# Splitting the dataset for training and testing","34db7279":"Describing the normalized dataset again.","d42e9e52":"# NEW Insight","d922a1c1":"# Adding the development set","9f4b12d8":"Let's visualize the mean of each pixel in a bar plot.\n\nBefore Scaling :\n\n* The content in the following plots represents the data before scaling, you can see that the features vary. The first features have 0 in the mean value, that's because all the values in the first features are zeros (Black background).","2fdff1d7":"# Data Understanding\nIn this notebook I am using the MNIST Digits dataset.\n\nAbout the dataset: The dataset consists of 10 classes of handwritten Images pictures each with a number between 0-9.","e9cffdbd":"# Visulaize a single digit with an array\n","b1a593e5":"# Model Building Process","328d7ac5":"\n\n# 1) Using manual approach:\n\na) Compute standardization of data\n","56b69eeb":"# Building Model Architecture","cf74ce1b":"* Let's see how the values in the output target are distributed.","5aaa9134":"# PCA Dimension Reduction","c1146478":"b) Calculate covariance matrix S(dxd)","bfd02b26":"We do not have any missing values in the datasets, therfore, the data is clean already","da21d55b":"Plotting the mean to see what's the difference","2f1b181f":"# Prediction & Submission","b5b08f8e":"Before training, we'll first modify your images to be better suited for training a convolutional neural network. For this task we'll use the Keras ImageDataGenerator function to perform data preprocessing and data augmentation.\n\nThis class also provides support for basic data augmentation such as random horizontal flipping of images. We also use the generator to transform the values in each batch so that their mean is 0 and their standard deviation is 1 (this will faciliate model training by standardizing the input distribution). The generator also converts our single channel Digits (gray-scale) to a three-channel format by repeating the values in the image across all channels (we will want this because the pre-trained model that we'll use requires three-channel inputs).","4ee7d904":"Underesting the shape and other information about the datasets could give us a better intution to solve the problem","75bedf51":"# Normalization :\n\nNormalizing the data helps with converging to the global minima, instead of having a lot of local minima.\nSimilarly, the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization. It is required only when features have different ranges.For example, consider a data set containing two features, age, and income(x2). Where age ranges from 0\u2013100, while income ranges from 0\u2013100,000 and higher. Income is about 1,000 times larger than age. So, these two features are in very different ranges. When we do further analysis, like multivariate linear regression, for example, the attributed income will intrinsically influence the result more due to its larger value. But this doesn\u2019t necessarily mean it is more important as a predictor. So we normalize the data to bring all the variables to the same range.","d2f834fe":"# Submitting the prediction.","9c598e36":"# 2) Using Sci-kit Learn library:","5df36f1b":"In the train file, the first column is the label (0..9, output). You can change .iloc[:, this] to see more columns. Each column has a max value of 255 and a min value of 0. That is each pixel has values between 0..255.\n![pixel.gif](attachment:pixel.gif)\n\nLet's now see the description of both these two datasets. Descritption is a method with dataframes, it allows us to see the statistical values of a dataset. Like for example, the mean, the std (standard deviation), the max and min values etc,...","b6a9326a":"# Encoding train labels","6793d5b2":"Underesting the shape and other information about the datasets could give us a better intution to solve the problem","a4a5c5b1":"# Data Cleaning and Normalization","f975c741":"# Preparing the inputs :\nWe're going to prepare the input images, and put them in the correct shape. The shapes should be (num_examples,  nh,nw,nc ).\n\n* nc  = Number of channels (1 Gray-scale).\n\n* nh  = Height of images.\n\n* nw  = Width of images.","63809469":"# NEW insight ","3db640af":"# Building a Sequential Model","4debc65e":"# Model Performance Analysis","455555e7":"# Data augmentation :\n* Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n\n* Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n\n* The Keras deep learning neural network library provides the capability to fit models using image data augmentation via the ImageDataGenerator class.\n![1_dJNlEc7yf93K4pjRJL55PA--1-.png](attachment:1_dJNlEc7yf93K4pjRJL55PA--1-.png)","569d98e6":"* As you see above, the mean of all the features is close to zero, that means all of the features have a similar mean.\n* This will help increasing the performance of course.","0cbf31f6":"e) Plot FacetGrid using seaborn\n","2cd1fcc0":"c) Calculate Eigen values and eigen vectors","a680f904":"# PCA Implementation on MNIST Digits","0f2e2ece":"# Display examples in the dataset","fb80ae23":"# Data Normalization\n","5bfb92e2":"# Transforming testing data"}}