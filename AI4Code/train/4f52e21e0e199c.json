{"cell_type":{"542e609c":"code","6f4d12d3":"code","ef90438c":"code","57c1f737":"code","68c75db1":"code","8fbfdd55":"code","bd7711a0":"code","8f8a9f0e":"code","9cabea9e":"code","3eacda0f":"code","d4eedf9b":"code","2ff697d7":"code","067aefc4":"code","215eef22":"code","385f4a36":"code","dc91165a":"code","6113e741":"code","18c8eda6":"code","c0896a9a":"code","831ef8a5":"code","d5d6e32c":"code","d0ac8ee6":"code","5fbf0a8f":"code","619f4773":"code","7f3ad7ab":"code","82791da2":"code","4b1b1d70":"code","8582f71b":"code","1db654e7":"code","3b8de95f":"code","3394fc42":"code","1b6d78de":"code","d74c1fbb":"code","be71d6f4":"code","5ab3f782":"code","6afd937d":"code","0f668062":"code","fb44bf60":"code","7c99051d":"code","39dce90e":"code","9f5f9bdc":"code","caf8d445":"code","a5e4e4a8":"code","8b817cb1":"code","37b540a4":"markdown","3d651265":"markdown","695f35aa":"markdown","ab03489f":"markdown","27100a6b":"markdown","ca8fdbce":"markdown"},"source":{"542e609c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f4d12d3":"import matplotlib.pyplot as plt","ef90438c":"df = pd.read_csv(\"\/kaggle\/input\/vehicle-dataset-from-cardekho\/CAR DETAILS FROM CAR DEKHO.csv\")","57c1f737":"df.head()","68c75db1":"df.columns","8fbfdd55":"data = df","bd7711a0":"data['year'] = 2021-data['year']","8f8a9f0e":"data.head()","9cabea9e":"data.drop(['name'],axis=1,inplace=True)","3eacda0f":"data.head()","d4eedf9b":"print(data['fuel'].unique())\nprint(data['seller_type'].unique())\nprint(data['transmission'].unique())\nprint(data['owner'].unique())","2ff697d7":"data.isnull().sum()","067aefc4":"data.dtypes","215eef22":"data['owner'].value_counts()","385f4a36":"owner_encoded_values = {'First Owner':1,'Second Owner':2,'Third Owner':3,'Fourth & Above Owner':4,'Test Drive Car':5}","dc91165a":"data=data.replace(owner_encoded_values)","6113e741":"data=pd.get_dummies(data,drop_first=True)","18c8eda6":"data.head()","c0896a9a":"data.dtypes","831ef8a5":"import seaborn as sns","d5d6e32c":"data.corr()","d0ac8ee6":"#get correlations of each features in dataset\ncorrmat = data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","5fbf0a8f":"features = data.columns.tolist()","619f4773":"features.remove('selling_price')\nprint(features)","7f3ad7ab":"X = data[features]\ny = data[\"selling_price\"]","82791da2":"X.head()","4b1b1d70":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","8582f71b":"X_train.head()","1db654e7":"y_train.head()","3b8de95f":"from sklearn.ensemble import RandomForestRegressor","3394fc42":"regressor = RandomForestRegressor()","1b6d78de":"n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\nprint(n_estimators)","d74c1fbb":"from sklearn.model_selection import RandomizedSearchCV","be71d6f4":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","5ab3f782":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","6afd937d":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()","0f668062":"# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","fb44bf60":"rf_random.fit(X_train,y_train)","7c99051d":"rf_random.best_params_","39dce90e":"predictions=rf_random.predict(X_test)","9f5f9bdc":"plt.scatter(y_test,predictions)","caf8d445":"from sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","a5e4e4a8":"print(\"R2 score:\", metrics.r2_score(y_test, predictions))","8b817cb1":"import pickle\n# open a file, where you ant to store the data\nfile = open('model.pkl', 'wb')\n\n# dump information to that file\npickle.dump(rf_random, file)","37b540a4":"## Importing Libraries","3d651265":"## Training","695f35aa":"## Data Preprocessing","ab03489f":"## Evaluating the model","27100a6b":"## Data Visualization","ca8fdbce":"## Train and Test Data"}}