{"cell_type":{"8422e4ee":"code","d805ae95":"code","d3d24435":"code","b4c5b886":"code","34bbf0fe":"code","a45633fa":"code","3a0dc63f":"code","b314889d":"code","a8c23f9c":"code","6c7b081f":"code","e193bbc9":"code","ada008b6":"code","b4c1bd57":"code","d84d42e3":"code","83a6dff8":"code","1db1d2ec":"code","f98eb66b":"markdown","b6a2d232":"markdown","6d6a8006":"markdown","777c56f1":"markdown","53797024":"markdown","c9cc1fc6":"markdown","613c63a2":"markdown","048276ab":"markdown","34967c5d":"markdown","c9254307":"markdown","67dde67a":"markdown","5431fc82":"markdown","680d84a5":"markdown","f1873554":"markdown","ae9a0350":"markdown"},"source":{"8422e4ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n'''import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# Any results you write to the current directory are saved as output. \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc4f0\ub294 \ubaa8\ub4e0 \uacb0\uacfc\ub294 \ucd9c\ub825\uc73c\ub85c \uc800\uc7a5\ub41c\ub2e4.","d805ae95":"import tensorflow\nimport keras\nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom sklearn.datasets import load_files #\uac01\uc885 \ud30c\uc774\uc36c \ub77c\uc774\ube0c\ub7ec\ub9ac, \uc2e0\uacbd\ub9dd \ub77c\uc774\ube0c\ub7ec\ub9ac \ub4f1\uc774 impot \ub418\uc5b4 \uc788\ub2e4. from \uc774\ud558\ub97c import \uc774\ud558\uc758 \uc774\ub984\uc73c\ub85c \uac00\uc838\uc654\ub2e4.","d3d24435":"train_dir='\/kaggle\/input\/withwithout-mask\/maskdata\/maskdata\/train\/'\ntest_dir='\/kaggle\/input\/withwithout-mask\/maskdata\/maskdata\/test\/' #\ub370\uc774\ud130\uc14b\uc744 \ubcc0\uc218\uc5d0 \uc800\uc7a5.","b4c5b886":"def load_dataset(path):\n    data = load_files(path) #load all files from the path #sklearns\uc5d0 \uc778\uc790\ub97c \ubc1b\uc544\uc11c data\uc5d0 \uc800\uc7a5, filenames\ub85c nump\n    files = np.array(data['filenames']) #get the file #filename data\ub97c \uc778\uc790\ub85c \uc0ac\uc6a9\ud574 numpy\ubc30\uc5f4\uc744 \ub9cc\ub4e4\uc5b4\uc11cfiles \ubcc0\uc218\uc5d0 \ud560\ub2f9.  \n    targets = np.array(data['target'])#get the the classification labels as integer index\n    target_labels = np.array(data['target_names'])#get the the classification labels \n    return files,targets,target_labels\n    \nx_train, y_train,target_labels = load_dataset(train_dir) \n#x_train\uc5d0 files\ub97c, y_train\uc5d0 targets\ub97c target_labels\uc5d0 target_label\uc744 \ud560\ub2f9. \uc704\uc758 \ud568\uc218 \uc774\uc6a9.\nx_test, y_test,_ = load_dataset(test_dir)\n\nprint('Training set size : ' , x_train.shape[0])\nprint('Testing set size : ', x_test.shape[0]) #\ub450 \ub370\uc774\ud130\uc14b\uc758 \ub370\uc774\ud130\ud504\ub808\uc784 \uc0ac\uc774\uc988\ub97c \ubc18\ud658\ud55c\ub2e4.","34bbf0fe":"num_classes = 2","a45633fa":"resnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5' #\ub370\uc774\ud130\uc14b\uc744 \ubcc0\uc218\uc5d0 \uc800\uc7a5.","3a0dc63f":"my_new_model = Sequential() #\uc21c\ucc28\uc801 \ubaa8\ub378 \uc0ac\uc6a9, \ub808\uc774\uc5b4\ub97c \uc120\ud615\uc73c\ub85c \uc5f0\uacb0\ud558\uc5ec \uad6c\uc131, \ub808\uc774\uc5b4 \uc778\uc2a4\ud134\uc2a4\ub97c \uc0dd\uc131\uc790\uc5d0\uac8c \ub118\uaca8\uc90c\uc73c\ub85c\uc368 Sequential \ubaa8\ub378\uc744 \uad6c\uc131\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path)) \n\"\"\"\ninclude_top : \uac00\uc7a5 \uc0c1\ub2e8\uc758 fully connected\uacc4\uce35\ub4e4\uc744 \ud3ec\ud568 \uc2dc\ud0ac\uc9c0\uc758 \uc5ec\ubd80\uc785\ub2c8\ub2e4.\nweight : \ucf00\ub77c\uc2a4\uc5d0\uc11c \ubbf8\ub9ac pretraining \uc2dc\ucf1c\ub193\uc740 weight\uc744 \uc0ac\uc6a9 \ud560 \uac83\uc778\uc9c0 \uc5ec\ubd80\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \uc0ac\uc804 \ud6c8\ub828\ub41c \uccab\ubc88\uc9f8 \ub808\uc774\uc5b4\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uaca0\ub2e4\uace0 \ud588\uc73c\ubbc0\ub85c include_top=False\uac00 \ub429\ub2c8\ub2e4.\npooling : top layer\ub97c \ud3ec\ud568\uc2dc\ud0a4\uc9c0 \uc54a\uc558\uc744\ub54c \uac00\uc7a5 \uc0c1\ub2e8\ubd80\ubd84\uc758 pooling \ubc29\ubc95\uc744 \uc14b\ud305.\n\"\"\"\nmy_new_model.add(Dense(num_classes, activation='softmax')) #\uc785\ub825 \ud615\ud0dc\ub97c \uc815\uc758\ud558\uc9c0 \uc54a\uc558\ub2e4.\n#\uc774\ucc98\ub7fc .add() \uba54\uc18c\ub4dc\ub97c \ud1b5\ud574\uc11c \ub808\uc774\uc5b4\ub97c \ucd94\uac00\n\nmy_new_model.layers[0].trainable = False","b314889d":"my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n#\ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\uae30 \uc774\uc804\uc5d0, compile \uba54\uc18c\ub4dc\ub97c \ud1b5\ud574\uc11c \ud559\uc2b5 \ubc29\uc2dd\uc5d0 \ub300\ud55c \ud658\uacbd\uc124\uc815\n'''\n\uc815\uaddc\ud654\uae30, optimizer \n\uc190\uc2e4 \ud568\uc218, loss function : \ubaa8\ub378\uc774 \ucd5c\uc801\ud654\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ubaa9\uc801 \ud568\uc218\uc785\ub2c8\ub2e4.\n\uae30\uc900(metric) \ub9ac\uc2a4\ud2b8. \ubd84\ub958 \ubb38\uc81c\uc5d0 \ub300\ud574\uc11c\ub294 metrics=['accuracy']\ub85c \uc124\uc815\n'''","a8c23f9c":"#\ubcf4\ucda9\uc608\uc815\n\n#keras\ub294 python\uc758 \uc624\ud508\uc18c\uc2a4 \uc2e0\uacbd\ub9dd \ub77c\uc774\ube0c\ub7ec\ub9ac\uc774\ub2e4.\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras_preprocessing.image import ImageDataGenerator\nimport numpy as np\n#\ud544\uc694\ud55c keras\uac1c\uccb4\ub4e4\uc744 \uc784\ud3ec\ud2b8\n\n\nimage_size = 224\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip=True,\n                                   width_shift_range = 0.2, #50% \ud655\ub960\ub85c \uc774\ubbf8\uc9c0\ub97c \uc218\ud3c9\uc73c\ub85c \ub4a4\uc9d1\uc2b5\ub2c8\ub2e4. \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc5d0 \uc218\ud3c9 \ube44\ub300\uce6d\uc131\uc774 \uc5c6\uc744 \ub54c \ud6a8\uacfc\uc801\uc785\ub2c8\ub2e4\n                                   height_shift_range = 0.2) #\uc2e4\uc2dc\uac04 \ub370\uc774\ud130 \uc99d\uac15\uc744 \uc0ac\uc6a9\ud574\uc11c \ud150\uc11c \uc774\ubbf8\uc9c0 \ub370\uc774\ud130 \ubc30\uce58\ub97c \uc0dd\uc131\n\n\ntrain_generator = data_generator.flow_from_directory(\n        train_dir,\n        target_size=(image_size, image_size),\n        batch_size=50,# \ud55c \ubc88\uc5d0 50\uc7a5\uc758 \uc0ac\uc9c4\uc744 \uc77d\uc5b4\ub4e4\uc778\ub2e4.\n        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(test_dir,target_size=(image_size, image_size),\n        class_mode='categorical') #categorical\uc758 \ud615\ud0dc\ub85c target_size\uc758 \ud06c\uae30\ub85c \ub77c\ubca8\ub9c1\ud55c\ub2e4.\n#\uc774\ubbf8\uc9c0 \uc99d\uc2dd\n\nhistory=my_new_model.fit_generator(\n        train_generator,\n        steps_per_epoch=4,epochs=3,\n        validation_data=validation_generator,\n        validation_steps=1) #\ud30c\uc774\uc36c \uc0dd\uc131\uae30(\ud639\uc740 Sequence \uc778\uc2a4\ud134\uc2a4)\uac00 \ubc30\uce58 \ub2e8\uc704\ub85c \uc0dd\uc0b0\ud55c \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c \ubaa8\ub378\uc744 \ud559\uc2b5\n#\ud2b8\ub808\uc774\ub2dd. \u3131\u3131","6c7b081f":"import matplotlib.pyplot as plt #\uadf8\ub798\ud504 \uc791\uc131. \ubaa8\ub378\uc758 \uc815\ud655\uc131, \uc815\ubc00\ub3c4\uc758 \ub300\ud55c \uadf8\ub798\ud504 \uc791\uc131\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss']) #\uc190\uc2e4\uc758 \ub300\ud55c \uadf8\ub798\ud504 \uc791\uc131.\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e193bbc9":"import pickle\n#\ud14d\uc2a4\ud2b8 \uc774\uc678\uc758 \uc790\ub8cc\ud615\uc744 \ud30c\uc77c\ub85c \uc800\uc7a5\ud558\uae30 \uc704\ud558\uc5ec pickle\uc774\ub77c\ub294 \ubaa8\ub4c8\uc744 \uc0ac\uc6a9.\n\npickle_out = open(\"resnet50_history.pickle\",\"wb\")\npickle.dump(history.history, pickle_out)\npickle_out.close()","ada008b6":"pickle_in = open(\"resnet50_history.pickle\",\"rb\") #\ud30c\uc77c\uc5d0 \uc785\ub825.\nsaved_history = pickle.load(pickle_in) #\ud30c\uc77c \uc77d\uae30.\nprint(saved_history)","b4c1bd57":"import random\nimport cv2\n#OpenCV\ub294 \uc774\ubbf8\uc9c0, \uc601\uc0c1\ucc98\ub9ac, Object Detection, Motion Detecton \ub4f1 \ub9e4\uc6b0 \ub2e4\uc591\ud55c \uae30\ub2a5\ub4e4\uc744 \uc81c\uacf5\ud558\ub294 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc774\ub2e4.\n\ndef image_show(image,title):\n    print(image)\n    img = cv2.imread(image) #\uc778\uc790\ub85c \ubc1b\uc740 image\ub97c \uc77d\ub294\ub2e4.\n    plt.imshow(img) #\uc77d\uc740 img\ub97c \ud654\uba74\uc5d0 \ud45c\uc2dc\ud55c\ub2e4.\n    plt.title(title)\n    plt.show()\n","d84d42e3":"test_gen1=data_generator.flow_from_directory('\/kaggle\/input\/test-data\/test\/',target_size=(image_size, image_size),\n        class_mode='categorical',shuffle=False) #\ub370\uc774\ud130\ub97c \uc601\uc22b\uc790 \uc21c\uc11c\ub85c \uc815\ub82c.\n\ntest_gen1.filenames","83a6dff8":"predictions_test=my_new_model.predict_generator(test_gen1) #\ub370\uc774\ud130 \uc0dd\uc131\uae30\uc758 \uc778\ud48b \uc0d8\ud50c\uc5d0 \ub300\ud574\uc11c \uc608\uce21 \uac12\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \nlen(predictions_test)\nres_test=[]\nfor i in predictions_test:\n    if i[0]<0.5:\n        res_test.append(\"Not Wearing mask\")\n    else:\n        res_test.append(\"Wearing mask\")","1db1d2ec":"image_show('\/kaggle\/input\/test-data\/test\/1\/464-with-mask.jpg',res_test[5])","f98eb66b":"# **MASK DETECTION IN IMAGES USING RESNET50**#  ","b6a2d232":"More stats for nerds! \ub108\ub4dc\uc5d0 \ub300\ud55c \ucd94\uac00 \ud1b5\uacc4","6d6a8006":"# Creating the model and removing its first layer as we wish to train it and not use the pre-trained first layer. ***\uc0ac\uc804 \ud6c8\ub828\ub41c \uccab \ubc88\uc9f8 \ub808\uc774\uc5b4\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0*** \ubaa8\ub378\uc744 \ub9cc\ub4e4\uace0 \uc6b0\ub9ac\uac00 \uc6d0\ud558\ub294 \ub300\ub85c \uccab \ubc88\uc9f8 \ub808\uc774\uc5b4\ub97c \uc81c\uac70\ud569\ub2c8\ub2e4.","777c56f1":"Importing the training and testing data from respective directories and splitting it into categories for validation using load_files.","53797024":"This is a basic implementation using the ResNet50 model. I am a beginner so please feel free to offer corrections and suggestions.","c9cc1fc6":"Importing small dataset of 8 files for custom testing. \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ud14c\uc2a4\ud2b8\ub97c \uc704\ud574 8\uac1c \ud30c\uc77c\uc758 \uc791\uc740 \ub370\uc774\ud130 \uc9d1\ud569\uc744 \uac00\uc838\uc624\ub294 \uc911\uc785\ub2c8\ub2e4.","613c63a2":"# **Further applications:**\n\nA mask detector like this one can be used in security cameras and only allow entry of those individuals who have a mask on. It will be extremely beneficial and can even lessen the transmission rate.\nAnother application can be identifying the people wearing masks and not wearing masks in an epicentre of corona virus so as to examine the circumstances and analyse if wearing a mask is really beneficial or not.","048276ab":"Plotting accuracies for training and testing. \uad50\uc721 \ubc0f \ud14c\uc2a4\ud2b8\uc5d0 \ub300\ud55c \uc815\ud655\uc131\uc744 \ud50c\ub85c\ud305\ud569\ub2c8\ub2e4.","34967c5d":"Importing resnet weights for importing the pretrained model. Resnet50 is used here because it proves to substantially reduce the number of parameters. \uac01 \ub514\ub809\ud1a0\ub9ac\uc5d0\uc11c \uad50\uc721 \ubc0f \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \uac00\uc838\uc640\uc11c load_files\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc720\ud6a8\uc131\uc744 \uac80\uc0ac\ud558\uae30 \uc704\ud55c \ubc94\uc8fc\ub85c \ub098\ub215\ub2c8\ub2e4.","c9254307":"![Masks are important!](https:\/\/forthebadge.com\/images\/badges\/check-it-out.svg)\n\n\nWearing masks in the midst of the rising corona virus(COVID-19) is made mandatory by a lot of cities. This is a basic resnet implementation that performs binary classification of images and identifies images where the individual is wearing a mask or not.","67dde67a":"##Architecture of ResNet50\n\n![Arch](https:\/\/www.researchgate.net\/publication\/338603223\/figure\/fig1\/AS:847598516711425@1579094642237\/ResNet-50-architecture-26-shown-with-the-residual-units-the-size-of-the-filters-and.png)","5431fc82":"Preprocessing the data via ImageDataGenerator.The data here is categorical as it is divided into two categories namely With Mask and Without Mask.\nImage Data Generator(\uc601\uc0c1 \ub370\uc774\ud130 \uc0dd\uc131\uae30)\ub97c \ud1b5\ud574 \ub370\uc774\ud130\ub97c \uc0ac\uc804 \ucc98\ub9ac\ud569\ub2c8\ub2e4.\uc5ec\uae30\uc11c \ub370\uc774\ud130\ub294 \ub9c8\uc2a4\ud06c \uc0ac\uc6a9 \ubc0f \ub9c8\uc2a4\ud06c \ubbf8\uc0ac\uc6a9\uc758 \ub450 \ubc94\uc8fc\ub85c \uad6c\ubd84\ub418\ubbc0\ub85c \ubc94\uc8fc\ud615\uc785\ub2c8\ub2e4.","680d84a5":"Also, please take the following measures if you step out:\n* Cover mouth and nose with mask and make sure there are no gaps between your face and the mask.\n* Avoid touching the mask while using it; if you do, clean your hands with alcohol-based hand rub or soap and water.\n* Replace the mask with a new one as soon as it is damp and do not re-use single-use masks.\n* To remove the mask: remove it from behind (do not touch the front of mask); discard immediately in a closed bin; clean hands with alcohol-based hand rub or soap and water.","f1873554":"The implementation ends here. Below is just a custom testing model that is created for validation and checking if the model predicts correctly for some new data. \uad6c\ud604\uc740 \uc5ec\uae30\uc11c \ub05d\ub0a9\ub2c8\ub2e4. \uc544\ub798\ub294 \ub2e8\uc9c0 \uac80\uc99d\uc744 \uc704\ud574 \uc0dd\uc131\ub41c \uc0ac\uc6a9\uc790 \uc815\uc758 \ud14c\uc2a4\ud2b8 \ubaa8\ub378\uc774\uba70, \ubaa8\ub378\uc774 \uc77c\ubd80 \uc0c8 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \uc62c\ubc14\ub974\uac8c \uc608\uce21\ud558\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.","ae9a0350":"![Individual wearing a mask](https:\/\/media.giphy.com\/media\/LM2BXEQUepvjLEgt1N\/giphy.gif)"}}