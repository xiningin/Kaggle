{"cell_type":{"7d410a91":"code","0263a70a":"code","1095fe02":"code","84191b94":"code","719b9f70":"markdown","3edaafc0":"markdown","1a6d6a7f":"markdown"},"source":{"7d410a91":"import os,re\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef atoi(text) : \n    return int(text) if text.isdigit() else text\n\ndef natural_keys(text) :\n    return [atoi(c) for c in re.split('(\\d+)', text)]\n\n\nread_csv = pd.read_csv('\/kaggle\/input\/semantic-drone-dataset\/class_dict_seg.csv',index_col=False,skipinitialspace=True)\nread_csv.head()","0263a70a":"def segmantation_images(path,new_path, debug_test_num):\n    filenames = []\n     \n    for root, dirnames, filenames in os.walk(path):\n        filenames.sort(key = natural_keys)\n        rootpath = root\n\n    #print(filenames)\n    count = 0\n    for item in filenames:\n        \n        if debug_test_num !=0:\n            if debug_test_num <= count:\n                break\n                \n        count = count + 1\n        \n        if os.path.isfile(path+item):\n            f, e = os.path.splitext(item)\n            image_rgb = Image.open(path+item)\n            image_rgb = np.asarray(image_rgb)\n            new_image = np.zeros((image_rgb.shape[0],image_rgb.shape[1],3)).astype('int')\n\n            for index, row  in read_csv.iterrows():\n                new_image[(image_rgb[:,:,0]==row.r)&\n                          (image_rgb[:,:,1]==row.g)&\n                          (image_rgb[:,:,2]==row.b)]=np.array([index+1,index+1,index+1]).reshape(1,3)\n\n            new_image = new_image[:,:,0]\n            output_filename = new_path+f+'.png'\n            cv2.imwrite(output_filename,new_image)\n            print('writing file: ',output_filename)\n            \n        else:\n            print('no file')\n        \n    print(\"number of files written: \",count)\n    \n","1095fe02":"debug_test_num = 5 # 5 samples are enough just to see it working. If you set 0, you can do all the datasets.\nsegmantation_images(\"\/kaggle\/input\/semantic-drone-dataset\/RGB_color_image_masks\/RGB_color_image_masks\/\", \"\", debug_test_num=debug_test_num)","84191b94":"from PIL import Image\ninput_image = \"\/kaggle\/input\/semantic-drone-dataset\/RGB_color_image_masks\/RGB_color_image_masks\/\"+\"002.png\"\noutput_image = \"002.png\"\n\nfig, axs = plt.subplots(1, 2, figsize=(16, 8), constrained_layout=True)\n\nimg_orig = Image.open(input_image)\naxs[0].imshow(img_orig)\naxs[0].grid(False)\n\noutput_image = Image.open(output_image)\nout_array = np.asarray(output_image)\naxs[1].imshow(out_array)\naxs[1].grid(False)","719b9f70":"The dataset has RGB colored segmentation masks, and there are 24 classes in the dataset. The dataset has a file named class_dict.csv and it contains the name of the classes and their respective RGB values. The contents of the file are as follows:\n\n| name        | r   | g   | b   |\n|-------------|-----|-----|-----|\n| unlabeled   | 0   | 0   | 0   |\n| paved-area  | 128 | 64  | 128 |\n| dirt        | 130 | 76  | 0   |\n| grass       | 0   | 102 | 0   |\n| gravel      | 112 | 103 | 87  |\n| water       | 28  | 42  | 168 |\n| rocks       | 48  | 41  | 30  |\n| pool        | 0   | 50  | 89  |\n| vegetation  | 107 | 142 | 35  |\n| roof        | 70  | 70  | 70  |\n| wall        | 102 | 102 | 156 |\n| window      | 254 | 228 | 12  |\n| door        | 254 | 148 | 12  |\n| fence       | 190 | 153 | 153 |\n| fence-pole  | 153 | 153 | 153 |\n| person      | 255 | 22  | 96  |\n| dog         | 102 | 51  | 0   |\n| car         | 9   | 143 | 150 |\n| bicycle     | 119 | 11  | 32  |\n| tree        | 51  | 51  | 0   |\n| bald-tree   | 190 | 250 | 190 |\n| ar-marker   | 112 | 150 | 146 |\n| obstacle    | 2   | 135 | 115 |\n| conflicting | 255 | 0   | 0   |","3edaafc0":"If you have RGB color image masks (like [Aerial Semantic Segmentation Drone Dataset RGB_color_masks Folder](https:\/\/www.kaggle.com\/bulentsiyah\/semantic-drone-dataset) )  , you can follow the steps below. First of all, our goal is to obtain a pixel-based class image from RGB color image masks as follows.\n\n| RGB color image masks      | pixel-based class image masks |\n| ----------- | ----------- |\n| ![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F5181549%2Ffbd1df30b8700a4f0c6581cd2c3a5a8d%2F040.png?generation=1610278890444345&alt=media)       | ![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F5181549%2F7a82aff10c03e2ec9f325b0651c53bfe%2F040.png?generation=1610278931040183&alt=media)       |\n\n","1a6d6a7f":"### Update(11.01.2021)\n\nHi, with this kernel, I will transfer your RGB color image masks to pre-process and make it ready for the semantic segmentation model.\n\n\nThe first step in training our segmentation model is to prepare the dataset. We would need the input RGB images and the corresponding segmentation images. If you want to make your own dataset, a tool like labelme or GIMP can be used to manually generate the ground truth segmentation masks.  Assign each class a unique ID. In the segmentation images, the pixel value should denote the class ID of the corresponding pixel. [You can examine for Deep Learning based Semantic Segmentation example](https:\/\/www.kaggle.com\/bulentsiyah\/deep-learning-based-semantic-segmentation-keras)\n\n![](https:\/\/divamgupta.com\/assets\/images\/posts\/imgseg\/image14.png?style=centerme)\n\n\n\n\n\n\n\n"}}