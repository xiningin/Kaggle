{"cell_type":{"5ced420f":"code","71133b97":"code","13e42d66":"code","244aa3a4":"code","871034bc":"code","8a448e10":"code","6e2cdc31":"code","44599831":"code","2a2ce91a":"code","dc2212c0":"code","a9a02036":"markdown","45581293":"markdown","c4d19099":"markdown","ebb8d638":"markdown","d39bf99e":"markdown","2d51888e":"markdown","6ed5716f":"markdown","17418109":"markdown","a5cb3ad9":"markdown","dd5cbbf3":"markdown","f58fa1b3":"markdown","77617307":"markdown"},"source":{"5ced420f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport re\n# trying my hands on plotly\nfrom plotly import tools\nimport plotly.graph_objs as go\n# TextBlob for quick text analysis\nfrom textblob import TextBlob\n# wordcloud for, well like the name suggests\nfrom wordcloud import WordCloud, STOPWORDS\n# matplotlib to visualize the word clouds\nimport matplotlib.pyplot as plt\n# To generate word clouds using a mask object. I might not use this\nfrom PIL import Image\n# Wordcloud usually generates in various colors. this library might help to convert to a gray color\nimport random\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","71133b97":"# Read the data\nemployee_reviews=pd.read_csv(\"..\/input\/employee_reviews.csv\", index_col=[0])\n# Clean up the column headers\nemployee_reviews.columns = employee_reviews.columns.str.replace(\"-\",\"_\")\n\nreplace_none_as_nan = lambda t: float('nan') if t==\"none\" else t\nemployee_reviews.overall_ratings = employee_reviews.overall_ratings.map(replace_none_as_nan)\nemployee_reviews.work_balance_stars = employee_reviews.work_balance_stars.map(replace_none_as_nan)\nemployee_reviews.culture_values_stars = employee_reviews.culture_values_stars.map(replace_none_as_nan)\nemployee_reviews.carrer_opportunities_stars = employee_reviews.carrer_opportunities_stars.map(replace_none_as_nan)\nemployee_reviews.comp_benefit_stars = employee_reviews.comp_benefit_stars.map(replace_none_as_nan)\nemployee_reviews.senior_mangemnet_stars = employee_reviews.senior_mangemnet_stars.map(replace_none_as_nan)\n\n# A quick view of the data to get the lay of the land, also because Excel has spoiled me that way\nemployee_reviews.head(5)","13e42d66":"# Get the list of reviews per company\nemployee_companies = employee_reviews.company.value_counts()\n# Prepare a Bar graph of the number of records\ndata = [go.Bar(\n    x=employee_companies.index.str.title().tolist(),\n    y=employee_companies.values\n)]\nlayout = go.Layout(title=\"# Reviews by Organization\",yaxis=dict(title=\"# Reviews\"), xaxis=dict(title=\"Organizations\"))\nfigure = go.Figure(data=data, layout=layout)\niplot(figure)","244aa3a4":"# Generate polarity and subjectivity number for just the summary column\nemployee_reviews[\"summary_polarity\"] = employee_reviews.summary.apply(lambda t: TextBlob(str(t)).sentiment.polarity)\nemployee_reviews[\"summary_subjectivity\"] = employee_reviews.summary.apply(lambda t: TextBlob(str(t)).sentiment.subjectivity)","871034bc":"# A short function to generate histograms for the polarity and subjectivity for each company. I could repeat the statements over and over, but that would make the graph generation appear too large\ndef generate_histogram(for_column,company_name,opacity=0.5):\n    '''\n    returns a plotly Histogram object with the parameters specified\n    \n    for_column: Specify the columns with which the histogram must be generated. In this case, it would be either \"summary_polarity\" or \"summary_subjectivity\"\n    \n    company_name: Specify the company name in lower case. In this case, it would be one of the following: amazon, apple, facebook, google, microsoft, or netflix\n    \n    opacity: the opacity of each hisogram visualization. By default it will be 0.5 or 50% opaque\n    '''\n    return go.Histogram(\n        x = employee_reviews[employee_reviews.company==company_name][for_column],\n        opacity=opacity,\n        xbins=dict(start=-1.0,end=1.1,size=0.2),\n        name=company_name.title()\n    )","8a448e10":"# Generate a Histogram if Polarity for each company.\n\namazon_polarity=generate_histogram(\"summary_polarity\",\"amazon\")\napple_polarity=generate_histogram(\"summary_polarity\",\"apple\")\ngoogle_polarity=generate_histogram(\"summary_polarity\",\"google\")\nfacebook_polarity=generate_histogram(\"summary_polarity\",\"facebook\")\nmicrosoft_polarity=generate_histogram(\"summary_polarity\",\"microsoft\")\nnetflix_polarity=generate_histogram(\"summary_polarity\",\"netflix\")\ndata=[\n    amazon_polarity,\n    apple_polarity,\n    google_polarity,\n    facebook_polarity,\n    microsoft_polarity,\n    netflix_polarity\n]\nlayout = go.Layout(barmode=\"overlay\", title=\"Summary Polarity by Company\",xaxis=dict(title=\"Polarity\"),yaxis=dict(title=\"# of Reviews\"))\nfigure = go.Figure(data=data,layout=layout)\niplot(figure)","6e2cdc31":"# Generate Subjectivity Histogram for each company\namazon_subjectivity=generate_histogram(\"summary_subjectivity\",\"amazon\")\napple_subjectivity=generate_histogram(\"summary_subjectivity\",\"apple\")\ngoogle_subjectivity=generate_histogram(\"summary_subjectivity\",\"google\")\nfacebook_subjectivity=generate_histogram(\"summary_subjectivity\",\"facebook\")\nmicrosoft_subjectivity=generate_histogram(\"summary_subjectivity\",\"microsoft\")\nnetflix_subjectivity=generate_histogram(\"summary_subjectivity\",\"netflix\")\ndata=[\n    amazon_subjectivity,\n    apple_subjectivity,\n    google_subjectivity,\n    facebook_subjectivity,\n    microsoft_subjectivity,\n    netflix_subjectivity\n]\nlayout = go.Layout(barmode=\"overlay\", title=\"Summary Subjectivity by Company\",xaxis=dict(title=\"Subjectivity\"),yaxis=dict(title=\"# of Reviews\"))\nfigure = go.Figure(data=data,layout=layout)\niplot(figure)","44599831":"# Slightly larger function to generate wordclouds for the summary, pros, and cons.\n\n# configure stop words aka words that dont need to be considered for word clouds\nstopwords=set(STOPWORDS)\nstopwords.add(\"let\")\nstopwords.add(\"to\")\nstopwords.add(\"from\")\nstopwords.add(\"a\")\nstopwords.add(\"an\")\nstopwords.add(\"the\")\nstopwords.add(\"of\")\n\n# The function itself\ndef generate_wordcloud(reviews, generate_by_frequency=False, addl_stopwords=[],):\n    '''\n    return a word cloud object that can be used in a matplotlib.pyplot's imshow function\n    \n    reviews: specify the entire employee_object for which the word cloud needs to be generated. Filtering must be done manually\n    \n    generate_by_frequency: default False. Configure whether the word cloud must be generated using a text string (WordCloud.generate_by_text) or if the word cloud must be generated using frequencies (WordCloud.generate_by_frequencies). See wordcloud documentation for further reference\n    \n    addl_stopwords: array of additonal words that must be added to the list of stop words\n    '''\n    \n#   Add the additional stopwords to the stopword list\n    for t in addl_stopwords:\n        stopwords.add(str(t))\n\n#   Combine all the reviews in the review series so that it becomes one really large text that can be passed to the wordcloud's generate function\n    def format_reviews(review):\n        processed_reviews = \" \".join(str(t) for t in review)\n        processed_reviews = processed_reviews.replace(\"\\,+\",\" \").replace(\"\\.+\",\" \").replace(\"\\*+\",\" \").replace(\"\\n+\", \" \")\n        return processed_reviews\n    \n#   Function to generate the word cloud words in gray color instead of various colors\n    def grey_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n        return \"hsl(0, 0%%, %d%%)\" % random.randint(60, 100)\n    \n#   Initialize the WordCloud object\n    wc = WordCloud(background_color=\"black\", max_words=100, stopwords=stopwords, max_font_size=40, random_state=42,width=600,height=200,margin=1)\n    if generate_by_frequency:\n        w_counts = TextBlob(format_reviews(reviews)).word_counts\n        for t in stopwords:\n            if t in w_counts:\n                del w_counts[t]\n        wc.generate_from_frequencies(w_counts)\n    else:\n        wc.generate_from_text(format_reviews(reviews))\n    wc.recolor(color_func=grey_color_func, random_state=3)\n    return wc","2a2ce91a":"fig, ax = plt.subplots(nrows=6,ncols=3,figsize=(36,36))\n\n# For each company name, generate a wordcloud of the company's summary, pros, and cons (in that order) and display the visualizations\nfor i in np.arange(employee_reviews.company.nunique()):\n    company_name=employee_reviews.company.unique()[i]\n    summary=generate_wordcloud(employee_reviews[employee_reviews.company==company_name].summary, addl_stopwords=[company_name], generate_by_frequency=True)\n    pros=generate_wordcloud(employee_reviews[employee_reviews.company==company_name].pros, addl_stopwords=[company_name], generate_by_frequency=True)\n    cons=generate_wordcloud(employee_reviews[employee_reviews.company==company_name].cons, addl_stopwords=[company_name], generate_by_frequency=True)\n    ax[i,0].set_title(\"{0} Summary\".format(company_name.title()),fontsize=36)\n    ax[i,1].set_title(\"{0} Pros\".format(company_name.title()),fontsize=36)\n    ax[i,2].set_title(\"{0} Cons\".format(company_name.title()),fontsize=36)\n    ax[i,0].imshow(summary, interpolation='bilinear')\n    ax[i,1].imshow(pros, interpolation='bilinear')\n    ax[i,2].imshow(cons, interpolation='bilinear')\n    ax[i,0].axis(\"off\")\n    ax[i,1].axis(\"off\")\n    ax[i,2].axis(\"off\")","dc2212c0":"# A short function to generate bar graphs for ratings. That being said, this is also the largest code block in this notebook! (Yikes!)\ndef generate_bargraphs(for_rating):\n    temp = pd.concat([\n        employee_reviews[(employee_reviews[\"company\"]==t)][for_rating].value_counts(normalize=True).rename(t.title()) for t in employee_reviews.company.unique().tolist()\n    ],axis=1,sort=True);\n    return [\n        go.Bar(\n            x=temp.T[t].index.tolist(),\n            y=temp.T[t].values.tolist(),\n            hovertemplate=\"%{y:.2%}\",\n            name=t,\n#             orientation=\"h\",\n        )\n        for t in temp.index];\n\nrating_colorpalette=[\"#aff895\",\"#89d471\",\"#64b04e\",\"#3f8e2b\",\"#106d00\"]\n\n# Generate graphs for each rating\noverall_rating_per_company = generate_bargraphs(\"overall_ratings\")\nwork_balance_rating_per_company = generate_bargraphs('work_balance_stars')\nculture_values_rating_per_company = generate_bargraphs('culture_values_stars')\ncarrer_opportunities_rating_per_company = generate_bargraphs('carrer_opportunities_stars')\ncomp_benefit_rating_per_company = generate_bargraphs('comp_benefit_stars')\nsenior_mangemnet_rating_per_company = generate_bargraphs('senior_mangemnet_stars')\n\n# Generate Subplots\nfigure = tools.make_subplots(rows=2,cols=5,shared_yaxes=True,specs=[[{'colspan':5},{},{},{},{}],[{},{},{},{},{}]],\nsubplot_titles=(\"Overall Rating per Company\",\"\",\"\",\"\",\"\",\"Work<br>Balance\", \"Culture<br>Values\",\"Career<br>Opportunities\",\"Compensation<br>Benefits\",\"Senior<br>Management\"))\n\n# Stack the graphs so it forms a 100% stacked bar graph\nfigure.layout.barmode=\"stack\"\n\n# A decent height for the large plot\nfigure.layout.height=800\n\n# Hide the y axis since the numbers are visible on hover\nfigure.layout.yaxis.visible=False\nfigure.layout.yaxis2.visible=False\n\n# Set the palette for the ratings. \n# Figuring out how to add in the palette for a stacked graph took me around 350 failed tries. \n# Was trying so much with the Bar.marker.colorscales because I was using colorscales to set Pandas plot for the earlier visualizations\n# Turns out that it was easier using the figure.layout.colorway and I still figure out how the figure.layout.colorscale fits into all this. In time.\nfigure.layout.colorway=rating_colorpalette\n\n# Hide the legend because this subplot ends up showing a legend graph for each subplot\nfigure.layout.showlegend=False\n\n# These subplots can only handle a single graph per subplot area. If the data is an array of plots, then iteration over each element is necessary\nfor t in overall_rating_per_company:\n    figure.add_trace(t,1,1)\nfor t in work_balance_rating_per_company:\n    figure.add_trace(t,2,1)\nfor t in culture_values_rating_per_company:\n    figure.add_trace(t,2,2)\nfor t in carrer_opportunities_rating_per_company:\n    figure.add_trace(t,2,3)\nfor t in comp_benefit_rating_per_company:\n    figure.add_trace(t,2,4)\nfor t in senior_mangemnet_rating_per_company:\n    figure.add_trace(t,2,5)\n\n# Reaching the plot finally\niplot(figure);","a9a02036":"**Reading the Data**\n\nThe usual steps, read the data and then remove special characters from the column headers to make it easier to access","45581293":"**Onto the word clouds**\n\nThe first thing that comes to mind when I think of text data is word clouds. In time, my first thoughts might change to NLP or Text generation or Bag of Words or Tokenization or something on those lines.\n\nWordCloud generates a word cloud using a text or frequencies. generating from text automatically removes the default stopwords, while generating from frequencies requires us to manually remove the text. At first I tried generating form text (since it was the easy way out) and found that some words were repeated. Resoluted to generating from frequencies (had to manually remove stopwords but was worth it)","c4d19099":"**Final Thoughts**\n\nPlotly seems to be quite interesting when it comes to visualizations, I might just end up using this as much as the pandas plot. There's several aspects to the TextBlob library that I haven't explored yet and might do in a future notebook. I also tried documenting as much of the code as possible, just so that a future more experienced me that forgot the basics, can come back and reminisce or laugh at it.\n\nCan the existing graphs be made better? Definitely! Take the ratings graph for instance, I tried to make the greens on each of the ratings as consistent as possible with the least amount of code. Turns out it was close enough but not just right. (I'm happy with it anyway)\n\nRegardless, This was an interesting experience for me. Before this, I was having a \"measure twice, cut once\" mindset and would get stuck on finding out the best visualization (lost many hours that way). This time, I went head first into the visualization and built from there, and the results were much more better for me.\n\nThroughout the notebook, I was trying to figure my way around getting the visualizations with unequal data sizes; I still haven't found the most accurate solution to it. Maybe there is a specific term to this, or maybe there isn't a clear cut way to approaching unequal data without cutting it down to size, I don't know.\n\n**Closing note**\nTo you, the reader, I thank you for reaching this far in what I consider to be my first analysis of reviews and ratings. Comments, criticism, or just general advice on the visualizations or the code? I'd love to hear from you.","ebb8d638":"**The Ratings**\n\nThe ratings are mostly complete numbers, if not complete, they're definite values like a 3 or a 3.5 or something. There are some rows with no ratings which have not been in this (although I think a visualization can be generated discarding the no ratings)\n\nThe data contains an Overall rating, along with ratings for Work Balance, Culture Values, Career Opportunities, Compensation Benefits, and Senior Management; all of which were listed under summaries, pros, and (or) cons for each company","d39bf99e":"My third notebook! I have to admit that I find the plot function from Pandas very convenient for basic plots. Seaborn was pretty interesting with more visualizations, and had options to add in colors (although with some extra work, I'm pretty sure it'd be possible in matplotlib)\n\nThis time I'm trying out Plotly mostly because it allows for creating more interactive graphs. This one sure has too many options to configure, so I'm still finding my way around the libraries and options. I also found that Plotly requires me to define properties as dictionaries or manually as properties (something I didn't think of or even pass by in the other libraries)\n\nThis is also my first notebook involving reviews or languages. I first thought I'd use the NLTK library but realized that I'd have to train the models myself. Since I'm just getting into NLP, I decided to use TextBlob which is built on top of NLP.","2d51888e":"**Word clouds for Summary, Pros, and Cons**\n\nI realize after running the visualization that this is overkill. 18 visualizations in total and so many ways this can be arranged! \n* Run 1 visualization for everything\n* Run everything in 1 visualization\n* Run visualizations of pros, cons, and summary and group by company \n* Run visualizations by company and group by summary, pros, and cons\n\nThere might be other ways of running this, but I'll go with running 1 visualization for everything\n\nAnyway, all company summaries have common words like *good, great, place, work*. So I guess it's great working for all of them. There are some words which are more frequent in some companies than the others. Like *Software* for Google and Microsoft for instance, or *Engineer* for Microsoft and Facebook, and so on. \n\nPros list words like *benefits, environment, culture*. Sure working for one of the big companies does stand out among peers, on paper and(or) in conversation. This is backedup with the pros. I guess people are happier with the perks of the job (*perks* also mentioned in the pros).\n\nWhen it comes to cons, I'd like to think that people don't find it as easy as they expected; aka the word *hard*, which is found in all visualizations but not the most common. *Managers* and *Management*, on the other hand, are most commonly mentioned in the cons for each company. Interestingly, the word *work* is found in the Pros and Cons for each company. Maybe working there is like cutting with a double edged blade? (Probably not, but who am I to comment on companies I haven't worked for)\n\nLooking at the notes, I'd like to make my own guess that the work becomes too difficult, or that there's differences of opinion\/ideas between employee and management.","6ed5716f":"**Overall Rating**: Facebook appears to be the clear winner, followed by Google, Apple, Netflix, Amazon, and Microsoft\n\n**Work Balance**: Google appears to provide better work balance followed by Facebook, Microsoft, Apple, Netflix, and finally Amazon\n\n**Culture Values**: Facebook comes out on top again followed by Google, Apple, Netflix, Amazon, Microsoft\n\n**Career Opportunities**: Facebook appears to provide better career opportunities followed by Google, Amazon, Microsoft, Apple, Netflix\n\n**Compensation Benefits**: Facebook pay\/benefits is valued more over the other companies followed by Google, Netflix, Apple, Microsoft, Amazon\n\n**Senior Management**: The senior management appears to be better with facebook followed by Google, Apple, Netflix, Amazon, and Microsoft\n\n**Thoughts**\n\nFacebook and Google rank among the top consistently\nAmazon is ranked as not so good when it comes to Work Balance, Culture values, Compensation benefits, and Senior management\nMicrosoft doesn't get any better when it comes to Culture Values, Career Opportunities, Compensation benefits, and Senior management\n\nNow these are just peer ratings and each person is entitled to their opinion. Whether or not this holds true is to be experienced by the employee themselves. Will this influence my opinion if I was applying to one of these organizations? No.\n\nI'd like to think that it comes down to how compatible an employee's ideals\/goals\/ideas align with the management that they're working for. Or rather how flexible an employee can be with their ideals\/goals\/ideas when it is not aligned with those of the company.","17418109":"**Polarity and Subjectivity**\n\nTextBlob provides a polarity number between -1 to +1, with -1 indicating very negative and +1 indicate very positive. It also provides a subjectivity score between 0 and 1 with 0 being least subjective and 1 being very subjective.\n\nSo I generate the polarity and subjectivity to the summary. Not very helpful when it comes to the Pros or Cons because the statements speak for themselves","a5cb3ad9":"**Polarity of Summary per company**\n\nNever thought that a title would rhyme, but I digress. \n\nThe summaries for each company is mostly neutral to slightly positive. There are a few negative reviews, but the positives appear to outweigh the negatives.\n\nGoing back to the sample size problem that I've encountered, there's way too many reviews for certain companies. This has suppressed the smaller numbers. For instance, there's 382 summaries for Amazon that are very negative and 1181 reviews that are very positive.\n\n**Note to Self:** If I took the company with the least reviews, and then took the same amount of random samples from the other companies, It'd be more uniform but I'm guessing it wouldn't make much of a difference (since it's a distribution). But if I were generating a bar graph of the ratings and didn't consider the # of reviews per company, then the comparitively large number of reviews for Amazon would indicate that it is probably the best place to work as opposed to the other companies","dd5cbbf3":"**Subjectivity of Summary per company**\n\nNot much here other than inferring that the summaries are mostly \"objective\" and a few of them could be either objective or subjective (subjectively neutral maybe?)\n\nSimilar to Polarity, identifying the company with the fewest reviews and taking an equal amount of random samples from all of them might make the visualization a bit more uniform, but with this being a histogram, it wouldn't skew the results by a very large margin","f58fa1b3":"**The Data**\n\nThe columns in this are pretty much expected. We have the company, location, reviews, and also a rating","77617307":"**Reviews per Company**\n\nLearning from my past experiences, I learnt that having more data means that the inferences would be pretty accurate.\n\nIn this case, there's way too many Amazon, Microsoft, and Apple Reviews, and comparitively less data for Google, Facebook, and Netflix, I'm not sure how I'd be able to compare company reviews. Netflix does have around 800 reviews, but it' 800 netflix reviews against 26000 amazon reviews.\n\nI know normalization would help for varying data, but what should be done when the data is already normalized (take the ratings for instance), but the number of samples are off by a very large margin (800 for netflix against the others)\n\nI tried looking up how to handle visualizations for data of unequal sizes. I came up empty handed; Maybe there's a term for this that I don't know. Maybe I could randomly select reviews for all companies based on the company with the least count? or maybe I'm overthinking this by thinking of machine learning vs data analysis?"}}