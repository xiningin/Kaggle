{"cell_type":{"f085eef0":"code","25e0c4f9":"code","53810bb0":"code","9b94fecb":"code","9be9da3f":"code","ad78dca8":"code","e1bcc03c":"code","9ffafd2a":"code","615256bd":"code","9a0f85d4":"code","01af3512":"code","8fbd77bf":"code","f20dff5d":"code","7491de42":"code","aa45eaab":"code","390a7c6a":"code","ff06b4fd":"code","7216ee5d":"code","9fb4e9f9":"code","a91f0bde":"code","4bf66edd":"code","52c60b1f":"code","c55f410f":"code","ac1c7137":"code","d5f264ac":"code","3c8de1e3":"code","819b0f91":"code","534916c0":"code","ab82daee":"code","7952b2f5":"code","eb3ed57c":"code","d378052f":"code","8bc5ccb6":"code","5c94888d":"code","867a742e":"code","c9763f27":"code","c2d66b75":"markdown","82587be1":"markdown","7ab34b02":"markdown","bda523d9":"markdown","1b93343f":"markdown","0e44cd1d":"markdown","267465a9":"markdown","990ee06a":"markdown","880ecbaa":"markdown"},"source":{"f085eef0":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","25e0c4f9":"df = pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")","53810bb0":"df.head()","9b94fecb":"#checking for the null values\ndf.isnull().sum()","9be9da3f":"#now we check the number of rows and columns in the dataset\ndf.shape","ad78dca8":"df.describe()","e1bcc03c":"df.dtypes","9ffafd2a":"sns.pairplot(df, hue='HeartDisease')","615256bd":"sns.barplot(data=df,x='Sex',y ='HeartDisease')","9a0f85d4":"plt.figure(figsize=(15,5))\nsns.countplot(data=df,x='Age')\nplt.title('Age Distribution')","01af3512":"plt.figure(figsize=(15,5))\nplt.subplot(221)\nsns.histplot(x='Cholesterol',data=df,kde=True)\nplt.title('Cholesterol data')\n\nplt.figure(figsize=(15,5))\nplt.subplot(222)\nplt.title('MaxHR Data')\nsns.histplot(x='MaxHR',data=df,kde=True)","8fbd77bf":"from sklearn.preprocessing import LabelEncoder","f20dff5d":"le = LabelEncoder()","7491de42":"df['Sex'].value_counts()","aa45eaab":"df['Sex']= le.fit_transform(df['Sex'])","390a7c6a":"df['Sex'].value_counts()","ff06b4fd":"df['ChestPainType'].value_counts()","7216ee5d":"df['ChestPainType']= le.fit_transform(df['ChestPainType'])","9fb4e9f9":"df['ChestPainType'].value_counts()","a91f0bde":"df['ExerciseAngina'] = le.fit_transform(df['ExerciseAngina'])\ndf['RestingECG'] = le.fit_transform(df['RestingECG'])\ndf['ST_Slope'] = le.fit_transform(df['ST_Slope'])","4bf66edd":"df.head(5)","52c60b1f":"tc = df.corr()","c55f410f":"sns.heatmap(tc)","ac1c7137":"df.columns","d5f264ac":"X = df[['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS',\n       'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope']]\nY = df[['HeartDisease']]","3c8de1e3":"from sklearn.model_selection import train_test_split  ","819b0f91":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=20)","534916c0":"print(X_train.shape)\nprint(Y_train.shape)","ab82daee":"from sklearn.linear_model import LogisticRegression","7952b2f5":"model = LogisticRegression(solver='liblinear')","eb3ed57c":"model.fit(X_train,Y_train)","d378052f":"pred = model.predict(X_test)","8bc5ccb6":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","5c94888d":"cm = confusion_matrix(Y_test,pred)","867a742e":"cm","c9763f27":"print(metrics.accuracy_score(Y_test,pred))","c2d66b75":"# **Heart Failure Prediction**","82587be1":"From the above given data, there are 918 rows and 12 columns in the dataset.","7ab34b02":"### To check the accuracy and confusion matrix ","bda523d9":"### To change the categorical columns to numerical values. Here we use label encoding  ","1b93343f":"## features and Target","0e44cd1d":"## Splitting the data into train and test data","267465a9":"Here the features are Age,Sex,cheatpain type, Fasting BP, Resting ECG, MaxHeartRate(HR),Exercise angina, Oldpeak, ST_slope\nand the Target is either the person's heart will have disease or not. \n\nAs the target variable is discrete, either 1 or 0. \nSo the problem statement is a Classification(Binary).","990ee06a":"### Loading the datasets","880ecbaa":"As the dataset is already cleaned and so there is no null values in the dataset."}}