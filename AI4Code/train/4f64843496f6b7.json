{"cell_type":{"1a437101":"code","dff49d3c":"code","d7ad1a58":"code","a1096165":"code","b5a4052b":"code","0e956f78":"code","f2a48fc5":"code","76f5bd09":"code","52adc803":"code","db95e994":"code","41f87d2e":"code","5321990d":"code","341455d0":"code","f66c3b0d":"markdown","8f46e0af":"markdown","d7bb8bca":"markdown","4819380e":"markdown","6dc5d6a5":"markdown","1b5bf09f":"markdown","3dbf2d68":"markdown","352b8db9":"markdown","ef425104":"markdown","da92688c":"markdown","ca4b6cec":"markdown","a212fbd2":"markdown","ade49634":"markdown"},"source":{"1a437101":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # For visualization the data\nimport seaborn as sns # For statistical graphics plotting with beautiful styles and color\n\n# Input data files are available in the read-only \"..\/input\/\" director\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dff49d3c":"df = pd.read_csv('\/kaggle\/input\/salary\/Salary.csv')","d7ad1a58":"x=df.loc[:, \"YearsExperience\"].values\ny=df.loc[:, \"Salary\"].values","a1096165":"df.isnull().sum()","b5a4052b":"m=len(x)\nX=np.column_stack((np.ones(m), x))\nY=np.row_stack((y))\ntheta=np.zeros((2,1))\niterations=1500\nalpha=0.03","0e956f78":"def compute_cost(X, y, theta):\n    m=len(y)\n    J=0\n    hx=np.dot(X, theta)\n    J=(1\/(2*m))*np.sum(np.square(hx-y))\n    return J","f2a48fc5":"def gradient_descent(X, y, theta, alpha, iterations):\n    m=len(y)\n    J_history=np.zeros((iterations, 1))\n\n    for iter in range(iterations):\n        theta = theta - alpha*(1\/m)*X.T.dot(X.dot(theta) - np.transpose([y]))\n        J_history[iter]=(compute_cost(X, y, theta))\n\n    return theta, J_history","76f5bd09":"theta, J_history = gradient_descent(X, y, theta, alpha, iterations)\ntheta","52adc803":"plt.scatter(x, y, color='red')\nplt.plot(X[:, 1], X.dot(theta), '-', label='Linear regression')\nplt.legend(loc='lower right')\nplt.title('Salary')\nplt.xlabel('Experience (in years)')\nplt.ylabel('Salary')","db95e994":"plt.plot(range(0,iterations), J_history)\nplt.xlabel('Iterations')\nplt.ylabel('Cost Function')","41f87d2e":"compare = pd.DataFrame(x, columns=[\"Experience (in years)\"])\ncompare[\"Actual Salary\"] = np.transpose([y])\ncompare[\"Predicted Salary\"] = np.round(X.dot(theta))\n# compare[\"Difference\"] = np.transpose([y])-np.round(X.dot(theta))\ncompare","5321990d":"# plt.scatter(X[:, 1], (X.dot(theta)-Y))\nsns.distplot(X.dot(theta)-y).set_title('Error in prediction')","341455d0":"print(np.array([1, 11.2]).dot(theta))","f66c3b0d":"## Function to calculate cost function,  \ud835\udc3d(\ud835\udf03)\nCost function computes the cost using theta as the parameter for linear regression to fit the data points in X and y so as to check the convergence of the gradient descent implementation.","8f46e0af":"## Comparing the actual salary and predicted salary","d7bb8bca":"## Defining values for implementing linear regression","4819380e":"## Checking if there is any null value present in the dataset","6dc5d6a5":"## Importing Libraries","1b5bf09f":"## Plotting cost function vs iterations\u00b6\nThis shows how the cost function decreases after every iteration.","3dbf2d68":"## Plotting the error in prediction","352b8db9":"## Visualising the prediction\nCreating a scatter plot between Salary and Experinece (in years). Also plotting the linear regression model on same plot.","ef425104":"# Salary Predictions Based on Years of Experience","da92688c":"## Importing the dataset","ca4b6cec":"## Calling the gradient_descent function and printing the computed theta","a212fbd2":"## Function to implement gradient descent\nPerforms gradient descent to learn theta. Updates theta by taking iterations gradient steps with learning rate alpha.","ade49634":"### Test"}}