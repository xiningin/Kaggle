{"cell_type":{"de6e23f1":"code","fd98bbbd":"code","0099a1b9":"code","b37eb99f":"code","8012ab87":"code","8fbf0475":"code","51507284":"code","dbc1ac7c":"code","755e563d":"code","d8522672":"code","28e54010":"code","7c5af185":"code","7b6b20b3":"markdown","6c9f7815":"markdown","5cbeb601":"markdown","d7844697":"markdown","1bd1c591":"markdown","aa71b6e3":"markdown","f7502086":"markdown","b08340db":"markdown","12b19aa4":"markdown","e5e2d211":"markdown","cef0d7f4":"markdown","04258095":"markdown"},"source":{"de6e23f1":"import os\nimport ast\nfrom collections import namedtuple\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tqdm import tqdm\nfrom PIL import Image\n\nimport joblib\nfrom joblib import Parallel, delayed\n\nimport cv2\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom albumentations.core.transforms_interface import DualTransform\nfrom albumentations.augmentations.bbox_utils import denormalize_bbox, normalize_bbox\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib.image import imsave","fd98bbbd":"import sys\nsys.path.insert(0, \"..\/input\/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"..\/input\/omegaconf\")\n\nimport torch\nimport torchvision\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom glob import glob\n\nfrom PIL import Image\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2, ToTensor\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\nfrom tqdm.notebook import tqdm\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nfrom matplotlib import pyplot as plt\n\nSEED = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","0099a1b9":"train_folder_path = \"\/kaggle\/input\/global-wheat-detection\/train\/\"\ntest_folder_path = \"\/kaggle\/input\/global-wheat-detection\/test\/\"\n\ndirlist  = os.listdir(train_folder_path)\ndirtlist =  os.listdir(test_folder_path)\na=len(dirlist)\nb=len(dirtlist)\nprint(\"# of train sample: \" , a)\nprint(\"# of test sample: \" , b)\n\na=random.randint(0,a-1)\nb=random.randint(0,b-1)\nc=random.randint(0,a)\nd=random.randint(0,a)\n\nim = cv2.imread(os.path.join(train_folder_path, dirlist[a]))\nim1 = cv2.imread(os.path.join(train_folder_path, dirlist[a+b]))\nim3 = cv2.imread(os.path.join(train_folder_path, dirlist[a-b]))\nim2 = cv2.imread(os.path.join(test_folder_path, dirtlist[b]))\nim4 = cv2.imread(os.path.join(train_folder_path, dirlist[c+b]))\nim5 = cv2.imread(os.path.join(train_folder_path, dirlist[d+b]))\nim6 = cv2.imread(os.path.join(train_folder_path, dirlist[c-+b]))\n\n\nprint(\"shape of the train photo: \", im.shape)\nprint(\"shape of the test photo: \", im2.shape)\n\n\n\n\n\nfig = plt.figure()\n\n\nf, ax = plt.subplots(2,3,figsize=(20, 20)) \n\nax[0][0].imshow(im)\nax[1][0].imshow(im2)\nax[1][1].imshow(im1)\nax[0][1].imshow(im3)\nax[1][2].imshow(im5)\nax[0][2].imshow(im4)\n\n\nplt.show()\n","b37eb99f":"# Constants\nBASE_DIR = '\/kaggle\/input\/global-wheat-detection'\nWORK_DIR = '\/kaggle\/working'\n\n\ntrain_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'))\nprint(\"Initial DF shape: \", train_df.shape)\ntrain_df.head(6)\n\n# Let's expand the bounding box coordinates and calculate the area of all the bboxes\ntrain_df[['x_min','y_min', 'width', 'height']] = pd.DataFrame([ast.literal_eval(x) for x in train_df.bbox.tolist()], index= train_df.index)\ntrain_df = train_df[['image_id', 'bbox', 'source', 'x_min', 'y_min', 'width', 'height']]\ntrain_df['area'] = train_df['width'] * train_df['height']\ntrain_df['x_max'] = train_df['x_min'] + train_df['width']\ntrain_df['y_max'] = train_df['y_min'] + train_df['height']\ntrain_df = train_df.drop(['bbox', 'source'], axis=1)\ntrain_df = train_df[['image_id', 'x_min', 'y_min', 'x_max', 'y_max', 'width', 'height', 'area']]\n\n# There are some buggy annonations in training images having huge bounding boxes. Let's remove those bboxes\ntrain_df = train_df[train_df['area'] < 100000]\n\nprint(\"Final DF shape:\",train_df.shape)\ntrain_df.head(6)","8012ab87":"# Read the image on which data augmentaion is to be performed\n\nimage = cv2.imread(os.path.join(train_folder_path, dirlist[a]),cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage \/= 255.0\nplt.figure(figsize = (10, 10))\nplt.imshow(image)\nplt.show()\nimage_id = dirlist[a][:-4]\nprint(image_id)","8fbf0475":"pascal_voc_boxes = train_df[train_df['image_id'] == image_id][['x_min', 'y_min', 'x_max', 'y_max']].astype(np.int32).values\npascal_voc_boxes.shape\ncoco_boxes = train_df[train_df['image_id'] == image_id][['x_min', 'y_min', 'width', 'height']].astype(np.int32).values\ncoco_boxes.shape\nassert(len(pascal_voc_boxes) == len(coco_boxes))\nlabels = np.ones((len(pascal_voc_boxes), ))","51507284":"def get_bbox(bboxes, col, color='white', bbox_format='pascal_voc'):\n    \n    for i in range(len(bboxes)):\n        # Create a Rectangle patch\n        if bbox_format == 'pascal_voc':\n            rect = patches.Rectangle(\n                (bboxes[i][0], bboxes[i][1]),\n                bboxes[i][2] - bboxes[i][0], \n                bboxes[i][3] - bboxes[i][1], \n                linewidth=2, \n                edgecolor=color, \n                facecolor='none')\n        else:\n            rect = patches.Rectangle(\n                (bboxes[i][0], bboxes[i][1]),\n                bboxes[i][2], \n                bboxes[i][3], \n                linewidth=2, \n                edgecolor=color, \n                facecolor='none')\n\n        # Add the patch to the Axes\n        col.add_patch(rect)","dbc1ac7c":"#Random Crop & VerticalFlip\n\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n        albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomCrop(height=350, width=350, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","755e563d":"#GaussNoise & Cutout\n\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Cutout(num_holes=8, max_h_size=26, max_w_size=56, fill_value=0, p=1),\n        albumentations.GaussNoise(var_limit=(0.002, 0.002), p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\n\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","d8522672":"#Random Snow\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomSnow(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","28e54010":"#RandomRain\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomRain(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","7c5af185":"#Random Sun Flake\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomSunFlare(flare_roi=(0, 0, 1, 0.4), src_radius=100, src_color=(255, 255, 255), p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","7b6b20b3":"# Kar Ya\u011fd\u0131rma","6c9f7815":"# WheatDet Augmentation Turkce Aciklamali\n\nAugmentation daha \u00e7ok projelerde ezberleme (overfitting) problemini \u00e7\u00f6zmek ve ba\u015far\u0131m\u0131 art\u0131rmak i\u00e7in kullan\u0131l\u0131r. Yapay sinir a\u011flar\u0131ndaki temel optimizasyon algoritmas\u0131 olan gradient descent ( momentumlar dahil) lokal min - max'a tak\u0131labilir. Bunlar\u0131 a\u015fman\u0131n g\u00fczel bir yolu datay\u0131 art\u0131rmak ve art\u0131r\u0131rken de farkl\u0131 yap\u0131lar kullanmakt\u0131r. Bu yap\u0131lar, foto\u011fraf\u0131 d\u00f6nd\u00fcrmek, foto\u011frafa yak\u0131nla\u015fmak veya uzakla\u015fmak, \u00fcst\u00fcnden par\u00e7alar \u00e7\u0131karmak, \u00fcst\u00fcne par\u00e7alar ilave etmek, g\u00fcr\u00fclt\u00fc eklemek, de\u011ferleriyle oynamak, renk kanallar\u0131ndan baz\u0131lar\u0131n\u0131 \u00e7\u0131karmak v.b olabilir. En ama en \u00f6nemli nokta: projenin ilgili oldu\u011fu konuda, ger\u00e7ek durumda kar\u015f\u0131la\u015f\u0131labilecek \u00f6rneklere g\u00f6re augmentation yapmakt\u0131r. \n\n\u00d6rne\u011fin araba tespiti yap\u0131yorsunuz diyelim. Arabay\u0131 vertical flip ile dikey aynalaman\u0131z g\u00fczel bir augmentationd\u0131r \u00e7\u00fcnk\u00fc ger\u00e7ek durumda arabalar her iki y\u00f6nde de gidebilir. Lakin horizantal flip yapmak yani arabay\u0131 ba\u015f a\u015fa\u011f\u0131 yapmak iyi bir durum olmayacakt\u0131r \u00e7\u00fcnk\u00fc ger\u00e7ek hayatta ara\u00e7lar lastikleri \u00fcst\u00fcnde giderler :)\n\nAlbumination k\u00fct\u00fcphanesi ile data augmentation ( Data art\u0131r\u0131m\u0131 )konusunu bu \u00e7al\u0131\u015fmada inceleyece\u011fiz. Yararland\u0131\u011f\u0131m\u0131z makale a\u015fa\u011f\u0131dad\u0131r, okuman\u0131z\u0131 tavsiye ederim:\n\n\nAlbumentations: Fast and Flexible Image Augmentations\n\nBuslaev, A., Iglovikov, V. I., Khvedchenya, E., Parinov, A., Druzhinin, M., & Kalinin, A. A. (2020). Albumentations: Fast and Flexible Image Augmentations. Information, 11(2), 125. doi:10.3390\/info11020125 \n\n> import albumentations\n","5cbeb601":"# G\u00fcne\u015f Yans\u0131mas\u0131 Ekleme","d7844697":"A\u015fa\u011f\u0131daki k\u00fct\u00fcphaneler, object detection i\u00e7in daha \u00e7ok.","1bd1c591":"Foto\u011fraflar\u0131 g\u00f6rselle\u015ftiriyoruz. 6 adet random foto\u011fraf \u00e7a\u011f\u0131r\u0131yoruz. ","aa71b6e3":"Foto\u011fraf\u0131n \u00fcst\u00fcne bounding box'\u0131 koyuyoruz. \u00c7ok basit bir i\u015flem. \u0130ster pascal-voc, ister coco olsun, koordinatlar\u0131 al\u0131p, foto\u011fraf\u0131n \u00fcst\u00fcne dikd\u00f6rtgen \u00e7iziyoruz. ","f7502086":"Bir adet foto\u011fraf \u00e7a\u011f\u0131r\u0131yoruz. BGR kanallar\u0131 RGB'ye \u00e7eviriyoruz. Daha sonras\u0131nda numpy float array'e d\u00f6n\u00fc\u015ft\u00fcr\u00fcyoruz.\nBir ba\u015fka ad\u0131m ise ( her zaman gerekli de\u011fil ama daha k\u00fc\u00e7\u00fck say\u0131larla u\u011fra\u015fmak i\u00e7in iyi bir y\u00f6ntem) de\u011ferleri 255'e b\u00f6lerek normalize ediyoruz. Bildi\u011finiz gibi RGB bir imgenin her bir renk kanal\u0131ndaki pixeller 0 ile 255 aras\u0131nda de\u011fer alabilir.\n\ndata frame --> np array'e \u00e7evriliyor:  \"  astype(np.int32).values \"","b08340db":"2 t\u00fcr bounding box vard\u0131r. Pascal-VOC ve COCO. Temel olarak ayn\u0131 yap\u0131lard\u0131r sadece bounding box kaydedilirken farkl\u0131 metrikleri saklamaktad\u0131rlar. \u0130nternette birbirine \u00e7evrim kodlar\u0131 mevcuttur.\n\npascal_voc yap\u0131s\u0131 :  [x_min, y_min, x_max, y_max]\n\nCOCO yap\u0131s\u0131 :  [x_min, y_min, width, height]\n\nData frame yap\u0131s\u0131ndaki bbox listesini 4 ayr\u0131 s\u00fctuna b\u00f6l\u00fcyoruz. G\u00f6rd\u00fc\u011f\u00fcn\u00fcz gibi xmin, ymin, width, height \u015feklindeki yap\u0131 bize COCO bounding box yap\u0131s\u0131na i\u015faret ediyor.\n\n","12b19aa4":"# Ya\u011fmur ya\u011fd\u0131rma","e5e2d211":"# Gaussian G\u00fcr\u00fclt\u00fc ekleme ve Cutout","cef0d7f4":"# Resize, Random Crpo ve Dikey d\u00f6nd\u00fcrme","04258095":"get_bbox fonksiyonu object detection i\u00e7in augmentation yaparken en \u00f6nemli yap\u0131lardan birisidir. Ana foto\u011frafa her nas\u0131l augmentation uyguluyorsan\u0131z, bounding box'lar da benzer \u015fekilde de\u011fi\u015fmelidir."}}