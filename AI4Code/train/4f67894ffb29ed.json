{"cell_type":{"0f51e6e3":"code","d3fe26ab":"code","3566b2fc":"code","6973f431":"code","cabab776":"code","b9c3953b":"code","a3ad869b":"code","80e72a6b":"code","350797e0":"code","2d460f00":"code","b168c677":"code","1d2dccea":"code","8eb54de9":"code","8f85c445":"code","6a5926aa":"code","d8206628":"code","0ef03e7f":"code","f5bd37b9":"code","a5f163a5":"code","5fe03844":"code","4955b6c2":"code","ca631021":"markdown","2b5b2df7":"markdown"},"source":{"0f51e6e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3fe26ab":"test_set = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/test.csv', index_col='ID_code')\ntrain_set = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/train.csv', index_col='ID_code')","3566b2fc":"test_set.head()","6973f431":"test_set.tail(2)","cabab776":"train_set.head()","b9c3953b":"train_set.tail(2)","a3ad869b":"test_set.describe()","80e72a6b":"train_set.describe()","350797e0":"y = train_set.iloc[:,0]\nX = train_set.drop(columns=['target'])\nX","2d460f00":"#Calculate of new features, aggreated of existing\nidx = X.columns.values\nfor df in [X, test_set]:\n    df['sum'] = df[idx].sum(axis=1)\n    df['min'] = df[idx].min(axis=1)\n    df['max'] = df[idx].max(axis=1)\n    df['mean'] = df[idx].mean(axis=1)\n    df['std'] = df[idx].std(axis=1)\n    df['skew'] = df[idx].skew(axis=1)\n    df['kurtosis'] = df[idx].kurtosis(axis=1)\n    df['med'] = df[idx].median(axis=1)","b168c677":"X.head()","1d2dccea":"test_set.head()","8eb54de9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","8f85c445":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","6a5926aa":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train, y_train)","d8206628":"y_pred = classifier.predict(X_test)","0ef03e7f":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","f5bd37b9":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()))\nprint(\"Standar Deviation: {:.2f} %\".format(accuracies.std()*100))","a5f163a5":"sc = StandardScaler()\nX = sc.fit_transform(X)\ntest_set_predict = sc.transform(test_set)\nclassifier.fit(X, y)\ny_submit = classifier.predict(test_set_predict)\ny_submit","5fe03844":"submission = pd.DataFrame({\n        \"ID_code\": test_set.index,\n        \"target\": y_submit\n    })\nsubmission.to_csv('sja-c2-log-reg.csv', index=False)","4955b6c2":"# Credits:\n# Kirill Eremenko, Hadelin Ponteves, SuperDataScience\n# https:\/\/www.kaggle.com\/gpreda\/santander-eda-and-prediction#Model","ca631021":"# Feature Engineering","2b5b2df7":"Since model shows good performance (acc 91%), let's train it with whole X and predict the test set."}}