{"cell_type":{"48452431":"code","d848b3ce":"code","df666fb8":"code","0023e1a5":"code","cfe7a642":"code","bd55f421":"code","1d12e500":"markdown"},"source":{"48452431":"import pandas as pd\nimport numpy as np\nimport glob\nfrom tqdm import tqdm\n\nfrom numpy.testing import assert_almost_equal","d848b3ce":"def compute_realized_volatility(wap_values):\n    \"\"\"Computes realized volatility from an array of weighted average prices\"\"\"\n    log_wap = np.log(wap_values)\n    log_return = np.diff(log_wap)\n    return np.sqrt((log_return ** 2).sum())\n\ndef get_time_id_data_splits(time_ids, data):\n    \"\"\"Returns zipped unique time_id and associated data\"\"\"\n    # Get unique_time_ids and their indices\n    unique_time_ids, indices = np.unique(time_ids, return_index=True)\n\n    # First index is zero so discard\n    assert indices[0] == 0\n    data_splits = np.split(data, indices[1:])\n    \n    return zip(unique_time_ids, data_splits)\n\ndef create_order_df(input_path):\n    \"\"\"Outputs a pandas dataframe with columns:\n            - stock_id\n            - time_id\n            - realized_volatility\n    \"\"\"\n    df = pd.read_parquet(input_path)\n    \n    # Compute weighted average price\n    time_ids, bid_price, bid_size, ask_price, ask_size = (df[col].values for col in ['time_id', 'bid_price1','bid_size1','ask_price1','ask_size1' ])\n    wap = (bid_price * ask_size + ask_price * bid_size) \/ (ask_size + bid_size)\n\n    # Compute realized vol for all time_ids\n    time_id_splits = get_time_id_data_splits(time_ids, wap)\n    output = {\"time_id\": [], \"realized_volatility\": []}\n    for time_id, wap_split in time_id_splits:\n        realized_volatility = compute_realized_volatility(wap_split)\n        output[\"realized_volatility\"].append(realized_volatility)\n        output[\"time_id\"].append(time_id)\n\n    # Convert data into a pandas dataframe\n    output_df = pd.DataFrame(output)\n\n    # Add stock_id column\n    stock_id = int(input_path.split(\"=\")[1])\n    output_df[\"stock_id\"] = stock_id\n\n    return output_df","df666fb8":"%%time\nbook_files = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\n\ndata = []\nfor input_path in tqdm(book_files):\n    data.append(create_order_df(input_path))\norder_df = pd.concat(data)\nprint(order_df.shape)","0023e1a5":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff()\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef create_order_df_pandas(input_path):\n    \"\"\"Outputs a pandas dataframe with columns:\n            - stock_id\n            - time_id\n            - realized_volatility\n    \"\"\"\n    df = pd.read_parquet(input_path)\n    \n    stock_id = int(input_path.split(\"=\")[1])\n    df[\"stock_id\"] = stock_id\n\n    df['wap'] =(df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1'])  \/ (df['bid_size1'] + df['ask_size1'])\n    df['log_return'] = df.groupby(['time_id'])['wap'].apply(log_return)\n    output_df = df.groupby(['time_id', 'stock_id']).agg(\n        realized_volatility=(\"log_return\", realized_volatility),\n    ).reset_index()\n    return output_df","cfe7a642":"%%time\nbook_files = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\n\ndata = []\nfor input_path in tqdm(book_files):\n    data.append(create_order_df_pandas(input_path))\norder_df_pandas = pd.concat(data)\nprint(order_df_pandas.shape)","bd55f421":"# Ensure computed values are almost equal\nfor col in order_df.columns:\n    assert_almost_equal(order_df[col].to_numpy(), order_df_pandas[col].to_numpy(), decimal=6)","1d12e500":"## Introduction\n\nThis notebook builds on [the work done here](https:\/\/www.kaggle.com\/slawekbiel\/naive-but-fast-submission) to show how to use numpy to speed up data processing.\n\nI've done a timed comparison of numpy vs. pandas to create a dataframe for all `stock_id` and `time_id` values. It shows that numpy is around 10x quicker than the pandas implementation given in the introductory notebook.\n\nAs you build out more features, using the numpy implementation will:\n\n* Enable much quicker iterations (hours -> minutes) \ud83e\udde0\n* Speed up submissions \u2615\ufe0f\n* Streamline your workflow \ud83d\udeb4\n\nIf you like this notebook please show your appreciation with an upvote \ud83d\ude03"}}