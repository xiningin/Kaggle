{"cell_type":{"f3e40819":"code","29c250ba":"code","3f266818":"code","4c9f021a":"code","d30d6405":"code","0b2d65be":"code","88aa923c":"code","5ff2cec7":"code","a46eccaa":"code","69a6c665":"code","8f2c6449":"code","68393c2b":"code","a778e892":"code","7a138b9c":"code","994bc8cb":"code","29ebc38b":"code","45994955":"markdown","2243be75":"markdown","885265ef":"markdown","a1022abc":"markdown","84adaecf":"markdown","ae4fe674":"markdown","6546f373":"markdown","99ea9467":"markdown","1161e88e":"markdown","9aba02dd":"markdown"},"source":{"f3e40819":"import os\nimport numpy as np\nimport imageio\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom tqdm import tqdm_notebook as tqdm\nimport torch.optim as optim\nfrom IPython.display import Image\n\nimport warnings\nwarnings.filterwarnings('ignore')","29c250ba":"Image(filename = '\/kaggle\/input\/imagesforkernel\/Autoencoder_fig.png')","3f266818":"Image(filename='\/kaggle\/input\/imagesforkernel\/autoenc.png')","4c9f021a":"IMG_DIR = '\/kaggle\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/'","d30d6405":"plt.figure(figsize=(15,10))\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    choose_img = np.random.choice(os.listdir(IMG_DIR))\n    image_path = os.path.join(IMG_DIR,choose_img)\n    image = imageio.imread(image_path)\n    plt.imshow(image)","0b2d65be":"class Autoencoders(nn.Module):\n    def __init__(self):\n        super().__init__()\n        ### encoder\n        self.conv1 = nn.Conv2d(3,64,5)\n        self.maxpool = nn.MaxPool2d(2,return_indices=True)\n        self.conv2 = nn.Conv2d(64,64,5)\n        self.conv3 = nn.Conv2d(64,128,5)\n        ### decoder\n        self.deconv1 = nn.ConvTranspose2d(128,64,5)\n        self.unpool = nn.MaxUnpool2d(2)\n        self.deconv2 = nn.ConvTranspose2d(64,64,5)\n        self.deconv3 = nn.ConvTranspose2d(64,3,5)\n    \n    def forward(self,x):\n        x = self.conv1(x)\n        x,ind1 = self.maxpool(x)\n        x = self.conv2(x)\n        x,ind2 = self.maxpool(x)\n        x = self.conv3(x)\n        \n        x = self.deconv1(x)\n        x = self.unpool(x,ind2)\n        x = self.deconv2(x)\n        x = self.unpool(x,ind1)\n        x = self.deconv3(x)\n        return x","88aa923c":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ntrain_transform = torchvision.transforms.Compose([\n    transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize\n])\n\ntrain_dataloader = torch.utils.data.DataLoader(dataset=torchvision.datasets.ImageFolder('\/kaggle\/input\/celeba-dataset\/img_align_celeba\/',\n                                                                                       transform=train_transform),\n                                              shuffle=True,batch_size=32,num_workers=0)","5ff2cec7":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","a46eccaa":"model = Autoencoders().to(device)\n\ncriterian = nn.MSELoss()\noptimizer = optim.Adam(model.parameters())","69a6c665":"n_epochs = 2 ### increase number of epochs for better result\nfor epoch in tqdm(range(n_epochs)):\n    model.train()\n    iteration = 0\n    for data,_ in tqdm(train_dataloader):\n        optimizer.zero_grad()\n        data = data.to(device)\n        output = model.forward(data)\n        loss = criterian(output,data)\n        loss.backward()\n        optimizer.step()\n        if iteration%1000 == 0:\n            print(f'iteration: {iteration} , loss : {loss.item()}')\n    print(f'epoch: {epoch} loss: {loss.item()}')","8f2c6449":"torch.save(model.state_dict(),'autoencoder.h5')","68393c2b":"model1 = Autoencoders()\nmodel1.load_state_dict(torch.load('autoencoder.h5'))\nmodel1.eval()","a778e892":"for data,_ in train_dataloader:\n    break","7a138b9c":"pred_img = model1(data)\npred_img = pred_img.detach().numpy()\npred_img = pred_img.reshape(32,224,224,3)","994bc8cb":"plt.imshow(pred_img[0])\nplt.show()","29ebc38b":"new_data = data.reshape(32,224,224,3)\n\nplt.imshow(new_data[0])\nplt.show()","45994955":"### Autoencoders : \n#### An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal \u201cnoise\u201d.\n\n#### The simplest form of an autoencoder is a feedforward, non-recurrent neural network similar to single layer perceptrons that participate in multilayer perceptrons (MLP) \u2013 having an input layer, an output layer and one or more hidden layers connecting them \u2013 where the output layer has the same number of nodes (neurons) as the input layer, and with the purpose of reconstructing its inputs (minimizing the difference between the input and the output) instead of predicting the target value.\n","2243be75":"### Autoencoder Model","885265ef":"### Predicted Images","a1022abc":"### Our Images ","84adaecf":"### Save Model","ae4fe674":"### Loading and transforming Images","6546f373":"### Please <B> UPVOTE <\/B> if you like my notebook","99ea9467":"### Original Image","1161e88e":"### Let's test our model on 1 image","9aba02dd":"### Training AutoEncoders\n\nNote: It will take approx 30 min for each epochs"}}