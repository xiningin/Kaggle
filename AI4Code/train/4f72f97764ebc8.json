{"cell_type":{"f6b015fc":"code","94e55503":"code","f31eb03e":"code","8babc949":"code","b0c70b84":"code","3b1bd0f4":"code","fa319d5f":"code","01e48ade":"code","941c5826":"code","ff13806d":"code","a7a2e493":"code","34024645":"markdown","05c7b154":"markdown","b08a5f0d":"markdown","d5f11a0d":"markdown","2d24b7ea":"markdown","00a5f54d":"markdown","3e712bc0":"markdown","8e2ff181":"markdown","e3c98d7d":"markdown","c7f31c27":"markdown","612b2765":"markdown","75a59b6d":"markdown","418c2d66":"markdown","bdc9800d":"markdown","79a0ec5d":"markdown","07b92287":"markdown","a43917f3":"markdown","67e0b65f":"markdown","11079108":"markdown","e627864c":"markdown","bf23bb0f":"markdown","2d360466":"markdown","be99f472":"markdown","6c5fea12":"markdown","9347fb4f":"markdown"},"source":{"f6b015fc":"# Import the dependencies\nimport numpy as np\nfrom scipy.linalg import toeplitz, cholesky, sqrtm\nfrom scipy.linalg import inv\nfrom scipy import signal\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\nprint(\"Done\")","94e55503":"# Setting up the time data:\ndt = 0.005; # integration step, average neuron resets 200 times per second\nT = 5+dt; # maximum time considered\nN = np.int(np.round(T\/dt)) #Amount of data points\nt = np.arange(0,T,dt)\nprint ('Amount of data points: ', N)\nprint ('Starting with', t[0:5])\nprint ('Ending with', t[N-5:N])\nprint ('Data elements', np.size(t))","f31eb03e":"# Example to draw random samples using the python numpy.random.normal function  \n# Generates a normal (Gaussian) distribution with a certain mean (0) and standard deviation (3)\nw_first = np.random.normal(0,3,N)\nprint('Example 1')\nprint('Generate random single zero-mean sequences with standard deviation 3')\nprint('First 10 values of a zero-mean random sequence for visual inspection')\nprint(w_first[0:10])\nprint('')\n\nprint ('Example 2')\nprint('Generate random zero-mean sequences from a covaraince matrix')\n# Example to generate random samples series with desired covariance matrix \n# note: on the diagonal you will find the variances, is is a symmetric matrix\n# This method is capable to generate noise with covariances but in case of active inference we generate independent noise, \n# hence 0 on the non-diagonals\nnp.random.seed(123456)\nSw = np.matrix('3 0 0;0 9 0; 0 0 16')\nn = Sw.shape[1] # dimension of noise = amount of sequences to be generated \nL =cholesky(Sw, lower=True)  #Cholesky method\nw = np.dot(L,np.random.randn(n,N))\n\n# Plot the first white noise sequence:\nplt.plot(t[0:200],w.T[0:200,1],label='white noise'); \nplt.title('Noise sequence 1, first second')\nplt.legend(loc='upper right')\nplt.show;\n# some plt versions expect data in same dimension, hence the w.T to align with w\n\n# Calculate the variance\/covariance of the generated data sets\n\nprint (\"Covariance matrix\")\nprint(Sw)\nprint (\"Estimated variance\/covariance of generated random sequence\")\nprint(np.cov(w))\nprint (\"The mean of sequence 1: \", np.mean(w[1,:]))\n","8babc949":"# Example of a univariate case (vector of 1 number)\n# In this example an embedding order of 3 (and thus has 4 entries)\nD= np.matrix('0 1 0 0 ; 0 0 1 0 ; 0 0 0 1 ; 0 0 0 0')\nprint ('Derivative operator')\nprint (D)\nprint ('vector with 1 data point in generalized coordinates of motion with embedding order 3')\nx = np.matrix('1; 2; 3; 4')\nprint (x)\nprint ('Result')\ndx = np.dot(D,x)\nprint (dx)\nprint ('vector with 2 data points in generalized coordinates of motion with embedding order 3')\ny = np.matrix('1 4; 2 3; 3 2 ; 4 1')\nprint (y)\nprint ('Result')\ndy = np.dot(D,y)\nprint (dy)","b0c70b84":"def makeNoise(C,s2,t):\n    \"\"\"\n    Generate coloured noise \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        C       - variance of the required coloured noise expressed as desired covariance matrix\n        s2      - temporal smoothness of the required coloured noise, expressed as variance of the filter\n        t       - timeline \n        \n    OUTPUT:\n        ws      - coloured noise, noise sequence with temporal smoothness\n    \"\"\"\n    \n    if np.size(C)== 1:\n        n = 1\n    else:\n        n = C.shape[1]  # dimension of noise\n        \n    # Create the white noise with correct covariance\n    N = np.size(t)      # number of elements\n    L =cholesky(C, lower=True)  #Cholesky method\n    w = np.dot(L,np.random.randn(n,N))\n    \n    if s2 < 1e-5: # return white noise\n        return w\n    else: \n        # Create the noise with temporal smoothness\n        P = toeplitz(np.exp(-t**2\/(2*s2)))\n        F = np.diag(1.\/np.sqrt(np.diag(np.dot(P.T,P))))\n        K = np.dot(P,F)\n        ws = np.dot(w,K)\n        return ws","3b1bd0f4":"# Example to generate coloured noise with desired covariance matrix \n\nnp.random.seed(123456) # same random seed so same random white noise generated as previous example\nws_64 = makeNoise(Sw,1\/64,t)\nnp.random.seed(123456) # same random seed so same random white noise generated as previous example\nws_4 = makeNoise(Sw,1\/4,t)\nnp.random.seed(123456) # same random seed so same random white noise generated as previous example\nws_512 = makeNoise(Sw,1\/512,t)\n\n\n# Plot the noise with temporal smoothness sequence (first second of sequence 1):\nplt.plot(t,w.T[:,1],label='white noise')\nplt.plot(t,ws_64.T[:,1],label='coloured noise 1\/64')\nplt.plot(t,ws_4.T[:,1],label='coloured noise 1\/4') \nplt.plot(t,ws_512.T[:,1],label='coloured noise 1\/512') \nplt.title('Coloured noise ')\nplt.legend(loc='upper right')\nplt.show;\n\nprint (\"Covariance matrix\")\nprint(Sw)\nprint (\"Estimated variance\/covariance of generated random sequence with temporal smoothness\")\nprint(np.cov(ws_64))\n","fa319d5f":"def temporalC(p,s2):\n    \"\"\"\n    Construct the temporal covariance matrix S for noise with embedding order p and smoothness parameter s\n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n        \n    OUTPUT:\n        S       - temporal covariance matrix ((p+1) x (p+1))\n    \"\"\" \n\n    q = np.arange(p+1)\n    \n    r = np.zeros(1+2*(p))\n    r[2*q] = np.cumprod(1-2*q)\/(2*s2)**(q)    \n    \n    S = np.empty([0,p+1])\n\n    for i in range(p+1):\n        S = np.vstack([S,r[q+i]])\n        r = -r\n           \n    return S ","01e48ade":"# Example temporal covariance matrix\np=5 # embedding order 5 of generative model, is the number of derivatives. p=5  means we have \u03bc(0)  until  \u03bc(6) , which means the vector has 6 entries\ns2_w = 1 # selected variance of 1 so you can easily compare with the printed example above\nprint(\"Temporal covariance matrix:\")\nprint(temporalC(p,s2_w))\nSigma_w = 1\n\nprint(\"Covariance matrix:\")\nprint( np.kron(temporalC(p,s2_w),Sigma_w))\n\nprint(\"Precision matrix:\")\nprint(inv(np.kron(temporalC(p,s2_w),Sigma_w)))","941c5826":"# Example temporal covariance matrix\n\np=5 # embedding order 5 of generative model, is the number of derivatives. p=5  means we have \u03bc(0)  until  \u03bc(6) , which means the vector has 6 entries\n# Baseline\ns2_w = 1 \nSigma_w = 1\nprint(\"Covariance matrix baseline:\")\nprint(np.kron(temporalC(p,s2_w),Sigma_w))\n\n# selected filter variance of 0.5 so you can easily see the numbers on the diagonal grow quickly and thus less influence of higher order motions\ns2_w = 0.5 \nSigma_w = 1\nprint(\"Covariance matrix with smaller variance of the filter so more rough noise:\")\nprint(np.kron(temporalC(p,s2_w),Sigma_w))\n\n# selected noise variance of 3 so you can easily see the numbers on the diagonal grow quickly and thus less influence of higher order motions\ns2_w = 1 \nSigma_w = 3\nprint(\"Covariance matrix with higer variance is more noise:\")\nprint(np.kron(temporalC(p,s2_w),Sigma_w))","ff13806d":"# Same sample code to highlight the power of matrix calculations\n\nv = np.matrix('1; 2; 3')\nA= np.matrix(' 1 2 3 ; 4 5 6 ; 7 8 9 ')\nB= np.matrix(' 3 0 0 ; 0 6 0 ; 0 0 9 ')\n\nprint ('Example matrix general A')\nprint(A)\nprint ('Example covariance matrix B')\nprint(B)\nprint ('Example vector v')\nprint(v)\nprint ('Sum of matrix A and B')\nprint(A+B)\nprint ('Transpose of matrix A')\nprint(A.T)\nprint ('Transpose of vector v')\nprint(v.T)\nprint ('Matrix B multiplied with vector v')\nprint(np.dot(B,v))\nprint ('Matrix B multiplied with matrix A')\nprint(np.dot(B,A))\nprint ('Matrix A multiplied with matrix B (notice A*B is not B*A)')\nprint(np.dot(A,B))\nprint ('Kronecker product Matrix A with matrix B')\nprint(np.kron(A,B))\n\n","a7a2e493":"# Same sample code to highlight the simplified math of \n\nv = np.matrix('-1; 2; 3')\nA= np.matrix(' 1 2 3 ; 4 5 6 ; 7 8 9 ')\nB= np.matrix(' 3 0 0 ; 0 6 0 ; 0 0 9 ')\n\nprint ('Example matrix general A')\nprint(A)\nprint ('Example covariance matrix B')\nprint(B)\nprint ('Transpose of matrix A')\nprint(A.T)\nprint ('Transpose of matrix B')\nprint(B.T)\nprint ('Inverse of Matrx A ')\nprint(np.linalg.inv(A))\nprint ('Inverse of Matrx B (notice non-zero values are replaced with its reciprocal in case of an inverse of a covariance matrix) ')\nprint(np.linalg.inv(B))\nprint ('Determinant of Matrix A')\nprint(np.linalg.det(A))\nprint ('Determinant of Matrix B (notice in case of a covariance matrix the determinant is the multiplication of the variances on the diagonal)')\nprint(round(np.linalg.det(B)))\nprint ('Show example covariance matrix B is semi-definite')\nprint(np.dot(v.T,np.dot(B,v)))\nprint ('Show example precision matrix B is semi-definite')\nprint(np.dot(v.T,np.dot(np.linalg.inv(B),v)))","34024645":"<a id='sec81'><\/a>\n## Generating coloured noise\n\nFor computer simulations coloured noise needs to be generated. In case of $\\tilde w$ (likewise for $\\tilde z$) a white gaussian noise signal (defined by covariance matrix $\\Sigma_w$ ) is convoluted with a Gaussian filter (defined by variance $s_w^2$ ) to create the coloured noise (see separate notebook [noise with temporal smoothness](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-noise) including explanation of the code).\nThe inputs needed to generate the coloured noise:\n\n### Noise variance\nThe variance of the required coloured noise, defined by the input parameter: covariance matrix $\\Sigma$, e.g. $\\Sigma_w$ or $\\Sigma_z$. \n* The input is expressed as a covariance matrix such that n-dimensional noise can be generated.  \n* In active inference noise levels are expressed in absolute numbers $\\Sigma$ while it is more custom in e.g. signal processing to express noise as relative to the signal level, a ratio that expresses the level of a signal to the level of the noise. (see WIKI [signal-to-noise ratio](https:\/\/en.wikipedia.org\/wiki\/Signal-to-noise_ratio#:~:text=Signal-to-noise)) E.g. A variance of 1 does not tell how much noise it is, if the main signal is in an order of magnitude of 100 it is 1% but if the main signal was around 1 it is 100%. Just remember to chose $\\Sigma$ relative to the signal not too small and not big, such that the consequence of it is clearly visible in the graphs.\n\n### Noise smoothness\nThe temporal smoothness of the required coloured noise, defined by input parameter $s^2$, e.g. $s_w^2$ or $s_z^2$. It is the variance of the Gaussian filter used to convolute the white noise.\n* 0<$s^2$<1 and usually $s^2$<<1\n* The higher $s^2$ (closer to 1) the smoother the noise coloured noise, hence the term smoothness parameter\n* In some papers a roughness parameter $\\gamma$ is used where noise roughness is inversely proportional to noise smoothness.\n\n\n\n","05c7b154":"<a id='sec74'><\/a>\n## Generalised Laplace encoded Free Energy\nApplying the Laplace\/mean-field approximation like in previous paragraphs in the example of the univariate generative model (single hidden state x and single sensory channel y, dynamic environment) results into:\n\n$$\\mathcal{F}(\\tilde y,\\mu) = \\sum_{j=0}^{p}\\left (  \\frac{1}{2\\sigma_{z^{(j)}}^2}\\varepsilon_{y^{(j)}}^2 \\right ) +  \\sum_{j=0}^{p}\\left (  \\frac{1}{2\\sigma_{w^{(j)}}^2}\\varepsilon_{x^{(j)}}^2 \\right )+\\frac{1}{2} ln\\: (\\sigma_{z^{(0)}}^2\\sigma_{w^{(0)}}^2..\\sigma_{z^{(p)}}^2\\sigma_{w^{(p)}}^2)  $$\n\nWhere:\n* p is the embedding order (note that the vector has p+1 values).\n* $\\varepsilon_{y^{(i)}}= y^{(i)}-g^{(i)}(\\mu_x^{(i)}) $ is the i'th component of the sensory prediction error. The delta between the sensory data y and the prediction of the function of sensory mapping.\n* $\\varepsilon_{x^{(i)}}= \\mu_x^{(i+1)} - f^{(i)}(\\mu_x^{(i)})$ is the i'th component of the motion prediction error. The delta between the belief of the hidden states higher order output $\\mu^{(i+1)}$ and the prediction of the function of motion. The higher order output because the function of motion is defined as $x'= f(x) + w$ resulting in a generalised $\\mathcal{D}\\tilde{x}= \\tilde{f}(\\tilde x) + \\tilde{w}$.\n* $\\sigma_{z^{(i)}}^2$ resp $\\sigma_{w^{(i)}}^2$ is the i'th component of the noise on the measurement resp environment. The higher orders of noise have increasing larger variances, thus the corresponding error term becomes less weighted and thus more and more eliminated from the expression of the Laplace encoded free energy.\n* And if you are wondering why it is written as $ \\mu $ in stead of $\\tilde \\mu $, please remember $ \\mu= \\begin{Bmatrix} \\tilde{\\mu}_x,\\mu_\\Theta,\\mu_\\lambda \\end{Bmatrix}$\n\nThe generic expression of the generalised Laplace Free Energy in matrix notation:\n$$\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix} $$\nwhere $\\tilde\\varepsilon$ are the generalized prediction errors\n$$\\tilde\\varepsilon=\\begin{bmatrix}\n\\tilde{ \\varepsilon}_y\n\\\\ \n\\tilde {\\varepsilon}_x\n\\end{bmatrix}\n=\\begin{bmatrix}\n\\tilde y - \\tilde g(\\tilde{\\mu}_x)\n\\\\ \n\\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x)\n\\end{bmatrix}$$\nand $ \\tilde\\Pi$ is the generalised precision matrix  \n$$\\tilde\\Pi=\\begin{bmatrix}\n\\tilde\\Pi_z & 0 \\\\ \n 0 & \\tilde\\Pi_w\n\\end{bmatrix}$$\n\nand $\\begin{vmatrix} \\tilde\\Pi \\end{vmatrix} $ is the [determinant](https:\/\/en.wikipedia.org\/wiki\/Determinant) of the generalised precision matrix. \n\nIn case you are not a big fan of matrix notations (and the additional complexity in the math), this is how it looks like when you write it out (grouped the indices to avoid clutter):\n\n$$\\mathcal{F}(\\tilde y,\\mu) = \\frac{1}{2} \\sum_{j=0}^{p} \\sum_{k=1}^{q} \\left (  \\frac{1}{\\sigma_{z^{(j,k)}}^2}\\varepsilon_{y^{(j,k)}}^2 + ln\\: (\\sigma_{z^{(j,k)}}^2) \\right ) + \\frac{1}{2}   \\sum_{j=0}^{p} \\sum_{k=1}^{n}\\left (  \\frac{1}{2\\sigma_{w^{(j,k)}}^2}\\varepsilon_{x^{(j,k)}}^2  + ln\\: (\\sigma_{w^{(j,k)}}^2) \\right ) $$\nWhere j the index of the generalised coordinates of motion and k the index of the sensory\/state vector.\nIt still is a sum of precision weighted quadratic prediction errors but now on all, including higher order, motions.\n\n\nWhen assuming noise levels are constant it is in some papers further simplified to ( because $-\\frac{1}{2} \\begin{vmatrix}\\tilde \\Pi\\end{vmatrix}$ is constant with respect to finding the optimum $\\tilde \\mu$, hence it is omitted):\n\n$$\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon=\n\\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$$\n\n","b08a5f0d":"To summarize the notebook\/progress again in a picture:\n\n* $x$ is the continuous stream of external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}(t)\\in\\mathbb{R}^n$ with n number of states.\n* $y$ is the continuous stream of sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation}(t) \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* $u$ is the continuous stream of actions that are performed on the environment, control signal. Shorthand notation for the vector $\\vec{u}(t) \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative model encoding a probabilistic model of the environment\/world in which it is immersed. \n    $x'= f(x,\\Theta) + w(\\lambda) \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y= g(x,\\Theta) + z(\\lambda)$   \n        where $\\Theta$ are the parameters of the generative model and $\\lambda$ the hyperparameters of the noise\n    * by estimating hidden causes $ \\mu= \\begin{Bmatrix} \\mu_x,\\mu_\\Theta,\\mu_\\lambda \\end{Bmatrix}$ (given sensory data $y$). Under the Laplace\/mean-field approximations estimating hidden causes simplify to estimating mean $ \\mu$ instead of a full recognition density . $\\tilde{\\mu}_x$ is shorthand notation for the vector $\\vec{\\mu}_x(t)\\in\\mathbb{R}^{n}$.\n    * by finding $\\mu_x,\\mu_\\Theta,\\mu_\\lambda,u$ with the lowest Free Energy and thus lowest surprise in sensory states:\n        * Improving perception:  $\\mu_x=\\underset{\\mu_x }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n        * Acting on the environment:  $u= \\underset{u }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n        * Learning the generative model: $\\mu_\\Theta=\\underset{\\mu_\\Theta }{Argmin}\\:  \\mathcal{F}(y,\\mu)$   \n        * Attention or optimizing expected precision of uncertainty: $\\mu_\\lambda=\\underset{\\mu_\\lambda }{Argmin}\\:  \\mathcal{F}(y,\\mu)$  \n\n![](https:\/\/i.imgur.com\/OTPiDph.jpg)","d5f11a0d":"<a id='sec3'><\/a>\n# Generative density \n\nNow the math gave this simplified result $\\mathcal{F}(y,\\mu)\\approx -ln \\, p(\\mu,y)$, let's also think for a moment what it implies. Negative log probability we have seen before, surprise. So it is the minimizing surprise in $p(\\mu,y)$. Where $p(x,y)$ is the more generic generative density formulation (how the brain encodes the environment), $p(\\mu,y)$ is the formulation but then applied for the brain best estimation $\\mu$ (given observations y). So, if the brain has a good generative density, and a good estimation of $\\mu$, it can explain the observations y, that lead to low free energy equals low surprise. Makes sense!    \nTherefore, the brain needs to have a good generative density encoding a probabilistic model of the environment\/world in which it is immersed in order to minimize the Free Energy effectively. This corresponds nicely to the good regulator theorem: \u201cEvery good regulator of a system must be a model of that system (Conant & Ashby 1970), this structure must instantiate a model of the system to be controlled, where the system includes both the body and the environment (and their interactions)\"  \n\nHow is the generative density modelled in active inference?\n<a id='sec31'><\/a>\n## Generative model\nThe generative density $p(x,y)$ is referred to as the generative model when it is written out in its functional form. Applying the product rule the generative density can be written as  $p(y\\mid x)* p(x)$, and therefor in the generative model represented as 2 functions:\n* **function of motion** $f(x,..)+w$, belief about states dynamics, function expressing $p(x)$. Where w are random fluctuations of the motion of hidden states making it a probabilistic model.  \n* **function of sensory mapping** $g(x,..)+z$, belief how states cause sensory input, function expressing $p(y \\mid x)$. Where z are random fluctuations of sensory observations making it a probabilistic model.   \n\nFor example:\n* function of motion estimates how e.g. a position of a car x changes with the speed, eg x = x + speed\/time + random fluctuations \n* function of sensory mapping estimates how the observation y is determined given position x, eg y = x + random fluctuations in case the car comes straight to you but if you would stand at an angle the observation y would be different.\n* recognition density $q(x; \\mu )=\\mu$  estimates the current position x of the car, eg 10 meter\n\n<a id='sec32'><\/a>\n## Generative process\nThe **generative model** is the internal model of the brain to encode a probabilistic model of the environment\/world in which it is immersed. The **generative process** is the process in the external environment\/world generating the sensory states. The latter does need to be coded in simulations. \n<img src=\"https:\/\/i.imgur.com\/iVZPPu9.jpg\" width=600>\nIt is interesting to notice the symmetry: the brain estimating the generative model  $p(x,y)$ and the generative process expressed likewise, $p(x,y)$ generating the hidden states $p(x)$  and the resulting sensory observations from the hidden states  $p(y)$. It also makes sense to have symmetry, the brain does try to encode a probabilistic model of the environment\/world in which it is immersed in order to inference the world. Inference thus corresponds to inverting the generative model in order to compute the posterior probability $p(x \\mid y)$ of hidden states\/causes given sensory observations.\n\n\n\n<a id='sec33'><\/a>\n## Generative model structure\n\nThe generative model in active inference is defined as a Hierarchical Dynamic Model (HDM) in generalized coordinates of motion. \nThis structure we will unpack step by step. In this notebook we will make a start with  \n(1) Dynamic model  \n(2) Dynamic Model in generalized coordinates of motion  \nAnd in the next notebook we will continue with   \n(3) Hierarchical Dynamic Model in generalized coordinates of motion  \n\n\n<a id='sec4'><\/a>\n## Dynamic model\n\n\nThe brain models the world to predict the sensory input. Because the world has structure the brain can predict. Why? Because this structure causes patterns\/regularities in the sensory input that the brain can predict. So, what are these patterns? There are a few \u00a8big\u00a8 ones we experience in everyday life that need to be modelled.\n\n\n        \n\n","2d24b7ea":"# How the brain might function - part 2 advanced base camp\n### Free Energy Principle tutorial without a PhD\n  \n<img src=\"https:\/\/cdn.pixabay.com\/photo\/2018\/05\/08\/08\/44\/artificial-intelligence-3382507_960_720.jpg\" width=500>\n<center>Image by <a href=\"https:\/\/pixabay.com\/users\/geralt-9301\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Gerd Altmann<\/a> from <a href=\"https:\/\/pixabay.com\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Pixabay<\/a> <\/center>   \n<br>\n\nWelcome to my notebook on Kaggle. I did record my notes with examples so it might help others in their journey to understand **Active Inference** minimizing the underlying **Free Energy**. Neuroscience has produced a candidate which suggests that several global brain theories might be unified within a free-energy framework: [Free Energy Principle](https:\/\/en.wikipedia.org\/wiki\/Free_energy_principle) (FEP) by [Karl Fristion](https:\/\/en.wikipedia.org\/wiki\/Karl_J._Friston): The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist.\n\nThis is the second notebook on active inference in the brain. If you didn't read the first one yet, please start with [how the brain might function - part 1 base camp](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1).  \n\nThe Free Energy Principle is mathematically rigorous and both neurologically and evolutionary plausible. Under some fairly basic assumptions the integrals and probability densities in the Free Energy translate into a straightforward prediction error minimization scheme as we will see in this notebook. It will take some \u00a8mathematically rigorous\u00a8 steps and for those who speak English more frequent than \u00a8Math\u00a8 (like me) you need some stamina, just follow step by step. Remember, in the end it will lead to a simplified result. The least I could do is to put math as much as possible in the Annex and use plenty examples.\n\nA lot of research papers have been published and understanding them has a steep learning curve. I did record my notes with examples so it might help you to get a better understanding. This to help catalyze knowledge and research on Active Inference and the Free Energy Principle in an engineering\/robotics\/data sciences\/machine learning context. So if you are interested please keep on reading and upvote top right, leave a comment or contact me directly.","00a5f54d":"<a id='sec8'><\/a>\n# Coloured noise\n\nIn conventional control theory it is assumed that fluctuations are independent, a sequence of serially uncorrelated random variables with zero mean (infinitely rough). (e.g. Gaussian white noise). The idea is that random fluctuations are sufficiently fast that we do not observe their serial or temporal correlations.\n\nThis is less plausible for biological reality, random fluctuations originate from dynamical systems themselves (e.g. sound, waves). Therefore, these signals are continuous and not infinitely rough as is white noise for example. It is noise with some form of temporal smoothness. This form of noise with a temporal smoothness is referred to as (a form of) \"coloured noise\" in signal processing. (I probably would have called it \"Natural noise\" but I will stick to the conventions to not introduce confusion).\n\nThis means higher order derivatives of the noise do contain information, as also the noise is differentiable with finite variance (in contrast to white noise that has infinite variance so there is no information in higher order derivatives). \n\nThe analyticity of the noise (means it can be differentiated) can be exploited by recursively differentiating the noise with respect to time to obtain noise in generalised coordinates of motion:\n$$\\tilde{w}(t)= [w(t), w'(t), w''(t), w'''(t),....w^{(p)}(t)]^{T} $$\n\nThus the idea is that estimating the trajectory of colored noise enables active inference to better extract the regularities from the irregularities, the signal from the noise, the prediction error from the noise.\n\n","3e712bc0":"<a id='secC'><\/a>\n# Conventions and Symbols\n\nBelow the symbols, functions and conventions used in this notebook  \n\nSymbols\/functions| Description | Alternative |\n--- | --- | --- |\n$\\tilde x$ | continuous stream of trajectories of external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}(t)\\in\\mathbb{R}^{n(p+1)}$ with n number of states and generalised coordinates of motion embedding order p. | |\n$\\tilde y$ | continuous stream of trajectories of of sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation}(t) \\in  \\mathbb{R}^{q(p+1)}$ with q number of sensors and generalised coordinates of motion embedding order p.  | also sometimes noted \u00a8s\u00a8 as of sensory states |\nu | actions, control signal, The action that can be performed on the environment. Shorthand notation for the vector $\\vec{u}(t) \\in  \\mathbb{R}^{l}$ with l number of controls.  | also noted as \u00a8a\u00a8 or \u00a8$\\alpha $\u00a8 |\n$\\mathcal{F}(\\tilde y ,\\mu)$ | The Free Energy | $\\mathcal{F}(\\tilde y,\\zeta)$ which simplifies under lapace assumption to $\\mathcal{F}(\\tilde y,\\mu)$\n$q(\\vartheta; \\mu )$    | recognition density with sufficient statistics $\\mu$, <br> the brain to estimate the hidden causes given observations y  | Ensemble density; $q(\\vartheta; \\zeta )$ Simplifies under lapace assumption to $q(\\vartheta; \\mu )=\\mu$. <br> Where $\\mu=\\begin{Bmatrix} \\tilde{\\mu}_x,\\mu_\\Theta,\\mu_\\lambda \\end{Bmatrix}$. <br> Also written as $q(x; \\mu)$ if only estimating the hidden state x.  |\n$p(\\vartheta, \\tilde y)$ | Generative density: the brain encoding a probabilistic model <br> of the environment\/world in which it is immersed. |  |\n$\\vartheta$ | Union of $\\tilde {x},\\theta,\\lambda$, the hidden causes |\n$\\zeta$ | sufficient statistics (e.g. for a Gaussian distribution: mean \ud835\udf07, variance $\ud835\udf0e^2$) for the recognition density | $\\mu$ <br> (because under Laplace approximation sufficient statistics simplifies to mean $\\mu$), <br> in few papers noted as $\\lambda$ but $\\lambda$ more often used for hyperparameters for random noise) |\n$\\mu$ | =$\\begin{Bmatrix} \\tilde{\\mu}_x,\\mu_\\Theta,\\mu_\\lambda \\end{Bmatrix}$ Belief or estimation of the hidden causes. <br> $\\tilde{\\mu}_x$ shorthand notation for the vector $\\tilde{\\vec{\\mu}}_{x}(t)\\in\\mathbb{R}^{n}$.   |sufficient statistics $\\zeta$ for the recognition density under Laplace approximation simplifies to mean $\\mu$. |\n$f(x)$ $g(x)$ | Equation of motion (f) and sensory mapping (g) to encode a generative model of the environment. | $f(x,\\theta)$ $g(x,\\theta)$  |\n$f_{gp}(x,u)$ $g_{gp}(x)$ | Equation of motion and sensory mapping in the generative process: <br> generating the sensory observations in simulations. | sometimes donated in bold $\\textbf{f(x,u))}$ $\\textbf{g(x))}$  |\n$\\theta$ | Parameters of generative model, eg $f(x,\\theta)$ $g(x,\\theta)$  | \n$\\lambda$ | Hyperparameters defining noises, eg $\\vec{w},\\vec{z}$ | \n$\\tilde{w},\\tilde\\Sigma_{w}, \\tilde\\Pi_w$ | Noise on hidden state, covariance matrix and precision matrix| \n$s_w^2, S(s_w^2)$ | The variance of the Gaussian filter and the temporal covariance matrix  used to create the coloured noise $\\tilde w$ |\n$\\tilde{z},\\tilde\\Sigma_{z}, \\tilde\\Pi_z$ | Noise on observation, covariance matrix and precision matrix| \n$s_z^2, S(s_z^2)$ | The variance of the Gaussian filter and the temporal covariance matrix  used to create the coloured noise $\\tilde z$ |\n$\\tilde \\varepsilon$ | Prediction error  | \n$\\tilde\\xi $ | Precision weighted prediction error $\\tilde\\xi = \\tilde\\Pi \\tilde\\varepsilon $  | \n$\\tilde{\\varepsilon}_x$ | Prediction error between motion of belief and belief of motion |  \n$\\tilde{\\varepsilon}_y$ | Prediction error between observation and expected observation |  \n$p$ | Embedding order of generative model. $p\\in\\mathbb{Z}^+$ is the number of derivatives. $p=6$ means we have <br>$\\mu^{(0)}$ until $\\mu^{(6)}$, which means the vector has 7 entries| \n$i$ | the index of the hierarchical level |\n$j$ | the index of the generalised coordinates of motion | \n$k$ |the index of the sensory\/state vector |\n\n\nConvention | description \n--- | ---  \n$I_n$ | Identity matrix of size $\\mathbb{R}^{n\\times n}$ \n$\\otimes$ | The kronecker tensor product\n$\\dot{*}$ vs. $*'$ | Derivative (physical) vs. motion (belief)  \n$*^{(n)}$ vs. $*^n$ | $n$-th component of the generlised form vs. exponent $*^n$ | | \n$\\tilde{*}$ | Variable or matrix in generalised form \n","8e2ff181":"# Table of Contents\nIn this notebook we will further explore where we ended in the first notebook. How the recognition density simplifies under the Laplace assumption, how the generative density can be expressed as a dynamic model and how minimizing the Free Energy corresponds to a prediction error minimization scheme. \n1. [Simplify Active Inference](#sec1)\n    1. [Laplace approximation](#sec11) \n    1. [Mean-field approximation](#sec12) \n1. [Recognition density](#sec2) \n1. [Generative density](#sec3)  \n    1. [Generative model](#sec31)  \n    1. [Generative process](#sec32) \n    1. [Generative model structure](#sec33)  \n1. [Dynamic model](#sec4)  \n    1. [Temporal patterns](#sec41)  \n    1. [Spatial-temporal patterns](#sec42) \n    1. [State space model](#sec43) \n    1. [Noise](#sec44)   \n1. [Prediction error minimization](#sec5) \n1. [Inference the Generative model](#sec6) \n1. [Dynamic model in generalised coordinates of motion](#sec7) \n    1. [Generalised coordinates of motion](#sec71) \n    1. [Local linearity approximation](#sec72)\n    1. [State space model in generalised coordinates of motion](#sec73)\n    1. [Generalised Laplace encoded Free Energy](#sec74)\n1. [Coloured noise](#sec8)    \n    1. [Generating coloured noise](#sec81)  \n    1. [Generalised precision matrix](#sec82)\n1. [Advanced base camp](#sec9)  \n1. [How the brain might function - part 3](#sec10)  \n1. [Appendix](#secA)  \n    1. [Laplace encoded Free Energy math - part 1](#secA1)\n    1. [Laplace encoded Free Energy math - part 2](#secA2)\n    1. [Laplace encoded Free Energy math - part 3](#secA3)\n    1. [Covariance matrix math](#secA4)\n    1. [Computation of the generalised precision matrix](#secA4) \n1. [Conventions and Symbols](#secC)  \n \nIt is a conscious choice to use as much as possible arguments and sentences from Friston's papers enriched with examples and insights for understanding. In the end this notebook turned out to be longer than I anticipated, there is a lot to explain. Enjoy.   \nThe articles of Karl Friston I used mainly for this notebook are: [A free energy principle for the brain ](https:\/\/www.fil.ion.ucl.ac.uk\/~karl\/A%20free%20energy%20principle%20for%20the%20brain.pdf), [The free-energy principle: a rough guide to the brain?](https:\/\/www.fil.ion.ucl.ac.uk\/~karl\/The%20free-energy%20principle%20-%20a%20rough%20guide%20to%20the%20brain.pdf), [Action and behavior: a free-energy formulation](https:\/\/www.fil.ion.ucl.ac.uk\/spm\/doc\/papers\/Action_and_behavior_A_free-energy_formulation.pdf). In this second notebook extended with [the free energy principle for action and perception: a mathematical review](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0022249617300962).   \nThe articles of Karl Friston expressed in a word cloud, hope you recognize them:\n![](https:\/\/i.imgur.com\/zS3KqnF.png)","e3c98d7d":"<a id='sec5'><\/a>\n# Prediction error minimization\n\nUnder the Laplace\/mean-field approximation the math significantly simplifies: Minimizing Free Energy corresponds to minimizing prediction error. In this chapter we explore how come so.\n\nThe Laplace encoded Free energy \n$$\\mathcal{F}(y,\\mu) =  -ln\\: p(\\mu,y)  $$ \nApplying the product rule and ln(ab)=lan(a)+ln(b) leads to\n$$= -ln\\: p(y \\mid \\mu) - ln \\:p(\\mu)$$\nBy using the functional form of the generative density (see annex [Laplace encoded Free Energy math - part 2](#secA2)) it is possible to express the probability densities (under the Laplace approximation) as Gaussian densities and substitute them in the above equation. \n\nBelow you see an example of the simplest generative model (single hidden state x and single sensory channel y, static environment) to build the intuition how the precision weighted prediction errors appear \n<img src=\"https:\/\/i.imgur.com\/Tal5Rsy.jpg\" width=600>\n\nWhich translates for this simplest example to (remember $ln (e^a)=a$) \n\n$$\\mathcal{F}(y,\\mu) = \\frac{1}{2\\sigma_z^2}\\varepsilon_y^2 + \\frac{1}{2\\sigma_w^2}\\varepsilon_x^2  +\\frac{1}{2} ln\\: ({\\sigma_z^2\\sigma_w^2) } $$\n\nWhere $\\varepsilon$ are the prediction errors:\n* $\\varepsilon_y $ is the sensory prediction error. The delta between the sensory data y and the prediction of the function of sensory mapping, $= y-g(\\mu)$ in this simplest example.\n* $\\varepsilon_x $ is the the motion prediction error. The delta between the belief of the hidden states and the prediction of the function of motion, $= \\mu - f(\\mu)$ in this simplest example.\n\nThe generic expression (for all cases eg dynamic environments, multivariate) of the Laplace Free Energy in matrix notation (see annex [Laplace encoded Free Energy math - part 3](#secA3)) as is used in the Free Energy scientific papers\n$$\\mathcal{F}(y,\\mu) = \\frac{1}{2}\\varepsilon^T \\Pi \\varepsilon - \\frac{1}{2} ln \\begin{vmatrix}\n\\Pi\n\\end{vmatrix} $$\nwhere $\\varepsilon$ are the prediction errors\n$$\\varepsilon=\\begin{bmatrix}\n\\varepsilon_y\n\\\\ \n\\varepsilon_x\n\\end{bmatrix}\n=\\begin{bmatrix}\ny-g(\\mu)\n\\\\ \n\\mu - f(\\mu)\n\\end{bmatrix}$$\nand $ \\Pi$ is the Precision matrix (the inverse of the Covariance Matrix $\\Sigma$) \n$$\\Pi=\\begin{bmatrix}\n\\Pi_z & 0 \\\\ \n 0 & \\Pi_w \n\\end{bmatrix}=\n\\begin{bmatrix}\n\\Sigma_z & 0 \\\\ \n 0 & \\Sigma_w \n\\end{bmatrix}^{-1}\n$$\n\nand $\\begin{vmatrix} \\Pi \\end{vmatrix} $ is the [determinant](https:\/\/en.wikipedia.org\/wiki\/Determinant) of the precision matrix.\n\nIn case you are not a big fan of matrix notations (and the additional complexity in the math), this is how it looks like when you write it out:\n\n$$\\mathcal{F}(\\tilde y,\\mu) = \\frac{1}{2} \\sum_{k=1}^{q} \\left (  \\frac{1}{\\sigma_{z^{(k)}}^2}\\varepsilon_{y^{(k)}}^2 + ln\\: (\\sigma_{z^{(k)}}^2) \\right ) + \\frac{1}{2}  \\sum_{k=1}^{n}\\left (  \\frac{1}{2\\sigma_{w^{(k)}}^2}\\varepsilon_{x^{(k)}}^2  + ln\\: (\\sigma_{w^{(k)}}^2) \\right ) $$\nWhere k is the the index of the sensory\/state vector.\n\n\nThe second part of the free energy formula ($-\\frac{1}{2} \\begin{vmatrix}\\Pi\\end{vmatrix}$) denotes that under more certainty (lower variance) the brain is able to lower the free energy more and thus less surprise in sensory states (The higher the precision the Free energy can be lowered faster and lower). \nWhen assuming noise levels are constant it can be further simplified to (because $-\\frac{1}{2} \\begin{vmatrix} \\Pi\\end{vmatrix}$ is constant with respect to the optimum $ \\mu$ it can be omitted), e.g. when catching a ball the light levels will not suddenly change:\n\n$$\\mathcal{F}(y,\\mu) = \\frac{1}{2}\\varepsilon^T \\Pi \\varepsilon=\n\\frac{1}{2}(\\varepsilon_{x}^T \\Pi_{w} \\varepsilon_{x}+\\varepsilon_{y}^T \\Pi_{z} \\varepsilon_{y})$$\n\nWhy does minimizing Free Energy under the Laplace approximation corresponds to minimizing prediction error? Because by expressing the Laplace encoded Free Energy like above, the Free Energy is lowered by minimizing the predictions errors $\\varepsilon$.   \nWhy does the Free Energy have a minimum? Because $\\varepsilon^T \\Pi \\varepsilon \\geq 0$ since $\\Pi$ is positive semi-definitive matrix (see [annex](http:\/\/)). It is also a convex function (quadratic product around a positive semi-definite matrix), hence it allows for the use of very efficient optimization algorithms like gradient descent which we will explore in next notebook. It should be noted that the convexity only applies to the optimization over $\\mu$. If one is also interested in optimizing $\\Theta$ and $\\lambda$ (latter paragraph) then the convexity does not apply.  \nWhy the term precision weighted prediction errors? Because the prediction errors are multiplied by the precision (inverse variance), it is an multiplier of the relative confidence of these errors (how reliable the signal is taken to be). \n* Low noise = Low uncertainty = probability with low variance (sharply peaked) = high precision: Prediction errors minimize the Free energy more fast  \n* High noise = High uncertainty = probability with high variance = low precision: Prediction errors minimize the Free energy less fast  \n\nMakes sense! The higher the precision the Free energy can be lowered faster and lower. We can't be precise because there is uncertainty, but we can be precise on uncertainty. Hence in active inference understanding the uncertainty\/noise has a very central role.    \nIn the Free Energy papers the symbol $\\xi $ is used to denote the precision weighted prediction error:\n$$\\xi = \\Pi \\varepsilon $$\n\nIn summary, minimizing the Laplace encoded Free Energy with Active Inference boils down to minimizing a quadratic sum of prediction errors, mediated by the precision (inverse variances). It is an automatable optimization problem through prediction error minimization by iterately finding $\\mu$ with the lowest Free Energy. Note the Free Energy can be computed if the generative model (f(x) and g(x)) and the precision matrix are known. How to infer these as well is subject of next chapter.\n\n* $x$ is the continuous stream of external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}(t)\\in\\mathbb{R}^n$ with n number of states.\n* $y$ is the continuous stream of sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation}(t) \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* $u$ is the continuous stream of actions that are performed on the environment, control signal. Shorthand notation for the vector $\\vec{u}(t) \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative model encoding a probabilistic model of the environment\/world in which it is immersed. \n    $x'= f(x,\\Theta) + w(\\lambda) \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y= g(x,\\Theta) + z(\\lambda)$   \n        where $\\Theta$ are the parameters of the generative model and $\\lambda$ the hyperparameters of the noise\n    * by estimating hidden states $x$ over time (given sensory data $y$). Under the Laplace\/mean-field approximations estimating hidden states simplify to estimating mean $\\mu$ instead of a full recognition density. Shorthand notation for the vector $\\vec{\\mu}(t)\\in\\mathbb{R}^{n}$.\n    * by finding $\\mu$ and $u$ with the lowest Free Energy and thus lowest surprise in sensory states:\n        * By improving perception:  $\\mu=\\underset{\\mu }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n        * By acting on the environment:  $u= \\underset{u }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n\n![](https:\/\/i.imgur.com\/U0UrVCu.jpg)\n","c7f31c27":"<a id='sec6'><\/a>\n## Inference the generative model\nHow does the brain learn and improve the generative model from the sensory observations?  \n\nUntil now we have been lowering the Free energy by inferring the hidden states x given a generative model and precision matrix. But the brain can also improve the model of the environment and the precisions to make the observations more likely. By expressing the generative model in terms of functions $x'(t)= f(x(t),\\Theta) + w(t,\\lambda)$ and $ y(t)= g(x(t),\\Theta) + z(t,\\lambda)$ it becomes clear that the brain can optimize the Free energy by estimating $\\Theta$ and $\\lambda$ better as well. Minimizing the Free energy can be applied as well to estimate $\\mu_\\Theta$ and $\\mu_\\lambda$.\n\nThat is why in Friston's papers you see $\\begin{Bmatrix} x,\\Theta,\\lambda \\end{Bmatrix} \\subseteq \\vartheta$  as hidden causes of sensory input (all these variables together cause a certain signal y to be perceived). By extending active inference to infer the generative model as well, the recognition density is written as $q(\\vartheta; \\mu)$ (instead of $q(x; \\mu )$ ) and the generative density as $p(\\vartheta, y)$ (instead of $p(x,y)$ ).\n\nActive Inferences approximates the recognition density by a mean-field approximation:\n\n$$q(\\vartheta; \\mu )=q(x;\\mu_{x} )q(\\Theta; \\mu_{\\Theta} )q(\\lambda; \\mu_{\\lambda} )$$ \n\nIt is an approximation because this can only be done if the hidden causes can be partitioned into independent sets. The latter is not completely true hence approximation, e.g. if you optimize the model parameters $\\mu_\\Theta$ they influence the trajectory of $\\mu_x$.  \nApplying the same logic as described in the previous recognition density chapter to the different partitions results into:\n$$ \\mu= \\begin{Bmatrix} \\mu_x,\\mu_\\Theta,\\mu_\\lambda \\end{Bmatrix}$$\n\nThus to iterately find the mean $\\mu$ with the highest probability of:\n* $x$: Set of hidden states that are being estimated that change quickly over time (timescale of milliseconds). E.g. $x$ could represent the joint positions of your arm.  \n* $\\Theta$: Time invariant (or very slowly varying) parameters of the dynamics of the world that need to be modelled (timescale of years). E.g. $\\Theta$ could be the length of your forearm arm, which is invariant when catching a ball but you will still grow if you are young. \n* $\\lambda$: Precision of random fluctuations that correspond to change slowly over time (timescale of seconds). E.g. If it is getting dark outside catching a ball will become harder, the random fluctuations in your sensory observations will be higher.  \n\nLike the Free Energy can be minimized by:\n* Improving perception:  $\\mu_x=\\underset{\\mu_x }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n* Acting on the environment:  $u= \\underset{u }{Argmin}\\:  \\mathcal{F}(y,\\mu)$   \n\nAlso the Free Energy can be minimized by:   \n* Learning the generative model (how the brain encodes the environment): $\\mu_\\Theta=\\underset{\\mu_\\Theta }{Argmin}\\:  \\mathcal{F}(y,\\mu)$   \n* Attention or optimizing the expected precision (regulating the learning): $\\mu_\\lambda=\\underset{\\mu_\\lambda }{Argmin}\\:  \\mathcal{F}(y,\\mu)$. \n\nPerception, action, learning and attention are all different but complementary means for the reduction of free energy, equals reduction of prediction error, equals reduction of surprise in the sensory data.\n\nNote that the partition into these three sets has not been chosen by accident, as we will see in next notebook, it corresponds to a biological plausible neurological implementation in the brain where perception corresponds to neural activity, learning to neural efficacy (strength of the neural connections) and attention to optimizing neural connection gain (openness to change neural connections).\n\nMinimizing the Free Energy is giving the mathematical fundament\/framework how to learn the generative model (and noise estimation).  But remember it is a monumental task to extract how the generative model (representing the real world) looks like just from the sensory signals. Especially because it has the complexity of an inverse problem, many potential generative models could explain the sensory signals and the brain has to figure out what is the most logical model.  We will have a look at how this model inversion could be done in a next notebook  (hint: Bayesian prior knowledge gives context to learning the generative model). Learning the hierarchical generative model from sensory data, I believe, might be the breakthrough in the development of true AI. \n","612b2765":"<a id='sec1'><\/a>\n# Simplify Active Inference\n\nUnder the Laplace and mean-field approximation the math significantly simplifies: \n* The recognition density sufficient statistics $\\zeta$ simplifies to the mean  $\\mu$ (and $\\sigma^2$ is not needed). The recognition density simplifies from a distribution to a single value to $q(x; \\mu)=\\mu$.\n\n* The Free Energy simplifies from probability densities with integrals\n$$\\mathcal{F}(y,\\zeta )= \\int q(x; \\zeta )ln(\\frac{q(x; \\zeta )}{p(x,  y)})dx $$\nto a precision weighted quadratic sum of prediction errors with below basic shape\n$$\\mathcal{F}(\\tilde y,\\mu) = \\frac{1}{2} \\sum  \\left (  \\frac{1}{\\sigma_{z}^2}\\varepsilon_{y}^2 + ln\\: (\\sigma_{z}^2) \\right ) + \\frac{1}{2}   \\sum \\left (  \\frac{1}{\\sigma_{w}^2}\\varepsilon_{x}^2  + ln\\: (\\sigma_{w}^2) \\right ) $$\nwhere $\\varepsilon_{x}$ resp. $\\varepsilon_{y}$ are the prediction errors for the hidden state resp. sensory signal and $\\sigma_{w}$ resp. $\\sigma_{z}$ are the variances of the prediction errors.\n* Minimizing the Laplace encoded Free Energy is an automatable optimization problem through prediction error minimization by iterately finding $\\mu$ with the lowest Free Energy.  \n\nOr simply put, under these assumptions minimizing the free energy basically boils down to minimizing prediction error. Don't worry if you can't see yet why this is the case. It will be explored in this notebook, starting with understanding the Laplace and mean-field approximations\n\n<a id='sec11'><\/a>\n## Laplace approximation\nThe Free Energy Principle \/ active inference assumes [Gaussian](https:\/\/en.wikipedia.org\/wiki\/Normal_distribution) (aka normal) probability densities. Laplace\u2013Gauss is an another name for the Gaussian distribution, hence the name Laplace approximation. \n\n<img src=\"https:\/\/www.syncfusion.com\/books\/Statistics_Using_Excel_Succinctly\/Images\/normal-curve.png\" width=200>\n\nThe Laplace approximation also assumes that the Gaussian probability densities are sharply peaked at its mean value $\\mu$. The analogy would be the more information you get to better estimate the mean the more the precision and thus lower the variance\/$\\sigma$ (sharply peaked).\n<a id='sec12'><\/a>\n## Mean-field approximation\nIn case (unknown) variables are assumed statistical independent of the each other (or only weakly covary) they can be partitioned. This partitioning or factorization is in statistical physics known as mean-field approximation.\n$$p(x)=\\prod_{i}p(x_i)=p(x_1)p(x_2)..p(x_n)$$\n\nFor example in case of statistical independence (or only weakly covary) a joint probability (eg $p(a,b)$ ) can be factorized.\n$$p(a,b)$$\nApply product rule\n$$=p(a)p(b\\mid a)$$\nIf a and b are statistically independent (b does not depend on a)\n$$=p(a)p(b)$$\nIf a and b are largely statistically independent\n$$\\approx p(a)p(b)$$\n\nFor example, the probability my cat asks attention to get more food tonight is independent from the probability the weather will be cloudy. The probability the cat begs for food and cloudy weather is approximately the same as the probability the cat begs for food times the probability of cloudy weather. Yes, there might be a weak (indirect) dependency, if there is sunshine the cat prefers to be outside, so it might hunt mice. That is why it is called an approximation.   \nWhere the mean-field approximation is used I will indicate so in the notebook. \n","75a59b6d":"<a id='sec2'><\/a>\n## Recognition density \n\nThe recognition density $q(x; \\zeta )$ is the brain estimating hidden states $x$ (given sensory data $y$) with a probability distribution. Which is specified by its sufficient statistics   $\\zeta$ In case of a Gaussian distribution: mean $\\mu$, variance $\\sigma^2$ E.g. the current position x of the ball: 10 meter with variance of 10 centimeter.  \n\nThe Free energy \n\n$$\\mathcal{F}(y,\\zeta)= \\int q(x; \\zeta )ln(\\frac{q(x; \\zeta )}{p(x,  y)})dx $$\n\nsimplifies under the Laplace approximation (see annex [Laplace encoded Free Energy math - part 1](#secA1)) to \n\n$$\\mathcal{F}(y,\\zeta)\\approx -ln \\, p(\\mu,y)$$\n\nAs you can see, the Free energy does not depend anymore on variance $\\sigma^2$ but solely mean $\\mu$. Under the Laplace Approximation the variance $\\sigma^2$ can be derived from the mean and does not need to be coded explicitly. To explain it in words, because the Laplace assumption assumes a recognition density that is sharply peaked, it is mainly dependent on the first order statistics $\\mu$ and far less from the second order statistics $\\sigma^2$.\n\nTherefor the Free Energy can be written as $\\mathcal{F}(y,\\mu)$ and the  recognition density can be written as $q(x; \\mu)=\\mu$. Instead of estimating a whole distribution it is under the Laplace approximation sufficient to iterately find the mean $\\mu$ with the highest probability. (for all hidden states, remember $\\mu$ is vector $\\vec{\\mu}\\in\\mathbb{R}^{n}$)\n\nNote that in the generative density (next paragraph) $\\sigma^2$ is used, encoding the agent\u2019s uncertain belief about its environment. So, the brain works with variances $\\sigma^2$, but not double in both generative and recognition density.\n\n\n","418c2d66":"<a id='secA4'><\/a>\n## Covariance matrix math\n\nActive inference assumes independent noises, random fluctuations are not correlated. Therefor a covariance matrix in active inference is a matrix with all zero's except for variances along its diagonal.  \nFor example  \n$$\n\\Sigma=\\begin{bmatrix}\n3 & 0 &0 \\\\ \n0 & 6 & 0\\\\ \n 0& 0 & 9\n\\end{bmatrix}\n$$\n\nIt has some convenient properties which simplify the math:\n+ The covariance matrix is a square and symmetric matrix , the [transpose](https:\/\/en.wikipedia.org\/wiki\/Transpose) of a covariance matrix with independent noises equals the same. $\\Sigma^{T}=\\Sigma$\n* The inverse of a covariance matrix (precision matrix) with independent noises: each of the non-zero values is replaced with its reciprocal.\nFor example the precision matrix corresponding to the above example is: \n$$\n\\Pi=\\Sigma^{-1}=\\begin{bmatrix}\n\\frac{1}{3} & 0 &0 \\\\ \n0 & \\frac{1}{6} & 0\\\\ \n 0& 0 & \\frac{1}{9}\n\\end{bmatrix}\n$$\n* The [determinant](https:\/\/en.wikipedia.org\/wiki\/Determinant) of a covariance matrix with independent distributed values, noted as $\\left | \\Sigma \\right |$ is the multiplication of the variances on the diagonal. In the example above: $\\left | \\Sigma \\right |$=3x6x9=162\n* $\\Sigma$ and $\\Pi$ are both [positive semi-definite](https:\/\/en.wikipedia.org\/wiki\/Definiteness_of_a_matrix). Thus $ v^T \\Sigma v \\geq 0$ and $ v^T \\Pi v \\geq 0$ for all vectors $v \\in\\mathbb{R}^n $\n\nBack to [Noise](#sec44) ","bdc9800d":"<a id='secA5'><\/a>\n## Computation of the generalised precision matrix\n\nSee chapter 3 of the [Generalised Motions in Active Inference by finite differences document](https:\/\/repository.tudelft.nl\/islandora\/object\/uuid%3A9102f269-ca73-4281-99e0-ea911282859e)  by Iris Hijne.\n\n","79a0ec5d":"You might have noticed that the temporal covariance matrix has structure. That is correct, see annex why [Computation of the generalised precision matrix](#secA5). The value of the i'th diagonal element of $S(s^2)$ can be written as:\n\n$$S(s^2)_{i,i} = \\frac{-1}{(2s^2)^{(i-1)}} \\prod_{j=1}^{i} (2j-3)$$\n\nand the same terms on the anti-diagonals are alternatingly positive and negative.  \nBelow the code to generate the temporal covariance matrix with an example to see it create a table.","07b92287":"\n<a id='sec41'><\/a>\n## Temporal patterns\nOne of the very basic patterns is that all sensory information that enters your brain are continuous sensory input signals, all the time (temporal signals). All your sensory observations (e.g. seeing, hearing, feeling, smelling, etc) are transported to the brain via the central nervous system \/ sensory pathways. It are all neural signals continuously firing in patterns. The brain has to model continuous sensory signals. We experience our conscious state of mind as thoughts\/images as a continuous stream and they constantly change. Our actions depend on exact timing. e.g. when you try to catch a ball the timing of your arm movement has to be precise.  \nHence, one should not see sensory observations y as stationary one-time inputs but as sensory observations y(t) data streams. Per same account hidden states x(t) and control signal u(t). The analogy would be: not \u00a8photo\u00a8 but \u00a8movie\u00a8. All chapters of this and previous notebook still hold true, but you have to read x as x(t) and y as y(t), u as u(t), $\\mu$ as $\\mu(t)$, etc. \n\nNote that also coming chapters I will again start omitting the time referral to not clutter notation, but don't forget it are all continuous signals. Rhythms, cycles, timing, all very fundamental and I would find it very suspicious if the model would not cater for pattern detection in continuous signals.\n\nNote that in the end all different sensory observations enter the brain as neural signals. Input in your brain are just neural patterns, it doesn't matter where the patterns originated from. In the brain it can all be handled the same, strengthening the [earlier observation](http:\/\/Minimize free energy by acting on the environment) that all parts operate through a common principle, e.g. the Free-energy principle. There is a famous [case](https:\/\/www.nytimes.com\/2000\/04\/25\/science\/rewired-ferrets-overturn-theories-of-brain-growth.html) where scientists have reconfigured new-born ferret brains so that the animals' eyes are hooked up to brain regions where hearing normally develops. The interesting result is that the ferrets develop fully functioning visual and auditory capability. \n<a id='sec42'><\/a>\n## Spatial-temporal patterns\nA second basic pattern is that your senses are spatial, we live in a 3D world. For example: \n*  You are not experiencing an upside-down picture on the retina at the back of your eyeball. You are seeing\/experiencing an 3D object in 3D space, relative to yourself. \n* Sound is spatial because you can hear where it is coming from. \n* Touch is spatial. Just close you eyes and ask a friend to put an unknown object in front of you, like a pen. By one touch you will not be able to figure out what it is. If start tracing the contours you can build a \u00a8image\u00a8 on what you are touching. Your spatial positioning of what you are touching is enabling this. \n\nSpatial patterns are coincident to patterns in time: things can move. To build some intuition around that statement let's ask the question: How to best predict y(t+1)?\n* If you sit still in a room and nothing is moving, everything stays the same. y(t+1)=y(t). \n* If you sit still but things are moving around you the next sensory prediction y(t+1) should be correlated to previous prediction y(t). Things can move but not \u00a8teleport\u00a8. Also things are not \u00a8falling apart\u00a8, for example if you see a pen falling from a table you predict to see it the next instant as well a little lower, also it will not suddenly be a different pen or not a pen at all. The natural dynamics of the world needs to be modelled by the brain to predict the next sensory observations. Babies that hold a toy above their head and let it loose learn quickly that things fall. \n* If you start moving the sensory observations change and we already concluded in the previous notebook there has to be a deep connection between action and perceptual inference because predicting y(t+1) is relative to yourself moving.\n\nWith things moving, the natural dynamics of the world needs to be modelled by the brain. The dynamics of nature (laws of physics) are expressed in differential equations (eg $\\frac{\\partial}{\\partial t}x(t)= f(x(t))$  or in condensed $x'(t)= f(x(t))$ notation) which express the motion of x over time. For example, you probably learned in high school physics class that speed it the derivative of position over time, acceleration the derivative of speed, etc. So if x is the position then $x'(t)$ is the functional expression for the speed, eg $x'(t)= 1$ expresses a constant speed of 1, $x'(t)= x $ expresses an acceleration, etc.  Or you can simply see it in discrete simulation code: $x(t+1)=f(x(t))$ for small delta's of t connecting $x(t+1)$ with $x(t)$. The Free Energy Principle applies differential equations for the movement of hidden causes, so the model can learn and use the basics of natural dynamics.  \n\n\nThe differential equations enforce a coupling between neighbouring orders of motion and thereby\n* couple space and time, the spatial-temporal patterns. e.g. speed is connecting positions (spatial) over time (temporal).  \n* confer memory to the system. The dynamic states have memory and evolve according to equations of motion prescribed by the non-linear continuous function f.  \n\n<a id='sec43'><\/a>\n## State space model\n\nIn the Free-energy principle the dynamics are formalized with a general non-linear [state space model](https:\/\/en.wikipedia.org\/wiki\/State-space_representation#Nonlinear_systems). In this [video](https:\/\/www.youtube.com\/watch?time_continue=727&v=p_di4Zn4wz4) you will find a good explanation of the essence of differential equations leading to states space models capturing the laws of physics. It is a mathematical model of a physical system as a set of input u(t), output y(t) and hidden state x(t) related by a differential equations: \n\n$$\\frac{\\partial}{\\partial t}x(t)= f(x(t),\\Theta) + w(t,\\lambda) \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y(t)= g(x(t),\\Theta) + z(t,\\lambda)$$  \n\nWhich can be compactly written as:\n\n$$x'= f(x) + w \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y= g(x) + z$$  \n\nWhere:\n* f is the function of motion: belief about state dynamics, representing probability density $p(x)$. It is a (possibly very complex) continuous non-linear function parameterised by $\\Theta$.\n* g is the function of sensory mapping: belief how states cause sensory input, representing probability density  $p(y\\mid x)$ . It is a (possibly very complex) continuous non-linear function parameterized by $\\Theta$.\n* z is noise in the measurement (zero-mean random fluctuations of sensory states) parameterized by $\\lambda$.\n* w noise in the actual environment (zero-mean random fluctuations of the motion of hidden states) parameterized by $\\lambda$.\n* $x$ is the continuous stream of the hidden states the brain tries to infer. The vector $\\vec{x}(t) \\in  \\mathbb{R}^{n}$ with n number of states over a time period as a stream of data.\n* $y$ is the continuous stream of sensory observations. The vector $\\vec{y}(t) \\in  \\mathbb{R}^{q}$ with q number of sensors over a time period as a stream of data.  \n* note that actions $u$ are not modelled in the generative model (they are in the generative process) as described in the section [minimize free energy by acting on the environment](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1#sec41) of the first notebook. The action is not modelled in the generative model because it is the result of lowering Free Energy. The equation of motion in the generative process depends on action, whereas the generative model has no notion of action.  \n\n<a id='sec44'><\/a>\n## Noise\n[Noise](https:\/\/www.merriam-webster.com\/dictionary\/noise) refers to any random fluctuations of data. Irrelevant or meaningless data or output occurring along with desired information. \nIn nature, noise and other inaccuracies are all around us and biological life need to function despite these fluctuations.  \n\nThe brain is remarkable robust against noise. For example, we have a good chance to catch a ball if it is later in the day and there are more shadows, if your cat suddenly rushes by, if the ball is spinning, if you arms are a little sore, etc.\n\nNoise is modelled in the Free Energy Principle as fluctuations in the actual states and fluctuations in the measurement.  Similar like regular state space models in conventional control theory. \n\nRandom noise $w$ is a zero-mean white noise with a certain variance $\\sigma_{w}^2$. Since x is a vector $\\vec{x}(t) \\in  \\mathbb{R}^{n}$ with n number of states, also $w$ needs to be a vector where the variance is expressed as a covariance matrix $\\Sigma _{w}$. (The capital of $\\sigma$ is $\\Sigma$) It defines the variances and covariances of the n dimensions. The [covariance matrix](https:\/\/en.wikipedia.org\/wiki\/Covariance_matrix) is a generalization of the covariance of two variables and captures the way in which all variables in the dataset may change together. The precision matrix is the inverse of the covariance matrix $\\Pi=\\Sigma^{-1}$\n+ For a quick introduction read this [article](https:\/\/machinelearningmastery.com\/introduction-to-expected-value-variance-and-covariance\/) or watch this [video](https:\/\/www.youtube.com\/watch?v=9B5vEVjH2Pk).\n+ The diagonal of the covariance matrix are the variances of each of the random variables.\n+ The covariance matrix is a square and symmetric matrix \n\nHence random noise $w$ is noted as $w=\\mathcal N(0,\\Sigma _{w})$. Likewise $z=\\mathcal N(0,\\Sigma _{z})$. Where  $\\begin{Bmatrix} \\Sigma _{w},\\Sigma _{z} \\end{Bmatrix} \\subseteq \\lambda$, the hyperparameters defining noises.\n\nActive inference assumes independent noises, random fluctuations (both w on hidden states and z on sensory observations) are not correlated. Therefor a covariance matrix in active inference is a matrix with all zero's except for variances along its diagonal. All the variances are positive numbers.  \nFor example a covariance matrix of 3 independent random sequences with variance 3, 6 and 9\n$$\n\\Sigma=\\begin{bmatrix}\n3 & 0 &0 \\\\ \n0 & 6 & 0\\\\ \n 0& 0 & 9\n\\end{bmatrix}\n$$\nand the corresponding Precision matrix corresponding to the above example is: \n$$\n\\Pi=\\Sigma^{-1}=\\begin{bmatrix}\n\\frac{1}{3} & 0 &0 \\\\ \n0 & \\frac{1}{6} & 0\\\\ \n 0& 0 & \\frac{1}{9}\n\\end{bmatrix}\n$$\nDue to this shape of the covariance matrix it has some convenient properties which simplify the math, see annex [Covariance matrix math](#secA4).\n\nNote for people who don't speak \u00a8math\u00a8 as often as English, don't mix up the meaning of $\\Pi$ in the various contexts. Here it is the precision matrix, but in the formula of the mean-field approximation context it is a multiplication  $\\prod p(x_i)=p(x_1)\\cdot p(x_2)\\cdot..p(x_n)$. Same for $\\Sigma$, here a covariance matrix but in different context a summation $\\Sigma p(x_i)=p(x_1)+p(x_2)+..p(x_n)$.\n\nIn active inference understanding the noise has a very central role and hence quite some focus on it. It is not \u00a8just\u00a8 adding some small random numbers.  Why? Because active inference requires to extract the regularities from the irregularities, the signal from the noise, the prediction error from the noise. More to follow in next chapters.\n\n","a43917f3":"In short, \n+ The more noisy the environment (higher variance) the bigger the variances of the higher order motion and thus less taken into account. Less noise -> more higher order motions will be taken into account\n+ The more rough the noise (smaller variance of the filter) the bigger the variances of the higher order motions and thus less taken into account. Smoother noise -> more higher order motions will be taken into account \n\nMakes sense!","67e0b65f":"<a id='sec7'><\/a>\n# Dynamic model in generalised coordinates of motion\n\nLet's go back for a moment to the example in the first active inference notebook where you catch the ball your child is throwing. Somehow the brain has estimated the basics of natural dynamics that we experience every day to catch the ball. Notice that I wrote estimated, if I would ask you to write down the exact position\/speed of the ball you couldn't do it. And even if you remembered the correct gravity acceleration constant and newton's laws, you probably did not have the math to calculate the effect of the air resistance, wind effects, effects of a spinning ball, etc. To estimate the path you did not have a little scientist in our brain doing complex math. People could catch falling apples even before Newton wrote down his laws of physics.  \n\nThe Free Energy principle equips the model with the possibility to estimate the instantaneous path or trajectory of a moving hidden cause (x) from the sensory data. It can estimate the higher order motions internally (position, speed, acceleration, jerk, etc) using generalized coordinates of motion. The brain has access to a stream of sensory data so it can estimate and improve continuously the instantaneous trajectory based on prediction error minimization at each point in time. That means in our example of catching the ball, the brain does not have to estimate all possible influences on the ball (e.g. wind, gravity, spinning ball, etc.) but it can simply start estimating the net result of these forces by estimating the path based on the observations\/path so far.\n\nThis also enables the brain to move your arm to match an moving object on the same trajectory. For example, ever been at an airport where you needed to pick up your suitcase from a moving conveyor belt? Noticed you can move your hand at the same speed as the suitcase and grab the handle. A good indication that the brain can match position, speed, acceleration (i.e. estimate he higher order of motions).\n\nInteresting idea!\n\n<a id='sec71'><\/a>\n## Generalised coordinates of motion\nThe instantaneous path or trajectory of x(t) at time t will be notated as $\\tilde{x}$, where\n$$\\tilde{x}(t)=\\begin{bmatrix}\nx(t)\\\\ \nx'(t)\\\\ \nx''(t)\\\\ \nx'''(t)\\\\ \n...\\\\ \nx^{(p)}(t)\\\\ \n\\end{bmatrix}\n\\: compactly \\: written\\: as\\:\\:\\:\n\\tilde{x}=\\begin{bmatrix}\nx\\\\ \nx'\\\\ \nx''\\\\ \nx'''\\\\ \n...\\\\ \nx^{(p)}\\\\ \n\\end{bmatrix}\n=[x, x', x'', x''',....x^{(p)}]^{T} $$\nWhere the symbol ' means the time derivative d\/dt as estimated by the brain at point t, '' the second derivative, etc.  \ne.g.  $\\tilde{x}$=[position, speed, acceleration, jerk, ...]$^T$  \nVariable p is the embedding order, and note that the vector has p+1 values. In the Free Energy principle the embedding order p=6 is suggested.  \nNote that $x=\\vec{x}(t)\\in\\mathbb{R}^{n(p+1)}$, it is already a 3 dimensional array in matrix terminology: n hidden causes $x_1,x_2,..,x_n$, over a number of timestamps $t \\in [0..T]$, expressed in $[x(t), x'(t), x''(t), ..x^{(p)}]$ coordinates of motion.  \nIn short, $\\tilde x$ represents the instantaneous probabilistic belief about the motions of the hidden state x. Likewise, $\\tilde{y}$, $\\tilde{w}, \\tilde {\\mu}_{x}$, etc are generalised states. \n\n<a id='sec72'><\/a>\n## Local linearity approximation\n\nTaking a sixth order derivative becomes a very complex long formula. Fortunately, this can be simplified. If you zoom in close enough to any specific point of a continuous function, it it becomes linear (see animation below). This is called [local linearity](https:\/\/www.khanacademy.org\/math\/ap-calculus-ab\/ab-diff-contextual-applications-new\/ab-4-6\/v\/local-linearity-and-differentiability). This handy characteristic can be used to approximate points around that specific point and thus to estimate the instantaneous path or trajectory at that point.\n<img src=\"https:\/\/math.la.asu.edu\/~arce\/mat210_web\/lessons\/Ch2\/2_3\/2_3ol_old_files\/local_linearity.gif\" width=200>.\n\nNote that both functions f and g of the generative model are continuous functions, so the local linearity approximation can be applied.\n<a id='sec73'><\/a>\n## State space model in generalised coordinates of motion\nExtending the state space model\n\n$$x'= f(x) + w \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y= g(x) + z$$  \n\ninto generalized coordinates of motion using local linearity approximation (only the first derivative parts to estimate a straight line) results into (recursive differentiation using the [chain rule](https:\/\/en.wikipedia.org\/wiki\/Chain_rule) and [product rule](https:\/\/en.wikipedia.org\/wiki\/Product_rule)):\n\n$$ {x}'= f(x) + w \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y= g(x) + z$$\n$$ {x}''= \\partial_{x}f(x)\\cdot{x}' +{w}' \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y'= \\partial_{x}g(x)\\cdot{x}' + z'$$\n$$ {x}'''= \\partial_{x}f(x)\\cdot{x}''  + {w}'' \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y''= \\partial_{x}g(x)\\cdot{x}'' + z''$$\n$$ {x}''''= \\partial_{x}f(x)\\cdot{x}''' + {w}''' \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y'''= \\partial_{x}g(x)\\cdot{x}''' + z'''$$\n$$ etc \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: etc$$\n\nWhere $\\partial_{x}f(x)= \\frac{\\partial f(x)}{\\partial x }$ , $\\partial_{x}g(x)= \\frac{\\partial g(x)}{\\partial x }$ and $x'(t)= \\frac{\\partial x(t)}{\\partial t}$. Thus  $\\partial_{x}f(x)$ is the derivative of function f with respect to x and $x'(t)$ is the time derivative of x.\n\nBy taking the following definitions\n$$\\tilde{f}(\\tilde x)= \\begin{bmatrix} f(x), \\partial_{x}f(x)\\cdot{x}', \\partial_{x}f(x)\\cdot{x}''  , \\partial_{x}f(x)\\cdot{x}'''... \\end{bmatrix}$$\n$$\\tilde{g}(\\tilde x)= \\begin{bmatrix} g(x), \\partial_{x}g(x)\\cdot{x}',\\partial_{x}g(x)\\cdot{x}''  , \\partial_{x}g(x)\\cdot{x}'''... \\end{bmatrix}$$\n\nthe state space model in generalized coordinates of motion can be compactly written as:\n\n$$\\mathcal{D}\\tilde{x}= \\tilde{f}(\\tilde x) + \\tilde{w} \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\tilde{y}= \\tilde{g}(\\tilde x) + \\tilde{z}$$  \n\nwhere $\\mathcal{D}$ is the derivative operator that shifts all variables of a vector up by one and adds a zero at the bottom. So $\\mathcal{D}\\tilde{x}=\\tilde{x}'$, with the exception that $\\mathcal{D}\\tilde{x}^{(p+1)}=0$. See example below.\n\nThis introduces a concept of derivatives of noise which is explained in the coloured noise section below.\n\n\n","11079108":"<a id='secA'><\/a>\n# Appendix\n\n<a id='secA1'><\/a>\n## Laplace encoded Free Energy math - part 1\n\nIn this annex the main steps for a simple case with a single hidden state x and a single hidden state y (vector of 1 number) are explained. To see the full detailed mathematical proof please See paper [the free energy principle for action and perception: a mathematical review](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0022249617300962), I will not try to compress 77 pages of math into this notebook. \n\nThe Free energy is defined as:\n\n$$\\mathcal{F}(y,\\zeta )= \\int q(x; \\zeta )ln(\\frac{q(x; \\zeta )}{p(x,  y)})dx $$\n\nsince ln(a\/b)=ln(a)-ln(b)    \nand defining the Laplace-encoded Energy as $E(x,y) = -ln \\, p(x, y) $\n\n$$= \\int q(x; \\zeta )E(x,y)dx + \\int q(x; \\zeta )ln({q(x; \\zeta )})dx  $$\n\nUnder the Laplace assumption the Recognition Density is assumed to be  Gaussian, thus:\n\n$$q(x; \\zeta ) = \\frac{1}{\\sqrt{2\\pi\\sigma^2} } e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }$$\n\nSubstituting this equation in the Free Energy, \n$$ = \\int q(x; \\zeta )E(x,y)dx  -ln\\sqrt{2\\pi\\sigma^2}-\\frac{1}{2})   $$\n\nand applying a second order [Taylor approximation](https:\/\/www.youtube.com\/watch?v=3d6DsjIBzJ4) (derivative information at a point translates to approximation around the point) of E(x, y) around x = $\\mu$ (non-zero density only at sharp peak $\\mu$) allows to re-write the approximation as (note: first order derivative is 0 because peak at $\\mu$):\n\n$$ \\approx E(\\mu,y)  +\\frac{1}{2}(\\left [ \\frac{d^{2}E}{dx^2} \\right ]_{\\mu}\\sigma^2-ln2\\pi\\sigma^2-1)   ) $$\n\nBy solving $d\\mathcal{F} =0 $ with respect to the variance $\\sigma^2$ (which optimizes the free-energy), it further simplifies to:\n\n$$ \\approx E(\\mu,y) -\\frac{1}{2}(ln2\\pi\\sigma^{2*}) $$\n\nWhere $\\sigma^{2*}=\\left [ \\frac{d^{2}E}{dx^2} \\right ]_{\\mu}^{-1} $ is the variance that optimizes the Free Energy. It is a constant, which is calculated from the mean $\\mu$. In other words, the Free Energy only depends on the Gaussian mean $\\mu$ and not $\\sigma$, which significantly simplifies the expression. To further simplify and get rid of the constant (remember that the objective is to minimize the free energy so a constant doesn't matter), \n\n$$ \\approx  E(\\mu,y) = -ln \\, p(\\mu,y) $$ \n\nthe **Laplace encoded Free Energy** as approximation of the Free Energy is written as:\n$$\\mathcal{F}(y,\\mu) = -ln \\, p(\\mu,y)  \\approx \\mathcal{F}(y,\\zeta )  $$ \n\nThis equation also holds for the multivariate case with $\\vec{x}\\in\\mathbb{R}^n$,  $\\vec{y} \\in  \\mathbb{R}^{q}$ and  $\\vec{\\mu}\\in\\mathbb{R}^{n}$ (assuming the mean-field approximation, and the multidimensional recognition density is still tightly peaked, see [the free energy principle for action and perception: a mathematical review](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0022249617300962) paper for the detailed proof).\n\nBack to [Recognition density](#sec2) \n\n<a id='secA2'><\/a>\n## Laplace encoded Free Energy math - part 2\n\n\nIn this annex the main steps continuing for a simplest case generative model (with a single hidden state x and a single sensory channel y, static environment) are explained. To see the full detailed mathematical proof please See paper [the free energy principle for action and perception: a mathematical review](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0022249617300962), I will not try to compress 77 pages of math into this notebook.\n\nIn this simplest example the brain is estimating a single static hidden cause. The generative model is  \n$x= f(x) + w$  (function of motion)   \n$y= g(x) + z$   (function of sensory mapping)  \n\nThis can be re-ordered as  \n$w=x - f(x)$  \n$z = y - g(x)$   \n\nSince under the Laplace assumption all probability densities are Gaussian, it also applies for w and z  \n$w=\\mathcal{N}(0,\\sigma^2_{w})$  \n$z=\\mathcal{N}(0,\\sigma^2_{z})$  \n\nThus the functional form of the generative density  (intuition: without the noise x-f(x) is 0 but with the noise it has become a probability distribution in the shape of the added noise)   \n$p(x)=\\mathcal{N}(x - f(x),\\sigma^2_{w})$  (function of motion)  \n$p(y\\mid x)=\\mathcal{N}(y - g(x),\\sigma^2_{z})$  (function of sensory mapping)  \n\nThe Laplace encoded Free energy formulation that we minimize with active inference\n$$\\mathcal{F} =  -ln\\: p(\\mu,y) $$\nproduct rule\n$$ -ln\\: p(y\\mid \\mu)p(\\mu) $$ \nln(ab)=ln(a)+ln(b)\n$$ -ln\\: p(y\\mid \\mu) -ln\\: p(\\mu)  $$ \nsubstituting the densities\n$$  -ln\\: \\frac{1}{\\sqrt{2\\pi\\sigma_z^2} } e^{ -\\frac{(y - g(\\mu))^2}{2\\sigma_z^2} } -ln\\:  \\frac{1}{\\sqrt{2\\pi\\sigma_w^2} } e^{ -\\frac{(\\mu - f(\\mu))^2}{2\\sigma_w^2} }$$  \n$ln(e^a)=a$\n$$ \\frac{(y - g(\\mu))^2}{2\\sigma_z^2} + \\frac{(\\mu - f(\\mu))^2}{2\\sigma_w^2}  -ln\\: \\frac{1}{\\sqrt{2\\pi\\sigma_z^2} }- ln\\:  \\frac{1}{\\sqrt{2\\pi\\sigma_w^2} }$$\n$ln(\\sqrt a)= \\frac{1}{2}ln(a)$\n$$x \\frac{(y - g(\\mu))^2}{2\\sigma_z^2} + \\frac{(\\mu - f(\\mu))^2}{2\\sigma_w^2}  +\\frac{1}{2} ln\\: ({2\\pi\\sigma_z^2) }+\\frac{1}{2} ln\\:  ({2\\pi\\sigma_w^2})$$\ngrouping of the ln equations\n$$ \\frac{(y - g(\\mu))^2}{2\\sigma_z^2} + \\frac{(\\mu - f(\\mu))^2}{2\\sigma_w^2}  +\\frac{1}{2} ln\\: ({\\sigma_z^2\\sigma_w^2) } + ln\\: (2\\pi) $$\nRemoving the constant (not relevant when lowering Free Energy)\n$$ \\frac{1}{2\\sigma_z^2}\\varepsilon_y^2 + \\frac{1}{2\\sigma_w^2}\\varepsilon_x^2  +\\frac{1}{2} ln\\: ({\\sigma_z^2\\sigma_w^2) } $$\n\nWhere $\\varepsilon$ are the prediction errors:\n* $\\varepsilon_y = y-g(\\mu) $ is the sensory prediction error. The delta between the sensory data y and the prediction of the function of sensory mapping.\n* $\\varepsilon_x = \\mu - f(\\mu) $ is the the model prediction error. The delta between the belief of the hidden states and the prediction of the function of motion.\n\nThis equation also holds for the multivariate case with $\\vec{x}\\in\\mathbb{R}^n$,  $\\vec{y} \\in  \\mathbb{R}^{q}$ and  $\\vec{\\mu}\\in\\mathbb{R}^{n}$, see [the free energy principle for action and perception: a mathematical review](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0022249617300962) paper for the detailed proof, leading to a summation of precision weighted prediction errors in all hidden causes and all sensory observations. The variance $\\sigma_z$ is substituted by a covariance matrix $\\Sigma_z$. Analogously for $\\sigma_w$ and $\\Sigma_w$. We only assume noises are independent, but not the hidden causes. In fact, the hidden causes do have dependencies, exactly the patterns that need to be inferred to construe the generative model from the sensory observations.\n\nBack to [Prediction error minimization](#sec5) \n<a id='secA3'><\/a>\n## Laplace encoded Free Energy math - part 3\n\nThe Laplace encoded Free energy in a generalized matrix notation that is used in the Free Energy scientific papers\n$$\\mathcal{F}(y,\\mu) = \\frac{1}{2}\\varepsilon^T \\Pi \\varepsilon - \\frac{1}{2} ln \\begin{vmatrix}\n\\Pi\n\\end{vmatrix} \\:\\:\\:\\:\\:\\:\\:\nwhere \\:\\:\\:\\:\\:\\:\\:\n\\varepsilon=\\begin{bmatrix}\n\\varepsilon_y\n\\\\ \n\\varepsilon_x\n\\end{bmatrix}$$\n\n$\\varepsilon$ written out in the Free Energy expression, Precision matrix is the inverse of the covariance matrix: $\\Pi = \\Sigma^{-1}$\n$$ = \\frac{1}{2} \\begin{bmatrix}\n\\varepsilon_y & \\varepsilon_x\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_z^2 & 0 \\\\ \n 0 & \\sigma_w^2 \n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n\\varepsilon_y\\\\ \n\\varepsilon_x\n\\end{bmatrix}- \\frac{1}{2} ln \\begin{vmatrix}\n\\begin{bmatrix}\n\\sigma_z^2 & 0 \\\\ \n 0 & \\sigma_w^2 \n\\end{bmatrix}^{-1}\n\\end{vmatrix}$$\n\nEach of the non-zero values is replaced with its reciprocal in case of an inverse of a covariance matrix with independent distributed values (square, with zero's except for variances along its diagonal)\nmatrix: $\\Pi = \\Sigma^{-1}$\n$$ = \\frac{1}{2} \\begin{bmatrix}\n\\varepsilon_y & \\varepsilon_x\n\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{1}{\\sigma_z^2} & 0 \\\\ \n 0 & \\frac{1}{\\sigma_w^2} \n\\end{bmatrix}\n\\begin{bmatrix}\n\\varepsilon_y\\\\ \n\\varepsilon_x\n\\end{bmatrix}- \\frac{1}{2} ln \\begin{vmatrix}\n\\begin{bmatrix}\n\\frac{1}{\\sigma_z^2} & 0 \\\\ \n 0 & \\frac{1}{\\sigma_w^2} \n\\end{bmatrix}\n\\end{vmatrix}$$\n\nThe [determinant](https:\/\/en.wikipedia.org\/wiki\/Determinant) of a 2x2 matrix $\\begin{bmatrix}\na & b \\\\ \nc & d\n\\end{bmatrix}$ = ad-bc, or more general: in case of a covariance matrix with independent distributed values (square, with zero's except for variances along its diagonal) the determinant is the multiplication of the variances on the diagonal\n\n$$= \\frac{1}{2} \\begin{bmatrix}\n\\varepsilon_y & \\varepsilon_x\n\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{\\varepsilon_y}{\\sigma_z^2}\\\\ \n\\frac{\\varepsilon_x}{\\sigma_w^2}\n\\end{bmatrix}- \\frac{1}{2}ln \n(\\frac{1}{\\sigma_z^2} \\frac{1}{\\sigma_w^2} -0)$$\n\n$$\n\\ =\\frac{1}{2\\sigma_z^2 }\n\\varepsilon_y^2\n+\n\\frac{1}{2\\sigma_w^2}\n\\varepsilon_x^2\n+ \\frac{1}{2} ln \n( \\sigma_z^2\\sigma_w^2)\n$$\n\n\nIf you are new to the world of linear algebra, I would like to recommend to watch the following video tutorials: [Essence of linear Algebra](https:\/\/www.youtube.com\/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\nBelow I have posted some basic matrix calculation examples to build a first understanding.\n\nBack to [Prediction error minimization](#sec5) ","e627864c":"<a id='sec10'><\/a>\n# How the brain might function- part 3\nWhen reaching advanced basecamp you again look up to the top and wondered if you made significant progress. Still a long way to go and you need some inspiration to continue next time. Below the result of an actual robot moving with active Inference by Corrado Pezzato at the Technical University Delft. See github repository [active inference for robot manipulators](https:\/\/github.com\/cpezzato\/panda_simulation).\n\n<img src=\"https:\/\/i.imgur.com\/yZxHtES.gif\" width=500> \nFull video: [https:\/\/www.youtube.com\/watch?v=Vsb0MzOp_TY](https:\/\/www.youtube.com\/watch?v=Vsb0MzOp_TY) \n<br>\n\nIn the video the hidden states x inferred are the joint angles of the robot. Simulation results with a 7-DOF robot manipulator shows a number advantages of an Active Inference Controller (AIC) over a more conventional controller (MRAC).\n* AIC adapts to real-world dynamics and worked out-of-the box. MARC not and cannot work out-of-the-box (safety stop)\n* MRAC needs to tune 70 parameters to get to reasonable performance, AIC 1. \n* AIC can cope with noise disrupting the system. (tested with eg additional noise added to the sensor readings). \n* AIC moves gracefully. When you stop the arm moving you feel it starts building force to push you away.\n* AIC is computable light and does not need intensive compute. No issue to add extra degrees of freedom.\n* AIC can easily integrates new sensors, eg next notebook will showcase an example where a robot moves to a position observed with it's camera\n\nMaybe it is also good that I explain why I like\/use this robot arm example. It goes back to how infants learn their abilities after birth. The brain is skull-bound and needs to infer the causes of its sensory input, even states of your own body need to be inferred, everything outside the brain needs to be inferred. According to this research [paper](https:\/\/royalsocietypublishing.org\/doi\/10.1098\/rstb.2018.0030) learning of the generative model starts by learning your own body: it enables infants to first recognize their body as sensory signals producing no or very small prediction error (self cognition). \n\nNext notebook we will explore the \u00a8neurologically plausible\u00a8 part, gradient descent to minimize the prediction error, how the free energy principle models the world in a Hierarchical Model leading to predictive coding schemes.\n\nHoped you liked my notebook (upvote top right), my way to contribute back to this fantastic Kaggle platform and community. Let me know if these notes helped you to better understand active inference and the free energy principle. My intent is to help catalyse knowledge and research on Active Inference in an engineering\/robotics\/data sciences\/machine learning context. So if you are interested to learn more about it please keep on reading in the next notebook:\n\n[How the brain might function - part 3](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-3) \n\nI would like to especially thank Sherin Grimbergen, I could build my understanding on his investigations and our dialogues helped me a lot understanding active inference. Also special thanks to Corrado Pezzato for proofreading and giving valuable feedback. And finally please remember, this notebook is just trying to make the brilliant work of Karl Friston more accessible, it might Hold the Key to True AI.\n\n\n","bf23bb0f":"<a id='sec82'><\/a>\n## Generalised precision matrix\n$\\tilde\\Pi_w$ resp. $\\tilde\\Pi_z$ is the generalised precision matrix for noise in the environment resp. measurement. Both matrices are needed to calculate the Free Energy.\n\nThe ultimate idea is that active inference infers the the expected precision of uncertainty by attention: $\\mu_\\lambda=\\underset{\\mu_\\lambda }{Argmin}\\:  \\mathcal{F}(y,\\mu)$  where $\\lambda$ are the hyperparameters defining the noises, as we have seen in the paragraph [Inference the generative model](#sec6).\n\nBut if the precision matrices are to be given as input to active inference (eg in simulations) they need be calculated from the way the noise that was created. Noise used in generalised coordinates of motion is continuous with some form of temporal smoothness. That means that derivates of the noise are dependent and entries in the covariance need to be calculated. \n\nIn case of $\\tilde \\Pi_w$ the white Gaussian noise signal (defined by covariance matrix $\\Sigma_w$ ) is convoluted with a Gaussian filter (defined by variance $s_w^2$ ) to create the coloured noise (see notebook [noise with temporal smoothness](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-noise)), the precision matrix can be constructed (see annex [Computation of the generalised precision matrix](#secA5)). The precision matrix of the generalized noise $\\tilde w$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{x}$ at all orders of motion and is calculated as :\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_w}^{-1}= (S(s_w^2) \\otimes \\Sigma_w )^{-1}= S(s_w^2)^{-1} \\otimes \\Sigma_w^{-1}  $$\n\nWhere:\n* $\\Sigma_w^{-1} = \\Pi_w$ is the precision matrix of the white noises as defined in paragraph [Noise](#sec44) \n* $S(s_w^2)$ is the temporal covariance matrix, or $S(s_w^2)^{-1}$ the temporal precision matrix\n* $s_w^2$ the variance of the Gaussian filter used to create the coloured noise\n  \nand the temporal covariance matrix (example with p=5):\n\n$$S(s_w^2)= \\begin{bmatrix}\n1 & 0 & -\\frac{1}{2s_w^2} & 0 & \\frac{3}{{(2s_w^2)}^{2}} & 0\\\\ \n0 & \\frac{1}{2s_w^2} & 0 & -\\frac{3}{{(2s_w^2)}^{2}} & 0 & \\frac{15}{{(2s_w^2)}^{3}}\\\\ \n-\\frac{1}{2s_w^2} & 0 & \\frac{3}{{(2s_w^2)}^{2}} & 0 & -\\frac{15}{{(2s_w^2)}^{3}} & 0\\\\ \n0 & -\\frac{3}{{(2s_w^2)}^{2}} & 0 & \\frac{15}{{(2s_w^2)}^{3}} & 0 & -\\frac{105}{{(2s_w^2)}^{4}} \\\\ \n\\frac{3}{{(2s_w^2)}^{2}} & 0 & -\\frac{15}{{(2s_w^2)}^{3}} & 0 & \\frac{105}{{(2s_w^2)}^{4}} & 0\\\\ \n0 & \\frac{15}{{(2s_w^2)}^{3}} & 0 & -\\frac{105}{{(2s_w^2)}^{4}}  & 0 & \\frac{945}{{(2s_w^2)}^{5}} \n\\end{bmatrix}$$\n\nUsually $s_w^2$<<1, so the variances on the diagonal of the above covariance matrix grow quickly and thus the influence of higher order motions in the Free energy quickly diminishes. For example $s_w^2$=1\/64 has been used to generate the noise with temporal smoothness in the code example earlier in the notebook.\n\nSimilar for $\\tilde \\Pi_z$.  \n\nIn short, because we generated noise with temporal smoothness, the generalised precision matrix can be exactly computed as input for simulations.\n","2d360466":"<a id='sec9'><\/a>\n# Advanced Base camp\nYou made it and reached advanced base camp!  \nTo summarize the notebook\/progress again in a picture:  \nMinimizing the Laplace encoded Free Energy with Active Inference boils down to minimizing a quadratic sum of prediction errors, mediated by the precision (inverse variances). It is an automatable optimization problem through prediction error minimization by iterately finding $\\mu$ with the lowest Free Energy.\n\n* $\\tilde x$ is the continuous stream of trajectories of external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}(t)\\in\\mathbb{R}^{n(p+1)}$ with n number of states and generalised coordinates of motion embedding order p.\n* $\\tilde y$ is the continuous stream of trajectories of sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation}(t) \\in  \\mathbb{R}^{q(p+1)}$ with q number of sensors and generalised coordinates of motion embedding order p. \n* $u$ is the continuous stream of actions that are performed on the environment, control signal. Shorthand notation for the vector $\\vec{u}(t) \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative model encoding a probabilistic model of the environment\/world in which it is immersed.   \n    $\\mathcal{D}\\tilde{x}= \\tilde{f}(\\tilde x,\\Theta) + \\tilde{w}(\\lambda) \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\tilde{y}= \\tilde{g}(\\tilde x,\\Theta) + \\tilde{z}(\\lambda)$  \n    where $\\Theta$ are the parameters of the generative model and $\\lambda$ the hyperparameters of the noise.\n    * by estimating hidden causes $ \\mu= \\begin{Bmatrix} \\tilde{\\mu}_x,\\mu_\\Theta,\\mu_\\lambda \\end{Bmatrix}$ (given sensory data $y$). Under the Laplace\/mean-field approximations estimating hidden causes simplify to estimating mean $ \\mu$ instead of a full recognition density . $\\tilde{\\mu}_x$ is shorthand notation for the vector $\\tilde {\\vec{\\mu}}_x(t)\\in\\mathbb{R}^{n(p+1)}$.\n    * by finding $\\tilde{\\mu}_x,\\mu_\\Theta,\\mu_\\lambda,u$ with the lowest Free Energy and thus lowest surprise in sensory states:\n        * Improving perception:  $\\tilde{\\mu}_x=\\underset{\\tilde{\\mu}_x }{Argmin}\\:  \\mathcal{F}(\\tilde y,\\mu)$ \n        * Acting on the environment:  $u= \\underset{u }{Argmin}\\:  \\mathcal{F}(\\tilde y,\\mu)$\n        * Learning the generative model: $\\mu_\\Theta=\\underset{\\mu_\\Theta }{Argmin}\\:  \\mathcal{F}(\\tilde y,\\mu)$   \n        * Attention or optimizing expected precision of uncertainty: $\\mu_\\lambda=\\underset{\\mu_\\lambda }{Argmin}\\:  \\mathcal{F}(\\tilde y,\\mu)$  \n\n![](https:\/\/i.imgur.com\/EOq0ghO.jpg)\n","be99f472":"Does the brain reconstruct the internal generative model with the exact same parameters as the generic process? Maybe for the more simple\/basic movement but in principal the generative model of the world may be different from the generative process generating the real sensory data: \n+ The brain can also abstract at a higher abstraction level to predict the trajectories. E.g. it is back to the argument of catching the ball, the brain does not have to estimate all possible influences on the ball (e.g. wind, gravity, spinning ball, etc.) but it can simply start estimating the net result of these forces by estimating the path based on the observations\/path so far. \n+ Moreover, the brain estimates movements relative to the viewpoint of its own position and movement is relative to other things you observe. In his book \u00a8[exploring robotics minds](https:\/\/books.google.nl\/books?id=iAUBDQAAQBAJ&pg)\u00a8 Jun Tani pitched a nice example of catching a baseball flying through the air by continuously adjusting your own movement such that the ball appears to come in a straight line to you in the visual field. No need for complicated computing like arc, speed, distance. A relatively simple principle of perceptual constancy. \n+ It also makes a difference if things move in the foreground or background.  e.g. the movement of a plane high in the sky. You (or for that matter also applicable for e.g. my cat) don't need to estimate all exact complex aerodynamics of the flying plane (generative process) to predict\/estimate the movement of the plane on the pixels of your retina (generative model)  \n\nIn short, the generative model estimates (belief) the instantaneous path or trajectory of a moving hidden cause. Which can be different from the generative process in the world (or simulated environment) generating the sensory observations. To emphasize the point a difference of notation is used: $\\dot{*}$ vs. $*'$ ;Derivative (physical) vs. motion (belief).\nHence, the generative process is written as:\n\n$$\\dot x= f(x) + w \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: y= g(x) + z$$  \n\n\n","6c5fea12":"## How the brain might function - part 1 basecamp recap\n\nAs a reminder, we ended the previous notebook with the following summary:\n* x are the external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states.\n* y are the sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* u are the actions that can be performed on the environment, control signal. Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative density $p(x,y)$: the brain encoding a probabilistic model of the environment\/world in which it is immersed. \n    * by a recognition density $q(x; \\zeta )$: the brain estimating hidden states $x$ (given sensory data $y$)\n    * by finding $\\zeta$ and $u$ with the lowest Free Energy and thus lowest surprise in sensory states:\n        * By improving perception:  $\\zeta=\\underset{\\zeta }{Argmin}\\:  \\mathcal{F}(y,\\zeta)$ \n        * By acting on the environment:  $u=\\underset{u }{Argmin}\\:  \\mathcal{F}(y,\\zeta)$ \n\n![](https:\/\/i.imgur.com\/eB6QaTB.jpg)\n\n","9347fb4f":"To summarize it again in a picture:\n* $x$ are the external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states.\n* $y$ are the sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* $u$ are the actions that can be performed on the environment, control signal. Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative density $p(x,y)$ encoding a probabilistic model of the environment\/world in which it is immersed. \n    * by estimating hidden states $x$ over time (given sensory data $y$). Under the Laplace\/mean-field approximations estimating hidden states simplify to estimating mean $\\mu$ instead of a full recognition density. Shorthand notation for the vector $\\vec{\\mu}(t)\\in\\mathbb{R}^{n}$.\n*  by finding $\\mu$ and $u$ with the lowest Free Energy and thus lowest surprise in sensory states:\n    * By improving perception:  $\\mu=\\underset{\\mu }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n    * By acting on the environment:  $u= \\underset{u }{Argmin}\\:  \\mathcal{F}(y,\\mu)$ \n\n\n![](https:\/\/i.imgur.com\/ZKepLun.jpg)"}}