{"cell_type":{"f903d84e":"code","3f447f27":"code","9dda1e14":"code","c68f0ea6":"code","5308deeb":"code","9770499b":"code","0f790a0a":"code","f50eb0fb":"code","79da977b":"code","090a64c3":"code","7b26218c":"code","87e2bc87":"code","e088c2c7":"code","4cb0a343":"code","4c4d6947":"code","1b19d884":"code","7cc1cc39":"code","4925d7c0":"code","eb8e541c":"code","fb2aee24":"code","3bd49c1d":"code","1148973e":"code","40741e68":"code","c4982edf":"code","35822a65":"code","12e42ba6":"code","7e2c2890":"code","b5a791c1":"markdown","021e7e7f":"markdown","b7ea5c3b":"markdown","d09dd2ae":"markdown","b272c3da":"markdown","6a12bc83":"markdown","33b42da6":"markdown","754af80e":"markdown","314436c0":"markdown","bf5cd011":"markdown","df4661b3":"markdown","abff6ca9":"markdown"},"source":{"f903d84e":"import sklearn.datasets\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split","3f447f27":"# load the breast cancer data\nbreast_cancer = sklearn.datasets.load_breast_cancer()","9dda1e14":"# convert the data to pandas dataframe\ndata = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n\ndata['class'] = breast_cancer.target","c68f0ea6":"data.head()","5308deeb":"data.tail()","9770499b":"data.describe()","0f790a0a":"print(breast_cancer.target_names)","f50eb0fb":"data.groupby('class').mean()","79da977b":"# plotting a graph to see c;ass imbalance\n\ndata['class'].value_counts().plot(kind = \"barh\") \nplt.xlabel(\"Count\")\nplt.ylabel(\"Classes\")\nplt.show()","090a64c3":"# perform scaling on the data\nX = data.drop(\"class\", axis = 1)\nY = data['class']","7b26218c":"# train test split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, stratify = Y, random_state=1)","87e2bc87":"plt.plot(X_test.T, '*')\nplt.xticks(rotation='vertical')\nplt.show()","e088c2c7":"X_binarised_3_train = X_train['mean area'].map(lambda x: 0 if x < 1000 else 1)","4cb0a343":"plt.plot(X_binarised_3_train, '*')","4c4d6947":"X_binarised_train = X_train.apply(pd.cut, bins=2, labels=[1,0])","1b19d884":"plt.plot(X_binarised_train.T, '*')\nplt.xticks(rotation='vertical')\nplt.show()\n","7cc1cc39":"X_binarised_test = X_test.apply(pd.cut, bins=2, labels=[1,0])","4925d7c0":"type(X_binarised_test)","eb8e541c":"X_binarised_test = X_binarised_test.values\nX_binarised_train = X_binarised_train.values","fb2aee24":"type(X_binarised_test)","3bd49c1d":"from sklearn.metrics import accuracy_score","1148973e":"X_train = X_train.values\nX_test = X_test.values","40741e68":"class Perceptron:\n# constructor \n    def __init__ (self):\n        self.w = None\n        self.b = None\n\n# model\n    def model(self, x):\n        return 1 if (np.dot(self.w, x) >= self.b) else 0\n\n# predictor to predict on the data based on w \n    def predict(self, X):\n        Y = []\n        for x in X:\n            result = self.model(x)\n            Y.append(result)\n        return np.array(Y)\n    \n    def fit(self, X, Y, epochs = 1, lr = 1):\n        self.w = np.ones(X.shape[1])\n        self.b = 0\n        \n        accuracy = {}\n        max_accuracy = 0\n        \n        for i in range(epochs):\n            for x, y in zip(X, Y):\n                y_pred = self.model(x)\n                if y == 1 and y_pred == 0:\n                    self.w = self.w + lr * x\n                    self.b = self.b - lr * 1\n                elif y == 0 and y_pred == 1:\n                    self.w = self.w - lr * x\n                    self.b = self.b + lr * 1\n            \n            accuracy[i] = accuracy_score(self.predict(X), Y)\n            if (accuracy[i] > max_accuracy):\n                max_accuracy = accuracy[i]\n                chkptw = self.w\n                chkptb = self.b\n        \n        self.w = chkptw\n        self.b = chkptb\n        \n        print(\"Max Accuracy\", max_accuracy)\n        \n        plt.plot(list(accuracy.values()))\n        plt.ylim([0, 1])\n        plt.show()","c4982edf":"perceptron = Perceptron()","35822a65":"perceptron.fit(X_train, Y_train, 10000, 0.0001)","12e42ba6":"Y_pred_test = perceptron.predict(X_test)\nprint(accuracy_score(Y_pred_test, Y_test))","7e2c2890":"plt.plot(perceptron.w)\nplt.show()","b5a791c1":"### Perceptron Model class","021e7e7f":"(Perceptron Preprocessing)\n\nAfter fetching the X and Y variables, we will perform Min-Max scaling to bring all the features in the range 0\u200a\u2014\u200a1. Before building the model, we will split the data so that we can train the model on training data and test the performance of the model on testing data. We will use sklearn\u2019s train_test_split function to split the data in the ratio of 90:10 for training and testing respectively. Now that we are done with preprocessing steps, we can start building the model. We will build our model inside a class called perceptron.\n\nIn the perceptron class, we will create a constructor function def__init__. The constructor initializes the weights vector **w** and threshold **b** to None.","b7ea5c3b":" $y = 1,\\mbox{if}\\sum_i w_i x_i >= b$","d09dd2ae":"### ***Formula***","b272c3da":"<img src='https:\/\/github.com\/taruntiwarihp\/raw_images\/blob\/master\/1_qJGkvQB_okmAVeX3k68D_A.jpeg?raw=true'>\n\nWe will see how to implement the perceptron model using breast cancer data set in python.\n\nA perceptron is a fundamental unit of the neural network which takes weighted inputs, process it and capable of performing binary classifications. This is a follow up to my previous post on the Perceptron Model.\n\n**Disclaimer**: The content and the structure of this article is based on the deep learning lectures from One-Fourth Labs\u200a\u2014\u200aPadhai.\n\n### Perceptron Recap\n\nIn the perceptron model inputs can be real numbers unlike the Boolean inputs in MP Neuron Model. The output from the model will still be binary {0, 1}. The perceptron model takes the input x if the weighted sum of the inputs is greater than threshold b output will be 1 else output will be 0.\n\n<img src='https:\/\/github.com\/taruntiwarihp\/raw_images\/blob\/master\/PM1.jpg?raw=true'>\n    \n                    Fig 1\u2014 Mathematical RepresentationLearning Algorithm\n\nThe main goal of the learning algorithm is to find vector **w** capable of absolutely separating Positive **P** (y = 1) and Negative **N**(y = 0) sets of data. Perceptron learning algorithm goes like this,\n\n<img src='https:\/\/github.com\/taruntiwarihp\/raw_images\/blob\/master\/PM2.jpg?raw=true'>\n                        \n                            (Fig 2\u2014 Perceptron Algorithm)\n\n\nTo understand the learning algorithm in detail and the intuition behind why the concept of updating weights works in classifying the Positive and Negative data sets perfectly, kindly refer to my previous post on the Perceptron Model.\n\nThe data set we will be using is breast cancer data set from sklearn. The data set has 569 observations and 30 variables excluding the class variable. The breast cancer data is an imbalanced data set, that means the classes \u20180\u2019 and \u20181\u2019 are not represented equally. In this example, we are not going to perform any sampling techniques to balance the data because this is a simple implementation of the perceptron model.\n\n<img src='https:\/\/github.com\/taruntiwarihp\/raw_images\/blob\/master\/PM3.jpg?raw=true'>\n\n(Class Imbalance)","6a12bc83":"* X as set of features and y as class label\n* In this case we looking for primary classification problem wheather a particular tissue is malignant and benign\n    * Malignant means it has cancerous nature\n    * Benign means it does't has cancer","33b42da6":"$y = 0, \\mbox{otherwise}$","754af80e":"### Train Test Split","314436c0":"### Binarisation of Inputs","bf5cd011":"(Perceptron Model Execution)\n\nOnce we have our class ready, we initialize a new perceptron class object and using that object we will call fit method on our training data to learn the best possible parameters. We will evaluate the model performance on the test data by calculating the testing accuracy.","df4661b3":"(Perceptron Model)\n\nThe function model takes input values x as an argument and perform the weighted aggregation of inputs (dot product between w.x) and returns the value 1 if the aggregation is greater than the threshold b else 0. Next, we have the predict function that takes input values x as an argument and for every observation present in x, the function calculates the predicted outcome and returns a list of predictions.\n\nFinally, we will implement fit function to learn the best possible weight vector w and threshold value b for the given data. The function takes input data(x & y), learning rate and the number of epochs as arguments.","abff6ca9":"# Perceptron Class"}}