{"cell_type":{"a89147cd":"code","1214828f":"code","b530cd94":"code","83e27ddd":"code","38aee573":"code","c1b67f3f":"code","e1a2ecdc":"code","d583682f":"code","12d17622":"code","8043351f":"code","0cb5cedd":"code","9a9c8387":"code","21d6f7b2":"code","c87104f4":"code","c226921e":"code","98160e5f":"code","df830302":"code","a31b2c01":"code","46c31c94":"code","07a69afe":"code","a5bc366f":"code","d7bcd6f6":"code","aba98172":"code","f85a0d8b":"code","07bc59ea":"code","4f913155":"code","d47e981a":"code","8e820aa6":"code","319b5509":"code","517c8ef1":"code","4ae13c06":"code","547b52cc":"code","3a307d7c":"code","6050fcd1":"code","3a78dfee":"code","be3d96e6":"code","734de1ae":"code","3107867f":"code","9b53821b":"code","bac29886":"code","71126439":"code","b53fde67":"code","214103c6":"code","589536af":"markdown","dbf3c4b5":"markdown","65cff596":"markdown","6f6a4e23":"markdown","4eaec4af":"markdown","454c09db":"markdown","e3570804":"markdown","6e68346e":"markdown","027de53f":"markdown","441d5135":"markdown","f93188dc":"markdown","88532820":"markdown","77374ea0":"markdown","d708e75f":"markdown"},"source":{"a89147cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1214828f":"# Read datas\npercent_over_25_completed_highschool = pd.read_csv(\"..\/input\/fatal-police-shootings-in-the-us\/PercentOver25CompletedHighSchool.csv\" , encoding =\"windows-1252\")\nmedian_household_income_2015 = pd.read_csv(\"..\/input\/fatal-police-shootings-in-the-us\/MedianHouseholdIncome2015.csv\" , encoding =\"windows-1252\" )\npolice_killings_us = pd.read_csv(\"..\/input\/fatal-police-shootings-in-the-us\/PoliceKillingsUS.csv\", encoding =\"windows-1252\")\nshare_race_by_city = pd.read_csv(\"..\/input\/fatal-police-shootings-in-the-us\/ShareRaceByCity.csv\", encoding =\"windows-1252\")\npercentage_people_below_poverty_level = pd.read_csv(\"..\/input\/fatal-police-shootings-in-the-us\/PercentagePeopleBelowPovertyLevel.csv\", encoding =\"windows-1252\")","b530cd94":"percentage_people_below_poverty_level.head()","83e27ddd":"percentage_people_below_poverty_level.info()","38aee573":"percentage_people_below_poverty_level.poverty_rate.value_counts()","c1b67f3f":"percentage_people_below_poverty_level[\"Geographic Area\"].unique()","e1a2ecdc":"len(percentage_people_below_poverty_level[\"Geographic Area\"].unique())","d583682f":"# Poverty rate of each state\npercentage_people_below_poverty_level.poverty_rate.replace([\"-\"],0.0, inplace = True) # - values are changed as 0.0\n#percentage_people_below_poverty_level.poverty_rate.replace([\"-\"],None, inplace = True) # or we can change - values to Nan values\npercentage_people_below_poverty_level.poverty_rate = percentage_people_below_poverty_level.poverty_rate.astype(float) # The object values that are in poverty level are changed as float\narea_list = list(percentage_people_below_poverty_level[\"Geographic Area\"].unique())\narea_poverty_ratio = []\nfor i in area_list:\n    \"\"\"\n    We determine AL state(1). Then we calculate average poverty rate(2). And then we append area_poverty_rate to area_poverty_ratio (3).\n    If you write print(i) and print(x) separately, you can see what values you have\n    \"\"\"\n    x = percentage_people_below_poverty_level[percentage_people_below_poverty_level[\"Geographic Area\"] == i] # 1 , we create new dataframe for each state\n    area_poverty_rate = sum(x.poverty_rate)\/len(x) # 2\n    area_poverty_ratio.append(area_poverty_rate) # 3\ndata = pd.DataFrame({\"area_list\": area_list,\"area_poverty_ratio\": area_poverty_ratio }) # we create new data that is from area_list and area_poverty_ratio\nnew_index = (data[\"area_poverty_ratio\"].sort_values(ascending=False)).index.values # we sort area_poverty_ratio as index values, ascending determine that sorted values increase or decrease\nsorted_data = data.reindex(new_index) # we change index values of data. And we put new data to sorted_data\n\n#visualization\nplt.figure(figsize = (15,10)) # size of figure\nsns.barplot(x = sorted_data[\"area_list\"], y = sorted_data[\"area_poverty_ratio\"]) # we create barplot\nplt.xticks(rotation= 45) # angle of x values\nplt.xlabel(\"States\")\nplt.ylabel(\"Poverty Rate\")\nplt.title(\"Poverty Rate Given States\")","12d17622":"police_killings_us.head()","8043351f":"police_killings_us.info()","0cb5cedd":"police_killings_us.name.value_counts()","9a9c8387":"# Most common 15 Name or Surname of killed people\nseparate = police_killings_us.name[police_killings_us.name != \"TK TK\"].str.split() #  split name and surname except for \"TK TK\"\na,b = zip(*separate) #  unzip separate data\nname_list = a+b #  type(name_list) = tupple\nname_count = Counter(name_list) # count names . type(name_count) = collections.Counter\nmost_common_names = name_count.most_common(15) # determine most 15 common names that is list\nx,y = zip(*most_common_names) # unzip list as x and y. (x and y are tupple)\nx,y = list(x),list(y) # change tupple to list\n#visualization\nplt.figure(figsize=(15,10))\nsns.barplot(x=x,y=y, palette = sns.cubehelix_palette(len(x)))\nplt.xlabel(\"Name or Surname of killed people\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Most common 15 Name or Surname of killed people\")","21d6f7b2":"percent_over_25_completed_highschool.head()","c87104f4":"percent_over_25_completed_highschool.info()","c226921e":"percent_over_25_completed_highschool.percent_completed_hs.value_counts()","98160e5f":"# High school graduation rate of the population that is older than 25 in states\npercent_over_25_completed_highschool.percent_completed_hs.replace([\"-\"],None,inplace = True)\npercent_over_25_completed_highschool.percent_completed_hs = percent_over_25_completed_highschool.percent_completed_hs.astype(float)\narea_list = list(percent_over_25_completed_highschool[\"Geographic Area\"].unique())\narea_highschool = []\nfor i in area_list:\n    x = percent_over_25_completed_highschool[percent_over_25_completed_highschool[\"Geographic Area\"]== i]\n    area_highschool_rate = sum(x.percent_completed_hs)\/len(x)\n    area_highschool.append(area_highschool_rate)\ndata2 = pd.DataFrame({\"area_list\": area_list, \"area_highschool_ratio\": area_highschool})\nnew_index2 = (data2[\"area_highschool_ratio\"].sort_values(ascending = True)).index.values\nsorted_data2 =data2.reindex(new_index2)\n#visualization\nplt.figure(figsize = (15,10))\nsns.barplot(x = sorted_data2[\"area_list\"], y =sorted_data2[\"area_highschool_ratio\"] )\nplt.xticks(rotation = 90)\nplt.xlabel(\"States\")\nplt.ylabel(\"High School Graduate Rate\")\nplt.title(\"Percentage of Given State's Population Above 25 that Has Graduated High School\")","df830302":"share_race_by_city.head()","a31b2c01":"share_race_by_city.info()","46c31c94":"share_race_by_city.share_white.value_counts() \n#share_race_by_city.share_black.value_counts()\n#share_race_by_city.share_native_american.value_counts()\n#share_race_by_city.share_asian.value_counts()\n#share_race_by_city.share_hispanic.value_counts()","07a69afe":"# Percentage of state's population according to races that are black,white,native american, asian and hispanic\nshare_race_by_city.replace([\"-\"],None, inplace = True)\nshare_race_by_city.replace([\"(X)\"],None, inplace = True)\nshare_race_by_city.loc[:,[\"share_white\",\"share_black\",\"share_native_american\",\"share_asian\",\"share_hispanic\"]] =share_race_by_city.loc[:,[\"share_white\",\"share_black\",\"share_native_american\",\"share_asian\",\"share_hispanic\"]].astype(float)\narea_list = list(share_race_by_city[\"Geographic area\"].unique())\nshare_white =[]\nshare_black =[]\nshare_native_american = []\nshare_asian =[]\nshare_hispanic =[]\nfor i in area_list:\n    x = share_race_by_city[share_race_by_city[\"Geographic area\"] == i]\n    share_white.append(sum(x.share_white)\/len(x))\n    share_black.append(sum(x.share_black)\/len(x))\n    share_native_american.append(sum(x.share_native_american)\/len(x))\n    share_asian.append(sum(x.share_asian)\/len(x))\n    share_hispanic.append(sum(x.share_hispanic)\/len(x))\n#visualization\nf, ax =plt.subplots(figsize = (9,15))\nsns.barplot(x =share_white, y = area_list, color = \"green\", alpha = 0.5,  label = \"white\" )\nsns.barplot(x =share_black, y = area_list, alpha = 0.5, color = \"black\", label = \"black\" )\nsns.barplot(x =share_native_american, y = area_list, alpha = 0.5, color = \"cyan\", label = \"native\" )\nsns.barplot(x =share_asian, y = area_list, alpha = 0.5, color = \"yellow\", label = \"asian\" )\nsns.barplot(x =share_hispanic, y = area_list, alpha = 0.5, color = \"red\", label = \"hispanic\" )\nax.legend(loc='lower right',frameon = True) \nax.set(xlabel='Percentage of Races', ylabel='States',title = \"Percentage of State's Population According to Races \")","a5bc366f":"# high school graduation rate vs Poverty rate of each state\nsorted_data[\"area_poverty_ratio\"] = sorted_data[\"area_poverty_ratio\"]\/ max(sorted_data[\"area_poverty_ratio\"]) #Basic Normalization\nsorted_data2[\"area_highschool_ratio\"] = sorted_data2[\"area_highschool_ratio\"]\/ max(sorted_data2[\"area_highschool_ratio\"]) #Basic Normalization\ndata3 = pd.concat([sorted_data,sorted_data2[\"area_highschool_ratio\"]], axis = 1)\ndata3.sort_values(\"area_poverty_ratio\", inplace = True)\n#visualization\nf ,ax = plt.subplots(figsize = (20,10))\nsns.pointplot ( x = \"area_list\", y = \"area_poverty_ratio\", data =data3, color = \"green\") # if we add data parameter in sns.pointplot , python recognize data columns\nsns.pointplot ( x = \"area_list\", y = \"area_highschool_ratio\" ,data=data3, color = \"red\")\nplt.text(40,0.6,'high school graduate ratio',color='red',fontsize = 17,style = 'italic')\nplt.text(40,0.55,'poverty ratio',color='lime',fontsize = 18,style = 'italic')\nplt.xlabel('States',fontsize = 15,color='blue')\nplt.ylabel('Values',fontsize = 15,color='blue')\nplt.title('High School Graduate  VS  Poverty Rate',fontsize = 20,color='blue')\nplt.grid()","d7bcd6f6":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\n# joint kernel density\n# pearsonr= if it is 1, there is positive correlation and if it is, -1 there is negative correlation.\n# If it is zero, there is no correlation between variables\n# Show the joint distribution using kernel density estimation \ng = sns.jointplot(\"area_poverty_ratio\", \"area_highschool_ratio\",data=data3, kind=\"kde\", size = 7)\nplt.savefig('graph.png')\nplt.show()","aba98172":"# you can change parameters of joint plot\n# kind : { \u201cscatter\u201d | \u201creg\u201d | \u201cresid\u201d | \u201ckde\u201d | \u201chex\u201d }\n# Different usage of parameters but same plot with previous one\ng = sns.jointplot(\"area_poverty_ratio\", \"area_highschool_ratio\", data=data3,size=5, ratio=3, color=\"r\")","f85a0d8b":"police_killings_us.race.head(15)","07bc59ea":"police_killings_us.info()","4f913155":"police_killings_us.race.value_counts()","d47e981a":"# Race rates according in kill data \nlabels = police_killings_us.race.value_counts().index\ncolors = ['grey','blue','red','yellow','green','brown']\nexplode = [0,0.1,0,0,0,0] #offsetting a slice with \"explode\"\nsizes = police_killings_us.race.value_counts().values\n\n# visual\nplt.figure(figsize = (7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%')\nplt.title('Killed People According to Races',color = 'blue',fontsize = 15)","8e820aa6":"data3.head()","319b5509":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\n# lmplot \n# Show the results of a linear regression within each dataset\nsns.lmplot(x=\"area_poverty_ratio\", y=\"area_highschool_ratio\", data=data3)","517c8ef1":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\n# cubehelix plot\nsns.kdeplot(data3.area_poverty_ratio, data3.area_highschool_ratio, shade=True, cut=3) # cut size of shape","4ae13c06":"# Show each distribution with both violins and points\n# Use cubehelix to get a custom sequential palette\npal = sns.cubehelix_palette(2, rot=-.5, dark=.3)\nsns.violinplot(data=data3, palette=pal, inner=\"points\")\nplt.show()","547b52cc":"data3.corr()","3a307d7c":"#correlation map\n# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\nf,ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(data3.corr(), annot=True, linewidths=0.5,linecolor=\"red\", fmt= '.1f',ax=ax)","6050fcd1":"# manner of death\n# gender\n# age\n# Plot the orbital period with horizontal boxes\nsns.boxplot(x=\"gender\", y=\"age\", hue=\"manner_of_death\", data=police_killings_us, palette=\"PRGn\")","3a78dfee":"# swarm plot\n# manner of death\n# gender\n# age\nsns.swarmplot(x=\"gender\", y=\"age\",hue=\"manner_of_death\", data=police_killings_us)","be3d96e6":"# pair plot\nsns.pairplot(data3)","734de1ae":"police_killings_us.manner_of_death.value_counts()","3107867f":"# kill properties\n# Manner of death\nsns.countplot(police_killings_us.gender)\n#sns.countplot(kill.manner_of_death)\nplt.title(\"gender\",color = 'blue',fontsize=15)","9b53821b":"# kill weapon\narmed = police_killings_us.armed.value_counts()\n#print(armed)\nplt.figure(figsize=(10,7))\nsns.barplot(x=armed[:7].index,y=armed[:7].values)\nplt.ylabel('Number of Weapon')\nplt.xlabel('Weapon Types')\nplt.title('Kill weapon',color = 'blue',fontsize=15)","bac29886":"# age of killed people\nfilter25 = [\"above_25\" if i >= 25 else \"below25\" for i in police_killings_us.age]\ndata4 = pd.DataFrame({\"age\": filter25})\nsns.countplot(x = data4.age)\nplt.ylabel('Number of Killed People')\nplt.title('Age of killed people',color = 'blue',fontsize=15)","71126439":"# Most dangerous cities\ncity = police_killings_us.city.value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(x=city[:12].index,y=city[:12].values)\nplt.xticks(rotation=45)\nplt.title('Most dangerous cities',color = 'blue',fontsize=15)","b53fde67":"# most dangerous states\nstate = police_killings_us.state.value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(x=state[:20].index,y=state[:20].values)\nplt.title('Most dangerous state',color = 'blue',fontsize=15)","214103c6":"# Having body cameras or not for police\nsns.countplot(police_killings_us.body_camera)\nplt.xlabel('Having Body Cameras')\nplt.title('Having body cameras or not on Police',color = 'blue',fontsize = 15)","589536af":"**BOX PLOT **","dbf3c4b5":"Basic Normalization\n\n0< [1,2,3,4,5]\/5 <1\n\n0< [1000,900,800,700,600]\/1000 < 1","65cff596":"**COUNT PLOT**","6f6a4e23":"**HEATMAP**","4eaec4af":"**KDE PLOT **","454c09db":"INTRODUCTION\n\n* Bar Plot\n* Point Plot\n* Joint Plot\n* Pie Chart\n* Lm Plot\n* Kde Plot\n* Violin Plot\n* Heatmap\n* Box Plot\n* Swarm Plot\n* Pair Plot\n* Count Plot","e3570804":"**JOINT PLOT **","6e68346e":"**SWARM PLOT**","027de53f":"**VIOLIN PLOT**","441d5135":"**PAIR PLOT**","f93188dc":"**PIE CHART**","88532820":"**BAR PLOT**","77374ea0":"**LM PLOT**","d708e75f":"**POINT PLOT**"}}