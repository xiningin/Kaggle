{"cell_type":{"068f3fa7":"code","a0c97695":"code","75eb66ff":"code","cb849e75":"code","e5e82493":"code","d8656c72":"code","3f6ebc95":"code","dae7ecf9":"code","86177250":"code","4b0a3a38":"code","93c6acb3":"code","8495fc10":"code","248175a5":"code","1884b75b":"code","23187a9a":"code","84a7af0d":"code","b03a0881":"code","0d29d516":"code","4e6857b0":"code","2a0cbd57":"code","62398800":"code","3e0cbe7f":"code","1fc31b6a":"code","daf408d4":"code","0684152f":"code","d966d613":"code","f0cd5586":"code","918e8502":"code","054e4772":"code","97f35449":"code","fbdde7be":"code","e72a5013":"code","f04840d6":"code","2d4e6b66":"code","258feda1":"code","eb9c5fc9":"code","e0e31a95":"code","2a41eb42":"code","51c4111d":"code","4e2364f3":"code","61db5e00":"code","ef1b9e90":"code","4f2ef5c4":"code","92d14c23":"code","6c4e10e3":"code","c544329a":"code","cc4faaad":"code","736664ab":"code","497732cb":"markdown","5d48a268":"markdown","ff20830e":"markdown","c76ece81":"markdown","2e53a8d9":"markdown","3bfd4015":"markdown","786f6a43":"markdown","007db2f0":"markdown","dca66747":"markdown","b01c04ef":"markdown","86a56ca9":"markdown","d847d722":"markdown","d6a3b9b2":"markdown","c09e9253":"markdown","041690ec":"markdown","2641cea1":"markdown","ce000c1d":"markdown","cfa88500":"markdown","6b12c3e6":"markdown","e0a04a7b":"markdown","133d5b1c":"markdown"},"source":{"068f3fa7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a0c97695":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","75eb66ff":"# local\n# df = pd.read_csv('Data\/creditcard.csv')\n\n# Kaggle\ndf = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","cb849e75":"df","e5e82493":"df.info()","d8656c72":"df.isnull().sum()","3f6ebc95":"plt.figure(figsize=(20,10))\nplt.title('Value Count of Class')\nsns.countplot(data=df, x='Class');","dae7ecf9":"df['Class'].value_counts()","86177250":"plt.figure(figsize=(20,20))\nplt.title('Heatmap of Pearson corrlation')\nsns.heatmap(data=round(df.corr(),2),annot=True);","4b0a3a38":"df.corr()[['Class']].sort_values('Class')[:-1]","93c6acb3":"plt.figure(figsize=(20,10))\nplt.title('V17 and V14 vs class')\nsns.scatterplot(data=df, x='V17',y='V14',hue='Class');","8495fc10":"plt.figure(figsize=(20,10))\nplt.title('V12, V10 vs Class')\nsns.scatterplot(data=df, x='V12',y='V10',hue='Class');","248175a5":"X = df.drop('Class', axis=1)\ny = df['Class']","1884b75b":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","23187a9a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","84a7af0d":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","b03a0881":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","0d29d516":"from warnings import filterwarnings\nfrom sklearn.metrics import classification_report\nfilterwarnings('ignore')","4e6857b0":"def fit_and_score(models, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train,y_train)\n        model_scores[name] = model.score(X_test,y_test)\n        y_pred = model.predict(X_test)\n        print(name)\n        print(classification_report(y_test, y_pred))\n        print('\\n')\n\n    model_scores = pd.DataFrame(model_scores, index=['Score']).transpose()\n    model_scores = model_scores.sort_values('Score')\n        \n    return model_scores","2a0cbd57":"models = {'LogisticRegression': LogisticRegression(max_iter=10000),\n          'KNeighborsClassifier': KNeighborsClassifier(),\n          'SVC': SVC(),\n          'DecisionTreeClassifier': DecisionTreeClassifier(),\n          'RandomForestClassifier': RandomForestClassifier(),\n          'AdaBoostClassifier': AdaBoostClassifier(),\n          'GradientBoostingClassifier': GradientBoostingClassifier(),\n          'XGBClassifier': XGBClassifier(),\n          'XGBRFClassifier': XGBRFClassifier(),\n          'LGBMClassifier':LGBMClassifier(),\n         'CatBoostClassifier': CatBoostClassifier()}","62398800":"baseline_model_scores = fit_and_score(models, X_train, X_test, y_train, y_test)","3e0cbe7f":"baseline_model_scores","1fc31b6a":"plt.figure(figsize=(20,10))\nsns.barplot(data=baseline_model_scores.sort_values('Score').T)\nplt.title('Baseline Model Precision Score')\nplt.xticks(rotation=90);","daf408d4":"sample_df = df.sample(frac=0.2,random_state=42)\nX = sample_df.drop('Class', axis=1)\ny = sample_df['Class']","0684152f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","d966d613":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","f0cd5586":"from sklearn.model_selection import RandomizedSearchCV","918e8502":"def randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_rs_scores = {}\n    model_rs_best_param = {}\n    \n    for name, model in models.items():\n        rs_model = RandomizedSearchCV(model,\n                                     param_distributions=params[name],\n                                      scoring='recall',\n                                      cv=3,\n                                     n_iter=40,n_jobs=1,\n                                     verbose=2)        \n        rs_model.fit(X_train,y_train)\n        model_rs_scores[name] = rs_model.score(X_test,y_test)\n        model_rs_best_param[name] = rs_model.best_params_\n        \n    return model_rs_scores, model_rs_best_param","054e4772":"models = {'XGBClassifier': XGBClassifier(objective='binary:logistic',eval_metric='error')}\n\nparams = {'XGBClassifier':{'eta':[0.01,0.1,0.2,0.3,0.5,0.8,0.9],\n                          'gamma': [0,1,2,5,10,50,100],\n                          'max_depth':[1,3,6,9,10,20],\n                          'lambda':[0,0.1,0.2,0.5,0.8,1],\n                          'alpha': [0,0.1,0.2,0.5,0.8,1],\n                          },\n         }","97f35449":"model_rs_scores1, model_rs_best_param1 = randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","fbdde7be":"model_rs_scores1","e72a5013":"model_rs_best_param1","f04840d6":"params = {'XGBClassifier':{'eta':[0.4,0.45,0.5,0.55,0.6,0.7],\n                          'gamma': [0],\n                          'max_depth':[2,3,4,5],\n                          'lambda':[0.3,0.4,0.5,0.6,0.7],\n                          'alpha': [0.2,0.3,0.4],\n                          },\n         }","2d4e6b66":"model_rs_scores2, model_rs_best_param2 = randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","258feda1":"model_rs_scores2","eb9c5fc9":"model_rs_best_param2","e0e31a95":"X = df.drop('Class', axis=1)\ny = df['Class']","2a41eb42":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","51c4111d":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","4e2364f3":"model = XGBClassifier(eta=0.7,max_depth=5,\n                      reg_lambda=0.5,gamma=0,alpha=0.4,\n                      objective='binary:logistic',\n                      eval_metric='error')\nmodel.fit(X_train,y_train)\ny_preds = model.predict(X_test)","61db5e00":"print(classification_report(y_test,y_preds))","ef1b9e90":"from sklearn.metrics import plot_confusion_matrix","4f2ef5c4":"plot_confusion_matrix(model,X_test,y_test)","92d14c23":"from sklearn.model_selection import cross_val_score","6c4e10e3":"def get_cv_score(model, X, y, cv=5):\n    \n    \n    cv_accuracy = cross_val_score(model,X,y,cv=cv,\n                         scoring='accuracy')\n    print(f'Cross Validaion accuracy Scores: {cv_accuracy}')\n    print(f'Cross Validation accuracy Mean Score: {cv_accuracy.mean()}')\n    \n    cv_precision = cross_val_score(model,X,y,cv=cv,\n                         scoring='precision')\n    print(f'Cross Validaion precision Scores: {cv_precision}')\n    print(f'Cross Validation precision Mean Score: {cv_precision.mean()}')\n    \n    cv_recall = cross_val_score(model,X,y,cv=cv,\n                         scoring='recall')\n    print(f'Cross Validaion recall Scores: {cv_recall}')\n    print(f'Cross Validation recall Mean Score: {cv_recall.mean()}')\n    \n    cv_f1 = cross_val_score(model,X,y,cv=cv,\n                         scoring='f1')\n    print(f'Cross Validaion f1 Scores: {cv_f1}')\n    print(f'Cross Validation f1 Mean Score: {cv_f1.mean()}')   \n    \n    cv_merics = pd.DataFrame({'Accuracy': cv_accuracy.mean(),\n                         'Precision': cv_precision.mean(),\n                         'Recall': cv_recall.mean(),\n                         'f1': cv_recall.mean()},index=[0])\n    \n    return cv_merics\n","c544329a":"cv_merics = get_cv_score(model, X_train, y_train, cv=5)","cc4faaad":"cv_merics","736664ab":"plt.figure(figsize=(20,10))\nplt.title('CV Scores')\nsns.barplot(data=cv_merics);","497732cb":"# 5. Modelling","5d48a268":"## Reading the Dataset","ff20830e":"# 2. Data\n\nData from: https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\n\n\n## Context\n\nIt is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n\n## Content\n\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\nGiven the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n\n## Update (03\/05\/2021)\n\nA simulator for transaction data has been released as part of the practical handbook on Machine Learning for Credit Card Fraud Detection - https:\/\/fraud-detection-handbook.github.io\/fraud-detection-handbook\/Chapter_3_GettingStarted\/SimulatedDataset.html. We invite all practitioners interested in fraud detection datasets to also check out this data simulator, and the methodologies for credit card fraud detection presented in the book.\n\n## Acknowledgements\n\nThe dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http:\/\/mlg.ulb.ac.be) of ULB (Universit\u00e9 Libre de Bruxelles) on big data mining and fraud detection.\nMore details on current and past projects on related topics are available on https:\/\/www.researchgate.net\/project\/Fraud-detection-5 and the page of the DefeatFraud project\n\nPlease cite the following works:\n\nAndrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n\nDal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n\nDal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n\nDal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n\nCarcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-A\u00ebl; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n\nCarcillo, Fabrizio; Le Borgne, Yann-A\u00ebl; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing\n\nBertrand Lebichot, Yann-A\u00ebl Le Borgne, Liyun He, Frederic Obl\u00e9, Gianluca Bontempi Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection, INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019\n\nFabrizio Carcillo, Yann-A\u00ebl Le Borgne, Olivier Caelen, Frederic Obl\u00e9, Gianluca Bontempi Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection Information Sciences, 2019\n\nYann-A\u00ebl Le Borgne, Gianluca Bontempi Machine Learning for Credit Card Fraud Detection - Practical Handbook ","c76ece81":"# Credit Card Fraud Detection","2e53a8d9":"## Model Imports","3bfd4015":"Going to take the following approach:\n\n1. Problem definition\n2. Data\n3. Evaluation\n4. Features\n5. Modelling\n6. Model Evaluation\n7. Experientmetion \/ Improvements","786f6a43":"We will take a closer look at the XGBClassifier\n\nXGBClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85307\n           1       0.95      0.83      0.89       136\n\n    accuracy                           1.00     85443\n    macro avg       0.97      0.92      0.94     85443\n    weighted avg       1.00      1.00      1.00     85443","007db2f0":"## Random Search CV","dca66747":"## Confusion Matrix","b01c04ef":"## Classification Report","86a56ca9":"# 3. Evaluation\n\nAs this is a classification problem, we will use the classification metics for evauluting the model","d847d722":"## Baseline Model Scores","d6a3b9b2":"we are dealling with a very in-balanced Label","c09e9253":"## Standard Imports","041690ec":"# 4. Features\n\n## Inputs \/ Features\n\n    1. Time -Number of seconds elapsed between this transaction and the first transaction in the dataset\n    \n     may be result of a PCA Dimensionality reduction to protect user identities and sensitive features(v1-v28)\n    2. V1\n    3. V2\n    4. V3\n    5. V4\n    6. V5\n    7. V6\n    8. V7\n    9. V8\n    10. V9\n    11. V10\n    12. V11\n    13. V12\n    14. V13\n    15. V14\n    16. V15\n    17. V16\n    18. V17\n    19. V18\n    20. V19\n    21. V20\n    22. V21\n    23. V22\n    24. V23\n    25. V24\n    26. V25\n    27. V26\n    28. V27\n    29. V28\n    30. Amount - Transaction amount\n    \n## Output \/ Label\n    31. Class1 for fraudulent transactions, 0 otherwise","2641cea1":"### RS Model 1","ce000c1d":"As the data is in-balance we will use the F1 scores for the scoring ","cfa88500":"## Evalution using cross-validation","6b12c3e6":"# 1. Problem Definition\n\nHow we can use various python based Machine Learning Model and the given parameters to predict Credit Card Fraud?","e0a04a7b":"# 6. Model Evalatuion ","133d5b1c":"## Data Exporation"}}