{"cell_type":{"3e383119":"code","29aa8f64":"code","c3192b82":"code","48ca7181":"code","a65ae3a5":"code","3f47a7c9":"code","54fd695f":"code","55195e5c":"code","f0cb9536":"code","b5dd3d59":"code","78a05f71":"code","39154003":"code","8751e20d":"code","04d97ba3":"code","c0f03f39":"code","b5767f36":"code","cdc28475":"code","332097a3":"code","e64b277f":"code","d436b636":"code","12abfbca":"code","88a5c483":"markdown","ff1bb289":"markdown","8f783df3":"markdown","e737faec":"markdown","9f62ab57":"markdown","8e7e8868":"markdown","35d2386a":"markdown","e5b4776c":"markdown"},"source":{"3e383119":"!pip -qq install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","29aa8f64":"!pip -qq install split-folders tqdm","c3192b82":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\n\nimport splitfolders\nimport os\nimport random\nimport shutil\n\n### Make prettier the prints ###\nfrom colorama import Fore, Style\nc_ = Fore.CYAN\nm_ = Fore.MAGENTA\nr_ = Fore.RED\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\ng_ = Fore.GREEN\nw_ = Fore.WHITE\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, Dataset\n\nprint(\"Pytorch Version: \",torch.__version__)\nprint(\"Torchvision Version \",torchvision.__version__)","48ca7181":"seed = 42\nprint(f'setting everything to seed {seed}')\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","a65ae3a5":"#https:\/\/www.pythoncentral.io\/how-to-recursively-copy-a-directory-folder-in-python\/\n\ndef copyDirectory(src, dest):\n    try:\n        shutil.copytree(src, dest)\n    # Directories are the same\n    except shutil.Error as e:\n        print('Directory not copied. Error: %s' % e)\n    # Any error saying that the directory doesn't exist\n    except OSError as e:\n        print('Directory not copied. Error: %s' % e)","3f47a7c9":"root = '..\/input\/rock-classification\/Dataset'\nfor class_name in os.listdir(root):\n    for rock_name in os.listdir(os.path.join(root, class_name)):\n        folder_path = os.path.join(os.path.join(root, class_name), rock_name)\n        copyDirectory(folder_path, f\"Dataset\/{folder_path.split('\/')[-1]}\")","54fd695f":"def del_corrupted_images(path):\n    del_count = 0\n    for folder in os.listdir(path):\n        folder_path = os.path.join(path, folder)\n        for filename in tqdm(os.listdir(folder_path)):\n            filepath = os.path.join(folder_path, filename)\n            try:\n                fileobject = open(filepath, 'rb')\n                is_ok = tf.compat.as_bytes('JFIF') in fileobject.peek(10)\n            finally:\n                fileobject.close()\n            if not is_ok:\n                del_count += 1\n                os.remove(filepath)\n    print(\"\\n\\nDeleted %d images\" % del_count)\n\ndel_corrupted_images('.\/Dataset')","55195e5c":"splitfolders.fixed(\".\/Dataset\", output=\".\/SplitDataset\", seed=1337, fixed=20, group_prefix=None, oversample=True) ","f0cb9536":"TRANSFORMS = transforms.Compose(\n                                    [transforms.RandomResizedCrop(224),\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])]\n                                )","b5dd3d59":"# Loading the datasets and plot some images from train split\ntrain_dataset = datasets.ImageFolder('.\/SplitDataset\/train',transform = TRANSFORMS)\nimage,label = train_dataset[15]\nplt.imshow(image.permute(2,1,0))\nplt.show()\nprint(label, train_dataset.classes[label])","78a05f71":"# Loading the datasets and plot some images from validation split\nval_dataset = datasets.ImageFolder('.\/SplitDataset\/val',transform = TRANSFORMS)\nimage,label = val_dataset[15]\nplt.imshow(image.permute(2,1,0))\nplt.show()\nprint(label, val_dataset.classes[label])","39154003":"print(train_dataset.classes)\nprint('\\ndataset size: ', len(train_dataset))","8751e20d":"class_names = train_dataset.classes\n\nfor i in 0, 10, 100, 200, 500:\n    img,label = train_dataset[i]\n    plt.title(f'Label: {label}, Class {class_names[label]}')\n    plt.imshow(img.permute(2,1,0))\n    plt.show()","04d97ba3":"labels = train_dataset.targets\n_,labels_count = np.unique(labels, return_counts=True)\nlabels_count","c0f03f39":"# Data Distribution plot\nplt.figure(figsize=(8, 4))\nplt.title('Data distribution')\nplt.bar(class_names, labels_count, width=.5, color = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6'])\nplt.show()","b5767f36":"#size of dataset\ndataset_size = len(train_dataset)\ndistribution_perc = 100*labels_count\/dataset_size\n\nfor class_name, count, distrib in zip(class_names,labels_count,distribution_perc):\n    print(f'{class_name} {distrib:.2f}% - {r_}{count} Images')\n    print(Style.RESET_ALL)\nprint('\\nTotal Images:',dataset_size,'Images')","cdc28475":"batch_size = 64\n\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\nvalid_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True)","332097a3":"model = models.resnext101_32x8d(pretrained=True)\n\n# view last input channels\nin_features = model.fc.in_features\n\n#lock previous layer\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Linear(in_features=2048, out_features=7)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \nmodel = model.to(device)\n\n# loss function\ncriteration = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.0001)\n\nmax_score = 0\n# param.requires_grad = False\nfor epoch in range(20):\n    print(f'\\n-----epoch {epoch+1}-----')\n    number_corect = 0\n    sum_loss = 0\n    val_cor = 0\n    model.train()\n    for datas, targets in train_loader:\n        datas = datas.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        #predict\n        outputs = model(datas)\n        #update model\n        loss = criteration(outputs, targets)\n        #update model\n        loss.backward()\n        optimizer.step()\n        #compute metrics\n        max_index = outputs.max(dim=1)[1]\n        sum_loss += loss.item()\n        number_corect += (max_index == targets.data).sum()\n\n    model.eval()\n    with torch.no_grad():\n        for datas, targets in valid_loader:\n            datas = datas.to(device)\n            targets = targets.to(device)\n            #predict\n            outputs = model(datas)\n            #compute metrics\n            max_index = outputs.max(dim=1)[1]\n            val_cor += (max_index == targets.data).sum()\n\n    #print metrics\n    loss = sum_loss \/ len(train_loader)\n    accuracy = 100.0*number_corect \/ len(train_dataset)\n    accuracy_val = 100.0*val_cor \/ len(val_dataset)\n    print(f'Loss {loss}, \\nAccuracy {accuracy}, \\nVal Accuracy {accuracy_val}')\n\n    if max_score < accuracy_val:\n        max_score = accuracy_val\n        torch.save(model.state_dict(), f'.\/model.pth')\n        print(f'{y_}Improvement in score. Model saved!')\n        print(Style.RESET_ALL)","e64b277f":"model.load_state_dict(torch.load('.\/model.pth'))","d436b636":"# reference https:\/\/discuss.pytorch.org\/t\/how-to-find-test-accuracy-after-training\/88962\ndef check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval() \n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n        \n        print(f'Got {num_correct} \/ {num_samples} with accuracy {float(num_correct)\/float(num_samples)*100:.2f}') \n    model.train()","12abfbca":"check_accuracy(valid_loader, model)","88a5c483":"# Train-Val Split","ff1bb289":"# Evaluation","8f783df3":"# Making class-wise folders ","e737faec":"# Seed Everything","9f62ab57":"# Deleting Corrupted Images","8e7e8868":"# Model","35d2386a":"# Simple Vizualization","e5b4776c":"# Importing libraries"}}