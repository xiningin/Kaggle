{"cell_type":{"2e1b2398":"code","0b563166":"code","e3f8c7d2":"code","8416504f":"code","e1080cd9":"code","78ffc5a6":"code","7baed66a":"code","335cd8b7":"code","528a32f0":"code","10e96291":"code","546d859b":"code","1f20d84e":"code","ac7b7a68":"code","92efc2f5":"code","5201661d":"code","819a72b3":"code","a202f9e0":"code","e5c31e42":"code","fe4c3901":"markdown","4975b114":"markdown","a308421d":"markdown","f556178e":"markdown","a7727bcd":"markdown","6ac919cf":"markdown","8534fb01":"markdown","9ba1c04e":"markdown","e00998f7":"markdown","a529c8c5":"markdown","3f28faad":"markdown","6e9494d5":"markdown","e0c66d3e":"markdown","12d4ef92":"markdown"},"source":{"2e1b2398":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()\n%config IPCompleter.use_jedi = False","0b563166":"# Path to the parent directory containing all the data \ndata_path = Path(\"..\/input\/nfl-health-and-safety-helmet-assignment\/\")","e3f8c7d2":"additional_images = sorted((data_path \/ \"images\").glob(\"*.jpg\"))\nadditional_images_df = pd.read_csv(data_path \/ \"image_labels.csv\")\n\nprint(\"Number of images: \", len(additional_images))\nprint(\"Number of annotations: \", len(additional_images_df))\nprint(additional_images_df.head())\nprint(\"=\"*50)\nprint(\"\\nAverage number of annotations per frame: \", len(additional_images_df) \/\/ len(additional_images))","8416504f":"additional_images_df[\"image\"] = str(data_path \/ \"images\") + \"\/\" + additional_images_df[\"image\"]\nadditional_images_df[\"right\"] = additional_images_df[\"left\"] + additional_images_df[\"width\"]\nadditional_images_df[\"bottom\"] = additional_images_df[\"top\"] + additional_images_df[\"height\"]\nadditional_images_df.head()","e1080cd9":"def plot_bboxes_on_frame(images, bbox, color=(0, 255, 0)):\n    \"\"\"Plots all the boundng boxes on a given frame.\n    \n    Args:\n        images: List of images\n        bbox: Corresposnding list of bboxes. All the bboxes corresponding\n            to an image should be provided in a single list of list of\n            dictionaries. For example:\n            [\n                [{\"left\": 100, \"top\":50, \"right\":30, \"bottom\":500}, {...}],\n                [{..}..],\n                ...\n            ]\n    \"\"\"\n    \n    if len(images) != len(bbox):\n        raise ValueError(\"Number of images and corresponding bboxes should be same\")\n        \n    for i in range(len(bbox)):\n        boxes = bbox[i]\n        for box in boxes:\n            cv2.rectangle(images[i], (box[\"left\"], box[\"top\"]), (box[\"right\"], box[\"bottom\"]), color, 2)    \n    return images\n\n\ndef get_bbox(df, idx, cols=[\"left\", \"right\", \"top\", \"bottom\"]):\n    \"\"\"Given an index, return a dictionary of box cooredinates.\n    \n    Args:\n        df: Dataframe containing the information\n        idx: The index to pick the data from\n        cols: The columns to extract the data\n    Returns:\n        A dictionary containing cooredinates of the bbox\n    \"\"\"\n    \n    box = {}\n    for col in cols:\n        box[col] = df[col][idx]\n    return box\n\n\ndef get_all_boxes(df, indices, cols=[\"left\", \"right\", \"top\", \"bottom\"]):\n    \"\"\"Gathers all bboxes corresponding to an image.\n    \n    Args:\n        df: Dataframe containing the information\n        indices: The indices to pick the data from\n        cols: The columns to extract the data\n    Returns:\n        A list of bboxes\n    \"\"\"\n    bbox = [get_bbox(df, idx) for idx in indices]\n    return bbox\n\ndef get_all_indices_of_image(df, image_path):\n    \"\"\"Find all the indices corresponding to an image.\n    \n    Args:\n        df: Dataframe containing the information\n        image_path: The image_path for which indices are required\n    Returns:\n        A list of indices\n    \"\"\"\n    \n    indices = df.index[df[\"image\"]==image_path]\n    return indices.tolist()\n\n\n\ndef read_images_and_bbox(df, images_path):\n    \"\"\"Read images and bbox information\"\"\"\n    images = []\n    bbox = []\n    \n    for i, img_path in enumerate(images_path):\n        indices = get_all_indices_of_image(df, img_path)\n        boxes = get_all_boxes(df, indices)\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        images.append(img)\n        bbox.append(boxes)\n        \n    return images, bbox","78ffc5a6":"# Get the list of all unique images\nall_images = list(set(additional_images_df[\"image\"]))\n\n# Select how many rows and columns you want in the subplots\nnum_rows = 5\nnum_cols = 2\n\n# Select the desired number of images randomly\nselected_images = np.random.choice(all_images, size=num_rows*num_cols)\n\n# Read the images and get box coordinates\nimages, boxes = read_images_and_bbox(df=additional_images_df, images_path=selected_images)\n\n# Draw the boxes on the images\nimages_with_boxes = plot_bboxes_on_frame(images, boxes)\n\n\n# Visualize the images\n_, ax = plt.subplots(num_rows, num_cols, figsize=(20, 22))\n\nfor i in range(num_rows*num_cols):\n    title = selected_images[i].split(\"\/\")[-1]\n    ax[i \/\/ num_cols][i % num_cols].imshow(images_with_boxes[i])\n    ax[i \/\/ num_cols][i % num_cols].axis(\"off\")\n    ax[i \/\/ num_cols][i % num_cols].set_title(title)\n\nplt.tight_layout()\nplt.show()","7baed66a":"def get_image_number(img_path):\n    img_num = img_path.split(\"\/\")[-1]\n    img_num = img_num.split(\"_\")[0]\n    return img_num\n\ndef get_frame_view(img_path):\n    img_view = img_path.split(\"\/\")[-1]\n    if \"Endzone\" in img_view:\n        return \"Endzone\"\n    elif \"Sideline\" in img_view:\n        return \"Sideline\"\n    else:\n        return \"Unknown\"","335cd8b7":"additional_images_df[\"image_no\"] = additional_images_df[\"image\"].apply(get_image_number)\nadditional_images_df[\"frame_view\"] = additional_images_df[\"image\"].apply(get_frame_view)\nadditional_images_df.head()","528a32f0":"plt.figure(figsize=(8, 5))\nsns.countplot(data=additional_images_df, x=\"frame_view\")\nplt.show()","10e96291":"# So, we have more sideline views compared to endzone views, but by how much\nadditional_images_df[\"frame_view\"].value_counts()","546d859b":"plt.figure(figsize=(12, 8))\nsns.countplot(data=additional_images_df, x=\"label\")\nplt.show()","1f20d84e":"def filter_df(df, filter_col, value):\n    df = df[df[filter_col]==value]\n    df = df.reset_index(drop=True)\n    return df","ac7b7a68":"def plot_samples(df, num_samples_to_plot, figsize=(20, 20)):\n    # Get the list of all unique images\n    all_images = list(set(df[\"image\"]))\n\n    # Select how many rows and columns you want in the subplots\n    num_rows = num_samples_to_plot \/\/ 2\n    num_cols = 2\n\n    # Select the desired number of images randomly\n    selected_images = np.random.choice(all_images, size=num_rows*num_cols)\n\n    # Read the images and get box coordinates\n    images, boxes = read_images_and_bbox(df=df, images_path=selected_images)\n\n    # Draw the boxes on the images\n    images_with_boxes = plot_bboxes_on_frame(images, boxes)\n\n\n    # Visualize the images\n    _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n\n    for i in range(num_rows*num_cols):\n        title = selected_images[i].split(\"\/\")[-1]\n        ax[i \/\/ num_cols][i % num_cols].imshow(images_with_boxes[i])\n        ax[i \/\/ num_cols][i % num_cols].axis(\"off\")\n        ax[i \/\/ num_cols][i % num_cols].set_title(title)\n\n    plt.tight_layout()\n    plt.show()","92efc2f5":"# We can use groupby here but I will do it manually because\n# I would be using these subsets for further analysis\n\nhelmet_df = filter_df(additional_images_df, \"label\", \"Helmet\")\nhelmet_blurred_df = filter_df(additional_images_df, \"label\",\"Helmet-Blurred\")\nhelmet_difficult_df = filter_df(additional_images_df, \"label\", \"Helmet-Difficult\")\nhelmet_sideline_df = filter_df(additional_images_df, \"label\", \"Helmet-Sideline\")\nhelmet_partial_df =  filter_df(additional_images_df, \"label\", \"Helmet-Partial\")","5201661d":"plot_samples(helmet_blurred_df, num_samples_to_plot=10)","819a72b3":"plot_samples(helmet_difficult_df, num_samples_to_plot=10)","a202f9e0":"plot_samples(helmet_partial_df, num_samples_to_plot=10)","e5c31e42":"plot_samples(helmet_partial_df, num_samples_to_plot=10)","fe4c3901":"I would consider `partial-helmet` and the `difficult-helmet` as the same category because these are really hard to spot and differentiate\n\n*To be continued..*","4975b114":"We will make two changes in this dataframe:\n1. We will modify the image path to the actual image path\n2. We will add `right` and `bottom` coordinates of the box","a308421d":"## Partial Helmets","f556178e":"## Blurred Helmets","a7727bcd":"# Visualizing the data","6ac919cf":"Hello Kagglers! So many interesting competitons but not so much of time. With the amazing results from last year, The National Football League (NFL) has asked Kagglers to help them on one more task. This time the NFL wants to assign specific players to each helmet, which would help accurately identify each player's \u201cexposures\u201d throughout a football play.\n\nTo aid with helmet detection, the NFL has also provided an ancillary dataset of images showing helmets with labeled bounding boxes. These files are located in `images` directory and the `bounding boxes` information is in `image_labels.csv`\n\nOur goal is to analyze this dataset, and se how can we make the best use of it for additional training. Let's jump in","8534fb01":"## Sideline Helmets","9ba1c04e":"## Difficult Helmets","e00998f7":"# Views in frames\n\nGiven that the images are from `endzone` and `sideline`, let's try to group and align these images and see if this data can be used in a much smarter way","a529c8c5":"The `difficult` helmet are actually hard to spot. This will require a very good object detector that can detect object at such small scale","3f28faad":"# Different kind of helmets\n\nAs we saw above that the helmets have been annotated in five different ways. We will plot a few samples for each of these type of helmets to get an idea why are they annotated in this fashion","6e9494d5":"## Supplementary Image Data\n\n1. Additional images provided for making a good helmet detector. Comparable to train\/test distribution\n2. Load these images first, check how the images look like and how the labels are provided in images_labels.csv","e0c66d3e":"# How many labels are there?\n\nIt looks like we have more than one class in this data. Let's take a look","12d4ef92":"# Distribution of `views` "}}