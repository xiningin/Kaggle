{"cell_type":{"b80473af":"code","972a57ff":"code","3582b5d9":"code","7d185636":"code","9288a582":"code","6fe62051":"code","9fee31a3":"code","2ffddb78":"code","2ce55eb6":"code","9f474a16":"code","3777a804":"code","5d92bd87":"code","18f8f5dc":"code","19baed99":"code","518d80cc":"code","4f0d54ce":"markdown","5021d90e":"markdown","5e5186d6":"markdown"},"source":{"b80473af":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","972a57ff":"def get_mae(max_leaf_nodes,X_train,X_val,y_test,y_val):\n    model = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes,random_state=1)\n    model.fit(X_train,y_train)\n    prediction = model.predict(X_val)\n    mae = mean_absolute_error(prediction,y_val)\n    return mae","3582b5d9":"df = pd.read_csv(\"..\/input\/winequalityredcsv\/winequality-red.csv\")","7d185636":"df.head()","9288a582":"df.describe()","6fe62051":"df.corr()","9fee31a3":"OUTLIER_RANGE = 3\narray = []\nfor column in df:\n    if column != 'quality':\n        std = df[column].std()\n        mean = df[column].mean()\n        n1 = mean+(OUTLIER_RANGE*std)\n        n2 = mean-(OUTLIER_RANGE*std)\n        count = 0\n        for number in df[column]:\n            if not(number>n2 and number<n1):\n                array.append(count)\n            count+=1\n\narray = list(set(array))\n\nnew_df = df.drop(array)","2ffddb78":"new_df['quality'] = np.where(new_df['quality']>6,1,0)\nnew_df['quality'].value_counts()","2ce55eb6":"new_df.describe()","9f474a16":"y = new_df['quality']\nX = new_df.drop(['quality'],axis=1)\n\nselect = SelectKBest(score_func=chi2,k=8)\nz = select.fit_transform(X,y)\n\nX = preprocessing.scale(z)\n\nX_train, X_val, y_train, y_val = train_test_split(X,y)","3777a804":"temp_array = []\nmin1 = 100000000\nfor i in range(2,100):\n    mae = get_mae(i,X_train,X_val,y_train,y_val)\n    temp_array.append(mae)\n    if mae < min1:\n        min1 = mae\n        minI = i\n    \nprint(min(temp_array),minI) #minI being the maximum leaf nodes for the dt","5d92bd87":"np_temp_array = np.array(temp_array)\nsns.lineplot(data=np_temp_array)","18f8f5dc":"tree = DecisionTreeClassifier(max_leaf_nodes=minI,random_state=42)\ntree.fit(X_train,y_train)\n\nforest = RandomForestClassifier(random_state=42)\nforest.fit(X_train,y_train)","19baed99":"predictions = tree.predict(X_val)\npredictions_forest = forest.predict(X_val)\n\nmae = mean_absolute_error(predictions,y_val)\nmae_forest = mean_absolute_error(predictions_forest,y_val)\n\nprint(\"Mae: {}\\nMae with forest: {}\".format(round(mae,4),round(mae_forest,4)))","518d80cc":"print(\"The accuracy for Decision Tree model is {}%\".format(tree.score(X_val,y_val)*100))\nprint(\"The accuracy for Random Forest model is {}%\".format(forest.score(X_val,y_val)*100))","4f0d54ce":"**Finding the outliers in the entire dataset based on the empirical rule**","5021d90e":"**Separating those with quality more than 6 to be good and rest to be bad**","5e5186d6":"**Finding the max leaf nodes for the decision tree**"}}