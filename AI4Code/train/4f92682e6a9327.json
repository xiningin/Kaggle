{"cell_type":{"2bde6bc3":"code","526a1044":"code","58d2593a":"code","f03ded67":"code","d1e6c95e":"code","8d8c18d7":"code","14ee5fb2":"code","933acb0b":"code","d42c57a2":"code","77f08289":"code","f14bfc90":"code","f88822b6":"code","807d1cc0":"code","7f6430b3":"code","eb0cf8ba":"code","6223cfdf":"code","943a4995":"code","7194d2a8":"code","9b9be592":"code","878fee77":"code","28d2c71a":"code","c1d706cf":"code","b196dd0e":"code","62a02819":"code","94341cd5":"code","1c832a3b":"code","07b4b5f2":"code","70de1937":"code","b78d1fdb":"code","9e890a52":"code","ad4885fc":"code","5c723f29":"markdown","e0f20399":"markdown"},"source":{"2bde6bc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","526a1044":"X_train = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\nX_test = pd.read_csv('..\/input\/mobile-price-classification\/test.csv')","58d2593a":"X_train.info()","f03ded67":"\nX_test.drop('id',inplace=True,axis=1)\nX_test.info()","d1e6c95e":"print(X_train.shape,X_test.shape)","8d8c18d7":"X_test.describe()","14ee5fb2":"print(X_train.shape,X_test.shape)","933acb0b":"Y_train = X_train['price_range']\n\nrel = X_train.corr()\n\nX_train.drop('price_range',axis=1,inplace=True)","d42c57a2":"rel","77f08289":"import seaborn as sns\nrel.shape","f14bfc90":"sns.heatmap(rel)","f88822b6":"# X_train = X_train.drop('price_range',axis=1)","807d1cc0":"rel = abs(rel)\nrel = rel['price_range'].sort_values(ascending=False)\nrel = rel[1:]","7f6430b3":"rel","eb0cf8ba":"useful_feature = rel[0:9]\nuseful_feature = useful_feature.index\nuseful_feature","6223cfdf":"X_test.columns","943a4995":"X_train = X_train[useful_feature]\nX_test = X_test[useful_feature]\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","7194d2a8":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X_train,Y_train,test_size= 0.3,random_state=101)","9b9be592":"from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n\nimport xgboost as xgb","878fee77":"\nlr = GradientBoostingClassifier()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\nprint(str(accuracy_score(y_test,pred)*100)+ \"% with gradient booster classifier\")\n\n\nlr = xgb.XGBClassifier()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\nprint(str(accuracy_score(y_test,pred)*100) + \"% with xgbooster classifier\")\n\nlr = RandomForestClassifier()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\nprint(str(accuracy_score(y_test,pred)*100) + \"% with random forest classifier\")","28d2c71a":"print(y_train.shape,y_test.shape)\nprint(x_train.shape,x_test.shape)\n\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)\n\nprint(y_train.shape,y_test.shape)\nprint(x_train.shape,x_test.shape)","c1d706cf":"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nhot = OneHotEncoder()\ny_train = hot.fit_transform(y_train).toarray()\ny_test = hot.fit_transform(y_test).toarray()\nprint(y_train.shape,y_test.shape)","b196dd0e":"y_train = np.array(y_train)\ny_test = np.array(y_test)\nprint(x_train.shape)","62a02819":"model = Sequential()\nmodel.add(Dense(8,input_shape = (x_train.shape[1],),activation='relu'))\n# model.add(Dropout(0.2))\nmodel.add(Dense(6,activation='relu'))\n# model.add(Dropout(0.2))\n# model.add(Dense(12,activation='relu'))\n\nmodel.add(Dense(4,activation='softmax'))\n\nprint(x_train.shape,y_train.shape)\nprint(x_test.shape,y_test.shape)","94341cd5":"model.summary()","1c832a3b":"model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","07b4b5f2":"hist = model.fit(x_train,y_train,epochs=150,validation_data = (x_test,y_test),batch_size=64,shuffle=True)","70de1937":"model.evaluate(x_test,y_test)","b78d1fdb":"import matplotlib.pyplot as plt\nhist = hist.history","9e890a52":"plt.style.use('seaborn')\nplt.plot(hist['accuracy'],label = 'Training Accuracy')\nplt.plot(hist['val_accuracy'],label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","ad4885fc":"plt.style.use('seaborn')\nplt.plot(hist['loss'],label = 'Training Loss')\nplt.plot(hist['val_loss'],label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","5c723f29":"**Thank You !!!!**","e0f20399":"**Using Artifical Neural Network**"}}