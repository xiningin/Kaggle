{"cell_type":{"41400ca7":"code","3cecdda1":"code","6e09e68d":"code","40b1cc4c":"code","6cf15ef3":"code","1255bc81":"code","d0bc515f":"code","66262b5d":"code","002d6b30":"code","916c1310":"code","3957e4ad":"code","a1a27425":"code","b3698607":"code","bb286c7a":"code","a067c269":"code","cc76a29b":"code","a77462a3":"code","3baee761":"code","1c159f76":"code","b70cf44f":"code","ef9ee96a":"code","977356d2":"code","776d909c":"code","d156284d":"code","76736364":"code","9710affd":"code","41c90890":"code","c28b2fce":"code","8a28991b":"code","ff070db6":"code","537f1100":"code","f9941613":"code","915dcf41":"code","53c9aa7a":"code","bbaf0391":"code","5f40ba66":"code","e0791f14":"code","6e65f673":"code","d1c2424e":"markdown","f2bfa24f":"markdown","424e9bfa":"markdown","d85b203a":"markdown","6b0e1b64":"markdown","071b2494":"markdown","5bd99e26":"markdown","8ada0901":"markdown","9cbce183":"markdown","2f968653":"markdown","98179194":"markdown","3fbf9c82":"markdown","e26d222f":"markdown","eae1eb6d":"markdown"},"source":{"41400ca7":"import pandas as pd\nimport io\nimport requests\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport gc\nimport random\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics","3cecdda1":"# Import dataset\n\ndataset = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\ndataset.shape","6e09e68d":"dataset.head()","40b1cc4c":"dataset.columns","6cf15ef3":"## Convert ID\n\ndataset[\"id\"] = dataset[\"Patient ID\"].values\ndataset = dataset.drop(columns=[\"Patient ID\"])","1255bc81":"## Convert Target\n\ndataset['target'] = np.where(dataset['SARS-Cov-2 exam result']=='negative',0,1)\ndataset['target'] = dataset['target'].astype(np.float64)\ndataset = dataset.drop(columns=[\"SARS-Cov-2 exam result\"])","d0bc515f":"#### Generate Metadata Function\n\ndef GenerateMetadata(train,var_id,targetname): \n    print('Running metadata...')\n    \n    for ids in var_id:\n        print('Renaming ---> ', ids,'to ---> ', 'ID_'+ids)\n        train = train.rename(columns={ids: 'ID_'+ids})\n   \n    train = train.rename(columns={targetname: 'target'})\n    # Verifying type of columns\n    t = []\n    for i in train.columns:\n            t.append(train[i].dtype)\n\n    n = []\n    for i in train.columns:\n            n.append(i)\n\n    aux_t = pd.DataFrame(data=t,columns=[\"Type\"])\n    aux_n = pd.DataFrame(data=n,columns=[\"Features\"])\n    df_tipovars = pd.merge(aux_n, aux_t, left_index=True, right_index=True) \n\n    data = []\n    for f in train.columns:\n        # Defining variable roles:\n        if f == 'target':\n            role = 'target'\n        elif f[0:3] == 'ID_':\n            role = 'id'\n        else:\n            role = 'input'\n\n        # Defining variable types: nominal, ordinal, binary ou interval\n        if f == 'target':\n            level = 'binary'\n        if train[f].dtype == 'object' or f == 'id': \n            level = 'nominal'\n        elif train[f].dtype in ['float','float64'] :\n            level = 'interval'\n        elif train[f].dtype in ['int','int64','int32'] :\n            level = 'ordinal'\n        else:\n            level = 'NA'\n\n        # Remove IDs\n        keep = True\n        if f[0:3] == 'ID_':\n            keep = False\n\n        #  Defining the type of input table variables\n        dtype = train[f].dtype\n\n        # Metadata list\n        f_dict = {\n            'Features': f,\n            'Role': role,\n            'Level': level,\n            'Keep': keep,\n            'Type': dtype\n        }\n        data.append(f_dict)\n\n    meta = pd.DataFrame(data, columns=['Features', 'Role', 'Level', 'Keep', 'Type'])\n\n    # Cardinality of columns\n    card = []\n\n    v = train.columns\n    for f in v:\n        dist_values = train[f].value_counts().shape[0]\n        f_dict = {\n                'Features': f,\n                'Cardinality': dist_values\n            }\n        card.append(f_dict)\n\n    card = pd.DataFrame(card, columns=['Features', 'Cardinality'])\n\n    metadados_train = pd.merge(meta, card, on='Features')\n    print('Metadada successfully completed')\n    return metadados_train,train ","66262b5d":"lista_ids = ['id']\ntargetname = 'target'\nmetadados,abt_desenv_01 = GenerateMetadata(dataset,lista_ids,targetname)","002d6b30":"metadados","916c1310":"metadados['Type'].unique()","3957e4ad":"### Convert numbers to \"float64\" and categorical to \"str\"\n\nnumeric_list = metadados[((metadados.Level  == 'ordinal')|(metadados.Level == 'interval')) & (metadados.Role == 'input')]\ncategory_list = metadados[(metadados.Level  == 'nominal') & (metadados.Role == 'input')]\n\nnumeric_list = list(numeric_list['Features'].values)\ncategory_list = list(category_list['Features'].values)","a1a27425":"abt_desenv_02 = abt_desenv_01[numeric_list].astype(np.float64)\nabt_desenv_03 = pd.merge(abt_desenv_02, abt_desenv_01[category_list].astype(np.str), left_index=True, right_index=True)\nabt_desenv_03.shape","b3698607":"abt_desenv_03['ID_id'] = abt_desenv_01['ID_id'].values\nabt_desenv_03['target'] = abt_desenv_01['target'].values\nabt_desenv_03.shape","bb286c7a":"abt_desenv_03.head()","a067c269":"def DataPrep(metadados,input_df,var_id,targetname):\n    \n    print('Starting data preparation ...')\n    \n    #-------------- Handling missing of numeric columns -----------------\n    input_df.rename(columns={var_id: 'id', targetname: 'target'}, inplace=True)\n    df_00 = input_df\n    targetname = 'target'\n    print('Executing')\n    \n    #--------- Numeric Features --------------------\n    vars_numericas_df = metadados[((metadados.Level  == 'ordinal')|(metadados.Level == 'interval')) & (metadados.Role == 'input')]\n    lista_vars_numericas = list(vars_numericas_df['Features'])\n    df01 = df_00[lista_vars_numericas]\n    df01 = df01.fillna(0)\n    df01 = df01.round(4)\n    \n    print('Missings done')\n\n    #--------- Nominal Features - Low Cardinality --------------------\n    vars_char_baix_cardin_df = metadados[(metadados.Level  == 'nominal') & (metadados.Role == 'input') & (metadados.Cardinality <= 50)]\n    lista_char_baix_cardin_df = list(vars_char_baix_cardin_df['Features'])\n    \n    df_00[lista_char_baix_cardin_df].apply(lambda x: x.fillna(x.mode, inplace=True))\n    df02 = df_00[lista_char_baix_cardin_df]\n    \n    df03 = pd.get_dummies(df02,columns=lista_char_baix_cardin_df,drop_first=True,\n                          prefix=lista_char_baix_cardin_df,prefix_sep='_')\n    print('Dummifications done')    \n    \n    #--------- Nominal Features - High Cardinality --------------------\n    vars_char_alta_cardin_df = metadados[(metadados.Level  == 'nominal') & (metadados.Role == 'input') & (metadados.Cardinality > 50)]\n    lista_char_alta_cardin_df = list(vars_char_alta_cardin_df['Features'])\n    \n    df_00[lista_char_alta_cardin_df].apply(lambda x: x.fillna(x.mode, inplace=True)) \n    df04 = df_00[lista_char_alta_cardin_df]\n\n    def MultiLabelEncoder(columnlist,dataframe):\n        for i in columnlist:\n            labelencoder_X=LabelEncoder()\n            dataframe[i]=labelencoder_X.fit_transform(dataframe[i])\n\n    MultiLabelEncoder(lista_char_alta_cardin_df,df04)\n    print('Label Encodings done')\n    \n    #---------- Checking IDs -----------------------\n    vars_ids_df = metadados[(metadados.Role  == 'id')]\n    lista_ids = list(vars_ids_df['Features'])\n\n    df1_3 = pd.merge(df01, df03, left_index=True, right_index=True)\n    df1_3_4 = pd.merge(df1_3, df04, left_index=True, right_index=True)\n    \n    lista_vars_keep = lista_ids + [targetname]\n    \n    df_out = pd.merge(input_df[lista_vars_keep], df1_3_4, left_index=True, right_index=True)    \n    \n    print('Data Preparation Sucess')\n    \n    return df_out","cc76a29b":"abt_desenv_04 = DataPrep(metadados, abt_desenv_03,'id','target')\nabt_desenv_04.shape","a77462a3":"abt_desenv_04.head()","3baee761":"abt_desenv_04.isnull().sum()","1c159f76":"df_to_select = abt_desenv_04.drop(columns=['ID_id'])","b70cf44f":"Y = df_to_select['target']\nX = df_to_select.drop(columns='target', axis=1)","ef9ee96a":"correlated_features = set()\ncorrelation_matrix = X.corr()\n\nfor i in range(len(correlation_matrix.columns)):\n    for j in range(i):\n        if abs(correlation_matrix.iloc[i, j]) > 0.875:\n            colname = correlation_matrix.columns[i]\n            correlated_features.add(colname)","977356d2":"correlated_features","776d909c":"X = X.drop(columns=correlated_features)","d156284d":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\n\nrfc = RandomForestClassifier(n_estimators=50, max_depth=5, n_jobs=10, random_state=12345)\nrfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(15), scoring='accuracy')\nrfecv.fit(X, Y)","76736364":"plt.figure(figsize=(16, 9))\nplt.title('Recursive Feature Elimination with Cross-Validation - Random Forest', fontsize=18, fontweight='bold', pad=20)\nplt.xlabel('Number of features selected', fontsize=14, labelpad=20)\nplt.ylabel('% Correct Classification', fontsize=14, labelpad=20)\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='#303F9F', linewidth=3)\n\nplt.show(), print('Optimal number of features: {}'.format(rfecv.n_features_))","9710affd":"rfecvcv_cols = X.drop(X.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)\n\ndf_rfecv = pd.DataFrame()\ndf_rfecv['attr'] = X.columns\ndf_rfecv['importance'] = rfecv.estimator_.feature_importances_\ndf_rfecv = df_rfecv.sort_values(by='importance', ascending=False)\n\nplt.figure(figsize=(16, 14))\nplt.barh(y=df_rfecv['attr'], width=df_rfecv['importance'], color='#1976D2')\nplt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)\nplt.xlabel('Importance', fontsize=14, labelpad=20)\nplt.show()","41c90890":"rfecvcv_cols","c28b2fce":"X.columns","8a28991b":"# Split Train and Test\n\nfrom sklearn.model_selection import train_test_split\n\nexplicativas = X\nresposta = Y\n\nx_train, x_test, y_train, y_test = train_test_split(explicativas,\n                                                    resposta,\n                                                    test_size = 0.2,\n                                                    random_state = 666)","ff070db6":"# Gradient Boosting \n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nnp.random.seed(123456)\n\ngbc = GradientBoostingClassifier(loss='exponential', \n                                 learning_rate=0.05,\n                                 n_estimators=500, \n                                 subsample=1.0,\n                                 random_state=123456)\n\ngbc.fit(x_train, y_train)\n\n# Train\ny_pred_gbc_train = gbc.predict(x_train)\ny_score_gbc_train = gbc.predict_proba(x_train)[:,1]\n\n# Test\ny_pred_gbc_test = gbc.predict(x_test)\ny_score_gbc_test = gbc.predict_proba(x_test)[:,1]","537f1100":"# 1) Accuracy\nfrom sklearn.metrics import accuracy_score\n\n#Train\nacc_gbc_train = round(accuracy_score(y_pred_gbc_train, y_train) * 100, 2)\n\n#Test\nacc_gbc_test = round(accuracy_score(y_pred_gbc_test, y_test) * 100, 2)\n\n# 2) AUC ROC and Gini\nfrom sklearn.metrics import roc_curve, auc\n\n# Train\nfpr_gbc_train, tpr_gbc_train, thresholds = roc_curve(y_train, y_score_gbc_train)\nroc_auc_gbc_train = 100*round(auc(fpr_gbc_train, tpr_gbc_train), 2)\ngini_gbc_train = 100*round((2*roc_auc_gbc_train\/100 - 1), 2)\n\n# Test\nfpr_gbc_test, tpr_gbc_test, thresholds = roc_curve(y_test, y_score_gbc_test)\nroc_auc_gbc_test = 100*round(auc(fpr_gbc_test, tpr_gbc_test), 2)\ngini_gbc_test = 100*round((2*roc_auc_gbc_test\/100 - 1), 2)\n\n\n# 3) ROC Curve graph\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(12,6))\n\nplt.plot(fpr_gbc_train, tpr_gbc_train, color='blue',lw=2, label='ROC (Train = %0.0f)' % roc_auc_gbc_train)\nplt.plot(fpr_gbc_test, tpr_gbc_test, color='green',lw=2, label='ROC (Test = %0.0f)' % roc_auc_gbc_test)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive', fontsize=14)\nplt.ylabel('True Positive', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.legend(fontsize=20) \nplt.title('ROC Curve - Gradient Boosting - Covid19', fontsize=22)\nplt.show()\n\nprint('Accuracy, Gini and ROC Curve Area (Train): ',acc_gbc_train, gini_gbc_train, roc_auc_gbc_train)\nprint('Accuracy, Gini and ROC Curve Area (Test): ',acc_gbc_test, gini_gbc_test, roc_auc_gbc_test)","f9941613":"# XG Boost\n\nimport xgboost as xgb\n\nnp.random.seed(123456)\n\nxgb = xgb.XGBClassifier(loss='exponential',\n                        learning_rate=0.05,\n                        n_estimators=500,\n                        subsample=1.0,\n                        random_state=123456)\n\nxgb.fit(x_train, y_train)\n\n# Train\ny_pred_xgb_train = xgb.predict(x_train)\ny_score_xgb_train = xgb.predict_proba(x_train)[:,1]\n\n# Test\ny_pred_xgb_test = xgb.predict(x_test)\ny_score_xgb_test = xgb.predict_proba(x_test)[:,1]","915dcf41":"# 1) Accuracy\nfrom sklearn.metrics import accuracy_score\n\n#Train\nacc_xgb_train = round(accuracy_score(y_pred_xgb_train, y_train) * 100, 2)\n\n#Test\nacc_xgb_test = round(accuracy_score(y_pred_xgb_test, y_test) * 100, 2)\n\n# 2) AUC ROC and Gini\nfrom sklearn.metrics import roc_curve, auc\n\n# Train\nfpr_xgb_train, tpr_xgb_train, thresholds = roc_curve(y_train, y_score_xgb_train)\nroc_auc_xgb_train = 100*round(auc(fpr_xgb_train, tpr_xgb_train), 2)\ngini_xgb_train = 100*round((2*roc_auc_xgb_train\/100 - 1), 2)\n\n# Test\nfpr_xgb_test, tpr_xgb_test, thresholds = roc_curve(y_test, y_score_xgb_test)\nroc_auc_xgb_test = 100*round(auc(fpr_xgb_test, tpr_xgb_test), 2)\ngini_xgb_test = 100*round((2*roc_auc_xgb_test\/100 - 1), 2)\n\n\n# 3) ROC Curve graph\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(12,6))\n\nplt.plot(fpr_xgb_train, tpr_xgb_train, color='blue',lw=2, label='ROC (Train = %0.0f)' % roc_auc_xgb_train)\nplt.plot(fpr_xgb_test, tpr_xgb_test, color='green',lw=2, label='ROC (Test = %0.0f)' % roc_auc_xgb_test)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive', fontsize=14)\nplt.ylabel('True Positive', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.legend(fontsize=20) \nplt.title('ROC Curve - XG Boost - Covid19', fontsize=22)\nplt.show()\n\nprint('Accuracy, Gini and ROC Curve Area (Train): ',acc_xgb_train, gini_xgb_train, roc_auc_xgb_train)\nprint('Accuracy, Gini and ROC Curve Area (Test): ',acc_xgb_test, gini_xgb_test, roc_auc_xgb_test)","53c9aa7a":"# Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(123456)\n\nrndforest = RandomForestClassifier(n_estimators=30,\n                                   criterion='gini',\n                                   max_depth=10,\n                                   min_samples_split=2, \n                                   min_samples_leaf=1,\n                                   n_jobs=100,\n                                   random_state=123456)\n\nrndforest.fit(x_train, y_train)\n\n# Train\ny_pred_rndforest_train = rndforest.predict(x_train)\ny_score_rndforest_train = rndforest.predict_proba(x_train)[:,1]\n\n# Test\ny_pred_rndforest_test = rndforest.predict(x_test)\ny_score_rndforest_test = rndforest.predict_proba(x_test)[:,1]","bbaf0391":"# 1) Accuracy\nfrom sklearn.metrics import accuracy_score\n\n#Train\nacc_rndforest_train = round(accuracy_score(y_pred_rndforest_train, y_train) * 100, 2)\n\n#Test\nacc_rndforest_test = round(accuracy_score(y_pred_rndforest_test, y_test) * 100, 2)\n\n# 2) AUC ROC and Gini\nfrom sklearn.metrics import roc_curve, auc\n\n# Train\nfpr_rndforest_train, tpr_rndforest_train, thresholds = roc_curve(y_train, y_score_rndforest_train)\nroc_auc_rndforest_train = 100*round(auc(fpr_rndforest_train, tpr_rndforest_train), 2)\ngini_rndforest_train = 100*round((2*roc_auc_rndforest_train\/100 - 1), 2)\n\n# Test\nfpr_rndforest_test, tpr_rndforest_test, thresholds = roc_curve(y_test, y_score_rndforest_test)\nroc_auc_rndforest_test = 100*round(auc(fpr_rndforest_test, tpr_rndforest_test), 2)\ngini_rndforest_test = 100*round((2*roc_auc_rndforest_test\/100 - 1), 2)\n\n\n# 3) ROC Curve graph\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(12,6))\n\nplt.plot(fpr_rndforest_train, tpr_rndforest_train, color='blue',lw=2, label='ROC (Train = %0.0f)' % roc_auc_rndforest_train)\nplt.plot(fpr_rndforest_test, tpr_rndforest_test, color='green',lw=2, label='ROC (Test = %0.0f)' % roc_auc_rndforest_test)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive', fontsize=14)\nplt.ylabel('True Positive', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.legend(fontsize=20) \nplt.title('ROC Curve - Random Forest - Covid19', fontsize=22)\nplt.show()\n\nprint('Accuracy, Gini and ROC Curve Area (Train): ',acc_rndforest_train, gini_rndforest_train, roc_auc_rndforest_train)\nprint('Accuracy, Gini and ROC Curve Area (Test): ',acc_rndforest_test, gini_rndforest_test, roc_auc_rndforest_test)","5f40ba66":"# Neural Networks\n\nfrom sklearn.neural_network import MLPClassifier\n\nclf1 = MLPClassifier(solver='adam', activation='logistic', alpha=1e-3, hidden_layer_sizes=(40, 4), random_state=10)\nclf1.fit(x_train, y_train)\n# Train\ny_pred_nn1_train = clf1.predict(x_train)\ny_score_nn1_train = clf1.predict_proba(x_train)[:,1]\n# Test\ny_pred_nn1_test = clf1.predict(x_test)\ny_score_nn1_test = clf1.predict_proba(x_test)[:,1]\n\nclf2 = MLPClassifier(solver='adam', activation='tanh', alpha=1e-3, hidden_layer_sizes=(40, 4), random_state=10)\nclf2.fit(x_train, y_train)\n# Train\ny_pred_nn2_train = clf2.predict(x_train)\ny_score_nn2_train = clf2.predict_proba(x_train)[:,1]\n# Test\ny_pred_nn2_test = clf2.predict(x_test)\ny_score_nn2_test = clf2.predict_proba(x_test)[:,1]","e0791f14":"# 1) Accuracy\nfrom sklearn.metrics import accuracy_score\n\n#Train\nacc_nn1_train = round(accuracy_score(y_pred_nn1_train, y_train) * 100, 2)\n\n#Test\nacc_nn1_test = round(accuracy_score(y_pred_nn1_test, y_test) * 100, 2)\n\n# 2) AUC ROC and Gini\nfrom sklearn.metrics import roc_curve, auc\n\n# Train\nfpr_nn1_train, tpr_nn1_train, thresholds = roc_curve(y_train, y_score_nn1_train)\nroc_auc_nn1_train = 100*round(auc(fpr_nn1_train, tpr_nn1_train), 2)\ngini_nn1_train = 100*round((2*roc_auc_nn1_train\/100 - 1), 2)\n\n# Test\nfpr_nn1_test, tpr_nn1_test, thresholds = roc_curve(y_test, y_score_nn1_test)\nroc_auc_nn1_test = 100*round(auc(fpr_nn1_test, tpr_nn1_test), 2)\ngini_nn1_test = 100*round((2*roc_auc_nn1_test\/100 - 1), 2)\n\n\n# 3) ROC Curve graph\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(12,6))\n\nplt.plot(fpr_nn1_train, tpr_nn1_train, color='blue',lw=2, label='ROC (Train = %0.0f)' % roc_auc_nn1_train)\nplt.plot(fpr_nn1_test, tpr_nn1_test, color='green',lw=2, label='ROC (Test = %0.0f)' % roc_auc_nn1_test)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive', fontsize=14)\nplt.ylabel('True Positive', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.legend(fontsize=20) \nplt.title('ROC Curve - Neural Network 1 - Covid19', fontsize=22)\nplt.show()\n\nprint('Accuracy, Gini and ROC Curve Area (Train): ',acc_nn1_train, gini_nn1_train, roc_auc_nn1_train)\nprint('Accuracy, Gini and ROC Curve Area (Test): ',acc_nn1_test, gini_nn1_test, roc_auc_nn1_test)","6e65f673":"# 1) Accuracy\nfrom sklearn.metrics import accuracy_score\n\n#Train\nacc_nn2_train = round(accuracy_score(y_pred_nn2_train, y_train) * 100, 2)\n\n#Test\nacc_nn2_test = round(accuracy_score(y_pred_nn2_test, y_test) * 100, 2)\n\n# 2) AUC ROC and Gini\nfrom sklearn.metrics import roc_curve, auc\n\n# Train\nfpr_nn2_train, tpr_nn2_train, thresholds = roc_curve(y_train, y_score_nn2_train)\nroc_auc_nn2_train = 100*round(auc(fpr_nn2_train, tpr_nn2_train), 2)\ngini_nn2_train = 100*round((2*roc_auc_nn2_train\/100 - 1), 2)\n\n# Test\nfpr_nn2_test, tpr_nn2_test, thresholds = roc_curve(y_test, y_score_nn2_test)\nroc_auc_nn2_test = 100*round(auc(fpr_nn2_test, tpr_nn2_test), 2)\ngini_nn2_test = 100*round((2*roc_auc_nn2_test\/100 - 1), 2)\n\n\n# 3) ROC Curve graph\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(12,6))\n\nplt.plot(fpr_nn2_train, tpr_nn2_train, color='blue',lw=2, label='ROC (Train = %0.0f)' % roc_auc_nn2_train)\nplt.plot(fpr_nn2_test, tpr_nn2_test, color='green',lw=2, label='ROC (Test = %0.0f)' % roc_auc_nn2_test)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive', fontsize=14)\nplt.ylabel('True Positive', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.legend(fontsize=20) \nplt.title('ROC Curve - Neural Network 2 - Covid19', fontsize=22)\nplt.show()\n\nprint('Accuracy, Gini and ROC Curve Area (Train): ',acc_nn2_train, gini_nn2_train, roc_auc_nn2_train)\nprint('Accuracy, Gini and ROC Curve Area (Test): ',acc_nn2_test, gini_nn2_test, roc_auc_nn2_test)","d1c2424e":"## Contents\n\n\n### 1) Import Data\n\n\n### 2) Generate Metadata\n\n\n### 3) Fast DataPrep - Missing Treatment, Dummification and Label Encoding\n\n\n### 4) Feature Selection - Correlation Matrix and RecursiveFeatureSelection\n\n\n### 5) Training Models\n","f2bfa24f":"## 2) Generate Metadata\n\nI use a function to generate metadata of dataset. The goal here is make DataPrep easier.","424e9bfa":"## 5) Training Models\n\n- Gradient Boosting\n- XGBoost\n- Random Forest\n- Neural Network","d85b203a":"## 3) Fast DataPrep - Missing Treatment, Dummification and Label Encoding","6b0e1b64":"### 4.2) Feature Selection - RecursiveFeatureSelection\n\nI used Recursive Feature Selection to obtain a smaller number of explanatory variables.","071b2494":"### 4.1) Feature Selection - Correlation Matrix\n\nI eliminated the explanatory variables with the highest correlation with each other. I set a cutoff threshold above 0.875.","5bd99e26":"## 4) Feature Selection\n\n- Correlation Matrix\n- RecursiveFeatureSelection","8ada0901":"## 1) Import Data","9cbce183":"### 5.1) Gradient Boosting","2f968653":"### 5.2) XG Boost","98179194":"### 5.4) Neural Networks","3fbf9c82":"### 5.3) Random Forest","e26d222f":"### Importar bibliotecas","eae1eb6d":"# Diagnosis of COVID-19 and its clinical spectrum\n\n\n\n### Dataset\n\nThis dataset contains anonymized data from patients seen at the Hospital Israelita Albert Einstein, at S\u00e3o Paulo, Brazil, and who had samples collected to perform the SARS-CoV-2 RT-PCR and additional laboratory tests during a visit to the hospital.\n\nAll data were anonymized following the best international practices and recommendations. All clinical data were standardized to have a mean of zero and a unit standard deviation.\n\n### Task\n\nPredict confirmed COVID-19 cases among suspected cases. Based on the results of laboratory tests commonly collected for a suspected COVID-19 case during a visit to the emergency room, would it be possible to predict the test result for SARS-Cov-2 (positive\/negative)?"}}