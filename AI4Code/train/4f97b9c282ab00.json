{"cell_type":{"3ac23537":"code","21672e2b":"code","7a123635":"code","cd0e4509":"code","ab2657b8":"code","bfc7561e":"code","83ef06c4":"code","97f70f30":"code","7f18076d":"code","d21d2a0d":"code","02525313":"code","4f73596d":"code","ea146798":"code","b12e9865":"code","22d44bfa":"code","4d7dddf3":"code","24ad4d6d":"code","4f4c8cf0":"code","edc82b39":"code","1065e5cb":"code","3bf9222a":"code","cada906a":"code","1212119e":"code","3ae035ca":"code","d2d02a00":"code","3714c9bf":"code","4531a0fb":"code","823938e2":"code","0cc21e1b":"code","bb0405c5":"code","99b85c1c":"code","0bf6d968":"code","19f21328":"code","cb3b9a15":"code","7245788f":"code","9020e834":"code","0cd90e0b":"code","73422d9f":"code","23645318":"code","28889ec0":"code","abf488e8":"code","c2dc3461":"code","6f66f7af":"code","0da69b1f":"code","048fad8a":"code","db94c289":"code","c521c99d":"code","dd2c07a3":"code","571ee2e8":"code","7e162b6a":"code","6a7ca1f9":"code","b7b0bcdb":"code","15d9b3a6":"code","03653f06":"code","39cea800":"code","e15e8194":"code","8538d88b":"code","3a282223":"code","e4befb7f":"code","1e2c2cbe":"code","81d4f3f8":"code","4426f923":"code","7b25caa5":"markdown","8c2a46e2":"markdown","2a162355":"markdown","35254fef":"markdown","50ebfe2c":"markdown","30679a10":"markdown"},"source":{"3ac23537":"import tensorflow as tf\nimport os\nimport pandas as pd\nimport numpy as np","21672e2b":"zip_path = tf.keras.utils.get_file(\n    origin='https:\/\/storage.googleapis.com\/tensorflow\/tf-keras-datasets\/jena_climate_2009_2016.csv.zip',\n    fname='jena_climate_2009_2016.csv.zip',\n    extract=True)\ncsv_path, _ = os.path.splitext(zip_path)","7a123635":"df = pd.read_csv(csv_path)\ndf","cd0e4509":"df = df[5::6]\ndf","ab2657b8":"df.index = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\ndf[:26]","bfc7561e":"temp = df['T (degC)']\ntemp.plot()","83ef06c4":"# [[[1], [2], [3], [4], [5]]] [6]\n# [[[2], [3], [4], [5], [6]]] [7]\n# [[[3], [4], [5], [6], [7]]] [8]\n\ndef df_to_X_y(df, window_size=5):\n  df_as_np = df.to_numpy()\n  X = []\n  y = []\n  for i in range(len(df_as_np)-window_size):\n    row = [[a] for a in df_as_np[i:i+window_size]]\n    X.append(row)\n    label = df_as_np[i+window_size]\n    y.append(label)\n  return np.array(X), np.array(y)","97f70f30":"WINDOW_SIZE = 5\nX1, y1 = df_to_X_y(temp, WINDOW_SIZE)\nX1.shape, y1.shape","7f18076d":"X_train1, y_train1 = X1[:60000], y1[:60000]\nX_val1, y_val1 = X1[60000:65000], y1[60000:65000]\nX_test1, y_test1 = X1[65000:], y1[65000:]\nX_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape","d21d2a0d":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.metrics import RootMeanSquaredError\nfrom tensorflow.keras.optimizers import Adam\n\nmodel1 = Sequential()\nmodel1.add(InputLayer((5, 1)))\nmodel1.add(LSTM(64))\nmodel1.add(Dense(8, 'relu'))\nmodel1.add(Dense(1, 'linear'))\n\nmodel1.summary()","02525313":"cp1 = ModelCheckpoint('model1\/', save_best_only=True)\nmodel1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","4f73596d":"model1.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=10, callbacks=[cp1])","ea146798":"from tensorflow.keras.models import load_model\nmodel1 = load_model('model1\/')","b12e9865":"train_predictions = model1.predict(X_train1).flatten()\ntrain_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train1})\ntrain_results","22d44bfa":"import matplotlib.pyplot as plt\nplt.plot(train_results['Train Predictions'][50:100])\nplt.plot(train_results['Actuals'][50:100])","4d7dddf3":"val_predictions = model1.predict(X_val1).flatten()\nval_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val1})\nval_results","24ad4d6d":"plt.plot(val_results['Val Predictions'][:100])\nplt.plot(val_results['Actuals'][:100])","4f4c8cf0":"test_predictions = model1.predict(X_test1).flatten()\ntest_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test1})\ntest_results","edc82b39":"plt.plot(test_results['Test Predictions'][:100])\nplt.plot(test_results['Actuals'][:100])","1065e5cb":"# Part 2","3bf9222a":"from sklearn.metrics import mean_squared_error as mse\n\ndef plot_predictions1(model, X, y, start=0, end=100):\n  predictions = model.predict(X).flatten()\n  df = pd.DataFrame(data={'Predictions':predictions, 'Actuals':y})\n  plt.plot(df['Predictions'][start:end])\n  plt.plot(df['Actuals'][start:end])\n  return df, mse(y, predictions)","cada906a":"plot_predictions1(model1, X_test1, y_test1)","1212119e":"model2 = Sequential()\nmodel2.add(InputLayer((5, 1)))\nmodel2.add(Conv1D(64, kernel_size=2))\nmodel2.add(Flatten())\nmodel2.add(Dense(8, 'relu'))\nmodel2.add(Dense(1, 'linear'))\n\nmodel2.summary()","3ae035ca":"cp2 = ModelCheckpoint('model2\/', save_best_only=True)\nmodel2.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","d2d02a00":"model2.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=10, callbacks=[cp2])","3714c9bf":"model3 = Sequential()\nmodel3.add(InputLayer((5, 1)))\nmodel3.add(GRU(64))\nmodel3.add(Dense(8, 'relu'))\nmodel3.add(Dense(1, 'linear'))\nmodel3.summary()","4531a0fb":"cp3 = ModelCheckpoint('model3\/', save_best_only=True)\nmodel3.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","823938e2":"model3.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=10, callbacks=[cp3])","0cc21e1b":"temp_df = pd.DataFrame({'Temperature':temp})\ntemp_df['Seconds'] = temp_df.index.map(pd.Timestamp.timestamp)\ntemp_df","bb0405c5":"day = 60*60*24\nyear = 365.2425*day\n\ntemp_df['Day sin'] = np.sin(temp_df['Seconds'] * (2* np.pi \/ day))\ntemp_df['Day cos'] = np.cos(temp_df['Seconds'] * (2 * np.pi \/ day))\ntemp_df['Year sin'] = np.sin(temp_df['Seconds'] * (2 * np.pi \/ year))\ntemp_df['Year cos'] = np.cos(temp_df['Seconds'] * (2 * np.pi \/ year))\ntemp_df.head()","99b85c1c":"temp_df = temp_df.drop('Seconds', axis=1)\ntemp_df.head()","0bf6d968":"def df_to_X_y2(df, window_size=6):\n  df_as_np = df.to_numpy()\n  X = []\n  y = []\n  for i in range(len(df_as_np)-window_size):\n    row = [r for r in df_as_np[i:i+window_size]]\n    X.append(row)\n    label = df_as_np[i+window_size][0]\n    y.append(label)\n  return np.array(X), np.array(y)","19f21328":"X2, y2 = df_to_X_y2(temp_df)\nX2.shape, y2.shape","cb3b9a15":"X2_train, y2_train = X2[:60000], y2[:60000]\nX2_val, y2_val = X2[60000:65000], y2[60000:65000]\nX2_test, y2_test = X2[65000:], y2[65000:]\nX2_train.shape, y2_train.shape, X2_val.shape, y2_val.shape, X2_test.shape, y2_test.shape","7245788f":"temp_training_mean = np.mean(X2_train[:, :, 0])\ntemp_training_std = np.std(X2_train[:, :, 0])\n                           \ndef preprocess(X):\n  X[:, :, 0] = (X[:, :, 0] - temp_training_mean) \/ temp_training_std\n  return X","9020e834":"preprocess(X2_train)\npreprocess(X2_val)\npreprocess(X2_test)","0cd90e0b":"model4 = Sequential()\nmodel4.add(InputLayer((6, 5)))\nmodel4.add(LSTM(64))\nmodel4.add(Dense(8, 'relu'))\nmodel4.add(Dense(1, 'linear'))\n\nmodel4.summary()","73422d9f":"cp4 = ModelCheckpoint('model4\/', save_best_only=True)\nmodel4.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","23645318":"model4.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=10, callbacks=[cp4])","28889ec0":"plot_predictions1(model4, X2_test, y2_test)","abf488e8":"p_temp_df = pd.concat([df['p (mbar)'], temp_df], axis=1)\np_temp_df.head()","c2dc3461":"def df_to_X_y3(df, window_size=7):\n  df_as_np = df.to_numpy()\n  X = []\n  y = []\n  for i in range(len(df_as_np)-window_size):\n    row = [r for r in df_as_np[i:i+window_size]]\n    X.append(row)\n    label = [df_as_np[i+window_size][0], df_as_np[i+window_size][1]]\n    y.append(label)\n  return np.array(X), np.array(y)","6f66f7af":"X3, y3 = df_to_X_y3(p_temp_df)\nX3.shape, y3.shape","0da69b1f":"X3_train, y3_train = X3[:60000], y3[:60000]\nX3_val, y3_val = X3[60000:65000], y3[60000:65000]\nX3_test, y3_test = X3[65000:], y3[65000:]\nX3_train.shape, y3_train.shape, X3_val.shape, y3_val.shape, X3_test.shape, y3_test.shape","048fad8a":"p_training_mean3 = np.mean(X3_train[:, :, 0])\np_training_std3 = np.std(X3_train[:, :, 0])\n\ntemp_training_mean3 = np.mean(X3_train[:, :, 1])\ntemp_training_std3 = np.std(X3_train[:, :, 1])\n\ndef preprocess3(X):\n  X[:, :, 0] = (X[:, :, 0] - p_training_mean3) \/ p_training_std3\n  X[:, :, 1] = (X[:, :, 1] - temp_training_mean3) \/ temp_training_std3\n\ndef preprocess_output3(y):\n  y[:, 0] = (y[:, 0] - p_training_mean3) \/ p_training_std3\n  y[:, 1] = (y[:, 1] - temp_training_mean3) \/ temp_training_std3\n  return y","db94c289":"preprocess3(X3_train)\npreprocess3(X3_val)\npreprocess3(X3_test)","c521c99d":"preprocess_output3(y3_train)\npreprocess_output3(y3_val)\npreprocess_output3(y3_test)","dd2c07a3":"model5 = Sequential()\nmodel5.add(InputLayer((7, 6)))\nmodel5.add(LSTM(64))\nmodel5.add(Dense(8, 'relu'))\nmodel5.add(Dense(2, 'linear'))\n\nmodel5.summary()","571ee2e8":"cp5 = ModelCheckpoint('model5\/', save_best_only=True)\nmodel5.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","7e162b6a":"model5.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=10, callbacks=[cp5])","6a7ca1f9":"def plot_predictions2(model, X, y, start=0, end=100):\n  predictions = model.predict(X)\n  p_preds, temp_preds = predictions[:, 0], predictions[:, 1]\n  p_actuals, temp_actuals = y[:, 0], y[:, 1]\n  df = pd.DataFrame(data={'Temperature Predictions': temp_preds,\n                          'Temperature Actuals':temp_actuals,\n                          'Pressure Predictions': p_preds,\n                          'Pressure Actuals': p_actuals\n                          })\n  plt.plot(df['Temperature Predictions'][start:end])\n  plt.plot(df['Temperature Actuals'][start:end])\n  plt.plot(df['Pressure Predictions'][start:end])\n  plt.plot(df['Pressure Actuals'][start:end])\n  return df[start:end]","b7b0bcdb":"plot_predictions2(model5, X3_test, y3_test)","15d9b3a6":"def postprocess_temp(arr):\n  arr = (arr*temp_training_std3) + temp_training_mean3\n  return arr\n\ndef postprocess_p(arr):\n  arr = (arr*p_training_std3) + p_training_mean3\n  return arr","03653f06":"def plot_predictions2(model, X, y, start=0, end=100):\n  predictions = model.predict(X)\n  p_preds, temp_preds = postprocess_p(predictions[:, 0]), postprocess_temp(predictions[:, 1])\n  p_actuals, temp_actuals = postprocess_p(y[:, 0]), postprocess_temp(y[:, 1])\n  df = pd.DataFrame(data={'Temperature Predictions': temp_preds,\n                          'Temperature Actuals':temp_actuals,\n                          'Pressure Predictions': p_preds,\n                          'Pressure Actuals': p_actuals\n                          })\n  plt.plot(df['Temperature Predictions'][start:end])\n  plt.plot(df['Temperature Actuals'][start:end])\n  plt.plot(df['Pressure Predictions'][start:end])\n  plt.plot(df['Pressure Actuals'][start:end])\n  return df[start:end]","39cea800":"post_processed_df = plot_predictions2(model5, X3_test, y3_test)\npost_processed_df","e15e8194":"start, end = 0, 100\nplt.plot(post_processed_df['Temperature Predictions'][start:end])\nplt.plot(post_processed_df['Temperature Actuals'][start:end])","8538d88b":"plt.plot(post_processed_df['Pressure Predictions'][start:end])\nplt.plot(post_processed_df['Pressure Actuals'][start:end])","3a282223":"model6 = Sequential()\nmodel6.add(InputLayer((7, 6)))\nmodel6.add(LSTM(32, return_sequences=True))\nmodel6.add(LSTM(64))\nmodel6.add(Dense(8, 'relu'))\nmodel6.add(Dense(2, 'linear'))\n\nmodel6.summary()","e4befb7f":"cp6 = ModelCheckpoint('model6\/', save_best_only=True)\nmodel6.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","1e2c2cbe":"model6.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=10, callbacks=[cp6])","81d4f3f8":"model7 = Sequential()\nmodel7.add(InputLayer((7, 6)))\nmodel7.add(Conv1D(64, kernel_size=2, activation='relu'))\nmodel7.add(Flatten())\nmodel7.add(Dense(8, 'relu'))\nmodel7.add(Dense(2, 'linear'))\nmodel7.summary()\n\ncp7 = ModelCheckpoint('model6\/', save_best_only=True)\nmodel7.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])","4426f923":"model7.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=10, callbacks=[cp7])","7b25caa5":"# GRU (Gated Recurrent Unit)\nLSTM > GRU > CNN would be the order of complexity. GRU is faster and better than LSTM while you have less data. If you have enough data LSTM could be a better choice, as one can see here, https:\/\/datascience.stackexchange.com\/questions\/14581\/when-to-use-gru-over-lstm\n\nOne can also see a nice video, https:\/\/www.youtube.com\/watch?v=kGdbPnMCdOg&t=168s","8c2a46e2":"# Using more than one inputs.","2a162355":"The notebook credit goes to, Greg Hogg, https:\/\/www.youtube.com\/watch?v=c0k-YLQGKjY\nI will do try some change here to learn some more.","35254fef":"# Predict pressure and Temperature.","50ebfe2c":"# CNN again\n","30679a10":"# 1d CNN\nCNN could reduce complexity to an extreme and hence will be much faster. You will see that we will not conpromise with the performance though."}}