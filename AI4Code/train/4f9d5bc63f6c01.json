{"cell_type":{"891e1ec7":"code","fcbd0ad9":"code","8098a2fb":"code","d20b291d":"code","1bcc2347":"code","7b24ff9c":"code","03141f3c":"code","028f6c4c":"code","0f934900":"code","9d8e8ac7":"code","f31546ce":"code","2e070179":"code","4674309d":"code","cc9c1ebb":"code","5f657a3e":"code","0c46d6d7":"markdown","51d769f7":"markdown","3766dd35":"markdown","27448eb9":"markdown","f48dd218":"markdown","21f64c7a":"markdown","dfca89d3":"markdown","1a9e0638":"markdown","c2803cb3":"markdown","2f8b5248":"markdown"},"source":{"891e1ec7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fcbd0ad9":"!pip install pyspark","8098a2fb":"from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator","d20b291d":"spark = SparkSession.builder.appName('assignment7').getOrCreate()","1bcc2347":"raw_train = spark.read.csv('..\/input\/car-acceptability-prediction\/train.csv', header = True, inferSchema=True)\nraw_test = spark.read.csv('..\/input\/car-acceptability-prediction\/test.csv', header = True, inferSchema=True)","7b24ff9c":"train_pd = raw_train.toPandas()\ntest_pd = raw_test.toPandas()","03141f3c":"train_pd.info()","028f6c4c":"test_pd.info()","0f934900":"raw_train.groupBy('acceptability').count().sort('count').show()","9d8e8ac7":"indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(raw_train) for column in raw_train.columns[1:-1]]\npipeline = Pipeline(stages=indexers)\ntransformer = pipeline.fit(raw_train)\ntrain = transformer.transform(raw_train)","f31546ce":"test = transformer.transform(raw_test)","2e070179":"label_indexer = StringIndexer(inputCol='acceptability', outputCol='acceptability_index').fit(train)\ntrain = label_indexer.transform(train)","4674309d":"feature_transformer_train = VectorAssembler(inputCols=train.columns[8:14],outputCol=\"features\")\ntrain = feature_transformer_train.transform(train)\nfeature_transformer_test = VectorAssembler(inputCols=test.columns[7:13],outputCol=\"features\")\ntest = feature_transformer_test.transform(test)","cc9c1ebb":"from pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"acceptability_index\", featuresCol=\"features\", maxDepth=10,seed=465)\nrf_model = rf.fit(train)\npredict = rf_model.transform(test)\n\nfrom pyspark.sql.functions import col, when\npredict = predict.withColumn(\"acceptability\", when(col(\"prediction\")==0, \"unacc\").when(col(\"prediction\")==1, \"acc\").when(col(\"prediction\")==2, \"good\").otherwise(\"vgood\"))\n\nsubmit = predict.select(\"car_id\", \"acceptability\")\nsubmit.toPandas().to_csv('final_submission.csv', header=True, index=False)","5f657a3e":"submit.groupBy('acceptability').count().sort('count').show()","0c46d6d7":"T\u1eadp test kh\u00f4ng c\u00f3 gi\u00e1 null.","51d769f7":"# Tr\u1ecbnh Ng\u1ecdc Ph\u00e1p - 18521227\n# Tr\u1ea7n Nguy\u1ec5n Anh Khoa - 18520938","3766dd35":"Xem ph\u00e2n ph\u1ed1i gi\u00e1 tr\u1ecb c\u1ee7a bi\u1ebfn d\u1ef1 \u0111o\u00e1n.","27448eb9":"# Import dataset","f48dd218":"# Transform to features","21f64c7a":"# Check datatypes and null value","dfca89d3":"T\u1eadp train kh\u00f4ng c\u00f3 gi\u00e1 tr\u1ecb null.","1a9e0638":"# Build Model, Predict Testset and Submit","c2803cb3":"# Transform to indexers","2f8b5248":"# Import libraries"}}