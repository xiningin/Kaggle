{"cell_type":{"c9844a3d":"code","9282a9af":"code","389d3c6e":"code","ed0c45e4":"code","1e66ca63":"code","2e364cdb":"code","daa79057":"code","6ab95d6a":"code","99449915":"code","f7bd620a":"code","bfe037df":"code","69ee2cbf":"code","61c65cf2":"code","8092393e":"code","e320e043":"code","0d5968d7":"code","efa3b63a":"code","9e4bbe04":"code","c5ee5990":"code","0dddc5fb":"code","86230705":"code","8126f4c3":"code","59233870":"code","158f6ce8":"code","49b48a12":"code","01d3989f":"code","db01ab83":"code","58f34cb1":"code","9b6034d0":"code","86054ae6":"code","6c02b315":"code","74068933":"code","50a021f1":"code","26f0e114":"code","b7203709":"code","740aa970":"code","b68b4d0a":"markdown","317c3ee9":"markdown","e4f0813a":"markdown"},"source":{"c9844a3d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib \nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nimport sklearn\nimport xgboost\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9282a9af":"home = pd.read_csv(\"\/kaggle\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\")\nhome.head()","389d3c6e":"home.info()","ed0c45e4":"## finding null values in %form\n\nround(100*(home.isnull().sum()\/len(home.index)),2)","1e66ca63":"#removing NaN values from the dataset\nhome.dropna(inplace =True)","2e364cdb":"home = home.drop(columns='society')","daa79057":"home.reset_index(drop= True, inplace =True)","6ab95d6a":"home['bhk'] = home['size'].str.split().str[0]\nhome['bhk'].dropna(inplace = True)\nhome['bhk'] = home['bhk'].astype('int')","99449915":"print(home['total_sqft'].iloc[[17]])\n\n## fucntion to remove 2100 - 2850 by taking there average\ndef convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return (float(tokens[0])+float(tokens[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None","f7bd620a":"## applying the fucntion to the column: - 'total_sqft'\nhome.total_sqft = home.total_sqft.apply(convert_sqft_to_num)\n# Taking only the Numeric values from the data and storing it in 'home'\nhome = home[home.total_sqft.notnull()]\n# display the first 2 columns from the dataset\nhome.head(2)","bfe037df":"##removing invalid data entry\n## Example: The total sqft divided by the number of bhk should always be more than 300\n\nhome = home[~(home.total_sqft\/home.bhk<200)]\nhome.shape","69ee2cbf":"## dividing the dataset into Continous and Categorical variables:\ncont_ = home.select_dtypes(exclude = 'object')\ncat_ = home.select_dtypes(include  = 'object')","61c65cf2":"## displaying only the continous variables from the dataset\n## to determine the variables which have outliers and those which needs to be removed\nfig = plt.figure(figsize = (10,8))\nfor index,col in enumerate(cont_):\n    plt.subplot(3,2,index+1)\n    sns.boxplot(y = cont_.loc[:,col])\nfig.tight_layout(pad = 1.0)","8092393e":"home = home.drop(home[home['bath']>6].index)\nhome = home.drop(home[home['bhk']>7.0].index)","e320e043":"## Feature Engineering step\nhome['price_per_sqft'] = home['price']*100000\/home['total_sqft']\nhome.head()","0d5968d7":"home['price_per_sqft'].describe()","efa3b63a":"## taking only the values with 1st Standard devaition values.\n## as per Normal Distribution, 95% of our data lies within 1st Standard Deviation as per the location\n\ndef remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n    return df_out\nhome = remove_pps_outliers(home)\nhome.shape","9e4bbe04":"## finding correlation values within the dataset\n## we remove features which are highly related to each other as they do not provide\n## any significance value to our Model\n\ncorr = home.corr()\nplt.figure(figsize = (10,8))\nsns.heatmap(corr,mask = corr<0.8 ,annot= True,cmap = 'Blues')","c5ee5990":"home.drop(columns=['availability','size','area_type'],inplace = True)","0dddc5fb":"## checking the dataset with highest location data provided\n## because havind values for a location less than 10 wont give us good information on the dataset\n\nhome.location = home.location.str.strip()\nlocation_stats = home['location'].value_counts(ascending=False)\nlocation_stats","86230705":"## cretaing a Series of all the location having less than 10 entries against its  \nlocation_stats_less_than_10 = location_stats[location_stats<=10]\nlocation_stats_less_than_10","8126f4c3":"## using lambda function to naming 'location_stats_less_than_10' as 'other' and then removing it\n\nhome.location = home.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n\nhome = home[home.location != 'other']","59233870":"## Keeping in mind that the number of Bathroom shouldn't be more than BHK+2\n## Example for a 3 bhk, the number of bathrooms shouldn't be more than 5\n\nhome = home[home.bath<home.bhk+2]","158f6ce8":"## representing Numerical Data and Visualizing the same usin Distplot to gain further info\n\nnum_ = home.select_dtypes(exclude = 'object')\nfig = plt.figure(figsize =(10,8))\nfor index, col in enumerate(num_):\n    plt.subplot(3,2,index+1)\n    sns.distplot(num_.loc[:,col],kde = False)\nfig.tight_layout(pad = 1.0)","49b48a12":"## performing One hot encoding on the Categorical values\n## 1st step. create dummies\ndummies = pd.get_dummies(home.location)\ndummies.head(3)","01d3989f":"## adding the dummies dataframe to our main DataFrame\n\nhome = pd.concat([home,dummies],axis='columns')\n\n## removing 'location' as we have already created the dummies\nhome1 = home.drop('location',axis = 1)\n\n## removing columns which will not be required by our model\nhome1 = home1.drop(columns=['balcony','price_per_sqft'])\nhome1","db01ab83":"home1.reset_index(drop = True)","58f34cb1":"## Dividing our dataset to Independent and Dependent Variables\n\nX = home1.drop('price',axis = 1).values ## Independent Variables\ny = home1.price.values ## Dependent Variables","9b6034d0":"## adding a new axis\ny = y[:,np.newaxis]","86054ae6":"## preprocessing the data values to StandardScaler\nsc = preprocessing.StandardScaler()\nX1 = sc.fit_transform(X)\n","6c02b315":"## Standardize a dataset along any axis\n\n## Center to the mean and component wise scale to unit variance.\n\nStd_x1 = preprocessing.scale(X)","74068933":"## importing the required libraries for Machine Learning\n\nfrom sklearn.model_selection import cross_val_score,cross_val_predict\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nfrom sklearn.model_selection import cross_validate as CV","50a021f1":"## using Cross Validation of 5 andscoring of Negative mean sqaured error\n\ncross1 = cross_val_score(lr,Std_x1,y,cv=5,scoring='neg_mean_squared_error')\nprint(cross1.mean())","26f0e114":"sklearn.metrics.SCORERS.keys()","b7203709":"# from the model selection module import train_test_split for the ML training and testing.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X1,y,test_size=0.3,random_state=10)","740aa970":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,r2_score\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)\nacc = mean_squared_error(y_pred,y_test)\nrscore = r2_score(y_pred,y_test)\nprint(rscore)\n","b68b4d0a":"## Machine Learning Part","317c3ee9":"### Standardize features by removing the mean and scaling to unit variance\n\n#### The standard score of a sample x is calculated as:\n\n**z = (x - u) \/ s**\n\n- where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n\n","e4f0813a":"## Data Preprocessing!"}}