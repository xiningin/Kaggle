{"cell_type":{"c9863807":"code","79323a38":"code","3dbe853a":"code","4e0e7bec":"code","28fca88b":"code","6423875f":"code","8ce5731d":"code","d9cf4841":"code","b5aaf3bd":"code","df3907e7":"code","b1550877":"code","dfdd75d4":"code","742ddb14":"code","56dda2f9":"code","c5eae0d9":"code","50b4292e":"code","f69bc769":"code","da90de4f":"code","bd28ed5c":"code","d475a6c3":"code","42ffb97a":"code","62cb6aaf":"code","dae68ffe":"code","a87788fc":"code","5de090bc":"code","98bb3619":"code","ab5d322c":"code","5e5d7c00":"code","bae2cc33":"code","aa0a9206":"code","d24129ab":"code","a514b00e":"code","f96a75c8":"code","c1d5bf55":"code","cf192556":"code","75fa144c":"code","51efa9ce":"code","7719ff16":"code","1f98c8f8":"code","b9963a88":"code","5d720dc5":"markdown","fcaeff58":"markdown","1f3ec736":"markdown","fb8bdf3e":"markdown"},"source":{"c9863807":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","79323a38":"from pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go","3dbe853a":"data = pd.read_csv('\/kaggle\/input\/gamestop-historical-stock-prices\/GME_stock.csv')","4e0e7bec":"data.head()","28fca88b":"profile = ProfileReport(data, title=\"Pandas Profiling Report\")","6423875f":"profile","8ce5731d":"data.info()","d9cf4841":"# Converting the date column into datetime index\ndata['date'] = pd.to_datetime(data['date'])\ndata.set_index('date',inplace=True)\ndata.head()","b5aaf3bd":"print(data.index)\nprint('\\nUnique dates in our data: ', len(data.index.unique()), 'Days')","df3907e7":"print('\\nUnique dates in our data: ', len(data.index.unique()), 'Days')\nour_date_range = data.index.max() - data.index.min()\n\n# Calculate number of days in date range\nprint('Total days in our date range:', our_date_range.days, 'Days')","b1550877":"new_index = pd.date_range(data.index.min(), data.index.max())\ndata_new = data.reindex(new_index, fill_value=0)\ndata_new","dfdd75d4":"sales_weekly = data_new.resample('W').sum()\nprint('Weekly Sales')\nprint(sales_weekly.head(), '\\n')\n\nsales_monthly = data_new.resample('M').sum()\nprint('Monthly Sales')\nprint(sales_monthly.head(), '\\n')\n\nsales_quarterly = data_new.resample('Q').sum()\nprint('Quarterly Sales')\nprint(sales_quarterly.head(), '\\n')\n\nsales_annual = data_new.resample('Y').sum()\nprint('Annual Sales')\nprint(sales_annual.head())","742ddb14":"sales_quarterly['close_price'].plot(figsize=(13,5))\nsales_monthly['close_price'].plot(figsize=(13,5))\nsales_weekly['close_price'].plot(figsize=(13,5), title='Close Price')","56dda2f9":"sales_quarterly['open_price'].plot(figsize=(13,5))\nsales_monthly['open_price'].plot(figsize=(13,5))\nsales_weekly['open_price'].plot(figsize=(13,5), title='Open Price')","c5eae0d9":"sales_quarterly['open_price'].plot(figsize=(13,5))\nsales_monthly['open_price'].plot(figsize=(13,5))\nsales_weekly['open_price'].plot(figsize=(13,5), title='Open Price')","50b4292e":"# Plotting the data from december 2020 to january 2021 to view the trend\nfig = px.line(data, x=data.index, y=data.columns, \n              range_x=['2020-12-01','2021-01-28'],\n              title='Plot of values for December 20 and January 21')\nfig.show()","f69bc769":"# Plotting the total amount traded\ndata['total_amount_traded'] = data['open_price']*data['volume']\n\nfig = px.line(data, x=data.index, y=data.total_amount_traded,\n              title='Plot of total amount traded')\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()","da90de4f":"# Plotting the exponential moving average for the opening price\ndata['EWMA12'] = data['open_price'].ewm(span=12).mean()\n#data[['open_price','EWMA12']].plot(figsize=(16,8))\nfig = px.line(data[['EWMA12']], x=data.index, y=data.open_price,\n              title='Moving average of opening price')\nfig.show()","bd28ed5c":"# Plotting candlestick chart\nfig = go.Figure(data=[go.Candlestick(x=data.index,\n                open=data['open_price'],\n                high=data['high_price'],\n                low=data['low_price'],\n                close=data['close_price'])])\n\nfig.show()","d475a6c3":"# Scatter and density plots\ndef plotScatterMatrix(data, plotSize, textSize):\n    data = data.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    data = data.dropna('columns')\n    data = data[[col for col in data if data[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(data)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    data = data[columnNames]\n    ax = pd.plotting.scatter_matrix(data, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = data.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()","42ffb97a":"plotScatterMatrix(data, 18, 10)","62cb6aaf":"# Importing required libraries\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, SimpleRNN, Activation\nfrom sklearn.metrics import mean_squared_error","dae68ffe":"#creating dataframe\ndata = data.sort_index(ascending=True, axis=0)\ntrain_data = pd.DataFrame(index=range(0,len(data)),columns=['Date', 'Close'])\nfor i in range(0,len(data)):\n    train_data['Date'][i] = data.index[i]\n    train_data['Close'][i] = data['close_price'][i]\ntrain_data.head()","a87788fc":"#setting index\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data.set_index('Date',inplace=True)\ntrain_data.head()","5de090bc":"# Creating train and test sets\ndataset = train_data.values\n\ntrain = dataset[0:3773,:]\nvalid = dataset[1000:,:]","98bb3619":"# Feature scaling\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(dataset)","ab5d322c":"# Converting dataset into x_train and y_train for 60 timesteps\nx_train, y_train = [], []\nfor i in range(60,len(train)):\n    x_train.append(scaled_data[i-60:i,0])\n    y_train.append(scaled_data[i,0])\nx_train, y_train = np.array(x_train), np.array(y_train)\n\nx_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))","5e5d7c00":"# Build the LSTM model\nregressor = Sequential()\n\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))\n\nregressor.add(Dense(units = 1))\n\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\nregressor.fit(x_train, y_train, epochs = 100, batch_size = 32)","bae2cc33":"# Predicting values, using past 60 from the train data\ninputs = train_data[len(train_data) - len(valid) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs  = scaler.transform(inputs)","aa0a9206":"X_test = []\nfor i in range(60,inputs.shape[0]):\n    X_test.append(inputs[i-60:i,0])\nX_test = np.array(X_test)","d24129ab":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\nclosing_price_pred = regressor.predict(X_test)\nclosing_price_pred = scaler.inverse_transform(closing_price_pred)","a514b00e":"rms=np.sqrt(np.mean(np.power((valid-closing_price_pred),2)))\nrms","f96a75c8":"# Plotting\ntrain = train_data[:3773]\nvalid = train_data[1000:]\nvalid['Predictions'] = closing_price_pred\nplt.plot(train['Close'])\nplt.plot(valid[['Close','Predictions']])","c1d5bf55":"len(valid)","cf192556":"# Build the Simple RNN model\nregressor = Sequential()\n\nregressor.add(SimpleRNN(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\nregressor.add(SimpleRNN(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\nregressor.add(Dense(units = 1))\n\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\nregressor.fit(x_train, y_train, epochs = 100, batch_size = 32)","75fa144c":"# Predicting values, using past 60 from the train data\ninputs = train_data[len(train_data) - len(valid) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs  = scaler.transform(inputs)","51efa9ce":"X_test = []\nfor i in range(60,inputs.shape[0]):\n    X_test.append(inputs[i-60:i,0])\nX_test = np.array(X_test)","7719ff16":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\nclosing_price_pred = regressor.predict(X_test)\nclosing_price_pred = scaler.inverse_transform(closing_price_pred)","1f98c8f8":"rms=np.sqrt(np.mean(np.power((valid-closing_price_pred),2)))\nrms","b9963a88":"# Plotting\ntrain = train_data[:3773]\nvalid = train_data[1000:]\nvalid['Predictions'] = closing_price_pred\nplt.plot(train['Close'])\nplt.plot(valid[['Close','Predictions']])","5d720dc5":"# Simple RNN","fcaeff58":"# Basic EDA","1f3ec736":"# Model development\n\n## LSTM","fb8bdf3e":"Since we have now created a column for each category, we can see there no longer repeated values in the Datetime Index. \n\n## Generating a complete Index and Setting Frequency\nSince we are using daily data, we would like to set a daily frequency. We see our data has a length of 4773 days. By subtracting the smallest date from the largest date, we can tell there are some days missing:"}}