{"cell_type":{"d37a3d11":"code","d7d54207":"code","586be1cd":"code","e359de32":"code","23e2ffb7":"code","c447888c":"code","4212223d":"code","c2853c43":"code","f5ea7256":"code","29c616a2":"code","69d957ba":"code","46201d22":"code","259b3791":"code","fa89676c":"code","473cd4d6":"code","eee3300a":"code","94b01501":"code","e0e6cbed":"code","8b5f3023":"code","0526b2d0":"code","cd8f9f45":"code","1f881185":"code","60eb3380":"code","29e3ebaa":"code","bb9a5cdd":"markdown","a65ed9a6":"markdown"},"source":{"d37a3d11":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7d54207":"import lightgbm as lgb\nimport optuna.integration.lightgbm as oplgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport category_encoders as ce\nimport seaborn as sns","586be1cd":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\ndf_sample = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/sample_submission.csv\")","e359de32":"df_train","23e2ffb7":"df_test","c447888c":"train_id = df_train[\"id\"]\ntest_id = df_test[\"id\"]\n\ndf_train.drop(\"id\", axis=1, inplace=True)\ndf_test.drop(\"id\", axis=1, inplace=True)","4212223d":"# use all train data\ntrain_jscodes = []\ntest_jscodes = []\ncat_features = [f\"cat{i}\" for i in range(9 + 1)]\nfor i in tqdm(range(13 + 1)):\n    js_encoder = ce.james_stein.JamesSteinEncoder()\n    js_encoder.fit(df_train[cat_features], df_train[f\"cont{i}\"])\n    train_jscode = js_encoder.transform(df_train[cat_features])\n    test_jscode = js_encoder.transform(df_test[cat_features])\n    train_jscode.columns = [f\"JS_cont{i}_{col}\" for col in train_jscode]\n    test_jscode.columns = [f\"JS_cont{i}_{col}\" for col in test_jscode]\n    train_jscodes.append(train_jscode)\n    test_jscodes.append(test_jscode)","c2853c43":"count_encoder = ce.CountEncoder()\ncount_encoder.fit(df_train[cat_features])\ntrain_ce = count_encoder.transform(df_train[cat_features])\ntest_ce = count_encoder.transform(df_test[cat_features])\ntrain_ce.columns = [f\"CE_{col}\" for col in train_ce]\ntest_ce.columns = [f\"CE_{col}\" for col in test_ce]","f5ea7256":"numerical_features = [f\"cont{i}\" for i in range(13 + 1)]","29c616a2":"train_x = pd.concat([\n    df_train[numerical_features],\n    *train_jscodes,\n    train_ce\n], axis=1)","69d957ba":"test_x = pd.concat([\n    df_test[numerical_features],\n    *test_jscodes,\n    test_ce\n], axis=1)","46201d22":"train_y = df_train[\"target\"]","259b3791":"train_x","fa89676c":"test_x","473cd4d6":"class FoldsAverageLGBM:\n    def __init__(self, folds):\n        self.folds = folds\n        self.models = []\n        \n    def fit(self, lgb_params, train_x, train_y):\n        oof_preds = np.zeros_like(train_y)\n        \n        self.train_x = train_x\n        self.train_y = train_y.values\n        \n        for tr_idx, va_idx in tqdm(folds.split(train_x)):\n            tr_x, va_x = self.train_x.iloc[tr_idx], self.train_x.iloc[va_idx]\n            tr_y, va_y = self.train_y[tr_idx], self.train_y[va_idx]\n            \n            lgb_train_dataset = lgb.Dataset(tr_x, tr_y)\n            lgb_valid_dataset = lgb.Dataset(va_x, va_y)\n            model = lgb.train(lgb_params, lgb_train_dataset, valid_sets=[lgb_valid_dataset], verbose_eval=100)\n            self.models.append(model)\n            \n            oof_pred = model.predict(va_x)\n            oof_preds[va_idx] = oof_pred\n            \n        self.oof_preds = oof_preds\n        \n    def predict(self, test_x):\n        preds = []\n        for model in tqdm(self.models):\n            pred = model.predict(test_x)\n            preds.append(pred)\n        preds = np.mean(preds, axis=0)\n        return preds\n    \n    def get_feature_importance(self, importance_type=\"gain\"):\n        feature_names = self.models[0].feature_name()\n        feature_importances_list = [model.feature_importance(importance_type) for model in self.models]\n        \n        out_df = pd.DataFrame()\n        for i, name in enumerate(feature_names):\n            out_df[name] = [v[i] for v in feature_importances_list]\n        return out_df","eee3300a":"def plot_importance(importance_df, max_features=100):\n    feature_order = list(importance_df.mean().sort_values(ascending=False).index[:max_features])\n    target_data = importance_df[feature_order]\n    sns.boxenplot(data=target_data, orient=\"h\", order=feature_order)","94b01501":"folds = KFold(n_splits=5, shuffle=True, random_state=2021)","e0e6cbed":"lgb_params = {\n    \"objective\": \"regression\",\n    \"metric\": \"root_mean_squared_error\",\n    \"verbosity\": -1,\n    \"learning_rate\": 0.01,\n    \"early_stopping_rounds\": 1000,\n    \"num_iterations\": 10000\n}","8b5f3023":"folds_average_lgbm = FoldsAverageLGBM(folds)","0526b2d0":"folds_average_lgbm.fit(lgb_params, train_x, train_y)","cd8f9f45":"plt.figure(figsize=(20, 20))\nimportance_df = folds_average_lgbm.get_feature_importance()\nplot_importance(importance_df)","1f881185":"np.sqrt(mean_squared_error(df_train.target, folds_average_lgbm.oof_preds))","60eb3380":"y_pred = folds_average_lgbm.predict(test_x)","29e3ebaa":"sub = df_sample.copy()\nsub[\"target\"] = y_pred\n\nsub.to_csv(\"submission_lgbm_js_ce_v1.csv\", index=False)\n\nsub.head()","bb9a5cdd":"# CountEncoder","a65ed9a6":"# JamesSteinEncoder"}}