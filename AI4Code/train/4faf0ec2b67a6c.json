{"cell_type":{"fe0890a1":"code","18f54dd3":"code","e23098c6":"code","0b66181d":"code","12b5654f":"code","42762bbb":"code","cec72c73":"code","6ee6e915":"code","841aca88":"code","c52c928a":"code","5c30ec0a":"code","f5c779fc":"code","ff8b4104":"markdown"},"source":{"fe0890a1":"import numpy as np\nimport pandas as pd \n\n# Import files, view data\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\n\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","18f54dd3":"from sklearn.preprocessing import LabelEncoder\n\n# Get pclass dummies\n\npclass_dummies_train = pd.get_dummies(train['Pclass'],drop_first=True,prefix='pclass')\ntrain = pd.concat([train,pclass_dummies_train],axis=1)\ntrain = train.drop(columns = ['Pclass'])\n\npclass_dummies_test = pd.get_dummies(test['Pclass'],drop_first=True,prefix='pclass')\ntest = pd.concat([test,pclass_dummies_test],axis=1)\ntest = test.drop(columns = ['Pclass'])\n\n# Label encode sex\n\nle = LabelEncoder()\n\ntrain['Sex'] = le.fit_transform(train['Sex'].values)\ntest['Sex'] = le.fit_transform(test['Sex'].values)\n    \n# Replace missing age with average\n\nmean_age_train = train['Age'].mean()\nmean_age_test = test['Age'].mean()\n\ntrain['Age'] = train['Age'].fillna(mean_age_train)\ntest['Age'] = test['Age'].fillna(mean_age_test)\n\n# Replace missing fare with average\n\nmean_fare_train = train['Fare'].mean()\nmean_fare_test = test['Fare'].mean()\n\ntrain['Fare'] = train['Fare'].fillna(mean_fare_train)\ntest['Fare'] = test['Fare'].fillna(mean_fare_test)\n\n# Fill embarked Na with 'Q'\n\ntrain['Embarked'] = train['Embarked'].fillna('Q')\ntest['Embarked'] = test['Embarked'].fillna('Q')\n\n# Label encode embarked\n\ntrain['Embarked'] = le.fit_transform(train['Embarked'].values)\n\nle = LabelEncoder()\n\ntest['Embarked'] = le.fit_transform(test['Embarked'].values)\n\n# Get embarked dummies\n\nembarked_dummies_train = pd.get_dummies(train['Embarked'],drop_first=True,prefix='embarked')\ntrain = pd.concat([train,embarked_dummies_train],axis=1)\ntrain = train.drop(columns = ['Embarked'])\n\n\nembarked_dummies_test = pd.get_dummies(test['Embarked'],drop_first=True,prefix='embarked')\ntest = pd.concat([test,embarked_dummies_test],axis=1)\ntest = test.drop(columns = ['Embarked'])","e23098c6":"pip install langdetect","0b66181d":"# Language: Langdetect on name\n\nfrom langdetect import detect\n\ntrain_names = train['Name'].values\ntest_names = test['Name'].values\n\ntrain_lang = []\ntest_lang = []\n\nfor i in range(len(train)):\n    train_lang.append(detect(train_names[i]))\n\nfor i in range(len(test)):\n    test_lang.append(detect(test_names[i]))\n    \ntrain['Language'] = train_lang\ntest['Language'] = test_lang\n\n# Replace languages unique to train\/test set\n\ntrain['Language'] = train['Language'].replace('hu','en')\ntrain['Language'] = train['Language'].replace('sk','en')\ntrain['Language'] = train['Language'].replace('hr','en')\ntrain['Language'] = train['Language'].replace('sl','en')\ntrain['Language'] = train['Language'].replace('lv','en')\n\ntest['Language'] = test['Language'].replace('sq','en')\n\n# Group languages\n\n# Afrikaans -> Dutch\n\ntrain['Language']  = train['Language'].replace('af','nl')\ntest['Language']  = test['Language'].replace('af','nl')\n\n# Welsh -> English\n\ntrain['Language']  = train['Language'].replace('cy','en')\ntest['Language']  = test['Language'].replace('cy','en')\n\n# Portugese -> Spanish\n\ntrain['Language']  = train['Language'].replace('pt','es')\ntest['Language']  = test['Language'].replace('pt','es')\n\n# Catalan -> Spanish\n\ntrain['Language']  = train['Language'].replace('ca','es')\ntest['Language']  = test['Language'].replace('ca','es')\n\n# Danish -> Swedish\n\ntrain['Language']  = train['Language'].replace('da','sv')\ntest['Language']  = test['Language'].replace('da','sv')\n\n# Norwegian -> Swedish\n\ntrain['Language']  = train['Language'].replace('no','sv')\ntest['Language']  = test['Language'].replace('no','sv')\n\n# Somali -> Swahili\n\ntrain['Language']  = train['Language'].replace('so','sw')\ntest['Language']  = test['Language'].replace('so','sw')\n\n# Tagalog -> Indonesian\n\ntrain['Language']  = train['Language'].replace('tl','id')\ntest['Language']  = test['Language'].replace('tl','id')\n","12b5654f":"# Label encode language\n\ntrain['Language'] = le.fit_transform(train['Language'])\n\ntest['Language'] = le.fit_transform(test['Language'])\n\n# Get language dummies\n\nlanguage_dummies_train = pd.get_dummies(train['Language'],drop_first=True,prefix='language')\ntrain = pd.concat([train,language_dummies_train],axis=1)\ntrain = train.drop(columns = ['Language'])\n\nlanguage_dummies_test = pd.get_dummies(test['Language'],drop_first=True,prefix='language')\ntest = pd.concat([test,language_dummies_test],axis=1)\ntest = test.drop(columns = ['Language'])","42762bbb":"test.columns","cec72c73":"# Ticket: Get first # of ticket Performance increases without running this cell!\n'''\nimport re\n\ntrain_tickets = train['Ticket'].replace('LINE','100000000')\ntest_tickets = test['Ticket'].replace('LINE','100000000')\n\nmatcher = re.compile('([0-9]+)([0-9]+)')\none_digit_matcher = re.compile('([0-9]+)')\n\ntrain_tickets_processed = []\ntest_tickets_processed = []\n\nfor t in train_tickets:\n    result = matcher.search(t)\n    \n    if result == None:\n        result = one_digit_matcher.search(t)\n        \n    result = int(result.group(0))\n    \n    train_tickets_processed.append(int(result))\n    \nfor t in test_tickets:\n    \n    result = matcher.search(t)\n    \n    if result == None:\n        result = one_digit_matcher.search(t)\n    \n    result = int(result.group(0))\n    test_tickets_processed.append(int(result))\n    \ntrain['Ticket'] = train_tickets_processed\ntest['Ticket'] = test_tickets_processed\n'''","6ee6e915":"'''# Get ticket dummies\n\n\nticket_dummies_train = pd.get_dummies(train['Ticket'],drop_first=True)\ntrain = pd.concat([train,ticket_dummies_train],axis=1)\ntrain = train.drop(columns = ['Ticket'])\n\nticket_dummies_test = pd.get_dummies(test['Ticket'],drop_first=True)\ntest = pd.concat([test,ticket_dummies_test],axis=1)\ntest = test.drop(columns = ['Ticket'])\n'''","841aca88":"import re\n\ntrain_ticket_prefix = []\ntest_ticket_prefix = []\n\nfor t in train['Ticket'].values:\n    \n    prefix = t.split(' ')[0]\n    \n    # Remove punctuation\n    prefix = re.sub(r'[^\\w\\s]','',prefix)\n    \n    if prefix.isdigit():\n        prefix = 'No Prefix'\n    \n    prefix = \" \".join(re.findall(\"[a-zA-Z]+\", prefix))\n    train_ticket_prefix.append(prefix.lower())\n    \ntrain['Ticket Prefix'] = train_ticket_prefix\n\nfor t in test['Ticket'].values:\n    \n    prefix = t.split(' ')[0]\n    \n    # Remove punctuation\n    prefix = re.sub(r'[^\\w\\s]','',prefix)\n    \n    if prefix.isdigit():\n        prefix = 'No Prefix'\n        \n    prefix = \" \".join(re.findall(\"[a-zA-Z]+\", prefix))\n    test_ticket_prefix.append(prefix.lower())\n    \ntest['Ticket Prefix'] = test_ticket_prefix\n\n# Replace ticket prefixes that don't appear in both train\/test sets\n\ntrain['Ticket Prefix'] = train['Ticket Prefix'].replace(to_replace=['sp','sop','fa','line','swpp',\n                                                         'scow','ppp','as','casoton','aw',\n                                                        'lp','sotono','sopp','scah','sc','fc'],value='no prefix')\n\ntest['Ticket Prefix'] = train['Ticket Prefix'].replace(to_replace=['sp','sop','fa','line','swpp',\n                                                         'scow','ppp','as','casoton','aw',\n                                                        'lp'],value='no prefix')\n\n# Get ticket prefix dummies\n    \nprefix_dummies_train = pd.get_dummies(train['Ticket Prefix'],drop_first=True,prefix='prefix')\ntrain = pd.concat([train,prefix_dummies_train],axis=1)\ntrain = train.drop(columns = ['Ticket Prefix'])\n\nprefix_dummies_test = pd.get_dummies(test['Ticket Prefix'],drop_first=True,prefix='prefix')\ntest = pd.concat([test,prefix_dummies_test],axis=1)\ntest = test.drop(columns = ['Ticket Prefix'])","c52c928a":"# Upsample train set: Performance increases without running this cell!\n'''\nfrom sklearn.utils import resample\n\ndied = train[train['Survived']==0]\nsurvived = train[train['Survived']==1]\n        \nsurvived_upsampled = resample(survived,replace=True,n_samples=len(died))\n        \ntrain = pd.concat([died,survived])\n'''","5c30ec0a":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n# Get feature and target vectors\n\nX = train.drop(columns=['PassengerId','Ticket','Survived','Name','Cabin'])\n\nY = train['Survived']\n\n\n# Instantiate and fit models\n\nrf = RandomForestClassifier()\nrf.fit(X,Y)\n\ngb = GradientBoostingClassifier()\ngb.fit(X,Y)\n\nxgb = XGBClassifier()\nxgb.fit(X,Y)\n\ncb = CatBoostClassifier()\n\ncb.fit(X,Y)","f5c779fc":"# Get test feature vector\n\nX_Test = test.drop(columns=['PassengerId','Ticket','Name','Cabin'])\n\n# Get prediction files\n\npred = rf.predict(X_Test)\nprediction = pd.DataFrame()\nprediction['PassengerId'] = test['PassengerId']\nprediction['Survived'] = pred\nprediction.to_csv('rf.csv',index=False)\n\npred = gb.predict(X_Test)\nprediction = pd.DataFrame()\nprediction['PassengerId'] = test['PassengerId']\nprediction['Survived'] = pred\nprediction.to_csv('gb.csv',index=False)\n\npred = xgb.predict(X_Test)\nprediction = pd.DataFrame()\nprediction['PassengerId'] = test['PassengerId']\nprediction['Survived'] = pred\nprediction.to_csv('xgb.csv',index=False)\n\npred = cb.predict(X_Test)\nprediction = pd.DataFrame()\nprediction['PassengerId'] = test['PassengerId']\nprediction['Survived'] = pred\nprediction.to_csv('cb.csv',index=False)\n","ff8b4104":"****Data Preprocessing:****\n\n- Pclass: Get dummies [X]\n- Sex: Label encode [X]\n- Age: Replace Na with mean [X]\n- Embarked: Label encode, get dummies [X]\n\n****Feature Engineering:****\n\n- Language: Detect language of name using langdetect [X] -> Increased performance\n- Ticket: First number of ticket [X] -> Decreased performance, but may have to do with prefix bug\n- Ticket: Whole number of ticket [X] -> Decreased performance\n- Ticket: Ticket prefix [X]\n- Cabin: Floor\/Section []\n\n****Parameter Tuning****"}}