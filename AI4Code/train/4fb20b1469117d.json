{"cell_type":{"5043ae6e":"code","64d231a5":"code","dbdf2bdb":"code","8cb47882":"code","5c80c775":"code","dc7aae0b":"code","3c934cb7":"code","db7ed320":"code","b01ea7af":"code","516dc885":"code","3d9a3d51":"code","bc764bf0":"code","9fc350a8":"code","efab8964":"code","d85a9baf":"code","e0ea27ea":"code","f44d57e2":"code","5bf0b1e7":"code","ac883c5d":"code","2fb24579":"code","6c84970b":"code","b82ad387":"code","2992dcff":"code","1b24bc17":"code","d894fc2b":"code","9599cf17":"code","a10d3a02":"code","0674bf23":"code","bc26533e":"code","5d1db1da":"code","5778ffe3":"code","debe322e":"code","07155f5c":"code","2f0d88b4":"code","34f5a1fb":"code","0901e382":"code","cad59de8":"code","3fdc4cb3":"code","6739145d":"code","eb6ba4f3":"code","4ea73676":"code","d23f2de4":"code","803de311":"code","3fff9f7b":"code","a8df5570":"code","3f368037":"code","0258592b":"code","404cd888":"markdown","39a1fc55":"markdown"},"source":{"5043ae6e":"#basic\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageFile\nimport os\nimport cv2\nimport math\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook as tqdm_notebook\n\n#deeplearning\nimport time\nimport torch\nimport torchvision\nimport torch.nn as nn\n\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\")","64d231a5":"import warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","dbdf2bdb":"!ls \/kaggle\/input\/dsnet-kaggledays-hackathon\/train\/train","8cb47882":"BASE_PATH = \"..\/input\/dsnet-kaggledays-hackathon\/train\/train\"\ndf_arr = []\nfor dirname in os.listdir(BASE_PATH):\n    for filename in os.listdir(os.path.join(BASE_PATH, dirname)):\n        df_dict = {\"y\": dirname, \"path\": os.path.join(BASE_PATH,dirname,filename)}\n        df_arr.append(df_dict)","5c80c775":"df = pd.DataFrame(df_arr)","dc7aae0b":"len(df)","3c934cb7":"img = plt.imread(df['path'][0])\nplt.axis('off')\nplt.imshow(img)\nplt.show()","db7ed320":"plt.figure(figsize=(20,2))\ndf['y'].value_counts().plot(kind='bar')\n","b01ea7af":"dicty =  df['y'].value_counts().sort_values()[0:25].index.values","516dc885":"dicty = {i:100 for i in dicty }","3d9a3d51":"dicty","bc764bf0":"from imblearn.over_sampling import RandomOverSampler\n\n\nsm = RandomOverSampler(sampling_strategy=dicty, random_state=42)\n\n# Fit the model to generate the data.\noversampled_X, oversampled_Y = sm.fit_sample(df['path'].values.reshape(-1,1), df['y'])\noversampled_train = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)\noversampled_train.columns = df.columns","9fc350a8":"plt.figure(figsize=(20,2))\noversampled_train['y'].value_counts().plot(kind='bar')","efab8964":"df = oversampled_train","d85a9baf":"def preprocess_image(filename):\n    image = cv2.imread(filename)\n    image = cv2.resize(image, (380, 380))\n    return image","e0ea27ea":"len(df)","f44d57e2":"N =  len(df)\nx_train = np.empty((N, 380,380, 3), dtype=np.uint8)\nfor i, path in enumerate(tqdm(df['path'])):\n    x_train[i, :, :, :]= preprocess_image(path)","5bf0b1e7":"from sklearn.preprocessing import LabelEncoder\nnumber = LabelEncoder()","ac883c5d":"y_train = number.fit_transform(df['y'])\ncls = number.classes_","2fb24579":"y_train.shape","6c84970b":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.14,random_state = 42)","b82ad387":"transform = {'train' : transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(360),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\n}","2992dcff":"class ARTWORK(Dataset):\n    \n    def __init__(self,x_train,y_train,transform=None,train=True):\n        self.x = x_train\n        self.y = y_train\n        self.transform = transform\n        self.train=train\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        if self.train==True:\n            image = self.x[idx].astype(np.uint8).reshape((380,380,3))\n            label = self.y[idx]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return {'image': image,\n                'label': label\n                }","1b24bc17":"data = ARTWORK(x_train,y_train,transform=transform['train'],train=True)","d894fc2b":"valid = ARTWORK(x_val,y_val,transform=transform['valid'],train=True)","9599cf17":"x = data.__getitem__(12)\nimage = x['image'].numpy()\nimage = np.transpose(image,[2,1,0])\nplt.imshow(image)\nplt.title(cls[x['label']])\nplt.show()","a10d3a02":"!pip install efficientnet-pytorch","0674bf23":"from efficientnet_pytorch import EfficientNet","bc26533e":"!ls ..\/input\/efficientnet-pytorch","5d1db1da":"import torchvision.models as models","5778ffe3":"model = EfficientNet.from_name('efficientnet-b4')\nmodel.load_state_dict(torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b4-e116e8b3.pth'))\nmodel._fc = nn.Sequential(\n     nn.Linear(in_features=1792, out_features=49, bias=True),\n     nn.LogSoftmax()\n    )\n\nmodel = model.to(device)\n","debe322e":"data_loader = torch.utils.data.DataLoader(data, batch_size=16, shuffle=True, num_workers=4)\nvalid_data_loader = torch.utils.data.DataLoader(valid, batch_size=16, shuffle=False, num_workers=4)","07155f5c":"optimizer = optim.Adam(model.parameters(), lr=0.0005)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=5,gamma=0.1)","2f0d88b4":"since = time.time()\ncriterion = nn.NLLLoss()\nnum_epochs = 25\nprevious_loss = 100\nlossy = []\naccy = []\nfor epoch in range(num_epochs):\n    print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n    scheduler.step()\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(data_loader, total=int(len(data_loader)))\n    counter = 0\n    train_acc  = []\n    for bi, d in enumerate(tk0):\n        inputs = d[\"image\"]\n        labels = d[\"label\"]\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            outputs = torch.max(outputs,1)[1]\n            outputs = outputs.cpu().detach().numpy()\n            labels = labels.cpu().numpy()\n            acc = accuracy_score(outputs,labels)\n            train_acc.append(acc)\n        running_loss += loss.item()\n        counter += 1\n    epoch_loss = running_loss \/ len(data_loader)\n    print('train acc {:.4f}'.format(np.mean(train_acc)) )\n    print('Training Loss: {:.4f}'.format(epoch_loss))\n    model.eval()\n    val_loss = []\n    correct = []\n\n    with torch.no_grad():\n        for bi,d in enumerate(tqdm(valid_data_loader,total=int(len(valid_data_loader)))):\n            inputs = d[\"image\"]\n            labels = d[\"label\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.long)\n            outputs = model(inputs)\n            loss = criterion(outputs,labels)\n            outputs = torch.max(outputs,1)[1]\n            outputs = outputs.cpu().detach().numpy()\n            labels = labels.cpu().numpy()\n            acc = accuracy_score(outputs,labels)\n           \n            correct.append(acc)\n            val_loss.append(loss.item())\n            \n            \n    \n    print('Validation Loss: {:.4f}'.format(np.mean(val_loss)))\n    print('Accuracy score: {:.4f}'.format(np.mean(correct)))\n    if np.mean(val_loss)<previous_loss:\n        previous_loss = np.mean(val_loss)\n        print('LOSS improved')\n    lossy.append(np.mean(val_loss))\n    accy.append(np.mean(correct))","34f5a1fb":"torch.save(model.state_dict(), \"model_dsnet_1.pth\")","0901e382":"sub = pd.read_csv(\"..\/input\/dsnet-kaggledays-hackathon\/sample_submission.csv\")","cad59de8":"sub.head()","3fdc4cb3":"len(sub)","6739145d":"N =  len(sub)\nx_test= np.empty((N, 380, 380, 3), dtype=np.uint8)\nfor i, path in enumerate(tqdm(sub['id'])):\n    x_test[i, :, :, :]= preprocess_image(f'..\/input\/dsnet-kaggledays-hackathon\/test\/test\/{path}')","eb6ba4f3":"class TEST(Dataset):\n    \n    def __init__(self,x_train,transform=None,train=True):\n        self.x = x_train\n        self.transform = transform\n        self.train=train\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        if self.train==True:\n            image = self.x[idx].astype(np.uint8).reshape((380, 380,3))\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return {'image': image\n                }","4ea73676":"test = TEST(x_test,transform=transform['valid'],train=True)","d23f2de4":"data_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False, num_workers=4)","803de311":"model.eval()\npred = []\nwith torch.no_grad():\n    for i, data in enumerate(tqdm(data_loader,total=int(len(data_loader)))):\n        images = data['image']\n        images = images.to(device, dtype=torch.float)\n        predict = model(images)\n        predict = torch.max(predict,1)[1].cpu().squeeze().numpy().reshape(-1)[0]\n        pred.append(predict)\n        ","3fff9f7b":" torch.max(model(images),1)[1].detach().cpu().squeeze().numpy().reshape(-1)[0]","a8df5570":"number.classes_[pred]","3f368037":"\nsub['predicted_class'] = number.classes_[pred]\nsub.to_csv(\"submission.csv\",index=False)","0258592b":"sub['predicted_class'].value_counts()","404cd888":"<a href=\".\/submission.csv\"> Download File <\/a>","39a1fc55":"<a href=\".\/model_dsnet_1.pth\"> Download File <\/a>"}}