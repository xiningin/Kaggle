{"cell_type":{"4c664725":"code","7fde62e9":"code","369c7e55":"code","7f44be9a":"code","86081640":"code","7f294224":"code","fa87074d":"code","daa3b5ba":"code","7f570ff2":"code","61c2a23a":"code","f890a763":"code","d6a1012f":"code","0026322a":"code","517a292f":"code","1d4b2797":"code","a7ffb313":"code","bb42d8a0":"code","5543363f":"code","25fa2ae1":"code","713bf3bc":"code","f709f11d":"code","1b220fc1":"markdown","b6c64592":"markdown","8671264d":"markdown","880ef4d6":"markdown","fa7f561b":"markdown","42cd3829":"markdown","e9ce4ae6":"markdown","606371af":"markdown"},"source":{"4c664725":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fde62e9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","369c7e55":"df=pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","7f44be9a":"df.head()","86081640":"df.shape","7f294224":"df[['Amount','Time','Class']].describe()","fa87074d":"df.columns","daa3b5ba":"df.isna().any()","7f570ff2":"nfcount=0\nnotfraud =df['Class']\nfor i in range(len(notfraud)):\n    if notfraud[i]==0:\n        nfcount=nfcount+1\n\nnfcount\nper_nf=(nfcount\/len(notfraud))*100\nprint(per_nf)","61c2a23a":"fcount=0\nfraud =df['Class']\nfor i in range(len(fraud)):\n    if fraud[i]==1:\n        fcount=fcount+1\n\nnfcount\nper_f=(fcount\/len(fraud))*100\nprint(per_f)","f890a763":"plot_data=pd.DataFrame()\nplot_data['Fraud Transaction']=fraud\nplot_data['Genuine Transaction']= notfraud\nplot_data","d6a1012f":"plt.title(\"bar  plot fro fraud and genuine transaction\")\nsns.barplot(x='Fraud Transaction' , y='Genuine Transaction',data=plot_data,palette='Blues')","0026322a":"x=df['Amount']\ny=df['Time']\nplt.plot(x,y)\nplt.title(\"Time vs amount\")","517a292f":"plt.figure(figsize=(10,8),)\nplt.title('Amount Distribution')\n\nsns.distplot(df['Amount'],color='red')","1d4b2797":"fig, ax= plt.subplots(figsize=(16,8))\nax.scatter(df['Amount'],df['Time'])\nax.set_xlabel('Amount')\nax.set_ylabel('Time')\nplt.show()","a7ffb313":"# correlational matrices\ncor_mat=df.corr()\nfig=plt.figure(figsize=(14,9))\nsns.heatmap(cor_mat,vmax=0.9,square=True)\nplt.show()","bb42d8a0":"x=df.drop(['Class'],axis=1)\ny=df['Class']\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest , ytrain , ytest=train_test_split(x,y,test_size=0.2,random_state=42)","5543363f":"from sklearn.linear_model import LogisticRegression\nlogis=LogisticRegression()\nlogis.fit(xtrain,ytrain)","25fa2ae1":"y_pred=logis.predict(xtest)","713bf3bc":"from sklearn import metrics\n\ncm=metrics.confusion_matrix(ytest,y_pred)\nprint(cm)","f709f11d":"accuracy = logis.score(xtest,ytest)\nprint('Accuracy of the Logistic regression model :',accuracy*100,'%')","1b220fc1":"* it contains 285,000 rows of data and 31 columns.\n* the most important columns are \n* Time\n* Amount\n* and class (fraud or not fraud)\n* data_df[class]=0 not a fraud transaction \n* data_df[class]=1 fraud detection\n* ","b6c64592":"as per the graph we can say the ratio of genuine transaction is higher than fraud transactions.\n","8671264d":"Correlation metrice help us to understand the core relation between two attributes.\n","880ef4d6":"TO start with modelling first we need to split the dataset \n80% for train the model\n20% for test the model","fa7f561b":"From this amount distribution curve it is shown that the number high amount transaction are very low. So there is a high probability for huge transaction to be fraudulent","42cd3829":"# Accuracy Calculation","e9ce4ae6":"# Percentage of total not fraud transaction","606371af":"# Percebtage of total fraud detection"}}