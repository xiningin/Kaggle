{"cell_type":{"b7cc6aea":"code","e06093af":"code","0a4ab4b3":"code","c9245fbf":"code","0b92ee71":"code","7bfa0f76":"code","0865b9bb":"code","6413bd31":"code","1be4294a":"code","2fa1c0ba":"code","1589141a":"code","ee270c41":"code","a630d31d":"code","560a4223":"code","005c2467":"code","12f0334b":"code","9a292aca":"code","4c557961":"code","fa847d4f":"code","af6a53ce":"code","86f4ddd1":"code","57ffeab6":"code","cdf54370":"code","7a99f25f":"code","373a2bba":"code","ee4ce5d6":"code","37d60b50":"code","a7d8fe42":"code","ab157032":"code","61fae3dc":"code","02b67966":"code","69ec3fcf":"code","ccb21b59":"code","72405d6b":"code","a6c6da3f":"code","e10da039":"code","75a58105":"code","646583c9":"code","a04bc876":"code","e6d8e807":"code","7dbb70ab":"code","95dea7e2":"code","ee5d616f":"code","e7dba512":"code","732d72e9":"code","6a178cd4":"code","1749e675":"code","76a627e4":"code","4e7dc1b3":"code","0c92c228":"code","3ee859e2":"code","62a215b6":"code","d61aced9":"code","2dfabd3d":"code","29587b15":"code","1df222db":"code","63ebd96c":"code","107ebac4":"code","8b66843a":"code","0bce9960":"code","318207e7":"code","57a569fe":"code","e51c4d22":"code","893dc5ef":"code","c6aa8a51":"code","0f966515":"code","59c97671":"code","b0966140":"code","9ad9a8dd":"code","1732ba2e":"code","040c7f73":"code","c2bc62b7":"code","c7cfb26c":"code","21e1808b":"code","bcea4e09":"code","5498fb4c":"code","38275aad":"code","fdefd13b":"code","a3827e90":"code","aa359980":"code","2d22726c":"code","15d5ec9c":"code","21543013":"code","4f33bd3e":"code","ba4cc45c":"code","a38de75a":"code","e6d80b5e":"markdown","e6ed6314":"markdown","d07b366c":"markdown","895f614f":"markdown","21b7c939":"markdown","a63c20f2":"markdown","a32e196b":"markdown","8c7816e6":"markdown","9fbf0ce8":"markdown","1184b4bc":"markdown","d5c573b1":"markdown","8a7c2a5f":"markdown","5a8b6bb6":"markdown","9ff74cd4":"markdown","f69f74f1":"markdown","f05b0291":"markdown","ca334fd9":"markdown","7b741c50":"markdown","7f41cc2c":"markdown","238fb84d":"markdown","6b3158f9":"markdown","d102d333":"markdown","7985cb9e":"markdown","68996b6b":"markdown","3543dbb1":"markdown","841d6d65":"markdown","dd24e96a":"markdown","9c1d5b1e":"markdown","228888da":"markdown","a8b570b1":"markdown","49053cba":"markdown","6a3a6608":"markdown","1acba928":"markdown","259ea271":"markdown","2a68aa62":"markdown","1af63758":"markdown","91b37c04":"markdown","761dbceb":"markdown","1d3c42ec":"markdown","968d21b9":"markdown","1c7dab1c":"markdown","eaee7954":"markdown","0db7c0da":"markdown","382e7dc6":"markdown","620a3f7a":"markdown","51045836":"markdown","0602d767":"markdown","d0b66a10":"markdown","a4dc02c4":"markdown","2dd13396":"markdown","b43cb0f2":"markdown","520fcb6c":"markdown","dd0e14b5":"markdown","1e2a772c":"markdown","798effe4":"markdown","14b51de7":"markdown","e8ab824a":"markdown","1664ce60":"markdown","6b29a860":"markdown","2302e428":"markdown","e394f648":"markdown","12c11e50":"markdown","6c9ea559":"markdown","13c71bef":"markdown","5b37b0b4":"markdown","80cc4a98":"markdown","411a0c51":"markdown","1114ccac":"markdown","1d5d4a2b":"markdown"},"source":{"b7cc6aea":"import pandas as pd \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom catboost import Pool\n\nimport shap\n\nimport warnings\nwarnings.filterwarnings('ignore')","e06093af":"df = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","0a4ab4b3":"df","c9245fbf":"df.info()","0b92ee71":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\ndf['TotalCharges'].dtype","7bfa0f76":"df['TotalCharges'].isnull().sum()","0865b9bb":"df['tenure'].isin([0]).sum()","6413bd31":"print(df[df['tenure'].isin([0])].index)\nprint(df[df['TotalCharges'].isna()].index)","1be4294a":"df.loc[:,'TotalCharges'] = df.loc[:,'TotalCharges'].replace(np.nan,0)\ndf['TotalCharges'].isnull().sum()","2fa1c0ba":"df['SeniorCitizen'] = df['SeniorCitizen'].apply(str)\nsenior_map = {'0': 'No', '1': 'Yes'}\ndf['SeniorCitizen'] = df['SeniorCitizen'].map(senior_map)\n\ndf.info()","1589141a":"for col in df.select_dtypes('object').columns:\n    print(col, '- # unique values:', df[col].nunique())","ee270c41":"for col in df.select_dtypes('object').columns:\n    print(col, '\\n')\n    print(df[col].value_counts(), '\\n')","a630d31d":"df.describe().T","560a4223":"plt.figure(figsize=(6,4))\n\nax = sns.countplot(x=\"Churn\", data=df, palette=\"rocket\")\n\nplt.xlabel(\"Churn?\", fontsize= 12)\nplt.ylabel(\"# of Clients\", fontsize= 12)\nplt.ylim(0,7500)\nplt.xticks([0,1], ['No', 'Yes'], fontsize = 11)\n\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x()+0.30, p.get_height()+300), fontsize = 14)\n    \nplt.show()","005c2467":"plt.figure(figsize=(7,5))\n\ndf['Churn'].value_counts().plot(kind='pie',labels = ['',''], autopct='%1.1f%%', colors = ['indigo','salmon'], explode = [0,0.05], textprops = {\"fontsize\":15})\n\nplt.legend(labels=['No Churn', 'Churn'])\nplt.show()","12f0334b":"#Label encoding Churn to use sns.barplot\nle = LabelEncoder()\ndf['Churn'] = le.fit_transform(df['Churn'])\ndf['Churn'].value_counts()","9a292aca":"demo_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents']\n\nserv_features = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup'\n                , 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n\ncat_accinfo_features = ['Contract', 'PaperlessBilling', 'PaymentMethod']\n\nnum_accinfo_features = ['tenure', 'MonthlyCharges', 'TotalCharges']","4c557961":"plt.figure(figsize=(18,12))\n\nfor i,col in enumerate(demo_features):    \n    plt.subplot(2,2,i + 1)\n    \n    ax = sns.countplot(data = df, x = col, palette = 'rocket')\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"# of Clients\", fontsize= 13)\n    plt.ylim(0,7000)\n    plt.xticks(fontsize= 15)\n    plt.yticks(fontsize= 14)\n\n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.32, p.get_height()+300), fontsize= 16)\n\nplt.tight_layout()\n\nplt.show()","fa847d4f":"plt.figure(figsize=(18,12))\n\nfor i,col in enumerate(demo_features):    \n    plt.subplot(2,2,i + 1)\n    \n    ax = sns.countplot(data = df, x = col, hue=\"Churn\", palette = 'rocket')\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"# of Clients\", fontsize= 13)\n    plt.ylim(0,7000)\n    plt.xticks(fontsize= 14)\n    \n    plt.legend(title = 'Churn', fontsize='x-large', title_fontsize='17')\n    \n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.14, p.get_height()+300), fontsize= 14)\n\nplt.tight_layout()\n\nplt.show()","af6a53ce":"plt.figure(figsize=(16,10))\n\nfor i,col in enumerate(demo_features):    \n    plt.subplot(2,2,i + 1)\n    \n    ax = sns.barplot(x = col, y = \"Churn\", data = df, palette = 'rocket', ci = None)\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"% of Churn\", fontsize= 13)\n    plt.ylim(0,0.5)\n    plt.xticks(fontsize= 14)\n\n    for p in ax.patches:\n        ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.35, p.get_height()+0.03),fontsize=15)\n\nplt.tight_layout()\n\nplt.show()","86f4ddd1":"df.groupby(['Partner'])['Dependents'].value_counts()","57ffeab6":"df.groupby(by=['Partner', 'Dependents'])['Churn'].value_counts(normalize = True)","cdf54370":"plt.figure(figsize=(12,4))\n\nax = sns.barplot(x = \"Dependents\", y = \"Churn\", hue = \"Partner\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Churn\", fontsize= 12)\nplt.ylim(0,0.5)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.15, p.get_height()+0.03),fontsize=14)\n\nplt.show()","7a99f25f":"plt.figure(figsize=(18,30))\n\nfor i,col in enumerate(serv_features):    \n    plt.subplot(5,2,i + 1)\n    \n    ax = sns.countplot(data = df, x = col, palette = 'rocket')\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"# of Clients\", fontsize= 13)\n    plt.ylim(0,7500)\n    plt.xticks(fontsize= 15)\n    plt.yticks(fontsize= 14)\n\n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.31, p.get_height()+300), fontsize= 16)\n\nplt.tight_layout()\n\nplt.show()","373a2bba":"plt.figure(figsize=(18,30))\n\nfor i,col in enumerate(serv_features):    \n    plt.subplot(5,2,i + 1)\n    \n    ax = sns.countplot(data = df, x = col, hue=\"Churn\", palette = 'rocket')\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"# of Clients\", fontsize= 13)\n    plt.ylim(0,7000)\n    plt.xticks(fontsize= 14)\n    \n    plt.legend(title = 'Churn', fontsize='x-large', title_fontsize='17')\n\n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.12, p.get_height()+300), fontsize= 13)\n\nplt.tight_layout()\n\nplt.show()","ee4ce5d6":"plt.figure(figsize=(16,25))\n\nfor i,col in enumerate(serv_features):    \n    plt.subplot(5,2,i + 1)\n    \n    ax = sns.barplot(x = col, y = \"Churn\", data = df, palette = 'rocket', ci = None)\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"% of Churn\", fontsize= 13)\n    plt.ylim(0,0.5)\n    plt.xticks(fontsize= 14)\n\n    for p in ax.patches:\n        ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.32, p.get_height()+0.03),fontsize=15)\n\nplt.tight_layout()\n\nplt.show()","37d60b50":"df.groupby(by=['InternetService'])['MonthlyCharges'].mean().sort_values()","a7d8fe42":"print(df.groupby(by=['TechSupport'])['MonthlyCharges'].mean().sort_values(), '\\n')\nprint(df.groupby(by=['OnlineSecurity'])['MonthlyCharges'].mean().sort_values(), '\\n')\nprint(df.groupby(by=['OnlineSecurity', 'TechSupport'])['MonthlyCharges'].mean().sort_values())","ab157032":"print(df.groupby(by=['TechSupport'])['OnlineSecurity'].value_counts(), '\\n')","61fae3dc":"plt.figure(figsize=(12,4))\n\nax = sns.barplot(x = \"TechSupport\", y = \"Churn\", hue = \"OnlineSecurity\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Churn\", fontsize= 12)\nplt.ylim(0,1.0)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.070, p.get_height()+0.03),fontsize=14)\n\nplt.show()","02b67966":"plt.figure(figsize=(12,15))\n\nfor i,col in enumerate(cat_accinfo_features):    \n    plt.subplot(3,1,i + 1)\n    \n    ax = sns.countplot(data = df, x = col, palette = 'rocket')\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"# of Clients\", fontsize= 13)\n    plt.ylim(0,5000)\n    plt.xticks(fontsize= 14)\n    plt.yticks(fontsize= 14)\n\n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.32, p.get_height()+300), fontsize= 15)\n\nplt.tight_layout()\n\nplt.show()","69ec3fcf":"plt.figure(figsize=(12,15))\n\nfor i,col in enumerate(cat_accinfo_features):    \n    plt.subplot(3,1,i + 1)\n    \n    ax = sns.countplot(data = df, x = col, hue=\"Churn\", palette = 'rocket')\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"# of Clients\", fontsize= 13)\n    plt.ylim(0,5000)\n    plt.xticks(fontsize= 13)\n\n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.135, p.get_height()+300), fontsize= 14)\n\nplt.tight_layout()\n\nplt.show()","ccb21b59":"plt.figure(figsize=(12,15))\n\nfor i,col in enumerate(cat_accinfo_features):    \n    plt.subplot(3,1,i + 1)\n    \n    ax = sns.barplot(x = col, y = \"Churn\", data = df, palette = 'rocket', ci = None)\n\n    plt.xlabel(col, fontsize= 14)\n    plt.ylabel(\"% of Churn\", fontsize= 13)\n    plt.ylim(0,0.55)\n    plt.xticks(fontsize= 14)\n\n    for p in ax.patches:\n        ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.32, p.get_height()+0.02),fontsize=15)\n\nplt.tight_layout()\n\nplt.show()","72405d6b":"print(df.groupby(by=['Contract'])['PaperlessBilling'].value_counts(normalize = True),' \\n')\nprint(df.groupby(by=['Contract'])['PaymentMethod'].value_counts(normalize = True))","a6c6da3f":"plt.figure(figsize=(12,4))\n\nax = sns.barplot(x = \"PaperlessBilling\", y = \"Churn\", hue = \"Contract\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Churn\", fontsize= 12)\nplt.ylim(0,0.6)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.08, p.get_height()+0.03),fontsize=14)\n\nplt.show()","e10da039":"plt.figure(figsize=(12,4))\n\nax = sns.barplot(x = \"PaymentMethod\", y = \"Churn\", hue = \"Contract\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Churn\", fontsize= 12)\nplt.ylim(0,0.6)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.05, p.get_height()+0.020),fontsize=14)\n\nplt.show()","75a58105":"print(df.groupby(by=['InternetService'])['PaperlessBilling'].value_counts(normalize = True), '\\n')\nprint(df.groupby(by=['InternetService'])['PaymentMethod'].value_counts(normalize = True))","646583c9":"plt.figure(figsize=(12,15))\n\nfor i,col in enumerate(num_accinfo_features):    \n    plt.subplot(3,1,i + 1)\n    sns.distplot(df.loc[:,col])\n    #plt.ticklabel_format(style='plain', axis='x') #repressing scientific notation    \n    plt.ylabel('')\n    plt.tight_layout()\n\nplt.show()","a04bc876":"plt.figure(figsize=(12,15))\n\nfor i,col in enumerate(num_accinfo_features):    \n    plt.subplot(3,1,i + 1)    \n    sns.kdeplot(df.loc[(df['Churn'] == 0), col], label = 'No Churn', shade = True)\n    sns.kdeplot(df.loc[(df['Churn'] == 1), col], label = 'Churn', shade = True)\n    plt.legend()\n    plt.ylabel('')\n    plt.tight_layout()\n\nplt.show()","e6d8e807":"print(df.groupby(by=['Churn'])['tenure'].mean().sort_values(), '\\n')\nprint(df.groupby(by=['Churn'])['MonthlyCharges'].mean().sort_values(), '\\n')\nprint(df.groupby(by=['Churn'])['TotalCharges'].mean().sort_values())","7dbb70ab":"df['tenure_bin'] = pd.cut(df['tenure'],[-1,12,24,36,48,60,100])\ndf['tenure_bin'].value_counts(sort = False)","95dea7e2":"plt.figure(figsize=(12,4))\n\nax = sns.barplot(x = \"tenure_bin\", y = \"Churn\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Churn\", fontsize= 12)\nplt.ylim(0,0.6)\nplt.xticks([0,1,2,3,4,5], ['12 or less', '13 to 24', '25 to 36', '37 to 48', '49 to 60', 'more than 60'], fontsize = 12)\nplt.xlabel(\"Tenure Group (in months)\", fontsize= 12)\n\n\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.25, p.get_height()+0.03),fontsize=14)\n\nplt.show()","ee5d616f":"X = df.copy().drop('Churn', axis = 1)\nY = df['Churn'].copy()","e7dba512":"X = X.drop(['customerID', 'tenure_bin'], axis = 1)\nX","732d72e9":"X.info()","6a178cd4":"gender_map = {'Female': 0, 'Male': 1}\nyes_or_no_map = {'No': 0, 'Yes': 1} #seniorcitizen, partner, dependents, phoneservice, paperlessbilling\nmultiplelines_map = {'No phone service': -1, 'No': 0, 'Yes': 1}\ninternetservice_map = {'No': -1, 'DSL': 0, 'Fiber optic': 1}\nadd_netservices_map = {'No internet service': -1, 'No': 0, 'Yes': 1} #onlinesecurity, onlinebackup, deviceprotection,techsupport,streaming services\ncontract_map = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\npaymentmethod_map = {'Electronic check': 0, 'Mailed check': 1, 'Bank transfer (automatic)': 2, 'Credit card (automatic)': 3}\n\n\nX['gender'] = X['gender'].map(gender_map).astype('int')\nX['Partner'] = X['Partner'].map(yes_or_no_map).astype('int')\nX['SeniorCitizen'] = X['SeniorCitizen'].map(yes_or_no_map).astype('int')\nX['Dependents'] = X['Dependents'].map(yes_or_no_map).astype('int')\nX['PhoneService'] = X['PhoneService'].map(yes_or_no_map).astype('int')\nX['MultipleLines'] = X['MultipleLines'].map(multiplelines_map).astype('int')\nX['InternetService'] = X['InternetService'].map(internetservice_map).astype('int')\nX['OnlineSecurity'] = X['OnlineSecurity'].map(add_netservices_map).astype('int')\nX['OnlineBackup'] = X['OnlineBackup'].map(add_netservices_map).astype('int')\nX['DeviceProtection'] = X['DeviceProtection'].map(add_netservices_map).astype('int')\nX['TechSupport'] = X['TechSupport'].map(add_netservices_map).astype('int')\nX['StreamingTV'] = X['StreamingTV'].map(add_netservices_map).astype('int')\nX['StreamingMovies'] = X['StreamingMovies'].map(add_netservices_map).astype('int')\nX['Contract'] = X['Contract'].map(contract_map).astype('int')\nX['PaperlessBilling'] = X['PaperlessBilling'].map(yes_or_no_map).astype('int')\nX['PaymentMethod'] = X['PaymentMethod'].map(paymentmethod_map).astype('int')\n","1749e675":"X.info()","76a627e4":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42\n                                                    , stratify = Y)","4e7dc1b3":"num_features = num_accinfo_features\n\ncat_3p_features = []\nfor col in X.columns:\n    if (X[col].nunique() > 2) & (X[col].nunique() < 5):  #less than 5 to exclude the numerical features\n        cat_3p_features.append(col)\nprint('Numerical features: ', num_features, '\\n')        \nprint('Nominal with 3 or more categories: ', cat_3p_features)","0c92c228":"cat_transformer = OneHotEncoder(handle_unknown='ignore')\nnum_transformer = StandardScaler()\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, num_features),\n        ('cat', cat_transformer, cat_3p_features)      \n    ], remainder='passthrough')","3ee859e2":"lr_pipe = Pipeline([('Transformers', preprocessor)\n                        ,('LR',  LogisticRegression(random_state = 42, max_iter = 1000))])","62a215b6":"def cv_function (model, param, list):\n    \n    rp_st_kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats = 3, random_state = 42)\n    search_model = model\n    print ('Hyperparameter: ', param)\n    \n    for i in list:\n        param_dict = {param : i}\n        search_model.set_params(**param_dict)    \n        cv_score = cross_val_score(search_model, X_train, Y_train, cv=rp_st_kfold, scoring='roc_auc')\n        print(\"Parameter: {0:0.2f} - AUC(SD): {1:0.4f} ({2:0.4f})\". format(i, cv_score.mean(), cv_score.std()))\n        \nparams_lr_list = [0.01,0.1,0.2,0.3,0.5,0.7,1,2,3,5]\nparam_lr = 'LR__C'\ncv_function(lr_pipe, param_lr, params_lr_list)","d61aced9":"lr_param = {'LR__C': 3.0}\nlr_pipe.set_params(**lr_param) \nlr_pipe","2dfabd3d":"lr_pipe.fit(X_train, Y_train)\npred_lr = lr_pipe.predict(X_test)\n\nprint(\"Test Accuracy: \",metrics.accuracy_score(Y_test, pred_lr))\nprint(\"Test F1 Score: \",metrics.f1_score(Y_test, pred_lr))","29587b15":"lr_confusion_matrix = metrics.confusion_matrix(Y_test, pred_lr)\nsns.heatmap(lr_confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","1df222db":"print(metrics.classification_report(Y_test, pred_lr, labels = [0, 1]))","63ebd96c":"lr_pred_proba = lr_pipe.predict_proba(X_test)[:,1]\n\nlr_roc_auc = metrics.roc_auc_score(Y_test, lr_pred_proba)\nprint('ROC_AUC: ', lr_roc_auc)\n\nlr_fpr, lr_tpr, thresholds = metrics.roc_curve(Y_test, lr_pred_proba)\n\nplt.plot(lr_fpr,lr_tpr, label = 'ROC_AUC = %0.3f' % lr_roc_auc)\n\nplt.xlabel(\"False Positive Rate\", fontsize= 12)\nplt.ylabel(\"True Positive Rate\", fontsize= 12)\nplt.legend(loc=\"lower right\")\n\nplt.show()","107ebac4":"rf_model = RandomForestClassifier(random_state = 42)\n\nparams_rf_list = [100,150,200,250,300,400,500]\nparam_rf = 'n_estimators'\ncv_function(rf_model, param_rf, params_rf_list)","8b66843a":"rf_param = {'n_estimators': 500}\nrf_model.set_params(**rf_param) \nrf_model","0bce9960":"rf_model.fit(X_train, Y_train)\npred_rf = rf_model.predict(X_test)\n\nprint(\"Test Accuracy: \",metrics.accuracy_score(Y_test, pred_rf))\nprint(\"Test F1 Score: \",metrics.f1_score(Y_test, pred_rf))","318207e7":"rf_confusion_matrix = metrics.confusion_matrix(Y_test, pred_rf)\nsns.heatmap(rf_confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","57a569fe":"print(metrics.classification_report(Y_test, pred_rf, labels = [0, 1]))","e51c4d22":"rf_pred_proba = rf_model.predict_proba(X_test)[:,1]\n\nrf_roc_auc = metrics.roc_auc_score(Y_test, rf_pred_proba)\nprint('ROC_AUC: ', rf_roc_auc)\n\nrf_fpr, rf_tpr, thresholds = metrics.roc_curve(Y_test, rf_pred_proba)\n\nplt.plot(rf_fpr,rf_tpr, label = 'ROC_AUC = %0.3f' % rf_roc_auc)\n\nplt.xlabel(\"False Positive Rate\", fontsize= 12)\nplt.ylabel(\"True Positive Rate\", fontsize= 12)\nplt.legend(loc=\"lower right\")\n\nplt.show()","893dc5ef":"rf_pipe = Pipeline([('Transformers', preprocessor)\n                        ,('RF',  RandomForestClassifier(n_estimators = 500, random_state = 42))])\n\nrf_pipe.fit(X_train, Y_train)\npred_rf_pipe = rf_pipe.predict(X_test)\n\nprint(\"Test Accuracy: \",metrics.accuracy_score(Y_test, pred_rf_pipe))\nprint(\"Test F1 Score: \",metrics.f1_score(Y_test, pred_rf_pipe))","c6aa8a51":"rf_pipe_confusion_matrix = metrics.confusion_matrix(Y_test, pred_rf_pipe)\nsns.heatmap(rf_pipe_confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","0f966515":"print(metrics.classification_report(Y_test, pred_rf_pipe, labels = [0, 1]))","59c97671":"rf_pipe_pred_proba = rf_pipe.predict_proba(X_test)[:,1]\n\nrf_pipe_roc_auc = metrics.roc_auc_score(Y_test, rf_pipe_pred_proba)\nprint('ROC_AUC: ', rf_pipe_roc_auc)\n\nrf_pipe_fpr, rf_pipe_tpr, thresholds = metrics.roc_curve(Y_test, rf_pipe_pred_proba)\n\nplt.plot(rf_pipe_fpr,rf_pipe_tpr, label = 'ROC_AUC = %0.3f' % rf_pipe_roc_auc)\n\nplt.xlabel(\"False Positive Rate\", fontsize= 12)\nplt.ylabel(\"True Positive Rate\", fontsize= 12)\nplt.legend(loc=\"lower right\")\n\nplt.show()","b0966140":"xgb_model = XGBClassifier(learning_rate = 0.05 ,random_state = 42, eval_metric = 'logloss')\n\nparams_xgb_list = [50,75,100,150,200,250]\nparam_xgb = 'n_estimators'\ncv_function(xgb_model, param_xgb, params_xgb_list)","9ad9a8dd":"xgb_param = {'n_estimators': 75}\nxgb_model.set_params(**xgb_param) \nxgb_model","1732ba2e":"xgb_model.fit(X_train, Y_train, eval_set = [(X_test,Y_test)])\n\npred_xgb = xgb_model.predict(X_test)","040c7f73":"print(\"Test Accuracy: \",metrics.accuracy_score(Y_test, pred_xgb))\nprint(\"Test F1 Score: \",metrics.f1_score(Y_test, pred_xgb))","c2bc62b7":"xgb_confusion_matrix = metrics.confusion_matrix(Y_test, pred_xgb)\nsns.heatmap(xgb_confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","c7cfb26c":"print(metrics.classification_report(Y_test, pred_xgb, labels = [0, 1]))","21e1808b":"xgb_pred_proba = xgb_model.predict_proba(X_test)[:,1]\n\nxgb_roc_auc = metrics.roc_auc_score(Y_test, xgb_pred_proba)\nprint('ROC_AUC: ', xgb_roc_auc)\n\nxgb_fpr, xgb_tpr, thresholds = metrics.roc_curve(Y_test, xgb_pred_proba)\n\nplt.plot(xgb_fpr,xgb_tpr, label = 'ROC_AUC = %0.3f' % xgb_roc_auc)\n\nplt.xlabel(\"False Positive Rate\", fontsize= 12)\nplt.ylabel(\"True Positive Rate\", fontsize= 12)\nplt.legend(loc=\"lower right\")\n\nplt.show()","bcea4e09":"categorical_ft = [x for x in X.columns if x not in num_features]\nprint(categorical_ft)","5498fb4c":"cat_model = CatBoostClassifier (random_state = 42, eval_metric = 'AUC', cat_features = categorical_ft, verbose = 0)\n\n#cat_model.get_params()\n\nparams_cat_list = [50,75,100,150,200,250]\nparam_cat = 'n_estimators'\ncv_function(cat_model, param_cat, params_cat_list)","38275aad":"cat_param = {'n_estimators':100}\ncat_model.set_params(**cat_param) \n#cat_model","fdefd13b":"cat_model.fit(X_train, Y_train, eval_set = [(X_test,Y_test)], cat_features = categorical_ft)\n\npred_cat = cat_model.predict(X_test)\n\nprint(\"Test Accuracy: \",metrics.accuracy_score(Y_test, pred_cat))\nprint(\"Test F1 Score: \",metrics.f1_score(Y_test, pred_cat))","a3827e90":"cat_confusion_matrix = metrics.confusion_matrix(Y_test, pred_cat)\nsns.heatmap(cat_confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","aa359980":"print(metrics.classification_report(Y_test, pred_cat, labels = [0, 1]))","2d22726c":"cat_pred_proba = cat_model.predict_proba(X_test)[:,1]\n\ncat_roc_auc = metrics.roc_auc_score(Y_test, cat_pred_proba)\nprint('ROC_AUC: ', cat_roc_auc)\n\ncat_fpr, cat_tpr, thresholds = metrics.roc_curve(Y_test, cat_pred_proba)\n\nplt.plot(cat_fpr,cat_tpr, label = 'ROC_AUC = %0.3f' % cat_roc_auc)\n\nplt.xlabel(\"False Positive Rate\", fontsize= 12)\nplt.ylabel(\"True Positive Rate\", fontsize= 12)\nplt.legend(loc=\"lower right\")\n\nplt.show()","15d5ec9c":"pool = Pool(X_train, Y_train, cat_features=categorical_ft)\n\nFeature_importance = pd.DataFrame({'feature_importance': cat_model.get_feature_importance(pool), \n                      'feature_names': X_train.columns}).sort_values(by=['feature_importance'], \n                                                           ascending=False)\n\nFeature_importance","21543013":"plt.figure(figsize=(10,10))\n\nsns.barplot(x=Feature_importance['feature_importance'], y=Feature_importance['feature_names'], palette = 'rocket')\n\nplt.show()","4f33bd3e":"explainer = shap.TreeExplainer(cat_model)\nshap_values = explainer.shap_values(pool)\n\nshap.summary_plot(shap_values, X_train)","ba4cc45c":"custom_th_pred= np.where(cat_pred_proba>0.250, 1, 0)\nprint(metrics.classification_report(Y_test, custom_th_pred, labels = [0, 1], digits = 3))","a38de75a":"prob_confusion_matrix = metrics.confusion_matrix(Y_test, custom_th_pred)\nsns.heatmap(prob_confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","e6d80b5e":"Now, let's move on to the predictive models. In this notebook, we will use the Area Under the Curve of Receiver Characteristic Operator (AUC-ROC or ROC-AUC) as the main metric to assess the performance of our models. The ROC-AUC measures the ability of a model is to distinguish between classes. [(Link for more information about ROC-AUC)](https:\/\/www.analyticsvidhya.com\/blog\/2020\/06\/auc-roc-curve-machine-learning\/). Nevertheless, we will also check the accuracy and the F1-Score, plus the classification report and the confusion matrix for each model.\n\nFirst, we will make a copy of the dataset and separate the features from the target.","e6ed6314":"## <a id=\"31\">Demographic Features<\/a> ","d07b366c":"A relatively small group of customers doesn\u2019t have internet services and an even smaller one doesn\u2019t have phone services. One thing to keep in mind is that most services can be and\/or are only provided to customers who sign the Telco\u2019s internet service.","895f614f":"Results (AUC\/accuracy\/F1-Score):\n- Logistic Regression: 0.842\/0.807\/0.608\n- Random Forest: 0.825\/0.788\/0.554\n- Random Forest w\/preprocessing: 0.823\/0.780\/0.545\n- XGBoost: 0.846\/0.806\/0.599\n- Catboost: 0.849\/0.813\/0.611","21b7c939":"## <a id=\"46\">Feature Importance and SHAP Plot<\/a>","a63c20f2":"Curiously enough, the difference of churn between clients with and without phone services is quite small, been negligible if we take those with multiple lines out of equation. In this group of features, the real game-changing ones in terms of customer retainment are those related to internet services.\n\nIn the feature \u2018InternetServices\u2019, the percentage of churn in each category is highly different one from another. Those who don\u2019t subscribe to the company\u2019s internet (presumably, they only use their phone service), are the most likely to endure as their customers. The likelihood of churn from customers with DSL service is also smaller than the overall probability. \n\nThe highest percentage of churn, with over 40%, is from customers with fiber optic internet. Fiber optic tends to be faster than DSL internet, but their subscription is usually more expensive as well. We don't have the information about the fee for each service, but at least we can find the mean value of monthly charges per type of internet just to have an idea that this is the case.\n","a32e196b":"## <a id=\"33\">Account Information Features (categorical)<\/a> ","8c7816e6":"As expected, the average tenure period for churned customers is lower and the average monthly charges are higher than the same metrics for retained customers. The average total charges are lower for churned customers, which is probably due to their lower tenure.\n\nThe density plot for churned customers in the \u2018tenure\u2019 feature showed a high concentration in the first months. Let\u2019s divide this feature in bins to get the churn rate per year of service.","9fbf0ce8":"# <a id=\"5\">References<\/a>","1184b4bc":"\n### Content\n\n\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n\nEach row represents a customer, each column contains customer\u2019s attributes described on the column Metadata.\n\nThe data set includes information about:\n\n- Customers who left within the last month \u2013 the column is called Churn\n- Services that each customer has signed up for \u2013 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n- Customer account information \u2013 how long they\u2019ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n- Demographic info about customers \u2013 gender, age range, and if they have partners and dependents","d5c573b1":"## <center> If you find this notebook useful, support with an upvote! <center>","8a7c2a5f":"## <center> If you find this notebook useful, support with an upvote! <center>","5a8b6bb6":"We can divide the features into the following groups:\n- Demographic features;\n- Service-related features\n- Account information related features (categorical and numerical).\n\nFor each group, we\u2019ll start by looking at the features\u2019 distributions. Then, we\u2019ll check the percentage of churn for each category to understand their relationship with the target.","9ff74cd4":"## Churn","f69f74f1":"To better interpret the model\u2019s results, and maybe gain some insights, we can use the SHAP package [(link)](https:\/\/shap.readthedocs.io\/en\/latest\/example_notebooks\/tabular_examples\/tree_based_models\/Catboost%20tutorial.html).","f05b0291":"We need to encode the features to use them in our models. We could use something like sklearn\u2019s OrdinalEncoder for this, but I\u2019ll do it manually. This effort will pay off later when we\u2019ll analyze the predictions using SHAP.","ca334fd9":"The results we found with Random Forest were quite disappointing. Although feature scaling and one hot encoding aren\u2019t necessary, we can use them just for testing purposes.","7b741c50":"Now we will split the data into train and test sets.","7f41cc2c":"We\u2019re also going to remove the customer_id and the feature \u2018tenure_bin\u2019, that we created for EDA purposes, since we\u2019re not planning to use them","238fb84d":"Let's finish this section by checking the possible values of categorical features and viewing descriptive statistics (df.describe) for numerical features.","6b3158f9":"We can see that both features contribute to the likelihood of churn. The group of people with partners and dependents and the group with neither of those are on the extremes in terms of likelihood of churn (14% and 34%, respectively). The churn of customers with partners and without dependents falls close to the overall percentage of churn in our dataset, while the \u2018opposite\u2019 group still have a lower chance of it.","d102d333":"# <a id=\"2\">Importing Packages and Dataset + Data Cleaning<\/a> ","7985cb9e":"## <a id=\"34\">Account Information Features (numerical)<\/a> ","68996b6b":"We will start our EDA by looking at the distribution of the target variable (Churn). It\u2019s expected that the dataset is imbalanced, with less than 50% of the customers leaving the company.","3543dbb1":"The three features that have the most impact on the model\u2019s predictions are related to the account information (Contract, Monthly Chargers and Tenure). \n\nAmong the service-related features, the most important are \u2018Tech Support\u2019 and \u2018Online Security\u2019. Per our encoding, the purple color represents the clients who subscribe to Telco\u2019s internet, but don\u2019t have the mentioned additional service. We can see that the model assigns a higher probability of churn to those customers. This result follows what we discovered on the EDA stage and highlights the discussion about new strategies involving those services.\n\nAmong the demographic features, \u2018Senior Citizen\u2019 and \u2018Dependents\u2019 have some significative impact on the model\u2019s predictions.","841d6d65":"What we can observe for each feature:\n- Gender: There is barely any difference in churn percentage between men and women;\n- Senior Citizen: The churn percentage for senior customers are above 40%, indicating a high likelihood of churn from that group;\n- Partner: Single customers are more likely to churn than customers with partners;\n- Dependents: Customers with dependents are less likely to churn than customers without any dependents.\n\nWe could go a little further and combine the two \u2018family-related\u2019 features, \u2018Partner\u2019 and \u2018Dependents\u2019 to see if, in fact, both of them contribute to the chance of customer churn or retention.\n\nIt is expected that the majority of customers with dependents are married and, for instance, it could be that the partnership has more influence on the target than the fact that a customer has or hasn\u2019t a child.  Although this might be unlikely, by analyzing both features together, we can discard such hypothesis with more confidence.","dd24e96a":"# <a id=\"1\">Dataset Information<\/a> ","9c1d5b1e":"# <a id='0'>Content<\/a>\n\n- <a href='#1'>Dataset Information<\/a>  \n- <a href='#2'>Importing Packages and Dataset + Data Cleaning<\/a>  \n- <a href='#3'>Exploratory Data Analysis<\/a>  \n    - <a href='#31'>Demographic Features<\/a>  \n    - <a href='#32'>Services Related Features<\/a>\n    - <a href='#33'>Account Information Features (categorical)<\/a>\n    - <a href='#34'>Account Information Features (numerical)<\/a>\n- <a href='#4'>Creating and Evaluating Models<\/a>\n    - <a href='#41'>Logistic Regression<\/a> \n    - <a href='#42'>Random Forest<\/a>\n    - <a href='#43'>Random Forest w\/preprocessing<\/a>\n    - <a href='#44'>XGBoost<\/a> \n    - <a href='#45'>CatBoost<\/a> \n    - <a href='#46'>Feature Importance and SHAP Plot<\/a>\n    - <a href='#47'>About Class Imbalance<\/a>     \n- <a href='#5'>References<\/a>","228888da":"## <a id=\"45\">Catboost<\/a> ","a8b570b1":"What we can observe for each feature:\n- Tenure: High concentration of churned customer in the first months.\n- Monthly Charges: High concentration of churned customer in higher values (around 60 and beyond)\n- Total Charges: Somewhat similar distributions, but the \u2018No churn\u2019 distribution have lower values.\n\nLet\u2019s get the mean values to complement our analysis.","49053cba":"The Catboost yielded the best results, although they were quite close from those obtained with XGBoost and Logistic Regression.","6a3a6608":"# <a id=\"4\">Creating and Evaluating Models<\/a>","1acba928":"Apparently, there are no missing values. But there is clearly an error. \u2018Total Charges\u2019 should be numeric. We can use pd.to_numeric to convert it.","259ea271":"Naturally, in terms of contract, the highest churn rate is from the \u2018month-to-month\u2019 type, which is also the most dominant contract. What seems odd is the high chance of churn from customers who choose electronic check as payment method and opts for paperless billing. It could be, for instance, that most customers in the month-to-month contract also fall into those categories. We can check that.","2a68aa62":"Even without the intent of doing an extensive hyperparameter tuning, we can give each model a better chance of good performance by testing some values for a key parameter and choosing one of them based on cross-validation score.","1af63758":"<br>\n<h1 style = \"font-size:30px; font-weight : bold; color : blue; text-align: center; border-radius: 10px 15px;\"> Telco Customer Churn: EDA, Predictions and Feature Importance with SHAP <\/h1>\n<br>","91b37c04":"After some point, there is barely an improvement. Choice: C = 3.0","761dbceb":"At the period represented in this dataset, there is a 26,5% rate of customer churn. As we move on to analyze the features, we can compare this number with the percentage of churn found for each category, providing us a better idea on the impact of a given feature in the company\u2019s ability to retain its customers.","1d3c42ec":"After changing a column from string to numeric, some values may not be recognized, resulting in missing values. Let\u2019s check if this happened.","968d21b9":"It did not go too well either. Let\u2019s move on to the boosting models.","1c7dab1c":"## <a id=\"42\">Random Forest<\/a> ","eaee7954":"# Goals\nPerform an Exploratory Data Analysis (EDA) to visualize and understand:\n* The distribution of values of the target and features;\n* The relationship between each feature and the likelihood of customer churn.\n\nPredict churn using 20% of data as test set using the following models:\n* Logistic Regression;\n* Random Forest;\n* XGBoost;\n* Catboost.\n\nUnderstand how each feature impacts the predicted value using:\n* Feature Importance;\n* SHAP.","0db7c0da":"We were able to find a recall of 82.4%, against less than 56% from the original predictions. Of course, there is a tradeoff involved. Reducing the threshold comes with the downside of losing precision. Yet, the F1-score was also better with the custom threshold (0.634 vs 0.611).","382e7dc6":"## <a id=\"47\">About Class Imbalance<\/a>","620a3f7a":"- https:\/\/www.analyticsvidhya.com\/blog\/2020\/06\/auc-roc-curve-machine-learning\/\n- https:\/\/shap.readthedocs.io\/en\/latest\/example_notebooks\/tabular_examples\/tree_based_models\/Catboost%20tutorial.html","51045836":"Both services don\u2019t seem to affect the subscription charges by much. If the company can quantify the cost of providing each service per customer and find out that it is relatively small, they could either reduce the extra subscription fee for those additional services or simply cut that fee and offer those services as standard for internet customers for a trial period. Given that most customers don\u2019t subscribe to those services and given that they have a significant impact on the customer retainment, it\u2019s possible that such strategy could result in a higher profit on the long term.\n\nLet\u2019s see if the churn rate gets significantly lower for customers who have access to both services.","0602d767":"Almost 50 percent of those who became a customer for a year or less ended up leaving the company. It\u2019s not unusual to have a higher churn rate in the first year or two for some types of business. Nevertheless, a churn rate this high in the first year indicates that the quality of the service provided fails to hold up to their new customers\u2019 expectation.","d0b66a10":"The first model we're going to use is Logistic Regression, which will require two things for a better performance:\n- Scaling the numerical features;\n- (One hot) encoding the categorical (nominal) features.\n\nWe can use the Column Transformer to assign each transformation to its correct features and fit it in a pipeline as a preprocessing step.","a4dc02c4":"Let\u2019s see what features have more importance for the Catboost\u2019s predictions.","2dd13396":"What stands out here in our grouping operations:\n- Customers with Internet Service = \u2018No\u2019: Less than 30% receive paperless bills and only 8% pay them with electronic check;\n- Customers with Internet Service = \u2018Fiber Optic\u2019: 77% receive paperless bills and more them 51% pay them with electronic check.\n\nWe can recall that the lowest churn rate in the internet services feature is from those customers who don\u2019t use Telco\u2019s internet, while the highest is found among those who use their fiber optic internet. So, we can say that those results don\u2019t come out as a surprise. \n\nAlthough we shouldn\u2019t conclude that the payment method or the way the bills are sent have a direct influence in the customer retainment, it is worth to point that those features will probably be useful for our prediction models.","b43cb0f2":"## <a id=\"41\">Logistic Regression<\/a> ","520fcb6c":"<img src=\"https:\/\/cdn.radiall.com\/media\/contenttype\/insights\/\/iStock-878803262.jpg\" width=\"620\" height=\"360\" align=\"center\"\/>","dd0e14b5":"When we group the dataset by contract, we can see that the percentage of customers who don\u2019t receive their bills through the mail and that pay them via electronic check is higher for the \u2018month-to-month\u2019 type. Yet, this doesn\u2019t seem to be enough to justify such a high churn rate for those categories. There is a good chance that we will find higher percentages of churn in them, regardless of the type of contract. Let\u2019s see.","1e2a772c":"This notebook will be updated on a near feature to present how we can optimize the threshold. For now, I\u2019ll be showing a quick example of how using a custom threshold can affect the classification metrics.\n\nLet\u2019s get the probabilities found by the CatBoost and classify the test set using a threshold of 25%.","798effe4":"As shown in the beginning of the EDA stage, the dataset is imbalanced. 26,5% of the samples represent customers who left in the last month. Such imbalance is somewhat expected, given the nature of this problem, but it comes with issue that the predictions will be biased towards the majority class. \nNeither one of the models were able to reach a recall of 56%+, which means that if we were to use the \u2018hard\u2019 (0 or 1) predictions to target customers that were close to churn, we would miss almost half of them. There are a few options to deal with class imbalance, such as:\n\n-\tApply Oversampling\/Undersampling: Generate new samples for the minority class or remove some samples from the majority class in order to have a balanced dataset;\n-\tTune the \u2018class weighting\u2019 hyperparameter: Some models have a specific hyperparameter (e.g.: XGBoost\u2019s \u2018scale_pos_weight\u2019) which can be used to assign a higher weight to the misclassification of a minority class sample;\n-\tAdjust the classification threshold: The default threshold for binary classification models is 50%. Instead of using the hard predictions, we can get the probabilities of churn for each sample and classify them based on a custom threshold.\n\nThe last technique, although simple, can be quite effective depending on the goal. We can tune the threshold, for instance, to optimize the F1 score or to find the best recall at a minimum expected value for precision. \n","14b51de7":"## <a id=\"43\">Random Forest with Preprocessing<\/a> ","e8ab824a":"The differences in terms of churn rate are quite significant. While customers who don\u2019t use neither of those services have a close to 50% chance of churn, the churn rate for those who have both is lower than 10%, supporting the previous point.","1664ce60":"Now, let\u2019s fit this model and predict.","6b29a860":"The feature 'Senior Citizen', which is categorical ('Yes' or 'No'), is set as numeric. Although all features will be changed to numeric to be used in our prediction models, I'll convert it from numeric to string for now.","2302e428":"Now there are supposedly 11 missing values, but they might indicate that there were no charges for that customer up to the point when the data was obtained. The feature 'tenure' indicates for how long someone has been a customer. Let's check the number of samples with value '0' on that feature and, in case we also find 11 customers, compare if their index match those from the 'missing' values.","e394f648":"We got a match here. After confirming our suspects, we can replace those missing values with '0'.","12c11e50":"The likelihood of churn is, in fact, higher for those categories, regardless of type of contract. Personally, is hard for me to see a causality, without additional information or domain knowledge, between the churn rate and the way someone receives their bill and choose to pay them. It is more likely that those two features are associated with several others. The internet service, a feature with notable differences of churn rate between each one of its categories, could present some correlation between them.","6c9ea559":"## <a id=\"32\">Services Related Features<\/a> ","13c71bef":"As expected, most customers with dependents also have a partner. Yet, the number of single customers with dependents seems significant enough for us to draw some conclusions about this particular group.","5b37b0b4":"## <a id=\"44\">XGBoost<\/a> ","80cc4a98":"# <a id=\"3\">Exploratory Data Analysis<\/a> ","411a0c51":"As expected, the average charges for each service are significantly different, with fiber optic been the most expensive. Without any additional information, it\u2019s hard to draw definitive conclusions, but it seems that the cost-benefit relationship of their fiber optic service is far from been attractive enough to retain customers.\n\nSuch a high churn rate might indicate that their service\u2019s quality is subpar in terms of speed and\/or reliability. Analyzing complaints received by their customer service call center service to extract useful and specific information about their internet is a must. A survey with a significant group of customers, aiming to understand how they perceive the quality of the service, is another step to find the problem and to help defining the course of action.\n\nAs for the other services, the likelihood of churn from customers who have each one of them is actually lower than from those who haven\u2019t. The higher differences are found in \u2018TechSupport\u2019 and \u2018OnlineSecurity\u2019, while the lower ones are found in the streaming services.\n\nLet\u2019s calculate the average monthly charges from each category in the Tech Support and Online Security features.","1114ccac":"For every model, we\u2019re going to follow the same steps that we made with Logistic Regression, with the exception of using a pipeline for preprocessing.","1d5d4a2b":"Since we manually encoded the categorical features, it becomes easier to understand what\u2019s been represented in each category. For instance, the feature \u2018contract\u2019 has 3 categories. \u2018Month-to-month\u2019 was encoded with the lowest value and it\u2019s represented by the blue color. \u2018One year\u2019 is the mid value and it\u2019s represented in purple. \u2018Two years\u2019 is the highest value and is represented in red. We can clearly see that the \u2018month-to-month\u2019 category impacts the prediction towards the positive value (churn), while the other types of contracts push the prediction into the opposite direction (no churn)."}}