{"cell_type":{"c0b4666e":"code","0b22f211":"code","ac5fd92a":"code","186fb466":"code","f00d1529":"code","5ed4e909":"code","596075fe":"code","bdb40b2d":"code","a420fdd6":"code","c383e427":"code","dc1e1218":"code","01921bc4":"code","e2f99c84":"code","924f852d":"code","17ab4ed2":"code","74a94c07":"code","4ff8b001":"code","e873d419":"code","01f54c84":"code","e3458cca":"code","35d04fab":"code","709a055d":"code","7183f7cf":"code","f8393316":"code","987ec5bf":"code","aad2e6fb":"code","e2612253":"code","6cb3708e":"markdown","14385bf8":"markdown","8e6b2c93":"markdown","87441566":"markdown"},"source":{"c0b4666e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom tqdm import tqdm\nimport json\n\nimport re\nfrom gensim.parsing.preprocessing import remove_stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.stem.porter import PorterStemmer\n\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","0b22f211":"train_df = pd.read_csv(\"..\/input\/coleridgeinitiative-show-us-the-data\/train.csv\")","ac5fd92a":"train_df.head()","186fb466":"train_df.info()","f00d1529":"sample_df = pd.read_csv(\"..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\")","5ed4e909":"sample_df.head()","596075fe":"test_path = \"..\/input\/coleridgeinitiative-show-us-the-data\/test\"\nall_test_path = [os.path.join(test_path,s) + \".json\" for s in sample_df[\"Id\"]]","bdb40b2d":"alltexts = []\n\nfor json_path in tqdm(all_test_path):\n\n    with open(json_path, 'r') as f:\n            json_decode = json.load(f)\n    jsontest = pd.DataFrame(json_decode)\n\n    texts = \"\"\n\n    for a in jsontest.values:\n        texts += a[0] + \" \" + a[1] + \" \"\n        \n    alltexts.append(texts)","a420fdd6":"sample_df[\"text\"] = alltexts","c383e427":"train_path = \"..\/input\/coleridgeinitiative-show-us-the-data\/train\"\nall_train_path = [os.path.join(train_path,s) + \".json\" for s in train_df[\"Id\"]]","dc1e1218":"alltexts = []\n\nfor json_path in tqdm(all_train_path):\n\n    with open(json_path, 'r') as f:\n            json_decode = json.load(f)\n    jsontest = pd.DataFrame(json_decode)\n\n    texts = \"\"\n\n    for a in jsontest.values:\n        texts += a[0] + \" \" + a[1] + \" \"\n        \n    alltexts.append(texts)","01921bc4":"train_df[\"text\"] = alltexts","e2f99c84":"cleaned = list(train_df['cleaned_label'])\n\ncleans = []\n\nfor i in cleaned:\n    i = list(i.split(\" \"))\n    for j in i:\n        cleans.append(j.replace(\" \", \"\"))\n\ncln = Counter(cleans)","924f852d":"clns = list(set(cln))\nplt.rcParams['figure.figsize'] = (15,15)\nwordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = 'white').generate(str(clns))\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Cleaned Label Distribution', size = 23, color = 'darkblue')\nplt.show()\n\n","17ab4ed2":"from collections import Counter\n\ncleaned = list(train_df['dataset_label'])\n\ncleans = []\n\nfor i in cleaned:\n    i = list(i.split(\" \"))\n    for j in i:\n        cleans.append(j.replace(\" \", \"\"))\n\ncln = Counter(cleans)","74a94c07":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nclns = list(set(cln))\nplt.rcParams['figure.figsize'] = (15,15)\nwordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = 'white').generate(str(clns))\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Dataset Label Distribution', size = 23, color = 'darkblue')\nplt.show()\n\n","4ff8b001":"from collections import Counter\n\ncleaned = list(train_df['dataset_title'])\n\ncleans = []\n\nfor i in cleaned:\n    i = list(i.split(\" \"))\n    for j in i:\n        cleans.append(j.replace(\" \", \"\"))\n\ncln = Counter(cleans)","e873d419":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nclns = list(set(cln))\nplt.rcParams['figure.figsize'] = (15,15)\nwordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = 'white').generate(str(clns))\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Dataset Title Distribution', size = 23, color = 'darkblue')\nplt.show()\n\n","01f54c84":"from collections import Counter\n\ncleaned = list(train_df['pub_title'])\n\ncleans = []\n\nfor i in cleaned:\n    i = list(i.split(\" \"))\n    for j in i:\n        cleans.append(j.replace(\" \", \"\"))\n\ncln = Counter(cleans)","e3458cca":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nclns = list(set(cln))\nplt.rcParams['figure.figsize'] = (15,15)\nwordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = 'white').generate(str(clns))\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Pub Title Distribution', size = 23, color = 'darkblue')\nplt.show()\n\n","35d04fab":"porter = PorterStemmer()\ndef lower_case(input_str):\n    input_str = input_str.lower()\n    return input_str\ndef stemSentence(sentence):\n    token_words=word_tokenize(sentence)\n    token_words\n    stem_sentence=[]\n    for word in token_words:\n        stem_sentence.append(porter.stem(word))\n        stem_sentence.append(\" \")\n    return \"\".join(stem_sentence)\n\ndef clean_text(text):\n    text= re.sub('r[^\\w\\s]',' ',text)\n    #text= re.sub('[^a-zA-z0-9\\s]','',text)\n    text=lower_case(text)\n    text=remove_stopwords(text)\n    text=stemSentence(text)    \n    return text","709a055d":"temp_1 = [x.lower() for x in train_df['dataset_label'].unique()]\ntemp_2 = [x.lower() for x in train_df['dataset_title'].unique()]\ntemp_3 = [x.lower() for x in train_df['cleaned_label'].unique()]\ntemp_4 = [x.lower() for x in train_df['pub_title'].unique()]\ntemp_5 = [x.lower() for x in train_df['text'].unique()]\n\nexisting_labels = set(temp_1 + temp_2 + temp_3 + temp_4  + temp_5)","7183f7cf":"id_list = []\nlables_list = []\nfor index, row in tqdm(sample_df.iterrows()):\n    sample_text = row['text']\n    row_id = row['Id']\n\n    temp_df = train_df[train_df['text'] == clean_text(sample_text)]\n    cleaned_labels = temp_df['cleaned_label'].to_list()\n    for known_label in existing_labels:\n        if known_label in sample_text.lower():\n            cleaned_labels.append(clean_text(known_label))\n    cleaned_labels = [clean_text(x) for x in cleaned_labels]\n    cleaned_labels = set(cleaned_labels)\n    lables_list.append(' | '.join(cleaned_labels))\n    id_list.append(row_id)","f8393316":"sample_df[\"PredictionString\"] = lables_list","987ec5bf":"del sample_df['text']","aad2e6fb":"sample_df.head()","e2612253":"sample_df.to_csv('submission.csv', index = False)","6cb3708e":"# Import Data","14385bf8":"# Figure Train Text","8e6b2c93":"> Making submission","87441566":"# Combine Datasets"}}