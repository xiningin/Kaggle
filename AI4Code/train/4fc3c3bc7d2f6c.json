{"cell_type":{"5b68dd24":"code","861aaae7":"code","6514393f":"code","bdad89b5":"code","14f91c23":"code","4cef16cc":"code","af6532b6":"code","5e3f847a":"code","09f43c9c":"code","016fe220":"code","200708fa":"code","ef111620":"code","d0a2c5e0":"code","ca1f096f":"code","45047730":"code","d4b9e370":"code","226d51e6":"code","2b09962c":"code","4b40407e":"code","42a80e89":"code","61bffa1a":"code","a0027d6b":"code","a7e99bfe":"code","6ad7fa1c":"code","a4e826ab":"code","4c1f68bc":"code","1c1857ee":"code","5e2a53ed":"code","910f5f8f":"code","5b5f35b0":"code","cfd4ad60":"code","da0a5988":"code","27653274":"code","0079da4e":"code","133de0db":"code","6ec95760":"code","9ba9bf88":"markdown","2df05b85":"markdown","576a7d28":"markdown","b4de1cb0":"markdown","9e715621":"markdown"},"source":{"5b68dd24":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","861aaae7":"import pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np ","6514393f":"df=pd.read_csv('\/kaggle\/input\/real-or-fake-fake-jobposting-prediction\/fake_job_postings.csv')","bdad89b5":"df.info()\ndf\ndf.isnull().sum()\ndf.nunique().sum","14f91c23":"df.department=df.department.isna()\ndf.company_profile=df.company_profile.isna()\ndf.requirements=df.requirements.isna()\ndf.benefits=df.benefits.isna()\ndf.industry=df.industry.isna()\ndf.function=df.function.isna()\ndf[['department','company_profile','requirements','benefits','industry','function']] = df[['department','company_profile','requirements','benefits','industry','function']].replace({True: 1, False: 0})","4cef16cc":"df = df.dropna(subset=['location','description'])","af6532b6":"df.isnull().sum()","5e3f847a":"df['location'] = df['location'].str.split(',').str[0]","09f43c9c":"df['salary_range'] = df['salary_range'].str.split('-').str[-1]\ndf['salary_range'] = df['salary_range'].fillna(0)\ndf = df[df.salary_range != 'Nov']\ndf = df[df.salary_range != 'Oct']\ndf = df[df.salary_range != 'Dec']\ndf = df[df.salary_range != 'Apr']\ndf = df[df.salary_range != 'Jun']\ndf = df[df.salary_range != 'Sep']","016fe220":"df[['employment_type','required_experience','required_education']] = df[['employment_type','required_experience','required_education']].fillna('Other')","200708fa":"df=df.drop('title',axis=1)\ndf=df.drop('description',axis=1)\ndf=df.drop('job_id',axis=1)","ef111620":"dummies= pd.get_dummies(df[['location','employment_type','required_experience','required_education']],drop_first=True)\ndf=pd.concat([df.drop(['location','employment_type','required_experience','required_education'], axis=1), dummies],axis=1) ","d0a2c5e0":"df.isnull().sum()","ca1f096f":"df.nunique().sum","45047730":"df","d4b9e370":"df.info\nsns.countplot(x='fraudulent',data=df)\n#The data is very skew","226d51e6":"x = df.drop('fraudulent',axis=1).values\ny = df['fraudulent'].values","2b09962c":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=101)","4b40407e":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","42a80e89":"scores=[]\nfor i in range(1,100):\n  tree=DecisionTreeClassifier(max_depth = i) \n  tree.fit(x_train, y_train) \n  scores.append(tree.score(x_test,y_test)) \nplt.plot(range(1,100),scores) \nplt.show()\n","61bffa1a":"tree=DecisionTreeClassifier(max_depth =18) \ntree.fit(x_train, y_train) \ntree.score(x_test,y_test)","a0027d6b":"predictions = tree.predict(x_test) \nfrom sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_test,predictions)) \nprint(confusion_matrix(y_test,predictions))","a7e99bfe":"from sklearn.neighbors import KNeighborsClassifier","6ad7fa1c":"accuracies=[]\nfor k in range(1,101):\n  classifier = KNeighborsClassifier(n_neighbors = k)\n  classifier.fit(x_train, y_train)\n  accuracies.append(classifier.score(x_test, y_test)) \n  \nk_list=list(range(1,101)) \nplt.plot(k_list,accuracies)\nplt.show() ","a4e826ab":"classifier = KNeighborsClassifier(n_neighbors =10)\nclassifier.fit(x_train, y_train)\nclassifier.score(x_test, y_test) ","4c1f68bc":"predictions = classifier.predict(x_test) \nfrom sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_test,predictions)) \nprint(confusion_matrix(y_test,predictions))\n","1c1857ee":"from sklearn.svm import SVC\nscores=[]\nfor i in (np.arange(0.01,1,0.02)):\n  classifier = SVC(kernel = 'linear', C = i)\n  classifier.fit(x_train,y_train) \n  scores.append(classifier.score(x_test,y_test)) \nplt.plot(np.arange(0.01,1,0.02),scores) \nplt.show()","5e2a53ed":"scores=[]\nfor i in (np.arange(0.01,1,0.02)):\n  classifier = SVC(kernel = 'rbf', gamma=i, C = i)\n  classifier.fit(x_train,y_train) \n  scores.append(classifier.score(x_test,y_test)) \nplt.plot(np.arange(0.01,1,0.02),scores) \nplt.show()","910f5f8f":"classifier = SVC(kernel = 'rbf', gamma=0.96, C = 0.96)\nclassifier.fit(x_train,y_train) \nclassifier.score(x_test,y_test)","5b5f35b0":"predictions = classifier.predict(x_test) \nfrom sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_test,predictions)) \nprint(confusion_matrix(y_test,predictions))","cfd4ad60":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping","da0a5988":"from tensorflow.keras.layers import Dropout\nmodel = Sequential()\nmodel.add(Dense(units=100,activation='relu'))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(units=1,activation='sigmoid')) \nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n\n","27653274":"#early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\nmodel.fit(x_train,y_train,epochs=65,validation_data=(x_test, y_test), verbose=1)\n","0079da4e":"losses = pd.DataFrame(model.history.history)\n\nlosses[['accuracy','val_accuracy']].plot()\nlosses[['loss','val_loss']].plot()\n","133de0db":"print(model.metrics_names) \nprint(model.evaluate(x_test,y_test,verbose=0))","6ec95760":"from sklearn.metrics import classification_report,confusion_matrix\n\npredictions = model.predict_classes(x_test)\nprint(classification_report(y_test,predictions))","9ba9bf88":"**Decision Tree**","2df05b85":"Hello, I want to share my humble work regarding this dataset. I tried to make ML models to predict whether the job posting is real or not. Here you can see the performance difference between the ML algorithms (Decision Tree, KNN, SVM, ANN)","576a7d28":"**SVM**","b4de1cb0":"**ANN**","9e715621":"**KNN**"}}