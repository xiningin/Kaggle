{"cell_type":{"e9cfe278":"code","5e98740c":"code","27cb02df":"code","1a139e0e":"code","cf957a85":"code","8982c7ef":"code","8fbb07dc":"code","d628ede7":"code","7618899f":"code","63c5be58":"code","85c06ddd":"code","15f6871e":"code","37a64126":"code","f897c8ad":"code","245b1892":"code","d4d60e00":"code","657148bd":"code","8fbaa1a0":"code","fc326e1d":"code","aa3e014e":"code","2ee22e17":"code","831c6dc8":"code","615f8285":"code","dc50d6cd":"code","2b262223":"code","345aeae2":"code","0484d32e":"code","ec6fae2f":"code","1245b28a":"code","8632f83f":"code","a95ecaed":"code","4c98ab09":"code","1f40d7d8":"code","a92f7ed1":"code","2e867b38":"code","6a0e777d":"code","1f0c8dc8":"code","8379bb38":"markdown","59f3a296":"markdown","b0a129a7":"markdown","03a6cb99":"markdown","ac430eca":"markdown","c5639dcb":"markdown","105e4991":"markdown","0203c324":"markdown","3de936e6":"markdown","a1c087d6":"markdown","a2202aae":"markdown","3a708cb7":"markdown","90704858":"markdown","a40cf3cf":"markdown","d0e2dbb5":"markdown","47d85db8":"markdown","798e40aa":"markdown","05444974":"markdown","fbe9ddc8":"markdown","970c2946":"markdown"},"source":{"e9cfe278":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e98740c":"import pandas as pd\nimport numpy as np\nimport datatable as dt\nimport time\n#import pickle\n#import warnings\n#warnings.simplefilter(\"ignore\")\nimport matplotlib.pyplot as plt\n%pylab\n%matplotlib inline","27cb02df":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","1a139e0e":"%%time\n\ndf_train = (\n    dt.fread('..\/input\/jane-street-market-prediction\/train.csv', max_nrows=100000)\n      .to_pandas()\n      .pipe(reduce_mem_usage)\n)\ndf_train.head()","cf957a85":"#size = 100000\n#dftrain = df_train.tail(size)","8982c7ef":"#Index reset\ndf_train.reset_index(drop=True, inplace=True)\ndf_train.head()","8fbb07dc":"#Features selection\nfeatures = [c for c in df_train.columns if 'feature' in c]\n#Target\n#Reference: https:\/\/www.kaggle.com\/iamleonie\/utility-function-and-patterns-in-missing-values\ndf_train['action'] = (df_train['resp'] > 0).astype('int')\n#We delete cases when weight is equal to 0\ndf_train = df_train.loc[df_train.weight != 0]\n#We generate the Dataset selection to model\ndf_train = pd.concat([df_train.weight, df_train[features], df_train.action], axis=1)\n#Reindex to keep numbers in a row\ndf_train.reset_index(drop=True, inplace=True)\ndf_train.head()","d628ede7":"df_train.info()","7618899f":"#We check that we have removed all other null and infinite values\ndf_train.replace([np.inf, -np.inf], np.nan, inplace=True)","63c5be58":"#First estrategy\n#Fill nan values with 0\n#df_train.fillna(0,inplace=True)\n\n#Second estrategy\n#Fill nan values with median\ntrain_median = df_train.median()\ndf_train = df_train.fillna(train_median)\n\n#Third estrategy\n#Lineal Interpolation\n#df_train.interpolate(method='linear', inplace=True)","85c06ddd":"#print('Original size:', df_train.shape[0])\n#print('Sample size:', df_train.shape[0])\n#print('% Sample:', round((df_train.shape[0]\/df_train.shape[0]),2)*100,'%')","15f6871e":"#We save is df and then work after\n#dftrain.to_csv('\/kaggle\/working\/df_tail_slice.csv')","37a64126":"#%%time\n#dftrain = pd.read_csv('\/kaggle\/working\/df_tail_slice.csv', index_col=0)","f897c8ad":"!pip install pycaret","245b1892":"%%time\n\nfrom pycaret.classification import *\nexp1 = setup(df_train, target = 'action', feature_selection = True, feature_selection_threshold=0.8,\n             remove_multicollinearity=True, multicollinearity_threshold=0.6, numeric_imputation='zero')","d4d60e00":"%%time\n\ncompare_models()","657148bd":"#We create the model that has given us the best performance: \"Extra Trees Classifier\"\net_model = create_model('et')","8fbaa1a0":"#Try to improve the choice of hyperparameters to optimize performance\ntuned_et_model = tune_model(et_model)","fc326e1d":"#We save the model\nsave_model(et_model, '\/kaggle\/working\/et_model_saved_15012021')\n\n#Loading the saved model\n#et_saved = load_model('\/kaggle\/working\/et_model_saved_21122020')","aa3e014e":"%%time\n\n# tune multiple models dynamically\ntop3 = compare_models(n_select = 3)\ntuned_et_modeltop3 = [tune_model(i) for i in top3]","2ee22e17":"tuned_et_modeltop3","831c6dc8":"#We save the model\nsave_model(tuned_et_modeltop3, '\/kaggle\/working\/tuned_et_top3_saved_21122020')","615f8285":"#We predict the model with the testset generated in the Pycaret model and check for overfitting\net_model_pred = predict_model(et_model)","dc50d6cd":"%%time\n\n#We save the model to test performance in a traditional way and others dataset\net_final = finalize_model(et_model);","2b262223":"%%time\n\ndf_train = (\n    dt.fread('..\/input\/jane-street-market-prediction\/train.csv')\n      .to_pandas()\n      .pipe(reduce_mem_usage)\n)\ndf_train.head()","345aeae2":"##PREPROCESING##\n\n#Features selection\nfeatures = [c for c in df_train.columns if 'feature' in c]\n#Target\n#Reference: https:\/\/www.kaggle.com\/iamleonie\/utility-function-and-patterns-in-missing-values\ndf_train['action'] = (df_train['resp'] > 0).astype('int')\n#We delete cases when weight is equal to 0\ndf_train = df_train.loc[df_train.weight != 0]\n#We generate the Dataset selection to model\ndf_train = pd.concat([df_train.weight, df_train[features], df_train.action], axis=1)\n\n#Fill nan values with 0\ndf_train.fillna(0,inplace=True)\n#We check that we have removed all other null and infinite values\ndf_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n#Reindex to keep numbers in a row\ndf_train.reset_index(drop=True, inplace=True)","0484d32e":"#Function to measure model metrics\nfrom sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n\ndef metrics_models(y_true, y_pred):\n    from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n\n    # Obtaining a confusion matrix\n    confusion_matrix = confusion_matrix(y_true, y_pred)\n\n    print(\"La matriz de confusi\u00f3n es \")\n    print(confusion_matrix)\n\n    print('Precisi\u00f3n:', accuracy_score(y_true, y_pred))\n    print('Exactitud:', precision_score(y_true, y_pred))\n    print('Exhaustividad:', recall_score(y_true, y_pred))\n    print('F1:', f1_score(y_true, y_pred))\n\n    false_positive_rate, recall, thresholds = roc_curve(y_true, y_pred)\n    roc_auc = auc(false_positive_rate, recall)\n\n    print('AUC:', auc(false_positive_rate, recall))\n\n    plot(false_positive_rate, recall, 'b')\n    plot([0, 1], [0, 1], 'r--')\n    title('AUC = %0.2f' % roc_auc)","ec6fae2f":"#We calculate performance tradicional way with metricas_modelos() function\ny_test = df_train['action']\n\ny_pred_test = predict_model(et_final, data = df_train)\ny_pred_test = y_pred_test['Label']\ny_pred_test = pd.to_numeric(y_pred_test)\nmetrics_models(y_test, y_pred_test)","1245b28a":"%%time\nfolder_path = '..\/input\/jane-street-market-prediction\/'\ntest = dt.fread(folder_path + 'example_test.csv').to_pandas()","8632f83f":"##PREPROCESING##\n\n#Features selection\nfeatures = [c for c in test.columns if 'feature' in c]\n\n#Fill nan values with 0\n#test.fillna(0,inplace=True)\n\n#Fill nan values with median\ntest_median = test.median()\ntest = test.fillna(test_median)\n#We check that we have removed all other null and infinite values\n#df_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n#Reindex to keep numbers in a row\n#df_train.reset_index(drop=True, inplace=True)\n\nprediction = predict_model(et_final, data = test)\nprediction.head()","a95ecaed":"#prediction = predict_model(etc_final, data = test)\n#sample_prediction_df = pd.DataFrame([prediction.Label], columns=['action'], index=prediction.ts_id)\nsample_prediction_df = pd.concat([prediction.Label], axis=1, keys=prediction.ts_id)\nsample_prediction_df.rename(columns={ sample_prediction_df.columns[0]: \"action\" }, inplace=True)\n#sample_prediction_df.rename(columns={'0':'action'}, inplace = True)\nsample_prediction_df.head()","4c98ab09":"%%time\n#First option\nimport janestreet\ntry:\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test()\nexcept:\n    env = janestreet.make_env.__called__ = False\n    env = janestreet.make_env() # initialize the environment again\n    iter_test = env.iter_test()\n\n    \nfor (test_df, sample_prediction_df) in iter_test:\n    wt = test_df.iloc[0].weight\n    if(wt == 0):\n        sample_prediction_df.action = 0 \n    else:\n        #test_median = test_df.median()\n        #test_df = test_df.fillna(test_median)\n        test_df.fillna(0,inplace=True)\n        predictions = predict_model(et_final, data = test_df)['Label'].astype(int)\n        sample_prediction_df = predictions.to_frame()\n        sample_prediction_df.rename(columns ={'Label':'action'}, inplace = True)\n    env.predict(sample_prediction_df)","1f40d7d8":"#Second option\nimport janestreet\ntry:\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test()\nexcept:\n    env = janestreet.make_env.__called__ = False\n    env = janestreet.make_env() # initialize the environment again\n    iter_test = env.iter_test()\n\nfor (test_df, sample_prediction_df) in iter_test:\n    #X_test = test_df.loc[:, test_df.drop(columns=(drop_col+['resp']))]\n    if test_df['weight'].item() > 0:\n        sample_prediction_df = predict_model(et_final, data = test)['Label'].astype(int)\n        sample_prediction_df = predictions.to_frame()\n        sample_prediction_df.rename(columns ={'Label':'action'}, inplace = True)\n        env.predict(sample_prediction_df)","a92f7ed1":"#Loading the saved model\n#et_final = load_model('..\/input\/et-model-pycaret\/et_model_saved_13012021.pkl')","2e867b38":"import pickle\n\n# path file\npkl_path = \"..\/input\/et-model-pycaret\/et_model_saved_13012021.pkl\"\n# Load from file\nwith open(pkl_path, 'rb') as file:\n    rf_final = pickle.load(file)","6a0e777d":"# Calculate the accuracy score and predict target values\nscore = pickle_model.score(Xtest, Ytest)\nprint(\"Test score: {0:.2f} %\".format(100 * score))\nYpredict = pickle_model.predict(Xtest)\n\nfor (test_df, sample_prediction_df) in iter_test:\n    X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n    y_preds = clf.predict(X_test)\n    sample_prediction_df.action = y_preds\n    env.predict(sample_prediction_df)","1f0c8dc8":"#Test to restart the environment\nimport janestreet\ntry:\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test()\nexcept:\n    env = janestreet.make_env.__called__ = False\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test()\n    \n\niter_test","8379bb38":"Let's try to make a quick approach to which model can show better performance and then delve into aspects that can optimize performance.  \nTo do this we use the [PyCaret](https:\/\/pycaret.org\/) library and test on a sample of the original dataset.","59f3a296":"The best results are provided by the **Extra Trees Classifier** model.  \nBetter results are obtained when filled with the means of all data. \n#Second estrategy  \n#Fill nan values with median    \ntrain_median = df_train.median()  \ndf_train = df_train.fillna(train_median)  ","b0a129a7":"### Test Load model ","03a6cb99":"We treat null values","ac430eca":"Looks like there's not too much overfit.","c5639dcb":"> ## **Loading** and Reduce Memory  \n\nWe load the data, trying to reduce the memory overload  \nReference: https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage","105e4991":"## **Quick approach model optimization**","0203c324":"Reducing dimensionality to 26 variables features eliminating multicolinearity by 60%","3de936e6":"The missing values would be filled directly by setting the parameters in PyCaret with numeric_imputation='zero'","a1c087d6":"The goal of this notebook is **not to do a thorough data exploration**, as there are great jobs that develop this task. Based on these findings, we will try to develop a quick method optimized to predict Jane Street's challenge","a2202aae":"### Libraries\ud83d\udcd8","3a708cb7":"We tested the model again in all train set","90704858":"Reference:https:\/\/www.kaggle.com\/muhammadmelsherbini\/jane-street-extensive-eda","a40cf3cf":"### Test to restart the environment","d0e2dbb5":"* We calculate the target from the variable 'resp'\n* We erase cases where the weight is equal to 0","47d85db8":"We select the last hundred thousand rows to check how our model works without overloading memory","798e40aa":"### Approaching the best model with PyCaret (AutoML)","05444974":"## EDA","fbe9ddc8":"## Submitting test in ALL dataset","970c2946":"## **Preprocesing**\u2699"}}