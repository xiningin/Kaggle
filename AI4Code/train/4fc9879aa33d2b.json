{"cell_type":{"c82901e3":"code","76d475b6":"code","b356842e":"code","16ec8917":"code","114ef35c":"code","2ff90869":"code","646f9075":"code","d13315ee":"code","083f7134":"code","ed3c3358":"code","f77c2074":"code","eabe381b":"code","d7290ed6":"code","6596a5db":"code","f04606f5":"code","ee8219c4":"code","9b3fd94d":"code","b2a26c2e":"code","581df5bb":"code","8c2a2b5a":"code","5f3a0ccc":"code","ed59f24e":"code","db63d4fd":"code","5dd1c65a":"code","509f179a":"code","237bb2e0":"code","9aba1ab2":"code","3b912d25":"code","a65ccfad":"code","188f7db1":"code","d71b39fe":"code","32d38e4b":"code","a8be5573":"code","f97e84cb":"code","74d8ef01":"code","1097d90a":"code","6dc31bf2":"code","97e73073":"code","006a423f":"code","46302bbf":"code","9bd51d6e":"code","2e9a4122":"code","f42fdf84":"code","1387c8fb":"code","7003e93d":"code","91dc658d":"code","e45a6f3b":"code","adf392fc":"code","c1f6bb04":"code","64ec3321":"code","0793550e":"code","647b7f43":"code","2bc9ab25":"code","1276ba12":"code","470a7c34":"code","dee6951d":"code","6eab3da5":"code","234031ab":"code","0a986b50":"code","70d85eb0":"code","17433220":"code","38faff7f":"code","4f232455":"code","a0081660":"code","1377b609":"code","f718a6ec":"code","8fcc1203":"code","3e67533d":"code","2e69409c":"code","05f3dc10":"code","c5abcc9c":"code","618274e8":"code","6c4bb4b5":"code","a7bd439b":"code","2a530f38":"code","8a1bf2cd":"code","37544c2e":"code","7f89d23f":"code","4d044e2b":"code","e434d842":"code","24166886":"code","41533a37":"code","b94c6106":"code","301c2f45":"code","c0cf4c82":"code","e0d382d6":"code","a7de1233":"code","9f37a109":"code","42940a0d":"code","c5a73052":"code","1a62aa08":"code","91b10d93":"code","b26feadc":"code","3f8aa681":"code","19bf4633":"code","a62e155c":"code","9242a606":"code","ce1e890a":"code","ee884d2c":"code","eb6d3e77":"code","5aca3c02":"code","95e94cc8":"code","1af236cd":"code","fa07ad3e":"code","75c36910":"code","69e5c4dd":"code","f50d930a":"code","fe9d1104":"code","258c5a7f":"code","f10082ec":"code","576b077b":"code","92029026":"code","6a4aafc7":"code","5a51ca52":"code","4a4fdf45":"code","dc96ff8e":"code","4096fea0":"code","eba686b4":"code","da60f53a":"code","5d67c3e9":"code","47c1c8d8":"markdown","870de63d":"markdown","bd5a0665":"markdown","ad8700b6":"markdown","14467d6a":"markdown","853812d3":"markdown","7ca599aa":"markdown","dea050ae":"markdown","6bd9a0f4":"markdown","733d51c6":"markdown","8e62f06c":"markdown","8c307226":"markdown","a68df54c":"markdown","56ac931f":"markdown","76f65594":"markdown","abfd2de8":"markdown","80ea1217":"markdown","7710c443":"markdown","481cb731":"markdown","372e8238":"markdown","889b7dca":"markdown","d635fe3f":"markdown","056e343d":"markdown"},"source":{"c82901e3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","76d475b6":"# To load Dataset from Kaggle Input\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b356842e":"app_df = pd.read_csv(\"\/kaggle\/input\/credit-card-approval-prediction\/application_record.csv\")\napp_df.head()","16ec8917":"app_df.shape","114ef35c":"app_df.info()","2ff90869":"credit_df = pd.read_csv(\"\/kaggle\/input\/credit-card-approval-prediction\/credit_record.csv\") \ncredit_df.head()","646f9075":"credit_df.shape","d13315ee":"credit_df.info()","083f7134":"app_df.describe()","ed3c3358":"app_df.isnull().sum()","f77c2074":"# dropping occupation type which has many null values\napp_df.drop('OCCUPATION_TYPE', axis=1, inplace=True)","eabe381b":"# Checking duplicates in 'ID' column\nlen(app_df['ID']) - len(app_df['ID'].unique())","d7290ed6":"# Dropping duplicate entries from ID column\napp_df = app_df.drop_duplicates('ID', keep='last') ","6596a5db":"# Checking Non-Numerical Columns\ncat_columns = app_df.columns[(app_df.dtypes =='object').values].tolist()\ncat_columns","f04606f5":"# Checking Numerical Columns\napp_df.columns[(app_df.dtypes !='object').values].tolist()","ee8219c4":"# Checking unique values from Categorical Columns\n\nfor i in app_df.columns[(app_df.dtypes =='object').values].tolist():\n    print(i,'\\n')\n    print(app_df[i].value_counts())\n    print('-----------------------------------------------')","9b3fd94d":"# Checking unique values from Numerical Columns","b2a26c2e":"app_df['CNT_CHILDREN'].value_counts()","581df5bb":"# Checking Min , Max values from 'DAYS_BIRTH' column\nprint('Min DAYS_BIRTH :', app_df['DAYS_BIRTH'].min(),'\\nMax DAYS_BIRTH :', app_df['DAYS_BIRTH'].max())","8c2a2b5a":"# Converting 'DAYS_BIRTH' values from Day to Years\napp_df['DAYS_BIRTH'] = round(app_df['DAYS_BIRTH']\/-365,0)\napp_df.rename(columns={'DAYS_BIRTH':'AGE_YEARS'}, inplace=True)","5f3a0ccc":"# Checking unique values greater than 0\napp_df[app_df['DAYS_EMPLOYED']>0]['DAYS_EMPLOYED'].unique()","ed59f24e":"# As mentioned in document, if 'DAYS_EMPLOYED' is positive no, it means person currently unemployed, hence replacing it with 0\napp_df['DAYS_EMPLOYED'].replace(365243, 0, inplace=True)","db63d4fd":"# Converting 'DAYS_EMPLOYED' values from Day to Years\napp_df['DAYS_EMPLOYED'] = abs(round(app_df['DAYS_EMPLOYED']\/-365,0))\napp_df.rename(columns={'DAYS_EMPLOYED':'YEARS_EMPLOYED'}, inplace=True)   ","5dd1c65a":"app_df['FLAG_MOBIL'].value_counts()","509f179a":"# As all the values in column are 1, hence dropping column\napp_df.drop('FLAG_MOBIL', axis=1, inplace=True)","237bb2e0":"app_df['FLAG_WORK_PHONE'].value_counts()","9aba1ab2":"# This column only contains 0 & 1 values for Mobile no submitted, hence dropping column\napp_df.drop('FLAG_WORK_PHONE', axis=1, inplace=True)","3b912d25":"app_df['FLAG_PHONE'].value_counts()","a65ccfad":"# This column only contains 0 & 1 values for Phone no submitted, hence dropping column\napp_df.drop('FLAG_PHONE', axis=1, inplace=True)","188f7db1":"app_df['FLAG_EMAIL'].value_counts()","d71b39fe":"# This column only contains 0 & 1 values for Email submitted, hence dropping column\napp_df.drop('FLAG_EMAIL', axis=1, inplace=True)","32d38e4b":"app_df['CNT_FAM_MEMBERS'].value_counts()","a8be5573":"app_df.head()","f97e84cb":"#create plot to detect outliers\nsns.boxplot(app_df['CNT_CHILDREN'])","74d8ef01":"sns.boxplot(app_df['AMT_INCOME_TOTAL'])","1097d90a":"sns.boxplot(app_df['AGE_YEARS'])","6dc31bf2":"sns.boxplot(app_df['YEARS_EMPLOYED'])","97e73073":"sns.boxplot(app_df['CNT_FAM_MEMBERS'])","006a423f":"high_bound = app_df['CNT_CHILDREN'].quantile(0.999)\nprint('high_bound :', high_bound)\nlow_bound = app_df['CNT_CHILDREN'].quantile(0.001)\nprint('low_bound :', low_bound)","46302bbf":"app_df = app_df[(app_df['CNT_CHILDREN']>=low_bound) & (app_df['CNT_CHILDREN']<=high_bound)]","9bd51d6e":"high_bound = app_df['AMT_INCOME_TOTAL'].quantile(0.999)\nprint('high_bound :', high_bound)\nlow_bound = app_df['AMT_INCOME_TOTAL'].quantile(0.001)\nprint('low_bound :', low_bound)","2e9a4122":"app_df = app_df[(app_df['AMT_INCOME_TOTAL']>=low_bound) & (app_df['AMT_INCOME_TOTAL']<=high_bound)]","f42fdf84":"high_bound = app_df['YEARS_EMPLOYED'].quantile(0.999)\nprint('high_bound :', high_bound)\nlow_bound = app_df['YEARS_EMPLOYED'].quantile(0.001)\nprint('low_bound :', low_bound)","1387c8fb":"app_df = app_df[(app_df['YEARS_EMPLOYED']>=low_bound) & (app_df['YEARS_EMPLOYED']<=high_bound)]","7003e93d":"high_bound = app_df['CNT_FAM_MEMBERS'].quantile(0.999)\nprint('high_bound :', high_bound)\nlow_bound = app_df['CNT_FAM_MEMBERS'].quantile(0.001)\nprint('low_bound :', low_bound)","91dc658d":"app_df = app_df[(app_df['CNT_FAM_MEMBERS']>=low_bound) & (app_df['CNT_FAM_MEMBERS']<=high_bound)]","e45a6f3b":"app_df.head()","adf392fc":"credit_df.head()","c1f6bb04":"app_df.isnull().sum()","64ec3321":"credit_df['STATUS'].value_counts()","0793550e":"# categorizing 'STATUS' column to binary classification   0 : Good Client and 1 : bad client\ncredit_df['STATUS'].replace(['C', 'X'],0, inplace=True)","647b7f43":"credit_df['STATUS'].replace(['2','3','4','5'],1, inplace=True)","2bc9ab25":"credit_df['STATUS'] = credit_df['STATUS'].astype('int')","1276ba12":"credit_df.info()","470a7c34":"credit_df['STATUS'].value_counts(normalize=True)*100","dee6951d":"credit_df_trans = credit_df.groupby('ID').agg(max).reset_index()","6eab3da5":"credit_df_trans.drop('MONTHS_BALANCE', axis=1, inplace=True)\ncredit_df_trans.head()","234031ab":"credit_df_trans['STATUS'].value_counts(normalize=True)*100","0a986b50":"# merging the two datasets based on 'ID'\nfinal_df = pd.merge(app_df, credit_df_trans, on='ID', how='inner')\nfinal_df.head()","70d85eb0":"final_df.shape","17433220":"# dropping 'ID' column as it is having only unique values (not required for ML Model)\nfinal_df.drop('ID', axis=1, inplace=True)","38faff7f":"# checking if there are still duplicate rows in Final Dataframe\nlen(final_df) - len(final_df.drop_duplicates())","4f232455":"# Dropping duplicate records\nfinal_df = final_df.drop_duplicates()\nfinal_df.reset_index(drop=True ,inplace=True)","a0081660":"final_df.shape","1377b609":"final_df.isnull().sum()","f718a6ec":"final_df['STATUS'].value_counts(normalize=True)*100","8fcc1203":"final_df.head()","3e67533d":"# This graph shows that, there is no column (Feature) which is highly co-related with 'Status'\nplt.figure(figsize = (8,8))\nsns.heatmap(final_df.corr(), annot=True)\nplt.show()","2e69409c":"# This graph shows that, majority of application are submitted by Female's\nplt.pie(final_df['CODE_GENDER'].value_counts(), labels=['Female', 'Male'], autopct='%1.2f%%')\nplt.title('% of Applications submitted based on Gender')\nplt.show()","05f3dc10":"# This graph shows that, majority of application are approved for Female's\nplt.pie(final_df[final_df['STATUS']==0]['CODE_GENDER'].value_counts(), labels=['Female', 'Male'], autopct='%1.2f%%')\nplt.title('% of Applications Approved based on Gender')\nplt.show()","c5abcc9c":"# This graph shows that, majority of applicatant's dont own a car\nplt.pie(final_df['FLAG_OWN_CAR'].value_counts(), labels=['No', 'Yes'], autopct='%1.2f%%')\nplt.title('% of Applications submitted based on owning a Car')\nplt.show()","618274e8":"# This graph shows that, majority of applicatant's own a Real Estate property \/ House\nplt.pie(final_df['FLAG_OWN_REALTY'].value_counts(), labels=['Yes','No'], autopct='%1.2f%%')\nplt.title('% of Applications submitted based on owning a Real estate property')\nplt.show()","6c4bb4b5":"# This graph shows that, majority of applicatant's don't have any children\nplt.figure(figsize = (8,8))\nplt.pie(final_df['CNT_CHILDREN'].value_counts(), labels=final_df['CNT_CHILDREN'].value_counts().index, autopct='%1.2f%%')\nplt.title('% of Applications submitted based on Children count')\nplt.legend()\nplt.show()","a7bd439b":"# This graph shows that, majority of applicatant's income lies between 1 to 3 lakh\nplt.hist(final_df['AMT_INCOME_TOTAL'], bins=20)\nplt.xlabel('Total Annual Income')\nplt.title('Histogram')\nplt.show()","2a530f38":"# This graph shows that, majority of applicatant's are working professional\nplt.figure(figsize = (8,8))\nplt.pie(final_df['NAME_INCOME_TYPE'].value_counts(), labels=final_df['NAME_INCOME_TYPE'].value_counts().index, autopct='%1.2f%%')\nplt.title('% of Applications submitted based on Income Type')\nplt.legend()\nplt.show()","8a1bf2cd":"# This graph shows that, majority of applicatant's completed the Secondary Education\nplt.figure(figsize=(8,8))\nplt.pie(final_df['NAME_EDUCATION_TYPE'].value_counts(), labels=final_df['NAME_EDUCATION_TYPE'].value_counts().index, autopct='%1.2f%%')\nplt.title('% of Applications submitted based on Education')\nplt.legend()\nplt.show()","37544c2e":"# This graph shows that, majority of applicatant's are married\nplt.figure(figsize=(8,8))\nsns.barplot(final_df['NAME_FAMILY_STATUS'].value_counts().index, final_df['NAME_FAMILY_STATUS'].value_counts().values)\nplt.title('% of Applications submitted based on Family Status')\nplt.show()","7f89d23f":"# This graph shows that, majority of applicatant's lives in House \/ Apartment\nplt.figure(figsize=(12,5))\nsns.barplot(final_df['NAME_HOUSING_TYPE'].value_counts().index, final_df['NAME_HOUSING_TYPE'].value_counts().values)\nplt.title('% of Applications submitted based on Housing Type')\nplt.show()","4d044e2b":"# This graph shows that, majority of applicatant's are 25 to 65 years old\nplt.hist(final_df['AGE_YEARS'], bins=20)\nplt.xlabel('Age')\nplt.title('Histogram')\nplt.show()","e434d842":"# This graph shows that, majority of applicatant's are Employed for 0 to 7 years\nplt.hist(final_df['YEARS_EMPLOYED'], bins=20)\nplt.xlabel('No of Years Employed')\nplt.title('Histogram')\nplt.show()","24166886":"# This graph shows that, majority of applications are rejected if Total income & years of Employment is less\nsns.scatterplot(final_df['YEARS_EMPLOYED'], final_df['AMT_INCOME_TOTAL'], hue=final_df['STATUS'])\nplt.title('Scatter Plot')\nplt.show()","41533a37":"final_df.head()","b94c6106":"cat_columns = final_df.columns[(final_df.dtypes =='object').values].tolist()\ncat_columns","301c2f45":"#Converting all Non-Numerical Columns to Numerical\nfrom sklearn.preprocessing import LabelEncoder\n\nfor col in cat_columns:\n        globals()['LE_{}'.format(col)] = LabelEncoder()\n        final_df[col] = globals()['LE_{}'.format(col)].fit_transform(final_df[col])\nfinal_df.head()    ","c0cf4c82":"for col in cat_columns:\n    print(col , \"  : \", globals()['LE_{}'.format(col)].classes_)","e0d382d6":"final_df.corr()","a7de1233":"features = final_df.drop(['STATUS'], axis=1)\nlabel = final_df['STATUS']","9f37a109":"features.head()","42940a0d":"label.head()","c5a73052":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features,\n                                                    label,\n                                                    test_size=0.2,\n                                                    random_state = 10)","1a62aa08":"# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\nlog_model = LogisticRegression()\nlog_model.fit(x_train, y_train)\n\nprint('Logistic Model Accuracy : ', log_model.score(x_test, y_test)*100, '%')\n\nprediction = log_model.predict(x_test)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test, prediction))","91b10d93":"# Decision Tree classification\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecision_model = DecisionTreeClassifier(max_depth=12,min_samples_split=8)\n\ndecision_model.fit(x_train, y_train)\n\nprint('Decision Tree Model Accuracy : ', decision_model.score(x_test, y_test)*100, '%')\n\nprediction = decision_model.predict(x_test)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test, prediction))","b26feadc":"# Random Forest classification\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nRandomForest_model = RandomForestClassifier(n_estimators=250,\n                                            max_depth=12,\n                                            min_samples_leaf=16)\n\nRandomForest_model.fit(x_train, y_train)\n\nprint('Random Forest Model Accuracy : ', RandomForest_model.score(x_test, y_test)*100, '%')\n\nprediction = RandomForest_model.predict(x_test)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test, prediction))","3f8aa681":"# Support Vector Machine classification\n\nfrom sklearn.svm import SVC\n\nsvc_model = SVC()\n\nsvc_model.fit(x_train, y_train)\n\nprint('Support Vector Classifier Accuracy : ', svc_model.score(x_test, y_test)*100, '%')\n\nprediction = svc_model.predict(x_test)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test, prediction))","19bf4633":"# K Nearest Neighbor classification\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors = 7)\n\nknn_model.fit(x_train, y_train)\n\nprint('KNN Model Accuracy : ', knn_model.score(x_test, y_test)*100, '%')\n\nprediction = knn_model.predict(x_test)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test, prediction))","a62e155c":"# XGBoost  classification\n\nfrom xgboost import XGBClassifier\n\nXGB_model = XGBClassifier()\n\nXGB_model.fit(x_train, y_train)\n\nprint('XGBoost Model Accuracy : ', XGB_model.score(x_test, y_test)*100, '%')\n\nprediction = XGB_model.predict(x_test)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test, prediction))","9242a606":"# scaling all features\nfrom sklearn.preprocessing import MinMaxScaler\nMMS = MinMaxScaler()\nx_train_scaled = pd.DataFrame(MMS.fit_transform(x_train), columns=x_train.columns)\nx_test_scaled = pd.DataFrame(MMS.transform(x_test), columns=x_test.columns)","ce1e890a":"# adding samples to minority class using SMOTE\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\n\nx_train_oversam, y_train_oversam = oversample.fit_resample(x_train_scaled, y_train)\nx_test_oversam, y_test_oversam = oversample.fit_resample(x_test_scaled, y_test)","ee884d2c":"# Original majority and minority class\ny_train.value_counts(normalize=True)*100","eb6d3e77":"# after using SMOTE \ny_train_oversam.value_counts(normalize=True)*100","5aca3c02":"# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\nlog_model = LogisticRegression()\nlog_model.fit(x_train_oversam, y_train_oversam)\n\nprint('Logistic Model Accuracy : ', log_model.score(x_test_oversam, y_test_oversam)*100, '%')\n\nprediction = log_model.predict(x_test_oversam)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test_oversam, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test_oversam, prediction))","95e94cc8":"# Decision Tree classification\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecision_model = DecisionTreeClassifier(max_depth=12,min_samples_split=8)\n\ndecision_model.fit(x_train_oversam, y_train_oversam)\n\nprint('Decision Tree Model Accuracy : ', decision_model.score(x_test_oversam, y_test_oversam)*100, '%')\n\nprediction = decision_model.predict(x_test_oversam)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test_oversam, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test_oversam, prediction))","1af236cd":"# Random Forest classification\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nRandomForest_model = RandomForestClassifier(n_estimators=250,\n                                            max_depth=12,\n                                            min_samples_leaf=16)\n\nRandomForest_model.fit(x_train_oversam, y_train_oversam)\n\nprint('Random Forest Model Accuracy : ', RandomForest_model.score(x_test_oversam, y_test_oversam)*100, '%')\n\nprediction = RandomForest_model.predict(x_test_oversam)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test_oversam, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test_oversam, prediction))","fa07ad3e":"# Support Vector Machine classification\n\nfrom sklearn.svm import SVC\n\nsvc_model = SVC()\n\nsvc_model.fit(x_train_oversam, y_train_oversam)\n\nprint('Support Vector Classifier Accuracy : ', svc_model.score(x_test_oversam, y_test_oversam)*100, '%')\n\nprediction = svc_model.predict(x_test_oversam)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test_oversam, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test_oversam, prediction))","75c36910":"# K Nearest Neighbor classification\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors = 7)\n\nknn_model.fit(x_train_oversam, y_train_oversam)\n\nprint('KNN Model Accuracy : ', knn_model.score(x_test_oversam, y_test_oversam)*100, '%')\n\nprediction = knn_model.predict(x_test_oversam)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test_oversam, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test_oversam, prediction))","69e5c4dd":"# XGBoost  classification\n\nfrom xgboost import XGBClassifier\n\nXGB_model = XGBClassifier()\n\nXGB_model.fit(x_train_oversam, y_train_oversam)\n\nprint('XGBoost Model Accuracy : ', XGB_model.score(x_test_oversam, y_test_oversam)*100, '%')\n\nprediction = XGB_model.predict(x_test_oversam)\nprint('\\nConfusion matrix :')\nprint(confusion_matrix(y_test_oversam, prediction))\n      \nprint('\\nClassification report:')      \nprint(classification_report(y_test_oversam, prediction))","f50d930a":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nkfold = KFold(5)","fe9d1104":"# Logistic Regression\n\nresults=cross_val_score(log_model,features,label,cv=kfold)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","258c5a7f":"# Decision Tree classification\n\nresults=cross_val_score(decision_model,features,label,cv=kfold)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","f10082ec":"# Random Forest classification\n\nresults=cross_val_score(RandomForest_model,features,label,cv=kfold)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","576b077b":"# Support Vector Machine classification\n\nresults=cross_val_score(svc_model,features,label,cv=kfold)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","92029026":"# K Nearest Neighbor classification\n\nresults=cross_val_score(knn_model,features,label,cv=kfold)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","6a4aafc7":"# XGBoost classification\n\nresults=cross_val_score(XGB_model,features,label,cv=kfold)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","5a51ca52":"from sklearn.model_selection import StratifiedShuffleSplit\nssplit=StratifiedShuffleSplit(n_splits=5,test_size=0.30)","4a4fdf45":"# Logistic Regression\n\nresults=cross_val_score(log_model,features,label,cv=ssplit)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","dc96ff8e":"# Decision Tree classification\n\nresults=cross_val_score(decision_model,features,label,cv=ssplit)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","4096fea0":"# Random Forest classification\n\nresults=cross_val_score(RandomForest_model,features,label,cv=ssplit)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","eba686b4":"# Support Vector Machine classification\n\nresults=cross_val_score(svc_model,features,label,cv=ssplit)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","da60f53a":"# K Nearest Neighbor classification\n\nresults=cross_val_score(knn_model,features,label,cv=ssplit)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","5d67c3e9":"# XGBoost classification\n\nresults=cross_val_score(XGB_model,features,label,cv=ssplit)\nprint(results*100,'\\n')\n\nprint(np.mean(results)*100)","47c1c8d8":"### Exploratory Data Analysis (EDA)","870de63d":"# Validation","bd5a0665":"### Removing Outliers","ad8700b6":"Logistic Model Accuracy            :  78.84 %\nDecisionTree Model Accuracy        :  73.64 %\nRandom Forest Model Accuracy       :  78.84 %\nSupport Vector Classifier Accuracy :  78.84 %\nKNN Model Accuracy                 :  76.80 %\nXGBoost Model Accuracy             :  75.72 %","14467d6a":"# Visualization","853812d3":"## Machine Learning Model after Balancing","7ca599aa":"# Feature Selection","dea050ae":"# Machine Learning Model","6bd9a0f4":"### Stratified Shuffle Split","733d51c6":"Dataset downloaded from Kaggle - https:\/\/www.kaggle.com\/rikdifos\/credit-card-approval-prediction","8e62f06c":"#### On File - Credit Record.csv","8c307226":"# Visualization","a68df54c":"###### File - Credit Record.csv\n\n|Feature name|Explanation|\n|:--|:--|\n|ID|Client number|\n|MONTHS_BALANCE|Record month|\n|STATUS|Status|\n\n* Note -                                                                                                                       \nMONTHS_BALANCE ---> The month of the extracted data is the starting point, backwards, 0 is the current month, -1 is the previous month, and so on.                                                                                                        \nSTATUS ---> 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month","56ac931f":"### Loading Data","76f65594":"### K-Fold Cross Validation","abfd2de8":"### Content & Explanation\n\n###### File - Application Record.csv\n\n|Feature name|Explanation|\n|:--|:--|\n|ID|Client number|\n|CODE_GENDER|Gender|\n|FLAG_OWN_CAR|Is there a car|\n|FLAG_OWN_REALTY|Is there a property|\n|CNT_CHILDREN|Number of children|\n|AMT_INCOME_TOTAL|Annual income|\n|NAME_INCOME_TYPE|Income category|\n|NAME_EDUCATION_TYPE|Education level|\n|NAME_FAMILY_STATUS|Marital status|\n|NAME_HOUSING_TYPE|Way of living|\n|DAYS_BIRTH|Birthday|\n|DAYS_EMPLOYED|Start date of employment|\n|FLAG_MOBIL|Is there a mobile phone|\n|FLAG_WORK_PHONE|Is there a work phone|\n|FLAG_PHONE|Is there a phone|\n|FLAG_EMAIL|Is there an email|\n|OCCUPATION_TYPE|Occupation|\n|CNT_FAM_MEMBERS|Family size|\n\n\n* Note -                                                                                                                       \nDAYS_BIRTH ---> Count backwards from current day (0), -1 means yesterday                                                       \nDAYS_EMPLOYED ---> Count backwards from current day(0). If positive, it means the person currently unemployed.","80ea1217":"# Balancing dataset","7710c443":"As we have seen that, XGBoost Model is giving highest accuracy of 84.14 %, hence we will use XGBoost Model for predicion","481cb731":"# Credit Card Approval Prediction\n\nProblem Statment - \nA Company wants to automate the Credit Card eligibility process based on customer detail provided while filling online application form & Credit history of customer.\n\nThey have given a problem to identify the customers segments which are eligible for Credit Card approval, so that they can specifically target these customers.","372e8238":"Logistic Model Accuracy            : 50.60  %\nDecisionTree Model Accuracy        : 69.55  %\nRandom Forest Model Accuracy       : 76.00  %\nSupport Vector Classifier Accuracy : 49.79  %\nKNN Model Accuracy                 : 45.98  %\nXGBoost Model Accuracy             : 84.14  %","889b7dca":"# Conclusion","d635fe3f":"# Merging Dataframes","056e343d":"#### On File - Application Record.csv"}}