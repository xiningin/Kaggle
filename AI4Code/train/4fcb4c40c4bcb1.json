{"cell_type":{"d3146ae1":"code","25672907":"code","6bcdd5f7":"code","119fb9b8":"code","b3826db9":"code","b7eb8a3b":"code","f45bf65b":"code","2f112692":"code","aa92a448":"code","4e9c1a91":"code","9339cc0e":"code","6a0c206b":"code","d599f905":"code","4ef8516b":"code","b8e325d6":"code","ba166f7d":"code","092d8c8d":"code","f8aafb11":"code","5440585e":"code","04a5ea89":"code","9cde0950":"code","74e4148a":"code","0005d08e":"code","218b35a1":"code","5a205069":"code","da9543cd":"code","db4ee67d":"code","049cb1bd":"code","ae6ef973":"code","fc85c1b5":"code","680a3b6d":"code","45bea872":"markdown","949886f6":"markdown","484eabba":"markdown","dcd6ef10":"markdown","c58a6d49":"markdown","a9693dde":"markdown","83d48863":"markdown","6c37191c":"markdown","5c62f799":"markdown","1e8ff306":"markdown","eb46c824":"markdown","bb9b77ef":"markdown","397ed324":"markdown","20da1477":"markdown","355b8011":"markdown","aa59b71d":"markdown","e02072a3":"markdown","850326ed":"markdown","fa5bc1c2":"markdown","b2c2c5d5":"markdown","e4fa6c69":"markdown"},"source":{"d3146ae1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom scipy.stats import iqr \n%matplotlib inline","25672907":"# Loading the Dataset\ndata = pd.read_csv('\/kaggle\/input\/concrete-compressive-strength-data-set\/compresive_strength_concrete.csv')\n# lets take a look on dataset\ndata.head()","6bcdd5f7":"#Renaming feature names\ncol_map = {'Cement (component 1)(kg in a m^3 mixture)': 'cement',\n 'Blast Furnace Slag (component 2)(kg in a m^3 mixture)': 'slag',\n 'Fly Ash (component 3)(kg in a m^3 mixture)': 'ash',\n 'Water  (component 4)(kg in a m^3 mixture)': 'water',\n 'Superplasticizer (component 5)(kg in a m^3 mixture)': 'superplastic',\n 'Coarse Aggregate  (component 6)(kg in a m^3 mixture)': 'coarseagg',\n 'Fine Aggregate (component 7)(kg in a m^3 mixture)': 'fineagg',\n 'Age (day)': 'age',\n 'Concrete compressive strength(MPa, megapascals) ': 'strength'}","119fb9b8":"data.rename(columns=col_map,inplace=True)\ndata.head()","b3826db9":"# Checking for null values in dataset\ndata.info()","b7eb8a3b":"# Five Point Statistics Summary\n#data.describe().T\nsummary = data.describe().T\nsummary['Diff'] = summary['mean'] - summary['50%']\nsummary","f45bf65b":"sns.pairplot(data)","2f112692":"## Plotting BoxPlot to perform univariate analysis\ndata.plot(kind='box',figsize=(15,8))","aa92a448":"# Function to find the Upper Cut-off & Median Value for the Given Variable\ndef outlier_cap(df):\n    IQR = iqr(df)\n    Q3 = np.percentile(df,75)\n    ucap = IQR*1.5 + Q3\n    median = df[df<ucap].median()\n    return ucap,median","4e9c1a91":"# Treating fineagg outlier\nf,((ax_box,ax_box_post),(ax_hist,ax_hist_post)) = plt.subplots(2,2,gridspec_kw={'height_ratios':(0.15,0.85)},figsize=(10,7))\nsns.boxplot(data['fineagg'],ax=ax_box).set_title(\"fineagg_Pre\")\nsns.distplot(data['fineagg'],ax=ax_hist)\nucap_fineagg,median_fineagg = outlier_cap(data['fineagg'])\ndata.loc[data['fineagg']>ucap_fineagg,'fineagg'] = median_fineagg\nsns.boxplot(data['fineagg'],ax=ax_box_post).set_title(\"fineagg_Post\")\nsns.distplot(data['fineagg'],ax=ax_hist_post)","9339cc0e":"# Treating age outlier\nf,((ax_box,ax_box_post),(ax_hist,ax_hist_post)) = plt.subplots(2,2,gridspec_kw={'height_ratios':(0.15,0.85)},figsize=(10,7))\nsns.boxplot(data['age'],ax=ax_box).set_title(\"age_Pre\")\nsns.distplot(data['age'],ax=ax_hist)\nucap_age,median_age = outlier_cap(data['age'])\ndata.loc[data['age']>ucap_age,'age'] = median_age\nsns.boxplot(data['age'],ax=ax_box_post).set_title(\"age_Post\")\nsns.distplot(data['age'],ax=ax_hist_post)","6a0c206b":"#%matplotlib notebook\nplt.figure(figsize=(9,5))\ncorr = data.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n#ax = sns.heatmap(corr,annot=True,linewidth=0.5)\nwith sns.axes_style(\"white\"):\n    ax = sns.heatmap(corr,annot=True,linewidth=2,\n                mask = mask,cmap=\"magma\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\n","d599f905":"# Feature Engineering\ndata['water_cement'] = data['cement']\/data['water']\ndata.corr()","4ef8516b":"#Splitting the dataset in X & y\nX = data.drop(['strength','cement','water'],axis=1)\ny = data['strength']","b8e325d6":"# Importing preprocessing & sklearn libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","ba166f7d":"# Splitting the dataset into training & testing dataset\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=400)\n\n#Scaling the dataset\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","092d8c8d":"# Importing linear , Tree & Ensemble model libraries\nfrom sklearn.linear_model import Lasso,Ridge\nfrom sklearn.ensemble import BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor","f8aafb11":"#Lets create a Lasso object & try to fit our model\nreg_lasso = Lasso(alpha=0.1,max_iter=10e5)\nreg_lasso.fit(X_train_scaled,y_train)\n#Checking the train & test score\nprint(\"Train Score {} & Test Score {}\".format(reg_lasso.score(X_train_scaled,y_train),reg_lasso.score(X_test_scaled,y_test)))","5440585e":"# Lets check the Feature Coefficent of Lasso Model\nvalues = np.argsort(reg_lasso.coef_)\nval = sorted(reg_lasso.coef_)\ncolumns = X.columns.tolist()\ncol = [columns[i] for i in values]\nplt.bar(col,val)\nplt.title(\"Lasso Co-efficient Plot\")\nplt.xticks(rotation=45)","04a5ea89":"#Lets create a Ridge object & try to fit our model\nreg_ridge = Ridge(alpha=0.01,max_iter=10e5)\nreg_ridge.fit(X_train_scaled,y_train)\nprint(\"Train Score {} & Test Score {}\".format(reg_ridge.score(X_train_scaled,y_train),reg_ridge.score(X_test_scaled,y_test)))","9cde0950":"# Lets check the Feature Coefficent of Ridge Model\nvalues = np.argsort(reg_ridge.coef_)\nval = sorted(reg_ridge.coef_)\ncolumns = X.columns.tolist()\ncol = [columns[i] for i in values]\nplt.title(\"Ridge Co-efficient Plot\")\nplt.bar(col,val)\nplt.xticks(rotation=45)","74e4148a":"#Modelling with DecisionTreeRegressor\nreg_dt = DecisionTreeRegressor()\nreg_dt.fit(X_train,y_train)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_dt.score(X_train,y_train),reg_dt.score(X_test,y_test)))","0005d08e":"#Tuning Hyperparameter max_depth & min_sam_split of DecisionTreeRegressor\nmax_d = list(range(1,10))\nmin_sam_split = list(range(10,50,15))\nfrom sklearn.model_selection import GridSearchCV\ngridcv = GridSearchCV(reg_dt,param_grid={'max_depth':max_d,'min_samples_split':min_sam_split},n_jobs=-1)\ngridcv.fit(X_train,y_train)","218b35a1":"print(\"Parameters :\",gridcv.best_params_)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(gridcv.score(X_train,y_train),gridcv.score(X_test,y_test)))","5a205069":"# Lets find out the feature importance based on DecisionTree Model\nimportances = reg_dt.feature_importances_\ncol = X.columns.tolist()\nindices = importances.argsort()[::-1]\nnames = [col[i] for i in indices]\n\n# Plotting Feature importance Chart\nplt.title(\"Decision Tree: Feature Importance\")\nplt.bar(range(X.shape[1]),importances[indices])\nplt.xticks(range(X.shape[1]),names,rotation=45);","da9543cd":"#Modelling with RandomForestRegressor\nreg_rfe = RandomForestRegressor()\nreg_rfe.fit(X_train,y_train)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_rfe.score(X_train,y_train),reg_rfe.score(X_test,y_test)))","db4ee67d":"# Tuning Hyperparameter of DecisionTreeRegressor\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Maximum number of levels in tree\nmax_depth = list(range(10,110,10))\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\nfrom sklearn.model_selection import GridSearchCV\ngridcv_rf = GridSearchCV(reg_rfe,param_grid={'n_estimators':n_estimators,'max_depth':max_depth,'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf},n_jobs=-1)\ngridcv_rf.fit(X_train,y_train)","049cb1bd":"print(\"Best Parameters:\",gridcv_rf.best_params_)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(gridcv_rf.score(X_train,y_train),gridcv_rf.score(X_test,y_test)))","ae6ef973":"import xgboost\nreg_xgb = xgboost.XGBRegressor()\n# Fitting model \nreg_xgb.fit(X_train,y_train)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))","fc85c1b5":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ngridcv_xgb = GridSearchCV(reg_xgb,param_grid={'n_estimators':list(range(100,1000,100)),'max_depth':list(range(1,10,1)),\n                                     'learning_rate':[0.0001,0.001,0.005,0.01,0.05,0.1,0.15,0.2,0.25,0.3]})\ngridcv_xgb.fit(X_train,y_train);","680a3b6d":"print(\"Best Parameter:\",gridcv_xgb.best_params_)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(gridcv_xgb.score(X_train,y_train),gridcv_xgb.score(X_test,y_test)))","45bea872":"> water_cement & age followed by slag seems to be the most importance feature.\n\n# Lets use Ensemble Technique\n\n### RandomForest Model\n","949886f6":"- Cement, Superplastic & age is highly correlated with dependent variable.\n- water is highly correlated with superplastic.\n- As we know the perfect ratio of water & cement gives concrete the desired strength.\n- Lets try to take a ratio of cement & water to make new feature.","484eabba":"### We have used following model and the results are :\n1. Lasso : Train Score 0.70 & Test Score 0.70\n2. Ridge : Train Score 0.70 & Test Score 0.70\n3. Decision Tree : Train Score 0.93 & Test Score 0.83\n4. RandomForest : Train Score 0.98 & Test Score 0.92\n\nNow Lets Try to model it using XGBoost Regressor","dcd6ef10":"# To Predict the Strength of Concrete\n\n\n\n## **Context:**\nConcrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. These ingredients include cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, and fine aggregate.\n\n## **Data Description:**\nThe actual concrete compressive strength (MPa) for a given mixture under a\nspecific age (days) was determined from laboratory. Data is in raw form (not scaled).The data has 8 quantitative input variables, and 1 quantitative output variable, and 1030 instances (observations).\n\n## **Objective:**\nModeling of strength of high performance concrete using Machine Learning","c58a6d49":"# <u>Summary :<\/u>\n\n### Linear Model\n- Accuracy on Test Data Set with Lasso Regression : 70%\n- Accuracy on Test Data Set with Ridge Regression : 70%\n\n### Tree Model\n- Accuracy on Test Data Set with DecisionTree Regression : 85%\n\n### Ensemble Model\n- Accuracy on Test Data Set with RandomForest Regression : 92%\n\n### XGBoost Model\n- Accuracy on Test Data Set with XGBoost Regression : 94%\n\n> So far <b>XGBoostRegression<\/b> proved to be the best performing model with 94% accuracy.\n","a9693dde":"### Inference\n1. As inferred, slag, ash & age are right skewed and variable cement is also slight right skewed.\n2. Most of the other features has multimodal distribution.\n\n## Univariate Analysis","83d48863":"- As usual Decision Tree seems to have overfit.\n- Let try to tune to hyperparameter.","6c37191c":"> With Hyperparameter Tuning using Gridsearchcv, we have been able to improve the accuracy of Model from 90% to 92%.","5c62f799":"## Bivariate Analysis","1e8ff306":"# DecisionTree Model","eb46c824":"### Inference\n1. Slag, Ash & Age has right skewed distribution as Mean > Median.\n2. Even the Cement Variable is slightly right skewed.\n\n### Now lets plot and check the distribution","bb9b77ef":"### Lets import all the required libraries","397ed324":"1. Feature \"fineagg\" & \"age\" has extreme outliers.\n2. Feature \"Slag\", \"Water\" and \"superplastic\" also has outlier but are not extreme so we do not need to treat them.","20da1477":"### Lets Explore the Dataset","355b8011":"# Lasso Regression","aa59b71d":"- From above chart, new created feature water_cement is showing a good correlation with dependent variable.\n- Also as superplastic is highly correlated with another independent variable i.e water.\n- lets drop water & cement from the dataset","e02072a3":"# XGBoost","850326ed":">Bar Chart Shows that \"courseagg\" has co-efficient close to zero.\n>New Engineering Feature has the highest coe-efficient values.","fa5bc1c2":"## Exploratory Data Analysis","b2c2c5d5":"# Ridge Regression","e4fa6c69":"### Outlier Treatment\n1. Find out the samples which are beyond the (IQR*1.5 + Q3) values.\n2. Replace all such values with the Median.\n\nNote: Median is robust to the effect of Outlier."}}