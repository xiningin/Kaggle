{"cell_type":{"33eae36d":"code","76bc3f06":"code","ed93c0d1":"code","4b3c9c89":"code","f365ebd9":"code","6dc1a6c1":"code","2a3facf2":"code","92c3c6d0":"code","52c8647d":"code","07d15332":"code","998bce27":"code","4292838e":"code","9ad74e9d":"code","a74fe615":"code","a43c9579":"code","d6e224dc":"code","aca2eb08":"code","fa4f61b1":"code","c44b324e":"code","26bb8fb3":"code","a6b0b951":"code","13943508":"code","f91116b3":"code","d07c79c7":"code","1a06c5ea":"code","5eea36ae":"code","d3671553":"code","56b7e78b":"code","d2efefe9":"code","44fd1416":"code","36f5928a":"code","b73e0c1b":"code","859bbb07":"code","cf94a046":"code","adff1500":"code","198748d5":"code","3bb98f1c":"code","7b328e2d":"code","d02cedaa":"code","8d35e297":"code","4f4b324f":"code","fc179d8a":"markdown","3d7845cb":"markdown"},"source":{"33eae36d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","76bc3f06":"import os\nimport numpy as np\nimport torch\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom collections import OrderedDict\nimport time\nimport copy\nfrom PIL import Image\n\n%matplotlib inline","ed93c0d1":"data_dir = '..\/input\/hackathon-blossom-flower-classification\/'\ntrain_dir = data_dir + 'flower_data\/flower_data\/train'\nvalid_dir = data_dir + 'flower_data\/flower_data\/valid'\ntest_dir = data_dir + 'test set\/test set\/'","4b3c9c89":"import json\n\nwith open('..\/input\/hackathon-blossom-flower-classification\/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)","f365ebd9":"# Data augmentation and normalization for training\n# Just normalization for validation\nbatch_size=32\nnum_workers=0\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomRotation(45),\n        transforms.Resize(226),\n        transforms.CenterCrop(224),\n        transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n        transforms.ColorJitter(hue=.08, saturation=.08),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(226),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    \n    'test': transforms.Compose([\n        transforms.Resize(226),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n    ])\n    \n}\n\n\nimage_datasets = {\n    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n    'valid':datasets.ImageFolder(valid_dir, transform=data_transforms['valid']),\n    'test':datasets.ImageFolder('..\/input\/hackathon-blossom-flower-classification\/test set\/', transform=data_transforms['test'])\n}\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers)\n              for x in ['train', 'valid', 'test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","6dc1a6c1":"classes=[]\nfor i in image_datasets['train'].classes:\n    classes.append(cat_to_name[i])\n","2a3facf2":"from PIL import Image\ndef imshow1(inp):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)","92c3c6d0":"images, labels = next(iter(dataloaders['train']))                      \nprint(labels)\n#images = images.numpy()\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(35, 6))\nfor idx in np.arange(batch_size):\n    ax = fig.add_subplot(batch_size\/16, batch_size\/2, idx+1, xticks=[], yticks=[])\n    imshow1(images[idx])\n    ax.set_title(classes[labels[idx]])","52c8647d":"def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    \n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        \n        \"\"\"if epoch > 20:\n            for param in model_ft.parameters():\n              param.requires_grad = True\"\"\"\n            \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                print('Accuracy increased ({:.6f} --> {:.6f}).  Saving model checkpoint13jul ...'.format(best_acc, epoch_acc))\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                # save model if loss has decreased\n                model.cpu()\n                torch.save({'epoch': epoch + 1,\n                                 'state_dict': model.state_dict(),\n                                 'optimizer' : optimizer.state_dict(),\n                                 'model': 'densenet161',\n                                 'loss': loss,\n                                 'class_to_idx': model_ft.class_to_idx},\n                                 '.\/checkpoint1.pth'\n                                )\n                model.cuda()\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","07d15332":"model_ft = models.densenet201(pretrained=True)\nmodel_ft.class_to_idx = image_datasets['train'].class_to_idx\nmodel_ft.classifier.cpu()","998bce27":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\nprint(torch.cuda.is_available())\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\n    ","4292838e":"n_inputs = 1920\n# Freeze parameters so we don't backprop through them\n\n\n  \nfor i in range(len(model_ft.features)-6):\n    model_ft.features[i].requires_grad = False\n\nfor i in range(6,12):\n    model_ft.features[i].requires_grad=True\n    \n\"\"\" \nct = 0\nfor child in model_ft.children():\n  ct += 1\n  if ct < 10:\n    for param in child.parameters():\n        param.requires_grad = False\"\"\"\n\nfrom collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(n_inputs, 500)),\n                          ('relu', nn.ReLU()),\n                          ('dropout', nn.Dropout(0.4)),\n                          ('fc2', nn.Linear(500, 102)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel_ft.classifier = classifier\nmodel_ft = model_ft.to(device)\n\n# Criteria NLLLoss which is recommended with Softmax final layer\ncriterion = nn.NLLLoss()\n\n# Observe that all parameters are being optimized\n#optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n#try with\n#optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n","9ad74e9d":"#model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)","a74fe615":"#torch.save({'model': 'densenet201',\n#            'state_dict': model_ft.state_dict(), \n#           'class_to_idx': model_ft.class_to_idx}, \n#            'classifier13_1.pt')","a43c9579":"#unfreeze parameters\n#for param in model_ft.parameters():\n#    param.requires_grad = True\n\n#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n# Decay LR by a factor of 0.1 every 7 epochs\n#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n","d6e224dc":"#model_rt = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)","aca2eb08":"#torch.save({'model': 'densenet201',\n#            'state_dict': model_ft.state_dict(), \n#            'class_to_idx': model_ft.class_to_idx}, \n#            'classifier13_98.pt')","fa4f61b1":"def load_model(checkpoint_path):\n    chpt = torch.load(checkpoint_path)\n    \n    if chpt['model'] == 'densenet201':\n        model_ft = models.densenet201(pretrained=False)\n        for param in model_ft.parameters():\n            param.requires_grad = False\n    else:\n        print(\"Sorry base architecture note recognized\")\n      \n    \n    model_ft.class_to_idx = chpt['class_to_idx']\n    from collections import OrderedDict\n    # Create the classifier\n    classifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(n_inputs, 500)),\n                          ('relu', nn.ReLU()),\n                          ('dropout', nn.Dropout(0.2)),\n                          ('fc2', nn.Linear(500, 102)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \n    # Put the classifier on the pretrained network\n    model_ft.classifier = classifier\n    \n    model_ft.load_state_dict(chpt['state_dict'])\n    \n    return model_ft","c44b324e":"# I am reloading a previously trained model because my kernel just shut down \n#suddendly while I was finishing up \nmodel_rl =load_model('..\/input\/hackathon-blossom-challenge-v2\/classifier13_98.pt')\nmodel_rl.cuda()","26bb8fb3":"def visualize_model(model, num_images=8):\n    model.cuda()\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['valid']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            print(labels)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            print(inputs.size()[0])\n            \n            \n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far) #subplot(nrows, ncols, index, **kwargs)\n                #ax = plt.subplot(num_images\/\/2, 2, j+1, xticks=[], yticks=[])\n                ax.axis('off')\n                ax.set_title('{}'.format(classes[preds[j]]) + ' ({})'.format(classes[labels[j]]), color=(\"green\" if preds[j]==labels[j] else \"red\"))\n               \n                imshow1(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","a6b0b951":"visualize_model(model_rl)","13943508":"def calc_accuracy(model, data):\n    model.eval()\n    model.to(device)    \n    \n    with torch.no_grad():\n        batch_accuracy=[]\n        for idx, (inputs, labels) in enumerate(data):\n            inputs, labels = inputs.cuda(), labels.cuda()\n            # obtain the outputs from the model\n            outputs = model.forward(inputs)\n            # max provides the (maximum probability, max value)\n            _, predicted = outputs.max(dim=1)\n            # check the \n            #if idx == 0:\n                #print(\"predicted flower type\", predicted) #the predicted class\n                #print(\"label data\", labels.data)\n                #print(\"how sure is model\", torch.exp(_)) # the predicted probability\n            equals = predicted == labels.data\n            #if idx == 0:\n               # print(\"correct or not\", equals)\n            #print(\"accuracy for each batch\", equals.float().mean())\n            batch_accuracy.append(equals.float().mean().cpu().numpy())\n            mean_acc = np.mean(batch_accuracy)\n            print(\"Mean accuracy: {}\".format(mean_acc))\n    return mean_acc","f91116b3":"calc_accuracy(model_rl, dataloaders['valid'])","d07c79c7":"# track test loss \ndef calculate_loss(model, dataloader):\n    test_loss = 0.0\n    class_correct = list(0. for i in range(102))\n    class_total = list(0. for i in range(102))\n\n    model.eval() # eval mode\n\n    # iterate over test data\n    for data, target in dataloader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update  test loss \n        test_loss += loss.item()*data.size(0)\n        # convert output probabilities to predicted class\n        _, pred = torch.max(output, 1)    \n        # compare predictions to true label\n        correct_tensor = pred.eq(target.data.view_as(pred))\n        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n        # calculate test accuracy for each object class\n        for i in range(len(data)):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n    # calculate avg test loss\n    test_loss = test_loss\/len(dataloader.dataset)\n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n      \n    \n    ","1a06c5ea":"calculate_loss(model_rl, dataloaders['valid'])","5eea36ae":"def predict_flowername(image_path, model):\n    \n    # Process image\n    img = transform_image(image_path)\n        \n    # Predict     \n    # Numpy -> Tensor\n    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n    #remove alpha channel in png\n    image_tensor = image_tensor[:3,:,:]\n    #print(image_tensor.shape)\n    # Add batch of size 1 to image\n    model_input = image_tensor.unsqueeze(0)\n    #print(model_input.shape)\n    # Probs\n    probs = torch.exp(model.forward(model_input.cuda()))\n    \n    # Top probs\n    probs, labs = probs.topk(5)\n    #prob=probs[0].cpu()\n    #print(labs)\n    lab = labs[0].cpu()\n    # Convert indices to classes\n    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n    label = idx_to_class[lab[0].item()]\n    flower_name = cat_to_name[label]\n\n    return flower_name","d3671553":"def transform_image(image_path):\n    ''' \n    Scales, crops, and normalizes a PIL image for a PyTorch       \n    model, returns an Numpy array\n    '''\n    # Open the image\n    from PIL import Image\n    img = Image.open(image_path)\n    # Resize\n    if img.size[0] > img.size[1]:\n        img.thumbnail((10000, 226))\n    else:\n        img.thumbnail((226, 10000))\n\n    # Normalize\n    img = np.array(img)\/255\n    mean = np.array([0.485, 0.456, 0.406]) #provided mean\n    std = np.array([0.229, 0.224, 0.225]) #provided std\n    #img = (img - mean)\/std\n    \n    # Move color channels to first dimension as expected by PyTorch\n    img = img.transpose((2, 0, 1))\n   # print(img.shape)\n    \n    return img","56b7e78b":"#create list of url and flower names\ndata = []\nfor img_filename in os.listdir(test_dir):\n    image_path= test_dir + img_filename\n    \n    flower_name = predict_flowername(image_path, model_rl)\n   # print(image_path, flower_name)\n    if flower_name != None:\n        data.append([img_filename, flower_name])    \n","d2efefe9":"len(data)","44fd1416":"df = pd.DataFrame(data, columns = ['file','species'])\npd.set_option('display.max_colwidth', -1)\nresult = df.sort_values(['file', 'species'], ascending=[1, 0])\nresult","36f5928a":"df.to_csv(r'.\/flowers_FP.csv')","b73e0c1b":"def process_image(image_path):\n    ''' \n    Scales, crops, and normalizes a PIL image for a PyTorch       \n    model, returns an Numpy array\n    '''\n    # Open the image\n    from PIL import Image\n    img = Image.open(image_path)\n    # Resize\n    if img.size[0] > img.size[1]:\n        img.thumbnail((10000, 226))\n    else:\n        img.thumbnail((226, 10000))\n    # Crop \n    left_margin = (img.width-224)\/2\n    bottom_margin = (img.height-224)\/2\n    right_margin = left_margin + 224\n    top_margin = bottom_margin + 224\n    img = img.crop((left_margin, bottom_margin, right_margin,   \n                      top_margin))\n    # Normalize\n    img = np.array(img)\/255\n    mean = np.array([0.485, 0.456, 0.406]) #provided mean\n    std = np.array([0.229, 0.224, 0.225]) #provided std\n    img = (img - mean)\/std\n    \n    # Move color channels to first dimension as expected by PyTorch\n    img = img.transpose((2, 0, 1))\n    \n    return img","859bbb07":"def predict(image_path, model, top_num=5):\n    # Process image\n    img = process_image(image_path)\n    \n    # Numpy -> Tensor\n    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n    # Add batch of size 1 to image\n    model_input = image_tensor.unsqueeze(0)\n    \n    # Probs\n    probs = torch.exp(model.forward(model_input))\n    \n    # Top probs\n    top_probs, top_labs = probs.topk(top_num)\n    top_probs = top_probs.detach().numpy().tolist()[0] \n    top_labs = top_labs.detach().numpy().tolist()[0]\n    \n    # Convert indices to classes\n    idx_to_class = {val: key for key, val in    \n                                      model.class_to_idx.items()}\n    top_labels = [idx_to_class[lab] for lab in top_labs]\n    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n    return top_probs, top_labels, top_flowers","cf94a046":"import seaborn as sns\ndef plot_solution(image_path, model):\n    # Set up plot\n    plt.figure(figsize = (6,10))\n    ax = plt.subplot(2,1,1)\n    # Set up title\n    #flower_num = image_path.split('\/')[path_num]\n    #print(flower_num)\n    \n    # Plot flower\n    \n    img = process_image(image_path)\n    \n    # Make prediction\n    probs, labs, flowers = predict(image_path, model.cpu()) \n    title_ = cat_to_name[labs[0]]\n    imshow(img, ax, title = title_);\n    print(labs)\n    # Plot bar chart\n    plt.subplot(2,1,2)\n    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n    plt.show()","adff1500":"def imshow(image, ax=None, title=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    if title:\n        plt.title(title)\n    # PyTorch tensors assume the color channel is first\n    # but matplotlib assumes is the third dimension\n    image = image.transpose((1, 2, 0))\n    \n    # Undo preprocessing\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n    \n    # Image needs to be clipped between 0 and 1\n    image = np.clip(image, 0, 1)\n    \n    ax.imshow(image)\n    \n    return ax","198748d5":"image_path = \"..\/input\/hackathon-blossom-flower-classification\/test set\/test set\/nic23.jpg\"\nplot_solution(image_path, model_rl)","3bb98f1c":"image_path = \"..\/input\/hackathon-blossom-flower-classification\/test set\/test set\/ab42.jpg\"\nplot_solution(image_path, model_rl)","7b328e2d":"image_path = \"..\/input\/hackathon-blossom-flower-classification\/test set\/test set\/ab44.jpg\"\nplot_solution(image_path, model_rl)","d02cedaa":"image_path = \"..\/input\/hackathon-blossom-flower-classification\/test set\/test set\/ab49.jpg\"\nplot_solution(image_path, model_rl)","8d35e297":"image_path = \"..\/input\/hackathon-blossom-flower-classification\/test set\/test set\/ab50.jpg\"\nplot_solution(image_path, model_rl)","4f4b324f":"image_path = \"..\/input\/hackathon-blossom-flower-classification\/test set\/test set\/ab52.jpeg\"\nplot_solution(image_path, model_rl)","fc179d8a":"Model: I have used the Densenet 201 pretrained model, froze the first layers and retrained the rest.\nI have used optimizer SGD with momentum, a learning rate of 0.001 and a sheduler StepLR to decrease the learning rate with steps of 5-7 epochs. I trained first with frozen parameters, then retrained the same model with unfrozen parameters and with different hyperparameters.\nMost of the code is taken from a previous Pytorch challenge where I have used different resources, mainly Pytorch Tutorials and Udacity code. Unfortunately the classifier I use here to produce the results is not the one I have trained. I lost my work a couple of times and not everything was saved.","3d7845cb":"**Prediction results**"}}