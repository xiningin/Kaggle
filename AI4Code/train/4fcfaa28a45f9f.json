{"cell_type":{"082e0ea5":"code","b5c9d761":"code","b2daa11e":"code","356491e5":"code","4dfbfe73":"code","585598ee":"code","635a804f":"code","aa75db3e":"code","324ebec3":"code","85270de4":"code","0250fbe5":"code","a730ea41":"code","f0b15a6f":"code","c5fcf7e3":"code","6d54f073":"code","fd98e23d":"code","83ef7efc":"code","8a9d7dd0":"code","b3453fc9":"code","89526084":"code","fa80b8a8":"code","6a5d40c8":"code","dc302b75":"code","722e03c5":"code","a382d25a":"code","03af5dcb":"code","8c383237":"markdown","de124e61":"markdown","5db9751f":"markdown","00070756":"markdown","d9022c84":"markdown","24c7df2b":"markdown","404cffcc":"markdown","c5b3b8b0":"markdown"},"source":{"082e0ea5":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt \nimport torch.nn.functional as F \nimport torch \nimport numpy as np ","b5c9d761":"class CNFG:\n\n    epochs =10                              \n    lr = 0.001                              \n    batch_size = 16                         \n\n    model_name = 'tf_efficientnet_b4_ns'    \n    img_size = 224                          \n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:{}\".format(device))","b2daa11e":"from torchvision import transforms as T,datasets","356491e5":"train_transform = T.Compose([\n                             T.Resize(size=(CNFG.img_size,CNFG.img_size)), # Resizing the image to be 224 by 224\n                             T.RandomRotation(degrees=(-20,+20)), #Randomly Rotate Images by +\/- 20 degrees, Image argumentation for each epoch\n                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n\n])\n\nvalidate_transform = T.Compose([\n                             \n                             T.Resize(size=(CNFG.img_size,CNFG.img_size)), \n                             T.ToTensor(), \n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) \n\n])\n\ntest_transform = T.Compose([\n                             \n                             T.Resize(size=(CNFG.img_size,CNFG.img_size)),\n                             T.ToTensor(), \n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) \n\n])","4dfbfe73":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid","585598ee":"train_dir='..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_dir='..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_dir='..\/input\/chest-xray-pneumonia\/chest_xray\/val'","635a804f":"train_data = datasets.ImageFolder(train_dir,       \n                    transform=train_transform)\ntest_data = datasets.ImageFolder(test_dir,\n                    transform=test_transform)\nval_data = datasets.ImageFolder(val_dir,\n                    transform=test_transform)","aa75db3e":"len(val_data)","324ebec3":"def show_image(image,label,get_denormalize = True):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    if get_denormalize == True:\n        image = image*std + mean\n        image = np.clip(image,0,1)\n        plt.imshow(image)\n        plt.title(label)\n        \n    else: \n        plt.imshow(image)\n        plt.title(label)\n\ndef show_grid(image,title = None):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    image = image*std + mean\n    image = np.clip(image,0,1)\n    \n    plt.figure(figsize=[15, 15])\n    plt.imshow(image)\n    if title != None:\n        plt.title(title)\n\n\ndef accuracy(y_pred,y_true):\n    y_pred = F.softmax(y_pred,dim = 1)\n    top_p,top_class = y_pred.topk(1,dim = 1)\n    equals = top_class == y_true.view(*top_class.shape)\n    return torch.mean(equals.type(torch.FloatTensor))\n\n\ndef view_classify(image,ps,label):\n    \n    class_name = ['NORMAL', 'PNEUMONIA']\n    classes = np.array(class_name)\n\n    ps = ps.cpu().data.numpy().squeeze()\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    \n    image = image*std + mean\n    img = np.clip(image,0,1)\n    \n    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    return None","85270de4":"img, label = train_data[0]\nshow_image(img, label)","0250fbe5":"trainloader = DataLoader(train_data,batch_size=CNFG.batch_size,shuffle=True)\nprint(\"No. of batches in trainloader:{}\".format(len(trainloader))) \nprint(\"No. of Total examples:{}\".format(len(trainloader.dataset)))","a730ea41":"validationloader = DataLoader(val_data,batch_size=CNFG.batch_size,shuffle=True)\nprint(\"No. of batches in validationloader:{}\".format(len(validationloader)))  \nprint(\"No. of Total examples:{}\".format(len(validationloader.dataset)))","f0b15a6f":"testloader = DataLoader(test_data,batch_size=CNFG.batch_size,shuffle=True)\nprint(\"No. of batches in testloader:{}\".format(len(testloader))) \nprint(\"No. of Total examples:{}\".format(len(testloader.dataset)))","c5fcf7e3":"class_name = ['NORMAL', 'PNEUMONIA']","6d54f073":"dataiter = iter(trainloader)\nimages,labels = dataiter.next()\n\nout = make_grid(images,nrow=4)\n\nshow_grid(out,title = [class_name[x] for x in labels])","fd98e23d":"!pip install timm","83ef7efc":"from torch import nn\nimport torch.nn.functional as F\nimport timm # PyTorch Image Models\n\nmodel = timm.create_model(CNFG.model_name,pretrained=True) #load pretrained model","8a9d7dd0":"model","b3453fc9":"#Updating the pretarined model:\nfor param in model.parameters():\n    param.requires_grad=False\n\nmodel.classifier = nn.Sequential(\n    nn.Linear(in_features=1792, out_features=625), #1792 is the orginal in_features\n    nn.ReLU(), #ReLu to be the activation function\n    nn.Dropout(p=0.3),\n    nn.Linear(in_features=625, out_features=256),\n    nn.ReLU(),\n    nn.Linear(in_features=256, out_features=2), \n)\n\nmodel","89526084":"!pip install torchsummary","fa80b8a8":"from torchsummary import  summary\nmodel.to(device) # move the model to GPU\nsummary(model,input_size=(3,224,224))","6a5d40c8":"class PneumoniaTrainer():\n    \n    def __init__(self,criterion = None,optimizer = None,schedular = None):\n        \n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.schedular = schedular\n    \n    def train_batch_loop(self,model,trainloader):\n        \n        train_loss = 0.0\n        train_acc = 0.0\n        \n        for images,labels in tqdm(trainloader): \n            \n            # move the data to CPU\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = self.criterion(outputs,labels)\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            train_loss += loss.item()\n            train_acc += accuracy(outputs,labels)\n            \n        return train_loss \/ len(trainloader), train_acc \/ len(trainloader) \n\n    \n    def valid_batch_loop(self,model,validloader):\n        \n        valid_loss = 0.0\n        valid_acc = 0.0\n        \n        for images,labels in tqdm(validloader):\n            \n            # move the data to CPU\n            images = images.to(device) \n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = self.criterion(outputs,labels)\n            \n            valid_loss += loss.item()\n            valid_acc += accuracy(outputs,labels)\n            \n        return valid_loss \/ len(validloader), valid_acc \/ len(validloader)\n            \n        \n    def fit(self,model,trainloader,validloader,epochs):\n        \n        valid_min_loss = np.Inf \n        \n        for i in range(epochs):\n            \n            model.train() # this turn on dropout\n            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader) ###\n            \n            model.eval()  # this turns off the dropout lapyer and batch norm\n            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader) ###\n            \n            if avg_valid_loss <= valid_min_loss :\n                print(\"Valid_loss decreased {} --> {}\".format(valid_min_loss,avg_valid_loss))\n                torch.save(model.state_dict(),'ColabPneumoniaModel.pt')\n                valid_min_loss = avg_valid_loss\n\n                \n            print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(i+1, avg_train_loss, avg_train_acc))\n            print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(i+1, avg_valid_loss, avg_valid_acc))","dc302b75":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = CNFG.lr)\n\ntrainer = PneumoniaTrainer(criterion,optimizer)\ntrainer.fit(model,trainloader,validationloader,epochs = CNFG.epochs)","722e03c5":"model.eval()\n\navg_test_loss, avg_test_acc = trainer.valid_batch_loop(model,testloader)\n\n\nprint(\"Test Loss : {}\".format(avg_test_loss))\nprint(\"Test Acc : {}\".format(avg_test_acc))","a382d25a":"import torch.nn.functional as F\n\nimage,label = test_data[15]\n\nps = model(image.to(device).unsqueeze(0))\nps = F.softmax(ps,dim = 1)\n\nview_classify(image,ps,label)","03af5dcb":"import torch.nn.functional as F\n\nimage,label = test_data[325]\n\nps = model(image.to(device).unsqueeze(0))\nps = F.softmax(ps,dim = 1)\n\nview_classify(image,ps,label)","8c383237":"# Defininf some functions","de124e61":"# Evaluating the model!","5db9751f":"# Creating the Configuration Class","00070756":"# Importing the pre-trained EfficientNet model!","d9022c84":"# An accuracy of 94% on the training data and 90% on the test data!","24c7df2b":"# Transforming the data","404cffcc":"# DataLoaders","c5b3b8b0":"# Training the model"}}