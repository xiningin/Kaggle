{"cell_type":{"bf4c9c5e":"code","df5f49a1":"code","552cbe5e":"code","3102fd8f":"code","38f10b4a":"code","7be7c660":"code","69835a92":"code","27dfa618":"code","4e7b1963":"code","894c1427":"code","6e88bc94":"code","8430b17e":"code","e098906d":"code","e8872780":"code","14c4c11a":"code","25d3ad19":"code","5a62ce42":"code","1e838737":"code","6116ce71":"code","8bf07dcf":"code","8bdcaaf1":"code","3bd1799d":"code","6875e33b":"code","da4888b8":"code","d5377ce8":"code","704a34d1":"code","ebaa1cc5":"code","6eae3dcf":"code","5f461416":"code","f108c8bb":"code","16348c87":"code","8b4821b2":"code","bb8862d3":"code","32051b82":"code","ad9a8e7c":"code","2d4441e9":"code","a73dc6d4":"markdown","f66d2016":"markdown","2ac06ca7":"markdown","215a4fb0":"markdown","2c4bfaad":"markdown","20bd205b":"markdown","98917054":"markdown","e39b71cd":"markdown","d088c67c":"markdown","166324a8":"markdown","02d0b598":"markdown","fbd736f0":"markdown","5b74f5b7":"markdown","25eede17":"markdown","beb9e5cf":"markdown","2b1dfabb":"markdown","56b0295c":"markdown","ebc8afda":"markdown","6399ae05":"markdown","104e5cc1":"markdown","5c6eea26":"markdown","c4ed9fd4":"markdown","03d9602d":"markdown","2145fde6":"markdown","6f14aa50":"markdown","65864013":"markdown","f1a5f2f1":"markdown","2e1511ba":"markdown","0c175937":"markdown","3c49c77b":"markdown","233586ec":"markdown","1a17330a":"markdown","4596a2b3":"markdown","67aa7e5d":"markdown"},"source":{"bf4c9c5e":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfrom math import ceil, sqrt as root\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nimport seaborn as sns\nfrom sklearn.feature_selection import mutual_info_regression, SelectFromModel\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\n\nwarnings.filterwarnings('ignore')","df5f49a1":"train_set = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain_set.head()","552cbe5e":"test_set = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest_set.head()","3102fd8f":"set(train_set.columns) - set(test_set.columns)","38f10b4a":"sample = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")","7be7c660":"train_set[\"SalePrice\"].describe()","69835a92":"# Let's take a look at the distribution of the SalePrice \nsns.distplot(train_set['SalePrice'] , fit=norm);\n(mu, sigma) = norm.fit(train_set['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')","27dfa618":"price = np.log1p(train_set[\"SalePrice\"])\n \nsns.distplot(price , fit=norm);\n(mu, sigma) = norm.fit(price)\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')","4e7b1963":"plt.figure(figsize=(18,10))\nplots = train_set[\"YrSold\"].value_counts().plot(kind=\"bar\")\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.0f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 8),\n                   textcoords='offset points')\nplt.title(\"Houses Sold over the Years\")\nplt.ylabel(\"Number\")\nplt.show()","894c1427":"plt.figure(figsize=(18,10))\nplots = train_set[\"SaleType\"].value_counts().plot(kind=\"bar\")\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.0f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 8),\n                   textcoords='offset points')\nplt.title(\"Most purchsed Sale Type\")\nplt.ylabel(\"Frequency\")\nplt.xlabel(\"Sale Type\")\nplt.show()","6e88bc94":"plt.figure(figsize=(18,10))\nplots = train_set.loc[train_set[\"YrSold\"] == 2009][\"SaleType\"].value_counts().plot(kind=\"bar\")\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.0f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 8),\n                   textcoords='offset points')\nplt.title(\"Most Frequent Sale Type in 2009\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Sale Type\")\nplt.show()","8430b17e":"train_set.groupby([\"YrSold\", \"MoSold\"]).count()","e098906d":"train_set.isnull().sum()[train_set.isnull().sum() > 0]","e8872780":"def clean_data(dataframe: pd.DataFrame) -> pd.DataFrame:\n    df = dataframe.copy()\n    # Replace columns where nan means they don't have these features with \"None\".\n    unavailable = [\"Alley\", \"PoolQC\", \"Fence\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"FireplaceQu\",\n                    \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"MasVnrType\"]\n\n    for col in unavailable:\n        df[col].fillna('None',inplace=True)\n    for column in df.columns:\n        if df[column].dtype == 'object':\n            df[column] = df[column].fillna(\"None\")\n        if df[column].dtype == 'int' or df[column].dtype == 'float':\n            df[column] = df[column].fillna(df[column].mean())\n    return df\n        ","14c4c11a":"df = clean_data(train_set)\ndf.isnull().sum()[df.isnull().sum() > 0] #check if it still contains null values","25d3ad19":"# Number of each type of columns\ntrain_set.dtypes.value_counts()","5a62ce42":"#correlation matrix\ncorr = train_set.corr()\nf, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(corr)","1e838737":"def encode_similar_columns(dataframe: pd.DataFrame) -> pd.DataFrame: \n    df = dataframe.copy()\n    condition_encoder = LabelEncoder()\n    df[\"Condition1\"] = condition_encoder.fit_transform(df[\"Condition1\"])\n    df[\"Condition2\"] = condition_encoder.transform(df[\"Condition2\"])\n    df[\"Condition\"] = df[\"Condition1\"] * df[\"Condition2\"] * df[\"Condition1\"] * df[\"Condition2\"]\n    exterior_encoder = LabelEncoder()\n    exterior_encoder.fit(list(set.union(set(df[\"Exterior1st\"]), set(df[\"Exterior2nd\"]))))\n    df[\"Exterior1st\"] = exterior_encoder.transform(df[\"Exterior1st\"])\n    df[\"Exterior2nd\"] = exterior_encoder.transform(df[\"Exterior2nd\"])\n    df[\"Exterior\"] = df[\"Exterior1st\"] * df[\"Exterior2nd\"] * df[\"Exterior1st\"] * df[\"Exterior2nd\"]\n    bsmt_encoder = LabelEncoder()\n    bsmt_encoder.fit(list(set.union(set(df[\"BsmtFinType1\"]), set(df[\"BsmtFinType2\"]))))\n    df[\"BsmtFinType1\"] = bsmt_encoder.transform(df[\"BsmtFinType1\"])\n    df[\"BsmtFinType2\"] = bsmt_encoder.transform(df[\"BsmtFinType2\"])\n    df[\"BsmtFinType\"] = df[\"BsmtFinType1\"] * df[\"BsmtFinType2\"] * df[\"BsmtFinType1\"] * df[\"BsmtFinType2\"]\n    return df","6116ce71":"def encode_all_columns(df: pd.DataFrame) -> pd.DataFrame: \n    dataframe = df.copy()\n    dataframe.drop([\"Id\"], axis=1, inplace=True)\n    dataframe = dataframe.apply(LabelEncoder().fit_transform)\n    return dataframe","8bf07dcf":"def simplify_features(df):\n    df[\"SimplOverallQual\"] = df.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                           4 : 2, 5 : 2, 6 : 2, # average\n                                                           7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                          })\n    df[\"SimplOverallCond\"] = df.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                           4 : 2, 5 : 2, 6 : 2, # average\n                                                           7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                          })\n    df[\"SimplGarageCond\"] = df.GarageCond.replace({1 : 1, # bad\n                                                         2 : 1, 3 : 1, # average\n                                                         4 : 2, 5 : 2 # good\n                                                        })\n    df[\"SimplGarageQual\"] = df.GarageQual.replace({1 : 1, # bad\n                                                         2 : 1, 3 : 1, # average\n                                                         4 : 2, 5 : 2 # good\n                                                        })\n    df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace({1 : 1, # bad\n                                                           2 : 1, 3 : 1, # average\n                                                           4 : 2, 5 : 2 # good\n                                                          })\n    df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace({1 : 1, # bad\n                                                           2 : 1, 3 : 1, # average\n                                                           4 : 2, 5 : 2 # good\n                                                          })\n    df[\"SimplFunctional\"] = df.Functional.replace({1 : 1, 2 : 1, # bad\n                                                         3 : 2, 4 : 2, # major\n                                                         5 : 3, 6 : 3, 7 : 3, # minor\n                                                         8 : 4 # typical\n                                                        })\n    df[\"SimplKitchenQual\"] = df.KitchenQual.replace({1 : 1, # bad\n                                                           2 : 1, 3 : 1, # average\n                                                           4 : 2, 5 : 2 # good\n                                                          })\n    df[\"SimplHeatingQC\"] = df.HeatingQC.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\n    df[\"SimplBsmtFinType1\"] = df.BsmtFinType1.replace({1 : 1, # unfinished\n                                                             2 : 1, 3 : 1, # rec room\n                                                             4 : 2, 5 : 2, 6 : 2 # living quarters\n                                                            })\n    df[\"SimplBsmtFinType2\"] = df.BsmtFinType2.replace({1 : 1, # unfinished\n                                                             2 : 1, 3 : 1, # rec room\n                                                             4 : 2, 5 : 2, 6 : 2 # living quarters\n                                                            })\n    df[\"SimplBsmtCond\"] = df.BsmtCond.replace({1 : 1, # bad\n                                                     2 : 1, 3 : 1, # average\n                                                     4 : 2, 5 : 2 # good\n                                                    })\n    df[\"SimplBsmtQual\"] = df.BsmtQual.replace({1 : 1, # bad\n                                                     2 : 1, 3 : 1, # average\n                                                     4 : 2, 5 : 2 # good\n                                                    })\n    df[\"SimplExterCond\"] = df.ExterCond.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\n    df[\"SimplExterQual\"] = df.ExterQual.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\n    return df","8bdcaaf1":"def cross_features(datfr: pd.DataFrame) -> pd.DataFrame:\n    df = simplify_features(datfr.copy())\n    df[\"OverallGrade\"] = df[\"OverallQual\"] * df[\"OverallCond\"]\n    df[\"GarageGrade\"] = df[\"GarageQual\"]* df[\"GarageCond\"]\n    df[\"ExterGrade\"] = df[\"ExterQual\"] * df[\"ExterCond\"]\n    df[\"KitchenScore\"] = df[\"KitchenAbvGr\"] * df[\"KitchenQual\"]\n    df[\"FireplaceScore\"] = df[\"Fireplaces\"] * df[\"FireplaceQu\"]\n    df[\"GarageScore\"] = df[\"GarageArea\"] * df[\"GarageQual\"]\n    df[\"SimplOverallGrade\"] = df[\"SimplOverallQual\"] * df[\"SimplOverallCond\"]\n    df[\"SimplExterGrade\"] = df[\"SimplExterQual\"] * df[\"SimplExterCond\"]\n    df[\"SimplGarageScore\"] = df[\"GarageArea\"] * df[\"SimplGarageQual\"]\n    df[\"SimplFireplaceScore\"] = df[\"Fireplaces\"] * df[\"SimplFireplaceQu\"]\n    df[\"SimplKitchenScore\"] = df[\"KitchenAbvGr\"] * df[\"SimplKitchenQual\"]\n    df[\"TotalBath\"] = df[\"BsmtFullBath\"] + (0.5 * df[\"BsmtHalfBath\"]) + \\\n    df[\"FullBath\"] + (0.5 * df[\"HalfBath\"])\n    df[\"AllSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n    df[\"AllFlrsSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n    df[\"AllPorchSF\"] = df[\"OpenPorchSF\"] + df[\"EnclosedPorch\"] + \\\n    df[\"3SsnPorch\"] + df[\"ScreenPorch\"]\n    df[\"HasMasVnr\"] = df.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \n                                                   \"Stone\" : 1, \"None\" : 0})\n    df[\"BoughtOffPlan\"] = df.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n                                                          \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n    \n    df[\"OverallQual-s2\"] = df[\"OverallQual\"] ** 2\n    df[\"OverallQual-s3\"] = df[\"OverallQual\"] ** 3\n    df[\"OverallQual-Sq\"] = np.sqrt(df[\"OverallQual\"])\n    df[\"AllSF-2\"] = df[\"AllSF\"] ** 2\n    df[\"AllSF-3\"] = df[\"AllSF\"] ** 3\n    df[\"AllSF-Sq\"] = np.sqrt(df[\"AllSF\"])\n    df[\"AllFlrsSF-2\"] = df[\"AllFlrsSF\"] ** 2\n    df[\"AllFlrsSF-3\"] = df[\"AllFlrsSF\"] ** 3\n    df[\"AllFlrsSF-Sq\"] = np.sqrt(df[\"AllFlrsSF\"])\n    df[\"GrLivArea-2\"] = df[\"GrLivArea\"] ** 2\n    df[\"GrLivArea-3\"] = df[\"GrLivArea\"] ** 3\n    df[\"GrLivArea-Sq\"] = np.sqrt(df[\"GrLivArea\"])\n    df[\"SimplOverallQual-s2\"] = df[\"SimplOverallQual\"] ** 2\n    df[\"SimplOverallQual-s3\"] = df[\"SimplOverallQual\"] ** 3\n    df[\"SimplOverallQual-Sq\"] = np.sqrt(df[\"SimplOverallQual\"])\n    df[\"ExterQual-2\"] = df[\"ExterQual\"] ** 2\n    df[\"ExterQual-3\"] = df[\"ExterQual\"] ** 3\n    df[\"ExterQual-Sq\"] = np.sqrt(df[\"ExterQual\"])\n    df[\"GarageCars-2\"] = df[\"GarageCars\"] ** 2\n    df[\"GarageCars-3\"] = df[\"GarageCars\"] ** 3\n    df[\"GarageCars-Sq\"] = np.sqrt(df[\"GarageCars\"])\n    df[\"TotalBath-2\"] = df[\"TotalBath\"] ** 2\n    df[\"TotalBath-3\"] = df[\"TotalBath\"] ** 3\n    df[\"TotalBath-Sq\"] = np.sqrt(df[\"TotalBath\"])\n    df[\"KitchenQual-2\"] = df[\"KitchenQual\"] ** 2\n    df[\"KitchenQual-3\"] = df[\"KitchenQual\"] ** 3\n    df[\"KitchenQual-Sq\"] = np.sqrt(df[\"KitchenQual\"])\n    df[\"GarageScore-2\"] = df[\"GarageScore\"] ** 2\n    df[\"GarageScore-3\"] = df[\"GarageScore\"] ** 3\n    df[\"GarageScore-Sq\"] = np.sqrt(df[\"GarageScore\"])\n\n    dataframe = df\n    dataframe[\"basement_condition\"] = (dataframe['BsmtQual'] + dataframe['BsmtCond'] + dataframe['BsmtExposure']\n                                    + dataframe['BsmtFinType1'] + dataframe['BsmtFinSF1'] + dataframe['BsmtFinType2']\n                                    + dataframe['BsmtFinSF2'] + dataframe['BsmtUnfSF'] + dataframe['TotalBsmtSF']\n                                    + dataframe['BsmtFullBath'] + dataframe['BsmtHalfBath'])\n    dataframe[\"garage_condition\"] = (dataframe['GarageType'] + dataframe['GarageYrBlt'] + dataframe['GarageFinish']\n                                    + dataframe['GarageCars'] + dataframe['GarageArea'] + dataframe['GarageQual'] + dataframe['GarageCond'])\n    dataframe[\"kitchen_condition\"] = dataframe['KitchenAbvGr'] + dataframe['KitchenQual']\n    dataframe[\"Mas\"] = dataframe['MasVnrType'] + dataframe['MasVnrArea']\n    return dataframe","3bd1799d":"def scale_features(dataframe: pd.DataFrame) -> pd.DataFrame:\n    scaler = MinMaxScaler()\n    dataset = scaler.fit_transform(dataframe)\n    return pd.DataFrame(dataset, columns=dataframe.columns)","6875e33b":"def handle_skew(d_frame):\n    df = d_frame.copy()\n    numerical = [col for col in df.columns if df[col].dtype != \"object\"]\n    df_num = df[numerical]\n    skewness = df_num.apply(lambda x: skew(x))\n    skewness = skewness[abs(skewness) > 0.5]\n    skewed_features = skewness.index\n    for feature in skewed_features:\n        df[feature] = np.log1p(df[feature])\n    return df","da4888b8":"def process_data(df: pd.DataFrame) -> pd.DataFrame:\n    dataframe = df.copy()\n    cleaned_data = handle_skew(clean_data(dataframe))  \n    first_encoding = encode_similar_columns(cleaned_data)\n    encoded_data = encode_all_columns(first_encoding)\n    processed_dataframe = cross_features(encoded_data)\n    return scale_features(processed_dataframe)","d5377ce8":"def make_mi_scores(X, y):\n    discrete_features = X.dtypes == int\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","704a34d1":"data = process_data(train_set)\nmi_scores = make_mi_scores(data, data.pop(\"SalePrice\"))\nmi_scores","ebaa1cc5":"# Split data into train and validation sets.\ndataset = process_data(train_set).drop(\"SalePrice\", axis=1)\ntrain_X, validate_X, train_y, validate_y = train_test_split(dataset, price, test_size=0.25)","6eae3dcf":"test_data = process_data(test_set)","5f461416":"## making predictions using Linear Regression \n\nlinear_model = LinearRegression()\nlinear_model.fit(train_X, train_y)\npredicted_linear = linear_model.predict(validate_X)\nprint(\"Mean squared Error using LinearRegression:\", root(mean_squared_error(validate_y, predicted_linear)))\n","f108c8bb":"predicted_linear = linear_model.predict(test_data)\npd.DataFrame({'id': test_set['Id'], 'SalePrice': np.expm1(predicted_linear)}).head(10)","16348c87":"## making predictions using the Random Forest algorithm \n\nforest_model = RandomForestRegressor(n_jobs=-1, random_state=0)\nforest_model.fit(train_X, train_y)\npredicted_random_forest = forest_model.predict(validate_X)\n# print(\"Mean squared Error using Random Forest:\", root(mean_squared_error(validate_y, predicted_random_forest)))\nprint(\"Mean squared Log Error using Random Forest:\", root(mean_squared_log_error(validate_y, predicted_random_forest)))","8b4821b2":"predicted_test = forest_model.predict(test_data)\nprint(\"Mean squared Log Error using Random Forest on Test Set:\", root(mean_squared_log_error(np.log1p(sample[\"SalePrice\"]+1), predicted_test)))","bb8862d3":"pd.DataFrame({'id': test_set['Id'], 'SalePrice': np.expm1(predicted_test)}).head(10)","32051b82":"sample.head(10)","ad9a8e7c":"perm = PermutationImportance(forest_model, random_state=1).fit(validate_X, validate_y)\neli5.show_weights(perm, feature_names=list(dataset.columns))","2d4441e9":"submission = pd.DataFrame({'id': test_set['Id'], 'SalePrice': np.expm1(predicted_test)})\nsubmission.to_csv(\"submission.csv\",index = False)\nprint(\"predictions successfully submitted\")","a73dc6d4":"#### Well, a closer look at the charts and data just shows that nothing spectacular happened in 2009. The number of purchases increase by the year and it is safe to say that the data available to us at the moment does not have complete records for the whole year 2010, only records up to the month of July in 2010 are available.","f66d2016":"### Random Forest Result","2ac06ca7":"#### Apparently, the `SalePrice` for the test_set is what we are to predict.","215a4fb0":"#### Obviously, the random forest model gives a more reasonable result than the linear regression model.","2c4bfaad":"#### Of the now 81 columns, 43 are non numerical data. This simply means that we have to do alot of encoding on our current data.","20bd205b":"# Modelling","98917054":"#### We still have many categorical features so we use LabelEncoder for the rest of the categorical columns.","e39b71cd":"#### The train set consists of 1460 rows and 81 features while the test set consists of 1459 rows and 80 features. What feature is missing in the test set?","d088c67c":"#### From the above matrix, we can see that `OverallQual` has the highest positive correlation with `SalesPrice` followed closely by `GrLivarea` while `OverallCond`, `KitchenAbvGr`, `EnclosedPorch` have the lowest correlations with `SalesPrice`. This simply means that the features with high correlation can be very useful in predicting prices aand we should pay close attention to them.","166324a8":"#### Looks like the price is left skewed so we work with the log of the prices.","02d0b598":"# Submission","fbd736f0":"#### Some columns represent the same set of categories if the apartment has multiple types. We'll train one of the columns to label encoder and then use the same label encoder to fit to the other one.","5b74f5b7":"#### Let's look into the data to see the features that have empty values","25eede17":"#### How about another lookat the data","beb9e5cf":"## Random Forest","2b1dfabb":"#### Ok, so now we can make predictions for the test set using the previous steps. First, I'll put the processes into sort of a pipeline.","56b0295c":"# Exploratory Data Analysis","ebc8afda":"#### Now that looks more like it...","6399ae05":"#### What year did we have the most sales?","104e5cc1":"# Feature Engineering","5c6eea26":"#### Looks like we had more house sales in 2009 and the least sales in 2010.\n#### What type of sale was the most purchased?","c4ed9fd4":"### Linear Regression Result","03d9602d":"## Data Cleaning","2145fde6":"#### Hmm, Warranty deeds sold out the most but what happened in 2009 that didn't happen in 2010?","6f14aa50":"#### Some feature are related to one another so I'll add all related features together to provide a new feature that shows the overall condition for that particular utility.","65864013":"# Feature Selection from Mutual Information","f1a5f2f1":"`Alley`, `PoolQC`, `Fence`, `MiscFeature` have the highest number of NaN values, we can fill this for EDA as nan means that feature is unavailable for the apartment. Other columns can be filled with their means if numerical and modes if categorical. However, I'll drop `MiscFeature`.","2e1511ba":"### We start by loading and viewing the data available to us.","0c175937":"#### Next is to scale the features ","3c49c77b":"# Permutation Importance on selected features","233586ec":"#### In order to determine the features that play important roles in the determination of the sales price, we can start by checking the features that have strong positive or negative correlations with the sales price. ","1a17330a":"#### How about we take a closer look into the type of prices available in the dataset?","4596a2b3":"## Linear Regression","67aa7e5d":"#### Created a function that replaces nan values in each categorical column as the mode of the values in that column and replace nan values in numerical values with the means of the columns."}}