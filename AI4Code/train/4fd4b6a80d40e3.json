{"cell_type":{"33403f8b":"code","71b94793":"code","4305870f":"code","94a39361":"code","75fb9ca7":"code","ac43b0f3":"code","a1f90d20":"code","0dfcf365":"code","eb77fc87":"code","561a9537":"code","1573388f":"code","185854be":"code","da1922f3":"code","daadbf2e":"code","2616a5b2":"code","74744d17":"code","d0148b6c":"code","6d802ddf":"code","60b00f14":"code","8b442bca":"code","4365e32c":"code","8b6aed78":"code","74c97a4a":"markdown","40d70cb8":"markdown","52ad21da":"markdown","7392ef32":"markdown","290e282e":"markdown","37232ac8":"markdown","a02d09a1":"markdown","96018f34":"markdown","6a886941":"markdown","e6c566f0":"markdown","482a50c5":"markdown","141ee116":"markdown","8d7cf4d3":"markdown","c6470527":"markdown","ef0789a5":"markdown","c1b20bce":"markdown","ead3d5fa":"markdown","a8a07f30":"markdown","7ed20ef5":"markdown","52a599be":"markdown","0d009f34":"markdown","eede14fc":"markdown","90909df3":"markdown"},"source":{"33403f8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","71b94793":"# Numpy array cannot be added as an argument.\ndef step_function(x):\n    if x > 0:\n        return 1\n    else:\n        return 0","4305870f":"# Numpy array can be added as an argument.\ndef step_function(x):\n    y = x > 0 \n    return y.astype(np.int)","94a39361":"# Specifically\nimport numpy as np\nx = np.array([-2.0, 1.0, 2.0])\nprint(x)\n\ny = x > 0\nprint(y) # bool array\n\ny = y.astype(np.int) # bool to int\nprint(y)","75fb9ca7":"# Step Function graph\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef step_function(x):\n    return np.array(x > 0, dtype=np.int)\n\nx = np.arange(-6.0, 6.0, 0.1)\ny = step_function(x)\nplt.plot(x, y)\nplt.ylim(-0.1, 1.1)\nplt.show()","ac43b0f3":"def sigmoid(x):\n    return 1 \/ (1 + np.exp(-x))\n\n# Handle numpy array properly \nx = np.array([-2.0, 1.0, 3.0])\nprint(sigmoid(x))","a1f90d20":"# Sigmoid function graph\nx = np.arange(-6.0, 6.0, 0.1)\ny = sigmoid(x)\nplt.plot(x, y)\nplt.ylim(-0.1, 1.1)\nplt.show()","0dfcf365":"def relu(x):\n    return np.maximum(0, x)","eb77fc87":"# Relu function graph\nx = np.arange(-6.0, 6.0, 0.5)\ny = relu(x)\nplt.plot(x, y)\nplt.ylim(-1, 6)\nplt.show()","561a9537":"A = np.array([[1,2], [3,4]])\nprint(A.shape)\n\nB = np.array([[5,6], [7,8]])\nprint(B.shape)\n\nprint(np.dot(A, B))","1573388f":"A = np.array([[2,3], [3,4], [5,6]])\nprint(A.shape)\n\nB = np.array([8,9])\nprint(B.shape)\n\nprint(np.dot(A, B))","185854be":"X = np.array([2,3])\nprint(X.shape)\n\nW = np.array([[1,3,5], [2,4,6]])\nprint(W)\nprint(W.shape)\n\nY = np.dot(X, W)\nprint(Y)","da1922f3":"X = np.array([2.0, 2.5])\nW1 = np.array([[0.2, 0.4, 0.6], [0.3, 0.6, 0.8]])\nB1 = np.array([-.2, 0.3, 0.4])\n\nprint(W1.shape)\nprint(X.shape)\nprint(B1.shape)\n\nA1 = np.dot(X, W1) + B1\nprint(A1)","daadbf2e":"Z1 = sigmoid(A1)\n\nprint(A1)\nprint(Z1)","2616a5b2":"W2 = np.array([[0.2, 0.4], [0.3, 0.5], [0.4, 0.7]])\nB2 = np.array([0.2, 0.3])\n\nprint(Z1.shape)\nprint(W2.shape)\nprint(B2.shape)\n\nA2 = np.dot(Z1, W2) + B2\nZ2 = sigmoid(A2)","74744d17":"def identity_function(x):\n    return x\n\nW3 = np.array([[0.2, 0.4], [0.3, 0.6]])\nB3 = np.array([0.3,0.6])\n\nA3 = np.dot(Z2, W3) + B3\nY = identity_function(A3) # Y = A3","d0148b6c":"# Organization\ndef init_network():\n    network = {}\n    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n    network['b1'] = np.array([0.1, 0.2, 0.3])\n    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n    network['b2'] = np.array([0.1, 0.2])\n    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n    network['b3'] = np.array([0.1, 0.2])\n    \n    return network\n\ndef forward(network, x):\n    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n    \n    a1 = np.dot(x, W1) + b1\n    z1 = sigmoid(a1)\n    a2 = np.dot(z1, W2) + b2\n    z2 = sigmoid(a2)\n    a3 = np.dot(z2, W3) + b3\n    y = identity_function(a3)\n    \n    return y\n\nnetwork = init_network()\nx = np.array([1.0, 0.5])\ny = forward(network, x)\nprint(y)\n    ","6d802ddf":"a = np.array([0.4, 3.0, 4.5])\nexp_a = np.exp(a)\nprint(exp_a)\n\nsum_exp_a = np.sum(exp_a)\nprint(sum_exp_a)\n\ny = exp_a \/ sum_exp_a\nprint(y)","60b00f14":"def softmax(a):\n    exp_a = np.exp(a)\n    sum_exp_a = np.sum(exp_a)\n    y = exp_a \/ sum_exp_a\n\n    return y","8b442bca":"a = np.array([2000, 1900, 800])\nprint(np.exp(a) \/ np.sum(np.exp(a)))\n\nc = np.max(a) # Maximum value of input signal\nprint(a - c)\n\nprint(np.exp(a - c) \/ np.sum(np.exp(a - c)))","4365e32c":"def softmax(a):\n    c = np.max(a)\n    exp_a = np.exp(a - c) # Overflow Countermeasures\n    sum_exp_a = np.sum(exp_a)\n    y = exp_a \/ sum_exp_a\n\n    return y","8b6aed78":"# You can interpret the output of a Softmax function as a probability\na = np.array([0.5, 3.0, 4.5])\ny = softmax(a)\nprint(y)\nprint(np.sum(y))","74c97a4a":"### Signal Transmission from Input Layer to One Layer\n\n![image.png](attachment:image.png)","40d70cb8":"## Softmax Function Overflow Solution\n\n![image.png](attachment:image.png)","52ad21da":"![image.png](attachment:image.png)","7392ef32":"## Signal Transfer from the 2 Layer to the Output Layer\n\n![image.png](attachment:image.png)","290e282e":"$a_{1}^{1} = w_{11}^{1}x_{1} + w_{12}^{1}x_{2} + b_{1}^{1}$\n\n$\\mathbf{A}^{(1)} = \\mathbf{X}\\mathbf{W}^{(1)} + \\mathbf{B}^{(1)}$\n\n$\\mathbf{A}^{(1)} = (a_{1}^{(1)}, a_{2}^{(1)}, a_{3}^{(1)})$\n\n$\\mathbf{X} = (x_{1}, x_{2})$\n\n$\\mathbf{B}^{(1)} = (b_{1}^{1}, b_{2}^{1}, b_{3}^{1})$\n\n$\\mathbf{W}^{(1)} = \\begin{pmatrix}\nw_{11}^{(1)} & w_{21}^{(1)} & w_{31}^{(1)}\\\\ \nw_{12}^{(1)} & w_{22}^{(1)} & w_{32}^{(1)}\n\\end{pmatrix}$","37232ac8":"## Softmax Function\n\n![image.png](attachment:image.png)","a02d09a1":"## Expression 2\n\n![image.png](attachment:image.png)","96018f34":"## 3-Layer Neural Network\n\n![image.png](attachment:image.png)","6a886941":"## Identity Function\n\n![image.png](attachment:image.png)","e6c566f0":"## Sigmoid Function\n\n![image.png](attachment:image.png)","482a50c5":"## Step Function","141ee116":"![image.png](attachment:image.png)","8d7cf4d3":"## Signaling from the 1 Layer to the 2 Layer\n\n![image.png](attachment:image.png)","c6470527":"![image.png](attachment:image.png)","ef0789a5":"## Activation Function\n\na = b + $w_{1}x_{1}$ + $w_{2}x_{2}$\n\ny = h(a)\n\n![image.png](attachment:image.png)","c1b20bce":"## ReLu Function\n\n![image.png](attachment:image.png)","ead3d5fa":"## Neural Network Example\n\n![image.png](attachment:image.png)","a8a07f30":"## Perform Neural Network Calculation with Product of Matrices\n\n![image.png](attachment:image.png)","7ed20ef5":"## A Perceptron Specifying Bias\n\n![image.png](attachment:image.png)","52a599be":"## Dot Product of A Matrix\n\n![image.png](attachment:image.png)","0d009f34":"### Expression 1\n\n![image.png](attachment:image.png)","eede14fc":"## Perceptron Review\n\n![image.png](attachment:image.png)","90909df3":"![image.png](attachment:image.png)"}}