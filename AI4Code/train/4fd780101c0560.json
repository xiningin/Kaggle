{"cell_type":{"d14d30d8":"code","addaa9ad":"code","591f71f4":"code","2a41e430":"code","4337a187":"code","0bad2878":"code","9bb8c0f8":"code","290447b9":"code","68d5df31":"code","505a51d4":"code","330d38a0":"code","479be924":"code","aac20c43":"code","f6836edd":"code","c009e80b":"code","b6c28bc5":"code","13eb9ee6":"code","bd823fa3":"code","60ddf37d":"code","ce84b2ef":"code","58df0e62":"code","276782cc":"code","d319e8ed":"markdown","059771e6":"markdown","5d9cd4da":"markdown","4c9f7f75":"markdown","31c3bf37":"markdown","1345255b":"markdown","ba0abc77":"markdown","779057c2":"markdown","90b4aa19":"markdown","f1651aeb":"markdown","4eceb9bd":"markdown","e8ba641e":"markdown","77806c9e":"markdown","36cdb2c0":"markdown","ebf9e403":"markdown","c7cfd293":"markdown","05bd7063":"markdown","4640145e":"markdown","d93a37ce":"markdown","984881e0":"markdown","b541d43e":"markdown","78765e88":"markdown","38892499":"markdown","6a4b4214":"markdown","6317a2b9":"markdown","46e29859":"markdown"},"source":{"d14d30d8":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport pylab as plt\nfrom tqdm import tqdm_notebook\nnp.random.seed(5)\n\nplt.rc('figure', figsize=(10, 5))\nfizsize_with_subplots = (10, 10)\nbin_size = 10\n\n# df_train \u00e9 o nosso dataframe com os dados de treinamento para constru\u00e7\u00e3o de nosso modelo.\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_train.head(3)\n","addaa9ad":"df_train.describe()","591f71f4":"df_train.dtypes","2a41e430":"df_train.SibSp.unique()","4337a187":"y = df_train.Survived\ndf_train.drop('Survived', axis=1, inplace=True) #removemos a coluna com a resposta que foi armazenada em y","0bad2878":"n_train = df_train.PassengerId.count()\nn_test = df_test.PassengerId.count()\n\ndf_todos = pd.concat([df_train, df_test]) # concatena os dataframes\nn_todos = df_todos.PassengerId.count()\n\nprint(n_train, n_test, n_train+n_test, n_todos)","9bb8c0f8":"## Tornando os nulos em Embarked igual \u00e0 moda (valor mais comum)\ndf_todos.loc[df_todos['Embarked'].isnull(), 'Embarked'] = 'S'","290447b9":"### Aqui fazemos pela m\u00e9dia a substitui\u00e7\u00e3o dos nulos\ndf_todos.loc[df_todos['Age'].isnull(), 'Age'] = int(df_todos.Age.mean())\ndf_todos.loc[df_todos['Fare'].isnull(), 'Fare'] = int(df_todos.Fare.mean())","68d5df31":"### C\u00f3digo para gerar features polinomiais\nfrom sklearn.preprocessing import PolynomialFeatures\n\n#gera as features polinomiais com os atributos na lista (alterar se quiser)\npoly = PolynomialFeatures(2, interaction_only=True)\nnovas_colunas = poly.fit_transform(df_todos[['Fare', 'Age']])\nnovas_colunas","505a51d4":"## Adiciona as novas colunas polinomiais no dataframe.\nfor i in range(novas_colunas.shape[1]):\n    df_todos['p' + str(i)] = novas_colunas[:,i]\ndf_todos.head(3)","330d38a0":"novas_colunas_ohe_embarked = pd.get_dummies(df_todos['Embarked']) \ndf_todos = pd.concat([df_todos,novas_colunas_ohe_embarked], axis=1) # axis = 1 concatena colunas. axis = 0 concatena linhas\ndf_todos.head(3)","479be924":"# aqui atribuimos a nova coluna ao dataframe com outro nome.\ndf_todos['Pclass_int'] = df_todos['Pclass'].astype('int16')\ndf_todos['Sex_int'] = pd.factorize(df_todos['Sex'])[0]\ndf_todos.head(3)","aac20c43":"df_todos['Pclass'] = df_todos['Pclass'].astype(np.int16)\ndf_todos.dtypes","f6836edd":"passenger_Id = df_todos['PassengerId'] # precisamos guardar para fazer a submiss\u00e3o para o kaggle\n\ndf_todos_final = df_todos.drop(['PassengerId', 'Pclass', 'Name', 'Ticket', 'Cabin', 'Embarked', 'Sex'], \n                               axis=1, inplace=False)\ndf_todos_final.head(3)","c009e80b":"## checando se estamos com a quantidade certa de linhas. Vai lan\u00e7ar uma exce\u00e7\u00e3o se for diferente\nassert df_todos_final.Age.count()==n_todos","b6c28bc5":"X_train = df_todos_final[:n_train].values\nX_test = df_todos_final[n_train:].values\ny_train = y.values\npassenger_Id_test = passenger_Id[n_train:].values ## s\u00f3 nos interessa os ids dos passageiros do conjunto de teste para submiss\u00e3o\nprint(X_train.shape, y_train.shape, X_test.shape, passenger_Id_test.shape)","13eb9ee6":"## Agora j\u00e1 podemos embaralhar os dados de treino\nfrom sklearn.model_selection import KFold\nnfolds=5\nkf = KFold(n_splits=nfolds, shuffle=True, random_state=5)","bd823fa3":"from sklearn import tree\nfrom sklearn.metrics import accuracy_score ## Essa \u00e9 a m\u00e9trica usada na competi\u00e7\u00e3o do kaggle\n\ny_full_test =[] ##Aqui guardamos as previs\u00f5es de cada modelo (classificador) em todo o dado de teste\ny_full_valid = np.zeros(len(y_train)) ##Aqui fazemos a previs\u00e3o de valia\u00e7\u00e3o out-of-fold\n\nfor train, valid in tqdm_notebook(kf.split(X_train, y_train)):\n    ## Separamos os dados dos folds\n    x_train_fold = X_train[train]\n    y_train_fold = y_train[train]\n    x_valid = X_train[valid]\n    y_valid = y_train[valid]\n    \n    ##Treinamos o classificador, avaliamos nos dados de valida\u00e7\u00e3o e medimos o desempenho\n    clf = tree.DecisionTreeClassifier(random_state=5)\n    clf.fit(x_train_fold, y_train_fold)\n    y_full_valid[valid] = clf.predict(x_valid)\n    \n    \n    ##Aqui realizamos a previs\u00e3o nos dados de teste. Para cada modelo (fold) vamos gerar as previs\u00f5es completas\n    ##nesses dados\n    y_full_test.append(clf.predict(X_test))\n    \nprint('acur\u00e1cia na valida\u00e7\u00e3o', accuracy_score(y_train, y_full_valid))\n","60ddf37d":"## soma as previs\u00f5es de cada classificador (0 ou 1), que no final pode dar at\u00e9 nfold no total \n##em cada passageiro, se todos votarem 1\ntotal = np.sum(y_full_test, axis=0)\n## Agora dividimos pelo numero de folds e arredondamos.\npreds_test = np.round(np.divide(total,nfolds))","ce84b2ef":"df_result = pd.DataFrame(passenger_Id_test, columns=['PassengerId'])\ndf_result['Survived'] = (preds_test.astype('int'))\ndf_result.head(3)","58df0e62":"df_result.to_csv('submittion.csv', index=False) #Index=false remove uma coluna in\u00fatil numerada de 0 a n","276782cc":"df_result.head()","d319e8ed":"## Parte 1 - Importando os dados e gerando features","059771e6":"Se ao contr\u00e1rio de querer usar OHE em uma coluna voc\u00ea quiser usar o dado categ\u00f3rico, para algum modelo baseado em \u00e1rvore de decis\u00e3o (DecisionTreeClassifier, RandomForest, etc.), voc\u00ea pode usar o c\u00f3digo abaixo, pois mesmo sendo categ\u00f3rico, o dado tem de ser num\u00e9rico e n\u00e3o string.","5d9cd4da":"# Estudo de caso - Competi\u00e7\u00e3o Kaggle - Sobreviventes do Titanic","4c9f7f75":"#### Importanto bibliotecas e carregando os dados","31c3bf37":"## Gerando nossos dados de treino, valida\u00e7\u00e3o e teste","1345255b":"### Tratando os nulos das colunas Embarked e Age","ba0abc77":"Aqui criamos o dataframe que usaremos para salvar um csv","779057c2":"O c\u00f3digo abaixo cria OHE para uma determinada coluna e a anexa ao dataframe. Cabe a voc\u00ea remover a coluna original depois","90b4aa19":"No caso da idade, a distribui\u00e7\u00e3o de valores \u00e9 muito grande e arbitrar um valor vai distorcer muito os dados. Nesse caso, usaremos o valor m\u00e9dio da idade.","f1651aeb":"Nesse laborat\u00f3rio vamos utilizar nossos conhecimentos em modelos de classifica\u00e7\u00e3o, ensemble e an\u00e1lise de dados para elaborar um bom modelo que preveja a sobreviv\u00eancia ou n\u00e3o de um passageiro do Titanic. \n\nPara quem n\u00e3o se lembra, o Titanic afundou em sua viagem inaugural em 1912, ap\u00f3s colidir com um iceberg. O acidente matou 1502 dos 2224 passsageiros. Os dados s\u00e3o divididos entre treino (`train.csv`) e teste (`test.csv`), mas n\u00e3o temos os dados dos 2224 passageiros e sim de 1309 no total.\n\nAo final vamos submeter nossas previs\u00f5es para a competi\u00e7\u00e3o de treinamento do Kaggle: https:\/\/www.kaggle.com\/c\/titanic\n\n**N\u00e3o desperdi\u00e7e envios. Voc\u00ea tem apenas 10 envios de respostas por dia.**\n","4eceb9bd":"<pre>\nsurvival        Sobreviveu ao acidente?\n                (0 = N\u00e3o; 1 = Sim)\npclass          Classe do passageiro\n                (1 = primeira classe; 2 = segunda classe; 3 = terceira classe)\nname            Nome\nsex             G\u00eanero\nage             Idade\nsibsp           Soma do n\u00famero irm\u00e3os + cunhados + c\u00f4njuge\nparch           Soma do n\u00famero pais + filhos\nticket          N\u00famero da passagem\nfare            Valor da passagem\ncabin           N\u00famero da cabine\nembarked        Porto de embarque\n                (C = Cherbourg; Q = Queenstown; S = Southampton)\n<\/pre>","e8ba641e":"Os arquivos possuem as seguintes informa\u00e7\u00f5es de cada passageiro:","77806c9e":"*Notar que esse \u00e9 o dado original do Kaggle, sem a inser\u00e7\u00e3o de outliers que fizemos como exerc\u00edcio no come\u00e7o do curso.*","36cdb2c0":"### One Hot Encoding","ebf9e403":"Aqui est\u00e3o os c\u00f3digos que trabalhamos anteriormente para remover os nulos dos dados. \n\nAlterar e executar se quiser. Lembrar que os nossos resultados ser\u00e3o influenciados pelos tratamentos das *features*","c7cfd293":"### Usando algoritmo de \u00e1rvore de decis\u00e3o simples","05bd7063":"Primeiro passo vamos escolher as colunas que vamos remover (n\u00e3o usaremos). Basta alterar a lista. `df_todos.columns` lista as colunas caso precise.","4640145e":"Com a fun\u00e7\u00e3o abaixo vamos mescar as previs\u00f5es nos dados de teste dos modelos de cada um dos folds","d93a37ce":"Aqui vamos guardar quantos s\u00e3o os dados de treino e teste e juntar os *dataframes*, para que possamos dar tratamento uniformizado \u00e0s *features*. Depois dividimos novamente os conjuntos usando os \u00edndices.","984881e0":"## Os dados","b541d43e":"### Convertendo categorias em n\u00fameros","78765e88":"Agora vamos usar uma \u00e1rvore de decis\u00e3o simples para gerar um modelo e na sequ\u00eancia gerar o arquivo que vai ser submetido.","38892499":"Aqui voc\u00ea define a sua estrat\u00e9gia de valida\u00e7\u00e3o (K-fold cross validation \u00e9 prefer\u00edvel e o exemplo est\u00e1 abaixo)","6a4b4214":"#### Dividimos novamente os dados de traino e teste. Veja que em momento algum embaralhamos os dados. Isso \u00e9 essencial para poder dividir novamente.","6317a2b9":"### Gerando features polinomiais","46e29859":"Agora salvamos o arquivo. Ap\u00f3s executar a c\u00e9lula abaixo, veja no sistema de arquivos que foi gerado e submeta-o ao kaggle quando achar conveniente."}}