{"cell_type":{"2abe681c":"code","a92ca379":"code","f0e5a07d":"code","dbef85e7":"code","3126603e":"code","1e2bca70":"code","c2b38268":"code","4f6a72ff":"code","30dd44b9":"code","71ef1421":"code","440a9b79":"code","744d266e":"code","ab0e67d1":"code","ff963fc1":"code","0f4fda41":"code","83e64dfc":"code","fedae4a9":"code","6897b056":"code","7fcdfa51":"code","1da744a2":"code","ae71d24e":"code","cbe588da":"code","5f5d4ce0":"code","8c1c6e3f":"code","4b15722b":"code","e377d93f":"markdown","77a41024":"markdown","80876896":"markdown","d4975a7f":"markdown","9229c505":"markdown","484f13ea":"markdown","0ad5e811":"markdown","ddceedc4":"markdown","32498885":"markdown","85895134":"markdown","246573e6":"markdown","a4d1ba94":"markdown","bf5787c2":"markdown","8cf98aed":"markdown","54def3e9":"markdown","2c5fb2e2":"markdown","a8097e01":"markdown","f3b428c2":"markdown","81912396":"markdown","cad14937":"markdown","63772852":"markdown","36c87e59":"markdown","ae5b7298":"markdown","5c5ac3d7":"markdown","528dfa30":"markdown","1a376955":"markdown","deeec7ae":"markdown","143b33eb":"markdown","006e2180":"markdown","2dce98ca":"markdown","e84297c9":"markdown","d466c830":"markdown"},"source":{"2abe681c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a92ca379":"SEED = 15\ntrain = pd.read_csv('..\/input\/airline-passenger-satisfaction\/train.csv')\ntest = pd.read_csv('..\/input\/airline-passenger-satisfaction\/test.csv')","f0e5a07d":"train.head()","dbef85e7":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import tree","3126603e":"#clears the dataset of undefined values\ndef clean_dataset(data):\n    assert isinstance(data, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    data.dropna(inplace=True)\n    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(1)","1e2bca70":"def find_cat(data, max_count_unique=5):\n    for name in data.columns:\n        s = ''\n        s += name\n        if type(data[name][0]) == str:\n            s += ' is string, '\n        if data[name].nunique() <= max_count_unique:\n            s += ' few unique'\n        if s != name:\n            print(s, data[name].unique())\n\n#replacing categorical variables\ndef encoding_cat(data, max_count_unique=5, msg=True):\n    for name in data.columns:\n        if type(data[name][0]) == str and data[name].nunique() <= max_count_unique:\n            le = LabelEncoder()\n            le.fit(data[name])\n            data[name] = le.transform(data[name])\n    if msg:\n        print('Encoding done!')\n            ","c2b38268":"clean_dataset(train)\nfind_cat(train)\nencoding_cat(train)","4f6a72ff":"train.info()","30dd44b9":"train.Class = train.Class.replace({0: 3}) \n#Correcting Class variable in accordance with the meaning Eco -> Eco Plus -> Business\ntrain['Arrival Delay in Minutes'].astype('int')\ny = train.satisfaction\nX = train.drop(['Unnamed: 0', 'id', 'satisfaction'], axis=1)\nX.head()","71ef1421":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","440a9b79":"decision_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 10, random_state=SEED)\ndecision_tree.fit(X_train, y_train)","744d266e":"from IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw\nimport graphviz  \nfrom sklearn.tree import export_graphviz\n\n# Export our trained model as a .dot file\nwith open(\"tree1.dot\", 'w') as f:\n     f = export_graphviz(decision_tree, out_file=f, max_depth = 4,\n                         impurity = True, feature_names = X_train.columns,\n                         rounded = True, filled= True )\n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree.png'])\n# Annotating chart with PIL\nimg = Image.open(\"tree.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","ab0e67d1":"decision_tree.score(X_val, y_val)","ff963fc1":"def search_param(model, param, X_train, y_train, X_val, y_val, area=range(1, 11), msg=True, plot=True, seed=None):\n    import matplotlib.pyplot as plt\n    import time\n    score_list = []\n    if msg:\n        print('#     accuracy  time')\n    for i in area:\n        start = time.time()\n        rfc = eval(model + '(' + param + '=' + str(i) + ', random_state=' + str(seed) + ')')\n        rfc.fit(X_train, y_train)\n        s = rfc.score(X_val, y_val)\n        end = time.time()\n        score_list.append(s)\n        if msg:\n            print(\"%-3d %10f  %7f\" % (i, s, end - start))\n    if plot:\n        plt.plot(list(area), score_list)\n    return list(area)[score_list.index(max(score_list))]","0f4fda41":"search_param('RandomForestClassifier', 'n_estimators', X_train, y_train, X_val, y_val, area=range(1, 51), seed=SEED)","83e64dfc":"search_param('RandomForestClassifier', 'max_depth', X_train, y_train, X_val, y_val, range(1, 25), seed=SEED)","fedae4a9":"search_param('RandomForestClassifier', 'min_samples_split', X_train, y_train, X_val, y_val, range(2, 10), seed=SEED)","6897b056":"search_param('RandomForestClassifier', 'min_samples_leaf', X_train, y_train, X_val, y_val, range(1, 10), seed=SEED)","7fcdfa51":"rfc = RandomForestClassifier(random_state=SEED)\nparam = {'n_estimators': [i for i in range(38, 51)], 'max_depth': [i for i in range(20, 25)]}\ngscv =  GridSearchCV(rfc, param, cv=3, n_jobs=-1, verbose=1)\ngscv.fit(X_train, y_train)","1da744a2":"gscv.best_params_","ae71d24e":"best_c = gscv.best_estimator_\nimp = pd.DataFrame(best_c.feature_importances_, index=X_train.columns, columns=['importance'])\nimp.sort_values('importance').plot(kind='barh', figsize=(12, 8))","cbe588da":"best_c.score(X_val, y_val)","5f5d4ce0":"clean_dataset(test)\nfind_cat(test)\nencoding_cat(test)\ntest.Class = test.Class.replace({0: 3})\ntest['Arrival Delay in Minutes'].astype('int')\ny_test = test['satisfaction']\nX_test = test.drop(['Unnamed: 0', 'id', 'satisfaction'], axis=1)\nbest_c.score(X_test, y_test)","8c1c6e3f":"from sklearn.metrics import roc_auc_score , roc_curve\nimport matplotlib.pyplot as plt\ndtc_proba=best_c.predict_proba(X_test)\ndtc_proba=dtc_proba[:,1]\nauc=roc_auc_score(y_test, dtc_proba)\nprint('Random Forest Classifier: ROC AUC=%.3f' % (auc))\nlr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_proba)\nplt.plot(lr_fpr, lr_tpr, marker='.', label='Random Forest Classifier')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","4b15722b":"!rm -rf .\/sample-out.png .\/tree1.dot .\/tree.png","e377d93f":"\u041f\u0440\u0438 \u043e\u0442\u0431\u043e\u0440\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0435\u0442\u0441\u044f \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f. \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u0438\u043b\u0438 \u0441\u043a\u043e\u043b\u044c\u0437\u044f\u0449\u0438\u0439 \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044c \u2014 \u043f\u0440\u043e\u0446\u0435\u0434\u0443\u0440\u0430 \u044d\u043c\u043f\u0438\u0440\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u043d\u0438\u044f \u043e\u0431\u043e\u0431\u0449\u0430\u044e\u0449\u0435\u0439 \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432. \u0421 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u044d\u043c\u0443\u043b\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043d\u0435 \u0443\u0447\u0430\u0441\u0442\u0432\u0443\u0435\u0442 \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438, \u043d\u043e \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0435 \u043e\u0442\u0432\u0435\u0442\u044b.\n\nCross-validation is used for selection. Cross-validation or sliding control is a procedure for empirically evaluating the generalizing ability of algorithms. Cross-validation emulates the presence of a test sample that does not participate in training, but for which the correct answers are known.","77a41024":"![](https:\/\/cf2.ppt-online.org\/files2\/slide\/v\/VXgjNpHShCby6zFJdWZeUocmsLTvaltkQERxfOuqP7\/slide-12.jpg)","80876896":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 (Data loading)","d4975a7f":"# Decision Tree and Random Forest (RU, EN)\n\n\u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0435 \u044f \u0440\u0430\u0437\u0431\u0438\u0440\u0430\u044e, \u043a\u0430\u043a \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 DecisionTree \u0438 RandomForestClassifier \u0438\u0437 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 sklearn \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0430 \u0432 \u0437\u0430\u0434\u0430\u0447\u0435 [Airline Passenger Satisfaction](https:\/\/www.kaggle.com\/teejmahal20\/airline-passenger-satisfaction) \u0438 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e \u0441\u043f\u043e\u0441\u043e\u0431 \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0432\u0430\u0436\u043d\u044b\u0445 \u0444\u0438\u0447\u0435\u0439 \u0432 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0438 \u0443\u0434\u043e\u0432\u043b\u0435\u0442\u0432\u043e\u0440\u0451\u043d\u043d\u043e\u0441\u0442\u0438 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440\u0430 \u0430\u0432\u0438\u0430\u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438\u0438.\n\nIn this notebook, I'm looking at how DecisionTree and RandomForestClassifier from the sklearn library work to train the classifier in the [Airline Passenger Satisfaction](https:\/\/www.kaggle.com\/teejmahal20\/airline-passenger-satisfaction) problem and show a way to determine the most important features in determining passenger satisfaction with the airline.\n\n**\u0418\u0422\u041e\u0413\u041e\u0412\u042b\u0419 \u0420\u0415\u0417\u0423\u041b\u042c\u0422\u0410\u0422 (FINAL RESULT): accuracy=0.96, ROC AUC=0.99**","9229c505":"\u041f\u043e\u0434\u0440\u043e\u0431\u043d\u0435\u0435 \u043e \u0440\u0430\u0431\u043e\u0442\u0435 \u044d\u0442\u0438\u0445 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u043c\u043e\u0437\u043d\u043e \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u0442\u044c, \u043f\u0435\u0440\u0435\u0439\u0434\u044f \u043f\u043e \u044d\u0442\u0438\u043c \u0441\u0441\u044b\u043b\u043a\u0430\u043c.\n\nYou can read more about how these tools work by clicking on these links.\n\n* [DecisionTreeClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier)\n* [train_test_split](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split)\n* [RandomForestClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier)\n* [GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV)\n* [LabelEncoder](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html?highlight=labelencoder#sklearn.preprocessing.LabelEncoder)\n* [tree](https:\/\/scikit-learn.org\/stable\/modules\/classes.html?highlight=tree#module-sklearn.tree)","484f13ea":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0440\u0435\u0448\u0430\u044e\u0449\u0435\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u0430 (Training DecisionTree)","0ad5e811":"\u041f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c \u043f\u043e\u0438\u0441\u043a \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 (search optimal parameters of a RandomForest)","ddceedc4":"\u0420\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u043c \u043e\u0431\u0443\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 (Splitting the training selection)\n\n![](https:\/\/lh6.googleusercontent.com\/uuKkYCYun1Ky6C7_GwEtv0gNdaoHyx0WTXiM8jvGOQqGx75gIRVhx1to7OapyGDbOsmKyAl9Eyi5RC-atbk6AXukkA7UBXA-NutKcAdHaTGDsWSzNGyBaCBMvVu1HLuU1Wm6TxWb)","32498885":"**min_samples_split**\n\n\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u044b\u0431\u043e\u0440\u043e\u043a, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445 \u0434\u043b\u044f \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0433\u043e \u0443\u0437\u043b\u0430:\n* \u0415\u0441\u043b\u0438 int, \u0442\u043e \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c min_samples_split \u043a\u0430\u043a \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e.\n* \u0415\u0441\u043b\u0438 float, \u0442\u043e min_samples_split-\u044d\u0442\u043e \u0434\u0440\u043e\u0431\u044c, \u0430 ceil(min_samples_split * n_samples) - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u044b\u0431\u043e\u0440\u043e\u043a \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f.\n\nThe minimum number of samples required to split an internal node:\n* If int, then consider min_samples_split as the minimum number.\n* If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.","85895134":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u0444\u0438\u0447\u0435\u0439 \u0432 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0438 \u0443\u0434\u043e\u0432\u043b\u0435\u0442\u0432\u043e\u0440\u0451\u043d\u043d\u043e\u0441\u0442\u0438 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440\u043e\u0432\n\nVisualization of the importance of features in determining passenger satisfaction","246573e6":"\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043e\u0447\u0438\u0441\u0442\u043a\u0438 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u043e\u0442 \u043d\u0435\u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0451\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u043d\u0438\u0439 ","a4d1ba94":"![](https:\/\/img2.goodfon.ru\/original\/1999x1333\/8\/4c\/park-les-derevya-priroda.jpg)","bf5787c2":"\u0414\u0435\u043b\u0430\u0435\u043c \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0435 \u0448\u0442\u0440\u0438\u0445\u0438 \u0432 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0435 \u0434\u0430\u043d\u043d\u044b\u0445.\n\u041f\u043e\u0434\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u0443\u044e \u0447\u0438\u0441\u043b\u043e\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e \u043a\u043b\u0430\u0441\u0441\u0430 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440\u0430 \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0438 \u0441\u043e \u0441\u043c\u044b\u0441\u043b\u043e\u043c. \n\u0423\u0434\u0430\u043b\u044f\u0435\u043c \u043d\u0435\u043d\u0443\u0436\u043d\u044b\u0435 \u0441\u0442\u0440\u043e\u043a\u0438.","8cf98aed":"# \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f","54def3e9":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f (Preparing data for training)","2c5fb2e2":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0447\u0438\u0441\u043b\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432. \u041a\u0430\u0436\u0434\u043e\u0435 \u0434\u0435\u0440\u0435\u0432\u043e \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u043c\u043e \u0434\u0440\u0443\u0433 \u043e\u0442 \u0434\u0440\u0443\u0433\u0430 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e. \u0410 \u043f\u043e\u0441\u043b\u0435 \u044d\u0442\u043e\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u044f (\u043b\u0435\u0441) \u043f\u0440\u0438\u043c\u0443\u0442 \u043e\u0431\u0449\u0435\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u0432 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0435 \u0433\u043e\u043b\u043e\u0441\u043e\u0432\u0430\u043d\u0438\u044f, \u0442\u0435\u043c \u0441\u0430\u043c\u044b\u043c, \u043f\u043e\u0434\u0441\u0442\u0440\u0430\u0445\u043e\u0432\u044b\u0432\u0430\u044f \u0434\u0440\u0443\u0433 \u0434\u0440\u0443\u0433\u0430 \u043e\u0442 \u043e\u0448\u0438\u0431\u043e\u043a.\n\nLet's try to improve the classification and increase the number of trees. Each tree will classify independently of each other. And after that, the trees (forest) will make a common decision as a result of voting, thereby protecting each other from mistakes","a8097e01":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044bx \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a (Importing the necessary libraries)","f3b428c2":"\u0424\u043e\u0440\u043c\u0443\u043b\u0430 \u043f\u043e\u0434\u0441\u0447\u0451\u0442\u0430 \u044d\u043d\u0442\u0440\u043e\u043f\u0438\u0438 (formula for calculating entropy criterion)\n\n![](https:\/\/i.stack.imgur.com\/r5exj.jpg)","81912396":"**min_samples_leaf**\n\n\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432, \u0442\u0440\u0435\u0431\u0443\u0435\u043c\u043e\u0435 \u0434\u043b\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0432 \u043b\u0438\u0441\u0442\u043e\u0432\u043e\u043c \u0443\u0437\u043b\u0435. \u0422\u043e\u0447\u043a\u0430 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u043b\u044e\u0431\u043e\u0439 \u0433\u043b\u0443\u0431\u0438\u043d\u0435 \u0431\u0443\u0434\u0435\u0442 \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0442\u044c\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0442\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, \u0435\u0441\u043b\u0438 \u043e\u043d\u0430 \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u043f\u043e \u043a\u0440\u0430\u0439\u043d\u0435\u0439 \u043c\u0435\u0440\u0435 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 min_samples_leaf \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0437 \u043b\u0435\u0432\u044b\u0445 \u0438 \u043f\u0440\u0430\u0432\u044b\u0445 \u0432\u0435\u0442\u0432\u0435\u0439.\n* \u0415\u0441\u043b\u0438 int, \u0442\u043e \u0441\u0447\u0438\u0442\u0430\u0439\u0442\u0435 min_samples_leaf \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u0447\u0438\u0441\u043b\u043e\u043c.\n* \u0415\u0441\u043b\u0438 float, \u0442\u043e min_samples_leaf-\u044d\u0442\u043e \u0434\u0440\u043e\u0431\u044c, \u0430 ceil(min_samples_leaf * n_samples) - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u044b\u0431\u043e\u0440\u043e\u043a \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0443\u0437\u043b\u0430.\n\nThe minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches.\n* If int, then consider min_samples_leaf as the minimum number.\n* If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.","cad14937":"**\u0424\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0431\u043e\u0440 \u043b\u0443\u0447\u0448\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432 (final selection of the best algorithms)**","63772852":"\u0412\u044b\u0432\u043e\u0434 \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0430 (output of the best classifier parameters)","36c87e59":"**n_estimators** \n\n\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u0432 \u043b\u0435\u0441\u0443.\n\nThe number of trees in the forest.","ae5b7298":"\u0418\u0442\u043e\u0433\u043e\u0432\u0430\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 (final verification of the algorithm)","5c5ac3d7":"\u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043d\u0430\u0445\u043e\u0434\u0435\u043d\u0438\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0438 \u0438\u0445 \u0437\u0430\u043c\u0435\u043d\u044b","528dfa30":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0434\u0435\u0440\u0435\u0432\u0430 \u0440\u0435\u0448\u0435\u043d\u0438\u0439 (DecisionTree Visualisation)","1a376955":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430","deeec7ae":"\u0421\u043e\u0437\u0434\u0430\u0451\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u0435\u0433\u043e (Creating a classifier and training it)","143b33eb":"**\u0418\u0422\u041e\u0413\u041e\u0412\u042b\u0419 \u0420\u0415\u0417\u0423\u041b\u042c\u0422\u0410\u0422(FINAL RESULT): accuracy=0.96, ROC AUC=0.99**","006e2180":"**max_depth**\n\n\u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430. \u0415\u0441\u043b\u0438 \u043d\u0435\u0442, \u0442\u043e \u0443\u0437\u043b\u044b \u0440\u0430\u0441\u0448\u0438\u0440\u044f\u044e\u0442\u0441\u044f \u0434\u043e \u0442\u0435\u0445 \u043f\u043e\u0440, \u043f\u043e\u043a\u0430 \u0432\u0441\u0435 \u043b\u0438\u0441\u0442\u044c\u044f \u043d\u0435 \u0441\u0442\u0430\u043d\u0443\u0442 \u0447\u0438\u0441\u0442\u044b\u043c\u0438 \u0438\u043b\u0438 \u043f\u043e\u043a\u0430 \u0432\u0441\u0435 \u043b\u0438\u0441\u0442\u044c\u044f \u043d\u0435 \u0431\u0443\u0434\u0443\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u043c\u0435\u043d\u044c\u0448\u0435 \u043e\u0431\u0440\u0430\u0437\u0446\u043e\u0432 min_samples_split.\n\nThe maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.","2dce98ca":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0443 ROC AUC (Visualize the ROC AUC metric)","e84297c9":"**\u0418\u0442\u043e\u0433\u043e\u0432\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0430 (final accuracy of the classifier):**","d466c830":"![](https:\/\/i.ytimg.com\/vi\/goPiwckWE9M\/maxresdefault.jpg)"}}