{"cell_type":{"42d8fff8":"code","4461265a":"code","66baa38c":"code","c9341866":"code","dbc2be8a":"code","1e12efca":"code","346ae873":"code","9d07b996":"code","f0a8c1d3":"code","13cb7bc1":"code","d8a3f0ad":"code","dde8d8d6":"code","678ab865":"code","97aae020":"code","125243d0":"markdown","90cea364":"markdown","76d037e1":"markdown","dc46782e":"markdown","2b537d7b":"markdown","bcc67fa4":"markdown","db5b2693":"markdown","0698706e":"markdown","f4289edf":"markdown","f19ec9f1":"markdown","c2560119":"markdown","1d8eb2db":"markdown","0ba74c04":"markdown","829a20cf":"markdown"},"source":{"42d8fff8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\n\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.patches as patches\n","4461265a":"# Suppress warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom IPython.display import HTML","66baa38c":"import os\nprint(os.listdir(\"..\/input\/cusersmarildownloadsdeathscsv\/\"))","c9341866":"%%time\ndf = pd.read_csv('..\/input\/cusersmarildownloadsdeathscsv\/deaths.csv', delimiter=';', encoding = \"ISO-8859-1\")\ndf.dataframeName = 'deaths.csv'","dbc2be8a":"print('Size of df data', df.shape)","1e12efca":"df.head()","346ae873":"total = df.isnull().sum().sort_values(ascending = False)\npercent = (df.isnull().sum()\/df.isnull().count()*100).sort_values(ascending = False)\nmissing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(8)","9d07b996":"# Number of each type of column\ndf.dtypes.value_counts()","f0a8c1d3":"# Number of unique classes in each object column\ndf.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","13cb7bc1":"corrs = df.corr()\ncorrs","d8a3f0ad":"plt.figure(figsize = (20, 8))\n\n# Heatmap of correlations\nsns.heatmap(corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap');","dde8d8d6":"HTML('<iframe width=\"980\" height=\"520\" src=\"https:\/\/www.youtube.com\/embed\/PL2cXmFL-OM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","678ab865":"HTML('<iframe width=\"980\" height=\"520\" src=\"https:\/\/www.youtube.com\/embed\/onFx-7b2M3I\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","97aae020":"HTML('<iframe width=\"980\" height=\"520\" src=\"https:\/\/www.youtube.com\/embed\/VSyj_OC4QO4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","125243d0":"### Correlations\n\nNow that we have dealt with the categorical variables and the outliers, let's continue with the EDA. One way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the `.corr` dataframe method.\n\nThe correlation coefficient is not the greatest method to represent \"relevance\" of a feature, but it does give us an idea of possible relationships within the data. Some [general interpretations of the absolute value of the correlation coefficent](http:\/\/www.statstutor.ac.uk\/resources\/uploaded\/pearsons.pdf) are:\n\n\n* .00-.19 \u201cvery weak\u201d\n*  .20-.39 \u201cweak\u201d\n*  .40-.59 \u201cmoderate\u201d\n*  .60-.79 \u201cstrong\u201d\n* .80-1.0 \u201cvery strong\u201d\n","90cea364":"## Categorical Feature Encoding Challenge WITH PYTHON\n[Crisl\u00e2nio Mac\u00eado](https:\/\/medium.com\/sapere-aude-tech) -  January, 04th, 2020\n\n [ \ud83d\udc69\ud83d\udc68 Mortality Among Children  ](https:\/\/www.kaggle.com\/caesarlupum\/mortality-among-children)\n\n----------\n----------","76d037e1":"## Infant mortality rate under 5 years for (1000) West Africa","dc46782e":"## Read in Data \n\nFirst, we can list all the available data files. There are a total of 6 files: 1 main file for training (with target) 1 main file for testing (without the target), 1 example submission file, and 4 other files containing additional information about energy types based on historic usage rates and observed weather. . ","2b537d7b":"# Context\nGlobal and regional probability of dying among children aged 5-14 (10q5) and number of deaths by UNICEF Regions\nEstimates generated by the UN Inter-agency Group for Child Mortality Estimation (UN IGME) in 2019\ndownloaded from http:\/\/www.childmortality.org\nNotes:\n10q5 is the probability of dying between age 5 and 14 expressed per 1 000 children aged 5\nLower and Upper refer to the lower bound and upper bound of 90% uncertainty intervals.\nRegional classifications refer to the UNICEF's regional classification.\n\n\n![](https:\/\/imgk.timesnownews.com\/story\/1537239356-About-802000-infant-deaths-reported-in-India-in-2017-UN.jpg?tr=w-600,h-450)\n\n### Content\nChild Mortality Estimates. Last update: 19 September 2019. Contact: childmortality@unicef.org\n\nFor further details please refer to http:\/\/data.unicef.org\/regionalclassifications\/\n\n#### Acknowledgements\nhttp:\/\/www.childmortality.org\n\nPhoto by Heather Mount on Unsplash\n\n#### Inspiration\n> Abhijit Banerjee, Esther Duflo and Michael Kremer were awarded the Nobel Prize in Economics 2019, for their \"experimental approach to alleviating global poverty.\" With their new approach to getting reliable answers on the best ways to combat global poverty, maybe some children's lives could be saved.","bcc67fa4":"# Glimpse of Data","db5b2693":"# Final","0698706e":"# Examine Missing Values\n\nNext we can look at the number and percentage of missing values in each column. \n","f4289edf":"### Child Mortality Rate in India","f19ec9f1":"### checking missing data for df","c2560119":"## Column Types\n\nLet's look at the number of columns of each data type. `int64` and `float64` are numeric variables ([which can be either discrete or continuous](https:\/\/stats.stackexchange.com\/questions\/206\/what-is-the-difference-between-discrete-data-and-continuous-data)). `object` columns contain strings and are  [categorical features.](http:\/\/support.minitab.com\/en-us\/minitab-express\/1\/help-and-how-to\/modeling-statistics\/regression\/supporting-topics\/basics\/what-are-categorical-discrete-and-continuous-variables\/) . ","1d8eb2db":"## Imports\n\n> We are using a typical data science stack: `numpy`, `pandas`, `sklearn`, `matplotlib`. ","0ba74c04":"> Data head","829a20cf":"### Top 15 Country population Ranking (1900-2019) "}}