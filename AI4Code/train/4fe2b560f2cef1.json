{"cell_type":{"0db9bae0":"code","bb681d85":"code","27016b3f":"code","23828abe":"code","c2140a0c":"code","0d073530":"code","ffd8fb99":"code","11d47b77":"code","1d6ff336":"code","7a82f281":"code","1ecf2091":"code","45bbddfd":"code","cda63f51":"code","992295ce":"code","1ff6e9e9":"code","295638a1":"code","0b0e1527":"code","8cd1a4cc":"code","52f6f181":"code","24a8416a":"code","9d251606":"code","cad5709a":"code","78b5052b":"code","b73c4a09":"code","f6d4cbdf":"markdown","d429a095":"markdown","45764181":"markdown","28e5b915":"markdown","d0d6f5dc":"markdown"},"source":{"0db9bae0":"DEBUG = 0","bb681d85":"!pip install lycon","27016b3f":"import sys\npackage_path = '..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nfrom tqdm import tqdm\nimport cv2\nimport lycon\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport torch\nfrom torch import nn, optim\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom scipy.ndimage.interpolation import zoom\nimport albumentations as A\nfrom torch.nn import functional as F\nfrom albumentations.pytorch import ToTensorV2\nfrom efficientnet_pytorch import model as enet\nimport torch.cuda.amp as amp","23828abe":"class CFG:\n    model_name = \"dog120_v3_9\"\n    backbone = 'efficientnet-b4'\n    Progress_Bar = False\n    init_lr = 1e-3\n    weight_decay = 1e-4\n    image_size = 384\n    batch_size = 16\n    freeze_epochs = 0\n    n_epochs = 5 if DEBUG else 40\n    no_aug_epochs = 3\n    n_fold = 5\n    train_fold = 1\n    n_seed = 1\n    seed = 42\n    num_workers = 4\n    model_save_path = False\n    APEX = False","c2140a0c":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ndef seed_everything(seed=CFG.seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything()","0d073530":"# data\u8aad\u307f\u8fbc\u307f\ndf_train = pd.read_csv(\"\/kaggle\/input\/comp-dog\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/comp-dog\/submission.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/comp-dog\/submission.csv\")\ndf_train.head()","ffd8fb99":"#label encoding\nle = preprocessing.LabelEncoder()\ndf_train[\"label\"] = le.fit_transform(df_train[\"class\"])\ndf_test[\"label\"] = -1\nprint(\"training_class : \", len(le.classes_))","11d47b77":"skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\ndf_train[\"fold\"] = -1\nfor fold,(train_index, test_index) in enumerate(skf.split(df_train[\"img_name\"],df_train[\"label\"])):\n    df_train[\"fold\"][test_index] = fold\n    ","1d6ff336":"df_train","7a82f281":"def ResizeMix(s,sl,t,tl,label_oh,a=0.1,b=0.8): #s:source image, t:target image, a,b:min-max resize scale\n    #s,t:channel last\n    H,W = t.shape[0],t.shape[1]\n    \n    R = random.uniform(a,b)\n    h,w = int(H*R),int(W*R)\n    \n    #4\u9685\u306bsource image\u3092\u56fa\u5b9a\u3059\u308b\u5834\u5408\u306f\u3053\u3063\u3061\n    choice = [(0,0),(0,H-h),(W-w,0),(W-w,H-h)]\n    x,y = choice[random.randint(0,3)]\n    \n    #\u5b8c\u5168\u30e9\u30f3\u30c0\u30e0\u306a\u5834\u5408\u306f\u3053\u3063\u3061\n    #x,y = random.randrange(0,H-h),random.randrange(0,W-w) #source image\u306e\u5de6\u4e0a\u306e\u5ea7\u6a19\u3092\u6c7a\u5b9a\n    \n    #\u753b\u50cf\u306e\u8cbc\u308a\u4ed8\u3051\n    t[y:y+h,x:x+w,:] = cv2.resize(s,(h,w))\n    \n    label_oh[sl] += R\n    label_oh[tl] -= R\n    \n    return t,label_oh #image,label(array)","1ecf2091":"def img2tensor(img,dtype:np.dtype=np.float32):\n    if img.ndim==2 : img = np.expand_dims(img,2)\n    img = np.transpose(img,(2,0,1))\n    return torch.from_numpy(img.astype(dtype, copy=False))\n\nclass DogDataset(Dataset):\n    def __init__(self, fold, train=True, tfms=None):\n        if train:\n            #self.fnames = df_train[df_train[\"fold\"] != fold][\"img_name\"].tolist()\n            #self.labels = df_train[df_train[\"fold\"] != fold][\"label\"].tolist()\n            #whole train\n            self.fnames = df_train[\"img_name\"].tolist()\n            self.labels = df_train[\"label\"].tolist()\n        else:\n            self.fnames = df_train[df_train[\"fold\"] == fold][\"img_name\"].tolist()\n            self.labels = df_train[df_train[\"fold\"] == fold][\"label\"].tolist()\n        if DEBUG:\n            self.fnames = self.fnames[:100]\n        self.train = train\n        self.tfms = tfms\n        self.resize = A.Compose([A.Resize(CFG.image_size,CFG.image_size)],p=1)\n        self.RM = 0 if train else 0 #ResizeMix \n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        fname,label = self.fnames[idx],self.labels[idx]\n        label_oh = np.zeros((len(le.classes_),))\n        label_oh[label] = 1\n        img = lycon.load(os.path.join(\"..\/input\/comp-dog\/train\/train\",fname+\".jpg\"))\n        if self.tfms is not None:\n            #ResizeMix\n            if self.RM and random.random() <= 0.5:\n                idx2 = random.randint(0,len(self)-1)\n                fname2,label2 = self.fnames[idx2],self.labels[idx2]\n                img2 = lycon.load(os.path.join(\"..\/input\/comp-dog\/train\/train\",fname2+\".jpg\"))\n                \n                img = self.resize(image=img)[\"image\"]\n                img2 = self.resize(image=img2)[\"image\"]\n                \n                img,label_oh = ResizeMix(img2,label2,img,label,label_oh,a=0.1,b=0.8)\n            \n            #Albumentations Augmentation\n            augmented = self.tfms(image=img)\n            img = augmented['image']\n            \n        else:\n            img = self.resize(image=img)[\"image\"]\n        \n        return img2tensor(img\/255.0),label_oh","45bbddfd":"def get_aug(p=1.0):\n    return A.Compose([\n        A.Resize(CFG.image_size,CFG.image_size),\n        A.HorizontalFlip(p=0.5),\n        #A.VerticalFlip(p=0.5),\n        A.ShiftScaleRotate(scale_limit=0.20, rotate_limit=10, shift_limit=0.1, p=0.5, border_mode=cv2.BORDER_REFLECT),\n        #A.RandomBrightnessContrast(p=0.5),\n        #A.CLAHE(p=0.5),\n        #A.GridDistortion(p=0.5),\n        #A.OpticalDistortion(p=0.5),\n        #A.RandomGamma(p=0.5),\n        #A.GaussNoise(p=0.5),\n        #A.HueSaturationValue(p=0.5),\n        #A.ToGray(p=0.5),\n        #A.Cutout(p=0.5),\n    ], p=p)\n\ndef get_aug_lastnepo(p=1.0):\n    return A.Compose([\n        A.Resize(CFG.image_size,CFG.image_size),\n        A.HorizontalFlip(),\n        #A.VerticalFlip(),\n    ], p=p)","cda63f51":"ds = DogDataset(0,tfms = get_aug())","992295ce":"img,label = ds[2]\nprint(label)\nimg = img.numpy().transpose(1,2,0)\nplt.imshow(img)","1ff6e9e9":"label.sum()","295638a1":"\"\"\"pretrained_model = {\n        'efficientnet-b0': '..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth',\n        'efficientnet-b1': '..\/input\/efficientnet-pytorch\/efficientnet-b1-dbc7070a.pth',\n        'efficientnet-b2': '..\/input\/efficientnet-pytorch\/efficientnet-b2-27687264.pth',\n        'efficientnet-b3': '..\/input\/efficientnet-pytorch\/efficientnet-b3-c8376fa2.pth',\n        'efficientnet-b4': '..\/input\/efficientnet-pytorch\/efficientnet-b4-e116e8b3.pth',\n        'efficientnet-b5': '..\/input\/efficientnet-pytorch\/efficientnet-b5-586e6cc6.pth',\n        \n    }\"\"\"\n\n\nclass enetv2(nn.Module):\n    def __init__(self, backbone, out_dim=len(le.classes_)):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        #self.enet.load_state_dict(torch.load(pretrained_model[backbone])) #pretrain\u306a\u3057\uff01\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.sigmoid = nn.Sigmoid()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        #x = self.sigmoid(x)\n        return x\n    \nclass enetv2_amp(enetv2):\n    def __init__(self,*args):\n        super(enetv2_amp, self).__init__(*args)\n        \n    @torch.cuda.amp.autocast()\n    def forward(self,*args):\n        return super(enetv2_amp, self).forward(*args)","0b0e1527":"def trainfn(model, iterator, optimizer, criterion, device, freeze):\n    \n    epoch_loss = 0\n    model.train()\n    \n    #\u30d7\u30ed\u30b0\u30ec\u30b9\u30d0\u30fc\u3092\u8868\u793a\u3059\u308b\u304b\u5426\u304b\n    bar = tqdm(iterator) if CFG.Progress_Bar else iterator\n    \n    for (x, y) in bar:\n        x = torch.tensor(x, device=device, dtype=torch.float32)\n        y = torch.tensor(y, device=device, dtype=torch.float32)\n        optimizer.zero_grad()\n        if CFG.APEX:\n            with amp.autocast():\n                y_pred = model(x)\n                loss = criterion(y_pred, y)\n            scaler.scale(loss).backward() \n            scaler.unscale_(optimizer)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            loss.backward()\n            optimizer.step()\n        loss_np = loss.detach().cpu().numpy()\n        epoch_loss += loss_np\n        \n        if CFG.Progress_Bar:\n            bar.set_description('Training loss: %.5f' % (loss_np))\n        \n    return epoch_loss\/len(iterator)\n\ndef evaluate(model, iterator, criterion, device):\n    \n    epoch_loss = 0\n    preds = torch.tensor([])\n    targets = torch.tensor([])\n    model.eval()\n    \n    bar = tqdm(iterator) if CFG.Progress_Bar else iterator\n    \n    with torch.no_grad():\n        for (x, y) in bar:\n            x = torch.tensor(x, device=device, dtype=torch.float32)\n            y = torch.tensor(y, device=device, dtype=torch.float32)\n            \n            if CFG.APEX:\n                with amp.autocast():\n                    y_pred = model(x)\n                    loss = criterion(y_pred, y)\n            else:\n                y_pred = model(x)\n                loss = criterion(y_pred, y)\n            loss_np = loss.detach().cpu().numpy()\n            epoch_loss += loss_np\n            y_pred = torch.sigmoid(y_pred)\n            preds = torch.cat([preds,y_pred.detach().cpu()],dim=0)\n            targets = torch.cat([targets,y.detach().cpu()],dim=0)\n            \n            if CFG.Progress_Bar:\n                bar.set_description('Validation loss: %.5f' % (loss_np))\n    \n    try:\n       val_acc = accuracy_score(np.argmax(targets,axis=1),np.argmax(preds,axis=1))\n    except ValueError:\n       val_acc = -1\n    \n    return epoch_loss\/len(iterator), val_acc\n\ndef fit_model(model, name, train_iterator, valid_iterator, optimizer, loss_criterion, device,fold, freeze, epochs):\n    \"\"\" Fits a dataset to model\"\"\"\n    best_valid_score = float('inf')\n    \n    train_losses = []\n    valid_losses = []\n    valid_accs = []\n    \n    for epoch in range(epochs):\n        #\u6700\u5f8c\u306e3\u4e16\u4ee3\u3001augmentation\u306a\u3057\u3067\u5b66\u7fd2\n        if (freeze==False) and (epoch == CFG.n_epochs): #\u6700\u5f8c5\u4e16\u4ee3\u306b\u5bfe\u3057\u3066\u3001Aug\u3092\u9069\u7528\u3057\u306a\u3044\n            print(\"-_-_-_-_-_-_-_-_-\")\n            print(\"No augment mode\")\n            print(\"-_-_-_-_-_-_-_-_-\")\n            train_data = DogDataset(fold, \n                                 tfms=get_aug_lastnepo())\n            train_iterator = DataLoader(train_data,shuffle=True,batch_size=CFG.batch_size,num_workers=CFG.num_workers)\n        \n        if scheduler:\n            scheduler.step(epoch)\n        start_time = time.time()\n    \n        train_loss = trainfn(model,train_iterator,optimizer,loss_criterion,device,freeze)\n        valid_loss, valid_acc = evaluate(model,valid_iterator,loss_criterion,device)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        valid_accs.append(valid_acc)\n\n        \"\"\"if valid_dice < best_valid_score:\n            best_valid_score = valid_dice\n            if CFG.model_save_path:\n                torch.save(model.state_dict(), os.path.join(model_save_path,f'{name}.pt'))\n            else:\n                torch.save(model.state_dict(), f'{name}_best.pt')\"\"\"\n        \n        end_time = time.time()\n\n        epoch_mins, epoch_secs = (end_time-start_time)\/\/60,round((end_time-start_time)%60)\n    \n        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins:.0f}m {epoch_secs}s')\n        print(f'lr:{optimizer.param_groups[0][\"lr\"]:.7f}')\n        print(f'Train Loss: {train_loss:.4f}')\n        print(f'e:{epoch+1:02} | Val. Loss: {valid_loss:.4f} | Val. acc Score: {valid_acc:.3f}')\n        \n    #\u6700\u5f8c\u306eAug\u306e\u52b9\u679c\u3092\u898b\u305f\u3044\u305f\u3081\u3001\u6700\u7d42\u4e16\u4ee3\u306e\u307f\u3092\u51fa\u529b\n    if not freeze:\n        torch.save(model.state_dict(),f'{name}_final.pt')\n        \n    return train_losses, valid_losses, valid_accs","8cd1a4cc":"tr_loss=[]\nval_loss=[]\nval_acc=[]\nmodels = []\n\n\nfor fold in range((1 if DEBUG else CFG.train_fold)):\n    print(f\"Fitting on Fold {fold+1}\")\n    #\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n    train_data = DogDataset(fold,tfms=get_aug())\n    valid_data = DogDataset(fold,train=False,tfms=get_aug_lastnepo())\n    #\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\n    train_iterator = DataLoader(train_data,shuffle=True,batch_size=CFG.batch_size,num_workers=CFG.num_workers)\n    valid_iterator = DataLoader(valid_data,shuffle=False,batch_size=8,num_workers=CFG.num_workers)\n    \n    #\u30e2\u30c7\u30eb\u306e\u547c\u3073\u51fa\u3057(\u8a2d\u8a08\u56f3\u304b\u3089\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3078)\n    if CFG.APEX:\n        model = enetv2_amp(CFG.backbone).cuda()\n        scaler = amp.GradScaler()\n    else:\n        model = enetv2(CFG.backbone).to(device)\n        scaler = None\n    name = CFG.model_name + \"_f\" + str(fold)\n    \n    #\u6700\u521d\u306e3\u4e16\u4ee3\u3092\u51fa\u529b\u5c64\u4ee5\u5916freeze\u3057\u3066\u5b66\u7fd2\n    if CFG.freeze_epochs:\n        print(\"+-+-+-+-+-+-+-+-+\")\n        print(\"pretrain mode\")\n        print(\"+-+-+-+-+-+-+-+-+\")\n        loss_criterion = nn.BCEWithLogitsLoss()\n        opt= AdamW(model.parameters(), lr=1e-3)\n        scheduler=None\n\n        head_name = [\"myfc.weight\",\"myfc.bias\"]\n        for hname,param in model.named_parameters():\n            if hname in head_name:\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n\n        nouse0,nouse1,nouse2 = fit_model(model, name, train_iterator, valid_iterator, opt, loss_criterion, device,fold,freeze=True,epochs=CFG.freeze_epochs)\n    \n    print(\"@*@*@*@*@*@*@*@*@\")\n    print(\"fulltrain mode\")\n    print(\"@*@*@*@*@*@*@*@*@\")\n    #\u640d\u5931\u95a2\u6570\u306e\u5b9a\u7fa9\n    loss_criterion = nn.BCEWithLogitsLoss()\n    \n    opt= AdamW(model.parameters(), lr=CFG.init_lr,weight_decay=CFG.weight_decay)\n    \n    #\u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc\u306e\u5b9a\u7fa9\n    scheduler = CosineAnnealingLR(opt,CFG.n_epochs+CFG.no_aug_epochs,eta_min=1e-6)\n    \n    for hname,param in model.named_parameters():\n        param.requires_grad = True\n    #\u5168\u3066\u306e\u60c5\u5831\u3092fit_model\u306b\u5165\u308c\u3066\u3001\u5b66\u7fd2\u3092\u958b\u59cb\u3057\u307e\u3059\n    temp_tr_loss, temp_val_loss, temp_val_accs = fit_model(model, name, train_iterator, valid_iterator, opt, \n                                                           loss_criterion, device,fold,freeze=False, epochs=CFG.n_epochs+CFG.no_aug_epochs)\n    \n    \n    #loss\u3068\u8a55\u4fa1\u6307\u6a19\u306b\u5bfe\u3059\u308b\u30b9\u30b3\u30a2\u3092\u8a18\u9332\u3057\u307e\u3059\n    tr_loss.append(temp_tr_loss)\n    val_loss.append(temp_val_loss)\n    val_acc.append(temp_val_accs)\n    \n    #fold\u3054\u3068\u306b\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3059\u308b\u70ba\u3001\u5b66\u7fd2\u3057\u7d42\u308f\u3063\u305f\u30e2\u30c7\u30eb\u306f\u30ea\u30b9\u30c8\u306b\u4fdd\u6301\u3057\u3066\u304a\u304d\u307e\u3059\n    models.append(model)","52f6f181":"for i in range(len(tr_loss)):\n    fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n    ax[0].plot(tr_loss[i])\n    ax[0].set_title('Training and Validation Loss')\n    ax[0].plot(val_loss[i])\n    ax[0].set_xlabel('Epoch')\n\n    ax[1].plot(val_acc[i])\n    ax[1].set_title('Val acc Score')\n    ax[1].set_xlabel('Epoch')\n\n\n    ax[0].legend();\n    ax[1].legend();","24a8416a":"class DogTestDataset(Dataset):\n    def __init__(self,tfms=None):\n        self.fnames = df_test[\"img_name\"].tolist()\n        self.tfms = tfms\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        img = lycon.load(os.path.join(\"..\/input\/comp-dog\/test\/test\",fname+\".jpg\"))\n        if self.tfms is not None:\n            augmented = self.tfms(image=img)\n            img = augmented['image']\n        else:\n            img = A.Compose([A.Resize(CFG.image_size,CFG.image_size)],p=1)(image=img)[\"image\"]\n        \n        return img2tensor(img\/255.0)","9d251606":"def get_predictions(model, iterator):\n    model.eval()\n    bar = tqdm(iterator) if CFG.Progress_Bar else iterator\n    \n    with torch.no_grad():\n        res = None\n        for x in bar:\n            x = torch.tensor(x, device=device, dtype=torch.float32)\n            y_pred = model(x)\n            y_pred = torch.sigmoid(y_pred)\n            if res is None:\n                res = y_pred.detach().cpu().numpy()\n            else:\n                res = np.append(res,y_pred.detach().cpu().numpy(),axis=0)\n    return res","cad5709a":"pred = None\nfor fold in range((1 if DEBUG else CFG.train_fold)):\n    ds = DogTestDataset()\n    test_iterator = DataLoader(ds,shuffle=False,batch_size=8,num_workers=CFG.num_workers)\n\n    pred_res = get_predictions(models[fold],test_iterator)\n    \n    if pred is None:\n        pred = pred_res\n    else:\n        pred += pred_res\n\npred \/= CFG.train_fold","78b5052b":"pred = np.argmax(pred,axis=1)\npred = le.inverse_transform(pred)\nsubmission[\"class\"] = pred\nsubmission.to_csv(\"submission.csv\", index=False)","b73c4a09":"submission.head()","f6d4cbdf":"# v3  \n\n- v1 :  \n    pretrain=False  \n    resizemix\u306a\u3057  \n    init_lr1e-3  \n    20epo\n    \u2192\u3044\u3044\u611f\u3058\n- v2 :  \n    init_lr5e-2\n    20epo\n    \u2192acc0.02\u524d\u5f8c\u3067\u505c\u6ede\u3002init_lr\u306f\u3084\u306f\u308a1e-3\u304b\u3089\u3067\u3001epoch\u5897\u3084\u3059\u65b9\u5411\u304c\u826f\u3044\u304b\n- v4 :  \n    init_lr1e-3  \n    40epo  \n- v6 :  \n    img_size=320x320  \n    enetb3  \n- v7 :  \n    v6\u306e\u72b6\u614b\u3067\u3001\n    vflip,randombrightnesscontrast\u3042\u308a  \n- v8 :  \n    v6\u306eAug\u3067\u3001\n    384\u306eb4  \n    batch\u306f16  \n- v9 :  \n    v8\u306e\u72b6\u614b\u3067whole train(5-fold\u56de\u3059\u8a08\u7b97\u8cc7\u6e90\u304c\u306a\u3044)  \n    \u6027\u80fd\u8a55\u4fa1\u306floss\u306e\u4e0b\u304c\u308a\u65b9\u3067\u78ba\u8a8d\u3002  \n    \n    \n","d429a095":"# Augmentation","45764181":"# Extra Augmentation (implementation)","28e5b915":"# import","d0d6f5dc":"# Dataset  "}}