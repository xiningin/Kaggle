{"cell_type":{"325b1dd5":"code","c7848df4":"code","735bde17":"code","a7a64abf":"code","f8bb8b27":"code","ad3ecbd6":"code","9a27d91f":"code","eb8db080":"code","49850a26":"code","1b94cb94":"code","8d054889":"code","32c123c9":"code","0dd8c8ee":"code","aa310d1b":"code","84e4a67d":"code","ae4b4e0e":"code","8f56425c":"code","8e00d29a":"code","149d3c13":"code","6afb7b40":"code","d8079cdd":"code","e4d2fc1b":"markdown","f4a48252":"markdown","e0b980aa":"markdown","413e2cc0":"markdown","8848f2d2":"markdown","9f941711":"markdown","c222e78f":"markdown","131e99d3":"markdown","0ccc6286":"markdown","42ca644b":"markdown","3787804e":"markdown","6832615a":"markdown"},"source":{"325b1dd5":"import os\nimport time\nfrom itertools import product\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt","c7848df4":"### Kaggle or Local-PC ###\nKAGGLE = True       # <==== SET ============\n\nif KAGGLE:\n    DIR = '..\/input\/competitive-data-science-predict-future-sales'\nelse:              # local PC\n    DIR = '.\/competitive-data-science-predict-future-sales\/'","735bde17":"for dirname, _, filenames in os.walk(DIR):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a7a64abf":"sales = pd.read_csv(os.path.join(DIR, \"sales_train.csv\"))\ntest = pd.read_csv(os.path.join(DIR, \"test.csv\"))","f8bb8b27":"sales","ad3ecbd6":"test","9a27d91f":"sales = sales[(sales['item_price'] > 0)\n              & (sales['item_cnt_day'] > 0)].reset_index(drop = True)\nsales","eb8db080":"sales = (sales.groupby(['date_block_num','shop_id','item_id'])\n         .agg({'item_cnt_day':'sum'}).reset_index())\nsales.columns = ['date_block_num','shop_id','item_id','cnt_SIM']\nsales","49850a26":"# Create item_month DataFrame\nitem_month_df = pd.DataFrame(product(sales['item_id'].unique(),\n                                     range(34)))\nitem_month_df.columns = ['item_id', 'date_block_num']\nitem_month_df = item_month_df.sort_values(['item_id', 'date_block_num'])","1b94cb94":"# Add 'cnt_IM'\ngroup = sales.groupby(['date_block_num','item_id']).agg({'cnt_SIM':'sum'}).reset_index()\ngroup.columns = ['date_block_num','item_id','cnt_IM']\nitem_month_df = pd.merge(item_month_df, group,\n                         on = ['item_id','date_block_num'],\n                         how = 'left').fillna(0)\n\n# Add 'cnt_IM_ma'(ma:moving average)\nitem_month_df['cnt_IM_ma'] = (item_month_df.groupby('item_id')['cnt_IM']\n#                                .rolling(3, center=True, min_periods=1)\n                               .rolling(3, min_periods = 1)\n                               .mean()).reset_index()['cnt_IM'].fillna(0)\n\nitem_month_df","8d054889":"from scipy import optimize, stats\n\n# Approximate Formula (Beta distribution based)\ndef formula(x, A, a, b, alpha):\n    # Scale conversion on the horizontal axis\n    if a + 0.2 > b:\n        b = max(0.2, a + 0.2)\n    x = (b - a) \/ 33 * x + a\n    # Beta distribution is defined by range [0, 1]\n    x = np.clip(x, 0.0, 1.0)\n    # Probability density function\n    y = A * stats.beta.pdf(x, alpha, 10 - alpha, loc=0, scale=1)\n    return y\n\n# calculate\ndef culc(x, p):\n    return formula(x, *p)\n    \n# curve_fit and calculate\ndef fit(y):\n    try:\n        peak_x = (np.where(y == y.max())[0] \/ 33)[0]\n        p, _ = optimize.curve_fit(formula, x, y,\n                                  # Initial for the parameters\n                                  p0 = [y.max(), 0.5-peak_x, 1.5-peak_x, 5.],\n                                  # Bounds on parameters\n                                  bounds = ([0.1, -3., 0.2, 2.],\n                                            [100000., 0.5, 3., 8.]),\n                                 )\n    except RuntimeError:    # least-squares minimization fails\n        p = [1., 0, 1, 5.]\n    return p\n\n# predict\ndef pred(y):\n    return culc(34, fit(y))","32c123c9":"# from scipy import optimize\n# from scipy.special import erf\n# from numpy import exp, sqrt, pi\n\n# # probability distribution function\n# def pdf(x):\n#     return 1 \/ sqrt(2 * pi) * exp(-x * x \/ 2.0)\n\n# # cumulative distribution function\n# def cdf(x):\n#     return (1.0 + erf(x \/ sqrt(2.))) \/ 2.\n\n# # Approximate Formula (skew normal distribution based)\n# def formula(x, a, mu, sig, lam):\n#     z = (x - mu) \/ sig\n#     y = a * 2. \/ sig * pdf(z) * cdf(lam * (x - mu))\n#     return y\n\n# # calculate\n# def culc(x, p):\n#     return formula(x, *p)\n    \n# # curve_fit and calculate\n# def fit(y):\n#     try:\n#         p, _ = optimize.curve_fit(formula, x, y,\n#                                   p0 = [100., 25., 5., 0.],\n#                                   method = 'dogbox' #{lm\u2019,trf\u2019,'dogbox\u2019}\n#                                  )\n#     except RuntimeError:    # least-squares minimization fails\n#         p = [1., 16., 5., 0.]\n#     return p\n\n# # predict\n# def pred(y):\n#     return culc(34, fit(y))","0dd8c8ee":"idx = 792        # example item_id\n\nx = np.array(range(34))\ny = item_month_df.loc[item_month_df['item_id']==idx, 'cnt_IM']\ny0 = item_month_df.loc[item_month_df['item_id']==idx, 'cnt_IM_ma']\n\n# Create Approximate Formula and Predict 'date_block_num'=34.\np = fit(y0)\ny_pred = culc(34, p)\n\nprint(f'p[a, mue, sigma, lambda] = {p}')\nprint(f'y_pred = {y_pred}')","aa310d1b":"# plot\nfig = plt.figure(figsize = (8,4))\nax = fig.add_subplot(111)\n\nax.plot(x, y, c = 'k', label = 'cnt_IM')\nax.scatter(x, y, c = 'k')\nax.plot(x, y0, c = 'g', label = 'cnt_IM_ma')\nax.scatter(x, y0, c = 'g')\nax.plot(x, culc(x, p), c = 'r', label = 'curve_fit')\nax.scatter(34, y_pred, c = 'r', label = 'pred month\"34\"')\nplt.title(f'item_id : {idx}')\nplt.legend()","84e4a67d":"ts = time.time()\n\n# Predict number of sales of each item in date_block_num:34.\ny_preds = (item_month_df\n           .groupby(['item_id'])['cnt_IM_ma']\n           .apply(pred))\n\ntime.time() - ts","ae4b4e0e":"# cnt_I_34'(Number of sales of each item in date_block_num:34)\ncnt_df = pd.DataFrame({'item_id':item_month_df['item_id'].unique(),\n                       'cnt_I_34':y_preds}).reset_index(drop = True)\ncnt_df['cnt_I_34'] = np.clip(cnt_df['cnt_I_34'], 0, 400)\ncnt_df","8f56425c":"# Create shop_item DataFrame\nshop_item_df = pd.DataFrame(product(sales['shop_id'].unique(),\n                                    sales['item_id'].unique()))\nshop_item_df.columns = ['shop_id', 'item_id']\nshop_item_df = shop_item_df.sort_values(['shop_id', 'item_id'])","8e00d29a":"# Add 'cnt_SI'(Number of sales of each item for each store)\ngroup = (sales\n         .groupby(['item_id', 'shop_id'])['cnt_SIM']\n         .agg('sum')).reset_index()\ngroup.columns = ['item_id','shop_id','cnt_SI']\nshop_item_df = pd.merge(shop_item_df, group,\n                        on = ['item_id','shop_id'],\n                        how = 'left').fillna(0)\n\n# Add 'cnt_I'(Number of sales of each item)\ngroup = (sales\n         .groupby(['item_id'])['cnt_SIM']\n         .agg('sum')).reset_index()\ngroup.columns = ['item_id','cnt_I']\nshop_item_df = pd.merge(shop_item_df, group,\n                        on = ['item_id'],\n                        how = 'left')\n\n# Add 'cnt_I_34'(Number of sales of each item in date_block_num:34)\nshop_item_df = pd.merge(shop_item_df, cnt_df, on = 'item_id', how = 'left')\n\n# Add 'item_cnt_month'\nshop_item_df['item_cnt_month'] = (shop_item_df['cnt_I_34']\n                                  * shop_item_df['cnt_SI']\n                                  \/ shop_item_df['cnt_I']).clip(0, 20)\n\nshop_item_df","149d3c13":"test = (pd.merge(test, shop_item_df,\n                 on = ['shop_id','item_id'], how = 'left')\n        .fillna(0))\ntest","6afb7b40":"submission = test[['ID','item_cnt_month']]\nsubmission","d8079cdd":"submission.to_csv('submission.csv', index = False)","e4d2fc1b":"## submission","f4a48252":"## Create Approximate Formula and Predict\nCreate an approximate expression based on the formula of **Beta distribution**. And Calculate 'item_cnt_month' for 'date_block_num' = 34","e0b980aa":"### Skew normal distribution based","413e2cc0":"### Distribute to each shop","8848f2d2":"### Aggregate daily data into monthly data ","9f941711":"## Sales history of each item","c222e78f":"## Data Cleaning and Aggregation\n\n### Remove outliers\nWhat's negative for 'item_price' and 'item_cnt_day'?\nIs it a return or is it just incorrect data?","131e99d3":"### Example","0ccc6286":"# Predict by the approximate expression of 'count_item'\nThis kernel shows an example of approximation using `scipy.optimize.curve_fit()`.<BR>\nI've even submitted, but please **note** that this kernel alone isn't enough to solve the \"Predict Future Sales\" competition.\n\nThe sales number history of item is expressed by an **approximate expression**, and the sales number at 'date_block_num'= 34 is estimated. I tried using the **Skew nomal distribution**, but in many cases it failed to generate an approximate expression, so I changed it to the **Beta distribution**.\n![img40.png](attachment:img40.png)![img792.png](attachment:img792.png)![img15238.png](attachment:img15238.png)\n* It may be improved a little by adding seasonal periodicity correction.","42ca644b":"## Load Data","3787804e":"### Beta distribution based","6832615a":"## Predict all items"}}