{"cell_type":{"b4a5aedd":"code","0dea74fc":"code","7e3de846":"code","6c9754be":"code","a219d6bf":"code","27c217ff":"code","bde9aa60":"code","b4fe0bfc":"code","231d18a4":"code","1bb8e633":"code","19933d19":"code","6f9ff641":"code","09081b4a":"code","a54e044e":"code","726893de":"code","5652aac1":"code","05ee472b":"code","a668bd92":"code","2aeac542":"code","d5dc3590":"code","a029ef04":"code","1b3ed650":"code","152a1dfd":"code","f0b0bc54":"code","beb09be0":"markdown","bdb8fe05":"markdown","76f1f1e4":"markdown","a3d9078b":"markdown","4c5d83c1":"markdown","4e3b46ac":"markdown","9518aa1d":"markdown","bd4bcc55":"markdown","2c671774":"markdown","c80fdb35":"markdown","1e4dc4e6":"markdown","71de9f8d":"markdown","a3eee846":"markdown","3178674f":"markdown"},"source":{"b4a5aedd":"import numpy as np \nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt","0dea74fc":"# Set random seed and Use 'cuda' GPU\n\ntorch.manual_seed(0)\n\nif torch.cuda.is_available():\n    device = 'cuda'\n    torch.cuda.manual_seed_all(0)\n    \nelse:\n    device = 'cpu'","7e3de846":"# Get Total Dataset\ndf_train = pd.read_csv('..\/input\/diabetes-health-indicators-dataset\/diabetes_binary_5050split_health_indicators_BRFSS2015.csv')","6c9754be":"df_train.shape","a219d6bf":"df_train.head()","27c217ff":"df_train['Diabetes_binary'].value_counts()","bde9aa60":"df_train.info()","b4fe0bfc":"df_train = df_train.astype(int)","231d18a4":"# Dataset split\nX = df_train.drop('Diabetes_binary', axis=1)\ny = df_train['Diabetes_binary']","1bb8e633":"# Use 10 % of total data as Test set and the rest as (Train + Validation) set \nX_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1)\n\n# Use 20 % of (Train + Validation) set as Validation set\nX_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2)","19933d19":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)","6f9ff641":"X_train = torch.FloatTensor(X_train).to(device)\nX_val = torch.FloatTensor(X_val).to(device)\n\ny_train = torch.LongTensor(y_train.values).to(device)\ny_val = torch.LongTensor(y_val.values).to(device)","09081b4a":"# Hyperparameter\nlearning_rate = 1e-1\nn_epochs = 500\ndrop_prob = 0.3","a54e044e":"X_train.shape","726893de":"# Model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.fc1 = nn.Linear(21, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 256)\n        self.fc4 = nn.Linear(256, 64)\n        self.fc5 = nn.Linear(64, 2)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=drop_prob)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight.data)\n                \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.dropout(out)\n        \n        out = self.fc2(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        \n        out = self.fc3(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        \n        out = self.fc4(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        \n        out = self.fc5(out)\n        return out","5652aac1":"model = Net().to(device)\n\n# Optimizer and Loss function\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\nloss_fn = nn.CrossEntropyLoss()","05ee472b":"train_loss = list()\nval_loss = list()\n\nfor epoch in range(1, n_epochs+1):\n    model.train()\n    H = model(X_train)\n    loss = loss_fn(H, y_train)\n    \n    train_loss.append(loss.item())\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    acc = (torch.argmax(H, dim=1) == y_train).float().mean().item()\n    \n    model.eval()\n    with torch.no_grad():\n        H_val = model(X_val)\n        loss_val = loss_fn(H_val, y_val)\n        acc_val = (torch.argmax(H_val, dim=1) == y_val).float().mean().item()\n        \n        val_loss.append(loss_val.item())\n        \n    if epoch % 50 == 0:\n        print('Epoch {:4d} \/ {}, Cost : {:.4f}, Acc : {:.2f} %, Val Cost : {:.4f}, Val Acc : {:.2f} %'.format(\n            epoch, n_epochs, loss.item(), acc*100, loss_val.item(), acc_val*100))","a668bd92":"plt.figure(figsize=(12, 6))\nplt.plot(train_loss, label='Train')\nplt.plot(val_loss, label='Validation')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","2aeac542":"# Scaling\nscaler = MinMaxScaler()\n\nX_train_val = scaler.fit_transform(X_train_val)\nX_test = scaler.transform(X_test)","d5dc3590":"# To Tensor\nX_train_val = torch.FloatTensor(X_train_val).to(device)\nX_test = torch.FloatTensor(X_test).to(device)\n\ny_train_val = torch.LongTensor(y_train_val.values).to(device)\ny_test = torch.LongTensor(y_test.values).to(device)","a029ef04":"model = Net().to(device)\n\n# Optimizer and Loss function\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n\nloss_fn = nn.CrossEntropyLoss()","1b3ed650":"# Train\nfor epoch in range(1, n_epochs+1):\n    model.train()\n    H = model(X_train)\n    loss = loss_fn(H, y_train)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    acc = (torch.argmax(H, dim=1) == y_train).float().mean().item()\n        \n    if epoch % 50 == 0:\n        print('Epoch {:4d} \/ {}, Cost : {:.4f}, Acc : {:.2f} %'.format(\n            epoch, n_epochs, loss.item(), acc*100))","152a1dfd":"# Predict Test set\nmodel.eval()\nwith torch.no_grad():\n    pred = model(X_test)","f0b0bc54":"test_loss = loss_fn(pred, y_test)\ntest_acc = (torch.argmax(pred, dim=1) == y_test).float().mean().item()\n\nprint('Test Loss : {:.4f}'.format(test_loss))\nprint('Test Accuacy : {:.2f} %'.format(test_acc*100))","beb09be0":"Let's visualize the Train loss and Validadtion loss.","bdb8fe05":"Use the whole train set(Train + Validation above).","76f1f1e4":"# Model","a3d9078b":"Validation loss is lower than Train loss because of 'Dropout' layer.","4c5d83c1":"## Convert into Tensor","4e3b46ac":"### Please **Upvote** if you like my notebook!\n### Thank you!","9518aa1d":"As I can see with ```df_train.head()``` and ```df_train.info()```, it would be better to convert the values into **int**.","bd4bcc55":"## Scaling","2c671774":"# Data Preparation","c80fdb35":"## Dataset Split\n\nTrain set + Validation set + Test set","1e4dc4e6":"# Train\n\nTrain with Validation","71de9f8d":"Let's check Test loss and Test accuracy.","a3eee846":"Let's predict Diabetes using ```'diabetes_binary_5050split_health_indicators_BRFSS2015.csv'``` file.**","3178674f":"# Predict Test set"}}