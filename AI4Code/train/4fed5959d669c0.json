{"cell_type":{"fdd0c622":"code","8b509ff6":"code","367227b7":"code","2a7a9daf":"code","51b683ad":"code","c4bc2339":"code","19b5a0e1":"code","9d21ca3f":"code","ecb2575a":"code","b967bda9":"code","e23ab504":"code","3b823aa1":"code","a523ffe4":"code","aceafc6b":"code","c3ed62ed":"code","fc66befb":"code","6515782b":"code","8b4cd62d":"code","bc3e3014":"code","de4b1a7b":"code","6842ae82":"code","28d2a772":"code","896ef841":"code","ad3623a7":"markdown","dba379e5":"markdown","d8f4df04":"markdown","314908b7":"markdown","c40041df":"markdown","a82267ff":"markdown","34114224":"markdown","6efc395e":"markdown","d8a1969a":"markdown","5d6728f7":"markdown","728af49e":"markdown","aaff2628":"markdown","7fee96e4":"markdown","3e63c857":"markdown","0446929b":"markdown","db45044a":"markdown","cee97a81":"markdown","5e1b550d":"markdown","1fdeb49c":"markdown","e0e69f59":"markdown","272146fd":"markdown","6f657161":"markdown","22cc3130":"markdown"},"source":{"fdd0c622":"import numpy as np\nimport pandas as pd\nimport os\n\nPATH = \"\/kaggle\/input\/applications-of-deep-learning-wustlfall-2021\/city\"\nPATH_TRAIN = os.path.join(PATH, \"train.csv\")\nPATH_TEST = os.path.join(PATH, \"test.csv\")","8b509ff6":"# What version of Python do you have?\nimport sys\n\nimport tensorflow.keras\nimport pandas as pd\nimport sklearn as sk\nimport tensorflow as tf\n\nprint(f\"Tensor Flow Version: {tf.__version__}\")\nprint(f\"Keras Version: {tensorflow.keras.__version__}\")\nprint()\nprint(f\"Python {sys.version}\")\nprint(f\"Pandas {pd.__version__}\")\nprint(f\"Scikit-Learn {sk.__version__}\")\nprint(\"GPU is\", \"available\" if tf.test.is_gpu_available() \\\n      else \"NOT AVAILABLE\")","367227b7":"df_train = pd.read_csv(PATH_TRAIN)\ndf_test = pd.read_csv(PATH_TEST)\n\ndf_train['filename'] = df_train.id.astype(str) + \".jpg\"\ndf_test['filename'] = df_test.id.astype(str) + \".jpg\"","2a7a9daf":"# splitting scheme from starter code\nTRAIN_PCT = 0.9\nTRAIN_CUT = int(len(df_train) * TRAIN_PCT)\n\ndf_train_cut = df_train[0:TRAIN_CUT]\ndf_validate_cut = df_train[TRAIN_CUT:]\n\nprint(f\"Training size: {len(df_train_cut)}\")\nprint(f\"Validate size: {len(df_validate_cut)}\")\nprint(len(df_train))","51b683ad":"# # 10fold splitting scheme\n# k_fold_idx = [0,0.2,0.4,0.6,0.8,1]\n\n# # MANUALLY CHANGE PARAMETER TO RUN EACH FOLD!\n# fold = 5\n\n# VAL_START = int(len(df_train) * k_fold_idx[fold-1])\n# VAL_END = int(len(df_train) * k_fold_idx[fold])\n\n# df_train_cut = df_train[0:VAL_START].append(df_train[VAL_END:])\n# df_validate_cut = df_train[VAL_START:VAL_END]\n\n\n# print(f\"Training size: {len(df_train_cut)}\")\n# print(f\"Validate size: {len(df_validate_cut)}\")\n\n# df_train_cut","c4bc2339":"df_validate_cut","19b5a0e1":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\nWIDTH = 256\nHEIGHT = 256\n\n# don't tweak brightness it did not work\ntraining_datagen = ImageDataGenerator(\n  rescale = 1.\/255,\n  horizontal_flip=True,\n  #vertical_flip=True,\n  fill_mode='nearest')\n\ntrain_generator = training_datagen.flow_from_dataframe(\n        dataframe=df_train_cut,\n        directory=PATH,\n        x_col=\"filename\",\n        y_col=\"sqft\",\n        target_size=(HEIGHT, WIDTH),\n        batch_size=32, # Keeping the training batch size small USUALLY increases performance\n        class_mode='raw')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nval_generator = validation_datagen.flow_from_dataframe(\n        dataframe=df_validate_cut,\n        directory=PATH,\n        x_col=\"filename\",\n        y_col=\"sqft\",\n        target_size=(HEIGHT, WIDTH),\n        batch_size=256, # Make the validation batch size as large as you have memory for\n        class_mode='raw')","9d21ca3f":"'''\nimport matplotlib.pyplot as plt\ndef plots(ims, figsize=(25,25), rows=3, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)\/\/rows if len(ims) % 2 == 0 else len(ims)\/\/rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\nimgs, labels = next(train_generator)\n\n# prints batch of imgs\n# plots(imgs, titles=labels)\n\nplt.imshow(imgs[0])\nplt.show()\n'''","ecb2575a":"from tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.layers import Input\n\ninput_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n\nbase_model = DenseNet121(\n    include_top=False, weights=None, input_tensor=input_tensor,\n    input_shape=None)\n\n#base_model.summary()","b967bda9":"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Model\n\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) \nx=Dense(1024,activation='relu')(x)\nmodel=Model(inputs=base_model.input,outputs=Dense(1)(x))\nmodel.summary()\n\n# design from keras doc, this one is very slow and did not see much improvement\n# x=base_model.output\n# x=GlobalAveragePooling2D()(x)\n# x =Dropout(0.2)(x)  # Regularize with dropout\n# model=Model(inputs=base_model.input,outputs=Dense(1)(x))\n# model.summary()","e23ab504":"from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras.metrics import RootMeanSquaredError\n\n# Important, calculate a valid step size for the validation dataset\nSTEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=val_generator.n\/\/val_generator.batch_size\n\nmodel.compile(loss = 'mean_squared_error', optimizer='adam', metrics=[RootMeanSquaredError(name=\"rmse\")])\n\n# callbacks: early stopping and learning rate decay\nearly_stop  = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=25, verbose=1, mode='auto',\n        restore_best_weights=True)\n# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1) # tune if training too slow; should not cause over fit as this only put lr down\n\nhistory = model.fit(train_generator, epochs=200, steps_per_epoch=STEP_SIZE_TRAIN, \n                    validation_data = val_generator, callbacks=[early_stop],\n                    verbose = 1, validation_steps=STEP_SIZE_VALID)","3b823aa1":"# plot training curve\n\nimport matplotlib.pyplot as plt\n\ndef display_training_curves(training, validation, title, subplot):\n  if subplot%10==1: # set up the subplots on the first call\n    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n    plt.tight_layout()\n  ax = plt.subplot(subplot)\n  ax.set_facecolor('#F8F8F8')\n  ax.plot(training)\n  ax.plot(validation)\n  ax.set_title('model '+ title)\n  ax.set_ylabel(title)\n  ax.set_xlabel('epoch')\n  ax.legend(['train', 'valid.'])\n  plt.savefig('learning curve.png')\n\nprint(history.history.keys())\ndisplay_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211) \ndisplay_training_curves(history.history['rmse'], history.history['val_rmse'], 'rmse', 212) ","a523ffe4":"# save the model for later transfer tuning\nmodel.save('.\/model.h5')","aceafc6b":"## loading from our trained model\n# from tensorflow import keras \n# model = keras.models.load_model('..\/input\/model-v31\/model_v31.h5')\n# model.summary()","c3ed62ed":"## access history\n# history.history['rmse']\n# history.history['val_rmse']","fc66befb":"# this tells the final val_loss\ntextfile = open(\"final_val_rmse.txt\", \"w\")\ntextfile.write(str(history.history['val_rmse'][-1]))\ntextfile.close()","6515782b":"submit_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nsubmit_generator = submit_datagen.flow_from_dataframe(\n        dataframe=df_test,\n        directory=PATH,\n        x_col=\"filename\",\n        batch_size = 1,\n        shuffle = False,\n        target_size=(HEIGHT, WIDTH),\n        class_mode=None)\n\nsubmit_generator.reset()\npred = model.predict(submit_generator,steps=len(df_test))","8b4cd62d":"imgs = next(submit_generator)\n\n# prints batch of imgs\n# plots(imgs, titles=labels)\n\nplt.imshow(imgs[0])\nplt.show()","bc3e3014":"df_submit = pd.DataFrame({\"id\":df_test['id'],'sqft':pred[:,0].flatten()})\ndf_submit.to_csv(\"\/kaggle\/working\/submit.csv\",index = False)","de4b1a7b":"p2 = pred[:,0].flatten()","6842ae82":"df_submit[df_submit.id==24163]","28d2a772":"submit_generator.filenames","896ef841":"'''\nimport pandas as pd\nimport numpy as np\n\nimport os\nPATH = 'workplace'\nfilenames = os.listdir(PATH)\nfilenames\n\ndf_list = []\nfor i in filenames:\n    df = pd.read_csv(PATH+'\/'+i)\n    df_list.append(df)\ndf_submit = df_list[0][['id']].copy()\n\n# avg\nsqft_col = pd.DataFrame(0, index=np.arange(len(df_submit)), columns=['sqft'])\n\nfor i in df_list:\n    sqft_col += i[['sqft']]\n\ndf_submit['sqft'] = sqft_col\/len(df_list)\ndf_submit\n\n# this is meant to keep output organized\nID = input('input submit number: ')\n\ndf_submit.to_csv(f\"submit_{ID}.csv\",index = False)\n'''","ad3623a7":"This **might not** be the optimal\/'textbook' way to conduct ensemble: What we did was taking an average of all the output .csv files that perfomed well on public test set. Following code were used to make things a bit easier when there's multiple outputs to ensemble. ","dba379e5":"Note that this snippet was ran on a local pc, feel free to modify as needed.","d8f4df04":"Now we train just like before, the only difference is that we do not define the entire neural network here.","314908b7":"# Build Submission\n\nNow that the neural network is trained; we need to generate a submit CSV file to send to Kaggle.  We will use nearly the same technique to build the submit file.  However, these essential points that we must address:\n\n* We do not want the data generator to create an infinite date like we did when training.  We have a fixed number of cases to score for the Kaggle submit; we only want to process them.\n* We do not want the data generator to randomize the samples' order like it did when training. Therefore we set shuffle to false.\n* We want to always start at the beginning of the data, so we reset the generator.\n\nThese ensure that the predictions align with the id's.","c40041df":"Following utility snippet can be used to take a peek into the image data produced ImageDataGenerator","a82267ff":"Next, we prepare to read the training data (that we have labels for) and the test data that we must predict and send to Kaggle.","34114224":"# Scrapping up after training","6efc395e":"If we want to do kfold-validation, we could use `sklearn.model_selection.KFold`, however, since kaggle notebook has a 9-hour cap on single run, we can manually do the split to seperate each of the kfold, run seperately, and aggreagate the results later.","d8a1969a":"# Ensemble","5d6728f7":"We took the time to try out different networks in `Keras.Applications`, for this competition, DenseNet121 is performing well.","728af49e":"# Transfer Learning\n\n(FROM STARTER CODE)We will now use a ResNet neural network as a basis for our neural network.  We will redefine both the input shape and output of the ResNet model, so we will not transfer the weights.  Since we redefine the input; the weights are of minimal value.  We begin by loading, from Keras, the ResNet50 network.","aaff2628":"# Splitting training set and validation set","7fee96e4":"Next we check versions and if the GPU is available. A GPU or TPU will be very helpful.","3e63c857":"Since model training is very time consuming, and weight initilazation is stochastic, it is not that easy to build reproducible model. we would want to save up some information for later reference as","0446929b":"After testing, we think there's a maximum`steps_per_epoch` that can be computed using `STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size`, as mentioned before, it would not increase the size of your training set.\nBy setting a`steps_per_epoch` larger than `STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size`, we would see the training stops at 1 epoch as there is no more training data that can be passed into the neural network.","db45044a":"`model.save()` in previous code should be helpful if we want to do proper bagging or anything like that.","cee97a81":"**(This block is copied from starter, might not be all true)**\nWe now create the neural network and fit it.  Some essential concepts are going on here.\n\n* **Batch Size** - The number of training samples that should be evaluated per training step.  Smaller batch sizes, or mini-batches, are generally preferred.\n* **Step** - A training step is one complete run over the batch.  At the end of a step, the weights are updated, and the neural network learns.\n* **Epoch** - An arbitrary point at which to measure results or checkpoint the model.  Generally, an epoch is one complete pass over the training set.  However, when generators are used, the training set size is theoretically infinite. Because of this, we set a **steps_per_epoch** parameter.\n* **validation steps** - The validation set may also be infinite; because of this, we must specify how many steps we wish to validate at the end of each Epoch.","5e1b550d":"Some parameters you might want to work on:\n* **optimizer**: some articles states that a well tuned `sgd` (usually with momentum) performs better at the cost of longer training time, we did not pull off one that performs better than adam though.\n* **steps_per_epoch**: this works with `batch_size` defined in ImageDataGenerator, to use all data in training set, follow this formula`STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size`. \n* **callbacks**: a simple EarlyStopping performs well enough for this competition, we tried `ReduceLROnPlateau` along side with `sgd` but did not see much improvement.\n* **epochs**: too small could cause underfit or caught in the peak during loss fluctuation. If you choose to count on EarlyStopping you should be able to get away with setting this one as large as possible.\n* **patience**: this determines how much epochs the training would continue before no improvement greater than `min_delta` is perceived. A setting too small might get you trapped in a saddle point, too large would lead to longer training time. 25 worked fine for us.","1fdeb49c":"Now we must add a few layers to the end of the neural network so that it becomes a regression model.","e0e69f59":"We've tested out some other configurations but did not see much improvements over the 2\\*1024 dense layer one from starter.","272146fd":"If we want to use early stopping, we need a validation set.  We will break the data into 90 percent test data and 10 validation.  Do not confuse this validation data with the test set provided by Kaggle.  This validation set is unique to your program and is just used for early stopping.","6f657161":"Next, we create the generators that will provide the images to the neural network as it is trained.  We normalize the images so that the RGB colors between 0-255 become ratios between 0 and 1.  We also use the **flow_from_dataframe** generator to connect the Pandas dataframe to the actual image files. We see here a straightforward implementation; you might also wish to use some of the image transformations provided by the data generator.\n\nFor the image transformations part, it should be noted that ImageDataGenerator would only randomly apply transformation to certain image in the data, it WOULD NOT increse the size of training dataset. 20k training data stays 20k. (Ref:https:\/\/www.pyimagesearch.com\/2019\/07\/08\/keras-imagedatagenerator-and-data-augmentation\/)\n\nThe **HEIGHT** and **WIDTH** constants specify the dimensions that the image will be scaled (or expanded) to. It is probably not a good idea to expand the images.","22cc3130":"# Kaggle Transfer Learning Code for the City Square Feed Kaggle In-Class Competition\n\n**Author: Shawn S Lin and Qingyuan Gao(Group777)**\n\nThis workbook is a modified code for the [City Square Feed Kaggle In-Class Competition](https:\/\/www.kaggle.com\/c\/applications-of-deep-learning-wustlfall-2021)  This competition is one of the assignments for [T81-558: Applications of Deep Neural Netw1orks](https:\/\/sites.wustl.edu\/jeffheaton\/t81-558\/) at [Washington University in St. Louis](https:\/\/www.wustl.edu).\n\nThis is a more advanced notebook that uses transfer learning; however, it is not particularly optimized.  It is also possable to run this project from Google CoLab.  "}}