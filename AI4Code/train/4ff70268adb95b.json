{"cell_type":{"afcbda81":"code","ecf8c186":"code","148a5ba2":"code","6c2a09d8":"code","065b9764":"code","9a904503":"code","f4b0a511":"code","afd53d90":"code","a590d703":"code","759a6605":"code","8f7e2138":"code","64f0a378":"code","ed529a3e":"code","6f40d0ce":"code","385abee1":"code","9903fbd8":"code","2bbbdced":"code","4e2825bf":"code","f941a382":"code","cc5efc39":"code","eb90516e":"code","12cbab5d":"code","df134446":"code","cad82531":"code","55606277":"code","a9a771b9":"code","d7a5837e":"code","64fbd1e9":"code","ea2c601a":"code","503d1558":"code","7c47de7c":"code","24e57d40":"code","041291d3":"code","5e03bf4d":"code","bddf762e":"code","2a86cd07":"code","06f5b634":"code","e54ead3a":"code","edbea7a6":"code","948f1f89":"code","db5ee3c7":"code","66d0c9a8":"code","54c6721a":"code","c3511f69":"code","81e877a8":"code","c28ab0f2":"code","b0a16384":"code","1e431cab":"code","360f5664":"code","98fd60b7":"code","20c1a0d2":"code","fe3a7b6f":"code","411d5613":"code","8dc621ac":"code","5fe736d9":"code","e0f9ac20":"code","4ccd52b9":"code","54d8c469":"code","b10cbd2f":"code","d41cc213":"code","254b138a":"code","ffbbef96":"code","ddbcd018":"code","ab711c5d":"code","5f729d05":"code","0398578c":"markdown","99949521":"markdown","c9faa802":"markdown","acd59f1e":"markdown","c12ac8bd":"markdown","480615a3":"markdown","d06c9af6":"markdown","2cd52d12":"markdown","1488195b":"markdown","a3a296cc":"markdown","39cd2701":"markdown","f751997d":"markdown","abd9d145":"markdown","921c3da5":"markdown","02fb61d9":"markdown","8dd87576":"markdown","acea7765":"markdown","ec5474b0":"markdown","056afbc4":"markdown","847e7cc9":"markdown","a3157128":"markdown","30222f41":"markdown","c132cb62":"markdown","8824b9be":"markdown","59be7555":"markdown","11a07b33":"markdown","2fc7216e":"markdown","b810bf47":"markdown","a73d9b50":"markdown","0ca2c912":"markdown","2f2cce0f":"markdown"},"source":{"afcbda81":"!pip install -q nnAudio","ecf8c186":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom glob import glob\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.metrics import AUC\n\nimport librosa.display\nimport torch\n\n# this is used for Contant Q Transform\nfrom nnAudio.Spectrogram import CQT1992v2\nfrom tensorflow.keras.applications import EfficientNetB0 as efn","148a5ba2":"train_label_dataset = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/training_labels.csv\")\ntrain_label_dataset.head()","6c2a09d8":"train_label_dataset.shape","065b9764":"sns.countplot(data=train_label_dataset, x=\"target\")","9a904503":"train_label_dataset['target'].value_counts()","f4b0a511":"train_label_dataset.isnull().sum() # no null","afd53d90":"train_path = glob('..\/input\/g2net-gravitational-wave-detection\/train\/*\/*\/*\/*')","a590d703":"len(train_path)","759a6605":"explore_sample_3 = np.load(train_path[3])\nexplore_sample_3","8f7e2138":"explore_sample_3.shape","64f0a378":"print(len(explore_sample_3[0]), len(explore_sample_3[1]), len(explore_sample_3[2]))","ed529a3e":"# just a tensor representation\ntf.convert_to_tensor(explore_sample_3[0])","6f40d0ce":"train_path[3]","385abee1":"rind = train_path[3].rindex('\/') # last index where the character '\/' appeared\nextracted_id_for_explore_sample_3 = train_path[3][rind+1:].replace('.npy', '') # replaced .npy\nextracted_id_for_explore_sample_3","9903fbd8":"train_label_dataset[train_label_dataset['id']==extracted_id_for_explore_sample_3]['target']","2bbbdced":"positive_sample = explore_sample_3\n# index 1 od train_path has a target of 0 so it is a negative sample.\nnegative_sample = np.load(train_path[1])\nnegative_sample","4e2825bf":"samples = (positive_sample, negative_sample)\ntargets = (1, 0)","f941a382":"colors = (\"red\", \"green\", \"blue\")\nsignal_names = (\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n\nfor x, i in tqdm(zip(samples, targets)):\n    figure = plt.figure(figsize=(16, 7))\n    figure.suptitle(f'Raw wave (target={i})', fontsize=20)\n    # range is 3 because we have 3 different rows for each interferometers\n    for j in range(3):\n        axes = figure.add_subplot(3, 1, j+1)\n        librosa.display.waveshow(x[j], sr=2048, ax=axes, color=colors[j])\n        axes.set_title(signal_names[j], fontsize=12)\n        axes.set_xlabel('Time[sec]')\n    plt.tight_layout()\n    plt.show()","cc5efc39":"sns.displot(positive_sample[0,:])","eb90516e":"pd.set_option('display.max_colwidth',None)","12cbab5d":"ids = []\nfor files in train_path:\n    ids.append(files[files.rindex('\/')+1:].replace('.npy',''))\ndf = pd.DataFrame({\"id\":ids,\"path\":train_path})\ndf = pd.merge(df, train_label_dataset, on='id')","df134446":"df.head()","cad82531":"df.shape","55606277":"# CQT\ntransform = CQT1992v2(sr=2048,        # sample rate\n                fmin=20,        # min freq\n                fmax=500,      # max freq\n                hop_length=64,  # hop length\n                verbose=False)","a9a771b9":"# the Cqt function\n# preprocess function\ndef preprocess_function_cqt(path):\n    signal = np.load(path.numpy())\n    # there are 3 signal as explained before for each interferometers\n    for i in range(signal.shape[0]):\n        # normalize signal\n        signal[i] \/= np.max(signal[i])\n    # horizontal stack\n    signal = np.hstack(signal)\n    # tensor conversion\n    signal = torch.from_numpy(signal).float()\n    # getting the image from CQT transform\n    image = transform(signal)\n    # converting to array from tensor\n    image = np.array(image)\n    # transpose the image to get right orientation\n    image = np.transpose(image,(1,2,0))\n    \n    # conver the image to tf.tensor and return\n    return tf.convert_to_tensor(image)","d7a5837e":"image = preprocess_function_cqt(tf.convert_to_tensor(df['path'][2]))\nprint(image.shape)\nplt.imshow(image)","64fbd1e9":"image = preprocess_function_cqt(tf.convert_to_tensor(df['path'][5069]))\nprint(image.shape)\nplt.imshow(image)","ea2c601a":"input_shape = (56, 193, 1)","503d1558":"def preprocess_function_parse_tf(path, y=None):\n    [x] = tf.py_function(func=preprocess_function_cqt, inp=[path], Tout=[tf.float32])\n    x = tf.ensure_shape(x, input_shape)\n    if y is None:\n        return x\n    else:\n        return x,y","7c47de7c":"# preprocess_function_parse_tf(tf.convert_to_tensor(df['path'][5069]))","24e57d40":"X = df['id']\ny = df['target'].astype('int8').values","041291d3":"y","5e03bf4d":"x_train, x_valid, y_train, y_valid = train_test_split(X, y, random_state = 42, stratify = y)","bddf762e":"batch_size = 250","2a86cd07":"def get_npy_filepath(id_, is_train=True):\n    path = ''\n    if is_train:\n        return f'..\/input\/g2net-gravitational-wave-detection\/train\/{id_[0]}\/{id_[1]}\/{id_[2]}\/{id_}.npy'\n    else:\n        return f'..\/input\/g2net-gravitational-wave-detection\/test\/{id_[0]}\/{id_[1]}\/{id_[2]}\/{id_}.npy'","06f5b634":"train_dataset = tf.data.Dataset.from_tensor_slices((x_train.apply(get_npy_filepath).values, y_train))\n# shuffle the dataset\ntrain_dataset = train_dataset.shuffle(len(x_train))\ntrain_dataset = train_dataset.map(preprocess_function_parse_tf, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_dataset = train_dataset.batch(batch_size)\ntrain_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)","e54ead3a":"valid_dataset = tf.data.Dataset.from_tensor_slices((x_valid.apply(get_npy_filepath).values, y_valid))\nvalid_dataset = valid_dataset.map(preprocess_function_parse_tf, num_parallel_calls=tf.data.AUTOTUNE)\nvalid_dataset = valid_dataset.batch(batch_size)\nvalid_dataset = valid_dataset.prefetch(tf.data.AUTOTUNE)","edbea7a6":"train_dataset","948f1f89":"valid_dataset","db5ee3c7":"train_dataset.take(1)","66d0c9a8":"# Instantiate the Sequential model\nmodel_cnn = Sequential(name='CNN_model')\n\n# Add the first Convoluted2D layer w\/ input_shape & MaxPooling2D layer followed by that\nmodel_cnn.add(Conv2D(filters=16,\n                     kernel_size=3,\n                     input_shape=input_shape,\n                     activation='relu',\n                     name='Conv_01'))\nmodel_cnn.add(MaxPooling2D(pool_size=2, name='Pool_01'))\n\n# Second pair of Conv1D and MaxPooling1D layers\nmodel_cnn.add(Conv2D(filters=32,\n                     kernel_size=3,\n                     input_shape=input_shape,\n                     activation='relu',\n                     name='Conv_02'))\nmodel_cnn.add(MaxPooling2D(pool_size=2, name='Pool_02'))\n\n# Third pair of Conv1D and MaxPooling1D layers\nmodel_cnn.add(Conv2D(filters=64,\n                     kernel_size=3,\n                     input_shape=input_shape,\n                     activation='relu',\n                     name='Conv_03'))\nmodel_cnn.add(MaxPooling2D(pool_size=2, name='Pool_03'))\n\n# Add the Flatten layer\nmodel_cnn.add(Flatten(name='Flatten'))\n\n# Add the Dense layers\nmodel_cnn.add(Dense(units=512,\n                activation='relu',\n                name='Dense_01'))\nmodel_cnn.add(Dense(units=64,\n                activation='relu',\n                name='Dense_02'))\n\n# Add the final Output layer\nmodel_cnn.add(Dense(1, activation='sigmoid', name='Output'))","54c6721a":"model_cnn.summary()","c3511f69":"model_cnn.compile(optimizer=Adam(learning_rate=0.0001),\n                  loss='binary_crossentropy',\n                  metrics=[[AUC(), 'accuracy']])","81e877a8":"# Fit the data\nhistory_cnn = model_cnn.fit(x=train_dataset,\n                            epochs=3,\n                            validation_data=valid_dataset,\n                            batch_size=batch_size,\n                            verbose=1)","c28ab0f2":"model_cnn.save('.\/model\/cnn_model.h5')","b0a16384":"ls -a .\/","1e431cab":"ls -a ..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv","360f5664":"sub = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\nx_test = sub[['id']]","98fd60b7":"x_test.tail()","20c1a0d2":"# test dataset\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test['id'].apply(get_npy_filepath, is_train=False).values))\ntest_dataset = test_dataset.map(preprocess_function_parse_tf, num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size)\ntest_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)","fe3a7b6f":"test_dataset","411d5613":"ls -a .\/model\/","8dc621ac":"saved_cnn_model = tf.keras.models.load_model('.\/model\/cnn_model.h5')","5fe736d9":"saved_cnn_model","e0f9ac20":"saved_cnn_model.fit(x=valid_dataset, epochs=3, batch_size=batch_size, verbose=1)","4ccd52b9":"saved_cnn_model.save('.\/model\/full_cnn_model.h5')","54d8c469":"full_cnn_model = tf.keras.models.load_model('.\/model\/full_cnn_model.h5')","b10cbd2f":"prediction = full_cnn_model.predict(test_dataset)","d41cc213":"prediction","254b138a":"prediction = prediction.flatten()","ffbbef96":"submission = pd.DataFrame({'id': x_test.id, 'target': prediction})","ddbcd018":"submission.shape","ab711c5d":"submission.head()","5f729d05":"submission.to_csv('.\/submission.csv', index= False)","0398578c":"# Creating the Model","99949521":"the value of `train_path` at index 3 looks like:'\n\n'..\/input\/g2net-gravitational-wave-detection\/train\/7\/7\/7\/77727f6826.npy'\n\nSo, we know that the Id of `explore_sample_3` is **77727f6826**. To extract the Id the following code snippet has been written. \n\n","c9faa802":"retraining the saved model on `valid_dataset`\n\n> previously we set x = train_dataset","acd59f1e":"We can see that there are 3 rows to the data. This represents data extracted by 3 gravitational wave interferometers (LIGO Hanford, LIGO Livingston, and Virgo) respectively.","c12ac8bd":"# Preprocessing\n\n#### Core Idea: \nIf any particular frequency is widespread in the signal or not. If true then our required GW is present.\n\nApproach:\n\n- convert original signal  -->  spectrogram signal\n- coverting from time domain  --> frequency domain\n    - done using **[Constant Q transformation](https:\/\/en.wikipedia.org\/wiki\/Constant-Q_transform)**\n    - **[kernel](https:\/\/www.kaggle.com\/atamazian\/nnaudio-constant-q-transform-demonstration\/comments)**\n","480615a3":"for a different path","d06c9af6":"# Imports","2cd52d12":"# Preprocessing Test ","1488195b":"## Files\n\n```\ntrain: contains one npy file per observation.\n\ntest: we have to predict the probability whether or not the observation contains a gravitational wave.\n\ntraining_labels: If associated signal contains a GW or not.\n```\n\nThe waves detected by GW detectors have noises in output signals. So researchers need to find out if the output signal is only **noise** or **signal+noise**.\n\n\nWe are provided with a training set of time series data containing simulated gravitational wave measurements from a network of 3 gravitational wave interferometers (LIGO Hanford, LIGO Livingston, and Virgo). \n\nThis problem is seen as a binary classification problem, if signal is detected or not. \n ","a3a296cc":"There are 560,000 **.npy** files in the `train` set","39cd2701":"We see that it is a positive sample","f751997d":"If we want to take a took at how these data looks:\n\nlets see how data at index 3 looks","abd9d145":"## Data Exploration","921c3da5":"Using librosa.display() to view raw waves: \n\nKernel: https:\/\/www.kaggle.com\/hinamimi\/visualization-gravitational-wave-with-librosa","02fb61d9":"I started with zero idea and I ended up learning about a lot of new things. I am very much thankful to all these resources that help me increase my knowledge and give me more insight as I proceed to improve my skills on my coding journey.\n\nI tried referencing as much as I could.","8dd87576":"assigning submission ids to the test set to make prediction on them","acea7765":"Model from [here](https:\/\/github.com\/SiddharthPatel45\/gravitational-wave-detection\/blob\/main\/code\/gw-detection-modelling.ipynb) ~","ec5474b0":"each index of `explore_sample_3` has **4096** columns","056afbc4":"# Prediction","847e7cc9":"# Preparing to Submit","a3157128":"## Exploring the sample data with Librosa\n\nLibrosa is a python package for music and audio analysis, more about this awesome library can be found [here](https:\/\/librosa.org\/doc\/latest\/index.html).\n\nThere is a very good kernel that can be found [here](https:\/\/www.kaggle.com\/hinamimi\/visualization-gravitational-wave-with-librosa).\nIt has really great demonstration of how to use Librosa.\n\nNow first I will find the `label` (id) of `explore_sample_3` from the `training_label.csv` dataset. After that I can find whether the target is 1 or 0.\n\n- 0 = negative sample\n- 1 = possotive sample","30222f41":"saving the model after training is complete","c132cb62":"# Intro\n\nMachine learning can help astronomers sort big data recorded in space exploration.\n\n**Gravitational Wave:**\n\nVery simply,\n`A gravitational wave is like ripples in space time. It is usually caused by some of the most violent and energetic processes in the Universe.`\n\nThey are invisible but incredibly fast. \n\n**Why we need to detect GW?**\n\nDetecting and analyzing the information carried by gravitational waves is allowing us to observe the Universe in a way never before possible, providing astronomers and other scientists with their first glimpses of literally un-seeable wonders.\n When a gravitational wave passes by Earth, it squeezes and stretches space. LIGO can detect this squeezing and stretching. Each LIGO observatory has two \u201carms\u201d that are each more than 2 miles (4 kilometers) long.\n \n##### **above info collected via some very rough googling**\n \n### Goal\n\nThe GW was first detected\/seen when two blackholes merged into one big black whole back in Sept, 2015.\n\nIn this competition, our goal is to detect GW signals from the mergers of binary black holes.\n\nI am going to document this process as I start with zero idea about any of these.\n\nThe folowing two kernels have been my overall inspiration to understand this whole task to my best capability. These are really well explained and worth mentioning.\n\n- [kernel 1](https:\/\/www.kaggle.com\/pranay1990\/pranay-g2net-gw)\n- [kernel 2](https:\/\/github.com\/SiddharthPatel45\/gravitational-wave-detection\/blob\/main\/code\/gw-detection-modelling.ipynb)\n- [kernel 3](https:\/\/www.kaggle.com\/atamazian\/nnaudio-constant-q-transform-demonstration\/comments)\n\nThank you for sharing your work.","8824b9be":"Now saving the full model after training to make prediction on `test_dataset`","59be7555":"we can see that the image shape is **(56, 193, 1)**, so thats our shpa eof the input.","11a07b33":"Looking for null values:","2fc7216e":"I refer to the kernel [here](https:\/\/www.kaggle.com\/atamazian\/nnaudio-constant-q-transform-demonstration\/comments) to define my CQT.\n\nPlease have a look. ","b810bf47":"when `target = 1` it means that the signal (GW) is present","a73d9b50":"## Working with a cleaner datset by merging `train` and `training_labels` datasets","0ca2c912":"### I will define the `training` and `validation` dataset from `df`","2f2cce0f":"Now, we will load the cnn model that we saved after training to make prediction on `test_dataset`"}}