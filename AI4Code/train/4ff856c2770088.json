{"cell_type":{"9cd67df7":"code","a45631f1":"code","ad434e10":"code","7f3d933e":"code","1748aa7f":"code","bcc83e31":"code","24b549ca":"code","6e3db973":"code","6d22716f":"code","8ff9fa30":"code","300b24a9":"code","918a8a8f":"code","c9ecf80b":"code","b1aaad5a":"code","5d638c2d":"code","781732ef":"code","419c19f8":"code","a762a2e6":"code","e8c0ad9f":"code","2ede4afa":"markdown","89787d75":"markdown","fc7cc52c":"markdown","24c711d8":"markdown","ff48798d":"markdown","75b9fb2a":"markdown","3b904d4e":"markdown","f9c7ae22":"markdown","85a211d2":"markdown","267ccf57":"markdown","69670923":"markdown","c9938463":"markdown","32f0a6f5":"markdown","a29bc6f7":"markdown","079b748d":"markdown","7babeac9":"markdown","1b12c9c1":"markdown","695ce129":"markdown","f0da1479":"markdown"},"source":{"9cd67df7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # for figures\nimport matplotlib as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a45631f1":"netflix = pd.read_csv('..\/input\/netflix-shows\/netflix_titles.csv')\nnetflix_movies = netflix[netflix['type'] == 'Movie']\nnetflix_movies.head()","ad434e10":"data = netflix_movies[['title', 'listed_in', 'release_year']]\ndata = data.rename(columns={'release_year': 'year'})\ndata = data.rename(columns={'listed_in': 'genre'})\ndata.head()\ndata.info()","7f3d933e":"imdb_movies = pd.read_csv('..\/input\/imdb-movie-extensive-dataset\/IMDb movies.csv\/IMDb movies.csv')\nimdb_movies.head()\nimdb_movies = imdb_movies[['imdb_title_id', 'title', 'year']]\nimdb_ratings = pd.read_csv('..\/input\/imdb-movie-extensive-dataset\/IMDb ratings.csv\/IMDb ratings.csv')\nimdb = pd.merge(imdb_movies, imdb_ratings, on='imdb_title_id')\nimdb.head()\nimdb.info()","1748aa7f":"imdb = imdb[['title', 'weighted_average_vote']]\nimdb.info()","bcc83e31":"data = data.merge(imdb, how=\"inner\", left_on=['title'], right_on=['title'])\nprint(data.head())\ndata.info()","24b549ca":"top = data[\"weighted_average_vote\"].nlargest(1) # this returns the top weight and another number which I guess it's the index\nindex = top.index[0]\ntop_title = data['title'].iloc[index]\ntop_weight = data[\"weighted_average_vote\"].iloc[index]\n\nprint(\"Best movie ever \" + str(top_title)+ \" with vote: \" + str(top_weight))","6e3db973":"# reload (the whole dataset this time)\nimdb_movies = pd.read_csv('..\/input\/imdb-movie-extensive-dataset\/IMDb movies.csv\/IMDb movies.csv')\nimdb_movies.head()\nimdb_movies = imdb_movies[['imdb_title_id', 'title', 'year']]\nimdb_ratings = pd.read_csv('..\/input\/imdb-movie-extensive-dataset\/IMDb ratings.csv\/IMDb ratings.csv')\nimdb = pd.merge(imdb_movies, imdb_ratings, on='imdb_title_id')\ndata = netflix_movies.merge(imdb, how=\"inner\", left_on=['title'], right_on=['title'])\n\npd.set_option('max_rows', None)\nprint(data.isna().sum())\npd.reset_option('max_rows')\n","6d22716f":"# reload (the whole dataset this time)\n#data = data.fillna(0)\n#pd.set_option('max_rows', None)\n#print(data.isna().sum())\n#pd.reset_option('max_rows')","8ff9fa30":"def DetermineColumn(gender_group,age_group):\n    \n    A = 'dummy'\n    if gender_group in [\"F\",'f','fem', \"Fem\", \"FEM\", \"female\", \"Female\", \"FEMALE\", \"females\", \"Females\", \"FEMALES\"]:\n        A = \"females\"\n    if gender_group in [\"M\",'m','male', \"Male\", \"MALE\"]:\n        A = \"males\"\n    if gender_group in [\"A\",'a','all', \"All\", \"ALL\"]:\n        A = \"allgenders\"\n    if A == 'dummy':\n        print('I coudn\\'t understand the gender. Please try again. (the script is going to fail)')\n    B = 'dummy'\n    if age_group == '0-18':\n        B = \"0age\"\n    if age_group == '18-30':\n        B = \"18age\"\n    if age_group == '30-45':\n        B = \"30age\"\n    if age_group == '45+':\n        B = \"45age\"\n    if age_group == 'all':\n        B = \"allages\"\n    if B == 'dummy':\n        print('I coudn\\'t understand the age group. Please try again. (the script is going to fail)')\n        print('your age group: ', age_group)\n        print('possible choices: 0-18, 18-30, 30-45, 45+, all')\n    column = A+'_'+B+'_avg_vote'\n    if column == 'allgenders_allages_avg_vote':\n        # here I am not actually sure if one should select\n        # mean_vote or weighted_average_vote\n        column = 'weighted_average_vote'\n    \n    return column\n\ndef BestK(data, gender_group = 'all', age_group = 'all', k = 10):\n\n    column = DetermineColumn(gender_group,age_group)\n    \n    titles = []\n    votes = []\n    topK=data[column].nlargest(k)\n    for i in range(len(topK)):\n        index = topK.index[i]\n        title = data['title'].iloc[index]\n        titles.append(title)\n        vote = data[column].iloc[index]\n        votes.append(vote)\n        print(i+1, '.', title, ':', vote)\n        \n    ax = sns.barplot(x = titles, y = votes)\n    ax.set(xlabel='Movie Title', ylabel='Mean Rating')\n    ax.set_title('Best Rated Movies on Netflix for ' + gender_group + ' of age ' + age_group)\n    \n    return ","300b24a9":"# please chose any age group among:\n# 0-18,18-30, 30-45, 45+, 'all'\nage_group = '18-30'\n# please chose any gender group among:\n# 'male', 'female', 'all'\ngender_group = 'male'\n# please choose the list lenght (default = 10)\nk = 6\nBestK(data,  gender_group = gender_group, age_group = age_group, k = k)","918a8a8f":"#data.info()\n#pd.set_option('max_rows', None)\n#print(data.groupby(['listed_in'])['weighted_average_vote'].mean())\n#pd.reset_option('max_rows')\n\n# make a vector of all possible genres\nGenres = []\nfor i in range(len(data)):\n    row = data.iloc[i]\n    genres = row['listed_in']\n    genres = genres.split(',')\n    for g in genres:\n        g = g.replace(\" \", \"\")\n        if g not in Genres:\n            Genres.append(g)\n#print(Genres)\n\n# now we have all genres, let's initialize columns for that\nfor g in range(len(Genres)):\n    vector = [False] * len(data)\n    data[Genres[g]] = vector  \n#print(data['Action & Adventure']).head()\n\n# and now let's fill these columns\nfor i in range(len(data)):\n    row = data.iloc[i]\n    genres = row['listed_in']\n    genres = genres.split(',')\n    for g in genres:\n        g = g.replace(\" \", \"\")\n        data.at[i,g] = True","c9ecf80b":"age_groups = [\"0-18\", \"18-30\", \"30-45\", \"45+\", \"all\"]\ngender_groups = ['male', 'female', 'all' ]\n\nboolean = True\nfor a_g in age_groups:\n    for g_g in gender_groups:\n        column = DetermineColumn(g_g,a_g)\n        group_a_g_g_g = g_g + '_'+ a_g\n        vector = []\n        for g in Genres:\n            average = data[column].loc[data[g] == True].mean()\n            vector.append(average)\n        if boolean:\n            hm_df = {group_a_g_g_g : vector}\n            hm_df = pd.DataFrame(hm_df)\n            boolean = False\n        else:\n            hm_df[group_a_g_g_g] = vector\n\nhm = sns.heatmap(data = hm_df, yticklabels = Genres, center=5)","b1aaad5a":"# choose any (multiple allowed)\n# 'Dramas', 'InternationalMovies', 'HorrorMovies', 'Action&Adventure', 'IndependentMovies', \n#'Sci-Fi&Fantasy', 'Thrillers', 'Comedies', 'RomanticMovies', 'Music&Musicals', \n#'Children&FamilyMovies', 'Documentaries', 'CultMovies', 'LGBTQMovies', 'AnimeFeatures', \n#'ClassicMovies', 'SportsMovies', 'Faith&Spirituality', 'Movies', 'Stand-UpComedy'\ngenres_to_analyze = ['InternationalMovies', 'HorrorMovies', 'Action&Adventure']\n\n# choose any (multiple allowed): 'male', 'female', 'all'\ngenders_to_analyze = ['female','male']\n\n# choose any (multiple allowed): [\"0-18\", \"18-30\", \"30-45\", \"45+\", \"all\"]\nage_to_analyze = [ \"18-30\", \"30-45\", \"all\"]","5d638c2d":"def PrintSubHeatMap(genres_to_analyze,genders_groups,age_groups,Genres):\n        \n    boolean = True\n    for a_g in age_groups:\n        for g_g in genders_groups:\n            column = DetermineColumn(g_g,a_g)\n            group_a_g_g_g = g_g + '_'+ a_g\n            vector = []\n            for g in Genres:\n                if g in genres_to_analyze:\n                    average = data[column].loc[data[g] == True].mean()\n                    vector.append(average)\n            if boolean:\n                hm_df = {group_a_g_g_g : vector}\n                hm_df = pd.DataFrame(hm_df)\n                boolean = False\n            else:\n                hm_df[group_a_g_g_g] = vector\n\n    hm = sns.heatmap(data = hm_df, yticklabels = genres_to_analyze, center=5)","781732ef":"PrintSubHeatMap(genres_to_analyze,genders_to_analyze,age_to_analyze,Genres)","419c19f8":"# \nmaximum = ['dummy', 0 ]\nminimum = ['dummy', 10]\nboolean = True\nfor a_g in age_groups:\n    for g_g in gender_groups:\n        column = DetermineColumn(g_g,a_g)\n        group_a_g_g_g = g_g + '_'+ a_g\n        for g in Genres:\n            average = data[column].loc[data[g] == True].mean()\n            if average > maximum[1]:\n                maximum = [ [g, g_g, a_g] ,average]\n            if average < minimum[1]:\n                minimum = [ [g, g_g, a_g] ,average]\n\nprint('most  liked genre - gender - age: ',  maximum)\nprint('least liked genre - gender - age: ',  minimum)\n\n# actually it's probably more efficint to ask the min to the coloumn of the database\n# and then confront just those. \n# Anyway the df is small so also like this is quite fast","a762a2e6":"data['country'].value_counts()","e8c0ad9f":"# take top 100 movies (general rating)\ntop100 = data.nlargest(100,['weighted_average_vote'])\n# isolate only indian movies\nprint('Indian movies in the top100: ', len(top100[(top100.country == \"india\") | (top100.country == \"India\")]))\n# isolate only indian movies\nprint('Usa movies in the top100: ', len(top100[(top100.country == \"United States\") | (top100.country == \"united states\")]))","2ede4afa":"Now let's see how poupar are the movies genre with respect to gender \/ age.","89787d75":"\nNow we will try to make something a bit more sophisticated. I aim to make a function that given a gender\/age group, it returns the best k movies.\nIf geneder\/age group are not specified, then it is assumed to be all of them.\nif k is not specified, it is assumed to be 10.\n(in this dataset, we have info only for men\/female.)","fc7cc52c":"Now let's plot the heatmap of only the selected options","24c711d8":"Now we load the Netflix data and take a quick look at it.","ff48798d":"This is a lot of info. We will analyze movie ratings based on year of the movie, gender and age of the reviewers.\nLet's start by analyzing the best movies for \"everybody\" (so not segmented by gender or age).\nSmall note, the information on the year is already included in the netflix dataset, so we don't need to load it again. However, if you load it, and try to merge by title and year, you are going to miss some data points possibly due to small differences or onymicity.","75b9fb2a":"Let's test it","3b904d4e":"Now let's start analizing segmenting customers for gender and age","f9c7ae22":" now we have all genres in the df, let's create the heatmap\n \n ","85a211d2":"Another analysis i would like to dive in, is to try to take into consideration \"national\" biases in movie rating. For instance, an italian such as myself might be more benevolent when jeudging italian movies becuase they may speak to something closer to my own reality. This becomes interesting because some countries with massive population can shift the overall score of some movies. ","267ccf57":"68 of the top 100 movies were produced in India as opposed to just 13 in the Usa, and this does not even take into account the collaboration with other countries!","69670923":"Let's take the case of India (1.3+ billion people) VS USA (0.3+ billion people). They have roughly hte same number of movies in this dataframe but Let's check how many indian movies there are in the top 100. (disclaimer, this is not to say that Bollywood or such does not produce good movies. Bollywood prodocues excellent movies in my opinion).","c9938463":"although difficult to read, the previous heatmap has all the info we were looking for.\nLet's just try to visualize it better","32f0a6f5":"It is worth noting that from a dataset of around 8k we are reduced to just 2.4k points. This can be due to the fact the movie's title were saved differently (capital letters or such). **LOOK AGIAN INTO THIS**","a29bc6f7":"Now we have to load the IMBD data.","079b748d":"Now let's merge the two dataset together (via the title)","7babeac9":"Among all this information, only some is useful for us (at least for now).\nWe are only interested in the title of the movie, its genre (listed_in) and the release year.","1b12c9c1":"From the heatmap (the main one), we can see that *cult movies* and *classic movies* are the most liked ones (and this does not really come as a suprise I would say). \nThe least liked are *horrors* and *movie* (which i belive is an incorrect label).\n\nWhat is the tuple [gender-age-genre] most and least liked?","695ce129":"As we can see many data are missing. This is well reasonable since some groups cannot\/ did not vote for some movies. For instance, people below 18 cannot vote for pg-18 movies. \nSince we already have information about the average vote, we can fill in the missing datas with zeros (since this won't affect the average which is already being computed). A vote of zero, in this case, means that a particular category is not interested in one specific movie.","f0da1479":"In this notebook, we will dive into a Netflix database (for the sake of easiness, we will limit ourselves to movies and not series). We will try to understand which range of people like what movies. To quantify how much a movie is \"liked\" we will use data from the IMBD rating website.\n\nThis notebook takes inspiration from: https:\/\/www.kaggle.com\/eward96\/best-movies-on-netflix-eda\/data\n\nAs always, let's start by uploading some useful libraries."}}