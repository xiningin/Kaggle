{"cell_type":{"85448fc3":"code","ce274892":"code","742daec7":"code","be13a8c3":"code","5cc965ae":"code","d50f388e":"code","f2408459":"code","1a84afae":"code","3d1f68d5":"code","7f39d41d":"code","4e07aaba":"code","6e0dfd11":"code","204cbce5":"code","9f320be9":"code","c180be39":"code","1488074f":"code","7b0ee6e8":"code","e08a0eb2":"code","13e3b35c":"code","224ea0e5":"code","e57a06ed":"code","fe9b9708":"code","25432dde":"code","117f36f1":"code","5790dc85":"code","51602baf":"code","debcd5dd":"code","2d1ecd42":"code","10e1858b":"code","ae168460":"code","e2ac34bc":"markdown","f0181811":"markdown","e3acb1f4":"markdown","f791f1ff":"markdown","6c255033":"markdown","45f17cda":"markdown","b6cdb996":"markdown","41b06ea5":"markdown","3e421905":"markdown","e522c48f":"markdown","fe28af6a":"markdown","385e5630":"markdown","65f79f57":"markdown","db8964be":"markdown","b4b83602":"markdown","1b03e4b4":"markdown","30bf9cc3":"markdown","14214467":"markdown","b204e606":"markdown"},"source":{"85448fc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce274892":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv\")\nsample_submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\n\nrandom_state = 42","742daec7":"df_train.head()","be13a8c3":"%%time\ndf_train.info()","5cc965ae":"df_train.describe()","d50f388e":"columns = df_test.columns[1:]\nprint(columns)","f2408459":"x_train = df_train.drop(labels = \"target\", axis=1)\n# y_train = df_train[\"target\"].values\ny_train = df_train[\"target\"]\n\nx_test = df_test.copy()\nx_train.head()","1a84afae":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer","3d1f68d5":"std_scaler = StandardScaler()\n\nnum_pipeline = Pipeline([(('std_scaler'), StandardScaler()),])\nfull_pipeline = ColumnTransformer([('num', num_pipeline, columns),])\n\nx_train[columns] = full_pipeline.fit_transform(x_train)\nx_test[columns] = full_pipeline.transform(df_test)","7f39d41d":"# x_train.shape\nx_train.head()","4e07aaba":"from sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","6e0dfd11":"def plot_roc_curve(fpr, tpr, label=None, title=None):\n    \"\"\"\n    \"\"\"\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') \n    plt.legend(loc = 'lower right')\n    plt.title(title)\n    plt.show()\n\n    \ndef roc_auc_score_func(y_true, y_head, plot_roc=False):\n    \"\"\" evaluate roc auc score\n    Args:\n        y_true : a numpy array. True labels.\n        y_head : a numpy array. Predicted labels.\n        plot_roc : if you want to plot roc curve. (Default is False)\n        \n    \"\"\"\n    \n    if plot_roc:\n        fpr, tpr, thresholds = roc_curve(y_true, y_head)\n        plot_roc_curve(fpr, tpr, label=None, title=None)\n        \n        \n    # evaluate roc auc score\n    model_roc_auc_score = roc_auc_score(y_true, y_true)\n#     print(\"ROC AUC Score:\",roc_auc_score_train)\n    \n    return model_roc_auc_score\n\n\ndef train_and_predict(clf, clf_name, X, Y, x_test, n_splits=5):\n    \"\"\"train ml models with Stratified Kfol return auc score for probability of test data with ml model name\n    \n    Args:\n        clf : model classifier\n        clf_name : classifier name\n        x_train : a numpy.darray training data \n        y_train : a numpy.darray training labels\n        x_test: test data\n        n_splits : StratifiedKFold splits number\n        \n    Returns:\n        roc_auc_score_mean\n        accuracy_mean\n        valid_preds_dict : a dict that stores validation set ids and predictions probabilities from StratifiedKFold\n        test_preds: predictions probabilities of test set\n    \"\"\"\n    \n    valid_preds = []\n    valid_ids = []\n    valid_preds_dict = {}\n    \n    test_preds = []\n    \n    roc_auc_score_list = []  # roc auc score list\n    acc_score_list = [] # auc score list\n    \n#     test_preds = {}\n\n    skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n    \n    for i, (train_index, val_index) in enumerate(skf.split(X, Y)):\n        print(\"Fitting fold\", i+1)\n        X_train, X_val = X[train_index], X[val_index]\n        Y_train, Y_val = Y[train_index], Y[val_index]\n#         print(X_train.head())\n        \n        print(\"Model:\", clf_name)\n\n        # TRAINING\n        training_start_time = time.time()\n        local_time = time.ctime(training_start_time)\n        print(\"Local time:\", local_time)\n        \n        model = clf\n#         model.fit(X_train[columns], Y_train)\n        model.fit(X_train[:,1:], Y_train)  # except id column\n\n        training_end_time = time.time()\n        training_time = training_end_time - training_start_time\n        print(f\"Training elapsed seconds: {round(training_time,3)}\")\n\n\n        # EVALUATING\n        evaluating_start_time = time.time()\n        local_time = time.ctime(evaluating_start_time)\n        print(\"Local time:\", local_time)\n        \n        # create dictionary to save predictions of validation data\n#         valid_pred = model.predict_proba(X_val[:,1:])[:, 1]  # predict probabilty of validation set\n#         valid_preds.append(valid_pred)\n#         valid_ids.append(X[val_index,0])\n        valid_preds = model.predict_proba(X_val[:,1:])[:, 1]  # predict probabilty of validation set\n        valid_ids = X[val_index,0].tolist()\n        valid_preds_dict.update(dict(zip(valid_ids, valid_preds)))  \n    \n        \n        roc_auc_score_list.append(roc_auc_score(Y_val, valid_preds))\n        acc_score_list.append(accuracy_score(Y_val, model.predict(X_val[:,1:])))\n\n        evaluating_end_time = time.time()\n        evaluating_time = evaluating_end_time - evaluating_start_time\n        print(f\"evaluating scores elapsed seconds: {round(evaluating_time,3)}\")\n    \n    \n        # PREDICTION\n        prediction_start_time = time.time()\n        local_time = time.ctime(prediction_start_time)\n        print(\"Local time:\", local_time)\n        \n        test_pred = clf.predict_proba(x_test)[:, 1]\n        test_preds.append(test_pred)\n\n        prediction_end_time = time.time()\n        prediction_time = prediction_end_time - prediction_start_time\n        print(f\"predicting test probability scores elapsed seconds: {round(prediction_time,3)}\")\n    \n    roc_auc_score_mean = np.mean(roc_auc_score_list)\n    accuracy_mean = np.mean(acc_score_list) \n    \n    \n    print(f\"Mean accuracy: {round(accuracy_mean*100,3)}, Mean AUC Score: {round(roc_auc_score_mean*100,3)}\")\n    \n    return roc_auc_score_mean, accuracy_mean, valid_preds_dict, test_preds","204cbce5":"# # IT CONTROLS THE CODE WORKS BEFORE SUBMIT\n# from sklearn.model_selection import StratifiedShuffleSplit\n\n# split = StratifiedShuffleSplit(n_splits=1, test_size=0.001, random_state=42)\n\n# for train_index, val_index in split.split(x_train, y_train):\n#     x_train, y_train = x_train.loc[val_index], y_train.loc[val_index] \n# #     x_val, y_val = x_train.loc[val_index], y_train.loc[val_index]\n\n# # x_train_2 = x_train_2.values\n# # y_train_2 = y_train_2.values\n\n# # # x_train_2[:,0] # id","9f320be9":"!pip install --upgrade xgboost\n\n# # xgb.__version__","c180be39":"from xgboost import XGBClassifier","1488074f":"# assert False","7b0ee6e8":"x_train = x_train.values\ny_train = y_train.values","e08a0eb2":"classifiers = [LogisticRegression(solver='liblinear', random_state = random_state),\n               XGBClassifier(max_depth=8,\n                             learning_rate=0.01,\n                             n_estimators=10000,\n                             verbosity=1,\n                             silent=None,\n                             objective='binary:logistic',  \n                             tree_method = 'gpu_hist',\n                             booster='gbtree',\n                             n_jobs=-1,\n                             nthread=None,\n                             eval_metric='auc',\n                             gamma=0,\n                             min_child_weight=1,\n                             max_delta_step=0,\n                             subsample=0.7,\n                             colsample_bytree=1,\n                             colsample_bylevel=1,\n                             colsample_bynode=1,\n                             reg_alpha=0,\n                             reg_lambda=1,\n                             scale_pos_weight=1,\n                             base_score=0.5,\n                             random_state=random_state,\n                             seed=None)]\n\nclassifiers_names = [\"LogisticRegression\",\n                     \"XGB\"]","13e3b35c":"%%time\n\nimport time\n\nclf_roc_auc_scores = [] \nclf_auc_scores = []\n\nscores_of_models = {}\n\n\n\nfor i, clf in enumerate(classifiers):\n    \n    \n    start_time = time.time()\n    clf_name = classifiers_names[i]\n    roc_auc_score_mean, accuracy_mean, valid_preds_dict, test_preds = train_and_predict(clf, \n                                                                                        clf_name, \n                                                                                        x_train, \n                                                                                        y_train,  \n                                                                                        x_test[columns],\n                                                                                        n_splits=2)\n    \n    clf_roc_auc_scores.append(roc_auc_score_mean)\n    clf_auc_scores.append(accuracy_mean)\n    \n    end_time = time.time()\n    \n    print('Elapsed seconds classifier training time:', round(end_time-start_time,2))\n    \n#     assert False\n\n    # save predictions of validation data to csv\n    valid_preds_dict = pd.DataFrame.from_dict(valid_preds_dict, orient=\"index\").reset_index()\n    valid_preds_dict.columns = [\"id\", f\"pred_{i}\"]\n    valid_preds_dict.to_csv(f\"valid_preds_{clf_name}.csv\", index=False)\n\n    # save predictions of test data to csv\n    sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\n    \n    # it can be deleted.\n#     print(\"sub.shape\", sub.shape)\n#     print(test_preds)\n#     print(\"lenght test_preds\", len(test_preds))\n#     print(\"shape test_preds\", test_preds.shape())\n#     sub = sub[0:len(test_preds)]\n    \n    test_preds = np.mean(np.column_stack(test_preds), axis=1)  # mean of every kfold predictions. Before that it gives a list has two columns\n    \n    sub['target'] = test_preds\n    sub.columns = [\"id\", f\"pred_{i}\"]\n    sub.to_csv(f'test_preds_{clf_name}.csv', index=False)\n    \n\n# SAVE MODELS AUC SCORES \nclf_results = pd.DataFrame({\"ML Models\": classifiers_names, \"clf_roc_auc_scores\":clf_roc_auc_scores})\nclf_results.to_csv(\"classifiers_auc_scores.csv\", index=False)","224ea0e5":"# PLOT AUC Scores\n\nsns.set(style=\"whitegrid\", color_codes=True)\npal = sns.color_palette(\"Greens_d\", len(clf_results[\"ML Models\"]))\nrank = clf_results[\"ML Models\"].argsort().argsort() \ng = sns.barplot(\"ML Models\", \"clf_roc_auc_scores\", data = clf_results, palette=np.array(pal[::1])[rank])\ng.set_xlabel(\"Mean ROC AUC Score of Probability\")\ng.set_title(\"Stratified KFold\")\nplt.show()","e57a06ed":"df_valid_preds_0 = pd.read_csv(\"valid_preds_LogisticRegression.csv\")\ndf_valid_preds_1 = pd.read_csv(\"valid_preds_XGB.csv\")\n\ndf_test_preds_0 = pd.read_csv(\"test_preds_LogisticRegression.csv\")\ndf_test_preds_1 = pd.read_csv(\"test_preds_XGB.csv\")","fe9b9708":"df_valid_preds_0.head()","25432dde":"df_valid_preds_1.head()","117f36f1":"df_test_preds_0.head()","5790dc85":"df_test_preds_1.head()","51602baf":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv\")","debcd5dd":"# df_valid_preds_0 = df_valid_preds_0.merge(df_train, on=\"id\", how=\"left\")\n# df_valid_preds_0 = df_valid_preds_0.merge(df_valid_preds_1, on=\"id\", how=\"left\")\n\n\ndf_train = df_train.merge(df_valid_preds_0, on=\"id\", how=\"left\")\ndf_train = df_train.merge(df_valid_preds_1, on=\"id\", how=\"left\")\n\ndf_train.head()","2d1ecd42":"df_train.shape","10e1858b":"# useful_features_train = [\"pred_0\", \"pred_1\", \"pred_2\", \"target\"]\nuseful_features_train = [\"pred_0\", \"pred_1\", \"target\"]\n\ndf_train[useful_features_train].head()","ae168460":"df_test = df_test.merge(df_test_preds_0, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test_preds_1, on=\"id\", how=\"left\")\n\ndf_test.head()","e2ac34bc":"[back to the top](#0)","f0181811":"[back to the top](#0)","e3acb1f4":"## Create a Pipeline for Preparing Data to Training","f791f1ff":"[Variable Describtions](#7)\n\n[back to the top](#0)","6c255033":"I've chosen three classifiers according to my previous notebook's evaluation results.","45f17cda":"[back to the top](#0)","b6cdb996":"<a id=\"7\"><\/a> <br>\n## A. Split Train and Validation Data\n[back to the top](#0)","41b06ea5":"<a id=\"0\"><\/a> <br>\n# Table of Contents\n\n1. [Introduction to Tabular Playground Series - Nov 2021](#1)\n    1. [Variable Describtions](#2)\n1. [Load and Glance at the Data](#3)   \n1. [Feature Scaling](#4)\n1. [Helper Functions](#5)  \n1. [ML Models](#6)  \n1. [Read CSV files and Merge](#8)","3e421905":"<a id=\"4\"><\/a> <br>\n# 3. Feature Scaling\nIn order to, ML algorithms perform well, I will scale data with Standardization method.\n\n[Variable Describtions](#7)\n\n[back to the top](#0)","e522c48f":"<a id=\"5\"><\/a> <br>\n# 4. Helper Functions\n[back to the top](#0)","fe28af6a":"<font color=green>All variables is numerical. So we will not strive with categorical data.<\/font>","385e5630":"<a id=\"6\"><\/a> <br>\n# 5. ML Models\n[back to the top](#0)","65f79f57":"<a id=\"3\"><\/a> <br>\n# 2. Load and Glance at the Data\nFirst things first, load and glance at the data.\n\n[back to the top](#0)","db8964be":"<a id=\"8\"><\/a> <br>\n# 6. Read CSV files and Merge\n[back to the top](#0)","b4b83602":"<a id=\"2\"><\/a> <br>\n## A. Variable Describtions:\n- **df_train** : Pandas data frame for training data set\n- **df_test** : Pandas data frame for test data set\n- **x_train** : Pandas data frame removed target columns from df_train\n- **y_train** : Pandas data frame from df_train","1b03e4b4":"<a id=\"1\"><\/a> <br>\n# 1. Introduction to Tabular Playground Series - Nov 2021 \n\nTPS is a monthly competition prepared by Kaggle. The data is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. More information can be found on the [Competition Overview Page](https:\/\/www.kaggle.com\/c\/tabular-playground-series-nov-2021\/overview).\n\n**The goal** is **predicting probability** of the observed target 0 or 1. So it is **supervised learning** and **classification task**. Also **evaluation metric** is selected **area under the ROC curve**.\n\n[My first Notebook on this competition: TPS Nov 2021 Starter with XGBoost](https:\/\/www.kaggle.com\/ahmetekiz\/tps-nov-2021-starter-with-xgboost#7.-Selecting-Models)\n\n[back to the top](#0)","30bf9cc3":"[back to the top](#0)","14214467":"One of my references here [abhishek's notebook](https:\/\/www.kaggle.com\/abhishek\/competition-part-6-stacking\/notebookhttps:\/\/www.kaggle.com\/abhishek\/competition-part-6-stacking\/notebook), especially mean of several kfold test predictions. \n\n[back to the top](#0)","b204e606":"[Variable Describtions](#7)\n[back to the top](#0)"}}