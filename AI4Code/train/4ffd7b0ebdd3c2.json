{"cell_type":{"9a6fd51b":"code","f13ae8a3":"code","fe22828b":"code","7f6396a4":"code","272a09a2":"code","ebd9e797":"code","c03bbad8":"code","2b32ce47":"code","5de4bd43":"code","ad19cfb6":"code","d1ca41b4":"code","deb353ba":"code","68b10f8d":"code","ffe55f89":"code","b861e912":"code","59fdebc0":"code","46daa60f":"code","b2ca752e":"code","0acd0181":"code","59f78037":"code","fbeb955a":"code","30e9c4e8":"code","13ce0b80":"code","d08d4a1e":"code","5098304e":"code","50b9a826":"code","43cb9447":"code","3685e698":"code","ee2102ff":"code","bfe8ebaf":"code","c3947087":"code","af191dab":"code","b8622457":"code","b93bb69a":"code","9be4e5ec":"code","8ce92a6c":"code","ff1c20ff":"code","e8842139":"code","cfd4cb83":"code","3cbd2fca":"code","23202f21":"code","9150857f":"code","5de82184":"code","c9b868d3":"code","eb29d65d":"markdown","198b2ad7":"markdown","32d9acd5":"markdown","08430002":"markdown","e8bad22c":"markdown","d4dc9e9d":"markdown","c74777ed":"markdown","d6f117a2":"markdown","7c189ba4":"markdown","be05bc20":"markdown","306312aa":"markdown","250a2c99":"markdown","bfa2e604":"markdown","b13bfd3b":"markdown","4013aeec":"markdown","efac381f":"markdown","74bc5989":"markdown","2b68fda6":"markdown","eb10994c":"markdown","2099d7f1":"markdown","8e99ffe9":"markdown","c7326b04":"markdown","bb768029":"markdown","442db25f":"markdown","9cd0c1ea":"markdown","8c332af8":"markdown","6357ea74":"markdown","eaba5cbf":"markdown","9cbc2abd":"markdown","d4907880":"markdown","a5d2e34e":"markdown","0a613b6f":"markdown"},"source":{"9a6fd51b":"# Importa as bibliotecas\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics ","f13ae8a3":"# Importa o Dataset\nindios = pd.read_csv('..\/input\/pima-indians\/PimaIndians.csv')\nindios.tail()","fe22828b":"# Escolher o alvo. Dividir os atributos (vari\u00e1veis independentes) da target (label)\nx = indios[['pregnant', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi', 'diabetes', 'age']]\ny = indios['test']","7f6396a4":"# Vamos criar uma \u00e1rvore de decis\u00e3o\nmodelodt = DecisionTreeClassifier()\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x, y)\n\n# Aplica o modelo treinado no dataset para prever o resultado\ny_previsao = modelodt.predict(x)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y, y_previsao)","272a09a2":"# An\u00e1lise Explorat\u00f3ria Inicial\nindios.describe()","ebd9e797":"# Tem Outliers?\nindios.boxplot()","c03bbad8":"# Avalia um dos atributos: quantidade de gravidez\nindios.boxplot('pregnant')","2b32ce47":"# Valores Ausentes - Missing Values\nindios.isnull().sum().sort_values(ascending = False)","5de4bd43":"# Correla\u00e7\u00e3o. Cad\u00ea a vari\u00e1vel test?\nindios.corr()","ad19cfb6":"# Transforma test em binario: 0 - sem diabentes  ,   1 - com diabetes   \nimport numpy as np\nindios['test'] = pd.Series( np.where(indios.test== 'positif' , 1 , 0 ) , name = 'test' )","d1ca41b4":"# Verifica\nindios.head()","deb353ba":"# Correla\u00e7\u00e3o. \nindios.corr()","68b10f8d":"# Visualiza a Correla\u00e7\u00e3o\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(11,8)})\nsns.heatmap(indios.corr(), annot=True, annot_kws={\"size\": 10})","ffe55f89":"# Escolher o alvo. Dividir os atributos (vari\u00e1veis independentes) da target (label)\nx = indios[['pregnant', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi', 'diabetes', 'age']]\ny = indios['test']","b861e912":"# Divide os dados entre 70% treino e 30% teste\nfrom sklearn.model_selection import train_test_split\nx_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3)","59fdebc0":"# Vamos criar uma \u00e1rvore de decis\u00e3o \nmodelodt = DecisionTreeClassifier()\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelodt.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y_teste, y_previsao)","46daa60f":"# Imprime as primeiras linhas da previsao do resultado\ny_previsao[0:5]","b2ca752e":"# Imprime a profundidade da \u00e1rvore\nprint(modelodt.tree_.max_depth)","0acd0181":"# Imprime a quantidade de n\u00f3s\nprint(modelodt.tree_.node_count)","59f78037":"# Settings: habilitar a Internet\n!pip install pydotplus","fbeb955a":"# Visualiza\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\n\ndot_data = StringIO()\nexport_graphviz(modelodt, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = x_treino.columns,class_names=['0','1'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('diabetes.png')\nImage(graph.create_png())","30e9c4e8":"# Vari\u00e1veis mais importantes com \u00c1rvore de Decis\u00e3o\nimport matplotlib.pyplot as plt\n\n# Cria uma serie de atributos mais importantes e ordena as s\u00e9ries\nimportances = pd.Series(data=modelodt.feature_importances_, index= x_treino.columns)\nimportances_sorted = importances.sort_values()\n\n# Desenha um gr\u00e1fico de barras\nimportances_sorted.plot(kind='barh', color='lightgreen')\nplt.title('Features Importances')\nplt.show()","13ce0b80":"# Imprime a profundidade da \u00e1rvore\nprint(modelodt.tree_.max_depth)","d08d4a1e":"# Model Tuning\nmodelodt = DecisionTreeClassifier(max_depth=3)\nmodelodt = modelodt.fit(x_treino, y_treino)\ny_previsao = modelodt.predict(x_teste)\nmetrics.accuracy_score(y_teste, y_previsao)","5098304e":"# Visualiza\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\n\ndot_data = StringIO()\nexport_graphviz(modelodt, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = x_treino.columns,class_names=['0','1'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('diabetes.png')\nImage(graph.create_png())","50b9a826":"# Vamos criar uma \u00e1rvore de decis\u00e3o com crit\u00e9rio entropia\nmodelodt = DecisionTreeClassifier(criterion='entropy', splitter='random')\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelodt.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y_teste, y_previsao)","43cb9447":"# 1. Adicione um Dataset chamado \"Heart Disease UCI\" clicando no menu em  `+ Add Dataset`\n# 2. Importe os dados do heart.csv num dataframe chamado \"doenca\" e imprima suas primeiras linhas\ndoenca = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\n# 3. Crie uma vari\u00e1vel x com os atributos 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','exang','oldpeak','slope','ca','thal'\nx = doenca[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','exang','oldpeak','slope','ca','thal']]\n# 4. Crie uma vari\u00e1vel y com o 'target'\ny = doenca['target']\n# 5. Crie as vari\u00e1veis x_treino, x_teste, y_treino, y_teste, dividindo os dados entre 70% treino e 30% teste\nx_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3)\n# 6. Importe as bibliotecas de \u00c1rvore de Decis\u00e3o\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics \n# 7. Crie um modelo de \u00c1rvore de Decis\u00e3o\nmodelodt = DecisionTreeClassifier()\n# 8. Treine o modelo com \u00e1rvore de decis\u00e3o e salve na variavel chamada modelodt (use o fit)\nmodelodt = modelodt.fit(x_treino, y_treino)\n# 9. Aplique o modelo treinado no dataset de teste para prever o resultado e coloque o resultado em y_previsao (use o predict)\ny_previsao = modelodt.predict(x_teste)\n# 10. Avalie a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o (use metrics.accuracy_score)\nmetrics.accuracy_score(y_teste, y_previsao)","3685e698":"# Divis\u00e3o com Random State\nx_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3, random_state=1)\n\n# Vamos criar uma \u00e1rvore de decis\u00e3o com Random State\nmodelodt = DecisionTreeClassifier(random_state=1)\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelodt.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y_teste, y_previsao)","ee2102ff":"from sklearn.ensemble import RandomForestClassifier\n\n# Vamos criar uma Random Forest\nmodelorf = RandomForestClassifier()\n\n# Treina o modelo\nmodelorf = modelorf.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelorf.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo \nmetrics.accuracy_score(y_teste, y_previsao)","bfe8ebaf":"# Vari\u00e1veis mais importantes com RandomForest\nimport matplotlib.pyplot as plt\n\n# Cria uma serie de atributos mais importantes e ordena as s\u00e9ries\nimportances = pd.Series(data=modelorf.feature_importances_, index= x_treino.columns)\nimportances_sorted = importances.sort_values()\n\n# Desenha um gr\u00e1fico de barras\nimportances_sorted.plot(kind='barh', color='lightgreen')\nplt.title('Features Importances')\nplt.show()","c3947087":"from sklearn.ensemble import RandomForestClassifier\n\n# Random Forest\nmodelorf = RandomForestClassifier(max_depth = 6, n_estimators=100, random_state=1)\nmodelorf = modelorf.fit(x_treino, y_treino)\ny_previsao = modelorf.predict(x_teste)\nprint(metrics.accuracy_score(y_teste, y_previsao))\n\n# Extract single tree\nestimator_limited = modelorf.estimators_[5]\nestimator_limited","af191dab":"# 1. Importe as bibliotecas de Random Forest \nfrom sklearn.ensemble import RandomForestClassifier\n# 2. Crie um modelo de Random Forest\nmodelorf = RandomForestClassifier()\n# 3. Treine o modelo com Random Forest e salve na variavel chamada modelorf (use o fit)\nmodelorf = modelorf.fit(x_treino, y_treino)\n# 4. Aplique o modelo treinado no dataset de teste para prever o resultado e coloque o resultado em y_previsao (use o predict)\ny_previsao = modelorf.predict(x_teste)\n# 5. Avalie a acur\u00e1cia do modelo de RandomForest (use metrics.accuracy_score). Foi melhor, igual ou pior que o \u00c1rvores de Decis\u00e3o?\nprint(metrics.accuracy_score(y_teste, y_previsao))\n# 6. Que par\u00e2metros voc\u00ea alteraria para otimizar o modelo de Random Forest?\n# max_depth e n_estimators\n# 7. Fa\u00e7a a altera\u00e7\u00e3o de parametros para otimizar o modelo (Model Tuning) e avalie o resultado com o resultado sem Model Tuning.\nmodelorf = RandomForestClassifier(max_depth = 4, n_estimators=200)\nmodelorf = modelorf.fit(x_treino, y_treino)\ny_previsao = modelorf.predict(x_teste)\nprint(metrics.accuracy_score(y_teste, y_previsao))","b8622457":"# Propor\u00e7\u00e3o\nprint(indios.test.value_counts())\nprint(doenca.target.value_counts())","b93bb69a":"# Vamos criar uma \u00e1rvore de decis\u00e3o com classes balanceadas\nmodelodt = DecisionTreeClassifier(class_weight='balanced')\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelodt.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y_teste, y_previsao)","9be4e5ec":"# Curva ROC\nfrom sklearn.metrics import roc_auc_score  \n\nprobs = modelodt.predict_proba(x_teste)\nprobs = probs[:, 1]  \nroc_auc_score(y_teste,probs)","8ce92a6c":"# Gr\u00e1fico\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import roc_curve  \n\ny_pred_proba = modelodt.predict_proba(x_teste)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_teste,  y_pred_proba)\nauc = metrics.roc_auc_score(y_teste, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","ff1c20ff":"# Resultado da Matriz de Confus\u00e3o\nmetrics.confusion_matrix(y_teste, y_previsao)","e8842139":"# precision, sensibilidade ou precis\u00e3o: TP\/(TP+FP)\n72\/(72+15)\n\n# recall: TP\/(TP+FN)\n72\/(72+10)\n\n# f1-score: 2 * precision * recall \/ precision + recall\n(2*(72\/(72+15))*(72\/(72+10)))\/((72\/(72+15))+(72\/(72+10)))\n\n# Support: quantidade de itens classificados em cada classe\n72 + 10 # negatif\n15 + 21 # posifif","cfd4cb83":"# Resultado da Matriz de Confus\u00e3o\nprint(metrics.classification_report(y_teste, y_previsao))","3cbd2fca":"# especificidade: TN\/TN+FP\n19\/(19+17)\n\n# acur\u00e1cia: TP+TN\/TP+FN+TN+FP\n(64+19)\/(64+18+19+17)\n\n# Outra forma de imprimir a acur\u00e1cia\nmetrics.accuracy_score(y_teste, y_previsao)","23202f21":"from sklearn.tree import DecisionTreeRegressor\n# Vamos criar uma \u00e1rvore de decis\u00e3o \nmodelodt = DecisionTreeRegressor()\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelodt.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\n#metrics.accuracy_score(y_teste, y_previsao)\nprint(metrics.r2_score(y_teste, y_previsao))\n\nfrom sklearn import metrics  \nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_teste, y_previsao))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_teste, y_previsao))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_teste, y_previsao)))  \n\n# \u00c9 menor que 10% da m\u00e9dia dos valores da target?\ny.mean()","9150857f":"from sklearn.ensemble import RandomForestRegressor\n\n# Vamos criar uma Random Forest\nmodelorf = RandomForestRegressor()\n\n# Treina o modelo\nmodelorf = modelorf.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelorf.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo \n#metrics.accuracy_score(y_teste, y_previsao)\n\n# Avalia a acur\u00e1cia do modelo \nmetrics.r2_score(y_teste, y_previsao)\n\nfrom sklearn import metrics  \nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_teste, y_previsao))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_teste, y_previsao))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_teste, y_previsao)))  ","5de82184":"import pandas as pd\ndoenca = pd.read_csv('..\/input\/heart.csv')\ndoenca.head()\n\n# Escolher o alvo. Dividir os atributos (vari\u00e1veis independentes) da target (label)\nx = doenca[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','exang','oldpeak','slope','ca','thal']]\ny = doenca['target']\n\n# Divide os dados entre 70% treino e 30% teste\nfrom sklearn.model_selection import train_test_split\nx_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3)\n\n# \u00c1rvore de Decisao\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics \n\n# Vamos criar uma \u00e1rvore de decis\u00e3o \nmodelodt = DecisionTreeClassifier()\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelodt = modelodt.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelodt.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y_teste, y_previsao)","c9b868d3":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics \n\n# Vamos criar uma \u00e1rvore de decis\u00e3o \nmodelorf = RandomForestClassifier(max_depth=4, n_estimators=100, random_state=1, criterion='entropy')\n\n# Treina o modelo com \u00e1rvore de decis\u00e3o\nmodelorf = modelorf.fit(x_treino, y_treino)\n\n# Aplica o modelo treinado no dataset de teste para prever o resultado\ny_previsao = modelorf.predict(x_teste)\n\n# Avalia a acur\u00e1cia do modelo de \u00e1rvore de decis\u00e3o\nmetrics.accuracy_score(y_teste, y_previsao)","eb29d65d":"Na \u00e1rvore de decis\u00e3o o n\u00f3 raiz em conjunto com os n\u00f3s de decis\u00e3o representam os atributos (ou vari\u00e1veis) e cada n\u00f3 de t\u00e9rmino representa uma sa\u00edda. Sua estrutura em \u00e1rvore facilita o entendimento, a interpreta\u00e7\u00e3o e a l\u00f3gica da tomada de decis\u00e3o. Funciona da seguinte forma:\n1. Seleciona o melhor atributo para dividir os registros;\n2. Faz daquele atributo um n\u00f3 de decis\u00e3o e divide o dataset em conjuntos menores de dados (subsets)\n3. Repete este processo de forma recursiva at\u00e9 que n\u00e3o exista mais atributos para dividir, ou n\u00e3o exista mais registros, ou todos os registros perten\u00e7am ao mesmo atributo;","198b2ad7":"## Regress\u00e3o com Random Forest","32d9acd5":"## Regress\u00e3o com \u00c1rvore de Decis\u00e3o\nUsa Mean Squared Error para fazer as divis\u00f5es da \u00e1rvore, e n\u00e3o a entropia ou Gini.","08430002":"### 6. Caracter\u00edsticas da \u00c1rvore","e8bad22c":"## Conclus\u00e3o\nVantagens:\n* \u00c1rvores de Decis\u00e3o s\u00e3o f\u00e1ceis de interpretar e visualizar\n* Pode capturar facilmente com padr\u00f5es n\u00e3o-lineares\n* Requer menor pr\u00e9-processamento dos dados, n\u00e3o precisamos normalizar as colunas\n* Pode ser usado para prever missing values\n\nDesvantagens:\n* Sens\u00edvel a outliers, pode sofrer overfitting facilmente\n* Na \u00e1rvore de decis\u00e3o, uma pequena variancia pode resultar em diferentes \u00e1rvores. Este problema pode ser reduzido com o uso de Random Forest.\n* Podem ser enviesadas por datasets desbalanceados. Este problema pode ser resolvido com o balanceamento dos datasets.","d4dc9e9d":"### 3. Model Tuning ou Otimiza\u00e7\u00e3o do Modelo\n* **n_estimators:** quantidade de \u00e1rvores de decis\u00e3o\n* **max_depth:** profundidade da \u00e1rvore de decis\u00e3o","c74777ed":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSjLta8fwnUGWIOdujZ4ADLSoHStF0ZPMQWBMHLdnfF9A5d171Wqg)","d6f117a2":"![](https:\/\/assets.almanaquesos.com\/wp-content\/uploads\/2012\/05\/541190_267646449990606_165232073565378_577645_1319247076_n.jpg)","7c189ba4":"### 2. An\u00e1lise Explorat\u00f3ria","be05bc20":"## Random x Reprodutibilidade","306312aa":"### 1. Criar Modelo de Random Forest","250a2c99":"Num dataset com 50 fotos de gatos e 50 fotos n\u00e3o s\u00e3o de gatos, total de 100. A soma de todos os valores \u00e9 o tamanho de y = 100.\n\n* **sensibilidade ou precis\u00e3o:** s\u00e3o os verdadeiros positivos classificados corretamente. Dentre todas as classifica\u00e7\u00f5es de classe Positivo que o modelo fez, quantas est\u00e3o corretas. A precis\u00e3o pode ser usada em uma situa\u00e7\u00e3o em que os Falsos Positivos s\u00e3o considerados mais prejudiciais que os Falsos Negativos. 25\/50\n* **especificidade:** s\u00e3o os casos negativos identificados corretamente. 40\/50\n* **acur\u00e1cia:** s\u00e3o os casos verdadeiros previstos corretamente. Indica uma performance geral do modelo. Dentre todas as classifica\u00e7\u00f5es, quantas o modelo classificou corretamente. 65\/100\n* **recall:** dentre todas as situa\u00e7\u00f5es de classe Positivo como valor esperado, quantas est\u00e3o corretas. O recall pode ser usada em uma situa\u00e7\u00e3o em que os Falsos Negativos s\u00e3o considerados mais prejudiciais que os Falsos Positivos. 25\/35\n* **f1-score:** m\u00e9dia harm\u00f4nica entre precis\u00e3o e recall. ","bfa2e604":"## Matriz de Confus\u00e3o\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*s0aMRNsHq7A3bCA9gX_qXQ.png)","b13bfd3b":"## Voc\u00ea consegue descobrir se uma pessoa vai ter diabetes?\nTemos um conjunto de dados com 8 caracter\u00edsticas de pessoas ind\u00edgenas e um resultado que mostra quais tiveram diabetes.\n1. Modelo de \u00c1rvore de Decis\u00e3o\n2. An\u00e1lise Explorat\u00f3ria\n3. Correla\u00e7\u00e3o\n4. Divis\u00e3o do Dataset\n5. Cria\u00e7\u00e3o do Modelo de \u00c1rvore de Decis\u00e3o\n6. Caracter\u00edsticas da \u00c1rvore\n7. Import\u00e2ncia das Vari\u00e1veis\n8. Model Tuning: Poda da \u00c1Rvore\n9. Model Tuning: Crit\u00e9rio de Divis\u00e3o \n10. Exerc\u00eddio de \u00c1rvore de Decis\u00e3o","4013aeec":"### 4. Exerc\u00edcio de Random Forest\nVamos descobrir se um paciente ter\u00e1 doen\u00e7as do cora\u00e7\u00e3o com o Random Forest e comparar o resultado com a \u00c1rvore de Decis\u00e3o do Exerc\u00edcio anterior.","efac381f":"### 7. Import\u00e2ncia das Vari\u00e1veis","74bc5989":"## Balanceamento de Classes\nQuando um lado \u00e9 bem maior do que o outro. Um dataset \u00e9 considerado desbalanceado se uma categoria \u00e9 muito mais expressiva do que a outra. Uma \u00e1rvore pode se considerada enviesada se tiver classes desbalanceadas. Neste caso, \u00e9 recomend\u00e1vel balancear as classes antes de criar o modelo. \n![](https:\/\/classeval.files.wordpress.com\/2015\/06\/balanced-or-imbalanced.png?w=450&h=213)","2b68fda6":"### 2. Import\u00e2ncia das Vari\u00e1veis com RandomForest","eb10994c":"### 3. Correla\u00e7\u00e3o","2099d7f1":"### 9. Model Tuning: Crit\u00e9rio de Divis\u00e3o - Como Selecionar o Melhor Atributo\nA medida de sele\u00e7\u00e3o de atributo ou Attribute Selection Measures - ASM \u00e9 aplicada para realizar a sele\u00e7\u00e3o de melhor atributo, usada para dividir os registros do dataset. Esta medida de sele\u00e7\u00e3o de atributo faz um ranking de cada vari\u00e1vel que explica a sua import\u00e2ncia para explicar um dataset. As vari\u00e1veis de melhor score ser\u00e3o selecionadas como n\u00f3s de decis\u00e3o ou atributos de divis\u00e3o. escolhe a medida de sele\u00e7\u00e3o de atributo. Pode ser `gini` para o Gini Index, ou `entropy` para Information Gain. O default \u00e9 `gini`.\n* **Information Gain:** a entropia mede a impureza dos dados de entrada. Information gain busca diminuir a entropia e mede a diferen\u00e7a entre a entropia antes e depois da divis\u00e3o do dataset baseado em determinados valores de atributos. Esta medida prefere atributos com uma grande variedade de valores distintos, o que pode levar a um resultado enviesado. Por exemplo: campo ID com uma sequencia num\u00e9rica. Para aplicar: `criterion = 'entropy'`. Entropia de 0 significa nenhuma impureza, todos os registros s\u00e3o da mesma classe. Ou seja, quanto mais pr\u00f3ximo de zero, melhor.\n* **Gini Index:** usa a probabilidade de um registro pertencer \u00e0 uma classe para dividir os registros. Considera um divis\u00e3o bin\u00e1ria para cada atributo. No caso de vari\u00e1veis categ\u00f3ricas, o subconjunto de dados que tiver o menor gini index \u00e9 selecionado como atributo de divis\u00e3o. Para o caso de vari\u00e1veis cont\u00ednuas, a estrat\u00e9gia \u00e9 selecionar cada par de valores adjacentes como poss\u00edvel ponto de divis\u00e3o e o ponto com o menor gini index \u00e9 escolhido como ponto de divis\u00e3o. Vai de 0 a 1. \u00c9 usada para avaliar a separa\u00e7\u00e3o dos dados entre as classes. Seu valor indica o qu\u00e3o boa foi a separa\u00e7\u00e3o das classes entre dois grupos. Uma separa\u00e7\u00e3o perfeita resulta num Gini de 0. Enquanto que o pior caso resulta num valor de 0.5. \u00c9 o valor default. Para aplicar: `criterion = 'gini'`.\n\nOutro par\u00e2metro \u00e9 a estrat\u00e9gia de divis\u00e3o:\n* **splitter:** escolhe a estrat\u00e9gia de divis\u00e3o, que pode ser `best` ou `random`. O default \u00e9 `best`.","8e99ffe9":"### 4. Divis\u00e3o do Dataset entre Treino e Teste","c7326b04":"### 8. Model Tuning: Poda da \u00c1rvore\n* **max_depth:** limita a profundidade m\u00e1xima da \u00e1rvore, ou seja, poda a \u00e1rvore. O valor pode ser um n\u00famero inteiro que representa a profundidade da \u00e1rvore ou `None` para nenhum. O valor padr\u00e3o \u00e9 `None`, o qual ir\u00e1 expandir ao m\u00e1ximo. Quanto maior a profundidade, maior o overfitting. Quanto menor a profundidade, maior o underfitting.","bb768029":"Os n\u00f3s em azul s\u00e3o os casos positivos. Os n\u00f3s laranja s\u00e3o os casos negativos. Gini \u00e9 a probabilidade de pertencer \u00e0 classe. Samples \u00e9 a quantidade de registros em cada n\u00f3.","442db25f":"### 10. Exerc\u00edcio de \u00c1rvore de Decis\u00e3o\nVamos descobrir se um paciente ter\u00e1 doen\u00e7as do cora\u00e7\u00e3o.","9cd0c1ea":"---\n# Exerc\u00edcios Complementares:\n1. [Criar modelo de \u00c1rvores de Decis\u00e3o (Decision Trees)](https:\/\/www.kaggle.com\/kernels\/fork\/400771)\n2. [Avaliar o modelo de \u00c1rvore de Decis\u00e3o (Decision Trees)](https:\/\/www.kaggle.com\/kernels\/fork\/1259097)\n3. [Underfitting e Overfitting](https:\/\/www.kaggle.com\/kernels\/fork\/1259126)\n4. [Random Forest](https:\/\/www.kaggle.com\/kernels\/fork\/1259186)\n\n### Pr\u00f3xima Aula:\n[Support Vector Machines - SVM](https:\/\/www.kaggle.com\/debkings\/6-m-quinas-de-suporte-de-vetores-svm)","8c332af8":"![](https:\/\/raw.githubusercontent.com\/rafjaa\/machine_learning_fecib\/master\/src\/static\/img\/resampling.png)","6357ea74":"### 1. Modelo de \u00c1rvore de Decis\u00e3o \n","eaba5cbf":"---\n# Random Forest\nRandom Forest ou \u00c1rvores Aleat\u00f3rias \u00e9 um m\u00e9todo de aprendizado de m\u00e1quina supervisionado que aplica \u00e1rvores de decis\u00e3o em v\u00e1rios subconjuntos dos dados, criando uma floresta aleat\u00f3ria, onde seu resultado tem a maioria dos valores dos modelos das \u00e1rvores de decis\u00e3o geradas. A m\u00e9trica de valida\u00e7\u00e3o \u00e9 medida pela m\u00e9dia da m\u00e9trica das \u00e1rvores de decis\u00e3o. Random Forest reduz a vari\u00e2ncia. \n\n1. Criar Modelo de Random Forest\n2. Import\u00e2ncia das Vari\u00e1veis com Random Forest\n3. Model Tuning de Random Forest\n4. Exerc\u00edcio de Random Forest","9cbc2abd":"### 5. Cria\u00e7\u00e3o do Modelo de \u00c1rvore de Decis\u00e3o","d4907880":"## Curva ROC \nAvalia a performance do algoritmo, muito usado principalmente no caso de dataset desbalanceado. A ROC mostra o qu\u00e3o bom o modelo criado pode distinguir entre duas coisas (j\u00e1 que \u00e9 utilizado para classifica\u00e7\u00e3o). Essas duas coisas pode ser 0 ou 1, ou positivo e negativo. AUC - Area Under the ROC Curve nada mais \u00e9 que a \u201c\u00e1rea sob a curva\u201d. O valor do AUC varia de 0,0 at\u00e9 1,0 e o limiar entre a classe \u00e9 0,5. Ou seja, acima desse limite, o algoritmo classifica em uma classe e abaixo na outra classe. Quanto maior o AUC, melhor. Quanto mais pr\u00f3ximo de 1.0 melhor. ","a5d2e34e":"--- \n### Resposta dos Exerc\u00edcios","0a613b6f":"**[Voltar para a P\u00e1gina Inicial do Curso](https:\/\/www.kaggle.com\/c\/ml-em-python)**\n\n# **\u00c1rvore de Decis\u00e3o**\nAntes de entrarmos no assunto de Random Forest, precisamos conhecer as \u00c1rvores de Decis\u00e3o ou Decision Trees. \n![N\u00f3s e Divis\u00f5es](https:\/\/i1.wp.com\/www.vooo.pro\/insights\/wp-content\/uploads\/2016\/12\/RDS-Vooo_insights-Tutorial_arvore_de_decisao_02.jpg?resize=640%2C371&ssl=1)"}}