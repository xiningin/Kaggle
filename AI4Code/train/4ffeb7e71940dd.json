{"cell_type":{"fe17d3a5":"code","35873459":"code","722c6572":"code","d3b5bc04":"code","dbdbba30":"code","dd189da6":"code","ec3fafe2":"code","f5416e68":"code","4a1f7696":"code","545d7c93":"code","2f40fdec":"code","b2ce2c22":"code","52c0a0ac":"code","a53d8f8a":"code","99fcd6eb":"code","52466b93":"code","40c8c536":"code","cace1a73":"code","49eb582f":"code","2f5d2cf8":"code","290bf6ee":"code","25a267fa":"code","8b02a487":"code","4f143f4d":"code","10572696":"code","086b5554":"code","d503aa02":"code","1fd5192c":"code","bd25cab0":"code","29c33b01":"code","0a2d57ec":"code","f342f380":"code","834ef101":"code","73da17d3":"code","4b8a1eb7":"code","ea317195":"markdown","e6b590ee":"markdown","40ed9abd":"markdown","69d8687d":"markdown","f1b78fce":"markdown","b88f9995":"markdown","e9d4723e":"markdown","9556b857":"markdown","a554c4c5":"markdown","71c26642":"markdown"},"source":{"fe17d3a5":"import pandas as pd\nfrom pandas import DataFrame\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","35873459":"ercot = pd.read_csv('..\/input\/wids-datathon-sri\/ercot_hourly_load.csv')\nweather_history = pd.read_csv('..\/input\/wids-datathon-sri\/weather_history.csv')\nweather_forecast = pd.read_csv('..\/input\/wids-datathon-sri\/weather_forecast.csv')\ncovid_confirmed = pd.read_csv('..\/input\/wids-datathon-sri\/texas_covid_confirmed.csv')\ncovid_deaths = pd.read_csv('..\/input\/wids-datathon-sri\/texas_covid_deaths.csv')\nsamplefile = pd.read_csv('..\/input\/wids-datathon-sri\/sampleSubmission.csv')","722c6572":"# Adding the time column from submission file to prep both train and test dataset together\nercot = pd.concat([ercot,samplefile],ignore_index= True)","d3b5bc04":"ercot['Time'] = pd.to_datetime(ercot.Hour_Ending, utc=True)\n\n#Splitting the date columns to make it easier too merge with other data sources\nercot['Year'] = ercot.Time.dt.year\nercot['Month'] = ercot.Time.dt.month\nercot['Date'] = ercot.Time.dt.date\n\nercot['Quarter'] = 0\n\nercot.loc[(ercot['Month'] <= 3),'Quarter'] = 'Q1'\nercot.loc[(ercot['Month'] > 3)&(ercot['Month'] <= 6),'Quarter'] = 'Q2'\nercot.loc[(ercot['Month'] > 6)&(ercot['Month'] <= 9),'Quarter'] = 'Q3'\nercot.loc[(ercot['Month'] > 9),'Quarter'] = 'Q4'","dbdbba30":"# Adding suffixes to keep the county names different\ncovid_deaths = covid_deaths.add_suffix('_covid_deaths')\ncovid_confirmed = covid_confirmed.add_suffix('_covid_confirmed')","dd189da6":"# converting date to datetime objects\ncovid_confirmed.Date_covid_confirmed = pd.to_datetime(covid_confirmed.Date_covid_confirmed).dt.date\ncovid_deaths.Date_covid_deaths = pd.to_datetime(covid_deaths.Date_covid_deaths).dt.date","ec3fafe2":"ercot = ercot.merge(covid_deaths, left_on = 'Date', right_on='Date_covid_deaths', how = 'left')\nercot = ercot.merge(covid_confirmed, left_on = 'Date', right_on='Date_covid_confirmed', how = 'left')","f5416e68":"weather = pd.concat([weather_history,weather_forecast],ignore_index= True)\n\nweather['zone'] = weather.city.map({'Abilene':'West', 'Austin':'South Central', 'Brownsville':'South', 'Corpus Christi':'South',\n                           'Dallas':'North Central', 'Houston':'Coast','Midland':'Far West', 'San Antonio':'South Central',\n                           'Tyler':'East', 'Wichita Falls':'North'})\n\nweather.drop(['time','city'],axis = 1,inplace = True)","4a1f7696":"# Population of the counties\npopulation = pd.read_csv('..\/input\/wids-datathon-sri\/population_total.csv')\n\n# Average salaries\nsalaries  = pd.read_csv('..\/input\/wids-datathon-sri\/average_salaries_census.csv')\n\n# Job counts\njobs = pd.read_csv('..\/input\/wids-datathon-sri\/job_counts_census.csv')\n\n# Electricity prices\nkwhr = pd.read_csv('..\/input\/wids-datathon-sri\/average electricity prices.csv')\n","545d7c93":"# merge with average kwhr prices df\nercot = ercot.merge(kwhr, on = 'Year',how = 'left')\n\nercot.Year = ercot.Year.astype(str)+ercot.Quarter","2f40fdec":"# Merge population, total jobs, and average salaries to one df\n\ncombined_df = jobs.merge(salaries,how = 'left')\ncombined_df = combined_df.merge(population,how = 'left')","b2ce2c22":"# Based on the counties file lets divide the\nCoast = [\"Austin\",\"Brazoria\",\"Calhoun\",\"Chambers\",\"Colorado\",\"Fort Bend\",\"Galveston\",\"Goliad\",\"Grimes\",\"Hardin\",\"Harris\",\"Jackson\",\"Jasper\",\"Jefferson\",\"Liberty\",\"Matagorda\",\"Montgomery\",\"Newton\",\"Orange\",\"Polk\",\"San Jacinto\",\"Tyler\",\"Victoria\",\"Waller\",\"Wharton\"]\nEast = [\"Anderson\",\"Angelina\",\"Brazos\",\"Camp\",\"Cass\",\"Cherokee\",\"Falls\",\"Franklin\",\"Freestone\",\"Gregg\",\"Grimes\",\"Harrison\",\"Henderson\",\"Hopkins\",\"Houston\",\"Hunt\",\"Jasper\",\"Kaufman\",\"Leon\",\"Limestone\",\"Madison\",\"Marion\",\"Miller\",\"Montgomery\",\"Morris\",\"Nacogdoches\",\"Navarro\",\"Newton\",\"Panola\",\"Rains\",\"Robertson\",\"Rusk\",\"Sabine\",\"San Augustine\",\"Shelby\",\"Smith\",\"Titus\",\"Trinity\",\"Upshur\",\"Van Zandt\",\"Walker\",\"Waller\",\"Washington\",\"Wood\"]    \nFar_West =  [\"Andrews\",\"Borden\",\"Brewster\",\"Crane\",\"Crockett\",\"Culberson\",\"Dawson\",\"Ector\",\"El Paso\",\"Gaines\",\"Glasscock\",\"Howard\",\"Hudspeth\",\"Jeff Davis\",\"Loving\",\"Lynn\",\"Martin\",\"Midland\",\"Otero\",\"Pecos\",\"Presidio\",\"Reagan\",\"Reeves\",\"Terrell\",\"Upton\",\"Val Verde\",\"Ward\",\"Winkler\"    ]\nNorth = [\"Archer\",\"Armstrong\",\"Baylor\",\"Bowie\",\"Briscoe\",\"Childress\",\"Clay\",\"Collin\",\"Collingsworth\",\"Cooke\",\"Cottle\",\"Crosby\",\"Denton\",\"Dickens\",\"Donley\",\"Fannin\",\"Floyd\",\"Foard\",\"Grayson\",\"Hall\",\"Hardeman\",\"Haskell\",\"Hemphill\",\"Hunt\",\"Jack\",\"Kent\",\"King\",\"Knox\",\"Lamar\",\"Lubbock\",\"Montague\",\"Motley\",\"Red River\",\"Stonewall\",\"Wheeler\",\"Wichita\",\"Wilbarger\",\"Wise\"    ]  \nNorth_Central = [\"Archer\",\"Bell\",\"Bosque\",\"Brown\",\"Burnet\",\"Callahan\",\"Coleman\",\"Collin\",\"Comanche\",\"Cooke\",\"Coryell\",\"Dallas\",\"Delta\",\"Denton\",\"Eastland\",\"Ellis\",\"Erath\",\"Falls\",\"Fannin\",\"Freestone\",\"Grayson\",\"Hamilton\",\"Henderson\",\"Hill\",\"Hood\",\"Hopkins\",\"Hunt\",\"Jack\",\"Johnson\",\"Kaufman\",\"Lampasas\",\"Limestone\",\"McLennan\",\"Milam\",\"Mills\",\"Navarro\",\"Palo Pinto\",\"Parker\",\"Rains\",\"Robertson\",\"Rockwall\",\"Shackelford\",\"Somervell\",\"Stephens\",\"Tarrant\",\"Throckmorton\",\"Van Zandt\",\"Williamson\",\"Wise\",\"Young\"]\nSouth = [\"Aransas\",\"Atascosa\",\"Bee\",\"Bexar\",\"Brooks\",\"Calhoun\",\"Cameron\",\"Dimmit\",\"Duval\",\"Frio\",\"Goliad\",\"Hidalgo\",\"Jim Hogg\",\"Jim Wells\",\"Kenedy\",\"Kleberg\",\"La Salle\",\"Live Oak\",\"Maverick\",\"McMullen\",\"Medina\",\"Nueces\",\"Refugio\",\"San Patricio\",\"Starr\",\"Webb\",\"Willacy\",\"Wilson\",\"Zapata\",\"Zavala\"    ]\nSouth_Central = [\"Atascosa\",\"Austin\",\"Bandera\",\"Bastrop\",\"Bee\",\"Bell\",\"Bexar\",\"Blanco\",\"Burleson\",\"Burnet\",\"Caldwell\",\"Colorado\",\"Comal\",\"DeWitt\",\"Falls\",\"Fayette\",\"Frio\",\"Goliad\",\"Gonzales\",\"Guadalupe\",\"Hays\",\"Karnes\",\"Kendall\",\"Kerr\",\"Lavaca\",\"Lee\",\"Live Oak\",\"Llano\",\"Medina\",\"Milam\",\"Real\",\"Travis\",\"Victoria\",\"Washington\",\"Williamson\",\"Wilson\"    ]\nWest = [\"Bandera\",\"Bell\",\"Blanco\",\"Borden\",\"Burnet\",\"Callahan\",\"Coke\",\"Coleman\",\"Concho\",\"Coryell\",\"Edwards\",\"Fisher\",\"Gillespie\",\"Haskell\",\"Irion\",\"Jones\",\"Kendall\",\"Kent\",\"Kerr\",\"Kimble\",\"Kinney\",\"Lampasas\",\"Llano\",\"Mason\",\"McCulloch\",\"Medina\",\"Menard\",\"Mills\",\"Mitchell\",\"Nolan\",\"Real\",\"Runnels\",\"San Saba\",\"Schleicher\",\"Scurry\",\"Shackelford\",\"Sterling\",\"Stonewall\",\"Sutton\",\"Taylor\",\"Throckmorton\",\"Tom Green\",\"Uvalde\",\"Val Verde\"]\n","52c0a0ac":"cst = ['Year']\nfor county in Coast:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        cst.append(item)\n\nest = ['Year']\nfor county in East:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        est.append(item)\n        \nfwst = ['Year']\nfor county in Far_West:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        fwst.append(item)\n\nnor = ['Year']\nfor county in North:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        nor.append(item)\n\nnorct = ['Year']\nfor county in North_Central:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        norct.append(item)\n        \nsou = ['Year']\nfor county in South:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        sou.append(item)\n        \nsouct = ['Year']\nfor county in South_Central:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        souct.append(item)\n\nwst = ['Year']\nfor county in West:\n    match = [s for s in combined_df.columns if county in s]\n    for item in match:\n        wst.append(item)","a53d8f8a":"# Zone wise dataframes created\nercot_coast = ercot.drop(['East', 'Far West', 'North', 'North Central','South', 'South Central', 'West'],axis = 1).merge(combined_df[cst], how = 'left' )\nercot_east = ercot.drop(['Coast','Far West', 'North', 'North Central','South', 'South Central', 'West'],axis = 1).merge(combined_df[est], how = 'left' )\nercot_far_west = ercot.drop(['Coast', 'East','North', 'North Central','South', 'South Central', 'West'],axis = 1).merge(combined_df[fwst], how = 'left' )\nercot_north = ercot.drop(['Coast', 'East', 'Far West', 'North Central','South', 'South Central', 'West'],axis = 1).merge(combined_df[nor], how = 'left' )\nercot_north_central = ercot.drop(['Coast', 'East', 'Far West', 'North', 'South', 'South Central', 'West'],axis = 1).merge(combined_df[norct], how = 'left' )\nercot_south = ercot.drop(['Coast', 'East', 'Far West', 'North', 'North Central','South Central', 'West'],axis = 1).merge(combined_df[sou], how = 'left' )\nercot_south_central = ercot.drop(['Coast', 'East', 'Far West', 'North', 'North Central','South', 'West'],axis = 1).merge(combined_df[souct], how = 'left' )\nercot_west = ercot.drop(['Coast', 'East', 'Far West', 'North', 'North Central','South', 'South Central'],axis = 1).merge(combined_df[wst], how = 'left' )","99fcd6eb":"# Zone wise dataframes created for weather dataset\nweather_coast = weather[weather.zone == 'Coast'].groupby('date').mean().reset_index()\nweather_east = weather[weather.zone == 'East'].groupby('date').mean().reset_index()\nweather_far_west = weather[weather.zone == 'Far West'].groupby('date').mean().reset_index()\nweather_north = weather[weather.zone == 'North'].groupby('date').mean().reset_index()\nweather_north_central = weather[weather.zone == 'North Central'].groupby('date').mean().reset_index()\nweather_south = weather[weather.zone == 'South'].groupby('date').mean().reset_index()\nweather_south_central = weather[weather.zone == 'South Central'].groupby('date').mean().reset_index()\nweather_west = weather[weather.zone == 'West'].groupby('date').mean().reset_index()\n\n# Converting to datetime format\nweather_coast.date = pd.to_datetime(weather_coast.date, utc=True).dt.date\nweather_east.date = pd.to_datetime(weather_east.date, utc=True).dt.date\nweather_far_west.date = pd.to_datetime(weather_coast.date, utc=True).dt.date\nweather_north.date = pd.to_datetime(weather_north.date, utc=True).dt.date\nweather_north_central.date = pd.to_datetime(weather_north_central.date, utc=True).dt.date\nweather_south.date = pd.to_datetime(weather_south.date, utc=True).dt.date\nweather_south_central.date = pd.to_datetime(weather_south_central.date, utc=True).dt.date\nweather_west.date = pd.to_datetime(weather_west.date, utc=True).dt.date","52466b93":"# Merge zone-wise dfs with weather dataset.\nercot_coast = ercot_coast.merge(weather_coast, left_on='Date', right_on='date',how = 'left')\nercot_east = ercot_east.merge(weather_east, left_on='Date', right_on='date',how = 'left')\nercot_far_west = ercot_far_west.merge(weather_far_west, left_on='Date', right_on='date',how = 'left')\nercot_north = ercot_north.merge(weather_north, left_on='Date', right_on='date',how = 'left')\nercot_north_central = ercot_north_central.merge(weather_north_central, left_on='Date', right_on='date',how = 'left')\nercot_south = ercot_south.merge(weather_south, left_on='Date', right_on='date',how = 'left')\nercot_south_central = ercot_south_central.merge(weather_south_central, left_on='Date', right_on='date',how = 'left')\nercot_west = ercot_west.merge(weather_west, left_on='Date', right_on='date',how = 'left')","40c8c536":"# Drop the repetitive columns\nercot_coast.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_east.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_far_west.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_north.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_north_central.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_south.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_south_central.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)\nercot_west.drop(['Date', 'Quarter', 'Date_covid_deaths','State','date','Date_covid_confirmed','chanceofrain','chanceofwindy','chanceofovercast','chanceofsunshine','chanceoffrost','chanceoffog','chanceofsnow','chanceofthunder','chanceofhightemp','chanceofremdry'], axis = 1, inplace = True)","cace1a73":"# ercot_coast\ncovid_deaths = ercot_coast.columns[ercot_coast.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_coast.columns[ercot_coast.columns.str.contains('_covid_confirmed')]\npopulation = ercot_coast.columns[ercot_coast.columns.str.contains('_population')]\nsalaries = ercot_coast.columns[ercot_coast.columns.str.contains('_salaries')]\njobs = ercot_coast.columns[ercot_coast.columns.str.contains('_jobs')]\n\nercot_coast['covid_deaths'] = ercot_coast[covid_deaths].mean(axis = 1)\nercot_coast['covid_confirmed'] = ercot_coast[covid_confirmed].mean(axis = 1)\nercot_coast['population'] = ercot_coast[population].mean(axis = 1)\nercot_coast['salaries'] = ercot_coast[salaries].mean(axis = 1)\nercot_coast['jobs'] = ercot_coast[jobs].mean(axis = 1)\n\nercot_coast.drop(covid_deaths, axis = 1, inplace = True)\nercot_coast.drop(covid_confirmed, axis = 1, inplace = True)\nercot_coast.drop(population, axis = 1, inplace = True)\nercot_coast.drop(salaries, axis = 1, inplace = True)\nercot_coast.drop(jobs, axis = 1, inplace = True)","49eb582f":"# ercot_east\ncovid_deaths = ercot_east.columns[ercot_east.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_east.columns[ercot_east.columns.str.contains('_covid_confirmed')]\npopulation = ercot_east.columns[ercot_east.columns.str.contains('_population')]\nsalaries = ercot_east.columns[ercot_east.columns.str.contains('_salaries')]\njobs = ercot_east.columns[ercot_east.columns.str.contains('_jobs')]\n\nercot_east['covid_deaths'] = ercot_east[covid_deaths].mean(axis = 1)\nercot_east['covid_confirmed'] = ercot_east[covid_confirmed].mean(axis = 1)\nercot_east['population'] = ercot_east[population].mean(axis = 1)\nercot_east['salaries'] = ercot_east[salaries].mean(axis = 1)\nercot_east['jobs'] = ercot_east[jobs].mean(axis = 1)\n\nercot_east.drop(covid_deaths, axis = 1, inplace = True)\nercot_east.drop(covid_confirmed, axis = 1, inplace = True)\nercot_east.drop(population, axis = 1, inplace = True)\nercot_east.drop(salaries, axis = 1, inplace = True)\nercot_east.drop(jobs, axis = 1, inplace = True)","2f5d2cf8":"# ercot_far_west\ncovid_deaths = ercot_far_west.columns[ercot_far_west.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_far_west.columns[ercot_far_west.columns.str.contains('_covid_confirmed')]\npopulation = ercot_far_west.columns[ercot_far_west.columns.str.contains('_population')]\nsalaries = ercot_far_west.columns[ercot_far_west.columns.str.contains('_salaries')]\njobs = ercot_far_west.columns[ercot_far_west.columns.str.contains('_jobs')]\n\nercot_far_west['covid_deaths'] = ercot_far_west[covid_deaths].mean(axis = 1)\nercot_far_west['covid_confirmed'] = ercot_far_west[covid_confirmed].mean(axis = 1)\nercot_far_west['population'] = ercot_far_west[population].mean(axis = 1)\nercot_far_west['salaries'] = ercot_far_west[salaries].mean(axis = 1)\nercot_far_west['jobs'] = ercot_far_west[jobs].mean(axis = 1)\n\nercot_far_west.drop(covid_deaths, axis = 1, inplace = True)\nercot_far_west.drop(covid_confirmed, axis = 1, inplace = True)\nercot_far_west.drop(population, axis = 1, inplace = True)\nercot_far_west.drop(salaries, axis = 1, inplace = True)\nercot_far_west.drop(jobs, axis = 1, inplace = True)","290bf6ee":"# ercot_north\ncovid_deaths = ercot_north.columns[ercot_north.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_north.columns[ercot_north.columns.str.contains('_covid_confirmed')]\npopulation = ercot_north.columns[ercot_north.columns.str.contains('_population')]\nsalaries = ercot_north.columns[ercot_north.columns.str.contains('_salaries')]\njobs = ercot_north.columns[ercot_north.columns.str.contains('_jobs')]\n\nercot_north['covid_deaths'] = ercot_north[covid_deaths].mean(axis = 1)\nercot_north['covid_confirmed'] = ercot_north[covid_confirmed].mean(axis = 1)\nercot_north['population'] = ercot_north[population].mean(axis = 1)\nercot_north['salaries'] = ercot_north[salaries].mean(axis = 1)\nercot_north['jobs'] = ercot_north[jobs].mean(axis = 1)\n\nercot_north.drop(covid_deaths, axis = 1, inplace = True)\nercot_north.drop(covid_confirmed, axis = 1, inplace = True)\nercot_north.drop(population, axis = 1, inplace = True)\nercot_north.drop(salaries, axis = 1, inplace = True)\nercot_north.drop(jobs, axis = 1, inplace = True)","25a267fa":"# ercot_north_central\ncovid_deaths = ercot_north_central.columns[ercot_north_central.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_north_central.columns[ercot_north_central.columns.str.contains('_covid_confirmed')]\npopulation = ercot_north_central.columns[ercot_north_central.columns.str.contains('_population')]\nsalaries = ercot_north_central.columns[ercot_north_central.columns.str.contains('_salaries')]\njobs = ercot_north_central.columns[ercot_north_central.columns.str.contains('_jobs')]\n\nercot_north_central['covid_deaths'] = ercot_north_central[covid_deaths].mean(axis = 1)\nercot_north_central['covid_confirmed'] = ercot_north_central[covid_confirmed].mean(axis = 1)\nercot_north_central['population'] = ercot_north_central[population].mean(axis = 1)\nercot_north_central['salaries'] = ercot_north_central[salaries].mean(axis = 1)\nercot_north_central['jobs'] = ercot_north_central[jobs].mean(axis = 1)\n\nercot_north_central.drop(covid_deaths, axis = 1, inplace = True)\nercot_north_central.drop(covid_confirmed, axis = 1, inplace = True)\nercot_north_central.drop(population, axis = 1, inplace = True)\nercot_north_central.drop(salaries, axis = 1, inplace = True)\nercot_north_central.drop(jobs, axis = 1, inplace = True)","8b02a487":"# ercot_south\ncovid_deaths = ercot_south.columns[ercot_south.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_south.columns[ercot_south.columns.str.contains('_covid_confirmed')]\npopulation = ercot_south.columns[ercot_south.columns.str.contains('_population')]\nsalaries = ercot_south.columns[ercot_south.columns.str.contains('_salaries')]\njobs = ercot_south.columns[ercot_south.columns.str.contains('_jobs')]\n\nercot_south['covid_deaths'] = ercot_south[covid_deaths].mean(axis = 1)\nercot_south['covid_confirmed'] = ercot_south[covid_confirmed].mean(axis = 1)\nercot_south['population'] = ercot_south[population].mean(axis = 1)\nercot_south['salaries'] = ercot_south[salaries].mean(axis = 1)\nercot_south['jobs'] = ercot_south[jobs].mean(axis = 1)\n\nercot_south.drop(covid_deaths, axis = 1, inplace = True)\nercot_south.drop(covid_confirmed, axis = 1, inplace = True)\nercot_south.drop(population, axis = 1, inplace = True)\nercot_south.drop(salaries, axis = 1, inplace = True)\nercot_south.drop(jobs, axis = 1, inplace = True)","4f143f4d":"# ercot_south_central\ncovid_deaths = ercot_south_central.columns[ercot_south_central.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_south_central.columns[ercot_south_central.columns.str.contains('_covid_confirmed')]\npopulation = ercot_south_central.columns[ercot_south_central.columns.str.contains('_population')]\nsalaries = ercot_south_central.columns[ercot_south_central.columns.str.contains('_salaries')]\njobs = ercot_south_central.columns[ercot_south_central.columns.str.contains('_jobs')]\n\nercot_south_central['covid_deaths'] = ercot_south_central[covid_deaths].mean(axis = 1)\nercot_south_central['covid_confirmed'] = ercot_south_central[covid_confirmed].mean(axis = 1)\nercot_south_central['population'] = ercot_south_central[population].mean(axis = 1)\nercot_south_central['salaries'] = ercot_south_central[salaries].mean(axis = 1)\nercot_south_central['jobs'] = ercot_south_central[jobs].mean(axis = 1)\n\nercot_south_central.drop(covid_deaths, axis = 1, inplace = True)\nercot_south_central.drop(covid_confirmed, axis = 1, inplace = True)\nercot_south_central.drop(population, axis = 1, inplace = True)\nercot_south_central.drop(salaries, axis = 1, inplace = True)\nercot_south_central.drop(jobs, axis = 1, inplace = True)","10572696":"# ercot_west\ncovid_deaths = ercot_west.columns[ercot_west.columns.str.contains('_covid_deaths')]\ncovid_confirmed = ercot_west.columns[ercot_west.columns.str.contains('_covid_confirmed')]\npopulation = ercot_west.columns[ercot_west.columns.str.contains('_population')]\nsalaries = ercot_west.columns[ercot_west.columns.str.contains('_salaries')]\njobs = ercot_west.columns[ercot_west.columns.str.contains('_jobs')]\n\nercot_west['covid_deaths'] = ercot_west[covid_deaths].mean(axis = 1)\nercot_west['covid_confirmed'] = ercot_west[covid_confirmed].mean(axis = 1)\nercot_west['population'] = ercot_west[population].mean(axis = 1)\nercot_west['salaries'] = ercot_west[salaries].mean(axis = 1)\nercot_west['jobs'] = ercot_west[jobs].mean(axis = 1)\n\nercot_west.drop(covid_deaths, axis = 1, inplace = True)\nercot_west.drop(covid_confirmed, axis = 1, inplace = True)\nercot_west.drop(population, axis = 1, inplace = True)\nercot_west.drop(salaries, axis = 1, inplace = True)\nercot_west.drop(jobs, axis = 1, inplace = True)","086b5554":"#Changing the formats of the  dates to numbers \nercot_coast.Time = ercot_coast.Time.dt.hour.astype(int)\nercot_coast.Year = ercot_coast.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_east.Time = ercot_east.Time.dt.hour.astype(int)\nercot_east.Year = ercot_east.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_north.Time = ercot_north.Time.dt.hour.astype(int)\nercot_north.Year = ercot_north.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_south.Time = ercot_south.Time.dt.hour.astype(int)\nercot_south.Year = ercot_south.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_far_west.Time = ercot_far_west.Time.dt.hour.astype(int)\nercot_far_west.Year = ercot_far_west.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_north_central.Time = ercot_north_central.Time.dt.hour.astype(int)\nercot_north_central.Year = ercot_north_central.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_south_central.Time = ercot_south_central.Time.dt.hour.astype(int)\nercot_south_central.Year = ercot_south_central.Year.str.extract('(\\d+)', expand=False).astype(int)\n\n#Changing the formats of the  dates to numbers \nercot_west.Time = ercot_west.Time.dt.hour.astype(int)\nercot_west.Year = ercot_west.Year.str.extract('(\\d+)', expand=False).astype(int)","d503aa02":"# COAST\n# Test train split\ntest = ercot_coast[ercot_coast.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['Coast','Hour_Ending'], axis = 1)\ntrain = ercot_coast.drop(ercot_coast[ercot_coast.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\nX = train.drop(['Coast','Hour_Ending'], axis = 1)\ny = train['Coast']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer),('m', model)])\n\npipeline.fit(X,y)\n\ncoast_predictions = pipeline.predict(test)","1fd5192c":"# EAST\n# Test train split\ntest = ercot_east[ercot_east.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['East','Hour_Ending'], axis = 1)\ntrain = ercot_east.drop(ercot_east[ercot_east.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['East','Hour_Ending'], axis = 1)\ny = train['East']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\neast_predictions = pipeline.predict(test)","bd25cab0":"# far_west\n# Test train split\ntest = ercot_far_west[ercot_far_west.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['Far West','Hour_Ending'], axis = 1)\ntrain = ercot_far_west.drop(ercot_far_west[ercot_far_west.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['Far West','Hour_Ending'], axis = 1)\ny = train['Far West']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\nfar_west_predictions = pipeline.predict(test)","29c33b01":"# north\n# Test train split\ntest = ercot_north[ercot_north.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['North','Hour_Ending'], axis = 1)\ntrain = ercot_north.drop(ercot_north[ercot_north.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['North','Hour_Ending'], axis = 1)\ny = train['North']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\nnorth_predictions = pipeline.predict(test)","0a2d57ec":"# north_central\n# Test train split\ntest = ercot_north_central[ercot_north_central.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['North Central','Hour_Ending'], axis = 1)\ntrain = ercot_north_central.drop(ercot_north_central[ercot_north_central.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['North Central','Hour_Ending'], axis = 1)\ny = train['North Central']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\nnorth_central_predictions = pipeline.predict(test)","f342f380":"# south\n# Test train split\ntest = ercot_south[ercot_south.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['South','Hour_Ending'], axis = 1)\ntrain = ercot_south.drop(ercot_south[ercot_south.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['South','Hour_Ending'], axis = 1)\ny = train['South']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\nsouth_predictions = pipeline.predict(test)","834ef101":"# south_central\n# Test train split\ntest = ercot_south_central[ercot_south_central.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['South Central','Hour_Ending'], axis = 1)\ntrain = ercot_south_central.drop(ercot_south_central[ercot_south_central.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['South Central','Hour_Ending'], axis = 1)\ny = train['South Central']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\nsouth_central_predictions = pipeline.predict(test)","73da17d3":"# west\n# Test train split\ntest = ercot_west[ercot_west.Hour_Ending >= '2021-06-13 01:00:00-05:00'].drop(['West','Hour_Ending'], axis = 1)\ntrain = ercot_west.drop(ercot_west[ercot_west.Hour_Ending >= '2021-06-13 01:00:00-05:00'].index)\n\n\nX = train.drop(['West','Hour_Ending'], axis = 1)\ny = train['West']\n\nfrom sklearn.preprocessing import RobustScaler\nfrom xgboost import XGBRegressor\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.pipeline import Pipeline\n\n# define model pipeline\n\nscaler = RobustScaler()\nimputer = IterativeImputer(random_state= 42, missing_values = np.nan)\nmodel = XGBRegressor(random_state=42, n_jobs=-1)\n\npipeline = Pipeline(steps=[('s',scaler),('i', imputer), ('m', model)])\n\npipeline.fit(X,y)\n\nwest_predictions = pipeline.predict(test)","4b8a1eb7":"results = pd.DataFrame(coast_predictions, samplefile.Hour_Ending, columns={'Coast'})\n\nresults['East'] = east_predictions\nresults['Far West'] = far_west_predictions\nresults['North'] = north_predictions\nresults['North Central'] = north_central_predictions\nresults['South'] = south_predictions\nresults['South Central'] = south_central_predictions\nresults['West'] = west_predictions\n\nresults.to_csv('result_submission.csv')","ea317195":"# Machine Learning model building\n\nHere, we can split the dataset into train and test(based on sample submission file) and build a model using LightGBoost algorithms.","e6b590ee":"# External Data inclusions\n1. Population of the zones - 10 year population estimates from https:\/\/demographics.texas.gov\/\n1. Try to include the average pay scales of each zone from job reports from https:\/\/ledextract.ces.census.gov\/static\/data.html\n1. Electricity price per kWhr from https:\/\/www.eia.gov\/electricity\/data\/state\/\n\nThese external datasets were slightly modified, mainly to pivot them so that the datasets are structured based on counties. Also these are linearly interpolated in order to cover missing data from 2020 and 2021.","40ed9abd":"# Feature engineering","69d8687d":"Based on the counties json file, we divided the counties into zone lists as seen below. Seperate zonewise dataframes were constructed using just the counties in that zone.","f1b78fce":"We chose to keep the County as the basis for location as most of the datasets have countywise datasets except for the weather. The weather dataset has only 10 unique cities, these were converted into weatherzones and an average value was considered for modeling.","b88f9995":"# Data provided as part of the repository\n\nAlll the csv files are read as is. The only change made was to add teh date column for the submission file. This helps in processing both the training and testing data together and providing the predictions.","e9d4723e":"# Combining the data sources from repository\nThis section, we tried to combine all the data sourcers into one dataframe. The date variable was the basis of merging all the several datasets. We choose to keep the ercot as the base dataframe as it contains the dates for the submission file. ","9556b857":"# Weather Dataset Merge","a554c4c5":"![image-3.png](attachment:image-3.png)","71c26642":"# Even after dropping, there are like over 500 columns per zone, we decided to take averages  of all the external data columns based on the counties and teh zones that they belong to."}}