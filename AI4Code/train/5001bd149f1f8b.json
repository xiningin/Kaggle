{"cell_type":{"3e75207d":"code","4d203b90":"code","d656c95e":"code","b8bc9552":"code","c82a7da8":"code","b9a9a252":"code","28119285":"code","d5c22186":"code","0e3a34eb":"code","6f6b3edf":"code","5374569e":"code","95b98b49":"code","4755aaa8":"code","e724ad0a":"code","79b90d67":"code","595700e7":"code","c050c404":"code","02ca17e4":"code","12ed35cf":"code","d5a5e01b":"code","a69a5a93":"code","f974745c":"code","b4409d7a":"code","352d53fa":"code","cb82989d":"code","5db6278a":"code","be52803c":"code","5431d89e":"code","14cd6f13":"code","3e8dab39":"code","4fe3ad5a":"code","9d3f580d":"code","501f1796":"code","b7a6bce1":"code","550042d4":"code","a68e648e":"code","f4894b8c":"code","7b226aa5":"markdown","e8220eca":"markdown","2ffa5cbd":"markdown","dda3312c":"markdown","b5b3fa08":"markdown","1cd7da36":"markdown","dbbf4fb4":"markdown","b5985ebc":"markdown","19f10679":"markdown","bde75c04":"markdown","1f17e101":"markdown","ca0a0024":"markdown","1be8834c":"markdown","2609693f":"markdown","7da452f8":"markdown","5dd53060":"markdown","4c692c23":"markdown","6be2bbbf":"markdown","b54f3aba":"markdown"},"source":{"3e75207d":"import janestreet\nimport datatable as dt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import set_config\n\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\n\nplt.style.use('bmh')\nplt.rcParams['figure.figsize'] = [16, 5]  # width, height","4d203b90":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","d656c95e":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n# modified code for group gaps; source\n# https:\/\/github.com\/getgaurav2\/scikit-learn\/blob\/d4a3af5cc9da3a76f0266932644b884c99724c57\/sklearn\/model_selection\/_split.py#L2243\nclass PurgedGroupTimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Allows for a gap in groups to avoid potentially leaking info from\n    train into test if the model has windowed or lag features.\n    Provides train\/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    max_train_group_size : int, default=Inf\n        Maximum group size for a single training set.\n    group_gap : int, default=None\n        Gap between train and test\n    max_test_group_size : int, default=Inf\n        We discard this number of groups from the end of each train split\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 max_train_group_size=np.inf,\n                 max_test_group_size=np.inf,\n                 group_gap=None,\n                 verbose=False\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_group_size = max_train_group_size\n        self.group_gap = group_gap\n        self.max_test_group_size = max_test_group_size\n        self.verbose = verbose\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train\/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        n_splits = self.n_splits\n        group_gap = self.group_gap\n        max_test_group_size = self.max_test_group_size\n        max_train_group_size = self.max_train_group_size\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_test_size = min(n_groups \/\/ n_folds, max_test_group_size)\n        group_test_starts = range(n_groups - n_splits * group_test_size,\n                                  n_groups, group_test_size)\n        for group_test_start in group_test_starts:\n            train_array = []\n            test_array = []\n\n            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n                train_array_tmp = group_dict[train_group_idx]\n                \n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n \n            for test_group_idx in unique_groups[group_test_start:\n                                                group_test_start +\n                                                group_test_size]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n\n            test_array  = test_array[group_gap:]\n            \n            \n            if self.verbose > 0:\n                    pass\n                    \n            yield [int(i) for i in train_array], [int(i) for i in test_array]","b8bc9552":"%%time\n\ntrain_data = (\n    dt.fread('..\/input\/jane-street-market-prediction\/train.csv')\n      .to_pandas()\n      .query('weight > 0')\n)","c82a7da8":"(1+(train_data.groupby('date')['resp'].mean())).cumprod().plot();\ntrain_data['weight_x_resp'] = train_data['weight']*train_data['resp']\n(1+(train_data.groupby('date')['weight_x_resp'].mean())).cumprod().plot();\nplt.legend();","b9a9a252":"plt.scatter(train_data['weight'], train_data['resp'], alpha=0.25);\nplt.xlabel('weight');\nplt.ylabel('resp');","28119285":"np.log(train_data['weight']).hist(bins=50);\nplt.xlabel('Histogram bin of ln(weight)');","d5c22186":"bins = 100","0e3a34eb":"train_data['daily_wr_bin'] = (\n    train_data.groupby('date')['weight_x_resp']\n              .apply(pd.qcut, q=bins, labels=False)\n)","6f6b3edf":"plt.scatter(train_data['daily_wr_bin'], train_data['weight_x_resp'], alpha=0.25);\nplt.axvline(bins\/\/2, linestyle='--', c='r');\nplt.xlabel('Daily Bin');\nplt.ylabel('weight_x_resp');","5374569e":"train_data['bin_resp'] = (train_data['daily_wr_bin'] > bins\/\/2).astype(int)","95b98b49":"imp_mean = SimpleImputer(strategy='mean')\nscaler = StandardScaler()\nlr = LogisticRegression(C=0.1, max_iter=1000)\n\npipe = Pipeline(steps=[\n    ('imputer', imp_mean),\n    ('scaler', scaler),\n    ('lr', lr)\n])\n\npipe","4755aaa8":"cv = PurgedGroupTimeSeriesSplit(\n    n_splits=3,\n    max_train_group_size=150,\n    group_gap=20,\n    max_test_group_size=60\n)\n","e724ad0a":"X = train_data[train_data.columns[train_data.columns.str.contains('feature')]].values\ngroups = train_data['date'].values","79b90d67":"def run_cv(pipe, X, y, cv, groups, scoring='roc_auc'):\n    cv_scores = cross_val_score(pipe, X, y, cv=cv, groups=groups, scoring=scoring)\n    print(cv_scores)\n    print(f'mean: {np.mean(cv_scores)}   std: {np.std(cv_scores)}')","595700e7":"%%time\ny = (train_data['resp']>0).astype(int).values\nrun_cv(pipe, X, y, cv=cv, groups=groups)","c050c404":"%%time\ny = train_data['bin_resp'].values\nrun_cv(pipe, X, y, cv=cv, groups=groups)","02ca17e4":"train_data.head()","12ed35cf":"train_data[['resp', 'resp_1']].plot();","d5a5e01b":"train_data[['resp', 'resp_2']].plot();","a69a5a93":"train_data[['resp', 'resp_3']].plot();","f974745c":"train_data[['resp', 'resp_4']].plot();","b4409d7a":"resps = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\nresp_stds = (train_data[resps]\n    .std()\n    .sort_values()\n);\nax = resp_stds.plot(kind='bar', title='Standard Deviation of each `resp_`')\nfor bar in ax.patches:\n    bar.set_facecolor('#aa3333')\npos = resp_stds.index.get_loc('resp')\nax.patches[pos].set_facecolor('#348ABD')","352d53fa":"train_data['resp_target'] = (train_data['resp'] > 0).astype(np.int8)\ntrain_data['resp_1_target'] = (train_data['resp_1'] > 0).astype(np.int8)\ntrain_data['resp_2_target'] = (train_data['resp_2'] > 0).astype(np.int8)\ntrain_data['resp_3_target'] = (train_data['resp_3'] > 0).astype(np.int8)\ntrain_data['resp_4_target'] = (train_data['resp_4'] > 0).astype(np.int8)\n\n# TARGET_NAMES = [\n#     'resp_target', 'resp_1_target', 'resp_2_target', 'resp_3_target' ,'resp_4_target'\n# ]\n\n# TARGET_NAMES = [\n#     'resp_target'\n# ]\n\n# I am going to train againt only two targets\nTARGET_NAMES = [\n    'resp_target', 'resp_2_target'\n]\n\nFEATURE_NAMES = train_data.columns[train_data.columns.str.contains('feature')]","cb82989d":"train_means = train_data.mean()\ntrain_data.fillna(train_means, inplace=True)","5db6278a":"import gc\ngc.collect()","be52803c":"from fastai.tabular.data import TabularDataLoaders\nfrom fastai.tabular.learner import TabularLearner\nfrom fastai.callback.schedule import fit_one_cycle, lr_find  # this is monkey patched ","5431d89e":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super().__init__()\n\n        dropouts = [0.10, 0.20, 0.25, 0.25, 0.25]\n        hidden_size = [384, 896, 896, 384]\n        \n        layers = [nn.BatchNorm1d(num_features)]\n        in_size = num_features\n\n        for i in range(len(hidden_size)):\n            out_size = hidden_size[i]\n            layers.append(nn.Dropout(dropouts[i]))\n            layers.append(nn.Linear(in_size, out_size))\n            layers.append(nn.BatchNorm1d(out_size))\n            layers.append(nn.SiLU())  # SiLU aka swish\n            in_size = out_size\n\n        layers.append(nn.Dropout(dropouts[-1]))\n        layers.append(nn.Linear(in_size, num_targets))\n        layers.append(nn.Sigmoid())\n        \n        self.model = torch.nn.Sequential(*layers)\n\n    def forward(self, cat, cont):\n        # fastai tabular passes categorical and continuous features separately\n        x = self.model(cont)\n        return x","14cd6f13":"NUM_FEATURES = len(FEATURE_NAMES)\nNUM_TARGETS = len(TARGET_NAMES)\nBATCH_SIZE = 4096\nEPOCHS = 5","3e8dab39":"# this should not be necessary IMHO, but I think there is a bug somewhere that\n# requries this to avoid. see https:\/\/forums.fast.ai\/t\/tabular-learner-error-found-dtype-char-but-expected-float\/77245\/2\ntrain_data[TARGET_NAMES] = train_data[TARGET_NAMES].astype(np.float32)","4fe3ad5a":"# get indices for the validation set\nn_samples = len(train_data)\nsplit_idx = int(n_samples*0.70)\nval_idxs = range(split_idx, n_samples)","9d3f580d":"dls = TabularDataLoaders.from_df(\n    train_data,\n    cont_names=list(FEATURE_NAMES),\n    y_names=TARGET_NAMES,\n    bs=BATCH_SIZE,\n    valid_idx=val_idxs\n)\n","501f1796":"dls.show_batch()","b7a6bce1":"net = Model(num_features=NUM_FEATURES, num_targets=NUM_TARGETS)\n\nlearner = TabularLearner(dls, model=net, loss_func=nn.BCELoss())","550042d4":"learner.fit_one_cycle(EPOCHS)","a68e648e":"inference_model = learner.model\ninference_model.to('cpu')\ninference_model.eval()","f4894b8c":"env = janestreet.make_env()\nenv_iter = env.iter_test()\n\nopt_th = 0.5\n\nf_mean = train_means[FEATURE_NAMES].values[1:]  # forget feature 0\n\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, FEATURE_NAMES].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = 0.\n        \n        # note the empty tensor; fastai expects categorial features and we have none\n        pred_vector = (\n        inference_model(torch.tensor([]), torch.tensor(x_tt, dtype=torch.float))\n             .detach()\n             .cpu()\n             .numpy()\n        )\n        \n        # only buy if both horizons look good\n        pred_df.action = (\n            (pred_vector[0][0] > opt_th).astype(int) * \n            (pred_vector[0][1] > opt_th).astype(int)\n        )\n\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","7b226aa5":"# fastai Code\n\nUsing the fastai classes, we can train a DL model with just a tiny bit of code.","e8220eca":"![image.png](attachment:image.png)\nSource: LdP, Advances in Financial Machine Learning, chapter 3.\n\n\nThe key idea in this notebook is that if we can convince ourselves that one or more of the `resp_{1,2,3,4}` variables is shorter in time than `resp`, then we should get a more robust model with multi-target training. We want a loss function in our model which takes into account the model's ability to **predict at all relevant horizons**. We can't do this with traditional ML or GBDT modles like XGBoost or LightGBM, we need a deep learning model.","2ffa5cbd":"Now to the model. Since we beleive that `resp_{1,2,3}` come *before* `resp` in time, we can use these returng to make our model more robust to overfitting.\n\nThe sponsor also includes a \"weight\" indicator for the trade. This is a scalar that multiplies the `resp` in the score. As noted elsewhere, I believe the weight to be an inverse function of the expected transaction cost to do the trade. There are many zero weights in the training data and we want to remove these.","dda3312c":"\nThank you to\n- [@artgor](https:\/\/www.kaggle.com\/artgor) and [@abhishek](https:\/\/www.kaggle.com\/abhishek); originally I wrote this notebook with PyTorch Lightning; following their YouTube talk [Pair Programming: Deep Learning Model For Drug Classification With Andrey Lukyanenko](https:\/\/www.youtube.com\/watch?v=VRVit0-0AXE)\n- I re-wrote the notebook in fastai; thanks to [@muellerzr](https:\/\/www.kaggle.com\/muellerzr) for being so kind in responding to my questions on the fastai forums in the past day.\n- [@gogo827jz](https:\/\/www.kaggle.com\/gogo827jz); the model architecture and hyperparams follow his notebook [\nJane Street: Neural Network Starter](https:\/\/www.kaggle.com\/gogo827jz\/jane-street-neural-network-starter). The prediction loop follows this notebook as well.","b5b3fa08":"How do we account for this drift in the modeling process? The referenced notebook indicated that one could tune the classifier decision boundary, noting that this is likely just overfitting to the public leaderboard.","1cd7da36":"# What is the Time Ordering of responses?\n\nI believe that `resp_1 < resp_2 < resp_3 < resp < resp_4`. Why is this? A stylized feature of financial time series is that the variance scales with time. In a perfectly efficient market, the variance scales linearly with time (i.e., the price series is a random walk). Thus we can order the resp_x labels in time by looking at their variances. Simple plots make this clear.","dbbf4fb4":"Any now we fit using a cyclical learning rate schedule. See [the docs](https:\/\/fastai1.fast.ai\/callbacks.one_cycle.html) for details.","b5985ebc":"Read train data.","19f10679":"I see about 80 iters per second, which is well above the required 60 per second.","bde75c04":"# Prediction Loop","1f17e101":"First we need a model. This is pure PyTorch.","ca0a0024":"# A Multi-Target Approach\n\n\nIn this competition, we are provided with sequential trading opportunities and we need to decide \"yes\"\/\"no\" as to do the trade or not; the sponsor provides anonymous features. The ultimate score is a function of the `resp` target, which is a (presumably raw) future return of unknown horizon. The motivation here is to take advantage of `resp_1`, `resp_2`, `resp_3`, and `resp_4`. Per the comptition intro \n\n> In the training set, train.csv, you are provided a resp value, as well as several other resp_{1,2,3,4} values that represent returns over different time horizons. These variables are not included in the test set.\n\nAnd as noted\/suggested by the sponsor in [this comment](https:\/\/www.kaggle.com\/c\/jane-street-market-prediction\/discussion\/198965#1088950)\n\n![image.png](attachment:image.png)\n\n\n**So the idea is that perhaps a model which is robust to predicting returns at multiple horizons will be more robust at predicting the single horizon competition target, `resp`.**\n\n## A Corollary to the Triple Barrier Method\n\nIt is not clear what the resp_ time horizons are. It is well known that quant models which predict for time *t+1* are often unsuitable for predicting at time *t+2* if the time step is large. However, the reverse is posited to be: models which predict *t+1* **are more robust** if they are able to predict at time *t+f* where *f < 1*. If we can simultaneously predict at multiple horizons up to t+1 then we capture path dynamics. The loss function must include the combined loss of all horizons.\n\nThis idea is similar to the so-called \"triple barrier method\" postited by Lopez de Prado in [Advances in Financial Machine Learning](https:\/\/www.amazon.com\/Advances-Financial-Machine-Learning-Marcos\/dp\/1119482089\/ref=sr_1_1?crid=29OT5YAU1GUMZ&dchild=1&keywords=advances+in+financial+machine+learning&qid=1607535288&sprefix=advances+%2Caps%2C184&sr=8-1):\n\nThe idea he proposes implies that the path of the stock, from prediction t to the final horizon time, matters. In this formulation however there is still only **one label**. That single label is a function of the path.","1be8834c":"This notebook presents two ideas for target enginnering:\n- Training on **cross-sectional daily bins** of `weight` x `resp`\n- Training on **two** targets simultaneiously\n\n# Why Target Engineering?\n\nIn low signal-to-noise prediction problems, it is very difficult to build a robust model. One way to aid in robustness is to engineer the target. In fact, most everyone in this competition is already doing this with something like\n\n```y = (train_data['resp'] > 0).astype(int)```\n\n\nto make a binary target for use in a classifier. Can we do \"better\" than this?\n\nAs noted in the great notebook [The Most Important Model Parameter](https:\/\/www.kaggle.com\/gkoundry\/the-most-important-model-parameter), there is a drift in the mean daily return, `resp`, and this drift is different when  you account for the `weight`:","2609693f":"We set up our tabular data class.","7da452f8":"So we do see some greater ability to predict if a `weight_x_resp` will be in the top half. It remains to be seen if this correlates better with higher utility.","5dd53060":"and simply instantiate the model and pass it to a Learner.","4c692c23":"If we quantile the `weight_x_resp`, we see that most of the trades are in the tails.","6be2bbbf":"## Cross Sectional Daily Bins\n\nSince `weight` is strictly positive, it doesn't help to engineer the `resp` target simply by multiplying by `weight`. However, one approach to engineer the target and \"solve\" this is to quantile the `resp x weight` per day and then set the target to be the top N bins. This approach focuses the classifer to train on high return **and** high weight trades. It removes, in training, any drift in the dataset.","b54f3aba":"The weights are log-normally distributed. A simple log transform shows this."}}