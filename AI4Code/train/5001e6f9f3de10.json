{"cell_type":{"d9b041fd":"code","30fbdfa3":"code","c59bacef":"code","b226c855":"code","56884f12":"code","8577b9ed":"code","fec124b3":"code","f12992b0":"code","fb6dedf3":"code","c6442e19":"code","f72083df":"code","62b805e4":"code","cee62f57":"code","161decb1":"code","244db663":"code","e37f98bf":"code","a39823d6":"code","c435086f":"code","d75eba33":"code","b6d36a2c":"code","473dc860":"code","14d0b586":"code","bf19fe3f":"code","1f8cb8cc":"code","62ac8681":"code","85d3c98e":"code","dfd46a54":"code","ea1af2c3":"code","9a796b51":"code","2e89ba4c":"code","19dfbe34":"code","47d539a2":"code","9d584e44":"code","857b2509":"code","c1e8533e":"code","d4c9ff76":"markdown","b34f73c9":"markdown","89f1cbc8":"markdown","3b8cb03c":"markdown"},"source":{"d9b041fd":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom os.path import join\nimport seaborn as sns","30fbdfa3":"BASE_DIR='..\/'","c59bacef":"train_path = join(BASE_DIR, 'input', 'kagglecamp2022', 'train.csv')\ntest_path = join(BASE_DIR, 'input', 'kagglecamp2022', 'test.csv')","b226c855":"data = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)","56884f12":"data.info()","8577b9ed":"data.describe()","fec124b3":"label = data['Cover_Type']\n#label = label.astype(int)\n\nid = data['id']","f12992b0":"data.drop(columns=['id', 'Cover_Type'], inplace=True)\ntest.drop(columns=['id'], inplace=True)","fb6dedf3":"cat_columns = ['Soil_Type', 'Wilderness_Area']\nnum_columns = [col for col in data.columns if col not in cat_columns]\n\nprint('\ubc94\uc8fc\ud615 \uceec\ub7fc: \\n{}\\n'.format(cat_columns))\nprint('\uc218\uce58\ud615 \uceec\ub7fc: \\n{}\\n'.format(num_columns))","c6442e19":"import missingno as msno\n\nmsno.matrix(data)","f72083df":"msno.matrix(test)","62b805e4":"data.shape, label.shape","cee62f57":"test.shape","161decb1":"plt.figure(figsize=(12,14))\nsns.heatmap(pd.concat([data, label], axis=1).corr(), vmin=-1, vmax=1, annot=True, linewidths=0.2, fmt='.2f', cmap='RdGy')\nplt.show()","244db663":"meaningless_cols = [col for col in num_columns if col not in ['Elevation', 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points']]\nprint('|\uc0c1\uad00 \uacc4\uc218| < 0.1 \uceec\ub7fc:\\n{}'.format(meaningless_cols))","e37f98bf":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder","a39823d6":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(data, label, test_size=0.3,\n                                                      shuffle=True, random_state=42,\n                                                      stratify=label)","c435086f":"y_train.reset_index(drop=True, inplace=True)\ny_valid.reset_index(drop=True, inplace=True)","d75eba33":"def preprocess(x_train, x_valid, x_test):\n    temp_x_train = x_train.copy()\n    temp_x_valid = x_valid.copy()\n    temp_x_test = x_test.copy()\n\n    temp_x_train.reset_index(drop=True, inplace=True)\n    temp_x_valid.reset_index(drop=True, inplace=True)\n\n    # \uc218\uce58\ud615 \uacb0\uce21\uce58 \ucc98\ub9ac\n    imputer = IterativeImputer(max_iter=20, random_state=42)\n\n    temp_x_train[num_columns] = imputer.fit_transform(temp_x_train[num_columns])\n    temp_x_valid[num_columns] = imputer.transform(temp_x_valid[num_columns])\n    temp_x_test[num_columns] = imputer.transform(temp_x_test[num_columns])\n\n    # \uc0c1\uad00 \uacc4\uc218 0.1\uc774\ud558 \uc2a4\ucf00\uc77c\ub9c1\n    scaler = RobustScaler()\n\n    temp_x_train[meaningless_cols] = scaler.fit_transform(temp_x_train[meaningless_cols])\n    temp_x_valid[meaningless_cols] = scaler.transform(temp_x_valid[meaningless_cols])\n    temp_x_test[meaningless_cols] = scaler.transform(temp_x_test[meaningless_cols])\n\n    # \uc6d0 \ud56b \uc778\ucf54\ub529\n    cat_all = pd.concat([temp_x_train[cat_columns],temp_x_valid[cat_columns], temp_x_test[cat_columns]], axis=0)\n    ohe = OneHotEncoder(sparse=False)\n    ohe.fit(cat_all)\n\n    ohe_columns = list()\n    for cols, col in zip(ohe.categories_, cat_columns):\n        ohe_columns += [f'{col}_{c}' for c in cols.tolist()]\n\n    cat_train = pd.DataFrame(ohe.transform(temp_x_train[cat_columns]), columns=ohe_columns)\n    cat_valid = pd.DataFrame(ohe.transform(temp_x_valid[cat_columns]), columns=ohe_columns)\n    cat_test = pd.DataFrame(ohe.transform(temp_x_test[cat_columns]), columns=ohe_columns)\n\n    temp_x_train.drop(columns=cat_columns, inplace=True)\n    temp_x_valid.drop(columns=cat_columns, inplace=True)\n    temp_x_test.drop(columns=cat_columns, inplace=True)\n\n    temp_x_train = pd.concat([temp_x_train, cat_train], axis=1)\n    temp_x_valid = pd.concat([temp_x_valid, cat_valid], axis=1)\n    temp_x_test = pd.concat([temp_x_test, cat_test], axis=1)\n\n    return temp_x_train, temp_x_valid, temp_x_test","b6d36a2c":"from sklearn.ensemble import VotingClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","473dc860":"x_train, x_valid, _ = preprocess(x_train, x_valid, test)\n\nfrom sklearn.inspection import permutation_importance\n\nclfs = [\n        ['LGBM', LGBMClassifier(n_estimators=1000,learning_rate=0.1, max_depth= 9, reg_alpha= 0.01, reg_lambda=0.01, tree_method='gpu_hist')],\n       \n        ['XGBM', XGBClassifier(n_estimators=1000,learning_rate=0.1, max_depth= 9, reg_alpha= 0.01, reg_lambda=0.01, tree_method='gpu_hist')],\n        ['CatBoost', CatBoostClassifier(learning_rate=0.1, max_depth=9, l2_leaf_reg=0.01, iterations=1000)]]\nvote_clf = VotingClassifier(clfs, voting='soft')\nvote_clf.fit(x_train, y_train)\n\nr = permutation_importance(vote_clf, x_valid, y_valid,\n                           n_repeats=10,\n                           random_state=42)","14d0b586":"for i in r.importances_mean.argsort()[::]:\n  #if r.importances_mean[i] - 2 * r.importances_std[i] > 0:        # \uc88b\uc740 \ubcc0\uc218\ub97c \uc120\ubcc4\ud558\ub294 \uc870\uac74\ubb38\uc744 \uc9c0\uc6b4\ub2e4.\n  print(f\"{x_valid.columns[i]:<8}: \"\n    f\"{r.importances_mean[i]:.3f}\"\n    f\" +\/- {r.importances_std[i]:.3f}\")","bf19fe3f":"for i in r.importances_mean.argsort()[::-1]:\n    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n        print(f\"{x_valid.columns[i]:<8}: \"\n               f\"{r.importances_mean[i]:.3f}\"\n               f\" +\/- {r.importances_std[i]:.3f}\")","1f8cb8cc":"# \ud53c\uccd0 \uc120\nspec_columns = ['Elevation','Soil_Type_0','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points','Wilderness_Area_0',\n                'Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Hydrology','Wilderness_Area_2','Soil_Type_38','Soil_Type_1',\n                'Soil_Type_3','Soil_Type_37','Soil_Type_39','Soil_Type_21','Soil_Type_22','Soil_Type_2','Soil_Type_32','Soil_Type_9',\n                'Soil_Type_31','Soil_Type_34','Soil_Type_12','Wilderness_Area_3','Soil_Type_4','Soil_Type_30','Soil_Type_10','Soil_Type_23',\n                'Soil_Type_16','Soil_Type_11','Soil_Type_36','Soil_Type_35','Soil_Type_29','Soil_Type_19','Soil_Type_17','Soil_Type_13',\n                'Soil_Type_25','Soil_Type_15','Soil_Type_26','Soil_Type_33','Soil_Type_20','Soil_Type_18','Soil_Type_8','Soil_Type_27','Soil_Type_28']","62ac8681":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(data, label, test_size=0.3,\n                                                      shuffle=True, random_state=42,\n                                                      stratify=label)","85d3c98e":"y_train.reset_index(drop=True, inplace=True)\ny_valid.reset_index(drop=True, inplace=True)","dfd46a54":"x_train.shape, y_train.shape, x_valid.shape, y_valid.shape","ea1af2c3":"from sklearn.model_selection import StratifiedKFold","9a796b51":"val_scores = list()\noof_pred = np.zeros((test.shape[0],4))\nn_splits = 5\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)","2e89ba4c":"from sklearn.metrics import f1_score, log_loss","19dfbe34":"for i, (train_idx, valid_idx) in enumerate(skf.split(data, label)):\n    x_train, y_train = data.iloc[train_idx, :], label.iloc[train_idx,]\n    x_valid, y_valid = data.iloc[valid_idx, :], label.iloc[valid_idx,]\n    \n    # \uc804\ucc98\ub9ac\n    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n    # \ud2b9\uc815 \uceec\ub7fc\ub9cc \uc0ac\uc6a9\n    x_train = x_train[spec_columns]\n    x_valid = x_valid[spec_columns]\n    x_test = x_test[spec_columns]\n    \n    # \ubaa8\ub378 \uc815\uc758\n    clfs = [['CatBoost', CatBoostClassifier(learning_rate=0.1, max_depth=9, l2_leaf_reg=0.01, iterations=1000)],\n        ['LGBM', LGBMClassifier(n_estimators=1000,learning_rate=0.1, max_depth= 9, reg_alpha= 0.01, reg_lambda=0.01, tree_method='gpu_hist')],\n        ['XGBM', XGBClassifier(n_estimators=1000,learning_rate=0.1, max_depth= 9, reg_alpha= 0.01, reg_lambda=0.01, tree_method='gpu_hist')]]\n\n    vote_clf = VotingClassifier(clfs, voting='soft')\n\n    \n    # \ubaa8\ub378 \ud559\uc2b5\n    vote_clf.fit(x_train, y_train)\n    \n    # \ud6c8\ub828, \uac80\uc99d \ub370\uc774\ud130 log_loss \ud655\uc778\n    train_logloss = log_loss(y_train, vote_clf.predict_proba(x_train))\n    valid_logloss = log_loss(y_valid, vote_clf.predict_proba(x_valid))\n    print('{} Fold, train logloss : {:.4f}, validation logloss : {:.4f}'.format(i, train_logloss, valid_logloss))\n    \n    val_scores.append(valid_logloss)\n    \n    oof_pred += vote_clf.predict_proba(x_test) \/ skf.n_splits \n\n# \uad50\ucc28 \uac80\uc99d \uc815\ud655\ub3c4 \ud3c9\uade0 \uacc4\uc0b0\ud558\uae30\nprint('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","47d539a2":"oof_pred\noof_pred.shape","9d584e44":"sub_path = join(BASE_DIR, 'input', 'kagglecamp2022', 'sample_submission.csv')\nsub = pd.read_csv(sub_path)","857b2509":"sub['Cover_Type'] = oof_pred.argmax(axis=1)+1","c1e8533e":"sub","d4c9ff76":"## \ub370\uc774\ud130 \uc7ac \uc120\uc5b8","b34f73c9":"## k-fold","89f1cbc8":"## feature importance \ube44\uad50","3b8cb03c":"## \uc804\ucc98\ub9ac \ud504\ub85c\uc138\uc2a4"}}