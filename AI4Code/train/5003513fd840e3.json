{"cell_type":{"0ebf7d1b":"code","c35f5593":"code","25829f96":"code","42b52a76":"code","aa24c6a3":"code","1045075d":"code","892e1406":"code","9904e8ea":"code","70095462":"code","5e39ff91":"code","3e65379d":"code","b8a52282":"code","80c2b172":"code","2168ba32":"code","22cf87d6":"code","932cf37d":"code","b0139fb0":"code","5bfdc419":"code","8022f86f":"code","ed8957ee":"code","0adb74e3":"code","e2a85bf8":"code","f0862c49":"code","3e7b459b":"code","9b8a590f":"code","7f1bea6c":"code","2b8fb8e4":"code","6be10b5f":"code","13540701":"markdown","514759f1":"markdown","d99926de":"markdown","c774c803":"markdown","45a005a5":"markdown","9825ed99":"markdown","278bf56d":"markdown","f067ae14":"markdown","e27ab5f8":"markdown","bc40f97b":"markdown","de108d2f":"markdown","291becac":"markdown","842078e1":"markdown","e71370c9":"markdown","5d016f72":"markdown","d97ef9b0":"markdown"},"source":{"0ebf7d1b":"import numpy as np # linear algebra\nimport json\nimport os\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom IPython.display import HTML\n\npd.set_option('max_columns', 50)","c35f5593":"from platform import python_version\nprint(python_version())","25829f96":"## https:\/\/github.com\/SoftwareAG\/nyoka\n    \n!pip install pypmml\n!pip install --upgrade nyoka","42b52a76":"!pip install numpy protobuf==3.16.0\n!pip install onnx","aa24c6a3":"!pip install pydot","1045075d":"!pip install onnxmltools","892e1406":"!pip install onnxruntime\n!pip install skl2onnx","9904e8ea":"## ONNX \nimport onnxruntime as rt\nimport onnx\nimport skl2onnx\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx import convert_sklearn, update_registered_converter\nfrom skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\nfrom onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost  # noqa\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n","70095462":"from sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nimport joblib\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom lightgbm import LGBMClassifier\nfrom pypmml import Model\nimport numpy as np","5e39ff91":"%%time\nsampleEntry = pd.read_csv('\/kaggle\/input\/GiveMeSomeCredit\/sampleEntry.csv')\ntrain = pd.read_csv('\/kaggle\/input\/GiveMeSomeCredit\/cs-training.csv')\ntest = pd.read_csv('\/kaggle\/input\/GiveMeSomeCredit\/cs-test.csv')\ndel test['Unnamed: 0']\ndel test['SeriousDlqin2yrs']\ndel train['Unnamed: 0']","3e65379d":"print('train shape  ',train.shape)","b8a52282":"train['SeriousDlqin2yrs'] = train['SeriousDlqin2yrs'].astype(np.int32)\ntrain['age'] = train['age'].astype(np.int32)\ntrain['NumberOfTime30-59DaysPastDueNotWorse'] = train['NumberOfTime30-59DaysPastDueNotWorse'].astype(np.int32)\ntrain['NumberOfOpenCreditLinesAndLoans'] = train['NumberOfOpenCreditLinesAndLoans'].astype(np.int32)\ntrain['NumberOfTimes90DaysLate'] = train['NumberOfTimes90DaysLate'].astype(np.int32)\ntrain['NumberRealEstateLoansOrLines'] = train['NumberRealEstateLoansOrLines'].astype(np.int32)\ntrain['NumberOfTime60-89DaysPastDueNotWorse'] = train['NumberOfTime60-89DaysPastDueNotWorse'].astype(np.int32)\n\ntarget = 'SeriousDlqin2yrs'\nfeatures = ['RevolvingUtilizationOfUnsecuredLines',\n            'age', 'NumberOfTime30-59DaysPastDueNotWorse',\n 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n 'NumberOfDependents']","80c2b172":"pipeline = Pipeline([\n    ('LGBMC_preprocess',LGBMClassifier(n_estimators=5))\n])\npipeline.fit(train[features], train[target])","2168ba32":"from nyoka import lgb_to_pmml\nlgb_to_pmml(pipeline,features,target,\"lgbcreditmodel.pmml\")","22cf87d6":"def pipeline_train(train):\n    \"\"\" Summary or Description of the Function\n\n    Parameters:\n    train (dataframe): dataframe with train data\n    Returns:\n    binary: machine learning model\n    \"\"\" \n    train = train.dropna()\n    train_x, val_x, train_y, val_y=train_test_split(train.drop('SeriousDlqin2yrs',axis=1),train['SeriousDlqin2yrs'].astype('uint8'),test_size=.2,random_state=2021)\n    xgb_cfl = xgb.XGBClassifier(n_jobs = -1, \n                                n_estimators = 50)\n    xgb_cfl.fit(train_x, train_y)\n    return xgb_cfl\nmodel = pipeline_train(train)\ntype(model)","932cf37d":"filename_pmml = '..\/input\/model-credito\/model_credito.sav'","b0139fb0":"json_simulation = test.head(1).to_json()\njson_simulation","5bfdc419":"def entry_point_script(data, train_data):\n    \"\"\" Summary or Description of the Function\n\n    Parameters:\n    data (json): json with client information\n\n    Returns:\n    json: client probability that somebody will experience financial distress in the next two years.\n\n\n   \"\"\"\n    model = pipeline_train(train_data)\n    jdata = json.loads(data)\n    escoragem = pd.DataFrame(jdata)\n    res = model.predict_proba(escoragem)[:,1]\n    result = pd.DataFrame(res.tolist(), columns=['probability'])\n    return result.to_json(orient = \"records\", lines=False)","8022f86f":"%%time\nres = entry_point_script(json_simulation, train)\nres","ed8957ee":"def entry_point_binarymodel(data, filename):\n    \"\"\" Summary or Description of the Function\n\n    Parameters:\n    data (json): json with client information\n    filename:  path with binary modeo\n\n    Returns:\n    json: client probability that somebody will experience financial distress in the next two years.\n\n\n   \"\"\"\n    jdata = json.loads(data)\n    escoragem = pd.DataFrame(jdata)\n    loaded_model = joblib.load(open(filename, 'rb'))    \n    res = loaded_model.predict_proba(escoragem)[:,1]\n    result = pd.DataFrame(res.tolist(), columns=['probability'])\n    return result.to_json(orient = \"records\", lines=False)","0adb74e3":"%%time\nres = entry_point_binarymodel(json_simulation, filename_pmml)\nres","e2a85bf8":"def entry_point_pmml(data):\n    \"\"\" Summary or Description of the Function\n\n    Parameters:\n    train_data (dataframe): dataframe with train data\n    filename (str): machine learning model path\n\n    Returns:\n    json: client probability that somebody will experience financial distress in the next two years.\n    \"\"\" \n    jdata = json.loads(data)\n    escoragem = pd.DataFrame(jdata)\n    loaded_model = Model.fromFile(\"lgbcreditmodel.pmml\")\n    res = model.predict(escoragem)\n    result = pd.DataFrame(res.tolist(), columns=['probability'])\n    return result.to_json(orient = \"records\", lines=False)","f0862c49":"%%time\nres = entry_point_pmml(json_simulation)\nres","3e7b459b":"test.columns = [x.lower() for x in test.columns]\ntrain.columns = [x.lower() for x in train.columns]\n\ntrain.rename(columns={'seriousdlqin2yrs': 'target',  'revolvingutilizationofunsecuredlines':'f1', 'age':'f2',       'numberoftime30-59dayspastduenotworse':'f3', 'debtratio':'f4', 'monthlyincome':'f5',       'numberofopencreditlinesandloans':'f6', 'numberoftimes90dayslate':'f7',\n       'numberrealestateloansorlines':'f8', 'numberoftime60-89dayspastduenotworse':'f9','numberofdependents':'f10'}, inplace=True)\ntest.rename(columns={'seriousdlqin2yrs': 'target',  'revolvingutilizationofunsecuredlines':'f1', 'age':'f2',       'numberoftime30-59dayspastduenotworse':'f3', 'debtratio':'f4', 'monthlyincome':'f5',       'numberofopencreditlinesandloans':'f6', 'numberoftimes90dayslate':'f7',\n       'numberrealestateloansorlines':'f8', 'numberoftime60-89dayspastduenotworse':'f9','numberofdependents':'f10'}, inplace=True)\n\ntrain.fillna(-1, inplace=True)\ntest.fillna(-1, inplace=True)\n\ntrain['target'] = train['target'].astype(np.int32)\ntrain['f1'] = train['f1'].astype(np.int32)\ntrain['f2'] = train['f2'].astype(np.int32)\ntrain['f3'] = train['f3'].astype(np.int32)\ntrain['f4'] = train['f4'].astype(np.int32)\ntrain['f5'] = train['f5'].astype(np.int32)\ntrain['f6'] = train['f6'].astype(np.int32)\ntrain['f7'] = train['f7'].astype(np.int32)\ntrain['f8'] = train['f8'].astype(np.int32)\ntrain['f9'] = train['f9'].astype(np.int32)\ntrain['f10'] = train['f10'].astype(np.int32)\n\ntest['f1'] = test['f1'].astype(np.int32)\ntest['f2'] = test['f2'].astype(np.int32)\ntest['f3'] = test['f3'].astype(np.int32)\ntest['f4'] = test['f4'].astype(np.int32)\ntest['f5'] = test['f5'].astype(np.int32)\ntest['f6'] = test['f6'].astype(np.int32)\ntest['f7'] = test['f7'].astype(np.int32)\ntest['f8'] = test['f8'].astype(np.int32)\ntest['f9'] = test['f9'].astype(np.int32)\ntest['f10'] = test['f10'].astype(np.int32)\n\ntarget = 'target'\nfeatures = ['f1','f2','f3','f4','f5','f6','f7','f8','f9', 'f10']\n\npipeline2 = Pipeline([\n    ('XGB_preprocess',XGBClassifier(n_estimators=5))\n])\npipeline2.fit(train[features], train[target])\n","9b8a590f":"\nupdate_registered_converter(\n    XGBClassifier, 'XGBoostXGBClassifier',\n    calculate_linear_classifier_output_shapes, convert_xgboost,\n    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})\n\n\n\nmodel_onnx = convert_sklearn(\n    pipeline2, 'pipeline_xgboost',\n    [('input', FloatTensorType([None, 10]))],\n    target_opset=10)\n\n# And save.\nwith open(\"pipeline_xgboost.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())\n    ","7f1bea6c":"pydot_graph = GetPydotGraph(\n    model_onnx.graph, name=model_onnx.graph.name, rankdir=\"TB\",\n    node_producer=GetOpNodeProducer(\n        \"docstring\", color=\"yellow\",\n        fillcolor=\"yellow\", style=\"filled\"))\npydot_graph.write_dot(\"pipeline.dot\")\n\nos.system('dot -O -Gdpi=300 -Tpng pipeline.dot')\n\nimage = plt.imread(\"pipeline.dot.png\")\nfig, ax = plt.subplots(figsize=(40, 20))\nax.imshow(image)\nax.axis('off')","2b8fb8e4":"def entry_point_onnx(data):\n    \"\"\" Summary or Description of the Function\n\n    Parameters:\n    data (json): data for prediction\n\n    Returns:\n    json: client probability that somebody will experience financial distress in the next two years.\n    \"\"\" \n    jdata = json.loads(data)\n    escoragem = pd.DataFrame(jdata)\n    sess = rt.InferenceSession(\"pipeline_xgboost.onnx\")\n    pred_onx = sess.run(None, {\"input\": escoragem.values.astype(np.float32)})\n    \n    return pd.DataFrame([{\"probability_target_0\":pred_onx[1][0][0],\"probability_target_1\":pred_onx[1][0][1]}]).to_json(orient = \"records\", lines=False)\n","6be10b5f":"%%time\nres = entry_point_onnx(json_simulation)\nres","13540701":"#### Model ONNX- generate pipeline","514759f1":"### Convert the model to PMML\nNow we can convert the model to PMML using nyoka:","d99926de":"Variable Name\tDescription\tType\n- ``SeriousDlqin2yrs``\tPerson experienced 90 days past due delinquency or worse\tY\/N\n- ``RevolvingUtilizationOfUnsecuredLines``\tTotal balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits\tpercentage\n- ``age``\tAge of borrower in years\tinteger\n- ``NumberOfTime3059DaysPastDueNotWorse``\tNumber of times borrower has been 30-59 days past due but no worse in the last 2 years.\tinteger\n- ``DebtRatio``\tMonthly debt payments, alimony,living costs divided by monthy gross income\tpercentage\n- ``MonthlyIncome``\tMonthly income\treal\n- ``NumberOfOpenCreditLinesAndLoans``\tNumber of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)\tinteger\n- ``NumberOfTimes90DaysLate``\tNumber of times borrower has been 90 days or more past due.\tinteger\n- ``NumberRealEstateLoansOrLines``\tNumber of mortgage and real estate loans including home equity lines of credit\tinteger\n- ``NumberOfTime60-89DaysPastDueNotWorse``\tNumber of times borrower has been 60-89 days past due but no worse in the last 2 years.\tinteger\n- ``NumberOfDependents``\tNumber of dependents in family excluding themselves (spouse, children etc.)\tinteger","c774c803":"## End notebook","45a005a5":"# Using binary model","9825ed99":"# Using ONNX","278bf56d":"##### Around 6% of samples defaulted\n- MonthlyIncome and NumberOfDependents have 29731 (19.82%) and 3924 (2.61%) null values respectively\n- We also notice that when NumberOfTimes90DaysLate has values above 17, there are 267 instances where the three columns \n- NumberOfTimes90DaysLate, NumberOfTime60-89DaysPastDueNotWorse, NumberOfTime30-59DaysPastDueNotWorse share the same values, specifically 96 and 98.\n    - We can see that sharing the same values of 96 and 98 respectively is not logical since trivial calculations can reveal that being 30 days past due for 96 times for a single person within a timespan of 2 years is not possible.\n- RevolvingUtilizationOfUnsecuredLines\n    - Defined as ratio of the total amount of money owed to total credit limit\ndistribution of values is right-skewed, consider removing outliers\n    - It is expected that as this value increases, the proportion of people defaulting should increase as well\n    - However, we can see that as the minimum value of this column is set to 13, the proportion of defaulters is smaller than that belonging to the pool of clients with total amount of money owed not exceeding total credit limit.\n    - Thus we should remove those samples with RevolvingUtilizationOfUnsecuredLines's value more than equal to 13\n- age\n    - There seems to be more younger people defaulting and the distribution seems fine on the whole\n- NumberOfTimes90DaysLate\n    - It is interesting to note that there are no one who is 90 or more days past due between 17 and 96 times.\n- NumberOfTime60-89DaysPastDueNotWorse\n    - It is interesting to note that there are no one who is 60-89 days past due between 11 and 96 times.\n- NumberOfTime30-59DaysPastDueNotWorse\n    - It is interesting to note that there are no one who is 30-59 days past due between 13 and 96 times.\n- DebtRatio\n    - 2.5% of clients owe around 3490 or more times what they own\n    - For the people who have monthly income in this 2.5%, only 185 people have values for their monthly incomes and the values are either 0 or 1.\n    - There are 164 out of these 185 people who are of two different types, first with no monthly income and does not default and second with monthly income and does default.\n- MonthlyIncome\n    - Distribution of values is skewed, we can consider imputation with median.\n    - We can also consider imputing with normally distributed values with its mean and standard deviation.\n- Numberof Dependents\n    - We can consider imputing with its mode, which is zero.","f067ae14":"### Using script","e27ab5f8":"# Simulation - test deploy","bc40f97b":"# XGB Classifier","de108d2f":"### Read Data","291becac":"# Using PMML model\nValidate whether the predictions of PMML are the same as ones produced by the Python model.\n","842078e1":"# Final","e71370c9":"# Imports","5d016f72":"## Display the ONNX graph","d97ef9b0":"# Give Me Some Credit\n![](https:\/\/www.freshfacs.com\/v\/vspfiles\/photos\/D3-2.jpg)\n\nImprove on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.\n"}}