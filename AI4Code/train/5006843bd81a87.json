{"cell_type":{"c8c70f09":"code","8eac9b78":"code","ae7ea3de":"code","9b84fd1a":"code","18791dc3":"code","f9c1fdd7":"code","ec9c5494":"code","d82079b6":"code","1a7e7d8e":"code","512ab28d":"code","2201744b":"code","7bf25219":"code","db1e0238":"code","a2a7bf41":"code","579c234c":"code","4900efea":"code","99baf656":"code","eb1218bb":"code","adf2506b":"code","2de2a00b":"code","8d8d9952":"code","1cdb11b1":"code","69a7ddfb":"markdown","5f0cd460":"markdown","42696f01":"markdown","f7c5f72e":"markdown","cbef9a75":"markdown","e95a9779":"markdown"},"source":{"c8c70f09":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/bike-sharing-dataset\"))\n# Any results you write to the current directory are saved as output.","8eac9b78":"raw = pd.read_csv('..\/input\/bike-sharing-dataset\/hour.csv')","ae7ea3de":"raw.head()","9b84fd1a":"raw.info()","18791dc3":"raw.describe()","f9c1fdd7":"raw.hist(figsize=(12,10))","ec9c5494":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(18,13))\nsns.heatmap(raw.corr(), annot=True)","d82079b6":"def generate_dummies(df, dummy_column):\n    dummies = pd.get_dummies(df[dummy_column], prefix=dummy_column)\n    df = pd.concat([df, dummies], axis=1)\n    return df\n\nX = pd.DataFrame.copy(raw)\ndummy_columns = [\"season\", \"yr\", \"mnth\", \"hr\", \"weekday\", \"weathersit\"]\nfor dummy_column in dummy_columns:\n    X = generate_dummies(X, dummy_column)","1a7e7d8e":"X.head()","512ab28d":"#remove the original categorical variables: \"season\", \"yr\", \"mnth\", \"hr\", \"weekday\", \"weathersit\"\n\nfor dummy_column in dummy_columns:\n    del X[dummy_column]\n","2201744b":"X.head()","7bf25219":"first_5_weeks = 5*7*24 # 3 weeks (7 days), 24 hours each day\nX[:first_5_weeks].plot(x='dteday', y='cnt', figsize=(18, 5))","db1e0238":"## We use 'cnt' as the response variable. We drop 'casual' and 'registered'\n\ny = X['cnt']\ndel X['cnt']\ndel X['casual']\ndel X['registered']","a2a7bf41":"## drop also the variables 'instant' and 'dteday' since they are irrelevant\n\ndel X['instant']\ndel X['dteday']","579c234c":"X.head()","4900efea":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 22, test_size = 0.2)","99baf656":"# Grid Search\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nregressor = RandomForestRegressor()\nparameters = [{'n_estimators' : [150,200,250,300], 'max_features' : ['auto','sqrt','log2']}]\ngrid_search = GridSearchCV(estimator = regressor, param_grid = parameters)\ngrid_search = grid_search.fit(X_train, y_train)\nbest_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_\n","eb1218bb":" best_parameters","adf2506b":"# Random Forest Regression model\n# Use the best parameters found from above to build the model\n\nregressor = RandomForestRegressor(n_estimators = 300, max_features = 'auto') \nregressor.fit(X_train,y_train)\n\n# Predicting the values \n\ny_pred = regressor.predict(X_test) \n","2de2a00b":"# Comparing predicted values with true values in testing set\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test, y_pred)","8d8d9952":"# Using k-fold cross validation to evaluate the performance of the model\n\nfrom sklearn.model_selection import cross_val_score\naccuracy = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv =10)\naccuracy.mean()","1cdb11b1":"# Relative importance of features \n\nfeature_importance = regressor.feature_importances_\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\nplt.figure(figsize=(12,10))\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X_train.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","69a7ddfb":"## Split the data set into training set and testing set, with 80% as training set","5f0cd460":"This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system in Washington, DC with the corresponding weather and seasonal information.\n\n### Content\nBoth hour.csv and day.csv have the following fields, except hr which is not available in day.csv\n\n* instant: Record index\n* dteday: Date\n* season: Season (1:springer, 2:summer, 3:fall, 4:winter)\n* yr: Year (0: 2011, 1:2012)\n* mnth: Month (1 to 12)\n* hr: Hour (0 to 23)\n* holiday: weather day is holiday or not (extracted from Holiday Schedule)\n* weekday: Day of the week\n* workingday: If day is neither weekend nor holiday is 1, otherwise is 0.\n* weathersit: (extracted from Freemeteo)\n  1.  Clear, Few clouds, Partly cloudy, Partly cloudy\n  2.  Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n  3.  Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n  4.  Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n* temp: Normalized temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n* atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n* hum: Normalized humidity. The values are divided to 100 (max)\n* windspeed: Normalized wind speed. The values are divided to 67 (max)\n* casual: count of casual users\n* registered: count of registered users\n* cnt: count of total rental bikes including both casual and registered","42696f01":"## Random Forest Regression model","f7c5f72e":"## Data Exploration","cbef9a75":"## Categorical variables to dummy variables","e95a9779":"## Data Visualization"}}