{"cell_type":{"9ba6c2bf":"code","53490ab3":"code","2cb72b7f":"code","8ff599fd":"code","7c97580a":"code","5885856f":"code","3d5ef9f4":"code","6c091e58":"code","b3f613e1":"markdown","c45a1bff":"markdown","eb57dd32":"markdown"},"source":{"9ba6c2bf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize']=[20,8]\n\ndf=pd.read_csv('..\/input\/faulty-steel-plates\/faults.csv')\ndf.head()","53490ab3":"#Import Library\nfrom sklearn import svm\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nX=df.iloc[:,:-1]\ny=df['Other_Faults']\n# Import train_test_split function\nfrom sklearn.model_selection import train_test_split\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test","2cb72b7f":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\n# clf = svm.SVC(kernel='linear').fit(X_train, y_train) # Linear Kernel\n\n# clf = svm.SVC(kernel='linear', C=1,gamma='auto').fit(X, y) \n# clf = svm.SVC(kernel='poly', C=1,gamma='auto').fit(X, y)\nclf = svm.SVC(kernel='rbf', C=1,gamma='auto').fit(X, y)","8ff599fd":"#Predict the response for test dataset\ny_pred = clf.predict(X_test)\n\nfrom sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint('Accuracy is the degree of closeness to true value.')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\n# Model Precision: what percentage of positive tuples are labeled as such?( how valid the results are)\nprint('\\nPrecision is the degree to which an instrument or process will repeat the same value.')\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\n\n# Model Recall: what percentage of complete the results are\nprint('\\nRecall is a metric that quantifies the number of correct positive predictions made out of all positive predictions that could have been made. ')\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","7c97580a":"import seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\n\npipe_df=pd.read_csv('..\/input\/faulty-steel-plates\/faults.csv')\nX=pipe_df.iloc[:,:-1]\ny=pipe_df['Other_Faults']\nsns.countplot(x=\"Other_Faults\", data=pipe_df)\n\n# Splitting the dataset into training and test set.  \nfrom sklearn.model_selection import train_test_split  \nx_train, x_test, y_train, y_test= train_test_split(X, y, test_size= 0.25, random_state=0)\n\n#feature Scaling  \nfrom sklearn.preprocessing import StandardScaler    \nst_x= StandardScaler()   \nx_train= st_x.fit_transform(x_train)    \nx_test= st_x.transform(x_test)  \n\nclassifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )\nclf_fit=classifier.fit(x_train, y_train)\nkn_scores=clf_fit.score(x_test, y_test)\ny_pred=clf_fit.predict(x_test)\n\n##\nplt.figure(figsize=(16,5))\nplt.plot(y_test,y_pred)\nplt.errorbar(y_test, y_pred, fmt='o')\nplt.title(str(clf)+' Score = '+str(kn_scores),fontsize=20)\nplt.ylabel(\"Predict-y\",fontsize=14)\nplt.xlabel('Actual-y',fontsize=14)\nplt.show()\n\n#Creating the Confusion matrix  \nfrom sklearn.metrics import confusion_matrix  \ncm= confusion_matrix(y_test, y_pred)  \n# visualize confusion matrix with seaborn heatmap\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint('Accuracy is the degree of closeness to true value.')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\n# Model Precision: what percentage of positive tuples are labeled as such?( how valid the results are)\nprint('\\nPrecision is the degree to which an instrument or process will repeat the same value.')\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\n\n# Model Recall: what percentage of complete the results are\nprint('\\nRecall is a metric that quantifies the number of correct positive predictions made out of all positive predictions that could have been made. ')\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))\n\nprint('\\nThe F-score, also called the F1-score, is a measure of a model\\'s accuracy on a dataset.')\nprint('\\nSupport is the number of samples of the true response that lie in that class(Imbalanced dataset)')\nfrom sklearn.metrics import classification_report\nprint('\\nclassification_report\\n',classification_report(y_test, y_pred))","5885856f":"# First, we split the data into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=0)\n    \n# We create two lists to keep training and test accuracies. We'll later use them to evaluate an \n# appropriate number of neighbors\ntraining_accuracy = []\ntest_accuracy = []\nerror_rate=[]\n# We define a range of 1 to 40(included) neighbors that will be tested\nneighbors_settings = range(1,40)\n\n# We loop the KNN model through the range of possible neighbors to evaluate which one would be \n# appropriate for this analysis\n\nfor n_neighbors in neighbors_settings:\n    \n    # creating the KNN classifier\n    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n    # fitting the model\n    clf.fit(X_train, y_train)\n    #recording the accuracy of the training set\n    training_accuracy.append(clf.score(X_train, y_train))\n    #recording the accuracy of the test set\n    test_accuracy.append(clf.score(X_test, y_test))\n    ##\n    y_pred=clf_fit.predict(X_test)\n    error_rate.append(np.mean(y_pred != y_test))\n    \n# Data Visualization - Evaluating the accuracy of both the training and the testing sets against \n# n_neighbors\n    \nplt.plot(neighbors_settings, training_accuracy, label='Accuracy of the Training Set')\nplt.plot(neighbors_settings, test_accuracy, label='Accuracy of the Test Set')\nplt.title('Accuracy vs K-value',fontsize=24)\nplt.ylabel('Accuracy',fontsize=24)\nplt.xlabel('Number of Neighbors',fontsize=24)\nplt.legend()","3d5ef9f4":"plt.plot(neighbors_settings, error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)\nplt.title('Error Rate vs K-value',fontsize=24)\nplt.ylabel('error_rate',fontsize=24)\nplt.xlabel('Number of Neighbors',fontsize=24)\nplt.legend()","6c091e58":"# Find the K-neighbors of a point.\nfrom sklearn.neighbors import NearestNeighbors\nneigh = NearestNeighbors(n_neighbors=1)\nneigh.fit(X)\n\n##\nprint(neigh.kneighbors(X))\nprint(neigh.kneighbors(X, return_distance=False))\n\n##\n# A = neigh.kneighbors_graph(X)  # Compute the (weighted) graph of k-Neighbors for points in X.\n# A = neigh.radius_neighbors_graph(X) #Compute the (weighted) graph of Neighbors for points in X.","b3f613e1":"# SVC","c45a1bff":"# KNeighborsClassifier\n\n* n_neighbors: To define the required neighbors of the algorithm. Usually, it takes 5.\n* metric='minkowski': This is the default parameter and it decides the distance between the points.\n* p=2: It is equivalent to the standard Euclidean metric.","eb57dd32":"# Load"}}