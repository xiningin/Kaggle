{"cell_type":{"029988fd":"code","527af570":"code","03823674":"code","98d84700":"code","cbd0be4d":"code","e9f98d2a":"code","f8355188":"code","a94cdecf":"code","f61c2b73":"code","b74504c3":"code","86073b88":"code","bfa85e00":"code","3171f430":"code","56649994":"code","f9716e43":"code","498ff803":"code","f9b44b15":"code","967142ef":"code","8261c43b":"code","c7c5421d":"code","11039ea4":"code","9a757ad6":"markdown","7536d868":"markdown"},"source":{"029988fd":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport shutil\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport cv2\nfrom os.path import isfile, join\nfrom IPython.display import Image, clear_output\nimport subprocess\nimport torch","527af570":"#!rm *\n#!rm -r \/kaggle\/working\/yolov5","03823674":"#!mkdir -p \/kaggle\/working\/sample1\n!mkdir -p \/kaggle\/working\/sample2","98d84700":"import shutil\nshutil.copytree('\/kaggle\/input\/vehicle-images-dataset\/vehicle_images\/vehicle_images','\/kaggle\/working\/sample1')","cbd0be4d":"print(os.listdir('\/kaggle\/input'))\nprint(os.listdir('\/kaggle\/working'))\n#print(os.listdir('\/kaggle\/working\/sample1'))","e9f98d2a":"if 'yolov5' in os.listdir('\/kaggle\/working\/'):\n    print('yolov5 exists')\nelse:\n    shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5','\/kaggle\/working\/yolov5') \n    print('yolov5 copytree')","f8355188":"os.chdir('\/kaggle\/working\/yolov5')","a94cdecf":"clear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","f61c2b73":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ..\/sample1 --save-txt","b74504c3":"from matplotlib import animation,rc\nrc('animation',html='jshtml')","86073b88":"def create_animation(ims):\n    fig=plt.figure(figsize=(14,14))\n    plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[0],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval=1000\/\/5)","bfa85e00":"print(os.listdir('\/kaggle\/working\/yolov5\/runs\/detect\/')) ","3171f430":"print(os.listdir('\/kaggle\/working\/yolov5\/runs\/detect\/exp\/')[0:10])  ### after YOLO\n#print(os.listdir('\/kaggle\/working\/sample1'))    ### before YOLO","56649994":"!rm -rf \/kaggle\/working\/sample2","f9716e43":"shutil.copytree('\/kaggle\/working\/yolov5\/runs\/detect\/exp\/','\/kaggle\/working\/sample2') ","498ff803":"print(os.listdir('\/kaggle\/working\/sample2')[0:10])","f9b44b15":"paths0=[]\nfor file in os.listdir('\/kaggle\/working\/sample2'):\n    paths0+=[os.path.join('\/kaggle\/working\/sample2',file)]\npaths0[0:5]","967142ef":"paths1=[]\nfor item in paths0:\n    if item[-4:]=='.jpg':\n        paths1+=[item]","8261c43b":"images0=[]\nfor i in tqdm(range(0,len(paths1),10)):\n    images0+=[cv2.imread(paths1[i])]","c7c5421d":"def create_animation(ims):\n    fig=plt.figure(figsize=(6,4))\n    plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[0],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval=1000\/\/2)","11039ea4":"create_animation(np.array(images0))","9a757ad6":"# Copy Source Images","7536d868":"# YOLOv5"}}