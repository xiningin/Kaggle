{"cell_type":{"8aff00cd":"code","418a15c6":"code","b2e8b3ee":"code","4e4d5690":"code","fca1fbe7":"code","e230c48a":"code","37fe84b5":"code","d5905449":"code","e6503c39":"code","3020123c":"code","2897df2d":"code","4d7f2e7f":"code","bbb958e8":"code","6bdd4d48":"code","dd84fc9b":"code","f04aa748":"code","386c8af9":"code","59967b9e":"markdown","e93e36a7":"markdown","84763b4d":"markdown","08c5dbb4":"markdown","c7d6222d":"markdown","e5ca3529":"markdown","94f2981c":"markdown","e0744b2b":"markdown","0f2d8238":"markdown","c7f7e2af":"markdown","a97a864f":"markdown","c52ec562":"markdown","713ecbde":"markdown"},"source":{"8aff00cd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\n%matplotlib inline\npd.set_option('display.max_rows', 500)\npd.get_option(\"display.max_columns\",500)","418a15c6":"folder_path = '..\/input\/'\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')\ntrain_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\n\n\ndf = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')","b2e8b3ee":"pd.DataFrame(df.groupby(\"addr2\").count()[\"TransactionID\"])","4e4d5690":"import datetime\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\ndf['TransactionDT'] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\ndf['hour'] = df['TransactionDT'].dt.hour","fca1fbe7":"df.groupby(\"addr2\").mean()[\"hour\"]","e230c48a":"df.groupby(\"addr2\").mean()[\"hour\"] - 14.049229","37fe84b5":"def change(addr):\n    if  addr==60.0:\n        return 1\n    elif addr==96.0:\n        return 1\n    elif addr == np.nan:\n        return np.nan\n    \n    else:\n        return 0\n\ndf[\"Europe\"] = df[\"addr2\"].map(change)","d5905449":"df.groupby(\"Europe\").count().isFraud","e6503c39":"586818*0.034585 + 3722*0.098872","3020123c":"df.groupby(\"Europe\").mean().isFraud","2897df2d":"def change(addr):\n    if  addr==16.0:\n        return 1\n    elif addr==65.0:\n        return 1\n    elif addr == np.nan:\n        return np.nan\n    \n    else:\n        return 0\n\ndf[\"Asia\"] = df[\"addr2\"].map(change)","4d7f2e7f":"pd.DataFrame(df[\"Asia\"]).info()","bbb958e8":"df.groupby(\"Asia\").isFraud.sum()","6bdd4d48":"df.groupby(\"Asia\").isFraud.mean()","dd84fc9b":"def change(addr):\n    if  addr==31.0:\n        return 1\n    elif addr==32.0:\n        return 1\n    elif addr == np.nan:\n        return np.nan\n    \n    else:\n        return 0\n\ndf[\"North America\"] = df[\"addr2\"].map(change)","f04aa748":"df.groupby(\"North America\").isFraud.mean()","386c8af9":"plt.ylim(0,0.4)\nplt.subplot(2,2,1)\nplt.bar([0,1],df.groupby(\"Asia\").mean().isFraud.values)\n\n\nplt.subplot(2,2,2)\nplt.ylim(0,0.4)\nplt.bar([0,1],df.groupby(\"Europe\").mean().isFraud.values)\n\n\nplt.subplot(2,2,3)\nplt.ylim(0,0.4)\nplt.bar([0,1],df.groupby(\"North America\").mean().isFraud.values)","59967b9e":"# Conclusion\nThis identification is meningful to some degree, because we can find the gap between Europe data and other data.\n\nThe problem is that America has some standart time, so some error is appearing, for example, we can not boastfuly say that 16 is Russia.\n\nI want to apply this result for futher data_engineering.","e93e36a7":"We can find the difference between them.","84763b4d":"## the appearance of addr2","08c5dbb4":"# General\nI'm very sorry that I changed the name of this kernel. This is becuase I often update this kernel and the content is changing.\n\nThanks to VESTA, we can know about what the addr2 data is.\n\nhttps:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/101203#latest-596566\n\nIn this discussion(the URL\u2191), VESTA person says \"addr2 as billing country\".\n\nTherefore, I want to identify the country and use data more efficiently.\n\nI wish that this sharing help other kagglers!","c7d6222d":"### make hour column from transactionDT\n\nAs I said, I consulted with the discussion. Thanks for people who excite the discussion. \n","e5ca3529":"Various country data is used.\n\nI use only the countries which have more tha 50 transaction data, because I can not guess the precise standard time if the amount of data is small.\n\nThat is, 16.0 31.0 32.0 60.0 65.0 87.0 96.0","94f2981c":"There is a gap between them.","e0744b2b":"# 16,65\nOne of them may be Russia, but it is uncertain.\n\nThe possibility of china also exist.\n\nHowever, we can say that these two countries are similar place to Russia or China.\n\nI name them Asia group.","0f2d8238":"# making future\nAt first, I made Europe future.\n\nSoon, I'll increase it.","c7f7e2af":"## speculation of standard time\nAt first, the country \"87.0\" has 520481 transaction.\n\nThis must be the U.S.\n\nI checked the gap between the U.S. and others.","a97a864f":"# 31,32\nThe standard time is similar to America.\nJuding from country size, 32 should be Canada. \n\nHowever, it may be Mexico.","c52ec562":"# 60,96\nThey are about -6 hour. \nThrefore, it should be Europe country.","713ecbde":"# what already is known\n\nI consulted with this discussion.\n\nhttps:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/100400#579001\n\nWe can know the hour data from transactionDT.\n\nTherefore, the gap of standard time should be supeculated."}}