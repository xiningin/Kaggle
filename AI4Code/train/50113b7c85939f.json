{"cell_type":{"a59d5b2b":"code","4d36c9ae":"code","3a143df5":"code","54d1a8c4":"code","d434be6a":"markdown","5c9b0465":"markdown","1ab4f71f":"markdown"},"source":{"a59d5b2b":"from pyspark.ml.classification import LinearSVC\nimport sklearn.metrics as metrics\nimport pandas as pd\nfrom plotnine import *\nfrom plotnine.data import meat\nfrom mizani.breaks import date_breaks\nfrom mizani.formatters import date_format\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StandardScaler, StringIndexer, OneHotEncoder, Imputer, VectorAssembler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nimport mlflow\nimport mlflow.spark\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\nfrom pyspark.ml.linalg import Vectors\n\n\n# setting the parameters\nmaxIter = 10    #max itteration is the number of trees\n  \n \n # we start with mlflow.start_run() which essentially start tracking what we are doing in this notebook in databricks\nwith mlflow.start_run():\n    indexers = list(map(lambda c: StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid = \"keep\"), categoricals))\n    ohes = list(map(lambda c: OneHotEncoder(inputCol=c + \"_idx\", outputCol=c+\"_class\"), categoricals))\n    imputers = Imputer(inputCols = numerics, outputCols = numerics)\n    featureCols = list(map(lambda c: c+\"_class\", categoricals)) + numerics\n    \n    # Define vector assemblers\n    labelCol = \"default_loan\"\n    model_matrix_stages = indexers + ohes + \\\n                          [imputers] + \\\n                          [VectorAssembler(inputCols=featureCols, outputCol=\"features\"), \\\n                           StringIndexer(inputCol= labelCol, outputCol=\"label\")]\n    \n       \n    # here, we define a lsvc model.\n    \n    lsvc = LinearSVC(maxIter=maxIter)\n    \n    params = ParamGridBuilder() \\\n             .addGrid(lsvc.regParam, [0.1, 0.99, 10, 100]) \\\n             .build()\n\n    \n    # Chain indexer and lsvc in a Pipeline\n    #now, we define a pipline which includes everything from standardazing the data, imputing missing values and encoding for categorical columns\n    pipeline_lsvc = Pipeline(stages=model_matrix_stages+[lsvc])\n    \n    # Train model. This also runs the indexer. \n    cv = CrossValidator(estimator=pipeline_lsvc, estimatorParamMaps=params, evaluator=BinaryClassificationEvaluator(), numFolds=10)\n    lsvc_model = cv.fit(train)\n      \n    ## here we log the auc values and the area under the curve for the models metrics as we defined before for training as well as validation dataset\n#    mlflow.log_metric(\"train_auc\", auc(lsvcm_train))\n#    mlflow.log_metric(\"valid_auc\", auc(lsvcm_valid))","4d36c9ae":"def extract(row):\n  return (row.remain,) + (row.label,) + (row.prediction,)\n\ndef score(model,data):\n  pred = model.transform(data).select(\"remain\", \"label\", \"prediction\")\n  pred = pred.rdd.map(extract).toDF([\"remain\", \"label\", \"prediction\"])\n  return pred\n\ndef auc(pred):\n  metric = BinaryClassificationMetrics(pred.select(\"prediction\", \"label\").rdd)\n  return metric.areaUnderROC\n    \n    \n    ## Evaluate and Log Metrics  (here we score the customers)\nlsvcm_train = score(lsvc_model, train)\nlsvcm_valid = score(lsvc_model, valid)\n    \n    \nprint( \"lsvcM Training AUC :\" + str( auc(lsvcm_train)))\nprint( \"lsvcM Validation AUC :\" + str(auc(lsvcm_valid)))\n  \n    ## here we log the auc values and the area under the curve for the models metrics as we defined before for training as well as validation dataset\n#    mlflow.log_metric(\"train_auc\", auc(lsvcm_train))\n#    mlflow.log_metric(\"valid_auc\", auc(lsvcm_valid))","3a143df5":"lsvcm_valid = lsvc_model.transform(valid).select(\"remain\", \"label\", \"prediction\")\n# lsvcm_valid= pred.rdd.map(extract).toDF([\"remain\", \"label\", \"prediction\"])\npandas_df = lsvcm_valid.toPandas()\ntxt = 'This table represents the \"CONFUSION MATRIX\" from LINEAR SUPPORT VECTOR MACHINE'\nprint(txt.title())\npd.crosstab(pandas_df.label, pandas_df.prediction, values=pandas_df.remain, aggfunc=\"count\").round(2)","54d1a8c4":"pandas_df_sum_net = glm_valid.groupBy(\"label\", \"prediction\").agg((sum(col(\"remain\"))).alias(\"sum_net\")).toPandas()\r\ntxt = 'This table represents the \"SUM NET\" from LINEAR SUPPORT VECTOR MACHINE'\r\nprint(txt.title())\r\npd.crosstab(pandas_df_sum_net.label, pandas_df_sum_net.prediction, values=pandas_df_sum_net.sum_net , aggfunc=\"sum\").round(2)\r\n","d434be6a":"# LINEAR SUPPORT VECTOR MACHINE","5c9b0465":"# Machine Learning Codes for Credit Scoring - LINEAR SUPPORT VECTOR MACHINE!\n\nFor citation: https:\/\/doi.org\/10.1016\/j.eswa.2021.114835 (Journal - Expert Systems with Applications.)\n\nAsk for full-text in [ResearchGate](https:\/\/www.researchgate.net\/profile\/Afshin-Ashofteh-2)\n\nAfshin Ashofteh [email](aashofteh@novaims.unl.pt)\n\nSubject: Credit Risk and Credit Scoring.\n\nDatasource: loan.csv - Each loan includes applicant information provided by the applicant as well as current loan status (Current, Late, Fully Paid, etc.) and latest payment information.\n\n","1ab4f71f":"Links: \n*[ResearchGate](https:\/\/www.researchgate.net\/profile\/Afshin-Ashofteh-2)\n*[Kaggle](https:\/\/www.kaggle.com\/aashofteh)\n*[Google Scholar](https:\/\/scholar.google.com\/citations?user=oIa1W0gAAAAJ&hl=en)\n*[Data Science Discussion Group](https:\/\/www.linkedin.com\/groups\/12420006)\n*[email](aashofteh@novaims.unl.pt)"}}