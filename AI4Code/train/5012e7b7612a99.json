{"cell_type":{"4a314bb1":"code","38e24b83":"code","a37fbc5f":"code","b4791ff2":"code","1cd4f407":"code","0e94e2be":"code","a4e4f954":"code","0f9dbe17":"code","8c5bdc02":"code","b84bfaca":"code","129e5448":"code","80988c30":"code","7581baf8":"code","43837e50":"code","05afb103":"code","faadade7":"code","30b4f602":"code","a471f079":"code","b47ce957":"code","8c0ca7c8":"code","e72ed478":"code","e7d7b843":"code","2c325555":"code","9428c265":"code","b45cf560":"code","4211a411":"code","84ce1150":"code","76773c08":"code","85c244b8":"code","8a63ef67":"code","74bebbe2":"code","078ed14b":"markdown","8fa73cf9":"markdown","e3818485":"markdown","c8756bde":"markdown","b9bc64f9":"markdown","355cee94":"markdown","f15e37f1":"markdown","537b923a":"markdown","ff167b3f":"markdown","c35ceb3a":"markdown","c0e8ad38":"markdown","eaae2532":"markdown"},"source":{"4a314bb1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, gc\nimport random\nimport datetime\n\nfrom tqdm import tqdm_notebook as tqdm\n\n# matplotlib and seaborn for plotting\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\n\nimport lightgbm as lgb","38e24b83":"path = '..\/input\/ashrae-energy-prediction'\n# Input data files are available in the \"..\/input\/\" directory.\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a37fbc5f":"%%time\n# unimportant features (see importance below)\nunimportant_cols = ['wind_direction', 'wind_speed', 'sea_level_pressure']\ntarget = 'meter_reading'\n\ndef load_data(source='train', path=path):\n    ''' load and merge all tables '''\n    assert source in ['train', 'test']\n    \n    building = pd.read_csv(f'{path}\/building_metadata.csv', dtype={'building_id':np.uint16, 'site_id':np.uint8})\n    weather  = pd.read_csv(f'{path}\/weather_{source}.csv', parse_dates=['timestamp'],\n                                                           dtype={'site_id':np.uint8, 'air_temperature':np.float16,\n                                                                  'cloud_coverage':np.float16, 'dew_temperature':np.float16,\n                                                                  'precip_depth_1_hr':np.float16},\n                                                           usecols=lambda c: c not in unimportant_cols)\n    df = pd.read_csv(f'{path}\/{source}.csv', dtype={'building_id':np.uint16, 'meter':np.uint8}, parse_dates=['timestamp'])\n    df = df.merge(building, on='building_id', how='left')\n    df = df.merge(weather, on=['site_id', 'timestamp'], how='left')\n    return df\n\n","b4791ff2":"# load and display some samples\ntrain = load_data('train')\ntrain.sample(7)","1cd4f407":"test = load_data('test')\ntest.sample(7)","0e94e2be":"# the counts above expose the missing data (Should we drop or refill the missing data?)\nprint(\"Ratio of available data (not NAN's):\")\ndata_ratios = train.count()\/len(train)\ndata_ratios","a4e4f954":"class ASHRAE3Preprocessor(object):\n    @classmethod\n    def fit(cls, df, data_ratios=data_ratios):\n        cls.avgs = df.loc[:,data_ratios < 1.0].mean()\n        cls.pu_le = LabelEncoder()\n        cls.pu_le.fit(df[\"primary_use\"])\n\n    @classmethod\n    def transform(cls, df):\n        df = df.fillna(cls.avgs) # refill NAN with averages\n        df['primary_use'] = np.uint8(cls.pu_le.transform(df['primary_use']))  # encode labels\n\n        # expand datetime into its components\n        df['hour'] = np.uint8(df['timestamp'].dt.hour)\n        df['day'] = np.uint8(df['timestamp'].dt.day)\n        df['weekday'] = np.uint8(df['timestamp'].dt.weekday)\n        df['month'] = np.uint8(df['timestamp'].dt.month)\n        df['year'] = np.uint8(df['timestamp'].dt.year-2000)\n        \n        # parse and cast columns to a smaller type\n        df.rename(columns={\"square_feet\": \"log_square_feet\"}, inplace=True)\n        df['log_square_feet'] = np.float16(np.log(df['log_square_feet']))\n        df['year_built'] = np.uint8(df['year_built']-1900)\n        df['floor_count'] = np.uint8(df['floor_count'])\n        \n        # remove redundant columns\n        for col in df.columns:\n            if col in ['timestamp', 'row_id']:\n                del df[col]\n    \n        # extract target column\n        if 'meter_reading' in df.columns:\n            df['meter_reading'] = np.log1p(df['meter_reading']).astype(np.float32) # comp metric uses log errors\n\n        return df\n        \nASHRAE3Preprocessor.fit(train)","0f9dbe17":"train = ASHRAE3Preprocessor.transform(train)\ntrain.sample(7)","8c5bdc02":"train.dtypes","b84bfaca":"%%time\nfig, ax = plt.subplots(figsize=(16,8))\n# use a ranked correlation to catch nonlinearities\ncorr = train[[col for col in train.columns if col != 'year']].sample(100100).corr(method='spearman')\n_ = sns.heatmap(corr, annot=True,\n                xticklabels=corr.columns.values,\n                yticklabels=corr.columns.values)","129e5448":"# force the model to use the weather data instead of dates, to avoid overfitting to the past history\nfeatures = [col for col in train.columns if col not in [target, 'year', 'month', 'day']]","80988c30":"# Shuffle:\nn = train.shape[0]\nix = np.random.permutation(n)","7581baf8":"# Training data:\nntrain = 15000000\nnvalid = 5000000\ntr_x, tr_y = train[features].iloc[ix[:ntrain]], train[target][ix[:ntrain]]\nva_x, va_y = train[features].iloc[ix[ntrain:(ntrain+nvalid)]], train[target][ix[ntrain:(ntrain+nvalid)]]","43837e50":"xtr = tr_x.values\nytr = tr_y.values\nxval = va_x.values\nyval = va_y.values","05afb103":"print(xtr.shape)\nprint(ytr.shape)\nprint(xval.shape)\nprint(yval.shape)","faadade7":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nxtr = scaler.fit_transform(xtr)\nxval = scaler.transform(xval)","30b4f602":"print(xtr.mean())\nprint(xtr.std())\nprint(xtr.shape)\n\nprint(xval.mean())\nprint(xval.std())\nprint(xval.shape)","a471f079":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import backend as K","b47ce957":"def rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))","8c0ca7c8":"model = keras.Sequential()\n\n# Linear model that obtains 1.90 in the public ranking:\n#model.add(keras.layers.Dense(1, activation=\"linear\", input_shape=(13,)))\n\n# More complex network that obtains 1.27 in the public ranking:\nmodel.add(keras.layers.Dense(1000, activation=\"relu\", input_shape=(13,)))\n#model.add(keras.layers.Dense(1000, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(1))\n\nmodel.compile(optimizer=keras.optimizers.Adam(1.e-2), loss='mse', metrics=[rmse])\nmodel.summary()","e72ed478":"nepochs = 6\nhistory = model.fit(xtr, \n                    ytr, \n                    epochs=nepochs, \n                    validation_data=(xval, yval),\n                    batch_size=10000)","e7d7b843":"hd = history.history\n\nepochs = range(1, nepochs+1)\n\nplt.figure(figsize=(12,6))\n\nplt.subplot(1,2,1)\nplt.plot(epochs, hd['rmse'], \"r\", label=\"train\")\nplt.plot(epochs, hd['val_rmse'], \"b\", label=\"valid\")\nplt.grid(True)\nplt.xlabel(\"epoch\")\nplt.ylabel(\"rmse\")\nplt.title(\"RMSE\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(epochs, hd['loss'], \"r\", label=\"train\")\nplt.plot(epochs, hd['val_loss'], \"b\", label=\"valid\")\nplt.grid(True)\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"Loss\")\nplt.legend()\n\nplt.show()","2c325555":"test = ASHRAE3Preprocessor.transform(test)\ntest.sample(7)","9428c265":"tst_x = test[features].iloc[:]","b45cf560":"xtst = tst_x.values\nprint(xtst.shape)","4211a411":"xtst = scaler.transform(xtst)","84ce1150":"print(xtst.mean())\nprint(xtst.std())\nprint(xtst.shape)","76773c08":"tst_preds = model.predict(xtst)\nprint(tst_preds.shape)","85c244b8":"submission = pd.read_csv(f'{path}\/sample_submission.csv')\nsubmission['meter_reading'] = np.clip(np.expm1(tst_preds), a_min=0, a_max=None) # clip min at zero","8a63ef67":"submission.head(9)","74bebbe2":"submission.to_csv('submission.csv', index=False)","078ed14b":"### Neural networks with tensorflow:\n\nThe data pre-processing is based on this notebook: https:\/\/www.kaggle.com\/hmendonca\/starter-eda-and-feature-selection-ashrae3","8fa73cf9":"### Variable normalization:","e3818485":"### Function to load the data:","c8756bde":"### Test data:","b9bc64f9":"### Data preprocessing:\n\nImportant: note that the target variable is computed as the logarithm of the column \"meter_reading\".","355cee94":"### Training data:","f15e37f1":"### Neural network model with keras:","537b923a":"### Train-validation partition:","ff167b3f":"Note that we have to compute the exponential of the predictions, as we used the logarithm of the target to train the network:","c35ceb3a":"### Predictions on the test set:","c0e8ad38":"### Feature ranked correlation:","eaae2532":"The next function computes the RMSE to evaluate the model. Note that, as we have taken the logarithm of the target, this value is equivalent to the RLMSE that kaggle uses for the evaluation. The function is from this notebook: https:\/\/www.kaggle.com\/isaienkov\/keras-nn-with-embeddings-for-cat-features-1-24 "}}