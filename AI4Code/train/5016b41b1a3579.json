{"cell_type":{"6dfd0815":"code","4b921e9b":"code","44944e97":"code","24066db7":"code","142ff88c":"code","6a14dce0":"code","4e25a559":"code","38664a89":"code","1d8aa783":"code","860954df":"code","7dc561d5":"code","a1279570":"code","957804ca":"code","6c5ac524":"code","679fe5e1":"markdown","5376d1f4":"markdown","211aa492":"markdown","65456397":"markdown","29174710":"markdown","3a3b7b7f":"markdown","6c3d86f2":"markdown","74c6fe62":"markdown","3e3ce2fb":"markdown","a9fb0227":"markdown","fb69e2b0":"markdown","7fb44b94":"markdown","52b6078f":"markdown","1bbf1835":"markdown","594078a2":"markdown","c206a5fe":"markdown","a11edf7d":"markdown","24725e25":"markdown","36b7e3f6":"markdown","4da70561":"markdown"},"source":{"6dfd0815":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","4b921e9b":"#Load data set\ndataFrame = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","44944e97":"#number of rows and columns\ndataFrame.shape","24066db7":"dataFrame.head(5)","142ff88c":"dataFrame.isnull().values.any()","6a14dce0":"dataFrame.describe()","4e25a559":"count_by_class = pd.value_counts(dataFrame['Class'], sort = True)\n\n## % of Fraud observations\nprint(\"\")\nprint(\"% of Fraud (outlier) cases in dataset =\",(count_by_class[1]\/(count_by_class[1]+count_by_class[0])) * 100)\nprint(\"\")\n\n##Graphical view\ncount_by_class.plot(kind='bar', color=\"g\")\nplt.title(\"Distribution of Normal Vs Fraud observations in dataset.\")\nplt.xlabel(\"Classes\")\nplt.xticks(range(2), [\"Normal\", \"Fraud\"])\nplt.ylabel(\"Number of observations\");","38664a89":"f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True)\nplt.xlabel('Time of Transaction')\nplt.ylabel('Amount in Transaction')\n\nfraud_observations = dataFrame[dataFrame['Class']==1]\nax1.scatter(fraud_observations.Time, fraud_observations.Amount, color='r')\nax1.set_title('Fraud')\n\nnormal_observations = dataFrame[dataFrame['Class']==0]\nax2.scatter(normal_observations.Time, normal_observations.Amount, color='g')\nax2.set_title('Normal')\n\n\nplt.show()","1d8aa783":"correlation_matrix = dataFrame.corr()\nprint(correlation_matrix)","860954df":"fig = plt.figure(figsize=(31,31))\nsns.heatmap(correlation_matrix)\nplt.show()","7dc561d5":"from sklearn.model_selection import train_test_split\ny = dataFrame['Class']\nX = dataFrame.drop('Class', axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)","a1279570":"print (\" Training data set : \",X_train.shape)\nprint (\" Test data set : \",X_test.shape)\nprint (\" Number of Fraud cases in training set : \",len(y_train[y_train==1]))\nprint (\" Number of Fraud cases in test set : \",len(y_test[y_test==1]))","957804ca":"from sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\n\nfraud_fraction = len(y_train[y_train==1])\/float(len(y_train[y_train==0]))\nnumber_of_train_samples=len(X_train)\n\n# fit the model\nclf=IsolationForest(n_estimators=100, max_samples=number_of_train_samples,contamination=fraud_fraction,random_state=None, verbose=0)\nclf.fit(X_train)\n\n#predict on training set\ny_pred_train = clf.predict(X_train)\n\n#predict on test set\ny_pred_test = clf.predict(X_test)\n\n#Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\ny_pred_train[y_pred_train == 1] = 0\ny_pred_train[y_pred_train == -1] = 1\n\ny_pred_test[y_pred_test == 1] = 0\ny_pred_test[y_pred_test == -1] = 1\n\n\nprint(\"-----------------------------------------------------------\")\nprint(\" Score on Test set\")\nprint(\" Error count : \",(y_test!=y_pred_test).sum())\nprint(\" Accuracy Score:\")\nprint(accuracy_score(y_test,y_pred_test))\nprint(\" Classification Report:\")\nprint(classification_report(y_test,y_pred_test))\n\nprint(\"-----------------------------------------------------------\")\nprint(\" Score on training set\")\nprint(\" Error count : \",(y_train != y_pred_train).sum())\nprint(\" Accuracy Score:\")\nprint(accuracy_score(y_train,y_pred_train))\nprint(\" Classification Report:\")\nprint(classification_report(y_train,y_pred_train))","6c5ac524":"from sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.neighbors import LocalOutlierFactor\n\nfraud_fraction = len(y_train[y_train==1])\/float(len(y_train[y_train==0]))\nnumber_of_train_samples=len(X_train)\n\n# fit the model\nclf=LocalOutlierFactor(n_neighbors=20, algorithm='auto',leaf_size=30, metric='minkowski',p=2, metric_params=None, contamination=fraud_fraction)\nclf.fit(X_train)\n\n\n#predict on training set\ny_pred_train = clf.fit_predict(X_train)\n\n#predict on test set\ny_pred_test = clf.fit_predict(X_test)\n\n\n#Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\ny_pred_train[y_pred_train == 1] = 0\ny_pred_train[y_pred_train == -1] = 1\n\ny_pred_test[y_pred_test == 1] = 0\ny_pred_test[y_pred_test == -1] = 1\n\n\nprint(\"-----------------------------------------------------------\")\nprint(\" Score on Test set\")\nprint(\" Error count : \",(y_test!=y_pred_test).sum())\nprint(\" Accuracy Score:\")\nprint(accuracy_score(y_test,y_pred_test))\nprint(\" Classification Report:\")\nprint(classification_report(y_test,y_pred_test))\n\nprint(\"-----------------------------------------------------------\")\nprint(\" Score on training set\")\nprint(\" Error count : \",(y_train != y_pred_train).sum())\nprint(\" Accuracy Score:\")\nprint(accuracy_score(y_train,y_pred_train))\nprint(\" Classification Report:\")\nprint(classification_report(y_train,y_pred_train))","679fe5e1":"### Inspect Shape of data set","5376d1f4":"### At this stage data looks good and can be used for building initial anomaly model and evaluate\/compare mode performance.","211aa492":" #### Heat map shows small correlation between Features, not alarming.","65456397":"### 1) Isolation Forest algorithm","29174710":"### Inspect percentage of Fraud and Normal cases in data set","3a3b7b7f":"### Inspect Missing data in data set","6c3d86f2":"### Observations\n - Isolation Forest has slightly better accuracy compared to LocalOutlierFactor\n - Isolation Forest has lesser number of error counts compared to LocalOutlierFactor\n \nOverall, Isolation Forest appears to be better choice. However, deep learning approach may outperform Isolation Forest but it will require higher compute power, training time  and larger data-set.\n\n","74c6fe62":"### 2) LocalOutlierFactor algorithm","3e3ce2fb":"**** No  visible pattern between Time, Amount and Fraud","a9fb0227":"## 4. Implementation ","fb69e2b0":"#### Split data into training-set and test-set [80 -20 ratio]","7fb44b94":"##### Data set has no missing data.","52b6078f":"### Inspect Correlation between features in data set","1bbf1835":"## Getting started - Anomaly detection\nIn this post we will have a brief overview of what is Anomaly detection, Types of anomaly (broad categories), Detection techniques and Implementation using Python. Objective of this post is to to provide baby-step to developers and beginners to get started conceptually as well as working code in Python.\n\n## 1. What is Anomaly detection?\nAnomaly detection is about \u201cIdentifying unusual data pattern that does not conform to expected behavior\u201d. Although not all detected anomalies are possibly harmful, but identifying such outliers and bringing to notice is perhaps crucial. In most cases training a model to detect anomaly is very challenging, because outlier occurrences in data set are very sparse (for example 0.001%) thus creating bias. \n## 2. Types of anomalies\n### a.\tPoint anomalies: \nAn instance of data (observation) which is too far from rest of observations. \nLet\u2019s say, in a time-series a data point is deviating off from other observations by 5 standard deviation, this data can be considerd as outlier (anomaly) because system is not expecting such behaviour. \n\nLet's use simple example to illustrate -\n    \n   An IoT device records temperature in Toronto, in month of January: \n\n    1. \u201c\u201310 centigrade, at 8:00 AM\u201d, \n    2. \u201c-10 centigrade, at 8:15 AM\u201d, \n    3. \u201c-30 centigrade, at 8:30 AM\u201d, \n    4. \u201c-09 centigrade, at 8:45 AM\u201d.  \n    \nIn this time-series \u201c-30 centigrade, at 8:30 AM\u201d is an outlier or anomaly, because system does not expect a temperature variation by 20 centigrade in time span of 15 minnutes.  In this case, above anomaly may be due to signal-noise, and data point is worth special treatment.\n\n### b.\tContextual anomalies: \nA data point does not conform to normal behaviour in defined Context.  In this case \u201cContext\u201d acts as pivot in determining whether a data point is outlier.\n\nLet\u2019s build on previous example -\n    An IoT device records temperature in Toronto, in month of June:\n\n    1. \u201c\u201310 centigrade, at 8:00 AM\u201d.\n    2. \u201c\u201310 centigrade, at 8:15 AM\u201d.\n    3. \u201c\u201310 centigrade, at 8:30 AM\u201d.\n\nIn this case, data points \u201c\u201310 centigrade\u201d in month June (Context) is outlier. \nAlthough IoT device consistently records \u201c-10 centigrade\u201d, and there is no drastic deviation between successive readings, data in given **Context** (Season summer) does not conform to normal behaviour.  \u201c-10 centigrade\u201d is normal in month of January, but it is an outlier in month of June. \nIn above case, data is deemed as anomaly based on **Context**.  For example this might happen because IoT device is broken and not recordings true temperature.\n\n### c.\tCollective anomalies: \n\u201cCollection of related data points\u201d does not conform to normal behaviour. The individual data points in collection may or may not be anomalies by themselves, but their combined occurrence as a collection decides whether it is anomalous.\n\nLet\u2019s build on previous example -\n a) An IoT device (device#1) records temperature in Toronto, in month of April:  \n    1. \u201c15.4 centigrade, at 12:00 PM\u201d.\n    2. \u201c15.5 centigrade, at 12:15 PM\u201d.\n    3. \u201c15.6 centigrade, at 12:30 PM\u201d.\n\nb) An IoT device(device#2), at same location and time as first IoT (device#1), records snow flurries:  \n    1. \u201c0.3 centimeter, at 12:00 PM\u201d.\n    2. \u201c0.2 centimeter, at 12:15 PM\u201d.\n    3. \u201c0.2 centimeter, at 12:30 PM\u201d.\n\nIt is possible to get snow flurries in month of April, also temperature might rise to 15 centigrade (early summer glimpse). But both, flurries and 15 centigrade high temperature does not occur simultaneously. \n\nIndependent data\/readings from both IoTs appear valid Contextually (Seasonal behaviour of April) as well as valid Time-series (successive data are within deviation range).\n\nHowever, if data from both IoT are integrated together, then as Collection data does not conform to reality. Because at same time and same location it is very unlikely to have temperature as high as \u201c15 centigrade\u201d and \u201cSnow flurries\u201d together. \n\nIn above example data is deemed as anomaly because Collectively (collection unit) it is not normal behaviour, although it may be normal contextually or as individual data point. In such case, data anomaly may raise suspicion that one of the IoT device is not correct, because they conflict each other as collective unit.\n\n\n\n## 3. Commonly used detection techniques\n### a. Statistical approach: \nThis is the simplest approach to identify irregularities based on statistical properties such as z-score, distribution, mean, quartile etc. \nLet take a very simple example, say we have a time-series data and want to flag fluctuation if any in new data points. For such case, you can compute rolling average (. i.e. mean\/average of rolling window), and when new data arrives compare it with current rolling average. If deviation is more than specified threshold then flag the new data point as outlier. \nStatistical approach is useful in simple use case where you can predefine criteria and check data against it, anything which does not satisfy criteria is outlier. \nStatistical approach cannot handle complex situations, for example malicious adversaries constantly and slowly (small incremental value) inject abnormal behaviour. Statistical approach can only handle simple use cases. \nAlso, as number of feature (dimensions) increases, it becomes very challenging for Statistical approach to adapt (learn) to changing dynamics.\n### b.\tMachine learning approach: \n####  Few approaches to name are - \n  * Density based - This approach is useful when data points occur around dense neighbourhood.  The nearest set of data points are evaluate based on measure of distance, for example Euclidian distance or similar measure based on data type. If data is far away from neighbourhood then it will be considered as outlier.\n\n  * Cluster based (Unsupervised) \u2013 Data points are similar and tend to belong to similar group (cluster).  Distance of data point from centroid of cluster determines which cluster does data belong. Data instances that fall outside of groups could potentially be marked as anomalies. K-Means method is used to evaluate distance between cluster and data point.\n    \n  * Isolation forest -  Similar to Random Forest, it is built on an ensemble of binary (isolation) trees.\n    \n  * LocalOutlierFactor\n    \n* Deep learning - Neural network deep learning outperforms in most cases, however it required intense compute and training.\n   \n  \n  #### Above list is by no means exhaustive or complete, I recommend readers to research more on detection techniques. ","594078a2":"### We will use \"creditcard.csv\" dataset, and perform following tasks\n1. Inspect and explore data set\n    * Inspect Shape of data set \n    * Inspect Missing data in data set\n    * Inspect Statistical description of data set\n    * Inspect percentage of Fraud and Normal cases in data set\n    * Inspect Correlation between features in data set\n\n\n2. Build and evaluate anomaly model using below algorithms\n    * Isolation Forest Algorithm \n    * LocalOutlierFactor Algorithm \n\n\n3.  Evaluate performance of above two models\n\n4.  Observation and Suggestions\n    ","c206a5fe":"### Build and Evaluate model\n* Let us split data into training and test set, and use one set for training and other set for evaluation\n* We will get started by building model using below algorithms \n        1) Isolation Forest algorithm\n        2) LocalOutlierFactor algorithm\n\n","a11edf7d":"Statistics shows \"Fraud\" class are only 0.17 percent in data set. Hence, data set is highly biased towards \"Normal\" class, .i.e. \"Normal\" by far outnumbers \"Fraud\". This is normal dataset for Anomaly detection cases, .i.e percentage of anomaly will be less than 1%","24725e25":"#### Inspect features columns and target\/dependent variable of data set.\nLast column \"Class\" in dataFrame - is target\/dependent variable, boolean; True inidcates its \"Fraud\" and False indicates its \"Normal.","36b7e3f6":"### Inspect Statistical description of data set","4da70561":"#### Since number of dimensions are too many, its not easy to read and comprehend correlation. So, lets draw it."}}