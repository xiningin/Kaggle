{"cell_type":{"7204ab87":"code","8888b061":"code","8ef7372f":"code","2750b410":"code","8975ae10":"code","b5385440":"code","1a6a3a70":"code","ac17c66d":"code","68e1a0f2":"code","9ad90563":"code","e397dccc":"code","ccc18959":"code","6c13943f":"code","1c63f56f":"code","08d27ab3":"code","1757f560":"code","b68f2275":"code","6b2a628f":"code","2c01b74b":"code","ed91e0a2":"code","a2b71621":"code","003c6e93":"code","3a27e283":"code","2d8e7535":"code","573cc42c":"code","c8136159":"code","ba240e4b":"code","9637a5a9":"code","0a6df540":"code","cb108cd8":"code","cd8db9f2":"code","3dff5889":"code","78ff176c":"code","1a1f2511":"code","72403f50":"code","aa4fedef":"code","ad747876":"code","3d508b73":"code","2d874d39":"code","c3bd41eb":"code","b948ab1e":"code","71185adf":"code","5a3aed45":"code","20c7a774":"code","84550d25":"code","4ebfab4e":"code","695a3e3e":"code","93d4ba26":"code","c8db7937":"code","2e0944b9":"code","3e492162":"code","25e0c80e":"code","c1447ce2":"markdown","e59ce0e0":"markdown","d98071d7":"markdown","e97be02d":"markdown","d968c3c2":"markdown","a8cad181":"markdown","7b2ea373":"markdown","f0c22f3e":"markdown","5a8bd670":"markdown","7246261f":"markdown","ae41082c":"markdown","cb041e3c":"markdown","743cad2c":"markdown","c3e7aba1":"markdown","7fc42b5f":"markdown","9c02784a":"markdown","b3589c0c":"markdown","d73cc725":"markdown","4b7f0182":"markdown","cca3296d":"markdown","a7998dbc":"markdown","05f713cd":"markdown","2e3510a2":"markdown","638898d0":"markdown","b1565592":"markdown","6abf5b3d":"markdown","914609fc":"markdown","1b7a2c22":"markdown","83a83e4a":"markdown","d4d20fa1":"markdown","a05419ea":"markdown"},"source":{"7204ab87":"# Load required Directories\ntrain_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\nval_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'","8888b061":"import os\nimport torch\nimport torchvision","8ef7372f":"print(os.listdir(train_dir))","2750b410":"print(os.listdir(test_dir))","8975ae10":"print(os.listdir(val_dir))","b5385440":"classes = os.listdir(train_dir)\nclasses","1a6a3a70":"from torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor","ac17c66d":"trainset = ImageFolder(train_dir, transform = ToTensor())","68e1a0f2":"valset = ImageFolder(val_dir, transform = ToTensor())\ntestset = ImageFolder(test_dir, transform = ToTensor())","9ad90563":"img, label = trainset[3]\nprint(img.shape, label)","e397dccc":"import torchvision.transforms as transforms","ccc18959":"train_trans = transforms.Compose([\n    # this will resize all images to 128*128 pixel size, irrespective of their initial size, as we need all images of same size\n    transforms.Resize(size = (128,128)),\n    # This will randomly rotate each image\n    transforms.RandomRotation(degrees = (-20, +20)),\n    # We can change image parameters, but I have kept it inactive \n    #transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2),\n    # We need to convert all numpy array to Tensor as Pytorch need tensor as input\n    transforms.ToTensor(),\n    # this will add padding of 2 pixels along all edges\n    transforms.Pad(2),\n    # This will normalize data, I have provided with Mean and standard deviation for all 3 color channels, Blue, Green red\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])","6c13943f":"val_trans = transforms.Compose([\n    transforms.Resize(size = (128, 128)),\n    transforms.ToTensor(),\n    transforms.Pad(2),\n     transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])","1c63f56f":"trainset = ImageFolder(train_dir, transform = train_trans)","08d27ab3":"valset = ImageFolder(val_dir, transform = val_trans)\ntestset = ImageFolder(test_dir, transform = val_trans)","1757f560":"img, label = trainset[999]\nprint(img.shape, label)","b68f2275":"img, label = valset[1]\nprint(img.shape, label)","6b2a628f":"img, label = testset[1]\nprint(img.shape, label)","2c01b74b":"import matplotlib.pyplot as plt\ndef show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0))","ed91e0a2":"show_img(*trainset[1000])","a2b71621":"len(trainset)","003c6e93":"len(valset)","3a27e283":"len(testset)","2d8e7535":"show_img(*valset[10])","573cc42c":"from torch.utils.data.dataloader import DataLoader","c8136159":"train_loader = DataLoader(trainset, batch_size = 128, shuffle = True)","ba240e4b":"val_loader = DataLoader(testset, batch_size = 128, shuffle = True)","9637a5a9":"sample = next(iter(train_loader))\nprint(sample[0].shape)\nprint(sample[1].shape)","0a6df540":"sample = next(iter(val_loader))\nprint(sample[0].shape)\nprint(sample[1].shape)","cb108cd8":"from torchvision.utils import make_grid","cd8db9f2":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize = (12,12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:25], 5).permute(1,2,0))\n        break","3dff5889":"show_batch(train_loader)","78ff176c":"show_batch(val_loader)","1a1f2511":"import torch.nn as nn\nimport torch.nn.functional as F","72403f50":"model = nn.Sequential(\n    \n    nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1),\n    nn.ReLU(),\n    nn.MaxPool2d(2,2),\n    nn.BatchNorm2d(16), # Output size : bs * 16 * 66 * 66 \n    \n    nn.Conv2d(16, 64, kernel_size = 3, stride = 1, padding = 1),\n    nn.ReLU(),\n    nn.MaxPool2d(2,2),\n    nn.BatchNorm2d(64), # Output size : bs * 64 * 33 * 33\n    \n    nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n    nn.ReLU(),\n    nn.MaxPool2d(2,2),\n    nn.BatchNorm2d(128), # Output size : bs * 128 * 16 * 16\n    \n    nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n    nn.ReLU(),\n    nn.MaxPool2d(2,2),\n    nn.BatchNorm2d(256), # Output size : bs * 256 * 8 * 8\n    \n    nn.Flatten(),\n    \n    nn.Linear(256*8*8, 256),\n    nn.ReLU(),\n    \n    nn.Linear(256, 8),\n    nn.ReLU(),\n    \n    nn.Linear(8, 2)    \n)","aa4fedef":"# Demo plot\n\nfor images, labels in train_loader:\n    print('Image Shape', images.shape)\n    out = model(images)\n    print('output shape', out.shape)\n    print('out[0]', out[0])\n    break","ad747876":"probs = F.softmax(out[0], dim = 0)\nprobs","3d508b73":"m = torch.argmax(probs)\nm","2d874d39":"trainset.classes[m]","c3bd41eb":"trainset.classes[labels[0]]","b948ab1e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","71185adf":"device = get_default_device()\ndevice","5a3aed45":"train_dl = DeviceDataLoader(train_loader, device)\nval_dl = DeviceDataLoader(val_loader, device)\nto_device(model, device)","20c7a774":"def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n    pred = model(x)\n    \n    loss = loss_func(pred, y)\n    \n    if opt is not None:\n        \n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n    metric_result = None\n    \n    if metric is not None:\n        \n        metric_result = metric(pred, y)\n            \n    return loss.item(), len(x), metric_result\n            ","84550d25":"def evaluate(model, loss_fn, valid_dl, metric = None):\n    with torch.no_grad():\n        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in valid_dl]\n        \n        losses, nums, metrics = zip(*results)\n        \n        total = np.sum(nums)\n        \n        avg_loss = np.sum(np.multiply(losses, nums)) \/ total\n        \n        avg_metric = None\n        \n        if metric is not None:\n            avg_metric = np.sum(np.multiply(metrics, nums)) \/ total\n            \n    return avg_loss, total, avg_metric","4ebfab4e":"def fit(epochs, model, loss_fn, train_dl, valid_dl, opt_fn = None, lr = None, metric = None):\n    train_losses, val_losses, val_metrics = [], [], []\n    \n    if opt_fn is None: opt_fn = torch.optim.SGD\n    \n    opt = opt_fn(model.parameters(), lr = lr)\n    \n    for epoch in range(epochs):\n        model.train()\n        \n        for x, y in train_dl:\n            train_loss, _, _ = loss_batch(model, loss_fn, x, y, opt)\n            \n        model.eval()\n        result = evaluate(model, loss_fn, valid_dl, metric)\n        val_loss, total, val_metric = result\n        \n        \n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_metrics.append(val_metric)\n        \n        if metric is None:\n            print('Epoch{}\/{}, train_loss: {:.4f}, val_loss: {:.4f}' \n                 .format(epoch+1, epochs, train_loss, val_loss))\n            \n        else:\n            print('Epoch {}\/{}, train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}'\n                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric))\n            \n    return train_losses, val_losses, val_metrics","695a3e3e":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim = 1)\n    return torch.sum(preds == labels).item() \/ len(preds)","93d4ba26":"import numpy as np","c8db7937":"val_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric = accuracy)\n\nprint(val_loss, val_acc)","2e0944b9":"num_epochs = 10\nopt_fn = torch.optim.Adam\nlr = 0.005","3e492162":"num_epochs = 10\nopt_fn = torch.optim.Adam\nlr = 0.005","25e0c80e":"history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, opt_fn, lr, accuracy)","c1447ce2":"Initial Image loading to study different Images","e59ce0e0":"Silimar transformations for Validation and Test Set","d98071d7":"Let,s have some initial guesses","e97be02d":"# Load Data & Import Libraries","d968c3c2":"Storing Folders as classes","a8cad181":"Each Batch of [128, 3, 132, 132] size","7b2ea373":"Aim of these transformations, to nullify chances of Overfitting","f0c22f3e":"It seems, I need to let it run for some more Epochs to get more accurate model,\n\nI will come up with next model where, i will show some more hyper parameters to improve Model,\n\nIf You like this Notebook, kindly consider upvoting, Keep learning!!","5a8bd670":"# Model Formation","7246261f":"# Image Transformations\n","ae41082c":"There are 2 class, \n1. Pneumonia Infected \n2. Normal Lung","cb041e3c":"So its class 2 i.e. Normal X ray, as per initial guess from model.\n\nLet's verify","743cad2c":"We will define different transformations for both Train and Validation set.\n\n\nI will consider test set as validation set, as original validation data has only 16 images, \nConsider changes as below","c3e7aba1":"Form Transformed Image set for train and validation","7fc42b5f":"# Helper function to train model","9c02784a":"We have,\n1. 5216 Train Images,\n2. 624 Test Images,\n3. 16 Validation Images","b3589c0c":"What is Pneumonia? Pneumonia is an inflammatory condition of the lung affecting primarily the small air sacs known as alveoli.Symptoms typically include some combination of productive or dry cough, chest pain, fever and difficulty breathing. The severity of the condition is variable. Pneumonia is usually caused by infection with viruses or bacteria and less commonly by other microorganisms, certain medications or conditions such as autoimmune diseases.Risk factors include cystic fibrosis, chronic obstructive pulmonary disease (COPD), asthma, diabetes, heart failure, a history of smoking, a poor ability to cough such as following a stroke and a weak immune system. Diagnosis is often based on symptoms and physical examination. Chest X-ray, blood tests, and culture of the sputum may help confirm the diagnosis.The disease may be classified by where it was acquired, such as community- or hospital-acquired or healthcare-associated pneumonia.\n\nPneumonia is a very common disease. It can be either: 1) Bacterial pneumonia 2) Viral Pneumonia 3) Mycoplasma pneumonia and 4) Fungal pneumonia. This dataset consists pneumonia samples belonging to the first two classes. The dataset consists of only very few samples and that too unbalanced. The aim of this kernel is to develop a robust deep learning model from scratch on this limited amount of data. We all know that deep learning models are data hungry but if you know how things work, you can build good models even with a limited amount of data.","d73cc725":"Dataloader use to batch wise image feed possible","4b7f0182":"This is most important step, keep an eye on output size after each layer","cca3296d":"# Model training","a7998dbc":"Following code transfers, model and batches to GPU, time as required","05f713cd":"Well, that was incorrect Guess !!","2e3510a2":"Initial guess is Pneumonia","638898d0":"We have initial guess of model,tensor([0.3376, -0.1185] but we need to conveet into Probability form, using Softmax","b1565592":"All are of 132*132 Pixel size\n\n\nDefine random image generator function for reproduceability","6abf5b3d":"Read both folderes within Train, test, Validation set","914609fc":"Define a function to plot random images","1b7a2c22":"It seems all Images are of different size,but for Pytorch Neural network we need all images from Train, test and validation set of same size,\nElse Model wont be able to train","83a83e4a":"Define accuracy as measure parameter, to find correctness of Model","d4d20fa1":"Sample checking","a05419ea":"Let's check size of random images"}}