{"cell_type":{"97a6db7e":"code","7f9637c8":"code","c5afdc73":"code","a3b79aa9":"code","e8dfbec5":"code","42224ca6":"code","931af096":"code","addca1b5":"code","0b4855ca":"code","f2a9da83":"code","d486bc83":"code","38c390f5":"code","a19a8337":"code","88ad4f1c":"code","1c1c523f":"code","792c877f":"code","8dac55a2":"code","3bc4afd5":"code","485ec0aa":"code","149f1032":"code","1e578da0":"code","9bc6a6f9":"code","fd3d145b":"code","1b530ee7":"code","3aa29492":"code","0896a047":"code","7d3ddca9":"code","88468467":"code","a2e78876":"markdown","5778a9d6":"markdown","baa26196":"markdown","abbfed88":"markdown"},"source":{"97a6db7e":"import numpy as np \nimport pandas as pd \nfrom pathlib import Path\n\nfrom fastai.imports import *\nfrom fastai import *\nfrom fastai.vision import *\n\nfrom tqdm import tqdm_notebook as tqdm\n\nbase_path = Path('\/kaggle\/input\/plant-pathology-2020-fgvc7\/')","7f9637c8":"def get_tag(row):\n    if row.healthy:\n        return \"healthy\"\n    if row.multiple_diseases:\n        return \"multiple_diseases\"\n    if row.rust:\n        return \"rust\"\n    if row.scab:\n        return \"scab\"","c5afdc73":"def transform_data(train_labels):\n    train_labels.image_id = [image_id+'.jpg' for image_id in train_labels.image_id]\n    train_labels['tag'] = [get_tag(train_labels.iloc[idx]) for idx in train_labels.index]\n    train_labels.drop(columns=['healthy', 'multiple_diseases', 'rust', 'scab'], inplace=True)","a3b79aa9":"train_labels = pd.read_csv(base_path\/\"train.csv\")\npath = base_path\/\"images\"","e8dfbec5":"transform_data(train_labels)\ntrain_labels = train_labels.set_index(\"image_id\")","42224ca6":"train_labels['tag'].value_counts()","931af096":"tfms = get_transforms(flip_vert=True,max_zoom=1.3,max_lighting=0.3,) ","addca1b5":"src = (ImageList.from_folder(path)\n      .filter_by_func(lambda fname: \"Train\" in fname.name)\n      .split_by_rand_pct()\n      .label_from_func(lambda o: train_labels.loc[o.name]['tag']))","0b4855ca":"data_224 = (src.transform(tfms, size=224)\n       .databunch(bs=16)\n       .normalize())","f2a9da83":"data_224.show_batch(4)","d486bc83":"\nimport torch \nimport torchvision\nmodel = torchvision.models.mnasnet1_0(pretrained=True)","38c390f5":"model","a19a8337":"model.classifier[1].out_features=4","88ad4f1c":"# model.layer4[0].bn1.momentum=0.3","1c1c523f":"# model.layer4[0].bn1.momentum=0.1\n# model.layer4[0].bn1.eps=1e-04\n# model.layer4[0].bn2.momentum=0.2\n# model.layer4[0].bn2.eps=1e-03\n# model.layer4[0].bn3.momentum=0.15\n# model.layer4[0].bn3.eps=1e-03\n# # model.layer4[1].bn1.momentum=0.05\n# model.layer4[1].bn1.eps=1e-04\n# model.layer4[1].bn2.momentum=0.13\n# model.layer4[1].bn2.eps=1e-03\n# model.layer4[1].bn3.momentum=0.15\n# model.layer4[1].bn3.eps=1e-03\n# model.layer4[2].bn1.momentum=0.15\n# model.layer4[2].bn1.eps=1e-04\n# model.layer4[2].bn2.momentum=0.3\n# model.layer4[2].bn2.eps=1e-03\n# model.layer4[2].bn3.momentum=0.05\n# model.layer4[2].bn3.eps=1e-06\n","792c877f":"model=model.cuda()","8dac55a2":"from fastai.callbacks import *\n\nlearn = Learner(data_224, model, metrics=[error_rate, accuracy,],model_dir='kaggle\/working\/model')","3bc4afd5":"learn.model_dir = \"\/kaggle\/working\"","485ec0aa":"from fastai.callbacks import *\ntry:\n    learn.fit(20,1e-4,callbacks=[SaveModelCallback(learn, every='imrpovement', monitor='accuracy')])\nexcept :\n    learn.fit(20,1e-4)\n    learn.save('bestmodel')","149f1032":"learn","1e578da0":"learn.unfreeze()","9bc6a6f9":"learn.load('bestmodel')\nlearn.fit_one_cycle(25,1e-6,callbacks=[SaveModelCallback(learn, every='imrpovement', monitor='accuracy')])","fd3d145b":"test_images = ImageList.from_folder(base_path\/\"images\")\ntest_images.filter_by_func(lambda x: x.name.startswith(\"Test\"))","1b530ee7":"\ntest_df = pd.read_csv(base_path\/\"test.csv\")\ntest_df['healthy'] = [0.0 for _ in test_df.index]\ntest_df['multiple_diseases'] = [0.0 for _ in test_df.index]\ntest_df['rust'] = [0.0 for _ in test_df.index]\ntest_df['scab'] = [0.0 for _ in test_df.index]\ntest_df = test_df.set_index('image_id')\n        ","3aa29492":"for item in tqdm(test_images.items):\n    name = item.name[:-4]\n    img = open_image(item)\n    preds = learn.predict(img)[2]\n\n    test_df.loc[name]['healthy'] = preds[0]\n    test_df.loc[name]['multiple_diseases'] = preds[1]\n    test_df.loc[name]['rust'] = preds[2]\n    test_df.loc[name]['scab'] = preds[3]\n            ","0896a047":"test_df","7d3ddca9":"test_df.to_csv(f\"\/kaggle\/working\/resnet_result.csv\")","88468467":"test_df.to_csv(f\"\/kaggle\/working\/resnet_result1111.csv\")","a2e78876":"We want first to train our models on small resolution and then using transfer learning fine-tune them on high resolution. This approach speeds up learning dramatically","5778a9d6":"### Training","baa26196":"### get csv tags","abbfed88":"### create data_bunch"}}