{"cell_type":{"27718032":"code","f4333b50":"code","c0dccb22":"code","27344a52":"code","d578dd00":"code","7b3d02bb":"code","dc3fd507":"code","0c22c3e2":"code","91690bba":"code","3bf39be3":"code","3f601145":"code","a7aa6538":"code","af02876e":"markdown","9c72a511":"markdown","a016cf17":"markdown","20683d5f":"markdown","eac3d4b7":"markdown","3eb7156d":"markdown","f44afc4c":"markdown","e3cde520":"markdown","d9ede7bd":"markdown"},"source":{"27718032":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f4333b50":"# import fast ai vision library\nfrom fastai.vision import *","c0dccb22":"# create validation set by removing drivers from the training set and putting their pictures in a validation set.\npath = '\/kaggle\/input\/state-farm-distracted-driver-detection\/'\nimg_list = pd.read_csv(path + 'driver_imgs_list.csv')\n\n# select a subset of the subjects for validation\nvalid_subjects = img_list.subject.sort_values().unique()[-4:]\n# create new column identifying the subjects for validation\nimg_list['is_valid'] = img_list['subject'].isin(valid_subjects)\n\nprint(\"valid subjects: \", valid_subjects)\nprint(img_list[img_list['is_valid']==True].subject.count())\n\nimg_list['img_path'] = img_list.classname + '\/' + img_list.img\n\nvalid_names = img_list[img_list['subject'].isin(valid_subjects)].img\nvalid_names = valid_names.to_list()","27344a52":"# apply standard image transformations except flipping the pictures.  \n# The categories we are trying to predict can be specific to left hand \/ right hand\ntfms = get_transforms(do_flip=False)\n\n# create the data bunch\ndata = (ImageList.from_df(df=img_list, path = path + 'train\/', cols='img_path' )\n        #.split_by_valid_func(lambda o: os.path.basename(o) in valid_names)\n        .split_by_rand_pct(.1)\n        .label_from_df(1)\n        .transform(tfms=tfms)\n        .add_test_folder(path + 'test\/')\n        .databunch(bs=64))\n\n# output description of data\ndata","d578dd00":"# review images from a batch\n\ndata.show_batch(3)","7b3d02bb":"# Used resnet34 because of memory errors.  Would have liked to try resnet50 or VGG16.\n\nlearn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir='\/')","dc3fd507":"# find optimal learning rate\n\nlearn.lr_find()\nlearn.recorder.plot()","0c22c3e2":"# fit the model\n# this takes several minutes to run on the kaggle GPU ~12 mins per cycle.\n# You can run additional cycles until the validation error stops improving.\n\nlearn.fit_one_cycle(5, max_lr=1e-02)","91690bba":"interp = ClassificationInterpretation.from_learner(learn)\n\ninterp.plot_top_losses(6)","3bf39be3":"# preds = learn.get_preds(DatasetType.Test)","3f601145":"# labels = pd.DataFrame(data.test_ds.x.items, columns=['img'])\n# labels.img = labels.img.astype(str)\n# labels = labels.img.str.rsplit('\/', 1, expand=True)\n# labels.drop(0, axis=1, inplace=True)\n# labels.rename(columns={1: 'img'}, inplace=True)","a7aa6538":"# columns = data.classes\n\n# submission = pd.DataFrame(preds[0].numpy(), columns=columns, index=labels.img)\n# submission.reset_index(inplace=True)\n# submission.to_csv('submission.csv', index=False)","af02876e":"# Distracted Driver Predictions Using Fast AI\nUse the Fast.AI library to quickly create an image recognition model with performance in the top 25% of the private leaderboard.","9c72a511":"## 4 - Define CNN Model w\/ Transfer Learning","a016cf17":"## 3 - Create Data Bunch","20683d5f":"## 5 - Review Errors","eac3d4b7":"## 2 - Create Validation Set","3eb7156d":"## 1 - Import Libraries","f44afc4c":"If you use a random split the train \/ validtion error look similar because a person may appear in both sets.  Although the model is overfitting, the performance on the test set is still in the top 25%.\n\nWhen you create a validation sample that removes individual subjects completely from the training set the validation error is more closely aligned with the leaderboard.  However, you have to make sure to train on all of the data before submitting test predictions because the information from the validation subjects is valuable (subjects have different ethnicity, size, color, etc.).","e3cde520":"For this model we are not going to train the resnet34 layers.  Instead we are going to go with the pretrained weights and apply the standard model head defined by Fast AI.  \n\nlearn.freeze accomplishes the task of freezing the base model layers and adding predefined layers of Adaptive Pooling (max & avg), BN -> Dropout -> Dense w\/ Relu -> BN -> Dropout -> Dense (predictions).  learn.freeze() is the default in FastAI.  Unfreezing the layers may yeild better results given we have over 20k training images.\n\nYou can review the layers of the model by calling \"learn.layer_groups\"","d9ede7bd":"## 6 - Create Predictions for Test Set\nTo get the best results you would want to retrain the model using all of the training data."}}