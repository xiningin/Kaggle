{"cell_type":{"7fc63d6a":"code","2281f9eb":"code","9af48333":"code","9bfd530a":"code","0192cd08":"code","1308177b":"code","61816642":"code","246cfddf":"code","bb1a1fde":"code","7686344b":"code","5912a6dc":"code","8693cbc0":"code","aca1e95d":"code","dd4487ae":"code","0f143746":"code","eb57e3df":"code","9645b3b4":"code","7a213a7f":"code","b39ae87a":"code","767dee75":"code","43d8dde7":"code","1e2cfb63":"code","4808a423":"code","121e3643":"code","4da31278":"code","ecaca3b2":"code","c6b0fde2":"code","2d654196":"code","b9e17006":"code","a536ce64":"code","c34b16c9":"code","d3449234":"code","d5b689ce":"code","ad0690cc":"code","48c53203":"code","dbde8dff":"code","9d46b91e":"code","3d7f5897":"code","1fe6b76a":"code","7795d0cf":"code","f21a3931":"code","c2879085":"code","6a304d91":"code","a75b28fd":"code","579a55ec":"code","d6cebf94":"code","ac3e8a69":"code","72429f78":"code","b0450a6b":"code","2c67fa2b":"code","eac32d58":"code","d6c0ce18":"code","d789aa25":"code","1596cc03":"code","be236f51":"code","662a782f":"code","3793f244":"code","87290021":"code","ddcea4b9":"code","9217eef3":"code","7b5323f8":"code","d478a236":"code","c0c8516a":"code","63c2cf64":"code","c3afd85f":"code","e33ca55b":"code","bb25ed3c":"code","88a3e504":"code","1ea55e87":"code","78452c75":"code","7ef2b681":"code","adfb1c1f":"code","22013bc2":"code","7572f4e6":"code","90b2faba":"code","a82a8a78":"code","c1cfbe46":"code","6cc1f9ad":"code","211f6b85":"code","b1e0cefe":"code","9c5e9468":"code","de6d9df5":"code","dfce8cae":"code","80c7aff8":"code","357f188f":"code","2774ba34":"code","ed696da4":"code","3520c4ee":"code","8188081e":"code","b9390116":"code","e93976c9":"code","dfd41cb5":"code","6c98ae87":"code","bef342a0":"code","638e32c4":"code","fa6bb413":"code","9637ccbf":"code","cffa3530":"code","092cf20b":"code","0995d3b5":"code","b7ddbb45":"markdown","7097fbf1":"markdown","7b0eef9a":"markdown","e69cca1e":"markdown","50927f56":"markdown","e0a3ee50":"markdown","968cd617":"markdown","a4627317":"markdown","f55e0473":"markdown","deb7d57a":"markdown","df64c9ab":"markdown","1ad8f5fd":"markdown","ba890810":"markdown","a00b2e8f":"markdown","2240cf0e":"markdown","0a63066a":"markdown","ac9f9324":"markdown","cddc5df8":"markdown","59b7835c":"markdown","250ce787":"markdown","73512d24":"markdown","9e9d4908":"markdown","d2dfefc9":"markdown","9f7953d5":"markdown","140a0916":"markdown","1951c557":"markdown","a28f8e61":"markdown","dbf7b975":"markdown","09db4b1c":"markdown","310e5d2a":"markdown","676dd511":"markdown","332bb4c7":"markdown"},"source":{"7fc63d6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2281f9eb":"import warnings\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","9af48333":"from sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import VotingClassifier","9bfd530a":"testDf=pd.read_csv(\"..\/input\/test.csv\")\ntrainDf=pd.read_csv(\"..\/input\/train.csv\")\ngenderDf=pd.read_csv('..\/input\/gender_submission.csv')","0192cd08":"testDf.info()","1308177b":"passengerID=testDf['PassengerId']","61816642":"titanicDf=pd.concat([testDf,trainDf],keys=['Test','Train'],names=['Dataset','Dataset ID'])","246cfddf":"titanicDf.head()","bb1a1fde":"titanicDf.tail()","7686344b":"# titanicDf.xs('Train').head()  # Another method for doing so\ntitanicDf.loc['Train'].head()","5912a6dc":"titanicDf.loc['Test'].head()","8693cbc0":"titanicDf.info()","aca1e95d":"titanicDf.xs('Train').info()","dd4487ae":"titanicDf.xs('Test').info()","0f143746":"titanicDf.xs('Train').describe()","eb57e3df":"titanicDf.xs(\"Test\").describe()","9645b3b4":"titanicDf.xs('Train').hist(bins=20,figsize=(15,10))","7a213a7f":"# As we can see there are a couple of null values that we have to resolve\ntitanicDf.xs('Train').isnull().sum()","b39ae87a":"# To find the most repetative data in the Embarked column\nembarked_modeSeries=titanicDf.xs('Train')['Embarked'].dropna().mode()","767dee75":"embarked_mode=embarked_modeSeries[0]\nembarked_mode","43d8dde7":"titanicDf['Embarked'].fillna(embarked_mode,inplace=True)","1e2cfb63":"titanicDf['Embarked'][titanicDf['Embarked'].isnull()==True]","4808a423":"titanicDf.isnull().sum()","121e3643":"FareMode=titanicDf['Fare'].mode()\nFareMode","4da31278":"titanicDf['Fare'].fillna(FareMode[0],inplace=True)","ecaca3b2":"titanicDf['Fare'].isnull().sum()","c6b0fde2":"titanicDf.xs('Train').corr()['Age'].sort_values(ascending=False)","2d654196":"titanicDf.xs('Train')[['Age','Sex']].groupby('Sex').mean().sort_values(by='Age',ascending=False)","b9e17006":"titanicDf['Pclass'].unique()","a536ce64":"for valAge in ['male','female']:\n    for x in range(0,3):\n        titanicDfMedianAge=titanicDf.xs('Train')[(titanicDf.xs('Train')['Sex']==valAge) &\n                                                 (titanicDf.xs('Train')['Pclass']==x+1)]['Age'].dropna().median()\n        print('the median age is ',titanicDfMedianAge)\n        \n        titanicDf.loc[(titanicDf[\"Age\"].isnull()) & (titanicDf[\"Sex\"] == valAge) & (titanicDf[\"Pclass\"] == x+1), \"Age\"] = titanicDfMedianAge\n        ","c34b16c9":"# Display specified ages for test \n# titanicDf.loc[(titanicDf[\"Sex\"] == valAge) & (titanicDf[\"Pclass\"] == x+1),\"Age\"]","d3449234":"titanicDf.loc['Train','Cabin'].unique()","d5b689ce":"titanicDf.loc['Train','Cabin'].isnull().sum()","ad0690cc":"titanicDf.fillna('None',inplace=True)","48c53203":"titanicDf.loc['Train','Cabin'].isnull().sum()","dbde8dff":"titanicDf.isnull().sum()","9d46b91e":"titanicDf['Title']=titanicDf['Name'].str.extract(\"([A-Za-z]+)\\.\",expand=False)","3d7f5897":"# Listing out the unique titles that we have created\nset(titanicDf['Title'])","1fe6b76a":"pd.crosstab(titanicDf['Title'],titanicDf['Sex'])","7795d0cf":"titanicDf['Title'].replace('Mme','Mrs',inplace=True)\ntitanicDf['Title'].replace('Ms','Miss',inplace=True)\ntitanicDf[\"Title\"].replace([\"Capt\", \"Col\", \"Countess\", \"Don\", \"Dona\", \"Dr\", \"Jonkheer\", \"Lady\", \"Major\", \"Rev\", \"Sir\"], \"Special\", inplace=True)\ntitanicDf['Title'].replace('Mlle','Miss',inplace=True)","f21a3931":"# titanicDf.xs('Train')[['Survived','Title']].groupby(['Title']).mean().sort_values(by='Survived',ascending=False)titanicDf","c2879085":"titanicDf.loc['Train'][['Title','Survived']].groupby('Title').sum().sort_values(by='Survived',ascending=False)","6a304d91":"pd.cut(titanicDf.loc['Train','Age'],bins=5).dtype","a75b28fd":"titanicDf.loc[titanicDf['Age']<16,'Age']=0\ntitanicDf.loc[(titanicDf['Age']>=16) & (titanicDf['Age']<32),'Age']=1\ntitanicDf.loc[(titanicDf['Age']>=32) & (titanicDf['Age']<48),'Age']=2\ntitanicDf.loc[(titanicDf['Age']>=48) & (titanicDf['Age']<64),'Age']=3\ntitanicDf.loc[(titanicDf['Age']>=64),'Age']=4","579a55ec":"titanicDf['Age'].sort_values().unique()","d6cebf94":"# Its better to have such values in int type \ntitanicDf['Age']=titanicDf['Age'].astype(int)","ac3e8a69":"titanicDf['Age'].value_counts()","72429f78":"titanicDf.loc['Train'][['Age','Survived']].groupby('Age').sum().sort_values(by='Survived',ascending=False)","b0450a6b":"# Including the passenger on board\ntitanicDf['Family']=titanicDf['SibSp']+titanicDf['SibSp']+1 ","2c67fa2b":"titanicDf.loc['Train'][['Family','Survived']].groupby('Family').sum()","eac32d58":"titanicDf['IsAlone']=0\ntitanicDf.loc[titanicDf['Family']>1,\"IsAlone\"]=1","d6c0ce18":"titanicDf.loc['Train'][['IsAlone','Survived']].groupby('Survived').mean().sort_values(by='IsAlone',ascending=False)","d789aa25":"set(pd.qcut(titanicDf['Fare'],q=4))","1596cc03":"titanicDf.loc[titanicDf['Fare']<=7.896,'Fare']=0\ntitanicDf.loc[(titanicDf['Fare']>7.896) & (titanicDf['Fare']<=14.454),'Fare']=1\ntitanicDf.loc[(titanicDf['Fare']>14.454) & (titanicDf['Fare']<=31.275),'Fare']=2\ntitanicDf.loc[(titanicDf['Fare']>31.275),'Fare']=3","be236f51":"titanicDf['Fare'].astype(int)","662a782f":"titanicDf['Fare'].unique()","3793f244":"titanicDf['Fare'].value_counts()","87290021":"titanicDf.loc['Train'][['Fare','Survived']].groupby('Fare').sum().sort_values(by='Survived',ascending=False)","ddcea4b9":"titanicDf['Cabin'].isnull().sum()","9217eef3":"titanicDf['Cabin']=titanicDf['Cabin'].str.extract(\"([A-Za-z]+)\",expand=False)","7b5323f8":"titanicDf.loc['Train'][['Cabin','Survived']].groupby(['Cabin']).sum().sort_values(by='Survived',ascending=False)","d478a236":"titanicDf.info()","c0c8516a":"titanicDf.drop(['Name','PassengerId','Ticket'],axis=1,inplace=True)","63c2cf64":"titanicDf.head()","c3afd85f":"titanicDf['Survived'].value_counts()","e33ca55b":"labelEncoder=LabelEncoder()\ntitanicDfEncodedTrain=titanicDf.loc['Train'].apply(labelEncoder.fit_transform)\ntitanicDfEncodedTest=titanicDf.loc['Test'].apply(labelEncoder.fit_transform)","bb25ed3c":"titanicDfEncodedTrain.head()","88a3e504":"titanicDfEncodedTest.head()","1ea55e87":"plt.figure(figsize=(20,10))\nsns.heatmap(titanicDfEncodedTrain.corr(),annot=True,)","78452c75":"X_train=titanicDfEncodedTrain.drop('Survived',axis=1)\ny_train=titanicDfEncodedTrain['Survived']","7ef2b681":"randomForestClassifier=RandomForestClassifier()\nrandomForestClassifier.fit(X_train,y_train)","adfb1c1f":"randomForestClassifier.feature_importances_","22013bc2":"# Zips the feature columns to the  feature importances \nfeature_importances=zip(list(X_train.columns.values),randomForestClassifier.feature_importances_)\n\n# sort acc to the feature importances \nfeature_importances=sorted(feature_importances,key=lambda feature:feature[1],reverse=True)\n\n# print the columns names and its importances in a good fashion\nfor name,score in feature_importances:\n    print(\"{:10} | {}\".format(name,score))","7572f4e6":"titanicDf.drop('Cabin',axis=1,inplace=True)","90b2faba":"y_train=titanicDf.loc['Train']['Survived']","a82a8a78":"X_titanicdf=pd.get_dummies(titanicDf.drop('Survived',axis=1))\ny_titanic=titanicDf['Survived']","c1cfbe46":"X_train=X_titanicdf.loc['Train']\ny_train=y_titanic.loc['Train'].astype(int)\nX_test=X_titanicdf.loc['Test']","6cc1f9ad":"X_train.head()","211f6b85":"y_train.head()","b1e0cefe":"X_test.head()","9c5e9468":"scaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)","de6d9df5":"logisticClassifier=LogisticRegression()\ncross_val_score(logisticClassifier,X_train,y_train,cv=10,scoring='accuracy').mean()","dfce8cae":"sgcClassifer=SGDClassifier()\ncross_val_score(sgcClassifer,X_train,y_train,scoring='accuracy').mean()","80c7aff8":"svcClassifier=SVC()\ncross_val_score(svcClassifier,X_train,y_train,scoring='accuracy').mean()","357f188f":"ldaClassifier=LinearDiscriminantAnalysis()\ncross_val_score(ldaClassifier,X_train,y_train,scoring='accuracy').mean()","2774ba34":"grid_params=[\n    {\n    \"C\":[4,5,6],\n    \"kernel\":[\"rbf\"],\n    \"tol\":[0.00001,0.00003,0.00005,0.00008],\n    \"gamma\":[\"auto\",\"scale\"],\n    \"class_weight\": [\"balanced\", None],\n    \"shrinking\":[True,False],\n    \"probability\":[True]\n    },\n    {\n        \"kernel\":[\"linear\"],\n        \"degree\":[1,3,5],\n        \"gamma\":['auto',\"scale\"],\n        \"probability\":[True]\n    }\n    ]","ed696da4":"gridsearchCV=GridSearchCV(estimator=svcClassifier,param_grid=grid_params,verbose=2,scoring=\"accuracy\")","3520c4ee":"gridsearchCV.fit(X_train,y_train)","8188081e":"gridsearchCV.best_params_","b9390116":"gridsearchCV.best_score_","e93976c9":"svcClassifier=gridsearchCV.best_estimator_","dfd41cb5":"cross_val_score(svcClassifier,X_train,y_train,scoring='accuracy').mean()","6c98ae87":"votingClassifierEstimators=[(\"svc\",svcClassifier),\n                           (\"lda\",ldaClassifier),\n                            (\"Logistic Classifier\",logisticClassifier)\n                           ]","bef342a0":"votingClassifier=VotingClassifier(estimators=votingClassifierEstimators,voting=\"soft\")","638e32c4":"votingClassifier.fit(X_train,y_train)","fa6bb413":"cross_val_score(votingClassifier, X_train, y_train, cv=10, scoring=\"accuracy\").mean()","9637ccbf":"predictions=votingClassifier.predict(X_test)","cffa3530":"submissions=pd.DataFrame(\n{\n    'PassengerId':passengerID,\n    'Survived':predictions\n})","092cf20b":"submissions.head(7)","0995d3b5":"# Writing the submissions to a csv file \nsubmissions.to_csv(\"submissions.csv\",index=False)","b7ddbb45":"What we can do better is we can group the titles to make it easier for us","7097fbf1":"As we have tested many models, Now Voting classifier will be used to combine all these models as these models kind of have a similar accuracy score ","7b0eef9a":"As we have no null values, we can continue with our feature extraction process","e69cca1e":"Also similar to the Age , we can group the fare into differnet categories","50927f56":" As we can see that between the cabin is of low importance as compared to pclass of which it is derived from. so instead of keeping both we will remove the cabin feature","e0a3ee50":"So what we can do is, take the necessary features and remove all  the features that do not commit much to the classification task","968cd617":"Data preprocessing for the fare ","a4627317":"As we can see the whole df contains alot of the null values ","f55e0473":"*Now we are done with the missing values now we can work on the fetaure extraction modules.*","deb7d57a":"so we have successfully concatenated the train and test data","df64c9ab":"    The above array shows all the importances of the respective features","1ad8f5fd":"we can create another feature to demonstrate if the passenger was alone or not ","ba890810":"Now as we have checked the different accuracies of the models, Now we will use Grid Search Cv to find the best params","a00b2e8f":"Now, scale the data using the Standard Scaler library of scikit learn ","2240cf0e":"So  now we have removed the fetaures that are less important to us now , get the dummies from the dataframe to remove the categorical data ","0a63066a":"Okay, Now we can have a rough insights from the title of the peoples and most of it makes sense ","ac9f9324":"Now we have succesfully converted all our data into numerical data","cddc5df8":"we can see that the total number of female passengers who survived were more than that of males\n","59b7835c":"We   can observe that the passengers who had high class tickets were the one to survive and the chances of survival of passenger who had lower ticket were comparatively low","250ce787":"As we can see there is a good corelation between relation between sibsp, family as the feature family is derived from these only features","73512d24":"Now we are going to fill the null values of the age and fill the null values of it , according to the median value of its sex and pclass","9e9d4908":"sibsp is the number of siblings\/spouses on board while parch is the number of  parents\/childrens on board. We can combing both to create a family feature ","d2dfefc9":"so we have sucessfully removed all the missing values ****","9f7953d5":"So now what we can do is classify the Age group into some sort of categorical values, we will use the cut function of the pandas","140a0916":"Now we will check the importance of each features and decide which of the features to keep for building the model ","1951c557":"Now it seems that our data preprocessing is almost complete but at last lets check our complete head of data frame and  drop irrelevant features ","a28f8e61":"As we can  observe that the passenger who , on board were  single , were the most to survive","dbf7b975":"Data Preprocessing for the age column","09db4b1c":"Suprisingly , the passeners who didn't had a cabin  in the particular set of datset were the most to survive, and the cabin 'T' passengers were the least to survive","310e5d2a":"Now that we have converted all the variables into dummies, now split the data into train and  test.","676dd511":"Now further looking into the data we can see there are a lot of fetaures not having a numerical value. The machine learning model just understands the numerical value.\nSo we will be using the scikit  learn libraries to change the categorical features into numerical values ","332bb4c7":"Data preprocessing for cabin column"}}