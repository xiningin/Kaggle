{"cell_type":{"711bfd57":"code","647275a3":"code","1dfce1f3":"code","b0885c4d":"code","5b4cae5f":"code","e53c5c36":"code","dd264db5":"code","a138071a":"code","af1d2059":"code","bb00d835":"code","06642984":"code","96ee2705":"code","01ad9af5":"code","b95a2dd2":"code","05874fe6":"code","eee238ee":"code","2668335b":"code","8ffe6ad1":"code","8e4e6273":"code","03f5eda9":"code","09aa92ce":"markdown","1d5d3376":"markdown","7703653f":"markdown","076048ad":"markdown","454bbfc9":"markdown","58790514":"markdown","2cc40a26":"markdown","ecf49e69":"markdown","de5ac35a":"markdown","8a293b64":"markdown"},"source":{"711bfd57":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","647275a3":"import pandas as pd # data processing\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler # Normalize data\nfrom sklearn.model_selection import train_test_split # Create training and test data\nfrom sklearn.metrics import confusion_matrix # Evaluate NN\nfrom sklearn.metrics import classification_report # Evaluate NN\nfrom sklearn.metrics import accuracy_score # Evaluate NN\nfrom tensorflow import keras # Create NN\nfrom tensorflow.keras import layers # Create NN\nfrom tensorflow.keras.optimizers import SGD # Create NN","1dfce1f3":"df = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head(5)","b0885c4d":"df.shape","5b4cae5f":"df.describe() # No missing values","e53c5c36":"df.dtypes","dd264db5":"plt.style.use(\"ggplot\")","a138071a":"sns.catplot(x = \"sex\", data = df, kind = \"count\");","af1d2059":"sns.catplot(x = \"target\", data = df, kind = \"count\", hue = \"sex\");","bb00d835":"sns.pairplot(df, vars=[\"age\", \"chol\", \"thalach\", \"trestbps\"]);","06642984":"df = df.sample(frac=1)\ny = df.target\nX = df.drop(\"target\",axis=1)","96ee2705":"X, y","01ad9af5":"scaler = MinMaxScaler()\nX = scaler.fit_transform(X)","b95a2dd2":"X","05874fe6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=100)\nprint(\"X_train\", X_train.shape)\nprint (\"------------------------------------\")\nprint(\"X_test\", X_test.shape)\nprint (\"------------------------------------\")\nprint(\"Y_train\", y_train.shape)\nprint (\"------------------------------------\")\nprint(\"Y_test\", y_test.shape)","eee238ee":"epoch=1000\nbatch=10\nneuronas=10\na1=\"softplus\"\na2=\"softmax\"\nmodel = keras.Sequential([\n    layers.Dense(neuronas, activation=a1,input_shape=(13,)),\n    layers.Dense(neuronas, activation=a2),\n    layers.Dense(neuronas, activation=a2),\n    layers.Dense(neuronas, activation=a2),\n    layers.Dense(1, activation=\"tanh\")])\nsgd = SGD(lr=0.1)\nmodel.compile(optimizer=sgd, loss='mean_squared_error')\n\nmodel.fit(X_train, y_train, epochs=epoch, batch_size=batch)","2668335b":"y_hat_train = model.predict(X_train).round() # for traning data\ncm_train = confusion_matrix(y_train,y_hat_train)\nlabels = np.unique(y_hat_train)\nsns.heatmap(cm_train, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"inferno\")\nplt.ylabel(\"Predicted\")\nplt.xlabel(\"Truth\")\nplt.title(\"Confusion Matrix for prediction using training data\");","8ffe6ad1":"print(accuracy_score(y_train,y_hat_train))\nprint(classification_report(y_train,y_hat_train))","8e4e6273":"y_hat_test = model.predict(X_test).round() # for test data\ncm_test = confusion_matrix(y_test,y_hat_test)\nlabels = np.unique(y_hat_test)\nsns.heatmap(cm_test, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"inferno\")\nplt.ylabel(\"Predicted\")\nplt.xlabel(\"Truth\")\nplt.title(\"Confusion Matrix for prediction using test data\");","03f5eda9":"print(accuracy_score(y_test,y_hat_test))\nprint(classification_report(y_test,y_hat_test))","09aa92ce":"Now we can predict \"y\" values","1d5d3376":"Now it's possible program an artificial neural network using Keras.\n\nThe NN has the following specifications\n\n* epoch=1000\n\n* batch size=10\n\n* number of neuron in each one layer=10\n\n* 5 layers, the first using softplus, trhee more using softmax and the last with hyperbolic tangent Activation Function\n\n* The optimizer is of Gradient descent (with momentum) stochastic, with a learning rate of 10%","7703653f":"It's time to create the training and test data","076048ad":"\"y\" is the values that we want to predict\n\n\"X\" is the data to predict \"y\"","454bbfc9":"En espa\u00f1ol:\n\n303 datos con 14 columnas\n\n* age= Edad\n* sex= Sexo (1=hombre, 0=mujer)\n* cp= Cardiopat\u00eda (0=ninguna)\n* trestbps= Presi\u00f3n arterial en reposo (mm Hg)\n* chol= Colerter\u00f3l s\u00e9rico (mg \/ dl)\n* fbs= Nivel de azucar en ayunas & gt; 120 mg \/ dl (1= verdadero, 0=falso)\n* restecg= Resultados de electrocardiograma en reposo\n* thalach= Frecuencia cardiaca m\u00e1xima\n* exang= Angina de pecho provocada por el ejercicio (1=si, 0=no)\n* oldpeak= Depresi\u00f3n del segmento ST provocada por el ejercicio en comparaci\u00f3n al reposo\n* slope= Pendiente del segmento ST durante el pico de ejercicio\n* ca= N\u00famero de vasos iluminados durante la fluroscop\u00eda\n* thal= 1 = normal; 2 = defecto fijo; 3 = defecto reversible\n* target (0 y 1)\n\nSin celdas vac\u00edas","58790514":"Now it's necessary divide the data in a vector called \"y\" and in a matrix called \"X\"","2cc40a26":"**Categorical data analysis**","ecf49e69":"**non categorical data analysis**","de5ac35a":"**Open Dataframe with Pandas**","8a293b64":"Now we normalized the \"X\" data with MinMaxScaler() "}}