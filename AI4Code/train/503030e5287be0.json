{"cell_type":{"dfc9b51f":"code","c1856836":"code","d04648ea":"code","980809f7":"code","f16aa30b":"code","cda8f228":"code","87cc8638":"code","9884c78f":"code","323020d4":"code","2b8feb85":"code","705990ab":"code","08dbe1b5":"code","c0341a47":"code","c245dcf9":"code","381fcd3b":"code","f4573294":"code","cfc5a50a":"code","0e4a9424":"code","822f7ed1":"code","97c543d6":"code","b2b2953c":"code","82ace5ba":"code","8399c4ee":"code","b8853c02":"code","3a1e07e6":"code","2ebbebfa":"code","2bd84300":"code","b208ec92":"markdown","d598da61":"markdown","38b9efe4":"markdown","648aa796":"markdown","b5306bdc":"markdown","62da8da2":"markdown","de103755":"markdown","dd4014fb":"markdown","3605b574":"markdown"},"source":{"dfc9b51f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1856836":"df = pd.read_csv('..\/input\/parkinsons-disease-data-set\/parkinsons.data')","d04648ea":"df.head(10)","980809f7":"df.info()","f16aa30b":"df.describe()","cda8f228":"df.shape","87cc8638":"df['status'].value_counts()","9884c78f":"df['status'].hist()","323020d4":"df.hist(figsize=(15, 20))","2b8feb85":"df.corr()","705990ab":"pd.plotting.scatter_matrix(df, figsize=(35, 40))","08dbe1b5":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","c0341a47":"class park_model(nn.Module):\n    # We have hidden layer containg 30 neurons and another containg 20 neurons\n    # We will use only 22 feature from the dataset we will exclude name and status\n    def __init__(self,in_features=22, h1=20, h2=30, out_features=1):\n        super().__init__()\n        self.fc1 = nn.Linear(in_features, h1)\n        self.fc2 = nn.Linear(h1, h2)\n        self.out = nn.Linear(h2, out_features)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.out(x)\n        return x","c245dcf9":"torch.manual_seed(7)\nmodel = park_model()","381fcd3b":"model","f4573294":"X = df.drop(['name', 'status'], axis=1).values\ny = df['status'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=8)\n\ny_train = y_train.reshape((X_train.shape[0],1))\n\nX_train = torch.FloatTensor(X_train)\nX_test = torch.FloatTensor(X_test)\n\ny_train = torch.FloatTensor(y_train)\ny_test = torch.FloatTensor(y_test)","cfc5a50a":"print(X_train.shape)\nprint(y_train.shape)","0e4a9424":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","822f7ed1":"epochs = 1000\nlosses = []\n\nfor i in range(epochs):\n    i+=1\n    y_pred = model.forward(X_train)\n    loss = criterion(y_pred, y_train)\n    losses.append(loss)\n    \n    # a neat trick to save screen space:\n    if i%10 == 1:\n        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","97c543d6":"import matplotlib.pyplot as plt\n\nplt.plot(np.array(losses))","b2b2953c":"with torch.no_grad():\n    y_val = model.forward(X_test)\n    loss = criterion(y_val, y_test)\nprint(f'{loss:.8f}')","82ace5ba":"import tensorflow as tf\nimport keras","8399c4ee":"X = df.drop(['name', 'status'], axis=1).values\ny = df['status'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=8)\n\ny_train = y_train.reshape((X_train.shape[0],1))","b8853c02":"modeltf = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(20),\n    tf.keras.layers.Dense(30),\n#     tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","3a1e07e6":"modeltf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","2ebbebfa":"modeltf.fit(X_train, y_train, epochs=100)","2bd84300":"modeltf.evaluate(X_test, y_test)","b208ec92":"1. First we have 5 samples.\n2. We have 24 columns.","d598da61":"# This notebook is about using DS(Data science) to get imporatnt answers from this data set.\n\n## We need to ask questions like:\n1. What are the most important features related to the target?\n2. What is the distribution of each feature?\n3. Do we need to clean the data?\n4. Are the classes balanced?\n\n### Then we will build a small model using ***Pytorch & TensorFlow*** to predict the status of the paitent.\n\nHope you enjoy it ^_^\n![Pytorch is Fun](https:\/\/miro.medium.com\/max\/6400\/1*LLVL8xUiUOBE8WHgzAuY-Q.png)\n![](https:\/\/www.tensorflow.org\/resources\/images\/tf-logo-card-16x9.png)","38b9efe4":"**To get the correlation values between different features.**","648aa796":"# First we need to identify the data and know more insights about it","b5306bdc":"***It is noticed that there is imbalance between the two target classes which will lead to a problem when we train our model, it will be more biased towards the positive class.***","62da8da2":"**To show the structure of our Neural Network**","de103755":"# we don't have Nan values .","dd4014fb":"***We will use all features as a basic draft model, then we will enhance the notebook in the incoming versions to choose best features and to build a more powerful and robust models***","3605b574":"# To get the distribuition of each feature."}}