{"cell_type":{"02557adc":"code","5866fba5":"code","b3bfded2":"code","e128b535":"code","b72a757d":"code","cbdfdc26":"code","682366ee":"code","2e80cff1":"code","3f434c73":"code","480673f8":"code","f4a28141":"code","30befc98":"code","434971f8":"code","bedb43d3":"code","77b8c724":"code","a3ef9941":"code","a6e993ea":"code","b9e1d5d7":"code","b7caeb5a":"code","aaaff2f5":"code","750a42c6":"code","49b4a629":"code","c4a8784e":"code","ee7a79ce":"code","7cd87d32":"markdown"},"source":{"02557adc":"!pip install caer canaro","5866fba5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(14, 14))\nfrom tensorflow.keras import utils\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom sklearn.model_selection import train_test_split\nimport cv2 as cv\nimport caer\nimport canaro\nimport gc\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3bfded2":"IMG_SIZE = (80, 80)\nCHANNELS = 1\nCHAR_PATH = r'..\/input\/the-simpsons-characters-dataset\/simpsons_dataset'\nBATCH_SIZE = 32\nEPOCHS = 20","e128b535":"# read character names and # of images (len) from the respective directories\nCHAR_DICT = {}\nfor char in os.listdir(CHAR_PATH):\n    CHAR_DICT[char] = len(os.listdir(os.path.join(CHAR_PATH, char)))\n    \n# sort keys based on len value descending order\nCHAR_DICT = caer.sort_dict(CHAR_DICT, descending=True)\nCHAR_DICT","b72a757d":"# consider first 10 characters\nCHARACTERS = []\nfor i in CHAR_DICT[:10]:\n    CHARACTERS.append(i[0])\n    \nCHARACTERS","cbdfdc26":"# Create training data\ntrain = caer.preprocess_from_dir(CHAR_PATH, CHARACTERS, channels=CHANNELS, IMG_SIZE=IMG_SIZE, isShuffle=True)","682366ee":"len(train)","2e80cff1":"train.shape","3f434c73":"plt.imshow(train[0][0])\nplt.show()","480673f8":"# Separate feature_set from labels \nfeature_set, labels = caer.sep_train(train, IMG_SIZE=IMG_SIZE)","f4a28141":"# Normalize the feaure set and get dummy of labels\nfeature_set = caer.normalize(feature_set)\nlabels = utils.to_categorical(labels, len(characters))","30befc98":"# Train and Validation split\n# x_train, x_val, y_train, y_val = train_val_split(feature_set, labels, val_ratio=.2)\nsplit_data = train_test_split(feature_set, labels, test_size=.2)\nx_train, x_val, y_train, y_val = (np.array(item) for item in split_data)","434971f8":"len(feature_set), len(x_train), len(y_train), len(x_val), len(y_val)","bedb43d3":"# garbage collect\n# del train\n# del feature_set\n# del labels\n# gc.collect()","77b8c724":"BATCH_SIZE","a3ef9941":"# Image data generator\n\ndatagen = canaro.generators.imageDataGenerator()\ntrain_gen = datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)","a6e993ea":"# Create a model\nmodel = canaro.models.createSimpsonsModel(IMG_SIZE=IMG_SIZE, channels=CHANNELS, \n                                          output_dim=len(CHARACTERS), loss='binary_crossentropy', \n                                          decay=1e-6, learning_rate=0.001, momentum=0.9, nesterov=True)","b9e1d5d7":"plot_model(model)","b7caeb5a":"callbacks_list = [LearningRateScheduler(canaro.lr_schedule)]","aaaff2f5":"training = model.fit(train_gen,\n                    steps_per_epoch = len(x_train)\/\/BATCH_SIZE,\n                    epochs = EPOCHS,\n                    validation_data = (x_val, y_val),\n                    validation_steps = len(y_val)\/\/BATCH_SIZE,\n                    callbacks = callbacks_list)","750a42c6":"CHARACTERS","49b4a629":"def preprocess_img(img):\n    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n    img = cv.resize(img, IMG_SIZE)\n    img = caer.reshape(img, IMG_SIZE, 1)\n    return img","c4a8784e":"# Evalue Model Predictions\ntest_img_path = '..\/input\/the-simpsons-characters-dataset\/kaggle_simpson_testset\/kaggle_simpson_testset\/krusty_the_clown_5.jpg'\n\nimg = cv.imread(test_img_path)\nplt.imshow(img);\nplt.title('Raw Image')\nplt.show();\n\n# Process Image\nprocessed_img = preprocess_img(img)\nplt.imshow(processed_img[0]);\nplt.title('Processed Image')\nplt.show();","ee7a79ce":"plt.imshow(processed_img[0]);\nactual = 'krusty_the_clown'\nprediction = model.predict(processed_img)\nprediction = CHARACTERS[np.argmax(prediction[0])]\n\nplt.title(f'Actual:{actual}, Predictions:{prediction}')","7cd87d32":"__It's a correct predictions. To be honest, I had to try multiple test images, to get a correct prediction. It was expected though.. our accuracy was just 47%. We should use a better Network for better accuracy__\n"}}