{"cell_type":{"4814f859":"code","fab36277":"code","1b67fea3":"code","ed6945d4":"code","ed5161e1":"code","d4ef5354":"code","6c08884d":"code","3247a4e3":"code","263b898b":"code","87d2a974":"code","0fd45752":"code","0aa48e24":"code","cac330f0":"code","a082e529":"code","3a112cad":"code","8d0c7748":"code","6a552250":"code","53181a35":"code","1b173f24":"code","0bca1fc3":"code","0a899d50":"code","ccc14e3e":"code","c233d53c":"code","33089b35":"code","eb917562":"code","42d0941a":"code","5fc6d7db":"code","acc9b472":"code","010347e6":"code","b7b713af":"code","ddc2c2eb":"code","77cc2cab":"code","f70636ff":"code","a985403b":"code","97a1aad5":"code","7dcb8197":"code","c7aad3c3":"code","cdb67aa7":"code","b153b955":"code","c07f319f":"code","ca98d8a5":"code","82d295b5":"code","d2926d7f":"code","10c8d662":"code","b1bc46f8":"code","5ad0445e":"code","9822c993":"code","bf79f55e":"code","dea45dd6":"code","7c0dca52":"code","7f41a9d0":"code","0774b71c":"code","62503d6e":"code","c6ee4dab":"code","ce2e50be":"code","c16aa7bf":"code","a0d26025":"code","af6f9af6":"code","3f91f323":"code","071894b3":"code","f6679a23":"code","9d6f3ce3":"markdown","a2da46c2":"markdown","353e6f37":"markdown","980b4b53":"markdown","a1baca0d":"markdown","48cfd679":"markdown","fa4113c0":"markdown","52cc11fd":"markdown","03464688":"markdown","41720b93":"markdown","4fe00e51":"markdown","48cdb2ab":"markdown","e7b3d95b":"markdown","b3388a03":"markdown","9a72618f":"markdown","69a73dd6":"markdown","73b4a806":"markdown","5e4c5002":"markdown","ba912b78":"markdown","e9dd6f6b":"markdown","c6db7913":"markdown"},"source":{"4814f859":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fab36277":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set()","1b67fea3":"df= pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.head()","ed6945d4":"print(df.shape)","ed5161e1":"df.columns","d4ef5354":"df.info()","6c08884d":"df.describe(include='all')","3247a4e3":"df= df.drop(['Name', 'PassengerId', 'Ticket'], axis=1)\ndf.head()","263b898b":"# Let's get unique values for each category\nunique_vals = {\n    k: df[k].unique()\n    for k in df.columns\n}\n\nunique_vals","87d2a974":"df.dtypes","0fd45752":"df['Survived'] = df['Survived'].astype('category')\ndf['Pclass'] = df['Pclass'].astype('category')\ndf['Sex'] = df['Sex'].astype('category')\ndf['Embarked'] = df['Embarked'].astype('category')","0aa48e24":"numerical_cols= df.columns[df.dtypes == 'float']\n\n# Categorical columns are the following\ncategorical_cols = [x for x in df.columns if x not in numerical_cols]\n\nprint(f\"numerical columns = {numerical_cols}\")\nprint(f\"categorical columns = {categorical_cols}\")","cac330f0":"df.isnull().sum()","a082e529":"df= df.drop(['Cabin'], axis=1)","3a112cad":"# From above, it is clearly evident that missing values are present in many columns\n\n# Filling the missing values of numeric columns with median value\ndf[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n\n# Filling the missing values of categorical column with the most frequent value from one column. \n#Embarked Column have 2 missing Values. We can fill it with maximum frequency value of 'S'\ndf['Embarked'].fillna('S', inplace=True)\n\n# Checking no more NULLs in the data\nall(df.isna().sum() == 0)","8d0c7748":"df.dtypes","6a552250":"df['Age'].hist()","53181a35":"# Plot for survival vs Age\nage_survival = sns.catplot(x=\"Survived\", y=\"Age\", data=df)\nage_survival.fig.suptitle('Survival based on age')","1b173f24":"sns.pairplot(df, hue='Survived', diag_kind='hist')\nplt.show()","0bca1fc3":"df.hist(figsize=(12,6))\nplt.show()","0a899d50":"sns.countplot(x='Embarked', data=df, hue='Survived')\nplt.show()","ccc14e3e":"station=df.groupby('Sex')['Embarked'].value_counts().reset_index(name='count')\nstation","c233d53c":"sns.barplot(x='Embarked', y='count', data=station, hue='Sex')\nplt.show()","33089b35":"sns.countplot(x='Parch', hue='Survived', data=df)\nplt.legend(loc='upper right')\nplt.show()","eb917562":"sns.barplot(x='Pclass', y='Fare', data=df)\nplt.show()","42d0941a":"df.boxplot(figsize=(8,6))\nplt.show()","5fc6d7db":"df.describe(include='all')","acc9b472":"df.corr()","010347e6":"df.var()","b7b713af":"df['TravelAlone']=np.where((df[\"SibSp\"]+df[\"Parch\"])>0, 0, 1)\ndf.head()","ddc2c2eb":"print(df.shape)","77cc2cab":"#PClass, SibSp, Parch belongs to ordinal category\n#Perform Onehode Encoding only on Sex and Embarked though it is nominal categorical colummns\n\nencoded= pd.get_dummies(df[['Sex', 'Embarked']], drop_first=True)\nencoded.head()","f70636ff":"df_final= pd.concat([df, encoded], axis=1)\ndf_final= df_final.drop(['Sex','Embarked','SibSp','Parch'], axis=1)\ndf_final.head()","a985403b":"#seperate the training and test set\n\ny= df_final['Survived']\nX= df_final.drop('Survived', axis=1)\n\ny.value_counts()","97a1aad5":"from sklearn.model_selection import train_test_split, cross_val_score\n\n#Lets divide the data-set into training and test-set\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=30, test_size=0.30,stratify=y)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","7dcb8197":"from sklearn.preprocessing import StandardScaler\n\nscaler= StandardScaler()\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\n\nX_train, X_test","c7aad3c3":"from sklearn.linear_model import LogisticRegression\n\nseed=3\n#Instantiate Logistic Regression model\nlogreg= LogisticRegression(solver='lbfgs', max_iter=1800, random_state=seed)","cdb67aa7":"# Compute 5-fold cross-validation scores: cv_scores\ncv_scores= cross_val_score(logreg, X, y, cv=5)\n\n# Print the 5-fold cross-validation scores\nprint(cv_scores)\nprint(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))","b153b955":"#Fit the logistic regression model to training data\nlogreg.fit(X_train, y_train)","c07f319f":"#Check Training and Test Set Accuracy\n\ntraining_accuracy= logreg.score(X_train, y_train)\ntest_accuracy= logreg.score(X_test, y_test)\n\nprint(f\"Training Set accuracy = {training_accuracy}\")\nprint(f\"Test Set accuracy = {test_accuracy}\")","ca98d8a5":"# Coefficients of the model and its intercept\nprint(logreg.coef_)\nprint(logreg.intercept_)","82d295b5":"# Coefficients of the model and its intercept\nprint(dict(zip(X.columns, abs(logreg.coef_[0]).round(2))))\nprint(logreg.intercept_)","d2926d7f":"from sklearn.feature_selection import RFE\nfrom sklearn.metrics import accuracy_score\n\n# Create the RFE with a LogisticRegression estimator and 5 features to select\nrfe = RFE(estimator=logreg, n_features_to_select=5, verbose=1)\n# Fits the eliminator to the data\nrfe.fit(X_train, y_train)\n# Print the features and their ranking (high = dropped early on)\nprint(dict(zip(X.columns, rfe.ranking_)))\n# Print the features that are not eliminated\nprint(X.columns[rfe.support_])\n# Calculates the test set accuracy\nacc = accuracy_score(y_test, rfe.predict(X_test))\nprint(\"{0:.1%} accuracy on test set.\".format(acc))","10c8d662":"from sklearn.model_selection import GridSearchCV\n\n# Instantiate the GridSearchCV object and run the search\nsearcher = GridSearchCV(logreg, {'C':[0.001, 0.01, 0.1, 1, 10]})\nsearcher.fit(X_train, y_train)\n# Report the best parameters\nprint(\"Best CV params\", searcher.best_params_)","b1bc46f8":"selected_features= ['Pclass', 'Age', 'TravelAlone', 'Sex_male', 'Embarked_S']\n\n#seperate the training and test set\n\nX_RFE= df_final[selected_features]\ny= df_final['Survived']","5ad0445e":"from sklearn.model_selection import train_test_split, cross_val_score\n\n#Lets divide the data-set into training and test-set\ntrain_X, test_X, train_y, test_y = train_test_split(X_RFE, y, random_state=30, stratify=y)\n\ntrain_X.shape, test_X.shape, train_y.shape, test_y.shape","9822c993":"#Instantiate Logistic Regression model\nmodel= LogisticRegression(C=0.1)\n\n#Fit the logistic regression model to training data\nmodel.fit(train_X, train_y)","bf79f55e":"#Predictions on Test set\ny_pred= model.predict(test_X)\ny_pred","dea45dd6":"# Making the confusion matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\ncm = confusion_matrix(test_y,y_pred)\nacc_score = accuracy_score(test_y, y_pred)\n\nprint(f\"Accuracy = {acc_score*100:.2f}%\")\nprint(f\"Confusion matrix = \\n{cm}\")","7c0dca52":"#Check Training and Test Set Accuracy\n\ntraining_accuracy= model.score(train_X, train_y)\ntest_accuracy= model.score(test_X, test_y)\n\nprint(f\"Training Set accuracy = {training_accuracy}\")\nprint(f\"Test Set accuracy = {test_accuracy}\")","7f41a9d0":"from sklearn.metrics import roc_curve, auc\n\n#compute predicted probabilities: y_pred_prob\ny_pred_prob= model.predict_proba(test_X)[:,1]\n\n\n#Generate ROC curve values: fpr, tpr, thresholds\nfpr, tpr, thresholds = roc_curve(test_y, y_pred_prob)\n\n# Calculate the AUC\n\nroc_auc = auc(fpr, tpr)\nprint ('ROC AUC: %0.3f' % roc_auc )\n\n#Plot ROC curve\nplt.figure(figsize=(10,8))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","0774b71c":"test_df= pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_df.head()","62503d6e":"test_df.isnull().sum()","c6ee4dab":"test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\ntest_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\ntest_df.isnull().sum()","ce2e50be":"test_df['TravelAlone']=np.where((test_df[\"SibSp\"]+test_df[\"Parch\"])>0, 0, 1)\n\nvalid_data= test_df.drop([\"SibSp\", \"Parch\"], axis=1)\nvalid_data.head()","c16aa7bf":"test_data=valid_data.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1)\ntest_data.head()","a0d26025":"encoded_test= pd.get_dummies(test_data[['Sex', 'Embarked']], drop_first=True)\nencoded_test.head()","af6f9af6":"df_test= pd.concat([test_data, encoded_test], axis=1)\ndf_test= df_test.drop(['Sex','Embarked'], axis=1)\ndf_test.head()","3f91f323":"df_test.isnull().sum()","071894b3":"df_test['Survived'] = model.predict(df_test[selected_features])\ndf_test","f6679a23":"\ndf_test['PassengerId'] = test_df['PassengerId']\n\nsubmission= df_test[['PassengerId','Survived']]\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","9d6f3ce3":"#### Model Evaluation:\nEvaluate model performance by plotting an ROC curve","a2da46c2":"More People from Southampton were survived","353e6f37":"#### HyperParameterTuning\n\n\u2022\tC(inverse regularization strength)\n\nSmaller C value= more regularization.More regularization results in lower training accuracy, (almost always) higher test accuracy","980b4b53":"#### Model Validation:","a1baca0d":"#### Visual EDA","48cfd679":"There are outliers present in Numeric Columns\nNumerical Columns are in Different Scale. making sure that all of your data is on the same scale is advisable for most analyses","fa4113c0":"Out of all people embarked from Southampton Port, most of them are Male","52cc11fd":"Feature Engineering\nExtract New Column 'Travel Alone' combining SibSp, Parch","03464688":"No Distinctive pattern found in pairwise relationships","41720b93":"Name and Passenger Column has unique values in each observation. Keeping it for analysis will add no meaning to our model. Ticket also has more unique values. so, it is advisable to drop the columns.","4fe00e51":"some of feature coefficients are close to zero. We can check if model performance ever improved by dropping these features","48cdb2ab":"Target labels have uneven distribution; test and training sets might not be representative samples of our data and could bias the model we are trying to train. We will use stratified Sampling to split up the dataset according to the y dataset","e7b3d95b":"The AUC for both the test and train samples when run on my logistic regression demonstrates relatively strong power of separation between positive and negative occurences (survived - 1, died - 0)","b3388a03":"Most of the current passengers are in the 20-30 range. Also, by looking at statiscal summary of age column. mean of 29.8 and median of data are almost same. filling missing values with any of the method will be advisable. For now, we will fill missing values with median value of 28","9a72618f":"Now that we have got our cleaned dataset, we will explore patterns\/insights using Visual EDA","69a73dd6":"Cabin has more missing values. Filling the column with any of the strategy will add up bias in our ML model. So, will drop the column","73b4a806":"RFE- Recursive Feature Elimination is features selection algorithm wrapped around model coefficient values. This function takes the model, number of features to be select for the model. Wrap a Recursive Feature Eliminator (RFE) around our logistic regression estimator and pass it the desired number of features.","5e4c5002":"#### Statistical EDA","ba912b78":"### Apply the same changes we did in Train dataset to Test Dataset","e9dd6f6b":"Some of the features have categorical definition but described as numerial columns. Lets make them as 'category' dtype","c6db7913":"    Drop Columns PassengerId, Name, Cabin, Ticket from Test Dataframe\n    Fill the missing values of Age with median\n    No missing values with Embarked\n    Fare has missing value. fill it with median"}}