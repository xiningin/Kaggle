{"cell_type":{"1d0f04ba":"code","feaeb79c":"code","a394841c":"code","81218a03":"code","f9019ae9":"code","689d8ee7":"code","c3247854":"code","3855df79":"code","fd5873e9":"code","21b9d409":"code","32518669":"code","e782847a":"code","fbf16335":"code","53d27c7c":"code","d7c794f9":"code","0a120e7b":"code","68f1abed":"code","19209933":"code","2f50309d":"code","b2d7678f":"code","87f07c7f":"code","6b2109d9":"code","453bcde1":"code","458c9cf0":"code","fde709c5":"code","65e6a0c7":"code","c6dd16ab":"code","57190f85":"code","52f4009f":"markdown","df70f7b0":"markdown","2f282ac8":"markdown","1bf109a3":"markdown","1b4ab1df":"markdown","24ecf41e":"markdown","5446c6ec":"markdown","4813c803":"markdown","196203a9":"markdown","c65f27c5":"markdown","1fea6ca3":"markdown","1ca5ff2d":"markdown","9a5828db":"markdown","aa47872f":"markdown","52612089":"markdown","25d6302a":"markdown","3f7b2a97":"markdown","d4154968":"markdown","981bd434":"markdown","e6b4d27a":"markdown","06117904":"markdown","82be86fe":"markdown","a472ff76":"markdown","5f662edc":"markdown","9b725ee8":"markdown","71494f4f":"markdown","4e0b627e":"markdown","2d95bf02":"markdown"},"source":{"1d0f04ba":"import os\nimport pandas as pd\n\ninput_io_dir=\"..\/input\"\n\noriginal_train_data=pd.read_csv(input_io_dir+\"\/train.csv\")\noriginal_test_data=pd.read_csv(input_io_dir+\"\/test.csv\")\nprint('original_train_data',original_train_data.shape)\nprint('original_test_data',original_test_data.shape)","feaeb79c":"original_train_data.head()","a394841c":"print('Training data --------------')\nprint(original_train_data.info())\nprint('Test data ------------------')\nprint(original_test_data.info())","81218a03":"original_train_data.describe()","f9019ae9":"original_test_data.describe()","689d8ee7":"def ExploreCategoricalVariable(dataSet,variableName):\n    print('Variable:'+variableName)\n    print(dataSet[variableName].value_counts()\/len(dataSet[variableName]))\n    print('')\n\nprint('----------------------- Training set')\nExploreCategoricalVariable(original_train_data,'Sex')\nExploreCategoricalVariable(original_train_data,'Pclass')\nExploreCategoricalVariable(original_train_data,'Embarked')\nprint('----------------------- Test set')\nExploreCategoricalVariable(original_test_data,'Sex')\nExploreCategoricalVariable(original_test_data,'Pclass')\nExploreCategoricalVariable(original_test_data,'Embarked')","c3247854":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfig, axarr = plt.subplots(4, 2, figsize=(12, 8))\n\noriginal_train_data['Age'].hist(ax=axarr[0][0])\noriginal_test_data['Age'].hist(ax=axarr[0][1])\noriginal_train_data['Fare'].hist(ax=axarr[1][0])\noriginal_test_data['Fare'].hist(ax=axarr[1][1])\noriginal_train_data['Parch'].hist(ax=axarr[2][0])\noriginal_test_data['Parch'].hist(ax=axarr[2][1])\noriginal_train_data['SibSp'].hist(ax=axarr[3][0])\noriginal_test_data['SibSp'].hist(ax=axarr[3][1])","3855df79":"original_train_data.corr()","fd5873e9":"original_train_data.groupby('Sex')['Survived'].sum().plot.bar(stacked=True)","21b9d409":"original_train_data.groupby('Embarked')['Survived'].sum().plot.bar(stacked=True)","32518669":"original_train_data.head()","e782847a":"import numpy as np\n\ndef extractTitleFromNameForExploring(name):\n    pos_point=name.find('.')\n    if pos_point == -1: return \"\"\n    wordList=name[0:pos_point].split(\" \")\n    if len(wordList)<=0: return \"\"\n    title=wordList[len(wordList)-1]\n    return title\n\n# Get a list with different titles\ntraining_titleList=np.unique(original_train_data['Name'].apply(lambda x: extractTitleFromNameForExploring(x)))\nfor title in training_titleList:\n    training_titleSet=original_train_data[original_train_data['Name'].apply(lambda x: title in x)]\n    # Evaluate survival rate for each subset\n    survivalRate=float(len(training_titleSet[training_titleSet['Survived']==1]))\/float(len(training_titleSet))\n    print('Title['+title+'] count:'+str(len(training_titleSet))+' survival rate:'+str(survivalRate))","fbf16335":"# Let's check test data set values - just to confirm the training will consider all potential values\ntest_titleList=np.unique(original_test_data['Name'].apply(lambda x: extractTitleFromNameForExploring(x)))\nfor title in test_titleList:\n    test_titleSet=original_test_data[original_test_data['Name'].apply(lambda x: title in x)]\n    print('Title['+title+'] count:'+str(len(test_titleSet)))","53d27c7c":"import numpy as np\n\ndef multipleReplace(text, wordDic):\n    for key in wordDic:\n        if text.lower()==key.lower():\n            text=wordDic[key]\n            break\n    return text\n\ndef normaliseTitle(title):\n    wordDic = {\n    'Mlle': 'Miss',\n    'Ms': 'Mrs',\n    'Mrs':'Mrs',\n    'Master':'Master',\n    'Mme': 'Mrs',\n    'Lady': 'Nobility',\n    'Countess': 'Nobility',\n    'Capt': 'Army',\n    'Col': 'Army',\n    'Dona': 'Other',\n    'Don': 'Other',\n    'Dr': 'Other',\n    'Major': 'Army',\n    'Rev': 'Other',\n    'Sir': 'Other',\n    'Jonkheer': 'Other',\n    }     \n    title=multipleReplace(title,wordDic)\n    return title\ndef extractTitleFromName(name):\n    pos_point=name.find('.')\n    if pos_point == -1: return \"\"\n    wordList=name[0:pos_point].split(\" \")\n    if len(wordList)<=0: return \"\"\n    title=wordList[len(wordList)-1]\n    normalisedTitle=normaliseTitle(title)\n    return normalisedTitle\n\n# Get a list with different titles\ntitleList=np.unique(original_train_data['Name'].apply(lambda x: extractTitleFromName(x)))\nfor title in titleList:\n    titleSet=original_train_data[original_train_data['Name'].apply(lambda x: title in extractTitleFromName(x))]\n    # Evaluate survival rate for each subset\n    survivalRate=float(len(titleSet[titleSet['Survived']==1]))\/float(len(titleSet))\n    print('Title['+title+'] count:'+str(len(titleSet))+' survival rate:'+str(survivalRate))","d7c794f9":"original_train_data['IsAlone']=(original_train_data[\"SibSp\"]+original_train_data[\"Parch\"]).apply(lambda x: 0 if x>0 else 1)\noriginal_train_data['FamilySize']=original_train_data[\"SibSp\"]+original_train_data[\"Parch\"]+1\n\noriginal_train_data.corr()","0a120e7b":"import numpy as np\ntotal=original_train_data.groupby('IsAlone')['PassengerId'].count()\nsurvived=original_train_data[original_train_data['Survived']==1].groupby('IsAlone')['PassengerId'].count()\nnotSurvived=original_train_data[original_train_data['Survived']==0].groupby('IsAlone')['PassengerId'].count()\ndf=pd.concat([total, survived,notSurvived], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Total','Survived','NotSurvived']\ndf=df.astype('int64')\nprint(df)\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","68f1abed":"print(\"FamilySize value distribution\")\nprint(original_train_data['FamilySize'].value_counts()\/len(original_train_data))","19209933":"import numpy as np\ntotal=original_train_data.groupby('FamilySize')['PassengerId'].count()\nsurvived=original_train_data[original_train_data['Survived']==1].groupby('FamilySize')['PassengerId'].count()\nnotSurvived=original_train_data[original_train_data['Survived']==0].groupby('FamilySize')['PassengerId'].count()\ndf=pd.concat([total, survived,notSurvived], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Total','Survived','NotSurvived']\ndf=df.astype('int64')\nprint(df)\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","2f50309d":"original_train_data['NoCabin']=original_train_data['Cabin'].isnull().apply(lambda x: 1 if x is True else 0)\noriginal_train_data.corr()","b2d7678f":"total=original_train_data.groupby('NoCabin')['PassengerId'].count()\nsurvived=original_train_data[original_train_data['Survived']==1].groupby('NoCabin')['PassengerId'].count()\nnotSurvived=original_train_data[original_train_data['Survived']==0].groupby('NoCabin')['PassengerId'].count()\ndf=pd.concat([total, survived,notSurvived], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Total','Survived','NotSurvived']\ndf=df.astype('int64')\nprint(df)\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","87f07c7f":"import numpy as np\n# Group data to detect sharing of cabins - excluding missing  values\ncabinList=original_train_data[original_train_data['Cabin'].notnull()==True].groupby('Cabin')['PassengerId'].count()\ncabinList=cabinList.reset_index()\ncabinList.columns=['Cabin','Count']\nprint('Distribution of people per cabin - not considering those with missing cabin')\nprint(cabinList['Count'].value_counts())\n\n# Add new column to indicate number of people a passenger is sharing with\n# -1 means there is no data to compute the feature\ndef extractCabinSharedWithFeature(name):\n    if (str(name)!='nan'):\n        row=cabinList.loc[cabinList['Cabin'] == name]\n        count=row['Count']-1\n        return count\n    else:\n        return -1\n\noriginal_train_data['CabinSharedWith']=original_train_data['Cabin'].apply(lambda x: extractCabinSharedWithFeature(x)).astype(int)\n# Let's now analyse this new column\ntotal=original_train_data[original_train_data['CabinSharedWith']!=-1]['PassengerId'].count()\nsurvived=original_train_data[(original_train_data['CabinSharedWith']!=-1) & (original_train_data['Survived']==1)].groupby('CabinSharedWith')['PassengerId'].count()\nnotSurvived=original_train_data[(original_train_data['CabinSharedWith']!=-1) & (original_train_data['Survived']==0)].groupby('CabinSharedWith')['PassengerId'].count()\nsurvivedPercent=survived\/total\nnotSurvivedPercent=notSurvived\/total\nprint('Survivor distribution by feature CabinSharedWith')\nprint(survivedPercent)\nprint('NotSurvivor distribution by feature CabinSharedWith')\nprint(notSurvivedPercent)\ndf=pd.concat([survived,survivedPercent,notSurvived,notSurvivedPercent], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Survived','SurvivedPercent','NotSurvived','NotSurvivedPercent']\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","6b2109d9":"original_train_data.corr()","453bcde1":"original_train_data['Ticket'].head(10)","458c9cf0":"def getTicketType(name, normalise):\n    item=name.split(' ')\n    itemLength=len(item)\n    if itemLength>1:\n        ticketType=\"\"\n        for i in range(0,itemLength-1):\n            ticketType+=item[i].upper()\n    else:\n        ticketType=\"NORMAL\"\n    if normalise==True:\n        ticketType= ticketType.translate(str.maketrans('','','.\/'))\n    return ticketType\n\n# Let's list what we have - first view without normalising\ntraining_itemList=[]\nfor ticket in original_train_data['Ticket']:\n    training_itemList.append(getTicketType(ticket,False))\nticketTypeList=np.unique(training_itemList)\nprint(\"Ticket type values: no normalisation\")\nprint(ticketTypeList)","fde709c5":"training_itemList=[]\nfor ticket in original_train_data['Ticket']:\n    training_itemList.append(getTicketType(ticket,True))\nticketTypeList=np.unique(training_itemList)\nprint(\"Ticket type values: normalisation\")\nprint(ticketTypeList)","65e6a0c7":"pd.set_option('display.max_columns', None)\noriginal_train_data['TicketType']=original_train_data['Ticket'].apply(lambda x: getTicketType(x,True))\ntotal=pd.DataFrame(original_train_data.groupby('TicketType')['PassengerId'].count())\ntotal.columns=['Total']\nsurvived=pd.DataFrame(original_train_data[original_train_data['Survived']==1].groupby('TicketType')['PassengerId'].count())\nsurvived.columns=['Survived']\nnotSurvived=pd.DataFrame(original_train_data[original_train_data['Survived']==0].groupby('TicketType')['PassengerId'].count())\nnotSurvived.columns=['NotSurvived']","c6dd16ab":"# Let's merge all ticket type in the same list\ndf_all=total\ndf_all=df_all.merge(survived,left_index=True, right_on=\"TicketType\")\ndf_all=df_all.merge(notSurvived,left_on='TicketType',left_index=True, right_on=\"TicketType\")\ndf_all['Ratio']=df_all['Survived']\/df_all['Total']\ndf_all.loc[:,['Ratio']].plot.bar(figsize=(20,8))\ndf_all\n","57190f85":"original_train_data[original_train_data['TicketType']=='FCC']","52f4009f":"Same concern as with the previous feature - what if this feature is highly correlated with socio-economic status?\nIt may be redundant and ineffective for training...\nLet's explore the data directly....in particular, the ticketType with the highest ratio.","df70f7b0":"Ups...there is a new value (Dona) which was not present in the training data set.","2f282ac8":"Now, we will explore correlation between these values and survival...","1bf109a3":"Interesting! It seems that  three of the members belong to the same family...  \nLet's take note for the next rounds of exploration...","1b4ab1df":"For categorical data (non-ordinal), let's analyse data manually...","24ecf41e":"There is some correlation with socio-economic status - Fare\/Pclass.\nIn case these are relevant variables for training, I wonder whether this new variables will contribute much or will be somewhat redudant.","5446c6ec":"## Building new features\nThe following features are good candidates for creating new features:\n* Name\n* Parch\n* SibSp \n* Cabin \n* Ticket","4813c803":"Strange but true, it seems that those with no cabin assigned are less likely to survive than those with cabin.\nIt would be wise to know exactly what 'not having a cabin assigned' really means.\n\nLet's know have a look at shared cabins - are people sharing cabins more likely to survive?\n","196203a9":"# Titanic Competition: Exploring Data - Iteration 1\n\nWelcome! This kernel is part of the *Titatic competition learning series* which can be accessed from <a href=\"https:\/\/www.kaggle.com\/sergioortiz\/titanic-competition-a-learning-diary\">here<\/a>.  \n\nLet's start with the data exploration basics...","c65f27c5":"## Trends and correlations\nLet's start identifying correlations with the corr function.\nThis will be useful only for ordinal variables as it reflects the extent to which a variable (e.g. Survived) varies when other features values change.  ","1fea6ca3":"### General overview: conclusions\n* Small training data set - less than 1,000 rows. \n* Features by type\n  * Categorical\n    * Pclass: ordinal\n    * Sex\n    * Embarked\n  * Numeric\n    * Age: continuous\n    * Fare: continuous\n    * SibSp: discrete\n    * Parch: discrete\n  * Other\n    * Name\n    * Ticket\n    * Cabin\n* Missing data\n  * Age: some missing values - strategy relevant for training\n  * Cabin: many missing values - watch out as training may not be good on such a reduced data set\n  * Embarked: few missing values - strategy unlikely to affect training\n* Potential outliers (Fare - max is far way from mean+-std)","1ca5ff2d":"In both cases, it seems there is a clear relationship with survival - e.g. female are more likely to survive than male - and also people embarking in Southampton.","9a5828db":"Survival varies with family size  - families with 3 and 4 members are the most likely to survive.","aa47872f":"Some of the tickets types are quite similar.\nLet's normalise them so that they are grouped.","52612089":"The following title values are numerous and will be very useful for the learning model:\n* Miss\n* Mr\n* Mrs\n* Master  \n...but others are not so numerous, as Capt or Jonkheer.\nIt is also remarkable:\n* Some titles seem redundant -e.g. Mme = Miss or Mlle=Mrs  \n* Some titles can be grouped in categories\n  * Army-related\n    * Capt\n    * Col\n    * Major\n  * Nobility\n    * Countess\n    * Lady\n    \n Let's group titles in these categories and analyse again data... \n\n\n\n\n\n","25d6302a":"### Trends and correlations: conclusions\nInitial exploration only directly relates a small subset of features with survival:\n* Sex\n* Embarked\n* Fare\n* Pclass\n\nThis does not mean that the rest of features are not related - may be it's only that the relationship is not obvious.","3f7b2a97":"## General overview\nLet's first have a look at some data with basic pandas DataFrame functions...","d4154968":"### Ticket: exploring TicketType\nThe ticket feature can be difficult to explore as contains text and code information altogether.  \nLet's explore the field and try to build something useful...","981bd434":"### Potential barriers for learning: conclusions\nThere are no significant differences in both categorical and numeric data - that is, it appears to be evenly distributed between the two data sets.  \nOn the other hand, there can be limitations derived from the reduced data set size - e.g. some learning models can improve its accuracy with increased datasets. Learning curves will help to evaluate if this is the case.\nFinally, existing features present very different values and this can hinder learning. Data values must be scaled and normalised.","e6b4d27a":"## Potential barriers for learning\nLet's analyse different factors that can hinder learning\n### Comparing training and test data sets\nLearning models can be ineffective when data distribution is very different between training and test sets.<br\/>\nLet's explore this subject for a while...","06117904":"### Name: exploring Title feature\nThe most obvious case is extracting the title feature from the name string.\nLet's  create an initial extraction routine and analyse how the feature is correlated with survival","82be86fe":"It seems what tickets have prefixes - we will extract them and try to find patterns.","a472ff76":"Ups...travelling Alone appears to be negatively correlated with Survival - almost 42% of lonely passengers didn't survive!","5f662edc":"In the table above, we will look at the the second column - Survived column.\nAs we can see, the following fields are clearly correlated:\n* Fare\n* Pclass\n\nUnlike I would have expected, it is curious how Age is not directly correlated with survival.\nBoth SubSp and Parch are not directly related with the survival.  ","9b725ee8":"### Cabin: exploring passengers with NoCabin defined\nCabin is one of the most unreliable features as there are many missing values.\nHowever, let's explore if defining the cabin is related with survival\n","71494f4f":"Some of the categories such as Army or Nobility have a so few samples that the learning algorithm may not be able to learn effectively.  \nIn addition to these categories, we may be able to extract additional features related with Age (e.g. Master is a young boy) or Marital Status. However, we will stop here and postpone this exploration for the next iteration.\n\n### Parch\/SibSp: exploring IsAlone and FamilySize feature\nCombining these two features we can extract whether a passenger traveled alone and family size. \nLet's explore these possibilities...","4e0b627e":"### Devising new features: conclusions\nThese are the conclusions after work on this section:  \n* New features\n  * Title\n  * IsAlone\n  * FamilySize\n  * NoCabin\n  * CabinSharedWith\n  * TicketType\n * Doubts on whether some of these features will add more variance and enrich the learning model.","2d95bf02":"Interesting - notice how survival rate is higher among those passengers sharing cabin.\nWe might wonder whether this is true or those sharing cabin have something in common.\nLet's search for correlations..."}}