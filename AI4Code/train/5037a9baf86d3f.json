{"cell_type":{"959650de":"code","12267ca8":"code","51086165":"code","ab826ee6":"code","359dce5e":"code","4202392f":"code","dd4dedc9":"code","5d9b2907":"code","8ff4357d":"code","e01c75ed":"code","0c397b47":"code","e77df84d":"code","ffdade2b":"code","5ff29478":"code","568e769e":"code","11a83122":"code","b30f0667":"code","1f0085e8":"code","b7919792":"code","0ac0333c":"code","bb118894":"markdown","2f91521e":"markdown","1f75c466":"markdown","cbbcd973":"markdown","3639815d":"markdown","d32e4fc4":"markdown","826eb3cd":"markdown","d9121a8b":"markdown"},"source":{"959650de":"import torch\nfrom torch import nn,optim,tensor\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets,transforms\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport time\nimport pandas as pd","12267ca8":"pip install py7zr","51086165":"import py7zr\n\narchive = py7zr.SevenZipFile('..\/input\/cifar-10\/test.7z', mode='r')\n# Must have a root folder wrapper on the test dataset folder.\n# Otherwise, the ImageFolder will complain.\narchive.extractall(path=\".\/root_test\")\narchive.close()","ab826ee6":"batch_size = 32 \nnum_print = int(50000\/\/batch_size\/\/4)  \nepoch_num = 50  \nlr = 0.01        \nstep_size = 10  ","359dce5e":"def transforms_RandomHorizontalFlip():\n    transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                          transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n    transform = transforms.Compose([transforms.ToTensor(),\n                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n    train_dataset = datasets.CIFAR10(root='.\/data', \n                                     train=True, transform = transform_train,download=True)\n    test_dataset = datasets.CIFAR10(root='.\/data', \n                                    train=False, transform = transform,download=True)\n    return train_dataset,test_dataset","4202392f":"train_dataset,test_dataset = transforms_RandomHorizontalFlip()\n\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size,shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size = batch_size,shuffle=False)","dd4dedc9":"classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\ndef image_show(img):\n    img = img \/ 2 + 0.5     \n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\ndef label_show(loader):  \n    global classes\n    dataiter = iter(loader)  \n    images, labels = dataiter.next()\n    image_show(make_grid(images))\n    print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n    return images,labels\nlabel_show(train_loader)","5d9b2907":"from torch import nn\n\ndef vgg_block(num_convs,in_channels,out_channels):\n    blk = []\n    for i in range(num_convs):\n        if i == 0:\n            blk.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,stride = 1,padding = 1 ))\n        else:\n            blk.append(nn.Conv2d(out_channels,out_channels,kernel_size=3,stride = 1,padding = 1 ))\n        blk.append(nn.BatchNorm2d(out_channels))\n        blk.append(nn.ReLU(inplace = True))\n    blk.append(nn.MaxPool2d(kernel_size=2,stride=2))\n    return nn.Sequential(*blk)\n\nclass Vgg16_Net(nn.Module):\n    def __init__(self,conv_arch,fc_features,fc_hidden_units):\n        super(Vgg16_Net, self).__init__()\n        self.conv_arch = conv_arch\n        self.fc_features = fc_features\n        self.fc_hidden_units = fc_hidden_units\n        self.conv_layer = nn.Sequential()\n        for i ,(num_convs,in_channels,out_channels) in enumerate(self.conv_arch):\n            self.conv_layer.add_module('vgg_block_'+str(i+1),vgg_block(num_convs,in_channels,out_channels))\n        self.fc_layer = nn.Sequential(   \n                nn.Linear(self.fc_features, self.fc_features),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.5),\n                \n                nn.Linear(self.fc_features, self.fc_hidden_units),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.5),\n        \n                nn.Linear(self.fc_hidden_units, 10)\n                )\n        \n    def forward(self, x):\n        x = self.conv_layer(x)\n        x = x.view(-1, self.fc_features)\n        x = self.fc_layer(x)\n        return x\n","8ff4357d":"'''\nfrom torch import nn\n\nclass Vgg16_Net(nn.Module):\n    def __init__(self):\n        super(Vgg16_Net, self).__init__()\n        #2\u4e2a\u5377\u79ef\u5c42\u548c1\u4e2a\u6700\u5927\u6c60\u5316\u5c42\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size = 3, stride=1, padding=1),             # (32-3+2)\/1+1 = 32  32*32*64\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64,64, kernel_size = 3, stride=1, padding=1),             # (32-3+2)\/1+1 = 32  32*32*64\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2)                                                  # (32-2)\/2+1 = 16    16*16*64\n            \n            )\n        #2\u4e2a\u5377\u79ef\u5c42\u548c1\u4e2a\u6700\u5927\u6c60\u5316\u5c42\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size = 3, stride=1, padding=1),           # (16-3+2)\/1+1 = 16  16*16*128\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(128, 128, kernel_size = 3, stride=1, padding=1),          # (16-3+2)\/1+1 = 16  16*16*128\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2)                                                  # (16-2)\/2+1 = 8    8*8*128\n            )\n        #3\u4e2a\u5377\u79ef\u5c42\u548c1\u4e2a\u6700\u5927\u6c60\u5316\u5c42\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size = 3, stride=1, padding=1),          # (8-3+2)\/1+1 = 8  8*8*256\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(256, 256, kernel_size = 3, stride=1, padding=1),          # (8-3+2)\/1+1 = 8  8*8*256\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(256, 256, kernel_size = 3, stride=1, padding=1),          # (8-3+2)\/1+1 = 8  8*8*256\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2),                                                 # (8-2)\/2+1 = 4    4*4*256\n            )\n        #3\u4e2a\u5377\u79ef\u5c42\u548c1\u4e2a\u6700\u5927\u6c60\u5316\u5c42\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size = 3, stride=1, padding=1),          # (4-3+2)\/1+1 = 4  4*4*512\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(512, 512, kernel_size = 3, stride=1, padding=1),          # (4-3+2)\/1+1 = 4  4*4*512\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(512, 512, kernel_size = 3, stride=1, padding=1),          # (4-3+2)\/1+1 = 4  4*4*512\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2)                                                  # (4-2)\/2+1 = 2    2*2*512\n            )\n        #3\u4e2a\u5377\u79ef\u5c42\u548c1\u4e2a\u6700\u5927\u6c60\u5316\u5c42\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size = 3, stride=1, padding=1),          # (2-3+2)\/1+1 = 2  2*2*512\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(512, 512, kernel_size = 3, stride=1, padding=1),          # (2-3+2)\/1+1 = 2  2*2*512\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(512, 512, kernel_size = 3, stride=1, padding=1),          # (2-3+2)\/1+1 = 2  2*2*512\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2)                                                  # (2-2)\/2+1 = 1    1*1*512\n            )\n        self.conv = nn.Sequential(\n            self.layer1,\n            self.layer2,\n            self.layer3,\n            self.layer4,\n            self.layer5\n            )\n        self.fc = nn.Sequential(    \n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            \n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n    \n            nn.Linear(256, 10)\n            )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.view(-1, 512)\n        x = self.fc(x)\n        return x\n\n'''","e01c75ed":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","0c397b47":"conv_arch = ((2,3,64),(2,64,128),(3,128,256),(3,256,512),(3,512,512))\nfc_features = 512\nfc_hidden_units = 256\n\nmodel = Vgg16_Net(conv_arch,fc_features,fc_hidden_units).to(device)","e77df84d":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(),lr = lr,momentum = 0.8,weight_decay = 0.001 )\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.5, last_epoch=-1)","ffdade2b":"loss_list = []\nstart = time.time()\n\n# train\nfor epoch in range(epoch_num):  \n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader, 0):\n        inputs ,labels = inputs.to(device),labels.to(device)\n        \n        optimizer.zero_grad()   \n        outputs = model(inputs)\n        loss = criterion(outputs, labels).to(device)\n        \n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        loss_list.append(loss.item())\n        if i % num_print == num_print-1 :\n            print('[%d epoch, %d] loss: %.6f' %(epoch + 1, i + 1, running_loss \/ num_print))\n            running_loss = 0.0  \n    lr_1 = optimizer.param_groups[0]['lr']\n    print('learn_rate : %.15f'%lr_1)\n    scheduler.step()\n\nend = time.time()\nprint('time:{}'.format(end-start))","5ff29478":"# loss images show\nplt.plot(loss_list, label='Minibatch cost')\nplt.plot(np.convolve(loss_list,np.ones(200,)\/200, mode='valid'),label='Running average')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Iteration')\nplt.legend()\nplt.show()","568e769e":"# prediction with images\nimages,labels = label_show(test_loader)\nimages, labels = images.to(device), labels.to(device)\noutputs = model(images)\npredicted = outputs.argmax(dim = 1)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size)))","11a83122":"# test\nmodel.eval()\ncorrect = 0.0\ntotal = 0\nwith torch.no_grad():  # No need to back propogate\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device) \n        outputs = model(inputs)\n        pred = outputs.argmax(dim = 1)  \n        total += inputs.size(0)\n        correct += torch.eq(pred,labels).sum().item()\nprint('Accuracy of the network on the 10000 test images: %.2f %%' % (100.0 * correct \/ total))\n\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nfor inputs, labels in test_loader:\n    inputs, labels = inputs.to(device), labels.to(device)\n    outputs = model(inputs)\n    pred = outputs.argmax(dim = 1)  \n    c = (pred == labels.to(device)).squeeze()\n    for i in range(4):\n        label = labels[i]\n        class_correct[label] += float(c[i])\n        class_total[label] += 1\n\nfor i in range(10):\n    print('Accuracy of %5s : %.2f %%' % (classes[i], 100 * class_correct[i] \/ class_total[i]))","b30f0667":"# show feature_map\na = 0\ndef viz(module, input):\n    global a\n    x = input[0][0].cpu()\n    # print(x.device)\n    min_num = min(4,x.size()[0])\n    for i in range(min_num):\n        plt.subplot(1, min_num, i+1)\n        plt.xticks([]) \n        plt.yticks([])  \n        plt.axis('off')\t\n        plt.rcParams['figure.figsize'] = (20, 20) \n        plt.rcParams['savefig.dpi'] = 480\n        plt.rcParams['figure.dpi'] = 480\n        plt.imshow(x[i])\n    plt.savefig('.\/'+str(a)+'.jpg')\n    a += 1\n    plt.show()","1f0085e8":"dataiter = iter(test_loader)  \nimages, labels = dataiter.next()\n\nfor name, m in model.named_modules():\n    if isinstance(m, torch.nn.Conv2d):\n        m.register_forward_pre_hook(viz)\n\nmodel.eval()\nwith torch.no_grad():\n    model(images[2].unsqueeze(0).to(device))","b7919792":"transform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n\ntest_ds = datasets.ImageFolder('root_test', transform=transform_test)\n\ntest_iter = torch.utils.data.DataLoader(test_ds, 128, shuffle=False)","0ac0333c":"preds = []\nlabels = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n\nwith torch.no_grad():\n    for X, _ in test_iter:\n        y_hat = model(X.cuda(0))\n        preds.extend(y_hat.argmax(dim=1).type(torch.int32).cpu().numpy())\nsorted_ids = list(range(1, len(test_ds) + 1))\nsorted_ids.sort(key=lambda x: str(x))  # this version of test dataset sortted by this order\ndf = pd.DataFrame({'id': sorted_ids, 'label': preds})\ndf['label'] = df['label'].apply(lambda x: labels[x])\ndf.to_csv('submission.csv', index=False)","bb118894":"## Model and Optimizer","2f91521e":"## Define the Model\n","1f75c466":"# Homework 6 - Berkeley STAT 157\n\n**Your name: XX, SID YY, teammates A,B,C (Please add your name, SID and teammates to ease Ryan and Rachel to grade.)**\n\nHandout 3\/5\/2019, due 3\/12\/2019 by 4pm. Please submit through gradescope.\n\nIn this homework, we will train a CNN model on CIFAR-10 and submit the results into [Kaggle](https:\/\/www.kaggle.com\/c\/cifar-10). The rule is similar to homework 4: \n\n- work as a team\n- submit your results into Kaggle\n- take a screen shot of your best score and insert it below\n- the top 3 teams\/individuals will be awarded with 500 dollar AWS credits\n\nThe rest of this notebook contains a baseline ResNet-15 model to train on CIFAR-10. Please use it as a starting point. The end of this notebooks has several hints to improve your results.\n\nFirst, import the packages or modules required for the competition.","cbbcd973":"## Classify the Testing Set and Submit Results on Kaggle\n\nAfter obtaining a satisfactory model design and hyper-parameters, we use all training data sets (including validation sets) to retrain the model and classify the testing set.","3639815d":"## Train and Validate the Model\n","d32e4fc4":"## Feature Map","826eb3cd":"## Same Model in Another Way","d9121a8b":"After executing the above code, we will get a \"submission.csv\" file. The format of this file is consistent with the Kaggle competition requirements. \n\n## Hints to Improve Your Results\n\n* You should use the compete CIFAR-10 dataset to get meaningful results. \n* You'd better use a GPU machine to run it, otherwise it'll be quite slow. (Please DON'T FORGET to stop or terminate your instance if you are not using it, otherwise AWS will change you)\n* Change the `batch_size` and number of epochs `num_epochs` to 128 and 100, respectively. (It will take a while to run.)\n* Change to another network, such as ResNet-34 or Inception"}}