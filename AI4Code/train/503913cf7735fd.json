{"cell_type":{"eb7d6934":"code","38dfb8af":"code","641fac75":"code","40f9941f":"code","43be9ecb":"code","c673f15e":"code","a179912b":"code","591271d7":"code","7d88d762":"code","9caf4c8b":"code","0e6f3a47":"code","51cf6919":"code","3bf2ebf6":"code","8a7b6968":"code","e4c7a45f":"code","66780da2":"code","fbd3897d":"code","83d342d3":"code","01cd27ed":"code","82970449":"code","ce5dc72d":"code","e71bf877":"code","8a09929a":"code","17134e2b":"code","17ff398e":"code","d50160a0":"code","0ebd96be":"code","60448ccf":"code","5cbda544":"code","f24e8318":"code","9c0429cf":"code","785a197e":"code","0ecda202":"code","7ff72072":"code","25458d1d":"code","69aa07d4":"code","e58f7380":"code","c403674f":"code","8530837f":"code","8b5800fd":"code","da1b2fce":"code","2e66adc4":"code","28eec04b":"code","e2779eaa":"code","97b5f6ff":"code","4fc7d911":"code","3a8db65b":"code","9590a7c7":"code","689ceca9":"code","9b6cf13d":"code","55f01355":"code","609d4196":"code","09642600":"code","cd62316b":"code","84e63d51":"code","2bf3a44f":"code","4322f647":"code","5ab5480f":"code","6fb3327a":"code","fbf64b99":"code","cd73a314":"code","42027855":"code","ab8a9fad":"code","22500adb":"code","56a95c1b":"code","b9fa174f":"code","c783b39c":"code","5454a8a9":"code","64fe644a":"code","04c441b0":"code","ec205552":"code","a569a018":"code","d58d4952":"code","40024ae1":"code","a61d9e72":"code","c5cf3d57":"code","cb10f877":"code","4862fbba":"code","5d6057bb":"code","dad8cb25":"code","beb44b62":"code","3740d556":"code","5fd50cb7":"code","c00a6da9":"code","7d1b444a":"code","6a4340d3":"code","346a872f":"code","510ad678":"code","0c239cf9":"code","6171fa48":"code","0cc15c97":"code","73549c81":"code","b3ad0d80":"code","215003e4":"code","da8c76cd":"markdown","8ca0f9a4":"markdown","f85c5a39":"markdown","663ce43b":"markdown","d5e97bde":"markdown","848d396d":"markdown","79ae3a7c":"markdown","94d2d8ee":"markdown","2e27cc29":"markdown","95bcf3f5":"markdown","9961730e":"markdown","92d0f97a":"markdown","e45bae54":"markdown","a14c821c":"markdown","92062b8e":"markdown","a2e33dea":"markdown","8211978c":"markdown","0d4bf3f3":"markdown","3813ccf1":"markdown","9b9f5600":"markdown","d6263581":"markdown","85105f16":"markdown","29ce1e05":"markdown","0abfbc04":"markdown","c9b0fd63":"markdown","d1dd2591":"markdown","2e7759ae":"markdown","7093e2e5":"markdown","656875e0":"markdown","87a917a4":"markdown","574465fe":"markdown","3aa28075":"markdown","68802c4e":"markdown","efcbbaa4":"markdown","65074ab0":"markdown","d8cc3192":"markdown","0e1f5df3":"markdown","fc73405e":"markdown","47dcf567":"markdown","1dc75735":"markdown","55e62049":"markdown","d8a929f7":"markdown","4d41d060":"markdown","69685274":"markdown","84dc2572":"markdown","a7abdf6c":"markdown","40cf8ba7":"markdown","571be91f":"markdown","4ba4a5aa":"markdown","2a62fe5e":"markdown","d5882868":"markdown","8f42ccc2":"markdown","3b94d004":"markdown","ea318617":"markdown","d5dd4b9b":"markdown","a09bf176":"markdown","138e7c61":"markdown","a3d0f80c":"markdown","4148ff1d":"markdown","7e2193df":"markdown","d2395899":"markdown","2c951f9e":"markdown","1594bd9c":"markdown","fc1f8d76":"markdown","20abf791":"markdown","ae4e2d36":"markdown","3def65b9":"markdown","b6b898ff":"markdown","0db8bd9f":"markdown","2a1e2750":"markdown","ce5a939e":"markdown","4a7cbaf3":"markdown"},"source":{"eb7d6934":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","38dfb8af":"from imp import reload \nfrom tabulate import tabulate","641fac75":"import pandas as pd\nimport numpy as np\nimport math\nimport json\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","40f9941f":"from sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import confusion_matrix\n","43be9ecb":"sns.color_palette()","c673f15e":"plt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = (10,5)\nplt.rcParams['lines.linewidth'] = 2\n\n\nfont = {'family': 'serif',\n        'color':  '#2E86C1',\n        'weight': 'normal',\n        'size': 20,\n        }\n\nbase_color = sns.color_palette()[0]","a179912b":"import print as p\nfrom confusion_matrix import make_confusion_matrix","591271d7":"reload(p)","7d88d762":"# read in the json files\nportfolio = pd.read_csv('..\/input\/starbucks-customer-data\/portfolio.csv')\nprofile = pd.read_csv('..\/input\/starbucks-customer-data\/profile.csv')\ntranscript = pd.read_csv('..\/input\/starbucks-customer-data\/transcript.csv')","9caf4c8b":"profile.head(2)","0e6f3a47":"portfolio.head(2)","51cf6919":"transcript.head(2)","3bf2ebf6":"# check the type on columns\np.print_comment('check the type on columns')\n\nprofile.info()","8a7b6968":"# check the null values\np.print_comment('check the null values')\n\nprofile.isnull().sum()","e4c7a45f":"p.print_comment('check the age column')\n\n# check the age column\nprint(profile.age.value_counts(), '\\n')\n\np.print_comment('describe of age column')\n\n# check the describe of age column\nprint(profile.age.describe(), '\\n')\n\np.print_comment('check the age 118')\n\n# check the age 118\nx = profile[profile.age == 118]\nprint(x[:2])\nx.age.value_counts()","66780da2":"# check income column\np.print_comment('describe of income column')\nprofile.income.describe()","fbd3897d":"# check duplicate\np.print_comment('check duplicate')\nprofile[profile.duplicated()]","83d342d3":"portfolio.head(2)","01cd27ed":"# check columns type\np.print_comment('check columns type')\n\nportfolio.info()","82970449":"# check offer_type column\n\np.print_comment('check offer_type column')\nportfolio.offer_type.value_counts()","ce5dc72d":"transcript.head(2)","e71bf877":"# check column type\np.print_comment('check column type')\ntranscript.info()","8a09929a":"# check event column\np.print_comment('check event column')\ntranscript.event.value_counts()","17134e2b":"# check time column\np.print_comment('check time column')\ntranscript.time.value_counts()","17ff398e":"# check value column\np.print_comment('check value column')\ntranscript.value","d50160a0":"# check became_member_on column\np.print_comment('check became_member_on column')\n\nprint(profile.became_member_on.value_counts())\n\n# Code: convert date string to date\np.print_comment('Code:convert date string to date')\n\nprofile['became_member_on'] =\\\n    pd.to_datetime(profile.became_member_on, format=\"%Y%m%d\")\nprint('done')\n\n\n# test : convert date string to date\np.print_comment('test:convert date string to date')\nprint(profile.became_member_on)","0ebd96be":"# code: drop nan value rows\np.print_comment('code: drop nan value rows')\nprofile.dropna(inplace=True)\nprofile.reset_index(drop=True, inplace=True)\np.print_done()\n\n# test: \np.print_comment('test:')\nprofile.isnull().sum()","60448ccf":"# check columns name\np.print_comment('check columns name')\nprint(profile.columns)\n\n\n# code: change id name\ntry:\n    p.print_comment('code: change id name')\n    profile.rename(columns={\"id\": \"customer_id\"}, inplace=True)\nexcept Exception as e: print(e)\nelse:\n    p.print_done()\n\n\n# test:\np.print_comment('test: columns name')\nprint(profile.columns)","5cbda544":"profile.gender.value_counts()","f24e8318":"encoder = OneHotEncoder(sparse=False)\n\n\ntry:\n    # code: encode gender column\n    p.print_comment('code: encode gender column')\n    onehot = encoder.fit_transform(profile[['gender']])\n    # print(onehot)\n\n    profile[['Female', 'Male', 'other']] = onehot\n    \nexcept Exception as e: print(e)\nelse: p.print_done()","9c0429cf":"profile.head(2)","785a197e":"# code: encode become_member_on\np.print_comment('code: encode become_member_on')\ntry:\n    profile['become_member_on_year'] = profile.became_member_on.dt.year.astype(str)\n    profile['become_member_on_month'] = profile.became_member_on.dt.month.astype(str)\n    profile['become_member_on_day'] = profile.became_member_on.dt.day.astype(str)\nexcept Exception as e: print(e)\nelse: p.print_done()","0ecda202":"profile","7ff72072":"# drop become_member_on column\np.print_comment('drop become_member_on column')\n\nprofile.drop('became_member_on', axis=1, inplace=True)","25458d1d":"# check columns name\np.print_comment('check columns name')\nprint(portfolio.columns)\n\n\n# code: change id name\ntry:\n    p.print_comment('code: change id name')\n    portfolio.rename(columns={\"id\": \"offer_id\"}, inplace=True)\nexcept Exception as e: print(e)\nelse:\n    p.print_done()\n\n\n# test:\np.print_comment('test: columns name')\nprint(portfolio.columns)","69aa07d4":"# check the type\np.print_comment('check the type')\ntype(portfolio.channels[0])","e58f7380":"# return all channels\np.print_comment('return all channels')\ntry:\n    print(portfolio.channels.value_counts())\nexcept: pass","c403674f":"portfolio.head(2)","8530837f":"# code: split channels column\np.print_comment('code: split channels column')\n\ndef split_channels(channels_list):\n    \"\"\"split channels to columns\"\"\"\n    if channel in channels_list:\n        return 1\n    else:\n        return 0\ntry:\n    all_channels = ['web', 'email', 'mobile', 'social']\n    for channel in all_channels:\n        portfolio.loc[:, channel] = portfolio.channels.apply(split_channels)\n    \n    \nexcept: pass\n\nelse: p.print_done()\n\n\n# test\np.print_comment('test: split channels column')\n\nportfolio.head(2)","8b5800fd":"try:\n    p.print_comment('Drop channels column')\n    portfolio.drop('channels', axis=1, inplace=True)\nexcept: pass\nelse: p.print_done()","da1b2fce":"# return all offer_type\n\np.print_comment('return all offer_type')\noffer_type = portfolio.offer_type.unique()\noffer_type","2e66adc4":"portfolio.head(2)","28eec04b":"# code: split offer_type column\np.print_comment('code: split offer_type column')\n\ndef split_offer_type(val):\n    \"\"\"split offer_type column\"\"\"\n    if val == offer:\n        return 1\n    else:\n        return 0\n\ntry:\n    for offer in offer_type:\n        portfolio[offer] = portfolio.offer_type.apply(split_offer_type)\n    \nexcept: pass\nelse: p.print_done()\n    \n\n# test\np.print_comment('test: split offer_type column')\nportfolio.head(2)","e2779eaa":"portfolio","97b5f6ff":"# code: create offer_name column\np.print_comment('code: create offer_name column')\n\ntry: \n    lst = range(1,portfolio.shape[0]+1)\n    x = [f\"offer_{x}\" for x in lst]\n    portfolio['offer_name'] = x\n\nexcept: pass\n\nelse: \n    p.print_done()\n    print(portfolio[['offer_id','offer_name']])\n","4fc7d911":"transcript.head(5)","3a8db65b":"# check time column\np.print_comment('check time column')\nprint(transcript.time.value_counts().sort_index()[:5])\n\n# check the type\np.print_comment('check the type')\nprint(type(transcript.time[0]))","9590a7c7":"def convert_time_day(val):\n    \"\"\"convert from time to days\"\"\"\n    return val \/ 24\n\ntry:\n    # code: convert time to days\n    p.print_comment('code: convert time to days')\n\n    transcript['days'] = transcript.time.apply(convert_time_day)\n\nexcept Exception as e: print(e)\n\nelse: p.print_done()","689ceca9":"# test: convert time to days\np.print_comment('test: convert time to days')\n\ntranscript.days[-10:]","9b6cf13d":"# return columns name\n\np.print_comment('return columns name')\nprint(transcript.columns)\n\n# code: change column name\ntry:\n    p.print_comment('code: change column name')\n    transcript.rename(columns={\"person\": \"customer_id\"}, inplace=True)\nexcept: pass\nelse: p.print_done()\n    \n# test: change column name\np.print_comment('return columns name')\nprint(transcript.columns)","55f01355":"# check value column\np.print_comment('check value column')\ntranscript.value","609d4196":"\nimport ast\ndef string_to_dict(val):\n    return ast.literal_eval(val)\n\ntranscript.value = transcript.value.apply(string_to_dict)","09642600":"# return the keys in value column\np.print_comment('return the keys in value column')\n\nkeys = []\ndef get_keys(val):\n    \"\"\"return available keys\"\"\"\n    if list(val.keys()) not in keys:\n        keys.append(list(val.keys()))\n    \n    \ntranscript.value.apply(get_keys)\n\nkeys = [ item for elem in keys for item in elem]\nprint(keys)","cd62316b":"transcript.tail(10)","84e63d51":"def split_key(val):\n    \"\"\"split key column\"\"\"\n    if list(val.keys())[0].startswith(key[:2]):\n        return list(val.values())[0]\n    else:\n        return 0\n    \ntry:  \n    # code: split value column\n    p.print_comment('code: splite value column')\n    \n    for key in keys[1:3]:\n        transcript[key] = transcript.value.apply(split_key)\nexcept: pass\n\nelse: p.print_done()\n    \n# test: split value column\np.print_comment('test: splite value column')\ntranscript.tail(10)\n\n","2bf3a44f":"# drop value column\np.print_comment('drop value column')\n\ntranscript.drop('value', axis=1, inplace=True)\n\n# test\np.print_comment('test')\n\ntranscript.columns","4322f647":"# return unique value in event column\np.print_comment('return unique value in event column')\n\nevent_list = transcript.event.unique()\nevent_list","5ab5480f":"transcript.tail(50)","6fb3327a":"def split_event(val):\n    \"\"\"split event column\"\"\"\n    if val == event:\n        return 1\n    else:\n        return 0\n\ntry:\n    # code: split event column\n    p.print_comment('code: split event column')\n    \n    for event in event_list:\n        transcript[event] = transcript.event.apply(split_event)\nexcept: pass\nelse: p.print_done()\n    \n\n# test: split event column\np.print_comment('test: split event column')\n\ntranscript.tail(50)","fbf64b99":"# rename columns\np.print_comment('rename columns')\n\ntranscript.rename(columns={ \"offer received\": \"offer_received\", \n                            \"offer viewed\": \"offer_viewed\",\n                            \"offer completed\": \"offer_completed\"},\n                 inplace=True)\n\n# test: rename columns\np.print_comment('test: rename columns')\ntranscript.columns","cd73a314":"# create offer dataframe \noffer = transcript[transcript.event != 'transaction']\noffer.head()","42027855":"# check if the offer is success or not\n\n# Group-by value counts in event column \noffer_customer = offer.pivot_table(index=['customer_id','offer_id'],\\\n                 columns='event', aggfunc='size', fill_value=0)\noffer_customer.reset_index(level=[0,1], inplace=True)\n\n# creat successful_offer column \noffer_customer['successful_offer'] =\\\n    offer_customer['offer completed'] * offer_customer['offer viewed']\n\noffer_customer['successful_offer'] = offer_customer['successful_offer'].apply(lambda x: 1 if x > 0 else 0)","ab8a9fad":"# merge dataset profile and portolio and offer_customer\noverall_df = pd.merge(offer_customer,portfolio,on='offer_id', how='left')\noverall_df = pd.merge(overall_df,profile,on='customer_id')\noverall_df","22500adb":"# export clean data\np.print_comment('export clean data')\n\nprofile.to_csv('clean_profile.csv', index=False)\nportfolio.to_csv('clean_portfolio.csv', index=False)\ntranscript.to_csv('clean_transcript.csv', index=False)\noverall_df.to_csv('overall_df.csv', index=False)\n\np.print_done()","56a95c1b":"portfolio = pd.read_csv('clean_portfolio.csv')\nprofile = pd.read_csv('clean_profile.csv')\ntranscript = pd.read_csv('clean_transcript.csv')\noverall_df = pd.read_csv('overall_df.csv')","b9fa174f":"profile['become_member_on_month'] = profile.become_member_on_month.astype(str)\nprofile['become_member_on_year'] = profile.become_member_on_year.astype(str)\nprofile['become_member_on_day'] = profile.become_member_on_day.astype(str)","c783b39c":"gender_count = [profile.Female.sum(), profile.Male.sum(), profile.other.sum()]\nx_label = ['Female', 'Male', 'Other']\nsns.barplot(y = gender_count, x = x_label , color=base_color);\nplt.title('Gender Distribution', fontdict=font);\n","5454a8a9":"bin_edges = np.arange(0, profile['income'].max()+1, 10000)\n\nsns.histplot(profile['income'],bins=10);\nplt.xticks(bin_edges)\nplt.xlim(profile.income.min()-5000, profile.income.max()+5000)\nplt.title('Income Distribution', fontdict=font);","64fe644a":"bin_edges = np.arange(0, profile['age'].max()+10, 10)\nsns.histplot(profile['age'],bins=10);\nplt.xticks(bin_edges)\nplt.xlim(profile.age.min()-5, profile.age.max()+10)\nplt.title('Age Distribution', fontdict=font);","04c441b0":"cat_order = profile['become_member_on_year'].value_counts().index\nsns.countplot(data = profile, x = 'become_member_on_year', color=base_color, \n              order=cat_order)\nplt.title('New Member based of Year', fontdict=font)\n\n# add annotations\nn_points = profile.shape[0]\ncat_counts = profile['become_member_on_year'].value_counts()\nlocs, labels = plt.xticks() # get the current tick locations and labels\n\n# loop through each pair of locations and labels\nfor loc, label in zip(locs, labels):\n\n    # get the text property for the label to get the correct count\n    count = cat_counts[label.get_text()]\n    pct_string = '{:0.1f}%'.format(100*count\/n_points)\n\n    # print the annotation just below the top of the bar\n    plt.text(loc, count-8, pct_string, ha = 'center', color = 'k')\n","ec205552":"cat_order = profile['become_member_on_month'].value_counts().index\nsns.countplot(data = profile, x = 'become_member_on_month', color=base_color, \n              order=cat_order)\nplt.title('New Member based of Month', fontdict=font)\n\n# add annotations\nn_points = profile.shape[0]\ncat_counts = profile['become_member_on_month'].value_counts()\nlocs, labels = plt.xticks() # get the current tick locations and labels\n\n# loop through each pair of locations and labels\nfor loc, label in zip(locs, labels):\n\n    # get the text property for the label to get the correct count\n    count = cat_counts[label.get_text()]\n    pct_string = '{:0.1f}%'.format(100*count\/n_points)\n\n    # print the annotation just below the top of the bar\n    plt.text(loc, count-8, pct_string, ha = 'center', color = 'k')\n","a569a018":"sns.countplot(data = profile, x = 'become_member_on_year', hue = 'gender')\nplt.title('New Member based of Year and Gender', fontdict=font);","d58d4952":"sns.violinplot(data = profile, y = 'income', x = 'gender');\nplt.title('Income based on Gender', fontdict=font);","40024ae1":"sns.histplot(data=profile, x=\"income\", hue=\"gender\", multiple=\"stack\", \n            bins=10);\n\nbin_edges = np.arange(0, profile['income'].max()+1, 10000)\n\nplt.xticks(bin_edges)\nplt.xlim(profile.income.min()-5000, profile.income.max()+5000)\nplt.title('Income Distribution Based on Gender', fontdict=font);","a61d9e72":"# create event list\nx_value = ['Offer received','Offer viewed','Transaction','Offer completed']\ny_value = [transcript.offer_received.sum(), transcript.offer_viewed.sum(),\n    transcript.transaction.sum(), transcript.offer_completed.sum()]\n\n# sort values\nx_value = [x for _,x in sorted(zip(y_value,x_value), reverse=True)]\ny_value.sort(reverse=True)\n\n# show graph\nsns.barplot(y = y_value, x = x_value , color=base_color);\nplt.title('Event Distribution', fontdict=font);","c5cf3d57":"table = [\n    ['Number of customer made transaction' ,\n         transcript[transcript.transaction == 1].customer_id.count(),\n    '100%'],\n    \n    \n    ['Number of unique customers made transaction',\n        transcript[transcript.transaction == 1].customer_id.nunique(),\n    f\"{round((16578\/138953)*100, 2)}%\"],\n    \n    \n    ['Number of customers who recived offers', \n        transcript[transcript.transaction != 1].customer_id.count(),\n    '100%'],\n    \n    \n    ['Number of unique customers who recived offers',\n        transcript[transcript.transaction != 1].customer_id.nunique(),\n    f\"{round((16994\/167581)*100, 2)}%\"]\n        \n        ]\n\nheader = ['Notice', 'Number', 'Percentage']\n\nprint(tabulate(table,header, tablefmt=\"simple\"))","cb10f877":"x = overall_df['successful_offer'].value_counts()\nx.index = ['Failure', 'Success']\n\nax = sns.countplot(data = offer_customer, x = 'successful_offer', color = base_color)\nplt.title('Distribution of Successfule offers', fontdict=font);\nax.set_xticklabels(['Failure', 'Success']);\nax.set_xlabel('Successfule Offers');\n\n# add annotations\nn_points = overall_df.shape[0]\ncat_counts = x\nlocs, labels = plt.xticks() # get the current tick locations and labels\n\n# loop through each pair of locations and labels\nfor loc, label in zip(locs, labels):\n\n    # get the text property for the label to get the correct count\n    count = cat_counts[label.get_text()]\n    pct_string = '{:0.1f}%'.format(100*count\/n_points)\n\n    # print the annotation just below the top of the bar\n    plt.text(loc, count-8, pct_string, ha = 'center', color = 'k')","4862fbba":"plt.subplots(figsize=(15,5))\nax = sns.countplot(data = overall_df, x = 'offer_name', hue = 'successful_offer', \n                  palette=['#AAB7B8', '#5DADE2'])\nax.legend(['Failure', 'Success'], title = 'Offer', );\nplt.title('Distribution of Success based on offer type', fontdict=font);\nplt.xticks(rotation=20);\nplt.xlabel('Offer Name');","5d6057bb":"plt.subplots(figsize=(15,5))\nax = sns.countplot(data = overall_df, x = 'offer_name', hue = 'gender', \n                   )\nplt.title('Distribution of Offers based on Gender', fontdict=font);\nplt.xticks(rotation=20);\nplt.xlabel('Offers Name');","dad8cb25":"ax = sns.countplot(data = overall_df, x = 'gender', hue = 'successful_offer', \n                   palette=['#AAB7B8', '#5DADE2'])\nax.legend(['Failure', 'Success'], title = 'Offer', );\nplt.title('Distribution of Success based on gender', fontdict=font);\nplt.xlabel('Gender');","beb44b62":"succes_offer = overall_df[overall_df.successful_offer == 1]\nplt.subplots(figsize=(15,5))\nax = sns.countplot(data = succes_offer, x = 'offer_name', hue = 'gender', \n                   )\nplt.title('Distribution of of Success offers based on Gender', fontdict=font);\nplt.xticks(rotation=20);\nplt.xlabel('Offers Name');","3740d556":"ax = sns.histplot(data=overall_df, x=\"income\", hue=\"successful_offer\", multiple=\"stack\", \n            bins=10);\n\nbin_edges = np.arange(0, profile['income'].max()+1, 10000)\n\nplt.xticks(bin_edges)\nplt.xlim(profile.income.min()-5000, profile.income.max()+5000)\nplt.title('Income Distribution Based on Success', fontdict=font);","5fd50cb7":"overall_df = pd.read_csv('overall_df.csv')","c00a6da9":"overall_df.head()","7d1b444a":"# create x and y data\nX = overall_df.drop(['customer_id', 'offer_id', \n                     'offer_type', 'gender', 'offer_name', 'successful_offer', \n                    'offer received', 'social', 'discount', 'other', # remove C-1 binary variables\n                     'become_member_on_year', 'become_member_on_month',\n                     'become_member_on_day'], axis=1)\ny = overall_df.loc[:, 'successful_offer']","6a4340d3":"X.iloc[:5]","346a872f":"X.shape","510ad678":"X_train,X_test,y_train,y_test =\\\n    train_test_split(X, y, \n                     test_size=0.3, random_state=42)\n","0c239cf9":"all_column = X.columns\n\n# feature scaling\ntrf1 = ColumnTransformer([\n    ('scale', MinMaxScaler(), all_column)\n])\n\ntrf2 = LogisticRegression(solver='liblinear',random_state=42)","6171fa48":"pipe = Pipeline([\n    ('trf1', trf1),\n    ('trf2', trf2),\n])\n\n#fit data\npipe.fit(X_train, y_train);","0cc15c97":"# check cross validation \nscoring = ['accuracy', 'precision', 'recall']\n\ncross_val = cross_validate(pipe, X, y, cv=10, scoring=scoring)","73549c81":"# cross validation accurecy\ntable = []\nheader = [\"Matrices\", 'Score']\ntable.append(['Accuracy', cross_val['test_accuracy']])\ntable.append(['Precision', cross_val['test_precision']])\ntable.append(['Recall', cross_val['test_recall']])\n\nprint(tabulate(table, header, tablefmt=\"fancy_grid\"))","b3ad0d80":"# pipeline accurecy\npipe.score(X_test, y_test)","215003e4":"y_pred = pipe.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred)\n\ngroup_names =  ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['Zero', 'One']\n\nmake_confusion_matrix(cf_matrix, group_names,categories, cbar=False)","da8c76cd":"## Overall dataframe","8ca0f9a4":"> We can notice grow in member based on month is almost equal","f85c5a39":"## Data Preparation","663ce43b":"## Merge datasets\ncreate overall dataset that a combination from offer_customer dataset and profile dataset and portoflio dataset","d5e97bde":"### \n**Define**: `id` change his name to `offer_id`","848d396d":"### Gender Distribution","79ae3a7c":"### New Member based of Month","94d2d8ee":"> The Percentage of failure offers greater than success offers","2e27cc29":"### Income based on Gender","95bcf3f5":"> 2017 has the highest number of new members.","9961730e":"### Distribution of Offers based on Gender","92d0f97a":"> There are alot of offers need to review because is not success like offer_8. <br>\noffer_7, offer_9, offer_6 have a successeful story","e45bae54":"## Introduction\n\n- This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks.\n\n- Not all users receive the same offer, and that is the challenge to solve with this data set.\n\n- Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n\n- Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only $5$ days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n\n- You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer.\n\n- Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n\n\n## Data Sets\n\nThe data is contained in three files:\n\n* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n* profile.json - demographic data for each customer\n* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n\nHere is the schema and explanation of each variable in the files:\n\n### profile.json\n\n* `age` (int) - age of the customer \n* `became_member_on` (int) - date when customer created an app account\n* `gender` (str) - gender of the customer (note some entries contain '`O`' for other rather than M or F)\n* `id` (str) - customer id\n* `income` (float) - customer's income\n\n### portfolio.json\n\n* `id` (string) - offer id\n* `offer_type` (string) - type of offer ie BOGO, discount, informational\n* `difficulty` (int) - minimum required spend to complete an offer\n* `reward` (int) - reward given for completing an offer\n* `duration` (int) - time for offer to be open, in days\n* `channels` (list of strings)\n\n\n\n### transcript.json\n\n* `event` (`str`) - record description (ie transaction, offer received, offer viewed, etc.)\n* `person` (`str`) - customer id\n* `time` (`int`) - time in hours since start of test. The data begins at time `t=0`\n* `value` - (`dict of strings`) - either an offer id or transaction amount depending on the record","a14c821c":"# Export clean data","92062b8e":"### Distribution of of Success offers based on Gender","a2e33dea":"> We can notice that the most income between $50000 \\to 70000$","8211978c":"## ML Pipline","0d4bf3f3":"# Starbucks Capstone Challenge","3813ccf1":"### Offers Distribution","9b9f5600":"### \n**Define**: `channels` need to encode","d6263581":"## portfolio","85105f16":"# Import Datasets","29ce1e05":"### New Memeber based on Year and Gender","0abfbc04":"## Observation\n\n**Profile Dataset**\n- [x] `became_member_on` not date\n- [x] `gender`there are $2175$ Missing value\n- [x] `income`there are $2175$ Missing value\n- [x] `age` there are $2175$ persons have 118 years it seem to be outlier. we can also notice that is located in same row with `gender` and `income` that have `NaN` value\n- [x] `id` change his name to `customer_id`\n- [x] `gender` need to encode\n- [x] `become_member_on` need to encode\n\n---\n\n**Portfolio Dataset**\n- [x] `id` change his name to `offer_id`\n- [x] `channels` need to encode\n- [x] `offer_type` need to encode\n- [x] `offer_id` create column has offer name like `offer_1`\n\n---\n\n**Transcript Dataset**\n- [x] `time` convert to days\n- [x] `person` change his name to `customer_id`\n- [x] `value` extract `offer_id` and `amount`\n- [x] `event` need to encode","c9b0fd63":"### New Member based of Year","d1dd2591":"## profile","2e7759ae":"> We can notice that there are alot of repeated offers to the same customer\nalso we can notice that the customers who made transaction mostly are the same customers no new customer come","7093e2e5":"## profile","656875e0":"> We can notice that the most age is between 40 to 75","87a917a4":"### \n**Define**: id change his name to customer_id","574465fe":"> We can notice that the success offer in female is more than the other despite of the male in data set is more than female","3aa28075":"### Create Transformers","68802c4e":"### Train Test Split","efcbbaa4":"# Data Wrangling & Feature Enginnering","65074ab0":"### \n**Define**: `event` need to encode","d8cc3192":"### \n**Define**`become_member_on` need to encode","0e1f5df3":"---","fc73405e":"### \n**Define**: `offer_type` need to encode\n","47dcf567":"### Distribution of Success based on offer type","1dc75735":"### Create Pipeline","55e62049":"### Check the Accurecy","d8a929f7":"### Income Distribution","4d41d060":"### Distribution of Success based on Gender","69685274":"> The offers is failed with male more than female","84dc2572":"## Create successful offer column\n\n**Note**: that the offer be success if a customer completed an offer and viewed it and if not viewed the offer become not success offer","a7abdf6c":"> we can notice that most of users are Male","40cf8ba7":"> We can notice that the count Female gender is the highest one","571be91f":"## transcript","4ba4a5aa":"### \n**Define**: `person` change his name to `customer_id`","2a62fe5e":"# Exploratory analysis","d5882868":"### \n**Define**: `became_member_on` not date","8f42ccc2":"# Assessing","3b94d004":"> We can notice that most new member are Male","ea318617":"## transcript","d5dd4b9b":"## Create offer dataframe\n\ncreate offer dataframe from people that have offers","a09bf176":"> We can notice that most of offers are just received and viewed","138e7c61":"### \n**Define** `offer_id` create column has offer name like offer_1","a3d0f80c":"# Modeling\n\nI will build a model that **predicts whether or not someone will respond to an offer**. ","4148ff1d":"### Income Distribution Based on Success","7e2193df":"## Profile","d2395899":"## transcript","2c951f9e":"### Event Distribution","1594bd9c":"### Distribution of Successfule offers","fc1f8d76":"### \n**Define**: `age` there are $2175$ persons have 118 years it seem to be outlier. we can also notice that is located in same row with `gender` and `income` that have `NaN` value\n\n**Define**: `gender`there are $2175$ Missing value\n\n**Define**: `income`there are $2175$ Missing value","20abf791":"> We can notice that the income does not have any role in the reject offers","ae4e2d36":"# Load Lib","3def65b9":"### \n**Define**: `gender` need to encode","b6b898ff":"### \n**Define**: `time` convert to days","0db8bd9f":"### \n**Define**: `value` extract `offer_id` and `amount`","2a1e2750":"## portfolio ","ce5a939e":"### Age Distribution","4a7cbaf3":"> We can notice that male have more offers then female and that is normal because the count of male is more than female"}}