{"cell_type":{"2f48a21b":"code","23b293de":"code","cc967fdd":"code","502d1c3d":"code","fee5c12d":"code","46b05ba2":"code","6056b27b":"code","3ed49e30":"markdown","78bcee2d":"markdown","05a2062f":"markdown","e8f8ddea":"markdown","b9fe8332":"markdown"},"source":{"2f48a21b":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tqdm import trange","23b293de":"val_ratio = 0.1\nbatch_size = 512\nnum_epochs = 30","cc967fdd":"class MovieRatings(Dataset):\n    def __init__(self, dat_file):\n        dfr = pd.read_csv(dat_file, delimiter='::', header=None)\n        dfr.columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n        dfr = dfr.drop(columns=['Timestamp'])\n        self.samples = torch.from_numpy(dfr.values)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        # every sample is a tensor with 3 values: user ID, movie ID, and rating\n        return self.samples[idx]","502d1c3d":"class Model(nn.Module):\n    def __init__(self, num_users, num_movies, num_latent=30):\n        super(Model, self).__init__()\n        self.user_features = nn.Embedding(num_users, num_latent)\n        self.movie_features = nn.Embedding(num_movies, num_latent)\n        nn.init.normal_(self.user_features.weight, 0, 0.1)\n        nn.init.normal_(self.movie_features.weight, 0, 0.1)\n\n    def forward(self, user_ids, movie_ids):\n        users_latent = self.user_features(user_ids)\n        movies_latent = self.movie_features(movie_ids)\n        ratings = (users_latent * movies_latent).sum(dim=1)\n        return ratings","fee5c12d":"data = MovieRatings('..\/input\/movielens-1m\/ml-1m\/ratings.dat')\nval_size = int(len(data) * val_ratio)\ntrain_size = len(data) - val_size\ntrain, val = random_split(data, [train_size, val_size])\n\ndataloaders = {\n    'train': DataLoader(train, batch_size=batch_size, shuffle=True,\n                        num_workers=4),\n    'val': DataLoader(val, batch_size=batch_size, shuffle=False,\n                      num_workers=4)\n}\ndataset_sizes = {'train': train_size, 'val': val_size}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = Model(\n    num_users=data[:, 0].max() + 1,\n    num_movies=data[:, 1].max() + 1,\n    num_latent=30\n).to(device)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","46b05ba2":"bar = trange(num_epochs)\nepoch_loss = {'train': 0, 'val': 0}\ndft = pd.DataFrame(columns=['train_rmse', 'val_rmse'])\nfor epoch in bar:\n    # Each epoch has a training and validation phase\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()  # Set model to training mode\n        else:\n            model.eval()   # Set model to evaluate mode\n\n        running_loss = 0.0\n        bar.set_description(f'Epoch {epoch} {phase}'.ljust(20))\n\n        # Iterate over data.\n        for batch in dataloaders[phase]:\n            user_ids = batch[:, 0].to(device)\n            movie_ids = batch[:, 1].to(device)\n            ratings = batch[:, 2].float().to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward\n            # track history if only in train\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(user_ids, movie_ids)\n                preds = torch.round(outputs)\n                loss = criterion(outputs, ratings)\n\n                # backward + optimize only if in training phase\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n            # statistics\n            running_loss += loss.item() * user_ids.size(0)\n\n        epoch_loss[phase] = running_loss \/ dataset_sizes[phase]\n        bar.set_postfix(train_loss=f'{epoch_loss[\"train\"]:0.5f}',\n                        val_loss=f'{epoch_loss[\"val\"]:0.5f}')\n        dft.loc[epoch, f'{phase}_rmse'] = epoch_loss[phase]","6056b27b":"dft.plot(marker=\".\");","3ed49e30":"# 2. Imports and global variables","78bcee2d":"# 1. Another Matrix Factorization with PyTorch\n\nWe continue studying Matrix Factorization techniques. Now, using batches and PyTorch proper objects.\nSimple but very effective.","05a2062f":"# 3. Dataset interface","e8f8ddea":"# 5. Training","b9fe8332":"# 4. Model"}}