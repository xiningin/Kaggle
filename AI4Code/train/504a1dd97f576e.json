{"cell_type":{"215893ff":"code","894064e2":"code","561bc5b5":"code","796c6096":"code","ab1a2252":"code","303bb9a4":"code","8e3ae958":"code","b23d4d93":"code","471a438f":"code","c8f34fac":"code","58724439":"code","341a750c":"code","4c6633e6":"code","1834eed7":"code","e599258e":"code","d4c8c92d":"code","380c7bbf":"code","5c525aca":"code","f864b744":"code","e0afce29":"code","f250a5b5":"code","99c0cd72":"markdown","1fe28efb":"markdown","d839c7a5":"markdown","9bf2da12":"markdown","03c1ad0e":"markdown","d5f7f2b6":"markdown","467c1ecd":"markdown","00678f0b":"markdown"},"source":{"215893ff":"# !pip install tensorflow-gpu==2.0.0-beta1","894064e2":"from __future__ import absolute_import, division, print_function, unicode_literals\nimport os\nimport pathlib\nimport tensorflow as tf\ntf.enable_eager_execution()\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\n%matplotlib inline","561bc5b5":"# Compatibility operations\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","796c6096":"print('Version: {}'.format(tf.VERSION))","ab1a2252":"AUTOTUNE = tf.data.experimental.AUTOTUNE","303bb9a4":"# Organizing paths of data locations\nmain_path = pathlib.Path(r\"..\/input\/oct2017\/OCT2017 \")\ntrain_path = main_path \/ 'train'\ntest_path = main_path \/ 'test'\nval_path = main_path \/ 'val'\n\n# TRAIN_PATH='..\/input\/oct2017\/OCT2017 \/train'\n# TEST_PATH='..\/input\/oct2017\/OCT2017 \/test'\n# VAL_PATH='..\/input\/oct2017\/OCT2017 \/val'\n\ntrain_path","8e3ae958":"import random\ntrain_image_paths = [str(path) for path in list(train_path.glob('*\/*.jpeg'))]\nrandom.shuffle(train_image_paths)\ntest_image_paths = [str(path) for path in list(test_path.glob('*\/*.jpeg'))]\nval_image_paths = [str(path) for path in list(val_path.glob('*\/*.jpeg'))]\n\n\nprint('Number of training images:', len(train_image_paths))\nprint('Number of testing images:', len(test_image_paths))\nprint('Number of validation images:', len(val_image_paths))","b23d4d93":"label_names = sorted(set(item.name for item in train_path.glob('*') if item.is_dir()))\nlabel_to_index = dict((name, index) for index,name in enumerate(label_names))\nlabel_to_index","471a438f":"train_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in train_image_paths]\ntest_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in test_image_paths]\nval_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in val_image_paths]\n\nprint(\"First 10 labels indices: \", train_image_labels[:10])","c8f34fac":"ex_im = tf.read_file(train_image_paths[0])\nex_im = tf.image.decode_jpeg(ex_im, channels=1)\nex_im = tf.image.resize_images(ex_im, [192, 192])\n\nplt.imshow(ex_im[:, :, 0])","58724439":"target_im_size = [192, 192]\n\ndef preprocess_image(image):\n    image = tf.image.decode_jpeg(image, channels=1)\n    image = tf.image.resize_image_with_crop_or_pad(image, 496, 496) # First crop center square of image (some have extra left\/right pixels)\n    image = tf.image.resize_images(image, target_im_size) # Resize to final dimensions\n    image \/= 255.0  \n    return image\n\ndef load_and_preprocess_image(path):\n    image = tf.read_file(path)\n    return preprocess_image(image)","341a750c":"# Path datasets\ntrain_path_ds = tf.data.Dataset.from_tensor_slices(train_image_paths)\ntest_path_ds = tf.data.Dataset.from_tensor_slices(test_image_paths)\nval_path_ds = tf.data.Dataset.from_tensor_slices(val_image_paths)\n\n\n# Image datasets\ntrain_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\ntest_image_ds = test_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\nval_image_ds = val_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n\n# Label datasets\ntrain_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_image_labels, tf.int64))\ntest_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(test_image_labels, tf.int64))\nval_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(val_image_labels, tf.int64))\n\n\n# Datasets with both images and labels\ntrain_image_label_ds = tf.data.Dataset.zip((train_image_ds, train_label_ds))\ntest_image_label_ds = tf.data.Dataset.zip((test_image_ds, test_label_ds))\nval_image_label_ds = tf.data.Dataset.zip((val_image_ds, val_label_ds))","4c6633e6":"print('image shape: ', train_image_label_ds.output_shapes[0])\nprint('label shape: ', train_image_label_ds.output_shapes[1])\nprint('types: ', train_image_label_ds.output_types)\nprint()\nprint(train_image_label_ds)","1834eed7":"BATCH_SIZE = 64\n\ntrain_ds = train_image_label_ds.shuffle(buffer_size=400) # Shuffles datasets\ntrain_ds = train_ds.repeat() # Creates datasets iterator\ntrain_ds = train_ds.batch(BATCH_SIZE) # Batches dataset\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # Allows dataset to prefetch batches while training for performance\n\n# Repeat for testing dataset\ntest_ds = test_image_label_ds.shuffle(buffer_size=200)\ntest_ds = test_ds.repeat()\ntest_ds = test_ds.batch(BATCH_SIZE)\ntest_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n# Repeat for validation dataset\nval_ds = val_image_label_ds.shuffle(buffer_size=200)\nval_ds = val_ds.repeat()\nval_ds = val_ds.batch(BATCH_SIZE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)","e599258e":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (5, 5), padding='valid', activation='relu', input_shape=(*target_im_size, 1))) # CNN Layer 1\nmodel.add(layers.MaxPooling2D((2, 2))) # Pooling layer 1\n\nmodel.add(layers.Conv2D(64, (5, 5), activation='relu')) # CNN Layer 2\nmodel.add(layers.MaxPooling2D((2, 2))) # Pooling layer 2\n\nmodel.add(layers.Conv2D(128, (5, 5), activation='relu')) # CNN Layer 3\nmodel.add(layers.Flatten()) # Flattening layer\n\nmodel.add(layers.Dense(64, activation='relu')) # Fully-connected layer \"on top\"\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Dense(4, activation='softmax')) # Softmax output from logits","d4c8c92d":"model.summary()","380c7bbf":"model.compile(optimizer='adam',\n             loss='sparse_categorical_crossentropy',\n             metrics=['accuracy'])","5c525aca":"import os\n# Directory where the checkpoints will be saved\ncheckpoint_dir = '.\/training_checkpoints'\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_weights_only=True)","f864b744":"EPOCHS = 1\nmodel.fit(train_ds, epochs=EPOCHS, steps_per_epoch=len(train_image_paths)\/\/BATCH_SIZE, callbacks=[checkpoint_callback])","e0afce29":"test_loss, test_acc = model.evaluate(test_ds, steps=len(test_image_paths))","f250a5b5":"print('Model Accuracy on Test Data: {:.1f}%'.format(test_acc * 100))","99c0cd72":"#### Data loading, resizing and rescaling","1fe28efb":"#### Let's look at an example image.","d839c7a5":"#### Construct the CNN and DNN architecture.","9bf2da12":"#### Extracting label IDs for all corpora","03c1ad0e":"#### Extracting label names from parent directories and mapping to integer","d5f7f2b6":"#### Creating path datasets from which image datasets can be made.","467c1ecd":"#### Getting a list of paths to all images.","00678f0b":"#### Look at overall architecture of NN"}}