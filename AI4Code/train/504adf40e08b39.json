{"cell_type":{"77740b4b":"code","2df5d66e":"code","7c3aae2e":"code","5ab510e8":"code","e9f258bb":"code","07b85b12":"code","953290d9":"code","22f9984a":"code","97e8e53b":"code","51eb5435":"code","609fa111":"code","7c26ea8f":"code","0783f968":"code","e7eb99aa":"code","0d34db42":"code","c062a5ed":"code","f2c69d21":"code","190bb8e6":"code","29cce835":"code","2872d1ef":"code","a9d256e3":"code","e29413cb":"code","31916ded":"code","a40e74f2":"code","6a7937c6":"code","1678abd3":"code","e6e07431":"code","76516e5e":"code","9fc33616":"code","6f1838ce":"code","124bc9bc":"code","e9418d4b":"code","551f2d57":"code","bab85168":"code","8cba21f2":"code","bbab8d70":"code","02d232f4":"code","46e3a52a":"code","86c8432e":"code","f442575a":"code","42215b5d":"code","641a6cc3":"code","57c6dd7b":"markdown","64d1a16d":"markdown","c84b9df8":"markdown","993b7ebd":"markdown","91ebc7f6":"markdown","e6543c3c":"markdown","22bbaebf":"markdown","a9239b39":"markdown","bb927346":"markdown"},"source":{"77740b4b":"!pip install opencv-python\n!pip install efficientnet\nfrom keras.models import load_model","2df5d66e":"image_dir = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages'\namount_glob = 100\nmax_amount = 6000\n\"set\"","7c3aae2e":"import cv2\nimport os\n\n# def load_all_images(amount = max_amount):\n#     orig_imgs.clear()\n#     all_im = os.listdir(image_dir)\n#     for idx,img_path in enumerate(all_im):\n#         if (idx == amount):\n#             break    \n#         img = cv2.imread(image_dir+\"\/\"+img_path)\n#         orig_imgs.append(img)\n#         if (idx % 100 == 0):\n#             print (idx)\n#     return orig_imgs\n\n\n# load_all_images()\n# \"finished loading \", len (orig_imgs)\n\ndef load_images_iter(amount = 64,start_pos = 0, end_pos = 5011):\n  ans = []\n  all_im = os.listdir(image_dir)\n  all_im.sort()\n  print (len(all_im))\n  while (True):\n    for idx,img_path in enumerate(all_im[start_pos:end_pos]):\n      if (len(ans) !=0 and len(ans)%amount == 0):\n        ret = ans\n        ans = []\n        yield ret\n      ans.append(cv2.imread(image_dir+\"\/\"+img_path))","5ab510e8":"import numpy as np\n\ndef train_generator_1(batch=64, tar_size=144, train_size=72):\n    collect_train = []\n    collect_target = []\n    \n    while True:\n        file_gen = load_images_iter(amount=batch, start_pos = 1000)#first 1000 images are for validation\n        imgs = []\n        while (True):\n          try:\n            imgs = next(file_gen)\n          except:\n            break\n          for idx,img in enumerate(imgs): \n              if (len(collect_train)!=0 and len(collect_train)%batch == 0):\n                  ans_train = np.asarray(collect_train,dtype=np.float)\n                  ans_target = np.asarray(collect_target,dtype=np.float)\n                  collect_train = []\n                  collect_target = []\n                  yield (ans_train, ans_target)\n              collect_train.append(cv2.resize(img,(train_size,train_size))\/255.0)\n              collect_target.append(cv2.resize(img,(tar_size,tar_size))\/255.0)\n\ndef train_generator_2(batch=64, tar1_size=144, tar2_size=288 , train_size=72):\n    collect_train = []\n    collect_target_1 = []\n    collect_target_2 = []\n\n    while True:\n        file_gen = load_images_iter(amount=batch, start_pos = 1000)#first 1000 images are for validation\n        imgs = []\n        while (True):\n          try:\n            imgs = next(file_gen)\n          except:\n            break\n          for idx,img in enumerate(imgs): \n              if (len(collect_train)!=0 and len(collect_train)%batch == 0):\n                  ans_train = np.asarray(collect_train,dtype=np.float)\n                  ans_target_1 = np.asarray(collect_target_1,dtype=np.float)\n                  ans_target_2 = np.asarray(collect_target_2,dtype=np.float)\n                  collect_train = []\n                  collect_target_1 = []\n                  collect_target_2 = []\n                  yield (ans_train, (ans_target_1,ans_target_2))\n              collect_train.append(cv2.resize(img,(train_size,train_size))\/255.0)\n              collect_target_1.append(cv2.resize(img,(tar1_size,tar1_size))\/255.0)\n              collect_target_2.append(cv2.resize(img,(tar2_size,tar2_size))\/255.0)\n            \n\ndef val_generator_1(batch=64, tar_size= 144, train_size=72):\n    collect_train = []\n    collect_target = []\n    \n    while True:\n        file_gen = load_images_iter(amount=batch, end_pos = 1000)#first 1000 images are for validation\n        imgs = []\n        while (True):\n          try:\n            imgs = next(file_gen)\n          except:\n            break\n          for idx,img in enumerate(imgs): \n              if (len(collect_train)!=0 and len(collect_train)%batch == 0):\n                  ans_train = np.asarray(collect_train,dtype=np.float)\n                  ans_target = np.asarray(collect_target,dtype=np.float)\n                  collect_train = []\n                  collect_target = []\n                  yield (ans_train, ans_target)\n              collect_train.append(cv2.resize(img,(train_size,train_size))\/255.0)\n              collect_target.append(cv2.resize(img,(tar_size,tar_size))\/255.0)\n            \ndef val_generator_2(batch=64, tar1_size=144, tar2_size=288 , train_size=72):\n    collect_train = []\n    collect_target_1 = []\n    collect_target_2 = []\n\n    while True:\n        file_gen = load_images_iter(amount=batch, end_pos = 1000)#first 1000 images are for validation\n        imgs = []\n        while (True):\n          try:\n            imgs = next(file_gen)\n          except:\n            break\n          for idx,img in enumerate(imgs): \n              if (len(collect_train)!=0 and len(collect_train)%batch == 0):\n                  ans_train = np.asarray(collect_train,dtype=np.float)\n                  ans_target_1 = np.asarray(collect_target_1,dtype=np.float)\n                  ans_target_2 = np.asarray(collect_target_2,dtype=np.float)\n                  collect_train = []\n                  collect_target_1 = []\n                  collect_target_2 = []\n                  yield (ans_train, (ans_target_1,ans_target_2))\n              collect_train.append(cv2.resize(img,(train_size,train_size))\/255.0)\n              collect_target_1.append(cv2.resize(img,(tar1_size,tar1_size))\/255.0)\n              collect_target_2.append(cv2.resize(img,(tar2_size,tar2_size))\/255.0)\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef plot_imgs(rows,cols,img_list,titles = None,fig_size=(20,9)):\n  fig,ax = plt.subplots(rows,cols,figsize=fig_size)\n  if (rows == 1):\n    for j in range(cols):\n      ax[j].imshow(img_list[j][0])\n      if (titles):\n         ax[j].set_title(titles[j])\n  else:\n    for i in range(rows):\n      for j in range(cols):\n        ax[i,j].imshow(img_list[j][i])\n    if (titles):\n      for idx,title in enumerate(titles):\n        ax[0,idx].set_title(title)\n  plt.show()\n\n\n\"generators created\"","e9f258bb":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef plot_imgs(rows,cols,img_list,titles = None,fig_size=(20,9)):\n  fig,ax = plt.subplots(rows,cols,figsize=fig_size)\n  if (rows == 1):\n    for j in range(cols):\n      ax[j].imshow(img_list[j][0])\n      if (titles):\n         ax[j].set_title(titles[j])\n  else:\n    for i in range(rows):\n      for j in range(cols):\n        ax[i,j].imshow(img_list[j][i])\n    if (titles):\n      for idx,title in enumerate(titles):\n        ax[0,idx].set_title(title)\n  plt.show()\n\n\ntrain_imgs = next(train_generator_2())\nplot_imgs(3,3,[train_imgs[0],train_imgs[1][0],train_imgs[1][1]],fig_size=(20,9), titles = [\"size = 72\",\"size = 144\",\"size = 288\"])\nval_imgs = next(val_generator_2())\nplot_imgs(3,3,[val_imgs[0],val_imgs[1][0],val_imgs[1][1]],fig_size=(20,9), titles = [\"size = 72\",\"size = 144\",\"size = 288\"])","07b85b12":"from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\nfrom keras import backend as K\nimport math\n\nimport numpy as np\n\ndef set_callbacks(description,patience=5,tb_base_logdir='.\/logs\/'):\n#     cp = ModelCheckpoint(name +'.h5',save_best_only=True)\n#     es = EarlyStopping(patience=patience,monitor='val_loss')\n    rlop = ReduceLROnPlateau(patience=patience,monitor='val_out1_PSNR')\n    cb = [rlop]\n    return cb\n\n\ndef PSNR(y_true, y_pred):\n    max_pixel = 1.0\n    return 10.0 * (1.0 \/ math.log(10)) * K.log((max_pixel ** 2) \/ (K.mean(K.square(y_pred - y_true))))\n\ndef plot_histories(history, model_name = \"Model\"):\n    plt.plot(history.history['out1_loss'], label = \"out1_loss\")\n    plt.plot(history.history['val_out1_loss'], label = \"val_out1_loss\")\n    plt.plot(history.history['out2_loss'], label = \"out2_loss\")\n    plt.plot(history.history['val_out2_loss'], label = \"val_out2_loss\")\n    plt.title(model_name + ' Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(loc='upper left')\n    plt.show()\n    \n    plt.plot(history.history['out1_PSNR'], label = \"out1_PSNR\")\n    plt.plot(history.history['out2_PSNR'], label = \"out1_PSNR\")\n    plt.plot(history.history['val_out1_PSNR'], label = \"val_out1_PSNR\")\n    plt.plot(history.history['val_out2_PSNR'], label = \"val_out2_PSNR\")\n    \n    plt.title(model_name + ' PSNR')\n    plt.ylabel('PSNR')\n    plt.xlabel('Epoch')\n    plt.legend(loc='upper left')\n    plt.show()\n\n\"set\"","953290d9":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input\nfrom keras.utils import plot_model\n\ninp = Input((72,72,3))\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size=(2,2))(x)\nx = Conv2D(3,(1,1), activation = 'relu', padding = 'same')(x)\n\nmodel1 = Model(inputs = inp ,outputs = x)\nmodel1.summary()\nplot_model(model1,show_shapes=True)\n","22f9984a":"batch_size = 64\nmodel1.compile(optimizer = 'adam', loss='mse',metrics=[PSNR])\nhistory1 = model1.fit(train_generator_1(), epochs=12, batch_size=batch_size,steps_per_epoch= 4011\/\/batch_size,\n                     validation_data = val_generator_1(),validation_steps=1000\/\/batch_size )\n\nfrom keras.models import load_model\nmodel1.save('model1.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history1.history['loss'], label = \"loss\")\nplt.plot(history1.history['val_loss'], label = \"val_loss\")\nplt.title('Model Loss')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(loc='upper left')\nplt.show()\n\nplt.plot(history1.history['PSNR'], label = \"PSNR\")\nplt.plot(history1.history['val_PSNR'], label = \"PSNR\")\nplt.title('Model PSNR')\nplt.ylabel('PSNR')\nplt.xlabel('Epoch')\nplt.legend(loc='upper left')\nplt.show()","97e8e53b":"gen = val_generator_1()\nimgs = next(gen)\npredictions = model1.predict(imgs[0][:10])\nplot_imgs(5,3,[imgs[0][:10],imgs[1][:10], predictions], titles=[\"source-72\",\"val-144\",\"prediction-144\"])\n\nimgs = next(gen)\npredictions = model1.predict(imgs[0][:10])\nplot_imgs(5,3,[imgs[0][:10],imgs[1][:10], predictions], titles=[\"source-72\",\"val-144\",\"prediction-144\"])","51eb5435":"import keras \nmodel1 = None\nkeras.backend.clear_session()\n\"clear\"","609fa111":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input\nfrom keras.utils import plot_model\n\ninp = Input((None,None,3))\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\nup1 = UpSampling2D(size=(2,2))(x)\nout1 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out1\")(up1)\nup2 = UpSampling2D(size=(2,2))(up1)\nout2 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel2 = Model(inputs = inp ,outputs=[out1,out2])\nmodel2.summary()\nplot_model(model2,show_shapes=True)\n","7c26ea8f":"batch_size = 64\nmodel2.compile(optimizer = 'adam', loss =['mse','mse'], metrics =[PSNR])\nhistory2 =model2.fit(train_generator_2(), epochs=12, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel2.save('model2.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history2, \"Model 2\")","0783f968":"# model2 = load_model(\"model2.h5\")\n\ngen = val_generator_2()\nimgs = next(gen)\n\npred2 = model2.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred2[0],pred2[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred2 = model2.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred2[0],pred2[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","e7eb99aa":"import keras \nmodel2 = None\nkeras.backend.clear_session()\n\"clear\"","0d34db42":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU\nfrom keras.utils import plot_model\n\n\ndef get_residual_block(in_layer, filters = 32):\n  x = Conv2D(filters,(3,3), activation = LeakyReLU(0.2), padding = 'same')(in_layer)\n  x = Conv2D(filters,(3,3), activation = LeakyReLU(0.2), padding = 'same')(x)\n  # x = averagepooling or somethign\n  x = Add()([in_layer,x])\n  x = Activation(LeakyReLU(0.2))(x)\n  return x\n\ninp = Input((None,None,3))\nx = Conv2D(32,(1,1),activation = LeakyReLU(0.2), padding = 'same')(inp)\nres = get_residual_block(x)\nres = get_residual_block(res)\nup1 = UpSampling2D(size=(2,2))(res)\nout1 = Conv2D(3,(1,1), activation = LeakyReLU(0.2), padding = 'same', name=\"out1\")(up1)\nres2 = get_residual_block(up1)\nup2 = UpSampling2D(size=(2,2))(res2)\nout2 = Conv2D(3,(1,1), activation = LeakyReLU(0.2), padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel3 = Model(inputs = inp ,outputs=[out1,out2])\nmodel3.summary()\nplot_model(model3,show_shapes=True)\n","c062a5ed":"batch_size = 64\nmodel3.compile(optimizer = 'adam', loss =[\"mse\",\"mse\"], metrics = [PSNR], loss_weights=[0.3,0.7])\n\nhistory3 = model3.fit(train_generator_2(), epochs=12, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel3.save('model3.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history3, \"Model 3\")","f2c69d21":"gen = val_generator_2()\nimgs = next(gen)\npred3 = model3.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred3[0],pred3[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\npred3 = model3.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred3[0],pred3[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","190bb8e6":"import keras \nmodel3 = None\nkeras.backend.clear_session()\n\"clear\"","29cce835":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU, Concatenate\nfrom keras.utils import plot_model\n\n\ndef get_atrous_block(in_layer, filters = 32):\n  x = Conv2D(filters,(3,3), activation = LeakyReLU(0.2), padding = 'same')(in_layer)\n  x = Conv2D(filters,(3,3),dilation_rate=(2,2), activation = LeakyReLU(0.2), padding = 'same')(x)\n  x = Conv2D(filters,(3,3),dilation_rate=(4,4), activation = LeakyReLU(0.2), padding = 'same')(x)\n  # x = averagepooling or somethign\n  x = Concatenate()([in_layer,x])\n  x = Activation(LeakyReLU(0.2))(x)\n  x = Conv2D(filters,(3,3), activation = LeakyReLU(0.2), padding = 'same')(x)\n  return x\n\ninp = Input((72,72,3))\nx = Conv2D(32,(1,1),activation = LeakyReLU(0.2), padding = 'same')(inp)\nres = get_atrous_block(x)\nres = get_atrous_block(res)\nup1 = UpSampling2D(size=(2,2))(res)\nout1 = Conv2D(3,(1,1), activation = LeakyReLU(0.2), padding = 'same', name=\"out1\")(up1)\nres2 = get_atrous_block(up1)\nup2 = UpSampling2D(size=(2,2))(res2)\nout2 = Conv2D(3,(1,1), activation = LeakyReLU(0.2), padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel4 = Model(inputs = inp ,outputs=[out1,out2])\nmodel4.summary()\nplot_model(model4,show_shapes=True)\n","2872d1ef":"batch_size = 64\nmodel4.compile(optimizer = 'adam', loss =['mse','mse'], metrics =[PSNR], loss_weights=[0.3,0.7])\n\nhistory4 = model4.fit(train_generator_2(), epochs=12, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel4.save('model4.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history4,\"Model 4\")\n","a9d256e3":"gen = val_generator_2()\nimgs = next(gen)\n\npred4 = model4.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred4[0],pred4[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred4 = model4.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred4[0],pred4[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","e29413cb":"import keras \nmodel4 = None\nkeras.backend.clear_session()\n\"clear\"","31916ded":"import efficientnet.keras as efn \n\n\nefn = efn.EfficientNetB4(include_top = False, input_shape = (None,None,3))\n\nefn.trainable = False\nfor layer in efn.layers:\n  layer.trainable = False\n\nefn.summary()","a40e74f2":"from keras.models import Sequential, Model\n\nmy_efn = Model(inputs = efn.input, outputs = efn.get_layer(\"block1a_activation\").output)\nmy_efn.trainable = False\nfor layer in efn.layers:\n  my_efn.trainable = False\n\nmy_efn.summary()","6a7937c6":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU, Concatenate\nfrom keras.utils import plot_model\n\n\ninp = Input((None,None,3))\next = my_efn(inp)\next = UpSampling2D(size=(2,2))(ext)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\nx = Concatenate()([x,ext])\nx = Conv2D(112,(1,1), activation = 'relu', padding = 'same')(x)\nup1 = UpSampling2D(size=(2,2))(x)\nout1 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out1\")(up1)\nup2 = UpSampling2D(size=(2,2))(out1)\nout2 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel5 = Model(inputs = inp ,outputs=[out1,out2])\nmodel5.summary()\nplot_model(model5,show_shapes=True)\n","1678abd3":"batch_size = 64\nmodel5.compile(optimizer = 'adam', loss =['mse','mse'], metrics =[PSNR], loss_weights=[0.3,0.7])\nhistory5 = model5.fit(train_generator_2(), epochs=20, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel5.save('model5.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history5, \"Model 5\")\n","e6e07431":"gen = val_generator_2()\nimgs = next(gen)\n\npred5 = model5.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5[0],pred5[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred5 = model5.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5[0],pred5[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","76516e5e":"import keras \nmodel5 = None\nkeras.backend.clear_session()\n\"clear\"","9fc33616":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU, Concatenate\nfrom keras.utils import plot_model\n\n\ninp = Input((None,None,3))\next = my_efn(inp)\next = UpSampling2D(size=(2,2))(ext)\next = Conv2D(48,(1,1),activation = 'relu', padding = 'same')(ext) ## Added convolutional layer\n\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\n\nx = Concatenate()([x,ext])\nx = Conv2D(112,(1,1), activation = 'relu', padding = 'same')(x)\nup1 = UpSampling2D(size=(2,2))(x)\nout1 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out1\")(up1)\nup2 = UpSampling2D(size=(2,2))(out1)\nout2 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel5_2 = Model(inputs = inp ,outputs=[out1,out2])\nmodel5_2.summary()\nplot_model(model5_2,show_shapes=True)\n","6f1838ce":"batch_size = 64\nmodel5_2.compile(optimizer = 'adam', loss =['mse','mse'], metrics =[PSNR])\nhistory5_2 = model5_2.fit(train_generator_2(), epochs=12, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel5_2.save('model5_2.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history5_2, \"Model 5_2\")\n","124bc9bc":"gen = val_generator_2()\nimgs = next(gen)\n\npred5_2 = model5_2.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5_2[0],pred5_2[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred5_2 = model5_2.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5_2[0],pred5_2[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","e9418d4b":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU, Concatenate\nfrom keras.utils import plot_model\n\n\ninp = Input((None,None,3))\next = my_efn(inp)\next = UpSampling2D(size=(2,2))(ext)\next = Conv2D(96,(1,1),activation = 'relu', padding = 'same')(ext) ## Doubled Number of Filters\n\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\n\nx = Concatenate()([x,ext])\nx = Conv2D(80,(1,1), activation = 'relu', padding = 'same')(x) \nup1 = UpSampling2D(size=(2,2))(x)\nup1 = Conv2D(80,(1,1), activation = 'relu', padding = 'same')(up1) ## Added convolutinal layer\nout1 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out1\")(up1)\nup2 = UpSampling2D(size=(2,2))(out1)\nout2 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel5_3 = Model(inputs = inp ,outputs=[out1,out2])\nmodel5_3.summary()\nplot_model(model5_3,show_shapes=True)\n","551f2d57":"batch_size = 64\nmodel5_3.compile(optimizer = 'adam', loss =['mse','mse'], metrics =[PSNR], loss_weights= [0.65,0.35])\nhistory5_3 = model5_3.fit(train_generator_2(), epochs=25, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel5_3.save('model5_3.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history5_3, \"Model 5_3\")\n","bab85168":"gen = val_generator_2()\nimgs = next(gen)\n\npred5_3 = model5_3.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5_3[0],pred5_3[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred5_3 = model5_3.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5_3[0],pred5_3[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","8cba21f2":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, LSTM,Dropout, BatchNormalization, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU, Concatenate\nfrom keras.utils import plot_model\n\n\ninp = Input((None,None,3))\next = my_efn(inp)\next = UpSampling2D(size=(2,2))(ext)\next = Conv2D(96,(1,1),activation = 'relu', padding = 'same')(ext)\n\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\n\nx = Concatenate()([x,ext])\nx = Conv2D(80,(1,1), activation = 'relu', padding = 'same')(x) \nup1 = UpSampling2D(size=(2,2))(x)\nup1 = Conv2D(80,(1,1), activation = 'relu', padding = 'same')(up1)\nout1 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out1\")(up1)\nup2 = Conv2D(32,(1,1), activation = 'relu', padding = 'same')(out1) ## Added convolutional layer\nup2 = UpSampling2D(size=(2,2))(out1)\nup2 = Conv2D(64,(1,1), activation = 'relu', padding = 'same')(up2) ## Added convolutional layer\nup2 = Conv2D(64,(1,1),dilation_rate = (2,2), activation = 'relu', padding = 'same')(up2) ## Added convolutional layer\nout2 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out2\")(up2)\n\n\n\nmodel5_4 = Model(inputs = inp ,outputs=[out1,out2])\nmodel5_4.summary()\nplot_model(model5_4,show_shapes=True)\n","bbab8d70":"batch_size = 64\nmodel5_4.compile(optimizer = 'adam', loss =['mse','mse'], metrics =[PSNR], loss_weights= [0.65,0.35])\nhistory5_4 = model5_4.fit(train_generator_2(), epochs=30, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel5_4.save('model5_4.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nplot_histories(history5_4)","02d232f4":"gen = val_generator_2()\nimgs = next(gen)\n\npred5_4 = model5_4.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5_4[0],pred5_4[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred5_4 = model5_4.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred5_4[0],pred5_4[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","46e3a52a":"# !pip install efficientnet\n\nimport efficientnet.keras as efn \n\n\nefn = efn.EfficientNetB4(include_top = False, input_shape = (None,None,3))\n\nefn.trainable = False\nfor layer in efn.layers:\n  layer.trainable = False\n\nefn.summary()","86c8432e":"from keras.models import Sequential, Model\nmy_efn = Model(inputs = efn.input, outputs = efn.get_layer(\"block1a_activation\").output)\nmy_efn.trainable = False\nfor layer in efn.layers:\n  my_efn.trainable = False\n\nmy_efn.summary()","f442575a":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, UpSampling2D, Conv2D, Input, Add, Activation, LeakyReLU, Concatenate, Lambda\nfrom keras.utils import plot_model\nfrom tensorflow.nn import depth_to_space\n\n\ninp = Input((None,None,3))\n\next = my_efn(inp)\next = UpSampling2D(size=(2,2))(ext)\next = Conv2D(48,(1,1),activation = 'relu', padding = 'same')(ext)\n\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(inp)\nx = Conv2D(64,(3,3), activation = 'relu', padding = 'same')(x)\n\nconc = Concatenate()([x,ext])\nconc = Conv2D(112,(1,1), activation = 'relu', padding = 'same')(conc)\nup1 =  Lambda(lambda x:depth_to_space(x,2))(conc)\nup1 = Conv2D(64,(1,1), activation = 'relu', padding = 'same')(up1)\nout1 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out1\")(up1)\nup2 = Lambda(lambda x:depth_to_space(x,2))(Conv2D(64,(1,1), activation = 'relu', padding = 'same')(out1))\nout2 = Conv2D(3,(1,1), activation = 'relu', padding = 'same', name=\"out2\")(up2)\n\n\nmodel6 = Model(inputs=inp,outputs=[out1, out2])\nmodel6.summary()\nplot_model(model6,show_shapes=True)","42215b5d":"batch_size=64\nmodel6.compile(optimizer = 'adam',loss =['mse','mse'], metrics =[PSNR],loss_weights= [0.7,0.3])\nhistory6 = model6.fit(train_generator_2(), epochs=20, batch_size=batch_size, steps_per_epoch= (4011\/\/batch_size),\n                      validation_data = val_generator_2(), validation_steps= (1000\/\/batch_size) )\n\n\nfrom keras.models import load_model\nmodel6.save('model6.h5')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplot_histories(history6,\"Model 6\")\n","641a6cc3":"gen = val_generator_2()\nimgs = next(gen)\n\npred6 = model6.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred6[0],pred6[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])\n\nimgs = next(gen)\n\npred6 = model6.predict(imgs[0][:10])\nplot_imgs(5,5,[imgs[0],imgs[1][0],imgs[1][1],pred6[0],pred6[1]] ,\n          titles=[\"source-72\",\"val-144\",\"val-288\",\"prediction-144\",\"prediction-288\"])","57c6dd7b":"#### MODEL 5 -3\n\nThis time I added some more covolutional layers and filters, and added loss weigths adding more weight to the first output loss and also increased the number of epoches","64d1a16d":"### MODEL 5 - ADDING PRE-TRAINED NETWORK\n\nI used EfficntNetB4 network first block","c84b9df8":"### MODEL 4 - ATROUS MODEL","993b7ebd":"### MODEL 3 - RESIDUAL BLOCK MODEL","91ebc7f6":"### MODEL 6 - PXIEL SHUFFLE","e6543c3c":"####MODEL 5-2\n\nThis time I didn't use loss weights and added a convolution 1x1 after up-samplint the efficenet features","22bbaebf":"### MODEL 1 - ONE OUTPUT","a9239b39":"#### MODEL 5 - 4\n\nthis time I added some epochs and more convolutions to the second output","bb927346":"### MODEL 2 - TWO OUTPUTS"}}