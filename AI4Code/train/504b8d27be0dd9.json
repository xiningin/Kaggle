{"cell_type":{"bf7ab1eb":"code","59b59910":"code","046012b8":"code","b3fb5cc8":"code","d9153955":"code","667ae37c":"code","99b49119":"code","820ba55e":"code","9915d8e2":"code","b9f5a20a":"code","994851ac":"code","b00736e3":"code","ef5edce2":"code","42f8c483":"code","3a4faef4":"code","0c1a9385":"code","11ab8ecc":"code","e190a7cc":"code","a3f16665":"code","8f4f9bb1":"code","ba42a1f5":"markdown","83262f60":"markdown","e624a0dd":"markdown","c269b026":"markdown","da0d780a":"markdown","dee700e1":"markdown","7c5e78b6":"markdown","e3c1b696":"markdown","9a431cbe":"markdown","7c69ab03":"markdown","58a7977b":"markdown","438c3ec8":"markdown","79ad305c":"markdown","47fe97f7":"markdown","23271452":"markdown","a4145b73":"markdown","47b9ea2f":"markdown","f351007d":"markdown","1c647bd5":"markdown","7a02d5e1":"markdown","a1004b04":"markdown","cb1e128e":"markdown","35345a9e":"markdown","d13d569f":"markdown","19db3fdd":"markdown","5e6f4f26":"markdown","8f90efd8":"markdown","a5923a34":"markdown","e61494f1":"markdown","33a713ec":"markdown","08ed305a":"markdown"},"source":{"bf7ab1eb":"from tensorflow.keras.datasets import reuters\n(train_data,train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)","59b59910":"print(f\"Shape of train data: {train_data.shape}\")\nprint(f\"Shape of test data: {test_data.shape}\")","046012b8":"print(f\"First example: {train_data[0]}\")","b3fb5cc8":"print(f\"The label of first example: {train_labels[0]}\")","d9153955":"# Creating a function to turn data into multi-hot encode.\nimport numpy as np\ndef vectorize_sequences(sequences, dimension=10000):\n    # Creating an all-zero matrix of shape\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        for j in sequence:\n            # Seting specific indices of results[i] to 1s\n            results[i, j] = 1. \n    return results","667ae37c":"# Vectorized traning data and test data:\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data) ","99b49119":"print(f\"First row : {x_train[0]}\")","820ba55e":"from tensorflow.keras.utils import to_categorical\ny_train = to_categorical(train_labels)\ny_test = to_categorical(test_labels)","9915d8e2":"print(f\"First label: {y_train[0]}\")","b9f5a20a":"from tensorflow import keras\nfrom tensorflow.keras import layers\nmodel = keras.Sequential([\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(46, activation=\"softmax\")\n])","994851ac":"model.compile(optimizer=\"rmsprop\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\"])","b00736e3":"x_val = x_train[:1000]\npartial_x_train = x_train[1000:]\ny_val = y_train[:1000]\npartial_y_train = y_train[1000:]","ef5edce2":"history = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    validation_data=(x_val, y_val))","42f8c483":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nplt.figure(figsize = (16, 10))\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, \"bo\", label=\"Training loss\")\nplt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\nplt.title(\"Training and validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","3a4faef4":"plt.clf()    \nplt.figure(figsize = (16, 10))\nacc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nplt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\nplt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\nplt.title(\"Training and validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","0c1a9385":"model = keras.Sequential([\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(46, activation=\"softmax\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\"])\nmodel.fit(x_train,\n          y_train,\n          epochs=9,\n          batch_size=512)","11ab8ecc":"results = model.evaluate(x_test, y_test)\nprint(f\"Test loss : {results[0]}\")\nprint(f\"Test accuracy : {results[1]}\")","e190a7cc":"import copy\ntest_labels_copy = copy.copy(test_labels)\nnp.random.shuffle(test_labels_copy)\nhits_array = np.array(test_labels) == np.array(test_labels_copy)\nprint(f\"The accuracy of a random baseline: {hits_array.mean()}\")","a3f16665":"predictions = model.predict(x_test)","8f4f9bb1":"print(f\" The predicted label of first example: {np.argmax(predictions[0])}\")","ba42a1f5":"## <span style = \"color:Orange\"> Building the Model <\/span>","83262f60":"### To feed lists of integers into a neural network, you have to turn your lists into tensors.","e624a0dd":"## <span style = \"color:Orange\"> Compiling the Model <\/span>","c269b026":"## <span style = \"color:Orange\"> Creating Validation Dataset <\/span>","da0d780a":"## <span style = \"color:Orange\"> Training the Model <\/span>","dee700e1":"## <span style = \"color:Orange\"> Resource<\/span>","7c5e78b6":"### Let's see the accuracy of a random baseline.","e3c1b696":"### To build the model, I will use two intermediate layers with 64 units and because we have 46 different class I will set an output layer with 46 units. Let me set relu activation for intermediate layers and the a softmax activation for output layer.","9a431cbe":"## <span style = \"color:Orange\"> Predicting New Data<\/span>","7c69ab03":"### Let's take a look at shapes of datasets. ","58a7977b":"### Each example is a list of integers. ","438c3ec8":"## <span style = \"color: Orange\"> Preparing the Data <span>","79ad305c":"## <span style = \"color:Orange\"> Plotting the Training and Validation Accuracy <\/span>","47fe97f7":"### The random classifier has 19% accuracy, but our model has 79% accuracy. So the result of our model seem pretty good.","23271452":"## <span style = \"color:Orange\"> Loading the Dataset <\/span>","a4145b73":"### As you can see, the model begins to overfit after nine epochs. Let\u2019s train a new model from scratch for nine epochs and then evaluate it on the test set.","47b9ea2f":"### [Chollet, F. 2021, Deep Learning with Python](https:\/\/www.manning.com\/books\/deep-learning-with-python-second-edition)","f351007d":"### The best loss function to use in multiclass classification is categorical_crossentropy.  I will use rmsprop optimizer which is a usually a good default choice for any problem. I will also set accuracy to monito during training.","1c647bd5":"# <span style = \"color:OrangeRed\"> A Multiclass Classification with Keras <\/span>","7a02d5e1":"### To restricts the data to the 10,000 most frequently occurring words, I am going to use num_words argument.","a1004b04":"### I used a softmax activation so the model will produce a 46-dimensional output vector. ","cb1e128e":"## <span style = \"color:Orange\"> The Reuters Dataset <\/span>","35345a9e":"### In this example, I will show you how to build a model for multiclassification problem using Reuters newswires.\n\n### When each data point could belong to multiple categories, you\u2019d be facing a multilabel multiclass classification problem.","d13d569f":"## <span style = \"color:Orange\"> Plotting the Training and Validation Loss <\/span>\n","19db3fdd":"### Let's see the predicted label of the first text sample.","5e6f4f26":"### Don\u2019t forget to follow us on [YouTube](https:\/\/youtube.com\/c\/tirendazakademi) \ud83c\udf9e, [GitHub](https:\/\/github.com\/tirendazacademy) \ud83c\udf31, [Twitter](https:\/\/twitter.com\/@tirendazacademy) \ud83d\ude0e, [LinkedIn](https:\/\/www.linkedin.com\/in\/tirendaz-academy) \ud83d\udc4d","8f90efd8":"### Let's predict with our model using test dataset.","a5923a34":"### To vectorize the labels, you can use one-hot encoding using to_categorical() method.","e61494f1":"### Reuters dataset published by Reuters in 1986. There are 46 different topics. Each topic has at least 10 examples in training set. ","33a713ec":"![](https:\/\/images.unsplash.com\/photo-1478940020726-e9e191651f1a?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1170&q=80)","08ed305a":"### Let's see the label of first example."}}