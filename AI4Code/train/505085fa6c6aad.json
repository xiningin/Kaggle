{"cell_type":{"8a43ea7a":"code","55b63968":"code","ee1cd8cc":"code","9eb03b14":"code","68874c8e":"code","eb6055dc":"code","2d57f9ec":"code","860590c9":"code","2aa2d1ce":"code","38850dc8":"code","029163ef":"code","8df8a019":"code","b3e0f331":"code","e47d44c7":"markdown","ae000414":"markdown","b1484b96":"markdown","0deed09b":"markdown","fac81191":"markdown","8626f249":"markdown","8d1a3139":"markdown","e7fd4c9a":"markdown","193be6af":"markdown","0d4d3a40":"markdown","4c767e2e":"markdown","6883b70d":"markdown"},"source":{"8a43ea7a":"import os,cv2\n!pip install keract\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom numpy import *\n\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\n\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD,RMSprop,adam\nfrom keras.constraints import maxnorm\nfrom PIL import Image\nfrom PIL import ImageMath\n","55b63968":"files_trainNO = '..\/input\/cellphone\/training\/training\/cellphone-NO\/'\nfiles_trainYES = '..\/input\/cellphone\/training\/training\/cellphone-YES\/'\nfiles_OS_trainNO = os.listdir(files_trainNO)\nfiles_OS_trainYES = os.listdir(files_trainYES)\ntrainingSamples = size(files_OS_trainNO) + size(files_OS_trainYES)\nprint(' No cellphone samples:', size(files_OS_trainNO))\nprint(' Yes cellphone samples:', size(files_OS_trainYES))\nprint(' Total training samples:', trainingSamples)","ee1cd8cc":"immatrixNo = array([array(Image.open('{}img{}.png'.format(files_trainNO, image))).flatten()\n                          for image in range(size(files_OS_trainNO))], 'f')\n\nimmatrixYes = array([array(Image.open('{}img{}.png'.format(files_trainYES, 121 + image))).flatten()\n                          for image in range(size(files_OS_trainYES))], 'f')\n    \nimmatrix = np.concatenate((immatrixNo, immatrixYes), axis=0)\nlabelSamples = np.ones((trainingSamples,), dtype=int)\nlabelSamples[0:120] = 0\nlabelSamples[120:] = 1\n\ncellphone = immatrixYes[123]\n\nnb_epoch = 30\nrows, cols = 90, 90\nn_channels = 1\nbatch_size = 32\nn_classes = 2\nn_filter = 32\nn_pool = 2\nn_conv = 3\n\nprint(\"If value = 0 , then : THERE IS NOT A CELLPHONE !\")\nprint(\"If value = 1 , then : THERE IS A CELLPHONE !\")\n\ndata, label = shuffle(immatrix, labelSamples, random_state=2)\ntrain_data = [data, label]\nprint(train_data)","9eb03b14":"def show_Samples(show, j):\n    s = [0, 30, 60, 130, 200, 190]\n    fig, axs = plt.subplots(1, show, figsize=(10, 3))\n    for i in range(0, show):\n        anyOne = random.randint(0, 250)\n        axs[i].imshow(immatrix[s[i] + j].reshape(rows, cols))\n        \n\nfor i in range(0, 6):\n    show_Samples(6, i)\n","68874c8e":"(X,y) = (train_data[0],train_data[1])\nX_train, X_test,y_train,y_test = train_test_split(X,y,random_state=4)\ncellphone = X_train[125]\nX_train = X_train.reshape(X_train.shape[0],1,rows,cols)\ncellphone = cellphone.reshape(1, 1, 90, 90)\n\nX_test = X_test.reshape(X_test.shape[0],1,rows,cols)\nX_train = X_train.astype(\"float32\")\nX_test = X_test.astype(\"float32\")\nX_train \/= 255\nX_test \/= 255\n\nY_train = np_utils.to_categorical(y_train,n_classes)\nY_test = np_utils.to_categorical(y_test,n_classes)","eb6055dc":"model = Sequential()\n\nmodel.add(Conv2D(n_filter,(n_conv,n_conv),border_mode='same',input_shape=(n_channels,rows,cols)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(n_filter,(n_conv,n_conv)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(n_pool,n_pool)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64,(n_conv,n_conv)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(n_pool,n_pool)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes))\nmodel.add(Activation('softmax'));\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])","2d57f9ec":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","860590c9":"from keract import get_activations\nactivations = get_activations(model, cellphone)\n\nplt.imshow(cellphone.reshape(90, 90))","2aa2d1ce":"from keract import display_activations\ndisplay_activations(activations, save=False)","38850dc8":"from keract import display_heatmaps\ndisplay_heatmaps(activations, cellphone.reshape(1, 90, 90, 1), save=False)","029163ef":"history = model.fit(X_train,Y_train,batch_size = batch_size, epochs = nb_epoch, verbose=1)","8df8a019":"def show_loss():\n    plt.figure(figsize=(10,3))\n    plt.plot(history.history['loss'], \n             color='red', \n             label='Loss')\n    plt.title(\"My Test Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n    \ndef show_acc_epochs():\n    plt.figure(figsize=(10,3))\n    plt.plot(history.history['acc'],\n             color='blue',\n             label='Acc')\n    plt.title(\"My Test Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy Value\")\n    plt.legend()\n    plt.show()\n    \n    \nshow_loss()\nshow_acc_epochs()","b3e0f331":"answer = model.predict_classes(X_test)\n\ntest_pred = X_test\ndef show_Samples_test(show, test_pred, answer):\n    fig, axs = plt.subplots(1, show, figsize=(10, 3))\n    for i in range(0, show):\n        axs[i].imshow(test_pred[i].reshape(rows, cols), label=answer[i])\n        axs[i].set_title('Label: {}'.format(answer[i]))\n        leg = axs[i].legend()\n        \nshow_Samples_test(6, test_pred, answer)","e47d44c7":"<p><\/p>","ae000414":"## Visualizing Convolutions","b1484b96":"## Testing some samples","0deed09b":"## Training the Neural Network","fac81191":"## Some samples in our Dataset","8626f249":"## Convolutional Neural Networks\n\n<p style=\"text-align: justify;\">Convolutional networks are a type of artificial feed-foward neural network that has been successfully applied in the processing, analysis and classification of images and videos. Such neural networks require a minimum level of preprocessing when compared to other image classification algorithms.<\/p>\n\n<img src=\"http:\/\/storage.ning.com\/topology\/rest\/1.0\/file\/get\/2808372202?profile=RESIZE_1024x1024\">\n\n<p style=\"text-align: justify;\">Convolutional neural networks are deep learning algorithms widely used to work with image recognition. Compared to other algorithms such as Multilayer Perceptrons, convolutional networks require much less preprocessing than other artificial neural networks. In convolutional networks, It Is not necessary to design filters manually to analyze the images. In this context, convolutional neural networks were inspired by the connectivity between the neurons of our visual cortex. Thus, a convolutional network is capable of capturing and analyzing images by applying filters.<\/p>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1280\/1*ciDgQEjViWLnCbmX-EeSrA.gif\">","8d1a3139":"<p><\/p>","e7fd4c9a":"\n\n# <center> Machine Learning <\/center>\n# <center> Finding cellphone on images using CNN <\/center>\n\n","193be6af":"## Formating our dataset ","0d4d3a40":"## Importing Python Libraries","4c767e2e":"## Convolutional Network Architecture","6883b70d":"## Our datasets"}}