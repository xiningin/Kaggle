{"cell_type":{"196e083b":"code","a943f97a":"code","3b78a76b":"code","a121a4ae":"code","898297a1":"code","66e6557e":"code","447c5d6b":"code","54517bb8":"code","22e1b88f":"code","e24d3e13":"code","9c6b06a2":"code","ff98679c":"code","dbc3c1a2":"code","efc7c27a":"code","9e277871":"code","5faee93e":"code","97e7763b":"code","1d5fb360":"code","e27c47e2":"code","1ade3454":"code","47429378":"code","4856611b":"code","566dda76":"code","b49bcf41":"code","2af30315":"code","1925e942":"code","ae2ac55d":"code","4adde559":"code","73a44fee":"code","0b2b40a4":"code","a899a4ad":"code","edb3a953":"code","8dc026a9":"code","a0da158f":"code","9740304b":"code","53648526":"code","531a1ea6":"code","a6feb65b":"code","32fe51cd":"code","5eeea8b4":"code","cb19467b":"code","83303373":"code","066e0ae1":"code","a2cc8994":"code","6a6b47a0":"code","388314aa":"code","653de515":"code","69b76f33":"code","a87520e8":"code","84ee2864":"code","c098fe25":"code","af9c9bb2":"code","02d4b8a2":"code","65d7df6d":"code","38fc73dc":"code","ca0fa928":"code","82a1bcff":"code","857ab74b":"code","662e6041":"code","2dd2f036":"code","28a1b505":"code","a79e0e9a":"code","c3ab9c89":"code","ad131a36":"code","a7bebb38":"code","b7c4dd80":"code","bd3e6d23":"code","0c9f7fe6":"code","8a2037b0":"code","241f3f7e":"code","3434aeab":"code","f50c46ba":"code","78216843":"code","71eeeeaf":"code","e168a74a":"code","1438302e":"code","1493f3e1":"code","70088554":"code","1c4e84cc":"code","cca204b3":"code","fe19b250":"code","50ec4026":"code","7e169e63":"code","170b6238":"code","da312f98":"code","71179893":"code","235dde72":"code","1a644bef":"code","ad836f12":"code","d598f751":"code","d20469af":"code","cd27c994":"code","8c305cbe":"code","ec154dd4":"code","1fac86b2":"code","627fd63d":"code","a221ffd4":"code","83b93e17":"code","391889f3":"code","bd345a15":"code","089c9bcd":"code","8f101e62":"code","dca926ab":"code","762b2643":"code","bf178c7a":"code","201c6ea9":"code","b1256dc5":"code","14b750b7":"code","287119a2":"code","33b01b08":"code","570d29ad":"code","7785a8e8":"code","934f535a":"code","761138fb":"code","4ea1213a":"code","5284213f":"code","a99bbb12":"code","18051a0f":"code","ba86766d":"code","d3cc283a":"code","b9531926":"code","0728415a":"code","ba583e85":"code","4638b0cb":"code","f27521a3":"code","f289312b":"code","4ef8f029":"code","6dc8675a":"code","66711cda":"code","52a0297e":"code","57d646b4":"code","b4b22512":"code","62ffc3a2":"code","79a4f399":"code","4fb16dea":"code","86fa08d9":"code","6995618c":"code","bf4d7279":"code","f0bd4688":"code","65053141":"code","c3145773":"code","deb1664b":"code","d6013c53":"code","673877ca":"code","bdac835a":"code","a6db4986":"code","13043d2f":"code","0fbf764f":"code","8b59c8b6":"code","f6f6165e":"code","8e7d7e73":"code","01f85816":"code","f3cf96f0":"code","75822f0f":"markdown","5aeb1774":"markdown","996af3cb":"markdown","d4895ac1":"markdown","5b3aee38":"markdown","4d47f884":"markdown","3c8d9772":"markdown","984cc42b":"markdown","082850ec":"markdown","03f0eec1":"markdown","8ab8068a":"markdown","f6024ee3":"markdown","46c11ae0":"markdown","dc268a99":"markdown","bc937cd2":"markdown","791e4e68":"markdown","853aed23":"markdown","721aaa7b":"markdown","476da03d":"markdown","6ce11773":"markdown","aaefc5b1":"markdown","afc77083":"markdown","743f600c":"markdown","89d19483":"markdown","210b53ca":"markdown","f666f33c":"markdown","13209e37":"markdown","1cc04b92":"markdown","e330fd49":"markdown","81a88c18":"markdown","6f9a48a7":"markdown","37f43a98":"markdown","8e1bae27":"markdown","95aad9fe":"markdown","725d4e63":"markdown","37d61f27":"markdown","13102ac5":"markdown"},"source":{"196e083b":"import json\nfrom datetime import timedelta\n\nfrom time import time \n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n#from scipy.integrate import solve_ivp # Solve an initial value problem for a system of ODEs.\nfrom scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error #MSLE for kaggle, MAE for ZIND\n\nfrom IPython.display import Image\nfrom IPython.core.display import HTML\n\nfrom pprint import pprint\n\nfrom tqdm import notebook\nnotebook.tqdm().pandas\n\nidx = pd.IndexSlice","a943f97a":"path ='\/kaggle\/input\/covid19-global-forecasting-week-4\/'\ntrain_df = pd.read_csv(path+\"train.csv\",parse_dates = True)\ntest_df = pd.read_csv(path+\"test.csv\",parse_dates = True)\nsub_df = pd.read_csv(path+\"submission.csv\",parse_dates = True)","3b78a76b":"train_df.Date = pd.to_datetime(train_df.Date)\ntest_df.Date = pd.to_datetime(test_df.Date)","a121a4ae":"train_df.head(2)","898297a1":"test_df.head(2)","66e6557e":"sub_df.head(2)","447c5d6b":"countries = train_df.Country_Region.unique()\nlen(countries)","54517bb8":"provinces = train_df.Province_State.unique()\nlen(provinces)","22e1b88f":"num_province_on_country = train_df.groupby(\"Country_Region\")[\"Province_State\"].apply(lambda s: len(s.dropna().unique()))\nnum_province_on_country[num_province_on_country>0]","e24d3e13":"train_begin_date = train_df.Date.min()\ntrain_end_date = train_df.Date.max()\ntest_begin_date = test_df.Date.min()\ntest_end_date = test_df.Date.max()","9c6b06a2":"train_begin_date","ff98679c":"# https:\/\/www.kaggle.com\/anjum48\/seir-hcd-model#Fitting-the-model-to-data\nDATE_BORDER = '2020-04-15'\n\n# Load the population data into lookup dicts\npop_info = pd.read_csv('\/kaggle\/input\/covid19-population-data\/population_data.csv')\ncountry_pop = pop_info.query('Type == \"Country\/Region\"')\nprovince_pop = pop_info.query('Type == \"Province\/State\"')\ncountry_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\nprovince_lookup = dict(zip(province_pop['Name'], province_pop['Population']))\n\n# Fix the Georgia State\/Country confusion - probably a better was of doing this :)\ntrain_df['Province_State'] = train_df['Province_State'].replace('Georgia', 'Georgia (State)')\ntest_df['Province_State'] = test_df['Province_State'].replace('Georgia', 'Georgia (State)')\nprovince_lookup['Georgia (State)'] = province_lookup['Georgia']\n\ntrain_df['Area'] = train_df['Province_State'].fillna(train_df['Country_Region'])\ntest_df['Area'] = test_df['Province_State'].fillna(test_df['Country_Region'])\n\n# https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-1\/discussion\/139172\ntrain_df['ConfirmedCases'] = train_df.groupby('Area')['ConfirmedCases'].cummax()\ntrain_df['Fatalities'] = train_df.groupby('Area')['Fatalities'].cummax()\n\n# Remove the leaking data\ntrain_full_df = train_df.copy()\nvalid_df = train_df[train_df['Date'] >= test_df['Date'].min()].copy()\ntrain_df = train_df[train_df['Date'] < test_df['Date'].min()].copy()\n\n# Split the test into public & private\ntest_public_df = test_df[test_df['Date'] <= DATE_BORDER].copy()\ntest_private_df = test_df[test_df['Date'] > DATE_BORDER].copy()\n\n# use area country dictionary for later match statistics\narea_country_dict = dict(zip(train_full_df[\"Area\"],train_full_df[\"Country_Region\"]))\n\n# Use a multi-index for easier slicing\ntrain_full_df.set_index(['Area', 'Date'], inplace=True)\ntrain_df.set_index(['Area', 'Date'], inplace=True)\nvalid_df.set_index(['Area', 'Date'], inplace=True)\ntest_public_df.set_index(['Area', 'Date'], inplace=True)\ntest_private_df.set_index(['Area', 'Date'], inplace=True)\n\nsub_df['ConfirmedCases'] = 0\nsub_df['Fatalities'] = 0\n\ntrain_full_df.shape, train_df.shape, valid_df.shape, test_public_df.shape, test_private_df.shape, sub_df.shape","dbc3c1a2":"train_full_df.sort_index(level=[0,1],inplace=True)\ntrain_df.sort_index(level=[0,1],inplace=True)\nvalid_df.sort_index(level=[0,1],inplace=True)\ntest_public_df.sort_index(level=[0,1],inplace=True)\ntest_private_df.sort_index(level=[0,1],inplace=True)\ntrain_full_df.head(2)","efc7c27a":"len(area_country_dict)","9e277871":"non_zero_regions_df = train_full_df.loc[idx[:,train_begin_date],:][train_full_df.loc[idx[:,train_begin_date],\"ConfirmedCases\"]!=0].copy()\nnon_zero_regions_df","5faee93e":"# we pick the area of China out and assume the ConfirmedCases and Death will not change a lot in the future\nprovince_country_dict = dict(zip(train_full_df.loc[:,\"Province_State\"],train_full_df.loc[:,\"Country_Region\"]))\nchina_area = [k for k,v in province_country_dict.items() if v == \"China\"] \nlen(china_area)","97e7763b":"china_area = china_area + [\"Taiwan*\"]\nlen(china_area)","1d5fb360":"# check plots\n#fig,axs = plt.subplots(33,1,figsize = (8,33*6))\n#count = 0\n#for area in china_area:\n#    train_full_df.loc[idx[area,:],\"ConfirmedCases\"].plot(ax=axs[count])\n#    axs[count].set_title(area)\n#    count += 1","e27c47e2":"!pip install pycountry_convert","1ade3454":"import pycountry\nimport pycountry_convert as pc\nfrom pycountry_convert import country_name_to_country_alpha2 as name_to_code2\nfrom pycountry_convert import country_alpha2_to_continent_code as code2_to_cont\nfrom pycountry_convert import country_alpha2_to_country_name as code2_to_country\nfrom pycountry_convert import country_name_to_country_alpha3 as country_to_code3","47429378":"all_countries = list(set(area_country_dict.values()))\nlen(all_countries)","4856611b":"all_country_official = [c.name for c  in pycountry.countries]\nall_code_official = [name_to_code2(c) for c in all_country_official]\nno_match_dict = {}\nfor c in all_countries:\n    if not c in all_country_official:\n        no_match_dict[c] = c\nlen(no_match_dict)","566dda76":"no_match_l = list(no_match_dict.keys())\nno_match_l","b49bcf41":"# mannually fix some\nmannual_dict= {\n    \"Cote d'Ivoire\":\"C\u00f4te d'Ivoire\",\n    \"Venezuela\":\"Venezuela, Bolivarian Republic of\",\n    'Congo (Brazzaville)': 'Congo',\n    'West Bank and Gaza':\"Palestine, State of\", # no perfect match\n    'Taiwan*':\"Taiwan, Province of China\",\n    'Russia':'Russian Federation',\n    'Iran':'Iran, Islamic Republic of',\n    'Korea, South':\"Korea, Republic of\",\n    'Syria':'Syrian Arab Republic',\n    'Kosovo':\"Kosovo\", # Not Sure\n    'Diamond Princess':\"NoNeedToModel_1\", # a ship\n    'Burma': 'Myanmar',\n    'US':\"United States\",\n    'Holy See': 'Holy See (Vatican City State)',\n    'Moldova':\"Moldova, Republic of\",\n    'Vietnam':\"Viet Nam\",\n    'Congo (Kinshasa)': 'Congo, The Democratic Republic of the',\n     'Laos':\"Lao People's Democratic Republic\",\n     'Brunei':\"Brunei Darussalam\",\n     'Tanzania':\"Tanzania, United Republic of\",\n     'MS Zaandam':\"NoNeedToModel_2\",#a ship\n    \"Bolivia\":\"Bolivia, Plurinational State of\",\n}\nlen(mannual_dict)","2af30315":"\"Palestine, State of\" in train_full_df[\"Country_Region\"]","1925e942":"train_full_df[train_full_df[\"Country_Region\"]==\"Kosovo\"]","ae2ac55d":"# check tool\nkeyword  = 'Moro'\nfor c in all_country_official:\n    if keyword in c:\n        print(c)","4adde559":"kname_to_oname_dict = {}\nkname_to_oname_dict.update(mannual_dict)\nlen(kname_to_oname_dict)","73a44fee":"kname_to_ocode_dict = {}\nfor c in all_countries:\n    if c in kname_to_oname_dict:\n        pass\n    else:\n        kname_to_oname_dict[c] = c\nfor k,v in kname_to_oname_dict.items():\n    \n    if v not in all_country_official:\n        if v == \"Kosovo\":\n            kname_to_ocode_dict[k] = \"XK\"\n        else:\n            kname_to_ocode_dict[k] = v\n    else:\n        kname_to_ocode_dict[k] = name_to_code2(v)\nkname_to_ocode_dict","0b2b40a4":"name_transfer_back_dict = {v:k for k,v in kname_to_oname_dict.items()}\ncode_transfer_back_dict = {v:k for k,v in kname_to_ocode_dict.items()}","a899a4ad":"new_countries_l = [kname_to_oname_dict[c] for c in kname_to_oname_dict]","edb3a953":"area_feature_df = pd.DataFrame([area_country_dict.keys(),area_country_dict.values()]).T\narea_feature_df.columns = [\"area\",\"country_region\"]\narea_feature_df[\"official_name\"] = area_feature_df[\"country_region\"].apply(lambda x: kname_to_oname_dict[x])\narea_feature_df[\"code2\"] = area_feature_df[\"country_region\"].apply(lambda x: kname_to_ocode_dict[x])\narea_feature_df[\"code3\"] = area_feature_df[\"official_name\"].apply(lambda x: country_to_code3(x) if x in all_country_official else x)\narea_feature_df.set_index(\"official_name\",drop=False,inplace=True)\narea_feature_df.head(3)","8dc026a9":"def code2_to_cont_specific(code2):\n    if code2 not in all_code_official:\n        if code2 == \"XK\": # special Kosolov\n            return \"EU\"\n        return \"NotKnow\"\n    if code2 == \"VA\":#Holy See (Vatican City State)\n        return \"EU\"\n    if code2 ==\"TL\":#Timor-Leste\n        return \"AS\"\n    if code2 == \"EH\": #Western Sahara\n        return \"AF\" \n    return code2_to_cont(code2)\narea_feature_df[\"continent\"] = area_feature_df.code2.apply(lambda x : code2_to_cont_specific(x))","a0da158f":"\"XK\" in all_code_official","9740304b":"code2_to_cont(\"XK\")","53648526":"area_feature_df[area_feature_df[\"continent\"] == \"NotKnow\"]","531a1ea6":"area_feature_df[area_feature_df.code2 ==\"VA\"]","a6feb65b":"area_feature_df.shape","32fe51cd":"len(area_feature_df.code3.unique())","5eeea8b4":"def find_latest(row):\n    for col in rep_cols[::-1]:\n        if row.loc[col] is not np.nan:\n            return row.loc[col]\ndemo = pd.read_csv(\"\/kaggle\/input\/global-population-estimates\/data.csv\")\ndemo.dropna(thresh=93,inplace=True) # drop those almost nan row\ndemo_pct_df = demo[demo[\"Series Code\"].str.contains(\"TO.ZS\")].copy() # find those pct feature\nbasic_cols = ['Country Name', 'Country Code', 'Series Name', 'Series Code'] + ['2015 [YR2015]',\n               '2016 [YR2016]', '2017 [YR2017]', '2018 [YR2018]', '2019 [YR2019]',\n               '2020 [YR2020]']\ndemo_pct_df = demo_pct_df[basic_cols].copy() # pick valuable one\nage_map_dict= {\"SP.POP.0014.TO.ZS\": \"young\",\n \"SP.POP.1564.TO.ZS\":\"middle\",\n \"SP.POP.65UP.TO.ZS\":\"old\"}\ndemo_pct_df[\"Series Code\"] = demo_pct_df[\"Series Code\"].apply(lambda x: age_map_dict[x] if x in age_map_dict else x) # new name\nrep_cols = ['2015 [YR2015]','2016 [YR2016]', '2017 [YR2017]', '2018 [YR2018]', '2019 [YR2019]','2020 [YR2020]']\ndemo_pct_df['latest_pct'] = demo_pct_df.apply(axis = 1, func = lambda row : find_latest(row)) # get the latest estimation\npop_df = demo_pct_df.pivot_table(index = \"Country Code\",columns = \"Series Code\",values = \"latest_pct\") \/100  # pivot it\npop_df.head()","cb19467b":"area_feature_df = area_feature_df.merge(pop_df,how = \"left\",left_on = \"code3\",right_index = True)","83303373":"area_feature_df.isna().sum(axis = 1).sort_values(ascending=False)[:17]\n# 16 region without age distribution data","066e0ae1":"# more accurate population for country level\npop_worldometer_df = pd.read_csv(\"\/kaggle\/input\/population-by-country-2020\/population_by_country_2020.csv\")\ncountry_s = pop_worldometer_df[\"Country (or dependency)\"]\npop_worldometer_df.head()","a2cc8994":"c_dicts = {}\nfor c in country_s:\n    if c in all_country_official:\n        pass\n    else:\n        c_dicts[c] = c\nfor c1 in c_dicts:\n    l_find = []\n    for c2 in all_country_official:\n        if c1 in c2:\n            l_find.append(c1)\n    if len(l_find) == 1:\n        c_dicts[c1] = l_find[0]\n    else:\n        print(c1)","6a6b47a0":"# mannually fix some\nmannual_dict= {\n    \"Vietnam\":\"Viet Nam\",\n    \"DR Congo\":'Congo, The Democratic Republic of the',\n    \"South Korea\":\"Korea, Republic of\",\n    \"North Korea\":\"Korea, Democratic People's Republic of\",\n    \"Czech Republic (Czechia)\":\"Czechia\",\n    \"Laos\":\"Lao People's Democratic Republic\",\n    \"State of Palestine\":\"Palestine, State of\",\n    \"Sao Tome & Principe\":\"Sao Tome and Principe\",\n    \"St. Vincent & Grenadines\":\"Saint Vincent and the Grenadines\",\n    \"U.S. Virgin Islands\":\"Virgin Islands, U.S.\",\n    \"Saint Kitts & Nevis\":\"Saint Kitts and Nevis\",\n    \"Faeroe Islands\":\"Faroe Islands\",\n    \"British Virgin Islands\":\"Virgin Islands, British\",\n    \"Wallis & Futuna\":\"Wallis and Futuna\",\n    \"Saint Barthelemy\":\"Saint Barth\u00e9lemy\",\n    \"Saint Pierre & Miquelon\":\"Saint Pierre and Miquelon\",\n}\nc_dicts.update(mannual_dict)","388314aa":"# check tool\nkeyword  = 'Saint'\nfor c in all_country_official:\n    if keyword in c:\n        print(c)","653de515":"pop_worldometer_df[\"Country (or dependency)\"] = country_s.replace(c_dicts)\npop_worldometer_df[\"code3\"] = pop_worldometer_df[\"Country (or dependency)\"].apply(lambda x : country_to_code3(x) if x in all_country_official else np.nan)\npop_w_combine = pop_worldometer_df[[\"code3\",\"Population (2020)\",\"Density (P\/Km\u00b2)\",\"Med. Age\",\"Urban Pop %\"]].copy()\npop_w_combine.columns = [\"code3\",\"wm_pop\",\"wm_density\",\"wm_med\",\"wm_urban_pct\"]\narea_feature_df = area_feature_df.merge(pop_w_combine,on=\"code3\",how = \"left\")","69b76f33":"area_feature_df[area_feature_df[\"wm_pop\"] == \".N.A\"]","a87520e8":"def getAreaPop(area):\n    if area in province_lookup:\n        return province_lookup[area]\n    else:\n        if not np.isnan(area_feature_df.loc[area,\"wm_pop\"]):\n            return area_feature_df.loc[area,\"wm_pop\"]\n        elif area in country_lookup:\n            return country_lookup[area]\n        else:\n            return np.nan\narea_feature_df.set_index(\"area\",drop=False,inplace=True)\narea_feature_df[\"pop\"] = area_feature_df.area.apply(getAreaPop)\narea_feature_df[area_feature_df[\"pop\"].isna()] # all data is good","84ee2864":"train_begin_date_str = train_begin_date.strftime(\"%Y-%m-%d\")\ntrain_end_date_str = train_end_date.strftime(\"%Y-%m-%d\")\ntrain_begin_date_str","c098fe25":"import urllib.request, json \n# use the stringency score as the government response feature\nlink = f\"https:\/\/covidtrackerapi.bsg.ox.ac.uk\/api\/stringency\/date-range\/{train_begin_date_str}\/{train_end_date_str}\"\nwith urllib.request.urlopen(link) as url:\n    data = json.loads(url.read().decode())\ndata_Oxford_df = pd.DataFrame(data[\"data\"])\nfor i in range(data_Oxford_df.shape[0]):\n    for j in range(data_Oxford_df.shape[1]):\n        if isinstance(data_Oxford_df.iloc[i,j],dict):\n            if len(data_Oxford_df.iloc[i,j]) == 6:\n                pass\n            else:\n                print(data_Oxford_df.iloc[i,j])\n            data_Oxford_df.iloc[i,j] = data_Oxford_df.iloc[i,j][\"stringency_actual\"]","af9c9bb2":"data_Oxford_df.columns = [\"Stringency_\" + col for col in data_Oxford_df.columns]\ndata_Oxford_df.fillna(axis = 1,method = \"ffill\",inplace=True) # no score than regard it as the score before\ndata_Oxford_df.fillna(0,inplace=True) # still no score than regarding it as 0","02d4b8a2":"data_Oxford_df","65d7df6d":"len(set(area_feature_df.code3) -  set(data_Oxford_df.index)) # missing 64 coutries","38fc73dc":"code3_no_stringency = set(area_feature_df.code3) -  set(data_Oxford_df.index)\ncode3_no_stringency","ca0fa928":"area_feature_df = area_feature_df.merge(data_Oxford_df,right_index = True,left_on = \"code3\",how = \"left\")","82a1bcff":"WDICountry_df = pd.read_csv(\"\/kaggle\/input\/world-development-indicators\/wdi-csv-zip-57-mb-\/WDICountry.csv\")\nWDICountry_df.columns","857ab74b":"WDICountry_cols = ['Country Code', 'Region', 'Income Group']\nWDICountry_selected_df = WDICountry_df[WDICountry_cols].copy()\nWDICountry_selected_df.head(3)","662e6041":"# add  World Bank Open Data: https:\/\/www.kaggle.com\/theworldbank\/world-development-indicators#WDISeries.csv\nWDI = pd.read_csv(\"\/kaggle\/input\/world-development-indicators\/wdi-csv-zip-57-mb-\/WDIData.csv\")\nWDI.head(2)","2dd2f036":"WDI.shape","28a1b505":"selected_features_dict = {\n    'Access to electricity (% of population)': 'EG.ELC.ACCS.ZS',\n    'Adjusted net national income per capita (current US$)': 'NY.ADJ.NNTY.PC.CD',\n    'Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)': 'SH.DTH.COMM.ZS',\n    'Consumer price index (2010 = 100)': 'FP.CPI.TOTL',\n    'Coverage of social insurance programs (% of population)': 'per_si_allsi.cov_pop_tot',\n    'Current health expenditure (% of GDP)': 'SH.XPD.CHEX.GD.ZS',\n    'Current health expenditure per capita (current US$)': 'SH.XPD.CHEX.PC.CD',\n    'Current health expenditure per capita, PPP (current international $)': 'SH.XPD.CHEX.PP.CD',\n    'Domestic general government health expenditure (% of current health expenditure)': 'SH.XPD.GHED.CH.ZS',\n    'Domestic general government health expenditure (% of GDP)': 'SH.XPD.GHED.GD.ZS',\n    'Domestic general government health expenditure (% of general government expenditure)': 'SH.XPD.GHED.GE.ZS',\n    'Domestic general government health expenditure per capita (current US$)': 'SH.XPD.GHED.PC.CD',\n    'Domestic general government health expenditure per capita, PPP (current international $)': 'SH.XPD.GHED.PP.CD',\n    'Domestic private health expenditure (% of current health expenditure)': 'SH.XPD.PVTD.CH.ZS',\n    'Domestic private health expenditure per capita (current US$)': 'SH.XPD.PVTD.PC.CD',\n    'Domestic private health expenditure per capita, PPP (current international $)': 'SH.XPD.PVTD.PP.CD',\n    'GDP growth (annual %)': 'NY.GDP.MKTP.KD.ZG',\n    'GDP per capita (current US$)': 'NY.GDP.PCAP.CD',\n    'GDP per capita growth (annual %)': 'NY.GDP.PCAP.KD.ZG',\n    'GNI (current US$)': 'NY.GNP.MKTP.CD',\n    'GNI growth (annual %)': 'NY.GNP.MKTP.KD.ZG',\n    'GNI per capita (current LCU)': 'NY.GNP.PCAP.CN',\n    'GNI per capita growth (annual %)': 'NY.GNP.PCAP.KD.ZG',\n    'Life expectancy at birth, total (years)': 'SP.DYN.LE00.IN',\n    'Mortality rate attributed to unsafe water, unsafe sanitation and lack of hygiene (per 100,000 population)': 'SH.STA.WASH.P5',\n    'People using at least basic drinking water services (% of population)': 'SH.H2O.BASW.ZS',\n    'People using at least basic sanitation services (% of population)': 'SH.STA.BASS.ZS',\n    'People using safely managed drinking water services (% of population)': 'SH.H2O.SMDW.ZS',\n    'People using safely managed sanitation services (% of population)': 'SH.STA.SMSS.ZS',\n    'People with basic handwashing facilities including soap and water (% of population)': 'SH.STA.HYGN.ZS',\n    'People with basic handwashing facilities including soap and water, rural (% of rural population)': 'SH.STA.HYGN.RU.ZS',\n    'People with basic handwashing facilities including soap and water, urban (% of urban population)': 'SH.STA.HYGN.UR.ZS',\n    'Population density (people per sq. km of land area)': 'EN.POP.DNST',\n    'Population, total': 'SP.POP.TOTL',\n    'Prevalence of undernourishment (% of population)': 'SN.ITK.DEFC.ZS',\n}\nlen(selected_features_dict)","a79e0e9a":"# delete some highly correlated variables (from later correlation plot)\ndel_hi_corr_var_l = [\n    # --- \n    'SH.XPD.GHED.GD.ZS', # highly correlated with SH.XPD.PVTD.PP.CD\t\n    'SH.XPD.GHED.PC.CD',\n    'SH.XPD.PVTD.PC.CD',\n    'SH.XPD.CHEX.PC.CD',\n    'SH.XPD.CHEX.GD.ZS',\n    'SH.XPD.GHED.PP.CD',\n    'SH.XPD.CHEX.PP.CD',\n    'SH.XPD.PVTD.PP.CD',\n    #----\n    'NY.GNP.MKTP.CD',   # highly correlated with NY.GDP.MKTP.KD.ZG\n    'NY.GNP.MKTP.KD.ZG', # highly correlated with NY.GDP.PCAP.CD\n    'NY.GNP.PCAP.CN', \n    'NY.GNP.PCAP.KD.ZG',\n    # ---- \n    \"SP.DYN.LE00.IN\", # highly correlated with SH.STA.BASS.ZS\n    \"SH.H2O.BASW.ZS\",\n    \n    # -----\n    'NY.GDP.MKTP.KD.ZG', # highly correlated with  'NY.GNP.MKTP.KD.ZG': 'GNI growth (annual %)',\n    'NY.GNP.PCAP.KD.ZG',\n    'NY.GDP.PCAP.KD.ZG',\n    \n    # -----\n    'NY.GDP.PCAP.CD', # highly correlated with 'NY.ADJ.NNTY.PC.CD': 'Adjusted net national income per capita (current US$)',\n    'NY.GNP.MKTP.CD',\n    'NY.GNP.PCAP.CN',\n]","c3ab9c89":"needed_WDI_feature = list(set(selected_features_dict.values()) - set(del_hi_corr_var_l))\nlen(needed_WDI_feature)","ad131a36":"code3_needed = list(area_feature_df[\"code3\"].values)\nWDI_selected_df = WDI[(WDI[\"Country Code\"].isin(code3_needed))&(WDI[\"Indicator Code\"].isin(needed_WDI_feature))].copy()\nWDI_selected_df.columns","a7bebb38":"WDI_selected_df.head(2)","b7c4dd80":"cols_to_fill=['1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n       '2014', '2015', '2016', '2017', '2018']\ndef find_latest(row):\n    for col in cols_to_fill[::-1]:\n        if np.isnan(row.loc[col]):\n            continue\n        else:\n            return row.loc[col]\n    return np.nan\nWDI_selected_df[\"val\"] = WDI_selected_df.apply(axis = 1,func = lambda row: find_latest(row))","bd3e6d23":"WDI_selected_pivot_df = WDI_selected_df.pivot_table(index= \"Country Code\",columns = \"Indicator Code\",values = \"val\")\nWDI_selected_pivot_df.head()","0c9f7fe6":"WDI_selected_pivot_df.shape","8a2037b0":"'''\n    Drop the following cols:\n    'People with basic handwashing facilities including soap and water (% of population)': 'SH.STA.HYGN.ZS',\n    'People with basic handwashing facilities including soap and water, rural (% of rural population)': 'SH.STA.HYGN.RU.ZS',\n    'People with basic handwashing facilities including soap and water, urban (% of urban population)': 'SH.STA.HYGN.UR.ZS',\n    'People using safely managed sanitation services (% of population)': 'SH.STA.SMSS.ZS',\n    'People using safely managed drinking water services (% of population)': 'SH.H2O.SMDW.ZS',\n    'Coverage of social insurance programs (% of population)': 'per_si_allsi.cov_pop_tot', 80\n'''\nWDI_selected_pivot_df.isna().sum().sort_values(ascending =False)","241f3f7e":"WDI_selected_pivot_df.dropna(axis = 1, thresh = 100 ,inplace=True)\nWDI_selected_pivot_df.isna().sum().sort_values(ascending =False)","3434aeab":"WDI_selected_pivot_df","f50c46ba":"WDI_data_selected = WDICountry_selected_df.merge(WDI_selected_pivot_df,how=\"right\",left_on=\"Country Code\",right_index = True)\nWDI_data_selected.head(2)","78216843":"len(set(code3_needed) - set(WDI_data_selected[\"Country Code\"])) # nice only 6 we don't have, which actually is 3!","71eeeeaf":"# combine with country_feature_df\narea_feature_df = area_feature_df.merge(WDI_data_selected,how=\"left\",left_on=\"code3\",right_on = \"Country Code\")\narea_feature_df.head(2)","e168a74a":"area_feature_df.shape","1438302e":"area_feature_df.set_index(\"area\",inplace=True, drop = False)","1493f3e1":"area_feature_df.isna().sum(axis = 1).sort_values(ascending = False)[:20]","70088554":"area_feature_df.isna().sum()","1c4e84cc":"# check first\narea_feature_df.shape","cca204b3":"area_feature_df[area_feature_df[\"continent\"] == \"NotKnow\"]","fe19b250":"area_feature_df[area_feature_df.continent.apply(lambda x: True if len(x)>2 else False)]","50ec4026":"area_feature_df[area_feature_df[\"Income Group\"].isna()]","7e169e63":"# fill missing value of Income Group\narea_feature_df[\"Income Group\"].unique()","170b6238":"# Taiwan - Upper middle income\n# Holy See - 'Lower middle income'\n# https:\/\/en.wikipedia.org\/wiki\/List_of_countries_by_GDP_(PPP)\narea_feature_df.loc[\"Holy See\",\"Income Group\"] = \"Lower middle income\"\narea_feature_df.loc[\"Taiwan*\",\"Income Group\"] = \"Upper middle income\"\narea_feature_df.loc[\"Western Sahara\",\"Income Group\"] = \"Low income\"\narea_feature_df.loc[\"Kosovo\",\"Income Group\"] = \"Low income\"","da312f98":"area_feature_df[area_feature_df[\"Income Group\"].isna()]","71179893":"# No missing value of continent.\narea_feature_df[\"continent\"].unique()","235dde72":"# fill missing value of population\narea_feature_df[area_feature_df[\"pop\"].isna()].index","1a644bef":"'''\npop_fill_dict = {\n    'Saint Pierre and Miquelon' : 5800, \n    'Malawi':19021137,\n    'Bonaire, Sint Eustatius and Saba':25160, \n    'Sao Tome and Principe':218271,\n    'South Sudan':11165316, \n    'Falkland Islands (Malvinas)':3548,\n}\nfor k,v in pop_fill_dict.items():\n    area_feature_df.loc[k,\"pop\"] = v\narea_feature_df[area_feature_df[\"pop\"].isna()].index\n'''","ad836f12":"area_feature_df.groupby([\"continent\",\"country_region\"])[\"pop\"].mean().reset_index().groupby(\"continent\")[\"pop\"].sum() \/area_feature_df.groupby([\"continent\",\"country_region\"])[\"pop\"].mean().reset_index().groupby(\"continent\")[\"pop\"].sum().sum()","d598f751":"area_feature_df.loc[\"Kosovo\",\"young\"] = 0.258\narea_feature_df.loc[\"Kosovo\",\"middle\"] = 0.672\narea_feature_df.loc[\"Kosovo\",\"old\"] = 0.07","d20469af":"# treat these special areas specially\nspecial_areas = [\"Diamond Princess\",\"MS Zaandam\"] + china_area\nspecial_areas_feature = area_feature_df.loc[special_areas,:].copy()\narea_feature_df.drop(index = special_areas, axis = 0,inplace=True)","cd27c994":"age_dist_group_df = area_feature_df.drop_duplicates(subset=\"country_region\").groupby([\"continent\",\"Income Group\"])[[\"middle\",\"old\",\"young\"]].mean()\nage_dist_group_df","8c305cbe":"for i in range(area_feature_df.shape[0]):\n    c = area_feature_df.index[i]\n    if np.isnan(area_feature_df.loc[c,\"middle\"]):\n        cont = area_feature_df.loc[c,\"continent\"]\n        income_group = area_feature_df.loc[c,\"Income Group\"]\n        for age in [\"young\",\"middle\",\"old\"]:\n            area_feature_df.loc[c,age] = age_dist_group_df.loc[idx[cont,income_group],age]\narea_feature_df[area_feature_df[\"old\"].isna()] # only those 4 special are nan, which will be taken out treat specially","ec154dd4":"pop_df","1fac86b2":"stringency_cols = data_Oxford_df.columns ","627fd63d":"stringency_score_dist_group_df = area_feature_df.drop_duplicates(subset=\"country_region\").groupby([\"continent\",\"Income Group\"])[stringency_cols].mean()\nstringency_score_dist_group_df.head()","a221ffd4":"# stringency score fill\nfor i in range(area_feature_df.shape[0]):\n    c = area_feature_df.index[i]\n    if np.isnan(area_feature_df.loc[c,stringency_cols[0]]):\n        cont = area_feature_df.loc[c,\"continent\"]\n        income_group = area_feature_df.loc[c,\"Income Group\"]\n        if np.isnan(stringency_score_dist_group_df.loc[idx[cont,income_group],stringency_cols[0]]):\n            area_feature_df.loc[c,stringency_cols] = area_feature_df[stringency_cols].mean()\n        else:\n            for str_col in stringency_cols:\n                area_feature_df.loc[c,str_col] = stringency_score_dist_group_df.loc[idx[cont,income_group],str_col]\narea_feature_df[area_feature_df[stringency_cols[0]].isna()]","83b93e17":"Image(url= \"https:\/\/covid19-scenarios.org\/assets\/model_sketch.741fd99.svg\")","391889f3":"oneday = timedelta(days=1)\n\n# Susceptible equation\ndef make_a_s(df,age,t):\n    return df.loc[:,age].loc[t]\n\n# Susceptible individuals are exposed to the\n# virus by contact with an infected individual.\ndef dS_dt(t, S, I, R_t, t_inf):\n    \n    def dSa_dt(Sa, I, R_t, ta_inf):\n        return -(R_t \/ ta_inf) * I * Sa\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        Sa = make_a_s(S,age,t)\n        ta_inf = t_inf[age]\n        val =  S.loc[t,age] + dSa_dt(Sa , I.loc[t,:].sum(), R_t.loc[t], ta_inf)\n        S.loc[t+oneday,age]  = val\n    return S\n\n# Exposed equation\ndef dE_dt(t, S, E, I, R_t, t_inf, t_inc):\n\n    def dEa_dt(Sa, Ea, I, R_t, ta_inf, ta_inc):\n        # Exposed individuals progress towards a \n        # symptomatic state on average time t_inc\n        return (R_t \/ ta_inf) * I * Sa - (Ea \/ ta_inc)\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        Sa = make_a_s(S,age,t)\n        Ea = make_a_s(E,age,t)\n        ta_inf = t_inf[age]\n        ta_inc = t_inc[age]\n        val = E.loc[t,age] + dEa_dt(Sa, Ea, I.loc[t,:].sum(), R_t.loc[t], ta_inf, ta_inc)\n        E.loc[t+oneday,age] = val\n    \n    return E\n\n# Infected equation\ndef dI_dt(t, I, E, t_inc, t_inf):\n    \n    def dIa_dt(Ia, Ea, ta_inc, ta_inf):\n        # Infected individuals infect an average of R_0  secondary \n        # infections. On a time-scale of t_inf infected individuals \n        # either recover or progress towards hospitalization.\n        return (Ea \/ ta_inc) - (Ia \/ ta_inf)\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        Ia = make_a_s(I,age,t)\n        Ea = make_a_s(E,age,t)\n        ta_inc = t_inc[age]\n        ta_inf = t_inf[age]\n        val = I.loc[t,age] + dIa_dt(Ia, Ea, ta_inc, ta_inf)\n        I.loc[t+oneday,age] = val\n    return I\n\n\n# Hospialized equation\ndef dH_dt(t,I,C,H,t_inf,t_hosp,t_crit,m,f):\n    \n    def dHa_dt(Ia, Ca, Ha, ta_inf, ta_hosp, ta_crit, m_a, f_a):\n        # Hospitalized individuals either recover or \n        # worsen towards a critical state on a time-scale of t_hosp\n        return ((1 - m_a) * (Ia \/ ta_inf)) + ((1 - f_a) * Ca \/ ta_crit) - (Ha \/ ta_hosp)\n\n    for age in [\"young\",\"middle\",\"old\"]:\n        Ia = make_a_s(I,age,t)\n        Ca = make_a_s(C,age,t)\n        Ha = make_a_s(H,age,t)\n        ta_inf = t_inf[age]\n        ta_hosp = t_hosp[age]\n        ta_crit = t_crit[age]\n        m_a = m[age]\n        f_a = f[age]\n        val = H.loc[t,age] + dHa_dt(Ia, Ca, Ha, ta_inf, ta_hosp, ta_crit, m_a, f_a)\n        H.loc[t+oneday,age] = val\n    return H\n\n# Critical equation\ndef dC_dt(t,H,C,t_hosp,t_crit,c):\n    def dCa_dt(Ha, Ca, ta_hosp, ta_crit, c_a):\n        # Critical individuals model ICU usage. \n        # They either return to the hospital state or die on a time-scale of t_crit\n        return (c_a * Ha \/ ta_hosp) - (Ca \/ ta_crit)\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        Ha = make_a_s(H,age,t)\n        Ca = make_a_s(C,age,t)\n        ta_hosp = t_hosp[age]\n        ta_crit = t_crit[age]\n        c_a = c[age]\n        val = C.loc[t,age] + dCa_dt(Ha, Ca, ta_hosp, ta_crit, c_a)\n        C.loc[t+oneday,age] = val\n    \n    return C\n\n# Recovered equation\n# Recovered individuals can not be infected again.\ndef dR_dt(t, R, I, H, t_inf, t_hosp, m, c):\n    \n    def dRa_dt(Ia, Ha, ta_inf, ta_hosp, m_a, c_a):\n        return (m_a * Ia \/ ta_inf) + (1 - c_a) * (Ha \/ ta_hosp)\n\n    for age in [\"young\",\"middle\",\"old\"]:\n        Ia = make_a_s(I,age,t)\n        Ha = make_a_s(H,age,t)\n        ta_inf = t_inf[age]\n        ta_hosp = t_hosp[age]\n        m_a = m[age]\n        c_a = c[age]\n        val = R.loc[t,age] + dRa_dt(Ia, Ha, ta_inf, ta_hosp, m_a, c_a)\n        R.loc[t+oneday,age] = val   \n        \n    return R\n\n# Deaths equation\ndef dD_dt(t,D, C,t_crit,f):\n\n    def dDa_dt(Ca, ta_crit, f_a):\n        return f_a * Ca \/ ta_crit\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        Ca = make_a_s(C,age,t)\n        ta_crit = t_crit[age]\n        f_a = f[age]\n        val = D.loc[t,age] +  dDa_dt(Ca, ta_crit, f_a)\n        D.loc[t+oneday,age] = val    \n        \n    return D\n\n\n#def SEIR_HCD_model(t, y, R_t, t_inc=2.9, t_inf=5.2, t_hosp=4, t_crit=14, m_a=0.8, c_a=0.1, f_a=0.3):\ndef SEIR_HCD_model_age(t, y, R_t, param_dict):\n    \"\"\"\n    :param t: Time step for solve_ivp\n    :param y: Previous solution or initial values\n    :param R_t: Reproduction number. Default 3.6 days.\n    :param t_inc: Average incubation period. Default 5.2 days\n    :param t_inf: Average infectious period. Default 2.9 days\n    :param t_hosp: Average time a patient is in hospital before either recovering or becoming critical. Default 4 days\n    :param t_crit: Average time a patient is in a critical state (either recover or die). Default 14 days\n    :param m: Fraction of infections that are asymptomatic or mild. Default 0.8\n    :param c: Fraction of severe cases that turn critical. Default 0.1\n    :param f: Fraction of critical cases that are fatal. Default 0.3\n    :return:\n    \"\"\"\n    if callable(R_t):\n        reprod = R_t(t)\n    else:\n        reprod = R_t\n        \n    S, E, I, R, H, C, D = y\n    # S,E,I,R,H,C,D is a series with date as index and multiindex columns. (type, age_group)\n    S = dS_dt(t, S, I, reprod, t_inf = param_dict['t_inf'])\n    E = dE_dt(t, S, E, I, reprod, t_inf = param_dict['t_inf'], t_inc = param_dict['t_inc'])\n    I = dI_dt(t, I, E, t_inc = param_dict['t_inc'], t_inf = param_dict['t_inf'])\n    R = dR_dt(t, R, I, H, t_inf = param_dict['t_inf'], t_hosp = param_dict['t_hosp'], m = param_dict['m'], c = param_dict['c'])\n    H = dH_dt(t, I, C, H, t_inf = param_dict['t_inf'], t_hosp= param_dict['t_hosp'], t_crit = param_dict['t_crit'],\n                          m = param_dict['m'], f= param_dict['f'])\n    C = dC_dt(t, H, C, t_hosp= param_dict['t_hosp'], t_crit= param_dict['t_crit'], c = param_dict['c'])\n    D = dD_dt(t, D, C, t_crit = param_dict['t_crit'], f = param_dict['f'])\n    return [S, E, I, R, H, C, D]","bd345a15":"area_feature_df.head()","089c9bcd":"pop_df = area_feature_df[[\"area\",\"young\",\"middle\",\"old\",\"pop\"]].copy()\npop_df.set_index(\"area\",inplace=True,drop = True)\npop_df.head()","8f101e62":"# generate \n# 1. pop_type_df: store the change of those people type \n# 2. R_df: store the time changing value R, because of restriction of government posted\n# 3. time_fixed_param_df: store time fixed model relative parameter.\n\n#code2_s = list(code_pop_dict.keys())\ndates = train_full_df.index.levels[1]\npop_type = [ptype for ptype in \"SEIHCRD\"]\nage_type = [\"young\",\"middle\",\"old\"]\nR = [\"R_t\"]\ntime_fixed_param = [\"t_inc\",\"t_inf\",\"t_hosp\",\"t_crit\",\"m\",\"c\",\"f\"]\npop_age_cols = pd.MultiIndex.from_product([pop_type,age_type])\n#code_dates_index = pd.MultiIndex.from_product(code2_s,dates)\ntime_fixed_param_age_cols = pd.MultiIndex.from_product([time_fixed_param,age_type])\n\npop_type_df = pd.DataFrame(index = dates, columns = pop_age_cols)\nR_s = pd.Series(index = dates)\n#time_fixed_param_df = pd.DataFrame(index = dates, columns = time_fixed_param_age_cols)","dca926ab":"param_dict = {}\ndefault_param_dict = {\n    \"t_inc\":4,\n    \"t_inf\":3, \n    \"t_hosp\":4, \n    \"t_crit\":14, \n    \"m\":0.8, \n    \"c\":0.1, \n    \"f\":0.3\n}\n# mcf_dict, reference to https:\/\/covid19-scenarios.org\/\nmcf_dict = {\n    'young': {'m': 0.98, 'c': 0.075, 'f': 0.3},\n 'middle': {'m': 0.96, 'c': 0.15, 'f': 0.3},\n 'old': {'m': 0.7, 'c': 0.4, 'f': 0.45}\n}\nfor param in time_fixed_param:\n    if param in [\"m\",\"c\",\"f\"]:\n        param_dict[param] = {\n           age:mcf_dict[age][param] for age in mcf_dict\n        }\n    else:\n        param_dict[param] = {\n            \"young\": default_param_dict[param],\n            \"middle\":default_param_dict[param],\n            \"old\":default_param_dict[param],\n        }\nparam_dict","762b2643":"pop_type_df.head(2)","bf178c7a":"R_s.head(2)","201c6ea9":"default_R = 3.6","b1256dc5":"# stringency feature\nstringency_features = [\"code2\"] + list(stringency_cols)\nstringency_df = area_feature_df[stringency_features].copy()\nstringency_df = stringency_df.groupby(\"code2\").mean().reset_index()\nstringency_df.columns = [\"code2\"]+list(dates)\nstringency_df = stringency_df.melt(value_vars= dates,id_vars = \"code2\")\nstringency_df.columns = [\"code2\",\"date\",\"stringency\"]\nstringency_df.sort_values([\"code2\",\"date\"],inplace=True)\nstringency_df.set_index([\"code2\",\"date\"],inplace=True)\nstringency_df.head()","14b750b7":"def pop_lookup(area):\n    if area in province_lookup:\n        return province_lookup[area]\n    else:\n        return country_lookup[area]\ndef show_l(a_l):    \n    print(len(a_l),\" Areas:\")\n    for a in a_l:\n        print(a,\":\\t country: \" + area_country_dict[a],\",\\t pop: \",pop_lookup(a))\n\nzero_case_df = train_full_df.loc[idx[:,train_end_date],\"ConfirmedCases\"] == 0\nzero_case_l = []\nfor c in area_country_dict.keys():\n    if zero_case_df.loc[idx[c,train_end_date]] == True:\n        zero_case_l.append(c)\nshow_l(zero_case_l)","287119a2":"not_zero_case_df = train_full_df.loc[idx[:,train_begin_date],\"ConfirmedCases\"] >10\nnot_zero_case_l = []\nfor a in area_country_dict.keys():\n    if not_zero_case_df.loc[idx[a,train_begin_date]] == True:\n        not_zero_case_l.append(a)\nshow_l(not_zero_case_l)","33b01b08":"def init_pop(area = \"Afghanistan\",show = True):\n    cases_series_eg = train_full_df.loc[idx[area,:],:].copy()\n    cases_series_eg = cases_series_eg[cases_series_eg['ConfirmedCases']>0].copy()\n    if area in special_areas:\n        return 0,cases_series_eg, 0, 0\n    if cases_series_eg.shape[0] == 0:\n        return 0, 0, 0, 0 \n    first_case_date = cases_series_eg.index[0][1]\n    first_case_num = cases_series_eg.loc[idx[:,first_case_date],\"ConfirmedCases\"].values[0]\n    # add pop_type_data\n    pop_type_df_eg  = pop_type_df.loc[first_case_date:,:].copy()\n    # initialize pop_type_df\n    col_num = pop_type_df.shape[1]\n    pct_young = pop_df.loc[area,\"young\"]\n    pct_middle = pop_df.loc[area,\"middle\"]\n    pct_old = pop_df.loc[area,\"old\"]\n    all_pop = pop_df.loc[area,\"pop\"]\n    I_ratio = first_case_num\/all_pop\n    S_ratio = 1 - I_ratio\n    pop_type_df_eg.loc[first_case_date,:] = np.array([S_ratio*pct_young,S_ratio*pct_middle,S_ratio*pct_old] + [0.] * 3 \\\n                                        + [I_ratio*pct_young,I_ratio*pct_middle,I_ratio*pct_old] + [0.]*(col_num-9))\n    if show:\n        print(f\"Inititialize population for area {area}...\")\n        print(\"First Case Date: \", first_case_date)\n        print(\"First Case Number: \", first_case_num )\n    return pop_type_df_eg,cases_series_eg, first_case_date,all_pop\n\ndef init_R(naive=True, c2=\"AF\", stringency_df = 0, show = True, default_R = default_R, sensitivity = 1, b = 1):\n    if show:\n        if naive:\n            print(f\"Inititialize Reproduction Rate as {default_R}, Naively\")\n        else:\n            print(\"Initialize Reproduction Rate according to Stringency Score\")\n    R_s_eg = R_s.copy()\n    R_s_eg.fillna(default_R,inplace=True)\n    if not naive:\n        assert not isinstance(stringency_df,int)\n        stringency_score_eg = stringency_df.loc[idx[c2,:],\"stringency\"]\n        stringency_score_eg.index = stringency_score_eg.index.droplevel(0) \n        # add sensitivity to measure how people tend to react to the policy (0.8~1.2), lower means more sensitive\n        # add beta to measure how soon the policy get implemented (0.5~1), lower means slower\n        stringency_multiplier = 1 - b * (stringency_score_eg\/100) ** sensitivity\n        R_s_eg  = R_s_eg * stringency_multiplier\n    return R_s_eg\n'''\ndef init_param(naive = True, mcf_dict = 0, default_param_dict = default_param_dict, show = True):\n    if show:\n        if naive:\n            print(f\"Inititialize Parameters as default_para_dict, Naively\")\n        else:\n            print(\"Initialize Parameters according to Stringency Score\")\n        \n    # initialize time_fixed_param_df\n    time_fixed_param_df_eg = time_fixed_param_df.copy()\n    if naive:\n        for k,v in default_param_dict.items():\n            time_fixed_param_df_eg.loc[:,idx[k,:]] = v\n    else:        \n        assert not isinstance(mcf_dict, int)\n        for k,v in default_param_dict.items():\n            if k not in [\"m\",\"c\",\"f\"]:\n                time_fixed_param_df_eg.loc[:,idx[k,:]] = v\n            else:\n                for age in [\"young\",\"middle\",\"old\"]:\n                    time_fixed_param_df_eg.loc[:,idx[k,age]] = mcf_dict[age][k]\n    return time_fixed_param_df_eg\n'''\n\ndef init_input(pop_type_df_eg , show = True):\n    if show:\n        print(\"Inititialize Input...\")\n    S_eg = pop_type_df_eg.loc[:,idx[\"S\",:]].copy()\n    E_eg = pop_type_df_eg.loc[:,idx[\"E\",:]].copy()\n    I_eg = pop_type_df_eg.loc[:,idx[\"I\",:]].copy()\n    H_eg = pop_type_df_eg.loc[:,idx[\"H\",:]].copy()\n    C_eg = pop_type_df_eg.loc[:,idx[\"C\",:]].copy()\n    R_eg = pop_type_df_eg.loc[:,idx[\"R\",:]].copy()\n    D_eg = pop_type_df_eg.loc[:,idx[\"D\",:]].copy()\n\n\n    \n    #t_inc_eg = time_fixed_param_df_eg.loc[:,idx[\"t_inc\",:]].copy()\n    #t_inf_eg = time_fixed_param_df_eg.loc[:,idx[\"t_inf\",:]].copy()\n    #t_hosp_eg = time_fixed_param_df_eg.loc[:,idx[\"t_hosp\",:]].copy()\n    #t_crit_eg = time_fixed_param_df_eg.loc[:,idx[\"t_crit\",:]].copy()\n    #m_eg = time_fixed_param_df_eg.loc[:,idx[\"m\",:]].copy()\n    #c_eg = time_fixed_param_df_eg.loc[:,idx[\"c\",:]].copy()\n    #f_eg = time_fixed_param_df_eg.loc[:,idx[\"f\",:]].copy()\n\n    for df in [S_eg,E_eg,I_eg,H_eg, C_eg, R_eg, D_eg]:\n        df.columns = df.columns.levels[1]\n        \n    y_eg = [S_eg,E_eg, I_eg, H_eg, C_eg, R_eg, D_eg]\n    \n    return y_eg","570d29ad":"def run_model(first_case_date, y_eg, R_s_eg, param_dict, end_date = train_end_date):\n    date = first_case_date\n    while date < end_date:\n        y_eg = SEIR_HCD_model_age(date, y_eg, R_s_eg, param_dict)\n        date += oneday\n    pop_type_df_eg_end = pd.concat(y_eg,axis = 1)\n    pop_type_df_eg_end.columns = pop_age_cols\n    return pop_type_df_eg_end","7785a8e8":"OPTIM_DAYS = 21\ndef evaluate_model(pop_type_df_end, cases_series, all_pop, show = True, est_begin_date = train_begin_date, est_end_date = train_end_date):\n    pop_type_df_end_pop = pop_type_df_end.sum(axis =1 ,level = 0) * all_pop\n    cases_pop = cases_series.reset_index(level=0,drop = True)    \n    cases_pop = cases_pop.loc[est_begin_date:est_end_date].copy()\n    pop_type_df_end_pop = pop_type_df_end_pop.loc[est_begin_date:est_end_date].copy()\n    \n    optim_days = min(OPTIM_DAYS, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    sus = pop_type_df_end_pop[\"S\"]\n    exp = pop_type_df_end_pop[\"E\"]\n    inf = pop_type_df_end_pop[\"I\"]\n    rec = pop_type_df_end_pop[\"R\"]\n    hosp = pop_type_df_end_pop[\"H\"]\n    crit = pop_type_df_end_pop[\"C\"]\n    death  = pop_type_df_end_pop[\"D\"]\n    cases = inf + rec + hosp + crit + death\n    cases_real = cases_pop.loc[:,\"ConfirmedCases\"]\n    death_real = cases_pop.loc[:,\"Fatalities\"]\n    \n    # Mean Absolute Error.\n    case_score = mean_absolute_error(cases_real.iloc[-optim_days:],cases.iloc[-optim_days:],sample_weight = weights)\n    death_score = mean_absolute_error(death_real.iloc[-optim_days:],death.iloc[-optim_days:],sample_weight = weights)\n\n    # the column-wise root mean squared logarithmic error.\n    case_log_score = np.sqrt(mean_squared_log_error(cases_real.iloc[-optim_days:],cases.iloc[-optim_days:],sample_weight = weights))\n    death_log_score = np.sqrt(mean_squared_log_error(death_real.iloc[-optim_days:],death.iloc[-optim_days:],sample_weight = weights))\n    \n    MAE = {\n        \"case\": case_score,\n        \"death\": death_score,\n    }\n    target_MAE = MAE[\"death\"]\n    \n    RMSLE = {\n        \"case\":case_log_score,\n        \"death\": death_log_score,\n    }\n    target_RMSLE = np.mean([RMSLE[\"case\"],RMSLE[\"death\"]])\n    if show:\n        print(\"MAE: {:.2f}, RMSLE: {:.3f}\".format(target_MAE,target_RMSLE))\n        print(\"MAE Detail\\n\")\n        pprint(MAE)\n        print(\"RMSLE Detail\\n\")\n        pprint(RMSLE)\n    return MAE, RMSLE, target_MAE, target_RMSLE","934f535a":"from pandas.plotting import register_matplotlib_converters\nfrom matplotlib.dates import DateFormatter\nregister_matplotlib_converters()\ndate_form = DateFormatter(\"%m-%d\")\n\ndef plot_model(pop_type_df_end, cases_series, all_pop, R_s, title='SEIR+HCD model'):\n    \n    pop_type_df_end_pop = pop_type_df_end.sum(axis =1 ,level = 0) * all_pop\n    cases_pop = cases_series.reset_index(level=0,drop = True)\n\n    pop_type_df_end_pop.index = pd.to_datetime(pop_type_df_end_pop.index)\n    cases_pop.index = pd.to_datetime(cases_pop.index)\n    R_s.index = pd.to_datetime(R_s.index)\n\n    R_s = R_s.loc[cases_pop.index]\n    \n    \n    sus = pop_type_df_end_pop[\"S\"]\n    exp = pop_type_df_end_pop[\"E\"]\n    inf = pop_type_df_end_pop[\"I\"]\n    rec = pop_type_df_end_pop[\"R\"]\n    hosp = pop_type_df_end_pop[\"H\"]\n    crit = pop_type_df_end_pop[\"C\"]\n    death  = pop_type_df_end_pop[\"D\"]\n    cases = inf + rec + hosp + crit + death\n    cases_real = cases_pop[\"ConfirmedCases\"]\n    death_real = cases_pop[\"Fatalities\"]\n\n    \n    #ax1.plot(exp, 'tab:orange', label='Exposed');\n    #ax1.plot(inf, 'tab:red', label='Infected');\n    #ax1.plot(rec, 'tab:green', label='Recovered');\n    #ax1.plot(hosp, 'tab:purple', label='Hospitalised');\n    #ax1.plot(crit, 'tab:brown', label='Critical');\n    #ax1.plot(death, 'tab:cyan', label='Deceased');\n    \n    #ax1.set_xlabel(\"Date\", fontsize=10);\n    #ax1.set_ylabel(\"Population\", fontsize=10);\n    #ax1.legend(loc='best');\n    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(16,6))\n    fig.suptitle(title)    \n    ax1.plot(cases, color = \"b\", label='Cases');    \n    ax1.plot(cases_real, color = \"b\", linestyle = '--',label='Cases(Real)');    \n    ax1.set_xlabel(\"Date\", fontsize=10);\n    ax1.set_ylabel(\"Cases\", fontsize=10, color='b');\n    ax1.legend(loc=\"upper left\")\n    ax3 = ax1.twinx()\n    ax3.plot(R_s, color = \"black\",label = \"Rt\")\n    ax3.set_ylabel(\"Rt\", fontsize=10, color='black');\n    ax3.legend(loc=\"upper right\")\n    ax1.xaxis.set_major_formatter(date_form)\n    \n    ax2.plot(death,  color = 'r', label='Fatalities');    \n    ax2.plot(death_real, color = 'r', linestyle = '--',label='Fatalities(Real)');    \n    ax2.set_xlabel(\"Date\", fontsize=10)\n    ax2.set_ylabel(\"Fatalities\", fontsize=10, color='r')\n    ax2.legend(loc=\"upper left\")\n    ax4 = ax2.twinx()\n    ax4.plot(R_s, color = \"black\",label = \"Rt\")\n    ax4.set_ylabel(\"Rt\", fontsize=10, color='black');\n    ax4.legend(loc=\"upper right\")\n    ax2.xaxis.set_major_formatter(date_form)\n    plt.show()","761138fb":"area_code2_dict = dict(zip(area_feature_df.area,area_feature_df.code2))\narea = \"Afghanistan\"\nc2 = area_code2_dict[area]\npop_type_df_eg, cases_series_eg, first_case_date,all_pop = init_pop(area = area)\nif isinstance(pop_type_df_eg, int):\n    print(area,\" no cases until now\")\nelse:    \n    R_s_eg = init_R(naive=True)\n    y_eg = init_input(pop_type_df_eg,param_dict)\n    pop_type_df_eg_end = run_model(first_case_date, y_eg, R_s_eg, param_dict)\n    plot_model(pop_type_df_eg_end, cases_series_eg, all_pop,R_s = R_s_eg, title='SEIR+HCD model without intervention')\n    MAE_1,RMSLE_1, target_MAE_1,target_RMSLE_1 = evaluate_model(pop_type_df_eg_end, cases_series_eg, all_pop)","4ea1213a":"def plot_exp(y_exp, title='SEIR+HCD model'):\n    sus, exp, inf, rec, hosp, crit, death = y_exp\n    sus = sus.sum(axis = 1) \n    exp = exp.sum(axis = 1) \n    inf = inf.sum(axis = 1) \n    rec = rec.sum(axis = 1) \n    hosp = hosp.sum(axis = 1) \n    crit = crit.sum(axis = 1) \n    death = death.sum(axis = 1) \n    \n    cases = inf + rec + hosp + crit + death\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n    fig.suptitle(title)\n    \n    ax1.plot(sus, 'tab:blue', label='Susceptible');\n    ax1.plot(exp, 'tab:orange', label='Exposed');\n    ax1.plot(inf, 'tab:red', label='Infected');\n    ax1.plot(rec, 'tab:green', label='Recovered');\n    ax1.plot(hosp, 'tab:purple', label='Hospitalised');\n    ax1.plot(crit, 'tab:brown', label='Critical');\n    ax1.plot(death, 'tab:cyan', label='Deceased');\n    \n    ax1.set_xlabel(\"Days\", fontsize=10);\n    ax1.set_ylabel(\"Fraction of population\", fontsize=10);\n    ax1.legend(loc='best');\n    ax1.xaxis.set_major_formatter(date_form)\n    \n    ax2.plot(cases, 'tab:red', label='Cases');    \n    ax2.set_xlabel(\"Days\", fontsize=10);\n    ax2.set_ylabel(\"Fraction of population (Cases)\", fontsize=10, color='tab:red');\n    \n    ax3 = ax2.twinx()\n    ax3.plot(death, 'tab:cyan', label='Deceased');    \n    ax3.set_xlabel(\"Days\", fontsize=10);\n    ax3.set_ylabel(\"Fraction of population (Fatalities)\", fontsize=10, color='tab:cyan');\n    ax2.xaxis.set_major_formatter(date_form)\n    \ndef fill_data(data, pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date):\n    new_dates = pd.date_range(pred_begin_date,pred_end_date)\n    if isinstance(data, pd.Series):\n        new_s = pd.Series(data.iloc[-1],index = new_dates)\n        data = pd.concat([data,new_s],axis = 0)\n    elif isinstance(data, pd.DataFrame):\n        new_df = pd.DataFrame(np.nan,index = new_dates,columns= data.columns)\n        new_df.iloc[0,:] = data.iloc[-1,:]\n        new_df.fillna(method = \"ffill\",inplace=True)\n        data = pd.concat([data,new_df],axis = 0)\n    else:\n        raise Error\n    return data\nfrom datetime import date\n\ndef run_sim(R0, n_inf, pop_exp, pct_young,pct_middle, title = 'SEIR+HCD model'):\n    I_ratio = n_inf\/pop_exp\n    S_ratio = 1- I_ratio\n    pop_type_exp = pd.DataFrame(index = pd.date_range(start_date,end_date), columns = pop_age_cols)\n    pop_type_exp.loc[start_date,:] = 0\n    col_num = pop_type_exp.shape[1]\n    pop_type_exp.loc[start_date,:] = np.array([S_ratio*pct_young,S_ratio*pct_middle,S_ratio*pct_old] + [0.] * 3 \\\n                                        + [I_ratio*pct_young,I_ratio*pct_middle,I_ratio*pct_old] + [0.]*(col_num-9))\n    y_exp = init_input(pop_type_exp,show=False)\n    R_exp = init_R(naive=True,default_R=R0,show = False,)\n    R_exp = fill_data(R_exp, pred_begin_date = train_end_date+oneday, pred_end_date = end_date)\n    date = start_date\n    while date < end_date:\n        y_exp = SEIR_HCD_model_age(date, y_exp, R_exp, param_dict)\n        date += oneday\n    plot_exp(y_exp, title=title)\nstart_date = date(2020,1,22)\nend_date = start_date + timedelta(days=100)\npop_exp = 1e5\nn_inf  = 1\npct_young = 0.2\npct_middle = 0.6\npct_old = 1-pct_young-pct_middle\nparam_dict\nR0 = 3.6\nrun_sim(R0, n_inf,pop_exp, pct_young, pct_middle, title = \"SEIR+HCD model, R0 = \" + str(R0))\nR0 = 7.2\nrun_sim(R0, n_inf,pop_exp, pct_young, pct_middle, title = \"SEIR+HCD model, R0 = \" + str(R0))","5284213f":"if isinstance(pop_type_df_eg, int):\n    print(area,\" no cases until now\")\nelse:    \n    R_s_eg = init_R(naive=False,c2 = c2,stringency_df = stringency_df,sensitivity = 0.8)\n    y_eg = init_input(pop_type_df_eg,param_dict)\n    pop_type_df_eg_end = run_model(first_case_date, y_eg, R_s_eg, param_dict)\n    plot_model(pop_type_df_eg_end, cases_series_eg, all_pop,R_s = R_s_eg, title='SEIR+HCD model with Reproduction Rate Modified')\n    MAE_2,RMSLE_2, target_MAE_2,target_RMSLE_2 = evaluate_model(pop_type_df_eg_end, cases_series_eg, all_pop)    ","a99bbb12":"print(\"Compared with model 1, model 2 performance:\")\nprint(\"MAE Improved: {:.2f} %\".format((target_MAE_1\/target_MAE_2-1)*100))\nprint(\"RMLSE Improved: {:.2f} %\".format((target_RMSLE_1\/target_RMSLE_2-1)*100))","18051a0f":"def eval_model(area = \"Afghanistan\", \n               naive_R = True,stringency_df = 0,default_R = default_R,sensitivity = 1, b = 1,\n               param_dict = param_dict,\n               title=\"No title provided\", plot=True, show = True):\n    c2 = area_code2_dict[area]\n    pop_type_df_eg, cases_series_eg, first_case_date,all_pop = init_pop(area = area,show = show)\n    \n    \n    if isinstance(pop_type_df_eg, int):\n        print(area,\" no cases until now\")\n        default_loss ={'case':0, 'death':0,'rec': 0}\n        MAE, RMSLE, target_MAE, target_RMSLE = default_loss, default_loss, 0 , 0\n    else:    \n        R_s_eg = init_R(naive=naive_R,c2 = c2,stringency_df = stringency_df,show = show, default_R = default_R, sensitivity = sensitivity, b = b)\n        y_eg = init_input(pop_type_df_eg, show = show)\n        pop_type_df_eg_end = run_model(first_case_date, y_eg, R_s_eg, param_dict)\n        if plot:\n            plot_model(pop_type_df_eg_end, cases_series_eg,all_pop, R_s_eg, title=title)\n        MAE, RMSLE, target_MAE, target_RMSLE = evaluate_model(pop_type_df_eg_end, cases_series_eg, all_pop, show = show)        \n    \n    return MAE, RMSLE, target_MAE, target_RMSLE","ba86766d":"selected_features_dict_vk = {v:k for k,v in selected_features_dict.items()}\nWDI_features_dict = {}\nfor col in area_feature_df.columns:\n    if col in selected_features_dict_vk:\n        WDI_features_dict[col] = selected_features_dict_vk[col]\n        continue","d3cc283a":"def get_area_basic_info(area):\n    c2 = area_code2_dict[area]\n    country = area_country_dict[area]\n    continent = area_feature_df[area_feature_df.area==area].loc[area,\"continent\"]\n    income_group = area_feature_df[area_feature_df.area==area].loc[area,\"Income Group\"]\n    density = area_feature_df[area_feature_df.area==area].loc[area,\"EN.POP.DNST\"]\n    \n    young, middle, old, pop = pop_df.loc[area,:]\n    print(f\"Area: {area}\\nCountry: {country}\\nContinent: {continent}\\nIncome Group: {income_group}\")\n    print(f\"Population: {pop}, Density: {density}\\nyoung:{np.round(young,2)}, middle:{np.round(middle,2)}, old:{np.round(old,2)}\\n\")\n    for k,v in WDI_features_dict.items():\n        val = area_feature_df[area_feature_df.area==area].loc[area,k]\n        print(v,\": \",val)","b9531926":"area = \"Turkey\"\nget_area_basic_info(area)\n\nshow = False\nMAE_1, RMSLE_1, target_MAE_1, target_RMSLE_1 = eval_model(area = area,naive_R=True, title = \"naive\",show = show)\nMAE_2, RMSLE_2, target_MAE_2, target_RMSLE_2= eval_model(area = area,naive_R=False, stringency_df = stringency_df, default_R=50,\n                                                          title = \"+ Stringency Score\", show = show)","0728415a":"print(area)\nprint(\"Compared with model 1, model 2 performance:\")\nprint(\"MAE Improved: {:.2f} %\".format((target_MAE_1\/target_MAE_2-1)*100))\nprint(\"RMLSE Improved: {:.2f} %\".format((target_RMSLE_1\/target_RMSLE_2-1)*100))","ba583e85":"def pick_best_param(x,\n                    area = \"Turkey\", \n                    naive_R = False,stringency_df = stringency_df,\n                    param_dict = param_dict,\n                    title=\"No title provided\", plot=False, show = False):\n    # we only paly with t_inc, t_inf, t_hosp, t_crit parameters\n    # as we have already used method to determine m,c,f and R_s_t.\n    #R0 = 3.6, sensitivity = 1, t_inc = 4, t_inf = 3, t_hosp = 4, t_crit = 14,\n    #print(x)\n    R0,b,t_inc,t_inf, t_hosp, t_crit = x\n    param_dict_picked = param_dict\n    sensitivity = 1\n    for age in [\"young\",\"middle\",\"old\"]:\n        param_dict_picked[\"t_inc\"][age] = t_inc\n        param_dict_picked[\"t_inf\"][age] = t_inf\n        param_dict_picked[\"t_hosp\"][age] = t_hosp\n        param_dict_picked[\"t_crit\"][age] = t_crit\n    #print(\"R0:\",R0)\n    # change default_param_dict -> test_param_dict\n    MAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n                                                naive_R = naive_R,stringency_df = stringency_df, default_R= R0 ,sensitivity = sensitivity,b=b,\n                                                param_dict = param_dict_picked,\n                                                title=title, plot=plot, show = show)\n    # choose the optimization target as target_RMSLE \n    return target_RMSLE\n\ndef fit_model(initial_guess = [3.6, 1, 3, 3, 5, 10], \n              bounds = [\n                  (2, 5),# R0\n                  (0.5,1), # b\n                  (1, 7), # t_inc\n                  (1, 5), # t_inf\n                  (3, 7),# t_hosp\n                  (7, 14),# t_crit\n              ],\n                area = \"Turkey\", \n                naive_R = False,\n                stringency_df = stringency_df,\n                param_dict = param_dict,\n                title=\"No title provided\",\n                plot=False,\n                show = False,\n):\n    # R_0....  T_inc, T_inf, T_hosp, T_critical\n    \n    args = (area, \n            naive_R, stringency_df, \n            param_dict, \n            title, plot, show)\n    special_func = lambda x : pick_best_param(x,*args)\n    print(\"Start Fitting \"+ area + \"....\")\n    res = minimize(special_func, \n                   x0 = initial_guess, bounds=bounds,\n                   method='L-BFGS-B')\n    # save it\n    #optimized_param = res.x\n    #optimized_param_dict = dict(zip([\"t_inc\",\"t_inf\",\"t_hosp\",\"t_crit\"],optimized_param))\n    #optimized_param_dict.update({\n    #    \"m\":0.8, \n    #    \"c\":0.1, \n    #    \"f\":0.3\n    #})\n    # rerun it\n    \n    R0,b,sensitivity,t_inc,t_inf, t_hosp, t_crit =  res.x\n    param_dict_picked = param_dict\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        param_dict_picked[\"t_inc\"][age] = t_inc\n        param_dict_picked[\"t_inf\"][age] = t_inf\n        param_dict_picked[\"t_hosp\"][age] = t_hosp\n        param_dict_picked[\"t_crit\"][age] = t_crit\n    \n    MAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n               naive_R = naive_R, stringency_df = stringency_df, default_R = R0, sensitivity = sensitivity,b = b,\n               param_dict = param_dict_picked,\n               title= \"Fitted Model for \" + area, plot = True, show = False)\n    return R0,b,sensitivity,t_inc, t_inf, t_hosp, t_crit, MAE, RMSLE","4638b0cb":"def show_param(area, R0, b,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE):\n    print(area)\n    print(\"R0 {:.2f}, b {:.2f}, sensitivity {:.2f}, t_inc {:.2f}, t_inf {:.2f}, t_hosp {:.2f}, t_crit {:.2f}\".format(R0, b, sensitivity,\n                                                                                                                     t_inc, t_inf, t_hosp, t_crit))\n    print(\"Case RMSLE {:.3f}, Death RMSLE {:.3f}\".format(RMSLE[\"case\"],RMSLE[\"death\"]))\n    print(\"Reach score {:.3f}\".format((RMSLE[\"case\"]+RMSLE[\"death\"])\/2))","f27521a3":"top_worst_10 =['Nepal', 'Thailand', 'Turkey', 'United Arab Emirates',\n       'British Columbia', 'Michigan', 'Louisiana', 'Cambodia', 'Panama',\n       'Finland']\narea_feature_df.loc[:,\"fitted_R0\"] = np.nan\narea_feature_df.loc[:,\"fitted_b\"] = np.nan\narea_feature_df.loc[:,\"fitted_sensitivity\"] = np.nan\narea_feature_df.loc[:,\"fitted_t_inc\"] = np.nan\narea_feature_df.loc[:,\"fitted_t_inf\"] = np.nan\narea_feature_df.loc[:,\"fitted_t_crit\"] = np.nan\narea_feature_df.loc[:,\"fitted_t_hosp\"] = np.nan\narea_feature_df.loc[:,\"fitted_case_RMSLE\"] = np.nan\narea_feature_df.loc[:,\"fitted_death_RMSLE\"] = np.nan\nsensitivity = 1\ncount = 0\nbefore_area_has_finished  = \"Prince Edward Island\"\nstart = True\nfor area in  area_feature_df.index:# remember to change\n    if not start:\n        if area == before_area_has_finished:\n            start = True\n        count += 1\n        continue\n    t0 = time()\n    R0, b,sensitivity, t_inc,t_inf,t_hosp,t_crit,MAE, RMSLE = fit_model(area = area)\n    area_feature_df.loc[area,\"fitted_R0\"] = R0\n    area_feature_df.loc[area,\"fitted_b\"] = b\n    area_feature_df.loc[area,\"fitted_sensitivity\"] = sensitivity\n    area_feature_df.loc[area,\"fitted_t_inc\"] = t_inc\n    area_feature_df.loc[area,\"fitted_t_inf\"] = t_inf\n    area_feature_df.loc[area,\"fitted_t_hosp\"] = t_hosp\n    area_feature_df.loc[area,\"fitted_t_crit\"] = t_crit\n    area_feature_df.loc[area,\"fitted_case_RMSLE\"] = RMSLE[\"case\"]\n    area_feature_df.loc[area,\"fitted_death_RMSLE\"] = RMSLE[\"death\"]\n    show_param(area, R0,b,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE)\n    t1 = time()\n    print(np.round((t1-t0)\/60,2),\" minutes\")\n    count += 1\n    if count % 20 == 0:\n        print(np.round(count\/area_feature_df.shape[0] * 100,1), \"% finished\")","f289312b":"# test\narea = \"Nepal\"\nR0 = 2\nb = 1\nsensitivity = 1\nt_inc = 10\nt_inf = 3\nt_hosp = 7\nt_crit = 14\nparam_dict_picked = param_dict\n\nfor age in [\"young\",\"middle\",\"old\"]:\n    param_dict_picked[\"t_inc\"][age] = t_inc\n    param_dict_picked[\"t_inf\"][age] = t_inf\n    param_dict_picked[\"t_hosp\"][age] = t_hosp\n    param_dict_picked[\"t_crit\"][age] = t_crit\n\nMAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n           naive_R = False, stringency_df = stringency_df, default_R = R0, sensitivity = sensitivity, b = b,\n           param_dict = param_dict_picked,\n           title= \"Fitted Model for \" + area, plot = True, show = False)\nshow_param(area, R0, b,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE)","4ef8f029":"area_feature_df.to_csv(\"feature.csv\")","6dc8675a":"area_feature_df.shape[0]","66711cda":"area_feature_df.shape[0] - area_feature_df[\"fitted_R0\"].isna().sum()","52a0297e":"fitted_cols = [\"fitted_R0\",\"fitted_b\",\"fitted_sensitivity\",\"fitted_t_inc\",\"fitted_t_inf\",\"fitted_t_hosp\",\"fitted_t_crit\",\"fitted_case_RMSLE\",\"fitted_death_RMSLE\"]\narea_feature_df.loc[:,fitted_cols].describe()","57d646b4":"stringency_cols_refined = [col for col in stringency_cols if (\"01-22\" not in col and \"04-10\" not in col)]\ncorr_cols = []\nfor col in area_feature_df:\n    if col in stringency_cols_refined:\n        continue\n    corr_cols.append(col)\ncorr_df = area_feature_df[corr_cols].copy()\ncorr_df.shape\ncorr = corr_df.corr().sort_values(\"fitted_case_RMSLE\").T\ncorr_df = area_feature_df[corr.columns].copy()\ncorr = corr_df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)\n# 'RdBu_r' & 'BrBG' are other good diverging colorm   SH.XPD.CHEX.GD.ZS","b4b22512":"# train_end_date+oneday != test_begin_date\ndef fill_data(data, pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date):\n    new_dates = pd.date_range(pred_begin_date,pred_end_date)\n    if isinstance(data, pd.Series):\n        new_s = pd.Series(data.iloc[-1],index = new_dates)\n        data = pd.concat([data,new_s],axis = 0)\n    elif isinstance(data, pd.DataFrame):\n        new_df = pd.DataFrame(np.nan,index = new_dates,columns= data.columns)\n        new_df.iloc[0,:] = data.iloc[-1,:]\n        new_df.fillna(method = \"ffill\",inplace=True)\n        data = pd.concat([data,new_df],axis = 0)\n    else:\n        raise Error\n    return data\n\ndef init_R_pred(naive=True, c2=\"AF\", stringency_df = 0, show = True, default_R = default_R, sensitivity = 1,b = 1,\n                pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date):\n    if show:\n        if naive:\n            print(f\"Inititialize Reproduction Rate as {default_R}, Naively\")\n        else:\n            print(\"Initialize Reproduction Rate according to Stringency Score\")\n    R_s_eg = R_s.copy()\n    R_s_eg.fillna(default_R,inplace=True)\n    R_s_eg = fill_data(R_s_eg, pred_begin_date = pred_begin_date, pred_end_date = pred_end_date)\n    new_dates = pd.date_range(pred_begin_date,pred_end_date)\n    const = np.exp(-np.log(2)\/30) # account for the shape of Stringency Score\n    if not naive:\n        assert not isinstance(stringency_df,int)\n        stringency_score_eg = stringency_df.loc[idx[c2,:],\"stringency\"]\n        stringency_score_eg.index = stringency_score_eg.index.droplevel(0) \n        stringency_score_eg = fill_data(stringency_score_eg, pred_begin_date = pred_begin_date, pred_end_date = pred_end_date)\n        stringency_score_eg \/= 100\n        for date in new_dates:\n            stringency_score_eg.loc[date] = 1 - (1 - stringency_score_eg.loc[date-oneday])*const        \n        # add sensitivity to measure how people tend to react to the policy (0~3)\n        stringency_multiplier = 1 - stringency_score_eg ** sensitivity * b\n        R_s_eg  = R_s_eg * stringency_multiplier\n    return R_s_eg\n    \ndef get_predict_pop_type(area,all_pop, pop_type_df_eg_end, adjust = True):               \n    pop_type_df_end_pop = pop_type_df_eg_end.sum(axis =1 ,level = 0) * all_pop\n    pop_type_df_end_pop = pop_type_df_end_pop.loc[test_begin_date: test_end_date]    \n    \n    sus = pop_type_df_end_pop[\"S\"]\n    exp = pop_type_df_end_pop[\"E\"]\n    inf = pop_type_df_end_pop[\"I\"]\n    rec = pop_type_df_end_pop[\"R\"]\n    hosp = pop_type_df_end_pop[\"H\"]\n    crit = pop_type_df_end_pop[\"C\"]\n    death  = pop_type_df_end_pop[\"D\"]\n    cases = inf + rec + hosp + crit + death\n    \n    # adjust cases and death according to the last day value of the training data\n    last_case = train_full_df.loc[idx[area,train_end_date],\"ConfirmedCases\"]\n    last_death = train_full_df.loc[idx[area,train_end_date],\"Fatalities\"]\n    if adjust:\n        if last_case != 0 and cases.loc[train_end_date] != 0 :\n            cases *= last_case\/cases.loc[train_end_date]\n        if last_death != 0 and death.loc[train_end_date] != 0 :\n            death *= last_death\/death.loc[train_end_date]     \n    output = pd.concat([cases,death],axis = 1)\n    output.reset_index(inplace=True)\n    output.columns = [\"Date\",\"ConfirmedCases\",\"Fatalities\"]    \n    output[\"Area\"] = area\n    return output\n\ndef predict(area = \"Afghanistan\", pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date,\n            naive_R = False, stringency_df = stringency_df, default_R = default_R,\n            param_dict = param_dict,\n            show = False,\n            adjust = False\n            ):\n    # adjust is to adjust the last case to match with the actual data\n    \n    c2 = area_code2_dict[area]\n    pop_type_df_eg, cases_series_eg, first_case_date, all_pop = init_pop(area = area,show = show)\n    pop_type_df_eg = fill_data(pop_type_df_eg, pred_begin_date, pred_end_date)\n    cases_series_eg = fill_data(cases_series_eg, pred_begin_date, pred_end_date)\n    \n    fitted_R0 = area_feature_df.loc[area,\"fitted_R0\"]\n    fitted_b = area_feature_df.loc[area,\"fitted_b\"]\n    fitted_sensitivity = area_feature_df.loc[area,\"fitted_sensitivity\"]\n    fitted_t_inc =  area_feature_df.loc[area,\"fitted_t_inc\"]\n    fitted_t_inf =  area_feature_df.loc[area,\"fitted_t_inf\"]\n    fitted_t_hosp =  area_feature_df.loc[area,\"fitted_t_hosp\"]\n    fitted_t_crit =  area_feature_df.loc[area,\"fitted_t_crit\"]\n    if np.isnan(fitted_R0):\n        print(f\"Area {area}'s fitted value is nan\")\n        fitted_R0 = 3.6\n        fitted_b = 1\n        fitted_sensitivity = 1\n        fitted_t_inc = 3\n        fitted_t_inf = 2\n        fitted_t_hosp = 4\n        fitted_t_crit = 12\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        param_dict[\"t_inc\"][age] = fitted_t_inc\n        param_dict[\"t_inf\"][age] = fitted_t_inf\n        param_dict[\"t_hosp\"][age] = fitted_t_hosp\n        param_dict[\"t_crit\"][age] = fitted_t_crit\n\n    \n    if isinstance(pop_type_df_eg, int):\n        print(area,\" no cases until now\")\n        default_loss ={'case':0, 'death':0,'rec': 0}\n    else:    \n        R_s_eg = init_R_pred(naive=naive_R, c2=c2, stringency_df=stringency_df, show = show, \n                            default_R = fitted_R0, sensitivity= fitted_sensitivity, b = fitted_b,\n                            pred_begin_date = pred_begin_date, pred_end_date = pred_end_date)\n        y_eg = init_input(pop_type_df_eg, show = show)\n        pop_type_df_eg_end = run_model(first_case_date, y_eg, R_s_eg, param_dict, end_date = test_end_date)\n        output = get_predict_pop_type(area ,all_pop, pop_type_df_eg_end,adjust = adjust)\n    return output","62ffc3a2":"outputs = pd.DataFrame(columns = [\"Date\",\"Area\",\"ConfirmedCases\",\"Fatalities\"])","79a4f399":"before_area_has_finished  = \"Botswana\"\nstart = True\ncount = 0\nfor area in  area_feature_df.index:\n    if not start:\n        if area == before_area_has_finished:\n            start = True\n        count += 1\n        continue\n    print(area)\n    out = predict(area = area, show = False,adjust = False)\n    outputs = pd.concat([outputs, out],axis = 0, sort =True)        \n    count += 1\n    if count % 20 == 0:\n        print(np.round(count\/area_feature_df.shape[0] * 100,1), \"% finished\")","4fb16dea":"def naive_fill(area, pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date,\n                          show = False):\n    _, cases_series_eg, _, _ = init_pop(area = area,show = show)\n    cases_series_eg = cases_series_eg\n    #before_part = train_full_df.loc[idx[\"Diamond Princess\",test_begin_date:],[\"ConfirmedCases\",\"Fatalities\"]]\n    #cases_series_eg = pd.concat([before_part,cases_series_eg],axis = 0)\n    \n    cases_series_eg.sort_index(level=[0,1],inplace=True)\n    cases_series_eg.reset_index(level=0,drop = True,inplace=True)\n    cases_series_eg = fill_data(cases_series_eg, pred_begin_date, pred_end_date)\n    cases_series_eg = cases_series_eg.loc[test_begin_date:pred_end_date]\n    cases_series_eg.reset_index(inplace=True)\n    cases_series_eg = cases_series_eg.loc[:,[\"index\",\"ConfirmedCases\",\"Fatalities\"]].copy()\n    cases_series_eg.columns = [\"Date\",\"ConfirmedCases\",\"Fatalities\"]    \n    cases_series_eg[\"Area\"] = area\n    return cases_series_eg\n\ndef predict_special_areas(area, pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date,\n                          show = False):    \n    if area in special_areas:\n        cases_series_eg = naive_fill(area, pred_begin_date = pred_begin_date, pred_end_date = pred_end_date,\n                          show = False)\n        return cases_series_eg\n    else:\n        raise KeyError(area)","86fa08d9":"outputs_special = pd.DataFrame(columns = [\"Date\",\"Area\",\"ConfirmedCases\",\"Fatalities\"])","6995618c":"for area in special_areas_feature.index:\n    print(area)\n    out = predict_special_areas(area = area)\n    outputs_special = pd.concat([outputs_special, out],axis = 0,sort=False)        \noutputs_special","bf4d7279":"outputs_all = pd.concat([outputs,outputs_special],axis = 0,sort=False)\noutputs_all","f0bd4688":"test_df = test_df.merge(outputs_all,on=[\"Date\",\"Area\"],how = \"left\")\ntest_df","65053141":"sub_df2 = test_df.loc[:,[\"ForecastId\",\"ConfirmedCases\",\"Fatalities\"]].copy()\nsub_df2.fillna(0,inplace=True)","c3145773":"sub_df.shape == sub_df2.shape","deb1664b":"sub_df2.isna().sum()","d6013c53":"sub_df2.to_csv(\"submission.csv\",index=False)","673877ca":"def pick_best_param_exp(x,\n                    area = \"Turkey\", \n                    naive_R = False,stringency_df = stringency_df,\n                    param_dict = param_dict,\n                    title=\"No title provided\", plot=False, show = False):\n    # we only paly with t_inc, t_inf, t_hosp, t_crit parameters\n    # as we have already used method to determine m,c,f and R_s_t.\n    #R0 = 3.6, sensitivity = 1, t_inc = 4, t_inf = 3, t_hosp = 4, t_crit = 14,\n    #print(x)\n    R0, sensitivity, t_inc, t_inf,t_hosp, t_crit = x\n    param_dict_picked = param_dict\n    for age in [\"young\",\"middle\",\"old\"]:\n        param_dict_picked[\"t_inc\"][age] = t_inc\n        param_dict_picked[\"t_inf\"][age] = t_inf\n        param_dict_picked[\"t_hosp\"][age] = t_hosp\n        param_dict_picked[\"t_crit\"][age] = t_crit\n    #print(\"R0:\",R0)\n    # change default_param_dict -> test_param_dict\n    MAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n                                                naive_R = naive_R,stringency_df = stringency_df, default_R= R0 ,sensitivity = sensitivity,\n                                                param_dict = param_dict_picked,\n                                                title=title, plot=plot, show = show)\n    # choose the optimization target as target_RMSLE \n    return target_RMSLE\n\ndef fit_model_exp(initial_guess = [3.6, 1, 3, 3, 4, 12], \n              bounds = [\n                  (2, 5),# R0\n                  (0.8,1.2), # sensitivity\n                  (1, 7), # t_inc\n                  (1, 5), # t_inf\n                  (3, 10),# t_hosp\n                  (7, 14),# t_crit\n              ],\n                area = \"Turkey\", \n                naive_R = False,\n                stringency_df = stringency_df,\n                param_dict = param_dict,\n                title=\"No title provided\",\n                plot=False,\n                show = False,\n):\n    # R_0....  T_inc, T_inf, T_hosp, T_critical\n    \n    args = (area, \n            naive_R, stringency_df, \n            param_dict, \n            title, plot, show)\n    special_func = lambda x : pick_best_param_exp(x,*args)\n    print(\"Start Fitting \"+ area + \"....\")\n    res = minimize(special_func, \n                   x0 = initial_guess, bounds=bounds,\n                   method='L-BFGS-B')\n    # save it\n    #optimized_param = res.x\n    #optimized_param_dict = dict(zip([\"t_inc\",\"t_inf\",\"t_hosp\",\"t_crit\"],optimized_param))\n    #optimized_param_dict.update({\n    #    \"m\":0.8, \n    #    \"c\":0.1, \n    #    \"f\":0.3\n    #})\n    # rerun it\n    \n    R0, sensitivity, t_inc, t_inf, t_hosp, t_crit = res.x\n    param_dict_picked = param_dict\n    \n    for age in [\"young\",\"middle\",\"old\"]:\n        param_dict_picked[\"t_inc\"][age] = t_inc\n        param_dict_picked[\"t_inf\"][age] = t_inf\n        param_dict_picked[\"t_hosp\"][age] = t_hosp\n        param_dict_picked[\"t_crit\"][age] = t_crit\n    \n    MAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n               naive_R = naive_R, stringency_df = stringency_df, default_R = R0, sensitivity = sensitivity,\n               param_dict = param_dict_picked,\n               title= \"Fitted Model for \" + area, plot = True, show = False)\n    return R0,sensitivity,t_inc, t_inf, t_hosp, t_crit, MAE, RMSLE","bdac835a":"area = \"Finland\"\nR0,sensitivity, t_inc, t_inf, t_hosp, t_crit,MAE, RMSLE  = fit_model_exp(area = area)","a6db4986":"area = \"Thailand\"\nR0,sensitivity, t_inc, t_inf, t_hosp, t_crit,MAE, RMSLE  = fit_model_exp(area = area)\nshow_param(area, R0,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE)","13043d2f":"area = \"Nepal\"\nt0 = time()\nR0,sensitivity, t_inc, t_inf, t_hosp, t_crit,MAE, RMSLE  = fit_model_exp(area = area)\nt1 = time()\nprint((t1-t0)\/60,\" minutes\")","0fbf764f":"area = \"Turkey\"\nt0 = time()\nR0,sensitivity, t_inc, t_inf, t_hosp, t_crit,MAE, RMSLE  = fit_model_exp(area = area)\nt1 = time()\nprint((t1-t0)\/60,\" minutes\")\nshow_param(area, R0,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE)","8b59c8b6":"area = \"Michigan\"\nt0 = time()\nR0,sensitivity, t_inc, t_inf, t_hosp, t_crit,MAE, RMSLE  = fit_model_exp(area = area)\nt1 = time()\nprint((t1-t0)\/60,\" minutes\")\nshow_param(area, R0,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE)","f6f6165e":"area = \"Panama\"\nt0 = time()\nR0,sensitivity, t_inc, t_inf, t_hosp, t_crit,MAE, RMSLE  = fit_model_exp(area = area)\nt1 = time()\nprint((t1-t0)\/60,\" minutes\")\nshow_param(area, R0,sensitivity, t_inc, t_inf, t_hosp, t_crit, RMSLE)","8e7d7e73":"area = \"Panama\"\nR0 = 5\nsensitivity = 1.2\nt_inc = 1\nt_inf = 1\nt_hosp = 3\nt_crit = 7\nparam_dict_picked = param_dict\n\nfor age in [\"young\",\"middle\",\"old\"]:\n    param_dict_picked[\"t_inc\"][age] = t_inc\n    param_dict_picked[\"t_inf\"][age] = t_inf\n    param_dict_picked[\"t_hosp\"][age] = t_hosp\n    param_dict_picked[\"t_crit\"][age] = t_crit\n\nMAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n           naive_R = False, stringency_df = stringency_df, default_R = R0, sensitivity = sensitivity,\n           param_dict = param_dict_picked,\n           title= \"Fitted Model for \" + area, plot = True, show = False)","01f85816":"area = \"Panama\"\nR0 = 5\nsensitivity = 0.8\nt_inc = 1\nt_inf = 1\nt_hosp = 3\nt_crit = 7\nparam_dict_picked = param_dict\n\nfor age in [\"young\",\"middle\",\"old\"]:\n    param_dict_picked[\"t_inc\"][age] = t_inc\n    param_dict_picked[\"t_inf\"][age] = t_inf\n    param_dict_picked[\"t_hosp\"][age] = t_hosp\n    param_dict_picked[\"t_crit\"][age] = t_crit\n\nMAE, RMSLE, target_MAE, target_RMSLE = eval_model(area = area, \n           naive_R = False, stringency_df = stringency_df, default_R = R0, sensitivity = sensitivity,\n           param_dict = param_dict_picked,\n           title= \"Fitted Model for \" + area, plot = True, show = False)","f3cf96f0":"stringency_df.loc[]","75822f0f":"# SEIR-HCD Model\nThis is a working example of a [SEIR](https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology#The_SEIR_model) model with added compartments for HCD. The letters stand for:\n* S: Susceptible\n* E: Exposed\n* I: Infected\n* R: Recovered\n* H: Hospitalized (Severe)\n* C: Critical in (ICU). O is \"critical not in ICU\/overflow\" \n* D: Death , Fatalities","5aeb1774":"## Parameters used in the model\n`R_t` = reproduction number at time t.The number of secondary infections each infected individual produces. Typical 3.6* at t=0\n\n**Transition times**\n* `T_inc` = average incubation period. Exposed individuals progress to a symptomatic\/infectious state after an average latency. Typical 5.6* days\n* `T_inf` = average infectious period. Duration patient is infectious. Typical 2.9 days\n* `T_hosp` = average time a patient is in hospital before either recovering or becoming critical. Typical 4 days\n* `T_crit` = average time a patient is in a critical state (either recover or die). Typical 14 days\n\n**Fractions**\nThese constants are likely to be age specific (hence the subscript a):\n* `m_a` = fraction of infections that are asymptomatic or mild. Assumed 80% (i.e. 20% severe)\n* `c_a` = fraction of severe cases that turn critical. Assumed 10%\n* `f_a` = fraction of critical cases that are fatal. Assumed 30%\n\n*Averages taken from https:\/\/www.kaggle.com\/covid-19-contributions","996af3cb":"## Fill Some Missing Value of area_feature_df\n1. Income Group\n2. Demographic ( no need to)\n3. Stringency Score","d4895ac1":"## add demographic data","5b3aee38":"area_feature_df[[\"case_RMSLE\",\"death_RMSLE\"]].describe()","4d47f884":"## Submission\n1. Using all train data to fit and pick out the right parameter\n2. Extend the end date to test_end_date.","3c8d9772":"if plot:\n    #Create a pair grid instance\n    grid = sns.PairGrid(data = area_feature_df[RMSLE_l + pos_corr_4].copy(),height = 4)\n\n    #Map the plots to the locations\n    grid = grid.map_upper(plt.scatter, color = 'darkred')\n    grid = grid.map_upper(corr)\n    grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n    grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');\n    plt.title(\"Visualization of variable positively correlated with RMSLE\")","984cc42b":"# Find the reason why prediction fail\n- Use the RMSLE score of each area's prediction and correlates it with other features.","082850ec":"area = \"Andorra\"\npop_type_df_eg_exp,_,_,_ = init_pop(area = area,show = show)\n\n#area = \"Afghanistan\"\n#pop_type_df_eg_exp,_,_,_ = init_pop(area = area,show = show)\npop_type_df_eg_exp","03f0eec1":"Following equations are from these great web apps: \n* http:\/\/gabgoh.github.io\/COVID\/index.html\n* https:\/\/covid19-scenarios.org\/","8ab8068a":"## Data Initialization (Change Data into the format we need)","f6024ee3":"# Naive Example: Model without Intervention\n- $R_t$ is the same regardless of stringency of country\n- All parameters are the same for each age group\n- No interaction between each step","46c11ae0":"# Find the right paramter\n1. Adjusting $R_0$ using stringency score, fixing m,c,f.  t_inc(5.2), t_inf(2.9), t_hosp(4), t_crit(14)\/\n2. Get each different areas $R_0$ score and try to find the pattern","dc268a99":"print(area)\narea = \"Andorra\"\npop_type_df_eg_exp,_,_,_ = init_pop(area = area,show = show)\narea_feature_df.loc[area,\"fitted_R0\"]\nc2 = area_code2_dict[area]\nR_s_exp = init_R_pred(naive=False, c2=c2, stringency_df=stringency_df, show = show, \n                            default_R = 3.6, sensitivity= 1,\n                            pred_begin_date = train_end_date+oneday, pred_end_date = test_end_date)\ny_eg_exp = init_input(pop_type_df_eg_exp, show = show)\ny_eg_exp","bc937cd2":"if plot:\n    #plot the remaining variables\n    \n    #Create a pair grid instance\n    grid = sns.PairGrid(data = area_feature_df[[ col for col in corr_cols_2 if \\\n                                                (col not in (pos_corr_4+neg_corr_4) and (col in WDI_features_dict) or col in RMSLE_l)]].copy(),height = 4)\n\n    #Map the plots to the locations\n    grid = grid.map_upper(plt.scatter, color = 'darkred')\n    grid = grid.map_upper(corr)\n    grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n    grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred')","791e4e68":"# Check Area with non-zero case in the beginning","853aed23":"corr = corr_df.corr().sort_values(\"case_RMSLE\").T\ncols = corr.index\ncorr = corr_df[cols].corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","721aaa7b":"## Create area_feature_df","476da03d":"We can see from the model, predicted value is much larger than real value. The most direct way is to decrease the __reproduction rate__.","6ce11773":"## Add Stringency Score\n- Goverment Response and lockdown data\n- Government Response Data from Oxford Data: \n    - https:\/\/www.bsg.ox.ac.uk\/research\/research-projects\/oxford-covid-19-government-response-tracker\n    - white paper: https:\/\/www.bsg.ox.ac.uk\/sites\/default\/files\/2020-03\/BSG-WP-2020-031-v3.0.pdf","aaefc5b1":"corr_cols_2 = [col for col in corr_cols if col not in del_hi_corr_var_l]","afc77083":"# Experiment","743f600c":"### Finding 2\n1. the evaluate metric will let the model tend to fit the begining well but bad in the long run\n2. especially when the COVID19 is controlled in some country, like China. The predicted curve still tend to go up and show no signs of slow down.\n3. The death curve usually perform badly.","89d19483":"## Special Fit\n- just some test","210b53ca":"for col in neg_corr_4 + pos_corr_4:\n    if col in del_hi_corr_var_l:\n        print(col)","f666f33c":"area_feature_df.sort_values(\"case_RMSLE\")","13209e37":"# Country Specific Feature\n- Population\n- Age Distribution\n- Stringency Score\n- World Development Index Data","1cc04b92":"## Analyze the correlation of RMSLE and other feature ","e330fd49":"def corr(x, y, **kwargs):\n    #Calculate the value\n    coef = np.corrcoef(x, y)[0][1]\n    #Make the label\n    label = r'$\\rho$ = ' + str(round(coef, 2))\n    #Add the label to the plot\n    ax = plt.gca()\n    ax.annotate(label, xy = (0.2, 0.95), xycoords = ax.transAxes)\n    \nplot = False\nif plot:\n    #Create a pair grid instance\n    grid = sns.PairGrid(data = area_feature_df[RMSLE_l + neg_corr_4].copy(),height = 4)\n\n    #Map the plots to the locations\n    grid = grid.map_upper(plt.scatter, color = 'darkred')\n    grid = grid.map_upper(corr)\n    grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n    grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');","81a88c18":"# Upgrade: Model with Intervention\n- __Assumption 1__ -  about Reproduction Rate:\n    - $R_0$ depends on the density of country and how much attention people usually put to health. Using World Development Index.\n    - $R_t$ can be modeled in a __Transmission Reduction__ way:  Several studies attempt to estimate the effect of different aspects of social distancing and infection control on the rate of transmission. A report by Wang et al estimates a step-wise reduction of $R_0$ from above three to around 1 and then to around 0.3 due to successive measures implemented in Wuhan. This study investigates the effect of school closures on influenza transmission.\n    - We can model the reduction use Stringency Score from Oxford.\n- We first implement the __Transmission Reduction__","6f9a48a7":"# SEIR & HCD with age distribution Model for COVID19 Global forecast\nSEIR MODEL Reference:\n\nMany thanks for @datasaurus great Kernel : https:\/\/www.kaggle.com\/anjum48\/seir-model-with-intervention\n\nBased on his kernel, we add age distribution to the model for more accurate estimation. Also, we add stringency score to reflect how the reproduction rate will change.","37f43a98":"RMSLE_l = [\"case_RMSLE\",\"death_RMSLE\"]\nneg_corr_4 = [\"SN.ITK.DEFC.ZS\",\"SH.DTH.COMM.ZS\",\"young\",\"SH.STA.WASH.P5\"]  \npos_corr_4 = [\"SH.XPD.GHED.GE.ZS\",'NY.ADJ.NNTY.PC.CD',\"SH.STA.BASS.ZS\",\"EG.ELC.ACCS.ZS\"]\nprint(\"Negatively Correlated with RMSLE\")\nfor neg in neg_corr_4:\n    if neg in WDI_features_dict:\n        print(neg,\":\",WDI_features_dict[neg])\n    else:\n        print(neg)\nprint()\nprint(\"Positively Correlated with RMSLE\")\nfor pos in pos_corr_4:\n    if pos in WDI_features_dict:\n        print(pos,\":\",WDI_features_dict[pos]) \n    else:\n        print(pos)","8e1bae27":"## Add World Development Index Data","95aad9fe":"area_feature_df.loc[:,\"case_RMSLE\"] = np.nan\narea_feature_df.loc[:,\"death_RMSLE\"] = np.nan\ncount = 0\nfor area in  area_feature_df.index:\n    print(area)\n    _, RMSLE_eg,_,_ = eval_model(area = area,\n                                 naive_R=False, stringency_df = stringency_df, default_R=3.6,\n                                 title = \"+ Stringency Score\", show = False,plot = False)\n    area_feature_df.loc[area,\"case_RMSLE\"] = RMSLE_eg[\"case\"]\n    area_feature_df.loc[area,\"death_RMSLE\"] = RMSLE_eg[\"death\"]\n    print(RMSLE_eg)\n    count += 1\n    if count % 20 == 0:\n        print(np.round(count\/area_feature_df.shape[0] * 100,1), \"% finished\")","725d4e63":"corr_cols = []\nfor col in area_feature_df:\n    if col not in stringency_cols:\n        corr_cols.append(col)\ncorr_df = area_feature_df[corr_cols].copy()\ncorr_df.shape","37d61f27":"## Finding 1\n1.   From the correlation matrix, we can see that some variable are highly correlated, like GDP and GNP data, which we can delete. Also, Health expenditure data are also highly correlated, for this case, we keep the one with highest correlation with RMSLE, especially death RMSLE (0.4), SH.XPD.GHED.GE.ZS, which is Domestic general government health expenditure (% of general government expenditure). We apply the same method to variables that negatively correlated with score\n2. From the first negative correlation pair plot we can see that the model tends to __perform well in country with country with high pct of young people, and country without enough access to sanitation infrastructure__.\n3. From the second positive correlation pair plot we can see that the model still tend to perform well in poor country","13102ac5":"# Transform and Load Data"}}