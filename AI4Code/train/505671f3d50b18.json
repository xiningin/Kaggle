{"cell_type":{"896ecb10":"code","2d23f4d2":"code","472e5bdb":"code","4a67aa36":"code","a8bd109c":"code","d0e9401d":"code","c35ea9c0":"code","3dd4014a":"code","1b7bd654":"code","84680ddc":"code","edc3348c":"code","08b51646":"code","1025b6cb":"code","72a4a9d7":"code","afb3392c":"code","a6d2dd2d":"code","dc4ed154":"code","066b8bae":"code","3737866c":"code","a4bfc45a":"code","4b4ec93d":"code","fb3325d1":"code","3a9cc011":"markdown","642efc02":"markdown","685375eb":"markdown","b425c556":"markdown","d8d26cda":"markdown","993fb0ba":"markdown","71de1523":"markdown","8fe5fabf":"markdown","d1fdb570":"markdown"},"source":{"896ecb10":"!git clone https:\/\/github.com\/tensorflow\/datasets.git\n%cd datasets","2d23f4d2":"!pip install -e.","472e5bdb":"%cd datasets\n!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=oxford_iiit_pet","4a67aa36":"# TODO: Make all necessary imports.\nimport warnings\nwarnings.filterwarnings('ignore')\n%pip --no-cache-dir install tfds-nightly","a8bd109c":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()","d0e9401d":"print('TensorFlow version:', tf.__version__)\nprint('tf.keras version:', tf.keras.__version__)\nprint('Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')","c35ea9c0":"# TODO: Load the dataset with TensorFlow Datasets.\n# https:\/\/www.tensorflow.org\/datasets\/api_docs\/python\/tfds\/load\n'''tfds.load(\n    name, split=None, data_dir=None, batch_size=None, shuffle_files=False,\n    download=True, as_supervised=False, decoders=None, read_config=None,\n    with_info=False, builder_kwargs=None, download_and_prepare_kwargs=None,\n    as_dataset_kwargs=None, try_gcs=False\n)\n'''\ndataset, dataset_info =  tfds.load('oxford_flowers102', as_supervised = True, with_info = True)\n\n# TODO: Create a training set, a validation set and a test set.\ntrain_set = dataset[\"train\"]\ntest_set = dataset[\"test\"]\nval_set = dataset[\"validation\"]","3dd4014a":"# TODO: Get the number of examples in each set from the dataset info.\nnum_train_examples = dataset_info.splits['train'].num_examples\nnum_val_examples = dataset_info.splits['validation'].num_examples\nnum_test_examples = dataset_info.splits['test'].num_examples\n\nprint('There are {:,} images in the training set'.format(num_train_examples))\nprint('There are {:,} images in the validation set'.format(num_val_examples))\nprint('There are {:,} images in the test set'.format(num_test_examples))\n\n# TODO: Get the number of classes in the dataset from the dataset info.\nnum_classes = dataset_info.features['label'].num_classes\n\nprint('There are {:,} number of classes'.format(num_classes))","1b7bd654":"# TODO: Print the shape and corresponding label of 3 images in the training set.\nfor image, label in train_set.take(3):\n    image = image.numpy()\n    label = label.numpy()\n\n    print('The shape of this image is:', image.shape)\n    print('The label of this image is:', label)","84680ddc":"# TODO: Plot 1 image from the training set. Set the title \n# of the plot to the corresponding image label. \nfor image, label in train_set.take(1):\n    image = image.numpy()\n    label = label.numpy()\n    \n    flower_label = label\n    plt.imshow(image)\n    plt.suptitle(flower_label, fontsize=20)\n    plt.show()","edc3348c":"import json\nwith open('\/kaggle\/input\/josnfile\/label_map.json', 'r') as f:\n    class_names = json.load(f)\nclass_names","08b51646":"# TODO: Plot 1 image from the training set. Set the title \n# of the plot to the corresponding class name. \nfor image, label in train_set.take(1):\n    image = image.numpy()\n    label = label.numpy()\n    \n    flower_label = class_names[str(label)]\n    plt.imshow(image)\n    plt.suptitle(flower_label, fontsize=20)\n    plt.show()","1025b6cb":"# TODO: Create a pipeline for each set.\nbatch_size = 32\nimage_size = 224\n\ndef format_image(image, label):\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, (image_size, image_size))\n    image \/= 255\n    return image, label\n\ntrain_batches = train_set.shuffle(num_train_examples\/\/4).map(format_image).batch(batch_size).prefetch(1)\nval_batches = val_set.map(format_image).batch(batch_size).prefetch(1)\ntest_batches = test_set.map(format_image).batch(batch_size).prefetch(1)","72a4a9d7":"import tensorflow_hub as hub\n\nURL = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\"\n\nfeature_extractor = hub.KerasLayer(URL, input_shape=(image_size, image_size, 3))\nfeature_extractor.trainable = False","afb3392c":"# TODO: Build and train your network.\n\nmodel = tf.keras.Sequential([\n        feature_extractor,\n        tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.summary()","a6d2dd2d":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nEPOCHS = 20\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\n\nhistory = model.fit(train_batches,\n                        epochs=EPOCHS,\n                        validation_data=val_batches,\n                        callbacks=[early_stopping])","dc4ed154":"# TODO: Save your trained model as a Keras model.\nt = time.time()\n\nsaved_keras_model_filepath = '.\/model{}.h5'.format(int(t))\n\nmodel.save(saved_keras_model_filepath)","066b8bae":"# TODO: Load the Keras model\n\nreloaded_keras_model = tf.keras.models.load_model(saved_keras_model_filepath\n                                                  ,custom_objects={'KerasLayer':hub.KerasLayer})\nreloaded_keras_model.summary()","3737866c":"# TODO: Create the process_image function\nimage_size = 224\n\ndef process_image(image):\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, (image_size, image_size))\n    image \/= 255\n    image = image.numpy()\n    return image","a4bfc45a":"from PIL import Image\n\nimage_path = '\/kaggle\/input\/test-images\/hard-leaved_pocket_orchid.jpg'\nim = Image.open(image_path)\ntest_image = np.asarray(im)\n\nprocessed_test_image = process_image(test_image)\n\nfig, (ax1, ax2) = plt.subplots(figsize=(10,10), ncols=2)\nax1.imshow(test_image)\nax1.set_title('Original Image')\nax2.imshow(processed_test_image)\nax2.set_title('Processed Image')\nplt.tight_layout()\nplt.show()","4b4ec93d":"# TODO: Create the predict function\ndef predict(image_path, model, top_k=5):\n    im = Image.open(image_path)\n    test_image = np.asarray(im)\n    processed_test_image = process_image(test_image)\n    final_img = np.expand_dims(processed_test_image, axis=0)\n    preds = model.predict(final_img)\n    probs = - np.partition(-preds[0], top_k)[:top_k]\n    classes = np.argpartition(-preds[0], top_k)[:top_k]\n    return probs, classes","fb3325d1":"# TODO: Plot the input image along with the top 5 classes\n# TODO: Plot the input image along with the top 5 classes\nfile_names = ['cautleya_spicata.jpg','hard-leaved_pocket_orchid.jpg','orange_dahlia.jpg','wild_pansy.jpg']\ntop_k = 5\nfor filename in file_names:\n    image_path = '\/kaggle\/input\/test-images\/' + filename\n    image = np.asarray(Image.open(image_path)).squeeze()\n    probs, classes = predict(image_path, model, top_k)\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(image)\n    ax1.axis('off')\n    ax2.barh(np.arange(top_k), probs)\n    ax2.set_aspect(0.2)\n    ax2.set_yticks(np.arange(top_k))\n    keys = [str(x+1) for x in list(classes)] #add 1 to the class index to match the json dict keys\n    ax2.set_yticklabels([class_names.get(key) for key in keys], size='small')\n    ax2.set_title('Class Probabilities')\n    ax2.set_xlim(0, 1.1)\n    plt.tight_layout()","3a9cc011":"# Label Mapping","642efc02":"# Load the Keras Model","685375eb":"# Explore the Dataset","b425c556":"# Sanity Check\n\nIt's always good to check the predictions made by your model to make sure they are correct. To check your predictions we have provided 4 images in the `.\/test_images\/` folder:\n\n* cautleya_spicata.jpg\n* hard-leaved_pocket_orchid.jpg\n* orange_dahlia.jpg\n* wild_pansy.jpg\n\nIn the cell below use `matplotlib` to plot the input image alongside the probabilities for the top 5 classes predicted by your model. Plot the probabilities as a bar graph. The plot should look like this:\n\n<img src='assets\/inference_example.png' width=600px>\n\nYou can convert from the class integer labels to actual flower names using `class_names`. ","d8d26cda":"# Save the Model","993fb0ba":"# Build and Train the Classifier","71de1523":"Once you can get images in the correct format, it's time to write the `predict` function for making inference with your model.\n\n### Inference\n\nRemember, the `predict` function should take an image, a model, and then returns the top $K$ most likely class labels along with the probabilities. The function call should look like: \n\n```python\nprobs, classes = predict(image_path, model, top_k)\n```\n\nIf `top_k=5` the output of the `predict` function should be something like this:\n\n```python\nprobs, classes = predict(image_path, model, 5)\nprint(probs)\nprint(classes)\n> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n> ['70', '3', '45', '62', '55']\n```\n\nYour `predict` function should use `PIL` to load the image from the given `image_path`. You can use the [Image.open](https:\/\/pillow.readthedocs.io\/en\/latest\/reference\/Image.html#PIL.Image.open) function to load the images. The `Image.open()` function returns an `Image` object. You can convert this `Image` object to a NumPy array by using the `np.asarray()` function.\n\n**Note:** The image returned by the `process_image` function is a NumPy array with shape `(224, 224, 3)` but the model expects the input images to be of shape `(1, 224, 224, 3)`. This extra dimension represents the batch size. We suggest you use the `np.expand_dims()` function to add the extra dimension. ","8fe5fabf":"# Create Pipeline","d1fdb570":"# Inference for Classification\n\nNow you'll write a function that uses your trained network for inference. Write a function called `predict` that takes an image, a model, and then returns the top $K$ most likely class labels along with the probabilities. The function call should look like: \n\n```python\nprobs, classes = predict(image_path, model, top_k)\n```\n\nIf `top_k=5` the output of the `predict` function should be something like this:\n\n```python\nprobs, classes = predict(image_path, model, 5)\nprint(probs)\nprint(classes)\n> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n> ['70', '3', '45', '62', '55']\n```\n\nYour `predict` function should use `PIL` to load the image from the given `image_path`. You can use the [Image.open](https:\/\/pillow.readthedocs.io\/en\/latest\/reference\/Image.html#PIL.Image.open) function to load the images. The `Image.open()` function returns an `Image` object. You can convert this `Image` object to a NumPy array by using the `np.asarray()` function.\n\nThe `predict` function will also need to handle pre-processing the input image such that it can be used by your model. We recommend you write a separate function called `process_image` that performs the pre-processing. You can then call the `process_image` function from the `predict` function. \n\n### Image Pre-processing\n\nThe `process_image` function should take in an image (in the form of a NumPy array) and return an image in the form of a NumPy array with shape `(224, 224, 3)`.\n\nFirst, you should convert your image into a TensorFlow Tensor and then resize it to the appropriate size using `tf.image.resize`.\n\nSecond, the pixel values of the input images are typically encoded as integers in the range 0-255, but the model expects the pixel values to be floats in the range 0-1. Therefore, you'll also need to normalize the pixel values. \n\nFinally, convert your image back to a NumPy array using the `.numpy()` method."}}