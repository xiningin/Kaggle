{"cell_type":{"0aea2a0f":"code","3fc168c5":"code","2e1be5bf":"code","99834d9b":"code","13308aeb":"code","806c88ab":"code","4cf0c225":"code","153c8bb0":"code","3372e02e":"code","797a4391":"code","10916e95":"code","ab20ffb9":"code","0c8c71fa":"code","8c81d3cd":"code","422b983b":"code","c98a9ff6":"code","e432e457":"code","d9c58e55":"code","511b7e5d":"code","827ce0d9":"markdown","6dccb664":"markdown","6c75f878":"markdown","410ebe2e":"markdown","419efce0":"markdown","c100a8e8":"markdown","bbde02cc":"markdown","3c126776":"markdown","d74a68d7":"markdown","14ce80cf":"markdown"},"source":{"0aea2a0f":"import datetime as dt\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('darkgrid')\n\n\nimport os\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport cv2\nfrom scipy.stats import uniform\n\nfrom tqdm import tqdm\nfrom glob import glob\n\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking\nfrom keras.utils import np_utils, to_categorical\nimport keras\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","3fc168c5":"#copying the pretrained models to the cache directory\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n\n#copy the Xception models\n!cp ..\/input\/keras-pretrained-models\/xception* ~\/.keras\/models\/\n#show\n!ls ~\/.keras\/models","2e1be5bf":"data_folder = '..\/input\/face-mask-detection-data'\ncategories = ['with_mask', 'without_mask']\nlen_categories = len(categories)","99834d9b":"#show number of images per category\nfor category in categories:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(data_folder, category)))))","13308aeb":"train_data = []\n\nfor i, category in tqdm(enumerate(categories)):\n    class_folder = os.path.join(data_folder, category)    \n    for path in os.listdir(os.path.join(class_folder)):\n        train_data.append(['{}\/{}'.format(category, path), category, i])\ndf = pd.DataFrame(train_data, columns=['filepath', 'class', 'label'])\n\n#reduce the data\nSAMPLE_PER_CATEGORY = 500\ndf = pd.concat([df[df['class'] == i][:SAMPLE_PER_CATEGORY] for i in categories])\n\nprint('DATAFRAME SHAPE: ',df.shape)\ndf.head()","806c88ab":"# function to get an image\ndef read_img(filepath, size):\n    img = image.load_img(os.path.join(data_folder, filepath), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img)\n    return img","4cf0c225":"nb_rows = 3\nnb_cols = 5\nfig, axs = plt.subplots(nb_rows, nb_cols, figsize=(10, 5));\nplt.suptitle('SAMPLE IMAGES');\nfor i in range(0, nb_rows):\n    for j in range(0, nb_cols):\n        axs[i, j].xaxis.set_ticklabels([]);\n        axs[i, j].yaxis.set_ticklabels([]);\n        axs[i, j].imshow((read_img(df['filepath'].iloc[np.random.randint(998)], (255,255)))\/255);\nplt.show();","153c8bb0":"# function to sharpen the images\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp \/ 255","3372e02e":"INPUT_SIZE = 255\nX_train = np.zeros((len(df), INPUT_SIZE, INPUT_SIZE, 3), dtype='float')\n\nfor i, file in tqdm(enumerate(df['filepath'])):\n    img_sharpen = sharpen_image(read_img(file, (255,255)))\n    X_train[i] = xception.preprocess_input(np.expand_dims(img_sharpen.copy(), axis=0))\n    ","797a4391":"print('Train Image Shape: ', X_train.shape)\nprint('Train Image Size: ', X_train.size)","10916e95":"#split the data\ny = df['label']\ntrain_x, train_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=101)","ab20ffb9":"xception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\nbf_train_x = xception_bf.predict(train_x, batch_size=32, verbose=1)\nbf_train_val = xception_bf.predict(train_val, batch_size=32, verbose=1)","0c8c71fa":"#print shape of feature and size\nprint('Train Shape: ', bf_train_x.shape)\nprint('Train Size: ', bf_train_x.size)\n\nprint('Validation Shape: ', bf_train_val.shape)\nprint('Validation Size: ', bf_train_val.size)","8c81d3cd":"#optimizer\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=10000,\n    decay_rate=0.9)\nopt = keras.optimizers.Adam(learning_rate=lr_schedule)\n\n#keras model\nmodel = Sequential()\nmodel.add(Dense(units = 256 , activation = 'relu', input_dim=bf_train_x.shape[1]))\nmodel.add(Dense(units = 64 , activation = 'relu'))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nmodel.compile(optimizer = opt , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","422b983b":"#set callbacks\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2),\n         ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\n#fit the data\nhistory = model.fit(bf_train_x, y_train, batch_size=32, epochs=500, callbacks=callbacks)","c98a9ff6":"fig, ax = plt.subplots(1,2,figsize=(14,5))\nax[0].set_title('TRAINING LOSS');\nax[1].set_title('TRAINING ACCURACY');\n\n\nax[0].plot(history.history['loss'], color= 'salmon',lw=2);\nax[1].plot(history.history['accuracy'], color= 'green',lw=2);","e432e457":"#predict the validation data\npredictions = model.predict_classes(bf_train_val)","d9c58e55":"print(classification_report(y_val, predictions))","511b7e5d":"con_mat = confusion_matrix(y_val, predictions)\n\nplt.figure(figsize=(8,8))\nplt.title('CONFUSION MATRIX')\n\nsns.heatmap(con_mat,\n            yticklabels=['with_mask', 'without_mask'], \n            xticklabels=['with_mask', 'without_mask'],\n            annot=True, linecolor='black', linewidths=4, square=True);\n\nplt.xlabel('Y_TRUE'), plt.ylabel('PREDICTIONS');","827ce0d9":"### LOSS AND ACCURACY","6dccb664":"### CREATE A DATAFRAME","6c75f878":"### PREPROCESSING THE IMAGES","410ebe2e":"### DATA UTILITIES\n","419efce0":"### MODELLING","c100a8e8":"### BOTTLENECK FEATURE EXTRACTION","bbde02cc":"## OVERVIEW\n---\n* Image Processing\n* Transfer Learning With Keras Pretrained Models\n* Bottleneck Feature Extraction\n* Keras library for building a basic Convolutional Neural Network.\n* Predictive Modelling\n* Plotting of Model Performance","3c126776":"### SHOW SAMPLE IMAGES","d74a68d7":"### CONFUSION MATRIX","14ce80cf":"### CLASSIFICATION REPORT"}}