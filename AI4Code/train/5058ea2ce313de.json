{"cell_type":{"b486b972":"code","a03caf51":"code","f1a160ed":"code","ad6d5c1c":"code","2223b3a6":"code","57c54234":"code","9bb36b03":"code","bf295b73":"code","9f41c9df":"code","f696cf95":"code","5380f964":"code","53fba622":"code","4f9f5026":"code","1a16d63b":"code","3e6e67ae":"code","64f873f8":"code","b750eef6":"code","3e558875":"code","f392f24d":"code","07db8125":"markdown","6972d802":"markdown","c002f54e":"markdown","9c824ced":"markdown","86d98800":"markdown","5bc988ee":"markdown","1e1ab2d2":"markdown"},"source":{"b486b972":"!pip install -U git+https:\/\/github.com\/qubvel\/efficientnet\/","a03caf51":"import os\nimport PIL\nimport time\nimport math\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport albumentations as albu\nimport matplotlib.pyplot as plt\nimport efficientnet.tfkeras as efn\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom sklearn.metrics import cohen_kappa_score, make_scorer, accuracy_score,confusion_matrix\n\nSEED = 329\nwarnings.filterwarnings('ignore')\nAUTO = tf.data.experimental.AUTOTUNE\nprint('Tensorflow version : {}'.format(tf.__version__))","f1a160ed":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU : {}'.format(tpu.master()))\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"Replicas : {}\".format(strategy.num_replicas_in_sync))","ad6d5c1c":"TRAIN_FLAG = False\nTRAIN_FOLD = 0\n\nRADBOUD_FILE_NUMS = [\n    918,\n    896,\n    910,\n    872,\n    910\n]\nKAROLINSKA_FILE_NUMS = [\n    1076,\n    1098,\n    1082,\n    1111,\n    1081\n]","2223b3a6":"\nGCS_DS_PATH1 = KaggleDatasets().get_gcs_path('ptfrecord1')\nGCS_DS_PATH2 = KaggleDatasets().get_gcs_path('ptfrecord2')\nGCS_DS_PATH3 = KaggleDatasets().get_gcs_path('ptfrecord3')\nGCS_DS_PATH4 = KaggleDatasets().get_gcs_path('ptfrecord4')\nGCS_DS_PATH5 = KaggleDatasets().get_gcs_path('ptfrecord5')\n\nprint(GCS_DS_PATH1)\nprint(GCS_DS_PATH2)\nprint(GCS_DS_PATH3)\nprint(GCS_DS_PATH4)\nprint(GCS_DS_PATH5)\n\n\ntotal_fns = tf.io.gfile.glob(os.path.join(GCS_DS_PATH1, 'tiles_tfrec\/*.tfrec')) + tf.io.gfile.glob(os.path.join(GCS_DS_PATH2, 'tiles_tfrec\/*.tfrec')) + \\\n            tf.io.gfile.glob(os.path.join(GCS_DS_PATH3, 'tiles_tfrec\/*.tfrec')) + tf.io.gfile.glob(os.path.join(GCS_DS_PATH4, 'tiles_tfrec\/*.tfrec')) + \\\n            tf.io.gfile.glob(os.path.join(GCS_DS_PATH5, 'tiles_tfrec\/*.tfrec'))\n\ntrain_fns = []\nvalid_fns = []\n\nfor fn in total_fns:\n    if 'val_%d'%TRAIN_FOLD in fn:\n        valid_fns.append(fn)\n    else:\n        train_fns.append(fn)\n\nFOLDED_NUM_TRAIN_IMAGES = np.sum(RADBOUD_FILE_NUMS)   - RADBOUD_FILE_NUMS[TRAIN_FOLD] + np.sum(KAROLINSKA_FILE_NUMS) - KAROLINSKA_FILE_NUMS[TRAIN_FOLD]\nFOLDED_NUM_VALID_IMAGES =  KAROLINSKA_FILE_NUMS[TRAIN_FOLD]  + RADBOUD_FILE_NUMS[TRAIN_FOLD] ","57c54234":"val_radboud_fns = []\nval_kar_fns = []\n\nfor fn in total_fns:\n    if 'val_%d'%TRAIN_FOLD in fn and 'radboud' in fn:\n        val_radboud_fns.append(fn)\n    elif 'val_%d'%TRAIN_FOLD in fn and 'radboud' not in fn:\n        val_kar_fns.append(fn)","9bb36b03":"print(len(train_fns))\nprint(len(valid_fns))","bf295b73":"x_tiles_num = 12\ny_tiles_num = 12\nsz = 128\nN = 144\nIMG_DIM = (int(sz*y_tiles_num), int(sz*x_tiles_num))\nCLASSES_NUM = 1\nBATCH_SIZE = 4 * strategy.num_replicas_in_sync\nEPOCHS = 40\nTRAIN_EPOCHS= 25\nSTART_EPOCH = 0\nLEARNING_RATE = 5e-4\nSTEPS_PER_EPOCH = FOLDED_NUM_TRAIN_IMAGES \/\/ BATCH_SIZE\nVALIDATION_STEPS = FOLDED_NUM_VALID_IMAGES \/\/ BATCH_SIZE\nPRETRAIN_PATH = '..\/input\/panda-best-weights\/fold0_b3_144tiles_128tilesize_mse_huber_0905kcv_0853rcv_0706.h5'","9f41c9df":"print('*'*20)\nprint('Notebook info')\nprint('Training data : {}'.format(FOLDED_NUM_TRAIN_IMAGES))\nprint('Validing data : {}'.format(FOLDED_NUM_VALID_IMAGES))\nprint('Categorical classes : {}'.format(CLASSES_NUM))\nprint('Training image size : {}'.format(IMG_DIM))\nprint('Training epochs : {}'.format(EPOCHS))\nprint('Batch size : {}'.format(BATCH_SIZE))\nprint('*'*20)","f696cf95":"class Dataset:\n    \n    def __init__(self,\n                 filenames,\n                 data_len,\n                 image_shape,\n                 mode = 'train',\n                 batch_size=BATCH_SIZE,\n                 shuffle=4096,\n                 repeat=True,\n                 augmentation=True,\n                 rot_prob=0.25,\n                 shear_prob=0.0,\n                 shift_prob=0.25,\n                 scale_prob=0.25,\n                 rot_range=10,\n                 shear_range=5,\n                 shift_range=50,\n                 scale_range=0.05\n                 ):\n        \n        self.filenames = filenames\n        self.data_len = data_len\n        self.image_shape = image_shape\n        self.mode = mode\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.repeat = repeat\n        self.aug = augmentation\n        \n        self.rot_prob = 1.0 - rot_prob\n        self.shift_prob = 1.0 - shift_prob\n        self.scale_prob = 1.0 - scale_prob\n        self.shear_prob = 1.0 - shear_prob\n        self.rot_range = rot_range\n        self.shear_range = shear_range\n        self.shift_range = shift_range\n        self.scale_range = scale_range\n\n        self.log_adjust = tf.math.log(1e-6)\n        self.rgb_from_hed = tf.constant([[0.65, 0.7 , 0.29],\n                                         [0.07, 0.99, 0.11],\n                                         [0.27, 0.57, 0.78]], dtype=tf.float32)\n        \n        self.hed_from_rgb = tf.linalg.inv(self.rgb_from_hed)\n        \n    def get_dataset(self, order=False, drop_remainder=True):\n\n        data_options = tf.data.Options()\n        if not order:\n            data_options.experimental_deterministic = False\n\n        ds = tf.data.TFRecordDataset(self.filenames, num_parallel_reads=AUTO)\n        ds = ds.with_options(data_options)\n        ds = ds.map(self.decode_example, num_parallel_calls=AUTO)\n        \n        if self.shuffle:\n            ds = ds.shuffle(self.shuffle, seed=SEED)\n        if self.repeat:\n            ds = ds.repeat()\n        if self.batch_size:\n            ds = ds.batch(self.batch_size, drop_remainder=drop_remainder)         \n        if self.aug:\n            ds = ds.map(self.batch_data_augmentation, num_parallel_calls=AUTO)\n            \n        ds = ds.map(self.encode_labels, num_parallel_calls=AUTO)      \n        ds = ds.prefetch(AUTO)\n        \n        return ds\n    \n    def encode_labels(self, images, isup_grade, data_providers):\n\n        isup_grade = tf.expand_dims(isup_grade, axis=-1)\n        data_providers = tf.expand_dims(data_providers, axis=-1)\n        encoded_labels = tf.concat([isup_grade, data_providers], axis=-1)\n        \n        return images, encoded_labels\n    \n    def rgb2hed(self, images):\n        images = tf.math.maximum(images, 1e-6)\n        hed = (tf.math.log(images) \/ self.log_adjust) @ self.hed_from_rgb\n        return hed\n    \n    def hed2rgb(self, heds):\n        log_rgb = -(heds * -self.log_adjust) @ self.rgb_from_hed\n        rgb = tf.math.exp(log_rgb)\n        return tf.clip_by_value(rgb, 0.0, 1.0)\n    \n    def hedjitter(self, heds, alpha, beta):\n        auged_hed = tf.identity(heds)\n        alpha = tf.random.uniform(shape=[self.batch_size, 1, 1, 3], minval=1-alpha, maxval=1+alpha, dtype=tf.float32)\n        beta = tf.random.uniform(shape=[self.batch_size, 1, 1, 3], minval=-beta, maxval=beta, dtype=tf.float32)\n        auged_hed = tf.multiply(auged_hed, alpha) + beta\n        return auged_hed\n    \n    def ColorStain(self, images, alpha=0.05, beta=0.01, return_heds=False):\n        heds = self.rgb2hed(images)\n        heds = self.hedjitter(heds, alpha, beta)\n\n        if return_heds:\n            return self.hed2rgb(heds), heds\n        else:\n            return self.hed2rgb(heds)\n    \n    def batch_data_augmentation(self, images, isup_grade, data_provider):\n\n        select_prob = self.random_prob()\n        select_prob2 = self.random_prob()\n        \n        if select_prob < 0.5:\n            if self.random_prob() >= 0.5:\n                images = self.ColorStain(images)\n        else:\n            if self.random_prob() >= 0.5:\n                if select_prob2 < 0.5:\n                    images = tf.image.random_brightness(images, 0.1)\n                else:\n                    images = tf.image.random_contrast(images, 0.7, 1.3)\n\n            if self.random_prob() >= 0.7:\n                images = tf.image.random_saturation(images, 0.8, 1.2)\n                \n        if self.random_prob() >=0.5:\n            images = tf.image.rot90(images)\n        \n        images = tf.image.random_flip_left_right(images)\n        images = tf.image.random_flip_up_down(images)\n        images = self.shift_rotate_scale_shear(images)\n        images = tf.clip_by_value(images, 0.0, 1.0)\n        return images, isup_grade, data_provider\n    \n    def decode_example(self, example):\n        feature_format = {\n            \"image\" : tf.io.FixedLenFeature([], tf.string),\n            \"isup_grade\" : tf.io.FixedLenFeature([], tf.int64),\n            \"data_provider\" : tf.io.FixedLenFeature([], tf.int64)\n        }\n        \n        example = tf.io.parse_single_example(example, feature_format)\n        \n        image = tf.image.decode_jpeg(example['image'], channels=3)\n        image = tf.reshape(image, [*self.image_shape, 3])\n        \n        image = tf.cast(image, tf.float32) \/ 255.0\n        \n        isup_grade = example['isup_grade']\n        data_provider = example['data_provider'] # 0 for radboud , 1 for kar\n\n        return image, isup_grade, data_provider\n\n    def random_prob(self, shape=1, minval=0.0, maxval=1.0):\n        return tf.random.uniform(shape=[shape], minval=minval, maxval=maxval)\n    \n    def shift_rotate_scale_shear(self, images):\n\n        angles  = self.rot_range * tf.random.normal([self.batch_size],dtype='float32')\n        shears  = self.shear_range * tf.random.normal([self.batch_size],dtype='float32')\n        hshifts = self.shift_range *  tf.random.normal([self.batch_size],dtype='float32')\n        vshifts = self.shift_range *  tf.random.normal([self.batch_size],dtype='float32')\n        hscales = tf.random.uniform(shape=[self.batch_size], minval=-self.scale_range, maxval=self.scale_range, dtype=tf.float32) + 1.0\n        wscales = tf.random.uniform(shape=[self.batch_size], minval=-self.scale_range, maxval=self.scale_range, dtype=tf.float32) + 1.0\n\n        shear_do_cond = self.random_prob(self.batch_size) >= self.shear_prob\n        shift_do_cond = self.random_prob(self.batch_size) >= self.shift_prob\n        scale_do_cond = self.random_prob(self.batch_size) >= self.scale_prob\n        rotate_do_cond = self.random_prob(self.batch_size) >= self.rot_prob\n\n        zeros = tf.zeros_like(angles)\n        ones = tf.ones_like(angles)\n\n        angles = tf.where(rotate_do_cond, angles,  zeros)\n        shears = tf.where(shear_do_cond,  shears,  zeros)\n        hshifts = tf.where(shift_do_cond, hshifts, zeros)\n        vshifts = tf.where(shift_do_cond, vshifts, zeros)\n        hscales = tf.where(scale_do_cond, hscales, ones)\n        wscales = tf.where(scale_do_cond, wscales, ones)\n\n        transform_mat = self.get_batch_transform_inv_matrix(angles, shears, hshifts, vshifts, hscales, wscales)\n        \n        images = self.batch_transform(images, transform_mat, (*self.image_shape, 3), self.batch_size)\n      \n        return images\n    \n    def get_batch_transform_inv_matrix(self, angles, shears, hshifts, vshifts, hscales, wscales):\n\n        angles = math.pi * angles \/ 180\n        shears = math.pi * shears \/ 180\n\n        ones = tf.ones_like(angles)\n        zeros = tf.zeros_like(angles)\n\n        rot_cs = tf.math.cos(angles)\n        rot_ss = tf.math.sin(angles)\n\n        she_cs = tf.math.cos(shears)\n        she_ss = tf.math.sin(shears)\n\n        inv_rot_mat = tf.stack([ rot_cs, rot_ss, zeros, -rot_ss, rot_cs, zeros,  zeros, zeros, ones], axis=0)\n        inv_rot_mat = tf.reshape(tf.transpose(inv_rot_mat), shape=(self.batch_size, 3, 3))\n\n        inv_she_mat = tf.stack([ ones, she_ss, zeros, zeros, she_cs, zeros,  zeros, zeros, ones], axis=0)\n        inv_she_mat = tf.reshape(tf.transpose(inv_she_mat), shape=(self.batch_size, 3, 3))\n\n        inv_shi_mat = tf.stack([ones, zeros, vshifts, zeros, ones, hshifts, zeros, zeros, ones], axis=0)\n        inv_shi_mat = tf.reshape(tf.transpose(inv_shi_mat), shape=(self.batch_size, 3, 3))\n\n        inv_sca_mat = tf.stack([ones\/hscales, zeros, zeros, zeros, ones\/wscales, zeros, zeros, zeros, ones], axis=0)\n        inv_sca_mat = tf.reshape(tf.transpose(inv_sca_mat), shape=(self.batch_size, 3, 3))\n        transform_mat = tf.matmul(tf.matmul(inv_rot_mat, inv_she_mat), tf.matmul(inv_shi_mat, inv_sca_mat))\n\n        return transform_mat\n\n    def batch_transform(self, images, inv_mat, image_shape=(512, 512, 3), batch_size=16):\n        \n        images = tf.pad(images, [[0,0], [1,1], [1,1], [0,0]])\n        h, w, c = image_shape\n        h, w = h+2, w+2\n        cx, cy = w\/\/2, h\/\/2\n\n        new_xs = tf.repeat( tf.range(-cx, cx, 1), h)\n        new_ys = tf.tile( tf.range(-cy, cy, 1), [w]) \n        new_zs = tf.ones([h*w], dtype=tf.int32)\n        \n        #5x3x3 dot 3 * (h*w) => 5 x 3 x (h*w)\n        old_coords = tf.matmul(inv_mat, tf.cast(tf.stack([new_xs, new_ys, new_zs]), tf.float32))\n        old_coords_x, old_coords_y = old_coords[:, 0, ]+cx, old_coords[:, 1, ]+cy\n        \n        old_coords_x = tf.clip_by_value(tf.cast(old_coords_x, tf.int32), 0, w-1)\n        old_coords_y = tf.clip_by_value(tf.cast(old_coords_y, tf.int32), 0, h-1)\n        gather_coords = tf.stack([old_coords_y, old_coords_x], axis=1)\n        d = tf.gather_nd(images, tf.transpose(gather_coords, perm=[0, 2, 1]), batch_dims=1)\n\n        new_images = tf.reshape(d, (batch_size, w, h, 3))\n        new_images = tf.transpose(new_images, perm=[0,2,1,3])\n        new_images = tf.image.crop_to_bounding_box(new_images, 1, 1, h-2, w-2)\n        return new_images","5380f964":"train_ds = Dataset(filenames=train_fns,\n                   data_len=FOLDED_NUM_TRAIN_IMAGES,\n                   image_shape=IMG_DIM,\n                   batch_size=BATCH_SIZE,\n                   shuffle=2048,\n                   ).get_dataset()\n\nvalid_ds = Dataset(filenames=valid_fns,\n                   data_len=FOLDED_NUM_VALID_IMAGES,\n                   image_shape=IMG_DIM,\n                   batch_size=BATCH_SIZE,\n                   shuffle=0,\n                   augmentation=False,\n                   repeat=False\n                   ).get_dataset(order=True, drop_remainder=True)","53fba622":"class Generalized_mean_pooling2D(tf.keras.layers.Layer):\n    def __init__(self, p=3, epsilon=1e-6, name='', **kwargs):\n        super(Generalized_mean_pooling2D, self).__init__(name, **kwargs)\n        self.init_p = p\n        self.epsilon = epsilon\n    \n    def build(self, input_shape):\n        if isinstance(input_shape, list) or len(input_shape) != 4:\n            raise ValueError('`GeM` pooling layer only allow 1 input with 4 dimensions(b, h, w, c)')\n        self.build_shape = input_shape\n        self.p = self.add_weight(\n                  name='p',\n                  shape=[1,],\n                  initializer=tf.keras.initializers.Constant(value=self.init_p),\n                  regularizer=None,\n                  trainable=True,\n                  dtype=tf.float32\n                  )\n        self.built=True\n\n    def call(self, inputs):\n        input_shape = inputs.get_shape()\n        if isinstance(inputs, list) or len(input_shape) != 4:\n            raise ValueError('`GeM` pooling layer only allow 1 input with 4 dimensions(b, h, w, c)')\n        return (tf.reduce_mean(tf.abs(inputs**self.p), axis=[1,2], keepdims=False) + self.epsilon)**(1.0\/self.p)\n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'init_p': self.init_p,\n            'epsilon': self.epsilon,\n        })\n        return config\n\ndef build_model():\n    \n    Input_layer = tf.keras.layers.Input(shape=(*IMG_DIM,3), name='image_input')\n    base_model = efn.EfficientNetB3(weights='noisy-student', input_shape=(*IMG_DIM,3), include_top=False, input_tensor=Input_layer)\n    x = Generalized_mean_pooling2D()(base_model.output)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(units=128, kernel_initializer='he_normal', activation='relu')(x)\n    Output_layer = tf.keras.layers.Dense(units=1)(x)\n    model = tf.keras.models.Model(inputs=[Input_layer], outputs=[Output_layer])\n    \n    return model","4f9f5026":"with strategy.scope():\n\n    @tf.function\n    def cosine_annealing(epoch, total_epochs=EPOCHS, cycles=1, max_lr=LEARNING_RATE, min_lr=5e-6):\n        epoch += START_EPOCH\n        epoch_per_cycle = int(total_epochs\/cycles)\n        cos_inner = ( 3.14 * (epoch % epoch_per_cycle)) \/ (epoch_per_cycle)\n        lr = max_lr\/2 * ( tf.math.cos(cos_inner) + 1)\n        return tf.where(lr > min_lr, lr, min_lr)\n\n    class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n        def __call__(self, step):\n            return cosine_annealing(epoch=step\/\/STEPS_PER_EPOCH)\n    \n    @tf.function\n    def Huber_Loss(y_true, y_pred, delta=1.0):\n        y_true = tf.reshape(y_true, (-1,))\n        y_pred = tf.reshape(y_pred, (-1,))\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        abs_diff = abs(y_true-y_pred)\n        loss = tf.where(abs_diff < delta , 0.5 * tf.pow(y_true-y_pred, 2), delta * (abs_diff - 0.5*delta))\n        return loss\n\n    def radboud_loss(y_trues, y_preds):\n        y_trues, center_mask = tf.split(y_trues, [1,1], axis=-1)\n        center_mask = tf.reshape(center_mask, (-1,))\n        mae_loss = tf.keras.losses.mean_absolute_error(y_trues, y_preds)\n        huber_loss = Huber_Loss(y_trues, y_preds)\n        rad_loss = tf.where(center_mask==0, huber_loss, tf.zeros_like(huber_loss))\n        rad_loss = tf.where(mae_loss >= 4.0, tf.zeros_like(rad_loss), rad_loss)\n        return rad_loss \n    \n    @tf.function\n    def Karolinska_loss(y_trues, y_preds):\n        y_trues, center_mask = tf.split(y_trues, [1,1], axis=-1)\n        center_mask = tf.reshape(center_mask, (-1,))\n        mse_loss = tf.keras.losses.mean_squared_error(y_trues, y_preds)\n        kar_loss = tf.where(center_mask==1, mse_loss, tf.zeros_like(mse_loss))\n        return kar_loss\n    \n    rad_loss_object = radboud_loss\n    kar_loss_object = Karolinska_loss\n\n    def compute_radboud_loss(labels, predictions):\n        per_example_loss = rad_loss_object(labels, predictions)\n        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZE)\n    \n    def compute_karolinska_loss(labels, predictions):\n        per_example_loss = kar_loss_object(labels, predictions)\n        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZE)\n\n\n    model = build_model()\n    optimizer = tf.keras.optimizers.Adam(learning_rate=LRSchedule())\n    \n    train_loss = tf.keras.metrics.Sum()\n    valid_loss = tf.keras.metrics.Sum()\n    train_rad_loss = tf.keras.metrics.Sum()\n    valid_rad_loss = tf.keras.metrics.Sum()\n    train_kar_loss = tf.keras.metrics.Sum()\n    valid_kar_loss = tf.keras.metrics.Sum()","1a16d63b":"if PRETRAIN_PATH:\n    print('load model pretrain weights..')\n    model.load_weights(PRETRAIN_PATH)","3e6e67ae":"@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as grad_tape:\n        preds = model(images, training=True)\n        \n        rad_loss = compute_radboud_loss(labels, preds)\n        kar_loss = compute_karolinska_loss(labels, preds)\n        loss = rad_loss + kar_loss\n\n    grads = grad_tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    train_loss.update_state(loss)\n    train_rad_loss.update_state(rad_loss)\n    train_kar_loss.update_state(kar_loss)\n\n@tf.function\ndef valid_step(images, labels):\n    preds = model(images, training=False)\n    \n    rad_loss = compute_radboud_loss(labels, preds)\n    kar_loss = compute_karolinska_loss(labels, preds)\n    loss = rad_loss + kar_loss\n\n    valid_loss.update_state(loss)\n    valid_rad_loss.update_state(rad_loss)\n    valid_kar_loss.update_state(kar_loss)\n\n    \n@tf.function\ndef inference_step(images):\n    preds = model(images, training=False)\n    return preds","64f873f8":"best_valid_loss = 10000\nbest_rad_valid_loss = 10000\nbest_kar_valid_loss = 10000\nhistory = {\n    'train_loss' : [],\n    'valid_loss' : [],\n    'train_rad_loss' : [],\n    'valid_rad_loss' : [],\n    'train_kar_loss' : [],\n    'valid_kar_loss' : [],\n    'qwk' : []\n}","b750eef6":"if TRAIN_FLAG:\n    train_dist_ds = strategy.experimental_distribute_dataset(train_ds)\n    valid_dist_ds = strategy.experimental_distribute_dataset(valid_ds)\n    print(\"Steps per epoch:\", STEPS_PER_EPOCH, \"Valid steps per epoch:\", VALIDATION_STEPS)\n    epoch = 0\n    start_time = time.time()\n    for step, (images, labels) in enumerate(train_dist_ds):\n\n        strategy.run(train_step, args=(images, labels))\n        print('=', end='', flush=True)\n\n        if ((step+1) \/\/ STEPS_PER_EPOCH) > epoch:\n            print('|', end='',flush=True)\n\n            for images, labels in valid_dist_ds:\n                print('=', end='', flush=True)\n                strategy.run(valid_step, args=(images, labels))\n\n            history['train_loss'].append(train_loss.result().numpy() \/ STEPS_PER_EPOCH)\n            history['valid_loss'].append(valid_loss.result().numpy() \/ VALIDATION_STEPS)\n\n            history['train_rad_loss'].append(train_rad_loss.result().numpy() \/ STEPS_PER_EPOCH)\n            history['train_kar_loss'].append(train_kar_loss.result().numpy() \/ STEPS_PER_EPOCH)\n\n            history['valid_rad_loss'].append(valid_rad_loss.result().numpy() \/ VALIDATION_STEPS)\n            history['valid_kar_loss'].append(valid_kar_loss.result().numpy() \/ VALIDATION_STEPS)\n\n            print('\\nEPOCH {:d}\/{:d}'.format(epoch+1, EPOCHS))\n            print('loss: {:0.4f}'.format(history['train_loss'][-1]), 'valid_loss: {:0.4f}'.format(history['valid_loss'][-1]))\n            print('radboud loss : {:0.4f}'.format(history['train_rad_loss'][-1]), 'valid radboud loss : {:0.4f}'.format(history['valid_rad_loss'][-1]))\n            print('karolinska loss : {:0.4f}'.format(history['train_kar_loss'][-1]), 'valid karolinska loss : {:0.4f}'.format(history['valid_kar_loss'][-1]))\n\n            train_loss.reset_states()\n            valid_loss.reset_states()\n            train_rad_loss.reset_states()\n            valid_rad_loss.reset_states()\n            train_kar_loss.reset_states()\n            valid_kar_loss.reset_states()\n\n            if history['valid_loss'][-1] < best_valid_loss:\n                print('Validation loss improve from {} to {}, save model checkpoint'.format(best_valid_loss, history['valid_loss'][-1]))\n                model.save('model.h5')\n                best_valid_loss = history['valid_loss'][-1]\n                patience=0\n\n            if history['valid_rad_loss'][-1] < best_rad_valid_loss:\n                print('Validation rad loss improve from {:0.4f} to {:0.4f}, save rad checkpoint'.format(best_rad_valid_loss, history['valid_rad_loss'][-1]))\n                model.save('rad_model.h5')\n                best_rad_valid_loss = history['valid_rad_loss'][-1]\n\n            if history['valid_kar_loss'][-1] < best_kar_valid_loss:\n                print('Validation kar loss improve from {:0.4f} to {:0.4f}, save kar checkpoint'.format(best_kar_valid_loss, history['valid_kar_loss'][-1]))\n                model.save('kar_model.h5')\n                best_kar_valid_loss = history['valid_kar_loss'][-1]\n\n            print('Spending time : {} second...'.format(time.time()-start_time))\n            start_time = time.time()\n            epoch = (step+1) \/\/ STEPS_PER_EPOCH\n            if epoch >= TRAIN_EPOCHS:\n                break","3e558875":"def prediction_decode(y_preds):\n    \n    for i, pred in enumerate(y_preds):\n        if pred < 0.5:\n            y_preds[i] = 0\n        elif pred >= 0.5 and pred < 1.5:\n            y_preds[i] = 1\n        elif pred >= 1.5 and pred < 2.5:\n            y_preds[i] = 2\n        elif pred >= 2.5 and pred < 3.5:\n            y_preds[i] = 3\n        elif pred >= 3.5 and pred < 4.5:\n            y_preds[i] = 4\n        else:\n            y_preds[i] = 5\n    \n    return y_preds.astype(np.int32)","f392f24d":"\nrad_valid_ds = Dataset(filenames=val_radboud_fns,\n                      data_len=FOLDED_NUM_VALID_IMAGES,\n                      image_shape=IMG_DIM,\n                      batch_size=BATCH_SIZE,\n                      shuffle=0,\n                      augmentation=False,\n                      repeat=False,\n                      ).get_dataset(order=True, drop_remainder=False)\n\nkar_valid_ds = Dataset(filenames=val_kar_fns,\n                      data_len=FOLDED_NUM_VALID_IMAGES,\n                      image_shape=IMG_DIM,\n                      batch_size=BATCH_SIZE,\n                      shuffle=0,\n                      augmentation=False,\n                      repeat=False,\n                      ).get_dataset(order=True, drop_remainder=False)\n\n\ndef valid_qwk(valid_ds, data_center='Both'):\n    predictions = []\n    groundtruths = []\n    for images, labels in valid_ds:\n        print('=', end='', flush=True)\n        preds = inference_step(images)\n        preds = prediction_decode(preds.numpy())\n        labels = prediction_decode(labels.numpy()[:,0])\n\n        groundtruths += list(labels)\n        predictions += list(preds)\n        \n    qwk = cohen_kappa_score(groundtruths, predictions, labels=None, weights= 'quadratic', sample_weight=None)\n    confusion_mat = confusion_matrix(groundtruths, predictions)\n    print('\\n {} data center validation qwk : {:0.4f}'.format(data_center, qwk))\n\n    return confusion_mat, groundtruths, predictions\n\nif TRAIN_FLAG:\n    model.save('model_finalcheckpoint.h5')\n    model.load_weights('model.h5')\n\nprint('Validation qwk on overall validation loss checkpoint :')\nprint('-'*20)\nrad_confusion_mat, rad_groundtruths, rad_predictions = valid_qwk(rad_valid_ds, 'Radboud')\nkar_confusion_mat, kar_groundtruths, kar_predictions = valid_qwk(kar_valid_ds, 'Karolinska')\n\noverall_groundtruths = list(rad_groundtruths) + list(kar_groundtruths)\noverall_predictions = list(rad_predictions) + list(kar_predictions)\noverall_confusion_mat = confusion_matrix(overall_groundtruths, overall_predictions)\noverall_qwk = cohen_kappa_score(overall_groundtruths, overall_predictions, labels=None, weights= 'quadratic', sample_weight=None)\n\nprint(' both data center validation qwk : {:0.4f}'.format(overall_qwk))\n\nprint('overall confusion matrix : ')\nprint(overall_confusion_mat)\nprint('Radboud confusion matrix : ')\nprint(rad_confusion_mat)\nprint('Karolinska confusion matrix : ')\nprint(kar_confusion_mat)\nprint('-'*20)","07db8125":"## hyper parameters\n\nSince Kaggle has 3 hours tpu limit, so for 40 epochs, this kernel need 2 runs to finish the model training.\nFirst run : TRAIN_EPOCHS->25, START_EPOCH->0, which means only train 25 epochs and the starting epoch of learning rate scheduler is 0\nSecond run : TRAIN_EPOCHS->15, START_EPOCH->26, continue the training from first run","6972d802":"## Prepare tfrecord files","c002f54e":"## Training\/Inference steps","9c824ced":"## TFRecordDataset\/augmentation","86d98800":"## Model","5bc988ee":"## Model evaluation","1e1ab2d2":"## TPU strategy scope (loss function\/learning scheduler\/metrics)"}}