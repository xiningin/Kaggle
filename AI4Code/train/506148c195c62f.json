{"cell_type":{"704fd25a":"code","79f32f65":"code","d6e0be45":"code","084c3bb3":"code","6e278c2f":"code","715e2fbc":"code","053de78b":"code","8f56f71b":"code","a65ed536":"code","bd3f8237":"code","0a877150":"code","40c68a2f":"code","ac57756e":"code","1c4430c0":"code","a9b7f6b4":"code","f5c60ee6":"code","5f99daf2":"code","e2c178aa":"code","d835d04e":"code","f2e01e8c":"code","8436dea0":"code","081d2bb8":"code","13667411":"code","230a8fc4":"code","9adba76f":"code","681619e6":"code","e99b54fc":"code","12edc4e3":"code","cea5370c":"code","faf928b6":"code","8a5a754c":"code","9fe2cdb8":"code","caea2a42":"code","57243b9b":"code","abf23adb":"code","c70ddccc":"code","b6a00552":"code","3f0b4b71":"code","f1cc77c0":"code","f4cf6db3":"code","c1735e36":"code","9f908134":"code","58f5ca44":"code","1a792779":"code","1d76b087":"code","9494cbbd":"code","1c1db8af":"code","8c2dd218":"code","6440a455":"code","d153d9ab":"code","75d6026f":"code","9fc659f1":"code","024b4297":"code","65ab8d87":"code","8244976e":"code","cfdc2931":"code","9349f15d":"code","f3f30159":"code","7ab58fa6":"code","b5ad7e3c":"code","4b16157b":"code","3b92febc":"code","7587ee35":"code","7aa2ef9e":"code","0f38f009":"code","b48fdf4f":"code","aff592fc":"code","2e671488":"code","26e73e8f":"code","ce566a50":"code","de6fadae":"code","406756e3":"code","3ec1cb14":"code","b9ee3518":"code","a1e893ba":"code","1aa048ab":"code","fb947df8":"code","4e4d0ca1":"code","53b9375f":"code","9abacc23":"code","77137802":"code","ea84b4cf":"code","592e3359":"code","db4cfd67":"code","6be90cf8":"code","72bd3b44":"code","d0056690":"code","48df66d7":"code","b62180c4":"code","d155d2cb":"code","24856632":"code","38edee1d":"code","460d000a":"code","00a617f7":"code","06ee528a":"code","3f29d8c6":"code","7ad629fd":"code","1d8e3d58":"code","96cd4876":"code","96c3685c":"code","7dbbefa7":"code","a2264f2c":"code","7a51024d":"code","02bb3d4f":"code","ee77cf0f":"code","5ec7573f":"code","0f751648":"code","3630cc65":"code","0a1ddbed":"code","64acff53":"code","95bd3359":"code","e94e4fcc":"code","806bb905":"code","bf80b001":"code","127ffbbd":"code","cd8676c5":"code","013d9017":"code","e0c97312":"code","bc33b7f0":"code","a94c5e20":"markdown","624f9e4c":"markdown","407508a7":"markdown","b05c552d":"markdown","fdc1403c":"markdown","f6f12d30":"markdown","286e2d32":"markdown","92b1f1d7":"markdown","6ac0603e":"markdown","2e7b0313":"markdown"},"source":{"704fd25a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","79f32f65":"pip install openpyxl","d6e0be45":"df=pd.read_excel('\/kaggle\/input\/retail-analysis\/all_data_copy.xlsx', parse_dates=['date'])","084c3bb3":"df.head() #first five ","6e278c2f":"df.tail() #last five ","715e2fbc":"df.shape # verified with given detan as same number of row and column in data","053de78b":"df.info()","8f56f71b":"df.isnull().sum()","a65ed536":"sd=df.copy(deep=True)","bd3f8237":"duplicate = df[df.duplicated()]\n  \nprint(\"Duplicate Rows :\")\nlen(duplicate)","0a877150":"duplicate = df[df.duplicated(keep = 'last')]\n  \nprint(\"Duplicate Rows :\")\n  \n# Print the resultant Dataframe\nduplicate","40c68a2f":"duplicate = df[df.duplicated(['Order ID'])]\n  \nprint(\"Duplicate Rows based on Name and Age :\")\n  \n# Print the resultant Dataframe\nduplicate","ac57756e":"sale=df.copy(deep=True)# making copy of dataframe","1c4430c0":"sale = sale.astype({\"Product\":'category',\"Order ID\":'category'})","a9b7f6b4":"sale['Price Each'] = pd.to_numeric(sale['Price Each'], errors='coerce')","f5c60ee6":"sale['Quantity Ordered'] = pd.to_numeric(sale['Quantity Ordered'], errors='coerce')","5f99daf2":"sale['Order Date'] =  pd.to_datetime(sale['Order Date'],errors ='coerce')","e2c178aa":"ef.value_counts()","d835d04e":"sale.isnull().sum()","f2e01e8c":"sale.rename({'Order ID': 'id', 'Quantity Ordered': 'qty','Price Each': 'price', 'Order Date': 'date','Purchase Address': 'address'}, axis=1, inplace=True)","8436dea0":"sale['dates'] = pd.to_datetime(sale['date']).dt.date\nsale['time'] = pd.to_datetime(sale['date']).dt.time","081d2bb8":"sale = sale.drop(['date'],axis=1)","13667411":"sale['dates'] =  pd.to_datetime(sale['dates'],errors ='coerce')","230a8fc4":"sale['time'] =  pd.to_datetime(sale['time'],errors ='coerce')","9adba76f":"sale[['Street', 'City', 'State']] = sale['address'].str.split(',', expand=True)","681619e6":"sale.head()","e99b54fc":"sale1=sale.copy(deep=True)","12edc4e3":"sale1[['state','zip']]=sale1.State.str.extract('(?P<state>.+?) (?P<zip>.+?\\S+)')","cea5370c":"sale1 = sale1.drop(['State','address','time'],axis=1)","faf928b6":"sale1.head()","8a5a754c":"sale1.info()","9fe2cdb8":"sale1['month'] = sale1['dates'].dt.month","caea2a42":"sale1['months'] = sale1['dates'].dt.to_period('M')","57243b9b":"sale1 = sale1.drop(['months'],axis=1)","abf23adb":"sale1 = sale1.drop(['month'],axis=1)","c70ddccc":"sale1.describe(include='all')","b6a00552":"sale1['yyyy'] = pd.to_datetime(sale1['dates']).dt.strftime('%Y')#final for separate month\nsale1['mm'] = pd.to_datetime(sale1['dates']).dt.strftime('%m')","3f0b4b71":"sale1['sales']=sale1['price']*sale1['qty']","f1cc77c0":"sale1.head()","f4cf6db3":"sale1.info()","c1735e36":"sale1.City.value_counts()","9f908134":"s_c_gp['Product'].count()","58f5ca44":"p_c_gp =sale1.groupby(['City','Product'],sort = False)","1a792779":"p1_c_gp =sale1.groupby(['Product','qty'],sort = False)","1d76b087":"p1_c_gp['City'].sum()","9494cbbd":"x23=p_c_gp['qty'].max()","1c1db8af":"x23.head(50)","8c2dd218":"m_c_gp =sale1.groupby(['mm'],sort = False)","6440a455":"s_c_gp =sale1.groupby(['City'],sort = False)","d153d9ab":"m_c_gp['sales'].sum().nlargest()","75d6026f":"m_c_gp['sales'].sum().nlargest().plot(kind='pie')","9fc659f1":"s_c_gp['sales'].sum().nlargest()","024b4297":"s_c_gp['sales'].sum().nlargest().plot(kind='pie')","65ab8d87":"x","8244976e":"sale,month,city","cfdc2931":"import seaborn as sns","9349f15d":"x.plot(kind='bar',figsize=(30, 10))","f3f30159":"%pylab inline\nimport matplotlib as mpl","7ab58fa6":"mpl.rc(\"figure\", figsize=(45, 10))\nsns.catplot(y='sales', x='mm', col='City',col_wrap=3 ,data=sale1, kind='bar')","b5ad7e3c":"er=df.copy(deep=True)","4b16157b":"ner=er[er.isna().any(axis=1)]","3b92febc":"ner","7587ee35":"er = er.dropna(how='all')","7aa2ef9e":"er['City'].value_counts()","0f38f009":"er.info()","b48fdf4f":"er=er[er['Order Date'].astype(str).str[0:2]!='Or']","aff592fc":"#er=er[er['Order Date'].str[0:2]!='Or']\n# jk.head()\ner['Month']=er['Order Date'].astype(str).str[5:7]\ner['Month']=er['Month'].astype('int32')\ner.head()","2e671488":"er['Price Each'] = pd.to_numeric(er['Price Each'], errors='coerce')\ner['Quantity Ordered'] = pd.to_numeric(er['Quantity Ordered'], errors='coerce')\ner['sales']=er['Price Each']*er['Quantity Ordered']","26e73e8f":"results = er.groupby('Month').sum()","ce566a50":"import matplotlib.pyplot as plt","de6fadae":"months=range(1,13)","406756e3":"\nplt.bar(months,results['sales'])","3ec1cb14":"er['Order Date']","b9ee3518":" er['O_D_T']=pd.to_datetime(er['Order Date'])","a1e893ba":"er['Hour']=er['O_D_T'].dt.hour","1aa048ab":"\ner.groupby('Hour')['Product'].unique()","fb947df8":"result1=er.groupby(er['Hour'])['Quantity Ordered'].count().plot()\nresult1","4e4d0ca1":"er","53b9375f":"ner = er[er['Order ID'].duplicated(keep=False)]\nner","9abacc23":"er.head(-50)","77137802":"df","ea84b4cf":"ner","592e3359":" er['Order Date']=pd.to_datetime(er['Order Date'],errors ='coerce')","db4cfd67":"sd['Price Each'] = pd.to_numeric(sd['Price Each'], errors='coerce')","6be90cf8":"er['Price Each'] = pd.to_numeric(er['Price Each'], errors='coerce')\ner['Quantity Ordered'] = pd.to_numeric(er['Quantity Ordered'], errors='coerce')\ner['sales']=er['Price Each']*er['Quantity Ordered']","72bd3b44":"er['Year'] = ['Order Date'].index.year\ner['Month'] = ['Order Date'].index.month\ner['Weekday Name'] = ['Order Date'].index.weekday_name","d0056690":"er[['Street', 'City', 'State']] = er['Purchase Address'].str.split(',', expand=True)","48df66d7":"er.info()","b62180c4":"products = df[['Product','Order ID']].copy()","d155d2cb":"products = products.set_index('Order ID')# Convert to Series for eve easier lookups\n","24856632":" pip install mlxtend ","38edee1d":"from mlxtend.frequent_patterns import apriori, association_rules","460d000a":"import apriori","00a617f7":"products = products.reset_index()","06ee528a":"from mlxtend.preprocessing import TransactionEncoder as te\n# fit the TransactionEncoder\nte.fit(products['Order ID'])\n# do the transformation\norders_1hot = transform(products['Order ID'])","3f29d8c6":"products","7ad629fd":"sd.head()","1d8e3d58":"sd.info()","96cd4876":"sd['Order Date'] = pd.to_datetime(sd['Order Date'],errors ='coerce') ","96c3685c":"sd['Date']=sd['Order Date'].dt.date","7dbbefa7":"sd['Order Date'].dt.time","a2264f2c":"sd['time']=sd['Order Date'].dt.strftime('%H:%M')","7a51024d":"sd[['Street', 'City', 'State']] = sd['Purchase Address'].str.split(',', expand=True)","02bb3d4f":"sd[['state','zip']]=sd.State.str.extract('(?P<state>.+?) (?P<zip>.+?\\S+)')","ee77cf0f":"sd = sd.drop(['Order Date','Purchase Address','Street','State','zip'],axis=1)","5ec7573f":"sd['year'] = pd.to_datetime(sd['Date']).dt.strftime('%Y')#final for separate month\nsd['month'] = pd.to_datetime(sd['Date']).dt.strftime('%m')","0f751648":"sd.info()","3630cc65":"sd = sd.astype({\"Product\":'category',\"Quantity Ordered\":'float','Price Each':'float'},errors ='ignore')","0a1ddbed":"sd['Price Each'] = pd.to_numeric(sd['Price Each'], errors='coerce')","64acff53":"sd['Quantity Ordered'] = pd.to_numeric(sd['Quantity Ordered'], errors='coerce')","95bd3359":"sd['sales']=sd['Price Each']*sd['Quantity Ordered']","e94e4fcc":"sd=sd.reset_index()","806bb905":"sd.head().round()","bf80b001":"sd.info()","127ffbbd":" sd['Date']=pd.to_datetime(sd['Date'])","cd8676c5":"trail = sd.copy(deep=True)","013d9017":"trail['time']","e0c97312":"trail['time'] = pd.to_numeric(trail['time'], errors='coerce')","bc33b7f0":"conditions = [\n    (trail['time'] >= '06:00') & (trail['time'] <= 12),\n    (trail['time'] >= 13) & (trail['time'] <= 16),\n    (trail['time'] >= 17) & (trail['time'] <= 20),\n    (trail['time'] >= 21) & (trail['time'] <= '05:00')\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['Moarning', 'Afternoon', 'Evening', 'Night']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ntrail['tier'] = np.select(conditions, values)\n\n# display updated DataFrame\ntrail.head()","a94c5e20":"only show object type of data need to retify futher.","624f9e4c":"What is the distribution of sales among different cities in different months?","407508a7":"simmilar number of null, so we can drop it all togather.","b05c552d":"Retail Analysis\nDataset Description:\nInstances: 3.73 Lakh\nFeatures: 6 columns\nNumerical: 4 columns\nCategorical: 2 columns\n\nAttribute Information:\n\nOrder ID: Order identification number for each product\nProduct: Product name\nQuantity Ordered: Amount of items\nPrice Each: Price of each product per item in dollars\nOrder Date: Date of purchase\nPurchase Address: Address of purchase order\nQuestions:","fdc1403c":"result1=er.groupby(er['Hour']).count","f6f12d30":"er.groupby('Product')","286e2d32":"## Retail Analysis\nDataset Description:\n\n    Instances: 3.73 Lakh\n    Features: 6 columns\n    Numerical: 4 columns\n    Categorical: 2 columns\n\nAttribute Information:\n\n\n* Order ID: Order identification number for each product\n* Product: Product name\n* Quantity Ordered: Amount of items\n* Price Each: Price of each product per item in dollars\n* Order Date: Date of purchase\n* Purchase Address: Address of purchase order\n","92b1f1d7":"### Find out the distribution of sales over different times of the day (Morning, Afternoon, Evening, Night) and answer the following for each city:","6ac0603e":"### Reading Excel File ","2e7b0313":"1. Load the dataset into pandas and provide a summary of columns in the loaded dataset without any modification.\n2. Prepare the data frame for further analysis. Clean it, mould it in any manner you see fit.\n3. Provide a summary of the cleaned dataset along with some preliminary analysis and contrast it with the uncleaned dataset wherever modifications are made.\n4. Answer the following questions using the clean dataset by plotting suitable graphs:\n    \n    What is the distribution of sales among different cities in different months?\n    \n    Which City had the highest sales overall?\n    \n    Which Month had the highest amount of sales overall?\n    \n    Most bought products per city.\n    \n    \n5. Based on your analysis, suggest a city for establishing a new branch for the retail store backed with proper reasoning.\n6. Find out the distribution of sales over different times of the day (Morning, Afternoon, Evening, Night) and answer the following for each city:\n7. What products are mostly sold at different times of the day?\n8. Which time of day has the most sales?\n9. Based on your analysis, suggest the best working hours and the best products for the retail stores in each city.\n10. Find out the pair of products that are most sold together. \n    For example, generally, we would expect a person who buys an iPhone 11 to also buy the Apple Airpods together with it. Identify such pairs of products and suggest what promotional offers should the retail company come up with based on your outcome."}}