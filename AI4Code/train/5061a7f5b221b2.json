{"cell_type":{"0f83d40e":"code","173caa58":"code","fa93aeda":"code","0ff9f326":"code","536adb11":"code","79f2dbd6":"code","6572c897":"code","3e5d32bd":"code","c9defdcd":"code","ac293e3b":"code","bae355f3":"code","633bf4f5":"code","fc39d617":"code","d1949edb":"code","2e47ebec":"code","f010d8d0":"code","6b8ebb47":"code","39d8e7ca":"code","bee83de5":"code","328937a0":"code","99fa67e3":"code","c41ed2b4":"code","5d5cf5bc":"code","c79880e7":"markdown","97771b23":"markdown","d95ce056":"markdown","20c0eb6a":"markdown","83057750":"markdown","8728b975":"markdown","201c6741":"markdown","63e5e7d0":"markdown","2810d705":"markdown"},"source":{"0f83d40e":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport skimage.io\nimport tensorflow \nimport tqdm\nimport glob\n\nfrom tqdm import tqdm \n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, Dense, Flatten, BatchNormalization, Dropout, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n%matplotlib inline","173caa58":"train_o = glob.glob('..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/*.jpg')\na = len(train_o)","fa93aeda":"train_r = glob.glob('..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/*.jpg')\nb = len(train_r)","0ff9f326":"# Total training images \n\nprint(\"Nos of training samples: {}\".format(a+b))","536adb11":"train_datagen = ImageDataGenerator(rescale = 1.0 \/ 255.0,\n                                   zoom_range = 0.4,\n                                   rotation_range = 10,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   validation_split = 0.2)\n\nvalid_datagen = ImageDataGenerator(rescale = 1.0 \/ 255.0,\n                                   validation_split = 0.2)\n\ntest_datagen  = ImageDataGenerator(rescale = 1.0 \/ 255.0)","79f2dbd6":"train_dataset  = train_datagen.flow_from_directory(directory = '..\/input\/waste-classification-data\/DATASET\/TRAIN',\n                                                   target_size = (224,224),\n                                                   class_mode = 'binary',\n                                                   batch_size = 128, \n                                                   subset = 'training')","6572c897":"valid_dataset = valid_datagen.flow_from_directory(directory = '..\/input\/waste-classification-data\/DATASET\/TRAIN',\n                                                  target_size = (224,224),\n                                                  class_mode = 'binary',\n                                                  batch_size = 128, \n                                                  subset = 'validation')","3e5d32bd":"# Class Indices \n\ntrain_dataset.class_indices","c9defdcd":"# Viewing Images\n\nfig, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (20,20))\n\nfor i in tqdm(range(5)):\n    rand1 = np.random.randint(len(train_dataset))\n    rand2 = np.random.randint(128)\n    ax[i].imshow(train_dataset[rand1][0][rand2])\n    ax[i].axis('off')\n    label = train_dataset[rand1][1][rand2]\n    if label == 1:\n        ax[i].set_title('Recycle Waste')\n    else:\n        ax[i].set_title('Organic Waste')","ac293e3b":"# Defining Model\n\nbase_model = VGG16(input_shape=(224,224,3), \n                   include_top=False,\n                   weights=\"imagenet\")","bae355f3":"# Freezing Layers \n\nfor layer in base_model.layers:\n    layer.trainable=False","633bf4f5":"# Summary\n\nbase_model.summary()","fc39d617":"# Defining Layers\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))","d1949edb":"# Summary\n\nmodel.summary()","2e47ebec":"# Model Compile \n\nOPT    = tensorflow.keras.optimizers.Adam(lr=0.001)\n\nmodel.compile(loss='binary_crossentropy',\n              metrics=[tensorflow.keras.metrics.AUC(name = 'auc')],\n              optimizer=OPT)","f010d8d0":"# Defining Callbacks\n\nfilepath = '.\/best_weights.hdf5'\n\nearlystopping = EarlyStopping(monitor = 'val_auc', \n                              mode = 'max' , \n                              patience = 5,\n                              verbose = 1)\n\ncheckpoint    = ModelCheckpoint(filepath, \n                                monitor = 'val_auc', \n                                mode='max', \n                                save_best_only=True, \n                                verbose = 1)\n\n\ncallback_list = [earlystopping, checkpoint]","6b8ebb47":"# Model Fitting \n\nmodel_history=model.fit(train_dataset,\n                        validation_data=valid_dataset,\n                        epochs = 10,\n                        callbacks = callback_list,\n                        verbose = 1)","39d8e7ca":"# Summarize the model loss\n\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\nplt.show()","bee83de5":"# Summarize models auc\n\nplt.plot(model_history.history['auc'])\nplt.plot(model_history.history['val_auc'])\nplt.title('Model AUC')\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\nplt.show()","328937a0":"# Test Data \n\ntest_data = test_datagen.flow_from_directory(directory = '..\/input\/waste-classification-data\/DATASET\/TEST',\n                                             target_size = (224,224),\n                                             class_mode = 'binary',\n                                             batch_size = 128)","99fa67e3":"# Evaluating Loss and AUC - Test Data \n\nmodel.evaluate(test_data)","c41ed2b4":"# Test Case:1 - ORGANIC\n\ndic = test_data.class_indices\nidc = {k:v for v,k in dic.items()}\n\nimg = load_img('..\/input\/waste-classification-data\/DATASET\/TEST\/O\/O_12650.jpg', target_size=(224,224))\nimg = img_to_array(img)\nimg = img \/ 255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\nanswer = model.predict_proba(img)\n\nif answer[0][0] > 0.5:\n    print(\"The image belongs to Recycle waste category\")\nelse:\n    print(\"The image belongs to Organic waste category \")","5d5cf5bc":"# Test Case:2 - RECYCLE\n\ndic = test_data.class_indices\nidc = {k:v for v,k in dic.items()}\n\nimg = load_img('..\/input\/waste-classification-data\/DATASET\/TEST\/R\/R_10011.jpg', target_size=(224,224))\nimg = img_to_array(img)\nimg = img \/ 255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\nanswer = model.predict_proba(img)\n\nif answer[0][0] > 0.5:\n    print(\"The image belongs to Recycle waste category\")\nelse:\n    print(\"The image belongs to Organic waste category \")","c79880e7":"### IMPORT DATASET ","97771b23":"# WASTE MANAGEMENT\n\nPROBLEM\n\nWaste management is a big problem in our country. Most of the wastes end up in landfills. This leads to many issues like\n\n* Increase in landfills\n* Eutrophication\n* Consumption of toxic waste by animals\n* Increase in toxins\n* Land, water and air pollution\n\nAPPROACH\n\n* Analysed the components of household waste\n* Segregated into two classes (Organic and recyclable)\n* Automated the process by using IOT and machine learning\n* Reduce toxic waste ending in landfills","d95ce056":"### MODEL EVALUATION","20c0eb6a":"> `1. We were able to classify images properly having accuracy of 97.00% in training dataset.`\n\n> `2. We acheived an accuracy of 95.60% on validation data and 94.98% accuracy on test accuracy.`","83057750":"> `TRAINING IMAGES`","8728b975":"### MODEL BUILDING","201c6741":"> `DATA AUGMENTATION`","63e5e7d0":"### IMPORT LIBRARIES","2810d705":"### CONCLUSION"}}