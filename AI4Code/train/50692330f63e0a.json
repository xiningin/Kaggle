{"cell_type":{"65209bf8":"code","0f08abc6":"code","bf5ffc77":"code","98c792a1":"code","15f95a69":"code","7acba9c7":"code","e2ebf31a":"code","c5667d2f":"code","07371c9b":"code","3479c78f":"code","faae4dd6":"code","10fb8705":"code","2853c6de":"code","4bf3b4a3":"code","0baa0455":"code","024d0311":"code","5394d3ae":"code","e4ee60eb":"code","30a8ec3b":"code","b981c6d3":"code","d8e4ae38":"code","aecf2861":"code","8bbf0521":"code","bcf91339":"code","d8f2e59e":"markdown","4275595d":"markdown","e40f7b53":"markdown","6f02f3ee":"markdown","812de937":"markdown","40c34bf1":"markdown","34750caf":"markdown","c86d2115":"markdown","fd3664d2":"markdown","36a320b3":"markdown","ebb831d2":"markdown","3f40fa68":"markdown","cdcefb52":"markdown","8a0c3b66":"markdown","5bfc6a71":"markdown","4d7ff0f1":"markdown","fd9dfff7":"markdown","3833d02b":"markdown","906cbd9e":"markdown","12dc8a1c":"markdown","162b8593":"markdown","6891a9b4":"markdown"},"source":{"65209bf8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","0f08abc6":"diabetes_data = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\n\n#Print the first 5 rows of the dataframe.\ndiabetes_data.head()","bf5ffc77":"diabetes_data.shape","98c792a1":"diabetes_data.describe()\n","15f95a69":"diabetes_data.info(verbose=True)","7acba9c7":"sns.countplot(x='Outcome',data=diabetes_data)\nplt.show()","e2ebf31a":"diabetes_data_copy = diabetes_data.copy(deep = True)\ndiabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(diabetes_data_copy.isnull().sum())","c5667d2f":"plt.style.use('classic')\nplot = diabetes_data.hist(figsize = (20,20))","07371c9b":"diabetes_data_copy['Glucose'].fillna(diabetes_data_copy['Glucose'].mean(), inplace = True)\ndiabetes_data_copy['BloodPressure'].fillna(diabetes_data_copy['BloodPressure'].mean(), inplace = True)\ndiabetes_data_copy['SkinThickness'].fillna(diabetes_data_copy['SkinThickness'].median(), inplace = True)\ndiabetes_data_copy['Insulin'].fillna(diabetes_data_copy['Insulin'].median(), inplace = True)\ndiabetes_data_copy['BMI'].fillna(diabetes_data_copy['BMI'].median(), inplace = True)","3479c78f":"diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] =diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(diabetes_data_copy.isnull().sum())","faae4dd6":"plot = diabetes_data_copy.hist(figsize = (20,20))\n","10fb8705":"\nsns.pairplot(diabetes_data )","2853c6de":"sns.pairplot(data=diabetes_data_copy,hue='Outcome',diag_kind='kde', kind=\"reg\")\nplt.show()","4bf3b4a3":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\nax = sns.heatmap(diabetes_data.corr(), xticklabels=2, annot=True ,yticklabels=False)","0baa0455":"from pandas_profiling import ProfileReport \n\nprofile = ProfileReport(diabetes_data.corr(), title='Pandas profiling report ' , html={'style':{'full_width':True}})\n\nprofile.to_notebook_iframe()","024d0311":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(diabetes_data_copy.drop([\"Outcome\"],axis = 1),),\n        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])\nX.head()","5394d3ae":"y = diabetes_data_copy.Outcome","e4ee60eb":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1\/3,random_state=42, stratify=y)","30a8ec3b":"# Import Libraries\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying VotingClassifier Model \n\n'''\n#ensemble.VotingClassifier(estimators, voting=\u2019hard\u2019, weights=None,n_jobs=None, flatten_transform=None)\n'''\n\n#loading models for Voting Classifier\nLRModel_ = LogisticRegression(solver='lbfgs', multi_class='multinomial',random_state=33)\nRFModel_ = RandomForestClassifier(n_estimators=100, criterion='gini',max_depth=5, random_state=33)\nKNNModel_ = KNeighborsClassifier(n_neighbors= 10, weights ='uniform', algorithm='auto')\nNNModel_ = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1000, 20),learning_rate='constant',activation='relu', power_t=0.4, max_iter=250)\n\n#loading Voting Classifier\nVotingClassifierModel = VotingClassifier(estimators=[('LRModel',LRModel_),('RFModel',RFModel_),('KNNModel',KNNModel_),('NNModel',NNModel_)], voting= 'soft')\nVotingClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('VotingClassifierModel Train Score is : ' , VotingClassifierModel.score(X_train, y_train))\nprint('VotingClassifierModel Test Score is : ' , VotingClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n","b981c6d3":"y_pred = VotingClassifierModel.predict(X_test)\nprint('Predicted Value for VotingClassifierModel is : ' , y_pred[:10])","d8e4ae38":"\n#Calculating Confusion Matrix\n\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"BuPu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","aecf2861":"#Import Libraries\nfrom sklearn.metrics import accuracy_score\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccScore = accuracy_score(y_test, y_pred, normalize=False)\nprint('Accuracy Score is : ', AccScore)","8bbf0521":"#Import Libraries\nfrom sklearn.metrics import f1_score\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating F1 Score  : 2 * (precision * recall) \/ (precision + recall)\n# f1_score(y_true, y_pred, labels=None, pos_label=1, average=\u2019binary\u2019, sample_weight=None)\n\nF1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('F1 Score is : ', F1Score)","bcf91339":"from sklearn.metrics import roc_curve\ny_pred_proba = VotingClassifierModel.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('VotingClassifierModel ROC curve')\nplt.show()","d8f2e59e":"Plotting after Nan removal","4275595d":"It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values","e40f7b53":"\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/","6f02f3ee":"DataFrame.describe() method generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution, excluding NaN values. This method tells us a lot of things about a dataset. One important thing is that the describe() method deals only with numeric values. It doesn't work with any categorical values. So if there are any categorical values in a column the describe() method will ignore it and display summary for the other columns unless parameter include=\"all\" is passed.\n\nNow, let's understand the statistics that are generated by the describe() method:\n\n* count tells us the number of NoN-empty rows in a feature.\n* mean tells us the mean value of that feature.\n* std tells us the Standard Deviation Value of that feature.\n* min tells us the minimum value of that feature.\n* 25%, 50%, and 75% are the percentile\/quartile of each features. This quartile information helps us to detect Outliers.\n* max tells us the maximum value of that feature.","812de937":"Scaling the data\n\ndata Z is rescaled such that \u03bc = 0 and \ud835\uded4 = 1, and is done through this formula:\n\n\n![image.png](attachment:image.png)","40c34bf1":"pandas_profiling library\nGenerates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n\nFor each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n\nType inference: detect the types of columns in a dataframe.\n* Essentials: type, unique values, missing values\n* Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n* Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n* Most frequent values\n* Histogram\n* Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n* Missing values matrix, count, heatmap and dendrogram of missing values\n* Text analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.","34750caf":"On these columns, a value of zero does not make sense and thus indicates missing value.\n\nFollowing columns or variables have an invalid zero value:\n\n1. Glucose\n2. BloodPressure\n3. SkinThickness\n4. Insulin\n5. BMI","c86d2115":"First we import the main libraries","fd3664d2":"###### #Calculating Prediction\n","36a320b3":"Heatmap for unclean data","ebb831d2":"It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values","3f40fa68":"import Dataset","cdcefb52":"\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/","8a0c3b66":"Scatter matrix of uncleaned data","5bfc6a71":"# IDF Diabetes Atlas Eighth Edition 2019\n![image.png](attachment:image.png)\n\nThis link contains the complete picture clearly https:\/\/diabetesatlas.org\/upload\/resources\/material\/20191218_144459_2019_global_factsheet.pdf\n\nFor reference\nhttps:\/\/diabetesatlas.org\/en\/resources\/","4d7ff0f1":"Pair plot for clean data","fd9dfff7":"Aiming to impute nan values for the columns in accordance with their distribution","3833d02b":"Here I would like to clarify something very important\n\nPearson's Correlation Coefficient: helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.\n\nA heat map is a two-dimensional representation of information with the help of colors. Heat maps can help the user visualize simple or complex information.","906cbd9e":"https:\/\/seaborn.pydata.org\/search.html?q=cmap&check_keywords=yes&area=default\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.VotingClassifier.html\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html\nhttps:\/\/towardsdatascience.com\/visualizing-data-with-pair-plots-in-python-f228cf529166\nhttps:\/\/www.kaggle.com\/shrutimechlearn\/step-by-step-diabetes-classification-knn-detailed","12dc8a1c":"#  Basic EDA and statistical analysis","162b8593":"# Introduction\nDiabetes is a serious, long-term condition with a major impact on the lives and well-being of individuals, families, and societies worldwide. It is among the top 10 causes of death in adults, and was estimated to have caused four million deaths globally in 2017 [1]. In 2017\n\nhe global diabetes prevalence in 2019 is estimated to be 9.3% (463 million people), rising to 10.2% (578 million) by 2030 and 10.9% (700 million) by 2045. The prevalence is higher in urban (10.8%) than rural (7.2%) areas, and in high-income (10.4%) than low-income countries (4.0%). One in two (50.1%) people living with diabetes do not know that they have diabetes. The global prevalence of impaired glucose tolerance is estimated to be 7.5% (374 million) in 2019 and projected to reach 8.0% (454 million) by 2030 and 8.6% (548 million) by 2045\n\nFor reference\n\nhttps:\/\/www.diabetesresearchclinicalpractice.com\/article\/S0168-8227(19)31230-6\/fulltext","6891a9b4":"The above graph shows that the data is biased towards datapoints having outcome value as 0 where it means that diabetes was not present actually. The number of non-diabetics is almost twice the number of diabetic patients"}}