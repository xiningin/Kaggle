{"cell_type":{"7fc32723":"code","5bb8afcb":"code","c66d2d7d":"code","9fa14cfa":"code","46f55917":"code","1daf76b3":"code","97c20095":"code","d6413764":"code","899e7071":"code","68c6b2f0":"code","0cfbc526":"code","e308d6c1":"code","1b96d1f6":"code","c54d2313":"code","f2a11c1e":"code","b820b765":"code","a02cf9b1":"markdown"},"source":{"7fc32723":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5bb8afcb":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","c66d2d7d":"# Doing Data Augmentation On Training Data\ntrain_gen = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=90,\n    height_shift_range=0.2,\n    width_shift_range=0.2,\n    validation_split=0.1)\n\ntest_gen = ImageDataGenerator(rescale=1.\/255)","9fa14cfa":"train = train_gen.flow_from_directory(\n    directory = '..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/train',\n    batch_size = 64,\n    class_mode = 'categorical',\n    target_size = (300,300)\n)\n\ntest = test_gen.flow_from_directory(\n    directory = '..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/test',\n    batch_size = 64,\n    class_mode = 'categorical',\n    target_size = (300,300)\n)","46f55917":"for data_batch, labels_batch in train:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","1daf76b3":"def plot_image (image):\n  fig,axes = plt.subplots(1,5,figsize=(20,20))\n  axes = axes.flatten()\n  for img , ax in zip(image , axes):\n    ax.imshow(img) \n  plt.tight_layout()\n  plt.show()","97c20095":"plot_image(train[0][0])","d6413764":"from tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers","899e7071":"model = models.Sequential([\n        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3) , activation='relu' , input_shape=(300, 300, 3)),\n        tf.keras.layers.MaxPool2D((2,2)),\n        tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5) , activation='relu'),\n        tf.keras.layers.MaxPool2D((2,2)),\n        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3) , activation='relu'),\n        tf.keras.layers.MaxPool2D((2,2)),\n        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3) , activation='relu'),\n        tf.keras.layers.MaxPool2D((2,2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n","68c6b2f0":"model.summary()","0cfbc526":"model.compile(loss='categorical_crossentropy',\n            optimizer=optimizers.Adam(),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train,\n      #steps_per_epoch=128,\n      epochs=15,\n      validation_data=test\n      #validation_steps=128\n      )","e308d6c1":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","1b96d1f6":"from keras.preprocessing import image\ndef predictor(location):\n    test_image=image.load_img(location,target_size=(300,300))\n    test_image=image.img_to_array(test_image)\n    test_image=np.expand_dims(test_image, axis=0)\n    result=model.predict(test_image)\n    if result[0][0] == 1:\n        prediction = \"It is a paper\"\n    elif result[0][1] == 1:\n        prediction = \"It is a rock\"\n    else:\n        prediction =\"It is a scissor\"\n    return prediction","c54d2313":"path = '..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation'\npathes = []\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        pathes.append(os.path.join(dirname, filename))","f2a11c1e":"for i in pathes:\n    print(i , \" :\" , predictor(i))","b820b765":"model.save('Paper_Scisor_Rock.h5')","a02cf9b1":"for layer in model.layers[-5:]:\n    layer.trainable = True"}}