{"cell_type":{"134c41f9":"code","edd31eed":"code","73be5d6b":"code","3d82a19d":"code","1b31e9f7":"code","eca0ba45":"code","0ab3f515":"code","e3d96f4d":"code","e8d28b53":"code","973db3ca":"code","637a49f1":"code","399662fc":"code","a67b6339":"code","9a3b3b2e":"code","bcd53a1d":"code","360bcd77":"code","7fe78bd9":"code","4f4de8b2":"code","126e3895":"code","953a88ff":"code","e43577e9":"code","36e9acf2":"code","7b7ab363":"code","acd36014":"code","1a460d7a":"code","2e347279":"code","f2560525":"code","c886d7e5":"code","15cd73a0":"code","ffdab798":"code","c286c02f":"markdown","ba05fec3":"markdown","53622ac9":"markdown","92daffbc":"markdown","fc3b5a39":"markdown","b62cfb6b":"markdown","f4b7bd18":"markdown","e451288a":"markdown","29bbaa73":"markdown","157af43a":"markdown"},"source":{"134c41f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","edd31eed":"from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","73be5d6b":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntrain_df[\"data_type\"]=\"train\"\ntest_df[\"data_type\"]=\"test\"\n","3d82a19d":"train_df[train_df[\"Sex\"] == \"female\"].groupby(\"Survived\").count()","1b31e9f7":"#cabin \u00fczerinden incelemeler\n#df = train_data[[\"Cabin\",\"Survived\"]]\n#df2 = pd.get_dummies(df[\"Survived\"])\n#df = df.merge(df2,left_index=True, right_index=True)\n#df.drop(\"Survived\",axis=\"columns\",inplace=True)\n#df.columns = [\"Cabin\",\"Survived_0\",\"Survived_1\"]\n#df[\"Cabin\"]=df[\"Cabin\"].str.slice(stop=1)\n#dfg = df.groupby('Cabin')[\"Survived_0\",\"Survived_1\"].agg('sum')\n#dfg[\"Ort_0\"] = dfg[\"Survived_0\"]\/(dfg[\"Survived_0\"]+dfg[\"Survived_1\"])\n#dfg\n#cabin numaralar\u0131n\u0131 kald\u0131r\u0131p sadece kabin harferine g\u00f6re i\u015flem yapmaya karar verdik","eca0ba45":"train_df[\"Cabin\"]","0ab3f515":"train_df.isnull().sum()","e3d96f4d":"train_df.shape","e8d28b53":"test_df.shape","973db3ca":"full_data = pd.concat([train_df, test_df],ignore_index=True)\nfull_data.shape","637a49f1":"full_data[\"Cabin\"]= full_data[\"Cabin\"].str.slice(stop=1)\nfull_data[\"Cabin\"].fillna(\"U\",inplace=True)\n\nfull_data[\"IsaChild\"]  = np.where(full_data[\"Parch\"]>0, 1, 0)\nfull_data[\"Family_Mem\"]=full_data[\"SibSp\"]+full_data[\"Parch\"]+1\n\nfull_data[\"Family_Mem\"]=full_data[\"SibSp\"]+full_data[\"Parch\"]+1\nfull_data.drop([\"SibSp\",\"Parch\"],axis=\"columns\",inplace=True)\n\nfull_data[\"Fare_By_Person\"]= full_data[\"Fare\"] \/ full_data[\"Family_Mem\"]\nfull_data.drop(\"Fare\",axis=\"columns\",inplace=True)\n\nfull_data[\"Age\"].fillna(-5,inplace=True)","399662fc":"bins_age =      [-np.inf,0, 1, 4, 8, 12, 18,30, 50, 70, np.inf]\ngrp_names_age = ['u','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h','l']\nfull_data['Age_Grp'] = pd.cut(full_data['Age'], bins_age ,labels=grp_names_age)\nsns.barplot(x=\"Age_Grp\", y=\"Survived\", data=full_data, palette='Set3')","a67b6339":"full_data.groupby(\"Age_Grp\").count()","9a3b3b2e":"bins_fare = [-1, 3, 6, 10, 25, 60, 150, np.inf]\ngrp_name_fare = ['a', 'b','c', 'd', 'e', 'f','g']\nfull_data['Fare_Grp'] = pd.cut(full_data['Fare_By_Person'], bins_fare ,labels=grp_name_fare)\nsns.barplot(x=\"Fare_Grp\", y=\"Survived\", data=full_data, palette='Set3');","bcd53a1d":"full_data.groupby(\"Fare_Grp\").count()","360bcd77":"bins_fam = [0,1,3,np.inf]\ngrp_name_fam = ['a', 'b','c']\nfull_data['Family_Size_Grp'] = pd.cut(full_data['Family_Mem'], bins_fam ,labels=grp_name_fam)\nsns.barplot(x=\"Family_Size_Grp\", y=\"Survived\", data=full_data, palette='Set3');","7fe78bd9":"full_data.groupby(\"Family_Size_Grp\").count()","4f4de8b2":"full_data['Title'] = full_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n#train_data['Title'].unique()\n# Replacing some titles with common use \ntitle_mapping = {'Mlle': 'Miss', \n           'Ms': 'Miss', \n           'Mme': 'Mrs',\n           'Major': 'Other', \n           'Col': 'Other', \n           'Dr' : 'Other', \n           'Rev' : 'Other',\n           'Capt': 'Other', \n           'Jonkheer': 'Royal',\n           'Sir': 'Royal', \n           'Lady': 'Royal', \n           'Don': 'Royal',\n           'Countess': 'Royal', \n           'Dona': 'Royal'}\nfull_data.replace({'Title': title_mapping}, inplace=True)\nsns.barplot(x=\"Title\", y=\"Survived\", data=full_data, palette='Set3');","126e3895":"full_data.groupby(\"Title\").count()","953a88ff":"target_feature = [\"Survived\"]\n#num_features=[\"Family_Mem\"]\ncat_features = [\"Pclass\",\"Sex\",\"Cabin\",\"Embarked\",\"Age_Grp\",\"Fare_Grp\",\"Title\",\"Family_Size_Grp\",\"IsaChild\"]\njoin_data = full_data[[\"data_type\"]]\ncat_pivot_data = pd.get_dummies(full_data[cat_features])\n#num_data = train_data[num_features]\ny_full = train_df[target_feature]\n\n#train_data_full = num_data.merge(cat_pivot_data,left_index=True, right_index=True)\ncat_pivot_data = join_data.merge(cat_pivot_data,left_index=True, right_index=True)","e43577e9":"cat_pivot_data.columns","36e9acf2":"cat_pivot_data.drop([\"Age_Grp_u\",\"Fare_Grp_a\",\"Family_Size_Grp_a\",\"Title_Other\",\"Sex_male\",\"Cabin_U\"],axis=1,inplace=True)\n# kategorik de\u011fi\u015fkenlerde olarak bu kolonlar\u0131n olmas\u0131na gerek yok\n# We dont need these columns. ","7b7ab363":"cat_pivot_data.columns","acd36014":"cat_pivot_data.groupby(\"data_type\").count()","1a460d7a":"train_data_full=cat_pivot_data[cat_pivot_data[\"data_type\"]==\"train\"]\ntest_data_full=cat_pivot_data[cat_pivot_data[\"data_type\"]==\"test\"]\n\ntrain_data_full.drop(\"data_type\",axis=1,inplace=True)\ntest_data_full.drop(\"data_type\",axis=1,inplace=True)\n\ntrain_X,val_X,train_y,val_y = train_test_split(train_data_full,y_full, random_state=1)","2e347279":"print(train_data_full.shape)\nprint(test_data_full.shape)","f2560525":"rf_params = {\"max_depth\": [3,4,8,10,14],\n            \"max_features\": [7,18,19,25],\n            \"n_estimators\": [100,120,140,200],\n            \"min_samples_split\": [2,5,6,7,8,10]}\n\nrf_model = RandomForestClassifier()\nrf_cv_model = GridSearchCV(rf_model, rf_params, cv=5,n_jobs = -1,verbose = 2)\nrf_cv_model.fit(train_X,train_y.values.ravel())\n\nprint(\"En iyi skor:\" + str(rf_cv_model.best_score_))\nprint(\"En iyi parametreler: \" + str(rf_cv_model.best_params_))","c886d7e5":"y_pred = rf_cv_model.predict(val_X)\nprint(\"Accuracy : \", accuracy_score(val_y, y_pred),\"\\nMEA      : \",mean_absolute_error(val_y, y_pred))","15cd73a0":"## I change the paramater value manuelu and get better score. \n\nrf_model_man = RandomForestClassifier(n_estimators=200, \n                                  max_depth=3,\n                                  max_features=19,\n                                  min_samples_split=5)\nrf_model_man.fit(train_X,train_y)\n\ny_pred = rf_model_man.predict(val_X)\nprint(\"Accuracy : \", accuracy_score(val_y, y_pred),\"\\nMEA      : \",mean_absolute_error(val_y, y_pred))","ffdab798":"predicts = rf_model_man.predict(test_data_full)\ntest_data_df2 = full_data[full_data[\"data_type\"] ==\"test\"]\n\noutput = pd.DataFrame({'PassengerId': test_data_df2.PassengerId, 'Survived': predicts})\noutput\n\noutput.to_csv('my_submission_5.csv', index=False)\nprint(\"Your submission was successfully saved!\")","c286c02f":"## parametre ayarlar\u0131 daha iyi sonu\u00e7 i\u00e7in de\u011fi\u015ftirilebilir.\n## Parameter values should change for better score","ba05fec3":"## Cat Boosting","53622ac9":"lgbm_params = {\n        'n_estimators': [20,40,50,100, 500],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6,12],\n        'learning_rate': [0.1, 0.01, 0.02, 0.05],\n        \"min_child_samples\": [5, 10, 20]\n}\n\nfrom lightgbm import LGBMClassifier\nlgbm = LGBMClassifier()\nlgbm_cv_model = GridSearchCV(lgbm,lgbm_params,cv=5,n_jobs=-1,verbose=2)\nlgbm_cv_model.fit(train_X,train_y.values.ravel())\nlgbm_cv_model.best_params_","92daffbc":"y_pred = catb_cv_model.predict(val_X)\nprint(\"Accuracy : \", accuracy_score(val_y, y_pred),\"\\nMEA      : \",mean_absolute_error(val_y, y_pred))","fc3b5a39":"## Test verilerinin Dosyaya yaz\u0131lmas\u0131","b62cfb6b":"catb_params = {\n    'iterations': [100,200,500],\n    'learning_rate': [0.01,0.05, 0.1,0.2],\n    'depth': [3,5,8,12] }\n\ncatb = CatBoostClassifier()\ncatb_cv_model = GridSearchCV(catb, catb_params, cv=5, n_jobs = -1, verbose = 2)\ncatb_cv_model.fit(train_X, train_y.values.ravel())\n\ncatb_cv_model.best_params_","f4b7bd18":"## istenirse a\u015fa\u011f\u0131daki modellerde kullan\u0131labilir","e451288a":"## Random Forest & Tuning","29bbaa73":"y_pred = lgbm_cv_model.predict(val_X)\nprint(\"Accuracy : \",accuracy_score(val_y,y_pred),\"\\nMEA      :\",mean_absolute_error(val_y,y_pred))","157af43a":"## Light GBM"}}