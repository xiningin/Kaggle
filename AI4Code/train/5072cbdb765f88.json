{"cell_type":{"44f15947":"code","9029b577":"code","cbf4bb0b":"code","0f4e7a14":"code","5e45a4e0":"code","cfa7616a":"code","e54b45d4":"code","dc7d185d":"code","00d1274b":"code","ca6f4b94":"code","44695b0d":"code","e7e3f6a3":"code","f19506e4":"code","e9dfab1a":"code","e8e2bbe7":"code","81bf33e0":"code","d8936681":"code","0b36a574":"code","06f5ab03":"code","efdf147b":"code","a13bfdfa":"code","35873b83":"code","08cb267c":"code","958eac2f":"code","1418707b":"code","b6c7a300":"code","c302d837":"markdown","1ec7c86a":"markdown","a54dc755":"markdown","7763a94c":"markdown","3f99d5fd":"markdown","0aea0bef":"markdown","098ccbca":"markdown","3a7ad06e":"markdown","b3b125ab":"markdown","4c89d955":"markdown","0cd425d3":"markdown","39e435b5":"markdown","92f3a4d8":"markdown","afda39b1":"markdown","ccc89620":"markdown","7bfa312e":"markdown","0278bda3":"markdown"},"source":{"44f15947":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9029b577":"dir = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\nlabel = []\npath = []\nfor dirname, _,filenames in os.walk(dir):\n    for filename in filenames:\n        if os.path.splitext(filename)[1]=='.png':\n            if dirname.split()[-1]!='GT':          \n                label.append(os.path.split(dirname)[1])\n                path.append(os.path.join(dirname,filename))\n\ndf = pd.DataFrame(columns=['path','label'])\ndf['path']=path\ndf['label']=label","cbf4bb0b":"df.head()","0f4e7a14":"df.info()","5e45a4e0":"df['label']=df['label'].astype('category')","cfa7616a":"df['label'].value_counts()","e54b45d4":"import matplotlib.pyplot as plt\nimport seaborn as sns","dc7d185d":"df['label'].unique()","00d1274b":"fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15,8), constrained_layout=True)\nax=ax.flatten()\nj=0\nfor i in df['label'].unique():\n    \n    ax[j].imshow(plt.imread(df[df['label']==i].iloc[0,0]))\n    ax[j].set_title(i)\n    j=j+1","ca6f4b94":"fig=plt.figure(figsize=(15,8))\nsns.countplot(df['label'])","44695b0d":"plt.imread(df['path'][1]).shape","e7e3f6a3":"\nfrom sklearn.model_selection import train_test_split\nX_train, X_test=train_test_split(df, test_size=0.2, random_state=42)","f19506e4":"print(X_train.shape)\nprint(X_test.shape)","e9dfab1a":"from tensorflow.keras.applications import ResNet50V2, MobileNetV2\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrainGen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.3)\ntestGen =ImageDataGenerator(preprocessing_function= preprocess_input)\nX_train_img = trainGen.flow_from_dataframe(dataframe=X_train, x_col='path', y_col='label',class_mode='categorical', subset='training', color_mode='rgb', batch_size=32)\nX_val_img = trainGen.flow_from_dataframe(dataframe=X_train, x_col='path', y_col='label',class_mode='categorical', subset='validation', color_mode='rgb', batch_size=32)\nX_test_img =testGen.flow_from_dataframe(dataframe=X_test, x_col='path', y_col='label',class_mode='categorical', color_mode='rgb', batch_size=32, shuffle=False)","e8e2bbe7":"fit, ax= plt.subplots(nrows=2, ncols=3, figsize=(15,8))\nax=ax.flatten()\nj=0\nfor _ in range(6):\n    img, label = X_test_img.next()\n    #print(img.shape)   #  (1,256,256,3)\n    ax[j].imshow(img[0],)\n    ax[j].set_title(label[0])\n    #plt.show()\n    j=j+1","81bf33e0":"X_test_img[0][0].shape","d8936681":"image_shape=(256,256,3)","0b36a574":"X_train_img.class_indices","06f5ab03":"X_val_img.class_indices","efdf147b":"X_test_img.class_indices","a13bfdfa":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\npre_trained= MobileNetV2(include_top=False, pooling='avg', input_shape=image_shape)\n\n#for layers in pre_trained.layers:\n#    layers.trainable=False\npre_trained.trainable=False\n\ninp_model = pre_trained.input\n#x=Flatten()(pre_trained.output)\nx=Dense(128, activation='relu')(pre_trained.output)\nx=Dropout(0.5)(x)\nx=Dense(128, activation='relu')(x)\noutput=Dense(9, activation='softmax')(x)\nmodel = Model(inputs=inp_model, outputs=output)\n\n\n\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='val_loss',patience=1)\n\nresults = model.fit(X_train_img,epochs=30,\n                              validation_data=X_val_img,\n                                callbacks=[early_stop])\n","35873b83":"result=pd.DataFrame(results.history)\nfig, ax=plt.subplots(nrows=1, ncols=2,figsize=(18,6))\nax=ax.flatten()\nax[0].plot(result[['accuracy','val_accuracy']])\nax[0].set_title(\"Accuracy\")\nax[1].plot(result[['loss','val_loss']])\nax[1].set_title(\"Loss\")\n","08cb267c":"pred = model.predict(X_test_img)\npred=np.argmax(pred,axis=1)","958eac2f":"pred_df=X_test.copy()\nlabels={}\nfor l,v in X_test_img.class_indices.items():\n    labels.update({v:l})\npred_df['pred']=pred\npred_df['pred']=pred_df['pred'].apply(lambda x: labels[x])\n    ","1418707b":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nprint(f\"Accuracy Score: {accuracy_score(pred_df['label'],pred_df['pred'])}\")\nsns.heatmap(confusion_matrix(pred_df['label'],pred_df['pred']), annot=True, fmt='2d')","b6c7a300":"print(pred_df[pred_df['label']==pred_df['pred']].head(6))\nfig, ax=plt.subplots(nrows=2, ncols=3, figsize=(15,8))\nax=ax.flatten()\nimlist=pred_df[pred_df['label']==pred_df['pred']].head(6).reset_index()\nfor i in range(0,6):\n    ax[i].imshow(plt.imread(imlist['path'][i]))\n    ax[i].set_title(imlist['label'][i])","c302d837":"There are 9 category of fishes and each are unifromly distrubuted. so no prob on imbalance in the data","1ec7c86a":"Converting the \"label\" column as category type","a54dc755":"![](https:\/\/www.mcgill.ca\/oss\/files\/oss\/styles\/hd\/public\/fish_2.jpg?itok=tiod_UxK&timestamp=1582137895)","7763a94c":"Generating Dataframe with image path and label","3f99d5fd":"### Plotting image after preprocessing","0aea0bef":"# Read Dataset","098ccbca":"#### **Problem Statement**: we have been provided with image data set of different categorical fishes. objective is to create a model that identifies the fish category based on the picture. ","3a7ad06e":"# Train Test split","b3b125ab":"## Creating the image dataset using Tensorflow \n### we are using resnet_v2 preprocessing step to check if we can use Reset model in trasform learning","4c89d955":"# Exploratory Data Analysis","0cd425d3":"**Let us try plot the 1 sample image from each category**","39e435b5":"#### I have tried with Conv2d, Resenet & Mobilenet. MobileNet provides more accuracy than other models. ","92f3a4d8":"# Tensorflow Model\n#### MobileNet Transfer learning\nI tried with both Resnet & MobileNet, MobileNet gives better accuracy result","afda39b1":"Please review and provide yout comments for further improvements. ","ccc89620":"DataFrame is create with 2 colmuns, \n1. path will have the paths to impage in the folder \n2. Label will have the corresponding label name for the image","7bfa312e":"#### Lets check the classes are appropriate in both Test & Train dataset","0278bda3":"# Model Prediction"}}