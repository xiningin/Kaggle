{"cell_type":{"5f97f62a":"code","706b3a0d":"code","ffc9401e":"code","fc3f3d24":"code","e52e6a27":"code","8117f120":"code","2e55a27b":"code","2437be8c":"code","3c780147":"code","d6afb937":"code","4d0216b8":"code","ca49025c":"code","bf5d5b4f":"code","46d4854d":"code","a7668336":"code","2dde8fbb":"code","f524fa53":"code","6998a636":"code","d95ea72b":"code","6053776b":"markdown","3c9eb580":"markdown","0041a400":"markdown","a70e2d96":"markdown","0f83626b":"markdown","2af7e734":"markdown","74c4d858":"markdown","9671a1f0":"markdown","aa420611":"markdown"},"source":{"5f97f62a":"import os # operation system variables\nimport gc \n\nimport numpy as np\nimport pandas as pd\nimport feather\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler # data preprocessing\nfrom sklearn.pipeline import make_pipeline # additionals modules\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras # nn modeling\nfrom tensorflow.keras import layers\nimport tensorflow as tf\n","706b3a0d":"import warnings \nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #suppressing GPU warnings\nos.environ[\"CUDA_VISIBLE_DEVICES\"]='1'# GPU using on","ffc9401e":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","fc3f3d24":"tf.debugging.set_log_device_placement(True)\n\n# Create some tensors\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\n\nprint(c)","e52e6a27":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n#                 elif\n\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","8117f120":"%%time\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv', index_col='id')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv', index_col='id')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","2e55a27b":"%%time\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","2437be8c":"train.info()","3c780147":"y = train.pop('target')\nsubmission_index = test.index\nfeatures = list(train.columns)","d6afb937":"numerical_transformer = make_pipeline(\n    StandardScaler(), #Standardization\n    MinMaxScaler(),    #Normalization\n)\n\npreprocessor = make_column_transformer(\n    (numerical_transformer, features), #since all features are numerical\/continous\n)\n\ntrain = preprocessor.fit_transform(train)\ntest = preprocessor.transform(test)","4d0216b8":"x_train, x_val, y_train, y_val = train_test_split(train, y, test_size=0.33)","ca49025c":"input_shape = [x_train.shape[1]]\nPATIENCE = 10\nMIN_DELTA = 0.0005\n\nmodel = keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(units=166, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(units=100, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(units=50, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(units=1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n\n#early_stopping = keras.callbacks.EarlyStopping( # it's important feature to stop our training procedure early\n#    patience=PATIENCE,\n#    min_delta=MIN_DELTA,\n#    restore_best_weights=True,\n#)","bf5d5b4f":"model.summary()","46d4854d":"%%time\n\nBATCH_SIZE = 128\nEPOCHS = 40\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_data=(x_val, y_val),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    #callbacks=[early_stopping], \n    verbose=1 # we need it to control ou NN training\n)","a7668336":"%%time\ny_pred_f = model.predict(test).ravel()","2dde8fbb":"y_pred_f ","f524fa53":"#y_pred_f = np.array([1 if x>=0.5 else 0 for x in y_pred_f])","6998a636":"#y_pred_f ","d95ea72b":"sub['target'] = y_pred_f\nsub.to_csv('submission.csv', index = 0)\nsub","6053776b":"Here we do preprocessing: standartization and normalization. \nWe have to do same operation with test data as train data.","3c9eb580":"## Modules","0041a400":"## 5. Results\n\nPredict our results and save them to `submission.csv`","a70e2d96":"Here we activate GPU and swithc off warnings.","0f83626b":"## 2. Utils\n\nWe use only one util to reduce memory usage.","2af7e734":"# TPS November: simple Keras NN + GPU\n\nThis notebook work with simple Keras NN with GPU.\n\nNotebook plan:\n\n1. Modules import.\n2. Utils.\n3. Data load and prepare\n4. NN creation and training.\n5. Results.","74c4d858":"Check GPU status.","9671a1f0":"## 3. Data load and prepare\n\nAt first we load data to our memory, then reduce memory usage.","aa420611":"## 4. NN creation and training\n\nWe use simple NN model with 3 hidden layers (128, 64, 32 neurons)."}}