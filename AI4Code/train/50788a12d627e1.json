{"cell_type":{"ba023f2c":"code","225a29fd":"code","3c8563d1":"code","2f14f0fd":"code","e03d325a":"code","9204de93":"code","75867837":"code","d661f389":"code","e91c261e":"code","e4338176":"code","5a3e61b1":"code","fc8876e5":"code","086d706a":"code","02aeeb6e":"code","67b2b132":"code","dbd8a169":"code","0a6bc458":"code","17419c13":"code","93dec393":"code","88f630f0":"code","4e1dd0ed":"code","9ce74f9d":"code","c2870fd5":"code","8daa2fce":"markdown","0a97eba9":"markdown","fdb7c396":"markdown","d4c4b386":"markdown","fa75fb51":"markdown","952f8422":"markdown","7858593e":"markdown","bd2fb0aa":"markdown","bb37e42a":"markdown","52fbf4f0":"markdown","546f4f29":"markdown","2258660a":"markdown","f6bb9978":"markdown","255cba2c":"markdown","cc4d8de0":"markdown","21f97a7c":"markdown","d90a9ab1":"markdown","d8f036e1":"markdown","41cc1024":"markdown","466cc896":"markdown","55a4cf6c":"markdown"},"source":{"ba023f2c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib \nfrom matplotlib import pyplot as plt","225a29fd":"df = pd.read_csv('\/kaggle\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndf.head()","3c8563d1":"df.columns","2f14f0fd":"df['Easy Apply'].replace(to_replace='-1',value='False',inplace=True)\ndf.replace(to_replace='-1',value=np.nan,inplace=True)\ndf['Revenue'].replace(to_replace='Unknown \/ Non-Applicable',value=np.nan,inplace=True)\ndf['Founded'].replace(to_replace=-1,value=np.nan,inplace=True)\ndf = df.dropna()\ndf = df.drop(columns='Unnamed: 0',axis=1)\n","e03d325a":"df = df.reset_index()\ndf = df.drop(columns='index',axis=1)","9204de93":"df","75867837":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncol = df[['Size','Type of ownership','Sector','Revenue','Easy Apply']]\ndf1 = col.apply(lambda x: le.fit_transform(x))\ndf1['Rating'] = df['Rating']\ndf1","d661f389":"import seaborn as sns\nsns.countplot(x=df1['Easy Apply'])","e91c261e":"import imblearn\nfrom imblearn.over_sampling import SMOTE\n\nx = df1[['Size','Type of ownership','Sector','Revenue','Rating']]\ny = df1['Easy Apply']\nsamples = SMOTE()\nX,Y = samples.fit_resample(x,y)","e4338176":"df2 = pd.DataFrame(X)\ndf2['Easy Apply'] = Y\ndf2","5a3e61b1":"sns.countplot(x=df2['Easy Apply'])","fc8876e5":"from sklearn.model_selection import train_test_split\nx = df2[['Size','Type of ownership','Sector','Revenue','Rating']]\ny = df2['Easy Apply']\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=5)","086d706a":"from sklearn.model_selection import learning_curve,KFold,cross_val_predict,cross_val_score\nfold = KFold(shuffle=True)\ndef cv_accuracy(estimator,train_size=np.linspace(0.1,1.0,5)):\n                        \n                        model = cross_val_predict(estimator,x_train,y_train,cv=fold)\n                        accuracy1 = cross_val_score(estimator,x_train,y_train,cv=fold)\n                        print(accuracy1.mean())\n                        train_sizes,train_scores,test_scores = learning_curve(estimator,x_train,y_train,train_sizes=train_size,cv=fold)\n                        train_scores_mean = np.mean(train_scores,axis=1)\n                        train_scores_std = np.std(train_scores,axis=1)\n                        test_scores_mean = np.mean(test_scores,axis=1)\n                        test_scores_std = np.std(test_scores,axis=1)\n                        plt.plot(train_sizes,train_scores_mean,'o-',color='r',label='Training samples')\n                        plt.plot(train_sizes,test_scores_mean,'o-',color='g',label='Test samples')\n                        plt.xlabel('Training sizes')\n                        plt.ylabel('Error')\n                        plt.title('Learning curve')\n                        ","02aeeb6e":"from sklearn.linear_model import LogisticRegression\ncv_accuracy(LogisticRegression())","67b2b132":"from sklearn.tree import DecisionTreeClassifier\ncv_accuracy(DecisionTreeClassifier())","dbd8a169":"from sklearn.ensemble import RandomForestClassifier\ncv_accuracy(RandomForestClassifier())","0a6bc458":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nrc = RandomForestClassifier()\nparm = {'n_estimators':[100,200,300,500],'max_depth':[1,3,5,7]}\ngrid = GridSearchCV(estimator=rc,param_grid=parm,cv=fold)\n    ","17419c13":"grid.fit(x_train,y_train)\n","93dec393":"grid.best_params_","88f630f0":"accuracy1 = cross_val_score(RandomForestClassifier(max_depth=7, n_estimators=300),x_train,y_train,cv=fold)\nprint(accuracy1.mean())","4e1dd0ed":"rc = RandomForestClassifier(max_depth=7,n_estimators=300)\nrc = rc.fit(x_train,y_train)\nyhat = rc.predict(x_test)","9ce74f9d":"from sklearn.metrics import classification_report,accuracy_score,plot_confusion_matrix\nprint('Classification Report')\nprint(classification_report(y_test,yhat))\nprint('Accuracy',accuracy_score(y_test,yhat))\nplot_confusion_matrix(rc,x_test,y_test,cmap='Blues')","c2870fd5":"df_output = x_test\ndf_output['Easy Apply'] = yhat\ndf_output","8daa2fce":"## Hyper Parameter Tuning","0a97eba9":"### Random Forest Classifier","fdb7c396":"Based on the Grid search result, the best parameters are maximum depth '7' and the estimator number is 300. Hence, the same is applied to the test samples.","d4c4b386":"### Over sampling the Minority class via SMOTE","fa75fb51":"Among the three models tested in CV, random forest classifier provides highest accuracy of 94%. The learning curve shows low bias and variance.","952f8422":"Based on the overall evaluation metrics, the model fits for 96","7858593e":"## Model Development","bd2fb0aa":"### Logistic regression","bb37e42a":"The accuracy is 93% and the learning curve shows a decent gap between the training samples and cross-validation samples. ","52fbf4f0":"## Decision Tree Classifier","546f4f29":"There are NaN records in most of the columns. But they are provided as '-1'. These records are updated as Nan to ease the cleaning process.","2258660a":"Since the target variable is a feature of probablity, the first option would to choose Logistic regression due to its effective probability feature.","f6bb9978":"Based on the size,sector,type of ownership and revenue, the application probability is predicted.","255cba2c":"## Prediction of data analyst job application probability","cc4d8de0":"## Model Evaluation","21f97a7c":"From the cross validation results, the accuracy is around 80%. However, the learning curve indicates a high bias meaning the dataset is undersampled. Hence, Logistic regresion model is not considered.","d90a9ab1":"Few of the columns like Size, type of ownership,Revenue have categorised values. Hence, Label encoding has been incorporated to turn them into independent features that can be used for the classification model,","d8f036e1":"## Data Wrangling","41cc1024":"Samples are now balanced.","466cc896":"### Cross validation - accuracy and Learning curve","55a4cf6c":"Upon conversion, there is an imbalance in the samples categorised under 'Easy Apply' column as shown below."}}