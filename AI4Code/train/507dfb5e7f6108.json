{"cell_type":{"1daf886b":"code","911e7b8c":"code","bb58ef1e":"code","eb06a641":"code","6ede5a9e":"code","fa735230":"code","294c5578":"code","ddf051a1":"code","f3266b3c":"code","6c9ceb95":"code","be917d12":"code","59521b36":"code","d3ecbb00":"code","84f8ca71":"code","2e99310e":"code","ac9aa8af":"code","7585caa6":"code","5e33bf39":"code","185298ec":"code","4c7b9690":"code","8e6d8720":"code","c3502538":"code","31e658dc":"code","4139f267":"code","0882031b":"code","1d3826ff":"code","c4217e8c":"code","0d783eff":"markdown","f255f4b7":"markdown"},"source":{"1daf886b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","911e7b8c":"df_imdb = pd.read_csv(\"..\/input\/imdb_labelled.txt\", sep=\"\\t\", header=None)\ndf_amazon = pd.read_csv(\"..\/input\/amazon_cells_labelled.txt\", sep=\"\\t\", header=None)\ndf_yelp = pd.read_csv(\"..\/input\/yelp_labelled.txt\", sep=\"\\t\", header=None)","bb58ef1e":"df_imdb.head(), df_amazon.head(), df_yelp.head()","eb06a641":"df_corpus = pd.concat([df_amazon, df_imdb, df_yelp], axis=0)\ndf_amazon.shape, df_imdb.shape, df_yelp.shape, df_corpus.shape","6ede5a9e":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef gen_wordcloud(data, max_words, stopwords):\n    wordcloud = WordCloud(\n        background_color = 'white',\n        max_words = max_words,\n        stopwords = stopwords,\n        max_font_size = 40, \n        scale = 3,\n        random_state = 1\n    ).generate(str(data))\n    fig = plt.figure(1, figsize=(12, 12))\n    plt.axis('off')\n    plt.imshow(wordcloud)\n    plt.show()","fa735230":"stopwords = set([\"I\",\n\"a\",\n\"about\",\n\"an\",\n\"are\",\n\"as\",\n\"at\",\n\"be\",\n\"by\",\n\"com\",\n\"for\",\n\"from\",\n\"is\",\n\"it\",\n\"of\",\n\"on\",\n\"or\",\n\"that\",\n\"this\",\n\"was\",\n\"what\",\n\"when\",\n\"will\",\n\"with\",\n\"how\",\n\"in\",\n\"the\",\n\"to\",\n\"the\",\n\"www\",\n\"where\",\n\"who\"])","294c5578":"from textblob import TextBlob\ndf_corpus['blobbed'] = df_corpus[0].apply(lambda x: TextBlob(x).words)","ddf051a1":"df_corpus.head()","f3266b3c":"df_corpus['cleaned'] = df_corpus['blobbed'].apply(lambda x: list(set(x.lower()) - stopwords))","6c9ceb95":"df_corpus.head()","be917d12":"gen_wordcloud(df_corpus['cleaned'][df_corpus[1] == 0] , 200, stopwords)","59521b36":"negative_words =  [\"n't\", \"not\", \"off\", \"but\", \"problem\", \"disappointed\", \"bad\", \"tied\", \"should\", \"no\", \"only\", \"waste\", \"con\", \"unless\", \"misleading\", \"suck\", \"wasted\", \"breakage\", \"little\"]","d3ecbb00":"gen_wordcloud(df_corpus['cleaned'][df_corpus[1] == 1] , 200, stopwords)","84f8ca71":"positive_words = [\"excellent\",\"pretty\", \"fine\", \"love\", \"great\", \"reasonable\", \"nice\", \"good\", \"impressed\", \"works\", \"must\", \"everything\", \"highly\", \"well\", \"value\", \"absolutely\", \"best\", \"ideal\", \"quality\", \"real\", \"helped\", \"happy\", \"delightful\", 'pleasure', 'flavurful', 'wow']","2e99310e":"def count_words(x, word_list):\n    temp = []\n    for word in word_list:\n        if word in x:\n            temp.append(word)\n    return temp","ac9aa8af":"df_corpus['pos_words'] = df_corpus['cleaned'].apply(lambda x: len(count_words(x, positive_words)))\ndf_corpus['neg_words'] = df_corpus['cleaned'].apply(lambda x: len(count_words(x, negative_words)))","7585caa6":"df_corpus.head()","5e33bf39":"import math\ndf_corpus['polarity'] = df_corpus[0].apply(lambda x: TextBlob(x).sentiment.polarity)\ndf_corpus['polarity_norm'] = df_corpus[0].apply(lambda x: math.ceil(TextBlob(x).sentiment.polarity))\ndf_corpus.head()","185298ec":"df_corpus['polarity_norm'].value_counts()","4c7b9690":"df_corpus=df_corpus.replace({'polarity_norm': {-1: 0}}) \ndf_corpus['polarity_norm'].value_counts()","8e6d8720":"from sklearn.metrics import confusion_matrix\ntn, fp, fn, tp = confusion_matrix(df_corpus[1], df_corpus['polarity_norm']).ravel()\ntp, tn, fp, fn ","c3502538":"#Recall and precision\nrecall = tp \/ (fn + tp)\nprecision = tp \/ (fp + tp)\nrecall, precision","31e658dc":"def sentiment_process(pos, neg, tblob):\n    if pos > neg:\n        return 1\n    elif pos < neg:\n        return 0\n    else:\n        return tblob","4139f267":"df_corpus['sentiment_pred'] = df_corpus.apply(lambda x: sentiment_process(x['pos_words'], x['neg_words'], x['polarity_norm']) , axis=1)\ndf_corpus['sentiment_pred'].value_counts()","0882031b":"df_corpus.head(10)","1d3826ff":"tn, fp, fn, tp = confusion_matrix(df_corpus[1], df_corpus['sentiment_pred']).ravel()\ntp, tn, fp, fn ","c4217e8c":"#Recall and precision\nrecall = tp \/ (fn + tp)\nprecision = tp \/ (fp + tp)\nrecall, precision","0d783eff":"**What I aim for is to detect the words that occur most per labelled data. I'd do this using word clouds. Let's have function to create wordclouds:**","f255f4b7":"**First I would like to compare the polarity results from TextBlob Sentiment analysis:**"}}