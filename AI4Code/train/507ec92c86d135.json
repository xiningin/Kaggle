{"cell_type":{"fdd1284d":"code","3aad01b8":"code","4fb0219e":"code","f1b43a1e":"code","ea027957":"code","a0d0affe":"code","f915722c":"code","7017f715":"code","eabb367e":"code","e1177a39":"code","428ba7d8":"code","933e4b18":"code","9440648b":"code","4be4cf67":"code","039e8444":"code","aef389e4":"code","df0058bf":"code","45e14557":"code","1b0f4ae9":"code","0da89674":"code","194f0ce5":"code","825ea600":"code","ddc824b3":"markdown","bc1b40ec":"markdown","1fb1230d":"markdown","8655df1f":"markdown","6ae7236e":"markdown","88dc1c20":"markdown","9da29e2e":"markdown","6515f892":"markdown","2f0a9148":"markdown","14b9aa78":"markdown","a9e10d73":"markdown","37f07f32":"markdown"},"source":{"fdd1284d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3aad01b8":"prod_price_df = pd.read_csv('\/kaggle\/input\/19560-indian-takeaway-orders\/restaurant-1-products-price.csv')\nprod_price_df.head(10)\norders_df = pd.read_csv('\/kaggle\/input\/19560-indian-takeaway-orders\/restaurant-1-orders.csv')\norders_df.head(10)","4fb0219e":"print(orders_df.shape)\nprint(orders_df.dtypes)","f1b43a1e":"# convert to proper format:\ntry:\n    orders_df['Order Date'] = pd.to_datetime(orders_df['Order Date'])\nexcept:\n    pass","ea027957":"# check the range of the datetime\nprint(orders_df['Order Date'].min())\nprint(orders_df['Order Date'].max())","a0d0affe":"# add additional column\norders_df['total_price'] = orders_df['Quantity'] * orders_df['Product Price']\norders_df.head(5)","f915722c":"orders_df[['Order Date', 'total_price']].set_index('Order Date').plot(kind='line', figsize=(15,9))\nplt.title('Timeline for total order prices')\nplt.ylabel('Total order $')\nplt.grid()\nplt.show()","7017f715":"orders_grouped = pd.DataFrame(orders_df.groupby(by='Order Number').total_price.sum()).sort_values('total_price')\n# filter out some outliers\norders_grouped_filtered = orders_grouped[orders_grouped.total_price < 100]","eabb367e":"orders_grouped_filtered.hist(bins = 100, rwidth = 0.8, figsize= (15,8), cumulative = True, density = True, color = '#838ac4')\nplt.xticks(np.arange(0,100, 50))\nplt.title('Cumulative historgram for total order price ')\nplt.ylabel('% of orders')\nplt.xlabel('Order $ value')\nplt.show()","e1177a39":"# add weekday column\norders_df['weekday'] = orders_df['Order Date'].dt.weekday\norders_df['weekday'] += 1\n\ngrouped_df_weekday = orders_df.groupby(by='weekday')['Order Number'].count()\ngrouped_df_weekday","428ba7d8":"grouped_df_weekday.plot(kind = 'bar', color = 'y', figsize= (15,6))\nplt.grid()\nplt.ylabel('Number or orders')\nplt.title('Order volume by weekday')","933e4b18":"# rename some columns\ndf_order_items = orders_df[['Order Number','Item Name']].rename(columns={'Order Number':'order_id','Item Name':'item'})\ndf_order_items['flag'] = 1\ndf_order_items.head(10)","9440648b":"# create a pivot table on order_id\ndf_order_pivot = pd.pivot_table(data = df_order_items,\n              index = 'order_id',\n              columns = 'item').fillna(0)\nprint(df_order_pivot.shape)\ndf_order_pivot.head(5)","4be4cf67":"# plot correlation between the dishes\ndf_corr_dishes = df_order_pivot.corr()\ndf_corr_dishes.columns = df_corr_dishes.columns.droplevel()\ndf_corr_dishes.reset_index(level=0, drop=True, inplace = True)\ndf_corr_dishes","039e8444":"# pick a random example as parameter for the recommendation\ndish_to_recommend_to = ['Vegetable Samosa']\n\ndef return_recommended_dishes(df_corr_dishes, dish_to_recommend_to):\n    '''\n    Takes an input correlation dataframe and a set of at least one dish to return a sorted dataframe with recommended dishes and their score\n    '''\n    df_recommend_output = df_corr_dishes[dish_to_recommend_to]\n    df_recommend_output['total_corr'] = df_recommend_output.mean(axis = 1)\n\n    # sort by score\n    df_recommend_output.sort_values(by= 'total_corr', ascending = False, inplace = True)\n\n    # remove the first x items since they are the items in the list\n    df_recommend_output = df_recommend_output.iloc[2:,:]\n\n    #only show the score (total correlation)\n    df_recommend_output[['total_corr']].head(10)\n    \n    return df_recommend_output[['total_corr']]\n\ndf_recommended_dishes = return_recommended_dishes(df_corr_dishes, dish_to_recommend_to = ['Vegetable Samosa'])\ndf_recommended_dishes.head(10)","aef389e4":"df_item_popularity = pd.DataFrame(df_order_items.item.value_counts())\n\n# how many total items were ordered\ntotal_item_count = df_item_popularity.item.sum()\n\ndf_item_popularity['%'] = df_item_popularity.item \/ total_item_count\ndf_item_popularity.head(20)","df0058bf":"df_order_items_list = df_order_items.groupby(by='order_id').agg({ 'item': lambda x: \"','\".join(x)})\ndf_order_items_list['item'] = \"['\" + df_order_items_list + \"']\"\ndf_order_items_list","45e14557":"from difflib import SequenceMatcher\n\ndef similar(a, b):\n    return SequenceMatcher(None, a, b).ratio()","1b0f4ae9":"random_item = df_order_items_list.iloc[12115,:][0]\nrandom_item","0da89674":"# apply the similarity function to each row, this might take a few seconds:\ndf_order_items_list['similarity'] = df_order_items_list['item'].apply(lambda x: similar(x, random_item))\ndf_order_items_list.sort_values('similarity', ascending = False, inplace= True)\ndf_order_items_list.iloc[3,:][0]","194f0ce5":"# create a list of items and get the frequency of each item within that list\ninit_list = []\nfor item_group in df_order_items_list.head(20).item:\n    res = item_group.strip('][').split(',') \n    print(res)\n    init_list = init_list + res\n    \nfrom collections import Counter\n\nfrequ_dict = Counter(init_list)\nlen(frequ_dict)","825ea600":"# create a data frame with the top recommended dishes\nfreq_df = pd.DataFrame.from_dict(dict(frequ_dict), orient='index').reset_index().sort_values(0, ascending = False)\nfreq_df_total_ratings = freq_df[0].sum()\nfreq_df['%_rating'] = freq_df[0] \/ freq_df_total_ratings\nfreq_df","ddc824b3":"### --> This shows us which dish tends to be bought together with which other dish.","bc1b40ec":"Clearly there is one outlier in 2019 somewhere, and also there are a lot of data points missing from and before 2016.","1fb1230d":"# **Indian restaurant order analysis**","8655df1f":"### Data import and libraries","6ae7236e":"### Basic recommendation: Recommend by overall popularity (non-specific)","88dc1c20":"## Some ideas for analysis that would be useful to the business:\n\n1. Analyse order volume by weekday to assess if additional staff might need to be hired.\n1. Analyse order volume by daytime to assess at what time staff needs to be present.\n1. Is there a fluctuation during the month, for instance month end vs month beginning?\n1. Order volume and revenue by month to check if there are substantial seaonal fluctuations.\n1. Which dishes bring in the most revenue? (We dont have any margin data which would be interesting.)\n1. How many items are there normally in an individual order?\n1. What does the distribution of order price look like?\n\n(I work on this stuff all day at my job, so not gonna go too much into this.)\n\n# What's more interesting: Recommending dishes if a customer already chose a dish.\n\n**Which dishes tend to be bought together? Can we recommend anything based on what dishes previous orders had?**\n\n### Approach to this problem:\n\nThere are multiple approaches to this problem, a really basic one used here is to **correlate the occurrence of each dish with every other dish.**\nThe resulting correlation matrix can be used to recommend a set of dishes to a customer, given that he or she has already selected one dish.\n\nIt also works for multiple dishes: The correlation scores with every other dish is averaged to provide a resulting overall score for each other dish, taking into account both already chosen dishes.","9da29e2e":"**Data set and topic:**\nThe data set provided contains information on individual *orders places to a London-based Indian restaurant.*","6515f892":"## EDA","2f0a9148":"## Clustering\/ Recommendation","14b9aa78":"This takes another approach of comparing the string similarity of simply the string of all dishes together in one order to other strings of other orders to figure out how similar they are. This is a very simplistic approach, however.","a9e10d73":"## **Table of contents:**\n\n1. Data import and libraries\n2. Exploratory Data Analysis\n3. Recommendation for already selected dish","37f07f32":"### Cluster by string similarity"}}