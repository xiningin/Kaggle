{"cell_type":{"86ecfee1":"code","296487c4":"code","de8f5f46":"code","1afd14af":"code","b02cc93a":"code","e8b0ff66":"code","ed755c79":"code","29fffdd7":"code","4144490b":"code","a5ea67e5":"code","2cde47bf":"markdown","3b987e3c":"markdown","eb92a852":"markdown","4c772289":"markdown","efc76019":"markdown","921799e9":"markdown","a4ace8ad":"markdown","f2a5e6f5":"markdown"},"source":{"86ecfee1":"import os\nimport cv2\nfrom random import shuffle\nimport  pandas as pd\nimport numpy as np\nfrom random import shuffle\nimport  pandas as pd\nimport numpy as np\nimport shutil\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout\nfrom keras.models import Model, load_model\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import MinMaxScaler\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom  keras.applications import *","296487c4":"def resizer(from_path,to_path,HEIGHT=150,WIDTH=150,igore_files=None):\n\n    to_path=to_path+\"\/Resized_\"\n    if not os.path.exists(to_path):\n        os.mkdir(to_path)\n    for file in os.listdir(from_path):\n        if (igore_files is not None and file not in igore_files) or igore_files is None:\n            image = cv2.imread(from_path + \"\/\" + file)\n            scaled_image = cv2.resize(image, (HEIGHT, WIDTH))\n            cv2.imwrite(to_path + \"\/\" + file, scaled_image)\n\npath1 = \"..\/input\/all\/All\"\npath2 = \".\/\"\nresizer(path1,path2,igore_files=[\"GTruth.csv\"])\nshutil.copy(\"..\/input\/all\/All\/GTruth.csv\", \"Resized_\/GTruth.csv\")\n","de8f5f46":"def load_data(PATH,train,test,val,ground_truth):\n    if round(train+test+val,5) != 1:\n        print(\"Sum not One !!! \"+str(train+test+val))\n        return\n    scaler = MinMaxScaler()\n    image_id=[]\n    trainX=[]\n    testX=[]\n    valX=[]\n    trainY = []\n    testY = []\n    valY = []\n    images=[]\n    for file in os.listdir(PATH):\n        if file!=ground_truth:\n            image_id.append(file.split(\".\")[0])\n            images.append(cv2.imread(PATH+\"\/\"+file))\n    #shuffle(image_id)\n    images=np.array(images)\/255\n    gt=pd.read_csv(PATH+\"\/\"+ground_truth)\n    temp = gt[\"Id\"].values.tolist()\n    truth_value = gt[\"Ground_Truth\"].values.tolist()\n\n    from_length=0\n    to_length=round(len(image_id)*train)\n    id_list=image_id[from_length:to_length]\n    trainX=images[from_length:to_length]\n    trainY=[truth_value[temp.index(int(name))]for name in id_list if int(name) in temp]\n    trainY=to_categorical(trainY,2)\n\n    from_length = to_length\n    to_length = to_length+round(len(image_id) * val)\n    id_list = image_id[from_length:to_length]\n    valX=images[from_length:to_length]\n    valY = [truth_value[temp.index(int(name))] for name in id_list if int(name) in temp]\n    valY = to_categorical(valY,2)\n\n    from_length = to_length\n    to_length = to_length + round(len(image_id) * val)\n    id_list = image_id[from_length:to_length]\n    testX=images[from_length:to_length]\n    testY = [truth_value[temp.index(int(name))] for name in id_list if int(name) in temp]\n    testY = to_categorical(testY,2)\n    \n    return trainX,valX,testX,trainY,valY,testY","1afd14af":"def get_model(input_shape,output):\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.125))\n \n    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n \n    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n \n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.19))\n    model.add(Dense(output, activation='softmax'))\n    return model","b02cc93a":"def pre_trained_model(name,input_shape1,output):\n  model = Sequential()\n  model.add(name(weights='imagenet',include_top=False,input_shape=input_shape1))\n  model.add(Flatten())\n  model.add(Dense(512, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(output, activation='softmax'))\n  return model","e8b0ff66":"trainX,valX,testX,trainY,valY,testY=load_data(\"Resized_\",0.7,0.2,0.1,\"GTruth.csv\")","ed755c79":"model=get_model(trainX.shape[1:],2)\n#model=pre_trained_model(InceptionV3,trainX.shape[1:],2)\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","29fffdd7":"batch_size = 256\nepochs = 20\nhistory = model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(valX, valY))\nmodel.evaluate(testX,testY)","4144490b":"plt.style.use('seaborn-ticks')\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a5ea67e5":"!rm -r Resized_","2cde47bf":"# Plot","3b987e3c":"# Import","eb92a852":"# Model Compile","4c772289":"# Train Test Split","efc76019":"# Resize Image","921799e9":"# Model Creation","a4ace8ad":"# Start","f2a5e6f5":"# Divide data as train,test,validation"}}