{"cell_type":{"4c4ae33e":"code","75b6c019":"code","21546216":"code","3d7caaf1":"code","85ce104e":"code","eefab4e4":"code","78b2fa94":"code","a79af61b":"code","ff9aa462":"code","a43bb62f":"code","417b9349":"code","578b36f4":"code","f2534071":"code","b83a8513":"code","f624259d":"code","f7f963b1":"code","2d136d5b":"code","7cd5c507":"code","38a31d4e":"code","3c0c0580":"code","f0daa37d":"code","0021bed5":"code","c6263ff6":"code","3769e8d7":"code","a0dd9de9":"code","4b481319":"code","183cc951":"code","a88ec664":"code","09f6df41":"code","458afa0c":"code","48160423":"code","c3060284":"code","bdd56c3c":"code","c551fddb":"code","34ce3510":"code","8e4581a1":"code","e992f074":"code","689070ee":"code","7f61dae6":"code","cd73cb7d":"code","09649e48":"code","4f91f4b0":"code","676d2159":"code","1c605c36":"code","f2f998d6":"code","78996bea":"code","ec71ccc8":"code","1f899a43":"markdown","fc03d1da":"markdown","c2a3700c":"markdown"},"source":{"4c4ae33e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75b6c019":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv') # reading csv file\ndf # output the whole .csv file using Pandas Dataframe\n#print(\"Dataset Shape:{}\".format(df.shape))","21546216":"df.describe()","3d7caaf1":"df.isnull().sum() #Let's see how many null values we have in out dataset","85ce104e":"df = df.drop([\"PassengerId\",\"Ticket\"], axis=1) # TODO write more about AXIS\ndf.head()","eefab4e4":"df['Age'].fillna(df[\"Age\"].mean(),inplace=True) # filling NA values with mean values of each column\ndf[\"Embarked\"].fillna(df['Embarked'].mode()[0],inplace=True)","78b2fa94":"df.info()","a79af61b":"def column_visualization(column):\n    survived = df[df['Survived']==1][column].value_counts()\n    dead = df[df[\"Survived\"]==0][column].value_counts()\n    new_df = pd.DataFrame([survived,dead])\n    new_df.index = ['Survived', 'Dead']\n    new_df.plot(kind = 'bar',title = ' Plot of - {} column'.format(column), figsize = (10,5))\n    \ncolumn_visualization(\"Sex\")\ncolumn_visualization('Pclass')\ncolumn_visualization('SibSp')","ff9aa462":"def box_outliers(column):\n    df.boxplot(by = 'Survived', column = [column], grid = True)","a43bb62f":"box_outliers('Fare')","417b9349":"df.nlargest(10, ['Fare'])","578b36f4":"df = df.drop([258,679,737])","f2534071":"df.nlargest(10, ['SibSp'])","b83a8513":"df = df.drop([159,180,201, 324,792,846,863])","f624259d":"box_outliers('Parch')","f7f963b1":"df.nlargest(10, ['Parch'])","2d136d5b":"df.drop([678])","7cd5c507":"import seaborn as sns\nplt.figure(figsize = (10,10))\nsns.heatmap(df.corr(), annot=True, linewidths = 0.05, fmt = '.2f', cmap = 'magma')\nplt.show()","38a31d4e":"X = df.drop(['Cabin', 'Fare', 'Name', 'Survived'], axis = True)\ny = df['Survived']\n\nprint(X.shape, y.shape)\nx = pd.get_dummies(X)","3c0c0580":"from sklearn.preprocessing import MinMaxScaler\nx_scaler = MinMaxScaler(feature_range = (0,1))\nx[x.columns] = x_scaler.fit_transform(x[x.columns])\n","f0daa37d":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .25, random_state =40)\n","0021bed5":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state = 40)\nlr.fit(x_train,y_train)\nprint(lr.score(x_test,y_test))","c6263ff6":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(random_state = 140)\ndtc.fit(x_train,y_train)\nprint(dtc.score(x_test,y_test))","3769e8d7":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state = 80, min_impurity_decrease=0.002, min_weight_fraction_leaf=0.001)\nrfc.fit(x_train,y_train)\nprint(rfc.score(x_test,y_test))","a0dd9de9":"y_lr_pre = lr.predict(x_test)\ny_dtc_pre = dtc.predict(x_test)\ny_rfc_pre = rfc.predict(x_test)","4b481319":"new_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nnew_df.head()","183cc951":"new_x = new_df.drop(['Cabin', 'PassengerId', 'Fare', 'Name', 'Ticket'],axis = True)\nnew_x.head()","a88ec664":"new_x.isnull().sum()\nnew_x['Age'].fillna(new_x['Age'].mean(),inplace=True)","09f6df41":"new_x = pd.get_dummies(new_x)\nnew_x.head()\nmissing_col = set(x_train.columns)-set(new_x.columns)\nfor col in missing_col:\n    new_x[col] = 0\n    ","458afa0c":"new_x=new_x[x_train.columns]\nnew_x.shape","48160423":"new_predict = rfc.predict(new_x)\nprint(new_predict)","c3060284":"vip = np.array(new_predict).tolist()\nlen(vip)","bdd56c3c":"new_df.insert(2,column = 'Survived', value=vip)\nnew_df.head()\nanother_df = new_df.drop(['Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'],axis=1)\nanother_df.head()","c551fddb":"another_df.to_csv('gender_submission1.csv', index=False)\nanother_df.head()\n","34ce3510":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_df.head()","8e4581a1":"train_df.drop(['Ticket', 'Name', 'PassengerId', 'Cabin'], axis = 1, inplace = True)\ntrain_df.head()","e992f074":"train_df.isna().sum()","689070ee":"#replacing Zero values in Fare column with average value of this column\ntrain_df['Fare'] = train_df['Fare'].replace(0, train_df['Fare'].mean())\ntrain_df['Age'].fillna(train_df['Age'].mean(), inplace = True)\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace = True)\ntrain_df.isna().sum()","7f61dae6":"train_df['Sex'] = train_df['Sex'].apply(lambda val: 1 if val == 'male' else 0)\ntrain_df['Embarked'] = train_df['Embarked'].map({'S':0, 'C': 1, 'Q': 2})\ntrain_df.head()","cd73cb7d":"train_df.describe()","09649e48":"train_df['Age'] = np.log(train_df['Age'])\ntrain_df['Fare'] = np.log(train_df['Fare'])","4f91f4b0":"train_df.head()","676d2159":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.drop(['Ticket', 'Name', 'PassengerId', 'Cabin'], axis = 1, inplace = True)\ntest_df['Fare'] = test_df['Fare'].replace(0, test_df['Fare'].mean())\ntest_df['Age'].fillna(test_df['Age'].mean(), inplace = True)\ntest_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace = True)\ntest_df['Fare'].fillna(test_df['Fare'].mean(), inplace = True)\ntest_df.isna().sum()\ntest_df['Sex'] = test_df['Sex'].apply(lambda val: 1 if val == 'male' else 0)\ntest_df['Embarked'] = test_df['Embarked'].map({'S':0, 'C': 1, 'Q': 2})\ntest_df.head()\ntest_df['Age'] = np.log(test_df['Age'])\ntest_df['Fare'] = np.log(test_df['Fare'])","1c605c36":"test_df","f2f998d6":"X = train_df.drop('Survived', axis =1)\ny = train_df['Survived']\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n\nsgb = GradientBoostingClassifier(subsample = 0.90, max_features = 0.70)\nsgb.fit(X_train, y_train)\n\nsgb_acc = accuracy_score(y_test, sgb.predict(X_test))\n\nprint('Training accuracy of Detection tree classifier is {}'.format(accuracy_score(y_train, sgb.predict(X_train))))","78996bea":"predictions = sgb.predict(test_df)","ec71ccc8":"pred = pd.DataFrame(predictions)\nsub_df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsub_df['Survived'] = pred\nsub_df.to_csv('Submission.csv', index = False)","1f899a43":"## PART 2: DATA PREP and Model Building","fc03d1da":"## PART 1: DATASET VISUALIZATION \n","c2a3700c":"box_outliers('SibSp')"}}