{"cell_type":{"e430b766":"code","bc1535fb":"code","39e59af1":"code","51573eeb":"code","d6e71261":"code","5ce1c4f0":"code","ca213adb":"code","9c8cb107":"code","5d3ae192":"code","f3e8d0ca":"code","e72fd112":"code","54640bbb":"code","77a31e10":"code","49c02ada":"code","a9bceaef":"code","3ce340ba":"code","06da6479":"code","55a9ca81":"code","7f2a5dbd":"code","d54345ce":"code","6bed2a89":"code","7c06dc52":"code","ac4e4750":"code","0483b86a":"code","94a1bf44":"code","065fdbc1":"code","fdd17495":"markdown","d0d0fa12":"markdown","baea9254":"markdown","52b94868":"markdown","64dd420c":"markdown","c3ed94c8":"markdown","322e390d":"markdown","4f98bb72":"markdown","e1584978":"markdown","1c74f8b9":"markdown","66a6ab30":"markdown","ebc0d40b":"markdown","26fa399e":"markdown","93b6528e":"markdown","7e245a84":"markdown","f861d99b":"markdown","d6cff0f9":"markdown","12fbfbfa":"markdown"},"source":{"e430b766":"#import libraries\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Activation, Dense, LSTM, Dropout, GlobalMaxPooling1D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom keras.preprocessing.sequence import TimeseriesGenerator","bc1535fb":"def GlobalTemperature_values(chart_time,inicial_date = '1995-01-01',final_date = '2019-12-31',Region=None,Country=None,City=None):  \n  \"\"\"\n  Funtion which returns the values of the Average Temperature from a given location and time.\n\n  If any location is specified the function returns a chart related with the data from the whole world.\n  To know what is the exactly list of Regions\/Country\/City for the parameters, involke the GlobalTemperature_dataInfo.\n  \n  The Parameter chart_time only accepts the following string names: [Day, Month, Year].\n\n  The correct format for the inicial_date and final_date is: Year-Month-Day.\n  If not specified, the inicial_date and final_date are: '1995-01-01', '2019-12-31'.\n  The Parameters inicial_date and final_date only accepts values in the interval of: 1995-01-01 ------ 2019-12-31.\n\n  \"\"\"\n  #Operations\n  def AvgperDate(data):\n    avgperDate = data.groupby('Date')['AvgTemperature'].mean()\n    return avgperDate\n  def Avgperday(data):\n    avgperday = data.groupby('Day')['AvgTemperature'].mean()\n    return avgperday\n  def Avgpermonth(data):\n    avgpermonth = data.groupby('Month')['AvgTemperature'].mean()\n    return avgpermonth\n  def Avgperyear(data):  \n    avgperyear = data.groupby('Year')['AvgTemperature'].mean()\n    return avgperyear\n\n  data = pd.read_csv('\/kaggle\/input\/daily-temperature-of-major-cities\/city_temperature.csv',low_memory=False) #import data\n  data.drop(columns = 'State',inplace=True) #drop column state\n  data['AvgTemperature'] = (data['AvgTemperature']-32)*(5\/9) #transforming in Celsius\n  remove = data.loc[(data['AvgTemperature']< -50)] #removing outliers\n  data.drop(remove.index,inplace=True)\n  remove = data.loc[(data['Year'] == 2020)] #removing data from incomplete year\n  data.drop(remove.index,inplace=True)\n  date = pd.to_datetime(data[['Month','Day','Year']],errors='coerce') #data format\n  data['Date'] = date #new column\n \n  #Location choice\n  if Region != None and Country == None and City == None:\n    if any(data['Region'].unique() == Region) == False:\n      return print('Please check the list of locations and the spelling accepted using the funtion: GlobalTemperature_dataInfo ')\n    data = data[data['Region'] == Region]\n\n  elif Region == None and Country != None and City == None:\n    if any(data['Country'].unique() == Country) == False:\n      return print('Please check the list of locations and the spelling accepted using the funtion: GlobalTemperature_dataInfo ')\n    data = data[data['Country'] == Country]\n\n  elif Region == None and Country == None and City != None:\n    if any(data['City'].unique() == City) == False:\n      return print('Please check the list of locations and the spelling accepted using the funtion: GlobalTemperature_dataInfo ')\n    data = data[data['City'] == City]\n  \n  elif Region == None and Country == None and City == None:\n    data = data\n\n  else:\n    return print('Please select just one of types of location: Region, Country, City or let None in all for World data')\n\n\n\n  #Date choice\n  if inicial_date<'1995-01-01' or inicial_date>'2019-12-31':\n    return print('Please choose a initial_date greater than 1995-01-01 and lesser than 2019-12-31.')\n  elif final_date<'1995-01-01' or final_date>'2019-12-31':\n    return print('Please choose a initial_date greater than 1995-01-01 and lesser than 2019-12-31.')\n\n  data = data[(data['Date'] >= inicial_date) & (data['Date'] <= final_date)]\n\n  #chart period choice\n\n  if chart_time == 'Day':\n    return Avgperday(data)\n\n  elif chart_time == 'Month':\n    return Avgpermonth(data)\n\n  elif chart_time == 'Year':\n    return Avgperyear(data)\n  \n  elif chart_time == 'Date':\n    return AvgperDate(data)\n\n  elif chart_time == None:\n    return Avgperyear(data)\n  \n  else:\n    return print('Please type one of the following: Day,Month,Year or None ')","39e59af1":"data = GlobalTemperature_values(chart_time='Date',inicial_date = '1995-01-01',final_date = '2019-12-31',Region=None,Country=None,City='Sao Paulo')","51573eeb":"data","d6e71261":"train,test= train_test_split(data.values,test_size=0.3,shuffle=False)","5ce1c4f0":"len(data.values)","ca213adb":"len(train)","9c8cb107":"scaler1 = MinMaxScaler()\ntrain = scaler1.fit_transform(train.reshape(-1, 1))\ntest = scaler1.transform(test.reshape(-1, 1))","5d3ae192":"train","f3e8d0ca":"split=int((1-0.3)*len(data))\n\ndate_train = data.index[:split]\ndate_test = data.index[split:]","e72fd112":"date_train","54640bbb":"look_back = 20\ntrain_gen = TimeseriesGenerator(train, train, length=look_back, batch_size=20)     \ntest_gen = TimeseriesGenerator(test, test, length=look_back, batch_size=1)","77a31e10":"train_gen","49c02ada":"model = Sequential()\nmodel.add(LSTM(500,activation='relu', return_sequences=True, input_shape=(look_back, 1)))\nmodel.add(LSTM(200,activation='relu', return_sequences=True, input_shape=(look_back, 1)))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam')\nmodel.summary()","a9bceaef":"model.fit_generator(train_gen, epochs=20, \n      verbose=1)\nmodel.save('model.pb')","3ce340ba":"test = scaler1.inverse_transform(test)\ntrain = scaler1.inverse_transform(train)","06da6479":"pred = scaler1.inverse_transform(model.predict_generator(test_gen))","55a9ca81":"plt.figure(figsize=(20,8))\n# plt.plot(date_train,train, label = \"Train data\")\n# plt.plot(date_test[:-look_back],pred, label = \"Prediction based in the Test data\")\nplt.plot(data.index,data.values, label = \"Data\")\nplt.title('Avg Temperature in C\u00b0 per {}'.format(data.index.name))\nplt.xlabel('{}'.format(data.index.name),fontsize=15)\nplt.ylabel('Avg Temperature in C\u00b0',fontsize=15)\nplt.legend()\nplt.show()","7f2a5dbd":"plt.figure(figsize=(20,8))\nplt.plot(date_train,train, label = \"Train data\")\nplt.plot(date_test[:-look_back],pred, label = \"Prediction based in the Test data\")\n# plt.plot(data.index,data.values, label = \"Data\")\nplt.title('Avg Temperature in C\u00b0 per {}'.format(data.index.name))\nplt.xlabel('{}'.format(data.index.name),fontsize=15)\nplt.ylabel('Avg Temperature in C\u00b0',fontsize=15)\nplt.legend()\nplt.show()","d54345ce":"plt.figure(figsize=(20,8))\n#plt.plot(date_train,train, label = \"Train data\")\nplt.plot(date_test[:-look_back],pred, label = \"Prediction based in the Test data\")\nplt.plot(date_test[:-look_back],test.reshape(-1)[:-look_back],label = \"Test Data\")\nplt.title('Avg Temperature in C\u00b0 per {}'.format(data.index.name))\nplt.xlabel('{}'.format(data.index.name),fontsize=15)\nplt.ylabel('Avg Temperature in C\u00b0',fontsize=15)\nplt.legend()\nplt.show()","6bed2a89":"  from sklearn import metrics\n  print('MAE:', metrics.mean_absolute_error(data.values[split+look_back:],pred))\n  print('MSE:', metrics.mean_squared_error(data.values[split+look_back:],pred))\n  print('RMSE:', np.sqrt(metrics.mean_squared_error(data.values[split+look_back:],pred)))","7c06dc52":"def predict(forecast_num, model,data,look_back):\n  prediction_list = data[-look_back:]\n\n  for _ in range(forecast_num):\n      x = prediction_list[-look_back:]\n      x = x.reshape((1, look_back, 1))\n      out = model.predict(x)[0][0]\n      prediction_list = np.append(prediction_list, out)\n  prediction_list = prediction_list[look_back-1:]\n\n  return prediction_list\n\ndef predict_dates(forecast_num):\n    last_date = data.index[-1]\n    prediction_dates = pd.date_range(last_date, periods=forecast_num+1).tolist()\n    return prediction_dates","ac4e4750":"forecast_num = 2 #number of day to predict after the last date in data\nforecast=predict(forecast_num, model=model,data=data.values,look_back=look_back)\nforecast_date=predict_dates(forecast_num)","0483b86a":"  print('forecast',forecast)\n  print('forecast dates',forecast_date)","94a1bf44":"data = pd.read_csv('\/kaggle\/input\/daily-temperature-of-major-cities\/city_temperature.csv',low_memory=False) #import data\ndata.drop(columns = 'State',inplace=True) #drop column state\ndata['AvgTemperature'] = (data['AvgTemperature']-32)*(5\/9) #transforming in Celsius\nremove = data.loc[(data['AvgTemperature']< -50)] #removing outliers\ndata.drop(remove.index,inplace=True)\ndate = pd.to_datetime(data[['Month','Day','Year']],errors='coerce') #data format\ndata['Date'] = date #new column\nd=data[((data['Date'] =='2020-1-1') | (data['Date'] =='2020-1-2'))& (data['City'] == 'Sao Paulo')]","065fdbc1":"d","fdd17495":"After you train and test your model, with the data that you already had, you want to predict future data, which is, I think, the trully interresting thing about recurrent networks.\n\nSo in order to make this, you need to start predicting the values from one day after your final date in your original dataset, using the model (which is trained with this past data). Once you predict this value, you do the same thing, but considering the last values predict, and so on.\n\nThe fact that you are using a prediction to make others predictions, implies that is much more difficult to get good results, so is common to try to predict short ranges of time.","d0d0fa12":"The most difficult part in time series is to separate the data in batches, transforming in proper way.\n\nThere is a keras API for help us make this.\n\nThe parameter length, is how much of previus data we want to use to make predictions","baea9254":"Trainning the model\n\nIf it is taking too long, set less steps or change the look back value","52b94868":"Scaling the values\nIt is necessary to reshape the values to 2 dimensions","64dd420c":"For data visualizations purpose, we gonna keep the dates into separate variables","c3ed94c8":"Scalling back to the original data, to visualize the results","322e390d":"Ploting the whole data","4f98bb72":"# Time Series LSTM - FORECAST NEW DATA","e1584978":"Performing predictions with the test data\n","1c74f8b9":"# Forecast Time Series","66a6ab30":"Metrics of the model","ebc0d40b":"\nAfter obtaining the data you want to perform the forecast, it is necessary to separate the data in training and testing.\n\nTest = %TOTAL_LENGTH (usually ~30%)\n\nTrain = TOTAL_LENGTH - Test","26fa399e":"Let's see the data in 2020, that was not used in the train or test for the model","93b6528e":"The model predicts that the average temperature would be 48 \u00b0 C and the correct answer is 26 \u00b0 C. We need to improve the model by using more layers and testing other parameters\n\n\nThis kernel was a simple example to show only the basic steps, I hope this can help someone.","7e245a84":"\n\nFunction to access a specific set of information, which will be used in the predictive model","f861d99b":"Ploting the train and the predicted test data ","d6cff0f9":"predicted test data and the original test data","12fbfbfa":"Model structure"}}