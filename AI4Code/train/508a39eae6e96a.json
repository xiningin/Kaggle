{"cell_type":{"0943c296":"code","c77a4d1f":"code","343f3d85":"code","6c7c7494":"code","c3aa272d":"code","c0bc6e2b":"code","daf0dedd":"code","011833b1":"code","fbca1847":"code","1b779334":"code","95087388":"code","23a56c68":"code","25b15ef5":"code","6d4700c5":"code","d89bbf6e":"code","b25de2b5":"code","73bc4ef2":"markdown","93c71868":"markdown","64890b0c":"markdown","e3705e8d":"markdown","e820385e":"markdown","299475e0":"markdown","c6384076":"markdown"},"source":{"0943c296":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c77a4d1f":"!pip uninstall keras -y\n!pip uninstall keras-nightly -y\n!pip uninstall keras-Preprocessing -y\n!pip uninstall keras-vis -y\n!pip uninstall tensorflow -y\n\n!pip install tensorflow==2.3.0\n!pip install keras==2.4","343f3d85":"!python -c 'import keras; print(keras.__version__)'","6c7c7494":"import os\n\nrepo_url = 'https:\/\/github.com\/fizyr\/keras-retinanet'\nrepo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url))) \n\n!git clone {repo_url} # clone repo","c3aa272d":"# from \/content\/keras-retinanet\n%cd {repo_dir_path} \n!pip install .\n!python setup.py build_ext --inplace\n\n%cd ..","c0bc6e2b":"# show images inline\n%matplotlib inline\n\n# automatically reload modules when they have changed\n%load_ext autoreload\n%autoreload 2\n\n# import keras\nfrom tensorflow import keras\n\n# import keras_retinanet\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\nfrom keras_retinanet.utils.gpu import setup_gpu\n\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport numpy as np\nimport time\nimport tifffile\nfrom os import listdir\nfrom os.path import isfile, join, isdir","daf0dedd":"model_path = os.path.join('.\/keras-retinanet', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')","011833b1":"model = models.load_model('..\/input\/tf-retinanet-with-pretrained-models\/pretrained_models\/resnet50_coco_best_v2.h5',\n                          backbone_name='resnet50')\n","fbca1847":"# model1 = models.load_model('..\/input\/tf-retinanet-with-pretrained-models\/pretrained_models\/resnet101_oid_v1.h5',\n#                            backbone_name='resnet101')\n","1b779334":"labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n","95087388":"def show_img(img_path,caption=False):\n    # load image\n    image = read_image_bgr(img_path)\n\n    # copy to draw on\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n    \n    # preprocess image for network\n    image = preprocess_image(image)\n    image, scale = resize_image(image)\n\n    # process image\n    start = time.time()\n    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n    print(\"processing time: \", time.time() - start)\n    \n    boxes \/= scale\n       \n    # visualize detections\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n    # scores are sorted so we can break        \n            if score < 0.4:\n                break\n            b = box.astype(int)\n            color = label_color(label)\n            draw_box(draw, b, color=color)\n            if caption == True:\n                caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n                draw_caption(draw, b, caption)  \n\n    plt.figure(figsize=(10, 8))\n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()\n\n    \n\n    ","23a56c68":"testcases_ucsd=['..\/input\/ucsddataset\/UCSD_Anomaly_Dataset.v1p2\/UCSDped1\/Train\/Train001\/002.tif',\n                '..\/input\/ucsddataset\/UCSD_Anomaly_Dataset.v1p2\/UCSDped1\/Test\/Test036\/051.tif',\n               '..\/input\/ucsddataset\/UCSD_Anomaly_Dataset.v1p2\/UCSDped1\/Test\/Test003\/002.tif']\n\nfor test in testcases_ucsd:\n    show_img(test)","25b15ef5":"test_cases_shai=['..\/input\/shanghaitech\/ShanghaiTech\/part_B\/train_data\/images\/IMG_1.jpg',\n                '..\/input\/shanghaitech\/ShanghaiTech\/part_A\/train_data\/images\/IMG_125.jpg',\n                '..\/input\/shanghaitech\/ShanghaiTech\/part_B\/train_data\/images\/IMG_12.jpg']\nfor test in test_cases_shai:\n    show_img(test,caption=True)","6d4700c5":"num_samples = 10\nindex = 0\ntest_path='..\/input\/ucsddataset\/UCSD_Anomaly_Dataset.v1p2\/UCSDped1\/Test\/'\nfor f in sorted(listdir(test_path)):\n    directory_path = join(test_path, f)\n    if isdir(directory_path):\n        \n        for c in sorted(listdir(directory_path)):\n            img_path = join(directory_path, c).replace(\"\\\\\", '\/')\n            if str(img_path)[-3:] == \"tif\":\n                \n                image=cv2.imread(img_path)\n                plt.imshow(image, cmap=\"gray\")\n                plt.title(\"Ground Truth Image\")\n                plt.show()\n\n                show_img(img_path)\n                index+=1\n                break\n\n    if index >= num_samples:\n        break","d89bbf6e":"show_img('..\/input\/ucsddataset\/UCSD_Anomaly_Dataset.v1p2\/UCSDped1\/Test\/Test036\/060.tif')","b25de2b5":"! wget https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2019\/02\/crowd-at-a-stadium-in-johannesburg-south-africa-for-rugby.jpg\nimage = plt.imread('crowd-at-a-stadium-in-johannesburg-south-africa-for-rugby.jpg')\nshow_img('crowd-at-a-stadium-in-johannesburg-south-africa-for-rugby.jpg')","73bc4ef2":"## UCSD Dataset Multiple cases :","93c71868":"## Install Necessary Libraries :","64890b0c":"## Install Keras RetinaNet:","e3705e8d":"### Sample img from UCF Dataset:","e820385e":"## Test cases on Shanghai Dataset:","299475e0":"## Test cases on UCSD Dataset:","c6384076":"## Load RetinaNet Model:"}}