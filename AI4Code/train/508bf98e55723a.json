{"cell_type":{"4ca03ff5":"code","a0db7921":"code","886a9405":"code","631074db":"code","d3fd7495":"code","1374ac1f":"code","fe6f4bac":"code","cdb41374":"code","d84bd4da":"code","6111c365":"code","3685fcee":"code","5eaf6410":"code","be7041a5":"code","f4cccdcf":"code","7619df6b":"code","192f2c9f":"code","f48e4b80":"code","efde9469":"code","20b5251f":"code","14ed4245":"code","01503107":"code","ff917db3":"code","77a504d6":"code","2e854498":"code","980ccba8":"code","cfa8e0bf":"code","08951a2f":"code","305e9283":"code","bdbde406":"code","8277b1a7":"code","94ed213a":"code","2c85e8d0":"code","3f84b7b6":"code","229f384e":"code","4c91c8f0":"code","e5c0f785":"code","0d48ac49":"code","7804b665":"code","f292a0fd":"code","09984ba4":"code","634537c5":"code","47f68cc1":"code","5786def9":"code","b12ecec0":"code","4fe38897":"code","c4406e57":"code","170d46c4":"code","27894625":"code","e601b039":"code","4343b0cb":"code","36907f50":"code","0178c39f":"code","3fcb363c":"code","ff83b01e":"code","c6e4df9f":"code","cc5b8026":"code","821431e7":"code","a64a971a":"code","78019256":"code","63a03c50":"code","127296b4":"code","aac3b595":"code","061b3464":"code","9a382b76":"code","fdc1da1e":"code","a1fd940a":"code","c2cc1b3a":"code","4d5a47db":"code","0a3cb7d9":"code","1fa72e02":"code","23b47b98":"code","a8fe7f8f":"code","294f95b3":"code","f720edb1":"code","10bccaa2":"code","8c42c2be":"code","4ebd6815":"code","f470c127":"code","251f56fb":"code","ccd3a637":"code","a59a6e1b":"code","571ec561":"code","e689571b":"code","2346024d":"code","adc99b89":"code","ab272f25":"code","b07be279":"code","4047dabf":"code","f23fef63":"code","b6f0584c":"markdown","c0184a19":"markdown","3c706419":"markdown","816973c8":"markdown","67e39619":"markdown","3ed7a597":"markdown","60513997":"markdown","b8042e81":"markdown","ac7d7e68":"markdown","87f67aa6":"markdown","1abc9e85":"markdown","027824bd":"markdown","99400d0a":"markdown","c6fd22cb":"markdown","4bd22108":"markdown","8e267e6a":"markdown","15df971e":"markdown","7aac543a":"markdown","af817369":"markdown","aeaf273f":"markdown","25195cc3":"markdown","f3c2d6b6":"markdown","958caa97":"markdown","7f9d796f":"markdown","f28ca927":"markdown","d0db3337":"markdown","6b58dd23":"markdown","72812c66":"markdown","3c5525ac":"markdown","789a6dd0":"markdown","3fd04dae":"markdown","f63312b6":"markdown","15972cbb":"markdown","9083be15":"markdown"},"source":{"4ca03ff5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import  confusion_matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')","a0db7921":"names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n'B', 'LSTAT', 'MEDV']\ndf = pd.read_csv(\"..\/input\/boston-house-prices\/housing.csv\",delim_whitespace=True, names=names)\ndf","886a9405":"\n# Exploratory Data Analysis\ndef libraries():\n    global pd,np\n    import pandas as pd\n    import numpy as np\ndef load():\n    global df\n    names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n    'B', 'LSTAT', 'MEDV']\n    df = pd.read_csv(\"..\/input\/boston-house-prices\/housing.csv\",delim_whitespace=True, names=names)\n    \ndef top_rows(value):\n    print('\\033[1m'+ 'displaying the', value, 'rows from top'+'\\033[0m')\n    a=df.head(value)\n    print(a,'\\n')\n    \ndef bottom_rows(value):\n    print('\\033[1m'+'displaying the', value, 'rows from bottom'+'\\033[0m')\n    b=df.tail(value)\n    print(b,'\\n')\n    \ndef rows_columns():\n    print('\\033[1m'+'Shape of the Data set'+'\\033[0m')\n    c=df.shape\n    print(c,'\\n')\n    \ndef col_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    d=df.columns\n    print(d,'\\n')\n    \ndef information():\n    print('\\033[1m'+'Quick Overview of DataSet(info)'+'\\033[0m')\n    e = df.info()\n    print(e,'\\n')\n\ndef sizee():\n    print('\\033[1m'+'No.of Elements in the DataSet'+'\\033[0m')\n    f = df.size\n    print(f,'\\n')\n\ndef ndimension():\n    print('\\033[1m'+'Dimensions in your dataframe'+'\\033[0m')\n    g = df.ndim\n    print(g,'\\n')\n    \ndef stats_summary():\n    print('\\033[1m'+'Staistical Summary of DataSet'+'\\033[0m')\n    h = df.describe()\n    print(h,'\\n')\n    \ndef null_values():\n    print('\\033[1m'+'Number of Missing values in each column'+'\\033[0m')\n    i = df.isnull().sum()\n    print(i,'\\n')\n    \ndef n_unique():\n    print('\\033[1m'+'Number of unique elements'+'\\033[0m')\n    j = df.nunique()\n    print(j,'\\n')\n    \ndef memory_use():\n    print('\\033[1m'+'Memory used by all colomns in bytes'+'\\033[0m')\n    k = df.memory_usage()\n    print(k,'\\n')\n    \ndef is_na(value):\n    print('\\033[1m'+'Dataframe filled with boolean values with true indicating missing values'+'\\033[0m')\n    l = df.isna().head(value)\n    print(l,'\\n')\n    \ndef duplicate():\n    print('\\033[1m'+'Boolean Series denoting duplicate rows'+'\\033[0m')\n    m = df.duplicated().sum()\n    print(m,'\\n')\n    \ndef valuecounts():\n    print('\\033[1m'+'Series containing count of unique values'+'\\033[0m')\n    n = df.value_counts()\n    print(n,'\\n')\n\ndef datatypes():\n    print('\\033[1m'+'Datatype of each column'+'\\033[0m')\n    o = df.dtypes\n    print(o,'\\n')\n    \ndef correlation():\n    print('\\033[1m'+'Correalation between all columns in DataFrame'+'\\033[0m')\n    p = df.corr()\n    print(p,'\\n')\n    \ndef nonnull_count():\n    print('\\033[1m'+'Count of non-null values'+'\\033[0m')\n    q = df.count()\n    print(q,'\\n')\n    \ndef eda():\n    load()\n    value= 5 \n    datatypes()\n    top_rows(value)\n    bottom_rows(value)\n    rows_columns()\n    col_names()\n    information()\n    sizee()\n    ndimension()\n    stats_summary()\n    null_values()\n    n_unique()\n    memory_use()\n    is_na(value)\n    nonnull_count()\n    duplicate()\n    valuecounts()\n    correlation()\n    \n    \n    \n        \ndef stats_u(data,col):\n    if data[col].dtype == \"float64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        max_value = data[col].max()\n        print('Maximum value of',col,'column',max_value)\n        min_value = data[col].min()\n        print('Minimum value of',col,'column',min_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n            \n    elif data[col].dtype == \"int64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(\"Outliers are:\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n    else:\n        print(col,'has Qualitative Data')\n        z = df[col].mode()\n        print('mode of',col,'column:\\n',z)\n        print('Count of mode is:\\n',df[col].value_counts())\n        print('Unique strings in',col,'are',data[col].nunique())\n        if(data[col].nunique() == 1):\n            print(col,'has same string')\n        elif(data[col].nunique() == 2):\n            print(col,'has binary strings')\n        else:\n            print(col,'has multi stings')\n\n\nlibraries()\neda()\n\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of DataSet'+'\\033[0m')\nprint('\\033[1m'+'DataTypes in the DataSet:\\n'+'\\033[0m',df.dtypes)\nprint('\\033[1m'+'Columns in DataSet:'+'\\033[0m',df.columns)\nprint('\\033[1m'+'Shape of DataSet:'+'\\033[0m',df.shape)\nprint('\\033[1m'+'Size of DataSet:'+'\\033[0m',df.size)\nprint('\\033[1m'+'Dimension of DataSet:'+'\\033[0m',df.ndim)\nprint('\\033[1m'+'Total Memory used in DataSet:'+'\\033[0m',df.memory_usage().sum())\nprint('\\033[1m'+'Total Number of missing values in DataSet:'+'\\033[0m',df.isnull().sum().sum())\nprint('\\033[1m'+'Total Number of Unique values in DataSet:'+'\\033[0m',df.nunique().sum())\nprint('\\033[1m'+'Total Number of non null values in DataSet:'+'\\033[0m',df.count().sum())\nprint('\\033[1m'+'Total Number of duplicate rows in DataSet:'+'\\033[0m',df.duplicated().sum())\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of Each Colomn'+'\\033[0m')\nprint(\"\\n\")\ncols=df.columns\ncols\nfor i in cols:\n    print('\\033[1m'+i+'\\033[0m')\n    stats_u(df,i)\n    print(\"\\n\")\n            ","631074db":"df.head()","d3fd7495":"df.tail()","1374ac1f":"df.dtypes","fe6f4bac":"df.columns","cdb41374":"df.size","d84bd4da":"df.shape","6111c365":"df.info()","3685fcee":"df.describe()","5eaf6410":"df.isnull().sum()","be7041a5":"df.duplicated().sum()","f4cccdcf":"df.skew()","7619df6b":"df.corr()","192f2c9f":"df['CHAS'].value_counts()\n# 0 = no rivers\n# 1= rivers at surroundings","f48e4b80":"sns.countplot(x = 'CHAS',data = df)\nplt.show()","efde9469":"df['RAD'].value_counts()\n\n# rad = index of accessbility of highways","20b5251f":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","14ed4245":"df_nunique = {var: pd.DataFrame(df[var].value_counts()) \n              for var in {'CHAS','RAD'}}\nmulti_table([df_nunique['CHAS'], df_nunique['RAD']])","01503107":"df_groupby = {var: pd.DataFrame(df.groupby([var, 'CRIM']).size()) \n              for var in {'CHAS','RAD'}}","ff917db3":"multi_table([df_groupby['CHAS'],df_groupby['RAD']])","77a504d6":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True,cmap = 'viridis')\nplt.show()","2e854498":"''' Plot a Shifted Correlation Matrix '''\n# Diagonal correlation is always unity & less relevant, shifted variant shows only relevant cases\ndef corrMat(df,id=False):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=(12,7))\n    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n#     bottom, top = ax.get_ylim() \n#     ax.set_ylim(bottom + 0.5, top - 0.5) \n    ax.set_title('Shifted Linear Correlation Matrix')\n    \ncorrMat(df.drop(['CHAS','RAD'],axis = 1))","980ccba8":"'''Plot Correlation to Target Variable only'''\ndef corrMat2(df,target='MEDV',figsize=(9,0.5),ret_id=False):\n    \n    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n    corr_mat = corr_mat.transpose()\n    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n    if(ret_id is False):\n        f, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                     cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n        plt.title(f'Feature Correlation to {target}')\n    \n    if(ret_id):\n        return corr\ncorrMat2(df.drop(['CHAS','RAD'],axis = 1))","cfa8e0bf":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='CHAS',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = df.columns\nsnsPairGrid(df[numvars_targ])","08951a2f":"data=df.copy()\ndata.groupby('CHAS')['CRIM'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('CRIM')\nplt.title('CHAS')\nplt.show()","305e9283":"data=df.copy()\ndata.groupby('CHAS')['ZN'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('ZN')\nplt.title('CHAS')\nplt.show()","bdbde406":"data=df.copy()\ndata.groupby('CHAS')['INDUS'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('INDUS')\nplt.title('CHAS')\nplt.show()","8277b1a7":"data=df.copy()\ndata.groupby('CHAS')['NOX'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('NOX')\nplt.title('CHAS')\nplt.show()","94ed213a":"data=df.copy()\ndata.groupby('CHAS')['RM'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('RM')\nplt.title('CHAS')\nplt.show()","2c85e8d0":"data=df.copy()\ndata.groupby('CHAS')['AGE'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('AGE')\nplt.title('CHAS')\nplt.show()","3f84b7b6":"data=df.copy()\ndata.groupby('CHAS')['DIS'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('DIS')\nplt.title('CHAS')\nplt.show()","229f384e":"data=df.copy()\ndata.groupby('CHAS')['TAX'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('TAX')\nplt.title('CHAS')\nplt.show()","4c91c8f0":"data=df.copy()\ndata.groupby('CHAS')['PTRATIO'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('PTRATIO')\nplt.title('CHAS')\nplt.show()","e5c0f785":"data=df.copy()\ndata.groupby('CHAS')['B'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('B')\nplt.title('CHAS')\nplt.show()","0d48ac49":"data=df.copy()\ndata.groupby('CHAS')['LSTAT'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('LSTAT')\nplt.title('CHAS')\nplt.show()","7804b665":"data=df.copy()\ndata.groupby('CHAS')['MEDV'].mean().plot.bar()\nplt.xlabel('CHAS')\nplt.ylabel('MEDV')\nplt.title('CHAS')\nplt.show()","f292a0fd":"obj= ['CHAS']\nnum = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'RAD','AGE', 'DIS', 'TAX',\n       'PTRATIO', 'B', 'LSTAT', 'MEDV']","09984ba4":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'CRIM':\n        sns.scatterplot(x= 'CRIM',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","634537c5":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'ZN':\n        sns.scatterplot(x= 'ZN',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","47f68cc1":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'INDUS':\n        sns.scatterplot(x= 'INDUS',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","5786def9":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'NOX':\n        sns.scatterplot(x= 'NOX',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","b12ecec0":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'RM':\n        sns.scatterplot(x= 'RM',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","4fe38897":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'RAD':\n        sns.scatterplot(x= 'RAD',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","c4406e57":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'AGE':\n        sns.scatterplot(x= 'AGE',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","170d46c4":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'DIS':\n        sns.scatterplot(x= 'DIS',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","27894625":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'TAX':\n        sns.scatterplot(x= 'TAX',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","e601b039":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'PTRATIO':\n        sns.scatterplot(x= 'PTRATIO',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","4343b0cb":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'B':\n        sns.scatterplot(x= 'B',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","36907f50":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'LSTAT':\n        sns.scatterplot(x= 'LSTAT',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')","0178c39f":"x = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.boxplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","3fcb363c":"x = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.violinplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","ff83b01e":"sns.set(rc={'figure.figsize':(10,8)})\nfor j in range(len(num)):\n    if num[j] != 'MEDV':\n        sns.scatterplot(x= 'MEDV',y=num[j],hue='CHAS',data=df)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n        plt.show()\n        print('-----------------------------------------------------------------------')\n        \n# MEDV is positively corealted with ZM,RM,DIS,B        ","c6e4df9f":"for j in range(len(num)):\n    if num[j] != 'MEDV':\n        sns.scatterplot(x= 'MEDV',y=num[j],data=df)\n        plt.show()","cc5b8026":"df1 = df.groupby('CHAS').agg({'CRIM' : 'mean', 'ZN' : 'mean', 'INDUS' : 'mean', 'NOX' : 'mean', 'RM' : 'mean',\n                              'AGE' : 'mean', 'DIS' : 'mean', 'TAX' : 'mean',\n       'PTRATIO' : 'mean', 'B' : 'mean', 'LSTAT' : 'mean', 'MEDV' : 'mean'})\ndf1","821431e7":"px.bar(data_frame=df1, barmode='group',\n       title = \"<b>CHAS wise Analyzing<\/b>\",template=\"plotly_dark\")","a64a971a":"df2 = df.groupby('RAD').agg({'CRIM' : 'mean', 'ZN' : 'mean', 'INDUS' : 'mean', 'CHAS' : 'sum', 'NOX' : 'mean', 'RM' : 'mean',\n                              'AGE' : 'mean', 'DIS' : 'mean', 'TAX' : 'mean',\n       'PTRATIO' : 'mean', 'B' : 'mean', 'LSTAT' : 'mean', 'MEDV' : 'mean'})\ndf2","78019256":"px.bar(data_frame=df2[:-1], barmode='group',\n       title = \"<b>RAD wise Analyzing<\/b>\",template=\"plotly_dark\")","63a03c50":"px.bar(data_frame=df2[-1:], barmode='group',\n       title = \"<b>RAD wise Analyzing<\/b>\",template=\"plotly_dark\")","127296b4":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in x.columns:\n    count_outliers(x,i)\n# less outliers no need to rectify","aac3b595":"Num_vars = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX',\n       'PTRATIO', 'B', 'LSTAT', 'MEDV']","061b3464":"Cat_vars = df.drop(Num_vars, axis = 1).columns.tolist()\nCat_vars","9a382b76":"Cat_vars_low = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() < 10)].nunique().index)\nCat_vars_high = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() >= 10)].nunique().index)","fdc1da1e":"sns.set_theme(rc = {'grid.linewidth': 0.5,\n                    'axes.linewidth': 0.75, 'axes.facecolor': '#fff3e9', 'axes.labelcolor': '#6b1000',\n                    'figure.facecolor': '#f7e7da'})\n                    #'xtick.labelcolor': '#6b1000', 'ytick.labelcolor': '#6b1000'","a1fd940a":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['MEDV']), \n                        hue =  np.log(df['MEDV']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","c2cc1b3a":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['CRIM']), \n                        hue =  np.log(df['CRIM']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","4d5a47db":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['ZN']), \n                        hue =  np.log(df['ZN']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","0a3cb7d9":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['INDUS']), \n                        hue =  np.log(df['INDUS']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","1fa72e02":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['NOX']), \n                        hue =  np.log(df['NOX']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","23b47b98":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['RM']), \n                        hue =  np.log(df['RM']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","a8fe7f8f":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['AGE']), \n                        hue =  np.log(df['AGE']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","294f95b3":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['DIS']), \n                        hue =  np.log(df['DIS']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","f720edb1":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['TAX']), \n                        hue =  np.log(df['TAX']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","10bccaa2":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['PTRATIO']), \n                        hue =  np.log(df['PTRATIO']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","8c42c2be":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['B']), \n                        hue =  np.log(df['B']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","4ebd6815":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(4, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['LSTAT']), \n                        hue =  np.log(df['LSTAT']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","f470c127":"train_num_visual_0 = df.select_dtypes(include = ['float64']).columns.tolist()","251f56fb":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['MEDV'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","ccd3a637":"list(zip(Num_vars, ax_0.flatten()))","a59a6e1b":"list(enumerate(zip(Num_vars, ax_0.flatten())))","571ec561":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['CHAS']].columns.tolist()","e689571b":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.55)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['MEDV'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['MEDV'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['MEDV'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","2346024d":"X = df.drop(['MEDV'],axis = 1)\nY = df['MEDV']\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.33,random_state=44)","adc99b89":"from sklearn.ensemble import RandomForestRegressor\nforest= RandomForestRegressor(n_estimators =40, random_state = 0)\nforest.fit(X_train,Y_train)  \ny_pred = forest.predict(X_test)\nforest.score(X_test,Y_test)","ab272f25":"sns.set(rc={'figure.figsize':(10,8)})\nplt.scatter(Y_test,y_pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","b07be279":"metrics.explained_variance_score(Y_test,y_pred)","4047dabf":"print('MAE',metrics.mean_absolute_error(Y_test,y_pred))\nprint('MSE',metrics.mean_squared_error(Y_test,y_pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(Y_test,y_pred)))","f23fef63":"sns.displot(Y_test-y_pred,bins = 50,kde = True)","b6f0584c":"#### Distance to boston centers is very near to houses which are not near to river","c0184a19":"#### Houses near rivers are older than houses which are not near to river","3c706419":"# Data Visualisation","816973c8":"# (IMPORTANT) Analysis using groupby","67e39619":"#### Price of house near rivers are more","3ed7a597":"# Prediction using Random Forest Regressor","60513997":"#### Nitric oxide concentration is more neaar rivers","b8042e81":"## Getting unique values of each category","ac7d7e68":"#### We can see that our target variable having many negative correaltion columns it has highly corealation with RM","87f67aa6":"## Now I will plot groupby of categorical column(Primary Type) with average values numerical columns ","1abc9e85":"## Boxplot of numerical columns","027824bd":"#### Average rooms is almost same with or without river","99400d0a":"# Importing Libraries","c6fd22cb":"## Scatterplot of target column(MEDV)","4bd22108":"#### Low status of population are having houses not near rivers","8e267e6a":"# Exploratory Data Analysis","15df971e":"#### Square feets number is big where there are no rivers","7aac543a":"#### pupil teacher ratio is high for the people having houses not near to river","af817369":"# Count Of Outliers","aeaf273f":"#### Non retail business acers are more near rivers","25195cc3":"#### Tax is alomost same irrespective of river surrounded or not","f3c2d6b6":"## violin plot of numerical columns","958caa97":"## grouped tables for categorical variables","7f9d796f":"# Loading Data Set","f28ca927":"#### Values are distrubuted normally so our model is good","d0db3337":"## Scatter PLots","6b58dd23":"# Exploratory Data Analysis Using User Defined Function","72812c66":"#### more values are in no river criteria and they are stacked at one place","3c5525ac":"# Feature Selection","789a6dd0":"## Summary of column\n#### CRIM: per capita crime rate by town\n#### ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n#### INDUS: proportion of non-retail business acres per town\n#### CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n#### NOX: nitric oxides concentration (parts per 10 million)\n#### RM: average number of rooms per dwelling\n#### AGE: proportion of owner-occupied units built prior to 1940\n#### DIS: weighted distances to \ufb01ve Boston employment centers\n#### RAD: index of accessibility to radial highways\n##### TAX: full-value property-tax rate per  10,000 dollars\n#### PTRATIO: pupil-teacher ratio by town 12. B: 1000(Bk\u22120.63)2 where Bk is the proportion of blacks by town 13. \n#### LSTAT: % lower status of the population\n#### MEDV: Median value of owner-occupied homes in $1000s","3fd04dae":"# Advanced visualisation","f63312b6":"#### Blacks are mainly having houses near river","15972cbb":"#### Crime rate is high where there are no rivers","9083be15":"### So our target variable is MEDV"}}