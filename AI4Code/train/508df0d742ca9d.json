{"cell_type":{"ce1c78be":"code","ae347331":"code","53d8a640":"code","a2acb9dd":"code","557a61b1":"code","dd2d29f4":"code","665a0c91":"code","5edaf428":"code","90122b5c":"code","699c58f9":"code","84f02575":"code","791eb0e0":"code","c9e1731d":"code","2611867d":"code","2aedf891":"code","f63e662f":"code","83acedb8":"code","e6dd9189":"markdown","2ae718df":"markdown","7a15c72d":"markdown","922af606":"markdown","9584b519":"markdown","8a714a24":"markdown","064e77e2":"markdown","23b2ca50":"markdown","d5edf16b":"markdown","7862ac4c":"markdown","901ea0f6":"markdown","6d440db3":"markdown","ca620563":"markdown","e495664d":"markdown","2ad5ab25":"markdown"},"source":{"ce1c78be":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\/pokemon-challenge-mlh\"))\nprint(os.listdir(\"..\/input\/\"))","ae347331":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Dropout\nsns.set_context(\"paper\")\nprint(tf.__version__)","53d8a640":"def super_battle(battles, duplicate=False):\n    battles[\"first_turn\"] = 0\n    \n    if duplicate:\n        battles2 = pd.DataFrame({\n            \"idx\" : battles['battle_number'] + battles['battle_number'].max() + 1,\n            \"battle_number\" : battles['battle_number'] + battles['battle_number'].max() + 1,\n            \"first_pokemon\" : battles[\"second_pokemon\"],\n            \"second_pokemon\" : battles[\"first_pokemon\"],\n            \"winner\": np.abs(battles[\"winner\"] - 1), \n            \"first_turn\": 1    \n        }\n        ).set_index(\"idx\")\n        battles2.index.name = None\n        battles = pd.concat([battles, battles2])\n    \n    return battles","a2acb9dd":"typetable = pd.read_csv(\"..\/input\/pokemon-type-table\/typetable.csv\")\nvals = []\n\nfor c1 in typetable.columns[1:]:\n    vals.append(pd.DataFrame({\n        \"idx\": typetable[\"atck\"].map(lambda x: \"%s-vs-%s-None\" % (x, c1)), #.rename(None)\n        \"mul\": typetable[c1],\n    }))\n    for c2 in typetable.columns[1:]:\n        vals.append(pd.DataFrame({\n            \"idx\": typetable[\"atck\"].map(lambda x: \"%s-vs-%s-%s\" % (x, c1, c2)), #.rename(None)\n            \"mul\": typetable[c1] * typetable[c2],\n        }))\n    \nmult = pd.concat(vals).reset_index().drop([\"index\"], axis=1)\nmult = dict(zip(mult.values[:,0], mult.values[:,1]))\ndef multiplier(cat):\n    return mult.get(cat, 0)\n\nprint(multiplier(\"Water-vs-Fire-None\"))\nprint(multiplier(\"Water-vs-Fire-Grass\"))\nprint(multiplier(\"Fire-vs-Water-Fire\"))\nprint(multiplier(\"Fire-vs-Grass-Bug\"))\nprint(multiplier(\"None-vs-Grass-Bug\"))","557a61b1":"def plot_history(history, title=\"\", since=40, until=-1):\n    if hasattr(history, \"history\"):\n        history = pd.DataFrame(history.history)\n    \n    if \"val_acc\" in history:\n        acc_keys = [\"acc\", \"val_acc\"]\n        los_keys = [\"loss\", \"val_loss\"]\n    else:\n        acc_keys = [\"acc\"]\n        los_keys = [\"loss\"]\n    \n    sns.set_style(\"whitegrid\")\n    \n    f = plt.figure(figsize=(16, 5))\n    rows = 1\n    cols = 2\n    ax = f.add_subplot(rows, cols, 1)\n    sns.lineplot(data=history[acc_keys].iloc[since:until]).set_title('accuracy of %s' % title)\n    ax = f.add_subplot(rows, cols, 2)\n    sns.lineplot(data=history[los_keys].iloc[since:until]).set_title('loss of %s' % title)\n    print()\n    print()\n    print(history.tail(3))","dd2d29f4":"class ModelCallback(keras.callbacks.Callback):\n    def set_params(self, params):\n        self.epochs = params[\"epochs\"]\n    \n    def on_epoch_end(self, epoch, epoch_logs):\n        print(\"\\r\", \"%5s\/%-5s \" % (epoch + 1, self.epochs), end=\"\")\n        for k, v in epoch_logs.items():\n            print(\"%s: %04.4f   \"% (k, v), end=\"\")","665a0c91":"to_underscore = lambda x: re.sub(\"[^0-9a-zA-Z#]+\", \"_\", x.lower())\nload_csv = lambda file: pd.read_csv(\"..\/input\/pokemon-challenge-mlh\/%s.csv\" % file).rename(to_underscore, axis='columns')\nto_underscore(\"First Colum. Value\")","5edaf428":"def df_pokemon():\n    pokemon = load_csv(\"pokemon\").fillna(\"None\")\n    pokemon = pokemon.drop([\"name\", \"generation\", \"legendary\"], axis = 1)\n    pokemon[\"speed2\"] = pokemon[\"speed\"] ** 2\n    # NORMALIZE\n    pokemon[\"speed2\"] = pokemon[\"speed2\"] \/ pokemon[\"speed2\"].max()\n    pokemon[\"speed\"] = pokemon[\"speed\"] \/ pokemon[\"speed\"].max()\n    pokemon[\"hp\"] = pokemon[\"hp\"] \/ pokemon[\"hp\"].max()\n\n    mx = max([pokemon[\"defense\"].max(), pokemon[\"sp_def\"].max()])\n    pokemon[\"defense\"] = pokemon[\"defense\"] \/ mx\n    pokemon[\"sp_def\"] = pokemon[\"sp_def\"] \/ mx\n\n    mx = max([pokemon[\"attack\"].max(), pokemon[\"sp_atk\"].max()])\n    pokemon[\"attack\"] = pokemon[\"attack\"] \/ mx\n    pokemon[\"sp_atk\"] = pokemon[\"sp_atk\"] \/ mx\n\n    t1 = pd.get_dummies(pokemon[\"type_1\"], prefix='t1_')\n    t2 = pd.get_dummies(pokemon[\"type_2\"], prefix='t2_')\n    ds = [pokemon, t1, t2]\n    \n    pokemon = pd\\\n        .concat(ds,axis=1)\\\n        .rename(to_underscore, axis='columns')        \n            \n    return pokemon","90122b5c":"def merge_data(battles, pokemon): \n    battles = battles \\\n        .merge(pokemon.rename(lambda x: \"f_%s\" % x, axis=\"columns\"), left_on=\"first_pokemon\", right_on=\"f_#\") \\\n        .merge(pokemon.rename(lambda x: \"s_%s\" % x, axis=\"columns\"), left_on=\"second_pokemon\", right_on=\"s_#\") \n\n    battles[\"f_t1\"] = (battles.f_type_1 + \"-vs-\" + battles.s_type_1 + \"-\" + battles.get(\"s_type_2\", \"None\")).map(multiplier)\n    battles[\"s_t1\"] = (battles.s_type_1 + \"-vs-\" + battles.f_type_1 + \"-\" + battles.get(\"f_type_2\", \"None\")).map(multiplier)\n    battles[\"f_t2\"] = (battles.f_type_2 + \"-vs-\" + battles.s_type_1 + \"-\" + battles.get(\"s_type_2\", \"None\")).map(multiplier)\n    battles[\"s_t2\"] = (battles.s_type_2 + \"-vs-\" + battles.f_type_1 + \"-\" + battles.get(\"f_type_2\", \"None\")).map(multiplier)\n\n    battles[\"f_t\"] = battles[[\"f_t1\", \"f_t2\"]].max(axis=1)\n    battles[\"s_t\"] = battles[[\"s_t1\", \"s_t2\"]].max(axis=1)\n    battles[\"f_t_min\"] = battles[[\"f_t1\", \"f_t2\"]].min(axis=1)\n    battles[\"s_t_min\"] = battles[[\"s_t1\", \"s_t2\"]].min(axis=1) \n\n    battles = battles.drop([\"f_type_1\", \"s_type_1\", \"f_type_2\", \"s_type_2\", \"f_t1\", \"f_t2\", \"s_t1\", \"s_t2\"], axis=1)\n        \n    battles = battles\\\n        .sort_values(['battle_number']) \\\n        .reset_index(drop=True) \\\n        .drop([\"battle_number\", \"first_pokemon\", \"second_pokemon\", \"f_#\", \"s_#\"], axis=1)\n    \n    return battles","699c58f9":"def params(train, units=[]):\n    X, Xs = to_model(train)\n    Y = train[\"winner\"].values\n    y = keras.utils.to_categorical(Y)\n\n    assert X.shape[0] == y.shape[0]\n    input_dim = X.shape[1]\n    outuput_dim = 1 if len(y.shape) == 1 else y.shape[1]\n    samples = train.shape[0]\n    \n    print(\"\ud835\udc41\ud835\udc56: %s, \ud835\udc41\ud835\udc5c: %s, \ud835\udc41\ud835\udc60: %s\" % (input_dim, outuput_dim, samples))\n    print(\"units: sum(%s) = %s\" % (units, sum(units)))\n    \n    return (input_dim, outuput_dim, units, X, Xs, Y, y)","84f02575":"def to_model(X):\n    if \"winner\" in X:\n        X = X.drop([\"winner\"], axis=1)\n    X = X.values\n    return X, X","791eb0e0":"def remove_duplicate_battles(battles):\n    return battles\\\n        .groupby([\"first_pokemon\", \"second_pokemon\", \"winner\"])\\\n        .count()\\\n        .reset_index()\\\n        .drop([\"battle_number\"],axis=1)\\\n        .sample(frac=1) \\\n        .reset_index(drop=True)\\\n        .reset_index()\\\n        .rename(columns={\"index\": \"battle_number\"})","c9e1731d":"battles_values = load_csv(\"battles\").values\nacc100 = dict(zip(map(tuple, battles_values[:, 1:-1]), map(tuple, battles_values[:, -1:])))","2611867d":"# MODEL PARAMS\nregularizer = {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 0.001}}\noptimizer = {'class_name': 'Adam', 'config': \n    {'lr': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'decay': 1e-5, 'epsilon': 1e-07, 'amsgrad': False\n }}\n\nloss = 'binary_crossentropy'\nmetrics = ['accuracy']\ndropout = 0.1\n\n#Dataset\npokemon = df_pokemon()\nbattles = super_battle(remove_duplicate_battles(load_csv(\"battles\")), duplicate=True)\n\ndf = merge_data(battles, pokemon)\n\n# Creating model\n(input_dim, outuput_dim, units, X, Xs, Y, y) = params(df, [110, 110, 110])\n\nmodel = keras.models.Sequential()\n\nunit, units = units[0], units[1:]\nmodel.add(Dense(unit, kernel_regularizer = regularizer, activation='relu', input_shape=Xs.shape[1:]))\nmodel.add(Dropout(dropout))\n\nfor unit in units:\n    model.add(Dense(unit, kernel_regularizer = regularizer, activation='relu'))\n    model.add(Dropout(dropout))    \n\nmodel.add(Dense(outuput_dim, activation = tf.nn.sigmoid))\nmodel.compile(optimizer = optimizer, loss = loss, metrics = metrics)\nmodel.summary()","2aedf891":"# FIT PARAMS\nepochs, validation_split = (600, 0.0)\n\nhistory = model.fit(Xs, y, workers=4, epochs=epochs, verbose=0, validation_split=validation_split, \n                        batch_size=512, shuffle=True, callbacks=[ModelCallback()], initial_epoch=0)\nplot_history((history), title=\"\", since=0)","f63e662f":"test = load_csv(\"test\")\nX, Xs = to_model(merge_data(super_battle(load_csv(\"test\")), pokemon))\n\nprediction = model.predict_classes(Xs)\ndf_submission = pd.DataFrame({\"Winner\": prediction}, index = test.index.rename(\"battle_number\"))\n\nfor i, p1, p2 in load_csv(\"test\").values:\n    if (p1, p2) in acc100: df_submission.iloc[i] = acc100[(p1, p2)][0]\n\ndf_submission.to_csv(\"solution.csv\")","83acedb8":"model.save_weights(\"cp-{epoch:04d}.ckpt\".format(epoch=epochs))\n! mkdir \"saved_models\"\nsaved_model_path = tf.contrib.saved_model.save_keras_model(model, \".\/saved_models\")","e6dd9189":"Entrenamos nuestro modelo 600 epochs.","2ae718df":"De dataframe a matriz valida para datos de entrada de nuestro modelo. (de nuevo esta funci\u00f3n vivi\u00f3 dias mejores)","7a15c72d":"Cargamos y procesamos los datos de los pokemon.\n\n* Descargamos name, generation, legendary\n* A\u00f1adiremos *speed2*: que contendr\u00e1 el cuadrado de la velocidad del pokemon.\n* Normalizamos speed2, speed, hp, defense, sp_def, attack, sp_atk\n* Pasamos a varialbes categorigas type_1 y type_2","922af606":"acc100 es un diccionario con el resultado de todas las batallas. Esto nos servira para asegurarnos unas cuantas predicciones acertadas que hay en repetidas entre el conjunto de entrenamiento y el de test. Alguien ha dicho overfitting?","9584b519":"Cargamos la tabla de tipos.","8a714a24":"Ensamblamos todo y construimos nuestro modelo.\n\nEl modelo consiste en 3 capas iguales basadas en un Dense 110 con un regularizer L2 0.001, activacion RELU + Dropout 0.1\n\nUtilizaremos un optimizador Adam con un Learning rate 0.001 y con un decay de 1e-5\n\nPara la funcion de perdida utilizaremos binary_crossentropy\n\n","064e77e2":"Duplicaremos las batallas invirtiendo el orden de los oponentes, y a\u00f1adiremos una columna extra para saber que se invirti\u00f3 el orden. Esto le permitir\u00e1 a la red aprender mejor sobre el valor de empezar primero en una batalla.\nEl parametro duplicate nos servira para diferenciar entre training y prediction","23b2ca50":"# Deep Pokemon\n\nEste kernel es una version mas limpia y comentada del que aparece en el leaderboard con un 98.350.\nSi quieres ver la version original puedes mirar los commits anteriores","d5edf16b":"Esta funcion la utilizaremos para visualizar el accuracy del entrenamiento","7862ac4c":"Usaremos keras con tensorflow","901ea0f6":"Version simplificada de la barra de progresion para el entrenamiento","6d440db3":"generador de configuracion para nuestra red neuronal. (Actualmente algunos parametros son inutiles porque antes se hacia mas magia con ellos)","ca620563":"Nuestra funcion para cargar los datasets de la competicion","e495664d":"En el set de datos de entradas hay batallas sobrerrepresentadas, con esta funcion eliminaremos esas batallas repetidas.","2ad5ab25":"Cargamos y procesamos los datos de las batallas:\n\n* A\u00f1adimos las columnas con los datos de cada pokemon\n* A\u00f1adimos el multiplicador de la tabla de tipos, pero ordenado f_t, s_t para el multiplicador mas alto y f_t_min y s_t_min para el multiplicador mas bajo"}}