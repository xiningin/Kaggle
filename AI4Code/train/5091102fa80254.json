{"cell_type":{"333427c9":"code","882116f4":"code","dbb32274":"code","32767c0d":"code","9aa98bba":"code","ab78bde1":"code","ff5e3dac":"code","05000860":"code","2daeb482":"code","4de9e00a":"code","732322b3":"code","c154f1f8":"code","1dfab629":"code","02c7153e":"code","5be27cfb":"code","de112990":"code","084355f5":"code","08ea8b6a":"code","30feb022":"code","cd5a6af7":"code","503d8e20":"markdown","5fa11be1":"markdown","cf76c20e":"markdown","d0d0b58d":"markdown","86f757f6":"markdown","282ef9bf":"markdown","bd21cdc0":"markdown","49bdc9ef":"markdown","47ec44c2":"markdown","d80717a0":"markdown","8e8f3278":"markdown","cb9bd392":"markdown","e7f78f6d":"markdown","e739c427":"markdown","f3317850":"markdown","8788f375":"markdown"},"source":{"333427c9":"# Basic Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\n%matplotlib inline\n\nnp.random.seed(2)","882116f4":"# Machine Learning\nfrom sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, cross_val_predict\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_curve, roc_curve\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn import tree, linear_model, ensemble\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore')","dbb32274":"# Setting Default Seaborn Style\nsns.set(style='white', context='notebook', palette='deep')","32767c0d":"train = pd.read_csv(\"..\/input\/chestxraypneumoniacsv\/train.csv\").iloc[:, 1:]\ntest = pd.read_csv(\"..\/input\/chestxraypneumoniacsv\/test.csv\").iloc[:, 1:]\nval = pd.read_csv(\"..\/input\/chestxraypneumoniacsv\/val.csv\").iloc[:, 1:]","9aa98bba":"df = pd.concat([train, test])\ndf","ab78bde1":"df.iloc[:, :-1] = df.iloc[:, :-1] \/ 255.0\nval.iloc[:, :-1] = val.iloc[:, :-1] \/ 255.0","ff5e3dac":"le = LabelEncoder()\n\ndf.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\nval.iloc[:, -1] = le.transform(val.iloc[:, -1])","05000860":"df.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)","2daeb482":"X_df = df.iloc[:, :-1]\ny_df = df.iloc[:, -1]\n\nX_val = val.iloc[:, :-1]\ny_val = val.iloc[:, -1]","4de9e00a":"pca_columns = []\nfor i in range(50):\n    pca_columns.append(f\"PCA{i+1}\")\n\npca = PCA(50)\n\nX_df = pd.DataFrame(pca.fit_transform(X_df), columns=pca_columns)\nX_val = pd.DataFrame(pca.transform(X_val), columns=pca_columns)","732322b3":"df_pca = pd.concat([X_df, y_df], axis=1)\nval_pca = pd.concat([X_val, y_val], axis=1)","c154f1f8":"split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(df_pca, df_pca.iloc[:, -1]):\n    train = df_pca.loc[train_index]\n    test = df_pca.loc[test_index]","1dfab629":"X_train = train.iloc[:, :-1]\ny_train = train.iloc[:, -1].values\n\nX_test = test.iloc[:, :-1]\ny_test = test.iloc[:, -1].values\n\nX_val = val.iloc[:, :-1]\ny_val = val.iloc[:, -1].values","02c7153e":"MLA_compare = pd.DataFrame()\n\nrow_index = 0\n\ndef MLA_testing(MLA, X_train, X_test, y_train, y_test):  \n    global row_index\n    \n    # Training The Model\n    MLA.fit(X_train, y_train)\n\n    # KFold Accuracies on Training Data\n    kfold_accuracy = cross_val_score(estimator = MLA, X = X_train, y = y_train, cv = 10, n_jobs=-1)\n    print(\"K-Fold Accuracies:\\n\", kfold_accuracy, \"\\n\")\n    \n    # Prediction on Testing Data\n    y_pred = cross_val_predict(estimator = MLA, X = X_test, y = y_test, cv = 10, n_jobs=-1)\n    \n    # Accuracy for y_test and y_pred\n    classifier_accuracy_score = accuracy_score(y_test, y_pred)\n    print(\"Accuracy Score:\\n\", classifier_accuracy_score, \"\\n\")\n    \n    # Confusion Matrix\n    conf_mtx = confusion_matrix(y_test, y_pred)\n    print(\"Confusion Matrix:\\n\", conf_mtx, \"\\n\")\n    \n    # Classification Report\n    class_rep = classification_report(y_test, y_pred)\n    print(\"Classification Report:\\n\", class_rep, \"\\n\")\n    \n    # Precision - Recall Curve\n    yhat = MLA.predict_proba(X_test)\n    no_skill = len(df_pca[\"784\"][df_pca[\"784\"]==1]) \/ len(df_pca[\"784\"])\n    precision, recall, _ = precision_recall_curve(y_test, yhat[:, 1])\n    \n    plt.figure(dpi=100, figsize=(15, 6))\n    plt.subplot(121)\n    sns.lineplot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n    sns.lineplot(recall, precision, marker='.', label=MLA.__class__.__name__)\n    plt.title(\"Recall vs Precision Curve\")\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.legend()\n    \n    # ROC Curve\n    plt.subplot(122)\n    sns.lineplot([0, 1], [0, 1], linestyle='--', label='No Skill')\n    fpr, tpr, _ = roc_curve(y_test, yhat[:, 1])\n    sns.lineplot(fpr, tpr, marker='.', label=MLA.__class__.__name__)\n    plt.title(\"ROC Curve\")\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    plt.show()\n\n    # Saving Data in Dataframe\n    MLA_name = MLA.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'Accuracy Score'] = classifier_accuracy_score*100\n    MLA_compare.loc[row_index, 'K-Fold Accuracy'] = kfold_accuracy.mean()*100\n\n    print(MLA_name, \"Done\")\n    \n    row_index+=1","5be27cfb":"rf_clf = ensemble.RandomForestClassifier()\n\nMLA_testing(rf_clf, X_train, X_test, y_train, y_test)","de112990":"gb_clf = ensemble.GradientBoostingClassifier()\n\nMLA_testing(gb_clf, X_train, X_test, y_train, y_test)","084355f5":"lr_clf = linear_model.LogisticRegression()\n\nMLA_testing(lr_clf, X_train, X_test, y_train, y_test)","08ea8b6a":"sgf_clf = linear_model.SGDClassifier(loss=\"log\")\n\nMLA_testing(sgf_clf, X_train, X_test, y_train, y_test)","30feb022":"dt_clf = tree.DecisionTreeClassifier()\n\nMLA_testing(dt_clf, X_train, X_test, y_train, y_test)","cd5a6af7":"MLA_compare = MLA_compare.sort_values(by=\"K-Fold Accuracy\", ascending=False).reset_index(drop=True)\nMLA_compare","503d8e20":"## Importing the Data","5fa11be1":"# Preparing Data For Model","cf76c20e":"## Feature Scaling","d0d0b58d":"## RandomForestClassifier","86f757f6":"## LogisticRegression","282ef9bf":"# Classification Model - ML","bd21cdc0":"## Stratified Train Test Split","49bdc9ef":"# Comparing Algorithm's Performance","47ec44c2":"## Before Proceeding i Request you to add the Dataset at the link Below for the Code Below to Function\nhttps:\/\/www.kaggle.com\/datarohitingole\/chestxraypneumoniacsv\n### What i did is used PIL and Numpy to scale all the Images to 28x28 size and store them as Numeric data in CSV Files.","d80717a0":"## SGDClassifier","8e8f3278":"# Data Preprocessing","cb9bd392":"## GradientBoostingClassifier","e7f78f6d":"## Label encoding","e739c427":"## PCA","f3317850":"# Importing Libraries","8788f375":"## DecisionTreeClassifier"}}