{"cell_type":{"10e35866":"code","55ce44a5":"code","79b77540":"code","4158c519":"code","0d913eb0":"code","d071e3ba":"code","4340d3f5":"code","0464038c":"code","1e5c724f":"code","69d058f5":"code","be3838cc":"code","b5cacf88":"code","8beba63d":"code","ebed6a69":"code","74a5ab1d":"code","4645a5d0":"code","2ea8b941":"code","188f078a":"code","751d8dd4":"code","9edd6c8d":"code","a844eb57":"code","c0ddccb9":"code","f87e71d3":"code","e5add23f":"code","7a17ea48":"code","f990a9ba":"code","0095bc2f":"code","ff0c4595":"code","4aa51133":"code","98324a52":"code","57253237":"code","b7254247":"code","28086760":"code","d6231f41":"code","7979898c":"code","05dd7067":"code","92d42ae1":"code","07c014ce":"code","598642f7":"code","b1f60ca5":"code","4a50f165":"code","4e6e2ba4":"code","fdb652e7":"code","b1713608":"code","6ec84c1a":"code","760f6fe3":"code","2e47431f":"code","7bfd3ff1":"code","21a6db90":"code","3079a3eb":"code","6c0aab50":"markdown","909b07ca":"markdown","8ba9b68c":"markdown","e91bb777":"markdown","73aa4fae":"markdown","9ea76734":"markdown","9fb8b0aa":"markdown","e80cbf94":"markdown","fd6dbabb":"markdown","1443edd5":"markdown","69e5bdbd":"markdown","68448d96":"markdown","6ba2709b":"markdown","967d8a96":"markdown","01f0caf4":"markdown","78902b2d":"markdown","4d8f67a2":"markdown","4cd72b6e":"markdown"},"source":{"10e35866":"# Base\n# -----------------------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration\n# -----------------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\npd.set_option('display.max_columns', None)\npd.options.display.float_format = '{:.2f}'.format\n\n# Models \n# -----------------------------------\nimport lightgbm as lgb\n\n# Metrics & Evaluation\n# -----------------------------------\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV","55ce44a5":"# Grab Column Names\ndef grab_col_names(dataframe, cat_th=10, car_th=20, show_date = False):\n\n    date_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"datetime64[ns]\"]\n\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\" and dataframe[col].dtypes != \"datetime64[ns]\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'date_cols: {len(date_cols)}')\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    # cat_cols + num_cols + cat_but_car = de\u011fi\u015fken say\u0131s\u0131.\n    # num_but_cat cat_cols'un i\u00e7erisinde zaten.\n    # dolay\u0131s\u0131yla t\u00fcm \u015fu 3 liste ile t\u00fcm de\u011fi\u015fkenler se\u00e7ilmi\u015f olacakt\u0131r: cat_cols + num_cols + cat_but_car\n    # num_but_cat sadece raporlama i\u00e7in verilmi\u015ftir.\n\n    if show_date == True:\n        return date_cols, cat_cols, cat_but_car, num_cols, num_but_cat\n    else:\n        return cat_cols, cat_but_car, num_cols, num_but_cat\n    \n    \n# Rare Encoder\ndef rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n\n    rare_columns = [col for col in temp_df.columns if temp_df[col].nunique() >= 5 and temp_df[col].nunique() <= 20\n                    and (temp_df[col].value_counts() \/ len(temp_df) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() \/ len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n\n        return temp_df\n      \n# Missing Value\ndef missing_values(data, plot = False, target = \"SalePrice\"):\n    \n    mst = pd.DataFrame({\"Num_Missing\":data.isnull().sum(), \"Missing_Ratio\":data.isnull().sum() \/ data.shape[0]}).sort_values(\"Num_Missing\", ascending = False)\n    mst[\"DataTypes\"] = data[mst.index].dtypes.values\n    mst = mst[mst.Num_Missing > 0].reset_index().rename({\"index\":\"Feature\"}, axis = 1)\n    mst = mst[mst.Feature != target]\n    \n    print(\"Number of Variables include Missing Values:\", mst.shape[0], \"\\n\")\n    \n    if mst[mst.Missing_Ratio >= 1.0].shape[0] > 0:  \n        print(\"Full Missing Variables:\",mst[mst.Missing_Ratio >= 1.0].Feature.tolist())\n        data.drop(mst[mst.Missing_Ratio >= 1.0].Feature.tolist(), axis = 1, inplace = True)\n\n        print(\"Full missing variables are deleted!\", \"\\n\")\n\n    if plot:\n        plt.figure(figsize = (25, 8))    \n        p = sns.barplot(mst.Feature, mst.Missing_Ratio)\n        for rotate in p.get_xticklabels():\n            rotate.set_rotation(90)\n        plt.show()    \n            \n    print(mst, \"\\n\")        \n    \n    \n# Ordinal Variables\ndef ordinal(serie, category):\n    numeric = np.arange(1, len(category)+1, 1)\n    zip_iterator = zip(category, numeric)\n    mapping = dict(zip_iterator)\n    serie = serie.map(mapping)\n    return serie\n\ndef transform_ordinal(data, ordinal_vars, category):\n    \n    for i in ordinal_vars:\n        data[i] = ordinal(data[i], category = category)\n        \n# Categorical Variables & Target\ndef cat_analyzer(dataframe, variable, target):   \n    print(variable)\n    print(pd.DataFrame({\n        \"COUNT\":dataframe[variable].value_counts(),\n        \"RATIO\":dataframe[variable].value_counts() \/ len(dataframe),\n        \"TARGET_COUNT\":dataframe.groupby(variable)[target].count(),\n        \"TARGET_MEAN\":dataframe.groupby(variable)[target].mean(),\n        \"TARGET_MEDIAN\":dataframe.groupby(variable)[target].median(),\n        \"TARGET_STD\":dataframe.groupby(variable)[target].std()}), end=\"\\n\\n\\n\")\n        \n# One Hot Encoder        \ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n    \n# Label Encoder\ndef label_encoder(dataframe, binary_col):\n    labelencoder = preprocessing.LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n  \n# CART FEATURE GENERATOR\ndef cart_feature_gen(model_type, dataframe, X, y, suffix = None):\n    # Model Type\n    if model_type == \"reg\":\n        from sklearn.tree import DecisionTreeRegressor\n        model = DecisionTreeRegressor()\n    elif model_type == \"class\":\n        from sklearn.tree import DecisionTreeClassifier\n        model = DecisionTreeClassifier()\n    else:\n        print(\"Give a model type! model_type argument should be equal to 'reg' or 'class'\")\n        return None\n    \n    # Remove NaN\n    temp = dataframe[[X,y]].dropna()\n    \n    # Fit a tree\n    rules = model.fit(temp[[X]], temp[y])\n  \n    # First Decision Rule\n    print(X)\n    print(\"Threshold:\", rules.tree_.threshold[0])\n    print(\"Range:\", \"[\"+str(dataframe[X].min())+\" - \"+str(dataframe[X].max()) +\"]\", \"\\n\")\n    if suffix == None:\n        new_colname = \"DTREE_\"+X.upper()\n    else:\n        new_colname = \"DTREE_\"+suffix+\"_\"+X.upper()\n    dataframe[new_colname] = np.where(dataframe[X] <= rules.tree_.threshold[0], 1, 0)   ","79b77540":"# Import\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\n# Bind rows\ndf = train.append(test)\n\n# Num of dtypes\ncat_cols, cat_but_car, num_cols, num_but_cat = grab_col_names(df, car_th=10)\n\n# Dimensions\nprint(df.shape, train.shape, test.shape)\n\ndf.head()","4158c519":"# First investigation\nmissing_values(df, plot = True, target = \"SalePrice\")","0d913eb0":"# Some categorical variables includes None category as missing value.\ncat_missing = [\"Alley\", 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1','BsmtFinType2','Fence', \"MiscFeature\",\n               \"FireplaceQu\", \"GarageFinish\",\"GarageCond\", \"GarageQual\", \"GarageType\", \"MasVnrType\"]\n\n# Fill NA\nfor i in cat_missing:\n    df[i] = df[i].fillna(\"None\")","d071e3ba":"# Second investigation    \nmissing_values(df, plot = False, target = \"SalePrice\")","4340d3f5":"ordinal_vars = [\n    \"LotShape\", \"OverallQual\", \"OverallCond\", \"ExterQual\", \"ExterCond\", \"BsmtQual\",\n    \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"HeatingQC\", \"KitchenQual\", \"Functional\",\n    \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"Fence\", \"Electrical\", \"LandSlope\"\n]\n\ncat_cols, cat_but_car, num_cols, num_but_cat = grab_col_names(df.drop(ordinal_vars, axis = 1), car_th=10)","0464038c":"df.ExterQual.unique()","1e5c724f":"# Same Categories        \ntransform_ordinal(\n    df, \n    ordinal_vars = [\"ExterQual\", \"ExterCond\", \"HeatingQC\",\"KitchenQual\"],\n    category = [\"Po\", \"Fa\", \"TA\", \"Gd\" ,\"Ex\"]\n)\n\ntransform_ordinal(\n    df, \n    ordinal_vars = [\"BsmtQual\", \"BsmtCond\", \"FireplaceQu\",\"GarageCond\", \"GarageQual\"],\n    category = [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\",\"Ex\"]\n)\n\ntransform_ordinal(\n    df, \n    ordinal_vars = [\"BsmtFinType1\", \"BsmtFinType2\"],\n    category = [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\",\"GLQ\"]\n)\n\n# Different\ndf[\"LotShape\"] = ordinal(df[\"LotShape\"], category = [\"IR3\", \"IR2\", \"IR1\",\"Reg\"])\ndf[\"BsmtExposure\"] = ordinal(df[\"BsmtExposure\"], category = [\"None\", \"No\", \"Mn\", \"Av\",\"Gd\"])\ndf[\"Functional\"] = ordinal(df[\"Functional\"], category = [\"Sal\", \"Sev\", \"Maj2\", \"Maj1\", \"Mod\", \"Min2\", \"Min1\",\"Typ\"])\ndf[\"Fence\"] = ordinal(df[\"Fence\"], category = [\"None\", \"MnWw\", \"GdWo\", \"MnPrv\",\"GdPrv\"])\ndf[\"Electrical\"] = ordinal(df[\"Electrical\"], category = ['SBrkr', 'FuseA', 'FuseF', 'FuseP', 'Mix'])\ndf[\"LandSlope\"] =  ordinal(df[\"LandSlope\"], category = ['Gtl', 'Mod', \"Sev\"])\nprint(\"Ordinal transformation completed!\")  ","69d058f5":"# Run Cat Analyzer for Ordinal Variables\nfor i in ordinal_vars:\n    cat_analyzer(df, i, \"SalePrice\") ","be3838cc":"# Create Ordinal Scores\ndf[\"TotalQual\"] = df[[\"OverallQual\", \"OverallCond\", \"ExterQual\", \"ExterCond\", \"BsmtCond\", \"BsmtFinType1\", \n                      \"BsmtFinType2\", \"HeatingQC\", \"KitchenQual\", \"Functional\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"Fence\"]].sum(axis = 1)\ndf[\"BsmtQual\"] = df[[\"BsmtCond\", \"BsmtFinType1\", \"BsmtFinType2\"]].sum(axis = 1)\ndf[\"TotalGarageQual\"] = df[[\"GarageQual\", \"GarageCond\"]].sum(axis = 1)\ndf[\"Overall\"] = df[[\"OverallQual\", \"OverallCond\"]].sum(axis = 1)\ndf[\"Exter\"] = df[[\"ExterQual\", \"ExterCond\"]].sum(axis = 1)\ndf[\"ExtraQual\"] = df[[\"Fence\", \"FireplaceQu\", \"Functional\", \"HeatingQC\"]].sum(axis = 1)\ndf[\"Qual\"] = df[[\"OverallQual\", \"ExterQual\", \"GarageQual\", \"Fence\", \"BsmtFinType1\", \"BsmtFinType2\", \"KitchenQual\", \"FireplaceQu\"]].sum(axis = 1)\ndf[\"Cond\"] = df[[\"OverallCond\", \"ExterCond\", \"GarageCond\", \"BsmtCond\", \"HeatingQC\", \"Functional\"]].sum(axis = 1)\ndf[\"CLUSTER_TOTALQUAL\"] = pd.qcut(df.TotalQual, q=10, labels=range(1,11))\ndf.groupby(\"CLUSTER_TOTALQUAL\").SalePrice.agg({\"count\", \"mean\", \"median\", \"std\"})\n\n\n# Create Ratio\ndf[\"RATIO_OVERALLQ\"] = df.OverallQual \/ df.TotalQual\ndf[\"RATIO_OVERALLC\"] = df.OverallCond \/ df.TotalQual\ndf[\"RATIO_EXTERQ\"] = df.ExterQual \/ df.TotalQual\ndf[\"RATIO_EXTERC\"] = df.ExterCond \/ df.TotalQual\ndf[\"RATIO_BSMTC\"] = df.BsmtCond \/ df.TotalQual\ndf[\"RATIO_BSMTFT1\"] = df.BsmtFinType1 \/ df.TotalQual\ndf[\"RATIO_BSMTFT2\"] = df.BsmtFinType2 \/ df.TotalQual\ndf[\"RATIO_HEATINGQC\"] = df.HeatingQC \/ df.TotalQual\ndf[\"RATIO_KITCHENQ\"] = df.KitchenQual \/ df.TotalQual\ndf[\"RATIO_FUNCTIONAL\"] = df.Functional \/ df.TotalQual\ndf[\"RATIO_FIREPLACEQ\"] = df.FireplaceQu \/ df.TotalQual\ndf[\"RATIO_GARAGEQ\"] = df.GarageQual \/ df.TotalQual\ndf[\"RATIO_GARAGEC\"] = df.GarageCond \/ df.TotalQual\ndf[\"RATIO_FENCE\"] = df.Fence \/ df.TotalQual\n\n# Grade\ndf[\"OverallGrade\"] = (df[\"OverallQual\"]+1) * (df[\"OverallCond\"]+1)\ndf[\"BsmtGrade\"] = (df[\"BsmtQual\"]+1) * (df[\"BsmtCond\"]+1)\ndf[\"GarageGrade\"] = (df[\"GarageQual\"]+1) * (df[\"GarageCond\"]+1)\ndf[\"ExterGrade\"] = (df[\"ExterQual\"]+1) * (df[\"ExterCond\"]+1)\ndf[\"KitchenGrade\"] = (df[\"KitchenAbvGr\"]+1) * (df[\"KitchenQual\"]+1)\ndf[\"FireplaceGrade\"] = (df[\"Fireplaces\"]+1) * (df[\"FireplaceQu\"]+1)\ndf[\"DifGrade\"] = (df.HeatingQC+1)*(df.Functional+1)*(df.Fence+1)*(df.Electrical+1)\n\n# Unite some categories by looking summary stats\ndf[\"LotShape\"] = np.where(df.LotShape == 1, 2, df[\"LotShape\"])\ndf[\"OverallQual\"] = np.where(df.OverallQual.isin([1, 2, 3]), 3, df[\"OverallQual\"])\ndf[\"OverallCond\"] = np.where(df.OverallCond.isin([1, 2, 3]), 3, df[\"OverallCond\"])\ndf[\"ExterCond\"] = np.where(df.ExterCond.isin([1, 2]), 2, df[\"ExterCond\"])\ndf[\"ExterCond\"] = np.where(df.ExterCond.isin([5]), 4, df[\"ExterCond\"])\ndf[\"BsmtQual\"] = np.where(df.BsmtQual.isin([1,2,3]), 3, df[\"BsmtQual\"])\ndf[\"BsmtCond\"] = np.where(df.BsmtCond.isin([1,2]), 2, df[\"BsmtCond\"])\ndf[\"HeatingQC\"] = np.where(df.HeatingQC.isin([1]), 2, df[\"HeatingQC\"])\ndf[\"Functional\"] = np.where(df.Functional.isin([2]), 3, df[\"Functional\"])\ndf[\"Functional\"] = np.where(df.Functional.isin([6]), 7, df[\"Functional\"])\ndf[\"FireplaceQu\"] = np.where(df.FireplaceQu.isin([1]), 2, df[\"FireplaceQu\"])\ndf[\"GarageQual\"] = np.where(df.GarageQual.isin([2]), 3, df[\"GarageQual\"])\ndf[\"GarageQual\"] = np.where(df.GarageQual.isin([5,6]), 4, df[\"GarageQual\"])\ndf[\"GarageCond\"] = np.where(df.GarageCond.isin([2]), 3, df[\"GarageCond\"])\ndf[\"GarageCond\"] = np.where(df.GarageCond.isin([5,6]), 4, df[\"GarageCond\"])\ndf[\"Fence\"] = np.where(df.Fence.isin([2]), 3, df[\"Fence\"])\ndf[\"Electrical\"] = np.where(df.Electrical.isin([4,5]), 3, df[\"Electrical\"])","b5cacf88":"# Show variables\ncat_but_car","8beba63d":"# Some categories are same\ndf[\"Exterior1st\"] = np.where((df[\"Exterior1st\"].isin([\"Brk Cmn\", \"BrkComm\"])) | (df[\"Exterior2nd\"].isin([\"Brk Cmn\", \"BrkComm\"])), \"BrkComm\",df[\"Exterior1st\"])\ndf[\"Exterior2nd\"] = np.where((df[\"Exterior1st\"].isin([\"Brk Cmn\", \"BrkComm\"])) | (df[\"Exterior2nd\"].isin([\"Brk Cmn\", \"BrkComm\"])), \"BrkComm\",df[\"Exterior2nd\"])\ndf[\"Exterior1st\"] = np.where((df[\"Exterior1st\"].isin([\"CemntBd\", \"CmentBd\"])) | (df[\"Exterior2nd\"].isin([\"CemntBd\", \"CmentBd\"])), \"CmentBd\",df[\"Exterior1st\"])\ndf[\"Exterior2nd\"] = np.where((df[\"Exterior1st\"].isin([\"CemntBd\", \"CmentBd\"])) | (df[\"Exterior2nd\"].isin([\"CemntBd\", \"CmentBd\"])), \"CmentBd\",df[\"Exterior2nd\"])\ndf[\"Exterior1st\"] = np.where((df[\"Exterior1st\"].isin([\"Wd Shng\", \"WdShing\"])) | (df[\"Exterior2nd\"].isin([\"Wd Shng\", \"WdShing\"])), \"WdShing\",df[\"Exterior1st\"])\ndf[\"Exterior2nd\"] = np.where((df[\"Exterior1st\"].isin([\"Wd Shng\", \"WdShing\"])) | (df[\"Exterior2nd\"].isin([\"Wd Shng\", \"WdShing\"])), \"WdShing\",df[\"Exterior2nd\"])\n","ebed6a69":"# Cat Analyzer\nfor i in cat_but_car:\n    cat_analyzer(df, i, \"SalePrice\")\n  \n  \n# Rare Encoder for Exterior\nfor i in ['Exterior1st', 'Exterior2nd']:\n    df[i] = rare_encoder(df[[i]], rare_perc=0.01)\n  ","74a5ab1d":"# Cat Analyzer\nfor i in cat_but_car:\n    cat_analyzer(df, i, \"SalePrice\")","4645a5d0":"# Neighborhood \nsns.stripplot(x='Neighborhood', y='SalePrice', data=df, jitter=True)\n#sns.despine()\nplt.show()","2ea8b941":"\n\n# Create Cluster\nngb =df.groupby(\"Neighborhood\").SalePrice.mean().reset_index()\nngb[\"CLUSTER_NEIGHBORHOOD\"] = pd.cut(df.groupby(\"Neighborhood\").SalePrice.mean().values, 4, labels = range(1,5))\nngb.groupby(\"CLUSTER_NEIGHBORHOOD\").SalePrice.agg({\"count\", \"mean\", \"max\"})\ndf = pd.merge(df, ngb.drop([\"SalePrice\"], axis = 1), how = \"left\", on = \"Neighborhood\")\ndf.groupby(\"CLUSTER_NEIGHBORHOOD\").SalePrice.agg({\"count\", \"median\", \"mean\", \"max\", \"std\"})\ndel ngb","188f078a":"# One Hot Encoder for CAT BUT CAR\ndf = one_hot_encoder(df, cat_but_car, drop_first=True)","751d8dd4":"time_cols = [\"GarageYrBlt\", \"MoSold\", \"YrSold\", \"YearBuilt\", \"YearRemodAdd\"]\n\nfor i in time_cols:\n    print(i)\n    print(\"MIN:\", df[i].min(), \"\\t\", \"MAX:\", df[i].max(), \"\\n\")\n\nfor i in time_cols:\n    df.plot.scatter(x = i, y =\"SalePrice\")\n    plt.show()","9edd6c8d":"# Some issues\n# same as construction date if no remodeling or additions\ndf.YearRemodAdd = np.where(df.YearRemodAdd.isnull(), df.YearBuilt, df.YearRemodAdd)\ndf.YearRemodAdd = np.where(df.YearBuilt > df.YearRemodAdd, df.YearBuilt, df.YearRemodAdd)\ndf.YrSold = np.where(df.YearBuilt > df.YrSold, df.YearBuilt, df.YrSold)\ndf.YrSold = np.where(df.YearRemodAdd > df.YrSold, df.YearRemodAdd, df.YrSold)\n\ndf[\"GarageYrBlt\"] = np.where(df.GarageYrBlt == 2207, 2007, df.GarageYrBlt)\n\n# Age Features\ndf[\"HOUSEAGE\"] = df.YrSold - df.YearBuilt\ndf[\"REMODAGE\"] = df.YrSold - df.YearRemodAdd\ndf[\"GARAGEAGE\"] = df.YrSold - df.GarageYrBlt\ndf[\"REMODBLTAGE\"] = df.YearRemodAdd - df.YearBuilt\ndf[\"GARAGEBLTAGE\"] = df.GarageYrBlt - df.YearBuilt\n\n\ndf[\"REMODELED\"] = np.where(df.YearBuilt == df.YearRemodAdd, 0 ,1)\ndf[\"ISNEWHOUSE\"] = np.where(df.YearBuilt == df.YrSold, 1 ,0)\n\ndf.drop([\"MoSold\", \"YrSold\"],axis = 1, inplace = True)\n\n# Create Cluster\ndf[\"CLUSTER_YEARBUILT\"] = np.where(df.YearBuilt <= 1940, 1, 2)\ndf[\"CLUSTER_YEARBUILT\"] = np.where(df.YearBuilt >= 1980, 3, df[\"CLUSTER_YEARBUILT\"])\ndf[\"CLUSTER_GARAGEBUILT\"] = np.where(df.GarageYrBlt <= 1940, 1, 2)\ndf[\"CLUSTER_GARAGEBUILT\"] = np.where(df.GarageYrBlt >= 1980, 3, df[\"CLUSTER_GARAGEBUILT\"])\ndf[\"CLUSTER_YEARREMODADD\"] = np.where(df.YearRemodAdd >= 1980, 2, 1)","a844eb57":"# Apply CART Feature Generator\ntime_cols = [\"GarageYrBlt\", \"YearBuilt\", \"YearRemodAdd\", \"HOUSEAGE\", \"REMODAGE\", \"GARAGEAGE\", \"REMODBLTAGE\", \"GARAGEBLTAGE\"]\n\nfor i in time_cols:\n    cart_feature_gen(model_type=\"reg\", dataframe=df, X=i, y=\"SalePrice\", suffix = \"TIME\")\n\n# Cat Analyzer for CART Features\nfor i in df.columns[df.columns.str.contains(\"DTREE_TIME\")].tolist():\n    cat_analyzer(df, i ,\"SalePrice\")\n\n# Remove Years\ndf.drop([\"GarageYrBlt\", \"YearBuilt\", \"YearRemodAdd\"], axis = 1, inplace = True)","c0ddccb9":"num_but_cat.remove(\"YrSold\")\nnum_but_cat","f87e71d3":"df.BsmtFullBath.value_counts()","e5add23f":"for i in num_but_cat:\n    cat_analyzer(df, i ,\"SalePrice\")","7a17ea48":"df[\"TOTALBATH\"] = df.BsmtFullBath + df.BsmtHalfBath*0.5 + df.FullBath + df.HalfBath*0.5\ndf[\"TOTALFULLBATH\"] = df.BsmtFullBath + df.FullBath \ndf[\"TOTALHALFBATH\"] = df.BsmtHalfBath + df.HalfBath\ndf[\"ROOMABVGR\"] = df.BedroomAbvGr + df.KitchenAbvGr\ndf[\"RATIO_ROOMABVGR\"] = df[\"ROOMABVGR\"] \/ df.TotRmsAbvGrd","f990a9ba":"# Apply CART Feature Generator\nfor i in num_but_cat:\n    cart_feature_gen(model_type=\"reg\", dataframe=df, X=i, y=\"SalePrice\", suffix = \"NUMCAT\")\n\n# Cat Analyzer for CART Features\nfor i in df.columns[df.columns.str.contains(\"DTREE_NUMCAT\")].tolist():\n    cat_analyzer(df, i ,\"SalePrice\")","0095bc2f":"df[\"BedroomAbvGr\"] = np.where(df.BedroomAbvGr == 0, 1, df.BedroomAbvGr)\ndf[\"BedroomAbvGr\"] = np.where(df.BedroomAbvGr > 4, 4, df.BedroomAbvGr)\ndf[\"BsmtFullBath\"] = np.where(df.BsmtFullBath > 2, 2, df.BsmtFullBath)\ndf[\"Fireplaces\"] = np.where(df.Fireplaces > 2, 2, df.Fireplaces)\ndf[\"FullBath\"] = np.where(df.Fireplaces < 1, 1, df.FullBath)\ndf[\"FullBath\"] = np.where(df.Fireplaces > 2, 3, df.FullBath)\ndf[\"GRG_CARS_AREA\"] = df.GarageCars \/ df.GarageArea\ndf[\"GarageCars\"] = np.where(df.GarageCars > 2, 3, df.GarageCars)\ndf.drop([\"BsmtHalfBath\", \"KitchenAbvGr\"], axis = 1, inplace = True) # We generated this by using cart feature gen","ff0c4595":"for i in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold', \"Id\"]:\n    num_cols.remove(i)\nnum_cols","4aa51133":"# Visuals\nfor i in num_cols:\n    #if i == \"SalePrice\":\n    #    return None\n    fig, axes = plt.subplots(1, 4, figsize = (20,4))\n    df.hist(str(i), bins = 10, ax=axes[0])\n    df.boxplot(str(i),  ax=axes[1], vert=False);\n    try: \n        sns.kdeplot(np.array(df[str(i)]),ax=axes[2])\n    except: ValueError\n    df.plot.scatter(x = i, y = \"SalePrice\", ax=axes[3])\n    cortext = df[[i, \"SalePrice\"]].corr().SalePrice.sort_values()[0]\n    axes[1].set_yticklabels([])\n    axes[1].set_yticks([])\n    axes[0].set_title(i + \" | Histogram\")\n    axes[1].set_title(i + \" | Boxplot\")\n    axes[2].set_title(i + \" | Density\")\n    axes[3].set_title(i + \" | Scatter \\n Spearman Coef:\" + str(cortext)[:5])\n    plt.show()","98324a52":"# Correlation     \ndf[num_cols].corr(\"spearman\").SalePrice.sort_values(ascending = False)[1:]","57253237":"# Floor\n# --------------------------------------\ndf[\"TOTAL_FLRSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\ndf[\"Floor\"] = np.where((df[\"2ndFlrSF\"] < 1), 1, 2)\n\n# Basement\n# --------------------------------------\n# Total Finished Basement Area\ndf[\"TOTAL_BSMTFIN\"] = df.BsmtFinSF1+df.BsmtFinSF2\ndf[\"RATIO_BSMTFIN\"] = (df.TOTAL_BSMTFIN \/ df.TotalBsmtSF).fillna(0)\n# Is there a basement?\ndf[\"BASEMENT\"] = np.where(df.TotalBsmtSF < 1 , 0, 1)\n\n# Basement Rooms\ndf[\"BsmtRoom\"] = np.where((df.BsmtFinSF1 > 0) & (df.BsmtFinSF2 < 1), 1, np.nan)\ndf[\"BsmtRoom\"] = np.where((df.BsmtFinSF1 < 1) & (df.BsmtFinSF2 > 0 ), 1, df[\"BsmtRoom\"])\ndf[\"BsmtRoom\"] = np.where((df.BsmtFinSF1 < 1) & (df.BsmtFinSF2 < 1 ), 0, df[\"BsmtRoom\"])\ndf[\"BsmtRoom\"] = np.where((df.BsmtFinSF1 > 0) & (df.BsmtFinSF2 > 0 ), 2, df[\"BsmtRoom\"])\n\n\n# Total House Area\ndf[\"TotalHouseArea\"] = df.TOTAL_FLRSF + df.TotalBsmtSF\ndf[\"TotalSqFeet\"] = df.GrLivArea + df.TotalBsmtSF\n\n\n# Porch Area\n# --------------------------------------\ndf[\"PorchArea\"] = df.OpenPorchSF + df.EnclosedPorch + df.ScreenPorch + df[\"3SsnPorch\"] + df.WoodDeckSF\n\n\n# Lot \n# --------------------------------------\ndf[\"LotRatio\"] = df.GrLivArea \/ df.LotArea\ndf[\"RatioArea\"] = df.TotalHouseArea \/ df.LotArea\ndf[\"GarageLotRatio\"] = df.GarageArea \/ df.LotArea\n\n# Other\n# --------------------------------------\n# MasVnrArea\ndf[\"MasVnrRatio\"] = df.MasVnrArea \/ df.TotalHouseArea\n# LowQualFinSF\ndf[\"LowQualFinSFRatio\"] = df.LowQualFinSF \/ df.TotalHouseArea","b7254247":"# Apply CART Feature Generator\nnum_cols.remove(\"MSSubClass\")\nnum_cols.remove(\"SalePrice\")\n\nfor i in num_cols:\n    cart_feature_gen(model_type=\"reg\", dataframe=df, X=i, y=\"SalePrice\", suffix = \"NUM\")\n\n# Cat Analyzer for CART Features\nfor i in df.columns[df.columns.str.contains(\"DTREE_NUM\")].tolist():\n    cat_analyzer(df, i ,\"SalePrice\")","28086760":"df[\"HasMasVnrType\"] = np.where(df.MasVnrType == \"None\", 0, 1)\ndf[\"BoughtOffPlan\"] = np.where(df.SaleCondition == \"Partial\", 1, 0)\n\nfor i in ['BedroomAbvGr', 'BsmtFullBath', 'BsmtHalfBath', 'Fireplaces', 'FullBath', 'GarageCars', 'HalfBath', 'KitchenAbvGr', 'YrSold']:\n    cat_cols.remove(i)\ncat_cols = [\"MSSubClass\"]+cat_cols","d6231f41":"for i in cat_cols:\n    cat_analyzer(df, i, \"SalePrice\")","7979898c":"# Remove useless variables\nrm = [\"Street\", \"Utilities\", \"PoolQC\", \"MiscFeature\", \"Heating\", \"Condition2\"]\ndf.drop(rm, axis = 1, inplace = True)\nfor i in rm:\n    cat_cols.remove(i)\ncat_cols","05dd7067":"# Condition1\ndf[\"Condition1\"] = np.where(df.Condition1.isin([\"Artery\", \"Feedr\"]), \"Road\", df.Condition1)\ndf[\"Condition1\"] = np.where(df.Condition1.isin([\"RRAe\", \"RRAn\", \"RRNe\", \"RRNn\"]), \"RR\", df.Condition1)\ndf[\"Condition1\"] = np.where(df.Condition1.isin([\"PosA\", \"PosN\"]), \"Pos\", df.Condition1)","92d42ae1":"# Rare Encoder\nfor i in [\"MSSubClass\", \"Foundation\", \"HouseStyle\", \"RoofMatl\", \"RoofStyle\", \"SaleCondition\", \"SaleType\"]:\n    df[i] = rare_encoder(df[[i]], rare_perc=0.01)\n\n# Cat Analyzer\nfor i in cat_cols:\n    cat_analyzer(df, i, \"SalePrice\")","07c014ce":"# One Hot Encoder\ndf = one_hot_encoder(df, cat_cols, drop_first=True)","598642f7":"# Shape\ndf.shape","b1f60ca5":"# Shape\ndf.shape\n\n# Correlation\nc = df.corr(\"spearman\").SalePrice.sort_values(ascending = False)[1:]\nc.head()","4a50f165":"\nc.tail()","4e6e2ba4":"df.head()","fdb652e7":"train_model = df[df.Id.isin(train.Id)]\ntest_model = df[df.Id.isin(test.Id)]\ntest_model.drop(\"SalePrice\", axis = 1, inplace = True)\n\n\nX = train_model.drop(['SalePrice', \"Id\"], axis=1)\ny = train_model[[\"SalePrice\"]]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=46)\n\n\n\n######### MODEL: LGBM\nlgb_param = {\n    # Configuration\n    \"nthread\": -1,\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"verbose\": -1,\n}\n\nreg = lgb.LGBMRegressor(\n    random_state=46, **lgb_param\n)\n\nreg.fit(X_train,y_train, \n        eval_set=[(X_train, y_train),(X_test, y_test)],\n        eval_metric = [\"rmse\", \"mae\"],\n        eval_names=[\"Train\", \"Valid\"],\n        early_stopping_rounds=10,\n        verbose=10,\n        categorical_feature='auto')\n\nprint(\"\")\nprint(\"# MODEL RESULTS \\n Train RMSE: {:,.2f} \\n Valid RMSE: {:,.2f} \\n\\n Train MAE: {:,.2f} \\n Valid MAE: {:,.2f} \\n\\n Train RMSLE: {:,.5f} \\n Valid RMSLE: {:,.5f} \\n\\n Train R2: {:,.2f} \\n Valid R2: {:,.2f}\".format(\n  mean_squared_error(y_train, reg.predict(X_train), squared=False),\n  mean_squared_error(y_test, reg.predict(X_test), squared=False),\n  mean_absolute_error(y_train, reg.predict(X_train)),\n  mean_absolute_error(y_test, reg.predict(X_test)),\n  np.sqrt(mean_squared_log_error(y_train, reg.predict(X_train))),\n  np.sqrt(mean_squared_log_error(y_test, reg.predict(X_test))),\n  r2_score(y_train, reg.predict(X_train)),\n  r2_score(y_test, reg.predict(X_test))\n  ))","b1713608":"train.SalePrice.mean(), train.SalePrice.std()","6ec84c1a":"########################################\n# 15. ERROR ANALYSIS\n########################################\n\nres = pd.DataFrame({\"Actual\":y_test.SalePrice, \"Pred\":reg.predict(X_test)})\nres[\"Error\"] = res.Actual - res.Pred\nres[\"AbsoluteError\"] = np.abs(res.Error)\nres.sort_values(\"AbsoluteError\", ascending = False, inplace = True)\nres.head(10)","760f6fe3":"res.describe([0.01, 0.05, 0.10, 0.20, 0.40, 0.70, 0.80, 0.90, 0.95, 0.99]).T","2e47431f":"fig, axes = plt.subplots(4, 2, figsize = (20,20))\nfor axi in axes.flat:\n    axi.ticklabel_format(style=\"sci\", axis=\"y\", scilimits=(0,10))\n    axi.ticklabel_format(style=\"sci\", axis=\"x\", scilimits=(0,10))\n    axi.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n    axi.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n    \nres.hist(\"Error\", ax = axes[0, 0], color = \"steelblue\", bins = 20)\nres.hist(\"AbsoluteError\", ax = axes[0,1], color = \"steelblue\", bins = 20)\nsr = res.copy()\nsr[\"StandardizedR\"] = (sr.Error \/ sr.Error.std())\nsr[\"StandardizedR2\"] = ((sr.Error \/ sr.Error.std())**2)\nsr.plot.scatter(x = \"Pred\",y = \"StandardizedR\", color = \"red\", ax = axes[1,0])\nsr.plot.scatter(x = \"Pred\",y = \"StandardizedR2\", color = \"red\", ax = axes[1,1])\nres.Actual.hist(ax = axes[2, 0], color = \"purple\", bins = 20)\nres.Pred.hist(ax = axes[2, 1], color = \"purple\", bins = 20)\nres.plot.scatter(x = \"Actual\",y = \"Pred\", color = \"seagreen\", ax = axes[3,0]);\n# QQ Plot\nimport statsmodels.api as sm\nimport pylab\nsm.qqplot(sr.Pred, ax = axes[3,1], c = \"seagreen\")\nplt.suptitle(\"ERROR ANALYSIS\", fontsize = 20)\naxes[0,0].set_title(\"Error Histogram\", fontsize = 15)\naxes[0,1].set_title(\"Absolute Error Histogram\", fontsize = 15)\naxes[1,0].set_title(\"Standardized Residuals & Fitted Values\", fontsize = 15)\naxes[1,1].set_title(\"Standardized Residuals^2 & Fitted Values\", fontsize = 15)\naxes[2,0].set_title(\"Actual Histogram\", fontsize = 15)\naxes[2,1].set_title(\"Pred Histogram\", fontsize = 15);\naxes[3,0].set_title(\"Actual Pred Relationship\", fontsize = 15);\naxes[3,1].set_title(\"QQ Plot\", fontsize = 15);\naxes[1,0].set_xlabel(\"Fitted Values (Pred)\", fontsize = 12)\naxes[1,1].set_xlabel(\"Fitted Values (Pred)\", fontsize = 12)\naxes[3,0].set_xlabel(\"Actual\", fontsize = 12)\naxes[1,0].set_ylabel(\"Standardized Residuals\", fontsize = 12)\naxes[1,1].set_ylabel(\"Standardized Residuals^2\", fontsize = 12)\naxes[3,0].set_ylabel(\"Pred\", fontsize = 12)\nfig.tight_layout(pad=3.0)\nplt.savefig(\"errors.png\")\nplt.show()","7bfd3ff1":"params = {\n    # Training \n    'learning_rate': [0.1, 0.09, 0.08, 0.07, 0.05],\n    # Tree\n    'max_depth': [-1] + np.arange(5, 33, 1),\n    # Deal with Over-fitting\n    'num_leaves':np.arange(20, 81, 1),\n    'n_estimators':[100, 500, 1000, 3000, 4000, 5000, 10000, 15000], \n    'max_bin':np.arange(240, 301, 5), # Default 255\n    'min_data_in_leaf':np.arange(15, 31, 1), # Default 20\n    #\"feature_fraction_seed\":np.arange(2, 100, 1),\n    #\"feature_fraction\":np.arange(0.1, 1.01, 0.01),#[0.4, 0.5, 0.6, 0.7, 0.8, 0.8, 1], #0.41,# Default: 1 \n    #\"bagging_freq\":[0], # Default: 0 | Note: to enable bagging, bagging_freq should be set to a non zero value as well\n    #\"bagging_fraction\":[1], # Default: 1 \n    #\"min_sum_hessian_in_leaf\":[1e-2,1e-3, 1e-4, 1e-5, 1e-6], # Default: 1e-3 \n    # Regularization\n    # - Try lambda_l1, lambda_l2 and min_gain_to_split for regularization\n    # \"lambda_l1\":np.arange(0.0, 1.1, 0.1),\n    \"lambda_l2\":np.arange(0.0, 1.1, 0.1),\n    \"min_gain_to_split \": np.arange(0, 11, 1)  # Default: 0\n}\n\n\nreg = lgb.LGBMRegressor(\n    random_state=46, objective = \"rmse\", metric = \"rmse\"\n)\n\nfrom sklearn.model_selection import RandomizedSearchCV\nrs = RandomizedSearchCV(reg, params, random_state=46, cv = 5, scoring = \"neg_mean_squared_error\")\nrs_lgbm = rs.fit(X_train, y_train,\n                 eval_set=[(X_train, y_train),(X_test, y_test)],\n                 eval_metric = [\"rmse\", \"mae\"],\n                 eval_names=[\"Train\", \"Valid\"],\n                 early_stopping_rounds=30,\n                 verbose=0,\n                 categorical_feature='auto')\n\nprint(rs_lgbm.best_params_)","21a6db90":"print(\"# MODEL RESULTS \\n Train RMSE: {:,.2f} \\n Valid RMSE: {:,.2f} \\n\\n Train MAE: {:,.2f} \\n Valid MAE: {:,.2f} \\n\\n Train RMSLE: {:,.5f} \\n Valid RMSLE: {:,.5f} \\n\\n Train R2: {:,.2f} \\n Valid R2: {:,.2f}\".format(\n  mean_squared_error(y_train, rs_lgbm.predict(X_train), squared=False),\n  mean_squared_error(y_test, rs_lgbm.predict(X_test), squared=False),\n  mean_absolute_error(y_train, rs_lgbm.predict(X_train)),\n  mean_absolute_error(y_test, rs_lgbm.predict(X_test)),\n  np.sqrt(mean_squared_log_error(y_train, rs_lgbm.predict(X_train))),\n  np.sqrt(mean_squared_log_error(y_test, rs_lgbm.predict(X_test))),\n  r2_score(y_train, rs_lgbm.predict(X_train)),\n  r2_score(y_test, rs_lgbm.predict(X_test))\n  ))","3079a3eb":"train_model = df[df.Id.isin(train.Id)].drop(df.select_dtypes(object).columns, axis = 1)\ntest_model = df[df.Id.isin(test.Id)].drop(df.select_dtypes(object).columns, axis = 1)\ntest_model.drop(\"SalePrice\", axis = 1, inplace = True)\n\n\nX = train_model.drop(['SalePrice', \"Id\"], axis=1)\ny = train_model[[\"SalePrice\"]]\n\n\nfinal = lgb.LGBMRegressor(\n    random_state=46,\n    **rs_lgbm.best_params_\n)\n\nfinal.fit(X,y, \n        eval_set=[(X,y)],\n        eval_metric = [\"rmse\", \"mae\"],\n        eval_names=[\"Train\"],\n        # early_stopping_rounds=10,\n        verbose=1000,\n        categorical_feature='auto')\n        \n        \n        \nprint(\"# MODEL RESULTS \\n Train RMSE: {:,.2f}  \\n\\n Train MAE: {:,.2f}  \\n\\n Train RMSLE: {:,.5f} \\n\\n Train R2: {:,.2f}\".format(\n  mean_squared_error(y, final.predict(X), squared=False),\n  mean_absolute_error(y, final.predict(X)),\n  np.sqrt(mean_squared_log_error(y, final.predict(X))),\n  r2_score(y, final.predict(X))\n  ))\n\n\n# Submission\nsubmission = pd.DataFrame({\"Id\": test_model.Id, \"SalePrice\":final.predict(test_model.drop(\"Id\", axis = 1))})\nsubmission.to_csv(\"submission.csv\", index = None)\n","6c0aab50":"<a id='missing'><\/a>\n<h1 style=\"color:firebrick\" >4. MISSING VALUE<\/h1>","909b07ca":"<a id='lgbm'><\/a>\n<h1 style=\"color:firebrick\" >13. LIGHT GBM<\/h1>","8ba9b68c":"<a id='finaldata'><\/a>\n<h1 style=\"color:firebrick\" >12. FINAL DATA<\/h1>","e91bb777":"<a id='categoric'><\/a>\n<h1 style=\"color:firebrick\" >11. CATEGORIC VARIABLES<\/h1>","73aa4fae":"<a id='datatypes'><\/a>\n<h1 style=\"color:firebrick\" >5. DATA TYPES<\/h1>","9ea76734":"<a id='numbutcat'><\/a>\n<h1 style=\"color:firebrick\" >9. NUMERICAL BUT CATEGORICAL<\/h1>","9fb8b0aa":"<a id='ordinal'><\/a>\n<h1 style=\"color:firebrick\" >6. ORDINAL VARIABLES<\/h1>","e80cbf94":"<a id='libraries'><\/a>\n<h1 style=\"color:firebrick\" >1. PACKAGES<\/h1>","fd6dbabb":"<a id='functions'><\/a>\n<h1 style=\"color:firebrick\" >2. FUNCTIONS<\/h1>","1443edd5":"<a id='catbutcar'><\/a>\n<h1 style=\"color:firebrick\" >7. CATEGORICAL BUT CARDINALITY HIGH<\/h1>","69e5bdbd":"<a id='load'><\/a>\n<h1 style=\"color:firebrick\" >3. DATA<\/h1>","68448d96":"<a id='final'><\/a>\n<h1 style=\"color:firebrick\" >16. FINAL MODEL & SUBMISSION<\/h1>","6ba2709b":"<a id='rs'><\/a>\n<h1 style=\"color:firebrick\" >15. RANDOMIZED SEARCH CV<\/h1>","967d8a96":"<a id='numeric'><\/a>\n<h1 style=\"color:firebrick\" >10. NUMERIC VARIABLES<\/h1>","01f0caf4":"<a id='error'><\/a>\n<h1 style=\"color:firebrick\" >14. ERROR ANALYSIS<\/h1>","78902b2d":"# Fill NA\nfor i in cat_missing:\n    df[i] = np.where(df[i].isnull() == True, \"None\", df[i])","4d8f67a2":"<a id='time'><\/a>\n<h1 style=\"color:firebrick\" >8. TIME RELATED FEATURES<\/h1>","4cd72b6e":"<center> <h1 style=\"background-color:firebrick; color:white\" >House Price<\/h1> \n\n<center><img\nsrc=\"https:\/\/smallcaps.com.au\/wp-content\/uploads\/2020\/07\/Property-market-fall-Australia-COVID-19-2020.jpg\" style=\"width:90%;height:40%;\">\n<\/center>\n    \n<br>    \n    \n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" style=\"background-color:firebrick; color:white\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content!<\/h3>  \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#libraries\" role=\"tab\" aria-controls=\"profile\" style=\"color:firebrick\">Import Libraries<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">1<\/span><\/a>\n  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#functions\" role=\"tab\" aria-controls=\"messages\" style=\"color:firebrick\">Functions<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">2<\/span><\/a>\n <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#load\" role=\"tab\" aria-controls=\"messages\" style=\"color:firebrick\">Load Data<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">3<\/span><\/a>\n <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#missing\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Missing Value<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">4<\/span><\/a>\n <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#datatypes\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Data Types<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">5<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#ordinal\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Ordinal Variables<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">6<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#catbutcar\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Categorical But Cardinality High<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">7<\/span><\/a> \n <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#time\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Time Related Features<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">8<\/span><\/a> <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#numbutcat\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Numerical But Categorical<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">9<\/span><\/a>    \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#numeric\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Numeric Variables<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">10<\/span><\/a> \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#categoric\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Categoric Variables<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">11<\/span><\/a> \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#finaldata\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Final Data<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">12<\/span><\/a> \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#lgbm\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Light GBM<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">13<\/span><\/a> \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#error\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Error Analysis<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">14<\/span><\/a>     \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#rs\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Randomized Search CV<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">15<\/span><\/a> \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#final\" role=\"tab\" aria-controls=\"settings\" style=\"color:firebrick\">Final Model & Submission<span class=\"badge badge-primary badge-pill\" style=\"background-color:orangered; color:white\">16<\/span><\/a> "}}