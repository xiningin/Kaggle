{"cell_type":{"55ded128":"code","3ae4317b":"code","28367adc":"code","10373804":"code","97f14fbd":"code","573428a0":"code","90dcbd94":"code","dd636a11":"code","64fbad92":"code","66bb7bf0":"code","d402943e":"code","2a4064be":"code","05494a9c":"code","9cfe4ce9":"code","49a14fb1":"code","96a02e44":"code","b89e0308":"code","9fdba60e":"code","e4161b44":"code","bda23469":"code","22e79ee4":"code","44649347":"code","34b6968f":"code","2cf2bd45":"code","9e4c208b":"code","47e9dbc8":"code","4b9fc567":"code","ef0e4eb5":"code","32eee195":"code","e64cb910":"code","c1c5a2b6":"code","23fe494a":"code","c44338a9":"code","dced770d":"code","26937025":"code","6d902ccf":"code","2ce88c3c":"code","119af9bd":"code","96d527e4":"code","ea99e89f":"code","71b86630":"code","2fe6c89a":"code","f792f45b":"code","f27ae817":"code","799331c1":"code","f22e9323":"markdown","a338aec3":"markdown","0b143d9d":"markdown","8001fc8f":"markdown","322827e9":"markdown"},"source":{"55ded128":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3ae4317b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,accuracy_score","28367adc":"### Reading the Train Data\ntrain_X1 = pd.read_csv(\"..\/input\/Train-1564659747836.csv\", na_values=['',' ','-','NaN'])\ntrain_X2 = pd.read_csv(\"..\/input\/Train_Complaints-1564659763354.csv\", na_values=['',' ','-','NaN'])","10373804":"## Merging the train Data\ntrain_x = pd.merge(train_X1,train_X2, left_on='InsurerID', right_on='InsurerID',how = 'left')\ntrain_x.head()","97f14fbd":"#### Making the DRC Classes Into numeric\ndef cat(train_x):\n    if train_x['DRC'] == 'poor':\n        return 1\n    elif train_x['DRC'] == 'average':\n        return 2\n    elif train_x['DRC'] == 'outstanding':\n        return 3\n        \ntrain_x['DRC'] = train_x.apply(lambda x : cat(x), axis=1)","573428a0":"categorical_Columns = train_x.select_dtypes(include= \"object\").copy()\n### Box_Plot of Categorical Coloumn in Reasons\nsns.set(font_scale=0.9)\nplt.figure(figsize=(16,5)) \nsns.countplot(data = categorical_Columns, x = 'Reason')","90dcbd94":"### Bar_Plot of Categorical Coloumn in Sub-Reasons\nsns.set(font_scale=1.5)\nplt.figure(figsize=(20,30))\nsns.countplot(data = categorical_Columns, y = 'SubReason')","dd636a11":"## Bar_Plot of Categorical Coloumn in Enforcement-Action \n\nsns.set(font_scale=1)\nplt.figure(figsize=(12,12))\nsns.countplot(data = categorical_Columns, y = 'EnforcementAction')\n","64fbad92":"#### Bar_Plot for Categorical Coloumn in Conclusion\nsns.set(font_scale=1.0)\nplt.figure(figsize=(12,5)) \nsns.countplot(data = categorical_Columns, x = 'Conclusion')\n","66bb7bf0":"#### Dropping the Columns \ntrain_x = train_x.drop(['Company', 'FileNo', 'ComplaintID', 'State'], axis=1)\ntrain_x.head()\n\n","d402943e":"#### Finding null values count\ntrain_x.isnull().sum(axis = 0)\n","2a4064be":"#### Converting  Date into Day Format\ntrain_x[\"DateOfRegistration\"] = pd.to_datetime(train_x[\"DateOfRegistration\"],format=\"%Y-%m-%d\", utc=True)\ntrain_x[\"DateOfResolution\"] = pd.to_datetime(train_x[\"DateOfResolution\"],format=\"%Y-%m-%d\", utc=True)\n\ntrain_x[\"Duration_Days\"] = train_x['DateOfResolution'] - train_x['DateOfRegistration']","05494a9c":"#####    Droping   DateOfRegistration ,DateOfResolution   columns\ntrain_x1 = train_x.drop(['DateOfRegistration', 'DateOfResolution'], axis =1)\ntrain_x1.head()","9cfe4ce9":"#### Filling NA Values\u00b6\ntrain_x1['Coverage'] = train_x1['Coverage'].fillna('No')\ntrain_x1['SubCoverage'] = train_x1['SubCoverage'].fillna('None')\ntrain_x1['Duration_Days'] = train_x1['Duration_Days'].fillna(2500)\ntrain_x1.isnull().sum()\n","49a14fb1":"#### Converting the DurationDays column into integer\u00b6\ntrain_x1[\"Duration_Days\"]=pd.to_timedelta(train_x1[\"Duration_Days\"]).dt.days.astype('int64')\n","96a02e44":"train_x1.dtypes\n","b89e0308":"### Converting DRC Column into Category\u00b6\ntrain_x1['DRC'] = train_x1['DRC'].astype('category')\n### Copying and Dropping the InsurerID Column and cheeking the Shape\ntrain_x2 = train_x1.InsurerID.copy()\ntrain_x2 = train_x1.drop(['InsurerID'], axis=1)\ntrain_x2.shape\n\n\n","9fdba60e":"### Changing the object type Columns into category with 'COLUMN'\u00b6\ncolumn =train_x2.dtypes[train_x2.dtypes == 'object'].index\ntrain_x2[column]=train_x2[column].astype('category')\ntrain_x2.dtypes","e4161b44":"cat_col = ['Coverage','SubCoverage', 'Reason', 'SubReason', 'EnforcementAction', 'Conclusion','ResolutionStatus']\n","bda23469":"#####   Dummification\ndummies_train = pd.get_dummies(train_x2,columns = cat_col ,drop_first=True)\ndummies_train.shape","22e79ee4":"### Copy and Drop DRC\nX = dummies_train.copy().drop(\"DRC\",axis=1)\ny = dummies_train[\"DRC\"]","44649347":"### Train_Test_Spilt\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","34b6968f":"print(y_test.shape)\ny_train = pd.DataFrame(y_train)\ny_test = pd.DataFrame(y_test)","2cf2bd45":"#### Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nDTclassifier =  DecisionTreeClassifier(criterion= 'entropy', max_depth= 5 )\nDTclassifier.fit(X_train,y_train)\n\ny_pred = DTclassifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))\n\nprint('Train Accuracy =',DTclassifier.score(X_train, y_train))\nprint('Test Accuracy =',DTclassifier.score(X_test, y_test))\n","9e4c208b":"from sklearn.metrics import f1_score,accuracy_score\ndt_f1_test = f1_score(y_pred, y_test, labels=None, average='weighted')\n\nprint('DecisionTreeClassifier F1_score on test: %.4f' %dt_f1_test)","47e9dbc8":"#### Random Forest Classifier\u00b6\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,accuracy_score\n\nRFC = RandomForestClassifier(n_estimators=120,max_depth=10,min_samples_split=5,random_state=52)\nRFC.fit(X_train, y_train)\npred_ytest_RF = RFC.predict(X_test)\n#pred_test_rfc = RFC.predict(test_merge)\n\nRF_f1_test = f1_score(pred_ytest_RF, y_test,labels=None, average='weighted')  \nRF_accuracy_test = accuracy_score(pred_ytest_RF, y_test)\n\nprint('Random Forest Classifier F1_score on test: %.4f' %RF_f1_test)\nprint('Random Forest Classifier Accuracy on test: %.4f' %RF_accuracy_test)","4b9fc567":"from sklearn.metrics import f1_score,accuracy_score\nRF_f1_test = f1_score(y_pred, y_test, labels=None, average='weighted')\n\nprint('Random Forest Classifier F1_score on test: %.4f' %dt_f1_test)","ef0e4eb5":"### Logistic regression \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlr_model = LogisticRegression()\nlr_model.fit(X_train,y_train)\npred_train = lr_model.predict(X_train)\npred_test = lr_model.predict(X_test)\nprint(\"Accuracy on train is:\",accuracy_score(y_train,pred_train))\nprint(\"Accuracy on test is:\",accuracy_score(y_test,pred_test))","32eee195":"\ntest_X1 = pd.read_csv(\"..\/input\/Test-1565162240834.csv\", na_values=['',' ','-','NaN'])\ntest_X2 = pd.read_csv(\"..\/input\/Test_Complaints-1565162197608.csv\", na_values=['',' ','-','NaN'])","e64cb910":"test_x = pd.merge(test_X1,test_X2, left_on='InsurerID', right_on='InsurerID',how = 'right')\ntest_x.head()","c1c5a2b6":"test_x1 = test_x.drop(['Company','FileNo','ComplaintID','State'], axis=1)\ntest_x1.head()","23fe494a":"test_x1.isnull().sum(axis = 0)","c44338a9":"test_x1[\"DateOfRegistration\"] = pd.to_datetime(test_x1[\"DateOfRegistration\"],format=\"%Y-%m-%d\", utc=True)\ntest_x1[\"DateOfResolution\"] =   pd.to_datetime(test_x1[\"DateOfResolution\"],format=\"%Y-%m-%d\", utc=True)\n\ntest_x1[\"Duration_Days\"] = test_x1['DateOfResolution'] - test_x1['DateOfRegistration']","dced770d":"test_x2 = test_x1.drop(['DateOfRegistration', 'DateOfResolution'], axis =1)\ntest_x2.head()","26937025":"test_x2['Coverage'] = test_x2['Coverage'].fillna('No')\ntest_x2['SubCoverage'] = test_x2['SubCoverage'].fillna('None')\ntest_x2['Duration_Days'] = test_x2['Duration_Days'].fillna(2500)\ntest_x2.isnull().sum()","6d902ccf":"test_x2[\"Duration_Days\"]=pd.to_timedelta(test_x2[\"Duration_Days\"]).dt.days.astype('int64')","2ce88c3c":"test_Insurers = test_x2.InsurerID.copy()\ntest_x3 = test_x2.drop(['InsurerID'], axis=1)\ntest_x3.head()","119af9bd":"column = test_x3.dtypes[test_x3.dtypes == 'object'].index\ntest_x3[column]=test_x3[column].astype('category')\ntest_x3.dtypes","96d527e4":"cat_col = ['Coverage','SubCoverage', 'Reason', 'SubReason', 'EnforcementAction', 'Conclusion','ResolutionStatus']","ea99e89f":"#Dummification\ndummies_test = pd.get_dummies(test_x3,columns = cat_col ,drop_first=True)\ndummies_test.shape","71b86630":"print(dummies_test.shape)\nX_train, dummies_test = X_train.align(dummies_test, join = 'left', axis = 1)\ndummies_test.fillna(0, inplace=True)\nprint(dummies_test.shape)\nprint(X_train.shape)","2fe6c89a":"predict_test = DTclassifier.predict(dummies_test)\n","f792f45b":"predict_test","f27ae817":"submission_dt = pd.DataFrame()\nsubmission_dt['InsurerID'] = test_Insurers\nsubmission_dt.shape","799331c1":"final_predictions_dt = predict_test\nsubmission_dt['DRC'] = final_predictions_dt\nsubmission_dt.to_csv('submission_dt.csv')","f22e9323":"### Tasks Of This Project :\n\n* To do Exploratory Data Analysis using visualizations\n* Analysing the complaints of a Resolution system of insurer can be rate on a scale\n* Forecasting the Insurer Claims through major models are a DecisionTree, a RandomForest, a      BinaryLogisticRegression","a338aec3":"\n## Predicting of Claim Classification of the Insurers through DRC","0b143d9d":"### Problem Statement\n\nA great number of different variables are under analysis in this case. The algorithms involve detection of relations between claims, implementation of high dimensionality to reach all the Complaints resolution system levels of InsurerID and detection of the missing observations to predict in the three given DRC Classes\n\n### Business Understanding\n\nFor Financial examination of the insurers Financial Stability and Market Conduct are the two pillars of regulation. The Insurance company capture the market conduct of the insurer complaints and thus handling has recently become integral part of the consumer affairs function of insurance regulatory body\n\nGenerally,In the Insurance domain Claims may occurs in between these two sub-groups\n\na. Consumer Complaints against Insurers fall into 3 categories\n\n* Underwriting \/Sales Related\n* Unfair claims Related\n* Service Related\n\nb. Insurers Could Fail due to\n\n* Improper handling of pricing\n* Underwriting\/Sales\n* Poor Quality & Experience of Governance\/management\n* Inefficient internal operational Processes and inappropriate risk appetite\n\nc. The improper handling of the Complaints Resolution System (CRS) reflects to\n\n* Low \/declining profitability\n* Failure to implement regulatory requirement\n* Non-cooperation \/delay in producing information \/lax Management attitude\n\n\nBy analysing, the complaints for a given period ,the complaints \"resolution system of insurer\"can be rate on a scale of (low\/medium\/high)- in increasing order of regulatory concern\n","8001fc8f":"#### On Test Data","322827e9":"#### Task 01\n\n* Visualization on train data\n* Uni-Variant And Bi-Variant Plots\n\n\n#### Task 02 \nPreprocessing On Train data and Test Data\n   * Merging with InsurerID\n   * DRC Classes Into numeric\n   * Dropping the Unwanted Columns\n   * Converting Date into Day Format\n   * Filling NA Values\n   * Converting the DurationDays column into integer\n   * Copying and Dropping the InsurerID Column and cheeking the Shape\n   * Changing the object type Columns into category with 'COLUMN'\n   * Dummification the Category Columns\n   \n   \n   \n #####  MODEL BUILDING\n* Decision Tree\n* Random Forest Classifier\n* Logistic Regression "}}