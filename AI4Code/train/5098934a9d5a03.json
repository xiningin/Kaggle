{"cell_type":{"b13d4edc":"code","beef91e7":"code","5d5e8e99":"code","5e0d0a04":"code","8e9c7e89":"code","8d0b038c":"code","3a3567a8":"code","0de6f3c7":"code","e0107b9b":"code","a5c8941b":"code","4d9f600e":"code","394fd712":"code","d91bbf95":"code","43544be9":"code","d062c743":"code","980141cf":"code","4a668749":"code","01aebb88":"code","212a5cd4":"code","9ce2badc":"code","06a5baa9":"code","e26b844f":"code","08963dc0":"code","18e7494d":"code","d0b73081":"code","7b24d49f":"code","75727f18":"code","73116654":"code","a5a57f9d":"code","b5744e2e":"code","2a4607a2":"code","0c771ea7":"code","bf3a8a48":"code","745811e5":"code","2d0a8152":"code","1d0d4d30":"code","3e6d4826":"code","b71fb42c":"code","f5057b9d":"code","b281ff4f":"code","04ce85b1":"code","a8d59284":"code","7868e9d6":"code","4c49de62":"code","180643d5":"code","3f9dbe2d":"code","4acf5110":"code","2451b20e":"code","b2bd9610":"code","68c1c3ed":"code","41fbbcde":"code","dde9200b":"code","ce7a3952":"code","21ed2813":"code","9e46af2f":"code","2cf5631d":"code","5185a7e4":"code","2d00729d":"code","12b9a8bd":"code","6b4c2f18":"code","01274190":"code","bb20e7f3":"code","af620bd8":"code","306fe72c":"code","d37d0bc8":"code","89f4ab03":"code","925bd427":"code","f8950fb8":"code","fcdcbb52":"code","9606b095":"code","ff585056":"code","acea5e33":"code","a4e6b1d0":"code","6fad7b09":"code","98a5cf54":"code","285f91a6":"code","abb749e4":"code","a5c8de36":"code","d2bb377a":"code","977825d6":"code","5758a081":"code","35d7c8db":"code","42cd9483":"code","a38f447a":"code","21c13aaf":"code","161eb473":"code","04e692e8":"code","3069f4f9":"code","49582edc":"code","bab94797":"code","7c745529":"code","0e795d5b":"code","8f2043b4":"code","a33a63f3":"code","0e9f472f":"code","089d83f5":"code","0c79716f":"code","608092e0":"code","ea583d55":"code","971250ad":"code","2a15248d":"code","19ce9db3":"code","cf05da43":"code","f0b2d215":"code","e38e2abb":"code","88b09980":"code","e54afae8":"code","32d70522":"code","713fa389":"code","b0fcc166":"code","22ccc44f":"code","272d266c":"code","9889b943":"code","a3a0de2f":"code","373fd17f":"code","ba8f8a6f":"code","2e937c23":"code","cd7b88b5":"code","10f23fb5":"code","5ddf8af5":"code","7868e38b":"code","90fead69":"code","f4c7cdba":"code","8a1a62b9":"code","8be79aaf":"code","e95a6895":"code","0a8237d3":"code","84046cdc":"code","adf8ca2e":"code","633a7751":"code","51bc4d29":"code","efcb3faf":"code","cb58185b":"code","448d94ee":"code","28765155":"code","12ba6758":"code","690167cc":"code","0fb701e2":"code","78452cd7":"code","f7f98129":"code","5b8ceed5":"code","469bf8bd":"code","b8b30e57":"code","32d822ce":"code","e9f1440a":"code","277e189c":"code","62a832f5":"code","6fcc0ec8":"code","421cea35":"code","86d93edf":"code","c1804937":"code","bb323b3a":"code","17c9d6b1":"code","a82bd8d4":"code","197e3340":"code","379e71d6":"code","4277a233":"code","1c88a4ad":"code","615586b4":"code","afec6f84":"code","835600e7":"code","91869ea3":"code","cd97f745":"code","32a42b81":"code","90efbc19":"code","f83ae366":"code","0ab24eee":"code","4f3504fa":"code","bbdd8588":"code","c016e59a":"code","2afee973":"code","ac9383c9":"code","72f79fb0":"code","8e1f013d":"code","5fb3dd6e":"markdown","824afbd2":"markdown","8b845be4":"markdown","7fa3dac0":"markdown","7298d805":"markdown","0df93058":"markdown","3464c455":"markdown","c6b61507":"markdown","891a8dcc":"markdown","11fc49c8":"markdown","2df35f15":"markdown","83227a71":"markdown","010b81ad":"markdown","2fc6f9dd":"markdown","520669d2":"markdown","9569f04f":"markdown","7338853e":"markdown","7a97a591":"markdown","16e90a9f":"markdown","df081980":"markdown","a29c7f6f":"markdown","a7db1c98":"markdown","d9070997":"markdown","7b92b953":"markdown","0f2d7415":"markdown"},"source":{"b13d4edc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport scipy.stats as stats\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics","beef91e7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/ramen-ratings\/ramen-ratings.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5d5e8e99":"data= pd.read_csv('\/kaggle\/input\/ramen-ratings\/ramen-ratings.csv') # Read Csv File","5e0d0a04":"data.head(4)","8e9c7e89":"from sklearn import preprocessing","8d0b038c":"data.columns","3a3567a8":"df = data.drop('Top Ten',axis=1) # Dropping Top Ten as the columns has many missing values","0de6f3c7":"df.head()","e0107b9b":"df.describe(include='all')","a5c8941b":"df['Variety'].value_counts()","4d9f600e":"df.isnull().sum() # To find if there are any null values","394fd712":"#df['Style']=df['Style'].fillna('Pack')","d91bbf95":"df.isnull().sum() ","43544be9":"df['Variety'].value_counts().head(10).plot(kind='bar') #Top 10 variety","d062c743":"df['Country'].value_counts().plot(kind='bar') #Distribution of Countries","980141cf":"df['Country'].value_counts().head(5).plot(kind='bar') #Top Five countries selling Ramen","4a668749":"df['Country'].value_counts().tail(5).plot(kind='bar') # Least Popular countries","01aebb88":"df[df['Style'].isnull()] #Missing values in the column Style","212a5cd4":"df_kamfen=df[df['Brand']=='Kamfen']  # Filling the Style value according to the brand Kamfen on how it sells in China\nDf_kam_ch=df_kamfen[df_kamfen['Country']=='China']\nDf_kam_ch['Style'].value_counts()","9ce2badc":"df_unif=df[df['Brand']=='Unif'] # Filling the Style value according to the brand Unif on how it sells in Taiwan\ndf_unif_ta=df_unif[df_unif['Country']=='Taiwan']\ndf_unif_ta['Style'].value_counts()","06a5baa9":"df.loc[2152,'Style'] = 'Pack'  # Replacing the values","e26b844f":"df.loc[2442,'Style'] = 'Bowl'  # Replacing the values","08963dc0":"df.isnull().sum()","18e7494d":"df['Stars'].value_counts()","d0b73081":"df[df['Stars']=='Unrated'] # 3 values of stars were unrated","7b24d49f":"df.loc[32,'Stars'] = 0 #Assuming the ramen was not rated because it wasnt liked, we assign rating as 0\ndf.loc[122,'Stars'] = 0\ndf.loc[993,'Stars'] = 0","75727f18":"df['Stars']=pd.to_numeric(df['Stars']) #Converting Value of stars to numeric","73116654":"sns.distplot(df['Stars'], bins=15) #Distribution plot for Stars","a5a57f9d":"df.head()","b5744e2e":"country_rate = df.groupby('Country', as_index=False)['Stars'].median() # grouping countries by their median star rating","2a4607a2":"country_rate.sort_values(['Stars'], ascending=False).head(10) # Top 10 countries according to star rating","0c771ea7":"country_rate.sort_values(['Stars'], ascending=False).tail(10)  # Last 10 countries according to star rating","bf3a8a48":"df['Stars'].describe()","745811e5":"sns.boxplot(df['Style'],df['Stars']) # boxplot to show the spread","2d0a8152":"df_high=df[df['Stars']>4.5]","1d0d4d30":"pd.crosstab(df_high['Stars'],df_high['Style']).plot(kind='bar') # distribution of packages having more than 4.75 ","3e6d4826":"pd.crosstab(df_high['Country'],df_high['Stars']).plot(kind='bar') #distribution of countries having more than 4.75 stars","b71fb42c":"features=['Stars','Review #']    # subplots for Stars and Review\nfig=plt.subplots(figsize=(15,15))\nfor i, j in enumerate(features):\n    plt.subplot(8, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sns.boxplot(x=j,data = df)\n    plt.xticks(rotation=90)\n    #plt.title(\"Telecom\")\n    \nplt.show()","f5057b9d":"df.columns","b281ff4f":"features=['Style', 'Country'] # Subplot for count plot\nfig=plt.subplots(figsize=(25,20))\nfor i, j in enumerate(features):\n    plt.subplot(4, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sns.countplot(x=j,data = df)\n    plt.xticks(rotation=90)\n    plt.title(\"Ramen\")\n    \nplt.show()","04ce85b1":"sns.boxplot(x = df.Style, y = df.Stars)","a8d59284":"df_cup=df[(df['Style']=='Cup') & (df['Stars']<1.5)]\ndf_cup\n","7868e9d6":"df_pack=df[(df['Style']=='Pack') & (df['Stars']<1.75)]\ndf_pack['Brand'].value_counts().head()\n","4c49de62":"df_knorr=df[(df['Brand']=='Knorr')]\ndf_knorr","180643d5":"df_box=df[(df['Style']=='Box') & (df['Stars']>4)]\ndf_box['Brand'].value_counts().head()\n","3f9dbe2d":"df_bowl=df[(df['Style']=='Bowl') & (df['Stars']<3.25)]\ndf_bowl['Brand'].value_counts().head()","4acf5110":"df_tray=df[(df['Style']=='Tray') & (df['Stars']<1.5)]\ndf_tray['Brand'].value_counts().head()\n","2451b20e":"df_canbar=df[(df['Style']=='Can') | (df['Style']=='Bar')]\ndf_canbar\n","b2bd9610":"df['Style'].value_counts()","68c1c3ed":"from sklearn import preprocessing","41fbbcde":"#data=df.drop('Variety',axis=1)","dde9200b":"df.head()","ce7a3952":"data = df.apply(preprocessing.LabelEncoder().fit_transform)","21ed2813":"data.head()","9e46af2f":"data['Style'].value_counts()","2cf5631d":"data['Category'] = [0 if x == 5 else 1 for x in data['Style']] \n  \n# Print the DataFrame \nprint(data.head()) ","5185a7e4":"df=data.drop('Style',axis= 1)","2d00729d":"\nfrom sklearn.model_selection import train_test_split\n\n","12b9a8bd":"X=df.drop('Category',axis=1) # spliting dataframe as X and y for test train model\ny=df['Category']","6b4c2f18":"dfx=X\ndfy=y","01274190":"from sklearn.model_selection import train_test_split # spliting as 70 \/ 30\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=425)","bb20e7f3":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train,y_train)","af620bd8":"y_pred = classifier.predict(X_test)","306fe72c":"cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)","d37d0bc8":"accuracy_score(y_test,y_pred)","89f4ab03":"print(classification_report(y_test,y_pred))","925bd427":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test= sc.fit_transform(X_test)","f8950fb8":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'gini',random_state = 0)\nclassifier.fit(X_train,y_train)","fcdcbb52":"y_pred = classifier.predict(X_test)","9606b095":"cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)","ff585056":"print(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","acea5e33":"y_pred_proba = classifier.predict_proba(X_test)[::,1]\nfpr,tpr,_ = metrics.roc_curve(y_test,y_pred_proba)\nauc = metrics.roc_auc_score(y_test,y_pred_proba)\nplt.plot(fpr,tpr,label='data 1,auc='+str(auc))\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"DT- ROC\")\nplt.legend(loc= 4)\nplt.show()\n","a4e6b1d0":"feature_cols=['Review #', 'Brand', 'Country','Stars']","6fad7b09":"clf = DecisionTreeClassifier(class_weight=None,criterion = 'gini',max_depth=10,max_features=None, max_leaf_nodes= 5, min_samples_leaf=3,\n                             min_samples_split=2,min_weight_fraction_leaf=0.0,presort=False , random_state = 0)\nclf.fit(X_train,y_train)","98a5cf54":"y_pred = clf.predict(X_test)","285f91a6":"cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)","abb749e4":"print(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","a5c8de36":"from sklearn.ensemble import RandomForestClassifier\n\nrclf = RandomForestClassifier(n_estimators= 100)","d2bb377a":"rclf.fit(X_train,y_train)","977825d6":"y_pred = rclf.predict(X_test)","5758a081":"cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","35d7c8db":"y_pred_proba = rclf.predict_proba(X_test)[::,1]\nfpr,tpr,_ = metrics.roc_curve(y_test,y_pred_proba)\nauc = metrics.roc_auc_score(y_test,y_pred_proba)\nplt.plot(fpr,tpr,label='data 1,auc='+str(auc))\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"DT- ROC\")\nplt.legend(loc= 4)\nplt.show()","42cd9483":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors= 5)\nclassifier.fit(X_train,y_train)\n","a38f447a":"y_pred = classifier.predict(X_test)","21c13aaf":"cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)","161eb473":"print(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","04e692e8":"from sklearn.model_selection import cross_val_score\n\nk_range = range(1,31)\nk_scores =[]\n#loop through reasonable values of k\nfor k in k_range:\n    #run knn\n    knn = KNeighborsClassifier(n_neighbors= k)\n    # obtin cross_val_Score\n    scores = cross_val_score(knn,X,y,cv= 10,scoring='accuracy')\n    #append mean scores\n    k_scores.append(scores.mean())\nprint(k_scores)\n\n","3069f4f9":"k=pd.DataFrame(k_scores,columns= ['dist'])\n#print(k)\nk[k['dist']== k['dist'].max()]","49582edc":"plt.plot(k_range,k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross validated Accuracy')","bab94797":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors= 19)\nclassifier.fit(X_train,y_train)\n","7c745529":"# from sklearn.neighbors import KNeighborsClassifier\n# classifier = KNeighborsClassifier(n_neighbors= 19)\n# classifier.fit(X_train,y_train)\n\ny_pred = classifier.predict(X_test)\n# cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n# print('Confusion Matrix \\n',cm)\n# print(accuracy_score(y_test,y_pred))\n# print(metrics.precision_score(y_test,y_pred,average='macro'))\n# print(metrics.recall_score(y_test,y_pred,average='macro'))","0e795d5b":"cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)","8f2043b4":"print(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","a33a63f3":"k_range= list(range(1,31))\nweight_options=[\"uniform\",\"distance\"]","0e9f472f":"param_grid = dict(n_neighbors = k_range, weights = weight_options)\nknn= KNeighborsClassifier()","089d83f5":"from sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(knn,param_grid=param_grid,cv=10,scoring='accuracy')\ngrid.fit(X,y)","0c79716f":"#grid = GridSearchCV(knn,param_grid=param_grid,cv=10,scoring='accuracy')\n#grid.fit(X,y)\nprint(grid.best_score_)\nprint(grid.best_estimator_)\nprint(grid.best_params_)","608092e0":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors= 12)\nclassifier.fit(X_train,y_train)\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","ea583d55":"from sklearn.naive_bayes import GaussianNB","971250ad":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(X_train,y_train)","2a15248d":"model.fit(X_train,y_train)","19ce9db3":"predicted = model.predict(X_test)\nprint('Predicted Value',predicted)","cf05da43":"cm = confusion_matrix(y_true=y_test,y_pred=predicted)\nprint('Confusion Matrix \\n',cm)","f0b2d215":"print(accuracy_score(y_test,predicted))\nprint(metrics.precision_score(y_test,predicted,average='macro'))\nprint(metrics.recall_score(y_test,predicted,average='macro'))","e38e2abb":"# Bagged Decision Trees for Classification - necessary dependencies\n\nfrom sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier","88b09980":"seed=7\nkfold = model_selection.KFold(n_splits=10, random_state=21)\ncart = DecisionTreeClassifier()\nnum_trees = 100\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nprint(results.mean())","e54afae8":" # fit a ensemble.BaggingClassifier() model to the data\nmodel = BaggingClassifier()\nmodel.fit(X_train, y_train)\nprint(); print(model)","32d70522":"# make predictions\nexpected_y  = y_test\npredicted_y = model.predict(X_test)","713fa389":"from sklearn import metrics\nprint(); print('ensemble.BaggingClassifier(): ')\nprint();print(\"Accuracy:\",metrics.accuracy_score(expected_y, predicted_y))\nprint(); print(metrics.classification_report(expected_y, predicted_y))","b0fcc166":"# fit a ensemble.ExtraTreesClassifier() model to the data\nfrom sklearn.ensemble import ExtraTreesClassifier \nmodel = ExtraTreesClassifier()\nmodel.fit(X_train, y_train)\nprint(); print(model)\n    \n# make predictions\nexpected_y  = y_test\npredicted_y = model.predict(X_test)","22ccc44f":"# summarize the fit of the model\nprint(); print('ensemble.ExtraTreesClassifier(): ')\nprint();print(\"Accuracy:\",metrics.accuracy_score(expected_y, predicted_y))\nprint(); print(metrics.classification_report(expected_y, predicted_y))\nprint(); print(metrics.confusion_matrix(expected_y, predicted_y))","272d266c":"# Boosting Methods","9889b943":"#import the libraries\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report","a3a0de2f":"classifier = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=1),\n    n_estimators=200\n)\nclassifier.fit(X_train, y_train)","373fd17f":"predictions = classifier.predict(X_test)\nconfusion_matrix(y_test, predictions)\n# Model Accuracy, how well the model performs\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))","ba8f8a6f":"confusion_matrix(y_test, predictions)","2e937c23":"from sklearn.ensemble import GradientBoostingClassifier","cd7b88b5":"lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n\nfor learning_rate in lr_list:\n    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n    gb_clf.fit(X_train, y_train)\n    \n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))","10f23fb5":"gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.75, max_features=2, max_depth=2, random_state=0)\ngb_clf2.fit(X_train, y_train)\npredictions = gb_clf2.predict(X_test)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\n\nprint();print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n\nprint();print(\"Classification Report\")\nprint();print(classification_report(y_test, predictions))","5ddf8af5":"#!pip install xgboost\nfrom xgboost import XGBClassifier\n\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)","7868e38b":"y_pred = classifier.predict(X_test)\ny_pred","90fead69":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_pred, y_test)\ncm","f4c7cdba":"# Model Accuracy, how well the model performs\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","8a1a62b9":"import pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom vecstack import stacking\n\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlxtend.classifier import StackingClassifier\nfrom xgboost.sklearn import XGBClassifier\nimport numpy as np\nimport warnings\n\nwarnings.simplefilter('ignore')","8be79aaf":"models = [\n    KNeighborsClassifier(n_neighbors=5,\n                        n_jobs=-1),\n\n    RandomForestClassifier(random_state=0, n_jobs=-1,\n                           n_estimators=100, max_depth=3),\n\n    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1,\n                  n_estimators=100, max_depth=3)\n]","e95a6895":"S_train, S_test = stacking(models,\n                           X_train, y_train, X_test,\n                           regression=False,\n\n                           mode='oof_pred_bag',\n\n                           needs_proba=False,\n\n                           save_dir=None,\n\n                           metric=accuracy_score,\n\n                           n_folds=4,\n\n                           stratified=True,\n\n                           shuffle=True,\n\n                           random_state=0,\n\n                           verbose=2)","0a8237d3":"X.head()","84046cdc":"X.columns","adf8ca2e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf = sc.fit_transform(X)","633a7751":"X=pd.DataFrame(df,columns=['Review #', 'Brand', 'Variety','Country', 'Stars'])","51bc4d29":"cluster_range = range(1,15)\ncluster_errors=[]","efcb3faf":"from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt","cb58185b":"for num_clusters in cluster_range:\n    clusterrs = KMeans(num_clusters)\n    clusterrs.fit(X)\n    cluster_errors.append(clusterrs.inertia_)","448d94ee":"culters_df = pd.DataFrame({\"num_clusters\":cluster_range,\"cluster_errors\":cluster_errors})\nculters_df[0:10]","28765155":"plt.figure(figsize=(12,6))\nplt.plot(culters_df.num_clusters,culters_df.cluster_errors,marker = 'o')","12ba6758":"kmeans = KMeans(n_clusters=4, n_init = 10, random_state=251)","690167cc":"kmeans.fit(X)","0fb701e2":"centroids = kmeans.cluster_centers_","78452cd7":"centroid_df = pd.DataFrame(centroids, columns = list(X) )","f7f98129":"centroid_df = pd.DataFrame(centroids, columns = list(X) )\ndf_labels = pd.DataFrame(kmeans.labels_ , columns = list(['labels']))\n\ndf_labels['labels'] = df_labels['labels'].astype('category')","5b8ceed5":"# df_labels = pd.DataFrame(kmeans.labels_ , columns = list(['labels']))\n\n# df_labels['labels'] = df_labels['labels'].astype('category')\nsnail_df_labeled = X.join(df_labels)\n# df_analysis = (snail_df_labeled.groupby(['labels'] , axis=0)).head(4177) \n# df_analysis.head(3)","469bf8bd":"df_analysis = (snail_df_labeled.groupby(['labels'] , axis=0)).head(4177) \ndf_analysis.head(3)","b8b30e57":"y_test = y\ny_pred= df_analysis['labels']\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","32d822ce":"from sklearn.model_selection import train_test_split  \n\nX= df_analysis.drop('labels',axis =1)\ny= df_analysis['labels']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","e9f1440a":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train,y_train)","277e189c":"# predict Model\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\naccuracy_score(y_test,y_pred)","62a832f5":"# DTfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'gini',random_state = 0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","6fcc0ec8":"X.columns","421cea35":"feature_cols=['Review #', 'Brand', 'Country', 'Stars']","86d93edf":"clf = DecisionTreeClassifier(class_weight=None,criterion = 'gini',max_depth=10,max_features=None, max_leaf_nodes= 5, min_samples_leaf=3,\n                             min_samples_split=2,min_weight_fraction_leaf=0.0,presort=False , random_state = 0)\nclf.fit(X_train,y_train)","c1804937":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'gini',random_state = 0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","bb323b3a":"rclf = RandomForestClassifier(n_estimators= 100)\nrclf.fit(X_train,y_train)\ny_pred = rclf.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","17c9d6b1":"classifier = KNeighborsClassifier(n_neighbors= 5)\nclassifier.fit(X_train,y_train)\n","a82bd8d4":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))\nprint(metrics.precision_score(y_test,y_pred,average='macro'))\nprint(metrics.recall_score(y_test,y_pred,average='macro'))","197e3340":"model = GaussianNB()\nmodel.fit(X_train,y_train)\npredicted = model.predict(X_test)\nprint('Predicted Value',predicted)","379e71d6":"cm = confusion_matrix(y_true=y_test,y_pred=predicted)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,predicted))\nprint(metrics.precision_score(y_test,predicted,average='macro'))\nprint(metrics.recall_score(y_test,predicted,average='macro'))","4277a233":"X=dfx\ny=dfy","1c88a4ad":"\nfrom scipy.cluster.hierarchy import dendrogram , linkage\nlinked = linkage(X,'ward')\n\nplt.figure(figsize=(10,7))\ndendrogram(linked,orientation='top',distance_sort='descending',show_leaf_counts=True)\nplt.show()\n","615586b4":"from sklearn.cluster import AgglomerativeClustering\ncluster = AgglomerativeClustering(n_clusters=2,affinity='euclidean',linkage='ward')\ncluster.fit_predict(X)\ny=data['Category']\ncm = confusion_matrix(y_true=y,y_pred=cluster.fit_predict(X))\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y,cluster.fit_predict(X)))","afec6f84":"cluster = AgglomerativeClustering(n_clusters=2,affinity='euclidean',linkage='ward')\ncluster.fit_predict(X)","835600e7":"y=data['Category']","91869ea3":"cm = confusion_matrix(y_true=y,y_pred=cluster.fit_predict(X))\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y,cluster.fit_predict(X)))","cd97f745":"df_labels = pd.DataFrame(kmeans.labels_ , columns = list(['labels']))\n\ndf_labels['labels'] = df_labels['labels'].astype('category')\nsnail_df_labeled = X.join(df_labels)\ndf_analysis = (snail_df_labeled.groupby(['labels'] , axis=0)).head(4177) \ndf_analysis.head(3)","32a42b81":"X=df_analysis.drop('labels',axis=1)\ny=df_analysis['labels']","90efbc19":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n","f83ae366":"names = X.columns\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\n\nseed = 7\nfrom sklearn import model_selection\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","0ab24eee":"X = dfx\ny =dfy\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","4f3504fa":"from sklearn.decomposition import PCA","bbdd8588":"\npca = PCA(n_components= 2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nplt.plot(pca.explained_variance_ratio_)\nplt.xlabel('no. of omponents')\nplt.ylabel('cumulative explained variance')\nplt.show()","c016e59a":"names = X.columns\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\n\nseed = 7\nfrom sklearn import model_selection\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","2afee973":"# PCA Without scaling\nX = dfx\ny = dfy\n\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=425)","ac9383c9":"data.head()","72f79fb0":"pca = PCA(n_components=2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n","8e1f013d":"names = data.columns\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\n\n\nseed = 7\nfrom sklearn import model_selection\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","5fb3dd6e":"# Logistic Regression","824afbd2":"Inference:Highest selling Variety is non vegeterian Variety","8b845be4":"Kmeans: Random Forest has accuracy 96.1 % ","7fa3dac0":"We see that the distribution of stars is maximum in the range 3.5 to 4, which tells us the majority of the Ramen are rated in that range","7298d805":"# grid KNN","0df93058":"Inference: Japan is the highest consumer of Ramen, Nigeria is the least consumer of Ramen","3464c455":"# Extra Trees Classifiers","c6b61507":"# PCA with scaling","891a8dcc":"KMeans","11fc49c8":"Random Forest For Kmeans","2df35f15":"# Decision Trees","83227a71":"# Ensemble Techniques","010b81ad":"Label Encoding for values to hange it into numerals","2fc6f9dd":"Naive Bayes:","520669d2":"Since the value count  of style is 7 and its not easy to balance the data.So for the sake of practicing Machine learning wehave grouped them into Packs as 0 and others as 1","9569f04f":"# Naive Bayes","7338853e":"KNN Classifier for Kmeans","7a97a591":"Value counts for outlier data","16e90a9f":"## USL","df081980":"# Bagged Decision Trees for Classification - necessary dependencies","a29c7f6f":"Results after Hierachial Clustering: KNN gives the highest accuracy","a7db1c98":"# Random Forest","d9070997":"PCA without scaling: RF has the highest Accuracy:66.6%","7b92b953":"#### PCA  scaling : Random Forest has highest Accuracy 66.5%","0f2d7415":"# KNN"}}