{"cell_type":{"c2e534ec":"code","7d4d869b":"code","6e3f3a07":"code","9bff32e8":"code","d686346f":"code","cbc2c3c6":"code","da3947a2":"code","c86ff16e":"code","20410f04":"code","edd8ec06":"code","fc1c0eab":"code","72915ce9":"code","38ed6586":"code","e209321f":"code","1e01455b":"code","d4a9fd25":"code","ed0a6d1f":"code","d0d8d74c":"code","65bf072a":"code","64b58116":"code","9c0a162f":"code","3a242497":"code","5bb3f66e":"code","cb8b4812":"code","bd849388":"code","1d57fa9e":"code","5ce51fdd":"code","17493f1a":"code","99efaee9":"code","9bd522ec":"code","61fe945d":"code","f39a28c3":"code","c364a1ef":"code","e120cd45":"code","a157e401":"code","f0d1bfb1":"code","b27766d0":"code","f6105520":"code","b2d7f054":"code","e5b4db6c":"markdown","b3af1364":"markdown"},"source":{"c2e534ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d4d869b":"# \u5fc5\u8981\u306a\u30e2\u30b8\u30e5\u30fc\u30eb\u306eimport\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm","6e3f3a07":"# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n\ndf_train = pd.read_csv('..\/input\/homework-for-students4plus\/train.csv',index_col=0)\ndf_test = pd.read_csv('..\/input\/homework-for-students4plus\/test.csv',index_col=0)","9bff32e8":"#2015\u5e74\u306e\u878d\u8cc7\u30c7\u30fc\u30bf\u306b\u7d5e\u308b\ndf_train['issue_d'] = df_train['issue_d'].astype(str)\ndf_train = df_train[df_train['issue_d'].str.contains(\"2015\")]","d686346f":"#X\u3068y\u306b\u5206\u5272\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = df_test","cbc2c3c6":"#\u5916\u90e8\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\ngdp = pd.read_csv('..\/input\/homework-for-students4plus\/US_GDP_by_State.csv')\ngdp = gdp.rename(columns={'State': 'city'})\n\nstate_long = pd.read_csv('..\/input\/homework-for-students4plus\/statelatlong.csv')","da3947a2":"#train\u30c7\u30fc\u30bf\u306b\u306f2014\u5e74\u3001test\u30c7\u30fc\u30bf\u306b\u306f2015\u5e74\u306e\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3059\u308b\ngdp_train = gdp.query('year == 2014')\ngdp_test = gdp.query('year == 2015')","c86ff16e":"merge_train = pd.merge(gdp_train[['city','State & Local Spending','Gross State Product','Real State Growth %','Population (million)']], \n         state_long[['State','City']], left_on='city', right_on='City', how='inner').drop(['City'],axis=1).drop(['city'],axis=1)\nmerge_test = pd.merge(gdp_test[['city','State & Local Spending','Gross State Product','Real State Growth %','Population (million)']], \n         state_long[['State','City']], left_on='city', right_on='City', how='inner').drop(['City'],axis=1).drop(['city'],axis=1)","20410f04":"#\u30ad\u30fc\u306e\u4f5c\u6210\nX_train['key'] = X_train['addr_state']\nX_test['key'] = X_test['addr_state']\nmerge_train['key'] = merge_train['State']\nmerge_test['key'] = merge_test['State']","edd8ec06":"X_train = X_train.reset_index()\nX_test = X_test.reset_index()","fc1c0eab":"#merge\u30c6\u30fc\u30d6\u30eb\u3092X\u30c6\u30fc\u30d6\u30eb\u306bleft-join\nX_train = pd.merge(X_train,merge_train,on='key',how = 'left').drop(['key'],axis=1).drop(['State'],axis=1)\nX_test = pd.merge(X_test,merge_test,on='key',how = 'left').drop(['key'],axis=1).drop(['State'],axis=1)","72915ce9":"X_train = X_train.set_index('ID')\nX_test = X_test.set_index('ID')","38ed6586":"#\u7279\u5fb4\u91cf\u306e\u8ffd\u52a0\n#1.\u6b20\u640d\u306e\u6570\u3092\u30ec\u30b3\u30fc\u30c9\u306b\u52a0\u3048\u308b\nX_train['null_cnt'] = X_train.isnull().sum(axis=1)\nX_test['null_cnt'] = X_test.isnull().sum(axis=1)","e209321f":"#2.\u6708\u3005\u306e\u652f\u6255\u984d(installment)*12 \u3092\u5e74\u53ce(annual_inc)\u3067\u5272\u308b\nX_train['burden'] = round((X_train['installment']+1)*12\/(X_train['annual_inc']+1),2)\nX_test['burden'] = round((X_test['installment']+1)*12\/(X_test['annual_inc']+1),2)","1e01455b":"#2.\u30ed\u30fc\u30f3\u91d1\u984d\u3092\u5e74\u53ce(annual_inc)\u3067\u5272\u308b\nX_train['burden2'] = round((X_train['loan_amnt']+1)*12\/(X_train['annual_inc']+1),2)\nX_test['burden2'] = round((X_test['loan_amnt']+1)*12\/(X_test['annual_inc']+1),2)","d4a9fd25":"#3.\u8fd4\u6e08\u5b9f\u7e3e\uff1a\u3053\u308c\u307e\u3067\u306e\u652f\u6255\u7dcf\u984d\/\u3053\u308c\u307e\u3067\u306e\u878d\u8cc7\u984d\n#tot_coll_amt \/ (tot_coll_amt +tot_cur_bal)\nX_train['repayment_record'] = round((X_train['tot_coll_amt']+1)\/(X_train['tot_coll_amt']+X_train['tot_cur_bal']+1),2)\nX_test['repayment_record'] = round((X_test['tot_coll_amt']+1)\/(X_test['tot_coll_amt']+X_test['tot_cur_bal']+1),2)","ed0a6d1f":"#4.\u8cc7\u7523ALL\n#tot_cur_bal + annual_inc\nX_train['all_money'] = round((X_train['tot_cur_bal']+X_train['annual_inc']+1),2)\nX_test['all_money'] = round((X_test['tot_cur_bal']+X_test['annual_inc']+1),2)","d0d8d74c":"#2.\u30ed\u30fc\u30f3\u91d1\u984d\u3092\u8cc7\u7523ALL(all_money)\u3067\u5272\u308b\nX_train['burden3'] = round((X_train['loan_amnt']+1)*12\/(X_train['all_money']+1),2)\nX_test['burden3'] = round((X_test['loan_amnt']+1)*12\/(X_test['all_money']+1),2)","65bf072a":"#\u4e0d\u8981\u5217\u306e\u524a\u9664 'Gross State Product', 'Population (million)', 'State & Local Spending', 'Real State Growth %'\ndrop_col = ['installment','issue_d','State & Local Spending']\nX_train = X_train.drop(drop_col,axis=1)\nX_test = X_test.drop(drop_col,axis=1)","64b58116":"#\u6b20\u640d\u5024\u306e\u5bfe\u5fdc\n#1.\u6b20\u640d\u306b\u6570\u5b57\u3092\u5165\u308c\u308b\nX_train = X_train.fillna({'mths_since_last_delinq': 0, 'mths_since_last_record': 0, 'mths_since_last_major_derog': 0, \n                          'dti': 0,'revol_util':0,'delinq_2yrs':-1})\nX_test = X_test.fillna({'mths_since_last_delinq': 0, 'mths_since_last_record': 0, 'mths_since_last_major_derog': 0,\n                        'dti': 0,'revol_util':0,'delinq_2yrs':-1})\n\n#2.\u6b20\u640d\u306b\u4e2d\u592e\u5024\u3092\u5165\u308c\u308b\nX_train = X_train.fillna({'tot_coll_amt': X_train['tot_coll_amt'].mean(),\n                         'tot_cur_bal': X_train['tot_cur_bal'].mean()})\n\nX_test = X_test.fillna({'tot_coll_amt': X_train['tot_coll_amt'].mean(),\n                         'tot_cur_bal': X_train['tot_cur_bal'].mean()})\n\n#3.\u6b20\u640d\u306b\u300c#\u300d\u3092\u5165\u308c\u308b\nX_train = X_train.fillna({'emp_length': '##', 'title': '##','emp_title':'##'})\nX_test = X_test.fillna({'emp_length': '##', 'title': '##','emp_title':'##'})","9c0a162f":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\n#sub_grade\u306eA~G\u309235~1\u306b\u5909\u63db\nf = 'sub_grade'\n\nfor i,col in zip(range(1,36),['G5','G4','G3','G2','G1','F5','F4','F3','F2','F1','E5','E4','E3','E2','E1',\n                            'D5','D4','D3','D2','D1','C5','C4','C3','C2','C1','B5','B4','B3','B2','B1',\n                            'A5','A4','A3','A2','A1']):\n    X_train.loc[X_train[f] == col, f] = i\n    X_test.loc[X_test[f] == col, f] = i\n\n\nX_train[f] = X_train[f].astype(int)\nX_test[f] = X_test[f].astype(int)","3a242497":"#sub_grade\u306eA~G\u30927~1\u306b\u5909\u63db\nf = 'grade'\n\nfor i,col in zip(range(1,8),['G','F','E','D','C','B','A']):\n    X_train.loc[X_train[f] == col, f] = i\n    X_test.loc[X_test[f] == col, f] = i\n\n\nX_train[f] = X_train[f].astype(int)\nX_test[f] = X_test[f].astype(int)","5bb3f66e":"#\u6570\u5024\u306e\u5909\u63db\n#1.\u6a19\u6e96\u5316\n\n#\u6a19\u6e96\u5316\u30fb\u6b63\u898f\u5316\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nfrom sklearn.preprocessing import StandardScaler\n\nstand_col = ['loan_amnt','dti','mths_since_last_delinq','mths_since_last_record','open_acc',\n             'pub_rec','revol_util','total_acc','mths_since_last_major_derog']\nscaler = StandardScaler()\nscaler.fit(X_train[stand_col])\n\nX_train[stand_col] = scaler.transform(X_train[stand_col])\nX_test[stand_col] = scaler.transform(X_test[stand_col])","cb8b4812":"#2.Yeo-Jhonson\u5909\u63db\n\nlog_col =['annual_inc','delinq_2yrs','inq_last_6mths','revol_bal','collections_12_mths_ex_med',\n          'tot_coll_amt','tot_cur_bal','all_money','acc_now_delinq']\n\nfrom sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer(method='yeo-johnson')\npt.fit(X_train[log_col])\n\nX_train[log_col] = pt.transform(X_train[log_col])\nX_test[log_col] = pt.transform(X_test[log_col])","bd849388":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\n#emp_length\u30920~11\u306b\u5909\u63db\nf = 'emp_length'\n\nfor i,col in zip([0,1,2,3,4,5,6,7,8,9,10,11],['##','< 1 year','1 year','2 years','3 years','4 years','5 years','6 years',\n                           '7 years','8 years','9 years','10+ years']):\n    X_train.loc[X_train[f] == col, f] = i\n    X_test.loc[X_test[f] == col, f] = i\n\nX_train[f] = X_train[f].astype(float)\nX_test[f] = X_test[f].astype(float)","1d57fa9e":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\n#earliest_cr_line\u3092\u5e74\u306b\u5909\u63db\nX_train['earliest_cr_line'] = X_train['earliest_cr_line'].str[-4:]\nX_test['earliest_cr_line'] = X_test['earliest_cr_line'].str[-4:]","5ce51fdd":"#label_encoding\nfrom sklearn.preprocessing import LabelEncoder\n\ncat_cols = ['application_type']\n\nfor c in cat_cols:\n    le = LabelEncoder()\n    le.fit(X_train[c])\n    X_train[c] = le.transform(X_train[c])\n    X_test[c] = le.transform(X_test[c])","17493f1a":"#target-encoding\n\ncols = ['home_ownership','purpose','title','addr_state','earliest_cr_line','initial_list_status','zip_code']\ntarget = 'loan_condition'\nX_temp = pd.concat([X_train, y_train], axis=1)\n\nfor col in cols:\n\n    # X_test\u306fX_train\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    summary = X_temp.groupby([col])[target].mean()\n    X_test[col] = X_test[col].map(summary) \n\n\n    # X_train\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092oof\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[col].map(summary)\n        \n    X_train[col]  = enc_train","99efaee9":"y_pred_test = np.zeros(len(X_test)) # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u683c\u7d0d\u7528array\ny_pred = np.zeros(len(X_test)) # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u683c\u7d0d\u7528array","9bd522ec":"#TEXT\nTXT_train = X_train.emp_title.copy()\nTXT_test = X_test.emp_title.copy()\n\nTXT_train = TXT_train.str.lower()\nTXT_test = TXT_test.str.lower()\n\n#emp_title\u306f\u30c6\u30ad\u30b9\u30c8\u306a\u306e\u3067\u3044\u3063\u305f\u3093\u306e\u305e\u304f\nX_train = X_train.drop('emp_title',axis=1)\nX_test = X_test.drop('emp_title',axis=1)\n\ntfidf = TfidfVectorizer(max_features=1000, use_idf=True)\n\nTXT_train_enc = tfidf.fit_transform(TXT_train)\nTXT_test_enc = tfidf.transform(TXT_test)\n\nX_train = sp.sparse.hstack([X_train.values, TXT_train_enc])\nX_test = sp.sparse.hstack([X_test.values, TXT_test_enc])\n\n# \u884c\u65b9\u5411\u306e\u30b9\u30e9\u30a4\u30b9\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u5909\u63db\u3059\u308b\nX_train = X_train.tocsr()\nX_test = X_test.tocsr()","61fe945d":"##Ave. CV score is 0.715028  (Ave. CV score is 0.713696)\n\nimport lightgbm as lgb\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c2\nskf = StratifiedKFold(n_splits=5, random_state=9434, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c3\nskf = StratifiedKFold(n_splits=5, random_state=94, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c4\nskf = StratifiedKFold(n_splits=5, random_state=34, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c5\nskf = StratifiedKFold(n_splits=5, random_state=35, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c6\nskf = StratifiedKFold(n_splits=5, random_state=77, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c7\nskf = StratifiedKFold(n_splits=5, random_state=101, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c8\nskf = StratifiedKFold(n_splits=5, random_state=373, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c9\nskf = StratifiedKFold(n_splits=5, random_state=365, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c10\nskf = StratifiedKFold(n_splits=5, random_state=1000, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c11\nskf = StratifiedKFold(n_splits=5, random_state=2, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c12\nskf = StratifiedKFold(n_splits=5, random_state=3, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c13\nskf = StratifiedKFold(n_splits=5, random_state=4, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c14\nskf = StratifiedKFold(n_splits=5, random_state=5, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c15\nskf = StratifiedKFold(n_splits=5, random_state=6, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c16\nskf = StratifiedKFold(n_splits=5, random_state=7, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c17\nskf = StratifiedKFold(n_splits=5, random_state=8, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c18\nskf = StratifiedKFold(n_splits=5, random_state=9, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c19\nskf = StratifiedKFold(n_splits=5, random_state=10, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\n#random_state\u3092\u5909\u3048\u3066\u518d\u5ea6\u5b9f\u884c20\nskf = StratifiedKFold(n_splits=5, random_state=11, shuffle=True)\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n clf = lgb.LGBMClassifier(colsample_bytree=0.7000000000000001, learning_rate=0.05,\n               max_depth=10, subsample=0.9929417385040324,n_estimators=9999)\n\n clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n y_pred = clf.predict_proba(X_val)[:,1]\n scores.append(roc_auc_score(y_val, y_pred))\n\n y_pred_test += clf.predict_proba(X_test)[:,1] # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f\n\nscores = np.array(scores)\nprint('Ave. CV score is %f' % scores.mean())\ny_pred_test \/= 100 # \u6700\u5f8c\u306bfold\u6570\u3067\u5272\u308b","f39a28c3":"submission = pd.read_csv('..\/input\/homework-for-students4plus\/sample_submission.csv', index_col=0)\n\nsubmission.loan_condition = y_pred_test\nsubmission.to_csv('submission.csv')","c364a1ef":"submission","e120cd45":"\"\"\"from hyperopt import fmin, tpe, hp, rand, Trials\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom lightgbm import LGBMClassifier\"\"\"","a157e401":"\"\"\"def objective(space):\n    scores = []\n\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n    for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train[train_ix,:], y_train.iloc[train_ix]\n        X_val, y_val = X_train[test_ix,:], y_train.iloc[test_ix]\n\n        clf = LGBMClassifier(n_estimators=9999, **space) \n\n        clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])\n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n    scores = np.array(scores)\n    print(scores.mean())\n    \n    return -scores.mean()\"\"\"","f0d1bfb1":"\"\"\"space ={\n 'max_depth': hp.choice('max_depth', np.arange(10, 30, dtype=int)),\n 'subsample': hp.uniform ('subsample', 0.8, 1),\n 'learning_rate' : hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n 'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05)\n }\"\"\"","b27766d0":"\"\"\"best = fmin(\n    objective,\n    space=space,\n    algo=tpe.suggest,\n    max_evals=200)\"\"\"","f6105520":"\"\"\"LGBMClassifier(**best)\"\"\"","b2d7f054":"\"\"\"trials.best_trial['result']\"\"\"","e5b4db6c":"### \u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u3057\u3066\u307f\u308b","b3af1364":"# \u5916\u90e8\u30c7\u30fc\u30bf\u306emerge"}}