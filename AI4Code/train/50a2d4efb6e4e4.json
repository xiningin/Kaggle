{"cell_type":{"f19ad73f":"code","a607931c":"code","2236197a":"code","77c8e5d1":"code","7f8149be":"code","08a20ff3":"code","109afad9":"code","2d4e4771":"code","631806ae":"code","3d172f69":"code","133efe28":"code","d9b7f313":"code","b4c65d2d":"code","645b7b04":"markdown","7b58a5f5":"markdown","9c7ec579":"markdown","022a7a88":"markdown"},"source":{"f19ad73f":"# Importing all the important libraries that we need\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn import datasets","a607931c":"# Loading the dataset from sklearn datasets\n\ndf = pd.read_csv('..\/input\/iris\/Iris.csv')\n#y = iris.target\n","2236197a":"x = df.drop(['Id', 'Species'], axis = 1) ","77c8e5d1":"# A glance of the dataset\n\n#x","7f8149be":"# Defining the number of clusters an\n\nkmeans5 = KMeans(n_clusters=5)\n\n#Output of Kmeans clustering with value 5\ny_kmeans5 = kmeans5.fit_predict(x)\nprint(y_kmeans5)\n","08a20ff3":"\n#Print the centers of 5 clusters\nkmeans5.cluster_centers_","109afad9":"# Printing the interia value\n\n#  Inertia actually calculates the sum of distances of all the points within\n#a cluster from the centroid of that cluster. It tells us how far the points \n#within a cluster are. The distance between them should be as low as possible.\n\n\nkmeans5.inertia_","2d4e4771":"SSE =[]\nfor clusters in range(1, 11):\n    kmeans = KMeans(n_clusters = clusters).fit(x)\n    kmeans.fit(x)\n    SSE.append(kmeans.inertia_)\nimport matplotlib.pyplot as plt\nplt.plot(range(1, 11), SSE)\nplt.title('Elbow method')\nplt.xlabel('No of clusters')\nplt.ylabel('Inertia')\nplt.show()","631806ae":"kmeans3 = KMeans(n_clusters = 3)","3d172f69":"y_kmeans3 = kmeans3.fit_predict(x)\nprint(y_kmeans3)","133efe28":"# Printing the center points\nkmeans3.cluster_centers_","d9b7f313":"# Let's see how many data points are in these 3 clusters.\n\nframe = pd.DataFrame(x)\nframe['cluster'] = y_kmeans3\nframe['cluster'].value_counts()","b4c65d2d":"plt.scatter(x.iloc[:,0],x.iloc[:,1], c = y_kmeans3, cmap='rainbow')","645b7b04":"## Visualize the data","7b58a5f5":"## How can we decide the optimum number of clusters? \n\nWe can do that with elbow method. \nWe will plot a graph, where the x-axis will represent the number of clusters and the y-axis will be an evaluation metric (inertia)","9c7ec579":"> ** Author: Kazi Amit Hasan <br>**\nDepartment of Computer Science & Engineering,<br>\nRajshahi University of Engineering & Technology (RUET)<br>\nWebsite: https:\/\/amithasanshuvo.github.io\/<br>\nLinkedin: https:\/\/www.linkedin.com\/in\/kazi-amit-hasan-514443140\/<br>\nEmail: kaziamithasan89@gmail.com<br>\n\n\nIf you want some basic ideas on clustering, then you can follow the following link: https:\/\/www.kaggle.com\/getting-started\/160596\n\n*\n**Please leave your feedback and upvote if you like it.***\n\nRef:\n\n1. https:\/\/www.analyticsvidhya.com\/blog\/2019\/08\/comprehensive-guide-k-means-clustering\/\n2. https:\/\/heartbeat.fritz.ai\/k-means-clustering-using-sklearn-and-python-4a054d67b187","022a7a88":"The cluster value where this decrease in inertia value becomes constant can be chosen as the right cluster value for our data. \n\nHere, Our optimal cluster value is between 3 and 4. So, let's select 3 as our num of clusters.\n\n## Repeat the same process with no_clusters = 3"}}