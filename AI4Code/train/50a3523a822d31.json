{"cell_type":{"a16d42b3":"code","a820bef7":"code","bc231abb":"code","4c937c49":"code","bc6edc5b":"code","18aee9fc":"code","2b2aeef8":"code","d490cd16":"code","444311b8":"code","eeccb620":"code","9e1a76a8":"code","b3be5f11":"markdown","9005af1a":"markdown","e7106828":"markdown","83db9370":"markdown","53330b4a":"markdown","ff41c55b":"markdown","a72865ea":"markdown"},"source":{"a16d42b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a820bef7":"data = pd.read_csv(\"\/kaggle\/input\/adult-income-dataset\/adult.csv\")\ndata = pd.DataFrame(data, columns=data.columns)\ndata","bc231abb":"data.income = [1 if each=='>50K' else 0 for each in data.income]\ny = data.income\ny","4c937c49":"data.drop([\"fnlwgt\",\"native-country\"],axis=1,inplace=True)\ndata","bc6edc5b":"data = pd.get_dummies(data)\ndata","18aee9fc":"over  = data[data.income == 1]\nbelow = data[data.income == 0]\nover","2b2aeef8":"plt.scatter(over[\"capital-gain\"],over.income,color='purple',alpha=0.4,label='kotu')\nplt.scatter(below[\"capital-gain\"],below.income,color='green',alpha=0.4,label='iyi')","d490cd16":"from sklearn.model_selection import train_test_split\nx_train , x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)","444311b8":"from sklearn.neighbors import KNeighborsClassifier\nscore_list=[]\nscore_list2=[]\nfor i in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    score_list.append(knn.score(x_test,y_test))\nplt.plot(range(1,20),score_list)\nplt.show()","eeccb620":"score_list2=[]\nfor i in range(20,40):\n    knn2 = KNeighborsClassifier(n_neighbors=i)\n    knn2.fit(x_train,y_train)\n    score_list2.append(knn2.score(x_test,y_test))\nplt.plot(range(20,40),score_list2)\nplt.show()","9e1a76a8":"knn3 = KNeighborsClassifier(n_neighbors=33)\n\nknn3.fit(x_train,y_train)\nprint(knn3.score(x_test,y_test))","b3be5f11":"This dataset has so much non-numerical data , we must encode them but first i need to divide my labels and features.","9005af1a":"As you can see i got my labels as y and encoded them if bigger than 50K to 1 else 0.","e7106828":"Let's start with importing our data and , take a look at it.","83db9370":"I am splitting my data for training and testing.","53330b4a":"Now i will split my data for visualization.","ff41c55b":"Our maximum accuracy is not so good but if we use K=33 it gives maximum.","a72865ea":"It's time for encoding other features !"}}