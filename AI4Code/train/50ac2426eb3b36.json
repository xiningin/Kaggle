{"cell_type":{"46a95a77":"code","1b5b4626":"code","906481ff":"code","ed5746bd":"code","79aef304":"code","e8faf030":"code","b2706040":"code","8efc4763":"code","70787a4f":"code","2c90d2d4":"code","f60eed2e":"code","7928f15c":"code","8095dc33":"code","5b728b71":"code","59a7c5c2":"code","b75123b2":"code","48715d9b":"code","7920c292":"code","5473bea5":"code","a08d5b9b":"code","90a148c7":"markdown","e9791faf":"markdown","9ae22a92":"markdown","be8c35c4":"markdown","b129ded3":"markdown","4772f722":"markdown","112f24f5":"markdown","e82d1000":"markdown","108e1eca":"markdown","be55e16e":"markdown","89de8347":"markdown"},"source":{"46a95a77":"import os, sys\n\nimport numpy as np\nfrom scipy.stats import chi2_contingency\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","1b5b4626":"df = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ndf.head()","906481ff":"df.shape","ed5746bd":"df_targets = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ndf_targets.head()","79aef304":"df_targets.shape","e8faf030":"df_test_sub = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')","b2706040":"def summarize_categoricals(df, show_levels=False, threshold=5):\n    \"\"\"\n        Display uniqueness in each column\n    \"\"\"\n    data = [[df[c].unique(), len(df[c].unique()), df[c].isnull().sum()] for c in df.columns]\n    df_temp = pd.DataFrame(data, index=df.columns,\n                           columns=['Levels', 'No. of Levels', 'No. of Missing Values'])\n    return df_temp[df_temp['No. of Levels'] <= threshold].iloc[:, 0 if show_levels else 1:]\n\n\ndef return_categoricals(df, threshold=5):\n    \"\"\"\n        Returns a list of columns that have less than or equal to\n        `threshold` number of unique categorical levels\n    \"\"\"\n    return list(filter(lambda c: c if len(df[c].unique()) <= threshold else None,\n                       df.columns))\n\n\ndef to_categorical(columns, df):\n    \"\"\"\n        Converts the columns passed in `columns` to categorical datatype\n    \"\"\"\n    for col in columns:\n        df[col] = df[col].astype('category')\n    return df","8efc4763":"summarize_categoricals(df, show_levels=True, threshold=500)","70787a4f":"categorical_columns = return_categoricals(df)","2c90d2d4":"df = to_categorical(categorical_columns, df)","f60eed2e":"df.info()","7928f15c":"df_test_sub = to_categorical(categorical_columns, df_test_sub)","8095dc33":"x = df.iloc[:, 1:]\ny = df_targets.iloc[:, 1:]\n\ncategorical_columns = list(x.select_dtypes(include='category').columns)\nnumeric_columns = list(x.select_dtypes(exclude='category').columns)","5b728b71":"from sklearn.model_selection import train_test_split\n\ndata_splits = train_test_split(x, y, test_size=0.15, random_state=0,\n                               shuffle=True)\nx_train, x_test, y_train, y_test = data_splits\n\nlist(map(lambda x: x.shape, [x, y, x_train, x_test,\n                             y_train, y_test]))","59a7c5c2":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline \n\n\nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', dtype=np.int))])\n\n## Column Transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_columns),\n        ('cat', categorical_transformer, categorical_columns)],\n    remainder='passthrough')\n\n\n## Applying Column Transformer\nx_train = preprocessor.fit_transform(x_train)\nx_test = preprocessor.transform(x_test)\n\nx_test_sub = preprocessor.transform(df_test_sub.iloc[:, 1:])\n\n\n## Label encoding\ny_train = y_train.to_numpy(dtype=np.int64)\ny_test = y_test.to_numpy(dtype=np.int64)\n\n\n## Save feature names after one-hot encoding for feature importances plots\nfeature_names = list(preprocessor.named_transformers_['cat'].named_steps['onehot'] \\\n                     .get_feature_names(input_features=categorical_columns))\nfeature_names = feature_names + numeric_columns","b75123b2":"from sklearn.metrics import log_loss\nfrom xgboost import XGBClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\n\nxgb = XGBClassifier(tree_method='gpu_hist',\n                    predictor='gpu_predictor',\n                    random_state=0, n_jobs=-1)\n\novr_clf = OneVsRestClassifier(estimator=xgb, n_jobs=-1)\n\novr_clf.fit(x_train, y_train)\n\novr_probs = ovr_clf.predict_proba(x_test)\n\nlog_loss(y_test, ovr_probs)","48715d9b":"from sklearn.multioutput import MultiOutputClassifier\n\nmo_clf = MultiOutputClassifier(estimator=xgb, n_jobs=-1)\n\nmo_clf.fit(x_train, y_train)\n\nmo_probs = mo_clf.predict_proba(x_test)\n\nn_classes = y_test.shape[1]\nn_test_samples = x_test.shape[0]\nmo_probs_pos = np.zeros((n_test_samples, n_classes))\n\nfor c in range(n_classes):\n    c_probs = mo_probs[c]\n    mo_probs_pos[:, c] = c_probs[:, 1]\n\nlog_loss(y_test, mo_probs_pos)","7920c292":"from sklearn.multioutput import ClassifierChain\nfrom joblib import Parallel, delayed\nimport timeit\n\nchains = [ClassifierChain(base_estimator=xgb, order='random')\n          for i in range(5)]\n\nchains = Parallel(n_jobs=-1)(delayed(chain.fit)(x_train, y_train) for chain in chains)\n\nchains_ensemble_proba = Parallel(n_jobs=-1)(delayed(chain.predict_proba)(x_test) for chain in chains)\n\nlog_loss(y_test, np.array(chains_ensemble_proba).mean(axis=0))","5473bea5":"## Final Model\nx_train_full = preprocessor.fit_transform(x)\ny_train_full = y.to_numpy(dtype=np.int64)\n\nx_test_final = preprocessor.transform(df_test_sub.iloc[:, 1:])\n\nchains = Parallel(n_jobs=-1)(delayed(chain.fit)(x_train_full, y_train_full) for chain in chains)\n\nfinal_proba = Parallel(n_jobs=-1)(delayed(chain.predict_proba)(x_test_final) for chain in chains)","a08d5b9b":"pd.DataFrame(np.array(final_proba).mean(axis=0),\n             index=df_test_sub['sig_id'],\n             columns=df_targets.columns[1:]).to_csv('submission.csv')","90a148c7":"<a id=\"data-preprocessing\"><\/a>\n# 2. Data Preprocessing","e9791faf":"<a id=\"train-test-split\"><\/a>\n## 2.1. Train-Test split","9ae22a92":"Thank You!!","be8c35c4":"<a id=\"xgboost-%2B-classifierchain\"><\/a>\n# 5. XGBoost + ClassifierChain","b129ded3":"* [1. Import Data](#import-data)\n* [2. Data Preprocessing](#data-preprocessing)\n    * [2.1. Train-Test split](#train-test-split)\n    * [2.2. Preprocessing Pipeline: One-hot Encoding and Standardization](#preprocessing-pipeline%3A-one-hot-encoding-and-standardization)\n* [3. XGBoost + OneVsRestClassifier](#xgboost-%2B-onevsrestclassifier)\n* [4. XGBoost + MultiOutputClassifier](#xgboost-%2B-multioutputclassifier)\n* [5. XGBoost + ClassifierChain](#xgboost-%2B-classifierchain)\n* [6. Retrain on full dataset and Submit Predictions](#retrain-on-full-dataset-and-submit-predictions)","4772f722":"<a id=\"xgboost-%2B-multioutputclassifier\"><\/a>\n# 4. XGBoost + MultiOutputClassifier","112f24f5":"## 1.1. Find categorical columns and change their *Dtype* from `object` to `Categorical`","e82d1000":"<a id=\"xgboost-%2B-onevsrestclassifier\"><\/a>\n# 3. XGBoost + OneVsRestClassifier","108e1eca":"<a id=\"import-data\"><\/a>\n# 1. Import Data","be55e16e":"<a id=\"preprocessing-pipeline%3A-one-hot-encoding-and-standardization\"><\/a>\n## 2.2. Preprocessing Pipeline: One-hot Encoding and Standardization","89de8347":"<a id=\"retrain-on-full-dataset-and-submit-predictions\"><\/a>\n# 6. Retrain on full dataset and Submit Predictions"}}