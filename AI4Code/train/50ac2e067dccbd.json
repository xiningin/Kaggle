{"cell_type":{"6e764890":"code","addf2a63":"code","686fb982":"code","601629a7":"code","448f51c1":"code","3fa1f8f5":"code","2d9216e0":"code","56562247":"code","34e4fa5a":"code","49b5c83f":"code","66f5774e":"code","1f26931b":"code","d12b1dcd":"code","529ff070":"code","a17a1749":"code","17967c8c":"code","c8bcdcbf":"code","5fa94ea2":"code","0e2d87c6":"code","13d0d861":"code","b913f54a":"code","d737e4cb":"code","2b987a3f":"code","95180693":"code","55f1108f":"code","318e81f0":"code","db897ffc":"code","fa14b9c9":"code","15b9230e":"code","10d031ad":"code","6757bc3f":"code","cb63da14":"code","688496a2":"code","d2486484":"code","1541e3dd":"code","5ca8421b":"code","ef7ac2a9":"code","dbe1b89e":"code","0269f743":"code","8ceb8c81":"code","2dd66efd":"code","3a24d341":"code","4d71c819":"code","35e463da":"code","e9397045":"code","f2cf9879":"code","facd64c2":"code","a3b0d190":"code","2d210f9b":"code","7f79ee14":"code","ca234404":"code","ee183d52":"code","f80afe5c":"code","b475af33":"code","768cc32d":"code","d0b37ef7":"code","287d0ed7":"code","be4fb98a":"code","1f0e4838":"code","23e30e99":"code","b4893ec3":"code","30a42dd0":"code","2b4fb1b6":"code","008fd85c":"code","bf0dbde5":"code","1968a463":"code","d3d5c695":"code","67525988":"code","61773fe7":"code","8ca40c72":"code","78f6a964":"code","bd3d3dea":"markdown","decd646c":"markdown","a8af7cb1":"markdown","ba81df3e":"markdown","ab1b9c40":"markdown","21836dd2":"markdown","931f794e":"markdown","ea9e0453":"markdown","ccabec95":"markdown","b9158a7a":"markdown","66d08421":"markdown"},"source":{"6e764890":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn import preprocessing\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\npd.set_option('display.max_columns', 30)\npd.set_option('display.max_rows', 50)","addf2a63":"\ntrain = pd.read_csv(\"\/kaggle\/input\/bigquery-geotab-intersection-congestion\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/bigquery-geotab-intersection-congestion\/test.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/bigquery-geotab-intersection-congestion\/sample_submission.csv\")","686fb982":"train.head() \n\n#test\n","601629a7":"test.head()","448f51c1":"test.shape","3fa1f8f5":"sample_submission.shape","2d9216e0":"# address_encoding = {\"Street\": \"Street\",\n#  \"St\": \"Street\",\n#  \"Avenue\": \"Avenue\",\n#  \"Ave\": \"Avenue\",\n#  \"Boulevard\": \"Boulevard\",\n#  \"Road\": \"Road\",\n#  \"Drive\": \"Drive\",\n#  \"Lane\": \"Lane\",\n#  \"Tunnel\":\"Tunnel\",\n#  \"Highway\": \"Highway\",\n#  \"Way\":\"Way\",\n#  \"Parkway\":\"Parkway\",\n#  \"Parking\": \"Parking\",\n#  \"Oval\": \"Oval\",\n#  \"Square\": \"Square\",\n#  \"Place\": \"Place\",\n#  \"Bridge\": \"Bridge\"} \n\naddress_encoding = {\n    \"Street\": 0,\n     \"St\": 0,\n     \"Avenue\": 1,\n     \"Ave\": 1,\n     \"Boulevard\": 2,\n     \"Road\": 3,\n     \"Drive\": 4,\n     \"Lane\": 5,\n     \"Tunnel\": 6,\n     \"Highway\": 7,\n     \"Way\": 8,\n     \"Parkway\": 9,\n     \"Parking\": 10,\n     \"Oval\": 11,\n     \"Square\": 12,\n     \"Place\": 13,\n     \"Bridge\": 14\n}","56562247":"def encode(x):\n    if pd.isna(x):\n        return 15\n    for road in address_encoding:\n        if (road in x):\n            return address_encoding[road]\n    return 15","34e4fa5a":"train[\"EntryAdressEncoded\"] = train['EntryStreetName'].apply(encode)\ntrain['ExitAddressEncoded'] = train['ExitStreetName'].apply(encode)\ntest[\"EntryAdressEncoded\"] = test['EntryStreetName'].apply(encode)\ntest['ExitAddressEncoded'] = test['ExitStreetName'].apply(encode)","49b5c83f":"pd.set_option('display.max_rows', 200)\ntrain","66f5774e":"def check_if_entry_equals_exit_address(entry_address, exit_address):\n    if (entry_address == exit_address):\n        return True\n    return False\n","1f26931b":"train['IfEntryExitSame'] = train.apply(lambda x: check_if_entry_equals_exit_address(x.EntryStreetName, x.ExitStreetName), axis=1)\ntest['IfEntryExitSame'] = test.apply(lambda x: check_if_entry_equals_exit_address(x.EntryStreetName, x.ExitStreetName), axis=1)","d12b1dcd":"directions = {\n    'N': 0,\n    'NE': 1\/4,\n    'E': 1\/2,\n    'SE': 3\/4,\n    'S': 1,\n    'SW': 5\/4,\n    'W': 3\/2,\n    'NW': 7\/4\n}","529ff070":"train['EntryHeading'] = train['EntryHeading'].map(directions)\ntrain['ExitHeading'] = train['ExitHeading'].map(directions)\n\ntest['EntryHeading'] = test['EntryHeading'].map(directions)\ntest['ExitHeading'] = test['ExitHeading'].map(directions)","a17a1749":"# train['diffHeading'] = train['EntryHeading']-train['ExitHeading'] \n# test['diffHeading'] = test['EntryHeading']-test['ExitHeading']\n\n# train[['ExitHeading','EntryHeading','diffHeading']].drop_duplicates().head(10)\n# train[\"same_street_exact\"] = (train[\"EntryStreetName\"] ==  train[\"ExitStreetName\"]).astype(int)\n# test[\"same_street_exact\"] = (test[\"EntryStreetName\"] ==  test[\"ExitStreetName\"]).astype(int)\u2029","17967c8c":"le = preprocessing.LabelEncoder()","c8bcdcbf":"train[\"Intersection\"] = train[\"IntersectionId\"].astype(str) + train[\"City\"]\ntest[\"Intersection\"] = test[\"IntersectionId\"].astype(str) + test[\"City\"]\n\nprint(train[\"Intersection\"].sample(6).values)\npd.concat([train[\"Intersection\"],test[\"Intersection\"]],axis=0).drop_duplicates().values\n","5fa94ea2":"le.fit(pd.concat([train[\"Intersection\"],test[\"Intersection\"]]).drop_duplicates().values)\ntrain[\"Intersection\"] = le.transform(train[\"Intersection\"])\ntest[\"Intersection\"] = le.transform(test[\"Intersection\"])","0e2d87c6":"one_hot = pd.get_dummies(train['City'])\ntrain = train.drop('City',axis = 1)\ntrain = train.join(one_hot)\n","13d0d861":"one_hot = pd.get_dummies(test['City'])\ntest = test.drop('City',axis = 1)\ntest = test.join(one_hot)\n","b913f54a":"def isLeft(entry, exit):\n    if entry == exit:\n        return False\n    left_dir = []\n    current_dir = entry\n    for i in range(3):\n        current_dir -= 1\/4\n        if current_dir < 0:\n            current_dir += 2.0\n        left_dir.append(current_dir)\n    return exit in left_dir","d737e4cb":"train['TurnLeft'] = train.apply(lambda x: isLeft(x.EntryHeading, x.ExitHeading), axis = 1)\ntest['TurnLeft'] = test.apply(lambda x: isLeft(x.EntryHeading, x.ExitHeading), axis = 1)","2b987a3f":"# train = train.dropna()","95180693":"train","55f1108f":"test","318e81f0":"train.columns","db897ffc":"Y = train[[\"TotalTimeStopped_p20\", \"TotalTimeStopped_p50\", \"TotalTimeStopped_p80\", \"DistanceToFirstStop_p20\",\"DistanceToFirstStop_p50\", \"DistanceToFirstStop_p80\" ]]\nX = train[[ 'IntersectionId', \"Intersection\", 'Latitude', 'Longitude',\n         'EntryHeading', 'ExitHeading', \"TurnLeft\", 'Hour', 'Weekend',\n       'Month', 'EntryAdressEncoded', 'ExitAddressEncoded', 'IfEntryExitSame',\n       'Atlanta', 'Boston', 'Chicago', 'Philadelphia']]\n\n# X = train \n# X = X.drop(['TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n#        'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n#        'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n#        'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n#        'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n#        'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n#        'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80' ], axis = 1)","fa14b9c9":"X_test = test[[ 'IntersectionId', \"Intersection\", 'Latitude', 'Longitude',\n         'EntryHeading', 'ExitHeading', \"TurnLeft\", 'Hour', 'Weekend',\n       'Month', 'EntryAdressEncoded', 'ExitAddressEncoded', 'IfEntryExitSame',\n       'Atlanta', 'Boston', 'Chicago', 'Philadelphia']]\n","15b9230e":"Y","10d031ad":"X","6757bc3f":"X_train, X_validate, y_train, y_validate = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n","cb63da14":"X_test.isnull().any()","688496a2":"print(X_train.shape)\nprint(X_validate.shape)\nprint(y_train.shape)\nprint(y_validate.shape)\n","d2486484":"print(X_test.shape)","1541e3dd":"model = LinearRegression()\nmodel.fit(X_train, y_train)\n#reg.score(X_validate, y_validate)\ny_pred = model.predict(X_validate)","5ca8421b":"y_pred","ef7ac2a9":"y_validate","dbe1b89e":"mean_squared_error(y_validate, y_pred)","0269f743":"model.score(X_validate, y_validate)","8ceb8c81":"from sklearn.cross_decomposition import PLSRegression\npls2 = PLSRegression(n_components=2)\npls2.fit(X_train, y_train)\ny_pred = pls2.predict(X_validate)","2dd66efd":"y_pred","3a24d341":"mean_squared_error(y_validate, y_pred)","4d71c819":"pls2.score(X_validate, y_validate)","35e463da":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=6, random_state = 0)\nmodel.fit(X_train, y_train)\n# y_pred = model.predict(X_validate)","e9397045":"mean_squared_error(y_validate, y_pred)","f2cf9879":"model.score(X_validate, y_validate)","facd64c2":"n_list = []\nmse_list = []\nr_score_list = []\nfor n in range(1, 10):\n    model = RandomForestRegressor(n_estimators=n, random_state = 0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_validate)\n    mse_list.append(mean_squared_error(y_validate, y_pred))\n    r_score_list.append(model.score(X_validate, y_validate))\n    n_list.append(n)\n\n\n    \n","a3b0d190":"y_pred_test = model.predict(X_test)\n","2d210f9b":"y_pred_test","7f79ee14":"output_index = []\noutput_values = []\nfor i in range(len(y_pred_test)):\n    for j in range(6):\n        index = str(i) + \"_\" + str(j)\n        output_index.append(index)\n        output_values.append(y_pred_test[i][j])\n\n    \n  \n    \n    \n    ","ca234404":"def generate_submission_file(y_pred_test):\n    output_index = []\n    output_values = []\n    for i in range(len(y_pred_test[0])):\n        for j in range(6):\n            index = str(i) + \"_\" + str(j)\n            output_index.append(index)\n            output_values.append(y_pred_test[j][i])\n    df = pd.DataFrame()\n    df[\"TargetId\"] = output_index\n    df[\"Target\"] = output_values\n    df_cut = df.iloc[0: 11522010]\n    df_cut.to_csv(\"submission.csv\", index = False)\n    print(df_cut.shape)\n    return df \n    ","ee183d52":"df = pd.DataFrame()\ndf[\"TargetId\"] = output_index\ndf[\"Target\"] = output_values\n","f80afe5c":"df.shape","b475af33":"df_smaller = df.iloc[0: 11522010]","768cc32d":"df_smaller.shape","d0b37ef7":"df.to_csv(\"submission.csv\", index = False)\n","287d0ed7":"df_smaller.to_csv(\"submission.csv\", index = False)","be4fb98a":"print(mse_list)\nprint(r_score_list)\n","1f0e4838":"import matplotlib.pyplot as plt\n\nfig = plt.figure()\nax = plt.axes()\nax.plot(n_list, mse_list)\nplt.title(\"Number of trees vs. MSE\")\nplt.xlabel(\"Number of Trees\")\nplt.ylabel(\"Mean Squared Error\");\n# for i, v in enumerate(mse_list):\n#     ax.annotate(str(round(v, 1)), xy=(i,v), xytext=(-7,7), textcoords='offset points')","23e30e99":"fig = plt.figure()\nax = plt.axes()\nax.plot(n_list, r_score_list)\nplt.title(\"Number of trees vs. R-squared Coefficient\")\nplt.xlabel(\"Number of Trees\")\nplt.ylabel(\"R-squared Coefficient\");\n# for i, v in enumerate(r_score_list):\n#     ax.annotate(str(round(v, 3)), xy=(i,v), xytext=(0,0), textcoords='offset points')","b4893ec3":"# ","30a42dd0":"import lightgbm as lgb","2b4fb1b6":"# lgbm_train = lgb.Dataset(X_train, label =  y_train)\n# lgbm_valid = lgb.Dataset(X_validate, label = y_validate)\n\n","008fd85c":"# lgbm_reg = lgb.train(best_params, xg_train, 10000,\n#                       valid_sets = [xg_valid],\n#                       verbose_eval=500, \n#                       early_stopping_rounds = 250)","bf0dbde5":"params = {'boosting': 'gbdt',\n 'colsample_bytree': 0.9360683895657687,\n 'gpu_device_id': 0,\n 'learning_rate': 0.09642143740152433,\n 'max_depth': 6,\n 'metric': 'rmse',\n 'min_child_samples': 70,\n 'num_leaves': 140,\n 'objective': 'regression',\n 'subsample': 1}","1968a463":"all_preds ={0:[],1:[],2:[],3:[],4:[],5:[]}\nfor i in range(len(all_preds)):\n    lgbm_train = lgb.Dataset(X_train, label =  y_train.iloc[:,i])\n    lgbm_valid = lgb.Dataset(X_validate, label = y_validate.iloc[:,i])\n    lgbm_reg = lgb.train(params, train_set = lgbm_train, valid_sets = [lgbm_valid], verbose_eval = 500)\n    all_preds[i] = lgbm_reg.predict(X_test, num_iteration=lgbm_reg.best_iteration)\n\n\n\n","d3d5c695":"all_preds","67525988":"len(all_preds)","61773fe7":"pd_pred = generate_submission_file(all_preds)","8ca40c72":"pd_pred","78f6a964":"lgbm_reg = lgb.LGBMRegressor()\nlgbm_reg = lgb.train(params, train_set = lgbm_train, valid_sets = [lgbm_valid], verbose_eval = 500)","bd3d3dea":"# TODO\n\n~~1. categorize address~~\n\n~~2. if entry address is the same as exit address~~\n\n3. convert directions\n\n\n\n","decd646c":"## RandomForestRegressor","a8af7cb1":"## Intersection\n","ba81df3e":"# LGM\n","ab1b9c40":"## isLeft ","21836dd2":"## PLS regression\n","931f794e":"# Direction Diff ","ea9e0453":"## One hot encoding for City \n","ccabec95":"11522010","b9158a7a":"## drop rows with NaN\n","66d08421":"## Linear Regression\n"}}