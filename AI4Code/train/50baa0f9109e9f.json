{"cell_type":{"83207070":"code","8cc44027":"code","59368113":"code","50c6e85f":"code","885c832b":"code","da8a2a22":"code","32270138":"code","0822cde5":"code","83da39a9":"code","7a39745b":"code","3773a638":"markdown","c4571655":"markdown","d8c9e08c":"markdown","824fcc39":"markdown","a0266023":"markdown"},"source":{"83207070":"!pip install nb_black -q","8cc44027":"%load_ext nb_black","59368113":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv(\"..\/input\/spam-ham-emails\/emails.csv\")\ndata.head()","50c6e85f":"data.info()","885c832b":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n\ndef wordcloud(df, column_name, spam, title):\n    text = df.query(f\"spam == '{spam}'\")\n    # Juntando todos os textos na mesma string\n    all_words = \" \".join([text for text in text[column_name]])\n    # Gerando a nuvem de palavras\n    wordcloud = WordCloud(\n        width=800, height=500, max_font_size=110, collocations=False\n    ).generate(all_words)\n    # Plotando nuvem de palavras\n    plt.figure(figsize=(24, 12))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n\n\nwordcloud(data, \"text\", \"1\", \"Word cloud for SPAM\")","da8a2a22":"wordcloud(data, \"text\", \"0\", \"Word cloud for HAM\")","32270138":"import plotly.graph_objects as go\n\ncounts = data.spam.value_counts()\n\n\ndef counts_percent(cv):\n    aux = []\n    percent = cv \/ sum(cv)\n    for i in range(0, len(percent)):\n        aux.append(f\"{cv[i]} ({round(percent[i],2)*100} %)\")\n    return aux\n\n\nfig = go.Figure(\n    data=[\n        go.Bar(\n            x=counts.index,\n            y=counts.values,\n            text=counts_percent(counts.values),\n            textposition=\"auto\",\n        )\n    ]\n)\n\nfig.update_layout(\n    title=\"Counts classes: Spam as 1 and Ham as 0\",\n    yaxis=dict(title=\"Count value\", titlefont_size=16, tickfont_size=14,),\n    xaxis=dict(title=\"Classes\", titlefont_size=16, tickfont_size=14,),\n)\nfig.show()","0822cde5":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorize = CountVectorizer()\n\nX = vectorize.fit_transform(data.text)\nY = data.spam.values\nprint(\"How many features (bag of words): \", len(vectorize.get_feature_names()))","83da39a9":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, Y, test_size=0.33, random_state=42\n)\n\nmodel = MultinomialNB()\n\nmodel.fit(X_train, y_train)\n\n\n# Let's see the results\npredictions = model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions) * 100\nprint(\"The accuracy was %.2f%%\" % accuracy)","7a39745b":"from sklearn.metrics import confusion_matrix\n\nm_c = confusion_matrix(y_test, predictions)\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c, annot=True, cmap=\"Reds\", fmt=\"d\").set(xlabel=\"Predict\", ylabel=\"Real\")","3773a638":"# Importing ","c4571655":"# Machine learning","d8c9e08c":"## Classes, Spam vs Ham","824fcc39":"# EAD","a0266023":"## Word cloud"}}