{"cell_type":{"c4340f81":"code","8ddfc563":"code","1837aefe":"code","fd716afd":"code","2ad991ae":"code","48334268":"code","3f5fe529":"code","7cda546f":"code","7af26b8a":"code","ba0decda":"code","e9e3c08e":"code","6127b445":"code","95340297":"code","e6e212d3":"code","082efc42":"code","56977213":"code","afd82077":"code","41c14ae0":"code","e2605b44":"code","fdc5ffac":"code","00041126":"code","4c7d8645":"code","fa2061a0":"code","8ba70915":"code","d4d6c0c5":"code","7405a216":"code","e1bb1923":"code","2d54bc39":"code","23c724cb":"code","f189c445":"code","ed8e788f":"code","a1e2c93e":"code","94068fd7":"code","8cac3538":"code","107daf65":"code","8daba901":"code","c2dd9171":"code","e77f32f8":"code","ee61e08b":"code","b338506d":"markdown","ab80987f":"markdown","7765fd93":"markdown","1323648a":"markdown","09682cde":"markdown","b1d3fe1c":"markdown","7a0d516b":"markdown","af144ac0":"markdown","cc1ea490":"markdown","b6abeee0":"markdown","d4a2f0b3":"markdown","3ff9b785":"markdown","9231333e":"markdown","260c64cc":"markdown","3c2ad594":"markdown","5376a35f":"markdown","59d22917":"markdown","c0493031":"markdown","f1489538":"markdown"},"source":{"c4340f81":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import BaggingClassifier\nfrom lightgbm import LGBMClassifier\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nimport plotly.offline as py\nimport os\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \n\nsns.set()\n\ndataset = pd.read_csv('..\/input\/ks-projects-201801.csv').set_index('ID')\ndataset.head()","8ddfc563":"# Changfe state to boolean for predictions.(successful and failed)\nprint(dataset['state'].unique())\n\nstate_mapper = {\"successful\": 1} \n\nindexState = dataset[(dataset['state'] == 'live') | (dataset['state'] == 'undefined') | (dataset['state'] == 'suspended')].index\ndataset['state'].drop(indexState , inplace=True)\ndataset['state'] = dataset['state'].map(state_mapper)\ndataset['state'].fillna(0, inplace = True)\n\nprint(dataset.groupby('state').size())","1837aefe":"print(\"data nan Count:\")\nprint('Nan in data:\\n',dataset.isnull().sum())","fd716afd":"plt.figure(figsize=(9,5))\nsns.heatmap(dataset.corr(),linewidths=.5,cmap=\"YlGnBu\")\nplt.show()","2ad991ae":"# Goal\n\ndataset['goal'].apply(lambda x: np.round(x))\ndataset.groupby('goal').size().plot(title = \"Goal Distribution\",logx = True, figsize=(14,5))\nplt.show()\n\ndataset['goalQ'] = pd.qcut(dataset['goal'], 4,labels=False)\n\nquarter_mapper = {}\nfor column in dataset['goalQ']:\n    quarter_mapper[column] = \"quar_\"+str(column)\n\ndataset['goalQ'] = dataset['goalQ'].map(quarter_mapper)\n\nstate_successful = dataset[dataset['state'] == True]\nstate_failed = dataset[dataset['state'] == False]\nstate_successful.groupby('goalQ').count()['state'].plot(title = \"Goal Distribution\",marker='o', figsize=(14,5), color = 'g')\nstate_failed.groupby('goalQ').count()['state'].plot(color = 'r',marker='o')\nstate_successful.groupby('goalQ').size().plot.bar(color = 'b', alpha = 0.5)\nstate_failed.groupby('goalQ').size().plot.bar(color = 'y',alpha = 0.5)\nplt.show()\n\nprint(\"By spliting to 4 quarters \\nwe can see that when the goad is bigger the more chance to failed colocation the money\")","48334268":"# main category feature\n\nmain_category_mean = dataset.groupby('main_category').mean()['state'].sort_values(ascending = False)\nprint(main_category_mean)\nmain_category_mean.plot.bar(figsize=(14,5), title = \"Main category state mean\")\nplt.axhline(0.25,color = 'b',linestyle='--')\nplt.axhline(0.41,color = 'b',linestyle='--')\nplt.show()","3f5fe529":"bins = np.array([0.0, 0.3, 0.41, 1])\ninds = np.digitize(main_category_mean, bins)\ncategory_scores = pd.DataFrame(inds, index = main_category_mean.index)\nprint(category_scores)\ncategory_scores_dict = category_scores.to_dict()[0]\ncategory_mapper = {1 : 'low',2 : 'mid',3 : 'high'} \n\ndataset['main_category_score'] = dataset['main_category'].map(category_scores_dict)\ndataset['main_category_score'] = dataset['main_category_score'].map(category_mapper)\ndataset.groupby('main_category_score').mean()['state'].plot.bar(title = \"Main category score mean\")\nplt.show()","7cda546f":"category_groupby = dataset.groupby('category').agg([np.size,np.mean])['state']\nmean_size = category_groupby['size'].mean()\ncategory_groupby = category_groupby[category_groupby['size'] > mean_size] # drop low size\ncategory_groupby.sort_values(by = 'mean' ,ascending = False, inplace = True)\n\ncategory_groupby['round_mean'] = round(category_groupby['mean'],1)\n# high_mean_category = category_mean[category_mean['mean'] > 0.5]\n# low_mean_category = category_mean[category_mean['mean'] < 0.21]\n\ncategory_groupby['mean'].plot.bar(figsize=(14,5), title = \"category mean\")\nplt.show()\ncategory_groupby['round_mean'].plot.bar(figsize=(14,5), title = \"category round mean\")\nplt.show()\n\nbins = np.array([0.1,0.2, 0.3, 0.4, 0.5])\ninds = np.digitize(category_groupby['round_mean'], bins)\ncategory_scores = pd.DataFrame(inds, index = category_groupby['round_mean'].index)\ncategory_scores_dict = category_scores.to_dict()\ncategory_mapper = {1 : 'low',2 : 'low_mid',3 : 'mid',4 : 'mid_high',5 : 'high'} \n\n\ndataset['category_score'] = dataset['category'].map(category_scores_dict[0])\ndataset['category_score'].fillna(round(dataset['category_score'].median()), inplace = True)\ndataset['category_score'] = dataset['category_score'].map(category_mapper)\ndataset.groupby('category_score').mean()['state'].sort_values().plot.bar(title = \"sub category score mean\")\nplt.show()","7af26b8a":"# Backers\nplt.figure(figsize=(10,5))\nsns.kdeplot(state_failed['backers'],shade=True,color='Red', label='failed').set_xlim(0,20000)\nsns.kdeplot(state_successful['backers'],shade=True,color='Green', label='successful').set_xlim(0,20000)\n\nplt.title('Backers Vs State')\nplt.axvline(2000,color = 'b',linestyle='--')\nplt.show()\n\nprint(\"we can see distribution between failed (under 2000), and successful (bigger the 2000)\")","ba0decda":"# amount pledged by \"crowd\"\n\nplt.figure(figsize=(10,5))\nsns.kdeplot(state_failed['pledged'],shade=True,color='Red', label='failed').set_xlim(0.5)\nsns.kdeplot(state_successful['pledged'],shade=True,color='Green', label='successful').set_xlim(0.5)\nplt.title('pledged Vs State')\nplt.axvline(200000,color = 'b',linestyle='--')\nplt.axvline(3700000,color = 'b',linestyle='--')\nplt.show()\n\n#We can see distribution between failed (under 200000), and successful (bigger the 200000)","e9e3c08e":"# deadline\ndataset['launched_year'] = pd.DatetimeIndex(dataset['launched']).year\ndataset['launched_month'] = pd.DatetimeIndex(dataset['launched']).month\n\nplt.figure(figsize=(20,5))\ndataset.groupby(['launched_year','launched_month']).mean()['state'].plot.bar(title = \"launched year and month Vs state\")\nplt.axvline(63.5,color = 'b',linestyle='--')\nplt.axvline(83.5,color = 'b',linestyle='--')\nplt.show()\n\nprint(dataset.groupby('launched_year').size())\nprint()\nprint(\"between 7.2014 to 3.2016 there was growth of use in kickstart, but this doesn\u2019t translate in more projects getting funded.\")\nprint()\nprint(\"from - http:\/\/icopartners.com\/2016\/02\/2015-in-review\/\")\nprint(\"'The growth of total number of projects is significant though, meaning more creators are coming to Kickstarter to finance their projects, but this doesn\u2019t translate in more projects getting funded.'\")\n\n# between 7.2014 to 3.2016 there was less successful\n\ndef weak_year(year):\n    if year >= 2014 & year <= 2016:\n        if year == 2014 & year > 6:\n            return True\n        if year == 2016 & year < 3:\n            return True\n        if year == 2015:\n            return True\n    return False\n\ndataset['is_launched_weak_year'] = dataset['launched_year'].apply(weak_year)\n\ndataset['launched_day'] = pd.DatetimeIndex(dataset['launched']).day\ndataset.groupby('launched_day').mean()['state'].plot.bar(title = \"launched day Vs state\")\nplt.show()\n","6127b445":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n\ndataset['launched_hour'] = pd.DatetimeIndex(dataset['launched']).hour\ndataset['dayfloat']=dataset.launched_day+dataset.launched_hour\/24.0\ndataset['monthfloat']=dataset.launched_month+dataset.launched_day\/28.\n\ndataset['x_launched']=np.sin(2.*np.pi*dataset.monthfloat\/12.)\ndataset['y_launched']=np.cos(2.*np.pi*dataset.monthfloat\/12.)\n\nax = sns.scatterplot(x=\"x_launched\", y=\"y_launched\", hue=\"state\",style=\"state\",alpha = 0.4,palette = 'Set1_r',ax = axes[1], data=dataset)\nax.set_title(\"launched time\")\n\ndataset['deadline_hour'] = pd.DatetimeIndex(dataset['deadline']).hour\ndataset['deadline_year'] = pd.DatetimeIndex(dataset['deadline']).year\ndataset['deadline_month'] = pd.DatetimeIndex(dataset['deadline']).month\n\ndataset['dayfloat']=dataset.launched_day+dataset.launched_hour\/24.0\ndataset['monthfloat']=dataset.launched_month+dataset.launched_day\/28.\n\ndataset['x_deadline']=np.sin(2.*np.pi*dataset.monthfloat\/12.)\ndataset['y_deadline']=np.cos(2.*np.pi*dataset.monthfloat\/12.)\n\nax = sns.scatterplot(x=\"x_deadline\", y=\"y_deadline\", hue=\"state\",style=\"state\",alpha = 0.2,palette = 'Set1_r',ax = axes[0], data=dataset)\nax.set_title(\"deadline time\")\nplt.show()","95340297":"#  currncy\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(13,5))\n\ndataset.groupby(['currency']).mean()['state'].plot.bar(title = \"mean currency vs state\", ax = axes[0])\ndataset.groupby(['currency']).sum()['state'].plot.bar(title = \"count currency vs state\", ax = axes[1])\nplt.show()\n\n# it better use EasyPeasy ,but I dont what to enable internet with tbhe karnel\ndef covenrtToUSD(goal,currency):\n    switcher = {\n        'USD': goal,\n        'EUR': goal*1.13109,\n        'MXN': goal*0.05176,\n        'AUD': goal*0.70616,\n        'GBP': goal*1.32556,\n        'CAD': goal*0.75065,\n        'SEK': goal*0.10741,\n        'NOK': goal*0.11655,\n        'CHF': goal*0.99581,\n        'HKD': goal*0.12739,\n        'DKK': goal*0.00834,\n        'SGD': goal*0.73782,\n        'NZD': goal*0.68293,\n    }\n    return switcher.get(currency,goal)\n\ndataset[\"goal\"] = dataset.apply(lambda x: covenrtToUSD(x.goal, x.currency), axis=1)","e6e212d3":"dataset[\"project_time\"] = (pd.DatetimeIndex(dataset['deadline']) - pd.DatetimeIndex(dataset['launched'])).days\ndataset.plot.scatter(\"project_time\",\"state\", title= \"project_time VS state\")\nplt.axvline(6000,color = 'b',linestyle='--')\nplt.show()\n\nprint(\"We will remove the project that bigger then 6000 days (16 year)\")\nprint(\"kickstart was founded in April 28, 2009 - 10 year ago\")\nprint(\"bigger then 6000:\",len(dataset[dataset[\"project_time\"] > 6000]))\nprint(\"less then 6000:\",len(dataset[dataset[\"project_time\"] < 6000]))\n\n# drop outliar \ndataset['goal_per_day'] = dataset[\"goal\"] \/ (dataset[\"project_time\"]+0.0001)\nsns.swarmplot(x=\"state\", y=\"goal_per_day\", data=dataset.sample(300,random_state = 444))\nplt.title(\"goal per day\")\nplt.show()","082efc42":"\nfig, axes = plt.subplots(nrows=2, ncols=1)\nfig.tight_layout()\nsns.kdeplot(state_failed['usd_pledged_real'],shade=True,color='Red', label='failed', ax = axes[0])\nax = sns.kdeplot(state_successful['usd_pledged_real'],shade=True,color='Green', label='successful', ax = axes[0])\nax.set_title(\"usd pledged Vs state\")\nsns.kdeplot(state_failed['usd_goal_real'],shade=True,color='Red', label='failed', ax = axes[1])\nax = sns.kdeplot(state_successful['usd_goal_real'],shade=True,color='Green', label='successful', ax = axes[1])\nax.set_title(\"usd goal Vs state\")\n\nplt.show()\n\n\ndataset['diff_pledged_goal'] = round(np.log(dataset['usd_pledged_real']+1) - np.log(dataset['usd_goal_real']+1))\n\nplt.title('diff_pledged_goal Vs state')\n\nstate_successful = dataset[dataset['state'] == True]\nstate_failed = dataset[dataset['state'] == False]\nsns.kdeplot(state_failed['diff_pledged_goal'],shade=True,color='Red', label='failed')\nsns.kdeplot(state_successful['diff_pledged_goal'],shade=True,color='Green', label='successful')\nplt.show()","56977213":"dataset['diff_pledged_desirable_real'] = round(np.log(dataset['usd_pledged_real']+1) - np.log(dataset['usd pledged']+1))\n\nstate_successful = dataset[dataset['state'] == True]\nstate_failed = dataset[dataset['state'] == False]\n\nsns.kdeplot(state_failed['diff_pledged_desirable_real'],shade=True,color='Red', label='failed').set_xlim(-0.5,0.5)\nsns.kdeplot(state_successful['diff_pledged_desirable_real'],shade=True,color='Green', label='successful').set_xlim(-0.5,0.5)\nplt.title(\"pledged_real - usd pledged Vs state\")\nplt.show()\n\ndataset['diff_pledged_desirable_real'].fillna(dataset['diff_pledged_desirable_real'].mean(), inplace = True)","afd82077":"dataset['word_count'] = dataset['name'].str.split().apply(np.size)\nword_count_size_mean = dataset.groupby('word_count').agg([np.mean,np.size])['state']\nword_count_size_mean = word_count_size_mean[word_count_size_mean['size'] > 500]\nword_count_size_mean['mean'].plot.area(title = \"Number of word\")\nplt.show()\n\ndataset['name_len'] = dataset['name'].str.len()\ndataset.groupby('name_len').mean()['state'].plot(title = \"Name character number\")\nplt.show()\n\ndataset.dropna(subset = ['name'] ,inplace = True)","41c14ae0":"\n# help func for model_performance\n# please use:\n# y_pred = clf.predict(X_valid)\n# y_score = clf.predict_proba(X_valid)[:,1]\n# X_train, X_test, y_train, y_test = train_test_split(X, y)\ndef model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)\/(tp+tn+fp+fn))\n    Precision =  (tp\/(tp+fp))\n    Recall    =  (tp\/(tp+fn))\n    F1_score  =  (2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/((tp\/(tp+fp))+(tp\/(tp+fn)))))\n\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n\n    print(conf_matrix)\n    ax= plt.subplot()\n    sns.heatmap(conf_matrix, annot=True, ax = ax); \n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n    ax.set_title('Confusion Matrix'); \n    ax.xaxis.set_ticklabels(['successful', 'failed']); ax.yaxis.set_ticklabels(['successful', 'failed'])\n    plt.show()\n    \n    \n    y_pred_proba = y_score\n    fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n    auc = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n    plt.title(\"roc_curve\")\n    plt.legend(loc=4)\n    plt.show()\n  \n    print(classification_report(y_test,y_pred))\n    \n    print('model_roc_auc',model_roc_auc)","e2605b44":"def train_test_split_balance_min(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n    X_train['state'] = y_train\n    positiveData = X_train[X_train['state'] == True]\n    nagitiveData = X_train[X_train['state'] == False]\n    if len(positiveData) > len(nagitiveData):\n        X_train = pd.concat([nagitiveData,positiveData.sample(len(nagitiveData))])\n    else:\n        X_train = pd.concat([positiveData,nagitiveData.sample(len(positiveData))])\n    \n    y_train = X_train['state']\n    X_train = X_train.drop('state',axis = 1)\n    return X_train, X_test, y_train, y_test\n\ndef train_test_split_balance_max(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n    X_train['state'] = y_train\n    positiveData = X_train[X_train['state'] == True]\n    nagitiveData = X_train[X_train['state'] == False]\n    if len(positiveData) > len(nagitiveData):\n        X_train = pd.concat([X_train,nagitiveData.sample(len(positiveData) - len(nagitiveData))])\n    else:\n        X_train = pd.concat([X_train,positiveData.sample(len(nagitiveData) - len(positiveData))])\n    \n    y_train = X_train['state']\n    X_train = X_train.drop('state',axis = 1)\n    return X_train, X_test, y_train, y_test","fdc5ffac":"to_prdic = dataset.drop('state',axis = 1)\ny = dataset['state']\n\nprdict_feature = ['diff_pledged_goal']\nprdict_df = to_prdic[prdict_feature]\nmms = MinMaxScaler()\nmms.fit(prdict_df)\nX = pd.DataFrame(mms.transform(prdict_df))","00041126":"X_train, X_test, y_train, y_test = train_test_split(X, y)\n\nclf = DecisionTreeClassifier(max_depth = 2,class_weight = \"balanced\")\nclf.fit(X_train,y_train)\n\nclf.fit(X_train, y_train)\n\nscores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\nprint(\"Cross validated:\",scores)\nprint(\"Cross validated mean:\",scores.mean())","4c7d8645":"# Perper Transformer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.feature_extraction.text import CountVectorizer  \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.preprocessing import KBinsDiscretizer","fa2061a0":"class ItemSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, data_dict):\n        return data_dict[self.key]","8ba70915":"X = dataset.drop('state',axis = 1)\ny = dataset['state']\n\n# select features\nprdict_feature = ['goal','name','main_category_score','category_score','project_time','goal_per_day','word_count']\nX = X[prdict_feature]\n\n# split\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# name\nname_pipeline = Pipeline([('name_column', ItemSelector(key = 'name')),\n                          ('vectorizer', CountVectorizer(max_features=100))])\n\n# dummeys\none_hot_pipeline = Pipeline([('hot_columns', ItemSelector(key = ['main_category_score','category_score'])),\n                             ('oneHowEncoder', OneHotEncoder(handle_unknown='ignore',sparse=True))])\n\n# min max scaler\nmin_max_pipeline = Pipeline([('min_max_columns', ItemSelector(key = ['project_time','word_count','goal_per_day'])),\n                             ('minMaxScaler', MinMaxScaler())])\n\n# min max scaler\nk_bins_pipeline = Pipeline([('goal', ItemSelector(key = ['goal'])),\n                             ('k_bins', KBinsDiscretizer(n_bins = 4,encode = 'onehot',strategy = 'quantile'))])\n\n# FeatureUnion \nfeature_pipeline = FeatureUnion([('one_hot',one_hot_pipeline),\n                                 ('name',name_pipeline),\n                                 ('min_max',min_max_pipeline),\n                                 ('k_bins',k_bins_pipeline)])\n\n\nfeature_pipeline.fit(X_train)\n\nX_train = feature_pipeline.transform(X_train)\nX_test = feature_pipeline.transform(X_test)\n","d4d6c0c5":"%%time\nscoreTest_DT = []\nscoreTrain_DT = []\nfor number in range(1,30):\n    clf = DecisionTreeClassifier(max_depth = number, class_weight = \"balanced\")\n    clf.fit(X_train,y_train)\n    y_score_train = clf.predict_proba(X_train)[:,1]\n    y_score_test = clf.predict_proba(X_test)[:,1]\n\n    scoreTrain_DT.append(round(roc_auc_score(y_train, y_score_train) , 3))\n    scoreTest_DT.append(round(roc_auc_score(y_test, y_score_test) , 3))\n    \npd.DataFrame({'test roc score':scoreTest_DT,'train roc score':scoreTrain_DT}).plot(grid = True)\nplt.xlabel('Max depth')\nplt.ylabel('Score')\nplt.title(\"DecisionTreeClassifier\")\nplt.show()\n\nclf_DT = DecisionTreeClassifier(max_depth = np.array(scoreTest_DT).argmax(), class_weight = \"balanced\")\nclf_DT.fit(X_train,y_train)\n\nprint(\"DT roc_train:\",round(roc_auc_score(y_train, clf_DT.predict_proba(X_train)[:,1]) , 3))\nprint(\"DT roc_test:\",round(roc_auc_score(y_test, clf_DT.predict_proba(X_test)[:,1]) , 3))\n\n# DT_cross_score = cross_val_score(clf_DT, X_train, y_train, cv=5, scoring='roc_auc').mean()\nDT_roc = round(roc_auc_score(y_test, clf_DT.predict_proba(X_test)[:,1]) , 3)","7405a216":"%%time\nscoreTest_RF = []\nscoreTrain_RF = []\nfor number in range(1,30):\n    clf = RandomForestClassifier(max_depth = number,n_estimators = 100, class_weight = \"balanced\")\n    clf.fit(X_train,y_train)\n    y_score_train = clf.predict_proba(X_train)[:,1]\n    y_score_test = clf.predict_proba(X_test)[:,1]\n\n    scoreTrain_RF.append(round(roc_auc_score(y_train, y_score_train) , 3))\n    scoreTest_RF.append(round(roc_auc_score(y_test, y_score_test) , 3))\n    \npd.DataFrame({'test roc score':scoreTest_RF,'train roc score':scoreTrain_RF}).plot(grid = True)\nplt.xlabel('Max depth')\nplt.ylabel('Score')\nplt.title(\"RandomForestClassifier\")\nplt.show()\n\n\n\ncls_RF = RandomForestClassifier(max_depth = np.array(scoreTest_RF).argmax(),n_estimators = 100, class_weight = \"balanced\")\ncls_RF.fit(X_train,y_train)\n\nprint(\"RF roc_train:\",round(roc_auc_score(y_train, cls_RF.predict_proba(X_train)[:,1]) , 3))\nprint(\"RF roc_test:\",round(roc_auc_score(y_test, cls_RF.predict_proba(X_test)[:,1]) , 3))\n\n# RF_cross_score = cross_val_score(cls_RF, X_train, y_train, cv=5, scoring='roc_auc').mean()\nRF_roc = round(roc_auc_score(y_test, cls_RF.predict_proba(X_test)[:,1]) , 3)","e1bb1923":"%%time\n# scoreTest = []\n# scoreTrain = []\n# knnRange = [50,100,200,300,350]\n# for number in knnRange:\n#     clf = KNeighborsClassifier(n_neighbors = number)\n#     clf.fit(X_train,y_train)\n#     y_score_train = clf.predict_proba(X_train)[:,1]\n#     y_score_test = clf.predict_proba(X_test)[:,1]\n\n#     scoreTrain.append(round(roc_auc_score(y_train, y_score_train) , 3))\n#     scoreTest.append(round(roc_auc_score(y_test, y_score_test) , 3))\n    \n# pd.DataFrame({'test roc score':scoreTest,'train roc score':scoreTrain}).plot(grid = True)\n# plt.xlabel('Max depth')\n# plt.ylabel('Score')\n# plt.title(\"KNeighborsClassifier\")\n# plt.show()\n\n# clf_KNN = KNeighborsClassifier(n_neighbors = knnRange[np.array(scoreTest).argmax()])\nclf_KNN = KNeighborsClassifier(n_neighbors = 50)\nclf_KNN.fit(X_train,y_train)\n\nprint(\"KNN roc_train:\",round(roc_auc_score(y_train, clf_KNN.predict_proba(X_train)[:,1]) , 3))\nprint(\"KNN roc_test:\",round(roc_auc_score(y_test, clf_KNN.predict_proba(X_test)[:,1]) , 3))\n\n# KNN_cross_score = cross_val_score(clf_KNN, X_train, y_train, cv=5, scoring='roc_auc').mean()\nKNN_roc = round(roc_auc_score(y_test, clf_KNN.predict_proba(X_test)[:,1]) , 3)","2d54bc39":"%%time\nclf_NB = GaussianNB()\nclf_NB.fit(X_train.todense(),y_train)\ny_score_train = clf_NB.predict_proba(X_train.todense())[:,1]\ny_score_test = clf_NB.predict_proba(X_test.todense())[:,1]\n\nprint(\"NB roc_train:\",round(roc_auc_score(y_train, y_score_train) , 3))\nprint(\"NB roc_test:\",round(roc_auc_score(y_test, y_score_test) , 3))\n\n# NB_cross_score = cross_val_score(clf_NB, X_train.todense(), y_train, cv=5, scoring='roc_auc').mean()\nNB_roc = round(roc_auc_score(y_test, y_score_test) , 3)","23c724cb":"%%time\n\nscoreTest_LR = []\nscoreTrain_LR = []\nC_range = [1,2,3,4,5,6,7,8]\nfor number in C_range:\n    clf = LogisticRegression(C = number, class_weight = \"balanced\", penalty = 'l2')\n    clf.fit(X_train,y_train)\n    y_score_train = clf.predict_proba(X_train)[:,1]\n    y_score_test = clf.predict_proba(X_test)[:,1]\n    scoreTrain_LR.append(round(roc_auc_score(y_train, y_score_train) , 3))\n    scoreTest_LR.append(round(roc_auc_score(y_test, y_score_test) , 3))\n     \npd.DataFrame({'test roc score':scoreTest_LR,'train roc score':scoreTrain_LR}).plot(grid = True)\nplt.xlabel('C')\nplt.ylabel('Score')\nplt.title(\"LogisticRegression\")\nplt.show()\n\nprint(\"LR roc_train:\",round(roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]) , 3))\nprint(\"LR roc_test:\",round(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]) , 3))\n\nclf_LR = LogisticRegression(C = C_range[np.array(scoreTest_LR).argmax()], class_weight = \"balanced\")\nclf_LR.fit(X_train,y_train)\n\n# LR_cross_score = cross_val_score(clf_LR, X_train, y_train, cv=5, scoring='roc_auc').mean()\nLR_roc = round(roc_auc_score(y_test, clf_LR.predict_proba(X_test)[:,1]) , 3)","f189c445":"%%time\nfrom sklearn.neural_network import MLPClassifier\n\nclf_MLP = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=100,tol=0.0001, alpha=0.0001,\n                     solver='sgd', verbose= False)\nclf_MLP.fit(X_train, y_train)\n\nprint(\"MLP roc_train:\",round(roc_auc_score(y_train, clf_MLP.predict_proba(X_train)[:,1]) , 3))\nprint(\"MLP roc_test:\",round(roc_auc_score(y_test, clf_MLP.predict_proba(X_test)[:,1]) , 3))\n\n# MLP_cross_score = cross_val_score(clf_MLP, X_train, y_train, cv=5, scoring='roc_auc').mean()\nMLP_roc = round(roc_auc_score(y_test, clf_MLP.predict_proba(X_test)[:,1]) , 3)","ed8e788f":"%%time\nscoreTrain_LGBMC = []\nscoreTest_LGBMC = []\nn_estimators = [100,400,800,1000]\nfor number in n_estimators:\n    clf = LGBMClassifier(\n        n_estimators= number,\n        num_leaves=15,\n        colsample_bytree=.8,\n        subsample=.8,\n        max_depth=7,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n    )\n    clf.fit(X_train,y_train)\n    y_score_train = clf.predict_proba(X_train)[:,1]\n    y_score_test = clf.predict_proba(X_test)[:,1]\n    scoreTrain_LGBMC.append(round(roc_auc_score(y_train, y_score_train) , 3))\n    scoreTest_LGBMC.append(round(roc_auc_score(y_test, y_score_test) , 3))\n     \npd.DataFrame({'test roc score':scoreTest_LGBMC,'train roc score':scoreTrain_LGBMC}).plot(grid = True)\nplt.xlabel('n_estimators')\nplt.ylabel('Score')\nplt.title(\"LGBMClassifier\")\nplt.show()\n\n\nclf_lgbm = LGBMClassifier(\n        n_estimators= n_estimators[np.array(scoreTest_LGBMC).argmax()],\n        num_leaves=15,\n        colsample_bytree=.8,\n        subsample=.8,\n        max_depth=7,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n    )\nclf_lgbm.fit(X_train, y_train)\n\nprint(\"LGBM roc_train:\",round(roc_auc_score(y_train, clf_lgbm.predict_proba(X_train)[:,1]) , 3))\nprint(\"LGBM roc_test:\",round(roc_auc_score(y_test, clf_lgbm.predict_proba(X_test)[:,1]) , 3))\n\nLGBM_roc = round(roc_auc_score(y_test, clf_lgbm.predict_proba(X_test)[:,1]) , 3)","a1e2c93e":"%%time\nclf_MLP_vot = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=100,tol=0.0001, alpha=0.0001,\n                     solver='sgd', verbose= False)\nclf_LR_vot = LogisticRegression(C = C_range[np.array(scoreTest_LR).argmax()], class_weight = \"balanced\")\nclf_DT_vot = DecisionTreeClassifier(max_depth = np.array(scoreTest_DT).argmax(), class_weight = \"balanced\")\nclf_lgbm_vot = LGBMClassifier(\n        n_estimators= n_estimators[np.array(scoreTest_LGBMC).argmax()],\n        num_leaves=15,\n        colsample_bytree=.8,\n        subsample=.8,\n        max_depth=7,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n    )\n\nclf_vot = VotingClassifier(estimators=[('MLP', clf_MLP_vot), ('RL', clf_LR_vot),('LGBM',clf_lgbm_vot)],voting='soft', weights=[1,1,2])\nclf_vot.fit(X_train, y_train)\n\nprint(\"voting roc_train:\",round(roc_auc_score(y_train, clf_vot.predict_proba(X_train)[:,1]) , 3))\nprint(\"voting roc_test:\",round(roc_auc_score(y_test, clf_vot.predict_proba(X_test)[:,1]) , 3))\n\nVOT_roc = round(roc_auc_score(y_test, clf_vot.predict_proba(X_test)[:,1]) , 3)","94068fd7":"%%time\nclf_bag = LogisticRegression(C = C_range[np.array(scoreTest_LR).argmax()], class_weight = \"balanced\")\nclf_LR_Bag = BaggingClassifier(base_estimator = clf_bag,n_estimators = 10)\nclf_LR_Bag.fit(X_train, y_train)\n\nprint(\"Bagging roc_train:\",round(roc_auc_score(y_train, clf_LR_Bag.predict_proba(X_train)[:,1]) , 3))\nprint(\"Bagging roc_test:\",round(roc_auc_score(y_test, clf_LR_Bag.predict_proba(X_test)[:,1]) , 3))\n\nLR_BAG_roc = round(roc_auc_score(y_test, clf_LR_Bag.predict_proba(X_test)[:,1]) , 3)","8cac3538":"\nindexs = [\"DecisionTreeClassifier\",\"RandomForestClassifier\",\"KNeighborsClassifier\",\"GaussianNB\",\"LogisticRegression\",\"MLPClassifier\",\"VotingClassifier\",\"BaggingClassifierLR\",\"LGBMClassifier\"]\nmodels = pd.DataFrame([], index = indexs)\nmodels[\"Roc\"] = [DT_roc,RF_roc, KNN_roc,NB_roc,LR_roc,MLP_roc,VOT_roc,LR_BAG_roc,LGBM_roc]\nmodels.plot.barh(figsize=(10,10 ), xlim = (0.6,0.8),colormap='YlOrRd_r')\nplt.axvline(models[\"Roc\"].max(),color = 'g',linestyle='--')\nplt.show()\n\nmodels","107daf65":"y_pred = clf_lgbm.predict(X_test)\ny_score = clf_lgbm.predict_proba(X_test)[:,1]\n\nscores = cross_val_score(clf_lgbm, X_train, y_train, cv=5, scoring='roc_auc')\nprint(\"Cross validated:\",scores)\nprint(\"Cross validated mean:\",scores.mean())\nprint()\nmodel_performance('clf_lgbm')","8daba901":"clf_lgbm","c2dd9171":"print(\"successful count:\",len(y_train[y_train == True]))\nprint(\"failed count:\",len(y_train[y_train == False]))","e77f32f8":"X_train, X_test, y_train, y_test = train_test_split_balance_min(X, y)\nfeature_pipeline.fit(X_train)\nX_train = feature_pipeline.transform(X_train)\nX_test = feature_pipeline.transform(X_test)\n\nclf_lgbm.fit(X_train, y_train)\nprint(classification_report(y_test,clf_lgbm.predict(X_test)))\nprint(\"roc:\",round(roc_auc_score(y_test, clf_lgbm.predict_proba(X_test)[:,1]) , 3))","ee61e08b":"X_train, X_test, y_train, y_test = train_test_split_balance_max(X, y)\nfeature_pipeline.fit(X_train)\nX_train = feature_pipeline.transform(X_train)\nX_test = feature_pipeline.transform(X_test)\n\nclf_lgbm.fit(X_train, y_train)\nprint(classification_report(y_test,clf_lgbm.predict(X_test)))\nprint(\"roc:\",round(roc_auc_score(y_test, clf_lgbm.predict_proba(X_test)[:,1]) , 3))","b338506d":"Launched date feature","ab80987f":"Backers feature ","7765fd93":"Sub category feature","1323648a":"# Modle #2 (With ONLY start project data)\ndata that we have if we start now project in kickstarter","09682cde":"Pledged feature - The amount pledged by \"crowd\"","b1d3fe1c":"usd pledged and usd_pledged_real feature","7a0d516b":"# Model Selecting","af144ac0":"Model with only diff_pledged_desirable_real feature","cc1ea490":"Main category feature","b6abeee0":"Goal feature -  The goal amount in project currency","d4a2f0b3":"## Balance the data \n\n- Set 'failed'  and 'successful to the same count by reduce successful\n- Set 'failed'  and 'successful to the same count by duplicated failed","3ff9b785":"# data leakage!!\n\n### Beacuse all are data if final project data (successful or failed), The diff_pledged_goal feature is just the \"state\" feature that we what to prdict.\n\nAlso for: \n- The diff_pledged_goal \n- pledged\n- backers\n- usd pledged\n- usd_pledged_real\n- usd_goal_real\n\n## We will use only data . that we have when the project is start","9231333e":"launched time and deadline","260c64cc":"Currency","3c2ad594":"![](https:\/\/assets.entrepreneur.com\/content\/3x2\/2000\/10-questions-ask-creating-kickstarter-project.jpg?width=700&crop=2:1)","5376a35f":"Splite the category to groups by mean","59d22917":"\n\"\"usd_pledged_real and usd_goal_real feature - Pledged amount in USD, Goal amount in USD","c0493031":"Nan in the data","f1489538":"Change state to boolean - successful anf failed"}}