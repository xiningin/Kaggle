{"cell_type":{"0c075a17":"code","3fe7885c":"code","fea244d6":"code","2bc6d263":"code","6b37de53":"code","e9c5d3ce":"code","8249e37f":"code","e7240eff":"code","e48ed4c3":"code","42a5708b":"code","931121ed":"code","98291856":"code","f6d3da83":"code","4110c262":"code","76518026":"code","aa3d1f90":"code","08fc5ee5":"code","f9615da2":"code","a9e503fe":"code","49cac021":"code","6274cef5":"code","f21651e5":"code","5b70b939":"code","112e234c":"code","06a281bb":"markdown","0f524f75":"markdown","05927696":"markdown","bfd98474":"markdown","7eca1888":"markdown","e8874ca2":"markdown","de813441":"markdown"},"source":{"0c075a17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader,  ConcatDataset\nimport torch\nimport torch.nn.functional as F\n\nfrom collections import OrderedDict\n\nfrom sklearn.metrics import confusion_matrix","3fe7885c":"data = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")\nlabels_values = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\nprint(data.shape)\ndata.columns","fea244d6":"X = np.asarray(data.drop(\"label\", axis=1), dtype=np.float32).reshape(-1, 28, 28, 1) #(n, height, width, channels)->This because we are going to use ToTensor in the transformation step.\ny = np.asarray(data[\"label\"], dtype=np.int8)\nX.dtype","2bc6d263":"gs = GridSpec(2, 5)\n\nfor row in range(0, 2):\n    for col in range(0, 5):\n        ind = np.where(y == (row*5 + col))[0][0]\n        axis = plt.subplot(gs[row, col])\n        axis.imshow(X[ind, :, :, 0], cmap=\"gray\")\n        axis.set_xticks([])\n        axis.set_yticks([])\n        axis.set_xlabel(labels_values[row*5 + col])\nplt.show()","6b37de53":"# Splitting into traning and validations set\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nX_train, y_train = (None, None)\nX_valid, y_valid = (None, None)\nfor train_ind, valid_ind in splitter.split(X, y):\n    X_train, y_train = X[train_ind], y[train_ind]\n    X_valid, y_valid = X[valid_ind], y[valid_ind]","e9c5d3ce":"class Transformation(Dataset):\n    \n    def __init__(self, center, X, y, *args, **kwargs):\n        self.images = X\n        self.labels = y\n        self.totensor = torchvision.transforms.ToTensor()#nxchannelxheightxwidth\n        self.affine = torchvision.transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(1, 1.5))\n        self.rotate = torchvision.transforms.RandomRotation((0, 45), center=center)\n        \n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        label = self.labels[idx]\n        img = self.images[idx]\n        \n        img = img * 1.0\/255\n        img = self.totensor(img)\n        img = self.affine(img)\n        img = self.rotate(img)\n        return img, label\n\nclass SimpleToTensor(Dataset):\n    \n    def __init__(self, X, y):\n        self.images = X\n        self.labels = y\n        self.transform = torchvision.transforms.ToTensor()\n    \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\/255.0\n        img = self.transform(img)\n        return img, self.labels[idx]","8249e37f":"transformed_set = Transformation(center=X[0, 0, :, :].shape, X=X_train, y=y_train)\nloader = DataLoader(ConcatDataset([transformed_set, SimpleToTensor(X_train, y_train)]), batch_size=2048, shuffle=True)\n\nloader_validation = DataLoader(SimpleToTensor(X_valid, y_valid), batch_size=4096)","e7240eff":"len(SimpleToTensor(X_valid, y_valid))","e48ed4c3":"gs = GridSpec(2, 2)\nlab = 1\nind = np.where(y_train == lab)[0][0:4]\ncounter = 0\nfor row in range(0, 2):\n    axis = plt.subplot(gs[row, 0])\n    axis.imshow(X_train[ind[counter], :, :, 0], cmap=\"gray\")\n    axis.set_xticks([])\n    axis.set_yticks([])\n    axis.set_xlabel(labels_values[lab])\n    #transformed image\n    x, _ = transformed_set.__getitem__(ind[counter])\n    axis = plt.subplot(gs[row, 1])\n    axis.imshow(x[0], cmap=\"gray\")\n    axis.set_xticks([])\n    axis.set_yticks([])\n    axis.set_xlabel(labels_values[lab])\n    counter += 1\nplt.show()","42a5708b":"# See https:\/\/arxiv.org\/pdf\/1606.08415.pdf\n\nclass GeluActivation(torch.autograd.Function):\n    \n    @staticmethod\n    def forward(ctx, x):\n        #save information in the node that is used by backward step \n        ctx.save_for_backward(x)\n        \n        #copy values in order not to change the original values in order to do gradient between previous and current values of the parameter\n        output = x.clone()\n        output = x * torch.sigmoid(1.702 * x)\n        return output\n    \n    @staticmethod\n    def backward(ctx, grad_backward):\n        \n        x,  = ctx.saved_tensors\n        grad_input = None\n        #Check if required_grad is set to zero\n        if ctx.needs_input_grad[0]:\n            grad_input = grad_backward.clone()\n            \n            grad_input *= ((torch.sigmoid(1.702 * x) + x * 1.702 * torch.exp(-1.702 * x))\/ \n                          torch.pow(1 + torch.exp(-1.702*x), 2))\n        return grad_input","931121ed":"block = torch.nn.Sequential(OrderedDict([\n    (\"cnn\", torch.nn.Conv2d(64, 64, (3, 3))), \n    (\"gelu\", torch.nn.ReLU()),\n    #(\"subsampling\", torch.nn.MaxPool2d((2, 2), 2)), \n    (\"dropout\", torch.nn.Dropout2d(0.25))\n]))\n                            \nclass GeluModel(torch.nn.Module):\n\n    def __init__(self, *args, **kwargs):\n        super(GeluModel, self).__init__()\n        self.cnn1 = torch.nn.Conv2d(1, 32, (7, 7), 1)\n        self.pool = torch.nn.MaxPool2d((2, 2), 2)\n        #self.block1 = block\n        #self.block2 = block\n        #self.block3 = block\n        #self.cnn2 = torch.nn.Conv2d(64, 32, (5, 5), 1)\n        \n        #self.cnn3 = torch.nn.Conv2d(128, 128, (3, 3), 1)\n        #self.cnn4 = torch.nn.Conv2d(128, 32, (3, 3), 1)\n        #self.dropout2 = torch.nn.Dropout2d(0.2)\n        \n        #don't create object because we are using only the static methods\n        self.activation = GeluActivation.apply\n        \n        self.fc1 = torch.nn.Linear(5408, 32)\n        self.fc2 = torch.nn.Linear(32, 64)\n        self.fc3 = torch.nn.Linear(64, 64)\n        self.fc4 = torch.nn.Linear(64, 10)\n\n    \n    def forward(self, x):\n        #image 28x28\n        x = F.pad(x, (2, 2, 2,2))\n        #32x32\n        x = self.activation(self.cnn1(x))#32x26x26\n        x = self.pool(x)#32x13x13\n        \n        #x = self.block1(x)#32x12x12\n        #x = self.block2(x)#64x14x14\n        #x = torch.nn.LeakyReLU()(self.cnn2(x))#32x8x8\n        #x = self.pool(x)#32x4x4\n        #x = torch.nn.LeakyReLU()(self.cnn3(x))#128x4x4\n        #x = torch.nn.LeakyReLU()(self.cnn4(x))#32x2x2\n        \n        x = x.view(-1, 5408)#flatten\n        #x = torch.nn.BatchNorm1d(128)(x)\n        x = self.fc1(x)\n        x = torch.nn.BatchNorm1d(32)(x)\n        x = torch.nn.ReLU()(x)\n        x = torch.nn.Dropout(0.2)(x)\n        x = self.fc2(x)\n        x = torch.nn.BatchNorm1d(64)(x)\n        x = torch.nn.ReLU()(x)\n        x = torch.nn.Dropout(0.2)(x)\n        x = self.fc3(x)\n        x = torch.nn.BatchNorm1d(64)(x)\n        x = torch.tanh(x)\n        x = torch.nn.Dropout(0.2)(x)\n        x = self.fc4(x)\n        #x = torch.nn.Dropout(0.4)(x)\n        \n        return F.softmax(x, dim=1)\n    \nclass LeNet5(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(LeNet5, self).__init__()\n        self.cnn1 = torch.nn.Conv2d(1, 6, (5, 5), 1)\n        self.pool = torch.nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        self.cnn2 = torch.nn.Conv2d(6, 16, (5, 5), 1)\n        self.cnn3 = torch.nn.Conv2d(16, 120, (5, 5), 1)\n        self.fc1 = torch.nn.Linear(120, 84)\n        self.fc2 = torch.nn.Linear(84, 10)\n        \n    def forward(self, x):\n        #Pad the image because in the original paper the first CNN had same padding\n        x = F.pad(x, (2, 2, 2, 2))#pad it from all sides\n        x = torch.tanh(self.cnn1(x))\n        x = self.pool(x)\n        x = torch.tanh(self.cnn2(x))\n        x = self.pool(x)\n        x = torch.tanh(self.cnn3(x))\n        # flatten the layer\n        x = x.view(-1, 120)#nx120\n        x = torch.tanh(self.fc1(x))\n        x = F.softmax(self.fc2(x), dim=1)#Apply softmax to the rows of the column vector.\n        \n        return x","98291856":"def init_param(param):\n    \n    if type(param) == torch.nn.Linear:\n        torch.nn.init.xavier_normal_(param.weight)\n    if type(param) == torch.nn.Conv2d:\n        torch.nn.init.xavier_uniform_(param.weight)\n#model = LeNet5()\nmodel = GeluModel()\nmodel.apply(init_param)\nprint(model)","f6d3da83":"#number of parameters \nsum(p.numel() for p in model.parameters())","4110c262":"loss_fn = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=3e-4)\ntraining_loss = []\nvalidation_loss = []","76518026":"import time\n\ntotal_time = 0\n\nfor epoch in range(0, 20):\n    losses = []\n    counter = 0\n    begin = time.time()\n    for images, labels in loader:\n        optim.zero_grad()\n        pred = model(images)\n        loss = loss_fn(pred, labels.type(torch.LongTensor))\n        loss.backward()\n        optim.step()\n        losses.append(loss.item())\n        #print(f\"loss at {epoch} iter {counter} is {loss.item()}\")\n        counter += 1\n    training_loss.append(np.mean(losses))\n    #For validation \n    valid_loss = []\n    for images, labels in loader_validation:\n        pred = model(images)\n        loss = loss_fn(pred, labels.type(torch.LongTensor))\n        valid_loss.append(loss.item())\n        optim.zero_grad()\n    validation_loss.append(np.mean(valid_loss))\n    print(f\"#epoch: {epoch} and the -log training error is {training_loss[epoch]}\")    \n    print(f\"#epoch: {epoch} and the -log validation error is {validation_loss[epoch]}\")\n    print(f\"Time taken to finish training the model is {time.time() - begin} sec\")\n    if len(validation_loss) > 2:\n        if abs(validation_loss[-1] - validation_loss[-2]) < 0.002:\n            break\n    total_time += time.time() - begin\n\nprint(f\"Total time in minutes {(int)(total_time\/60)}\")","aa3d1f90":"# Training vs Validation error\n#Validation error is low becuase the validation set doesn't have any augemented data\nplt.plot(training_loss, c=\"green\")\nplt.plot(validation_loss, c=\"red\")\nplt.legend([\"Training_error\", \"Validation_error\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"-log-likelihood\")\nplt.show()","08fc5ee5":"#Training confusion matrix \ny_pred_res = []\ny = []\nfor images, labels in loader:\n    y_pred = model(images)\n    y_p = torch.argmax(y_pred, dim=1)\n    y_pred_res.extend(y_p)\n    y.extend(labels)\ncnf = confusion_matrix(y, y_pred_res)\n#plt.matshow(cnf)\n#plt.colorbar()\nprint(f\"Accuracy {np.sum(np.diag(cnf))\/np.sum(cnf)}\")\ncnf","f9615da2":"del X_train\ndel y_train\ndel cnf\ndel y_pred","a9e503fe":"#Validation confusion matrix\nX_tensor = torch.reshape(torch.from_numpy(X_valid\/255.0), (len(X_valid), 1, 28, 28))\n\ny_pred = model(X_tensor)\ny_p = torch.argmax(y_pred, dim=1)\ncnf = confusion_matrix(y_valid, y_p)\nprint(f\"Accuracy {np.sum(np.diag(cnf))\/np.sum(cnf)}\")\ncnf","49cac021":"del X_tensor\ndel cnf\ndel y_pred\ndel X_valid\ndel y_valid","6274cef5":"del loader\ndel loader_validation","f21651e5":"data = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\")\nX = torch.from_numpy(np.asarray(data.drop(\"label\", axis=1), dtype=np.float32).reshape(-1, 1, 28, 28)\/255.0)#(n, height, width, channels)->This because we are going to use ToTensor in the transformation step.\ny = torch.from_numpy(np.asarray(data[\"label\"], dtype=np.int8))","5b70b939":"#Validation confusion matrix \ny_pred = model(X)\ny_p = torch.argmax(y_pred, dim=1)\ncnf = confusion_matrix(y, y_p)\nprint(f\"Accuracy {np.sum(np.diag(cnf))\/np.sum(cnf)}\")\ncnf","112e234c":"del X\ndel cnf\ndel y_pred","06a281bb":"A small note the reasone I didn't get a high accuracy is that because I am using a customize activation function and the architecture tha I am using isn't usually used. I am just trying to get used to torch syntax.","0f524f75":"## Visualizing the augmentation of the data","05927696":"# Initialize paramters","bfd98474":"# Building the model with custom activation function","7eca1888":"# Training Model","e8874ca2":"# Test Set prediciton","de813441":"# Loading and Transforming the Data with Random Augmentation"}}