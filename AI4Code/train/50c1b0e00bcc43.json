{"cell_type":{"96b557c7":"code","b9b7f246":"code","918f9330":"code","07faea64":"code","6f70daf6":"code","fe7c086c":"code","49b9f84b":"code","1ae85893":"code","49c9c53e":"code","36bc7ca5":"code","6c11ae7f":"code","3009d8c3":"code","e3a82629":"code","b3cad96b":"code","161cd0c0":"code","1dce45a6":"code","5960d8bf":"code","f42c0571":"code","ef59da21":"code","fa71c80c":"code","9cff1988":"code","2b7f73df":"code","7578ec08":"code","f8dd4a28":"code","95601524":"code","a04a0678":"code","e154d282":"code","d57fec3b":"code","31b46c04":"code","e0cf1c97":"markdown","52af64e3":"markdown","690c081f":"markdown"},"source":{"96b557c7":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nfrom matplotlib import pyplot as plt\nfrom matplotlib import rcParams as rcP","b9b7f246":"df = pd.read_csv('..\/input\/pune-house-data\/Pune house data.csv')\ndf.head()","918f9330":"# Exploring the dataset\ndf.shape","07faea64":"# Exploring the dataset\ndf.groupby('area_type')['area_type'].agg('count')","6f70daf6":"# Exploring the dataset\ndf.groupby('availability')['availability'].agg('count')","fe7c086c":"# Exploring the dataset\ndf.groupby('size')['size'].agg('count')","49b9f84b":"# Exploring the dataset\ndf.groupby('site_location')['site_location'].agg('count')","1ae85893":"# Removing the columns of society\ndf = df.drop('society', axis='columns')\ndf.head()","49c9c53e":"# Data Cleaning\n# Checking the null values in the dataset\ndf.isnull().sum()","36bc7ca5":"# Applying median to the balcony and bath column\nfrom math import floor\n\nbalcony_median = float(floor(df.balcony.median()))\nbath_median = float(floor(df.bath.median()))\n\ndf.balcony = df.balcony.fillna(balcony_median)\ndf.bath = df.bath.fillna(bath_median)\n\n# Checking the null values in the dataset again\ndf.isnull().sum()","6c11ae7f":"# Dropping the rows with null values because the dataset is huge as compared to null values.\ndf = df.dropna()\ndf.isnull().sum()","3009d8c3":"# Converting the size column to bhk\ndf['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\ndf = df.drop('size', axis='columns')\ndf.groupby('bhk')['bhk'].agg('count')","e3a82629":"\n# Since the total_sqft contains range values such as 1133-1384, lets filter out these values\ndef isFloat(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True\n\n# Displaying all the rows that are not integers\ndf[~df['total_sqft'].apply(isFloat)]","b3cad96b":"# Converting the range values to integer values and removing other types of error\ndef convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return (float(tokens[0])+float(tokens[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None\n    \ndf['new_total_sqft'] = df.total_sqft.apply(convert_sqft_to_num)\ndf = df.drop('total_sqft', axis='columns')\ndf.head()","161cd0c0":"# Removing the rows in new_total_sqft column that hase None values\ndf.isna().sum()","1dce45a6":"df = df.dropna()\ndf.isnull().sum()","5960d8bf":"# Adding a new column of price_per_sqft\ndf1 = df.copy()\n\n# In our dataset the price column is in Lakhs\ndf1['price_per_sqft'] = (df1['price']*100000)\/df1['new_total_sqft']\ndf1.head()","f42c0571":"# Checking unique values of 'location' column\nlocations = list(df['site_location'].unique())\nprint(len(locations))","ef59da21":"# Removing the extra spaces at the end\ndf1.site_location = df1.site_location.apply(lambda x: x.strip())\n\n# Calulating all the unqiue values in 'site_location' column\nlocation_stats = df1.groupby('site_location')['site_location'].agg('count').sort_values(ascending=False)\nlocation_stats","fa71c80c":"\n# Checking locations with less than 10 values\nprint(len(location_stats[location_stats<=10]), len(df1.site_location.unique()))","9cff1988":"# Labelling the locations with less than or equal to 10 occurences to 'other'\nlocations_less_than_10 = location_stats[location_stats<=10]\n\ndf1.site_location = df1.site_location.apply(lambda x: 'other' if x in locations_less_than_10 else x)\nlen(df1.site_location.unique())","2b7f73df":"\n# Checking the unique values in 'availability column'\ndf1.groupby('availability')['availability'].agg('count').sort_values(ascending=False)","7578ec08":"# Labelling the dates into Not Ready\ndates = df1.groupby('availability')['availability'].agg('count').sort_values(ascending=False)\n\ndates_not_ready = dates[dates<10000]\ndf1.availability = df1.availability.apply(lambda x: 'Not Ready' if x in dates_not_ready else x)\n\nlen(df1.availability.unique())","f8dd4a28":"# Checking the unique values in 'area_type' column\ndf1.groupby('area_type')['area_type'].agg('count').sort_values(ascending=False)\n\n# Since the column has only few unique values, we don't perform any operation","95601524":"df2= df1.copy()\ndf2= df2.drop('price_per_sqft', axis='columns')","a04a0678":"# Converting the categorical_value into numerical_values using get_dummies method\ndummy_cols = pd.get_dummies(df2.site_location)\ndf2 = pd.concat([df2,dummy_cols], axis='columns')","e154d282":"# Converting the categorical_value into numerical_values using get_dummies method\ndummy_cols = pd.get_dummies(df2.availability).drop('Not Ready', axis='columns')\ndf2 = pd.concat([df2,dummy_cols], axis='columns')","d57fec3b":"# Converting the categorical_value into numerical_values using get_dummies method\ndummy_cols = pd.get_dummies(df2.area_type).drop('Super built-up  Area', axis='columns')\ndf2 = pd.concat([df2,dummy_cols], axis='columns')","31b46c04":"\ndf2.drop(['area_type','availability','site_location'], axis='columns', inplace=True)\ndf2.head(10)","e0cf1c97":"# will release second notebook building function using all algorithms upvote it if you like it","52af64e3":"**Feature Engineering**","690c081f":"** Data Cleaning Process**"}}