{"cell_type":{"014c0284":"code","7b779e88":"code","5371dc80":"code","c9f8ce21":"code","df849637":"code","88d0cb23":"code","727da995":"code","031b2326":"code","b8a89a6a":"code","217cc5d0":"code","a3a9973c":"code","bced7545":"code","9f6df475":"markdown","fd1c5236":"markdown","2291f183":"markdown","4385d168":"markdown"},"source":{"014c0284":"import random\nimport copy\nimport time\nimport pandas as pd\nimport numpy as np\nimport gc\nimport re\nimport torch\nfrom torchtext import data\n#import spacy\nfrom tqdm import tqdm_notebook, tnrange\nfrom tqdm.auto import tqdm\n\ntqdm.pandas(desc='Progress')\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom nltk import word_tokenize\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.autograd import Variable\nfrom torchtext.data import Example\nfrom sklearn.metrics import f1_score\nimport torchtext\nimport os \n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# cross validation and metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom torch.optim.optimizer import Optimizer\nfrom unidecode import unidecode\n\nfrom sklearn.preprocessing import StandardScaler\nfrom textblob import TextBlob\nfrom multiprocessing import  Pool\nfrom functools import partial\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport torch as t\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom fastai.text import * ","7b779e88":"n_epochs = 5 # how many times to iterate over all samples\nn_splits = 5 # Number of K-fold Splits\nSEED = 10\ndebug = 0","5371dc80":"def load_and_prec():\n    if debug:\n        train_df = pd.read_csv(\"..\/input\/train.csv\")[:200]\n        test_df = pd.read_csv(\"..\/input\/test.csv\")[:200]\n    else:\n        train_df = pd.read_csv(\"..\/input\/train.csv\")\n        test_df = pd.read_csv(\"..\/input\/test.csv\")\n    print(\"Train shape : \",train_df.shape)\n    print(\"Test shape : \",test_df.shape)\n\n    return train_df,test_df","c9f8ce21":"start = time.time()\ntrain_df,test_df = load_and_prec() \nprint(time.time()-start)","df849637":"# Language model data : We use test_df as validation for language model\ndata_lm = TextLMDataBunch.from_df(path = \"\",train_df= train_df ,valid_df = test_df)","88d0cb23":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\nlearn.fit_one_cycle(1, 1e-2)","727da995":"learn.unfreeze()\nlearn.fit_one_cycle(1, 1e-3)","031b2326":"# check how the language model performs\nlearn.predict(\"What should\", n_words=10)","b8a89a6a":"# save the language model\nlearn.save_encoder('ft_enc')","217cc5d0":"def ulmfit_model_run_cv(train_df,test_df,target):\n    # matrix for the out-of-fold predictions\n    train_preds = np.zeros((len(train_df)))\n    # matrix for the predictions on the test set\n    test_preds = np.zeros((len(test_df)))\n    splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(train_df,target))\n    for i, (train_idx, valid_idx) in enumerate(splits):\n        print(\"Running Fold:\"+str(i+1))\n        train = train_df.iloc[train_idx]\n        valid = train_df.iloc[valid_idx]\n        # Creating Classification Data\n        print(\"Creating Classification Data\")\n        data_clas = TextClasDataBunch.from_df(path =\"\", train_df=train, valid_df =valid,  test_df=test_df, vocab=data_lm.train_ds.vocab, bs=32,label_cols = 'target')\n        \n        print(\"Creating Classifier Object\")\n        learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n        learn.load_encoder('ft_enc')\n        print(\"Fitting Classifier Object\")\n        learn.fit_one_cycle(1, 1e-2)\n        print(\"Fitting Classifier Object after freezing all but last 2 layers\")\n        learn.freeze_to(-2)\n        learn.fit_one_cycle(1, slice(5e-3\/2., 5e-3))\n        print(\"Fitting Classifier Object - discriminative learning\")\n        learn.unfreeze()\n        learn.fit_one_cycle(1, slice(2e-3\/100, 2e-3))\n        \n        valid_preds_fold = np.array(learn.get_preds(DatasetType.Valid, ordered=True)[0])[:,1]\n        test_preds_fold = np.array(learn.get_preds(DatasetType.Test, ordered=True)[0])[:,1]\n        train_preds[valid_idx] = valid_preds_fold\n        test_preds += test_preds_fold \/ len(splits)\n        \n    return train_preds, test_preds","a3a9973c":"train_oof_preds, test_preds = ulmfit_model_run_cv(train_df,test_df,train_df.target)","bced7545":"def bestThresshold(y_train,train_preds):\n    tmp = [0,0,0] # idx, cur, max\n    delta = 0\n    for tmp[0] in tqdm(np.arange(0.1, 0.501, 0.01)):\n        tmp[1] = f1_score(y_train, np.array(train_preds)>tmp[0])\n        if tmp[1] > tmp[2]:\n            delta = tmp[0]\n            tmp[2] = tmp[1]\n    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(delta, tmp[2]))\n    return delta , tmp[2]\n\ndelta, _ = bestThresshold(train_df.target,train_oof_preds)","9f6df475":"### Basic Parameters","fd1c5236":"# Load data for use in FastAI\n\n## 1. Load Language model data, and Finetune Language model","2291f183":"\n## 2. Load Classifier data, and learn classifier weights","4385d168":"## IMPORTS "}}