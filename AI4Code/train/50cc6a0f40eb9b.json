{"cell_type":{"49377954":"code","da448ca6":"code","eb4b58b4":"code","a2622655":"code","a4b19834":"code","fc504599":"code","079a7b22":"code","7deb3ec4":"code","4c43dc70":"code","fadd59ad":"code","ba6f72f6":"code","9ccd53a9":"code","62068f23":"code","607e7edf":"code","b9803798":"code","0d28b1af":"code","f577811e":"code","7d90e043":"code","0e3bf561":"code","34cc9c69":"code","bc48bd3e":"code","617a1f6e":"code","6fc03bad":"code","644bf891":"markdown","1d520959":"markdown","541fd129":"markdown"},"source":{"49377954":"# import Tools\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom joblib import dump, load\nfrom scipy.sparse import save_npz, load_npz\nfrom sklearn.linear_model import SGDClassifier, LinearRegression, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import csc_matrix\nfrom scipy.stats import uniform\nfrom sklearn.ensemble import AdaBoostClassifier , RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","da448ca6":"# load Englih A Data \nengA = pd.read_csv('..\/input\/arabic-english-tweets\/English-A.txt', sep='\\t', names=['id', 'label', 'Text', 'non'])\nprint(engA['label'].unique())\nprint(engA.info())\nengA.head()","eb4b58b4":"# Convert Labels to int (0 for neutral, 1 for positive, -1 for negative)\nfor i in engA.index:\n  if engA.loc[i, 'label'] == 'neutral':\n    engA.loc[i, 'label'] = 0\n\n  if engA.loc[i, 'label'] == 'positive':\n    engA.loc[i, 'label'] = 1\n\n  if engA.loc[i, 'label'] == 'negative':\n    engA.loc[i, 'label'] = -1  \n\nengA.head()","a2622655":"# load Englih B Data \nengB = pd.read_csv('..\/input\/arabic-english-tweets\/English-B.txt', sep='\\t', names=['id', 'Subject', 'label', 'Text', 'non'])\nprint(engB['label'].unique())\nprint(engB.info())\nengB.head()","a4b19834":"# Convert Labels to int (0 for neutral, 1 for positive, -1 for negative)\nfor i in engB.index:\n  if engB.loc[i, 'label'] == 'neutral':\n    engB.loc[i, 'label'] = 0\n\n  if engB.loc[i, 'label'] == 'positive':\n    engB.loc[i, 'label'] = 1\n\n  if engB.loc[i, 'label'] == 'negative':\n    engB.loc[i, 'label'] = -1  \n\nengB.head()","fc504599":"# load Englih C Data\nengC = pd.read_csv('..\/input\/arabic-english-tweets\/English-C.txt', sep='\\t', names=['id', 'Subject', 'label', 'Text', 'non'])\nprint(engC['label'].unique())\nprint(engC.info())\nengC.head()","079a7b22":"# Convert Labels to int (0 for neutral, 1 for positive, -1 for negative)\nfor i in engC.index:\n  if engC.loc[i, 'label'] == 0:\n    engC.loc[i, 'label'] = 0\n\n  if engC.loc[i, 'label'] > 0:\n    engC.loc[i, 'label'] = 1\n\n  if engC.loc[i, 'label'] < 0:\n    engC.loc[i, 'label'] = -1  \n\nengC.head()","7deb3ec4":"# Load Arabic A Data\nArbA = pd.read_csv('..\/input\/arabic-english-tweets\/Arabic-A.txt', sep='\\t', names=['id', 'label', 'Text'])\nprint(ArbA['label'].unique())\nprint(ArbA.info())\nArbA.head()","4c43dc70":"# Convert Labels to int (0 for neutral, 1 for positive, -1 for negative)\nfor i in ArbA.index:\n  if ArbA.loc[i, 'label'] == 'neutral':\n    ArbA.loc[i, 'label'] = 0\n\n  if ArbA.loc[i, 'label'] == 'positive':\n    ArbA.loc[i, 'label'] = 1\n\n  if ArbA.loc[i, 'label'] == 'negative':\n    ArbA.loc[i, 'label'] = -1  \n\nArbA.head()","fadd59ad":"# load Arabic B Data\nArbB = pd.read_csv('..\/input\/arabic-english-tweets\/Arabic-B.txt', sep='\\t', names=['id', 'Subject', 'label', 'Text'])\nprint(ArbB['label'].unique())\nprint(ArbB.info())\nArbB.head()","ba6f72f6":"# Convert Labels to int (0 for neutral, 1 for positive, -1 for negative)\nfor i in ArbB.index:\n  if ArbB.loc[i, 'label'] == 'neutral':\n    ArbB.loc[i, 'label'] = 0\n\n  if ArbB.loc[i, 'label'] == 'positive':\n    ArbB.loc[i, 'label'] = 1\n\n  if ArbB.loc[i, 'label'] == 'negative':\n    ArbB.loc[i, 'label'] = -1  \n\nArbB.head()","9ccd53a9":"# Load Arabic C Data\nArbC = pd.read_csv('..\/input\/arabic-english-tweets\/Arabic-C.txt', sep='\\t', names=['id', 'Subject', 'label', 'Text'])\nprint(ArbC['label'].unique())\nprint(ArbC.info())\nArbC.head()","62068f23":"# Concat Arabic Data\nArabicData = pd.concat([ArbA[['Text','label']], ArbB[['Text','label']], ArbC[['Text','label']]])\nprint(ArabicData.info())\nArabicData.head()","607e7edf":"# Concat English Data\nEnglishData = pd.concat([engA[['Text','label']], engB[['Text','label']], engC[['Text','label']]])\nprint(EnglishData.info())\nEnglishData.head()","b9803798":"# Make Folder To Save Preprocesses & Vectorization\nif os.path.isdir('Preprocessors') == False:\n    os.system(\"mkdir Preprocessors\")\n\nif os.path.isdir('Vectorized') == False:\n    os.system(\"mkdir Vectorized\")","0d28b1af":"# Vectorization Function\ndef Vectorizer(*, Data, DataName):\n  if os.path.isfile(f'Preprocessors\/BigramVectorizer{DataName}.joblib') == False:\n      BigramVectorizer = CountVectorizer(ngram_range=(1, 2))  # Unigram & Bigram\n      BigramVectorizer.fit(Data['Text'].values)\n      dump(BigramVectorizer, f'Preprocessors\/BigramVectorizer{DataName}.joblib')\n\n  print(f'Loading BigramVectorizer{DataName}.joblib...')     \n  BigramVectorizer = load(f'Preprocessors\/BigramVectorizer{DataName}.joblib')\n  print('Done!')\n\n  if os.path.isfile(f'Vectorized\/BigramTrainText{DataName}.npz') == False:\n      BigramTrainText = BigramVectorizer.transform(Data['Text'].values)\n      save_npz(f'Vectorized\/BigramTrainText{DataName}.npz', BigramTrainText)\n\n  print(f'Loading BigramTrainText{DataName}.npz...')     \n  BigramTrainText = load_npz(f'Vectorized\/BigramTrainText{DataName}.npz')\n  print('Done!')\n  return BigramTrainText\n\nEnglishBigramTrainText = Vectorizer(Data=EnglishData, DataName='English')\nArabicBigramTrainText = Vectorizer(Data=ArabicData, DataName='Arabic')","f577811e":"# Make TFIDF(term frequency-inverse document frequency)\ndef BigramTFIDF(*, BigramTrainText, Name):\n  if os.path.isfile(f'Preprocessors\/BigramTFIDFTransformer{Name}.joblib') == False:\n      BigramTFIDFTransformer = TfidfTransformer()\n      BigramTFIDFTransformer.fit(BigramTrainText)\n      dump(BigramTFIDFTransformer, f'Preprocessors\/BigramTFIDFTransformer{Name}.joblib')\n\n  print(f'Loading BigramTFIDFTransformer{Name}.joblib...')      \n  BigramTFIDFTransformer = load(f'Preprocessors\/BigramTFIDFTransformer{Name}.joblib')\n  print('Done!')\n\n  if os.path.isfile(f'Vectorized\/BigramTFIDFTrainText{Name}.npz') == False:\n      BigramTFIDFTrainText = BigramTFIDFTransformer.transform(BigramTrainText)\n      save_npz(f'Vectorized\/BigramTFIDFTrainText{Name}.npz', BigramTFIDFTrainText)\n\n  print(f'Loading BigramTFIDFTrainText{Name}.npz...')      \n  BigramTFIDFTrainText = load_npz(f'Vectorized\/BigramTFIDFTrainText{Name}.npz')\n  print('Done!')\n  return BigramTFIDFTrainText\n\nEnglishBigramTFIDFTrainText = BigramTFIDF(BigramTrainText=EnglishBigramTrainText, Name='English')  \nArabicBigramTFIDFTrainText = BigramTFIDF(BigramTrainText=ArabicBigramTrainText, Name='Arabic')  ","7d90e043":"# Train Model And Test Calculate Model Score \ndef TrainAndTest(Model, modelName,  X: csc_matrix,  y: np.array, title: str):\n    TextTrain, TextValid, LabelTrain, LabelValid = train_test_split(\n        X, y, train_size=0.75, stratify=y)\n    Model.fit(TextTrain, LabelTrain)\n    TrainScore = Model.score(TextTrain, LabelTrain)\n    TestScore = Model.score(TextValid, LabelValid)\n    print(f'{title} with {modelName}\\nTrain score: {round(TrainScore, 2)}')\n    print(f'Validation score: {round(TestScore, 2)}\\n ')           ","0e3bf561":"model = SGDClassifier()\n\nTrainAndTest(Model=model, modelName='SGD Classifier', X=EnglishBigramTFIDFTrainText,\n             y=EnglishData['label'].values.astype('int'), title='English Data')   \n \nTrainAndTest(Model=model, modelName='SGD Classifier', X=ArabicBigramTFIDFTrainText, \n             y=ArabicData['label'].values.astype('int'), title='Arabic Data')","34cc9c69":"model = LinearRegression()\n\nTrainAndTest(Model=model, modelName='Linear Reression', X=EnglishBigramTFIDFTrainText,\n             y=EnglishData['label'].values.astype('int'), title='English Data')   \n \nTrainAndTest(Model=model, modelName='Linear Reression', X=ArabicBigramTFIDFTrainText, \n             y=ArabicData['label'].values.astype('int'), title='Arabic Data')","bc48bd3e":"model = AdaBoostClassifier()\n\nTrainAndTest(Model=model, modelName='Adaptive Boosting', X=EnglishBigramTFIDFTrainText,\n             y=EnglishData['label'].values.astype('int'), title='English Data')   \n \nTrainAndTest(Model=model, modelName='Adaptive Boosting', X=ArabicBigramTFIDFTrainText, \n             y=ArabicData['label'].values.astype('int'), title='Arabic Data')","617a1f6e":"model = RandomForestClassifier(max_depth=10 , random_state=0)\n\nTrainAndTest(Model=model, modelName='Random Forest', X=EnglishBigramTFIDFTrainText,\n             y=EnglishData['label'].values.astype('int'), title='English Data')   \n \nTrainAndTest(Model=model, modelName='Random Forest', X=ArabicBigramTFIDFTrainText, \n             y=ArabicData['label'].values.astype('int'), title='Arabic Data')","6fc03bad":"model = DecisionTreeClassifier()\n\nTrainAndTest(Model=model, modelName='Decision Tree', X=EnglishBigramTFIDFTrainText,\n             y=EnglishData['label'].values.astype('int'), title='English Data')   \n \nTrainAndTest(Model=model, modelName='Decision Tree', X=ArabicBigramTFIDFTrainText, \n             y=ArabicData['label'].values.astype('int'), title='Arabic Data')","644bf891":"## Training Models","1d520959":"## Vectorization","541fd129":"## Load & Preprocessing"}}