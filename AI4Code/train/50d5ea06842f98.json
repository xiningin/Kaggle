{"cell_type":{"be8caa40":"code","d6c14632":"code","030ca722":"code","425f31e0":"code","6f80e030":"code","ff131fc7":"code","29b1ef6d":"markdown","2ed6e20c":"markdown","e209d8d7":"markdown","8d304f4d":"markdown","b19fd0ed":"markdown"},"source":{"be8caa40":"import os\nfrom os.path import join\n\nimport tensorflow as tf\nfrom tensorflow.data import Dataset\nfrom tensorflow.keras import layers\n\nSRC = join(\"\/kaggle\/input\/bitmojis\/bitmojis\")","d6c14632":"def load_raw_data(root, img_size, prefix):\n    \"\"\"load_raw_data.\n\n    :param root: the path of the root directory with all files\n    :param img_size: the img_size (either W,H or only one scalar for square resolution)\n    :param prefix: a prefix giving the format of the input files\n    \"\"\"\n    img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n    def _load_img(path):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_png(img, channels=3)\n        img = tf.image.resize(img, img_size)\n        img = (img - 127.5) \/ 127.5 # tanh\n        return img\n\n    pattern = join(root, prefix)\n    ds = Dataset.list_files(pattern)\n    ds = ds.map(_load_img)\n    return ds","030ca722":"class Generator(tf.keras.models.Model):\n    def __init__(self, latent_dim):\n        super(Generator, self).__init__()\n        self.latent_dim = latent_dim\n        alpha = .2\n        w, h, f = 4, 4, 256\n\n        self.network = tf.keras.models.Sequential([\n            layers.Input(shape=(latent_dim,)),\n\n            layers.Dense(w * h * f, use_bias=False),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha),\n            layers.Reshape((w, h, f)),\n\n            layers.Conv2DTranspose(f, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha),\n\n            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha),\n\n            layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha),\n            \n            layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha),\n\n            layers.Conv2D(3, (4, 4), 1, padding='same', use_bias=False)\n        ])\n\n    def call(self, inputs):\n        x = self.network(inputs)\n        return tf.tanh(x)","425f31e0":"class Discriminator(tf.keras.models.Model):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        alpha = .2\n        rate = .2\n        self.network = tf.keras.models.Sequential([\n\n            layers.Conv2D(128, (5, 5), strides=2, padding='same'),\n            layers.LeakyReLU(alpha),\n            layers.Dropout(rate),\n\n            layers.Conv2D(256, (5, 5), strides=2, padding='same'),\n            layers.LeakyReLU(alpha),\n            layers.Dropout(rate),\n            \n            layers.Conv2D(512, (5, 5), strides=2, padding='same'),\n            layers.LeakyReLU(alpha),\n            layers.Dropout(rate),\n\n            layers.Flatten(),\n\n            layers.Dense(1)\n        ])\n\n    def call(self, inputs):\n        return self.network(inputs)","6f80e030":"class WGAN(tf.keras.Model):\n    def __init__(self, d, g, critic):\n        super(WGAN, self).__init__()\n        self.critic = critic\n        self.latent_dim = g.latent_dim\n        self.d = d\n        self.g = g\n\n    def compile(self,\n                d_optim,\n                g_optim,\n                ):\n        super(WGAN, self).compile()\n        self.d_optim = d_optim\n        self.g_optim = g_optim\n\n    def get_penalty(self, real, fake, epsilon):\n        mixed_images = fake + epsilon * (real - fake)\n        with tf.GradientTape() as tape:\n            tape.watch(mixed_images)\n            mixed_scores = self.d(mixed_images)\n\n        gradient = tape.gradient(mixed_scores, mixed_images)[0]\n\n        gradient_norm = tf.norm(gradient)\n        penalty = tf.math.reduce_mean((gradient_norm - 1)**2)\n        return penalty\n\n    def discriminator_step(self, real_images, z, epsilon, c_lambda):\n        fake_images = self.g(z)\n        penalty = self.get_penalty(real_images, fake_images, epsilon)\n        with tf.GradientTape() as tape:\n            real_output = self.d(real_images)\n            fake_output = self.d(fake_images)\n            loss = tf.math.reduce_mean(fake_output) - tf.math.reduce_mean(real_output) + c_lambda*penalty\n\n        grads = tape.gradient(loss, self.d.trainable_variables)\n        self.g_optim.apply_gradients(zip(grads, self.d.trainable_variables))\n        return loss\n\n    def generator_step(self, z):\n        with tf.GradientTape() as tape:\n            fake_images = self.g(z)\n            try_to_fool = self.d(fake_images)\n            loss = -tf.math.reduce_mean(try_to_fool)\n\n        grads = tape.gradient(loss, self.g.trainable_variables)\n        self.g_optim.apply_gradients(zip(grads, self.g.trainable_variables))\n        return loss\n\n    def train_step(self, real_images):\n        batch_size = real_images.shape[0]\n\n        dloss = tf.constant(.0)\n        z = tf.random.normal((batch_size, self.latent_dim))\n        epsilon = tf.random.normal((batch_size, 1, 1, 1), mean=0, stddev=1)\n        _dloss = self.discriminator_step(real_images, z, epsilon, 10.)\n        dloss += _dloss\n\n        z = tf.random.normal((batch_size\/\/self.critic, self.latent_dim))\n        gloss = self.generator_step(z)\n\n        return dict(gloss=gloss, dloss=dloss \/ self.critic)\n\n    def call(self, x):\n        return self.d(self.g(x))","ff131fc7":"NAME = \"EXPERIMENTAL\"\nBATCH_SIZE = 512\nLATENT_DIM = 10\nOUT_SIZE = 64\nEPOCHS = 2000\nCRITIC = 16\n\ngpus = tf.config.list_physical_devices(\"GPU\")\nif gpus and len(gpus) > 1:\n    print(f\"Mirrored strategy over {len(gpus)} gpus\")\n    strategy = tf.distribute.MirroredStrategy()\nelse:\n    print(f\"Basic strategy on {'gpu' if gpus else 'cpu'}\")\n    strategy = tf.distribute.get_strategy()\n    \nwith strategy.scope():\n    d = Discriminator()\n    g = Generator(LATENT_DIM)\n    wgan = WGAN(d, g, CRITIC)\n    wgan.compile(\n        tf.keras.optimizers.RMSprop(.0002),\n        tf.keras.optimizers.RMSprop(.0002),\n    )\n    \nds = load_raw_data(SRC, OUT_SIZE, prefix=\"*\")\n\nds = (ds\n      .cache()\n      .shuffle(140_000)\n      .batch(BATCH_SIZE*strategy.num_replicas_in_sync, drop_remainder=True)\n      .prefetch(-1)\n      )\n\ntry:\n    wgan.fit(\n        ds,\n        epochs=EPOCHS,\n        callbacks=[\n            tf.keras.callbacks.TensorBoard(f\".\/runs{OUT_SIZE}\/{NAME}\", histogram_freq=1),\n            tf.keras.callbacks.ModelCheckpoint(f\".\/runs{OUT_SIZE}\/{NAME}\")\n        ]\n    )\nexcept KeyboardInterrupt:\n    print(f\"Saved the last weights as .\/runs{OUT_SIZE}\/KEYBOARDINTERRUPT.h5\")\n    wgan.save_weights(f\".\/runs{OUT_SIZE}\/KEYBOARDINTERRUPT.h5\")","29b1ef6d":"### Then implement the discriminator","2ed6e20c":"### And finally put all together in the WGANGP class\nHere we have the main train step with generator and discriminator step. We also have the compute of the gradient penalty.","e209d8d7":"### We can then declare a function to load all data as a Tensorflow Dataset","8d304f4d":"## Here is the time to implement the whole GAN\n\n<p align=\"center\"> \n<img src=\"https:\/\/media.giphy.com\/media\/NEvPzZ8bd1V4Y\/giphy.gif\">\n<\/p>\n\n### Let's first declare the generator","b19fd0ed":"> This notebook is a copy of the code you can find in the main GitHub repository ([https:\/\/github.com\/RomainGrx\/LINMA2472-Homeworks](https:\/\/github.com\/RomainGrx\/LINMA2472-Homeworks\/tree\/main\/Homework%204))\n\nIn this notebook we will implement a Wasserstein GAN with gradient penalty in order to retrieve the best diversity in the generation of bitmojis. If you want to exactly know why I choose this particular algorithm, everything is explained in the report ([report.pdf](https:\/\/github.com\/RomainGrx\/LINMA2472-Homeworks\/raw\/main\/Homework%204\/LINMA2472_Homework4.pdf)).\n\n### Let's first declare all imports and input directory "}}