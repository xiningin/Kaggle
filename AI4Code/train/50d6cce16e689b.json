{"cell_type":{"24b5b74c":"code","9966a97f":"code","f72d3bf3":"code","c920b285":"code","f41ed4ab":"code","f0af0e8a":"code","efe4a7f3":"code","aee45820":"code","7f90f2ce":"code","a59288c1":"code","79a59714":"code","0ab17fd7":"code","476e2162":"code","4cd3c519":"code","5698dc06":"code","f01979bc":"code","0822440a":"code","2bad20e2":"code","fd15e9ad":"code","57b179cf":"code","f1a0e3b4":"code","5ff48046":"code","f7c3e9a9":"code","27a5e9db":"code","d4dc2c8e":"markdown","3496e39a":"markdown","5d5aca60":"markdown","f09f8ea2":"markdown","d1832ecb":"markdown","012e38cd":"markdown","e997ac81":"markdown"},"source":{"24b5b74c":"import pandas as pd\nfrom tqdm import tqdm\nimport numpy as np\nimport gc\n\npd.options.display.max_columns = 1000\npd.options.display.max_rows = 1000\npd.options.display.max_seq_items = 1000","9966a97f":"exceptional_days = pd.read_csv(\"..\/input\/exceptional-days\/exceptional_days.txt\",parse_dates=['date'])\nactions = pd.read_csv('..\/input\/trendyol-project\/dailyProductActions.csv',parse_dates=['date'])\nproducts = pd.read_csv('..\/input\/trendyol-project\/product.csv')","f72d3bf3":"submission = pd.read_csv('..\/input\/trendyol-project\/SampleSubmission.csv')","c920b285":"actions['saleDay'] = 0\nactions[\"week\"] = pd.DatetimeIndex(actions[\"date\"]).weekofyear\nactions.loc[actions[actions.date.isin(exceptional_days.date.unique())].index,'saleDay'] = 1\nactions.loc[actions[\"week\"] == 2, \"week\"] = 11\nactions.loc[actions[\"week\"] == 1, \"week\"] = 10\nactions.loc[actions[\"week\"] == 52, \"week\"] = 9\nactions.loc[actions[\"week\"] == 51, \"week\"] = 8\nactions.loc[actions[\"week\"] == 50, \"week\"] = 7\nactions.loc[actions[\"week\"] == 49, \"week\"] = 6\nactions.loc[actions[\"week\"] == 48, \"week\"] = 5\nactions.loc[actions[\"week\"] == 47, \"week\"] = 4\nactions.loc[actions[\"week\"] == 46, \"week\"] = 3\nactions.loc[actions[\"week\"] == 45, \"week\"] = 2\nactions.loc[actions[\"week\"] == 44, \"week\"] = 1\nactions.fillna(0, inplace=True)","f41ed4ab":"weekly = (actions.groupby([\"productid\", \"week\"], as_index=False)\n             .agg({'saleDay':'sum', 'stock':'mean', 'clickcount':'sum','favoredcount':'sum', 'soldquantity':'sum', }).sort_values('week'))","f0af0e8a":"product_means = (weekly.groupby([\"productid\"], as_index=False)\n               .agg({'soldquantity':'mean','stock':'mean','clickcount':'mean','favoredcount':'mean'})\n               .rename(columns={'soldquantity':'soldquantitymean','stock':'stockmean','clickcount':'clickcountmean','favoredcount':'favoredcountmean'}))\nproduct_means.set_index(\"productid\", inplace=True)","efe4a7f3":"train_set = pd.DataFrame(index=list(products['productid']))\nfor row in tqdm(weekly.itertuples()):\n    train_set.at[row[1], 'prior_week_'        + str(row[2])] = 1\n    train_set.at[row[1], 'saleday_week_'      + str(row[2])] = row[3]\n    train_set.at[row[1], 'stock_week_'        + str(row[2])] = row[4]\n    train_set.at[row[1], 'clickcount_week_'   + str(row[2])] = row[5]\n    train_set.at[row[1], 'favoredcount_week_' + str(row[2])] = row[6]\n    train_set.at[row[1], 'soldquantity_week_' + str(row[2])] = row[7]","aee45820":"products['kadin'] = 0\nproducts['erkek'] = 0\nproducts.loc[products[(products.gender==2)|(products.gender==3)].index,'kadin'] = 1\nproducts.loc[products[(products.gender==1)|(products.gender==3)].index,'erkek'] = 1\nproducts.drop(columns=['gender'],inplace=True)","7f90f2ce":"train_set = pd.concat([products.set_index('productid'), product_means, train_set], axis=1, join='inner')\ntrain_set.reset_index(inplace=True)\ntrain_set.rename(columns={'index':'productid'},inplace=True)\ntrain_set.fillna(0, inplace=True)","a59288c1":"del product_means, weekly, actions, products, exceptional_days\ngc.collect()","79a59714":"submission = submission.merge(train_set,how='left',on=['productid'])","0ab17fd7":"submission.drop(columns=['sales','soldquantity_week_11'], inplace=True)","476e2162":"y = train_set['soldquantity_week_11']","4cd3c519":"colsToTrain = train_set.drop(['soldquantity_week_11'], axis=1)\nX = colsToTrain","5698dc06":"print('X.shape = ' + str(X.shape))\nprint('y.shape = ' + str(y.shape))","f01979bc":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(X, y,\n                                                      random_state=6,\n                                                      test_size=0.15)","0822440a":"X_test = submission.copy()","2bad20e2":"del colsToTrain, train_set, X, y , submission\ngc.collect()","fd15e9ad":"import xgboost as xgb\nmodel = xgb.XGBRegressor(objective = 'reg:linear',\n                         metric = 'rmse',\n                         n_estimators = 50000,\n                         max_depth = 6,\n                         learning_rate = 0.001,\n                         tree_method = 'gpu_hist',\n                         verbosity = 0)","57b179cf":"%%time\nmodel.fit(x_train,y_train,\n          eval_metric='rmse',\n          eval_set=[(x_train, y_train), (x_valid, y_valid)])","f1a0e3b4":"del x_train, y_train, x_valid, y_valid\ngc.collect()","5ff48046":"ax = xgb.plot_importance(model)\nfig = ax.figure\nfig.set_size_inches(20, 20)","f7c3e9a9":"preds = model.predict(X_test)\npreds[preds < 0] = 0","27a5e9db":"subm = pd.DataFrame()\nsubm['productid'] = X_test.productid.values\nsubm['sales'] = preds\nsubm.to_csv('submission.csv', index=False)","d4dc2c8e":"### Model Predict ","3496e39a":"### Model train ","5d5aca60":"### Model parameters ","f09f8ea2":"## Load Data","d1832ecb":"### Train set\/ Test set split ","012e38cd":"### Generate Features for Train set","e997ac81":"### Merge features into test data"}}