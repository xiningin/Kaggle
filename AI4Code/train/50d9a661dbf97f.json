{"cell_type":{"f30c92f5":"code","e5ee5307":"code","c962fda0":"code","a1333c3c":"code","e97ad2e8":"code","b0df6519":"code","3accf21b":"code","2002c11d":"code","3644406b":"code","62fe6528":"code","fe27b8cb":"code","4775735c":"code","e8b149fe":"code","0f3d341e":"code","a50259c4":"code","9c80a304":"code","0a39ae7c":"code","53b2f01d":"code","ad95f998":"markdown","2c45a5f7":"markdown","641007b1":"markdown","c79ef347":"markdown","de67b521":"markdown","c4441fde":"markdown","cd8e93a5":"markdown","25433f5a":"markdown","49be9561":"markdown","ab396692":"markdown","d3ca95cd":"markdown","e526394d":"markdown","2d6bf0e8":"markdown","8d168abd":"markdown","97dcda82":"markdown"},"source":{"f30c92f5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import probplot\nfrom sklearn.metrics import r2_score\nimport statsmodels.formula.api as smf\nfrom statsmodels.stats import diagnostic\n\nplt.style.use('default')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nnp.random.seed(123)","e5ee5307":"df = pd.read_csv('..\/input\/weight-height\/weight-height.csv')\ndf.head()","c962fda0":"print(df.isna().sum())","a1333c3c":"# Outliers: \npalette=['navy','orange']\nfig, (ax1,ax2) = plt.subplots(2,1,figsize=(6,3))\nax1.grid()\n# ax1.boxplot(data=df, x=['Weight'])\nsns.boxplot(x=df.Weight, y=df.Gender, ax=ax1, palette=palette)\nax2.grid()\nsns.boxplot(x=df.Height, y=df.Gender, ax=ax2, palette=palette);","e97ad2e8":"# 3. Distribution across genders is perfect\npd.value_counts(df.Gender)","b0df6519":"fig,ax = plt.subplots(1,2, figsize=(8,4))\nax[0].scatter(df.Height, df.Weight, c=df.Gender=='Male',marker='.',s=1)\nax[0].set_xlabel('Height')\nax[0].set_ylabel('Weight')\nsns.heatmap(df.corr(), annot=True, ax=ax[1],cmap='viridis');","3accf21b":"fig,ax = plt.subplots(1,2,figsize=(12,3))\nfig.suptitle('Distribution of Variables', fontsize=16)\nsns.histplot(data=df, x='Weight', hue='Gender', ax=ax[0], stat='percent', palette='viridis')\nsns.histplot(data=df, x='Height', hue='Gender',ax=ax[1], palette='viridis');","2002c11d":"# Split the data to train and test using pandas\n\ndf_test = df.sample(frac=0.3)\ndf_train = pd.merge(df, df_test, how='outer', indicator=True).query('_merge ==\"left_only\"').drop(columns=['_merge'])\nprint(f'Size of training set:{len(df_train)}, size of test set: {len(df_test)}\\n')","3644406b":"print(\"Gender count across Train Set:\\n\",pd.value_counts(df_train.Gender))","62fe6528":"# Ordinary Least Square (OLS) regression\nols = smf.ols(formula=\"Weight ~ C(Gender) + Height\", data=df_train)\nres = ols.fit(cov_type='nonrobust')\nprint(res.summary())","fe27b8cb":"#Correlation between Hieght and Weight across Genders\nprint(\"Corrolation table:\\n\", df_train.groupby('Gender').corr().Height.to_frame().loc[(slice(None),[\"Weight\"]),])","4775735c":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(9,4), squeeze=True)\nfig.suptitle(\"Linearity Assumption\", fontsize=16)\nax1.scatter(x=df_train.Weight, y=res.predict(), c=df_train.Gender=='Male', s=0.65, marker='x')\nax1.set_title('Figure 1')\nax1.set_xlabel('True Weight')\nax1.set_ylabel('Predicted Weight')\nax2.scatter(x=res.predict(), y= res.resid, c=df_train.Gender=='Male', s=0.65, marker='x')\nax2.set_title('Figure 2')\nax2.set_xlabel('Predicted Weight')\nax2.set_ylabel('Residual')\nax2.axhline(0,lw=0.8,c='k',ls=':')\nplt.show()","e8b149fe":"#Breusch_Pagan x^2 tests the hypothesis that the residual variance does NOT depend on the variables in x \n# It also assums the data has a constant column. So I'm gonna add one \n# The test cannot read categorical varaiabls without factorization\ndf_train['Const'] = 1\ndf_train['G'],_ = df_train.Gender.factorize()\n\n_,_,F,p_value = diagnostic.het_breuschpagan(res.resid, df_train[['Height','G','Const']], robust=False)\nprint(f\"Breusch_Pagan: F-statistic {F}, P-value:{p_value}\")","0f3d341e":"fig,ax1 = plt.subplots(1,1,figsize=(6,4), squeeze=True)\nfig.suptitle(\"Homoscedasticity\", fontsize=16)\nax1.scatter(x=df_train.Height, y=res.resid, c=df_train.Gender=='Male', s=1, marker='x')\nax1.set_title('Figure 3')\nax1.set_xlabel('True Weight')\nax1.set_ylabel('Predicted Weight')\nplt.show()","a50259c4":"fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,4))\nax1.hist(res.resid, color='gold')\nax1.set_title('Error Distribution')\nprobplot(res.resid, plot=ax2)\nax2.set_title('Q-Q Plot');","9c80a304":"y_test_pred = res.predict(exog=df_test)\ntest_rsquare= r2_score(df_test.Weight, y_test_pred)\nprint(f\"Test R-squared:{test_rsquare:.3f} \")","0a39ae7c":"male_mask = np.where(df_test.Gender=='Male', True, False)\ntest_pred = res.get_prediction(df_test)\ntest_summary = test_pred.summary_frame()\nlabels = ['True','Pred','U-band','L-band']\nfig,(axm, axf) = plt.subplots(1,2,figsize=(10,5))\nfig.suptitle('Test vs. Prediction', fontsize=15)\naxm.scatter(df_test[male_mask].Height,df_test[male_mask].Weight, label=labels[0], marker='o',s=1, color='navy')\naxm.plot(df_test[male_mask].Height, test_summary[male_mask]['mean'], color='b', label=labels[1],lw=0.75)\naxm.plot(df_test[male_mask].Height, test_summary[male_mask]['obs_ci_lower'], 'b:', label=labels[2],lw=0.75)\naxm.plot(df_test[male_mask].Height, test_summary[male_mask]['obs_ci_upper'], 'b:', label=labels[3],lw=0.75)\naxm.set_title('Male')\n\naxf.scatter(df_test[~male_mask].Height,df_test[~male_mask].Weight, s=1,marker='x',color='gold',label=labels[0])\naxf.plot(df_test[~male_mask].Height, test_summary[~male_mask]['mean'], color='red', label=labels[1],lw=0.5)\naxf.plot(df_test[~male_mask].Height, test_summary[~male_mask]['obs_ci_lower'], 'k--', label=labels[2],lw=0.5, alpha=0.5)\naxf.plot(df_test[~male_mask].Height, test_summary[~male_mask]['obs_ci_upper'], 'k--', label=labels[3],lw=0.5, alpha=0.5)\naxf.set_title('Female')\naxf.legend()\naxm.legend();","53b2f01d":"\"\"\"\nOutlier detection methods:\n- 'bonferroni` : one-step correction\n- `sidak` : one-step correction\n- `holm-sidak` :\n- `holm` :\n- `simes-hochberg` :\n- `hommel` :\n- `fdr_bh` : Benjamini\/Hochberg\n- `fdr_by` : Benjamini\/Yekutieli\n\"\"\"\noutliers = res.outlier_test('bonf')\noutidx = outliers[outliers.iloc[:,-1] < 0.99].index\noutliers.loc[outidx]\n\nfig= plt.figure(figsize=(6,4))\nplt.scatter(df_train.Height, df_train.Weight, c=df_train.Gender.values=='Male', s=0.7)\nplt.scatter(df_train.loc[outidx].Height, df_train.loc[outidx].Weight, c=df_train.loc[outidx].Gender.values=='Male', marker='<',cmap='flag');","ad95f998":"### 2.1 Missing Values (N\/A):\nExamine the data for any missing values in $x, y$. If there is any, you can either drop the missing record or fill it with its closest match","2c45a5f7":"**Conclusion** Breusch_Pagan F-statistic is very small and its p-value is > 0.05. So we fail to reject the null hypothesis that the residuals do NOT depend on x. \nThe scatter plot also confirms this in the absence of any patterns. Therefore no violation of this assumption\n\n### 4.1.4 Serial Correlation:\nAlso known as autocorrelation, when the residuals are correlated with one another. This is more of a problem in time series data.  \nTo diagnose it we look at **Durbin-Watson** number from regression results DW = 2.014. Since it is in the range of (1.5, 2.5) then there is no serial correlation to worry about.\n\n### 4.1.5 Normality of Error Terms:\nIf error terms are **NOT** normally distributed it'll cause problems when t-testing the coefficients because standard error is no longer reliable. This will affect the confidence intervals of model predictions.  \nThe easiest way to diagnose normality is to plot a histogram of residuals or a Q-Q plot (from `scipy.stats.probplot`).  \n\n*Note: In `statsmodels` regression summary, many of the outputs address the normality of residuals $\\epsilon$: Omnibus, Skew, Kurtosis, Jarque-Bera (details at the end of this notebook)*","641007b1":"**Conclusion** error terms appear to be normally distributed \n### 5.1 Prediction\n","c79ef347":"Seems like both variables are normally distributed. This will make our life easier when investigating some of the typical problems of linear regressions. \n\n## 3. Analyzing the Data\n\nThis step should answer the question asked in step (1). i.e. is there a linear relationship between the dependent and independent variables?  That said, let's list the assumptions of linear regression:\n### 3.1 Assumptions of a Linear Regression\n\n1. There is a linear relationship between dependent and independent variables\n2. The independent variables are not random, and there is no exact linear relationship between them. (no multicollinearity)\n3. The expected value of error term is zero $E(\\epsilon | x_i)=0$\n4. The variance of the error term is constant for all observations (i.e. $E(\\epsilon^2_i)=\\sigma_{\\epsilon}^2$ (no heteroscedasticity)\n5. The error term of one observation is not correlated with that of another (no serial correlation)\n6. The error term is normally distributed\n\nWe are going to test each of these assumptions after regressing the data  \n\n\n### 3.2 Pre-Processing\n#### 3.2.1 Split the Data\n\nIt's standard practice to split the data into training and test sets to see how the model behaves when presented with data it hasn't seen. I'm going to use pandas to do this. \n\nAnother, very common way to do it is by using`train_test_split` from `sklearn.model_selection`, but I prefer pandas. As it retains both sets as DataFrames. This will make the regression outcome much more user-friendly!  \n","de67b521":"**Conclusion:** No N\/As to worry about.\n\n### 2.2 Outliers\n\nSometimes outliers are bad data that you must get rid of, but sometimes they're Michael Jordan or Shaquille O'Neal and you must keep. Either way, outliers must be identified before you decide how to deal with them.  \nThe two most common definitions of outliers are: \n1. Observations that are more than 3 standard deviations away from the mean.\n2. Observations that are more than 1.5 * Inter-Quartile-Range (IQR) below\/above the 25th\/75th percentiles (ends of the boxplot).\n\nCurrent data contains one continuous and one categorical (discrete) variable. So a simple boxplot should reveal any outliers.  \n\n**More on outliers detection**   \nThe most common techniques used to identify outliers by data types is:  \n- Univariate data -> boxplot. outside of 1.5 times the inter-quartile range is an outlier.  \n- Bivariate -> scatterplot with confidence ellipse. outside of, say, 95% confidence ellipse is an outlier.  \n- Multivariate -> Mahalanobis D2 distance   \n\nOnce defined, mark those observations as outliers. Then run a logistic regression to see if there are any systematic patterns.  ","c4441fde":"**Conclusion** the data is split equally between Males and females, which is great!  \n\nNo further action is needed.\n### 2.4 Scatter plot x,y","cd8e93a5":"**Conclusion** \nThere are visible outliers that meet the definition, but I don't think I should remove them because I see no reason why a 270 lbs male or a 55-inch female should be excluded! \n\n### 2.3 Balanced\n\nIn general, having balanced data generates higher accuracy models. This is true for all regression types and machine learning algorithms.  ","25433f5a":"## 4. Interpreting Regression Results\n\nAdj. R-Squared value at 0.902 and Prob(F-statistic) at 3.2e+4, tell that the model is doing a good job explaining the variability in the independent variable. The coefficients have high t-values and zero associated p-values indicating statistical significance.  \n\n\n### 4.1 Is the Model Valid?\n\nTo answer this question we need to make sure the model does not violate any of the assumptions in 4.1, So let's group them and sort them from most to least serious.  \n\n\n### 4.1.1 Violations of linearity (Extremely Serious)\n\n**First:** Check the correlation between dependent and independent variables. The table below shows a strong positive association between Height and Weight across Genders, which supports linearity in our case (be careful when using correlation in higher dimensions as it could be misleading)   \n\n**Second:**  \nPlot predicted vs. observed: the points should be symmetrically distributed around a diagonal line (figure 1)  \nPlot predicted vs. residuals: the points should be symmetrically distributed around a horizontal line (figure 2)  ","49be9561":"# 2. Read & Clean the Data:\nThe second step is collecting data. Here we're using a simple Bivariate dataset that contains Weights - in lbs- and Heights -in inches- of 10,000 observations. They represent Male and Female adults that we presume were taken randomly from the population!","ab396692":"### 2.5 Distribution of Variables (Optional)\nThe dependent and\/or independent variables don't need to be Normal distributed. Yet, if their distributions are extremely off normal, it's difficult to fit a line that results in normal errors. Which is one of the assumptions of linear regression 3.1.6. \nI usually check the distribution of all variables upfront to know what to expect. This is an optional but helpful step.  \n\nThe easiest way to do that in practice is to visualize the distribution using a histogram (across categories):","d3ca95cd":"# Introduction:\n\nThis notebook is to summarize the practical steps of linear regression. I tried to be as generic as possible, but each dataset has its unique characteristics that need extra, or fewer, steps. That said if you notice any missing or extra steps don't hesitate to leave a comment :) \n\nLet's denote the dependent variable $y$, and the independent variables (features) $x ~ (x_1, x_2\\dots x_n)$. Then list the project pipeline as follows:\n1. Ask the right question\n2. Read the data: \n - Examine data types; look for any missing values, outliers, imbalance (across $y$ and $x$) in the set\n - Scatter plot $y,x$: this will help spot the relationship between them \n - Plot histograms $y,x$: look for normality. This will help you know what to expect! \n3. Based on the spotted relationship, decide which model to use (linear, log-linear, quadratic..etc). Try to answer the following questions:\n - What value\/s can $y$ take (positive, negative, or zero)?\n - What should the signs of the coefficients be (positive, negative)?\n4. Build the model and examine results:\n - Are the coefficients statistically significant?\n - Do they have the signs you'd expected?\n - Make sense of the coefficients irrespective of their significance. Adjust if needed. **, For example,**: ask the question does the sign\/value\/p-value of a coefficient make economic sense?\n5. Now that you've built the model and adjusted parameters, run a goodness-of-fit to make sure the model doesn't violate any of the assumptions of linear regressions (4.1 for details) :\n - Linearity\n - Independence (of $x$): is there a multicollinearity\n - Homoscadasticity of $\\epsilon$: Breusch\u2013Pagan test.\n - No autocorrelation of $\\epsilon$: Durbin-Watson test \n - Normality of $\\epsilon$: Shapiro-Wilk Test for normality, Q-Q plot, histogram \n6. If the model is invalid, try another formula and repeat step 4. \n7. Make sure the residuals are 1) normally distributed 2) have constant variance 3) independent 4) not serially correlated.\n8. Predict values and calculate their intervals. Try to set aside a slice of your data to test with, or we can mock-up test data if possible! \n9. Make sure the predictions make economic sense \n \n\n# 1. Ask the Right Question:\n   \nThe first and most important step in data analysis is to ask the right question. Here, the question is: is there a linear relationship between (Height, Gender) and Weight. If Yes, build a model to reference it, validate this model, interpret results and make predictions.","e526394d":"#### 3.2.2 Balance Re-Check\n\nTo make sure splitting the data didn't affect the balance of observations:","2d6bf0e8":"Our model appears to be linear.\n\n### 4.1.2 Violation of Independence (Multicollinearity):\n\"The independent variables are not random and there is no exact linear relationship between them\".  \nTypically spotted when t-tests indicate non of the individual coefficients is significant **while** R-squared and F-statistics are high. We don't have this here.  \nIt can also be present if the **Condition Number** is large, which it is here, but we can ignore this since we have only one continuous variable\n\n### 4.1.3 Violations of Homoscedasticity:\nHeteroskedasticity occurs when the variance of the residuals is not constant across observations. There are two methods to detect heteroskedasticity: examining scatter plots of the residuals\nand using the Breusch-Pagan chi-square $\\chi^2$ test.\n\nVisually, scatter plot **residuals vs. predicted** and **residuals vs. one or more independent** variable. And look for patterns where residuals grow\/shrink as a function of predicted values (or time in case of time series)  \nWe've already plotted residuals vs predicted in figure (1) and it seems consistent, so lets look at residuals vs independent variables Height\/Gender ","8d168abd":"### 3.3 OLS regression model","97dcda82":"\n# Appendex\nHere are some important definitions and explanations of regression outputs often used in statistical analysis.\n\n### Bias of Estimator\nBias is a measure of the difference between the estimator's expected and true values. As such, a biased estimator is one with coefficients that are very different from the true values \n\n### Efficiency of Estimator\nAn efficient estimator is the 'best possible' estimator of the parameter of interest that minimizes the loss function. In linear regression, it's the parameter that provides the smallest variance.\n\n#### 7.1 R-squared\nR-squared\/Adj.R-squared: 90.4% of the variability in the dependent variable is explained by the independent variables. This is high enough for the training set, but let's see how well the model deals with data it hasn't seen (test_set)\nTest R-squared at 90.5% is as high as train R-squared, which means the model generalizes well\n\n\n#### 7.2 F-statistic|Prob(F)\nIt tests how well the independent variables as a group explain the variations of the dependent variable (i.e. tests the null hypothesis $H_0: \\beta_1=\\beta_2=\\dots \\beta_n=0$   \nP-value of F-statistic, or the probability of type I error (observation happening giving the null hypothesis is true)  \nIn this case, F-statistic is very large and Prob(F) is zero, which is great!  \n\n#### 7.3 AIC:\nThe Akaike Information Criterion (AIC) measures overfit. It rewards the model for goodness-of-fit and penalizes it if it became overly complicated.  \nAIC is useful when comparing models but very hard to interpret standalone!  \n\n#### 7.4 Omnibus\/Prob(Omnibus):\nTests the normality of the residuals. We hope to see a value close to zero for the Omnibus number and a value close to one for the Prob (Omnibus).\n**Omnibus: the closer to zero the better***  \n**Prob(Omnibus): The closer to one the better***  \n\nIn this case, Omnibus is relatively high and the Prob (Omnibus) is relatively low so the data is far from normal. \n\n#### 7.5 Skew \nMeasures data symmetry. We want to see something close to zero, indicating the residual distribution is normal. Note that this value also drives the Omnibus.  \n**The closer to zero the better***   \n\n#### 7.6 Kurtosis\nA measure of peakiness, or data curvature. Higher peaks lead to greater Kurtosis, and in the case of residuals, a greater Kurtosis means tighter clustering around zero, which implies a better model with few outliers.  \n**The higher the better**  \n\n#### 7.7 Durbin-Watson\nTests for serial correlation. A value between 1.5 and 2.5 means there is no serial correlation. In this case, the number is within the acceptable range.  \n\n#### 7.8 Jarque-Bera (JB)\/Prob(JB)\nLike the Omnibus test, it measures both skewness and kurtosis. We hope to see in this test confirmation of the Omnibus test.   \n\n#### 7.9 Condition Number\nMeasures the sensitivity of a function's output as compared to its input. When we have multicollinearity, we can expect much higher fluctuations to small changes in the data, hence, we hope to see a relatively small number, something below 30.  \n**The smaller below 30 the better**\n\n\nGood reading on regression violations and how to correct them:  \nhttps:\/\/people.duke.edu\/~rnau\/testing.htm\n\n#### 7.10 Outliers\n\nThe below code is another way to identify outliers using a built-in function in `statsmodels` library. It has many options to calculate them. That said, I still don't think there is a need to exclude any observation from this particular dataset"}}