{"cell_type":{"b86c65fa":"code","e507973b":"code","7f256d0d":"code","8d5cf892":"code","c608bb75":"code","59898579":"code","4821f74b":"code","a3e6c465":"code","64b01833":"code","4f4299c7":"code","5ff67ccb":"markdown","8e4d939b":"markdown","e87b40dc":"markdown","c5ad7edb":"markdown","53f05d1e":"markdown","756b8d1b":"markdown","d5cb54e4":"markdown","a37c1065":"markdown","26cc6694":"markdown","a1663530":"markdown"},"source":{"b86c65fa":"import numpy as np\nimport pandas as pd\n# burada numpy da dahil ediyoruz cunku birbiriyle baglantili kullandigimiz yerler olacak\n\n\nlabels_list = [\"mustafa\" , \"kemal\" , \"murat\" , \"tugce\" , \"tugba\"]\n\ndata_list = [10,20,30,40,50]\n\n# PANDAS SERILERINI BIR TANE INDEKS VE DEGERLERDEN OLUSAN ARRAY DIYEBILIIRIZ\n\nprint(pd.Series(data = data_list, index=labels_list))\n\"\"\"\nmustafa    10\nkemal      20\nmurat      30 ----> ciktisini verir\ntugce      40 \ntugba      50\ndtype: int64 --> burada datalarimizin hangi veritipinden oldugunu gorebiliyoruz\n\n\"\"\"\n\n\n\nprint(pd.Series(data_list))\n\n\"\"\"\n0    10\n1    20\n2    30\n3    40\n4    50\ndtype: int64\n\nBURADA HERHANGIBIR INDEX VERMEDIGIMIZ ICIN \nOTOMATIK DEFAULT OLARAK 0,1,2,3,4. INDEKSLER OLARAK CIKAR\n\n\"\"\"\n\nnpArray = np.array([10,20,30,40,50])\n\nprint(pd.Series(npArray))\n#burada pandas icine bir array serisi verebiliriz\n#burada print ettigimizde yine default olarak index karsiligini verir\n\"\"\"\n0    10\n1    20\n2    30\n3    40\n4    50\ndtype: int64\n\"\"\"\n\nprint(pd.Series(npArray,labels_list))\n#burada herbir deger karsisine indeksi vermis olduk\n\"\"\"\nmustafa    10\nkemal      20\nmurat      30\ntugce      40\ntugba      50\ndtype: int64\n\"\"\"\n\nprint(pd.Series(data=npArray, index=[\"A\",\"B\",\"C\",\"D\",\"E\"]))\n#burada da indexleri kendi istedgimiz gibi yazabiliriz\n\n\"\"\"\nA    10\nB    20\nC    30\nD    40\nE    50\ndtype: int64\n\n\"\"\"\n\ndataDict = {\"kadir\":30, \"kemal\":80,\"tugba\":60}\n#burada bir sozluk olusturup degerlerin karsiliklarini yazdik\nprint(pd.Series(dataDict))\n#bu sozlugu pandas serisi olarak yazdirabiliriz\n#asagidaki gibi vikti verir\n\n\n\"\"\"\nsozlukler sirali bir veritipi olmadigi icin karisik olarak cikmis oldu:\n\n\nkadir    30\nkemal    80\ntugba    60\ndtype: int64\n\n\"\"\"\n\nser2017=pd.Series([5,10,14,20],[\"bugday\",\"misir\",\"kiraz\",\"erik\"])\n\nprint(ser2017)\n\nser2018=pd.Series([2,12,12,6],[\"bugday\",\"misir\",\"cilek\",\"erik\"])\n\nprint(ser2018)\n\n#burada seriler arasinda \" cilek \" ve \" kiraz \"  farkli digerleri ayni\n\nprint(ser2018+ser2017)\n\n\"\"\"\nbugday     7.0\ncilek      NaN\nerik      26.0\nkiraz      NaN\nmisir     22.0\ndtype: float64\n\nORTAK OLMAYAN SERILERI TOPLAYAMAYACAGI ICIN \"NOT A NUMBER\" (NAN) HATASI ALMIS OLDUK\n\n\n\"\"\"\n\ntotal  = ser2018+ser2017\n\nprint(total[\"erik\"])#burada degerlerden sadece erik  e karsilik geleni almak istedigimizi soyluyoruz\n\n\"\"\"26.0\"\"\"  #cikti olarak sadece erik e karsilik gelen deger\n\nprint(total[\"cilek\"])\n#burada \"nan\" hatasinin ciktisini alacaktir","e507973b":"import pandas as pd\nimport numpy as np\n\nfrom numpy.random import randn\n\nprint(randn(3,3))#bruada negatif degerlerle beraber 3e3 bir matris olusturacak\n\n\"\"\"\nornek:\n[[ 3.05125875e-01  2.30795044e+00  7.93996435e-01]\n [-1.53363802e-01 -1.87714762e-01  7.93797135e-01]\n [-4.39728563e-01  1.91089607e-01 -2.02253836e-03]]\n \"\"\"\n\n#simdi burada 3e3 matristen birtane frame olusturacagiz\n\n\ndf = pd.DataFrame(data=randn(3,3),index=[\"A\",\"B\",\"C\"],columns=[\"column1\",\"column2\",\"column3\"])\n\nprint(df)\n\n\"\"\"\n\n   column1   column2   column3\nA -1.501969 -1.272858 -0.265564\nB  1.536454 -0.168669  0.083941\nC -0.618879 -0.205629  0.867064\n\nbu sekilde bir dataframe olusmus olur\n\naslinda serilerin birlesmis hali gibi dusunulebilir\n\nyani A,B,C satirlari birer seri\ncolumn1,column2,column3 sutunlari ayri birer seri olarak kullanilabilir\n\n\"\"\"\n#ornek olarak column1 i almak istersek\n\nprint(df[\"column1\"])\n\n\"\"\"\nA    1.492723\nB    0.407823\nC    0.592123\nName: column1, dtype: float64\n\nburda sadece colum1 e denk gelen degerleri almis olduk\n\"\"\"\n\nprint(type(df[\"column2\"]))\n#<class 'pandas.core.series.Series'>  burada turunun  seri oldugunu gorebiliriz\n\n#yani sonuc olarak dataframe ler serilerin birlesimi olarak dusunulebilir\n\n\n#BU SEFER A SATIRINI KULLANMAK ISTERSEK\n\nprint(df.loc[\"A\"]) #burada loc location in kisaltilmasi\n\n\n\"\"\"\ncolumn1   -0.953905\ncolumn2   -2.534302\ncolumn3    2.123128\nName: A, dtype: float64\n\ncolumn lar aslinda burda index gibi davrandi\n\ntype a bakarsak yine bunun seri oldugunu gorecegiz\n\n\n\"\"\"\n\n\nprint(df[[\"column1\",\"column2\"]])\n\n\"\"\"\nburda da kucuk bir dataframe olusmus oldu \n\n\n    column1   column2\nA -1.587557  1.081876\nB  1.074711 -0.701565\nC -1.114674  0.257387\n\n\n\"\"\"\n\n# DATAFRAME BIR TANE DAHA COLUMN EKLEMEK ISTERSEK\n\ndf[\"column4\"] = pd.Series(randn(3),[\"A\",\"B\",\"C\"])\n\nprint(df)\n\n\"\"\"\nburada yeni bir column un eklendigini goruruz\n\n \n    column1   column2   column3   column4\nA  0.241777  1.298464 -0.499235  1.585928\nB  0.654612  2.820911 -1.472475 -0.416358\nC -0.289617 -1.108525  0.453456 -0.062038\n\n\"\"\"\n\n\ndf[\"column5\"] = df[\"column1\"] + df[\"column2\"] + df[\"column3\"]\n\nprint(df)\n\n\"\"\"\ncolumn5 in yani 1-2-3 columnlarinin toplamini bu sekilde seriye ekleyebiliriz\n\n column1   column2   column3   column4   column5\nA -0.983716  0.764547 -0.387030 -0.672593 -0.606199\nB  0.431860 -0.382803  1.956575 -0.084792  2.005632\nC -0.136474 -0.208077 -0.021431  0.413457 -0.365983\n\n\"\"\"\n\n# BIR TANE SUTUNU YA DA COLUMN I SILME\n\nprint(df.drop(\"column5\" , axis=1))\n\n\"\"\"\ncolumn5 i silindigini gormus oluruzu burda\n\n column1   column2   column3   column4\nA  0.573660  0.493511 -0.099867 -0.138561\nB -0.959622 -0.502691 -0.498539  1.156420\nC -0.030925 -1.556798 -0.525098 -0.413382\n\n\"\"\"\n\nprint(df)\n#burada df yi tekrar yazdirirsak drop islemini yani silme islemini yaptiktan sonra\n#drop ettigimiz column5 in tekrar geri geldgini goruruz\n\n#icine bir parametre daha verirsek eger ancak kalici olarak silmis oluruz\n\nprint(df.drop(\"column5\",axis=1,inplace=True))\n#burada icine \"inplace=True\" parametresini verirsek bu sefer sil ve guncelle demis oluyoruz\n\nprint(df)\n\n\"\"\"\nburada silindigini gorebiliriz kalici olarakta guncellenmis olur\n\n    column1   column2   column3   column4\nA -0.174924 -0.159935 -0.106543  0.696225\nB -0.022623  0.834390  0.449900 -1.901480\nC  0.426884 -2.239874  0.856686  0.268647\n\n\n\"\"\"\n\n# INDEX E ERISMEK ICIN\n\nprint(df.loc[\"A\"])\n#sadece \"A\" satirindakileri almak icin\n\n\n\"\"\"\ncolumn1   -0.817550\ncolumn2    1.117828\ncolumn3   -1.097090\ncolumn4   -1.565289\nName: A, dtype: float64\n\n\"\"\"\n\nprint(df.iloc[0])\n#burada yine ayni sonucu verir\n\"\"\"\nyine a satirini aldigimiz gibi ayni sonucu aldik burada\n\n\ncolumn1   -0.091171\ncolumn2    0.332072\ncolumn3    0.012015\ncolumn4    1.016859\nName: A, dtype: float64\n\n\"\"\"\n\n\nprint(df.loc[\"A\",\"column1\"])\n#burda da \"A\" endexine karsilik gelen column sutunundaki degeri almak istersek\n\n\"\"\"\n-1.8590818436924574\n\nyine:\nornek:\n\ndf.loc[\"B\",\"column2\"]  desek bu seferde b nin column2 ye denk gelen degerini verir\n\n\n\"\"\"","7f256d0d":"import numpy as np\nimport pandas as pd\n\nfrom numpy.random import randn\n\n\nouterIndex =  [\"Group1\",\"Group1\",\"Group1\",\"Group2\",\"Group2\",\"Group\",\"Group3\",\"Group3\",\"Group3\"]\n\n\ninnerIndex = [\"Index1\",\"Index1\",\"Index1\",\"Index2\",\"Index2\",\"Index2\",\"Index3\",\"Index3\",\"Index3\"]\n\n\nzip(outerIndex,innerIndex)\n#burada zip fonksiyonunu kullaniyoruz\n#ve zip fonksiyonunu daha sonra listeye cevirebiliriz\n\n\nprint(list(zip(outerIndex,innerIndex)))\n\n\"\"\"\n\n[('Group1', 'Index1'), ('Group1', 'Index1'), ('Group1', 'Index1'), ('Group2', 'Index2'), ('Group2', 'Index2'), ('Group', 'Index2'), ('Group3', 'Index3'), ('Group3', 'Index3'), ('Group3', 'Index3')]\n\n\"\"\"\n\n#dataframe i gruplamak istersek\n\nhierarchy = list(zip(outerIndex,innerIndex))\n\n\nhierarchy = pd.MultiIndex.from_tuples(hierarchy)\n\nprint(hierarchy)\n\n\"\"\"\nMultiIndex([('Group1', 'Index1'),\n            ('Group1', 'Index1'),\n            ('Group1', 'Index1'),\n            ('Group2', 'Index2'),\n            ('Group2', 'Index2'),\n            ( 'Group', 'Index2'),\n            ('Group3', 'Index3'),\n            ('Group3', 'Index3'),\n            ('Group3', 'Index3')],\n           )\n           \n\"\"\"\n\ndf = pd.DataFrame(randn(9,3),hierarchy,columns=[\"column1\",\"column2\",\"column3\"])\n\nprint(df)\n\n\"\"\"\n                column1   column2   column3\nGroup1 Index1  1.269333 -0.398785 -0.571607\n       Index1 -0.400218 -0.538992 -0.906395\n       Index1 -0.756547  0.201318  1.018360\nGroup2 Index2 -1.403767 -0.156331 -0.660266\n       Index2  1.923512  0.648003  0.276761\nGroup  Index2  1.528844 -0.262915 -0.025348\nGroup3 Index3 -1.796768  2.367349  0.537825\n       Index3 -0.595885 -1.379446  0.389105\n       Index3  0.586776  1.258694 -1.312381\n       \n\"\"\"\n\n\nprint(df[\"column1\"])\n\n\"\"\"\nSADECE COLUMN1 E AIT VERILERI ALIR\n\n\nGroup1  Index1    0.888592\n        Index1    0.149276\n        Index1   -0.062622\nGroup2  Index2   -0.130522\n        Index2   -0.248451\nGroup   Index2    0.239760\nGroup3  Index3   -0.529793\n        Index3    1.130778\n        Index3    0.712903\nName: column1, dtype: float64\n\"\"\"\n\nprint(df.loc[\"Group1\"])\n\n\"\"\"\nBURADA DA SADECE GROUP1 ALINMIS OLDU\n        column1   column2   column3\nIndex1 -0.675209  0.567387 -0.400552\nIndex1 -0.714443 -1.631250 -0.860060\nIndex1 -0.893227  0.274972  0.319853\n\n\"\"\"\n\n#YANI DATAFRAME ILE IHTIYACA GORE PARCALAYIP KULLANABILIRIZ VERILERI\n\nprint(df.loc[[\"Group1\",\"Group2\"]])\n\n\"\"\"\nSADECE GROUP1 VE GROUP2 ALINIR\n\n               column1   column2   column3\nGroup1 Index1 -0.166519 -1.064305  1.522499\n       Index1  2.532445  0.612128 -0.257651\n       Index1  0.465853 -0.553955  0.142491\nGroup2 Index2  0.268160 -0.170358 -0.957564\n       Index2 -0.221887 -0.610284  1.888540\n\n\n\"\"\"\n\n#GROUP1 IN ICINDEKI INDEX 1 IN DEGERLERINI BULMAK ISTERSEK EGER\n\nprint(df.loc[\"Group1\"].loc[\"Index1\"])\n\n\"\"\"\nyani sadece index1 i almis olduk\n\n       column1   column2   column3\nIndex1  0.893492  1.563686  0.123854\nIndex1  0.480956  1.861047  1.081648\nIndex1  1.185695  0.354632  0.392441\n\n\"\"\"\n\nprint(df.loc[\"Group1\"].loc[\"Index1\"][\"column1\"])\n\ndf.index.names= [\"Groups\",\"Index\"]\n\nprint(df)\n\n\n\"\"\"\nburda grouplara Groups ismini indexlere de Index ismini vermis olduk\n\n\n                column1   column2   column3\nGroups Index                               \nGroup1 Index1 -0.973220  1.061227 -0.980360\n       Index1 -0.297062 -1.447446  0.965287\n       Index1 -0.483209 -0.057918  0.715275\nGroup2 Index2 -1.799557 -1.043056  0.248148\n       Index2  1.357227  0.918505 -0.190696\nGroup  Index2  0.861682 -0.865498  0.177148\nGroup3 Index3 -1.622727  0.545117 -2.034281\n       Index3 -1.084391 -0.130436 -1.968499\n       Index3 -0.200170  0.328910 -1.009514\n\n\n\"\"\"\n\nprint(df.xs(\"Group1\"))\n\n\"\"\"\n     column1   column2   column3\nIndex                               \nIndex1 -0.401660 -0.004233 -1.454002\nIndex1  0.400219 -0.339027  1.815558\nIndex1 -0.028161 -2.415524 -0.344498\n\n\n\"\"\"\n\nprint(df.xs(\"Group2\").xs(\"Index2\"))\n\n\nprint(df.xs(\"Index1\",level= \"Index\"))\n#burada sadece gruplarin index1 lerini almak istedigimizi soyluyoruz","8d5cf892":"import numpy as np\nimport pandas as pd\n\narr = np.array([[10,20,np.nan],[5,np.nan,np.nan],[21,np.nan,10]])\n\n#burada ornek olmasi acisindan icerisinde not a number (nan) degerler verdik\n\nprint(arr)\n\n\"\"\"\n\n[[10. 20. nan]\n [ 5. nan nan]\n [21. nan 10.]]\n\n\"\"\"\n\n#buradaki arrayden bir dataframe olusturuyoruz\n\ndf=pd.DataFrame(arr,index=[\"Index1\",\"Index2\",\"Index3\"],columns=[\"Column1\",\"Column2\",\"Column3\"])\n#dataframe icin serilerin birlesmis hali diyebiliriz\n\n\nprint(df)\n\n\"\"\"\n        Column1  Column2  Column3\nIndex1     10.0     20.0      NaN\nIndex2      5.0      NaN      NaN\nIndex3     21.0      NaN     10.0\n\n\"\"\"\n\n#NaN olan verileri silmek icin \"df.dropna\" metodunu kullanabiliriz\n\ndf.dropna()\n#burada axis=0 oldugu zaman index yani satira gore axis=1 oldugu zaman column yani sutuna gore siler\n#yani burda index1,index2,index3 e bakicak NaN varmi yokmu?-varsa satirlari silecek\n\nprint(df.dropna())\n\n\"\"\"\nColumns: [Column1, Column2, Column3]\nIndex: []\n\nsilinmis hali bu sekilde olacaktir\n\nburda index e gore silmis olduk NaN olan satirlari\n\n\n\"\"\"\n\n#column a gore de silebiliriz\n\ndf.dropna(axis=1)\n#icine parametre olarak \"axis=1\" dersek bu sefer sutun yani column a gore siler\n#icine birsey vermezsek otomatik \"axis=0\" olarak aldigi icin yani satirlari siler (indexleri yani)\n\nprint(df.dropna(axis=1))\n\n\"\"\"\n       Column1\nIndex1     10.0\nIndex2      5.0\nIndex3     21.0\n\n-sadece column1 de NaN olmadigi icin digerleri silinmis oldu yani\n\n\"\"\"\n\n\"\"\"\nozet olarak\naxis=0 oldugu zaman satirlari (indexleri) siler\naxis=1 oldugu zaman sutunlari(columnlari) siler\n\"\"\"\n\n#eger bir satirda ki butun verileri silmek istemiyorsak \"thresh\" parametresini kullanabiliriz\n#yani satirda 2 tane normal veri var bir tane NaN var diyelim o zaman silme tut komutu verebilirizi\n\ndf.dropna(thresh=2)\n#yani burada satirda 2 tane sayi varsa tut silme demis oluyoruz\n\nprint(df.dropna(thresh=2))\n\n\"\"\"\n         Column1  Column2  Column3\nIndex1     10.0     20.0      NaN\nIndex3     21.0      NaN     10.0\n\ngoruldugu gibi burada  satirdaki 2 tane sayi olan yeryerler silinmemis duruyor icinde NaN olmasina ragmen\n\"\"\"\n\n\n# \"NaN\" degerleri yerine bir deger eklemek icin \"fillna\" yi kullanabiliriz(icinede deger vermemiz gerekiyor)\n# fillna(value= buraya ne deger vermek istersek onu yaziyoruz)\n\nprint(df.fillna(value=1))\n# 1 degerini verirsen NaN olan heryere 1 degeri gelir\n\n\"\"\"\n        Column1  Column2  Column3\nIndex1     10.0     20.0      1.0\nIndex2      5.0      1.0      1.0\nIndex3     21.0      1.0     10.0\n\nburada NaN degeerleri yerine 1 gelmis oldu\n\n\n\n\"\"\"\n\n# NaN larin yerin dataframe icindeki tum sayilarini ortalamasini vermek istersek eger\n\n#bunun icin once tum degerleri toplamamiz lazim ortalama degerini bulmak icin. yani first step degerleri toplamak\n\nprint(df.sum())\n\n\"\"\"\nColumn1    36.0\nColumn2    20.0\nColumn3    10.0\ndtype: float64\n\n#sayilari toplayip birer seri haline donusturmus oldu\n\"\"\"\n\n# daha sonraki adim olarak gostermek istersek bu serileride toplayip tek bir sayi haline getirmek gerekiyor onun icinde:\n\nprint(df.sum().sum())\n#yani burada yukaridaki seri haline getiriyor sonra o serileride toplayip tek bir seri haline getir komutunu vermis oluyoruz\n\n\"\"\"\n66.0\n\ncikan sonuc tum sayilarin toplami \n\n\"\"\"\n\n#next step olarakta NaN lari saymazsak 5 tane normal verimiz var toplam 9 veri var NaN lar iler beraber\n# toplam veri sayisini bulmak icin \"size\" fonksiyonunu kullaniyoruz\n\n\nprint(df.size)\n\n\"\"\"\n9\n#toplamda 9 veri var yani\n\n\"\"\"\n\n# kac tane NaN veri oldugunu bulmak icin ise \"isnull\" metodunu kullaniyoruz\n\nprint(df.isnull().sum())\n#kac tane NaN oldugunu \"isnull\" ile buluyoruz kac tane oldugunu bulmak icin \"sum\" ile toplamina bakiyoruz\n\n\"\"\"\nColumn1    0\nColumn2    2\nColumn3    2\ndtype: int64\n\nhangi columnda kac tane NaN var toplami\n\n\"\"\"\n\nprint(df.isnull().sum().sum())#yine birtane daha \"sum()\" eklersek genel toplamini bulmus oluruzu\n\"\"\"\n4\nyani genel toplam NaN sayisi\n\nstep by step bakarsak asamalara daha basit ve anlasilabilir olur...\n\n\"\"\"\n\n# 9 dan 4 u cikarirsek kac tane normal degerimiz oldgunu bulabiliriz\n#bunun icin gerekli fonksiyon:\n\ndef calculateMean(df):\n    totalSum = df.sum().sum()\n    totalNum = df.size - df.isnull().sum().sum()\n\n    return totalSum\/totalNum\n\n#yani burda total summary yani genel sayilarin toplamini bulduk\n#daha sonra size dan yani kac tane veri varsa ordan(9 adet veri) toplam NaN veri sayisini cikarttik\n#daha sonra toplami sayilarin toplam veri sayisina bolduk\n#yani once sayilarin toplamini bulduk daha sonra genel ortalamayi aradigimiz icin buldugumuz toplami kac tane sayi varsa one bolduk\n\n\n# simdi NaN larin yerine buldugumuz ortalamalari koymak icin \"value=calculateMena\" fonksiyonunu yazmamiz lazim\n\nprint(df.fillna(value=calculateMean(df)))\n\n\"\"\"\n        Column1  Column2  Column3\nIndex1     10.0     20.0     13.2\nIndex2      5.0     13.2     13.2\nIndex3     21.0     13.2     10.0\n\n#burada gordugumuz gibi NaN larin yerine buldugumuz ortalamalari koymus olduk\n\n\n\"\"\"","c608bb75":"# BURADA DATAFRAME DE KI GROUPBY SORGULARI CALISILMISTIR\n# SQL TABLOLARINDA KI GROUPBY ILE BIREBIR AYNI!\n\nimport numpy as np\nimport pandas as pd\n\ndataset = {\n        \"Departman\":[\"Bili\u015fim\",\"\u0130nsan Kaynaklar\u0131\",\"\u00dcretim\",\"\u00dcretim\",\"Bili\u015fim\",\"\u0130nsan Kaynaklar\u0131\"],\n        \"\u00c7al\u0131\u015fan\": [\"Mustafa\",\"Jale\",\"Kadir\",\"Zeynep\",\"Murat\",\"Ahmet\"],\n        \"Maa\u015f\":[3000,3500,2500,4500,4000,2000]\n        }\n\n#dataset i dataframe'e ceviriyoruz burada\ndf = pd.DataFrame(dataset)\n\nprint(df)\n\n\"\"\"\n          Departman  \u00c7al\u0131\u015fan  Maa\u015f\n0           Bili\u015fim  Mustafa  3000\n1  \u0130nsan Kaynaklar\u0131     Jale  3500\n2            \u00dcretim    Kadir  2500\n3            \u00dcretim   Zeynep  4500\n4           Bili\u015fim    Murat  4000\n5  \u0130nsan Kaynaklar\u0131    Ahmet  2000\n\n#burada gordugumuz gibi dataset icinde verilenleri dataframe e cevirmis olduk\n#tablo yapisi olusturduk yani\n\"\"\"\n\n# olusturdugumuz dataframe uzerinde \"groupby\" islemlerini yapmaya baslayabiliriz\n# ornek olarak \"groupby\" ile departman uzerinde islemler yapalim\n\nDepGroup = df.groupby(\"Departman\")# \"DepGroup\" adli degiskene atadik\n# \"Departman\" a gore islemk yapmak istedigimiz icin icine onu atiyoruz\n\nprint(DepGroup)\n\n\"\"\"\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x10cd1c208>\n\n#calistirdigimizda bize boyle bir obje doner\n\n#artik biz bu objenin uzerinde\n-toplama\n-min deger bulma\n-ortalama deger bulma gibi islemleri yapabiliriz\n\n\n\"\"\"\n\nprint(DepGroup.sum())\n\n\"\"\"\n                  Maa\u015f\nDepartman             \nBili\u015fim           7000\n\u00dcretim            7000\n\u0130nsan Kaynaklar\u0131  5500\n\n#burada departmanlara gore toplam maaslari bir araya getirmis olduk\n\"\"\"\n\n#islemi daha kisa yapabiliriz\n\nprint(df.groupby(\"Departman\").sum())\n#yine ayni sonucu verir\n\n#sadece tek bir sektorun toplamini almak istersek\n\n\nprint(df.groupby(\"Departman\").sum().loc[\"Bili\u015fim\"])\n\"\"\"\nMaa\u015f    7000\nName: Bili\u015fim, dtype: int64\n\n#sadece bilisim departmaninin maaslarinin toplamini almis olduk\n\n\"\"\"\n# toplam cikan maas sonucunu integer e cevirip tek bir sayi olarak ciktisini alabiliriz\n#yapmamiz gereken tek sey basina \"int\" yazmak\n\nprint(int(df.groupby(\"Departman\").sum().loc[\"Bili\u015fim\"]))\n\"\"\"\n7000\n#sadece 7000 olarak cikti verecektir\n\n\"\"\"\n\n# \"sum\" yerine \"count\" fonksiyonunu kullanirsak\n\nprint(df.groupby(\"Departman\").count())\n\"\"\"\n                  \u00c7al\u0131\u015fan  Maa\u015f\nDepartman                      \nBili\u015fim                 2     2\n\u00dcretim                  2     2\n\u0130nsan Kaynaklar\u0131        2     2\n\n#bu sefer departmanlarda calisan sayisini bulmus oluyoruz\n\n\"\"\"\n\n# \"max\" degeri kullanimi\n\nprint(df.groupby(\"Departman\").max())\n\n\"\"\"\n                  \u00c7al\u0131\u015fan  Maa\u015f\nDepartman                      \nBili\u015fim           Mustafa  4000\n\u00dcretim             Zeynep  4500\n\u0130nsan Kaynaklar\u0131     Jale  3500\n\n#departmanlarda calisan en fazla maas alanlarin ciktisini verir bu sekilde\n#isim siralamsida sozlukteki buyukluge gore gerceklesiyor\n\n\"\"\"\n\n# \"min\" deger kullanimi\n\nprint(df.groupby(\"Departman\").min())\n\n\"\"\"\n                \u00c7al\u0131\u015fan  Maa\u015f\nDepartman                     \nBili\u015fim            Murat  3000\n\u00dcretim             Kadir  2500\n\u0130nsan Kaynaklar\u0131   Ahmet  2000\n\n\"\"\"\n# sadece maas degerlerini almak istersek yani isimleri almadan\n\nprint(df.groupby(\"Departman\").min()[\"Maa\u015f\"])\n\n\"\"\"\nDepartman\nBili\u015fim             3000\n\u00dcretim              2500\n\u0130nsan Kaynaklar\u0131    2000\nName: Maa\u015f, dtype: int64\n\n#sadece maaslari aldik isimler cikartilmis oldu\n\n\"\"\"\n\n#dataframe uzerinde adim adim giderek islemlerimizi gerceklestirebiliiriz yani\n#ornegin sadece bilisim departmanini almak istersek\n\n\nprint(df.groupby(\"Departman\").min()[\"Maa\u015f\"][\"Bili\u015fim\"])\n\n\"\"\"\n3000\n\n#sadece bilisim dep. ciktisini verir\n\n\"\"\"\n\n#toplam maaslarin ortalmasini bulmak istersek eger\n\nprint(df.groupby(\"Departman\").mean())#buradaki \"mean\" ortalama bulmak icin kullandigimiz fonksiyon\n\"\"\"\n\n                  Maa\u015f\nDepartman             \nBili\u015fim           3500\n\u00dcretim            3500\n\u0130nsan Kaynaklar\u0131  2750\n\n#ortalama maaslarin ciktisi\n\"\"\"\n#yine adim adim istedgimiz gibi analiz edebiliriz\n\nprint(df.groupby(\"Departman\").mean()[\"Maa\u015f\"][\"\u0130nsan Kaynaklar\u0131\"])\n\n\"\"\"\n2750\n\n#burda sadece insan kaynaklari departmanini ortalama maasini almis olduk yani\n\n\n\"\"\"","59898579":"import numpy as np\nimport pandas as pd\n\n#concatenate: eklemek anlamina geliyor. 2 tane dataframe i istersek index e gore istersekte column a gore birbirine ekleyebiliyoruz\n\ndataset1 = {\n    \"A\": [\"A1\",\"A2\",\"A3\",\"A4\"],\n    \"B\":[\"B1\",\"B2\",\"B3\",\"B4\"],\n    \"C\":[\"C1\",\"C2\",\"C3\",\"C4\"],\n}\n\ndataset2 = {\n    \"A\": [\"A5\",\"A6\",\"A7\",\"A8\"],\n    \"B\":[\"B5\",\"B6\",\"B7\",\"B8\"],\n    \"C\":[\"C5\",\"C6\",\"C7\",\"C8\"],\n}\n\n#simdi bu datasetlerden dataframe olusturuyoruyz\n\ndf1 = pd.DataFrame(dataset1,index = [1,2,3,4])\ndf2 = pd.DataFrame(dataset2,index = [5,6,7,8] )\n\nprint(df1)\n\n\"\"\"\n A   B   C\n1  A1  B1  C1\n2  A2  B2  C2\n3  A3  B3  C3\n4  A4  B4  C4\n\"\"\"\n\nprint(df2)\n\n\"\"\"\n  A   B   C\n5  A5  B5  C5\n6  A6  B6  C6\n7  A7  B7  C7\n8  A8  B8  C8\n\n\"\"\"\n\n#dataframe lerimizi olusturduk\n\n#bunlari birbirine eklemek icin \"concat\" metodunu kullaniyoruz\n\nprint(pd.concat([df1,df2]))\n\n\"\"\"\n    A   B   C\n1  A1  B1  C1\n2  A2  B2  C2\n3  A3  B3  C3\n4  A4  B4  C4\n5  A5  B5  C5\n6  A6  B6  C6\n7  A7  B7  C7\n8  A8  B8  C8\n\n#index lere gore topladigimiz zaman bu sekilde oluyor\n# 2 tane dataframe i toplamak icin birbirlerine benzemesi lazim\n#axis=0 a gore boyle toplama\n\"\"\"\n\n# column lari toplamak icin yine axis=1 yapmamiz lazim\n\nprint(pd.concat([df1,df2],axis=1))\n\n\"\"\"\n     A    B    C    A    B    C\n1   A1   B1   C1  NaN  NaN  NaN\n2   A2   B2   C2  NaN  NaN  NaN\n3   A3   B3   C3  NaN  NaN  NaN\n4   A4   B4   C4  NaN  NaN  NaN\n5  NaN  NaN  NaN   A5   B5   C5\n6  NaN  NaN  NaN   A6   B6   C6\n7  NaN  NaN  NaN   A7   B7   C7\n8  NaN  NaN  NaN   A8   B8   C8\n\n#columnlari toplanmasi sonucunda toplanamayan degerler NaN olarak cikiyor\n\n\n\"\"\"\n\n# join metodu icin ornekler:\n\ndataset3 = {\n    \"X\" : [\"X1\",\"X2\",\"X3\",\"X4\"],\n    \"Y\" : [\"Y1\",\"Y2\",\"Y3\",\"Y4\"],\n    \"anahtar\" : [\"K1\",\"K2\",\"K5\",\"K4\"]\n}\n\n#yine burda datasetimizi dataframe e ceviriyoruz\n\ndf3 = pd.DataFrame(dataset3,index= [1,2,3,4])\n\nprint(df3)\n\nprint(df3.join(df1))\n\n\"\"\"\n    X   Y anahtar   A   B   C\n1  X1  Y1      K1  A1  B1  C1\n2  X2  Y2      K2  A2  B2  C2\n3  X3  Y3      K5  A3  B3  C3\n4  X4  Y4      K4  A4  B4  C4\n\n\n\"\"\"","4821f74b":"import numpy as np\nimport pandas as pd\n\n# MERGE ISLEMINDE DATAFRAMELERIN ORTAK OLAN DEGERLERINI ALIP YENI BIR DATAFRAME OLUSTURMAK OLARAK TANIMLAYABILIRIZ\n# YANI 2 KUME DUSUNUN ORTAK ELEMANLARINDAN OLUSTURDUGUMUZ KUME MERGE ISLEMIYLE ALIDIGIMIZ DEGERLERE ESIT\n\ndataset1 = {\n    \"A\" : [\"A1\",\"A2\",\"A3\"],\n    \"B\" : [\"B1\",\"B2\",\"B3\"],\n    \"anahtar\" : [\"K1\",\"K2\",\"K3\"]\n}\n\ndataset2 = {\n    \"X\" : [\"X1\",\"X2\",\"X3\",\"X4\"],\n    \"Y\" : [\"Y1\",\"Y2\",\"Y3\",\"Y4\"],\n    \"anahtar\" : [\"K1\",\"K2\",\"K5\",\"K4\"]\n}\n\n# datasetlerimizi yazdik sonrasinda dataframlerimizi olusturuyoruz\n\ndf1 = pd.DataFrame(dataset1,index = [1,2,3])\n\ndf2 = pd.DataFrame(dataset2,index = [1,2,3,4])\n\n\n\nprint(df1)\n\n\"\"\"\n    A   B anahtar\n1  A1  B1      K1\n2  A2  B2      K2\n3  A3  B3      K3\n\n\"\"\"\n\nprint(df2)\n\n\"\"\"\n   X   Y anahtar\n1  X1  Y1      K1\n2  X2  Y2      K2\n3  X3  Y3      K5\n4  X4  Y4      K4\n\n\"\"\"\n\n#BURADA birtane \"anahtar\" column una gore dataframeleri birlestirecegiz\n\n# burada \"anahtar\" column una gore islem gerceklestirdigimiz zaMAN \"K1\" ve \"K2\" satirlarinin ortak oldugunu goruyoruz\n\n\"\"\"\n        FARK\n\nJOIN : indexler uzerinden \nMERGE : columnlar uzerinden yapilir\n\n\"\"\"\n\nprint(pd.merge(df1,df2,on = \"anahtar\"))\n#burda onemli olana \"on\" parametresi \"on\" parametresine \" anahtar\" i yazdigimizda o zamana \" anahtar kelimesine gore islem yapar\n\n\"\"\"\n   A   B anahtar   X   Y\n0  A1  B1      K1  X1  Y1\n1  A2  B2      K2  X2  Y2\n\nBu sekilde \"anahtar kelimesine gore columnlari ortak alarak islem yapilir\n\n\"\"\"","a3e6c465":"import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    \"Column1\":[1,2,3,4,5,6],\n    \"Column2\":[100,100,200,300,300,100],\n    \"Column3\":[\"Mustafa\",\"Kamil\",\"Emre\",\"Ay\u015fe\",\"Murat\",\"Zeynep\"]\n})\n\n#modullerimizi dahil ettikten sonra dataframemiz olusturuyoruz\n\nprint(df)\n\n\"\"\"\n   Column1  Column2  Column3\n0        1      100  Mustafa\n1        2      100    Kamil\n2        3      200     Emre\n3        4      300     Ay\u015fe\n4        5      300    Murat\n5        6      100   Zeynep\n\n\"\"\"\n\n# \"head\" kullanimi --> \"head(n = 3)\" burda \" n=3 \" dersek sadece ilk 3 satiri alir!\n# anlasilacagi uzere \"n\" e verdigimiz degere gore alinacak satir sayisi belirlenir\n\nprint(df.head(n=3))\n\n\"\"\"\n Column1  Column2  Column3\n0        1      100  Mustafa\n1        2      100    Kamil\n2        3      200     Emre\n\ngoruldugu gibi burada sadece ilk 3 satir alinmis olur\n\n\"\"\"\n\n# dataframe icinde birbirini tekrar eden degerler var. Kac tane farkli deger var onu gormek icin:\n# Kullanacagimiz fonksiyon: \"unique\"\n\nprint(df[\"Column2\"].unique())\n\n\"\"\"\n\n[100 200 300]\n\n\"\"\"\n\n# \"unique\" degerlerin kac adet oldugunu bulmak icin ise: \"nunique\" fonksiyonu kullaniyoruz\n\nprint(df[\"Column2\"].nunique())\n\n\"\"\"\n3\ntoplamda birbirinden farkli toplamda 3 adet unique yani essiz deger var\n\n\"\"\"\n\n# \"value_count\" fonksiyonu islevi\n\nprint(df[\"Column2\"].value_counts())\n\n\"\"\"\n00    3\n300    2\n200    1\nName: Column2, dtype: int64\n\nburada Column2 icinde hangi degerden kacar adet oldugunu verir bu fonksiyon\n\n\"\"\"\n\n\n# Ornekleri cesitlendirerek ogrenmek acisindan; \"Column1\" deki 4 ten buyuk degerleri ve 300 olan degerleri nasil buluruz\n# burada dataframe filtreleme islemleri yapacagiz\n\nprint(df[df[\"Column1\"] >=4])\n\n\"\"\"\n Column1  Column2 Column3\n3        4      300    Ay\u015fe\n4        5      300   Murat\n5        6      100  Zeynep\n\nburdq 4 ten buyuk degerler gelmis oldu\n\n\"\"\"\n\n#ayni zamanda son ornege ek olarak bir sart koyabiliriz ornegin \"column2\" de ki degerler de 300 olacak sekilde al diyebiliriz\n\nprint(df[(df[\"Column1\"] > 2) & (df[\"Column2\"] == 300)])\n\n\"\"\"\n Column1  Column2 Column3\n3        4      300    Ay\u015fe\n4        5      300   Murat\n\n\"\"\"\n\n# Column2 de ki butun degerleri bir sayi ile carpmak istersek eger:\n# Column2 de ki her degerin uzerinde bir fonksiyon uygulamamiz lazim\n# Bunun icinde pandas da ki \"apply\" fonksiyonunu kullanacagiz\n\ndef times3(x):\n    return x * 3\n#fonksiyonumuzu yazdik\n\nprint(times3(3))\n\"\"\"\n9\n\nfonksiyon bu sekilde caliscak icine aldigi degeri 3 le carpar \n\n\"\"\"\n#simdi bu fonksiyonu \"Column2\" deki herbir degere uygulamak icin yapmamiz gereken:\n\nprint(df[\"Column2\"])\n\n\"\"\"\n0    100\n1    100\n2    200\n3    300\n4    300\n5    100\nName: Column2, dtype: int64\n\nnormalde \"column2\" bu sekilde\n\"\"\"\nprint(df[\"Column2\"].apply(times3))\n\n\"\"\"\n0    300\n1    300\n2    600\n3    900\n4    900\n5    300\nName: Column2, dtype: int64\n\n\"Column2\" de ki butun degerleri goruldugu gibi 3 ile carpmis olduk\n\n\"\"\"\n# Eger ki \"Column2\" yi son halinde aldigi degerler ile guncellemek istersem:\n\ndf[\"Column2\"] = df[\"Column2\"].apply(times3)\n\nprint(df[\"Column2\"])\n\n\"\"\"\n0    300\n1    300\n2    600\n3    900\n4    900\n5    300\nName: Column2, dtype: int64\n\n\"Column2\" yi yeni degerlerine guncellemis olduk yani artik 3 ile carpilmis haline guncellenmis oldu\n\"\"\"\n\n# \"lambda\" fonksiyonunu kullanarak islem yaoma( lambda : fonksiyon olusturmak icin kullaniyoruz \"def\" yerine tek satirda yazilabilir\n\nprint(df[\"Column2\"].apply(lambda x : x*2))\n\n\"\"\"\n0     600\n1     600\n2    1200\n3    1800\n4    1800\n5     600\nName: Column2, dtype: int64\n\nBurada goruldugu gibi ayri bir fonksiyon olusturup eklemek yerine direkt \"lambda\" ile halledilebilir\n\n\"\"\"\n\n# \"len\" fonksiyonu ornek:\n\nprint(df[\"Column3\"].apply(len))\n\n\"\"\"\n0    7\n1    5\n2    4\n3    4\n4    5\n5    6\nName: Column3, dtype: int64\n\n\"column3\" teki stringlerin uzunluklarini \"len\" ile tek tek gormus olduk\n    \n\"\"\"\n\n# Columnlardan birini silmek istersek: \"drop\" fonksiyonunu kullaniyoruz\n\n# columnlarin oldugu axis=1 olmasi lazim satirlarin oldugu axis=0\n\nprint(df.drop(\"Column3\",axis=1))\n\n\"\"\"\n   Column1  Column2\n0        1      300\n1        2      300\n2        3      600\n3        4      900\n4        5      900\n5        6      300\n\nColumn3 burda silinmis oldu\n\n\n\"\"\"\n\n# eger burda silme islemini gerceklestirdikten sonra son haline guncellemek istersek \"inplace = True\" parametresini yazmamis lazim\n\nprint(df.drop(\"Column3\",axis=1 , inplace=True))\n\n#son haliyle \"Column3\" silinmis haline yani guncellenmis oldu dataframe\n\n\n# dataframe uzerinde kac tane sutun yani calumn oldugunu bulmak icin:\n\nprint(df.columns)\n\n\"\"\"\n\nIndex(['Column1', 'Column2'], dtype='object')\n\nbu sekilde cikti verir\nbunu ozellikle buyuk veri setlerinde kullaniyoruz\n\n\"\"\"\n# dataframe icinde kac tane satir yani index oldugunu bulmak icin\n\nprint(df.index)\n\n\"\"\"\n\nRangeIndex(start=0, stop=6, step=1)\n\n\"\"\"\nprint(len(df.index))\n\n\"\"\"\n6 ciktisini verir\n\nkac tane satir oldugunu \"len\" fonksiyonu ile bulabiliriz\n\n\"\"\"\n\n# indexlerini isimlerine bakmak icin:\n\nprint(df.index.names)\n\n\"\"\"\nburada: \"[None]\" ciktisini verecektir cunku dataframe e baktigimizda indexklerin isimleri olmadigini gorecegiz\n\"\"\"\n\n# bu arada dataframe in son haline bakalim\n\nprint(df)\n\n\"\"\"\nColumn1  Column2\n0        1      300\n1        2      300\n2        3      600\n3        4      900\n4        5      900\n5        6      300\n\n\"\"\"\n\n# dataframe i column a gore \"kucukten buyuge\" dogru siralamak icin:\n\nprint(df.sort_values(\"Column2\"))\n\n\"\"\"\n   Column1  Column2\n0        1      300\n1        2      300\n5        6      300\n2        3      600\n3        4      900\n4        5      900\n\n\"\"\"\n\n# \"buyukten kucuge\" dogru siralamak istersek eger: normalde \"sort_value\" fonks kullandigimizda icinde \"ascending = True\" default olarak verir\n# \"ascending = False\" olarak degistirirsek eger o zaman buyukten kucuge dogru siralar\n\nprint(df.sort_values(\"Column2\",ascending=False))\n\n\"\"\"\n   Column1  Column2\n3        4      900\n4        5      900\n2        3      600\n0        1      300\n1        2      300\n5        6      300\n\n\"\"\"\n\n#buraya kadar kullanilan operasyonlar \"data mining\" isinde cok kullanilan operasyonlar\n\n# \"PIVOT TABLE\" mantigi\ndf2 = pd.DataFrame({\n    \"Ay\" : [\"Mart\",\"Nisan\",\"May\u0131s\",\"Mart\",\"Nisan\",\"May\u0131s\",\"Mart\",\"Nisan\",\"May\u0131s\"],\n    \"\u015eehir\":[\"Ankara\",\"Ankara\",\"Ankara\",\"\u0130stanbul\",\"\u0130stanbul\",\"\u0130stanbul\",\"\u0130zmir\",\"\u0130zmir\",\"\u0130zmir\"],\n    \"Nem\":[10,25,50,21,67,80,30,70,75]\n})\n\nprint(df2)\n\n\"\"\"\n    Ay     \u015eehir  Nem\n0   Mart    Ankara   10\n1  Nisan    Ankara   25\n2  May\u0131s    Ankara   50\n3   Mart  \u0130stanbul   21\n4  Nisan  \u0130stanbul   67\n5  May\u0131s  \u0130stanbul   80\n6   Mart     \u0130zmir   30\n7  Nisan     \u0130zmir   70\n8  May\u0131s     \u0130zmir   75\n\n\"\"\"\n\n# burada yapmak istedigimiz sey bu dataframe i daha guzel,toplu gostermek(yani programlama mantigida budur zaten kolaylastirmak)\n\n#bu dataframe uzerinden bir pivot table olusturacagiz once\n\nprint(df2.pivot_table(index = \"\u015eehir\",columns =\"Ay\",values = \"Nem\"))\n\n\"\"\"\nAy        Mart  May\u0131s  Nisan\n\u015eehir                       \nAnkara      10     50     25\n\u0130stanbul    21     80     67\n\u0130zmir       30     75     70\n\nyani buradaki amac dataframe i daha toplu duzgun bir hale getirmek\n\"\"\"\n\n# baska sekilde column ve indexlerin yerini degistirerekte yazmamiz mumkun\n\nprint(df2.pivot_table(index = \"Ay\",columns =\"\u015eehir\",values = \"Nem\"))\n\n\"\"\"\u015eehir  Ankara  \u0130stanbul  \u0130zmir\nAy                            \nMart       10        21     30\nMay\u0131s      50        80     75\nNisan      25        67     70\n\n\"\"\"","64b01833":"import pandas as pd\nimport numpy as np\n\n# you can use datas from kaggle as \"csv\"\n# https:\/\/www.kaggle.com\/datasnaek\/youtube-new  this is the link that i am usind data from kaggle\n# and when you download data which is \"USvideos.csv\" it must be in same folder\n# \"USvideos.csv\" is in my folder already\n\ndataset = pd.read_csv(\"USvideos.csv\")\n\nprint(dataset)\n\n# when you print out dataset its gonna look like this:\n\n\"\"\"\n          video_id  ...                                        description\n0      2kyS6SvSYSE  ...  SHANTELL'S CHANNEL - https:\/\/www.youtube.com\/s...\n1      1ZAPwfrtAFY  ...  One year after the presidential election, John...\n2      5qpjK5DgCt4  ...  WATCH MY PREVIOUS VIDEO \u25b6 \\n\\nSUBSCRIBE \u25ba http...\n3      puqaWrEC7tY  ...  Today we find out if Link is a Nickelback amat...\n4      d380meD0W0M  ...  I know it's been a while since we did this sho...\n...            ...  ...                                                ...\n23357  pH7VfJDq7f4  ...  ...and other musings on thermal movement of la...\n23358  hV-yHbbrKRA  ...  Visit Our Website! \u25b6 http:\/\/www.townsends.us\/ ...\n23359  CwKp6Xhy3_4  ...  Chris Young's Hangin' On from his #1 album Los...\n23360  vQiiNGllGQo  ...  very wholesome stuff.\\n\\nThis video was taken ...\n23361  2afSbqlp5HU  ...  The new marvel film Black Panther is set in th...\n\n[23362 rows x 16 columns]\n\nthere are 23362 index and 16 columns in this dataset\n\"\"\"\n\n# if you wanna delete some things from this dataset you need to yous \"drop\" function and if you wanna delete from column you have to write \"axis=1\" alos\n# if you wanna delete some things from index(row) you do not have to write anything because its axis=0 a=s default already\n\nnewdataset1 = dataset.drop([\"video_id\",\"trending_date\"],axis = 1)\n\n# when you look at \"the newdataset1\" you will see there is no \"video_id\",\"trending_date\" anymore\n\nprint(newdataset1)\n\n\"\"\"\n                                                  title  ...                                        description\n0                     WE WANT TO TALK ABOUT OUR MARRIAGE  ...  SHANTELL'S CHANNEL - https:\/\/www.youtube.com\/s...\n1      The Trump Presidency: Last Week Tonight with J...  ...  One year after the presidential election, John...\n2      Racist Superman | Rudy Mancuso, King Bach & Le...  ...  WATCH MY PREVIOUS VIDEO \u25b6 \\n\\nSUBSCRIBE \u25ba http...\n3                       Nickelback Lyrics: Real or Fake?  ...  Today we find out if Link is a Nickelback amat...\n4                               I Dare You: GOING BALD!?  ...  I know it's been a while since we did this sho...\n...                                                  ...  ...                                                ...\n23357                                Why Bridges Move...  ...  ...and other musings on thermal movement of la...\n23358                      Macaroni - A Recipe From 1784  ...  Visit Our Website! \u25b6 http:\/\/www.townsends.us\/ ...\n23359                           Chris Young - Hangin' On  ...  Chris Young's Hangin' On from his #1 album Los...\n23360      Elderly man making sure his dog won't get wet  ...  very wholesome stuff.\\n\\nThis video was taken ...\n23361         How to speak like Black Panther - BBC News  ...  The new marvel film Black Panther is set in th...\n\n[23362 rows x 14 columns]\n\nas you can see \"video_id\",\"trending_date\" columns dropped (deleted) from dataset\nand there is 14 column after that\n\n\"\"\"\n\n# we created new dataset \"as newdataset\". if you wanna write this dataset as csv :\n\nnewdataset1.to_csv(\"UsVideosNew.csv\")\n\n# we created new csv in folder now wherever is your location\n\n# if you do not wanna take indexes: the purpose is here making this code,app,programme(whatever) better and easier\n\nnewdataset1.to_csv(\"UsVideosNew.csv\" , index=False)\n\nprint(newdataset1)\n\n# that will be look better than last one\n\n\"\"\"\n                                                  title  ...                                        description\n0                     WE WANT TO TALK ABOUT OUR MARRIAGE  ...  SHANTELL'S CHANNEL - https:\/\/www.youtube.com\/s...\n1      The Trump Presidency: Last Week Tonight with J...  ...  One year after the presidential election, John...\n2      Racist Superman | Rudy Mancuso, King Bach & Le...  ...  WATCH MY PREVIOUS VIDEO \u25b6 \\n\\nSUBSCRIBE \u25ba http...\n3                       Nickelback Lyrics: Real or Fake?  ...  Today we find out if Link is a Nickelback amat...\n4                               I Dare You: GOING BALD!?  ...  I know it's been a while since we did this sho...\n...                                                  ...  ...                                                ...\n23357                                Why Bridges Move...  ...  ...and other musings on thermal movement of la...\n23358                      Macaroni - A Recipe From 1784  ...  Visit Our Website! \u25b6 http:\/\/www.townsends.us\/ ...\n23359                           Chris Young - Hangin' On  ...  Chris Young's Hangin' On from his #1 album Los...\n23360      Elderly man making sure his dog won't get wet  ...  very wholesome stuff.\\n\\nThis video was taken ...\n23361         How to speak like Black Panther - BBC News  ...  The new marvel film Black Panther is set in th...\n\n[23362 rows x 14 columns]\n\n\"\"\"\n# reading writing on excel files with pandas: using \"read_excel\"\n# excel file mustbe in same folder\n\nexcelset = pd.read_excel(\"excelfile.xlsx\")\n\nprint(excelset)\n\n\"\"\"\n Unnamed: 0  Column1  Column2  Column3  Column4\n0     Index1       10       50       90      130\n1     Index2       20       60      100      140\n2     Index3       30       70      110      150\n3     Index4       40       80      120      160\n\n\"\"\"\n\n# if you wanna add column on this dataset which is excelset\n\nexcelset[\"Column5\"] = [170,180,190,200]\n\nprint(excelset)\n\n\"\"\"\n Unnamed: 0  Column1  Column2  Column3  Column4  Column5\n0     Index1       10       50       90      130      170\n1     Index2       20       60      100      140      180\n2     Index3       30       70      110      150      190\n3     Index4       40       80      120      160      200\n\ncolumn will be added already \n\n\"\"\"\n\n# if you wanna save this excel file to different(another excel file) excel file: using \"to_excel\"\n\nexcelset.to_excel(\"excelfilenew.xlsx\")\n\n\"\"\"\nUnnamed: 0  Column1  Column2  Column3  Column4  Column5\n0     Index1       10       50       90      130      170\n1     Index2       20       60      100      140      180\n2     Index3       30       70      110      150      190\n3     Index4       40       80      120      160      200\n\nit will be saved as new excel file right in the location folder\n\n\"\"\"\n\n# If you wanna take dataset from website: using \"read_html\"\n\nnew = pd.read_html(\"http:\/\/www.contextures.com\/xlSampleData01.html\",header = 0)\n\nprint(new)","4f4299c7":"import pandas as pd\nUSvideos = pd.read_csv(\"..\/input\/USvideos.csv\")","5ff67ccb":"**PANDAS DATAFRAMDE MULTILNDEX TANIMLAMA**","8e4d939b":"**PANDAS YAPISI VE SERILERI**","e87b40dc":"**PANDAS KAYIP VE BOZUK VERILER**","c5ad7edb":"**PANDAS MERGE ISLEMI**","53f05d1e":"**youtube trend videos data**","756b8d1b":"**PANDAS GROUPBY OPERASYONU**","d5cb54e4":"**PANDAS JOIN VE CONCANATE**","a37c1065":"**PANDAS DATAFRAMELERIN TANIMLANMASI**","26cc6694":"**PANDAS WAY TO READ DATASETS**","a1663530":"**PANDAS DATAFRAME OPERASYONLARI VE PIVOT TABLE **"}}