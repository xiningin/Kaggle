{"cell_type":{"5cc33fee":"code","d8f15804":"code","cd79e1ed":"code","146e59ea":"code","19c06818":"code","a07369ab":"code","989702ee":"code","b01af3f7":"code","b112a870":"code","91bfc255":"code","64539e0c":"code","fcd4439b":"code","ec9cc692":"code","1e336f24":"code","bdff1c71":"code","a789f166":"code","e03e078f":"code","c89a529a":"code","bfa1adff":"code","5b2d005a":"code","6d29bafe":"code","537f3262":"code","bf5ac48d":"code","75cfe210":"code","13e17cc6":"code","05eb9b82":"code","2e60466f":"code","525000ba":"code","878820bd":"code","b6c26a2c":"code","6b9e6d5f":"code","d006f420":"markdown","13af7c70":"markdown","8e5ee3fc":"markdown","9d50ae67":"markdown","e80788b1":"markdown","e6eabf5a":"markdown","7fc624cd":"markdown","68791b29":"markdown","40c58128":"markdown","b1dfcc2c":"markdown","0e522f3c":"markdown"},"source":{"5cc33fee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8f15804":"# Import the libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","cd79e1ed":"#Load the dataset\n\ndata = pd.read_csv(\"..\/input\/wine-quality-dataset\/WineQT.csv\")","146e59ea":"data.head()","19c06818":"data['quality'].value_counts()","a07369ab":"data.isnull().sum()","989702ee":"data.info()","b01af3f7":"data.duplicated().any()","b112a870":"data = data.drop('Id',axis=1)","91bfc255":"X = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values","64539e0c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","fcd4439b":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","ec9cc692":"X_train.shape","1e336f24":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA(n_components = 2)\nX_train = lda.fit_transform(X_train, y_train)\nX_test = lda.transform(X_test)","bdff1c71":"X_train.shape,X_test.shape","a789f166":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","e03e078f":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc1 = accuracy_score(y_test, y_pred)","c89a529a":"print(acc1)","bfa1adff":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)","5b2d005a":"y_pred = classifier.predict(X_test)","6d29bafe":"print(y_pred)","537f3262":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc2 = accuracy_score(y_test, y_pred)","bf5ac48d":"print(acc2)","75cfe210":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)","13e17cc6":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc3 = accuracy_score(y_test, y_pred)","05eb9b82":"print(acc3)","2e60466f":"from catboost import CatBoostClassifier\nclassifier = CatBoostClassifier()\nclassifier.fit(X_train, y_train)","525000ba":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc4 = accuracy_score(y_test, y_pred)","878820bd":"print(acc4)","b6c26a2c":"mylist=[]\nmylist2=[]\nmylist.append(acc1)\nmylist2.append(\"Logistic Regression\")\nmylist.append(acc2)\nmylist2.append(\"SVM\")\nmylist.append(acc3)\nmylist2.append(\"XG Boost\")\nmylist.append(acc4)\nmylist2.append(\"CatBoost\")","6b9e6d5f":"plt.rcParams['figure.figsize']=8,6\nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classification Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classification Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","d006f420":"# Training CatBoost on the Training set","13af7c70":"# Training the SVM model on the Training set","8e5ee3fc":"# Training the Logistic Regression model on the Training set","9d50ae67":"# Create visualization for all model with their Accuracy","e80788b1":"# Predict the test result","e6eabf5a":"# Making the Confusion Matrix","7fc624cd":"# Making the confusion matrix","68791b29":"# Feature Scaling","40c58128":"# Applying LDA - Linear Discriminant Analysis","b1dfcc2c":"# XG Boost model","0e522f3c":"# Splitting the dataset into the Training set and Test set"}}