{"cell_type":{"f6e02625":"code","20def18d":"code","eabd7c61":"code","c5c53fa7":"code","163d2f41":"markdown"},"source":{"f6e02625":"classes = os.listdir('..\/input\/bbc-news-summary\/BBC News Summary\/News Articles')\nArticles_dir = '..\/input\/bbc-news-summary\/BBC News Summary\/News Articles\/'\nSummaries_dir = '..\/input\/bbc-news-summary\/BBC News Summary\/Summaries\/'\n\narticles = []\nsummaries = []\nfile_arr = []\nfor cls in classes:\n    files = os.listdir(Articles_dir + cls)\n    for file in files:\n        article_file_path = Articles_dir + cls + '\/' + file\n        summary_file_path = Summaries_dir + cls + '\/' + file\n        try:\n            with open (article_file_path,'r') as f:\n                articles.append('.'.join([line.rstrip() for line in f.readlines()]))\n            with open (summary_file_path,'r') as f:\n                summaries.append('.'.join([line.rstrip() for line in f.readlines()]))\n            file_arr.append(cls + '\/' + file)\n        except:\n            pass\n            \ndataset = pd.DataFrame({'File_path':file_arr,'Articles': articles,'Summaries':summaries})\ndataset.head()","20def18d":"def summary(text,  porcetagem = 0.3):\n  stopwords = list(STOP_WORDS) #Lista das stopwords\n  nlp = spacy.load(\"en_core_web_sm\")\n\n  doc = nlp(text)\n\n  tokens = [token.text for token  in doc]\n\n  from string import punctuation\n  punctuation = punctuation + '\\n'\n\n  word_frequencies = {}\n  for word in doc:\n    if word.text.lower() not in stopwords:\n      if word.text.lower() not in punctuation:\n        if word.text not in word_frequencies.keys():\n          word_frequencies[word.text] = 1\n        else:\n          word_frequencies[word.text] += 1\n\n  max_frequency = max(word_frequencies.values())\n\n  for word in word_frequencies.keys():\n    word_frequencies[word] = word_frequencies[word]\/max_frequency\n\n  sentence_tokens = [sent for sent in doc.sents]\n\n  sentence_scores = {}\n  for sent in sentence_tokens:\n    for word in sent:\n      if word.text.lower() in word_frequencies.keys():\n        if sent not in sentence_scores.keys():\n          sentence_scores[sent] = word_frequencies[word.text.lower()]\n        else:\n          sentence_scores[sent] += word_frequencies[word.text.lower()]\n\n  from heapq import nlargest\n\n  select_leght = int(len(sentence_tokens)*porcetagem)\n\n  summary = nlargest(select_leght, sentence_scores, key=sentence_scores.get)\n\n  final_summary = [word.text for word in summary]\n  summary = ' '.join(final_summary)\n  #print(summary)\n  return summary\n","eabd7c61":"sumList = []\ncount = 0\nporcentagem = 0.3\nwhile count < len(dataset['Articles']):\n  sumList.append(summary(dataset['Articles'][count],porcentagem))\n  count +=1\n","c5c53fa7":"dataset[\"Summary\"] = sumList\ndataset","163d2f41":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom string import punctuation\n\nimport os\nimport time\nimport pandas as pd"}}