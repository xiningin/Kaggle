{"cell_type":{"d1bbc339":"code","5a2c0930":"code","f28b241f":"code","f71cd6fd":"code","f57ce703":"code","f97d902f":"code","de62aab0":"code","f31b9ee0":"code","a7379b01":"code","7a57699c":"code","0fb87d07":"code","ff69b691":"code","aa4db75c":"code","f93ad27e":"code","05bb5ecc":"code","d988e377":"code","09af176e":"code","daadc50a":"code","4fc9985b":"code","af69dd6f":"code","323d9d32":"code","c43eff8b":"code","7d18d617":"code","c3c16f87":"code","ea98fc0a":"code","123c8981":"code","a39f000d":"code","f7262825":"code","f3d02e72":"code","e4a202e4":"code","301f6e3f":"code","8bb01b78":"code","9474425f":"code","8aa5abf7":"code","9813bf00":"code","79900176":"code","293c2000":"code","f3782af6":"code","f2943ed5":"code","30c33275":"code","80141ac1":"code","fc0e49a4":"code","35cde543":"code","18d55570":"code","67642908":"code","f297f112":"code","be9a601f":"code","cc94e854":"code","e8673f17":"code","b277e1ae":"code","be78dfcf":"code","a82a5832":"code","982c582f":"code","4903ae79":"code","74bc17cc":"code","8a88fb61":"code","dcb032fa":"code","3612e936":"code","4d141e18":"code","cc9d94e5":"code","25b744ca":"code","4534ec0e":"code","b053e8ed":"code","5506cddc":"code","cc560f68":"code","f565609f":"code","a7664943":"code","670a8590":"code","350f5eec":"code","6584916f":"code","125ad764":"code","1d6c34c9":"code","33c40ec2":"code","ac7a10ac":"code","e32e52ff":"code","b2169daa":"code","7086e141":"code","a9b23be5":"code","93c05f17":"code","b595662d":"code","cb94c6a9":"code","eeffea9c":"code","65e0edcf":"code","4b20f8f3":"code","eca5bf39":"code","de5b71a3":"code","c2a02d97":"code","63a2c95d":"markdown","513ec4d9":"markdown","b2589418":"markdown","6e2994b5":"markdown","228c4131":"markdown","9c7b9b13":"markdown","a33de192":"markdown","fecd04aa":"markdown"},"source":{"d1bbc339":"#import the required packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set(color_codes = True)\nimport os","5a2c0930":"#load train and test data\ntrain_data = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\ntrain_data.head()","f28b241f":"print(\"In training data, there are \",train_data.shape[0],\" records and \",train_data.shape[1],\" columns\")\nprint(\"In test data, there are \",test_data.shape[0],\" records and \",test_data.shape[1],\" columns\")","f71cd6fd":"#Main data analysis steps:\n#remove duplicates,outliers\n#remove irrelelvant observations\n#Major tasks of data preprocessing\n#1. Handling misssing values\n#2. Handling categorical variables\n#3. Handling outliers","f57ce703":"train_data.describe()","f97d902f":"#Remove unnnecessary fields\n#The column id doesnt provide any additional informaion so we can drop this column\ntrain_data = train_data.drop(['Id'],axis = 1)\ntest_data = test_data.drop(['Id'],axis = 1)","de62aab0":"y = train_data['SalePrice']\ndel train_data['SalePrice']","f31b9ee0":"#Check if there are any duplicate records\nsum(train_data.duplicated())","a7379b01":"train_missing_cols = list(train_data.columns[train_data.isnull().any()])\ntest_missing_cols = list(test_data.columns[test_data.isnull().any()])\nprint(\"There are \",len(train_missing_cols),\" columns with missing values in training data\")\nprint(\"There are \",len(test_missing_cols),\" columns with missing values in test data\")","7a57699c":"train_data.info()","0fb87d07":"test_data.info()","ff69b691":"#percentage of missing values in train data\ntrain_mis_cols = pd.Series(train_data.isnull().sum())*100\/train_data.shape[0]\ntrain_mis_cols = train_mis_cols[train_mis_cols>0]\ntrain_mis_cols","aa4db75c":"#percentage of missing values in test data\ntest_mis_cols = pd.Series(test_data.isnull().sum())*100\/test_data.shape[0]\ntest_mis_cols = test_mis_cols[test_mis_cols>0]\ntest_mis_cols","f93ad27e":"#from the above results notice that Alley,FireplaceQu,PoolQC,Fence,MiscFeature have more than 50% missing data. So we can ignore this columns for training the model.\n#Theoretically if there are more than 30% of missing values then those columns are said to be ignored\ntrain_data = train_data.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis = 1)\ntest_data = test_data.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis = 1)","05bb5ecc":"#There will be a relation between lot frontage and lot area. Lets get the square root of lot area and check if it has any correlation with the lot frontage ","d988e377":"test_data['SqrtLotArea'] = np.sqrt(test_data['LotArea'])\ntrain_data['SqrtLotArea'] = np.sqrt(train_data['LotArea'])\nprint(test_data['LotFrontage'].corr(test_data['SqrtLotArea']))\nprint(train_data['LotFrontage'].corr(train_data['SqrtLotArea']))","09af176e":"#From the above results we can see that there is a linear relation between square root of lot area and lot frontage. So lets replace missin vlues of lot frontage with lot area.","daadc50a":"test_data.LotFrontage[test_data['LotFrontage'].isnull()] = test_data.SqrtLotArea[test_data['LotFrontage'].isnull()]\ntrain_data.LotFrontage[train_data['LotFrontage'].isnull()] = train_data.SqrtLotArea[train_data['LotFrontage'].isnull()]\ndel test_data['SqrtLotArea']\ndel train_data['SqrtLotArea']","4fc9985b":"def get_counts(data,column):\n    return(data[column].value_counts())\ndef impute_values(data,column,value):\n    data.loc[data[column].isnull(),column] = value","af69dd6f":"print(get_counts(test_data, 'MasVnrType'), len(test_data))\nprint(get_counts(train_data, 'MasVnrType'), len(train_data))","323d9d32":"#As most the values are none lets replace missing values with None\nimpute_values(test_data, 'MasVnrType', 'None')\nimpute_values(train_data, 'MasVnrType', 'None')","c43eff8b":"print(get_counts(test_data, 'MasVnrArea'), len(test_data))\nprint(get_counts(train_data, 'MasVnrArea'), len(train_data))","7d18d617":"impute_values(test_data, 'MasVnrArea', 0.0)\nimpute_values(train_data, 'MasVnrArea', 0.0)","c3c16f87":"print(get_counts(train_data, 'Electrical'), len(train_data))","ea98fc0a":"impute_values(test_data, 'Electrical', 'SBrkr')\nimpute_values(train_data, 'Electrical', 'SBrkr')","123c8981":"def weightedAvg(data, col):\n    tmp = get_counts(data, col)\n    return sum(tmp.index * tmp.values)\/sum(tmp.values)","a39f000d":"impute_values(train_data, 'GarageYrBlt', round(weightedAvg(train_data, 'GarageYrBlt')))\nimpute_values(test_data, 'GarageYrBlt', round(weightedAvg(test_data, 'GarageYrBlt')))","f7262825":"get_counts(train_data,'GarageType')","f3d02e72":"impute_values(train_data, 'GarageType', 'Attchd')\nimpute_values(test_data, 'GarageType', 'Attchd')","e4a202e4":"train_data = train_data.replace({'ExterQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'ExterQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'ExterCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'ExterCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'BsmtQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'BsmtQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'BsmtCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'BsmtCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, np.NaN: 0}})\ntest_data = test_data.replace({'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, np.NaN: 0}})\ntest_data = test_data.replace({'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'BsmtFinType2': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, np.NaN: 0}})\ntest_data = test_data.replace({'BsmtFinType2': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'HeatingQC': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'HeatingQC': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'KitchenQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'KitchenQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'Functional': {'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, np.NaN: 0}})\ntest_data = test_data.replace({'Functional': {'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'FireplaceQu': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'FireplaceQu': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, np.NaN: 0}})\ntest_data = test_data.replace({'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'GarageQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'GarageQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'GarageCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'GarageCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'PavedDrive': {'Y': 3, 'P': 2, 'N': 1, np.NaN: 0}})\ntest_data = test_data.replace({'PavedDrive': {'Y': 3, 'P': 2, 'N': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'PoolQC': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntest_data = test_data.replace({'PoolQC': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, np.NaN: 0}})\ntrain_data = train_data.replace({'Fence': {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, np.NaN: 0}})\ntest_data = test_data.replace({'Fence': {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, np.NaN: 0}})","301f6e3f":"print(pd.crosstab(test_data.MSSubClass, test_data.MSZoning))","8bb01b78":"print(test_data[test_data['MSZoning'].isnull() == True])","9474425f":"test_data.loc[(test_data['MSZoning'].isnull()) & (test_data['MSSubClass']==20), 'MSZoning'] = 'RL'\ntest_data.loc[(test_data['MSZoning'].isnull()) & (test_data['MSSubClass']==30), 'MSZoning'] = 'RM'\ntest_data.loc[(test_data['MSZoning'].isnull()) & (test_data['MSSubClass']==70), 'MSZoning'] = 'RM'","8aa5abf7":"print(get_counts(test_data, 'Utilities'), len(test_data))","9813bf00":"impute_values(test_data, 'Utilities', 'AllPub')","79900176":"print(pd.crosstab(test_data.Exterior1st, test_data.Exterior2nd))","293c2000":"impute_values(test_data, 'Exterior1st', 'VinylSd')\nimpute_values(test_data, 'Exterior2nd', 'VinylSd')","f3782af6":"print(pd.crosstab(test_data.BsmtFinSF1, test_data.BsmtFinSF2))","f2943ed5":"impute_values(test_data, 'BsmtFinSF1', 0.0)","30c33275":"impute_values(test_data, 'BsmtFinSF2', 0.0)","80141ac1":"print(get_counts(test_data, 'BsmtUnfSF'), len(test_data))","fc0e49a4":"impute_values(test_data, 'BsmtUnfSF', round(weightedAvg(test_data, 'BsmtUnfSF')))","35cde543":"test_data = test_data.drop(['TotalBsmtSF'], axis=1)\ntrain_data = train_data.drop(['TotalBsmtSF'], axis=1)","18d55570":"print(get_counts(test_data, 'BsmtFullBath'), len(test_data))","67642908":"impute_values(test_data, 'BsmtFullBath', round(weightedAvg(test_data, 'BsmtFullBath')))","f297f112":"print(get_counts(test_data, 'BsmtHalfBath'), len(test_data))","be9a601f":"impute_values(test_data, 'BsmtHalfBath', 0.0)","cc94e854":"print(get_counts(test_data, 'KitchenQual'), len(test_data))","e8673f17":"impute_values(test_data, 'KitchenQual', 'TA')","b277e1ae":"print(get_counts(test_data, 'Functional'), len(test_data))","be78dfcf":"impute_values(test_data, 'Functional', 'Typ')","a82a5832":"print(get_counts(test_data, 'GarageCars'), len(test_data))","982c582f":"impute_values(test_data, 'GarageCars', 2.0)","4903ae79":"print(get_counts(test_data, 'GarageArea'), len(test_data))","74bc17cc":"impute_values(test_data, 'GarageArea', round(weightedAvg(test_data, 'GarageArea')))","8a88fb61":"print(get_counts(test_data, 'SaleType'), len(test_data))","dcb032fa":"impute_values(test_data, 'SaleType', 'WD')","3612e936":"s = pd.Series(train_data.isnull().sum())*100\/train_data.shape[0]\ns = s[s>0]\nprint(s)\ns = pd.Series(test_data.isnull().sum())*100\/test_data.shape[0]\ns = s[s>0]\nprint(s)","4d141e18":"#There are no more missing values.","cc9d94e5":"#check correlation between all columns and ignore few columns if they are higly correlated with other columns.","25b744ca":"corr_table = train_data.corr(method ='pearson') \ncorr_table[(corr_table>0.7) | (corr_table<-0.7)]","4534ec0e":"#from the above results notice that external quality and over quality are highly correlated.\n#from the above results notice that year built and garage year built are highly correlated.\n#so lets drop garage year built and external quality\ndel train_data['ExterQual']\ndel train_data['GarageYrBlt']\ndel test_data['ExterQual']\ndel test_data['GarageYrBlt'] ","b053e8ed":"train_data.head()","5506cddc":"tmp = train_data.columns.to_series().groupby(train_data.dtypes).groups\nprint({k.name: v for k, v in tmp.items()})","cc560f68":"# feature list for one-hot encoding\noneHotCol = ['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir',\n       'Electrical', 'Functional', 'GarageType', 'SaleType',\n       'SaleCondition']\n# process each column in the list\nfor cols in oneHotCol:\n    train_data = pd.concat((train_data, pd.get_dummies(train_data[cols], prefix=cols)), axis=1)\n    del train_data[cols]\n    test_data = pd.concat((test_data, pd.get_dummies(test_data[cols], prefix=cols)), axis=1)\n    del test_data[cols]","f565609f":"# min-max scaling\ntrain_data = (train_data - train_data.min()) \/ (train_data.max() - train_data.min())\ntest_data = (test_data - test_data.min()) \/ (test_data.max() - test_data.min())","a7664943":"print(train_data.shape)\nprint(test_data.shape)","670a8590":"#Notice that there are different number of columns in train and test data. Lets just consider the columns which are present in both\nfor col in train_data.columns:\n    if col not in test_data.columns:\n        del train_data[col]\nfor col in test_data.columns:\n    if col not in train_data.columns:\n        del test_data[col]","350f5eec":"X = train_data\nX_test = test_data","6584916f":"print(get_counts(test_data, 'Utilities_AllPub'), len(test_data))\nimpute_values(test_data, 'Utilities_AllPub', 1)","125ad764":"from sklearn import linear_model\nlm = linear_model.LinearRegression()\nlm.fit(X,y)\nresults = lm.predict(X_test)","1d6c34c9":"np.mean((np.log(y.values) - np.log(lm.predict(X)))**2)","33c40ec2":"from sklearn import linear_model\nridge = linear_model.Ridge(alpha = 1.0)\nridge.fit(X,y)\nresults = ridge.predict(X_test)","ac7a10ac":"np.mean((np.log(y.values) - np.log(ridge.predict(X)))**2)","e32e52ff":"las = linear_model.Lasso(alpha = 1.0)\nlas.fit(X,y)\nresults = las.predict(X_test)","b2169daa":"np.mean((np.log(y.values) - np.log(las.predict(X)))**2)","7086e141":"las_weight = las.coef_\nlas_weight = pd.DataFrame({'feature': X.columns, 'weight': las_weight})\nprint(las_weight[las_weight['weight'] == 0])","a9b23be5":"#delete all the above columns\nX_new = X.drop(['MSSubClass_40','MSSubClass_90','MSZoning_RL','LotConfig_Inside','LandSlope_Mod',\n               'Neighborhood_Sawyer','Condition1_RRNn','BldgType_1Fam','RoofStyle_Hip',\n               'RoofStyle_Shed','MasVnrType_Stone','CentralAir_Y','Electrical_SBrkr','Functional_7','SaleType_Oth'],axis = 1)","93c05f17":"#delete all the above columns\nX_test_new = X_test.drop(['MSSubClass_40','MSSubClass_90','MSZoning_RL','LotConfig_Inside','LandSlope_Mod',\n               'Neighborhood_Sawyer','Condition1_RRNn','BldgType_1Fam','RoofStyle_Hip',\n               'RoofStyle_Shed','MasVnrType_Stone','CentralAir_Y','Electrical_SBrkr','Functional_7','SaleType_Oth'],axis = 1)","b595662d":"lm = linear_model.LinearRegression()\nlm.fit(X_new,y)\nresults = lm.predict(X_test_new)\nnp.mean((np.log(y.values) - np.log(lm.predict(X_new)))**2)","cb94c6a9":"ridge = linear_model.Ridge(alpha = 1.0)\nridge.fit(X_new,y)\nresults = ridge.predict(X_test_new)\nnp.mean((np.log(y.values) - np.log(ridge.predict(X_new)))**2)","eeffea9c":"las = linear_model.Lasso(alpha = 2.0)\nlas.fit(X_new,y)\nresults = las.predict(X_test_new)\nnp.mean((np.log(y.values) - np.log(las.predict(X_new)))**2)","65e0edcf":"from sklearn.model_selection import GridSearchCV\nparameters = {'alpha':[0.001,0.01,0.1,1,10,15,20,30,50,100,200,300,500,1000]}\nmodel = linear_model.Ridge()\nRidge_reg= GridSearchCV(model, parameters, scoring='neg_mean_squared_error',cv=5)\nRidge_reg.fit(X_new,y)\nprint(Ridge_reg.best_estimator_)","4b20f8f3":"best_model = Ridge_reg.best_estimator_\nbest_model.fit(X_new,y)\nresults = best_model.predict(X_test_new)\nnp.mean((np.log(y.values) - np.log(best_model.predict(X_new)))**2)","eca5bf39":"sample_data = pd.read_csv(\"..\/input\/home-data-for-ml-course\/sample_submission.csv\")\nsample_data['SalePrice'] = results","de5b71a3":"sample_data.to_csv('submission.csv', index=False)","c2a02d97":"sample_data","63a2c95d":"# **Handle categorical data**","513ec4d9":"# Lasso Regression","b2589418":"The main goal of this notebook is provide step by step data analysis, data preprocessing and implement various machine learning tasks. The goal is not just to build a model which gives better results but also to learn various analysis and modeling techniques in the process of building the best model.","6e2994b5":"# **Simple Linear Regression Model**","228c4131":"# **Normalize data**","9c7b9b13":"# **Gridsearchcv for selecting parameters for ridge regression**","a33de192":"# **Ridge regression**","fecd04aa":"# **Handling Missing Data**"}}