{"cell_type":{"cfec6d14":"code","434f37ac":"code","a865e2e7":"code","f6ea901f":"code","be33d104":"code","71b5c580":"code","4e08c7df":"code","7d961cbd":"code","339a998b":"code","a3fcf3cc":"code","60997607":"code","d2f81a20":"code","923b6984":"code","a85846cd":"code","a143da8c":"code","2b5d77be":"code","0e778731":"code","73249ff8":"code","a18c220a":"code","ffaa2843":"code","85381530":"code","4b06f7b6":"markdown","ee75c902":"markdown","1158536b":"markdown","b07547a7":"markdown","cce9505b":"markdown","6473c034":"markdown","98f5890a":"markdown","007c1eeb":"markdown","4cd51e10":"markdown","64467c16":"markdown","bb93733c":"markdown","4c2c67ad":"markdown","9a4e7c0c":"markdown","0d3be3d9":"markdown","24ae2484":"markdown","1dff85ce":"markdown"},"source":{"cfec6d14":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import ensemble\nfrom sklearn.tree import DecisionTreeClassifier\nimport gc\nfrom imblearn.under_sampling import TomekLinks\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n# import pickle\nimport matplotlib.cm as cm\nimport seaborn as sn\nfrom collections import Counter\nimport lightgbm as lgb\n# from kmodes.kprototypes import KPrototypes\nimport gc\n# %reload_ext autotime","434f37ac":" dataset = pd.read_csv('..\/input\/car-purchase-prediction\/Social_Network_Ads.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","a865e2e7":"dataset.head()","f6ea901f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","be33d104":"print(X_train)","71b5c580":"print(X_test)","4e08c7df":"print(y_train)","7d961cbd":"print(y_test)","339a998b":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","a3fcf3cc":"print(X_train)","60997607":"print(X_test)","d2f81a20":"print(y_train)","923b6984":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train,y_train)","a85846cd":"print(classifier.predict(sc.transform([[30,87000]])))","a143da8c":"y_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","2b5d77be":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","0e778731":"print(classification_report(y_test, y_pred))\ncnf_matrix = confusion_matrix(y_test, y_pred)\n#print(cnf_matrix)\naccuracy_score(y_test, y_pred)","73249ff8":"def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=plt.cm.summer):\n    plt.clf\n    plt.imshow(cm, interpolation='nearest')\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(target_names))\n    plt.xticks(tick_marks, target_names, rotation=45)\n    plt.yticks(tick_marks, target_names)\n    plt.tight_layout()\n \n    width, height = cm.shape\n \n    for x in range(width):\n        for y in range(height):\n            plt.annotate(str(cm[x][y]), xy=(y, x), \n                        horizontalalignment='center',\n                        verticalalignment='center',color='black',fontsize=22)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\n","a18c220a":"plot_confusion_matrix(cnf_matrix, np.unique(y_pred))","ffaa2843":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_train), y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","85381530":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_test), y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","4b06f7b6":"# Visualising the Test Set Results","ee75c902":"# Importing the Libraries","1158536b":"# Splitting the dataset into Training Set and Test Set","b07547a7":"We're going to visualize not only the training set results but also the test results. And this will be super interesting because we will actually see how the **logistic regression** classifier was actually trained to classify our customer as you know our observations in to the two different classes.","cce9505b":"Now we have trained our **Logistic Regression Model**. Now test the cutomer with Age=30 and Salary=87000 but before puting this values in classifier we need to scale these values as well, as we have scaled our orignal values so that's why it should have exact same scaler that we have applied on **Training Data**.","6473c034":"# Feature Scaling","98f5890a":"So that concludes the **Car Purchase Prediction Model** using **Logistic Regression** with the **Accuracy** of **89%**. Please add if i have missed something and correct me if there is anything wrong.","007c1eeb":"The dataset we have here belongs to a **Car company** and we have to predict that which of our previous customers will buy brand new SUV as company has launched new SUV.\nAnd to predict this we need data on which we train classification model to predict that \nwhich customers will buy new SUV.\nThe dataset contains 3 columns.\n\n* **Age**\n* **Estimated Salary**\n* **Purchased - Target Variable**\n\nIn **Purchased Column** we have 2 values, 0 & 1. 0 means that customer didnot buy any SUV and 1 means\nthat customer have bought SUV. The customers here we are talking about are basically previous customers.","4cd51e10":"The confusion matrix showing that we have indeed **65 correct predictions** of the **class 0** meaning the customers of the test who didn't buy the new SUV then **24 Correct predictions** of the **class 1** meaning correct prediction that the customers who bought the SUV and then **3 incorrect predictions** of the **class 1** meaning **3 incorrect predictions** of the customers who in reality bought the SUV but were predicted not to. And finally **8 incorrect predictions** of the **class 0** meaning 8 customers who in reality didn't buy the SUV but were predicted to buy it.","64467c16":"According to the Test Data we have this customer who does not buy SUV and we can see that predicted answer is also the same, so the model did well here on this single observation of customer.","bb93733c":"# Training the Logistic Regression Model on Training Set","4c2c67ad":"Now we are going to scale 2 given features named as **Age and Salary**. No need to scale Target variable as it is in already binary form.","9a4e7c0c":"We get the two vectors next to each other with first on the left, Your vector of predictions you know of the predicted purchase decisions for all the customers. Of course the test set right. This was applied to excess here so that all the customers of the test set and on the right in the second column you have the real purchasing decisions.\n\nAnd so here what's interesting to see is to compare the predicted purchase decisions to the real ones for all the customers in the test. All right so let's see for the first customer of the test. You remember that particular custoemr with age 30 and an estimated salary 87000 dollars.\n\nWell the prediction is **NO** this customer didn't buy the new SUV and the real result is indeed **NO**.\n\nIn reality that customer didn't buy the new SUV.\n\nAs we can see that in the results that majority of the predictions are correct and also we have some incorrect predictions. Lets draw confusion matrics to check the predictions.","0d3be3d9":"# Importing the Dataset","24ae2484":"# Visualising the Training Set Results","1dff85ce":"So now we're gonna move on to the next step which is predicting the test results and displaying the vector of the predictions next to the vector of the real results mean the real purchase decisions."}}