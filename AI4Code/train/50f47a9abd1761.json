{"cell_type":{"af3e7189":"code","1d2bedfc":"code","168c80a4":"code","2eaf4c60":"code","4ce2fbab":"code","e5305bfd":"code","f261aff9":"code","103ea6f5":"code","f81fac29":"code","7c368f94":"code","6f4c819f":"code","3236083b":"code","32918835":"code","f92a1c10":"code","f820d64b":"code","c17a0862":"code","dbfd4e36":"code","35f609ca":"code","bba353e8":"code","545b7bce":"code","a09ee608":"code","60c2d49b":"code","7435980d":"code","11215838":"code","b6b8bb92":"code","44fe50ca":"code","5ea8cf3a":"code","833a572b":"code","91f57f63":"markdown","b0f0d2e2":"markdown","7a2cafcb":"markdown","bf5c0843":"markdown","92eb119f":"markdown","d4418122":"markdown","8cb2c2a8":"markdown","d7007cb2":"markdown","38ac62a6":"markdown","fd6941be":"markdown","696d3f5d":"markdown","ac4d9009":"markdown","7fd715b3":"markdown"},"source":{"af3e7189":"!pip install -q torchmetrics\n!pip install -q iterative-stratification\n!pip install -q pytorch-lightning==1.2.8","1d2bedfc":"package_paths = [\n    '..\/input\/pytorch-image-library\/pytorch-image-models-master\/pytorch-image-models-master',\n]\nimport sys;\n\nfor pth in package_paths:\n    sys.path.append(pth)\n\nimport timm","168c80a4":"import pandas as pd\nimport numpy as np\nimport cv2\nimport timm\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\nimport torchmetrics\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.pytorch import ToTensorV2\n\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold","2eaf4c60":"print(f\"PyTorch Lightning version: {pl.__version__}\")","4ce2fbab":"DEBUG = False\n\nclass CFG:\n    seed = 42\n    model_name = 'tf_efficientnet_b5_ns'\n    pretrained = True\n    img_size = 512\n    num_classes = 6\n    lr = 1e-4\n    max_lr = 1e-3\n    pct_start = 0.3\n    div_factor = 1.0e+3\n    final_div_factor = 1.0e+3\n    num_epochs = 20\n    batch_size = 16\n    accum = 1\n    precision = 16\n    n_fold = 5\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","e5305bfd":"PATH = \"..\/input\/plant-pathology-2021-fgvc8\/\"\n\n# TRAIN_DIR = PATH + 'train_images\/'\nTRAIN_DIR = \"..\/input\/resized-plant2021\/img_sz_640\/\"\nTEST_DIR = PATH + 'test_images\/'","f261aff9":"seed_everything(CFG.seed)","103ea6f5":"df_all = pd.read_csv(PATH + \"train.csv\")\nif DEBUG == True:\n    df_all = df_all[:200]\n    CFG.num_epochs = 30\n\ndf_all.shape","f81fac29":"from collections import defaultdict\n\n\ndct = defaultdict(list)\n\nfor i, label in enumerate(df_all.labels):\n    for category in label.split():\n        dct[category].append(i)\n \ndct = {key: np.array(val) for key, val in dct.items()}\ndct","7c368f94":"new_df = pd.DataFrame(np.zeros((df_all.shape[0], len(dct.keys())), dtype=np.int8), columns=dct.keys())\n\nfor key, val in dct.items():\n    new_df.loc[val, key] = 1\n\nnew_df.head()","6f4c819f":"df_all = pd.concat([df_all, new_df], axis=1)\ndf_all.to_csv('better_train.csv', index = False)\ndf_all.head()","3236083b":"duplicates = pd.read_csv(\"..\/input\/pp2021-duplicates-revealing\/duplicates.csv\",  names=('image1', 'image2'))\nsorted_index = duplicates['image1'].sort_values().index\nduplicates = duplicates.iloc[sorted_index].reset_index(drop=True)\nduplicates.head()","32918835":"if DEBUG != True:\n    for idx, images in duplicates.iterrows():\n    #     print(images['image1'])\n        mask1 = df_all['image'] == images['image1']\n        mask2 = df_all['image'] == images['image2']\n        tmp = df_all[mask1].iloc[0, 2:].values | df_all[mask2].iloc[0, 2:].values\n        df_all.loc[mask1, df_all.columns[2:]] = tmp\n        df_all = df_all.drop(df_all[mask2].index)\n    assert (len(new_df) - len(duplicates)) == len(df_all)","f92a1c10":"# sfk = StratifiedKFold(CFG.n_fold)\n# for train_idx, valid_idx in sfk.split(df_all['image'], df_all['labels']):\n#     df_train = df_all.iloc[train_idx]\n#     df_valid = df_all.iloc[valid_idx]\n#     break\n    \n# print(f\"train size: {len(df_train)}\")\n# print(f\"valid size: {len(df_valid)}\")","f820d64b":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n\nmsss = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n\nfor train_idx, valid_idx in msss.split(df_all['image'], df_all.loc[:, list(df_all.columns[2:].values)]):\n    df_train = df_all.iloc[train_idx]\n    df_valid = df_all.iloc[valid_idx]\n\nprint(f\"train size: {len(df_train)}\")\nprint(f\"valid size: {len(df_valid)}\")","c17a0862":"class PlantDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.image_id = df['image'].values\n        self.labels = df.iloc[:, 2:].values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image_id = self.image_id[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        \n        image_path = TRAIN_DIR + image_id\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        augmented = self.transform(image=image)\n        image = augmented['image']\n        return {'image':image, 'target': label}","dbfd4e36":"def get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.Flip(p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.5),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=0.5),\n                A.RandomGamma(p=0.5),\n            ], p=0.5),\n            A.OneOf([\n                A.Blur(p=0.1),\n                A.GaussianBlur(p=0.1),\n                A.MotionBlur(p=0.1),\n            ], p=0.1),\n            A.OneOf([\n                A.GaussNoise(p=0.1),\n                A.ISONoise(p=0.1),\n                A.GridDropout(ratio=0.5, p=0.2),\n                A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n            ], p=0.2),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","35f609ca":"train_dataset = PlantDataset(df_train, get_transform('train'))\nvalid_dataset = PlantDataset(df_valid, get_transform('valid'))\n\ntrain_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, pin_memory=True, drop_last=True, num_workers=2)\nvalid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, pin_memory=True, num_workers=2)","bba353e8":"CFG.steps_per_epoch = len(train_loader)\nCFG.steps_per_epoch","545b7bce":"import torch.nn.functional as F\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss","a09ee608":"class CustomResNet(nn.Module):\n    def __init__(self, model_name='resnet18', pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n#         self.model.fc = nn.Linear(in_features, CFG.num_classes)\n        self.model.fc = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, CFG.num_classes)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","60c2d49b":"class CustomEffNet(nn.Module):\n    def __init__(self, model_name='tf_efficientnet_b0_ns', pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n#         self.model.fc = nn.Linear(in_features, CFG.num_classes)\n        self.model.classifier = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, CFG.num_classes)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","7435980d":"class LitCassava(pl.LightningModule):\n    def __init__(self, model):\n        super(LitCassava, self).__init__()\n        self.model = model\n#         self.metric = pl.metrics.F1(num_classes=CFG.num_classes)\n        self.metric = torchmetrics.F1(CFG.num_classes, average='weighted')\n#         self.criterion = nn.BCELoss()\n        self.criterion = nn.BCEWithLogitsLoss()\n#         self.criterion = FocalLoss()\n        self.sigmoid = nn.Sigmoid()\n        self.lr = CFG.lr\n\n    def forward(self, x, *args, **kwargs):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n#         self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=CFG.t_max, eta_min=CFG.min_lr)\n        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, \n                                                             epochs=CFG.num_epochs, steps_per_epoch=CFG.steps_per_epoch,\n                                                             max_lr=CFG.max_lr, pct_start=CFG.pct_start, \n                                                             div_factor=CFG.div_factor, final_div_factor=CFG.final_div_factor)\n        scheduler = {'scheduler': self.scheduler, 'interval': 'step',}\n\n        return [self.optimizer], [scheduler]\n\n    def training_step(self, batch, batch_idx):\n        image = batch['image']\n        target = batch['target']\n        output = self.model(image)\n#         output = self.sigmoid(output)\n        loss = self.criterion(output, target)\n        score = self.metric(self.sigmoid(output), target.clone().detach().to(torch.int32))\n        logs = {'train_loss': loss, 'train_f1': score, 'lr': self.optimizer.param_groups[0]['lr']}\n        self.log_dict(\n            logs,\n            on_step=False, on_epoch=True, prog_bar=True, logger=True\n        )\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        image = batch['image']\n        target = batch['target']\n        output = self.model(image)\n#         output = self.sigmoid(output)\n        loss = self.criterion(output, target)\n        score = self.metric(self.sigmoid(output), target.clone().detach().to(torch.int32))\n        logs = {'valid_loss': loss, 'valid_f1': score}\n        self.log_dict(\n            logs,\n            on_step=False, on_epoch=True, prog_bar=True, logger=True\n        )\n        return loss","11215838":"# model = CustomResNet(model_name=CFG.model_name, pretrained=CFG.pretrained)\n# lit_model = LitCassava(model.model)","b6b8bb92":"model = CustomEffNet(model_name=CFG.model_name, pretrained=CFG.pretrained)\nlit_model = LitCassava(model.model)","44fe50ca":"logger = CSVLogger(save_dir='logs\/', name=CFG.model_name)\nlogger.log_hyperparams(CFG.__dict__)\ncheckpoint_callback = ModelCheckpoint(monitor='valid_f1',\n                                      save_top_k=1,\n                                      save_last=True,\n                                      save_weights_only=True,\n                                      filename='{epoch:02d}-{valid_loss:.4f}-{valid_f1:.4f}',\n                                      verbose=False,\n                                      mode='max')\n\ntrainer = Trainer(\n    max_epochs=CFG.num_epochs,\n    gpus=[0],\n    accumulate_grad_batches=CFG.accum,\n    precision=CFG.precision,\n#     callbacks=[EarlyStopping(monitor='valid_loss', patience=3, mode='min')],\n    checkpoint_callback=checkpoint_callback,\n    logger=logger,\n    weights_summary='top',\n    amp_backend='native',\n)","5ea8cf3a":"trainer.fit(lit_model, train_dataloader=train_loader, val_dataloaders=valid_loader)","833a572b":"metrics = pd.read_csv(f'{trainer.logger.log_dir}\/metrics.csv')\n\ntrain_acc = metrics['train_f1'].dropna().reset_index(drop=True)\nvalid_acc = metrics['valid_f1'].dropna().reset_index(drop=True)\n    \nfig = plt.figure(figsize=(7, 6))\nplt.grid(True)\nplt.plot(train_acc, color=\"r\", marker=\"o\", label='train\/f1')\nplt.plot(valid_acc, color=\"b\", marker=\"x\", label='valid\/f1')\nplt.ylabel('F1', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='lower right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}\/f1.png')\n\ntrain_loss = metrics['train_loss'].dropna().reset_index(drop=True)\nvalid_loss = metrics['valid_loss'].dropna().reset_index(drop=True)\n\nfig = plt.figure(figsize=(7, 6))\nplt.grid(True)\nplt.plot(train_loss, color=\"r\", marker=\"o\", label='train\/loss')\nplt.plot(valid_loss, color=\"b\", marker=\"x\", label='valid\/loss')\nplt.ylabel('Loss', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='upper right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}\/loss.png')\\\n\nlr = metrics['lr'].dropna().reset_index(drop=True)\n\nfig = plt.figure(figsize=(7, 6))\nplt.grid(True)\nplt.plot(lr, color=\"g\", marker=\"o\", label='learning rate')\nplt.ylabel('LR', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='upper right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}\/lr.png')","91f57f63":"# Config","b0f0d2e2":"# Remove duplicates\n\nThe output of the following [notebook](https:\/\/www.kaggle.com\/nickuzmenkov\/pp2021-duplicates-revealing\/output) was used as a reference.\nIf you find it useful, please vote not only for this notebook, but also for the notebook it refers to!","7a2cafcb":"## Version Notes\n\n- V4  Model: Resnet50,           IMAGE_SIZE: 512, BS: 32, LB: 0.616\n- V6  Model: SE-ResNeXt50_32x4d, IMAGE_SIZE: 512, BS: 16, LB: 0.555\n- V8  Model: Resnet50, IMAGE_SIZE: 512, BS: 32, LB: 0.584\n  - Add processing to remove duplicates [Reference Discussion](https:\/\/www.kaggle.com\/c\/plant-pathology-2021-fgvc8\/discussion\/227829)\n- V11 Model: Resnet50, IMAGE_SIZE: 512, BS: 32, LB: 0.585\n  - More epoch, change lr_scheduler\n- V14 Model: Resnet50, IMAGE_SIZE: 512, BS: 32, LB: 0.572\n  - used torchmetrics(F1, weighted)\n- V15 Model: Resnet50, IMAGE_SIZE: 512, BS: 32, LB: 0.560\n  - Focal Loss(alpha=1, gamma=2)\n- V16 Model: Resnet50, IMAGE_SIZE: 512, BS: 32, LB: 0.580\n  - iterative-stratification(cross validators with stratification for multilabel data)\n- V17 Model: Resnet50, IMAGE_SIZE: 512, BS: 32, LB: 0.758\n  - epoch 60\n- V18 Model: EfficientNetB5 NS, IMAGE_SIZE: 512, BS: 32, LB: ???\n  - change model","bf5c0843":"## Split Train Data","92eb119f":"# Define Model","d4418122":"# Result","8cb2c2a8":"Duplicate images removed and the label should be the sum of the two.","d7007cb2":"# Focal Loss","38ac62a6":"# Training","fd6941be":"# Overview\n\nIn this notebook, I used Pytorch Lightning to solve it as a multi-label problem.\nI used the following [notebook](https:\/\/www.kaggle.com\/demetrypascal\/better-train-csv-format-keras-starter) as a reference.\n\nThe accuracy of the multi-label solution is about the same as that of the simple solution, and I think the accuracy can be improved by post-processing.\n\n[Inference Notebook](https:\/\/www.kaggle.com\/pegasos\/plant2021-multi-label-model-inference)","696d3f5d":"# Define Dataset","ac4d9009":"# MultilabelStratifiedKFold","7fd715b3":"# Import"}}