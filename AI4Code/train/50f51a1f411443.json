{"cell_type":{"e6ef00fe":"code","fa3a547e":"code","fdd5cbf8":"code","84e12504":"code","0e513274":"code","1703bd57":"code","6d8631a9":"code","355de620":"code","4683510e":"code","f3e2cb98":"code","a7cefebc":"code","77ec6bbf":"code","2a0b5664":"code","565f8eca":"code","fc0ec9b2":"code","dfbb99cc":"markdown","3db7cff3":"markdown","0bd93496":"markdown","5222c298":"markdown","2f9d3961":"markdown","e5e1990c":"markdown","1d194e27":"markdown","e41c2b6b":"markdown","5652ef12":"markdown","0a4f68f9":"markdown","1def3e9d":"markdown","75c82fc8":"markdown","bb6a4749":"markdown","9f7fe5e1":"markdown","943fa22f":"markdown","6782915b":"markdown","39f4e1bd":"markdown","8243b8c2":"markdown"},"source":{"e6ef00fe":"import tensorflow as tf\nimport tensorflow_addons as tfa\nimport math\nimport json\n\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets","fa3a547e":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","fdd5cbf8":"IMAGE_SIZE = [512, 512]\nINPUT_SIZE = [256, 256] #just for fast training\nAUTO = tf.data.experimental.AUTOTUNE # \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0432\u043e\u0431\u043e\u0434\u043d\u044b \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b\n\n# num_parallel_reads - \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u0438\u0437\u043c\u0430 \ndef data_pipeline(filenames, label_num, batch_size, is_train=True):\n    label_num = tf.constant(label_num, tf.int32) # \u0421\u043e\u0437\u0434\u0430\u0435\u0442 \u043f\u043e\u0441\u0442\u043e\u044f\u043d\u043d\u044b\u0439 \u0442\u0435\u043d\u0437\u043e\u0440 \u0438\u0437 \u0442\u0435\u043d\u0437\u043e\u0440\u043d\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # \u041d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0439 \u0437\u0430\u043f\u0438\u0441\u0438 \u0438\u0437 \u043e\u0434\u043d\u043e\u0433\u043e \u0438\u043b\u0438 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0444\u0430\u0439\u043b\u043e\u0432 TFRecord\n#     for raw_record in dataset.take(2):\n#         print('\u0432\u044b\u0432\u043e\u0434 \u0447\u0435\u0440\u0435\u0437 repr, \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430 \u0438\u0437 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430')\n#         print(repr(raw_record))\n    print('\u0442\u0438\u043f \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0434\u043e map', type(dataset))\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO) # Dataset.map() \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e read_tfrecord \u043a \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \u043e\u0431\u044a\u0435\u043a\u0442\u0443 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\n    print('\u0442\u0438\u043f \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u043f\u043e\u0441\u043b\u0435 map', type(dataset))\n    print('\u043f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u0438', dataset.take(1))\n    for raw_record in dataset.take(1):\n        print('\u043f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0432 \u0446\u0438\u043a\u043b\u0435')\n        print(repr(raw_record))\n    dataset = dataset.filter(lambda x, y: y == label_num)#only seletcted label number can go through\n    dataset = dataset.map(lambda x, y: x, num_parallel_calls=AUTO)#do not use label    \n    print(\"\u0442\u0438\u043f \u0432 \u0441\u0430\u043c\u043e\u043c \u043a\u043e\u043d\u0446\u0435! : \", type(dataset))\n    for raw_record in dataset.take(1):\n        print('\u041a\u041e\u041d\u0415\u0427\u041d\u042b\u0419 \u0412 \u0426\u0418\u041a\u041b\u0415')\n        print(repr(raw_record))\n    if is_train: # \u0415\u0441\u043b\u0438 \u044d\u0442\u043e \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430, \u0442\u043e:\n        dataset = dataset.map(data_augmentation, num_parallel_calls=AUTO)\n        # repeat \u0438 shuffle \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u044e\u0442 \u0441\u043e\u0437\u0434\u0430\u0432\u0430\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043c\u0430 (\u0447\u0435\u043c \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0439) \u0438\u0437 \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n        dataset = dataset.shuffle(64) # \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0438\u0432\u0430\u0435\u0442 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u044d\u0442\u043e\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n        dataset = dataset.repeat() # \u0432\u0442\u043e\u0440\u0430\u044f \u044d\u043f\u043e\u0445\u0430 \u0431\u0443\u0434\u0435\u0442 \u0438\u043c\u0435\u0442\u044c \u0434\u0440\u0443\u0433\u043e\u0439 \u043f\u043e\u0440\u044f\u0434\u043e\u043a, \u0447\u0435\u043c \u043f\u0435\u0440\u0432\u0430\u044f \u044d\u043f\u043e\u0445\u0430 (\u043f\u043e\u0432\u0442\u043e\u0440\u0435\u043d\u0438\u0435 \u043f\u043e\u0441\u043b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0438\u0432\u0430\u043d\u0438\u044f - \u0432\u0441\u0435\u0433\u0434\u0430 \u0440\u0430\u0437\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445? \u0430 \u043d\u0430\u043e\u0431\u043e\u0440\u043e\u0442 \u0431\u0443\u0434\u0435\u0442 \u043e\u0434\u0438\u043d \u0438 \u0442\u043e\u0442 \u0436\u0435)\n    dataset = dataset.map(resize_and_normalize, num_parallel_calls=AUTO)   \n    dataset = dataset.batch(batch_size) # \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u0442 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u044d\u0442\u043e\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u043f\u0430\u043a\u0435\u0442\u044b (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, 8 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e 3 \u0431\u0430\u0442\u0447\u0430: (1,2,3) (4,5,6) (7,8))\n    dataset = dataset.prefetch(AUTO) # \u041f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u0442\u044c \u0431\u043e\u043b\u0435\u0435 \u043f\u043e\u0437\u0434\u043d\u0438\u0435 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b, \u043f\u043e\u043a\u0430 \u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\n    return dataset\n\ndef read_tfrecord(example):\n    #create a description of the features (\u0441\u043b\u043e\u0432\u0430\u0440\u044c: \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0444\u043e\u0440\u043c\u044b \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0441\u0438\u0433\u043d\u0430\u0442\u0443\u0440\u044b \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0442\u0438\u043f\u0430)\n    tfrecord_format = { \n        \"image\": tf.io.FixedLenFeature([], tf.string), # \u041a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0432\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0434\u043b\u0438\u043d\u044b. \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b:(\u0444\u043e\u0440\u043c\u0430 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u0442\u0438\u043f \u0432\u0432\u043e\u0434\u0438\u043c\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445)\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n        }\n    print('example \u0434\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430', example)\n    example = tf.io.parse_single_example(example, tfrecord_format) # \u041f\u0430\u0440\u0441\u0438\u0442 example \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0442\u0435\u043d\u0437\u043e\u0440\u043e\u0432 (\u043a\u0430\u0436\u0434\u044b\u0439 FixedLenFeature \u0441\u043e\u043f\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d \u0441 \u0442\u0435\u043d\u0437\u043e\u0440\u043e\u043c)\n    print('example \u043f\u043e\u0441\u043b\u0435 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430',example)\n    img = decode_img(example['image'])\n    print('\u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 ', img)\n    label = tf.cast(example['target'], tf.int32)\n    print('\u043c\u0435\u0442\u043a\u0430', label)\n    return img, label\n\ndef decode_img(img):\n    img = tf.image.decode_jpeg(img, channels=3) # \u0414\u0435\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0444\u043e\u0440\u043c\u0430\u0442\u0430 JPEG \u0432 \u0442\u0435\u043d\u0437\u043e\u0440 \u0442\u0438\u043f\u0430 uint8\n    img = tf.cast(img, tf.float32) # \u041f\u0440\u0438\u0432\u043e\u0434\u0438\u0442 \u0442\u0435\u043d\u0437\u043e\u0440 \u043a \u043d\u043e\u0432\u043e\u043c\u0443 \u0442\u0438\u043f\u0443\n    img = tf.reshape(img, [*IMAGE_SIZE, 3]) # \u0418\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0444\u043e\u0440\u043c\u044b \u0442\u0435\u043d\u0437\u043e\u0440\u0430 (512, 512, 3)\n    return img\n\ndef data_augmentation(img):\n    # horizontal flip\n    if tf.random.uniform(()) > 0.5: # \u0412\u044b\u0432\u043e\u0434\u0438\u0442 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0438\u0437 \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f.\n        img = img[:, ::-1, :]\n    \n    # vertical flip\n    if tf.random.uniform(()) > 0.5:\n        img = img[::-1, :, :]\n        \n    # random crop\n    if tf.random.uniform(()) > 0.3:\n        height = tf.random.uniform(shape=(), minval=450, maxval=500)\n        width = tf.random.uniform(shape=(), minval=450, maxval=500)\n        img = tf.image.random_crop(img, [height,width,3])\n    \n    # change brightness and contrast\n    contrast_rate = tf.random.uniform(shape=(), minval=0.8, maxval=1.2)\n    img = tf.image.adjust_contrast(img, contrast_rate)\n    brightness_shift = tf.random.uniform(shape=(), minval=-20, maxval=20)\n    img = tf.image.adjust_brightness(img, brightness_shift)\n    img = tf.clip_by_value(img, 0, 255)\n\n    # change hue\n    hue_rate = tf.random.uniform(shape=(), minval=-0.05, maxval=0.05)\n    img = tf.image.adjust_hue(img, hue_rate)\n    return img\n      \ndef resize_and_normalize(img):\n    img = img[tf.newaxis, ...]\n    print('\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 (\u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u043d\u043e\u0432\u044b\u0439 \u0441\u0442\u043e\u043b\u0431\u0435\u0446)',img)\n    img = tf.image.resize(img, tuple(INPUT_SIZE))[0,:,:,:]\n    print('\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 (\u043f\u043e\u0441\u043b\u0435 resize)',img)\n    img = (img\/127.5) - 1\n    print('\u043c\u043e\u0434\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f', img)\n    return img","84e12504":"def build_gan_models(): # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u0437 2 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u0432 \u0438 2 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u043e\u0432\n    generator_x2y = build_generator()\n    generator_y2x = build_generator()\n    discriminator_x = build_discriminator()\n    discriminator_y = build_discriminator()\n    return generator_x2y, generator_y2x, discriminator_x, discriminator_y\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 UNET \u0434\u043b\u044f CycleGAN. \u0427\u0442\u043e\u0431\u044b \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440, \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0442\u0441\u044f \n# \u043c\u0435\u0442\u043e\u0434\u044b \u043f\u043e\u043d\u0438\u0436\u0430\u044e\u0449\u0435\u0439 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u0438 - downsample \u0438\u043b\u0438 \u043a\u043e\u0434\u0435\u0440 (\u0441\u0432\u0435\u0440\u0442\u043a\u0430 \u0438 \u0441\u0443\u0431\u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u044f) \u0438 \n# \u043f\u043e\u0432\u044b\u0448\u0430\u044e\u0449\u0435\u0439 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u0438 - upsample \u0438\u043b\u0438 \u0434\u0435\u043a\u043e\u0434\u0435\u0440 (\u0442\u0440\u0430\u043d\u0441\u043f\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0432\u0435\u0440\u0442\u043a\u0438).\n\n# \u041f\u043e\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u044f, \u043a\u0430\u043a \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u0438\u0437 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f, \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442 \u0440\u0430\u0437\u043c\u0435\u0440 2D, \u0448\u0438\u0440\u0438\u043d\u0443 \u0438 \u0432\u044b\u0441\u043e\u0442\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043d\u0430 \u0448\u0430\u0433 (stride). \u0428\u0430\u0433 - \u044d\u0442\u043e \u0434\u043b\u0438\u043d\u0430 \u0448\u0430\u0433\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0434\u0435\u043b\u0430\u0435\u0442 \u0444\u0438\u043b\u044c\u0442\u0440. \n# \u041f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u0448\u0430\u0433 \u0440\u0430\u0432\u0435\u043d 2, \u0444\u0438\u043b\u044c\u0442\u0440 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043a\u043e \u0432\u0441\u0435\u043c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u043c \u043f\u0438\u043a\u0441\u0435\u043b\u044f\u043c, \u0447\u0442\u043e \u0441\u043d\u0438\u0436\u0430\u0435\u0442 \u0432\u0435\u0441 \u0438 \u0432\u044b\u0441\u043e\u0442\u0443 \u043d\u0430 2.\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u0432\u043c\u0435\u0441\u0442\u043e \u043f\u0430\u043a\u0435\u0442\u043d\u043e\u0439. \u0422\u0430\u043a\u0430\u044f \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043d\u0435 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u043e\u0439 \u0432 TensorFlow API, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0441\u043b\u043e\u0439 \u0438\u0437 TensorFlow Add-ons.\ndef downsample(filters, size, apply_instancenorm=True):\n    # \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0442\u043e\u0440\u044b \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u044e\u0442 \u0437\u0430\u0440\u0430\u043d\u0435\u0435 \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438, \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u0432 \u043e\u0431\u044a\u0435\u043a\u0442\u0435 Initializer, \u0431\u0435\u0437 \u0437\u043d\u0430\u043d\u0438\u044f \u0444\u043e\u0440\u043c\u044b \u0438 dtype \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439.\n    initializer = tf.random_normal_initializer(0., 0.02) # \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0442\u043e\u0440, \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u044e\u0449\u0438\u0439 \u0442\u0435\u043d\u0437\u043e\u0440\u044b \u0441 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u043c (c\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c\u044b\u0445 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439; \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u043e\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435 \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c\u044b\u0445 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02) # (\u043a\u043b\u0430\u0441\u0441) \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0442\u043e\u0440, \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u044e\u0449\u0438\u0439 \u0442\u0435\u043d\u0437\u043e\u0440\u044b \u0441 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u043c.\n\n    result = tf.keras.Sequential() # \u041f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u0433\u0440\u0443\u043f\u043f\u0438\u0440\u0443\u0435\u0442 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0439 \u0441\u0442\u0435\u043a \u0441\u043b\u043e\u0435\u0432 \u0432 tf.keras.Model. \u041f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0432\u044b\u0432\u043e\u0434\u0430\n    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                             kernel_initializer=initializer, use_bias=False)) # 2D \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0439 \u0441\u043b\u043e\u0439 (1. filter - \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0430 (\u0442\u043e \u0435\u0441\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0445 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0432 \u0441\u0432\u0435\u0440\u0442\u043a\u0435)\n                # 2. kernel_size - \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0435\u0442 \u0432\u044b\u0441\u043e\u0442\u0443 \u0438 \u0448\u0438\u0440\u0438\u043d\u0443 \u043e\u043a\u043d\u0430 \u0434\u0432\u0443\u043c\u0435\u0440\u043d\u043e\u0439 \u0441\u0432\u0435\u0440\u0442\u043a\u0438. \u041c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043e\u0434\u043d\u0438\u043c \u0446\u0435\u043b\u044b\u043c \u0447\u0438\u0441\u043b\u043e\u043c, \u0447\u0442\u043e\u0431\u044b \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u043e\u0434\u043d\u043e \u0438 \u0442\u043e \u0436\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u0439.\n                # 3. strides - \u0446\u0435\u043b\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0449\u0435\u0435 \u0448\u0430\u0433 \u0441\u0432\u0435\u0440\u0442\u043a\u0438 \u043f\u043e \u0432\u044b\u0441\u043e\u0442\u0435 \u0438 \u0448\u0438\u0440\u0438\u043d\u0435. \u041c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043e\u0434\u043d\u0438\u043c \u0446\u0435\u043b\u044b\u043c \u0447\u0438\u0441\u043b\u043e\u043c, \u0447\u0442\u043e\u0431\u044b \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u043e\u0434\u043d\u043e \u0438 \u0442\u043e \u0436\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u0439. \n                # 4. padding - \u00absame\u00bb \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442 \u043a \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u043c\u0443 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044e \u0441\u043b\u0435\u0432\u0430 \/ \u0441\u043f\u0440\u0430\u0432\u0430 \u0438\u043b\u0438 \u0432\u0432\u0435\u0440\u0445 \/ \u0432\u043d\u0438\u0437 \u043e\u0442 \u0432\u0432\u043e\u0434\u0430, \u0442\u0430\u043a \u0447\u0442\u043e \u0432\u044b\u0432\u043e\u0434 \u0438\u043c\u0435\u0435\u0442 \u0442\u043e\u0442 \u0436\u0435 \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u044b\u0441\u043e\u0442\u044b \/ \u0448\u0438\u0440\u0438\u043d\u044b, \u0447\u0442\u043e \u0438 \u0432\u0432\u043e\u0434.\n                # 5. kernel_initializer - b\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0442\u043e\u0440 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0432\u0435\u0441\u043e\u0432 \u044f\u0434\u0440\u0430\n                # 6. use_bias - \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435, \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u043b\u0438 \u0441\u043b\u043e\u0439 \u0432\u0435\u043a\u0442\u043e\u0440 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u044f.)\n\n    if apply_instancenorm:\n        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)) # \u0421\u043b\u043e\u0439 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 (gamma_initializer: \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0442\u043e\u0440 \u0433\u0430\u043c\u043c\u0430-\u0432\u0435\u0441\u0430)\n        # \u0412 \u00ab\u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430\u00bb \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044f \u0440\u0430\u0441\u0441\u0447\u0438\u0442\u044b\u0432\u0430\u044e\u0442\u0441\u044f \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043a\u0430\u043d\u0430\u043b\u0430 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u043f\u043e \u043e\u0431\u043e\u0438\u043c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u043c \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f\u043c\n\n    # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043d\u0435\u0439\u0440\u043e\u043d\u0430 \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u0432\u0437\u0432\u0435\u0448\u0435\u043d\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b \u0432\u0445\u043e\u0434\u043e\u0432 \u0438 \u043f\u043e\u0440\u043e\u0433\u043e\u0432\u043e\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.\n    result.add(tf.keras.layers.LeakyReLU()) # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438 ReLU \u0441 \u00ab\u0443\u0442\u0435\u0447\u043a\u043e\u0439\u00bb (leaky ReLU, LReLU)\n\n    return result\n\ndef upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = tf.keras.Sequential()\n    \n    # \u0422\u0440\u0430\u043d\u0441\u043f\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0439 \u0441\u043b\u043e\u0439 (\u0438\u043d\u043e\u0433\u0434\u0430 \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u044b\u0439 \u0434\u0435\u043a\u043e\u043d\u0432\u043e\u043b\u044e\u0446\u0438\u0435\u0439). \u041f\u043e\u0442\u0440\u0435\u0431\u043d\u043e\u0441\u0442\u044c \u0432 \u0442\u0440\u0430\u043d\u0441\u043f\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0441\u0432\u0435\u0440\u0442\u043a\u0430\u0445 \u043e\u0431\u044b\u0447\u043d\u043e \u0432\u043e\u0437\u043d\u0438\u043a\u0430\u0435\u0442 \u0438\u0437-\u0437\u0430 \u0436\u0435\u043b\u0430\u043d\u0438\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435, \u0438\u0434\u0443\u0449\u0435\u0435 \u0432 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0438, \u043f\u0440\u043e\u0442\u0438\u0432\u043e\u043f\u043e\u043b\u043e\u0436\u043d\u043e\u043c \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0439 \u0441\u0432\u0435\u0440\u0442\u043a\u0435, \u0442. e. \u043e\u0442 \u0447\u0435\u0433\u043e-\u0442\u043e, \u0447\u0442\u043e \u0438\u043c\u0435\u0435\u0442 \u0444\u043e\u0440\u043c\u0443 \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0441\u0432\u0435\u0440\u0442\u043a\u0438, \u043a \u0447\u0435\u043c\u0443-\u0442\u043e, \u0447\u0442\u043e \n    # \u0438\u043c\u0435\u0435\u0442 \u0444\u043e\u0440\u043c\u0443 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u0440\u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0438 \u0448\u0430\u0431\u043b\u043e\u043d \u0441\u0432\u044f\u0437\u043d\u043e\u0441\u0442\u0438, \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u044b\u0439 \u0441 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0439 \u0441\u0432\u0435\u0440\u0442\u043a\u043e\u0439.\n    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', \n                                      kernel_initializer=initializer, use_bias=False))\n\n    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    if apply_dropout:\n        result.add(tf.keras.layers.Dropout(0.5)) # 0.5 \u044d\u0442\u043e \u0434\u043e\u043b\u044f \u0432\u0432\u043e\u0434\u0438\u043c\u044b\u0445 \u0435\u0434\u0438\u043d\u0438\u0446, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043d\u0443\u0436\u043d\u043e \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u0442\u044c.\n        # \u0421\u043b\u043e\u0439 Dropout \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u0442 \u0434\u043b\u044f \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0435\u0434\u0438\u043d\u0438\u0446 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 0 \u0441 \u0447\u0430\u0441\u0442\u043e\u0442\u043e\u0439 \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0448\u0430\u0433\u0435 \u0432\u043e \u0432\u0440\u0435\u043c\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u0447\u0442\u043e \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442 \u043f\u0440\u0435\u0434\u043e\u0442\u0432\u0440\u0430\u0442\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n\n    result.add(tf.keras.layers.ReLU()) # ReLu \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0445, \u0435\u0441\u043b\u0438 \u0445 \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u043e, \u0438 0 \u0432 \u043f\u0440\u043e\u0442\u0438\u0432\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435. \n\n    return result\n\n# U-net \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442 \u0441 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438 \u043e\u0447\u0435\u043d\u044c \u043f\u0440\u043e\u0441\u0442\u0443\u044e \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u044e \u2014 \u043f\u043e\u0448\u0430\u0433\u043e\u0432\u043e \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442 \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0441 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u043c\u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f\u043c\u0438 \u0438 \u043f\u043e\u0441\u043b\u0435 \u043f\u044b\u0442\u0430\u0435\u0442\u0441\u044f \u0432\u043e\u0441\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u044c \u043c\u0430\u0441\u043a\u0443 \n# \u0438\u0437 \u0441\u0436\u0430\u0442\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \u0422.\u0435. \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442\u0441\u044f \u0438 \u0434\u0430\u043b\u0435\u0435 \u043f\u044b\u0442\u0430\u0435\u043c\u0441\u044f \u0432\u043e\u0441\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u044c \u043c\u0430\u0441\u043a\u0443 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u043e \u0432\u0441\u0435\u0445 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0445 \u0441\u0436\u0430\u0442\u0438\u0439.\n\n# \u0413\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043f\u043e\u043d\u0438\u0436\u0430\u0435\u0442 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u044e \u0432\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u0430 \u0437\u0430\u0442\u0435\u043c \u043f\u043e\u0432\u044b\u0448\u0430\u0435\u0442 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u044e, \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u044f \u0441\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044f \u0441 \u0434\u043b\u0438\u043d\u043d\u044b\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u043c.\n# \u041f\u0440\u043e\u043f\u0443\u0441\u043a \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0439 - \u044d\u0442\u043e \u0441\u043f\u043e\u0441\u043e\u0431 \u043f\u043e\u043c\u043e\u0447\u044c \u043e\u0431\u043e\u0439\u0442\u0438 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0438\u0441\u0447\u0435\u0437\u0430\u044e\u0449\u0435\u0433\u043e \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u0430, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u044f \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u043b\u043e\u044f \u0441 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u043c\u0438 \u0441\u043b\u043e\u044f\u043c\u0438, \u0430 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0441 \u043e\u0434\u043d\u0438\u043c.\n# \u0417\u0434\u0435\u0441\u044c \u043c\u044b \u0441\u0438\u043c\u043c\u0435\u0442\u0440\u0438\u0447\u043d\u043e \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0443\u0440\u043e\u0432\u043d\u044f \u0441\u0443\u0431\u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u0438 \u0441\u043e \u0441\u043b\u043e\u0435\u043c \u043f\u043e\u0432\u044b\u0448\u0430\u044e\u0449\u0435\u0439 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u0438.\ndef build_generator():\n    # Input() \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0442\u0435\u043d\u0437\u043e\u0440\u0430.\n    # \u0422\u0435\u043d\u0437\u043e\u0440 Keras - \u044d\u0442\u043e \u0441\u0438\u043c\u0432\u043e\u043b\u044c\u043d\u044b\u0439 \u0442\u0435\u043d\u0437\u043e\u0440\u043d\u044b\u0439 \u043e\u0431\u044a\u0435\u043a\u0442 TensorFlow, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u044b \u0434\u043e\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u043c\u0438 \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u0430\u043c\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u044e\u0442 \u043d\u0430\u043c \u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c Keras, \u043f\u0440\u043e\u0441\u0442\u043e \u0437\u043d\u0430\u044f \u0432\u0445\u043e\u0434\u043d\u044b\u0435 \u0438 \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438.\n    inputs = tf.keras.layers.Input(shape=[256,256,3]) \n\n    # bs = batch size\n    down_stack = [\n        downsample(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n        downsample(128, 4), # (bs, 64, 64, 128)\n        downsample(256, 4), # (bs, 32, 32, 256)\n        downsample(512, 4), # (bs, 16, 16, 512)\n        downsample(512, 4), # (bs, 8, 8, 512)\n        downsample(512, 4), # (bs, 4, 4, 512)\n        downsample(512, 4), # (bs, 2, 2, 512)\n        downsample(512, 4), # (bs, 1, 1, 512)\n    ]\n\n    up_stack = [\n        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n        upsample(512, 4), # (bs, 16, 16, 1024)\n        upsample(256, 4), # (bs, 32, 32, 512)\n        upsample(128, 4), # (bs, 64, 64, 256)\n        upsample(64, 4), # (bs, 128, 128, 128)\n    ]\n\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = tf.keras.layers.Conv2DTranspose(3, 4, # \u0444\u0438\u043b\u044c\u0442\u0440\u044b 3 \u0438 4 \u044d\u0442\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0430 (\u0442\u043e \u0435\u0441\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0445 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u0432 \u0441\u0432\u0435\u0440\u0442\u043a\u0435)\n                                  strides=2,\n                                  padding='same',\n                                  kernel_initializer=initializer,\n                                  activation='tanh') # (bs, 256, 256, 3)\n\n    x = inputs # \u0442\u0435\u043d\u0437\u043e\u0440 (inputs = tf.keras.layers.Input(shape=[256,256,3]))\n\n    # Downsampling through the model (\u043f\u043e\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u0438 \u043f\u043e \u043c\u043e\u0434\u0435\u043b\u0438)\n    skips = []\n    for down in down_stack:\n        # \u0432\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 (x) \u043f\u0435\u0440\u0435\u0434\u0430\u044e\u0442\u0441\u044f \u0432 \u0441\u043b\u043e\u0438 \n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections (\u043f\u043e\u0432\u044b\u0448\u0435\u043d\u0438\u0435 \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0430\u0446\u0438\u0438 \u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430 \u0441\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0439)\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = tf.keras.layers.Concatenate()([x, skip]) # \u0421\u043b\u043e\u0439, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u044e\u0449\u0438\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u0432\u0445\u043e\u0434\u043e\u0432. \u041e\u043d \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u043f\u0438\u0441\u043e\u043a \u0442\u0435\u043d\u0437\u043e\u0440\u043e\u0432, \u0432\u0441\u0435 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e\u0439 \u0444\u043e\u0440\u043c\u044b, \n        # \u0437\u0430 \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435\u043c \u043e\u0441\u0438 \u043a\u043e\u043d\u043a\u0430\u0442\u0435\u043d\u0430\u0446\u0438\u0438, \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0439 \u0442\u0435\u043d\u0437\u043e\u0440, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043a\u043e\u043d\u043a\u0430\u0442\u0435\u043d\u0430\u0446\u0438\u0435\u0439 \u0432\u0441\u0435\u0445 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445.\n\n    # \u043f\u0435\u0440\u0435\u0434\u0430\u0447\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0439 \u0441\u043b\u043e\u0439\n    x = last(x)\n    \n    \"\"\"\n                                                                # !!!\u0434\u043b\u044f \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432 \u0432\u0438\u0434\u0435 \u0433\u0440\u0430\u0444\u0438\u043a\u0430!!!\n                                              # >>> keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)\n    \"\"\"\n    \n    return tf.keras.Model(inputs=inputs, outputs=x)\n\n# \u0414\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0432\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u0446\u0438\u0440\u0443\u0435\u0442 \u0435\u0433\u043e \u043a\u0430\u043a \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u0435 \u0438\u043b\u0438 \u043f\u043e\u0434\u0434\u0435\u043b\u044c\u043d\u043e\u0435 (\u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435). \u0412\u043c\u0435\u0441\u0442\u043e \u0432\u044b\u0432\u043e\u0434\u0430 \u043e\u0434\u043d\u043e\u0433\u043e \u0443\u0437\u043b\u0430 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u0432\u044b\u0432\u043e\u0434\u0438\u0442 \n# \u043c\u0435\u043d\u044c\u0448\u0435\u0435 2D-\u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0441 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u0438\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439, \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0438\u043c\u0438 \u0440\u0435\u0430\u043b\u044c\u043d\u0443\u044e \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e, \u0438 \u0431\u043e\u043b\u0435\u0435 \u043d\u0438\u0437\u043a\u0438\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438, \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0438\u043c\u0438 \u043f\u043e\u0434\u0434\u0435\u043b\u044c\u043d\u0443\u044e \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e.\ndef build_discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    inputs = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n    \n    # \u0421\u043e\u0437\u0434\u0430\u0435\u0442 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440 \u043c\u043e\u0434\u0435\u043b\u0438 VGG16. \u041f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u043e\u043d \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u0442 \u0432\u0435\u0441\u0430, \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0432 ImageNet. \n    # include_top - \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u043b\u0438 \u0432\u043a\u043b\u044e\u0447\u0430\u0442\u044c 3 \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0445 \u0443\u0440\u043e\u0432\u043d\u044f \u0432 \u0432\u0435\u0440\u0445\u043d\u044e\u044e \u0447\u0430\u0441\u0442\u044c \u0441\u0435\u0442\u0438.\n    # input_shape - \u043d\u0435\u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043a\u043e\u0440\u0442\u0435\u0436 \u0444\u043e\u0440\u043c\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0434\u043e\u043b\u0436\u0435\u043d \u0431\u044b\u0442\u044c \u0443\u043a\u0430\u0437\u0430\u043d \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0442\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, \u0435\u0441\u043b\u0438 include_top \u2014 False (\u0438\u043d\u0430\u0447\u0435 \u0432\u0445\u043e\u0434\u043d\u0430\u044f \u0444\u043e\u0440\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c (224, 224, 3). \n    # \u041e\u043d \u0434\u043e\u043b\u0436\u0435\u043d \u0438\u043c\u0435\u0442\u044c \u0440\u043e\u0432\u043d\u043e 3 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u043a\u0430\u043d\u0430\u043b\u0430, \u0430 \u0448\u0438\u0440\u0438\u043d\u0430 \u0438 \u0432\u044b\u0441\u043e\u0442\u0430 \u0434\u043e\u043b\u0436\u043d\u044b \u0431\u044b\u0442\u044c \u043d\u0435 \u043c\u0435\u043d\u0435\u0435 32. \n    pretrained_model = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False ,input_shape=[256, 256, 3])\n    x = pretrained_model(inputs)\n    \n    last =  tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x)\n    \n    return tf.keras.Model(inputs=inputs, outputs=last)\n\n# \u041f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u0430\u044f \u043d\u0438\u0436\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u0442 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441 \u043c\u0430\u0442\u0440\u0438\u0446\u0435\u0439 \u0435\u0434\u0438\u043d\u0438\u0446, \u0430 \u043f\u043e\u0434\u0434\u0435\u043b\u044c\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f - \u0441 \u043c\u0430\u0442\u0440\u0438\u0446\u0435\u0439 \u043d\u0443\u043b\u0435\u0439. \n# \u0418\u0434\u0435\u0430\u043b\u044c\u043d\u044b\u0439 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u0432\u044b\u0434\u0430\u0441\u0442 \u0432\u0441\u0435 \u0435\u0434\u0438\u043d\u0438\u0446\u044b \u0434\u043b\u044f \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u0432\u0441\u0435 \u043d\u0443\u043b\u0438 \u0434\u043b\u044f \u043f\u043e\u0434\u0434\u0435\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.\n# \u041f\u043e\u0442\u0435\u0440\u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0432\u044b\u0432\u043e\u0434\u044f\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c\u044b\u0445 \u043f\u043e\u0442\u0435\u0440\u044c.\ndef discriminator_loss(real, generated):\n    # BinaryCrossentropy \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u0442 \u043f\u043e\u0442\u0435\u0440\u044e \u043a\u0440\u043e\u0441\u0441-\u044d\u043d\u0442\u0440\u043e\u043f\u0438\u0438 \u043c\u0435\u0436\u0434\u0443 \u0438\u0441\u0442\u0438\u043d\u043d\u044b\u043c\u0438 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u043c\u0438 \u043c\u0435\u0442\u043a\u0430\u043c\u0438.\n    # \u0435\u0441\u043b\u0438 reduction None \u0442\u043e \u0431\u0443\u0434\u0435\u0442 \u0438\u043c\u0435\u0442\u044c \u0444\u043e\u0440\u043c\u0443 [batch_size, d0, .. dN-1], \u0430 \u0432 \u043f\u0440\u043e\u0442\u0438\u0432\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 - \u0441\u043a\u0430\u043b\u044f\u0440\n    # (\u041e\u0431\u0440\u0430\u0442\u0438\u0442\u0435 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u043d\u0430 dN-1, \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u0432\u0441\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u044e\u0442\u0441\u044f \u043d\u0430 1 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u0435, \u043e\u0431\u044b\u0447\u043d\u043e \u043e\u0441\u044c = -1.)\n    bc_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n    real_loss = bc_loss(tf.ones_like(real), real)# real as real\n    generated_loss = bc_loss(tf.zeros_like(generated), generated)# fake as fake\n    return (real_loss + generated_loss) * 0.5\n\n# \u0413\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0445\u043e\u0447\u0435\u0442 \u043e\u0431\u043c\u0430\u043d\u0443\u0442\u044c \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440, \u0437\u0430\u0441\u0442\u0430\u0432\u0438\u0432 \u0435\u0433\u043e \u0434\u0443\u043c\u0430\u0442\u044c, \u0447\u0442\u043e \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u043c. \n# \u0418\u0434\u0435\u0430\u043b\u044c\u043d\u044b\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0431\u0443\u0434\u0435\u0442 \u0438\u043c\u0435\u0442\u044c \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0442\u043e\u043b\u044c\u043a\u043e \u0435\u0434\u0438\u043d\u0438\u0446\u044b. \n# \u0422\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u043e\u043d \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u0442 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0441 \u043c\u0430\u0442\u0440\u0438\u0446\u0435\u0439 \u0435\u0434\u0438\u043d\u0438\u0446, \u0447\u0442\u043e\u0431\u044b \u043d\u0430\u0439\u0442\u0438 \u043f\u043e\u0442\u0435\u0440\u044e.\ndef generator_loss(generated):\n    bc_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE) # fake as real\n    return bc_loss(tf.ones_like(generated), generated)\n\n# \u041c\u044b \u0445\u043e\u0442\u0438\u043c, \u0447\u0442\u043e\u0431\u044b \u043d\u0430\u0448\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u0430\u044f \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044f \u0438 \u0434\u0432\u0430\u0436\u0434\u044b \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044f \u0431\u044b\u043b\u0438 \u043f\u043e\u0445\u043e\u0436\u0438 \u0434\u0440\u0443\u0433 \u043d\u0430 \u0434\u0440\u0443\u0433\u0430. \n# \u0422\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u043f\u043e\u0442\u0435\u0440\u044e \u0441\u043e\u0433\u043b\u0430\u0441\u043e\u0432\u0430\u043d\u043d\u043e\u0441\u0442\u0438 \u0446\u0438\u043a\u043b\u0430, \u043d\u0430\u0439\u0434\u044f \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438\u0445 \u0440\u0430\u0437\u043d\u0438\u0446\u044b.\ndef calc_cycle_loss(real_image, cycled_image):\n    # reduce_mean \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0443 \u0442\u0435\u043d\u0437\u043e\u0440\u0430. \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0439 \u0442\u0435\u043d\u0437\u043e\u0440.\n    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n    return 10 * loss\n\n# \u041f\u0440\u0438 \u043f\u043e\u0442\u0435\u0440\u0435 \u0438\u0434\u0435\u043d\u0442\u0438\u0447\u043d\u043e\u0441\u0442\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441 \u0435\u0433\u043e \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u043c (\u0442.\u0435. \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044f \u0441 \u0444\u043e\u0442\u043e\u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u043c). \n# \u0415\u0441\u043b\u0438 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044f, \u043c\u044b \u0445\u043e\u0442\u0438\u043c, \u0447\u0442\u043e\u0431\u044b \u043e\u043d\u0430 \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043b\u0430 \u0442\u043e \u0436\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435, \u0447\u0442\u043e \u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435.\n# \u041f\u0440\u0438 \u043f\u043e\u0442\u0435\u0440\u0435 \u0438\u0434\u0435\u043d\u0442\u0438\u0447\u043d\u043e\u0441\u0442\u0438 \u0432\u0445\u043e\u0434\u043d\u043e\u0439 \u0441\u0438\u0433\u043d\u0430\u043b \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441 \u0432\u044b\u0445\u043e\u0434\u043e\u043c \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430.\ndef identity_loss(real_image, same_image):\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return 5 * loss\n\n\n# \u041d\u0430 \u044d\u0442\u0430\u043f\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u0442 \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044e \u0440\u0430\u0441\u0442\u0435\u043d\u0438\u044f \u0432 \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044e \u0431\u043e\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u0442\u0435\u043d\u0438\u044f, \u0430 \u0437\u0430\u0442\u0435\u043c \u043e\u0431\u0440\u0430\u0442\u043d\u043e \u0432 \u0437\u0434\u043e\u0440\u043e\u0432\u043e\u0435. \n# \u0420\u0430\u0437\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0439 \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0435\u0439 \u0438 \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0435\u0439 \u0441 \u0434\u0432\u043e\u0439\u043d\u044b\u043c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u043f\u043e\u0442\u0435\u0440\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0446\u0438\u043a\u043b\u0430.\n# \u041c\u044b \u0445\u043e\u0442\u0438\u043c, \u0447\u0442\u043e\u0431\u044b \u0438\u0441\u0445\u043e\u0434\u043d\u0430\u044f \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044f \u0438 \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044f \u0441 \u0434\u0432\u043e\u0439\u043d\u044b\u043c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0431\u044b\u043b\u0438 \u043f\u043e\u0445\u043e\u0436\u0438 \u0434\u0440\u0443\u0433 \u043d\u0430 \u0434\u0440\u0443\u0433\u0430.\nclass CycleGan(tf.keras.Model):\n    def __init__( # init - \u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0442\u043e\u0440 \u043a\u043b\u0430\u0441\u0441\u0430. \u041c\u0435\u0442\u043e\u0434 __init__ \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043f\u0440\u0438 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0438 \u043f\u0430\u043c\u044f\u0442\u0438 \u0434\u043b\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u0430: x = CycleGan(g, g, d, d)\n        self, # \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 self \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0441\u044f \u043a \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0443 \u043e\u0431\u044a\u0435\u043a\u0442\u0430. \u0412\u0430\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 self \u0432\u043d\u0443\u0442\u0440\u0438 \u043c\u0435\u0442\u043e\u0434\u0430 \u043e\u0431\u044a\u0435\u043a\u0442\u0430, \u0435\u0441\u043b\u0438 \u0432\u044b \u0445\u043e\u0442\u0438\u0442\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u043c.\n        # \u0415\u0441\u043b\u0438 \u043d\u0435 \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c self, \u0442\u043e \u0432\u0441\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u0443\u0434\u0443\u0442 \u0445\u0440\u0430\u043d\u0438\u0442\u044c\u0441\u044f \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0432 \u0441\u0442\u0435\u043a\u0435 \u0438 \u0431\u0443\u0434\u0443\u0442 \u043e\u0442\u0431\u0440\u043e\u0448\u0435\u043d\u044b, \u043a\u043e\u0433\u0434\u0430 \u043c\u0435\u0442\u043e\u0434 init \u0432\u044b\u0439\u0434\u0435\u0442 \u0437\u0430 \u043f\u0440\u0435\u0434\u0435\u043b\u044b \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0432\u0438\u0434\u0438\u043c\u043e\u0441\u0442\u0438.\n        generator_x2y,\n        generator_y2x,\n        discriminator_x,\n        discriminator_y,\n    ):\n        super(CycleGan, self).__init__() # super \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0438\u0437\u0431\u0435\u0433\u0430\u0442\u044c \u044f\u0432\u043d\u043e\u0433\u043e \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u044f \u043a \u0431\u0430\u0437\u043e\u0432\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443 (\u043d\u0435 \u043f\u0438\u0441\u0430\u0442\u044c \u043a\u043b\u0430\u0441\u0441-\u0440\u043e\u0434\u0438\u0442\u0435\u043b\u044c)\n        self.generator_x2y = generator_x2y\n        self.generator_y2x = generator_y2x\n        self.discriminator_x = discriminator_x\n        self.discriminator_y = discriminator_y\n        \n    def compile(\n        self,\n        generator_x2y_optimizer,\n        generator_y2x_optimizer,\n        discriminator_x_optimizer,\n        discriminator_y_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile() # compile() \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043a\u043e\u0434 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u0430 \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043e\u0431\u044a\u0435\u043a\u0442 \u043a\u043e\u0434\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043b\u0435\u0433\u043a\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0434\u043b\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f.\n        self.generator_x2y_optimizer = generator_x2y_optimizer\n        self.generator_y2x_optimizer = generator_y2x_optimizer\n        self.discriminator_x_optimizer = discriminator_x_optimizer\n        self.discriminator_y_optimizer = discriminator_y_optimizer\n        self.generator_loss = gen_loss_fn\n        self.discriminator_loss = disc_loss_fn\n        self.cycle_loss = cycle_loss_fn\n        self.identity_loss = identity_loss_fn\n        \n    def train_step(self, batch_data):\n        real_x, real_y = batch_data # \u0420\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445 \u0438 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0431\u043e\u043b\u044c\u043d\u044b\u0445\n        \n        # TensorFlow \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442tf.GradientTape API \u0434\u043b\u044f \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043b\u0438\u0447\u0435\u043d\u0438\u044f; \u0442\u043e \u0435\u0441\u0442\u044c \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \n        # \u043e\u0431\u044b\u0447\u043d\u043e tf.Variable s. TensorFlow \u00ab\u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u0442\u00bb \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438, \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c\u044b\u0435 \u0432 \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\u0435 tf.GradientTape \u043d\u0430 \u00ab\u043b\u0435\u043d\u0442\u0443\u00bb. \n        # \u0417\u0430\u0442\u0435\u043c TensorFlow \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u044d\u0442\u0443 \u043b\u0435\u043d\u0442\u0443 \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \u00ab\u0437\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u043e\u0433\u043e\u00bb \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043e\u0431\u0440\u0430\u0442\u043d\u043e\u0433\u043e \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f .\n        # \u041e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u044e\u0442\u0441\u044f, \u0435\u0441\u043b\u0438 \u043e\u043d\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u044e\u0442\u0441\u044f \u0432 \u044d\u0442\u043e\u043c \u0434\u0438\u0441\u043f\u0435\u0442\u0447\u0435\u0440\u0435 \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\u0430 \u0438 \u0445\u043e\u0442\u044f \u0431\u044b \u043e\u0434\u0438\u043d \u0438\u0437 \u0438\u0445 \u0432\u0445\u043e\u0434\u043e\u0432 \u00ab\u043e\u0442\u0441\u043b\u0435\u0436\u0438\u0432\u0430\u0435\u0442\u0441\u044f\u00bb.\n        # \u041e\u0431\u0443\u0447\u0430\u0435\u043c\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 (\u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0435 tf.Variable \u0438\u043b\u0438 tf.compat.v1.get_variable, \u0433\u0434\u0435 trainable = True \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0432 \u043e\u0431\u043e\u0438\u0445 \u0441\u043b\u0443\u0447\u0430\u044f\u0445) \u043e\u0442\u0441\u043b\u0435\u0436\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438.\n        # \u0427\u0442\u043e\u0431\u044b \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \u0437\u0430 \u043e\u0434\u043d\u043e \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435, \u0441\u043e\u0437\u0434\u0430\u0439\u0442\u0435 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u0443\u044e \u043b\u0435\u043d\u0442\u0443 \u0441 persistent=True\n        with tf.GradientTape(persistent=True) as tape: \n            # Generator G translates X -> Y    \n            # Generator F translates Y -> X.   \n            # generator_x2y - \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \u0432 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 (\u0412\u0415\u0420\u041d\u041e!)\n            # generator_y2x - \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 \u0432 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 (\u0412\u0415\u0420\u041d\u041e!)\n\n            # \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 \u0432 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \u0438 \u043e\u0431\u0440\u0430\u0442\u043d\u043e \u0432 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435\n            fake_y = self.generator_x2y(real_x, training=True) # \u0432 \u043f\u0435\u0440\u0432\u044b\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 -> \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \n            cycled_x = self.generator_y2x(fake_y, training=True) # \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 (\u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435) \u0431\u043e\u043b\u044c\u043d\u044b\u0435 -> \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0441\u043d\u043e\u0432\u0430 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 (\u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435)\n\n            # \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \u0432 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 \u0438 \u043e\u0431\u0440\u0430\u0442\u043d\u043e \u0432 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \n            fake_x = self.generator_y2x(real_y, training=True) # \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 -> \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435\n            cycled_y = self.generator_x2y(fake_x, training=True) # \u0432 \u043f\u0435\u0440\u0432\u044b\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 -> \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0441\u043d\u043e\u0432\u0430 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 (\u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435)\n\n            # generating itself\n            # same_x and same_y are used for identity loss. in half cycle, do not change original image (\u0432 \u043f\u043e\u043b\u0443\u043f\u0435\u0440\u0438\u043e\u0434\u0435, \u043d\u0435 \u043c\u0435\u043d\u044f\u0442\u044c \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435)\n            same_x = self.generator_y2x(real_x, training=True) # \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 (\u0431 -> \u0437) \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 -> \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0442\u0430\u043a\u0438\u0435 \u0436\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435\n            same_y = self.generator_x2y(real_y, training=True) # \u0432 \u043f\u0435\u0440\u0432\u044b\u0439 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 (\u0437 -> \u0431) \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 -> \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0442\u0430\u043a\u0438\u0435 \u0436\u0435 \u0431\u043e\u043b\u044c\u043d\u044b\u0435\n\n            # discriminate 4 images in total \n            # \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u044b, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438, \u0432\u0432\u043e\u0434\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n            disc_real_x = self.discriminator_x(real_x, training=True) # \u0432 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n            disc_real_y = self.discriminator_y(real_y, training=True) # \u0432 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u0431\u043e\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\n            # \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u044b, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438, \u0432\u0432\u043e\u0434\u0430 \u043f\u043e\u0434\u0434\u0435\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n            disc_fake_x = self.discriminator_x(fake_x, training=True) # \u0432 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n            disc_fake_y = self.discriminator_y(fake_y, training=True) # \u0432 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440 \u0431\u043e\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0431\u043e\u043b\u044c\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\n            # calculate the loss (\u043e\u0446\u0435\u043d\u0438\u0432\u0430\u0435\u0442 \u043f\u043e\u0442\u0435\u0440\u0438 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430)\n            gen_x2y_loss = self.generator_loss(disc_fake_y) # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0440\u0430\u0431\u043e\u0442\u044b \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0431\u043e\u043b\u044c\u043d\u044b\u0445 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043e\u0446\u0435\u043d\u043a\u0438 \u043e\u0448\u0438\u0431\u043a\u0438 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 (\u0437->\u0431)\n            gen_y2x_loss = self.generator_loss(disc_fake_x) # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0440\u0430\u0431\u043e\u0442\u044b \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445 \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043e\u0446\u0435\u043d\u043a\u0438 \u043e\u0448\u0438\u0431\u043a\u0438 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 (\u0431->\u0437)\n\n            # \u041e\u0446\u0435\u043d\u0438\u0432\u0430\u0435\u0442 \u043e\u0431\u0449\u0443\u044e \u043f\u043e\u0442\u0435\u0440\u044e \u0441\u043e\u0433\u043b\u0430\u0441\u043e\u0432\u0430\u043d\u043d\u043e\u0441\u0442\u0438 \u0446\u0438\u043a\u043b\u0430\n            total_cycle_loss = self.cycle_loss(real_x, cycled_x) + self.cycle_loss(real_y, cycled_y) # \u043f\u043e\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0438 \u043f\u0440\u043e\u0448\u0435\u0434\u0448\u0438\u0435 2 \u043c\u043e\u0434\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\n\n            # Total generator loss = adversarial loss + cycle loss (\u041f\u043e\u043b\u043d\u0430\u044f \u043f\u043e\u0442\u0435\u0440\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 = \u0441\u043e\u0441\u0442\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043f\u043e\u0442\u0435\u0440\u044f + \u043f\u043e\u0442\u0435\u0440\u044f \u0446\u0438\u043a\u043b\u0430)\n            # \u041e\u0446\u0435\u043d\u0438\u0432\u0430\u0435\u0442 \u043e\u0431\u0449\u0438\u0435 \u043f\u043e\u0442\u0435\u0440\u0438 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430\n            total_gen_x2y_loss = gen_x2y_loss + total_cycle_loss + self.identity_loss(real_y, same_y)\n            total_gen_y2x_loss = gen_y2x_loss + total_cycle_loss + self.identity_loss(real_x, same_x)\n\n            # \u041e\u0446\u0435\u043d\u0438\u0432\u0430\u0435\u0442 \u043f\u043e\u0442\u0435\u0440\u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430\n            disc_x_loss = self.discriminator_loss(disc_real_x, disc_fake_x) # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445\n            disc_y_loss = self.discriminator_loss(disc_real_y, disc_fake_y) # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0431\u043e\u043b\u044c\u043d\u044b\u0445\n      \n        # Calculate the gradients for generator and discriminator (\u0420\u0430\u0441\u0441\u0447\u0435\u0442 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430)\n        # \u041f\u043e\u0441\u043b\u0435 \u0442\u043e\u0433\u043e, \u043a\u0430\u043a \u0437\u0430\u043f\u0438\u0441\u0430\u043d\u044b \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 GradientTape.gradient(target, sources) \u0447\u0442\u043e\u0431\u044b \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0446\u0435\u043b\u0438 (\u0447\u0430\u0441\u0442\u043e \u043f\u043e\u0442\u0435\u0440\u0438) \n        # \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0430 (\u0447\u0430\u0441\u0442\u043e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0438):\n        #  (trainable_variables - \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0432\u0441\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435, \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e trainable = True)\n        generator_x2y_gradients = tape.gradient(total_gen_x2y_loss, self.generator_x2y.trainable_variables) # \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0431\u043e\u043b\u044c\u043d\u044b\u0445 \u0438\u0437 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445\n        generator_y2x_gradients = tape.gradient(total_gen_y2x_loss, self.generator_y2x.trainable_variables) # \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445 \u0438\u0437 \u0431\u043e\u043b\u044c\u043d\u044b\u0445\n        \n        discriminator_x_gradients = tape.gradient(disc_x_loss, self.discriminator_x.trainable_variables) # \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u0434\u043b\u044f \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0445\n        discriminator_y_gradients = tape.gradient(disc_y_loss, self.discriminator_y.trainable_variables) # \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u0434\u043b\u044f \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0431\u043e\u043b\u044c\u043d\u044b\u0445\n      \n        # Apply the gradients to the optimizer (\u041f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0435\u043d\u0438\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 (\u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e tf.GradientTape) \u043a \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u0443 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e apply_gradients())\n        generator_x2y_optimizer.apply_gradients(zip(generator_x2y_gradients, self.generator_x2y.trainable_variables))\n        generator_y2x_optimizer.apply_gradients(zip(generator_y2x_gradients, self.generator_y2x.trainable_variables))\n        \n        discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, self.discriminator_x.trainable_variables))\n        discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n        #discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, self.discriminator_y.trainable_variables))\n    \n    \n        # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043e\u0431\u0449\u0438\u0435 \u043f\u043e\u0442\u0435\u0440\u0438 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u0432 \u0438 \u043e\u0431\u0449\u0438\u0435 \u043f\u043e\u0442\u0435\u0440\u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u043e\u0432\n        return {\n                \"gen_x2y_loss\": total_gen_x2y_loss,\n                \"gen_y2x_loss\": total_gen_y2x_loss,\n                \"disc_x_loss\": disc_x_loss,\n                \"disc_y_loss\": disc_y_loss\n                }","0e513274":"# 2 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0438\u0437 \u0440\u0430\u0437\u043d\u044b\u0445 \u0434\u043e\u043c\u0435\u043d\u043e\u0432 Source \u0438 Target. \u0417\u0430\u0434\u0430\u0447\u0435\u0439 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043c\u043e\u0436\u0435\u0442 \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0441\u0435\u043c\u043f\u043b\u044b \u0438\u0437 \u043e\u0434\u043d\u043e\u0433\u043e \u0434\u043e\u043c\u0435\u043d\u0430 \u0432 \u0434\u0440\u0443\u0433\u043e\u0439\nbatch_size = 1 # \u0420\u0430\u0437\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430 \u0432\u0435\u0437\u0434\u0435 \u044d\u0442\u043e\u0442\n# GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification') # \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u0443\u0442\u044c \u043a \u043d\u0430\u0431\u043e\u0440\u0430\u043c \u0434\u0430\u043d\u043d\u044b\u0445\n# filenames = tf.io.gfile.glob(GCS_PATH + '\/train_tfrecords\/ld_train*.tfrec') # \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432, \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u0437\u0430\u0434\u0430\u043d\u043d\u043e\u043c\u0443 \u0448\u0430\u0431\u043b\u043e\u043d\u0443 (\u0448\u0430\u0431\u043b\u043e\u043d\u0430\u043c)\n# CBSD_data = data_pipeline(filenames, label_num=1, batch_size=batch_size, is_train=True) # \u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a (source-\u043c\u043e\u0434\u0435\u043b\u044c)\n# Healthy_data = data_pipeline(filenames, label_num=4, batch_size=batch_size, is_train=True) # \u0426\u0435\u043b\u044c (target-\u043c\u043e\u0434\u0435\u043b\u044c)\n\nGCS_PATH = KaggleDatasets().get_gcs_path('tfrecords-corn-first-true') \nfilenames = tf.io.gfile.glob(GCS_PATH + '\/*.tfrec') \nBB_data = data_pipeline(filenames, label_num=0, batch_size=batch_size, is_train=True)\nH_data = data_pipeline(filenames, label_num=1, batch_size=batch_size, is_train=True)","1703bd57":"# num_samples = 4\n# fig, axes = plt.subplots(2, num_samples, figsize=(12,6))\n# for i, data in enumerate(CBSD_data.take(num_samples)):\n#     axes[0, i].imshow(data[0].numpy() * 0.5 + 0.5)\n#     axes[0, i].title.set_text(\"CBSD\")\n    \n# for i, data in enumerate(Healthy_data.take(num_samples)):\n#     axes[1, i].imshow(data[0].numpy() * 0.5 + 0.5)\n#     axes[1, i].title.set_text(\"Healthy\")    \n\n# fig.tight_layout()\n# plt.show()","6d8631a9":"print(BB_data.take(2))\n","355de620":"num_samples = 4\nfig, axes = plt.subplots(2, num_samples, figsize=(12,6))\nfor i, data in enumerate(BB_data.take(num_samples)):\n    axes[0, i].imshow(data[0].numpy() * 0.5 + 0.5)\n    axes[0, i].title.set_text(\"Corn infected by pests like Fall Armyworm\")\n    \nfor i, data in enumerate(H_data.take(num_samples)):\n    axes[1, i].imshow(data[0].numpy() * 0.5 + 0.5)\n    axes[1, i].title.set_text(\"Healthy corn\")    \n\nfig.tight_layout()\nplt.show()","4683510e":"data_num = 220\nlearning_rate = 1e-4\nbatch_size = 1\n\n# \u041c\u043e\u0434\u0435\u043b\u044c \u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440 \u0434\u043e\u043b\u0436\u043d\u044b \u0431\u044b\u0442\u044c \u0441\u043e\u0437\u0434\u0430\u043d\u044b \u0432 `strategy.scope`. \u0422.\u0435. \u0432\u0441\u0435, \u0447\u0442\u043e \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435, \u0434\u043e\u043b\u0436\u043d\u043e \u0432\u0445\u043e\u0434\u0438\u0442\u044c \u0432 \u0441\u0444\u0435\u0440\u0443 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0438.\n# \u0417\u0434\u0435\u0441\u044c \u0441\u043e\u0437\u0434\u0430\u044e\u0442\u0441\u044f \u043a\u043e\u043f\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0435\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c GPU, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u043e\u0431\u0443\u0447\u0430\u0442\u044c\u0441\u044f \u0432\u043e \u0432\u0440\u0435\u043c\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f. \n# \u0420\u0430\u0437\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430 \u0431\u0443\u0434\u0435\u0442 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0445 GPUs, \u0438 \u044d\u0442\u0438 \u0431\u0430\u0442\u0447\u0438 \u0431\u0443\u0434\u0443\u0442 \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u044b \u0442\u0435\u043c GPUs. \n# \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0435\u0441\u043b\u0438 batch_size = 64 \u0438 \u0435\u0441\u0442\u044c 2 GPUs, \u0442\u043e \u043a\u0430\u0436\u0434\u044b\u0439 GPU \u043f\u043e\u043b\u0443\u0447\u0438\u0442 \u0440\u0430\u0437\u043c\u0435\u0440 \u043f\u0430\u043a\u0435\u0442\u0430 = 32. \nwith strategy.scope(): \n    generator_x2y, generator_y2x, discriminator_x, discriminator_y = build_gan_models() # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0434\u0432\u0443\u0445 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u0432 \u0438 \u0434\u0432\u0443\u0445 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u043e\u0432\n    model_json = generator_x2y.to_json()\n    with open(\"model_in_json.json\", \"w\") as json_file:\n        json.dump(model_json, json_file)\n\n\n    # loss and learning rate (\u043f\u043e\u0442\u0435\u0440\u0438 \u0438 \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f)\n    # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u0432 \u0434\u043b\u044f 2 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u0432 \u0438 2 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u043e\u0432 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0431\u0430\u0437\u043e\u0432\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430 \u0434\u043b\u044f \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u0432, \u0430 \u0438\u043c\u0435\u043d\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440 \u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437 \u0435\u0433\u043e \u043f\u043e\u0434\u043a\u043b\u0430\u0441\u0441\u043e\u0432\n    # \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 Adam (\u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u0438\u0435 \u0441\u0442\u043e\u0445\u0430\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0430) \u0434\u043b\u044f \u0438\u0442\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u043e\u0433\u043e \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0432\u0435\u0441\u043e\u0432 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n    # learning_rate (\u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f) \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u0438\u0440\u0443\u0435\u0442, \u043d\u0430\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0438\u0437\u043c\u0435\u043d\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u0432 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u043e\u0446\u0435\u043d\u0435\u043d\u043d\u0443\u044e \u043e\u0448\u0438\u0431\u043a\u0443 \u043a\u0430\u0436\u0434\u044b\u0439 \u0440\u0430\u0437, \u043a\u043e\u0433\u0434\u0430 \u043e\u0431\u043d\u043e\u0432\u043b\u044f\u044e\u0442\u0441\u044f \u0432\u0435\u0441\u0430 \u043c\u043e\u0434\u0435\u043b\u0438.\n    # beta_1 - \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0441 \u043f\u043b\u0430\u0432\u0430\u044e\u0449\u0435\u0439 \u0437\u0430\u043f\u044f\u0442\u043e\u0439 \u0438\u043b\u0438 \u043f\u043e\u0441\u0442\u043e\u044f\u043d\u043d\u044b\u0439 \u0442\u0435\u043d\u0437\u043e\u0440 \u0441 \u043f\u043b\u0430\u0432\u0430\u044e\u0449\u0435\u0439 \u0437\u0430\u043f\u044f\u0442\u043e\u0439, \u0438\u043b\u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u043c\u044b\u0439 \u043e\u0431\u044a\u0435\u043a\u0442, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043d\u0435 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u0438 \n    # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f. \u041e\u0446\u0435\u043d\u043a\u0430 \u044d\u043a\u0441\u043f\u043e\u043d\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u0438 \u0437\u0430\u0442\u0443\u0445\u0430\u043d\u0438\u044f \u0434\u043b\u044f 1-\u0433\u043e \u043c\u043e\u043c\u0435\u043d\u0442\u0430. \u041f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e 0,9.\n    generator_x2y_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5) # learning_rate \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e 0.001, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f 1e-4\n    generator_y2x_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5)\n    discriminator_x_optimizer = tf.keras.optimizers.Adam(learning_rate\/10, beta_1=0.5)\n    discriminator_y_optimizer = tf.keras.optimizers.Adam(learning_rate\/10, beta_1=0.5)\n\n    # \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u0437 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0445 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u0432 \u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u043e\u0432\n    cycle_gan_model = CycleGan(generator_x2y, generator_y2x, discriminator_x, discriminator_y)\n\n    # \u0441\u043a\u043e\u043c\u043f\u0438\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438 \u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c\n    def compile_and_fit(epochs):\n        cycle_gan_model.compile(generator_x2y_optimizer, generator_y2x_optimizer,\n                                discriminator_x, discriminator_y,\n                                generator_loss,\n                                discriminator_loss,\n                                calc_cycle_loss,\n                                identity_loss\n                                )\n        cycle_gan_model.fit(tf.data.Dataset.zip((BB_data, H_data)),\n                            batch_size = batch_size, # = 1\n                            # \u041e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0448\u0430\u0433\u043e\u0432 (batches of samples) \u043f\u0440\u0435\u0436\u0434\u0435 \u0447\u0435\u043c \u043e\u0431\u044a\u044f\u0432\u0438\u0442\u044c \u043e\u0434\u043d\u0443 \u044d\u043f\u043e\u0445\u0443 \u0437\u0430\u043a\u043e\u043d\u0447\u0435\u043d\u043d\u043e\u0439 \u0438 \u043d\u0430\u0447\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0443\u044e \u044d\u043f\u043e\u0445\u0443.\n                            # \u041f\u0440\u0438 \u043f\u0435\u0440\u0435\u0434\u0430\u0447\u0435 \u0431\u0435\u0441\u043a\u043e\u043d\u0435\u0447\u043d\u043e \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u044e\u0449\u0435\u0433\u043e\u0441\u044f \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442 steps_per_epoch.\n                            # \u041f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u00abNone\u00bb = \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0443 \u0432\u044b\u0431\u043e\u0440\u043e\u043a \u0432 \u043d\u0430\u0431\u043e\u0440\u0435 \u0434\u0430\u043d\u043d\u044b\u0445, \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u043c\u0443 \u043d\u0430 \u0440\u0430\u0437\u043c\u0435\u0440 \u043f\u0430\u043a\u0435\u0442\u0430, \u0438\u043b\u0438 1, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c.\n                            steps_per_epoch = data_num\/\/batch_size, # = 2000\/\/1 (\u0448\u0430\u0433\u0438 \u0432 \u044d\u043f\u043e\u0445\u0443)\n                            epochs=epochs # \u043f\u0435\u0440\u0435\u0434\u0430\u0435\u0442\u0441\u044f \u0432 \u0441\u0430\u043c\u043e\u043c \u0432\u044b\u0437\u043e\u0432\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\n                           )    \n\n\n    # I don't want to break the pretrained weight of disciminator at initial epochs. (\u043d\u0435 \u0440\u0430\u0437\u0440\u0443\u0448\u0430\u0442\u044c \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043d\u0430\u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0432\u0435\u0441 \u0434\u0438\u0441\u043a\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0432 \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u044d\u043f\u043e\u0445\u0438.)\n    # \u0415\u0441\u043b\u0438 \u0432\u044b \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u0435 trainable = False \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u043b\u0438 \u043b\u044e\u0431\u043e\u0433\u043e \u0441\u043b\u043e\u044f, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0438\u043c\u0435\u0435\u0442 \u043f\u043e\u0434\u0441\u043b\u043e\u0438, \u0432\u0441\u0435 \u0434\u043e\u0447\u0435\u0440\u043d\u0438\u0435 \u0441\u043b\u043e\u0438 \u0442\u0430\u043a\u0436\u0435 \u0441\u0442\u0430\u043d\u0443\u0442 \u043d\u0435\u043e\u0431\u0443\u0447\u0430\u0435\u043c\u044b\u043c\u0438.\n    # \u041a\u043e\u0433\u0434\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c\u044b\u0439 \u0432\u0435\u0441 \u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u0441\u044f \u043d\u0435\u043f\u0440\u0438\u0433\u043e\u0434\u043d\u044b\u043c \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438, \u0435\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 \u043d\u0435 \u043e\u0431\u043d\u043e\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432\u043e \u0432\u0440\u0435\u043c\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 (\u0442.\u0435. \u0437\u0430\u043c\u043e\u0440\u0430\u0436\u0438\u0432\u0430\u044e\u0442\u0441\u044f)\n    discriminator_x.trainable = False\n    discriminator_y.trainable = False\n    compile_and_fit(epochs=3)\n\n    # \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u044b \u0440\u0430\u0437\u043c\u043e\u0440\u043e\u0436\u0435\u043d\u044b\n    discriminator_x.trainable = True\n    discriminator_y.trainable = True\n    compile_and_fit(epochs=10)\n\n    cycle_gan_model.save_weights(\"gan_10ep_CBSD_healthy.h5\")\n    generator_x2y.save('generator_bb.h5') # \u0432 \u0437\u0434\u043e\u0440\u043e\u0432\u044b\u0435!\n    generator_y2x.save('generator_h.h5') # \u0432 \u0431\u043e\u043b\u044c\u043d\u044b\u0435!","f3e2cb98":"def generate_images(model, test_input):\n    prediction = model(test_input)\n    plt.figure(figsize=(10, 10))\n    display_list = [test_input[0], prediction[0]]\n    title = ['Original Image', 'Generated Image']\n    for i in range(2):\n        plt.subplot(1, 2, i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i] * 0.5 + 0.5)\n        plt.axis('off')\n    plt.show()\n\n","a7cefebc":"for inputs in BB_data.take(30):\n    generate_images(generator_x2y, inputs)","77ec6bbf":"for inputs in H_data.take(30):\n    generate_images(generator_y2x, inputs) ","2a0b5664":"CBB_data = data_pipeline(filenames, label_num=0, batch_size=batch_size, is_train=True)\nwith strategy.scope(): \n    generator_x2y, generator_y2x, discriminator_x, discriminator_y = build_gan_models()\n\n    generator_x2y_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5)\n    generator_y2x_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5)\n    discriminator_x_optimizer = tf.keras.optimizers.Adam(learning_rate\/10, beta_1=0.5)\n    discriminator_y_optimizer = tf.keras.optimizers.Adam(learning_rate\/10, beta_1=0.5)\n    \n    cycle_gan_model = CycleGan(generator_x2y, generator_y2x, discriminator_x, discriminator_y)\n\n    def compile_and_fit(epochs):\n        cycle_gan_model.compile(generator_x2y_optimizer, generator_y2x_optimizer,\n                                discriminator_x, discriminator_y,\n                                generator_loss,\n                                discriminator_loss,\n                                calc_cycle_loss,\n                                identity_loss\n                                )\n        cycle_gan_model.fit(tf.data.Dataset.zip((CBB_data, Healthy_data)),\n                            batch_size = batch_size,\n                            steps_per_epoch = data_num\/\/batch_size, \n                            epochs=epochs\n                           )    \n\n\n    # I don't want to break the pretrained weight of disciminator at initial epochs.\n    discriminator_x.trainable = False\n    discriminator_y.trainable = False\n    compile_and_fit(epochs=3)\n\n    discriminator_x.trainable = True\n    discriminator_y.trainable = True\n    compile_and_fit(epochs=10)\n\n    cycle_gan_model.save_weights(\"gan_10ep_CBB_healthy.h5\")\n","565f8eca":"for inputs in CBB_data.take(12):\n    generate_images(generator_x2y, inputs)","fc0ec9b2":"for inputs in Healthy_data.take(12):\n    generate_images(generator_y2x, inputs)","dfbb99cc":"### CBSD to HEALTHY","3db7cff3":"#### CBB to HEALTHY","0bd93496":"## Train Models\nLet's start training! \n\nAs I don't want to break the pretrained weights of disciminators(VGG16) at initial epochs, weights are frozen at first 3 epochs. Then train all layers.","5222c298":"## Next Step\nGenerated images shown above are not so good at this point. So the next step is tuning models and hyper parameters to generate better images. Then train classifier with newly generated images (fake images) and compare its performance with the original classifier.\n\nThank you for reading!","2f9d3961":"## Introduction\nI guess **generating additional data by GANs or other generators can be an approach to improve the performance** of CNN classifier. So I've applied one of the best-known GAN \"CycleGAN\" on the Cassava Leaf dataset.","e5e1990c":"## Other Transforms","1d194e27":"## Check Generated Image","e41c2b6b":"## Define Cycle GAN Model\nModels are based on Amy Jang's great notebook. Thank you for sharing!\n\nhttps:\/\/www.kaggle.com\/amyjang\/monet-cyclegan-tutorial#Visualize-our-Monet-esque-photos\n\nThe only difference is the discriminator. I use pretrained model of VGG16 instead of the model given in the original notebook because this classification task is much more difficult than the original task(Monet or photo). \n","5652ef12":"## Import Libraries","0a4f68f9":"Some images look healthy comparing with the original images.","1def3e9d":"## Data Pipeline\nData pipeline is defined in this section. \n\nNoted that the labels are not used as target value in Cycle GAN. Labels are just used for filtering the inputs.","75c82fc8":"#### HEALTHY to CBB","bb6a4749":"### 1. CBB <-> HEALTHY","9f7fe5e1":"### What is Cycle GAN?\nCycle GAN is the image style transfer. It translates an image from a source domain to a target domain. Zebra to Horse \/ Horse to Zebra is well-known examples.\n\nFollowing images are from original paper.\n![image.png](attachment:image.png)\n\nFor further information, please check original paper and Monet competition.\n* original paper: https:\/\/arxiv.org\/pdf\/1703.10593.pdf\n* Monet Competition: https:\/\/www.kaggle.com\/c\/gan-getting-started\/overview\n\n### Why Cycle GAN?\nIn this competition, we need to classify the images of the same plant. The only difference is the health condition.\nThat inspired me to use Cycle GAN as a health transfer. It might changes the color of leaves, might makes some holes on the leaves.","943fa22f":"## Build Data Pipeline\nCycle GAN requires two inputs:\n- **Images of Source Domain**\n- **Images of Target Domain**\n\nFirst, I choose \"CBSD\" as source and \"Healthy\" as target.  ","6782915b":"### HEALTHY to CBSD","39f4e1bd":"Training multiple CycleGANs takes a lot of time. So I'm plannning to implement StarGANv2 to create images across multiple domain (multiple classes).","8243b8c2":"Colors and patterns of leaves look slightly changing. They are somewhat unhealthy."}}