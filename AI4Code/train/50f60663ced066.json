{"cell_type":{"bb1ff2fa":"code","67ddcbab":"code","e7ab041f":"code","ccd6457f":"code","946de4e6":"code","fb05a3de":"code","7fc779ef":"code","8c22c44b":"code","f2ddfa24":"code","acaf6ac5":"code","94b066ad":"code","d5bb56c4":"code","d6fc8aba":"code","0ff73acd":"code","38bc8425":"code","b81faea8":"code","7d63b824":"code","59bf2664":"code","8655cf0c":"code","d690fb59":"markdown"},"source":{"bb1ff2fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","67ddcbab":"FILEPATH_TRAIN = '\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip'","e7ab041f":"df = pd.read_csv(FILEPATH_TRAIN, encoding = \"ISO-8859-1\")","ccd6457f":"df.sample(2)","946de4e6":"df_toxic = df.drop(['id', 'comment_text'], axis=1)\ncounts = []\ncategories = list(df_toxic.columns.values)\n\nfor i in categories:\n    counts.append((i, df_toxic[i].sum()))\ndf_stats = pd.DataFrame(counts, columns=['category', 'number_of_comments'])\n\ndf_stats","fb05a3de":"%matplotlib inline\nimport re\nimport matplotlib\nimport matplotlib.pyplot as plt","7fc779ef":"df_stats.plot(x='category', y='number_of_comments', kind='bar', legend=False, grid=True, figsize=(8, 5))\nplt.title(\"Number of comments per category\")\nplt.ylabel('# of Occurrences', fontsize=12)\nplt.xlabel('category', fontsize=12)","8c22c44b":"import seaborn as sns","f2ddfa24":"rowsums = df.iloc[:,2:].sum(axis=1)\nx=rowsums.value_counts()\n#plot\nplt.figure(figsize=(8,5))\nax = sns.barplot(x.index, x.values)\nplt.title(\"Multiple categories per comment\")\nplt.ylabel('# of Occurrences', fontsize=12)\nplt.xlabel('# of categories', fontsize=12)","acaf6ac5":"print('Percentage of comments that are not labelled:')\nprint(len(df[(df['toxic']==0) & (df['severe_toxic']==0) & (df['obscene']==0) & (df['threat']== 0) & (df['insult']==0) & (df['identity_hate']==0)]) \/ len(df))","94b066ad":"lens = df.comment_text.str.len()\nlens.hist(bins = np.arange(0,5000,50))","d5bb56c4":"print('Number of missing comments in comment text:')\ndf['comment_text'].isnull().sum()","d6fc8aba":"df['comment_text'][0]","0ff73acd":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"can not \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    text = re.sub('\\W', ' ', text)\n    text = re.sub('\\s+', ' ', text)\n    text = text.strip(' ')\n    return text","38bc8425":"df['comment_text'] = df['comment_text'].map(lambda com : clean_text(com))\ndf['comment_text'][0]","b81faea8":"from sklearn.model_selection import train_test_split","7d63b824":"categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain, test = train_test_split(df, random_state=42, test_size=0.33, shuffle=True)\n\nX_train = train.comment_text\nX_test = test.comment_text\n\nprint(X_train.shape)\nprint(X_test.shape)","59bf2664":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score","8655cf0c":"# Define a pipeline combining a text feature extractor with multi lable classifier\nNB_pipeline = Pipeline([\n                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n                ('clf', OneVsRestClassifier(MultinomialNB(\n                    fit_prior=True, class_prior=None))),\n            ])\n\nfor category in categories:\n    print('... Processing {}'.format(category))\n    # train the model using X_dtm & y\n    NB_pipeline.fit(X_train, train[category])\n    # compute the testing accuracy\n    prediction = NB_pipeline.predict(X_test)\n    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))","d690fb59":"Source:\n\nhttps:\/\/towardsdatascience.com\/multi-label-text-classification-with-scikit-learn-30714b7819c5"}}