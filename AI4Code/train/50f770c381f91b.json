{"cell_type":{"c169cd0a":"code","e8e4a08a":"code","61b71946":"code","2119a1b7":"code","0eeb39de":"code","97d53b7f":"code","fc523440":"code","91624110":"code","6aaab504":"code","7be0d55b":"code","8ed646f9":"code","d9917fcb":"code","bac64cac":"code","241325cb":"code","582ad12f":"code","10fe9c3c":"code","560ea5e9":"code","0962d12a":"code","c7a0fc1f":"code","63cdba95":"code","cf446817":"code","501c2a65":"code","6aca55e3":"code","4c375b4b":"code","9ae5e6d9":"code","559b980d":"code","2ee8abf7":"code","7b0b4321":"code","32b1bd39":"code","0bb56329":"code","9692305f":"code","fde4262b":"code","4f9cb548":"code","c7f8dedc":"code","b06c6c95":"code","d35ae182":"markdown","a0817d9a":"markdown","6f1ab7e6":"markdown","81d25f5a":"markdown","add2a669":"markdown","9c12353c":"markdown","9f2af9cf":"markdown","c35c584b":"markdown","8f1767da":"markdown","022fb439":"markdown","afd789fb":"markdown","fce599e6":"markdown","1c42822b":"markdown","de5f000a":"markdown","a9e9c234":"markdown","0c5f7c11":"markdown","bcfc9fab":"markdown","6fde6336":"markdown","4a1f8dab":"markdown"},"source":{"c169cd0a":"#Loading the data\nimport pandas as pd","e8e4a08a":"train = pd.read_csv(\"..\/input\/train-dataset\/train.csv\", low_memory = False) #imports data train.csv\ntrain.head()\ntrain = train.drop([\"Unnamed: 0\"],1)","61b71946":"test = pd.read_csv(\"..\/input\/test-dataset\/test.csv\", low_memory = False) #Loading the test data\ntest = test.drop(['Unnamed: 0.1'],1)\ntest = test.drop([\"Unnamed: 0\"],1)\ntest.head()","2119a1b7":"percent= train.default.sum() \/ train.default.count() #Sum method counts the values and since False has a default value of 0, \nprint(\"Percentage of training set loans in default {:.0%}\".format(percent))","0eeb39de":"train.groupby(\"ZIP\").default.value_counts() #using the groupby for counting the value counts","97d53b7f":"train_year0 = train.loc[train[\"year\"] == 0]\npercent = train_year0.default.sum() \/ train_year0.default.count()\nprint(\"Percentage of default rate in training set for year {:.0%}\".format(percent))","fc523440":"train_corr_matrix = train.corr() #stores all the values of the training correlation matrix\n","91624110":"#train_corr_matrix[\"age\"].sort_values(ascending= False)\ntrain_corr_matrix","6aaab504":"print(\"correlation between age and income in the training dataset is {:.0}\".format(train.age.corr(train.income)))\ntrain.columns","7be0d55b":"y_train = train['default'] #creates dataset that includes only defaulted loans from train \nx_train = pd.concat([train.drop( [\"default\", 'occupation', 'ZIP', 'sex', 'minority'], axis=1), \n                     pd.get_dummies (train['occupation']),pd.get_dummies (train['ZIP'])], axis=1)\nx_train.columns","8ed646f9":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100,random_state=42,oob_score=True)\nrfc.fit(x_train,y_train)\ny_predict = rfc.predict(x_train)\ntrain.head()","d9917fcb":"from sklearn import metrics\nscore = metrics.accuracy_score(y_train,y_predict)\nprint(\"Insample Score is {:.0%}\".format(score))","bac64cac":"from sklearn.model_selection import cross_val_score\ncv_score = cross_val_score(rfc,x_train,y_train, cv = 3, scoring = \"accuracy\")\ncv_score","241325cb":"from sklearn.model_selection import cross_val_predict\ny_predict = cross_val_predict(rfc,x_train, y_train, cv = 3)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train,y_predict)","582ad12f":"from sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score","10fe9c3c":"precision_score(y_train, y_predict)","560ea5e9":"recall_score(y_train,y_predict)","0962d12a":"f1_score(y_train,y_predict)","c7a0fc1f":"train_target = train.drop([\"default\"],1)","63cdba95":"%matplotlib inline  \nimport matplotlib.pyplot as plt\ntrain_target.hist(bins=10,figsize=(20,20))\nplt.show()","cf446817":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\nplt.figure(figsize=(15,8))\nsns.heatmap(train.corr(),annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm',fmt=\".2%\")","501c2a65":"print(\"Out of Bag Score:\")\noob = rfc.oob_score_\nprint(oob)","6aca55e3":"y_test = test[\"default\"] #creates dataset that includes only defaulted loans\nx_test = pd.concat([test.drop( [\"default\", \"occupation\", \"ZIP\", \"sex\", \"minority\"], axis=1),\n                     pd.get_dummies (test[\"occupation\"]),pd.get_dummies (test[\"ZIP\"])], axis=1)","4c375b4b":"y_predict_test = rfc.predict(x_test)\ntest[\"default_predict\"] = y_predict_test\nfrom sklearn import metrics\nscore_test = metrics.accuracy_score(y_test,y_predict_test)\nprint(\"Outofsample Score is {:.0%}\".format(score_test))","9ae5e6d9":"majority_default = (test[test.minority == 0].default_predict.sum()\/len(test))*100\nprint(\"Predicted average default probability for non-minority members {:.2f}\".format(majority_default))","559b980d":"test.groupby(\"minority\").default_predict.value_counts()","2ee8abf7":"majority_default = (test[test.minority == 1].default_predict.sum()\/len(test))*100\nprint(\"Predicted average default probability for non-minority members {:.2f}\".format(majority_default))","7b0b4321":"test[\"loan_approved\"] = ~(test.default_predict)\ntest.head()","32b1bd39":"share_approved_male = test[test.sex == 0].loan_approved.sum()\/(len(test[test.sex == 0]))\nprint(\"Share of approved male applicant\", (share_approved_male)*100)","0bb56329":"share_approved_female = test[test.sex == 1].loan_approved.sum()\/(len(test[test.sex == 1]))\nprint(\"Share of approved female applicant is\" ,(share_approved_female)*100)","9692305f":"test.groupby(\"sex\").loan_approved.value_counts()","fde4262b":"test.groupby(\"minority\").loan_approved.value_counts()","4f9cb548":"share_approved_minority = test[test.minority == 1].loan_approved.sum()\/(len(test[test.minority == 1]))\nshare_approved_majority = test[test.minority == 0].loan_approved.sum()\/(len(test[test.minority == 0]))\nprint(\"Share of approved majority applicant is {maj} and share of approved minority applicant is {min}\".format(maj= share_approved_majority*100, min = share_approved_minority*100) )","c7f8dedc":"test[\"pay_cap\"] = ~(test.default)\nfrom sklearn.metrics import confusion_matrix #determmining the true positive rate for quantifying equal opportunity\ncm_min= confusion_matrix(test[test.minority==1].pay_cap,test[test.minority==1].loan_approved)\ncm_maj= confusion_matrix(test[test.minority==0].pay_cap,test[test.minority==0].loan_approved)\ncm_male = confusion_matrix(test[test.sex==0].pay_cap,test[test.sex==0].loan_approved)\ncm_female = confusion_matrix(test[test.sex==1].pay_cap,test[test.sex==1].loan_approved)","b06c6c95":"eq_op_min = cm_min[1][1]*100\/(cm_min[1][1]+cm_min[1][0])\neq_op_maj = cm_maj[1][1]*100\/(cm_maj[1][1]+cm_min[1][0])\neq_op_male = cm_male[1][1]*100\/(cm_male[1][1]+cm_male[1][0])\neq_op_female =cm_female[1][1]*100\/(cm_female[1][1]+cm_female[1][0])\nprint(\"Share of successful non-minority applicants that would repay {:.2f}\".format(eq_op_maj))\nprint(\"Share of successsful minority applicants that would repay {:.2f}\".format(eq_op_min))\nprint(\"Share of successsful male applicants that would repay {:.2f}\".format(eq_op_male))\nprint(\"Share of successsful female applicants that would repay {:.2f}\".format(eq_op_female))","d35ae182":"### Exploratory Data Analysis","a0817d9a":"### Q10 Is the loan granting scheme (the cutoff, not the model) group unaware? (hint: this question does not require a calculation)","6f1ab7e6":"### Q1 What percentage of your training set loans are in default?","81d25f5a":"## Loading the data","add2a669":"### Q5 What is the in-sample accuracy? That is, find the accuracy score of the fitted model for predicting the outcomes using the whole training dataset","9c12353c":"###  Q4 What is the correlation between age and income in the training dataset?","9f2af9cf":"# Homework Assignment 2","c35c584b":"The Cutoff model for the default is based on probability which is same for the group\n","8f1767da":"### Q2 Which ZIP code has the highest default rate in the training dataset?","022fb439":"### Q8 What is the predicted average default probability for all non-minority members in the test set? ","afd789fb":"### Q6. What is the out of bag score for the model? The out of bag score is a fit and validation method that is calculated while the model is being trained.","fce599e6":"#### We can use a different function as well","1c42822b":"### Q11 Is the loan granting scheme equal opportunity? Compare the share of successful non-minority applicants that would repay to the share of successful minority applicants that would repay. Do the same comparison of the share of successful female applicants that would repay versus successful male applicants that would repay. What do these shares indicate about the likelihood of securing a loan in different population groups that would repay a loan?","de5f000a":"The model doesn't achieve Demographic partiy for males and neither it for minority applicants","a9e9c234":"### Q11 Has the loan granting scheme achieved demographic parity? Compare the share of approved female applicants to the share of approved male applicants. Do the same for minority and non-minority applicants. What does this indicate about the demographic parity achieved by the model?","0c5f7c11":"### Q7 What is the out of sample accuracy? That is, find the accuracy score of the model using the test data without re-estimating the model parameters. ","bcfc9fab":"### Q9 What is the predicted average default probability for all non-minority members in the test set? ","6fde6336":"## Cross Validation","4a1f8dab":"### Q3 What is the default rate in the training set for the first year for which you have data?"}}