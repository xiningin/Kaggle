{"cell_type":{"e4a154c6":"code","f08e8bff":"code","1af31b0a":"code","23a152a8":"code","13e584d2":"code","be4fadec":"code","f7fb2314":"code","fe5023b0":"code","9f7ae80c":"code","206fba03":"code","2987c228":"code","87f58473":"code","4104e995":"code","7101d088":"code","149d43a4":"code","bf9ed585":"code","86f1bb93":"code","dbbacb8b":"code","9e5499c3":"code","138819b0":"code","9bdbf089":"code","06a4a315":"code","686e750c":"markdown","8578a6dd":"markdown","a0b305d3":"markdown","e5dd9c8a":"markdown","4ac2bc1f":"markdown","ecd3b35c":"markdown"},"source":{"e4a154c6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport time\n\nimport os\nprint(os.listdir(\"..\/input\"))","f08e8bff":"train_labels = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv')\ntest_labels = pd.read_csv('..\/input\/histopathologic-cancer-detection\/sample_submission.csv')\n\n#print('train : ','\\n', train_sample.head(5))\n#print('test : ','\\n', test_labels.head(5))","1af31b0a":"test_labels.shape","23a152a8":"#This image is labelled as having a cancer cell.\nimage = plt.imread('..\/input\/histopathologic-cancer-detection\/train\/c18f2d887b7ae4f6742ee445113fa1aef383ed77.tif')\nplt.imshow(image)\nplt.show()","13e584d2":"image.shape","be4fadec":"#let's start with a small sample first:\n\n#size train sample:\nx = 30000\n\n#size of val sample:\nl = 5000\n\ntrain_sample = train_labels[:x]\nval_sample = train_labels[x:x+l]\ntest_sample = test_labels","f7fb2314":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils, to_categorical\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport tensorflow as tf\nfrom sklearn.metrics import roc_auc_score\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline","fe5023b0":"img_heigth, img_width = 96, 96","9f7ae80c":"img=load_img('..\/input\/histopathologic-cancer-detection\/train\/c18f2d887b7ae4f6742ee445113fa1aef383ed77.tif')","206fba03":"train_sample.iloc[0][1]","2987c228":"nb_train_examples=train_sample.shape[0]\nnb_val_examples=val_sample.shape[0]\n\ntrain_img_array = np.ndarray(shape=[nb_train_examples, 96, 96, 3])\ntrain_img_label = np.ndarray(shape=[nb_train_examples, 1])\n\nval_img_array = np.ndarray(shape=[nb_val_examples, 96, 96, 3])\nval_img_label = np.ndarray(shape=[nb_val_examples, 1])\n\ntest_img_array = np.ndarray(shape=[test_sample.shape[0], 96, 96, 3])\ntest_img_label = np.ndarray(shape=[test_sample.shape[0], 1])","87f58473":"t1=time.time()\nfor p in range(nb_train_examples):\n    #We turn the .tif into an array\n    img_name=train_sample.iloc[p][0]\n    img=load_img('..\/input\/histopathologic-cancer-detection\/train\/'+img_name+'.tif')\n    img=img_to_array(img)\n    img=img\/255\n    #print(img_name)\n    #print(img.shape)\n    train_img_array[p]=img #putting the image inside the 4 dim array\n    \n    #We put the label into a new ndarray:\n    train_img_label[p]=train_sample.iloc[p][1]\nt2=time.time()\nprint('time to turn .tif into array for train_set : ',t2-t1)\nprint('train_img_array shape is : ', train_img_array.shape)\nprint('train_img_label shape is : ', train_img_label.shape)","4104e995":"t1=time.time()\nfor p in range(nb_val_examples):\n    #We turn the .tif into an array\n    img_name=val_sample.iloc[p][0]\n    img=load_img('..\/input\/histopathologic-cancer-detection\/train\/'+img_name+'.tif')\n    img=img_to_array(img)\n    img=img\/255\n    #print(img_name)\n    #print(img.shape)\n    val_img_array[p]=img #putting the image inside the 4 dim array\n    \n    #We put the label into a new ndarray:\n    val_img_label[p]=val_sample.iloc[p][1]\nt2=time.time()\nprint('time to turn .tif into array for val_sample : ',t2-t1)\nprint('val_img_array shape is : ', val_img_array.shape)\nprint('val_img_label shape is : ', val_img_label.shape)","7101d088":"def auroc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n\ndef FirstModel(num_classes):\n    \n    model = Sequential()\n    model.add(ResNet50(include_top = False, pooling='avg'))\n    model.add(Dense(num_classes, activation = 'sigmoid'))\n    \n    model.layers[0].trainable = False\n    \n    return model","149d43a4":"#my_model=FirstModel(train_img_array[0].shape)\nmy_model = FirstModel(num_classes = 2)","bf9ed585":"my_model.compile(optimizer = Adam(lr=0.0001), loss = 'binary_crossentropy', metrics = ['accuracy', auroc])","86f1bb93":"train_img_label = to_categorical(train_img_label, num_classes=2)\nval_img_label = to_categorical(val_img_label, num_classes=2)","dbbacb8b":"stats = my_model.fit(x = train_img_array, y = train_img_label, epochs = 5)","9e5499c3":"evaluation = my_model.evaluate(x= val_img_array, y=val_img_label)\nprint()\nprint (\"Loss = \" + str(evaluation[0]))\nprint (\"Test Accuracy = \" + str(evaluation[1]))","138819b0":"#This turned out to be a bad idea. But I'm keeping it, never know when I might need it\n\ndummy_img = np.ndarray(shape=(1, 96, 96, 3))\n\nt1=time.time()\nfor p in range(test_sample.shape[0]):\n    #We turn the .tif into an array\n    img_name=test_sample.iloc[p][0]\n    img=load_img('..\/input\/histopathologic-cancer-detection\/test\/'+img_name+'.tif')\n    img=img_to_array(img)\n    img=img\/255\n    \n    #print(img_name)\n    #print(img.shape)\n    \n    pred = my_model.predict(img.reshape(1,96,96,3))\n    #We put the label into a new ndarray:\n    test_sample.at[p ,'label'] = pred.argmax()\n    \n    \nt2=time.time()\nprint('time to turn .tif into array for test_sample : ',t2-t1)\n","9bdbf089":"print('number of images labelled with cancer : ',test_sample[test_sample['label']==1].shape[0],\n      ' out of ', test_sample.shape[0], ' examples')","06a4a315":"test_sample.to_csv('test_predictions.csv', index=False)","686e750c":"It takes about 2.42 seconds to do img_to_array on 1,000 examples. This means it's going to take about 8.4 min for all 220k training examples, + 2,3 min for the test set. That's about 11 min in total just to convert the images to numpy using this method. (goes much much faster whe using GPU)\n\nIt's long, but at least it works, so for now, that's good enough.","8578a6dd":"Very early remarks:\n\n1. We have 220,025 images in train_labels, of which 89,117 are labelled as having a cancer pixel in the 32x32 center zone.\n2. There are 57,5k images in sample_sumbissions\n3. Images are of size 96x96x3 (Meaning RBG, and of total size 27,648)\n4. The only information we have is, if there is a cancer cell of not (in the 32x32 center zone, according to the data description). We do not know what it looks like, which pixel is identified as the one being the cancer, and what makes or doesn't make a cancer cell. This will make EDA relatively fast in my opinion, because there isn't much information we are going to be abel to look at; apart from looking at 1 labelled pictures, and visually trying to find what looks like the patterns compared to 0 labelled data.\n","a0b305d3":"**TO DO**\nProblem at the moment: memory overload.\n- Train model with about 2000 train ex, 500 test ex, and then do the prediction inside the loop, so no array storing of the image on submission set. In submission loop: img_to_array, then predict, then put prediction into sample_submission['label']. I think this is the file that has to be submitted again, have to check that.\n\n- I have taken the predicitons and made that any prediction >= 0.5 should be considered as 1, and any prediciton < 0.5 should be labelled as 0. I don't know if that 0.5 limit is good, or if it should be higher\/lower?\n\n- The competition says that the goal of the NN is to determine if there are cancer pixels in the 32x32 main area of the image. One idea would be to crop the images down to the 32x32 main part, and run the model & estimate, to see if it runs better like that.\n\n- I am using an Adam optimizer, with binary crossentropy loss. This might be interesting to look into aswell","e5dd9c8a":"Now we are going to try (emphasis on the word 'try') to make a model based on the exciting keras models","4ac2bc1f":"This kernel is my first try at making a NN using keras to apply it to the cancer cell competion. Any comments are more than welcome on any topic, as I am a very early beginner in data science :-)","ecd3b35c":"**Things that I learned**\nThis is my first deep learning code, so obviously, it can only be a learning experience. Since I've read a few Kernels already, I figured if any other beginner like me stumbles upon my Kernel, maybe this might be helpful. If not, well at least I get to write feedback for myself ;-)\n\n- I started by trying to make a [57k, 96, 96, 3] np.ndarray containing all the arrays of all the images we need to classify. While that did seem to work with smaller set (I tried with 25k, and it worked), at 57k, the Kernel just crashes. After some investigation (*puts Sherlock's hat on*) the issue seems to be memory overload. I mean I'm just turning 57,000+ images into 96x96x3 arrays, what could go wrong? Next step is to try inserting the prediction inside the for loop. Here's the idea: I'm still training my model (Well, not really mine, rather the one used in the week 2 of Course 4 of Andrew Ng's Coursera Deep Learning course) with a small amount of data, just to see if it's working. I'm taking baby steps, I'll gradually add more data as things work (eventually, I hope). I saw a tweet from Andrej Karapathy a fw weeks ago saying that you should try making a small model, with little data, until it overfits, and then move on. This allows you to check that the model is working, and helps find potential (as a beginner, I'd change the word 'potential' by 'numerous', but maybe it's just me) sources of error. Once I have my first model, then the prediciton is done image by image: I take an image, convert it to an array, and then predict it. Repeat ~57,000 times. This means no storing of the arrays, and (hopefully) no memory crash.\n\n- I did the above, successfully. Meaning that I can get an output and send it for classification (I got 0.6520 with about 2,000 training examples, 4 epochs; and this grew to 0.6793 with 25,000 training examples and 20 epochs). So next step, is to change the model, or neural network. It seems like I am getting only slight improvements with adding more training examples, which is good, but I am sure I can make bigger steps, without using more than a few thousand training examples. Then, once I found a much better model, I will add more examples, and training epochs. Next step: trying the Keras build-in ResNet50."}}