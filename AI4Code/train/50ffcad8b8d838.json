{"cell_type":{"c8e43a0c":"code","d85c3392":"code","ee7e6442":"code","2ee2733b":"code","ed0506c7":"code","b8f377ff":"code","d28414d6":"code","2cc5e76a":"code","e912cb7d":"code","3d0eff8d":"code","db3a72eb":"code","5ebb396f":"code","7639d508":"code","f605b14e":"code","be780d1e":"code","81f1b066":"code","3fe11bf5":"code","b5c9ece7":"code","bf59bd5a":"code","c5954f23":"code","6f6f1128":"code","1de3001b":"code","aacf664f":"code","06555430":"code","1aeb0af5":"code","d421113a":"code","05cdf423":"code","e5d4f7d8":"code","218bc2f7":"code","96610c96":"code","7591ee37":"code","430e02d8":"code","36a36eb1":"code","c3c87a87":"code","00fcb55b":"code","d88cb465":"code","8d97e3ba":"code","53bc7e8d":"code","b89f807e":"code","9197cdce":"code","adc068a6":"code","38a81316":"code","9f7a4de1":"code","12bad8e3":"code","8cfdfa6d":"code","b65c6925":"code","22f4428a":"code","8a5aadca":"code","def453ce":"markdown","d507a8e5":"markdown","cfde3320":"markdown","647a7c2a":"markdown","0e325a9f":"markdown","6e1776d7":"markdown","c3523a61":"markdown","5550b6d2":"markdown","2b4daae5":"markdown","917f1da9":"markdown","2ccc05a3":"markdown"},"source":{"c8e43a0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d85c3392":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)","ee7e6442":"train_path = '..\/input\/richters-predictor-modeling-earthquake-damage\/train_values.csv'\ntrain_sub_path = '..\/input\/richters-predictor-modeling-earthquake-damage\/train_labels.csv'\ntest_path = '..\/input\/richters-predictor-modeling-earthquake-damage\/test_values.csv'","2ee2733b":"data = pd.read_csv(train_path)\ndata.head()","ed0506c7":"label_data = pd.read_csv(train_sub_path)\nlabel_data.head()","b8f377ff":"dataset = pd.concat([data, label_data['damage_grade']], axis=1)\ndataset.head(3)","d28414d6":"dataset.info()","2cc5e76a":"dataset.isnull().sum().sum()","e912cb7d":"plt.figure(figsize=(10,8))\ncorr = dataset.corr()\nsns.heatmap(corr, cmap='cool')","3d0eff8d":"cat_feat = [i for i in dataset.columns if dataset[i].dtypes == 'O']\ncat_feat","db3a72eb":"dataset.shape","5ebb396f":"for i in cat_feat:\n    plt.figure(figsize=(5,3))\n    sns.countplot(dataset[i], palette='cool')","7639d508":"land = dataset['land_surface_condition'].unique()\nfoundation = dataset['foundation_type'].unique()\nground = dataset['ground_floor_type'].unique()\nplan = dataset['plan_configuration'].unique()\nlegal = dataset['legal_ownership_status'].unique()","f605b14e":"dataset['land_surface_condition']=dataset['land_surface_condition'].map({land[0]:land[0], land[1]:'Other', land[2]:'Other'})\ndataset['foundation_type']=dataset['foundation_type'].map({foundation[0]:foundation[0], foundation[1]:'Other', foundation[2]:'Other', foundation[3]:'Other', foundation[4]:'Other'})\ndataset['ground_floor_type']=dataset['ground_floor_type'].map({ground[0]:ground[0], ground[1]:'Other', ground[2]:'Other', ground[3]:'Other', ground[4]:'Other'})\ndataset['plan_configuration']=dataset['plan_configuration'].map({plan[0]:plan[0], plan[1]:'Other', plan[2]:'Other', plan[3]:'Other', plan[4]:'Other', plan[5]:'Other', plan[6]:'Other', plan[7]:'Other', plan[8]:'Other', plan[9]:'Other'})\ndataset['legal_ownership_status']=dataset['legal_ownership_status'].map({legal[0]:legal[0], legal[1]:'Other', legal[2]:'Other', legal[3]:'Other'})","be780d1e":"for i in cat_feat:\n    plt.figure(figsize=(5,3))\n    sns.countplot(dataset[i], palette='cool')","81f1b066":"num_feat = [i for i in dataset.columns if dataset[i].dtypes != 'O']\nnum_feat","3fe11bf5":"dataset[num_feat].head(5)","b5c9ece7":"plt.scatter(data = dataset, x = 'age', y = 'damage_grade')","bf59bd5a":"dataset = dataset.drop(dataset[dataset['age']>400].index)","c5954f23":"plt.scatter(data = dataset, x = 'age', y = 'damage_grade')","6f6f1128":"dataset['count_floors_pre_eq'].unique()","1de3001b":"for i in num_feat[4:]:\n    print(i)\n    print(dataset[i].unique())\n    print('---------------------------')","aacf664f":"num_to_be_label = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage']","06555430":"dataset.drop(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'], axis=1, inplace=True)","1aeb0af5":"for i in ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']:\n    num_feat.remove(i)","d421113a":"dataset.head(2)","05cdf423":"data_cat = pd.get_dummies(dataset[cat_feat])","e5d4f7d8":"data_cat.head()","218bc2f7":"from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\nfor i in num_to_be_label:\n    dataset[i] = label.fit_transform(dataset[i])","96610c96":"dataset.head()","7591ee37":"dataset.drop(cat_feat, axis=1, inplace=True)","430e02d8":"train_data = pd.concat([dataset, data_cat], axis=1)","36a36eb1":"train_data.head()","c3c87a87":"X = train_data.drop('damage_grade', axis=1)\ny = train_data.damage_grade","00fcb55b":"from xgboost import XGBClassifier\nmodel = XGBClassifier()\nmodel.fit(X, y)\nmodel.score(X, y)","d88cb465":"# from sklearn.ensemble import AdaBoostClassifier\n# bst = AdaBoostClassifier(random_state = 42, n_estimators = 100)\n# model = bst.fit(X, y)\n# model.score(X, y)","8d97e3ba":"# from sklearn.ensemble import RandomForestClassifier\n# model = RandomForestClassifier()\n# model.fit(X, y)\n# model.score(X, y)","53bc7e8d":"test_data = pd.read_csv(test_path)\ntest_data.head(2)","b89f807e":"test_data.isnull().sum().sum()","9197cdce":"test_data['land_surface_condition']=test_data['land_surface_condition'].map({land[0]:land[0], land[1]:'Other', land[2]:'Other'})\ntest_data['foundation_type']=test_data['foundation_type'].map({foundation[0]:foundation[0], foundation[1]:'Other', foundation[2]:'Other', foundation[3]:'Other', foundation[4]:'Other'})\ntest_data['ground_floor_type']=test_data['ground_floor_type'].map({ground[0]:ground[0], ground[1]:'Other', ground[2]:'Other', ground[3]:'Other', ground[4]:'Other'})\ntest_data['plan_configuration']=test_data['plan_configuration'].map({plan[0]:plan[0], plan[1]:'Other', plan[2]:'Other', plan[3]:'Other', plan[4]:'Other', plan[5]:'Other', plan[6]:'Other', plan[7]:'Other', plan[8]:'Other', plan[9]:'Other'})\ntest_data['legal_ownership_status']=test_data['legal_ownership_status'].map({legal[0]:legal[0], legal[1]:'Other', legal[2]:'Other', legal[3]:'Other'})","adc068a6":"test_data[test_data['age']>400] = test_data['age'].mean()\ntest_data.drop(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'], axis=1, inplace=True)\ntest_data_cat = pd.get_dummies(test_data[cat_feat])\n\nfor i in num_to_be_label:\n    test_data[i] = label.fit_transform(test_data[i])\n    \ntest_data.drop(cat_feat, axis=1, inplace=True)","38a81316":"X_test = pd.concat([test_data, test_data_cat], axis=1)","9f7a4de1":"X.shape, X_test.shape","12bad8e3":"test_data.columns","8cfdfa6d":"X_test.drop(list(set(X_test.columns) - set(X.columns)), axis=1, inplace=True)","b65c6925":"y_pred = model.predict(X_test)","22f4428a":"sub = pd.read_csv('..\/input\/richters-predictor-modeling-earthquake-damage\/submission_format.csv')\nresult = pd.DataFrame({sub.columns[0] : sub['building_id'],\n                        sub.columns[1] : y_pred})\nresult.to_csv('submission.csv', index=False)","8a5aadca":"result.head(2)","def453ce":"#### strong corretion between :\n* #### 'height_percentage' and 'count_floors_pre_eq'\n* #### 'has_secondary_use_agriculture' and 'has_secondary_use                       '\n* #### 'has_secondary_use_hotel' and 'has_secondary_use'\n* #### 'has_superstructure_cement_mortar_brick' and 'has_superstructure_mud_mortar_stone'\n* #### 'has_superstructure_mud_mortar_brick' and  'has_superstructure_mud_mortar_stone'","d507a8e5":"### MODEL 1","cfde3320":"### MODEL 3","647a7c2a":"#### train accuracy -->\n#### test accuracy -->","0e325a9f":"### Test Data","6e1776d7":"### MODEL 2","c3523a61":"#### train accuracy --> 0.6271\n#### test accuracy --> 0.6053","5550b6d2":"#### train accuracy --> 0.9999\n#### test accuracy --> 0.5778","2b4daae5":"#### train accuracy --> 0.5843\n#### test accuracy --> 0.5803","917f1da9":"#### Great !!!\n#### WE're good to go with categorical data","2ccc05a3":"### BEST MODEL YET TO COME"}}