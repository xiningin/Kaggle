{"cell_type":{"8147554f":"code","854f40d3":"code","b3486b3e":"code","1860055c":"code","06cc08e2":"code","5a010ca5":"code","0095c486":"code","e09c0de3":"code","a64c387c":"code","695fe918":"code","4c94f4e4":"code","7afb22f2":"code","46c87327":"code","71d1cb81":"code","200ec6f8":"code","c22f966b":"code","04375d08":"code","dc53c921":"code","40d67221":"code","5ca4c49e":"code","f7f1e739":"code","b02f967b":"code","664ea9df":"code","bc569994":"code","0e81e70d":"code","4bc89fb4":"code","b9dfb17d":"code","9614e88f":"code","cae439e7":"code","a71f66e8":"markdown","50cbfffd":"markdown","478e56bf":"markdown","94cd8188":"markdown"},"source":{"8147554f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","854f40d3":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize']=20,10\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dropout,Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport seaborn as sb\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold","b3486b3e":"Apple=pd.read_csv(\"\/kaggle\/input\/d\/advikmaniar\/popular-stock-prices\/AppleStocks.csv\")\ndisplay(Apple)","1860055c":"Apple[\"Date\"]=pd.to_datetime(Apple.Date,format=\"%Y-%m-%d\")\nApple.index=Apple['Date']\n\nplt.figure(figsize=(20,14))\nplt.subplot(2,1,1)\nplt.plot(Apple[\"Open\"],label='Open Price history')\nplt.plot(Apple[\"High\"],label='High Price history')\nplt.plot(Apple[\"Low\"],label='Low Price history')\nplt.plot(Apple[\"Close\"],label='Close Price history')\nplt.plot(Apple[\"Adj Close\"],label='Adj Close Price history')\nplt.grid()\nplt.legend()\nplt.show()","06cc08e2":"#Sort the dataset on date time and filter \u201cDate\u201d and \u201cClose\u201d columns\nApple1=Apple.sort_index(ascending=True,axis=0)\nnew_dataset=pd.DataFrame(index=range(0,len(Apple)),columns=['Date','Close'])\nL=len(Apple)\n\nfor i in range(0,len(Apple1)):\n    new_dataset[\"Date\"][i]=Apple1['Date'][i]\n    new_dataset[\"Close\"][i]=Apple1[\"Close\"][i]\n\n#Normalize the Dataset\nscaler=MinMaxScaler(feature_range=(0,1))\nnew_dataset.index=new_dataset.Date\nnew_dataset.drop(\"Date\",axis=1,inplace=True)\nfinal_dataset=new_dataset.values\n\ntrain_data=final_dataset[0:L-300,:]\nvalid_data=final_dataset[L-300:,:]\n\nscaled_data=scaler.fit_transform(final_dataset)\n\nx_train_data,y_train_data=[],[]\n\nfor i in range(300,len(train_data)):\n    x_train_data.append(scaled_data[i-300:i,0])\n    y_train_data.append(scaled_data[i,0])","5a010ca5":"x_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data)\nx_train_data=np.reshape(x_train_data,(x_train_data.shape[0],x_train_data.shape[1],1))","0095c486":"#Build and train the LSTM model\nlstm_model=Sequential()\nlstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_data.shape[1],1)))\nlstm_model.add(LSTM(units=50))\nlstm_model.add(Dense(1))\n\ninputs_data=new_dataset[len(new_dataset)-len(valid_data)-300:].values\ninputs_data=inputs_data.reshape(-1,1)\ninputs_data=scaler.transform(inputs_data)\n\nlstm_model.compile(loss='mean_squared_error',optimizer='adam')\nlstm_model.fit(x_train_data,y_train_data,epochs=1,batch_size=1,verbose=2)","e09c0de3":"#Testing data for the model\nX_test=[]\nfor i in range(300,inputs_data.shape[0]):\n    X_test.append(inputs_data[i-300:i,0])\n    \nX_test=np.array(X_test)\nX_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n\npredicted_closing_price=lstm_model.predict(X_test)\npredicted_closing_price=scaler.inverse_transform(predicted_closing_price)","a64c387c":"train_data=new_dataset[:L-300]\nvalid_data=new_dataset[L-300:]\nvalid_data['Predictions']=predicted_closing_price\ndisplay(valid_data)\n\n#Plot predicted stock values\nplt.figure(figsize=(20,8))\nplt.plot(train_data[\"Close\"])\nplt.plot(valid_data['Close'],label = \"Real Value\")\nplt.plot(valid_data[\"Predictions\"],label = \"Prediction\")\n\nplt.legend()\nplt.grid()\nplt.show()","695fe918":"Tata=pd.read_csv(\"\/kaggle\/input\/d\/advikmaniar\/popular-stock-prices\/TataStocks.csv\")\nTata","4c94f4e4":"Tata[\"Date\"]=pd.to_datetime(Tata.Date,format=\"%Y-%m-%d\")\nTata.index=Tata['Date']\n\nplt.figure(figsize=(20,8))\nplt.plot(Tata[\"Open\"],label='Open Price history')\nplt.plot(Tata[\"High\"],label='High Price history')\nplt.plot(Tata[\"Low\"],label='Low Price history')\nplt.plot(Tata[\"Close\"],label='Close Price history')\nplt.grid()\nplt.legend()\nplt.show()","7afb22f2":"#Sort the dataset on date time and filter \u201cDate\u201d and \u201cClose\u201d columns\ndata1=Tata.sort_index(ascending=True,axis=0)\nnew_dataset=pd.DataFrame(index=range(0,len(Tata)),columns=['Date','Close'])\nL=len(Tata)\n\nfor i in range(0,len(data1)):\n    new_dataset[\"Date\"][i]=data1['Date'][i]\n    new_dataset[\"Close\"][i]=data1[\"Close\"][i]\n\n    #Normalize the Dataset\nscaler=MinMaxScaler(feature_range=(0,1))\nnew_dataset.index=new_dataset.Date\nnew_dataset.drop(\"Date\",axis=1,inplace=True)\nfinal_dataset=new_dataset.values\n\ntrain_data=final_dataset[0:L-300,:]\nvalid_data=final_dataset[L-300:,:]\n\nscaled_data=scaler.fit_transform(final_dataset)\n\nx_train_data,y_train_data=[],[]\n\nfor i in range(300,len(train_data)):\n    x_train_data.append(scaled_data[i-300:i,0])\n    y_train_data.append(scaled_data[i,0])","46c87327":"x_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data)\nx_train_data=np.reshape(x_train_data,(x_train_data.shape[0],x_train_data.shape[1],1))","71d1cb81":"#Build and train the LSTM model\nlstm_model=Sequential()\nlstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_data.shape[1],1)))\nlstm_model.add(LSTM(units=50))\nlstm_model.add(Dense(1))\n\ninputs_data=new_dataset[len(new_dataset)-len(valid_data)-300:].values\ninputs_data=inputs_data.reshape(-1,1)\ninputs_data=scaler.transform(inputs_data)\n\nlstm_model.compile(loss='mean_squared_error',optimizer='adam')\nlstm_model.fit(x_train_data,y_train_data,epochs=1,batch_size=1,verbose=2)","200ec6f8":"#Testing data for the model\nX_test=[]\nfor i in range(300,inputs_data.shape[0]):\n    X_test.append(inputs_data[i-300:i,0])\nX_test=np.array(X_test)\n\nX_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\npredicted_closing_price=lstm_model.predict(X_test)\npredicted_closing_price=scaler.inverse_transform(predicted_closing_price)","c22f966b":"train_data=new_dataset[:L-300]\nvalid_data=new_dataset[L-300:]\nvalid_data['Predictions']=predicted_closing_price\n\n#Plot predictions\nplt.figure(figsize=(20,8))\nplt.plot(train_data[\"Close\"])\nplt.plot(valid_data['Close'],label = \"Real Value\")\nplt.plot(valid_data[\"Predictions\"],label = \"Prediction\")\n\nplt.legend()\nplt.grid()\nplt.show()","04375d08":"netflix=pd.read_csv(\"\/kaggle\/input\/d\/advikmaniar\/popular-stock-prices\/NFLX.csv\")\nnetflix[\"Date\"]=pd.to_datetime(netflix.Date,format=\"%Y-%m-%d\")\nnetflix.index=netflix['Date']\nnetflix","dc53c921":"#Correlation of values\ncorr = netflix.corr(method='pearson')\ncorr","40d67221":"#Dataset prepare\nnflx_df=netflix[['Date','High','Open','Low','Close']]\ndisplay(nflx_df.head(10))\n\nplt.figure(figsize=(20,8))\nplt.title('Netflix Closing Price ')\nplt.plot(nflx_df.index,nflx_df['Close'],label=\"Close\")\nplt.xlabel('Date',fontsize=18)\nplt.ylabel('Close Price',fontsize=18)\nplt.legend()\nplt.grid()\nplt.show()","5ca4c49e":"#Specific values visualiation\nnflx_df[['Open','Close']].head(20).plot(kind='bar')\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()\n\nnflx_df[['Low','Close']].head(20).plot(kind='bar')\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()\n\nnflx_df[['High','Close']].head(20).plot(kind='bar')\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","f7f1e739":"netflix['Date'] = pd.to_datetime(netflix.Date, format='%Y-%m-%d')\nnflx_df['Year']=netflix['Date'].dt.year\nnflx_df['Month']=netflix['Date'].dt.month\nnflx_df['Day']=netflix['Date'].dt.day\n\nnfx_df=nflx_df[['Day','Month','Year','High','Open','Low','Close']]\nnfx_df.tail(10)","b02f967b":"#Separate Independent and dependent variable\nX = nfx_df.iloc[:,nfx_df.columns !='Close']\nY= nfx_df.iloc[:, 5]\n\nx_train,x_test,y_train,y_test= train_test_split(X,Y,test_size=0.3)\nprint(x_train.shape) \nprint(x_test.shape) \nprint(y_train.shape)\nprint(y_test.shape) ","664ea9df":"lr=LinearRegression()\nlr.fit(x_train,y_train)\n\nc=lr.intercept_\nm=lr.coef_\nprint(\"Intercept is: {}\".format(c))\nprint(\"Coefficients are: {}\".format(m))","bc569994":"y_pred=lr.predict(x_test)\n\n#Check accuracy of model\nkfold = model_selection.KFold(n_splits=20)\nresults_kfold = model_selection.cross_val_score(lr, x_test, y_test.astype('int'), cv=kfold)\nprint(\"Accuracy: \", results_kfold.mean()*100,\"%\")","0e81e70d":"future_days = 100\nApple['Prediction'] = Apple[['Close']].shift(-future_days)\nApple.tail()","4bc89fb4":"X = np.array(Apple.drop([\"Date\",'Prediction'], 1))[:-future_days]\nprint(X)\n\nY = np.array(Apple['Prediction'])[:-future_days]\nprint(\"Predictions: {}\".format(Y))","b9dfb17d":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4)\ntree = DecisionTreeRegressor().fit(x_train, y_train)\nlr = LinearRegression().fit(x_train, y_train)","9614e88f":"x_future = Apple.drop([\"Date\",'Prediction'], 1)[:-future_days]\nx_future = x_future.tail(future_days) \nx_future = np.array(x_future)\n\ntree_prediction = tree.predict(x_future)\nprint( tree_prediction )\nprint()\n\nlr_prediction = lr.predict(x_future)\nprint(lr_prediction)","cae439e7":"#Visualize the data\npredictions = tree_prediction\n\n#Plot the data\nvalid =  Apple[X.shape[0]:]\nvalid['Predictions'] = predictions #Create a new column called 'Predictions' that will hold the predicted prices\nplt.figure(figsize=(20,8))\nplt.xlabel('Days')\nplt.ylabel('Close Price')\nplt.plot(Apple['Close'])\nplt.plot(valid[['Close','Predictions']])\nplt.legend(['Close', 'Val', 'Prediction' ], loc='lower right')\nplt.grid()\nplt.show()","a71f66e8":"# **APPLE (2016-present)**","50cbfffd":"# **TATA 2016-present**","478e56bf":"# **Using Decision Tree**\n__(For apple stocks)__","94cd8188":"# **Netflix (2016-present)**"}}