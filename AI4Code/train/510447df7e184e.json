{"cell_type":{"13fbeea8":"code","1d9e1d76":"code","1bb29c68":"code","12493767":"code","46f7da62":"code","68ec622e":"code","131941fe":"code","22b7b005":"code","bab6872c":"code","419f25dc":"markdown","6b6dd54d":"markdown","06303788":"markdown","6f2bb452":"markdown","5603cd22":"markdown","49c9aad9":"markdown","00cf94f4":"markdown","c5a041ac":"markdown"},"source":{"13fbeea8":"%mkdir -p data\/MNIST\/processed # make directory for datasets.MNIST\n%cp -r ..\/input\/* data\/MNIST\/processed # copy from ..\/input to data\/MNIST\/processed\n\nimport os\n# os.makedirs(\"input\/MNIST\/processed\", exist_ok=True) # or try this\nprint(os.listdir(\"data\/MNIST\/processed\"))","1d9e1d76":"import torch\nfrom torchvision import datasets, transforms\n\nbs = 64 # batch size in every epoch\n\n# trainning set\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(root = 'data', train=True, download=False,\n                    transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1307,), (0.3081,))\n                    ])),\n    batch_size=bs, shuffle=True) # shuffle set to True to have the data reshuffled at every epoch.\n\n# test set\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(root = 'data', train=False, transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1307,), (0.3081,))  # why using that?\n                    ])),\n    batch_size=bs*2, shuffle=True) # the validation set does not need backpropagation and thus takes less memory,\n                                   # so we use a larger batch size.","1bb29c68":"print(len(train_loader.dataset)) # number of samples\nprint(len(train_loader)) # number of batches\n\nprint(len(test_loader.dataset))","12493767":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img * 0.3081 + 0.1307     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % labels[j] for j in range(4)))\nprint(images.size())","46f7da62":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass LeNet5_like(nn.Module):\n    def __init__(self):\n        super(LeNet5_like, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        # NOTE! This layer is different from LeNet5: we do not use the Gaussian connections for simplicity.\n        self.fc3 = nn.Linear(84, 10)\n    \n    # Connect layers, define activation functions\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square you can only specify a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        # Flat x for fc\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n    def num_flat_features(self, x): # To see dimensions of layers\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n    \n\nmodel = LeNet5_like()\nprint(model)","68ec622e":"import torch.optim as optim\n\noptimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\nloss_f = nn.CrossEntropyLoss(reduction = 'mean')","131941fe":"def train(train_loader, model, optimizer, log_interval, epoch, criterion):\n    model.train() # Sets the module in training mode.\n    for batch_idx, (inputs, labels) in enumerate(train_loader, 0): # get the inputs. Start from index 0.\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        # print statistics\n        if batch_idx % log_interval == (log_interval-1):\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(inputs), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))\n            \ndef test(test_loader, model, criterion):\n    model.eval() # Sets the module in evaluation mode.\n    test_loss = 0 # loss compute by criterion\n    correct = 0 # for computing accurate\n    \n    # `with` allows you to ensure that a resource is \"cleaned up\" \n    # when the code that uses it finishes running, even if exceptions are thrown.\n    with torch.no_grad(): # It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n        for inputs, labels in test_loader:\n            outputs = model(inputs)\n            test_loss += criterion(outputs, labels).item() # sum up batch loss\n            pred = outputs.argmax(dim=1, keepdim=True)\n            correct += pred.eq(labels.view_as(pred)).sum().item()\n    \n    test_loss \/= len(test_loader) # average on batches\n    \n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct \/ len(test_loader.dataset)))","22b7b005":"# Constants\nepochs = 2 # how many epochs to train for\nlog_interval = 200 # how many batches to wait before logging training status\ncriterion = loss_f\n\nfor epoch in range(1, epochs + 1):\n    train(train_loader, model, optimizer, log_interval, epoch, criterion)\n    test(test_loader, model, criterion)","bab6872c":"use_cuda = torch.cuda.is_available()\nprint(use_cuda)\n\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nmodel = LeNet5_like().to(device)\n\n# Insert \"data, target = data.to(device), target.to(device)\" in train and test.","419f25dc":"# MNIST: Hand-writing numbers recognization\n\n## Contents\n\n* Load data from torchvision\n* Construct a CNN with torch.nn\n* Loss function and optimizer\n* Train and test the model\n\n**Result**: 99% accuracy on test set within 3 epochs.","6b6dd54d":"## 1. Load data from torchvision\n\nThe [`torchvision`](https:\/\/pytorch.org\/docs\/stable\/torchvision\/index.html#torchvision) package consists of popular datasets, model architectures, and common image transformations for computer vision (See [`torchvision.transforms`](https:\/\/pytorch.org\/docs\/stable\/torchvision\/transforms.html)).\n\n\n> **CLASS**  *torchvision.datasets.MNIST*(root, train=True, transform=None, target_transform=None, download=False)\n>\n> Parameters:\t\n>* *root* (string) \u2013 Root directory of dataset where MNIST\/processed\/training.pt and MNIST\/processed\/test.pt exist.\n>\n>* *train* (bool, optional) \u2013 If True, creates dataset from training.pt, otherwise from test.pt.\n>\n>* *download* (bool, optional) \u2013 If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.\n>\n>* *transform* (callable, optional) \u2013 A function\/transform that takes in an PIL image and returns a transformed version. E.g, transforms.RandomCrop\n>\n>* *target_transform* (callable, optional) \u2013 A function\/transform that takes in the target and transforms it.\n\nWe format the data as [`DataLoader`](https:\/\/pytorch.org\/docs\/stable\/data.html#torch.utils.data.DataLoader). Pytorch's ``DataLoader`` is responsible for managing batches. You can create a ``DataLoader`` from any ``Dataset``. ``DataLoader`` makes it easier to iterate over batches. Rather than having to use ``train_ds[i*bs : i*bs+bs]``, the DataLoader gives us each minibatch automatically.\n\n","06303788":"See some statistics of our datasets:","6f2bb452":"Let us show some of the training images, for fun.","5603cd22":"## 3. Loss function and optimizer\n\n`torch.optim` contains various optimization algorithms. We use SGD with momentum as the optimizer.\n\nWe use [`nn.CrossEntropyLoss`](https:\/\/pytorch.org\/docs\/stable\/nn.html#torch.nn.CrossEntropyLoss) as our loss function.","49c9aad9":"## 2. Construct a CNN with torch.nn\n\nIn PyTorch, networks are constructed in `torch.nn` package. `torch.nn` depends on `autograd` to define models and differents them. An `nn.Module` contains layers, a method `forward(input)` that returns the `output`.\n\nWe will use Pytorch's predefined [`Conv2d`](https:\/\/pytorch.org\/docs\/stable\/nn.html#torch.nn.Conv2d) class as our convolutional layer.\n\n> **CLASS** *torch.nn.Conv2d* (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n\nWe use the architecture of LeNet-5,\n![LeNet-5](http:\/\/daweiwong.com\/2017\/03\/07\/MNIST%20LeNet-5\/LeNet-5-structure.png)\n\nbut note that our image size is 28 * 28.","00cf94f4":"## 4. Train and test the network","c5a041ac":"## If we has CUDA ..."}}