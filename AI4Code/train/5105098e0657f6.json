{"cell_type":{"6d81d985":"code","ba7ffa12":"code","92471d26":"code","72c57300":"code","6b5b6fc2":"code","9206d3a4":"code","1bda072d":"code","50aec492":"code","450d7b73":"code","c8154fb8":"code","1f4d0927":"code","27072468":"markdown","9305cbf7":"markdown","55463286":"markdown","c1f6668f":"markdown","352eef84":"markdown","e959c59d":"markdown","9cf9392c":"markdown","0c33742c":"markdown"},"source":{"6d81d985":"import itertools\nimport cv2\nimport os\nimport time\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB7  as PretrainedModel, preprocess_input\nfrom tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nfrom glob import glob","ba7ffa12":"# Copying the folders into a single folder\n!mkdir .\/LungColon\n\nprint('Copying files...')\n!cp -R ..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/colon_image_sets\/* .\/LungColon\n!cp -R ..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/* .\/LungColon\nprint('All files copied successfully!')","92471d26":"folders = glob('.\/LungColon' + '\/*')\nprint('New Paths: ', folders)\n\nIMAGE_FILES = glob('.\/LungColon' + '\/*\/*.jpeg')\nprint('Images Count: ', len(IMAGE_FILES))","72c57300":"SAMPLES = ['.\/LungColon\/lung_scc\/lungscc1.jpeg', '.\/LungColon\/lung_n\/lungn1.jpeg', \n           '.\/LungColon\/lung_aca\/lungaca1.jpeg', '.\/LungColon\/colon_n\/colonn1.jpeg', \n           '.\/LungColon\/colon_aca\/colonca1.jpeg']\n\nplt.figure(figsize=(22, 8)) \nglobal c\nc = 0\n\nfor i in SAMPLES:\n    plt.subplot(1, 5, c + 1)\n    c += 1\n    t = i.split('\/')\n    plt.title(t[3])\n    plt.imshow(image.load_img(i))\n    plt.axis('off')\nplt.show()","6b5b6fc2":"data_dir = '.\/LungColon'\n\n# 80-20 Split\ndata = ImageDataGenerator(validation_split = 0.2)\n\nBATCH_SIZE = 128\n\n# 224 x 224 -- The minimum for EfficientNetB7, you can go as high as 600 x 600\nX = Y = 224\n\ntraining = data.flow_from_directory(data_dir,\n                                    class_mode = \"categorical\",\n                                    target_size = (X, Y),\n                                    color_mode=\"rgb\",\n                                    batch_size = BATCH_SIZE, \n                                    shuffle = False,\n                                    subset='training',\n                                    seed = 42)\n\nvalidation = data.flow_from_directory(data_dir,\n                                      class_mode = \"categorical\",\n                                      target_size = (X, Y),\n                                      color_mode=\"rgb\",\n                                      batch_size = BATCH_SIZE, \n                                      shuffle = False,\n                                      subset='validation',\n                                      seed = 42)","9206d3a4":"ptm = PretrainedModel(\n    input_shape=(X, Y, 3),\n    weights='imagenet',\n    include_top=False)\n\nptm.trainable = False\n\nK = len(folders)\n\nx = GlobalAveragePooling2D()(ptm.output)\nx = Flatten()(x)\nx = Dense(128, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\n\ny = Dense(K, activation='softmax')(x)\n\nmodel = Model(inputs=ptm.input, outputs=y)","1bda072d":"model.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n\n# model.summary()","50aec492":"early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nhistory = model.fit(\n    training,\n    validation_data=validation,\n    epochs=50,\n    callbacks=[early_stopping])","450d7b73":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(10, 10))\nplt.subplot(2, 1, 1)\n\nplt.plot(acc, label='Training Accuracy', color='r')\nplt.plot(val_acc, label='Validation Accuracy', color='b')\n\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='lower right', fontsize=13)\nplt.ylabel('Accuracy', fontsize=16, weight='bold')\nplt.title('Training & Validation Acc.', fontsize=16, weight='bold')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='r')\nplt.plot(val_loss, label='Validation Loss', color='b')\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='upper right', fontsize=13)\nplt.ylabel('Cross Entropy', fontsize=16, weight='bold')\nplt.title('Training & Validation Loss', fontsize=15, weight='bold')\nplt.xlabel('Epoch', fontsize=15, weight='bold')\nplt.show()","c8154fb8":"from sklearn.metrics import classification_report\n\nY_pred = model.predict(validation)\ny_pred = np.argmax(Y_pred, axis=1)\n\nprint(classification_report(validation.classes, y_pred))","1f4d0927":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(validation.classes, y_pred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc'],normalize=True,\n                      title='Normalized Confusion Matrix')\nplt.show()","27072468":"# **Approach**\n### **I'm gonna use Transfer Learing, specifically the EfficientNetB7 architecture to train a single model. Since I'm lazy, I'm gonna copy and merge the folders! Perhaps the worst approach! It's gonna take a while to copy all images!**\n### **Other approaches you can take:**\n#### 1. Create two seperate keras generator functions *('ImageDataGenerator')* and wrap them using a simple function, [like this](https:\/\/stackoverflow.com\/questions\/46313525\/how-do-i-combine-two-keras-generator-functions).\n#### 2. Build and Train two different models.\n#### 3. Probably the best approach is to iterate through the folders in order to create a dataframe of the filepaths and then feed it to the ImageDataGenerator.\n","9305cbf7":"# **Imports**","55463286":"# **TODO:**\n* ### Either set 'restore_best_weights=True' for the early stopping or use ModelCheckpoint in order to save the model in its best state\n* ### Use a \n","c1f6668f":"# **Classification Report**","352eef84":"# **Data Preparation**","e959c59d":"# **Confusion Matrix**","9cf9392c":"# **Generating Data**","0c33742c":"# **Showing Sample Images**"}}