{"cell_type":{"001730a8":"code","804d0adf":"code","a44aa23f":"code","c8c71fb7":"code","3fb49467":"code","0375065c":"code","32993405":"code","d7ede8d3":"code","8ccaee74":"code","fac96435":"code","4bf91129":"code","478b5fe4":"code","7f8ac595":"code","665bf079":"code","78a07936":"code","399ba2cf":"markdown"},"source":{"001730a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","804d0adf":"# Importamos las librer\u00edas necesarias\n\nimport matplotlib.pyplot as plt\n\n\nimport cv2 \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split","a44aa23f":"#Leemos el dataset de entrenamiento\ntrain_set = pd.read_csv(\"data\/train_set.csv\")","c8c71fb7":"#Creamos array con las im\u00e1genes de entrenamiento\ntrain_images = []\nfor i in range(len(train_set['id_img'])):\n    temp_imag = cv2.imread(\"data\/train\/\" + train_set.path[i], 0)\n    train_images.append(temp_imag)\ntrain_images = np.array(train_images)    ","3fb49467":"#Creamos array con las labels\ntrain_labels = np.array(train_set['label'])","0375065c":"#Codificamos las labels en valores binarios\nfor i in range(len(train_labels)):\n    if train_labels[i] == 'happy':\n        train_labels[i] = 1\n    else:\n        train_labels[i] = 0   ","32993405":"#Creamos nuestros conjuntos de entrenamiento y test y los normalizamos\ntrain_images, test_images, train_labels, test_labels = train_test_split(train_images,\n                                                      train_labels,test_size=0.2, random_state= 42)\ntrain_images = train_images.astype(\"float32\")\/255\ntest_images = test_images.astype(\"float32\")\/255\ntrain_labels = train_labels.astype(\"float32\")\ntest_labels = test_labels.astype(\"float32\")","d7ede8d3":"#Creamos las capas de nuestro modelo\nmodel = keras.models.Sequential()\n\n# Capa entrada\nmodel.add(keras.layers.Flatten(input_shape=(48, 48)))\n\n# Hidden layer\nmodel.add(keras.layers.Dense(units = 300,\n                            activation='relu'))\n\n                         \n\n\n# Hidden layer\nmodel.add(keras.layers.Dense(units = 100,\n                            activation='relu'))\n\n# Capa salida\nmodel.add(keras.layers.Dense(units = 2,\n                            activation='sigmoid'))","8ccaee74":"#Compilamos\nmodel.compile(\n    optimizer = \"adam\",\n    loss = \"sparse_categorical_crossentropy\",\n    \n    metrics = [\"accuracy\"]","fac96435":"#Entrenamos\nhistory = model.fit(\n    train_images,\n    train_labels,\n    batch_size = 64,\n    epochs = 60,\n    validation_split = 0.2,\n    #callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)]\n)","4bf91129":"#Cargamos nuestros datos de predicci\u00f3n\npred_set = pd.read_csv(\"data\/test_set.csv\")","478b5fe4":"#Creamos el array con las im\u00e1genes y realizamos las transformaciones necesarias\npred_images = []\nfor i in range(len(pred_set['id_img'])):\n    temp_pred = cv2.imread(\"data\/\" + pred_set.path[i], 0)\n    pred_images.append(temp_pred)\npred_images = np.array(pred_images)\npred_images = pred_images.astype(\"float32\")\/255","7f8ac595":"#Realizamos nuestras predicciones y las convertimos a sus valores en string\npred_labels = model.predict(pred_images)\nlabels_pred = []\nfor i in range(len(pred_labels)):\n    if pred_labels[i][0] > pred_labels[i][1]:\n        labels_pred.append('sadness')\n    else:\n        labels_pred.append('happy')  ","665bf079":"#Creamos nuestro dataframe de submissions\nsample = pd.read_csv(\"data\/sample_submission.csv\")\nsubmission_pred = sample.drop(['path'], axis = 'columns')\nsubmission_pred['label'] = pd.Series(labels_pred)","78a07936":"#Creamos csv para subir a Kaggle\nsubmission_pred.to_csv('submission.csv', index=False)","399ba2cf":"#Evaluamos con los datos de test\nresults = model.evaluate(test_images, test_labels)\nresults"}}