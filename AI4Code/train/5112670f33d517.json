{"cell_type":{"4de9a010":"code","de31f949":"code","8b040933":"code","8b46125f":"code","4a11bb1b":"code","de7a088e":"code","7d65583b":"code","e3cfb6e6":"code","10a4820e":"code","837a6145":"code","7194d8aa":"code","cdd8e71c":"code","6a07911a":"code","56d4441f":"code","81cc203b":"code","c57d23fb":"code","eee68586":"code","25012ffc":"code","89cf11f5":"code","aa6cda0f":"code","5490167f":"code","9b4f70a0":"code","44deac73":"code","92d13ec3":"code","b8d17482":"code","50604062":"code","10b179d6":"code","f2dd072f":"code","9c156d5b":"code","1fb641cd":"code","220fab9e":"code","5ad3138c":"markdown","a27a9792":"markdown","297bb38d":"markdown","6c73f74b":"markdown","0834744f":"markdown","0a8fec3b":"markdown","6518a202":"markdown","6b6891d7":"markdown","c7fc7d15":"markdown","749f23e1":"markdown","26efe0b2":"markdown","8d22270b":"markdown"},"source":{"4de9a010":"import os\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.metrics import classification_report, confusion_matrix","de31f949":"folder_parasitized = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/'\nfolder_uninfected = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/'\n\n# checking how many images do we have for each class\n\nprint(len(os.listdir(folder_parasitized)))\nprint(len(os.listdir(folder_uninfected)))","8b040933":"def visualize_cell(cell='p', n=5):\n    \"\"\"\n    mount a simple visualization of cell images\n    \"\"\"\n    p_cells = os.listdir(folder_parasitized)\n    u_cells = os.listdir(folder_uninfected)\n\n    if cell == 'p':\n        folder = 'Parasitized\/' \n        cells = p_cells\n    else:\n        folder = 'Uninfected\/'\n        cells = u_cells\n    \n    plt.figure(figsize=(10,8))\n    for i in range(n):\n        plt.subplot(1,n,i+1)\n        img=imread('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/' + folder + cells[i])\n        plt.title(cell + ' ' +  str(img.shape))\n        plt.imshow(img)\n        plt.tight_layout()\n    plt.show()","8b46125f":"print(visualize_cell(cell='p', n=5))\nprint(visualize_cell(cell='u', n=5))","4a11bb1b":"def check_dimensions(cell='p'):\n    \"\"\"\n    plot a jointplot showing dimensions distributions of cell images\n    \"\"\"\n    p_cells = [i for i in os.listdir(folder_parasitized) if i.endswith(\".png\")]\n    u_cells = [i for i in os.listdir(folder_uninfected) if i.endswith(\".png\")]\n\n    if cell=='p':\n        folder = 'Parasitized\/'\n        cells = p_cells\n    else:\n        folder = 'Uninfected\/'\n        cells = u_cells\n        \n    dim1 = []\n    dim2 = []\n\n    for image_file in cells:\n        img = imread('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/' + folder +  image_file)\n        d1,d2,colors = img.shape\n        dim1.append(d1)\n        dim2.append(d2)\n        \n    print(np.mean(dim1))\n    print(np.mean(dim2))\n        \n    sns.jointplot(x=dim1,y=dim2)","de7a088e":"check_dimensions(cell='p')","7d65583b":"check_dimensions(cell='u')","e3cfb6e6":"image_shape = (130,130,3)","10a4820e":"train_data_dir = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/'\nbatch_size = 64\n\nimage_gen = ImageDataGenerator(validation_split=0.2,\n                               rotation_range=30,\n                               width_shift_range=0.10,\n                               height_shift_range=0.10,\n                               rescale=1\/255,\n                               shear_range=0.1,\n                               zoom_range=0.1,\n                               horizontal_flip=True,\n                               fill_mode='nearest')\n\ntrain_generator = image_gen.flow_from_directory(\n    train_data_dir,\n    shuffle=True,\n    seed=42,\n    target_size=image_shape[:2],\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training', # set as training data\n    classes=['Uninfected', 'Parasitized'])\n\nvalidation_generator = image_gen.flow_from_directory(\n    train_data_dir, # same directory as training data\n    shuffle=False,\n    seed=42,\n    target_size=image_shape[:2],\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation', # set as validation data\n    classes=['Uninfected', 'Parasitized'])","837a6145":"print(train_generator.class_indices)\nprint(validation_generator.class_indices)","7194d8aa":"# taking an image to check the transformation result\n\nimages = [i for i in os.listdir(folder_parasitized) if i.endswith(\".png\")]\nimg=imread('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/' + images[0])\nplt.imshow(img)","cdd8e71c":"plt.imshow(image_gen.random_transform(img))","6a07911a":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units=128,activation='relu'))\nmodel.add(Dense(units=64,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","56d4441f":"model.summary()","81cc203b":"# set early stopping, to avoid overtraining\n\nearly_stop = EarlyStopping(monitor='val_loss',patience=3)","c57d23fb":"results = model.fit(train_generator,\n                    epochs=10,\n                    validation_data = validation_generator,\n                    callbacks=[early_stop])","eee68586":"losses = pd.DataFrame(model.history.history)","25012ffc":"losses[['loss','val_loss']].plot()","89cf11f5":"losses[['accuracy','val_accuracy']].plot()","aa6cda0f":"model.evaluate(validation_generator)","5490167f":"pred_probabilities = model.predict(validation_generator)","9b4f70a0":"pred_probabilities","44deac73":"predictions = pred_probabilities > 0.5","92d13ec3":"predictions","b8d17482":"print(classification_report(validation_generator.classes, predictions))","50604062":"confusion_matrix = pd.DataFrame(confusion_matrix(validation_generator.classes, predictions))\nconfusion_matrix","10b179d6":"model.save('malaria_detector.h5')","f2dd072f":"# taking an sample image from dataset\n\nimage_shape = (130,130,3)\nimages = [i for i in os.listdir(folder_parasitized) if i.endswith(\".png\")]\nimg = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/' + images[0]","9c156d5b":"new_image = image.load_img(img, target_size=image_shape)\nnew_image","1fb641cd":"# prepare image\n\nnew_image = image.img_to_array(new_image)\nnew_image = np.expand_dims(new_image, axis=0)","220fab9e":"model.predict(new_image)","5ad3138c":"1. <a href=\"#load\">Load data<\/a>\n2. <a href=\"#exp\">Explore data<\/a>\n3. <a href=\"#prep\">Prepare data for model<\/a>\n4. <a href=\"#model\">Set Model (Convolutional Neural Network)<\/a>\n5. <a href=\"#eval\">Evaluate Model <\/a>\n6. <a href=\"#simu\">Simulate new image prediction <\/a>","a27a9792":"we will set input image shape as (130,130,3)","297bb38d":"Let's automatically generate a flow of batches from a directory (and also do some data augmentation in images) with the help of Keras _flow_from_directory_ and _ImageDataGenerator_ classes. Ref.: https:\/\/keras.io\/api\/preprocessing\/image\/\n\nAs manipulation, we are going to rotate, resize and scale the images, so the model becomes more robust to different image settings.\n\nAlso, let's split our data in train and validation data. Ref.: https:\/\/stackoverflow.com\/questions\/42443936\/keras-split-train-test-set-when-using-imagedatagenerator\n","6c73f74b":"we can clearly see differences in parasitized and uninfected images. Hopefully our convolutional neural network will be able to learn these patterns.","0834744f":"# <a id=\"load\">Load data<\/a>","0a8fec3b":"# <a id=\"simu\"> Simulate new image prediction <\/a>","6518a202":"# <a id=\"model\">Set Model (Convolutional Neural Network)<\/a>","6b6891d7":"# <a id=\"eval\"> Evaluate Model <\/a>","c7fc7d15":"# <a id='prep'> Prepare data for model <\/a>","749f23e1":"p.s. to use Keras _.flow_from_directory_ and generate manipulated images from a directory, it is mandatory to organize images in sub-directories, and the directories should contain only images of one class.\n\nStructure Needed:\n\n* Image Data Folder\n    * Parasitized\n        * 0.png\n        * 1.png\n        * ...\n    * Uninfected\n        * 0.png\n        * 1.png\n        * ...","26efe0b2":"# <a id='exp'>Explore data<\/a>","8d22270b":"Let's now check the average dimensions of images. This information is relevant for posterior neural network input shape."}}