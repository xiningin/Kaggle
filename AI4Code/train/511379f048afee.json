{"cell_type":{"a321c1b6":"code","481fdea9":"code","1bc0e5e8":"code","510884f2":"code","dc288d1b":"code","6e1d3f6b":"code","c82de4db":"code","371af51d":"code","9c0bd31f":"code","9f5c5d27":"code","b0782703":"code","2920c7aa":"code","4b18c84a":"code","9f84e1a2":"code","f7b05486":"code","1531a103":"code","bb199f05":"code","25f7c373":"code","d4e77e32":"code","56733e48":"code","7d912c7a":"code","1800c661":"code","1fe291ce":"code","ff69ef8e":"code","cc732311":"code","6ba198c1":"code","8ecb8ff8":"code","ca9daf7b":"code","d8d0ad07":"code","27a4b6cc":"markdown","cbc6811b":"markdown","6d1789db":"markdown","56f57fbf":"markdown","1bfb724c":"markdown","807c0211":"markdown","a124e6f9":"markdown","29ca0732":"markdown","bbb7378e":"markdown","68b3e328":"markdown","d8f60c82":"markdown","4c4520a0":"markdown","b541c5c3":"markdown","20a2be8f":"markdown","77213c6e":"markdown","2bdc876a":"markdown","57d0a81c":"markdown","744e943d":"markdown","3c8615c8":"markdown","b774dffa":"markdown","127fa8d0":"markdown","5c8d2f87":"markdown","e37d02a6":"markdown"},"source":{"a321c1b6":"# Set your own project id here\nPROJECT_ID = 'innate-entry-249611'\n\nfrom google.cloud import bigquery\nclient = bigquery.Client(project=PROJECT_ID, location=\"US\")\ndataset = client.create_dataset('model_dataset', exists_ok=True)\n\nfrom google.cloud.bigquery import magics\nfrom kaggle.gcp import KaggleKernelCredentials\nmagics.context.credentials = KaggleKernelCredentials()\nmagics.context.project = PROJECT_ID","481fdea9":"%load_ext google.cloud.bigquery","1bc0e5e8":"# Datasets in ML can be splited into 'train' and 'test' sets. (train=80\/75% of your dataset, test=20\/25% of your dataset)\n# train dataset is usually used for training the ML model,\n# while test dataset is for tesing the model and evaluating it.","510884f2":"# create table reference\ntable = client.get_table(\"bigquery-public-data.austin_bikeshare.bikeshare_trips\")\n# look at the head of dataset\nclient.list_rows(table, max_results=5).to_dataframe()","dc288d1b":"%%bigquery train\nSELECT\n    start_station_name,\n    TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n    COUNT(1) AS num_rides\nFROM\n    `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nWHERE\n    start_time < '2018-01-01'\nGROUP BY\n    start_station_name, start_hour","6e1d3f6b":"train.head(5)","c82de4db":"train[train.num_rides == train.num_rides.max()]","371af51d":"train.num_rides.mean()","9c0bd31f":"train.groupby('start_station_name')['num_rides'].count().sort_values(ascending=False).head(10)","9f5c5d27":"%%bigquery\nCREATE OR REPLACE MODEL`model_dataset.bike_trips`\nOPTIONS(model_type='linear_reg') AS \nSELECT\n    start_station_name,\n    TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n    COUNT(1) AS label\nFROM\n    `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nWHERE\n    start_time <= '2018-01-01'\nGROUP BY\n    start_station_name, start_hour","b0782703":"%%bigquery\nSELECT\n *\nFROM \n ML.TRAINING_INFO(MODEL `model_dataset.bike_trips`)\nORDER BY\n iteration","2920c7aa":"%%bigquery\nSELECT\n*\nFROM ML.EVALUATE(MODEL `model_dataset.bike_trips`, (\n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(1) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    WHERE\n        start_time BETWEEN '2018-01-01' AND '2019-01-01'\n    GROUP BY\n        start_station_name, start_hour))","4b18c84a":"## There's some reasons behind that the model is not working great.\n\n## Sometimes choosing regression as model is not appropriate for some datasets, because:\n# 1. maybe there is no linear relationship between variables.\n# 2. the residuals don't follow a normal distribution.\n# 3. the residuals are distributed randomly.","9f84e1a2":"%%bigquery pearl_2018\nSELECT\n    AVG(ROUND(predicted_label)) AS avg_predicted_num_rides,\n    AVG(label) AS avg_actual_num_rides\nFROM\n ML.PREDICT(MODEL `model_dataset.bike_trips`, (\n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(1) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    WHERE\n        start_station_name = '22nd & Pearl'\n    AND\n        start_time BETWEEN '2018-01-01' AND '2019-01-01'\n    GROUP BY\n        start_station_name, start_hour))","f7b05486":"pearl_2018","1531a103":"%%bigquery annual_avg_num_rides\nSELECT\n    TIMESTAMP_TRUNC(start_time, DAY) AS start_day,\n    COUNT(1)\/COUNT(DISTINCT start_station_name) AS avg_num_rides\nFROM\n    `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nGROUP BY\n    start_day\nORDER BY\n    start_day","bb199f05":"annual_avg_num_rides.head(5)","25f7c373":"avg_daily_rides = annual_avg_num_rides.groupby('start_day')['avg_num_rides'].sum()\navg_daily_rides.plot(figsize=(15,5)).set(xlabel=None, ylabel='number of rides')","d4e77e32":"## According to the chart, the pattern after 2018 was not as same as what it was before 2018. It seems the daily number of rides faced a significant increase from the begining of 2018 till its middle, while this was almost under half of its values of 2018 in previous years.","56733e48":"%%bigquery\nCREATE OR REPLACE MODEL`model_dataset.bike_trips_improved`\nOPTIONS(model_type='linear_reg') AS \n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(DISTINCT bikeid) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    WHERE\n        start_time < '2018-01-01'\n    GROUP BY\n        start_station_name, start_hour","7d912c7a":"%%bigquery\nSELECT\n *\nFROM \n ML.TRAINING_INFO(MODEL `model_dataset.bike_trips_improved`)\nORDER BY\n iteration","1800c661":"%%bigquery\nSELECT\n*\nFROM ML.EVALUATE(MODEL `model_dataset.bike_trips_improved`, (\n    SELECT\n    start_station_name,\n    TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n    COUNT(1) AS label\nFROM\n    `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nWHERE\n    start_time >= '2018-01-01'\nGROUP BY\n    start_station_name, start_hour))","1fe291ce":"%%bigquery predict_2018\nSELECT\n    start_station_name AS station,\n    start_hour,\n    ROUND(predicted_label) AS pred_rides,\n    label AS rides\nFROM ML.PREDICT( MODEL `model_dataset.bike_trips_improved`,(\n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(1) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    WHERE\n        start_time BETWEEN '2018-01-01' AND '2019-01-01'\n    GROUP BY\n        start_station_name, start_hour))","ff69ef8e":"display(predict_2018.head(10))\neval_2018 = predict_2018.groupby('station')['pred_rides','rides'].sum()\neval_2018.plot(figsize=(15,5)).set(xlabel='stations', ylabel='number of rides', title='Number of rides from stations in 2018')","cc732311":"%%bigquery predict_all\nSELECT\n    start_station_name AS station,\n    start_hour,\n    ROUND(predicted_label) AS pred_rides,\n    label AS rides\nFROM ML.PREDICT( MODEL `model_dataset.bike_trips_improved`,(\n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(1) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    GROUP BY\n        start_station_name, start_hour))","6ba198c1":"eval_all = predict_all.groupby('station')['pred_rides','rides'].sum()\neval_all.plot(figsize=(15,5)).set(xlabel='stations', ylabel='number of rides', title='Number of rides from stations')","8ecb8ff8":"%%bigquery pearl_2018_new\nSELECT\n    AVG(ROUND(predicted_label)) AS avg_predicted_rides,\n    AVG(label) AS avg_actual_rides\nFROM\n ML.PREDICT(MODEL `model_dataset.bike_trips_improved`, (\n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(1) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    WHERE\n        start_station_name = '22nd & Pearl'\n    AND\n        start_time BETWEEN '2018-01-01' AND '2019-01-01'\n    GROUP BY\n        start_station_name, start_hour))","ca9daf7b":"print('Previous Model:')\ndisplay(pearl_2018)\nprint('New Model:')\ndisplay(pearl_2018_new)","d8d0ad07":"%%bigquery\nSELECT\n    AVG(ROUND(predicted_label)) AS avg_predicted_rides,\n    AVG(label) AS avg_actual_rides\nFROM\n ML.PREDICT(MODEL `model_dataset.bike_trips_improved`, (\n    SELECT\n        start_station_name,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        COUNT(1) AS label\n    FROM\n        `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    WHERE\n        start_station_name = '21st & Speedway @PCL'\n    GROUP BY\n        start_station_name, start_hour))","27a4b6cc":"You'll want to inspect your data to ensure it looks like what you expect. Run the line below to get a quick view of the data, and feel free to explore it more if you'd like (if you don't know how to do that, the [Pandas micro-course](https:\/\/www.kaggle.com\/learn\/pandas)) might be helpful.","cbc6811b":"## Linear Regression\n\nYour dataset is quite large. BigQuery is especially efficient with large datasets, so you'll use BigQuery-ML (called BQML) to build your model. BQML uses a \"linear regression\" model when predicting numeric outcomes, like the number of riders.\n\n## 1) Training vs testing\n\nYou'll want to test your model on data it hasn't seen before (for reasons described in the [Intro to Machine Learning Micro-Course](https:\/\/www.kaggle.com\/learn\/intro-to-machine-learning). What do you think is a good approach to splitting the data? What data should we use to train, what data should we use for test the model?","6d1789db":"Prediction of average number of the rides for the most crowded station (21st & Speedway @PCL)","56f57fbf":"You should see that the r^2 score here is negative. Negative values indicate that the model is worse than just predicting the mean rides for each example.\n\n## 5) Theories for poor performance\n\nWhy would your model be doing worse than making the most simple prediction based on historical data?","1bfb724c":"What you should see here is that the model is underestimating the number of rides by quite a bit. \n\n## 7) Exercise: Average daily rides per station\n\nEither something is wrong with the model or something surprising is happening in the 2018 data. \n\nWhat could be happening in the data? Write a query to get the average number of riders per station for each year in the dataset and order by the year so you can see the trend. You can use the `EXTRACT` method to get the day and year from the start time timestamp. (You can read up on EXTRACT [in this lesson in the Intro to SQL course](https:\/\/www.kaggle.com\/dansbecker\/order-by)). ","807c0211":"Write your query below:","a124e6f9":"### This exercise is designed to pair with [this tutorial](https:\/\/www.kaggle.com\/rtatman\/bigquery-machine-learning-tutorial). If you haven't taken a look at it yet, head over and check it out first. (Otherwise these exercises will be pretty confusing!) -- Rachael ","29ca0732":"Write your query below:","bbb7378e":"## 2) Exercise: Query the training data\n\nWrite the query to retrieve your training data. The fields should be:\n1. The start_station_name\n2. A time trips start, to the nearest hour. Get this with `TIMESTAMP_TRUNC(start_time, HOUR) as start_hour`\n3. The number of rides starting at the station during the hour. Call this `num_rides`.\nSelect only the data before 2018-01-01 (so we can save data from 2018 as testing data.)","68b3e328":"Write your query below:","d8f60c82":"## Training data\n\nFirst, you'll write a query to get the data for model-building. You can use the public Austin bike share dataset from the `bigquery-public-data.austin_bikeshare.bikeshare_trips` table. You predict the number of rides based on the station where the trip starts and the hour when the trip started. Use the `TIMESTAMP_TRUNC` function to truncate the start time to the hour.","4c4520a0":"Write your query below:","b541c5c3":"## 8) What do your results tell you?\n\nGiven the daily average riders per station over the years, does it make sense that the model is failing?","20a2be8f":"Write your query below:","77213c6e":"## 6) Exercise: Looking at predictions\n\nA good way to figure out where your model is going wrong is to look closer at a small set of predictions. Use your model to predict the number of rides for the 22nd & Pearl station in 2018. Compare the mean values of predicted vs actual riders.","2bdc876a":"## Model creation\n\nNow it's time to turn this data into a model. You'll use the `CREATE MODEL` statement that has a structure like: \n\n```sql\nCREATE OR REPLACE MODEL`model_dataset.bike_trips`\nOPTIONS(model_type='linear_reg') AS \n-- training data query goes here\nSELECT ...\n    column_with_labels AS label\n    column_with_data_1 \n    column_with_data_2\nFROM ... \nWHERE ... (Optional)\nGROUP BY ... (Optional)\n```\n\nThe `model_type` and `optimize_strategy` shown here are good parameters to use in general for predicting numeric outcomes with BQML.\n\n**Tip:** Using ```CREATE OR REPLACE MODEL``` rather than just ```CREATE MODEL``` ensures you don't get an error if you want to run this command again without first deleting the model you've created.","57d0a81c":"# 9) Next steps\n\nGiven what you've learned, what improvements do you think you could make to your model? Share your ideas on the [Kaggle Learn Forums](https:\/\/www.kaggle.com\/learn-forum)! (I'll pick a couple of my favorite ideas & send the folks who shared them a Kaggle t-shirt. :)","744e943d":"# Stocking rental bikes\n\n![bike rentals](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/a\/a0\/Bay_Area_Bike_Share_launch_in_San_Jose_CA.jpg\/640px-Bay_Area_Bike_Share_launch_in_San_Jose_CA.jpg)\n\nYou stock bikes for a bike rental company in Austin, ensuring stations have enough bikes for all their riders. You decide to build a model to predict how many riders will start from each station during each hour, capturing patterns in seasonality, time of day, day of the week, etc.\n\nTo get started, create a project in GCP and connect to it by running the code cell below. Make sure you have connected the kernel to your GCP account in Settings.","3c8615c8":"## 3) Exercise: Create and train the model\n\nBelow, write your query to create and train a linear regression model on the training data.","b774dffa":"According to the previous model in the exercise, the performance of this model is improved. However, there is still more room for improvement.\n\nEvaluation of model is as follows:","127fa8d0":"Let's train a new model based on number of bikes","5c8d2f87":"I used the improved model to predict the number of rides for the 22nd & Pearl station in 2018.","e37d02a6":"## 4) Exercise: Model evaluation\n\nNow that you have a model, evaluate it's performance on data from 2018. \n\n\n> Note that the ML.EVALUATE function will return different metrics depending on what's appropriate for your specific model. You can just use the regular ML.EVALUATE funciton here. (ROC curves are generally used to evaluate binary problems, not linear regression, so there's no reason to plot one here.)"}}