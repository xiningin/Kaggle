{"cell_type":{"cf8e630f":"code","96583ff5":"code","546ee952":"code","b244e6bd":"code","62f64faa":"code","58977058":"code","4b728ce0":"code","0449215b":"code","2ab960bc":"code","469b6450":"code","920d927d":"code","90de8f58":"code","b494cbce":"code","1bf9dba8":"code","f5cf4dcb":"code","31813bf8":"code","109ae380":"code","77ebf051":"code","104be78e":"markdown","bba185bf":"markdown","b367cd39":"markdown","3cfcc680":"markdown","78566680":"markdown","61748e96":"markdown","0f68033d":"markdown","cd4f46b3":"markdown","119b1d38":"markdown","ffeaf834":"markdown","6d8b051f":"markdown","cb17e1fc":"markdown","b461eaa7":"markdown","2b838435":"markdown"},"source":{"cf8e630f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport string\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","96583ff5":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","546ee952":"train_datagen = ImageDataGenerator(rescale = 1\/255, validation_split = 0.2)\ntest_datagen = ImageDataGenerator(rescale = 1\/255)","b244e6bd":"train_generator = train_datagen.flow_from_directory(\n    '\/kaggle\/input\/handsignimages\/Train',\n    target_size = (28, 28),\n    batch_size = 128,\n    class_mode = \"sparse\",\n    color_mode='grayscale',\n    subset = 'training'\n    )\n\nvalidation_generator = train_datagen.flow_from_directory(\n    '\/kaggle\/input\/handsignimages\/Train',\n    target_size = (28, 28),\n    batch_size = 128,\n    class_mode = \"sparse\",\n    color_mode='grayscale',\n    subset = 'validation'\n    )\n\ntest_generator = test_datagen.flow_from_directory(\n    '\/kaggle\/input\/handsignimages\/Test',\n    target_size = (28, 28),\n    batch_size = 128,\n    class_mode = \"sparse\",\n    color_mode='grayscale'\n    )","62f64faa":"classes = [char for char in string.ascii_uppercase if char != \"J\" if char != \"Z\"]\nprint(classes, end = \" \")","58977058":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img[:,:,0])\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","4b728ce0":"sample_training_images, _ = next(train_generator)\nplotImages(sample_training_images[:5])","0449215b":"import tensorflow as tf","2ab960bc":"model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\", input_shape = (28,28,1)),\n        tf.keras.layers.MaxPool2D((2,2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(256, activation = \"relu\"),\n        tf.keras.layers.Dense(256, activation = \"relu\"),\n        tf.keras.layers.Dense(len(classes), activation = \"softmax\")\n])","469b6450":"model.summary()","920d927d":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs = {}):\n        if logs.get(\"loss\") < 0.004:\n            print(\"\\nReached 99.6% accuracy so cancelling training!\")\n            self.model.stop_training = True\n\ncallback = myCallback()","90de8f58":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(\n    optimizer = RMSprop(lr = 0.001),\n    loss = \"sparse_categorical_crossentropy\",\n    metrics = [\"accuracy\"]\n)","b494cbce":"history = model.fit(\n    train_generator,\n    epochs=10,\n    callbacks = [callback],\n    validation_data = validation_generator\n)","1bf9dba8":"results = model.evaluate(test_generator)","f5cf4dcb":"# PLOT LOSS AND ACCURACY\n# %matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt","31813bf8":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')\n\n# Desired output. Charts with training and validation metrics. No crash :)","109ae380":"from random import randint\nimport cv2 as cv\n\ndef testModel(alphabet = \"A\"):\n    dirname, _, filenames = list(os.walk(f'\/kaggle\/input\/handsignimages\/Test\/{alphabet.upper()}'))[0]\n    img_path = os.path.join(dirname, filenames[randint(0, len(filenames))])\n    print(img_path)\n    img = cv.imread(img_path, 0).reshape(1, 28, 28, 1)\n    pred = model.predict(img)\n    pred_label = classes[np.argmax(pred)]\n\n    plt.title(pred_label)\n    plt.imshow(img[0,:,:,0], cmap = \"gray\")","77ebf051":"testModel(\"m\")","104be78e":"**Loading data as 28 * 28 grayscale images**","bba185bf":"**A small network of single convolution and 3 Dense layers**","b367cd39":"**Callback to stop training on 99.8% accuracy**","3cfcc680":"**Using RMSprop with learning rate = 0.01 and loss as categorical cross entropy**","78566680":"# **Visualizing the results**","61748e96":"* **Preparing the data generator**","0f68033d":"# **Evaluating**\n**Testing the model on unseen dataset of 7k images**","cd4f46b3":"**Visualizing the dataset**","119b1d38":"# Class Labels\n**24 classes excluding J and Z**","ffeaf834":"**Normalizing the data before feeding to model**","6d8b051f":"# Loading the libraries","cb17e1fc":"# **Training**\n**Training for 10 epochs**","b461eaa7":"# **Predicting**\n**Randomly choose an alphabet from folder and display its prediction**","2b838435":"# **Preparing the CNN model**"}}