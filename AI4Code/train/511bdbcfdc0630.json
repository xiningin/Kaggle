{"cell_type":{"d2a44e5d":"code","692359ce":"code","5549a4ca":"code","84f451d6":"code","a95ae552":"code","aff8a57a":"code","67f168c8":"code","1c1dc12a":"code","a519edc8":"code","5ebcd1fd":"code","0ece8c44":"code","e165cafb":"code","87c49003":"code","da03d5b6":"code","062c0dab":"code","edf582d0":"code","359ba15e":"code","61bb9d86":"code","11b7a14c":"code","157c4ad4":"code","1614b5cd":"code","ed5d586f":"code","e43e0cb8":"code","206d75e9":"code","ced99c22":"code","7c2e3105":"code","d8bc3dc3":"code","78869013":"code","d4e52f52":"code","4d0a00ea":"code","5a4a5010":"code","6e32028a":"code","fd122596":"code","5f20e1ff":"code","fd97d8ac":"code","7c6b8789":"code","4f5875c4":"code","de3f7450":"code","3318fe9e":"code","b883777c":"code","bc06b148":"code","1389a819":"code","d7a32f81":"code","18e6be6c":"code","29a9a0da":"code","7484bf30":"code","bc19e1cb":"code","251c07e5":"code","2987ddfa":"code","7754693d":"code","ab6536ab":"code","794c4e85":"code","a87dda7f":"code","a27bde47":"code","8486ba27":"code","782dd4c6":"code","d1e7a800":"code","b62efafb":"code","a96e4279":"code","be44e190":"markdown","e808ad0f":"markdown","e9367fc2":"markdown","27273630":"markdown","384ba329":"markdown","db63db1a":"markdown","6a8dad98":"markdown","4565d4c1":"markdown","2e23546e":"markdown","7a8c907e":"markdown","8f34ff36":"markdown","d5507071":"markdown","1547e6ed":"markdown","db6dd2f7":"markdown","813ff1ae":"markdown","b4fca0f4":"markdown","6b79789f":"markdown","07adf803":"markdown","6d72d106":"markdown","accd9532":"markdown","f7940572":"markdown","f493857c":"markdown","d5f93334":"markdown","c50b4906":"markdown","6b89e007":"markdown","e7b6f8af":"markdown","c4a7b756":"markdown","3c755dce":"markdown","90b51224":"markdown","b9c163ed":"markdown","eb634928":"markdown","0e8a0871":"markdown","9503481a":"markdown","13d18b07":"markdown","90ee1b78":"markdown","d3b6c6fe":"markdown","43438456":"markdown","3c0d8ff3":"markdown","ab9dbd88":"markdown","674645a6":"markdown","455488fa":"markdown","2e1c620f":"markdown","b460839f":"markdown","27b3ab39":"markdown"},"source":{"d2a44e5d":"# for data processing\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport re\n\n# for data pipeline --------------------\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import*\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import*\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\n# for prediction (machine learning models) ------------------------\n\nfrom sklearn.linear_model import*\nfrom sklearn.preprocessing import*\nfrom sklearn.ensemble import*\nfrom sklearn.neighbors import*\nfrom sklearn import svm\nfrom sklearn.naive_bayes import*\nimport xgboost as xgb","692359ce":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5549a4ca":"train_path='\/kaggle\/input\/doctor-fees-prediction\/Final_Train.xlsx'\ntest_path='\/kaggle\/input\/doctor-fees-prediction\/Final_Test.xlsx'","84f451d6":"train=pd.read_excel(train_path)\ntest=pd.read_excel(test_path)","a95ae552":"train.head()","aff8a57a":"train.info()","67f168c8":"test.head()","1c1dc12a":"test.info()","a519edc8":"for i in train['Miscellaneous_Info'].value_counts().index:\n  train['Miscellaneous_Info'].replace(i,int(1),inplace=True)\ntrain['Miscellaneous_Info'].fillna(int(0),inplace=True)\n\nfor i in test['Miscellaneous_Info'].value_counts().index:\n  test['Miscellaneous_Info'].replace(i,int(1),inplace=True)\ntest['Miscellaneous_Info'].fillna(int(0),inplace=True)","5ebcd1fd":"for i in train['Experience'].value_counts().index:\n  ww=i.split()\n  train['Experience'].replace(i,int(ww[0]),inplace=True)\n\nfor i in test['Experience'].value_counts().index:\n  ww=i.split()\n  test['Experience'].replace(i,int(ww[0]),inplace=True)","0ece8c44":"train['Place'].fillna('None,None',inplace=True)\ntest['Place'].fillna('None,None',inplace=True)","e165cafb":"train['Area']=train['Place'].str.rsplit(',',1).str.get(0)\ntrain['City']=train['Place'].str.rsplit(',',1).str.get(1)\ntest['Area']=test['Place'].str.rsplit(',',1).str.get(0)\ntest['City']=test['Place'].str.split(',',1).str.get(1)\n\ntrain['City']=train['City'].str.strip()\ntest['City']=test['City'].str.strip()","87c49003":"train['Area'].isnull().sum(),test['Area'].isnull().sum(),train['City'].isnull().sum(),test['City'].isnull().sum()","da03d5b6":"train[train['City'].isnull()]","062c0dab":"train.loc[train['City'].isnull(),'Area']='None'\ntrain['City']=train['City'].fillna('None')","edf582d0":"train['Area'].isnull().sum(),test['Area'].isnull().sum(),train['City'].isnull().sum(),test['City'].isnull().sum()","359ba15e":"train.drop('Place',1,inplace=True)\ntest.drop('Place',1,inplace=True)\n","61bb9d86":"train['Qualification'].value_counts()[:30]","11b7a14c":"# func to make feature \ndef fun(arr,string):\n  for data in dat:\n    if data.find(string) !=-1:\n      arr.append(int(1))\n    else :\n      arr.append(int(0))\ndef to_df(lst):\n  lst=pd.DataFrame(lst)\n  return lst\n\ncols=['mbbs','bhms','bams','ddvl','dlo','mlo','dnb','bds','md','ms','fellowship']","157c4ad4":"dat=train['Qualification']\n\nmbbs=[]\nbds=[]\nbams=[]\nmd=[]\nbhms=[]\nfellowship=[]\ndlo=[]\nmlo=[]\ndnb=[]\nddvl=[]\nms=[]\n\nfun(mbbs,'MBBS')\nfun(bds,'BDS')\nfun(bams,'BAMS')\nfun(md,'MD')\nfun(bhms,'BHMS')\nfun(fellowship,'Fellowship')\nfun(dlo,'DLO')\nfun(mlo,'MLO')\nfun(dnb,'DNB')\nfun(ddvl,'DDVL')\nfun(ms,'MS')\n\nmbbs=to_df(mbbs)\nbds=to_df(bds)\nbams=to_df(bams)\nmd=to_df(md)\nbhms=to_df(bhms)\nfellowship=to_df(fellowship)\ndlo=to_df(dlo)\nmlo=to_df(mlo)\ndnb=to_df(dnb)\nddvl=to_df(ddvl)\nms=to_df(ms)\n\ntrain.drop('Qualification',1,inplace=True)\ntrain=pd.concat([mbbs,bhms,bams,ddvl,dlo,mlo,dnb,bds,md,ms,fellowship,train],axis=1)\n\nmx=train.columns[11:]\nfor i in mx:\n  cols.append(i)\ntrain.columns=cols\ntrain.head()","1614b5cd":"dat=test['Qualification']\nmbbs=[]\nbds=[]\nbams=[]\nmd=[]\nbhms=[]\nfellowship=[]\ndlo=[]\nmlo=[]\ndnb=[]\nddvl=[]\nms=[]\n\ndat=test['Qualification']\nfun(mbbs,'MBBS')\nfun(bds,'BDS')\nfun(bams,'BAMS')\nfun(md,'MD')\nfun(bhms,'BHMS')\nfun(fellowship,'Fellowship')\nfun(dlo,'DLO')\nfun(mlo,'MLO')\nfun(dnb,'DNB')\nfun(ddvl,'DDVL')\nfun(ms,'MS')\n\nmbbs=to_df(mbbs)\nbds=to_df(bds)\nbams=to_df(bams)\nmd=to_df(md)\nbhms=to_df(bhms)\nfellowship=to_df(fellowship)\ndlo=to_df(dlo)\nmlo=to_df(mlo)\ndnb=to_df(dnb)\nddvl=to_df(ddvl)\nms=to_df(ms)\n\ntest.drop('Qualification',1,inplace=True)\ntest=pd.concat([mbbs,bhms,bams,ddvl,dlo,mlo,dnb,bds,md,ms,fellowship,test],axis=1)\n\ncols=['mbbs','bhms','bams','ddvl','dlo','mlo','dnb','bds','md','ms','fellowship']\nmx=test.columns[11:]\nfor i in mx:\n  cols.append(i)\n\ntest.columns=cols\ntest.head()","ed5d586f":"train['Rating'].fillna('-99999%',inplace=True)\ntest['Rating'].fillna('-99999%',inplace=True)\n\nfor i in train['Rating'].value_counts().index:\n  train['Rating'].replace(i,int(i[:-1]),inplace=True)\n\nfor i in test['Rating'].value_counts().index:\n  test['Rating'].replace(i,int(i[:-1]),inplace=True)","e43e0cb8":"train.head()","206d75e9":"train.head()","ced99c22":"profile=train['Profile'].value_counts().index\nArea=train['Area'].value_counts().index\nCity=train['City'].value_counts().index","7c2e3105":"col1=['mbbs','bhms','bams','ddvl','dlo','dnb','bds','md','ms','fellowship']\nlab=['has degree','no degree']\nfig,axes=plt.subplots(2,5,figsize=(15,8))\nfig.suptitle('Qualification',fontsize=20)\nk=1\nfor col in col1:\n  arr=[]\n  for i in range(2):\n    x=train[train[col]==i]\n    arr.append(np.mean(x['Fees']))\n  plt.subplot(2,5,k)\n  k+=1 \n  plt.title(col)\n  plt.pie(arr,labels=lab)\nplt.show()","d8bc3dc3":"col2=['mbbs','bhms','bams','ddvl','dlo','mlo','dnb','bds','md','ms','fellowship']\nsumm=np.zeros(len(train))\nfor i in col2:\n  arr=train[i]\n  summ=np.add(summ,arr)\ntemp_df=pd.DataFrame({'qual':summ,'fees':train['Fees']})     # created a dataframe adding all the qualifications into one.\n","78869013":"plt.scatter(temp_df['qual'],temp_df['fees'])","d4e52f52":"sns.catplot(x='qual',y='fees', data=temp_df.sort_values(\"fees\"),kind='box',height=6,aspect= 1.5,color='r')\nplt.show()","4d0a00ea":"plt.figure(figsize=(15,5))\nplt.title('Profile Analysis')\n\nplt.scatter(train['Profile'],train['Fees'],s=2)\nplt.show()","5a4a5010":"arr=[]\nfor i in profile:\n  x=train[train['Profile']==i]\n  arr.append(np.mean(x['Fees']))\nplt.title('average fees')\nplt.pie(arr,labels=profile)\nplt.show()","6e32028a":"plt.figure(figsize=(15,5))\nplt.title('Experience Analysis')\n\nplt.scatter(train['Experience'],train['Fees'],s=2)\nplt.show()","fd122596":"plt.figure(figsize=(15,5))\nplt.title('Fees on area Analysis')\n\nplt.scatter(train['Area'],train['Fees'],s=2)\nplt.xticks(rotation=270)\nplt.show()","5f20e1ff":"sns.catplot(x='City',y='Fees', data=train.sort_values(\"Fees\"),kind='box',height=6,aspect= 1.5,color='b')\nplt.xticks(rotation=30)\nplt.show()","fd97d8ac":"arr=[]\nfor i in City:\n  x=train[train['City']==i]\n  arr.append(np.mean(x['Fees']))\nplt.title('average fees')\nplt.pie(arr,labels=City)\nplt.show()","7c6b8789":"xx=train[train['Rating']>=0.0]\nplt.figure(figsize=(15,5))\nplt.title('Rating Analysis')\n\nplt.scatter(xx['Rating'],xx['Fees'],s=2)\nplt.show()","4f5875c4":"arr=[]\nfor i in range(2):\n  x=train[train['Miscellaneous_Info']==i]\n  arr.append(np.mean(x['Fees']))\nplt.title('Other information Analysis')\nlab=['no info','has info']\n\nplt.pie(arr,labels=lab)\nplt.show()","de3f7450":"train.drop(labels=col2,axis=1,inplace=True)\nqual=temp_df['qual']                                         # for train data\nqual=to_df(qual)\ntrain=pd.concat([qual,train],axis=1)\ntrain.head()","3318fe9e":"summ=np.zeros(len(test))\nfor i in col2:\n  arr=test[i]\n  summ=np.add(summ,arr)\ntemp_df=pd.DataFrame({'qual':summ})\ntest.drop(labels=col2,axis=1,inplace=True)\ntest=pd.concat([temp_df,test],axis=1)\ntest.head()","b883777c":"profile","bc06b148":"def encode(str):\n  scaler=LabelEncoder()\n  ar1=train[str]\n  ar1=scaler.fit_transform(ar1)\n  train[str]=ar1\n  ar2=test[str]\n  ar2=scaler.transform(ar2)\n  test[str]=ar2\n    ","1389a819":"encode('Profile')\nencode('City')","d7a32f81":"x1=train['Area']\nx2=test['Area']\ntry:\n  encode('Area')\nexcept:\n  print('ERROR ! New area token found in test.')\n  train['Area']=x1\n  test['Area']=x2","18e6be6c":"xx=train['Area'].value_counts().index\nxy=test['Area'].value_counts().index\nxx=to_df(xx)\nxy=to_df(xy)","29a9a0da":"x3=pd.concat([xx,xy],axis=0)\nx3.columns=['0']\na1=x3['0'].value_counts().index\ni=0\nfor val in a1:\n  train['Area'].replace(val,int(i),inplace=True)\n  test['Area'].replace(val,int(i),inplace=True)\n  i+=1","7484bf30":"test.head()","bc19e1cb":"X_train=train.drop('Fees',1)\ny_train=train['Fees']\nX_test=test","251c07e5":"print('shape of the X and Y s')\nX_train.shape,y_train.shape,X_test.shape","2987ddfa":"print(X_train.info())\nprint(X_test.info())","7754693d":"clf=RandomForestRegressor(random_state=0,criterion='mse')\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_train)\nprint('RMSE loss in train :',np.sqrt(mean_squared_error(y_train,y_pred)))","ab6536ab":"clf.score(X_train,y_train)","794c4e85":"X_tr=X_train.drop('Area',1)\nclf.fit(X_tr,y_train)\ny_pred=clf.predict(X_tr)\nprint('RMSE loss in train :',np.sqrt(mean_squared_error(y_train,y_pred)))\nprint('Accuracy of the model :',clf.score(X_tr,y_train))","a87dda7f":"X_tr,X_val,y_tr,y_val=train_test_split(X_train,y_train,test_size=0.2,random_state=0)","a27bde47":"clf.fit(X_tr,y_tr)\ny_pred=clf.predict(X_tr)\nprint('RMSE loss in train :',np.sqrt(mean_squared_error(y_tr,y_pred)))\ny_pred=clf.predict(X_val)\nprint('RMSE loss in validation :',np.sqrt(mean_squared_error(y_val,y_pred)))","8486ba27":"y_prediction=clf.predict(X_test)","782dd4c6":"for i in range(len(y_prediction)):\n  print(y_prediction[i])\n  break","d1e7a800":"def rounding(x):\n  m=(x\/\/50)*50\n  if m==x:\n    return int(x\/1.0)\n  elif x-m>=25.0:\n    return int((m+50)\/1.0)\n  else:\n    return int(m\/1.0)","b62efafb":"y_fin=[]\nfor i in range(len(y_prediction)):\n  y_fin.append(rounding(y_prediction[i]))\ny_fin=pd.DataFrame({'id':np.arange(1,len(y_fin)+1,1),'Fees':y_fin})\nprint(y_fin.head())","a96e4279":"y_fin.to_csv('final_submission.csv',index=False)","be44e190":"**Profile**","e808ad0f":"It is seen that the soctors having other info charges more than others.","e9367fc2":"**City**","27273630":"#### Primary Visualizations","384ba329":"# Pre-processing","db63db1a":"# Output generation or deployment of the project :\n\n       1. Now we are going to predict the test data with the model we've build.\n       2. After that we are going to turn that into a dataframe.\n       3. Then we will produce a 'sample_submission.csv'\n\n\nand thus our project comes to an **END**.","6a8dad98":"# THE END :)","4565d4c1":"At first we are going to fill the null values with *(None,None)*","2e23546e":"we are going to make this column '*None*' for city and area both","7a8c907e":"**Random Forest**","8f34ff36":"If we drop the *Area* column we can get :","d5507071":"Already the curve shows that this features doesn't varies on wages.","1547e6ed":"### Encoding","db6dd2f7":"Now we have encoded and prepared the train and test data for model fitting and evaluation.","813ff1ae":"# Do not forget to UPVOTE :) \n\nYou can visit my other works [kaggle notebooks](https:\/\/kaggle.com\/sagnik1511\/notebooks) , [github](https:\/\/github.com\/sagnik1511?tab=repositories) .","b4fca0f4":"It is not showing a greater influence of any singular degree . So we are going to sum up and check again.","6b79789f":"This seems that the fees are in float values. But we need them rounded with 50 as all the fees given in the test set are similar to that.","07adf803":"**Rating**","6d72d106":"### X and Y generation :\n\nwe are going to split the X_train and y_train from the train and simply declare the test as X_train as it does not possess any target values.","accd9532":"**Miscellaneous Info**","f7940572":"It shows that the model is not overfitted and we can move forward.\n\n","f493857c":"# Data gathering and post data preparation","d5f93334":"# Model selection and fitting :\n We are going to use 3 classifiers.\n\n As this is a regression task we are going to take -      ***Random Forest Regressor***","c50b4906":"**Experience**","6b89e007":"**Area**","e7b6f8af":"If there is any query or feedback please comment below. Feedbacks help us making precise projects .\n\nOr you can email me in [sagnik.jal00@gmail.com](sagnik.jal00@gmail.com).","c4a7b756":"**Rating**\n\nAs the rating column has many null values we are going to put their -99999% and after that we are going to change those percentages into numerical values.","3c755dce":"**Experience**\n\n      We'll discard all the texts and only put the numeric value ther.","90b51224":"It shows that the cities are highly correlated with the wages or charges of the doctor.","b9c163ed":"#### Final Pre-processing \n\nWe've seen that the qualifications are not informative as segragated but when treated as one. so we are going to drop those features and add a summed version to it.","eb634928":"**Qualification**","0e8a0871":"# Exploratory Data analysis","9503481a":"**Miscellaneaous column**\n\n          As the column holds special infomation and blank spaces also, we are going to treat all the non-null as '1' and others as '0'.","13d18b07":"The experience doesn't look quite corelated with the fees.","90ee1b78":"**Place**\n\n    We will split the area and the city into two different features as they can give us hints about the fees.","d3b6c6fe":"We found out that area is a valuable feature for the data .","43438456":"The area has one extra data in test so we are manually encoding the 'area'.","3c0d8ff3":"Now we are going separate the comma separated two types-city and area.","ab9dbd88":"**Qualification**\n\nWe are going to check which degrees the doctors have and then treat them as several features.","674645a6":"We can see that - \n    \n    MBBS,BDS,BAMS,MD,BHMS,Fellowship,DLO,MLO,DNB,DDVL,MS  , these qualifications are present in a very high number. \n    So, we are going to add features of those and add values '1' or '0' as if they are present or not.\n","455488fa":"This catplot shows that the charges also vary with the total qualification of the doctors. They increase with increase in number of degrees.","2e1c620f":"It states that '*Ayurveda*' doctors earns some less than others.\n\nwhereas the '*Dermatologists*' and the '*ENT*' specialists are earning more.","b460839f":"# Libraries","27b3ab39":"Similarly the rating is aslo not giving high correlation with features."}}