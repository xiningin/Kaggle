{"cell_type":{"5bdeff52":"code","ce0f5e4a":"code","3c094e3c":"code","ce620355":"code","de2c856a":"code","9eb754cf":"code","2bc6e938":"code","53225316":"code","c3e3f390":"code","3a22d977":"code","7145d8a0":"code","5a003cae":"code","08ea9dce":"code","6864a77c":"code","aa3a4c28":"code","70cced47":"code","88705cb7":"code","fd7474de":"code","a4f62200":"code","508be97a":"code","836e8323":"code","091a93f3":"code","e8285b3c":"code","ebcf3347":"code","7f83f812":"code","3a5489b8":"code","24643f63":"code","9cfa020d":"code","4fb89c55":"code","6227b9c1":"code","c7a3ab9a":"code","c0c6dd8e":"code","5ead86fd":"code","14d8a28e":"markdown","7baef632":"markdown","5eb1377e":"markdown","0b5c9949":"markdown","4ad8b6bf":"markdown","60b00c16":"markdown","adfc8933":"markdown","cc4bfa5c":"markdown","ac8ce612":"markdown","2add8208":"markdown","2fae0d40":"markdown","b939286b":"markdown"},"source":{"5bdeff52":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import  plot_model ,Sequence\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nimport tensorflow as tf\nfrom tensorflow.python.keras.losses import binary_crossentropy\nfrom scipy.ndimage import morphology as mp\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom glob import glob  # for getting list paths of image and labels\nfrom random import choice,sample\nfrom matplotlib import pyplot as plt\nimport cv2 # saving and loading images\n\n# Any results you write to the current directory are saved as output.","ce0f5e4a":"import wandb\nfrom wandb.keras import WandbCallback\nwandb.login(key =\"6dd3e9139115fb204a9bfb3fb90e225f8362fa7e\")","3c094e3c":"train_img_dir = '..\/input\/concatenation-endo\/cropped_train\/instrument_dataset_1\/images\/' \ntrain_mask_dir = '..\/input\/concatenation-endo\/cropped_train\/instrument_dataset_1\/binary_masks\/'\n\ntrain_imgs = os.listdir(train_img_dir)# if you have an error take a look here ...\ntrain_masks = os.listdir(train_mask_dir)\ntrain_imgs= sorted([ i for i in train_imgs ])\n\ntrain_masks= sorted([ i for i in train_masks ])\nprint(len(train_imgs))\nprint(len(train_masks))","ce620355":"print(train_imgs[:3])\ntrain_masks[:3]\n","de2c856a":"from sklearn.model_selection import train_test_split\n\nval_img_dir =  train_img_dir\nval_mask_dir = train_mask_dir\n\n\ntrain_imgs,val_imgs,train_masks,val_masks =  train_test_split(train_imgs, train_masks, test_size=0.13, random_state=42)\n\n\nprint(len(train_masks))\nprint(len(val_masks))","9eb754cf":"SATURATION  = (0.9, 1.1)\nCONTRAST = (0.9, 1.1)\nBRIGHTNESS  =  0.1\nROTATION    = 10.0\nSHEAR    = 2.0\nHZOOM  = 8.0\nWZOOM  = 4.0\nHSHIFT = 4.0\nWSHIFT = 4.0","2bc6e938":"import keras.backend as K\nfrom keras.layers import *\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nmask = cv2.imread(\"..\/input\/concatenation-endo\/cropped_train\/instrument_dataset_1\/binary_masks\/frame000.png\")[:,:,0].reshape(1024, 1280, 1)\nim = cv2.imread(\"..\/input\/concatenation-endo\/cropped_train\/instrument_dataset_1\/images\/frame000.jpg\")\n\nprint(mask.shape)\nprint(im.shape)\n\nconcate = np.concatenate([mask,im],axis = 2)\nconcate = tf.image.random_flip_left_right( concate)\ncpncate = tf.image.random_contrast(concate, CONTRAST[0], CONTRAST[1])\n\n\nprint(concate.shape)\nplt.imshow(concate)","53225316":"plt.imshow(concate[:,:,0])","c3e3f390":"plt.imshow(concate[:,:,1:])","3a22d977":"from scipy import ndimage","7145d8a0":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, images,image_dir,labels,label_dir ,batch_size=16, dim=(224,224,3) ,shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.images = images\n        self.image_dir = image_dir\n        self.labels = labels\n        self.label_dir = label_dir\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.images) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [k for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        \n        return X, y\n    \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.images))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_imgs = list()\n        batch_labels = list()\n\n        # Generate data\n        for i in list_IDs_temp:\n#             degree=np.random.random() * 360\n            # Store sample\n            img = load_img(self.image_dir + self.images[i] ,target_size=self.dim)\n            img = img_to_array(img)\/255.\n            \n            \n           # Store class\n            label = load_img(self.label_dir + self.labels[i] ,target_size=self.dim)\n            label = img_to_array(label)[:,:,0]\n            label = label != 0\n            label = mp.binary_erosion(mp.binary_erosion(label))\n            label = mp.binary_dilation(mp.binary_dilation(mp.binary_dilation(label)))\n            label = np.expand_dims((label)*1 , axis=2)\n            \n            #####################\n            X,y = img,label\n            concate = np.concatenate([y,X],axis = 2)\n            concate = tf.image.random_flip_left_right( concate)\n            # concate = tf.image.random_saturation(concate, SATURATION[0], SATURATION[1])\n            # concate = tf.image.random_contrast(concate, CONTRAST[0], CONTRAST[1])\n            concate = tf.image.random_flip_up_down(concate)\n            y,X = concate[:,:,0],concate[:,:,1:]\n            ########################\n            \n            batch_imgs.append(X)\n            batch_labels.append(y)\n            \n        return np.array(batch_imgs,dtype = np.float32 ) ,np.array(batch_labels , dtype = np.float32 )","5a003cae":"train_generator = DataGenerator(train_imgs,train_img_dir,train_masks,train_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\ntrain_steps = train_generator.__len__()\ntrain_steps","08ea9dce":"X,y = train_generator.__getitem__(2)\nt = 3\n\nplt.figure(figsize=(8,8))\nplt.subplot(121)\nplt.imshow(X[t])\nplt.subplot(122)\nplt.imshow(np.reshape(y[t],(224,224)))\n","6864a77c":"val_generator = DataGenerator(val_imgs,val_img_dir,val_masks,val_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\nval_steps = val_generator.__len__()\nval_steps","aa3a4c28":"def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n    y = concatenate([y, residual], axis=3)\n    y = conv_block(y, nfilters)\n    return y\n\n\ndef Unet(h, w, filters):\n# down\n    input_layer = Input(shape=(h, w, 3), name='image_input')\n    conv1 = conv_block(input_layer, nfilters=filters)\n    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = conv_block(conv1_out, nfilters=filters*2)\n    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = conv_block(conv2_out, nfilters=filters*4)\n    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = conv_block(conv3_out, nfilters=filters*8)\n    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv4_out = Dropout(0.5)(conv4_out)\n    conv5 = conv_block(conv4_out, nfilters=filters*16)\n    conv5 = Dropout(0.5)(conv5)\n# up\n    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n    deconv6 = Dropout(0.5)(deconv6)\n    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n    deconv7 = Dropout(0.5)(deconv7) \n    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n    output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(deconv9)\n    # using sigmoid activation for binary classification\n    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n    return model","70cced47":"inputs = Input(224,224)","88705cb7":"model = Unet(224 , 224 , 64)\n#model.summary()","fd7474de":"def jaccard_distance_loss(y_true, y_pred,smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return 1 - jac\n\ndef iou(y_true, y_pred,smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","a4f62200":"wandb.init(project =\"surgical_image_segmentation\",entity = \"medait\",name = \"binary- unet\")","508be97a":"model.compile(optimizer='adam', loss=jaccard_distance_loss ,metrics = [dice_coef,iou])\nmc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_dice_coef',save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(mode='max', monitor='val_dice_coef', patience=3, verbose=1)\ncallbacks = [WandbCallback()]\nmodel.metrics_names","836e8323":"# model.load_weights('..\/input\/endovis-unet-binary-segmentation\/top-weights.h5')","091a93f3":"results = model.fit(train_generator, steps_per_epoch=train_steps,epochs=40,callbacks=callbacks,validation_data=val_generator,validation_steps=val_steps)","e8285b3c":"results.history.keys()","ebcf3347":"# loss = results.history[\"loss\"]\n# # val_loss = results.history[\"val_loss\"]\n\n# dice_coef = results.history[\"dice_coef\"]\n# # val_dice_coef = results.history[\"val_dice_coef\"]\n\n# # acc = results.history[\"accuracy\"]\n# # val_acc = results.history[\"val_accuracy\"]\n","7f83f812":"# plt.plot(loss,label = \"loss\")\n# # plt.plot(val_loss,label  = \"val loss\")\n# plt.xlabel(\"iterations\")\n# # plt.ylabel(\"X axis label\")\n# plt.legend()","3a5489b8":"# plt.plot(dice_coef,label = \"dice_coef\")\n# # plt.plot(val_dice_coef,label  = \"val dice_coef\")\n# plt.xlabel(\"iterations\")\n# # plt.ylabel(\"X axis label\")\n# plt.legend()","24643f63":"# plt.plot(acc,label = \"acc\")\n# # plt.plot(val_acc,label  = \"val acc\")\n# plt.xlabel(\"iterations\")\n# # plt.ylabel(\"X axis label\")\n# plt.legend()","9cfa020d":"model.save_weights('top-weights.h5')","4fb89c55":"def make_prediction(model,image,shape):\n    img = img_to_array(load_img(image,target_size=shape))\n    img = np.expand_dims(img,axis=0)\/255.\n    mask = model.predict(img)\n    \n    mask = (mask[0] > 0.5)*1\n#     print(np.unique(mask,return_counts=True))\n    mask = np.reshape(mask,(224,224))\n    return mask                       ","6227b9c1":"# multiedovis\/multiclass_segmentation\/cropped_train\/instrument_dataset\/images\/15frame010.jpg\n#  multiedovis\/multiclass_segmentation\/cropped_train\/instrument_dataset\/images\/15frame020.jpg\n# multiedovis\/multiclass_segmentation\/cropped_train\/instrument_dataset\/images\/15frame040.jpg\n\nimage = \"..\/input\/multiedovis\/multiclass_segmentation\/cropped_train\/instrument_dataset\/images\/15frame040.jpg\"\nimg = img_to_array(load_img(image))\nplt.imshow(img\/255.)\nimg.shape","c7a3ab9a":"mask = make_prediction(model,image,(224,224,3))\nmask2 = cv2.merge([mask,mask,mask]).astype('float32')\nprint(img.shape,mask2.shape)\nmask2 = cv2.resize(mask2,(img.shape[1],img.shape[0]))\n# print(mask.shape)\nplt.imshow(mask2)","c0c6dd8e":"h,w = img.shape[:2]\nmask_resized = cv2.resize(np.uint8(mask*1),(w,h))\nmask_resized = mask_resized != 0\n#print(np.unique(mask_resized,return_counts=True))\nsegment = np.zeros((h,w,3))\nsegment[:,:,0] = img[:,:,0]*mask_resized\nsegment[:,:,1] = img[:,:,1]*mask_resized\nsegment[:,:,2] = img[:,:,2]*mask_resized\nsegment[np.where((segment == [0,0,0]).all(axis=2))] = [0,0,0]\n#img[np.where((img==[255,255,255]).all(axis=2))] = [0,0,0];","5ead86fd":"plt.figure(figsize=(8,8))\nplt.imshow(segment\/255.)","14d8a28e":"**Now use the mask to get the segmented image**","7baef632":"**After defining generator lets check the some of the dataset it generates for the training and visualize them**","5eb1377e":" **Now we need to define our training and validation generator using above implimented class.**","0b5c9949":"**Function to make prediction \nNote:-  Dont forget to Normalise image dataset (here i divided every pixel by 255. )**","4ad8b6bf":"# Now finally train our model with above configuration and train data generator.","60b00c16":"# listing image and their respective labels \nalso here we are asserting the presence of label file w.r.t each image.","adfc8933":"# Now its time to make some predictions","cc4bfa5c":"# Defining callbacks and compile model with adam optimiser with default learning rate.","ac8ce612":"# Segmentation Network Unet\n\n","2add8208":"# Here we impliment keras custom data generator to get batch images and labels without loading whole dataset in the active memory\n","2fae0d40":"# Here we define keras custom metric for the loss and accuracy computation\n\nJaccard distance loss - this loss help to get rid of the side effects of unbalanced class label in a image (like - 80% background , 20 % human )  https:\/\/en.wikipedia.org\/wiki\/Jaccard_index\n\ndice_coef - To evaluate accuracy of the segmentation.   https:\/\/en.wikipedia.org\/wiki\/S%C3%B8rensen%E2%80%93Dice_coefficient","b939286b":"**Repeat same steps for validation dataset**"}}