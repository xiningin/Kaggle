{"cell_type":{"405da71a":"code","4a4de458":"code","93f3ea3e":"code","33fe5865":"code","07ac206c":"code","a8910495":"code","4a92e074":"code","28822b3a":"code","98d0de72":"code","6f8d7c92":"code","4b2e8dfb":"code","17bb4f09":"code","d55d28f4":"code","01c72a0c":"code","1f0db8af":"code","005abe4b":"code","00199182":"code","d56fa0af":"code","357a732c":"markdown","ddd4b82e":"markdown","b20ebcbe":"markdown"},"source":{"405da71a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a4de458":"import numpy as np\nimport pandas as pd\nimport seaborn as sns","93f3ea3e":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nprint(\"Rows, columns of train-set: \" + str(train_data.shape))\ntrain_data.head()","33fe5865":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(\"Rows, columns of test-set: \" + str(test_data.shape))\ntest_data.head()","07ac206c":"train_data.describe()","a8910495":"train_data.isnull().sum()","4a92e074":"test_data.isnull().sum()","28822b3a":"train_data.drop('Cabin',axis=1,inplace=True)\n\ntest_data.drop('Cabin',axis=1,inplace=True)","98d0de72":"median_age=train_data['Age'].median(skipna=True)\ntrain_data['Age'].replace(np.nan,median_age,inplace=True)\n\nmedian_age=test_data['Age'].median(skipna=True)\ntest_data['Age'].replace(np.nan,median_age,inplace=True)","6f8d7c92":"freq_port = train_data.Embarked.dropna().mode()[0]\ntrain_data['Embarked'] = train_data['Embarked'].fillna(freq_port)","4b2e8dfb":"train_data.isnull().sum()","17bb4f09":"test_data.isnull().sum()","d55d28f4":"sns.countplot(x='Survived',hue='Sex',data=train_data);","01c72a0c":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\nprint(\"% of women who survivers:\", rate_women)\n\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nprint(\"% of men who survivers:\", rate_men)","1f0db8af":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])","005abe4b":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)","00199182":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.Survived = output.Survived.map({0: 'No', 1: 'Yes'})\noutput","d56fa0af":"output.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","357a732c":"We can understand that there are some missing values in this column.","ddd4b82e":"Here, 0 represents non-survived and 1 as survived.More than 400 males didn't survive where as around less than 100 females survived.","b20ebcbe":"The Age, Cabin and Embarked column have null values. Roughly 20% of Age data is missing.The cabin data has just too much of missing values this will be probably dropped further."}}