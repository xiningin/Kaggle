{"cell_type":{"327b21a0":"code","7badb8f1":"code","b2506719":"code","9b62f03c":"code","65bfd921":"code","d198e72f":"code","ca2bfd19":"code","a9bcbefb":"code","51859415":"code","90aee26c":"code","3c382e3c":"code","9484d355":"code","14af20bf":"code","a2e6d68a":"code","68674e4f":"code","6f242369":"code","5290741d":"code","51a02c12":"markdown","56c0b883":"markdown","31309635":"markdown","c8ff613e":"markdown","6ff9ee46":"markdown","73fafad3":"markdown"},"source":{"327b21a0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer","7badb8f1":"train=pd.read_csv(\"\/kaggle\/input\/jane-street-market-prediction\/train.csv\")","b2506719":"train.head()","9b62f03c":"train.shape","65bfd921":"train.describe()","d198e72f":"train.isna().sum().sort_values(ascending=False)","ca2bfd19":"print('Train Nan Valued colas: %d' %train.isna().any().sum())","a9bcbefb":"import missingno as msno\nday0 = train.loc[train['date'] == 0]\nmsno.matrix(day0);","51859415":"imputer = SimpleImputer(strategy='mean')\nimputed_train= pd.DataFrame(imputer.fit_transform(train))\n\nimputed_train.columns=train.columns\nimputed_train.index=train.index\n\nprint(f\"Is there any missing values left? {imputed_train.isna().sum().any()}\")\nimputed_train.head()","90aee26c":"threshold = 4\nz = np.abs(stats.zscore(imputed_train, nan_policy='omit'))\nclean_train= imputed_train[(z < threshold).all(axis=1)].reset_index(drop=True)\nclean_train","3c382e3c":"clean_train.drop_duplicates(keep=False,inplace=True)\nclean_train","9484d355":"correlations = clean_train.corr(method='pearson')\nfig, axs = plt.subplots(figsize=(16, 16))\nsns.heatmap(correlations)\nfig.show()","14af20bf":"day0 = clean_train.loc[clean_train['date'] == 0]\nday1 = clean_train.loc[clean_train['date'] == 1]\nday0and1 = pd.concat([day0, day1])\nday0and1.corr().style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)","a2e6d68a":"def find_skewed_boundaries(df, variable, distance):\n\n    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n\n    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n\n    return upper_boundary, lower_boundary\n\nupper_resp,lower_resp = find_skewed_boundaries(train,'resp',1.5)\n\n\nprint('Capping are',lower_resp,upper_resp)","68674e4f":"fig, axs = plt.subplots(2, 3, figsize=(12, 10))\naxs = axs.flatten()\nsns.distplot(clean_train['resp'], ax=axs[0])\naxs[0].set_title('resp')\nsns.distplot(clean_train['weight'], ax=axs[1])\naxs[1].set_title('weight')\nsns.distplot(clean_train['resp_1'], ax=axs[2])\nsns.distplot(clean_train['resp_2'], ax=axs[3])\nsns.distplot(clean_train['resp_3'], ax=axs[4])\nsns.distplot(clean_train['resp_4'], ax=axs[5])","6f242369":"fig, ax = plt.subplots(figsize=(20, 6))\nbalance= pd.Series(clean_train['resp']).cumsum()\nresp_1= pd.Series(clean_train['resp_1']).cumsum()\nresp_2= pd.Series(clean_train['resp_2']).cumsum()\nresp_3= pd.Series(clean_train['resp_3']).cumsum()\nresp_4= pd.Series(clean_train['resp_4']).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_title (\"Cumulative return of resp and time horizons 1, 2, 3, and 4\", fontsize=18)\nbalance.plot(lw=3)\nresp_1.plot(lw=3)\nresp_2.plot(lw=3)\nresp_3.plot(lw=3)\nresp_4.plot(lw=3)\nplt.legend(loc=\"upper left\");","5290741d":"feat= [c for c in clean_train.columns if 'feature' in c]\nfor f in feat:\n    fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n    sns.distplot(clean_train[f], ax=axs[0])\n    sns.distplot(clean_train.query('weight > 0')[f], ax=axs[1])\n    try:\n        sns.distplot(clean_train.query('weight > 0 and resp > 0')[f].dropna().apply(np.log1p), ax=axs[2])\n        sns.distplot(clean_train.query('weight > 0 and resp < 0')[f].dropna().apply(np.log1p), ax=axs[2])\n    except:\n        pass\n    train.sample(5000).plot(kind='scatter', x=f, y='resp', ax=axs[3])\n    fig.suptitle(f, fontsize=15, y=1.1)\n    \n    axs[0].set_title('feature distribution')\n    axs[1].set_title('only weight > 0')\n    axs[2].set_title('log transform')\n    axs[3].set_title('feature vs. response')\n    \n    plt.tight_layout()\n    plt.show()\n","51a02c12":"## Missing values","56c0b883":"## Correlation","31309635":"## Outlier Analysis","c8ff613e":"## EDA","6ff9ee46":"## Import libraries","73fafad3":"## Handling Missing Data"}}