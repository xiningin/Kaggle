{"cell_type":{"6106156f":"code","fc366019":"code","61c29301":"code","415714d9":"code","dbc4b478":"code","28a93168":"code","4b142434":"code","e1ef08fe":"code","8b9beaf1":"code","29f30789":"code","7d64c9d7":"code","6369a6cf":"code","78359e5a":"code","fe4c6d04":"code","e606ed3c":"code","70d4991f":"code","c48895f9":"code","d42bd7a3":"code","3f1a4601":"code","2481d847":"code","78d0b07d":"code","a8652be1":"code","cfc88c12":"code","44384063":"code","dc44de4a":"code","77a72304":"code","6acb22dc":"code","d2cc8d75":"code","699ec088":"code","93663e1f":"code","d57a4fd9":"code","2ab08920":"code","e22776d1":"code","e4587d38":"code","31fac35c":"code","555c02d1":"code","55139b15":"code","c4e388c8":"code","cc8c3d1a":"code","fb6cc25e":"code","6d7e6783":"code","248c7246":"code","dd8903f7":"code","3b8f5085":"code","5bd4736b":"code","1dc50527":"code","884cd80f":"code","23d68a7f":"code","f1838048":"code","2ce2d0e5":"code","0a543264":"code","e96ddaf6":"code","82145a3d":"code","5cc5e911":"code","30e22980":"code","456fec0d":"code","9879ad9f":"code","21c0097c":"code","2a0dbb68":"code","cab7bd44":"code","102b4e0f":"code","1fddefa6":"code","7ba9f18c":"code","9671309c":"code","7848b6a9":"code","d1892461":"code","92e466e8":"code","2cc3fb07":"code","41d655b4":"code","287bf93b":"code","0b3103c9":"code","70040986":"code","9b1c2c6c":"code","c14ab536":"code","9eb8c8b0":"code","66157832":"code","7e565e4f":"markdown","d92a269c":"markdown","5f26c5aa":"markdown","81b62d9a":"markdown","4f0043ce":"markdown","6692df99":"markdown","5eaad10e":"markdown","96e0dacd":"markdown","5aeb7914":"markdown","20aa2183":"markdown","fcc87057":"markdown","0444ef7f":"markdown","a4122349":"markdown","1ddfd386":"markdown","d346066f":"markdown","6f1e279e":"markdown","2d0e4fb1":"markdown","b22d95f1":"markdown","3b6f356a":"markdown","8a85c067":"markdown","c145f75d":"markdown","b88aa042":"markdown"},"source":{"6106156f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#garbage collector\nimport gc\ngc.enable() #enabling collection","fc366019":"PATH = '\/kaggle\/input\/instacart-market-basket-analysis\/'","61c29301":"#Reading all the datasets.\nprint('loading files ...')\norder_products_prior = pd.read_csv(PATH + 'order_products__prior.csv')\norder_products_train = pd.read_csv(PATH + 'order_products__train.csv')\norders = pd.read_csv(PATH + 'orders.csv')\nproducts = pd.read_csv(PATH + 'products.csv', usecols=['product_id', 'aisle_id', 'department_id'])\norders.eval_set = orders.eval_set.replace({'prior': 0, 'train': 1, 'test':2})\norders.days_since_prior_order = orders.days_since_prior_order.fillna(30)\nprint('done loading')","415714d9":"#merging orders and prior datasets\nprior_orders = pd.merge(orders, order_products_prior, on='order_id', how='inner')\nprior_orders.head()","dbc4b478":"#deleting prior dataset\ndel order_products_prior\ngc.collect()","28a93168":"#number of orders placed by each user.\nusers = prior_orders.groupby(by='user_id')['order_number'].aggregate('max').to_frame('u_num_of_orders').reset_index()\n# #converting the datatype to int.\n# users.u_num_of_orders = users.u_num_of_orders.astype(np.uint8)\nusers.head()","4b142434":"#average products in orders placed by each users.\n\n#1. First getting the total number of products in each order.\ntotal_prd_per_order = prior_orders.groupby(by=['user_id', 'order_id'])['product_id'].aggregate('count').to_frame('total_products_per_order').reset_index()\n\n#2. Getting the average products purchased by each user\navg_products = total_prd_per_order.groupby(by=['user_id'])['total_products_per_order'].mean().to_frame('u_avg_prd').reset_index()\navg_products.head()\n\n#deleting the total_prd_per_order dataframe\ndel [total_prd_per_order]\ngc.collect()\n\navg_products.head()\n","e1ef08fe":"#dow the user has ordered most.\n#importing the scipy's stats model\nfrom scipy import stats\n\n\n#execution will take approx 45sec.\ndow = prior_orders.groupby(by=['user_id'])['order_dow'].aggregate(lambda x : stats.mode(x)[0]).to_frame('dow_u_most_orders')\n#resetting the index\ndow = dow.reset_index()\ndow.head()","8b9beaf1":"#hour of day the user has ordered most.\n\n#execution will take approx 45sec.\nhod = prior_orders.groupby(by=['user_id'])['order_hour_of_day'].aggregate(lambda x : stats.mode(x)[0]).to_frame('hod_u_most_orders')\n#resetting the index\nhod = hod.reset_index()\nhod.head()","29f30789":"#reorder ratio of user.\nreorder_u = prior_orders.groupby(by='user_id')['reordered'].aggregate('mean').to_frame('u_reorder_ratio').reset_index()\n#changing the dtype.\nreorder_u['u_reorder_ratio'] = reorder_u['u_reorder_ratio'].astype(np.float16)\nreorder_u.head()","7d64c9d7":"#filling the NAN values with 0.\nprior_orders.days_since_prior_order.fillna(0, inplace=True)","6369a6cf":"#average days between orders.\navg_days = prior_orders.groupby(by='user_id')['days_since_prior_order'].aggregate('mean').to_frame('average_days_between_orders')\n#resetting index\navg_days = avg_days.reset_index()\navg_days.head()","78359e5a":"#total items bought.\ntotal_item = prior_orders.groupby(by='user_id').size().to_frame('u_total_items_bought').astype(np.int16)\ntotal_item.head()","fe4c6d04":"#merging users df and avg_prd\nusers = users.merge(avg_products, on='user_id', how='left')\n#merging users df with dow\nusers = users.merge(dow, on='user_id', how='left')\n#merging users df with hod\nusers = users.merge(hod, on='user_id', how='left')\n#merging users df with reorder_u\nusers = users.merge(reorder_u, on='user_id', how='left')\n#merging users df with avg_days\nusers = users.merge(avg_days, on='user_id', how='left')\n#merging total_item df with reorder_u\nusers = users.merge(total_item, on='user_id', how='left')\n\nusers.head()","e606ed3c":"#deleting unwwanted df\ndel [reorder_u, dow, hod, avg_products, avg_days, total_item]\ngc.collect()","70d4991f":"#number of times purchased.\nprd = prior_orders.groupby(by='product_id')['order_id'].aggregate('count').to_frame('p_num_of_times').reset_index()\n# prd['p_num_of_times'] = prd['p_num_of_times'].astype(np.uint16)\nprd.head()","c48895f9":"#reordered ratio for each product\nreorder_p = prior_orders.groupby(by='product_id')['reordered'].aggregate('mean').to_frame('p_reorder_ratio').reset_index()\n# #changing dtype\n# reorder_p['p_reorder_ratio'] = reorder_p['p_reorder_ratio'].astype(np.float16)\nreorder_p.head()","d42bd7a3":"#add to cart for each product.\nadd_to_cart = prior_orders.groupby(by='product_id')['add_to_cart_order'].aggregate('mean').to_frame('p_avg_cart_position').reset_index()\n# #changing the dtype\n# add_to_cart['p_avg_cart_position'] = add_to_cart['p_avg_cart_position'].astype(np.float16)\nadd_to_cart.head()","3f1a4601":"#merging reorder_p with prd.\nprd = prd.merge(reorder_p, on='product_id', how='left')\n\n#merging add_to_cart with prd.\nprd = prd.merge(add_to_cart, on='product_id', how='left')\n\n#deleting unwanted df.\ndel [reorder_p, add_to_cart]\ngc.collect()","2481d847":"prd.head()","78d0b07d":"#times a user have bough a product.\nuxp = prior_orders.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('uxp_times_bought')\n#resetting index\nuxp = uxp.reset_index()\n# #changing the dtype.\n# uxp['uxp_times_bought'] = uxp['uxp_times_bought'].astype(np.uint8)\nuxp.head()","a8652be1":"#times a user have bough a product.\ntimes = prior_orders.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('times_bought')\n#resetting index\ntimes = times.reset_index()\n# #changing the dtype.\n# times['times_bought'] = times['times_bought'].astype(np.uint8)\ntimes.head()","cfc88c12":"#Total orders\ntotal_orders = prior_orders.groupby('user_id')['order_number'].max().to_frame('total_orders').reset_index()\ntotal_orders.head()","44384063":"#Finding when the user has bought a product the first time.\nfirst_order_num = prior_orders.groupby(by=['user_id', 'product_id'])['order_number'].aggregate('min').to_frame('first_order_num')\n#resetting the index\nfirst_order_num = first_order_num.reset_index()\nfirst_order_num.head()","dc44de4a":"#merging both the dataframes\nspan = pd.merge(total_orders, first_order_num, on='user_id', how='right')\nspan.head()","77a72304":"#Calculating the order range.\n# The +1 includes in the difference the first order were the product has been purchased\nspan['Order_Range_D'] = span.total_orders - span.first_order_num + 1\nspan.head()","6acb22dc":"#merging times df with the span\nuxp_ratio = pd.merge(times, span, on=['user_id', 'product_id'], how='left')\nuxp_ratio.head()","d2cc8d75":"#calculating the ratio.\nuxp_ratio['uxp_reorder_ratio'] = uxp_ratio.times_bought \/ uxp_ratio.Order_Range_D\nuxp_ratio.head()","699ec088":"#dropping all the unwanted columns.\nuxp_ratio.drop(['times_bought', 'total_orders', 'first_order_num', 'Order_Range_D'], axis=1, inplace=True)\nuxp_ratio.head()","93663e1f":"#deleting all the unwanted df.\ndel [times, span, first_order_num, total_orders]\ngc.collect()","d57a4fd9":"#merging uxp_ratio with uxp.\nuxp = uxp.merge(uxp_ratio, on=['user_id', 'product_id'], how='left')\n#deleting uxp_ratio\ndel uxp_ratio\n#calling garbage collector.\ngc.collect()","2ab08920":"uxp.head()","e22776d1":"# #chacging the dtype of uxp_reorder_ratio\n# uxp.uxp_reorder_ratio = uxp.uxp_reorder_ratio.astype(np.float16)","e4587d38":"#Reversing the order number for each product.\nprior_orders['order_number_back'] = prior_orders.groupby(by=['user_id'])['order_number'].transform(max) - prior_orders.order_number + 1\nprior_orders.head()","31fac35c":"#keeping only the first 5 orders from the order_number_back.\ntemp = prior_orders.loc[prior_orders.order_number_back <= 5]\ntemp.head()","555c02d1":"#product bought by users in the last_five orders.\nlast_five = temp.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('uxp_last_five').reset_index()\nlast_five.head()","55139b15":"#ratio of the products bought in the last_five orders.\nlast_five['uxp_ratio_last_five'] = last_five.uxp_last_five \/ 5.0\n# #changing the dtype.\n# last_five['uxp_ratio_last_five'] = last_five['uxp_ratio_last_five'].astype(np.float16)\nlast_five.head()","c4e388c8":"# #changin the dtype of uxp_last_five.\n# last_five['uxp_last_five'] = last_five['uxp_last_five'].astype(np.uint8)","cc8c3d1a":"#merging this feature with uxp df.\nuxp = uxp.merge(last_five, on=['user_id', 'product_id'], how='left')\n\ndel [last_five, temp]\ngc.collect()\nuxp.head()","fb6cc25e":"#filling the NAN values with 0.\nuxp.fillna(0, inplace=True)\nuxp.head(10)","6d7e6783":"uxp.info()","248c7246":"# #Merge uxp features with the user features\n# #Store the results on a new DataFrame\ndata = uxp.merge(users, on='user_id', how='left')\ndata.head()","dd8903f7":"#Merging prd features with data.\ndata = data.merge(prd, on='product_id', how='left')\ndata.head()","3b8f5085":"#deleting unwanted df.\ndel [users, prd, uxp]\ngc.collect()","5bd4736b":"#shape of the dataset.\ndata.shape","1dc50527":"#keeping only the train and test set from the orders df.\norders_future = orders.loc[((orders.eval_set == 1) | (orders.eval_set == 2)), ['user_id', 'eval_set', 'order_id']]\norders_future.head()","884cd80f":"#merging the orders_future with data.\ndata = data.merge(orders_future, on='user_id', how='left')\ndata.head()","23d68a7f":"#Preparing training data set.\ndata_train = data[data.eval_set == 1]\ndata_train.head()","f1838048":"#merging the information contained in the order_products__train.csv into data_train.\ndata_train = data_train.merge(order_products_train[['product_id', 'order_id', 'reordered']], on=['product_id', 'order_id'], how='left')\ndata_train.head()","2ce2d0e5":"#filling the NAN values in the reordered\ndata_train.reordered.fillna(0, inplace=True)","0a543264":"# #setting user_id and product_id as index.\n# data_train = data_train.set_index(['user_id', 'product_id'])\n\n#deleting eval_set, order_id as they are not needed for training.\ndata_train.drop(['eval_set', 'order_id'], axis=1, inplace=True)","e96ddaf6":"#head()\ndata_train.head()","82145a3d":"#Preparing the test dataset.\ndata_test = data[data.eval_set == 2]\ndata_test.head()","5cc5e911":"# #setting user_id and product_id as index.\n# data_test = data_test.set_index(['user_id', 'product_id'])\n\n#deleting eval_set, order_id as they are not needed for training.\ndata_test.drop(['eval_set', 'order_id'], axis=1, inplace=True)","30e22980":"#shape of train and test.\ndata_train.shape, data_test.shape","456fec0d":"# #resetting index\n# data_train.reset_index()\n# data_test.reset_index()\n\n#adding aisle and department data\nproducts = pd.read_csv(PATH + 'products.csv', usecols=['product_id', 'aisle_id', 'department_id'])\n\n#merging product data into data_train and data_test.\ndata_train = data_train.merge(products, on='product_id', how='left')\ndata_test = data_test.merge(products, on='product_id', how='left')\n\n#setting the index again\ndata_train = data_train.set_index(['user_id', 'product_id'])\ndata_test = data_test.set_index(['user_id', 'product_id'])","9879ad9f":"#mean encoding categorical variables.\ncolumns_mean = ['aisle_id', 'department_id']\nfor col in columns_mean:\n        mean = data_train.groupby(col).reordered.mean()\n        data_train[col] = data_train[col].map(mean)\n        data_test[col] = data_test[col].map(mean)","21c0097c":"#deleting unwanted df and collecting garbage\ndel [data, orders_future, products, order_products_train]\ngc.collect()","2a0dbb68":"#importing the necessary packages.\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.metrics import f1_score, classification_report\nfrom scikitplot.metrics import plot_confusion_matrix\nfrom scikitplot.classifiers import plot_feature_importances\n\n#importing model packages.\nimport xgboost as xgb\nimport lightgbm as lgb","cab7bd44":"#Creating X and y variables.\nX = data_train.drop(['reordered', 'uxp_ratio_last_five'], axis=1)\ny = data_train.reordered\n\n#splitting dataset into train and test split.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)","102b4e0f":"#deleting X, y\ndel [data_train]\ngc.collect()","1fddefa6":"#setting boosters parameters\nparameters = {\n    'eavl_metric' : 'logloss',\n    'max_depth' : 5,\n    'colsample_bytree' : 0.4,\n    'subsample' : 0.8\n}","7ba9f18c":"#Creating a XGBoost model.\n# #Initializing the model\nxgb = xgb.XGBClassifier(objective='binary:logistic', parameters=parameters, num_boost_round=10)\n\n#fitting the model.\nxgb.fit(X_train, y_train)\n\n#prediction\ny_pred = (xgb.predict_proba(X_test)[:, 1] >= 0.21).astype('int') #setting a threshold.\n\n#Evaluation.\nprint('F1 Score: {}'.format(f1_score(y_pred, y_test)))\nprint(classification_report(y_pred, y_test))\nplot_confusion_matrix(y_pred, y_test)\n","9671309c":"#plotting feature importance.\nplot_feature_importances(xgb, feature_names=data_test.columns, x_tick_rotation=90, max_num_features=20, figsize=(10,8))","7848b6a9":"#Fitting on entire data.\nxgb.fit(data_train.drop(['reordered', 'uxp_ratio_last_five'], axis=1), data_train.reordered)","d1892461":"#making prdeictions on the test dataset\ny_pred_test = (xgb.predict_proba(data_test.drop('uxp_ratio_last_five', axis=1))[:, 1] >= 0.21).astype('int') #setting a threshold.","92e466e8":"#saving the prediction as a new column in data_test\ndata_test['prediction'] = y_pred_test\ndata_test.head()","2cc3fb07":"# Reset the index\nfinal = data_test.reset_index()\n# Keep only the required columns to create our submission file (for chapter 6)\nfinal = final[['product_id', 'user_id', 'prediction']]\n\ngc.collect()\nfinal.head()","41d655b4":"#Creating a submission file\norders = pd.read_csv(PATH + 'orders.csv')\norders_test = orders.loc[orders.eval_set == 'test', ['user_id', 'order_id']]\norders_test.head()","287bf93b":"#merging our prediction with orders_test\nfinal = final.merge(orders_test, on='user_id', how='left')\nfinal.head()","0b3103c9":"#remove user_id column\nfinal = final.drop('user_id', axis=1)","70040986":"#convert product_id as integer\nfinal['product_id'] = final.product_id.astype(int)\n\n## Remove all unnecessary objects\ndel orders\ndel orders_test\ngc.collect()\n\nfinal.head()","9b1c2c6c":"d = dict()\nfor row in final.itertuples():\n    if row.prediction== 1:\n        try:\n            d[row.order_id] += ' ' + str(row.product_id)\n        except:\n            d[row.order_id] = str(row.product_id)\n\nfor order in final.order_id:\n    if order not in d:\n        d[order] = 'None'\n        \ngc.collect()\n\n#We now check how the dictionary were populated (open hidden output)\n#d","c14ab536":"#Convert the dictionary into a DataFrame\nsub = pd.DataFrame.from_dict(d, orient='index')\n\n#Reset index\nsub.reset_index(inplace=True)\n#Set column names\nsub.columns = ['order_id', 'products']\n\nsub.head()","9eb8c8b0":"sub.to_csv('sub.csv', index=False, header=True)","66157832":"del [X, y, X_train, y_train, y_test, X_test, xgb, y_pred]\ngc.collect()","7e565e4f":"# Creating Training and Testing datasets.","d92a269c":"# Merging users, prd and uxp dataframes.","5f26c5aa":"7. Total items bought by user.","81b62d9a":"# Creating features using product_id.","4f0043ce":"3. Average add to cart order for each product.","6692df99":"1. How many times a User has bought a product.","5eaad10e":"1. Number of times the product has been purchased by the users.","96e0dacd":"# Creating Features using user_id.","5aeb7914":"** Merging all the created features into the users dataset. **","20aa2183":"# Model Building.","fcc87057":"** Merging all the created features into the prd dataset. **","0444ef7f":"3. Day of the week the users orders the most.","a4122349":"2. How many times a user bought a product after its first purchase.","1ddfd386":"** Merging all the created features into the uxp dataset. **","d346066f":"2. Reorder ratio of each products. Number of times the product was reordered \/ number of times it was purchased.","6f1e279e":"1. Total number of orders placed by each users. Max of the order_number column.","2d0e4fb1":"# Creating features using user_id and product_id.","b22d95f1":"5. Reordered ratio of each user.","3b6f356a":"4. Hour of the day the user has placed most of his\/her orders.","8a85c067":"3. How many times a customer bought a product on its last 5 orders.","c145f75d":"2. Average number of products bought in each orders.","b88aa042":"6. Average days since prior order."}}