{"cell_type":{"bbc89a4f":"code","861d6154":"code","9e727efa":"code","9eade1e1":"code","c7b41f06":"code","d9e22cfe":"code","0276cc84":"code","bf749b60":"code","1cb47c46":"code","66a6bddd":"code","cc7292a0":"code","e17d959c":"code","c5c99b52":"code","1e9c228d":"code","29b753c2":"code","df3c67f1":"code","12adf9ac":"code","0adae2eb":"code","b78a0ca5":"code","876c2841":"code","de9af364":"code","6581e859":"code","26cf7bab":"code","79f67f35":"code","e428aafc":"code","62a551bc":"code","143b30e2":"code","48a84b9c":"code","fd32fb5a":"markdown","096c7e26":"markdown","9d952369":"markdown","fdf963eb":"markdown","334edf5c":"markdown","d6129667":"markdown","b06db3a7":"markdown","42c22509":"markdown","96feb7fd":"markdown","b02af257":"markdown","bdbecbc2":"markdown","26259f40":"markdown","a8cfd75e":"markdown","616d810b":"markdown","bec5d8c1":"markdown","7d02dd60":"markdown"},"source":{"bbc89a4f":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport seaborn as sns \nimport matplotlib\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","861d6154":"train = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\nsample_sub = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')","9e727efa":"train.head()","9eade1e1":"train.describe().T[1:].sort_values(by='mean',ascending=False).style.background_gradient(cmap='YlOrRd')","c7b41f06":"train.info()","d9e22cfe":"print(f'Number of rows       : {train.shape[0]}\\nNumber of columns    : {train.shape[1]}\\nNo of missing values : {sum(train.isna().sum())}')","0276cc84":"test.head()","bf749b60":"print(f'Number of rows       : {test.shape[0]}\\nNumber of columns    : {test.shape[1]}\\nNo of missing values : {sum(test.isna().sum())}') ","1cb47c46":"test.describe().T[1:].sort_values(by='mean',ascending=False).style.background_gradient(cmap='YlOrRd')","66a6bddd":"features = []\nfor i in train.columns:\n    if len(train[i].value_counts())<=2:\n        features.append(i)","cc7292a0":"d = dict(train['Cover_Type'].value_counts())\n\nfig = plt.figure(figsize=(20, 5), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 2)\ngs.update(wspace=0.3, hspace=0.05)\n\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor('#f6f5f5')\nax1 = fig.add_subplot(gs[0, 1])\n\nax0.bar(d.keys(),d.values(),color='#ffd514',edgecolor='black')\nax1.set_facecolor('#f6f5f5')\nheight_per = [i\/len(train) for i in d.values()]\nax1.bar(d.keys(),height_per,color='#ff355d',edgecolor='black')\n\nax0.set_xlabel('Cover_Type')\nax1.set_xlabel('Cover_Type')\nax0.set_ylabel('count')\nax1.set_ylabel('percentage')\n\nfor i in ['right','top']:\n    ax0.spines[i].set_visible(False)\n    ax1.spines[i].set_visible(False)\n    \nplt.show()","e17d959c":"train_l_0,train_l_1 = [],[]\nfor i in train.columns:\n    if len(train[i].value_counts())<=2:\n        d = {0:0,1:0}\n        temp = dict(train[i].value_counts())\n        try:\n            d[0] = temp[0]\n        except:\n            pass\n        try:\n            d[1] = temp[1]\n        except:\n            pass\n        train_l_0.append(d[0])\n        train_l_1.append(d[1])\n        \n        \ntest_l_0,test_l_1 = [],[]\nfor i in test.columns:\n    if len(test[i].value_counts())<=2:\n        d = {0:0,1:0}\n        temp = dict(test[i].value_counts())\n        try:\n            d[0] = temp[0]\n        except:\n            pass\n        try:\n            d[1] = temp[1]\n        except:\n            pass\n        test_l_0.append(d[0])\n        test_l_1.append(d[1])\n        \nfeatures = [i for i in train.columns  if len(train[i].value_counts())<30]","c5c99b52":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(6,10),facecolor='#f6f5f5')\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=.35, hspace=0.05)\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#ffd514']*120)\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\nax0.set_facecolor(background_color)\nax0_sns = sns.barplot(ax=ax0, y=features[4:-1], x=train_l_0[4:], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1)\nsns.barplot(ax=ax0,y=features[4:-1], x=train_l_1[4:], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1,color='#ff355d')\nax0_sns.set_xlabel(\"count\",fontsize=4, weight='bold')\nax0_sns.set_ylabel(\"features\",fontsize=4, weight='bold')\nax0_sns.tick_params(labelsize=3, width=0.5, length=1.5)\nax0_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax0_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax0.text(0, -1.8, 'Train Dataset', fontsize=5, ha='left', va='top', weight='bold')\nax0.text(0, -1.105, 'Number of records with different soil type', fontsize=3, ha='left', va='top')\nax0.get_xaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\nfor p in ax0.patches:\n    value = f'{p.get_width():,.0f} | {(p.get_width()\/train.shape[0]):,.1%}'\n    x = p.get_x() + p.get_width() + 1000\n    y = p.get_y() + p.get_height() \/ 2 \n    ax0.text(x, y, value, ha='left', va='center', fontsize=3, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.2))\n    \n    \nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#ffd514']*120)\n\nfor s in [\"right\", \"top\"]:\n    ax1.spines[s].set_visible(False)\nax1.set_facecolor(background_color)\nax1_sns = sns.barplot(ax=ax1, y=features[4:-1], x=test_l_0[4:], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1)\nsns.barplot(ax=ax1,y=features[4:-1], x=test_l_1[4:], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1,color='#ff355d')\nax1_sns.set_xlabel(\"count\",fontsize=4, weight='bold')\nax1_sns.tick_params(labelsize=3, width=0.5, length=1.5)\nax1_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax1_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax1.text(0, -1.8, 'Test Dataset', fontsize=5, ha='left', va='top', weight='bold')\nax1.text(0, -1.105, 'Number of records with different soil type', fontsize=3, ha='left', va='top')\nax1.get_xaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n\n\nfor p in ax1.patches:\n    value = f'{p.get_width():,.0f} | {(p.get_width()\/test.shape[0]):,.1%}'\n    x = p.get_x() + p.get_width()+1000\n    y = p.get_y() + p.get_height() \/ 2 \n    ax1.text(x, y, value, ha='left', va='center', fontsize=3, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.2))\n    \nplt.show()","1e9c228d":"d = dict()\nd['train'],d['test'] = dict(),dict()\nfor i in features[:4]:\n    d['train'][i] = dict(train[i].value_counts())\n    d['test'][i] = dict(test[i].value_counts())\nd","29b753c2":"fig = plt.figure(figsize=(13,3),facecolor='#f6f5f5')\ngs = fig.add_gridspec(1,2)\n\nax4 = fig.add_subplot(gs[0,:])\n\nx = np.arange(4)\nax4.set_facecolor(background_color)\nax4.bar(x-0.1,[i[0] for i in d['train'].values()],0.2,edgecolor='black')\nax4.bar(x+0.1,[i[1] for i in d['train'].values()],0.2,color='#ff355d',edgecolor='black')\nax4.bar(x,[i[0] for i in d['test'].values()],0.2,edgecolor='black')\nax4.bar(x+0.2,[i[1] for i in d['test'].values()],0.2,color='#ff355d',edgecolor='black')\n\nax4.set_xticklabels(['','Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4'])\nax4.xaxis.set_major_locator(mtick.MultipleLocator(1))\n\nfor i in ['top','right']:\n    ax4.spines[i].set_visible(False)\n    \nfor p in ax4.patches:\n    value = f'{p.get_height():,.0f}'\n    x = p.get_x() + p.get_width()-0.2\n    y = p.get_y() + p.get_height()+140000\n    ax4.text(x, y, value, ha='left', va='center', fontsize=8, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.2))\n       \nplt.legend([0,1])\nplt.show()","df3c67f1":"fig = plt.figure(figsize=(15,15),facecolor='#f6f5f5')\ngs = fig.add_gridspec(5,2)\ngs.update(wspace=.35, hspace=0.25)\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[1,0])\nax3 = fig.add_subplot(gs[1,1])\nax4 = fig.add_subplot(gs[2,0])\nax5 = fig.add_subplot(gs[2,1])\nax6 = fig.add_subplot(gs[3,0])\nax7 = fig.add_subplot(gs[3,1])\nax8 = fig.add_subplot(gs[4,0])\nax9 = fig.add_subplot(gs[4,1])\n\nbackground_color = '#f6f5f5'\nax0.set_facecolor(background_color)\nax1.set_facecolor(background_color)\nax2.set_facecolor(background_color)\nax3.set_facecolor(background_color)\nax4.set_facecolor(background_color)\nax5.set_facecolor(background_color)\nax6.set_facecolor(background_color)\nax7.set_facecolor(background_color)\nax8.set_facecolor(background_color)\nax9.set_facecolor(background_color)\n\nax0.hist(train.Slope,bins=100)\nax0.hist(test.Slope,bins=100,color='#ff355d')\nax0.set_xlabel(\"Elevation\",fontsize=10, weight='bold')\nax0.text(80, 250000, 'Distribution of data', fontsize=20, fontweight='bold', fontfamily='serif', horizontalalignment='center')\n\nax1.hist(train.Aspect,bins=100)\nax1.hist(test.Aspect,bins=100,color='#ff355d')\nax1.set_xlabel(\"Aspect\",fontsize=10, weight='bold')\n\nax2.hist(train.Elevation,bins=100)\nax2.hist(test.Elevation,bins=100,color='#ff355d')\nax2.set_xlabel(\"Slope\",fontsize=10, weight='bold')\n\nax3.hist(train.Horizontal_Distance_To_Hydrology,bins=100)\nax3.hist(test.Horizontal_Distance_To_Hydrology,bins=100,color='#ff355d')\nax3.set_xlabel(\"Horizontal_Distance_To_Hydrology\",fontsize=10, weight='bold')\n\nax4.hist(train.Vertical_Distance_To_Hydrology,bins=100)\nax4.hist(test.Vertical_Distance_To_Hydrology,bins=100,color='#ff355d')\nax4.set_xlabel(\"Vertical_Distance_To_Hydrology\",fontsize=10, weight='bold')\n\nax5.hist(train.Horizontal_Distance_To_Roadways,bins=100)\nax5.hist(test.Horizontal_Distance_To_Roadways,bins=100,color='#ff355d')\nax5.set_xlabel(\"Horizontal_Distance_To_Roadways\",fontsize=10, weight='bold')\n\nax6.hist(train.Hillshade_9am,bins=100)\nax6.hist(test.Hillshade_9am,bins=100,color='#ff355d')\nax6.set_xlabel(\"Hillshade_9am\",fontsize=10, weight='bold')\n\nax7.hist(train.Hillshade_Noon,bins=100)\nax7.hist(test.Hillshade_Noon,bins=100,color='#ff355d')\nax7.set_xlabel(\"Hillshade_Noon\",fontsize=10, weight='bold')\n\nax8.hist(train.Hillshade_3pm,bins=100)\nax8.hist(test.Hillshade_3pm,bins=100,color='#ff355d')\nax8.set_xlabel(\"Hillshade_3pm\",fontsize=10, weight='bold')\n\nax9.hist(train.Horizontal_Distance_To_Fire_Points,bins=100)\nax9.hist(test.Horizontal_Distance_To_Fire_Points,bins=100,color='#ff355d')\nax9.set_xlabel(\"Horizontal_Distance_To_Fire_Points\",fontsize=10, weight='bold')\n\nfor i in ['top','right']:\n    ax0.spines[i].set_visible(False)\n    ax1.spines[i].set_visible(False)\n    ax2.spines[i].set_visible(False)\n    ax3.spines[i].set_visible(False)\n    ax4.spines[i].set_visible(False)\n    ax5.spines[i].set_visible(False)\n    ax6.spines[i].set_visible(False)\n    ax7.spines[i].set_visible(False)\n    ax8.spines[i].set_visible(False)\n    ax9.spines[i].set_visible(False)\n\nax1.legend(['train','test'],loc=0)\nplt.show()","12adf9ac":"features = ['Wilderness_Area1','Elevation','Wilderness_Area4','Cover_Type']","0adae2eb":"train[features].corr()","b78a0ca5":"x_train,x_val,y_train,y_val = train_test_split(train[features[:-1]],train['Cover_Type'])","876c2841":"model = RandomForestClassifier()","de9af364":"model.fit(x_train,y_train)","6581e859":"pred = model.predict(x_val)","26cf7bab":"print(classification_report(y_val, pred))","79f67f35":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_val, pred, normalize='true')\nsns.heatmap(cm, annot=True, cmap=\"YlOrRd\")\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title('Confusion matrix')\nplt.show()","e428aafc":"print('Accuracy : ', accuracy_score(y_val, pred))","62a551bc":"final_pred = model.predict(test[features[:-1]])","143b30e2":"submission = pd.DataFrame({'Id': test['Id'], 'Cover_Type': final_pred })\nsubmission.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","48a84b9c":"submission","fd32fb5a":"# Tabular Playground Series - Dec 2021\n\n**Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.**\n\nFor this competition, you will be predicting a categorical target based on a number of feature columns given in the data. The data is synthetically generated by a GAN that was trained on a the data from the [Forest Cover Type Prediction](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/overview). This dataset is (a) much larger, and (b) may or may not have the same relationship to the target as the original data.\n\nPlease refer to this [data page](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/data) for a detailed explanation of the features.","096c7e26":"# If you find this notebook useful, support with an upvote \ud83d\udc4d","9d952369":"<div id='soil'><\/div>\n\n#### 3.2 Soil_Type","fdf963eb":"<div id='val'><\/div>\n\n#### 4.3 validating model","334edf5c":"<div id='fit'><\/div>\n\n#### 4.2 fitting model","d6129667":"<div id='wild'><\/div>\n\n#### 3.3 Wilderness_Area","b06db3a7":"<div id='Chapter3'><\/div>\n\n## 3.0 EDA\n\n<div id='cover'><\/div>\n\n#### 3.1 Cover_Type","42c22509":"<div id='Chapter4'><\/div>\n\n## 4.0 Model Building","96feb7fd":"<div id='features'><\/div>\n\n#### 3.4 Feature Distribution","b02af257":"<div id='Chapter6'><\/div>\n\n## 6.0 submitting the predictions","bdbecbc2":"<div id='test'><\/div>\n\n#### 2.1 Exploring Test Data","26259f40":"<div id='content'><\/div>\n\n## Index of Content\n\n* [**1.0 Importing the modules**](#Chapter1)\n* [**2.0 Data Loading and Preperation**](#Chapter2)\n * [2.1 Exploring Train Data](#train)\n * [2.2 Exploring Test Data](#test)\n* [**3.0 EDA**](#Chapter3)\n * [3.1 Cover_Type](#cover)\n * [3.2 Soil_Type](#soil)\n * [3.4 Wilderness_Area](#wild)\n * [3.3 Features distribution](#features)\n* [**4.0 Model Building**](#Chapter4)\n * [4.1 spliting into train, val](#split)\n * [4.2 fitting model](#fit)\n * [4.3 validating model](#val)\n* [**5.0 Confusion Matrix**](#Chapter5)\n* [**6.0 submitting the predictions**](#Chapter6)\n\n<div id='Chapter1'><\/div>\n\n## 1.0 Importing the modules","a8cfd75e":"<div id='Chapter5'><\/div>\n\n## 5.0 Confusion Matrix","616d810b":"<div id='Chapter2'><\/div>\n\n## 2.0 Data Loading and Preperation","bec5d8c1":"<div id='split'><\/div>\n\n#### 4.1 spliting into train, val","7d02dd60":"* **Files**\n * **train.csv** - the training data with the target Cover_Type column\n * **test.csv** - the test set; you will be predicting the Cover_Type for each row in this file (the target integer class)\n * **sample_submission.csv** - a sample submission file in the correct format\n \n <div id='train'><\/div>\n\n#### 2.1 Exploring Train Data"}}