{"cell_type":{"220cbee0":"code","29fa6223":"code","1a602deb":"code","18cb409f":"code","9229fdae":"code","33319df6":"code","759fd48e":"code","6e3f4cec":"code","09ba5ebb":"code","862b782e":"code","286712fe":"code","31a475b0":"code","81bda615":"code","f1d2cbc1":"code","a9f345b1":"code","c1cb0f76":"code","88268f1f":"code","a81a394f":"code","c51d4ce1":"code","376287a9":"code","5e86c98f":"code","754549a3":"code","74d18999":"code","253d0d23":"code","0e409dec":"code","0a2cbe5c":"code","39437251":"markdown","b16ad00b":"markdown","2a6fb4ab":"markdown","2503c60b":"markdown","678f326c":"markdown","3b681958":"markdown","382aa15b":"markdown","cdaedf71":"markdown"},"source":{"220cbee0":"# import libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd# data processing\n\n# Visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","29fa6223":"heart = pd.read_csv(\"\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\nheart.head()","1a602deb":"# number of rows and columns\nheart.shape","18cb409f":"#to know more information\nheart.info()\n# output shows there is no missing values and all columns are integers except oldpeak which is a float","9229fdae":"# missing values\nheart.isnull().sum()\n# output shows that there is no null value","33319df6":"# statistical measures\nheart.describe()\n# count,mean,std, min,25% , 50% ,75%, max will be shown","759fd48e":"# to know more about the output variable\nheart['output'].value_counts()\n# shows 165 people are having heart diseases and 138 does not have heart disease\n# we are analyisng this becasue we need to check whether the data is distributed equally between the classes or not","6e3f4cec":"plt.figure(figsize=(10,8))\nsns.distplot(heart['output'],color = 'r',bins = 100,hist_kws = {'alpha': 0.8});\n# As this is a Binary Classification method, we don't get much information from plotting this dist plot\n# Otherwise we can see about the distribution of output value","09ba5ebb":"list(set(heart.dtypes.tolist()))\n# to know the data types","862b782e":"# pass that to a variable \nheart_num = heart.select_dtypes(include = ['float64', 'int64'])\nheart_num.head()","286712fe":"#  Plot all of them, to understand the distribution","31a475b0":"heart_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8); ","81bda615":"heart_num_corr = heart_num.corr()['output'][:-1] # -1 because the latest row is Output\ncorrelated_features_list = heart_num_corr[abs(heart_num_corr) > 0.5].sort_values(ascending=False)\nprint(\"There is {} strongly correlated values with Output:\\n{}\".format(len(correlated_features_list), correlated_features_list))","f1d2cbc1":"# We don't have strongly correlated features\n# Still we try to plot to see any other correlation is present\nfor i in range(0, len(heart_num.columns), 5):\n    sns.pairplot(data=heart_num,\n                x_vars=heart_num.columns[i:i+5],\n                y_vars=['output'])","a9f345b1":"# Creating Train and Test data\n# we menation axis = 1, when we are dropping a column and \n# axis =0 , when we are dropping a row\n\n# inorder to create the training data, we are removing the output column from the data\nX = heart.drop(columns = 'output',axis=1)\nY = heart['output']\nX.head()","c1cb0f76":"Y.head()","88268f1f":"# Splitting the data in to Train and Test\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,stratify = Y,random_state = 42)\n# when stratify is mentioned then the data is divided equally, like similar 0's and 1's.\n# Otherwise, train data may contain more 1's and test more 0's..like that\n","a81a394f":"print(X.shape,X_train.shape,X_test.shape)","c51d4ce1":"print(Y.shape,Y_train.shape,Y_test.shape)","376287a9":"model = LogisticRegression(solver=\"liblinear\").fit(X_train,Y_train)\n# In this we have included one instance of Logistic Regression to the model","5e86c98f":"# We use accuracy score to evaluate our metrix\n# In this model will predict the output value\n# Then this predicted value is compared with the orginal value\n# How much they match will tell us about the accuracy","754549a3":"# Accuarcy on training Data\nX_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(X_train_prediction, Y_train)","74d18999":"print('Accuracy on Training Data : ',training_data_accuracy)","253d0d23":"X_test_prediction = model.predict(X_test)\ntesting_data_accuracy = accuracy_score(X_test_prediction, Y_test)\nprint('Accuracy on Testing Data : ',testing_data_accuracy)","0e409dec":"input_data = (41,0,1,130,204,0,0,172,0,1.4,2,0,2)\n# now input_data is in the form of tuples.\n# we need to change it to numpy array\ninput_data_array = np.asarray(input_data)\n\n# reshape the numpy array as we are predicting for only one instace\ninput_data_reshape = input_data_array.reshape(1,-1)\nprediction = model.predict(input_data_reshape)\nprint(prediction)\n","0a2cbe5c":"# output predicted is correct as we expected","39437251":"**Data Modelling**","b16ad00b":"**Building a Predictive Model for Validation**","2a6fb4ab":"**Correlation**","2503c60b":"**Model Trainig**","678f326c":"**Exploratory Data Analysis**","3b681958":"**Model Evaluation**","382aa15b":"**Accuracy Score on Test Data**","cdaedf71":"**Numerical Data Distrubtion**"}}