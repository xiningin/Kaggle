{"cell_type":{"fcdb5aeb":"code","2c274515":"code","6a1dfa7d":"code","9d74fb81":"code","f7c69338":"code","a4b05f7a":"code","4a8fc99e":"code","811bdb4e":"code","05accc82":"code","fac178ca":"code","8a1a650f":"code","caaef830":"code","b0e9e69b":"code","3ab996be":"code","59da3c90":"code","79b03402":"code","6ec7a719":"code","57e9dacd":"markdown","54159475":"markdown","05bfe77a":"markdown","115cc446":"markdown","652ae03f":"markdown","942abd1e":"markdown","92d05b64":"markdown","7c26cef4":"markdown","6d12fa97":"markdown"},"source":{"fcdb5aeb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2c274515":"dataset = pd.read_csv(\"..\/input\/dataset\/datasets.csv\")\n","6a1dfa7d":"df = dataset.copy()\ndf = df.dropna(axis=0, subset=['Source'])\ndf.head()","9d74fb81":"import requests\nfrom io import BytesIO\nfrom PIL import Image\n\nfor i in range(100):\n  r = requests.get(df['Source'][i])\n  print(\"Status:\", r.status_code)\n  print(r.url)","f7c69338":"from PIL import Image \n  \n\nim = Image.open(r\"..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG\")  \n  \n\nim.show()  ","a4b05f7a":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimg = cv2.imread('..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG',0)\nret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\nret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n\nret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\nret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\nret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n\ntitles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\nimages = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n\nfor i in range(6):\n    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\nplt.show()","4a8fc99e":"img = cv2.imread('..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG',0)\nimg = cv2.medianBlur(img,5)\nret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\nth2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\nth3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\ntitles = ['Original Image', 'Global Thresholding (v = 127)','Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\nimages = [img, th1, th2, th3]\n\nfor i in range(4):\n    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\n    \nplt.show()\n","811bdb4e":"img = cv2.imread('..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG',0)\nedges = cv2.Canny(img,100,200)\n\nplt.subplot(121), plt.imshow(img,cmap = 'gray')\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(edges,cmap = 'gray')\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n\nplt.show()","05accc82":"from skimage import io\n\nimg = io.imread('..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG')\n\n\n\n\n#img = cv2.imread('simple.jpg')\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\ncorners = cv2.goodFeaturesToTrack(gray,25,0.01,10)\ncorners = np.int0(corners)\nfor i in corners:\n    x,y = i.ravel()\n    cv2.circle(img,(x,y),3,255,-1)\nplt.figure(figsize=(20,10))    \nplt.imshow(img)\nplt.show()","fac178ca":"import cv2\nfrom skimage import io\n\nimg = io.imread('..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG',0)\n\nfast = cv2.FastFeatureDetector()\n\n# find and draw the keypoints\nkp = fast.detect(img,None)\nimg2 = cv2.drawKeypoints(img, kp, color=(255,0,0))\n\n\n# Print all default params\nprint(\"Threshold: \", fast.getInt('threshold'))\nprint(\"nonmaxSuppression: \", fast.getBool('nonmaxSuppression'))\nprint(\"neighborhood: \", fast.getInt('type'))\nprint(\"Total Keypoints with nonmaxSuppression: \", len(kp))\ncv2.imwrite('fast_true.png',img2)\n\n\n# Disable nonmaxSuppression\nfast.setBool('nonmaxSuppression',0)\nkp = fast.detect(img,None)\nprint(\"Total Keypoints without nonmaxSuppression: \", len(kp))\nimg3 = cv2.drawKeypoints(img, kp, color=(255,0,0))\n\ncv2.imwrite('fast_false.png',img3)\nplt.show()","8a1a650f":"import cv2 as cv2\nfrom skimage import io, color\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import  Image\n","caaef830":"filename1='..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG'\nrgb = Image.open(filename1)\nrgb = np.asarray(rgb)\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nplt.title('Test Image')\nplt.imshow(rgb)\nimage_B = np.copy(rgb[:, :, 0])\nimage_G = np.copy(rgb[:, :, 1])\nimage_R = np.copy(rgb[:, :, 2]) \ns=np.shape(rgb)\n\n#Converting RGB to LAB color space\nlab = color.rgb2lab(rgb)\nimage_b = np.copy(lab[:, :, 0])\nimage_a = np.copy(lab[:, :, 1])\nimage_l = np.copy(lab[:, :, 2])\n\nlm=np.mean(lab[:,:,0], axis=(0, 1))\nam=np.mean(lab[:,:,1], axis=(0, 1))\nbm=np.mean(lab[:,:,2], axis=(0, 1))\n\n#Creating empty mask for masking shadow\nmas = np.empty([rgb.shape[0], rgb.shape[1]], dtype = bool)\nlb=lab[:,:,0]+lab[:,:,2]\n\n#Hand crafted thresholds: Dataset specific\nif (am+bm)<=15:\n mas[(image_l <=(lm-(np.std(image_l))\/15))] = False\nelse:\n mas[(image_l+image_b)<=50] = False\nB_masked = np.ma.masked_array(image_b, mask = mas)\nG_masked = np.ma.masked_array(image_G, mask = mas)\nR_masked = np.ma.masked_array(image_R, mask = mas) \nmam = np.dstack([rgb, (~mas).astype(np.uint8)*255])\n\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,2)\nplt.imshow(mam)\nplt.title('Shadow detected Image')\nplt.show()","b0e9e69b":"!pip install deepforest","3ab996be":"import matplotlib.pyplot as plt\nfrom deepforest import deepforest\nfrom deepforest import get_data\n\ntest_model = deepforest.deepforest()\ntest_model.use_release()\n\n#predict image\nimage_path = get_data(\"DJI_0040.JPG\")\nimage = test_model.predict_image(image_path = '..\/input\/reservoir-capacity-map-with-gcp\/Gregg1_2\/DJI_0040.JPG')\n\n#Show image, matplotlib expects RGB channel order, but keras-retinanet predicts in BGR\nplt.figure(figsize=(30,15))\nplt.imshow(image[...,::-1])\nplt.show()","59da3c90":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg# reading in an image\nimage = mpimg.imread('..\/input\/roaddataset\/asphalt-empty-road-4k_1540144695.jpg')\n# printing out some stats and plotting the image\nprint('This image is:', type(image), 'with dimensions:', image.shape)\nplt.figure(figsize=(30,15))\nplt.imshow(image)\nplt.show()","79b03402":"import numpy as np\nimport cv2\ndef region_of_interest(img, vertices):\n    # Define a blank matrix that matches the image height\/width.\n    mask = np.zeros_like(img)    # Retrieve the number of color channels of the image.\n    channel_count = img.shape[2]    # Create a match color with the same color channel counts.\n    match_mask_color = (255,) * channel_count\n      \n    # Fill inside the polygon\n    cv2.fillPoly(mask, vertices, match_mask_color)\n    \n    # Returning the image only where mask pixels match\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image","6ec7a719":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nregion_of_interest_vertices = [\n    (0, 2050),\n    (3800 \/ 2, 2050 \/ 2),\n    (3800, 2050),\n]\nimage = mpimg.imread('..\/input\/roaddataset\/asphalt-empty-road-4k_1540144695.jpg')\ncropped_image = region_of_interest(\n    image,\n    np.array([region_of_interest_vertices], np.int32),\n)\nplt.figure(figsize=(30,15))\nplt.imshow(cropped_image)\nplt.show()\n\n","57e9dacd":"#### Corner Detection","54159475":"## Road Detection","05bfe77a":"### shadow Detection","115cc446":"## Feature detection","652ae03f":"###  Image Thresholding","942abd1e":"#### Edge Detection","92d05b64":"##### 1. Canny Edge Detection","7c26cef4":"There are some tiny red dots which indicates the conres that are detected.","6d12fa97":"Testing the Image"}}