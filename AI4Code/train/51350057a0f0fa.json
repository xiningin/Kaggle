{"cell_type":{"772b7d3a":"code","493b8ff9":"code","03fd70e8":"code","fccd45ea":"code","fa1a1c55":"code","52c84bcf":"code","27b5347f":"code","48591e8f":"code","d8f2d5a1":"code","b9948a79":"code","b7e757e7":"code","7d8f154a":"code","b60d946b":"code","cccd614a":"code","c7506e2f":"code","c1984608":"code","c2bc550b":"code","eb30969c":"code","bae217e3":"code","a92f2899":"code","b8fd60ce":"code","750d2608":"code","57ed1831":"code","69d1b85e":"code","6bd860a3":"code","4dfd8ca3":"code","26e179f0":"code","0bb55b0d":"code","5063e8b2":"code","fa4d5275":"code","983f1760":"code","2734fa2f":"code","9c72548c":"code","5efce168":"code","d8adb5e7":"code","72b6db9c":"code","abd4bd0f":"code","bcf5f847":"code","913b636e":"code","bca76184":"code","c128f595":"code","c42a64b2":"code","ad890af7":"code","108e8a0e":"code","407f3b78":"markdown","24bc37bc":"markdown","4098614d":"markdown","682cd24c":"markdown","6fe57274":"markdown","3ea61c5b":"markdown","85d4d11f":"markdown","e9f9f774":"markdown","2e6f1554":"markdown","baa1cfdb":"markdown","eb045652":"markdown","fa4e046a":"markdown","cd8e33ef":"markdown","d1327fcc":"markdown","2b6c9875":"markdown","dff2f1b2":"markdown","cc2ce4bc":"markdown","7667ba37":"markdown","f126ef34":"markdown","2c86c6bc":"markdown","6c5bcb39":"markdown","9e050a17":"markdown","2798c794":"markdown","2ec62497":"markdown","f162b291":"markdown","d4ca0ae3":"markdown","804cc761":"markdown"},"source":{"772b7d3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","493b8ff9":"import sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, auc, roc_curve\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, learning_curve, cross_validate, train_test_split, KFold, cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom xgboost import XGBClassifier","03fd70e8":"data=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\ndata.head(2)\ntest_df=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv')","fccd45ea":"data.drop(columns='id',inplace=True)","fa1a1c55":"def count_plot(df,feat,palette='rainbow'):\n    plt.style.use('seaborn')\n    sns.set_style('whitegrid')\n\n    labels=df[feat].value_counts().index\n    values=df[feat].value_counts().values\n    \n    plt.figure(figsize=(15,5))\n\n    ax = plt.subplot2grid((1,2),(0,0))\n    sns.barplot(x=labels, y=values,palette=palette, alpha=0.75)\n    for i, p in enumerate(ax.patches):\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2., height + 0.1, values[i],ha=\"center\")\n    plt.title('Response of Customer', fontsize=15, weight='bold')    \n    plt.show()","52c84bcf":"sns.set_style(\"whitegrid\")","27b5347f":"count_plot(data,'Response')","48591e8f":"missing = data.isnull().sum()\nmissing","d8f2d5a1":"count_plot(data,'Gender','Purples')\nplt.show()","b9948a79":"import plotly.express as px\nfig=px.histogram(data, x=\"Age\", color=\"Response\", marginal=\"violin\",title =\"Distribution of Age vs Response\", \n                   labels={\"Age\": \"Age\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"Not Buy\", \"1\": \"Buy\"})\nfig.show()","b7e757e7":"bins = [20, 30, 40, 50, 60, 70, 80,90]\nlabels = ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79','80+']\ndata['AgeClass']=pd.cut(data.Age, bins, labels = labels,include_lowest = True)\n\ntest_df['AgeClass']=pd.cut(test_df.Age, bins, labels = labels,include_lowest = True)\n\ndata[['Age','AgeClass']].head(5)","7d8f154a":"with sns.axes_style(style='ticks'):\n    g = sns.factorplot(\"Vehicle_Damage\", \"Age\", \"Gender\", data=data, kind=\"box\")\n    g.set_axis_labels(\"Vehicle_Damage\", \"Age\");","b60d946b":"data_cats=['Gender','Driving_License','Region_Code','Previously_Insured','Vehicle_Age','Vehicle_Damage','Policy_Sales_Channel','Vintage','AgeClass']\ndata_nums=['Age','Annual_Premium']\ndata_all=data_cats+data_nums","cccd614a":"def detect_outliers(df,feat):\n    Q1 = data[feat].quantile(0.25)\n    Q3 = data[feat].quantile(0.75)\n    IQR = Q3 - Q1\n    #data[~ ((data['Annual_Premium'] < (Q1 - 1.5 * IQR)) |(data['Annual_Premium'] > (Q3 + 1.5 * IQR))) ]\n    return df[((df[feat] < (Q1 - 1.5 * IQR)) |(data[feat] > (Q3 + 1.5 * IQR))) ].shape[0]\n\ndef clean_outliers(df,feat):\n    Q1 = data[feat].quantile(0.25)\n    Q3 = data[feat].quantile(0.75)\n    IQR = Q3 - Q1\n    return df[~ ((df[feat] < (Q1 - 1.5 * IQR)) |(data[feat] > (Q3 + 1.5 * IQR))) ]","c7506e2f":"for feat in data_nums:\n    res=detect_outliers(data,feat)\n    if (res>0):\n        print('%d Outlier detected in feature %s' % (res,feat))","c1984608":"clean_data=clean_outliers(data,'Annual_Premium')\nclean_data.shape","c2bc550b":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(clean_data[data_cats+data_nums], clean_data.Response, test_size=0.33, random_state=1)","eb30969c":"def prepare_inputs(train):\n    oe = OrdinalEncoder()\n    oe.fit(train)\n    return oe","bae217e3":"oe=prepare_inputs(data[data_cats])\n\nX_train_enc=oe.transform(X_train[data_cats])\nX_test_enc=oe.transform(X_test[data_cats])\n\n# there is 2 unknown new Policy_Sales_Channel values in test 141 and 142\n# we replace them with 140\n\ntest_df.loc[test_df['Policy_Sales_Channel']==141.0, 'Policy_Sales_Channel']=140.0\ntest_df.loc[test_df['Policy_Sales_Channel']==142.0, 'Policy_Sales_Channel']=140.0\n\ntest_df_enc=oe.transform(test_df[data_cats])\n","a92f2899":"all_train_enc=np.concatenate((X_train_enc, X_train[data_nums].values), axis=1)\nall_test_enc=np.concatenate((X_test_enc, X_test[data_nums].values), axis=1)\n\nall_test_df_enc=np.concatenate((test_df_enc, test_df[data_nums].values), axis=1)","b8fd60ce":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, mutual_info_classif\n\n# chi2 for categorical variables\n# mutual_info_classif for mixed variables\n   \nfs = SelectKBest(score_func=mutual_info_classif, k='all')\nfs.fit(all_train_enc, y_train)\nX_train_fs = fs.transform(all_train_enc)\n\n\n\nfor i in range(len(fs.scores_)):\n    print('%s: %f' % (data_all[i], fs.scores_[i]))\n\nplt.figure(figsize=(18,8))\nsns.barplot(data_all, fs.scores_, orient='v')\nplt.title('Categorical Feature Selection with mutual_info_classif')\nplt.show()","750d2608":"from imblearn.over_sampling import RandomOverSampler \nfrom imblearn.over_sampling import ADASYN\n\n#ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n#all_train_enc_over_sampled, y_train_over_sampled = ros.fit_resample(all_train_enc, y_train)\n\nada = ADASYN(random_state=42)\nall_train_enc_over_sampled, y_train_over_sampled = ada.fit_resample(all_train_enc, y_train)\n\ny_train=y_train_over_sampled","57ed1831":"import plotly.express as px\nfrom sklearn.decomposition import PCA\nn_components = 2\n\npca = PCA(n_components=n_components)\ncomponents = pca.fit_transform(all_train_enc_over_sampled)\n\ntotal_var = pca.explained_variance_ratio_.sum() * 100\n\n\nfig = px.scatter(components, x=0, y=1, color=y_train, title=f'Total Explained Variance: {total_var:.2f}%',)\nfig.show()\n","69d1b85e":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\nscaler.fit(all_train_enc)\nX_train_transformed = scaler.transform(all_train_enc_over_sampled)\nX_test_transformed = scaler.transform(all_test_enc)\nall_test_df_transformed = scaler.transform(all_test_df_enc)","6bd860a3":"from collections import Counter \n\n#calculate class weight for XGBoost\ncounter = Counter(y_train)\nweight_estimate = counter[0] \/ counter[1]\nprint('Estimate: %.3f' % weight_estimate)\n# this is mainly for scale_pos_weight in xgboost since it's not support class_weight='balanced' like option\n# weights is manual in xgboost\n# eg. xgtest=XGBClassifier(random_state=55,  scale_pos_weight=weight_estimate)","4dfd8ca3":"rf=RandomForestClassifier(random_state=55, n_jobs=-1)\nlr=LogisticRegression(random_state=55, n_jobs=-1)\nsv = SVC(probability=True,random_state=55,)\nlogreg = LogisticRegression(solver='newton-cg',random_state=55, n_jobs=-1) \ngb = GradientBoostingClassifier(random_state=55)\ngnb = GaussianNB()\nxgb = XGBClassifier(random_state=55, nthread=-1)","26e179f0":"models=[rf, lr, logreg, gb, gnb, xgb]\ncv = StratifiedKFold(5, shuffle=True, random_state=42)","0bb55b0d":"model_results = pd.DataFrame()\nrow_number = 0\nresults = []\nnames = []\n\nfor ml in models:\n    model_name=ml.__class__.__name__\n    print('Training %s model ' % model_name)\n    cv_results = cross_validate(ml, X_train_transformed, y_train, cv=cv, scoring='roc_auc', return_train_score=True, n_jobs=-1 )\n    model_results.loc[row_number,'Model Name']=model_name\n    model_results.loc[row_number, 'Train roc_auc  Mean']=cv_results['train_score'].mean()\n    model_results.loc[row_number, 'Test roc_auc  Mean']=cv_results['test_score'].mean()\n    model_results.loc[row_number, 'Fit Time Mean']=cv_results['fit_time'].mean()\n    results.append(cv_results)\n    names.append(model_name)\n    \n    row_number+=1","5063e8b2":"cv_results_array = []\nfor tt in results:\n    cv_results_array.append(tt['test_score'])\n\nfig = plt.figure(figsize=(18, 6))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(cv_results_array)\nax.set_xticklabels(names)\nplt.show()","fa4d5275":"display(model_results.style.background_gradient(cmap='summer_r'))","983f1760":"eval_set = [(X_train_transformed, y_train), (X_test_transformed,y_test)]\nxgtest=XGBClassifier(random_state=55, nthread=-1)\nxgtest.fit(X_train_transformed, y_train, eval_metric=[\"auc\", \"logloss\", \"error\"], eval_set=eval_set, verbose=False)","2734fa2f":"y_scores=xgtest.predict(X_test_transformed)\nroc_auc_score(y_test, y_scores)","9c72548c":"from matplotlib import pyplot\nresults = xgtest.evals_result()\nepochs = len(results['validation_0']['error'])\nx_axis = range(0, epochs)\n# plot log loss\nfig, ax = pyplot.subplots()\nax.plot(x_axis, results['validation_0']['logloss'], label='Train')\nax.plot(x_axis, results['validation_1']['logloss'], label='Test')\nax.legend()\npyplot.ylabel('Log Loss')\npyplot.title('XGBoost Log Loss')\npyplot.show()\n# plot classification error\nfig, ax = pyplot.subplots()\nax.plot(x_axis, results['validation_0']['error'], label='Train')\nax.plot(x_axis, results['validation_1']['error'], label='Test')\nax.legend()\npyplot.ylabel('Classification Error')\npyplot.title('XGBoost Classification Error')\n# plot auc\nfig, ax = pyplot.subplots()\nax.plot(x_axis, results['validation_0']['auc'], label='Train')\nax.plot(x_axis, results['validation_1']['auc'], label='Test')\nax.legend()\npyplot.ylabel('AUC')\npyplot.title('XGBoost AUC Score')\npyplot.show()","5efce168":"gb_proba=xgtest.predict_proba(X_test_transformed)[:,1]","d8adb5e7":"fpr, tpr, thresholds  = roc_curve(y_test, gb_proba)\n\n\nplt.title('XGBoost ROC curve')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', format(round(auc(fpr,tpr),5)))","72b6db9c":"from yellowbrick.classifier import ClassificationReport\n\n\ndef view_report(model,X,y):\n    visualizer = ClassificationReport(\n        model, classes=['0', '1'],\n        cmap=\"YlGn\", size=(600, 360)\n    )\n    visualizer.fit(X,y)\n    visualizer.score(X,y)\n    visualizer.show()\n","abd4bd0f":"model = xgtest\nview_report(model,X_train_transformed, y_train)","bcf5f847":"from yellowbrick.classifier import ClassPredictionError\n\ndef show_errors(model, X_train,y_train,X_test,y_test):\n    classes=['Not Responded','Responded']\n    visualizer = ClassPredictionError(model)\n\n    visualizer.fit(X_train, y_train)\n    visualizer.score(X_test, y_test)\n    visualizer.show()","913b636e":"model = xgtest\nshow_errors(model, X_train_transformed, y_train,X_test_transformed,y_test)","bca76184":"from yellowbrick.classifier import DiscriminationThreshold\n\nmodel = xgtest\n\nvisualizer = DiscriminationThreshold(model, n_trials=1,excludestr=['queue_rate'],random_state=55)\nvisualizer.fit(X_train_transformed, y_train)\nvisualizer.show()","c128f595":"tt=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/sample_submission.csv')\nid=tt.id","c42a64b2":"best_model=XGBClassifier(random_state=55)\nbest_model.fit(X_train_transformed, y_train)","ad890af7":"preds=best_model.predict_proba(all_test_df_transformed)[:,1]","108e8a0e":"submission = pd.DataFrame(data = {'id': id, 'Response': preds})\nsubmission.to_csv('vehicle_insurance.csv', index = False)\nsubmission.head()","407f3b78":"# **Submission**","24bc37bc":"# **Missing Values**","4098614d":"SelectKBest score functions:\n\nFor Regression: f_regression, mutual_info_regression<br>\nFor Classification: chi2, f_classif, mutual_info_classif <p>\n    \nChi2 in general for categorical variables. We use mutual_info_classif which is suitable for mixed variables not just categorical or numerical ones \ud83d\udc4d <br>\nHere we see adding age groups as new feature doest not bring any improvements. Age and Ageclass have same feature importance \ud83d\ude12\nDepending of the kscores we can drop some non useful features form dataset for example vintage here is the lowers k-score we may drop it if we want.\n","682cd24c":"## **Class Prediction Error**\n\nThe Yellowbrick ClassPredictionError plot is a twist on other and sometimes more familiar classification model diagnostic tools like the Confusion Matrix and Classification Report. Like the Classification Report, this plot shows the support (number of training samples) for each class in the fitted classification model as a stacked bar chart. Each bar is segmented to show the proportion of predictions (including false negatives and false positives, like a Confusion Matrix) for each class. <p>\n    \n    \n[https:\/\/www.scikit-yb.org\/en\/latest\/api\/classifier\/class_prediction_error.html](https:\/\/www.scikit-yb.org\/en\/latest\/api\/classifier\/class_prediction_error.html)\n","6fe57274":"Let's also see xgb eval metrics here","3ea61c5b":"Some Age ranges have more interest in Vehicle insurance. So, it will be better to group ages regarding to above distributions","85d4d11f":"## **Classification Report**\n\nThe classification report visualizer displays the precision, recall, F1, and support scores for the model. In order to support easier interpretation and problem detection, the report integrates numerical scores with a color-coded heatmap. All heatmaps are in the range (0.0, 1.0) to facilitate easy comparison of classification models across different classification reports.<p>\n    \n[https:\/\/www.scikit-yb.org\/en\/latest\/api\/classifier\/classification_report.html](https:\/\/www.scikit-yb.org\/en\/latest\/api\/classifier\/classification_report.html)","e9f9f774":"# **Select Features**","2e6f1554":"# **Insights of Best Model**\n\nAnalyze internals of best model. **XGBoost** in this case.","baa1cfdb":"# **Scale Values**","eb045652":"# **Models**","fa4e046a":"# **Visualize**","cd8e33ef":"# **Target Variable**\n\n**Respone** is our target variable where 1 means customers interested in vehichle insurance or 0 when not interested. \nSo this is a classification task. Also when we look at the target distribution it's clear that we have imbalance between labels.\nWe can try to up or down sample data for increasing accuracy. <p>\n\n\nOversampling and undersampling in data analysis are techniques used to adjust the class distribution of a data set (i.e. the ratio between the different classes\/categories represented). These terms are used both in statistical sampling, survey design methodology and in machine learning.<p>\nReference: [https:\/\/en.wikipedia.org\/wiki\/Oversampling_and_undersampling_in_data_analysis](https:\/\/en.wikipedia.org\/wiki\/Oversampling_and_undersampling_in_data_analysis)","d1327fcc":"# **Features Cat vs Num**\n\nLet's decide which features are categorical and numeric. This will be later used for encoding purposes.","2b6c9875":"# **Gender**\n\nGender distribution in data looks balanced.","dff2f1b2":"# **OverSampling**","cc2ce4bc":"# **Age Groups**\n\nLet's see if Age has any effects on response target variable.","7667ba37":"# **Run Models**\n\n","f126ef34":"# **Helper Functions**","2c86c6bc":"# **ROC Curve**\n\nA receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was developed for operators of military radar receivers, which is why it is so named.The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection in machine learning. The false-positive rate is also known as probability of false alarm and can be calculated as (1 \u2212 specificity). <p>\n    \n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/3\/36\/ROC_space-2.png\" width=\"500px\">\n\nReference: [https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic)","6c5bcb39":"**RandomForest Classifier** looks overfit so XGBoost looks better","9e050a17":"# **Health Insurance Cross Sell Prediction**\n\nVehicle insurance (also known as car insurance, motor insurance, or auto insurance) is insurance for cars, trucks, motorcycles, and other road vehicles. Its primary use is to provide financial protection against physical damage or bodily injury resulting from traffic collisions and against liability that could also arise from incidents in a vehicle. Vehicle insurance may additionally offer financial protection against theft of the vehicle, and against damage to the vehicle sustained from events other than traffic collisions, such as keying, weather or natural disasters, and damage sustained by colliding with stationary objects. The specific terms of vehicle insurance vary with legal regulations in each region.<p>\n \nReference: [https:\/\/en.wikipedia.org\/wiki\/Vehicle_insurance](https:\/\/en.wikipedia.org\/wiki\/Vehicle_insurance)\n    \n    \nOur goal is to build a model from Health insurance customer data to predict whether they interest in purchasing vehicle insurance policy.\n[https:\/\/www.kaggle.com\/anmolkumar\/health-insurance-cross-sell-prediction](https:\/\/www.kaggle.com\/anmolkumar\/health-insurance-cross-sell-prediction) <p>","2798c794":"# **Age vs Vehicle Damage**\n\nOlder people having more damaged cars.","2ec62497":"# **Outlier Detection**\n\nIn statistics, an outlier is a data point that differs significantly from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set. An outlier can cause serious problems in statistical analyses. Reference: [https:\/\/en.wikipedia.org\/wiki\/Outlier](https:\/\/en.wikipedia.org\/wiki\/Outlier)\n\n<p>\n    \nThe interquartile range (IQR) is often used to find outliers in data. Outliers here are defined as observations that fall below Q1 \u2212 1.5 IQR or above Q3 + 1.5 IQR. In a boxplot, the highest and lowest occurring value within this limit are indicated by whiskers of the box (frequently with an additional bar at the end of the whisker) and any outliers as individual points. Reference: [https:\/\/en.wikipedia.org\/wiki\/Interquartile_range#Outliers](https:\/\/en.wikipedia.org\/wiki\/Interquartile_range#Outliers) <p>\n\n![https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/1a\/Boxplot_vs_PDF.svg](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/1a\/Boxplot_vs_PDF.svg)\n","f162b291":"# **Train Test Split**\n\nWe split data into 33% test and rest for training.","d4ca0ae3":"## **Discrimination Threshold**\n\nA visualization of precision, recall, f1 score, and queue rate with respect to the discrimination threshold of a binary classifier. The discrimination threshold is the probability or score at which the positive class is chosen over the negative class. Generally, this is set to 50% but the threshold can be adjusted to increase or decrease the sensitivity to false positives or to other application factors.<p>\n    \n[https:\/\/www.scikit-yb.org\/en\/latest\/api\/classifier\/threshold.html](https:\/\/www.scikit-yb.org\/en\/latest\/api\/classifier\/threshold.html)","804cc761":"# **Encode Categorical Values**\n\n**OrdinalEncoder\/LabelEncoder:** When order is important for categorical variables, it's important to use sklearn OrdinalEncoder or LabelEncoder. eg. cold, warm, hot <p>\n**One Hot Encoding:** When order is NOT important we can use sklearn OneHotEncoder or pandas get_dummies function. eg. Gender is an example Female,Male<p>\n    \n\nThere is two rows in test data which has different Policy Sales Channel not exists in train data. It's 141 and 142. Just 2 of them so we replace them with 140.\n\n"}}