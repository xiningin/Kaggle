{"cell_type":{"695e8d9b":"code","869f947f":"code","c1931fc1":"code","6f6346bd":"code","1d40b1aa":"code","7e16df61":"code","3ae15d70":"code","ca52c475":"code","cea2b3fb":"code","b289de5a":"code","08ba9ae0":"code","b51e9bd9":"code","19d5738d":"code","1ac66e7d":"code","8249c025":"code","f20c3498":"code","52337b1b":"code","9830f73f":"code","fb97951c":"code","b2738f1c":"code","41147871":"code","770bc314":"code","9006d939":"code","450263a0":"code","3aabe94c":"code","5dbfb105":"code","fd2e0c48":"code","02871ab5":"code","aa62ca7a":"code","358111c6":"code","d30887c8":"code","ce539dc9":"code","4b715549":"code","2c1cb4c9":"code","30dfc5a0":"code","cbf31ad8":"code","13ea53ab":"code","7bbc022c":"code","fa681d5c":"code","1690773a":"code","b921f61b":"code","7ebc2bb4":"code","9d32c53c":"code","a5a80415":"code","dfe6be57":"code","da2d4e8f":"code","3f882744":"markdown","75f91531":"markdown","2d481786":"markdown","53228956":"markdown","6b5b8036":"markdown"},"source":{"695e8d9b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","869f947f":"df=pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf_o2=pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/o2Saturation.csv')","c1931fc1":"df.head()","6f6346bd":"df.info()","1d40b1aa":"df.isna().sum()","7e16df61":"df[df.duplicated()]\n","3ae15d70":"df.drop_duplicates(inplace=True)","ca52c475":"df.describe()","cea2b3fb":"sns.countplot(df['slp'])","b289de5a":"sns.countplot(df['caa'])","08ba9ae0":"sns.countplot(df['slp'])","b51e9bd9":"sns.countplot(df['exng'])","19d5738d":"sns.countplot(df['thall'])","1ac66e7d":"sns.displot(df['thalachh'])","8249c025":"sns.countplot(df['fbs'])","f20c3498":"sns.countplot(df['restecg'])","52337b1b":"sns.distplot(df['chol'])","9830f73f":"sns.distplot(df['trtbps'])","fb97951c":"sns.distplot(df['age'])","b2738f1c":"sns.countplot(df['sex'],hue=df['output'])","41147871":"sns.countplot(df['cp'])","770bc314":"sns.countplot(df['exng'],hue=df['output'])","9006d939":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize = (15, 8))\nsns.scatterplot(data=df,x='thalachh',y='chol' ,hue='output')","450263a0":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize = (15, 8))\nsns.scatterplot(data=df,x='thalachh',y='age' ,hue='output')","3aabe94c":"labels=['less chance of heart attack','more chance of heart attack']\ncolors = [\"cyan\",\"red\"]\nplt.pie(df['output'].value_counts(),labels=labels,colors=colors,\n        autopct='%1.2f%%', shadow=True, startangle=140) \nplt.show()","5dbfb105":"sns.countplot(df['cp'],hue=df['output'])","fd2e0c48":"plt.figure(figsize=(15,8))\nsns.displot(df, x=\"trtbps\", hue=\"output\", element=\"step\")","02871ab5":"plt.figure(figsize=(15,8))\nsns.displot(df, x=\"chol\", hue=\"output\", element=\"step\")","aa62ca7a":"plt.figure(figsize=(15,8))\nsns.displot(df, x=\"thalachh\", hue=\"output\", element=\"step\")","358111c6":"plt.figure(figsize=(15,8))\nsns.countplot(df[\"slp\"], hue=df[\"output\"])","d30887c8":"plt.figure(figsize=(15,8))\nsns.swarmplot(x=df['caa'],y=df['age'],hue=df['output'])","ce539dc9":"plt.figure(figsize=(15,8))\nsns.countplot(df['restecg'],hue=df['output'])","4b715549":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True)","2c1cb4c9":"summary_df = df[['exng','caa','cp','restecg','fbs','sex','output']]\nsummary = pd.concat([pd.crosstab(summary_df[x], summary_df.output) for x in summary_df.columns[:-1]], keys=summary_df.columns[:-1])\nsummary","30dfc5a0":"X=df.drop('output',axis=1)\ny=df['output']","cbf31ad8":"from sklearn import preprocessing\nnorm = preprocessing.StandardScaler()\nndf=norm.fit_transform(X)\nX = pd.DataFrame(ndf, index=X.index, columns=X.columns)\nX.head(10)","13ea53ab":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)","7bbc022c":"import lightgbm as lgb\nclf = lgb.LGBMClassifier(class_weight='balanced',drop_rate=0.8, min_data_in_leaf=10, \n                                 n_estimators=250,min_sum_hessian_in_leaf=5,importance_type='gain',\n                         learning_rate=0.09,bagging_fraction = 0.9,objective='binary',\n                         boosting_type='goss',metric='auc',colsample_bytree=0.8,feature_fraction = 0.1,\n                         reg_alpha = 5,reg_lambda = 5,max_depth = 8,\n                                 min_child_samples = 55,min_child_weight = 5.0,min_split_gain = 0.01,\n                         num_leaves = 70,subsample = 1,random_state=42)  \nclf.fit(X_train,y_train)","fa681d5c":"y_predict=clf.predict(X_test)\nprint(classification_report(y_test, y_predict))","1690773a":"print(roc_auc_score(y_test,y_predict))\nprint(plot_confusion_matrix(clf,X_test,y_test))","b921f61b":"feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(15, 8))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()","7ebc2bb4":"from catboost import CatBoostClassifier\ncatboost_params = {'loss_function' : 'CrossEntropy',\n            'iterations': 100,\n            'depth': 5,\n            'learning_rate': 0.01,\n            'eval_metric': 'AUC',\n            'random_seed': 42,\n            'l2_leaf_reg': 50.0,\n            'bagging_temperature': 0.5,\n            'allow_writing_files': True, 'border_count':50\n        }\nmodel = CatBoostClassifier(**catboost_params)\nmodel.fit(X_train, y_train,verbose=False)","9d32c53c":"y_predict=model.predict(X_test)\nprint(classification_report(y_test, y_predict))","a5a80415":"print(roc_auc_score(y_test,y_predict))\nprint(plot_confusion_matrix(model,X_test,y_test))","dfe6be57":"def plot_feature_importance(importance,names,model_type):\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n    plt.figure(figsize=(15,8))\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    plt.title('FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')","da2d4e8f":"plot_feature_importance(model.get_feature_importance(),X_train.columns,'CATBOOST')","3f882744":"Based on the visual analysis, we can immediately see the distribution of our data, the relationships. However, it is worth noting that there is a relationship between age and the number of large vessels, and the actual heart problems. You can also see that pressure also plays an important role (the higher the pressure, the worse, of course). It can also be seen that if a patient's ECG shows ST wave abnormality, this significantly increases the risks. You can also see that there is a tendency to increase blood pressure with age and cholesterol levels","75f91531":"Both models showed their good side. Personally, I would prefer the CatBoost model, as it better identifies sick people. It is also worth noting what features are important for a particular model. For the LightGBM model, these are ca, old peak, cholesterol, and cp. For CatBoost, it's already thall, cap, and sternum pain. Upvote :)","2d481786":"Let's start building models. I chose 2 models: LightGBM and Catboost. I focused primarily on the interpretability of the results. For this purpose, in addition to various metrics, graphs of the significance of the features were constructed. The importance of signs in medical tasks is important for early identification of patients. The idea is simple: Randomly rearrange or shuffle one column in the validation dataset set, leaving all the other columns intact. A feature is considered \"important\" if the model's accuracy drops and its change causes an increase in errors. On the other hand, a feature is considered \"unimportant\" if the shuffling of its values does not affect the accuracy of the model.","53228956":"![\u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435.png](attachment:bd43915f-e962-4e08-89dd-c901a9a7eb28.png)","6b5b8036":"In this task, we have 14 variables: Target and many different features that reflect the health of the heart and body (angina, blood sugar, age, blood cholesterol, blood pressure, etc.). We have no missing values and only 1 duplicate, which we will immediately delete. Let's do a visual analysis right away. All conclusions are below"}}