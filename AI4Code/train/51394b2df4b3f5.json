{"cell_type":{"7885c1da":"code","cc9ec979":"code","acca14ac":"code","3bc373d2":"code","dd290f73":"code","8f194e5e":"code","4036f723":"code","c7beb172":"code","0dae7647":"code","f3cb39ea":"code","47ebbcd6":"code","40ed1fb5":"code","73ad38db":"code","a4ed6626":"markdown","aab25a84":"markdown","07c982f4":"markdown","7a13eeab":"markdown","a6de3152":"markdown","429e4c2c":"markdown"},"source":{"7885c1da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport tensorflow as tf\n# import model \nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras.models import Sequential \nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n# Create a list with the filepaths for training and testing\n\ntrain_dir = Path('..\/input\/fruits\/fruits-360\/Training')\ntrain_filepaths = list(train_dir.glob(r'**\/*.jpg'))\n\ntest_dir = Path('..\/input\/fruits\/fruits-360\/Test')\ntest_filepaths = list(test_dir.glob(r'**\/*.jpg'))","cc9ec979":"def proc_img(filepath):\n    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n\n    labels = [str(filepath[i]).split(\"\/\")[-2] \\\n              for i in range(len(filepath))]\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df\n\ntrain_df = proc_img(train_filepaths)\ntest_df = proc_img(test_filepaths)\n\nprint(f'Number of pictures: {train_df.shape[0]}\\n')\nprint(f'Number of different labels: {len(train_df.Label.unique())}\\n')\nprint(f'Labels: {train_df.Label.unique()}')\n\n# The DataFrame with the filepaths in one column and the labels in the other one\ntrain_df.head(5)","acca14ac":"# Create a DataFrame with one Label of each category\ndf_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display some pictures of the dataset\nfig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i], fontsize = 12)\nplt.tight_layout(pad=0.5)\nplt.show()","3bc373d2":"train_datagen = ImageDataGenerator(rescale= 1.\/255,\n                validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1\/255.)\n\n\ntrain_generator  = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(32, 32),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    subset='training',\n    seed=0\n)\n\nvalidation_generator  = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(32, 32),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False,\n    subset='validation',\n    seed=0\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(32, 32),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False,\n    seed=0\n)","dd290f73":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity","8f194e5e":"\ndef identity_block(X, f, filters, training=True, initializer=random_uniform):\n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE\n    ## Second component of main path (\u22483 lines)\n    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n\n    ## Third component of main path (\u22482 lines)\n    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    \n    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (\u22482 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X) \n    ### END CODE HERE\n\n    return X","4036f723":"def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n    # f is the shape of the convol filter\n    \n    # Retrieve Filters: amount of filters \n    F1, F2, F3 = filters\n    \n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    \n    # First component of main path glorot_uniform(seed=0)\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X)\n\n    ### START CODE HERE\n    \n    ## Second component of main path (\u22483 lines)\n    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X)\n\n    ## Third component of main path (\u22482 lines)\n    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    \n    ##### SHORTCUT PATH ##### (\u22482 lines)\n    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n    \n    ### END CODE HERE\n\n    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","c7beb172":"def ResNet(input_shape = (32, 32, 3), classes = 131):\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [32, 32, 64], s = 1)\n    X = identity_block(X, 3, [32, 32, 64])\n    X = identity_block(X, 3, [32, 32, 64])\n\n    ## Stage 3 \n    X = convolutional_block(X, f = 3, filters =  [64, 64, 128], s = 2)\n    X = identity_block(X, 3,  [64, 64, 128])\n    X = identity_block(X, 3,  [64, 64, 128])\n    X = identity_block(X, 3,  [64, 64, 128])\n    \n     ## Stage 4 \n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n    X = identity_block(X, 3, [128, 128, 512])\n    X = identity_block(X, 3, [128, 128, 512])\n    X = identity_block(X, 3, [128, 128, 512])\n\n    ## AVGPOOL \n    X = AveragePooling2D(pool_size=(2, 2) )(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X)\n\n    return model\n","0dae7647":"model = ResNet(input_shape = (32, 32, 3), classes = 131)\nprint(model.summary())","f3cb39ea":"model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy', metrics='accuracy')","47ebbcd6":"epochs = 20  \nbatch_size= 32\ntrain_steps = train_generator.n\/\/train_generator.batch_size\nvalidation_steps = validation_generator.n\/\/validation_generator.batch_size\nresnet_model = model.fit_generator(\n                generator = train_generator,\n                steps_per_epoch =train_steps,\n                epochs=epochs,\n                validation_data = validation_generator,\n                validation_steps = validation_steps)","40ed1fb5":"plt.figure()\nplt.plot(resnet_model.history[\"accuracy\"],label = \"Train Accuracy\", color = \"black\")\nplt.plot(resnet_model.history[\"val_accuracy\"],label = \"Validation Accuracy\", color = \"darkred\", linestyle=\"dashed\",markeredgecolor = \"purple\", markeredgewidth = 2)\nplt.title(\"Model Accuracy\", color = \"darkred\", size = 13)\nplt.legend()\nplt.show()","73ad38db":"STEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\nresnet_model_test = model.evaluate_generator(test_generator, steps=STEP_SIZE_TEST, verbose=1)","a4ed6626":"# Create Model: Resnet","aab25a84":"# Create Identity Block","07c982f4":"# Accuracy Plot","7a13eeab":"# Test Model","a6de3152":"# Train Model","429e4c2c":"# Create Convolutional Block"}}