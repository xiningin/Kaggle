{"cell_type":{"381b4aab":"code","c64f6465":"code","72f361dc":"code","6fe1c3ed":"code","9a96e2a0":"code","200b36c8":"code","031eed60":"code","0606ba99":"code","67fd2f7b":"code","78681d69":"code","a7ef6e74":"code","2fb86a88":"code","2b83a37a":"code","67042040":"code","c3e2cbd2":"code","972992d6":"code","fce95f6b":"code","e3443186":"code","5c90e00a":"code","76f549a2":"code","c7e099ea":"code","65dfc3f9":"code","1c2fd693":"code","56fb46db":"code","46e1ff1d":"code","324c3ce9":"code","2a8577bf":"code","e5f8266a":"code","e66a49b6":"code","489ac66c":"code","4672a0d1":"code","c81b9ea4":"code","6c8ef5ad":"code","50181777":"code","3d313e78":"code","d536ea03":"code","3307d30c":"code","a3e3e286":"code","22160a25":"code","3d5cdbb7":"code","30cceb0d":"code","78c9192f":"code","1a363d66":"code","c925469b":"code","d82722fb":"code","75a6a162":"code","2aeab1b8":"code","1de30e2a":"code","fa29dc2c":"code","406ecafa":"code","cb7f2379":"code","07b11e78":"code","a1912c57":"code","039922a6":"code","bd6d8691":"code","569cef09":"code","fd20d876":"code","cfea16ed":"code","d631b300":"code","750307e7":"code","ead897f7":"code","d2fc989b":"code","2fdfc8c8":"code","54693b2a":"code","9860fcf3":"code","de35c243":"code","cc89aa78":"code","51bd92a1":"code","b394d0ba":"code","77d71401":"code","c5603ef8":"markdown","29577a61":"markdown","2a3e9142":"markdown","ac1ad6ef":"markdown","509c1057":"markdown","f903e61b":"markdown","9fd85c7c":"markdown","c22b3438":"markdown","d9b0d59c":"markdown","63b61c5b":"markdown","83b9f899":"markdown","450830e7":"markdown","b76063ea":"markdown","570c36a3":"markdown","b1a6693c":"markdown"},"source":{"381b4aab":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport datetime\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn import preprocessing\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\nsns.set_style('whitegrid')\n%matplotlib inline\n\n#VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom patsy import dmatrices\n\n#Modelling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost\n\nfrom sklearn.tree import export_graphviz #plot tree\nfrom subprocess import call\n\n#Neural Nets\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.preprocessing import text, sequence\nfrom keras import layers, models, optimizers\n# Evaluation metrics\nfrom sklearn import metrics ","c64f6465":"#data = pd.read_csv('\/media\/vishwadeepg\/New Volume\/Work\/0. Gauty\/Kernal\/heart_disease\/heart.csv')\ndata = pd.read_csv('..\/input\/heart.csv')","72f361dc":"data.shape","6fe1c3ed":"data.info()","9a96e2a0":"data.describe().T","200b36c8":"data.dtypes.value_counts()","031eed60":"data.columns","0606ba99":"data.head()","67fd2f7b":"def missing_check(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) \n    #print(\"Missing check:\",missing_data )\n    return missing_data\n","78681d69":"missing_check(data)","a7ef6e74":"print(data['target'].value_counts())\nax = sns.countplot(x=data['target'], data=data)","2fb86a88":"data['age_bin'] = pd.cut(data.age,[29,30,35,40,45,50,55,60],labels=[30,35,40,45,50,55,60])\nprint(pd.DataFrame(data['age_bin'].value_counts()))\nax = sns.countplot(x=data['age_bin'], data=data)","2b83a37a":"print(pd.DataFrame(data['sex'].value_counts()))\nax = sns.countplot(x=data['sex'], data=data)","67042040":"print(pd.DataFrame(data['cp'].value_counts()))\nax = sns.countplot(x=data['cp'], data=data)","c3e2cbd2":"data['chol_bin'] = pd.cut(data.chol,[125,150,200,250,300,350,400,450,500,550,600],\n                              labels=[150,200,250,300,350,400,450,500,550,600])\nprint(pd.DataFrame(data['chol_bin'].value_counts()))\nax = sns.countplot(x=data['chol_bin'], data=data)","972992d6":"data['trestbps_bin'] = pd.cut(data.trestbps,[93,110,120,130,140,150,160,205],labels=[110,120,130,140,150,160,205])\nprint(pd.DataFrame(data['trestbps_bin'].value_counts()))\nax = sns.countplot(x=data['trestbps_bin'], data=data)","fce95f6b":"print(pd.DataFrame(data['fbs'].value_counts()))\nax = sns.countplot(x=data['fbs'], data=data)","e3443186":"print(pd.DataFrame(data['restecg'].value_counts()))\nax = sns.countplot(x=data['restecg'], data=data)","5c90e00a":"data['thalach_bin'] = pd.cut(data.thalach,[70,90,110,130,150,170,180,200,203],labels=[90,110,130,150,170,180,200,203])\nprint(pd.DataFrame(data['thalach_bin'].value_counts()))\nax = sns.countplot(x=data['thalach_bin'], data=data)","76f549a2":"print(pd.DataFrame(data['exang'].value_counts()))\nax = sns.countplot(x=data['exang'], data=data)","c7e099ea":"data['oldpeak_bin']=pd.cut(data.oldpeak,[-0.1,0.0,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.25,2.5,6.5],\n                                    labels=[0.0,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.25,2.5,6.5])\nprint(pd.DataFrame(data['oldpeak_bin'].value_counts()))\nax = sns.countplot(x=data['oldpeak_bin'], data=data)","65dfc3f9":"print(pd.DataFrame(data['slope'].value_counts()))\nax = sns.countplot(x=data['slope'], data=data)","1c2fd693":"print(pd.DataFrame(data['ca'].value_counts()))\nax = sns.countplot(x=data['ca'], data=data)","56fb46db":"print(pd.DataFrame(data['thal'].value_counts()))\nax = sns.countplot(x=data['thal'], data=data)","46e1ff1d":"target_1 = data[data['target']==1]['age_bin'].value_counts()\ntarget_0 = data[data['target']==0]['age_bin'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","324c3ce9":"target_1 = data[data['target']==1]['sex'].value_counts()\ntarget_0 = data[data['target']==0]['sex'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","2a8577bf":"target_1 = data[data['target']==1]['cp'].value_counts()\ntarget_0 = data[data['target']==0]['cp'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","e5f8266a":"target_1 = data[data['target']==1]['trestbps_bin'].value_counts()\ntarget_0 = data[data['target']==0]['trestbps_bin'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","e66a49b6":"target_1 = data[data['target']==1]['chol_bin'].value_counts()\ntarget_0 = data[data['target']==0]['chol_bin'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","489ac66c":"target_1 = data[data['target']==1]['fbs'].value_counts()\ntarget_0 = data[data['target']==0]['fbs'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","4672a0d1":"target_1 = data[data['target']==1]['restecg'].value_counts()\ntarget_0 = data[data['target']==0]['restecg'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","c81b9ea4":"target_1 = data[data['target']==1]['thalach_bin'].value_counts()\ntarget_0 = data[data['target']==0]['thalach_bin'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","6c8ef5ad":"target_1 = data[data['target']==1]['exang'].value_counts()\ntarget_0 = data[data['target']==0]['exang'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","50181777":"target_1 = data[data['target']==1]['oldpeak_bin'].value_counts()\ntarget_0 = data[data['target']==0]['oldpeak_bin'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","3d313e78":"target_1 = data[data['target']==1]['slope'].value_counts()\ntarget_0 = data[data['target']==0]['slope'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","d536ea03":"target_1 = data[data['target']==1]['ca'].value_counts()\ntarget_0 = data[data['target']==0]['ca'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","3307d30c":"target_1 = data[data['target']==1]['thal'].value_counts()\ntarget_0 = data[data['target']==0]['thal'].value_counts()\ndf = pd.DataFrame([target_1, target_0])\ndf.index = ['target_1','target_0']\nprint(df)\nprint('------------------------------------------------------------------------------------------------------------------------')\ndf.plot(kind='bar',stacked=True, figsize=(10,6))","a3e3e286":"data.plot(kind=\"scatter\", x=\"age\", y=\"chol\", alpha= 0.5, color=\"g\", figsize=(12,8))","22160a25":"data.plot(kind=\"scatter\", x=\"age\", y=\"trestbps\", alpha= 0.5, color=\"r\", figsize=(12,8))","3d5cdbb7":"data.plot(kind=\"scatter\", x=\"age\", y=\"thalach\", alpha= 0.5, color=\"b\", figsize=(12,8))","30cceb0d":"data.plot(kind=\"scatter\", x=\"age\", y=\"oldpeak\", alpha= 0.5, color=\"m\", figsize=(12,8))","78c9192f":"data.groupby(['age_bin', 'chol_bin'])['target'].value_counts()","1a363d66":"data.groupby(['age_bin', 'sex'])['target'].value_counts()","c925469b":"data.groupby(['age_bin', 'trestbps_bin'])['target'].value_counts()","d82722fb":"data.groupby(['age_bin', 'fbs'])['target'].value_counts()","75a6a162":"data.groupby(['age_bin', 'restecg'])['target'].value_counts()","2aeab1b8":"data.groupby(['age_bin', 'thalach_bin'])['target'].value_counts()","1de30e2a":"data.groupby(['age_bin', 'exang'])['target'].value_counts()","fa29dc2c":"data.groupby(['age_bin', 'slope'])['target'].value_counts()","406ecafa":"data.groupby(['age_bin', 'ca'])['target'].value_counts()","cb7f2379":"data.groupby(['age_bin', 'thal'])['target'].value_counts()","07b11e78":"pd.DataFrame(data.groupby(['sex', 'fbs', 'exang', 'slope'])['target'].value_counts())","a1912c57":"data.chol.plot(kind=\"line\",color=\"green\",label=\"chol\",grid=True,linestyle=\":\", figsize= (20,10))\ndata.thalach.plot(kind=\"line\",color=\"purple\",label=\"thalach\",grid=True, figsize= (20,10))\ndata.age.plot(kind=\"line\",color=\"pink\",label=\"age\",grid=True, figsize= (20,10))\ndata.trestbps.plot(kind=\"line\",color=\"orange\",label=\"trestbps\",grid=True, figsize= (20,10))\nplt.legend(loc=\"upper right\") #legend: puts feature label into plot\nplt.xlabel(\"indexes\")\nplt.ylabel(\"Features\")\nplt.title(\"Heart Diseases\")\nplt.show()","039922a6":"sns.pairplot(data.loc[:,[\"chol\",\"age\",\"ca\",\"oldpeak\"]])\nplt.show()","bd6d8691":"data_corr = data.corr()['target'][:-1] # -1 because the latest row is Target\ngolden_features_list = data_corr[abs(data_corr) > 0.1].sort_values(ascending=False)\nprint(\"There is {} strongly correlated values with Target:\\n{}\".format(len(golden_features_list), golden_features_list))","569cef09":"corr = data.corr() \nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.1) | (corr <= -0.1)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","fd20d876":"def detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n#Outliers_to_drop = detect_outliers(train,2,[col])","cfea16ed":"def printContingencyTable(y_cv, Y_pred):\n    confusion_matrix = metrics.confusion_matrix(y_cv, Y_pred)\n    plt.matshow(confusion_matrix)\n    plt.title('Confusion matrix')\n    plt.colorbar()\n    plt.ylabel('Churned')\n    plt.xlabel('Predicted')\n    plt.show()\n    print(\"precision_score : \", metrics.precision_score(y_cv, Y_pred))\n    print(\"recall_score : \", metrics.recall_score(y_cv, Y_pred))\n    print(\"f1_score : \", metrics.f1_score(y_cv, Y_pred))\n    print(confusion_matrix)","d631b300":"data = data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']]","750307e7":"Y = data['target']\nX = data.drop(['target'], axis=1)\n\ntrain_x, X_cv, train_y, y_cv = train_test_split(X, Y, test_size=0.30, random_state=42)","ead897f7":"logreg = LogisticRegression()\nlogreg.fit(train_x, train_y)\nY_pred = logreg.predict(X_cv)\n\nprintContingencyTable(y_cv, Y_pred)","d2fc989b":"DT = DecisionTreeClassifier()\nDT.fit(train_x, train_y)\nY_pred = DT.predict(X_cv)\n\n\nprintContingencyTable(y_cv, Y_pred)","2fdfc8c8":"RF = RandomForestClassifier()\nRF.fit(train_x, train_y)\nY_pred = RF.predict(X_cv)\n\nprintContingencyTable(y_cv, Y_pred)","54693b2a":"\nestimator = RF.estimators_[1]\nfeature_names = [i for i in train_x.columns]\n\ny_train_str = train_y.astype('str')\ny_train_str[y_train_str == '0'] = 'no disease'\ny_train_str[y_train_str == '1'] = 'disease'\ny_train_str = y_train_str.values\n\nexport_graphviz(estimator, out_file='tree.dot', \n                feature_names = feature_names,\n                class_names = y_train_str,\n                rounded = True, proportion = True, \n                label='root',\n                precision = 2, filled = True)\n\n\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\nfrom IPython.display import Image\nImage(filename = 'tree.png')\n","9860fcf3":"GB = GradientBoostingClassifier()\nGB.fit(train_x, train_y)\nY_pred = GB.predict(X_cv)\n\nprintContingencyTable(y_cv, Y_pred)","de35c243":"et = ExtraTreesClassifier()\net.fit(train_x, train_y)\nY_pred = et.predict(X_cv)\n\nprintContingencyTable(y_cv, Y_pred)","cc89aa78":"adb = AdaBoostClassifier()\nadb.fit(train_x, train_y)\nY_pred = adb.predict(X_cv)\n\nprintContingencyTable(y_cv, Y_pred)","51bd92a1":"import lightgbm as lgbm\nparams = {\n    'objective' :'binary',\n    'learning_rate' : 0.02,\n    'num_leaves' : 76,\n    'feature_fraction': 0.64, \n    'bagging_fraction': 0.8, \n    'bagging_freq':1,\n    'boosting_type' : 'gbdt',\n    'metric': 'binary_logloss'\n}\nd_train = lgbm.Dataset(train_x, train_y)\nd_valid = lgbm.Dataset(X_cv, y_cv)\nbst = lgbm.train(params, d_train, 5000, valid_sets=[d_valid], verbose_eval=50, early_stopping_rounds=100)","b394d0ba":"prediction = bst.predict(X_cv)\n#convert into binary values\nfor i in range(0,len(prediction)):\n    if prediction[i]>=.5:\n        prediction[i]=1\n    else:  \n        prediction[i]=0\n\nprintContingencyTable(y_cv,prediction)","77d71401":"xgb = xgboost.XGBClassifier()\nxgb.fit(train_x, train_y)\nY_pred = xgb.predict(X_cv)\n\nprintContingencyTable(y_cv, Y_pred)","c5603ef8":"\n> 1. age \n> 2. sex \n> 3. cp: chest pain type (4 values) \n> 4. trestbps: resting blood pressure \n> 5. chol: serum cholestoral in mg\/dl \n> 6. fbs: fasting blood sugar > 120 mg\/dl\n> 7. restecg: resting electrocardiographic results (values 0,1,2)\n> 8. thalach: maximum heart rate achieved \n> 9. exang: exercise induced angina \n> 10. oldpeak: ST depression induced by exercise relative to rest \n> 11. slope: the slope of the peak exercise ST segment \n> 12. number of major vessels (0-3) colored by flourosopy \n> 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n>14. target","29577a61":"__DecisionTreeClassifier__","2a3e9142":"__Bagging: Random Forest Classifier__","ac1ad6ef":"__Boosting: GradientBoostingClassifier__","509c1057":"### The features described in the below data set are:\n\n1. Count tells us the number of NoN-empty rows in a feature.\n\n2. Mean tells us the mean value of that feature.\n\n3. Std tells us the Standard Deviation Value of that feature.\n\n4. Min tells us the minimum value of that feature.\n\n5. 25%, 50%, and 75% are the percentile\/quartile of each features.\n\n6. Max tells us the maximum value of that feature.","f903e61b":"## outliers","9fd85c7c":"## Bivariate Analysis","c22b3438":"__LightBGM___","d9b0d59c":"## Attribute Information: ","63b61c5b":"## Misasing Value","83b9f899":"__XGBClassifier__","450830e7":"__ExtraTreesClassifier__","b76063ea":"__AdaBoostClassifier__","570c36a3":"## Univariate Analysis","b1a6693c":"__Logistic Regression__"}}