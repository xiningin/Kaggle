{"cell_type":{"c0cfe19d":"code","94e25764":"code","ba24ad44":"code","5c060cea":"code","52179258":"code","9ca3f014":"code","d70717ae":"code","803d7480":"code","0fd2a6ac":"code","edc8b977":"code","e5d5bc7a":"code","01b67464":"code","acb57bd8":"code","7f68cab5":"code","e9175f0b":"code","6d1b986d":"code","94072e83":"code","8e9abb88":"code","625c6237":"markdown","16150dfd":"markdown","38c0a2bd":"markdown","a57a066d":"markdown","b9d2c59d":"markdown","e58ef709":"markdown","5e2feec5":"markdown","3a879374":"markdown","7b0b07cf":"markdown","a032c12d":"markdown","4fafb273":"markdown","b450401e":"markdown","d34f4dbf":"markdown","1111b95b":"markdown","7e779805":"markdown","cd9b62b5":"markdown","c8eeef5a":"markdown","e31c104e":"markdown","7470827a":"markdown","b7404d3d":"markdown"},"source":{"c0cfe19d":"import pandas as pd                  #For data eploration.\nfrom bs4 import BeautifulSoup        #For scraping the website.\nimport requests                      #For sending the requests to the website.\nfrom nltk import word_tokenize       #For cleaning the text data.\nimport json                          #For reading json data\nfrom tqdm.notebook import tqdm       #For checking the loop timinngs.\nimport seaborn as sns                #For visualization.\nfrom matplotlib import pyplot as plt #For visualization.\nimport folium                        #For Map Visualization\nimport re                            #Regular Expression\nimport operator","94e25764":"headers = {'User-Agent': 'Mozilla\/5.0'}\nname_=[]  #For saving Restaurant's name\nonline_=[] #For saving Restaurant's \ntitle_=[]  #For saving Restaurant's type\narea_=[]   #For saving Restaurant's area\nrating_=[] #For saving Restaurant's rating\nvotes_=[]  #For saving Restaurant's votes\nadd_=[]    #For saving Restaurant's address\ncuisines_=[]#For saving Restaurant's cuisines\ncf2_=[]    #For saving Restaurant's cost for 2 persons\nhours_=[]  #For saving Restaurant's timings\nlink_=[]   #For saving Restaurant's web link\njson_=[]   #For saving Restaurant's json file\ndish_=[]   #For saving Restaurant's dish   \nprice_=[]  #For saving Restaurant'sdish price\ncontact_=[] #For saving Restaurant's Contact number\nurl='https:\/\/www.zomato.com\/lucknow\/restaurants?page='\nfor page in tqdm(range(1,265)):\n    print(f'{url}{page}')\n    r=requests.get(f'{url}{page}',headers=headers)\n    print(r)\n    soup=BeautifulSoup(r.text,'html.parser')\n    cards=soup.find_all(class_='card search-snippet-card search-card')\n    for card in cards:\n        try:\n            contact=card.find(class_='item res-snippet-ph-info')['data-phone-no-str']\n            contact_.append(contact)\n        except:\n            contact_.append(0)\n        try:\n          content=card.find(class_='content')\n          online=card.find('span',class_='fontsize4 bold action_btn_icon o2_closed_now')\n          if online:\n            online_.append('Delivery Available')\n          else:\n            online_.append('Delivery Not Available')\n        except:\n          online_.append('Delivery Not Available')\n        try:\n            title=content.find(class_='res-snippet-small-establishment mt5').find('a').getText()\n            title_.append(title)\n        except:\n            title_.append(0)\n        try:\n            name=content.find('a',class_='result-title hover_feedback zred bold ln24 fontsize0').getText()\n            name_.append(name)\n        except:\n            name_.append(0)\n        try:\n            area=content.find(class_='row').find(class_='row').find('a').find_next('a').find_next('a').getText()\n            area_.append(area)\n        except:\n            area_.append(0)\n        try:\n            rating=content.find(class_='row').find(class_='row').find(class_='ta-right floating search_result_rating col-s-4 clearfix').find('div').getText()\n            rating_.append(rating)\n        except:\n            rating_.appned(0)\n        try:\n            votes=content.find(class_='row').find(class_='row').find(class_='ta-right floating search_result_rating col-s-4 clearfix').find('span').getText()\n            votes_.append(votes)\n        except:\n            votes_.append(0)\n        try:\n            add=content.find(class_='row').find(class_='row').find_next(class_='row').find('div').getText()\n            add_.append(add)\n        except:\n            add_.append(0)\n        try:    \n            cuisines=content.find(class_='search-page-text clearfix row').find(class_='clearfix').find('span').find_next('span').getText()\n            cuisines_.append(cuisines)\n        except:\n            cuisines_.appned(0)\n        try:\n            cf2=content.find(class_='search-page-text clearfix row').find(class_='res-cost clearfix').find('span').find_next('span').getText()\n            cf2_.append(cf2)\n        except:\n            cf2_.append(0)\n        try:    \n            hours=content.find(class_='search-page-text clearfix row').find(class_='res-timing clearfix')('div')[0].getText()\n            hours_.append(hours)\n        except:\n            hours_.append(0)\n        try:\n            link=content.find('a',class_='result-title hover_feedback zred bold ln24 fontsize0')['href']\n            link_.append(link)\n        except:\n            link_.appned(0)\n        r=requests.get(f'{link}\/order',headers=headers)\n        soup=BeautifulSoup(r.text,'html.parser')\n        try:\n            _json=soup.find('script',type='application\/ld+json').find_next('script',type='application\/ld+json')\n            _json=_json.getText()\n            _json=json.loads(_json)\n            json_.append(_json)\n        except:\n            json_.append(0)\n        if online:\n            try:\n                    \n                dish=soup.find(id='root').find_all('h4')\n                l=[]\n                for i in dish:\n                    i=i.getText()\n                    l.append(i)\n                dish_.append(l)\n                price=soup.find_all('span',class_='sc-17hyc2s-1 fnhnBd')\n                l=[]\n                for i in price:\n                    i=i.getText()\n                    l.append(i)\n                price_.append(l)\n            except:\n                dish_.append(0)\n                price_.append(0)\n        else:\n            \n            dish_.append(0)\n            price_.append(0)","ba24ad44":"data={'Name':name_,'Contact':contact_,'Online':online_,'Title':title_,'Area':area_,'Rating':rating_,'Votes':votes_,'Add':add_,'Cuisines':cuisines_,'CF2':cf2_,'Hours':hours_,'Link':link_,'Json':json_,'Dish':dish_,'Price':price_}\ndf=pd.DataFrame(data)\ndf.to_csv('Zomato_LucknowLatest.csv')","5c060cea":"df=pd.read_csv('..\/input\/Zomato_LucknowLatest.csv')\ndf.drop('Unnamed: 0',axis=1,inplace=True)#If reading from CSV\ndf","52179258":"df.isnull().sum()","9ca3f014":"count=0\nfor name,rating,vote,cf2,hours in tqdm(zip(df.Name,df.Rating,df.Votes,df.CF2,df.Hours)):\n    l=word_tokenize(name)\n    string=' '.join(l).replace(\" 's\",\"'s\")\n    df.iloc[count,0]=string\n    l=word_tokenize(rating)\n    string=''.join(l)\n    df.iloc[count,5]=string\n    try:\n        string=vote.replace(' votes','')\n        df.iloc[count,6]=string\n    except:\n        pass\n    string=''.join(re.findall(r'[0-9]', cf2))\n    df.iloc[count,9]=string\n    string=(''.join(re.findall(r'.', hours))).strip()\n    df.iloc[count,10]=string\n    count+=1","d70717ae":"df","803d7480":"top=[]\nimport ast\nl=df.Dish.tolist()\nfor j in l:\n    try:\n        j=j.strip('][').split(', ')\n        for i in j:\n            i=i.replace(\"\\'\",\"\").replace(\"\\'\",\"\")\n            if i=='Bestsellers' or i=='Bestseller':\n                index=0\n                c=0\n                for k in j:\n                    c+=1\n                    if c>=2:\n                        top.append(k)\n                        index+=1\n                    if index==10:\n                        break\n    except:\n        pass\ntop[0:10]\ntops={}\nfor i in top:\n    tops[i]=top.count(i)\nsorted_d = dict(sorted(tops.items(), key=operator.itemgetter(1),reverse=True))\nsorted_d.pop('\"Restaurant\\'s Recommendations\"')\nsorted_d.pop(\"'Starters'\")\nsorted_d.pop(\"'Combos'\")\nsorted_d.pop(\"'Bestsellers'\")\nsorted_d","0fd2a6ac":"dish_name=[]\nnumber=[]\nfor count,key in enumerate(sorted_d.keys()):\n    dish_name.append(key)\n    number.append(sorted_d[key])\n    if count==14:\n        break\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nax=plt.figure(figsize=(12,8))\nax=sns.set(style=\"darkgrid\")\nax=sns.barplot(y=dish_name,x=number);\nax.set(xlabel='No. of Restaurants where they are mentioned as Bestsellers',ylabel='Dishes',title=\"Top Dishes 15 w.r.t. Restaurant's Bestsellers\");\nplt.tight_layout()","edc8b977":"df.Votes=df.Votes.astype(int)\nax=plt.figure(figsize=(12,8))\nax=sns.set(style=\"darkgrid\")\nax=sns.barplot(y=df.sort_values(by='Votes', ascending=False).Name[0:15],x=df.sort_values(by='Votes', ascending=False).Votes[0:15])\nax.set(xlabel=\"No. of Votes\",ylabel=\"Restaurant's\",title=\"Top 15 Popular Restaurant's of the City\");\nplt.tight_layout()","e5d5bc7a":"df.Online.value_counts()","01b67464":"slices=[2122,1830]\nplt.figure(figsize=(12,8))\nplt.pie(slices, labels =['Delivery Not Available','Delivery Available'],startangle = 90,autopct='%1.0f%%', shadow = True, explode = (0, 0.1,))\nplt.title('Percentage of Restaurant w.r.t. to Delivery Option',bbox={'facecolor':'0.8', 'pad':5})\nplt.show()","acb57bd8":"df.CF2=df.CF2.astype(int)\nax=plt.figure(figsize=(12,8))\nax=sns.set(style=\"darkgrid\")\nax=sns.barplot(y=df.sort_values(by='CF2', ascending=False).Name[0:15],x=df.sort_values(by='CF2', ascending=False).CF2[0:15])\nax.set(xlabel=\"Price for 2 Persons\",ylabel=\"Restaurant's\",title=\"15 Most Expensive Restaurant's in the City\");\nplt.tight_layout()","7f68cab5":"name=[]\nnum=[]\nfor i in df.groupby('Area').size().sort_values( ascending=False)[0:14].index:\n    name.append(i)\nfor i in df.groupby('Area').size().sort_values( ascending=False)[0:14]:\n    num.append(i)\nname.pop(3)\nnum.pop(3)\nax=plt.figure(figsize=(12,8))\nax=sns.set(style=\"darkgrid\")\nax=sns.barplot(y=name,x=num)\nax.set(xlabel=\"No. of Restaurant's\",ylabel=\"Area\",title=\"Top 15 Area's with the maximum Restaurant\");\nplt.tight_layout()","e9175f0b":"ax=plt.figure(figsize=(12,8))\nax=sns.set(style=\"darkgrid\")\nax=sns.countplot(y=df.Title)\nax.set(xlabel=\"No. of Restaurant's\",ylabel=\"Types\",title=\"Types of Restaurant's in the City\");\nplt.tight_layout()\n","6d1b986d":"df.Json[1]","94072e83":"longitude=[]\nlatitude=[]\nfor c,i in enumerate(df.Json):\n    try:\n        j=json.loads(i.replace(\"\\'\", \"\\\"\"))\n        longitude.append(j['geo']['longitude'])\n        latitude.append(j['geo']['latitude'])\n    except:\n        try:\n            a=i.replace(\"\\'\",\"\\\"\").replace('\\\"s','',1)\n            a=a.replace(\"\\'\", \"\\\"\")\n            j=json.loads(a)\n            longitude.append(j['geo']['longitude'])\n            latitude.append(j['geo']['latitude'])\n        except:\n            longitude.append(str(0))\n            latitude.append(str(0))\nfor count,i in enumerate(longitude):\n    if isinstance(i,int):\n        longitude[count]=float(i)\n    elif i.replace('.', '', 1).isdigit() :\n        longitude[count]=float(i)\n      \n    else:\n        longitude[count]=0.0\nfor count,i in enumerate(latitude):\n    if isinstance(i,int):\n        latitude[count]=float(i)\n    elif i.replace('.', '', 1).isdigit() :\n        latitude[count]=float(i)\n      \n    else:\n        latitude[count]=0.0\n\ndf2=pd.concat([df,pd.DataFrame(list(zip(longitude,latitude)),columns=['Longitude','Latitude'])],axis=1)\ndf2=df2.drop(df2.index[df2[df2.Latitude==0.0].index.values],axis=0)\ndf2=df2.drop(df2.index[df2[df2.Longitude==0.0].index.values],axis=0)\n","8e9abb88":"map_ = folium.Map(location=[26.8542,80.9448], zoom_start=10)\nlocs = df2.sort_values(by='Votes', ascending=False)[['Latitude', 'Longitude']][0:50]\nloc_list = locs.values.tolist()\n\n# To display all data use the following two lines, but, since your data has\n# so many points, this process will be time-consuming.\nfor point in range(0, len(loc_list)):\n    folium.Marker(loc_list[point]).add_to(map_)\n\n# To display first 1000 points\n# for point in range(0, 1000):\n#     folium.Marker(loc_list[point]).add_to(map_)\n\nmap_","625c6237":"Now converting the data to DataFrame and exporting the DataFrame for future use.","16150dfd":"# First we'll import all the libraries we need.","38c0a2bd":"# Now lets map this data.Checking Top 50 restaurant area","a57a066d":"# Now we'll check the bestsellers of every restaurants and check which dish is widely loved in the city","b9d2c59d":"# Now lets check how many Restaurant's offer online delivery service","e58ef709":"Now lets Check for null vaues","5e2feec5":"# For Scraping you have to run it on your system.Clouds not working.","3a879374":"Now Look it a json File of a Restaurant","7b0b07cf":"# Now Lets do some data cleaning beacuse its not in right format","a032c12d":"0 means type of restaurant in none","4fafb273":"# Now lets visualize the most sold dishes of the city.","b450401e":"Now lets take a look at scrapped data","d34f4dbf":"# Now lets check the type of Restaurant's(Count) in the City","1111b95b":"# Lets check the Area's with the maximum Restaurant's","7e779805":"# Now let's check the most popular Restaurant's in the city","cd9b62b5":"# Now We'll have to clean this data and extract the longitude of latitude of every Restaurant for mapping","c8eeef5a":"Below I'm scraping the website so I have used try\/catch at every instance and storing it in variables.","e31c104e":"# Now let's look at the cleaned data","7470827a":"# Check the most expensive Restaurant's of the city","b7404d3d":"\n# General Introduction:\n\nIn this we are going to scrape Zomato and will do some EDA.You can Choose your city for scraping. As I'm from Lucknow so I'm going scrape all Zomato' Restarant's details.\n\n**Caution!:** = Don't use your public IP Address for scraping as you may get blocked.You can use public proxies or a VPN.\n"}}