{"cell_type":{"572dc3b7":"code","198c9d1f":"code","a6746da5":"code","3e56567a":"code","831fb592":"code","fa7656fd":"code","cb69a3c7":"code","3cc44be3":"code","10550501":"code","ebc3e03f":"code","e3ec3fcc":"code","350b5fb4":"code","406d8d0d":"code","5a24de60":"code","3ef0d179":"code","511d58a3":"markdown","f25323ef":"markdown","39328f5d":"markdown","b745767c":"markdown","cd9f3bfb":"markdown","68fb5f69":"markdown"},"source":{"572dc3b7":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport torch\nimport copy\nimport torch.utils.data\nimport matplotlib.patches as patches\nfrom torchvision import transforms\nimport collections\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nprint(os.listdir(\"..\/input\"))","198c9d1f":"def rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 1\n        current_position += lengths[index]\n    return mask.reshape(width, height)","a6746da5":"class SIIMDataset(torch.utils.data.Dataset):\n    def __init__(self, df_path, img_dir):\n        self.df = pd.read_csv(df_path, nrows=100)\n        self.height = 1024\n        self.width = 1024\n        self.image_dir = img_dir\n        self.image_info = collections.defaultdict(dict)\n        self.df = self.df.drop_duplicates('ImageId', keep='last').reset_index(drop=True)\n\n        counter = 0\n        for index, row in tqdm(self.df.iterrows(), total=len(self.df)):\n            image_id = row['ImageId']\n            image_path = os.path.join(self.image_dir, image_id)\n            if os.path.exists(image_path + '.png') and row[\" EncodedPixels\"].strip() != \"-1\":\n                self.image_info[counter][\"image_id\"] = image_id\n                self.image_info[counter][\"image_path\"] = image_path\n                self.image_info[counter][\"annotations\"] = row[\" EncodedPixels\"].strip()\n                counter += 1\n\n    def __getitem__(self, idx):\n        img_path = self.image_info[idx][\"image_path\"]\n        img = Image.open(img_path + '.png').convert(\"RGB\")\n        width, height = img.size\n        img = img.resize((self.width, self.height), resample=Image.BILINEAR)\n        info = self.image_info[idx]\n\n        mask = rle2mask(info['annotations'], width, height)\n        mask = Image.fromarray(mask.T)\n        mask = mask.resize((self.width, self.height), resample=Image.BILINEAR)\n        mask = np.expand_dims(mask, axis=0)\n\n        pos = np.where(np.array(mask)[0, :, :])\n        xmin = np.min(pos[1])\n        xmax = np.max(pos[1])\n        ymin = np.min(pos[0])\n        ymax = np.max(pos[0])\n\n        boxes = torch.as_tensor([[xmin, ymin, xmax, ymax]], dtype=torch.float32)\n        labels = torch.ones((1,), dtype=torch.int64)\n        masks = torch.as_tensor(mask, dtype=torch.uint8)\n        image_id = torch.tensor([idx])\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        iscrowd = torch.zeros((1,), dtype=torch.int64)\n\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"masks\"] = masks\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n        return transforms.ToTensor()(img), target\n\n    def __len__(self):\n        return len(self.image_info)","3e56567a":"dataset = SIIMDataset(\"..\/input\/siim-dicom-images\/train-rle.csv\", \"..\/input\/siim-png-images\/input\/train_png\/\")","831fb592":"def plotter(img, target):\n    fig,ax = plt.subplots(1)\n    ax.imshow(transforms.ToPILImage()(img))\n    ax.imshow(transforms.ToPILImage()(target[\"masks\"][0].cpu() * 255), alpha=0.5)\n    rect = patches.Rectangle((target[\"boxes\"][0][0].item(),\n                             target[\"boxes\"][0][1].item()),\n                             target[\"boxes\"][0][2].item() - target[\"boxes\"][0][0].item(),\n                             target[\"boxes\"][0][3].item() - target[\"boxes\"][0][1].item(),\n                             linewidth=1,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)\n    plt.show()","fa7656fd":"img, target = dataset[0]\nplotter(img, target)","cb69a3c7":"def horizontal_flip(image, target):\n    img = copy.deepcopy(image)\n    tgt = copy.deepcopy(target)\n    height, width = img.shape[-2:]\n    img = img.flip(-1)\n    bbox = tgt[\"boxes\"]\n    bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n    tgt[\"boxes\"] = bbox\n    tgt[\"masks\"] = tgt[\"masks\"].flip(-1)\n    return img, tgt","3cc44be3":"_img, _target = horizontal_flip(img, target)\nplotter(_img, _target)","10550501":"def vertical_flip(image, target):\n    img = copy.deepcopy(image)\n    tgt = copy.deepcopy(target)\n    height, width = img.shape[-2:]\n    img = img.flip(1)\n    bbox = tgt[\"boxes\"]\n    bbox[:, [1, 3]] = height - bbox[:, [3, 1]]\n    tgt[\"boxes\"] = bbox\n    tgt[\"masks\"] = tgt[\"masks\"].flip(1)\n    return img, tgt","ebc3e03f":"_img, _target = vertical_flip(img, target)\nplotter(_img, _target)","e3ec3fcc":"def rotation(image, target, degrees):\n    img = copy.deepcopy(image)\n    tgt = copy.deepcopy(target)\n    height, width = img.shape[-2:]\n    img = transforms.ToTensor()(transforms.ToPILImage()(img).rotate(degrees))\n    rotated_mask = transforms.ToTensor()(transforms.ToPILImage()(tgt[\"masks\"]).rotate(degrees))\n    \n    pos = np.where(np.array(rotated_mask)[0, :, :])\n    xmin = np.min(pos[1])\n    xmax = np.max(pos[1])\n    ymin = np.min(pos[0])\n    ymax = np.max(pos[0])\n\n    bbox = torch.as_tensor([[xmin, ymin, xmax, ymax]], dtype=torch.float32)\n    \n    tgt[\"boxes\"] = bbox\n    tgt[\"masks\"] = rotated_mask\n    return img, tgt","350b5fb4":"_img, _target = rotation(img, target, 30)\nplotter(_img, _target)","406d8d0d":"_img, _target = rotation(img, target, 90)\nplotter(_img, _target)","5a24de60":"_img, _target = rotation(img, target, 120)\nplotter(_img, _target)","3ef0d179":"_img, _target = rotation(img, target, 270)\nplotter(_img, _target)","511d58a3":"These are just some of the augmentations you can do to possibly get a better result. How you integrate these to Dataset Class you ask? It's not very difficult. I'll leave it as an exercise to the reader! ;)","f25323ef":"# Vertical Flip","39328f5d":"# Prepare Dataset","b745767c":"# Horizontal Flip","cd9f3bfb":"If you want more image+mask augmentations, write in comments and i would try my best to implement them!","68fb5f69":"# Rotation"}}