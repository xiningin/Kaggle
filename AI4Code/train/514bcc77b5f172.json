{"cell_type":{"9b0402d1":"code","32771728":"code","9cee5e83":"code","75795d97":"code","f0a1b475":"code","0d499c4b":"code","7c281978":"code","710d7eef":"code","58b2d00a":"code","85b6691c":"code","717ec368":"code","5a32d15a":"code","a2a5c8b1":"code","f8ab1438":"code","42b5b987":"code","29d3240f":"code","b3cf5c97":"code","57ddcf60":"code","263ff1c7":"code","40e05bf8":"code","829a8288":"code","37f6fe87":"markdown","e2c1de0c":"markdown","d344890a":"markdown","96877abf":"markdown","173f51eb":"markdown","27a8b1c3":"markdown","3830b10c":"markdown","74b001c6":"markdown","01a1dfbb":"markdown","03d4ed54":"markdown","4531b698":"markdown","0f07b850":"markdown","e4ac37c5":"markdown","1d10ee98":"markdown","4db5424a":"markdown","c371acd6":"markdown","43e1e5fb":"markdown","6e649f15":"markdown"},"source":{"9b0402d1":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.utils import shuffle","32771728":"path = \"..\/input\/breast-cancer-wisconsin-data\/data.csv\"\ndf = pd.read_csv(path)\ndf = shuffle(df)\ndf.head()","9cee5e83":"df.drop('id', axis=1, inplace=True)\ndf.drop('Unnamed: 32', axis=1, inplace=True)","75795d97":"categories = {'B':0, 'M':1}\ndf['diagnosis'].replace(categories, inplace=True)\ndf.head()","f0a1b475":"df.describe().T","0d499c4b":"# verify if data has any null values\ndf.isnull().values.any()","7c281978":"plt.figure(figsize=(16,8))\ncorr = df.corr()\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True)","710d7eef":"# select only the strong correlated columns with diagnosis\nbest_correlated = list(corr['diagnosis'][corr['diagnosis'] > 0.7].index)\nprint(best_correlated)","58b2d00a":"features = df[best_correlated[1:]]\nlabels = df['diagnosis'].values","85b6691c":"scaler = MinMaxScaler()\nscaler.fit(features)\nfeatures = scaler.transform(features)","717ec368":"# use of batch size of 8\nlimit = 8*8*8\n\nX_train, X_test = features[:limit], features[limit:]\ny_train, y_test = labels[:limit], labels[limit:]","5a32d15a":"def cross_entropy(y_hat, y):\n    if y == 1:\n        return -np.log(y_hat)\n    else:\n        return -np.log(1 - y_hat)\n    \ndef dcross_entropy(y_hat, y):\n    if y == 1:\n        return -1\/y_hat\n    else:\n        return 1 \/ (1 - y_hat)","a2a5c8b1":"def sigmoid(x):\n    return 1 \/ (1 + np.exp(-x))\n\ndef dsigmoid(x):\n    return sigmoid(x) * (1 - sigmoid(x))","f8ab1438":"lr = 0.01\nepochs = 100\nbatch_size = 8\nnp.random.seed(234242)","42b5b987":"w = np.random.uniform(low=-0.01, high=0.01, size=(batch_size,1))\nb = np.random.uniform(low=-0.01, high=0.01, size=(batch_size,1))\n\nbatches = np.array_split(shuffle(np.arange(len(X_train))), \n                                           len(X_train)\/\/batch_size)","29d3240f":"total_losses = []\ntotal_accuracies = []\n\nfor epoch in range(epochs):\n    \n    losses = 0\n    accuracies = 0\n    \n    for batch in batches:\n        X, y = features[batch], labels[batch]\n\n        z = X @ w + b\n        z = sigmoid(z)\n        l = np.array([cross_entropy(z[i], y).tolist() \n                                              for i, y in enumerate(y)])\n\n        accuracies += np.sum(np.squeeze(np.round(z)) == y)\n        losses += l.mean()\n\n        dl = np.array([dcross_entropy(z[i], y).tolist()\n                                                for i, y in enumerate(y)])\n\n        dw = ((dl * dsigmoid(z)).T.dot(X)).T\n        db = dl * dsigmoid(z)\n\n        w -= lr * dw\n        b -= lr * db\n        \n    total_losses.append(losses \/ len(batches))\n    total_accuracies.append(accuracies \/ (len(batches) * 8))\n    \n    if((epoch+1) % 10 == 0):\n        print(\"Epoch:{:3d}, Loss:{:1.3f}, Accuracy:{:1.3f}\"\n                 .format(epoch+1, total_losses[-1], total_accuracies[-1]))","b3cf5c97":"plt.figure(figsize=(14,8))\nplt.title(\"Train Losses\")\nplt.plot(total_losses, label='Losses')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","57ddcf60":"plt.figure(figsize=(14,8))\nplt.title(\"Train Accuracy\")\nplt.plot(total_accuracies, label='Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","263ff1c7":"def get_test_accuracy(X_test, y_test):\n    y_hat = []\n    accuracies = 0\n    for i in range(len(X_test[:-1]) \/\/ 8):\n        X = X_test[i * 8:i * 8 + 8]\n        y = y_test[i * 8:i * 8 + 8] \n\n        z = X @ w + b\n        z = sigmoid(z)\n\n        y_hat.append(z.tolist())\n        accuracies += np.sum(np.squeeze(np.round(z)) == y)\n\n    y_hat = np.array(y_hat)\n    y_hat = y_hat.reshape(y_hat.shape[0] * y_hat.shape[1],)\n    y_hat = [np.round(y) for y in y_hat]\n    total_accuracy = accuracies \/ len(X_test[:-1])\n    \n    return y_hat, total_accuracy","40e05bf8":"y_hat, test_accuracy = get_test_accuracy(X_test, y_test)\nprint('Accuracy:{:1.3f}'.format(test_accuracy))","829a8288":"target_names = ['beignet', 'malignant']\nprint(classification_report(y_test[:-1], y_hat, target_names=target_names))","37f6fe87":"<h1 id=\"dataset\" style=\"color:#5f20aa; background:white; border:0.5px dotted #5f20aa;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","e2c1de0c":"<h1 id=\"analysis\" style=\"color:#5f20aa; background:white; border:0.5px dotted #5f20aa;\"> \n    <center>Analysis\n        <a class=\"anchor-link\" href=\"#analysis\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","d344890a":"## Training function","96877abf":"## Test dataset accuracy","173f51eb":"## Parameters","27a8b1c3":"## Drop non-useful columns","3830b10c":"## Train\/Test split","74b001c6":"## Correlation heatmap","01a1dfbb":"<h1 id=\"activation\" style=\"color:#5f20aa; background:white; border:0.5px dotted #5f20aa;\"> \n    <center>Activation function\n        <a class=\"anchor-link\" href=\"#activation\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","03d4ed54":"## Classification metrics","4531b698":"## Columns information","0f07b850":"## Categorize cancer malignant or benign","e4ac37c5":"<h1 id=\"loss\" style=\"color:#5f20aa; background:white; border:0.5px dotted #5f20aa;\"> \n    <center>Loss function\n        <a class=\"anchor-link\" href=\"#loss\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","1d10ee98":"## Load dataset","4db5424a":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/180\/384\/3da2510581f9d3b902307ff8d06fe327\/dataset-cover.jpg\" \/>\n<\/div>","c371acd6":"# Min-Max Scaler to normalize columns","43e1e5fb":"<h1 id=\"training\" style=\"color:#5f20aa; background:white; border:0.5px dotted #5f20aa;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","6e649f15":"## Weights, biases and batches"}}