{"cell_type":{"ccd86d7e":"code","cb79ba71":"code","f2db2b30":"code","58b5cdc0":"code","8d8a9964":"code","32624039":"code","e2ff1f51":"code","4311a257":"code","dd66e47a":"code","9312ac40":"code","552ca819":"code","c939a3ef":"code","01e4570f":"code","238cf2ac":"code","3436a38e":"code","d3d82c12":"code","429ba7ff":"code","47b68354":"code","f09b6f83":"code","920924da":"code","ba455e4a":"code","5806e981":"code","e957ce1b":"code","ee6978ad":"code","1f3a93ac":"code","a67f342c":"code","0ff69677":"code","41b64593":"code","546931e9":"code","f167ef49":"code","da0114da":"code","2adc8f96":"code","28cd8ad6":"code","b98f9f7b":"code","abd4a0db":"code","c8a68173":"code","2e9e2741":"code","3c5f602c":"code","5f15da6c":"markdown","acdc85ad":"markdown","53869b40":"markdown","6a97d61d":"markdown","2ea5eeb1":"markdown"},"source":{"ccd86d7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb79ba71":"df=pd.read_csv(\"..\/input\/vehicle-dataset-from-cardekho\/car data.csv\")\nprint(df.head())\n#dependent and independemt features\ni=df.iloc[:,0:]\no=df.iloc[:,2]\n\nfrom sklearn.model_selection import train_test_split\ni_train,i_test,o_train,o_test=train_test_split(i,o,test_size=0.2)\n#print(X_train.shape)\n#print(X_test.shape)\n#print(X_train.head(2))\n#print(y_train.head(2))\n","f2db2b30":"print(df[\"Seller_Type\"].unique())\nprint(df[\"Fuel_Type\"].unique())\nprint(df[\"Transmission\"].unique())\nprint(df[\"Car_Name\"].unique())","58b5cdc0":"print(df.isnull().sum())\n","8d8a9964":"df.describe()","32624039":"df.columns","e2ff1f51":"dataset=df[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]","4311a257":"dataset['current_year']=2020","dd66e47a":"dataset.head()","9312ac40":"dataset['no_of_year']=dataset['current_year']-dataset['Year']\ndataset.head()","552ca819":"dataset.drop(['Year'],axis=1,inplace=True)\ndataset.drop(['current_year'],axis=1,inplace=True)\ndataset.head()","c939a3ef":"##onehot encoding\n\ndataset=pd.get_dummies(dataset,drop_first=True)\ndataset.head()","01e4570f":"dataset.corr()","238cf2ac":"import seaborn as sns","3436a38e":"#sns.pairplot(dataset)","d3d82c12":"#import matplotlib.pyplot as plt\n#%matplotlib inline","429ba7ff":"#corrmat=dataset.corr() \n#top_corr_features=corrmat.index\n#plt.figure(figsize=(20,20))\n#plot heat map \n#g=sns.heatmap(dataset[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n\n","47b68354":"##dependent and independemt features\nX=dataset.iloc[:,1:]\nY=dataset.iloc[:,0]\n","f09b6f83":"#feature importance\nfrom sklearn.ensemble import ExtraTreesRegressor\nmodel=ExtraTreesRegressor()\nmodel.fit(X,Y)","920924da":"print(model.feature_importances_)","ba455e4a":"#plot graph of feature importances for better visualization \nfeat_importances = pd.Series(model.feature_importances_, index=X.columns) \nfeat_importances.nlargest(5).plot(kind='barh') \nplt.show()","5806e981":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)\nprint(X_train.shape)\nprint(X_test.shape)","e957ce1b":"from sklearn.ensemble import RandomForestRegressor \nrf_random=RandomForestRegressor()\n","ee6978ad":"#Hyperparameters\nimport numpy as np\nn_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)]\nprint(n_estimators)","1f3a93ac":"from sklearn.model_selection import RandomizedSearchCV","a67f342c":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","0ff69677":"#create the random grid\nrandom_grid={'n_estimators':n_estimators,\n            'max_features':max_features,\n            'max_depth':max_depth,\n            'min_samples_split':min_samples_split,\n            'min_samples_leaf':min_samples_leaf}\nprint(random_grid)","41b64593":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()","546931e9":"# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","f167ef49":"rf_random.fit(X_train,y_train)","da0114da":"rf_random.best_params_","2adc8f96":"rf_random.best_score_","28cd8ad6":"predictions=rf_random.predict(X_test)","b98f9f7b":"sns.distplot(y_test-predictions)","abd4a0db":"plt.scatter(y_test,predictions)","c8a68173":"from sklearn import metrics","2e9e2741":"print('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","3c5f602c":"print(predictions)\nprint(X_test.head())\n\nmysubmission = pd.DataFrame({\n        \"Car_Name\": i_test[\"Car_Name\"],\n        \"Predictions\": predictions\n    })\nmysubmission.to_csv('submission.csv', index=False)","5f15da6c":"# HYPERPARAMETER TRAINING IN RANDOMFORESTREGRESSOR USING RANDOMIZED SEARCH CV","acdc85ad":"#  ONE HOT ENCODING TO CONVERT CATEGORICAL TO NUMERICAL \n\n","53869b40":"# **SUBMISSION FILE**","6a97d61d":"# TEST TRAIN SPLIT","2ea5eeb1":"# FEATURE SELECTION"}}