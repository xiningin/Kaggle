{"cell_type":{"37f22885":"code","987683c3":"code","032d7861":"code","f4c5f85a":"code","40d3d213":"code","c72863e5":"code","c2b13720":"code","6ae00bab":"code","94f4f1e4":"code","db20b4a0":"code","8fbeb58a":"code","470282cc":"code","5fca4d7e":"code","b7d5412d":"code","f05b2f35":"code","1da06695":"code","592e8b28":"code","77f7b2b6":"code","ce87dc6e":"code","e6ad12eb":"code","39453540":"code","bc04a3eb":"code","7cfead0b":"code","ddebc54f":"code","349afc98":"code","cfe62f2d":"code","85b60b21":"code","d1b480b6":"code","bb726452":"code","dd576aa9":"code","e288bee1":"code","e02e28a4":"code","e3d9e7c3":"code","1512aeb4":"code","92648246":"code","c4cf74ac":"code","5edf7f0f":"code","eeacc09d":"code","7ad92e97":"code","5def5947":"code","344bcfa8":"code","1e1b1925":"code","43739022":"markdown","a6585b5b":"markdown","ffb5666f":"markdown","d910447a":"markdown","8826b94b":"markdown","981c13f4":"markdown","149b16c7":"markdown","20d79f69":"markdown","c3ff5f11":"markdown","7a9059da":"markdown","a91fec87":"markdown","cdc5f573":"markdown","732915f5":"markdown","541745fb":"markdown","4cc9cbec":"markdown","dbdaf6a6":"markdown","6110c2ff":"markdown","b160b8b4":"markdown","5eb338b3":"markdown","8dc3e5df":"markdown","0d6cf9e6":"markdown","a999370b":"markdown","72b348e7":"markdown","f023f301":"markdown"},"source":{"37f22885":"import pandas as pd \nimport numpy as np\nfrom scipy import stats\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder,OneHotEncoder,StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error,r2_score","987683c3":"dataset_path = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/'\n\ntrain = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(train.shape))\n\ntrain.head(10)","032d7861":"train.describe()","f4c5f85a":"train.info()","40d3d213":"train.drop_duplicates(inplace=True)","c72863e5":"test = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(test.shape))\n\ntest.head(5)","c2b13720":"[col for col in train.columns if train[col].isnull().sum()!=0]","6ae00bab":"missing_val_count_by_column = (train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","94f4f1e4":"[col for col in test.columns if test[col].isnull().sum()!=0]","db20b4a0":"missing_val_count_by_column = (test.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","8fbeb58a":"train.drop(['Id','MiscFeature'],axis=1,inplace=True)\ntrain.shape","470282cc":"Id = test['Id']\ntest.drop(['Id','MiscFeature'],axis=1,inplace=True)\ntest.shape","5fca4d7e":"sns.set_theme(style=\"white\")\ncorr = train.corr()\nf, ax = plt.subplots(figsize=(30, 30))\nmask = np.triu(np.ones_like(corr, dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, annot=True, mask = mask, cmap=cmap)\nplt.show()","b7d5412d":"corr[\"SalePrice\"].sort_values(ascending=False)","f05b2f35":"quantitative_features = [col for col in train.columns if train[col].dtypes != 'object']\ncategorical_features = [col for col in train.columns if train[col].dtypes == 'object']","1da06695":"train[quantitative_features].hist(bins=50, figsize=(20,17))\nplt.show()","592e8b28":"sns.histplot(data=train,x='SalePrice',stat='count',bins=10,kde=True)\nplt.title(\"Sale Price Distribution\")\nplt.show()","77f7b2b6":"y = train['SalePrice']\nx = train.drop(['SalePrice'],axis=1)","ce87dc6e":"X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2,random_state=0)","e6ad12eb":"#Train Data \nX_train['BsmtQual'].fillna('No Basement',inplace=True)\nX_train['BsmtCond'].fillna('No Basement',inplace=True)\nX_train['BsmtExposure'].fillna('No Basement',inplace=True)\nX_train['BsmtFinType1'].fillna('No Basement',inplace=True)\nX_train['BsmtFinType2'].fillna('No Basement',inplace=True)\nX_train['GarageType'].fillna('No Garage',inplace=True)\nX_train['GarageFinish'].fillna('No Garage',inplace=True)\nX_train['GarageQual'].fillna('No Garage',inplace=True)\nX_train['GarageCond'].fillna('No Garage',inplace=True)\nX_train['Alley'].fillna('No',inplace=True)\nX_train['PoolQC'].fillna('No Pool',inplace=True)\nX_train['Fence'].fillna('No Fence',inplace=True)\nX_train['FireplaceQu'].fillna('No Fireplace',inplace=True)\n\n#Validation Data\nX_valid['BsmtQual'].fillna('No Basement',inplace=True)\nX_valid['BsmtCond'].fillna('No Basement',inplace=True)\nX_valid['BsmtExposure'].fillna('No Basement',inplace=True)\nX_valid['BsmtFinType1'].fillna('No Basement',inplace=True)\nX_valid['BsmtFinType2'].fillna('No Basement',inplace=True)\nX_valid['GarageType'].fillna('No Garage',inplace=True)\nX_valid['GarageFinish'].fillna('No Garage',inplace=True)\nX_valid['GarageQual'].fillna('No Garage',inplace=True)\nX_valid['GarageCond'].fillna('No Garage',inplace=True)\nX_valid['Alley'].fillna('No',inplace=True)\nX_valid['PoolQC'].fillna('No Pool',inplace=True)\nX_valid['Fence'].fillna('No Fence',inplace=True)\nX_valid['FireplaceQu'].fillna('No Fireplace',inplace=True)\n\n#Test Data\ntest['BsmtQual'].fillna('No Basement',inplace=True)\ntest['BsmtCond'].fillna('No Basement',inplace=True)\ntest['BsmtExposure'].fillna('No Basement',inplace=True)\ntest['BsmtFinType1'].fillna('No Basement',inplace=True)\ntest['BsmtFinType2'].fillna('No Basement',inplace=True)\ntest['GarageType'].fillna('No Garage',inplace=True)\ntest['GarageFinish'].fillna('No Garage',inplace=True)\ntest['GarageQual'].fillna('No Garage',inplace=True)\ntest['GarageCond'].fillna('No Garage',inplace=True)\ntest['Alley'].fillna('No',inplace=True)\ntest['PoolQC'].fillna('No Pool',inplace=True)\ntest['Fence'].fillna('No Fence',inplace=True)\ntest['FireplaceQu'].fillna('No Fireplace',inplace=True)","39453540":"num_X_train = X_train.drop(categorical_features, axis=1)\nnum_X_valid = X_valid.drop(categorical_features, axis=1)\n\ncat_X_train = X_train.drop(quantitative_features[:-1], axis=1)\ncat_X_valid = X_valid.drop(quantitative_features[:-1], axis=1)","bc04a3eb":"num_test = test.drop(categorical_features, axis=1)\n\ncat_test = test.drop(quantitative_features[:-1], axis=1)","7cfead0b":"N_SI = SimpleImputer(strategy='median')\nimputed_Num_X_train = pd.DataFrame(N_SI.fit_transform(num_X_train))\nimputed_Num_X_valid = pd.DataFrame(N_SI.transform(num_X_valid))\nimputed_Num_X_train.columns = num_X_train.columns\nimputed_Num_X_valid.columns = num_X_valid.columns","ddebc54f":"imputed_Num_test = pd.DataFrame(N_SI.fit_transform(num_test))\nimputed_Num_test.columns = num_test.columns","349afc98":"C_SI = SimpleImputer(strategy='most_frequent')\nimputed_Cat_X_train = pd.DataFrame(C_SI.fit_transform(cat_X_train))\nimputed_Cat_X_valid = pd.DataFrame(C_SI.transform(cat_X_valid))\nimputed_Cat_X_train.columns = cat_X_train.columns\nimputed_Cat_X_valid.columns = cat_X_valid.columns","cfe62f2d":"imputed_Cat_test = pd.DataFrame(C_SI.fit_transform(cat_test))\nimputed_Cat_test.columns = cat_test.columns","85b60b21":"imputed_X_train = pd.concat([imputed_Num_X_train, imputed_Cat_X_train], axis=1)\nimputed_X_valid = pd.concat([imputed_Num_X_valid, imputed_Cat_X_valid], axis=1)\nimputed_test = pd.concat([imputed_Num_test, imputed_Cat_test], axis=1)\nprint(\"Train Data shape is : \",imputed_X_train.shape)\nprint(\"Validation Data shape is : \",imputed_X_valid.shape)\nprint(\"Test Data shape is : \",imputed_test.shape)","d1b480b6":"object_cols = [col for col in imputed_test.columns if imputed_test[col].dtype == \"object\"]\n\ngood_label_cols = [col for col in object_cols if \n                   set(imputed_X_train[col]).issubset(set(imputed_test[col]))]\n        \n# Problematic columns that will be dropped from the dataset\nbad_label_cols = list(set(object_cols)-set(good_label_cols))\n        \nprint('Categorical columns that will be ordinal encoded:', good_label_cols)\nprint('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)","bb726452":"imputed_X_train.drop(bad_label_cols, axis=1,inplace=True)\nimputed_X_valid.drop(bad_label_cols, axis=1,inplace=True)\nimputed_test.drop(bad_label_cols, axis=1,inplace=True)","dd576aa9":"quantitative_features = [col for col in imputed_X_train.columns if imputed_X_train[col].dtypes != 'object']\ncategorical_features = [col for col in imputed_X_train.columns if imputed_X_train[col].dtypes == 'object']","e288bee1":"object_nunique = list(map(lambda col: imputed_X_train[col].nunique(), categorical_features))\nd = dict(zip(categorical_features, object_nunique))\n\nsorted(d.items(), key=lambda x: x[1])","e02e28a4":"low_cardinality_cols = [col for col in categorical_features if imputed_X_train[col].nunique() < 10]\n\nhigh_cardinality_cols = list(set(categorical_features)-set(low_cardinality_cols))","e3d9e7c3":"OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\nnum_X_train = imputed_X_train.drop(categorical_features, axis=1)\nnum_X_valid = imputed_X_valid.drop(categorical_features, axis=1)\nnum_test = imputed_test.drop(categorical_features, axis=1)\n\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(imputed_X_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(imputed_X_valid[low_cardinality_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(imputed_test[low_cardinality_cols]))\n\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\nOH_test = pd.concat([num_test, OH_cols_test], axis=1)","1512aeb4":"O_encoder = OrdinalEncoder()\n\nnum_X_train = imputed_X_train.drop(categorical_features, axis=1)\nnum_X_valid = imputed_X_valid.drop(categorical_features, axis=1)\nnum_test = imputed_test.drop(categorical_features, axis=1)\n#print((imputed_X_valid[imputed_X_valid['Functional']=='Sev']).index)\n#imputed_X_valid = imputed_X_valid[imputed_X_valid['Functional']=='Sev'].drop(index=215)\nOH_cols_train = pd.DataFrame(O_encoder.fit_transform(imputed_X_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(O_encoder.fit_transform(imputed_X_valid[low_cardinality_cols]))\nOH_cols_test = pd.DataFrame(O_encoder.fit_transform(imputed_test[low_cardinality_cols]))\n\nOH_X_train1 = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid1 = pd.concat([num_X_valid, OH_cols_valid], axis=1)\nOH_test1 = pd.concat([num_test, OH_cols_test], axis=1)","92648246":"print(OH_test1.shape)\nprint(OH_X_train1.shape)","c4cf74ac":"sc = StandardScaler()\nOH_X_train = sc.fit_transform(OH_X_train)\nOH_X_valid = sc.transform(OH_X_valid)\nOH_test = sc.transform(OH_test)","5edf7f0f":"model = XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=0)\n\nmodel.fit(OH_X_train, y_train)\n\npredicted=model.predict(OH_X_valid)","eeacc09d":"print('mean_squared_error using XGBRegressor : {}'.format(np.sqrt(mean_squared_error(y_valid,predicted))))\n\nprint('Accuracy using XGBRegressor : {}'.format(r2_score(y_valid,predicted)))","7ad92e97":"model1 = XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=0)\n\nmodel1.fit(OH_X_train1, y_train)\n\npredicted=model1.predict(OH_X_valid1)","5def5947":"print('mean_squared_error using XGBRegressor : {}'.format(np.sqrt(mean_squared_error(y_valid,predicted))))\n\nprint('Accuracy using XGBRegressor : {}'.format(r2_score(y_valid,predicted)))","344bcfa8":"test_predicted = model.predict(OH_test)","1e1b1925":"test['SalePrice']= test_predicted\ntest['Id']= Id\ntest[['Id','SalePrice']].to_csv('\/kaggle\/working\/submission.csv', index=False)","43739022":"<h3> Load training dataset <\/h3>","a6585b5b":"<h3> Columns with Null values in Test data <\/h3>","ffb5666f":"<h3>Distinguish between Quantitative features and Categorical features<\/h3>","d910447a":"<h3> Load testing dataset <\/h3>","8826b94b":"<h3>Null values in Categorical data<\/h3>","981c13f4":"<h3> Remove columns with more than 50% rows Null<\/h3>","149b16c7":"<h3> Ordinal Encoding<\/h3>","20d79f69":"<h3> One Hot Encoding<\/h3>","c3ff5f11":"<h3> Plot histograms of Numeric data <\/h3>","7a9059da":"<h3>Plot the Heatmap to figure out the correlation between features<\/h3>","a91fec87":"<h3> Deal with Null values <\/h3>","cdc5f573":"<h3>Print some statisical information <\/h3>","732915f5":"<h2>Modeling<\/h2>","541745fb":"<h3> columns with Null values <\/h3>","4cc9cbec":"<h3>Build the model<\/h3>","dbdaf6a6":"<h2>Deal with Categorical data<\/h2>","6110c2ff":"<h4>Null values in Numerical data<\/h4>","b160b8b4":"<h3>Plot The distribution of label data<\/h3>","5eb338b3":"<h3> Split data in training and validation <\/h3>","8dc3e5df":"<h3>Remove duplicates<\/h3>","0d6cf9e6":"<h3> Check for Cardinality<\/h3>","a999370b":"<h3>Load Libraries<\/h3>","72b348e7":"<h3>Scaling Features<\/h3>","f023f301":"<h3> Extract the features and label <\/h3>"}}