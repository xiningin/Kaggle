{"cell_type":{"2c51adcb":"code","36611689":"code","9cd6c4e1":"code","19dc4dc5":"code","f83d7db0":"code","fe109b8e":"code","ecffcc60":"code","0a51ba0b":"code","1e4d816c":"code","232c176b":"code","dfe1163c":"code","27a43ce3":"code","3b4516c9":"code","f6f435c0":"code","1c0f42fd":"code","16adbc77":"code","83d07a39":"markdown"},"source":{"2c51adcb":"import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport torch.nn as nn","36611689":"# number of points\nN = 20\n\n# Generates random numbers between -10 and 10\nX = np.random.random(N)*20 - 10\n\n# Generates random numbers between -2.5 and 2.5\nnoise = np.random.random(N)*5 - 2.5\n\n# True slope of the line\nm = 0.25\n\n# True value of the y-intercept\nc = 3\n\n# True equation of the line\nY_true = m*X + c\n\n# Equation of the line with noise introduced\nY = Y_true + noise","9cd6c4e1":"plt.scatter(X,Y_true);","19dc4dc5":"plt.scatter(X,Y);","f83d7db0":"# create a model with one input and one output\nmodel = nn.Linear(1,1)","fe109b8e":"# Define Loss and Optimizer \ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.03)","ecffcc60":"display(X.shape)\ndisplay(Y.shape)","0a51ba0b":"# Reshape our data into appropriate dimesnions so that we can feed it into PyTorch\nX = X.reshape(N,1)\nY = Y.reshape(N,1)\nprint(f'X shape: {X.shape}')\nprint(f'Y shape: {Y.shape}')","1e4d816c":"# Check the data type of your the values inside your numpy array\nX.dtype","232c176b":"# Change data type from float 64, which is the default datatype of numpy array, to float32, which is the default datatype of a torch tensor\nX = X.astype('float32')\nY = Y.astype('float32')\nprint(f'data type of X: {X.dtype}')\nprint(f'data type of Y: {Y.dtype}')","dfe1163c":"# Change data from numpy format to torch tensor\ninputs = torch.from_numpy(X)\ntargets = torch.from_numpy(Y)\nprint(f'type of X: {type(X)}')\nprint(f'type of inputs: {type(inputs)}')","27a43ce3":"# just to remeber what we are trying to map\n# given a certain input we want to predict the corresponding output\nfor i,t in zip(inputs,targets):\n    print('expected input          expected target')\n    print(f'{i.item():.4f}                        {t.item():.4f}')\n    print()","3b4516c9":"epochs = 300\nlosses = []\n\nfor i in range(epochs):\n    # reset the gradients parameter\n    optimizer.zero_grad()\n    \n    # forward propagate\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    \n    # append the loss to list of losses\n    losses.append(loss.item())\n    \n    # back propagate (calculate the gradients)\n    loss.backward()\n    \n    # apply gradient descent\n    # performs a parameter update based on the current gradient (stored in .grad attribute of a parameter) and the update rule\n    optimizer.step()\n    \n    print(f'Epoch {i+1}\/{epochs}, Loss: {loss.item():.4f}')\n    ","f6f435c0":"plt.plot(losses[50:100]);","1c0f42fd":"# Plot the graph\npredicted = model(inputs).detach().numpy()\nplt.scatter(X, Y, label='Original data')\nplt.plot(X, predicted, label='Fitted line')\nplt.legend()\nplt.show()","16adbc77":"# Compare obtained weight and bias with true slope and y-intercept\n\nw = model.weight.data.numpy()\nb = model.bias.data.numpy()\nprint(f'True Slope: {m}')\nprint(f'Obtained Weight: {w.squeeze():.3F}')\nprint()\nprint(f'True y-intercept: {c}')\nprint(f'Obtained y-intercept: {b.squeeze():.3F}')","83d07a39":"Our objective is to train a linear regression model using pytorch to output the line closest to the actual line while still being able to capture the maximum amount of variation created by the noise."}}