{"cell_type":{"7cafb185":"code","65df4ad3":"code","1892e20f":"code","33195eb1":"code","20c68aeb":"code","d158f58b":"code","50fedbf0":"code","713118bb":"code","fa86d598":"code","6398f82f":"code","6bde5990":"code","d87f0df4":"code","fc382667":"code","d0a6fcb1":"code","ade8b89d":"code","b4f1ed35":"code","b6d73672":"code","fc3c3cd8":"code","3a6848a3":"code","e7e4250a":"code","a0ddb277":"code","2ae461a5":"code","1b01c2a6":"code","a2d3696b":"code","410c2160":"code","3407d065":"code","fcd2cd86":"code","b971702d":"code","e0930805":"code","2af9ae2a":"code","40138a1b":"code","d27d98e1":"markdown","23ebed9e":"markdown","f00199e8":"markdown","064b4ebd":"markdown","664abaae":"markdown","f784691b":"markdown","10939edc":"markdown"},"source":{"7cafb185":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport geopandas as gpd\nfrom shapely import wkt\nfrom collections import Counter\nplt.style.use('fivethirtyeight')","65df4ad3":"# Read in wrangled NYC airbnb data from 2016-2020\ndf16 = pd.read_csv(\"..\/input\/math301-final-project-data\/airbnb16.csv\", index_col=0)\ndf17 = pd.read_csv(\"..\/input\/math301-final-project-data\/airbnb17.csv\", index_col=0)\ndf18 = pd.read_csv(\"..\/input\/math301-final-project-data\/airbnb18.csv\", index_col=0)\ndf19 = pd.read_csv(\"..\/input\/math301-final-project-data\/airbnb19.csv\", index_col=0)\ndf20 = pd.read_csv(\"..\/input\/math301-final-project-data\/airbnb20.csv\",  index_col=0)\n\n# Read in NYC Shape\/Geometry data\nnbhoods = pd.read_csv('..\/input\/nyctractshape\/nynta.csv')","1892e20f":"# Add year variable to all the data sources\nfor dataf,year in zip([df16,df17,df18,df19,df20], ['16','17','18','19','20']):\n    dataf['year'] = '20' + year","33195eb1":"# Merge data sources into one big dataset\ndf = pd.concat([df16,df17,df18,df19,df20])","20c68aeb":"df17.price.describe()","d158f58b":"# Upper limit for outlier detection (Q3 + IQR * 1.5) => Anything beyond this value will be considered an outlier for year of 2017\n165 + 1.5 * 100","50fedbf0":"df17[df17.price >=315].neighbourhood_group.value_counts() * 100 \/ len(df17[df17.price >=315])","713118bb":"(df17[df17.price >=315].neighbourhood.value_counts() * 100 \/ len(df17[df17.price >=315]))[:20]","fa86d598":"df20.price.describe()","6398f82f":"# Upper limit for outlier detection (Q3 + IQR * 1.5) => Anything beyond this value will be considered an outlier for year of 2020\n180 + 1.5 * 110","6bde5990":"df20[df20.price >=345].neighbourhood_group.value_counts() * 100 \/ len(df20[df20.price >=345])","d87f0df4":"(df20[df20.price >=345].neighbourhood.value_counts() * 100 \/ len(df20[df20.price >=345]))[:20]","fc382667":"# rename the \"NTAName\" column to \"neighborhood\" to make the column seem more straightforward to understand\nnbhoods.rename(columns={'NTAName':'neighbourhood'}, inplace=True)\n\n# Convert the geometry column text into well known text, allowing me to plot geometry accurately\nnbhoods['geom'] = nbhoods['the_geom'].apply(wkt.loads)\n\n# Convert dataframe to \"Geopandas GeoDataFrame\"\nnbhoods = gpd.GeoDataFrame(nbhoods, geometry='geom')","d0a6fcb1":"# Match each Airbnb location, and enable the \"data\" dataframe into a geopandas dataframe\ndf17_geo = gpd.GeoDataFrame(df17, geometry=gpd.points_from_xy(df17.longitude, df17.latitude))\n\n# Spatial join\njoined17 = gpd.sjoin(nbhoods, df17_geo, how='inner', op='intersects')","ade8b89d":"# Drop the second geometry column\njoined17.drop(columns='geom', inplace=True)\n\n# Rename the neighbourhood_left column to neighbourhood\njoined17.rename(columns={'neighbourhood_left':'neighbourhood'}, inplace=True)\n\n# Create a count of listings in each neighborhood (tract)\nnb_join_count17 = joined17.groupby('neighbourhood').agg('count').reset_index()\n\n# Attach count of listings onto nbhood map\nlistings_count17 = nbhoods.merge(nb_join_count17, on='neighbourhood')\n\n# Make an index column for colorbar later\nlistings_count17['index'] = range(0,len(listings_count17))","b4f1ed35":"# Plot 2017 Number of Listings Map Visualization\n\nfig,ax = plt.subplots(1,1, figsize=(10,10))\n\nbase = nbhoods.plot(color='white', edgecolor='black', ax=ax)\n\nlistings_count17.plot(column='index',cmap='plasma_r', ax=base, legend=True)\n\nplt.title('Number of Airbnb listings by tract in NYC in 2017')","b6d73672":"# Match each Airbnb location, and enable the \"data\" dataframe into a geopandas dataframe\ndf20_geo = gpd.GeoDataFrame(df20, geometry=gpd.points_from_xy(df20.longitude, df20.latitude))\n\n# Spatial join\njoined20 = gpd.sjoin(nbhoods, df20_geo, how='inner', op='intersects')","fc3c3cd8":"# Drop the second geometry column\njoined20.drop(columns='geom', inplace=True)\n\n# Rename the neighbourhood_left column to neighbourhood\njoined20.rename(columns={'neighbourhood_left':'neighbourhood'}, inplace=True)\n\n# Create a count of listings in each neighborhood (tract)\nnb_join_count20 = joined20.groupby('neighbourhood').agg('count').reset_index()\n\n# Attach count of listings onto nbhood map\nlistings_count20 = nbhoods.merge(nb_join_count20, on='neighbourhood')\n\n# Make an index column for colorbar later\nlistings_count20['index'] = range(0,len(listings_count20))","3a6848a3":"# Plot 2020 Number of Listings Map Visualization\n\nfig,ax = plt.subplots(1,1, figsize=(10,10))\n\nbase = nbhoods.plot(color='white', edgecolor='black', ax=ax)\n\nlistings_count20.plot(column='index',cmap='plasma_r', ax=base, legend=True)\n\nplt.title('Number of Airbnb listings by tract in NYC in 2020')","e7e4250a":"# Create variable for Minimum Revenue for each listing \ndf['revenue'] = df['price'] * df['minimum_nights'] * df['number_of_reviews']","a0ddb277":"df.groupby(['neighbourhood_group','year']).revenue.agg({'sum','mean','median'})","2ae461a5":"df17['revenue'] = df17['price'] * df17['minimum_nights'] * df17['number_of_reviews']\ndf20['revenue'] = df20['price'] * df20['minimum_nights'] * df20['number_of_reviews']","1b01c2a6":"df17.groupby(['neighbourhood']).revenue.agg({'sum','mean','median'}).sort_values('median', ascending=False)[:20]","a2d3696b":"df20.groupby(['neighbourhood']).revenue.agg({'sum','mean','median'}).sort_values('median', ascending=False)[:20]","410c2160":"# List of top 20 tracts with highest median min revenues in 2017 and 2020\n\ntop17_rev_2017 = df17.groupby(['neighbourhood']).revenue.agg({'sum','mean','median'}).sort_values('median', ascending=False)[:20].index.tolist()\ntop20_rev_2020 = df20.groupby(['neighbourhood']).revenue.agg({'sum','mean','median'}).sort_values('median', ascending=False)[:20].index.tolist()","3407d065":"top17_rev_2017_neighb = []\nfor tract in top17_rev_2017:\n    top17_rev_2017_neighb.append(list(set(df[df.neighbourhood == tract].neighbourhood_group))[0])","fcd2cd86":"pd.DataFrame([top17_rev_2017,top17_rev_2017_neighb]).T","b971702d":"Counter(top17_rev_2017_neighb)","e0930805":"top20_rev_2020_neighb = []\nfor tract in top20_rev_2020:\n    top20_rev_2020_neighb.append(list(set(df[df.neighbourhood == tract].neighbourhood_group))[0])","2af9ae2a":"pd.DataFrame([top20_rev_2020,top20_rev_2020_neighb]).T","40138a1b":"Counter(top20_rev_2020_neighb)","d27d98e1":"### Import Libraries, Read in Data and Merge into one big dataset with year indicator variable","23ebed9e":"##### 2020","f00199e8":"### Minimum Revenue = price x minimum number of nights x Demand (proxy: Number of Reviews)","064b4ebd":"##### 2020","664abaae":"##### 2017","f784691b":"### Number of Listings over time on a tract level (more granular than borough level)","10939edc":"### Outliers - Which listings and where are they? (e.g. luxurious penthouses)"}}