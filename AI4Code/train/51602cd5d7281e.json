{"cell_type":{"1fd782fa":"code","6eb740d9":"code","791e6830":"code","80a13909":"code","f262f004":"code","1e7144e0":"code","65321758":"code","d2cfc7cd":"code","96c0898a":"code","28b3dff6":"markdown"},"source":{"1fd782fa":"# Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n%matplotlib inline\n\n# Global Vectors for Word Representation\n# Source: https:\/\/nlp.stanford.edu\/projects\/glove\/\nglove_data = \"\/kaggle\/input\/glovedataw2v\/glove.6B.50d.txt\"","6eb740d9":"# Helper functions\n# Source: Coursera Website\ndef read_glove_vecs(glove_file):\n    with open(glove_file, 'r') as f:\n        words = set()\n        word_to_vec_map = {}\n        for line in f:\n            line = line.strip().split()\n            curr_word = line[0]\n            words.add(curr_word)\n            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n    return words, word_to_vec_map\n\ndef cosine_similarity(u, v):\n    distance = 0.0\n    dot = u @ v\n    norm_u = np.linalg.norm(u)  \n    norm_v = np.linalg.norm(v)\n    cosine_similarity = dot \/ (norm_u * norm_v)\n    return cosine_similarity","791e6830":"# Function for category selection from user \n# Increase the threshold number to include more words at the expense of run time\ndef get_category():\n    categories = [\n                ('art', 0.57),\n                ('biography', 0.51),\n                ('business', 0.61),\n                ('comics', 0.51),\n                ('computers', 0.53),\n                ('economics', 0.5),\n                ('health', 0.57),\n                ('history', 0.62),\n                ('literature', 0.52),\n                ('math', 0.46),\n                ('medical', 0.55),\n                ('music', 0.53),\n                ('philosophy', 0.51),\n                ('poetry', 0.49),\n                ('politics', 0.56),\n                ('religion', 0.53),\n                ('romance', 0.52),\n                ('science', 0.56),\n                ('sci-fi', 0.48),\n                ('sports', 0.59)]\n    \n    print (\"Available Categories: \")\n    for i,cat in enumerate(categories):\n        print ('  ', i+1, '. ', cat[0].title(), sep='')\n    print ('\\n')\n    \n    tot_cat = len(categories)\n    while True:\n        try:\n            cat_num = int(input('Select from above categories (1-' + str(tot_cat) + '): '))\n            assert 1 <= cat_num <= tot_cat\n        except ValueError:\n            print(\"Invalid entry! Please enter an integer. \")\n        except AssertionError:\n            print(\"Invalid entry! Please enter an integer between 1 and \", tot_cat, \": \", sep='')\n        else:\n            break\n        \n    cat_num -= 1\n    category = categories[cat_num]\n    print (\"Selected category: \", category[0].title())\n    return category","80a13909":"# Select \"close\" words to category based on cosine similarity\ndef compute_category_parameters(category):\n    print (\"Computing category associations (should be just few secs) .... \", end='')\n    cat = category[0]\n    cat_thresh = category[1]\n\n    curr_words = []\n    curr_words_w2v = []\n    cat_w2v = word_to_vec_map[cat]\n    for w in words:\n        w_w2v = word_to_vec_map[w]\n        if (abs(cosine_similarity(cat_w2v, w_w2v)) > cat_thresh):\n        # if (np.linalg.norm(cat_w2v - w_w2v) < cat_thresh):  \n            curr_words.append(w)\n            curr_words_w2v.append(w_w2v)\n\n    # print (len(curr_words))\n    print (\"Done\")\n    return curr_words, curr_words_w2v ","f262f004":"# Cluster words using k means clustering based word to vectors\ndef cluster_words(curr_words, curr_words_w2v, n_clusters):\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(curr_words_w2v)\n    labels = kmeans.predict(curr_words_w2v)\n    centroids = kmeans.cluster_centers_\n    centroids_labels = kmeans.predict(centroids)\n\n    centroids_words = []\n    for i,cnt in enumerate(centroids):\n        min_dist = 1000\n        min_j = -1\n        for j,w2v in enumerate(curr_words_w2v):\n            if (centroids_labels[i] == labels[j]):\n                dist = np.linalg.norm(cnt-w2v)\n                if (dist < min_dist):\n                    min_dist = dist\n                    min_j = j\n        centroids_words.append(curr_words[min_j])\n\n    assert len(centroids_words) == len(centroids)\n    return centroids_words, centroids_labels, labels","1e7144e0":"# Function to play game using above functions\ndef play_game(curr_words, curr_words_w2v):\n    print (\"\\nLet The Game Begin !!\")\n    game_ends = 0\n    print(\"Think of a word from the chosen category. Press any key when ready.\")\n    _ = input()\n    print (\"Great. Now please select the option closest to the chosen word.\")\n    \n    while not game_ends:\n        #print (\"Movie: \", \"movie\" in curr_words)\n        n_clusters = min(4,len(curr_words))\n        centroids_words, centroids_labels, labels = cluster_words(curr_words, curr_words_w2v, n_clusters)\n        print (\"Please select the closest word: \")\n        for i,w in enumerate(centroids_words):\n            print ('  ', i+1, '. ', w.title(), sep='')\n        print ('  ', n_clusters+1, '. Multiple \/ None of the above \/ Not sure', sep='')\n        \n        while True:\n            try:\n                selection = int(input())\n                assert 1 <= selection <= n_clusters+1\n            except ValueError:\n                print(\"Invalid entry! Please enter an integer.\")\n            except AssertionError:\n                print(\"Invalid entry! Please enter an integer between 1 and \", n_clusters+1, \".\", sep='')\n            else:\n                break\n\n        selection -= 1\n        if (selection < n_clusters):\n            new_words = []\n            new_words_w2v = []\n            selection_label = centroids_labels[selection]                \n            for i,label in enumerate(labels):\n                if (label == selection_label):\n                    new_words.append(curr_words[i])\n                    new_words_w2v.append(curr_words_w2v[i])\n            curr_words = new_words\n            curr_words_w2v = new_words_w2v\n            \n        if ((selection == n_clusters) & (len(curr_words) <= n_clusters)): \n            print (\"\\nAhha ... You are thinking\", curr_words[0].title(), \".\")\n            break\n            \n        if ((selection == n_clusters) & (len(curr_words) > n_clusters)): \n            for w in centroids_words:\n                idx = curr_words.index(w)\n                del curr_words[idx]\n                del curr_words_w2v[idx]\n\n        if (len(curr_words) == 1):\n            print (\"\\nAhha ... You are thinking\", curr_words[0].title(), \".\")\n            break\n\n    check = 'YN'\n    while ((check != 'Y') and (check != 'N')):\n        check = input(\"Correct? (Y\/N): \").title()\n    \n    if (check == 'Y'):\n        print (\"Awesome! Great game. Good Bye.\")\n    else:\n        print (\"Hmm! I guess I need to work further on my game :(. Good Bye.\")","65321758":"# Getting Glove word to vector map\nwords, word_to_vec_map = read_glove_vecs(glove_data)","d2cfc7cd":"# Getting category and words close to that category\ncategory = get_category()\ncurr_words, curr_words_w2v = compute_category_parameters(category)","96c0898a":"# Let us play the game\nplay_game(curr_words, curr_words_w2v)","28b3dff6":"DESCRIPTION: \n\nThis is a variant of a popular 19th century game \u201cTwenty Questions\u201d. In the traditional game, one player chooses a subject (object) and other players have to guess the chosen word by asking 20 or less \u201cYes or No\u201d questions. Here we present a simulator that plays against the humans. Human will choose a word and the simulator will try to guess it based on the answers given. Internally, the simulator uses Natural Language Processing (NLP) to select the words closer to the chosen category from the large dictionary based on the cosine similarity of word to vectors. Within the chosen category, words are then clustered using k-means clustering method. Eventually search is performed based on the user\u2019s selection of centroid, representing words from respective cluster."}}