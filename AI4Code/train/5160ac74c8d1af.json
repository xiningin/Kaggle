{"cell_type":{"ca8fda36":"code","3c4507e0":"code","84969a60":"code","81ce510a":"code","8b24e670":"code","dd16380c":"code","1c14741c":"code","c960b163":"code","f2fc0cd0":"code","df1f792b":"code","e1735b26":"code","9b44bb49":"code","31f7b0e0":"code","dac10593":"code","aa1931ba":"code","38a64278":"code","592546a7":"code","0970da5e":"code","dcb1f8ad":"code","f3b010b4":"code","8a3ac575":"code","178abc62":"code","178e2a46":"code","818e1f66":"code","b51ba59f":"code","16cd3478":"code","58ae1891":"markdown","a37c1de5":"markdown","e760b49f":"markdown","e063c90b":"markdown","90df39ae":"markdown","a54453e9":"markdown","c7e6d615":"markdown","e5792504":"markdown","195357c0":"markdown","79e97b8c":"markdown","edcb7c16":"markdown","2aaa70df":"markdown","96cae67e":"markdown","9486d85f":"markdown","e6985ef9":"markdown","d1f01a51":"markdown","38c9f34b":"markdown"},"source":{"ca8fda36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c4507e0":"dataset = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","84969a60":"dataset.head()","81ce510a":"dataset.shape","8b24e670":"dataset.info()","dd16380c":"dataset.columns","1c14741c":"dataset.describe()","c960b163":"dataset.isnull().sum()","f2fc0cd0":"import seaborn as sns \nimport matplotlib.pyplot as plt","df1f792b":"y = dataset['Class']\ny.value_counts()","e1735b26":"X = dataset.iloc[:,:-1]\nX.shape","9b44bb49":"count_classes = pd.value_counts(dataset['Class'], sort=True).sort_index()\ncount_classes.plot(kind='bar')\nplt.title(\"Fraud Class Histogram\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")\nplt.show()","31f7b0e0":"corr_mtx = dataset.corr()\nf, ax = plt.subplots(figsize=(16, 14))\nax = sns.heatmap(corr_mtx,annot=False,cmap=\"YlGnBu\")","dac10593":"print(corr_mtx['Class'].sort_values(ascending = False)) ","aa1931ba":"X.hist(figsize=(20,21))\nplt.show()","38a64278":"dataset_new = dataset.drop(columns=['Time', 'V1', 'V2', 'V3','V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18','V20','V22', 'V23','V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],axis=1)","592546a7":"dataset_new.sample(10)","0970da5e":"dataset_new[\"Class\"].value_counts()","dcb1f8ad":"from sklearn.model_selection import train_test_split \n\ny = dataset_new.iloc[:,-1]\nX = dataset_new.iloc[:,:-1]\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)","f3b010b4":"from sklearn.cluster import KMeans\n\nks = range(1, 6)\ninertias = []\nfor k in ks:\n    model = KMeans(n_clusters=k)\n    model.fit(X_train)\n    inertias.append(model.inertia_)\n    \nplt.plot(ks, inertias, '-o')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.xticks(ks)\nplt.show()","8a3ac575":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbors=4)\nk_labels = model.fit(X_train,y_train)","178abc62":"model.predict(X_test)","178e2a46":"model.score(X_test,y_test)","818e1f66":"from sklearn.model_selection import GridSearchCV\n#create new a knn model\nknn2 = KNeighborsClassifier()\n#create a dictionary of all values we want to test for n_neighbors\nparam_grid = {\"n_neighbors\": np.arange(1, 25)}\n#use gridsearch to test all values for n_neighbors\nknn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n#fit model to data\nknn_gscv.fit(X, y)","b51ba59f":"knn_gscv.predict(X_test)","16cd3478":"knn_gscv.best_score_","58ae1891":"We used GridSearch Cv algorithm and obtained the score of 99.89%.","a37c1de5":"'X' is our feature variable.","e760b49f":"# **DATA VISUALIZATION**","e063c90b":"Define the class labels as 'y'.","90df39ae":"Let us now, split the dataset into training and testing data.","a54453e9":"V11, V4 and V2 are the features which have the most correlation impact on Class, and there are attributes which are negatively correlated as well.","c7e6d615":"Clearly the data is totally unbalanced and is responsible for the decrement in the accuracy of our predictive model.","e5792504":"Lets look at correlation of features. \n\nThis will tell us how the features are correlated with each other. \n\nCorrelation gives us a intution on which variables are important, and have impact on the predicted class.","195357c0":"# **EXPLORING THE DATASET**","79e97b8c":"Check the mean score for the top performing value of n_neighbors.\n","edcb7c16":"Steps :\n1. Create a new KNN model.\n2. Create a dictionary of all values that we want to test for n_neighbors.\n3. Use gridsearch to test all values for n_neighbors.\n4. Fit the model to data.\n\n","2aaa70df":"Let us now, plot a histogram of all features to see the spread of data. This allows us to get a deeper understanding of the data.","96cae67e":"# **KNN CLASSIFICATION**","9486d85f":"# **GRID SEARCH CV ALGORITHM**","e6985ef9":"In order to find the number of neighboirs, we plot the **elbow plot**.","d1f01a51":"**We have obtained the accuracy of 99.90% using KNN Classifier.**","38c9f34b":"Now, let us try using the Grid Search CV Algorithm."}}