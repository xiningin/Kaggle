{"cell_type":{"c45890f9":"code","b367e150":"code","907106c9":"code","b0cf659e":"code","589802fb":"code","24d97696":"code","f657d728":"code","a443d2eb":"code","d15c892a":"code","808f4259":"code","9ba92895":"code","1a235eb2":"code","58b3e6e5":"code","24de4886":"code","ada00aad":"code","a74ca359":"code","bd02daed":"markdown","7637a35b":"markdown","6498972b":"markdown","f52946dc":"markdown","8da946c4":"markdown"},"source":{"c45890f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b367e150":"df = pd.read_csv('\/kaggle\/input\/ttc4900\/7allV03.csv')","907106c9":"df.tail()","b0cf659e":"df.isnull().all()","589802fb":"# you can also use this\n'''for each in range(len(df['category'])):\n    if df['category'][each] == \"siyaset \":\n        df['category'][each] = 0\n    elif  df['category'][each] == \"dunya \":\n        df['category'][each]= 1  \n    elif  df['category'][each] == \"ekonomi \":\n        df['category'][each] = 2  \n    elif  df['category'][each] == \"kultur \":\n        df['category'][each] = 3  \n    elif  df['category'][each] == \"saglik \":\n        df['category'][each] = 4\n    elif  df['category'][each] == \"spor \":\n        df['category'][each] = 5\n    elif  df['category'][each] == \"teknoloji \":\n        df['category'][each] = 6\ndf['category'].unique()\n'''","24d97696":"import re\nimport nltk\n\ndocs = df['text']\nlabels = df['category'].unique()\ndocs_list = []\nWPT = nltk.WordPunctTokenizer()\nstop_word_list = nltk.corpus.stopwords.words('turkish')\n\npattern = r\"[{}]\".format(\",.;:\")\n    \nfor doc in docs:\n    doc = re.sub(\"\\d+\",\" \",doc)\n    doc = re.sub(pattern,\"\",doc)\n    doc = doc.lower()\n\n\n    doc = WPT.tokenize(doc)\n    filtered_tokens = [item for item in doc if item not in stop_word_list]\n    lemma = nltk.WordNetLemmatizer()\n    lemma_word = [lemma.lemmatize(word) for word in filtered_tokens]\n\n    doc = \" \".join(lemma_word)\n\n    docs_list.append(doc)\n","f657d728":"# count vectorize method\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vectorize = CountVectorizer()                 # You can give max_feature=\nsparce_matrix = count_vectorize.fit_transform(docs_list).toarray()\n\n#print(f\"Most used words \",count_vectorize.get_feature_names())\n","a443d2eb":"# TFxIDF method\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vector = TfidfVectorizer(use_idf=True)\ntfidf_matrix = tfidf_vector.fit_transform(docs_list).toarray()\n\nterms = tfidf_vector.get_feature_names()\nTfidf_df = pd.DataFrame(np.round(tfidf_matrix,3), columns=terms)\n","d15c892a":"# data preparation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nattribution = [tfidf_matrix, sparce_matrix]\n\nfor item in attribution:\n    y = df.iloc[:,0]\n    x = item\n\n    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1,random_state = 42)\n\n    nb = GaussianNB()\n    nb.fit(x_train,y_train)\n\n\n    # prediction\n    y_pred = nb.predict(x_test)\n    #print(\"accuracy\",np.score(y_pred,y_test))\n    ACC = metrics.accuracy_score(y_test,y_pred)    \n    print(\"Accuracy = %\"+ str(ACC*100))\n\n\n","808f4259":"# Confusion Matrix\nimport scikitplot.metrics as splt\n\nsplt.plot_confusion_matrix(y_test, y_pred,figsize=(10,9))","9ba92895":"# If you want to use it with other classifiers...\n'''\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nmodels = []\n\nmodels.append(('Logistic Regression',LogisticRegression()))\nmodels.append(('Decision Tree',DecisionTreeClassifier()))\nmodels.append(('RandomForestClassifier',RandomForestClassifier()))\nmodels.append(('K-NN', KNeighborsClassifier()))\n\nfrom sklearn.metrics import classification_report\n\nfor name , model in models:\n    model = model.fit(x_train,y_train)\n    y_pred = model.predic(x_test)\n    print(\"%s -> ACC: %%%.2f\" % (name,\n                                metrics.accuracy_score(y_test,y_pred)*100))\n'''","1a235eb2":"# Most popular word\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud \nsentence = docs_list[1]\ntext = []\nfor i in sentence:\n    text.append(i)\ntext = ''.join(map(str, text)) \nwordcloud = WordCloud(width=6000, height=1000, max_font_size=300,background_color='white').generate(text)\nplt.figure(figsize=(20,17))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","58b3e6e5":"import gensim as GN\n\nsentences = GN.models.word2vec.LineSentence('\/kaggle\/input\/ttc4900\/7allV03.csv',max_sentence_length=5000)\n","24de4886":"model = GN.models.Word2Vec()\nmodel.build_vocab(sentences)\nmodel.train(sentences,total_examples=model.corpus_count, epochs= model.epochs)\n","ada00aad":"model.predict_output_word(sentence)","a74ca359":"# I don't understand why this code is not working\n#model.most_similar(positive=[\"sava\u015f\"],topn=3)","bd02daed":"* **As you can see Count-Vectorizer Method did a little better**\n","7637a35b":"## PreProcessing","6498972b":"## Conclusion\n* **As a result, we learn;**\n *  **NLTK, RE libraries**\n *   **CountVectorize method and TFxIDF method**\n *   **Some Classifier algorithms.**\n *   **Word2Vec method**\n *   **I will add new methods to this project in the future.** *\n \n \n * **If you found the content useful, don't forget to upvote and comment. Have a Kaggle day** *","f52946dc":"## BoW(Bag of Word)","8da946c4":"\n## Let's look at Word2Vec"}}