{"cell_type":{"ec7bc26a":"code","7747f056":"code","f15cec79":"code","ab6fb795":"code","665a28ba":"code","af33ab9e":"code","f606cd90":"code","d1dbb0e1":"code","76b0b669":"code","3d2d97dc":"code","f8f7ea78":"code","be221d7c":"code","76d7fbf5":"code","da98678c":"code","9103d7a6":"code","725d0152":"code","a4e5f157":"code","ebc9db9c":"code","137c377d":"markdown","7350f388":"markdown","ccd95ca5":"markdown","ca9c1790":"markdown","26457c30":"markdown","76bda412":"markdown","9e4173cb":"markdown","2f4aa410":"markdown","8edbced7":"markdown","9111d201":"markdown"},"source":{"ec7bc26a":"%matplotlib inline\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nprint('Tensorflow version:', tf.__version__)","7747f056":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\nx_train = x_train.astype(np.float32) \/ 255.0\nx_test = x_test.astype(np.float32) \/ 255.0","f15cec79":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i], cmap=plt.cm.binary)\nplt.show()","ab6fb795":"batch_size = 32\n# This dataset fills a buffer with buffer_size elements, \n#then randomly samples elements from this buffer, replacing the selected elements with new elements.\ndataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)\n#Combines consecutive elements of this dataset into batches.\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n#Creates a Dataset that prefetches elements from this dataset","665a28ba":"num_features = 100\n\ngenerator = keras.models.Sequential([\n    keras.layers.Dense(7 * 7 * 128, input_shape=[num_features]), # Increase nodes per layer for better performance\n    keras.layers.Reshape([7, 7, 128]),\n    keras.layers.BatchNormalization(),\n    \n    # Repeat these two layers for better performance\n    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding=\"same\", activation=\"selu\"),\n    keras.layers.BatchNormalization(),\n    \n    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding=\"same\", activation=\"tanh\"),\n])","af33ab9e":"# Helper Function\ndef show(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","f606cd90":"noise = tf.random.normal(shape=[1, num_features])\ngenerated_images = generator(noise, training=False)\nshow(generated_images, 1)","d1dbb0e1":"discriminator = keras.models.Sequential([\n    keras.layers.Conv2D(64, (5,5), (2,2), padding=\"same\", input_shape=[28, 28, 1]),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    \n    # Repeat these three layers for better performance\n    keras.layers.Conv2D(128, (5,5), (2,2), padding=\"same\"),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(1, activation='sigmoid')\n])","76b0b669":"decision = discriminator(generated_images)\nprint(decision)","3d2d97dc":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan = keras.models.Sequential([generator, discriminator])\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","f8f7ea78":"from IPython import display\nfrom tqdm import tqdm\nseed = tf.random.normal(shape=[batch_size, 100])","be221d7c":"from tqdm import tqdm\ndef train_dcgan(gan, dataset, batch_size, num_features, epochs=5):\n    generator, discriminator = gan.layers\n    for epoch in tqdm(range(epochs)):\n        print(\"Epoch {}\/{}\".format(epoch + 1, epochs))\n        for X_batch in dataset:\n            noise = tf.random.normal(shape=[batch_size, num_features])\n            generated_images = generator(noise)\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            noise = tf.random.normal(shape=[batch_size, num_features])\n            y2 = tf.constant([[1.]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, y2)\n            # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epoch + 1, seed)\n        \n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epochs, seed)","76d7fbf5":"## Source https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif\ndef generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(10,10))\n\n    for i in range(25):\n        plt.subplot(5, 5, i+1)\n        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","da98678c":"x_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1.","9103d7a6":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan)\ndataset = dataset.shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","725d0152":"%%time\ntrain_dcgan(gan, dataset, batch_size, num_features, epochs=10)","a4e5f157":"noise = tf.random.normal(shape=[batch_size, num_features])\ngenerated_images = generator(noise)\nshow(generated_images, 8)","ebc9db9c":"## Source: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif\nimport imageio\nimport glob\n\nanim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob.glob('image*.png')\n    filenames = sorted(filenames)\n    last = -1\n    for i,filename in enumerate(filenames):\n        frame = 2*(i)\n        if round(frame) > round(last):\n            last = frame\n        else:\n            continue\n        \n        image = imageio.imread(filename)\n        writer.append_data(image)\n        image = imageio.imread(filename)\n        writer.append_data(image)\n\nimport IPython\ndisplay.Image(filename=anim_file)","137c377d":"## Task 6: Compile the Deep Convolutional Generative Adversarial Network (DCGAN)","7350f388":"<h2 align=center>Generate Synthetic Images with Deep Convolutional Generative Adversarial Networks<\/h2>","ccd95ca5":"## Task 2: Load and Preprocess the Data","ca9c1790":"## Tak 5: Build the Discriminator Network for DCGAN","26457c30":"## Task 4: Build the Generator Network for DCGAN","76bda412":"## Task 3: Create Batches of Training Data","9e4173cb":"## Task 1: Project Overview and Import Libraries","2f4aa410":"## Task 7: Define Training Procedure","8edbced7":"## Task 9: Generate Synthetic Images with DCGAN","9111d201":"## Task 8: Train DCGAN"}}