{"cell_type":{"1bd8de7e":"code","ac735cb6":"code","c4dafa37":"code","7c976189":"code","71ffeb48":"code","61475261":"code","572e2981":"code","c60b1639":"code","08b8f284":"code","0f07ca9e":"code","c992a6c1":"code","fb80a480":"code","24169a54":"code","a7c5fab2":"code","3e8f49ae":"code","2ccdbc9e":"code","1ec8dd4e":"markdown","dedffea1":"markdown","d5bcb54c":"markdown","dd080957":"markdown","52911f8f":"markdown","149560c8":"markdown","94706022":"markdown","7e17cf24":"markdown","cdcaaf8a":"markdown","95219a4e":"markdown","c4b6664d":"markdown"},"source":{"1bd8de7e":"# Importing libraries for data research\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Importing dataset\ntrainData = pd.read_csv('..\/input\/assignment2data\/train.csv')\ntestData = pd.read_csv('..\/input\/assignment2data\/eval.csv')","ac735cb6":"trainDataNull = trainData.isnull().sum()\ntestDataNull = testData.isnull().sum()\n\nprint(\"Training Data Null Values: \\n\", trainDataNull)\nprint(\"\\n\")\nprint(\"Testing Data Null Values: \\n\", testDataNull)\n","c4dafa37":"sns.boxplot(data=trainData)","7c976189":"# First to see how many observations there are\nprint(\"The amount of observations: \", len(trainData))\nprint(\"\\n\")\n\n# Lets see how many times Cartoon violence and Mild Cartoon Violence equal each other\nprint(\"The amount of times MCV occurs: \", len(trainData.loc[trainData['mild_cartoon_violence'] == 1]))\nprint(\"The amount of times CV occurs: \", len(trainData.loc[trainData['cartoon_violence'] == 1]))\nprint(\"The amount of times CV and MCV equal, CV = 1: \", len(trainData.loc[(trainData['cartoon_violence'] == trainData['mild_cartoon_violence']) & (trainData['cartoon_violence'] == 1)]))\nprint(\"The amount of times CV and MCV equal, MCV = 1: \", len(trainData.loc[(trainData['cartoon_violence'] == trainData['mild_cartoon_violence']) & (trainData['mild_cartoon_violence'] == 1)]))\nprint(\"\\n\")\n\n# how many times strong language interacts with language; interesting that the column name is spelled incorrectly\nprint(\"Amount of time language occurs: \", len(trainData.loc[trainData['language'] == 1]))\nprint(\"Amount of time language occurs: \", len(trainData.loc[trainData['strong_janguage'] == 1]))\nprint(\"The amount of times SL equals L, L = 1: \", len(trainData.loc[(trainData['strong_janguage'] == trainData['language']) & trainData['language'] == 1]))\nprint(\"The amount of times SL equals L, SL = 1: \", len(trainData.loc[(trainData['strong_janguage'] == trainData['language']) & trainData['strong_janguage'] == 1]))\nprint(\"\\n\")\n\n# alcohol_reference = use of alcohol\nprint(\"Amount of times theres a reference to alcohol: \", len(trainData.loc[trainData['alcohol_reference'] == 1]))\nprint(\"Amount of times theres a use of alcohol: \", len(trainData.loc[trainData['use_of_alcohol'] == 1]))\nprint(\"The amount of times a reference to alcohol equals the use of alcohol\", len(trainData.loc[(trainData['alcohol_reference'] == trainData['use_of_alcohol']) & trainData['alcohol_reference'] == 1]))\nprint(\"\\n\")\n\n# how many times no descriptors applies\nprint(\"Amount of times no descriptors occurs: \", len(trainData.loc[trainData['no_descriptors'] == 1]))\nprint(\"\\n\")\n\n# how many times nudity and partial nudity occur\nprint(\"Amount of times nudity occurs: \", len(trainData.loc[trainData['nudity'] == 1]))\nprint(\"Amount of times partial nudity occurs: \", len(trainData.loc[trainData['partial_nudity'] == 1]))\nprint(\"Amount of time nudity occurs with partial nudity: \", len(trainData.loc[(trainData['nudity'] == trainData['partial_nudity']) & trainData['nudity'] == 1]))\nprint(\"\\n\")\n\n# mild blood and blood\nprint(\"Amount of times theres blood: \", len(trainData.loc[trainData['blood'] == 1]))\nprint(\"Amount of times theres mild blood: \", len(trainData.loc[trainData['mild_blood'] == 1]))\nprint(\"The amount of times a reference to alcohol equals the use of alcohol\", len(trainData.loc[(trainData['blood'] == trainData['mild_blood']) & trainData['blood'] == 1]))\nprint(\"\\n\")\n\ntitleUnique = trainData['title'].unique()\nprint(\"Amount of unique game titles: \", titleUnique.shape)\n\n\nfor x in trainData.drop(['id','title','console'], axis=1):\n    g = sns.FacetGrid(trainData.drop(['id','title','console'], axis=1), col='esrb_rating')\n    g.map(sns.histplot, x)\n    plt.show()\n\n","71ffeb48":"trainData.loc[trainData['esrb_rating'] == 'E', 'esrb_rating'] = 1\ntrainData.loc[trainData['esrb_rating'] == 'ET', 'esrb_rating'] = 2\ntrainData.loc[trainData['esrb_rating'] == 'T', 'esrb_rating'] = 3\ntrainData.loc[trainData['esrb_rating'] == 'M', 'esrb_rating'] = 4\n\ntrainData.head(20)","61475261":"eRatedCols = []\netRatedCols = []\ntRatedCols = []\nmRatedCols = []\n\n# finding which columns have values in E with less than 5 observations total\nfor x in trainData.drop(['id','title','console'], axis=1):\n    if (len(trainData.loc[(trainData[x] == 1) & (trainData['esrb_rating'] == 1)]) < 5):\n        #print(\"The amount of observations for \" + x + \" with a rating of E is less than 5\")\n        eRatedCols.append(x)\n\n# finding which columns have values in ET with less than 5 observations\nfor x in trainData.drop(['id','title','console'], axis=1):\n    if (len(trainData.loc[(trainData[x] == 1) & (trainData['esrb_rating'] == 2)]) < 5):\n        #print(\"The amount of observations for \" + x + \" with a rating of ET is less than 5\")\n        etRatedCols.append(x)\n        \n# finding which columns have values in T with less than 5 observations\nfor x in trainData.drop(['id','title','console'], axis=1):\n    if (len(trainData.loc[(trainData[x] == 1) & (trainData['esrb_rating'] == 3)]) < 5):\n        #print(\"The amount of observations for \" + x + \" with a rating of T is less than 5\")\n        tRatedCols.append(x)\n        \n# finding which columns have values in M with less than 5 observations\nfor x in trainData.drop(['id','title','console'], axis=1):\n    if (len(trainData.loc[(trainData[x] == 1) & (trainData['esrb_rating'] == 4)]) < 5):\n        #print(\"The amount of observations for \" + x + \" with a rating of M is less than 5\")\n        mRatedCols.append(x)\n\n# dropping those observations\nfor x in eRatedCols:\n    trainData.drop(trainData[(trainData[x] == 1) & (trainData['esrb_rating'] == 1)].index, inplace=True)\n    \nfor x in etRatedCols:\n    trainData.drop(trainData[(trainData[x] == 1) & (trainData['esrb_rating'] == 2)].index, inplace=True)\n    \nfor x in tRatedCols:\n    trainData.drop(trainData[(trainData[x] == 1) & (trainData['esrb_rating'] == 3)].index, inplace=True)\n    \nfor x in mRatedCols:\n    trainData.drop(trainData[(trainData[x] == 1) & (trainData['esrb_rating'] == 4)].index, inplace=True)\n    \n\nprint(len(trainData))","572e2981":"from sklearn.model_selection import train_test_split\n\nfeatures = []\nfor x in trainData.drop(['id', 'title', 'console', 'no_descriptors', 'esrb_rating'], axis=1):\n    features.append(x)\n    \nX = pd.get_dummies(trainData[features])\ny = (trainData['esrb_rating'])\ny=y.astype('int')\nevalData = pd.get_dummies(testData[features]) \n\nxTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.3)\nprint(type(yTrain))\n","c60b1639":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV","08b8f284":"# parameter grids for each model\nlrParams = {    \n    'C': [0.001,0.01,0.1,1,10,100,1000]    \n}\n\nsvcParams = {\n    'C': [0.001,0.01,0.1,1,10,100,1000]    \n}\n\ndtParams = {\n    'max_depth': np.arange(1,21),\n    'min_samples_leaf': np.arange(1,21)\n}\n\nrfParams = {\n    'max_depth': np.arange(1,21),\n    'n_estimators': [100,200,300,400,500],\n    'max_features': ['auto', 'sqrt'],\n    'criterion': ['gini', 'entropy']\n}\n\nknnParams = {\n    'n_neighbors': [1,3,5,7,9,11,13,15,17,19],\n    'weights': ['uniform', 'distance']\n}","0f07ca9e":"# now it's time to perform the gridsearch , I will use individual code blocks for this so it doesn't take ten years\n# this will be for the logristic regression algorithm\nlrGrid = GridSearchCV(LogisticRegression(multi_class = 'multinomial', solver='newton-cg'), param_grid = lrParams, scoring='accuracy')\nlrGrid.fit(xTrain, yTrain)\n#lr = LogisticRegression()\n#lr.fit(xTrain,yTrain)\nprint('The accuracy of the Logistic Regression Model is: ', lrGrid.best_score_)","c992a6c1":"# grid search for SVC\nsvcGrid = GridSearchCV(SVC(), param_grid = svcParams, scoring = 'accuracy')\nsvcGrid.fit(xTrain, yTrain)\n\nprint('The accuracy of the Support Vector Machine Classifier is: ', svcGrid.best_score_)","fb80a480":"# grid search for Decision Tree\ndtGrid = GridSearchCV(DecisionTreeClassifier(), param_grid = dtParams, scoring = 'accuracy')\ndtGrid.fit(xTrain,yTrain)\n\nprint('The accuracy of the Decision Tree is: ', dtGrid.best_score_)","24169a54":"# grid search for Random Forest\nrfGrid = GridSearchCV(RandomForestClassifier(), param_grid = rfParams, scoring = 'accuracy')\nrfGrid.fit(xTrain,yTrain)\n\nprint('The accuracy of the Random Forest is: ', rfGrid.best_score_)","a7c5fab2":"# grid search for K Nearest Neighbors\nknnGrid = GridSearchCV(KNeighborsClassifier(), param_grid = knnParams, scoring = 'accuracy')\nknnGrid.fit(xTrain,yTrain)\n\nprint('The accuracy of the Nearest Neighbors model is: ', knnGrid.best_score_)","3e8f49ae":"from sklearn.metrics import accuracy_score\n\n# predicting over the test split\nlrPrediction = lrGrid.predict(xTest)\nsvcPrediction = svcGrid.predict(xTest)\ndtPrediction = dtGrid.predict(xTest)\nrfPrediction = rfGrid.predict(xTest)\nknnPrediction = knnGrid.predict(xTest)\n\n# printing accuracy\nprint('Lr accuracy: ', accuracy_score(yTest,lrPrediction))\nprint('SVC accuracy: ', accuracy_score(yTest,svcPrediction))\nprint('DT accuracy: ', accuracy_score(yTest,dtPrediction))\nprint('RF accuracy: ', accuracy_score(yTest,rfPrediction))\nprint('KNN accuracy: ', accuracy_score(yTest,knnPrediction))\n\n# printing results\ndistLRDF = pd.DataFrame(lrGrid.cv_results_)\ndistLRDF.describe()\n\ndistSVCDF = pd.DataFrame(svcGrid.cv_results_)\ndistSVCDF.describe()\n\ndistDTDF = pd.DataFrame(dtGrid.cv_results_)\ndistDTDF.describe()\n\ndistRFDF = pd.DataFrame(rfGrid.cv_results_)\ndistRFDF.describe()\n\ndistKNNDF = pd.DataFrame(knnGrid.cv_results_)\ndistKNNDF.describe()","2ccdbc9e":"lrEvaluation = lrGrid.predict(pd.get_dummies(testData[features]))\n\noutput = pd.DataFrame({\n    'id': testData['id'],\n    'esrb_rating': lrEvaluation\n})\n\ntemp = ['J', 'E', 'ET', 'T', 'M']\nfor x in range(1,5):\n    output.loc[output['esrb_rating'] == x, 'esrb_rating'] = temp[x]\n    \noutput.to_csv('submission.csv', index=False)\nprint(output.to_string())","1ec8dd4e":"Okay so now our target vector is ordinal in nature.\n\nI think I've decided that I will eliminate individual observations that are less than 5 total in every category as those could possibly be errors, as not consider console or no descriptors as a feature since they don't seem to be reliable data points in any sense, or at least their documentation leads me to believe they are non-helpful.","dedffea1":"It seems as if it's possible that there is some overlap for some categories, however I cannot tell whether this holds true for all values. Let's explore this.","d5bcb54c":"This makes sense as all of the data is completely **categorical**, or **binary values**. The outliers will for example be something like the use of alcohol category only having 1 observation resulting in an M rating whereas it has a ton of observations supporting T and ET ratings.\n\n---\n#### Exploring data in order to determine what data will be useful for my models","dd080957":"# Assignment 2 ESRB Ratings\n\n#### Info\n* Julian Boaz\n* Due: 10\/24\/2021\n* Assignment 2\n\n---","52911f8f":"---\n#### Looking for missing data","149560c8":"---\n# Predictions\n","94706022":"# Building Models","7e17cf24":"Looks like our regression algorithm is going to be out best bet! Lets apply it to our evaluation set!","cdcaaf8a":"So it looks like I didn't erase that much data so I'm hoping I just removed a few outliers from the dataset here. I'm thinking that with decision trees, having these outliers erased could drastically improve my sets here. We shall see!\n\n---\n\n#### Splitting data set for training purposes","95219a4e":"Well, this is pretty odd. By reading the documentation on the dataset, or even simply reading the names of the categories, one might interpret that there would be a lot of overlap in terms of how these game titles are scored. However, there is a lot of *inconsistancy* that I've discovered throughout looking through these sets. Some of these categories have extremely low observations associated with them so are they even worth using as a feature for my models? Also some of these columns should intuitively overlap, like blood and mild blood. If there's blood in the game, mild blood should also be in the game, however, not all observations are reported this way, so it's likely that there are tons of different people rating games, and they all interpret the intructions differently on how to handle multiple overlapping categories. This leads me to believe perhaps I should try using different datasets, one where I attempt to group the categories, and one without.\n\nRegardless I think I will also make the `esrb_rating` a ordinal category instead of nominal in order to promote these models to interpret it differently.","c4b6664d":"It looks like theres no missing values which is great, now I'll look for outliers\n\n---\n#### Outliers\n"}}