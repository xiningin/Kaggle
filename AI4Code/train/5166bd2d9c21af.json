{"cell_type":{"7add9b00":"code","0b1a47bc":"code","325720ee":"code","05ae6c1d":"code","6e2d014c":"code","f09b2c1a":"code","25fd9263":"code","1088772f":"code","08e59b3d":"code","267ad2f4":"code","4bea0fbf":"code","d1c1c1f0":"code","e14722aa":"markdown","590a8409":"markdown","ea0b0934":"markdown","759cd97e":"markdown","994a896a":"markdown","69968c16":"markdown","d03ad067":"markdown","bd6f15b0":"markdown","5920bc5f":"markdown"},"source":{"7add9b00":"import matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport pandas as pd\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom scipy.linalg import eigh\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')","0b1a47bc":"def find_diffusion_matrix(X=None, alpha=0.15):\n    \"\"\"Function to find the diffusion matrix P\n        \n        >Parameters:\n        alpha - to be used for gaussian kernel function\n        X - feature matrix as numpy array\n        \n        >Returns:\n        P_prime, P, Di, K, D_left\n    \"\"\"\n    alpha = alpha\n        \n    dists = euclidean_distances(X, X)\n    K = np.exp(-dists**2 \/ alpha)\n    \n    r = np.sum(K, axis=0)\n    Di = np.diag(1\/r)\n    P = np.matmul(Di, K)\n    \n    D_right = np.diag((r)**0.5)\n    D_left = np.diag((r)**-0.5)\n    P_prime = np.matmul(D_right, np.matmul(P,D_left))\n\n    return P_prime, P, Di, K, D_left","325720ee":"def find_diffusion_map(P_prime, D_left, n_eign=3):\n    \"\"\"Function to find the diffusion coordinates in the diffusion space\n        \n        >Parameters:\n        P_prime - Symmetrized version of Diffusion Matrix P\n        D_left - D^{-1\/2} matrix\n        n_eigen - Number of eigen vectors to return. This is effectively \n                    the dimensions to keep in diffusion space.\n        \n        >Returns:\n        Diffusion_map as np.array object\n    \"\"\"   \n    n_eign = n_eign\n    \n    eigenValues, eigenVectors = eigh(P_prime)\n    idx = eigenValues.argsort()[::-1]\n    eigenValues = eigenValues[idx]\n    eigenVectors = eigenVectors[:,idx]\n    \n    diffusion_coordinates = np.matmul(D_left, eigenVectors)\n    \n    return diffusion_coordinates[:,:n_eign]","05ae6c1d":"# Reference: https:\/\/scikit-learn.org\/stable\/auto_examples\/manifold\/plot_compare_methods.html#\ndef make_plot(N=1000, rseed=42):\n    # Make a plot with \"HELLO\" text; save as PNG\n    fig, ax = plt.subplots(figsize=(4, 1))\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n    ax.axis('off')\n    ax.text(0.5, 0.4, 'S', va='center', ha='center', size=85)\n    fig.savefig('plot.png')\n    plt.close(fig)\n    fig.show()\n    # Open this PNG and draw random points from it\n    from matplotlib.image import imread\n    data = imread('plot.png')[::-1, :, 0].T\n    rng = np.random.RandomState(rseed)\n    X = rng.rand(5 * N, 2)\n    i, j = (X * data.shape).astype(int).T\n    mask = (data[i, j] < 1)\n    X = X[mask]\n    X[:, 0] *= (data.shape[0] \/ data.shape[1])\n    X = X[:N]\n    return X[np.argsort(X[:, 0])]","6e2d014c":"# Generate shape\nX = make_plot(3000)\ndata=go.Scatter(x=X[:, 0], y=X[:, 1], mode='markers', marker=dict(\n        size=3,color=X[:,1],opacity=1,colorscale='Viridis'))\nlayout=go.Layout(title_text=\"Original shape\", title_x=0.5, title_y=0.8,title_font_size=12)\nfig = go.Figure(data=[data], layout=layout)\nfig.update_layout(height=400, width=400,showlegend=False)\nfig.update_xaxes(showticklabels=False)\nfig.update_yaxes(showticklabels=False)\nfig.show()","f09b2c1a":"# Adding new dimension to the original geometric structure\nnewX = pd.DataFrame(X)\nnewX['dimension1'] = [random.uniform(0.1,0.5) for _ in range(len(X))]\nnewX = np.asarray(newX)","25fd9263":"def plot_3Dfigure(newX, title='Datapoints'):\n    data = go.Scatter3d(x=newX[:,0], y=newX[:,1], z=newX[:,2], mode='markers', marker=dict(\n            size=2,color=newX[:,1],opacity=0.7,colorscale='Viridis'))\n    layout = go.Layout(title_text=title,title_x=0.5,title_y=0.8,title_font_size=12)\n    fig = go.Figure(data=[data], layout=layout)\n    fig.update_layout(showlegend=False)\n    fig.update_xaxes(showticklabels=False)\n    fig.update_yaxes(showticklabels=False)\n    fig.update_layout(scene = dict(\n                    xaxis = dict(title= '', ticks= '', showticklabels= False,),\n                    yaxis = dict(title= '', ticks= '', showticklabels= False,),\n                    zaxis = dict(title= '', ticks= '', showticklabels= False,),\n                    ))\n                  \n    fig.show()","1088772f":"plot_3Dfigure(newX, title='Synthetic 3D Datapoints')","08e59b3d":"def plot_2Dsub_figures(d_map, alpha_values, title='Diffused points'):\n    subplot_titles=[f'\u03b1={round(a,4)}' for a in alpha_values]\n    fig = make_subplots(rows=2, cols=5,subplot_titles=subplot_titles)\n    for i in range(1,3):\n        for j in range(1,6):\n            dmap_idx = i+j-1\n            fig.add_trace(\n                go.Scatter(x=d_map[dmap_idx][:,0], y=d_map[dmap_idx][:,1], mode='markers', marker=dict(\n                size=3,color=d_map[dmap_idx][:,1],opacity=0.8,colorscale='Viridis')),row=i, col=j)\n\n    fig.update_layout(title_text=title, title_x=0.5)\n    fig.update_xaxes(showticklabels=False)\n    fig.update_yaxes(showticklabels=False)\n    fig.update_layout(height=500, width=1000, showlegend=False)\n    fig.show()","267ad2f4":"def apply_diffusions(alpha_start=0.001, alpha_end= 0.009, title='Diffused points'):\n    d_maps = []\n    alpha_values = np.linspace(alpha_start, alpha_end, 10)\n    for alpha in alpha_values:\n        P_prime, P, Di, K, D_left = find_diffusion_matrix(newX, alpha=alpha)\n        d_maps.append(find_diffusion_map(P_prime, D_left, n_eign=2))\n    return d_maps, alpha_values\n","4bea0fbf":"d_maps, alpha_values = apply_diffusions(0.01, 0.09)\nplot_2Dsub_figures(d_maps,alpha_values)","d1c1c1f0":"d_maps, alpha_values = apply_diffusions(0.1, 0.9)\nplot_2Dsub_figures(d_maps,alpha_values)","e14722aa":"Now we will apply diffusion map with 10 alpha values between 0.01 and 0.09 and see the outcome","590a8409":"As it is seen the above alpha values did capture the structure. If we play around with different alpha values as shown below, we get to see a closer structure to the original one. ","ea0b0934":"Essentially, above two functions will create diffusion matrix first and then the diffusion map. Diffusion map is the transformed coordinates in diffusion space. If you would like to dig deeper into the theory behind, the paper has explained it pretty neatly. For a quick overview, the Wikipedia article also explains the theory well. (see references)","759cd97e":"To demonstrate the diffusion map, let's take a top-down approach. First we will create a 3D geometric shape and then diffuse it to 2D to see if it captures the structure in 2D.","994a896a":"Author\n------\n- Name: Rahul Raj\n- Contact: twitter.com\/rahulrajpl\n- Website: https:\/\/randomwalk.in\n- Copyright: \n\nThe MIT License (MIT)\n\nCopyright (c) 2020 Rahul Raj\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and\/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n","69968c16":"Let's begin by importing necessary libraries we will be using in this program. However, diffusion map algorithm will be handcoded.","d03ad067":"First stage in Diffusion Map is the creation of **Diffusion Matrix**. The core idea is a time-dependent diffusion process, which is nothing but a random walk on the dataset where each hop has a probability associated with it. When the diffusion process runs for a time t, we get different probabilities of various paths it can take to calculate the distance over the underlying geometric structure. Mathematically, we call this the steady-state probability of the Markov Chain.","bd6f15b0":"References\n-----------\n\n[1] Manifold Learning methods in Scikit-Learn (https:\/\/scikit-learn.org\/stable\/modules\/manifold.html)\n\n[2] https:\/\/inside.mines.edu\/~whereman\/talks\/delaPorte-Herbst-Hereman-vanderWalt-DiffusionMaps-PRASA2008.pdf\n\n[3] https:\/\/en.wikipedia.org\/wiki\/Diffusion_map","5920bc5f":"### Diffusion Maps for Non-linear Dimensionality Reduction\n\n\u2018Curse of dimensionality\u2019 is a well-known problem in Data Science, which often causes poor performance, inaccurate results, and, most importantly, a similarity measure break-down. The primary cause of this is because high dimensional datasets are typically sparse, and often a lower-dimensional structure or \u2018Manifold\u2019 would embed this data. So there is a non-linear relationship among the variables (or features or dimensions), which we need to learn to compute better similarity.\n\nManifold learning is an approach to non-linear dimensionality reduction. The basis for algorithms in manifold learning is that the dimensionality of many data sets is only artificially high 1. In this blog, we learn one of the many techniques in manifold learning called Diffusion Maps. The key idea is that Euclidean Distance, which is the most common measure of similarity, is meaningful only \u2018locally.\u2019 Therefore, assuming there is a lower-dimensional structure or manifold to the data, it would be appropriate to measure similarity over this structure rather than in the Euclidean space itself.\n\nThis notebook aims to introduce one of the manifold learning techniques called Diffusion Map. This technique enables us to understand the underlying geometric structure of high dimensional dataset as well as to reduce the dimensions, if required, by neatly capturing the non-linear relationships between the original dimensions."}}