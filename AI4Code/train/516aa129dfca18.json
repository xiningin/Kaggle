{"cell_type":{"2a639bd9":"code","1f812c4f":"code","784d5e00":"code","cf6f80fa":"code","65eba197":"code","e62abbe5":"code","539af355":"code","2bf5289c":"code","dbe0f136":"code","1ef77169":"code","fc42e04e":"code","e6f81cf6":"code","202cbb97":"code","67b0a120":"code","d3e27604":"code","9599190b":"code","24cd83e3":"code","20804865":"code","5f92669c":"code","ae16478a":"code","92dde9c4":"code","6a4f8751":"code","167f2b1f":"code","b2b76543":"code","99935daa":"code","4ccc67c0":"markdown","099b8a5e":"markdown","53f8c1b0":"markdown","240a9e38":"markdown"},"source":{"2a639bd9":"import pandas as pd\nimport random\nimport os\nimport numpy as np\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import text\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model\nfrom keras.layers import Embedding, Flatten, Dense, LSTM, Dropout, Bidirectional, Conv1D, MaxPooling1D, Input, concatenate\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","1f812c4f":"random.seed(42)","784d5e00":"df = pd.read_csv(\"..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv\")","cf6f80fa":"df.head()","65eba197":"df = df.fillna(\"\")","e62abbe5":"df[\"seq_input\"] = df.apply(lambda x: x[\"Title\"] + \" \" + x[\"Review Text\"], axis=1)","539af355":"df[\"split\"] = df.apply(lambda x: \"train\" if random.randrange(0,100) > 10 else \"valid\", axis=1)","2bf5289c":"df[\"split\"].value_counts()","dbe0f136":"df[\"nonseq_input\"] = df.apply(lambda x: [x[\"Age\"]] + [x[\"Rating\"]], axis=1)","1ef77169":"df_train = df[df[\"split\"] == \"train\"]\ndf_val = df[df[\"split\"] == \"valid\"]","fc42e04e":"tokenizer=Tokenizer(oov_token=\"'oov'\")\ntokenizer.fit_on_texts(df_train[\"seq_input\"])","e6f81cf6":"maxlen = 200\ntrain_X = pad_sequences(tokenizer.texts_to_sequences(df_train[\"seq_input\"]), maxlen=maxlen)\nval_X = pad_sequences(tokenizer.texts_to_sequences(df_val[\"seq_input\"]), maxlen=maxlen)","202cbb97":"train_Y = df_train[\"Recommended IND\"]\nval_Y = df_val[\"Recommended IND\"]","67b0a120":"glove_dir=\"\/kaggle\/input\/glove-global-vectors-for-word-representation\/\"\n\nembedding_index = {}\nf = open(os.path.join(glove_dir,'glove.6B.100d.txt'),encoding='utf8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:],dtype='float32')\n    embedding_index[word] = coefs\nf.close()\nprint('Found %s word vectors ' % len(embedding_index))","d3e27604":"max_words = len(tokenizer.word_index) + 1\nembedding_dim = 100\nembedding_matrix = np.zeros((max_words,embedding_dim))\n\nfor word, idx in tokenizer.word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[idx]=embedding_vector","9599190b":"inp = Input(shape=(maxlen,))\nx = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False)(inp)\nx = Bidirectional(LSTM(32))(x)\nx = Dense(32, activation=\"relu\")(x)\nout = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=out)\nmodel.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\nprint(model.summary())","24cd83e3":"model.fit(train_X, train_Y, epochs=30, batch_size=512, validation_data=(val_X, val_Y))","20804865":"val_pred = [p > 0.5 for p in model.predict(val_X)]","5f92669c":"print(classification_report(val_Y, val_pred))","ae16478a":"df_train.corr()","92dde9c4":"train_X_nonseq = np.asarray(list(df_train[\"nonseq_input\"]))\nval_X_nonseq = np.asarray(list(df_val[\"nonseq_input\"]))","6a4f8751":"seq_inp = Input(shape=(maxlen,))\nnonseq_inp = Input(shape=(train_X_nonseq.shape[1],))\nx = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False)(seq_inp)\nx = Bidirectional(LSTM(32))(x)\nx = concatenate([x, nonseq_inp])\nx = Dense(32, activation=\"relu\")(x)\nout = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=[seq_inp, nonseq_inp], outputs=out)\nmodel.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\nprint(model.summary())","167f2b1f":"model.fit([train_X, train_X_nonseq], train_Y, epochs=30, batch_size=512, validation_data=([val_X, val_X_nonseq], val_Y))","b2b76543":"val_pred = [p > 0.5 for p in model.predict([val_X, val_X_nonseq])]","99935daa":"print(classification_report(val_Y, val_pred))","4ccc67c0":"## Sequential + non-sequential features\nPredicting whether a customer recommends the product based on his text review, age, and provided rating.\n\nThe rating obviously strongly correlates with the recommendation. Normally, we would probably not have such a strong feature.","099b8a5e":"#### A code for medium article \"Enriching Sequential LSTM Model with Non-Sequential Features\".\nhttps:\/\/pub.towardsai.net\/enriching-sequential-lstm-model-with-non-sequential-features-7224b5262132","53f8c1b0":"## Preprocessing","240a9e38":"## Sequential features only\nPredicting whether a customer recommends the product based solely on his text review."}}