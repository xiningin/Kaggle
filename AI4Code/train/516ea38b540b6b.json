{"cell_type":{"cb7a7eb6":"code","f30894e3":"code","725be47c":"code","11c8cb2b":"code","ba6a9d58":"code","03cef668":"code","1486db33":"code","adff0adb":"code","0b114c6c":"code","42aa6528":"code","370cd8df":"code","990783da":"code","8e7ea01b":"code","c76379c2":"code","d3b2c03d":"code","4391097c":"code","20da7690":"code","ed6dcd88":"code","720e6f79":"code","098b05b8":"code","03242942":"markdown","e4aedca1":"markdown","69c52f11":"markdown","b4a8cf14":"markdown","8147d38a":"markdown","3a9edbc7":"markdown","19533af9":"markdown","6bcd1bae":"markdown","9a4ea059":"markdown","0cc3393e":"markdown","85fe9493":"markdown","dbdd89cd":"markdown","8ca5412c":"markdown","a8fe1010":"markdown","b9030b8d":"markdown","4aea3844":"markdown"},"source":{"cb7a7eb6":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import binary_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndevices = tf.config.experimental.list_physical_devices('GPU')\nprint(\"Num gpu available:\", len(devices))","f30894e3":"train_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'","725be47c":"train_batches = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True) \\\n    .flow_from_directory(directory = train_folder, target_size = (224,224), classes = ['NORMAL','PNEUMONIA'], class_mode = 'binary', batch_size = 32)","11c8cb2b":"test_batches = ImageDataGenerator(rescale = 1.\/255) \\\n    .flow_from_directory(directory = test_folder, target_size = (224,224), classes = ['NORMAL','PNEUMONIA'], class_mode = 'binary', batch_size = 32, shuffle = False)\nval_batches = ImageDataGenerator(rescale = 1.\/255) \\\n    .flow_from_directory(directory = val_folder, target_size = (224,224), classes = ['NORMAL','PNEUMONIA'], class_mode = 'binary', batch_size = 8)","ba6a9d58":"imgs, labels = next(train_batches)","03cef668":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1,10, figsize = (50,50))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nplotImages(imgs)\nprint(labels)","1486db33":"# Build the sequential CNN\ncnn = Sequential([\n    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n    MaxPool2D(pool_size = (2, 2)),\n    Dropout(.2),\n    Conv2D(32, (3, 3), activation=\"relu\"),\n    MaxPool2D(pool_size = (2, 2)),\n    Dropout(.5),\n    Conv2D(64, (3, 3), activation=\"relu\"),\n    Flatten(),\n    Dense(activation = 'relu', units = 128),\n    Dense(activation = 'relu', units = 64),\n    Dense(activation = 'sigmoid', units = 1)\n    \n])\n\n# Compile the network\n\ncnn.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])","adff0adb":"cnn.summary()","0b114c6c":"cnn.fit(x=train_batches,\n        steps_per_epoch = 162,\n        epochs = 10,\n        validation_data = val_batches,\n        validation_steps = 2,\n        verbose = 2)","42aa6528":"cnn.evaluate(test_batches)","370cd8df":"vgg = tf.keras.applications.vgg16.VGG16()","990783da":"type(vgg)","8e7ea01b":"vgg.summary()","c76379c2":"model = Sequential()\nfor layer in vgg.layers[:-1]:\n    model.add(layer)\n\nfor layer in model.layers:\n    layer.trainable = False","d3b2c03d":"model.add(Dense(units = 2, activation = 'softmax'))","4391097c":"model.summary()","20da7690":"model.compile(optimizer= Adam(learning_rate = .001), loss = 'categorical_crossentropy', metrics = ['accuracy'])","ed6dcd88":"train_batches_vgg = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory = train_folder, target_size = (224,224), classes = ['NORMAL','PNEUMONIA'],batch_size = 32)\n\ntest_batches_vgg = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory = test_folder, target_size = (224,224), classes = ['NORMAL','PNEUMONIA'], batch_size = 32, shuffle = False)\n\nval_batches_vgg = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory = val_folder, target_size = (224,224), classes = ['NORMAL','PNEUMONIA'], batch_size = 32)\n\n\n\n\n","720e6f79":"model.fit(x=train_batches_vgg,\n        steps_per_epoch = 162,\n        epochs = 10,\n        validation_data = val_batches_vgg,\n        validation_steps = 2,\n        verbose = 2)","098b05b8":"model.evaluate(test_batches_vgg)","03242942":"Below code creates a training batch. It uses ImageDataGenerator with simple preprocessins. We get the images using the flow from directory, declaring target size of 224x224 for the images we will be processing. Classes in this case is our classifications, either pneumonia or normal.","e4aedca1":"Not really sure why the validation accuracy bounces around so much, yet the model generalizes well enough on the test data. My guess is limited validation set.","69c52f11":"Take a look at our model now and note the trainable parameters. It's much lower, due to us freezing the vast majority and only dealing with the last layer weights now.","b4a8cf14":"Lets prepare our data for the vgg model","8147d38a":"Now we're going to add the prediction layer that suits our use case, in this case a dense layer with output of 2. We'll use the sigmoid activation function.","3a9edbc7":"This model was created to solve ImageNet, which has 1000 classifiers. We're going to augment it now to fit our problem that has 2 classifiers, NORMAL and PNEUMONIA. Below code block, we're taking off the predictions layer, and then going to freeze the remaining model parameters to not be trainable.","19533af9":"## Evaluation of the model versus the test data","6bcd1bae":"Because we are using the ImageDataGenerator to create a directory iterator where we're storing out training\/test data, we need to use an extra parameter when we're using the model.fit() functionality. Steps_per_epoch is how many batches of samples we want to train on before declaring one epoch finished.\n\nTypically you use # of examples in training set\/batch size. If you have 100 examples, 20 batches of 5 images, you use 20 steps per epoch.\n\nIf we're passing validation data, we need to specify validation steps. This works the same way, except in regard to validation set.","9a4ea059":"This function is directly from tensorflow's website. ","0cc3393e":"As you can see, the model loss decreases over time and the train accuracy decreases. Validation accuracy is all over the place.","85fe9493":"We're going to grab a single batch using the next() function for visualization","dbdd89cd":"## Bonus: Applying vgg-16","8ca5412c":"## Data Preparation","a8fe1010":"Declare your folders where your data is stored","b9030b8d":"## Building and Training Convolutional Neural Network","4aea3844":"Now create test and validation sets the same way, except don't shuffle the test"}}