{"cell_type":{"8f0c0045":"code","8a2e5404":"code","1ffb8755":"code","dea3c3d1":"code","c2a06816":"code","5e2ee784":"code","25051e45":"code","dffaa45e":"code","43a05b39":"code","79df92c3":"code","58e36c44":"code","eb7a307b":"code","c06b24d9":"code","531fb910":"code","e84fd9bc":"code","4c6f0056":"code","157b3b10":"code","7bb493ef":"code","42c43665":"code","a27eac11":"code","40293fa1":"code","0280e08d":"code","0c16863e":"code","c526f6e4":"code","e2750d2d":"code","cf4dc8f8":"code","71d20c2d":"code","fc654812":"code","a21f50a5":"code","6c43b926":"code","5422bd19":"code","1b7dea2a":"code","1e7dce91":"code","2a30d701":"code","29696f3f":"code","02866989":"code","a1ec9603":"code","d2b37172":"code","35c89956":"code","42100e00":"code","769147d7":"code","4fa6b3a5":"code","908d0a13":"code","0f2d409f":"code","88c76c3f":"code","49ec367e":"code","e9a06704":"code","5a162bb9":"code","bd446719":"code","5f56f612":"code","65a23ddc":"code","fb0ab5fc":"code","b1146643":"code","dec53468":"code","e1797a20":"code","f5f5661d":"code","3c081623":"code","a0d6a11d":"code","6fef68a2":"markdown","19408eb9":"markdown","62ed6edd":"markdown","332a3b5d":"markdown","daa605ec":"markdown","91fe1a38":"markdown","74334927":"markdown","42f38c11":"markdown","ccf6d070":"markdown","5f65740c":"markdown","f5d1b7d9":"markdown","46b78337":"markdown","e045870c":"markdown","a69333e9":"markdown","75e627de":"markdown","68020f6e":"markdown","ad12e6bb":"markdown","f40475cf":"markdown","37e1d9d9":"markdown","f0c6b106":"markdown","fc7e8f0e":"markdown","9d3bf45b":"markdown","02a530d0":"markdown","54a2308b":"markdown","2f08ba07":"markdown","31620d1d":"markdown","1fe689bf":"markdown","7c57dced":"markdown","bba14aad":"markdown","f951b3a5":"markdown","aa6cb7c6":"markdown","1fb89cd2":"markdown","56aa887b":"markdown","d0bcd579":"markdown","5f7d1bda":"markdown","04363b20":"markdown","aaa60698":"markdown","3c1e46cb":"markdown","9cd1776a":"markdown"},"source":{"8f0c0045":"# Import Necessary Libraries\nimport warnings\nwarnings.filterwarnings('ignore')","8a2e5404":"import os\nimport re\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport random\nimport tensorflow as tf\nimport cv2\nimport sklearn\n\ntf.compat.v1.disable_eager_execution()\n\nfrom tqdm import tqdm\nfrom skimage import io\nfrom itertools import chain\nfrom glob import glob\nfrom keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model, load_model\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, CSVLogger\nfrom tensorflow.keras.metrics import AUC, Precision, Recall\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\n%matplotlib inline\nrandom.seed(2020)","1ffb8755":"# Define Path to the Chest-Xray Data Directory\nDATA_DIR = 'G:\/Downloads\/archive\/chest_xray'\n\n# Training Data Directory\nTRAIN_DIR = os.path.join(DATA_DIR,'train')\n\n# Validation Data Directory\nVALID_DIR = os.path.join(DATA_DIR,'val')\n\n# Test Data Directory\nTEST_DIR = os.path.join(DATA_DIR,'test')","dea3c3d1":"# list of normal and pneumonia images\n\n#train set\ntrain_normal = os.listdir(TRAIN_DIR+'\/NORMAL')\ntrain_pneumonia = os.listdir(TRAIN_DIR+'\/PNEUMONIA')\n\n# validation set\nval_normal = os.listdir(VALID_DIR+'\/NORMAL')\nval_pneumonia = os.listdir(VALID_DIR+'\/PNEUMONIA')\n\n# test set\ntest_normal = os.listdir(TEST_DIR+'\/NORMAL')\ntest_pneumonia = os.listdir(TEST_DIR+'\/PNEUMONIA')","c2a06816":"# print counts of normal and pneumonia images\n# train set\nprint(f\"Number of Pneumonia cases in train set: {len(train_pneumonia)}\")\nprint(f\"Number of Normal cases in train set: {len(train_normal)}\")\nprint()\n\n# validation set\nprint(f\"Number of Pneumonia cases in valid set: {len(val_pneumonia)}\")\nprint(f\"Number of Normal cases in valid set: {len(val_normal)}\")\nprint()\n\n# test set\nprint(f\"Number of Pneumonia cases in test set: {len(test_pneumonia)}\")\nprint(f\"Number of Normal cases in test set: {len(test_normal)}\")","5e2ee784":"labels = ['train', 'valid', 'test']\npneumonia = [len(train_pneumonia), len(val_pneumonia), len(test_pneumonia)]\nnormal = [len(train_normal), len(val_normal), len(test_normal)]\n\nx = np.arange(len(labels))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width\/2, pneumonia, width, label='Pneumonia')\nrects2 = ax.bar(x + width\/2, normal, width, label='Normal')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Count')\nax.set_title('Frequency of each dataset')\nax.set_xticks(x)\nax.set_ylim([0, 4200])\nax.set_xticklabels(labels)\nax.legend()\n\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height() \n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nautolabel(rects2)\n\nfig.tight_layout()\n\nplt.show()","25051e45":"# Normal X-Ray images\nnum_samples = 3\ntrain_normal_samples = random.sample(train_normal, num_samples)\n\nfig, axes = plt.subplots(1, num_samples, figsize=(15, 4))\nfor path, ax in zip(train_normal_samples, axes):\n    img = plt.imread(TRAIN_DIR+'\/NORMAL\/'+path)\n    ax.imshow(img, cmap='gray')\n    ax.axis('off')\n    ax.set_aspect('auto')\n    ax.title.set_text('NORMAL')\nplt.show()","dffaa45e":"# Pneumonia X-Ray images\ntrain_pneumonia_samples = random.sample(train_pneumonia, num_samples)\n\nfig, axes = plt.subplots(1, num_samples, figsize=(15, 4))\nfor path, ax in zip(train_pneumonia_samples, axes):\n    img = plt.imread(TRAIN_DIR+'\/PNEUMONIA\/'+path)\n    ax.imshow(img, cmap='gray')\n    ax.axis('off')\n    ax.set_aspect('auto')\n    ax.title.set_text('PNEUMONIA')\nplt.show()","43a05b39":"CLASS_NAMES = np.array([class_name.split(os.path.sep)[-1] for class_name in glob(os.path.join(TRAIN_DIR,\"*\"))])\nCLASS_NAMES","79df92c3":"# Pixel Intensity Distribution of Pneumonia Positive Cases\ntrain_pneumonia_images = random.sample(train_pneumonia,100)\npneumonia_pixel = []\nfor img in train_pneumonia_images:\n    img = io.imread(os.path.join(TRAIN_DIR,\"PNEUMONIA\",img)).ravel()\n    # Remove Background Noise\n    img_mask = [True if 35 < pixel < 255 else False for pixel in img]\n    pneumonia_pixel.extend(img[img_mask])\nprint(f\"Mean: {round(np.mean(pneumonia_pixel), 2)}, STD: {round(np.std(pneumonia_pixel), 2)}\")\npneumonia_dist = plt.hist(pneumonia_pixel, bins=256);","58e36c44":"# Pixel Intensity Distribution of Pneumonia Negative Cases\ntrain_non_pneumonia_images = random.sample(train_normal,100)\nnon_pneumonia_pixel = []\nfor img in train_non_pneumonia_images:\n    img = io.imread(os.path.join(TRAIN_DIR,\"NORMAL\",img)).ravel()\n    # Remove Background Noise\n    img_mask = [True if 35 < pixel < 255 else False for pixel in img]\n    non_pneumonia_pixel.extend(img[img_mask])\nprint(f\"Mean: {round(np.mean(non_pneumonia_pixel), 2)}, STD: {round(np.std(non_pneumonia_pixel), 2)}\")\nnon_pneumonia_dist = plt.hist(non_pneumonia_pixel, bins=256);","eb7a307b":"plt.savefig(f'Images\/pneumonia_dist.png')\nplt.savefig(f'Images\/non_pneumonia_dist.png')","c06b24d9":"# Investigate a Single Image\n# Get the First Pneumonia Image that was in the DataFrame\nsample_img = os.path.join(TRAIN_DIR,'PNEUMONIA',train_pneumonia[0])\nraw_image = plt.imread(sample_img)\nplt.imshow(raw_image, cmap='gray')\nplt.colorbar();\nplt.title('Raw Pneumonia Positive Chest X-Ray');","531fb910":"print(f\"The Dimension of the Image are {raw_image.shape[0]} pixels width and {raw_image.shape[1]} pixels height, one single color channel.\")\nprint(f\"The Maximum pixel value is {raw_image.max():.4f} and the minimum is {raw_image.min():.4f}\")\nprint(f\"The Mean Value of the Pixels is {raw_image.mean():.4f} and the Standard Deviation is {raw_image.std():.4f}\")","e84fd9bc":"# Plot a Histogram of the distribution\nsns.set()\nsns.distplot(raw_image.ravel(), label=f\"Pixel Mean {np.mean(raw_image):.4f} & Standard Deviation {np.std(raw_image):.4f}\", kde=False)\nplt.legend(loc='upper center')\nplt.title('Distribution of Pixels Intensities in the Image')\nplt.xlabel('Pixel Intensity')\nplt.ylabel('# Pixels in Image');","4c6f0056":"IMAGE_SIZE = (128, 128)\nBATCH_SIZE = 8\nEPOCHS = 30\nVALIDATION_PCT = 0.20","157b3b10":"def get_label(file_path):\n    return 1 if file_path.split(os.path.sep)[-2] == \"PNEUMONIA\" else 0","7bb493ef":"filenames = glob(os.path.join(TRAIN_DIR, \"*\", \"*\"))\nfilenames.extend(glob(os.path.join(VALID_DIR, \"*\", \"*\")))","42c43665":"all_data = []\nfor path in filenames:\n    label = get_label(path)\n    all_data.append((path, label))\n\nall_data = pd.DataFrame(all_data, columns=['Path','Pneumonia'], index=None)    \nall_data = all_data.sample(frac=1.).reset_index(drop=True)","a27eac11":"# 80-20 split into train and validation set\ntrain_set, val_set = train_test_split(all_data, test_size=0.20, stratify=all_data['Pneumonia'])","40293fa1":"# Number of images in train set\ntrain_post_count = train_set['Pneumonia'].value_counts()\nprint(train_post_count)","0280e08d":"# Number of images in validation set\nval_post_count = val_set['Pneumonia'].value_counts()\nprint(val_post_count)","0c16863e":"print(f'Total Pneumonia Cases: {all_data[all_data.Pneumonia==1].shape[0]}')\nprint(f'{(1-VALIDATION_PCT)*100}% Pneumonia Cases: {int(all_data[all_data.Pneumonia==1].shape[0]*(1-VALIDATION_PCT))}')\nprint(f'{VALIDATION_PCT*100}% Pneumonia Cases: {int(all_data[all_data.Pneumonia==1].shape[0]*VALIDATION_PCT)}')\nprint()\nprint(f'Pneumonia Cases in Training set: {train_set[train_set.Pneumonia==1].shape[0]}')\nprint(f'Pneumonia Cases in Validation set: {val_set[val_set.Pneumonia==1].shape[0]}')\nprint()\nprint(f'Train Set Size: {train_set.shape[0]}')\nprint(f'Pos %: {train_set[train_set.Pneumonia==1].shape[0] \/ train_set.shape[0] *100:.2f}')\nprint(f'Neg %: {train_set[train_set.Pneumonia==0].shape[0] \/ train_set.shape[0] *100:.2f}')\nprint()\nprint(f'Validation Set Size: {val_set.shape[0]}')\nprint(f'Pos %: {val_set[val_set.Pneumonia == 1].shape[0] \/ val_set.shape[0] *100:.2f}')\nprint(f'Neg % {val_set[val_set.Pneumonia == 0].shape[0] \/ val_set.shape[0] *100:.2f}')","c526f6e4":"test_files = glob(os.path.join(TEST_DIR,'*','*'))","e2750d2d":"test_set = []\nfor path in test_files:\n    label = get_label(path)\n    test_set.append((path, label))\n    \ntest_set = pd.DataFrame(test_set, columns=['Path', 'Pneumonia'], index=None)\ntest_set = test_set.sample(frac=1.).reset_index(drop=True)","cf4dc8f8":"def get_train_generator(df, x_col, y_col, shuffle=True, batch_size=BATCH_SIZE, seed=1, target_w = 128, target_h = 128):\n    \"\"\"\n    Return generator for training set, normalizing using batch\n    statistics.\n\n    Args:\n      train_df (dataframe): dataframe specifying training data.\n      x_col (str): name of column in df that holds filenames.\n      y_col (list): name of column in df as target\n      sample_size (int): size of sample to use for normalization statistics.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        train_generator (DataFrameIterator): iterator over training set\n    \"\"\"        \n    print(\"[INFO] Getting Train Generator...\") \n    # Normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True,\n        shear_range=0.1,\n        zoom_range=0.15,\n        rotation_range=5,\n        width_shift_range=0.1,\n        height_shift_range=0.05,\n        horizontal_flip=True, \n        vertical_flip = False, \n        fill_mode = 'reflect')\n    \n    # Flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=None,\n            x_col=x_col,\n            y_col=y_col,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return generator","71d20c2d":"def get_test_and_valid_generator(valid_df, test_df, train_df, x_col, y_col, sample_size=100, batch_size=BATCH_SIZE, seed=1, target_w = 128, target_h = 128):\n    \"\"\"\n    Return generator for validation set and test test set using \n    normalization statistics from training set.\n\n    Args:\n      valid_df (dataframe): dataframe specifying validation data.\n      test_df (dataframe): dataframe specifying test data.\n      train_df (dataframe): dataframe specifying training data.\n      x_col (str): name of column in df that holds filenames.\n      y_col (list): name of column in df as target.\n      sample_size (int): size of sample to use for normalization statistics.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n    \"\"\"\n    print(\"[INFO] Getting Valid and Test Generators...\")\n    # Get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=None, \n        x_col=x_col, \n        y_col=y_col, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # Get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # Use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # Fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # Get Valid Generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=None,\n            x_col=x_col,\n            y_col=y_col,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    # Get Test Generator\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=None,\n            x_col=x_col,\n            y_col=y_col,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator","fc654812":"train_generator = get_train_generator(train_set, \"Path\", \"Pneumonia\")","a21f50a5":"valid_generator, test_generator = get_test_and_valid_generator(val_set, test_set, train_set, \"Path\", \"Pneumonia\")","6c43b926":"x, y = train_generator.__getitem__(0)\nplt.imshow(x[0]);","5422bd19":"t_x, t_y = next(train_generator)\nfig, m_axs = plt.subplots(2, 4, figsize = (8, 4))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'gray')\n    if c_y == 1: \n        c_ax.set_title('Pneumonia')\n    else:\n        c_ax.set_title('Normal')\n    c_ax.axis('off')","1b7dea2a":"def compute_class_freqs(labels):\n    \"\"\"\n    Compute positive and negative frequences for each class.\n\n    Args:\n        labels (np.array): matrix of labels, size (num_examples, num_classes)\n    Returns:\n        positive_frequencies (np.array): array of positive frequences for each\n                                         class, size (num_classes)\n        negative_frequencies (np.array): array of negative frequences for each\n                                         class, size (num_classes)\n    \"\"\"\n    # Total number of patients (rows)\n    N = labels.shape[0]\n    \n    positive_frequencies = np.sum(labels, axis=0) \/ N\n    negative_frequencies = 1 - positive_frequencies\n    \n    return positive_frequencies, negative_frequencies","1e7dce91":"# Computing class frequencies for our training set\nfreq_pos, freq_neg = compute_class_freqs(train_generator.labels)\npos_weights = freq_neg\nneg_weights = freq_pos\nclass_weights = {0: neg_weights, 1:pos_weights}","2a30d701":"def setup_densenet_pretrained_model():\n    # Create the base pre-trained model\n    base_model = DenseNet121(weights='nih\/densenet.hdf5', include_top=False)\n\n    x = base_model.output\n\n    # Add a global spatial average pooling layer\n    x = GlobalAveragePooling2D()(x)\n\n    # And a logistic layer\n    predictions = Dense(1, activation=\"sigmoid\")(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    return model","29696f3f":"x_ray_class = \"Pneumonia_Detection_Model_Dense_FINAL_ATTEMPT\"\n_time = time.localtime()\nprefix = time.strftime(\"%m_%d_%Y_%H_%M\")\n\nweight_path = f\"Model_Checkpoints\/{x_ray_class}_{prefix}_model_best.hdf5\"\n\ncb_checkpoint = ModelCheckpoint(weight_path,\n                            monitor = 'val_loss',\n                            verbose=1,\n                            save_best_only=True,\n                            mode='min',\n                            save_weights_only=True)\n\ncb_early = EarlyStopping(monitor='val_loss',\n                     mode='min',\n                     patience=10)\n\ncb_csv_logger = CSVLogger(f'Logs\/{x_ray_class}_{prefix}_log.csv', append=True, separator=';')","02866989":"call_backs_list = [cb_checkpoint, cb_early, cb_csv_logger]","a1ec9603":"run_custom_training = False\nif run_custom_training:\n    t_start = time.time()\n    print(f\"[INFO] Model Training Started : {time.ctime(t_start)}\")    \n    history = model.fit(train_generator,\n                        steps_per_epoch=len(train_generator),\n                        epochs=10,\n                        validation_data=valid_generator,\n                        validation_steps=len(valid_generator),\n                        class_weight=class_weights,\n                        callbacks = call_backs_list)\n    model.load_weights(weight_path)\n    print(f\"[INFO] Model Training Finished : {time.ctime(time.time())}\")\n    model.save(\"Models\/Pneumonia_Detection_Model_Final_Dense_FINAL_ATTEMPT.h5\")\n    print(f\"[INFO] Model Saved\")\n    t_finish = time.time()\n    print(f'Training took {(t_finish - t_start) \/\/ 60} minutes')\n    plt.plot(history.history['loss'])\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epoch\")\n    plt.title(\"Training Loss Curve\")\n    plt.show()","d2b37172":"# Functions for getting model predictions and plotting results\ndef get_model_predictions(model_filepath, data):\n    \"\"\"\n    Takes in a filepath to the saved model, loads in the model, and gets predictions for all data sent in.\n    :param model_filepath: filepath to a saved model, must have .h5 extension\n    :param data: Data to make predictions on\n    :return: True labels, predictions\n    \"\"\"\n    model = tf.keras.models.load_model(model_filepath)\n    pred_y = model.predict(data)\n    return [data for answer in pred_y for data in answer]","35c89956":"## Look at a sample of predicted v. true values along with model probabilities:\nfig, m_axs = plt.subplots(2, 4, figsize = (20, 10))\ni = 0\nfor (c_x, c_y, c_ax) in zip(image_batch[0:8], true_y[0:8], m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    prob = round(float(pred_y[i]),3)\n    if c_y != pred_y_binary[i]:\n        c_ax.set_title(f'True {c_y}, Predicted {pred_y_binary[i]}, Prob: {prob}', color = 'red')\n    else:\n        c_ax.set_title(f'True {c_y}, Predicted {pred_y_binary[i]}, Prob: {prob}', color = 'black')\n    c_ax.axis('off')\n    i=i+1","42100e00":"predicted_vals = model.predict(test_generator, steps = len(test_generator))","769147d7":"true_y = test_set['Pneumonia'].values","4fa6b3a5":"threshold = 0.135\npred_y_binary = [1.0 if pred > threshold else 0.0 for pred in predicted_vals]\npred_y_binary\ncm = confusion_matrix(true_y, pred_y_binary)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(4,4), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.savefig(f'Images\/CM_Full_Test_Data.png')\nplt.show();","908d0a13":"y_pred = model.predict(test_generator, steps=len(test_generator),verbose=1)\ntrue_y = test_generator.labels\nthreshold = 0.5\npred_y_binary = [1.0 if pred > threshold else 0.0 for pred in y_pred]\npred_y_binary\ncm = confusion_matrix(true_y, pred_y_binary)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(4,4), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.savefig(f'Images\/CM_Full_Test_Data_Thres_50.png')\nplt.show();","0f2d409f":"model_evaluation = model.evaluate(test_generator)\nprint(f\"Loss of Model on Test Set: {model_evaluation[0]*100:.2f}%\")\nprint(f\"Accuracy of Model on Test Set: {model_evaluation[1]*100:.2f}%\")\nprint(f\"AUC of Model on Test Set: {model_evaluation[2]*100:.2f}%\")\nprint(f\"Precision of Model on Test Set: {model_evaluation[3]*100:.2f}%\")\nprint(f\"Recall of Model on Test Set: {model_evaluation[4]*100:.2f}%\")","88c76c3f":"history_logs = pd.read_csv('Logs\/Pneumonia_Detection_Model_Dense_FINAL_ATTEMPT_10_01_2020_11_49_log.csv',sep=';')\nhistory_logs","49ec367e":"# Plot Model History\ndef plot_history(model_history, model_name):\n    N = len(model_history['loss'])\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0,N), model_history['loss'], label='train loss')\n    plt.plot(np.arange(0,N), model_history['val_loss'], label='valuation loss')\n    plt.plot(np.arange(0,N), model_history['accuracy'], label='train accuracy')\n    plt.plot(np.arange(0,N), model_history['val_accuracy'], label='valuation accuracy')\n    plt.title(\"Model Training Results\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Loss \\ Accuracy\")\n    plt.legend(loc=\"upper left\")\n    plt.savefig(f'Images\/{model_name}_history.png')\n    plt.plot()","e9a06704":"plot_history(history_logs, \"DenseNet\")","5a162bb9":"def plot_roc_curve(model_name, true_y, pred_y):\n    \"\"\"\n    Plot the ROC curve along with the curves AUC for a given model. Note make sure true_y and pred_y are from the same model as model_name\n    :param model_name: Name of model used for saving plot\n    :param true_y: true labels for dataset\n    :param pred_y: predicted labels for dataset\n    \"\"\"\n    fig, ax = plt.subplots(1,1, figsize=(7,7))\n    fpr, tpr, thresholds = sklearn.metrics.roc_curve(true_y, pred_y)\n    ax.plot(fpr, tpr, label=f'{model_name} AUC: {sklearn.metrics.auc(fpr,tpr)}')\n    ax.legend()\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"True Positive Rate\")\n    plt.savefig(f'Images\/{model_name}_roc.png')\n    return\n\ndef plot_precision_recall_curve(model_name, true_y, pred_y):\n    \"\"\"\n    Plot the precision recall curve for a given model. Note make sure true_y and pred_y are from the same model as model_name\n    :param model_name: Name of model used for saving plot\n    :param true_y: true labels for dataset\n    :param pred_y: predicted labels for dataset\n    \"\"\"\n    fig, ax = plt.subplots(1,1, figsize=(7,7))\n    precision, recall, thresholds = precision_recall_curve(true_y, pred_y)\n    ax.plot(recall, precision, label=f'{model_name} AP Score: {sklearn.metrics.average_precision_score(true_y,pred_y)}')\n    plt.legend()\n    ax.set_xlabel(\"Recall\")\n    ax.set_ylabel(\"Precision\")\n    plt.savefig(f'Images\/{model_name}_precision_recall.png')\n    return\n\ndef calculate_f1_scores(precision, recall):\n    return [(2*p*r)\/(p+r) for p,r in zip(precision,recall)]\n\ndef plot_f1_score(model_name, true_y, pred_y):\n    \"\"\"\n    Plot F1 Scores for a given model. Note make sure true_y and pred_y are from the same model as model_name\n    F1 = 2*(precision*recall) \/ (precision + recall)\n    :param model_name: Name of model used for saving plot\n    :param true_y: true labels for dataset\n    :param pred_y: predicted labels for the dataset\n    \"\"\"\n    fig, ax = plt.subplots(1,1,figsize=(7,7))\n    precision, recall, thresholds = precision_recall_curve(true_y,pred_y)\n    ax.plot(thresholds, precision[:-1], label=f'{model_name} Precision')\n    ax.plot(thresholds, recall[:-1], label=f'{model_name} Recall')\n    f1_scores = calculate_f1_scores(precision, recall)[:-1]\n    ax.plot(thresholds, f1_scores, label=f'{model_name} F1 Score')\n    plt.legend()\n    ax.set_xlabel(\"Threshold Values\")\n    plt.savefig(f'Images\/{model_name}_f1_score.png')\n    return max(f1_scores)","bd446719":"predicted_vals = model.predict(test_generator, steps = len(test_generator))","5f56f612":"true_y = test_set['Pneumonia'].values","65a23ddc":"plot_roc_curve(\"DenseNet\", true_y, predicted_vals)","fb0ab5fc":"plot_precision_recall_curve(\"DenseNet\", true_y, predicted_vals)","b1146643":"plot_f1_score('DenseNet', true_y, predicted_vals)","dec53468":"print(\"Original - PNEUMONIA\")\ncompute_gradcam(model, 'PNEUMONIA\\\\person20_virus_51.jpeg', train_set, labels, labels_to_show)","e1797a20":"print(\"Original - NORMAL\")\ncompute_gradcam(model, 'NORMAL\\\\NORMAL2-IM-0051-0001.jpeg', train_set, labels, labels_to_show)","f5f5661d":"print(\"Original - PNEUMONIA\")\ncompute_gradcam(model, 'PNEUMONIA\\\\person44_virus_93.jpeg', train_set, labels, labels_to_show)","3c081623":"print(\"Original - NORMAL\")\ncompute_gradcam(model, 'NORMAL\\\\NORMAL2-IM-0374-0001.jpeg', train_set, labels, labels_to_show)","a0d6a11d":"print(\"Original - PNEUMONIA\")\ncompute_gradcam(model, 'PNEUMONIA\\\\person1679_virus_2896.jpeg', train_set, labels, labels_to_show)","6fef68a2":"Now we need to build a new generator for validation and test set.\nWe cannot use the same generator as for training data because it normalizes each image per batch. In real life scenario we don't process incoming images a batch at a time instead we process one image at a time.","19408eb9":"Let's start the training process, it will take some time.","62ed6edd":"<a id=\"section6_1\"><\/a>\n#### 6.1 Confusion Matrix\nConfusion Matrix tells us about how our model is performing while classifying.\n\nThe diagonal elements of confusion matrix represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier.\n\n* True Positives(Bottom-Right) - Both actual and predicted values are Positive.\n* True Negatives(Top-Left) - Both actual and predicted values are Negative.\n* False Positives(Top-Right) - The actual value is negative but we predicted it as positive. \n* False Negatives(Bottom-Left) - The actual value is positive but we predicted it as negative.","332a3b5d":"**NOTE:** We can see that pneumonia images are in access almost 1:3 in ratio as compared to normal images. So, there is a class imbalance problem in our dataset. We need to consider it while preprocessing the images.\n\nThere is one more thing to notice, validation set consists of only 16 images, which is not good enough for model evaluation. So, we will need to make 80-20 split between train and validation set.","daa605ec":"<a id=\"section6_3\"><\/a>\n#### 6.3 Accuracy and Loss Curve of Training and Validation Set","91fe1a38":"Let's see how an image looks like after using generator.","74334927":"We can see that our model is performing pretty well in classifying Pneumonia as well as Normal X-Ray images.\n\n* TP - 389\n* TN - 148\n* FP - 86\n* FN - 1\n\nLet's explore more about it by reviewing the accuracy, recall, precision on test set.","42f38c11":"<a id='section4'><\/a>\n### 4. Exploratory Data Analysis","ccf6d070":"<a id='section4_2_1'><\/a>\n#### 4.2.1 Review `Normal` X-Ray Sample Images(3)","5f65740c":"<a id=\"section5_4\"><\/a>\n#### 5.4 Defining Model Checkpoints\nWe are defining some callback function which will helps us to view on internal states and statistics of the model during training so that we can fix bugs more quickly. Callbacks used are:\n\n* `CSVLogger:` We are defining a callback for logging every epoch result into a csv file.\n* `EarlyStopping:` EarlyStopping is used to avoid overfitting and terminate the process early if it is the case. Here, patience level is 10 means it waits for 10 epochs, if no change is noticed then it will automatically terminate the learning process.\n* Our callback is also keeping an eye on the `val_loss` metric at the point.\n* Checkpoint also saves the best fit model.","f5d1b7d9":"<a id='section5'><\/a>\n### 5. Preprocessing","46b78337":"<a id=\"section5_2\"><\/a>\n#### 5.2 Addressing Class Imbalance Problem using Class Weights","e045870c":"<a id=\"section6_4\"><\/a>\n#### 6.4 ROC Curve, Precision-Recall Curve, F1 Score","a69333e9":"**NOTE:** There are only 16 images in the validation set, which are very less as compared to training set. So, we need to append validation set with training set and create a new split that resembles the considerable 80:20 Split Instead.","75e627de":"<a id='section5_1'><\/a>\n#### 5.1 Defining Train, Val and Test Generators","68020f6e":"# \ud83e\ude7aPneumonia Detection - Pretrained Model\ud83d\udd0d","ad12e6bb":"- We are defining a train generator to modify the images before feeding it into the model. For this task we'll use the Keras [ImageDataGenerator](https:\/\/keras.io\/preprocessing\/image\/) function to perform data preprocessing and data augmentation.\n\n- The `image_generator` will adjust our image data such that the new mean of the data will be zero, and the standard deviation of the data will be 1. In other words, the generator will replace each pixel value in the image with a new value calculated by subtracting the mean and dividing by the standard deviation.\n\n$$\\frac{x_i - \\mu}{\\sigma}$$\n\n- We are also reducing the image size down to 128*128 pixels.\n\n- We are using data augmentation to avoid overfitting. `Data augmentation` is a strategy that helps to significantly increase the diversity of data available for training models, without actually collecting new data.","f40475cf":"<a id='section4_1'><\/a>\n#### 4.1 Distribution of Images in train, val and test set","37e1d9d9":"<a id='section4_3_2'><\/a>\n#### 4.3.2 Pixel Intensity of `Non-Pneumonia` Patient X-Ray Images","f0c6b106":"<a id='section4_4'><\/a>\n#### 4.4 Exploration of Single Pneumonia Patient Image\n\n#### Pneumonia Patient X-Ray Image","fc7e8f0e":"<a id=\"section6_2\"><\/a>\n#### 6.2 Accuracy, Loss, AUC, Precision and Recall","9d3bf45b":"\nPneumonia is an inflammatory condition of the lung affecting primarily the small air sacs known as alveoli. \n\n<a id='section1_1'><\/a>\n**`SYMPTOMS`**\n* Dry Cough - Pus or Bloody Sputum\n* Chest Pain\n* Fever\n* Shortness of Breath\n* Fatigue\n\n**Note :** Severity of condition is variable.\n\n<a id='section1_2'><\/a>\n**`MAIN CAUSE OF PNEUMONIA DISEASE`**\n* Infection with viruses or bacteria\n* Certain medications or conditions such as autoimmune diseases\n\n<a id='section1_3'><\/a>\n**`RISK FACTORS`**\n* Cystic Fibrosis\n* Chronic Obstructive Pulmonary Disease(COPD)\n* Sickle Cell Disease\n* Asthma\n* Diabetes\n* Heart Failure\n* History of Smoking\n![](http:\/\/)![](http:\/\/)* Poor ability to Cough\n* Weak Immune System\n\n<a id='section1_4'><\/a>\n**`DIAGNOSIS`**\n\n**Note :** Diagnosis is often based on symptoms and physical condition.\n* Chest X-rays\n* Blood Tests\n\n<a id='section1_5'><\/a>\n**`PNEUMONIA CATEGORIES`**\n* Community Acquired Pneumonia\n    * When person gets ill outside of a hospital.\n* Hospital acquired Pneumonia (NOSOCOMIAL)\n    * Person ALREADY Sick in Hospital\n    * SERIOUS\n        * Sick Patients have weakened immune systems.\n        * Microbes in hospitals are more resistant to antibiotics; Example - MRSA : which are resistant to antibiotics; and hard to treat.\n* Ventilator Associated Pneumonia\n    * Subset of hospital acquired Pneumonia\n    * Develops when person is connected to a ventilator, can't cough.\n    \n<a id='section1_6'><\/a>\n**`STAGES OF PNEUMONIA`**\n* Congestion - Days 1 & 2\n    * Blood Vessels and alveoli fill with excess fluid.\n* Red Hepatization - Days 3 & 4\n    * Exudate (RBCs, Neutrophils & Fibrin) fill airspaces, making them more solid.\n    * Liver-like appearance.\n* Grey Hepatization - Days 5 to 7\n    * Still firm\n    * Color change: RBCs in exudate breakdown.\n* Resolution - Days 8 to 3 Weeks\n    * Excudate is Digested, Ingested, or Coughed-Up.","02a530d0":"<a id='section4_3'><\/a>\n#### 4.3 Pixel Intensity of `Pneumonia` and `Normal` Patient X-Ray Images\n\n<a id='section4_3_1'><\/a>\n#### 4.3.1 Pixel Intensity of `Pneumonia` Patient X-Ray Images","54a2308b":"<a id='section1_7'><\/a>\n#### <u>Interesting Fact<\/u>\n\n**Connection of Pneumonia with Coronavirus**\n<div align=\"justify\">Pneumonia is an infection of lungs caused by viruses, bacteria, and fungi. Pneumonia can cause the small air sacs in your lungs, known as alveoli, to fill with fluid.\nPneumonia can be a complication of COVID-19, the illness caused by the new coronavirus known as SARS-CoV-2.\n<br>\n    \nInfection with SARS-CoV-2 begins when respiratory droplets containing the virus enter your upper respiratory tract. As the virus multiplies, the infection can progress to your lungs. When this happens, it is possible to develop pneumonia.\n\nTypically, the oxygen you breathe into your lungs crosses into your bloodstream inside the alveoli, the small air sacs in your lungs. However, infection with SARS-CoV-2 can damage the alveoli and surrounding tissues.\n\nFurther, as your immune system fights the virus, inflammation can cause fluid and dead cells to build up in your lungs. These factors interfere with the transfer of oxygen, leading to symptoms like coughing and shortness of breath.\n\nPeople with COVID-19 pneumonia can also go on to develop acute respiratory distress syndrome (ARDS), a progressive type of respiratory failure that occurs when the air sacs in the lungs fill up with fluid. This can make it hard to breathe.\n\nThe symptoms of COVID-19 pneumonia may be similar to other types of viral pneumonia. Because of this, it can be difficult to tell what\u2019s causing your condition without being tested for COVID-19 or other respiratory infections.\n\n**NOTE:** Research is underway to determine how COVID-19 pneumonia differs from other types of pneumonia.\n\n**Source:** <a href=\"https:\/\/www.healthline.com\/health\/coronavirus-pneumonia#connection\" style=\"text-decoration:None;\">Healthline<\/a>\n<\/div>","2f08ba07":"<a id='section2'><\/a>\n### 2. Problem Statement\n<br>\n<div align=\"justify\">There is an immense risk of pneumonia in almost all countries, especially in developing countries where people reply on polluting forms of energy due to energy poverty. The World Health Organization (WHO) estimates that over 4 millions premature death occur annually due to household air pollution related dieases. Over 150 million people get infected with pneumonia on an annual basis especially children under the age of 5 years.\n<br>\n    \nIn such regions, the problem can be further aggrevated due to the lack of medical resources and personnel. For Example: In Africa, there is a gap of 2.3 millions doctors and nurses. This gap leads to death of the patients suffering from diseases. Can you belive it? People just die because they do not have resources to get diagnosed and treated on time. So there is a need of systems which can automate the process to save human lives. This is where Machine Learning, Deep Learning, Artificial Intelligence comes to resue.\n\nPhysician burnout is another major topic of conversation in healthcare these days,  and much of the burnout is due to the increased data that physicians are required to both input and consume about their patients. However, it presents great opportunities for AI, because AI can enhance efficiency, reduce human errors, and achieve goals with minimal human operation.\n\nDeep neural networks perform very-well on medical problems, so building automatic systems using deep learning model would be a great help for assisting radiologist without any delay particularly in remote areas or developing nations.\n\n**GOAL:** Our specific goal here is to classify pneumonia by only looking at the x-ray image with reasonable level of accuracy and recall.<\/div>","31620d1d":"There is no significant difference between the intensity values of `Pneumonia` vs `Non-Pneumonia` Cases when looking at entire image.\nMay be I need to focus on lungs to identify the difference.","1fe689bf":"Let's plot some sample images of each class i.e. `Pneumonia` and `Normal` to see how these x-ray images look like.","7c57dced":"<a id=\"section5_3\"><\/a>\n#### 5.3 DenseNet121\n\nNow we will use a pre-trained DenseNet121 model. We will add two more layers on top of it.\n* `GlobalAveragePooling2D` to get the average of the last layer of DenseNet121.\n* `Dense` layer to get predictions.","bba14aad":"<a id=\"section6_5\"><\/a>\n#### 6.5 Visualize Model Learning with GradCAM\n\nGradient Class Activation Maps(GradCAM) are very useful for understanding where the model is looking on a particular layer when classifying an image.\n\nBelow we have applied this technique to visualize the model learning. This is done by extracting the gradients of each predicted class, flowing into our model's final convolution layer.\n\nWe will use GradCAM's technique to produce heatmap highlighting the important regions in the image for predicting the disease.","f951b3a5":"#### Pixel Intensity Values of Single Pneumonia Patient X-Ray Image","aa6cb7c6":"Load the log file to see the validation statistics","1fb89cd2":"<a id='section4_2_2'><\/a>\n#### 4.2.2 Review `Pneumonia` X-Ray Sample Images(3)","56aa887b":"<a id='section1'><\/a>\n### 1. Brief Introduction of Pneumonia Disease","d0bcd579":"Setting a threshold to classify the X-Ray image as Pneumonia or Normal. As Medical Model should be high Recall model, therefore we are taking a threshold of 0.135.","5f7d1bda":"<a id='section4_2'><\/a>\n#### 4.2 Review X-Ray Sample Images(Normal and Pneumonia)","04363b20":"<a id='section3'><\/a>\n### 3. Data Description\n<br>\n<div align=\"justify\">The dataset consists of only X-Ray images which is organised into 3 directories i.e. train, val and test. These directories consists of two subfolders which consists of x-ray images of normal and pneumonia patients i.e. NORMAL and PNEUMONIA.\n\nThere are total **5856** X-Ray images in our dataset which are splitted up as follows:\n* **train:** NORMAL - **1341** | PNEUMONIA - **3875**\n* **val:**   NORMAL - **8** | PNEUMONIA - **8**\n* **test:**  NORMAL - **234** | PNEUMONIA - **390**\n\n**Source:** <a href=\"https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\" style=\"text-decoration:None;\">Chest X-Ray Images(Pneumonia)<\/a><\/div>","aaa60698":"<a id=\"section6\"><\/a>\n#### 6. Prediction and Evaluation\n\nDefining a function to get predictions out of our model for test set.","3c1e46cb":"<a id='section4_5'><\/a>\n#### 4.5 EDA Findings\n\n**Exploration of Pneumonia Cases:** In this section, I have found that 73% of the whole dataset forms `Pneumonia` cases and rest 27% are `Normal`.\n\nSo, we need to take care of class imbalance problem when feeding data to the model.","9cd1776a":"Looking at the specific images including `NORMAL` as well as `PNEUMONIA` cases. "}}