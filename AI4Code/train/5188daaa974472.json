{"cell_type":{"92237328":"code","049b1f1d":"code","45df69fe":"code","3eaba870":"code","f6d5139c":"code","267a4aa9":"code","3a84e6c9":"code","cda2f0d3":"code","77ca5120":"code","9babd531":"code","2a48fc53":"code","b7e8744d":"code","26ed287f":"code","e2bba246":"code","bf5811d7":"code","e8a4c48f":"code","788916f2":"code","b09289c0":"code","e7ca3de7":"markdown","ea9d5cb3":"markdown","0aeb1bb1":"markdown","ec9e2855":"markdown","6a962e67":"markdown","fde39bf2":"markdown","7966351b":"markdown","61bcb43f":"markdown"},"source":{"92237328":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","049b1f1d":"data = pd.read_csv('\/kaggle\/input\/abalone-dataset\/abalone.csv')\ndata.head()","45df69fe":"data.info()","3eaba870":"sb.countplot(x='Sex', data=data)","f6d5139c":"def correlation_heatmap(train):\n    correlations = train.corr()\n    \n    fig, ax = plt.subplots(figsize=(16,16))\n    sb.heatmap(correlations, vmax=1.0, center=0, fmt='.2f', square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\":.70})\n    plt.show()\ncorrelation_heatmap(data)","267a4aa9":"sb.scatterplot(x=\"Shell weight\", y=\"Rings\", data=data, hue=\"Sex\")","3a84e6c9":"sb.catplot(x=\"Sex\", y=\"Rings\", data=data, kind='box')","cda2f0d3":"data['IsAdult'] = [0 if x=='I' else 1 for x in data['Sex']]\ndata_tf = data.drop('Sex', axis=1)\ndata_tf.head()","77ca5120":"X = data_tf.drop('Rings', axis=1)\ny = data_tf['Rings'].values","9babd531":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","2a48fc53":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","b7e8744d":"from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nclassifiers = [\n    SGDRegressor(),\n    LinearSVR(),\n    LinearRegression(),\n    DecisionTreeRegressor(),\n    RandomForestRegressor()\n]","26ed287f":"from sklearn.model_selection import cross_val_score\n\nfor clf in classifiers:\n    clf.fit(x_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    scores = cross_val_score(clf, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n    rmse_scores = np.sqrt(-scores)\n    \n    print('****Results****')\n    print(\"Scores: \", scores)\n    print(\"Mean: \", scores.mean())\n    print(\"Std deviation: \", scores.std())\n    \nprint(\"=\"*30)","e2bba246":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nrnd_reg = RandomForestRegressor(random_state=42)\ngrid_search = GridSearchCV(rnd_reg, param_grid, cv=5, scoring=\"neg_mean_squared_error\",\n                          return_train_score=True)\ngrid_search.fit(x_train, y_train)","bf5811d7":"grid_search.best_params_","e8a4c48f":"best_reg = grid_search.best_estimator_\ny_pred = best_reg.predict(x_test)\nfinal_mse = mean_squared_error(y_test, y_pred)\nfinal_rmse = np.sqrt(final_mse)\nfinal_rmse","788916f2":"for pred in range(0, len(y_pred)):\n    print(\"Predicition: \" + str(y_pred[pred]) + \" Actual: \" + str(y_test[pred]))","b09289c0":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nax.scatter(y_test, y_pred)\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","e7ca3de7":"## \u00a0Train model\nI will now train a few models and cmpare them against each other to find the best one.","ea9d5cb3":"All of the features presented seem to be of importance to each other so I won't drop any","0aeb1bb1":"It looks like RandomForestRegressor did best out of the box so now to find the best hyperparameters for it","ec9e2855":"This is our final RMSE for this task, which is a little better than what other users are getting which is good!","6a962e67":"## Visualize the data","fde39bf2":"I am now going to change the Sex column to be if the Abalone is an adult or not as I believ this will be of greater importance than the Sex of the Abalone.","7966351b":"This is a fairly even split of the Sex feature, later on I would like to split this up into adult or not instead of Sex as this could provide more useful information.","61bcb43f":"# Determine the age of Abalone\nThis task is to determine how old an Abalone is by a handful of features we are given."}}