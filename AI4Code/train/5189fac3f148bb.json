{"cell_type":{"20093efa":"code","800440b8":"code","7923f818":"code","541949f0":"code","411f9fcc":"code","05c7dece":"code","08d8936e":"code","d5764417":"code","b2e0ac2a":"code","34b2145c":"code","4e5b29d7":"code","6a69fbaf":"code","c5be21c0":"code","6a942e62":"code","3f014673":"code","0423a718":"code","12b07c0a":"code","35292db1":"code","0faa5755":"code","493b5960":"code","bdcdeeff":"code","9dbeec8a":"code","780a416a":"code","b4fedaf0":"code","2f345d07":"code","ff297e4b":"code","df0d46d8":"code","e15cf5d5":"code","1352d3e4":"code","62b3feae":"code","deb33337":"code","4e259716":"code","91bbbabf":"code","4b0127c0":"code","4234cba7":"code","dccaf710":"code","52b0623b":"code","dec6a603":"markdown","62377420":"markdown","d3c280a7":"markdown","316338e6":"markdown","d73b4d61":"markdown","0f0b5dd3":"markdown","1f50ccc2":"markdown","ebf1ea97":"markdown","525c0a9c":"markdown","58ad3fbd":"markdown","3ea63367":"markdown","2a90d02b":"markdown","1349f83c":"markdown","cfd7737c":"markdown","649e02e5":"markdown","090fa2ee":"markdown","aaa61c84":"markdown","cfa87517":"markdown","a23a0c10":"markdown","1cf15d0d":"markdown","483e265a":"markdown","bd4ec44a":"markdown","f6804588":"markdown","380042b9":"markdown","85612564":"markdown","0a1aa4a2":"markdown","47334f89":"markdown","86d071aa":"markdown","ee7dfe27":"markdown","6596d4b9":"markdown"},"source":{"20093efa":"# loading required libraries for cancer treament analysis\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# To ignore warinings\nimport warnings\nwarnings.filterwarnings('ignore')","800440b8":"# let's check in which directory our data is available so that it will be easy to pull from specific source location\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","7923f818":"# loading datasets\ntrain_variants = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/training_variants')\ntest_variants = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/test_variants')\ntrain_text = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntest_text = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])","541949f0":"train_variants.head()","411f9fcc":"train_text.head()","05c7dece":"train_merge = pd.merge(train_variants,train_text,how='left',on='ID')\n# let's pull train merge dataset and do the analysis on this\ntrain_merge.head()","08d8936e":"# Let's understand the type of values present in each column of our dataframe 'train_merge' dataframe.\ntrain_merge.info()","d5764417":"# Histogram : To check class distribution\nplt.figure(figsize=(12,8))\nsns.countplot(x='Class',data=train_variants)\nplt.ylabel('Frequency-Counts', fontsize=15)\nplt.xlabel('Class',fontsize=13)\nplt.xticks(rotation='vertical')\nplt.title('Class Counts',fontsize=15)\nplt.show()","b2e0ac2a":"train_merge[\"Text_num_words\"] = train_merge[\"Text\"].apply(lambda x: len(str(x).split()) )\ntrain_merge[\"Text_num_chars\"] = train_merge[\"Text\"].apply(lambda x: len(str(x)) )","34b2145c":"plt.figure(figsize=(12, 8))\nsns.distplot(train_merge.Text_num_words.values, bins=50, kde=False, color='red')\nplt.xlabel('Number of words in text', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title(\"Frequency of number of words\", fontsize=15)\nplt.show()","4e5b29d7":"plt.figure(figsize=(12, 8))\nsns.distplot(train_merge.Text_num_chars.values, bins=50, kde=False, color='brown')\nplt.xlabel('Number of characters in text', fontsize=12)\nplt.ylabel('log of Count', fontsize=12)\nplt.title(\"Frequency of Number of characters\", fontsize=15)\nplt.show()","6a69fbaf":"plt.figure(figsize=(12,8))\nsns.boxplot(x='Class', y='Text_num_words', data=train_merge)\nplt.xlabel('Class', fontsize=12)\nplt.ylabel('Text - Number of words', fontsize=12)\nplt.show()","c5be21c0":"train_merge.describe()","6a942e62":"# putting respon variable to y\n#y = train_merge['Class'].values\n#train_merge = train_merge.drop('Class',axis=1)","3f014673":"train_merge.head(3)","0423a718":"#y","12b07c0a":"test_merge = pd.merge(test_variants,test_text,how='left',on='ID')\ntest_merge.head(3)","35292db1":"pid = test_merge['ID'].values\npid","0faa5755":"test_merge.describe()","493b5960":"# check total number of null\/missing value present in whole datasets\ntrain_merge.isnull().sum()","bdcdeeff":"# find out percentage of \"?\" value present across the dataset\npercent_missing = train_merge.isnull().sum() * 100 \/ len(train_merge)\npercent_missing","9dbeec8a":"# droping missing values\ntrain_merge.dropna(inplace=True)\n\n# let's check again whether we have any further missing values\ntrain_merge.isnull().sum()","780a416a":"test_merge.isnull().sum()","b4fedaf0":"# dropping missing values\ntest_merge.dropna(inplace=True)\n\n# check if our data is clean or not\ntest_merge.isnull().sum()","2f345d07":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(train_merge,test_size=0.2)\nnp.random.seed(0)\ntrain","ff297e4b":"X_train = train['Text'].values\nX_test = test['Text'].values\ny_train = train['Class'].values\ny_test = test['Class'].values","df0d46d8":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import svm","e15cf5d5":"text_classifier = Pipeline([('vect', CountVectorizer()),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', svm.LinearSVC())\n])\ntext_classifier = text_classifier.fit(X_train,y_train)","1352d3e4":"y_test_predicted = text_classifier.predict(X_test)\nnp.mean(y_test_predicted == y_test)","62b3feae":"X_test_final = test_merge['Text'].values\n#X_test_final","deb33337":"predicted_class = text_classifier.predict(X_test_final)","4e259716":"test_merge['predicted_class'] = predicted_class","91bbbabf":"test_merge.head(5)","4b0127c0":"onehot = pd.get_dummies(test_merge['predicted_class'])\ntest_merge = test_merge.join(onehot)","4234cba7":"test_merge.head(5)","dccaf710":"submission_df = test_merge[[\"ID\",1,2,3,4,5,6,7,8,9]]\nsubmission_df.columns = ['ID', 'class1','class2','class3','class4','class5','class6','class7','class8','class9']\nsubmission_df.head(5)","52b0623b":"submission_df.to_csv('submission.csv', index=False)","dec6a603":"## Let's have a quick look whether we have balance data or not in our test datasets","62377420":"- Predicting values for test data","d3c280a7":"## Let's check whether the data is balance or not","316338e6":"- Awesome! Our test dataset is looks fine. ","d73b4d61":"## **If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That's will keep me motivated :)**","0f0b5dd3":"**- Let's look at the distribution of number of words in the text column.**","1f50ccc2":"- Set pipeline to build a complete text processing model with Vectorizer, Transformer and LinearSVC","ebf1ea97":"### Similarlly let's pull top 5 rows value fromtrain text data","525c0a9c":"``` The peak is around 4000 words.``` \n\n- Now let us look at character level.","58ad3fbd":"```Use Case Details:```\n\nA lot has been said during the past several years about how precision medicine and, more concretely, how genetic testing is going to disrupt the way diseases like cancer are treated.\n\nBut this is only partially happening due to the huge amount of manual work still required. Memorial Sloan Kettering Cancer Center (MSKCC) launched this competition, accepted by the NIPS 2017 Competition Track,  because we need your help to take personalized medicine to its full potential.\n\n\n\nOnce sequenced, a cancer tumor can have thousands of genetic mutations. But the challenge is distinguishing the mutations that contribute to tumor growth (drivers) from the neutral mutations (passengers). \n\nCurrently this interpretation of genetic mutations is being done manually. This is a very time-consuming task where a clinical pathologist has to manually review and classify every single genetic mutation based on evidence from text-based clinical literature.\n\nFor this competition MSKCC is making available an expert-annotated knowledge base where world-class researchers and oncologists have manually annotated thousands of mutations.\n\nWe need your help to develop a Machine Learning algorithm that, using this knowledge base as a baseline, automatically classifies genetic variations.\n\n\nKaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.","3ea63367":"    - Ohh Ok, We have only 5 missing values present in text feature\n    - Let's remove those since it's only 5 missing in number if we see the percentage of missing values it's like only 0.1% . Since it's very less number we can remove those.","2a90d02b":"- Awesome our data is cleaned! Good to go for model building","1349f83c":"## Now let's draw a histogram\/count plot to see how the classes are distributed","cfd7737c":"## Importing and Loading Datasets","649e02e5":"- Looks like data is pretty balanced since we didn't see any random pick value. We are good to go for further analysis","090fa2ee":"### Let's pull the top 5 rows value from train variants","aaa61c84":"- Appended the predicted class values to the testing data","cfa87517":"- Awesome we are good to model builing. let's do this.","a23a0c10":"**More to come. Stay tuned.!**","1cf15d0d":"### Now Let's explore the text column and see the text distribution\n","483e265a":"- check if we could use the number of words in the text has predictive power.","bd4ec44a":"## Onehot encoding to get the predicted class values as columns","f6804588":"### Merging Train variants and Train text into one trai dataset","380042b9":"## Now let's merge the test datasets(variants & text) together to one dataset","85612564":"## Work in Progress.....","0a1aa4a2":"\n# Splitting Datasets into Training and Testing sets\n**- Splitting Datasets into Training & Testing sets by using scikit learn library**\n","47334f89":"## Preparing submission data","86d071aa":"### Check test data is clean or not","ee7dfe27":"- Okay, We have only 1 missing value in text data. let's remove it.","6596d4b9":"## Missing Value Analysis\n\n- Check for missing values in both training and testing data columns"}}