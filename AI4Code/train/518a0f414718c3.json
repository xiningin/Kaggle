{"cell_type":{"f8303db6":"code","c53e024b":"code","89d60955":"code","f274ae58":"code","08dc1352":"code","eafe3f8a":"code","d60caf18":"code","10c299d2":"code","9327b02f":"code","989de3fd":"code","152b6c1a":"code","f2461a82":"code","d1fab83e":"code","befd2b23":"code","b0ce1489":"markdown","e88b2509":"markdown","02555220":"markdown","2c3231a7":"markdown","515c8289":"markdown","06d1e0bc":"markdown","e4a89239":"markdown","1ca30c3a":"markdown","4b9841c7":"markdown"},"source":{"f8303db6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c53e024b":"# Necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Libraries for ML model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","89d60955":"# Reading the training Dataset\ntrain_df = pd.read_csv(\"..\/input\/disease-prediction-using-machine-learning\/Training.csv\")\ntrain_df.head()","f274ae58":"# Reading the testing Dataset\ntest_df = pd.read_csv(\"..\/input\/disease-prediction-using-machine-learning\/Testing.csv\")\ntest_df.head()","08dc1352":"train_df.describe()","eafe3f8a":"# checking for testing set\nfor col in list(test_df.columns):\n    print('-'*35 + col + '-' * 35 , end='*')\n    display(test_df[col].unique())\n    ","d60caf18":"train_df.drop('Unnamed: 133', axis=1, inplace=True)\ntrain_df.info()","10c299d2":"train_df.isnull().sum()","9327b02f":"# split dataset into attributes and labels\nX_train = train_df.iloc[:,:-1].values # the training attributes\ny_train = train_df.iloc[:,132].values # the training labels\nX_test = test_df.iloc[:,:-1].values # the testing attributes\ny_test = test_df.iloc[:,132].values # the testing labels\nprint(\"X_trainshape: \",X_train.shape,\"y_train_shape: \", y_train.shape)\nprint(\"X_test.shape: \", X_test.shape,\"y_test.shape: \", y_test.shape)","989de3fd":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_predDT = decision_tree.predict(X_test)\nprint(\"Train Accuracy: \",round(accuracy_score(y_train, decision_tree.predict(X_train))*100,2))\nprint(\"Test Accuracy: \",round(accuracy_score(y_test, Y_predDT) * 100 ,2))","152b6c1a":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_predRF = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nprint(\"Train Accuracy: \",round(accuracy_score(y_train, random_forest.predict(X_train))*100,2))\nprint(\"Test Accuracy: \",round(accuracy_score(y_test, Y_predRF)*100,2))","f2461a82":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nY_predLR = logreg.predict(X_test)\nprint(\"Train Accuracy: \",round(accuracy_score(y_train, logreg.predict(X_train))*100,2))\nprint(\"Test Accuracy: \",round(accuracy_score(y_test, Y_predLR) * 100,2))","d1fab83e":"# Tabular Representation of model accuracy of Training set\nmodels_train = pd.DataFrame({\n    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression'],\n    'Score': [round(accuracy_score(y_train, decision_tree.predict(X_train))*100,2),\n              round(accuracy_score(y_train, random_forest.predict(X_train))*100,2),\n              round(accuracy_score(y_train, logreg.predict(X_train))*100,2)]})\nmodels_train.sort_values(by='Score', ascending=False)","befd2b23":"# Tabular Representation of model accuracy of Testing set\nmodels_test = pd.DataFrame({\n    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression'],\n    'Score': [round(accuracy_score(y_test, Y_predDT) * 100 ,2),\n              round(accuracy_score(y_test, Y_predRF)*100,2),\n              round(accuracy_score(y_test, Y_predLR) * 100,2)]})\nmodels_test.sort_values(by='Score', ascending=False)","b0ce1489":"We have no nulls in the data now we can proceed to building the ML model.","e88b2509":"We can see that in training set out of 133 variables `131 of them have binary categorical` (0 or 1) values. The column named \"Unnamed: 133\" seemed to be null so we will be dropping that column for futher analysis.","02555220":"Lets see get started with the training data","2c3231a7":"We have 4920 entries of data (row) and 132 variables (columns) and 1 target variable with a string format","515c8289":"In conclusion, the logistic model can be choosen as the best model to identify prognosis.","06d1e0bc":"Task highlights:\n\n> Perform Supervised Machine Learning on Disease Prediction dataset (https:\/\/www.kaggle.com\/kaushil268\/disease-prediction-using-machine-learning as at Sep 27, 2021)\n\n> Exploring the data\n\n> Performing Machine Learning model predictions on training and test sets\n","e4a89239":"Hello, My name is Swapnil and we are here today to create ML model for disease prediction. The following dataset details can be viewed at https:\/\/www.kaggle.com\/kaushil268\/disease-prediction-using-machine-learning.\n\nThis dataset includes `132 predictive variables` by which `42 diseases` can be classified with the help of these predictive variables. The predictive variables are binary variables where 1 stands for the certain symptoms to be positive and 0 stands for certain symptoms to be negative or absent. The aim of the case study is to create a Machine Learning model with good accuracy and precision to identify these diseases.\n","1ca30c3a":"As you can see,`Logistic Regression` model has the most important performance metrics with `100% accuracy` among\n> Decision Tree with 97.62% accuracy and\n> Random Forest with 97.62% accuracy.","4b9841c7":"Thus all prognosis are almost perfectly classified and predicted. The small difference between Decision Tree model and Random forest model's train and test datasets indicated that these models dont suffer from overfitting nor underfitting."}}