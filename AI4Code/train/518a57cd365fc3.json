{"cell_type":{"2b86622a":"code","26fa501d":"code","d9d39753":"code","28f36324":"code","2a009f85":"code","bae276b3":"code","f17634d4":"code","c8e9cef0":"code","ff0c5f92":"code","8313885d":"code","406ebf51":"code","e20821a0":"code","d09c0d61":"code","df970fe3":"code","477b96c8":"code","618c4b86":"code","e8ba77df":"code","3c66b369":"code","2bf6e714":"code","db3bd25f":"code","8f8f1171":"code","581aa3f7":"code","58501ae3":"code","e0f46890":"code","ccc71691":"code","9dc60e0b":"code","677dd119":"code","9363dcb1":"code","86b46d60":"code","f7cb1d2e":"code","ea52e112":"code","aa651b35":"code","b5655992":"code","9104cac4":"code","17e9934a":"code","8cecff78":"code","8957a4e8":"code","d4be2c70":"code","3e7b5be7":"markdown","be754f66":"markdown"},"source":{"2b86622a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use('ggplot')","26fa501d":"data = pd.read_csv('..\/input\/heart-disease\/heart.csv')","d9d39753":"data.head()","28f36324":"data.isnull().sum()","2a009f85":"data.dtypes","bae276b3":"data.hist(figsize=(10,8))\nplt.tight_layout()\nplt.show()","f17634d4":"# distribution plot for numeric variables","c8e9cef0":"fig, ax = plt.subplots(5,1, figsize=(11,10))\nsns.histplot(data['age'], ax=ax[0], kde=True)\nsns.histplot(data['trestbps'], ax=ax[1], kde=True)\nsns.histplot(data['chol'], ax=ax[2], kde=True)\nsns.histplot(data['thalach'], ax=ax[3], kde=True)\nsns.histplot(data['oldpeak'], ax=ax[4], kde=True)","ff0c5f92":"# correlation and heatmap","8313885d":"corr_matrix = data.corr()\nmask = np.array(corr_matrix)\nmask[np.tril_indices_from(mask, 0)] = False","406ebf51":"plt.figure(figsize=(11,9))\nsns.heatmap(corr_matrix, mask=mask, annot=True, \n           square=True, cmap='viridis')\nplt.tight_layout()\nplt.xticks(rotation=45)\nplt.show()","e20821a0":"#Data preprocessing","d09c0d61":"cat_variables = ['cp', 'restecg', 'slope', 'thal']\nX = data.iloc[:,:-1].copy()\ny = data['target']","df970fe3":"X_enc = pd.get_dummies(X, columns=cat_variables)","477b96c8":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import plot_confusion_matrix","618c4b86":"X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=0.33, random_state=101)","e8ba77df":"clf = DecisionTreeClassifier(random_state=101)\nclf = clf.fit(X_train, y_train)","3c66b369":"plot_confusion_matrix(clf, X_test, y_test)\nplt.grid(())","2bf6e714":"plt.figure(figsize=(20,15))\nplot_tree(clf, \n          rounded=True,\n         filled=True,\n         feature_names=X_enc.columns)\nplt.show()","db3bd25f":"path = clf.cost_complexity_pruning_path(X_train, y_train)","8f8f1171":"ccp_alphas = path['ccp_alphas'][:-1]","581aa3f7":"clfs = []\n\nfor alpha in ccp_alphas:\n    dt = DecisionTreeClassifier(random_state=101, ccp_alpha=alpha)\n    dt = dt.fit(X_train, y_train)\n    clfs.append(dt)","58501ae3":"# calculate scores for both train and set set\ntrain_scores = [dt.score(X_train, y_train) for dt in clfs]\ntest_scores = [dt.score(X_test, y_test) for dt in clfs] ","e0f46890":"plt.figure(figsize=(11,7))\nplt.plot(ccp_alphas, train_scores, label='train set', color='r', marker='o', ls= '--', drawstyle='steps-post')\nplt.plot(ccp_alphas, test_scores, label='test set', color='g',marker='o', ls= '--', drawstyle='steps-post')\nplt.legend()","ccc71691":"# Choosing alpha 0.017 as it leads to higher accuracy","9dc60e0b":"# Using cross validation to test 0.017 (alpha) ","677dd119":"clf = DecisionTreeClassifier(random_state=101, ccp_alpha=0.017)","9363dcb1":"scores = cross_val_score(clf, X_train, y_train, cv=5)\ndf_scores = pd.DataFrame(data={'tree': range(1,6),\n                               'accuracy': scores})","86b46d60":"df_scores.head()","f7cb1d2e":"plt.figure(figsize=(10,8))\ndf_scores.plot(x='tree', y='accuracy', marker='o', ls='--')","ea52e112":"# As the accuracy is quite sensitive to different datasets, so their mean and std are calculated\n\nalpha_cross = []\n\nfor alpha in ccp_alphas:\n    dt = DecisionTreeClassifier(random_state=101, ccp_alpha=alpha)\n    scores = cross_val_score(dt, X_train, y_train, cv=5)\n    alpha_cross.append([alpha, np.mean(scores), np.std(scores)])\n\ndf_cross = pd.DataFrame(alpha_cross, \n                        columns=['ccp_alpha', 'mean_accuracy', 'std_accuracy'])","aa651b35":"df_cross.head()","b5655992":"plt.figure(figsize=(11,9))\ndf_cross.plot(x='ccp_alpha',\n              y='mean_accuracy',\n              yerr='std_accuracy', \n              marker='o',\n              ls='--')","9104cac4":"# Take the best value\ndf_cross.sort_values(by='mean_accuracy', ascending=False).head(3)","17e9934a":"final_alpha = df_cross.iloc[15,0]\nprint(\"The ideal alpha for this dt model is %3.5f\" % final_alpha)","8cecff78":"# Buiding the final model\n\nfinal_clf = DecisionTreeClassifier(random_state=101, ccp_alpha=final_alpha)\nfianl_clf = final_clf.fit(X_train, y_train)","8957a4e8":"# plot confusion matrix\nplot_confusion_matrix(final_clf, X_test, y_test)\nplt.grid(())","d4be2c70":"# It is better than previous one!! \n# Finished !! \n","3e7b5be7":"## EDA","be754f66":"`pruning trees"}}