{"cell_type":{"5c81787b":"code","76c6c25a":"code","48d6c795":"code","b9388f95":"code","e6eb9fea":"code","4c11ecbd":"code","54e8ef9e":"markdown"},"source":{"5c81787b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","76c6c25a":"class BasicRNN(nn.Module):\n    def __init__(self, n_inputs, n_neurons):    \n        super(BasicRNN, self).__init__()\n        \n        self.Wx = torch.randn(n_inputs, n_neurons) # n_inputs X n_neurons\n        self.Wy = torch.randn(n_neurons, n_neurons) # n_neurons X n_neurons\n        self.b = torch.zeros(1, n_neurons) # 1 X n_neurons\n        \n    def forward(self, X0, X1):\n        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons        \n        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + torch.mm(X1, self.Wx) + self.b) # batch_size X n_neurons\n        return self.Y0, self.Y1    ","48d6c795":"N_INPUT = 3 # number of features in input\nN_NEURONS = 5 # number of units in layer\n\nX0_batch = torch.tensor([[0,1,2], [3,4,5], \n                         [6,7,8], [9,0,1]],\n                        dtype = torch.float) #t=0 => 4 X 3\n\nX1_batch = torch.tensor([[9,8,7], [0,0,0], \n                         [6,5,4], [3,2,1]],\n                        dtype = torch.float) #t=1 => 4 X 3\n\nmodel = BasicRNN(N_INPUT, N_NEURONS)\n\nY0_val, Y1_val = model(X0_batch, X1_batch)","b9388f95":"print(Y0_val)\nprint(Y1_val)","e6eb9fea":"rnn = nn.RNNCell(3, 5) # n_input X n_neurons\nX_batch = torch.tensor([[[0,1,2], [3,4,5], \n                         [6,7,8], [9,0,1]],\n                        [[9,8,7], [0,0,0], \n                         [6,5,4], [3,2,1]]\n                       ], dtype = torch.float) # X0 and X1\nhx = torch.randn(4, 5) # m X n_neurons\noutput = []\n\n# for each time step\nfor i in range(2):\n    hx = rnn(X_batch[i], hx)\n    output.append(hx)\n\nprint(output)","4c11ecbd":"class CleanBasicRNN(nn.Module):\n    def __init__(self, batch_size, n_inputs, n_neurons):\n        super(CleanBasicRNN, self).__init__()\n        \n        rnn = nn.RNNCell(n_inputs, n_neurons)\n        self.hx = torch.randn(batch_size, n_neurons) # initialize hidden state\n        \n    def forward(self, X):\n        output = []\n\n        # for each time step\n        for i in range(2):\n            self.hx = rnn(X[i], self.hx)\n            output.append(self.hx)\n        \n        return output, self.hx\n\nFIXED_BATCH_SIZE = 4 # our batch size is fixed for now\nN_INPUT = 3\nN_NEURONS = 5\n\nX_batch = torch.tensor([[[0,1,2], [3,4,5], \n                         [6,7,8], [9,0,1]],\n                        [[9,8,7], [0,0,0], \n                         [6,5,4], [3,2,1]]\n                       ], dtype = torch.float) # X0 and X1\n\n\nmodel = CleanBasicRNN(FIXED_BATCH_SIZE, N_INPUT, N_NEURONS)\noutput_val, states_val = model(X_batch)\nprint(output_val) # contains all output for all timesteps\nprint(states_val) # contains values for final state or final timestep, i.e., t=1","54e8ef9e":"![](https:\/\/miro.medium.com\/max\/700\/1*o65pRKyHxhw7m8LgMbVERg.png)"}}