{"cell_type":{"a5810d68":"code","a77421ff":"code","f032b326":"code","d06f021c":"code","14a952f9":"code","2894da55":"code","00fed8f5":"code","e9bccb93":"code","29b98835":"code","f3429904":"code","9ca7055e":"code","9a846480":"code","83d173ff":"code","5bc53240":"code","74c7c8f9":"code","1b01e606":"code","b3f3afd6":"code","6b874101":"code","f3094ec1":"code","de6eb635":"code","3927b285":"code","006648d3":"code","d2524d7d":"markdown","0b01ace8":"markdown","15939971":"markdown","e50ffd8d":"markdown","ef9bc177":"markdown","f3a1d12a":"markdown","37e13c6f":"markdown","dfe4f9e5":"markdown","9b39af6a":"markdown","eaab4095":"markdown","43208dd4":"markdown","eb130cc8":"markdown","53ce57de":"markdown","13837bc7":"markdown"},"source":{"a5810d68":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\n\n# Note that there are no NANs in these data; '?' is\n# used when there is missing information\nrating = pd.read_csv('..\/input\/rating_final.csv')","a77421ff":"rating.head()","f032b326":"# Surprise's Input is a df of this shape :\noverall_rating = rating[['userID','placeID','rating']]\noverall_rating.head()","d06f021c":"from surprise import SVD,SVDpp,KNNBasic,KNNWithZScore\nfrom surprise.dataset import Reader, Dataset\nfrom surprise.model_selection import LeaveOneOut\nfrom surprise import accuracy","14a952f9":"reader = Reader(rating_scale=(0, 2))\nds = Dataset.load_from_df(overall_rating,reader)\nloo = LeaveOneOut(n_splits=1,min_n_ratings=1)","2894da55":"LR = [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5]","00fed8f5":"train_loss = []\ntest_loss = []\nmodels = []\nfor i in range(len(LR)) :\n    lr_all = LR[i]\n    algo = SVD(n_epochs=50,reg_all=0.01,lr_all=lr_all)\n    models.append(algo)\n    for trainset,testset in loo.split(ds) : #train - validation split with leave one out\n        # train and test algorithm.\n        algo.fit(trainset)\n        train_pred = algo.test(trainset.build_testset())\n        test_pred = algo.test(testset)\n\n        # Compute and print Root Mean Squared Error\n        train_rmse = accuracy.rmse(train_pred, verbose=False)\n        test_rmse = accuracy.rmse(test_pred, verbose=False)\n        train_loss.append(train_rmse)\n        test_loss.append(test_rmse)","e9bccb93":"plt.plot(LR,train_loss,label='train')\nplt.plot(LR,test_loss, label = 'test')\nplt.xlabel('learning_rate')\nplt.ylabel('rmse')\nplt.legend()","29b98835":"# Index of minimum element\ni = test_loss.index(min(test_loss))\n# using the best model\nalgo = models[i]\n# predicting rating\nalgo.predict('U1077','132825')","f3429904":"from surprise.model_selection import GridSearchCV\nparam_grid = {\n    'n_factors' : [10, 20, 50, 100, 130, 150, 200],\n    'n_epochs': [10, 15, 30, 50, 100], \n    'lr_all': [0.001, 0.005, 0.007, 0.01, 0.05, 0.07, 0.1],\n    'reg_all': [0.01, 0.05, 0.07, 0.1, 0.2, 0.4, 0.6]\n}","9ca7055e":"gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=loo,return_train_measures = True)\ngs_svdpp = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=loo,return_train_measures = True)","9a846480":"gs_svd.fit(ds)\ngs_svdpp.fit(ds)","83d173ff":"# best RMSE score\nprint (\"Best RMSE Scores\")\nprint(f'SVD : {gs_svd.best_score[\"rmse\"]}')\nprint(f'SVDpp : {gs_svdpp.best_score[\"rmse\"]}')\n\n\n# combination of parameters that gave the best RMSE score\nprint(\"Parameters\")\nprint(f\"SVD : {gs_svd.best_params['rmse']}\")\nprint(f\"SVDpp : {gs_svdpp.best_params['rmse']}\")","5bc53240":"results_frame_svd = pd.DataFrame.from_dict(gs_svd.cv_results)\nresults_frame_svd['model'] = 'SVD'\nresults_frame_svdpp = pd.DataFrame.from_dict(gs_svdpp.cv_results)\nresults_frame_svdpp['model'] = 'SVDpp'\nresults_frame = pd.concat([results_frame_svd, results_frame_svdpp])","74c7c8f9":"results_frame.sort_values(by='mean_test_rmse').head()","1b01e606":"sim_options = {'name': ['pearson', 'cosine', 'msd'],\n               'user_based':[ True, False] # compute  similarities between users\n               }\nparam_grid_knn = {\n    'sim_options' : sim_options,\n    'k' : [10, 20, 40, 100],\n    'min_k' : [1, 5 , 10],\n    'verbose' : [False]\n}","b3f3afd6":"gs_knn= GridSearchCV(KNNBasic, param_grid=param_grid_knn, measures=['rmse', 'mae'], cv=loo,return_train_measures = True)\ngs_knnZ= GridSearchCV(KNNWithZScore, param_grid=param_grid_knn, measures=['rmse', 'mae'], cv=loo,return_train_measures = True)","6b874101":"gs_knn.fit(ds)\ngs_knnZ.fit(ds)","f3094ec1":"# best RMSE score\nprint (\"Best RMSE Scores\")\nprint(f'KNN : {gs_knn.best_score[\"rmse\"]}')\nprint(f'KNNWithZScore : {gs_knnZ.best_score[\"rmse\"]}')\n\n\n# combination of parameters that gave the best RMSE score\nprint(\"Parameters\")\nprint(f\"KNN : {gs_knn.best_params['rmse']}\")\nprint(f\"KNNWithZScore : {gs_knnZ.best_params['rmse']}\")","de6eb635":"results_frame_knn = pd.DataFrame.from_dict(gs_knn.cv_results)\nresults_frame_knn['model'] = 'KNN'\nresults_frame_knnZ = pd.DataFrame.from_dict(gs_knnZ.cv_results)\nresults_frame_knnZ['model'] = 'KNNWithZScore'\nresults_frame = pd.concat([results_frame, results_frame_knn, results_frame_knnZ],sort=False)","3927b285":"results_frame['rank_test_mae'] = results_frame['mean_test_mae'].rank()\nresults_frame['rank_test_rmse'] = results_frame['mean_test_rmse'].rank()\nresults_frame.head()","006648d3":"# Export for visualization\nresults_frame.to_csv('results.csv',index=False)","d2524d7d":"### KNN and KNN With Z Score :","0b01ace8":"#### Saving results","15939971":"#### Scores and best parameters","e50ffd8d":"#### Export models performance for visualisation","ef9bc177":"## Classical use of Suprise models\n\nLearning, calculating\/plotting metrics and making predictions\n\n### Fitting model using different parameters\n\nSteps followed :\n\n1. Model initializing :\n    - Call the model's class with chosen parameters\n2. dataset splitting : \n    - Loop over cross validation splits extracting trainset and testset\n3. Fitting model :\n    - Fit model on the train set\n4. Testing :\n    - Test model on train and test sets","f3a1d12a":"### SVD and SVD++ :","37e13c6f":"#### Scores and best parameters","dfe4f9e5":"## Grid search using GridSearchCV\n\nUsing Grid Search to try different parameters\n\n### Workflow :\n\n1. preparing parameter map :\n    - Create a dict of all the parameters you want to try (dict of arrays)\n2. dataset splitting : \n    - Prepare an instance of your preferred cross-validator\n3. Fitting model :\n    - Fit the whole dataset to the grid search instance (separation handled internally)\n4. Testing :\n    - Handled Internally\n5. Visualization :\n    - use the cv_results attribute of your gridsearch instance to visualize results.","9b39af6a":"### Finalize results set :\n\n#### Creating global ranks for metrics","eaab4095":"#### Saving results","43208dd4":"# Recommander systems performance comparision\n\nIn this notebook we compare many models performance on the [Restaurant Data with Consumer Ratings](https:\/\/www.kaggle.com\/uciml\/restaurant-data-with-consumer-ratings) dataset. For that we use [Surprise](http:\/\/surpriselib.com\/) for the ease of use and good documentation. The dataset used here (rating_final) has 1161 lines, so we are not very worried about (fitting) performance.","eb130cc8":"To import a df for use in Surprise, we need to load it into a `Surprise.Dataset`, for that we use `Dataset.load_from_df(dataframe,reader)` where `reader` has to specify the range of ratings in the dataset. \n\n\u26a0\ufe0f We use a different kind of validation, since we're trying to validate a recommender system we use the LeaveOneOut validation. From [Surprise Documentation on Cross Validators](https:\/\/surprise.readthedocs.io\/en\/stable\/model_selection.html#surprise.model_selection.split.LeaveOneOut) :\n> Cross-validation iterator where each user has exactly one rating in the testset.\n> \n> Contrary to other cross-validation strategies, LeaveOneOut does not guarantee that all folds will be different, although this is still very likely for sizeable datasets.\n\nIndeed, we leave one vote out from each user as a test set (user with less than the `min_n_ratings` are eliminated), that way we test the performance of the recommender system in a realistic situation.","53ce57de":"### Plotting test and train rmse lines","13837bc7":"### Predicting a rating"}}