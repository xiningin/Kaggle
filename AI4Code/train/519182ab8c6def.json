{"cell_type":{"0e88e863":"code","6b84c92e":"code","afe59dfc":"code","1f2c72dd":"code","bec8c65e":"code","aec1c061":"code","1c252bb7":"code","a85a47cb":"code","003cc1d5":"code","a1143e35":"code","d5a22609":"code","0fd23a1b":"code","7c45c07d":"code","060afeee":"code","6213ee39":"code","a64dddbd":"code","8ea66457":"code","1b6da7a1":"code","b4081490":"code","384a779a":"code","938296ea":"markdown","82aec8ab":"markdown","b7385738":"markdown","447b63a0":"markdown"},"source":{"0e88e863":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b84c92e":"import os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","afe59dfc":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","1f2c72dd":"train_set = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_set = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","bec8c65e":"# seperating the labels from pixel values in training set\nX = (train_set.iloc[: , 1:].values).astype('float32')\nY = (train_set.iloc[: , [0]].values).astype('float32')","aec1c061":"x_test = test_set.values.astype('float32')","1c252bb7":"#splitting the dataset in test set and valid set\nx_train , x_valid , y_train , y_valid = train_test_split(X , Y , test_size = 0.2)","a85a47cb":"print(\"x_train \" ,x_train.shape)\nprint(\"x_valid \" ,x_valid.shape)\nprint(\"y_train \" ,y_train.shape)\nprint(\"y-valid \" ,y_valid.shape)","003cc1d5":"#Convert X_train in format 28X28 and display first 25 images\nx_train = x_train.reshape(x_train.shape[0], 28, 28)\n\nplt.figure(figsize=(10,10))\ni = 0\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i], cmap=plt.cm.binary)\n    plt.xlabel(y_train[i])\nplt.show()","a1143e35":"#defining the batch size\nBATCH_SIZE = 128","d5a22609":"#Add grayscale chanel as tensorflow inputs three dimensional tensors.\nx_train = x_train.reshape(x_train.shape[0], 28, 28,1)\nx_valid = x_valid.reshape(x_valid.shape[0], 28, 28,1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28,1)","0fd23a1b":"image_train_generator = ImageDataGenerator(rescale = 1.\/255,\n                                    rotation_range=27,\n                                    horizontal_flip=False,\n                                    fill_mode = 'nearest'\n                                    )\n\ntrain_data_gen = image_train_generator.flow(x_train, y_train, batch_size=BATCH_SIZE,\n                                                     shuffle=True)\n                                                   ","7c45c07d":"image_valid_generator = ImageDataGenerator(rescale = 1.\/255)\nvalid_data_gen = image_valid_generator.flow(x_valid , y_valid , batch_size = BATCH_SIZE , shuffle = True)","060afeee":"#model definition\nmodel = tf.keras.Sequential([\n                            tf.keras.layers.Conv2D(64 , (3,3) ,activation='relu', input_shape=(28, 28, 1)), \n                            tf.keras.layers.MaxPooling2D(2,2),\n                            tf.keras.layers.Conv2D(128 , (3,3) ,activation='relu'), \n                            tf.keras.layers.MaxPooling2D(2,2),\n                            tf.keras.layers.Flatten(),\n                            tf.keras.layers.Dense(512, activation='relu'),\n                            tf.keras.layers.Dropout(0.2),\n                            tf.keras.layers.Dense(128, activation='relu'),\n                            tf.keras.layers.Dropout(0.2),\n                            tf.keras.layers.Dense(10 , activation = 'softmax')\n                            \n])","6213ee39":"#compiling the model\nmodel.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n              optimizer = 'adam',\n              metrics = ['accuracy']\n             )","a64dddbd":"#model summary\nmodel.summary()","8ea66457":"#Model training (on 20 epochs)\nepochs= 20\nhistory = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=int(np.ceil(x_train.shape[0]\/ float(BATCH_SIZE))),\n    epochs=epochs,\n    validation_data=valid_data_gen,\n    validation_steps=int(np.ceil(x_valid.shape[0]\/ float(BATCH_SIZE)))\n)","1b6da7a1":"#Plot training and validation graphs\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(10, 10))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","b4081490":"#predictions \npredictions = model.predict_classes(x_test, verbose=0)\n\ninitial_submission=pd.DataFrame({\"ImageId\": list(range(1 ,len(predictions)+1)),\n                         \"Label\": predictions})\ninitial_submission.to_csv(\"Digit_recognition_tf_4.csv\", index=False, header=True)","384a779a":"final accuracy achieved by this model on submission :- 98.971%","938296ea":"Hope you like the content! I tried to illustrate the CNN using tensorflow in easiest way possible. \nI'm also a beginner and open to all suggestions for increasing model performance.\n\nSo do upvote and comment.","82aec8ab":"Our training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\nData needs to be segregated and reshaped in order to feed it into our NN architecture.","b7385738":"# **DIGIT RECOGNIZER COMPETITION**\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\nThis notebook illustrates the simple CNN implementation using Tensorflow.\n**Manually categorizing the image set in folders\n**Use of ImageDataGenerator \n**Building Convolutional Neural Network using tensorflow\n**Dropout Regularisation\n**Assessing model performance and retraining.","447b63a0":"# ImageDataGenerator\nKeras\u2019 ImageDataGenerator class is to perform data augmentation on the available images. Data augmentation encompasses a wide range of techniques used to generate \u201cnew\u201d training samples from the original ones by applying random transformations. Main objectives of using this class are the generalisability of the data and increase the amount of data(In case data not enough).\n\nImageDataGenerator class is imported from *tensorflow.keras.preprocessing.image*."}}