{"cell_type":{"a2375f19":"code","2ef714ac":"code","7c43f091":"code","0c834af4":"code","614bbd09":"code","ed5e0a35":"code","e8caa373":"code","780447ad":"code","6819f4ae":"code","eb910903":"code","4b592a5d":"code","9c9c88e0":"code","e48bac5a":"code","40b84be8":"code","d6dad19e":"code","5de82e36":"code","34831db6":"code","edebfabf":"markdown","cdc9e694":"markdown","a88920bf":"markdown","5a9ce8a2":"markdown","78573916":"markdown","b972c5d3":"markdown","155347c4":"markdown","6cd7b3da":"markdown","84aa4375":"markdown","776c30e3":"markdown"},"source":{"a2375f19":"import os\nimport tqdm\nimport shutil\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","2ef714ac":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7c43f091":"# !rm -rf \/kaggle\/content","0c834af4":"CONTENT_DIR = '\/kaggle\/content'\n\nTRAIN_DIR = CONTENT_DIR + '\/train'\nTRAIN_DIR_DOG = TRAIN_DIR + '\/dog'\nTRAIN_DIR_CAT = TRAIN_DIR + '\/cat'\n\nVALID_DIR = CONTENT_DIR + '\/valid'\nVALID_DIR_DOG = VALID_DIR + '\/dog'\nVALID_DIR_CAT = VALID_DIR + '\/cat'\n\nif not os.path.exists(CONTENT_DIR):\n    import zipfile\n    with zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/train.zip', 'r') as zipf:\n        zipf.extractall(CONTENT_DIR)\n\n    # Split cats and dogs images to train and valid datasets\n    img_filenames = os.listdir(TRAIN_DIR)\n    print('Num of images:', len(img_filenames))\n\n    dog_filenames = [fn for fn in img_filenames if fn.startswith('dog')]\n    cat_filenames = [fn for fn in img_filenames if fn.startswith('cat')]\n\n    dataset_filenames = train_test_split(\n        dog_filenames, cat_filenames, test_size=0.1, shuffle=True, random_state=42\n    )\n\n    train_dog_total, valid_dog_total, train_cat_total, valid_cat_total = [len(fns) for fns in dataset_filenames]\n    train_total = train_dog_total + train_cat_total\n    valid_total = valid_dog_total + valid_cat_total\n    print('Train: {}, test: {}'.format(train_total, valid_total))\n\n    # Move images\n    make_dirs = [TRAIN_DIR_DOG, VALID_DIR_DOG, TRAIN_DIR_CAT, VALID_DIR_CAT]\n    for dir, fns in zip(make_dirs, dataset_filenames):\n        os.makedirs(dir, exist_ok=True)\n        for fn in tqdm.tqdm(fns):\n            shutil.move(os.path.join(TRAIN_DIR, fn), dir)\n        print('elements in {}: {}'.format(dir, len(os.listdir(dir))))","614bbd09":"BATCH_SIZE = 128\nIMAGE_SHAPE = 128","ed5e0a35":"def plot_images(images):\n    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n    for img, ax in zip(images, axes.flatten()):\n        ax.imshow(img)\n    plt.tight_layout()\n    plt.show()    ","e8caa373":"def show_augmentation(generator):\n    image_data = image_generator.flow_from_directory(\n        directory=TRAIN_DIR,\n        target_size=(IMAGE_SHAPE, IMAGE_SHAPE),\n        batch_size=BATCH_SIZE,\n        shuffle=True\n    )\n    augmented_images = [image_data[0][0][0] for _ in range(5)]\n    plot_images(augmented_images)","780447ad":"image_generator = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True)\nshow_augmentation(image_generator)","6819f4ae":"image_generator = ImageDataGenerator(rescale=1.\/255, rotation_range=45)\nshow_augmentation(image_generator)","eb910903":"image_generator = ImageDataGenerator(rescale=1.\/255, zoom_range=0.5)\nshow_augmentation(image_generator)","4b592a5d":"image_generator = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    rescale=1.\/255\n)\ntrain_data = image_generator.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=(IMAGE_SHAPE, IMAGE_SHAPE),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    class_mode='binary'\n)\nshow_augmentation(image_generator)","9c9c88e0":"valid_generator = ImageDataGenerator(rescale=1.\/255)\nvalid_data = valid_generator.flow_from_directory(\n    directory=VALID_DIR,\n    target_size=(IMAGE_SHAPE, IMAGE_SHAPE),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)","e48bac5a":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(\n        filters=32,\n        kernel_size=(3, 3),\n        activation='relu',\n        input_shape=(IMAGE_SHAPE, IMAGE_SHAPE, 3)\n    ),\n    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # dropout layer\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=512, activation='relu'),\n    tf.keras.layers.Dense(units=2, activation='softmax')\n])","40b84be8":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","d6dad19e":"model.summary()","5de82e36":"EPOCHS = 60\nhistory = model.fit_generator(\n    generator=train_data,\n    steps_per_epoch=(train_total + BATCH_SIZE - 1) \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=valid_data,\n    validation_steps=(valid_total + BATCH_SIZE - 1) \/\/ BATCH_SIZE,\n)","34831db6":"plt.figure(figsize=(12, 8))\n\nplt.subplot(1, 2, 1)\nplt.plot(range(EPOCHS), history.history['accuracy'], label='train')\nplt.plot(range(EPOCHS), history.history['val_accuracy'], label='valid')\nplt.legend(loc='lower right')\nplt.title('Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(EPOCHS), history.history['loss'], label='train')\nplt.plot(range(EPOCHS), history.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Loss (sparse_categorical_crossentropy)')\n\nplt.show()","edebfabf":"# Load data\nCopied from my [Intro to CNN (Dogs vs. Cats)](http:\/\/https:\/\/www.kaggle.com\/imcr00z\/intro-to-cnn-dogs-vs-cats)","cdc9e694":"# Train visualization\nLook at it and compare with the graph [here](http:\/\/https:\/\/www.kaggle.com\/imcr00z\/intro-to-cnn-dogs-vs-cats)","a88920bf":"## Zoom","5a9ce8a2":"# Augmentation\nWe change images to increase the size of the dataset.","78573916":"# Model\nWith dropout layer.","b972c5d3":"## Horisontal flipping","155347c4":"## Rotation","6cd7b3da":"## Putting it all together","84aa4375":"**Some tricks to combat overfitting**\n\n* Part 1 [Intro to CNN (Dogs vs. Cats)](https:\/\/www.kaggle.com\/imcr00z\/intro-to-cnn-dogs-vs-cats)\n* Part 2\n* Part 3 [Transfer Learning (Dogs vs. Cats) 98% acc.](https:\/\/www.kaggle.com\/imcr00z\/transfer-learning-dogs-vs-cats-98-acc)\n\nIn this part i use augmentation and dropout layers to reduce overfitting and increase the predictive power of the model.","776c30e3":"# Valid data"}}