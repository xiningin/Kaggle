{"cell_type":{"d89df82e":"code","fa7c02d8":"code","1b788dae":"code","9faf430a":"code","b0be45c0":"code","8e70274b":"code","666a6259":"code","d88f1461":"code","3f95c9b0":"code","eb67c3a8":"code","6876c392":"code","b1f2aab7":"code","7eb3d9ae":"code","07c3577a":"code","1cae65f7":"markdown","a2870ab0":"markdown","0916fcac":"markdown","d31649c3":"markdown","26772f45":"markdown","4dfa2e92":"markdown","76057be7":"markdown","bfb0df29":"markdown","bd0f3e8f":"markdown","57cdcb8f":"markdown","87a22e2f":"markdown"},"source":{"d89df82e":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets, linear_model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport requests\nimport joblib\n\n\n# fix random seed for reproducibility\nnp.random.seed(7)\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n%matplotlib inline","fa7c02d8":"path_name = \"..\/input\/392-crypto-currency-pairs-at-minute-resolution\/btcusd.csv\" \ndf = pd.read_csv(path_name, index_col='time')\ndf.index = pd.to_datetime(df.index, unit='ms')\ndf = df[~df.index.duplicated(keep='first')]\ndf = df.resample('1T').pad()","1b788dae":"#Get scaled differences between open and close\ndf['delta'] = (df.close - df.open) \/ df.open\n# Adding a previous close column\ndf['prev_close'] = df['close'].shift(1)","9faf430a":"df.sample(5)","b0be45c0":"df.tail(5)","8e70274b":"plt.figure(figsize=(15,10))\nplt.plot(df.index[-100000:], df.close[-100000:])\nplt.show()","666a6259":"def create_dataset(dataset, look_back=5):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","d88f1461":"dataset = df['close'][-100000:].values\ndataset = dataset.astype('float32')\ndataset = dataset.reshape(-1, 1)\ndataset","3f95c9b0":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))","eb67c3a8":"# reshape into X=t and Y=t+1\nlook_back = 6\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\ntestX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))","6876c392":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(look_back, 1)))\nmodel.add(Dense(8))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1, verbose=2)","b1f2aab7":"# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","7eb3d9ae":"# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.figure(figsize=(15,10))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","07c3577a":"# Scaler\nscaler_filename = \"scaler.save\"\njoblib.dump(scaler, scaler_filename) \n# Model\nmodel.save('keras_lstm_uni.h5')","1cae65f7":"# Thanks for making it to the end! I'm only two bronze medals away from Kaggle Expert (searching for jobs so maybe it would look cool on my LinkedIn?) so please leave a upvote if you enjoyed this notebook and\/or know the struggle of job searching!","a2870ab0":"# Univariate LSTM","0916fcac":"### Save Model","d31649c3":"## Training","26772f45":"# This is a work in progress. I am updating this code, and it  will be featured in a Medium article. ","4dfa2e92":"## If this notebook gets 10 upvotes I will release the Inference code notebook for real time deployment.","76057be7":"# **Bitcoin minute-by-minute predictions**","bfb0df29":"## Evaluation","bd0f3e8f":"## Prepare Dataset","57cdcb8f":"# Load in Data","87a22e2f":"# Import Libraries"}}