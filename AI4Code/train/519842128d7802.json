{"cell_type":{"aaa48e0e":"code","62e9b7e7":"code","6be49abf":"code","3132264b":"code","d917269f":"code","ab7befa2":"code","54144a9f":"code","36330f9b":"code","fc214912":"code","cb26f11d":"code","693589b8":"code","29b13d5e":"code","b707dfc3":"code","25349cdc":"code","3070c992":"code","1bc8f3cd":"code","77a2d572":"code","c8a900c7":"code","d99ab2af":"code","e6adcbd5":"code","5d25fbbd":"code","0e0a51cd":"code","61207a24":"code","ec17112e":"code","e56ddc47":"code","27dc1bc5":"code","773e5a64":"code","90b81521":"code","19f2f84a":"code","f2aed54f":"code","0e2c966c":"code","ba9ca3d2":"code","9b77fea9":"code","092cab0a":"code","ba60acc8":"code","f00d347d":"code","d51e050f":"code","be428dea":"code","bfc65e47":"code","48498eb2":"code","53e0e8a1":"code","3c5af710":"code","e41bf13b":"code","25e7fd32":"code","0d114fc1":"code","d7e463df":"code","7dce3b7d":"code","41f4c68c":"code","6fa64222":"code","b5b6e819":"code","2b8ab58e":"code","801da03e":"code","0dbdca05":"code","4832cc64":"code","86954fc5":"code","8765c851":"code","40e189ae":"code","0541659c":"code","f387068e":"markdown","566ffd23":"markdown","a1e93640":"markdown","ba878b92":"markdown","209cf150":"markdown","45eb8611":"markdown","e01dfe25":"markdown","99c2f7e5":"markdown","e5919fd0":"markdown","042d38c0":"markdown","4f978efd":"markdown","f19081a9":"markdown"},"source":{"aaa48e0e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport sys\nimport os\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nimport os\nprint(os.listdir(\"..\/input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","62e9b7e7":"df_train=pd.read_csv('..\/input\/train.csv')\ndf_test=pd.read_csv('..\/input\/test.csv')","6be49abf":"print(df_train.shape)\nprint(df_test.shape)","3132264b":"df_train.isnull().sum()","d917269f":"df_train.describe()","ab7befa2":"df_train.dtypes","54144a9f":"df_train['Embarked'].value_counts()","36330f9b":"df_train['Embarked'].fillna('S',inplace=True)\ndf_test['Embarked'].fillna('S',inplace=True)","fc214912":"df_train['Cabin'].fillna('None',inplace=True)\ndf_test['Cabin'].fillna('None',inplace=True)","cb26f11d":"sns.countplot(df_train['Age'])","693589b8":"age=df_train['Age'].unique()","29b13d5e":"print(age)","b707dfc3":"age.sort()","25349cdc":"age=np.delete(age,-1)","3070c992":"age","1bc8f3cd":"mean=age.mean()","77a2d572":"df_train['Age'].fillna(mean,inplace=True)\ndf_test['Age'].fillna(mean,inplace=True)","c8a900c7":"fare=df_test['Fare'].unique()","d99ab2af":"fare.sort()","e6adcbd5":"fare=np.delete(age,-1)","5d25fbbd":"fare=fare.mean()\ndf_test['Fare'].fillna(fare,inplace=True)","0e0a51cd":"print(df_test.isnull().sum())\nprint('---------------------------')\nprint(df_train.isnull().sum())","61207a24":"bins = [0,10,20,30,40,50,60,70,80]\nlabels = [1,2,3,4,5,6,7,8]\ndf_train['Agebinned'] = pd.cut(df_train['Age'], bins=bins, labels=labels)\ndf_test['Agebinned']=pd.cut(df_test['Age'],bins=bins,labels=labels)","ec17112e":"df_train.head()","e56ddc47":"Embarkeddum=pd.get_dummies(df_train['Embarked'])\nEmbarkeddumt=pd.get_dummies(df_test['Embarked'])\ndf_train=pd.concat([df_train,Embarkeddum],axis=1)\ndf_test=pd.concat([df_test,Embarkeddumt],axis=1)\nPclassdum=pd.get_dummies(df_train['Pclass'])\nPclassdumt=pd.get_dummies(df_test['Pclass'])\nPclassdum.rename(columns={1:'p1',2:'p2',3:'p3'},inplace=True)\nPclassdumt.rename(columns={1:'p1',2:'p2',3:'p3'},inplace=True)\ndf_train=pd.concat([df_train,Pclassdum],axis=1)\ndf_test=pd.concat([df_test,Pclassdumt],axis=1)","27dc1bc5":"df_train.dtypes","773e5a64":"bins = [-1,0,100,200,300,400,500,600]\nlabels = [0,1,2,3,4,5,6]\ndf_train['Farebin'] = pd.cut(df_train['Fare'], bins=bins, labels=labels)\ndf_test['Farebin']=pd.cut(df_test['Fare'],bins=bins,labels=labels)","90b81521":"df_train['Farebin'].unique()","19f2f84a":"from sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()","f2aed54f":"df_train['Sex']=labelencoder.fit_transform(df_train['Sex'])\ndf_test['Sex']=labelencoder.fit_transform(df_test['Sex'])","0e2c966c":"df_train.head()","ba9ca3d2":"df_train['Fam']=df_train['SibSp']+df_train['Parch']\ndf_test['Fam']=df_test['SibSp']+df_test['Parch']","9b77fea9":"df_train['AgebinnedI']=df_train['Agebinned'].astype(int)\ndf_test['AgebinnedI']=df_test['Agebinned'].astype(int)\ndf_train['FarebinI']=df_train['Farebin'].astype(int)\ndf_test['FarebinI']=df_test['Farebin'].astype(int)","092cab0a":"df_train.dtypes","ba60acc8":"sns.countplot(df_train['Pclass'],hue=df_train['Sex'])","f00d347d":"sns.countplot(df_train['Sex'])","d51e050f":"sns.countplot(df_train['Agebinned'],hue=df_train['Sex']) #Check Age Bins For more Info","be428dea":"sns.countplot(df_train['Fam'],hue=df_train['Sex'])","bfc65e47":"sns.countplot(df_train['Farebin'])","48498eb2":"sns.countplot(df_train['Embarked'])","53e0e8a1":"features=['Pclass','Sex','Agebinned','Fam','Farebin','Embarked']\nfor i in features:\n    plt.figure()\n    sns.barplot(df_train[i],df_train['Survived'])","3c5af710":"# df['lunch'] = (df['hour']<=11) & (df['hour']<=1)\ndf_train['IsAlone']=(df_train['Fam']==0)\ndf_train['IsAlone']=df_train['IsAlone'].astype(int)\ndf_test['IsAlone']=(df_test['Fam']==0)\ndf_test['IsAlone']=df_test['IsAlone'].astype(int)\ndf_train.head()","e41bf13b":"df_newtrain=df_train[['Sex','Q','S','p1','p2','Fam','AgebinnedI','FarebinI','IsAlone']]\ndf_newtest=df_test[['Sex','Q','S','p1','p2','Fam','AgebinnedI','FarebinI','IsAlone']]\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(df_newtrain.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","25e7fd32":"x_train = df_newtrain.copy()\ny_train = df_train[\"Survived\"]\nx_test  = df_newtest.copy()\nx_train.shape, y_train.shape, x_test.shape","0d114fc1":"################################################LOGISTIC REGRESSION#######################################################\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_log = round(logreg.score(x_train, y_train) * 100, 2)\nacc_log","d7e463df":"coeff_df = pd.DataFrame(df_newtrain.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","7dce3b7d":"##############################################Support Vector Machines#######################################3\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)\nacc_svc = round(svc.score(x_train, y_train) * 100, 2)\nacc_svc","41f4c68c":"###################################K-Nearest-Neighbours###############################\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train, y_train)\nyt_pred = knn.predict(x_test)\nacc_knn = round(knn.score(x_train, y_train) * 100, 2)\nacc_knn","6fa64222":"###########################################Gaussian Naive Bayes############################################\ngaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred = gaussian.predict(x_test)\nacc_gaussian = round(gaussian.score(x_train, y_train) * 100, 2)\nacc_gaussian","b5b6e819":"#############################################Perceptron#################################################\nperceptron = Perceptron()\nperceptron.fit(x_train, y_train)\ny_pred = perceptron.predict(x_test)\nacc_perceptron = round(perceptron.score(x_train, y_train) * 100, 2)\nacc_perceptron","2b8ab58e":"#####################################Linear SVC#####################################################\nlinear_svc = LinearSVC()\nlinear_svc.fit(x_train, y_train)\ny_pred = linear_svc.predict(x_test)\nacc_linear_svc = round(linear_svc.score(x_train, y_train) * 100, 2)\nacc_linear_svc","801da03e":"#################################Stochastic Gradient Descent#########################################################\nsgd = SGDClassifier()\nsgd.fit(x_train,y_train)\ny_pred = sgd.predict(x_test)\nacc_sgd = round(sgd.score(x_train,y_train) * 100, 2)\nacc_sgd","0dbdca05":"##########################################Decision Tree#########################################################\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(x_train, y_train)\ny_pred = decision_tree.predict(x_test)\nacc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\nacc_decision_tree","4832cc64":"################################################Random Forest######################################################\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(x_train, y_train)\nYtx_pred = random_forest.predict(x_test)\nrandom_forest.score(x_train, y_train)\nacc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\nacc_random_forest","86954fc5":"###############################################XGBOOST#####################################################\nxgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.5, gamma=0, subsample=1,\n                           colsample_bytree=1, max_depth=10)\nxgb.fit(x_train,y_train)\nYt_pred= xgb.predict(x_test)\nxgb.score(x_train, y_train)\nacc_xgb = round(xgb.score(x_train, y_train) * 100, 2)\nacc_xgb","8765c851":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree','XGBoost'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree,acc_xgb]})\nmodels.sort_values(by='Score', ascending=False)","40e189ae":"submission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": Ytx_pred\n    })","0541659c":"submission.to_csv('submission.csv', index=False)","f387068e":"1 fare Value missing in test data set replace by mean value","566ffd23":"Data Cleaning","a1e93640":"Label Encoder for Sex Category","ba878b92":"Model Build:","209cf150":"Feature Engineering:","45eb8611":"Replace Missing Values For Cabin by None","e01dfe25":"Age Count missing . Fill the mean of the total ages in dataset","99c2f7e5":"Replace Missing Values for embarked With the most frequent label","e5919fd0":"Dummy Variable Creation for Embarked and Pclass","042d38c0":"Bivariate Analysis","4f978efd":"Creating bins for age","f19081a9":"EXPLORATORY DATA ANALYSIS\nUNIVARIATE ANALYSIS:"}}