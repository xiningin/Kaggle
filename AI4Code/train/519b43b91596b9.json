{"cell_type":{"ff2c65a6":"code","8a94f163":"code","b47be1cc":"code","820e9579":"code","5b723208":"code","80f6c4a0":"code","53c54fa5":"code","2c4b8dca":"code","4878ed63":"code","62bc3c65":"code","43be4aa2":"code","566c0f29":"code","e8d75849":"code","ce5c8f0d":"code","73a74374":"code","c14b0fc9":"code","139e23ac":"code","d33d152d":"code","ad812f17":"code","80ca5f3b":"code","10b8c2a0":"code","434c3e5b":"code","42f9f049":"code","86cc8887":"code","d1e3ae27":"code","6cfc3c9f":"code","e7485d5f":"code","6a199019":"code","2c313bd4":"code","29736d34":"code","ea4f4faa":"code","eed0210f":"code","0aac5891":"code","598f9b92":"code","5ab48e83":"code","cab1c55f":"code","d86ac538":"code","45fb226f":"code","fc120422":"code","dacba27c":"code","b43fbefa":"code","8203bbae":"code","bf91ce42":"code","a12ee13b":"code","edd3713d":"code","7e1c3967":"code","3abaca05":"code","3ebc7faf":"code","388403eb":"code","e24e3023":"code","b5f330f5":"code","3d69ddd3":"code","b8d3e82a":"code","26c01e3c":"code","3b52a2b1":"code","22688e95":"code","4c5cc625":"code","040879e9":"code","0d77937f":"code","82d54bb9":"code","1e719e01":"code","431edd9f":"code","26266942":"code","24f58b04":"code","38e1be37":"code","ca0036ef":"code","87c301c3":"code","ea9c43ca":"code","c64f755e":"markdown","25219720":"markdown","89d6e1ac":"markdown","32c3a325":"markdown","0d53fee3":"markdown","5eadb6b8":"markdown","1f58de3a":"markdown","f4e1dca8":"markdown","aac1fbd8":"markdown","90b6e93d":"markdown","15e8348a":"markdown","7c244d29":"markdown","37827c9b":"markdown","d3aec604":"markdown","939b57ab":"markdown"},"source":{"ff2c65a6":"import pandas as pd\nimport os\nimport xml.etree.ElementTree as ET\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n%matplotlib inline\npd.set_option(\"display.max_columns\", None)","8a94f163":"# data path\n\ndataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'","b47be1cc":"# Reading Holidays\n# create a function to convert holidays xml file to dataframe\ndef xml_to_df(file_path):\n    tree = ET.parse(file_path)\n    root = tree.getroot()\n    columns = [\"date\", \"holiday\"]\n    holidays_df = pd.DataFrame(columns = columns)\n    for node in root:\n        date = node.find(\"date\").text\n        holiday = 1\n        holidays_df = holidays_df.append(pd.Series([date, holiday], index = columns), ignore_index = True)\n        holidays_df['date'] = pd.to_datetime(holidays_df['date'])\n    return holidays_df","820e9579":"holidays_df = xml_to_df(os.path.join(dataset_path,\"holidays.xml\"))","5b723208":"holidays_df.head()","80f6c4a0":"holidays_df.info()","53c54fa5":"# Read Weather file\nweather_df = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))\nweather_df.head()","2c4b8dca":"# collect the date in one column\nweather_df['date'] = weather_df['Year'].astype(str) +'-'+ weather_df['Month'].astype(str) +'-'+ weather_df['Day'].astype(str) +' '+ weather_df['Hour'].astype(str) +':00:00'\nweather_df['date'] = pd.to_datetime(weather_df['date'])","4878ed63":"# dropping duplicate weather info at the same date\nweather_df.drop_duplicates(subset='date',inplace=True)","62bc3c65":"# encode\n# use this encoder to encode\nle = LabelEncoder()\n\nweather_df.Weather_Condition = le.fit_transform(weather_df.Weather_Condition.astype('|S').values) \nweather_df.Selected = le.fit_transform(weather_df.Selected.astype('|S').values)","43be4aa2":"weather_df.head(3)","566c0f29":"weather_df.info()","e8d75849":"df = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n\ndf.head()","ce5c8f0d":"df.info()","73a74374":"# define a function to prepare date as it apear in other data sets to use it in merging\ndef Prepare_date(dataframe):\n    dataframe['timestamp'] = pd.to_datetime(dataframe['timestamp'])\n    dataframe['date_to_nearest_day'] = pd.to_datetime(dataframe['timestamp'].dt.date)\n    dataframe['hours'] =  dataframe['timestamp'].dt.hour\n    dataframe['time_to_nearest_hour'] = dataframe['timestamp'].dt.floor('h')\n    dataframe['dayofweek'] = dataframe.timestamp.dt.dayofweek\n    return dataframe","c14b0fc9":"df = Prepare_date(df)","139e23ac":"df.info()","d33d152d":"# Merge weather dataframe\ndef merge_weather(dataframe, weather_dataframe):\n    dataframe = dataframe.merge(weather_dataframe, left_on='time_to_nearest_hour', right_on='date', how ='left' )\n    return dataframe","ad812f17":"# Merge holiday dataframe\ndef merge_holidays(dataframe, holidays_dataframe):\n    dataframe = dataframe.merge(holidays_dataframe, left_on='date_to_nearest_day', right_on='date', how ='left' )\n    dataframe['holiday'] = dataframe['holiday'].fillna(0)\n    return dataframe","80ca5f3b":"df = merge_weather(df, weather_df)\ndf = merge_holidays(df, holidays_df)","10b8c2a0":"# check\ndf.head()","434c3e5b":"df.info()","42f9f049":"def drop_na(dataframe, col_lst):\n    dataframe.dropna(subset = col_lst, inplace=True)","86cc8887":"col_lst = ['Wind_Speed(mph)','Humidity(%)']\ndrop_na(df, col_lst)\n\n# df.fillna(df.mean(), inplace=True)","d1e3ae27":"df.info()","6cfc3c9f":"# describe dataset\ndf.drop(columns='ID').describe(include='all',datetime_is_numeric=True)","e7485d5f":"# # encode\n# def encode_columns(dataframe):\n#     dataframe = pd.get_dummies(dataframe, columns = ['Weather_Condition','Crossing','Give_Way','Junction','No_Exit','Railway','Stop','Amenity','Side'])\n#     return dataframe","6a199019":"# encode\n# use this encoder to encode\nle = LabelEncoder()\n\ndef encode_columns(dataframe, le):\n    dataframe.Crossing = le.fit_transform(dataframe.Crossing.values)\n    dataframe.Give_Way = le.fit_transform(dataframe.Give_Way.values)\n    dataframe.Junction = le.fit_transform(dataframe.Junction.values)\n    dataframe.No_Exit = le.fit_transform(dataframe.No_Exit.values)\n    dataframe.Railway = le.fit_transform(dataframe.Railway.values)\n    dataframe.Stop = le.fit_transform(dataframe.Stop.values)\n    dataframe.Amenity = le.fit_transform(dataframe.Amenity.values)\n    dataframe.Side = le.fit_transform(dataframe.Side.values)\n    return dataframe","2c313bd4":"df = encode_columns(df,le)","29736d34":"df.head()","ea4f4faa":"# get the correlation matrix \ndf.corr()","eed0210f":"# droping unneeded columns\n\ndef drop_unneeded_columns(dataframe, c_lst):\n    dataframe = dataframe.drop(columns=c_lst)\n    return dataframe","0aac5891":"column_lst = ['date_to_nearest_day','hours','time_to_nearest_hour', 'Selected',\n              'Bump', 'Roundabout','Wind_Chill(F)','Precipitation(in)','date_x' , 'date_y']\ndf = drop_unneeded_columns(df, column_lst)","598f9b92":"df.corr().Severity.sort_values()","5ab48e83":"plt.subplots(figsize=(15,10))\nplt.plot((df.corr().Severity.drop('Severity').sort_values()), color=\"purple\", lw=1, ls='--', marker='o', markersize=4)\nplt.xticks(rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Correlation With Severity')\nplt.grid();","cab1c55f":"# Modify the accident class value to combine them in one column\ndef modify_columns(df1):\n    df1.Give_Way.replace(to_replace=1, value=2, inplace=True)\n    df1.Junction.replace(to_replace=1, value=4, inplace=True)\n    df1.No_Exit.replace(to_replace=1, value=8, inplace=True)\n    df1.Railway.replace(to_replace=1, value=16, inplace=True)\n    df1.Stop.replace(to_replace=1, value=16, inplace=True)\n    df1.Amenity.replace(to_replace=1, value=32, inplace=True)\n    df1.Side.replace(to_replace=1, value=64, inplace=True)\n    df1.holiday.replace(to_replace=0, value=2, inplace=True)\n    \n    df1['Accident_class'] = (df1['Distance(mi)'] + df1['Crossing']+ df1['Give_Way'] + df1['Junction'] +\n                             df1['No_Exit'] + df1['Railway'] + df1['Stop'] + df1['Amenity'] + df1['Side']).astype(int)","d86ac538":"modify_columns(df)","45fb226f":"df.head()","fc120422":"df1 = df.copy().drop(columns=['Crossing','Give_Way','Junction','No_Exit','Railway','Stop','Amenity','Side'])","dacba27c":"df1.head()","b43fbefa":"s1 = df1[df1['Severity'] == 1]\ns2 = df1[df1['Severity'] == 2]\ns3 = df1[df1['Severity'] == 3]\ns4 = df1[df1['Severity'] == 4]","8203bbae":"def plot_feature_kde(feature):\n    s1[feature].plot.kde()\n    s2[feature].plot.kde()\n    s3[feature].plot.kde()\n    s4[feature].plot.kde()\n    plt.legend(labels=['S1','S2','S3','S4']);\n","bf91ce42":"plot_feature_kde('Lat')","a12ee13b":"plot_feature_kde('Lng')","edd3713d":"plot_feature_kde('Distance(mi)')","7e1c3967":"plot_feature_kde('Temperature(F)')","3abaca05":"plot_feature_kde('Visibility(mi)')","3ebc7faf":"def plot_feature_kde(s, features_lst):\n    plt.subplots(figsize=(20,10))\n    for feature in features_lst:\n        s[feature].plot.kde()\n    plt.legend();","388403eb":"feature_lst = ['Lat','Lng','Distance(mi)','dayofweek','Year','Day','Month','Hour','Weather_Condition','Temperature(F)','Humidity(%)','Wind_Speed(mph)','Visibility(mi)','Accident_class']\nplot_feature_kde(s1, feature_lst)","e24e3023":"plot_feature_kde(s2, feature_lst)","b5f330f5":"plot_feature_kde(s3, feature_lst)","3d69ddd3":"plot_feature_kde(s4, feature_lst)","b8d3e82a":"# Remove the outliers from Temperature\n\nQ1 = df['Temperature(F)'].quantile(0.25)\nQ3 = df['Temperature(F)'].quantile(0.75)\nIQR = Q3 -Q1\nfilter_w = (df['Temperature(F)'] >= Q1 -1.5* IQR) & (df['Temperature(F)'] <= Q3 +1.5 *IQR)\ndf = df.loc[filter_w]","26c01e3c":"# train_df, val_df = train_test_split(df, test_size=0.2, random_state=42) # Try adding `stratify` here\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify = df['Severity']) \n\nX_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']\n","3b52a2b1":"X_train.head()","22688e95":"allFeatures = ['Lat', 'Lng', 'Distance(mi)', 'Year', 'Month', 'Hour', 'Temperature(F)','dayofweek',\n                'Wind_Speed(mph)', 'Weather_Condition', 'Accident_class']\n\nX_train = X_train[allFeatures]\nX_val = X_val[allFeatures]","4c5cc625":"X_train","040879e9":"# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifierAccident_class\nclassifier = classifier.fit(X_train, y_train)","0d77937f":"print(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","82d54bb9":"importance = classifier.feature_importances_","1e719e01":"for i,v in zip(allFeatures,importance):\n    print(f'Feature: {i},           Score: {round(v,5)}')","431edd9f":"plt.subplots(figsize=(20,10))\nplt.bar(allFeatures, importance)\nplt.xticks(rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Importance');\n# plt.savefig('plot3.png', dpi=300 ,bbox_inches='tight');","26266942":"test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\ntest_df.head()","24f58b04":"# prepare test dataset\ntest_df = Prepare_date(test_df)\ntest_df = merge_weather(test_df, weather_df)\ntest_df = merge_holidays(test_df, holidays_df)\ndrop_na(df,col_lst)\ntest_df = encode_columns(test_df, le)\ntest_df = drop_unneeded_columns(test_df, column_lst)\ntest_df['Wind_Speed(mph)'].fillna(df['Wind_Speed(mph)'].mean(), inplace=True)\nmodify_columns(test_df)","38e1be37":"test_df.head()","ca0036ef":"test_df.info()","87c301c3":"X_test = test_df.drop(columns=['ID'])\n\n# You should update\/remove the next line once you change the features used for training\nX_test = X_test[allFeatures]\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted\n\ntest_df.head()","ea9c43ca":"test_df[['ID', 'Severity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","c64f755e":"Now let's test our classifier on the validation dataset and see the accuracy.","25219720":"# Mansoura Group1-05\n\n* **Ahmed Nabil Ibrahim Awaad**\n* **khaled osama mosaad**\n* **Mohammed Ayman Mohammed Samaha**","89d6e1ac":"## Model Training\n\nLet's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. ","32c3a325":"## Data Splitting\n\nNow it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n\n*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* ","0d53fee3":"## Exploratory Data Analysis","5eadb6b8":"# \n","1f58de3a":"### Reading training data CSV file","f4e1dca8":"## Remove the outliers","aac1fbd8":"Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only.","90b6e93d":"## Import the libraries\n\nWe'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections.","15e8348a":"### Reading Holidays XML file","7c244d29":"Well. That's a good start, right? A classifier that predicts all examples' `Severity` as 2 will get around 0.63. You should get better score as you add more features and do better data preprocessing.","37827c9b":"## Plot features vs. Severity","d3aec604":"## Submission File Generation\n\nWe have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n\nFirst, we'll load the data.","939b57ab":"### Reading Weather CSV file"}}