{"cell_type":{"c9b2f364":"code","24c00c65":"code","5808f954":"code","b66bf0d9":"code","83203f53":"code","d96c60d4":"code","68f4ea8c":"code","c4ba608b":"code","9b281b89":"code","0f0d4190":"code","c7fb9c18":"code","7eace649":"code","c503e70e":"code","63c4f02f":"markdown"},"source":{"c9b2f364":"import cv2\nimport os\nimport numpy as np\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras.datasets import mnist\nfrom keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout\nfrom keras.models import Sequential, load_model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.regularizers import l2\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","24c00c65":"def merge_rects(rects, thresh):\n    acceptedRects = list()\n    rectsUsed = [False] * len(rects)\n    \n    # Pick one not processed rectangle from the list\n    for supIdx, supVal in enumerate(rects):\n        if not rectsUsed[supIdx]:\n            currxMin = supVal[0]\n            currxMax = supVal[0] + supVal[2]\n            curryMin = supVal[1]\n            curryMax = supVal[1] + supVal[3]\n            \n            # Calculate the middle point of it and mark it as used\n            current_X_middle = (currxMin + currxMax) \/ 2\n            current_Y_middle = (curryMin + curryMax) \/ 2\n            rectsUsed[supIdx] = True\n            \n            # Pick one not processed rectangle from the list\n            for subIdx, subVal in enumerate(rects[(supIdx + 1):], start=(supIdx + 1)):\n                candxMin = subVal[0]\n                candxMax = subVal[0] + subVal[2]\n                candyMin = subVal[1]\n                candyMax = subVal[1] + subVal[3]\n                \n                # Calculate the middle point of it\n                candidate_X_middle = (candxMin + candxMax) \/ 2\n                candidate_Y_middle = (candyMin + candyMax) \/ 2\n                \n                # Compute the euclidean distance between two computed middle points\n                dist = np.abs(current_X_middle - candidate_X_middle)\n                \n                # If the distance is lower then some threshold, merge the rectangles and mark the rectangle as used\n                if dist <= thresh and np.abs(current_Y_middle - candidate_Y_middle) < 55:\n                    currxMax = max(currxMax, candxMax)\n                    currxMin = min(currxMin, candxMin)\n                    curryMin = min(curryMin, candyMin)\n                    curryMax = max(curryMax, candyMax)\n                    rectsUsed[subIdx] = True\n            \n            if (currxMax - currxMin) * (curryMax - curryMin) > 100:\n                acceptedRects.append([currxMin, curryMin, currxMax - currxMin, curryMax - curryMin])\n    return acceptedRects\n\ndef get_numbers(filename, prox=80, canny_thr=60):\n    image = 255 - cv2.resize(cv2.imread(filename, cv2.IMREAD_GRAYSCALE), dsize=(640, 480))\n    canny_features = cv2.Canny(image, 10, canny_thr)\n    contours, _ = cv2.findContours(canny_features, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    for contour in contours:\n        (x, y, w, h) = cv2.boundingRect(contour)\n\n        mean = np.mean(image[y:y + h, x:x + w])\n        std = np.std(image[y:y + h, x:x + w])\n\n        ret, canny_features[y:y + h, x:x + w] = cv2.threshold(image[y:y + h, x:x + w], mean + std \/ 2, 255, cv2.THRESH_BINARY)\n        \n    contours, _ = cv2.findContours(canny_features, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    boxes = list()\n\n    for contour in contours:\n        boxes.append(cv2.boundingRect(contour))\n    \n    acceptedRects = merge_rects(boxes, prox)\n    \n    result_list = list()\n    for rect in acceptedRects:\n        x, y, w, h = rect[0], rect[1], rect[2], rect[3]\n        dilated_canny = cv2.dilate(canny_features[y:y + h, x:x + w], np.ones((7, 7)))\n        contours, _ = cv2.findContours(dilated_canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        sorted_ctrs = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n        digit_list = list()\n        for contour in sorted_ctrs:\n            (ix, iy, iw, ih) = cv2.boundingRect(contour)\n            result_img = cv2.copyMakeBorder(dilated_canny[iy:iy + ih, ix:ix + iw], 10, 10, 10, 10, cv2.BORDER_CONSTANT)\n            result_img = cv2.erode(result_img, np.ones((4, 4)))\n            result_img = cv2.resize(result_img, dsize=(28, 28), interpolation=cv2.INTER_CUBIC)\n            digit_list.append(result_img)\n        result_list.append(np.array(digit_list))\n    return np.array(result_list)","5808f954":"!wget -O images.zip \"https:\/\/www.dropbox.com\/s\/l45ikrgvzuv5scb\/Camera%20Roll.zip?dl=0\"\n!unzip images.zip\n!mv -v \"Camera Roll\" \"test-images\"","b66bf0d9":"!ls test-images","83203f53":"model = Sequential()\n\nmodel.add(Conv2D(8, kernel_size=5, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(16, kernel_size=5, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, kernel_regularizer=l2(5e-3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, kernel_regularizer=l2(5e-3), activation=\"softmax\"))\n\nmodel.summary()","d96c60d4":"(x_train, y_train), (x_test, y_test) = mnist.load_data()","68f4ea8c":"x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","c4ba608b":"x_train = x_train \/ 255\nx_test = x_test \/ 255","9b281b89":"one_hot_enc = OneHotEncoder(sparse=False)\none_hot_enc.fit(np.concatenate((y_train, y_test)).reshape(-1, 1))\ny_train_transformed = one_hot_enc.transform(y_train.reshape(-1, 1))\ny_test_transformed = one_hot_enc.transform(y_test.reshape(-1, 1))","0f0d4190":"model.compile(optimizer=Adam(lr=5e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","c7fb9c18":"history = model.fit(\n    np.concatenate((x_train, x_test)),\n    np.concatenate((y_train_transformed, y_test_transformed)),\n    batch_size=100,\n    epochs=20)","7eace649":"def recognize_numbers(numbers):\n    for number in numbers:\n        digits = list()\n        for digit in number:\n            inp = digit.reshape(1, 28, 28, 1) \/ 255\n            digit_hat = model.predict(inp)\n            digits.append(one_hot_enc.inverse_transform(digit_hat)[0][0].astype(int))\n        print(\"\".join([str(d) for d in digits]))","c503e70e":"for image in glob.glob(\"test-images\/*.jpg\"):\n    numbers = get_numbers(image, 300, 50)\n    plt.imshow(cv2.imread(image, cv2.IMREAD_GRAYSCALE), cmap=\"gray\")\n    plt.show()\n    recognize_numbers(numbers)","63c4f02f":"# References\n[1] Yang, Xuan, and Jing Pu. \"MDig: Multi-digit Recognition using Convolutional Nerual Network on Mobile.\" Proc. Yang2015 MDigMR. 2015.\n\n# Introduction\nThis notebook is an implementation of \"MDig: Multi-digit Recognition using Convolutional Nerual Network on Mobile\" paper [1]. Some points in the paper are not clear. Thus, I come up with my own solutions."}}