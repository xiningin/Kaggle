{"cell_type":{"79a4a794":"code","faefcec3":"code","eb63906b":"code","34fa06b3":"code","a9489ec3":"code","5fb1336b":"code","a7f60c8c":"code","eb37b6fe":"code","cc171b7b":"code","f8cbf351":"code","e93b8a96":"code","484f61d0":"code","8cdd7740":"code","02172847":"code","81538f22":"code","22c9e930":"code","cf357ee0":"code","fbef84bd":"code","c239cfe5":"code","12cd4982":"code","53078091":"code","7142e94b":"code","ae963e34":"code","4569eb79":"code","9fca37fa":"code","02436f51":"code","2a1627fe":"code","6fbca2e1":"code","a054c7af":"code","60625f57":"code","2c68355c":"code","46b67fc2":"code","3fac6775":"code","2d9591a3":"code","681bc23a":"code","16461735":"code","ac7a17dc":"code","447b1bb7":"code","f968feb2":"code","e415eb9f":"code","dc3d055a":"code","c341c12a":"code","b23f7ce7":"code","9ff02ff5":"code","a459d9cd":"code","c3c09fd2":"code","e1aa9fce":"code","aad24cb7":"code","e6eb0baa":"code","2d8eb53f":"code","ce37bf6d":"code","27ea573b":"code","722c90c4":"code","054b02bc":"code","46a6fe4a":"code","cf896c5b":"code","59cbc301":"code","8b7ba04b":"code","0ee218fa":"code","da02f9a7":"code","1c99357f":"code","7e357c78":"code","9560d825":"code","10773aae":"code","aa5b64ee":"code","94559e23":"code","eb6f600a":"code","e4ecf9cd":"markdown","da1718e6":"markdown","0a1f917d":"markdown","7db9b64b":"markdown"},"source":{"79a4a794":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","faefcec3":"df_train=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_gender_submission=pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","eb63906b":"df_train.head()","34fa06b3":"df_train.info()","a9489ec3":"df_train.shape","5fb1336b":"df_train['Age'].fillna(df_train['Age'].median(),inplace=True)","a7f60c8c":"df_train['Died'] = 1-df_train['Survived']","eb37b6fe":"df_train.groupby('Sex').agg('sum')[['Survived','Died']].plot(kind='bar', figsize=(5, 5),\n                                                          stacked=True, color=['b','r']);","cc171b7b":"df_train.groupby('Sex').agg('mean')[['Survived','Died']].plot(kind='bar', figsize=(5, 5),\n                                                          stacked=True, color=['g','r']);","f8cbf351":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig = plt.figure(figsize=(5, 5))\nsns.violinplot(x='Sex', y='Age', \n               hue='Survived', data=df_train, \n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );","e93b8a96":"figure = plt.figure(figsize=(20, 7))\nplt.hist([df_train[df_train['Survived'] == 1]['Fare'], df_train[df_train['Survived'] == 0]['Fare']], \n         stacked=True, color = ['g','r'],\n         bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend();","484f61d0":"plt.figure(figsize=(20, 7))\nax = plt.subplot()\n\nax.scatter(df_train[df_train['Survived'] == 1]['Age'], df_train[df_train['Survived'] == 1]['Fare'], \n           c='green', s=df_train[df_train['Survived'] == 1]['Fare'])\nax.scatter(df_train[df_train['Survived'] == 0]['Age'], df_train[df_train['Survived'] == 0]['Fare'], \n           c='red', s=df_train[df_train['Survived'] == 0]['Fare']);","8cdd7740":"ax = plt.subplot()\nax.set_ylabel('Average fare')\ndf_train.groupby('Pclass').mean()['Fare'].plot(kind='bar', figsize=(20, 7), ax = ax);","02172847":"def merge_train_test_data():\n    # reading train data\n    train = pd.read_csv('..\/input\/titanic\/train.csv')\n    \n    # reading test data\n    test = pd.read_csv('..\/input\/titanic\/test.csv')\n\n    # extracting and then removing the targets from the training data \n    targets = train.Survived\n    train.drop(['Survived'], 1, inplace=True)\n    \n\n    # merging train data and test data for future feature engineering\n    # we'll also remove the PassengerID since this is not an informative feature\n    merged_data_frame = train.append(test)\n    merged_data_frame.reset_index(inplace=True)\n    merged_data_frame.drop(['index', 'PassengerId'], inplace=True, axis=1)\n    \n    return merged_data_frame","81538f22":"merged_df = merge_train_test_data()","22c9e930":"merged_df.shape","cf357ee0":"merged_df['Name'][1].split(',')[1].strip().split('.')[0].strip()","fbef84bd":"merged_df['Title'] = merged_df['Name'].map(lambda str_name:str_name.split(',')[1].strip().split('.')[0].strip())","c239cfe5":"merged_df['Title'].unique()","12cd4982":"title_dict={'Mr':'Mr',\n           'Mrs':'Mrs',\n           'Ms':'Mrs',\n           'Mme':'Miss',\n           'Miss':'Miss',\n           'Mlle':'Miss',\n           'Master':'Master',\n            'Col':'Defence_Officer',\n            'Major':'Defence_Officer',\n            'Capt':'Defence_Officer',\n            'Dr':'Dr',\n            'Jonkheer':'Jonkheer',\n            'Don':'Don',\n            'Rev':'Rev',\n            'Lady':'Lady',\n            'Sir':'Sir',\n            'the Countess':'the Countess',\n            'Dona':'Dona'\n           }","53078091":"merged_df['Title'] = merged_df['Title'].map(title_dict)","7142e94b":"merged_df['Title'].unique()","ae963e34":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Title'], drop_first=True,prefix='Title')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Title',axis=1,inplace=True)","4569eb79":"merged_df.drop('Name',axis=1,inplace=True)","9fca37fa":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Pclass'].astype('category'), drop_first=True,prefix='Pclass')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Pclass',axis=1,inplace=True)","02436f51":"sex_dict = {'male':1,\n           'female':0}\nmerged_df['Sex'] = merged_df['Sex'].map(sex_dict)","2a1627fe":"merged_df['Cabin'] = merged_df['Cabin'].str[0]","6fbca2e1":"merged_df['Cabin'].unique()","a054c7af":"merged_df['Cabin'].fillna('U',inplace=True)","60625f57":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Cabin'], drop_first=True,prefix='Cabin')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Cabin',axis=1,inplace=True)","2c68355c":"merged_df.groupby('Embarked').count()['Sex']","46b67fc2":"merged_df['Embarked'].isnull().sum()","3fac6775":"#Replacing the value of Embarked with 'S' based on the frequency\nmerged_df['Embarked'].fillna('S',inplace=True)","2d9591a3":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Embarked'], drop_first=True,prefix='Embarked')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Embarked',axis=1,inplace=True)","681bc23a":"merged_df['Age'].isnull().sum()","16461735":"def age_groups(num_age):\n    if num_age>=0 and num_age <=2:\n        return 'infant'\n    elif num_age>=3 and num_age<=15:\n        return 'kids'\n    else:\n        return 'adult'","ac7a17dc":"merged_df['age_group']=merged_df['Age'].map(lambda age:age_groups(age))\n","447b1bb7":"age_group=merged_df.groupby('age_group').median()['Age'].reset_index()\n","f968feb2":"age_group","e415eb9f":"age_group[age_group['age_group']=='adult']['Age'][0]","dc3d055a":"def age(row):\n    if row['age_group']=='adult':\n        return age_group[age_group['age_group']=='adult']['Age'][0]\n    elif row['age_group']=='infant':\n        return age_group[age_group['age_group']=='infant']['Age'][0]\n    else:\n        return age_group[age_group['age_group']=='kids']['Age'][0]","c341c12a":"merged_df['Age']=merged_df.apply(lambda row: age(row) if np.isnan(row['Age']) else row['Age'], axis=1)","b23f7ce7":"merged_df.head()","9ff02ff5":"merged_df.drop('age_group',axis=1,inplace=True)","a459d9cd":"merged_df['traveller_cnt'] = merged_df['SibSp'] + merged_df['Parch']+1","c3c09fd2":"merged_df.drop('Ticket',axis=1,inplace=True)","e1aa9fce":"def get_train_test_target():\n    targets = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Survived'])['Survived'].values\n    train = merged_df.iloc[:891]\n    test = merged_df.iloc[891:]\n    \n    return train, test, targets","aad24cb7":"train, test, targets = get_train_test_target()","e6eb0baa":"train.head(10)","2d8eb53f":"test.isnull().sum()","ce37bf6d":"test['Fare'].fillna(test['Fare'].mean(),inplace=True)","27ea573b":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nrf = rf.fit(train, targets)","722c90c4":"features = pd.DataFrame()\nfeatures['feature'] = train.columns\nfeatures['importance'] = rf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)","054b02bc":"features.plot(kind='barh', figsize=(25, 25))","46a6fe4a":"from sklearn.feature_selection import SelectFromModel\nmodel = SelectFromModel(rf, prefit=True)\ntrain_reduced = model.transform(train)\nprint(train_reduced.shape)","cf896c5b":"test_reduced = model.transform(test)\ntest_reduced.shape","59cbc301":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\n#logreg_cv = LogisticRegressionCV()\nrf = RandomForestClassifier()\n#gboost = GradientBoostingClassifier()\n#models = [logreg, logreg_cv, rf, gboost]\nmodels = [logreg, rf]","8b7ba04b":"from sklearn.model_selection import cross_val_score\ndef compute_score(rf, X, y, scoring='accuracy'):\n    xval = cross_val_score(rf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)","0ee218fa":"for model in models:\n    print('Cross-validation of : {0}'.format(model.__class__))\n    score = compute_score(rf=model, X=train_reduced, y=targets, scoring='accuracy')\n    print('CV score = {0}'.format(score))\n    print('****')","da02f9a7":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n# turn run_gs to True if you want to run the gridsearch again.\nrun_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [4, 6, 8],\n                 'n_estimators': [50, 10],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [2, 3, 10],\n                 'min_samples_leaf': [1, 3, 10],\n                 'bootstrap': [True, False],\n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(n_splits=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation,\n                               verbose=1,\n                               n_jobs=-1\n                              )\n\n    grid_search.fit(train, targets)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\n    \nelse: \n    parameters = {'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 50, \n                  'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    model = RandomForestClassifier(**parameters)\n    model.fit(train, targets)","1c99357f":"test.head()","7e357c78":"predictions = model.predict(test)","9560d825":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(predictions)","10773aae":"y_pred_1.head(10)","aa5b64ee":"# Renaming the column \ny_pred_1= y_pred_1.rename(columns={ 0 : 'Survived'})","94559e23":"df_gender_submission['Survived'] = y_pred_1['Survived'] ","eb6f600a":"df_gender_submission.head()","e4ecf9cd":"# Making Final Submisson File","da1718e6":"We can see that there is NULL values in the age. Lets replace NULL values in the age with median value of this column","0a1f917d":"Visualizations","7db9b64b":"# Data Cleansing"}}