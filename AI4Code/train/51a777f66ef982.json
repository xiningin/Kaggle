{"cell_type":{"e5d8e505":"code","95692d35":"code","cb1f9d89":"code","f28aad52":"code","39dca399":"code","cdfbfa14":"code","b6209162":"code","44913829":"code","512b90ec":"code","9a4dd590":"code","64594126":"code","cb3ff940":"code","2d49775f":"code","90c57d48":"code","3f67f334":"markdown","e7d22895":"markdown"},"source":{"e5d8e505":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95692d35":"#importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report,accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","cb1f9d89":"#import Dataset\ndataset = pd.read_csv('..\/input\/ckdisease\/kidney_disease.csv')","f28aad52":"dataset[['htn','dm','cad','pe','ane']]=dataset[['htn','dm','cad','pe','ane']].replace(to_replace={'yes':1,'no':0})\ndataset[['rbc','pc']] = dataset[['rbc','pc']].replace(to_replace={'abnormal':1,'normal':0})\ndataset[['pcc','ba']] = dataset[['pcc','ba']].replace(to_replace={'present':1,'notpresent':0})\ndataset[['appet']] = dataset[['appet']].replace(to_replace={'good':1,'poor':0,'no':np.nan})\ndataset['classification']=dataset['classification'].replace(to_replace={'ckd':1.0,'ckd\\t':1.0,'notckd':0.0,'no':0.0})\ndataset.rename(columns={'classification':'class'},inplace=True)","39dca399":"# Further cleaning\ndataset['pe'] = dataset['pe'].replace(to_replace='good',value=0) # Not having pedal edema is good\ndataset['appet'] = dataset['appet'].replace(to_replace='no',value=0)\ndataset['cad'] = dataset['cad'].replace(to_replace='\\tno',value=0)\ndataset['dm'] = dataset['dm'].replace(to_replace={'\\tno':0,'\\tyes':1,' yes':1, '':np.nan})\ndataset.drop('id',axis=1,inplace=True)","cdfbfa14":"# '?' character remove process in the dataset\nfor i in ['rc','wc','pcv']:\n    dataset[i] = dataset[i].str.extract('(\\d+)').astype(float)","b6209162":"# Filling missing numeric data in the dataset with mean\nfor i in ['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo','rc','wc','pcv']:\n    dataset[i].fillna(dataset[i].mean(),inplace=True)","44913829":"dataset = dataset.dropna(axis=1)","512b90ec":"#Data preprocessing\nX = dataset.iloc[:,:-1].values\ny = dataset.iloc[:,-1].values","9a4dd590":"# Feature Scaling\nsc = StandardScaler()\nX = sc.fit_transform(X)","64594126":"#Splitting the dataset in to training and testing set\nX_train , X_test , y_train , y_test   = train_test_split(X,y,test_size = 0.2 , random_state=123)  ","cb3ff940":"model_params ={\n    'svm':{\n        'model' :svm.SVC(gamma='auto'),\n        'params':{\n            'C':[1,10,20],\n            'kernel':['rbf','linear']\n        }\n    },\n    'random_forest':{\n        'model':RandomForestClassifier(),\n        'params':{\n            'n_estimators':[1,5,10]\n        }\n    },\n    'logistic_regression':{\n        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n        'params':{\n            'C':[1,5,10]\n        }\n    },\n    'decision_tree':{\n        'model': DecisionTreeClassifier(criterion='entropy'),\n        'params':{\n            'min_samples_split' : [4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]\n        }\n    },\n    'knn':{\n        'model': KNeighborsClassifier( metric='minkowski',p=2 ),\n        'params':{\n            'n_neighbors' :list(range(1,31)),\n            'weights' : [\"uniform\", \"distance\"]\n        }\n    },\n    'Kernal_Navie_bayes':{\n        'model': GaussianNB(),\n        'params':{\n            'var_smoothing': np.logspace(0,-9, num=100)\n        }\n    }\n}","2d49775f":"score = []\n\nfor model_name , mp in model_params.items():\n    clf = GridSearchCV(mp['model'], mp['params'] , cv=5 , return_train_score=False)\n    clf.fit(X_train , y_train)\n    score.append({\n        'model': model_name,\n        'best_score':clf.best_score_,\n        'best_params':clf.best_params_\n    })","90c57d48":"df = pd.DataFrame(score, columns=['model','best_score','best_params'])\ndf","3f67f334":"### Data Cleaning","e7d22895":"# Hyper parameter Tuning "}}