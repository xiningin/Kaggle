{"cell_type":{"9081be60":"code","f338bb48":"code","ebbd4b05":"code","685d1c95":"code","1d3c1193":"code","fdbeb8c4":"code","797b8642":"code","bcb48e96":"code","2cf35575":"code","275aae39":"code","9fc7fec3":"code","41ab6917":"code","c5a625ac":"code","34249eac":"code","8cabc5e4":"code","cc0f21c2":"code","2037bf70":"code","7d553ba0":"code","df030114":"code","5f4e97f8":"code","0e91a804":"code","2400a1a7":"code","fbf26696":"code","248d65b3":"code","3c10810c":"code","f512df34":"code","bd682ec5":"code","5a278cb3":"code","a5e1407f":"code","bab78f1e":"code","96e8e4a6":"code","40be081a":"code","3106beb0":"code","8c64ca3c":"code","2ea3efd4":"code","b056b5cc":"code","133b8c63":"code","21f8eb8c":"code","9f08026f":"code","efc0699b":"code","1d06d3ed":"code","d95898da":"code","704a4b4a":"code","41ba7aa3":"code","9d2242fc":"code","210e6647":"code","db6391b8":"code","fcbe1e9b":"code","2c2ea4da":"code","6dbad4fe":"code","7526789b":"code","867e01a3":"code","1925ec3e":"code","ca40eeab":"code","b33c3738":"code","55962e61":"code","67270d17":"code","cc2ea160":"code","58c6cdcb":"code","520c701f":"code","93951cfc":"markdown","9c9700e0":"markdown","f75179cc":"markdown","8eac8da5":"markdown","41ba1a34":"markdown","66d09e33":"markdown","b604fc2b":"markdown","e2d6c849":"markdown","e3ce5285":"markdown","62edce9e":"markdown","0f036b0d":"markdown","6a985c42":"markdown","61373158":"markdown","1594376a":"markdown","2a600e77":"markdown","61e627bd":"markdown","2de9292f":"markdown","162cae5c":"markdown","fa68e72f":"markdown","de34a0d0":"markdown","b6bdea71":"markdown","6f759bba":"markdown","fc9e6e16":"markdown","a61307fb":"markdown","a0df63b8":"markdown","9ab159dd":"markdown","9502c617":"markdown","0f37eb75":"markdown","3c71ca0d":"markdown","1ace4a8b":"markdown","4043e659":"markdown","c112ee09":"markdown","9c34c352":"markdown","e661c265":"markdown","99ed994d":"markdown","2d2c10d8":"markdown","94e294a1":"markdown"},"source":{"9081be60":"import sklearn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f338bb48":"wine=pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\nwine.head()","ebbd4b05":"wine['quality'].value_counts()","685d1c95":"wine.info()","1d3c1193":"wine.describe()","fdbeb8c4":"wine.hist(bins=50, figsize=(20,15)) \nplt.show()","797b8642":"wine.corr()","bcb48e96":"for i in wine.columns:\n    if i!='quality':\n        sns.boxplot(data=wine,x='quality',y=i)\n        plt.show()","2cf35575":"#Making binary classificaion for the response variable.\n#Dividing wine as good and bad by giving the limit for the quality\nbins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\nwine['quality'] = pd.cut(wine['quality'], bins = bins, labels = group_names)","275aae39":"#Now lets assign a labels to our quality variable\nfrom sklearn.preprocessing import LabelEncoder\nlabel_quality = LabelEncoder()\n","9fc7fec3":"#Bad becomes 0 and good becomes 1 \nwine['quality'] = label_quality.fit_transform(wine['quality'])","41ab6917":"wine['quality'].value_counts()","c5a625ac":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(wine.drop(['quality'],axis=1),wine['quality'],test_size=0.3,random_state=42)","34249eac":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX_train_scaled=scaler.fit_transform(X_train)\nX_test_scaled=scaler.fit_transform(X_test)","8cabc5e4":"def precision_recall_f1_scores(labels,predictions_from_cross_val_predict):\n    from sklearn.metrics import precision_score,recall_score,f1_score\n    precision=precision_score(labels,predictions_from_cross_val_predict)\n    recall=recall_score(labels,predictions_from_cross_val_predict)\n    f1=f1_score(labels,predictions_from_cross_val_predict)\n    print ('Precision Score = ',precision)\n    print ('Recall Score = ',recall)\n    print ('F1 Score = ',f1)","cc0f21c2":"def plot_precision_recall_vs_threshold(precisions,recalls,thresholds,f1=True):\n    f1_scores=(2*precisions*recalls)\/(precisions+recalls)\n    plt.plot(thresholds,precisions[:-1],'b--',label='Precision')\n    plt.plot(thresholds,recalls[:-1],'g--',label='Recall')\n    if f1:\n        plt.plot(thresholds,f1_scores[:-1],'r',label='F1')\n    plt.legend(loc=\"best\", fontsize=16) \n    plt.xlabel(\"Threshold\", fontsize=16)        \n    plt.grid(True)","2037bf70":"def plot_precision_vs_recall(precisions,recalls):\n    plt.plot(recalls,precisions,'b-',linewidth=2)\n    plt.xlabel('Recall',fontsize=16)\n    plt.ylabel('Precision',fontsize=16)\n    plt.axis([0,1,0,1])\n    plt.grid(True)","7d553ba0":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])                                    \n    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    \n    plt.grid(True) ","df030114":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_recall_curve\ndef initial_check(model,X_train,y_train):\n    val_pred=cross_val_predict(model,X_train,y_train,cv=5)\n    val_score=cross_val_predict(model,X_train,y_train,cv=5,method='predict_proba')\n\n    precision, recall,thresh_pr=precision_recall_curve(y_train,val_score[:,1])\n    plot_precision_vs_recall(precision,recall)\n    plt.show()\n    precision_recall_f1_scores(y_train,val_pred)","5f4e97f8":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state=42)","0e91a804":"from sklearn.model_selection import cross_val_score","2400a1a7":"val_score_sgd = cross_val_score(sgd_clf, X_train_scaled,y_train,scoring='accuracy',cv=5)","fbf26696":"val_score_sgd.mean()","248d65b3":"from sklearn.model_selection import cross_val_predict\nval_pred_sgd=cross_val_predict(sgd_clf,X_train_scaled,y_train,cv=5)","3c10810c":"val_score_sgd=cross_val_predict(sgd_clf,X_train_scaled,y_train,cv=5,method='decision_function')\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfpr,tpr,thresh_roc_sgd=roc_curve(y_train,val_score_sgd)\nroc_auc_score(y_train,val_score_sgd)","f512df34":"plot_roc_curve(fpr,tpr,thresh_roc_sgd)","bd682ec5":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train,val_pred_sgd)","5a278cb3":"val_pred_sgd=cross_val_predict(sgd_clf,X_train_scaled,y_train,cv=5)\nval_score_sgd=cross_val_predict(sgd_clf,X_train_scaled,y_train,cv=5,method='decision_function')\n\nprecision_sgd, recall_sgd,thresh_pr_sgd=precision_recall_curve(y_train,val_score_sgd)\nplot_precision_vs_recall(precision_sgd,recall_sgd)\nplt.show()\nprecision_recall_f1_scores(y_train,val_pred_sgd)\n","a5e1407f":"from sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier()","bab78f1e":"initial_check(knn_clf,X_train_scaled,y_train)","96e8e4a6":"from sklearn.ensemble import RandomForestClassifier\nforest_clf=RandomForestClassifier(random_state=42)","40be081a":"initial_check(forest_clf,X_train_scaled,y_train)","3106beb0":"from sklearn.linear_model import LogisticRegression\nlog_clf=LogisticRegression()","8c64ca3c":"initial_check(log_clf,X_train_scaled,y_train)","2ea3efd4":"from sklearn.svm import SVC\nsv_clf=SVC(random_state=42,probability=True)","b056b5cc":"initial_check(sv_clf,X_train_scaled,y_train)","133b8c63":"initial_check(forest_clf,X_train_scaled,y_train)","21f8eb8c":"from sklearn.metrics import confusion_matrix\nval_pred_forest=cross_val_predict(forest_clf,X_train_scaled,y_train,cv=5)\nval_score_forest=cross_val_predict(forest_clf,X_train_scaled,y_train,cv=5,method='predict_proba')\nprecision_forest,recall_forest,threshold_pr_forest=precision_recall_curve(y_train,val_score_forest[:,1])\nconfusion_matrix(y_train,val_pred_forest)","9f08026f":"plt.figure(figsize=(7,5))\nplot_precision_recall_vs_threshold(precision_forest,recall_forest,threshold_pr_forest)","efc0699b":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint","1d06d3ed":"param_distris={\n    'criterion':['gini', 'entropy'],\n    'n_estimators':randint(low=1,high=200),\n    'max_features':randint(low=1,high=10)\n}","d95898da":"random_search_prec=RandomizedSearchCV(forest_clf,param_distributions=param_distris,n_iter=50,cv=5,scoring='precision',return_train_score=True,random_state=42)","704a4b4a":"random_search_prec.fit(X_train_scaled,y_train)","41ba7aa3":"random_search_prec.best_estimator_","9d2242fc":"random_search_prec.cv_results_[\"mean_test_score\"].max()\n","210e6647":"max_prec_forest_clf=random_search_prec.best_estimator_","db6391b8":"initial_check(max_prec_forest_clf,X_train_scaled,y_train)","fcbe1e9b":"val_new_pred_forest=cross_val_predict(max_prec_forest_clf,X_train_scaled,y_train,cv=5)\nconfusion_matrix(y_train,val_new_pred_forest)","2c2ea4da":"random_search_f1=RandomizedSearchCV(forest_clf,param_distributions=param_distris,n_iter=50,cv=5,scoring='f1',return_train_score=True,random_state=42)","6dbad4fe":"random_search_f1.fit(X_train_scaled,y_train)","7526789b":"random_search_f1.cv_results_['mean_test_score'].max()","867e01a3":"max_f1_forest_clf=random_search_f1.best_estimator_","1925ec3e":"initial_check(max_f1_forest_clf,X_train_scaled,y_train)","ca40eeab":"val_max_f1_pred_forest=cross_val_predict(max_f1_forest_clf,X_train_scaled,y_train,cv=5)\nconfusion_matrix(y_train,val_max_f1_pred_forest)","b33c3738":"max_prec_forest_clf.fit(X_train_scaled,y_train)      #model with max precision on validation\npred_max_prec=max_prec_forest_clf.predict(X_test_scaled)","55962e61":"precision_recall_f1_scores(y_test,pred_max_prec)","67270d17":"confusion_matrix(y_test,pred_max_prec)","cc2ea160":"max_f1_forest_clf.fit (X_train_scaled,y_train)       #model with max f1 score on validation\npred_max_f1=max_f1_forest_clf.predict(X_test_scaled)","58c6cdcb":"precision_recall_f1_scores(y_test,pred_max_f1)","520c701f":"confusion_matrix(y_test,pred_max_f1)","93951cfc":"So far this is the best model we've get, both precesion and recall are significantly better","9c9700e0":"## User-defined Function","f75179cc":"## Testing both models on test set","8eac8da5":"## Exploratory Analysis of Data","41ba1a34":"## Initial Look at ML algorithms to get a idea how each algorithm performs on the data","66d09e33":"Accuracy, ROC curve and roc_auc_score all looks pretty good, but they are not correct measured for evaluation, let me explain","b604fc2b":"### Max f1 score model","e2d6c849":"### ii. KNeighborsClassifier","e3ce5285":"It is not better than RandomForestClassifier","62edce9e":"### Max precision model","0f036b0d":"Accuracy does look fine, lets have a look at the ROC Curve and PR Curve for more insights into the errors","6a985c42":"X_train --> train set\n\ny_train --> train labels\n\n\nX_test --> test set\n\ny_test --> test labels","61373158":"### i. SGD Binary Classifier","1594376a":"### RandomizedSearchCV","2a600e77":"#### Model with max f1 score","61e627bd":"Lets try another model","2de9292f":"### iv. Logistic Regressor","162cae5c":"There are a lot of outliers in the data and they are quite scattered, to solve this I will scale the data while preparing it for ML","fa68e72f":"It is not better than RandomForestClassifier","de34a0d0":"Therefore, we have found a model which has a high precision. But the recall is obviously decresed obviously beacuse of precision\/recall trade-off.\n\nWe can also get a model with balanced recall and precision by giving \"f1\" in scoring parameter of RandomizedSearchCV","b6bdea71":"For making the model I am going to assume that the ML model is build for a restaurant who want to serve ONLY THE GOOD QUALITY WINE (quality >= 7) to its customers, so the requirement for my model is that it should not classify any bad wine as as good (on the other hand it is okay if a good wine is classified as bad) i.e. it should have a high precision.","6f759bba":"### v. SVC","fc9e6e16":"### iii. RandomForestClassifier","a61307fb":"The plot gives a clear picture of precesion, recall and f1 score against thresholds, here threshold is 0.5 so we get the above values of precision, recall and f1 score according to it only","a0df63b8":"Although we are aiming for high precesion it doesn't mean we should take a model with 100% precision and totally ignore recall, we must select a model with optimal recall and a good precision.","9ab159dd":"Since the positive class is rare, we will prefer Precision-Recall(PR) Curve to evaluate the model","9502c617":"It is even worse than SGDClassifier, precision is same but recall decreased","0f37eb75":"We know that ROC Curve gives us True Positive Rate vs False positive rate and accuracy simply gives us ratio of correct prediction to total prediction.\n\nNow, since we have a lot more negaitves in our dataset then positives, which obviously increases accuracy becuse if it predecits everything as 0 then also the accuracy will be 86.4% and the model is obviously going to trained better for negatives as compared to positives which will reduce the false positive rate significantly as compared to true positive rate, which inturn gives a large area under the roc curve. This non-uniformity in data have a similar effect on roc auc score as it had on accuracy therefore both of them are not optimal evaluation metrices for the dataset\n\nTherefore, we prefer PR curve here","3c71ca0d":"## Working with RandomForestClassifier Model\n\nI selected this model because it showed the best results among all the algorithms that I tested and now  I'll try to make it even better by tweaking its hyperparameters.","1ace4a8b":"## Preparing data for Machine Learning","4043e659":"We can observe that the model is giving false negatives which can be understood because of the low recall, we need to make recall better to avoid it.","c112ee09":"For the purpose of this notebook, I have trained and tested 2 models:\n\n1. with maximum precision\n\n2. with maximum f1 score\n\nFor the problem statement that I've formed here, we are going to select the first model for deployment but I've trained other model to display the difference between the two models.\n\nThe model can be improved further if we can get more data ","9c34c352":"This curve is horrible, PR curve must be towards the top left for a good model and we can clearly observe that the model doesn't look so good now, because there were a lot of bad(0) wines and less good(1) ones, due to this irregularity in the dataset, the accuracy and roc_auc_score were high.","e661c265":"With the help of this model we are predicting wheather a wine is good or bad, to form the ML model for the task first we need to decide on to a problem statement, these are some questions we need to ask:\n\n1. For whom we are developing our model?\n\n2. What are the requarements of the predictions (high recall is preferable or high precision)","99ed994d":"X_train_scaled --> scaled train set\n\nX_test_scaled --> scaled test set","2d2c10d8":"Lets look at some more plots to understand what kind of errors does our model make","94e294a1":"#### Model with max precision"}}