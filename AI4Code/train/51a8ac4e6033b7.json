{"cell_type":{"68e9708d":"code","35ed5805":"code","1e5be544":"code","632b0a9b":"code","54e2982c":"code","a81bfd26":"code","c05910bc":"code","9d12907b":"code","3d31059f":"code","6bdcd549":"code","fce03f63":"code","0f0d4054":"code","9bec6be4":"code","fc7e8550":"code","a5e0cfe9":"code","2ab74c12":"code","20dc17b2":"code","cd394496":"code","50694e8d":"code","20934d17":"code","b1d6bf5a":"code","649489e0":"markdown","01b8ca7c":"markdown","cc796f70":"markdown","3cc4a800":"markdown","f99d4e7e":"markdown","2151c95c":"markdown"},"source":{"68e9708d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom imblearn.over_sampling import ADASYN\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","35ed5805":"data = pd.read_csv('..\/input\/train.csv')\ndata.fillna(value = 0, inplace=True)\ndata.tail(5)","1e5be544":"## not considering idhogar for the moment\nfeatures = data.drop(columns = ['Id','idhogar','dependency','edjefe','edjefa'], axis = 1)","632b0a9b":"dif_list = []\nall_families = list(set(data.idhogar))\nfor item in all_families:\n    check_target = list(set(data[data.idhogar == item]['Target']))\n    if len(check_target)>1:\n        dif_list.append(item)\nprint(list(dif_list))","54e2982c":"total = len(features)\ntarget_1 = len(features[features['Target']==1])\ntarget_2 = len(features[features['Target']==2])\ntarget_3 = len(features[features['Target']==3])\ntarget_4 = len(features[features['Target']==4])\n\nprint(\"Total: {}\".format(total))\nprint(\"Class 1: {0:.2f}%\".format(100*target_1\/total))\nprint(\"Class 2: {0:.2f}%\".format(100*target_2\/total))\nprint(\"Class 3: {0:.2f}%\".format(100*target_3\/total))\nprint(\"Class 4: {0:.2f}%\".format(100*target_4\/total))","a81bfd26":"ada = ADASYN(random_state = 199)\nX = features.drop(columns = ['Target'], axis = 1)\ny = features['Target']\nX_res, y_res = ada.fit_sample(X, y)","c05910bc":"total = len(y_res)\ntarget_1 = len(y_res[y_res==1])\ntarget_2 = len(y_res[y_res==2])\ntarget_3 = len(y_res[y_res==3])\ntarget_4 = len(y_res[y_res==4])\n\nprint(\"Total: {}\".format(total))\nprint(\"Class 1: {0:.2f}%\".format(100*target_1\/total))\nprint(\"Class 2: {0:.2f}%\".format(100*target_2\/total))\nprint(\"Class 3: {0:.2f}%\".format(100*target_3\/total))\nprint(\"Class 4: {0:.2f}%\".format(100*target_4\/total))","9d12907b":"## balanced\nx_train, x_test, y_train, y_test = train_test_split(X_res, \n                                                    y_res, \n                                                    test_size=0.20, \n                                                    random_state=42)\n## Imbalanced\nx_train_imba, x_test_imba, y_train_imba, y_test_imba = train_test_split(X, \n                                                            y, \n                                                            test_size=0.20, \n                                                            random_state=42)","3d31059f":"num_estimators = 30","6bdcd549":"## Balanced\nmodel_random = RandomForestClassifier(n_estimators = num_estimators, \n                                      random_state=0)\nmodel_random.fit(X_res, y_res)\npreds_random = model_random.predict(x_test)\naccuracy_score(y_test, preds_random)","fce03f63":"## Imbalanced\nmodel_random_imba = RandomForestClassifier(n_estimators = num_estimators, \n                                      random_state=0)\nmodel_random_imba.fit(x_train_imba, y_train_imba)\npreds_random_imba = model_random_imba.predict(x_test_imba)\naccuracy_score(y_test_imba, preds_random_imba)","0f0d4054":"test = pd.read_csv('..\/input\/test.csv')\ntest.fillna(value = 0, inplace=True)\ntest.drop(columns = ['idhogar','dependency','edjefe','edjefa'], axis = 1, inplace = True)\ntest.tail()","9bec6be4":"!ls ..\/input\/","fc7e8550":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nprint(sample_submission.columns)\nsample_submission.tail(5)","a5e0cfe9":"submission = pd.DataFrame(columns = ['Id', 'Target'])\nsubmission","2ab74c12":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, preds_random))","20dc17b2":"for i in range(len(test)):\n    ID = test['Id'].loc[i]\n    in_test = np.array(test.drop(columns = ['Id'], axis = 1).loc[i]).reshape(1, -1)\n    pred = model_random.predict(in_test)\n    submission.loc[i] = ([ID,pred[0]])","cd394496":"submission = submission.reset_index(drop=True)\nsubmission","50694e8d":"submission.to_csv('sample_submission.csv', index=False )","20934d17":"!ls","b1d6bf5a":"!cat sample_submission.csv","649489e0":"## Perform Oversampling for classes","01b8ca7c":"## Check if different household have different classifications","cc796f70":"## Classes\n**1** = extreme poverty  \n**2** = moderate poverty  \n**3** = vulnerable households   \n**4** = non vulnerable households  ","3cc4a800":"## Checking Test predictions","f99d4e7e":"## Check class imbalance","2151c95c":"## Check classes after re-sampling"}}