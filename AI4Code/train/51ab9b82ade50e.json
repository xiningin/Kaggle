{"cell_type":{"f2183bae":"code","13c0985d":"code","47ada3d5":"code","6f8bf5e8":"code","e41f4a4a":"code","bcb7d7d7":"code","b4628c64":"code","98eb3fac":"code","1538df3a":"code","e4539a17":"code","899f722b":"code","1305a0d7":"code","9dba0b2f":"code","76a8fc5f":"code","ff7a2454":"code","951fbf85":"code","c1272b9a":"code","69ee491c":"code","0b94f8a3":"code","e698e251":"code","8c79eb0e":"code","50cf835e":"code","98675a3f":"code","542db085":"markdown"},"source":{"f2183bae":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\nimport random\nimport os","13c0985d":"IMAGE_WIDTH=200\nIMAGE_HEIGHT=200\nIMAGE_CHANNELS=3\nEPOCHS=30\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nPATH='..\/input\/dataset-for-mask-detection\/dataset\/'\nPATH2= '..\/input\/face-mask-detection\/dataset\/'","47ada3d5":"# \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\nwith_mask = os.listdir(PATH+\"with_mask\")\nwithout_mask = os.listdir(PATH+\"without_mask\")\nwith_mask2 = os.listdir(PATH2+\"with_mask\")\nwithout_mask2 = os.listdir(PATH2+\"without_mask\")\n\n\ndef add_path1(filename):\n    return PATH +'with_mask\/' + filename\ndef add_path2(filename):\n    return PATH + 'without_mask\/' + filename\ndef add_path3(filename):\n    return PATH2 +'with_mask\/' + filename\ndef add_path4(filename):\n    return PATH2 + 'without_mask\/' + filename\n\nw_mask = list(map(add_path1, with_mask))\nwo_mask = list(map(add_path2, without_mask))\nw_mask2 = list(map(add_path3, with_mask2))\nwo_mask2 = list(map(add_path4, without_mask2))\n\n","6f8bf5e8":"# \ub370\uc774\ud130 preprocessing & label\n\ndef dataset(file_list_with, file_list_without,file_list_with2, file_list_without2,size=IMAGE_SIZE,flattened=False):\n    data = []\n    labels = []\n    sum_1 = 0\n    sum_2 = 0\n    for i, file in enumerate(file_list_with):\n        if(file == PATH + \"with_mask\/.ipynb_checkpoints\"):\n            continue\n        image = io.imread(file)\n        image = transform.resize(image, size, mode='constant')\n        data.append(image)\n        labels.append(1)\n    for i, file in enumerate(file_list_without):\n        if(file == PATH + \"without_mask\/.ipynb_checkpoints\"):\n            continue\n        image = io.imread(file)\n        image = transform.resize(image, size, mode='constant')\n        data.append(image)\n        labels.append(0)\n    for i, file in enumerate(file_list_with2):\n        if(file == PATH2 + \"with_mask\/.ipynb_checkpoints\"):\n            continue\n        image = io.imread(file)\n        image = transform.resize(image, size, mode='constant')\n        if(image.shape == (200,200,4)):\n            sum_1 += 1\n            continue\n        data.append(image)\n        labels.append(1)\n    for i, file in enumerate(file_list_without2):\n        if(file == PATH2 + \"without_mask\/.ipynb_checkpoints\"):\n            continue\n        image = io.imread(file)\n        image = transform.resize(image, size, mode='constant')\n        if(image.shape == (200,200,4)):\n            sum_2 += 1\n            continue\n        data.append(image)\n        labels.append(0)\n    \n    print(sum_1, sum_2)\n    return np.array(data), np.array(labels)","e41f4a4a":"# skimage \uc758 transform.resize \uac00 auto scale \ub418\uc11c \ub098\uc624\ub294\ub4ef\ud569\ub2c8\ub2e4.\n# 0-1 \uc758 \ubc94\uc704\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\nX, y = dataset(w_mask, wo_mask,w_mask2, wo_mask2)\nprint(X.shape,y.shape)\n","bcb7d7d7":"# \ub370\uc774\ud130 \ud655\uc778\ud558\uae30\nsample_1 = random.choice(X)\n\nf = plt.figure()\nplt.imshow(sample_1)\nplt.show(block=True)\n","b4628c64":"\n# create model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, BatchNormalization, MaxPooling2D, Dropout","98eb3fac":"def create_model():\n    model = Sequential()\n    model.add(Conv2D(64, (3,3), activation='relu', strides=(2,2), input_shape=(IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)))\n    model.add(Conv2D(64, (3,3), activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(128, (3,3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(128, (3,3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(256, (3,3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(256, (3,3), activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n    return model","1538df3a":"model1 = create_model()\nmodel1.summary()","e4539a17":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.10,stratify=y)","899f722b":"print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)","1305a0d7":"partial_x_train, validation_x_train, partial_y_train, validation_y_train = train_test_split(x_train, y_train, test_size=0.20)","9dba0b2f":"print(partial_x_train.shape,validation_x_train.shape,partial_y_train.shape,validation_y_train.shape)","76a8fc5f":"print('The size of the training set: ',len(x_train))\nprint('The size of the partial training set: ',len(partial_x_train))\nprint('The size of the validation training set: ',len(validation_x_train))\nprint('The size of the testing set: ',len(x_test))","ff7a2454":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\ncallbacks = [learning_rate_reduction]","951fbf85":"history = model1.fit(\n    partial_x_train, \n    partial_y_train,\n    validation_data=(validation_x_train, validation_y_train),\n    epochs=EPOCHS, \n    batch_size=32,\n    verbose =1,\n    callbacks=callbacks\n)\n","c1272b9a":"def smooth_curve(points, factor=0.8): #this function will make our plots more smooth\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous*factor+point*(1-factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\n","69ee491c":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n","0b94f8a3":"epochs = range(1, len(acc)+1)\nplt.plot(epochs, smooth_curve(acc), 'bo', label='Training acc')\nplt.plot(epochs, smooth_curve(val_acc), 'r-', label='Validation acc')\nplt.legend()\nplt.title('Training and Validation Acc')\nplt.figure()\n\nplt.plot(epochs, smooth_curve(loss), 'bo', label='Training loss')\nplt.plot(epochs, smooth_curve(val_loss), 'r-', label='Validation loss')\nplt.legend()\nplt.title('Training and Validation loss')\nplt.show()","e698e251":"test_loss, test_acc = model1.evaluate(x_test, y_test, steps=32)\nprint('The final test accuracy: ',test_acc)","8c79eb0e":"predictions = model1.predict(x_test)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability","50cf835e":"def print_mislabeled_images(test_images, test_labels, pred_labels):\n    \"\"\"\n        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n    \"\"\"\n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = random.choice(np.where(BOO == 0)[0])\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n    print(mislabeled_labels)\n    title = \"Some examples of mislabeled images by the classifier:\"\n    f = plt.figure()\n    plt.imshow(mislabeled_images)\n    plt.show(block=True)\n","98675a3f":"print_mislabeled_images(x_test, y_test, pred_labels)","542db085":"# Mask Face Classification"}}