{"cell_type":{"2ca8a6ec":"code","a4d6b547":"code","06dc61fa":"code","7e1bbb6a":"code","c1250cb5":"code","1d5619a0":"code","a798566b":"code","025bd95e":"markdown","d4ff39f5":"markdown","32e30455":"markdown","663a9c10":"markdown","ac40cfdc":"markdown","e40838bd":"markdown"},"source":{"2ca8a6ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a4d6b547":"# import csv files using pandas\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nprint(train_data.head())\nprint(test_data.head())","06dc61fa":"# necessary imports\nimport matplotlib.pyplot as plt\n\n# print out info of the data\nprint(train_data.info())\n\n# transform 'Sex' to 0 or 1 from object (male = 1, female = 0)\ntrain_data['Sex'] = (train_data['Sex'] == 'male').astype('int')\ntest_data['Sex'] = (train_data['Sex'] == 'male').astype('int')\n\n# find number of null values by columns for train\/test data\nprint('\\n----FINDING NULL VALUES BY COLUMNS----')\nprint('\\n----Training Data----\\n', train_data.count(), '\\n', train_data.isna().sum(), '\\n')\nprint('\\n----Testing Data----\\n', test_data.count(), '\\n', test_data.isna().sum(axis=1), '\\n')\n\nprint('\\n----FINDING NULL VALUES BY ROWS----')\nprint('\\n----Training Data----\\n', train_data.count(axis=1), '\\n', train_data.isna().sum(axis=1))\nprint('\\n----Testing Data----\\n', test_data.count(axis=1), test_data.isna().sum(axis=1), '\\n')\n\n# Cabin has many null values so drop\ntrain_data = train_data.drop('Cabin', axis=1)\ntest_data = test_data.drop('Cabin', axis=1)\n\n# check stats of age to either replace null with median or mean\nprint(train_data['Age'].mean(), train_data['Age'].median())\ntrain_data.boxplot(column='Age')\nplt.show()\n\n# replace 'Age' and 'Fare' column with median value\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\ntest_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())","7e1bbb6a":"# necessary imports\nimport seaborn as sns\n\n# create pair plot of remaining features\nsns.pairplot(data=train_data)\nplt.show()\nplt.clf()\n\n# investigate features' correlation to survival\nfeatures = ['Sex', 'Pclass', 'SibSp', 'Parch', 'Fare']\n\nfor feature in features:\n    sns.violinplot(x='Survived', y=feature, data=train_data)\n    plt.show()\n    plt.clf()","c1250cb5":"# create X\/y dataframes\nX_train = train_data[features]\ny_train = train_data['Survived'].values.ravel()","1d5619a0":"# import necessary models\/tools\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\n\n# create models\nlogistic_regression_model = LogisticRegression()\nknn_model = KNeighborsClassifier()\ntree_model = DecisionTreeClassifier()\ngradient_descent_model = SGDClassifier()\n\n# create object that holds the model and parameter grid\nc_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\nknn_grid = {'n_neighbors': np.arange(4, 26)}\ntree_grid = {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(2, 26), 'max_leaf_nodes': np.arange(2, 26), 'min_samples_leaf': np.arange(1, 15), 'random_state': [12, 42, 89]}\ngradient_descent_grid = {'loss': ['hinge', 'log'], 'penalty': ['l1', 'l2'], 'alpha': np.linspace(0.0001, 0.5, 15), 'random_state': [12, 42, 89]}\n\nknn_object = {'model': knn_model, 'param_grid': knn_grid}\ntree_object = {'model': tree_model, 'param_grid': tree_grid}\ngradient_descent_object = {'model': gradient_descent_model, 'param_grid': gradient_descent_grid}\n\nmodel_grid_objects = [knn_object, tree_object, gradient_descent_object]\nbest_models = []\n\n# test logistic regression individually\nbest_logistic_regression_scores = []\nfor c_value in c_values:\n    scores = cross_val_score(logistic_regression_model, X_train, y_train, scoring='accuracy')\n    best_logistic_regression_scores.append({'score': scores.mean(), 'c_value': c_value})\n    \nprint(best_logistic_regression_scores)\n\n# loop through all model\/grid objects and store the best randomized search model\nfor model_object in model_grid_objects:\n    grid_search_object = GridSearchCV(\n            estimator=model_object['model'],\n            param_grid=model_object['param_grid'],\n            scoring='accuracy',\n            n_jobs=-1,\n            cv=5,\n            refit=True,\n            return_train_score=True)\n    grid_search_object.fit(X_train, y_train)\n    best_models.append({'estimator':grid_search_object.best_estimator_, 'score':grid_search_object.best_score_})\n    \n# loop through the best models and see the best score\nfor model in best_models:\n    print('Estimator: ', model['estimator'], ' Score: ', model['score'])","a798566b":"# set submission model to best performed model\nsubmission_model = best_models[1]['estimator']\n\n# create X data from test_data\nX_submission = test_data[features]\n\n# generate predictions and put to output\npredictions = submission_model.predict(X_submission)\n\noutput = pd.DataFrame({'PassengerId':test_data.PassengerId, 'Survived':predictions})\noutput.to_csv('submission.csv', index=False)\nprint('Your submission was successfully saved!')","025bd95e":"# Building Models and Tune Hyperparameters","d4ff39f5":"# Generate Submission Data with Best Model","32e30455":"# Create Training Data from Initial Training Data","663a9c10":"# Exploratory Data Analysis","ac40cfdc":"# Finding Relevant Features","e40838bd":"# Loading Data"}}