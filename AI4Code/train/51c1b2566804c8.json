{"cell_type":{"bec89c08":"code","b778db37":"code","6a5a182c":"code","3223a2af":"code","0ad32b62":"code","f1097a2d":"code","f715a846":"code","d5129f67":"code","4d4041f5":"code","fa51cc8d":"code","3883d6f5":"code","c980cd3b":"code","ea95722f":"code","2223fc9b":"code","49a3d0b2":"code","0d9ba531":"code","6d8aca4b":"code","e84a01ad":"code","9b192c0d":"code","19b5fe0e":"code","05d302ee":"markdown","cc7ad2ee":"markdown","3939a999":"markdown","f28455de":"markdown"},"source":{"bec89c08":"import pandas as pd\n#Load the trainig set\n!wget https:\/\/raw.githubusercontent.com\/MicrosoftDocs\/mslearn-introduction-to-machine-learning\/main\/Data\/ml-basics\/penguins.csv\npenguins = pd.read_csv('penguins.csv')\n\n# Display a rondom sample of 10 observation\nsample = penguins.sample(10)\nsample\n","b778db37":"penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\nprint(penguins.columns[0:5].values, 'Species')\n\nfor index, row in penguins.sample(10).iterrows():\n    print('[', row[0], row[1], row[2], row[3],int(row[4]),']',penguin_classes[int(row[4])])","6a5a182c":"# Count the number of the null values in each column\npenguins.isnull().sum()","3223a2af":"# Show rows containing nulls\npenguins[penguins.isnull().any(axis =1)]","0ad32b62":"# Drop rows containing NaN values\npenguins = penguins.dropna()\n\n# Confirm there are now no nulls\n\npenguins.isnull().sum()","f1097a2d":"# data distribution\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\npenguin_features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\npenguin_label = 'Species'\n\nfor col in penguin_features:\n    penguins.boxplot(column = col, by = penguin_label, figsize = (6,6))\n    plt.title(col)\nplt.show()\n    \n\n","f715a846":"# Separate features and labels\npenguins_X, penguins_y = penguins[penguin_features].values, penguins[penguin_label].values\n\n# Split data into 70%-30% training set and test set\nfrom sklearn.model_selection import train_test_split\n\nx_penguin_train, x_penguin_test, y_penguin_train, y_penguin_test = train_test_split(penguins_X, penguins_y, test_size = 0.30, random_state = 0, stratify = penguins_y)\n\nprint('Training Set: %d \\nTest Set: %d \\n' % (x_penguin_train.shape[0], x_penguin_test.shape[0]))\n","d5129f67":"from sklearn.linear_model import LogisticRegression\n\n# Set regulation rate\nreg = 0.1\n\n# train a logistin regression model on the training set\nmulti_model = LogisticRegression(C = 1\/reg, solver = 'lbfgs', multi_class = 'auto', max_iter = 10000).fit(x_penguin_train, y_penguin_train)\nprint(multi_model)\n","4d4041f5":"# Predictions\npenguin_predictions = multi_model.predict(x_penguin_test)\nprint('Predicted labels: ', penguin_predictions[:15])\nprint('Actual labels    :', y_penguin_test[:15])","fa51cc8d":"# Evaluate the model\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_penguin_test, penguin_predictions))","3883d6f5":"from sklearn.metrics import precision_score, recall_score, accuracy_score\n\nprint(\"Overall Accuracy: \", accuracy_score(y_penguin_test, penguin_predictions))\nprint(\"Overall Precision: \", precision_score(y_penguin_test, penguin_predictions, average = 'macro'))\nprint(\"Overall Recall: \", recall_score(y_penguin_test, penguin_predictions, average = 'macro'))\n\n","c980cd3b":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_penguin_test, penguin_predictions)\nprint(cm)","ea95722f":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(cm,interpolation = \"nearest\", cmap = plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(penguin_classes))\nplt.xticks(tick_marks, penguin_classes, rotation =45)\nplt.yticks(tick_marks, penguin_classes)\nplt.xlabel('Predicted Labels')\nplt.ylabel('Actual Labels')\nplt.title('Confusion Matrix')\nplt.show()","2223fc9b":"#ROC study\n\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# Get class probability scores\n\npenguin_scores = multi_model.predict_proba(x_penguin_test)\n\nprint (penguin_scores)","49a3d0b2":"# Get ROC metrics for each class\nfpr = {}\ntpr = {}\nthreshold = {}\n\nfor i in range(len(penguin_classes)):\n    fpr[i], tpr[i], threshold[i] = roc_curve(y_penguin_test, penguin_scores[:,i], pos_label = i)\n","0d9ba531":"# Plot the ROC curve\nfig = plt.figure(figsize =(6,6))\nplt.plot([0,1],[0,1], 'k--') # Plot the 50% threshold diagonal line\n\nplt.plot(fpr[0],tpr[0], linestyle = '--', color ='orange', label = penguin_classes[0] + 'vs Rest')\nplt.plot(fpr[1], tpr[1], linestyle = '--', color = 'red', label = penguin_classes[1] + 'vs Rest')\nplt.plot(fpr[2], tpr[2], linestyle = '--', color =  'green', label = penguin_classes[2] + 'vs Rest')\nplt.title('Multiclas ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc = 'best')\nplt.show()","6d8aca4b":"#AUC calculation\nauc = roc_auc_score(y_penguin_test, penguin_scores, multi_class = 'ovr')\nprint('Average AUC: ',auc)","e84a01ad":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\n\n# Define preprocessing for numeric column (scale them)\nfeature_columns = [0,1,2,3]\nfeature_tranformer = Pipeline(steps = [\n    ('scaler', StandardScaler())])\n\n# Ceate preprocessing steps\npreprocessor = ColumnTransformer(transformers = [\n    ('peprocessor', feature_tranformer, feature_columns)])\n\n# create a training pipeline\n\npipeline = Pipeline(steps = [\n    ('preprocessor', preprocessor),\n    ('regressor', SVC(probability = True))])\n\n# fit the pipeline to train the new model on the training data set\nmulti_model = pipeline.fit(x_penguin_train, y_penguin_train)\nprint((multi_model))","9b192c0d":"# Get predictions\npenguin_predictions = multi_model.predict(x_penguin_test)\npenguin_prob = multi_model.predict_proba(x_penguin_test)","19b5fe0e":"#Evaluate the model\nprint(\"Overall accurancy: :\",accuracy_score(y_penguin_test, penguin_predictions))\nprint(\"Overall Precision: \", precision_score(y_penguin_test, penguin_predictions, average ='macro'))\nprint(\"Overall Recall: \", recall_score(y_penguin_test, penguin_predictions, average = 'macro'))\nprint(\"Averege AUC: \", roc_auc_score(y_penguin_test, penguin_prob, multi_class = 'ovr'))\n\n#Confusion matrix\nmcm = confusion_matrix(y_penguin_test, penguin_predictions)\nplt.imshow(mcm, interpolation = 'nearest', cmap = plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(penguin_classes))\nplt.xticks(tick_marks, penguin_classes, rotation = 45)\nplt.yticks(tick_marks, penguin_classes)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"Actual Label\")\nplt.title(\"Conusion Matrix\")\nplt.show()\n","05d302ee":"## Explore the data\n\nWe'll use a dataset that contains observations of three different species of penguin.","cc7ad2ee":"## Preprocess data in  a pipeline","3939a999":"## Prepare the data","f28455de":"## Train and evaluate a multiclass classifier"}}