{"cell_type":{"325c8b9e":"code","a381bdb6":"code","98955f10":"code","4bfd6202":"code","34b16f75":"code","c9dd3eb7":"code","0b1b99a4":"code","cb009c1d":"code","e2a79151":"markdown"},"source":{"325c8b9e":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom kaggle.competitions import twosigmanews\nimport datetime\nimport time\n\nenv = twosigmanews.make_env()","a381bdb6":"def prepare_market_data(market_df):\n    market_df['ratio'] = market_df['close'] \/ market_df['open']\n    market_df['average'] = (market_df['close'] + market_df['open'])\/2\n    market_df['pricevolume'] = market_df['volume'] * market_df['close']\n    market_df.drop(['assetName', 'volume'], axis=1, inplace=True)\n\n    return market_df","98955f10":"def prepare_news_data(news_df):\n    news_df['position'] = news_df['firstMentionSentence'] \/ news_df['sentenceCount']\n    news_df['coverage'] = news_df['sentimentWordCount'] \/ news_df['wordCount']\n\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence',\n                'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass',\n                'assetName', 'urgency','wordCount','sentimentWordCount']\n    news_df.drop(droplist, axis=1, inplace=True)\n\n    # create a mapping between 'assetCode' to 'news_index'\n    assets = []\n    indices = []\n    for i, values in news_df['assetCodes'].iteritems():\n        assetCodes = eval(values)\n        assets.extend(assetCodes)\n        indices.extend([i]*len(assetCodes))\n    mapping_df = pd.DataFrame({'news_index': indices, 'assetCode': assets})\n    del assets, indices\n    \n    # join 'news_train_df' and 'mapping_df' (effectivly duplicating news entries)\n    news_df['news_index'] = news_df.index.copy()\n    expanded_news_df = mapping_df.merge(news_df, how='left', on='news_index')\n    del mapping_df, news_df\n    \n    expanded_news_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return expanded_news_df.groupby(['time', 'assetCode']).mean().reset_index()","4bfd6202":"def prepare_data(market_df, news_df, start=None):\n    market_df['time'] = market_df['time'].dt.date\n    news_df['time'] = news_df['time'].dt.date\n    if start is not None:\n        market_df = market_df[market_df['time'] >= start].reset_index(drop=True)\n        news_df = news_df[news_df['time'] >= start].reset_index(drop=True)\n\n    market_df = prepare_market_data(market_df)\n    news_df = prepare_news_data(news_df)\n\n    # join news_df to market_df using ['assetCode', 'time']\n    return market_df.merge(news_df, how='left', on=['assetCode', 'time']).fillna(0)","34b16f75":"(market_df, news_df) = env.get_training_data()\n\n# TODO: remove this\n# market_df = market_df.tail(10_000)\n# news_df = news_df.tail(30_000)\n\nprint('preparing data...')\nstart = datetime.date(2009,1,1)\nmerged_df = prepare_data(market_df, news_df, start)\nprint('Ready!')","c9dd3eb7":"train_columns = [x for x in merged_df.columns if x not in ['assetCode', 'time', 'returnsOpenNextMktres10', 'universe']]\nX_train = merged_df[train_columns].values\ny_train = (merged_df.returnsOpenNextMktres10 >= 0).astype(int).values\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=99)","0b1b99a4":"from xgboost import XGBClassifier\nimport time\n\nprint('Training XGBoost')\nt = time.time()\n\nxgb_market = XGBClassifier(n_jobs=4, n_estimators=200, max_depth=8, eta=0.05)\nxgb_market.fit(X_train, y_train)\nprint(f'Done, time = {time.time() - t}s')","cb009c1d":"print(\"generating predictions...\")\ndays = env.get_prediction_days()\n\nfor market_df, news_df, pred_template_df in days:\n    test_df = prepare_data(market_df, news_df, start)\n    X_test = test_df[train_columns].values\n    preds = xgb_market.predict_proba(X_test)[:,1] * 2 - 1\n    preds_df = pd.DataFrame({'assetCode':test_df['assetCode'],'confidenceValue':preds})\n    env.predict(preds_df)\nenv.write_submission_file()","e2a79151":"## Predict"}}