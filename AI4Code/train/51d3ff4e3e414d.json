{"cell_type":{"4be472c1":"code","b4c00d1a":"code","1d15016e":"code","86707bde":"code","d41b9249":"code","faa40427":"code","2351f6a8":"code","176281a1":"code","cba29a53":"code","f0383bde":"code","67347fe5":"code","c970ce3a":"code","95cb2bdb":"code","3d60b832":"code","33351584":"code","7518c529":"code","64f54e76":"code","cb924b1e":"code","5b234a7a":"code","2b3717e7":"code","398e6613":"code","2fa1a249":"code","088195f1":"code","46d10b3d":"code","422894c6":"code","e49137c8":"code","bef82103":"code","25eed1c1":"code","eb458b1f":"code","35b5c857":"code","aba11270":"code","501e8f9e":"code","b0e04fad":"code","958152a8":"code","b9c4c374":"code","fa5570b9":"code","ff416384":"code","98988f54":"code","b330248e":"code","b008713b":"code","bc89f594":"code","945c6b55":"code","547b9f0a":"code","a6b515cf":"code","d79d805d":"code","9de3a372":"code","44bb16fe":"code","8ca53445":"code","6cc2aa1c":"code","e0f1d3e8":"markdown","d4b7c8ce":"markdown","4793f483":"markdown","cfdd0257":"markdown","d428e6d9":"markdown","2ac5f1c3":"markdown","0fbb1632":"markdown","8a5ee70a":"markdown","cd1e53bf":"markdown","6c97b636":"markdown","f79c7e85":"markdown","101fce72":"markdown","4f3d2781":"markdown","d3cbd300":"markdown","36798ec0":"markdown","afb1dab0":"markdown","757bd1e2":"markdown","b3705104":"markdown","a44a1ba9":"markdown","0d3b9310":"markdown","cd0b3cf0":"markdown","33ca3da6":"markdown","c4ab8350":"markdown","0cd17f92":"markdown"},"source":{"4be472c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b4c00d1a":"%cd \/kaggle\/input\/fashionmnist","1d15016e":"from matplotlib import pyplot as plt # for plotting graph and images                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \nfrom math import floor # math function 1.3 +=> 1.0\nimport seaborn as sns  # for plotting graph and images  \nimport random # generate random number or choice\nfrom scipy import ndarray # getting ndarray\nimport skimage as sk # for image processing\nfrom skimage import transform # for image processing\nfrom skimage import util # for image processing\nimport warnings # removing warnings\nwarnings.filterwarnings('ignore')\nfrom keras.preprocessing.image import ImageDataGenerator # for model\nfrom tqdm import tqdm # for model\nimport keras# for model\nfrom keras.regularizers import l2 # for model\nfrom keras.layers import Input,Conv2D,Dense, Dropout,UpSampling2D , BatchNormalization, GlobalAveragePooling2D, MaxPooling2D, Activation, Flatten, AvgPool2D, MaxPool2D # for model\nfrom keras.layers import  BatchNormalization as btn # for model\nfrom keras.models import Model, Sequential # for model\nfrom keras.applications.resnet50 import ResNet50 # for model\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score # for model\nfrom keras.callbacks import LearningRateScheduler# for model\nfrom IPython.display import HTML #downloading CSV FILE\nimport base64 \nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.ndimage.interpolation import shift\nfrom keras.optimizers import Adam\n%matplotlib inline","86707bde":"train_csv = pd.read_csv(r\"fashion-mnist_train.csv\",delimiter = \",\")  # TRAIN\ntest_csv  = pd.read_csv(r\"fashion-mnist_test.csv\",delimiter = \",\") #TEST\ntrain_csv.head() ","d41b9249":"test_csv.head()","faa40427":"train_csv.shape,test_csv.shape # SHAPE OF DATA","2351f6a8":"sns.set(color_codes=True)\nsns.distplot(train_csv.iloc[:,0],label = 'LABELS',kde=False\n             ,color='red',norm_hist=False,rug=False); # PLOTTING DISTRIBUTION OF TRAIN","176281a1":"sns.set(color_codes=True)\nsns.distplot(test_csv.iloc[:,0],label = 'LABELS',kde=False\n             ,color='red',norm_hist=False,rug=False); # PLOTTING DISTRIBUTION OF TRAIN","cba29a53":"size_of_img = (28, 28)\nfig=plt.figure(figsize=(72,72))\nfor i in range(60):\n    ax=fig.add_subplot(12,12,i+1)\n    plot_image = np.array(train_csv.iloc[i,1:]).reshape(size_of_img)\n    ax.imshow(plot_image,cmap='inferno')\nplt.show()","f0383bde":"def dataset_distribution(train,distribution = [60,20,20]):\n    # dividing dataset in TRAIN, DEV, TEST\n    # distribution is an array which tell divide percentage\n    train = np.array(train)\n    np.random.shuffle(train)\n    perc_train = floor(distribution[0] * 0.01*train.shape[0])\n    perc_dev = perc_train + floor(distribution[1] * 0.01*train.shape[0])\n    perc_test = perc_dev + floor(distribution[2] * 0.01*train.shape[0])\n    train_feature = train[0:perc_train,1:]\n    train_label =  train[0:perc_train,0]\n    \n    dev_feature = train[perc_train:perc_dev,1:]\n    dev_label =  train[perc_train:perc_dev,0]\n    \n    test_feature = train[perc_dev:perc_test,1:]\n    test_label =  train[perc_dev:perc_test,0]\n    \n    return train_feature\/255, train_label, dev_feature\/255, dev_label, test_feature\/255, test_label","67347fe5":"def one_hot_encoding(label):\n    ## Encoding target \n    ## 1 will turn into [0,1,0,0,0,0,0]\n    no_of_class = np.unique(label).shape[0]\n    enc_labels = np.zeros((label.shape[0],no_of_class))\n    for index in range(label.shape[0]):\n        enc_labels[index,label[index]] = 1\n    return enc_labels","c970ce3a":"def de_encoding(prediction):\n    ## Decoding The Target\n    ## [0,1,0,0,0,0,0,0,0] will be 1\n    predict = np.zeros((prediction.shape[0]))\n    for index in range(prediction.shape[0]):\n        predict[index] = np.argmax(prediction[index])\n    return predict","95cb2bdb":"def change_to_image(in_feature):\n    ### changing data from row vector to matrix representing data\n    ### Reshaping it in (,28,28,1) from (,784)\n    feature = np.zeros(shape = (in_feature.shape[0],size_of_img[0],size_of_img[1], 1))\n    for image_index in range(in_feature.shape[0]):\n        feature[image_index] = (in_feature[image_index]).reshape(size_of_img[0],size_of_img[1], 1)\n    return feature","3d60b832":"def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    ## Getting download link'\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","33351584":"def acc(y_test,prediction):\n    # Printing Accuracy\n    cm = confusion_matrix(y_test, prediction)\n    recall = np.diag(cm) \/ np.sum(cm, axis = 1)\n    precision = np.diag(cm) \/ np.sum(cm, axis = 0)\n    \n    print ('Recall:', recall)\n    print ('Precision:', precision)\n    print ('\\n clasification report:\\n', classification_report(y_test,prediction))\n    print ('\\n confussion matrix:\\n',confusion_matrix(y_test, prediction))\n    ax = sns.heatmap(confusion_matrix(y_test, prediction),linewidths= 0.5,cmap=\"YlGnBu\")","7518c529":"train_feature, train_labels, dev_feature, dev_labels,_,__ = dataset_distribution(train_csv,[80,20,0])\ntrain_feature.shape, train_labels.shape, dev_feature.shape, dev_labels.shape","64f54e76":"train_image = change_to_image(train_feature)\ndev_image     = change_to_image(dev_feature)","cb924b1e":"train_label = one_hot_encoding(train_labels)\ndev_label = one_hot_encoding(dev_labels)","5b234a7a":"no_of_class  = 10\nno_of_class,train_image.shape,dev_image.shape","2b3717e7":"perc = 85\n#no_of_image_in_train = floor(train_csv.shape[0]*perc*0.01)\nno_of_class = 10\nprint(\"no_of_class : \",no_of_class)\nprint(\"train_image.shape : \",train_image.shape)\nprint(\"dev_image.shape : \",dev_image.shape)\nprint(\"train_label.shape : \",train_label.shape)\nprint(\"dev_label.shape: \",dev_label.shape)\nprint(\"train_feature: \",train_feature.shape)\nprint(\"train_labels.shape : \",train_labels.shape)","398e6613":"datagen = ImageDataGenerator(\n        rotation_range=4,  \n        zoom_range = 0.090,  \n        width_shift_range=0.02, \n        height_shift_range=0.02)","2fa1a249":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, strides=1, padding='same', activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (3,3)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size = 3, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size = 3, strides=1, padding='same', activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (3,3)))\n\n\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\nmodel.add(Dense(10, activation='softmax'))\n\n\n# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","088195f1":"model.summary()","46d10b3d":"# print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n#        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))\n# DECREASE LEARNING RATE EACH EPOCH\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n# TRAIN NETWORKS\nhistory = None\nepochs = 32\n\nX_train2, X_val2, Y_train2, Y_val2 = train_image,dev_image, train_label, dev_label\nhistory = model.fit_generator(datagen.flow(X_train2,Y_train2, batch_size= 1250),\n    epochs = epochs, steps_per_epoch = X_train2.shape[0]\/\/1250,  \n    validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=1)\n","422894c6":"name_title = ['Loss','Accuracy']\n# for net in range(nets):\nfig=plt.figure(figsize=(64,64))\nfor i in range(0,2):\n    ax=fig.add_subplot(8,8,i+1)\n    plt.plot(history.history[list(history.history.keys())[i]], label = list(history.history.keys())[i] )\n    plt.plot(history.history[list(history.history.keys())[i+2]],label = list(history.history.keys())[i+2] )\n    plt.xlabel('Epochs', fontsize=18)\n    plt.ylabel(name_title[i], fontsize=18)\n    plt.legend()\n    plt.show()","e49137c8":"X_test = change_to_image(np.array(test_csv.iloc[:,1:]))\/255\nresults = np.zeros( (X_test.shape[0],10) ) \nresults = model.predict_proba(X_test)\nresults_ = np.argmax(results,axis = 1)\nresults = pd.Series(results_,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,10000),name = \"ImageId\"),results,test_csv.iloc[:,0]],axis = 1)\ncreate_download_link(submission)","bef82103":"acc(test_csv.iloc[:,0], results_)","25eed1c1":"sum(results == test_csv.iloc[:,0]) \/ 100 ### ACCURACY ON TEST SET","eb458b1f":"nets = 16\nmodels = [0] *nets\nfor j in range(nets):\n    models[j] = Sequential()\n\n    models[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n    models[j].add(BatchNormalization())\n    models[j].add(Conv2D(32, kernel_size = 3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    models[j].add(BatchNormalization())\n    models[j].add(Conv2D(32, kernel_size = 3, strides=1, padding='same', activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    models[j].add(BatchNormalization())\n    models[j].add(MaxPool2D(pool_size = (3,3)))\n    models[j].add(Dropout(0.3))\n\n    models[j].add(Conv2D(64, kernel_size = 3, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    models[j].add(BatchNormalization())\n    models[j].add(Conv2D(128, kernel_size = 3, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    models[j].add(BatchNormalization())\n    models[j].add(Conv2D(256, kernel_size = 3, strides=1, padding='same', activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    models[j].add(BatchNormalization())\n    models[j].add(MaxPool2D(pool_size = (3,3)))\n\n\n\n    models[j].add(Flatten())\n    models[j].add(Dropout(0.3))\n    models[j].add(Dense(128, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    models[j].add(Dense(10, activation='softmax'))\n\n\n    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n    models[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","35b5c857":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n# TRAIN NETWORKS\nhistory = [0] * nets\nepochs = 32\nfor j in range(nets):\n    X_train2, X_val2, Y_train2, Y_val2 = train_image,dev_image, train_label, dev_label\n    history[j] = models[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n        epochs = epochs, steps_per_epoch = X_train2.shape[0]\/\/64,  \n        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))","aba11270":"\nresults = np.zeros( (10000,10) ) \nfor j in tqdm(range(nets)):\n    results = results + models[j].predict(X_test)\nresults = np.argmax(results,axis = 1)\nacc(test_csv.iloc[:,0],results)","501e8f9e":"results = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,10000),name = \"ImageId\"),results],axis = 1)\ncreate_download_link(submission)","b0e04fad":"sum(results == test_csv.iloc[:,0]) \/ 100 ### ACCURACY ON TEST SET","958152a8":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1, metric='euclidean',n_jobs=8)\nknn.fit(train_feature, train_labels)","b9c4c374":"y_pred = knn.predict(dev_feature)\nacc(dev_labels,y_pred)","fa5570b9":"from sklearn.decomposition import PCA\npca = PCA(n_components=250)\ntrain_pca = pca.fit_transform(train_feature)\ntest_pca  = pca.transform(dev_feature)","ff416384":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1, metric='euclidean',n_jobs=8)\nknn.fit(train_pca, train_labels)","98988f54":"y_pred = knn.predict(test_pca)\nacc(dev_labels,y_pred)","b330248e":"batch_size = 128\nepochs = 36\ninChannel = 1\nx, y = 28, 28\ninput_img = Input(shape = (x, y, inChannel))","b008713b":"def Autoencoder(input_img):\n    #input = 28 x 28 x 1 (wide and thin)\n    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n    conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n    conv4 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n    \n    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n    return decoded","bc89f594":"autoencoder = Model(input_img, Autoencoder(input_img))\nautoencoder.compile(loss='mean_squared_error', optimizer = 'Adam')","945c6b55":"autoencoder.summary()","547b9f0a":"autoencoder_train = autoencoder.fit(train_image,train_image , batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(dev_image,dev_image))","a6b515cf":"name_title = ['Loss']\nfig=plt.figure(figsize=(8,8))\nplt.plot(range(56),autoencoder_train.history['val_loss'])\nplt.plot(range(56),autoencoder_train.history['loss'])\nplt.xlabel('Epochs', fontsize=18)\nplt.ylabel(name_title[0], fontsize=18)\nplt.legend()\nplt.show()","d79d805d":"size_of_img = (28,28)\nfig=plt.figure(figsize=(72,72))\nfor i in range(60):\n    ax=fig.add_subplot(12,12,i+1)\n    plot_image = np.array(test_csv.iloc[i,1:]).reshape(size_of_img)\n    ax.imshow(plot_image,cmap='inferno')\nplt.show()","9de3a372":"size_of_img = (28,28)\nfig=plt.figure(figsize=(72,72))\nfor i in range(60):\n    ax=fig.add_subplot(12,12,i+1)\n    plot_image = autoencoder.predict(np.array(train_image[i]).reshape(1,28,28,1))[0].reshape(28,28) \n    ax.imshow(plot_image)\n    plt.title(\"Label: \" + str(test_csv.iloc[i,0]))\nplt.show()","44bb16fe":"from imgaug import augmenters\nnoise = augmenters.SaltAndPepper(0.12)\nseq_object = augmenters.Sequential([noise])\n\ntrain_x_n = seq_object.augment_images(train_image * 255) \/ 255\ndev_x_n = seq_object.augment_images(dev_image * 255) \/ 255","8ca53445":"size_of_img = (28,28)\nfig=plt.figure(figsize=(72,72))\nfor i in range(60):\n    ax=fig.add_subplot(12,12,i+1)\n    plot_image = train_x_n[i].reshape(size_of_img)\n    ax.imshow(plot_image,cmap='inferno')\nplt.show()","6cc2aa1c":"size_of_img = (28,28)\nfig=plt.figure(figsize=(72,72))\nfor i in range(60):\n    ax=fig.add_subplot(12,12,i+1)\n    plot_image = autoencoder.predict(train_x_n[i].reshape(1,28,28,1)).reshape(size_of_img)\n    ax.imshow(plot_image,cmap='inferno')\nplt.show()","e0f1d3e8":"## Checking Accuracy Of Model","d4b7c8ce":"# Train and Test Data","4793f483":"\nNote: The number of filters, the filter size, the number of layers, number of epochs you train your model, are all hyperparameters and should be decided based on your own intuition, you are free to try new experiments by tweaking with these hyperparameters and measure the performance of your model. And that is how you will slowly learn the art of deep learning!","cfdd0257":"# Data Distribution","d428e6d9":"# Data Augmentation\nData augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks","2ac5f1c3":"## KNN\nK Nearest Neighbor(KNN) is a very simple, easy to understand, versatile and one of the topmost machine learning algorithms. KNN used in the variety of applications such as finance, healthcare, political science, handwriting detection, image recognition and video recognition. In Credit ratings, financial institutes will predict the credit rating of customers. In loan disbursement, banking institutes will predict whether the loan is safe or risky. In political science, classifying potential voters in two classes will vote or won\u2019t vote. KNN algorithm used for both classification and regression problems. KNN algorithm based on feature similarity approach.\n\n![](https:\/\/i1.wp.com\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/03\/knn3.png?resize=372%2C336&ssl=1)","0fbb1632":"# Insight of Dataset\n","8a5ee70a":"# Importing All the necessary Libraries.\n","cd1e53bf":"# Model 2","6c97b636":"# Introduction to AutoEncoders\n## AutoEncoders\n\nan autoencoder is an unsupervised machine learning algorithm that takes an image as input and tries to reconstruct it using fewer number of bits from the bottleneck also known as latent space. The image is majorly compressed at the bottleneck. The compression in autoencoders is achieved by training the network for a period of time and as it learns it tries to best represent the input image at the bottleneck. The general image compression algorithms like JPEG and JPEG lossless compression techniques compress the images without the need for any kind of training and do fairly well in compressing the images.\n\n![](http:\/\/res.cloudinary.com\/dyd911kmh\/image\/upload\/f_auto,q_auto:best\/v1522830223\/Autoencoder_structure_af1jh8.png)\n\nAutoencoder can be broken in to three parts\n\n* Encoder\nThis part of the network compresses or downsamples the input into a fewer number of bits. The space represented by these fewer number of bits is often called the latent-space or bottleneck. The bottleneck is also called the \"maximum point of compression\" since at this point the input is compressed the maximum. These compressed bits that represent the original input are together called an \u201cencoding\u201d of the input.\n\n* Decoder\nThis part of the network tries to reconstruct the input using only the encoding of the input. When the decoder is able to reconstruct the input exactly as it was fed to the encoder, you can say that the encoder is able to produce the best encodings for the input with which the decoder is able to reconstruct well!\nThere are variety of autoencoders, such as the convolutional autoencoder, denoising autoencoder, variational autoencoder and sparse autoencoder. However, as you read in the introduction, you'll only focus on the convolutional and denoising ones in this tutorial.","f79c7e85":"\n## CNN\n\n\n\nA Convolutional Neural Network (ConvNet\/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects\/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters\/characteristics.\nThe architecture of a ConvNet is analogous to that of the connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area.\n![](data:image\/jpeg;base64,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)","101fce72":"## Use:\n### Denoising Image","4f3d2781":"***Almost no overfitting due to:-**\n* **droupout layers**\n\nDropout Regularization For Neural Networks\nDropout is a regularization technique for neural network models proposed by Srivastava, et al. in their 2014 paper Dropout: A Simple Way to Prevent Neural Networks from Overfitting (download the PDF).\n\nDropout is a technique where randomly selected neurons are ignored during training. They are \u201cdropped-out\u201d randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.\n* **weight regularization**\n\n\nKeras provides a weight regularization API that allows you to add a penalty for weight size to the loss function.\n\nThree different regularizer instances are provided; they are:\n\nL1: Sum of the absolute weights.\nL2: Sum of the squared weights.\nL1L2: Sum of the absolute and the squared weights.\nThe regularizers are provided under keras.regularizers and have the names l1, l2 and l1_l2. Each takes the regularizer hyperparameter as an argument.","d3cbd300":"## PCA\n\nPrincipal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called principal components.","36798ec0":"#  Data Preprocessing","afb1dab0":"### Encoder\n\n* The first layer will have 32 filters of size 3 x 3, followed by a downsampling (max-pooling) layer,\n* The second layer will have 64 filters of size 3 x 3, followed by another downsampling layer,\n* The final layer of encoder will have 128 filters of size 3 x 3.","757bd1e2":"# Model 1","b3705104":"# Model 4","a44a1ba9":"# Welcome\n\n![](data:image\/jpeg;base64,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)\n\n\nThis Notebook will guide you on various ways to solve Fashion MNIST Dataset\n1. CNN\n2. Stacked Model\n3. KNN\n4. KNN with PCA\nI have taken some content from site: like [data camp](datacamp.com) , [towards data science](towardsdatascience.com)","0d3b9310":"## Output","cd0b3cf0":"### Decoder\n* The first layer will have 128 filters of size 3 x 3 followed by a upsampling layer,\/li>\n* The second layer will have 64 filters of size 3 x 3 followed by another upsampling layer,\n* The final layer of encoder will have 1 filter of size 3 x 3.\n* The max-pooling layer will downsample the input by two times each time you use it, while the upsampling layer will upsample the input by two times each time it is used.\n","33ca3da6":"\n## stacked Models\nStacking is a way to ensemble multiple classifications or regression model. There are many ways to ensemble models, the widely known models are Bagging or Boosting. Bagging allows multiple similar models with high variance are averaged to decrease variance. Boosting builds multiple incremental models to decrease the bias, while keeping variance small.\n\nStacking (sometimes called Stacked Generalization) is a different paradigm. The point of stacking is to explore a space of different models for the same problem. The idea is that you can attack a learning problem with different types of models which are capable to learn some part of the problem, but not the whole space of the problem. So, you can build multiple different learners and you use them to build an intermediate prediction, one prediction for each learned model. Then you add a new model which learns from the intermediate predictions the same target.\nThis final model is said to be stacked on the top of the others, hence the name. Thus, you might improve your overall performance, and often you end up with a model which is better than any individual intermediate model. Notice however, that it does not give you any guarantee, as is often the case with any machine learning technique.\n![](https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190515104518\/stacking.png)","c4ab8350":"#  All The Functions","0cd17f92":"# Model 3"}}