{"cell_type":{"c9332572":"code","97c90d16":"code","b601006f":"code","9ce2badd":"code","6bfd2f45":"code","2348b580":"code","54f13d54":"code","26a34a39":"code","a543a491":"code","70f906a9":"code","8ada1c91":"code","66cb884c":"code","d4c5aee3":"code","e010729f":"code","38ec46a1":"markdown","e3395a6b":"markdown","c68a3d21":"markdown","f07c39a3":"markdown","03938373":"markdown","c56df313":"markdown","725ab883":"markdown","e7e1ee7b":"markdown"},"source":{"c9332572":"%%bash\npip install --no-index --find-links ..\/input\/torchsummary torchsummary","97c90d16":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nfrom torchsummary import summary\nimport os, time\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat","b601006f":"DATASET_DIR = '..\/input\/bci-iv-2a\/' #@param {type:\"string\"}\nBASE_DIR = '.\/' #@param {type:\"string\"}","9ce2badd":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(device)","6bfd2f45":"class EEGNet(nn.Module):\n    def __init__(self):\n        super(EEGNet, self).__init__()\n\n        self.F1 = 8\n        self.F2 = 16\n        self.D = 2\n        \n        # Conv2d(in,out,kernel,stride,padding,bias)\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, self.F1, (1, 64), padding=(0, 32), bias=False),\n            nn.BatchNorm2d(self.F1)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(self.F1, self.D*self.F1, (22, 1), groups=self.F1, bias=False),\n            nn.BatchNorm2d(self.D*self.F1),\n            nn.ELU(),\n            nn.AvgPool2d((1, 4)),\n            nn.Dropout(0.5)\n        )\n        \n        self.Conv3 = nn.Sequential(\n            nn.Conv2d(self.D*self.F1, self.D*self.F1, (1, 16), padding=(0, 8), groups=self.D*self.F1, bias=False),\n            nn.Conv2d(self.D*self.F1, self.F2, (1, 1), bias=False),\n            nn.BatchNorm2d(self.F2),\n            nn.ELU(),\n            nn.AvgPool2d((1, 8)),\n            nn.Dropout(0.5)\n        )\n        \n        self.classifier = nn.Linear(16*17, 4, bias=True)\n        \n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.Conv3(x)\n        \n        x = x.view(-1, 16*17)\n        x = self.classifier(x)\n        return x\n    ","2348b580":"class ShallowConvNet(nn.Module):\n    def __init__(self):\n        super(ShallowConvNet, self).__init__()\n\n        self.conv1 = nn.Conv2d(1, 40, (1, 13), bias=False)\n        self.conv2 = nn.Conv2d(40, 40, (22, 1), bias=False)\n        self.Bn1   = nn.BatchNorm2d(40)\n        self.AvgPool1 = nn.AvgPool2d((1, 35), stride=(1, 7))\n        self.Drop1 = nn.Dropout(0.25)\n        self.classifier = nn.Linear(40*74, 4, bias=True)\n        \n    def forward(Self, x):\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.Bn1(x)\n        x = x ** 2\n        x = self.AvgPool1(x)\n        x = torch.log(x)\n        x = self.Drop1(x)\n        x = x.view(-1, 40*74)\n        x = self.classifier(x)\n        \n        return x\n    ","54f13d54":"class Model(object):\n    def __init__(self, model=None, lr=0.001):\n        super(Model, self).__init__()\n        self.model = model\n        self.losses = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n        \n    def fit(self, trainloader=None, validloader=None, epochs=1, monitor=None, only_print_finish_ep_num=False):\n        doValid = False if validloader == None else True\n        pre_ck_point = [float(\"inf\"), 0.0, float(\"inf\"), 0.0, 0] # loss, acc, val_loss, val_acc, epoch\n        history = {\"loss\": [], \"acc\": [], \"val_loss\": [], \"val_acc\": []}\n        for ep in range(1, epochs + 1):\n            proc_start = time.time() # timer start\n            if (not (ep % 10)) or (ep == 1):\n                if not only_print_finish_ep_num:\n                    print(f\"Epoch {ep}\/{epochs}\")\n            self.model.train()       # Train mode\n            step = 1                 # Restart step\n            for x_batch, y_batch in trainloader:\n                x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device)\n                pred = self.model(x_batch)\n                loss = self.losses(pred, y_batch)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                if (not (ep % 10)) or (ep == 1):\n                    pbar = int(step * 30 \/ len(trainloader))\n                    if not only_print_finish_ep_num:\n                        print(\"\\r{}\/{} [{}{}]\".format(\n                            step, len(trainloader), \">\" * pbar, \" \" * (30 - pbar)), \n                            end=\"\")\n                step += 1\n            loss, acc = self.evaluate(trainloader)   # Loss & Accuracy\n            val_loss, val_acc = self.evaluate(validloader) if doValid else (0, 0)   # if have validation dataset, evaluate validation\n            history[\"loss\"] = np.append(history[\"loss\"], loss)\n            history[\"acc\"] = np.append(history[\"acc\"], acc)\n            history[\"val_loss\"] = np.append(history[\"val_loss\"], val_loss)\n            history[\"val_acc\"] = np.append(history[\"val_acc\"], val_acc)\n            # Update checkpoint\n            if self.__updateCheckpoint(monitor, pre_ck_point, [loss, acc, val_loss, val_acc, ep]):\n                save_file_name = f\"checkpoint_model_ep-{ep}.pt\"\n                self.save(save_file_name)\n                pre_ck_point = [loss, acc, val_loss, val_acc, ep]\n                history['lastest_model_path'] = save_file_name\n                \n            if only_print_finish_ep_num and (ep % 50 == 0):\n                print(f\"{ep} \", end=\" \")\n        return history\n    \n    def evaluate(self, dataloader):\n        total, acc = 0, 0\n        self.model.eval()           # Eval mode\n        for x_batch, y_batch in dataloader:\n            x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device)\n            pred = self.model(x_batch)\n            loss = self.losses(pred, y_batch).item()\n            total += y_batch.shape[0]     # Number of data\n            acc += (torch.sum(pred.argmax(dim=1)==y_batch)).item()     # Sum the prediction that's correct\n        acc \/= total     # Accuracy = correct prediction \/ number of data\n        return (loss, acc)\n    \n    def predict(self, dataset):\n        dataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n        prediction = []\n        truth = []\n        self.model.eval()\n        for x_batch, y_batch in dataloader:\n            x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device)\n            pred = self.model(x_batch).cpu()\n            prediction = np.append(prediction, pred.argmax(dim=1).numpy())\n            truth = np.append(truth, y_batch.cpu().numpy())            \n        return prediction, truth\n    \n    def save(self, filepath):\n        torch.save(self.model, filepath)\n        \n    #@classmethod\n    def load(cls, filepath):\n        return cls(torch.load(filepath))\n    \n    def __updateCheckpoint(self, monitor, pre_ck_point, evaluation):\n        if type(monitor) is int:\n            return True if evaluation[4] % monitor == 0 else False\n        elif type(monitor) is list:\n            for _ in monitor:\n                if not _ in [\"loss\", \"acc\", \"val_loss\", \"val_acc\"]:\n                    raise Exception(f\"\\\"{_}\\\" is not a valid monitor condition.\")\n                elif _ == \"loss\" and pre_ck_point[0] <= evaluation[0]:\n                    return False # present epoch loss > history loss\n                elif _ == \"acc\" and pre_ck_point[1] >= evaluation[1]:\n                    return False # present epoch acc <= history acc\n                elif _ == \"val_loss\" and pre_ck_point[2] <= evaluation[2]:\n                    return False # present epoch val_loss > history val_loss\n                elif _ == \"val_acc\" and pre_ck_point[3] >= evaluation[3]:\n                    return False # present epoch val_acc < history val_acc        \n        return True","26a34a39":"def base_path(path: str):\n    return os.path.join(BASE_DIR, path)\n\ndef plot_acc_and_loss(history, figsize=(10,4), base_save_path=None):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n    if base_save_path:\n        st = fig.suptitle(base_save_path, fontsize=\"x-large\")\n    \n    ax1.title.set_text(\"Acc\")\n    ax1.set_xlabel(\"Epochs\")\n    l1 = ax1.plot(history[\"acc\"], color=\"red\", label='train')\n    l2 = ax1.plot(history[\"val_acc\"], color=\"blue\", label='test')\n    \n    ax2.title.set_text(\"Loss\")\n    ax2.set_ylabel(\"Epochs\")\n    l3 = ax2.plot(history[\"loss\"], color=\"red\", label='train')\n    l4 = ax2.plot(history[\"val_loss\"], color=\"blue\", label='test')\n\n    ax1.legend(loc=\"upper right\")\n    ax2.legend(loc=\"upper right\")\n\n    if base_save_path:\n        plt.savefig(base_path(base_save_path))\n    plt.show()","a543a491":"BATCH_SIZE = 32\nLearning_Rate = 0.001\nEPOCHS = 500","70f906a9":"#train_raw = [loadmat(DATASET_DIR + f\"BCIC_S0{i}_T.mat\") for i in range(1, 10)]\n#test_raw = [loadmat(DATASET_DIR + f\"BCIC_S0{i}_E.mat\") for i in range(1, 10)]\ntrain_raw = loadmat(DATASET_DIR + f\"BCIC_S01_T.mat\")     # Load raw subject 1 train\ntest_raw = loadmat(DATASET_DIR + f\"BCIC_S01_E.mat\")      # Load raw subject 1 test\ntrX, trY, teX, teY = train_raw[\"x_train\"], train_raw[\"y_train\"], test_raw[\"x_test\"], test_raw[\"y_test\"]\n\n#EEGNet use 2D convolution in the beginning, which expects a 3-dims input (channel, heigth, width). Thus, expand one dimension to 4-dim, from (288, 22, 562) to (288, 1, 22, 562).\nx_train = torch.from_numpy(np.expand_dims(trX, axis=1))\nx_test = torch.from_numpy(np.expand_dims(teX, axis=1))\n\n# Squeeze one dimension: (288, 1) => (288,)\ny_train = torch.from_numpy(np.reshape(trY, (trY.size,))).long()\ny_test = torch.from_numpy(np.reshape(teY, (teY.size,))).long()","8ada1c91":"print(trX.shape, trY.shape)\nprint(teX.shape, teY.shape)\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","66cb884c":"trainset, testset = TensorDataset(x_train, y_train), TensorDataset(x_test, y_test)\n\ntrainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True)\ntestloader = DataLoader(dataset=testset, batch_size=BATCH_SIZE, shuffle=True)","d4c5aee3":"eegnet = EEGNet().to(device)\n#summary(eegnet, (1, 22, 562))\nmodel = Model(eegnet, lr=Learning_Rate)\nhistory = model.fit(trainloader=trainloader, validloader=testloader, epochs=EPOCHS, monitor=[\"acc\", \"val_acc\"])","e010729f":"plot_acc_and_loss(history=history, base_save_path=\"part_1.png\")","38ec46a1":"# **Models**","e3395a6b":"# Load Dataset\nNotes\nDataset\nThe .mat (data) file is loaded as dictionaries.\nThe dict contains 5 keys:\n- __header__\n- __version__\n- __globals__\n- 'x_train' or 'x_test'\n- 'y_train' or 'y_test'","c68a3d21":"# Model : Auxiliary","f07c39a3":"# Shallow Conv Net\n\nSource : **Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG**\n\n1. Conv2D (temporal)\n2. Conv2D (Electrodes\/Channel)\n3. Squared\n4. MeanPooling\n5. Classification","03938373":"# **HyperParameter**","c56df313":"# Utilities","725ab883":"288 = 72 trials x 4 classes, 22 channels, 562 timepoints\n* trX = (288, 22, 562) -> (288, 1, 22, 562)\n* trY = (288, 1) -> (288)\n* teX = (288, 22, 562) -> (288, 1, 22. 562)\n* teY = (288, 1) -> (288)","e7e1ee7b":"# EEGNET\nsource : **EEGNet: A Compact Convolutional Neural Network for EEG-based Brain-Computer Interfaces**\n\nC = Channel, T = Time, F1 = n of Temporal Filter, D = Depth (n of spatial filter), F2 = n of pointwise filter\n\n-------------------------------------\n1. Input (C x T)\n2. Reshape (1, C, T)\n3. Conv2D (F1, C, T)\n4. BatchNorm2D (F1, C, T)\n5. DepthwiseConv2D (D * F1, 1, T)\n6. BatchNorm (D * F1, 1, T)\n7. Activation (D * F1, 1, T) - ELU\n8. AveragePool2D (D * F1, 1, T \/\/ 4) - (1,4) pool\n9. DropOut (D * F1, 1, T \/\/ 4)\n---------------------------------------\n1. SeparableConv2D (F2 1, T \/\/ 4)\n2. BatchNorm (F2 1, T \/\/ 4)\n3. Activation (F2 1, T \/\/ 4) - ELU\n4. AveragePool2D (F2 1, T \/\/ 32) - (1,8) pool\n5. DropOut (F2 1, T \/\/ 32)\n6. Flatten (F2 * (T \/\/ 32))\n--------------------------------------\n1. Dense (N) - SoftMax"}}