{"cell_type":{"7d52dc25":"code","f982ab59":"code","87691829":"code","82d801e9":"code","0b5ab13e":"code","652608c7":"code","6f76017e":"code","582438d9":"code","f1c280b4":"code","15c1f044":"code","144caa17":"code","95c68596":"code","1fd25fb4":"code","6d6a1473":"code","6f6b244c":"code","aa029504":"code","791c0884":"code","f084691d":"code","753e7f29":"code","1c2c79f8":"code","38ed1cc8":"code","0efffe86":"code","e3eb6299":"code","6d6890bd":"code","b7b1e35a":"code","72c64d25":"code","bf8c32d0":"code","919344a5":"code","445ea599":"markdown","d53f1ba3":"markdown","22ce9047":"markdown","39f54d84":"markdown","26b65dd5":"markdown","0fa94674":"markdown","1c19d4c6":"markdown","8dcc126e":"markdown","24072463":"markdown","2098229f":"markdown","acb85d08":"markdown","45ec0385":"markdown","f51421a5":"markdown","c046c1d1":"markdown","5b28072c":"markdown","aa80f34e":"markdown","94a0a044":"markdown","45835e59":"markdown","a68a54bc":"markdown","3da16474":"markdown","bb1988e6":"markdown","8623b478":"markdown","a6b61978":"markdown","9b3ae0a1":"markdown","117a2828":"markdown","5cedc714":"markdown","a8829be6":"markdown","7eeb2332":"markdown","70d89656":"markdown","6acfb9bf":"markdown","30535823":"markdown","58696e74":"markdown","eee6750d":"markdown","b0f4a618":"markdown","7dfe69f4":"markdown","40ea65bf":"markdown","f360a453":"markdown","2f5b867d":"markdown","ea0270a4":"markdown"},"source":{"7d52dc25":"#Load dependencies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns","f982ab59":"path = \"..\/input\/titanic-data-for-data-preprocessing\/titanic_data.csv\"\ntitanic = pd.read_csv(path).dropna() #drop missing data\n\nprint(titanic.shape)\ntitanic.head()","87691829":"#Step 1: Create grouper\ngrouper = titanic.groupby(['class'])\n\n#Step 2: Filter column and apply aggregation\ngrouper['survived'].sum().reset_index()","82d801e9":"titanic.groupby(['class'])['survived'].sum().reset_index()","0b5ab13e":"titanic.groupby(['embark_town'])['fare'].mean().reset_index()","652608c7":"titanic.groupby(['embark_town','sex'])['fare'].mean().reset_index()","6f76017e":"titanic.groupby(['embark_town','sex'])[['fare', 'age']].mean().reset_index()","582438d9":"grouper = titanic.groupby(['embark_town'])\n\n#Print dtype for each of the elements in the grouper\n[(type(k),type(g)) for k,g in grouper]","f1c280b4":"#Print shape for the dataframe groups\n[(k,g.shape) for k,g in grouper]","15c1f044":"print(list(grouper)[1][0]) #print key\nlist(grouper)[1][1]        #print dataframe","144caa17":"grouper = titanic.groupby(['embark_town','sex'])\n\n#Print dtype for each of the elements in the grouper\n[(k,g.shape) for k,g in grouper]","95c68596":"#The grouping columns become the index after the groupby aggregation\ntitanic.groupby(['embark_town','sex'])['age'].mean()","1fd25fb4":"titanic.groupby(['embark_town', 'who'])['age'].apply(set).reset_index()","6d6a1473":"titanic.groupby(['embark_town', 'who'])['age'].apply(lambda x: x.max()-x.min()).reset_index()","6f6b244c":"titanic.groupby(['embark_town', 'who']).apply(lambda x: (x['fare']\/x['age']).mean())","aa029504":"#Define aggregations as a dictionary\ng = {'fare':'mean', \n     'age':'median'\n    }\n\ntitanic.groupby(['embark_town', 'who']).agg(g).reset_index()","791c0884":"#Define aggregations as a dictionary\ng = {'fare':['sum', 'mean'], \n     'age':['median', 'min', 'max']\n    }\n\ntitanic.groupby(['embark_town', 'who']).agg(g).reset_index()","f084691d":"#Define aggregations directly as columns and tuples\n\n# titanic.groupby(['embark_town', 'who']).agg(A=('fare', 'sum'), \n#                                             B=('fare', 'mean'),\n#                                             C=('age', 'min'),\n#                                             D=('age', 'max')).reset_index()","753e7f29":"#Define aggregations as a dictionary\ng = {'fare':lambda x: x.sum(), \n     'age' :lambda x: x.max()\n    }\n\ntitanic.groupby(['embark_town', 'who']).agg(g).reset_index()","1c2c79f8":"titanic.groupby('who')['fare'].transform(lambda x: x.mean())","38ed1cc8":"df = pd.DataFrame({'A':[1,2,3,4,8,10,12,13],\n                   'B':[1,2,2,3,1,3,2,3]\n                  })\n\n#custom grouping\neven_odd = ['even' if i%2==0 else 'odd' for i in df['A']]\n\ndf.groupby(even_odd)['B'].mean()","0efffe86":"df = pd.DataFrame({'A':[1,1,2,2,2,1,1,3,3], #<- column to group on\n                   'B':[1,7,2,4,1,8,2,1,3]  #<- column to aggregate\n                  })\n\ngrouper = (df['A']!=df['A'].shift()).cumsum()\n\ndf.groupby(grouper).agg({'A':'mean','B':'sum'}).reset_index(drop=True)","e3eb6299":"d = {'id': [11, 11, 11, 11, 13, 13, 13],\n     'date': ['2017-06-01','2017-06-03','2017-06-05','2017-06-06','2017-06-01','2017-06-02','2017-06-07'],\n     'value': [1, 7, 8, 2, 9, 2, 11]\n    }\n\ndf = pd.DataFrame(d)\ndf['date'] = pd.to_datetime(df['date'])\nprint(\"Input dataframe:\")\ndf","6d6890bd":"#custom date range\nidx = pd.date_range('2017-06-01','2017-06-07')\n\n#set original date column as index\ndf.set_index('date', inplace=True)\n\n#grouby and apply pd.DataFrame.reindex to apply new index and fill value as 0\ndf.groupby('id').apply(pd.DataFrame.reindex, idx, fill_value=0).drop('id',1).reset_index()","b7b1e35a":"data = list(zip(np.random.randint(0,4,(10,)), np.random.randint(0,100,(10,))))\nprint(data)","72c64d25":"from collections import defaultdict\n\nd = defaultdict(list)\n\nfor k,v in data:\n    d[k].append(v)\n    \ngrouped_data = dict(d)\n\nprint(grouped_data)","bf8c32d0":"import numpy as np\n\n#sorted numpy array (sorted by the grouping column)\na = np.array(data)\na = a[np.argsort(a[:, 0])]\n\n#Take the index positions for the unique values using return_index \n#and start from the second one to split the data\ngroups = np.split(a[:,1], np.unique(a[:,0], return_index=True)[1][1:])\nprint(groups)","919344a5":"import itertools\n\nitems = sorted(data, key=lambda x:x[0])\ngrouper = itertools.groupby(items, key=lambda x:x[0])\ngroups = [list(g) for k, g in grouper]\ngroups","445ea599":"Before we can start writing code, let's explore the basics behind a groupby operation. The core concept behind any groupby operation is a three step process called [Split-Apply-Combine](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/groupby.html).\n\n- **Split:** Splitting the data into groups based on some criteria\n- **Apply:** Applying a function to each group independently\n- **Combine:** Combining the results into a data structure\n\nHere is a diagram to make this more intuitive.\n\n![split_apply_combine.png](attachment:5f7e0793-dd7f-4f99-82f8-246c11bf11f2.png)","d53f1ba3":"**Question:** Get the mean fare by age ratio for each age category (`who` column) from each town.","22ce9047":"### 6.2 Re-indexing to a fixed date range for each group\n\n**Question**: A dataframe only contains rows for few dates for each `id`. The goal is to re-index the dataframe for a fixed date range, but for each of the `id` individually. Also, fill the missing data with 0 values.\n\n> Here we can create a custom reindex using `pandas.date_range`. Then, after setting the original date column as index, we can apply `pandas.DataFrame.reindex` along with groupby on the `id` column to reindex with the new date range for group, while filling empty values as 0.","39f54d84":"**Question:** Get the unique set of ages for all each age category (`who` column) from each town.","26b65dd5":"> **Note:** The `reset_index()` helps bring the grouping columns from index, back as a column in a dataframe.\n\n**Question:** What was the average fare for passengers from each town?","0fa94674":"## 8. References\n\n- http:\/\/www.scipy-lectures.org\/packages\/statistics\/index.html#hypothesis-testing-comparing-two-groups\n- https:\/\/www.simple-talk.com\/sql\/t-sql-programming\/sql-group-by-basics\/\n- http:\/\/www.shanelynn.ie\/summarising-aggregation-and-grouping-data-in-python-pandas\/\n- http:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.groupby.html","1c19d4c6":"The key for each of the tuples\/groups is the value from the grouper column (in this case the `embark_town`) and the value is just the complete dataframe filtered for that value! If we try to print one of the dataframe from this grouper, you can see that all the rows in this slice of data contain `Queenstown` as the `embark_town`, as shown below.","8dcc126e":"### 4.3 Multiple aggregations using agg method\n\nSooner or later, you would find it necessary to work with multiple aggregations over multiple columns at once. This is where `agg()` method comes in. Here is a quick example of how you can use multiple in-built functions over multiple columns at once.\n\nThe general way to do this is to create a dictionary with the requirements and pass it to the `agg()` function. There are a few ways to structure the dictionary - \n\n```\n##Single function per column\n{\n 'column1': 'function1', \n 'column2': 'function2'\n}\n\n##Multiple functions per column\n{\n 'column1': ['function1', 'function2'], \n 'column2': ['function3', 'function4']\n}\n```","24072463":"### 2.1 Adding more groups\/levels\n\nWe can pass a list of features in the `groupby()` to increase the levels for grouping the data as below.\n\n**Question:** What was the average fare for male vs female passengers from each town?","2098229f":"### 4.2 Custom functions with pandas apply\n\nThis is by far the most popular way of applying a custom function to a dataframe, or in this case, applying it on each of the dataframe slices for groups defined by the grouper. The behavior of the `apply()` method with groupby is similar to the standard one. \n\nYou can apply it to each row (or column) of a dataframe input (if you have more than one column for aggregation) or to a series (if you have single column for aggregation). Within the function, you can actually either work directly with individual series or just write your own lambda function. Here are a few ways using the [apply](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.core.groupby.GroupBy.apply.html) function.","acb85d08":"### 4.4 Custom functions with agg method\n\nAs you might think, just modifying the aggregate functions to include lambda functions is a way to create your own custom functions applied to specific columns. Here are a few examples.","45ec0385":"## 3. Grouping\n\nBefore we go further and try other, more complex scenarios, let's try to understand the data structures we are working with, so that we can be much more creative with our approaches and get a deeper understanding on how they work. \n\nYou can imagine the pipeline of the above code to be as - \n\n- **Step 1:** Create a grouper object with `titanic.groupby(['embark_town'])` which splits data into the relevant groups\n- **Step 2:** Select the column `'fare'` from each of those groups\n- **Step 3:** Apply `mean()` on this column for each of the groups, combine and then return the aggregated dataset\n\n\nLet's see what the [grouper object](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Grouper.html) looks like for a better understanding.","f51421a5":"## 1. Introduction\n\n\"Groupby\" is probably one of the most basic data pre-processing step that a Data Scientist should master as soon as possible. Interestingly enough, you find it in almost every scripting language that claims to work well with databases. \n\nMost of us would have been introduced to the `SQL GROUPBY` statement which allows a user to summarize or aggregate a given dataset. Python brings the pandas groupby method to the table, which is highly pythonic in its syntax and equally versatile, if not more. But the utility of a groupby is much more than just aggregation. In this notebook, I will showcase a few examples, where you could really exploit this method for various other use-cases.","c046c1d1":"## 7. Other ways of grouping data\n\nHere I discuss 3 ways that are popularly used to group data depending on the data structures and libraries you are already working with. \n\n- Grouping using `collections.defaultdict`\n- Using `numpy.split()` to group an array\n- Chunking into groups using `itertools.groupby()`\n\nLet's say we have a list of tuples with keys and values which we need to group.","5b28072c":"### 7.1 Using collections' defaultdict\n\nA useful way of grouping data is to use `defaultdict`. [Defaultdict](https:\/\/docs.python.org\/3\/library\/collections.html#collections.defaultdict) can store the grouping values as keys, and store the values as a list of values (or a custom function on them)","aa80f34e":"As of **Pandas >= 0.25**, another way to define the `agg` function is define the each column with `('column', 'function')`. \n> **NOTE:** This may throw and error on Kaggle (pandas version ~ 0.23, check `pd.__version__`)","94a0a044":"## 5. Transform\n\nApart from just aggregating, you can use groupby to [transform](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.core.groupby.DataFrameGroupBy.transform.html) columns based on the grouper object. This requires using `transform()` function and returns the same number of rows as the original dataset, but the functions are applied based on the grouping defined. Let's consider the following point.\n\n**Question:** Create a new column that returns the average fare for the age group (`who` column) the passenger belongs to.","45835e59":"### 7.2 Using numpy's split function\n\nAnother way of [splitting an array](https:\/\/stackoverflow.com\/questions\/38013778\/is-there-any-numpy-group-by-function\/43094244) into a list of sub-arrays based on a grouping key is by using `np.split` along with the indexes for each group returned by `np.unique`. Only important thing is, the arrays needs to be sorted explicitly.","a68a54bc":"### 4.1 In-built aggregation methods\n\nPandas provides a ton of aggregation methods to quickly get the statistics you are looking for. Below are a few of the common ones that are use and more details on these can be found on the official [pandas documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/groupby.html).\n\n|Function   | Description\n|:----------|----------------------------------------------|\n|mean( )    | Compute mean of groups|\n|median( )  | Compute median of groups|\n|mode( )    | Compute mode of groups|\n|sum( )     | Compute sum of group values|\n|prod( )    | Compute product of group values|\n|size( )    | Compute group sizes|\n|count( )   | Compute count of group|\n|std( )     | Standard deviation of groups|\n|var( )     | Compute variance of groups|\n|skew( )    | Compute skewness\/3rd moment of groups|\n|kurt( )    | Compute kurtosis\/4th moment of groups|\n|sem( )     | Standard error of the mean of groups|\n|mad( )     | Mean absolute deviation for each group|\n|describe( )| Generates descriptive statistics|\n|first( )   | Compute first of group values|\n|last( )    | Compute last of group values|\n|nth( )     | Take nth value, or a subset if n is a list|\n|min( )     | Compute min of group values|\n|max( )     | Compute max of group values|","3da16474":"**Question:** Get the range (min - max) of ages for each age category (`who` column) from each town.","bb1988e6":"# Groupby & Aggregate using Pandas\n\n\nBlog: http:\/\/akshaysehgal.com\/groupby.html\n\n`python` `pandas` `groupby` `aggregate` \n<a href=\"http:\/\/akshaysehgal.com\/\"><span class=\"copyright\" style=\"float:right; font-size:x-small; color:#333333; margin-top: 5px;\">&copy; Copyright 2017, Akshay Sehgal | 3<sup>rd<\/sup> Oct 21<\/span><\/a>\n    \n-------","8623b478":"This will get more clear as we take an example from actual data. So, let's start by loading a dataset to work with. For this notebook I will use the Titanic dataset which can either be downloaded from [Kaggle](https:\/\/www.kaggle.com\/c\/titanic), or directly loaded using the visualization library called [Seaborn](https:\/\/github.com\/mwaskom\/seaborn-data).","a6b61978":"## 4. Aggregation\n\nThere are multiple ways of aggregating your grouper object. \n\n1. First part of this section is to understand that you can perform aggregations on multiple columns, OR, perform multiple aggregations themselves on different columns, or a combination of both.\n2. Second, you can use `apply()` or `agg()` to write your own custom aggregators but Pandas makes it much easier by providing a ton of in-built aggregators such as `sum()` or `mean()` as we discussed in the above examples.\n\nLet's try to go through a few scenarios and explore how we can use these aggregations.","9b3ae0a1":"**Question**: Get sum of the `value` column of the given dataframe based on the sequentially occuring groups `category` i.e, in `[1,1,2,2,1,1]` the first group of `1's` should be a separate group than second set of `1's`.\n\n> We can solve this creating a custom grouper, by shifting the column value by 1 and comparing them with original. If not equal, it will swap the boolean value. Then we can take a `cumsum` over the boolean to get groups where the value changes consecutively. Here is the solution for a [similar problem](https:\/\/stackoverflow.com\/a\/69287629\/4755954) I solved on Stack Overflow.","117a2828":"Notice that the output series is of the length of the original titanic dataframe, but contains only 3 unique values `[88.8, 69.8, 77.3]`, one for each of the `['woman', 'man', 'child']`. This make the grouping object highly versatile in the way you would use it for data preprocessing.","5cedc714":"You would usually do this in a single statement as the following:","a8829be6":"```python\n#SQL Query to groupby Col1 and Col2\n#and get mean and sum of col3 and col 4 respectively\n\nSELECT Col1, Col2, mean(Col3), sum(Col4)\nFROM Table\nGROUP BY Col1, Col2\n```","7eeb2332":"### 2.2 Adding more variables\/features\n\nSimilarly, we can select a list of variables for which you need to apply the aggreate function.\n\n**Question:** What was the average fare and age for male vs female passengers from each town?","70d89656":"## 2. Syntax\n\n\nThe syntax for using a groupby method in Pandas comprises of 2 parts. First is a grouper object and the second is the aggregator. The general structure looks like the following - \n\n```\ndataset.groupby(['grouping column(s)'])['output column(s)'].aggregation()\n|____________________________________| |________________________________|\n                   |                                    |\n        grouper object (split)            aggregation (apply & combine)\n```","6acfb9bf":"### 7.3 Using itertools' groupby\n\n[Itertools](https:\/\/stackoverflow.com\/questions\/38013778\/is-there-any-numpy-group-by-function\/43094244) provides a `groupby` api which is actually a sequential\/local grouping method. \n\nIt's powerful for getting groups from \"AAABBBAACCC\" as \"AAA BBB AA CCC\". But in order to get groups as \"AAAAA BBB CCC\", its necessary to first sort the data by the grouping key.","30535823":"Similarly, let's see how the grouper object looks like for multiple grouping features. The 'key' in this case is just a tuple with all the group combinations, which, after aggregation, gets set as the index of the final output.","58696e74":"**Question:** Get the mean of fare, AND median of age for each age category (`who` column) from each town","eee6750d":"So, this shows that if we try to iterate over the grouper object, its nothing but a tuple with the key and a dataframe. \n\nLet's see what each of those is.","b0f4a618":"**Question:** What is the total number of passengers from each class who survived?","7dfe69f4":"### Table of contents:\n\n1. [Introduction](#1.-Introduction)<br>\n2. [Syntax](#2.-Syntax)<br>\n    2.1 [Adding more groups\/levels](#2.1-Adding-more-groups\/levels)<br>\n    2.2 [Adding more variables\/features](#2.2-Adding-more-variables\/features)<br>\n3. [Grouping](#3.-Grouping)<br>\n4. [Aggregation](#4.-Aggregation)<br>\n    4.1 [In-built aggregation methods](#4.1-In-built-aggregation-methods)<br>\n    4.2 [Custom functions with pandas apply](#4.2-Custom-functions-with-pandas-apply)<br>\n    4.3 [Multiple aggregations using agg method](#4.3-Multiple-aggregations-using-agg-method)<br>\n    4.4 [Custom functions with agg method](#4.4-Custom-functions-with-agg-method)<br>\n5. [Transform](#5.-Transform)<br>\n6. [Advanced Usage](#6.-Advanced-Usage)<br>\n    6.1 [Sequential\/local grouping of a dataframe](#6.1-Sequential\/local-grouping-of-a-dataframe)<br>\n    6.2 [Re-indexing to a fixed date range for each group](#6.2-Re-indexing-to-a-fixed-date-range-for-each-group)<br>\n7. [Other ways of grouping data](#7.-Other-ways-of-grouping-data)<br>\n    7.1 [Using collections' defaultdict](#7.1-Using-collections'-defaultdict)<br>\n    7.2 [Using numpy's split function](#7.2-Using-numpy's-split-function)<br>\n    7.3 [Using itertools' groupby](#7.3-Using-itertools'-groupby)<br>\n8. [References](#8.-References)<br>\n\n\n\n\n\n\n\n\n","40ea65bf":"## 6. Advanced Usage\n\nLet's introduce a few advanced cases where you end up using groupby for data preprocessing.","f360a453":"### 6.1 Sequential\/local grouping of a dataframe\n\nThe grouper object doesnt need to explicitly come from the dataframe. As long as the length of the grouper is the same as the number of rows in the dataframe, you can assign any grouper to groupby the rows by.","2f5b867d":"**Question:** Get the sum & mean of fare, AND median, min and max of age for each age category (`who` column) from each town","ea0270a4":"**Question:** Get the sum & mean of fare, AND min and max of age for each age category (`who` column) from each town, but rename columns"}}