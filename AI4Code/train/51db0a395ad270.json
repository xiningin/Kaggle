{"cell_type":{"4879bb29":"code","47751220":"code","7438a7f3":"code","d70b7213":"code","5f0b6d08":"code","23786668":"code","1d5ae91d":"code","c2c5d92d":"code","f849dc6c":"code","c1715a97":"code","bf642f23":"code","150c3efc":"code","0e472a2a":"code","6684eae5":"code","361b63b9":"code","2355d8dd":"markdown"},"source":{"4879bb29":"# \u307e\u305a\u306f\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092import\u3057\u3088\u3046\u3002\nimport numpy as np\nimport pandas as pd\npd.options.display.max_columns = 200\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\n\nfrom tqdm import tqdm_notebook as tqdm","47751220":"# csv\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\u3002\ndf_train = pd.read_csv('..\/input\/machine-learning-homework\/train.csv', index_col=0)\ndf_test = pd.read_csv('..\/input\/machine-learning-homework\/test.csv', index_col=0)","7438a7f3":"# \u884c\u6570\u3068\u5217\u6570\u3092\u78ba\u8a8d\u3059\u308b\u3002\ndf_train.shape, df_test.shape","d70b7213":"# \u5148\u982d5\u884c\u3092\u78ba\u8a8d\u3057\u3066\u307f\u3088\u3046\u3002\ndf_train.head()","5f0b6d08":"# \u5148\u982d5\u884c\u3092\u78ba\u8a8d\u3057\u3066\u307f\u3088\u3046\u3002\ndf_test.head()","23786668":"# \u90fd\u9053\u5e9c\u770c\u5225\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u78ba\u8a8d\u3057\u3066\u307f\u3088\u3046\u3002\ndf_train.Prefecture.value_counts()","1d5ae91d":"df_test.Prefecture.value_counts()","c2c5d92d":"# \u30c7\u30fc\u30bf\u3092\u7279\u5fb4\u91cf\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u5206\u5272\u3057\u3066\u304a\u304d\u307e\u3059\u3002\ny_train = df_train.TradePrice\nX_train = df_train.drop(['TradePrice'], axis=1)\n\nX_test = df_test.copy()","f849dc6c":"# \u6700\u5bc4\u308a\u99c5\u307e\u3067\u306e\u6240\u8981\u6642\u9593\u304c\u30ab\u30c6\u30b4\u30ea\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u6570\u5024\u306b\u5909\u63db\u3057\u3066\u307f\u308b\u3002\nreplace_dict = {\n    '30-60minutes':30, '1H-1H30':60, '2H-':120, '1H30-2H':90}\nX_train.TimeToNearestStation.replace(replace_dict, inplace=True)\nX_test.TimeToNearestStation.replace(replace_dict, inplace=True)\n\nX_train.TimeToNearestStation = X_train.TimeToNearestStation.astype(float)\nX_test.TimeToNearestStation = X_test.TimeToNearestStation.astype(float)","c1715a97":"# dtype\u304cobject\u306e\u3082\u306e\u3092\u96d1\u306bLabelEncoding\u3057\u3066\u304a\u304f\u3002\u540c\u6642\u306b\u6b20\u640d\u3092\u57cb\u3081\u3066\u304a\u304f\u3002\nX_concat = pd.concat([X_train, X_test])\n\nfor col in X_concat.columns:\n    if (X_concat[col].dtype == 'object'):\n        le = LabelEncoder()\n        X_concat[col] = le.fit_transform(X_concat[col].fillna('NaN')) # \u30ab\u30c6\u30b4\u30ea\u306e\u6b20\u640d\u3092NaN\u3068\u3044\u3046\u5024\u3067\u57cb\u3081\u3066\u304a\u304f\n        \nX_train = X_concat[X_concat.index.isin(X_train.index)].fillna(-99999) # \u6570\u5024\u306e\u6b20\u640d\u3092-99999\u3067\u57cb\u3081\u3066\u304a\u304f\nX_test = X_concat[~X_concat.index.isin(X_train.index)].fillna(-99999)","bf642f23":"# \u51e6\u7406\u5f8c\u306b\u3064\u3044\u3066\u3082\u5148\u982d5\u884c\u3092\u307f\u3066\u307f\u3088\u3046\u3002\nX_train.head()","150c3efc":"X_test.head()","0e472a2a":"groups = X_train.Prefecture.values\nX_train.drop(['Prefecture'], axis=1, inplace=True)\nX_test.drop(['Prefecture'], axis=1, inplace=True)","6684eae5":"# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    model = HistGradientBoostingRegressor(learning_rate=0.05, random_state=71, max_iter=500)\n    model.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(model.predict(X_val))\n    y_pred_test += np.expm1(model.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","361b63b9":"df_sub = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\ndf_sub.TradePrice = y_pred_test\ndf_sub.to_csv('submission.csv')","2355d8dd":"## \u4f4f\u3093\u3067\u57fc\u7389\uff01 ~ \u4f4f\u5b85\u4fa1\u683c\u4e88\u6e2c"}}