{"cell_type":{"43496480":"code","32b3665c":"code","1e9888b8":"code","b4af7c74":"code","83d04d20":"code","823c186b":"code","ecc6bf16":"code","5fbb5eef":"code","f177171f":"code","4eae550e":"code","b323d98f":"code","7414d422":"code","9bd39423":"code","081a6fdf":"code","4889a625":"code","143585e3":"code","8f8f7d89":"code","1e9c06c8":"code","ac67c855":"code","3ad16ad8":"code","431d7c22":"code","00c006d0":"code","c133e60b":"code","ff7f32c0":"code","d0e79d38":"code","6c33fbfe":"code","218edb23":"code","097b223f":"code","fa1d5aa8":"code","f9c4e448":"code","0ff2edc3":"code","8e5bf36b":"code","e30d0714":"markdown","654a6473":"markdown","08c04823":"markdown","8f407dc4":"markdown","c695b5fe":"markdown","8cfbe857":"markdown","fe7ddc8a":"markdown","8bc45457":"markdown"},"source":{"43496480":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","32b3665c":"dataset = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\n","1e9888b8":"dataset.shape","b4af7c74":"dataset.head()","83d04d20":"from matplotlib import pyplot as plt\nimport seaborn as sns\ncorr = dataset.corr()\nfig, ax = plt.subplots(figsize=(30, 18))\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\ndropSelf = np.zeros_like(corr)\ndropSelf[np.triu_indices_from(dropSelf)] = True\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=colormap, linewidths=.5, annot=True, fmt=\".2f\", mask=dropSelf)\nplt.title('Fraud - Features Correlations')\nplt.show()","823c186b":"sns.set(style=\"whitegrid\")\nnum = [f for f in dataset.columns if ((dataset.dtypes[f] != 'object')& (dataset.dtypes[f]!='int64'))]\nnd = pd.melt(dataset, value_vars = num)\nn1 = sns.FacetGrid (nd, col='variable', col_wrap=4, sharex=False, sharey = False)\nn1 = n1.map(sns.distplot, 'value')\nn1","ecc6bf16":"num = [f for f in dataset.columns if ((dataset.dtypes[f] != 'object')& (dataset.dtypes[f]!='int64'))]\nnd = pd.melt(dataset, value_vars = num)\nn1 = sns.FacetGrid (nd, col='variable', col_wrap=4, sharex=False, sharey = False)\nn1 = n1.map(sns.boxplot, 'value')\nn1","5fbb5eef":"target = dataset['Class']\ntrain=dataset.drop('Class',axis=1)","f177171f":"#applying SMOTE\nfrom imblearn.combine  import SMOTETomek\nsmk=SMOTETomek(random_state=42)\ntrain_new,target_new=smk.fit_sample(train,target)","4eae550e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_new, target_new, test_size = 0.30, random_state = 0)","b323d98f":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()","7414d422":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)","9bd39423":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\naccuracy=accuracy_score(y_test,y_pred) \nprecision=precision_score(y_test,y_pred,average='weighted')\nrecall=recall_score(y_test,y_pred,average='weighted')\nf1=f1_score(y_test,y_pred,average='weighted')\n\nprint('Accuracy - {}'.format(accuracy))\nprint('Precision - {}'.format(precision))\nprint('Recall - {}'.format(recall))\nprint('F1 - {}'.format(f1))","081a6fdf":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","4889a625":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndisp = plot_precision_recall_curve(classifier, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","143585e3":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)","8f8f7d89":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        1#print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","1e9c06c8":"cnf_matrix = confusion_matrix(y_test,y_pred)\nnp.set_printoptions(precision=2)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cnf_matrix\n                      , classes=class_names\n                      , title='Confusion matrix')\nplt.show()","ac67c855":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier(criterion='gini', splitter='best',\n                             max_depth=16, min_samples_split=2,\n                             min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n                             max_features=None, random_state=None,\n                             max_leaf_nodes=None, min_impurity_decrease=0.0, \n                             min_impurity_split=None, class_weight=None, \n                             presort='deprecated', ccp_alpha=0.0)\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)","3ad16ad8":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\naccuracy=accuracy_score(y_test,y_pred) \nprecision=precision_score(y_test,y_pred,average='weighted')\nrecall=recall_score(y_test,y_pred,average='weighted')\nf1=f1_score(y_test,y_pred,average='weighted')\n\nprint('Accuracy - {}'.format(accuracy))\nprint('Precision - {}'.format(precision))\nprint('Recall - {}'.format(recall))\nprint('F1 - {}'.format(f1))","431d7c22":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","00c006d0":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndisp = plot_precision_recall_curve(classifier, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","c133e60b":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_pred,y_test)\nprint(cm)","ff7f32c0":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        1#print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","d0e79d38":"cnf_matrix = confusion_matrix(y_test,y_pred)\nnp.set_printoptions(precision=2)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cnf_matrix\n                      , classes=class_names\n                      , title='Confusion matrix')\nplt.show()","6c33fbfe":"from sklearn.naive_bayes import GaussianNB\nnb_model=GaussianNB()\nnb_model.fit(X_train,y_train)\ny_pred=nb_model.predict(X_test)","218edb23":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\naccuracy=accuracy_score(y_test,y_pred) \nprecision=precision_score(y_test,y_pred,average='weighted')\nrecall=recall_score(y_test,y_pred,average='weighted')\nf1=f1_score(y_test,y_pred,average='weighted')\n\nprint('Accuracy - {}'.format(accuracy))\nprint('Precision - {}'.format(precision))\nprint('Recall - {}'.format(recall))\nprint('F1 - {}'.format(f1))","097b223f":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","fa1d5aa8":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndisp = plot_precision_recall_curve(classifier, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","f9c4e448":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)","0ff2edc3":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        1#print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","8e5bf36b":"cnf_matrix = confusion_matrix(y_test,y_pred)\nnp.set_printoptions(precision=2)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cnf_matrix\n                      , classes=class_names\n                      , title='Confusion matrix')\nplt.show()","e30d0714":"### XGBoost Classifier","654a6473":"* Plotting the distributions of all the variables","08c04823":"### Naive Baye's","8f407dc4":"# Model Implementation","c695b5fe":"### Decision Tree","8cfbe857":"## Using SMOTE(Synthetic Minority Over-sampling Technique)","fe7ddc8a":"Plotting boxplots for every variable","8bc45457":"# Credit Card Fraud Analysis and detection"}}