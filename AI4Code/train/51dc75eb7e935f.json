{"cell_type":{"5b6c5445":"code","8dfbba2b":"code","4c9014b5":"code","9cac091a":"code","38e943ba":"code","3c4d20b7":"code","7d56734a":"code","70ca2d93":"code","2b21cc46":"code","f2095118":"code","c8626713":"code","54728215":"code","9c65b1e8":"code","19987a95":"code","560c4982":"code","ba218328":"code","bc09c6ee":"code","6c8a629e":"code","20631eb3":"code","c51e342e":"code","169d205c":"code","5a9f3240":"code","3c11d263":"code","24968c34":"markdown","89d4ee17":"markdown","7fca92ca":"markdown","2a646a9c":"markdown","7852f8e1":"markdown","81f2e2d9":"markdown","c700a30b":"markdown","78bcc80d":"markdown","9745b88f":"markdown","abac729b":"markdown","193cfb80":"markdown","ff2ae28f":"markdown","80b43920":"markdown","cf06729a":"markdown","406760ec":"markdown","06e3bed6":"markdown"},"source":{"5b6c5445":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\n\nimport re\nimport string\n\nimport nltk\nfrom nltk.stem import RSLPStemmer\nnltk.download('rslp')\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nSTOPWORDS = stopwords.words('portuguese')\n\nfrom scipy.stats import loguniform\nfrom pandas import read_csv\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV","8dfbba2b":"from argparse import Namespace\n\nparams = Namespace(\n    dataset_path = '\/kaggle\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv',\n    max_features = 300,\n    test_size=.30,\n    random_state=42,\n    max_iter_lg = 10000\n)","4c9014b5":"reviews = pd.read_csv(params.dataset_path)\nreviews.head()","9cac091a":"columns = ['review_comment_message','review_score']\nreviews = reviews[columns]\nreviews.head()","38e943ba":"hasNull = reviews.isnull().any().any()\n\nif hasNull :\n    print('\\nPorcentage (%).')\n    print(f'{round((reviews.count()\/reviews.isnull().sum()) * 100).replace([np.inf, -np.inf], 0),2}\\n')\nelse:\n    print('There are no null data.')","3c4d20b7":"print(f'Number of Observations with null data: {reviews.shape[0]}\\n')\nreviews = reviews.dropna(subset=['review_comment_message'])\nprint(f'Number of observations after null data removal: {reviews.shape[0]}\\n')","7d56734a":"points = [0, 2, 5]\npolarities = [0, 1]\nreviews['label'] = pd.cut(reviews['review_score'], bins=points, labels=polarities)\n\nreviews = reviews[['review_comment_message','label']]\nreviews = reviews.rename(columns={'review_comment_message':'text'})\nreviews.head(10)","70ca2d93":"class ClearPipe(BaseEstimator, TransformerMixin):\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        texto_transformado = []\n        for texto in X:\n            texto = re.sub('\\n', ' ', texto)\n            \n            texto = re.sub('\\r', ' ', texto)\n\n            texto = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', ' numero ', texto)\n\n            texto = re.sub(r'R\\$', ' ', texto)\n            texto = re.sub(r'\\W', ' ', texto)\n            texto = re.sub(r'\\s+', ' ', texto)\n\n            urls = re.findall('(http|ftp|https):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?', texto)\n            if len(urls) == 0:\n                pass\n            else:\n                for url in urls:\n                    for link in url:\n                        texto = texto.replace(link, '')\n                texto = texto.replace(':', '')\n                texto = texto.replace('\/', '')\n          \n            texto_transformado.append(texto)\n        return texto_transformado","2b21cc46":"class StopWordsPipe(BaseEstimator, TransformerMixin):\n    \n    def fit(self, X, y=None):\n        return self\n\n    def _removeStopPipe(self, text):\n        nopunc = [char for char in text if char not in string.punctuation]\n        nopunc = ''.join(nopunc)\n        return [word for word in nopunc.split() if word.lower() not in STOPWORDS]\n\n    def transform(self, X, y=None):\n        texto_transformado = list(map(lambda c: self._removeStopPipe(c), X))\n        texto_transformado = list(map(lambda x: ' '.join(x), texto_transformado))\n        return texto_transformado","f2095118":"class SteammingPipe(BaseEstimator, TransformerMixin):\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def _applySteaming(self, c):\n        stemmer = RSLPStemmer()\n        return list(map(lambda x: stemmer.stem(x), [word for word in c.split()]))\n    \n    def transform(self, X, y=None):\n        texto_transformado = list(map(lambda c: self._applySteaming(c), X))\n        texto_transformado = list(map(lambda x: ' '.join(x), texto_transformado))\n        return texto_transformado","c8626713":"pipe_preprocessamento = Pipeline([\n    ('clear', ClearPipe()),\n    ('stopwords', StopWordsPipe()),\n    ('stemming', SteammingPipe()),\n])","54728215":"text_preprocessed = pipe_preprocessamento.fit_transform(reviews['text'])","9c65b1e8":"vectorizer = CountVectorizer(max_features=params.max_features, stop_words=STOPWORDS)\nX = vectorizer.fit_transform(text_preprocessed).toarray()","19987a95":"from sklearn.model_selection import train_test_split\n\ny = reviews['label'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=params.test_size, random_state=params.random_state)","560c4982":"model = LogisticRegression( max_iter=params.max_iter_lg,  dual=False)\nmodel.fit(X_train, y_train,)","ba218328":"acc = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')\nacc.mean()","bc09c6ee":"fig = plt.figure()\nfig.suptitle('Model Performance (Accuracy)')\nax = fig.add_subplot(111)\nax.set_xticklabels(['Logistic Regression'])\nplt.boxplot(acc)\nplt.show()","6c8a629e":"def predict(text):\n    text_preprocessed = pipe_preprocessamento.fit_transform(text)\n    text_transformed = vectorizer.transform(text_preprocessed).toarray()\n    pred = model.predict(text_transformed)\n    return 'positive' if pred[0] == 1 else 'negative'","20631eb3":"text1 = ['produto de p\u00e9ssima qualidade.']\nprint(predict(text1))","c51e342e":"text2 = ['Excelente produto, indico']\nprint(predict(text2))","169d205c":"space = dict()\nspace['solver'] = ['lbfgs', 'liblinear']\nspace['penalty'] = ['none', 'l1', 'l2']\nspace['C'] = loguniform(1e-5, 100)","5a9f3240":"\ncv = RepeatedStratifiedKFold(n_splits=10, random_state=params.random_state)\nsearch = RandomizedSearchCV(model, space, scoring='accuracy', n_jobs=4, cv=cv, random_state=params.random_state)","3c11d263":"# execute search\nresult = search.fit(X, y)\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)","24968c34":"<a id=\"modeling\"><\/a>\n## Modeling","89d4ee17":"<a id=\"random-search\"><\/a>\n## Random Search","7fca92ca":"<a id=\"Steamming\"><\/a>\n### Steamming","2a646a9c":"<a id=\"split-train\"><\/a>\n### Split dataset","7852f8e1":"<a id=\"load-data\"><\/a>\n## Load Data","81f2e2d9":"<a id=\"label-sentiment\"><\/a>\n## Label","c700a30b":"<a id=\"preprocess\"><\/a>\n## Pre process","78bcc80d":"## **Table Content**\n\n* [Parameterization](#parameterization)\n* [Data Wrangling](#data-wrangling)\n    - [Load Data](#load-data)\n    - [Remove Missing Data](#missing-data)\n    - [Label Sentiment](#label-sentiment)\n* [Pre Process](#preprocess)\n    - [Clear Text](#clear-text)\n    - [Apply Steamming](#apply-steamming)\n    - [Remove Stop Word](#stop-word)\n* [Modeling](#modeling)\n    - [Logistic Regression](#logistic-regression)\n* [Evaluate](#evaluete)\n    - [Metrics](#metrics)\n    - [Curve ROC](#curve-roc)\n* [Hyperparametes Optimization](#hyperparametes-optimization)\n    - [Random Search](#random-search)\n* [Conclusion](#conclusion)","9745b88f":"<a id=\"remove-null\"><\/a>\n## Remove Null Data","abac729b":"<a id=\"parameterization\"><\/a>\n# Parameterization\n\nWe will parameterize our experiments, so that we can create tests just by changing the predefined parameters.\n\n**Parameters**\n\n<table style=\"width:45%;margin-right:60%;text-align:left\">\n  <tr>\n    <th>Name<\/th>\n    <th>Description<\/th>\n  <\/tr>\n  <tr>\n    <td>dataset_path<\/td>\n    <td>Dataset path<\/td>\n  <\/tr>\n  <tr>\n    <td>max_features<\/td>\n    <td>Max features used in vectorization<\/td>\n  <\/tr>\n    <tr>\n    <td>test_size<\/td>\n    <td>Percentage for dataset split<\/td>\n  <\/tr>\n    <tr>\n    <td>random_state<\/td>\n    <td>Random State<\/td>\n  <\/tr>\n    <tr>\n    <td>max_iter_lg<\/td>\n    <td>Number Max of Logistic Regression iteration<\/td>\n  <\/tr>\n<\/table>\n","193cfb80":"<a id=\"clear-text\"><\/a>\n### Clear Text","ff2ae28f":"<a id=\"data-wrangling\"><\/a>\n# Data Wrangling\n\nData wrangling is the process of cleaning, structuring and enriching raw data into a ideal format for preprocessed.\n\nIn this project, we are going to do the following steps.\n* Load Data\n* Remove Missing Data\n* Label Sentiment","80b43920":"<a id=\"select-columns\"><\/a>\n## Select Columns","cf06729a":"<a id=\"vectorization\"><\/a>\n### Vectorization","406760ec":"<a id=\"evaluation\"><\/a>\n## Evaluation","06e3bed6":"<a id=\"hyperparametes-optimization\"><\/a>\n## Hyperparametes Optimization"}}