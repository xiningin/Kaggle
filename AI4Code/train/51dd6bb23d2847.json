{"cell_type":{"be89f6db":"code","5d2e091b":"code","1d27b98a":"code","6f0416d2":"code","764496f8":"code","5c5256f3":"code","84a22a38":"code","f768de07":"code","b12e8e49":"code","b5a07a00":"code","8863d923":"code","bc956f14":"code","748d8a26":"code","651ec4db":"code","e443458c":"code","5e38e7ae":"code","d0a9683c":"code","b804f16b":"code","2e9998d3":"code","5c109ad5":"code","0de289e0":"markdown","6b694b00":"markdown","509d9bb0":"markdown","1899b8c4":"markdown","9415c18b":"markdown","8f9e727a":"markdown","2c1c5898":"markdown","ce366508":"markdown","118784f0":"markdown","3f1e1088":"markdown","3d44ead0":"markdown","949155cd":"markdown","75e36eaa":"markdown","aa021b52":"markdown","07a4bbe5":"markdown"},"source":{"be89f6db":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom keras.datasets import cifar10\n\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D, Conv2DTranspose\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Reshape\nfrom keras.utils.vis_utils import plot_model","5d2e091b":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\nprint('Train', X_train.shape, y_train.shape) \nprint('Test', X_test.shape, y_test.shape)","1d27b98a":"plt.figure(figsize=(15,7))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.axis('off')\n    plt.imshow(X_train[i])\nplt.show()","6f0416d2":"def define_discriminator(in_shape=(32,32,3)):\n    model = Sequential()\n    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.4))\n    \n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.4)) \n\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.4))\n    \n    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.4))\n    \n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    \n    model.add(Dense(1, activation='sigmoid'))\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    return model\n\nmodel = define_discriminator()\n\nplot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)","764496f8":"def load_real_samples():\n    (trainX, _), (_, _) = cifar10.load_data()\n    \n    X = trainX.astype('float32')\n    X = (X - 127.5) \/ 127.5\n    \n    return X\n\n\ndef generate_real_samples(dataset, n_samples):\n    ix = np.random.randint(0, dataset.shape[0], n_samples)\n    X = dataset[ix]\n    y = np.ones((n_samples, 1))\n    \n    return X, y\n    \n\ndef generate_fake_samples(n_samples):\n    X = np.random.rand(32*32*3*n_samples)\n    \n    # update to have the range [-1, 1]\n    X = -1 + X * 2\n    \n    X = X.reshape((n_samples, 32, 32, 3))\n    y = np.zeros((n_samples, 1))\n    \n    return X, y","5c5256f3":"def train_discriminator(model, dataset, n_epochs=40, n_batch=128):\n    half_batch = int(n_batch \/ 2)\n    \n    for i in range(n_epochs):\n        X_real, y_real = generate_real_samples(dataset, half_batch)\n        model.train_on_batch(X_real, y_real)\n        \n        X_fake, y_fake = generate_fake_samples(half_batch)\n        model.train_on_batch(X_fake, y_fake)\n        \n        _, acc_real = model.evaluate(X_real, y_real, verbose=0)\n        _, acc_fake = model.evaluate(X_fake, y_fake, verbose=0)\n        \n        print('>%d real=%.0f%% fake=%.0f%%' % (i+1, acc_real*100, acc_fake*100))\n        \nmodel = define_discriminator()\n\ndataset = load_real_samples()\n\ntrain_discriminator(model, dataset) ","84a22a38":"def define_generator(latent_dim):\n    model = Sequential()\n    n_nodes = 256 * 4 * 4 \n    \n    model.add(Dense(n_nodes, input_dim=latent_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((4, 4, 256)))\n    \n    #upsample to 8x8\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #upsample to 16x16\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))  \n    \n    #upsample to 32x32\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2)) \n    \n    model.add(Conv2D(3, (4,4), activation='tanh', padding='same'))\n    \n    return model\n\n\n\nlatent_dim = 100\n\nmodel = define_generator(latent_dim)\n\nplot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)","f768de07":"def generate_latent_points(latent_dim, n_samples):\n    x_input = np.random.randn(latent_dim * n_samples)\n    # reshape into a batch of inputs for the network\n    x_input = x_input.reshape(n_samples, latent_dim)\n    \n    return x_input\n\n\ndef generate_fake_samples(generator, latent_dim, n_samples):\n    x_input = generate_latent_points(latent_dim, n_samples)\n    X = generator.predict(x_input)\n    \n    y = np.zeros((n_samples, 1))\n    \n    return X, y","b12e8e49":"latent_dim = 100\n# define the discriminator model\nmodel = define_generator(latent_dim)\n# generate samples\nn_samples = 25\nX, _ = generate_fake_samples(model, latent_dim, n_samples)\n\nX = (X + 1) \/ 2.0\nplt.figure(figsize=(10, 5))\nfor i in range(n_samples):\n    plt.subplot(5, 5, i+1)\n    plt.axis('off')\n    plt.imshow(X[i])\n\nplt.show()","b5a07a00":"# define the combined generator and discriminator model, for updating the generator\n\ndef define_gan(generator, discriminator):\n    discriminator.trainable = False\n    model = Sequential()\n    \n    model.add(generator)\n    model.add(discriminator)\n    \n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    \n    return model","8863d923":"latent_dim = 100\n\ndiscriminator = define_discriminator()\n\ngenerator = define_generator(latent_dim)\n\ngan_model = define_gan(generator, discriminator)\n\n# plot gan model\nplot_model(gan_model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)","bc956f14":"def save_plot(examples, epoch, n=10):\n  # plot images\n    plt.figure(figsize=(10,5))\n    for i in range(n * n):\n        # define subplot\n        plt.subplot(n, n, 1 + i)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        plt.imshow(examples[i])\n        # save plot to file\n    filename = 'generated_plot_e%03d.png' % (epoch+1) \n    plt.savefig(filename)\n    plt.close()\n\ndef summarize_performance(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):\n    x_real, y_real = generate_real_samples(dataset, n_samples)\n    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n    \n    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)\n    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n\n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n    \n    save_plot(x_fake, epoch)\n    \n    # save plot to file\n    filename = 'generator_model_%03d.h5' % (epoch + 1)\n    generator.save(filename)","748d8a26":"def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=150, n_batch=128):\n    bat_per_epo = int(dataset.shape[0] \/ n_batch)\n    half_batch = int(n_batch \/ 2)\n    \n    for i in range(n_epochs):\n        g_losses, d_losses = list(), list()\n        for j in range(bat_per_epo):\n            X_real, y_real = generate_real_samples(dataset, half_batch)\n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n\n            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n\n            #Train & Update Discriminator weights\n            d_loss, _ = d_model.train_on_batch(X, y)\n\n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n\n            # create inverted labels for the fake samples\n            y_gan = np.ones((n_batch, 1))\n\n            # update the generator via the discriminator's error\n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            \n            g_losses.append(g_loss)\n            d_losses.append(d_loss)\n\n        print('>%d, d=%.3f, g=%.3f' % (i+1, np.mean(d_losses), np.mean(g_losses)))\n        \n        # evaluate the model every n_eval epochs\n        if (i+1) % 10 == 0:\n            summarize_performance(i, g_model, d_model, dataset, latent_dim)","651ec4db":"latent_dim = 100\n\ndiscriminator = define_discriminator()\n\ngenerator = define_generator(latent_dim)\n\ngan_model = define_gan(generator, discriminator)\n\ndataset = load_real_samples()\n\ntrain(generator, discriminator, gan_model, dataset, latent_dim)","e443458c":"PATH = '\/kaggle\/working\/'\n\n\nimg = plt.imread(PATH + '.\/generated_plot_e010.png')\n_ = plt.figure(figsize=(17,7))\n_ = plt.axis('off')\n_ = plt.imshow(img)","5e38e7ae":"img = plt.imread(PATH + '.\/generated_plot_e050.png')\n_ = plt.figure(figsize=(17,7))\n_ = plt.axis('off')\n_ = plt.imshow(img)","d0a9683c":"img = plt.imread(PATH + '.\/generated_plot_e100.png')\n_ = plt.figure(figsize=(17,7))\n_ = plt.axis('off')\n_ = plt.imshow(img)","b804f16b":"img = plt.imread(PATH + '.\/generated_plot_e150.png')\n_ = plt.figure(figsize=(17,7))\n_ = plt.axis('off')\n_ = plt.imshow(img)","2e9998d3":"from keras.models import load_model\n\ndef generate_latent_points(latent_dim, n_samples):\n    \n    x_input = np.random.randn(latent_dim * n_samples)\n    \n    x_input = x_input.reshape(n_samples, latent_dim)\n    \n    return x_input\n                           \ndef show_plot(examples, n):\n  # plot images\n    plt.figure(figsize=(20,10))\n    for i in range(n * n):\n        # define subplot\n        plt.subplot(n, n, 1 + i)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        plt.imshow(examples[i])\n    plt.show()","5c109ad5":"model = load_model('generator_model_150.h5')\n\nlatent_points = generate_latent_points(100, 100) \n\nX = model.predict(latent_points)\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nshow_plot(X, 10)","0de289e0":"<h3>3. After 100 Epochs<\/h3>","6b694b00":"<h3><center>2. Loading & Exploring CIFAR-10 Dataset<\/center><\/h3>","509d9bb0":"<h3><center>5. Train the Discriminator<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nFirst we will train the discriminator model to identify fake and real images by passing batches of fake & real images separately. Y=1 for real images, Y=0 for fake images\n<\/div>","1899b8c4":"<h3><center>4. Generate Samples<\/center><\/h3>","9415c18b":"<h3><center>1. Importing Libraries<\/center><\/h3>","8f9e727a":"<h3><center>Introduction<\/center><\/h3>\n\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\n    Developing a GAN for gener- ating images requires both a discriminator convolutional neural network model for classifying whether a given image is real or generated and a generator model that uses inverse convolutional layers to transform an input to a full two-dimensional image of pixel values.   \n<\/div>\n\n![image.png](attachment:image.png)\n\n<h3>Tutorial Link of \"Detailed working on DCGAN network from scratch\"<\/h3>\n<a href=\"https:\/\/www.kaggle.com\/ashrafkhan94\/tutorial-deep-convolutional-gans-on-mnist?scriptVersionId=55785402\">https:\/\/www.kaggle.com\/ashrafkhan94\/tutorial-deep-convolutional-gans-on-mnist?scriptVersionId=55785402<\/a>","2c1c5898":"<div style=\"font-family:verdana; word-spacing:1.7px;\">\nRunning the example generates 49 examples of fake CIFAR-10 images and visualizes them on a single plot of 5 by 5 images. As the model is not trained, the generated images are completely random pixel values in [-1, 1], rescaled to [0, 1]. As we might expect, the images look like a mess of gray.\n    <\/div>","ce366508":"<h3><center>3. Define the Discriminator Model<\/center><\/h3>","118784f0":"<h3><center>7. Generate points in Latent space.<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nWe have to generate new random points in the latent space. We can achieve this by calling the randn() NumPy function for generating arrays of random numbers drawn from a standard Gaussian.\n    <\/div>","3f1e1088":"<h3>4. After 150 Epochs<\/h3>","3d44ead0":"<h3><center>6. Define and Use the Generator Model<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.7px;\">","949155cd":"<h3><center>8. Train Generator Model.<\/center><\/h3>","75e36eaa":"<h3><center>9. Model Performance<\/center><\/h3>\n<h3>1. After 10 Epochs<\/h3>","aa021b52":"<h3><center>10. Use Final Generator Model<\/center><\/h3>","07a4bbe5":"<h3>2. After 50 EPOCHS<\/h3>"}}