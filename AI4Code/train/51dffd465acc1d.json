{"cell_type":{"6c448de1":"code","66059cb6":"code","3072936a":"code","71dd9cc5":"code","4c139108":"code","027ce965":"code","2410ea9d":"code","4163c0e7":"code","795b10df":"code","d98175f9":"code","2484e5b2":"code","cba1ae75":"code","349380f7":"code","ce93eb54":"code","2d61d54f":"code","170789fb":"code","a902f348":"code","26d86b43":"code","5537206e":"code","169e312c":"code","17d7fbe2":"code","cb0a2abc":"code","50bd058b":"code","afd5eda0":"code","f203d531":"code","0dcd452e":"code","4d09727e":"code","3fa67504":"code","789ffd03":"code","c0bd93a7":"code","b95e9d20":"code","37feb6a8":"code","37fed28e":"code","af2bd7e9":"code","3f7de131":"code","e8e1e00d":"code","ab21b49e":"code","ac35f67d":"code","ab6770f4":"code","72918516":"code","5b509530":"code","54527df6":"code","35423c3b":"code","2731d352":"code","050f4e62":"code","ec9f15e9":"code","a878d8fd":"code","a7fa5a70":"code","3e725a67":"code","7dc0cbf2":"code","ac5e853a":"code","600dcd83":"code","3c7cae43":"code","bd9f0257":"code","de1ed962":"code","ea435fbf":"code","d09f3e86":"code","42888130":"code","5924a224":"code","a80be8ba":"code","fc3051a4":"code","84b097a7":"code","3ac7d75e":"code","30b1bf78":"code","2387f3f3":"code","33d0eff3":"code","2fcad36c":"code","c4625506":"code","ec88383b":"code","7cafaf37":"code","d4c5beec":"code","9d7cf1a3":"code","99686897":"code","97098d29":"code","e94e558d":"code","69af4d2b":"code","2b0a1e17":"code","6e77c858":"code","8690e400":"code","15ea72ff":"code","62c77138":"code","868144c2":"code","71633d6a":"code","e06be681":"code","f68b3813":"code","d26f9ed7":"code","de6a5a5b":"code","e2ba4cbd":"code","73a8f16b":"code","6c91428e":"code","c0ce604c":"code","43b9164b":"code","4983b2d9":"code","afa66981":"code","078892b9":"code","8568f3cf":"code","7ce204c0":"code","d41e224d":"code","91d41fec":"code","8513ecb8":"code","1da10eaf":"code","f86f2456":"code","1d4e0586":"code","7ae4b1a4":"code","11b35937":"code","c6aa8107":"code","9a4624bb":"code","63764590":"code","a1990f5a":"code","32e6a2a8":"code","b0670ce7":"code","e818aa27":"code","8be36340":"code","597303e0":"code","e0d28496":"code","b51cc127":"code","61b3b17a":"code","8a6314dc":"code","c4bf1d31":"code","1b15ee9e":"code","eac7be17":"code","ec8a04a6":"code","8e254c4c":"code","3bf08db1":"code","2ff91a8a":"code","613621db":"code","9b7de585":"code","4cb2c5c3":"markdown","84bbd4f7":"markdown","e00274e0":"markdown","487bba5b":"markdown","c1f700a0":"markdown","4be00bf3":"markdown","f4d54603":"markdown","9321d953":"markdown","9a2bdc72":"markdown","eadc7c6a":"markdown","4fd9ee5b":"markdown","a47878bc":"markdown","593590e3":"markdown","178cff27":"markdown","43c4e0f5":"markdown","8182eb19":"markdown","3b52c441":"markdown","2e85292b":"markdown","48a52ba2":"markdown","d0df7b1f":"markdown","d3d31715":"markdown","9b498886":"markdown","61ef7134":"markdown","69cf9ffe":"markdown","63714481":"markdown","93b53320":"markdown","c9f617a3":"markdown","b7f7d9c3":"markdown","f2675cfa":"markdown","65a86f13":"markdown","dbd71d54":"markdown","83ee8e16":"markdown","ffa9c33a":"markdown","3204e4c4":"markdown","a3693cdd":"markdown","ae6a75f9":"markdown","922aa0a6":"markdown","c8ed36d4":"markdown","0e1f460a":"markdown","991d07cc":"markdown","836ebeab":"markdown","c5dacb4d":"markdown","07a9a0d0":"markdown","fe5f248e":"markdown","e75a90fe":"markdown","dda76922":"markdown","4e09392b":"markdown","5321cc21":"markdown","2afb8ddf":"markdown","27abad28":"markdown","08954b0f":"markdown","47367284":"markdown","803ede65":"markdown","ebe1918e":"markdown","b6de9ec4":"markdown","bb381215":"markdown","c6fd66fd":"markdown","db76e4e4":"markdown","683bf73b":"markdown"},"source":{"6c448de1":"from IPython.display import Image\nprint(\"World Heat Map That Displays Player Distribution by Country\")\nImage(filename='..\/input\/soccer-national-player-prediction\/world_heat_map_player_count_distrubution.png')","66059cb6":"#sources \n#https:\/\/www.kaggle.com\/ajinkyablaze\/football-manager-data\n#https:\/\/www.kaggle.com\/karangadiya\/fifa19\n#https:\/\/footballdatabase.com\/ranking\/world\/1\n#https:\/\/github.com\/python-visualization\/folium\/blob\/master\/examples\/data\/world-countries.json\n\n\nfrom pandas.plotting import scatter_matrix\nfrom time import time\nfrom datetime import datetime  \nfrom datetime import timedelta \nfrom IPython.display import display \n%matplotlib inline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.utils import resample\nfrom sklearn.cluster import KMeans\nimport math \nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom statistics import mean\n\n#https:\/\/github.com\/nalepae\/pandarallel\nfrom pandarallel import pandarallel\npandarallel.initialize(nb_workers=5)\n\n\n# player data from Football Manager 2017 dataset\ndata_fm = pd.read_csv('..\/input\/football-manager-data')\n\n# player data from Fifa 19 dataset\ndata = pd.read_csv('..\/input\/fifa19\/data.csv')\n\n#countries world-countries.json\nworld_countries_json_source = '..\/input\/soccer-national-player-prediction\/world-countries.json'\n\n","3072936a":"import seaborn as sns\nfig, ax = plt.subplots(figsize=(40,40))\nsns.heatmap(data.corr(), annot=True, ax=ax, cmap='BrBG').set(title='Feature Correlation', xlabel='Columns', ylabel='Columns')\nplt.show()","71dd9cc5":"import requests\nfrom bs4 import BeautifulSoup","4c139108":"data_club_rankings = pd.DataFrame(columns=['ranking', 'club', 'country', 'points'])","027ce965":"\n\nclub_data = 4*[None]\n\nfor page_id in range(1,53):\n    link = 'https:\/\/footballdatabase.com\/ranking\/world\/'+str(page_id)\n    print(link)\n    result = requests.get(link)\n    \n    src = result.content\n    soup = BeautifulSoup(src, 'lxml')\n\n    content_rank = soup.find_all('td', attrs={'class':'rank'})\n    content_club_text_left = soup.find_all('td', attrs={'class':'club text-left'})\n\n    for i, e in enumerate(content_club_text_left):\n        club_data[0] = content_rank[i*2].text\n        club_data[1] = e.find_all('a')[0].text\n        club_data[2] = e.find_all('a')[1].text\n        club_data[3] = content_rank[i*2+1].text\n        data_club_rankings.loc[data_club_rankings.shape[0]] = club_data\n        #print(\"ranking: {}  Club: {}  Country: {}  Points: {}\".format(club_data[0], club_data[1], club_data[2], club_data[3]))\n        print(\"{}\".format(club_data[1]))\n","2410ea9d":"len(data.Club.unique())","4163c0e7":"data_club_rankings.head()","795b10df":"# from data to data_club_rankings\ndict_club = {}\nu_clubs = data.Club.unique()\nranked_clubs = list(data_club_rankings.club)\nclubs_not_found = []\n\n# u_club in data,  club in ranked_clubs\nfor u_club in u_clubs:\n    if u_club not in list(ranked_clubs):\n        is_found=False\n        for club in ranked_clubs:\n            condition_A = str(club) in str(u_club)\n            condition_B = str(u_club) in str(club)\n            if condition_A or condition_B:\n                is_found = True\n                dict_club[u_club] = club\n                ranked_clubs.remove(club)\n                break\n        if not is_found:\n            # check longest\n            is_lengest_word_contained = False\n            words_in_u_club = u_club.split(' ')\n            len_words = [len(n) for n in words_in_u_club]\n            np_list_len_words_in_u_club = np.array(len_words)\n            longest_word_in_u_club = words_in_u_club[np_list_len_words_in_u_club.argmax()]\n            for club in ranked_clubs:\n                if longest_word_in_u_club in club:\n                    dict_club[u_club] = club\n                    ranked_clubs.remove(club)\n                    is_lengest_word_contained = True\n                    break\n            if not is_lengest_word_contained:\n                clubs_not_found.append(u_club)\n    else:\n        dict_club[u_club] = u_club\n        ranked_clubs.remove(u_club)","d98175f9":"clubs_not_found[:5]","2484e5b2":"dict_club","cba1ae75":"data_club_rankings[data_club_rankings.club.str.lower().str.contains('bren')]\n#data_club_rankings[data_club_rankings.country=='France']","349380f7":"# correction on dictionary\ndict_club[None] = 'unknown'\ndict_club['Bayer 04 Leverkusen'] = 'Bayer Leverkusen'\ndict_club['PFC CSKA Moscow'] = 'CSKA Moskva'\ndict_club['Tigres U.A.N.L.'] = 'Tigres UANL'\ndict_club['Derby County'] = 'Ross County'\ndict_club['Club Atl\u00e9tico Talleres'] = 'Talleres de Cordoba'\ndict_club['Cear\u00e1 Sporting Club'] = 'Cear\u00e1 SC'\ndict_club['Rionegro \u00c1guilas'] = '\u00c1guilas Doradas'\ndict_club['Am\u00e9rica de Cali'] = 'Am\u00e9rica de Cali'\ndict_club['Central Coast Mariners'] = 'Central Coast Mariners FC'\ndict_club['US Orl\u00e9ans Loiret Football'] = 'unknown'\ndict_club['Jaguares de C\u00f3rdoba'] = 'CD Jaguares'\ndict_club['Oldham Athletic'] = 'unknown'\ndict_club['Notts County'] = 'unknown'\ndict_club['Port Vale'] = 'unknown'\ndict_club['Forest Green Rovers'] = 'unknown'\ndict_club['Inter'] = 'Inter Milan'\ndict_club['Internacional'] = 'Internacional'","ce93eb54":"# adding 'unknown' record to 'data_club_rankings' data frame\nclub_data = [data_club_rankings.shape[0], 'unknown', 'unknown', int(data_club_rankings.points.min())-20]\ndata_club_rankings.loc[data_club_rankings.shape[0]] = club_data","2d61d54f":"starting_position_for_cr_bin = 0\ncr_bin_size = 10\nextension_factor = 1.42\nbin_no = 0\nfor i in range(data_club_rankings.shape[0]):\n    if i == data_club_rankings.shape[0]-1:\n        data_club_rankings.at[i, 'segment_point'] = bin_no+1\n        break\n    if i < starting_position_for_cr_bin + cr_bin_size:\n        data_club_rankings.at[i, 'segment_point'] = bin_no\n    elif i == starting_position_for_cr_bin + cr_bin_size:\n        starting_position_for_cr_bin = i\n        cr_bin_size = int(cr_bin_size * extension_factor)\n        bin_no += 1\n        data_club_rankings.at[i, 'segment_point'] = bin_no\n\nfor i in range(data_club_rankings.shape[0]):\n    data_club_rankings.at[i, 'segment_point'] = data_club_rankings.segment_point.max() - data_club_rankings.segment_point[i]","170789fb":"data_club_rankings.head()","a902f348":"list(data_club_rankings[data_club_rankings.club == 'Inter Milan'].country)[0]","26d86b43":"for i in range(data.shape[0]):\n    match_in_ranked_clubs_df = 'unknown'\n    if data.Club[i] in dict_club:\n        match_in_ranked_clubs_df = dict_club[data.Club[i]]\n    print(\"club: {},  match_in_ranked_clubs_df: {}\".format(data.Club[i], match_in_ranked_clubs_df))\n    cr_segment_point = list(data_club_rankings[data_club_rankings.club == match_in_ranked_clubs_df].segment_point)[0]\n    cr_country = list(data_club_rankings[data_club_rankings.club == match_in_ranked_clubs_df].country)[0]\n    #print(\"club: {},  match_in_ranked_clubs_df: {},  cr_segment_point: {},  cr_country: {}\".format(data.Club[i], match_in_ranked_clubs_df, cr_segment_point, cr_country))\n    data.at[i, 'club_segment_point'] = cr_segment_point\n    data.at[i, 'club_country'] = cr_country\n    ","5537206e":"data.head()","169e312c":"data_fm['national_player'] = data_fm['IntCaps'].map(lambda x: 1 if x>0 else 0)","17d7fbe2":"data['Preferred Foot'].mode()","cb0a2abc":"#First let's drop evidently irrelevant features\ncolumns_to_be_dropped = ['Joined', 'Real Face', 'Photo', 'Flag', 'Club Logo']\ndata = data.drop(columns_to_be_dropped, axis=1)","50bd058b":"number_of_columns_with_null_values = len(data.isnull().any()[data.isnull().any()==True])\nnumber_of_all_columns = len(data.columns)\n\nprint(\"{0} features have null values out of total {1} columns.\".format(number_of_columns_with_null_values, number_of_all_columns))","afd5eda0":"(data.isnull().sum() \/ data.shape[0])[data.isnull().sum() \/ data.shape[0] > 0][:35]","f203d531":"(data.isnull().sum() \/ data.shape[0])[data.isnull().sum() \/ data.shape[0] > 0][35:]","0dcd452e":"data['Height']","4d09727e":"data['ST'].mode()","3fa67504":"# remove \u20ac sign and convert into numeric value K 1000 and M 1.000.000\ndata['Release Clause'].fillna(value='\u20ac0.0K', inplace=True)\ndata['Wage'].fillna(value='\u20ac0.0K', inplace=True)\ndef convert_release_clause_into_numeric(x):\n    x = str(x).replace('\u20ac', '')\n    if 'M' in x:\n        x = x.replace('M', '')\n        x = float(x) * 1000000\n    elif 'K' in x:\n        x = x.replace('K', '')\n        x = float(x) * 1000\n    return x\n\nmonetary_features = ['Release Clause', 'Value', 'Wage']\nfor col in monetary_features:\n    data[col] = data[col].map(convert_release_clause_into_numeric)\n    data[col] = pd.to_numeric(data[col])\n\nfrom numpy import nanmean\ndata['Value'] = data['Value'].apply(lambda x: nanmean(data.groupby('Club')['Value']) if x == None else x)\n\n","789ffd03":"data.dtypes[:10]","c0bd93a7":"# remove lbs expression from weight\ndef remove_lbs(x):\n    x = str(x).replace('lbs', '')\n    return x\n\ndata['Weight'] = data['Weight'].map(remove_lbs)\ndata['Weight'].mode()","b95e9d20":"# remove ' and convert numeric \n# Note: 1 foot height is equal to 12 inches\ndata['Height'].mode()\ndef convert_height_into_numeric(x):\n    integer_part = float(str(x).split('\\'')[0])\n    float_part = 0.0\n    if len(str(x).split('\\'')) > 1:\n        float_part = float(str(x).split('\\'')[1])\/12.0\n    return integer_part + float_part\n\ndata['Height'] = data['Height'].map(convert_height_into_numeric)","37feb6a8":"#remove + sign and sum up both Operand\nmalformed_columns_with_plus_sign = [ 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', \n                                    'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB' ]\ndef remove_plus(x):\n    if '+' in str(x):\n        x0 = float(str(x).split('+')[0])\n        x1 = float(str(x).split('+')[1])\n        return x0+x1\n    return float(x)\nfor col in malformed_columns_with_plus_sign:\n    data[col] = data[col].map(remove_plus)\n\ndata['ST'].mode()","37fed28e":"missing_columns_to_be_assigned_median = [ 'Crossing',\n       'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling',\n       'Curve', 'FKAccuracy', 'LongPassing', 'BallControl', 'Acceleration',\n       'SprintSpeed', 'Agility', 'Reactions', 'Balance', 'ShotPower',\n       'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression',\n       'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure',\n       'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving', 'GKHandling',\n       'GKKicking', 'GKPositioning', 'GKReflexes', 'LS', 'ST', 'RS', 'LW', 'LF',\n       'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', \n       'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB',\n       'Height', 'Weight', 'International Reputation' ]\n\n\nfor col in missing_columns_to_be_assigned_median:\n    data[col].fillna(value=data[col].median(), inplace=True)","af2bd7e9":"missing_columns_to_be_assigned_mode = ['Body Type', 'Contract Valid Until', 'Weak Foot', \n                                       'Jersey Number', 'Preferred Foot', 'Skill Moves', 'Work Rate']\n\nfor col in missing_columns_to_be_assigned_mode:\n    data[col].fillna(value=data[col].mode()[0], inplace=True)","3f7de131":"data['Loaned From'].value_counts()","e8e1e00d":"missing_columns_to_be_assigned_unknown = ['Loaned From', 'Position', 'Club']\n\n\nfor col in missing_columns_to_be_assigned_unknown:\n    data[col].fillna(value='unknown', inplace=True)","ab21b49e":"data.head()","ac35f67d":"data.dtypes[:10]","ab6770f4":"data[data.Value>5000000].groupby(['Nationality'])['ID'].count()['United States']","72918516":"data_heat = data[['Nationality', 'ID', 'Value']]\n#data_heat['player_count_by_country'] = \n\ndict_country_name_from_df_to_follium = {}\ndict_country_name_from_df_to_follium['United States'] = 'United States of America'\ndict_country_name_from_df_to_follium['China PR'] = 'China'\ndict_country_name_from_df_to_follium['Korea Republic'] = 'South Korea'\ndict_country_name_from_df_to_follium['Korea DPR'] = 'North Korea'\ndict_country_name_from_df_to_follium['Bosnia Herzegovina'] = 'Bosnia and Herzegovina'\ndict_country_name_from_df_to_follium['FYR Macedonia'] = 'Macedonia'\ndict_country_name_from_df_to_follium['Central African Rep.'] = 'Central African Republic'\ndict_country_name_from_df_to_follium['Trinidad & Tobago'] = 'Trinidad and Tobago'\ndict_country_name_from_df_to_follium['DR Congo'] = 'Democratic Republic of the Congo'\ndict_country_name_from_df_to_follium['Congo'] = 'Republic of the Congo'\ndict_country_name_from_df_to_follium['England'] = 'United Kingdom'\ndict_country_name_from_df_to_follium['Republic of Ireland'] = 'Ireland'\n\ndata_heat.head(35)\n\n\n\nseries_player_counts = data_heat.groupby(['Nationality'])['ID'].count()\ndata_heat['Value'] = data_heat.Value.astype(float)\n\nnp_array_stats_by_country = np.hstack((np.array(series_player_counts.index), np.array(series_player_counts.values))).reshape(2,-1).T\n\n\ndata_heat = pd.DataFrame(np_array_stats_by_country, columns=['country', 'player_counts_by_country'])\n\ndata.Value = (data.Value).astype(float)\nseries_precious_players_by_country = data[data.Value>5000000].groupby(['Nationality'])['ID'].count()\nseries_precious_players_by_country\n\ndata.Overall = (data.Overall).astype(float)\nseries_average_overall_skill_of_players_by_country = data[data.national_player == 1].groupby(['Nationality'])['Overall'].mean()\nseries_average_overall_skill_of_players_by_country\n\n\n# shrink data logarithmically to obtain a more representative distribution of values through different polars (coumtries)\ndata_heat['precious_player_counts_by_country'] = data_heat['country'].apply(lambda x: series_precious_players_by_country[x] if x in series_precious_players_by_country else 0)\ndata_heat['average_overall_skill_of_players_by_country'] = data_heat['country'].apply(lambda x: series_average_overall_skill_of_players_by_country[x] if x in series_average_overall_skill_of_players_by_country else 0)\n\nprint(data_heat.sort_values(by=['precious_player_counts_by_country'], ascending=False).head(6))\n\ndata_heat['precious_player_counts_by_country'] = data_heat['precious_player_counts_by_country'].apply(lambda x: math.log(x+1) if x+1!=0 else 0.0)\ndata_heat['average_overall_skill_of_players_by_country'] = data_heat['average_overall_skill_of_players_by_country'].apply(lambda x: x**2 if x>0 else x)\n\nprint(data_heat.sort_values(by=['average_overall_skill_of_players_by_country'], ascending=False).head(6))\n\ndata_heat['player_counts_by_country'] = data_heat['player_counts_by_country'].apply(lambda x: math.log(x) if x!=0 else 0.0)\n\n# revise country names and modify if needed based on Folium API\n\ndata_heat['country'] = data_heat['country'].apply(lambda x: dict_country_name_from_df_to_follium[x] if x in dict_country_name_from_df_to_follium.keys() else x)\n\n\nscaler = MinMaxScaler()\nheat_columns = ['player_counts_by_country', 'precious_player_counts_by_country', 'average_overall_skill_of_players_by_country']\n\nfor col in heat_columns:\n    data_heat[col] = scaler.fit_transform(np.array(data_heat[col]).reshape(-1, 1))\n\n#data_heat['average_overall_skill_of_players_by_country'] = data_heat['average_overall_skill_of_players_by_country'].apply(lambda x: math.log(x+1) if x+1!=0 else 0.0)\n\nprint(data_heat.sort_values(by=['average_overall_skill_of_players_by_country'], ascending=False).head(6))\n","5b509530":"data[data.Value>5000000].groupby(['Nationality'])['ID'].count().describe()","54527df6":"import folium\n\nworld_heat_map_player_count_by_country = folium.Map(\n    location=[28.220860, 16.297040],\n    #tiles='Stamen Terrain',\n    zoom_start=1.5\n)\n#  One of the following color brewer palettes: \n# \u2018BuGn\u2019, \u2018BuPu\u2019, \u2018GnBu\u2019, \u2018OrRd\u2019, \u2018PuBu\u2019, \u2018PuBuGn\u2019, \u2018PuRd\u2019, \u2018RdPu\u2019, \u2018YlGn\u2019, \u2018YlGnBu\u2019, \u2018YlOrBr\u2019, and \u2018YlOrRd\u2019\n\nworld_heat_map_player_count_by_country.choropleth(geo_data=world_countries_json_source, data=data_heat, columns=['country', 'player_counts_by_country'], key_on='feature.properties.name',\n                         fill_color='OrRd', fill_opacity=0.7,  line_opacity=0.2, nan_fill_color='black', nan_fill_opacity=0.2)\n\nworld_heat_map_player_count_by_country","35423c3b":"world_heat_map_player_average_market_value_by_country = folium.Map(\n    location=[28.220860, 16.297040],\n    #tiles='Stamen Terrain',\n    zoom_start=1.5\n)\n#  One of the following color brewer palettes: \n# \u2018BuGn\u2019, \u2018BuPu\u2019, \u2018GnBu\u2019, \u2018OrRd\u2019, \u2018PuBu\u2019, \u2018PuBuGn\u2019, \u2018PuRd\u2019, \u2018RdPu\u2019, \u2018YlGn\u2019, \u2018YlGnBu\u2019, \u2018YlOrBr\u2019, and \u2018YlOrRd\u2019\n\nworld_heat_map_player_average_market_value_by_country.choropleth(geo_data=world_countries_json_source, data=data_heat, columns=['country', 'precious_player_counts_by_country'], key_on='feature.properties.name',\n                         fill_color='OrRd', fill_opacity=0.7,  line_opacity=0.2, nan_fill_color='black', nan_fill_opacity=0.2)\n\nworld_heat_map_player_average_market_value_by_country","2731d352":"data.head()","050f4e62":"data.columns","ec9f15e9":"data.Value","a878d8fd":"data.shape","a7fa5a70":"nationalities_in_fifa19 = len(data.Nationality.unique())\nnationalities_in_fm = len(data_fm.NationID.unique())\nprint(\"nationalities_in_fifa19: {0}\\nnationalities_in_fm: {1}\".format(nationalities_in_fifa19, nationalities_in_fm))","3e725a67":"nationality_distribution_fifa = data.Nationality.value_counts()\nsum_nat_55_plus = sum(nationality_distribution_fifa[nationality_distribution_fifa>55])\nno_nat_55_plus = len(nationality_distribution_fifa[nationality_distribution_fifa>55])\ntotal_players = len(data.ID.unique())\nprint(\"The number of nationalities with more than 55 players are {0} and covers {1} players out of {2}\".format(no_nat_55_plus, sum_nat_55_plus, total_players))","7dc0cbf2":"# find the players with similar names and obtain player's full name\ndef find_str(x, name):\n    if name in x:\n        print(x)\n    return x\na = data_fm['Name'].apply(find_str, name='De Bruyne')","ac5e853a":"data[data['Name'].str.contains('De Bruyne')]","600dcd83":"# to display the player to obtain his NationID\n#data_fm[data_fm['Name'] == 'Zhiyi']\ndata_fm[data_fm['Name'].str.contains('De Bruyne')]","3c7cae43":"dict_nationality = {}\ndict_nationality[788] = 'Portugal'\ndict_nationality[1649] = 'Argentina'\ndict_nationality[1651] = 'Brazil'\ndict_nationality[796] = 'Spain'\ndict_nationality[757] = 'Belgium'\ndict_nationality[761] = 'Croatia'\ndict_nationality[795] = 'Slovenia'\ndict_nationality[787] = 'Poland'\ndict_nationality[771] = 'Germany'\ndict_nationality[1657] = 'Uruguay'\ndict_nationality[769] = 'France'\ndict_nationality[776] = 'Italy'\ndict_nationality[16] = 'Egypt'\ndict_nationality[764] = 'Denmark'\ndict_nationality[19] = 'Gabon'\ndict_nationality[801] = 'Wales'\ndict_nationality[41] = 'Senegal'\ndict_nationality[366] = 'Costa Rica'\ndict_nationality[794] = 'Slovakia'\ndict_nationality[784] = 'Netherlands'\ndict_nationality[765] = 'England'\ndict_nationality[759] = 'Bosnia Herzegovina'\ndict_nationality[34] = 'Morocco'\ndict_nationality[802] = 'Serbia'\ndict_nationality[5] = 'Algeria'\ndict_nationality[755] = 'Austria'\ndict_nationality[772] = 'Greece'\ndict_nationality[1652] = 'Chile'\ndict_nationality[797] = 'Sweden'\ndict_nationality[135] = 'Korea Republic'\ndict_nationality[1653] = 'Colombia'\ndict_nationality[22] = 'Guinea'\ndict_nationality[379] = 'Mexico'\ndict_nationality[11] = 'Cameroon'\ndict_nationality[31] = 'Mali'\ndict_nationality[799] = 'Turkey'\ndict_nationality[1435] = 'Australia'\ndict_nationality[24] = 'Ivory Coast'\ndict_nationality[793] = 'Scotland'\ndict_nationality[53] = 'DR Congo'\ndict_nationality[1651] = 'Japan'\ndict_nationality[110] = 'China PR'\ndict_nationality[376] = 'Honduras'\ndict_nationality[791] = 'Russia'\ndict_nationality[789] = 'Republic of Ireland'\ndict_nationality[390] = 'United States'\ndict_nationality[786] = 'Norway'\ndict_nationality[133] = 'Saudi Arabia'\ndict_nationality[798] = 'Switzerland'\ndict_nationality[21] = 'Ghana'\n\n\ndict_nationality","bd9f0257":"data['UID'] = data.shape[0] * [-1]\ndata['national_player'] = data.shape[0] * [None]","de1ed962":"data.head()","ea435fbf":"\n\ndef match_players_from_2_datasets(row):\n    fname = row['Name'].replace('\u0107', 'c').replace('\u010d', 'c').replace('\u0161', 's').replace('\u00ed', 'i')\n    elm = fname.split(' ')\n    length_checker = np.vectorize(len) \n    lenelm = length_checker(elm)\n    shortest_word_in_name = elm[np.where(lenelm == lenelm.min())[0][0]]\n    wanted_name = ''\n    initial = ''\n    \n    \n    if len(shortest_word_in_name)==2 and shortest_word_in_name[1]=='.':\n        initial = shortest_word_in_name[0]\n    \n    \n    if len(elm) > 1 and len(shortest_word_in_name)<3:\n        wanted_name = fname.replace(shortest_word_in_name,'',1)\n    else:\n        wanted_name = fname\n    \n    #trims the white space at the start and end\n    wanted_name = wanted_name.strip()\n    \n    \n    print(\"{0}  >>>  wanted_name: {1}. {2}, row.Age: {3}\".format(row['Unnamed: 0'], initial, wanted_name, row.Age))\n    \n    \n    if wanted_name == '':\n        return row\n    \n    \n    cond_a = (data_fm.Name.str.contains(wanted_name))\n    \n    cond_b = data_fm.shape[0] * [True]\n    \n    if (initial!=''):\n        cond_b = np.array(data_fm.Name.apply(lambda x: str(x).upper())).astype('<U1') == initial\n    cond_c = (abs(row['Age']-data_fm.Age-2) < 2)\n    \n    nationality_contains_list = data_fm.NationID.apply(lambda x: True if x in dict_nationality.keys() and dict_nationality[x] == row['Nationality'] else False)\n    \n    cond_d = data_fm.shape[0] * [True]\n    if row['Nationality'] in dict_nationality.values():\n        cond_d = nationality_contains_list\n    \n    \n    condition = cond_a & cond_b & cond_c & cond_d\n    \n    cond_a = np.array(cond_a, dtype=np.float64)\n    cond_b = np.array(cond_b, dtype=np.float64)\n    cond_c = np.array(cond_c, dtype=np.float64)\n    \n    cond_a_result = (cond_a.astype(float)).sum()\n    cond_b_result = (cond_b.astype(float)).sum()\n    cond_c_result = (cond_c.astype(float)).sum()\n    \n    condition_result = (condition.astype(float)).sum()\n    \n    \n    \n    print(\"CONDITIONS  a: {0}, b: {1}, c: {2}, condition: {3}\".format(cond_a_result, cond_b_result, cond_c_result, condition_result))\n    \n    result_collection = data_fm[condition]\n    \n    np_value = result_collection['national_player']\n    if np_value.shape[0] == 1:\n        row['national_player'] = np_value.iloc[0]\n    uid_value = result_collection['UID']\n    if uid_value.shape[0] == 1:\n        row['UID'] = uid_value.iloc[0]\n        print (\"UID: {0},  national_player: {1}\".format(uid_value.iloc[0], np_value.iloc[0]))\n    else:\n        print(uid_value.shape[0])\n    \n    return row\n\nfrom pandarallel import pandarallel\n\ninitial_date_time = datetime.now()\nprint(\"initial_date_time: {0}\\n\\n\\n\\n\".format(initial_date_time))\n\n\n\nstarttime = time()\n\ndata = data.parallel_apply(match_players_from_2_datasets, axis=1)\n\n\nprint('That took {} seconds'.format(time() - starttime))","d09f3e86":"data.head()","42888130":"(data.isnull().sum() \/ data.shape[0])[data.isnull().sum() \/ data.shape[0] > 0][:45]","5924a224":"data.to_csv(r'fifa19_processed.csv', index = False)","a80be8ba":"data = pd.read_csv('fifa19_processed.csv')","fc3051a4":"data.shape","84b097a7":"data.columns","3ac7d75e":"data = data.dropna(subset=['national_player', 'UID'], how='any').reset_index()","30b1bf78":"data.shape","2387f3f3":"data = data.drop(['Unnamed: 0', 'ID', 'Name', 'UID'], axis=1)","33d0eff3":"data.shape","2fcad36c":"# data_fm\nlabels = 'National Players', 'Not National Players'\nsizes = [data_fm.national_player.value_counts()[1], data_fm.national_player.value_counts()[0]]\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0)  # explode 1st slice\n\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=140)\n\nplt.axis('equal')\nplt.show()\n\ndata_fm.national_player.value_counts()","c4625506":"\n# data\nlabels = 'National Players', 'Not National Players'\nsizes = [data.national_player.value_counts()[1], data.national_player.value_counts()[0]]\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0)  # explode 1st slice\n\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=140)\n\nplt.axis('equal')\nplt.show()\n\ndata.national_player.value_counts()","ec88383b":"import folium\nworld_heat_map_player_average_market_value_by_country = folium.Map(\n    location=[28.220860, 16.297040],\n    #tiles='Stamen Terrain',\n    zoom_start=1.5\n)\n#  One of the following color brewer palettes: \n# \u2018BuGn\u2019, \u2018BuPu\u2019, \u2018GnBu\u2019, \u2018OrRd\u2019, \u2018PuBu\u2019, \u2018PuBuGn\u2019, \u2018PuRd\u2019, \u2018RdPu\u2019, \u2018YlGn\u2019, \u2018YlGnBu\u2019, \u2018YlOrBr\u2019, and \u2018YlOrRd\u2019\n\nworld_heat_map_player_average_market_value_by_country.choropleth(geo_data=world_countries_json_source, data=data_heat, columns=['country', 'average_overall_skill_of_players_by_country'], key_on='feature.properties.name',\n                         fill_color='OrRd', fill_opacity=0.7,  line_opacity=0.2, nan_fill_color='black', nan_fill_opacity=0.2)\n\nworld_heat_map_player_average_market_value_by_country","7cafaf37":"plt.hist(data['Value'])\nplt.xlabel('Market Value of The Players')\nplt.ylabel('Number of The Players')\nplt.show()\n\nplt.hist(data[data.Value > 20000000]['Value'])\nplt.xlabel('Market Value of The Players (Higher Than $20M)')\nplt.ylabel('Number of The Players')\nplt.show()","d4c5beec":"plt.hist(data['Wage'])\nplt.xlabel('Wage of The Players')\nplt.ylabel('Number of The Players')\nplt.show()\n\nplt.hist(data[data.Wage > 100000]['Value'])\nplt.xlabel('Wage of The Players (Higher Than $100K)')\nplt.ylabel('Number of The Players')\nplt.show()","9d7cf1a3":"plt.hist(data['Release Clause'])\nplt.xlabel('Release Clause for The Players')\nplt.ylabel('Number of The Players')\nplt.show()\n\nplt.hist(data[data['Release Clause'] > 2000000]['Release Clause'])\nplt.xlabel('Release Clause for The Players (Higher Than $2M)')\nplt.ylabel('Number of The Players')\nplt.show()","99686897":"# Assign 0 market value and wages as the median of the series. \n# Because, 0 wage is unrealistic and may be misleading\nnumeric_columns_to_be_shrunk = ['Value', 'Wage']\nfor col in numeric_columns_to_be_shrunk:\n    data[col] = data[col].apply(lambda x: data[col].median() if x==0.0 else x)","97098d29":"numeric_columns_to_be_shrunk = ['Value', 'Wage', 'Release Clause']\nfor col in numeric_columns_to_be_shrunk:\n    data[col+'_shrunk'] = data[col].apply(lambda x: math.log(x+0.01))","e94e558d":"data = data.drop(numeric_columns_to_be_shrunk, axis=1)","69af4d2b":"data.head()","2b0a1e17":"plt.hist(data['Value_shrunk'])\nplt.xlabel('Shrunk Market Value of The Players')\nplt.ylabel('Number of The Players')\nplt.show()\n\nplt.hist(data['Wage_shrunk'])\nplt.xlabel('Shrunk Wage of The Players')\nplt.ylabel('Number of The Players')\nplt.show()\n\nplt.hist(data['Release Clause_shrunk'])\nplt.xlabel('Shrunk Release Clause for The Players')\nplt.ylabel('Number of The Players')\nplt.show()","6e77c858":"position_columns = ['LS', 'ST', 'RS', 'LW',\n           'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM',\n           'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB']","8690e400":"data[position_columns].head()","15ea72ff":"for col in position_columns:\n    data[col] = data[col].apply(lambda x: x\/100.0)","62c77138":"from sklearn.cluster import KMeans\n\nX = np.array(data[position_columns])\n\nkmeans = KMeans(n_clusters=11, random_state=0).fit(X)\n\nfor i in range(0, data.shape[0]):\n    data.at[i, 'PositionID'] = kmeans.labels_[i]\n","868144c2":"data.head()","71633d6a":"data.PositionID.value_counts()","e06be681":"columns_for_segment_comparison = ['Value_shrunk', 'Wage_shrunk', 'Release Clause_shrunk']\n\nfor col in columns_for_segment_comparison:\n    for i in range(0, data.shape[0]):\n        data.at[i, 'DistanceToMaxInSegment_'+col] = data.at[i, col] - data[(data.Nationality == data.at[i, 'Nationality']) &  (data.PositionID == data.at[i, 'PositionID'])][col].max()\n        data.at[i, 'DistanceToMedianInSegment_'+col] = data.at[i, col] - data[(data.Nationality == data.at[i, 'Nationality']) &  (data.PositionID == data.at[i, 'PositionID'])][col].median()","f68b3813":"data = data.drop(['index'], axis=1)\ndata.tail()","d26f9ed7":"data.to_csv(r'fifa19_processed2.csv', index = False)","de6a5a5b":"data = pd.read_csv('fifa19_processed2.csv')","e2ba4cbd":"data = data.drop(['International Reputation'], axis=1)","73a8f16b":"data['Weight'].fillna(value=data['Weight'].median(), inplace=True)","6c91428e":"number_of_national_players_by_nation = data.groupby(\"Nationality\").national_player.sum()\ndata['number_of_national_players_by_nation'] = data['Nationality'].apply(lambda x: number_of_national_players_by_nation[x])","c0ce604c":"data.head(3)","43b9164b":"# gather non-numeric columns\nnon_numeric_columns = []\ns = data.dtypes\nfor i in range(0, len(data.dtypes)):\n    e = data.dtypes[i]\n    if e!=float and e!=int:\n        non_numeric_columns.append(s.index[i])\n\nnon_numeric_columns = non_numeric_columns + ['PositionID']\nnon_numeric_columns","4983b2d9":"data['Loaned From'].value_counts()","afa66981":"data.iloc[70:76]","078892b9":"data = pd.get_dummies(data, columns=non_numeric_columns)","8568f3cf":"scaler = MinMaxScaler()\nfor col in data.columns:\n    data[col] = scaler.fit_transform(np.array(data[col]).reshape(-1, 1))","7ce204c0":"data.shape","d41e224d":"\ndata_pos = data[data.national_player == 1.0]\ndata_neg = data[data.national_player == 0.0]\n\nvalidation_spilt_ratio = 0.25\n\ndata_pos_0 = data_pos.sample(frac=validation_spilt_ratio)\ndata_pos_1 = data_pos.drop(data_pos_0.index)\n\ndata_neg_0 = data_neg.sample(frac=validation_spilt_ratio)\ndata_neg_1 = data_neg.drop(data_neg_0.index)\n\ndata_train = pd.concat([data_pos_1, data_neg_1], ignore_index=True)\ndata_train = data_train.sample(frac=1).reset_index(drop=True)\ndata_validation = pd.concat([data_pos_0, data_neg_0], ignore_index=True)\ndata_validation = data_validation.sample(frac=1).reset_index(drop=True)","91d41fec":"data_validation.shape","8513ecb8":"\nX = np.array(data_train.drop(['national_player'], 1)).astype(float)\ny = np.array(data_train['national_player']).astype(float)","1da10eaf":"def up_sample_minority_class(df, random_state, is_future_selection_to_be_made):\n    # Entries of the both minority and majority classes\n    data_majority = df.loc[df['national_player'] == 0.0]\n    data_minority = df.loc[df['national_player'] == 1.0]\n    \n    print(\"data_majority: {0} @ data_minority: {1}\".format(len(data_majority), len(data_minority)))\n    \n    #populates the minority portion of the samples up to the size of majority portion\n    data_minority_up_sampled = resample(data_minority, \n                                     replace=True,\n                                     n_samples=len(data_majority),\n                                     random_state=random_state)\n    \n    # Combine majority class with upsampled minority class\n    data_up_sampled = pd.concat([data_majority, data_minority_up_sampled])\n    \n    # Display new class counts\n    print(data_up_sampled.national_player.value_counts())\n    \n    X_up_sampled = np.array(data_up_sampled.drop(['national_player'], 1).astype(float))\n    y_up_sampled = np.array(data_up_sampled['national_player']).astype(float)\n    \n    if is_future_selection_to_be_made:\n        X_up_sampled = SelectKBest(chi2, k=10).fit_transform(X_up_sampled, y_up_sampled)\n    \n    X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled = train_test_split(X_up_sampled, y_up_sampled, random_state=random_state)\n    \n    return X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled, X_up_sampled, y_up_sampled","f86f2456":"#X = SelectKBest(chi2, k=40).fit_transform(X, y)\n\nX_train, X_test, y_train, y_test, X, y = up_sample_minority_class(data_train, 28, False)\n#train_test_split(X, y, test_size=0.25)","1d4e0586":"\n# Tried Principal Component Analysis to make the calculations faster \n# and see if it improves the performance by any chance\n\n\n# from sklearn.decomposition import PCA\n\n# # feature extraction\n# pca = PCA(n_components=X_train.shape[1]-0)\n# fit = pca.fit(X_train)\n\n# # # summarize components\n# # #print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n# # #print(fit.components_)\n\n# X_train = pca.fit_transform(X_train)\n# X_test = pca.transform(X_test)\n\n\n\n\n\nclf = RandomForestClassifier(max_depth=24, n_estimators=60, n_jobs=-2)\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\n\n\n# threshold = 0.35\n\n# prediction_probablities = clf.predict_proba(X_test)\n# predictions = (prediction_probablities [:,1] >= threshold).astype('float')\n\n\nprint(\"\\nAccuracy Score: {0}\".format(accuracy_score(y_test, predictions)))\nprint(\"Precision Score: {0}\".format(precision_score(y_test, predictions)))\nprint(\"Recall Score: {0}\".format(recall_score(y_test, predictions)))\nprint(\"F-Beta Score: {0}\".format(fbeta_score(y_test, predictions, beta=1.0)))","7ae4b1a4":"\nX_validation = np.array(data_validation.drop(['national_player'], 1)).astype(float)\ny_validation = np.array(data_validation['national_player']).astype(float)\n\n\nX_train_validation, X_test_validation, y_train_validation, y_test_validation, X_validation, y_validation = up_sample_minority_class(data_validation, 145, False)\n#train_test_split(X_validation, y_validation, test_size=0.25)\n#train_test_split(X, y, test_size=0.25)\n\n# print(\"X_test_validation: \"+str(X_test_validation.shape))\n\n\n# X_test_validation = pca.transform(X_test_validation)\n\n# print(\"X_test_validation: \"+str(X_test_validation.shape))\n\n\n\npredictions_validation = clf.predict(X_test_validation)\n\n\nthreshold = 0.33\n\nprediction_probablities_validation = clf.predict_proba(X_test_validation)\npredictions_validation = (prediction_probablities_validation [:,1] >= threshold).astype('float')\n\n\nprint(\"\\nValidation Accuracy Score: {0}\".format(accuracy_score(y_test_validation, predictions_validation)))\nprint(\"Validation Precision Score: {0}\".format(precision_score(y_test_validation, predictions_validation)))\nprint(\"Validation Recall Score: {0}\".format(recall_score(y_test_validation, predictions_validation)))\nprint(\"Validation F-Beta Score: {0}\".format(fbeta_score(y_test_validation, predictions_validation, beta=2.0)))","11b35937":"\nprediction_probablities_validation = clf.predict_proba(X_test_validation)\npredictions_validation = (prediction_probablities_validation [:,1] >= threshold).astype('float')\n\n\nwrongly_predicted_sample_indices = []\nfor i in range(len(predictions_validation)):\n    if predictions_validation[i] != y_test_validation[i]:\n        wrongly_predicted_sample_indices.append(i)\n\nlen(wrongly_predicted_sample_indices)","c6aa8107":"data_y_test_validation = pd.DataFrame(data = y_test_validation[wrongly_predicted_sample_indices], columns = ['national_player']).reset_index()\ndata_X_test_validation = pd.DataFrame(data = X_test_validation[wrongly_predicted_sample_indices], columns = data.drop(['national_player'], axis = 1).columns).reset_index()\ndata_wrongly_predicted = pd.merge(data_X_test_validation, data_y_test_validation, how = 'left', left_index = True, right_index = True).drop(['index_x', 'index_y'], axis=1)","9a4624bb":"data_wrongly_predicted.head()","63764590":"print(\"Age.mean for data_wrongly_predicted: {}, Age.mean for data_validation: {}\"\n      .format(data_wrongly_predicted.Age.mean(), data_validation.Age.mean()))","a1990f5a":"comparison_table = pd.DataFrame(None, columns = ['row_id'] + list(data.columns))","32e6a2a8":"data_wrongly_predicted.name = 'data_wrongly_predicted'\ndata_validation.name = 'data_validation'\n\n\nfor df in [data_wrongly_predicted, data_validation]:\n    s = df.mean()\n    s['row_id'] = df.name + '.mean()'\n    comparison_table = comparison_table.append(s, ignore_index=True)\n\n\nfor df in [data_wrongly_predicted, data_validation]:\n    s = df.sum()\n    s['row_id'] = df.name + '.sum()'\n    comparison_table = comparison_table.append(s, ignore_index=True)","b0670ce7":"i = 4\ncomparison_table.iloc[:,i*20:(i+1)*20]","e818aa27":"\nfor col in comparison_table.columns:\n    if col in ['row_id']:\n        comparison_table.at[4, col] = 'wrong_ratio\/all_ratio'\n        comparison_table.at[5, col] = 'wrong_count\/all_count'\n    elif comparison_table.at[1, col] != 0.0 and comparison_table.at[3, col] != 0.0:\n        comparison_table.at[4, col] = comparison_table.at[0, col] \/ comparison_table.at[1, col]\n        comparison_table.at[5, col] = comparison_table.at[2, col] \/ comparison_table.at[3, col]\n        ","8be36340":"comparison_table[['row_id', 'number_of_national_players_by_nation']]","597303e0":"comparison_table_T = comparison_table.T","e0d28496":"comparison_table_T.head()","b51cc127":"comparison_table_T.columns = list(np.array(comparison_table_T[:1]))[0]","61b3b17a":"comparison_table_T.shape","8a6314dc":"comparison_table_T.head()","c4bf1d31":"comparison_table_T = comparison_table_T.drop(comparison_table_T.index[0])\ncomparison_table_T.head()","1b15ee9e":"comparison_table_T = comparison_table_T.dropna( how='any')","eac7be17":"comparison_table_T.head()","ec8a04a6":"comparison_table_T = comparison_table_T.sort_values(by=['data_wrongly_predicted.sum()'], ascending=False)","8e254c4c":"i=5\ncomparison_table_T.iloc[10*i:10*(i+1),:]","3bf08db1":"contribution_to_wrong_predicitons = 0\ncount = 0\nfor col in comparison_table_T.index:\n    if 'Nationality_' in col and comparison_table_T['wrong_ratio\/all_ratio'][col] > 1.1:\n        print(\"col: {}  ---  {}  ---  {}\".format( col,  comparison_table_T['data_wrongly_predicted.sum()'][col] ,  comparison_table_T['wrong_ratio\/all_ratio'][col] )) \n        contribution_to_wrong_predicitons += comparison_table_T['data_wrongly_predicted.sum()'][col]\n        count = count + 1\n","2ff91a8a":"i=5\ncomparison_table.iloc[:10,15*i:15*(i+1)]","613621db":"data_wrongly_predicted.head()","9b7de585":"#TODO","4cb2c5c3":"#### drop 'International Reputation' to avoid a potential data leakage","84bbd4f7":"### Filling NA values","e00274e0":"### An overview on null and possible problematic values\/features","487bba5b":"# Missing Value Treatment","c1f700a0":"### Manual Correction of Some Wrong Records","4be00bf3":"#### Since the following features are rather characteristic than comparable quantitative values, assigning the median will be meaningless, it is much more accurate to consider them as the most common (mode) value.","f4d54603":"## Feature Creation","9321d953":"### Match Nationality And NationID\n- The data frame 'data' has a string feature named 'Nationality', wgile data frame 'data_fm' has a numeric feature named 'NationID'\n- For this reason, we should first match 'Nationality' and 'NationID' features.","9a2bdc72":"#### Scale data between 0.0 and 1.0 for each feature","eadc7c6a":"## Further Investigation False Prediction Distributions","4fd9ee5b":"## Outlier Treatment","a47878bc":"### Split the data frame into 2 completely separate pieces, shuffle the rows and keep 2nd half for test","593590e3":"#### newly created PositionID feature value distrubution","178cff27":"### Checkpoint - 2\n\nSave current state of the dataset","43c4e0f5":"### Player Counts by Country in 'data'","8182eb19":"### Binning of The Ranked Soccer Clubs\n\n- The clubs will be distributed into different buckets(categories) based on their points, from 14 to 1.\n- The higher the bucket no is the the successful the clubs within are.\n- The capacity of the buckets increases by 1.42 times for each number, so that the better clubs will be in narrower buckets and the unsuccessful clubs will be assigned to geometrically larger buckets relatively.","3b52c441":"- For Instance countries such as China, Saudi Arabia and New Zealand have large number of football players see the map above.      However the players from these countries do not have high market values as much. (see the map below)\n\n- On the other hand, in Western Europe, players are high in number in the data frame 'data' and also top value players are widespread in this region as well.","2e85292b":"## Normalization","48a52ba2":"# What makes a national soccer player, in search within Random Forest","d0df7b1f":"## Overview\n\nIn high school years, I played FIFA, Championship Manager and Football Manager Series quite a bit alongside many strategy games and accomplished this work as a prolongation of my early interests.\n\nThis projects aims to predict  if the soccer players have participated in their national team or not.\nAs  the result, we successfully obtained 94.9% accuracy, 97.8% recall and 95.1% f-beta scores for training set. \n\nAlso we achieved 83.9% accuracy, 89.5% recall and 87.4% f-beta scores for the completely seperate previously unseen validation set.\n\nWith this project, we will use 2 different kaggle dataset as well as additional data which I scraped from a website.\n\nAs usual in the industry, the datasets had a considerable amount of null values, outliers and moreover were in need of various brand new features to be created. So I derived many novel features that I thought could contribute the prediction power of our model, based on my foresight. And those worked indeed and increased the performance metrics by 28-34%.\n\nLastly, this project reflects data with a wide variety of illustrations. At the end of the work, I investigated the wrongly predicted minority of instances and have sought further ways to improve the results.\n\nCaner Bur\u00e7 BA\u015eKAYA","d3d31715":"Flagging them as 'unknown' might be better and may even indicate a common ground between them. Esspecially for club names ('Loaned From', 'Club').","9b498886":"### Considering the following illustration, It is evident that the average skill level of the national players excessively varies from one country to another.\n- ","61ef7134":"### World Heat Map Stats By Country via Folium\n\nLet's generate a heat map and reflect it onto the world map that describes the distrubution of player analytics in terms of different aspects.","69cf9ffe":"### Train model on training set and Display the Performance Matrics","63714481":"## Average Skill Value of National Players By Country","93b53320":"#### Shrunk Feature Histograms","c9f617a3":"# Table Of Contents\n\n\n    \u2022 Title\n        \u25e6 Overview And Results in Advance\n        \u25e6 World Heat Map instance for intro\n        \u25e6 Table Of Contents\n        \u25e6 import libraries and datasets\n        \u25e6 Feature Correlation (heat map)\n        \u25e6 Extract World Club Rankings via Beautiful Soup\n        \u25e6 Matching Club Data\n            \u25aa Manual Correction of Some Wrong Records\n        \u25e6 Binning of The Ranked Soccer Clubs\n        \u25e6 First of all, lets derive our prospective target feature 'national_player' (feature creation)\n        \u25e6 Missing Values Treatment\n            \u25aa An overview on null and possible problematic values\/features\n                \u2022 First let's drop evidently irrelevant features\n                \u2022 Null Value Percentage By Feature\n            \u25aa Handling Missing Data\n                \u2022 Special Cases\n                    \u25e6 remove \u20ac sign and convert into numeric value K 1000 and M 1.000.000\n                    \u25e6 remove lbs expression from weight\n                    \u25e6 remove ' and convert numeric (1 foot == 12 inches)\n                    \u25e6 remove + sign and sum up both Operand\n                \u2022 Filling NA values\n                    \u25e6 missing columns to be assigned as median\n                    \u25e6 missing columns to be assigned as mode\n                    \u25e6 missing columns to be assigned as unknown\n        \u25e6 Let's investigate our data\n            \u25aa World Heat Map Stats By Country via Folium\n                \u2022 Player Counts by Country in 'data'\n                \u2022 Number of Precious Players by Country in 'data' (> &#36;5,000,000)\n        \u25e6 Match players in FIFA 19 dataset with the ones in Football Manager 2017 in order to retrieve national_player feature\n            \u25aa Match Nationality And NationID\n            \u25aa Let's start to build up our nationality dictionary with 50 nations\n            \u25aa Match players from 2 datasets\n        \u25e6 Distribution of the target value (Graphs)\n        \u25e6 Outlier Treatment\n            \u25aa Histograms\n            \u25aa So we will shrink those features via logarithmic function in order to acquire a more meaningful set of values for the training.\n            \u25aa Shrunk Feature Histograms\n        \u25e6 More Feature Creation\n            \u25aa  Creating positionID by utilizing following columns\n            \u25aa Creation of distance of each player's key features from his segment's mean, max and median\n        \u25e6 Checkpoint\n        \u25e6 Normalization\n            \u25aa One Hot Encoder & MinMaxScaler\n        \u25e6 Training The Model\n            \u25aa Split the data frame into 2 completely separate pieces, shuffle the rows and keep 2nd half for test\n            \u25aa Up-Sampling\n            \u25aa Train Set Performance\n            \u25aa Validation Set Performance\n        \u25e6 Further Investigation False Prediction Distributions\n        \u25e6 Conclusion And Findings\n","b7f7d9c3":"#### Since we do not know target value national_player for some instances, we will not able to utilize that portion of the data with null target values neither in training nor in test or validation. So let's better drop them.","f2675cfa":"### Special Cases\n\n- remove \u20ac sign and convert into numeric value K 1000 and M 1.000.000\n- remove lbs expression from weight\n- remove ' and convert numeric (1 foot == 12 inches)\n- remove + sign and sum up both Operand","65a86f13":"## More Feature Creation","dbd71d54":"## Creation of distance of each player's key features from his segment's mean, max and median\n- A player has a value (market value), wage and release clause numeric features which we have already normalized and shrank.\n- That features may indicate the player's importance to his national team.\n- However, each national team has a different player profile at varying skills and importance. While Spain national team has plenty of talents, it is hard to say the same thing for Greenland. Two players with the resambling skills may be indispensible to a middling national team in their squad and may not be in even first 24 for another (top class national team).\n- So the players' metrics should be investigated in the frame of their segment.\n- In this work, segment refers to nationality and position in play of the player.","83ee8e16":"# Training The Model","ffa9c33a":"## Handling Missing Data","3204e4c4":"#### So we will shrink those features via logarithmic function in order to acquire a more meaningful set of values for the training.","a3693cdd":"##### Let's start to build up our nationality dictionary with 50 nations","ae6a75f9":"## Let's investigate our data","922aa0a6":"### One Hot Encoder & MinMaxScaler","c8ed36d4":"#### Thus, 'NationID' 757 corresponds to the 'Nationality' Belgium","0e1f460a":"## Feature Correlation","991d07cc":"### Distribution of the target value\nAs you can see below, data instances in our data frame 'data_fm' are extremely imbalanced and are majorly players with no international caps. The data frame 'data' which is mainly obtained from Fifa 19 data is also imbalanced, although to a lesser extent.\n\nWe will handle later on this imbalance problem via up-sampling.","836ebeab":"## Conclusion And Findings","c5dacb4d":"## Match players in Fifa 19 dataset with the ones in Football Manager 2017 in order to retrieve national_player feature\nTo Achieve this we need additional info such as age and nationality since only names may resemble between players and create conflict.","07a9a0d0":"### Matching Club Data","fe5f248e":"### Number of Precious Players by Country in 'data' (> $5,000,000)","e75a90fe":"### Another Feature Which may contribute to model training: number_of_national_players_by_nation","dda76922":"## Up-Sampling","4e09392b":"### Let's create a comparison table for false predictions to better understand the variation and to detect potantial anomalies","5321cc21":"## Extract World Club Rankings via Beautiful Soup\n\nLater on we will use the world rankings of the soccer clubs to create a brand new feature for our main soccer player dataset, in case this novel additional feature may help the algorithm to sort out the players' relative importance within their segment (the term segment will be defined soon).","2afb8ddf":"#### importing libraries and 2 datasets","27abad28":"### Here is the magical touch","08954b0f":"So we will only define 50 natinalities and their corresponding NationIDs due to limited time. Still it will cover ~ %92.5 of the total players.","47367284":"#### As you can see below, some players have astronomical market values in comparison to other more 'modest' players.\nEven displaying players with market value more than $20 millions, there are outliers and extreme instances.\nSame is valid for 'Wage' and 'Release Clause' features.","803ede65":"### Now, let's derive our prospective target feature 'national_player'.\n- Our brand new feature named 'national_player' will be assigned as 1, if the player played at least 1 international match in his national team and otherwise as 0.","ebe1918e":"## Validation","b6de9ec4":"# A typical unstructured dataset with lots of null and missing values\n\n- so let's get started to mend them all, feature by feature.","bb381215":"### Creating positionID by utilizing following columns","c6fd66fd":"### match players from 2 datasets\n\n- The match_players_from_2_datasets function will match players from data frame 'data' with the data frame 'data_fm' based on their full name, age and nationality info (if exists).\n- Subsequently, we will copy 'national_player' and 'UID' features from 'data_fm' to 'data'.","db76e4e4":"### Checkpoint - 1\n\nSave newly acquired datasets","683bf73b":"### Null Value Percentage By Feature"}}