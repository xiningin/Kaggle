{"cell_type":{"2a0efd8f":"code","e66c95bd":"code","0c792c17":"code","1148ffd1":"code","3ea9ffb6":"code","f7a40a76":"code","f23af323":"code","c0b95ff1":"code","03423154":"code","e415a7af":"code","8e2cc54d":"code","ccd65297":"code","9290ceb2":"code","f6a3035a":"code","d334173e":"code","94d88356":"code","8ba1a35b":"code","460d31c3":"markdown","b58a275e":"markdown","b3e999f4":"markdown","0475adcc":"markdown","0dd30790":"markdown","3bba8172":"markdown","ed1c4dec":"markdown","6af6b66f":"markdown"},"source":{"2a0efd8f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport optuna","e66c95bd":"def read_data(data_dir):\n    train = pd.read_csv(os.path.join(data_dir, 'train.csv'), index_col='id')\n    test = pd.read_csv(os.path.join(data_dir, 'test.csv'), index_col='id')\n    sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'), index_col='id')\n    return train, test, sample_submission","0c792c17":"DAT_DIR = '..\/input\/tabular-playground-series-feb-2021'\ntrain, test, sample_submission = read_data(DAT_DIR)","1148ffd1":"train.describe()","3ea9ffb6":"test.describe()","f7a40a76":"X_train = train.drop(['target'], axis=1)\ny_train = train.target","f23af323":"for c in X_train.select_dtypes(['object']):\n    enc = LabelEncoder()\n    X_train[c] = enc.fit_transform(X_train[c])\n    test[c] = enc.transform(test[c])","c0b95ff1":"valid_pct = 0.3\n\nX_tr, X_va, y_tr, y_va = train_test_split(X_train, y_train, test_size=valid_pct, random_state=123)","03423154":"print(f'X_tr.shape = {X_tr.shape}, X_va.shape = {X_va.shape}, y_tr.shape = {y_tr.shape}, y_va.shape={y_va.shape}')","e415a7af":"def score_dataset(X, y, model=XGBRegressor(), cv_folds=2):\n    # Metric is RMSE (Root Mean Squared Error)\n    score = cross_val_score(\n        model, X, y, cv=cv_folds, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    return score","8e2cc54d":"score = score_dataset(X_train, y_train)\nprint(f'RMSE: = {score:.4f}')","ccd65297":"def objective(trial):\n    xgb_params = dict(\n        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n    )\n    xgb = XGBRegressor(**xgb_params)\n    return score_dataset(X_tr, y_tr, xgb)","9290ceb2":"xgb_params = {'max_depth': 7, \n              'learning_rate': 0.002368706913117573, \n              'n_estimators': 3842, \n              'min_child_weight': 4, \n              'colsample_bytree': 0.6612496396706031, \n              'subsample': 0.6060764549240347, \n              'reg_alpha': 0.18899174723187226, \n              'reg_lambda': 30.33470416661318}","f6a3035a":"final_xgb = XGBRegressor(**xgb_params)\nscore = cross_val_score(final_xgb, X_train, y_train, cv=2, scoring=\"neg_mean_squared_error\")\nprint(f'RMSE: = {np.sqrt(-score.mean()):.4f}')","d334173e":"final_xgb = XGBRegressor(**xgb_params)\nfinal_xgb.fit(X_train, y_train)","94d88356":"y_test = final_xgb.predict(test)","8ba1a35b":"final_submission = pd.Series(y_test, name='target', index=sample_submission.index)\nfinal_submission.to_csv('submission.csv')","460d31c3":"## Baseline Model","b58a275e":"It seems the train and test data are quite similar. Next, let's build a baseline model in XGBoost. But before that, let us split the training data into training and validation.","b3e999f4":"In this notebook, I will explore the [Kaggle Tabular Competition Feb 2021](https:\/\/www.kaggle.com\/c\/tabular-playground-series-feb-2021\/overview).","0475adcc":"## Data exploration","0dd30790":"# Kaggle Tabular Competition Feb 2021 - Baseline","3bba8172":"## Output","ed1c4dec":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=5)\nxgb_params = study.best_params","6af6b66f":"Next, let us do some hyperparameter tuning to see if we can improve the results."}}