{"cell_type":{"5665620f":"code","13b2a9bd":"code","0611744a":"code","b437a1d1":"code","9a495cad":"code","7445760c":"code","3eee7777":"code","ae9df381":"code","3d459000":"markdown","8da0e18a":"markdown","918f4ab3":"markdown","e870af76":"markdown","d246f4f2":"markdown"},"source":{"5665620f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","13b2a9bd":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","0611744a":"#Training data\ntrain_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv') # Import the dataset\ntrain_y = train_data[\"label\"] # Create label vector\ntrain_data.drop([\"label\"], axis=1, inplace=True) # Remove the label vector from the pixel column matrix\ntrain_X = train_data\ntrain_X = train_X.values.reshape(-1, 28, 28, 1)\ntrain_y = train_y.values\ntrain_y = tf.keras.utils.to_categorical(train_y)\n \ntrain_X = train_X\/255.00 # Normalization\n#Test data\ntest_X = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest_X = test_X.values.reshape(-1,28,28,1)\ntest_X = test_X \/ 255.0 # Normalization","b437a1d1":"model = tf.keras.Sequential([\ntf.keras.layers.Conv2D(32, kernel_size = (5,5), padding = 'same', activation ='relu', input_shape = (28,28,1)),   \ntf.keras.layers.Dropout(0.8),\ntf.keras.layers.Conv2D(32, kernel_size = (5,5), padding = 'same', activation ='relu'),\ntf.keras.layers.Dropout(0.8),    \ntf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2),\ntf.keras.layers.Conv2D(32, kernel_size = (5,5), padding = 'same', activation ='relu', input_shape = (28,28,1)),\ntf.keras.layers.Conv2D(32, kernel_size = (5,5), padding = 'same', activation ='relu'),\ntf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2),\ntf.keras.layers.Flatten(),\ntf.keras.layers.Dense(1024, activation = \"relu\"),\ntf.keras.layers.Dense(256, activation = \"relu\"),\ntf.keras.layers.Dense(10, activation = \"softmax\")\n    ])","9a495cad":"model.summary()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])","7445760c":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40, zoom_range=0.2)# Create Data Augmentation (DA) Iterator\ndatagen.fit(train_X) #Our DA Iterator is trained with the image data, to calculate internal statistics\n# Let's add callbacks, which adjust learning rate\nln_fc = lambda x: 1e-3 * 0.985 ** x\nlrng_rt = tf.keras.callbacks.LearningRateScheduler(ln_fc)\n# Fit our CNN-model using the DA Iterator using Flow-method, which feeds batches of augmented data:\ndigitizer = model.fit_generator(datagen.flow(train_X, train_y, batch_size=1024), epochs=80, callbacks=[lrng_rt]) ","3eee7777":"predictions = model.predict(test_X)\npredictions[358]\npred = np.argmax(predictions, axis=1)\n\nplt.imshow(test_X[358][:,:,0],cmap='gray')\nplt.show()\n\npred[358]\n\npred_digits = pd.DataFrame({'ImageId': range(1,len(test_X)+1) ,'Label':pred })\npred_digits.to_csv(\"pre_digits.csv\",index=False)","ae9df381":"predictions = model.predict(test_X)\npredictions[364]\npred = np.argmax(predictions, axis=1)\n\nplt.imshow(test_X[364][:,:,0],cmap='gray')\nplt.show()\n\npred[364]\n\npred_digits = pd.DataFrame({'ImageId': range(1,len(test_X)+1) ,'Label':pred })\npred_digits.to_csv(\"pre_digits.csv\",index=False)","3d459000":"#  DATA PRE-PROCESSING","8da0e18a":"# Develop CNN Model","918f4ab3":"# PREDICTING RESULTS","e870af76":"# Import Libraries","d246f4f2":"# Result"}}