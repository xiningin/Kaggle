{"cell_type":{"c0bb9796":"code","712919d8":"code","64d3d552":"code","322d3c96":"code","d7eb5e68":"code","7ccc94d3":"code","b598ba4c":"code","4654e5f6":"code","9fec56e7":"code","d773ee04":"code","99569f02":"code","b452054f":"code","fa39ff44":"code","02bb8c82":"code","03071ed4":"code","18380114":"code","35f363de":"code","81c03bfd":"code","a4b5fe10":"code","99d72098":"code","b52afb62":"code","f0fcf654":"code","ff9f7019":"code","aa28abd3":"code","6f27044b":"code","74115bc0":"code","e9f79c47":"code","5dcbfb77":"markdown"},"source":{"c0bb9796":"import tensorflow as tf\n#tf.debugging.set_log_device_placement(True)\nprint(tf.__version__)\n\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Dense, Dropout","712919d8":"import matplotlib.pyplot as plt\nimport seaborn as sns","64d3d552":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","322d3c96":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\npd.options.display.float_format = \"{:.4f}\".format","d7eb5e68":"print(\"shape:\", df.shape)","7ccc94d3":"df.columns","b598ba4c":"df.info()","4654e5f6":"df.describe()","9fec56e7":"df.head(10)","d773ee04":"# Sample figsize in inches\nfig, ax = plt.subplots(figsize=(20,10))         \n# Imbalanced DataFrame Correlation\ncorr = df.corr()\nsns.heatmap(corr, cmap='YlGnBu', annot_kws={'size':30}, ax=ax)\nax.set_title(\"Imbalanced Correlation Matrix\", fontsize=14)\nplt.show()","99569f02":"from imblearn.over_sampling import SMOTE","b452054f":"sm = SMOTE(sampling_strategy='minority', random_state=7)","fa39ff44":"resampled_X, resampled_Y = sm.fit_resample(df.drop('Class', axis=1), df['Class'])\noversampled_df = pd.concat([pd.DataFrame(resampled_X), pd.DataFrame(resampled_Y)], axis=1)\noversampled_df.columns = df.columns\noversampled_df['Class'].value_counts()","02bb8c82":"# Sample figsize in inches\nfig, ax = plt.subplots(figsize=(20,10))         \n# Imbalanced DataFrame Correlation\ncorr = oversampled_df.corr()\nsns.heatmap(corr, cmap='YlGnBu', annot_kws={'size':30}, ax=ax)\nax.set_title(\"Imbalanced Correlation Matrix\", fontsize=14)\nplt.show()","03071ed4":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","18380114":"X = oversampled_df.iloc[:, 1:-1].values\ny = oversampled_df.iloc[:, -1].values\ny = y.reshape(-1, 1)\nprint(X.shape, y.shape)\n\nX = sc.fit_transform(X)\nprint(X[0])","35f363de":"x_features = X.shape[1]\ny_features = y.shape[1]\nprint(\"x_features: \", x_features)\nprint(\"y_features: \", y_features)","81c03bfd":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(\"train shapes:\", x_train.shape, y_train.shape)\nprint(\"test shapes:\", x_test.shape, y_test.shape)","a4b5fe10":"adam = tf.keras.optimizers.Adam(learning_rate=0.0005)\n\ni = Input(shape=(x_features,))\nx = Dense(64, activation=\"relu\")(i)\nx = Dense(64, activation=\"relu\")(x)\no = Dense(y_features, activation=\"sigmoid\")(x)\n\nmodel = Model(i,o)\nmodel.compile(loss=\"binary_crossentropy\", metrics=['accuracy'], optimizer=adam)\nmodel.summary()","99d72098":"callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=True\n)\nr = model.fit(x_train, y_train, epochs=100, batch_size=2048, verbose=1, validation_data=(x_test, y_test), callbacks=[callback])","b52afb62":"results = model.evaluate(x_test, y_test, batch_size=5, verbose=1)\nprint(\"Loss: %.2f\" % results[0])\nprint(\"Acc: %.2f\" % results[1])","f0fcf654":"print(r.history.keys())\nplt.plot(r.history['loss'])\nplt.plot(r.history['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","ff9f7019":"plt.plot(r.history['accuracy'])\nplt.plot(r.history['val_accuracy'])\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","aa28abd3":"y_pred = model.predict(x_test)\ny_pred = np.round(y_pred, decimals=0).astype(int)\n#y_pred = np.argmax(y_pred,axis=-1)\n#y_pred = y_pred.astype(int)\ny_pred","6f27044b":"df_pred = pd.concat([pd.DataFrame(x_test), pd.DataFrame(y_test)], axis=1)\ndf_pred.columns = df.drop('Time', axis=1).columns\ndf_pred.rename(columns={\"Class\":\"Old_class\"}, inplace=True)\ndf_pred['New_class'] = y_pred\ndf_pred.head()","74115bc0":"cm = pd.crosstab(df_pred[\"New_class\"], df_pred['Old_class'])\ncm","e9f79c47":"true_pos = np.sum(np.diag(cm))\nfalse_pos = cm[0][1]\nfalse_neg = cm[1][0]\n#tot = np.sum(np.sum(cm, axis=0))\nprecision = true_pos \/ (true_pos + false_pos) * 100\nrecall = true_pos \/ (true_pos + false_neg) * 100\nf1 = 2 * (precision * recall) \/ (precision + recall)\nprint(\"Precision: %.3f%%\" % (precision))\nprint(\"Recall: %.3f%%\" % (recall))\nprint(\"F1: %.3f%%\" % (f1))","5dcbfb77":"Link: https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud"}}