{"cell_type":{"46f3d267":"code","34757080":"code","59f776eb":"code","95d9b65e":"code","cfb5d0f5":"code","1c5a4a67":"code","03c22dfe":"code","7ea068d8":"code","8863dcf6":"code","e2646d49":"code","d2b1255f":"code","af884e53":"code","7e33c63a":"code","f94323df":"code","8804e5af":"code","f35c8cc8":"code","90081fd8":"markdown","4570d467":"markdown","0eb86589":"markdown","13396549":"markdown","9eb84de3":"markdown","62b7831d":"markdown","4f574d6b":"markdown","cedee5a8":"markdown","ec82fcc7":"markdown"},"source":{"46f3d267":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","34757080":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","59f776eb":"data_frame = pd.read_csv('..\/input\/creditcard.csv')\n\nfig, ax = plt.subplots(1,1)\nax.pie(data_frame.Class.value_counts(),explode=(0,0.1), autopct='%1.1f%%', labels = ['Genuine', 'Fraud'], colors=['y','r'])\nplt.axis = 'equal'","95d9b65e":"data_frame_1 = data_frame[data_frame['Class'] == 0]\ndata_frame_2 = data_frame[data_frame['Class'] == 1]\nprint(\"Cases with genuine transaction >> \", len(data_frame_1))\nprint(\"Cases with fraud transaction   >> \", len(data_frame_2)) ","cfb5d0f5":"for i in range(1,29):\n    sns.distplot(data_frame_1.iloc[:,i])\n    sns.distplot(data_frame_2.iloc[:,i], color='r')\n    plt.show()","1c5a4a67":"data_frame_1 = data_frame_1.drop(columns=[\"V8\",\"V13\",\"V15\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\"])\ndata_frame_2 = data_frame_2.drop(columns=[\"V8\",\"V13\",\"V15\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\"])\nprint(data_frame_1.head())\nprint(data_frame_2.head())","03c22dfe":"plot = sns.distplot(data_frame_1[\"Amount\"],color='b', kde=False )\nplot.set_yscale('log')\nplt.xlabel(\"Amount for Genuine cases\")\nplt.show()","7ea068d8":"plot = sns.distplot(data_frame_2[\"Amount\"],color='r', kde=False )\nplot.set_yscale('log')\nplt.xlabel(\"Amount for Fraudlent cases\")\nplt.show()","8863dcf6":"data_frame_final_test_1 = data_frame_2.head(50)\ndata_frame_final_test_0 = data_frame_1.head(2500)\nprint(\"Fraud cases in final test-set\",len(data_frame_final_test_1))\nprint(\"Genuine cases in final test-set\", len(data_frame_final_test_0))\n","e2646d49":"data_frame_train_class_1 = data_frame_2.tail(len(data_frame_2)-50)\ndata_frame_train_class_0 = data_frame_1.tail(len(data_frame_1)-2500)\nprint(\"Fraud cases in training data-set\", len(data_frame_train_class_1))\nprint(\"Genine cases in training data-set\",len(data_frame_train_class_0))","d2b1255f":"training_data_frame = pd.concat([data_frame_train_class_1, data_frame_train_class_0])\ntesting_data_frame = pd.concat([data_frame_final_test_1, data_frame_final_test_0])\n\ndata_x_test = testing_data_frame.drop(columns=['Class'])\ntest_x = data_x_test.values\ntest_y = testing_data_frame['Class'].values\n\ndata_x = training_data_frame.drop(columns=['Class'])\nx = data_x.values\ny = training_data_frame['Class'].values\ncount_0 = 0\ncount_1 = 0\nfor i in range(len(y)):\n    if y[i] == 0:\n        count_0 = count_0 + 1\n    else:\n        count_1 = count_1 + 1\nprint('count_0 in training data-set', count_0)\nprint('count_1 in training data-set', count_1)","af884e53":"from kmeans_smote import KMeansSMOTE\nsm = KMeansSMOTE(imbalance_ratio_threshold=float('Inf'), kmeans_args={'n_clusters':1})\nx_res, y_res = sm.fit_resample(x, y)\ncount_0 = 0\ncount_1 = 0\nfor i in range(len(y_res)):\n    if y_res[i] == 0:\n        count_0 = count_0 + 1\n    else:\n        count_1 = count_1 + 1\nprint('count_0 in training data-set after SMOTE', count_0)\nprint('count_1 in training data-set after SMOTE', count_1)","7e33c63a":"from sklearn.naive_bayes import GaussianNB\nGNB = GaussianNB()\nGNB.fit(x_res, y_res)","f94323df":"y_pred = GNB.predict(test_x)\ny_true = test_y\ny_pred_prob = GNB.predict_proba(test_x)\nprint(\"Predictions for the test-set\")\nprint(y_pred)\nprint(\"True values for the test-set\")\nprint(y_true)\nprint(\"\\n\")\nprint(\"Prediction probability for the test-set\")\nprint(y_pred_prob)\n","8804e5af":"from sklearn.metrics import confusion_matrix\nconfusion_1 = confusion_matrix(y_true, y_pred)\nprint(\"Confusion Matrix for Gaussian NB\")\nprint(\"\")\nprint(confusion_1)","f35c8cc8":"from sklearn.metrics import roc_auc_score,f1_score,precision_score, accuracy_score, recall_score\nroc_auc_score_1 = roc_auc_score(y_true, y_pred)\naccuracy_score_1 = accuracy_score(y_true, y_pred)\nprecision_score_1 = precision_score(y_true, y_pred)\nrecall_score_1 = recall_score(y_true, y_pred)\nf1_score_1 = f1_score(y_true, y_pred)\n\nprint(\"roc_auc_score\", \"%.3f\" %roc_auc_score_1)\nprint(\"accuracy_score\", \"%.3f\" %accuracy_score_1)\nprint(\"precision_score\", \"%.3f\" %precision_score_1)\nprint(\"recall_score\", \"%.3f\" %recall_score_1)\nprint(\"f1_score\", \"%.3f\" %f1_score_1)\n","90081fd8":"The original data_frame is split into two parts data_frame_1 and data_frame_2. data_frame_1 contains cases with class values = 0, and data_frame_2 containes cases with class values = 1. \nFrequency of count_0 in data_frame_1 and count_1 in data_frame_2 is plotted against features V1 to V28. ","4570d467":"From pie-chart, it is observed that the data-set is highly unbalanced, cases with class_0 dominates the data-set. Genuine transaction accounts for 99.8% of the total transactions, while fraudlent transaction accounts only for 0.2%.\n\nIf we train our model on this data-set, the results would be highly biased, skewing heavily towards the class having greater count.","0eb86589":"In this data-set we have 30 features related to credit cards, most of them are hidden except for time and amount. Apart from features \"time\" and \"amount\" we have 28 other features, named from V1 to V28.\n\nBased on these features we have to classify the cases into two parts, the class with genuine transactions (marked with class \"0\" in the data-set) and the class with fraudlent transactions (marked with class \"1\" in the data-set).\n\nModelling here is done using Gaussian Naive Bayes.\n","13396549":"Creating a pie_chart for the number of class_0 values and number of class_1 values.","9eb84de3":"As the data-set is highly unbalanced, dominated with the class values of 0, it is required to oversample the minority class in the training data-set. This oversampling is done with the help SMOTE algorithm. \n\nBut before oversampling the minority class in the training data-set, we segregate a test data-set, which contains 50 cases of class 1 and 2000 cases of class 0. This data-set would be used to measure various performance parameters for Naive Bayes Classification model.\n\n(Note: The training data-set doesn't contain any of the entries from test data-set).","62b7831d":"It can be observed that, frequency distribution for both the classes (\"0\" and \"1\") against features V8, V13, V15, V20, V21, V22, V23, V24, V25, V26, V27 and V28 are approximately similar. These features would most certainly not help out for the purpose of differentiating between class 0 and 1. So, we drop these features from our data_frames so as to make our model less complex.","4f574d6b":"Confusion matrix for the test-data-set showS that out of 50 fraud cases 46 were truly predicted.  ","cedee5a8":"After segregating a training and testing data-set, the minority class in training data-set is oversampled using  kMeansSMOTE.","ec82fcc7":"Naive-Bayes classification model."}}