{"cell_type":{"b3137e84":"code","75b9ebc6":"code","5cc6cc93":"code","8c62ec55":"code","ef5b0765":"code","9bb3dc95":"code","0b2c6508":"code","0c9ebad5":"code","dce1f2c4":"code","e506bd88":"code","4a9078b3":"code","9b24856f":"code","12be0f3d":"code","f3ced555":"code","dcf783dd":"code","7ae7f6b8":"code","36a64313":"code","704c470e":"code","7872c25f":"code","127b1aee":"code","0f09b1fd":"code","5b80d339":"markdown","2dd76b64":"markdown","fe5e58c4":"markdown","40a4409f":"markdown","6952fa4d":"markdown","c30f1218":"markdown","4e83d914":"markdown","42e44864":"markdown"},"source":{"b3137e84":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","75b9ebc6":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom category_encoders import MEstimateEncoder","5cc6cc93":"import warnings\nwarnings.simplefilter(action='ignore')","8c62ec55":"data = pd.read_csv(\"..\/input\/adult-income-dataset\/adult.csv\")\ndata.head()","ef5b0765":"data.columns.array","9bb3dc95":"data.dtypes","0b2c6508":"for col in data.columns:\n    print(col)\n    print(data[col].value_counts(), \"\\n\")","0c9ebad5":"data.describe()","dce1f2c4":"cat_cols = data.select_dtypes('object')\nnum_cols = data.select_dtypes(['int64'])","e506bd88":"for col in cat_cols:\n    sns.countplot(data[col], hue=data[\"income\"])\n    plt.xticks(rotation=90)\n    plt.show()","4a9078b3":"for col in num_cols:\n    f, axis = plt.subplots(1,2, figsize=(20, 5))\n    sns.distplot(data[col], ax=axis[0], kde=True)\n    sns.boxplot(data['income'], data[col], ax=axis[1])\n    plt.show()","9b24856f":"for i,v in enumerate(data.columns.to_list()):\n    data[v].replace(\"?\", np.NaN, inplace=True)","12be0f3d":"data[\"workclass\"].replace(np.NaN, \"Private\", inplace=True)\ndata[\"occupation\"].replace(np.NaN, \"Missing\", inplace=True)\ndata[\"native-country\"].replace(np.NaN, \"United-States\", inplace=True)","f3ced555":"data.isnull().sum()","dcf783dd":"for j, x in enumerate(data.select_dtypes(exclude=['float64','int64']).columns.to_list()): \n    my_dict = { v : i \n                   for i, v in enumerate(data[x].unique(), 0)\n              }\n    data.loc[:, x] = data.loc[:, x].map(my_dict)","7ae7f6b8":"df_train, df_test = train_test_split(data, test_size=0.2, stratify = data['income'])","36a64313":"X_train = df_train.drop(columns=['income'], axis=1)\nX_test = df_test.drop(columns=['income'], axis=1)\n\ny_train = pd.get_dummies(df_train['income'], drop_first=True)\ny_test = pd.get_dummies(df_test['income'], drop_first=True)","704c470e":"for col in X_train.columns:\n    print(col)\n    print(X_train[col].value_counts(), \"\\n\")","7872c25f":"rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=0)\nrf.fit(X_train, y_train)\n\nprint(classification_report(y_test, rf.predict(X_test)))\nprint('Train score : ', f1_score(y_train, rf.predict(X_train)))\nprint('test score : ', f1_score(y_test, rf.predict(X_test)))","127b1aee":"gb = GradientBoostingClassifier(n_estimators=300, max_depth=5,random_state=0)\ngb.fit(X_train, y_train)\n\nprint(classification_report(y_test, gb.predict(X_test)))\nprint('Train score : ', f1_score(y_train, gb.predict(X_train)))\nprint('test score : ', f1_score(y_test, gb.predict(X_test)))","0f09b1fd":"adbc = AdaBoostClassifier(n_estimators=500, random_state=0)\nadbc.fit(X_train, y_train)\n\nprint(classification_report(y_test, adbc.predict(X_test)))\nprint('Train score : ', f1_score(y_train, adbc.predict(X_train)))\nprint('test score : ', f1_score(y_test, adbc.predict(X_test)))","5b80d339":"----","2dd76b64":"## Feature Engineering:","fe5e58c4":"---\n## Model Building:","40a4409f":"---\n- AdaBoost:","6952fa4d":"- Random Forest:","c30f1218":"---\n<center> <h1> EDA <\/h1> <\/center>","4e83d914":"---\n- GB:","42e44864":"- There are a lot of missing values, need to be cleaned and imputed with values."}}