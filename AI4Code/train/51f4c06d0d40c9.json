{"cell_type":{"ee37ce13":"code","4be802ab":"code","272a06d0":"code","d828eb00":"code","d37f59f9":"code","a4b1740a":"code","884ad824":"code","50f68326":"code","cf1a5d95":"code","88b9280a":"code","22d86349":"code","b2fe49d5":"code","66fd5c26":"code","1019689e":"code","4110d5e1":"code","184d6c6f":"code","a9d4fc26":"code","27a0bb18":"code","ed01c6de":"code","efd0f772":"code","fdc51df3":"code","9b5dbfe0":"code","7748d5e1":"code","8f07a97e":"code","d6a2137a":"code","203f6e80":"code","89be03c0":"code","0119d7b9":"code","f512e756":"code","30e5ce81":"code","6ccbf4bb":"code","5d77bea2":"code","fa1c9333":"code","f94e2520":"code","0ace7efd":"code","a174baf0":"code","8f52cb2d":"code","e4002775":"code","1426a7a5":"code","079fff6a":"code","d2ac42f4":"code","f2b6f0bc":"code","166243e3":"code","8fb54274":"code","46b1420a":"code","12a5af20":"code","21b8933d":"code","e8b64196":"code","b2c4bdea":"code","1b23b4d0":"code","ced31ea1":"code","f6ba40e0":"code","8a62108c":"code","ac8040d1":"code","c833f91b":"code","938430eb":"code","4b034b8b":"code","864ac835":"code","16184c80":"code","43dfed44":"markdown","73299027":"markdown","c2824790":"markdown","340c7a8a":"markdown","46aed108":"markdown","ce86ef1c":"markdown","6da38d93":"markdown","ebe7e1f8":"markdown","8ac6f75a":"markdown","d8261ff7":"markdown","4506bd61":"markdown"},"source":{"ee37ce13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4be802ab":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom tqdm import tqdm","272a06d0":"df = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')","d828eb00":"price_df = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")","d37f59f9":"df.head()","a4b1740a":"price_df.head()","884ad824":"cal_df = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")","50f68326":"cal_df.head()","cf1a5d95":"cal_df[\"d\"]=cal_df[\"d\"].apply(lambda x: int(x.split(\"_\")[1]))\nprice_df[\"id\"] = price_df[\"item_id\"] + \"_\" + price_df[\"store_id\"] + \"_validation\"","88b9280a":"cal_df[cal_df[\"d\"]==1858]","22d86349":"cal_df[cal_df[\"d\"]==1886]","b2fe49d5":"for day in tqdm(range(1858, 1886)):\n    wk_id = list(cal_df[cal_df[\"d\"]==day][\"wm_yr_wk\"])[0]\n    wk_price_df = price_df[price_df[\"wm_yr_wk\"]==wk_id]\n    df = df.merge(wk_price_df[[\"sell_price\", \"id\"]], on=[\"id\"], how='inner')\n    df[\"unit_sales_\" + str(day)] = df[\"sell_price\"] * df[\"d_\" + str(day)]\n    df.drop(columns=[\"sell_price\"], inplace=True)","66fd5c26":"df[\"dollar_sales\"] = df[[c for c in df.columns if c.find(\"unit_sales\")==0]].sum(axis=1)","1019689e":"df.drop(columns=[c for c in df.columns if c.find(\"unit_sales\")==0], inplace=True)","4110d5e1":"df[\"weight\"] = df[\"dollar_sales\"] \/ df[\"dollar_sales\"].sum()","184d6c6f":"df.drop(columns=[\"dollar_sales\"], inplace=True)","a9d4fc26":"display(cal_df[cal_df[\"d\"]==1886])\ndisplay(cal_df[cal_df[\"d\"]==1858])","27a0bb18":"df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) <= 1885] +\\\n       [\"id\"]].set_index(\"id\").transpose()","ed01c6de":"complete_historical_mean_df =\\\n    df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) <= 1885] +\\\n       [\"id\"]].set_index(\"id\").transpose().mean().reset_index()","efd0f772":"complete_historical_mean_df.head()","fdc51df3":"# Nothing is always 0\ndf[[c for c in df.columns if c.find(\"d_\")==0]].sum(axis=1).min()","9b5dbfe0":"def find_first_non_0(s):\n    assert type(s) == np.ndarray\n    return (s!=0).argmax(axis=0)","7748d5e1":"non_0_strt_arr = []\nhist_arr = np.array(df[[c for c in df.columns if c.find(\"d_\")==0]])\nfor i in tqdm(range(len(df))):\n    non_0_strt_arr.append(find_first_non_0(hist_arr[i, :]))","8f07a97e":"df.head(1)","d6a2137a":"test = list(df[[c for c in df.columns if c.find(\"d_\")==0] +\\\n                [\"id\"]].set_index(\"id\").transpose()[\"HOBBIES_1_001_CA_1_validation\"])","203f6e80":"print(\"Supposedly first non-zero value equals:\", test[non_0_strt_arr[0]], \n      \"on the\", non_0_strt_arr[0], \"day\",\n     \"\\nSum of all values before the supposedly first non-zero value is:\", \n     sum(test[: non_0_strt_arr[0]]),\n     \"\\nSum of all values after the supposedly first non-zero value is:\", \n     sum(test[non_0_strt_arr[0]:]))","89be03c0":"num_non_zero = 1885 - np.array(non_0_strt_arr)","0119d7b9":"non_zero_historical_mean_arr = np.array(df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) <= 1885] +\\\n   [\"id\"]].set_index(\"id\").transpose().sum().reset_index()[0]) \/ num_non_zero","f512e756":"# days 1886 to 1913 are local test weeks\nfor d in range(1, 29):\n    df[\"F_1_\" + str(1885+d)] = list(complete_historical_mean_df[0])\n    df[\"F_2_\" + str(1885+d)] = non_zero_historical_mean_arr","30e5ce81":"method_dict = {1: \"complete historical mean\", 2: \"historical mean after first non-zero\"}","6ccbf4bb":"num_non_zero.min()","5d77bea2":"historical_mean_df10 =\\\n    df[[c for c in df.columns if c.find(\"d_\")==0 and\\\n        int(c.split(\"_\")[1]) in range(1876, 1886)] +\\\n       [\"id\"]].set_index(\"id\").transpose().mean().reset_index()\n\nhistorical_mean_df20 =\\\n    df[[c for c in df.columns if c.find(\"d_\")==0 and\\\n        int(c.split(\"_\")[1]) in range(1866, 1886)] +\\\n       [\"id\"]].set_index(\"id\").transpose().mean().reset_index()\n\nhistorical_mean_df30 =\\\n    df[[c for c in df.columns if c.find(\"d_\")==0 and\\\n        int(c.split(\"_\")[1]) in range(1856, 1886)] +\\\n       [\"id\"]].set_index(\"id\").transpose().mean().reset_index()\n\nhistorical_mean_df40 =\\\n    df[[c for c in df.columns if c.find(\"d_\")==0 and\\\n        int(c.split(\"_\")[1]) in range(1846, 1886)] +\\\n       [\"id\"]].set_index(\"id\").transpose().mean().reset_index()","fa1c9333":"# days 1886 to 1913 are local test weeks\nfor d in range(1, 29):\n    df[\"F_3_\" + str(1885+d)] = list(historical_mean_df10[0])\n    df[\"F_4_\" + str(1885+d)] = list(historical_mean_df20[0])\n    df[\"F_5_\" + str(1885+d)] = list(historical_mean_df30[0])\n    df[\"F_6_\" + str(1885+d)] = list(historical_mean_df40[0])","f94e2520":"method_dict[3] = \"historical mean of recent 10 days\"\nmethod_dict[4] = \"historical mean of recent 20 days\"\nmethod_dict[5] = \"historical mean of recent 30 days\"\nmethod_dict[6] = \"historical mean of recent 40 days\"","0ace7efd":"for d in range(1, 29):\n    df[\"F_7_\" + str(1885 + d)] = df[\"d_\" + str(1885 + d - 28)]","a174baf0":"method_dict[7] = \"same as last 28 days\"","8f52cb2d":"display(cal_df[cal_df[\"d\"]==1886])\ndisplay(cal_df[cal_df[\"d\"]==1886 - 364])","e4002775":"denominator = [(num \/\/ 364) if (num \/\/ 364) > 0 else 1 for num in num_non_zero]\nfor d in range(1, 29): \n    df[\"F_8_\" + str(1885 + d)] = (df[\"d_\" + str(1885 + d - 364*1)]+\\\n                                  df[\"d_\" + str(1885 + d - 364*2)]+\\\n                                  df[\"d_\" + str(1885 + d - 364*3)]+\\\n                                  df[\"d_\" + str(1885 + d - 364*4)]+\\\n                     df[\"d_\" + str(1885 + d - 364*5)]) \/ denominator","1426a7a5":"method_dict[8] = \"average of same day in historical years\"","079fff6a":"agg_df = pd.DataFrame(df[[c for c in df.columns if c.find(\"d_\") == 0 or c.find(\"F_\") == 0]].sum()).transpose()\nagg_df[\"level\"] = 1\nagg_df[\"weight\"] = 1\/12\ncolumn_order = agg_df.columns","d2ac42f4":"agg_df","f2b6f0bc":"level_groupings = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n              6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], 9: [\"store_id\", \"dept_id\"],\n              10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}","166243e3":"for level in tqdm(level_groupings):\n    temp_df = df.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n    temp_df[\"level\"] = level\n    temp_df[\"weight\"] \/= 12\n    agg_df = agg_df.append(temp_df[column_order])\n\ndel temp_df","8fb54274":"df[\"weight\"] \/= 12","46b1420a":"print(df.shape[0], agg_df.shape[0], df.shape[0] + agg_df.shape[0])","12a5af20":"agg_df[\"weight\"].sum() + df[\"weight\"].sum()","21b8933d":"h = 28\nn = 1885\ndef rmsse(ground_truth, forecast, train_series, axis=1):\n    # assuming input are numpy array or matrices\n    assert axis == 0 or axis == 1\n    assert type(ground_truth) == np.ndarray and type(forecast) == np.ndarray and type(train_series) == np.ndarray\n    \n    if axis == 1:\n        # using axis == 1 we must guarantee these are matrices and not arrays\n        assert ground_truth.shape[1] > 1 and forecast.shape[1] > 1 and train_series.shape[1] > 1\n    \n    numerator = ((ground_truth - forecast)**2).sum(axis=axis)\n    if axis == 1:\n        denominator = 1\/(n-1) * ((train_series[:, 1:] - train_series[:, :-1]) ** 2).sum(axis=axis)\n    else:\n        denominator = 1\/(n-1) * ((train_series[1:] - train_series[:-1]) ** 2).sum(axis=axis)\n    return (1\/h * numerator\/denominator) ** 0.5","e8b64196":"train_series_cols = [c for c in df.columns if c.find(\"d_\") == 0][:-28]\nground_truth_cols = [c for c in df.columns if c.find(\"d_\") == 0][-28:]\n\nforecast_cols_dict = {}\nfor i in range(1, 9):\n    forecast_cols_dict[i] = [c for c in df.columns if c.find(\"F_\"+str(i)+\"_\") == 0]","b2c4bdea":"for i in range(1, 9):\n    df[\"rmsse_\" + str(i)] = rmsse(np.array(df[ground_truth_cols]), \n        np.array(df[forecast_cols_dict[i]]), np.array(df[train_series_cols]))\n    agg_df[\"rmsse_\" + str(i)] = rmsse(np.array(agg_df[ground_truth_cols]), \n        np.array(agg_df[forecast_cols_dict[i]]), np.array(agg_df[train_series_cols]))","1b23b4d0":"for i in range(1, 9):\n    df[\"wrmsse_\" + str(i)] = df[\"weight\"] * df[\"rmsse_\" + str(i)]\n    agg_df[\"wrmsse_\" + str(i)] = agg_df[\"weight\"] * agg_df[\"rmsse_\" + str(i)]","ced31ea1":"for i in range(1, 9):\n    print(\"method:\", method_dict[i])\n    print(df[\"wrmsse_\" + str(i)].sum() + agg_df[\"wrmsse_\" + str(i)].sum())\n    print()","f6ba40e0":"sample_sub = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sample_submission.csv\")","8a62108c":"sample_sub.head()","ac8040d1":"sample_sub.tail()","c833f91b":"(sample_sub[\"id\"][:len(df)] == df[\"id\"]).all()","938430eb":"submit_df = df[[\"id\"]]\nfor i in range(1, 29):\n    submit_df[\"F\" + str(i)] = df[\"F_7_\" + str(1885 + i)]","4b034b8b":"submit_df2 = submit_df.copy()\nsubmit_df2[\"id\"] = submit_df2[\"id\"].apply(lambda x: x.replace('validation',\n                                                              'evaluation'))","864ac835":"submit_df = submit_df.append(submit_df2).reset_index(drop=True)","16184c80":"submit_df.to_csv(\"submission.csv\", index=False)","43dfed44":"## 0. Import libraries and read in data","73299027":"### Same as previous 28 days","c2824790":"### Mean of recent x days","340c7a8a":"## 2. Use the naive logic to make forecasts for each of the level 12 series\n- All 0s\n- Average through all history\n- Mean of previous 10, 20, 30, 40, 50, 60 days\n- Same as previous 28 days\n- Average of same day for all previous weeks","46aed108":"\t1. Calculate weight for the level 12 series\n\t2. Use the naive logic to make forecasts for each of the level 12 series\n\t3. Infer forecast, ground truth values, and weights for all the higher level series by aggregating\n\t4. Calculalte RMSSE for all series using the equation\n\t5. Multiply weight by respective RMSSE and add all these products","ce86ef1c":"## 1. Calculate weight for the level 12 series","6da38d93":"### Mean of history","ebe7e1f8":"## 3. Infer forecast, ground truth values, and weights for all the higher level series by aggregating","8ac6f75a":"## 4. Calculalte RMSSE for all series using the equation","d8261ff7":"### Historical averages from same day of the year","4506bd61":"## Make submission file"}}