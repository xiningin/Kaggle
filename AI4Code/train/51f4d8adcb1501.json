{"cell_type":{"f7a2ffbc":"code","bc0f894d":"code","d45b9a34":"code","15fa1a14":"code","59f67b1c":"code","576c4432":"code","e7572012":"code","4746793d":"code","b150edfb":"code","2d717368":"code","6fdd22be":"code","ca09c56c":"code","38d8e9b4":"code","75c9a864":"code","92d2e5b3":"code","2f4f87eb":"code","87523a30":"code","250b5a71":"code","aa08c094":"code","c194cb01":"code","96353037":"code","a29fb7b1":"code","53d35b99":"code","3e8d023c":"code","2aea4b1a":"code","3dce98c2":"code","f9dca24b":"code","b1f6cf7a":"code","e5960dae":"code","a3f610a1":"code","619ad443":"code","7a232e6d":"code","abe59d84":"code","a75292f8":"code","a9f43d0e":"code","df263452":"code","368de58d":"code","0c51679e":"markdown","418f72c3":"markdown","f3c979ab":"markdown","46fd2eb6":"markdown","31383a44":"markdown","bcceffc3":"markdown","840d2e82":"markdown","74140b49":"markdown","6f4b47eb":"markdown","dadad133":"markdown","3b49f39c":"markdown","7986e2de":"markdown","c6e853e6":"markdown","a99e66c0":"markdown","bc8ee7e6":"markdown","7072a441":"markdown","b807803d":"markdown","def9c0c3":"markdown","37342906":"markdown","3abbbe0a":"markdown","13c4f767":"markdown","d1fa6ae0":"markdown","a6760a1b":"markdown","eb32bc23":"markdown","f9e4b346":"markdown"},"source":{"f7a2ffbc":"# Check nvcc version\n!nvcc -V\n# Check GCC version\n!gcc --version","bc0f894d":"import torch","d45b9a34":"%%time\n\nprint(\"this will take around 9 mins\")\n# install dependencies: (use cu101 because colab has CUDA 10.1)\n# !pip install -U torch==1.7.0+cu101 torchvision==0.6.1+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n\n# install mmcv-full thus we could use CUDA operators\n!pip install mmcv-full\n\n\n","15fa1a14":"!rm -rf mmdetection\n!git clone --branch master https:\/\/github.com\/open-mmlab\/mmdetection.git\n%cd mmdetection\n\n!pip install -e .\n\n# install Pillow 7.0.0 back in order to avoid bug in colab\n!pip install Pillow==7.0.0","59f67b1c":"# Check Pytorch installation\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\n# Check MMDetection installation\nimport mmdet\nprint(mmdet.__version__)\n\n# Check mmcv installation\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())","576c4432":"!mkdir checkpoints\n# !wget -c https:\/\/openmmlab.oss-cn-hangzhou.aliyuncs.com\/mmdetection\/v2.0\/vfnet\/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco\/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth \\\n#       -O checkpoints\/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth","e7572012":"# from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\n# # Choose to use a config and initialize the detector\n# config = 'configs\/vfnet\/vfnet_r2_101_fpn_mdconv_c3-c5_mstrain_2x_coco.py'\n# # Setup a checkpoint file to load\n# checkpoint = 'checkpoints\/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth'\n# # initialize the detector\n# model = init_detector(config, checkpoint, device='cuda:0')","4746793d":"# # Use the detector to do inference\n# img = 'demo\/demo.jpg'\n# result = inference_detector(model, img)","b150edfb":"# # Let's plot the result\n# show_result_pyplot(model, img, result, score_thr=0.3)","2d717368":"import os\n\nos.listdir('.\/configs\/vfnet')","6fdd22be":"from mmcv import Config\n# cfg = Config.fromfile('.\/configs\/faster_rcnn\/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')\ncfg = Config.fromfile('.\/configs\/vfnet\/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco.py')\n","ca09c56c":"print(f'Config:\\n{cfg.pretty_text}')","38d8e9b4":"from mmdet.apis import set_random_seed\n\n# dataset_dir = '..\/vinbigdata-cocodataset\/vinbigdata-coco-dataset-3xdownsampled'\ndataset_dir = '\/kaggle\/input\/vinbigdatacocodatasetwbf3xdownsampled\/vinbigdata-coco-dataset-with-wbf-3xdownsampled_fold0'\n\ncfg.dataset_type = 'CocoDataset'\ncfg.classes = (\"Aortic_enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\", \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung_Opacity\", \"Nodule\/Mass\", \"Other_lesion\", \"Pleural_effusion\", \"Pleural_thickening\", \"Pneumothorax\", \"Pulmonary_fibrosis\")\n\ncfg.data.train.img_prefix = f'{dataset_dir}\/'\ncfg.data.train.classes = cfg.classes\ncfg.data.train.ann_file = f'{dataset_dir}\/train_annotations.json'\ncfg.data.train.type='CocoDataset'\n\n\ncfg.data.val.img_prefix = f'{dataset_dir}\/'\ncfg.data.val.classes = cfg.classes\ncfg.data.val.ann_file = f'{dataset_dir}\/val_annotations.json'\ncfg.data.val.type='CocoDataset'\n\n\n\ncfg.data.test.img_prefix = f'{dataset_dir}\/'\ncfg.data.test.classes = cfg.classes\ncfg.data.test.ann_file = f'{dataset_dir}\/val_annotations.json'\ncfg.data.test.type='CocoDataset'\ncfg.data.samples_per_gpu = 4\n\n# Train pipeline\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    # dict(type=\"Shear\", level=0),\n    dict(type=\"Rotate\", level=0, max_rotate_angle=10),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ncfg.model.bbox_head.num_classes = 14\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.val.type = 'CocoDataset'\ncfg.data.test.type = 'CocoDataset'\n\ncfg.optimizer.lr = 0.0032\n# cfg.lr_config.warmup = None\ncfg.log_config.interval = 4\n\n# Change the evaluation metric since we use customized dataset.\ncfg.evaluation.metric = 'bbox'\n# We can set the evaluation interval to reduce the evaluation times\ncfg.evaluation.interval = 4\n# We can set the checkpoint saving interval to reduce the storage cost\ncfg.checkpoint_config.interval = 4\n\n# Set seed thus the results are more reproducible\ncfg.seed = 42\nset_random_seed(42, deterministic=False)\ncfg.gpu_ids = range(1)\n\n# we can use here mask_rcnn.\n# cfg.load_from = '.\/mmdetection_checkpoints\/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth'\ncfg.load_from = '\/kaggle\/input\/vinbigdata-final-models\/vfnet_r101_fold0_v3_epoch4.pth'\ncfg.work_dir = \"\/kaggle\/working\/vinbig_output\"\n\n# One Epoch takes around 18 mins\ncfg.runner.max_epochs = 16\n# cfg.total_epochs = 24","75c9a864":"print(f'Config:\\n{cfg.pretty_text}')","92d2e5b3":"# the dataset has been taken : https:\/\/www.kaggle.com\/sreevishnudamodaran\/vinbigdata-fusing-bboxes-coco-dataset\nimport os\n# dataset_dir = '..\/..\/input\/vinbigdatacocodatasetwithwbf512\/vinbigdata-coco-dataset-with-wbf-512'\n# os.listdir(f\"{dataset_dir}\")\nos.listdir(\"\/kaggle\/input\/vinbigdatacocodatasetwbf3xdownsampled\/vinbigdata-coco-dataset-with-wbf-3xdownsampled\")","2f4f87eb":"# for saving checkpoint and plots\nimport os\nos.makedirs('\/kaggle\/working\/vinbig_output')","87523a30":"from mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector","250b5a71":"# model = build_detector(\n#         cfg.model,\n#         train_cfg=cfg.get('train_cfg'),\n#         test_cfg=cfg.get('test_cfg'))","aa08c094":"# datasets = [build_dataset(cfg.data.train)]","c194cb01":"# # cfg.lr_config.policy='step'\n# train_detector(model, datasets, cfg, distributed=False, validate=True)","96353037":"from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\ncheckpoint = '\/kaggle\/input\/vinbigdata-final-models\/vfnet_r101_fold0_v3_epoch4.pth'\nmodel = init_detector(cfg, checkpoint, device='cuda:0')\nmodel.CLASSES = ['Aortic_enlargement', 'Atelectasis', 'Calcification',\n                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n                 'Lung_Opacity', 'Nodule\/Mass', 'Other_lesion',\n                 'Pleural_effusion', 'Pleural_thickening', 'Pneumothorax',\n                 'Pulmonary_fibrosis']\n# img = ['..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/0a1addecfc432a1b425d61fe57bc29d2.jpg', '..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/abe3e3c83a7dc58474450b601e20cffb.jpg', '..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/0a1addecfc432a1b425d61fe57bc29d2.jpg', '..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/abe3e3c83a7dc58474450b601e20cffb.jpg']\n# img = ['..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/abe3e3c83a7dc58474450b601e20cffb.jpg']\nimg = ['\/kaggle\/input\/vinbigdata-competition-jpg-data-3x-downsampled\/test\/test\/b461cd28bc17c294dd986d0d91577ac3.jpg']\n# ..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/b461cd28bc17c294dd986d0d91577ac3.jpg\n# result = inference_detector(model, img)","a29fb7b1":"# Let's plot the result\n# test_img = mmcv.imread(img[0])\n# print(test_img.shape)\nresult = inference_detector(model, img)\nshow_result_pyplot(model, img[0], result[0], score_thr=0.01)","53d35b99":"print(result[0][0]) # x_min, y_min, x_max, y_max, prob","3e8d023c":"!pip install ensemble_boxes","2aea4b1a":"from ensemble_boxes import *","3dce98c2":"def nms_one_img(preds, img_path, img_width, img_height):\n    # print('img width:', img_width)\n    # print('img height:', img_height)\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    weights = [1]\n    # print(preds)\n    for i, pred in enumerate(preds):\n        if len(pred):\n            for p in pred:\n                box = [0, 0, 0, 0]\n                box[0] = min(1.0, p[0] \/ img_width)\n                box[1] = min(1.0, p[1] \/ img_height)\n                box[2] = min(1.0, p[2] \/ img_width)\n                box[3] = min(1.0, p[3] \/ img_height)\n                # print(box)\n                for b in box:\n                    if b > 1:\n                        print(img_path)\n                boxes_list.append(box)\n                score = p[4].astype(float)\n                scores_list.append(score)\n                labels_list.append(i)\n    # print('Before:')\n    # print(boxes_list)\n    boxes_list, scores_list, labels_list = nms([boxes_list], [scores_list], [labels_list], weights=weights, iou_thr=0.5)\n    # print('After:')\n    # print(boxes_list)\n    return boxes_list, scores_list, labels_list","f9dca24b":"import mmcv\n\nimg = mmcv.imread('\/kaggle\/input\/vinbigdata-competition-jpg-data-3x-downsampled\/test\/test\/b461cd28bc17c294dd986d0d91577ac3.jpg')\nimg.shape","b1f6cf7a":"def infer_img(model, img_path):\n    img = mmcv.imread(img_path)\n    result = inference_detector(model, img_path)\n    boxes_list, scores_list, labels_list = nms_one_img(result, img_path, img.shape[1], img.shape[0])\n    return boxes_list, scores_list, labels_list","e5960dae":"boxes_list, scores_list, labels_list = nms_one_img(result[0], '', 675, 800)\nprint(len(labels_list))","a3f610a1":"def convert_to_df_row_list(img_id, boxes_list, scores_list, labels_list):\n    res = []\n    res.append(img_id)\n    prediction_string = ''\n    for i, label in enumerate(labels_list):\n        prediction_string += str(int(label))\n        prediction_string += ' '\n        prediction_string += str(round(float(scores_list[i]), 3))\n        prediction_string += ' '\n        prediction_string += str(boxes_list[i][0]) + ' ' + str(boxes_list[i][1]) + ' ' + str(boxes_list[i][2]) + ' ' + str(boxes_list[i][3]) + ' '\n    res.append(prediction_string.rstrip())\n    return res","619ad443":"import pandas as pd\n\nsubmission_list = []\ntest_dir = '\/kaggle\/input\/vinbigdata-competition-jpg-data-3x-downsampled\/test\/test\/'\ntest_df = pd.read_csv('\/kaggle\/input\/vinbigdata-1024-image-dataset\/vinbigdata\/test.csv')\n\nfor img_name in os.listdir('\/kaggle\/input\/vinbigdata-competition-jpg-data-3x-downsampled\/test\/test'):\n    if '.jpg' in img_name:\n        img_path = test_dir + img_name\n        # boxes_list, scores_list, labels_list = infer_img(model, '..\/vinbigdata-cocodataset\/ori_vinbigdata_3xdownsampled\/test\/test\/b461cd28bc17c294dd986d0d91577ac3.jpg')\n        boxes_list, scores_list, labels_list = infer_img(model, img_path)\n        img_id = img_name[:len(img_name) - 4]\n        ori_img_width = test_df[test_df.image_id == img_id]['width'].iloc[0]\n        ori_img_height = test_df[test_df.image_id == img_id]['height'].iloc[0]\n        boxes_list[:, 0] = boxes_list[:, 0] * ori_img_width\n        boxes_list[:, 2] = boxes_list[:, 2] * ori_img_width\n        boxes_list[:, 1] = boxes_list[:, 1] * ori_img_height\n        boxes_list[:, 3] = boxes_list[:, 3] * ori_img_height\n        df_row_lst = convert_to_df_row_list(img_id, boxes_list, scores_list, labels_list)\n        submission_list.append(df_row_lst)","7a232e6d":"print(len(submission_list))","abe59d84":"submission_df = pd.DataFrame(submission_list, columns=['image_id', 'PredictionString'])\nsubmission_df.head(20)","a75292f8":"submission_df.to_csv('\/kaggle\/working\/vinbig_output\/vfnet_r101_fold0_v3_epoch4_submission.csv', index=False)","a9f43d0e":"os.chdir('..\/')\n","df263452":"# !python mmdetection\/tools\/analyze_logs.py plot_curve .\/vinbig_output\/None.log.json --keys loss_cls --legend loss_cls --out \"loss_cls\"","368de58d":"!rm -rf \".\/mmdetection\"","0c51679e":"# Prereq: MMCV(~9 mins)","418f72c3":"# Version\n\n* `v8`: vfnet_r101_fold0_v3_epoch4.pth\n* `v7`: vfnet_r101_fold2_v4_epoch18.pth\n* `v6`: vfnet_r101_fold1_v4_epoch18.pth\n* `v4`: vfnet_r101_fold4_v3_epoch18.pth\n* `v3`: vfnet_r101_8020_v1_epoch18.pth\n* `v2`: vfnet_r101_fold3_v1_epoch25.pth\n* `v1`: vfnet_r101_fpn 3x_downsampled_fold0","f3c979ab":"# Installing MMDet Framework","46fd2eb6":"# Downloading Checkpoint For Demo","31383a44":"# Training Detector With BBox Eval","bcceffc3":"MMDetection is an open source object detection toolbox based on PyTorch. It is a part of the OpenMMLab project developed by Multimedia Laboratory, CUHK.","840d2e82":"# Plotting Classification Loss","74140b49":"# Verifying Installation","6f4b47eb":"1. **Modular Design**\n    1. The detection framework is decomposed into different components. This gives the flexiblity to construct a customized object detection framework using different backbones and models.\n    \n    2. The framework mainly contains following parts:\n    \n        1. Config: This is the place where you get to set the configurations for the framwork like data dirs, num of epochs, gpus to use etc.\n        2. mmdet: This module contains the files related to backbones, necks, heads and losses etc.\n        \n        3. Tools: This is the directory that contains utilities for training, testing and computing the evaluation metric.\n","dadad133":"# Building MMDet From Source","3b49f39c":"# Features","7986e2de":"I am using here faster rcnn for the demo purpose but as listed above the training pipeline can be customized using different framework and backbones. Just need to change the config settings down here. The config dir of mmdet framework contains various implmentation. Do checkit out.","c6e853e6":"# Building Dataset","a99e66c0":"# NMS","bc8ee7e6":"# Initializing Detector","7072a441":"2. **Multiple Frameworks**(https:\/\/github.com\/open-mmlab\/mmdetection)\n    1. List of Supported Backbones\n    \n        1. ResNet (CVPR'2016)\n        2. ResNeXt (CVPR'2017)\n        3. VGG (ICLR'2015)\n        4. HRNet (CVPR'2019)\n        5. RegNet (CVPR'2020)\n        6. Res2Net (TPAMI'2020)\n        7. ResNeSt (ArXiv'2020)\n    2. Supported Frameworks\n        1. [RPN (NeurIPS'2015)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/rpn)\n        2. [Fast R-CNN (ICCV'2015)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fast_rcnn)\n        3. [Faster R-CNN (NeurIPS'2015)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/faster_rcnn)\n        4. [Mask R-CNN (ICCV'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/mask_rcnn)\n        5. [Cascade R-CNN (CVPR'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cascade_rcnn)\n        6. [Cascade Mask R-CNN (CVPR'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cascade_rcnn)\n        7. [SSD (ECCV'2016)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/ssd)\n        8. [RetinaNet (ICCV'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/retinanet)\n        9. [GHM (AAAI'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/ghm)\n        10. [Mask Scoring R-CNN (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/ms_rcnn)\n        11. [Double-Head R-CNN (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/double_heads)\n        12. [Hybrid Task Cascade (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/htc)\n        13. [Libra R-CNN (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/libra_rcnn)\n        14. [Guided Anchoring (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/guided_anchoring)\n        15. [FCOS (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fcos)\n        16. [RepPoints (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/reppoints)\n        17. [Foveabox (TIP'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/foveabox)\n        18. [FreeAnchor (NeurIPS'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/free_anchor)\n        19. [NAS-FPN (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/nas_fpn)\n        20. [ATSS (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/atss)\n        21. [FSAF (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fsaf)\n        22. [PAFPN (CVPR'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/pafpn)\n        23. [Dynamic R-CNN (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/dynamic_rcnn)\n        24. [PointRend (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/point_rend)\n        25. [CARAFE (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/carafe\/README.md)\n        26. [DCNv2 (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/dcn\/README.md)\n        27. [Group Normalization (ECCV'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gn\/README.md)\n        28. [Weight Standardization (ArXiv'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gn+ws\/README.md)\n        29. [OHEM (CVPR'2016)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/faster_rcnn\/faster_rcnn_r50_fpn_ohem_1x_coco.py)\n        30. [Soft-NMS (ICCV'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/faster_rcnn\/faster_rcnn_r50_fpn_soft_nms_1x_coco.py)\n        31. [Generalized Attention (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/empirical_attention\/README.md)\n        32. [GCNet (ICCVW'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gcnet\/README.md)\n        33. [Mixed Precision (FP16) Training (ArXiv'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fp16\/README.md)\n        34. [InstaBoost (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/instaboost\/README.md)\n        35. [GRoIE (ICPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/groie\/README.md)\n        36. [DetectoRS (ArXix'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/detectors\/README.md)\n        37. [Generalized Focal Loss (NeurIPS'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gfl\/README.md)\n        38. [CornerNet (ECCV'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cornernet\/README.md)\n        39. [Side-Aware Boundary Localization (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/sabl\/README.md)\n        40. [YOLOv3 (ArXiv'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/yolo\/README.md)\n        41. [PAA (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/paa\/README.md)\n        42. [YOLACT (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/yolact\/README.md)\n        43. [CentripetalNet (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/centripetalnet\/README.md)\n        44. [VFNet (ArXix'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/vfnet\/README.md)\n        45. [DETR (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/detr\/README.md)\n        46. [CascadeRPN (NeurIPS'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cascade_rpn\/README.md)\n        47. [SCNet (AAAI'2021)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/scnet\/README.md)","b807803d":"![image.png](attachment:image.png)","def9c0c3":"# MMDet on VinBigData","37342906":"Dataset Source: https:\/\/www.kaggle.com\/sreevishnudamodaran\/vinbigdata-fusing-bboxes-coco-dataset","3abbbe0a":"# Sample Inference Demo","13c4f767":"3. **High Efficiency**\n    1. All basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.","d1fa6ae0":"# MMDet Framework","a6760a1b":"Check the output dir for the plot.","eb32bc23":"# Configuration Settings On BaseConfig","f9e4b346":"The aim of this notebook is to install and run a training pipeline using MMDET Framework."}}