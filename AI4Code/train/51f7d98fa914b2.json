{"cell_type":{"58c36935":"code","0016b4a6":"code","5af67175":"code","3ee08e12":"code","64f04b0d":"code","3417b3c7":"code","c6376eee":"code","26402207":"code","c0623ef6":"code","e358fd93":"code","da5df8ac":"code","2594e77f":"code","4efcb1ae":"code","bcda6bff":"code","c78d2e03":"code","69dbe688":"code","361702d5":"code","33f2f7b0":"code","438fbe55":"code","f933e071":"code","b04dfe37":"code","6db3a4c1":"code","ad3bc393":"code","f52ac6f0":"code","c50ec0af":"code","9f40dc0e":"code","97626967":"code","a2822507":"code","6f795f9a":"code","ee11b801":"code","346d4692":"code","a5dd9e99":"code","6544a924":"code","c6f6713d":"code","4b3acdc3":"code","25fd1d03":"code","7032944a":"code","5c74055a":"code","1b87c9af":"code","ed6366f2":"code","4c7c4f21":"code","92035d89":"code","a61661d1":"code","ac8f3604":"code","67568b4a":"code","5c1eb008":"code","3afc6e1f":"code","8b2b68fa":"code","9413d61e":"code","df3531d4":"code","b8f349ab":"code","cfb9dab9":"code","1e2eb0b6":"code","7fc98fc1":"code","54e02f55":"code","5987665d":"code","58b01031":"code","d9cdc016":"code","c7521b9c":"code","2f378407":"code","36f8f29d":"code","f52c1284":"code","000f9c2a":"code","7440cfda":"code","ddfc4a85":"code","b230a627":"code","3daca48d":"code","c31d94bf":"code","e01e534c":"code","92fd8416":"code","408c4a5c":"code","e685f6f6":"code","35c8e6d1":"code","62329919":"code","7dfa3954":"code","ea556437":"code","1aa18331":"code","76871b2b":"markdown","d7aa8ccb":"markdown","db19df36":"markdown","d6c5a3d5":"markdown","20163c56":"markdown","5385592c":"markdown","b82275ef":"markdown","0ef82626":"markdown","021f7019":"markdown","f3f6e999":"markdown","b89f5568":"markdown"},"source":{"58c36935":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly\nfrom scipy.stats import zscore\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom statsmodels.api import OLS\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0016b4a6":"train_df= pd.read_excel('..\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')\ntest_df= pd.read_excel('..\/input\/flight-fare-prediction-mh\/Test_set.xlsx')\nsampsub_file= pd.read_excel('..\/input\/flight-fare-prediction-mh\/Sample_submission.xlsx')","5af67175":"train_df.shape, test_df.shape, sampsub_file.shape","3ee08e12":"train_df.head()","64f04b0d":"test_df.head()","3417b3c7":"sampsub_file.head()","c6376eee":"train_df.isnull().sum()","26402207":"train_df[\"Total_Stops\"].value_counts()","c0623ef6":"sns.countplot(train_df[\"Total_Stops\"])","e358fd93":"train_df[\"Duration\"].value_counts()","da5df8ac":"train_df.dropna(inplace=True)","2594e77f":"train_df.isnull().sum()","4efcb1ae":"test_df.isnull().sum()","bcda6bff":"train_df.info()","c78d2e03":"train_df[\"Day_of_Journey\"]= pd.to_datetime(train_df.Date_of_Journey,format=\"%d\/%m\/%Y\").dt.day\ntrain_df[\"Month_of_Journey\"]= pd.to_datetime(train_df.Date_of_Journey, format= \"%d\/%m\/%Y\").dt.month\ntrain_df.head()","69dbe688":"test_df[\"Day_of_Journey\"]= pd.to_datetime(test_df.Date_of_Journey,format=\"%d\/%m\/%Y\").dt.day\ntest_df[\"Month_of_Journey\"]= pd.to_datetime(test_df.Date_of_Journey, format= \"%d\/%m\/%Y\").dt.month\ntest_df.head()","361702d5":"train_df.drop([\"Date_of_Journey\"], axis=1, inplace=True)\ntest_df.drop([\"Date_of_Journey\"], axis=1, inplace=True)","33f2f7b0":"train_df.info()","438fbe55":"train_df[\"Dep_hr\"]= pd.to_datetime(train_df.Dep_Time).dt.hour\ntrain_df[\"Dep_mi\"]= pd.to_datetime(train_df.Dep_Time).dt.minute\ntrain_df[\"Arr_hr\"]= pd.to_datetime(train_df.Arrival_Time).dt.hour\ntrain_df[\"Arr_mi\"]= pd.to_datetime(train_df.Arrival_Time).dt.minute\ntrain_df.drop([\"Dep_Time\"], axis=1, inplace=True)\ntrain_df.drop([\"Arrival_Time\"], axis=1, inplace=True)","f933e071":"test_df[\"Dep_hr\"]= pd.to_datetime(test_df.Dep_Time).dt.hour\ntest_df[\"Dep_mi\"]= pd.to_datetime(test_df.Dep_Time).dt.minute\ntest_df[\"Arr_hr\"]= pd.to_datetime(test_df.Arrival_Time).dt.hour\ntest_df[\"Arr_mi\"]= pd.to_datetime(test_df.Arrival_Time).dt.minute\ntest_df.drop([\"Dep_Time\"], axis=1, inplace=True)\ntest_df.drop([\"Arrival_Time\"], axis=1, inplace=True)","b04dfe37":"train_df.columns","6db3a4c1":"test_df.columns","ad3bc393":"## Splitting Duration to hours and minutes\n\n# Assigning and converting Duration column into list\nduration = list(train_df[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration","f52ac6f0":"train_df[\"Duration_hours\"] = duration_hours\ntrain_df[\"Duration_mins\"] = duration_mins\ntrain_df.drop([\"Duration\"], axis = 1, inplace = True)","c50ec0af":"## Splitting Duration to hours and minutes\n\n# Assigning and converting Duration column into list\nduration2 = list(test_df[\"Duration\"])\n\nfor i in range(len(duration2)):\n    if len(duration2[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration2[i]:\n            duration2[i] = duration2[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration2[i] = \"0h \" + duration2[i]           # Adds 0 hour\n\nduration_hrs = []\nduration_min = []\nfor i in range(len(duration2)):\n    duration_hrs.append(int(duration2[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_min.append(int(duration2[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration","9f40dc0e":"test_df[\"Duration_hours\"] = duration_hrs\ntest_df[\"Duration_mins\"] = duration_min\ntest_df.drop([\"Duration\"], axis = 1, inplace = True)","97626967":"train_df.head()","a2822507":"train_df.Airline.unique()","6f795f9a":"plt.figure(figsize=(40,10))\nsns.countplot(train_df['Airline'])\nplt.show()","ee11b801":"# Airline vs Price\nplt.figure(figsize=(10,15))\nsns.barplot(x = \"Price\", y = \"Airline\", data = train_df)\nplt.show()","346d4692":"train_df[\"Airline\"]= train_df[\"Airline\"].replace({\n'IndiGo':'1', 'Air India':'2', 'Jet Airways':'3', 'SpiceJet':'4',\n       'Multiple carriers':'5', 'GoAir':'6', 'Vistara':'7', 'Air Asia':'8',\n       'Vistara Premium economy':'9', 'Jet Airways Business':'10',\n       'Multiple carriers Premium economy':'11', 'Trujet':'12'})\n\ntrain_df[\"Airline\"]= train_df[\"Airline\"].astype('int64')","a5dd9e99":"train_df.Airline.unique()","6544a924":"test_df.Airline.unique()","c6f6713d":"test_df[\"Airline\"]= test_df[\"Airline\"].replace({\n'Jet Airways':'1', 'IndiGo':'2', 'Multiple carriers':'3', 'Air Asia':'4',\n       'Air India':'5', 'Vistara':'6', 'SpiceJet':'7', 'Vistara Premium economy':'8',\n       'GoAir':'9', 'Multiple carriers Premium economy':'10',\n       'Jet Airways Business':'11', 'Trujet':'12'})\n\ntest_df[\"Airline\"]= test_df[\"Airline\"].astype('int64')","4b3acdc3":"test_df.Airline.unique()","25fd1d03":"train_df.dtypes","7032944a":"train_df.Total_Stops.unique()","5c74055a":"train_df[\"Total_Stops\"]= train_df[\"Total_Stops\"].replace(\n    {\n    'non-stop':0, '2 stops':2, '1 stop':1, '3 stops':3, '4 stops':4\n}\n)\n#train_df[\"Total_Stops\"]= train_df[\"Total_Stops\"].astype('int64')","1b87c9af":"test_df[\"Total_Stops\"]= test_df[\"Total_Stops\"].replace(\n    {\n    'non-stop':0, '2 stops':2, '1 stop':1, '3 stops':3, '4 stops':4\n}\n)","ed6366f2":"train_df.head()","4c7c4f21":"sns.countplot(train_df[\"Source\"])","92035d89":"sns.countplot(train_df[\"Destination\"])","a61661d1":"train_df.Source.unique()","ac8f3604":"train_df.Destination.unique()","67568b4a":"train_df[\"Source\"]= train_df[\"Source\"].replace({\n    'Banglore':1, 'Kolkata':4, 'Delhi':3, 'Chennai':2, 'Mumbai':5\n})\n\ntrain_df[\"Destination\"]= train_df[\"Destination\"].replace({\n    'New Delhi':6, 'Banglore':1, 'Cochin':2, 'Kolkata':5, 'Delhi':3, 'Hyderabad':4\n})","5c1eb008":"test_df[\"Source\"]= test_df[\"Source\"].replace({\n    'Banglore':1, 'Kolkata':4, 'Delhi':3, 'Chennai':2, 'Mumbai':5\n})\n\ntest_df[\"Destination\"]= test_df[\"Destination\"].replace({\n    'New Delhi':6, 'Banglore':1, 'Cochin':2, 'Kolkata':5, 'Delhi':3, 'Hyderabad':4\n})","3afc6e1f":"plt.figure(figsize=(9,9))\nsns.heatmap(train_df.corr(), annot=True, cmap='RdYlGn')","8b2b68fa":"train_df.head()","9413d61e":"train_df.shape, test_df.shape","df3531d4":"test_df.isnull().sum()","b8f349ab":"X= train_df.drop([\"Route\",\"Additional_Info\",\"Price\"],axis=1) ## Features\ny= train_df.Price.values ## Target variable or Label","cfb9dab9":"X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=1)","1e2eb0b6":"print('Train:',(X_train.shape, y_train.shape))\nprint('Test:',(X_test.shape, y_test.shape))","7fc98fc1":"def evaluation_metric(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return 1 - np.sqrt(np.square(np.log10(y_pred +1) - np.log10(y_true +1)).mean())","54e02f55":"#pipelines = []\n#pipelines.append(('ScaledLinear', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n#pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',KNeighborsRegressor())])))\n#pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR',SVR())])))\n#pipelines.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF',RandomForestRegressor())])))\n#pipelines.append(('ScaledETR', Pipeline([('Scaler', StandardScaler()),('ETR', ExtraTreesRegressor())])))\n#pipelines.append(('ScaledXGB', Pipeline([('Scaler', StandardScaler()),('XGB',XGBRegressor())])))\n#pipelines.append(('ScaledCatBoost', Pipeline([('Scaler', StandardScaler()),('CatBoost', CatBoostRegressor())])))","5987665d":"#results = []\n#names = []\n#for name, model in pipelines:\n#    kfold = KFold(n_splits=10, random_state=21)\n#    cv_results = cross_val_score(model, X, y, cv=kfold, scoring='neg_root_mean_squared_error')\n#    results.append(cv_results)\n#    names.append(name)\n#    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n#    print(msg)","58b01031":"# Algorithm comparison\n#fig = plt.figure(figsize=(8,5))\n#fig.suptitle('Algorithm Comparison')\n#ax = fig.add_subplot(111)\n#plt.boxplot(results)\n#ax.set_xticklabels(names)\n#plt.show()","d9cdc016":"catboost= CatBoostRegressor()\ncatboost.fit(X,y)","c7521b9c":"#plot graph of feature importances for better visualization\n\nplt.figure(figsize = (12,8))\nfeat_importances = pd.Series(catboost.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","2f378407":"model= catboost.fit(X_train, y_train)","36f8f29d":"y_preds= model.predict(X_test)\nprint('Total Predicted Prices:',len(y_preds))","f52c1284":"price_preds= pd.DataFrame(y_test, columns=[\"Actual_Price\"])\nprice_preds[\"Predicted_Price\"]= y_preds\nprice_preds[\"Error\"]= price_preds[\"Actual_Price\"]- price_preds[\"Predicted_Price\"]\nprice_preds.head()","000f9c2a":"print('Train Score:', model.score(X_train, y_train))\nprint('Test Score:', model.score(X_test, y_test))","7440cfda":"from sklearn import metrics\nprint(\"\\n========================================================\")\nprint(\" Regression Metrics \" )\nprint(\"========================================================\")  \nprint('MAE:', metrics.mean_absolute_error(y_test, y_preds))\nprint('MSE:', metrics.mean_squared_error(y_test, y_preds))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_preds)))\nprint('Coefficient of Determination:',metrics.r2_score(y_test,y_preds))","ddfc4a85":"print(\"\\n========================================================\")\nprint(\" Evaluation Metric \" )\nprint(\"========================================================\")  \nprint('Calculated value:', evaluation_metric(y_test, y_preds))","b230a627":"params = {\"depth\": [6,7,8,9,10],\n          \"eval_metric\": ['R2','RMSE'],\n          \"learning_rate\": [0.001, 0.01, 0.05, 0.5, 0.1]\n         }","3daca48d":"grid = GridSearchCV(estimator=model, param_grid =params, cv = 3, n_jobs=-1)\ngrid.fit(X_train, y_train)","c31d94bf":"print(\"\\n========================================================\")\nprint(\" Results from Grid Search\" )\nprint(\"========================================================\")    \n    \nprint(\"\\n The best estimator across ALL searched params:\\n\",grid.best_estimator_)\nprint(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\",grid.best_params_)","e01e534c":"final_model= CatBoostRegressor(depth=7, eval_metric= 'R2', n_estimators= 6000)\nfinal_model.fit(X_train, y_train)","92fd8416":"y_predictions= final_model.predict(X_test)\nprint('Total Predicted Prices:',len(y_predictions))","408c4a5c":"print('Train Score:', final_model.score(X_train, y_train))\nprint('Test Score:', final_model.score(X_test, y_test))","e685f6f6":"test_df.drop([\"Route\",\"Additional_Info\"], axis=1, inplace=True)","35c8e6d1":"print(\"\\n========================================================\")\nprint(\" Regression Metrics\" )\nprint(\"========================================================\")  \nprint('MAE:', metrics.mean_absolute_error(y_test, y_predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, y_predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_predictions)))\nprint('Coefficient of Determination:',metrics.r2_score(y_test,y_predictions))\nprint('Evaluation Metric value:', evaluation_metric(y_test, y_predictions))","62329919":"test_df.columns","7dfa3954":"final_preds= final_model.predict(test_df)","ea556437":"price_df= pd.DataFrame(final_preds, columns=[\"Price\"])\nprice_df.head()","1aa18331":"price_df.to_csv('\/kaggle\/working\/Price_output.csv', index=False)","76871b2b":"Considered **CatBoost** as my model to predict the results.","d7aa8ccb":"# **Define Evaluation Metric**","db19df36":"# **Hyper Parameter Tuning**\n## **Grid Search CV**","d6c5a3d5":"# **Data Wrangling**","20163c56":"**Jet Airways** has highest count of flights.","5385592c":"Flights operating from **Delhi** as Source are higher in number.","b82275ef":"# **Building Model (CatBoost)**","0ef82626":"# **Feature Engineering**","021f7019":"**Jet Airways Business** have the highest Prices.","f3f6e999":"Flights for **Cochin** as destination are higher in number. ","b89f5568":"# **Split Data**"}}