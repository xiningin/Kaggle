{"cell_type":{"8f92bfea":"code","fc34a425":"code","7ecf9b1f":"code","c4ea65e3":"code","d65c4ff2":"code","f2949a99":"code","821b00e6":"code","de097680":"code","c78741ff":"code","de7d4d86":"markdown"},"source":{"8f92bfea":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.metrics import classification_report, confusion_matrix \nfrom sklearn.preprocessing import StandardScaler \n","fc34a425":"data_sky= pd.read_csv(\"..\/input\/Skyserver_SQL2_27_2018 6_51_39 PM.csv\",header = 0)\ndata_sky.head()","7ecf9b1f":"#Dropping the id feature\ndata_sky.drop(columns = ['objid'], inplace = True)\ndata_sky.head()\n\n#Converting non-numeric data to numeric dataset\ndiag_map = {'STAR':1, 'GALAXY':2, 'QSO':3}\ndata_sky['class'] = data_sky['class'].map(diag_map)\n\n#Preparing the data set\nclass_all = list(data_sky.shape)[0]\nclass_categories = list(data_sky['class'].value_counts())\n\nprint(\"The dataset has {} classes, {} stars, {} galaxies and {} quasars.\".format(class_all, \n                                                                                 class_categories[0], \n                                                                                 class_categories[1],\n                                                                                 class_categories[2]))\ndata_sky.describe()","c4ea65e3":"#Creating training and test datasets\ny = data_sky[\"class\"].values\nX = data_sky.drop([\"class\"], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 41)","d65c4ff2":"#Training Model\nclassifier = KNeighborsClassifier(n_neighbors=4)  \nclassifier.fit(X_train, y_train) ","f2949a99":"#Testing the model\ny_pred = classifier.predict(X_test)  \nprint(np.mean(y_pred != y_test))\nprint(confusion_matrix(y_test, y_pred))  \nprint(classification_report(y_test, y_pred))  ","821b00e6":"#Improve Model Performance\n#z-score transformed \nscaler = StandardScaler()  \nscaler.fit(X_train)\n\n#Training the model\nX_train = scaler.transform(X_train)  \nX_test = scaler.transform(X_test) \nclassifier = KNeighborsClassifier(n_neighbors=4)  \nclassifier.fit(X_train, y_train) \n\n#Testing the model\ny_pred = classifier.predict(X_test)  \nprint(np.mean(y_pred != y_test))\nprint(confusion_matrix(y_test, y_pred))  \nprint(classification_report(y_test, y_pred))  ","de097680":"error = []\n\n# Calculating error for K values between 1 and 300\nfor i in range(1, 300):  \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error.append(np.mean(pred_i != y_test))\n    \nplt.figure(figsize=(12, 6))  \nplt.plot(range(1, 300), error, color='red', linestyle='dashed', marker='o',  \n         markerfacecolor='blue', markersize=10)\nplt.title('Error Rate K Value')  \nplt.xlabel('K Value')  \nplt.ylabel('Mean Error') \n\nplt.show()","c78741ff":"#Training Model for better accuracy (change n neighbour value)\nfrom sklearn.neighbors import KNeighborsClassifier  \nclassifier = KNeighborsClassifier(n_neighbors=50)  \nclassifier.fit(X_train, y_train)\n\n#Testing the model\nfrom sklearn.metrics import classification_report, confusion_matrix  \ny_pred = classifier.predict(X_test)  \nprint(np.mean(y_pred != y_test))\nprint(confusion_matrix(y_test, y_pred))  \nprint(classification_report(y_test, y_pred)) ","de7d4d86":"Import Dataset using Pandas"}}