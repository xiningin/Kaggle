{"cell_type":{"cac6a1bf":"code","97243456":"code","8c0a5c29":"code","6b8754c3":"code","8bb6defc":"code","e9061281":"code","876ee974":"code","8415bcd3":"code","437820b6":"code","cbad6b9e":"code","bea6afea":"markdown","0026ae9e":"markdown","74c3fdf1":"markdown","35a4b65d":"markdown"},"source":{"cac6a1bf":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport tensorflow as tf\nimport pathlib\nimport PIL\nimport time\nimport zipfile\nimport random\nfrom tensorflow.keras.layers import *","97243456":"import warnings\nwarnings.filterwarnings('ignore')","8c0a5c29":"MAIN_PATH = \"..\/input\/traffic-sign-classification-and-recognition\/train_dataset\/train\"\nTEST_PATH = \"..\/input\/traffic-sign-classification-and-recognition\/test_dataset\/test\/\"\nCLASSES = os.listdir(MAIN_PATH)\nNUM_CLASSES = len(CLASSES)\n\nHEIGHT,WIDTH = 32,32\nBATCH_SIZE = 32\nSPLIT = 0.2","6b8754c3":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=20,\n    horizontal_flip=True,\n    validation_split=SPLIT)\n\ntrain_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"training\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\nval_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"validation\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255)\ntest_ds = test_datagen.flow_from_directory(\n    TEST_PATH,\n    target_size = (HEIGHT,WIDTH),\n    shuffle = False\n)","8bb6defc":"def create_model():\n    vgg16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\n            \n    x = vgg16.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(128) (x)\n    x = tf.keras.layers.LeakyReLU(alpha=0.2) (x)\n    x = tf.keras.layers.GaussianDropout(0.4) (x)\n    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", dtype='float32')(x)\n        \n    model = tf.keras.Model(vgg16.input, outputs)\n    return model\n\nmodel = create_model()\nmodel.summary()","e9061281":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=1e-4)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n        \n    metrics = [\n       tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","876ee974":"def create_callbacks():\n    \n    cpk_path = '.\/best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_categorical_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","8415bcd3":"EPOCHS= 60\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE)","437820b6":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(15, 10))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Categorical Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Categorical Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Categorical Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","cbad6b9e":"model.evaluate(test_ds)","bea6afea":"# 3. Metrics Visualization","0026ae9e":"# 1. Loading and preprocessing data","74c3fdf1":"# 2. Creating model","35a4b65d":"I refered to Note Book 'Traffic Sign Recognition' https:\/\/www.kaggle.com\/shanmukh05\/traffic-sign-recognition to try VGG16. Thank you very much for sharing 'Traffic Sign Recognition' Note Book !"}}