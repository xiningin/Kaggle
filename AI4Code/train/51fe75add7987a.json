{"cell_type":{"461ea8bb":"code","4d0280fd":"code","4e738b47":"code","202b156b":"code","6bd3dcf9":"code","5e8533c3":"code","0ed0dc73":"code","3ac6efc3":"code","29a82f8f":"code","885c5e7d":"code","92653bdd":"code","fc64e750":"code","838983fc":"code","d0aaa492":"code","e5aa5c42":"code","301ac090":"code","7261c222":"code","4b22ee0e":"code","b0e3e3bb":"code","52395c95":"code","e32e9637":"code","41c3d41e":"code","70c605f6":"code","9bcb98f2":"code","99ff5c25":"code","8026b6d1":"code","0d0fcaeb":"code","86250fb4":"code","b6aff6ac":"code","5aa77f27":"code","08b59c97":"code","5cee5b74":"code","e29503fa":"code","529e128a":"code","b9149291":"code","103b4230":"code","b051c368":"code","d89c668d":"code","ca9883b7":"code","6287ea0e":"code","58124e5c":"code","613ebcb8":"code","1b7ba3fc":"code","a89c6604":"code","891e0b14":"code","0ae9ed05":"code","088f90da":"code","055239de":"code","19878289":"code","ff47def8":"code","a6c6f76f":"code","68798e09":"code","31039d20":"code","8cacbc00":"markdown","1bd6ae2d":"markdown","831c88f5":"markdown","ac6663fb":"markdown","9c0b69d3":"markdown","59752ac1":"markdown","c13c96dd":"markdown","9c571dbe":"markdown","acdfd239":"markdown","9c46ead2":"markdown","9bc5ee58":"markdown","19077b4d":"markdown","ca357c3f":"markdown","0299e76d":"markdown","6ccec0a6":"markdown","7d3fddd2":"markdown","ad275860":"markdown","0e8c5658":"markdown","aa6c61de":"markdown","50f1924f":"markdown","a18bba99":"markdown","f16e7b7f":"markdown","1f2f54e7":"markdown","2e1e2cfa":"markdown","7f6b7695":"markdown"},"source":{"461ea8bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d0280fd":"data = pd.read_csv('..\/input\/used-car-dataset-ford-and-mercedes\/skoda.csv')\ndata.head()","4e738b47":"data.info()","202b156b":"data[\"model\"].value_counts()","6bd3dcf9":"data.describe()","5e8533c3":"import matplotlib.pyplot as plt","0ed0dc73":"data.hist(bins=20, figsize=(20,15));","3ac6efc3":"from sklearn.model_selection import train_test_split","29a82f8f":"train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)","885c5e7d":"data[\"tax_cat\"] = pd.cut(data[\"tax\"], bins=[-1, 65, 130, 195, 260, np.inf], labels=[1, 2, 3, 4, 5])","92653bdd":"data.sample(5)","fc64e750":"data[\"tax_cat\"].hist();","838983fc":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"tax_cat\"]):\n    strat_train_set = data.loc[train_index]\n    strat_test_set = data.loc[test_index]","d0aaa492":"strat_test_set[\"tax_cat\"].value_counts() \/ len(strat_test_set)","e5aa5c42":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"tax_cat\", axis=1, inplace=True)","301ac090":"data_train = strat_train_set.copy()","7261c222":"import seaborn as sns\n\nsns.catplot(kind=\"bar\", x=\"model\", y=\"mileage\", data=data_train, alpha=.25, height=8, palette=\"bright\")\nplt.xticks(rotation=70)\nplt.tight_layout();","4b22ee0e":"corr_matrix = data_train.corr()","b0e3e3bb":"corr_matrix[\"price\"].sort_values(ascending=False)","52395c95":"from pandas.plotting import scatter_matrix\n\nattributes = [\"price\", \"year\", \"engineSize\", \"tax\", \"mpg\", \"mileage\"]\nscatter_matrix(data_train[attributes], figsize=(16,10));","e32e9637":"data_train.plot(kind=\"scatter\", x=\"year\", y=\"price\", alpha=0.1);","41c3d41e":"data_train.head(2)","70c605f6":"data_train[\"miles_per_year\"] = data_train.mileage \/ (2021 - data_train.year)","9bcb98f2":"data_train.head(2)","99ff5c25":"corr_matrix = data_train.corr()","8026b6d1":"corr_matrix[\"price\"].sort_values(ascending=False)","0d0fcaeb":"data_train.plot(kind=\"scatter\", x=\"miles_per_year\", y=\"price\", alpha=0.1);","86250fb4":"data_train = strat_train_set.drop(\"price\", axis=1)\ndata_train_labels = strat_train_set[\"price\"].copy()","b6aff6ac":"data_train.info()","5aa77f27":"data_train_cat = data_train[[\"model\", \"transmission\", \"fuelType\"]]\ndata_train_cat.sample(10)","08b59c97":"from sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\ndata_train_cat_encoded = ordinal_encoder.fit_transform(data_train_cat)\ndata_train_cat_encoded[:5]","5cee5b74":"ordinal_encoder.categories_","e29503fa":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\ndata_train_cat_1hot = cat_encoder.fit_transform(data_train_cat)\ndata_train_cat_1hot","529e128a":"data_train_cat_1hot.toarray()","b9149291":"from sklearn.compose import ColumnTransformer\n\ncat_attribs = [\"model\", \"transmission\", \"fuelType\"]\n\nfull_pipeline = ColumnTransformer([\n    (\"cat\", OneHotEncoder(), cat_attribs),\n])\n\ndata_train_prepared = full_pipeline.fit_transform(data_train)","103b4230":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(data_train_prepared, data_train_labels)","b051c368":"some_data = data_train.iloc[:5]\nsome_labels = data_train_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions: \", lin_reg.predict(some_data_prepared))\nprint(\"Labels: \", list(some_labels))","d89c668d":"from sklearn.metrics import mean_squared_error\n\ndata_predictions = lin_reg.predict(data_train_prepared)\nlin_mse = mean_squared_error(data_train_labels, data_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","ca9883b7":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(data_train_prepared, data_train_labels)","6287ea0e":"data_predictions = tree_reg.predict(data_train_prepared)\ntree_rmse = mean_squared_error(data_train_labels, data_predictions)\ntree_rmse = np.sqrt(tree_rmse)\ntree_rmse","58124e5c":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, data_train_prepared, data_train_labels, scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","613ebcb8":"def display_scores(scores):\n    print(f\"Scores: {scores}\")\n    print(\"Mean: \", scores.mean())\n    print(\"Standard deviation: \", scores.std())\n\ndisplay_scores(tree_rmse_scores)","1b7ba3fc":"lin_scores = cross_val_score(lin_reg, data_train_prepared, data_train_labels, scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\n\ndisplay_scores(lin_rmse_scores)","a89c6604":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()\nforest_reg.fit(data_train_prepared, data_train_labels)","891e0b14":"forest_scores = cross_val_score(forest_reg, data_train_prepared, data_train_labels, scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\n\ndisplay_scores(forest_rmse_scores)","0ae9ed05":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\"n_estimators\": [3, 10, 30], \"max_features\": [2, 4, 6, 8]},\n    {\"bootstrap\": [False], \"n_estimators\": [3, 10], \"max_features\": [2, 3, 4]},\n]\n\nforest_reg = RandomForestRegressor()\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n\ngrid_search.fit(data_train_prepared, data_train_labels)","088f90da":"grid_search.best_params_","055239de":"grid_search.best_estimator_","19878289":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","ff47def8":"feature_importances = grid_search.best_estimator_.feature_importances_\n\nextra_attribs = [\"miles_per_year\"]\ncat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","a6c6f76f":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"price\", axis=1)\ny_test = strat_test_set[\"price\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\n\nfinal_predictions =final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","68798e09":"final_rmse","31039d20":"from scipy import stats\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test) ** 2\nnp.sqrt(stats.t.interval(confidence, len(squared_errors) - 1, loc=squared_errors.mean(), scale=stats.sem(squared_errors)))","8cacbc00":"### 5.3 Using a pipeline","1bd6ae2d":"# 4. Correlations","831c88f5":"# 13. Evaluation on the test set","ac6663fb":"# 14. Result","9c0b69d3":"### 5.2 Use OneHotEncoding","59752ac1":"#### => Better model als RMSE is lower than with linear regression!","c13c96dd":"### Results:","9c571dbe":"### 11.1 Get best estimator directly","acdfd239":"### 9.1 Comparing these results to the Linear Regression model","9c46ead2":"### Based on the test set, the model predicts prices for Skoda cars with a RMSE of ~3,085, which is off by about 22%.","9bc5ee58":"# 1. EDA","19077b4d":"### 13.1 How confident are we in generalising?","ca357c3f":"# 6. Run regression","0299e76d":"# 7. Measuring prediction error with RMSE","6ccec0a6":"# 3. Visualisation","7d3fddd2":"# 10. Use a different Model (Random Forest)","ad275860":"# 9. Split the training set in a smaller training set and validation set (K-fold cross-validation)","0e8c5658":"# 12. Selecting the best model","aa6c61de":"# 11. Grid Search","50f1924f":"# 2. Train\/test sample & stratification","a18bba99":"Dataset complete","f16e7b7f":"### 6.1 Trial on some instances of the training set","1f2f54e7":"# 5. Data Cleaning","2e1e2cfa":"### 5.1 Creating numbers for categories","7f6b7695":"# 8. Use a different Model (Decision Tree)"}}