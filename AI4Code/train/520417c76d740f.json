{"cell_type":{"f9bd1d08":"code","d04c9246":"code","29b53431":"code","6b1b2989":"code","b81fe49c":"code","22acf3da":"code","ed158efd":"code","2fac6ca0":"code","affb3e4b":"code","b513fcc8":"code","b7fb7b23":"code","f4bd7f0e":"code","11c25959":"code","a8b00907":"code","50b8e046":"code","4fa31570":"code","e9bb81e4":"code","5f57420c":"code","97164b03":"code","10568a82":"code","3dba2a0c":"code","cc1a3303":"code","77d567a6":"code","71216c76":"code","d7a0202d":"code","8d6b9f22":"code","be39dc6b":"code","f1bfb99a":"code","09c37a09":"code","2c711c72":"code","eff3afd8":"code","7417d97b":"code","61f0b2cf":"code","43c40e0b":"code","9b73ee2d":"code","defaed36":"code","11048ae4":"code","2de28059":"code","77a06d57":"code","0786edd5":"code","79419eff":"code","6a8060b9":"code","9a8fd5c4":"code","85af7d4b":"markdown","26a6c168":"markdown","bf257d87":"markdown","2e88df3f":"markdown"},"source":{"f9bd1d08":"# Importing Modules\nimport os\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn   \nfrom torch.optim import Adam,SGD\nfrom matplotlib import pyplot as plt\nimport pandas as pd","d04c9246":"# Cudnn for internal optimization\ntorch.backends.cudnn.benchmark = True","29b53431":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","6b1b2989":"device","b81fe49c":"# Dataset Path\npath = r'..\/input\/digit-recognizer'\noutputPath = r'..\/input\/output\/'","22acf3da":"# Reading the Data\ntrain = pd.read_csv(os.path.join(path,'train.csv'))\ntest = pd.read_csv(os.path.join(path,'test.csv'))\nsample_submission = pd.read_csv(os.path.join(path,'sample_submission.csv'))","ed158efd":"# The label field is for label of the data\n# The other fields are pixel values ranging from 0 to 255\ntrain.head()","2fac6ca0":"test.head()","affb3e4b":"sample_submission.head()","b513fcc8":"trainY = train.pop('label')\ntestY = pd.get_dummies(sample_submission.Label)\ntrainX = train.copy()\ntestX = test.copy()","b7fb7b23":"trainX","f4bd7f0e":"trainY","11c25959":"testY","a8b00907":"testX","50b8e046":"testY","4fa31570":"# Load the model and the dataset in the GPU(if any) , will help to speed up","e9bb81e4":"class datasetClass(Dataset):\n    \n    def __init__(self,):\n        super(datasetClass,self).__init__()\n        self.trainX = torch.tensor(trainX.values).type(torch.float32).div(255).sub_(0.1307).div_(0.3081).contiguous().view(-1,28,28).to(device)\n        self.trainY = torch.tensor(trainY.values).type(torch.long).to(device)\n\n    def __getitem__(self,index):\n        return self.trainX[index],self.trainY[index]\n    \n    def __len__(self,):\n        return len(self.trainY)","5f57420c":"datasetClassObj = datasetClass()","97164b03":"iterObj= iter(datasetClassObj)","10568a82":"x,y = next(iterObj)","3dba2a0c":"x.shape","cc1a3303":"class datasetClassValid(Dataset):\n    \n    def __init__(self,):\n        super(datasetClassValid,self).__init__()\n        self.testX = torch.tensor(testX.values).type(torch.float32).div(255).sub_(0.1307).div_(0.3081).contiguous().view(-1,28,28).to(device)\n        self.testY = torch.tensor(testY.values).type(torch.long).to(device)\n        \n    def __getitem__(self,index):\n        return self.testX[index],self.testY[index]\n    \n    def __len__(self,):\n        return len(self.testY)","77d567a6":"datasetClassValidObj = datasetClassValid()","71216c76":"iterObj= iter(datasetClassValidObj)","d7a0202d":"x,y = next(iterObj)","8d6b9f22":"x.shape","be39dc6b":"class modelClass(nn.Module):\n    def __init__(self,inputDim,outputDim):\n        super(modelClass,self).__init__()\n\n        self.conv2dLayer1 = nn.Conv2d(1,100,kernel_size=5)\n        self.conv2dLayer2 = nn.Conv2d(100,1000,kernel_size=2)\n        self.conv2dLayer3 = nn.Conv2d(1000,100,kernel_size=2)\n        self.conv2dLayer4 = nn.Conv2d(100,100,kernel_size=2)\n        self.conv2dLayer5 = nn.Conv2d(100,20,kernel_size=2)\n        \n        self.batchnorm2dLayer1 = nn.BatchNorm2d(100)\n        self.batchnorm2dLayer2 = nn.BatchNorm2d(1000)\n        self.batchnorm2dLayer3 = nn.BatchNorm2d(100)\n        self.batchnorm2dLayer4 = nn.BatchNorm2d(100)\n        self.batchnorm2dLayer5 = nn.BatchNorm2d(20)\n        \n        self.maxpoolLayer1 = nn.AdaptiveMaxPool2d((16,16))\n        self.maxpoolLayer2 = nn.AdaptiveMaxPool2d((8,8))\n        self.maxpoolLayer3 = nn.AdaptiveAvgPool2d((4,4))\n        self.maxpoolLayer4 = nn.AdaptiveAvgPool2d((4,4))\n        self.maxpoolLayer5 = nn.AdaptiveAvgPool2d((2,2))\n        \n        self.ReLULayer1 = nn.ReLU()\n        self.ReLULayer2 = nn.ReLU()\n        self.ReLULayer3 = nn.ReLU() \n        self.ReLULayer4 = nn.ReLU()\n        self.ReLULayer5 = nn.ReLU() \n        \n        self.conv2DropoutLayer1 = nn.Dropout2d()\n        \n        self.linearLayer1 = nn.Linear(80,40)\n        self.linearLayer2 = nn.Linear(40, 10)\n        self.logsoftmax = nn.LogSoftmax()\n\n    def forward(self,x):\n        x = x.unsqueeze(0).permute(1,0,2,3)\n        \n        x = self.conv2dLayer1(x)\n        x = self.batchnorm2dLayer1(x)\n        x = self.ReLULayer1(x)\n        x = self.maxpoolLayer1(x)     \n        \n        x = self.conv2dLayer2(x)\n        x = self.batchnorm2dLayer2(x)\n        x = self.ReLULayer2(x)\n        x = self.maxpoolLayer2(x)\n        \n        x = self.conv2dLayer3(x)\n        x = self.batchnorm2dLayer3(x)\n        x = self.ReLULayer3(x)\n        x = self.maxpoolLayer3(x)\n        \n        x = self.conv2DropoutLayer1(x)\n        \n        x = self.conv2dLayer4(x)\n        x = self.batchnorm2dLayer4(x)\n        x = self.ReLULayer4(x)\n        x = self.maxpoolLayer4(x)\n        \n        x = self.conv2dLayer5(x)\n        x = self.batchnorm2dLayer5(x)\n        x = self.ReLULayer5(x)\n        x = self.maxpoolLayer5(x)\n        \n        x = x.view(-1,80)\n        x = self.linearLayer1(x)\n        x = self.linearLayer2(x)\n        \n        x = self.logsoftmax(x)\n        return x","f1bfb99a":"bs = 128\nepochs = 100","09c37a09":"Model = modelClass(784,10)\nModel.to(device)","2c711c72":"dataloaderTrain = DataLoader(datasetClassObj,batch_size=bs,shuffle=True)","eff3afd8":"optimizer =  SGD(Model.parameters(),lr=0.01)\nlossFunc = nn.NLLLoss()\nloss  =  torch.tensor(0.1,requires_grad=True)","7417d97b":"x,y = next(iter(dataloaderTrain))","61f0b2cf":"x.shape","43c40e0b":"Model(x).shape","9b73ee2d":"losses = []\nfor epoch in range(epochs):\n    # This step is very important\n    Model.train()\n    for x,y in dataloaderTrain:\n        ydash = Model(x) \n        loss = lossFunc(ydash,y)\n        loss.backward()\n        with torch.no_grad():\n            optimizer.step()\n            optimizer.zero_grad()\n    losses.append(loss)\n    print(f'The epoch {epoch} the Loss is {loss}')\n","defaed36":"# Loss Graph\ncpuLoss = [float(loss.to('cpu')) for loss in losses] \nplt.plot(cpuLoss)","11048ae4":"dataloaderValidObj = DataLoader(datasetClassValidObj,batch_size=64,shuffle=False)","2de28059":"plt.imshow(datasetClassValidObj.testX[0].to('cpu').view(28,28))","77a06d57":"submitframe = pd.DataFrame(columns=['Label'])","0786edd5":"for x,y in dataloaderValidObj:\n    Model.eval()\n    #plt.imshow(x.to('cpu').view(28,28))\n    prediction = torch.argmax(Model(x),dim=1).to('cpu').numpy()\n    submitframe = submitframe.append(pd.DataFrame(prediction,columns=['Label']))\n","79419eff":"submitframe.head()","6a8060b9":"submitframe.shape","9a8fd5c4":"submitframe.to_csv('sample_submission_Result.csv')","85af7d4b":"##  Lets build a model","26a6c168":"## Dataset Class","bf257d87":"## Lets understand the data","2e88df3f":"## Next Steps \n\n1. Addition of pytorch's transform function in the dataset creator.\n2. Introduction of LeNet architechture to improve the prediction.\n"}}