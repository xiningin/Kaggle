{"cell_type":{"05c4f217":"code","05a9c56e":"code","64f4d222":"code","1d1b1ebd":"code","7fca3085":"code","8d36c727":"code","fdbd762b":"code","bd620f22":"code","bca5c57e":"code","6912a27b":"code","2ae79717":"code","fedd708e":"code","b848714d":"code","afe671e8":"code","542009ec":"code","47f417c6":"code","9ca1bd02":"code","13e30dc4":"code","19e2d7dd":"code","6019e7f8":"code","1a570cac":"code","32f95a3e":"code","d43d0ec6":"code","2e83be4b":"code","555bc995":"code","fbd343d4":"code","9dd6ad48":"code","770426fb":"code","a724a50a":"code","65273b68":"code","262ed432":"code","372ee108":"code","e6610d2c":"code","10761cf3":"code","935560a7":"code","00af8f87":"code","dc5146bd":"code","e60b0fcc":"code","47c83adf":"code","7d473279":"code","19947de7":"code","7619a578":"code","760863be":"code","bac32cd1":"code","882b567b":"code","31498f55":"code","b8f0d677":"code","32916d30":"code","327dfb24":"code","4ef7ed97":"code","eff0b1a6":"code","a581ce92":"code","daca2007":"code","f3b3dad8":"code","ec0860b4":"code","fa1a4f34":"code","f4c00f62":"code","20571c94":"code","ad950f7f":"code","c0d109fe":"code","478a7cd2":"code","79e5fb9e":"code","3d95ea39":"code","d7cf6b0f":"code","ebe16aca":"code","113c9abc":"code","e9afded6":"code","d526cc66":"code","d698bf89":"code","9886ba8a":"code","77cc0038":"code","88c012bd":"code","55bb6492":"code","e2aaa4f3":"code","239c7974":"code","a506829d":"code","e1f99c2e":"code","e8e66904":"code","d82d5978":"code","bbfdb2a0":"code","a5e57145":"code","33d2f9e5":"code","7139260b":"code","32479229":"code","b7d14f71":"code","e2b633e0":"code","cc5b1a1f":"code","42b7fe23":"code","a6bd7517":"code","fb53cf48":"code","42f2336c":"code","aa1be55e":"code","63a83dd0":"code","652240bb":"code","5d5f3901":"code","a8d322ab":"code","bac7714f":"code","c54560d7":"code","c4ca3b34":"code","33274b63":"code","b9375ab4":"code","b184a63e":"code","e844c4f5":"code","85bebbef":"code","a32446bb":"code","ccd19345":"code","f49210ac":"code","496c86f0":"code","c0bf8d9c":"code","fe442f4c":"code","3ec83bce":"code","96da8fb7":"code","ddf44877":"code","eb593765":"code","baf74b9e":"code","9f82aa24":"code","94fd8a8c":"code","5246f9df":"code","b80a0f0d":"code","06db9672":"code","939516bb":"code","bf0f66d7":"markdown","649ed2f1":"markdown","4e0ce009":"markdown","526470f6":"markdown","99b73f0e":"markdown","66ade7d6":"markdown","a901ede4":"markdown","80da5c96":"markdown","99f14be0":"markdown","ee0d692b":"markdown","71651720":"markdown","c0d67aa8":"markdown","d35b19b2":"markdown","70bf7a33":"markdown","54e2e12a":"markdown","773fefff":"markdown","19880fb3":"markdown","deef0332":"markdown","514ff770":"markdown","dc005ec0":"markdown"},"source":{"05c4f217":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom shapely.geometry import LineString\nimport warnings\nwarnings.filterwarnings(\"ignore\")","05a9c56e":"bank_data = pd.read_csv(\"\/kaggle\/input\/bank-term-deposit\/bank-full.csv\",sep = \";\")\nbank_data.head()","64f4d222":"#rename the column 'y' to 'target'\nbank_data.rename(columns={\"y\": \"target\"},inplace = True)","1d1b1ebd":"bank_data.shape","7fca3085":"bank_data.info()","8d36c727":"#Check if any entry is null\nbank_data.isnull().sum()","fdbd762b":"bank_data.describe()","bd620f22":"bank_data.columns","bca5c57e":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,20])\ncols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(4,2,cnt)\n    sns.distplot(bank_data[col], hist_kws=dict(edgecolor=\"k\", linewidth=1,color='grey'), color='red')\n    cnt+=1\n    plot_name = \"Data distribution of column : \"+col\n    ax.set_title(plot_name,fontsize = 15)\nplt.tight_layout()\nplt.show() ","6912a27b":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,15])\ncols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(4,2,cnt)\n    sns.boxplot(bank_data[col])\n    cnt+=1\n    plot_name = \"IQR for column : \"+col\n    ax.set_title(plot_name,fontsize = 15)\nplt.tight_layout()\nplt.show() ","2ae79717":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,15])\ncols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(3,2,cnt)\n    sns.violinplot(data = bank_data,x = col, y='target')\n    cnt+=1\n    plot_title = \"Data distribution of \"+col+\" for output labels\"\n    ax.set_title(plot_title,fontsize = 15)\nplt.tight_layout()\nplt.show() ","fedd708e":"g = sns.pairplot(data = bank_data,hue = \"target\",diag_kws={'bw': 0.2})\ng.fig.suptitle(\"Pairplot of numerical columns in the dataset\",y = 1)\nplt.show()","b848714d":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,20])\ncols = ['marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'job', 'target']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(5,2,cnt)\n    sns.countplot(data = bank_data, x = col, order = bank_data[col].value_counts().index)\n    if col == 'job' :\n        plt.xticks(rotation = 90)\n    cnt+=1\n    plot_name = \"Countplot for column : \"+col\n    ax.set_title(plot_name,fontsize = 15)\nplt.tight_layout()\nplt.show()  ","afe671e8":"bank_data.target.value_counts()","542009ec":"bank_data.target.value_counts().plot(kind = 'pie', autopct='%.2f')\nplt.title(\"Target variable percentage\",fontsize = 15)\nplt.show()","47f417c6":"bank_data_yes = bank_data[bank_data.target == 'yes']\nbank_data_yes.head()","9ca1bd02":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,20])\ncols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(4,2,cnt)\n    sns.distplot(bank_data_yes[col], hist_kws=dict(edgecolor=\"k\", linewidth=1,color='grey'), color='red')\n    cnt+=1\n    plot_name = \"Data distribution of column : '\"+col+\"' for target label 1\"\n    ax.set_title(plot_name,fontsize = 15)\nplt.tight_layout()\nplt.show() ","13e30dc4":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,15])\ncols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(4,2,cnt)\n    sns.boxplot(bank_data_yes[col])\n    cnt+=1\n    plot_name = \"IQR for column : \"+col\n    ax.set_title(plot_name,fontsize = 15)\nplt.tight_layout()\nplt.show() ","19e2d7dd":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize = [15,20])\ncols = ['marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'job']\ncnt = 1\nfor col in cols :\n    ax = plt.subplot(5,2,cnt)\n    sns.countplot(data = bank_data_yes, x = col, order = bank_data_yes[col].value_counts().index)\n    if col == 'job' :\n        plt.xticks(rotation = 90)\n    plot_name = \"Countplot for column : '\"+col+\"' for target label 1\"\n    ax.set_title(plot_name,fontsize = 15)\n    cnt+=1\nplt.tight_layout()\nplt.show()  ","6019e7f8":"# List of variables to map\n\nvarlist =  ['housing', 'loan', 'default', 'target']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'yes': 1, \"no\": 0})\n\n# Applying the function to the housing list\nbank_data[varlist] = bank_data[varlist].apply(binary_map)","1a570cac":"bank_data.head()","32f95a3e":"def month_converter(month):\n    months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n    return months.index(month) + 1","d43d0ec6":"bank_data.month = bank_data.month.apply(month_converter)\nbank_data.head()","2e83be4b":"# correlation matrix \nplt.figure(figsize = (20,10))        \nsns.heatmap(bank_data.corr(),annot = True, fmt='.2f')\nplt.yticks(rotation=0) \nplt.show()","555bc995":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy = pd.get_dummies(bank_data[['marital', 'education', 'contact', 'poutcome', 'job']], drop_first=True)\n\n# Adding the results to the master dataframe\nbank_data = pd.concat([bank_data, dummy], axis=1)","fbd343d4":"bank_data.shape","9dd6ad48":"# We have created dummies for the below variables, so we can drop them\nbank_data = bank_data.drop(['marital', 'education', 'contact', 'poutcome', 'job'], 1)\nbank_data.shape","770426fb":"df_train,df_test = train_test_split(bank_data, train_size=0.7, test_size=0.3, random_state=0)\ndf_train.to_csv('df_train.csv',index = None)","a724a50a":"scaler = StandardScaler()\ncols = ['age','balance','day','month','duration','campaign', 'pdays', 'previous']\nbank_data[cols] = scaler.fit_transform(bank_data[cols])\nbank_data.head()","65273b68":"bank_data.info()","262ed432":"def logReg(x,y) :\n    X_train_sm = sm.add_constant(x)\n    logm1 = sm.GLM(y,X_train_sm, family = sm.families.Binomial())\n    res = logm1.fit()\n    return res","372ee108":"def get_classification_report(res, y_df, X_df, prob) :\n    y_df_pred = res.predict(X_df)#.values.reshape(-1)\n    y_df_pred_final = pd.DataFrame({'Target':y_df.values, 'Target_Prob':y_df_pred})\n    y_df_pred_final['predicted'] = y_df_pred_final.Target_Prob.map(lambda x: 1 if x > prob else 0)\n    #print(classification_report(y_df_pred_final.Target, y_df_pred_final.predicted))\n    return y_df_pred_final","e6610d2c":"def precision_recall(actual,predicted) :\n    recall = round(recall_score(actual,predicted),2)\n    print(\"precision : \",round(precision_score(actual,predicted),2))\n    print(\"recall : \",recall)\n    return recall","10761cf3":"def get_confusion_matrix(actual,predicted) :\n    cm = confusion_matrix(actual,predicted)\n    df = pd.DataFrame(cm)\n    return df","935560a7":"df = bank_data.copy()\nX = df.drop('target',axis = 1)\ny = df['target']\nX_aux, X_test, y_aux, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\nX_train, X_val, y_train, y_val = train_test_split(X_aux, y_aux, train_size=0.75, test_size=0.25, random_state=0)","00af8f87":"res = logReg(X_train,y_train)\nres.summary()","dc5146bd":"def get_vif(X_train) :\n    vif = pd.DataFrame()\n    vif['Features'] = X_train.columns\n    vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return vif","e60b0fcc":"get_vif(X_train)","47c83adf":"X_train_new = X_train.drop(['poutcome_unknown'],axis = 1)\nX_val_new = X_val.drop(['poutcome_unknown'],axis=1)\nX_test_new = X_test.drop(['poutcome_unknown'],axis = 1)\nres = logReg(X_train_new,y_train)","7d473279":"get_vif(X_train_new)","19947de7":"y_df_pred_final = get_classification_report(res,y_train,sm.add_constant(X_train_new),0.5)\nprecision_recall(y_df_pred_final.Target,y_df_pred_final.predicted)","7619a578":"y_df_pred_final","760863be":"def output_for_probability_range(target, target_prob) :\n    y_df_pred_final = pd.DataFrame({'Target':target, 'Target_Prob':target_prob})\n    numbers = [float(x)\/10 for x in range(10)]\n    for i in numbers:\n        y_df_pred_final[i]= y_df_pred_final.Target_Prob.map(lambda x: 1 if x > i else 0)\n        \n    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n    num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n    for i in num:\n        cm1 = metrics.confusion_matrix(y_df_pred_final.Target, y_df_pred_final[i] )\n        total1=sum(sum(cm1))\n        accuracy = (cm1[0,0]+cm1[1,1])\/total1\n        speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n        sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n    return cutoff_df","bac32cd1":"cutoff_df = output_for_probability_range(y_df_pred_final.Target,y_df_pred_final.Target_Prob)\ncutoff_df","882b567b":"def get_optimal_threshold_curve(cutoff_df) :\n    x = cutoff_df.prob\n    f = cutoff_df.accuracy\n    g = cutoff_df.sensi\n    h = cutoff_df.speci\n\n    plt.plot(x, f, '-',label = 'accuracy')\n    plt.plot(x, g, '-',label = 'sensitivity')\n    plt.plot(x, h, '-',label = 'specificity')\n\n    first_line = LineString(np.column_stack((x, f)))\n    second_line = LineString(np.column_stack((x, g)))\n    intersection = first_line.intersection(second_line)\n    plt.xticks(np.arange(0, 1, step=0.1))\n    plt.plot(*intersection.xy, 'o')\n    plt.legend()\n    plt.grid()\n    plt.savefig('optimal_probability_graph.png', bbox_inches='tight')\n    plt.show()\n    x,y = intersection.xy\n    prob_threshold = list(x)[0]\n    return prob_threshold","31498f55":"prob_threshold = get_optimal_threshold_curve(cutoff_df)\nprob_threshold","b8f0d677":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.grid()\n    plt.legend(loc=\"lower right\")\n    plt.savefig('Receiver_Operating_Characteristic.png', bbox_inches='tight')\n    plt.show()\n\n    return None","32916d30":"y_train_pred_final = get_classification_report(res, y_train, sm.add_constant(X_train_new), prob_threshold)\ndraw_roc(y_train_pred_final.Target, y_train_pred_final.Target_Prob)","327dfb24":"precision_recall(y_train_pred_final.Target, y_train_pred_final.predicted)","4ef7ed97":"X_val_sm = sm.add_constant(X_val_new)\ny_pred_lr = res.predict(X_val_sm)\ny_df_pred_final = get_classification_report(res, y_val, X_val_sm, prob_threshold)","eff0b1a6":"recall_lr = precision_recall(y_df_pred_final.Target, y_df_pred_final.predicted)","a581ce92":"X_test_sm = sm.add_constant(X_test_new)\ny_pred_lr = res.predict(X_test_sm)\ny_df_pred_final = get_classification_report(res, y_test, X_test_sm, prob_threshold)","daca2007":"precision_recall(y_df_pred_final.Target, y_df_pred_final.predicted)","f3b3dad8":"get_confusion_matrix(y_df_pred_final.Target, y_df_pred_final.predicted)","ec0860b4":"params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}","fa1a4f34":"elasticnet = ElasticNet()\nfolds = 5\n# cross validation\nmodel_cv = GridSearchCV(estimator = elasticnet, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","f4c00f62":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results.head()","20571c94":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(np.log10(cv_results['param_alpha']), cv_results['mean_train_score'])\nplt.plot(np.log10(cv_results['param_alpha']), cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.grid()\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","ad950f7f":"model_cv.best_estimator_","c0d109fe":"alpha = model_cv.best_estimator_.alpha\nelasticnet = ElasticNet(alpha=alpha)       \nelasticnet.fit(X_train, y_train) \nelasticnet.coef_","478a7cd2":"y_pred_reg = elasticnet.predict(X_test)\nprint(\"Mean squared error with LogReg : \",np.round(metrics.mean_squared_error(y_test,y_pred_lr),2))\nprint(\"Mean squared error with Regularization : \",np.round(metrics.mean_squared_error(y_test,y_pred_reg),2))","79e5fb9e":"print(\"R2 score with LogReg : \",np.round(metrics.r2_score(y_test,y_pred_lr),2))\nprint(\"R2 score with Regularization : \",np.round(metrics.r2_score(y_test,y_pred_reg),2))","3d95ea39":"y_df_pred_final_reg = get_classification_report(elasticnet, y_test, X_test, prob_threshold)\nprecision_recall(y_df_pred_final_reg.Target, y_df_pred_final_reg.predicted)","d7cf6b0f":"get_confusion_matrix(y_df_pred_final_reg.Target, y_df_pred_final_reg.predicted)","ebe16aca":"# Create a Decision Tree\ndt_basic = DecisionTreeClassifier(max_depth=10)\ndt_basic","113c9abc":"# Fit the training data\ndt_basic.fit(X_train,y_train)","e9afded6":"# Predict based on test data\ny_preds = dt_basic.predict(X_val)","d526cc66":"precision_recall(y_val,y_preds)","d698bf89":"# Calculate the number of nodes in the tree\ndt_basic.tree_.node_count","9886ba8a":"dt_basic.tree_.max_depth","77cc0038":"# Create a Parameter grid\nparam_grid = {\n    'classification__max_depth' : range(10,16),\n    'classification__min_samples_leaf' : range(5,60,5),\n    'classification__min_samples_split' : range(5,60,5),\n    'classification__criterion' : ['gini','entropy'],\n    'classification__max_features' : ['auto','sqrt','log2']\n}","88c012bd":"n_folds = 4","55bb6492":"# Create a Decision Tree\ndtree = DecisionTreeClassifier()","e2aaa4f3":"model = Pipeline([\n        ('sampling', SMOTE()),\n        ('classification', dtree)\n    ])","239c7974":"# Create a Grid with parameters\ngrid = GridSearchCV(model, param_grid, cv = n_folds, n_jobs = -1,return_train_score=True,scoring = 'recall')","a506829d":"%%time\ngrid.fit(X_train,y_train)","e1f99c2e":"scores = grid.cv_results_","e8e66904":"cv_result = pd.DataFrame(scores)\ncv_result.head()","d82d5978":"# Plot accuracy vs param_max_depth\nplt.figure\nplt.plot(scores['param_classification__max_depth'].data,scores['mean_train_score'], label = \"training_accuracy\")\nplt.plot(scores['param_classification__max_depth'].data,scores['mean_test_score'], label = \"test_accuracy\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.show()","bbfdb2a0":"grid.best_params_","a5e57145":"best_grid = grid.best_estimator_\nbest_grid","33d2f9e5":"best_grid.fit(X_train,y_train)","7139260b":"dtree_prob = best_grid.predict_proba(X_train)","32479229":"cutoff_df = output_for_probability_range(y_train,dtree_prob[:,1])\ncutoff_df","b7d14f71":"prob_threshold_dt = get_optimal_threshold_curve(cutoff_df)\nprob_threshold_dt","e2b633e0":"def get_classification_report_tree(res, y_df, X_df, prob) :\n    y_df_pred = res.predict_proba(X_df)[:,1]\n    y_df_pred_final = pd.DataFrame({'Target':y_df.values, 'Target_Prob':y_df_pred})\n    y_df_pred_final['predicted'] = y_df_pred_final.Target_Prob.map(lambda x: 1 if x > prob else 0)\n    return y_df_pred_final","cc5b1a1f":"dt_y_train_pred_final = get_classification_report_tree(best_grid, y_train, X_train, prob_threshold_dt)\ndraw_roc(dt_y_train_pred_final.Target, dt_y_train_pred_final.Target_Prob)","42b7fe23":"y_val_pred = best_grid.predict(X_val)\nrecall_dt = precision_recall(y_val,y_val_pred)","a6bd7517":"y_preds = best_grid.predict(X_test)\nprecision_recall(y_test,y_preds)","fb53cf48":"get_confusion_matrix(y_test,y_preds)","42f2336c":"rf = RandomForestClassifier(random_state=0, n_estimators=10, max_depth=4)","aa1be55e":"rf.fit(X_train, y_train)","63a83dd0":"y_preds = rf.predict(X_val)\nprecision_recall(y_val,y_preds)","652240bb":"X_train.shape","5d5f3901":"cols = X_train.columns\nlen(cols)","a8d322ab":"# Create the parameter grid based on the results of random search \nparams = {\n    'classification__max_depth': [7,8,10],\n    'classification__min_samples_leaf': range(50,100,10),\n    'classification__max_features': range(4,12,2),\n    'classification__n_estimators': range(20,100,20),\n    'classification__criterion' : ['entropy','gini']\n}","bac7714f":"classifier_rf = RandomForestClassifier(random_state=0, n_jobs=-1)","c54560d7":"model = Pipeline([\n        ('sampling', SMOTE()),\n        ('classification', classifier_rf)\n    ])","c4ca3b34":"# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator=model, param_grid=params, \n                          cv=4, n_jobs=-1, verbose=1)","33274b63":"%%time\ngrid_search.fit(X_train,y_train)","b9375ab4":"rf_best = grid_search.best_estimator_\nrf_best","b184a63e":"rf_best.fit(X_train, y_train)","e844c4f5":"rf_prob = rf_best.predict_proba(X_train)","85bebbef":"cutoff_df = output_for_probability_range(y_train,rf_prob[:,1])\ncutoff_df","a32446bb":"prob_threshold_rf = get_optimal_threshold_curve(cutoff_df)\nprob_threshold_rf","ccd19345":"rf_y_train_pred_final = get_classification_report_tree(rf_best, y_train, X_train, prob_threshold_rf)\ndraw_roc(rf_y_train_pred_final.Target, rf_y_train_pred_final.Target_Prob)","f49210ac":"y_val_pred = rf_best.predict(X_val)\nrecall_rf = precision_recall(y_val,y_val_pred)","496c86f0":"y_preds = rf_best.predict(X_test)\nprecision_recall(y_test,y_preds)","c0bf8d9c":"get_confusion_matrix(y_test,y_preds)","fe442f4c":"weight_lr = 1\/(100 - recall_lr*100)\nweight_dt = 1\/(100 - recall_dt*100)\nweight_rf = 1\/(100 - recall_rf*100)","3ec83bce":"def predict_probability(df) :\n    df_lr = sm.add_constant(df.drop(['poutcome_unknown'],axis = 1))\n    predict_prob_lr = np.array(res.predict(df_lr))\n    predict_prob_dt = best_grid.predict_proba(df)[:,1]\n    predict_prob_rf = rf_best.predict_proba(df)[:,1]\n    return predict_prob_lr,predict_prob_dt,predict_prob_rf","96da8fb7":"def weighted_probability(lr_df,dt_df,rf_df) :\n    size = len(lr_df)\n    weighted_prob = []\n    for i in range(0,size) :\n        prob = weight_lr * lr_df[i] + weight_dt * dt_df[i] + weight_rf * rf_df[i]\n        weighted_prob.append(prob)\n    return weighted_prob","ddf44877":"predict_prob_lr,predict_prob_dt,predict_prob_rf = predict_probability(X_train)","eb593765":"weighted_prob = weighted_probability(predict_prob_lr,predict_prob_dt,predict_prob_rf)","baf74b9e":"cutoff_df = output_for_probability_range(y_train,weighted_prob)\ncutoff_df","9f82aa24":"prob_threshold_ens = get_optimal_threshold_curve(cutoff_df)\nprob_threshold_ens","94fd8a8c":"draw_roc(y_train, weighted_prob)","5246f9df":"predict_prob_lr,predict_prob_dt,predict_prob_rf = predict_probability(X_test)\nweighted_prob = weighted_probability(predict_prob_lr,predict_prob_dt,predict_prob_rf)","b80a0f0d":"y_pred_final = pd.DataFrame({'Target' : y_test, 'Predicted_prob' : weighted_prob})\ny_pred_final['Predicted'] = y_pred_final.Predicted_prob.apply(lambda x : 1 if x >= prob_threshold_ens else 0)\ny_pred_final.head()","06db9672":"precision_recall(y_pred_final.Target,y_pred_final.Predicted)","939516bb":"get_confusion_matrix(y_pred_final.Target,y_pred_final.Predicted)","bf0f66d7":"# Data Preparation","649ed2f1":"### Finding Optimal Probability threshold","4e0ce009":"### VIF","526470f6":"### Converting binary variables (Yes\/No) to 0\/1","99b73f0e":"## Decision Trees","66ade7d6":"There are a lot of outliers in the numerical features for which the target variable value is 'yes' because of which the outliers have not been removed.","a901ede4":"### ROC ","80da5c96":"### Analysis of features for target == yes","99f14be0":"### Creating dummy variables for categorical data [One-hot encoding] ","ee0d692b":"### Converting month to numerical column","71651720":"Since the aim is to identify maximum number of users who will be willing to opt for 'term deposit' plan, we need to reduce the number of False Negatives predicted by a model. Thus the model used should have high 'recall'.","c0d67aa8":"## Regularization","d35b19b2":"### Feature Scaling","70bf7a33":"## Logistic Regression","54e2e12a":"## Ensemble","773fefff":"### Hyper-parameter tuning [RF]","19880fb3":"### Hyperparameter tuning Optimization [DT]","deef0332":"# Model Training","514ff770":"# EDA","dc005ec0":"## Random Forest"}}