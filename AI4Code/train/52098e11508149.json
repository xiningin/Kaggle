{"cell_type":{"9c9ad1dd":"code","84e7326a":"code","6629e4a9":"code","4850b3c3":"code","d8098dbd":"code","1f05620c":"code","3d794f9f":"code","5dc2b3ff":"code","7518b145":"code","1998d0ce":"code","cd41dc08":"code","dddd15bd":"code","d3e24d7f":"code","d9266b0a":"code","189459e7":"code","37f2bc96":"code","6d728488":"code","80354beb":"code","0443af60":"code","f9623676":"code","e1eaa79b":"code","e0bc3b79":"code","d3ddc453":"code","a54e5ebc":"markdown","72724252":"markdown","7bd93f29":"markdown","eec6b527":"markdown","432dc24a":"markdown","664bfa09":"markdown","b9ca9678":"markdown","889e01c6":"markdown","024774ff":"markdown","c4594e8d":"markdown"},"source":{"9c9ad1dd":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\ninit_notebook_mode(connected=True)\n\nimport re\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        continue\n        print(os.path.join(dirname, filename))\n        \nimport colorlover as cl\nfrom IPython.display import HTML\n\nimport collections","84e7326a":"train = pd.read_csv('\/kaggle\/input\/web-traffic-time-series-forecasting\/train_1.csv')","6629e4a9":"print(train.shape)","4850b3c3":"train.head(10)","d8098dbd":"train.columns","1f05620c":"train.iloc[34436].Page","3d794f9f":"def missingData(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum())\/df.isnull().count().sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\n    return missing_data","5dc2b3ff":"missingData(train).head(20)","7518b145":"missingData(train).tail(10)","1998d0ce":" sns.distplot(np.log1p(train.drop(columns='Page').sum(axis=1)), rug=True, kde=False)","cd41dc08":"data = [\n    go.Histogram(\n        x=np.log1p(train.drop(columns='Page').sum(axis=1))\/np.log(10),\n        histnorm='probability'\n    )\n]\n\n\nlayout = dict(\n            title='Distribution of page views',\n            autosize= True,\n            bargap= 0.015,\n            height= 400,\n            width= 600,       \n            hovermode= 'x',\n            xaxis=dict(\n            autorange= True,\n            zeroline= False,\n            tickvals=[0,1,2, 3, 4,5, 6, 7,8, 9,10],\n            ticktext=['10$^0$', '10$^1$', '10$^2$', '10$^3$', '10$^4$', '10$^5$','10$^6$', '10$^7$','10$^8$','10$^9$', '10$^{10}$',]),\n            yaxis= dict(\n            autorange= True,\n            showticklabels= True,\n           ))\n\nfig1 = dict(data=data, layout=layout)\n\n\niplot(fig1)\n","dddd15bd":"fig = go.Figure()\n\nfig.add_trace(\n    go.Histogram(\n        x = np.log1p(train.drop(columns='Page').sum(axis=1)),\n        histnorm='probability',\n        name = 'Training set')\n)\n\n\nfig.update_layout(height=450, width=900, title = 'Distribution of total no. views')\n\nfig.show()","d3e24d7f":"webpage = train.iloc[11214]\nwebpage_name = webpage['Page']\nwebpage = webpage.drop(labels = ['Page', 'lang'])\ndomnhall_gleeson = we\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage,\n        name='signal', \n        line = dict(color='crimson', width=4)\n        )\n)\n\n\"\"\"\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage.rolling(14).mean(),\n        name='2-week rolling average', \n        line = dict(color='crimson', width=4)\n        )\n)\n\"\"\"    \n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=webpage_name,\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Daily Traffic\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","d9266b0a":"webpage = train.iloc[34436]\nwebpage_name = webpage['Page']\nwebpage = webpage.drop(labels = ['Page'])\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage,\n        name='signal', \n        line = dict(color='crimson', width=4)\n        )\n)\n\n\"\"\"\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage.rolling(14).mean(),\n        name='2-week rolling average', \n        line = dict(color='crimson', width=4)\n        )\n)\n\"\"\"    \n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=webpage_name,\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Daily Traffic\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","189459e7":"webpage = train.iloc[4436]\nwebpage_name = webpage['Page']\nwebpage = webpage.drop(labels = ['Page'])\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage,\n        name='signal', \n        line = dict(color='crimson', width=4)\n        )\n)\n\n\"\"\"\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage.rolling(14).mean(),\n        name='2-week rolling average', \n        line = dict(color='crimson', width=4)\n        )\n)\n\"\"\"    \n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=webpage_name,\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Daily Traffic\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","37f2bc96":"npages = 5\ntop_pages = {}\nfor key in lang_sets:\n    print(key)\n    sum_set = pd.DataFrame(lang_sets[key][['Page']])\n    sum_set['total'] = lang_sets[key].sum(axis=1)\n    sum_set = sum_set.sort_values('total',ascending=False)\n    print(sum_set.head(10))\n    top_pages[key] = sum_set.index[0]\n    print('\\n\\n')","6d728488":"def get_language(page):\n    res = re.search('[a-z][a-z].wikipedia.org', page)\n    if res:\n        return res[0][0:2]\n    return 'na'\n\ntrain['lang'] = train.Page.map(get_language)\n\nfrom collections import Counter\n\nlanguages = pd.DataFrame.from_dict(dict(Counter(train.lang)), orient='index', columns=['Count'])\n\nfig = go.Figure([go.Bar(x=languages.index, y=languages.Count, marker_color='crimson')])\n\nfig.update_layout(\n    title=go.layout.Title(\n        text=\"Wikipage total counts per language\",\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            text=\"Language\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Number of Webpages\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n\nfig.update_xaxes( tickfont=dict(size=16))\nfig.update_yaxes( tickfont=dict(size=16))\n\n\nfig.show()","80354beb":"lang_sets = {}\n\nfor language in languages.index:\n    print(language)\n    lang_sets[language] = train[train.lang==language].iloc[:,0:-1]\n    lang_sets[language].index = pd.to_datetime(lang_sets[language].index)\n    \nsums = {}\nfor language in lang_sets:\n    sums[language] = lang_sets[language].iloc[:,1:].sum(axis=0)\/lang_sets[language].shape[0]\n\noffset = collections.defaultdict(int)\noffset['en'] = 1000\noffset['ru'] =  3000\noffset['es'] = 1800\noffset['de'] = 1300\noffset['ja'] = 1000\noffset['fr'] = 600\noffset['zh'] = 300","0443af60":"lang_dict = {'zh': 'Chinese', 'fr': 'French', 'en': 'English', 'ru': 'Russian', 'de': 'German', 'ja': 'Japanese', 'es': 'Spanish', 'na': 'Other'}","f9623676":"#cl.scales['7']\n#HTML(cl.to_html( cl.scales['8'] )) # All scales with 11 colors","e1eaa79b":"fig = go.Figure()\n\ncolorscale = cl.scales['8']['qual']['Set1']\ni=0\nfor language in sums.keys():\n    if offset[language]: name=lang_dict[language] + '(+' + str(offset[language])+')'\n    else: name = lang_dict[language] \n    fig.add_trace(\n        go.Scatter(\n        x = sums[language].index,\n        y = sums[language] + offset[language],\n        name=name , \n        line = dict(color=colorscale[i], width=4)\n        )\n    )\n    i+=1\n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=\"Time Series of Webpage Traffic in different languages (offsets for clarity)\",\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            text=\"Language\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Aggregate Number of Views\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","e0bc3b79":"npages = 5\ntop_pages = {}\nfor key in lang_sets:\n    print(key)\n    sum_set = pd.DataFrame(lang_sets[key][['Page']])\n    sum_set['total'] = lang_sets[key].sum(axis=1)\n    sum_set = sum_set.sort_values('total',ascending=False)\n    print(sum_set.head(10))\n    top_pages[key] = sum_set.index[0]\n    print('\\n\\n')","d3ddc453":"from statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import acf","a54e5ebc":"I have a function that computes the number of missing values per column. There appear to be quite a few of those in this dataset, and they'll need to be dealt with!","72724252":"### 0.0 Load libraries","7bd93f29":"### Periodicities with FFT","eec6b527":"The dataset consists of time series for a decently large number of pages. The first thing I did to explore the data was look at random at the time series for particular entries. ","432dc24a":"### Missing values","664bfa09":"## Most popular webpages","b9ca9678":"## Individual Webpages","889e01c6":"## Global features: Page Language","024774ff":"I'm reusing [muonneutrino's function](https:\/\/www.kaggle.com\/muonneutrino\/wikipedia-traffic-data-exploration) for computing the language of a webpage.","c4594e8d":"### 0.1 Load dataset"}}