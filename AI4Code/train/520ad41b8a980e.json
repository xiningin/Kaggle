{"cell_type":{"4d479a9f":"code","b759c1db":"code","fab55362":"code","35895d4e":"code","f5d91426":"code","f11f0385":"code","3d9aeade":"code","370bab56":"code","c107cbac":"code","30fd9cbb":"code","51e60c53":"code","650dcfb9":"code","3de286ac":"code","3cd386b4":"code","b6c35252":"code","74f96c2c":"code","7b2aaf07":"code","7d1e5764":"code","e4602198":"code","a260b9ae":"code","2ee15cdb":"code","e62a9b73":"code","54ca0c7a":"code","41ef2f7c":"code","e35ffb73":"code","495f2ff0":"code","0ddfa432":"code","7d0448b4":"code","e76a6f2f":"code","473311ef":"code","a4cfbb5b":"code","c9079709":"code","dbed7383":"code","9deb0649":"code","8a33f634":"code","292ab621":"code","f95e2aa8":"code","a4ed30b8":"code","288701be":"code","3500624e":"code","d4f4d76a":"code","a5660e70":"markdown","9a3e07e3":"markdown","e59bd598":"markdown","a63ac371":"markdown","e4862300":"markdown","97a32168":"markdown","3cc521c8":"markdown","cf333950":"markdown","7b486fa3":"markdown","fcb33db5":"markdown","658f0d47":"markdown","44327818":"markdown","3b85471e":"markdown","b60cc5bc":"markdown","297ab672":"markdown","649ec52c":"markdown","df6cf777":"markdown","a17014a3":"markdown","711cf309":"markdown","e5f0054e":"markdown","2c8960dc":"markdown","f3e6a1b9":"markdown","8fae46db":"markdown","e90feda3":"markdown"},"source":{"4d479a9f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n\nimport folium\nimport re\n\n# silhouette_score To select the appropriate number of clusters\nfrom sklearn.metrics import silhouette_score\n# kneed will return the knee point of the function.\n# The knee point is the point of maximum curvature\nfrom kneed import KneeLocator","b759c1db":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fab55362":"data = pd.read_csv('..\/input\/taxi-data\/taxi_data.csv')","35895d4e":"data.info()","f5d91426":"# Let's check if there are any duplicates\nduplicatedv = data.duplicated(subset = ['LON', 'LAT']).values.sum()\nprint('{:d} duplicate values'.format(duplicatedv))","f11f0385":"# Remove duplicates and null values\ndata.drop_duplicates(\n    subset=['LON','LAT'],\n    keep='first',\n    inplace=True\n)\ndata.dropna(inplace=True)\n# Let's check duplicates and null values\nduplicatedv_ = data.duplicated(subset = ['LON', 'LAT']).values.sum()\nnullv_ = data.isna().values.sum()\nprint('{:d} valeurs dupliqu\u00e9es'.format(duplicatedv_))\nprint('{:d} valeurs nulles'.format(nullv_))","3d9aeade":"data.info()","370bab56":"data.head()","c107cbac":"X = data[['LAT', 'LON']].values\nmap = folium.Map(\n    location = [X[:, 0].mean(), X[:, 1].mean()],\n    zoom_start = 10\n)","30fd9cbb":"for _, row in data.iterrows():\n  folium.CircleMarker(\n      location = [row.LAT, row.LON],\n      radius = 5,\n      popup = re.sub(r'\\W+', '', row.NAME),\n      fill = True,\n  ).add_to(map)","51e60c53":"map","650dcfb9":"# Choose the best number of clusters using silhouette method\nscore = -1\nscores = []\nk = 0\nfor i in range(2, 101):\n  kmeans = KMeans(n_clusters=i, random_state=0).fit(X)\n  score_ = silhouette_score(X, kmeans.predict(X))\n  scores.append(score_)\n  if score_ > score:\n    score = score_\n    k=i","3de286ac":"print(\n'Best number of clusters is {} with a score of {:.2f}'\n.format(k,score)\n)\nplt.plot(range(2, 101), scores)\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette score')\nplt.xticks(np.arange(0, 101, 5))\nplt.show()","3cd386b4":"# Choose the best number of clusters using Elbow method\ninertia = []\nfor i in range(1, 101):\n  kmeans = KMeans(n_clusters=i, random_state=0).fit(X)\n  inertia.append(kmeans.inertia_)\nplt.plot(range(1, 101), inertia)\nplt.title('Elbow')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertie')\nplt.xticks(np.arange(0, 101, 5))\nplt.show()","b6c35252":"knee_point = KneeLocator(\n    range(1, 101),\n    inertia,\n    curve = 'convex',\n    direction = 'decreasing'\n)\nprint(knee_point.knee)","74f96c2c":"kmeans = KMeans(n_clusters=11, random_state=0).fit(X)\ninertia_ = kmeans.inertia_\nsilhouette_ = silhouette_score(X, kmeans.labels_)\nprint(\"This model with 11 cluster is characterized by :\")\n# Iinertia is sum of squared distances of samples to their closest cluster center.\nprint(\"Iinertia : {:.3f}\".format(inertia_))\nprint(\"Silhouette mean score : {:.3f}\".format(silhouette_))","7b2aaf07":"data['Cluster_KMeans'] = kmeans.labels_\ndata.head()","7d1e5764":"# Show results\ncolors = ['royalblue', 'maroon', 'forestgreen', 'mediumorchid', 'tan',\n          'deeppink', 'olive', 'goldenrod', 'lightcyan', 'navy',\n          'springgreen','midnightblue', 'red','brown','limegreen','lime',\n          'pink','orchid','crimson','m']*10\nvectorizer = np.vectorize(lambda x: colors[x % len(colors)])\ndata['Colors_KMeans'] = vectorizer(kmeans.labels_)\ndef create_map(cluster_column, colors_column, title):\n    map = folium.Map(location=[X[:,0].mean(),X[:,1].mean()],zoom_start=8.5)\n    for _,row in data.iterrows():\n        folium.CircleMarker(\n            location=[row.LAT,row.LON],\n            radius=5,\n            popup = re.sub(r'\\W+', '', row.NAME),\n            fill=True,\n            color=row[colors_column],\n            fill_color=row[colors_column],\n        ).add_to(map)\n\n    print(title)\n    return map","e4602198":"create_map('Cluster_KMeans','Colors_KMeans','KMeans Clustering')","a260b9ae":"nearest_neighbors = NearestNeighbors(n_neighbors=7)\nneighbors = nearest_neighbors.fit(X)\ndistances, indices = neighbors.kneighbors(X)\ndistances = np.sort(distances[:, 5], axis=0)","2ee15cdb":"i = np.arange(len(distances))\nknee = KneeLocator(\n    i, distances, S=1,\n    curve='convex',\n    direction='increasing',\n    interp_method='polynomial'\n)\nfig = plt.figure(figsize=(5, 5))\nknee.plot_knee()\nplt.xlabel(\"Points\")\nplt.ylabel(\"Distance\")\nplt.show()","e62a9b73":"EPS = round(distances[knee.knee],3)\nprint('The elbow point is at around {}'.format(EPS))","54ca0c7a":"dbscan = DBSCAN(eps = EPS)\ndbscan.fit(X)\ndbscan_predictions = dbscan.labels_\ndata['Cluster_DBSCAN'] = dbscan_predictions\nvectorizer = np.vectorize(\n    lambda x: colors[x % len(colors)]\n)\ndata['Colors_DBSCAN'] = vectorizer(dbscan_predictions)","41ef2f7c":"create_map('Cluster_DBSCAN','Colors_DBSCAN','DBSCAN eps={}'.format(EPS))","e35ffb73":"round(silhouette_score(X,dbscan_predictions),2)","495f2ff0":"n_of_clusters = len(np.unique(dbscan_predictions))\nn_of_outliers = len(dbscan_predictions[dbscan_predictions==-1])\nprint('Number of clusters is: {}'.format(n_of_clusters))\nprint('Number of outliers is: {}'.format(n_of_outliers))\noutliers = [\n    (counter+2)*x if x == -1 else x\n    for counter,x in enumerate(dbscan_predictions)\n]\n\nign_outliers_score = silhouette_score(\n    X[dbscan_predictions != -1],\n    dbscan_predictions[dbscan_predictions != -1]\n)\noutliers_singl_score = silhouette_score(X,outliers)\n                                                                       \nprint(\n    'Silhouette score without outliers: {:.2f}'\n    .format(ign_outliers_score)\n    )\nprint(\n    'Silhouette score with outliers: {:.2f}'\n    .format(outliers_singl_score)\n    )","0ddfa432":"scores_no_outlier = []\nscores_with_outlier = []\nmax_score = 0\nbest_eps = 0\nfor i in np.arange(0.15, 0, -0.005):\n  dbscan = DBSCAN(eps = i)\n  dbscan.fit(X)\n  dbscan_predictions = dbscan.labels_\n  score_without_outlier = silhouette_score(\n      X[dbscan_predictions != -1],\n      dbscan_predictions[dbscan_predictions != -1]\n  )\n  scores_no_outlier.append(score_without_outlier)\n  outliers = [\n              (counter+2)*x if x==-1 else x \n              for counter,x in enumerate(dbscan_predictions)\n              ]\n  scores_with_outlier.append(silhouette_score(X,outliers))\n  if score_without_outlier > max_score:\n        max_score = score_without_outlier\n        best_eps = i","7d0448b4":"plt.figure(figsize=(10,6))\nplt.plot(np.arange(0.15,0,-0.005),scores_no_outlier)\nplt.xlabel('Epsilon')\nplt.ylabel('Silhouette Score')\nplt.title('Scores without outliers')\nplt.show()","e76a6f2f":"print(\n    'Highest score = {} obtained for epsilon = {}'\n    .format(round(max_score,3),round(best_eps,3))\n)","473311ef":"dbscan = DBSCAN(eps=0.01)\ndbscan.fit(X)\ndbscan_predictions = dbscan.labels_\ndata['Cluster_DBSCAN_OPT'] = dbscan_predictions\nvectorizer = np.vectorize(lambda x: colors[x % len(colors)])\ndata['Colors_DBSCAN_OPT'] = vectorizer(dbscan_predictions)","a4cfbb5b":"create_map('Cluster_DBSCAN_OPT','Colors_DBSCAN_OPT','DBSCAN OPT')","c9079709":"print('Number of clusters: {}'\n  .format(len(np.unique(dbscan_predictions))))\nprint('Number of outliers: {}'\n  .format(len(dbscan_predictions[dbscan_predictions==-1])))\noutliers=[\n          (counter+2)*x if x==-1 else x \n          for counter,x in enumerate(dbscan_predictions)]\nprint('Silhouette score without outliers: {}'\n  .format(\n      silhouette_score(X[dbscan_predictions!=-1],\n      dbscan_predictions[dbscan_predictions!=-1])))\nprint('Silhouette score with outliers: {}'\n  .format(silhouette_score(X,outliers)))","dbed7383":"X_train = data[data['Cluster_DBSCAN_OPT'] != -1][['LON', 'LAT']]\ny_train = data[data['Cluster_DBSCAN_OPT'] != -1][['Cluster_DBSCAN_OPT']]\nX_pred = data[data['Cluster_DBSCAN_OPT'] == -1][['LON', 'LAT']]","9deb0649":"print('Dimensions matrix: X_train ')\nprint(X_train.head())","8a33f634":"print('Labels vector: y_train')\nprint(y_train.head())","292ab621":"print('Samples to be classified: X_pred')\nprint(X_pred.head())","f95e2aa8":"# Before we use the model, let us first check\n# the best number of neighbors to use\nscores = []\nfor i in range(1, 11):\n  knc = KNeighborsClassifier(n_neighbors=i)\n  knc.fit(X_train, y_train.values.ravel())\n  scores.append(knc.score(X_train, y_train))\nplt.plot(range(1, 11), scores)\nplt.xticks(np.arange(1, 11, 4))\nplt.show()","a4ed30b8":"KNC = KNeighborsClassifier(n_neighbors=5)\nKNC.fit(X_train, y_train.values.ravel())\nKNC_predictions = KNC.predict(X_pred)","288701be":"data['Cluster_Hybrid'] = data['Cluster_DBSCAN_OPT']\ndata.loc[data['Cluster_DBSCAN_OPT'] == -1, 'Cluster_Hybrid'] = KNC_predictions\nvectorizer = np.vectorize(lambda x: colors[x % len(colors)])\ndata['Colors_Hybrid'] = vectorizer(data['Cluster_Hybrid'].values)","3500624e":"create_map('Cluster_Hybrid','Colors_Hybrid','Hybrid (DBSCAN + KNN)')","d4f4d76a":"print(\n    'Number of clusters: {}'\n    .format(len(np.unique(data['Cluster_Hybrid']))))\nprint(\n    'Silhouette score: {}'\n    .format(round(silhouette_score(X,data['Cluster_Hybrid']),2)))","a5660e70":"### Dataset visualization","9a3e07e3":"From Scikit-Learn documentation:\n*The eps float, default=0.5\nThe maximum distance between two samples for one to be considered\nas in the neighborhood of the other.\nThe eps is proportional to the expected number of neighbours,\nwe can use the nearest neighbors to reach a fair estimation for eps.\nWe still use the kneed library to get the elbow point.*","e59bd598":"silhouette score equal to 0.7 (more than 0.5 and nears 1) is good enough but 99 clusters is a very large number and is not practical.","a63ac371":"Clearly this is an unsupervised problem.","e4862300":"DBSCAN is another clustering algorithm that I find appropriate to use in this problem because we are dealing with geographic data which can have varying cluster shape and density. This algorithm also excludes noise \/ outliers unlike KMeans which uses all dataset samples. But before we do the DBSCAN calculation, we first need to find the most important parameter, epsilon, which is the maximum distance between points to create a cluster. We can find this using the NearestNeighbors algorithm.","97a32168":"### Conclusion","3cc521c8":"The dataset is now clean!","cf333950":"In this problem, we used different clustering techniques. We started with the KMeans algorithm, which is the simplest and fastest clustering algorithm. We have shown that DBSCAN works well on geolocation data, but selecting the epsilon value is critical. We must also remember that the Silhouette score near -1 is the worst and 1 is the best. But Silhouette can only be used as a guide for tuning hyperparameters and not as an absolute metric for whether the cluster is good or not. There is another algorithm better than DBSCAN like **HDBSCAN** which is based on **hierarchical clustering** and is efficient for variable density data which is applicable here because taxi density is higher around town and less far from town .","7b486fa3":"We get highest score by estimating the eps value using the Silhouette. Outliers values are identified as non-clustered values.","fcb33db5":"display geographic data on the map using **folium** library.","658f0d47":"The score using eps = 0.05 which was calculated using the NearestNeighbors estimate is very low. Let's use another method to determine eps.","44327818":"ok, let's take n_neighbors = 5","3b85471e":"The dataset consists of three variables and contains 837 out of 838 non-zero samples.","b60cc5bc":"### ***'The idea here is to combine an unsupervised learning algorithm and a supervised learning algorithm!'***","297ab672":"### DBSCAN","649ec52c":"We can deal with outliers using a hybrid algorithm, DBSCAN + KNearestNeighbors. The idea here is to combine an unsupervised learning algorithm and a supervised learning algorithm. Since we already have cluster groups obtained from DBSCAN, we will rank the outliers using KNN.","df6cf777":"### Semi-supervised Learning","a17014a3":"So, accepting this result.","711cf309":"### Libraries we use","e5f0054e":"### Dataset","2c8960dc":"### KMeans Clustering","f3e6a1b9":"Silhouette equal to 0.29 is not good :(","8fae46db":"First, we will use the simplest clustering method which is the **KMeans** algorithm.","e90feda3":"### Introduction\nThe dataset contains the locations of the taxi rank. In this notebook We will define principles clusters of these taxis to build service stations for all taxis operating in this region."}}