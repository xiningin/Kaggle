{"cell_type":{"51f62d80":"code","621b2041":"code","99aefb48":"code","8c18cdce":"code","e151a7ba":"code","932a490f":"code","c1f7e0e9":"code","7b49b210":"code","7ed32261":"code","81e164d9":"code","c575df89":"code","d3c91ce6":"code","a37a9dbe":"code","30be2a22":"code","a7b4cef4":"code","4a0363df":"code","413f7949":"code","f0d4e0c2":"code","3915a661":"code","df16921e":"code","72fa61a0":"code","b009e84f":"code","d060039a":"code","a3ea3e29":"code","50f9dd3a":"code","6918a837":"code","6dac2fa6":"code","aeeebe64":"code","7d8643db":"code","22aadb96":"code","6d3cd341":"markdown","86807fc8":"markdown","24a0baba":"markdown","d87e7725":"markdown","bef754f5":"markdown","6b4d4cef":"markdown","93d1ef81":"markdown","3cee89b3":"markdown","35f05872":"markdown","059c5262":"markdown","8e37b845":"markdown","6ff6fe09":"markdown","91bdcc2f":"markdown","55011327":"markdown","ff6b86c5":"markdown","46664ffe":"markdown","c26d4014":"markdown","58b37372":"markdown","edee08e6":"markdown","8a8a3ee1":"markdown","351249a2":"markdown","b4f03df6":"markdown","3359a50d":"markdown"},"source":{"51f62d80":"from pathlib import Path\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom tqdm import tqdm\nimport PIL.Image as Image\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom glob import glob\nimport shutil\nfrom collections import defaultdict\n\nimport torch, torchvision\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\n\n%matplotlib inline\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE=[\"#01BEFE\",\"#FFDD00\",\"#FF7D00\",\"#FF006D\",\"#ADFF02\",\"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 15, 10\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","621b2041":"train_folders = sorted(glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/*'))\nlen(train_folders)","99aefb48":"def load_image(img_path, resize=True):\n    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    \n    if resize:\n        img = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA)\n    \n    return img\n\ndef show_image(img_path):\n    img = load_image(img_path)\n    plt.imshow(img)\n    plt.axis('off')\n    \ndef show_sign_grid(image_paths):\n    images = [load_image(img) for img in image_paths]\n    images = torch.as_tensor(images)\n    images = images.permute(0,3,1,2)\n    grid_img = torchvision.utils.make_grid(images, nrow=11)\n    plt.figure(figsize=(24,12))\n    plt.imshow(grid_img.permute(1,2,0))\n    plt.axis('off')","8c18cdce":"sample_images = [np.random.choice(glob(f'{tf}\/*jpg')) for tf in train_folders]\nshow_sign_grid(sample_images)","e151a7ba":"img_path = glob(f'{train_folders[0]}\/*jpg')[1]\n\nshow_image(img_path)","932a490f":"class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n\nclass_indices = [0,1,2,3,4,5]","c1f7e0e9":"!rm -rf data\n\nDATA_DIR = Path('data')\n\nDATASETS = ['train', 'val']\n\nfor ds in DATASETS:\n    for cls in class_names:\n        (DATA_DIR \/ ds \/ cls).mkdir(parents=True, exist_ok=True)","7b49b210":"for i, cls_index in enumerate(class_indices):\n    image_paths = np.array(glob(f'{train_folders[cls_index]}\/*jpg'))\n    class_name = class_names[i]\n    print(f'{class_name}: {len(image_paths)}')\n    np.random.shuffle(image_paths)\n    \n    ds_split = np.split(\n        image_paths,\n        indices_or_sections=[int(.8*len(image_paths)), int(.9*len(image_paths))]\n    )\n    \n    dataset_data = zip(DATASETS, ds_split)\n    for ds, images in dataset_data:\n        for img_path in images:\n            shutil.copy(img_path, f'{DATA_DIR}\/{ds}\/{class_name}\/')","7ed32261":"mean_nums = [0.485, 0.456, 0.406]\nstd_nums = [0.229, 0.224, 0.225]\n\ntransforms = {'train': T.Compose([\n    T.RandomResizedCrop(size=256),\n    T.RandomRotation(degrees=15),\n    T.RandomHorizontalFlip(),\n    T.ToTensor(),\n    T.Normalize(mean_nums, std_nums)\n]), 'val': T.Compose([\n    T.Resize(size=256),\n    T.CenterCrop(size=224),\n    T.ToTensor(),\n    T.Normalize(mean_nums, std_nums)\n]),}","81e164d9":"image_datasets = {\n    d: ImageFolder(f'{DATA_DIR}\/{d}', transforms[d]) for d in DATASETS\n}\n\ndata_loaders = {\n    d: DataLoader(image_datasets[d], batch_size=4, shuffle=True, num_workers=4) for d in DATASETS\n}","c575df89":"dataset_sizes = {d: len(image_datasets[d]) for d in DATASETS}\nclass_names = image_datasets['train'].classes\n\ndataset_sizes","d3c91ce6":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1,2,0))\n    mean = np.array([mean_nums])\n    std = np.array([std_nums])\n    inp = std * inp + mean\n    inp = np.clip(inp,0,1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')\n    \ninputs, classes = next(iter(data_loaders['train']))\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","a37a9dbe":"def create_model(n_classes):\n    model = models.resnet34(pretrained=True)\n    \n    n_features = model.fc.in_features\n    model.fc = nn.Linear(n_features, n_classes)\n    \n    return model.to(device)","30be2a22":"base_model = create_model(len(class_names))","a7b4cef4":"def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n    model = model.train() #Convert to train mode\n    losses = []\n    correct_predictions = 0\n    \n    for inputs, labels in data_loader:\n        inputs = inputs.to(device) #Push array to gpu\n        labels = labels.to(device)\n        \n        outputs = model(inputs) #get prob of output per class\n        \n        _, preds = torch.max(outputs, dim=1) # get max of pred\n        loss = loss_fn(outputs, labels) # get loss\n        \n        correct_predictions += torch.sum(preds==labels)\n        losses.append(loss.item())\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    scheduler.step()\n    \n    return correct_predictions.double() \/ n_examples, np.mean(losses)\n\ndef eval_model(model, data_loader, loss_fn, device, n_examples):\n    model = model.eval() #Evaluation mode\n    \n    losses = []\n    correct_predictions = 0\n    \n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            \n            _, preds = torch.max(outputs, dim=1)\n            \n            loss = loss_fn(outputs, labels)\n            \n            correct_predictions += torch.sum(preds==labels)\n            losses.append(loss.item())\n    \n    return correct_predictions.double() \/ n_examples, np.mean(losses) ","4a0363df":"def train_model(model, data_loaders, dataset_sizes, device, n_epochs=5):\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n    loss_fn = nn.CrossEntropyLoss().to(device)\n    \n    history = defaultdict(list)\n    best_accuracy = 0\n    \n    for epoch in range(n_epochs):\n        print(f'Epoch {epoch + 1}\/{n_epochs}')\n        print('-' * 10)\n        \n        train_acc, train_loss = train_epoch(model, data_loaders['train'], loss_fn, \n                                            optimizer, device, scheduler, dataset_sizes['train'])\n        \n        print(f'Train loss {train_loss} accuracy {train_acc}')\n        \n        val_acc, val_loss = eval_model(model, data_loaders['val'], loss_fn, device, dataset_sizes['val'])\n        \n        print(f'Val loss {val_loss} accuracy {val_acc}')\n        print()\n        \n        history['train_acc'].append(train_acc)\n        history['train_loss'].append(train_loss)\n        history['val_acc'].append(val_acc)\n        history['val_loss'].append(val_loss)\n        \n        if val_acc > best_accuracy:\n            torch.save(model.state_dict(), 'best_model_state.bin')\n            best_accuracy = val_acc\n            \n    print(f'Best val accuracy: {best_accuracy}')\n    \n    model.load_state_dict(torch.load('best_model_state.bin'))\n    \n    return model, history","413f7949":"%%time\n\nbase_model, history = train_model(base_model, data_loaders, dataset_sizes, device, n_epochs=20)","f0d4e0c2":"def plot_training_history(history):\n    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(18,6))\n    ax1.plot(history['train_loss'], label='train loss')\n    ax1.plot(history['val_loss'], label='validation loss')\n    \n    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax1.set_ylim([-0.05,1.05])\n    ax1.legend()\n    ax1.set_ylabel('Loss')\n    ax1.set_xlabel('Epoch')\n    \n    ax2.plot(history['train_acc'], label='train accuracy')\n    ax2.plot(history['val_acc'], label='validation accuracy')\n    \n    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax2.set_ylim([-0.05,1.05])\n    ax2.legend()\n    ax2.set_ylabel('Accuracy')\n    ax2.set_xlabel('Epoch')\n    \n    fig.suptitle('Training History')\n    \nplot_training_history(history)","3915a661":"test_folders = sorted(glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/*'))\nlen(test_folders)","df16921e":"sample_images = [np.random.choice(glob(f'{tf}\/*jpg')) for tf in test_folders]\nshow_sign_grid(sample_images)","72fa61a0":"class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n\nclass_indices = [0,1,2,3,4,5]\n\nDATASETS = ['test']\n\nfor ds in DATASETS:\n    for cls in class_names:\n        (DATA_DIR \/ ds \/ cls).mkdir(parents=True, exist_ok=True)\n        \nfor i, cls_index in enumerate(class_indices):\n    image_paths = np.array(glob(f'{test_folders[cls_index]}\/*jpg'))\n    class_name = class_names[i]\n    print(f'{class_name}: {len(image_paths)}')\n    np.random.shuffle(image_paths)\n    \n    ds_split = np.split(\n        image_paths,\n        indices_or_sections=[int(.8*len(image_paths)), int(.9*len(image_paths))]\n    )\n    \n    dataset_data = zip(DATASETS, ds_split)\n    for ds, images in dataset_data:\n        for img_path in images:\n            shutil.copy(img_path, f'{DATA_DIR}\/{ds}\/{class_name}\/')\n            \nmean_nums = [0.485, 0.456, 0.406]\nstd_nums = [0.229, 0.224, 0.225]\n\ntransforms = {'test': T.Compose([\n    T.Resize(size=256),\n    T.CenterCrop(size=224),\n    T.ToTensor(),\n    T.Normalize(mean_nums, std_nums)\n]),}\n\nimage_datasets = {\n    d: ImageFolder(f'{DATA_DIR}\/{d}', transforms[d]) for d in DATASETS\n}\n\ndata_loaders = {\n    d: DataLoader(image_datasets[d], batch_size=4, shuffle=True, num_workers=4) for d in DATASETS\n}\n\ndataset_sizes = {d: len(image_datasets[d]) for d in DATASETS}\nclass_names = image_datasets['test'].classes\n\ndataset_sizes","b009e84f":"def show_predictions(model, class_names, n_images=6):\n    model = model.eval()\n    images_handeled = 0\n    plt.figure()\n    \n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loaders['test']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            \n            _, preds = torch.max(outputs, 1)\n            \n            for j in range(inputs.shape[0]):\n                images_handeled += 1\n                ax = plt.subplot(2, n_images\/\/2, images_handeled)\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n                ax.axis('off')\n                \n                if images_handeled == n_images:\n                    return\n                \nshow_predictions(base_model, class_names, n_images=8)","d060039a":"def get_predictions(model, data_loader):\n    model = model.eval()\n    predictions = []\n    real_values = []\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            \n            _, preds = torch.max(outputs, 1)\n            predictions.extend(preds)\n            real_values.extend(labels)\n    predictions = torch.as_tensor(predictions).cpu()\n    real_values = torch.as_tensor(real_values).cpu()\n    \n    return predictions, real_values\n\ny_pred, y_test = get_predictions(base_model, data_loaders['test'])\n\nprint(classification_report(y_test, y_pred, target_names=class_names))","a3ea3e29":"!rm -rf data\/pred_test","50f9dd3a":"show_image('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10004.jpg')","6918a837":"def predict_proba(model, img_path):\n    img = Image.open(img_path)\n    img = img.convert('RGB')\n    img = transforms['test'](img).unsqueeze(0)\n    \n    pred = model(img.to(device))\n    pred = F.softmax(pred,1)\n    return pred.detach().cpu().numpy().flatten()\n\ndef show_prediction_confidence(prediction, class_names):\n    pred_df = pd.DataFrame({'class_names': class_names, 'values': prediction})\n    sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n    plt.xlim([0, 1]);\n\npred = predict_proba(base_model, '..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10004.jpg')\nshow_prediction_confidence(pred, class_names)","6dac2fa6":"show_image('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10079.jpg')","aeeebe64":"pred = predict_proba(base_model, '..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10079.jpg')\nshow_prediction_confidence(pred, class_names)","7d8643db":"show_image('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/101.jpg')","22aadb96":"pred = predict_proba(base_model, '..\/input\/intel-image-classification\/seg_pred\/seg_pred\/101.jpg')\nshow_prediction_confidence(pred, class_names)","6d3cd341":"**We will copy all the images to new dir, the purpose is to make it easier to torchvision dataset helpers to utilize the images**","86807fc8":"**It is not bad, we have 0.9 average score for precision score among all class, but I have a little concern on recall score for class glacier and mountain, perhaps we need more data for that or other way of optimization to enhance that, but I am happy with the current score, and f1_score is good as well**","24a0baba":"**Now we will create pytorch dataset for image dataset and dataloaders**","d87e7725":"**We will create 3 helpers function to encapsualte train and eval func**","bef754f5":"**Here we build 3 helpers to load and view images**","6b4d4cef":"**Sample of images for all classes we have**","93d1ef81":"# The end, i hope you guys like it and share your views on how this model can better. Thanks all :)","3cee89b3":"**We are going to reserve 80% for train and 20% for validation for each class, then copy them to the correct folder**","35f05872":"# Evaluation","059c5262":"**Here i repeat the same data preprocess step as like the train dataset**","8e37b845":"**We will get each label folder and we can see that we have 6 folders**\n\n* buildings = 0 \n* forest = 1\n* glacier = 2\n* mountain = 3\n* sea = 4\n* street = 5 ","6ff6fe09":"# **Get test data from dataset folder for evaluation**","91bdcc2f":"* buildings = 0 \n* forest = 1\n* glacier = 2\n* mountain = 3\n* sea = 4\n* street = 5 ","55011327":"**Lets have a look at some sample images with all the transformations**","ff6b86c5":"**Evaluation is simple, we don't even do gradient calculations**","46664ffe":"# Using pretrained model to classify the images\n\nWe will use the pre-trained ResNet to classify this images\n1. We will import the model (import all weights and arch except we will change the output layer as number of output class is different from ResNet dataset)\n2. Convert it into training mode\n3. Train the model on new data\n4. Evaluate\n5. Hopefully celebrate :)","c26d4014":"**Intel Image Classification With Pytorch and Transfer Learning**\n\nIn this notebook, we will preprocess the intel images, we will create augemented images to increase the training dataset.\n\nThen we will use ResNet pre-trained model from torchvision and used the model to train in on our dataset","58b37372":"**Distribution of classes are good, the total per class ratio is not so high**\n\n**We will apply some image augmentation techniques to artifically increase the size of dataset, we will apply some random resizing, rotation and horizontal flips, then we normalize the tensors using present values for each channel, this is requirement of ResNet**","edee08e6":"**Last One for test then we are done**","8a8a3ee1":"**So based on the above figure, it seems like there is 0 wrong prediction,and 8 is correct, that is not bad, now lets see the classification report to understand the bigger view of model performance**","351249a2":"# Prediction on seg_pred dataset","b4f03df6":"**We will store each class total images for later use**","3359a50d":"Looks like building\/street to me"}}