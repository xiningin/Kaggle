{"cell_type":{"778edb40":"code","ecc425ca":"code","9a03d1a4":"code","522b3d95":"code","159ea112":"code","bb728da0":"code","f3283bea":"code","811d8675":"code","fa68b8fc":"code","685f5e7a":"code","5421bd48":"code","45aa4169":"code","7d7da4c9":"code","2a878574":"code","b0e96089":"code","764f7115":"code","cc05c8d3":"code","5ec83032":"code","03a4158a":"code","52a692d8":"code","a470a7be":"code","1370cb99":"code","0a86125a":"code","1ae34a76":"code","f479469e":"code","cd18dd81":"code","6a20aca0":"code","0f4258b0":"code","98e71f63":"code","bcc75955":"code","0b1e7e9e":"code","7706a58f":"code","a6856654":"code","bb972580":"markdown","e4f72df0":"markdown","3ad33b61":"markdown","99534262":"markdown","b2c7b3f7":"markdown","cf6e52d4":"markdown","1e15fca0":"markdown","0a82ebfa":"markdown","43969722":"markdown","9ad52848":"markdown","bdab6500":"markdown","f6705fc9":"markdown","7525d60c":"markdown","ef29e41c":"markdown"},"source":{"778edb40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\nfrom sklearn.metrics import (\n                mean_absolute_error, \n                mean_squared_error,\n                median_absolute_error,\n                max_error,\n                r2_score,\n                completeness_score,\n                fowlkes_mallows_score,\n                homogeneity_score,\n                v_measure_score )\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","ecc425ca":"df=pd.read_csv('..\/input\/property-sales\/raw_sales.csv')\n\nprint(df.head())\nprint(df.isna().sum())\nprint(df.info())\n","9a03d1a4":"\ndf_recente = df[(df['datesold'] > '2017-01-01 00:00:00')]\n# drop da mesma\ndf_recente=df_recente.drop('datesold',axis=1)\n\nprint(df_recente.head())\nprint(df_recente.info())\n\nprint(df_recente.price.count())","522b3d95":"ax = sns.countplot(x=\"bedrooms\", data=df_recente)\nfor p in ax.patches:\n    ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))","159ea112":"_ = sns.swarmplot(x='propertyType', y='price', data=df_recente)\n\n\n# Label the axes\n_ = plt.xlabel('Tipo de propriedade')\n_ = plt.ylabel('Pre\u00e7o')\n\n\n# Show the plot\nplt.show()","bb728da0":"_ = sns.swarmplot(x='bedrooms', y='price', data=df_recente)\n\n\n# Label the axes\n_ = plt.xlabel('Quartos')\n_ = plt.ylabel('Pre\u00e7o')\n\n\n# Show the plot\nplt.show()","f3283bea":"df_recente['propertyType'].replace('unit', 0,inplace=True)\ndf_recente['propertyType'].replace('house', 1,inplace=True)","811d8675":"# Selecao da coluna a ser treinada\npreco = df_recente.price\n# drop da mesma\ndf1=df_recente.drop('price',axis=1)\nprint(df1.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df1, preco, test_size = 0.2)\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","fa68b8fc":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\nmodeloLasso = Lasso().fit(train_X, train_y)\ny_predLasso =  modeloLasso.predict(val_X)","685f5e7a":"print(\"Regress\u00e3o linear \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regress\u00e3o Ridge \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regress\u00e3o Lasso \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloLasso.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloLasso.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predLasso),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLasso))\n","5421bd48":"# Selecao da coluna a ser treinada\ntipo = df_recente.propertyType\n# drop da mesma\ndf2=df_recente.drop('propertyType',axis=1)\nprint(df1.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df2, tipo, random_state = 1,test_size = 0.2)","45aa4169":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\n\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\n\nmodeloLogRegression = LogisticRegression().fit(train_X,train_y)\ny_predLog =  modeloLogRegression.predict(val_X)","7d7da4c9":"print(\"Regress\u00e3o linear \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),      \n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regress\u00e3o Ridge \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regress\u00e3o Regress\u00e3o Log\u00edstica \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloLogRegression.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloLogRegression.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predLog),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLog))","2a878574":"df_recente_semCEP=df_recente.drop('postcode',axis=1)\n# Selecao da coluna a ser treinada\npreco_semCEP = df_recente_semCEP.price\n# drop da mesma\ndf1_semCEP=df_recente_semCEP.drop('price',axis=1)\nprint(df1_semCEP.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df1_semCEP, preco_semCEP, test_size = 0.2)\n","b0e96089":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\n\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\n\nmodeloLasso = Lasso().fit(train_X, train_y)\ny_predLasso =  modeloLasso.predict(val_X)\n","764f7115":"print(\"Regress\u00e3o linear \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regress\u00e3o Ridge \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predRidge),      \n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regress\u00e3o Lasso \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloLasso.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloLasso.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLasso),\n    \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predLasso),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLasso))\n","cc05c8d3":"# Selecao da coluna a ser treinada\ntipo_semCEP = df_recente_semCEP.propertyType\n# drop da mesma\ndf2_semCEP=df_recente_semCEP.drop('propertyType',axis=1)\nprint(df2_semCEP.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df2_semCEP, tipo_semCEP, random_state = 1,test_size = 0.2)","5ec83032":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\n\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\n\nmodeloLogRegression = LogisticRegression().fit(train_X,train_y)\ny_predLog =  modeloLogRegression.predict(val_X)","03a4158a":"print(\"Regress\u00e3o linear \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regress\u00e3o Ridge \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regress\u00e3o Regress\u00e3o Log\u00edstica \\n\\t\\t\\t\\t Acur\u00e1cia treino: \", modeloLogRegression.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia valida\u00e7\u00e3o: \", modeloLogRegression.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio absoluto: \", mean_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro Percentual m\u00e9dio absoluto: \", mean_absolute_percentage_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro m\u00e9dio quadr\u00e1tico: \", mean_squared_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t M\u00e1ximo erro: \", max_error(val_y,y_predLog),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLog))","52a692d8":"zoo2 = pd.read_csv(\"..\/input\/zoo-animals-extended-dataset\/zoo2.csv\")\nzoo3 = pd.read_csv(\"..\/input\/zoo-animals-extended-dataset\/zoo3.csv\")","a470a7be":"# peeking at the dataset\nprint(zoo3.head())\n#Descriptive stats of the variables in data\nprint(zoo3.describe())\n# verificando se dados nulos\nprint(zoo3.isna().sum())","1370cb99":"animal_name = zoo3.animal_name\nclass_t = zoo3.class_type\nzoo3_Km = zoo3.drop(columns=['animal_name','class_type'],axis=1)","0a86125a":"plt.figure(figsize=(10, 8))\n\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(zoo3_Km)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('N\u00famero de Clusters')\nplt.ylabel('Coeficiente de Silhueta')\nplt.show()","1ae34a76":"kmeans = KMeans(n_clusters=6, random_state = 0)\nkmeans.fit(zoo3_Km)","f479469e":"labels = kmeans.predict(zoo3_Km)\ncentroides = kmeans.cluster_centers_\nown_labels = np.array(['Mam\u00edferos', 'Rept\u00e9is e Anf\u00edbios', 'Aves', 'Peixe'])\nprint(\"Labels: \\n\", labels);\nprint(\"Centroides: \\n\", centroides);\n\nprint(animal_name)\n\ndummy_data3 = {\n        'nome': animal_name,\n        'labels': labels}\ndf_label = pd.DataFrame(dummy_data3, columns = ['nome', 'labels'])\ngroup = df_label.groupby('labels')\n\n#df_label.to_csv('labels.csv')\nlabels_true = [1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,5,5,5,5,5,5,5,5,3,3,\n3,3,3,3,3,3,0,0,0,0,0,0,4,4,4,4,4,4,3,4,4]\n\nprint(group.count())\n\nfor key, item in group:\n    print(group.get_group(key), \"\\n\\n\")\n","cd18dd81":"tsne_out = TSNE(n_components=2,  n_iter=1000, init='pca').fit_transform(zoo3_Km)\nplt.figure(figsize=(13,7))\nplt.scatter(tsne_out[:,0], tsne_out[:,1], c=kmeans.labels_,cmap='cividis');","6a20aca0":"print(\"M\u00e9tricas da Cluster \\n\\t\\t\\t\\t Completude: \", completeness_score(labels_true,labels),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia fowlkes: \", fowlkes_mallows_score(labels_true,labels),\n     \"\\n\\t\\t\\t\\t Homogenidade: \", homogeneity_score(labels_true,labels),\n     \"\\n\\t\\t\\t\\t V-measure: \", v_measure_score(labels_true,labels) )","0f4258b0":"kmeans2 = KMeans(n_clusters=7, random_state = 0)\nkmeans2.fit(zoo3_Km)","98e71f63":"labels2 = kmeans2.predict(zoo3_Km)\ncentroides2 = kmeans2.cluster_centers_\nprint(\"Labels: \\n\", labels2);\nprint(\"Centroides: \\n\", centroides2);\n\ndummy_data3 = {\n        'nome': animal_name,\n        'labels': labels2}\ndf_label = pd.DataFrame(dummy_data3, columns = ['nome', 'labels'])\ngroup2 = df_label.groupby('labels')\n\nprint(group2.count())\n\nfor key, item in group2:\n    print(group2.get_group(key), \"\\n\\n\")\n","bcc75955":"tsne_out = TSNE(n_components=2,  n_iter=1000, init='pca').fit_transform(zoo3_Km)\nplt.figure(figsize=(13,7))\nplt.scatter(tsne_out[:,0], tsne_out[:,1], c=kmeans2.labels_,cmap='coolwarm');","0b1e7e9e":"print(\"M\u00e9tricas da Cluster \\n\\t\\t\\t\\t Completude: \", completeness_score(class_t,labels2),\n     \"\\n\\t\\t\\t\\t Acur\u00e1cia fowlkes: \", fowlkes_mallows_score(class_t,labels2),\n     \"\\n\\t\\t\\t\\t Homogenidade: \", homogeneity_score(class_t,labels2),\n     \"\\n\\t\\t\\t\\t V-measure: \", v_measure_score(class_t,labels2) )","7706a58f":"racing_king_train = pd.read_csv(\"..\/input\/racingkings\/racing_king_train.csv\")\nracing_king_validate = pd.read_csv(\"..\/input\/racingkings\/racing_king_validate.csv\")","a6856654":"print(racing_king_train.head())\nprint((racing_king_train.info()))","bb972580":"# Removendo o CEP (PostCode)\n\nAgora, removeremos o PostCode e faremos os mesmos modelos e m\u00e9tricas. ","e4f72df0":"# Aprendizado n\u00e3o supervisionado\n______________\n\nPara esse caso escolheu-se um dataset contendo animais de um zoologico de S\u00e3o Paulo.\n\nEssa tabela cont\u00eam o nome de cada bixo e seu ID.  Composto por 16 atributos que dizem se \u00e9 ou n\u00e3o \u00e9.\n\n* animal_name animal id (unique for each instance)\n* hairif -- se tem cabelo\n* feathersif -- se tem penas\n* eggsif -- se poe ovos\n* milkif -- se d\u00e1 leite\n* airborne -- se voa\n* aquaticif -- se \u00e9 aqu\u00e1tico\n* predatorif -- se \u00e9 predador\n* toothedif -- se tem dentes\n* backboneif -- se tem ossos\n* breathesif -- se \"respira ar\"\n* venomousif -- se \u00e9 venosos\n* finsif -- se tem barbatana\n* legsnumber -- numeros de pernas: {0,2,4,5,6,8}\n* tailif -- se tem pesco\u00e7o\n* domesticif -- se \u00e9 dom\u00e9stico\n* catsizeif -- tamanho referente em unidades de gato\n* class_typea -- classe pertecente. \n","3ad33b61":"# M\u00e9tricas\n__________\n\n* Completude\n\nRefere-se como os membros de um clusters foram preditos para um mesmo cluster (n\u00e3o necessariamente o cluster correto mas agrupados juntos). Calcula-se usando a entropia dos eventos. \n\n$completude = 1 - \\frac{H(Predito|Correto)}{H(Correto)}$\n\n* Homogenidade \n\nCada classe (cluster correto) contem membros  de um mesmo cluster predito, pode se imaginar como o inverso de completude. O que n\u00e3o implica em $Completude + Homogenidade = 1 $.  Logo, \u00e9 a raz\u00e3o de um membro de uma classe dada ser assinalado ao mesmo cluster.\nMas temos que $ Completude(Predito, Gabarito) == Homogenidade(Gabarito, Predito) $\n\n* V-measure\n\n\u00c9 a m\u00e9dia harm\u00f4nica de homogenidade e completude.\n\nDado que : Completude = c e Homogenidade = h\n\n$V_{Measure} = (1 + \\beta) \\frac{h \\times c}{\\beta \\times h + c}$\n\n* Acur\u00e1cia fowlkes\n\n\u00c9 definido como a m\u00e9dia geom\u00e9trica entre precis\u00e3o e recall:\n\n$Fowlkes = \\frac{Verdadeiro_{Positivo}}{ \\sqrt{((Verdadeiro_{Positivo} + Falso_{Positivo}) * (Verdadeiro_{Positivo} + Falso_{Negativo} ))}}$","99534262":"# **An\u00e1lise atemporal**\n______________\nBuscou-se usar somentes os dados mais recentes, desde de 2019, para que o n\u00e3o ficasse muito grande. E assim, perde-se a temporalidade dos dados, na verdade usa-se os dados de forma atemporal.","b2c7b3f7":"# Aprendizado supervisionado\n\nNessa parte, ir\u00e1 salvar a coluna de interesse e usa-l\u00e1 para treinos e ver qual modelo melhor se adapta.\nSeparar em treino e teste.\nPor costume teste ter\u00e1 20% do dataset.\n","cf6e52d4":"# M\u00e9todos de treino\n\nSer\u00e3o usados m\u00e9todos de regress\u00e3o. Buscando de sklearn alguns modelos usados como regress\u00e3o linear, logit, lasso, Ridge (dispon\u00edveis na biblioteca sklearn).\n\n### M\u00e9tricas usadas\n\nSer\u00e3o as que s\u00e3o usadas comumente para m\u00e9todos de regress\u00e3o:\n\n* Max Error \n\nRepresenta o valor m\u00e1ximo de erro entre o predito e o gabarito (true_value). Ou seja, max (|Y_predito - Gabarito|)\n\n* Mean Absolute Error \n\nErro m\u00e9dio absoluto, o nome j\u00e1 \u00e9 explicativo: Soma-se o total de erros e divide-se pelo n\u00famero de amostras. logo :\n $ \\frac{\\sum (Y_{predito} - Y_{gabarito})}{n_{amostras}} $\n\n* Mean Squared Error \n\nErro m\u00e9dio quadr\u00e1tico tem como base o erro m\u00e9dio absoluto, mas ao inv\u00e9s de pegar o valor absoluto, usa-se o valor quadr\u00e1tico desta diferen\u00e7a. logo :\n $ \\frac{\\sum \\sqrt{(Y_{predito} - Y_{gabarito})^{2}}}{n_{amostras}} $\n\n* Median Absolute Error\n\nNesse caso, pega-se os erros e se ordena e encontrar a tend\u00eancia central do mesmo. Ou seja, as amostras em $X[\\frac{n}{2}]$ ou $X\\frac{[\\frac{n}{2}] + X[\\frac{n}{2} + 1]}{2}$\n\n* Mean Absolute Percentage Error\n\nMAPE \u00e9 a soma dos erros absolutos individuais divididos pela demanda (cada per\u00edodo separadamente).\n$  MAPE = \\frac{1}{n} \\sum \\frac{Y_{Predito} - Y_{gabarito}}{Y_{gabarito}} $","1e15fca0":"# Aprendendo o tipo de im\u00f3vel\n\nAo inv\u00e9s de tentar aprender o pre\u00e7o do im\u00f3vel tentar descobrir o im\u00f3vel se \u00e9 unidade ou apartamento.","0a82ebfa":"### Aumentando n\u00famero de cluster para 7\n\n","43969722":"__________________________\n","9ad52848":"-------------------------------\n\n# Aprendizado por refor\u00e7o - Racing King\n------------------------------\n\n\nO dataset escolhido \u00e9 um jogo de Xadrez, na verdade uma variante do jogo de xadrez denominada Corrida dos Reis. Contendo um etapa de treino e outra de valida\u00e7\u00e3o.\nFoi escolhido esse dataset pois refor\u00e7o envolve caminhos bons que te levam a vit\u00f3ria e caminhos ruins que te levam a derrota.\n\n","bdab6500":"Por fim, obteve-se 6 grupos conforme abaixo:\n\n### Label 0 - Anf\u00edbios\n\n* 40                  jabuti       0 (estranho ao ninho)\n* 41            jacare-coroa       0 (estranho ao ninho)\n* 45                 tracaja       0 (OK)\n* 55  perereca-de-alcatrazes       0 (OK)\n* 56          ra-flecha-azul       0 (OK)\n* 57              ra-pimenta       0 (OK)\n* 58    sapo-barriga-de-fogo       0 (OK)\n* 59             sapo-cururu       0 (OK)\n* 60          sapo-de-chifre       0 (OK)\n\n### Label 1 - Mam\u00edferos\n* 0                anta       1 (OK)\n* 1            ariranha       1 (OK)\n* 3               bugio       1 (OK)\n* 4    cachorro-vinagre       1 (OK)\n* 5           chimpanze       1 (OK)\n* 6       gato-maracaja       1 (OK)\n* 7         jaguatirica       1 (OK)\n* 8          lobo-guara       1 (OK)\n* 9       macaco-aranha       1 (OK)\n* 10   macaco-barrigudo       1 (OK)\n* 11  mico-leao-dourado       1 (OK)\n* 12     mono-carvoeiro       1 (OK)\n* 13       onca-pintada       1 (OK)\n* 14        orangotango       1 (OK)\n* 15          peixe-boi       1 (OK)\n* 16           queixada       1 (OK)\n* 17  tamandua-bandeira       1 (OK)\n* 18     urso-de-oculos       1  (OK)\n\n### Label 2 - Aves\n* 9         aguia-cinzenta       2 (OK)\n* 20         aracari-banana       2 (OK)\n* 21             arara-azul       2 (OK)\n* 22          arara-caninde       2 (OK)\n* 23                  chaua       2 (OK)\n* 24                    ema       2 (OK)\n* 25           gaviao-pombo       2 (OK)\n* 26                  guara       2 (OK)\n* 27                 harpia       2 (OK)\n* 28               jacurutu       2 (OK)\n* 29              jacutinga       2 (OK)\n* 30        jandaia-amarela       2 (OK)\n* 31                 macuco       2 (OK)\n* 32             murucututu       2 (OK)\n* 33                  mutum       2 (OK)\n* 34  papagaio-de-cara-roxa       2 (OK)\n* 35         pato-de-crista       2 (OK)\n* 36                   pavo       2 (OK)\n* 37   tucano-de-bico-preto       2 (OK)\n* 38              urubu-rei       2  (OK)\n\n### Label 3 - Peixes\n* 47                     baiacu       3 (OK)\n* 48      cascudinho-de-caverna       3 (OK)\n* 49                    lambari       3 (OK)\n* 50                   matrinxa       3 (OK)\n* 51                   pirarucu       3 (OK)\n* 52                 raia-chita       3 (OK)\n* 53                   tambaqui       3 (OK)\n* 54             tubarao-raposa       3 (OK)\n* 67  caracol-da-mata-atlantica       3 (OK)\n\n### Label 4 - Insetos\n* 61         abelha       4 (OK)\n* 62       joaninha       4 (OK)\n* 63       mariposa       4 (OK)\n* 64      pirilampo       4 (OK)\n* 65          vespa       4 (OK)\n* 66      bicho-pau       4 (OK)\n* 68  caranguejeira       4 (OK)\n* 69    sauva-limao       4 (OK)\n\n### Label 5 - Rept\u00e9is\n* 2   boto-cor-de-rosa       5 (Estranho ao ninho)\n* 39        cobra-cipo       5 (Ok)\n* 42    jararaca-ilhoa       5 (Ok)\n* 43            jiboia       5 (Ok)\n* 44            sucuri       5 (Ok)\n* 46    urutu-cruzeiro       5  (Ok)\n","f6705fc9":"Nesse dataset h\u00e1 duas colunas\n\n* fen -- fen \u00e9 o estado atual do jogo e assim por dizer como est\u00e3o posicionadas as pe\u00e7as suas e do oponente.\n\n* score -- \u00e9 a pontua\u00e7\u00e3o da aquela \"snapshot\" do jogo X(fen) = score.\n\n\nLogo, a ideia seria ir refor\u00e7ando o aprendizado mostrando que tal jogada \u00e9 de pouco valor e outro \u00e9 de maior pontua\u00e7\u00e3o podendo direcionar as jogadas do bot.\n________________\n\n## M\u00e9tricas de aprendizado por refor\u00e7o\n\n* Regret -> Uma m\u00e9trica que diz quantas jogadas \"nesse caso do xadrez\" seriam economizadas. Ou seja, as vantagens que se levaria se tomasse o caminho \u00f3timo.\n\n\n* Reability -> confiabilidade, quanto aquela conhecimento realmente levou ao sucesso, ou se for ruim quanto levou ao fracasso.\n","7525d60c":"# Inicial verifica\u00e7\u00e3o dos dados \n__________\nComo n\u00e3o h\u00e1 valores vazios, podemos n\u00e3o nos preocupar com valores nulos e tratamentos desses dados.\n\nPara aprendizado supervisionado foi escolhido o atributo\/coluna 'pre\u00e7o' (price) para tentar prever os seus dados atrav\u00e9s de aprendizado supervisionado.\n\nLogo dado o CEP, tipo de propriedade e quantidade de quarto tentar prever qual ser\u00e1 seu pre\u00e7o.\n_________\nPosteriormente, ser\u00e1 feito o contr\u00e1rio ser\u00e1 colocado a coluna pre\u00e7o e tentar\u00e1 descobrir se \u00e9 casa ou \u00e9 \"unit\".  \n____________\nCEP ser\u00e1 desconsiderado depois, para mais testes, uma vez que CEP n\u00e3o est\u00e1 por bairro e sim algo mais detalhado, tornando mais dificil seu uso.\nE feito o teste para descobrir o pre\u00e7o e o tipo de im\u00f3vel.\n\n\n","ef29e41c":"# N\u00famero de cluster\n\nDados as colunas que cont\u00eam dados sobre os animais catolagados.\n\nTentaremos dividir em 6 grupos:\n* Mam\u00edferos\n* Insetos\n* Rept\u00e9is \n* anf\u00edbios\n* Aves \n* Peixes "}}