{"cell_type":{"73ac7e40":"code","fe476655":"code","c940198d":"code","0f3c8851":"code","48c7b91f":"code","f7b4c9e5":"code","de778be9":"code","02b2c5d1":"code","290cfd36":"code","708271e8":"code","28fa5a15":"code","d2cc96be":"code","369e5e80":"code","e5d12c0e":"code","daf6525f":"code","06b19a86":"code","96f6cd95":"code","7dcef8d6":"code","ba4d43eb":"code","2d5b15b2":"code","905cb445":"code","a8a5977f":"code","008fe2a6":"markdown","90089d89":"markdown","afee25d1":"markdown","a96e8e99":"markdown","7bd54e89":"markdown","8c5daed6":"markdown","059b569a":"markdown","7fbd5aba":"markdown","35121c5b":"markdown","35a75bcf":"markdown","ddd4e0af":"markdown","0a0c2fd0":"markdown","d9d41fd2":"markdown","70af8ec5":"markdown","f6833714":"markdown","68ed4b7d":"markdown"},"source":{"73ac7e40":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport pandas as pd\nfrom pandas.api.types import CategoricalDtype\n\nimport numpy as np\nfrom scipy import sparse\n\nimport string\n\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nstyle.use('seaborn-bright')\n\nimport seaborn as sns\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\n\ninit_notebook_mode(connected=True)\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import OneHotEncoder","fe476655":"train = pd.read_csv('..\/input\/cat-in-the-dat\/train.csv')\ntest = pd.read_csv('..\/input\/cat-in-the-dat\/test.csv')","c940198d":"train.head()","0f3c8851":"Combined_data = pd.concat([train.drop(['target'], axis=1), test], axis=0, ignore_index=True)\nprint('Shape of training dataset: {}'.format(train.shape))\nprint('Shape of testing dataset: {}'.format(test.shape))\nprint('Shape of combined dataset: {}'.format(Combined_data.shape))","48c7b91f":"total = Combined_data.isnull().sum().sort_values(ascending=False)\npercent = (Combined_data.isnull().sum())\/Combined_data.isnull().count().sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\nmissing_data.head(5)","f7b4c9e5":"Combined_data.columns","de778be9":"X_train = train.drop(['target'], axis=1)\ny_train = train['target']","02b2c5d1":"bin_cats = X_train[['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']]\nbin_cats.bin_3 = 1 *(bin_cats.bin_3 == 'T')\nbin_cats.bin_4 = 1 *(bin_cats.bin_3 == 'Y') \nbin_cats.head()","290cfd36":"nom_cats = X_train[['nom_1','nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']]\nnom_encoder=OneHotEncoder()\nnom_encoder.fit(nom_cats)\nnom_cats = nom_encoder.transform(nom_cats)\nnom_cats","708271e8":"ord_cat_names = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\nord_cats = X_train[ord_cat_names]\nord_cats.ord_1 = pd.factorize(ord_cats.ord_1.astype(CategoricalDtype(categories=[\"Novice\", \"Contibutor\", \"Expert\", \"Master\", \"Grandmaster\"], ordered=True)))[0]\nord_cats.ord_2 = pd.factorize(ord_cats.ord_2.astype(CategoricalDtype(categories=[\"Freezing\", \"Cold\", \"Warm\", \"Hot\", \"Boiling Hot\", \"Lava Hot\"], ordered=True)))[0]\nord_cats.ord_3 = ord_cats['ord_3'].apply(lambda x: ord(x)-ord('a'))\nord_cats.ord_4 = ord_cats['ord_4'].apply(lambda x: ord(x)-ord('A'))\n\nd = {}\nfor i, s in enumerate(string.ascii_letters):\n    d[s] = i\n\nord_cats.ord_5 = ord_cats['ord_5'].apply(lambda x: 10*d[x[0]]+ d[x[1]])\nord_cats.head()","28fa5a15":"cyclic_cats = X_train[['day', 'month']]","d2cc96be":"X = np.concatenate((bin_cats.values, ord_cats.values), axis=1)\nX = sparse.csr_matrix(X)\nX = sparse.hstack((X, nom_cats))\n\ny = train['target']","369e5e80":"print('The original input representation has shape {}'.format(train.shape))\nprint('The one-hot encoded input representation has shape {}'.format(X.shape))","e5d12c0e":"data = [\n    go.Bar(\n        y=train['target'].value_counts().to_dense().keys(),\n        x=train['target'].value_counts(),\n        orientation='h',\n        text=\"d\",\n    )]\nlayout = go.Layout(\n    height=500,\n    title='Target populations',\n    hovermode='closest',\n    xaxis=dict(title='Training set count', ticklen=5, zeroline=False, gridwidth=2, domain=[0.1, 1]),\n    yaxis=dict(title='', ticklen=5, gridwidth=2),\n    showlegend=False\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='Target Populations')","daf6525f":"X_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                    test_size=0.2, \n                                                    random_state=42)\n","06b19a86":"print('The shape of the training input is {}'.format(X_train.shape))\nprint('The shape of the validation input is {}'.format(X_val.shape))\nprint('The shape of the training output is {}'.format(y_train.shape))\nprint('The shape of the validation output is {}'.format(y_val.shape))","96f6cd95":"def adaboost(X_train, X_val, y_train):\n    model = AdaBoostClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_val)\n    return y_pred","7dcef8d6":"y_baseline = adaboost(X_train, X_val, y_train)","ba4d43eb":"#SMOTE\nsm = SMOTE(random_state=42)\nX_train_sm, y_train_sm = sm.fit_sample(X_train, y_train)\ny_smote = adaboost(X_train_sm, X_val, y_train_sm)","2d5b15b2":"#RUS\nX_full = X_train.copy()\nX_full['target'] = y_train\nX_maj = X_full[X_full.target == 0]\nX_min = X_full[X_full.target == 1]\nX_maj_rus = resample(X_maj, replace=False, n_samples=len(X_min), random_state=44)\nX_rus = pd.concat([X_maj_rus, X_min])\nX_train_rus = X_rus.drop(['target'], axis=1)\ny_train_rus = X_rus.target\ny_rus = adaboost(X_train_rus, X_val, y_train_rus)\nprint('RUS Adaboost')\nprint(classification_report(y_rus, y_val))","905cb445":"print('Vanilla AdaBoost')\nprint(classification_report(y_baseline, y_val))\n\nprint('SMOTE AdaBoost')\nprint(classification_report(y_smote, y_val))\n\nprint('RUS Adaboost')\nprint(classification_report(y_rus, y_val))","a8a5977f":"#y_pred = adaboost(train.drop('target'), test, train.target)","008fe2a6":"A tremendous reference for categorical encoding for this competition (and at any other time) is this kernel:\n    https:\/\/www.kaggle.com\/shahules\/an-overview-of-encoding-techniques","90089d89":"1. Elements of Statistical Learning by Friedman, Tibshirani and Hastie\n2. Blog post by Anna Vasilyeva from Urbint: https:\/\/medium.com\/urbint-engineering\/using-smoteboost-and-rusboost-to-deal-with-class-imbalance-c18f8bf5b805","afee25d1":"### Vanilla Adaboost (no resampling)","a96e8e99":"### RUS (Randomly Undersampling) Adaboost","7bd54e89":"Note that although the dimension of the one-hot encoded respresentation is massive, it is stored as a sparse matrix so it doesn't actually take up an unreasonable amount of space.","8c5daed6":"# Check for missing data","059b569a":"# Visualization","7fbd5aba":"### SMOTE (Synthetic Minority Oversampling Technique) Adaboost","35121c5b":"# Categorical encoding","35a75bcf":"## Load dataset","ddd4e0af":"# Training\/validation split","0a0c2fd0":"### Acknowledgements","d9d41fd2":"# Build models","70af8ec5":"### Adaboost function","f6833714":"# Submission","68ed4b7d":"### Classification results"}}