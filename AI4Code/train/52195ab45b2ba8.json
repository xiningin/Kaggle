{"cell_type":{"c28bfb8e":"code","3bc930bd":"code","859ee811":"code","6eadf4a4":"code","4125c5ff":"code","505cdeb2":"code","29865126":"code","30e6b4a8":"code","ab4029ae":"code","dadb4f8f":"code","f92b15ae":"code","2361229d":"code","8b29b907":"code","08d53e51":"code","4d7e6cb7":"code","1d850e78":"code","bc11a6ed":"code","e33dadaf":"code","86741a4e":"code","a0445d05":"markdown","2bb92c11":"markdown","97510dd3":"markdown","89a1aa26":"markdown","ebc229ae":"markdown","a8b8fb97":"markdown","10bb9182":"markdown","15799d5a":"markdown"},"source":{"c28bfb8e":"# main imports (for calculations and data manipulation)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# after glimpsing the data, I'll also import geopy to calculate the distance of each ride\nfrom geopy import distance, Point\n\n# to plot a map afterwards\nfrom bokeh.plotting import figure, show, output_notebook\nfrom bokeh.tile_providers import get_provider, Vendors\nfrom bokeh.models import Segment, ColumnDataSource\n\n# get the path of each file and join them\nimport glob\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3bc930bd":"# Reading all the files in and putting them together under one dataframe, by the name of 'trip_data'\npath = '\/kaggle\/input\/cyclistic-bike-share\/'\nall_files = glob.glob(path + \"*.csv\")\ntrip_data = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n\n# Info (details of the dataframe) and describe (stats for the numeric data) methods\ntrip_data.info()\ntrip_data.describe() # does not tell much, since most of the relevant data is not in numeric format\n\n# First records of the dataframe\ntrip_data.head()\n\n# Notes: from the start, we can note that the columns adhere to the snake case convention, which adds to its credibility and facilitates \n# manipulation. Moreover, I suppose that the 'ID' columns will not add much to the analysis as far as their content goes.","859ee811":"# Starting out the cleaning process, let's just confirm that there are no duplicates in the dataframe:\n\ntrip_data[trip_data.duplicated()]","6eadf4a4":"# Next up: check if there's any NA values in this dataset and what percentage of the dataset they represent:\n\n(trip_data.isna().sum() \/ len(trip_data)) * 100","4125c5ff":"# Considering that the NAs only represent ~ 4.4% of the dataset - given that the highest percentages are all across the station names and IDs, \n# I suppose that they are the same records, and that shouldn't significantly impact the outcome of the project regardless -, I'll simply drop \n# them. \n# Since there are no duplicate entries, the 'ride_id' column would be rather useless for the purpose of this analysis. Same for the ID of each \n# station - their names are much more descriptive. With that said, I'll drop those columns as well and save the changes into a new dataframe.\n\ntrip_data = trip_data.dropna()\nclean_trip_data = trip_data.drop(['ride_id', 'start_station_id', 'end_station_id'], axis=1)\n\n# After exploring what the 'rideable_type' column represents (basically, if a bike is classic, eletric, or docked) and what are the unique \n# values, I'll create an alternate dataframe without the docked bikes, to be used later on for analysis.\n\ntrip_data['rideable_type'].unique()\nbike_types = clean_trip_data.query(\"rideable_type == 'classic_bike' or rideable_type == 'electric_bike'\")\nbike_types.rideable_type.unique()","505cdeb2":"clean_trip_data.head()\n\n# Main steps: \n\n# 1. Format 'started_at' and 'ended_at' as datetime objects, which will then allow for calculations.\n\n# 2. Create columns for: day of the week for each ride, duration of each ride, start hour of each ride.\n\n# 3. Create columns for start and ending points of each ride (lat, lng). It will then enable to calculate the distance (in km) and\n# coordinates, that are the needed input for 'bokeh' to be able to plot the maps.","29865126":"# Transformation\n\n# 1. Format 'started_at' and 'ended_at' as datetime objects\n\nclean_trip_data['started_at'] = pd.to_datetime(clean_trip_data['started_at'])\nclean_trip_data['ended_at'] = pd.to_datetime(clean_trip_data['ended_at'])\n\n# 2. Creating the columns\n\n# 2.1 'Day of Week'\nclean_trip_data['day_of_week'] = clean_trip_data['started_at'].dt.day_name()\n\n# 2.2 'Duration'\nclean_trip_data['duration'] = (clean_trip_data['ended_at'] - clean_trip_data['started_at']) \/ pd.Timedelta(minutes=1)\n\n# 2.3 'Start hour'\nclean_trip_data['start_hour'] = clean_trip_data['started_at'].dt.hour\n\n# Checking:\nclean_trip_data.head()","30e6b4a8":"# Importing to ignore the warning for the following action.\n\nimport warnings\nwarnings.filterwarnings('ignore')","ab4029ae":"%%timeit\n\n# 3. Calculating the distance\n\n'''\nThe 'Point()' method from geopy basically converts each lat and lng into an object of its own that allows for calculations of distances\nlater on. However, the 'distance' method - which is what actually interests - can function receiving a tuple as well. Thus, we'll calculate \nthe time for each ('Point' vs a list comprehension) using a small sample set. Each has to be done in a separete cell, because of the %time it\nmagic function. Whichever is faster will be then passed into the entire dataframe.\n'''\n\n# Slice of the dataframe:\ntest_set = clean_trip_data.head(30)\n\n# Geopy:\ntest_set['start_point_geo'] = test_set.apply(lambda row: Point(latitude=row['start_lat'], longitude=row['start_lng']), axis=1)\ntest_set['end_point_geo'] = test_set.apply(lambda row: Point(latitude=row['end_lat'], longitude=row['end_lng']), axis=1)","dadb4f8f":"%%timeit\n\n# Slice of the dataframe:\ntest_set = clean_trip_data.head(30)\n\n# List comprehension:\ntest_set['start_point_lc'] = [tuple(l) for l in test_set[['start_lat', 'start_lng']].to_numpy()]\ntest_set['end_point_lc'] = [tuple(l) for l in test_set[['end_lat', 'end_lng']].to_numpy()]\n\n## Considering the results, we will proceed to use the list comprehension.","f92b15ae":"# 3.1. Creating the points \n\nclean_trip_data['start_point'] = [tuple(l) for l in clean_trip_data[['start_lat', 'start_lng']].to_numpy()]\nclean_trip_data['end_point'] = [tuple(l) for l in clean_trip_data[['end_lat', 'end_lng']].to_numpy()]\n\n# 3.2. Creating a column for the distance in km\nclean_trip_data['distance'] = clean_trip_data.apply(lambda row: distance.distance(row['start_point'], row['end_point']).km, axis=1)","2361229d":"# 3.3. Creating the coordinates\n# We'll see later, through a visualization, that the top five stations for start and finishing trips of 'casual' customers are 'Streeter Dr & \n# Grand Ave', 'Lake Shore Dr & Monroe St', 'Millennium Park', 'Theater on the Lake' and 'Michigan Ave & Oak St'.\n# With this info in mind, I'll create a dataframe that only contains a sample of 200 of these trips, where the start station is one of these. \n# Based on that, we will later plot a map of these routes. \n\ntrip_coord = clean_trip_data[(clean_trip_data['member_casual'] == 'casual') & (clean_trip_data['rideable_type'] != 'docked_bike')]\ntrip_coord = trip_coord.query(\"start_station_name == 'Streeter Dr & Grand Ave' or start_station_name == 'Lake Shore Dr & Monroe St' or start_station_name == 'Millennium Park' or start_station_name == 'Theater on the Lake' or start_station_name == 'Michigan Ave & Oak St'\").sample(200)\n\n# A function to transform each point into a coordinate, formatted for the plotting. \nimport math\nfrom ast import literal_eval\ndef merc(Coords):\n    Coordinates = literal_eval(Coords)\n    lat = Coordinates[0]\n    lon = Coordinates[1]\n    \n    r_major = 6378137.000\n    x = r_major * math.radians(lon)\n    scale = x\/lon\n    y = 180.0\/math.pi * math.log(math.tan(math.pi\/4.0 + \n        lat * (math.pi\/180.0)\/2.0)) * scale\n    return (x, y)\n\n# Coordinates (0 indicates the starting point and 1 the ending point. x stands for lat and y stands for lng). \ntrip_coord['coords_x0'] = trip_coord['start_point'].astype(str).apply(lambda x: merc(x)[0])\ntrip_coord['coords_y0'] = trip_coord['start_point'].astype(str).apply(lambda x: merc(x)[1])\ntrip_coord['coords_x1'] = trip_coord['end_point'].astype(str).apply(lambda x: merc(x)[0])\ntrip_coord['coords_y1'] = trip_coord['end_point'].astype(str).apply(lambda x: merc(x)[1])","8b29b907":"'''\nTopics to be explored:\n1. Most popular bikes by customer type\n2. Top 5 stations (start and end) that 'casual' customers use the most (may allow for Out of Home advertising at the location or nearby)\n3. Number of rides by user type in each day of the week\n4. Busiest starting hour by type of customer\n5. Average duration of each ride by user typer\n6. Average distance of each ride by user type\n7. Map for most popular routes of the casual customer  \n'''\n\n# 1. Most popular bikes by type of customer\n\nplt.figure(figsize=(10, 8))\nsns.set_style('whitegrid')\nsns.countplot(data=bike_types, x='member_casual', hue='rideable_type', palette='mako');\nplt.title('Rideable Type by Customer Type', fontdict={'fontsize': 15}, y=1.02);\nplt.xlabel('User type');\nplt.ylabel(None);\nplt.figtext(0.9, 0.01, 'Data licensed by Motivate International Inc.', wrap=True, horizontalalignment='right', fontsize=8);\n\n# Notes: through the following viz, we can clearly see that the proportion of casual customers using eletric bikes compared to members is\n# significant. There are a number of factors that could be behind this - pricing, availability, etc. By the data we have, though, the only\n# safe deduction is that casual customers tend to prefer eletric bikes.","08d53e51":"# 2. Top 5 stations that casual customers use the most\n\ntop_st_start = pd.DataFrame(clean_trip_data[clean_trip_data['member_casual'] == 'casual'].start_station_name.\n                            value_counts().sort_values(ascending=False).head(5))\ntop_st_end = pd.DataFrame(clean_trip_data[clean_trip_data['member_casual'] == 'casual'].end_station_name.\n                          value_counts().sort_values(ascending=False).head(5))\n\nfig, axs = plt.subplots(ncols=2, figsize=(25, 8))\naxs[0].set_title('Start Station by Traffic', fontdict={'fontsize': 15}, y=1.02);\naxs[1].set_title('End Station by Traffic', fontdict={'fontsize': 15}, y=1.02);\nsns.barplot(data=top_st_start, x=top_st_start.index, y='start_station_name', ax=axs[0], palette='mako');\nsns.barplot(data=top_st_end, x=top_st_end.index, y='end_station_name', ax=axs[1], palette='mako');\nplt.figtext(0.9, 0.01, 'Data licensed by Motivate International Inc.', wrap=True, horizontalalignment='right', fontsize=8);\n\n# Notes: the busiest stations for casual users are very well defined. That allows for our marketing team to survey what would be the best \n# options in terms of position and pricing to place 'out of home' advertisements - either on the stations or nearby.","4d7e6cb7":"# 3. Number of rides by user type in each day of the week\n\nplt.figure(figsize=(12, 9))\nsns.countplot(data=clean_trip_data, x='day_of_week', hue='member_casual', palette='mako', saturation=1);\nplt.title('Rides per day of week, by user type', loc='left', fontdict={'fontsize': 15}, y=1.02);\nplt.xlabel('Day of Week');\nplt.ylabel(None);\nplt.figtext(0.9, 0.01, 'Data licensed by Motivate International Inc.', wrap=True, horizontalalignment='right', fontsize=8);\n\n# Notes: there's a clear increase of casual members' usage on Friday and weekends, whilst annual members tend to have a more steady activity\n# throughout the week. It's also safe to assume that once casual customers become annual members, they should adopt a similar behavior.\n# Our marketing team could use this information to prompt these customers (e.g. sending an e-mail marketing on Thursday or Friday).","1d850e78":"# 4. Busiest starting hour by type of customer\n\nplt.figure(figsize=(20, 9))\nsns.countplot(data=clean_trip_data, x='start_hour', hue='member_casual', palette='bright', saturation=1);\nplt.title('Busiest hours of the day by user type', loc='left', fontdict={'fontsize': 18}, y=1.02);\nplt.xlabel('Hour of the day', fontdict={'fontsize': 12});\nplt.ylabel(None);\nplt.figtext(0.9, 0.01, 'Data licensed by Motivate International Inc.', wrap=True, horizontalalignment='right', fontsize=8);\n\n# Notes: the usage pattern of casual members seems normally distributed yet slightly left skewed. In other words, as the day goes by, the \n# number of rides increase even more for this user type. The range between 12pm-7pm should be the most fruitful for marketing campaigns in loco.","bc11a6ed":"# Before plotting the graphs 5 (Average duration of each ride by type of customer) and 6 (Average distance of each ride by type of customer),\n# I believe it would be useful to visualize it in a dataframe format:\n\nclean_trip_data.groupby('member_casual').mean()[['duration', 'distance']].transpose()\n\n# The mean distance between casual and annual members is almost identical. The mean duration, however, is significantly different - the unit\n# of measure is minutes. One reason behind this might be that as casual customers tend to have a higher usage on the weekends, so they are less \n# attached to the duration of their rides. Or even that some people use it for longer rides (perhaps with family and\/or friends) and it ends up \n# skewing the average.","e33dadaf":"fig, axs = plt.subplots(ncols=2, figsize=(25, 8))\naxs[0].set_title('Average duration by customer type', fontdict={'fontsize': 15}, y=1.02);\naxs[1].set_title('Average distance by customer type', fontdict={'fontsize': 15}, y=1.02);\n\n# 5. Average duration of each ride by type of customer\n\ndata = clean_trip_data.groupby('member_casual').mean()[['duration', 'distance']]\nsns.barplot(data=data, x=data.index, y='duration', ax=axs[0], palette='bright', saturation=1);\n\n# 6. Average distance of each ride by type of customer\n\nsns.barplot(data=data, x=data.index, y='distance', ax=axs[1], palette='bright', saturation=1);\n\nplt.figtext(0.9, 0.01, 'Data licensed by Motivate International Inc.', wrap=True, horizontalalignment='right', fontsize=8);","86741a4e":"# 7. Map for most popular routes of the casual customer\n# The map is interactive - with zooming tools and a reset button to come back to the original plot. \n\np = figure(x_range=(-9780000, -9745000), y_range=(5130000, 5160000),\n           x_axis_type=\"mercator\", y_axis_type=\"mercator\")\np.add_tile(get_provider('CARTODBPOSITRON'))\n\nsource = ColumnDataSource(dict(\n        x=trip_coord['coords_x0'],\n        y=trip_coord['coords_y0'],\n        xm01=trip_coord['coords_x1'],\n        ym01=trip_coord['coords_y1'],\n    )\n)\n\nglyph = Segment(x0=\"x\", y0=\"y\", x1=\"xm01\", y1=\"ym01\", line_color=\"#f4a582\", line_width=4, line_alpha=.2, line_join='miter', line_cap='round')\np.add_glyph(source, glyph)\np.title.text = 'Most popular routes for casual users'\np.title.align = 'left'\np.title.text_color= 'black'\np.title.text_font_size = '20px'\n\noutput_notebook()\nshow(p)\n\n# Notes: this plot only enhances the profile of the 'casual' user and its contrast to the annual member. It is safe to assume that most casual \n# users are people that use the services mainly on weekends, prefer eletric bike and ride mainly in the city centre. These people tend to favor \n# leisure or perhaps are tourists, but don't usually commute using our bikes. They are probably sightseeing and as a result, they end up using\n# the bikes for a longer period, even though the average distance is similar to that of the annual member.","a0445d05":"### Manipulation \/ Transformation\n* After cleaning the dataset, transformations are needed and documented in the following steps.  ","2bb92c11":"### Thank you for reading!\n##### You can find me on:\n* [Github](https:\/\/github.com\/yncosta)\n* [Kaggle](https:\/\/www.kaggle.com\/yanscosta)\n* [LinkedIn](https:\/\/www.linkedin.com\/in\/yanphcosta\/)","97510dd3":"### Cyclistic: analysis for a bike sharing company\n\nYan Costa\n<br>*July, 2021*\n\n---    \n\n##### **Mission statement**: Cyclistic is a bike-share program that features more than 5,800 bicycles and 600 docking stations across Chicago, IL (USA). The company currently has three distinct pricing plans: **single-ride passes**, **full-day passes**, and **annual memberships**. Their conclusion is that, financially speaking, 'annual members' are much more profitable than 'casual riders' - as they classify their customers. \n##### The idea behind this study is to analyze Cyclistic's user data and identify how customers behave differently, coming up with insights that could help convert 'casual riders' into 'annual members'.\n\n---\n\n##### The data analysis process consists of 6 key steps, them being: `Ask`, `Prepare`, `Process`, `Analyze`, `Share` and `Act`.\n##### Each step and relevant finding is going to be documented. At the end, I am going to share at least **three key insights** to help achieve the business goal.","89a1aa26":"### Ask\n#### At this point, it is important to have a clear understanding of what the business task is and what steps we plan to take to successfully tackle it. \n* The purpose of this analysis has already been clearly defined: **improve revenue by converting 'casual riders' into 'annual members'**. For that, we have to understand in what exactly they differ from each other, so that we can target these customers in marketing campaings. \n* The key **stakeholders** are the marketing analytics team, and the director of Marketing, to whom the results will be reported.","ebc229ae":"### Analyze\n#### Now that the data is finally clean, it is time to dive into it, perform calculations and identify trends and relationships that convey meaningful insights and ideas.\n* I have chosen to demonstrate calculations and visualizations all together. It makes more sense for documentation and to actually see the idea behind each insight.\n* The question to keep in mind derives from our business task: **based on their behavior, what could lead a 'casual' user to become an annual member?'**","a8b8fb97":"### Process\n#### Description of the chosen tools and documentation of each step taken for data cleaning and manipulation\n* The size of each file has played an important role in the choice of tools. Neither *BigQuery* (SQL, under a public license) nor *Google Sheets* were able to handle such amount of data. Therefore, I have chosen to use **Python** - and this Kaggle notebook - to perform the analysis. It should facilitate both manipulation and creation of visualizations when necessary.\n* Each step of the **analysis** is thoroughly documented.","10bb9182":"### Prepare\n#### Ensure that the data source is reliable and its content allows for the analysis.\n* The dataset comes from *Motivate International Inc.*, under a [data license agreement](https:\/\/www.divvybikes.com\/data-license-agreement). Forked via this Kaggle [dataset](https:\/\/www.kaggle.com\/kevinvenza\/cyclistic-bike-share). It consists of 660mb+ of .csv files. Its integrity and credibility are secured, given that it comes directly from the source - company's own data.\n* The files, as we will soon see, are well-organized and also follow a naming convention, which adds to its accessibility.\n\n\n","15799d5a":"### Share and Act\n#### With the data visualizations create throughout the analysis, it's time to share the findings and the story the data tells.\n#### Even though the task is simply to identify differences between user types, considering all of the following questions may be useful to convey valuable recommendations:\n\n1. **How do annual members and casual riders use Cyclistic bikes differently?**\n*  As described in the previous - and last - plot notes, the profile for each customer and its effect on the way they use our services is quite clear - obviously, more data would be important to determine if our inferences are actually accurate. \n* **Casual** customers are tend to prefer electric bikes, usually ride near the city centre - as demonstrate via the map and most frequent stations plots -, have higher usage on weekends and in the afternoon and usually have longer rides - maybe because they are on their time off and focused on leisure, sightseeing, etc. Of course, some of them may actually commute during working days but have not been triggered to sign for an annual membership. There could be strategies for both personas.\n* **Annual** members not necessary prefer one type of bike over the other - even though they, in general, use more of the classic bikes, it may only be due to availability. Because of their steady usage on working days and the peak around the end of business hours, they probably make the most use of our services to move to and from their working place. As a result of their annual membership, they probably use the bikes for shorter distances, which would reasonably explain the difference in the duration of their trips. \n\n2. **Why would casual riders buy Cyclistic annual memberships?**\n* Two main pieces of data, which are missing, could contribute to tackle this question: out of the docked bikes, which are electric and which are 'classic'? A higher availability of electric bikes in the busiest stations for casual customers could drive their usage up. Also, financial information could help emphasize the benefits of being an annual member. For those casual clients who use the bikes with a certain frequency, highlighting the cost-benefit of being an annual member might make them consider becoming one.\n\n3. **How can Cyclistic use digital media to influence casual riders to become members?**\n* The brand could try to drive up engagement by making posts related to leisure (especially closer to the weekend) and the benefits of using riding a bicycle on a daily basis - these could be related to the environment (less cars on the street), physical and mental health (avoid traffic, exercising, etc.)\n* Mentioning the benefits of being an annual member should also be effective.\n\n### *<ins>Recommendations<\/ins>* (top three):\n##### 1. Use social media and e-mail marketing to engane with casual customers. Emphasize the benefits of being an annual member, which they may not be acquainted with yet. \n##### 1.1 Give a special discount valid for working days for those who use frequently the services only on weekends. The percentage of this discount may gradually decrease throughout the day - which would mean that the earlier they used their coupon, the higher the percentage would be. This may lead them to use it early in the morning, which is currently their bottom in daily usage.<br>\n##### 2. Ensure availability of electric bikes on the most popular stations.<br> \n##### 3. Place 'out of home' ads near these stations and on their most frequent routes, especially in the city centre and close to tourist attractions."}}