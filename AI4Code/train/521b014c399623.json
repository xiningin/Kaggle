{"cell_type":{"c0f77511":"code","27e49e0f":"code","4b2f500c":"code","762bacab":"code","eb5a0e38":"code","9eb44f16":"code","5ccbad5c":"code","dbc97f1d":"code","034d46f7":"code","3da7d761":"code","35daca36":"code","150a332a":"code","16b4cd87":"code","18962101":"code","235334ac":"markdown","6fef1212":"markdown","7137e5b3":"markdown","55d56ff9":"markdown","f246cc8d":"markdown","930226c7":"markdown"},"source":{"c0f77511":"!git clone https:\/\/github.com\/Ryan-Rudes\/tacotron2\n%cd tacotron2\n!git submodule init; git submodule update","27e49e0f":"import pandas as pd\n\nmetadata = pd.read_csv(\"..\/..\/input\/johnoliver\/metadata.csv\")\nmetadata = metadata[metadata['include']]\n\ntotal = len(metadata)\nsplit = 0.9\ntrain = int(total * split)\n\ntrain_metadata = metadata[:train]\nval_metadata = metadata[train:]\n\nwith open('filelists\/audio_text_train_filelist.txt', 'w') as f:\n    for _, (index, _, _, _, text, _) in train_metadata.iterrows():\n        filepath = '..\/..\/input\/johnoliver\/wav\/%05d.wav' % index\n        f.write(filepath + '|' + text + '\\n')\n\nwith open('filelists\/audio_text_test_filelist.txt', 'w') as f:\n    for _, (index, _, _, _, text, _) in val_metadata.iterrows():\n        filepath = '..\/..\/input\/johnoliver\/wav\/%05d.wav' % index\n        f.write(filepath + '|' + text + '\\n')","4b2f500c":"!pip install tensorflow==1.15\n!pip install unidecode\n!pip install inflect","762bacab":"!pip install gdown\n!gdown https:\/\/drive.google.com\/uc?id=1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA","eb5a0e38":"!python train.py --output_directory=outdir --log_directory=logdir -c tacotron2_statedict.pt --warm_start","9eb44f16":"from multiprocessing import Pool\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom tqdm.notebook import tqdm\nimport IPython.display as ipd\nfrom time import time, sleep\nimport scipy.io.wavfile\nimport numpy as np\nimport matplotlib\nimport torch\nimport sys\n\nsys.path.append('waveglow\/')\n\nfrom audio_processing import griffin_lim\nfrom layers import TacotronSTFT, STFT\nfrom hparams import create_hparams\nfrom text import text_to_sequence\nfrom denoiser import Denoiser\nfrom train import load_model\nfrom model import Tacotron2","5ccbad5c":"def plot_data(data, figsize=(16, 4)):\n    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n    for i in range(len(data)):\n        axes[i].imshow(data[i], aspect='auto', origin='lower', interpolation='none')","dbc97f1d":"hparams = create_hparams()\nhparams.sampling_rate = 22000","034d46f7":"checkpoint = int(input(\"Enter steps at latest checkpoint: \"))\ncheckpoint_path = f\"outdir\/checkpoint_{checkpoint}\"\nmodel = load_model(hparams)\nmodel.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n_ = model.cuda().eval().half()","3da7d761":"!gdown https:\/\/drive.google.com\/uc?id=1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF","35daca36":"waveglow_path = 'waveglow_256channels_universal_v5.pt'\nwaveglow = torch.load(waveglow_path)['model']\nwaveglow.cuda().eval().half()\nfor k in waveglow.convinv:\n    k.float()\ndenoiser = Denoiser(waveglow)","150a332a":"def synthesize(word, n=5, cleaners=['english_cleaners'], sigma=0.666, strength=0.01):\n    sequence = np.array(text_to_sequence(word, cleaners))[None, :]\n    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n    with torch.no_grad():\n        mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n    audio = waveglow.infer(mel_outputs_postnet, sigma=sigma)\n    audio_denoised = denoiser(audio, strength=strength)[:, 0]\n    audio = audio[0].data.cpu().numpy().tolist()\n    mel_outputs = mel_outputs.float().data.cpu().numpy()[0]\n    mel_outputs_postnet = mel_outputs_postnet.float().data.cpu().numpy()[0]\n    alignments = alignments.float().data.cpu().numpy()[0]\n    return audio, mel_outputs, mel_outputs_postnet, alignments","16b4cd87":"tests = [\n         \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n         \"The state of Florida reports a surge in coronavirus deaths as restrictions are upended.\",\n         \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\",\n         \"A woodchuck would chuck all the wood it could chuck if a woodchuck could chuck wood.\",\n         \"Peter Piper picked a peck of pickled peppers. How many pickled peppers did Peter Piper pick?\",\n         \"Sally sells seashells by the seashore. The shells she sells are seashells I'm sure.\",\n         \"The blue lagoon is a nineteen eighty American romance adventure film.\",\n         \"George Washington was the first President of the United States.\",\n         \"Basilar membrane and otolaryngology are not auto-correlations.\",\n         \"Biden holds first foreign meeting with Canada's Justin Trudeau.\"\n]","18962101":"for text in tests:\n    audio, mel_outputs, mel_outputs_postnet, alignments = synthesize(text, n=15)\n    ipd.display_html(ipd.HTML(f\"\"\"\n    <h3>{text}<\/h3>\n    <br\/>\n    \"\"\"))\n    ipd.display(ipd.Audio(data = audio, rate = 22000, autoplay = False))","235334ac":"Create file lists from train and validation sets","6fef1212":"Download pretrained model from Google Drive for transfer learning","7137e5b3":"Clone the repo from GitHub","55d56ff9":"Train the model for 1000 epochs with a batch size of 32","f246cc8d":"Install dependencies","930226c7":"## Inference\n### Synthesize generated audio samples from text"}}