{"cell_type":{"1b2d2bbc":"code","36dd67d3":"code","dd26d821":"code","637d46f3":"code","618f4de4":"code","f7e13f4f":"code","cff735f8":"code","9612b078":"code","060595d5":"code","bf567987":"code","4fe68c7c":"code","b1432bf3":"code","ba09f10a":"code","7fa34005":"code","fa625fb3":"code","7773c3ae":"code","2a32c890":"code","400dd29b":"markdown","a33b1a2e":"markdown","14132646":"markdown","5ed2f17b":"markdown","1efa4edc":"markdown","7778c750":"markdown","48a0f0dc":"markdown","9528de4a":"markdown","4778e998":"markdown","b63b73d9":"markdown"},"source":{"1b2d2bbc":"import sqlite3 as sql\n!pip install pandas -q\nimport pandas as pd\n!pip install matplotlib -q\nimport matplotlib.pyplot as plt\n!pip install numpy -q\nimport numpy as np\n!pip install langdetect -q\nfrom langdetect import detect\n!pip install scikit-learn -q\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n!pip install nltk -q\nfrom nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('punkt', quiet=True)\nfrom nltk.corpus import stopwords\nfrom statistics import mean\nfrom math import floor","36dd67d3":"jobs = pd.read_csv('\/kaggle\/input\/job-adverts\/dfdailyadverts.csv')\nconn = sql.connect('job_adverts.db')\ntry:\n    jobs.to_sql('job_adverts', conn)\nexcept ValueError:\n    # DB already exists\n    pass\nconn = sql.connect('job_adverts.db')","dd26d821":"german_adverts = pd.read_sql_query(\"SELECT description FROM job_adverts WHERE language LIKE 'de'\", conn)\nmsk = np.random.rand(len(german_adverts)) < 0.95\ngerman_adverts_train = german_adverts[msk].description.to_numpy()\ngerman_adverts_test = german_adverts[~msk].description.to_numpy()\n\nenglish_adverts = pd.read_sql_query(\"SELECT description FROM job_adverts WHERE language LIKE 'en'\", conn)\nmsk = np.random.rand(len(english_adverts)) < 0.95\nenglish_adverts_train = english_adverts[msk].description.to_numpy()\nenglish_adverts_test = english_adverts[~msk].description.to_numpy()","637d46f3":"class LemmaTokenizer:\n    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`', \"(\", \")\", \"\/\", \"-\", \"+\"]\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]","618f4de4":"class GermanSimilarityChecker:\n    def __init__(self, documents):\n        # Lemmatize the stop words\n        stop_words = set(stopwords.words('german')) \n        self.tokenizer=LemmaTokenizer()\n        token_stop = self.tokenizer(' '.join(stop_words))\n\n        # Create TF-idf model\n        self.vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=self.tokenizer)\n        self.doc_vectors = self.vectorizer.fit_transform(documents)\n    \n    def checkSimilarity(self, sample):\n        #Calculate sample vector\n        sample_vector = self.vectorizer.transform([self.tokenize(sample)])\n        # Calculate similarity\n        cosine_similarities = linear_kernel(sample_vector, self.doc_vectors).flatten()\n        document_scores = [item.item() for item in cosine_similarities]\n        return mean(document_scores)\n    \n    def tokenize(self, sample):\n        sample_tokens = self.tokenizer(sample)\n        return ' '.join(sample_tokens)","f7e13f4f":"class EnglishSimilarityChecker:\n    def __init__(self, documents):\n        # Lemmatize the stop words\n        stop_words = set(stopwords.words('english')) \n        self.tokenizer=LemmaTokenizer()\n        token_stop = self.tokenizer(' '.join(stop_words))\n\n        # Create TF-idf model\n        self.vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=self.tokenizer)\n        self.doc_vectors = self.vectorizer.fit_transform(documents)\n    \n    def checkSimilarity(self, sample):\n        #Calculate sample vector\n        sample_vector = self.vectorizer.transform([self.tokenize(sample)])\n        # Calculate similarity\n        cosine_similarities = linear_kernel(sample_vector, self.doc_vectors).flatten()\n        document_scores = [item.item() for item in cosine_similarities]\n        return mean(document_scores)\n    \n    def tokenize(self, sample):\n        sample_tokens = self.tokenizer(sample)\n        return ' '.join(sample_tokens)","cff735f8":"class SimilarityChecker:\n    def __init__(self, german_train, english_train, german_test, english_test):\n        self.german_model = GermanSimilarityChecker(german_train)\n        self.english_model = EnglishSimilarityChecker(english_train)\n        #calculate similarities of test set to define scoring scale\n        self.english_test_results = []\n        for sample in english_test:\n            self.english_test_results.append(self.english_model.checkSimilarity(sample))\n        self.german_test_results = []\n        for sample in german_test:\n            self.german_test_results.append(self.german_model.checkSimilarity(sample))\n        #remove highest and lowest 10% of results\n        for i in range(0, floor(len(self.english_test_results)\/10)):\n            self.english_test_results.remove(max(self.english_test_results))\n            self.english_test_results.remove(min(self.english_test_results))\n        for i in range(0, floor(len(self.german_test_results)\/10)):\n            self.german_test_results.remove(max(self.german_test_results))\n            self.german_test_results.remove(min(self.german_test_results))\n    def getUniquenessScore(self, sample, lang = 'unkwn'):\n        if lang == 'unkwn':\n            lang = detect(sample)\n        if lang == 'de':\n            minsim = min(self.german_test_results)\n            maxsim = max(self.german_test_results)\n            sim = max(minsim, min(maxsim, self.german_model.checkSimilarity(sample)))\n        elif lang == 'en':\n            minsim = min(self.english_test_results)\n            maxsim = max(self.english_test_results)\n            sim = max(minsim, min(maxsim, self.english_model.checkSimilarity(sample)))\n        else:\n            print(f\"'{lang}' is not supported as a language.\")\n            return \n        return floor(100 - (100*(sim-minsim))\/(maxsim - minsim))","9612b078":"model = SimilarityChecker(german_adverts_train, english_adverts_train, german_adverts_test[0:100], english_adverts_test[0:100])","060595d5":"# a sample from the test set included in the scoring scale in german\nprint(german_adverts_test[0])\nprint(f'Score: {model.getUniquenessScore(german_adverts_test[0])}')","bf567987":"# a sample from the test set excluded from the scoring scale in german\nprint(german_adverts_test[101])\nprint(f'Score: {model.getUniquenessScore(german_adverts_test[101])}')","4fe68c7c":"# a sample from the test set included in the scoring scale in english\nprint(english_adverts_test[0])\nprint(f'Score: {model.getUniquenessScore(english_adverts_test[0])}')","b1432bf3":"# a sample from the test set excluded from the scoring scale in english\nprint(english_adverts_test[101])\nprint(f'Score: {model.getUniquenessScore(english_adverts_test[101])}')","ba09f10a":"# some generic job ad words in german. language need to be defined as otherwise might be detected as other language\nstring = 'Dynamisch flexibel kommunikativ kreativ motiviert selbstst\u00e4ndig team Vielf\u00e4ltige Kompetenzen hohe Eigenverantwortung selbstst\u00e4ndiges Arbeiten'\nprint(string)\nprint(f\"Score: {model.getUniquenessScore(string, 'de')}\")","7fa34005":"# look at the similarity score of the generic ad words in german\nmodel.german_model.checkSimilarity(string)","fa625fb3":"# lorem ipsum.\nloremipsum = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam facilisis risus sed turpis porttitor, eget semper urna varius. Vivamus consectetur diam eu varius suscipit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Integer maximus dignissim consectetur. Donec nisl velit, ullamcorper sit amet nulla nec, scelerisque lacinia ante. Donec eget sagittis metus. Ut pellentesque orci molestie erat porttitor efficitur rhoncus sed enim. Praesent urna quam, faucibus quis quam quis, consectetur egestas massa. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Donec gravida blandit mauris, vel pellentesque tellus varius sit amet. Integer porttitor, lorem vel pretium tempus, tellus nisl bibendum ligula, vitae eleifend ante mauris egestas tellus. Praesent non laoreet lacus. Vivamus nec feugiat dui. Integer id nisl quam. Donec nec libero eget felis tristique fermentum quis eget sapien.'\nprint(loremipsum)\nprint(f\"Score: {model.getUniquenessScore(loremipsum, 'en')}\")","7773c3ae":"# a recipe for pizza dough\nrecipe = 'Combine 1 cup (125g) of flour, instant yeast, sugar, and salt in a large bowl. If desired, add garlic powder and dried basil at this point as well.\\\nAdd olive oil and warm water and use a wooden spoon to stir well very well.\\\nGradually add another 1 cup (125g) of flour. Add any additional flour as needed (Ive found that sometimes I need as much as an additional \u2153 cup), stirring until the dough is forming into a cohesive, elastic ball and is beginning to pull away from the sides of the bowl (see video above recipe for visual cue). The dough will still be slightly sticky but still should be manageable with your hands.\\\nDrizzle a separate, large, clean bowl generously with olive oil and use a pastry brush to brush up the sides of the bowl.\\\nLightly dust your hands with flour and form your pizza dough into a round ball and transfer to your olive oil-brushed bowl. Use your hands to roll the pizza dough along the inside of the bowl until it is coated in olive oil, then cover the bowl tightly with plastic wrap and place it in a warm place.\\\nAllow dough to rise for 30 minutes or until doubled in size. If you intend to bake this dough into a pizza, I also recommend preheating your oven to 425F (215C) at this point so that it will have reached temperature once your pizza is ready to bake.\\\nOnce the dough has risen, use your hands to gently deflate it and transfer to a lightly floured surface and knead briefly until smooth (about 3-5 times).\\\nUse either your hands or a rolling pin to work the dough into 12 circle.\\\nTransfer dough to a parchment paper lined pizza pan and either pinch the edges or fold them over to form a crust.\\\nDrizzle additional olive oil (about a Tablespoon) over the top of the pizza and use your pastry brush to brush the entire surface of the pizza (including the crust) with olive oil.\\\nUse a fork to poke holes all over the center of the pizza to keep the dough from bubbling up in the oven.\\\nAdd desired toppings (see the notes for a link to my favorite, 5-minute pizza sauce recipe!) and bake in a 425F (215C) preheated oven for 13-15 minutes or until toppings are golden brown. Slice and serve.'\nprint(recipe)\nprint(f'Score: {model.getUniquenessScore(recipe)}')","2a32c890":"assert 0 <= model.getUniquenessScore(german_adverts_test[0]) <= 100\nassert 0 <= model.getUniquenessScore(english_adverts_test[0]) <= 100\nassert model.getUniquenessScore(recipe) == 100\nassert model.getUniquenessScore(loremipsum, 'en') == 100","400dd29b":"## Conclusion\nThe model seems to work okayish.\nThe scoring function is not so good, especially when the sample doesn't follow the format of a job ad and should be improved on.\nSee below the scoring function:\n![scoring.jpg](attachment:315b4bb0-add6-4801-8a35-1f798b4141e1.jpg)","a33b1a2e":"## Load csv data into sqlite database","14132646":"## Create model","5ed2f17b":"## Define Model\nConsists of two models (One for German and one for English job ads) They both use the same lemmatizer (NLTK wordnet) and NLTK's TFIDF Vectorizer.\nThe model is trained on the training portion of the data.\nThe test portion is used to define a function as to convert the simmilarity of a sample (values usually around 0.03 - 0.09) to a score on a scale from 0 to 100, representing the uniqueness.","1efa4edc":"## Load german & english job ads and split datasets into train and test portions","7778c750":"## Test model","48a0f0dc":"# Job ad uniqueness score\nReturns a score from 0 - 100 that reflects how unique your job ad description is compared to the available database","9528de4a":"The similarity score is lower than expected. but the score results is really unexpectedly high.. this is a result of a very imperfect scoring function.","4778e998":"## Unit Testing","b63b73d9":"## Import all dependencies"}}