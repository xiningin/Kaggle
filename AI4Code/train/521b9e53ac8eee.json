{"cell_type":{"d5646ada":"code","8bd8e341":"code","4689da82":"code","80397f6a":"code","c34ae9c4":"code","b2444da3":"code","6ba9590a":"code","c71759af":"code","f35c0499":"code","b6abb968":"code","72c30748":"code","1ec004a1":"code","706d4583":"code","0a902486":"code","49a673e7":"code","6ca74d67":"code","105a9f23":"code","ccab9bc8":"code","53c45363":"code","54d596c3":"code","c88d9e8d":"code","8c488448":"markdown","bb1d88bd":"markdown","c574cf00":"markdown"},"source":{"d5646ada":"from fastai.vision import *\nimport pandas as pd","8bd8e341":"# Load Labels\ntrain_label = pd.read_csv(\"..\/input\/banana-count-and-weight-in-a-bunch\/Estu.csv\", header=None)","4689da82":"#if flip_vert=true (default), errors are too huge and do not decrease as we train.\ntfms = get_transforms(flip_vert=False, max_lighting=0.2, max_zoom=1.05, max_warp=0.1)  ","80397f6a":"data = (ImageList.from_csv(path='..\/input\/banana-count-and-weight-in-a-bunch', csv_name='Estu.csv', folder='Banana_bunch_images')\n        .split_by_rand_pct()\n        .label_from_df(label_cls=FloatList) #label_cls=FloatList ensures that this is handled as 'Regression', not 'Classification'\n        .transform(tfms, size=224)  #without the 'size', it results in cuda out of memory\n        .databunch())","c34ae9c4":"# data.normalize(imagenet_stats)  #To do. How the train works without normalization","b2444da3":"data.show_batch(rows=3, figsize=(9,9))","6ba9590a":"# learn = cnn_learner(data, models.resnet34) #Todo. Check if other models can be used\nlearn = cnn_learner(data, models.resnet50) #Todo. Check if other models can be used\nlearn.loss = MSELossFlat # For Regression MSE loss is the Loss function","c71759af":"learn.lr_find()","f35c0499":"learn.recorder.plot()","b6abb968":"learn.fit_one_cycle(30, 0.05)  \n","72c30748":"learn.data.valid_ds[0][0].shape","1ec004a1":"learn.data.valid_ds[0][0]","706d4583":"learn.data.valid_ds[0][1]","0a902486":"learn.predict(learn.data.valid_ds[0][0])","49a673e7":"# Predict for a New Image\n# img = open_image('banana\/test\/IMG_20190401_084251.jpg')\nimg = open_image('banana\/train\/IMG_20190401_081240.jpg')\nimg\n","6ca74d67":"learn.predict(img) ","105a9f23":"img.shape  #It is observed that whenever the size is bigger, there is a high accuracy. Need to verify. Also, can this work with resnet32 as it was trained with sz 224.","ccab9bc8":"learn.export()","53c45363":"learn = load_learner('banana')","54d596c3":"il = ImageList.from_folder(\"banana\/test\/63\")","c88d9e8d":"for image in il:\n    image.show()\n    print(learn.predict(image))","8c488448":"#ToDo\n1. Trainining loss reduces slowly, but validation loss is unstable. Need to find out why.\n2. Above statement was run twice (first time with lr 0.1, second time with 0.5). It was observed that there was a sudden drop in training loss the second time. But the training loss still went on reducing for each epoch. The third time it did not reduce, rather moving sideways.\n3. Ensure that a single bunch's different images are not shared both in valid and train sets.\n4. Try with BW images\n5. Change the background and train\n6. While testing check how the same image works in different zoom level? roataion?","bb1d88bd":"Questions\n1. Any other model to choose?\n2. What about traning size?\n3. What does it mean to run learn.fit_one_cycle repeatedly? is it same as high number of epochs?\n","c574cf00":"Counting Bananas in a complete banana bunch"}}