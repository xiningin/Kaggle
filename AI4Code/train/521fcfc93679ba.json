{"cell_type":{"eb6d9c63":"code","9f9417c4":"code","c96b55b5":"code","6b5bfee1":"code","a174369e":"code","06a90f85":"code","386930ce":"code","ef85d7ad":"code","2dd7f101":"code","46e69c07":"code","2455f695":"code","efca6341":"code","d09e0a5b":"code","d9ec88f2":"code","d51ec1f5":"code","199ca701":"code","0f0ad03a":"code","2fb0c578":"code","125bda5a":"markdown","4dec9532":"markdown","b954b11b":"markdown","64bbcd31":"markdown"},"source":{"eb6d9c63":"from tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.preprocessing.text import Tokenizer as tk\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport pandas as pd","9f9417c4":"df = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\n\ndf.head()","c96b55b5":"df.info()","6b5bfee1":"df.describe()","a174369e":"encoder = LabelEncoder()\n\ndf['sentiment'] = encoder.fit_transform(df['sentiment'])","06a90f85":"X = np.array(df.drop(columns=['sentiment'])).reshape(len(df),)\ny = np.array(df['sentiment'])","386930ce":"xtr , xte , ytr, yte = train_test_split(X,y,shuffle=True,test_size = 0.1,stratify=y)","ef85d7ad":"tok=tk(num_words=10000, filters='!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True, split=' ',char_level=False, oov_token='Farid')","2dd7f101":"tok.fit_on_texts(xtr)","46e69c07":"xtr1 = tok.texts_to_sequences(xtr)\nxte1 = tok.texts_to_sequences(xte)","2455f695":"xtr2 = pad_sequences(xtr1,1000, padding='post',truncating='post')\nxte2 = pad_sequences(xte1,1000, padding='post', truncating='post')","efca6341":"xtr3 = np.flip(xtr2, 1)\nxte3 = np.flip(xte2, 1)","d09e0a5b":"print(xtr3.shape)\nprint(xte3.shape)","d9ec88f2":"embedding_vecor_length = 50\nmax_review_length = 1000\nNUM_WORDS = 10000\n\nmodel = Sequential()\nmodel.add(Embedding(NUM_WORDS, embedding_vecor_length, input_length=max_review_length))\nmodel.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling1D())\nmodel.add(GRU(50, return_sequences=True))\nmodel.add(GRU(50))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","d51ec1f5":"model.compile(optimizer='adam', loss='binary_crossentropy',metrics='accuracy')\nmodel.summary()","199ca701":"model.fit(xtr3,ytr,epochs=5,batch_size=100,validation_data = (xte3,yte),shuffle=True)","0f0ad03a":"print(\"Accuracy: \", np.round(model.evaluate(xte3,yte,verbose=0)[1]*100,3),\"%\")","2fb0c578":"review_num = 2\nrandom_indexs = []\nrandom_reviews = []\n\nfor _ in range(review_num):\n    rand_index = np.random.randint(0,xte.shape[0])\n    random_indexs.append(rand_index)\n    random_reviews.append(xte3[rand_index])\n\nrandom_reviews = np.array(random_reviews)\npredictions = (model.predict(random_reviews) > 0.5).astype('int32').reshape(review_num,)\n\nfor i,index in enumerate(random_indexs):\n    print(\"Review:  \" , xte[index],end=\"\\n\\n\\n\")\n    actual_review = \"Positive\" if yte[index] == 1 else \"Negative\"\n    predicted_review = \"Positive\" if predictions[i] == 1 else \"Negative\"\n    print(\"Actual review status: \",actual_review)\n    print(\"Predicted review status: \",predicted_review,end='\\n\\n')","125bda5a":"# Random Demonstration","4dec9532":"# Preparing data for model","b954b11b":"# Reading data","64bbcd31":"# Building model"}}