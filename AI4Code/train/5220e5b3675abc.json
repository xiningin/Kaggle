{"cell_type":{"1ebc50ab":"code","59bf0be9":"code","ca09bfff":"code","cc5cb1d9":"code","3991e3ab":"code","c5eba190":"code","0ac193f0":"code","8ae0b1d5":"code","d10e240a":"code","4c3bfcb8":"code","62d81d0e":"code","b3ba674c":"code","a20c533b":"code","89024667":"code","4b76b53d":"code","56af19b0":"code","c3b3893d":"code","a635bfd5":"code","32808295":"code","00e64498":"code","f7a76ee8":"code","914c58e0":"code","f5aca6ae":"code","5c6c46c2":"code","985af230":"code","ee3e6423":"code","f2126c8f":"code","8cc8f43f":"code","338710b6":"code","9827c85b":"code","2adb4a44":"markdown"},"source":{"1ebc50ab":"# --- Necessary Libraries --- #\nimport os\nimport sys\nimport random\nimport time\nimport _pickle\nimport pandas as pd\nimport numpy as np\nfrom itertools import chain\nfrom datetime import datetime\nfrom tqdm import tqdm_notebook, tnrange\n# -- Graphing -- #\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# -- Sci Kit Learn and Sci Kit Image -- # \nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import (\n    imread, imshow, concatenate_images\n)\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\n# --- TensorFlow ---\nimport tensorflow as tf\n\n# --- Keras Imports --- # \nfrom keras.models import Model, load_model\nfrom keras.layers import (\n    Input,Dropout,BatchNormalization,\n    Activation,Add, LeakyReLU,\n    UpSampling2D, Reshape, GaussianNoise,\n    Wrapper, Dense\n)\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import (\n    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n)\nfrom keras import backend as K\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import (\n    ImageDataGenerator, array_to_img, img_to_array,\n    load_img\n)\nfrom keras.layers import Activation\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.utils import plot_model\nfrom keras import optimizers\nfrom keras.optimizers import TFOptimizer","59bf0be9":"# DropConnect Wrapper\nclass DropConnect(Wrapper):\n    def __init__(self, layer, prob=1., **kwargs):\n        self.prob = prob\n        self.layer = layer\n        super(DropConnect, self).__init__(layer, **kwargs)\n        if 0. < self.prob < 1.:\n            self.uses_learning_phase = True\n\n    def build(self, input_shape):\n        if not self.layer.built:\n            self.layer.build(input_shape)\n            self.layer.built = True\n        super(DropConnect, self).build()\n\n    def compute_output_shape(self, input_shape):\n        return self.layer.compute_output_shape(input_shape)\n\n    def call(self, x):\n        if 0. < self.prob < 1.:\n            self.layer.kernel = K.in_train_phase(K.dropout(self.layer.kernel, self.prob), self.layer.kernel)\n            self.layer.bias = K.in_train_phase(K.dropout(self.layer.bias, self.prob), self.layer.bias)\n        return self.layer.call(x)","ca09bfff":"# d = datetime.fromtimestamp(1537315160) Our source Time Stamp\n# Function to Ensure Reproducible Results\ndef set_random(number):\n    os.environ['PYTHONHASHSEED'] = '6072019'\n    np.random.seed(number)\n    random.seed(number)\n    session_conf = tf.ConfigProto(\n        intra_op_parallelism_threads=1,\n        inter_op_parallelism_threads=1\n    )\n    tf.set_random_seed(number)\n    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n    K.set_session(sess)","cc5cb1d9":"# Functions to facilitate image\n# upsizing and downsizing\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)","3991e3ab":"# Introduce swish function supposedly better performance\n# than ReLU\n# swish: sigmoid x * x .804 lb\ndef swish(x):\n    return (K.sigmoid(x) * x )","c5eba190":"# dropconnect(X,P) -- \n# DropConnect implementation using tensorFlow\ndef dropconnect(input_value, prob):\n    return tf.nn.dropout(input_value, keep_prob=prob) * prob","0ac193f0":"# Metric Functions\n#Score the model and do a threshold optimization by the best IoU.\n# src: https:\/\/www.kaggle.com\/aglotero\/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels, y_pred = y_true_in, y_pred_in\n    true_objects, pred_objects = 2, 2\n    # Jiaxin fin that if all zeros, then, the background is treated as object\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n    intersection = temp1[0]\n    \n    # Compute areas (needed for finding the union between all objects)\n    #print(np.histogram(labels, bins = true_objects))\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    #print(\"area_true = \",area_true)\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n    \n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    y_pred_in = y_pred_in > 0.5 # added by sgx 20180728\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float64)\n    return metric_value","8ae0b1d5":"\"\"\"\nused for converting the decoded image to rle mask\nFast compared to previous one\n\"\"\"\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","d10e240a":"def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n    preds_test1 = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n    preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n    preds_avg = (preds_test1 +preds_test2)\/2\n    return preds_avg","4c3bfcb8":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation == True:\n        x = Activation('swish')(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = Activation('swish')(blockInput)\n    x = BatchNormalization()(x)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    return x","62d81d0e":"# Build model\n# for use model\ndef build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # For as much reproducibility as possible\n    # Applied to dropout layers\n    # 101 -> 50\n    prob_dc = 1 - (DropoutRatio\/4)\n    #conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = DropConnect(Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\"), prob =prob_dc)(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = Activation('swish')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    #pool1 = Dropout(DropoutRatio\/4)(pool1)\n    #x = DropConnect(Dense(64, activation='relu'), prob=0.5)(x)\n    #prob = 1 - (DropoutRatio\/4)\n    #pool1 = Lambda(dropconnect,arguments={\"prob\":prob})(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = Activation('swish')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio\/2)(pool2)\n    #prob = 1 - (DropoutRatio\/2)\n    #pool2 = Lambda(dropconnect,arguments={\"prob\":prob})(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = Activation('swish')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio\/2)(pool3)\n    #prob = 1 - (DropoutRatio\/2)\n    #pool3 = Lambda(dropconnect,arguments={\"prob\":prob})(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = Activation('swish')(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio\/2)(pool4)\n    #prob = 1 - (DropoutRatio\/2)\n    #pool4 = Lambda(dropconnect,arguments={\"prob\":prob})(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = Activation('swish')(convm)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio\/2)(uconv4)\n    #prob = 1 - (DropoutRatio\/2)\n    #uconv4 = Lambda(dropconnect,arguments={\"prob\":prob})(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = Activation('swish')(uconv4)\n    \n    # 12 -> 25\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio\/2)(uconv3)\n    #prob = 1 - (DropoutRatio\/2)\n    #uconv3 = Lambda(dropconnect,arguments={\"prob\":prob})(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = Activation('swish')(uconv3)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(DropoutRatio\/2)(uconv2)\n    #prob = 1 - (DropoutRatio\/2)\n    #uconv2 = Lambda(dropconnect,arguments={\"prob\":prob})(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = Activation('swish')(uconv2)\n    \n    # 50 -> 101\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(DropoutRatio\/2)(uconv1)\n    #prob = 1 - (DropoutRatio\/2)\n    #uconv1 = Lambda(dropconnect,arguments={\"prob\":prob})(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = Activation('swish')(uconv1)\n    \n    #uconv1 = Dropout(DropoutRatio\/4)(uconv1)\n    prob = 1 - (DropoutRatio\/4)\n    uconv1 = Lambda(dropconnect,arguments={\"prob\":prob})(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer","b3ba674c":"plt.style.use('seaborn-white')\nsns.set_style(\"white\")\n%matplotlib inline\nprint(os.listdir(\"..\/input\"))","a20c533b":"# Set all seeds and states for reproducibel\n# results can be further optimized if\n# a state object is saved and used\nset_random(1537315160)\n#Initialize Image dimension Variables\nimg_size_ori = 101\nimg_size_target = 101\n# Set Directory to grab from (needed when making predictions)\nDATA_DIR = \"..\/input\/tgsdata\/\"\n# Load in the train images and their masks for the training of models\nx_train2 = np.load(\"..\/input\/intermediatetgs\/x_train2.npy\")\nx_valid = np.load(\"..\/input\/intermediatetgs\/x_valid.npy\")\ny_train2 = np.load(\"..\/input\/intermediatetgs\/y_train2.npy\")\ny_valid = np.load(\"..\/input\/intermediatetgs\/y_valid.npy\")\nprint(\"Train Data:\")\nprint(\"X: \",x_train2.shape,\"Y: \",y_train2.shape)\nprint(\"Validation Data:\")\nprint(\"X: \",x_valid.shape,\"Y: \",y_valid.shape)\n# add swish to list of string options in activation\n# Needed for Keras\nget_custom_objects().update({\"swish\": swish})","89024667":"#fig, axs = plt.subplots(1, 2, figsize=(15,5))\n#sns.distplot(train.coverage, kde=False, ax=axs[0])\n#sns.distplot(train.coverage_class, bins=10, kde=False, ax=axs[1])\n#plt.suptitle(\"Salt coverage\")\n#axs[0].set_xlabel(\"Coverage\")\n#axs[1].set_xlabel(\"Coverage class\")","4b76b53d":"#Plotting the depth distributions\n#sns.distplot(train.z, label=\"Train\")\n#sns.distplot(test.z, label=\"Test\")\n#plt.legend()\n#plt.title(\"Depth distribution\")","56af19b0":"# Build the model then compile it using our custom metric\ninput_layer = Input((img_size_target, img_size_target, 2))\noutput_layer = build_model(input_layer, 16,0.6)\nmodel = Model(input_layer, output_layer)\n# Optimize optimizer\nadam_opt = optimizers.Adam(lr=0.001,\n                           beta_1=0.9,beta_2=0.999,\n                           epsilon=None,\n                           amsgrad=False,clipnorm=1.0\n                          )\n#sgd_opt = optimizers.SGD(lr=0.005)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=adam_opt, metrics=[my_iou_metric])\n#model.summary()","c3b3893d":"# Call backs \n# EarlyStopping: will stop after 20 epochs of no change in iou metric\n# ReduceLROnPlaeau: will reduce learning rate by 0.2 after 5 epochs of no change in iou metric\nearly_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',\n                               patience=35, verbose=1)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.97,\n                              patience=4, min_lr=0, verbose=1)\n\n# Save best model according to iou metric\nmodel_checkpoint = ModelCheckpoint(\".\/unet_best1.model\",monitor='val_my_iou_metric', \n                                   mode = 'max', save_best_only=True, verbose=1)\n\n# Declare number of epochs and batch size\nepochs = 200\nbatch_size = 32\n# Train Model and set to history variable for graphing purposes\n# Setting Shuffle should continur to ensure reproducibility in\n# later trails\nhistory = model.fit(x_train2, \n                    y_train2,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    shuffle=True,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n                    verbose=1\n                   )","a635bfd5":"# summarize history for loss\nplt.plot(history.history['my_iou_metric'][1:])\nplt.plot(history.history['val_my_iou_metric'][1:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper left')\nplt.show()","32808295":"fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")","00e64498":"#model = load_model(\".\/unet_best1.model\",custom_objects={'my_iou_metric': my_iou_metric})","f7a76ee8":"preds_valid = predict_result(model,x_valid,img_size_target)\npreds_valid2 = np.array([downsample(x) for x in preds_valid])\n\ny_valid2 = np.array([downsample(x) for x in y_valid])","914c58e0":"## Scoring for last model\nthresholds = np.linspace(0.3, 0.7, 31)\nious = np.array([iou_metric_batch(y_valid2, np.int32(preds_valid2 > threshold)) for threshold in tqdm_notebook(thresholds)])\nthreshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]","f5aca6ae":"# Plot threshold and iou\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","5c6c46c2":"#del(x_train2)\n#del(x_valid)\n#del(y_train2)\n#del(y_valid)","985af230":"x_test = np.load(\"..\/input\/intermediatetgs\/x_test.npy\")","ee3e6423":"preds_test = predict_result(model,x_test,img_size_target)","f2126c8f":"#test = pd.read_hdf(DATA_DIR + \"tgs_salt.h5\", key=\"test\")\n# load test indexes\nimport _pickle\nwith open(\"..\/input\/intermediatetgs\/test_index.obj\", \"rb\") as f:\n    indexes = _pickle.load(f)","8cc8f43f":"t1 = time.time()\npred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(indexes))}\nt2 = time.time()\n\nprint(f\"Usedtime = {t2-t1} s\")","338710b6":"sub = pd.DataFrame.from_dict(pred_dict,orient=\"index\")\nsub.index.names = [\"id\"]\nsub.columns = [\"rle_mask\"]\nsub.to_csv(\"submission4.csv\")","9827c85b":"# Return png representation\n#plot_model(model, to_file='model_version_2.png')","2adb4a44":"# Model Architecture"}}