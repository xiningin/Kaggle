{"cell_type":{"51122d3a":"code","6333ab3f":"code","969d42fe":"code","5ca06ee3":"code","86d05c80":"code","f16b928a":"code","185ca89b":"code","5d6af51f":"code","460b1123":"code","ad4d5eb9":"code","512a3cbd":"code","41a5adf8":"code","ca44ee7a":"code","4dee646c":"code","920291b9":"code","4586f025":"code","19cbc793":"code","f6892df1":"code","90f63e65":"code","0c81ccb3":"code","19d883ac":"code","e5ac54cb":"code","73e8676d":"code","f5295b6e":"code","8b35f706":"code","9d6999e3":"code","d7e26aac":"code","44e8536a":"code","2b392d27":"code","52bf118a":"code","b0924430":"code","4a2ebac8":"code","5790b73e":"code","01a372a8":"code","ebb824b0":"code","05dcda47":"code","2e47b48d":"code","7a622a19":"code","437b6116":"markdown","8dd2963d":"markdown","79e8930a":"markdown","da8450b2":"markdown","76594bd5":"markdown","bb1da37a":"markdown","7a9ff343":"markdown","4a72f2a7":"markdown","8d53f76b":"markdown","a129654e":"markdown","4255df12":"markdown"},"source":{"51122d3a":"# Importing the libraries\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport torchvision","6333ab3f":"data_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndata_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsample_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv' )","969d42fe":"# visualize the dimensions of the training data\ndata_train.shape","5ca06ee3":"# visualize the dimensions of the test data\ndata_test.shape","86d05c80":"# Visualize the first five training data\ndata_train.head()","f16b928a":"# Visualize the first five test data\ndata_test.head()","185ca89b":"# Getting all rows from column 1 to column 785 using the pandas class .iloc [], returning an array\ntrain = data_train.iloc[:, 1: 785 ].values\nlabel = data_train.iloc[:, 0].values","5d6af51f":"# visualizing the element in position 3 of our training data set \ntrain[3]","460b1123":"# Mapeamos nosso data set de treinamento\nnormalizer = MinMaxScaler()\ntrain = normalizer.fit_transform( train, ( 0, 1 ))","ad4d5eb9":"# We divided the training data set into 20% for training and 80% for testing, but it is up to the reader to choose.\nX_train, X_test, y_train, y_test =  train_test_split( train, label, test_size= 0.20, random_state= 0)","512a3cbd":"X_train.shape","41a5adf8":"# convert for tensors and resize them to four dimensions \nX_train = torch.tensor( X_train ).reshape( -1, 1, 28, 28)\nX_teste = torch.tensor( X_test).reshape( -1, 1, 28, 28)","ca44ee7a":"# Plotting our first image in position six\nimage = next(iter( X_train[6] )).view(28, 28) # (1, 1, 28, 28)\nplt.imshow(image, cmap='gray')","4dee646c":"# Plotting our second image in position two.\nimage = next(iter( X_train[2] )).view(28, 28) # (1, 1, 28, 28)\nplt.imshow(image, cmap='gray')","920291b9":"print(X_train.shape)\nprint(X_teste.shape)","4586f025":"# Transforming data for tensors\nY_train = torch.tensor( y_train )\nY_test = torch.tensor( y_test )","19cbc793":"print(Y_train.shape)\nprint(Y_test.shape)","f6892df1":"# A data set of tensor\ndataset_train = torch.utils.data.TensorDataset( X_train, Y_train)\ndataset_test = torch.utils.data.TensorDataset( X_teste, Y_test )\n\n# Data Loader\ntrain_loader = torch.utils.data.DataLoader( dataset_train, batch_size= 32, shuffle= True)\ntest_loader = torch.utils.data.DataLoader( dataset_test, batch_size= 32, shuffle= True)","90f63e65":"# Mapping the test data\ntest = normalizer.fit_transform( data_test, (0,1))","0c81ccb3":"test.shape","19d883ac":"# Resizing the data\ntest = torch.tensor( test , dtype= torch.float ).reshape(-1, 1, 28, 28)","e5ac54cb":"test.shape","73e8676d":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    \n        self.conv_input = nn.Conv2d( in_channels= 1, out_channels= 32, kernel_size= ( 3, 3 ))\n        self.conv_hidden = nn.Conv2d( in_channels= 32, out_channels=32, kernel_size= ( 3, 3 ))\n        self.function_activation = nn.ReLU()\n    \n        self.pool = nn.MaxPool2d(kernel_size=( 2, 2))\n        self.flaten = nn.Flatten()\n        \n        self.layer_input = nn.Linear( in_features= 32*5*5, out_features= 128 )\n        self.layer_hidden = nn.Linear( 128, 128 )\n        self.layer_output = nn.Linear( 128, 10 )\n        self.dropout = nn.Dropout( 0.2 )\n\n    def forward( self,  X ):\n        X = self.pool( self.function_activation( self.conv_input( X )))\n        X = self.pool( self.function_activation( self.conv_hidden( X )))\n        X = self.flaten( X )\n\n        X = self.dropout( self.function_activation( self.layer_input( X )))\n        X = self.dropout( self.function_activation( self.layer_hidden( X )))\n        X = self.layer_output( X )\n\n        return X","f5295b6e":"# Constructor of our Model class\nmodel = Model()\n# Our criteria for calculating our losses\ncritetion = nn.CrossEntropyLoss()\n# Our optimizer. Passing our CNN model as a parameter, \n# but it is up to the reader to make their choices of optimizer.\noptmizer = optim.Adam( model.parameters())","8b35f706":"model","9d6999e3":"def Train_loop( loader, epocha):\n    running_loss = 0.\n    running_accuracy = 0.\n    \n    for i, data in enumerate( loader ):\n\n        inputs, labels = data\n        optmizer.zero_grad()\n        \n        outputs = model( inputs.float() )\n        loss = critetion( outputs,  labels)\n        loss.backward()\n\n        optmizer.step()\n\n        running_loss += loss.item()\n\n        ps = F.softmax( outputs )\n        top_p, top_class = ps.topk( k=1, dim= 1)\n        equals = top_class == labels.view( *top_class.shape )\n\n        accuracy = torch.mean( equals.type( torch.float ))\n\n        running_accuracy += accuracy\n\n        # Printing the data for this loop\n        print('\\rEphoc {:3d} - Loop {:3d} in {:3d}: loss {:03.2f} - accuracy {:03.2f}'.format(epocha + 1, i + 1, len(loader), \n                                                                                              loss, accuracy), end = '\\r')\n\n    print('\\rEphoc {:3d} Finish: loss {:.5f} - accuracy {:.5f}'.format(epocha+1, running_loss\/len(loader), \n                     running_accuracy\/len( loader )))","d7e26aac":"for epocha in range( 15 ):\n    print('Training....')\n    Train_loop( train_loader, epocha )\n    print('Testing....')\n    #   Moving the model to the evaluation mode  \n    model.eval()\n    Train_loop( test_loader, epocha )\n    #   Moving the model to the training mode\n    model.train()","44e8536a":"# Save our model\ntorch.save( model.state_dict(), 'checkpoint.pth')","2b392d27":"model_forecast = model.eval()\nforecast = model_forecast.forward( test )","52bf118a":"forecast","b0924430":"forecast = F.softmax( forecast )","4a2ebac8":"forecast = forecast.cpu().detach().numpy()","5790b73e":"forecast","01a372a8":"results = [] \nfor i in range(len( forecast )):\n    results.append(np.argmax( forecast[i] )) ","ebb824b0":"results_f = np.array( results )","05dcda47":"# Salving submission\nresults =pd.DataFrame()\nresults['ImageId'] = sample_submission['ImageId']\nresults['Label'] = results_f.astype(int)","2e47b48d":"results.head()","7a622a19":"results.to_csv('submission_finish2.csv',index=False)","437b6116":"as we view the training data set has the Label column, then we must separate this column from the data sets so we can resize the images in the data sets the training and test","8dd2963d":"We get to the training of our model, where we go through our model according to the number of seasons defined. However, it is worth mentioning that the number of seasons is at the discretion of the readers","79e8930a":"First step we load our data sets to process the data, using *Pandas* as the reader is already known","da8450b2":"# **Treatment of test data**","76594bd5":"In the creation of our CNN model we defined that the reader is already known about the main concepts of an CNN, so we present our complete model in a constructive way.","bb1da37a":"# **Carrying out the forecast**","7a9ff343":"Here we are faced with a dimension problem which is the following: As the dimension of our data is a matrix *(x, y)* that is, two dimensions of values *(33600, 784)* for X_train. However, for our neural network model we need a dimensionality that is equivalent to *(x, y, z, j)* that is,\nfour dimensions and to solve this problem we will use the reshape *(x, y, z, j)* and we will take the value **784** which is equivalent to the pixels of our images and transform it into **28 X 28** which are the dimensions of the real images. Besides, we need to convert them to tensor.","4a72f2a7":"# **Using pytorch as a source for the implementation of the Convolutional Neural Network, obtaining a result of 0.99003 using the amount of 15 epochs, let's go to the code:**","8d53f76b":"Here we define the number of epochas and how many times we will train our model and for each epoch we train and test our model, considering that the accuracy we take into account is that of the test","a129654e":"In the last step, we will build a data loader from the 20% of the data selected for training and the 80% of the data that were selected for testing.","4255df12":"As we see the cell above, we realize that the data is between 0 and 255 which is equivalent to the RGB matrix, so we will have to map this data so that it is between 0 and 1. For this, we will use the class **MinMaxScaler()** and we will call your method **.fit_transform()** passing the data set *(train)* and our minimum and maximum mapping *(0, 1)* by parameter."}}