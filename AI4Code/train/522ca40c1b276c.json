{"cell_type":{"a2a1f0ec":"code","12cef7a9":"code","eedff8fd":"code","d43aae3e":"code","777d9186":"code","ab2a63fc":"code","a8235549":"code","ba76e3d9":"code","781f198c":"code","2747c629":"code","a2d681af":"code","51a98915":"code","af38bc0a":"code","f7bf01e3":"code","89e7ea83":"code","6e87a72c":"code","38a4a255":"code","7856b8e6":"code","e8e91fc7":"code","8f521ff2":"code","65a0479f":"code","c4ab12a1":"markdown","cf52a6a6":"markdown"},"source":{"a2a1f0ec":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","12cef7a9":"df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')","eedff8fd":"df","d43aae3e":"def feat_eng(df):\n    countries = {'Finland': 1, 'Norway': 2, 'Sweden': 3}\n    stores = {'KaggleMart': 1, 'KaggleRama': 2}\n    products = {'Kaggle Mug': 1,'Kaggle Hat': 2, 'Kaggle Sticker': 3}\n    \n    # load holiday info.\n    holiday = pd.read_csv('..\/input\/public-and-unofficial-holidays-nor-fin-swe-201519\/holidays.csv')\n    \n    fin_holiday = holiday.loc[holiday.country == 'Finland']\n    swe_holiday = holiday.loc[holiday.country == 'Sweden']\n    nor_holiday = holiday.loc[holiday.country == 'Norway']\n    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    df['date'] = pd.to_datetime(df['date'])\n    df['year'] = df['date'].dt.year\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['week']= df['date'].dt.weekday\n    df['country'] = df['country'].replace(countries)\n    df['store'] = df['store'].replace(stores)\n    df['product'] = df['product'].replace(products)\n    df = df.drop(columns = 'row_id')\n    df = df.drop(columns = 'date')\n    return df","777d9186":"df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')","ab2a63fc":"df_train = feat_eng(df)","a8235549":"df_train","ba76e3d9":"train_y = df_train['num_sold']\ntrain_x = df_train[['country',\n                   'store',\n                   'product',\n                   'holiday',\n                   'year',\n                   'quarter',\n                   'month',\n                   'day',\n                   'week']]","781f198c":"print(type(train_x))","2747c629":"train_x","a2d681af":"print(type(train_y))","51a98915":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","af38bc0a":"SEED   = 42","f7bf01e3":"from sklearn.metrics import log_loss, mean_squared_error\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\n\nkf = KFold(n_splits = 4, shuffle = True, random_state = 71)\nfold = 1\nfor tr_idx, va_idx in kf.split(train_x):\n    print(f'--------fold:{fold}--------')\n    fold+=1\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    \n    dtrain = xgb.DMatrix(tr_x, label = tr_y)\n    dvalid = xgb.DMatrix(va_x, label = va_y)\n\n    xgboost_params = {'eta'              : 0.1,\n                  'n_estimators'     : 16384,\n                  'max_depth'        : 8,\n                  'max_leaves'       : 256,\n                  'colsample_bylevel': 0.75,\n                  'colsample_bytree' : 0.75,\n                  'subsample'        : 0.75, # XGBoost would randomly sample 'subsample_value' of the training data prior to growing trees\n                  'min_child_weight' : 512,\n                  'min_split_loss'   : 0.002,\n                  'alpha'            : 0.08,\n                  'lambda'           : 128,\n                  'objective'        : 'reg:squarederror',\n                  'eval_metric'      : 'rmse', # Originally using RMSE, trying new functions...\n                  'seed'             : SEED\n                  }\n    \n    watch_list = [(dtrain, 'train'), (dvalid, 'eval')]\n    model = XGBRegressor(**xgboost_params)\n    \n    va_pred = model.fit(tr_x,\n              tr_y,\n              eval_set=[(va_x, va_y)],\n              early_stopping_rounds = 250,\n              verbose = 500)\n    val_pred = model.predict(va_x)\n    # Convert the target back to non-logaritmic.\n    print(f' SMAPE: {SMAPE(va_y, val_pred)}')","89e7ea83":"test = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')","6e87a72c":"test = feat_eng(test)","38a4a255":"test","7856b8e6":"y = model.predict(test)","e8e91fc7":"a =pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv') ","8f521ff2":"a['num_sold'] = y","65a0479f":"a.to_csv('.\/submission.csv', index = False)","c4ab12a1":"# Feature Engineering\n\nYou can start feature engineering quickly by The function 'feat_eng'(df)'\n\ndf is train.csv or test.csv","cf52a6a6":"## Data\n* country\n* store\n* product\n* (num_sold)\n* holiday (By Country)\n* year\n* quarter\n* month\n* day\n* week\n"}}