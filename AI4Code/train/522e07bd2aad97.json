{"cell_type":{"d9323f07":"code","93b4aede":"code","b63a833b":"code","d76ccbed":"code","6092f1c4":"code","4d075999":"code","de52c673":"code","9afe0223":"code","f96ca6cc":"code","b871cebd":"code","a3493a6d":"code","78d9a202":"code","f279453c":"code","7baa3004":"code","d0e3e02d":"code","add3ee7d":"code","aae70f9c":"code","1d7b2ba0":"code","4d2f4958":"code","688dc8f6":"code","6bebb6de":"code","9e7a597a":"code","4487ecc0":"code","a9ccc796":"code","c0f702d6":"code","30a24ee8":"code","56f1d452":"code","fffdc4b3":"code","7309f1cb":"code","f9eec8c3":"code","7b7aa661":"code","b663dee5":"code","dddeca23":"code","b2e61d2c":"code","15cbb819":"code","fa81b7f9":"code","c23b1f67":"code","e7e8bf02":"code","82b66a56":"code","c42a25fb":"code","d040bcb5":"code","8334322f":"code","3e91ea23":"code","e29c552b":"code","52f5859c":"code","89559a27":"code","665b10a9":"code","2a830cb9":"code","9824155a":"code","b5d1583a":"code","3ad22802":"code","9c6cafdb":"code","58aed01c":"markdown","a28608c0":"markdown","d2bcfc25":"markdown","5e54b137":"markdown","296a1446":"markdown","18ec866b":"markdown","a5734c1f":"markdown","c68de21a":"markdown","357a0498":"markdown","6738e5a8":"markdown","01f329d8":"markdown","26e4ccaa":"markdown","38adeb8f":"markdown","10c50081":"markdown","d03cdd71":"markdown","7a6fc6be":"markdown","faea66a0":"markdown","99567e30":"markdown","d79dc010":"markdown","69946599":"markdown"},"source":{"d9323f07":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport tensorflow as tf \nimport sklearn\nimport os \nimport pathlib\nfrom PIL import Image\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import SGDRegressor\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split","93b4aede":"data_path = r\"..\/input\/the-boston-houseprice-data\/boston.csv\"\ndata = pd.read_csv(data_path)\n","b63a833b":"data.head()","d76ccbed":"data.info()\n#NO missing values","6092f1c4":"data[\"RAD\"].value_counts()","4d075999":"Charles_River_dummy_variable = data[\"CHAS\"]\nCharles_River_dummy_variable.plot(kind='hist')","de52c673":"Charles_River_dummy_variable.value_counts()","9afe0223":"print(\"{}% of the houses (tract bounds river) class: 0\".format(\n    round((len(Charles_River_dummy_variable[Charles_River_dummy_variable==0]) \/ len(Charles_River_dummy_variable) * 100), 3)))","f96ca6cc":"data.describe()","b871cebd":"data.hist(figsize=(25, 25))","a3493a6d":"data[\"MEDV\"].describe()","78d9a202":"data.cov()","f279453c":"data.corr()","7baa3004":"sns.heatmap(data.corr())","d0e3e02d":"pd.plotting.scatter_matrix(data[[ 'RM','AGE',\n                                 'DIS','RAD',\n                                 'TAX','CRIM',\n                                 'MEDV']], figsize=(12,12))","add3ee7d":"data.duplicated()","aae70f9c":"# no duplicated rows\ndata.duplicated().sum()","1d7b2ba0":"# split the data to training and testing datasets\n\nx_all = data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']]\ny = data['MEDV']\n\nx_train, x_test, y_train, y_test = train_test_split(x_all, y, test_size=0.2)","4d2f4958":"x_train.head()","688dc8f6":"num_features = ['ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\ncat_features = [\"CHAS\"]\n\n\npreprocessing_pipeline = ColumnTransformer([\n    ('num', MinMaxScaler(), num_features),\n    ('cat', OneHotEncoder(), cat_features)\n])\n\nx_train_prepered = preprocessing_pipeline.fit_transform(x_train)","6bebb6de":"x_train_prepered.shape","9e7a597a":"y_train = np.array(y_train)","4487ecc0":"x_test_prepered = preprocessing_pipeline.fit_transform(x_test)","a9ccc796":"y_test = np.array(y_test)","c0f702d6":"linear_regression = LinearRegression()\n\nlinear_regression.fit(x_train_prepered, y_train)\nlinear_regression.score(x_train_prepered, y_train)","30a24ee8":"linear_regression = LinearRegression()\nlinear_regression.fit(x_train_prepered, y_train)\ntraining_score = linear_regression.score(x_train_prepered, y_train)\n\nstr_shuffle_split = StratifiedShuffleSplit(train_size=0.75, test_size=0.25, n_splits=5)\nscores = cross_val_score(linear_regression,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='neg_mean_absolute_error')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","56f1d452":"linear_regression_mae = sklearn.metrics.mean_absolute_error(y_test, linear_regression.predict(x_test_prepered))\nlinear_regression_mae","fffdc4b3":"ridge = Ridge(alpha=5)\nridge.fit(x_train_prepered, y_train)\ntraining_score = ridge.score(x_train_prepered, y_train)\n\nscores = cross_val_score(ridge,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='neg_mean_absolute_error')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","7309f1cb":"ridge_mae = sklearn.metrics.mean_absolute_error(y_test, ridge.predict(x_test_prepered))\nridge_mae","f9eec8c3":"SGDRegressor","7b7aa661":"sgd_regressor = SGDRegressor()\nsgd_regressor.fit(x_train_prepered, y_train)\ntraining_score = sgd_regressor.score(x_train_prepered, y_train)\n\nscores = cross_val_score(sgd_regressor,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='neg_mean_absolute_error')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","b663dee5":"sgd_regressor_mae = sklearn.metrics.mean_absolute_error(y_test, sgd_regressor.predict(x_test_prepered))\nsgd_regressor_mae","dddeca23":"#overfitting the training dataset\ndt_regressor = DecisionTreeRegressor()\ndt_regressor.fit(x_train_prepered, y_train)\ntraining_score = dt_regressor.score(x_train_prepered, y_train)\n\nscores = cross_val_score(dt_regressor,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='r2')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","b2e61d2c":"dt_regressor_mae = sklearn.metrics.mean_absolute_error(y_test, dt_regressor.predict(x_test_prepered))\ndt_regressor_mae","15cbb819":"#less overfitting than the DecisionTreeRegressor but better performance in validation dataset\nrf_regressor = RandomForestRegressor()\nrf_regressor.fit(x_train_prepered, y_train)\ntraining_score = rf_regressor.score(x_train_prepered, y_train)\n\nscores = cross_val_score(rf_regressor,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='r2')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","fa81b7f9":"rf_regressor_mae = sklearn.metrics.mean_absolute_error(y_test, rf_regressor.predict(x_test_prepered))\nrf_regressor_mae","c23b1f67":"sv_regressor = SVR()\nsv_regressor.fit(x_train_prepered, y_train)\ntraining_score = sv_regressor.score(x_train_prepered, y_train)\n\nscores = cross_val_score(sv_regressor,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='r2')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","e7e8bf02":"sv_regressor_mae = sklearn.metrics.mean_absolute_error(y_test, sv_regressor.predict(x_test_prepered))\nsv_regressor_mae","82b66a56":"linearsv_regressor = LinearSVR()\nlinearsv_regressor.fit(x_train_prepered, y_train)\ntraining_score = linearsv_regressor.score(x_train_prepered, y_train)\n\nscores = cross_val_score(linearsv_regressor,\n                        x_train_prepered, y_train, cv=5,\n                        scoring='r2')\n\nprint(\"Cross Validation Scores: {} \\n\".format(scores))\nprint(\"The Mean of Cross Validation Scores: {} \\n\".format(scores.mean()))\nprint(\"Training Score: {}\".format(training_score))","c42a25fb":"linearsv_regressor_mae = sklearn.metrics.mean_absolute_error(y_test, linearsv_regressor.predict(x_test_prepered))\nlinearsv_regressor_mae","d040bcb5":"x_train_prepered.shape","8334322f":"model = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(14,),\n                               kernel_regularizer=tf.keras.regularizers.L2()))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.compile(loss='mae',\n             optimizer='rmsprop',\n             metrics=['mae'])\n\nhistory = model.fit(x_train_prepered, y_train,\n                    epochs=200, batch_size=64)#,\n                    #validation_split=0.2)","3e91ea23":"model.evaluate(x_train_prepered, y_train)","e29c552b":"simple_Dence_NN_loss, simple_Dence_NN_mae = model.evaluate(x_test_prepered, y_test)\nsimple_Dence_NN_mae","52f5859c":"RF_DNN_MAE = sklearn.metrics.mean_absolute_error(y_test,\n                                    (((model.predict(x_test_prepered)).reshape(-1) + rf_regressor.predict(x_test_prepered))\/2))\nRF_DNN_MAE","89559a27":"models = pd.DataFrame({\n    'Model': ['Linear Regression', 'Ridge', \n              'SGDRegressor',  'DecisionTreeRegressor', \n              'RandomForestRegressor', 'SVR', 'Linear SVR', \n              'simple Dence NN', 'RF_DNN_MAE'],\n    \n    'MAE': [linear_regression_mae, ridge_mae, sgd_regressor_mae, \n              dt_regressor_mae, rf_regressor_mae, sv_regressor_mae, \n              linearsv_regressor_mae, simple_Dence_NN_mae, RF_DNN_MAE]})\nmodels","665b10a9":"def make_prediction(i):\n    \n    pred = (model.predict(x_test_prepered[i].reshape(1, -1)).reshape(-1) +\n            rf_regressor.predict(x_test_prepered[i].reshape(1, -1)))\/2\n    \n    return(pred)","2a830cb9":"make_prediction(1)","9824155a":"y_test[1]","b5d1583a":"make_prediction(6)","3ad22802":"y_test[6]","9c6cafdb":"np.sqrt(sklearn.metrics.mean_squared_error(y_test,\n                                    (((model.predict(x_test_prepered)).reshape(-1) + rf_regressor.predict(x_test_prepered))\/2)))","58aed01c":"These attributes have different scales and som of them have large standard deviation I \nwill scale them later.","a28608c0":"## Ridge ","d2bcfc25":"## correlations and covariance","5e54b137":"## RandomForestRegressor","296a1446":"averaging the prediction of RandomForestRegressor with the simple Dence NN \ngiv us better results than the two of the separated.","18ec866b":"# Training and Evaluation","a5734c1f":"## simple Dence NN","c68de21a":"## SGDRegressor","357a0498":"## discribtive statistics","6738e5a8":"# Understanding The Data ","01f329d8":"## SVR, LinearSVR","26e4ccaa":"The prices ranged from 5,000 to 50,000 the machine learning algorithms my facing difficulties to trying\nto predict prices out of this range and learn that the prices may not go beyond 50,000","38adeb8f":"## DecisionTreeRegressor","10c50081":"Context\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.\n\nAttribute Information\nInput features in order:\n1) CRIM: per capita crime rate by town\n\n2) ZN: proportion of residential land zoned for lots over 25,000 sq.ft\n.\n3) INDUS: proportion of non-retail business acres per town\n\n4) CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n\n5) NOX: nitric oxides concentration (parts per 10 million) [parts\/10M]\n\n6) RM: average number of rooms per dwelling\n\n7) AGE: proportion of owner-occupied units built prior to 1940\n\n8) DIS: weighted distances to five Boston employment centres\n\n9) RAD: index of accessibility to radial highways\n\n10) TAX: full-value property-tax rate per $10,000 [$\/10k]\n\n11) PTRATIO: pupil-teacher ratio by town\n\n12) B: The result of the equation B=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n\n13) LSTAT: % lower status of the population\n\nOutput variable:\n1) MEDV: Median value of owner-occupied homes in $1000's [k$]","d03cdd71":"# Feature Engineering and data preperation","7a6fc6be":"I will use the grid search to find the best estimator of different algorithms","faea66a0":"as we can see from the covariance table there are positive and inverse relationships","99567e30":"from this scatter plots we can find the correlatd attributes such as the clear relationship \nbetween  the average number of rooms per dwelling (RM) and the Median value of owner-occupied homes(MEDV)\nas the number of rooms increase the MEDV increase","d79dc010":"## removing duplicate rows","69946599":"## Linear Regression"}}