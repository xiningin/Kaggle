{"cell_type":{"6d5079e8":"code","2311c22e":"code","25b72bae":"code","105fdb72":"code","78e4fba6":"code","5cbf5d82":"code","3c3acc69":"code","a2110e7e":"code","bfdd80b8":"code","25b4373c":"code","79ff261d":"markdown","d3471d06":"markdown","58750f81":"markdown","75d0fa04":"markdown"},"source":{"6d5079e8":"!pip install tslearn","2311c22e":"import pandas as pd\nimport numpy as np\nimport os\n\nimport numpy\nimport matplotlib.pyplot as plt\n\nfrom tslearn.clustering import TimeSeriesKMeans\nfrom tslearn.datasets import CachedDatasets\nfrom tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n\nfrom sklearn.model_selection import train_test_split","25b72bae":"path = '..\/input\/ventilator-pressure-prediction'\ntrain = pd.read_csv(os.path.join(path, 'train.csv'))\ntest = pd.read_csv(os.path.join(path, 'test.csv'))\nsub = pd.read_csv(os.path.join(path, 'sample_submission.csv'))","105fdb72":"X = train['u_in'].values\ny = train['pressure'].values","78e4fba6":"elbow_data = []\nfor n_clusters in range (10,500,5):\n    train_ts = train['u_in'].values.reshape(-1, 80)\n    y = train['pressure'].values\n    test_ts = test['u_in'].values.reshape(-1, 80)\n\n    X_train = train_ts[:1000] # using only first 1.000 as a sample\n\n    km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=False, random_state=42,n_jobs=-1)\n    y_pred = km.fit_predict(X_train)\n    elbow_data.append((n_clusters, km.inertia_))\n\npd.DataFrame(elbow_data,columns=['clusters', 'distance']).plot(x='clusters',y='distance')","5cbf5d82":"N_CLUSTERS = 60\n\ntrain_ts = train['u_in'].values.reshape(-1, 80)\ny = train['pressure'].values\ntest_ts = test['u_in'].values.reshape(-1, 80)\n\nX_train = train_ts[:1000]  # using only first 1.000 as a sample\ny_train = y[:1000]  # using only first 1.000 as a sample\n\n\n# Euclidean k-means\nkm = TimeSeriesKMeans(n_clusters=N_CLUSTERS, verbose=False, random_state=42,n_jobs=-1)\ny_pred = km.fit_predict(X_train)\n\nprint(f'Inertia: {km.inertia_}')","3c3acc69":"y_pred = km.predict(train_ts)\nplt.figure()\nplt.subplots(figsize = (20, 16))\nfor yi in range(N_CLUSTERS):\n    plt.subplot(10, 6, yi + 1)\n    for xx in train_ts[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    for xx in y.reshape(-1, 80)[y_pred == yi]:\n        plt.plot(xx.ravel(), 'b-')\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","a2110e7e":"train_clusters = km.predict(train_ts)\ntest_clusters = km.predict(test_ts)","bfdd80b8":"pd.DataFrame(train_clusters, columns=['cluster']).value_counts().rename('count').reset_index()","25b4373c":"pd.DataFrame({'cluster':np.repeat(train_clusters, 80)}).to_csv('train_ts_clusters.csv')\npd.DataFrame({'cluster':np.repeat(test_clusters, 80)}).to_csv('test_ts_clusters.csv')","79ff261d":"# TimeSeriesKmeans clustering\nThe idea of this notebook is to cluster the different breath ids according to its shape in order to use it in the feature engineering \nThe output is two csv's with the cluster to which each row of the train_set and test_set corresponds.\nAlthough it seemed like a good idea, I did not manage to improve the CV\/LB when I used it on my feature engineering models.\n\n\nhttps:\/\/towardsdatascience.com\/how-to-apply-k-means-clustering-to-time-series-data-28d04a8f7da3\n\nhttps:\/\/tslearn.readthedocs.io\/en\/stable\/auto_examples\/clustering\/plot_kmeans.html#sphx-glr-auto-examples-clustering-plot-kmeans-py\n\n","d3471d06":"## Elbow Method\n\nTo determine the number of clusters I used the elbow method.<br>\nThe method consists of plotting the explained variation as a function of the number of clusters, and picking the elbow of the curve as the number of clusters to use.","58750f81":"## Ploting clusters\n\n__Black lines__: u_in of all breath ids in cluster<br>\n__Red lines__: cluster u_in center<br>\n__Blue lines__: pressure of all breath ids in cluster","75d0fa04":"###  Number Breath ids per cluster"}}