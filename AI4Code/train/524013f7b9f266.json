{"cell_type":{"7bee6004":"code","c9a4dc58":"code","437e105b":"code","32c2c799":"code","e2525d38":"code","91f1e01d":"code","2816fc3a":"code","4798c45a":"code","61e38375":"code","75df6405":"code","78b7d36f":"code","9ca2bc8a":"code","57364c74":"code","75e07fef":"code","d75189a9":"code","c4542d4b":"code","08fd04e1":"code","6176f26b":"code","9193614c":"code","5cb19b58":"code","54afd6da":"code","2db99fa6":"code","c7100be4":"code","8387fe90":"code","2c2774b8":"code","cc75b256":"code","c096c35b":"code","26d51882":"code","0f224d89":"code","f1be7afb":"code","26f13524":"code","b34d2b35":"code","a398f5f3":"code","e7c15f1a":"code","44b54ffd":"code","140512c5":"code","b68b0cb1":"code","5ed2f841":"code","97e7acb0":"code","84c2b862":"code","aa50552c":"code","e20fddec":"code","9a2a9d50":"code","5dd1b69d":"markdown","b5209559":"markdown","fa8c2659":"markdown","434ad022":"markdown","f94300ee":"markdown","f8a6aacf":"markdown","6144b457":"markdown","4cda61cb":"markdown","2628f7a7":"markdown","fc616530":"markdown","7887586b":"markdown","46601f8e":"markdown","e4680187":"markdown","8be34668":"markdown","c2cdda69":"markdown","e97d4a2c":"markdown","db299568":"markdown","dec135ad":"markdown","ac7d4385":"markdown","7fb1e7ee":"markdown","50514396":"markdown","05216ed2":"markdown","de7e3905":"markdown","970c787a":"markdown"},"source":{"7bee6004":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\n%matplotlib inline","c9a4dc58":"from sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom mlxtend.preprocessing import minmax_scaling\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import StratifiedKFold, KFold, LeaveOneGroupOut\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer","437e105b":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","32c2c799":"def roc_auc(true_list, pred_list):\n    \n    fpr, tpr, _ = roc_curve(true_list, pred_list)    \n    roc_auc = auc(fpr, tpr)\n\n    print(f'FPR: {fpr}')\n    print(f'TPR: {tpr}')\n    print(f'{list(zip(fpr,tpr))}')\n    print(f'\\nROC_AUC: %0.2f\\n' %roc_auc)\n    \n    plt.style.use('seaborn-whitegrid')\n    plt.figure(figsize=(6, 6), facecolor='lightgray')\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'\\nThe area under the ROC curve\\n')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n       ","e2525d38":"true_list  = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n\npred_list1 = np.array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n\npred_list2 = np.array([0.8, 0.8, 0.8, 0.8, 0.2, 0.2, 0.2, 0.2, 0.2, 0.8])\n\npred_list3 = np.array([0.8, 0.8, 0.8, 0.8, 0.5, 0.2, 0.2, 0.2, 0.2, 0.8])","91f1e01d":"roc_auc(true_list , pred_list1)","2816fc3a":"roc_auc(true_list , pred_list2)","4798c45a":"roc_auc(true_list , pred_list3)","61e38375":"DF1 = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\n\nDF2 = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\n\nSAM = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\n\ndisplay(DF1.shape, DF2.shape, SAM.shape)","75df6405":"MV1 = DF1.isnull().sum()\nMV2 = DF2.isnull().sum()\n\nprint(f'Missing Value DF1:\\n{MV1[MV1 > 0]}\\n')\nprint(f'Missing Value DF2:\\n{MV2[MV2 > 0]}\\n')","78b7d36f":"display(DF1, DF2)\n\n# display(DF1.describe().transpose())\n# display(DF2.describe().transpose())","9ca2bc8a":"print('=' * 40)\nDF1.info(memory_usage='deep')\nprint('=' * 40)\nDF2.info(memory_usage='deep')\nprint('=' * 40)","57364c74":"columns = DF2.columns[1:]\ndisplay(columns)","75e07fef":"DF1['claim'].value_counts().plot(figsize=(4, 4), kind='bar')","d75189a9":"DF1['claim'].value_counts().plot(figsize=(6, 6), kind='pie')\n\nDF1['claim'].value_counts(normalize=True)","c4542d4b":"X = DF1.drop(columns = ['id','claim'])\n\nXX = DF2.drop(columns = ['id'])\n\ny = DF1.claim\n\n#display(X, XX, y)\n#display(y.min(), y.max())","08fd04e1":"hist_data = [ y ]  \n\ngroup_labels = ['y']\n    \nfig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_hist=False, show_rug=False) \n\nfig.show()","6176f26b":"train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.50, random_state=123) \n\nval_X.to_csv(\"val_X.csv\",index=False)\nval_y.to_csv(\"val_y.csv\",index=False)","9193614c":"X_scaled = minmax_scaling(X, columns=X.columns)\n\nXX_scaled = minmax_scaling(XX, columns=XX.columns)\n\n#display(X_scaled, XX_scaled)","5cb19b58":"!pip install autogluon\n\nfrom autogluon.tabular import TabularDataset, TabularPredictor","54afd6da":"#data1 = TabularDataset('\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv').drop('id', axis=1)\n\n#data2 = TabularDataset('\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv').drop('id', axis=1)\n\n#display(data1.shape,data2.shape)","2db99fa6":"#model1 = TabularPredictor(label= 'claim',\n#                          eval_metric= 'roc_auc',\n#                          verbosity= 3)\n\n#model1.fit(train_data= data1,\n#           time_limit= 3* 3600,\n#           presets='best_quality',\n#           verbosity= 3)\n\n#model1.leaderboard(data1, silent=True)","c7100be4":"#results = model1.fit_summary()","8387fe90":"#pred1 = model1.predict_proba(data2)\n#display(pred1)","2c2774b8":"#sub1 = SAM.copy()\n\n#sub1.iloc[:, 1] = pred1[1]\n#display(sub1)","cc75b256":"#hist_data = [sub1.claim]  \n\n#group_labels = ['AutoGluon - 1']\n    \n#fig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_hist=False, show_rug=False) \n\n#fig.show()","c096c35b":"#sub1.to_csv(\"submission_AutoGluon1.csv\",index=False)\n#Public Score: ","26d51882":"df1 = DF1.drop(columns = ['id','claim'])\n\ndf2 = DF2.drop(columns = ['id'])\n\ndisplay(df1.shape,df2.shape)","0f224d89":"df1['mvl_row'] = df1.isna().sum(axis=1)\ndf1['min_row'] = df1.min(axis=1)\ndf1['std_row'] = df1.std(axis=1)\n\npipeline = Pipeline([('impute', SimpleImputer(strategy='mean')), ('scale', StandardScaler())])\n\ndf1 = pd.DataFrame(columns=df1.columns, data=pipeline.fit_transform(df1))\ndf1['claim'] = DF1['claim']\ndisplay(df1)","f1be7afb":"df2['mvl_row'] = df2.isna().sum(axis=1)\ndf2['min_row'] = df2.min(axis=1)\ndf2['std_row'] = df2.std(axis=1)\n\npipeline = Pipeline([('impute', SimpleImputer(strategy='mean')), ('scale', StandardScaler())])\n\ndf2 = pd.DataFrame(columns=df2.columns, data=pipeline.fit_transform(df2))\ndisplay(df2)","26f13524":"model2 = TabularPredictor(label= 'claim',\n                          eval_metric= 'roc_auc',\n                          verbosity= 3)\n\nmodel2.fit(train_data= df1,\n           time_limit= 3* 3600,\n           presets='best_quality',\n           verbosity= 3)\n\nmodel2.leaderboard(df1, silent=True)","b34d2b35":"results = model2.fit_summary()","a398f5f3":"pred2 = model2.predict_proba(df2)\ndisplay(pred2)","e7c15f1a":"sub2 = SAM.copy()\n\nsub2.iloc[:, 1] = pred2[1]\ndisplay(sub2)","44b54ffd":"hist_data = [sub2.claim]  \n\ngroup_labels = ['AutoGluon - 2']\n    \nfig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_hist=False, show_rug=False) \n\nfig.show()","140512c5":"sub2.to_csv(\"submission_AutoGluon2.csv\",index=False)\n# Public Score:","b68b0cb1":"def ensembling(main, support, coeff): \n    \n    suba  = main.copy() \n    subav = suba.values\n       \n    subb  = support.copy()\n    subbv = subb.values    \n           \n    ense  = main.copy()    \n    ensev = ense.values  \n \n    for i in range (len(main)):\n        \n        pera = subav[i, 1]\n        perb = subbv[i, 1]\n        per = (pera * coeff) + (perb * (1.0 - coeff))   \n        ensev[i, 1] = per\n        \n    ense.iloc[:, 1] = ensev[:, 1]  \n    \n    ###############################    \n    X  = suba.iloc[:, 1]\n    Y1 = subb.iloc[:, 1]\n    Y2 = ense.iloc[:, 1]\n    \n    plt.style.use('seaborn-whitegrid') \n    plt.figure(figsize=(9, 9), facecolor='lightgray')\n    plt.title(f'\\nE N S E M B L I N G\\n')   \n      \n    plt.scatter(X, Y1, s=1.5, label='Support')    \n    plt.scatter(X, Y2, s=1.5, label='Generated')\n    plt.scatter(X, X , s=0.1, label='Main(X=Y)')\n    \n    plt.legend(fontsize=12, loc=2)\n    #plt.savefig('Ensembling_1.png')\n    plt.show()     \n    ###############################   \n    ense.iloc[:, 1] = ense.iloc[:, 1].astype(float)\n    hist_data = [subb.iloc[:, 1], ense.iloc[:, 1], suba.iloc[:, 1]] \n    group_labels = ['Support', 'Ensembling', 'Main']\n    \n    fig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_hist=False, show_rug=False)\n    fig.show()   \n    ###############################       \n    \n    return ense      ","5ed2f841":"path0 = '..\/input\/tps9-81783\/TPS9_81783.csv' \n\nsub81783 = pd.read_csv(path0)","97e7acb0":"hist_data = [sub81783.claim]  \n\ngroup_labels = ['Public Score: 0.81783']\n    \nfig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_hist=False, show_rug=False) \n\nfig.show()","84c2b862":"path1 = '..\/input\/tps9-81800\/TPS9_81800.csv' \n\nsub81800 = pd.read_csv(path1)","aa50552c":"hist_data = [sub81800.claim]  \n\ngroup_labels = ['Public Score: 0.81800']\n    \nfig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_hist=False, show_rug=False) \n\nfig.show()","e20fddec":"sub3 = ensembling(sub81783, sub2, 0.80)\n\nsub4 = ensembling(sub81800, sub3, 0.70)","9a2a9d50":"sub3.to_csv(\"submission3.csv\",index=False)\nsub4.to_csv(\"submission_Final.csv\",index=False)\n!ls","5dd1b69d":"Thanks to: @maximkazantsev https:\/\/www.kaggle.com\/maximkazantsev\/tps-09-21-eda-lightgbm-with-folds","b5209559":"## Model - 2 \n\n## AutoGluon & Feature Engineering","fa8c2659":"<div class=\"alert alert-success\">  \n<\/div>","434ad022":"<div class=\"alert alert-success\">  \n<\/div>","f94300ee":"<div class=\"alert alert-success\">  \n<\/div>","f8a6aacf":"<div class=\"alert alert-success\">  \n<\/div>","6144b457":"<div class=\"alert alert-success\">  \n<\/div>","4cda61cb":"<div>\n    <h1 align=\"center\">AutoGluon & Missing Values<\/h1>    \n    <h1 align=\"center\">Tabular Playground Series - Sep 2021<\/h1> \n    <h4 align=\"center\">By: Somayyeh Gholami & Mehran Kazeminia<\/h4>\n<\/div>","2628f7a7":"## Competition Evaluation\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n\nThanks to: @ihelon","fc616530":"<div class=\"alert alert-success\">  \n<\/div>","7887586b":"## Split","46601f8e":"## Submission","e4680187":"## Scaling","8be34668":"## Model - 1 \n\n## AutoGluon\n\nThanks to: @antonellomartiello","c2cdda69":"## Data Set of Challenge","e97d4a2c":"<div class=\"alert alert-success\">  \n<\/div>","db299568":"## Missing Values \n\n## Feature Engineering\n\nThanks to: @mlanhenke","dec135ad":"Thanks to: @mlanhenke https:\/\/www.kaggle.com\/mlanhenke\/tps-09-single-catboostclassifier","ac7d4385":"## Ensembling","7fb1e7ee":"<div class=\"alert alert-success\">\n    <h3 align=\"center\">If you find this work useful, please don't forget upvoting :)<\/h3>\n<\/div>","50514396":"## Description:\n\n### The capabilities of \"AutoGluon\" are enormous. With just a few lines of coding, you can get a good result. But is \"Missing Values\" handling successful in \"AutoGluon\"? Or is it better to do this step by ourselves.\n\n### In this notebook, \"Model-1\" was initially created using only \"AutoGluon\". But we then handled the \"Missing Values\" ourselves and then provided these results to \"AutoGluon\" to create the \"Model-2\".\n\n### The \"Model-2\" score at the same time was much better than the \"Model-1\" score. We checked this several times. However, if we did not make a mistake, we can conclude that handling \"Missing Values\" manually is still better.\n\n### Good Luck.\n","05216ed2":"<div class=\"alert alert-success\">  \n<\/div>","de7e3905":"<div class=\"alert alert-success\">  \n<\/div>","970c787a":"<div class=\"alert alert-success\">  \n<\/div>"}}