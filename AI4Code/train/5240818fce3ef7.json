{"cell_type":{"9a422854":"code","5620482f":"code","2f21c034":"code","d3d700e7":"code","a9d5a6de":"code","943c501b":"code","afec2906":"code","592f738e":"code","6d6a01d2":"code","ece1f2c5":"code","6fca6ba9":"code","f3b30668":"code","2d487537":"code","69c967a3":"code","af32fe2a":"code","6259dcf4":"code","18d367de":"code","66c1fbc8":"code","e33316b0":"code","08e5d35b":"code","ef89b656":"code","b6f7c3e5":"code","32438cde":"code","cbe4a081":"code","45bc837f":"code","479dbc62":"code","2e37a647":"code","d417e815":"code","69cb556c":"code","9567094f":"code","d1b8267f":"code","f3a9f5a9":"code","44be984d":"code","f60cbea5":"code","8bbff561":"code","4000003c":"code","13b89af0":"code","a757193f":"code","af97bd11":"code","270c3e95":"code","5629df5e":"code","d61d98fb":"code","6a6a7674":"code","43513cbf":"code","bab7d308":"code","5e79bb66":"code","c4f95c2f":"code","78cdffd8":"code","b3a99884":"code","c17fef5b":"code","6351e98d":"code","996e8a65":"code","eec530e4":"code","c383288b":"code","7d8f222e":"code","94e27e43":"code","f4a8bd65":"code","d619b7fc":"code","511b622c":"code","cb3939c2":"code","a17a03ee":"markdown","97459067":"markdown","6ab9d00b":"markdown","2b4c6a5e":"markdown","235e17f6":"markdown","ab9af6c5":"markdown","d61c3d6c":"markdown","f2abadb3":"markdown","825bcf55":"markdown","5cbf40a7":"markdown","cb91e79e":"markdown","40f53228":"markdown","51b4ac0f":"markdown","a080351e":"markdown","6baafb58":"markdown","65e3d794":"markdown","f1ff6974":"markdown","56034a19":"markdown","873807df":"markdown","66080782":"markdown","04b64ca8":"markdown","4846c9b7":"markdown","68b65cb1":"markdown","877240fc":"markdown","ef210540":"markdown","a72493cc":"markdown","1b3b8cca":"markdown","9c8ecec3":"markdown","4fb55938":"markdown","d7c04762":"markdown","c36413b2":"markdown","3fce7f74":"markdown","0a1ad475":"markdown","0a92109b":"markdown","ed64e5cf":"markdown"},"source":{"9a422854":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5620482f":"import pandas as pd\nimport numpy as np","2f21c034":"train_data = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Test.csv')","d3d700e7":"print('\\nShape of training data :',train_data.shape)\nprint('\\nShape of testing data :',test_data.shape)","a9d5a6de":"train_data[\"source\"]=\"train\"\ntest_data[\"source\"]=\"test\"\ndata = pd.concat([train_data,test_data], sort= True)","943c501b":"print (train_data.shape, test_data.shape, data.shape , sep = \"\\n\")","afec2906":"data.head()","592f738e":"data.tail()","6d6a01d2":"data.describe()","ece1f2c5":"data.info()","6fca6ba9":"cat_col = data.select_dtypes(include=\"object\")\n\nfor c in cat_col:\n    if c not in( 'Item_Identifier','Outlet_Identifier','source'):\n        print( \"\\n Feature:\",c)\n        print(data[c].value_counts())","f3b30668":"import matplotlib.pyplot as plt\nimport seaborn as sns","2d487537":"sns.distplot(train_data['Item_Outlet_Sales'])\nplt.show()\n\nprint('Skewness: %f' % train_data['Item_Outlet_Sales'].skew())\nprint('Kurtsis: %f' %train_data['Item_Outlet_Sales'].kurt())","69c967a3":"train_data['Item_Weight'].hist(bins = 100);\nplt.show()","af32fe2a":"train_data['Item_Visibility'].hist(bins = 100);\nplt.show()","6259dcf4":"train_data['Item_MRP'].hist(bins = 100);\nplt.show()","18d367de":"sns.catplot(x= \"Item_Type\", data= train_data, kind = \"count\", aspect=4)\nplt.show()","66c1fbc8":"sns.catplot(x= \"Outlet_Size\", data= train_data, kind = \"count\")\nplt.show()","e33316b0":"sns.catplot(x= \"Item_Fat_Content\", data= train_data, kind = \"count\")\nplt.show()","08e5d35b":"sns.catplot(x= \"Outlet_Location_Type\", data= train_data, kind = \"count\")\nplt.show()","ef89b656":"sns.catplot(x= \"Outlet_Type\", data= train_data, kind = \"count\",aspect=2)\nplt.show()","b6f7c3e5":"data[\"Outlet_Establishment_Year\"]=data[\"Outlet_Establishment_Year\"].astype(\"category\")\nsns.catplot(x= \"Outlet_Establishment_Year\", data= train_data, kind = \"count\", aspect=4)\nplt.show()","32438cde":"sns.scatterplot(x = \"Item_Weight\" , y =\"Item_Outlet_Sales\" , data = train_data, alpha = 0.3, color = \"r\")\nplt.show()","cbe4a081":"sns.scatterplot(x = \"Item_Visibility\" , y =\"Item_Outlet_Sales\" , data = train_data, alpha = 0.3, color = \"y\")\nplt.show()","45bc837f":"sns.scatterplot(x = \"Item_MRP\" , y =\"Item_Outlet_Sales\" , data = train_data, alpha = 0.3, color = \"g\")\nplt.show()","479dbc62":"sns.catplot(x= \"Outlet_Size\", y = \"Item_Outlet_Sales\" ,data= train_data, kind = \"box\")\nplt.show()","2e37a647":"sns.catplot(x= \"Outlet_Establishment_Year\", y = \"Item_Outlet_Sales\" ,data= train_data, kind = \"box\", aspect=4)\nplt.show()","d417e815":"sns.catplot(x= \"Outlet_Type\", y = \"Item_Outlet_Sales\" ,data= train_data, kind = \"box\", aspect=3)\nplt.show()","69cb556c":"sns.catplot(x= \"Item_Fat_Content\", y = \"Item_Outlet_Sales\" ,data= train_data, kind = \"box\")\nplt.show","9567094f":"sns.catplot(x= \"Item_Type\", y = \"Item_Outlet_Sales\" ,data= train_data, kind = \"violin\", aspect=3)\nplt.show()","d1b8267f":"sns.catplot(x= \"Outlet_Type\", data= train_data, kind = \"count\", aspect = 2, hue=\"Outlet_Size\")\nplt.show()","f3a9f5a9":"sns.catplot(x= \"Outlet_Type\", data= train_data, kind = \"count\", aspect = 2, hue=\"Outlet_Location_Type\")\nplt.show()","44be984d":"data.isnull().sum()","f60cbea5":"item_mean_weight = data.pivot_table( index = \"Item_Identifier\" , values = \"Item_Weight\",aggfunc='mean')\n\nprint(\"Missing Item_Weight : \" , data['Item_Weight'].isnull().sum()  )\ndata.loc[data['Item_Weight'].isnull(), \"Item_Weight\"] =   data.loc[data['Item_Weight'].isnull(), \"Item_Identifier\"]. apply ( lambda x : item_mean_weight.loc[x])\nprint(\"Missing Item_Weight : \" , data['Item_Weight'].isnull().sum()  )","8bbff561":"from scipy.stats import mode\n\noutlet_mode= data.pivot_table( index = \"Outlet_Type\" , values = \"Outlet_Size\",aggfunc= lambda x : mode(x).mode[0]  )\n\nprint(\"Missing Outlet_Size : \" , data['Outlet_Size'].isnull().sum()  )\ndata.loc[data['Outlet_Size'].isnull(), \"Outlet_Size\"] =   data.loc[data['Outlet_Size'].isnull(), \"Outlet_Type\"]. apply ( lambda x : outlet_mode.loc[x])\nprint(\"Missing Outlet_Size : \" , data['Outlet_Size'].isnull().sum()  )","4000003c":"data.isnull().sum()","13b89af0":"item_mean_visibility = data.pivot_table( index = \"Item_Identifier\" , values = \"Item_Visibility\",aggfunc='mean')","a757193f":"print(\"Rows with '''0''' visbility \" , (data['Item_Visibility'] == 0).sum()  )\ndata.loc[data['Item_Visibility'] == 0, \"Item_Visibility\"] =   data.loc[data['Item_Visibility'] == 0, \"Item_Identifier\"]. apply ( lambda x : item_mean_visibility.loc[x])\nprint(\"Rows with '''0''' visbility \" , (data['Item_Visibility'] == 0).sum()  )","af97bd11":"data[\"Item_combined\"] = data [\"Item_Identifier\"].apply( lambda  x : x[0:2])\ndata[\"Item_combined\"]  = data[\"Item_combined\"]. map ( { \"FD\" : \"Food\", \"DR\" : \"Drink\",  \"NC\" : \"Non_Edible\"} )","270c3e95":"print(data[\"Item_Fat_Content\"].unique())\ndata[\"Item_Fat_Content\"].replace ( {\"low fat\": \"Low Fat\" , \"LF\": \"Low Fat\", \"reg\": \"Regular\"} , inplace = True)\nprint(data[\"Item_Fat_Content\"].unique())","5629df5e":"data.loc[data[\"Item_combined\"] == \"Non_Edible\" , \"Item_Fat_Content\" ] = \"Non_Edible\"\nprint(data[\"Item_Fat_Content\"].value_counts())","d61d98fb":"data.pivot_table(values= \"Item_Outlet_Sales\", index = \"Outlet_Type\",aggfunc='mean' )","6a6a7674":"data[\"year\"] = data[\"Outlet_Establishment_Year\"].apply( lambda x : 2013-x )\ndata[\"year\"]=data[\"year\"].astype(\"int8\")\ndata[\"year\"].describe()","43513cbf":"data[\"Outlet_Identifier\"].unique()","bab7d308":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder().fit(data[\"Outlet_Identifier\"])\ndata[\"Outlet\"]= le.transform(data[\"Outlet_Identifier\"])\ndata[\"Outlet\"] = data[\"Outlet\"].astype(\"category\")\ndata[\"Outlet\"].unique()","5e79bb66":"cor = data.corr()\nsns.heatmap(cor,cmap=\"bone\" )\nplt.show()","c4f95c2f":"sns.pairplot(data[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'year', 'Item_Outlet_Sales']] )\nplt.show()","78cdffd8":"data.dtypes","b3a99884":"data= pd.get_dummies (data = data , columns = ['Item_Fat_Content','Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'Item_combined',  'Outlet'] , drop_first = True)","c17fef5b":"data.dtypes","6351e98d":"data.head(5)","996e8a65":"data.drop ( [\"Item_Type\",\"Outlet_Establishment_Year\"] , inplace = True , axis = 1)","eec530e4":"train = data.loc [data[\"source\"] == \"train\"]\ntest = data.loc [data[\"source\"] == \"test\"]\n\n#Drop unnecessary columns:\ntest.drop(['Item_Outlet_Sales','source'],axis=1,inplace=True)\ntrain.drop(['source'],axis=1,inplace=True)\n\n#Export files as modified versions:\ntrain.to_csv(\"train_modified.csv\",index=False)\ntest.to_csv(\"test_modified.csv\",index=False)","c383288b":"import pandas as pd\nimport numpy as np\nimport warnings \nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv('train_modified.csv')\ntest= pd.read_csv('test_modified.csv')\n\nprint('\\nShape of training data :',train.shape)\nprint('\\nShape of testing data :',test.shape)","7d8f222e":"base_model = test[[\"Item_Identifier\", \"Outlet_Identifier\"]]\nbase_model[\"Item_Outlet_Sales\"] =  train[\"Item_Outlet_Sales\"].median()\nbase_model.to_csv(\"base_model.csv\",index=False)","94e27e43":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.linear_model import LinearRegression , Lasso ,Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_validate,cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n","f4a8bd65":"#Function \ndef models(algorithm,X_val,y_val,X_train,y_train ,file_name,X_test):\n    model = algorithm\n    model.fit(X_train,y_train)\n    \n    ytrain_pred = model.predict(X_train)\n    yval_pred = model.predict(X_val)\n    rmse_train = np.sqrt(mean_squared_error(y_train, ytrain_pred) )\n    rmse_val = np.sqrt(mean_squared_error(y_val, yval_pred) )\n    \n    scores_train = model.score(X_train,y_train)\n    scores_val = model.score(X_val,y_val)\n    \n    accuracy = cross_val_score(estimator=model, X=X_train, y=y_train,cv=10)\n#     print(f\"The accuracy of the Polynomial Regression Model is \\t {accuracy.mean()}\")\n#     print(f\"The deviation in the accuracy is \\t {accuracy.std()}\")\n\n\n    score.loc[file_name] = [ scores_train ,  scores_val,rmse_train, rmse_val,accuracy.mean(),accuracy.std()  ]\n    \n    #submission\n    submission = test[[\"Item_Identifier\", \"Outlet_Identifier\"]]\n    submission[\"Item_Outlet_Sales\"] =  model.predict(X_test)\n    file_name = file_name + \".csv\"\n    submission.to_csv(file_name,index=False)","d619b7fc":"\nscore = pd.DataFrame ( columns = [\"Train_Score\", \"Validate_Score\", \"Train_RMSE\",\"Validate_RMSE\", \"Accuuracy_Mean\", \"Accuracy_Std\"])\ny_train = train [\"Item_Outlet_Sales\"]\n\nX= train.drop([\"Item_Identifier\",\"Outlet_Identifier\",\"Item_Outlet_Sales\"] , axis = 1)\ny= train[\"Item_Outlet_Sales\"]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2,random_state = 0)\n\nX_test= test.drop([\"Item_Identifier\",\"Outlet_Identifier\"] , axis = 1)\n\nmodels (LinearRegression() , X_val,y_val, X_train,y_train ,\"LinearRegression\",X_test)\nmodels (Lasso() , X_val,y_val, X_train,y_train ,\"Lasso\",X_test)\nmodels (Ridge() , X_val,y_val, X_train,y_train ,\"Ridge\",X_test)\nmodels(DecisionTreeRegressor(max_depth=15, min_samples_leaf=100) ,  X_val,y_val, X_train,y_train ,\"DecisionTreeRegressor\",X_test)\nmodels(DecisionTreeRegressor(max_depth=8, min_samples_leaf=150) ,  X_val,y_val, X_train,y_train ,\"DecisionTreeRegressor2\",X_test)\nalg_RFR = RandomForestRegressor(n_estimators=200,max_depth=5, min_samples_leaf=100,n_jobs=4) \nmodels (alg_RFR , X_val,y_val, X_train,y_train ,\"RandomForestRegressor\",X_test)\nalg_RFR2 = RandomForestRegressor(n_estimators=400,max_depth=6, min_samples_leaf=100,n_jobs=4)\nmodels (alg_RFR2 , X_val,y_val, X_train,y_train ,\"RandomForestRegressor2\",X_test)\n\nscore","511b622c":"from sklearn import ensemble\n\nparams = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\nclf = ensemble.GradientBoostingRegressor(**params)\nmodels (clf , X_val,y_val, X_train,y_train ,\"GradientBoostingRegressor\",X_test)\n\n\nparams = {'n_estimators': 750, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.00999, 'loss': 'ls', 'criterion':'mse', 'random_state' : 1}\nclf = ensemble.GradientBoostingRegressor(**params )\nmodels (clf , X_val,y_val, X_train,y_train ,\"GradientBoostingRegressor2\",X_test)\nscore\n\n","cb3939c2":"from sklearn.linear_model import ElasticNetCV, ElasticNet\n\ncv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, .995, 1], eps=0.001, n_alphas=100, fit_intercept=True, \n                        normalize=True, precompute='auto', max_iter=2000, tol=0.0001, cv=5, \n                        copy_X=True, verbose=0, n_jobs=-1, positive=False, random_state=None, selection='cyclic')\ncv_model.fit(X_train, y_train)\n\ne_net = ElasticNet(l1_ratio=cv_model.l1_ratio_, alpha = cv_model.alpha_, max_iter=cv_model.n_iter_, fit_intercept=True, normalize = True)\n\nmodels (e_net , X_val,y_val, X_train,y_train ,\"ElasticNet\",X_test)\nscore","a17a03ee":"##### b) Target Variable vs Categorical Variables","97459067":"##### a )Item_Visibility\n    There are some records with \"0\" Visibility. Item_visibilty contributes Sales\n    So we can consider them as missing value and treat them\n    Lets replace them with the mean visibility of that particular item","6ab9d00b":"Observetions:\n- Deviation from the normal distribution.\n- There is  positive skewness.\n- Shows peakedness.","2b4c6a5e":"##### e) Outlet_Establishment_Year\n    Given data is for 2013, so we can calculate the no of years","235e17f6":"###### f) Outlet_Identifier\n\n    Identifier columns cannot be deleted since , we need them for submission","ab9af6c5":"#### b) Numeric variables","d61c3d6c":"   - All the categorical columns needs to be converted. \n   - In \"Item_Fat_Content\" column, ( Low Fat    : LF : low fat  ) , (Regular:reg) needs to be changed\n   - We can combine some cat. in \"Item_Type\" columns\n   - In \"Outlet_Type\" column, Supermarket Type2 and Type3 can be combined. But we should check if that\u2019s a good idea before doing it.","f2abadb3":"#### 4.2 Bivariant Analysis","825bcf55":"#### 4.1 Univariant Analysis","5cbf40a7":"     Here there is a drastic difference , so we should  not combine them","cb91e79e":"### 4. Treating Missing Values","40f53228":"###### a) Item_Weight\n        Lets replace them with the mean weight of that particular item","51b4ac0f":"##### c) Item_Fat_Content\n    In \"Item_Fat_Content\" column, ( Low Fat    : LF : low fat  ) , (Regular:reg) needs to be changed\n    But we have foods that are not edible (\"Item_combined\"). So we need to take that into consideration and change that value","a080351e":"###### c ) Categorical vs Categorical","6baafb58":"#### 10.1 Base Model\nSince we are working on a regression problem, we can use a central tendency measure as the result for all predictions, such as the mean or the median.\n","65e3d794":"### 8. Droping Columns","f1ff6974":"### 10 . Model Building\n","56034a19":"### 7. One Hot Coding:","873807df":"##### a) Target Variable vs Numerical Variables","66080782":"### 5. Feature Engineering","04b64ca8":"### 3. Data Exploration","4846c9b7":"###### Observations:\n    Item_Weight does not have any clear pattern. \n    Item_Visibility is right-skewed and should be transformed.\n    There are  4 different distributions for Item_MRP","68b65cb1":"#### c) Categorical variables","877240fc":"### 1. Import the data and library","ef210540":"### 2. Create column & Combining the data set","a72493cc":"### 4 Data Visualization","1b3b8cca":"###### b) Outlet_Size                  \n        Lets's replace them with the most frequent outlet size of that particular Outlet Type","9c8ecec3":"#### a)Target Column","4fb55938":"##### d) Outlet_Type\n    Supermarket Type2 and Type3 can be combined. But we should check if that\u2019s a good idea before doing it.\n    One way of checking is , by using \"mean\"(Sales.\n    If the Mean Sale of both are same, then we can combine them. But if they are different we cannot do it.","d7c04762":"#### Observations:\n    In \"Item_Fat_Content\" column Low Fat, LF , low fat  means the same. Regular, reg means the same\n    In \"Outlet_Type\" Supermarket_Typee is the most popular Type.\n    \"Outlet_Establishment_Year\" - 1998 has less data\n    ","c36413b2":"###### Observations:\n    Item_Outlet_Sales is spread well across the entire range of the Item_Weight. \n    In Item_Visibility vs Item_Outlet_Sales, there is a string of points at Item_Visibility = 0.0.But Item visibility cannot be completely zero.\n    In Item_MRP vs Item_Outlet_Sales, we can  see 4 segments of prices. We can use this to create a new variable.","3fce7f74":"### 9. Splitting the data","0a1ad475":"#### 10.2 Models","0a92109b":"##### b ) Item_Identifier\n\n    Here all the values start with \"FD\", \"DR\",\"NC\" followed by alphanumeric\n        - FD : Food\n        - DR : Drink\n        - NC : Non- Edible\n    We can create a new column","ed64e5cf":"Correlation"}}