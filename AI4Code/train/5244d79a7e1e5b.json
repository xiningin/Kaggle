{"cell_type":{"e3a840d2":"code","f3d87c0e":"code","8a135855":"code","a2a2b11b":"code","970f091b":"code","b4d0ee22":"code","673d25f9":"code","6c53cf94":"code","12d4aba2":"code","6518edf3":"code","1dc77468":"code","83903494":"code","08b7bf3a":"code","b5910c6c":"code","15cb66c1":"code","82d917b8":"code","b189e2f9":"code","ae348f69":"code","2690376f":"markdown","05110943":"markdown","fb303362":"markdown","e333d478":"markdown","34a9f28a":"markdown","b56ad932":"markdown"},"source":{"e3a840d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f3d87c0e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport gc\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.model_selection import GroupKFold, GridSearchCV\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# I don't like SettingWithCopyWarnings ...\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")","8a135855":"# Display\/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances.png')\n    \ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","a2a2b11b":"def load_data():\n    train = pd.read_csv('..\/input\/train.csv', low_memory=True)\n    test = pd.read_csv('..\/input\/test.csv', low_memory=True)\n    return train,test\ntrain, test = load_data()\nprint(\"Train Shape:\", train.shape)\nprint(\"Test Shape:\",test.shape)\ngc.enable()","970f091b":"train.head()","b4d0ee22":"train['target'].value_counts().plot(kind=\"barh\", figsize=(20,8))\nfor i, v in enumerate(train['target'].value_counts()):\n    plt.text(v, i, str(v), fontweight='bold', fontsize = 20)\nplt.xlabel(\"Count\", fontsize=12)\nplt.ylabel(\"State of the target\", fontsize=12)\nplt.title(\"Target repartition\", fontsize=15)\nplt.legend()\nplt.show()\n\ny = train.pop('target')","673d25f9":"train.pop('ID_code')\ntest.pop('ID_code')\ntr_col = train.columns","6c53cf94":"# train_df,y = SMOTE().fit_resample(train,y.ravel())","12d4aba2":"# train_df = pd.DataFrame(train_df)\n# train_df.columns = tr_col\n# train_df.head()","6518edf3":"# y = pd.Series(y)","1dc77468":"train_df = train.copy(deep=True)\nprint(\"Train Shape:\", train_df.shape)\nprint(\"Target Shape:\", y.shape)\ngc.collect()","83903494":"# y.value_counts().plot(kind=\"barh\", figsize=(20,8))\n# for i, v in enumerate(y.value_counts()):\n#     plt.text(v, i, str(v), fontweight='bold', fontsize = 20)\n# plt.xlabel(\"Count\", fontsize=12)\n# plt.ylabel(\"State of the target\", fontsize=12)\n# plt.title(\"Target repartition\", fontsize=15)\n# plt.legend()\n# plt.show()","08b7bf3a":"test_df = test.copy(deep=True)\nprint(\"Train Shape:\", train_df.shape)\nprint(\"Target Shape:\", y.shape)\nprint(\"Test Shape:\", test_df.shape)","b5910c6c":"train_df = StandardScaler().fit_transform(train_df)\ntest_df = StandardScaler().fit_transform(test_df)\ntrain_df.shape,test_df.shape","15cb66c1":"train_df = pd.DataFrame(train_df)\ntrain_df.columns = tr_col","82d917b8":"boosting = [\"goss\",\"dart\"]\ndef kfold_lightgbm(train_df, test_df, num_folds, stratified = False, boosting = boosting[0]):\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=326)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=2045)\n\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    \n    # k-fold\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, y)):\n        train_x, train_y = train_df.iloc[train_idx], y.iloc[train_idx]\n        valid_x, valid_y = train_df.iloc[valid_idx], y.iloc[valid_idx]\n\n        # set data structure\n        lgb_train = lgb.Dataset(train_x,label=train_y,free_raw_data=False)\n        lgb_test = lgb.Dataset(valid_x,label=valid_y,free_raw_data=False)\n\n        # params optimized by optuna\n        params ={\n                        'task': 'train',\n                        'boosting': 'goss',\n                        'objective': 'binary',\n                        'metric': 'auc',\n                        'learning_rate': 0.01,\n                        'subsample': 0.8,\n                        'max_depth': -1,\n                        'top_rate': 0.9064148448434349,\n                        'num_leaves': 32,\n                        'min_child_weight': 41.9612869171337,\n                        'other_rate': 0.0721768246018207,\n                        'reg_alpha': 9.677537745007898,\n                        'colsample_bytree': 0.5665320670155495,\n                        'min_split_gain': 9.820197773625843,\n                        'reg_lambda': 8.2532317400459,\n                        'min_data_in_leaf': 21,\n                        'verbose': -1,\n                        'seed':int(2**n_fold),\n                        'bagging_seed':int(2**n_fold),\n                        'drop_seed':int(2**n_fold)\n                        }\n\n        reg = lgb.train(\n                        params,\n                        lgb_train,\n                        valid_sets=[lgb_train, lgb_test],\n                        valid_names=['train', 'test'],\n                        num_boost_round=7000,early_stopping_rounds= 200,\n                        verbose_eval=100,\n                        )\n\n        oof_preds[valid_idx] = reg.predict(valid_x, num_iteration=reg.best_iteration)\n        sub_preds += reg.predict(test_df, num_iteration=reg.best_iteration) \/ folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = train_x.columns\n        fold_importance_df[\"importance\"] = np.log1p(reg.feature_importance(importance_type='gain', iteration=reg.best_iteration))\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d roc_auc_score : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del reg, train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    # display importances\n    display_importances(feature_importance_df)\n    \n        # save submission file\n    submission = pd.read_csv(\"..\/input\/sample_submission.csv\")\n    submission['target'] = sub_preds\n    submission.to_csv(boosting+\".csv\", index=False)\n    display(submission.head())\n    return (submission)","b189e2f9":"submission = kfold_lightgbm(train_df, test_df, num_folds=5, stratified=True, boosting=boosting[0])   ","ae348f69":"submission1 = kfold_lightgbm(train_df, test_df, num_folds=5, stratified=True, boosting=boosting[1])   ","2690376f":"## **5. Final Shape for Training**","05110943":"### **3.Target Variable Distribution**","fb303362":"### **2. Load Data**","e333d478":"### ***We can see that imbalance Class Problem***\n\n| State | Count |\n|--|--|\n|**0**|**179902**|\n|**1**|**20098**|\n\n## ***4.Solve Imbalance Class problem using SMOTE ANALYSIS***","34a9f28a":"## **6.Model Training LightGBM**","b56ad932":"![](https:\/\/www.worldfinance.com\/wp-content\/uploads\/2015\/07\/US-Fed-Santander-crackdown.jpg)\n### **1. Load Libraries**"}}