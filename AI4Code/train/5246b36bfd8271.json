{"cell_type":{"ec86799c":"code","ca20a82b":"code","5c842d7c":"code","ea59f182":"code","8e0cf1f1":"code","de694c27":"code","ac78a42d":"code","9f1a3d06":"code","a8b7eb90":"code","1d671343":"code","c1a7c0ac":"code","79e05ac6":"code","8f5b262e":"code","17f028f0":"code","8d9126ba":"code","5032655c":"code","bf4af6e6":"code","e8b3a125":"code","4ec7f465":"code","8f1b3995":"code","adee6dc5":"code","8aaff492":"code","b80182af":"code","9567071f":"code","77ed60d8":"code","8a943049":"code","235fb1e3":"code","bbdfedfe":"code","68c2eb5d":"code","05c1ccae":"code","a4a3dce5":"markdown"},"source":{"ec86799c":"%matplotlib inline","ca20a82b":"import matplotlib.pyplot as plt\nimport cv2","5c842d7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, decode_predictions, preprocess_input\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\nimport tensorflow as tf\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ea59f182":"modelv2 = InceptionResNetV2( input_shape = (224, 224, 3), weights = \"..\/input\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\")","8e0cf1f1":"images_gray = np.load('..\/input\/l\/gray_scale.npy')\nimages_lab = np.load('..\/input\/ab\/ab\/ab1.npy')","de694c27":"def get_rbg_from_lab(gray_imgs, ab_imgs, n = 10):\n    imgs = np.zeros((n, 224, 224, 3))\n    imgs[:, :, :, 0] = gray_imgs[0:n:]\n    imgs[:, :, :, 1:] = ab_imgs[0:n:]\n    \n    imgs = imgs.astype(\"uint8\")\n    \n    imgs_ = []\n    for i in range(0, n):\n        imgs_.append(cv2.cvtColor(imgs[i], cv2.COLOR_LAB2RGB))\n\n    imgs_ = np.array(imgs_)\n\n    print(imgs_.shape)\n    \n    return imgs_\n    ","ac78a42d":"new_model = Model(inputs = modelv2.inputs, outputs = modelv2.output)\n","9f1a3d06":"for i, layer in enumerate(new_model.layers):\n    layer.trainable = False","a8b7eb90":"x = Reshape((5, 5, 40))(new_model.output)\n\nx = Conv2DTranspose(strides = 2, kernel_size = 5, filters = 40, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu)(x)\nx = Conv2DTranspose(strides = 3, kernel_size = 7, filters = 40, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"same\", activation = tf.nn.relu)(x)\nx = Conv2DTranspose(strides = 3, kernel_size = 9, filters = 20, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"same\", activation = tf.nn.relu)(x)\nx = Conv2DTranspose(strides = 4, kernel_size = 11, filters = 20, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"same\", activation = tf.nn.relu)(x)\n\nx = Conv2D(strides = 2, kernel_size = 5, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu)(x)\nx = Conv2D(strides = 1, kernel_size = 9, filters = 3, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu)(x)\n\n\nfinal_model = Model(inputs = new_model.inputs, outputs = x)","1d671343":"#final_model.predict(get_rbg_from_lab(images_gray, images_lab, n = 2)).shape","c1a7c0ac":"final_model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False), loss = tf.losses.mean_pairwise_squared_error)","79e05ac6":"def pipe_line_img(gray_scale_imgs, batch_size = 100, preprocess_f = preprocess_input):\n    imgs = np.zeros((batch_size, 224, 224, 3))\n    for i in range(0, 3):\n        imgs[:batch_size, :, :,i] = gray_scale_imgs[:batch_size]\n    return preprocess_f(imgs)","8f5b262e":"tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='.\/folder_to_save_graph_3', histogram_freq=0, write_graph=True, write_images=True)","17f028f0":"imgs_for_input = pipe_line_img(images_gray, batch_size = 300)","8d9126ba":"imgs_for_output = preprocess_input(get_rbg_from_lab(gray_imgs = images_gray, ab_imgs = images_lab, n = 300))","5032655c":"plt.imshow(imgs_for_output[1])","bf4af6e6":"final_model.fit(imgs_for_input, imgs_for_output, epochs = 5, batch_size = 30, callbacks = [tbCallBack])","e8b3a125":"final_model.fit(imgs_for_input, imgs_for_output, epochs = 5, batch_size = 1, callbacks = [tbCallBack])","4ec7f465":"prediction2 = final_model.predict(x = pipe_line_img(gray_scale_imgs = images_gray, batch_size = 3))","8f1b3995":"final_model.summary()","adee6dc5":"prediction2[0]","8aaff492":"final_model.weights[-3]","b80182af":"# At first in settings, Make sure that Internet option is set to \"Internet Connected\"\n# After executing this cell, there will come a link below, open that to view your tensor-board\n\n!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '.\/folder_to_save_graph_3' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 6006 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","9567071f":"model_simple = Sequential()\nmodel_simple.add(Conv2D(strides = 1, kernel_size = 3, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))\nmodel_simple.add(Conv2D(strides = 1, kernel_size = 3, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))\nmodel_simple.add(Conv2DTranspose(strides = 1, kernel_size = 3, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))\nmodel_simple.add(Conv2DTranspose(strides = 1, kernel_size = 3, filters = 3, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))","77ed60d8":"model_simple.compile(optimizer = tf.keras.optimizers.Adam(epsilon = 1e-8), loss = tf.losses.mean_pairwise_squared_error)\n","8a943049":"imgs_for_s = np.zeros((300, 224, 224, 1))\nimgs_for_s[:, :, :, 0] = images_gray[:300] ","235fb1e3":"prediction = model_simple.predict(imgs_for_input)","bbdfedfe":"prediction.shape","68c2eb5d":"model_simple.fit(imgs_for_input, imgs_for_output, epochs = 15)","05c1ccae":"model_simple.fit(imgs_for_input, imgs_for_output, epochs = 1100, batch_size = 16)","a4a3dce5":"# I give up :)\n"}}