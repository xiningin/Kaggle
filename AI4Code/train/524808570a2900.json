{"cell_type":{"85250e53":"code","fb92c17f":"code","26391556":"code","bf765073":"code","b1be8169":"code","cff9558c":"code","758e7bce":"code","a142ae70":"code","0f68547e":"code","53c6f457":"code","dd3b144b":"code","90304b22":"code","2510bf4d":"code","c7e1cab7":"code","697f5118":"code","b50eb5c0":"code","ba62b75a":"code","d8225b21":"code","04e33016":"code","c30cf6f9":"code","1e13fe6d":"code","87ec9622":"code","a195c212":"code","c12e858c":"code","09fff906":"markdown","42d4a8c8":"markdown","be1edcec":"markdown","4f5e96fa":"markdown","ddc33c37":"markdown","63f679bf":"markdown","6c4cfdff":"markdown","4a4962b1":"markdown"},"source":{"85250e53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OneHotEncoder, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb92c17f":"data =pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv', parse_dates=['Date'])\ndata.head()","26391556":"# data \ud615\ud0dc \ud655\uc778\ndata.shape","bf765073":"data.info()","b1be8169":"data.isna().sum() ","cff9558c":"data.describe()","758e7bce":"total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum() \/ data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.T","a142ae70":"dropList = list(missing_data[missing_data['Percent'] > 0.15].index)\ndata.drop(dropList, axis=1, inplace=True)","0f68547e":"# data columns\ub9c8\ub2e4 \uc870\uc0ac\ud558\uc5ec dtype\uc774 object\uc778 \uceec\ub7fc\uba85\uc744 \ucd94\ucd9c\nobjectColumns = [name for name in data.columns if data[name].dtype == object]\n\n# 'RainToday', 'RainTomorrow'\ub294 0 or 1\ub85c \uad6c\uc131\ub418\ubbc0\ub85c BinaryCloumns\uc73c\ub85c \ub530\ub85c \ubd84\ub958\nBinaryCloumns = objectColumns[-2:]\nobjectColumns = objectColumns[:-2]\nprint(objectColumns, BinaryCloumns)","53c6f457":"# Nan\uc744 \uc81c\uc678\ud55c LabelEncoding\uc744 \uc9c4\ud589\ud558\uace0 dtype \ubcc0\ud658, \uac01 columns\uc758 Label \uc800\uc7a5\nfor col in objectColumns:\n    Label = LabelEncoder()\n    notnull = data[data[col].notnull()]\n    isna = data[data[col].isna()]\n    notnull[col] = Label.fit_transform(notnull[col])\n    globals()['{}_col'.format(col)] = Label.classes_\n    data = pd.concat([isna, notnull])\n    data[col] = data[col].astype(float)\n\n# Nan\uc744 \uc81c\uc678\ud55c Binary Encoding\uc744 \uc9c4\ud589\ud558\uace0 dtype \ubcc0\ud658, \uac01 columns\uc758 Label \uc800\uc7a5\nfor col in BinaryCloumns:\n    Binary = LabelBinarizer()\n    notnull = data[data[col].notnull()]\n    isna = data[data[col].isna()]\n    notnull[col] = Binary.fit_transform(notnull[col])\n    globals()['{}_col'.format(col)] = Label.classes_\n    data = pd.concat([isna, notnull])\n    data[col] = data[col].astype(float)\n\n\n# \uc798 \ub418\uc5c8\ub294\uc9c0 \ud655\uc778\n\ndata.info()","dd3b144b":"# datetime\uc21c\uc73c\ub85c DataFrame \uc815\ub82c\ndata.sort_values(by=['Date'], inplace=True)","90304b22":"# heatmap\uc744 \ud1b5\ud574 \uac01 columns \uac04 corr\uc744 \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.\n# \ubb50\ub77c\ub3c4 \uac74\uc9c8 \uc904 \uc54c\uc558\ub294\ub370 \uac74\uc9c4\uac8c \uc5c6\uc2b5\ub2c8\ub2e4.\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(data.corr(), annot=True, fmt='.2f')","2510bf4d":"print('\ube44\uc624\ub294 \ub0a0 \ucd5c\uc18c \uac15\uc218\ub7c9 : {}mm \\n\ud654\ucc3d\ud55c \ub0a0 \ucd5c\ub300 \uac15\uc218\ub7c9 : {}mm'.format(data[data.RainToday.values == 1.0].Rainfall.min(), data[data.RainToday.values == 0.0].Rainfall.max()))","c7e1cab7":"data.loc[(data.Rainfall.values > 1.0) & (data.Rainfall.isna()), 'RainToday'] = 1.0\ndata.loc[(data.Rainfall.values <= 1.0) & (data.Rainfall.isna()), 'RainToday'] = 0.0\ndata.RainToday.dropna(inplace=True)","697f5118":"data.fillna(0, inplace=True)","b50eb5c0":"data_x = data.drop('RainToday', axis=1)\ndata_y = data[['RainToday']]\ndata_x.shape","ba62b75a":"minmax = MinMaxScaler()\nminmaxCol = data_x.iloc[:, 1:]\nminmaxCol = pd.DataFrame(minmax.fit_transform(minmaxCol), columns=minmaxCol.columns, index=list(minmaxCol.index.values))\ndata_x = pd.concat([data_x[['Date']], minmaxCol], axis=1)","d8225b21":"data_x['Year'] = data_x['Date'].dt.year\ndata_x['Month'] = data_x['Date'].dt.month\ndata_x['Day'] = data_x['Date'].dt.day\ndata_x.drop(['Date'], axis=1, inplace=True)","04e33016":"data_x.reset_index(drop=True, inplace=True)","c30cf6f9":"data_x","1e13fe6d":"x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3, random_state=0)","87ec9622":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n\nregression = LogisticRegression(solver='liblinear', n_jobs=-1, random_state=0)\n\nregression.fit(x_train, y_train)","a195c212":"y_pred = regression.predict(x_test)\ny_pred","c12e858c":"print('accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","09fff906":"imputer = SimpleImputer(strategy='median')\nimputeCol = data_x.iloc[:, 1:]\nimputeCol = pd.DataFrame(imputer.fit_transform(imputeCol), columns=imputeCol.columns, index=list(imputeCol.index.values))\ndata_x = pd.concat([data_x[['Date']], imputeCol], axis=1)","42d4a8c8":"* \uac01 column\uc744 \ud655\uc778\ud558\uc5ec dtype\uacfc null\uac12 \ud655\uc778","be1edcec":"*   \uc704 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c Rainfall\uc758 \uac12\uc5d0 \ub530\ub77c RainToday\uc744 \uc9d1\uc5b4 \ub123\uc5b4\uc90d\ub2c8\ub2e4.\n*   \ub610\ud55c, Rainfall\uacfc RainToday\uc758 Nan\uc758 \uac12\uc774 \ub3d9\uc77c \ud55c \uac83\uc73c\ub85c \ubcf4\uc544 RainToday\uc758 \uac12\uc774 Nan\uc778 row\ub97c drop\ud574\uc90d\ub2c8\ub2e4.","4f5e96fa":"* \ub370\uc774\ud130 \ubd84\uc11d\uc744 \uc2dc\uc791\ud558\uae30 \uc804\uc5d0 train_set\uacfc test_set\uc744 \ub098\ub204\uc5b4 \uc90d\ub2c8\ub2e4.\n* BATCH_SIZE\uc640 EPOCHS, wieght\ub97c \uc800\uc7a5\ud560 filename\uc744 \uba3c\uc800 \uc120\uc5c5\ud574\uc90d\ub2c8\ub2e4!","ddc33c37":"# Rainfall\uacfc RainToday\uc758 \uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc544 \ud655\uc778\uc744 \ud574\ubd05\ub2c8\ub2e4.\n\n\n*   \ube44\uc624\ub294 \ub0a0\uacfc \uc624\uc9c0 \uc54a\ub294 \ub0a0\uc758 \uac15\uc218\ub7c9\uc774 1.0\uc744 \uae30\uc900\uc73c\ub85c \ub098\ub258\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.","63f679bf":"# **1. \uacb0\uce21\ub960\uc774 15%\uc774\uc0c1\uc778 data filtering**\n\n*   missing_data\ub97c \ud1b5\ud574 \uacb0\uce21\uce58\ub97c \ud655\uc778\n\n*   \ud1b5\uc0c1\uc801\uc73c\ub85c \uacb0\uce21\ub960\uc774 15%\uc774\uc0c1\uc774\uba74 \ud2b9\uc131\uc744 \uc81c\uc678\ud558\uace0 \ubd84\uc11d\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801","6c4cfdff":"# **2. Location One-Hot Encoding**\n\n**dtype\uc774 object\uc778 \uceec\ub7fd\uc5d0 \ub300\ud574 \uba3c\uc800 \uc870\uc0ac\ud55c \uc774\ud6c4**\n*   categorical columns\uc5d0 \ub300\ud574\uc11c\ub294 LabelEncoding\n*   Binary columns\uc5d0 \ub300\ud574\uc11c\ub294 LabelBinarizing","4a4962b1":"* RainToday\ub97c target\uc73c\ub85c \ud558\uae30 \uc704\ud574 DataFrame\uc744 \ubd84\ub9ac\ud558\ub294 \uc791\uc5c5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n* data_x\uc758 shape\uc744 \ud655\uc778\ud558\uc5ec input columns\ub97c \ud655\uc778\ud569\ub2c8\ub2e4."}}