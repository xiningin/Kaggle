{"cell_type":{"0dd60a94":"code","5856449a":"code","a23c889c":"code","01761841":"code","b03a564c":"code","997c7dc2":"code","8a464872":"code","6ce3123e":"code","4e06fab2":"code","e073a5b7":"markdown","fc364277":"markdown","719feb56":"markdown","cb13289c":"markdown","1a32d16f":"markdown"},"source":{"0dd60a94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5856449a":"import os\nimport numpy as np\nimport scipy.io\nimport keras\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nimport cv2\nfrom sklearn.model_selection import train_test_split","a23c889c":"img_labels = scipy.io.loadmat(\"\/kaggle\/input\/flower-dataset-102\/imagelabels.mat\")\nimg_labels = img_labels[\"labels\"]\nimg_labels = img_labels[0]\nfor i in range(len(img_labels)):\n  img_labels[i] = img_labels[i] - 1\nprint(img_labels)","01761841":"import tarfile\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nIMG_SIZE = 50\n\ntrain_x = []\ntrain_y = []\ntar = tarfile.open('\/kaggle\/input\/flower-dataset-102\/102flowers.tgz', \"r:gz\")\ni = 0\nfor tarinfo in tqdm(tar):\n    i+=1\n    tar.extract(tarinfo.name)\n    \n    if(tarinfo.name[-4:] == '.jpg'):\n        var = tarinfo.name[11:15]\n        img_num = int(var)-1\n        train_y.append(img_labels[img_num])\n        \n        image = cv2.imread(tarinfo.name)\n        resized = cv2.resize(image, (IMG_SIZE,IMG_SIZE))\n        normalized_img = cv2.normalize(resized, None, alpha=0, beta=1, \n                                norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n        train_x.append(normalized_img)\n\n#         label_list.append(tarinfo.name.split('_')[0])\n    if(tarinfo.isdir()):\n        os.rmdir(tarinfo.name)\n    else:\n        os.remove(tarinfo.name) \n\ntar.close()\ntrain_x = np.array(train_x)","b03a564c":"plt.imshow(train_x[1002])\nprint(train_y[1002])\nprint(train_x.shape)","997c7dc2":"trainx, testx, trainy, testy = train_test_split(train_x, train_y, test_size=0.10, random_state=10)\n\ntrainx, valx, trainy, valy = train_test_split(trainx, trainy, test_size=0.15, random_state=10)\n\ntrainy = to_categorical(trainy)\ntesty = to_categorical(testy)\nvaly = to_categorical(valy)\nnp.save('testx.npy', testx)\nnp.save('testy.npy', testy)\n\nprint(\"Training data number:\",len(trainx))\nprint(\"Testing data number:\",len(testx))\nprint(\"Validation data number:\",len(valx))\n\nprint(\"Training labels number:\",len(trainy))\nprint(\"Testing labels number:\",len(testy))\nprint(\"Validation labels number:\",len(valy))","8a464872":"print(\"Training data shape:\",trainx.shape)\nprint(\"Testing data shape:\",testx.shape)\nprint(\"Validation data shape:\",valx.shape)\n\nprint(\"Training labels shape:\",trainy.shape)\nprint(\"Testing labels shape:\",testy.shape)\nprint(\"Validation labels shape:\",valy.shape)","6ce3123e":"\"\"\"## Creating Model\"\"\"\n\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n\nmodel = Sequential()\n\n#add model layers\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,3)))\nmodel.add(Conv2D(128, kernel_size=3, activation='relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(102, activation='softmax'))\n\n\n# model = Sequential()\n# #Layer 1\n# model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(150, 150, 3)))\n# model.add(MaxPooling2D((2,2)))\n# model.add(Dropout(0.5))\n# #Layer 2\n# model.add(Conv2D(128, kernel_size=3, activation='relu'))\n# model.add(MaxPooling2D((2,2)))\n# model.add(Dropout(0.5))\n# #Layer 3\n# model.add(Conv2D(128, kernel_size=3, activation='relu'))\n# model.add(MaxPooling2D((2,2)))\n# model.add(Dropout(0.5))\n# #Layer 4\n# model.add(Conv2D(256, kernel_size=3, activation='relu'))\n# model.add(MaxPooling2D((2,2)))\n# #Input to Neural Network is flattened\n# model.add(Flatten())\n# #1st hidden layer with 512 neurons\/nodes\n# model.add(Dense(512, activation='relu'))\n# model.add(Dropout(0.5))\n# #Output layer with 102 nodes for classifying 102 flowers\n# model.add(Dense(102, activation='softmax'))\n\n\"\"\"## Compiling and Training the Neural Network\"\"\"\n\n#Compile the neural network\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n#Train the network\nmodel.fit(trainx, trainy, validation_data = (valx, valy), epochs=60, batch_size=20)\nmodel.save('model.h5')","4e06fab2":"from keras.models import load_model\nmodel = load_model(\"model.h5\")\n\nscore = model.evaluate(testx, testy)\n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])\n\n#Predict output on sample input data\npred = model.predict(testx) \npred = np.argmax(pred, axis = 1)[:10] \nlabel = np.argmax(testy,axis = 1)[:10] \n\nprint(\"Predicted labels:\",pred) \nprint(\"Actual Labels:   \",label)","e073a5b7":"## Building the model","fc364277":"## Processing Images","719feb56":"## Here I am making total data, train_data and test_data.","cb13289c":"# Please refer to version 8 of this notebook. ","1a32d16f":"## Processing Labels"}}