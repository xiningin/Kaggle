{"cell_type":{"ec7459f0":"code","4c06cab0":"code","98dbdcff":"code","19fd17c8":"code","457cd87b":"code","fff3c8ba":"code","50848399":"code","e3fec0f9":"code","470b8b78":"code","433d7505":"code","e90971df":"code","1774eccc":"code","fb4b0363":"code","dce424a3":"code","8db0692f":"code","e2c77283":"code","f6d7edd0":"code","e4f01e8c":"code","422e1492":"code","97fcec1a":"code","43eb370c":"code","6e770348":"code","b6968b19":"code","6075ba52":"code","13a93e16":"code","d4bfd425":"code","6d9c6bd2":"code","63428412":"markdown","bc614a71":"markdown","85f2ec71":"markdown","f7215100":"markdown","dbdd2710":"markdown","803ac478":"markdown","4da0b49f":"markdown","335db365":"markdown","008f2782":"markdown","11970468":"markdown","fd2147f1":"markdown","1043e77a":"markdown","11a3b401":"markdown","0b60b5fd":"markdown","59ff68b5":"markdown"},"source":{"ec7459f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c06cab0":"import warnings\nwarnings.filterwarnings('ignore')","98dbdcff":"#Load the data into dataframe\ncolumn_names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndf = pd.read_csv('\/kaggle\/input\/boston-house-prices\/housing.csv',names=column_names, header=None, delim_whitespace=True)\ndf.head()","19fd17c8":"df.info()","457cd87b":"df.shape","fff3c8ba":"X = df.drop('MEDV',axis=1)\ny = df['MEDV']\nX.shape, y.shape","50848399":"df['CRIM'].plot.hist(bins=20);\n","e3fec0f9":"df['ZN'].plot.hist();","470b8b78":"df['AGE'].plot.hist();","433d7505":"df['MEDV'].plot.hist();","e90971df":"df['MEDV'].mean()","1774eccc":"df['RAD'].unique()\n","fb4b0363":"df['CHAS'].unique()","dce424a3":"df = pd.get_dummies(df, columns=['CHAS'],drop_first=True)","8db0692f":"df.head()","e2c77283":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","f6d7edd0":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1)","e4f01e8c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import make_column_transformer\n\nct = make_column_transformer(\n    (StandardScaler(), ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']),\n    remainder='passthrough'\n    )\n\nct.fit(X_train)\n\n\n","422e1492":"ct.transform(X_train)\nct.transform(X_test)\nct.transform(X_valid);","97fcec1a":"import tensorflow as tf","43eb370c":"model_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(10,activation='relu'),\n    tf.keras.layers.Dense(10,activation='relu'),\n    tf.keras.layers.Dense(1, activation='linear')\n])\n\n","6e770348":"model_1.compile(loss = tf.keras.losses.mean_absolute_error,\n               optimizer = tf.keras.optimizers.Adam(lr=0.01),\n               metrics=['mae'])","b6968b19":"history_1 = model_1.fit(X_train, y_train, epochs=100, validation_data=(X_valid,y_valid))","6075ba52":"import matplotlib.pyplot as plt\nplt.rcdefaults()\n\n\n\nplt.rcParams.update({'axes.facecolor':'teal'})\n\n\n\n\n\n\npd.DataFrame(history_1.history).plot(figsize=(6,5))\nplt.xlabel(\"Epochs\")\nplt.title('Loss curves')\nplt.legend();\n","13a93e16":"model_1.evaluate(X_test,y_test)","d4bfd425":"y_pred = model_1.predict(X_test)\n\n","6d9c6bd2":"plt.figure()\nplt.scatter(range(len(y_test)),y_test,color='red',label='Actual Values')\nplt.scatter(range(len(y_pred)),y_pred,color='blue',label='Predicted Values')\nplt.title('Actual vs Predicted')\nplt.legend();","63428412":"Divide the train dataset further into train and validation datasets","bc614a71":"Now our data is ready, lets start building our Neural network using TensorFlow!","85f2ec71":"Explore the distribution of some of the columns","f7215100":"We will scale the numerical coulmns using sklearn's StandardScaler","dbdd2710":"The Boston Housing Dataset\n\nCRIM - per capita crime rate by town<br>\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.<br>\nINDUS - proportion of non-retail business acres per town.<br>\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)<br>\nNOX - nitric oxides concentration (parts per 10 million)<br>\nRM - average number of rooms per dwelling<br>\nAGE - proportion of owner-occupied units built prior to 1940<br>\nDIS - weighted distances to five Boston employment centres<br>\nRAD - index of accessibility to radial highways<br>\nTAX - full-value property-tax rate per $10,000<br>\nPTRATIO - pupil-teacher ratio by town<br>\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town<br>\nLSTAT - % lower status of the population<br>\n\nMEDV - Median value of owner-occupied homes in $1000's<br>\n\n**Based on the given house criteria, the target value will be \"MEDV\"**.","803ac478":"Majority of the properties are about 90 to 100 yrs old","4da0b49f":"Lets separate the Data into features X and target y","335db365":"We have 506 rows and 14 columns","008f2782":"Divide the data into train and test","11970468":"We can see that our NN model has quite well captured the overall distribution of the test data points","fd2147f1":"Lets do one-hot encoding for the 'CHAS' column","1043e77a":"The mean value for 'MEDV' column is 22.5. The mean absolute error that we are getting with our Neural Network model is about 3. ","11a3b401":"I am going to build a 3-layer Sequential model, with activations = 'relu' for the hidden layers and ","0b60b5fd":"## Data Exploration","59ff68b5":"Lets plot the predicted values against test values"}}