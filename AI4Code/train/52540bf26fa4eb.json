{"cell_type":{"be42a6ab":"code","0c1ea809":"code","60f8dc37":"code","79f7ec98":"code","31dd8537":"code","fdece84e":"code","af8453b6":"code","0179df6e":"code","fd3e1b04":"code","49d65859":"code","8363170b":"code","7a9379f9":"markdown","60a7aa17":"markdown","8738d31b":"markdown","4c9eb244":"markdown","af757997":"markdown","d7a4a70d":"markdown","ba8d0c9e":"markdown","836b3b5f":"markdown","8b080dcc":"markdown","924ffe2f":"markdown","89a7ca21":"markdown","a8253f09":"markdown","82f16ceb":"markdown"},"source":{"be42a6ab":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom itertools import combinations\nfrom collections import Counter\nimport warnings\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport wordcloud\n\nwarnings.filterwarnings(\"ignore\")\nsns.set_style('darkgrid')\nsns.color_palette(\"rocket\")\n%matplotlib inline\n\npd.set_option('display.width', 2000)\npd.set_option('display.float_format', '{:20,.2f}'.format)\npd.set_option('display.max_colwidth', None)","0c1ea809":"df = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\n\nquestions = df.loc[:0]\n\nmultiple_options_questions = set()\nmultiple_options_questions_A_B = set()\n\nfor q in list(questions.filter(regex=(\"Q\\d+_Part_\\d+\")).columns):\n    multiple_options_questions.add(int(q.split(\"_\")[0][1:]))\nfor q in list(questions.filter(regex=(\"Q\\d+_A_Part_\\d+\")).columns):\n    multiple_options_questions_A_B.add(int(q.split(\"_\")[0][1:]))\n\ndef extract_question(row):\n    row = list(row)\n    return row[0].split(\"-\")[0].strip()\n\nfor i in list(multiple_options_questions):\n    questions[f\"Q{i}\"] = questions.filter(regex=(f\"Q{i}_Part_\\d+\")).apply(lambda row: extract_question(row.values.astype(str)), axis=1)\n    \nfor i in list(multiple_options_questions_A_B):\n    questions[f\"Q{i}_A\"] = questions.filter(regex=(f\"Q{i}_A_Part_\\d+\")).apply(lambda row: extract_question(row.values.astype(str)), axis=1)\n    questions[f\"Q{i}_B\"] = questions.filter(regex=(f\"Q{i}_B_Part_\\d+\")).apply(lambda row: extract_question(row.values.astype(str)), axis=1)\n\nquestions.drop(columns=questions.filter(regex=(\"Q\\d+_Part_\\d+\")).columns, inplace=True)\nquestions.drop(columns=questions.filter(regex=(\"Q\\d+_A_Part_\\d+\")).columns, inplace=True)\nquestions.drop(columns=questions.filter(regex=(\"Q\\d+_B_Part_\\d+\")).columns, inplace=True)\nquestions.drop(columns=questions.filter(regex=(\"Q\\d+_A_OTHER\")).columns, inplace=True)\nquestions.drop(columns=questions.filter(regex=(\"Q\\d+_B_OTHER\")).columns, inplace=True)\nquestions.drop(columns=questions.filter(regex=(\"Q\\d+_OTHER\")).columns, inplace=True)\n\nquestions= questions.transpose().iloc[1:]\nquestions.columns = ['Question']\nquestions.sort_index(inplace=True)\n\ndf = df[1:]\ndf.reset_index(inplace=True)\n\n### Marking all the missing values as `Not Specified`\n\ndf.replace(to_replace=np.nan, value=\"Not Specified\", inplace=True)\n\n### Grouping responses for questions with more than one selected options\n\ndef group(row):\n    row = list(row)\n    result = list()\n    for val in row:\n        if val == \"Not Specified\":\n            pass\n        else:\n            result.append(val.strip())\n    return \";\".join(result)\n\nresponses = pd.DataFrame()\nfor i in range(1, 40):\n    if i in list(multiple_options_questions):\n        responses[f\"Q{i}\"] = df.filter(regex=(f\"Q{i}_Part_\\d+\")).apply(lambda row: group(row.values.astype(str)), axis=1)\n    elif i in list(multiple_options_questions_A_B):\n        responses[f\"Q{i}_A\"] = df.filter(regex=(f\"Q{i}_A_Part_\\d+\")).apply(lambda row: group(row.values.astype(str)), axis=1)\n        responses[f\"Q{i}_B\"] = df.filter(regex=(f\"Q{i}_B_Part_\\d+\")).apply(lambda row: group(row.values.astype(str)), axis=1)\n    else:\n        responses[f\"Q{i}\"] = df[f\"Q{i}\"]\n\n### Splitting the respondents into two categories: `Professional` and `Non Professional`\n\nnon_prof_index = responses[(responses['Q5']=='Student') | \n                           (responses['Q5']=='Currently not employed') | \n                           (responses['Q5']=='Other') |  \n                           (responses['Q5']=='Not Specified') |\n                           (responses['Q25']=='$0 ($USD)')].index\n\ntype_of_job_role =  list()\nfor index, row in responses.iterrows():\n    if index in list(non_prof_index):\n        type_of_job_role.append(\"Non Professional\")\n    else:\n        type_of_job_role.append(\"Professional\")\nresponses['type of Job Role'] = type_of_job_role\n\nnon_professional = responses[responses['type of Job Role']==\"Non Professional\"]\nprofessional = responses[responses['type of Job Role']==\"Professional\"]\n\n# Part B of the questions are supplement questions rephrased for non professional respondents\n\nnon_professional.drop(columns=non_professional.filter(regex=(\"Q\\d+_A\")).columns, inplace=True)\nprofessional.drop(columns=professional.filter(regex=(\"Q\\d+_B\")).columns, inplace=True)\n\nquestions.to_csv('.\/questions.csv')\nresponses.to_csv('.\/responses.csv', index=False)\nprofessional.to_csv('.\/professional.csv', index=False)\nnon_professional.to_csv('.\/non_professional.csv', index=False)","60f8dc37":"professionals = pd.read_csv('professional.csv')\nquestions = pd.read_csv('questions.csv')\n\nquestions.columns = [\"Question Number\", \"Question\"]\nquestions.set_index(keys=\"Question Number\", inplace=True)\n\ned_ind = professionals[\n    (professionals['Q4']==\"Master\u2019s degree\") |\n    (professionals['Q4']==\"Bachelor\u2019s degree\") |\n    (professionals['Q4']==\"Doctoral degree\")\n].index\nprofessionals = professionals.iloc[list(ed_ind)]\nprofessionals.reset_index(inplace=True)\nprofessionals.drop(columns=['index'], inplace=True)\n\nind = professionals[\n    (professionals['Q5']==\"Data Scientist\") |\n    (professionals['Q5']==\"Data Analyst\") |\n    (professionals['Q5']==\"Business Analyst\")\n].index\n\ndata_professionals = professionals.iloc[list(ind)]\ndata_professionals.reset_index(inplace=True)\ndata_professionals.drop(columns=['index'], inplace=True)\ndata_professionals['count'] = 1\n\ndf = data_professionals.groupby(\"Q5\")\ndata_scientists = df.get_group(\"Data Scientist\")\ndata_analysts = df.get_group(\"Data Analyst\")\nbusiness_analysts = df.get_group(\"Business Analyst\")","79f7ec98":"titles = [\"Data Scientist\", \"Data Analyst\", \"Business Analyst\"]\ndf_grouped = data_professionals[data_professionals[\"Q3\"]==\"United States of America\"].groupby(\"Q5\")\njob_role_dic = dict()\ntop3 = pd.DataFrame(columns=titles)\nfor title in titles:\n    df = df_grouped.get_group(title)\n    count = Counter()\n    for row in df['Q23']:\n        try:\n            row_list = row.split(\";\")\n        except:\n            pass\n        count.update(Counter(combinations(row_list, 1)))\n    dic = dict()    \n    for key,value in count.most_common(10):\n        dic[key[0]] = value\n        \n    top3[title] = list(dic.keys())[:3]\n    \nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(top3.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[top3[\"Data Scientist\"], top3[\"Data Analyst\"], top3[\"Business Analyst\"]],\n               fill_color='lavender',\n               align='left'))\n])\nfig.update_layout(\n    title={'text': \"Primary roles performed by Data Professionals\",\n           'x':0.5,\n          }\n)\nfig.update_layout(height=500, \n                  width=750,)\nfig.show()","31dd8537":"fig = px.parallel_categories(data_professionals[['Q5', 'Q4']], \n                       template=\"seaborn\", \n                       labels={\"Q5\":\"Job Title\", \"Q4\":\"Highest Degree\"}, \n                       title=\"Job Title vs. Highest Degree\"\n                      )\nfig.update_layout(height=500, \n                  width=750,)\nfig.show()","fdece84e":"coding_sorted_list = ['Not Specified', \n               'I have never written code', \n               '< 1 years', \n               '1-2 years', \n               '3-5 years', \n               '5-10 years', \n               '10-20 years', \n               '20+ years']\n\npivot_coding = pd.pivot_table(data=data_professionals, \n                       values='count', \n                       index=\"Q5\", \n                       columns=\"Q6\", \n                       aggfunc=np.sum).loc[titles][coding_sorted_list]\n\ndf_grouped = data_professionals.groupby(\"Q5\")\ncoding_exp_dic = dict()\nfor title in titles:\n    df = df_grouped.get_group(title)\n    df_title = pivot_coding.loc[pivot_coding.index==title].apply(lambda x: x*100\/df.shape[0])\n    coding_exp_dic[title]=df_title\npivot_coding_frac= pd.concat(coding_exp_dic.values())\n\nfig, axes = plt.subplots(3, 1, sharex=True, figsize=(15, 5))\nfig.suptitle(\"Coding Experience Distribution\")\nsns.heatmap(ax=axes[0], data = coding_exp_dic[\"Data Scientist\"], cmap=\"viridis\", annot=coding_exp_dic[\"Data Scientist\"])\nsns.heatmap(ax=axes[1], data = coding_exp_dic[\"Data Analyst\"], cmap=\"viridis\", annot=coding_exp_dic[\"Data Analyst\"])\nsns.heatmap(ax=axes[2], data = coding_exp_dic[\"Business Analyst\"], cmap=\"viridis\", annot=coding_exp_dic[\"Business Analyst\"])\nplt.show()","af8453b6":"ml_sorted_list = ['Not Specified', \n               'I do not use machine learning methods', \n               'Under 1 year', \n               '1-2 years',\n               '2-3 years',\n               '3-4 years',\n               '4-5 years',\n               '5-10 years', \n               '10-20 years', \n               '20 or more years']\n\npivot_ml = pd.pivot_table(data=data_professionals, \n                       values='count', \n                       index=\"Q5\", \n                       columns=\"Q15\", \n                       aggfunc=np.sum).loc[titles][ml_sorted_list]\n\ntitles = [\"Data Scientist\", \"Data Analyst\", \"Business Analyst\"]\ndf_grouped = data_professionals.groupby(\"Q5\")\ndf_dic_ml = dict()\nfor title in titles:\n    df = df_grouped.get_group(title)\n    df_title = pivot_ml.loc[pivot_ml.index==title].apply(lambda x: x*100\/df.shape[0])\n    df_dic_ml[title]=df_title\npivot_ml_frac= pd.concat(df_dic_ml.values())\n\nfig, axes = plt.subplots(3, 1, sharex=True, figsize=(15, 5))\nfig.suptitle(\"Machine Learning Experinece\")\nsns.heatmap(ax=axes[0], data = df_dic_ml[\"Data Scientist\"], cmap=\"viridis\", annot=df_dic_ml[\"Data Scientist\"])\nsns.heatmap(ax=axes[1], data = df_dic_ml[\"Data Analyst\"], cmap=\"viridis\", annot=df_dic_ml[\"Data Analyst\"])\nsns.heatmap(ax=axes[2], data = df_dic_ml[\"Business Analyst\"], cmap=\"viridis\", annot=df_dic_ml[\"Business Analyst\"])\nplt.show()","0179df6e":"salary_ind = data_professionals[data_professionals['Q24']==\"Not Specified\"].index\nsalary_df = data_professionals.copy()\nsalary_df.drop(index=salary_ind, inplace=True)\n\nsalary = salary_df['Q24'].apply(lambda x: x.replace('$', '').replace(',', '').replace('> ', ''))\n\ndef avg_sal(sal_range):\n    try:\n        min_sal = int(sal_range.split(\"-\")[0])\n        max_sal = int(sal_range.split(\"-\")[1])\n        return (max_sal+min_sal)\/2\n    except:\n        return int(sal_range.split(\"-\")[0])\nsalary_df['Salary Estimate'] = salary.apply(avg_sal)\n\nsalary_india_usa = salary_df.loc[salary_df[(salary_df[\"Q3\"]==\"India\") | (salary_df[\"Q3\"]==\"United States of America\")].index]","fd3e1b04":"fig = px.box(salary_india_usa, x=\"Q5\", \n             y=\"Salary Estimate\", \n             color=\"Q3\", \n             template=\"seaborn\",\n             labels={\"Q3\":\"Country\"},\n             title=\"Country-wise Salary Estimates for Data Professionals\"\n            )\nfig.update_layout(legend=dict(orientation=\"h\",\n                             yanchor=\"bottom\",\n                             y=1.02,\n                             xanchor=\"right\",\n                             x=1))\n\nfig.update_layout(height=500, \n                  width=750,)\nfig.show()\n\n\n","49d65859":"fig = px.box(salary_df, \n             x=\"Q4\", \n             y=\"Salary Estimate\", \n             color=\"Q5\", \n             template=\"seaborn\",\n             labels={\"Q5\":\"Job Title\", \"Q4\":\"Highest level of Education\"},\n             title=\"Estimated Annual Salaries According to the Highest Level of Education\"\n            )\nfig.update_layout(legend=dict(orientation=\"h\",\n                             yanchor=\"bottom\",\n                             y=1.02,\n                             xanchor=\"right\",\n                             x=1))\nfig.update_layout(height=500, \n                  width=750,)\nfig.show()\n\nfig1 = px.box(salary_india_usa, \n              x=\"Q4\", \n              y=\"Salary Estimate\", \n              color=\"Q5\", \n              template=\"seaborn\", \n              facet_col=\"Q3\",\n             labels={\"Q5\":\"Job Title\", \"Q4\":\"Highest level of Education\"},)\nfig1.update_layout(showlegend=False)\nfig1.update_layout(height=500, \n                  width=750,)\nfig1.show()","8363170b":"tool_df = data_professionals.drop(index=list(data_professionals[(data_professionals['Q38']==\"Not Specified\") | \n                                                                (data_professionals['Q38']==\"Other\")].index))\n\ntool_df = tool_df[tool_df[\"Q3\"]==\"United States of America\"]\ntool_df[\"Q38\"] = tool_df[\"Q38\"].apply(lambda x: x.split(\"(\")[0].strip())\n\nfig = px.parallel_categories(tool_df[[ 'Q5', 'Q38']], \n                             template=\"seaborn\",\n                             labels={\"Q5\":\"Job Title\", \"Q38\":\"Primary tool used for Data Analyis\"},\n                             title=\"Primary tools used for Data Analysis\"\n                            )\nfig.update_layout(autosize=True)\nfig.update_layout(height=500, \n                  width=750,)\nfig.show()","7a9379f9":"# Data Cleaning and Transformation\nAfter cleaning, transforming and splitting the provided data(`kaggle_survey_2020_responses.csv`), we get 4 seperate DataFrames, namely:\n1. *questions*: Questions asked in the survey\n2. *responses*: Responses entered by the respondents\n3. *professionals*: Responses by professional respondents\n4. *non professionals*: Responses by non-professional respondents\n\n> According to the [Survey Methodology](..\/input\/kaggle-survey-2020\/supplementary_data\/kaggle_survey_2020_methodology.pdf) provided with the Data, a respondent can be categorised as `Non Professional` if the respondent is either a \n- *student* or \n- *unemployed* or\n- *has never spent money on cloud services* \n","60a7aa17":"# Data\n<p style=\"font-size:13pt\">\nThe data used for this analysis focuses on the professionals working as:\n<ul style=\"font-size:13pt\">    \n<li>Data Scientists \n<li>Data Analysts \n<li>Business Analysts \n<\/ul>\n<\/p>","8738d31b":"<center><H1>Data Scientist vs. Data Analysts vs. Business Analysts<H1><\/center>\n<hr>","4c9eb244":"![story%20wc.png](attachment:story%20wc.png)","af757997":"<p style=\"font-size:13pt\">\n    It is a general rule of thumb, the more advanced your degrees are, the higher are the chances of getting a better salary package.<\/p>","d7a4a70d":"# Coding Experience\n\n<blockquote style=\"font-size:14pt\">\u201cA data scientist is someone who is better at statistics than any software engineer and better at software engineering than any statistician.\u201d<\/blockquote>\n<p style=\"font-size:13pt\"> A Data Scientist is expected to have strong computer science and programming skills as a major part of the job involves around machine learning and deploying the models to make them useable in production.\n    <br> Analysts need not to be as skilled programmers as scientists but knowledge of a statistical language like R or Python helps along the way.<br><br>\n    Here we can see that <strong>more than 50%<\/strong> of the Data Scientists have coding experience of between <strong>3 to 10 years<\/strong>.<br> The top 50% of the Data Analysts only have 1 to 5 years of coding expereince.<br> This plunges down even more (to 0 to 2 years) for Business Analysts.\n    <\/p>","ba8d0c9e":"# Primary Tool for Data Analysis\n\n<p style=\"font-size:13pt\">\n    Data Scientists and Analysts are expected to have strong programming foundations. A typical response of programmer for any problem is to whip up some code.<br> Same is applicable here, Data Scientists and Data Analysts prefer using ther <strong>local development environment<\/strong> such as R Studio or Jupyter notebooks.<br>\n    A Business Analyst on the other hand, uses basic statistical softwares such as Microsoft Excel and Business Intelligence tools such as Power BI or Tableau.\n    <\/p>\n    ","836b3b5f":"# Job Role\n<p style=\"font-size:13pt\">In all data related jobs there\u2019s a certain amount of skills overlap.<br><br>\nData Analysts perform a variety of tasks around collecting, organizing, and interpreting statistical information. Their mainly responsible for using data to identify efficiencies, problem areas, and possible improvements.<br><br>\nThe actual role of the Data Scientist is one of the most debated \u2014 probably because the role varies considerably from company to company. A Data Scientist is a person who utilizes Machine Learning algorithms to create a model from data that ultimately helps to make a business more efficient. But a Data Scientist is also expected to take on the mantle of an Analyst as well.<br><br>\nThe line between Business Analysts and Data Analysts has become so blurred that they\u2019re essentially the same thing. Both use their reports and analyses to help management make decisions and set goals. \n<\/p>\n\n![1_x9UhkTVsLIMkrCKblaMIug.png](attachment:1_x9UhkTVsLIMkrCKblaMIug.png)","8b080dcc":"# ML Experience\n\n<p style=\"font-size:13pt\">Data Professionals are a generalist in a variety of different areas, but have deep domain experience in one particular area. For a Data Scientist, that deep experience is probably in Statistics and Machine Learning. Thus Data Scientists have the most experience with Machine Learning.\n<\/p>","924ffe2f":"<p style=\"font-size:13pt\">\nIf you have an analytical mindset and love decoding data to tell a story, you may want to consider a career as a data analyst or data scientist. After all, data analysts and data scientists are two of the hottest jobs in tech (and pay pretty well, too). Harvard Business Review even awarded \u201cdata scientist\u201d the title of \u201csexiest job of the 21st century.\u201d <br><br>Data science and analytics (DSA) jobs are in high demand. According to Forbes, \u201c\u2026by 2020, the number of data science and analytics job listings is projected to grow by nearly 364,000 listings to approximately 2,720,000.\u201d They aren\u2019t the easiest positions to fill, either. Forbes goes on to say that DSA jobs \u201cremain open an average of 45 days, five days longer than the market average.\u201d<br><br> \nBut what is the difference between data analytics vs. data science, and how do the two job roles differ?<\/p>","89a7ca21":"<p style=\"font-size:13pt\">\n    Here below we have the top three tasks or roles respondents have mentioned that they perform in their jobs as <em>Data Professionals<\/em>\n<\/p>","a8253f09":"# How Much Do They Earn?\n\n<p style=\"font-size:13pt\">\n    According to Glassdoor, the average annual salary for a data scientist is \\$162,000 and for a data analyst it is $84,000.<br>\n    Along with technical and analytical skills, the candidate is expected to have great soft skills too.\n    Finding someone who has the ideal blend of right-brain and left-brain skills is not an easy task, which is one reason why data professionals are paid well.<br><br>\n    According to the survey data,<br>\n    The median salary for a Data Scientist in US is \\$137,499 per annum. Whereas in India, the median salary for a Data Scientist is just \\$12,499 per annum.<br>\n    In the US, median salaries for Data Analysts and Business Analysts are \\$85k and \\$95k respectively.<br><br>\n    In India, professionals are highly uderpaid and are expected to have the same skill sets and do the same tasks as their American counterparts.<\/p>","82f16ceb":"# Education\n\n<p style=\"font-size:13pt\">\n    While it may not be the case everywhere, but to bag a Data Scientist job, a master's degree is the minimum requirement at every reputed company.<br>\n    Most of the Data Scientists have a Master's degree. It can also be noted that <strong>almost 90%<\/strong> of the PhD or Doctoral degree holders are Data Scientists.<br>\n    This maybe due to the level of expertise expected from a Data Scientist to effectively achieve the goals of the organisation.<br>\n    \n<\/p>    "}}