{"cell_type":{"578d988a":"code","7ce497f0":"code","ef527187":"code","9dce4027":"code","5448b375":"code","8681e87e":"code","3c1044f1":"code","230e4651":"code","628b569d":"code","46a36547":"code","87b43e12":"code","90c3bc8a":"code","7c16fbef":"code","c9ddf08e":"code","94677591":"code","7e70e2e3":"code","629977bd":"code","94471704":"code","7a50e503":"code","8477ac1a":"code","5affe4d9":"code","e18f0b6c":"code","c3c1cce9":"code","5511ff98":"code","de670990":"code","3bdcfb11":"code","d4537ebb":"code","4bd2f1f9":"code","a153496f":"code","16ac352f":"markdown","58d55721":"markdown","ce711503":"markdown","dfe90249":"markdown","55402b39":"markdown","9ae2a0c7":"markdown","89888f63":"markdown","c51601db":"markdown"},"source":{"578d988a":"import glob, pylab, pandas as pd\nimport pydicom, numpy as np\nfrom os import listdir\nfrom os.path import isfile, join\nimport matplotlib.pylab as plt\n\nimport seaborn as sns\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom fastai.vision import *","7ce497f0":"DATA = Path(\"..\/input\/rsna-intracranial-hemorrhage-detection\")","ef527187":"df = pd.read_csv('..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train.csv')","9dce4027":"newtable = df.copy()","5448b375":"new = newtable[\"ID\"].str.split(\"_\", n = 1, expand = True)\nnewX = new[1].str.split(\"_\", n = 1, expand = True)\nnewX[1]\nnewtable['Image_ID'] = newX[0]\nnewtable['Sub_type'] = newX[1]","8681e87e":"image_ids = newtable.Image_ID.unique()\nlabels = [\"\" for _ in range(len(image_ids))]\nnew_df = pd.DataFrame(np.array([image_ids, labels]).transpose(), columns=[\"id\", \"labels\"])","3c1044f1":"lbls = {i : \"\" for i in image_ids}","230e4651":"newtable = newtable[newtable.Label == 1]\nnewtable = newtable[newtable.Sub_type != \"any\"]\n\ni = 0\nfor name, group in newtable.groupby(\"Image_ID\"):\n    lbls[name] = \" \".join(group.Sub_type)\n    if i % 10000 == 0: print(i)\n    i += 1","628b569d":"new_df = pd.DataFrame(np.array([list(lbls.keys()), list(lbls.values())]).transpose(), columns=[\"id\", \"labels\"])","46a36547":"del lbls\ndel newtable\ndel newX\ndel new\ngc.collect()","87b43e12":"#https:\/\/www.kaggle.com\/omission\/eda-view-dicom-images-with-correct-windowing\n\ndef window_image(img, window_center,window_width, intercept, slope):\n\n    img = (img*slope +intercept)\n    img_min = window_center - window_width\/\/2\n    img_max = window_center + window_width\/\/2\n    img[img<img_min] = img_min\n    img[img>img_max] = img_max\n    return img\n\ndef get_first_of_dicom_field_as_int(x):\n    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n    if type(x) == pydicom.multival.MultiValue:\n        return int(x[0])\n    else:\n        return int(x)\n\ndef get_windowing(data):\n    dicom_fields = [data[('0028','1050')].value, #window center\n                    data[('0028','1051')].value, #window width\n                    data[('0028','1052')].value, #intercept\n                    data[('0028','1053')].value] #slope\n    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]","90c3bc8a":"new_df.id = \"ID_\" + new_df.id + \".dcm\"","7c16fbef":"def new_open_image(path, div=True, convert_mode=None, after_open=None):\n    dcm = pydicom.dcmread(str(path))\n    window_center, window_width, intercept, slope = get_windowing(dcm)\n    im = window_image(dcm.pixel_array, window_center, window_width, intercept, slope)\n    im = np.stack((im,)*3, axis=-1)\n    im -= im.min()\n    im_max = im.max()\n    if im_max != 0: im = im \/ im.max()\n    x = Image(pil2tensor(im, dtype=np.float32))\n    #if div: x.div_(2048)  # ??\n    return x\n\n\nvision.data.open_image = new_open_image","c9ddf08e":"df_train = pd.concat([new_df[new_df.labels == \"\"][:15000], new_df[new_df.labels != \"\"][:15000]])","94677591":"bs = 128\n\nim_list = ImageList.from_df(df_train, path=DATA\/\"stage_1_train_images\")\ntest_fnames = pd.DataFrame(\"ID_\" + pd.read_csv(DATA\/\"stage_1_sample_submission.csv\")[\"ID\"].str.split(\"_\", n=2, expand = True)[1].unique() + \".dcm\")\ntest_im_list = ImageList.from_df(test_fnames, path=DATA\/\"stage_1_test_images\")\n\ntfms = get_transforms(do_flip=False)\n\ndata = (im_list.split_by_rand_pct(0.2)\n               .label_from_df(label_delim=\" \")\n               .transform(tfms, size=512)\n               .add_test(test_im_list)\n               .databunch(bs=bs, num_workers=0)\n               .normalize())","7e70e2e3":"data.show_batch(3)","629977bd":"learn = cnn_learner(data, models.resnet18)\n\nmodels_path = Path(\"\/kaggle\/working\/models\")\nif not models_path.exists(): models_path.mkdir()\n    \nlearn.model_dir = models_path\nlearn.metrics = [accuracy_thresh]","94471704":"learn.lr_find()\nlearn.recorder.plot()","7a50e503":"learn.fit_one_cycle(4, 5e-2)","8477ac1a":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()","5affe4d9":"learn.fit_one_cycle(12, slice(1e-3))","e18f0b6c":"submission = pd.read_csv(DATA\/\"stage_1_sample_submission.csv\")","c3c1cce9":"preds = learn.get_preds(ds_type=DatasetType.Test)","5511ff98":"preds = np.array(preds[0])","de670990":"any_probs = 1 - np.prod(1 - preds, axis=1)","3bdcfb11":"any_probs.shape","d4537ebb":"submission.Label = np.hstack([preds, np.expand_dims(any_probs, -1)]).reshape(-1)","4bd2f1f9":"submission.head()","a153496f":"submission.to_csv(\"submission.csv\", index=False)","16ac352f":"## Submission\n\nThe predicted probability for **any** hemorrhage being present is calculated as $1 - ((1 - \\text{P}(\\text{type 1})) \\times (1 - \\text{P}(\\text{type 2})) \\dots) $","58d55721":"Good luck everyone!","ce711503":"We will train on a subset of the data so that it doesn't take too long: 15000 examples containing one or more hemorrhage types, 15000 examples containing no hemorrhages","dfe90249":"## Imports","55402b39":"# fastai starter\n\nMany thanks to [Basic EDA + Data Visualization \ud83e\udde0 ](https:\/\/www.kaggle.com\/marcovasquez\/basic-eda-data-visualization) for the code to load the data.","9ae2a0c7":"## Train the model\n\nA resnet18 with imagenet weights.","89888f63":"## Load and preprocess data\n\nWe will transform the data into a nice space separated label format.","c51601db":"# fastai Dataset\n\nThanks to this kernel for the code to apply the windowing: [EDA: View dicom images with correct windowing](https:\/\/www.kaggle.com\/omission\/eda-view-dicom-images-with-correct-windowing)"}}