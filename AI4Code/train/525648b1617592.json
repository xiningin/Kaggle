{"cell_type":{"bfa6eec1":"code","15e70c3f":"code","08239f91":"code","cddfad5c":"code","6565ba56":"code","ceaac632":"markdown","058bcf7b":"markdown"},"source":{"bfa6eec1":"import gresearch_crypto\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport pickle\n\nimport time\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport lightgbm as lgb\n\nseed = 2021\n\nDEBUG = False","15e70c3f":"# https:\/\/stackoverflow.com\/questions\/38641691\/weighted-correlation-coefficient-with-pandas\ndef wmean(x, w):\n    return np.sum(x * w) \/ np.sum(w)\n\ndef wcov(x, y, w):\n    return np.sum(w * (x - wmean(x, w)) * (y - wmean(y, w))) \/ np.sum(w)\n\ndef wcorr(x, y, w):\n    return wcov(x, y, w) \/ np.sqrt(wcov(x, x, w) * wcov(y, y, w))\n\ndef eval_wcorr(preds, train_data):\n    w = train_data.add_w.values.flatten()\n    y_true = train_data.get_label()\n    return 'eval_wcorr', wcorr(preds, y_true, w), True","08239f91":"n_fold = 5\n\nimportances = []\n\nfor fold in range(n_fold):\n    print('Fold: '+str(fold))\n\n    train = pd.read_parquet('..\/input\/crypto-forecasting-static-feature-engineering\/train_fold_'+str(fold)+'.parquet')\n    test = pd.read_parquet('..\/input\/crypto-forecasting-static-feature-engineering\/test_fold_'+str(fold)+'.parquet')\n    \n    if DEBUG:\n        timestamp_sample_train = train.timestamp.unique()[:np.int(len(train.timestamp.unique())*0.05)]\n        timestamp_sample_test = test.timestamp.unique()[:np.int(len(test.timestamp.unique())*0.05)]\n        train = train[train.timestamp.isin(timestamp_sample_train)]\n        test = test[test.timestamp.isin(timestamp_sample_test)]\n\n    y_train = train['Target']\n    y_test = test['Target']\n\n    features = [col for col in train.columns if col not in {'timestamp', 'Target', 'Target_M','weights'}]\n\n    weights_train = train[['weights']]\n    weights_test = test[['weights']]\n\n    train = train[features]\n    test = test[features]\n    \n    train_dataset = lgb.Dataset(train, y_train, feature_name = features, categorical_feature= ['Asset_ID'])\n    val_dataset = lgb.Dataset(test, y_test, feature_name = features, categorical_feature= ['Asset_ID'])\n\n    train_dataset.add_w = weights_train\n    val_dataset.add_w = weights_test\n\n    val_data = test\n    val_y = y_test\n\n    del train\n    \n    evals_result = {}\n    \n    # parameters\n    params = {'n_estimators': 2000,\n            'objective': 'regression',\n            'metric': 'None',\n            'boosting_type': 'gbdt',\n            'max_depth': -1,\n            'learning_rate': 0.05,\n            'subsample': 0.72,\n            'subsample_freq': 4,\n            'feature_fraction': 0.4,\n            'lambda_l1': 1,\n            'lambda_l2': 1,\n            'seed': 46,\n            'verbose': -1,\n            }\n\n    model = lgb.train(params = params,\n                      train_set = train_dataset, \n                      valid_sets = [val_dataset],\n                      #early_stopping_rounds=1000,\n                      verbose_eval = 100,\n                      feval=eval_wcorr,\n                      evals_result = evals_result \n                     )\n    \n    importances.append(model.feature_importance(importance_type='gain'))\n    \n    plt.plot(np.array(evals_result['valid_0']['eval_wcorr']), label='fold '+str(fold))\n    \nplt.legend(loc=\"upper left\")\nplt.show()","cddfad5c":"def plot_importance(importances, features_names = features, PLOT_TOP_N = 20, figsize=(10, 10)):\n    importance_df = pd.DataFrame(data=importances, columns=features)\n    sorted_indices = importance_df.median(axis=0).sort_values(ascending=False).index\n    sorted_importance_df = importance_df.loc[:, sorted_indices]\n    plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n    _, ax = plt.subplots(figsize=figsize)\n    ax.grid()\n    ax.set_xscale('log')\n    ax.set_ylabel('Feature')\n    ax.set_xlabel('Importance')\n    sns.boxplot(data=sorted_importance_df[plot_cols],\n                orient='h',\n                ax=ax)\n    plt.show()","6565ba56":"plot_importance(np.array(importances),features, PLOT_TOP_N = 20, figsize=(10, 20))","ceaac632":"# Crypto Forecasting - Basic LGBM\n\nBasic lgbm, using standard Feature Engineering from here: ","058bcf7b":"from nyanp's Optiver solution."}}