{"cell_type":{"e675d337":"code","10abf431":"code","3d0c20eb":"code","2e39e081":"code","3c91d25a":"code","9104fda3":"code","809c5cf3":"code","071cd007":"code","6a03f4d7":"code","d96cf923":"code","30f9ff70":"code","a6beafd3":"code","45bddf2b":"code","34020dc2":"code","82065b5c":"code","6a89e5a4":"code","e1e34e11":"code","6b3b605e":"code","f5d912dc":"code","83b86e71":"code","48b17f3d":"code","362419bc":"code","ab74c626":"code","3593ddc6":"code","379f5a00":"code","70017559":"code","0a029aa2":"code","1cd83b51":"code","09e19555":"code","0d5f7c28":"code","9e5930ef":"code","5585c968":"code","f2bcbcc3":"code","f4550992":"code","46c3a2dc":"code","35d32eb6":"code","5acda068":"code","25da7596":"code","b6ea5ed2":"code","73f8e77d":"markdown","fbfe0150":"markdown","a3a6954e":"markdown","c34c93e0":"markdown","cf2aa827":"markdown","141347bb":"markdown","f3292977":"markdown","d915623e":"markdown","407fee69":"markdown","5fe5d623":"markdown","1c04a6b9":"markdown","dff7f200":"markdown","bb598243":"markdown","5d14587c":"markdown","2973a1cf":"markdown"},"source":{"e675d337":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom shutil import rmtree, copy\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans, SpectralClustering","10abf431":"# OS variables\nseed = np.random.randint(0, 115)\n\n# Data path\npath = '..\/input\/cassava-leaf-disease-classification\/'","3d0c20eb":"data = pd.read_csv(path + 'train.csv')\ndata['img_path'] = path + 'train_images\/' + data.image_id\n\nlabel_dict_ = {\n    '0': 'Cassava Bacterial Blight (CBB)',\n    '1': 'Cassava Brown Streak Disease (CBSD)',\n    '2': 'Cassava Green Mottle (CGM)',\n    '3': 'Cassava Mosaic Disease (CMD)',\n    '4': 'Healthy'\n}\n\ndata['class_label'] = [label_dict_[str(x)] for x in data['label']]\n\nle = LabelEncoder()\ndata['class_'] = le.fit_transform(data['class_label'])","2e39e081":"IMAGE_SIZE = 224\nBATCH_SIZE = 8\nMODEL_IMAGE_SIZE = 512\nEPOCHS = 20","3c91d25a":"data = data[~data['image_id'].isin(['1562043567.jpg', '3551135685.jpg', '2252529694.jpg'])]","9104fda3":"feature_base_model = tf.keras.applications.ResNet50(include_top = False, weights = 'imagenet', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\nfeature_model_pooling = tf.keras.layers.GlobalAveragePooling2D()(feature_base_model.output)\n\nfeature_model = tf.keras.models.Model(inputs = feature_base_model.input, outputs = feature_model_pooling)\n#feature_model.summary()","809c5cf3":"im_paths = data['img_path']\nclas = data['class_']\n#x_images = np.array([np.float32(Image.open(im_path).resize((IMAGE_SIZE, IMAGE_SIZE))) \/ 255.0 for im_path in im_paths])\n#Y = np.array([class_ for class_ in clas]) ","071cd007":"len(data['img_path'])","6a03f4d7":"y_pred = []\nfor i, im_path in enumerate(im_paths):\n    #print(\"Doing \" + str(i+1) )\n    x_images = np.array([np.float32(Image.open(im_path).resize((IMAGE_SIZE, IMAGE_SIZE))) \/ 255.0])\n    a = feature_model.predict(x_images)\n    #print(a[0])\n    #print(a[0].shape)\n    y_pred.append(a[0])\n","d96cf923":"y_pred = np.array(y_pred)\nprint('y: {}'.format(y_pred.shape))","30f9ff70":"\"\"\"max_clusters = 5\n\nplt.figure(figsize=(10, 5))\nplt.style.use('ggplot')\n\nskip = 1\nfor K in range(2, max_clusters+1):\n    KMC = KMeans(n_clusters=K).fit(y_pred)\n    labels = KMC.labels_\n    print('fitting for {} clusters completed..'.format(K))\n    score = silhouette_score(y_pred, labels, metric='euclidean')\n    print('silhouette_score for {} clusters: {}'.format(K, score))\n    plt.plot(K, score, '^')\n\nplt.xlabel('K')\nplt.ylabel('Silhoutte Score')\nplt.show()\"\"\"","a6beafd3":"# Select the value of K based on silhouette_score\nK = 2\n\nKMC = KMeans(n_clusters=K, n_jobs=-1, random_state=seed)\nKMC.fit(y_pred)\nK_pred = KMC.predict(y_pred)","45bddf2b":"import pickle\n\n# Save to file in the current working directory\npkl_filename = \".\/Kmeans.pkl\"\nwith open(pkl_filename, 'wb') as file:\n    pickle.dump(KMC, file)","34020dc2":"try:\n    rmtree('Clusters\/')\n    os.mkdir('Clusters\/')\nexcept: pass\n\nfor i in range(K):\n    os.makedirs('Clusters\/' + str(i))\n    [os.makedirs('Clusters\/{}\/{}'.format(i, class_)) for class_ in list(label_dict_.values())]","82065b5c":"for i, im_path in enumerate(im_paths):\n    class_ = data[data['img_path'] == im_path].class_label.values[0]\n    copy(im_path, 'Clusters\/{}\/{}'.format(K_pred[i], class_))","6a89e5a4":"#!zip -r Clusters_ResNet.zip .\/Clusters\/","e1e34e11":"x_images = None\nY = None\ny_pred = None","6b3b605e":"def preprocess(image):\n    #Converting to numpy array from numpy tensor with rank 3\n    image = np.array(image, dtype=np.uint8)\n    #Converting to RGB\n    #img = cv2.cvtCoor(img, cv2.COLOR_BGR2RGB)\n    #Gaussian Blur\n    gaussian_blur = cv2.GaussianBlur(image,(3,3),0)\n    img = np.asarray(gaussian_blur, dtype=np.float64)\n    return img","f5d912dc":"dir = '.\/Clusters\/0'","83b86e71":"del feature_model","48b17f3d":"BATCH_SIZE = 4","362419bc":"#Training  Augumentation\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0\/255,\n                             rotation_range=30,\n                             zoom_range=0.3,\n                             horizontal_flip=True,\n                             brightness_range=[0.6, 1.2],\n                             validation_split=0.2,\n                             fill_mode='nearest',\n                             preprocessing_function=preprocess)\n\n\ntrain_datagen = datagen.flow_from_directory(dir,\n                                            subset = \"training\",\n                                            target_size = (MODEL_IMAGE_SIZE, MODEL_IMAGE_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"categorical\")\n\n#Validation\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0\/255,\n                                        validation_split=0.2,\n                                       preprocessing_function=preprocess)\n\n\nvalid_datagen = validation_datagen.flow_from_directory(dir,\n                                            subset = \"validation\",\n                                            target_size = (MODEL_IMAGE_SIZE, MODEL_IMAGE_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"categorical\")","ab74c626":"!pip install -q efficientnet\nimport efficientnet.tfkeras as efn","3593ddc6":"inp = tf.keras.layers.Input(shape = (MODEL_IMAGE_SIZE, MODEL_IMAGE_SIZE, 3))\n\nx = efn.EfficientNetB5(weights = 'noisy-student', include_top = False)(inp)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutput = tf.keras.layers.Dense(5, activation = 'softmax')(x)\n        \nmodel_0 = tf.keras.models.Model(inputs = [inp], outputs = [output])\n\nopt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n\nmodel_0.compile(\noptimizer = opt,\n    loss = [tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.4)],\n    metrics = [tf.keras.metrics.CategoricalAccuracy()]\n)","379f5a00":"filepath = \"model_0.h5\"\n    \ncallbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n             tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n","70017559":"h = model_0.fit(train_datagen, epochs = EPOCHS, validation_data = valid_datagen, callbacks=callbacks)","0a029aa2":"plt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(h.history[\"categorical_accuracy\"], label=\"train_acc\")\nplt.plot(h.history[\"val_categorical_accuracy\"], label=\"val_acc\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch \")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","1cd83b51":"plt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(h.history[\"loss\"], label=\"train_loss\")\nplt.plot(h.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"upper left\")\nplt.show()\n","09e19555":"dir = '.\/Clusters\/1'","0d5f7c28":"#Training  Augumentation\ndatagen_1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0\/255,\n                             rotation_range=30,\n                             zoom_range=0.3,\n                             horizontal_flip=True,\n                             brightness_range=[0.6, 1.2],\n                             validation_split=0.2,\n                             fill_mode='nearest',\n                             preprocessing_function=preprocess)\n\n\ntrain_datagen_1 = datagen_1.flow_from_directory(dir,\n                                            subset = \"training\",\n                                            target_size = (MODEL_IMAGE_SIZE, MODEL_IMAGE_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"categorical\")\n\n#Validation\nvalidation_datagen_1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0\/255,\n                                        validation_split=0.2,\n                                       preprocessing_function=preprocess)\n\n\nvalid_datagen_1 = validation_datagen_1.flow_from_directory(dir,\n                                            subset = \"validation\",\n                                            target_size = (MODEL_IMAGE_SIZE, MODEL_IMAGE_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"categorical\")","9e5930ef":"inp = tf.keras.layers.Input(shape = (MODEL_IMAGE_SIZE, MODEL_IMAGE_SIZE, 3))\n\nx = efn.EfficientNetB5(weights = 'noisy-student', include_top = False)(inp)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutput = tf.keras.layers.Dense(5, activation = 'softmax')(x)\n        \nmodel_1 = tf.keras.models.Model(inputs = [inp], outputs = [output])\n\nopt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n\nmodel_1.compile(\noptimizer = opt,\n    loss = [tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.4)],\n    metrics = [tf.keras.metrics.CategoricalAccuracy()]\n)","5585c968":"filepath = \"model_1.h5\"\n    \ncallbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n             tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]","f2bcbcc3":"h2 = model_1.fit(train_datagen, epochs = EPOCHS, validation_data = valid_datagen, callbacks=callbacks)","f4550992":"plt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(h2.history[\"categorical_accuracy\"], label=\"train_acc\")\nplt.plot(h2.history[\"val_categorical_accuracy\"], label=\"val_acc\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch \")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","46c3a2dc":"plt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(h2.history[\"loss\"], label=\"train_loss\")\nplt.plot(h2.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"upper left\")\nplt.show()","35d32eb6":"model_0.save('model_0.tf', include_optimizer=True, save_format='tf')","5acda068":"model_1.save('model_1.tf', include_optimizer=True, save_format='tf')","25da7596":"!zip -r model_0.zip 'model_0.tf'","b6ea5ed2":"!zip -r model_1.zip 'model_1.tf'","73f8e77d":"### 5. Saving the Clusters","fbfe0150":"### 2. Defining Model (Xception)","a3a6954e":"## Setting up the environment","c34c93e0":"### 3. Model - Cluster 1","cf2aa827":"### 1. Augumentation and Preprocessing","141347bb":"#### model_0.summary()","f3292977":"### 1. Feature Extraction Baseline","d915623e":"## Defining Parameters","407fee69":"### 2. Reading Data","5fe5d623":"## Clustering Analysis","1c04a6b9":"## Importing Libraries","dff7f200":"### 4. Clustering using KMeans","bb598243":"## Training Model for Cluster 0","5d14587c":"## Removing Duplicates and Mis-labelled Images","2973a1cf":"### 3. Predicting"}}