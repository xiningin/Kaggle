{"cell_type":{"39f82a32":"code","1d2079ae":"code","e0428479":"code","56b6c2d8":"code","45e3b164":"code","92d50185":"code","f87b28ff":"code","0132dd4f":"code","66172e4a":"markdown","1515a85c":"markdown","90fcfd4f":"markdown","35839c48":"markdown","e20f07fc":"markdown","20095d25":"markdown"},"source":{"39f82a32":"\nimport pandas as pd\nimport numpy as np\nimport random\nimport datetime as dt\nimport math\nfrom pandasql import sqldf\npysqldf = lambda q: sqldf(q, globals())\n\npd.set_option(\"display.max_columns\",10)\npd.set_option(\"display.max_rows\",10)","1d2079ae":"#Random Generator for Employee ID\ndef ID_generator(min_size,seed=2):\n    min_size = int(min_size*1.0615)\n    np.random.seed(seed)\n    id = pd.DataFrame(np.random.randint(10000,99999,size=min_size),columns=['Employee_ID'])\n    id = id.drop_duplicates()\n    id=id.astype(int)\n    id = id.reset_index()[['Employee_ID']]\n    return id\n\n#Randomly Allocating Names and Surnames\ndef Name_Generator(Names,Surnames,size=1000,seed=42):\n    np.random.seed(seed)\n    Names = Names.loc[list(np.random.choice(np.arange(0,Names.shape[0]),size = size,p=Names.Probability))].reset_index()\n    Surnames = pd.DataFrame(np.random.choice(Surnames.Surname,size = size,p=Surnames.Probability),columns=['Surname'])\n    Names_data = pd.concat([Names,Surnames],axis=1)\n    #Names_gender=Names_gender.drop_duplicates()\n    return Names_data[['Name','Surname','Gender']]\n\n#Randomly ALlocate Verticals to Employee IDs\ndef Vertical_generator(Vertical=['Consulting','Operations','Technology'],size=1000,p=[0.4,0.3,0.3],seed=45):\n    np.random.seed(seed)\n    vertical = pd.DataFrame(np.random.choice(Vertical,size = size,p=p),columns=['Vertical'])\n    return vertical\n    \n#Randomly allocating the Joining Year and Semester for Employees    \ndef Joining_Year_generator(year=[2016,2017,2018,2019,2020],size=1000,p=[0.17,0.18,0.19,0.21,0.25],seed=31):\n    np.random.seed(seed)\n    year_of_joining = pd.DataFrame(np.random.choice(year,size = size,p=p),columns=['Year_of_Joining'])\n    semester_of_joining = pd.DataFrame(np.random.choice([1,2],size = size,p=[0.5,0.5]),columns=['Semester_of_Joining'])\n    year_sem_joining = pd.concat([year_of_joining,semester_of_joining],axis=1)\n    return year_sem_joining\n\n#Randomly Assigning a Designation to the employees\ndef Designation_generator(designation=[1,2,3,4],size=1000,p=[0.62,0.25,0.1,0.03],seed=21):\n    np.random.seed(seed)\n    Designation_ID = pd.DataFrame(np.random.choice(designation,size = size,p=p),columns=['Designation_ID'])\n    return Designation_ID\n\n\n\n\n#Concatenating all the randomly generated employee details\ndef Create_Employee_Details(size=1000,Names=['John']*1000,Surnames=['Doe']*1000):\n    employee_id = ID_generator(10000)\n    Name_list=Name_Generator(Names=Names,Surnames=Surnames,size=employee_id.shape[0])\n    Vertical=Vertical_generator(size=employee_id.shape[0])\n    year_of_joining=Joining_Year_generator(size=employee_id.shape[0])\n    Designation_ID = Designation_generator(size=employee_id.shape[0])\n    \n    employee_data = pd.concat([employee_id,Name_list,Vertical,Designation_ID,year_of_joining],axis=1)\n    return employee_data","e0428479":"\n#Loading List of Names and Surnames\nNames = pd.read_csv(\"..\/input\/input-feed-for-hr-mock-data\/List of Names with Probability.csv\")\nSurnames = pd.read_csv(\"..\/input\/input-feed-for-hr-mock-data\/List of Surnames with Probability.csv\")\n#Loading the Discrete probability distribution\nCycle_Probs = pd.read_csv(\"..\/input\/input-feed-for-hr-mock-data\/Cycle Probabilities for Generator.csv\")","56b6c2d8":"#Creating the dataset\nMock_employee_Data = pd.DataFrame()\nMock_employee_Data = Create_Employee_Details(10000,Names=Names,Surnames=Surnames)\nMock_employee_Data.tail(100)","45e3b164":"#Generating a promotion score for cycle\n#Adding white noise to the scores\n#-10 for quitters\n#When Cumulative score reaches 1, the Employee is promoted\ndef cycle_generator(Employee_ID,Points,p,cycle_number = 1):\n    size = Employee_ID.shape[0]\n    cycle_col = pd.DataFrame([cycle_number]*size,columns=['Cycle_number'])\n    generator =pd.DataFrame(np.random.choice(Cycle_Probs.Cycle2,size = 10000,p=Cycle_Probs.Cycle2_Prob) \n                            + np.random.normal(0,0.02,10000)\n                            ,columns=['Cycle_Generated'])\n    #generator = generator+ pd.DataFrame(np.random.normal(0,0.02,size))\n    generated_data = pd.concat([Employee_ID,cycle_col,generator],axis=1)\n    return generated_data\n\n#Creating 6 cycles equal to 1 Level\ndef all_cycle_values_generator(Cycle_Probs,Employee_ID,seed=67):\n    np.random.seed(seed)\n    size = Employee_ID.shape[0]\n    cycle1 = cycle_generator(Mock_employee_Data.Employee_ID,Cycle_Probs.Cycle1,p=Cycle_Probs.Cycle1_Prob,cycle_number=1)\n    cycle2 = cycle_generator(Mock_employee_Data.Employee_ID,Cycle_Probs.Cycle2,p=Cycle_Probs.Cycle2_Prob,cycle_number=2)\n    cycle3 = cycle_generator(Mock_employee_Data.Employee_ID,Cycle_Probs.Cycle3,p=Cycle_Probs.Cycle3_Prob,cycle_number=3)\n    cycle4 = cycle_generator(Mock_employee_Data.Employee_ID,Cycle_Probs.Cycle4,p=Cycle_Probs.Cycle4_Prob,cycle_number=4)\n    cycle5 = cycle_generator(Mock_employee_Data.Employee_ID,Cycle_Probs.Cycle5,p=Cycle_Probs.Cycle5_Prob,cycle_number=5)\n    cycle6 = cycle_generator(Mock_employee_Data.Employee_ID,Cycle_Probs.Cycle6,p=Cycle_Probs.Cycle6_Prob,cycle_number=6)\n    all_cycle_combined = pd.concat([cycle1,cycle2,cycle3,cycle4,cycle5,cycle6],axis=0)\n    all_cycle_combined = all_cycle_combined.sort_values(by=['Employee_ID','Cycle_number'])\n    all_cycle_combined= all_cycle_combined.reset_index().drop(columns='index')\n    return all_cycle_combined\n\n#Removing cycles post promotions and post quitting\ndef Filtering_valid_cycles(Cycle_Data):\n    Cleaned_Data=Cycle_Data\n    Cleaned_Data['Cycle_running_total']=Cleaned_Data.sort_values(by=['Employee_ID','Cycle_number'], ascending=True)\\\n                                            .groupby(['Employee_ID'])['Cycle_Generated'].cumsum()\n    #Cleaned_Data['Outcome_calculation']= Cleaned_Data.Cycle_running_total - Cleaned_Data.Base_Points\n    Cleaned_Data['Outcome']= Cleaned_Data.Cycle_running_total\\\n                                            .apply(lambda x:'Promoted' if x>=1 else ('Quit' if x<-1 else 'Nothing'))\n    Cleaned_Data['Prev_Outcome']=Cleaned_Data.sort_values(by=['Employee_ID','Cycle_number'], ascending=True)\\\n                                            .groupby(['Employee_ID'])['Outcome'].shift(1)\n    Cleaned_Data=Cleaned_Data[~Cleaned_Data.Prev_Outcome.isin(['Quit','Promoted'])]\n    Cleaned_Data['Cycle_running_total']=Cleaned_Data['Cycle_running_total']+ Cleaned_Data['Base_Points']\n    Cleaned_data = Cleaned_Data[['Employee_ID','Cycle_number','Cycle_running_total','Outcome']]\n    return Cleaned_data\n\n \n#Generating the Metadate for the Promotion Level\ndef create_metadata(Cleaned_data,Level):\n    Cleaned_data['Absolute_Cycle_running_total'] = abs(Cleaned_data.Cycle_running_total)\n    Aggregates = Cleaned_data.groupby(by='Employee_ID',as_index=False)\\\n                    .agg({'Absolute_Cycle_running_total': ['max'],'Cycle_number':['max']}).T.reset_index().T[2:]\n    Aggregates.columns=['Employee_ID','Cycle_running_total_max','Promote_Cycle_Number']\n    Aggregates['Final_Outcome'] = Aggregates.Cycle_running_total_max.apply(lambda x: 'Quit' if x>5 else ('Promoted' if x>0.9 else 'Fired'))\n    Aggregates['Level']= Level\n    Aggregates.columns=['Employee_ID','Base_Points','Base_Cycle','Prev_Outcome','Level']\n    return Aggregates\n\n#Creating the Level with the Metadata and Cycle Probabilities\ndef Create_Level(Metadata, Cycle_Probs,Level):\n    Metadata_useful = Metadata[Metadata.Prev_Outcome.isin(['Start','Promoted'])]\n    Cycle_data = all_cycle_values_generator(Cycle_Probs,Metadata_useful.Employee_ID)\n\n    \n    Cycle_data_with_meta = Metadata_useful.merge(Cycle_data,on='Employee_ID',how='inner')\n    Cycle_data_with_meta['Cycle_number'] = Cycle_data_with_meta['Base_Cycle'] +  Cycle_data_with_meta['Cycle_number'] \n    Cycle_data_with_meta= Cycle_data_with_meta[['Employee_ID','Cycle_number','Cycle_Generated','Base_Points']]\n    \n    Cleaned_Data = Filtering_valid_cycles(Cycle_data_with_meta)\n    Cleaned_Data['Level'] = Level\n    Cleaned_Data=Cleaned_Data[['Employee_ID','Cycle_number','Cycle_running_total','Level']]\n    metadata = create_metadata(Cleaned_Data,Level=Level)\n    \n    return Cleaned_Data,metadata\n\n#Creating Level 0 and Level 0 Metadata\ndef Create_Level0(Employee_details):\n    Level0=Employee_details[['Employee_ID','Designation_ID']] \n    Level0['Cycle_number'] = 0\n    Level0['Level'] = 0\n    Level0['Cycle_running_total']=Level0['Designation_ID']\n    Level0=Level0[['Employee_ID','Cycle_number','Cycle_running_total','Level']]\n    \n    level0_metadata=Employee_details[['Employee_ID','Designation_ID']]\n    level0_metadata['Base_Cycle']  = 0\n    level0_metadata['Prev_Outcome'] = 'Start'\n    level0_metadata['Level'] = 0\n    level0_metadata.columns=['Employee_ID','Base_Points','Base_Cycle','Prev_Outcome','Level']\n    return Level0, level0_metadata","92d50185":"#Using the Functions to Create the Cycles \n#using a discrete probability distribution \n\n\n\n#Generating 4 Levels\nLevel0, Level0_metadata = Create_Level0(Mock_employee_Data)\nLevel1, Level1_metadata = Create_Level(Level0_metadata,Cycle_Probs,Level=1)\nLevel2, Level2_metadata = Create_Level(Level1_metadata,Cycle_Probs,Level=2)\nLevel3, Level3_metadata = Create_Level(Level2_metadata,Cycle_Probs,Level=3)\n\n#Unioning the Level dataset\nLevel_Data=pd.concat([Level0,Level1,Level2,Level3],axis=0).sort_values(by=['Employee_ID','Cycle_number'])\nLevel_Data['Employee_ID']=Level_Data['Employee_ID'].astype(int)\nLevel_Data['Cycle_number']=Level_Data['Cycle_number'].astype(int)\nLevel_Data=Level_Data.reset_index()\nLevel_Data=Level_Data.drop(columns=['index','Absolute_Cycle_running_total'])\nLevel_Metadata = pd.concat([Level0_metadata,Level1_metadata,Level2_metadata,Level3_metadata],axis=0)\\\n.sort_values(by=['Employee_ID','Level'])\nLevel_Metadata['Employee_ID']=Level_Metadata['Employee_ID'].astype(int)\n","f87b28ff":"#Calculating the Next Cycle Running Total and other data formatting\nLevel_Data['Cycle_running_total_Next']=Level_Data.sort_values(by=['Cycle_number'], ascending=True)\\\n                       .groupby(['Employee_ID'])['Cycle_running_total'].shift(-1)\nLevel_Data['Cycle_number_Next']=Level_Data['Cycle_number']+1\nLevel_Data['Path_ID']= Level_Data.Employee_ID.astype(str) + \"_\" + Level_Data.Cycle_number.astype(str) +\"_\" + Level_Data.Level.astype(str) \nLevel_Data = Level_Data.dropna()\nLevel_Data_v2 =Level_Data.merge(Mock_employee_Data,on='Employee_ID',how='left')[['Employee_ID','Year_of_Joining','Semester_of_Joining','Cycle_number','Cycle_running_total','Level','Cycle_running_total_Next','Cycle_number_Next','Path_ID']]\nLevel_Data_v2['Cycle_year'] = Level_Data_v2['Year_of_Joining'] + np.floor((Level_Data_v2.Semester_of_Joining+Level_Data_v2.Cycle_number)\/2)\nLevel_Data_v2['Cycle_month'] = ((Level_Data_v2.Semester_of_Joining+Level_Data_v2.Cycle_number)%2)*6+1\nLevel_Data_v2['Cycle_date'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in zip(Level_Data_v2.Cycle_year.astype(int), Level_Data_v2.Cycle_month, [1]*Level_Data_v2.shape[0])])\n\nLevel_Data_v2['Current_Designation'] = Level_Data_v2['Cycle_running_total'].apply(lambda x: \n                                                                                 'Principal' if math.floor(x) ==5 else\n                                                                                  ('Manager' if math.floor(x) ==4 else\n                                                                                   ('Consulant' if math.floor(x) ==3 else\n                                                                                    ('Associate Consulant' if math.floor(x) ==2 else\n                                                                                     ('Associate' if math.floor(x)==1 else 'Quit'\n                                                                                     )))))\nLevel_Data_v2 = Level_Data_v2[['Employee_ID', 'Cycle_number',\n       'Cycle_running_total', 'Level', 'Cycle_running_total_Next',\n       'Cycle_number_Next', 'Current_Designation','Path_ID',\n       'Cycle_date','Cycle_year','Cycle_month']]","0132dd4f":"#Writing data to CSV\nLevel_Data_v2.to_csv(\"Mock HR Paths Data v3.csv\",index=False)\nMock_employee_Data.to_csv(\"Mock HR Employee Details v3.csv\",index=False)","66172e4a":"## Creating the Promotion Links","1515a85c":"### Generating the mock dataset","90fcfd4f":"Please Check out the Tableau Dashboard made using the following Mock Data <br> \nhttps:\/\/public.tableau.com\/views\/HumanResourceOverview_16363998269320\/OverviewDashboard?:language=en-US&:display_count=n&:origin=viz_share_link","35839c48":"## Loading Libraries","e20f07fc":"## Building the Employee Details Random Generator","20095d25":"### Loading the dataset of Names and Surnames"}}