{"cell_type":{"b7df85d4":"code","85dd3331":"code","b1f3c601":"code","61bcf0f0":"code","16f077bb":"code","c34503db":"code","a96af28f":"code","dd9f1cf6":"code","f4f99e9e":"code","56a2ab66":"code","9f7b3409":"code","d5014c07":"code","0e3bc8f7":"code","3ba1ed0e":"code","d544f4b7":"code","152df538":"markdown","d409b75d":"markdown","7fbdcc69":"markdown","ac94d516":"markdown","00a09565":"markdown","22a24cb2":"markdown","cec7cfc7":"markdown","d20198fe":"markdown","b6302b66":"markdown","418cd3a1":"markdown","188f832a":"markdown","0e9c20aa":"markdown","3b6851d6":"markdown"},"source":{"b7df85d4":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","85dd3331":"img = mpimg.imread('..\/input\/home.png')\ndata = img.reshape(1,img.shape[0], img.shape[1], img.shape[2])\n\n\nprint(type(img))\nprint(\"Image dimension \",img.shape)\nprint(\"Input data dimension \", data.shape)","b1f3c601":"plt.imshow(data[0,:,:,:])\nplt.grid(False)\nplt.axis(\"off\")","61bcf0f0":"def zero_pad(data, pad):\n    data_padded = np.pad(array = data, pad_width = ((0,0),(pad,pad), (pad,pad), (0,0)), mode = 'constant', constant_values = 0)\n    return data_padded\n    ","16f077bb":"print(\"dimension before padding: \", data.shape)\nimg_pad = zero_pad(data, 10)\nprint(\"dimension after padding: \", img_pad.shape)\nprint(img_pad[0,8:12,8:12,1])\nplt.imshow(img_pad[0,:,:,:], cmap = \"gray\")\nplt.grid(False)\n\noutput1 = np.mean(img_pad)","c34503db":"def conv_single_step(data_slice, W, b):\n    conv = np.multiply(data_slice, W)\n    Z = np.sum(conv) + b\n    \n    return Z","a96af28f":"def conv_forward(A_prev, W, b, hparams):\n  stride = hparams[\"stride\"]\n  pad = hparams[\"pad\"]\n \n  m, h_prev, w_prev, c_prev = A_prev.shape\n   \n  f, f, c_prev, n_c = W.shape\n  \n  n_h = int((h_prev - f + 2*pad)\/stride) + 1\n  n_w = int((w_prev - f + 2*pad)\/stride) + 1\n  \n  Z = np.zeros((m, n_h, n_w, n_c))\n  A_prev_pad = zero_pad(A_prev, pad)\n  for i in range(m):\n    for h in range(n_h):\n      for w in range(n_w):\n        for c in range(n_c):\n           w_start = w * stride\n           w_end = w_start + f \n           h_start = h * stride\n           h_end = h_start + f\n        \n           Z[i,h,w,c] = conv_single_step(A_prev_pad[i, h_start:h_end, w_start:w_end, :], W[:,:,:,c], b[:,:,:,c])\n  return Z","dd9f1cf6":"np.random.seed(1)\ninput_ = np.random.randn(10, 4, 4, 3)\nW = np.random.randn(2, 2, 3, 8)\nb = np.random.randn(1, 1, 1, 8)\nhparameters = {\"pad\" : 1,\n               \"stride\": 1}\n\noutput_ = conv_forward(input_, W, b, hparameters)\nprint(np.mean(output_))","f4f99e9e":"edge_detect = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]).reshape((3,3,1,1))","56a2ab66":"\nhparams = {\"pad\" : 0,\n               \"stride\": 1}\nb = np.zeros((1, 1, 1, 1))\nZ = conv_forward(data, edge_detect, b, hparams)\n\n\nplt.clf()\nplt.imshow(Z[0,:,:,0], cmap='gray',vmin=0, vmax=1)\nplt.grid(False)\nprint(\"dimension of image before convolution: \", data.shape)\nprint(\"dimension of image after convolution: \", Z.shape)\n\noutput2 = np.mean(Z[0,100:200,200:300,0])\n\n","9f7b3409":"\n##below are the filters for vetical as well as horizontal edge detection, try these filters once you have completed this handson.\nvertical_filter = np.array([[-1,2,-1],[-1,2,-1],[-1,2,-1]]).reshape(3,3,1,1)\n\nZ = conv_forward(data, vertical_filter, b, hparams)\nplt.clf()\nplt.imshow(Z[0,:,:,0], cmap='gray',vmin=0, vmax=1)\nplt.grid(False)\nprint(\"dimension of image before convolution: \", data.shape)\nprint(\"dimension of image after convolution: \", Z.shape)\n","d5014c07":"\n\nhorizontal_filter = np.array([[-1,-1,-1],[2,2,2],[-1,-1,-1]]).reshape((3,3,1,1))\nZ = conv_forward(data, horizontal_filter, b, hparams)\nplt.clf()\nplt.imshow(Z[0,:,:,0], cmap='gray',vmin=0, vmax=1)\nplt.grid(False)\nprint(\"dimension of image before convolution: \", data.shape)\nprint(\"dimension of image after convolution: \", Z.shape)\n","0e3bc8f7":"def max_pool(input, hparam):\n    m, h_prev, w_prev, c_prev = input.shape\n    f = hparam[\"f\"]  ## f is the filter size to use for pooling\n    stride = hparam[\"stride\"]\n    h_out = int(((h_prev - f)\/stride) + 1)\n    w_out = int(((w_prev -f)\/stride) + 1)\n    output = np.zeros((m, h_out, w_out, c_prev))\n    for i in range(m):\n        for c in range(c_prev):\n            for h in range(h_out):\n                for w in range(w_out):\n                    w_start = w * stride\n                    w_end = w_start + f\n                    h_start = h * stride\n                    h_end = h_start + f\n                    output[i, h, w, c] = np.max(input[i,h_start:h_end, w_start:w_end, c])\n    print(output.shape)\n    assert output.shape == (m, h_out, w_out, c_prev)\n    return output","3ba1ed0e":"pool_params = {\"stride\" : 2, \"f\" : 2}\noutput_ = max_pool(input_, pool_params)\nprint(np.mean(output_))","d544f4b7":"###start code\nhparams = {'stride':1, 'f':2}\nZ_pool =  max_pool(input_, hparams)\n###End code\n\nprint(\"dimension before pooling :\", Z.shape)\nprint(\"dimension after pooling :\", Z_pool.shape)\n\nplt.imshow(Z_pool[0,:,:,0], cmap = \"gray\")\n\nwith open(\"output.txt\", \"w+\") as file:\n    file.write(\"output1 = %f\" %output1)\n    file.write(\"\\noutput2 = %f\" %output2)","152df538":"### Max pooling\nDefine method max_pool to perform max pooling on the input data.  \nParameters:  \n        - data: input data on which convolution is performed  \n        - hparams: dictionary defined by {\"f\": f, \"stride\": s} , f is the filter size and s              the number of strides\nreturns:  \n       - output: output after pooling \n\nrefer the code snippet provided in the course.  ","d409b75d":"### zero padding\n- Define method named zero_pad that performs specified number of zero padding on the input data.  \nparameters: \n            data: the data on which padding is performed    \n            pad:  the amount of padding around the data    \nreturns: \n            data_padded: the nd-array after padding  ","7fbdcc69":"- Run the below cell to define edge_detect filter, the filter values for edge detection has been define for you","ac94d516":"- Define a dictionary hparams with stride = 1 and pad = 0\n- initialize bias parameter b to zero of dimension (1,1,1,1) hint: use np.zeros()\n- Perform strided convolution using the method conv_forward() you defined previously.\n  - pass edge_detect filter, bais b and hparams as parameters to perform convolution on the data variable defined previously.\n  - assign the result to variable Z","00a09565":"- Run the below cell to add zero zero padding using the method define above.   \nExpected output:\n             [[0. 0. 0. 0.]\n             [0. 0. 0. 0.]\n             [0. 0. 1. 1.]\n             [0. 0. 1. 1.]]","22a24cb2":"- The below cell defines the test data for input as well as filter.  \n- Run the cell to perfom the convolution operation using the method defined above.   \n**Expected output: 0.145**\n               ","cec7cfc7":"- Run the below cell to test the method you define above.  \nExpected output: **1.075**","d20198fe":"### Strided Convolution\nDefine method conv_forward to perform strided convolution on the input data.  \nuse conv_single_step() to perform the convolution at each stride.  \nParameters:  \n        - data: input data on which convolution is performed  \n        - W: the filter used for convolution operation  \n        - b: the bias term  \n        - hparams: dictionary defined by {\"stride\": s, \"pad\": p}  \nreturns:  \n       - Z: the convolved output  \n\nrefer the code snippet provided in the course.  ","b6302b66":"- Define pooling parameters \"stride\" and filter size \"f\" as a dictionary named **hparams** with stride = 1 and f = 2\n- call the method max_pool with parameters Z (the convolved output) and hparams ","418cd3a1":"Convolutional neural networks overcome the limitations of brute force and 1D representation of data approaches since their predictions are spatially invariant and independent of the size of the images.\n\nThey also greatly reduce the number of parameters required to train the network.\n\n","188f832a":"- Read the image file '**home.png**'(in current directory) using **mpimg.imread(\"file_path\")** function provided by matplotlib.image module. This function reads the image and returns the pixel intensities in numpy format. Assign this result to variable **img**.\n- The dimension of **img** will now be $n_H$ x $n_w$ x $n_c$\n- reshape **img** to dimension $m$ x $n_H$ x $n_w$ x $n_c$ and assign it to variable **data**. The dimension **m** will be **one** since we are dealing with one image data. (use numpy's reshape())\n\nExpected output:   \n**class 'numpy.ndarray'**  \n**Image dimension  (252, 362, 3)**  \n**input data dimension  (1, 252, 362, 3)**     ","0e9c20aa":"- Run the below cell to view the image from the data","3b6851d6":"### Convolution single step  \nDefine the function named conv_single_step() to convolve a slice of input data using the specified filter  \nparameter:  \n         - data_slice: the receptive field over which convolution is performed  \n         - W: the filter used for convolution  \n         - b: the bias term  \nreturns:\n         - Z: convolved output over the receptive field"}}