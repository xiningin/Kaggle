{"cell_type":{"71f2eb24":"code","9963441a":"code","a16ce77a":"code","5aa4e22d":"code","62ef1b87":"code","337a83c3":"code","d1b7db7e":"markdown","adfe527c":"markdown"},"source":{"71f2eb24":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image_dataset_from_directory\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","9963441a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a16ce77a":"# Assigning the training and validation directories\n\nbase_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/'\n\ntrain_dir = os.path.join(base_dir, \"Train\")\nvalidation_dir = os.path.join(base_dir, 'Validation')\ntest_dir = os.path.join(base_dir, \"Test\")","5aa4e22d":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   brightness_range = (0.5, 0.9),\n                                   zoom_range=0.3,\n                                   fill_mode=\"nearest\")\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","62ef1b87":"# Creating the dataset of augmented images: Images get augmented only during training\n# This will be passed to the model.fit() during training for using the augmented images\n\ntrain_dataset = train_datagen.flow_from_directory(train_dir,\n                                                  target_size=(160,160),\n                                                  batch_size=64,\n                                                  class_mode=\"binary\")\n\nvalidation_dataset = test_datagen.flow_from_directory(validation_dir,\n                                                      target_size=(160, 160),\n                                                      batch_size=64,\n                                                      class_mode=\"binary\")","337a83c3":"# 0 -- With Mask \/\/\/\/ 1 -- Without Mask\nclass_names = ['WithMask', 'WithoutMask']\n\n# Selects some images from the train_dataset (Iterator object)\nimages,labels = next(iter(train_dataset))\n\n# Plots the images\nplt.figure(figsize=(10,10))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(images[i])\n    plt.xticks([])\n    plt.yticks([])\n    if (labels[i]==1.0):plt.xlabel(class_names[1])\n    elif (labels[i]==0.0): plt.xlabel(class_names[0])\n    \n\nplt.show()","d1b7db7e":"# ***Data Augmentation***","adfe527c":"## ***Image Augmentation: Using ImageDataGenerator***"}}