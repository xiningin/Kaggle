{"cell_type":{"8fae10fd":"code","2b668331":"code","815cb514":"code","8e02bec3":"code","f0ab2ab0":"code","30d24387":"code","c67c8830":"code","d832c436":"code","d2ea28a7":"code","7246ddb9":"code","3e016329":"code","4dd1034a":"code","22a45d73":"code","9df33b91":"code","8479b6ea":"code","31a8d9b8":"code","7701bcca":"code","8c2ea9cb":"code","86a424df":"code","b3b791c8":"code","8b70c6d3":"code","d8bacdab":"code","80f73883":"code","960eca86":"code","17ad1638":"code","ce38e8e4":"code","3a935a35":"code","292f7163":"code","42ed4681":"code","5618dbde":"code","b1c77035":"code","94dd4888":"code","152a8866":"code","026b6dde":"code","c7e4d7b2":"code","320ae148":"code","740ca876":"code","73314a87":"code","ff13defe":"code","d20e66d9":"code","2dfd3a57":"code","4abdee61":"code","b2737b8f":"code","114cd008":"code","67e291af":"markdown","a424d082":"markdown","426f2afe":"markdown","41d80c53":"markdown","fc7b1fae":"markdown","310465b3":"markdown","1b47b0cc":"markdown","727cbe63":"markdown","277dad4d":"markdown","48dd12fa":"markdown","35de3a17":"markdown","81a3d341":"markdown","87ad5d58":"markdown","b5b5ada4":"markdown","7e807a90":"markdown","9db66817":"markdown","cd86c90a":"markdown","f8046b00":"markdown","d682b6d0":"markdown","2141c5ed":"markdown","e853b5d0":"markdown","7fb6c634":"markdown","575bb5b2":"markdown","c77e12a7":"markdown","1eacf452":"markdown","5669449b":"markdown","1b001455":"markdown","f20340e8":"markdown","91c45920":"markdown","f1524015":"markdown","21bd7431":"markdown","765e3173":"markdown","900278e8":"markdown","d465f568":"markdown","5ea96466":"markdown","cb94cdf7":"markdown","76dffa5b":"markdown","1648564c":"markdown","ae5126c3":"markdown","e10a5a52":"markdown","22f243b3":"markdown","a868a92b":"markdown","e4c414e3":"markdown","f55d1f87":"markdown","c6c47898":"markdown","59ac5881":"markdown","96fbebde":"markdown","16388696":"markdown","78760ba0":"markdown","ef31e8c3":"markdown","aed60d09":"markdown","f84f9c3b":"markdown"},"source":{"8fae10fd":"import numpy as np # to handle data in a vectorized manner\n\nimport pandas as pd # for data analsysis\npd.set_option(\"display.max_columns\", None) # to be able to see all columns\npd.set_option(\"display.max_rows\", None) # to be able to see all rows\n\nimport json # to handle JSON files\nfrom pandas.io.json import json_normalize # to tranform JSON file into a pandas dataframe\n\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # to handle requests\nimport urllib.request\nfrom bs4 import BeautifulSoup # to parse HTML and XML documents\n\nfrom sklearn.cluster import KMeans # import k-means from clustering stage\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n#!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # map rendering\n\nprint(\"Libraries imported.\")","2b668331":"url = 'https:\/\/en.wikipedia.org\/wiki\/List_of_postal_codes_of_Canada:_M'\npage = urllib.request.urlopen(url)  ","815cb514":"# parse the HTML from our URL into the BeautifulSoup parse tree format\nsoup = BeautifulSoup(page, \"lxml\")","8e02bec3":"# let's see the title of the web page as example\nsoup.title.string","f0ab2ab0":"# to see the important part, look at the characters between 9000-9300\nprint(soup.prettify()[9000:9300])","30d24387":"# all_tables = soup.find_all('table')\n# or just specify the table with a \"wikitable sortable\" class ID\n# doing so, we will get rid of some informations unnecessary\n\ntable = soup.find('table', class_ = 'wikitable sortable')\n# Let's see first 100 character of the table \nprint(table.prettify()[0:100])","c67c8830":"A = []\nB = []\nC = []\n\nfor row in table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==3:\n        A.append(cells[0].find(text=True).rstrip('\\n'))\n        B.append(cells[1].find(text=True).rstrip('\\n'))\n        C.append(cells[2].find(text=True).rstrip('\\n'))","d832c436":"df = pd.DataFrame(A, columns=['PostalCode'])\ndf['Borough'] = B\ndf['Neighborhood'] = C\ndf.head()","d2ea28a7":"df['Borough'].replace('Not assigned', np.nan, inplace=True)\ndf.dropna(subset=['Borough'], inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf.head()","7246ddb9":"# if there would be \"not assigned\" for Neighborhood column\n\nfor index, row in df.iterrows():\n    if row[\"Neighborhood\"] == \"Not assigned\":\n        row[\"Neighborhood\"] = row[\"Borough\"]","3e016329":"df.shape","4dd1034a":"!ls \/kaggle\/input\/toronto-geospatial","22a45d73":"df_coor = pd.read_csv('\/kaggle\/input\/toronto-geospatial\/Toronto_Geospatial_Coordinates.csv')\ndf_coor.head()","9df33b91":"# rename the colum \"Postal Code\" as \"PostalCode\" to be able to merge based on it\ndf_coor.rename(columns = {'Postal Code' : 'PostalCode'}, inplace=True)\ndf_coor.head()","8479b6ea":"df = pd.merge(df, df_coor, on=\"PostalCode\", how=\"left\")\ndf_neighborhood = df \ndf_neighborhood.head()","31a8d9b8":"address = 'Toronto'\n\ngeolocator = Nominatim(user_agent=\"to_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))","7701bcca":"# create map of Toronto using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(df_neighborhood['Latitude'], df_neighborhood['Longitude'], df_neighborhood['Borough'], df_neighborhood['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=3,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.5,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto","8c2ea9cb":"CLIENT_ID = 'DZVNYQSZ2SFHRFNLHMRXC5TTGASDMYLVLQ2ZUTT34WHOOC44' \nCLIENT_SECRET = 'O4SY41AI0OETZA1KTIHWYIAFKFZYW5F3RW3JTCKR4SFBSLR1' \nVERSION = '20180605' # Foursquare API version\nLIMIT = 100 # limit of number of venues returned by Foursquare API\nradius=500","86a424df":"def get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']","b3b791c8":"def getNearbyVenues(names, latitudes, longitudes, radius=500): # radius is 500m so as not to leave the center of neighborhood \n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        # print(name)\n            \n        # create the API request URL\n        url = 'https:\/\/api.foursquare.com\/v2\/venues\/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)","8b70c6d3":"Toronto_venues = getNearbyVenues(names=df['Neighborhood'],\n                                   latitudes=df['Latitude'],\n                                   longitudes=df['Longitude'])","d8bacdab":"print(Toronto_venues.shape)\nToronto_venues.head()","80f73883":"print('There are {} uniques categories.'.format(Toronto_venues['Venue Category'].nunique()))","960eca86":"df_chicken = Toronto_venues[Toronto_venues['Venue Category'] == 'Fried Chicken Joint'].reset_index(drop=True)\nprint(df_chicken.shape)\ndf_chicken.head()","17ad1638":"Toronto_venues.Neighborhood.value_counts()[0:10]","ce38e8e4":"most_venues=Toronto_venues.Neighborhood.value_counts().to_frame()\noptimal_venues = most_venues[(most_venues.Neighborhood < 80) & (most_venues.Neighborhood >= 35) ]\noptimal_neigs = optimal_venues.index.tolist()\n\ndf_35_80 = pd.DataFrame()\nfor neig in optimal_neigs:\n    df_35_80 = df_35_80.append(Toronto_venues[Toronto_venues['Neighborhood'] == neig], ignore_index=True)","3a935a35":"most_venues=Toronto_venues.Neighborhood.value_counts().to_frame()\noptimal_venues = most_venues[(most_venues.Neighborhood < 80) & (most_venues.Neighborhood >= 35) ]\noptimal_neigs = optimal_venues.index.tolist()\noptimal_neigs\n","292f7163":"df_35_80 = pd.DataFrame()\nfor neig in optimal_neigs:\n    df_35_80 = df_35_80.append(Toronto_venues[Toronto_venues['Neighborhood'] == neig], ignore_index=True)\nprint(df_35_80.shape)\ndf_35_80.head()","42ed4681":"venues_map = folium.Map(location=[latitude, longitude], zoom_start=13) # generate map centred around the central of Lille\n\n# add populer spots as blue circle markers   \nfor lat, lng, label in zip(df_35_80['Venue Latitude'], df_35_80['Venue Longitude'], df_35_80['Venue Category']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=1,\n        popup=label,\n        fill=True,\n        color='blue',\n        fill_color='red',\n        fill_opacity=0.1,\n        parse_html=False).add_to(venues_map) \n\n\n# add the Fried Chicken Joint as blue circle markers\nfor lat, lng, label in zip(df_chicken['Venue Latitude'], df_chicken['Venue Longitude'], df_chicken['Venue']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=3,\n        color='red',\n        popup=label,\n        fill = True,\n        fill_color='red',\n        fill_opacity=0.4,\n        parse_html=False).add_to(venues_map)\n    \n\n# display map\nvenues_map","5618dbde":"# one hot encoding\ntoronto_onehot = pd.get_dummies(df_35_80[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighborhood_1'] = df_35_80['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot.head()","b1c77035":"toronto_onehot.shape","94dd4888":"toronto_grouped = toronto_onehot.groupby('Neighborhood_1').mean().reset_index()\ntoronto_grouped.head()","152a8866":"toronto_grouped.shape","026b6dde":"num_top_venues = 5\n\nfor hood in toronto_grouped['Neighborhood_1']:\n    print(\"----\"+hood+\"----\")\n    temp = toronto_grouped[toronto_grouped['Neighborhood_1'] == hood].T.reset_index()\n    temp.columns = ['venue_category ','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","c7e4d7b2":"def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]","320ae148":"num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood_1']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood_1'] = toronto_grouped['Neighborhood_1']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.rename(columns={'Neighborhood_1': 'Neighborhood'}, inplace=True)\nneighborhoods_venues_sorted.head()","740ca876":"import matplotlib.pyplot as plt  \n\ncost =[] \ntoronto_grouped_clustering = toronto_grouped.drop('Neighborhood_1', 1)\n\nfor i in range(1, 11): \n    KM = KMeans(n_clusters = i, max_iter = 500) \n    KM.fit(toronto_grouped_clustering) \n      \n    # calculates squared error \n    # for the clustered points \n    cost.append(KM.inertia_)      \n\n# plot the cost against K values   \nplt.plot(range(1, 11), cost, color ='g', linewidth ='3') \nplt.xlabel(\"Value of K\") \nplt.ylabel(\"Sqaured Error (Cost)\") \nplt.show() # clear the plot \n  \n# the point of the elbow is the  \n# most optimal value for choosing k ","73314a87":"# best number of k is 5\nkclusters = 3\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ","ff13defe":"# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = df_neighborhood\n\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\nprint(toronto_merged.shape)\ntoronto_merged = toronto_merged.dropna()\ntoronto_merged.head() # check the last columns!","d20e66d9":"# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[int(cluster)-1],\n        fill=True,\n        fill_color=rainbow[int(cluster)-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters","2dfd3a57":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1,2] + list(range(5, toronto_merged.shape[1]))]]","4abdee61":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1,2] + list(range(5, toronto_merged.shape[1]))]]","b2737b8f":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1,2] + list(range(5, toronto_merged.shape[1]))]]","114cd008":"list_3_Neigs = ['Regent Park, Harbourfront', 'Kensington Market, Chinatown, Grange Park', 'Fairview, Henry Farm, Oriole'] \n\nnum_top_venues = 5\n\nfor hood in list_3_Neigs:\n    print(\"----\"+hood+\"----\")\n    temp = toronto_grouped[toronto_grouped['Neighborhood_1'] == hood].T.reset_index()\n    temp.columns = ['venue_category','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","67e291af":"for Neighborhood=\"Not assigned\", make the value the same as Borough","a424d082":"The important part is starting with an HTML __table tag__ with a class identifier of __\u201dwikitable sortable\u201d__. \n\nScroll down a little to see how the table is made up and you\u2019ll see the rows start and end with __tr__ and __tr__ tags.\n\nThe top row of headers has __th__ tags while the data rows beneath for each club has __td__ tags. It\u2019s in these tags that we will tell Python to extract our data from.","426f2afe":"## 1. Introduction to Business Problem <a name=\"introduction\"><\/a>","41d80c53":"We will try to find the possible locations that have normal restaurant and other types of venues density in addition to that they should don't have Fried Chicken Joint.\n\nIn the first step, we have collected the required data: The Neighborhoods and their locations and also the venues in each of these neighborhoods to see density.  \n\nIn the second step in our analysis, we will look at 'venues and restaurant density' across different areas of Toronto - we will use maps to identify a few promising areas close to center with moderate density of restaurants, neither too much nor too little.\n\nIn the third and final step, we will focus on the most promising areas and within those create clusters of locations (using k-means clustering) that meet some basic requirements established in discussion with entrepreneur. ","fc7b1fae":"\nNow, create the new dataframe and display the top 10 venues for each neighborhood.","310465b3":"To get an idea of the structure of the underlying HTML in our web page, we can view the HTML with __Soup\u2019s prettify__ function","1b47b0cc":"Let's find out how many unique categories can be curated from all the returned venues","727cbe63":"__Define Foursquare Credentials and Version__","277dad4d":"Run *k*-means to cluster the neighborhood into 5 clusters.","48dd12fa":"## I am waiting for your comment to improve my works \n\n## By the way, if you like this notebook thanks for Upvoting :)","35de3a17":"We create a dataframe, assigning each of the lists A-C into a column with the name of our source table columns (PostalCode, Borough, Neighborhood)","81a3d341":"### Merge two tables to get the coordinates","87ad5d58":"Let's write the code to run the above function on each neighborhood and create a new dataframe called Toronto_venues","b5b5ada4":"#### So:\nLike we decide at the beginning of this analysis, we want to find the neighborhoods that don't have too many venues because it may be risky for our new restaurant. In another aspect, we don't want to open it in a neighborhood that don't have much potential. So finally, after discussing with my client, we will focus on the neighborhoods that have more than 35 and less than 80 venues 500m near the center of the neighborhood.","7e807a90":"### Import libraries","9db66817":"We will need the __get_category_type__ function to extract category of venue.","cd86c90a":"remove  __'Not Assigned'__ cells","f8046b00":"### C. Use Foursquare API to explore the venues","d682b6d0":"### Now we will search for 'Fried Chicken Restaurant'","2141c5ed":"__import the functions from \"Beautiful Soup\" which will let us parse and work with the HTML that we fetched from our Wiki page:__","e853b5d0":"Let's look at the shape ","7fb6c634":"- In order to segment the neighborhoods and explore them, we will essentially need a dataset that contains the boroughs and the neighborhoods that exist in each borough as well as the latitude and longitude coordinates of each neighborhood. So we will scrape the data that contain neighborhoods names and their postal code from the following Wikipedia page:  'https:\/\/en.wikipedia.org\/wiki\/List_of_postal_codes_of_Canada:_M'\n\n\n- Then, we will merge it with the data that contain all the geographical coordinates of the neighborhoods thanks to the following csv file:\n\u201chttps:\/\/www.kaggle.com\/stevenluongtruong\/toronto-geospatial\u201d\n\n\n- Finally, to get the locations(latitude and longitude) and other informations about various venues in Toronto, we will use __Foursquare\u2019s API__. ","575bb5b2":"## 3. Methodology <a name=\"methodology\"><\/a>","c77e12a7":"#### Cluster 1","1eacf452":"## Examine Clusters","5669449b":"### Create a __map__ of Toronto with neighborhoods superimposed on top","1b001455":"### A. Scrap the data from Wikipedia page into a DataFrame","f20340e8":"There are 3 columns in our table that we want to scrape the data from.\n__so we will set up 3 empty lists (A, B, C) to store our data in.__\n\n*  We know that the table is set up in rows (starting with 'tr' tags) with the data sitting within 'td' tags in each row. We aren\u2019t too worried about the header row with the 'th' elements as we know what each of the columns represent by looking at the table.\n* To start with, we want to use the Beautiful Soup \u2018find_all\u2019 function again and set it to look for the string \u2018tr\u2019. We will then set up a FOR loop for each row within that array and set Python to loop through the rows, one by one.\n\n* Within the loop we are going to use find_all again to search each row for 'td' tags with the \u2018td\u2019 string. We will add all of these to a variable called \u2018cells\u2019 and then check to make sure that there are 3 items in our \u2018cells\u2019 array.\n\n* If there are then we use the find(text=True)) option to extract the content string from within each 'td' element in that row and add them to the A-C lists we created at the start of this step","91c45920":"__NOTE :__ all the information we need is in the items key.\n\n### Extract the data of venues in Toronto and make a dataframe from them\n\n__we will need \"getNearbyVenues\" fonctionne__","f1524015":"   ### Background \n  \n  My client is a successful entrepreneur in Europe. It's only been 3 years since he started his business. But now, in 2020, He has 16 Fried Chicken Restaurants in big cities of Europe like Paris, Berlin, Brussels, Amsterdam etc.  And now, he wants to expand his business in other countries. He has a particular interest in Canada. So, he wants to open a new restaurant in Toronto.\n  \n  ### Business Problem\n\nIn this project we will try to find an optimal location for a new __Fried Chicken Restaurant__ in Toronto, Canada. Since there are lots of restaurants in Toronto, we will try to detect locations that are not already so crowded with venues, especially  restaurants. By the way, the place should not be too secluded. \nWe are particularly interested in a potential neighborhood with no Fried Chicken Restaurant in vicinity. We would also prefer locations as close to the city center as possible to attract more customers, assuming that the first two conditions are met.\n\n   We will use some data science and machine learning techniques to generate a few most promissing neighborhoods based on these criteria. Advantages of each area will then be clearly expressed so that best possible final location can be chosen by my client.\n  \n\n   ### About Toronto\n  \n  Toronto is Canada\u2019s largest city and a world leader in such areas as business, finance, technology, entertainment and culture. Its large population of immigrants from all over the globe has also made Toronto one of the most multicultural cities in the world. \n  So Toronto has full potential but also is a very challenging district to open a business because of high competition. \n  \n  ### Target Audience\n   \n   Specifically, this report will be targeted to my client who wants to find the optimal location to open a new Fried Chicken Joint in Toronto. But the other stakeholders interested in the same kind of opportunity can also benefit from it.\n\n","21bd7431":"- __Cluster 1 :__ Most of the neighborhoods fall into this cluster. There are mostly business areas with coffee shops, pizza places, restaurants, bar, etc.. There are also social activity venues. Some of the neighborhoods are close to the University of Toronto. So they are at the center of Toronto. So it means high cost high gain for a new business. Some of the neighborhoods are far away from the center.  \n\n\n- __Cluster 2 :__ 40% of neighborhoods are in this cluster. There are mostly business areas with cafe, restaurants, bar, etc.. The neighborhoods are a little bit far from the center of Toronto. So it means high cost, high gain for a new business \n\n- __Cluster 3 :__ There are generally restaurants, coffee shops, etc. The neighborhoods are near the center of Toronto.","765e3173":"Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood.","900278e8":"## 5. Results and Discussion <a name=\"results\"><\/a>","d465f568":"#### Put that into a pandas dataframe\n\nFirstly, write a function to sort the venues in descending order.","5ea96466":"### B. Load the coordinates from __\"Geospatial_Coordinates.csv\"__ file ","cb94cdf7":"## 6. Conclusion <a name=\"conclusion\"><\/a>\n","76dffa5b":"__Use geopy library to get the latitude and longitude values of Toronto for mapping.__","1648564c":"## 4. Analysis <a name=\"analysis\"><\/a>","ae5126c3":"## Table of contents\n* [1. Introduction: Business Problem](#introduction)\n* [2. Data Acquisition](#data)\n* [3. Methodology](#methodology)\n* [4. Analysis](#analysis)\n* [5. Results and Discussion](#results)\n* [6. Conclusion](#conclusion)","e10a5a52":"### Observations:\n\nMost of the interested neighborhoods according to our criteria are concentrated in Downtown Toronto.  ","22f243b3":"#### Cluster 3","a868a92b":"#### Visualize the Fried Chicken Restaurant  and other venues ","e4c414e3":"## 2. Data Acquisition <a name=\"data\"><\/a>","f55d1f87":"# The Battle of the Neighborhoods\n\n\n![Toronto](https:\/\/cdn.britannica.com\/93\/94493-050-35524FED\/Toronto.jpg)","c6c47898":"Let's look at the table :","59ac5881":"## Cluster Neighborhoods","96fbebde":"The purpose of this project was to identify Toronto areas close to center with normal number of restaurants and venues in order to aid my client in narrowing down the search for optimal location for a new Fried Chicken Restaurant. By seeing the density of restaurants and venues from Foursquare data we have identified the borouhgs that don't have a Fried Chicken Restaurant and also have a normal density of venues and restaurants. \n\n1. Regent Park, Harbourfront \n  \n   -  According to the criteria and results of this analysis, it seems as the best option.\n   -  The venues and restaurants density is not saturated.\n   -  There is not other chicken restaurant so close.\n   -  The neighborhood is close to the center of the city and other neighborhoods that don't have a fried chicken restaurant \n\n\n2. Kensington Market, Chinatown, Grange Park \n\n   - It may be the best option but there are two other fried chicken restaurants close by.   \n   - High cost, high gain for a new business\n\n\n3. Fairview, Henry Farm, Oriole \n\n   - Good place to start with a new business in a new country to see how it will work. \n   - Moderate cost, moderate risk.\n\nThe final decission on optimal restaurant location will be made by my client based on specific characteristics of neighborhoods and locations in every recommended zone, taking into consideration additional factors like attractiveness of each location (proximity to park or water), levels of noise \/ proximity to major roads, real estate availability, prices, social and economic dynamics of every neighborhood, etc.","16388696":"Finally, let's visualize the resulting clusters","78760ba0":"### Let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category","ef31e8c3":"#### Cluster 2","aed60d09":"### Analyze Each Neighborhood","f84f9c3b":"### Let's print each neighborhood along with the top 5 most common venues"}}