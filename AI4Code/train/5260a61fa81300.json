{"cell_type":{"9983bf4d":"code","8587e0fb":"code","7d427b8f":"code","0c658811":"code","5b49bd95":"code","2b12c72f":"code","2c85d15d":"code","0b3a3fdd":"code","b5578358":"code","13820de6":"code","96bb0406":"code","79e19fe9":"code","f6efedb8":"code","368196ca":"code","454158a1":"code","8f449454":"markdown","1b04fee5":"markdown","34c525b3":"markdown","92d813e5":"markdown","0d348e29":"markdown","326a2ad6":"markdown"},"source":{"9983bf4d":"%matplotlib inline","8587e0fb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Dropout, Softmax\nfrom tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.activations import relu\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","7d427b8f":"df_train = pd.read_json('..\/input\/train.json')\ndf_test = pd.read_json('..\/input\/test.json')","0c658811":"df_train.head()","5b49bd95":"df_test.head()","2b12c72f":"num_cuisines = df_train.cuisine.unique().shape[0]\nnum_cuisines","2c85d15d":"def tt_split(df_train, df_test, train_size):  \n    X = np.array(df_train.drop(['id', 'cuisine'], axis=1))\n    \n    cuisine_vector = [[c] for c in df_train.cuisine]\n    mlb = MultiLabelBinarizer()\n    y = mlb.fit_transform(cuisine_vector)\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=train_size)\n    return X_train, X_val, y_train, y_val, mlb\n\ndef vect_train_test(dftrain, dftest, n_words=1000, words=None, vect=None):\n    if vect == 'tfid':\n        vectorizer = TfidfVectorizer(max_features = n_words)\n    else:\n        vectorizer = CountVectorizer(max_features = n_words)\n    ingredients_train = dftrain.ingredients\n    words_train = [' '.join(x) for x in ingredients_train]\n    ingredients_test = dftest.ingredients\n    words_test = [' '.join(x) for x in ingredients_test]\n    if isinstance(words, pd.Series):\n        bag_of_words = vectorizer.fit(words)\n    else:\n        bag_of_words = vectorizer.fit(words_train)\n\n    ing_array_train = bag_of_words.transform(words_train).toarray()\n    ing_array_test = bag_of_words.transform(words_test).toarray()\n\n    df_ing_train = pd.DataFrame(ing_array_train, columns=vectorizer.vocabulary_)\n    df_ing_test = pd.DataFrame(ing_array_test, columns=vectorizer.vocabulary_)\n\n    df_train = dftrain.merge(df_ing_train, \n                          left_index=True, \n                          right_index=True).drop('ingredients', axis=1)\n    df_test= dftest.merge(df_ing_test, \n                          left_index=True, \n                          right_index=True).drop('ingredients', axis=1)\n    return df_train, df_test","0b3a3fdd":"max_ing = 1000\ndf_train_new, df_test_new = vect_train_test(df_train, df_test, n_words=max_ing)\nX_train, X_val, y_train, y_val, mlb = tt_split(df_train_new, df_test_new, 0.85)","b5578358":"# m = Sequential([\n#     Dense(500, input_dim=1000, activation='relu'),\n#     Dropout(0.15),\n#     Dense(250, input_dim=1000, activation='relu'),\n#     Dense(20, activation='softmax')\n# ])\n\n# m.compile(loss='categorical_crossentropy',\n#         metrics=['accuracy'],\n#               optimizer=Adam(lr=0.002))","13820de6":"# m.fit(\n#     X_train, y_train,\n#     epochs=5,\n#     verbose=1,\n#     validation_data=(X_val, y_val)\n# )","96bb0406":"# pred = m.predict(X_val)\n# plt.scatter(pred.argmax(axis=1), y_val.argmax(axis=1), alpha=0.005)","79e19fe9":"max_ing = 1000\ndf_train_new, df_test_new = vect_train_test(df_train, df_test, \n                                            n_words=max_ing, vect='tfid')\nX_train, X_val, y_train, y_val, mlb = tt_split(df_train_new, df_test_new, 0.85)","f6efedb8":"m = Sequential([\n    Dense(500, input_dim=1000, activation='relu'),\n    Dropout(0.15),\n    Dense(250, input_dim=1000, activation='relu'),\n    Dense(20, activation='softmax')\n])\n\nm.compile(loss='categorical_crossentropy',\n        metrics=['accuracy'],\n              optimizer=Adam(lr=0.002))\n\nm.fit(\n    X_train, y_train,\n    epochs=5,\n    verbose=1,\n    validation_data=(X_val, y_val)\n)","368196ca":"y_pred = m.predict(df_test_new.drop('id', axis=1))\ny_cat = mlb.classes_[y_pred.argmax(axis=1)]\ny_cat","454158a1":"df_sub = pd.DataFrame(np.array([df_test.id, y_cat]).T, \n                      columns=['id', 'cuisine']).set_index('id')\n\ndf_sub.to_csv('submission_nn.csv')","8f449454":"## Load data","1b04fee5":"## Generate submission","34c525b3":"## Helper functions","92d813e5":"## First model","0d348e29":"## Prepare","326a2ad6":"## Check if new vectorizer makes a difference..."}}