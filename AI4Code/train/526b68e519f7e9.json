{"cell_type":{"46c090e1":"code","421de74c":"code","a4e1ccdd":"code","51820ee6":"code","929c9b2c":"code","f3bb52bc":"code","46878520":"code","12450015":"code","270437e8":"code","21a334ab":"code","0490a96a":"code","4eb3d360":"code","0f96cb05":"code","54555c02":"code","6980d8c7":"code","541df329":"code","5501a375":"code","3eb136b5":"code","8dac514c":"code","23abdf80":"code","e9427b50":"code","4b5d0262":"markdown","daf470f3":"markdown","ff900fa1":"markdown","40a3ccd9":"markdown","92edaba8":"markdown","19bf18c4":"markdown","46e65d10":"markdown","3b323253":"markdown","b7b6d226":"markdown","06d76069":"markdown","1b570ae5":"markdown","791fa34f":"markdown","ef17c38c":"markdown","f1b7624c":"markdown"},"source":{"46c090e1":"#Importing all the neccesary libraries\nimport numpy as np \nimport pandas as pd \n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport regex as re\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer","421de74c":"data={'bio':pd.read_csv('..\/input\/biology.csv',index_col=0),\n      'robo':pd.read_csv('..\/input\/robotics.csv',index_col=0),\n      'cryp':pd.read_csv('..\/input\/crypto.csv',index_col=0),\n      'diy':pd.read_csv('..\/input\/diy.csv',index_col=0),\n      'cooking':pd.read_csv('..\/input\/cooking.csv',index_col=0),\n      'travel':pd.read_csv('..\/input\/travel.csv',index_col=0),\n      'test':pd.read_csv('..\/input\/test.csv',index_col=0),\n     }\ndata['robo']","a4e1ccdd":"stops = set(stopwords.words(\"english\"))","51820ee6":"def clean_content(table):\n    content = table.content\n    #Converting text to lowercase characters\n    content = content.apply(lambda x: x.lower())\n    #Removing HTML tags\n    content = content.apply(lambda x: re.sub(r'\\<[^<>]*\\>','',x))\n    #Removing any character which does not match to letter,digit or underscore\n    content = content.apply(lambda x: re.sub(r'^\\W+|\\W+$',' ',x))\n    #Removing space,newline,tab\n    content = content.apply(lambda x: re.sub(r'\\s',' ',x))\n    #Removing punctuation\n    content = content.apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n    #Tokenizing data\n    content = content.apply(lambda x: word_tokenize(x))\n    #Removing stopwords\n    content = content.apply(lambda x: [i for i in x if i not in stops])\n    return(content)","929c9b2c":"def clean_title(table):\n    title = table.title\n    title = title.apply(lambda x: x.lower())\n    title = title.apply(lambda x: re.sub(r'^\\W+|\\W+$',' ',x))\n    title = title.apply(lambda x: re.sub(r'\\s',' ',x))\n    title = title.apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n    title = title.apply(lambda x: word_tokenize(x))\n    title = title.apply(lambda x: [i for i in x if i not in stops])\n    return(title)","f3bb52bc":"for df in data:\n    data[df].content = clean_content(data[df])","46878520":"for df in data:\n    data[df].title = clean_title(data[df])","12450015":"data['robo']","270437e8":"text = ' '\nfor x in data['robo'].content:\n    for y in x:\n        text+=' '+y","21a334ab":"plt.figure(figsize=(8,10))\nwc = WordCloud(max_words=1000,random_state=1).generate(text)\nplt.imshow(wc)\nplt.show()","0490a96a":"cooking = ' '\nfor x in data['cooking'].title:\n    for y in x:\n        cooking+=' '+y","4eb3d360":"plt.figure(figsize=(8,10))\nwf = WordCloud(background_color='white',max_words=1000,random_state=1).generate(cooking)\nplt.imshow(wf)\nplt.show()","0f96cb05":"crypt = ' '\nfor i in data['cryp'].content:\n    for j in i:\n        crypt+=' '+j","54555c02":"plt.figure(figsize=(8,10))\nwg = WordCloud(background_color='black',max_words=1000,random_state=1).generate(crypt)\nplt.imshow(wg)\nplt.show()","6980d8c7":"wordnet = WordNetLemmatizer()\ndata['test'].title = data['test'].title.apply(lambda x:[wordnet.lemmatize(i,pos='v') for i in x])\ndata['test'].content = data['test'].content.apply(lambda x:[wordnet.lemmatize(i,pos='v') for i in x])","541df329":"tst = ' '\nfor i in data['test'].title:\n    for j in i:\n        tst+=' '+j     ","5501a375":"plt.figure(figsize=(8,10))\nphy = WordCloud(background_color='white',max_words=1000,random_state=1).generate(tst)\nplt.imshow(phy)\nplt.show()","3eb136b5":"def identity_tokenizer(text):\n  return text\nvect = TfidfVectorizer(tokenizer=identity_tokenizer,lowercase=False)\nx = vect.fit_transform(data['test'].title.values)","8dac514c":"indices = np.argsort(vect.idf_)[::-1]\nfeatures = vect.get_feature_names()\ntop_n = 50\ntop_features = [features[i] for i in indices[:top_n]]\ntop_features","23abdf80":"from sklearn.cluster import KMeans\nmodel = KMeans(n_clusters=20, init='k-means++', max_iter=100, n_init=1)\nmodel.fit(x)","e9427b50":"print(\"Top terms per cluster:\")\norder_centroids = model.cluster_centers_.argsort()[:, ::-1]\nterms = vect.get_feature_names()\nfor i in range(20):\n    print (\"Cluster %d:\" % i,)\n    for ind in order_centroids[i, :10]:\n        print (' %s' % terms[ind],)\n    ","4b5d0262":"Doing the cleaning process on title as well","daf470f3":"Hi there! This is my first kernel dealing with textual data so any constructive feedabacks are higly appreciated.\n\nThis dataset contains data of over 7 topics namely biology, robotics, cryptography, diy, travel, cooking, robotics and physics extracted from Stack Exchange. Each of these topics except physics have been classified as to which topic data belongs. So our task is to do predictions on unseen physics questions.\n\nSince our data won't be related to each other for example tags in travel won't be related to tags in cryptography hence I will be using unsupervised learning on physics dataset which is the test dataset. ","ff900fa1":" Visualizing our cleaned robo data using WordCloud","40a3ccd9":"WordCloud for cooking data","92edaba8":"**k-means clustering**\n\nIn general, k-means is the first choice for clustering because of its simplicity. Here, the user has to define the number of clusters (Post on how to decide the number of clusters would be dealt later). The clusters are formed based on the closeness to the center value of the clusters. The initial center value is chosen randomly. K-means clustering is top-down approach, in the sense, we decide the number of clusters (k) and then group the data points into k clusters.","19bf18c4":"Making dictionary to put all the data in the same hood.","46e65d10":"**Text data preprocessing steps**\n\n1- Data Cleaning(either using regex or BeautifulSoup): \na) Removing HTML characters. \nb) Removing punctuation. \nc) Decoding encoded data.\nd) Split attached words.\ne) Removing URLs. \nf) Apostrophe removal.\ng) Removing Expressions. \nh) Uppercase & Lowercase letters \ni) Numbers such as amounts and data.\n\n2- Data Tokenization(using word_tokenize in nltk.tokenize) \nSegregation of text into individual words i.e tokens.\n\n3- Stopword Removal(using stopwords in nltk.corpus)\nDiscarding too common words or words which are not going to be helpful in our analysis.\n\n4- Stemming(using WordNetLemmatizer in nltk.stem) \nCombining different variants of words into a single parent word that conveys same meaning.\n\n5-Vectorization (either using TfidVectorizer or Countvectorizer in sklearn.feature_extraction.text or word embeddings) Changing text data into vector format.\n","3b323253":"Vectrorizing data using TfidVectrorizer which uses the concept of term frequency and inverse document frequency to get rid of all non-consequential tokens from being vectorized.\nFor more details see https:\/\/www.quora.com\/How-does-TfidfVectorizer-work-in-laymans-terms","b7b6d226":"Applying operations on data","06d76069":"WordCloud for physics dataset","1b570ae5":"**Stemming ** ","791fa34f":"WordCloud for cryptography","ef17c38c":"So from the output we can infer following points:\n\nCluster 1 classifies text related to 'angular momentum', 'torque' which can be associated to 'motor'\n\nCluster 2 is related to 'visible light source' \n\nCluster 3 deal with 'kinetic' and ' potential' energy which can be used to explain 'energy conservation'\n\nCluster 4 possibly relates to 'physics equations'\n\nCluster 10 has term like 'singularity' which is related to 'black hole'\n\nSimilarly we can draw other conclusions too.\n\nAny feedbacks to improve it further are appreciated.\n\nThank you!","f1b7624c":"Finally let's see how our test data look likes"}}