{"cell_type":{"de776580":"code","aeffd585":"code","60a349a0":"code","28844372":"code","147c5926":"code","f36f50a3":"code","2da97f16":"code","a7119ae3":"code","eab533ca":"code","332debbd":"code","60666d72":"code","3abdff92":"code","6cb82630":"code","4fc653d1":"code","a877cb3c":"code","ee2ab3bc":"code","056ba514":"code","e3cbb8f1":"code","501566e3":"code","5271924b":"code","48752bca":"code","bc576c8c":"markdown","25c8383a":"markdown","8a7b4cd0":"markdown","26e7eaf6":"markdown"},"source":{"de776580":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aeffd585":"!pip install TPOT","60a349a0":"from tpot import TPOTRegressor","28844372":"df = pd.read_csv('\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv')","147c5926":"df.describe()","f36f50a3":"def weird_division(n, d):\n    return n \/ d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)","2da97f16":"df = df[df.CPM>=0].reset_index(drop=True)\ndf = df[df['CPM']<df['CPM'].quantile(0.95)].reset_index(drop=True)\ntest = df[pd.to_datetime(df.date) >= pd.to_datetime('2019-06-22')].reset_index(drop=True)\ntrain = df[pd.to_datetime(df.date) < pd.to_datetime('2019-06-22')].reset_index(drop=True)","a7119ae3":"cols_to_drop = ['date', 'total_revenue', 'measurable_impressions', 'viewable_impressions', 'revenue_share_percent', 'total_impressions']\ntrain.drop(cols_to_drop, axis=1, inplace=True)\ntest.drop(cols_to_drop, axis=1, inplace=True)","eab533ca":"# Extract features and labels\ntrain_y = train['CPM']\ntrain_X = train.drop('CPM', axis = 1)\n\n# Training and Testing Sets\ntest_X = test.drop('CPM', axis = 1)\ntest_y = test['CPM']\n\ntrain_X = np.array(train_X)\ntest_X = np.array(test_X)\ntrain_y = np.array(train_y)\ntest_y = np.array(test_y)\n\ntrain_X.shape, test_X.shape","332debbd":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, mean_squared_error \nfrom sklearn import linear_model\n\nlasso_model = linear_model.Lasso()\ncv_res = cross_val_score(lasso_model, train_X, train_y,\n                          scoring=make_scorer(mean_squared_error), cv=10);\ncv_res","60666d72":"lasso_model.fit(train_X, train_y)","3abdff92":"predictions_lasso = lasso_model.predict(test_X)\nprint(\"MSE equal to: \", mean_squared_error(predictions_lasso, test_y))","6cb82630":"from catboost import CatBoostRegressor\ncatboost_model = CatBoostRegressor(iterations=1000,\n                          learning_rate=0.5,\n                          depth=6,\n                          l2_leaf_reg=3,\n                          loss_function='RMSE')","4fc653d1":"catboost_model.fit(train_X, train_y)","a877cb3c":"predictions = catboost_model.predict(test_X)\nprint(\"MSE equal to: \", mean_squared_error(predictions, test_y))","ee2ab3bc":"from sklearn.model_selection import train_test_split, KFold, cross_val_score # to split the data\nfrom sklearn.metrics import explained_variance_score, median_absolute_error, r2_score, mean_squared_error #To evaluate our model\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split # Model evaluation\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler # Preprocessing\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge # Linear models\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor  # Ensemble methods\nfrom xgboost import XGBRegressor, plot_importance # XGBoost\nfrom sklearn.svm import SVR, SVC, LinearSVC  # Support Vector Regression\nfrom sklearn.tree import DecisionTreeRegressor # Decision Tree Regression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline # Streaming pipelines\nfrom sklearn.decomposition import KernelPCA, PCA # Dimensionality reduction\nfrom sklearn.feature_selection import SelectFromModel # Dimensionality reduction\nfrom sklearn.model_selection import learning_curve, validation_curve, GridSearchCV # Model evaluation\nfrom sklearn.base import clone # Clone estimator\nfrom sklearn.metrics import mean_squared_error as MSE","056ba514":"tpot_config = {\n    'sklearn.ensemble.GradientBoostingRegressor': {\n        ''\n    },\n    'xgboost.XGBRegressor': {\n        'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n        'fit_prior': [True, False]\n    },\n    'sklearn.naive_bayes.MultinomialNB': {\n        'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n        'fit_prior': [True, False]\n    }\n}","e3cbb8f1":"tpot = TPOTRegressor(verbosity=2, scoring='neg_mean_squared_error', cv=3, \n                      n_jobs=-1, generations=6, config_dict='TPOT light',\n                      population_size=50, random_state=3,\n                      early_stop = 5)","501566e3":"tpot.fit(train_X, train_y)","5271924b":"predictions_tpot = tpot.predict(test_X)\nprint(\"MSE equal to: \", mean_squared_error(predictions_tpot, test_y))","48752bca":"res = pd.DataFrame({'model':['Lasso', 'TPOT', 'CatBoost'], 'Value':[7902.471763714017, 3659.890475848824, 3185.3504729663064]})\nax = res.plot.bar(x='model', y='Value', rot=0)","bc576c8c":"## Boosting","25c8383a":"# Final results","8a7b4cd0":"## Linear Model","26e7eaf6":"## AutoML (TPOT)"}}