{"cell_type":{"e541d614":"code","1d66ddb5":"code","b1781d97":"code","626a2005":"code","64b5e8cf":"code","edd61941":"code","cbb2e9eb":"code","395d20d0":"code","492cc1de":"code","1d812f88":"markdown","17a58f36":"markdown","e43d2b42":"markdown","4707f2d6":"markdown","3c60d494":"markdown","5d445ab3":"markdown","fa03c666":"markdown","742e4d47":"markdown","4d5ba10b":"markdown"},"source":{"e541d614":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDClassifier, Ridge\nfrom sklearn.pipeline import Pipeline","1d66ddb5":"df_train = pd.read_csv('..\/input\/titanic\/train.csv').drop('Name', axis=1)\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv').drop('Name', axis=1)\n\ndf_train['female'] = pd.get_dummies(df_train['Sex'])['female']\ndf_test['female'] = pd.get_dummies(df_test['Sex'])['female']\n\nprint(\"Overall:\")\nprint(df_train.drop('Survived', axis=1).drop('PassengerId', axis=1).describe())\n\nprint(\"\\nSurvived:\")\nsurvived = df_train[df_train['Survived'] == 1].drop('Survived', axis = 1).drop('PassengerId', axis=1)\nprint(survived.describe())","b1781d97":"print('\\nCorrelation between Age and Survival: ' + str(df_train['Age'].corr(df_train['Survived'])))\nprint('Correlation between Pclass and Survival: ' + str(df_train['Pclass'].corr(df_train['Survived'])))\nprint('Correlation between Ticket Cost and Survival: ' + str(df_train['Fare'].corr(df_train['Survived'])))\nprint('Correlation between # family members and Survival: ' + str((df_train['Parch'] + df_train['SibSp']).corr(df_train['Survived'])))\n\ndf_train['Age_group'] = [5 * round(age \/ 5) if not np.isnan(age) else np.NaN for age in df_train['Age']]\ndf_train['fare_group'] = [30 * round(cost \/ 30) if not np.isnan(cost) else np.NaN for cost in df_train['Fare']]\n\nprint('Correlation between Sex and Survival: ' + str(df_train['female'].corr(df_train['Survived'])))\n\nsns.barplot(x='Age_group', y='Survived', data=df_train)\nplt.show()\n\nsns.barplot(x='Pclass', y='Survived', data=df_train)\nplt.show()\n\nsns.barplot(x='fare_group', y='Survived', data=df_train)\nplt.show()","626a2005":"df_train = df_train.fillna({'Age': np.mean(df_train['Age'])})\ndf_test = df_test.fillna({'Age': np.mean(df_test['Age'])})\n\ndf_clean = df_train.dropna(subset=['female', 'Pclass', 'Fare', 'Age', 'Parch'])\ndf_submission = df_test.dropna(subset=['female', 'Pclass', 'Fare', 'Age', 'Parch'])\n\nX = df_clean[['female', 'Pclass', 'Fare', 'Age', 'Parch']]\ny = df_clean['Survived']\n\nX_sub = df_submission[['female', 'Pclass', 'Fare', 'Age', 'Parch']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)","64b5e8cf":"knn_params = {'n_neighbors': [1,2,3,4,5,6,7]}\nknn_cv = GridSearchCV(KNeighborsClassifier(), knn_params, cv = 5)\nknn_cv.fit(X_train, y_train)\n\nknn_score = knn_cv.score(X_test, y_test)\nknn_pred = knn_cv.predict(X_sub)\nprint(knn_score)","edd61941":"rf_params = {'max_depth': [2, 5, 10, 20]}\nrf_cv = GridSearchCV(RandomForestClassifier(), rf_params, cv = 5)\nrf_cv.fit(X_train, y_train)\n\nrf_score = rf_cv.score(X_test, y_test)\nrf_pred = rf_cv.predict(X_sub)\nprint(rf_score)","cbb2e9eb":"sgd_params = {'SGDClassifier__max_iter': [100, 1000, 10000, 15000]}\npipeline = Pipeline([('Scaler', StandardScaler()), (\"SGDClassifier\", SGDClassifier())])\n\nsgd_cv = GridSearchCV(pipeline, sgd_params, cv = 5)\n\nsgd_cv.fit(X_train, y_train)\nsgd_score = sgd_cv.score(X_test, y_test)\nsgd_pred = sgd_cv.predict(X_sub)\nprint(sgd_score)","395d20d0":"ridge = Ridge(alpha=1)\nridge.fit(X_train, y_train)\nridge_score = ridge.score(X_test, y_test)\nprint(ridge_score)","492cc1de":"submission_df = pd.DataFrame()\nsubmission_df['PassengerId'] = df_submission['PassengerId']\n\nif knn_score > rf_score and knn_score > sgd_score:\n    submission_df['Survived'] = knn_pred\n    print(\"KNearestNeighbors is the best predictor: \" + str(knn_score))\nelif rf_score > knn_score and rf_score > sgd_score:\n    submission_df['Survived'] = rf_pred\n    print(\"RandomForest is the best predictor: \" + str(rf_score))\nelse:\n    submission_df['Survived'] = sgd_pred\n    print(\"Gradient Descent is the best predictor: \" + str(sgd_pred))\n\n# Assume 0s for rows missing values which really tanks the accuracy but it's still good enough\nfor i in df_test['PassengerId']:\n    if not i in submission_df['PassengerId'].unique():\n        submission_df = submission_df.append({\"PassengerId\": i, \"Survived\": 0}, ignore_index=True)\n    \nsubmission_df.to_csv(\"submission.csv\", index=False)","1d812f88":"# Find best predictor and create submission\n### This doesn't need to reshape much but there's a single value without a fare in the test data and to keep this general I'm leaving the reshaping code ","17a58f36":"# SGD Classifier:\n### 5 fold CV while searching for best n_iters and attempting to use a Pipeline","e43d2b42":"# Exploratory Data Analysis (EDA)\n\n### See the columns of the data and some basic stats about them\n#### Compare the statistics of those who survived with the overall data\n#### Also some feature engineering by getting dummy variables for Sex","4707f2d6":"# CAP4611 Assignment #0\n### Using multiple different models and experimenting with hyper parameters to find the best model for the Titanic dataset\n\n### Import necessary libraries","3c60d494":"# Descision Trees:\n### 5 fold CV while randomly searching for best depth","5d445ab3":"#### It still seems like our best bet at predicting is by using Sex, Pclass, and ticket price. \n#### In our classifiers, we will use Sex, Pclass, and ticket price and experiement with age and Parch since some age groups seem more likely to survive and there might be a difference in survival for parents\/children according to the test statistics\n#### Replace unknown ages with the mean and clean data","fa03c666":"# Linear Regression:\n### This won't be accurate at all but its required. Google seems to say Ridge linear regression would be best for few features","742e4d47":"#### Those who survived are higher class on average, are more likely to be women, have a higher fare cost and range of fare costs. The age statistics between the 2 groups don't seem very different. Those either parents or children had a batter chance at survival\n\n#### Test the linear correlation between different columns and see for other types of trends in plots of data","4d5ba10b":"#### Using age increases our accuracy\n# KNearestNeighbors Classifier:\n### 5 fold cross validation while searching for the best n_neighbors"}}