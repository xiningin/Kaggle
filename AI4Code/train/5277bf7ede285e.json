{"cell_type":{"a7458044":"code","0987870a":"code","edb4052b":"code","e15c7e8d":"code","572513ca":"code","66346dae":"code","4c8a6868":"code","fd41a240":"code","ceacc7d9":"code","680a523e":"code","20208d39":"code","e1bac3ba":"markdown","2498af93":"markdown","1b641803":"markdown","a70eff67":"markdown","1412503b":"markdown","5c8943f6":"markdown","02cf8b62":"markdown","0606ab9a":"markdown"},"source":{"a7458044":"# package install\n!pip3 install keras-retinanet keras-maskrcnn\n\n# zip install\n!apt-get install zip\n\n# pretrained model download\n!mkdir model 2>\/dev\/null && cd model && wget https:\/\/github.com\/fizyr\/keras-maskrcnn\/releases\/download\/0.2.2\/resnet50_coco_v0.2.0.h5\n!ls -al model\/","0987870a":"# import keras\nimport keras\n\n# import keras_retinanet\nfrom keras_maskrcnn import models\nfrom keras_maskrcnn.utils.visualization import draw_mask\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption, draw_annotations\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.colors import label_color\n\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nimport PIL\nfrom PIL import Image, ImageDraw\nfrom skimage import color as skcolor\n\n# set tf backend to allow memory to grow, instead of claiming everything\nimport tensorflow as tf\n\ndef get_session():\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    return tf.Session(config=config)\n\n# use this environment flag to change which GPU to use\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\n# set the modified tf session as backend in keras\nkeras.backend.tensorflow_backend.set_session(get_session())","edb4052b":"# MaskRcnn Model Load\nrcnn_model_path = '.\/model\/resnet50_coco_v0.2.0.h5'\nrcnn_model = models.load_model(rcnn_model_path, backbone_name='resnet50')\nrcnn_model.trainable = False\n#print(rcnn_model.summary())\n\n# load label to names mapping\nrcnn_labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}","e15c7e8d":"# DataSet \uacbd\ub85c\nDATA_PATH = '..\/input\/'\n\n# \uc774\ubbf8\uc9c0 \ud3f4\ub354 \uacbd\ub85c\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\n# \uc791\uc5c5 \ud3f4\ub354\nTRAIN_CROP_PATH = \".\/train_segcrop\"\nTEST_CROP_PATH = \".\/test_segcrop\"\n\nfor dir in [TRAIN_CROP_PATH, TEST_CROP_PATH]:\n    if not os.path.exists(dir) :\n        os.mkdir(dir)\n    print(dir)\n\n# CSV \ud30c\uc77c\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))","572513ca":"# CSV \ud30c\uc77c \ud655\uc778\ndisplay(df_train.describe())\ndisplay(df_test.describe())","66346dae":"sample_index = 2999\ndf_bbox = df_train[sample_index:sample_index+1]\nprint(df_bbox)\nf_name = df_train['img_file'][sample_index]\n\nplt.figure(figsize=(9,12))\nplt.axis('off')\nimage = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name))\nplt.imshow(image)\nplt.show()\n\norg_bbox = df_bbox[['bbox_x1','bbox_y1','bbox_x2','bbox_y2']].values.reshape(-1)\nprint(org_bbox)","4c8a6868":"def bbox_iou(boxA, boxB):\n    # determine the (x, y)-coordinates of the intersection rectangle\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n \n    # compute the area of intersection rectangle\n    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n \n    # compute the area of both the prediction and ground-truth\n    # rectangles\n    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n \n    # compute the intersection over union by taking the intersection\n    # area and dividing it by the sum of prediction + ground-truth\n    # areas - the interesection area\n    iou = interArea \/ float(boxAArea + boxBArea - interArea)\n \n    # return the intersection over union value\n    return iou\n\nimport sys\ndef print2(string):\n    os.system(f'echo \\\"{string}\\\"')\n    print(string)","fd41a240":"# copy to draw on\nimage = read_image_bgr(os.path.join(TRAIN_IMG_PATH, f_name))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\ndraw_original = image.copy()\ndraw_singleboxed = image.copy()\ndraw_boxed = image.copy()\ndraw_shaped = image.copy()\n\ndraw_singlemask = image.copy()\ndraw_singlemask.fill(0)\n\n# preprocess image for network\nimage = preprocess_image(image)\nimage, scale = resize_image(image)\n\n# process image\nstart = time.time()\noutputs = rcnn_model.predict_on_batch(np.expand_dims(image, axis=0))\nprint(\"processing time: \", time.time() - start)\n\nboxes  = outputs[-4][0]\nscores = outputs[-3][0]\nlabels = outputs[-2][0]\nmasks  = outputs[-1][0]\n\n# correct for image scale\nboxes \/= scale\n\nb0 = org_bbox.astype(int)\ndraw_box(draw_singleboxed, b0, color=[255,0,0])\nprint(\"org bbox = \", b0)\n\n# visualize detections\nmax_iou = -1\nmax_iou_box = None\nmax_iou_score = None\nmax_iou_label = None\nmax_iou_mask = None\n\nfor box, score, label, mask in zip(boxes, scores, labels, masks):\n    if score < 0.5:\n        break\n\n    color = label_color(label)\n    \n    b = box.astype(int)\n    print(\"bbox = \", b)\n    draw_box(draw_boxed, b, color=color)\n    \n    mask2 = mask[:, :, label]\n    draw_mask(draw_shaped, b, mask2, color=label_color(label))\n\n    tmp_iou = bbox_iou(b0, b)\n    if (tmp_iou > max_iou):\n        max_iou = tmp_iou\n        max_iou_box = b\n        max_iou_score = score\n        max_iou_label = label\n        max_iou_mask = mask2\n    \nprint(\"max_iou = \", max_iou)\ndraw_mask(draw_singlemask, max_iou_box, max_iou_mask, color=[255,255,255])\n   \n    \nfig, (ax1,ax2, ax3) = plt.subplots(1,3)\nfig.set_size_inches(18,12)\nax1.axis('off')\nax1.imshow(draw_original)\nax2.axis('off')\nax2.imshow(draw_boxed)\nax3.axis('off')\nax3.imshow(draw_shaped)\nplt.show()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3)\nfig.set_size_inches(18,12)\nax1.axis('off')\nax1.imshow(draw_singleboxed)\n\ndraw_singlemask=np.where(draw_singlemask>1,255,0)\nax2.axis('off')\nax2.imshow(draw_singlemask)\n\nmasked_image = draw_original & draw_singlemask\narr_masked_image = Image.fromarray(masked_image.astype(np.uint8))\nfinal_image = arr_masked_image.crop(box=tuple(max_iou_box))\n\nax3.axis('off')\nax3.imshow(masked_image)\nplt.show()\n\nplt.imshow(final_image)\nplt.show()","ceacc7d9":"for (in_path, out_path, df) in [(TRAIN_IMG_PATH, TRAIN_CROP_PATH, df_train), (TEST_IMG_PATH, TEST_CROP_PATH, df_test)]:\n  cnt = df['img_file'].count()\n  print(\"#path={} count={}\".format(out_path, cnt))\n  for idx in range(0, cnt):\n    #\uc624\ub798\uac78\ub9ac\ubbc0\ub85c 10\uac1c\ub9cc \ucc98\ub9ac\ud568(\uc804\uccb4 \ucc98\ub9ac\uc2dc\uc5d0\ub294 \uc544\ub798\ubd80\ubd84 \uc81c\uac70\ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4.)\n    if idx>=10:\n        break;\n        \n    #\uc5d0\ub7ec\ub098\ub294\uac70 \ube7c\uace0\ub294 \ub2e4 \ub3cc\uc544\uac00\uc57c \ud55c\ub2e4.\n    try:\n\n        starttime = time.time()\n\n        df_row = df[idx:idx+1]\n        org_file_name = df_row['img_file'][idx]\n        #print(\"#{}\".format(org_file_name))\n        org_bbox = df_row[['bbox_x1','bbox_y1','bbox_x2','bbox_y2']].values.reshape(-1)\n        b0 = org_bbox.astype(int)\n\n        # copy to draw on\n        image = read_image_bgr(os.path.join(in_path, org_file_name))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        ctx_original = image.copy()\n        ctx_mask = image.copy()\n        ctx_mask.fill(0)\n\n        # preprocess image for network\n        image = preprocess_image(image)\n        image, scale = resize_image(image)\n\n        # process image\n        startpredict = time.time()\n        outputs = rcnn_model.predict_on_batch(np.expand_dims(image, axis=0))\n        #print(\"predict time: \", time.time() - startpredict)\n\n        boxes  = outputs[-4][0]\n        scores = outputs[-3][0]\n        labels = outputs[-2][0]\n        masks  = outputs[-1][0]\n\n        # correct for image scale\n        boxes \/= scale\n\n        # lookup best detections\n        max_iou = -1\n        max_iou_box = None\n        max_iou_score = None\n        max_iou_label = None\n        max_iou_mask = None\n\n\n        for box, score, label, mask in zip(boxes, scores, labels, masks):\n            b = box.astype(int)\n            mask = mask[:, :, label]\n\n            # lookup max iou bbox\n            tmp_iou = bbox_iou(b0, b)\n            if (tmp_iou > max_iou):\n              max_iou = tmp_iou\n              max_iou_box = b\n              max_iou_score = score\n              max_iou_label = label\n              max_iou_mask = mask\n\n        # bbox overflow adjust\n        max_iou_box = np.where(max_iou_box<0, 0, max_iou_box)\n        if (max_iou_box[0] > ctx_mask.shape[1]) :\n            max_iou_box[0] = ctx_mask.shape[1]\n        if (max_iou_box[2] > ctx_mask.shape[1]) :\n            max_iou_box[2] = ctx_mask.shape[1]\n        if (max_iou_box[1] > ctx_mask.shape[0]) :\n            max_iou_box[1] = ctx_mask.shape[0]\n        if (max_iou_box[3] > ctx_mask.shape[0]) :\n            max_iou_box[3] = ctx_mask.shape[0]\n            \n        # create mask and crop \n        draw_mask(ctx_mask, max_iou_box, max_iou_mask, color=[255,255,255])    \n        ctx_mask=np.where(ctx_mask>1,255,0)\n\n        # create masked and crop \n        ctx_masked = ctx_original & ctx_mask\n        cropped_image = Image.fromarray(ctx_masked.astype(np.uint8)).crop(box=tuple(org_bbox))\n\n        cropped_image.save(os.path.join(out_path, org_file_name) )\n\n        print2(\"#{} => elapsed:{}s\".format(org_file_name, round(time.time() - starttime,2)))\n    except KeyboardInterrupt:\n        print(\"Stopped\")\n        sys.exit()\n    except:\n        print2(\"#{} => FAIL!\".format(org_file_name))\n        print2(sys.exc_info()[0])\n    #break;\n  #break;\n","680a523e":"tmp_imgs = df_train['img_file'][0:5]\ntmp_imgs2 = df_test['img_file'][0:5]\nplt.figure(figsize=(16,16))\n\nfor num, f_name in enumerate(tmp_imgs):\n    img = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name))\n    plt.subplot(5, 4, 4*num + 1)\n    plt.title(f_name)\n    plt.imshow(img)\n    plt.axis('off')\n    \n    img_crop = PIL.Image.open(os.path.join(TRAIN_CROP_PATH, f_name))\n    plt.subplot(5, 4, 4*num + 2)\n    plt.title(f_name + ' cropped')\n    plt.imshow(img_crop)\n    plt.axis('off')\n    \nfor num, f_name in enumerate(tmp_imgs2):\n    img = PIL.Image.open(os.path.join(TEST_IMG_PATH, f_name))\n    plt.subplot(5, 4, 4*num + 3)\n    plt.title(f_name)\n    plt.imshow(img)\n    plt.axis('off')\n\n    img_crop = PIL.Image.open(os.path.join(TEST_CROP_PATH, f_name))\n    plt.subplot(5, 4, 4*num + 4)\n    plt.title(f_name + ' cropped')\n    plt.imshow(img_crop)\n    plt.axis('off')\n    ","20208d39":"!rm -rf model \n!cd train_segcrop;zip ..\/train_segcrop.zip *.jpg > \/dev\/null\n!rm -rf train_segcrop\n!cd test_segcrop;zip ..\/test_segcrop.zip *.jpg > \/dev\/null\n!rm -rf test_segcrop","e1bac3ba":"## Working Path & Data Check","2498af93":"# Car Image Segmentation Crop\n\n3\ucc28 \ub300\ud68c\ub294 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ucc28\uc885\uc744 \uc608\uce21\ud558\ub294 \ubb38\uc81c\uc785\ub2c8\ub2e4.<br>\n\uc81c\uacf5\ub41c \ub370\uc774\ud130\uc5d0 bounding box\uc704\uce58\uac00 \uc8fc\uc5b4\uc838 \uc788\uc73c\ubbc0\ub85c \uc774\ub97c \uc774\uc6a9\ud574 crop\ud558\uc5ec \uc0ac\uc6a9\ud560\uc218 \uc788\uc9c0\ub9cc,<br>\n\ubc15\uc2a4\uc548\uc5d0\ub294 \ub2e4\ub978 \ucc28\ub098 \ubc30\uacbd, \uc0ac\ub78c\ub4f1\uc758 \uc694\uc18c\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uae30\ub3c4 \ud569\ub2c8\ub2e4.<br>\n\ub530\ub77c\uc11c \ubc15\uc2a4\uc548\uc5d0 \uc788\ub294 \ucc28\ub97c \uc81c\uc678\ud55c \ub098\uba38\uc9c0 \ubd80\ubd84\uc744 \ubaa8\ub450 \uc798\ub77c\ub0b4\uba74 \uc131\ub2a5\uc774 \ub192\uc544\uc9c8 \uac83 \uac19\uc2b5\ub2c8\ub2e4. <br>\nMaskRCNN\uc744 \uc774\uc6a9\ud558\uc5ec segmentation\/crop\uc744 \ucc98\ub9ac\ud558\ub294 \ucee4\ub110\uc744 \uc791\uc131\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.<br>\n\n*\ucc38\uace0\uc790\ub8cc<br>\nhttps:\/\/www.kaggle.com\/fulrose\/3rd-ml-month-car-model-classification-baseline <br>\nhttps:\/\/www.kaggle.com\/tmheo74\/3rd-ml-month-car-image-cropping-updated-7-10 <br>\nhttps:\/\/github.com\/fizyr\/keras-maskrcnn<br>","1b641803":"# Sample Image Processing","a70eff67":"## Compress and remove files","1412503b":"# Common Task\n## Package Install\/Load","5c8943f6":"# Result Check","02cf8b62":"# Batch Image Processing ","0606ab9a":"## MaskRcnn Model Load"}}