{"cell_type":{"8fc63195":"code","ef7dfee5":"code","cb471c54":"code","965cd197":"code","4ca304df":"code","999b9fce":"code","900b4697":"code","32105c08":"code","58824b5a":"code","062bada9":"code","c6646ac3":"code","61e11c4e":"code","ec0e28b2":"code","c01e25d5":"code","60c674fd":"code","3ce406c7":"code","26fef2e2":"code","8e408516":"code","c9d1a408":"code","13243a1c":"code","27001cac":"code","fbec6788":"code","506f57eb":"code","3b9ab1dc":"code","6525676b":"code","a2038eae":"code","4175c2c4":"code","675b7058":"code","354c7021":"code","c0a6682d":"code","fe4c78fd":"code","d2b69909":"code","2ce2b55e":"code","407b4ec9":"code","19344720":"code","bf5e3c87":"code","70e9ffa8":"code","d6b37759":"code","c696fb91":"code","41d86ff2":"code","25116b5a":"markdown","e80e1758":"markdown","3e0b0c26":"markdown","666e69bd":"markdown","b33d95b3":"markdown","3364b98d":"markdown","34ac8a5d":"markdown","fd355be7":"markdown","2a6565e7":"markdown","07667f20":"markdown","ab86d53f":"markdown","ce7a238e":"markdown","8aa09d37":"markdown","061cd51a":"markdown","e31c6117":"markdown","e0e6d499":"markdown","5d3ed06e":"markdown"},"source":{"8fc63195":"import pandas as pd                                                  # to import csv and for data manipulation\nimport matplotlib.pyplot as plt                                      # to plot graph\nimport seaborn as sns                                                # for intractve graphs\nimport numpy as np                                                   # for linear algebra\nimport datetime                                                      # to deal with date and time\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler                     # for preprocessing the data\nfrom sklearn.ensemble import RandomForestClassifier                  # Random forest classifier\nfrom sklearn.tree import DecisionTreeClassifier                      # for Decision Tree classifier\nfrom sklearn.svm import SVC                                          # for SVM classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.model_selection import GridSearchCV                     # for tunnig hyper parameter it will use all combination of given parameters\nfrom sklearn.model_selection import RandomizedSearchCV               # same for tunning hyper parameter but will use random combinations of parameters\nfrom sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.utils import resample\n","ef7dfee5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cb471c54":"train_df = pd.read_csv('\/kaggle\/input\/airplane-accidents-severity-dataset\/train.csv')\ntrain_df.head()","965cd197":"test_df = pd.read_csv('\/kaggle\/input\/airplane-accidents-severity-dataset\/test.csv')\ntest_df.head()","4ca304df":"sub_df = pd.read_csv('\/kaggle\/input\/airplane-accidents-severity-dataset\/sample_submission.csv')\nsub_df.head()","999b9fce":"print(train_df['Severity'].nunique())\nprint(train_df['Severity'].unique())","900b4697":"print(\"The total number of Rows in Train dataset is : \", train_df.shape[0])\nprint(\"The total number of Rows in Test dataset is : \", test_df.shape[0])\nprint(\"The total number of Rows in both Train and Test dataset is : \", train_df.shape[0]+test_df.shape[0])","32105c08":"train_df.keys()","58824b5a":"train_df.columns","062bada9":"test_df.columns","c6646ac3":"train_df.dtypes","61e11c4e":"train_df['Severity'].value_counts()","ec0e28b2":"# Normalise can be set to true to print the proportions instead of Numbers.\ntrain_df['Severity'].value_counts(normalize=True)","c01e25d5":"train_df['Severity'].value_counts().plot.bar(figsize=(4,4),title='Severity - Split for Train Dataset')\nplt.xlabel('Severity')\nplt.ylabel('Count')","60c674fd":"train_df.columns","3ce406c7":"plt.figure(1)\nplt.subplot(121)\ntrain_df['Accident_Type_Code'].value_counts(normalize=True).plot.bar(figsize=(24,6), fontsize = 15.0)\nplt.title('Accident_Type_Code', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\nplt.subplot(122)\ntrain_df['Violations'].value_counts(normalize=True).plot.bar(figsize=(24,6), fontsize = 15.0)\nplt.title('Violations', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)","26fef2e2":"cols = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints', 'Control_Metric']\nfor col in cols:    \n    plt.figure(1)\n    plt.subplot(121)\n    sns.distplot(train_df[col])\n\n    plt.subplot(122)\n    train_df[col].plot.box(figsize=(16,5))\n\n    plt.show()","8e408516":"cols = ['Turbulence_In_gforces',\n       'Cabin_Temperature',  'Max_Elevation',\n        'Adverse_Weather_Metric']\nfor col in cols:    \n    plt.figure(1)\n    plt.subplot(121)\n    sns.distplot(train_df[col])\n\n    plt.subplot(122)\n    train_df[col].plot.box(figsize=(16,5))\n\n    plt.show()","c9d1a408":"# Correlation between numerical variables\nnum_cols_data = (train_df[['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n                        'Control_Metric', 'Turbulence_In_gforces',\n                       'Cabin_Temperature',  'Max_Elevation',\n                        'Adverse_Weather_Metric'                       \n                       ]])\nmatrix = num_cols_data.corr()\nf, ax = plt.subplots(figsize=(20, 10))\nsns.heatmap(matrix, vmax=.8, square=True, cmap=\"BuPu\");","13243a1c":"num_cols_data.describe()","27001cac":"# Check missing values\ntrain_df.isnull().sum()","fbec6788":"Accident_Type_Code=pd.crosstab(train_df['Accident_Type_Code'],train_df['Severity'])\nViolations=pd.crosstab(train_df['Violations'],train_df['Severity'])\n\n\nAccident_Type_Code.div(Accident_Type_Code.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(6,6))\nViolations.div(Violations.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(6,6))\n","506f57eb":"cols = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n                        'Control_Metric', 'Turbulence_In_gforces',\n                       'Cabin_Temperature',  'Max_Elevation',\n                        'Adverse_Weather_Metric']\n\ntrain_df.groupby('Severity')['Safety_Score'].mean().plot.bar()\n\nplt.ylabel('Mean_Safety_Score')","3b9ab1dc":"# cols = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n#                         'Control_Metric', 'Turbulence_In_gforces',\n#                        'Cabin_Temperature',  'Max_Elevation',\n#                         'Adverse_Weather_Metric']\nplt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Safety_Score'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Safety_Score', fontsize = 20.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Days_Since_Inspection'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Since_Inspection', fontsize = 20.0)","6525676b":"plt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Total_Safety_Complaints'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Total_Safety_Complaints', fontsize = 12.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Control_Metric'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Control_Metric', fontsize = 12.0)","a2038eae":"plt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Turbulence_In_gforces'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Turbulence_In_gforces', fontsize = 12.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Cabin_Temperature'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Cabin_Temperature', fontsize = 12.0)","4175c2c4":"# 'Max_Elevation',  'Adverse_Weather_Metric'\nplt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Max_Elevation'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Max_Elevation', fontsize = 12.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Adverse_Weather_Metric'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Adverse_Weather_Metric', fontsize = 12.0)","675b7058":"train_df.columns","354c7021":"test_df.columns","c0a6682d":"features = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n       'Control_Metric', 'Turbulence_In_gforces', 'Cabin_Temperature',\n       'Accident_Type_Code', 'Max_Elevation', 'Violations',\n       'Adverse_Weather_Metric']\nlabels = train_df['Severity']","fe4c78fd":"X = train_df.drop(['Accident_ID','Severity'],axis=1)\ny = train_df['Severity']\n\ntest_X = test_df.drop(['Accident_ID'],axis=1)\n# TODO: Shuffle and split the data into training and testing subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=100)\n\n# Success\nprint (\"Training and testing split was successful.\")\n","d2b69909":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmodel_log = LogisticRegression()\nmodel_log.fit(X_train, y_train)\npred_cv = model_log.predict(X_valid)\naccuracy_score(y_valid,pred_cv)","2ce2b55e":"confusion_matrix = confusion_matrix( y_valid,pred_cv)\nprint(\"the recall for this model is :\",confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[1,0]))\n\nfig= plt.figure(figsize=(6,3))# to plot the graph\nprint(\"TP\",confusion_matrix[1,1,]) \nprint(\"TN\",confusion_matrix[0,0]) \nprint(\"FP\",confusion_matrix[0,1]) \nprint(\"FN\",confusion_matrix[1,0])\nsns.heatmap(confusion_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\nplt.title(\"Confusion_matrix\")\nplt.xlabel(\"Predicted_class\")\nplt.ylabel(\"Real class\")\nplt.show()\nprint(confusion_matrix)\nprint(\"\\n--------------------Classification Report------------------------------------\")\nprint(classification_report(y_valid, pred_cv)) ","407b4ec9":"model_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\nmodel_rf.fit(X_train, y_train)\npred_cv = model_rf.predict(X_valid)\naccuracy_score(y_valid,pred_cv)","19344720":"pred_test = model_rf.predict(test_X)\npred_test = pd.DataFrame(pred_test)\npred_test.columns = ['Severity']","bf5e3c87":"pred_test.head()\nprint(len(pred_test))","70e9ffa8":"importances=pd.Series(model_rf.feature_importances_, index=X.columns).sort_values()\nimportances.plot(kind='barh', figsize=(20,20))\nplt.xlabel('Importance of Attributes - Score')\nplt.ylabel('Attribute Name')\nplt.title(\"Attribute Importance by RandomForest Application\")","d6b37759":"sub_df = test_df[['Accident_ID']]\n# # Fill the target variable with the predictions\nsub_df['Severity'] = pred_test['Severity']\n# # # Converting the submission file to csv format\nsub_df.to_csv('submission.csv', index=False)","c696fb91":"sub_df.shape","41d86ff2":"sub_df.head()","25116b5a":"We will first look at the target variable, i.e., Severity. As it is a categorical variable, let us look at its frequency table, percentage distribution and bar plot. Frequency table of a variable will give us the count of each category in that variable.","e80e1758":"Here there is no class imbalance problem . Hence we can proceed further without addressing any class imbalance issues","3e0b0c26":"Now lets visualize each variable separately. Different types of variables are Categorical, ordinal and numerical.\n\nCategorical features: These features have categories (Accident_Type_Code, 'Violations')\n\nOrdinal features: Variables in categorical features having some order involved \n\nNumerical features: These features have numerical values ('Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints', 'Control_Metric', 'Turbulence_In_gforces',\n       'Cabin_Temperature',  'Max_Elevation',\n        'Adverse_Weather_Metric')\n\nTarget variable : 'Severity'\n\nLet\u2019s visualize the categorical and ordinal features first.","666e69bd":"#### Model Building - RandomForestClassifier","b33d95b3":"We will try to find the meanvalues vs Target vs ","3364b98d":"### Read data","34ac8a5d":"### Missing Values Treatment","fd355be7":"### Structure, Features and DataTypes","2a6565e7":"### Load packages","07667f20":"Let's visualize the Numerical Attributes","ab86d53f":"### Univariate Analysis","ce7a238e":"There are no missing values in dataset\n","8aa09d37":"#### Numerical Independent Variable vs Target Variable","061cd51a":"### Bivariate Analysis","e31c6117":"#### Categorical Independent Variable vs Target Variable","e0e6d499":"### Baseline model","5d3ed06e":"#### Logistic Regression"}}