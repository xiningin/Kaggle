{"cell_type":{"6bbbf7ba":"code","8ab7bac3":"code","de712d40":"code","98152dd1":"code","595148e4":"code","f78fea20":"code","bdf26df2":"code","b0139e3f":"code","3c61a078":"markdown"},"source":{"6bbbf7ba":"import subprocess\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","8ab7bac3":"# Install bert-as-service\n!pip install bert-serving-server\n!pip install bert-serving-client","de712d40":"# Download and unzip the pre-trained model\n!wget http:\/\/storage.googleapis.com\/bert_models\/2018_10_18\/uncased_L-12_H-768_A-12.zip\n!unzip uncased_L-12_H-768_A-12.zip","98152dd1":"# Start the BERT server\nbert_command = 'bert-serving-start -model_dir \/kaggle\/working\/uncased_L-12_H-768_A-12'\nprocess = subprocess.Popen(bert_command.split(), stdout=subprocess.PIPE)","595148e4":"# Start the BERT client\nfrom bert_serving.client import BertClient\nbc = BertClient()","f78fea20":"# Compute embeddings for some test sentences\nembeddings = bc.encode(['Embed a single sentence', \n                        'Can it handle periods? and then more text?', \n                        'how about periods.  and <p> html stuffs? <p>'])","bdf26df2":"embeddings.shape","b0139e3f":"embeddings","3c61a078":"The model returns 768-dimensional embeddings:"}}