{"cell_type":{"28ce5171":"code","73654ed3":"code","c5d35adf":"code","9094b6b4":"code","c8237e4e":"code","44452213":"code","a8cb45c2":"code","154fc808":"code","36e8749d":"code","c32f6efe":"code","5cee03c0":"code","877aa4c6":"code","2a72671b":"code","4a29688d":"code","fdbc48de":"code","79e497dc":"code","998e169c":"code","d610d8c7":"code","639d3ab2":"code","792a9537":"code","da2f4561":"code","7a6ee8c9":"code","1ef5532b":"code","a45d5d1d":"code","c925c90e":"code","211e7d82":"code","1aedd762":"code","9afd7b12":"code","856d60c8":"code","baf0abd3":"code","494700f6":"code","3011e920":"markdown","98f56833":"markdown","815371b1":"markdown","5a1d402f":"markdown","9fb0473f":"markdown","529fb2f1":"markdown","0cea72d2":"markdown","0a08fb6c":"markdown","0111fc76":"markdown","6bf26f7e":"markdown","d6c09b4f":"markdown","c0618298":"markdown","8c90dbbc":"markdown","76171209":"markdown","ef533e2a":"markdown","a17c2bca":"markdown","56ee19a7":"markdown","f18e9453":"markdown","3fdb4aaa":"markdown","17e4cd74":"markdown","e5f79189":"markdown","8fb69eb7":"markdown","ba8c80e4":"markdown"},"source":{"28ce5171":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","73654ed3":"df_train=pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ndf_train.head()","c5d35adf":"df_train['target'].unique()","9094b6b4":"len(df_train)","c8237e4e":"df_train.describe()","44452213":"df_train.loc[:, 'f0':'f99'].describe().style.background_gradient(cmap='Pastel1')","a8cb45c2":"df=df_train.groupby('target').size()\ndf","154fc808":"plt.figure(figsize=(15, 7))\nplt.pie([df[0],df[1]], labels = [\"0\" , \"1\"],autopct='%1.1f%%',colors = [\"#2a9d8f\", \"#e9c46a\"])","36e8749d":"import seaborn as sns\ncolor = sns.color_palette()","c32f6efe":"fig, axes = plt.subplots(10,10,figsize=(12, 12))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\n\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=df_train[df_train['target']==0], x=f'f{idx}',ax=ax,palette = [\"#2a9d8f\"])\n    sns.kdeplot(data=df_train[df_train['target']==1], x=f'f{idx}',ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(f'f{idx}', loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average by class (by feature f0-f99)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","5cee03c0":"stick=['f0','f2','f4','f9','f12','f16','f19','f20','f23','f24','f27','f28','f30','f31','f32','f33','f35','f39','f42','f44','f46','f48','f49','f51','f52','f53','f56','f58','f59','f60','f61','f62','f63','f64','f68','f69','f72','f73','f75','f76','f78','f79','f81','f83','f84','f87','f88','f89','f90','f92','f93','f94','f95','f98','f99']\ntrain_stick=df_train[stick+['target']]\ntrain_mount=df_train.drop(stick+['id'],axis=1)","877aa4c6":"train_mount.head()","2a72671b":"train_stick.head()","4a29688d":"fig, axes = plt.subplots(2,1,figsize=(12, 12))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\n\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=df_train[df_train['target']==0], x=stick[idx],ax=ax,palette = [\"#2a9d8f\"])\n    sns.kdeplot(data=df_train[df_train['target']==1], x=stick[idx],ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(stick[idx], loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average by class (by feature f0 and f2)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","fdbc48de":"fig, axes = plt.subplots(11,5,figsize=(12, 12))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\n\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=df_train[df_train['target']==0], x=stick[idx],ax=ax,palette = [\"#2a9d8f\"])\n    sns.kdeplot(data=df_train[df_train['target']==1], x=stick[idx],ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(stick[idx], loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average by class (by feature f0 and f2)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","79e497dc":"mount=[columns for columns in train_mount]","998e169c":"fig, axes = plt.subplots(9,5,figsize=(12, 12))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\n\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=train_mount[train_mount['target']==0], x=mount[idx],ax=ax,palette = [\"#2a9d8f\"])\n    sns.kdeplot(data=train_mount[train_mount['target']==1], x=mount[idx],ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(stick[idx], loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average by class (by feature f0 and f2)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","d610d8c7":"df_test=pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\ndf_test.head()","639d3ab2":"sumple_submission=pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nsumple_submission","792a9537":"import datatable as dt\n\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport os\nimport gc\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","da2f4561":"N_SPLITS = 5\nN_ESTIMATORS = 20000\nEARLY_STOPPING_ROUNDS = 200\nVERBOSE = 1000\nSEED = 42","7a6ee8c9":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything(SEED)","1ef5532b":"train = dt.fread('..\/input\/tabular-playground-series-nov-2021\/train.csv').to_pandas()\ntest = dt.fread('..\/input\/tabular-playground-series-nov-2021\/test.csv').to_pandas()\ntrain = train[train.columns[1:]]\ntest = test[test.columns[1:]]\n\nTARGET = 'target'\n","a45d5d1d":"features = [col for col in train.columns if 'f' in col]","c925c90e":"train[features] = train[features].astype('float32')\n\ntest[features] = test[features].astype('float32')\n","211e7d82":"display(train.info())\ndisplay(train[features].head())","1aedd762":"display(test.info())\ndisplay(test[features].head())","9afd7b12":"lgb_params = {\n    'objective': 'binary',\n    'n_estimators': N_ESTIMATORS,\n    'random_state': SEED,\n    'learning_rate': 8e-3,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n    'categorical_feature': 0,\n}","856d60c8":"lgb_oof = np.zeros(train.shape[0])\nlgb_pred = np.zeros(test.shape[0])\nlgb_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X=train, y=train[TARGET])):\n    print(f\"===== fold {fold} =====\")\n    X_train, y_train = train[features].iloc[trn_idx], train[TARGET].iloc[trn_idx]\n    X_valid, y_valid = train[features].iloc[val_idx], train[TARGET].iloc[val_idx]\n    X_test = test[features]\n    \n    start = time.time()\n    model = lgb.LGBMClassifier(**lgb_params)\n    model.fit(\n        X_train, \n        y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_metric='auc',\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        verbose=VERBOSE,\n    )\n    \n    fi_tmp = pd.DataFrame()\n    fi_tmp['feature'] = model.feature_name_\n    fi_tmp['importance'] = model.feature_importances_\n    fi_tmp['fold'] = fold\n    fi_tmp['seed'] = SEED\n    lgb_importances = lgb_importances.append(fi_tmp)\n\n    lgb_oof[val_idx] = model.predict_proba(X_valid)[:, -1]\n    lgb_pred += model.predict_proba(X_test)[:, -1] \/ N_SPLITS\n\n    elapsed = time.time() - start\n    auc = roc_auc_score(y_valid, lgb_oof[val_idx])\n    print(f\"fold {fold} - lgb auc: {auc:.6f}, elapsed time: {elapsed:.2f}sec\\n\")\n\nprint(f\"oof lgb roc = {roc_auc_score(train[TARGET], lgb_oof)}\")\n\nnp.save(\"lgb_oof.npy\", lgb_oof)\nnp.save(\"lgb_pred.npy\", lgb_pred)","baf0abd3":"order = list(lgb_importances.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\nfig = plt.figure(figsize=(16, 32), tight_layout=True)\nsns.barplot(x=\"importance\", y=\"feature\", data=lgb_importances.groupby('feature').mean().reset_index(), order=order)\nplt.title(\"LightGBM feature importances\")","494700f6":"submission = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\n\nsubmission[TARGET] = lgb_pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","3011e920":"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.\n\nIn order to have a more consistent offering of these competitions for our community, we're trying a new experiment in 2021. We'll be launching month-long tabular Playground competitions on the 1st of every month and continue the experiment as long as there's sufficient interest and participation.\n\nThe goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.\n\nFor each monthly competition, we'll be offering Kaggle Merchandise for the top three teams. And finally, because we want these competitions to be more about learning, we're limiting team sizes to 3 individuals.\n\nThe dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting identifying spam emails via various extracted features from the email. Although the features are anonymized, they have properties relating to real-world features.\n\nGood luck and have fun!\n\nFor ideas on how to improve your score, check out the Intro to Machine Learning and Intermediate Machine Learning courses on Kaggle Learn.","98f56833":"**Marisa:This time it looks like a real number.**","815371b1":"lunana\n<br>\nlast update 2021.11.02\n<br>\nyukkurisiteittene","5a1d402f":"**Marisa:Really a stick.**","9fb0473f":"**Reimu:Doesn't 0 or 1 change much?  \nMarisa:But it seems that it can be classified into two types, one is a graph like a bar and the other is a graph with two peaks. Let's try it.  \nReimu:How?  \nMarisa:Count by hand.**","529fb2f1":"sample_submission.csv - a sample submission file in the correct format","0cea72d2":"**Reimu:Today is the November TPS competition.  \nMarisa:Let's take a look at the outline first.**","0a08fb6c":"[![](https:\/\/img.youtube.com\/vi\/FnV0thLS1Fs\/0.jpg)](https:\/\/www.youtube.com\/watch?v=FnV0thLS1Fs)","0111fc76":"**Reimu:Next, let's take a look at Test data**","6bf26f7e":"![https:\/\/4.bp.blogspot.com\/-IMLly7zzfIk\/Wn1ViNMu99I\/AAAAAAABKDE\/oTpDtyrZcTwGZLZAAtbeQ5PIn7ixnaaQgCLcBGAs\/s400\/bikkuri_me_tobideru_woman.png](https:\/\/4.bp.blogspot.com\/-IMLly7zzfIk\/Wn1ViNMu99I\/AAAAAAABKDE\/oTpDtyrZcTwGZLZAAtbeQ5PIn7ixnaaQgCLcBGAs\/s400\/bikkuri_me_tobideru_woman.png)","d6c09b4f":"**Reimu:Let's learning!!**","c0618298":"# Parameters","8c90dbbc":"![http:\/\/3.bp.blogspot.com\/-42ddByrXRig\/VZ-W1-dVteI\/AAAAAAAAvTU\/SOdvlTbjoz0\/s300\/woman_question.png](http:\/\/3.bp.blogspot.com\/-42ddByrXRig\/VZ-W1-dVteI\/AAAAAAAAvTU\/SOdvlTbjoz0\/s300\/woman_question.png)","76171209":"# Datasets","ef533e2a":"**Reimu:Why does 'Met negative value' come out?**","a17c2bca":"**Reimu:This time as well, we will train AI to guess 0 or 1.**","56ee19a7":"**Reimu:Next, let's look at the data.**","f18e9453":"**Reimu:K-I'll do cross-validation. The standard is 5 pieces.  \nMarisa:I set epoch to 20000, but I set it to stop learning when the score doesn't go up.**","3fdb4aaa":"**Marisa:Let's graph the relationship between each element and target.**","17e4cd74":"train.csv - the training data with the target column","e5f79189":"**Marisa:Finally, let's take a look at sumple_submission data**","8fb69eb7":"# LightGBM","ba8c80e4":"test.csv - the test set; you will be predicting the target for each row in this file (the probability of the binary target)"}}