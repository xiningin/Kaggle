{"cell_type":{"414acdec":"code","3cc4a307":"code","c282ed2e":"code","8c40c426":"code","368f9882":"code","85f1aeca":"code","74ba736a":"code","04bc0b08":"code","13bc1825":"code","76ac6d26":"code","dc86cde3":"code","59211408":"markdown","d9883418":"markdown","82c9be14":"markdown","9d16bf14":"markdown","aec2cf22":"markdown","7c39a530":"markdown"},"source":{"414acdec":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","3cc4a307":"data = pd.read_csv('..\/input\/carinsurance\/carInsurance_train.csv')","c282ed2e":"data","8c40c426":"data.info()","368f9882":"def onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","85f1aeca":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop Id column\n    df = df.drop('Id', axis=1)\n    \n    # Drop Outcome column (too many missing values)\n    df = df.drop('Outcome', axis=1)\n    \n    # Fill categorical missing values with column modes\n    for column in ['Job', 'Education', 'Communication']:\n        df[column] = df[column].fillna(df[column].mode()[0])\n    \n    # Extract duration feature\n    df['CallDuration'] = (pd.to_datetime(df['CallEnd']) - pd.to_datetime(df['CallStart'])).apply(lambda x: x.seconds)\n    df = df.drop(['CallStart', 'CallEnd'], axis=1)\n    \n    # Binary encoding\n    df['Communication'] = df['Communication'].replace({'telephone': 0, 'cellular': 1})\n    \n    # Ordinal encoding\n    df['Education'] = df['Education'].replace({'primary': 0, 'secondary': 1, 'tertiary': 2})\n    df['LastContactMonth'] = df['LastContactMonth'].replace({\n        'jan': 0, 'feb': 1, 'mar': 2, 'apr': 3, 'may': 4, 'jun': 5, 'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9, 'nov': 10, 'dec': 11\n    })\n    \n    # One-hot encoding\n    for column in ['Job', 'Marital']:\n        df = onehot_encode(df, column)\n    \n    # Split df into X and y\n    y = df['CarInsurance']\n    X = df.drop('CarInsurance', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","74ba736a":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","04bc0b08":"X_train","13bc1825":"y_train","76ac6d26":"models = {\n    \"                   Logistic Regression\": LogisticRegression(),\n    \"                   K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"                         Decision Tree\": DecisionTreeClassifier(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVC(),\n    \"   Support Vector Machine (RBF Kernel)\": SVC(),\n    \"                        Neural Network\": MLPClassifier(),\n    \"                         Random Forest\": RandomForestClassifier(),\n    \"                     Gradient Boosting\": GradientBoostingClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","dc86cde3":"for name, model in models.items():\n    print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))","59211408":"# Preprocessing","d9883418":"# Results","82c9be14":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/m0Vl--yH578","9d16bf14":"# Getting Started","aec2cf22":"# Training","7c39a530":"# Task for Today  \n\n***\n\n## Car Insurance Cold Call Success Prediction  \n\nGiven *data about car insurance cold calls*, let's try to predict whether a given call will be **successful** or not.\n\nWe will use a variety of classification models to make our predictions."}}