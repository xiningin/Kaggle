{"cell_type":{"bad0885d":"code","76b5e23f":"code","8bf736e3":"code","b9eeb849":"code","93a1016a":"code","a12d9560":"code","d0fbc79f":"code","f0e78902":"code","74143941":"code","d699eeff":"code","6e388d49":"code","9f0a3ed3":"code","99f14e5f":"code","3cde6eb4":"code","ff975520":"code","609c2a75":"code","52c40dff":"code","53b604a5":"code","fbb76e61":"code","91ec8da6":"code","1fed10ad":"code","2a3e1424":"code","824f4909":"code","42fec6b0":"code","87080055":"code","7954541b":"code","6a3e2f07":"code","63f4a540":"code","61087ad3":"code","34121beb":"markdown","de6fe468":"markdown","58e9a58c":"markdown","18a329ba":"markdown","8567c5c6":"markdown","3205fc28":"markdown","d618e792":"markdown","fcef8768":"markdown","fd73d0ac":"markdown","33cfe7ed":"markdown"},"source":{"bad0885d":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T,datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nimport torchvision.models as models\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm","76b5e23f":"def show_image(image,label,get_denormalize = True):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    if get_denormalize == True:\n        image = image*std + mean\n        image = np.clip(image,0,1)\n        plt.imshow(image)\n        plt.title(label)\n        \n    else: \n        plt.imshow(image)\n        plt.title(label)","8bf736e3":"def show_grid(image,title = None):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    image = image*std + mean\n    image = np.clip(image,0,1)\n    \n    plt.figure(figsize=[15, 15])\n    plt.imshow(image)\n    if title != None:\n        plt.title(title)","b9eeb849":"def accuracy(y_pred,y_true):\n    y_pred = F.softmax(y_pred,dim = 1)\n    top_p,top_class = y_pred.topk(1,dim = 1)\n    equals = top_class == y_true.view(*top_class.shape)\n    return torch.mean(equals.type(torch.FloatTensor))","93a1016a":"def view_classify(image,ps,label):\n    \n    class_name = ['NORMAL', 'PNEUMONIA']\n    classes = np.array(class_name)\n\n    ps = ps.cpu().data.numpy().squeeze()\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    \n    image = image*std + mean\n    img = np.clip(image,0,1)\n    \n    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    return None","a12d9560":"class CFG:\n\n    epochs = 10                             # No. of epochs for training the model\n    lr = 0.001                              # Learning rate\n    batch_size = 16                         # Batch Size for Dataset\n\n    img_size = 224                          # Resize all the images to be 224 by 224\n\n    # going to be used for loading dataset\n    train_path='..\/input\/chest-xray-pneumonia\/chest_xray\/train\/'\n    validate_path ='..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n    test_path='..\/input\/chest-xray-pneumonia\/chest_xray\/test'\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"On which device we are on:{}\".format(device))","d0fbc79f":"train_transform = T.Compose([\n                             \n                             T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n                             T.RandomRotation(degrees=(-20,+20)), #Randomly Rotate Images by +\/- 20 degrees, Image argumentation for each epoch\n                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n\n])\n\nvalidate_transform = T.Compose([\n                             \n                             T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n                             #T.RandomRotation(degrees=(-20,+20)), #NO need for validation\n                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n\n])\n\ntest_transform = T.Compose([\n                             \n                             T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n                             #T.RandomRotation(degrees=(-20,+20)), #NO need for validation\n                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n\n])","f0e78902":"trainset=datasets.ImageFolder(CFG.train_path,transform=train_transform)\nprint(\"Trainset Size:  {}\".format(len(trainset)))","74143941":"validateset=datasets.ImageFolder(CFG.validate_path,transform=validate_transform)\nprint(\"validateset Size:  {}\".format(len(validateset)))","d699eeff":"testset=datasets.ImageFolder(CFG.test_path,transform=test_transform)\nprint(\"testset Size:  {}\".format(len(testset)))","6e388d49":"trainloader = DataLoader(trainset,batch_size=CFG.batch_size,shuffle=True)\nprint(\"No. of batches in trainloader:{}\".format(len(trainloader))) #Trainset Size:  5216 \/ batch_size: 16 = 326(No. of batches in trainloader) \nprint(\"No. of Total examples:{}\".format(len(trainloader.dataset)))\n\nvalidationloader = DataLoader(validateset,batch_size=CFG.batch_size,shuffle=True)\nprint(\"No. of batches in validationloader:{}\".format(len(validationloader))) #validationset Size:  16 \/ batch_size: 16 = 1(No. of batches in validationloader) \nprint(\"No. of Total examples:{}\".format(len(validationloader.dataset)))\n\ntestloader = DataLoader(testset,batch_size=CFG.batch_size,shuffle=True)\nprint(\"No. of batches in testloader:{}\".format(len(testloader))) #testset Size:  624 \/ batch_size: 16 = 39(No. of batches in testloader) \nprint(\"No. of Total examples:{}\".format(len(testloader.dataset)))","9f0a3ed3":"dataiter = iter(trainloader)\nimages,labels = dataiter.next()\n\nout = make_grid(images,nrow=4)\nshow_grid(out)","99f14e5f":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        return loss\n\n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}],{} train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, \"last_lr: {:.5f},\".format(result['lrs'][-1]) if 'lrs' in result else '', \n            result['train_loss'], result['val_loss'], result['val_acc']))\n","3cde6eb4":"class PneumiaClassifier(ImageClassificationBase):\n    def __init__(self, num_classes, pretrained=True):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=pretrained)\n        # Replace last layer\n        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n\n    def forward(self, xb):\n        return self.network(xb)","ff975520":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\n\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n\n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","609c2a75":"import torch\nfrom tqdm.notebook import tqdm\n\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n\n    # Set up custom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n                                                steps_per_epoch=len(train_loader))\n\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n\n            # Gradient clipping\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","52c40dff":"device = get_default_device()\ndevice","53b604a5":"train_dl = DeviceDataLoader(trainloader, device)\nvalid_dl = DeviceDataLoader(validationloader, device)","fbb76e61":"model = PneumiaClassifier(2)\nto_device(model, device);","91ec8da6":"epochs = 6\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","1fed10ad":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","2a3e1424":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","824f4909":"plot_losses(history)","42fec6b0":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","87080055":"plot_lrs(history)","7954541b":"model.eval()","6a3e2f07":"image,label = testset[15]\n\nps = model(image.to(device).unsqueeze(0))\nps = F.softmax(ps,dim = 1)\n\nview_classify(image,ps,label)","63f4a540":"image,label = testset[5]\n\nps = model(image.to(device).unsqueeze(0))\nps = F.softmax(ps,dim = 1)\n\nview_classify(image,ps,label)","61087ad3":"torch.save(model.state_dict(), 'pneumia-detection-resnet34.pth')","34121beb":"# Testing","de6fe468":"# Data Augmentation","58e9a58c":"# Save Model","18a329ba":"# Evaluation","8567c5c6":"# Utils","3205fc28":"# Fine Tuning the Model","d618e792":"* Perfect video of [Dev Mit Yao ](https:\/\/www.youtube.com\/watch?v=012xnlwY3G4)\n\n\n* [Jovian](https:\/\/jovian.ai\/)\n\n* [PyTorch Documentation](https:\/\/pytorch.org\/tutorials\/beginner\/finetuning_torchvision_models_tutorial.html#)","fcef8768":"# References","fd73d0ac":"# Move Everything to GPU and Train","33cfe7ed":"# Explore the Data"}}