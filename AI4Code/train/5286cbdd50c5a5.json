{"cell_type":{"fca13bca":"code","1d8b8f56":"code","6a6b5a4b":"code","94521c79":"code","5aecfa0c":"code","6f404987":"code","da2a1d44":"code","1d0c1591":"code","ef84f258":"code","4e97c2d0":"code","06e6387b":"code","2f455f96":"code","dcb2df55":"code","ab7f6999":"code","e00dc1b5":"code","638ec516":"code","efee01e7":"code","bfcfa6f2":"code","cc4797fc":"code","a2c56cda":"code","0d223fc3":"code","79da8258":"code","0a6eede9":"code","fb2b802f":"code","663ebe32":"code","cd033d98":"code","98cfda30":"code","5b1425df":"code","ff22e117":"code","a76dad6c":"code","39e153af":"code","9f71d05f":"markdown"},"source":{"fca13bca":"!pip install -I keras==2.1.6\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom keras import backend as K\nimport keras.preprocessing.image as keras_img\nimport matplotlib.pyplot as plt\nimport PIL.Image as Image\nimport os\nfrom keras.models import load_model, Model\nprint(os.listdir(\"..\/input\"))\nfrom PIL import Image\nfrom shutil import copyfile\ncopyfile(src = \"..\/input\/facenetkaggle\/fr_utils.py\", dst = \"..\/working\/fr_utils.py\")\ncopyfile(src = \"..\/input\/facenetkaggle\/inception_blocks_v2.py\", dst = \"..\/working\/inception_blocks_v2.py\")\nfrom fr_utils import *\nfrom inception_blocks_v2 import *\nfrom keras.callbacks import EarlyStopping\nimport keras","1d8b8f56":"img_size=96\ndef load_image(path):\n    try:\n        img = Image.open(path)\n        img = img.resize((img_size,img_size), Image.ANTIALIAS)\n    except:\n        img=None\n        return None\n    return np.array(img)\n\n\ndef load_data():\n    train_data_path = \"..\/input\/bollywood\/q1_trainingdata\/Q1_TrainingData\/\"\n    classes = os.listdir(train_data_path)\n    arr_df = []\n    for i in range(len(classes)):\n        class_path = classes[i]\n        file_list = os.listdir(train_data_path + class_path)\n        df = pd.DataFrame({\"file\":file_list})\n        df[\"class\"] = i\n        df[\"class_name\"] = classes[i]\n        arr_df.append(df)\n\n    train_data = pd.concat(arr_df)\n    train_data = train_data.reset_index()\n    train_data[\"img\"] = train_data.apply(lambda x: load_image(train_data_path + x[\"class_name\"] + \"\/\" + x[\"file\"]), axis=1)\n    return train_data","6a6b5a4b":"K.set_image_data_format('channels_first')\ndef load_facenet_weights():\n    global FRmodel\n    facedir = \"..\/input\/facenetkaggle\/all_weights\/\"\n    fileNames = os.listdir(facedir)\n    filePaths = [facedir + fname for fname in fileNames]\n    paths = {}\n    weights_dict = {}\n    for n in range(len(fileNames)):\n            paths[fileNames[n].replace('.csv', '')] = filePaths[n]\n    load_weights_from_FaceNet(FRmodel, fileNames, filePaths)\n    \ndef triplet_loss(y_true, y_pred, alpha = 0.2):\n    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n    basic_loss = pos_dist - neg_dist + alpha\n    loss = tf.reduce_sum(tf.maximum(basic_loss, 0))\n    return loss\n\n\ndef img_to_fnencoding(img, model):\n    img = np.around(np.transpose(img, (2,0,1))\/255.0, decimals=12)\n    x_train = np.array([img])\n    embedding = model.predict_on_batch(x_train)\n    return embedding\n\n\ndef who_is_it(val_idx, val_img, encoding, true_class):\n#encoding = img_to_fnencoding(val_img, FRmodel) \n    train_idx = list(set(list(train_data.index)) - set([val_idx]))\n\n    train_data1 = train_data.loc[train_idx]\n    train_data1[\"dist\"] = train_data1[\"fn_encoding\"].map(lambda x: np.linalg.norm(encoding- x))\n    \n    idx = train_data1.sort_values(\"dist\").index[0]\n    pos_data = train_data1[train_data1[\"class_name\"]==true_class].sort_values(\"dist\")\n    neg_data = train_data1[train_data1[\"class_name\"]!=true_class].sort_values(\"dist\")\n    pos_idx1, pos_idx2, pos_idx3 = pos_data[0:1].index[0], pos_data[1:2].index[0], pos_data[2:3].index[0]\n    neg_idx1, neg_idx2, neg_idx3 = neg_data[0:1].index[0], neg_data[1:2].index[0], neg_data[2:3].index[0]\n    print(train_data1.loc[idx, \"class_name\"],idx, pos_idx1, pos_idx2, pos_idx3, neg_idx1, neg_idx2, neg_idx3)\n    return train_data1.loc[idx, \"class_name\"],idx, pos_idx1, pos_idx2, pos_idx3, neg_idx1, neg_idx2, neg_idx3\n\n\ndef batch_generator(batch_size = 32):\n    while True:\n        sample_review_idx = np.random.randint(0, review_idx.shape[0], batch_size)\n        idx= review_idx[sample_review_idx]\n        pos_col_idx = np.random.randint(1,4)\n        neg_col_idx = np.random.randint(1,4)\n        pos_idx = train_data.loc[idx,\"pos_idx\" + str(pos_col_idx)].values\n        neg_idx = train_data.loc[idx,\"neg_idx\" + str(neg_col_idx)].values\n        anc = train_data.loc[idx,\"img\"].apply(lambda x: np.around(np.transpose(x, (2,0,1))\/255.0, decimals=12)).values\n        neg = train_data.loc[neg_idx,\"img\"].apply(lambda x: np.around(np.transpose(x, (2,0,1))\/255.0, decimals=12)).values\n        pos = train_data.loc[pos_idx,\"img\"].apply(lambda x: np.around(np.transpose(x, (2,0,1))\/255.0, decimals=12)).values\n\n        arr = []\n        for val in anc:\n            arr.append(val)\n        anc = np.array(arr)\n\n        arr = []\n        for val in neg:\n            arr.append(val)\n        neg = np.array(arr)\n\n        arr = []\n        for val in pos:\n            arr.append(val)\n        pos = np.array(arr)\n\n        x_data = {'anchor': anc,\n                  'anchorPositive': pos,\n                  'anchorNegative': neg\n                  }\n        yield (x_data, np.zeros((batch_size, 2, 1)))\n    \n    \ndef triplet_loss_v2(y_true, y_pred):\n    positive, negative = y_pred[:,0,0], y_pred[:,1,0]\n    margin = K.constant(0.35)\n    loss = K.mean(K.maximum(K.constant(0), positive - negative + margin))\n    return loss\n\ndef euclidean_distance(vects):\n    x, y = vects\n    dist = K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n    return dist\n\n\n\n# Setting layers non-trainable\n\ndef get_triplet_model():\n    global FRmodel\n    # Model Structure\n    input_shape=(3, 96, 96)\n    anchor = Input(shape=input_shape, name = 'anchor')\n    anchorPositive = Input(shape=input_shape, name = 'anchorPositive')\n    anchorNegative = Input(shape=input_shape, name = 'anchorNegative')\n\n    anchorCode = FRmodel(anchor)\n    anchorPosCode = FRmodel(anchorPositive)\n    anchorNegCode = FRmodel(anchorNegative)\n\n\n    positive_dist = Lambda(euclidean_distance, name='pos_dist')([anchorCode, anchorPosCode])\n    negative_dist = Lambda(euclidean_distance, name='neg_dist')([anchorCode, anchorNegCode])\n    stacked_dists = Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist])\n    # Model\n    tripletModel = Model([anchor, anchorPositive, anchorNegative], stacked_dists, name='triple_siamese')\n    tripletModel.compile(optimizer = 'adadelta', loss = triplet_loss_v2, metrics = ['accuracy'])\n    \n    return tripletModel\n\ndef retrain_model():\n    global FRmodel, tripletModel\n    \n    for layer in FRmodel.layers:\n        layer.trainable = True\n        \n    for layer in FRmodel.layers[0:80]:\n        layer.trainable = False\n        \n    gen = batch_generator(64)\n\n    early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta=0.00005)\n    tripletModel.compile(optimizer = 'adadelta', loss = triplet_loss_v2, metrics = ['accuracy'])\n    tripletModel.fit_generator(gen, epochs=100,steps_per_epoch=30,callbacks=[early_stopping])\n    \n    for layer in FRmodel.layers[0: 100]:\n        layer.trainable  =  False\n        \n    gen = batch_generator(64)\n    \n    early_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=0.0000001)\n    tripletModel.compile(optimizer = 'adadelta', loss = triplet_loss_v2, metrics = ['accuracy'])\n    tripletModel.fit_generator(gen, epochs=1,steps_per_epoch=30,callbacks=[early_stopping])\n\n    #bst_model_path = \"FRmodel\"\n    #FRmodel.save(bst_model_path)","94521c79":"def get_acc():\n    global FRmodel\n    train_data[\"fn_encoding\"] = train_data[\"img\"].map(lambda x: img_to_fnencoding(x, FRmodel))\n    acc=0\n    review_idx = []\n    for val_idx in train_data.index.values:\n        val_img = train_data.loc[val_idx, \"img\"]\n        true_class = train_data.loc[val_idx, \"class_name\"]\n        fn_encoding = train_data.loc[val_idx, \"fn_encoding\"]\n        #plt.imshow(val_img)\n        pred_class, pred_idx, pos_idx1, pos_idx2, pos_idx3, neg_idx1, neg_idx2, neg_idx3 = who_is_it(val_idx, val_img, fn_encoding, true_class)\n        train_data.loc[val_idx,\"pred_idx\"] = pred_idx\n        train_data.loc[val_idx,\"pos_idx1\"] = pos_idx1\n        train_data.loc[val_idx,\"pos_idx2\"] = pos_idx2\n        train_data.loc[val_idx,\"pos_idx3\"] = pos_idx3\n        train_data.loc[val_idx,\"neg_idx1\"] = neg_idx1\n        train_data.loc[val_idx,\"neg_idx2\"] = neg_idx2\n        train_data.loc[val_idx,\"neg_idx3\"] = neg_idx3\n        train_data.loc[val_idx,\"pred_class_name\"] = pred_class\n        if true_class == pred_class:\n            acc = acc+1\n        else:\n            review_idx.append(val_idx)\n        #print(true_class, pred_class, acc)\n    print(acc)\n    review_idx = np.array(review_idx)\n    return review_idx\n\n\ndef get_val_acc():\n    global FRmodel\n    val_data[\"fn_encoding\"] = val_data[\"img\"].map(lambda x: img_to_fnencoding(x, FRmodel))\n    acc=0\n    list_idx = []\n    list_pred_idx = []\n    for val_idx in val_data.index.values:\n        val_img = val_data.loc[val_idx, \"img\"]\n        true_class = val_data.loc[val_idx, \"class_name\"]\n        fn_encoding = val_data.loc[val_idx, \"fn_encoding\"]\n        #plt.imshow(val_img)\n        pred_class, pred_idx, pos_idx1, pos_idx2, pos_idx3, neg_idx1, neg_idx2, neg_idx3 = who_is_it(val_idx, val_img, fn_encoding, true_class)\n        if true_class == pred_class:\n            acc = acc+1\n        else:\n            list_idx.append(val_idx)\n            list_pred_idx.append(pred_idx)\n        print(true_class, pred_class, acc)\n    print(acc)\n    return list_idx, list_pred_idx","5aecfa0c":"train_data = load_data()","6f404987":"train_data.groupby(\"class\").count()","da2a1d44":"cols = list(train_data.columns.values)\ntrain_data = train_data[train_data[\"img\"].isna()==False].reset_index()[cols]","1d0c1591":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(0,100):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","ef84f258":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(100,200):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","4e97c2d0":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(200,300):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","06e6387b":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(300,400):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","2f455f96":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(400,500):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","dcb2df55":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(500,600):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","ab7f6999":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(600,700):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","e00dc1b5":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(700,800):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","638ec516":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(900,1000):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","efee01e7":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(1000,1100):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","bfcfa6f2":"fig, ax = plt.subplots(10,10, figsize=(20,20))\ni,j = 0,0\nfor idx in range(1100,1200):\n    img = train_data.loc[idx,\"img\"]\n    ax[i,j].imshow(img)\n    j=j+1\n    if (j==10):\n        j=0\n        i=i+1","cc4797fc":"train_data.columns","a2c56cda":"cols = list(train_data.columns.values) \nval_data_idx = np.random.randint(0, train_data.shape[0], 100)\nval_data = train_data.loc[val_data_idx].reset_index()[cols]\ntrain_data_idx = list(set(train_data.index) - set(val_data_idx))\ntrain_data = train_data.loc[train_data_idx].reset_index()[cols]\n","0d223fc3":"FRmodel = load_model(\"..\/input\/is-this-the-image-of-my-favorite-khan\/KhanModel\", custom_objects={\"triplet_loss\":triplet_loss})","79da8258":"if 1==2:\n    FRmodel = faceRecoModel(input_shape=(3,img_size, img_size))\n    load_facenet_weights()\n    for layer in FRmodel.layers:\n        layer.trainable = True\nFRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])","0a6eede9":"review_idx = get_acc()","fb2b802f":"tripletModel = get_triplet_model()\nretrain_model()\nreview_idx = get_acc()","663ebe32":"#tripletModel = get_triplet_model(FRmodel)\nretrain_model()\n#review_idx = get_acc()","cd033d98":"val_data = val_data[val_data[\"img\"].isna()==False]\nval_idx_incorrect, pred_idx_correct = get_val_acc()\n#FRmodel = load_model(bst_model_path, custom_objects={\"triplet_loss\":triplet_loss}, compile=True)\n#review_idx = get_acc()","98cfda30":"len(val_idx_incorrect)","5b1425df":"fig, ax = plt.subplots(len(val_idx_incorrect),2, figsize=(20,20))\ni,j = 0,0\nfor i in range(len(val_idx_incorrect)):\n    img = val_data.loc[val_idx_incorrect[i],\"img\"]\n    ax[i,0].imshow(np.array(img))\n    img = train_data.loc[pred_idx_correct[i],\"img\"]\n    ax[i,1].imshow(np.array(img))","ff22e117":"FRmodel.save(\"KhanModel\")","a76dad6c":"\nfull_train_data = pd.concat([train_data[[\"class_name\",\"fn_encoding\"]], val_data[[\"class_name\",\"fn_encoding\"]]])\nfrom IPython.display import HTML\nimport base64\nfull_train_data[\"str_encoding\"] = full_train_data[\"fn_encoding\"].map(lambda x: \"^\".join(list(x.flatten().astype(str))))\nfull_train_data[[\"class_name\",\"str_encoding\"]].to_csv(\"model_encoding.csv\", index=False)\n\n\ndef create_download_link(title = \"Download CSV file\", filename='model_encoding.csv'):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n    ","39e153af":"create_download_link()","9f71d05f":"# So now that we have great accuracy on train data we look good to validate it on test images!!!"}}