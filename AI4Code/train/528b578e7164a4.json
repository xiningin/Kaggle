{"cell_type":{"bf038e21":"code","dee93f73":"code","37a9976a":"code","6033ecbf":"code","31b22191":"code","7d73a179":"code","3441ccd5":"code","ab5f3c53":"code","1b820441":"code","007e1416":"code","ec428097":"code","a5e6e816":"code","e4816c14":"code","2b8c64c3":"code","d0288c28":"code","f93f5265":"code","495f4637":"code","7656f9d7":"code","ea598495":"code","78d0c8c6":"code","ed6ad430":"code","c8309a84":"code","ef6b614e":"code","9f8783fe":"code","83e4e566":"code","6fd3b062":"code","9ee63b81":"code","579e7eef":"code","23f7e35d":"code","80207a5f":"markdown","166ae7a9":"markdown","07b2a392":"markdown","ea53e15a":"markdown","d16286b3":"markdown","7325fbeb":"markdown","bf1a6f83":"markdown","64dcb901":"markdown","e8daa539":"markdown"},"source":{"bf038e21":"import tensorflow as tf\nfrom tensorflow.keras import datasets,layers,models\nimport matplotlib.pyplot as plt\nimport numpy as np","dee93f73":"(X_train,y_train),(X_test,y_test)=datasets.cifar10.load_data()","37a9976a":"X_train.shape","6033ecbf":"X_test.shape","31b22191":"y_train.shape","7d73a179":"y_train[:5]","3441ccd5":"y_train = y_train.reshape(-1,)\ny_train[:5]","ab5f3c53":"y_test = y_test.reshape(-1,)","1b820441":"classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]","007e1416":"def plot_sample(X, y, index):\n    plt.figure(figsize = (15,2))\n    plt.imshow(X[index])\n    plt.xlabel(classes[y[index]])","ec428097":"plot_sample(X_train, y_train, 0)","a5e6e816":"plot_sample(X_train, y_train, 1)","e4816c14":"plot_sample(X_train, y_train, 2)","2b8c64c3":"for i in range(3,10):\n  plot_sample(X_train, y_train, i)","d0288c28":"X_train[0]","f93f5265":"X_train=X_train\/255\nX_test=X_test\/255","495f4637":"ann=models.Sequential([\n                      layers.Flatten(input_shape=(32,32,3)),\n                      layers.Dense(3000,activation='relu'),\n                      layers.Dense(1000,activation='relu'),\n                      layers.Dense(10,activation='softmax')\n])\n\nann.compile(optimizer='SGD',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n            )\nann.fit(X_train,y_train,epochs=5)","7656f9d7":"from sklearn.metrics import confusion_matrix , classification_report\nimport numpy as np\ny_pred = ann.predict(X_test)\ny_pred_classes = [np.argmax(element) for element in y_pred]\n\nprint(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))","ea598495":"cnn=models.Sequential([\n                       #cnn\n                      layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(32,32,3)),\n                      layers.MaxPool2D((2,2)),\n                       \n                      layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=(32,32,3)),\n                      layers.MaxPool2D((2,2)),\n\n\n                      layers.Flatten(),\n                      layers.Dense(64,activation='relu'),\n                      layers.Dense(10,activation='softmax')\n])","78d0c8c6":"cnn.compile(optimizer='adam',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n            )\ncnn.fit(X_train,y_train,epochs=15)","ed6ad430":"cnn.evaluate(X_test,y_test)","c8309a84":"y_pred = cnn.predict(X_test)\ny_pred[:5]","ef6b614e":"y_classes = [np.argmax(element) for element in y_pred]\ny_classes[:5]","9f8783fe":"y_test[:5]","83e4e566":"plot_sample(X_test, y_test,3)","6fd3b062":"classes[y_classes[3]]","9ee63b81":"plot_sample(X_test, y_test,10)","579e7eef":"classes[y_classes[10]]","23f7e35d":"from sklearn.metrics import confusion_matrix , classification_report\nimport numpy as np\ny_pred = cnn.predict(X_test)\ny_pred_classes = [np.argmax(element) for element in y_pred]\n\nprint(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))","80207a5f":"**With CNN, at the end 5 epochs, accuracy was at around 70% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features**","166ae7a9":"\ny_train is a 2D array, for our classification having 1D array is good enough. so we will convert this to now 1D array","07b2a392":"Let's plot some images to see what they are","ea53e15a":"Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. Hence to normalize in 0-->1 range, we need to divide it by 255","d16286b3":"**You can see that at the end of 5 epochs, accuracy is at around 49%**","7325fbeb":"**Importing Libraries**","bf1a6f83":"**Normalizing the training data**","64dcb901":"**Build simple artificial neural network for image classification**","e8daa539":"**Now let us build a convolutional neural network to train our images**"}}