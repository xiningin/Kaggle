{"cell_type":{"b6037615":"code","c6c158a8":"code","efe149aa":"code","9d6fea9e":"code","d6e0a2cf":"code","9a90a1e2":"code","34b27f44":"code","51bc2aa1":"code","4e1e054b":"code","6920b1d3":"code","26968427":"code","92e05eff":"code","e697d356":"markdown","4d915a22":"markdown","8452514c":"markdown","f0e6adbc":"markdown","d27f8ce1":"markdown","eba691d8":"markdown","a222d54c":"markdown","2a472153":"markdown"},"source":{"b6037615":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n","c6c158a8":"!git clone https:\/\/github.com\/aielawady\/horaira.git","efe149aa":"import horaira.augmentors\nimport horaira.im_proc\nimport horaira.utils","9d6fea9e":"# Removing .git dir because Kaggle gives error related to the depth of the dir.\n!rm -r horaira\/.git\/","d6e0a2cf":"preprocessed_path = 'preprocess_images\/'\ncompetition_base_path = '..\/input\/aptos2019-blindness-detection\/'\nimage_size = 300\nscale_value = 1\naspect_ratio = 1\ninput_aspect_ratio = 1\nNUM_CLASSES = 5","9a90a1e2":"df_train = pd.read_csv(competition_base_path + 'train.csv')\ndf_test = pd.read_csv(competition_base_path + 'test.csv')\nx = df_train['id_code'].values\ny = df_train['diagnosis'].values\n\ntrain_x,train_y,valid_x,valid_y = horaira.utils.balanced_valid_set_splitter(x, y, valid_n_per_class = 100, debug=True)\nprint(train_x.shape)\nprint(train_y.shape)\nprint(valid_x.shape)\nprint(valid_y.shape)","34b27f44":"encoding_decoding_methods = {\n    'train_encoding':'one',        # 'one', 'all_lower_ones' or 'pairs'\n    'valid_encoding': 'one',       # 'one', 'all_lower_ones' or 'pairs'\n    'decoding':'max'               # 'max' or 'highest_true'\n}\n\ntmp = np.arange(5)\nprint(\"\\nSample input 1:\")\nprint(tmp)\ntmp = horaira.utils.classes_encoder(tmp,5,method=encoding_decoding_methods['train_encoding'])\nprint(\"\\nEncoding using '{}' method:\".format(encoding_decoding_methods['train_encoding']))\nprint(tmp)\ntmp = horaira.utils.classes_decoder(tmp,method=encoding_decoding_methods['decoding'])\nprint(\"\\nDecoding using '{}' method:\".format(encoding_decoding_methods['decoding']))\nprint(tmp)\ntmp = horaira.utils.np.random.rand(6,5)\nprint(\"\\nSample input 2:\")\nprint(tmp)\ntmp = horaira.utils.classes_decoder(tmp,method=encoding_decoding_methods['decoding'])\nprint(\"\\nDecoding using '{}' method:\".format(encoding_decoding_methods['decoding']))\nprint(tmp)\n","51bc2aa1":"circle_centering_params = {\n    'circle_detection_method':'moments',      # 'enclosing_circle', 'moments' or 'max_dim'\n    'scale_value' : scale_value,\n    'aspect_ratio' : aspect_ratio,\n    'width' : image_size, \n    'gray_threshold' : 10\n}\n\n\npreprocess_sequence_step = [horaira.im_proc.circle_centering, horaira.im_proc.veins_spots_highlighter]\npreprocess_params_step = [circle_centering_params, {}]\n\nlister = np.random.choice(df_train['id_code'],8)\n\nimgs_orig = horaira.utils.apply_preprocess(lister,src_path=competition_base_path+'train_images\/', preprocessing_function={}, preprocessing_params={})\nimgs = horaira.utils.apply_preprocess(lister,src_path=competition_base_path+'train_images\/', preprocessing_function=preprocess_sequence_step, preprocessing_params=preprocess_params_step)\nplt.figure(figsize=(20,20))\nfor i in range(len(imgs) * 2):\n    plt.subplot(4,4,i+1)\n    if i%2 == 0:\n        plt.imshow(imgs_orig[i\/\/2].astype('uint8'))\n    else:\n        plt.imshow(imgs[i\/\/2].astype('uint8'))\n","4e1e054b":"preprocess_sequence_step = [horaira.im_proc.circle_centering]\npreprocess_params_step = [circle_centering_params]\n\nlister = np.random.choice(df_train['id_code'],8)\n\nimgs_orig = horaira.utils.apply_preprocess(lister,src_path=competition_base_path+'train_images\/', preprocessing_function={}, preprocessing_params={})\nimgs = horaira.utils.apply_preprocess(lister,src_path=competition_base_path+'train_images\/', preprocessing_function=preprocess_sequence_step, preprocessing_params=preprocess_params_step)\nplt.figure(figsize=(20,20))\nfor i in range(len(imgs) * 2):\n    plt.subplot(4,4,i+1)\n    if i%2 == 0:\n        plt.imshow(imgs_orig[i\/\/2].astype('uint8'))\n    else:\n        plt.imshow(imgs[i\/\/2].astype('uint8'))\n","6920b1d3":"!mkdir -p $preprocessed_path\/train\nhoraira.utils.apply_preprocess(df_train['id_code'][:100].values,src_path=competition_base_path+'train_images\/', dst_path=preprocessed_path+'train\/',\n                 preprocessing_function=preprocess_sequence_step, preprocessing_params=preprocess_params_step, write=True)","26968427":"train_x_aug, train_y_aug = horaira.augmentors.crop_augmentor(df_train['id_code'].values[:100], df_train['diagnosis'].values[:100], preprocessed_path, 10)","92e05eff":"plt.figure(figsize=(20,20))\nfor i in range(4):\n    plt.subplot(2,2,i+1)\n    plt.imshow(plt.imread(preprocessed_path+'train\/'+train_x_aug[-i]+'.png'))","e697d356":"# horaira \n\nTools I used in Kaggle competitions. (APTOS 2019 Blindness Detection and State Farm Distracted Driver Detection)\n\nYou can find more on https:\/\/github.com\/aielawady\/horaira\n","4d915a22":"# Augmentor","8452514c":"# Configurations","f0e6adbc":"# Encoding and decoding","d27f8ce1":"# Preparing the data","eba691d8":"# Imports","a222d54c":"# Preprocessing Pipeliner","2a472153":"Without the viens and spots highlighter."}}