{"cell_type":{"4dc20ea5":"code","911f13eb":"code","4de417c0":"code","0db2ee48":"code","e294b159":"code","753e8b24":"code","1d829216":"code","8e683234":"code","dc9b4090":"code","ae51d4e8":"code","f46a43e6":"code","8020116c":"code","4af09638":"code","cda35098":"code","8ad777af":"code","028d8661":"code","7f3c2980":"code","bb4df96c":"markdown","eaf4d37b":"markdown","109b0e92":"markdown","a34d1a95":"markdown","bbc21b01":"markdown","b4d630ac":"markdown","2627ac1b":"markdown","2b75b669":"markdown","a71586a5":"markdown","7d538858":"markdown","3cdead5d":"markdown","cb570ab0":"markdown","b2359640":"markdown"},"source":{"4dc20ea5":"import time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom glob import glob\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\n\nimport torchvision\nimport torchvision.transforms as transforms\n","911f13eb":"brown_spot = glob(\"..\/input\/riceleafs\/RiceLeafs\/train\/BrownSpot\/*\") + glob(\"..\/input\/riceleafs\/RiceLeafs\/validation\/BrownSpot\/*\")\nhealthy = glob(\"..\/input\/riceleafs\/RiceLeafs\/train\/Healthy\/*\") + glob(\"..\/input\/riceleafs\/RiceLeafs\/validation\/Healthy\/*\")\nhispa = glob(\"..\/input\/riceleafs\/RiceLeafs\/train\/Hispa\/*\") + glob(\"..\/input\/riceleafs\/RiceLeafs\/validation\/Hispa\/*\")\nleaf_blast = glob(\"..\/input\/riceleafs\/RiceLeafs\/train\/LeafBlast\/*\") + glob(\"..\/input\/riceleafs\/RiceLeafs\/validation\/LeafBlast\/*\")\n\nprint(\"Number of brown spot:\",len(brown_spot))\nprint(\"Number of healthy:\",len(healthy))\nprint(\"Number of hispa: \",len(hispa))\nprint(\"Number of leaf blast:\",len(leaf_blast))\n","4de417c0":"label_map = {0:\"brown_spot\",\n             1:\"healthy\",\n             2:\"hispa\",\n             3:\"leaf_blast\"\n            }","0db2ee48":"class LeafDataset(Dataset):\n    \n    def __init__(self,paths):\n        \n        self.x = []\n        self.y = []                         # This converts pil image to torch tensor.\n        self.transform = transforms.Compose([transforms.ToTensor(),\n                                             # We have to normalize data to use in torchvision models.\n                                             transforms.Normalize(mean=[0.485, 0.456, 0.406],                                     std=[0.229, 0.224, 0.225])\n                                            ])\n        \n        start = time.time()\n        for label,class_paths in enumerate(paths):\n            for sample_path in class_paths:\n                img = Image.open(sample_path).resize((224,224))\n                self.x.append(self.transform(img))\n                self.y.append(label)\n        end = time.time()\n        process_time = round(end-start,2)\n        print(\"Dataset has loaded, that took {} seconds\".format(process_time))\n        \n    \n    def __getitem__(self,index):\n        return self.x[index],self.y[index]\n    \n    def __len__(self):\n        return len(self.x)\n","e294b159":"dataset = LeafDataset((brown_spot,healthy,hispa,leaf_blast))","753e8b24":"random_sample_indexes = random.choices(range(len(dataset)),k=20)\n\nfig, axis = plt.subplots(4,5, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        \n        image,label = dataset[i]\n        \n        npimg = image.numpy()\n        npimg = np.transpose(npimg, (1, 2, 0))\n        label = label_map[label]\n        ax.imshow(npimg)\n        ax.set(title = f\"{label}\")\n        plt.axis(\"off\")","1d829216":"np.unique(dataset.y)","8e683234":"# Splitting indices into train and test sets.\ntrain,test = train_test_split(list(range(len(dataset))))\nprint(len(train))\nprint(len(test))","dc9b4090":"train_sampler = SubsetRandomSampler(train)\ntest_sampler = SubsetRandomSampler(test)","ae51d4e8":"BATCH_SIZE = 64\ntrain_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE,sampler=train_sampler)\ntest_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE,sampler=test_sampler)\n","f46a43e6":"vgg16 = torchvision.models.vgg16_bn(pretrained=True)\n\n# In transfer learning we don't need to train all layers, \n# actually in this mission we'll just train fully connected layers\n# other's will be pre-trained\n\nfor param in vgg16.features.parameters():\n    param.require_grad = False\n\n# This will return how many features we'll have after flattening.\nnum_features = vgg16.classifier[6].in_features\nnum_features","8020116c":"# We did not get the last layer (prediction layer) \n# we'll add our prediction layer.\nlayers = list(vgg16.classifier.children())[:-1]\n\nlayers.append(nn.Linear(num_features,4))\n\nvgg16.classifier = nn.Sequential(*layers)","4af09638":"# In order to work with gpu, we need to create a device object\ndevice = torch.device(\"cuda\")\nprint(device)","cda35098":"# Also we need an optimizer and a loss function\n# We'll use RMSprop as optimizer and cross entropy as loss\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(vgg16.parameters(),lr=1e-4)","8ad777af":"vgg16 = vgg16.to(device)","028d8661":"EPOCH_NUMBER = 5\n\nfor current_epoch in range(1,EPOCH_NUMBER+1):\n    epoch_total_train_loss = 0.0\n    epoch_total_train_true = 0\n    epoch_total_data_len = 0\n    \n    for images,labels in train_loader:\n        images,labels = images.to(device),labels.to(device)\n        \n        # Cleaning cached gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = vgg16(images)\n        \n        # Backward propagation\n        loss = criterion(outputs,labels)\n        loss.backward()\n        \n        # Optimizing\n        optimizer.step()\n        \n        epoch_total_train_loss += loss.item()\n        _,pred = torch.max(outputs,dim=1)\n        epoch_total_train_true += torch.sum(pred == labels).item()\n        epoch_total_data_len += labels.size(0)\n    \n    acc = round(100 * epoch_total_train_true \/ epoch_total_data_len,2)\n    print(f\"Epoch {current_epoch} completed: Train loss: {epoch_total_train_loss} Train Accuracy: {acc}\")\n        ","7f3c2980":"validation_loss = 0.0\nvalidation_correct = 0\nvalidation_total = len(test_sampler)\n\nwith torch.no_grad():\n    vgg16.eval()\n    for data_,target_ in test_loader:\n        data_,target_ = data_.to(device),target_.to(device)\n        \n        outputs = vgg16(data_)\n        loss = criterion(outputs,target_).item()\n        _,preds = torch.max(outputs,dim=1)\n        correct = torch.sum(preds == target_).item()\n        validation_loss += loss\n        validation_correct += correct\n\nvalidation_accuracy = round(100 * validation_correct \/ validation_total,2)\nprint(f\"Validation accuracy: {validation_accuracy}, Validation loss: {validation_loss}\")","bb4df96c":"* Done, now we can train our model.","eaf4d37b":"* We've trained our model, let's compute validation loss and validation accuracy.","109b0e92":"* And finally we can create our loader objects.","a34d1a95":"# Preparing Data\n\nIn this section we're going to create a custom dataset class, sampler and loader objects.","bbc21b01":"* Validation accuracy is pretty worse but we can handle this problem using data augmentation techniques and I'll learn (and also show you xD) it in the next kernel.\n","b4d630ac":"* Now let's get 20 random samples and see how our data seems.","2627ac1b":"# Conclusion\nThanks for your attention, if you have a questions please ask me in the comment section and also mention me. I'll return you as soon as possible.\n","2b75b669":"* Now we'll create subset samplers.\n","a71586a5":"# Preparing VGG16\nIn this section we're going to load and prepare our VGG16 model.","7d538858":"# Preparing Environment\nIn this section we're going to import libraries we'll use and read the paths of the images.\n","3cdead5d":"# Training VGG16\nNow we're going to train our model, one of the best things about Pytorch is training is always same and really easy to configure. When we train a transfer learning model, we won't do something different. We'll train it as other models.","cb570ab0":"* As you see we have 4096 features before the prediction layer, so we'll add a linear layer (in=4096,out=4)","b2359640":"# Introduction\nHello people, welcome to this kernel. In this kernel we're going to fine tune a pre-trained model using Pytorch. We'll do everything using Pytorch.\n\nIn previous kernel I said I'm planning to switch to Pytorch and now today I'll show you a really important thing, transfer learning.\n\nIf you don't know what is transfer learning let me explain briefly:\n\nTransfer learning is **training a pre-trained model (a model which trained on a big dataset, such as VGG16 model has trained on ImageNet which has 1000 classes and thousands of images.) using our data.** Maybe you can think *but it has 1000 classes and our data does not have 1000 classes*. We'll drop the fully connected layers, only use convolution layers. \n\n# Table of Content\n1. Preparing Environment\n1. Preparing Data\n1. Preparing VGG16\n1. Training VGG16\n1. Conclusion\n"}}