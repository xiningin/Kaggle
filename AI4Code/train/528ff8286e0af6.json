{"cell_type":{"e68ff3fd":"code","5c20098f":"code","6e40d26d":"code","f28f4369":"code","4a383b24":"code","c2e5ecb4":"code","d365a267":"code","e5d7af72":"code","f65cd00e":"code","b09bd432":"code","8f2ec99b":"code","867f0af2":"code","a8d0d23c":"code","72d64c0b":"code","68a78403":"code","06f01d89":"code","93dc218f":"code","d809f50c":"code","53e09819":"code","1acaf689":"code","369f6da9":"code","b3cce120":"code","aac6fae5":"code","505b9f65":"code","a35e76e0":"code","691f8b94":"code","055f3fea":"code","017853ba":"code","35717d60":"code","d2446b40":"code","30e519d6":"code","0479e351":"code","5811d096":"code","d6402269":"code","a5a7fc76":"code","bdebeafa":"code","843e5152":"code","a8a80ee1":"markdown","2398c4f5":"markdown","49b0b555":"markdown","c8204dce":"markdown","053fa3fa":"markdown","5468c658":"markdown","7e13ebb6":"markdown","db051021":"markdown","b5536b05":"markdown","4cb424be":"markdown","6e9c2978":"markdown","f3314a12":"markdown","0d06aa66":"markdown","3876e0e9":"markdown"},"source":{"e68ff3fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5c20098f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","6e40d26d":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine=[train_df,test_df]","f28f4369":"train_df.columns","4a383b24":"train_df.head()","c2e5ecb4":"sns.heatmap(train_df.isnull(),cbar=False,yticklabels=False)","d365a267":"train_df.info()\nprint('-'*50)\ntest_df.info()","e5d7af72":"train_df.describe()\n","f65cd00e":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","b09bd432":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","8f2ec99b":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","867f0af2":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","a8d0d23c":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","72d64c0b":"sns.countplot(x='Survived',data=train_df,hue='Pclass')","68a78403":"sns.countplot(x='SibSp',data=train_df)","06f01d89":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass',y='Age',data=train_df)","93dc218f":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","d809f50c":"guess_ages = np.zeros((2,3))\nguess_ages","53e09819":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                        'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","1acaf689":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","369f6da9":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","b3cce120":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","aac6fae5":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","505b9f65":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n","a35e76e0":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","691f8b94":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","055f3fea":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","017853ba":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","35717d60":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","d2446b40":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","30e519d6":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(5)","0479e351":"train_df = train_df.drop(['Ticket', 'Cabin','Name'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin','Name'], axis=1)\ncombine = [train_df, test_df]","5811d096":"train_df = train_df.drop(['PassengerId'], axis=1)","d6402269":"from sklearn.ensemble import RandomForestClassifier","a5a7fc76":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape\n","bdebeafa":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","843e5152":"my_submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nmy_submission.to_csv('submission.csv', index=False)\nY_pred","a8a80ee1":"Exploring the  data types","2398c4f5":"Now we iterating sex(0,1) and pclass(1,2,3) to find the missing the data of the age .","49b0b555":"**Here we can see that class 1 passengers had the highest survival rate where as lowest class had the lowest survival rate**","c8204dce":"# Analyzing the data\ngetting all the features names","053fa3fa":"**Creating new features from the existing features**","5468c658":"**Which features contain blank or null values**","7e13ebb6":"Importing our random classifier and predicting the new labels.","db051021":"Our main goal is to identify the relationship between our output(Survived) using features(Gender, Age, Port...)","b5536b05":"**Converting into categorical features**","4cb424be":"**Analyzing which features have the most effect on survival rate**","6e9c2978":"**Most of the survivors were female**","f3314a12":"# Analyzing by visualizing data\nWe can confirm some of our assumptions using visualization.\n","0d06aa66":"Importing all the major libraries which are required for data visualization and analysis as well as for linear algebra.","3876e0e9":"**Exploring the categorical as well as numerical features and distinguishing between them**"}}