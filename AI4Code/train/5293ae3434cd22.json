{"cell_type":{"6a7e419e":"code","9ce7f5ba":"code","f19ec49c":"code","426ba4bd":"code","4201f22d":"code","92ce0bcd":"code","fca02734":"code","e79617a8":"code","051a02c0":"code","bcbbd446":"code","b82758cb":"code","b959757c":"code","44db21e8":"code","419b3886":"code","781dcb8f":"code","f5c6a290":"code","40acb0c5":"code","90fa843a":"code","46e2afc1":"code","4e15becb":"markdown","7ba55ea2":"markdown","854cc606":"markdown","99883018":"markdown","079e77ed":"markdown","80ec9a8f":"markdown","ace6a680":"markdown","6052e0ea":"markdown","904c8a99":"markdown","f54f5af9":"markdown","4fe2a927":"markdown","07ea79d9":"markdown","dbd6db07":"markdown","4c37d99b":"markdown","4754a372":"markdown","8d99b8b7":"markdown"},"source":{"6a7e419e":"# Importing Libraries\nimport numpy as np \nimport pandas as pd \nimport cv2\npd.set_option('display.max_colwidth', None)\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing.image import ImageDataGenerator\nimport matplotlib.image as mpimg\nfrom tqdm.notebook import tqdm\nprint(\"packages imported.\")","9ce7f5ba":"# Input\nstanford_data_path = 'Car Images\\\\' # This folder contains train and test images of orginial stanford 196cars dataset\ntrain_df_path      = \"Annotations\\Train Annotations.csv\"\ntest_df_path       = \"Annotations\\Test Annotation.csv\"\n\n# output\naugment_path        = \"Augmented_Balanced_Stanford_Car_Images_Uncropped\\\\\"\n\ntrain_out_path  = augment_path + 'Train_Augmented_Images'\nval_out_path    = augment_path + 'Validation_Augmented_Images'\ntest_out_path   = augment_path + 'Test_Images'\n\nlist_path = [train_out_path ,val_out_path,test_out_path]\n\nprint('inputs and outputs defined')","f19ec49c":"base_path_train = stanford_data_path + 'Train'\n\nimage_folders = []\n\nsplit_position = len(base_path_train.split('\\\\'))\n\nfor dirname, _, _ in os.walk(base_path_train):\n    image_folders.append(dirname)\n\nimage_folders.remove(base_path_train)    \ntrain_image_folders = []\nfor folder in image_folders:\n    temp = folder.split('\\\\')[split_position]\n    train_image_folders.append(temp)\n\nprint(len(train_image_folders))\nprint(\"Image folders Name Created\")# This contains 196 folder names","426ba4bd":"# Creating the directory structure\ntry:\n    # Create Parent folder\n    os.mkdir(augment_path)\n\nexcept:\n    print(\"Folder already exists\")\n    \n# Create child folders\nfor aug_image_path in list_path:\n    try:\n        os.mkdir(aug_image_path)\n    except:\n        print('Check if folder already exists')\n\n    for folder in train_image_folders:\n        try:\n            os.mkdir(aug_image_path + '\/'+ folder)\n        except:\n            pass\n    print('all done')","4201f22d":"train_df = pd.read_csv(train_df_path)\ntest_df  = pd.read_csv(test_df_path)\n\noriginal_col_names = train_df.columns\ncol_names          = ['Image Name', 'bb_start_x', 'bb_start_y', 'bb_end_x', 'bb_end_y', 'Image class']\nreplace_dict       = {}\nfor k,v in zip(original_col_names, col_names):\n    replace_dict[k] = v\n\ntrain_df.rename(columns = replace_dict, inplace = True)\ntrain_df.drop(col_names[1:-1], axis = 1, inplace = True)\n\ntest_df.rename(columns = replace_dict, inplace = True)\ntest_df.drop(col_names[1:-1], axis = 1, inplace = True)\n\ndisplay(train_df.head(2),test_df.head(2))","92ce0bcd":"# The images are in different folders. Let's get the path to all images into one column\n\ndef change_path(path):\n    newPath = path.replace(os.sep, '\/')\n    return newPath\n\ndef path_finder(df,split,verbose = True):\n    \"\"\"\n    Pass the Dataframe\n    Use split to define - 'Train' or 'Test' Images\n    This function is used to add the filepath of each images in train and test folder\n    \"\"\"\n    \n    base_path = stanford_data_path + split\n    print(\"Working on: \",base_path);print()\n    image_paths = {os.path.basename(x): x for x in glob(os.path.join(base_path, '*', '*.jpg'))}\n    df['Filepath'] = df['Image Name'].map(image_paths.get)\n    df['Filepath'] = df['Filepath'].apply(change_path)\n    \n    print('Found:', len(image_paths), 'images. DataFrame Updated');print()\n    print(f'Nulls in DataFrame : {df.isnull().sum().sum()}');print()\n    if verbose:\n        display(df.head(2))\n    #return image_paths\nprint(\"*path_finder* is ready\")\n\n\npath_finder(train_df,'Train')\npath_finder(test_df,'Test')","fca02734":"from sklearn.model_selection import train_test_split\n\ntrain_data , valid_data = train_test_split(train_df,test_size = 0.33 , random_state = 42 , stratify = train_df['Image class'])\n\ndisplay(train_data.shape , valid_data.shape , train_data['Image class'].value_counts() , valid_data['Image class'].value_counts())","e79617a8":"def show_images(images, cols = 1, titles = None):\n    \"\"\"Display a list of images in a single figure with matplotlib.\n    \n    Parameters\n    ---------\n    images: List of np.arrays compatible with plt.imshow.\n    \n    cols (Default = 1): Number of columns in figure (number of rows is \n                        set to np.ceil(n_images\/float(cols))).\n    \n    titles: List of titles corresponding to each image. Must have\n            the same length as titles.\n    \"\"\"\n    assert((titles is None) or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure(figsize=(15,15))\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images\/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image)\n       \n        a.set_title(title)\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()","051a02c0":"import albumentations as A\n\n# Declare an augmentation pipeline\ntransform = A.Compose([\n                            A.HorizontalFlip(p=0.5),\n                            A.RandomBrightnessContrast(p=0.1, brightness_limit=0.1,contrast_limit=0.1),\n                            A.RandomGamma(gamma_limit=(90, 110), p=0.2),\n                            A.Rotate(limit = 5, p=0.9),\n                            A.RGBShift(p=0.2),\n                            A.GaussNoise(p=0.1),\n                            A.ChannelShuffle(p=0.2),\n                            A.ToGray(p=0.1),\n                            A.MedianBlur(p=0.1),\n                            A.CLAHE(p=0.1),\n                            A.JpegCompression(quality_lower=70, p=0.1)\n                    ])\n\ndef albu_gen(image, num = 3):\n    if num < 1 :\n        num = 1\n    albu_trans_img = []\n    for i in range(num):\n        transformed       = transform(image=image)\n        albu_trans_img.append(transformed[\"image\"])   \n\n    return albu_trans_img","bcbbd446":"img  = mpimg.imread(train_df.loc[1,'Filepath'])\nimg_ = albu_gen(img)\nshow_images(img_)","b82758cb":"####################################\nprefix_dict = { 'Test_Images'                 : 'Test_',\n                'Train_Augmented_Images'      : 'Train_',\n                'Validation_Augmented_Images' : 'Val_'}\n####################################\n\ndef save_img(img_array,filepath, aug_subfolder):\n    \"\"\"\n    1. Count images in img_array , create new outpath using filepath\n    2. save images to specific folder\n    \"\"\"\n    \n    prefix = prefix_dict[aug_subfolder]\n    f1     = filepath.split('\/')[split_position]\n    f2     = filepath.split('\/')[split_position+1]\n    \n    for n in range(len(img_array)):\n        pad    = ''  \n        if n < 9:\n            pad = '0'\n        outpath = augment_path + aug_subfolder + '\/' + f1 + '\/'+ prefix + pad + str(n+1) + '_' + f2\n        plt.imsave(outpath, img_array[n])\n","b959757c":"# To balance the classes in the output, we will need to augment the underrepresented classes more.\n# Therefore we need a inverse frequency number attached to each image, to reflect how common or uncommon that class is\n# This has to be done for each of the three dataframes\n\ndef inverse_frequency_calculations(df):\n    temp = df.copy()\n    class_dict = dict(temp['Image class'].value_counts())\n    temp['Inverse_frequency']  =  temp['Image class'].apply(lambda x: 1.0\/class_dict[x])\n    temp = temp.reset_index(drop=True)\n    return temp","44db21e8":"train_data = inverse_frequency_calculations(train_data)\nvalid_data = inverse_frequency_calculations(valid_data)\ntest_df    = inverse_frequency_calculations(test_df)\ndisplay(train_data.head(2))\ndisplay(valid_data.head(2))\ndisplay(test_df.head(2))","419b3886":"def auto_preprocess(data, num, aug_subfolder, partial = True):\n    '''\n    data          : a dataframe that contains filepaths from which to read images, create outpaths, augment and save\n    num           : the target number of images for each class. Pass -1 for no augmentation.\n                    for augmentation, always pass a number more than the highest class frequency. Using a least common\n                    multiple of the top few class frequencies will work the best. Higher numbers will achieve better balance\n                    than lower numbers.\n    aug_subfolder : name of the folder to which the augmented images will be saved\n    crop          : boolean, whether to crop or not\n    partial       : boolean, whether to run on the first five rows only, to test. \n    \n    returns a dictionary containing the number of images per class that form the final output \n    '''\n\n    # deciding if we want to make a test run\n    if partial:\n        data_under_process = data.head(2).copy().reset_index(drop = True)\n        display(data_under_process)\n        print('Running in the partial, diagnostic mode')\n    else:\n        data_under_process = data.copy().reset_index(drop = True)\n        \n    if num == -1:\n        print('No image augmentation is being done.')\n       \n    # creating a dictionary to keep tabs on how many images we are creating\n    uniks = data_under_process['Image class'].unique()\n    uniks.sort()\n    class_dict = dict()\n    for i in uniks:\n        class_dict[i] = 0  # initializing\n        \n    # the run through the dataframe\n    problem_images = []\n\n    for idx in tqdm(range(len(data_under_process))):\n        path     = data_under_process.loc[idx,'Filepath']\n        img      = mpimg.imread(path)\n        im_class = data_under_process.loc[idx,'Image class']\n        count    = int(num*data_under_process.loc[idx,'Inverse_frequency'])\n        if count < 1:\n            count = 1 # augmentation will return atleast one image, even if called with zero or a negative number. \n        class_dict[im_class] += count \n                   \n        if num != -1:\n            try:\n                img_ = albu_gen(img, count)          # this will generate required number of augmented images\n            except:\n                img_ = [img]\n        else:\n            img_ = [img]\n            \n        try:\n            save_img(img_, path, aug_subfolder) # will internally create the path to which the file needs to be written\n        except:\n            problem_images.append(idx)\n            \n    # reporting        \n    print(f'A total of {sum(class_dict.values())} images are now present in {aug_subfolder}')\n    print(f'There are {len(problem_images)} problem_images')\n\n    if len(problem_images):\n        print(problem_images)\n    return class_dict     \n### END OF FUNCTION ###\n\n# testing with partial = True\naug_subfolder   = 'Train_Augmented_Images'\n_ = auto_preprocess(train_data, 1000, aug_subfolder, partial = True)\n_","781dcb8f":"# TEST IMAGES\naug_subfolder   = 'Test_Images'\nclass_dict_test = auto_preprocess(test_df, -1, aug_subfolder, partial = False)","f5c6a290":"# VALIDATION IMAGES\naug_subfolder   = 'Validation_Augmented_Images'\nclass_dict_val   =  auto_preprocess(valid_data, 150, aug_subfolder, partial = False)","40acb0c5":"# TRAIN IMAGES\naug_subfolder   = 'Train_Augmented_Images'\nclass_dict_Train  =  auto_preprocess(train_data, 450, aug_subfolder, partial = False)","90fa843a":"print('All done')","46e2afc1":"# we can check the mean, minimum and maximum number of images per class\n\nto_check = class_dict_val\nprint('mean:', np.mean([x for x in to_check.values()]))\nprint('max :',  np.max([x for x in to_check.values()]))\nprint('min :',  np.min([x for x in to_check.values()]))","4e15becb":"**All the best. If you enjoyed the workflow, do please upvote. Thank you.**","7ba55ea2":"# Actual Image Process calls","854cc606":"## saving images","99883018":"## train val split","079e77ed":"# Path Finder on Train and Test Df","80ec9a8f":"# Generate 196 folders names for train,val,test folders","ace6a680":"# IMPORT Libraries","6052e0ea":"# balancing the classes","904c8a99":"# Read Train and Test Dataframes","f54f5af9":"# auto_preprocess","4fe2a927":"To generate this augmented dataset, you will need train and test images from the Stanford Cars Dataset.<br>\nThese images are included in the input data for this notebook.<br>\nAlternatively, they can be downloaded directly from the stanford site - link below.<br>\nFinal Output images are also available attached to this notebook.<br><br>\nAll images are available only for non-commercial, research purposes.<br>\n\n**ATTENTION: This notebook was run on a local machine Jupyter Notebook to create the dataset. It may not run on other platforms<br>\nsuch as Kaggle or Colab, because of directory structure restrictions.**\n\n\n\nhttps:\/\/ai.stanford.edu\/~jkrause\/cars\/car_dataset.html\n\n\n>https:\/\/www.kaggle.com\/saurabhsawhney\n\n>https:\/\/www.kaggle.com\/ameyapat\n\n>https:\/\/www.kaggle.com\/mewtyunjay\n\n>https:\/\/www.kaggle.com\/muraligollapudi\n\n>https:\/\/www.kaggle.com\/rohithandagl\n\n","07ea79d9":"## Show Images function","dbd6db07":"# Make Folders For Train\/Val\/Test-Crop_uncrop - Blank folders","4c37d99b":"# Define Global Paths","4754a372":"# Image Processing Functions","8d99b8b7":"## albu_gen"}}