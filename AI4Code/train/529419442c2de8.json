{"cell_type":{"5a551a8f":"code","c1dd573a":"code","8a5397f9":"code","5160ec8f":"code","bacdccc4":"code","a9b1dd0d":"code","0229b52b":"code","77c71b65":"code","35d8497a":"code","2e2021d4":"code","f0b59ebd":"code","4e32dec8":"code","047c719a":"code","5ff5788c":"code","569f0d32":"code","2271d6a7":"code","702e1fd4":"code","e1727530":"code","6bfc90f8":"markdown","a5367e02":"markdown","300f3a54":"markdown","5eb17b9b":"markdown","93bee11f":"markdown","c43e26aa":"markdown"},"source":{"5a551a8f":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\n\nfrom keras.models import Model","c1dd573a":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission = submission.set_index('id')","8a5397f9":"train.head()","5160ec8f":"print(f'Number of rows: {train.shape[0]};  Number of columns: {train.shape[1]}; No of missing values: {sum(train.isna().sum())}')","bacdccc4":"print(f'Number of rows: {test.shape[0]};  Number of columns: {test.shape[1]}; No of missing values: {sum(test.isna().sum())}')","a9b1dd0d":"train.info()","0229b52b":"train.describe()","77c71b65":"target_mass = train['target'].value_counts()\nvalues = target_mass.values.tolist()\nindexes = target_mass.index.tolist()\n\nax,fig = plt.subplots(1,2,figsize=(15,6))\nplt.subplot(1,2,1)\nplt.pie(values , labels = indexes)\nplt.subplot(1,2,2)\nplt.bar(indexes,values)\nplt.show()","35d8497a":"fet_set = train.drop(labels=['id','target'],axis=1)\ndef plot_diag_heatmap(data):\n    corr = data.corr()\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    f, ax = plt.subplots(figsize=(11, 9))\n    sns.heatmap(corr, mask=mask, cmap='YlGnBu', center=0,square=True, linewidths=1, cbar_kws={\"shrink\": 1.0})\nplot_diag_heatmap(fet_set)","2e2021d4":"train1 = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv', index_col = 'id')\ntest1 = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv', index_col = 'id')\nx_cols = train1.columns[0:-1].tolist()\ny_col = train1.columns[-1]","f0b59ebd":"import plotly.express as px\n\ntarget_column = 'target'\nnum_rows, num_cols = 15,5\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(30, 60))\n\nfor index, column in enumerate(x_cols):\n    i,j = (index \/\/ num_cols, index % num_cols)\n\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_1', column], color=px.colors.qualitative.G10[1], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_2', column], color=px.colors.qualitative.G10[2], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_3', column], color=px.colors.qualitative.G10[9], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_4', column], color=px.colors.qualitative.G10[4], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_5', column], color=px.colors.qualitative.G10[5], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_6', column], color=px.colors.qualitative.G10[6], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_7', column], color=px.colors.qualitative.G10[7], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_8', column], color=px.colors.qualitative.G10[8], shade=True, ax=axes[i,j])\n    sns.kdeplot(train1.loc[train1[target_column] == 'Class_9', column], color=px.colors.qualitative.G10[3], shade=True, ax=axes[i,j])\nplt.tight_layout()\nplt.show()","4e32dec8":"targets = pd.get_dummies(train['target'])","047c719a":"def custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss\n\ncce = tf.keras.losses.CategoricalCrossentropy()\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor='val_custom_metric', min_delta=1e-05, patience=5, verbose=0,\n    mode='min', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_custom_metric', factor=0.7, patience=2, verbose=0,\n    mode='min')","5ff5788c":"def conv_model():\n\n    conv_inputs = layers.Input(shape = (75))\n    embed = layers.Embedding (input_dim = 354, \n                              output_dim = 7,\n                              embeddings_regularizer='l2')(conv_inputs)\n    embed = layers.Conv1D(12,1,activation = 'relu')(embed)        \n    embed = layers.Flatten()(embed)\n    hidden = layers.Dropout(0.3)(embed)\n    \n    hidden = tfa.layers.WeightNormalization(\n                layers.Dense(\n                units=32,\n                activation ='relu',\n                kernel_initializer = \"lecun_normal\"))(hidden)\n    \n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden]))\n    output = tfa.layers.WeightNormalization(\n    layers.Dense(\n                units = 32,\n                activation='relu',\n                kernel_initializer = \"lecun_normal\"))(output) \n    output = layers.Dropout(0.4)(layers.Concatenate()([embed, hidden, output]))\n    output = tfa.layers.WeightNormalization(\n    layers.Dense(\n                units = 32, \n                activation = 'relu',\n                kernel_initializer = \"lecun_normal\"))(output)\n    \n    conv_outputs = layers.Dense(\n                units = 9, \n                activation ='softmax',\n                kernel_initializer =\"lecun_normal\")(output)\n    \n    model = Model(conv_inputs,conv_outputs)\n    \n    return model","569f0d32":"oof_NN_a = np.zeros((train.shape[0],9))\npred_NN_a = np.zeros((test.shape[0],9))\n\nN_FOLDS = 25\nSEED = 2021\nEPOCH = 75\n\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train,train.iloc[:,-1])):\n    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n\n    X_train = train.iloc[:,1:-1].iloc[tr_idx]\n    y_train = targets.iloc[tr_idx]\n    X_test = train.iloc[:,1:-1].iloc[ts_idx]\n    y_test = targets.iloc[ts_idx]\n\n    K.clear_session()\n    \n    print(\"\\n-----Convolution model Training----\\n\")\n\n    model_conv = conv_model()\n\n    model_conv.compile(loss='categorical_crossentropy', \n                            optimizer = keras.optimizers.Adam(learning_rate=2e-4), \n                            metrics=custom_metric)\n    model_conv.fit(X_train, y_train,\n              batch_size = 256, epochs = EPOCH,\n              validation_data=(X_test, y_test),\n              callbacks=[es, plateau],\n              verbose = 0)\n   \n    pred_a = model_conv.predict(X_test) \n    oof_NN_a[ts_idx] += pred_a \n    score_NN_a = log_loss(y_test, pred_a)\n    print(f\"\\nFOLD {fold} Score convolution model: {score_NN_a}\\n\")\n    pred_NN_a += model_conv.predict(test.iloc[:,1:]) \/ N_FOLDS \n \nscore_a = log_loss(targets, oof_NN_a)\nprint(f\"\\n=== FINAL SCORE CONVOLUTION MODEL : {score_a}===\\n\")","2271d6a7":"pred_embedding = pred_NN_a","702e1fd4":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission['Class_1']=pred_embedding[:,0]\nsubmission['Class_2']=pred_embedding[:,1]\nsubmission['Class_3']=pred_embedding[:,2]\nsubmission['Class_4']=pred_embedding[:,3]\nsubmission['Class_5']=pred_embedding[:,4]\nsubmission['Class_6']=pred_embedding[:,5]\nsubmission['Class_7']=pred_embedding[:,6]\nsubmission['Class_8']=pred_embedding[:,7]\nsubmission['Class_9']=pred_embedding[:,8]","e1727530":"submission.to_csv(\"Solution.csv\", index=False)","6bfc90f8":"# Target Distribution","a5367e02":"Refrence notebook - https:\/\/www.kaggle.com\/pourchot\/simple-neural-network","300f3a54":"# Version 3 : LightAutoML\n# Version 6 : Neural Network ","5eb17b9b":"# EDA","93bee11f":"# Correlation","c43e26aa":"# Checking null values"}}