{"cell_type":{"5e48ac4b":"code","81457446":"code","48215627":"code","2f3e814c":"code","764a77f0":"code","7ba96fa1":"code","56c0bbf8":"code","dd9c5f05":"code","b8a11993":"code","6f04ad92":"code","a346e8ce":"code","51483bae":"code","4dbb71f8":"code","f7f813e8":"code","046488a3":"code","4f0d2ee0":"code","70dc4cc4":"code","16f2026c":"code","c8a68c0c":"code","dfd7e022":"code","7838b607":"code","09a085f0":"code","b9179700":"code","5b211da1":"code","cef6fbdb":"code","e40e9e56":"code","62e9e752":"code","0617b2fd":"code","6e64817b":"code","6706a19b":"markdown","a10c012d":"markdown","c16e17fd":"markdown","ffc0f35f":"markdown","b5f08a8a":"markdown","45ccba8f":"markdown","bdc0f299":"markdown","bd17f517":"markdown","ab983214":"markdown","629173b7":"markdown","6a17fabb":"markdown"},"source":{"5e48ac4b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\n\nimport tensorflow as tf\nfrom tqdm import tqdm\n\nimport numpy as np #\nimport pandas as pd \n\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\nfrom keras.utils import to_categorical\n# from keras import regularizers\nfrom tensorflow.keras.models import Model\n\n\nfrom keras.preprocessing.image import load_img\n","81457446":"#reading labels csv file\n\nlabels = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\nlabels.head()","48215627":"# Describing the labels \nlabels.describe()","2f3e814c":"# Showing the CSV as a bar graph\ndef barg(ax):\n    for p in ax.patches:\n        val = p.get_width()  # Height of the Bar\n        x = p.get_x() + p.get_width() # x position\n        y = p.get_y() + p.get_height() \/ 2 # y postion\n        ax.annotate(round(val,2),(x,y))\n        \nplt.figure(figsize = (15,30))\nax0 =sns.countplot(y=labels['breed'],order=labels['breed'].value_counts().index)\nbarg(ax0)\nplt.show()","764a77f0":"# no of unique breeds \nlabels['breed'].nunique()","7ba96fa1":"# testing one picture \nfrom IPython.display import display, Image \nImage('..\/input\/dog-breed-identification\/train\/001513dfcb2ffafc82cccf4d8bbaba97.jpg')","56c0bbf8":"# Alphabetically sorting labels and putting it into a list \nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)  # no of unique breeds\nprint(\"Total unique breed: {}\".format(n_classes))\n\n# Now to map each label string to an integer label for easy use \n# To do this we create a dict\nclass_to_num = dict(zip(classes, range(n_classes)))\n\n# testing the dict\nclass_to_num","dd9c5f05":"# Since the output of our predictor for each input is a vector of probabilities for each class we must, \n# convert out label dataset to be the same format, \n# for this we will use one hot encoding.\n\ninput_shape = (331,331,3)  # numbers are specific to each keras model\n\n# maps each image and breed of the image to a numpy array\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    # passes the input shape and all 10222 images from the dataset from the label.csv file\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) \n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    # as we have huge data and limited ram memory. uint8 takes less memory\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')  # creates directory of each image\n        img = load_img(img_dir, target_size = target_size)  # reading the image\n\n        images[ix]=img  # saving the image with respect to its id\n        del img  # frees memory\n        \n        dog_breed = image_labels[ix]   # getting breed info for the img\n        y[ix] = class_to_num[dog_breed]  # converting breed info to a numerical value \n    \n    y = to_categorical(y)  # converting target variable to a one hot encoded matrix     \n    \n    return images,y","b8a11993":"# Calling the previous cell\nimport time \nt = time.time()\n\nX,y = images_to_array('\/kaggle\/input\/dog-breed-identification\/train', labels[:])\n\nprint('runtime in seconds: {}'.format(time.time() - t))","6f04ad92":"# To test the previous function, I will now print some images with their breed info from the train folder\n\nn = 25\n\nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n    x = plt.subplot(5, 5, i+1)\n    plt.title(classes[np.where(y[i] ==1)[0][0]])\n    plt.imshow(X[i].astype('int32')) # converting to int as imshow() needs integer data to read the image","a346e8ce":"# Learning Rate Annealer automatically reduces learning rate when a metric has stopped improving. \n# by monitoring the validation accuracy\nlrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1) \n\n# Prepare call backs\n# Monitors validation loss and stops the training if nothing significant is happening \nEarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","51483bae":"# Creating hyperparameters\nbatch_size = 128\nepochs = 50\nlearn_rate = .001\n# creating optimizers \nsgd = SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam = Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)","4dbb71f8":"# Function to extract features from the dataset by a given pretrained model\nimg_size = (331,331,3)\n\n# the name of each model is passed along with its preprocessor unit and an input size and some data\ndef get_features(model_name, model_preprocessor, input_size, data):\n    \n    # The data enters the input layer with the dimention of input size \n    input_layer = Input(input_size)\n    # On the input layer I apply the preprocessor to create the required preprocessed input \n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    # The model now extracts features from the preprocessed input \n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    # I apply globalaveragepooling to the output to average all values\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    # Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","f7f813e8":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X)","046488a3":"from keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, X)","4f0d2ee0":"from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, X)","70dc4cc4":"from keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_features(NASNetLarge,\n                               nasnet_preprocessor,\n                               img_size, X)","16f2026c":"del X  # To free up some ram as its not needed seeing as the feature map has been made \ngc.collect()","c8a68c0c":"final_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features,], axis=-1)  # axis=-1 to concatinate horizontally\n\nprint('Final feature maps shape', final_features.shape)","dfd7e022":"# Prepare Deep net\nmodel = Sequential()\nmodel.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\nmodel.add(Dense(n_classes,activation= 'softmax'))\n\nmodel.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Training the model. \nhistory = model.fit(final_features, y,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2,\n            callbacks=[lrr,EarlyStop])","7838b607":"# Deleting to free up ram memory\n\ndel inception_features\ndel xception_features\ndel nasnet_features\ndel inc_resnet_features\ndel final_features\ngc.collect()","09a085f0":"# Function to read images from test directory\n# This is the same as the previous images_to_array function but now applied to test data\n\ndef images_to_array_test(test_path, img_size = (331,331,3)):\n    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\n    data_size = len(test_filenames)\n    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    \n    for ix,img_dir in enumerate(tqdm(test_filenames)):\n        img = load_img(img_dir, target_size = img_size)\n        images[ix]=img\n        del img\n    print('Ouptut Data Size: ', images.shape)\n    return images\n\ntest_data = images_to_array_test('\/kaggle\/input\/dog-breed-identification\/test\/', img_size)","b9179700":"# Extract test data features.\ndef extact_features(data):\n    # Getting Inception features\n    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n    # Getting Xception features\n    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n    # Getting NASNetLarge features\n    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n    # Getting InceptionResNet features\n    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n\n    # Concatenating all features\n    final_features = np.concatenate([inception_features,\n                                     xception_features,\n                                     nasnet_features,\n                                     inc_resnet_features],axis=-1)\n    \n    print('Final feature maps shape', final_features.shape)\n    \n    #deleting to free up ram memory\n    del inception_features\n    del xception_features\n    del nasnet_features\n    del inc_resnet_features\n    gc.collect()\n    \n    \n    return final_features\n\ntest_features = extact_features(test_data)","5b211da1":"#Free up some space.\ndel test_data\ngc.collect()","cef6fbdb":"#Predict test labels given test data features.\npred = model.predict(test_features)","e40e9e56":"# First prediction\nprint(pred[0])\n# The max probability value predicted by the model\nprint(f\"Max value (probability of prediction): {np.max(pred[0])}\") \n\n# Because we used softmax activation in our model, this will be close to 1\nprint(f\"Sum: {np.sum(pred[0])}\") \n\n# The index of where the max value in predictions[0] occurs\nprint(f\"Max index: {np.argmax(pred[0])}\") \nprint(f\"Predicted label: {classes[np.argmax(pred[0])]}\")","62e9e752":"# Create pandas DataFrame with empty columns\npreds_df = pd.DataFrame(columns=[\"id\"] + list(classes))\npreds_df.head()","0617b2fd":"# Append test image ID's to predictions DataFrame\ntest_path = \"\/kaggle\/input\/dog-breed-identification\/test\/\"\npreds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","6e64817b":"preds_df.loc[:,list(classes)]= pred\n\npreds_df.to_csv('result.csv',index=None)\npreds_df.head()","6706a19b":"# Creating a file for all the predictions","a10c012d":"### Xception","c16e17fd":"### NASNetLarge","ffc0f35f":"# Creating the Neural net","b5f08a8a":"## Combining all the feature maps","45ccba8f":"### InceptionV3","bdc0f299":"# Creating Callbacks","bd17f517":"# Model Building \n### * The basic idea here is to extract features from the data set from pretrained models and create a simple deep net by using all those features combined.\n### * So we will use **GlobalAveragePooling2D** to extract a pooled output from our selected models\n### * Models I will use:\n###   1. **Inception**\n###   2. **Xception**\n###   3. **NASNETLarge**\n###   4. **InceptionResnetV2**\n### * Using these models I will extract features and combine them to create a combines feature map\n### * I will then feed this feature map to a neural net with an inputlayer and a softmax layer\n### * As a softmax layer is used, the loss function generated will be Categorical Cross Entropy\n### * This will lead to an output","ab983214":"### InceptionResNetV2","629173b7":"### As we are useing a Softmax layer, the loss function used is **Categorical Cross Entropy**. Below is the formala\n![image.png](attachment:b886ceac-8ed9-4b00-8ba3-a3e9e5ab290b.png)\n\n### where, $ y_{i} $ is the observed data and, $\\hat{y}_{i}$ is the predicted value ","6a17fabb":" # Importing Libraries and Testing and Loading the Dataset"}}