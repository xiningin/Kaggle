{"cell_type":{"6f582d6c":"code","bca370c7":"code","5ef4bbff":"code","53537634":"code","42b5e07a":"code","7cdc94e3":"code","82f52e1f":"code","b661570e":"code","8aa4864b":"code","f7524a6a":"code","65c6f85f":"code","2242f272":"code","58dd2679":"code","152b0d79":"code","0aa9ee3c":"code","daaead36":"code","a9a5fc26":"code","caba680a":"code","01d2d0c8":"code","430bc303":"code","0c7161ae":"code","9c0f2b90":"code","3a1abc1d":"code","98a61074":"code","3f26ffc1":"code","ee0fab73":"code","6cbafc6c":"code","70ca14a7":"code","c37be2d9":"code","9b8c2fc7":"code","1d79defc":"code","4f8deab5":"code","2254ab28":"code","25177948":"code","f18df4ff":"code","786fde00":"code","a7f8540d":"code","baf51374":"code","722a5ccb":"code","60d990cc":"code","7a83d3ad":"code","2e1bcae2":"code","dc72d1c7":"code","47be6bb4":"code","d41d9963":"code","a42d716c":"code","1c9a6e33":"code","7fb54631":"code","3b090d74":"code","522fef44":"code","4018df50":"code","d7d3b85b":"code","bf9fcef3":"code","a7f47253":"code","2de88b5b":"code","27cc327b":"code","84cc3919":"code","c43f8a8d":"code","905dcb17":"code","ffa3bb82":"code","426575a5":"code","9da13cb5":"code","2a11be1e":"code","b7fd1cf9":"code","889cb2c7":"code","5f239f18":"code","30fab931":"code","eca88822":"code","708b8bc2":"code","8426b98e":"code","a6267225":"code","c988907b":"code","9c198f51":"code","1cf84afb":"code","20f37ce8":"code","b2a69a3d":"code","0fe45676":"code","bd8cab11":"code","bba40c3a":"code","39fe68aa":"code","3771110e":"code","9c117c01":"code","e6b38201":"code","17f48fd0":"code","69e2c21a":"code","160395f6":"code","d2b7a085":"code","07e18de1":"code","28d198e7":"code","580c6cfc":"code","cc5863dc":"code","05aaa7e0":"code","02689667":"code","a4a69be9":"code","6d97f842":"code","9c492d8c":"code","a9d23fe7":"code","174461ab":"code","3bd4844b":"code","bbc93715":"code","b10b3ebe":"code","d17b166d":"code","960df5aa":"code","91a309b5":"code","85e3a091":"code","913667cd":"code","7267e10e":"code","d42488ff":"code","12d5935f":"code","8cc9a15b":"code","113032ed":"code","6982a74a":"code","c4a01c38":"code","5f5c751d":"markdown","59f0a02e":"markdown","e223ccdc":"markdown","d3e10d65":"markdown","88974e9e":"markdown","755dbc1a":"markdown","ed4476d9":"markdown","4b8441ed":"markdown","e058151d":"markdown","352ee282":"markdown","e22102d9":"markdown","158097f2":"markdown","e4ccdd93":"markdown","19178a24":"markdown","3515ae40":"markdown","a146dd86":"markdown","da072bef":"markdown","4ea97b74":"markdown","5b1e71b6":"markdown","5839bcce":"markdown","25f8a22d":"markdown","a9217d30":"markdown","b2f89410":"markdown","5109435d":"markdown"},"source":{"6f582d6c":"'''\n# bank client data:\n1 - age (numeric)\n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n5 - default: has credit in default? (categorical: 'no','yes','unknown')\n6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n  - balance: \n# related with the last contact of the current campaign:\n8 - contact: contact communication type (categorical: 'cellular','telephone')\n9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n10 - day: last contact day \n11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n# other attributes:\n12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n14 - previous: number of contacts performed before this campaign and for this client (numeric)\n15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n\nOutput variable (desired target):\n21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n'''","bca370c7":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom time import time\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# For the tree visualization\nimport pydot\nfrom IPython.display import Image\nfrom sklearn.externals.six import StringIO","5ef4bbff":"# Importing the dataset\n# Input: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing\nfilename='\/kaggle\/input\/bank-marketing\/bank-full.csv'\ndf = pd.read_csv(filename,sep=',')\norig_df_size = len(df)\nprint(df.info())","53537634":"#helper function\ndef check(df, feature):\n  df_new = df.groupby(feature)['y'].apply(lambda x: x.sum()\/len(x))\n  return df_new","42b5e07a":"df.loc[1:10]","7cdc94e3":"# Convert the result and two other columns to a number\ndf['y'] = df['y'].apply(lambda x: 0 if 'no' in x else 1)\ndf['housing'] = df['housing'].apply(lambda x: 0 if 'no' in x else 1)\ndf['loan'] = df['loan'].apply(lambda x: 0 if 'no' in x else 1)\ndf['default'] = df['default'].apply(lambda x: 0 if 'no' in x else 1)\n","82f52e1f":"#check if data is balanced\nprint(f\"the percentage of y out of all df {(df['y'].value_counts()[1]\/df['y'].value_counts())[0]}\")","b661570e":"# drop of unknown values\norig_len = len(df)\ndf = df[(df.age !='unknown') & (df.job !='unknown') & (df.marital !='unknown') & (df.housing !='unknown') & (df.loan !='unknown') & (df.education != 'unknown')]\nupdated_len = len(df)\nprint(f'df length reduced by {(orig_len-updated_len)\/orig_len*100} from {orig_len} to {updated_len}')","8aa4864b":"df.nunique()","f7524a6a":"df['marital'].value_counts()","65c6f85f":"axis = check(df,'marital').plot(kind=\"bar\")\nfig = axis.get_figure()","2242f272":"df['default'].value_counts()","58dd2679":"axis = check(df,'default').plot(kind=\"bar\")\nfig = axis.get_figure()","152b0d79":"print(df['balance'].min())\nprint(df['balance'].max())","0aa9ee3c":"df['balance_'] = df['balance'] \/\/ 1000\naxis = check(df,'balance_').plot(kind=\"bar\",figsize=(20,5))","daaead36":"#convert duration to minutes\ndf['durationMin'] = df['duration'] \/\/ 60","a9a5fc26":"#check the numbr of 'y' vs. duration\nx1 = (df.groupby('durationMin')['y'].sum()) \/ (df.groupby('durationMin')['y'].count()) * 100\nx1[0:80].plot(kind=\"bar\", figsize=(15, 5))","caba680a":"x2 = df.groupby('durationMin')['y'].count()\nx2.plot(kind=\"bar\", figsize=(15, 5))","01d2d0c8":"len(df[df['durationMin'] > 38]) \/ len(df) * 100","430bc303":"df['age'].hist()","0c7161ae":"axis = check(df,'age').plot(kind=\"bar\", figsize=(20, 5))\nfig = axis.get_figure()","9c0f2b90":"df['job'].value_counts()","3a1abc1d":"axis = check(df,'job').plot(kind=\"bar\", figsize=(15, 5))\nfig = axis.get_figure()","98a61074":"df['education'].value_counts()","3f26ffc1":"df['education'].unique()","ee0fab73":"axis = check(df,'education').plot(kind=\"bar\", figsize=(5, 5))\nfig = axis.get_figure()","6cbafc6c":"axis = check(df,'housing').plot(kind=\"bar\")\nfig = axis.get_figure()","70ca14a7":"axis = check(df,'loan').plot(kind=\"bar\")\nfig = axis.get_figure()","c37be2d9":"df['housing_loan'] = df.apply(lambda x: 1 if (x['loan']==1) | (x['housing']==1) else 0 ,axis=1)\ndf['housing_loan'] = np.where((df['loan']=='yes') | (df['housing']=='no'), 1,0)","9b8c2fc7":"df['month_num'] = df['month']\ndf['month_num'].replace({\"jan\":1,\n                   \"feb\":2, \n                   \"mar\":3, \n                   \"apr\":4, \n                   \"may\":5, \n                   \"jun\":6, \n                   \"jul\":7, \n                   \"aug\":8, \n                   \"sep\":9, \n                   \"oct\":10, \n                   \"nov\":11, \n                   \"dec\":12}, inplace=True)","1d79defc":"axis = check(df,'month_num').plot(kind=\"bar\")\n#fig = axis.get_figure()","4f8deab5":"df['month_num'].value_counts().sort_index()","2254ab28":"axis = check(df,'day').plot(kind=\"bar\", figsize=(20,5))\nfig = axis.get_figure()","25177948":"axis = check(df,'previous').plot(kind=\"bar\",figsize=(15, 5))","f18df4ff":"df['previous'].value_counts().sort_index()","786fde00":"axis = check(df,'poutcome').plot(kind=\"bar\")\nfig = axis.get_figure()","a7f8540d":"df['poutcome'].value_counts()","baf51374":"df_ct = pd.crosstab(columns=df[(df['previous'] != 0) & (df['poutcome'] != 'nonexistent')].previous, \n                          index=df[(df['previous'] != 0) & (df['poutcome'] != 'nonexistent')].poutcome, \n                          normalize='index')\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(ax=ax, data=df_ct, cmap='coolwarm')\n#There is no immidiate conclusion therfore these two feature will remain to be tested later by the model","722a5ccb":"print (len(df.loc[df.pdays==-1]))","60d990cc":"axis = check(df,'campaign').plot(kind=\"bar\", figsize=(15, 5))\nfig = axis.get_figure()","7a83d3ad":"df['campaign'].value_counts()","2e1bcae2":"len(df[df['campaign'] >= 17])","dc72d1c7":" '''\n Conclusions:\n 0   age             41188 non-null  int64 - use  \n 1   job             41188 non-null  object - change to percetage\n 2   marital         41188 non-null  object - use, get_dummies\n 3   education       41188 non-null  object - reduced, used (get_dummies)\n 4   default         41188 non-null  object - dropped\n 5   housing         41188 non-null  object - use \n 6   loan            41188 non-null  object - use\n 7   contact         41188 non-null  object - dropped\n 8   month           41188 non-null  object - use as percentage\n 9   day_of_week     41188 non-null  object - dropped\n 10  duration        41188 non-null  int64 - use  \n 11  campaign        41188 non-null  int64 - use, remove outliers \n 12  pdays           41188 non-null  int64 - Too many unknown values, dropped\n 13  previous        41188 non-null  int64 - use (consider reduce to 0,1,2,>=3) (correlate to poutcome?)\n 14  poutcome        41188 non-null  object - get dummies, use (correlate to previous?)\n 15  balance                                - drop\n'''","47be6bb4":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom time import time\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# For the tree visualization\nimport pydot\nfrom IPython.display import Image\nfrom sklearn.externals.six import StringIO","d41d9963":"# Importing the dataset\n# Input: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing\nfilename='\/kaggle\/input\/bank-marketing\/bank-full.csv'\ndf = pd.read_csv(filename,sep=',')\norig_df_size = len(df)\nprint(df.info())","a42d716c":"#helper function\ndef check(df, feature):\n  df_new = df.groupby(feature)['y'].apply(lambda x: x.sum()\/len(x))\n  return df_new","1c9a6e33":"#save the original dataframe\ndf1 = df.copy()\ndf1.head()","7fb54631":"df1 = df1[(df.age !='unknown') & (df1.job !='unknown') & (df1.marital !='unknown') & (df1.housing !='unknown') & (df1.loan !='unknown') & (df1.education != 'unknown')]","3b090d74":"#convert duration to minutes\ndf1['durationMin'] = df1['duration'] \/\/ 60\ndf1.drop(['duration'], axis=1, inplace=True)","522fef44":"# Convert the result and two other columns to a number\ndf1['y'] = df1['y'].apply(lambda x: 0 if 'no' in x else 1)\ndf1['housing'] = df1['housing'].apply(lambda x: 0 if 'no' in x else 1)\ndf1['loan'] = df1['loan'].apply(lambda x: 0 if 'no' in x else 1)\ndf1['default'] = df1['default'].apply(lambda x: 0 if 'no' in x else 1)","4018df50":"df1.drop(['contact','balance','pdays','day','default','poutcome'], axis=1, inplace=True)","d7d3b85b":"#create getdummies \ndf1 = pd.get_dummies(df1, columns=['marital'],drop_first=False)\ndf1 = pd.get_dummies(df1, columns=['education'],drop_first=False)","bf9fcef3":"train, test = train_test_split(df1, \n                              train_size=0.75, \n                              shuffle=True, \n                              stratify=df1['y'])","a7f47253":"#Remove outliers\norig_len = len(train)\ntrain = train[train['campaign'] <= 17]\ntrain = train[train['durationMin'] < 38]\ntrain = train[train['age'] < 85]\ntrain = train[train['previous'] < 17]\nprint(f'removed {orig_len - len(train)} out of {len(train)}')","2de88b5b":"#covert job to percentage\ndf_job = pd.DataFrame(check(train,'job'))\nprint(list(df_job.columns))\ndf_job.rename(columns={'y':'job_percent'},inplace=True)\nprint('df_job ',list(df_job.columns))\nprint('train ',list(train.columns))\ntrain = train.merge(df_job, how='inner', left_on='job',right_index=True)\ntrain.drop(['job'], axis=1, inplace=True)\ntrain","27cc327b":"#covert month to percentage\ndf_month = pd.DataFrame(check(train,'month'))\ndf_month.rename(columns={'y':'month_percent'},inplace=True)\nprint('df_month ',list(df_month.columns))\nprint('train ',list(train.columns))\ntrain = train.merge(df_month, how='inner', left_on='month',right_index=True)\ntrain.drop(['month'], axis=1, inplace=True)","84cc3919":"X_train = train.drop(['y'], axis=1)\ny_train = train['y']\nprint(y_train)","c43f8a8d":"X_train.info()","905dcb17":"def print_cm_metrics(cm):\n    total1=sum(sum(cm))\n    accuracy1=(cm[0,0]+cm[1,1])\/total1\n    print ('Accuracy : ', accuracy1)\n\n    specificity = cm[0,0]\/(cm[0,0]+cm[0,1])\n    print('specificity : ', specificity )\n    \n    # sensitivity == recall\n    sensitivity = cm[1,1]\/(cm[1,0]+cm[1,1])\n    print('sensitivity : ', sensitivity)","ffa3bb82":"my_cv = StratifiedShuffleSplit(n_splits=10, train_size=0.7, test_size=0.3)","426575a5":"test = test.merge(df_month, how='inner', left_on='month',right_index=True)\ntest = test.merge(df_job, how='inner', left_on='job',right_index=True)\ntest.drop(['month'], axis=1, inplace=True)\ntest.drop(['job'], axis=1, inplace=True)","9da13cb5":"X_test = test.drop(['y'], axis=1)\ny_test = test['y']","2a11be1e":"dt_model_dt = DecisionTreeClassifier(class_weight='balanced')","b7fd1cf9":"# from sklearn.metrics import fbeta_score, make_scorer\n# best_beta_ind = (Fb.Model1 - Fb.Model2).abs().idxmin()\n# my_beta = Fb.Beta[best_beta_ind]\n# print (my_beta)\n# my_fbeta_score = \\\n#     make_scorer(fbeta_score, beta=my_beta, pos_label='Yes', greater_is_better=True)","889cb2c7":"my_param_grid = {'min_samples_leaf': [5, 10, 15],\n                 'min_weight_fraction_leaf': [0.003, 0.005, 0.007],\n                 'criterion': ['gini', 'entropy'], \n                 'min_impurity_decrease': [1e-3, 1e-4, 1e-5]}\n#After running the above combinations these are the results:\n# my_param_grid = {'min_samples_leaf': [10],\n#                  'min_weight_fraction_leaf': [0.005],\n#                  'criterion': ['gini'], \n#                  'min_impurity_decrease': [1e-4]}","5f239f18":"dt_model_gs = GridSearchCV(estimator=dt_model_dt, \n                           param_grid=my_param_grid, \n                           cv=my_cv, \n                           scoring='roc_auc')","30fab931":"dt_model_gs.fit(X_train, y_train)","eca88822":"dt_model_3 = dt_model_gs.best_estimator_\ndt_model_3","708b8bc2":"y_train_pred = pd.DataFrame(dt_model_3.predict_proba(X_train), \n                           columns=dt_model_3.classes_)\n#log_loss(y_true=y_train, y_pred=y_train_pred)","8426b98e":"scores = dt_model_3.predict_proba(X_train)[:, 1]\nroc_auc_score(y_true=y_train, y_score=scores)","a6267225":"y_test_pred = pd.DataFrame(dt_model_3.predict_proba(X_test), \n                           columns=dt_model_3.classes_)\n#log_loss(y_true=y_test, y_pred=y_test_pred)","c988907b":"scores = dt_model_3.predict_proba(X_test)[:, 1]\nroc_auc_score(y_true=y_test, y_score=scores)","9c198f51":"y_test_pred['predict1'] = y_test_pred.apply(lambda x: x[1] > 0.1, axis=1)\n#asses the model\ncm = confusion_matrix(y_true=y_test,\n                      y_pred=y_test_pred['predict1'])\npd.DataFrame(cm, \n             index=dt_model_3.classes_, \n             columns=dt_model_3.classes_)","1cf84afb":"print_cm_metrics(cm)","20f37ce8":"def visualize_tree(model, md=5, width=800):\n    dot_data = StringIO()  \n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n    return Image(graph.create_png(), width=width) ","b2a69a3d":"def print_dot_text(model, md=5):\n    \"\"\"The output of this function can be copied to http:\/\/www.webgraphviz.com\/\"\"\"\n    dot_data = StringIO()\n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    dot_text = dot_data.getvalue()\n    print(dot_text)","0fe45676":"visualize_tree(dt_model_3, md=3, width=1200)","bd8cab11":"pd.Series(dt_model_3.feature_importances_, index=X_train.columns).sort_values()\\\n    .plot.barh(figsize=(4, 10), rot=0, title='Feature importances')","bba40c3a":"pd.Series(dt_model_3.feature_importances_, index=X_train.columns).sort_values()","39fe68aa":"rf_model = RandomForestClassifier(class_weight='balanced',**dt_model_gs.best_params_)","3771110e":"my_param_grid = {'bootstrap': [True, False], \n                 'n_estimators': [50, 100, 200], \n                 'oob_score': [True, False], \n                 'warm_start': [True, False]}\n#After running the above combinations these are the best results:\n# my_param_grid = {'bootstrap': [True], \n#                  'n_estimators': [200], \n#                  'oob_score': [False], \n#                  'warm_start': [True]}","9c117c01":"rf_model_gs = GridSearchCV(estimator=rf_model, \n                        param_grid=my_param_grid, \n#                        scoring='neg_log_loss', \n                        scoring='roc_auc', \n                        cv=my_cv)\n#roc_auc_score","e6b38201":"t1 = time()\nrf_model_gs.fit(X_train, y_train)\nt2 = time()\nprint(f\"It took {t2-t1:.2f} seconds\")","17f48fd0":"rf_model_gs_1 = rf_model_gs.best_estimator_\nrf_model_gs_1","69e2c21a":"y_train_pred = pd.DataFrame(rf_model_gs_1.predict_proba(X_train), \n                           columns=rf_model_gs_1.classes_)\n#log_loss(y_true=y_train, y_pred=y_train_pred)","160395f6":"scores = rf_model_gs_1.predict_proba(X_train)[:, 1]\nroc_auc_score(y_true=y_train, y_score=scores)","d2b7a085":"y_test_pred = pd.DataFrame(rf_model_gs_1.predict_proba(X_test), \n                           columns=rf_model_gs_1.classes_)\n#log_loss(y_true=y_test, y_pred=y_test_pred)","07e18de1":"pd.Series(rf_model_gs_1.feature_importances_, index=X_train.columns).sort_values()\\\n    .plot.barh(figsize=(4, 10), rot=0, title='Feature importances')","28d198e7":"y_test_pred['predict1'] = y_test_pred.apply(lambda x: x[1] > 0.4, axis=1)\n#y_test_pred.head(10)","580c6cfc":"#asses the model\ncm = confusion_matrix(y_true=y_test,\n                      y_pred=y_test_pred['predict1'])\npd.DataFrame(cm, \n             index=rf_model_gs_1.classes_, \n             columns=rf_model_gs_1.classes_)","cc5863dc":"print_cm_metrics(cm)","05aaa7e0":"X_train.info()\n#scores = rf_model_gs_1.predict_proba(X_train)[:, 1]\n#roc_auc_score(y_true=y_train, y_score=scores)","02689667":"scores = rf_model_gs_1.predict_proba(X_test)[:, 1]\nroc_auc_score(y_true=y_test, y_score=scores)","a4a69be9":"fpr, tpr, thresholds = roc_curve(y_test, scores, pos_label=1)\nres = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Threshold': thresholds})\n#res[['TPR', 'FPR', 'Threshold']][::100]","6d97f842":"plt.plot(fpr, tpr, '-o')\nplt.title('ROC')\nplt.xlabel('FPR (False Positive Rate = 1-specificity)')\nplt.ylabel('TPR (True Positive Rate = sensitivity)')\nplt.xlim([0, 1])\nplt.ylim([0, 1])","9c492d8c":"def change_age(df):\n    df_new = df.copy()\n    df_new['age_class'] = df_new['age'].apply(lambda x: 'young' if x<=25 else 'old' if x >= 61 else 'mid')\n    df_new = pd.get_dummies(df_new, columns=['age_class'],drop_first=False)\n    return df_new","a9d23fe7":"# from sklearn.pipeline import Pipeline, FeatureUnion\n\n# lr_model = LogisticRegression(class_weight='balanced', max_iter=10)\n# change_a = change_age()\n# # change_a.head()\n# steps = [('change_age', change_a), \n#          ('lr', lr_model)]\n# my_pipeline = Pipeline(steps)","174461ab":"#Consider use pandas.cut\nX_train_all = change_age(X_train)\nX_train_lr = X_train_all.drop(columns=['age'])\n# X_train_lr['age'] = X_train_lr['age'].apply(lambda x: 'young' if x<=25 else 'old' if x >= 61 else 'mid')\n# X_train_lr = pd.get_dummies(X_train_lr, columns=['age'],drop_first=False)\nmy_param_grid = {'C': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3], 'penalty': ['l1', 'l2']}\nlr_model = GridSearchCV(estimator=LogisticRegression(class_weight='balanced', max_iter=10), \n                        param_grid=my_param_grid, \n                        scoring='roc_auc', \n                        cv=my_cv)\nlr_model.fit(X_train_lr, y_train)","3bd4844b":"y_train_pred = pd.DataFrame(lr_model.predict_proba(X_train_lr), \n                           columns=lr_model.classes_)","bbc93715":"scores = lr_model.predict_proba(X_train_lr)[:, 1]\nroc_auc_score(y_true=y_train, y_score=scores)","b10b3ebe":"X_test_all = change_age(X_test)\nX_test_lr = X_test_all.drop(columns=['age'])\n\n# X_test_lr['age'] = X_test_lr['age'].apply(lambda x: 'young' if x<=25 else 'old' if x >= 61 else 'mid')\n# X_test_lr = pd.get_dummies(X_test_lr, columns=['age'],drop_first=False)\n#y_test_pred = lr_1.predict(X_test)\ny_test_pred = pd.DataFrame(lr_model.predict_proba(X_test_lr),\n                           columns=lr_model.classes_)","d17b166d":"scores = lr_model.predict_proba(X_test_lr)[:, 1]\nroc_auc_score(y_true=y_test, y_score=scores)","960df5aa":"y_test_pred['predict1'] = y_test_pred.apply(lambda x: x[1] > 0.4, axis=1)","91a309b5":"#asses the model\ncm = confusion_matrix(y_true=y_test, y_pred=y_test_pred['predict1'])\npd.DataFrame(cm, \n             index=lr_model.classes_, \n             columns=lr_model.classes_)","85e3a091":"print_cm_metrics(cm)","913667cd":"from sklearn.ensemble import VotingClassifier, BaggingClassifier, \\\n    AdaBoostClassifier, GradientBoostingClassifier","7267e10e":"clf1 = rf_model_gs_1 #RandomForestClassifier \nclf2 = lr_model #LogisticRegression\nclassifiers = [('LR', clf1), ('DT', clf2)]","d42488ff":"clf_voting = VotingClassifier(estimators=classifiers,\n                              voting='soft')\nclf_voting.fit(X_train_all, y_train)","12d5935f":"scores = clf_voting.predict_proba(X_train_all)[:, 1]\nroc_auc_score(y_true=y_train, y_score=scores)","8cc9a15b":"y_test_pred = pd.DataFrame(clf_voting.predict_proba(X_test_all),\n                           columns=clf_voting.classes_)\ny_test_pred['predict1'] = y_test_pred.apply(lambda x: x[1] > 0.2, axis=1)","113032ed":"scores = clf_voting.predict_proba(X_test_all)[:, 1]\nroc_auc_score(y_true=y_test, y_score=scores)","6982a74a":"print(f\"train accuracy: {clf_voting.score(X_train_all, y_train):.2f}\\n\\\ntest accuracy: {clf_voting.score(X_test_all, y_test):.2f}\")","c4a01c38":"#asses the model\ncm = confusion_matrix(y_true=y_test,\n                      y_pred=y_test_pred['predict1'])\npd.DataFrame(cm, \n             index=lr_model.classes_, \n             columns=lr_model.classes_)\nprint_cm_metrics(cm)","5f5c751d":"# Random forest","59f0a02e":"# Pre-processing","e223ccdc":"Conclusion: (We would like to union into fewer categories: employees, retired, self-employed, student, unemployed.)\nIt will be better to convert the jobs to percentage of y","d3e10d65":"Conclusion: it seems that campaign >= 17 are outliers","88974e9e":"Conclusion: it seems that the month effects the percentage of y\nuse the statistics approach","755dbc1a":"Conclusion: this feature effects the result","ed4476d9":"Conclusion: the are about 5% rows with 'unknown' cells, it's OK to remove them","4b8441ed":"Conclusion: there is no correlaiton betwen these feature for previous>1 so we need both features","e058151d":"* Conclusion: since there are too few 1s drop this feature","352ee282":"Conclusion: there are no null cells","e22102d9":"Conclusion: the balance has no affect on the result, drop this feature","158097f2":"# Models","e4ccdd93":"Conclusion: we don't see why day in the month effects, should be dropped","19178a24":"# Splitting the data","3515ae40":"# [](http:\/\/)Logistic Regression","a146dd86":"Conclusion: we can remove previous >= 17","da072bef":"NOTE: In order to run EDA start from the next cell.\nTo run the model search for \"Pre-processing\" and start from that cell","4ea97b74":"# **Decision Tree**","5b1e71b6":"Conclusion: Seems thar matiral is a requiered feature","5839bcce":"Conclusion: strange, we would expect higher results for ages 30-50. Remove ages age > 85","25f8a22d":"Coclusion: the data is not balance, only ~13% are 'y', the rest are 'n'","a9217d30":"Conclusion: we should drop this feature","b2f89410":"Conclusion: we can remove rows with duration > 38 (outliers), these are 0.08% of the data","5109435d":"# Ensemble methods - voting"}}