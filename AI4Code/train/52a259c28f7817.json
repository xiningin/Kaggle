{"cell_type":{"9dce5fb5":"code","41996f79":"code","2a6ea894":"code","8f6198c3":"code","83917eb3":"code","8a06be69":"code","d4da97e0":"code","6d32d9bd":"code","f9cd539f":"code","0cd8040c":"code","f2d347bb":"code","1354066d":"code","baf0e2fa":"code","208383d5":"code","fc78c27e":"code","ab6a49a2":"code","900af0c8":"code","4abb0563":"code","f7d87bf2":"code","294e377f":"code","64825c7a":"code","dc007b9d":"code","25df3f35":"code","542dafc0":"code","243f0fdb":"code","5f5f418d":"code","058683c8":"code","1411eba9":"code","93bf7e97":"code","0d52b048":"code","3cafa18d":"code","4f9a02fb":"code","fbb343a3":"markdown","da568958":"markdown","f2e70d5e":"markdown","5be7439f":"markdown","9e3fc27d":"markdown","5d3cb043":"markdown","80463659":"markdown","018c2577":"markdown","ac217186":"markdown","d1c37a21":"markdown","3da73908":"markdown","8f031c71":"markdown","57f7c688":"markdown","c76728e5":"markdown","e443b75a":"markdown","79ff7bfe":"markdown","7feec602":"markdown","6941239b":"markdown","2f9537de":"markdown","94198e2e":"markdown","beaffb90":"markdown","b3ad80e8":"markdown","60405cb8":"markdown","7f01599a":"markdown"},"source":{"9dce5fb5":"# We need to install a wide variety of libraries. \n#For this we will install pandas, numpy, seaborn and matplotlib libraries.\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nplt.style.use('ggplot')\nfrom matplotlib.pyplot import figure\n\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (12,8)\n\npd.options.mode.chained_assignment = None","41996f79":"# Now we need to read in the data\n\ndf = pd.read_csv('..\/input\/movies\/movies.csv', encoding = \"ISO-8859-1\")\ndf.head()","2a6ea894":"# shows the analysis of numerical values.\ndf.describe().T","8f6198c3":"# Let's loop through the data and see if there is anything missing\n \nfor col in df.columns:\n    pct_missing = np.mean(df[col].isnull())\n    print('%-15s  %-15s' %(col,pct_missing))","83917eb3":"sns.heatmap(df.isnull(), cbar=False) \nplt.title('Missing Values ', fontsize = 14)\n#plt.rcParams['figure.figsize'] = (5,3)\nplt.show()","8a06be69":"#Data types for our colums\n\ndf.dtypes","d4da97e0":"#Change data Type of colums\n\ndf['budget']=df['budget'].astype('int64')\n\ndf['gross'] = df['gross'].astype('int64')\n\ndf.head()","6d32d9bd":"#Create correct year column from released column\ndf['YearCorrect'] = df['released'].astype(str).str[:4]\ndf.dtypes","f9cd539f":"#This will allow you to see all column names & rows\n\n#pd.set_option('display.max_rows',None)","0cd8040c":"#Viewing the top movies with highest gross \n\ndf = df.sort_values(by=['gross'],ascending=False)\ndf.head()","f2d347bb":"#Checking the existence of duplicated rows\ndf.duplicated().sum()\n\n#Drop any duplicates\n#df.drop_duplicates()","1354066d":"comp = df.groupby(['name','company'])['budget','gross'].sum().sort_values(by='gross',ascending=False)\ncomp.head(10)","baf0e2fa":"df.groupby('company').size().plot(kind = \"bar\")","208383d5":"topcom = comp.reset_index()\ntopcom.head()","fc78c27e":"company = df['company'].value_counts()\ncompany = pd.DataFrame(company) \ncompany = company.head(10) \ncompany.head(3)\n\n","ab6a49a2":"sns.barplot(x = company.index, y = company['company'])\n\nlabels = company.index.tolist()\nplt.gcf().set_size_inches(15, 7)\n\nplt.title('Company vs. Movies released', fontsize = 15)\nplt.xlabel('Company', fontsize = 15)\nplt.ylabel('Released movies', fontsize = 15)\n#plt.rcParams['figure.figsize'] = (1,2)\nplt.xticks(ticks = [0,1,2,3,4,5,6,7,8,9] , labels = labels, rotation = '45')\n\nplt.show()","900af0c8":"Perc = company.sum() \/ df.shape[0] * 100\nPerc","4abb0563":"plt.figure(figsize = (12,10))\nsns.countplot(x = 'rating',data = df ,hue='genre')\nplt.legend(loc='upper center')\nplt.show()","f7d87bf2":"df['rating'].value_counts().plot.bar()\n","294e377f":"df1 = {key: df for key, df in df.groupby('genre')}\ndf1.keys()\naction, musical, comedy, family = df1['Action'], df1['Musical'], df1['Comedy'], df1['Family']","64825c7a":"action.head(10).sort_values(by = ['gross', 'budget'], ascending=False)","dc007b9d":"comedy.head(10).sort_values(by = ['gross', 'budget'], ascending=False)","25df3f35":"family[(family.rating == 'G') | (family.rating == 'PG')].sort_values(by = ['rating', 'score'], ascending = [True, False]) ","542dafc0":"#let's start looking at correlation\ndf.corr(method='pearson')  #pearson , kendall , spearman","243f0fdb":"\ncorrelation_matrix = df.corr(method='pearson')\nsns.heatmap(correlation_matrix, annot=True)\nplt.title('Correlation Matrix for Numeric Features')\nplt.xlabel('Movie Features')\nplt.ylabel('Movie Features')\nplt.rcParams['figure.figsize'] = (10,10)\nplt.show()","5f5f418d":"#looks at company\n\ndf.head(10)","058683c8":"# Using factorize - this assigns a random numeric value for each unique categorical value\n\ndf.apply(lambda x: x.factorize()[0]).corr(method='pearson')","1411eba9":"correlation_matrix = df.apply(lambda x: x.factorize()[0]).corr(method='pearson')\n\nsns.heatmap(correlation_matrix, annot = True)\n\nplt.title(\"Correlation matrix for Movies\")\n\nplt.xlabel(\"Movie features\")\n\nplt.ylabel(\"Movie features\")\n\nplt.show()","93bf7e97":"correlation_mat = df.apply(lambda x: x.factorize()[0]).corr()\n\ncorr_pairs = correlation_mat.unstack()\n\ncorr_pairs.head(100)","0d52b048":"sorted_pairs = corr_pairs.sort_values(kind=\"quicksort\")\n\ncorr_pairs.head(100)","3cafa18d":"# We can now take a look at the ones that have a high correlation (> 0.5)\n\nstrong_pairs = sorted_pairs[abs(sorted_pairs) > 0.7]\n\nstrong_pairs.head(30)","4f9a02fb":"f, (ax1, ax2) = plt.subplots(1, 2, sharey = True)\n\nplt.gcf().set_size_inches(15, 7)\nax1.scatter(df.budget, df.gross, c = 'pink')\nax1.set_title('Budget vs. Gross', c = 'pink', fontsize = 25)\nax2.scatter(df.votes, df.gross, c='blue')\nax2.set_title('Votes vs. Gross', c ='blue', fontsize = 25)\n\nplt.ylabel('Gross', fontsize = 25)\n\nplt.show()","fbb343a3":"## 7. Correlation Analysis","da568958":"- **We concluded that most of the movies are R and PG-13 rated, and that most movies are from Adventure,Action and Comedy.**\n- **G rated movies are mostly family ones.**","f2e70d5e":"**There is no missing values in the dataset**","5be7439f":"- **Low budget and voted movies seem to have poor profit.**\n- **As the budget raises, there is an exponencial tendency for gross improvement.**","9e3fc27d":"**the values in column \"Budget\" and \"Gross\" are \"float\" datatypes but there is no digits after the decimals.**","5d3cb043":"**5.3 Checking for duplicates**","80463659":"**Is there any Missing Data ?**","018c2577":"## 5.Data Cleaning","ac217186":"# ","d1c37a21":"**6.1 Company analysis**","3da73908":"#### - votes and budget have the highest correlation to gross earnings\n#### - I was wrong ! company has low correlation\n","8f031c71":"## 1. Introduction \n\nIn this project we will be working in Python to firstly recognize, analyze our data using a wide variety of functions in the pandas library and secondly find the correlations between variables .\nFor that we\u00b4ll use the Movie Industry dataset available in Kaggle, containing 6820 movies (220 movies per year, 1986-2016). Each movie has the following attributes:\n\nNumerical columns: Budget, Gross, Runtime, Score and Votes.\\\nCategorical columns: Company, Country, Director, Genre, Name, Rating, Star and Writer.\\\nDate columns: Released and Year.","57f7c688":"**Loading and Reading the dataset**\n","c76728e5":"**So I was right ! There is a clear and high correlation between 'Budget' and 'Gross'**","e443b75a":"## 6. Data Analysis","79ff7bfe":"**5.2 The year has incorrect values while we compare it with the released date column**","7feec602":"## 3.Data Collection","6941239b":"**My Guesses**\n- I think **Budget** will have a high Correlation because the more money they will spend the more they will get.\n- Also the **company** cuz bigger companies like Disney make movies that bring so much of money.","2f9537de":"**5.1 the values in column \"Budget\" and \"Gross\" are \"float\" datatypes but there is no digits after the decimals. So we will change the Type to integer.**\n\n","94198e2e":"**6.2 Genre and Rating Analysis**","beaffb90":"## 4. Checking Data","b3ad80e8":"## 2. Importing Libraries ","60405cb8":"#### Thanks for reaching the end! Upvote if you liked it!","7f01599a":"- **the dataset has 6820 titles.**\n- **The studied time lapse goes from 1986 to 2016.**"}}