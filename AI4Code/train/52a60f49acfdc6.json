{"cell_type":{"16e73c19":"code","fbc5815f":"code","4871bbd5":"code","110ac751":"code","b0eef9ed":"code","1f05e360":"code","0afb8f6f":"code","ecd44422":"code","c38c0ff9":"code","d938ae32":"code","9d8dc1f2":"code","2c201380":"code","c7abb2d4":"code","43cee0c7":"code","28ab1d07":"code","a4568b4d":"code","9afa0363":"code","21db5bf3":"code","f4ab5626":"code","8ea726bd":"code","80869d33":"code","db8b1937":"code","2e410a32":"code","9f50a8eb":"code","56a71081":"code","ee4822d4":"code","b62bdff9":"code","4710c990":"code","287046d3":"code","b13da539":"code","fd422f93":"code","9eef54c6":"code","9a7f8f5d":"code","8485420e":"code","34dc7a12":"code","455d424d":"code","07b03e78":"code","caa745ed":"code","05528108":"code","1fe784a0":"code","09220528":"code","aa7cd4eb":"code","d4b4a8af":"markdown","144fced0":"markdown","c3f05dc3":"markdown","2f116f12":"markdown","31c930a3":"markdown","6c424d04":"markdown","e68b435f":"markdown","765b249a":"markdown","0ce99591":"markdown","7748a5b9":"markdown","8c79d3e9":"markdown","691e20e8":"markdown","db331b2e":"markdown","f33ef5fa":"markdown","bec2b97b":"markdown","b4882561":"markdown","b6c876ae":"markdown","332fc01a":"markdown","bd37c70c":"markdown","99dd1348":"markdown","ceb0fb9b":"markdown","b0e5ca38":"markdown","6d6033d6":"markdown","6a3792fe":"markdown","f78c6734":"markdown","a85b75d1":"markdown","31980270":"markdown","44310994":"markdown","0a8b6946":"markdown","714b64e1":"markdown","7a318e28":"markdown","c2d4d010":"markdown","29981da6":"markdown","cbef120b":"markdown","b5a369c1":"markdown","2f40d959":"markdown","22d900c4":"markdown"},"source":{"16e73c19":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport emoji\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import preprocessing\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\nwarnings.filterwarnings(action='ignore', category=FutureWarning)\npd.set_option('display.max_columns', None)","fbc5815f":"data = pd.read_csv('\/kaggle\/input\/feb-2020-us-flight-delay\/feb-20-us-flight-delay.csv')","4871bbd5":"data.head()","110ac751":"data = data.drop(['Unnamed: 9'], axis=1)","b0eef9ed":"data['DEP_DEL15'].value_counts()","1f05e360":"# Split the data into positive and negative\npositive_rows = data.DEP_DEL15 == 1.0\ndata_pos = data.loc[positive_rows]\ndata_neg = data.loc[~positive_rows]\n\n# Merge the balanced data\ndata = pd.concat([data_pos, data_neg.sample(n = len(data_pos))], axis = 0)\n\n# Shuffle the order of data\ndata = data.sample(n = len(data)).reset_index(drop = True)","0afb8f6f":"data.isna().sum()","ecd44422":"data = data.dropna(axis=0)","c38c0ff9":"data.info()","d938ae32":"data['DEP_DEL15'] = data['DEP_DEL15'].astype(int)","9d8dc1f2":"print(f\"There are {data.shape[0]} rows and {data.shape[1]} columns in our dataset.\")","2c201380":"data.describe()","c7abb2d4":"plt.figure(figsize=(15,5))\nsns.distplot(data['DISTANCE'], hist=False, color=\"b\", kde_kws={\"shade\": True})\nplt.xlabel(\"Distance\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of distance\")\nplt.show()","43cee0c7":"print(emoji.emojize(\"Let's find it out :fire:\"))","28ab1d07":"print(f\"Average distance if there is a delay {data[data['DEP_DEL15'] == 1]['DISTANCE'].values.mean()} miles\")\nprint(f\"Average distance if there is no delay {data[data['DEP_DEL15'] == 0]['DISTANCE'].values.mean()} miles\")","a4568b4d":"plt.figure(figsize=(15,5))\nsns.countplot(x=data['OP_UNIQUE_CARRIER'], data=data)\nplt.xlabel(\"Carriers\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of unique carrier\")\nplt.show()","9afa0363":"plt.figure(figsize=(10,70))\nsns.countplot(y=data['ORIGIN'], data=data, orient=\"h\")\nplt.xlabel(\"Airport\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of Unique Origin Airports\")\nplt.show()","21db5bf3":"plt.figure(figsize=(10,70))\nsns.countplot(y=data['DEST'], data=data, orient=\"h\")\nplt.xlabel(\"Airport\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of Unique Destination Airports\")\nplt.show()","f4ab5626":"data = data.rename(columns={'DEP_DEL15':'TARGET'})","8ea726bd":"def label_encoding(categories):\n    \"\"\"\n    To perform mapping of categorical features\n    \"\"\"\n    categories = list(set(list(categories.values)))\n    mapping = {}\n    for idx in range(len(categories)):\n        mapping[categories[idx]] = idx\n    return mapping","80869d33":"data['OP_UNIQUE_CARRIER'] = data['OP_UNIQUE_CARRIER'].map(label_encoding(data['OP_UNIQUE_CARRIER']))","db8b1937":"data['ORIGIN'] = data['ORIGIN'].map(label_encoding(data['ORIGIN']))","2e410a32":"data['DEST'] = data['DEST'].map(label_encoding(data['DEST']))","9f50a8eb":"data.head()","56a71081":"data['TARGET'].value_counts()","ee4822d4":"X = data[['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST', 'DEP_TIME', 'DISTANCE']].values\ny = data[['TARGET']].values","b62bdff9":"# Splitting Train-set and Test-set\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=41)\n\n# Splitting Train-set and Validation-set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=41)","4710c990":"# Formula to get accuracy\ndef get_accuracy(y_true, y_preds):\n    # Getting score of confusion matrix\n    true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_true, y_preds).ravel()\n    # Calculating accuracy\n    accuracy = (true_positive + true_negative)\/(true_negative + false_positive + false_negative + true_positive)\n    return accuracy","287046d3":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=0).fit(X_train, y_train)","b13da539":"# Initialize CatBoostClassifier\ncatboost = CatBoostClassifier(random_state=0)\ncatboost.fit(X_train, y_train, verbose=False)","fd422f93":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)","9eef54c6":"rf = RandomForestClassifier(random_state=0)\nrf.fit(X_train, y_train)","9a7f8f5d":"knn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)","8485420e":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)","34dc7a12":"models = [lr, catboost, gnb, rf, knn, xgb]\nacc = []\nfor model in models:\n    preds_val = model.predict(X_val)\n    accuracy = get_accuracy(y_val, preds_val)\n    acc.append(accuracy)","455d424d":"model_name = ['Logistic Regression', 'Catboost', 'Naive Bayes', 'Random Forest', 'KNN', 'XGBoost']\naccuracy = dict(zip(model_name, acc))","07b03e78":"plt.figure(figsize=(15,5))\nax = sns.barplot(x = list(accuracy.keys()), y = list(accuracy.values()))\nfor p, value in zip(ax.patches, list(accuracy.values())):\n    _x = p.get_x() + p.get_width() \/ 2\n    _y = p.get_y() + p.get_height() + 0.008\n    ax.text(_x, _y, round(value, 3), ha=\"center\") \nplt.xlabel(\"Models\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model vs. Accuracy\")\nplt.show()","caa745ed":"test_preds = knn.predict(X_test)\nget_accuracy(y_test, test_preds)","05528108":"leaf_size = list(range(1,5))\nn_neighbors = list(range(1,3))\np=[1,2]\n\nhyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n\nknn_2 = KNeighborsClassifier()\n\nclf = GridSearchCV(knn_2, hyperparameters, cv=2)\n\nbest_model = clf.fit(X_train,y_train)\n\nprint('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\nprint('Best p:', best_model.best_estimator_.get_params()['p'])\nprint('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])","1fe784a0":"knn_best = KNeighborsClassifier(leaf_size=3, p=1, n_neighbors=1)","09220528":"knn_best.fit(X_train, y_train)\ntest_preds_1 = knn_best.predict(X_test)","aa7cd4eb":"get_accuracy(y_test, test_preds_1)","d4b4a8af":"__Encoding the categorical variable__","144fced0":"## Exploratory Data Analysis\nLet's uncover some meaningful and hidden insights out of our dataset.","c3f05dc3":"__XGBoost Classifier__","2f116f12":"We might have an extra column in our dataset, let's get rid of it first","31c930a3":"Let's visualize the categorical variables.","6c424d04":"### Choosing the evaluation metric\nHere we will go with the __Accuracy__ metric for our predicted values because we have already balanced our dataset.\nSo, accuracy is the best metric to evaluate any binary classification problem if it is performed on a balanced dataset.","e68b435f":"We can see that our __DISTANCE__ variable is positively skewed.\nI am just curious to find out the correlation between the distance and delay of a flight.","765b249a":"We can see that we have highly imbalanced data, as we there are only __14.43%__ rows with the value of 1.0 (Delay in flight).\n\nWe will drop a significant amount of rows where our target variable is 0.0 (No delay in flight).","0ce99591":"### Data Format\nData Source : [US Bureau of Transportation Statistics](https:\/\/www.transtats.bts.gov\/DL_SelectFields.asp?Table_ID=236)\n\nAfter carefully analyzing each data points, I decided to manually pick 9 variable to predict if there will be a delay in the flight.\n- __MONTH__ - Month\n- __DAY_OF_MONTH__ - Day of Month\n- __DAY_OF_WEEK__ - Day of Week\n- __OP_UNIQUE_CARRIER__ - Unique Carrier Code\n- __ORIGIN__ - Origin airport location\n- __DEST__ - Destination airport location\n- __DEP_TIME__ - Actual Departure Time (local time: hhmm)\n- __DEP_DEL15__ - Departure Delay Indicator, 15 Minutes or More (1=Yes, 0=No) [TARGET VARIABLE]\n- __DISTANCE__ - Distance between airports (miles)","7748a5b9":"Though, there is no possible way to find correlation between a continuous and categorical variable, I'll try to find the average distance for __DEP_DEL15__ variable.","8c79d3e9":"## Data Preprocessing","691e20e8":"Let's find out the distribution of our target variable","db331b2e":"## Modelling\n","f33ef5fa":"__Logistic Regression__","bec2b97b":"Let's quickly visualize the distribution of __DISTANCE__ variable","b4882561":"### Count of carriers in the dataset","b6c876ae":"There are around __~0.5%__ NULL values present in __DEP_TIME__ and __DEP_DEL15__","332fc01a":"We see that our target variable __DEP_DEL15__ has the datatype of _float64_.\n\nLet's convert it into _int_.","bd37c70c":"### Evaluation of accuracy on validation dataset","99dd1348":"**Also, this is my first kernel on Kaggle. Feel free to correct me if I am wrong anywhere :)**","ceb0fb9b":"### Count of origin and destination airport","b0e5ca38":"## Background\nLet's say we have to develop an AI model that can predict flight delays during the\nflight duration based on data about previous delay\/turbulence encountered.","6d6033d6":"Apart from the statistics given in the table above, we can also that there are 6 numerical and 3 categorical variables in our dataset.","6a3792fe":"### Accuracy on Test set with KNN before hyperparameter tuning","f78c6734":"## Conclusion","a85b75d1":"Let's quickly remove the NULL values if present any","31980270":"__KNN Classifier__","44310994":"### Creating some baseline models","0a8b6946":"#### We see an increment of __~ 6.1%__ in the accuracy of our model after tuning the hyperparamter.\n\n#### Accuracy can be improved further if time and resources are given.","714b64e1":"__CatboostClassifier__","7a318e28":"__Random Forest Classifier__","c2d4d010":"Our __MONTH__ variable is constant so it will not have any effect on in the training.\nIt's better to remove it. Also, let's rename the __DEP_DEL15__ column name to __TARGET__ to avoid confusion between predictors and target variable.","29981da6":"### Hyperparameter tuning for KNN","cbef120b":"__Naive Bayes__","b5a369c1":"Now let's have a look at the number of columns and rows in our dataset.","2f40d959":"### Accuracy on Test set with KNN after hyperparameter tuning","22d900c4":"We tried to fit our data on default parameters of different algorithms for binary classification.\n\nSurprisingly, __KNN Classifier__ turned out to best in terms of validation set accuracy.\n\nNow we'll try to find the best possible parameters for K-Nearest Neighbors Algorithm."}}