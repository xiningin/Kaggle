{"cell_type":{"1d238cb5":"code","bda1b593":"code","8783b383":"code","116ed441":"code","0f06644e":"code","4f100c2b":"code","a8918d57":"code","365d6b69":"code","e7124c96":"code","06117d18":"code","7888d1c3":"code","9b72d3ef":"code","6b66eba1":"code","6eea3200":"code","f55b6f16":"code","f8b10d0c":"code","7c5be5dc":"code","356c6f7d":"code","06e16de1":"code","bd83e4f5":"code","d3861579":"code","56a1401e":"code","2615b0b2":"code","dbaeb2f8":"code","5f9d744b":"code","ab5d75a3":"code","eb5bfcfe":"code","75835bb8":"code","3287a743":"code","c89a833a":"code","6fe8d681":"code","f10607c0":"code","06a3faef":"code","d187cf07":"code","88612852":"code","5b643323":"code","3ba0ea7b":"code","de68ae85":"code","34ff722b":"code","e7ed1965":"code","a0cf7ec1":"code","646caf28":"markdown","482905c1":"markdown","4403976b":"markdown","544f338f":"markdown","1f1401e1":"markdown","7bd29b40":"markdown","d0c3ec49":"markdown","c07f3711":"markdown","43cab662":"markdown","e707609e":"markdown","708b9725":"markdown","2c0f2b53":"markdown","9e030c78":"markdown","d87ecc37":"markdown","bb286f62":"markdown","35940778":"markdown","6e0e3835":"markdown","c05aebbe":"markdown","58234dd7":"markdown","4a67babe":"markdown","877277e3":"markdown","17640fc5":"markdown","5ecb7693":"markdown","c3aefbd2":"markdown","a5febe05":"markdown","7c7ff4a2":"markdown","5f438385":"markdown","8427486c":"markdown"},"source":{"1d238cb5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2","bda1b593":"# labels","8783b383":"labels = os.listdir(\"..\/input\/drowsiness-dataset\/train\")","116ed441":"labels","0f06644e":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/Closed\/_0.jpg\"))","4f100c2b":"a = plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/10.jpg\")","a8918d57":"a.shape","365d6b69":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/10.jpg\"))","e7124c96":"def face_for_yawn(direc=\"..\/input\/drowsiness-dataset\/train\", face_cas_path=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\"):\n    yaw_no = []\n    IMG_SIZE = 145\n    categories = [\"yawn\", \"no_yawn\"]\n    for category in categories:\n        path_link = os.path.join(direc, category)\n        class_num1 = categories.index(category)\n        print(class_num1)\n        for image in os.listdir(path_link):\n            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n            face_cascade = cv2.CascadeClassifier(face_cas_path)\n            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n            for (x, y, w, h) in faces:\n                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                roi_color = img[y:y+h, x:x+w]\n                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n                yaw_no.append([resized_array, class_num1])\n    return yaw_no\n\n\nyawn_no_yawn = face_for_yawn()","06117d18":"def get_data(dir_path=\"..\/input\/drowsiness-dataset\/train\/\", face_cas=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\", eye_cas=\"..\/input\/prediction-images\/haarcascade.xml\"):\n    labels = ['Closed', 'Open']\n    IMG_SIZE = 145\n    data = []\n    for label in labels:\n        path = os.path.join(dir_path, label)\n        class_num = labels.index(label)\n        class_num +=2\n        print(class_num)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([resized_array, class_num])\n            except Exception as e:\n                print(e)\n    return data","7888d1c3":"data_train = get_data()","9b72d3ef":"def append_data():\n#     total_data = []\n    yaw_no = face_for_yawn()\n    data = get_data()\n    yaw_no.extend(data)\n    return np.array(yaw_no)","6b66eba1":"new_data = append_data()","6eea3200":"X = []\ny = []\nfor feature, label in new_data:\n    X.append(feature)\n    y.append(label)","f55b6f16":"X = np.array(X)\nX = X.reshape(-1, 145, 145, 3)","f8b10d0c":"from sklearn.preprocessing import LabelBinarizer\nlabel_bin = LabelBinarizer()\ny = label_bin.fit_transform(y)","7c5be5dc":"y = np.array(y)","356c6f7d":"from sklearn.model_selection import train_test_split\nseed = 42\ntest_size = 0.30\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)","06e16de1":"len(X_test)","bd83e4f5":"# !pip install tensorflow==2.3.1\n# !pip install keras==2.4.3","d3861579":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","56a1401e":"tf.__version__","2615b0b2":"import keras\nkeras.__version__","dbaeb2f8":"train_generator = ImageDataGenerator(rescale=1\/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\ntest_generator = ImageDataGenerator(rescale=1\/255)\n\ntrain_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)\ntest_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)","5f9d744b":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\nmodel.summary()","ab5d75a3":"history = model.fit(train_generator, epochs=50, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))","eb5bfcfe":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\nplt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, \"b\", label=\"trainning loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\nplt.legend()\nplt.savefig(\"graph.png\")\nplt.show()\n","75835bb8":"model.save(\"drowiness_new6.h5\")","3287a743":"model.save(\"drowiness_new6.model\")","c89a833a":"prediction = model.predict_classes(X_test)","6fe8d681":"prediction","f10607c0":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]","06a3faef":"from sklearn.metrics import classification_report\nprint(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))","d187cf07":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\nIMG_SIZE = 145\ndef prepare(filepath, face_cas=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\"):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array \/ 255\n    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nmodel = tf.keras.models.load_model(\".\/drowiness_new6.h5\")","88612852":"# prepare(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1068.jpg\")\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1067.jpg\")])\nnp.argmax(prediction)","5b643323":"prediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/Closed\/_101.jpg\")])\nnp.argmax(prediction)","3ba0ea7b":"prediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/Open\/_104.jpg\")])\nnp.argmax(prediction)","de68ae85":"prediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/yawn\/113.jpg\")])\nnp.argmax(prediction)","34ff722b":"import IPython.display as ipd","e7ed1965":"input1=\"..\/input\/drowsiness-dataset\/train\/yawn\/113.jpg\"","a0cf7ec1":"fname = 'TF045.WAV'\nprediction = model.predict([prepare(input1)])\nif(np.argmax(prediction)==2 or np.argmax(prediction)==0):\n   ipd.display(ipd.Audio( '..\/input\/alarm-1\/' + fname))","646caf28":"# Prediction \n## 0-yawn, 1-no_yawn, 2-Closed, 3-Open","482905c1":"# keras version","4403976b":"# for closed and open eye","544f338f":"![fatigued-truck-driver-1.gif](attachment:fatigued-truck-driver-1.gif)\n\n## Driver drowsiness detection is a car safety technology which helps prevent accidents caused by the driver getting drowsy. Various studies have suggested that around 20% of all road accidents are fatigue-related, up to 50% on certain roads.","1f1401e1":"# Data Augmentation","7bd29b40":"# Prediction","d0c3ec49":"# visualize yawn image. \n# Here background is unnecessary. we need only face image array","c07f3711":"# LabelBinarizer","43cab662":"# train test split","e707609e":"# history","708b9725":"# for yawn and not_yawn. Take only face","2c0f2b53":"# length of X_test","9e030c78":"# Not necessary, only use to matching with my pc version","d87ecc37":"# visualize random 1 image","bb286f62":"# new variable to store","35940778":"# reshape the array","6e0e3835":"# classification report","c05aebbe":"# tensorflow version","58234dd7":"# label array","4a67babe":"# Model","877277e3":"# separate label and features","17640fc5":"# added an alarm here\n","5ecb7693":"# save model","c3aefbd2":"# predicting function","a5febe05":"# image array","7c7ff4a2":"# extend data and convert array","5f438385":"# import some dependencies","8427486c":"# image shape"}}