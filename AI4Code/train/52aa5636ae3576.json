{"cell_type":{"23480d13":"code","4e98091c":"code","e15c9b26":"code","be839078":"code","bfb90d12":"code","2d6c1271":"code","6ba62e46":"code","c86e486c":"code","58c4a8ae":"code","d3ce25da":"code","2fda99e0":"code","d9f1218d":"code","b7f43c8d":"markdown","af35eb58":"markdown"},"source":{"23480d13":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nfrom PIL import Image\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport fnmatch\nimport tensorflow as tf\nfrom time import sleep\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten,BatchNormalization,MaxPooling2D,Activation\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as k\nimport matplotlib.image as mpimg\nimport os\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nplt.rcParams['figure.figsize'] = (12,7)","4e98091c":"print(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\"))","e15c9b26":"# Setting paths and showing the number of images\ninfected = os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\")\ninfected_path = \"..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\"\nprint(\"Length of infected data = \", len(infected), 'images')\nuninfected = os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\")\nuninfected_path = \"..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\"\nprint(\"Length of uninfected data = \", len(uninfected), 'images')","be839078":"# Infected cells\n\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(cv2.imread(infected_path + '\/' + infected[i]))\n    plt.title('INFECTED CELLS')\n    plt.tight_layout()\nplt.show()","bfb90d12":"# Uninfected cells\n\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(cv2.imread(uninfected_path + '\/' + uninfected[i]))\n    plt.title('UNINFECTED CELLS')\n    plt.tight_layout()\nplt.show()","2d6c1271":"\n# Defining Image Data Gen\n\nimg_shape = (130, 130, 3)\nimage_gen = ImageDataGenerator(rotation_range=20,\n                              width_shift_range=0.1,\n                              height_shift_range=0.1,\n                              rescale=1\/225,\n                              shear_range=0.1,\n                              zoom_range=0.1,\n                              horizontal_flip=True,\n                              fill_mode='nearest',\n                              validation_split=0.2)","6ba62e46":"train = image_gen.flow_from_directory('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images',\n                                     target_size = img_shape[:2],\n                                     color_mode = 'rgb',\n                                     batch_size = 32,\n                                     class_mode = 'binary',\n                                     subset = 'training',\n                                     shuffle = True)\n\nvalidation = image_gen.flow_from_directory('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images',\n                                     target_size = img_shape[:2],\n                                     color_mode ='rgb',\n                                     batch_size = 32,\n                                     class_mode = 'binary',\n                                     subset = 'validation',\n                                     shuffle = False)","c86e486c":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nbase_model = InceptionV3(input_shape = (130, 130, 3), include_top = False, weights = 'imagenet')","58c4a8ae":"for layer in base_model.layers:\n    layer.trainable = False","d3ce25da":"from tensorflow.keras.optimizers import RMSprop\n\nx = layers.Flatten()(base_model.output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])","2fda99e0":"inc_history = model.fit_generator(train, validation_data = validation, steps_per_epoch = 100, epochs = 10)","d9f1218d":"fig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=False)\nax.plot(inc_history.history['acc'], color='red')\nax.plot(inc_history.history['val_acc'], color ='green')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()\n\n\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=False)\nax.plot(inc_history.history['loss'], color='red')\nax.plot(inc_history.history['val_loss'], color ='green')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","b7f43c8d":"# **Malaria Cell Classification with InceptionV3**","af35eb58":"In this project, I have used Convolutional Neural Network (CNN) using InceptionV3 Pre-Trained Model to classify Malaria cell images as Parasitized or Uninfected. The dataset is available at https:\/\/www.kaggle.com\/iarunava\/cell-images-for-detecting-malaria. I have split the dataset into 80% training and 20% validation sets. The total number of training and testing images are 22046 and 5512 respectively. The dataset contains equal number of images in both the classes. I have implemented the code using tensorflow and keras. I have obtained a validation accuracy of over 88%, training for 10 epochs only."}}