{"cell_type":{"d08486cd":"code","6dfd72a2":"code","f45870a8":"code","5ac31bcc":"code","f8fbfe39":"code","edb7bd72":"code","27665059":"code","8e63a50a":"code","07729336":"code","05583dc9":"code","be481f69":"code","70bf5f16":"code","446364bb":"code","92c68cef":"code","bc6a5025":"markdown"},"source":{"d08486cd":"import glob\nimport os.path as osp\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pickle\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchvision import datasets, models\nfrom torchvision.utils import make_grid\n\nimport os\nfrom PIL import Image\nfrom IPython.display import display\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport warnings\nwarnings.filterwarnings('ignore')","6dfd72a2":"class Config:\n    num_classes = 12\n    img_size = 224\n    batch_size = 64\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    min_lr = 10**-12\n    max_lr = 10\n    pretrained = False\n    criterion = nn.CrossEntropyLoss()\n    epochs = 30 ","f45870a8":" label_dict = ({\n    'encoded_label': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n    'labels': ['complex', 'frog_eye_leaf_spot', 'frog_eye_leaf_spot complex', \\\n                'healthy', 'powdery_mildew', 'powdery_mildew complex', 'rust', \\\n               'rust complex', 'rust frog_eye_leaf_spot', 'scab', \\\n               'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n})\ndf_labels_idx = pd.DataFrame(label_dict, index=label_dict['encoded_label'])\ndisplay(df_labels_idx)","5ac31bcc":"from sklearn.model_selection import train_test_split\n\ndef make_datapath_list():\n    phase_path = \"test_images\"\n        \n    rootpath = \"\/kaggle\/input\/plant-pathology-2021-fgvc8\/test_images\/\"\n    \n    target_path = osp.join(rootpath+\"\/*.jpg\")\n    path_list = []\n    \n    for path in glob.glob(target_path):\n        path_list.append(path)\n\n    return path_list","f8fbfe39":"test_list = make_datapath_list()\nprint(f'The length of testing set: {len(test_list)}')","edb7bd72":"import albumentations as A\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensorV2\nimport cv2","27665059":"transform = Compose([\n    A.Resize(Config.img_size, Config.img_size),\n    A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ToTensorV2()\n])","8e63a50a":"class PlantDataset(Dataset):\n    \"\"\"\n    Class to create a Dataset\n    \n    Attributes\n    ----------\n    df_train : DataFrame\n        DataFrame containing the image labels.\n    file_list : list\n        A list containing the paths to the images\n    transform : object\n        Instance of the preprocessing transform object\n    \"\"\"\n    def __init__(self, file_list, transform=None):\n        self.df_labels_idx = df_labels_idx\n        self.file_list = file_list\n        self.transform = transform\n        \n    def __len__(self):\n        \"\"\"\n        Returns the number of images.\n        \"\"\"\n        return len(self.file_list)\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Get data in Tensor format and labels of preprocessed images.\n        \"\"\"\n        \n        # Load the index number image.\n        img_path = self.file_list[index]\n        img = Image.open(img_path)\n        \n        # Preprocessing images\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_transformed = self.transform(image=img)\n        \n        # image name\n        image_name = img_path[-20:]\n        \n        # Extract the labels\n        label = -1\n        \n        return img_transformed, label, image_name","07729336":"test_dataset = PlantDataset(test_list, transform=transform)\n\nindex = 0\n\nprint(\"\\n\u3010test dataset\u3011\")\nprint(f\"img num : {test_dataset.__len__()}\")\n# print(f\"img : {test_dataset.__getitem__(index)[0].size()}\")\nprint(f\"label : {test_dataset.__getitem__(index)[1]}\")\nprint(f\"image name : {test_dataset.__getitem__(index)[2]}\")","05583dc9":"test_dataloader = DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False)","be481f69":"for i, image_data in enumerate(test_dataloader):\n    break\n    \nplt.figure(figsize=(20, 20))\n\nim = make_grid(image_data[0]['image'], nrow=8)\nplt.imshow(np.transpose(im.numpy(), (1, 2, 0)))","70bf5f16":"Pkl_Filename = '..\/input\/nh-m-1-chuy-n-c-ng-ngh\/2 FCs, 0.0001 Lr, 30 Epochs.pkl'\nwith open(Pkl_Filename, 'rb') as file:  \n    model = pickle.load(file)","446364bb":"class PlantPredictor():\n    \"\"\"\n    Class for predicting labels from output results\n    \n    Attributes\n    ----------\n    df_labels_idx: DataFrame\n        DataFrame that associates INDEX with a label name\n    \"\"\"\n    \n    def __init__(self, model, df_labels_idx,):\n        self.model = model\n        self.df_labels_idx = df_labels_idx\n        self.df_submit = pd.DataFrame()\n        \n    \n    def __predict_max(self, out):\n        \"\"\"\n        Get the label name with the highest probability.\n        \n        Parameters\n        ----------\n        predicted_label_name: str\n            Name of the label with the highest prediction probability\n        \"\"\"\n        maxid = np.argmax(out.detach().numpy(), axis=1)\n        df_predicted_label_name = self.df_labels_idx.iloc[maxid]\n        return df_predicted_label_name\n    \n    def inference(self):\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n        df_pred_list = []\n        for i, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n            image_name = data[2]\n            self.model.to(device)\n            inputs = data[0]['image']\n            inputs = inputs.to(device)\n            out = self.model(inputs)\n            device = torch.device(\"cpu\")\n            out = out.to(device)\n            df_pred = self.__predict_max(out).reset_index(drop=True)\n            df_pred[\"image\"] = image_name\n            df_pred_list.append(df_pred)\n            \n        self.df_submit = pd.concat(df_pred_list, axis=0)\n        self.df_submit = self.df_submit[[\"image\", \"labels\"]].reset_index(drop=True)","92c68cef":"predictor = PlantPredictor(model, df_labels_idx)\npredictor.inference()\n\ndf_submit = predictor.df_submit.copy()\n\ndf_submit.to_csv('submission.csv', index=False)\ndf_submit","bc6a5025":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}