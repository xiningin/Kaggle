{"cell_type":{"c0b5c2cd":"code","055a4129":"code","1ceed370":"code","3f978099":"code","af5ea39c":"code","cf40405b":"code","e4da64f9":"code","e96e3c33":"code","b8caa6ca":"code","2e220231":"code","e03fd32d":"markdown"},"source":{"c0b5c2cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","055a4129":"from __future__ import absolute_import\nfrom __future__ import division\nimport numpy as np\nimport scipy.io as sio\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport math\nfrom torch.optim.lr_scheduler import StepLR\nimport random\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn.modules.conv import _ConvNd\n# \u5404\u79cd\u5377\u79ef\u51fd\u6570\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'","1ceed370":"# from mat to matrix\ndef file2matrix(filename):  \n    mat_data = sio.loadmat(filename)\n    data = mat_data['Qt'][0]\n\n    # \u8bad\u7ec3\u6570\u636e\u6837\u672c\u6570train_num\u3001\u6d4b\u8bd5\u6570\u636e\u6837\u672c\u6570test_num\u3001\u6bcf\u4e2a\u6837\u672c\u7684\u91c7\u6837\u70b9\u6570time_num\u3001\u7c7b\u522b\u6570\n    data_num = len(data)\n    time_num = len(data[0][0])\n    class_num = int(data[-1][0][0][1]) + 1\n\n    X_set = np.zeros([data_num, time_num, 1], dtype='float32')\n    y_set = np.zeros([data_num, 1], dtype='int32')\n\n    for i in range(data_num):\n        for j in range(time_num):\n            X_set[i][j][0] = data[i][0][j][0]\n        y_set[i][0] = data[i][0][0][1]\n\n    \n    return X_set,y_set,data_num,time_num,class_num","3f978099":"filename_train = '\/kaggle\/input\/modultaion-recognition\/train-20sample-20db.mat'\nmetatrain_folders,metatrain_y_folders,metatrain_num,metatrain_time,metatrain_class = file2matrix(filename_train)","af5ea39c":"filename_test = '\/kaggle\/input\/modultaion-recognition\/test-20db.mat'\nmetatest_folders,metatest_y_folders,metatest_num,metatest_time,metatrain_class = file2matrix(filename_test)\nprint(metatrain_num)\nprint(metatest_num)","cf40405b":"# \u521d\u59cb\u5316\u6743\u91cd\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        n = m.kernel_size[0] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. \/ n))\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        n = m.weight.size(1)\n        m.weight.data.normal_(0, 0.01)","e4da64f9":"class ResNet(nn.Module):\n# 9\u5c42Res+GAP+Softmax \u5206\u621011\u7c7b\n    def __init__(self):\n        # \u5b9a\u4e49\u5377\u79ef\u7f51\u7edc\u7684\u7ed3\u6784\n        super(ResNet, self).__init__()\n        self.layer1 = nn.Sequential(\n                        nn.Conv1d(in_channels=1,out_channels=8,kernel_size=9,padding = 4),\n                        nn.BatchNorm1d(8,eps=1e-05, momentum=0.1, affine=True),\n                        nn.ReLU(),\n                        nn.Conv1d(in_channels=8,out_channels=8,kernel_size=5,padding = 2),\n                        nn.BatchNorm1d(8,eps=1e-05, momentum=0.1, affine=True),\n                        nn.ReLU(),\n                        nn.Conv1d(in_channels=8,out_channels=8,kernel_size=3,padding = 1),\n                        nn.BatchNorm1d(8,eps=1e-05, momentum=0.1, affine=True))\n        \n        self.layer2 = nn.Sequential(\n                        nn.Conv1d(in_channels=8,out_channels=16,kernel_size=9,padding = 4),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True),\n                        nn.ReLU(),\n                        nn.Conv1d(in_channels=16,out_channels=16,kernel_size=5,padding = 2),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True),\n                        nn.ReLU(),\n                        nn.Conv1d(in_channels=16,out_channels=16,kernel_size=3,padding = 1),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True))\n        self.layer3 = nn.Sequential(\n                        nn.Conv1d(in_channels=16,out_channels=16,kernel_size=9,padding = 4),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True),\n                        nn.ReLU(),\n                        nn.Conv1d(in_channels=16,out_channels=16,kernel_size=5,padding = 2),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True),\n                        nn.ReLU(),\n                        nn.Conv1d(in_channels=16,out_channels=16,kernel_size=3,padding = 1),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True))\n        self.layer4 = nn.AdaptiveAvgPool1d((11))\n        self.layer5 = nn.Linear(16*11,11)\n        self.shortcut1 = nn.Sequential(\n                        nn.Conv1d(in_channels=1,out_channels=8,kernel_size=1),\n                        nn.BatchNorm1d(8,eps=1e-05, momentum=0.1, affine=True))\n        self.shortcut2 = nn.Sequential(\n                        nn.Conv1d(in_channels=8,out_channels=16,kernel_size=1),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True))\n        self.shortcut3 = nn.Sequential(\n                        nn.Conv1d(in_channels=16,out_channels=16,kernel_size=1),\n                        nn.BatchNorm1d(16,eps=1e-05, momentum=0.1, affine=True))\n    def forward(self,x):\n        y = self.layer1(x)\n        shortcut_y = self.shortcut1(x)\n        y = torch.add(shortcut_y, y)\n        y = F.relu(y)\n        z = self.layer2(y)\n        shortcut_z = self.shortcut2(y)\n        z = torch.add(shortcut_z, z)\n        z = F.relu(z)\n        out = self.layer3(z)\n        shortcut_out = self.shortcut3(z)\n        out = torch.add(out, shortcut_out)\n        out = F.relu(out)\n        out = self.layer4(out)\n        out = out.view(out.size(0),-1)\n        out = self.layer5(out)\n        out = F.softmax(out)\n        return out","e96e3c33":"LEARNING_RATE = 0.001\nGPU = 0\n\nresnet = ResNet()\nresnet.apply(weights_init)\nresnet.cuda(GPU)\n\nresnet_optim = torch.optim.Adam(resnet.parameters(),lr=LEARNING_RATE)\nresnet_scheduler = StepLR(resnet_optim,step_size=10000,gamma=0.5)","b8caa6ca":"#\u62bdbatch\u7684\u540c\u65f6\u6253\u6807\u7b7e\nclass generateTask(object):\n    def __init__(self, data_folders, label_folders, batch_num, time_num, class_num):\n\n        self.data_folders = data_folders\n        self.label_folders = label_folders\n        self.batch_num = batch_num\n        self.time_num = time_num\n        self.class_num = class_num\n        \n        \n        # \u62bd\u53d6\u7684\u5185\u5bb9\n        self.sample_data = np.zeros((batch_num,time_num,1))\n        self.sample_label = np.zeros((batch_num,class_num))\n        self.real_label = np.zeros((batch_num))\n\n        \n        #\u4e0d\u80fd\u7834\u574f\u539f\u6709\u7684\u6570\u636e\u7ed3\u6784,\u6240\u4ee5\u53ea\u4ea7\u751f\u7d22\u5f15\n        idx = np.random.choice(len(data_folders),batch_num,replace = False)\n        #\u6253\u6807\u7b7e\u7684\u65f6\u5019\u76f4\u63a5one-hot\n        for i in range(batch_num):\n            self.sample_data[i] = self.data_folders[idx[i]]\n            tmp_label = self.label_folders[idx[i]]\n            self.real_label[i] = tmp_label\n            self.sample_label[i][tmp_label] = 1\n        \n        self.sample_data = self.sample_data.reshape(batch_num,1,1500)\n        self.sample_data = (torch.from_numpy(self.sample_data)).float()\n        self.sample_label = (torch.from_numpy(self.sample_label)).float()","2e220231":"BATCH_NUM = 32\nCLASS_NUM = 10\nEPISODE = 2000\naccuracy = 0.0\nTEST_EPISODE = 1000\nfor episode in range(EPISODE):\n    resnet_scheduler.step(episode)\n    #1:\u751f\u6210task\n    task = generateTask(metatrain_folders,metatrain_y_folders,BATCH_NUM,metatrain_time,metatrain_class)\n    data,label = task.sample_data,task.sample_label\n    scores = resnet(Variable(data).cuda(GPU))\n\n    #print(scores.shape) 128*11\n    mse = nn.MSELoss().cuda(GPU)\n    label = Variable(label).cuda(GPU)\n    loss = mse(scores,label)\n    # \u627e\u5230\u6bcf\u884c\u6700\u5927\u503c\n    #_,predict_labels = torch.max(relations.data,1)\n    \n    # training\n    resnet.zero_grad()\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(resnet.parameters(),0.5)\n    resnet_optim.step()\n    \n    #\u6bcf100step\u6253\u5370loss\u4fe1\u606f\n    if (episode+1)%100 == 0:\n            print(\"episode:\",episode+1,\"loss\",loss.item())\n            \n    if (episode+1)%1000 == 0:\n        total_rewards = 0\n        confusion = np.zeros((metatrain_class,metatrain_class))\n        for i in range(TEST_EPISODE):\n            task = generateTask(metatest_folders,metatest_y_folders,BATCH_NUM,metatest_time,metatrain_class)\n            data,label = task.sample_data,task.sample_label\n            real_label = task.real_label\n            scores = resnet(Variable(data).cuda(GPU))\n\n            _,predict_labels = torch.max(scores.data,1)\n            for i in range(BATCH_NUM):\n                confusion[int(real_label[i])][int(predict_labels[i])] += 1\n                if predict_labels[i] == real_label[i]:\n                    total_rewards += 1\n                else:\n                    total_rewards = total_rewards\n\n        #print(total_rewards)\n        #\u9a8c\u8bc1\u6d4b\u8bd5\u7cbe\u5ea6\u5e76\u6253\u5370\n        test_accuracy = total_rewards\/1.0000\/BATCH_NUM\/TEST_EPISODE\n        print(\"test accuracy:\",test_accuracy)\n        \n        if(test_accuracy > accuracy):\n            accuracy = test_accuracy\n            torch.save(resnet.state_dict(), 'model.pkl')\n        else:\n            accuracy = accuracy","e03fd32d":"# step1:\u5bfc\u5165\u6570\u636e"}}