{"cell_type":{"a2cbe8f5":"code","08817466":"code","7baf8f20":"code","106d86a2":"code","c16902b9":"code","5b58841d":"code","740fffc7":"code","05369e86":"code","cea547b8":"code","a83330f4":"code","b9f02450":"code","7c9cfc53":"code","48d8478e":"code","2e44b365":"code","a3a750a2":"code","4dec9187":"code","2dddbd47":"code","86858ec5":"code","3d15f599":"code","d92996de":"code","eaf92320":"code","cc9a1deb":"code","7a17961e":"code","f58e3249":"code","cfd196af":"code","00f54549":"code","9540e95b":"code","6f13d15f":"code","8e9ad432":"code","75886f34":"code","b03d5dfd":"code","39e8ab6d":"code","a4dbd4f8":"code","aeeacd2c":"code","dadb4344":"code","15a0f694":"code","908b1da9":"code","8d61047d":"code","20b10be5":"code","943969f2":"code","3e79b4fb":"code","ad96208c":"code","89af4513":"code","c53b5592":"code","d7caeee9":"code","dea5c850":"code","8b56fb4b":"code","41a365e4":"code","fe080849":"code","10ac1c9f":"code","3aab2e5d":"code","2d71752c":"code","4a55cfc0":"code","9a48e2f1":"code","684d423e":"code","6bd66ec2":"code","c2d9af71":"code","2c541be5":"code","8ac00a94":"code","5ae36236":"code","e3125783":"code","0a1789ac":"markdown","f80a0772":"markdown","d9074dab":"markdown","b944a525":"markdown","e9bfcc3e":"markdown","2b82eae3":"markdown","9e110e1f":"markdown","4aa7e60e":"markdown","9b9d77fa":"markdown","0c349bbb":"markdown","013620a3":"markdown","6947c59c":"markdown","27bd7107":"markdown","65d5327a":"markdown","d9e7db26":"markdown","a5d5f9f6":"markdown"},"source":{"a2cbe8f5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom numpy import random\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom skimage.transform import rotate\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom skimage.restoration.inpaint import inpaint_biharmonic\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers.core import Dense, Flatten, Dropout, Lambda\n\nfrom keras.utils.np_utils import to_categorical","08817466":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsample = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","7baf8f20":"target = train.label.values\n# Drop the label feature\ntrain = train.drop(\"label\",axis=1)","106d86a2":"scaler = MinMaxScaler()\ntrain = scaler.fit_transform(train)\ntest = scaler.transform(test)","c16902b9":"del scaler","5b58841d":"n = np.random.randint(0, 42000, 10)\n\ndigits = train[n]\nlabels = target[n]\nprint(labels)\n# code for rendering\nf, ax = plt.subplots(\n    2, 5, figsize=(12,5),\n    gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n    squeeze=True\n)\n\nindex = 0\nfor r in range(2):\n    for c in range(5):\n        ax[r,c].axis(\"off\")\n        image = digits[index].reshape(28, 28)\n        ax[r,c].imshow(image, cmap='gray')\n        ax[r,c].set_title('No. {0}'.format(labels[index]))\n        index+=1\n        \nplt.show()\nplt.close()","740fffc7":"rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\nrnd_clf.fit(train, target)","05369e86":"sns.set(rc={'figure.figsize': (15, 10)})\n\ndef plot_digit(data):\n    image = data.reshape(28, 28)\n    plt.imshow(image, cmap = mpl.cm.hot,\n               interpolation=\"nearest\")\n    plt.axis(\"off\")\n    \nplot_digit(rnd_clf.feature_importances_)\n\ncbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\ncbar.ax.set_yticklabels(['Not important', 'Very important'])\nplt.show()","cea547b8":"del rnd_clf","a83330f4":"k_index =[39010, 18519, 37412, 26715, 1257, 25694, 17832, 33398, 24817, 1548, 326, 27648, 4989, 34042, 27653,\n         35860, 36694, 23727, 1048, 38721, 985, 22155, 35557]\n\ndigits = train[k_index]\nlabels = target[k_index]\nprint(labels)\n# code for rendering\nf, ax = plt.subplots(\n    3, 7, figsize=(12,5),\n    gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n    squeeze=True\n)\n\nindex = 0\nfor r in range(3):\n    for c in range(7):\n        ax[r,c].axis(\"off\")\n        image = digits[index].reshape(28, 28)\n        ax[r,c].imshow(image, cmap='gray')\n        ax[r,c].set_title('No. {0}'.format(labels[index]))\n        index+=1\n        \nplt.show()\nplt.close()","b9f02450":"sns.set(rc={'figure.figsize': (7, 5)})\nsns.set_style({'axes.grid' : False}) \n\neight_test_images_restoration = train[34042].reshape(28, 28)\nplt.imshow(eight_test_images_restoration, cmap='gray')","7c9cfc53":"mask = np.zeros((28, 28))\nmask[5:12, 18:24] = 1.0\n\ntset_image_with_defect = eight_test_images_restoration.copy()\ntset_image_with_defect[np.where(mask)] = 0\n\nimage_inpainted = inpaint_biharmonic(tset_image_with_defect, mask) #multichannel=True)","48d8478e":"plt.imshow(image_inpainted.reshape(28, 28), cmap='gray')","2e44b365":"nine_test_images_restoration = train[24817].reshape(28, 28)\nplt.imshow(nine_test_images_restoration, cmap='gray')","a3a750a2":"mask = np.zeros((28, 28))\nmask[7:11, 17:19] = 1.0\n\ntest_images_restoration_defect = nine_test_images_restoration.copy()\ntest_images_restoration_defect[np.where(mask)] = 0\n\nimage_inpainted = inpaint_biharmonic(test_images_restoration_defect, mask)","4dec9187":"plt.imshow(image_inpainted.reshape(28, 28), cmap='gray')","2dddbd47":"index_target_8 = np.array(np.where(target == 8)[0])\nindex_target_9 = np.array(np.where(target == 9)[0])\n\nindex_98 = np.random.randint(0, 4063, 2000) \n\nindex_target_8 = index_target_8[index_98]\nindex_target_9 = index_target_9[index_98]","86858ec5":"for index_8 in tqdm(index_target_8):\n    eight_images_restoration = train[index_8]\n    eight_images_restoration = eight_images_restoration.reshape(28, 28)\n    \n    mask = np.zeros((28, 28))\n    mask[5:12, 18:24] = 1\n    \n    eight_image_with_defect = eight_images_restoration.copy()\n    eight_image_with_defect[np.where(mask)] = 0\n    \n    image_inpainted = inpaint_biharmonic(eight_image_with_defect, mask)\n    \n    train[index_8] = image_inpainted.reshape(784)","3d15f599":"for index_9 in tqdm(index_target_9):\n    nine_images_restoration = train[index_9]\n    nine_images_restoration = nine_images_restoration.reshape(28, 28)\n    \n    mask = np.zeros((28, 28))\n    mask[7:11, 17:19] = 1.0\n    \n    nine_image_with_defect = nine_images_restoration.copy()\n    nine_image_with_defect[np.where(mask)] = 0\n    \n    image_inpainted = inpaint_biharmonic(nine_image_with_defect, mask)\n    \n    train[index_9] = image_inpainted.reshape(784)","d92996de":"unknown_images = train[30352].reshape(28, 28)\nplt.imshow(unknown_images, cmap='gray')","eaf92320":"train = np.delete(train, 30352, axis = 0)\ntarget = np.delete(target, 30352, axis = 0)","cc9a1deb":"print(len(train))\nprint(len(target))","7a17961e":"# causes zooming in the x direction,\ndef matrix_\u0445\u0430\u0445(a):                   \n    matrix_\u0445\u0430\u0445 = np.array([[a, 0], \n                           [0, 1]])\n    return matrix_\u0445\u0430\u0445\n\n# in this example we will transform both coordinates\ndef matrix_\u0445\u0430\u0445_ydy(a, d):            \n    matrix_\u0445\u0430\u0445_ydy = np.array([[a, 0],  \n                               [0, d]])\n    return matrix_\u0445\u0430\u0445_ydy\n\n# point mapping relative to both x y axes\ndef revers_on_xy():\n    revers_on_xy = np.array([[-1, 0],  \n                             [0, -1]])\n    return revers_on_xy\n\n# the shift is proportional to x\ndef shift_on_x(b):\n    shift_on_x = np.array([[1, b],  \n                           [0, 1]])\n    return shift_on_x\n'''\n# the shift is proportional to y\ndef shift_on_y(c):\n    shift_on_y = np.array([[1, 0],  \n                           [c, 1]])\n    return shift_on_y\n'''\n# Turns 90 and 180\n\ndef Turn_on90():\n    turn_on90 = np.array([[0, 1],  \n                          [-1, 0]])\n    return turn_on90\n\ndef Turn_on180():\n    turn_on180 = np.array([[-1, 0],  \n                           [0, -1]])\n    return turn_on180","f58e3249":"n = np.random.randint(0, 41999, 7000)\n\ndigits = train[n] \nlabels = target[n]","cfd196af":"labels","00f54549":"random_transformation_matrix = [\n                                matrix_\u0445\u0430\u0445(np.random.randint(2, 5)), \n    \n                                matrix_\u0445\u0430\u0445_ydy(2, 2), \n                                matrix_\u0445\u0430\u0445_ydy(np.random.randint(0, 3), \n                                               np.random.randint(0, 3)), \n    \n                                revers_on_xy(), \n                    \n                                shift_on_x(np.random.randint(1, 4)), \n                                #shift_on_y(np.random.randint(1, 4)), \n    \n                                Turn_on90(),\n                                Turn_on180()\n                               ]\n\nFrame_new_alis = []\n\nfor ind_new_alis, mas_digits in tqdm(enumerate(digits)):\n    h = random_transformation_matrix[np.random.randint(0, 7)]\n    alis = []\n    for d in range(0, len(list(mas_digits)), 28):\n        alis.append(mas_digits[d:d+28]) \n\n    new_alis = np.zeros((200, 200)) \n    \n    for i, t in enumerate(alis):\n        for ind_t in range(len(t)):\n            new_koar = np.array([i, ind_t]).dot(h)\n            new_alis[abs(new_koar[0])][abs(new_koar[1])] = t[ind_t]\n            \n    Frame_new_alis.append(new_alis)","9540e95b":"f, ax = plt.subplots(\n    2, 5, figsize=(12,5),\n    gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n    squeeze=True\n)\n\nindex = 0\nfor r in range(2):\n    for c in range(5):\n        ax[r,c].axis(\"off\")\n        image = Frame_new_alis[index].reshape(200, 200)\n        ax[r,c].imshow(image, cmap='gray')\n        index+=1\n        \nplt.show()\nplt.close()","6f13d15f":"mas_DF_newalias_dict = {}\n\nfor di in tqdm(range(len(Frame_new_alis))):\n    mas_DF_newalias = []\n    for st_di in Frame_new_alis[di]: \n        for st_di_i in st_di:\n            mas_DF_newalias.append(st_di_i)\n    mas_DF_newalias_dict['{}'.format(di)] = mas_DF_newalias\n    \n    \ndf2 = pd.DataFrame(data=mas_DF_newalias_dict) \n    \ndel mas_DF_newalias_dict   ","8e9ad432":"df2 = df2.loc[:, (df2 != 0).any(axis=0)]","75886f34":"pd.to_numeric(df2.columns)","b03d5dfd":"target_X_reduced_new = labels[pd.to_numeric(df2.columns)]\nprint(len(target_X_reduced_new))","39e8ab6d":"target_X_reduced_new","a4dbd4f8":"print(df2.shape)\nprint(len(df2))\ndf2.head() ","aeeacd2c":"df2 = df2.T","dadb4344":"dict_abbreviated = {}\nfor index_df2 in tqdm(range(df2.shape[0])): \n    abbreviated_mas = []\n    for nd_df2 in df2.iloc[index_df2].values.reshape(200, 200):\n        for truncated_array in nd_df2[:100]:\n            abbreviated_mas.append(truncated_array)\n    dict_abbreviated[index_df2] = abbreviated_mas","15a0f694":"del df2\ndf3 = pd.DataFrame(data=dict_abbreviated).T\ndf3 = df3.iloc[:,0:10000]\ndel dict_abbreviated","908b1da9":"n_df3 = np.random.randint(0, df3.shape[0], 6)\ndigits_df3 = df3.values[n_df3]\nlabels_df3 = target_X_reduced_new[n_df3]\n\n# code for rendering\nf, ax = plt.subplots(\n    2, 3, figsize=(12,5),\n    gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n    squeeze=True\n)\n\nindex = 0\nfor r in range(2):\n    for c in range(3):\n        ax[r,c].axis(\"off\")\n        image = digits_df3[index].reshape(100, 100)\n        ax[r,c].imshow(image, cmap='gray')\n        ax[r,c].set_title('No. {0}'.format(labels_df3[index]))\n        index+=1\n        \nplt.show()\nplt.close()","8d61047d":"n_rotate = np.random.randint(0, 41999, 30000)\ndigits_rotate = train[n_rotate] \nlabels_rotate = target[n_rotate]","20b10be5":"rotatet_x = []\nfor x in digits_rotate:\n    angle = np.random.rand() * 30 - 15\n    rot_img = rotate(x.reshape(28, 28), angle)\n    rotatet_x.append(rot_img.flatten())\n    \nrotatet_x = pd.DataFrame(data=rotatet_x)","943969f2":"print(rotatet_x.shape)\nrotatet_x.head()","3e79b4fb":"n_rotatet_x = np.random.randint(0, rotatet_x.shape[0], 6)\ndigits_rotatet_x = rotatet_x.values[n_rotatet_x]\nlabels_rotatet_x = labels_rotate[n_rotatet_x]\n\n# \u043a\u043e\u0434 \u0434\u043b\u044f \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0438\nf, ax = plt.subplots(\n    2, 3, figsize=(12,5),\n    gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n    squeeze=True\n)\n\nindex = 0\nfor r in range(2):\n    for c in range(3):\n        ax[r,c].axis(\"off\")\n        image = digits_rotatet_x[index].reshape(28, 28)\n        ax[r,c].imshow(image, cmap='gray')\n        ax[r,c].set_title('No. {0}'.format(labels_rotatet_x[index]))\n        index+=1\n        \nplt.show()\nplt.close()","ad96208c":"df3_value = df3.values\ndel df3","89af4513":"pca = PCA(n_components=784)\npca.fit(df3_value)\nX_reduced_new = pca.transform(df3_value)","c53b5592":"len(X_reduced_new[0])","d7caeee9":"print(len(target_X_reduced_new ))\ntarget_X_reduced_new # target variables of converted images","dea5c850":"print(len(target))\ntarget","8b56fb4b":"c = np.concatenate((train, X_reduced_new, rotatet_x.values), axis=0) \ntarget_c = np.concatenate((target, target_X_reduced_new, labels_rotate), axis=0) ","41a365e4":"print(len(c))\nprint(len(target_c))","fe080849":"def ret(a):\n    return  a","10ac1c9f":"c = c.reshape([-1,28,28, 1])\ntarget_c = to_categorical(target_c, num_classes= 10)","3aab2e5d":"X_train, y_train, X_test, y_test = train_test_split(c, target_c, test_size=0.4, random_state=42)","2d71752c":"model= Sequential()\n\nmodel.add(Lambda(ret, input_shape = (28,28, 1)))\n\nmodel.add(Conv2D(64, (3,3), padding= 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3,3), padding= 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3,3), padding= 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32, (3,3), padding= 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\n\n\nmodel.add(Dense(400, activation = 'relu'))\nmodel.add(BatchNormalization())\n#model.add(Dropout(0.4))\nmodel.add(Dense(300, activation = 'relu'))\nmodel.add(BatchNormalization())\n#model.add(Dropout(0.4))\n\nmodel.add(Dense(100, activation = 'softmax'))\nmodel.add(BatchNormalization())\n#model.add(Dropout(0.4))\n\nmodel.add(Dense(10, activation = 'softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = tf.keras.optimizers.SGD())\n","4a55cfc0":"model_fit = model.fit(X_train, X_test, validation_data=(y_train, y_test), epochs=15) ","9a48e2f1":"sns.set(rc={'figure.figsize': (15, 10)})\nplt.plot(model_fit.history['accuracy'], label='train')\nplt.plot(model_fit.history['val_accuracy'], label='test')\nplt.legend()\nplt.show()","684d423e":"test = test.reshape([-1,28, 28, 1])","6bd66ec2":"predictions = model.predict(test)","c2d9af71":"len(predictions)","2c541be5":"predictions = np.argmax(predictions, axis = 1)","8ac00a94":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"predictions.csv\", index=False, header=True) ","5ae36236":"submissions.shape  ","e3125783":"submissions.head() ","0a1789ac":"To begin with, we note that points on the plane are defined using its two coordinates. Thus, geometrically each point is defined by the coordinates of the vector relative to the selected coordinate system. The coordinates of points can be considered as elements of the matrix [x, y], that is, in the form of a row vector or a column vector. The position of these points is controlled by transforming the matrix.           \n\nPoints on the xy plane can be moved to new positions by adding transfer constants to the coordinates of these points:                \n**[x* y*] = [x y]+[a b] = [x+a y+b]**            \nTo move a point on a plane, it is necessary to add a matrix of transformation coefficients to the matrix of its coordinates.   \nConsider the results of matrix multiplication of the matrix [x, y] that defines the point P and the transformation matrix 2*2 of the general form:        \n![image1](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image004.gif)\nLet us analyze the results obtained, considering x * and y * as transformed coordinates. To do this, we examine several special cases.          \nConsider the case when a = d = 1 and c = b = 0. The transformation matrix leads to a matrix identical to the original one:         \n![image2](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image006.gif)\nIf  d = 1, b = c = 0, a = const, then: \n![image3](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image008.gif)\nthis leads to a change in scale in the x direction, since x * = ax. Therefore, this matrix transformation is equivalent to moving the starting point in the x direction.    \nNow b = c = 0, i.e.\n![image4](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image010.gif)   \nAs a result, we get a change in scale in the x and y directions.            \nIf a or (and) d are negative, then the coordinates of the points are displayed. Consider this by setting b = c = 0; d = 1 and a = -1, then \n![image5](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image012.gif)    \nA point was displayed relative to the y axis. In the case b = c = 0, a = 1, d = -1, the mapping occurs relative to the x axis.\nIf b = c = 0, a = d <0, then the mapping will occur relative to the origin. Display and zooming cause only diagonal elements of the transformation matrix.                       \nNow we consider the case when a = d = 1 and c = 0           \n![image6](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image014.gif)\nThe x coordinate of point P does not change, while y * depends linearly on the initial coordinates. This effect is called a shift. Similarly, when a = d = 1, b = 0, the transformation performs a shift in proportion to the coordinate y.                 \n90 \u00b0 rotation can be done using the transformation matrix\n![image7](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image026.gif)\n180 \u00b0 rotation using matrix\n![image8](http:\/\/compgraph.tpu.ru\/Geometry_2D.files\/image030.gif)","f80a0772":"# **Feature Exploration**","d9074dab":"# **Delete controversial data**","b944a525":"![image.png](attachment:image.png)","e9bfcc3e":"# **Modelling**","2b82eae3":"# **Inpainting**","9e110e1f":"# **PCA()**","4aa7e60e":"## Table of contents\n\n\n1. [Data loading](#loading) \n2. [Feature Exploration](#Feature_Exploration)  \n3. [Inpainting](#Inpainting) \n4. [Delete controversial data](#controversial_data)  \n5. [Data addition: vol1](#Data_additionvol1) \n6. [Data addition: vol2](#Data_additionvol2)\n7. [PCA()](#PCA())\n7. [Modelling](#Modelling)\n7. [prediction table](#prediction_table)","9b9d77fa":"Scikit-image is a library for working with images. It has many ready-made algorithms. The advantage of this library is that it is easy to use in conjunction with the well-known numpy \/ scipy                \nrotate each digit by a random small angle from -15 to 15 degrees","0c349bbb":"## thanks for watching             \n![image.png](attachment:image.png)","013620a3":"# **Data addition: vol2**","6947c59c":"Sometimes it happens that in the image certain parts. The process of their restoration - inpainting","27bd7107":"\nTransformation Examples: https:\/\/www.kaggle.com\/morenovanton\/data-supplement","65d5327a":"# **Data loading**","d9e7db26":"# **prediction table**","a5d5f9f6":"# **Data addition: vol1**"}}