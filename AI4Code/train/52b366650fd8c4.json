{"cell_type":{"ea1ea52d":"code","7090f8d5":"code","d76ae734":"code","92a6dadf":"code","fe37edbb":"code","113c2770":"code","3a8163ee":"code","f976dd0f":"code","47cd5128":"code","85ebbc4a":"code","b0ed1ece":"code","ec93a771":"code","1a3431c1":"code","9857a930":"code","9126f50b":"code","956ceb76":"code","995ba86b":"code","4bceb1ef":"code","d8a5e4fb":"code","0f5568d4":"code","43509d83":"code","575d2cb3":"code","d281580d":"code","cf894660":"code","c1b00643":"code","3d7bdc37":"code","03a232fb":"code","0f19ec26":"code","177dce4f":"code","66e09b5d":"code","2b2d6681":"code","08fe3ca9":"code","6a918484":"code","65e8d9fb":"code","2bf4ebea":"code","729e692f":"code","78253327":"code","8e1900c3":"code","6bed6212":"code","f297daf1":"code","c825ec19":"code","d2d8c050":"code","11ca66f3":"code","bf80d10c":"code","755eabfe":"code","56839b38":"markdown","369d9afc":"markdown","05dd2ba8":"markdown","fc87b571":"markdown","e1b6173b":"markdown","cc58a402":"markdown","d2b50a7e":"markdown","e9b97643":"markdown","1626a054":"markdown","858a5790":"markdown","ac501d86":"markdown","33326c45":"markdown","7965192c":"markdown","d653b057":"markdown","8ccc593b":"markdown"},"source":{"ea1ea52d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7090f8d5":"# Importing the basic libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","d76ae734":"import tensorflow as tf","92a6dadf":"# checking the version of the tensorflow \n\nprint(tf.__version__)","fe37edbb":"(x_train,y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()","113c2770":"# Checking the shape of the dataset\n\nx_train.shape","3a8163ee":"y_train.shape","f976dd0f":"x_test.shape","47cd5128":"y_test.shape","85ebbc4a":"from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout","b0ed1ece":"# Getting the Model as well\n\nfrom tensorflow.keras.models import Model","ec93a771":"# kind of normalization\n\nx_train, x_test =  x_train\/255.0, x_test\/255.0","1a3431c1":"print(\"Shape of x_train is:-\",x_train.shape)","9857a930":"print(\"Shape of x_test is:-\", x_test.shape)","9126f50b":"x_train = np.expand_dims(x_train, -1)","956ceb76":"x_train.shape","995ba86b":"# same for x_test\n\nx_test = np.expand_dims(x_test, -1)","4bceb1ef":"x_test.shape","d8a5e4fb":"# Getting the number of classes \n\nk_classes = len(set(y_train))","0f5568d4":"print(\"Total number of classes are:-\",k_classes)","43509d83":"# Giving the shape of Input on the basis of first data of input data.\n\ni = Input(shape = x_train[0].shape)","575d2cb3":"x = Conv2D(32, (3,3), strides=2, activation='relu')(i)","d281580d":"x = Conv2D(64, (3,3), strides=2, activation='relu')(x)","cf894660":"x = Conv2D(128, (3,3), strides=2, activation='relu')(x)","c1b00643":"# To convert the image into the feature vector\n\nx = Flatten()(x)","3d7bdc37":"# Dropout is for regularization\n\nx = Dropout(0.2)(x)","03a232fb":"# Applying the Dense layer\nx = Dense(512, activation = 'relu',)(x)","0f19ec26":"x = Dropout(0.2)(x)","177dce4f":"x = Dense(k_classes, activation = 'softmax')(x)","66e09b5d":"# passing inside the model constructor\n\n# First parameter can be considered as input and second is considered as output\ncnn_model_1 = Model(i, x)","2b2d6681":"cnn_model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n                   metrics=['accuracy'])","08fe3ca9":"my_result_1 = cnn_model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 20)","6a918484":"plt.plot(my_result_1.history['loss'],label = 'loss line')\nplt.plot(my_result_1.history['val_loss'],label = 'validation loss line')\n\nplt.legend()","65e8d9fb":"### Plotting the accuracy per Iteration\n\nplt.plot(my_result_1.history['accuracy'], label = 'Accuracy line')\nplt.plot(my_result_1.history['val_accuracy'], label = 'Validation Accuracy line')\n\nplt.legend()","2bf4ebea":"from sklearn.metrics import confusion_matrix","729e692f":"import itertools","78253327":"def plot_confusion_matrix(cm, classes, normalize = False,\n                         title = 'Confusion Matrix',\n                         cmap = plt.cm.Blues):\n    \n    \"\"\"\n    This function prints and plots the confusion matrix. \n    Normalization can be applied by setting 'normalize=True'.\n    \"\"\"\n    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized Confusion Matrix\")\n        \n    else:\n        print(\"Confusion Matrix, without Normalization\")\n        \n    print(cm)\n    \n    \n    plt.imshow(cm, interpolation = 'nearest', cmap=cmap)\n    plt.title(title)\n    \n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    \n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n    \n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                horizontalalignment='center',\n                color=\"white\" if cm[i, j] > thresh else 'black')\n    \n    \n    plt.tight_layout()\n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    \n    plt.show()\n    \n","8e1900c3":"\np_test = cnn_model_1.predict(x_test).argmax(axis =1) \ncm = confusion_matrix(y_test, p_test)\nplot_confusion_matrix(cm, list(range(10)))","6bed6212":"# Now, performing the label mapping \n\nmy_labels = '''T-shirt\/Top\nTrouser\nPullover\nDress\nCoat\nSandal\nShirt\nSneaker\nBag\nAnkle boot'''.split()","f297daf1":"# We will get a list of these dresses\n\nmy_labels","c825ec19":"misclassified_idx = np.where(p_test!=y_test)[0]","d2d8c050":"misclassified_idx","11ca66f3":"# randomly selecting one data from all those misclassified data\n\ni = np.random.choice(misclassified_idx)","bf80d10c":"i","755eabfe":"plt.imshow(x_test[i].reshape(28,28), cmap = 'gray')\n\nplt.title(\"True Label: %s Predicted %s\" %(my_labels[y_test[i]], my_labels[p_test[i]]))","56839b38":"---\n\n## Compiling the model","369d9afc":"---\n\n### Bulding the Model using the functional API this time not with the sequential way","05dd2ba8":"---\n\nIn CNN shape required by N x H x W x C ...........C means color\n\nSo, In order to make the color channel we need to make that color channel as 1 because this image is a grey scale image","fc87b571":"---\n\n* As we did functional programming in spark and pig, the resultant of this previous layer will be used in the next layer as in functional programming concepts.","e1b6173b":"---\n\n# Plotting the loss per iteration and it should decrease","cc58a402":"* Our classification model using Neural Network got confused in some of the images.\n* It predicted the image as 'Coat' while it is 'Sandal' in real.\n* It also proves that fashion_mnist dataset is more tough in classification than normal mnist dataset.\n* These days fashion_mnist dataset is the normal bench mark for judging the classification of the any image classification technique.\n\n---","d2b50a7e":"---\n\nLoading the fashion_mnist dataset","e9b97643":"---\n\n## Fitting the model with the data or say training the model","1626a054":"---\n\nSo, as we have N x D images or data but in CNN we require N x D x C where C is color.\n So, we require the color information superfluously\n\n We will expand the data","858a5790":"---\n\n# Did not perform that great in case of validation loss, one of reason is also that fashion mnist dataset is more tought than mnist dataset. You can call it overfitting as well.","ac501d86":"---\n\n## Checking some miss classification","33326c45":"---\n\n### Importing the importing functions which will be used in CNN","7965192c":"---\n\n*  Conv2D is used beacause data iss 2D in real like Height and Weight,   there is Conv1D and Conv3D as well \n*  1st parameter used is feature map, second is the filter size, then strides and then activation function\n*  This whole calculation is applied on i type data","d653b057":"---\n\n# Plotting the confusion matrix","8ccc593b":"This also shows that in later Iteration of the model epochs the accuracy start to decrease\n\n---"}}