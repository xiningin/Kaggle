{"cell_type":{"cf2bdb0f":"code","7b1f4603":"code","2fa3848b":"code","725a0bcc":"code","fc5143bb":"code","cacf4cef":"code","6cd591ac":"code","8999470d":"code","1e53aef1":"code","61ce2659":"code","50750c8a":"code","b9a7bee2":"code","e2201a37":"code","38766217":"code","e065e48c":"code","566dda91":"code","2b461966":"code","05ad96fb":"code","99ff9056":"code","fd673688":"code","18d55648":"code","f6b38eba":"code","147c2db4":"markdown","883b4041":"markdown","9769d42b":"markdown","d5a8ccdc":"markdown"},"source":{"cf2bdb0f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7b1f4603":"#reading the files\ntn = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/True.csv\")\nfn = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv\")","2fa3848b":"tn.head()","725a0bcc":"fn.head()","fc5143bb":"#creating a column for true and false\ntn['Verdict'] = 1\nfn['Verdict'] = 0","cacf4cef":"#create a single dataset with 10000 rows of each which should be sufficient to make a good classifier.\ndf = pd.concat([tn.head(5000),fn.head(5000)], ignore_index = True)","6cd591ac":"#check the number of rows\nlen(df)","8999470d":"#creating a single column with text\ndf['Review'] = df['title'] + \" \" + df['text'] + \" \" + df['subject']","1e53aef1":"df.head()","61ce2659":"#import the required packages\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","50750c8a":"ps = PorterStemmer()","b9a7bee2":"#create a list to store all the lines \ncorpus = []","e2201a37":"for i in range (0,10000):\n    line = re.sub('[^a-zA-Z]', \" \", df['Review'][i])\n    line = line.lower()\n    line = line.split()\n    line = [ps.stem(word) for word in line if not word in set(stopwords.words('english'))]\n    line = \" \".join(line)\n    corpus.append(line)","38766217":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()","e065e48c":"#taking the verdict\ny = df['Verdict'].values","566dda91":"len(corpus)","2b461966":"#split into train and test set \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)","05ad96fb":"#classify using Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(X_train,y_train)","99ff9056":"y_pred = classifier.predict(X_test)","fd673688":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","18d55648":"#visualize the confusion matrix\nimport seaborn as sns\nsns.heatmap(cm, annot = True)","f6b38eba":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","147c2db4":"Create the sparse matrix using Count Vectorizer","883b4041":"![facebook-and-instagram-starting-to-identify-and-label-fake-news-before-it-goes-viral.png](attachment:facebook-and-instagram-starting-to-identify-and-label-fake-news-before-it-goes-viral.png)\n\nIn the current world, a single rumour or fake news can spread like wildfire. Even though this many news channels and private broadcasters continue to create their own news for viewership.\n\nIt is very important to know which news to believe in and which to not. This notebook does exactly that using the dataset with fake and true news I was able to train a model with an accuracy of 99%.","9769d42b":"The classification model gives us an accuracy of 99.95% which is very good! \nThus by using this method we can determine whether the news is fake or real.","d5a8ccdc":"Now to run the most important part of Natural Language Processing,\n\nThe sentences are taken and converted into a form that the system can easily understand and run classification on. This is done by using the natural language toolkit and the count vectorizer feature from sckit."}}