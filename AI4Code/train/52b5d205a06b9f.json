{"cell_type":{"da73b319":"code","78ed3235":"code","f53d1e87":"code","872eaa25":"code","ddd3bb49":"code","86e41a12":"code","bfd4b4e1":"code","ee748a3a":"code","746224e2":"code","e3e5ab2b":"code","a6fbf6d5":"code","d7838650":"code","3d8e2056":"code","a74e190b":"code","d70dffbf":"code","805e30a2":"code","7e4a6482":"code","9d810f24":"code","3eac6a38":"code","85c7c087":"code","2661dfcd":"code","c2291ad9":"code","051aa0e0":"code","2a0c6c44":"code","b8cddfc4":"code","e095c334":"code","f4210d13":"markdown"},"source":{"da73b319":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","78ed3235":"import pandas as pd\ncovid_19_clean_complete = pd.read_csv(\"..\/input\/corona-virus-report\/covid_19_clean_complete.csv\")","f53d1e87":"covid_19_clean_complete['Date'] = pd.to_datetime(covid_19_clean_complete['Date'], format=\"%m\/%d\/%y\")","872eaa25":"countries = covid_19_clean_complete['Country\/Region'].unique()","ddd3bb49":"countries","86e41a12":"country_series = {c:covid_19_clean_complete[covid_19_clean_complete['Country\/Region'] == c].groupby('Date').agg('sum').drop(['Lat', 'Long'], axis=1) for c in countries}","bfd4b4e1":"#np.log10(country_series['Mainland China']['Confirmed'].values)","ee748a3a":"c_confirmed = {c:(country_series[c]['Confirmed'] + 1).pct_change(fill_method='bfill').fillna(0) for c in countries}\nc_deaths = {c:(country_series[c]['Deaths'] + 1).pct_change(fill_method='bfill').fillna(0) for c in countries}","746224e2":"import tensorflow as tf\nimport tensorflow_probability as tfp\nimport tensorflow.keras as tfk\nimport tensorflow.keras.layers as tfkl\ntfpl = tfp.layers","e3e5ab2b":"class SpreadModel(tfk.Model):\n    \n    def __init__(self,\n                 n_outputs,\n                 **kwargs):\n        \n        super(SpreadModel, self).__init__(**kwargs)\n        self.input_layer = tfkl.Dense(n_outputs)\n        self.lstms = [tfkl.LSTM(256, return_sequences=True, return_state=True) for i in range(4)]\n        event_shape = [n_outputs]\n        num_components = 20\n        params_size = tfpl.MixtureSameFamily.params_size(\n            num_components,\n            component_params_size=tfpl.IndependentNormal.params_size(event_shape))\n        self.output_dense = tfkl.Dense(params_size, activation=None)\n        self.output_layer = tfpl.MixtureSameFamily(num_components, tfpl.IndependentNormal(event_shape))\n        \n        \n    def call(self, inputs, hidden_states=None, training=None):\n        \n        x = self.input_layer(inputs, training=training)\n        \n        next_hidden_states = []\n        if hidden_states is not None:\n            \n            for rnn, hs in zip(self.lstms, hidden_states):\n                x, fms, fcs = rnn(x, training=training, initial_state=hs)\n                next_hidden_states.append((fms, fcs))\n        else:\n            for rnn in self.lstms:\n                x, fms, fcs = rnn(x, training=training)\n                next_hidden_states.append((fms, fcs))\n        dist_params = self.output_dense(x)\n        return self.output_layer(dist_params, training=training), next_hidden_states\n        ","a6fbf6d5":"spreadModel = SpreadModel(1)","d7838650":"import numpy as np\n\n\n#Remove countries that aren't testing\n\nfilter_countries = set([\n    'China',\n    'Japan',\n    'Hong Kong',\n    'Singapore',\n    'Italy',\n    'France',\n    'UK',\n    'Iceland',\n    'Japan',\n    'Switzerland',\n    'South Korea',\n    'Taiwan',\n    'Spain',\n    'Australia',\n    'Finland',\n    'Sweden',\n    'Norway',\n    'Germany',\n    'Canada',\n])","3d8e2056":"data_filtered = {k:v for k,v in c_confirmed.items() if k in filter_countries}","a74e190b":"c_confirmed.keys()","d70dffbf":"data = np.clip(np.expand_dims(np.asarray([vs.values for vs in data_filtered.values()]), axis=-1).astype(np.float32), 0., 1.)","805e30a2":"data_x = data[:,:-1,:]\ndata_y = data[:,1:,:]","7e4a6482":"ds = tf.data.Dataset.from_tensor_slices((data_x, data_y))\nds = ds.batch(64)","9d810f24":"opt = tfk.optimizers.Adam(1e-6)","3eac6a38":"@tf.function\ndef train_step(data):\n    \n    with tf.GradientTape() as g:\n        \n        inputs, targets = data\n        \n        pred_dist, _ = spreadModel(inputs, training=True)\n        \n        loss = tf.reduce_mean(-pred_dist.log_prob(targets))\n        \n    grads = g.gradient(loss, spreadModel.trainable_variables)\n    grads, _ = tf.clip_by_global_norm(grads, 1.0)\n    opt.apply_gradients(zip(grads, spreadModel.trainable_variables))\n    \n    return loss","85c7c087":"for epoch in range(5000):\n    it = iter(ds)\n    for i, data in enumerate(it):\n        #print(data)\n        loss = train_step(data).numpy()\n        if loss < 0.0001:\n            break\n    if epoch % 100 == 0:\n        print(loss)\n    if loss < 0.0001:\n        break","2661dfcd":"def predict_next_month(country):\n    dist, states = spreadModel(np.expand_dims(np.expand_dims(c_confirmed[country].values, axis=0), axis=-1), training=False)\n    smpls = dist.sample()\n    #print(smpls)\n    #raise Exception()\n    #am = tf.argmax(dist.log_prob(smpls)[...,-1])[0].numpy()\n    #good_sample = smpls[am, 0, -1]\n    nxt_sample = tf.expand_dims(tf.expand_dims(tf.expand_dims(smpls[0,-1,0], axis=-1),axis=0),axis=0)\n    nxt_sample\n    steps = [nxt_sample]\n    \n    for i in range(29):\n        dist, states = spreadModel(nxt_sample, training=False, hidden_states=states)\n        smpls = dist.sample()\n        #raise Exception()\n        #good_sample = smpls[am, 0, -1]\n        #nxt_sample = tf.expand_dims(tf.expand_dims(good_sample, axis=0),axis=-1)\n        steps.append(smpls)\n        \n    return country_series[country]['Confirmed'][-1] * np.cumprod(1 + np.clip(tf.squeeze(tf.concat(steps, axis=1)).numpy().astype(np.float128), 0., 10.))","c2291ad9":"def sample_multi_next_month(country, samples=20):\n    smpls = []\n    for i in range(samples):\n        r = predict_next_month(country)\n        smpls.append(r)\n    return smpls","051aa0e0":"futures = sample_multi_next_month('US')\nfuture_means = np.stack(futures, axis=0).mean(axis=0).astype(np.int32).tolist()","2a0c6c44":"print('USA confirmed coming month:\\n', pd.Series(data=future_means, index=pd.date_range(c_confirmed['Sweden'].reset_index()['Date'].tolist()[-1] + pd.Timedelta('1 day'), periods=30, freq='D')))","b8cddfc4":"futures = sample_multi_next_month('Sweden')\nfuture_means = np.stack(futures, axis=0).mean(axis=0).astype(np.int32).tolist()","e095c334":"print('Sweden confirmed coming month:\\n', pd.Series(data=future_means, index=pd.date_range(c_confirmed['Sweden'].reset_index()['Date'].tolist()[-1] + pd.Timedelta('1 day'), periods=30, freq='D')))","f4210d13":"PREDICTIONS!"}}