{"cell_type":{"86ae4736":"code","dedf0b59":"code","d9903a78":"code","fac33089":"code","b8ad8190":"code","9a8a25de":"code","a30be9c8":"code","591d4abb":"code","7b8ccc1a":"code","fe6a958b":"code","002d3463":"code","964d3135":"code","e86b152d":"code","7d152ef5":"code","4dff36f8":"code","783244e2":"code","5230a0b6":"code","8d8ba199":"markdown","3bcea05e":"markdown","58d33614":"markdown","2fda94db":"markdown","12bb9a07":"markdown","fdb4db01":"markdown","5127277e":"markdown","609fd1ee":"markdown","616d1066":"markdown","dc23ec07":"markdown","14dfd8d9":"markdown","5dab46a1":"markdown","50f3e85f":"markdown","5b1e3b5c":"markdown","e28fb4a4":"markdown","a3a30a30":"markdown","68b61f2f":"markdown"},"source":{"86ae4736":"import numpy as np\nimport pandas as pd\n\nfrom random import randint\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.transform import resize\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n\nfrom functools import partial\nimport keras.backend as K\n\nfrom tqdm import tqdm_notebook","dedf0b59":"import os\nprint(os.listdir(\"..\/input\"))","d9903a78":"# train_path = \"..\/input\/train.csv\"\n# depths_path = \"..\/input\/depths.csv\"\n\n# images_path = \"..\/input\/train\/images\/{}.png\"\n# masks_path = \"..\/input\/train\/masks\/{}.png\"\n# test_path = \"..\/input\/test\/images\/{}.png\"\n\nprint(os.listdir(\"..\/input\"))\n\ntrain_path = \"..\/input\/tgs-salt-identification-challenge\/train.csv\"\ndepths_path = \"..\/input\/tgs-salt-identification-challenge\/depths.csv\"\n\nimages_path = \"..\/input\/tgs-salt-identification-challenge\/train\/images\/{}.png\"\nmasks_path = \"..\/input\/tgs-salt-identification-challenge\/train\/masks\/{}.png\"\ntest_path = \"..\/input\/tgs-salt-identification-challenge\/test\/images\/{}.png\"\n\nimage_1 = \"0b73b427d1\"\nimage_2 = \"0c02f95a08\"\n\nimg_size_target = 128\nimg_size_original = 101\nimg_channels = 1\n\ntest_size = 0.2\ntrain_size = 4000\nrandom_state = 1337","fac33089":"def _resize(img, target_size):\n    img_size = img.size\n    if img_size == target_size:\n        return img\n    return resize(img, (target_size, target_size), mode='constant', preserve_range=True)\n\ndef upsample(img, target_size=img_size_target):\n    return _resize(img, target_size)\n    \ndef downsample(img, target_size=img_size_original):\n    return _resize(img, target_size)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i","b8ad8190":"train_df = pd.read_csv(train_path, index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(depths_path, index_col=\"id\")\n\ntrain_df = train_df.join(depths_df)\n\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\ntrain_df[\"images\"] = [\n    np.array(load_img(images_path.format(idx), grayscale=True)) \/ 255 \n    for idx in tqdm_notebook(train_df.index)\n]\n\ntrain_df[\"masks\"] = [\n    np.array(load_img(masks_path.format(idx), grayscale=True)) \/ 255 \n    for idx in tqdm_notebook(train_df.index)\n]\n\ntrain_df[\"coverage\"] = train_df.masks.map(np.sum) \/ pow(img_size_original, 2)        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n\nx_test = np.array([\n    upsample(np.array(load_img(test_path.format(idx), grayscale=True))) \/ 255 \n    for idx in tqdm_notebook(test_df.index)\n]).reshape(-1, img_size_target, img_size_target, 1)","9a8a25de":"id_train = train_df.index.values\nx_train = np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\ny_train = np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\ncoverage = train_df.coverage.values\ncoverage_class = train_df.coverage_class.values\ndepths = train_df.z.values\n\nID_train, ID_valid, X_train, X_valid, Y_train, Y_valid, C_train, C_valid, CC_train, CC_valid, Z_train, Z_valid = train_test_split(\n    id_train,\n    x_train,\n    y_train,\n    coverage,\n    coverage_class,\n    depths,\n    test_size=test_size,\n    stratify=train_df.coverage_class,\n    random_state=random_state\n)","a30be9c8":"model_path = \"..\/input\/u-net-dropout-augmentation-stratification\/keras.model\"\n\nmodel = load_model(model_path)","591d4abb":"def dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return K.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\nmodel_path = \"..\/input\/u-net-bn-aug-strat-dice\/keras.model\"\n\nclf = partial(bce_dice_loss)\nclf.__name__ = \"bce_dice_loss\"\n\nmodel = load_model(model_path, custom_objects={'bce_dice_loss': clf})","7b8ccc1a":"P_valid = model.predict(X_valid).reshape(-1, img_size_target, img_size_target)\nP_valid = np.array([downsample(x) for x in P_valid])\ny_valid_ori = np.array([train_df.loc[idx].masks for idx in ID_valid])","fe6a958b":"# src: https:\/\/www.kaggle.com\/aglotero\/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","002d3463":"thresholds = np.linspace(0, 1, 50)\nious = np.array([iou_metric_batch(y_valid_ori, np.int32(P_valid > threshold)) for threshold in tqdm_notebook(thresholds)])\n\nthreshold_best_index = np.argmax(ious[9:-10]) + 9\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nPA_valid = np.array([\n    np.round(pred > threshold_best) \n    for pred in tqdm_notebook(P_valid)\n], dtype=np.float32)","964d3135":"plt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","e86b152d":"images_valid = [downsample(X_valid.reshape(-1,128,128)[i]) for i in range(len(X_valid))]\nmasks_valid = [downsample(Y_valid.reshape(-1,128,128)[i]) for i in range(len(Y_valid))]\n\npreds_valid = [P_valid[i] for i in range(len(P_valid))]\npreds_adjusted_valid = [PA_valid[i] for i in range(len(PA_valid))]\n\ncoverage_valid = C_valid\ncoverage_class_valid = CC_valid","7d152ef5":"valid_df = pd.DataFrame({\n    \"images\" : images_valid,\n    \"masks\" : masks_valid,\n    \"depths\" : Z_valid,\n    \"coverages\" : coverage_valid,\n    \"coverage_classes\" : coverage_class_valid,\n    \"predictions\": preds_valid,\n    \"predictions_with_threshold\": preds_adjusted_valid, \n}, index=ID_valid)","4dff36f8":"class_count = valid_df.groupby(\"coverage_classes\").agg(\"count\")[\"coverages\"]\n\ndef jaccard_index(row):\n    a_n_b = np.sum(row['predictions_with_threshold'] == row['masks'])\n    index = float(a_n_b) \/ float((img_size_original ** 2) * 2 - a_n_b)\n    return index\n\nvalid_df[\"jaccard_index\"] = valid_df.apply(jaccard_index, axis=1)\n\njaccard_index_df = valid_df.groupby(\"coverage_classes\").agg([\"mean\", \"count\"])[\"jaccard_index\"]\njaccard_index_df","783244e2":"number_of_images_per_class = 12\nnumber_of_classes = 10","5230a0b6":"df = valid_df.reset_index().set_index(\"coverage_classes\").join(jaccard_index_df).reset_index().set_index(\"index\")\n\nnumber_of_images_per_data = 3\nnumber_of_images = number_of_images_per_class * number_of_classes * number_of_images_per_data\ngrid_width = 12\ngrid_height = number_of_images \/\/ grid_width\n\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width * 2, grid_height * 2))\nimg_count = 0\n        \nfor coverage_class in jaccard_index_df.sort_values(\"mean\").index[:number_of_classes]:\n    temp = df[df[\"coverage_classes\"] == coverage_class].head(number_of_images_per_class)\n    for i in range(number_of_images_per_class):\n        data = temp.iloc[i]\n        \n        img = data.images\n        mask = data.masks\n        pred = data.predictions_with_threshold\n        depth = data.depths\n        coverage = round(data.coverages, 2)\n        \n        # image\n        ax = axs[img_count \/\/ grid_width, img_count % grid_width]\n        img_count += 1\n        ax.imshow(img, cmap=\"Greys\")\n        # mask\n        ax = axs[img_count \/\/ grid_width, img_count % grid_width]\n        img_count += 1\n        ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n        # prediction\n        ax = axs[img_count \/\/ grid_width, img_count % grid_width]\n        img_count += 1\n        ax.imshow(pred, alpha=0.3, cmap=\"OrRd\")\n        \n        # details\n        ax.text(1, img_size_original - 1, depth, color=\"black\")\n        ax.text(img_size_original - 1, 1, coverage, color=\"black\", ha=\"right\", va=\"top\")\n        ax.text(1, 1,                     coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n\nplt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")","8d8ba199":"## Evaulation","3bcea05e":"<span style=\"color:red\">Change these params to adjust number of images per classes to display.<\/span>","58d33614":"### Validation DF","2fda94db":"### First Model","12bb9a07":"## Data","fdb4db01":"## Predictions","5127277e":"<span style=\"color:red\">Add your model and loss function.<\/span>","609fd1ee":"## Libraries","616d1066":"# Purpose\n\n* The purpose of this notebook is to have a way to provide effective and systematic judgement on your models.\n* It calculates the jaccard distance and displays it in a table:\n    * This is based on the coverage class per mask which ranges from 0 to 10 inclusively.\n* It also displays the visuals of the image, mask and predicted mask (after thresholding):\n    * You can change the number of pictures per class.\n\nAdd your model and anything else to the notebook and run it. Where to add your model is highlighted in red.","dc23ec07":"## Confusion Matrix","14dfd8d9":"## Load Model","5dab46a1":"## Scoring","50f3e85f":"## Split the Data","5b1e3b5c":"## Helper Functions","e28fb4a4":"### Second Model","a3a30a30":"## Parameters","68b61f2f":"## Visuals (Threshold Adjusted Predictions)"}}