{"cell_type":{"ed803039":"code","2e372ede":"code","5995aeae":"code","e89fb1c9":"code","d4efb602":"code","765406ce":"code","a682a09a":"code","cd9f5066":"code","440e07f8":"code","e713b4fc":"code","af86d9b8":"code","a256eb25":"code","7404338d":"code","36e37d56":"code","1e3b6942":"code","74c69b3c":"code","f3bbd560":"code","35b28efc":"code","01f3c1f0":"code","b618aefe":"code","0ef069f9":"code","dbfc41fd":"markdown","ce6a4947":"markdown","96062487":"markdown","8915480b":"markdown","daa1138d":"markdown","cb8e7247":"markdown","320f448a":"markdown","fbe2b0ed":"markdown","1e78ed56":"markdown","b92f2891":"markdown","431db7fd":"markdown","541a0170":"markdown","ba74f0dd":"markdown","0f1c4458":"markdown","e23685d5":"markdown","556705e6":"markdown","cea11e48":"markdown","0fee4f36":"markdown","0707b347":"markdown"},"source":{"ed803039":"from random import randint\nimport os\nimport numpy as np \nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plot\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\n\nfrom IPython.display import SVG\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import MaxAbsScaler\n\nimport keras\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.activations as Actications\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport tensorflow.keras.metrics as Metrics\nimport tensorflow.keras.utils as Utils\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.utils.vis_utils import model_to_dot\n\nfrom sklearn.model_selection import train_test_split","2e372ede":"image_size = (128, 128)","5995aeae":"train_images_labels = []\n\ndef get_images(directory, type_id, limit=None):\n    Images = []\n    for dirname, _, filenames in os.walk(directory):\n        current, total = 0, len(filenames)\n        print(dirname)\n        for filename in sorted(filenames):\n            image = cv2.imread(os.path.join(dirname, filename))\n            image = cv2.resize(image,image_size)\n            if image.all() == None:\n                continue\n            Images.append(image)\n            train_images_labels.append(type_id)\n            current += 1\n            if limit and current == limit:\n                break\n            if current % (int(total \/ 10)) == 0:\n                print(round(current\/total * 100) , \"%\")\n       \n    return Images ","e89fb1c9":"cervical_train_images = get_images('..\/input\/224-224-cervical-cancer-screening\/kaggle\/train\/train', 1)\ncervical_train_images.extend(get_images('..\/input\/224-224-cervical-cancer-screening\/kaggle\/additional_Type_1_v2', 1))\ncervical_train_images.extend(get_images('..\/input\/224-224-cervical-cancer-screening\/kaggle\/additional_Type_2_v2', 1))\ncervical_train_images.extend(get_images('..\/input\/224-224-cervical-cancer-screening\/kaggle\/additional_Type_3_v2', 1))\n\nprint('Cervical images: ', len(cervical_train_images))","d4efb602":"f,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,len(cervical_train_images))\n        image = cervical_train_images[rnd_number]\n        ax[i,j].imshow(image)\n        ax[i,j].axis('off')","765406ce":"other_train_images =  get_images('..\/input\/cifar10-128x128-resized-via-cai-super-resolution\/cifar10-128\/train', 0, limit=1000)\n\nprint('Not Cervical images: ', len(other_train_images))","a682a09a":"f,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,len(other_train_images))\n        image = other_train_images[rnd_number]\n        ax[i,j].imshow(image)\n        ax[i,j].axis('off')","cd9f5066":"train_images = cervical_train_images + other_train_images\n\nprint('Total train images: ', len(train_images))\nprint('Total train ids: ', len(train_images_labels))","440e07f8":"def choose_label(id):\n    if id == 1:\n        return \"True\"\n    else: \n        return \"False\"\n\nf,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,len(train_images))\n        image = train_images[rnd_number]\n        type_id = train_images_labels[rnd_number]\n        ax[i,j].imshow(image)\n        ax[i,j].set_title(choose_label(type_id))\n        ax[i,j].axis('off')","e713b4fc":"\n\nx_train, x_test, y_train, y_test = train_test_split(train_images, train_images_labels, test_size=0.25, random_state=17)\n\nx_train = np.array(x_train) \nx_test = np.array(x_test)\n\ny_train = np.array(y_train) \ny_train = to_categorical(y_train)\n\ny_test = np.array(y_test)\ny_test = to_categorical(y_test)\n\nprint(\"Shape of train images:\",x_train.shape)\nprint(\"Shape of train labels:\",y_train.shape)\n\nprint(\"Shape of test images:\",x_test.shape)\nprint(\"Shape of test labels:\",y_test.shape)","af86d9b8":"from keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Input, Activation, merge, Dense, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization \nfrom keras import optimizers","a256eb25":"conf = dict()\n\nconf['num_classes'] = 2\nconf['num_channels'] = 3\nconf['num_epochs'] = 10\nconf['batch_size'] = 64\nconf['validation_split'] = 0.35\nconf['num_workers'] = 8\nconf['image_shape'] = image_size\nconf['pooling_strategy'] = MaxPooling2D","7404338d":"def create_model(conf):\n    \n    num_channels = conf['num_channels']\n    num_classes = conf['num_classes']\n    img_rows, img_cols = conf['image_shape']\n    PoolingStrategy = conf['pooling_strategy']\n    \n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), padding='valid',input_shape=(img_rows, img_cols, num_channels)))\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3))) \n    model.add(Activation('relu'))\n    model.add(PoolingStrategy(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Activation('relu'))\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n\n    adam = Optimizer.Adam(learning_rate=0.0001, decay=1e-6)\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=adam,\n                  metrics=['accuracy'])\n\n    return model\n\nmodel = create_model(conf)\nmodel.summary()\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nUtils.plot_model(model,to_file='model.png',show_shapes=True)","36e37d56":"training_history = model.fit(x = x_train,\n                             y = y_train, \n                             validation_split=conf['validation_split'],  \n                             batch_size=conf['batch_size'], \n                             epochs = conf['num_epochs'], \n                             workers =  conf['num_workers'], use_multiprocessing=True)","1e3b6942":"training_history.history.keys()","74c69b3c":"pd.DataFrame(training_history.history['accuracy']).plot()","f3bbd560":"pd.DataFrame(training_history.history['val_accuracy']).plot()","35b28efc":"pd.DataFrame(training_history.history['loss']).plot()","01f3c1f0":"pd.DataFrame(training_history.history['val_loss']).plot()","b618aefe":"loss, accuracy = model.evaluate(x_test, y_test)\n\nprint(f\"Accuracy for test: {accuracy}\")\nprint(f\"Loss for test: {loss}\")","0ef069f9":"model_name = 'model-0.98'\n\nmodel_json = model.to_json()\nwith open(model_name + \"json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights(model_name + \".h5\")","dbfc41fd":"**Load Cervical Cancer Images**","ce6a4947":"# PART 0 - Preparing\n**Import Libaries**","96062487":"**Save The Model**","8915480b":"# The Cervix Recongition  Project\n\n**Is it an image of the cervix or not?**","daa1138d":"**Show Train Cervical Cancer Samples**","cb8e7247":"**View History Of Training**","320f448a":"**Combine Data Sets**","fbe2b0ed":"**List All Data in History**","1e78ed56":"# PART 4 - Model Training And Testing\n**Training The Model**","b92f2891":"**Check Accuracy And Loss On Testing Data**","431db7fd":"**Show NOT Train Cervical Cancer Samples**","541a0170":"**Config declarations**","ba74f0dd":"# PART 3 - Model Building","0f1c4458":"**Import Libaries**","e23685d5":"**Define Model Arhitecture**","556705e6":"# PART 1 - Data Sets","cea11e48":"**Load The Other Images**","0fee4f36":"# PART 2 - Transform Data For Training\n**Split Data Into Two Separate Parts For Training And Testing**","0707b347":"**Helper Function For Image Extraction**"}}