{"cell_type":{"86700ed0":"code","d8e49fd2":"code","3cbbf7b5":"code","7dcfe464":"code","9dcf4917":"code","68e214b4":"code","1515539b":"code","68d131e7":"code","1641f8da":"code","a9f8edd2":"code","a953fd9b":"code","bbb4d4b3":"code","a0703c34":"code","002cf68f":"code","a88870f7":"code","316ec947":"markdown","ab16313e":"markdown","952fc3b6":"markdown","8f373a7d":"markdown","2f4d0ed7":"markdown","f9f15d4b":"markdown","fce72f43":"markdown","09eca134":"markdown","3fd15fb7":"markdown"},"source":{"86700ed0":"import numpy as np \nimport pandas as pd\nimport os","d8e49fd2":"# Sort paths for viral vs. bacteria pneumonia images\nBASEDIR = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'\ndataset_folders = ['test','train']\nviral_img_paths = []\nbacterial_img_paths = []\n\nfor folder in dataset_folders:\n    # Append path of each file in the directory to files list\n    directory = os.path.join(BASEDIR,folder)\n    path = os.path.join(directory,'PNEUMONIA')\n    print(f'{folder.capitalize()} Dataset')\n    files = os.listdir(path)\n    files = [os.path.join(path,file) for file in files]\n    print(f'Length of dataset is {len(files)}')\n    \n    \n    # Sort the files into either virus or bacteria\n    virus = [file for file in files if 'virus' in file]\n    bacteria = [file for file in files if 'bacteria' in file]\n    print(f'Viral Pneumonia Image Count: {len(virus)}')\n    print(f'Bacterial Pneumonia Image Count: {len(bacteria)}\\n')\n    \n    # Append these paths to the main viral and bacterial lists\n    viral_img_paths.extend(virus)\n    bacterial_img_paths.extend(bacteria)","3cbbf7b5":"# Check format of image paths directories\nprint(f'Total number of viral images: {len(viral_img_paths)}')\nprint(f'Total number of bacterial images: {len(bacterial_img_paths)}')","7dcfe464":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images","9dcf4917":"# Show next 8 X-Rays each time we run this cell\npic_index+=8\n\nnext_viral_pix = viral_img_paths[pic_index-8:pic_index]\nnext_bacterial_pix = bacterial_img_paths[pic_index-8:pic_index]\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n# Show images of viral pneumonia lung x-rays\nfor i, img_path in enumerate(next_viral_pix):\n    # Set up subplot; subplot indices start at 1\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    sp.set_title('Virus')\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\nplt.show()\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\n# Show images of bacterial pneumonia lung x-rays\nfor i, img_path in enumerate(next_bacterial_pix):\n    # Set up subplot; subplot indices start at 1\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    sp.set_title('Bacteria')\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\nplt.show()","68e214b4":"# --------------------\n# Split the data again into training and testing datasets\n# --------------------\nfrom sklearn.model_selection import train_test_split\n\n# Splitting viral pneumonia images\ntrain_virus_fpaths, test_virus_fpaths = train_test_split(viral_img_paths, test_size=0.2)\n\n# Splitting bacterial pneumonia images\ntrain_bacteria_fpaths, test_bacteria_fpaths = train_test_split(bacterial_img_paths, test_size=0.2)","1515539b":"import cv2\nimport random\n\n# Fetch images and resize them to (180,180)\ntrain = []\ntest = []\nimg_size = 180\n\n# Write function to convert images into numpy arrays with labels\ndef convert_images(fnames, label, img_size):\n    data = []\n    for img in fnames:\n        try:\n            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n            resized_arr = cv2.resize(img_arr, (img_size, img_size))\n            data.append([resized_arr, label])\n        except Exception as e:\n            print(e)\n    return data\n\n# Use function to append coverted images to lists above, with bacterial=0 and viral=1\ntrain_viral = convert_images(train_virus_fpaths,1,img_size)\ntrain_bacterial = convert_images(train_bacteria_fpaths,0,img_size)\ntrain = train_viral+train_bacterial\nrandom.shuffle(train)\n\ntest_viral = convert_images(test_virus_fpaths,1,img_size)\ntest_bacterial = convert_images(test_bacteria_fpaths,0,img_size)\ntest = test_viral+test_bacterial\nrandom.shuffle(test)\n\n# Split test and train lists into x and y\nx_train = []\ny_train = []\n\nx_test = []\ny_test = []\n\nfor feature, label in train:\n    x_train.append(feature)\n    y_train.append(label)\n\nfor feature, label in test:\n    x_test.append(feature)\n    y_test.append(label)    \n    \n# Normalise and resize data for feeding into model\nx_train = np.expand_dims(x_train, axis=3)\nx_train = np.array(x_train) \/ 255\ny_train = np.array(y_train)\nx_test = np.expand_dims(x_test, axis=3)\nx_test = np.array(x_test) \/ 255\ny_test = np.array(y_test)","68d131e7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Data augmentation to increase training dataset\ntrain_datagen = ImageDataGenerator( validation_split=0.2,\n                                    zoom_range = 0.2,\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1,\n                                    horizontal_flip = True)\ntest_datagen  = ImageDataGenerator()\n\n# Fit datagenerators\ntrain_datagen.fit(x_train)\ntest_datagen.fit(x_test)\nbatch_size = 16\n\n# --------------------\n# Fit training images in batches of 16 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow(x_train,\n                                    y_train,\n                                    batch_size=batch_size,\n                                    subset='training')   \n# --------------------\n# Fit validation images in batches of 16 using train_datagen generator\n# --------------------\nval_generator = train_datagen.flow(x_train,\n                                    y_train,\n                                    batch_size=batch_size,\n                                    subset='validation')  \n# --------------------\n# Fit test images in batches of 16 using test_datagen generator\n# --------------------\ntest_generator =  test_datagen.flow(x_test,\n                                    y_test,\n                                    batch_size=batch_size)","1641f8da":"# Print number of viral vs. bacterial pneumonia images in training dataset\nnum_train_virus = len(train_virus_fpaths)\nnum_train_bacteria = len(train_bacteria_fpaths)\nnum_train_total = num_train_virus+num_train_bacteria\n\nprint('Total training viral pneumonia images:', num_train_virus)\nprint('Total training bacterial pneumonia images:', num_train_bacteria)\n\nbias_ratio = num_train_bacteria\/num_train_virus\nprint(f'Ratio of bacterial pneumonia to viral pneumonia images: {bias_ratio:.2f}')","a9f8edd2":"# Calculating new weights for bacterial(0) and viral(1) data to correct bias\nweight_for_0 = (1 \/ num_train_bacteria)*(num_train_total)\/2.0 \nweight_for_1 = (1 \/ num_train_virus)*(num_train_total)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(f'Weight for class 0 (Bacteria): {weight_for_0:.2f}')\nprint(f'Weight for class 1 (Virus): {weight_for_1:.2f}')","a953fd9b":"from keras.applications.resnet50 import ResNet50\nimport tensorflow as tf\n\ndef build_model(input_shape, n_out):\n    input_tensor = tf.keras.layers.Input(shape=input_shape)\n    base_model = ResNet50(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    base_model.load_weights('..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',by_name=True)\n#     x = Conv2D(32, kernel_size=(1,1), activation='relu')(base_model.output)\n#     x = Flatten()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n#     x = Dense(1024, activation='relu')(x)\n#     x = Dropout(0.3)(x)\n    final_output = tf.keras.layers.Dense(n_out, activation='sigmoid', name='final_output')(x)\n    model = tf.keras.models.Model(input_tensor, final_output)\n    \n    return model","bbb4d4b3":"# Print out CNN model summary\nmodel = build_model((180,180,1),1)\nmodel.summary()","a0703c34":"# Compiling the model and training it\nfrom tensorflow.keras.optimizers import RMSprop\n\nMETRICS =  [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\nmodel.compile(optimizer=RMSprop(lr=0.0001),\n              loss='binary_crossentropy',\n              metrics = METRICS)\n\nhistory = model.fit(train_generator,\n                    validation_data=val_generator,\n                    steps_per_epoch=(num_train_total*0.8)\/\/batch_size,\n                    epochs=20,\n                    validation_steps=(num_train_total*0.2)\/\/batch_size,\n                    class_weight=class_weight,\n                    verbose=1)","002cf68f":"# Plotting accuracy, loss, precision and recall against number of epochs\nfig, ax = plt.subplots(2, 2, figsize=(15, 10))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss','precision', 'recall']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","a88870f7":"loss, acc, precision, recall = model.evaluate(test_generator)","316ec947":"# 6. Evaluation with Test Data","ab16313e":"**Correcting for Data Imbalance**\n****\nSimilar to the previous notebook where there were many more normal images compared to pneumonia images, there is also a data imbalance here where the dataset contains much more images of bacterial pneumonia compared to viral pneumonia. To correct this, we calculated weights for each category so that each viral pneumonia image has a greater weight and thus balances the dataset.","952fc3b6":"# 2. Visualising the Dataset\nWe can now observe the images by plotting batches of X-rays from the viral and bacterial pneumonia lists.","8f373a7d":"# 5. Training the Model","2f4d0ed7":"We can observe here that it is extremely difficult for a person with a non-medical background to differentiate between a viral versus bacterial pneumonia X-rays. Bacterial pneumonia will typically exhibit a focal lobar consolidation, whilst viral pneumonia develops a more interstitial pattern in both lungs.","f9f15d4b":"# 1. Introduction, Set Up and Checking Data\nContraction of the 2019 novel coronavirus (COVID-19) can lead to serious complications such as pneumonia in more severe cases. As mentioned in the previous notebook, Pneumonia can be detected through X-ray and CT scans, however these are only moderately characteristic to the human eye. Machine learning can be used as a tool to aid pneumonia detection through X-rays, and the objective is to create a model with a low rate of false negatives and false positives. Classifying between viral pneumonia and bacterial pneumonia can be an even more difficult task, as the model will have to differentiate between blocked areas of opacification (bacterial pneumonia) or a more 'interstitial' pattern (viral pneumonia).\n\nThis section includes importing modules, checking dataset for correctness and setting up directory lists. This notebook is run on Kaggle using this dataset: https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia","fce72f43":"# 4. Building CNN\nSince classifying viral versus bacterial pneumonia will require a much more complex neural network, I decided to use transfer learning from the ResNet-50 architecture which was trained on the ImageNet dataset:\n\nhttps:\/\/www.kaggle.com\/keras\/resnet50","09eca134":"By evaluating our model on the unseen test dataset, we acheived a 65.1% accuracy overall which again, is slightly lower than our training data likely due to overfitting. Our training accuracy levelled off at around 73% which resulted in the low test accuracy. This is possibly due to the difficulty in differentiating between the two images, which could potentially be improved through a larger dataset. Our recall is slightly better than our precision, at 59.2% and 50.1% respectively. This reflects that our model has a lower percentage of false negatives than false positives in detecting viral pneumonia.","3fd15fb7":"# 3. Data Preprocessing"}}