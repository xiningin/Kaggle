{"cell_type":{"bee3f957":"code","555e540b":"code","05f622ee":"code","bec0e41c":"code","7a6a42f2":"code","728bf7e7":"code","1ec610db":"code","0333af4d":"code","bcb518cd":"code","b331044f":"code","816f06f8":"code","440d5246":"code","71853929":"code","008e7562":"code","fca9bcd7":"code","e6b9e9b6":"code","79d55a41":"code","e0790d7e":"code","98c0fddd":"code","2d19300b":"code","1d58467f":"code","912c1dd3":"code","5b7f8b1a":"code","bdf36767":"code","4fd4b4fa":"code","f686050d":"code","6ca9f338":"code","2abd66c2":"code","eb2d92a9":"code","1eea5974":"code","c7b7e0b7":"code","133bd1b3":"code","55533492":"code","c3f4aa0e":"code","667d2027":"code","3f5cea1c":"code","f5d29d4a":"code","f90f3293":"code","c5665987":"code","681ee1ef":"code","ac42414e":"code","2b208038":"code","28424033":"code","12095ddf":"code","e015427d":"code","2e3457b1":"code","090ea616":"code","9c1f0fc6":"code","df0c4b7b":"code","ba1bb28d":"code","d55636cf":"code","1cf6239f":"code","d266453c":"code","9cdc34dd":"code","00901c76":"code","893cc1fc":"code","80936ea6":"code","6dcde453":"code","81d15187":"code","60c6e7cc":"markdown","a7792331":"markdown","3c40074c":"markdown","d4483d72":"markdown","27077e15":"markdown","5f5a84cd":"markdown","2581463d":"markdown","19fcc42a":"markdown","08bf9165":"markdown","862005a6":"markdown"},"source":{"bee3f957":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","555e540b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", context=\"talk\")\n\nimport re\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import roc_curve, accuracy_score, roc_auc_score, confusion_matrix, classification_report, cohen_kappa_score, recall_score, precision_score\nfrom sklearn import ensemble\nfrom sklearn.inspection import permutation_importance\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","05f622ee":"testing = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = testing.copy()\n\ntarget = 'Survived'\n\ndata = pd.concat([train, test], axis = 0)\ndata.info()\ndata.head(5)","bec0e41c":"plt.subplots(figsize=(10, 4))\nplt.pie(data['Survived'].value_counts()\n        ,labels = data['Survived'].value_counts().index\n        ,autopct='%1.1f%%'\n        ,shadow=True\n        ,explode = (0.05, 0.0)\n       )\nplt.title('Survived')\nplt.show()","7a6a42f2":"data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])","728bf7e7":"data[data['Fare'].isna()]","1ec610db":"data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Fare']","0333af4d":"data['Fare'] = data['Fare'].fillna(data.groupby(['Pclass'])['Fare'].transform('median'))","bcb518cd":"data.isna().sum()","b331044f":"data['Family_size'] =  data[\"Parch\"] + data[\"SibSp\"] + 1\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'Family_size',y = 'Survived')\nplt.show()","816f06f8":"# data.loc[ data['Family_size'] == 1, 'Family_size_group'] = 0\ndata.loc[(data['Family_size'] > 1) & (data['Family_size'] <= 4), 'small_family_size'] = 1\ndata.loc[(data['Family_size'] > 4) | (data['Family_size'] == 1), 'small_family_size'] = 0\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'small_family_size',y = 'Survived')\nplt.show()","440d5246":"data.loc[data['Family_size'] == 1, 'Alone'] = 1\ndata.loc[data['Family_size'] > 1, 'Alone'] = 0\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'Alone',y = 'Survived')\nplt.show()","71853929":"data['Title'] = data.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\ndata['Title'].unique()","008e7562":"data['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\ndata['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Title', y='Survived')\nplt.show()","fca9bcd7":"data['Title'].value_counts(normalize = True).round(3)","e6b9e9b6":"data['Age'].isna().sum()","79d55a41":"data[data['Age'] < 1]","e0790d7e":"data.loc[data['Age'] < 1, 'Age'] = None\ndata['Age'].isna().sum()","98c0fddd":"data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Age']","2d19300b":"# np.random.seed(42)\n# data['Age'][data['Age'].isna()] = np.random.randint(high = data['Age'].mean() + data['Age'].std()\n#                                                     ,low = data['Age'].mean() - data['Age'].std()\n#                                                     ,size = data['Age'].isna().sum())\n\ndata['Age'] = data['Age'].fillna(data.groupby(['Pclass', 'Title'])['Age'].transform('median'))\n\ndata['Age'].isna().sum()","1d58467f":"data.groupby('Title')['Age'].median()","912c1dd3":"plt.subplots(figsize = (10, 5))\nsns.distplot(data['Age'][data['Survived'] == 1].dropna(), kde = True, label = 'Survived = 1', color = 'orange', bins = 15)\nsns.distplot(data['Age'][data['Survived'] == 0].dropna(), kde = True, label = 'Survived = 0', bins = 15)\nplt.legend(prop = {'size': 12})\nplt.title('Surival by age groups')\nplt.show()","5b7f8b1a":"data.info()","bdf36767":"data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Age']","4fd4b4fa":"def age_grouping(age):\n    if (age < 4):\n        return 'Infants'\n    elif (age >= 4) & (age < 6):\n        return 'Preschool'\n    elif (age >= 6) & (age < 13):\n        return 'Children'\n    elif (age >= 13) & (age < 19):\n        return 'Adolescents'\n    elif (age >= 19) & (age < 45):\n        return 'Adults'\n    elif (age >= 45) & (age < 60):\n        return 'Middle age'\n    else:\n        return 'Seniors'  \n    \ndata['age_group'] = np.vectorize(age_grouping)(data['Age'])\n    \nplt.subplots(figsize=(18, 5))\nsns.barplot(data = data, x = 'age_group', y = 'Survived')\nplt.show()","f686050d":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Parch', y='Survived')\nplt.show()","6ca9f338":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='SibSp', y='Survived')\nplt.show()","2abd66c2":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Pclass', y='Survived')\nplt.show()","eb2d92a9":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Embarked', y='Survived')\nplt.show()","1eea5974":"data[['Pclass', 'Embarked', 'Survived']].groupby(['Pclass', 'Embarked']).mean().round(2)","c7b7e0b7":"data['Cabin'].unique()","133bd1b3":"data['Cabin_group'] = data['Cabin'].str[:1]\ndata.loc[data['Cabin'].isna(), 'Cabin_group'] = 'unkown'\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Cabin_group', y='Survived')\nplt.show()","55533492":"print('Pclass: ', data[data['Cabin_group'] == 'T']['Pclass'].values)\ndata.loc[data['Cabin'] == 'T', 'Cabin_group'] = 'A'","c3f4aa0e":"data[['Cabin_group', 'Pclass', 'Survived']].groupby(['Cabin_group', 'Pclass']).mean().round(2)","667d2027":"data.loc[data['Cabin_group'].isin(['A', 'B', 'C']), 'Cabin_group'] = 'ABC'\ndata.loc[data['Cabin_group'].isin(['D', 'E']), 'Cabin_group'] = 'DE'\ndata.loc[data['Cabin_group'].isin(['F', 'G']), 'Cabin_group'] = 'FG'\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Cabin_group', y='Survived')\nplt.show()","3f5cea1c":"plt.subplots(figsize = (10, 7))\nsns.distplot(data['Fare'][data['Survived'] == 1].dropna(), kde = True, label = 'Survived = 1', color = 'orange', bins = 8)\nsns.distplot(data['Fare'][data['Survived'] == 0].dropna(), kde = True, label = 'Survived = 0', bins = 8)\nplt.legend(prop = {'size': 12})\nplt.title('Surival by age groups')\nplt.show()","f5d29d4a":"data.head()","f90f3293":"data['Cabin_group'].unique()","c5665987":"data['Sex_int'] = data['Sex'].replace({'male': 1, 'female': 0})\ndata['Embarked_int'] = data['Embarked'].replace({'S': 0, 'C': 1, 'Q':2})\ndata['Title_int'] = data['Title'].replace({'Mr': 0, 'Mrs': 1, 'Miss':2, 'Master':3, 'Special':4})\ndata['age_group_int'] = data['age_group'].replace({'Adults': 0, 'Middle age': 1, 'Infants':2, 'Adolescents':3, 'Preschool':4, 'Children':5, 'Seniors':6})\ndata['Cabin_group_int'] = data['Cabin_group'].replace({'unkown': 0, 'ABC': 1, 'DE':2, 'FG':3})","681ee1ef":"corrMatrix = data.corr()\nmask = np.zeros_like(corrMatrix)\nmask[np.triu_indices_from(mask)] = True\n\nplt.subplots(figsize=(22, 10))\nsns.heatmap(corrMatrix, mask = mask, vmax = .3, square = False, annot = True)\nplt.show()","ac42414e":"plt.subplots(figsize = (20, 5))\ncorrMatrix[target].drop([target]).sort_values().plot(kind = 'bar')\nplt.axhline(y = 0.1, color = 'red', linestyle = '--')\nplt.axhline(y = -0.1, color = 'red', linestyle = '--')\nplt.show()","2b208038":"import scipy.stats as ss\n\ndef cramers_v(confusion_matrix):\n    \"calculate Cramers V statistic for categorial-categorial association\"\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum()\n    phi2 = chi2 \/ n\n    r, k = confusion_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))\/(n-1))\n    rcorr = r - ((r-1)**2)\/(n-1)\n    kcorr = k - ((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr \/ min((kcorr-1), (rcorr-1)))\n\ncramers_values = []\nobj_columns = data.select_dtypes(include = object).columns\n\nfor column in obj_columns:\n    confusion_matrix = pd.crosstab(data[column], data[target])\n    cramers_values.append(cramers_v(confusion_matrix.values))\n\ncramers_values_df = pd.DataFrame()\ncramers_values_df['feature'], cramers_values_df['value'] = obj_columns, cramers_values\n\nplt.subplots(figsize = (12, 10))\nplt.barh(cramers_values_df[cramers_values_df['value'] > 0].sort_values(['value'])['feature']\n        ,cramers_values_df[cramers_values_df['value'] > 0].sort_values(['value'])['value'])\nplt.axvline(x = 0.2, color = 'red', linestyle = '--', label = 'Reference line')\nplt.title(\"Categorical feature correlation with the target\")\nplt.show()\n\ncramers_values_df = cramers_values_df[cramers_values_df['value'] > 0.2]['feature'].to_list() # Select correlated features\nlen(cramers_values_df)","28424033":"data = data.loc[:,~data.columns.str.endswith('_int')]","12095ddf":"data.info()\ndata.head()","e015427d":"# Preparing features for analysis\ndummy_features = ['Sex'\n                  ,'Pclass'\n                  ,'Alone'\n                  ,'small_family_size'\n                  ,'Cabin_group'\n                  ,'Title'\n                  ,'Embarked'\n                 ]\n\nfor col in dummy_features:\n    data[col] = data[col].astype(object)\n    \ndrop_features = ['PassengerId', 'Ticket', 'Name', 'Cabin'\n#                  ,'small_family_size'\n                 ,'Family_size'\n#                  ,'Alone'\n                 ,'SibSp'\n                 ,'Parch'\n#                  ,'Embarked'\n#                  ,'Cabin_group'\n#                  ,'Title'\n                 ,'Age'\n                 ,'age_group'\n                ]\n    \ndata = pd.concat([data, pd.get_dummies(data[dummy_features], drop_first = True)], axis = 1, sort = False)\ndata.drop(columns = data[dummy_features], inplace = True)\ndata.drop(columns = data[drop_features], inplace = True)\n\ndata.tail()","2e3457b1":"test = data[data['Survived'].isnull()].drop(['Survived'], axis = 1)\ntrain = data[data['Survived'].notnull()]\n\ntrain.info()\nprint('-'*70)\ntest.info()","090ea616":"# Drop Nan just to be safe\ntrain.dropna(inplace = True)\ntest.dropna(inplace = True)","9c1f0fc6":"# Separating target column from other features\ny = train['Survived']\nx = train.drop(columns = target)\n\n# Train and Test dataset split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42\n                                                    , stratify = y\n                                                   )","df0c4b7b":"# random forest model hyper-tuned\nRF = ensemble.RandomForestClassifier()\nparams = {\n          'n_estimators':[n for n in range(100, 300, 50)] # default 100 \n          ,'max_depth':[n for n in range(3, 10, 2)] # default None \n#           ,'criterion': ['gini', 'entropy'] # default 'gini'\n          ,'min_samples_leaf': [n for n in range(3, 6, 1)] # default 1\n          ,'max_features' : [None] # default 'sqrt'\n          ,'random_state' : [42]\n          }\n\nRF_model = GridSearchCV(RF, param_grid = params, cv = 5, n_jobs = -1).fit(x_train, y_train)\nprint(\"Best Hyper Parameters:\",RF_model.best_params_)\n\n# Area under the curve probability score\nRF_probs = RF_model.predict_proba(x_test)\nRF_probs = RF_probs[:, 1]\nRF_auc = roc_auc_score(y_test, RF_probs)\nprint('AUC: %.3f' % RF_auc)\n\nRF_predictions = RF_model.predict(x_test).astype(int)\nRF_accuracy = accuracy_score(y_test, RF_predictions)\nprint(\"RF accuracy: %.3f\" % RF_accuracy)\nprint(\"RF Recall: \" + '%.3f' % recall_score(y_test, RF_predictions)) # The recall is intuitively the ability of the classifier to find all the positive samples.\nprint(\"RF Precission: \" + '%.3f' % precision_score(y_test, RF_predictions)) # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\nprint(\"RF cohen_kappa_score: %.3f\" % cohen_kappa_score(y_test, RF_predictions)) # Scores above .8 are generally considered good agreement\n\n# AUC plot\nplt.figure(figsize = (8, 6))\nRF_fpr, RF_tpr, RF_thresholds = roc_curve(y_test, RF_probs)\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.plot(RF_fpr, RF_tpr, color = 'tab:green')\nplt.show()","ba1bb28d":"cm = confusion_matrix(y_test, RF_predictions)\nplot_confusion_matrix(cm)\nplt.title('RF')\nplt.show()","d55636cf":"plt.figure(figsize = [6, 6])\npd.Series(RF_model.best_estimator_.feature_importances_, index = x.columns).nlargest(10).plot(kind = 'barh')\nplt.show()","1cf6239f":"perm_importance = permutation_importance(RF_model, x_test, y_test)\nsorted_idx = perm_importance.importances_mean.argsort()\n\nplt.figure(figsize = [8, 8])\nplt.barh(x.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\nplt.xlabel(\"Permutation Importance\")\nplt.show()","d266453c":"data['churn_proba'] = RF_model.best_estimator_.predict_proba(data[x.columns])[:,1]","9cdc34dd":"import shap\nshap.initjs()\n\nexplainer = shap.TreeExplainer(RF_model.best_estimator_)\nshap_values = explainer.shap_values(data[x.columns])\n\nshap.summary_plot(shap_values[1], data[x.columns], plot_type = \"bar\")","00901c76":"shap.summary_plot(shap_values[1], data[x.columns])","893cc1fc":"shap.dependence_plot(\"Fare\", shap_values[1], data[x.columns])","80936ea6":"row = 1\n\nshap.force_plot(explainer.expected_value[1], shap_values[1][:1000], data[x.columns].iloc[:1000], matplotlib = False)\n\nclass ShapObject:\n    def __init__(self, base_values, data, values, feature_names):\n        self.base_values = base_values # Single value\n        self.data = data # Raw feature values for 1 row of data\n        self.values = values # SHAP values for the same row of data\n        self.feature_names = feature_names # Column names\n        \nshap_object = ShapObject(base_values = explainer.expected_value[1],\n                         values = shap_values[1][row,:],\n                         feature_names = data[x.columns].columns,\n                         data = data[x.columns].iloc[row,:])\n\nshap.waterfall_plot(shap_object)","6dcde453":"shap.force_plot(explainer.expected_value[1], shap_values[1][:500], data[x.columns].iloc[:500], matplotlib = False)","81d15187":"predict_RF = RF_model.predict(test).astype(int)\nsubmit_RF = pd.DataFrame({'PassengerId': testing['PassengerId'],\n                          'Survived': predict_RF})\n\n#creating submission file\nfilename_RF = 'Titanic Prediction RF.csv'\nsubmit_RF.to_csv(filename_RF,index=False)\nprint('Saved file: ' + filename_RF)","60c6e7cc":"# Modelling","a7792331":"# Libraries ","3c40074c":"# Feature engineering","d4483d72":"# Feature Importance","27077e15":"# Data cleansing","5f5a84cd":"# Data input","2581463d":"# EDA","19fcc42a":" # Model investigation","08bf9165":"# Export data","862005a6":"# Prep before model"}}