{"cell_type":{"88436278":"code","a02309bf":"code","6f569a6a":"code","daded9b1":"code","8d69de64":"code","e67d6c94":"code","438664c1":"code","dcb1ed1f":"code","8dd4083e":"markdown"},"source":{"88436278":"! pip install tensorflow_model_optimization ","a02309bf":"from tensorflow import lite\nfrom tensorflow import keras\nimport tensorflow_model_optimization as tfmot","6f569a6a":"trainDataGen = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255,\n    shear_range=0.2\n)\n\ntestDataGen = keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255\n)\n\ntrainDataGenerator = trainDataGen.flow_from_directory(\n    directory='..\/input\/waste-classification-data\/DATASET\/TRAIN',\n    target_size=(32, 32),\n    batch_size=128,\n    class_mode='categorical'\n)\ntestDataGenerator = testDataGen.flow_from_directory(\n    directory='..\/input\/waste-classification-data\/DATASET\/TEST',\n    target_size=(32, 32),\n    batch_size=16,\n    class_mode='categorical'\n)","daded9b1":"model = keras.models.Sequential()\nmodel.add(keras.layers.DepthwiseConv2D((3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(keras.layers.Conv2D(32, (1, 1), activation='relu', input_shape=(30, 30, 3)))\nmodel.add(keras.layers.DepthwiseConv2D((3, 3), activation='relu', input_shape=(30, 30, 32)))\nmodel.add(keras.layers.Conv2D(32, (1, 1), activation='relu', input_shape=(28, 28, 32)))\n# model.add(Flatten())\nmodel.add(keras.layers.MaxPool2D((3, 3)))\nmodel.add(keras.layers.Dense(64, activation='relu'))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(2, activation='softmax'))\n\n# model = Sequential()\n# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n# model.add(MaxPool2D((2, 2)))\n# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 32)))\n# model.add(MaxPool2D((2, 2)))\n# model.add(Flatten())\n# model.add(Dense(64, activation='relu'))\n# model.add(Dense(2, activation='softmax'))\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nmodel.summary()","8d69de64":"quantize_model = tfmot.quantization.keras.quantize_model\n\nq_aware_model = quantize_model(model)\n\nq_aware_model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nq_aware_model.summary()\nq_aware_model.fit(trainDataGenerator, epochs=3, verbose=1)","e67d6c94":"q_aware_model.evaluate(testDataGenerator, verbose=1)","438664c1":"q_aware_model.save('model\/double_qu.h5')","dcb1ed1f":"converter = lite.TFLiteConverter.from_keras_model(q_aware_model)\n# converter = lite.TFLiteConverter.from_keras_model(q_aware_model)\nconverter.optimizations = [lite.Optimize.DEFAULT]\ntfliteModel = converter.convert()\nopen('model\/double_qu.tflite', 'wb').write(tfliteModel)","8dd4083e":"## Because I need to generate a quantized model, I use `tensorflow_model_optimization` here to convert the `model` into `q_aware_model`.  \n## If you want to use the original model, please use `model.fit()` by yourself."}}