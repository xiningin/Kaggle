{"cell_type":{"6e09b62d":"code","0cc50b44":"code","abef91fa":"code","8fdc3de4":"code","6546390e":"code","989fe177":"code","203db579":"code","2889fd96":"code","4b8f3611":"code","d1b23009":"code","0c8eb276":"code","c04e51d8":"code","a50fefc3":"markdown","44936e8f":"markdown","5f94ff9b":"markdown","fa4ee47f":"markdown","c87ecac2":"markdown","ae85719e":"markdown","73a3af04":"markdown","4514c697":"markdown","56f492b6":"markdown"},"source":{"6e09b62d":"import os\nimport random\n\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom PIL import Image ","0cc50b44":"DATA_DIR = '\/kaggle\/input\/fruits\/fruits-360_dataset\/fruits-360\/'\nTEST_DATA_DIR = os.path.join(DATA_DIR, 'Test')\n\nos.listdir(DATA_DIR)","abef91fa":"fruits_list = os.listdir(TEST_DATA_DIR)\nfruits_list[:5]","8fdc3de4":"def get_random_fruit_image():\n    fruit_class = np.random.choice(list(fruits_list), size=1)[0]\n    fruit_class_path = os.path.join(TEST_DATA_DIR, fruit_class)\n\n    image_names = os.listdir(fruit_class_path)\n    image_name = np.random.choice(image_names, size=1)[0]\n\n    image_path = os.path.join(fruit_class_path, image_name)\n    image = cv2.imread(image_path)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    return image, fruit_class","6546390e":"image, fruit_class = get_random_fruit_image()\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.title(f'Fruit class: {fruit_class}')\nplt.imshow(image)","989fe177":"fig, axs = plt.subplots(5, 6, figsize=(20, 15))\naxs = axs.flatten()\n\nfor ax in axs:\n    image, fruit_class = get_random_fruit_image()\n\n    ax.set_title(f'Fruit class: {fruit_class}')\n    \n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    ax.imshow(image)\n    \nplt.tight_layout()","203db579":"def remove_background(img, threshold):\n    \"\"\"\n    This method removes background from your image\n    \n    :param img: cv2 image\n    :type img: np.array\n    :param threshold: threshold value for cv2.threshold\n    :type threshold: float\n    :return: RGBA image\n    :rtype: np.ndarray\n    \"\"\"\n    \n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    _, threshed = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n    morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n\n    cnts = cv2.findContours(morphed, \n                            cv2.RETR_EXTERNAL,\n                            cv2.CHAIN_APPROX_SIMPLE)[0]\n\n    cnt = sorted(cnts, key=cv2.contourArea)[-1]\n\n    mask = cv2.drawContours(threshed, cnt, 0, (0, 255, 0), 0)\n    masked_data = cv2.bitwise_and(img, img, mask=mask)\n\n    x, y, w, h = cv2.boundingRect(cnt)\n    dst = masked_data[y: y + h, x: x + w]\n\n    dst_gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n    _, alpha = cv2.threshold(dst_gray, 0, 255, cv2.THRESH_BINARY)\n    b, g, r = cv2.split(dst)\n\n    rgba = [r, g, b, alpha]\n    dst = cv2.merge(rgba, 4)\n\n    return dst","2889fd96":"fig, axs = plt.subplots(3, 2, figsize=(12, 8))\nfig.suptitle('Background removal result', fontsize=14)\n\nfor ax in axs:\n    image, fruit_class = get_random_fruit_image()\n    \n    ax[0].set_title(f'Fruit class: {fruit_class}. Original image.')\n    ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    image = remove_background(image, threshold=250.)\n    \n    ax[1].set_title(f'Fruit class: {fruit_class}. With no backgound.')\n    ax[1].imshow(image)\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","4b8f3611":"def create_blank_image(height, width, rgb_color=(0, 0, 255)):\n    \"\"\"\n    Creates np.array, each channel of which is filled with value from rgb_color\n    \n    Was stolen from:\n    :source: https:\/\/stackoverflow.com\/questions\/4337902\/how-to-fill-opencv-image-with-one-solid-color\n    \"\"\"\n    \n    image = np.zeros((height, width, 3), np.uint8)\n    color = tuple(reversed(rgb_color))\n    \n    image[:] = color\n    \n    return image","d1b23009":"fig, axs = plt.subplots(1, 3, figsize=(12, 4))\nfig.suptitle('Blank images', fontsize=14)\n\naxs = axs.flatten()\n\nCOLORS = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n\nfor idx, ax in enumerate(axs):\n    image = create_blank_image(100, 100, rgb_color=COLORS[idx])\n    \n    ax.set_title(f'Blank image with color: {COLORS[idx]}')\n    ax.imshow(image)","0c8eb276":"def add_backgound(image):\n    \"\"\"\n    Adds background to given image using PIL\n    \"\"\"\n    \n    image_shape = image.shape\n    image_height = image_shape[0]\n    image_width = image_shape[1]\n    \n    backgound = create_blank_image(image_height, \n                                   image_width,\n                                   rgb_color=(0, 0, 255))\n    \n    background = Image.fromarray(backgound)\n    image = Image.fromarray(image)\n    \n    background.paste(image,\n                     (0, 0),\n                     image)\n    \n    return background","c04e51d8":"fig, axs = plt.subplots(6, 3, figsize=(16, 12))\nfig.suptitle('Background adding result', fontsize=14)\n\nfor ax in axs:\n    image, fruit_class = get_random_fruit_image()\n    \n    ax[0].set_title(f'Fruit class: {fruit_class}. Original image.')\n    ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    image = remove_background(image, threshold=250.)\n    \n    ax[1].set_title(f'Fruit class: {fruit_class}. With no backgound.')\n    ax[1].imshow(image)\n    \n    image = add_backgound(image)\n\n    ax[2].set_title(f'Fruit class: {fruit_class}. With new backgound.')\n    ax[2].imshow(image)\n    \nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","a50fefc3":"Background is the same everywhere, it is good.","44936e8f":"## First look on images","5f94ff9b":"You can play with `threshold` value by yourself and find which suits more to your dataset. Good luck!","fa4ee47f":"## Result","c87ecac2":"## Fruits 360 backgound removal\n\nIn this kernel you can find easy and ready-to-use way for removing backgound from images. I used OpenCV, PIL and numpy.\n\n<b>Motivation<\/b>:<br>\nActually, the main thing in Data Scientist's job, it is data processing. But what can you do, if there is no ready dataset? You can create it by yourself! Doing this, sometimes, you need to concatenate images. So, there it is ;)\n\n***\nContents:\n* [Imports](#Imports)\n\n* [First look on images](#First-look-on-images)\n\n* [Background removal](#Background-removal)\n\n* [Result](#Result)\n\n***\n\n#### Acknowledgments\n\n1. [Mihai Oltean and his team](https:\/\/www.kaggle.com\/moltean) - for damn great dataset.\n2. [OpenCV](https:\/\/opencv.org) - for joy and pain. ","ae85719e":"Let's plot more!","73a3af04":"## Background removal","4514c697":"## Imports","56f492b6":"For this task we are using `cv2.threshold` function from OpenCV. You can read more about it [here](https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_thresholding\/py_thresholding.html). From documentation:\n\n> First argument is the source image, which should be a grayscale image. Second argument is the threshold value which is used to classify the pixel values. Third argument is the maxVal which represents the value to be given if pixel value is more than (sometimes less than) the threshold value."}}