{"cell_type":{"b26cf093":"code","dc324a64":"code","f9b6ea7d":"code","ccfd7a7a":"code","bd93ab8f":"code","7d1cfa8d":"code","78170b22":"code","636cadf0":"code","01b572da":"code","721e9728":"code","1e4153a5":"code","996e5b1f":"code","1585854b":"code","0c6b69b6":"code","e5562099":"code","aa8e17e5":"code","d31895b5":"code","7d61757e":"code","9ccf0157":"code","ae1b6483":"code","41d57b83":"code","e0507bd5":"code","08e0e145":"code","6e1409ff":"code","c17b2433":"code","81a970e6":"code","eb6d4448":"code","da202c02":"code","a572ac51":"code","a53e3d13":"code","a8276c26":"code","810a2257":"code","b9fda103":"markdown","8b820286":"markdown","1765ba92":"markdown","7591c601":"markdown","2c31db7f":"markdown","85fb98e4":"markdown","18dcbfe9":"markdown","f8b11f97":"markdown","2da7de50":"markdown","f3d713a0":"markdown","34bd7fb9":"markdown","1e009b0a":"markdown","92dea5b1":"markdown","0c30cd54":"markdown","10aacd55":"markdown","a2fc368a":"markdown","d0e8895e":"markdown","c5d67310":"markdown","87551490":"markdown","bfd1fe3d":"markdown","cfcb665c":"markdown","bf32323d":"markdown","fc6d58e6":"markdown","42671bf2":"markdown"},"source":{"b26cf093":"\nimport numpy as np\nimport pickle\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom scipy.spatial import distance\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","dc324a64":"def dataExt(model, optimizer):\n    # Load feature ext Data\n    filesTrain = \"..\/input\/feature-extracted\/imgNames\/train_data_names.pkl\"\n    filesTest = \"..\/input\/feature-extracted\/imgNames\/test_data_names.pkl\"\n    #..\/input\/feature-extracted\/InceptionV3_features\/InceptionV3_Adagrad_test.npy\n    pathTrain = \"..\/input\/feature-extracted\/\" + model + \"_features\/\" + model + \"_\" + optimizer + \"_train.npy\"\n    pathTest = \"..\/input\/feature-extracted\/\" + model + \"_features\/\" + model + \"_\" + optimizer + \"_test.npy\"\n    \n    # unload pickle the file names\n    with open(filesTrain,'rb') as f:\n        file_train_list = np.load(f, allow_pickle=True)\n        \n    with open(filesTest,'rb') as f:\n        file_test_list = np.load(f, allow_pickle=True)\n    # data preprocessing \n    file_train_list = [i[18:] for i in file_train_list]\n    file_test_list = [i[17:] for i in file_test_list]\n    \n    feat_train_np = np.load(pathTrain)\n    feat_test_np = np.load(pathTest)\n    # return all the data of features of specific model\n    return file_train_list, file_test_list, feat_train_np, feat_test_np","f9b6ea7d":"def LogReg(model, optimizer, X_train, y_train, X_test, y_test):\n    print(\"Logistic Regression\", model, optimizer)    \n    # extract data using function made above\n    a,b,c,d = dataExt(model, optimizer)\n    \n    def name2feat(string):\n        try:\n            index = a.index(string)\n            return c[index]\n        except:\n            index = b.index(string)\n            return d[index]\n    #data preprocessing\n    X_train['img1'] = X_train['img1'].apply(name2feat)\n    X_train['img2'] = X_train['img2'].apply(name2feat)\n    X_test['img1'] = X_test['img1'].apply(name2feat)\n    X_test['img2'] = X_test['img2'].apply(name2feat)\n    \n    new_data_train = []\n    for index,row in X_train.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_train.append(new_list)\n    \n    new_data_test = []\n    for index,row in X_test.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_test.append(new_list)\n    #actual model of logistic regression from sklearn library\n    Model = LogisticRegression()\n    Model.fit(new_data_train, y_train)\n    y_pred = Model.predict(new_data_test)\n    # check the accuracy p, r,f\n    print(\"Acuracy\", accuracy_score(y_test, y_pred))\n    print(\"P,R,F1:\",precision_recall_fscore_support(y_test, y_pred, average='macro'))\n    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred,normalize = 'true'), index = [i for i in \"01\"],\n                  columns = [i for i in \"01\"])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)","ccfd7a7a":"def RandFor(model, optimizer, X_train, y_train, X_test, y_test):\n    print(\"Logistic Regression\", model, optimizer)    \n    \n    a,b,c,d = dataExt(model, optimizer)\n    \n    def name2feat(string):\n        try:\n            index = a.index(string)\n            return c[index]\n        except:\n            index = b.index(string)\n            return d[index]\n       \n    X_train['img1'] = X_train['img1'].apply(name2feat)\n    X_train['img2'] = X_train['img2'].apply(name2feat)\n    X_test['img1'] = X_test['img1'].apply(name2feat)\n    X_test['img2'] = X_test['img2'].apply(name2feat)\n    \n    new_data_train = []\n    for index,row in X_train.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_train.append(new_list)\n    \n    new_data_test = []\n    for index,row in X_test.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_test.append(new_list)\n    \n    Model = RandomForestClassifier()\n    Model.fit(new_data_train, y_train)\n    y_pred = Model.predict(new_data_test)\n    \n    print(\"Acuracy\", accuracy_score(y_test, y_pred))\n    print(\"P,R,F1:\",precision_recall_fscore_support(y_test, y_pred, average='macro'))\n    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred,normalize = 'true'), index = [i for i in \"01\"],\n                  columns = [i for i in \"01\"])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)","bd93ab8f":"\ndef LinearSVM(model, optimizer, X_train, y_train, X_test, y_test):\n    print(\"Linear SVM\", model, optimizer)    \n    \n    a,b,c,d = dataExt(model, optimizer)\n    \n    def name2feat(string):\n        try:\n            index = a.index(string)\n            return c[index]\n        except:\n            index = b.index(string)\n            return d[index]\n       \n    X_train['img1'] = X_train['img1'].apply(name2feat)\n    X_train['img2'] = X_train['img2'].apply(name2feat)\n    X_test['img1'] = X_test['img1'].apply(name2feat)\n    X_test['img2'] = X_test['img2'].apply(name2feat)\n    \n    new_data_train = []\n    for index,row in X_train.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_train.append(new_list)\n    \n    new_data_test = []\n    for index,row in X_test.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_test.append(new_list)\n    \n    Model = svm.SVC(kernel='linear') #rbf by default svm.SVC()\n    Model.fit(new_data_train, y_train)\n    y_pred = Model.predict(new_data_test)\n    \n    print(\"Acuracy\", accuracy_score(y_test, y_pred))\n    print(\"P,R,F1:\",precision_recall_fscore_support(y_test, y_pred, average='macro'))\n    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred,normalize = 'true'), index = [i for i in \"01\"],\n                  columns = [i for i in \"01\"])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)","7d1cfa8d":"def RbfSVM(model, optimizer, X_train, y_train, X_test, y_test):\n    print(\"RBF SVM\", model, optimizer)    \n    \n    a,b,c,d = dataExt(model, optimizer)\n    \n    def name2feat(string):\n        try:\n            index = a.index(string)\n            return c[index]\n        except:\n            index = b.index(string)\n            return d[index]\n       \n    X_train['img1'] = X_train['img1'].apply(name2feat)\n    X_train['img2'] = X_train['img2'].apply(name2feat)\n    X_test['img1'] = X_test['img1'].apply(name2feat)\n    X_test['img2'] = X_test['img2'].apply(name2feat)\n    \n    new_data_train = []\n    for index,row in X_train.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_train.append(new_list)\n    \n    new_data_test = []\n    for index,row in X_test.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_test.append(new_list)\n    \n    Model = svm.SVC(kernel='rbf') #rbf by default svm.SVC()\n    Model.fit(new_data_train, y_train)\n    y_pred = Model.predict(new_data_test)\n    \n    print(\"Acuracy\", accuracy_score(y_test, y_pred))\n    print(\"P,R,F1:\",precision_recall_fscore_support(y_test, y_pred, average='macro'))\n    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred,normalize = 'true'), index = [i for i in \"01\"],\n                  columns = [i for i in \"01\"])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)","78170b22":"def SigmoidSVM(model, optimizer, X_train, y_train, X_test, y_test):\n    print(\"Sigmoid SVM\", model, optimizer)    \n    \n    a,b,c,d = dataExt(model, optimizer)\n    \n    def name2feat(string):\n        try:\n            index = a.index(string)\n            return c[index]\n        except:\n            index = b.index(string)\n            return d[index]\n       \n    X_train['img1'] = X_train['img1'].apply(name2feat)\n    X_train['img2'] = X_train['img2'].apply(name2feat)\n    X_test['img1'] = X_test['img1'].apply(name2feat)\n    X_test['img2'] = X_test['img2'].apply(name2feat)\n    \n    new_data_train = []\n    for index,row in X_train.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_train.append(new_list)\n    \n    new_data_test = []\n    for index,row in X_test.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_test.append(new_list)\n    \n    Model = svm.SVC(kernel='sigmoid') #rbf by default svm.SVC()\n    Model.fit(new_data_train, y_train)\n    y_pred = Model.predict(new_data_test)\n    \n    print(\"Acuracy\", accuracy_score(y_test, y_pred))\n    print(\"P,R,F1:\",precision_recall_fscore_support(y_test, y_pred, average='macro'))\n    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred,normalize = 'true'), index = [i for i in \"01\"],\n                  columns = [i for i in \"01\"])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)","636cadf0":"def PolySVM(model, optimizer, X_train, y_train, X_test, y_test):\n    print(\"POLY SVM\", model, optimizer)    \n    \n    a,b,c,d = dataExt(model, optimizer)\n    \n    def name2feat(string):\n        try:\n            index = a.index(string)\n            return c[index]\n        except:\n            index = b.index(string)\n            return d[index]\n       \n    X_train['img1'] = X_train['img1'].apply(name2feat)\n    X_train['img2'] = X_train['img2'].apply(name2feat)\n    X_test['img1'] = X_test['img1'].apply(name2feat)\n    X_test['img2'] = X_test['img2'].apply(name2feat)\n    \n    new_data_train = []\n    for index,row in X_train.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_train.append(new_list)\n    \n    new_data_test = []\n    for index,row in X_test.iterrows():\n        new_list = list(row[0])\n        new_list.extend(row[1])\n        new_data_test.append(new_list)\n    \n    Model = svm.SVC(kernel='poly') #rbf by default svm.SVC()\n    Model.fit(new_data_train, y_train)\n    y_pred = Model.predict(new_data_test)\n    \n    print(\"Acuracy\", accuracy_score(y_test, y_pred))\n    print(\"P,R,F1:\",precision_recall_fscore_support(y_test, y_pred, average='macro'))\n    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred,normalize = 'true'), index = [i for i in \"01\"],\n                  columns = [i for i in \"01\"])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)","01b572da":"try:\n    %%time\n    data = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\n    X_data = data[['img1','img2']]\n    y_data = data[['target']]\n    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\n    LogReg('VGG16', 'Adam', X_train, y_train, X_test, y_test)\nexcept:\n    pass","721e9728":"try:\n    %%time\n    data = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\n    X_data = data[['img1','img2']]\n    y_data = data[['target']]\n    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\n    LogReg('VGG16','RMSprop', X_train, y_train, X_test, y_test)\nexcept:\n    pass","1e4153a5":"try:\n    %%time\n    data = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\n    X_data = data[['img1','img2']]\n    y_data = data[['target']]\n    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\n    LogReg('InceptionV3','Adam', X_train, y_train, X_test, y_test)\nexcept:\n    pass","996e5b1f":"try:\n    %%time\n    data = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\n    X_data = data[['img1','img2']]\n    y_data = data[['target']]\n    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\n    LogReg('InceptionV3','Adagrad', X_train, y_train, X_test, y_test)\nexcept:\n    pass","1585854b":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRandFor('VGG16','Adam', X_train, y_train, X_test, y_test)","0c6b69b6":"\n%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRandFor('VGG16','RMSprop', X_train, y_train, X_test, y_test)","e5562099":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRandFor('InceptionV3','Adam', X_train, y_train, X_test, y_test)","aa8e17e5":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRandFor('InceptionV3','Adagrad', X_train, y_train, X_test, y_test)","d31895b5":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nLinearSVM('VGG16','Adam', X_train, y_train, X_test, y_test)","7d61757e":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nLinearSVM('VGG16','RMSprop', X_train, y_train, X_test, y_test)","9ccf0157":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nLinearSVM('InceptionV3','Adam', X_train, y_train, X_test, y_test)","ae1b6483":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nLinearSVM('InceptionV3','Adagrad', X_train, y_train, X_test, y_test)","41d57b83":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRbfSVM('VGG16','Adam', X_train, y_train, X_test, y_test)","e0507bd5":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRbfSVM('VGG16','RMSprop', X_train, y_train, X_test, y_test)","08e0e145":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRbfSVM('InceptionV3','Adam', X_train, y_train, X_test, y_test)","6e1409ff":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nRbfSVM('InceptionV3','Adagrad', X_train, y_train, X_test, y_test)","c17b2433":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nSigmoidSVM('VGG16','Adam', X_train, y_train, X_test, y_test)","81a970e6":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nSigmoidSVM('VGG16','RMSprop', X_train, y_train, X_test, y_test)","eb6d4448":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nSigmoidSVM('InceptionV3','Adam', X_train, y_train, X_test, y_test)","da202c02":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nSigmoidSVM('InceptionV3','Adagrad', X_train, y_train, X_test, y_test)","a572ac51":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nPolySVM('VGG16','Adam', X_train, y_train, X_test, y_test)","a53e3d13":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nPolySVM('VGG16','RMSprop', X_train, y_train, X_test, y_test)","a8276c26":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nPolySVM('InceptionV3','Adam', X_train, y_train, X_test, y_test)","810a2257":"%%time\ndata = pd.read_csv('..\/input\/re-arranged-data\/sign_data\/data.csv')\nX_data = data[['img1','img2']]\ny_data = data[['target']]\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\nPolySVM('InceptionV3','Adagrad', X_train, y_train, X_test, y_test)","b9fda103":"![image.png](attachment:530ed830-9a48-4498-8fee-5a5b2060726b.png)","8b820286":"<h1> Linear SVM <\/h1>","1765ba92":"<h2> Outline <\/h2>","7591c601":"- Introduction\n- Literature Survey\n- The Proposed Methodology\n- Industrial Application\n- Conclusion\n- References","2c31db7f":"Models selected for feature extraction are used with supervised learning algorithms to classify:-\n\n1. Logistic Regression\n2. Random Forest\n3. Linear SVM\n4. RBF SVM\n5. Sigmoid SVM\n6. Poly SVM","85fb98e4":"<h1> Sigmoid SVM Test <\/h1>","18dcbfe9":"<h2> Part 2 <\/h2>","f8b11f97":"<h1> Classification Results <\/h1>","2da7de50":"<h1> HANDWRITTEN SIGNATURE VERIFICATION USING CONVOLUTION NEURAL NETWORK (CNN) <\/h1>","f3d713a0":"1. Average training time for Inception-v3-Adagrad architecture is significantly lower than other architectures.\n2. Best performing model is Poly SVM with the accuracy of 99.28 %.\n3. We have classified the fraud signature with accuracy of 99.999 %.\n4. We have classified the genuine with accuracy of 99.00 %.","34bd7fb9":"<h1> Rbf SVM <\/h1>","1e009b0a":"<h1> Logistic Regression Test <\/h1>","92dea5b1":"<h1> CLASSIFICATION <\/h1>","0c30cd54":"<h1> Random Forest <\/h1>","10aacd55":"<h1> Sigmoid SVM <\/h1>","a2fc368a":"_This is Yash Gupta, India Institute of Information Technology, Nagpur representing final year project. Stay and upvote if you like the notebook._","d0e8895e":"<h1> Linear SVM Test <\/h1>","c5d67310":"<h1> RBF SVM Test <\/h1>","87551490":"<h1> Classification Best Performing Models <\/h1>","bfd1fe3d":"<h1> Poly SVM <\/h1>","cfcb665c":"<h1> Random Forest <\/h1>","bf32323d":"<h1> Poly SVM Test <\/h1>","fc6d58e6":"<h1> Logistic Regression <\/h1>","42671bf2":"[](http:\/\/)"}}