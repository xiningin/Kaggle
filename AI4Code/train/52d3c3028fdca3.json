{"cell_type":{"040f1704":"code","bc36ca18":"code","0208ff2a":"code","124db26f":"code","93351dce":"code","22c308d7":"code","bffbb60f":"code","86f773ce":"code","2b8f5e99":"code","5b1a2c4a":"code","5bd84658":"code","6ebea423":"code","32af910d":"code","f9583d04":"code","ff00d2bb":"code","f70ade93":"code","63b697b4":"code","abbe78cf":"code","aebf5da5":"code","99b2fb94":"code","93cdc50c":"code","95a10ab2":"code","bfcfe79e":"code","ffe7a743":"code","37738e45":"code","5598722a":"code","d0623250":"code","8d78bb0e":"code","dfc12d1e":"code","4a181f5e":"code","ab22994a":"code","aae5d096":"code","d86a2e4f":"code","c40e3da3":"code","774e92e7":"code","e9f56308":"code","77d35230":"markdown","c13dbed6":"markdown","e2e793c7":"markdown","5a1ba498":"markdown","0bd2eb89":"markdown","278c03cd":"markdown","546dc973":"markdown","e1cd468e":"markdown","2ad5de00":"markdown","ef3d2dc3":"markdown","73124bb9":"markdown","345c6dad":"markdown","d797df29":"markdown","c99574f7":"markdown","b6b1138f":"markdown","c8bf07bc":"markdown","b75dd8ed":"markdown","11f675ec":"markdown","3c718d13":"markdown","c2f1071a":"markdown","fe2e896a":"markdown","616b7de0":"markdown","94250681":"markdown","85258a53":"markdown","c0579b2d":"markdown"},"source":{"040f1704":"# Basic Libraries\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Classification Models\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n\n# Helper Libraries\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_validate\nfrom imblearn.pipeline import Pipeline as imbpipeline\nfrom sklearn.datasets import make_classification, load_breast_cancer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report, f1_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nprint(os.listdir(\"..\/input\"))","bc36ca18":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","0208ff2a":"df.describe()","124db26f":"df.isna().sum()","93351dce":"df[df.duplicated() == True]","22c308d7":"df['Outcome'].value_counts()","bffbb60f":"fig, (ax1,ax2) = plt.subplots(1,2,figsize = (12,5),constrained_layout=True)\nplt.subplots_adjust(wspace = 0.5)\n\nnegative_count = df.Outcome.value_counts().tolist()[0]\npositive_count = df.Outcome.value_counts().tolist()[1]\n\nax1.bar(df.Outcome.unique(),df.Outcome.value_counts(),color = ['blue', 'orange'],width = 0.8)\nax1.set_xticks(df.Outcome.unique())\nax1.set_xticklabels(('Negative','Positive'))\n\nax2.pie((negative_count,positive_count), labels = ('Negative','Positive'), autopct='%1.1f%%', shadow=True, startangle=90, explode=[0,0.1])\n\nplt.show()","86f773ce":"feature = 'Age'\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,5),constrained_layout=True)\nbin_x = range(25,80,2)\n\nax1.hist(df[feature],bins=bin_x,rwidth=0.9)\nax1.set_xticks(range(25,80,2))\nax1.set_xlabel('Age',fontsize=15)\nax1.set_ylabel('Count',fontsize=15)\nax1.set_title('Age Distribution',fontsize=20)\n\nax2.hist(df[df['Outcome']==1][feature], label = 'Positive',bins=bin_x,rwidth=0.9)\nax2.hist(df[df['Outcome']==0][feature], label = 'Negative',bins=bin_x,rwidth=0.5)\nax2.legend()\nax2.set_xticks(range(25,80,2))\nax2.set_xlabel('Age',fontsize=15)\nax2.set_ylabel('Count',fontsize=15)\nax2.set_title('Diabetes: Positive vs Negative',fontsize=20)\n\nplt.show()","2b8f5e99":"x = df.groupby(['Age', 'Pregnancies']).agg({'Outcome':'count'})\ny = df.groupby(['Age']).agg({'Outcome':'count'})\nz = (x.div(y, level='Age') * 100)\nq= 100 - z\n\nfig, ax = plt.subplots(2,2, figsize = (20,12))\nplt.subplots_adjust(hspace = 0.5)\n\nax[0,0].hist(df[df['Outcome']==1].Age.tolist(),bins=bin_x,rwidth=0.8)\nax[0,0].set_xticks(range(30,80,2))\nax[0,0].set_xlabel('Age Range',fontsize=15)\nax[0,0].set_ylabel('Patient Count',fontsize=15)\nax[0,0].set_title('Patients having Diabetes',fontsize=20)\n\nax[0,1].hist(df[df['Outcome']==0].Age.tolist(),bins=bin_x,rwidth=0.8)\nax[0,1].set_xticks(range(30,80,2))\nax[0,1].set_xlabel('Age Range',fontsize=15)\nax[0,1].set_ylabel('Patient Count',fontsize=15)\nax[0,1].set_title('People not having Diabetes',fontsize=20)\n\nax[1,0].scatter(z.xs(1,level=1).reset_index().Age,z.xs(1,level=1).reset_index().Outcome, s=(x.xs(1,level=1).Outcome)*30,edgecolors = 'r',c = 'yellow')\nax[1,0].plot(z.xs(1,level=1).reset_index().Age,z.xs(1,level=1).reset_index().Outcome)\nax[1,0].set_xticks(range(15,70,2))\nax[1,0].set_yticks(range(0,50,2))\nax[1,0].set_xlabel('Age',fontsize=15)\nax[1,0].set_ylabel('%',fontsize=15)\nax[1,0].set_title('% of Patients with Diabetes by age',fontsize=20)\n\nax[1,1].scatter(z.xs(1,level=1).reset_index().Age,q.xs(1,level=1).reset_index().Outcome, s=(x.xs(1,level=1).Outcome)*30,edgecolors = 'r',c = 'yellow')\nax[1,1].plot(z.xs(1,level=1).reset_index().Age,q.xs(1,level=1).reset_index().Outcome)\nax[1,1].set_xticks(range(15,70,2))\nax[1,1].set_yticks(range(50,100,2))\nax[1,1].set_xlabel('Age',fontsize=15)\nax[1,1].set_ylabel('%',fontsize=15)\nax[1,1].set_title('% of Patients without Diabetes by age',fontsize=20)\n\nplt.show()","5b1a2c4a":"feature = 'BloodPressure'\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,5),constrained_layout=True)\nbin_x = range(40,100,2)\n\nax1.hist(df[feature],bins=bin_x,rwidth=0.9)\nax1.set_xticks(range(40,100,2))\nax1.set_xlabel('BloodPressure',fontsize=15)\nax1.set_ylabel('Count',fontsize=15)\nax1.set_title('BloodPressure Distribution',fontsize=20)\n\nax2.hist(df[df['Outcome']==1][feature], label = 'Positive',bins=bin_x,rwidth=0.9)\nax2.hist(df[df['Outcome']==0][feature], label = 'Negative',bins=bin_x,rwidth=0.5)\nax2.legend()\nax2.set_xticks(range(40,100,2))\nax2.set_xlabel('BloodPressure',fontsize=15)\nax2.set_ylabel('Count',fontsize=15)\nax2.set_title('Diabetes: Positive vs Negative',fontsize=20)\n\nplt.show()","5bd84658":"f,ax=plt.subplots(3,2,figsize=(18,18))\nsns.violinplot(x='Outcome', y='Pregnancies', data=df, ax=ax[0][0])\nax[0][0].set_title('Outcome vs Pregnancies',fontsize=20)\nsns.violinplot(x='Outcome', y='Glucose', data=df, ax=ax[0][1])\nax[0][1].set_title('Outcome vs Glucose',fontsize=20)\nsns.violinplot(x='Outcome', y='BloodPressure', data=df, ax=ax[1][0])\nax[1][0].set_title('Outcome vs BloodPressure',fontsize=20)\nsns.violinplot(x='Outcome', y='SkinThickness', data=df, ax=ax[1][1])\nax[1][1].set_title('Outcome vs SkinThickness',fontsize=20)\nsns.violinplot(x='Outcome', y='Insulin', data=df, ax=ax[2][0])\nax[2][0].set_title('Outcome vs Insulin',fontsize=20)\nsns.violinplot(x='Outcome', y='BMI', data=df, ax=ax[2][1])\nax[2][1].set_title('Outcome vs BMI',fontsize=20)\n\nplt.show()","6ebea423":"fig = plt.figure(figsize=(12,8))\nax1 = sns.scatterplot(x = df['Glucose'], y = df['Age'], hue = \"Outcome\",\n                    data = df, edgecolor='black')\n\nplt.annotate('N1', size=25, color='black', xy=(80, 30), xytext=(60, 35),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([70, 130], [30, 30], linewidth=2, color = 'red')\nplt.plot([130, 130], [20, 30], linewidth=2, color = 'red')\nplt.plot([70, 130], [20, 20], linewidth=2, color = 'red')\nplt.plot([70, 70], [20, 30], linewidth=2, color = 'red')\nplt.title('Glucose vs Age')\nplt.show()","32af910d":"df1 = df[(df['Glucose']<=130) & (df['Age']<=30)]\ndf2 = df[(df['Glucose']>130) & (df['Age']>30)]\n\nf,ax=plt.subplots(1,3,figsize=(18,5))\nax[0].bar(df.Outcome.unique(),df.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[0].set_xticks(df.Outcome.unique())\nax[0].set_xticklabels(('Negative','Positive'))\nax[0].set_title('Complete Distribution',fontsize=20)\n\nax[1].bar(df1.Outcome.unique(), df1.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[1].set_xticks(df1.Outcome.unique())\nax[1].set_xticklabels(('Negative','Positive'))\nax[1].set_title('N1 Distribution',fontsize=20)\n\nax[2].bar(df2.Outcome.unique(), df2.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[2].set_xticks(df1.Outcome.unique())\nax[2].set_xticklabels(('Negative','Positive'))\nax[2].set_title('Rest Distribution',fontsize=20)\n\nplt.show()","f9583d04":"fig = plt.figure(figsize=(12,8))\nax1 = sns.scatterplot(x = df['Glucose'], y = df['BloodPressure'], hue = \"Outcome\",\n                    data = df, edgecolor='black')\n\nplt.annotate('N2', size=25, color='black', xy=(70, 80), xytext=(50, 110),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([40, 105], [80, 80], linewidth=2, color = 'red')\nplt.plot([40, 40], [0, 80], linewidth=2, color = 'red')\nplt.plot([40, 105], [0, 0], linewidth=2, color = 'red')\nplt.plot([105, 105], [0, 80], linewidth=2, color = 'red')\nplt.title('Glucose vs BloodPressure')\nplt.show()","ff00d2bb":"df1 = df[(df['Glucose']<=120) & (df['BloodPressure']<=80)]\ndf2 = df[(df['Glucose']>120) & (df['BloodPressure']>0)]\n\nf,ax=plt.subplots(1,3,figsize=(18,5))\nax[0].bar(df.Outcome.unique(),df.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[0].set_xticks(df.Outcome.unique())\nax[0].set_xticklabels(('Negative','Positive'))\nax[0].set_title('Complete Distribution',fontsize=20)\n\nax[1].bar(df1.Outcome.unique(), df1.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[1].set_xticks(df1.Outcome.unique())\nax[1].set_xticklabels(('Negative','Positive'))\nax[1].set_title('N2 Distribution',fontsize=20)\n\nax[2].bar(df2.Outcome.unique(), df2.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[2].set_xticks(df1.Outcome.unique())\nax[2].set_xticklabels(('Negative','Positive'))\nax[2].set_title('Rest Distribution',fontsize=20)\n\nplt.show()","f70ade93":"fig = plt.figure(figsize=(12,8))\n\nax1 = sns.scatterplot(x = df['SkinThickness'], y = df['BMI'], hue = \"Outcome\",\n                    data = df, edgecolor='black')\n\nplt.annotate('N3', size=25, color='black', xy=(20, 20), xytext=(50, 25),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([0, 20], [30, 30], linewidth=2, color = 'red')\nplt.plot([0, 0], [16, 30], linewidth=2, color = 'red')\nplt.plot([0, 20], [16, 16], linewidth=2, color = 'red')\nplt.plot([20, 20], [16, 30], linewidth=2, color = 'red')\nplt.title('SkinThickness vs BMI')\nplt.show()","63b697b4":"df1 = df[(df['SkinThickness']<=20) & (df['BMI']<=30)]\ndf2 = df[(df['SkinThickness']>20) & (df['BMI']>30)]\n\nf,ax=plt.subplots(1,3,figsize=(18,5))\nax[0].bar(df.Outcome.unique(),df.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[0].set_xticks(df.Outcome.unique())\nax[0].set_xticklabels(('Negative','Positive'))\nax[0].set_title('Complete Distribution',fontsize=20)\n\nax[1].bar(df1.Outcome.unique(), df1.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[1].set_xticks(df1.Outcome.unique())\nax[1].set_xticklabels(('Negative','Positive'))\nax[1].set_title('N3 Distribution',fontsize=20)\n\nax[2].bar(df2.Outcome.unique(), df2.Outcome.value_counts(), color = ['blue', 'orange'],width = 0.8)\nax[2].set_xticks(df1.Outcome.unique())\nax[2].set_xticklabels(('Negative','Positive'))\nax[2].set_title('Rest Distribution',fontsize=20)\n\nplt.show()","abbe78cf":"categorical = ['Glucose', 'BMI', 'Age',]\nfor col in categorical:    \n    df['Categorical'] = pd.cut(df[col], 5)\n    df = pd.concat([df, pd.get_dummies(df['Categorical'])],axis=1)\n    del df['Categorical']","aebf5da5":"df['N1'] = [1 if x>30 else 0 for x in df['Age']]\ndf['N2'] = [1 if x>125 else 0 for x in df['Glucose']]\ndf['N3'] = [1 if x>80 else 0 for x in df['BloodPressure']]\ndf['N4'] = [1 if x>20 else 0 for x in df['SkinThickness']]\ndf['N5'] = [1 if x>30 else 0 for x in df['BMI']]\n\ndf['N1&N2'] = df['N1'] + df['N2']\ndf['N2&N3'] = df['N2'] + df['N3']\ndf['N4&N5'] = df['N4'] + df['N5']","99b2fb94":"df.head()","93cdc50c":"df.corr().style.background_gradient(cmap = 'Oranges')","95a10ab2":"plt.figure(figsize=(12,6))\ndf.corr()['Outcome'].sort_values().plot(kind='bar');","bfcfe79e":"x = df.corr()\npd.DataFrame(x['Outcome']).sort_values(by='Outcome',ascending = False).style.background_gradient(cmap = 'Greens')","ffe7a743":"class Classifier:\n    Models = {\n        'SVC': SVC(),\n        'LGBMClassifier': LGBMClassifier(),\n        'GaussianNB': GaussianNB(),\n        'SGD': SGDClassifier(),\n        'DecisionTree': DecisionTreeClassifier(),\n        'AdaBoostClassifier': AdaBoostClassifier(),\n        'RidgeClassifier': RidgeClassifier(),\n        'KNeighborsClassifier': KNeighborsClassifier(),\n        'LogisticRegression': LogisticRegression(),\n        'RandomForestClassifier': RandomForestClassifier(),\n        'GradientBoostingClassifier': GradientBoostingClassifier(),\n        'PassiveAggressiveClassifier': PassiveAggressiveClassifier(),\n        'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n        'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n        'CatBoostClassifier': CatBoostClassifier(verbose= False, eval_metric = 'AUC'),\n        'XGBClassifier': XGBClassifier(objective= 'binary:logistic', eval_metric='auc'),\n        'ExtraTreesClassifier': ExtraTreesClassifier()\n    }\n    scaler = StandardScaler()\n    scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n    model_results = {\n        'Model': [], 'Fitting time': [], 'Scoring time':[], 'Accuracy':[], 'Precision':[], 'Recall':[], 'F1_Score':[], 'AUC':[]\n    }\n    \n    def __init__(self, data, target):\n        self.df = data\n        self.cols = list(data.columns)\n        self.cols.remove(target)\n        self.scaler.fit(self.df[self.cols])\n        self.target = target\n    \n    def cross_validation(self, model, folds):\n        X = self.scaler.transform(self.df[self.cols])\n        scores = cross_validate(model, X, self.df[self.target], scoring=self.scoring, cv=folds, verbose=False)\n        sorted(scores.keys())\n        return scores['fit_time'].mean(), scores['score_time'].mean(), scores['test_accuracy'].mean(), scores['test_precision_macro'].mean(), scores['test_recall_macro'].mean(),scores['test_f1_weighted'].mean(),scores['test_roc_auc'].mean()\n    \n    def score_models(self, folds = 10):\n        for model_name in self.Models.keys():\n            fit_time, score_time, accuracy, precision, recall, f1_score, auc = self.cross_validation(self.Models[model_name], folds)\n            self.model_results['Model'].append(model_name)\n            self.model_results['Fitting time'].append(fit_time)\n            self.model_results['Scoring time'].append(score_time)\n            self.model_results['Accuracy'].append(accuracy)\n            self.model_results['Precision'].append(precision)\n            self.model_results['Recall'].append(recall)\n            self.model_results['F1_Score'].append(f1_score)\n            self.model_results['AUC'].append(auc)\n        \n        return pd.DataFrame(self.model_results)","37738e45":"pipeline = Classifier(df, 'Outcome')\nresults = pipeline.score_models()","5598722a":"results.sort_values(by='AUC', ascending=False)","d0623250":"plt.figure(figsize=(15,5))\n\nfor col in list(results.columns):\n    if col=='AUC' or col=='Accuracy':\n        plt.plot(results['Model'], results[col], '-o', label = col)\n\nplt.title('Mean Score with different params')\nplt.xticks(rotation=90)\nplt.grid(True)\nplt.legend()\nplt.show()","8d78bb0e":"cols = list(df.columns)\ncols.remove('Outcome')","dfc12d1e":"X_train, X_test, y_train, y_test = train_test_split(df[cols], df['Outcome'], test_size=0.1, stratify=df['Outcome'], random_state=123)","4a181f5e":"smote = SMOTE(random_state = 123)\nX_train, y_train = smote.fit_resample(X_train, y_train)","ab22994a":"pipeline = Pipeline(steps = [['scaler', MinMaxScaler()],\n                             ['classifier', LogisticRegression(random_state=11, max_iter=1000)]])\n\nstratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=11)\n\nparam_grid = {'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\ngrid_search = GridSearchCV(estimator=pipeline,\n                           param_grid=param_grid,\n                           scoring='roc_auc',\n                           cv=stratified_kfold,\n                           n_jobs=-1)\n\ngrid_search.fit(X_train, y_train)\ncv_score = grid_search.best_score_\ntest_score = grid_search.score(X_test, y_test)\nprint(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')","aae5d096":"y_prob = grid_search.predict_proba(X_test)[:,1]\ny_pred = grid_search.predict(X_test)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nprecision, recall, th = precision_recall_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nroc_auc","d86a2e4f":"plt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],linestyle='--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","c40e3da3":"plt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(recall, precision, color='red', label = 'LogisticRegression')\nplt.legend(loc = 'lower right')\nplt.plot([1, 0], [0, 1],linestyle='--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","774e92e7":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","e9f56308":"plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes=['Negative', 'Positive'], title='Confusion matrix')","77d35230":"## Checking missing values","c13dbed6":"## Contents of Data\n**Pregnancies:**                   Number of times pregnant\n\n**Glucose:**                       Plasma Glucose Concentration (mg\/dl)\n\n**Blood Pressure:**                Diastolic Blood Pressure(mmHg)\n\n**Skin Thickness:**                A value used to estimate body fat.\n\n**Insulin:**                       2-Hour Serum Insulin (mu U\/ml)\n\n**BMI:**                           Body Mass Index (weight in kg\/ height in m2)\n\n**Diabetes Pedigree Function:**    It provides information about diabetes history in relatives and genetics.\n\n**Age:**                           Age (years)\n\n**Outcome:**                       0 = Diabetic, 1 = Not Diabetic","e2e793c7":"## Distribution of other features (w.r.t Outcome)","5a1ba498":"## Blood Pressure Distribution (w.r.t Outcome)","0bd2eb89":"## Oversampling using SMOTE","278c03cd":"No duplicates present","546dc973":"Grouping \/ Categorising Linear Columns","e1cd468e":"## Thank you very much for your attention. Kindly upvote if you like my work.\ud83d\ude0a","2ad5de00":"I will use Linear Regression for further predictions as it showed promising results.","ef3d2dc3":"# Data Analysis","73124bb9":"## Importing Libraries","345c6dad":"## Checking duplicate values","d797df29":"# <span style = \"color:orange;\">Diabetes Prediction:<\/span>\n![](https:\/\/res.cloudinary.com\/grohealth\/image\/upload\/c_fill,f_auto,fl_lossy,h_650,q_auto,w_1085\/v1581695681\/DCUK\/Content\/causes-of-diabetes.png)","c99574f7":"## Feature Correlations","b6b1138f":"## Feature \n\nBased on this [Notebook](https:\/\/www.kaggle.com\/vincentlugat\/pima-indians-diabetes-eda-prediction-0-906) by - Vincent Lugat","c8bf07bc":"## GridSearch Pipeline","b75dd8ed":"Features Based on above analysis","11f675ec":"## Results","3c718d13":"## Age dependence on Diabetes","c2f1071a":"## First look at the Data","fe2e896a":"## Results","616b7de0":"Data contains contains some big values so normalization can be done.","94250681":"## Classification Pipeline","85258a53":"Data does not have any nan values.","c0579b2d":"## Creating extra features"}}