{"cell_type":{"8cb121c9":"code","50da17da":"code","c1c69ad8":"code","7433fdf1":"code","a36f9a0e":"code","0503d039":"code","a149fb4c":"code","e062f282":"code","8c66ca35":"code","7be02a42":"code","6a23116e":"code","7447543a":"code","e4a67b04":"code","f4edf8f7":"code","e81b9494":"code","0613b6f9":"code","6db521d9":"code","2582e1f7":"code","5898357a":"code","35e2b98e":"code","22f476cd":"code","52c672c9":"code","8da7b062":"code","e188745c":"code","54adf42a":"code","17dbff65":"code","0affcbf1":"code","cae68cc3":"markdown","771c97ed":"markdown","9b17c5ec":"markdown","7062a929":"markdown","c171ff16":"markdown","d91859ea":"markdown","c9356996":"markdown","861cbbe9":"markdown","4f8db63c":"markdown","3d6399df":"markdown","8d60ace6":"markdown","9940f98a":"markdown","54f0718e":"markdown","dc0fb6a5":"markdown","bce91c4e":"markdown","277b58c8":"markdown","7db6342c":"markdown","b814f589":"markdown","32c69434":"markdown","f63b570d":"markdown"},"source":{"8cb121c9":"%reset -sf","50da17da":"%%writefile simple_toward.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\n\n\ndef agent(obs_dict, config_dict):\n    \"\"\"This agent always moves toward observation.food[0] but does not take advantage of board wrapping\"\"\"\n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n    food = observation.food[0]\n    food_row, food_column = row_col(food, configuration.columns)\n\n    if food_row > player_row:\n        return Action.SOUTH.name\n    if food_row < player_row:\n        return Action.NORTH.name\n    if food_column > player_column:\n        return Action.EAST.name\n    return Action.WEST.name","c1c69ad8":"%%writefile greedy.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\nfrom random import choice, sample\n\ndef random_agent():\n    return choice([action for action in Action]).name\n\n\ndef translate(position: int, direction: Action, columns: int, rows: int):\n    row, column = row_col(position, columns)\n    row_offset, column_offset = direction.to_row_col()\n    row = (row + row_offset) % rows\n    column = (column + column_offset) % columns\n    return row * columns + column\n\n\ndef adjacent_positions(position: int, columns: int, rows: int):\n    return [\n        translate(position, action, columns, rows)\n        for action in Action\n    ]\n\n\ndef min_distance(position: int, food: [int], columns: int):\n    row, column = row_col(position, columns)\n    return min(\n        abs(row - food_row) + abs(column - food_column)\n        for food_position in food\n        for food_row, food_column in [row_col(food_position, columns)]\n    )\n\n\ndef agent(observation, configuration):\n    observation = Observation(observation)\n    configuration = Configuration(configuration)\n    rows, columns = configuration.rows, configuration.columns\n\n    food = observation.food\n    geese = observation.geese\n    opponents = [\n        goose\n        for index, goose in enumerate(geese)\n        if index != observation.index and len(goose) > 0\n    ]\n\n    # Don't move adjacent to any heads\n    head_adjacent_positions = {\n        opponent_head_adjacent\n        for opponent in opponents\n        for opponent_head in [opponent[0]]\n        for opponent_head_adjacent in adjacent_positions(opponent_head, rows, columns)\n    }\n    # Don't move into any bodies\n    bodies = {position for goose in geese for position in goose[0:-1]}\n    # Don't move into tails of heads that are adjacent to food\n    tails = {\n        opponent[-1]\n        for opponent in opponents\n        for opponent_head in [opponent[0]]\n        if any(\n            adjacent_position in food\n            # Head of opponent is adjacent to food so tail is not safe\n            for adjacent_position in adjacent_positions(opponent_head, rows, columns)\n        )\n    }\n\n    # Move to the closest food\n    position = geese[observation.index][0]\n    actions = {\n        action: min_distance(new_position, food, columns)\n        for action in Action\n        for new_position in [translate(position, action, columns, rows)]\n        if (\n            new_position not in head_adjacent_positions and\n            new_position not in bodies and\n            new_position not in tails\n        )\n    }\n\n    if any(actions):\n        return min(actions, key=actions.get).name\n\n    return random_agent()","7433fdf1":"%%writefile risk_averse_greedy.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\nimport numpy as np\nimport random\n\ndef get_nearest_cells(x,y):\n    # returns all cells reachable from the current one\n    result = []\n    for i in (-1,+1):\n        result.append(((x+i+7)%7, y))\n        result.append((x, (y+i+11)%11))\n    return result\n\ndef find_closest_food(table):\n    # returns the first step toward the closest food item\n    new_table = table.copy()\n    \n    \n    # (direction of the step, axis, code)\n    possible_moves = [\n        (1, 0, 1),\n        (-1, 0, 2),\n        (1, 1, 3),\n        (-1, 1, 4)\n    ]\n    \n    # shuffle possible options to add variability\n    random.shuffle(possible_moves)\n    \n    \n    updated = False\n    for roll, axis, code in possible_moves:\n\n        shifted_table = np.roll(table, roll, axis)\n        \n        if (table == -2).any() and (shifted_table[table == -2] == -3).any(): # we have found some food at the first step\n            return code\n        else:\n            mask = np.logical_and(new_table == 0,shifted_table == -3)\n            if mask.sum() > 0:\n                updated = True\n            new_table += code * mask\n        if (table == -2).any() and shifted_table[table == -2][0] > 0: # we have found some food\n            return shifted_table[table == -2][0]\n        \n        # else - update new reachible cells\n        mask = np.logical_and(new_table == 0,shifted_table > 0)\n        if mask.sum() > 0:\n            updated = True\n        new_table += shifted_table * mask\n\n    # if we updated anything - continue reccurison\n    if updated:\n        return find_closest_food(new_table)\n    # if not - return some step\n    else:\n        return table.max()\n\nlast_step = None\n\ndef agent(obs_dict, config_dict):\n    global last_step\n    \n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n\n\n    table = np.zeros((7,11))\n    # 0 - emply cells\n    # -1 - obstacles\n    # -4 - possible obstacles\n    # -2 - food\n    # -3 - head\n    # 1,2,3,4 - reachable on the current step cell, number is the id of the first step direction\n    \n    legend = {\n        1: 'SOUTH',\n        2: 'NORTH',\n        3: 'EAST',\n        4: 'WEST'\n    }\n    \n    # let's add food to the map\n    for food in observation.food:\n        x,y = row_col(food, configuration.columns)\n        table[x,y] = -2 # food\n        \n    # let's add all cells that are forbidden\n    for i in range(4):\n        opp_goose = observation.geese[i]\n        if len(opp_goose) == 0:\n            continue\n            \n        is_close_to_food = False\n            \n        if i != player_index:\n            x,y = row_col(opp_goose[0], configuration.columns)\n            possible_moves = get_nearest_cells(x,y) # head can move anywhere\n            \n            for x,y in possible_moves:\n                if table[x,y] == -2:\n                    is_close_to_food = True\n            \n                table[x,y] = -4 # possibly forbidden cells\n        \n        # usually we ignore the last tail cell but there are exceptions\n        tail_change = -1\n        if obs_dict['step'] % 40 == 39:\n            tail_change -= 1\n        \n        # we assume that the goose will eat the food\n        if is_close_to_food:\n            tail_change += 1\n        if tail_change >= 0:\n            tail_change = None\n            \n\n        for n in opp_goose[:tail_change]:\n            x,y = row_col(n, configuration.columns)\n            table[x,y] = -1 # forbidden cells\n    \n    # going back is forbidden according to the new rules\n    x,y = row_col(player_head, configuration.columns)\n    if last_step is not None:\n        if last_step == 1:\n            table[(x + 6) % 7,y] = -1\n        elif last_step == 2:\n            table[(x + 8) % 7,y] = -1\n        elif last_step == 3:\n            table[x,(y + 10)%11] = -1\n        elif last_step == 4:\n            table[x,(y + 12)%11] = -1\n        \n    # add head position\n    table[x,y] = -3\n    \n    # the first step toward the nearest food\n    step = int(find_closest_food(table))\n    \n    # if there is not available steps try to go to possibly dangerous cell\n    if step not in [1,2,3,4]:\n        x,y = row_col(player_head, configuration.columns)\n        if table[(x + 8) % 7,y] == -4:\n            step = 1\n        elif table[(x + 6) % 7,y] == -4:\n            step = 2\n        elif table[x,(y + 12)%11] == -4:\n            step = 3\n        elif table[x,(y + 10)%11] == -4:\n            step = 4\n                \n    # else - do a random step and lose\n        else:\n            step = np.random.randint(4) + 1\n    \n    last_step = step\n    return legend[step]","a36f9a0e":"%%writefile simple_bfs.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\nimport random\nimport numpy as np\n\ndirections = {0:'EAST', 1:'NORTH', 2:'WEST', 3:'SOUTH', 'EAST':0, 'NORTH':1, 'WEST':2, 'SOUTH':3}\n\n\ndef move(loc, direction):\n    \"\"\"Move the whole snake in the given direction\"\"\"\n    global directions\n    direction = directions[direction]\n    new_loc = []\n    if direction == 'EAST':\n        new_loc.append(int(11*(loc[0]\/\/11)  + (loc[0]%11 + 1)%11))\n    elif direction == 'WEST':\n        new_loc.append(int(11*(loc[0]\/\/11) + (loc[0]%11 + 10)%11))\n    elif direction == 'NORTH':\n        new_loc.append(int(11*((loc[0]\/\/11 + 6)%7) + loc[0]%11))\n    else:\n        new_loc.append(int(11*((loc[0]\/\/11 + 1)%7) + loc[0]%11))\n    if len(loc) == 1:\n        return new_loc\n    return new_loc + loc[:-1]\n    \n\ndef greedy_choose(head, board):\n    move_queue = []\n    visited = [[[100, 'NA'] for _ in range(11)] for l in range(7)]\n    visited[head\/\/11][head%11][0] = 0\n    \n    for i in range(4):\n        move_queue.append([head, [i]])\n    \n    while len(move_queue) > 0:\n        now_move = move_queue.pop(0)\n        \n        next_step = move([now_move[0]], now_move[1][-1])[0]\n        \n        if board[next_step\/\/11][next_step%11] < 0:\n            continue\n        \n        if len(now_move[1]) < visited[next_step\/\/11][next_step%11][0]:\n            visited[next_step\/\/11][next_step%11][0] = len(now_move[1])\n            visited[next_step\/\/11][next_step%11][1] = now_move[1][0]\n            for i in range(4):\n                move_queue.append([next_step, now_move[1] + [i]])\n        \n        if board[next_step\/\/11][next_step%11] > 0:\n            return now_move[1][0]\n    return random.randint(0,3)\n    \n    \n    \ndef agent(obs, conf):\n    global directions\n\n    obs = Observation(obs)\n    conf = Configuration(conf)\n    board = np.zeros((7, 11), dtype=int)\n    \n    #Obstacle-ize your opponents\n    for ind, goose in enumerate(obs.geese):\n        if ind == obs.index or len(goose) == 0:\n            continue\n        for direction in range(4):\n            moved = move(goose, direction)\n            for part in moved:\n                board[part\/\/11][part%11] -= 1\n    \n    #Obstacle-ize your body, except the last part\n    if len(obs.geese[obs.index]) > 1:\n        for k in obs.geese[obs.index][:-1]:\n            board[k\/\/11][k%11] -= 1\n            \n    #Count food only if there's no chance an opponent will meet you there\n    for f in obs.food: \n        board[f\/\/11][f%11] += (board[f\/\/11][f%11] == 0)\n        \n    return directions[greedy_choose(obs.geese[obs.index][0], board)]\n","0503d039":"%%writefile straightforward_bfs.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\nimport numpy as np\n\n\n\ndef bfs(start_x, start_y, mask, food_coords):\n    dist_matrix = np.zeros_like(mask)\n    vect_matrix = np.full_like(mask, -1)\n    \n    queue = [(start_x, start_y, 0, None)]\n    \n    while queue:\n        current_x, current_y, current_dist, vect = queue.pop(0)\n        vect_matrix[current_x, current_y] = vect\n        up_x = current_x + 1 if current_x != 6 else 0\n        down_x = current_x - 1 if current_x != 0 else 6\n        left_y = current_y - 1 if current_y != 0 else 10\n        right_y = current_y + 1 if current_y != 10 else 0\n        \n        if mask[up_x, current_y] != -1 and not dist_matrix[up_x, current_y]:\n            dist_matrix[up_x, current_y] = current_dist + 1\n            if vect is None:\n                queue.append((up_x, current_y, current_dist + 1, 0))\n            else:\n                queue.append((up_x, current_y, current_dist + 1, vect))\n        if mask[down_x, current_y] != -1 and not dist_matrix[down_x, current_y]:\n            dist_matrix[down_x, current_y] = current_dist + 1\n            if vect is None:\n                queue.append((down_x, current_y, current_dist + 1, 1))\n            else:\n                queue.append((down_x, current_y, current_dist + 1, vect))\n        if mask[current_x, left_y] != -1 and not dist_matrix[current_x, left_y]:\n            dist_matrix[current_x, left_y] = current_dist + 1\n            if vect is None:\n                queue.append((current_x, left_y, current_dist + 1, 2))\n            else:\n                queue.append((current_x, left_y, current_dist + 1, vect))\n        if mask[current_x, right_y] != -1 and not dist_matrix[current_x, right_y]:\n            dist_matrix[current_x, right_y] = current_dist + 1\n            if vect is None:\n                queue.append((current_x, right_y, current_dist + 1, 3))\n            else:\n                queue.append((current_x, right_y, current_dist + 1, vect))\n            \n    min_food_id = -1\n    min_food_dist = np.inf\n    for id_, food in enumerate(food_coords):\n        if dist_matrix[food[0], food[1]] != 0 and min_food_dist > dist_matrix[food[0], food[1]]:\n            min_food_id = id_\n            min_food_dist = dist_matrix[food[0], food[1]]\n    \n    if min_food_id == -1:\n        x, y = -1, -1\n        mn = 0 \n        for i in range(dist_matrix.shape[0]):\n            for j in range(dist_matrix.shape[1]):\n                if dist_matrix[i, j] > mn:\n                    x, y = i, j\n                    mn = dist_matrix[i, j]\n        return vect_matrix[x, y]\n    \n    food_x, food_y = food_coords[min_food_id]\n    return vect_matrix[food_x, food_y]\n\n\nLAST_ACTION = None\n\n\ndef straightforward_bfs(obs_dict, config_dict):\n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    player_index = observation.index\n    \n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    start_row, start_col = row_col(player_head, configuration.columns)\n\n    mask = np.zeros((configuration.rows, configuration.columns))\n    for current_id in range(4):\n        current_goose = observation.geese[current_id]\n        for block in current_goose:\n            current_row, current_col = row_col(block, configuration.columns)\n            mask[current_row, current_col] = -1\n    \n    food_coords = []\n    \n    for food_id in range(configuration.min_food):\n        food = observation.food[food_id]\n        current_row, current_col = row_col(food, configuration.columns)\n        mask[current_row, current_col] = 2\n        food_coords.append((current_row, current_col))\n        \n\n    last_action = bfs(start_row, start_col, mask, food_coords)\n    \n    global LAST_ACTION\n    up_x = start_row + 1 if start_row != 6 else 0\n    down_x = start_row - 1 if start_row != 0 else 6\n    left_y = start_col - 1 if start_col != 0 else 10\n    right_y = start_col + 1 if start_col != 10 else 0\n    \n    step = Action.NORTH.name\n    if last_action == 0:\n        step = Action.SOUTH.name\n        if LAST_ACTION == Action.NORTH.name:\n            if mask[down_x, start_col] != -1:\n                step = Action.NORTH.name\n            elif mask[start_row, left_y] != -1:\n                step = Action.WEST.name\n            elif mask[start_row, right_y] != -1:\n                step = Action.EAST.name\n    if last_action == 1:\n        step = Action.NORTH.name\n        if LAST_ACTION == Action.SOUTH.name:\n            if mask[up_x, start_col] != -1:\n                step = Action.SOUTH.name\n            elif mask[start_row, left_y] != -1:\n                step = Action.WEST.name\n            elif mask[start_row, right_y] != -1:\n                step = Action.EAST.name\n    if last_action == 2:\n        step = Action.WEST.name\n        if LAST_ACTION == Action.EAST.name:\n            if mask[up_x, start_col] != -1:\n                step = Action.SOUTH.name\n            elif mask[down_x, start_col] != -1:\n                step = Action.NORTH.name\n            elif mask[start_row, right_y] != -1:\n                step = Action.EAST.name\n    if last_action == 3:\n        step = Action.EAST.name\n        if LAST_ACTION == Action.WEST.name:\n            if mask[up_x, start_col] != -1:\n                step = Action.SOUTH.name\n            elif mask[down_x, start_col] != -1:\n                step = Action.NORTH.name\n            elif mask[start_row, left_y] != -1:\n                step = Action.WEST.name\n    LAST_ACTION = step\n    \n    return step","a149fb4c":"%%writefile boilergoose.py\n\n\nimport dataclasses\nfrom dataclasses import dataclass\nfrom typing import List, NamedTuple, Set, Dict, Optional, Tuple, Callable\nimport numpy as np\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Action\nfrom abc import ABC, abstractmethod\nimport sys\nimport traceback\n\n\ntrans_action_map: Dict[Tuple[int, int], Action] = {\n    (-1, 0): Action.NORTH,\n    (1, 0): Action.SOUTH,\n    (0, 1): Action.EAST,\n    (0, -1): Action.WEST,\n}\n\n\nclass Pos(NamedTuple):\n    x: int\n    y: int\n\n    def __repr__(self):\n        return f\"[{self.x}:{self.y}]\"\n\n\n@dataclass\nclass Goose:\n    head: Pos = dataclasses.field(init=False)\n    poses: List[Pos]\n\n    def __post_init__(self):\n        self.head = self.poses[0]\n\n    def __repr__(self):\n        return \"Goose(\" + \"-\".join(map(str, self.poses)) + \")\"\n\n    def __iter__(self):\n        return iter(self.poses)\n\n    def __len__(self):\n        return len(self.poses)\n\n\ndef field_idx_to_pos(field_idx: int, *, num_cols: int, num_rows: int) -> Pos:\n    x = field_idx \/\/ num_cols\n    y = field_idx % num_cols\n\n    if not (0 <= x < num_rows and 0 <= y < num_cols):\n        raise ValueError(\"Illegal field_idx {field_idx} with x={x} and y={y}\")\n\n    return Pos(x, y)\n\n\nclass Geometry:\n    def __init__(self, size_x, size_y):\n        self.size_x = size_x\n        self.size_y = size_y\n\n    @property\n    def shape(self) -> Tuple[int, int]:\n        return (self.size_x, self.size_y)\n\n    def prox(self, pos: Pos) -> Set[Pos]:\n        return {\n            self.translate(pos, direction)\n            for direction in [(0, 1), (1, 0), (0, -1), (-1, 0)]\n        }\n\n    def translate(self, pos: Pos, diff: Tuple[int, int]) -> Pos:\n        x, y = pos\n        dx, dy = diff\n        return Pos((x + dx) % self.size_x, (y + dy) % self.size_y)\n\n    def trans_to(self, pos1: Pos, pos2: Pos) -> Tuple[int, int]:\n        dx = pos2.x - pos1.x\n        dy = pos2.y - pos1.y\n\n        if dx <= self.size_x \/\/ 2:\n            dx += self.size_x\n\n        if dx > self.size_x \/\/ 2:\n            dx -= self.size_x\n\n        if dy <= self.size_y \/\/ 2:\n            dy += self.size_y\n\n        if dy > self.size_y \/\/ 2:\n            dy -= self.size_y\n\n        return (dx, dy)\n\n    def action_to(self, pos1, pos2):\n        diff = self.trans_to(pos1, pos2)\n\n        result = trans_action_map.get(diff)\n\n        if result is None:\n            raise ValueError(f\"Cannot step from {pos1} to {pos2}\")\n\n        return result\n\n@dataclass\nclass State:\n    food: Set[Pos]\n    geese: Dict[int, Goose]\n    index: int\n    step: int\n    geo: Geometry\n\n    field: np.ndarray = dataclasses.field(init=False)\n    my_goose: Goose = dataclasses.field(init=False)\n    danger_poses: Set[Pos] = dataclasses.field(init=False)\n\n    def __post_init__(self):\n        self.field = np.full(fill_value=0, shape=self.geo.shape)\n        for goose in self.geese.values():\n            for pos in goose.poses[:-1]:  # not considering tail!\n                self.field[pos.x, pos.y] = 1\n                \n            if self.geo.prox(goose.head) & self.food:\n                tail = goose.poses[-1]\n                self.field[tail.x, tail.y] = 1\n                \n\n        self.my_goose = self.geese[self.index]\n\n        self.danger_poses = {\n            pos\n            for i, goose in self.geese.items()\n            if i != self.index\n            for pos in self.geo.prox(goose.head)\n        }\n\n    @classmethod\n    def from_obs_conf(cls, obs, conf):\n        num_cols = conf[\"columns\"]\n        num_rows = conf[\"rows\"]\n        step = obs[\"step\"]\n        index = obs[\"index\"]\n\n        geese = {\n            idx: Goose(\n                poses=[\n                    field_idx_to_pos(idx, num_cols=num_cols, num_rows=num_rows)\n                    for idx in goose_data\n                ]\n            )\n            for idx, goose_data in enumerate(obs[\"geese\"])\n            if goose_data\n        }\n\n        food = {\n            field_idx_to_pos(idx, num_cols=num_cols, num_rows=num_rows)\n            for idx in obs[\"food\"]\n        }\n\n        return cls(\n            food=food,\n            geese=geese,\n            index=index,\n            step=step,\n            geo=Geometry(size_x=num_rows, size_y=num_cols),\n        )\n\n    def __repr__(self):\n        return (\n            f\"State(step:{self.step}, index:{self.index}, Geese(\"\n            + \",\".join(f\"{idx}:{len(goose.poses)}\" for idx, goose in self.geese.items())\n            + f\"), food:{len(self.food)})\"\n        )\n\n@dataclass\nclass FloodfillResult:\n    field_dist: np.ndarray\n    frontiers: List[List[Tuple[int, int]]]\n\n\ndef flood_fill(is_occupied: np.ndarray, seeds: List[Pos]) -> FloodfillResult:\n    \"\"\"\n    Flood will start with distance 0 at seeds and only flow where is_occupied[x,y]==0\n    \"\"\"\n    size_x, size_y = is_occupied.shape\n\n    field_dist = np.full(fill_value=-1, shape=(size_x, size_y))\n\n    frontier = [(s.x, s.y) for s in seeds]\n\n    frontiers = [frontier]\n\n    for seed in seeds:\n        field_dist[seed] = 0\n\n    dist = 1\n\n    while frontier:\n        new_frontier: List[Tuple[int, int]] = []\n        for x, y in frontier:\n            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                new_x = (x + dx) % size_x\n                new_y = (y + dy) % size_y\n                if is_occupied[new_x, new_y] == 0 and field_dist[new_x, new_y] == -1:\n                    field_dist[new_x, new_y] = dist\n                    new_frontier.append((new_x, new_y))\n        frontier = new_frontier\n        frontiers.append(frontier)\n        dist += 1\n\n    return FloodfillResult(field_dist=field_dist, frontiers=frontiers)\n\n\ndef get_dist(\n    floodfill_result: FloodfillResult, test_func: Callable[[Tuple[int, int]], bool]\n) -> Optional[int]:\n    for dist, frontier in enumerate(floodfill_result.frontiers):\n        for pos in frontier:\n            if test_func(pos):\n                return dist\n\n    return None\n\nclass BaseAgent(ABC):\n    def __init__(self):\n        self.last_pos: Optional[Pos] = None\n\n    def __call__(self, obs, conf):\n        try:\n            state = State.from_obs_conf(obs, conf)\n\n            next_pos = self.step(state)\n\n            action = state.geo.action_to(state.my_goose.head, next_pos)\n\n            self.last_pos = state.my_goose.head\n\n            return action.name\n        except Exception as exc:\n            traceback.print_exc(file=sys.stderr)\n            raise\n\n    @abstractmethod\n    def step(self, state: State) -> Pos:\n        \"\"\"\n        return: next position\n\n        Implement this\n        \"\"\"\n        pass\n\n    def next_poses(self, state: State) -> Set[Pos]:\n        head_next_poses = state.geo.prox(state.my_goose.head)\n\n        result = {\n            pos\n            for pos in head_next_poses\n            if pos != self.last_pos and state.field[pos] == 0\n        }\n\n        return result\n\nfrom operator import itemgetter\nimport random\n\nclass FloodGoose(BaseAgent):\n    def __init__(self, min_length=13):\n        super().__init__()\n        self.min_length = min_length\n        \n    def step(self, state):\n        result = None\n        \n        if len(state.my_goose) < self.min_length:\n            result = self.goto(state, lambda pos:pos in state.food)\n        elif len(state.my_goose) >= 3:\n            result = self.goto(state, lambda pos:pos==state.my_goose.poses[-1])\n            \n        if result is None:\n            result = self.random_step(state)\n            \n        return result\n    \n    def goto(self, state, test_func):\n        result = None\n        \n        pos_dists = {}\n        for pos in self.next_poses(state):\n            flood = flood_fill(state.field, [pos])\n            dist = get_dist(flood, test_func)\n            if dist is not None:\n                pos_dists[pos] = dist\n\n        if pos_dists:\n            closest_pos, _ = min(pos_dists.items(), key=itemgetter(1))\n\n            if closest_pos not in state.danger_poses:\n                result = closest_pos\n                \n        return result\n        \n    \n    def random_step(self, state):\n        next_poses = self.next_poses(state) - state.danger_poses - state.food\n        if not next_poses:\n            next_poses = self.next_poses(state) - state.danger_poses\n\n            if not next_poses:\n                next_poses = self.next_poses(state)\n\n                if not next_poses:\n                    next_poses = state.geo.prox(state.my_goose.head)\n                        \n        result = random.choice(list(next_poses))\n        \n        return result\n    \n\nagent = FloodGoose(min_length=8)\n\ndef call_agent(obs, conf):\n    return agent(obs, conf)","e062f282":"%%writefile crazy_goose.py\n\n# Base code for this from\n# https:\/\/www.kaggle.com\/ilialar\/risk-averse-greedy-goose\n\nimport numpy as np\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\n\n# Moves constants\nSOUTH = 1\nNORTH = 2\nEAST  = 3\nWEST  = 4\nREVERSE_MOVE = {\n    None : None,\n    SOUTH: NORTH,\n    NORTH: SOUTH,\n    EAST : WEST,\n    WEST : EAST,\n}\nCIRCLE_MOVE = {\n    None : None,\n    SOUTH: WEST,\n    NORTH: EAST,\n    EAST : SOUTH,\n    WEST : NORTH\n}\n\n# Board constants\nMY_HEAD             =  2\nFOOD_CELL           =  1\nEMPTY               =  0\nHEAD_POSSIBLE_CELL  = -1\nBODY_CELL           = -2\n\n# Store last move\nlast_move = None\nlast_eaten = 0\nlast_size = 1\nstep = 0\n\n# Returns a list of possible destinations in order to reach `dest_cell`\ndef move_towards (head_cell, neck_cell, dest_cell, configuration):\n    print (\"--- Computing food movements...\")\n    destinations = []\n    x_head, y_head = row_col(head_cell, configuration.columns)\n    x_neck, y_neck = row_col(neck_cell, configuration.columns)\n    x_dest, y_dest = row_col(dest_cell, configuration.columns)\n    print (\"-> Head at ({}, {})\".format(x_head, y_head))\n    print (\"-> Neck at ({}, {})\".format(x_neck, y_neck))\n    print (\"-> Dest at ({}, {})\".format(x_dest, y_dest))\n    dx = x_head - x_dest\n    dy = y_head - y_dest\n    if (dx >= 4):\n        dx = 7 - dx\n    elif (dx <= -4):\n        dx += 7\n    if (dy >= 6):\n        dy = 11 - dy\n    elif (dy <= -6):\n        dy += 11\n    print (\"dx={}, dy={}\".format(dx, dy))\n    if (dx > 0):\n        x_move = (x_head - 1 + 7) % 7\n        y_move = y_head\n        print (\"Move ({}, {}), Neck ({}, {})\".format(x_move, y_move, x_neck, y_neck))\n        if not ((x_move == x_neck) and (y_move == y_neck)):\n            destinations.append((x_move, y_move, NORTH))\n    elif (dx < 0):\n        x_move = (x_head + 1 + 7) % 7\n        y_move = y_head\n        print (\"Move ({}, {}), Neck ({}, {})\".format(x_move, y_move, x_neck, y_neck))\n        if not ((x_move == x_neck) and (y_move == y_neck)):\n            destinations.append((x_move, y_move, SOUTH))\n    if (dy > 0):\n        x_move = x_head\n        y_move = (y_head - 1 + 11) % 11\n        print (\"Move ({}, {}), Neck ({}, {})\".format(x_move, y_move, x_neck, y_neck))\n        if not ((x_move == x_neck) and (y_move == y_neck)):\n            destinations.append((x_move, y_move, WEST))\n    elif (dy < 0):\n        x_move = x_head\n        y_move = (y_head + 1 + 11) % 11\n        print (\"Move ({}, {}), Neck ({}, {})\".format(x_move, y_move, x_neck, y_neck))\n        if not ((x_move == x_neck) and (y_move == y_neck)):\n            destinations.append((x_move, y_move, EAST))\n    return destinations\n\ndef get_all_movements(goose_head, configuration):\n    x_head, y_head = row_col(goose_head, configuration.columns)\n    movements = []\n    movements.append(((x_head - 1 + 7) % 7, y_head, NORTH))\n    movements.append(((x_head + 1 + 7) % 7, y_head, SOUTH))\n    movements.append((x_head, (y_head - 1 + 11) % 11, WEST))\n    movements.append((x_head, (y_head + 1 + 11) % 11, EAST))\n    return movements\n    \ndef get_nearest_cells(x, y):\n    # Returns adjacent cells from the current one\n    result = []\n    for i in (-1,+1):\n        result.append(((x+i+7)%7, y))\n        result.append((x, (y+i+11)%11))\n    return result\n\n# Compute L1 distance between cells\ndef cell_distance (a, b, configuration):\n    xa, ya = row_col(a, configuration.columns)\n    xb, yb = row_col(b, configuration.columns)\n    dx = abs(xa - xb)\n    dy = abs(ya - yb)\n    if (dx >= 4):\n        dx = 7 - dx\n    if (dy >= 6):\n        dy = 11 - dy\n    return dx + dy\n\n# Tells if that particular cell forbids movement on the next step\ndef is_closed (movement, board):\n    return all([board[x_adj, y_adj] for (x_adj, y_adj) in get_nearest_cells(movement[0], movement[1])])\n\ndef is_safe (movement, board):\n    return board[movement[0], movement[1]] >= 0\n\ndef is_half_safe (movement, board):\n    return board[movement[0], movement[1]] >= -1\n\ndef agent (obs_dict, config_dict):\n    global last_move\n    global last_eaten\n    global last_size\n    global step\n    print (\"==============================================\")\n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n\n    if (len(player_goose) > last_size):\n        last_size = len(player_goose)\n        last_eaten = step\n    step += 1\n    \n    moves = {\n        1: 'SOUTH',\n        2: 'NORTH',\n        3: 'EAST',\n        4: 'WEST'\n    }\n\n    board = np.zeros((7, 11))\n    \n    # Adding food to board\n    for food in observation.food:\n        x, y = row_col(food, configuration.columns)\n        print (\"Food cell on ({}, {})\".format(x, y))\n        board[x, y] = FOOD_CELL\n        \n    # Adding geese to the board\n    for i in range(4):\n        goose = observation.geese[i]\n        # Skip if goose is dead\n        if len(goose) == 0:\n            continue\n        # If it's an opponent\n        if i != player_index:\n            x, y = row_col(goose[0], configuration.columns)\n            # Add possible head movements for it\n            for px, py in get_nearest_cells(x, y):\n                print (\"Head possible cell on ({}, {})\".format(px, py))\n                # If one of these head movements may lead the goose\n                # to eat, add tail as BODY_CELL, because it won't move.\n                if board[px, py] == FOOD_CELL:\n                    x_tail, y_tail = row_col(goose[-1], configuration.columns)\n                    print (\"Adding tail on ({}, {}) as the goose may eat\".format(x_tail, y_tail))\n                    board[x_tail, y_tail] = BODY_CELL\n                board[px, py] = HEAD_POSSIBLE_CELL\n        # Adds goose body without tail (tail is previously added only if goose may eat)\n        for n in goose[:-1]:\n            x, y = row_col(n, configuration.columns)\n            print (\"Body cell on ({}, {})\".format(x, y))\n            board[x, y] = BODY_CELL\n    \n    # Adding my head to the board\n    x, y = row_col(player_head, configuration.columns)\n    print (\"My head is at ({}, {})\".format(x, y))\n    board[x, y] = MY_HEAD\n    \n    # Debug board\n    print (board)\n    \n    # Iterate over food and geese in order to compute distances for each one\n    food_race = {}\n    for food in observation.food:\n        food_race[food] = {}\n        for i in range(4):\n            goose = observation.geese[i]\n            if len(goose) == 0:\n                continue\n            food_race[food][i] = cell_distance(goose[0], food, configuration)\n    \n    # The best food is the least coveted\n    best_food = None\n    best_distance = float('inf')\n    best_closest_geese = float('inf')\n    for food in food_race:\n        print (\"-> Food on {}\".format(row_col(food, configuration.columns)))\n        my_distance = food_race[food][player_index]\n        print (\" - My distance is {}\".format(my_distance))\n        closest_geese = 0\n        for goose_id in food_race[food]:\n            if goose_id == player_index:\n                continue\n            if food_race[food][goose_id] <= my_distance:\n                closest_geese += 1\n        print (\" - There are {} closest geese\".format(closest_geese))\n        if (closest_geese < best_closest_geese):\n            best_food = food\n            best_distance = my_distance\n            best_closest_geese = closest_geese\n            print (\"  * This food is better\")\n        elif (closest_geese == best_closest_geese) and (my_distance <= best_distance):\n            best_food = food\n            best_distance = my_distance\n            best_closest_geese = closest_geese\n            print (\"  * This food is better\")\n            \n    # Now that the best food has been found, check if the movement towards it is safe.\n    # Computes every available move and then check for move priorities.\n    if len(player_goose) > 1:\n        food_movements = move_towards(player_head, player_goose[1], best_food, configuration)\n    else:\n        food_movements = move_towards(player_head, player_head, best_food, configuration)\n    all_movements = get_all_movements(player_head, configuration)\n    # Excluding last movement reverse\n    food_movements = [move for move in food_movements if move[2] != REVERSE_MOVE[last_move]]\n    all_movements  = [move for move in all_movements if move[2] != REVERSE_MOVE[last_move]]\n    print (\"-> Available food moves: {}\".format(food_movements))\n    print (\"-> All moves: {}\".format(all_movements))\n    \n    # Trying to reach goal size of 4\n    if (len(player_goose) < 4):\n        \n        # 1. Food movements that are safe and not closed\n        for food_movement in food_movements:\n            print (\"Food movement {}\".format(food_movement))\n            if is_safe (food_movement, board) and not is_closed(food_movement, board):\n                print (\"It's safe! Let's move {}!\".format(moves[food_movement[2]]))\n                last_move = food_movement[2]\n                return moves[food_movement[2]] # Move here\n\n        # 2. Any movement safe and not closed\n        for movement in all_movements:\n            print (\"Movement {}\".format(movement))\n            if is_safe (movement, board) and not is_closed(movement, board):\n                print (\"It's safe! Let's move {}!\".format(moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n\n        # 3. Food movements half safe and not closed\n        for food_movement in food_movements:\n            if is_half_safe (food_movement, board) and not is_closed(food_movement, board):\n                print (\"Food movement {} is half safe, I'm going {}!\".format(food_movement, moves[food_movement[2]]))\n                last_move = food_movement[2]\n                return moves[food_movement[2]] # Move here\n\n        # 4. Any movement half safe and not closed\n        for movement in all_movements:\n            if is_half_safe (movement, board) and not is_closed(movement, board):\n                print (\"Movement {} is half safe, I'm going {}!\".format(movement, moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n\n        # 5. Food movements that are safe\n        for food_movement in food_movements:\n            print (\"Food movement {}\".format(food_movement))\n            if is_safe (food_movement, board):\n                print (\"It's safe! Let's move {}!\".format(moves[food_movement[2]]))\n                last_move = food_movement[2]\n                return moves[food_movement[2]] # Move here\n\n        # 6. Any movement safe\n        for movement in all_movements:\n            print (\"Movement {}\".format(movement))\n            if is_safe (movement, board):\n                print (\"It's safe! Let's move {}!\".format(moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n\n        # 7. Food movements half safe\n        for food_movement in food_movements:\n            if is_half_safe (food_movement, board):\n                print (\"Food movement {} is half safe, I'm going {}!\".format(food_movement, moves[food_movement[2]]))\n                last_move = food_movement[2]\n                return moves[food_movement[2]] # Move here\n\n        # 8. Any movement half safe\n        for movement in all_movements:\n            if is_half_safe (movement, board):\n                print (\"Movement {} is half safe, I'm going {}!\".format(movement, moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n    \n    # Just trying to walk in circles\n    else:\n        \n        # Delete food moves\n        food_coordinates = []\n        for food in food_race:\n            x_food, y_food = row_col(food, configuration.columns)\n            food_coordinates.append((x_food, y_food))\n        available_moves = []\n        for move in all_movements:\n            for (x_food, y_food) in food_coordinates:\n                if (move[0] != x_food) or (move[1] != y_food):\n                    available_moves.append(move)\n        \n        # 1. Run in circles if you can\n        circle_move = CIRCLE_MOVE[last_move]\n        for move in available_moves:\n            if (move[2] == circle_move) and (is_safe(move, board)) and not (is_closed(move, board)):\n                last_move = move[2]\n                return moves[move[2]]\n        \n        # 2. Any movement safe and not closed\n        for movement in all_movements:\n            print (\"Movement {}\".format(movement))\n            if is_safe (movement, board) and not is_closed(movement, board):\n                print (\"It's safe! Let's move {}!\".format(moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n\n        # 3. Any movement half safe and not closed\n        for movement in all_movements:\n            if is_half_safe (movement, board) and not is_closed(movement, board):\n                print (\"Movement {} is half safe, I'm going {}!\".format(movement, moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n            \n        # 4. Any movement safe\n        for movement in all_movements:\n            print (\"Movement {}\".format(movement))\n            if is_safe (movement, board):\n                print (\"It's safe! Let's move {}!\".format(moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n            \n        # 5. Any movement half safe\n        for movement in all_movements:\n            if is_half_safe (movement, board):\n                print (\"Movement {} is half safe, I'm going {}!\".format(movement, moves[movement[2]]))\n                last_move = movement[2]\n                return moves[movement[2]] # Move here\n            \n    # Finally, if all moves are unsafe, randomly pick one\n    rand_pick = np.random.randint(4) + 1\n    last_move = rand_pick\n    print (\"Yeah whatever, I'm going {}\".format(moves[rand_pick]))\n    return moves[rand_pick]","8c66ca35":"%%writefile pubhrl.py\n\n# This is a lightweight ML agent trained by self-play.\n# After sharing this notebook,\n# we will add Hungry Geese environment in our HandyRL library.\n# https:\/\/github.com\/DeNA\/HandyRL\n# We hope you enjoy reinforcement learning!\n\n\nimport pickle\nimport bz2\nimport base64\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# Neural Network for Hungry Geese\n\nclass TorusConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.edge_size = (kernel_size[0] \/\/ 2, kernel_size[1] \/\/ 2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = torch.cat([x[:,:,:,-self.edge_size[1]:], x, x[:,:,:,:self.edge_size[1]]], dim=3)\n        h = torch.cat([h[:,:,-self.edge_size[0]:], h, h[:,:,:self.edge_size[0]]], dim=2)\n        h = self.conv(h)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\n\nclass GeeseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        self.head_p = nn.Linear(filters, 4, bias=False)\n        self.head_v = nn.Linear(filters * 2, 1, bias=False)\n\n    def forward(self, x):\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n        p = self.head_p(h_head)\n        v = torch.tanh(self.head_v(torch.cat([h_head, h_avg], 1)))\n\n        return {'policy': p, 'value': v}\n\n\n# Input for Neural Network\n\ndef make_input(obses):\n    b = np.zeros((17, 7 * 11), dtype=np.float32)\n    obs = obses[-1]\n\n    for p, pos_list in enumerate(obs['geese']):\n        # head position\n        for pos in pos_list[:1]:\n            b[0 + (p - obs['index']) % 4, pos] = 1\n        # tip position\n        for pos in pos_list[-1:]:\n            b[4 + (p - obs['index']) % 4, pos] = 1\n        # whole position\n        for pos in pos_list:\n            b[8 + (p - obs['index']) % 4, pos] = 1\n            \n    # previous head position\n    if len(obses) > 1:\n        obs_prev = obses[-2]\n        for p, pos_list in enumerate(obs_prev['geese']):\n            for pos in pos_list[:1]:\n                b[12 + (p - obs['index']) % 4, pos] = 1\n\n    # food\n    for pos in obs['food']:\n        b[16, pos] = 1\n\n    return b.reshape(-1, 7, 11)\n\n\n# Load PyTorch Model\n\nPARAM = b'XXXXX'\n\nstate_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nmodel = GeeseNet()\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\n\n# Main Function of Agent\n\nobses = []\n\ndef agent(obs, _):\n    obses.append(obs)\n    x = make_input(obses)\n    with torch.no_grad():\n        xt = torch.from_numpy(x).unsqueeze(0)\n        o = model(xt)\n    p = o['policy'].squeeze(0).detach().numpy()\n\n    actions = ['NORTH', 'SOUTH', 'WEST', 'EAST']\n    return actions[np.argmax(p)]","7be02a42":"url = \"https:\/\/tonghuikang.github.io\/hungry-goose-training-logs\/strings\/pubhrl.txt\"\n\nimport urllib\nparams = next(urllib.request.urlopen(url)).decode(\"utf-8\")\n\nwith open(\"pubhrl.py\", \"r\") as f:\n    s = f.read()\ns = s.replace(\"XXXXX\", params)\nwith open(\"pubhrl.py\", \"w\") as f:\n    f.write(s)","6a23116e":"%%writefile pubhrl_trained.py\n\n# This is a lightweight ML agent trained by self-play.\n# After sharing this notebook,\n# we will add Hungry Geese environment in our HandyRL library.\n# https:\/\/github.com\/DeNA\/HandyRL\n# We hope you enjoy reinforcement learning!\n\n\nimport pickle\nimport bz2\nimport base64\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# Neural Network for Hungry Geese\n\nclass TorusConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.edge_size = (kernel_size[0] \/\/ 2, kernel_size[1] \/\/ 2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = torch.cat([x[:,:,:,-self.edge_size[1]:], x, x[:,:,:,:self.edge_size[1]]], dim=3)\n        h = torch.cat([h[:,:,-self.edge_size[0]:], h, h[:,:,:self.edge_size[0]]], dim=2)\n        h = self.conv(h)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\n\nclass GeeseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        self.head_p = nn.Linear(filters, 4, bias=False)\n        self.head_v = nn.Linear(filters * 2, 1, bias=False)\n\n    def forward(self, x):\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n        p = self.head_p(h_head)\n        v = torch.tanh(self.head_v(torch.cat([h_head, h_avg], 1)))\n\n        return {'policy': p, 'value': v}\n\n\n# Input for Neural Network\n\ndef make_input(obses):\n    b = np.zeros((17, 7 * 11), dtype=np.float32)\n    obs = obses[-1]\n\n    for p, pos_list in enumerate(obs['geese']):\n        # head position\n        for pos in pos_list[:1]:\n            b[0 + (p - obs['index']) % 4, pos] = 1\n        # tip position\n        for pos in pos_list[-1:]:\n            b[4 + (p - obs['index']) % 4, pos] = 1\n        # whole position\n        for pos in pos_list:\n            b[8 + (p - obs['index']) % 4, pos] = 1\n            \n    # previous head position\n    if len(obses) > 1:\n        obs_prev = obses[-2]\n        for p, pos_list in enumerate(obs_prev['geese']):\n            for pos in pos_list[:1]:\n                b[12 + (p - obs['index']) % 4, pos] = 1\n\n    # food\n    for pos in obs['food']:\n        b[16, pos] = 1\n\n    return b.reshape(-1, 7, 11)\n\n\n# Load PyTorch Model\n\nPARAM = b'XXXXX'\n\nstate_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nmodel = GeeseNet()\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\n\n# Main Function of Agent\n\nobses = []\n\ndef agent(obs, _):\n    obses.append(obs)\n    x = make_input(obses)\n    with torch.no_grad():\n        xt = torch.from_numpy(x).unsqueeze(0)\n        o = model(xt)\n    p = o['policy'].squeeze(0).detach().numpy()\n\n    actions = ['NORTH', 'SOUTH', 'WEST', 'EAST']\n    return actions[np.argmax(p)]","7447543a":"url = \"https:\/\/tonghuikang.github.io\/hungry-goose-training-logs\/strings\/pubhrl-trained-on-assorted-e4750.txt\"\n\nimport urllib\nparams = next(urllib.request.urlopen(url)).decode(\"utf-8\")\n\nwith open(\"pubhrl_trained.py\", \"r\") as f:\n    s = f.read()\ns = s.replace(\"XXXXX\", params)\nwith open(\"pubhrl_trained.py\", \"w\") as f:\n    f.write(s)","e4a67b04":"%%writefile alphageese.py\n\nimport pickle\nimport bz2\nimport base64\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport time\nfrom copy import deepcopy\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Action, translate\nfrom kaggle_environments.helpers import histogram\n# The model's parameters from https:\/\/www.kaggle.com\/yuricat\/smart-geese-trained-by-reinforcement-learning\nPARAM = b'XXXXX'\nclass MCTS():\n    def __init__(self, game, nn_agent, eps=1e-8, cpuct=1.0):\n        self.game = game\n        self.nn_agent = nn_agent\n        self.eps = eps\n        self.cpuct = cpuct\n        \n        self.Qsa = {}  # stores Q values for s,a (as defined in the paper)\n        self.Nsa = {}  # stores #times edge s,a was visited\n        self.Ns = {}  # stores #times board s was visited\n        self.Ps = {}  # stores initial policy (returned by neural net)\n\n        self.Vs = {}  # stores game.getValidMoves for board s\n        \n        self.last_obs = None\n\n    def getActionProb(self, obs, timelimit=1.0):\n        start_time = time.time()\n        while time.time() - start_time < timelimit:\n            self.search(obs, self.last_obs)\n\n        s = self.game.stringRepresentation(obs)\n        i = obs.index\n        counts = [\n            self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0\n            for a in range(self.game.getActionSize())\n        ]\n        prob = counts \/ np.sum(counts)\n        self.last_obs = obs\n        return prob\n\n    def search(self, obs, last_obs):\n        s = self.game.stringRepresentation(obs)\n\n        if s not in self.Ns:\n            values = [-10] * 4\n            for i in range(4):\n                if len(obs.geese[i]) == 0:\n                    continue\n                    \n                # leaf node\n                self.Ps[(s, i)], values[i] = self.nn_agent.predict(obs, last_obs, i)\n                    \n                valids = self.game.getValidMoves(obs, last_obs, i)    \n                self.Ps[(s, i)] = self.Ps[(s, i)] * valids  # masking invalid moves\n                sum_Ps_s = np.sum(self.Ps[(s, i)])\n                if sum_Ps_s > 0:\n                    self.Ps[(s, i)] \/= sum_Ps_s  # renormalize\n\n                self.Vs[(s, i)] = valids\n                self.Ns[s] = 0\n            return values\n\n        best_acts = [None] * 4\n        for i in range(4):\n            if len(obs.geese[i]) == 0:\n                continue\n            \n            valids = self.Vs[(s, i)]\n            cur_best = -float('inf')\n            best_act = self.game.actions[-1]\n\n            # pick the action with the highest upper confidence bound\n            for a in range(self.game.getActionSize()):\n                if valids[a]:\n                    if (s, i, a) in self.Qsa:\n                        u = self.Qsa[(s, i, a)] + self.cpuct * self.Ps[(s, i)][a] * math.sqrt(\n                                self.Ns[s]) \/ (1 + self.Nsa[(s, i, a)])\n                    else:\n                        u = self.cpuct * self.Ps[(s, i)][a] * math.sqrt(\n                            self.Ns[s] + self.eps)  # Q = 0 ?\n\n                    if u > cur_best:\n                        cur_best = u\n                        best_act = self.game.actions[a]\n                        \n            best_acts[i] = best_act\n        \n        next_obs = self.game.getNextState(obs, last_obs, best_acts)\n        values = self.search(next_obs, obs)\n\n        for i in range(4):\n            if len(obs.geese[i]) == 0:\n                continue\n                \n            a = self.game.actions.index(best_acts[i])\n            v = values[i]\n            if (s, i, a) in self.Qsa:\n                self.Qsa[(s, i, a)] = (self.Nsa[(s, i, a)] * self.Qsa[\n                    (s, i, a)] + v) \/ (self.Nsa[(s, i, a)] + 1)\n                self.Nsa[(s, i, a)] += 1\n\n            else:\n                self.Qsa[(s, i, a)] = v\n                self.Nsa[(s, i, a)] = 1\n\n        self.Ns[s] += 1\n        return values\nclass HungryGeese(object):\n    def __init__(self,\n                 rows=7,\n                 columns=11,\n                 actions=[Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST],\n                 hunger_rate=40):\n        self.rows = rows\n        self.columns = columns\n        self.actions = actions\n        self.hunger_rate = hunger_rate\n\n    def getActionSize(self):\n        return len(self.actions)\n\n    def getNextState(self, obs, last_obs, directions):\n        next_obs = deepcopy(obs)\n        next_obs.step += 1\n        geese = next_obs.geese\n        food = next_obs.food\n        \n        for i in range(4):\n            goose = geese[i]\n            \n            if len(goose) == 0: \n                continue\n            \n            head = translate(goose[0], directions[i], self.columns, self.rows)\n            \n            # Check action direction\n            if last_obs is not None and head == last_obs.geese[i][0]:\n                geese[i] = []\n                continue\n\n            # Consume food or drop a tail piece.\n            if head in food:\n                food.remove(head)\n            else:\n                goose.pop()\n            \n            # Add New Head to the Goose.\n            goose.insert(0, head)\n\n            # If hunger strikes remove from the tail.\n            if next_obs.step % self.hunger_rate == 0:\n                if len(goose) > 0:\n                    goose.pop()\n\n        goose_positions = histogram(\n            position\n            for goose in geese\n            for position in goose\n        )\n\n        # Check for collisions.\n        for i in range(4):\n            if len(geese[i]) > 0:\n                head = geese[i][0]\n                if goose_positions[head] > 1:\n                    geese[i] = []\n        \n        return next_obs\n\n    def getValidMoves(self, obs, last_obs, index):   \n        geese = obs.geese\n        pos = geese[index][0]\n        obstacles = {position for goose in geese for position in goose[:-1]}\n        if last_obs is not None: obstacles.add(last_obs.geese[index][0])\n        \n        valid_moves = [\n            translate(pos, action, self.columns, self.rows) not in obstacles\n            for action in self.actions\n        ]\n    \n        return valid_moves\n\n    def stringRepresentation(self, obs):      \n        return str(obs.geese + obs.food)\n# Neural Network for Hungry Geese\nclass TorusConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.edge_size = (kernel_size[0] \/\/ 2, kernel_size[1] \/\/ 2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = torch.cat([x[:,:,:,-self.edge_size[1]:], x, x[:,:,:,:self.edge_size[1]]], dim=3)\n        h = torch.cat([h[:,:,-self.edge_size[0]:], h, h[:,:,:self.edge_size[0]]], dim=2)\n        h = self.conv(h)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\nclass GeeseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        self.head_p = nn.Linear(filters, 4, bias=False)\n        self.head_v = nn.Linear(filters * 2, 1, bias=False)\n\n    def forward(self, x):\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n        p = torch.softmax(self.head_p(h_head), 1)\n        v = torch.tanh(self.head_v(torch.cat([h_head, h_avg], 1)))\n\n        return p, v\n\nclass NNAgent():\n    def __init__(self, state_dict):\n        self.model = GeeseNet()\n        self.model.load_state_dict(state_dict)\n        self.model.eval()\n        \n    def predict(self, obs, last_obs, index):\n        x = self._make_input(obs, last_obs, index)\n        with torch.no_grad():\n            xt = torch.from_numpy(x).unsqueeze(0)\n            p, v = self.model(xt)\n            \n        return p.squeeze(0).detach().numpy(), v.item()\n        \n    # Input for Neural Network\n    def _make_input(self, obs, last_obs, index):\n        b = np.zeros((17, 7 * 11), dtype=np.float32)\n        \n        for p, pos_list in enumerate(obs.geese):\n            # head position\n            for pos in pos_list[:1]:\n                b[0 + (p - index) % 4, pos] = 1\n            # tip position\n            for pos in pos_list[-1:]:\n                b[4 + (p - index) % 4, pos] = 1\n            # whole position\n            for pos in pos_list:\n                b[8 + (p - index) % 4, pos] = 1\n\n        # previous head position\n        if last_obs is not None:\n            for p, pos_list in enumerate(last_obs.geese):\n                for pos in pos_list[:1]:\n                    b[12 + (p - index) % 4, pos] = 1\n\n        # food\n        for pos in obs.food:\n            b[16, pos] = 1\n\n        return b.reshape(-1, 7, 11)\ngame = HungryGeese()\nstate_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nagent = NNAgent(state_dict)\nmcts = MCTS(game, agent)\n\ndef alphageese_agent(obs, config):\n    action = game.actions[np.argmax(\n        mcts.getActionProb(obs, timelimit=config.actTimeout))]\n    return action.name","f4edf8f7":"url = \"https:\/\/tonghuikang.github.io\/hungry-goose-training-logs\/strings\/pubhrl.txt\"\n\nimport urllib\nparams = next(urllib.request.urlopen(url)).decode(\"utf-8\")\n\nwith open(\"alphageese.py\", \"r\") as f:\n    s = f.read()\ns = s.replace(\"XXXXX\", params)\nwith open(\"alphageese.py\", \"w\") as f:\n    f.write(s)","e81b9494":"%%writefile alphageese_improved.py\n\nimport pickle\nimport bz2\nimport base64\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport time\nimport functools, collections\nfrom copy import deepcopy\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Action, translate\nfrom kaggle_environments.helpers import histogram\n\nsigmoid = lambda x: 1 \/ (1 + np.exp(-x))\neps = 10**(-6)\nDEBUG = True\n# The model\u2019s parameters from https:\/\/www.kaggle.com\/yuricat\/smart-geese-trained-by-reinforcement-learning\nPARAM = b'XXXXX'\nPARAM_SELF = b'YYYYY'\nclass MCTS():\n    def __init__(self, game, nn_agent_self, nn_agent_pubhrl, eps=1e-8, cpuct_self=1.0, cpuct_other=1.0):\n        self.game = game\n        self.nn_agent_self = nn_agent_self\n        self.nn_agent_pubhrl = nn_agent_pubhrl\n        self.eps = eps\n        self.cpuct_self = cpuct_self\n        self.cpuct_other = cpuct_other\n        \n        self.Qsa = {}  # stores Q values for s,a (as defined in the paper)\n        self.Nsa = {}  # stores #times edge s,a was visited\n        self.Ns = {}  # stores #times board s was visited\n        self.Ps = {}  # stores initial policy (returned by neural net)\n        self.Pm = {}  # masked initial policy (returned by neural net times masking)\n\n        self.Vs = {}  # stores game.getValidMoves for board s\n        \n        self.last_obs = None\n\n    def getActionProb(self, obs, timelimit=1.0):\n        extra_time = obs.remainingOverageTime\n        obs_step = obs.step\n        remaining_steps = 220 - obs.step\n        print(obs)\n        print(len(obs.geese[obs.index]), [len(goose) for goose in obs.geese])\n        \n        s = self.game.stringRepresentation(obs)\n        i = obs.index\n\n        start_time = time.time()\n        while time.time() - start_time < timelimit + extra_time\/(remaining_steps\/4):\n            self.search(obs, self.last_obs)\n\n            counts = [\n                self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0\n                for a in range(self.game.getActionSize())\n            ]\n            prob = counts \/ (np.sum(counts)+eps)\n            \n            target_prob = max(self.Ps[s, i])\n            if time.time() - start_time > timelimit and (extra_time < 10 or max(prob) >= target_prob):\n                break\n                        \n        self.last_obs = obs\n        \n        a = np.argmax(prob)\n        \n        if DEBUG:\n            print(s,i,a)\n            print(len(self.Qsa), len(self.Nsa), len(self.Ns), len(self.Ps), len(self.Vs))\n            print(\"self.Qsa\", self.Qsa[s,i,a])\n            print(\"self.Nsa\", self.Nsa[s,i,a])\n            print(\"self.Ns\",  self.Ns[s])\n            print(\"self.Ps\",  \" \".join(f\"{x:.4f}\" for x in self.Ps[s,i]))\n            print(\"self.Vs\",  self.Vs[s,i])\n            print(\"prob   \",  \" \".join(f\"{x:.4f}\" for x in prob))\n            print()\n        \n        return prob\n\n    def search(self, obs, last_obs, prev_v=0):\n        s = self.game.stringRepresentation(obs)\n        \n        if obs.step >= 200:\n            lengths = sorted(len(goose) for goose in obs.geese)[::-1]\n            position = lengths.index(len(obs.geese[obs.index]))\n            scores = {0:1, 1:0.5, 2:-0.5, 3:-1}\n            return [scores[position]]*4\n\n        if s not in self.Ns:\n            values = [-10] * 4\n            for i in range(4):\n                if len(obs.geese[i]) == 0:\n                    continue\n                    \n                valids = self.game.getValidMoves(obs, last_obs, i)\n                # leaf node\n                if sum(v == 0 for v in valids) >= 3:\n                    self.Ps[(s, i)], values[i] = valids, prev_v\n                elif obs.step >= 192:  # random rollouts\n                    self.Ps[(s, i)], values[i] = [0.25, 0.25, 0.25, 0.25], prev_v\n                elif i == obs.index:\n                    self.Ps[(s, i)], values[i] = self.nn_agent_self.predict(obs, last_obs, i)\n                else:\n                    self.Ps[(s, i)], values[i] = self.nn_agent_pubhrl.predict(obs, last_obs, i)                    \n                \n                self.Pm[s, i] = (valids + self.Ps[s, i]) * valids  # masking invalid moves\n                sum_Ps_s = np.sum(self.Pm[s, i])\n                if sum_Ps_s > 0:\n                    self.Pm[(s, i)] \/= sum_Ps_s  # renormalize\n\n                self.Vs[(s, i)] = valids\n                self.Ns[s] = 0\n            return values\n\n        best_acts = [None] * 4\n        for i in range(4):\n            if len(obs.geese[i]) == 0:\n                continue\n            \n            valids = self.Vs[(s, i)]\n            cur_best = -float('inf')\n            best_act = self.game.actions[-1]\n\n            # pick the action with the highest upper confidence bound\n            for a in range(self.game.getActionSize()):\n                if i == obs.index:\n                    cpuct = self.cpuct_self\n                else:\n                    cpuct = self.cpuct_other\n                if valids[a]:\n                    if (s, i, a) in self.Qsa:\n                        u = self.Qsa[(s, i, a)] + cpuct * self.Ps[(s, i)][a] * math.sqrt(\n                                self.Ns[s]) \/ (1 + self.Nsa[(s, i, a)])\n                    else:\n                        u = cpuct * self.Ps[(s, i)][a] * math.sqrt(\n                            self.Ns[s] + self.eps)  # Q = 0 ?\n\n                    if u > cur_best:\n                        cur_best = u\n                        best_act = self.game.actions[a]\n                        \n            best_acts[i] = best_act\n        \n        next_obs = self.game.getNextState(obs, last_obs, best_acts)\n        values = self.search(next_obs, obs)\n\n        for i in range(4):\n            if len(obs.geese[i]) == 0:\n                continue\n                \n            a = self.game.actions.index(best_acts[i])\n            v = values[i]\n            if (s, i, a) in self.Qsa:\n                self.Qsa[(s, i, a)] = (self.Nsa[(s, i, a)] * self.Qsa[\n                    (s, i, a)] + v) \/ (self.Nsa[(s, i, a)] + 1)\n                self.Nsa[(s, i, a)] += 1\n\n            else:\n                self.Qsa[(s, i, a)] = v\n                self.Nsa[(s, i, a)] = 1 + sigmoid(v)  # to tie break when needed\n\n        self.Ns[s] += 1\n        return values\nclass HungryGeese(object):\n    def __init__(self,\n                 rows=7,\n                 columns=11,\n                 actions=[Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST],\n                 hunger_rate=40):\n        self.rows = rows\n        self.columns = columns\n        self.actions = actions\n        self.hunger_rate = hunger_rate\n\n    def getActionSize(self):\n        return len(self.actions)\n\n    def getNextState(self, obs, last_obs, directions):\n        next_obs = deepcopy(obs)\n        next_obs.step += 1\n        geese = next_obs.geese\n        food = next_obs.food\n                \n        for i in range(4):\n            goose = geese[i]\n            \n            if len(goose) == 0: \n                continue\n            \n            head = translate(goose[0], directions[i], self.columns, self.rows)\n            \n            # Check action direction\n            if last_obs is not None and head == last_obs.geese[i][0]:\n                geese[i] = []\n                continue\n\n            # Consume food or drop a tail piece.\n            if head in food:\n                food.remove(head)\n            else:\n                goose.pop()\n            \n            # Add New Head to the Goose.\n            goose.insert(0, head)\n\n            # If hunger strikes remove from the tail.\n            if next_obs.step % self.hunger_rate == 0:\n                if len(goose) > 0:\n                    goose.pop()\n\n        goose_positions = histogram(\n            position\n            for goose in geese\n            for position in goose\n        )\n\n        # Check for collisions.\n        for i in range(4):\n            if len(geese[i]) > 0:\n                head = geese[i][0]\n                if goose_positions[head] > 1:\n                    geese[i] = []\n        \n        return next_obs\n\n    def getValidMoves(self, obs, last_obs, index):        \n        foods = obs.food        \n        geese = deepcopy(obs.geese)        \n        pos = geese[index][0]\n        \n        maxlen_goose = max(len(goose) for goose in geese)\n        num_goose = sum(len(goose) > 0 for goose in geese)\n        \n        potential_tail_strike = collections.defaultdict(lambda: 1)\n        potential_head_collision = collections.defaultdict(lambda: 1)\n        for goose_idx, goose in enumerate(geese):\n            if goose_idx == index or not goose:\n                continue\n            for action in self.actions:\n                nex_loc = translate(goose[0], action, self.columns, self.rows)\n                head_collision_factor = 1\n                if len(geese[index]) < len(goose):\n                    potential_head_collision[nex_loc] = 0.111  # avoid because of definite loss\n                elif num_goose == 2 and len(geese[index]) >= maxlen_goose:\n                    potential_head_collision[nex_loc] = 3.333  # secure first place\n                else:\n                    potential_head_collision[nex_loc] = 0.888  # would prefer higher placing\n                if nex_loc in foods:\n                    potential_tail_strike[goose[-1]] = 0.101\n        \n        next_poss = [translate(pos, action, self.columns, self.rows) for action in self.actions]\n        \n        mask_head_collision = np.array([potential_head_collision[next_pos] for next_pos in next_poss])\n        mask_tail_strike    = np.array([potential_tail_strike[next_pos] for next_pos in next_poss])\n\n        obstacles = {position for goose in geese for position in goose[:-1]}\n        if last_obs:\n            obstacles.add(last_obs.geese[index][0])            \n    \n        mask_valid = np.array([1.0 if next_pos not in obstacles else 0 \n                               for next_pos in next_poss])\n    \n        return mask_valid * mask_tail_strike * mask_head_collision\n\n    def stringRepresentation(self, obs):      \n        return str(obs.geese + obs.food)\n# Neural Network for Hungry Geese\nclass TorusConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.edge_size = (kernel_size[0] \/\/ 2, kernel_size[1] \/\/ 2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = torch.cat([x[:,:,:,-self.edge_size[1]:], x, x[:,:,:,:self.edge_size[1]]], dim=3)\n        h = torch.cat([h[:,:,-self.edge_size[0]:], h, h[:,:,:self.edge_size[0]]], dim=2)\n        h = self.conv(h)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\nclass GeeseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        self.head_p = nn.Linear(filters, 4, bias=False)\n        self.head_v = nn.Linear(filters * 2, 1, bias=False)\n\n    def forward(self, x):\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n        p = torch.softmax(self.head_p(h_head), 1)\n        v = torch.tanh(self.head_v(torch.cat([h_head, h_avg], 1)))\n\n        return p, v\n\nclass NNAgent():\n    def __init__(self, state_dict):\n        self.model = GeeseNet()\n        self.model.load_state_dict(state_dict)\n        self.model.eval()\n        \n    def predict(self, obs, last_obs, index):\n        x = self._make_input(obs, last_obs, index)\n        with torch.no_grad():\n            xt = torch.from_numpy(x).unsqueeze(0)\n            p, v = self.model(xt)\n            \n        return p.squeeze(0).detach().numpy(), v.item()\n        \n    # Input for Neural Network\n    def _make_input(self, obs, last_obs, index):\n        b = np.zeros((17, 7 * 11), dtype=np.float32)\n        \n        for p, pos_list in enumerate(obs.geese):\n            # head position\n            for pos in pos_list[:1]:\n                b[0 + (p - index) % 4, pos] = 1\n            # tip position\n            for pos in pos_list[-1:]:\n                b[4 + (p - index) % 4, pos] = 1\n            # whole position\n            for pos in pos_list:\n                b[8 + (p - index) % 4, pos] = 1\n\n        # previous head position\n        if last_obs is not None:\n            for p, pos_list in enumerate(last_obs.geese):\n                for pos in pos_list[:1]:\n                    b[12 + (p - index) % 4, pos] = 1\n\n        # food\n        for pos in obs.food:\n            b[16, pos] = 1\n\n        return b.reshape(-1, 7, 11)\ngame = HungryGeese()\n\nstate_dict_self = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nagent_self = NNAgent(state_dict_self)\n\nstate_dict_pubhrl = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nagent_pubhrl = NNAgent(state_dict_pubhrl)\n\nmcts = MCTS(game, agent_self, agent_pubhrl)\n\ndef alphageese_agent(obs, config):\n    action = game.actions[np.argmax(\n        mcts.getActionProb(obs, timelimit=config.actTimeout))]\n    return action.name\n\n# class Struct(object):\n#     # convert dictionary into object to allow instance.attribute notation\n#     def __init__(self, data):\n#         for name, value in data.items():\n#             setattr(self, name, self._wrap(value))\n\n#     def _wrap(self, value):\n#         if isinstance(value, (tuple, list, set, frozenset)): \n#             return type(value)([self._wrap(v) for v in value])\n#         else:\n#             return Struct(value) if isinstance(value, dict) else value\n\n# ## test code\n# config = {'episodeSteps': 200, 'actTimeout': 1, 'runTimeout': 1200, \n#           'columns': 11, 'rows': 7, 'hunger_rate': 40, 'min_food': 2, 'max_length': 99}\n\n# # [????] better to get stuck because game is ending\n# obs = {'remainingOverageTime': 60, 'index': 1, 'step': 197, 'geese': [[], \n#     [36,35,24,25,14,3,4,15,16,27,38,39,40,29,28,17,18,7,6,5], \n#     [56,45,46,57,68,2,13,12,23,34,33,43,42,31,20,21,10,9,75,64,65], \n#     [30,41,52,63,62,51,50,49,48,59,60,61,72,73,74,8,19]], 'food': [26, 69]}  \n\n# alphageese_agent(Struct(obs), Struct(config))\n\n# # [0100] https:\/\/www.kaggle.com\/c\/hungry-geese\/submissions?dialog=episodes-episode-24354313\n# obs = {'remainingOverageTime': 36.25855599999999, 'index': 3, 'step': 195, 'geese': [\n#     [76, 75, 74, 73, 72, 6, 7, 8, 9, 20, 21, 10], \n#     [3, 2, 13, 14, 25, 24, 23, 22, 11, 0, 66, 67, 68, 69, 70, 71, 5], \n#     [65, 64, 63, 52, 53, 42, 31, 32, 43, 54, 44, 45, 46, 57, 56], \n#     [36, 37, 38, 27, 26, 15, 16, 17, 28, 29, 18, 19, 30, 41, 40, 51, 62, 61, 50, 49, 48, 47]], 'food': [34, 39]}\n\n# alphageese_agent(Struct(obs), Struct(config))\n\n# # [0001] https:\/\/www.kaggle.com\/c\/hungry-geese\/submissions?dialog=episodes-episode-24354751\n# obs = {'remainingOverageTime': 8.744749000000029, 'index': 3, 'step': 159, 'geese': [\n#     [28, 17, 18, 7, 6, 5, 71, 70, 59, 48, 49, 38, 37], \n#     [57, 46, 47, 58, 69, 3, 14, 25, 36, 35, 24, 23, 12, 13, 2], \n#     [29, 30, 19, 20, 9, 8, 74, 73, 62, 61, 50, 51, 52, 63, 64, 53, 42, 41], \n#     [21, 32, 22, 33, 44, 45, 56, 67, 66, 76, 10, 0]], 'food': [60, 54]}\n\n# alphageese_agent(Struct(obs), Struct(config))","0613b6f9":"url = \"https:\/\/tonghuikang.github.io\/hungry-goose-training-logs\/strings\/pubhrl.txt\"\nurl_self = \"https:\/\/tonghuikang.github.io\/hungry-goose-training-logs\/strings\/pubhrl-trained-on-boiler-adverse.txt\"\n\nimport urllib\nparams = next(urllib.request.urlopen(url)).decode(\"utf-8\")\nparams_self = next(urllib.request.urlopen(url_self)).decode(\"utf-8\")\n\nwith open(\"alphageese_improved.py\", \"r\") as f:\n    s = f.read()\ns = s.replace(\"YYYYY\", params_self)\ns = s.replace(\"XXXXX\", params)\nwith open(\"alphageese_improved.py\", \"w\") as f:\n    f.write(s)","6db521d9":"'YYYYY' in params, 'XXXXX' in params, 'YYYYY' in params_self, 'XXXXX' in params_self","2582e1f7":"!python alphageese_improved.py","5898357a":"!pip install -q -U kaggle_environments","35e2b98e":"import collections, os\n\nimport kaggle_environments\nfrom kaggle_environments import evaluate, make, utils\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\nkaggle_environments.__version__","22f476cd":"env = make(\"hungry_geese\")","52c672c9":"vers = 32","8da7b062":"env.reset()\nenv.run(\n    [\n        \"..\/input\/hungry-goose-alphageese-agents\/v{}.py\".format(vers), \n        \"..\/input\/hungry-goose-alphageese-agents\/v1.py\", \n        \"..\/input\/hungry-goose-alphageese-agents\/v1.py\", \n        \"..\/input\/hungry-goose-alphageese-agents\/v1.py\",\n    ],\n)\nenv.render(mode=\"ipython\", width=800, height=700)","e188745c":"list_names = [\n    \"..\/input\/hungry-goose-alphageese-agents\/v{}\".format(vers),\n    \"..\/input\/hungry-goose-alphageese-agents\/v1\",\n#     \"boilergoose\",\n#     \"risk_averse_greedy\",\n]\n\nlist_agents = [agent_name + \".py\" for agent_name in list_names]","54adf42a":"def one_on_one_with_two_simple(agents):\n    n_agents = len(agents)\n\n    scores = np.zeros((n_agents, n_agents), dtype=np.int)\n    \n    print(\"Simulation of battles. It can take some time...\")\n\n    for ind_1 in range(n_agents):\n        for ind_2 in range(ind_1+1, n_agents):\n            if ind_1 == ind_2:\n                continue\n            def threaded_evaluation(_):\n                print(\"x\", end=\" \")\n\n                current_score = evaluate(\n                    \"hungry_geese\", \n                    [\n                        agents[ind_1], \n                        agents[ind_2], \n                        agents[ind_2], \n                        agents[ind_2], \n                    ],\n                    num_episodes=1,\n                )\n                \n                print(_, end=\" \")\n\n                episode_winners = np.argmax(current_score, axis=1)\n                episode_winner_counts = collections.Counter(episode_winners)\n\n                scores[ind_1, ind_2] += episode_winner_counts.get(0, 0)\n#                 scores[ind_2, ind_1] += episode_winner_counts.get(1, 0)\n\n                \n            for _ in range(25):\n                threaded_evaluation(_)\n                \n#             from multiprocessing.pool import ThreadPool as Pool\n#             with Pool(max(2,os.cpu_count()-4)) as p:\n#                 p.map(threaded_evaluation, list(range(20)))\n    \n    return scores","17dbff65":"def visualize_scores(scores, x_agents, y_agents, title):\n    df_scores = pd.DataFrame(\n        scores, \n        index=x_agents, \n        columns=y_agents,\n    )\n\n\n    plt.figure(figsize=(5, 5))\n    sn.heatmap(\n        df_scores, annot=True, cbar=False, \n        cmap='coolwarm', linewidths=1, \n        linecolor='black', fmt=\"d\",\n    )\n    plt.xticks(rotation=90, fontsize=15)\n    plt.yticks(rotation=0, fontsize=15)\n    plt.title(title, fontsize=18)\n    plt.savefig(title + \".png\")\n    \n    plt.show()","0affcbf1":"scores = one_on_one_with_two_simple(list_agents)\nvisualize_scores(scores, list_names, list_names, \"Number of wins: one versus one\")","cae68cc3":"# PubHRL","771c97ed":"Copy from kernel [Simple BFS- Starter Agent](https:\/\/www.kaggle.com\/aatiffraz\/simple-bfs-starter-agent)","9b17c5ec":"# Straightforward BFS","7062a929":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/25401\/logos\/header.png?t=2021-01-22-07-12-33)","c171ff16":"# Hungry Geese - Agents Comparison\n\n\n\n- This notebook contains a lot of different agents from different sources for the [Hungry Geese](https:\/\/www.kaggle.com\/c\/hungry-geese).   \n- In the [Comparison In Battle](#100) section, we also added a comparison of each pair of different agents (against two very simple additional agents so that real conditions are met). The agents fight for 100 rounds and then counts of the wins are calculated","d91859ea":"# PubHRL - trained","c9356996":"# AlphaGeese","861cbbe9":"# Crazy Goose","4f8db63c":"Copy from kernel [Risk averse greedy goose](https:\/\/www.kaggle.com\/ilialar\/risk-averse-greedy-goose)","3d6399df":"# BoilerGoose","8d60ace6":"Copy from kernel [Crazy Goose](https:\/\/www.kaggle.com\/gabrielmilan\/crazy-goose)","9940f98a":"# Simple Toward","54f0718e":"# Simple BFS","dc0fb6a5":"Copy from kernel [Mighty BoilerGoose with Flood fill](https:\/\/www.kaggle.com\/superant\/mighty-boilergoose-with-flood-fill)","bce91c4e":"# Running\nUsing The kaggle_environments For Testing Agents","277b58c8":"<a id=\"100\"><\/a>\n<h2 style='background:deeppink; border:0; color:white'><center>Comparison In Battle<center><h2>","7db6342c":"# Risk Adverse Greedy Goose","b814f589":"# AlphaGeese improved","32c69434":"Copy from kernel [Smart Geese Trained by Reinforcement Learning](https:\/\/www.kaggle.com\/yuricat\/smart-geese-trained-by-reinforcement-learning)","f63b570d":"# Greedy Agent"}}