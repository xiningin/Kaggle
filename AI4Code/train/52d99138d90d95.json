{"cell_type":{"492337b5":"code","522d6752":"code","c48e4805":"code","5b08f2cf":"code","7419fd44":"code","f1e0c064":"code","7802eddc":"code","f43fcaaf":"code","d5d76acc":"code","fc5f36a2":"code","757eb1d5":"code","1560e37b":"code","816d1a89":"code","59d5f541":"code","e1a75946":"code","a9db8ae5":"code","bac6b43e":"code","f43ce2b8":"code","000aa7e7":"code","44d2b5fa":"code","d6743d0b":"code","3b4cc504":"code","e98c9632":"code","67f862d2":"code","af41b78a":"code","e1f1283b":"code","52f98071":"code","30707bdc":"code","6e7123af":"code","0a780dcf":"code","f2f04522":"markdown","15a06c05":"markdown","c2c9826a":"markdown","166ec3f4":"markdown","2d060701":"markdown"},"source":{"492337b5":"import pandas as pd\nimport numpy as np\nfrom load_kaggle import load_kaggle","522d6752":"subm, train, test = load_kaggle()\nprint(train.shape, test.shape, subm.shape)\ntrain.head()","c48e4805":"target = ['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\nproject_name = 'July_TPS'","5b08f2cf":"!pip install featurewiz --upgrade","7419fd44":"!pip install deep_autoviml","f1e0c064":"import featurewiz as FW","7802eddc":"from deep_autoviml import deep_autoviml as deepauto","f43fcaaf":"### Let's split tyhe date time column into multiple fields using featurewiz\ndate_col = 'date_time'\ntrain_rem_cols = [x for x in list(train) if x not in target+[date_col]]\nlen(train_rem_cols)","d5d76acc":"ts_outs = FW.FE_create_time_series_features(train, date_col)","fc5f36a2":"### Let us see what features have been created from that one column ##\nts_outs[0].head(1), ts_outs[1]","757eb1d5":"ts_cols = ts_outs[1]\ntrain = ts_outs[0]","1560e37b":"test, ts_cols = FW.FE_create_time_series_features(test, date_col, ts_cols)\ntest.shape","816d1a89":"train_target = train[target].values\ntrain_target.shape","59d5f541":"train = train[ts_cols+train_rem_cols]\ntrain.shape","e1a75946":"test = test[ts_cols+train_rem_cols]\ntest.shape","a9db8ae5":"train[target] = train_target\nprint(train.shape)\ntrain.head(1)","bac6b43e":"######   D E F A U L T S    S E T T I N G S   F O R   D E E P    A U T O  V I M L ###\nkeras_model_type = \"fast\" ## always try \"fast\" first, then \"fast1\", \"fast2\", etc.\n### always set early_stopping to True first and then change it to False\n#### You always need 15 max_trials to get something decent #####\n#### always set tuner to \"storm\" and then \"optuna\". \n### NLP char limit kicks off NLP processing. Feature Cross later.\nmodel_options = {'nlp_char_limit':50, 'cat_feat_cross_flag':False,\n                 'max_trials': 10, \"tuner\": \"storm\"}\nkeras_options = {\"patience\":10, 'class_weight': True, 'early_stopping': True, \n                 'lr_scheduler': '', \"optimizer\": 'RMS'}","f43ce2b8":"model, cat_vocab_dict = deepauto.fit(train, target, keras_model_type=keras_model_type,\n\t\tproject_name=project_name, keras_options=keras_options,  \n\t\tmodel_options=model_options, save_model_flag=False, use_my_model='',\n\t\tmodel_use_case='', verbose=1)","000aa7e7":"predictions = deepauto.predict(model, project_name, test_dataset=test,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","44d2b5fa":"y_preds = predictions[-1]\ny_preds[:5]","d6743d0b":"subm[target] = y_preds\nsubm.head()","3b4cc504":"#subm.to_csv('fast_submission.csv', index=False)","e98c9632":"drop_cols = ['target_carbon_monoxide','target_benzene']","67f862d2":"train2 = train.sample(frac=1.0).sample(frac=1.0).drop(drop_cols, axis=1)\ntrain2.head(2)","af41b78a":"target2 = 'target_nitrogen_oxides'\nkeras_model_type =  \"fast\" ### let's try \"fast\", \"fast1\", \"fast2\" in that order","e1f1283b":"model2, cat_vocab_dict2 = deepauto.fit(train2, target2, keras_model_type=keras_model_type,\n\t\tproject_name=project_name, keras_options=keras_options,  \n\t\tmodel_options=model_options, save_model_flag=True, use_my_model='',\n\t\tmodel_use_case='', verbose=1)","52f98071":"predictions2 = deepauto.predict(model2, project_name, test_dataset=test,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict2)","30707bdc":"y_preds2 = predictions2[-1]\ny_preds2[:5]","6e7123af":"subm[target2] = y_preds2\nsubm.head()","0a780dcf":"subm.to_csv('submission_combo.csv', index=False)","f2f04522":"# Let's add 19 time series features using Featurewiz","15a06c05":"# Since the model did very well on the first 2 targets, but did poorly on the third target, we will build a separate model for the third target variable\nYou will notice that the rows are not shuffled well for the 'target_nitrogen_oxides'. Let us shuffle the dataset and see.","c2c9826a":"# Deep AutoViML is a brand-new AutoML library for building deep learning models using tensorflow and keras using a single line of code!\n## It will automatically do the following:\n- Load a wide variety of performant DNN architectures such as deep and wide, deep and cross models, etc.\n- Use a hypertuner named Storm-Tuner to select the best hyper params for each of the model architectures\n- Select the best model and add pre-processing layers for feature transformation and do selective feature engineering\n- For NLP tasks: it select a BERT or USE model along with text processors\n- Train best model and run predictions using the trained model\n- You can automatically save the model with its preprocessing layers and load it elsewhere or serve it using tf.serving on Cloud providers\n## For github visit: [deep_autoviml](https:\/\/github.com\/AutoViML\/deep_autoviml)","166ec3f4":"# Let's run Deep AutoViML with 26 features for 3 targets","2d060701":"# Install Deep AutoViML here"}}