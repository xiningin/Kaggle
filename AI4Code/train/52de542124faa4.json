{"cell_type":{"192ae3e0":"code","1a0db4bd":"code","72c500da":"code","58e07f49":"code","21df18e4":"code","3e8f2b75":"code","d528da94":"code","e3d271d2":"code","b6921968":"code","ba10a07d":"code","8dbfe199":"code","115ced25":"code","3643a45e":"code","72f8ffed":"code","268b44ad":"code","ac3846ed":"code","3504860b":"code","9956980b":"code","bb759cee":"markdown","3a24395f":"markdown","8a856162":"markdown","59123dee":"markdown","fc809799":"markdown","eed0975c":"markdown"},"source":{"192ae3e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a0db4bd":"df=pd.read_csv('\/kaggle\/input\/stocknews\/Combined_News_DJIA.csv', encoding = \"ISO-8859-1\")","72c500da":"df.head()","58e07f49":"df.info()","21df18e4":"train = df[df['Date'] < '20150101']\ntest = df[df['Date'] > '20141231']","3e8f2b75":"# Removing punctuations\ndata=train.iloc[:,2:27]\ndata.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n\n# Renaming column names for ease of access\nlist1= [i for i in range(25)]\nnew_Index=[str(i) for i in list1]\ndata.columns= new_Index\ndata.head(5)","d528da94":"# Convertng headlines to lower case\nfor index in new_Index:\n    data[index]=data[index].str.lower()\ndata.head(1)","e3d271d2":"' '.join(str(x) for x in data.iloc[1,0:25])","b6921968":"headlines = []\nfor row in range(0,len(data.index)):\n    headlines.append(' '.join(str(x) for x in data.iloc[row,0:25]))","ba10a07d":"headlines[0]","8dbfe199":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier","115ced25":"## implement BAG OF WORDS\ncountvector=CountVectorizer(ngram_range=(2,2))\ntraindataset=countvector.fit_transform(headlines)","3643a45e":"# 0-1 sparse matrix\ntraindataset[0]","72f8ffed":"# implement RandomForest Classifier\nrandomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\nrandomclassifier.fit(traindataset,train['Label'])","268b44ad":"## Predict for the Test Dataset\ntest_transform= []\nfor row in range(0,len(test.index)):\n    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\ntest_dataset = countvector.transform(test_transform)\npredictions = randomclassifier.predict(test_dataset)","ac3846ed":"## Import library to check accuracy\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score","3504860b":"matrix=confusion_matrix(test['Label'],predictions)\nprint(matrix)\nscore=accuracy_score(test['Label'],predictions)\nprint(score)\nreport=classification_report(test['Label'],predictions)\nprint(report)","9956980b":"df.to_csv('output.csv')","bb759cee":"## Feature extraction from text and model selection","3a24395f":"## Saving output","8a856162":"## Test data preprocessing and Prediction","59123dee":"## Train Test Splitting","fc809799":"## Evaluation of the model","eed0975c":"## Data Preprocessing"}}