{"cell_type":{"886d6280":"code","b6e2f1dc":"code","fe0a4ef4":"code","3d4c1a45":"code","f7e4f387":"code","7f730af6":"code","528c9778":"code","e44efc96":"code","20130560":"code","24616518":"code","fba90ab7":"code","95039190":"code","4bf9ac94":"code","7289c460":"code","9bcfb404":"code","a8039988":"code","b11554db":"code","c2147057":"code","c99f239b":"code","4587fdb7":"code","0d70376e":"code","e7dac4b9":"code","245c1e59":"code","4d60770e":"code","a6a18842":"code","8163e95c":"code","8967fd9e":"code","65df88a7":"code","ed5b3cd2":"code","e16103f1":"markdown","37aeb246":"markdown","4868ec29":"markdown","7cdaf285":"markdown","a84fde1b":"markdown","991d8629":"markdown","c5caacc6":"markdown"},"source":{"886d6280":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b6e2f1dc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","fe0a4ef4":"data = {\n'year': [2010, 2011, 2012,\n2010, 2011, 2012,\n2010, 2011, 2012],\n'team': ['FCBarcelona', 'FCBarcelona', 'FCBarcelona',\n'RMadrid', 'RMadrid', 'RMadrid',\n'ValenciaCF', 'ValenciaCF', 'ValenciaCF'],\n'wins': [30, 28, 32, 29, 32, 26, 21, 17, 19],\n'draws': [6, 7, 4, 5, 4, 7, 8, 10, 8],\n'losses': [2, 3, 2, 4, 2, 5, 9, 11, 11]\n}\n\nfootball = pd.DataFrame(data, columns = ['year', 'team', 'wins', 'draws', 'losses'])","3d4c1a45":"edu = pd.read_csv('\/kaggle\/input\/ict-ense3-2020\/files\/ch02\/educ_figdp_1_Data.csv',\n                  na_values=':', usecols=['TIME', 'GEO', 'Value'])","f7e4f387":"edu","7f730af6":"edu.head()","528c9778":"edu.tail()","e44efc96":"edu.describe()","20130560":"edu['Value'] ","24616518":"edu[10:14]","fba90ab7":"edu.iloc[90:94][['TIME','GEO']]","95039190":"edu[edu['Value'] > 6.5].tail()","4bf9ac94":"edu[edu[\"Value\"].isnull()].head()","7289c460":"edu.max(axis = 0)","9bcfb404":"print ('Pandas max function:', edu['Value'].max())\nprint ('Python max function:', max(edu['Value']))","a8039988":"s = edu[\"Value\"]\/100\ns.head()","b11554db":"s = edu[\"Value\"].apply(np.sqrt)\ns.head()","c2147057":"eduDrop = edu[~edu[\"Value\"].isnull()].copy()\neduDrop.head()","c99f239b":"eduDrop = edu.dropna(how = 'any', subset = [\"Value\"])\neduDrop.head()","4587fdb7":"eduFilled = edu.fillna(value = {\"Value\": 0})\neduFilled.head()","0d70376e":"edu.sort_values(by = 'Value', ascending = False,\n                inplace = True)\nedu.head()","e7dac4b9":"edu.sort_index(axis = 0, ascending = True, inplace = True)\nedu.head()","245c1e59":"group = edu[[\"GEO\", \"Value\"]].groupby('GEO').mean()\ngroup.head()","4d60770e":"filtered_data = edu[edu[\"TIME\"] > 2005]\npivedu = pd.pivot_table(filtered_data, values = 'Value',\n                        index = ['GEO'], columns = ['TIME'])\npivedu.head()","a6a18842":"pivedu.loc[['Spain','Portugal'], [2006,2011]]","8163e95c":"pivedu = pivedu.drop(['Euro area (13 countries)',\n                      'Euro area (15 countries)',\n                      'Euro area (17 countries)',\n                      'Euro area (18 countries)',\n                      'European Union (25 countries)',\n                      'European Union (27 countries)',\n                      'European Union (28 countries)'\n                      ], axis=0)\npivedu = pivedu.rename(\n    index={'Germany (until 1990 former territory of the FRG)': 'Germany'})\npivedu = pivedu.dropna()\npivedu.rank(ascending=False, method='first').head()","8967fd9e":"totalSum = pivedu.sum(axis = 1)\n\ntotalSum.rank(ascending = False, method = 'dense').sort_values().head()","65df88a7":"totalSum = pivedu.sum(axis = 1).sort_values(ascending = False)\ntotalSum.plot(kind = 'bar', style = 'b', alpha = 0.9,\n              title = \"Total Values for Country\")","ed5b3cd2":"my_colors = ['b', 'r', 'g', 'y', 'm', 'c']\nax = pivedu.plot(kind='barh', stacked=True, color=my_colors, figsize=(12, 12))\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.savefig('Value_Time_Country.png', dpi=300, bbox_inches='tight')","e16103f1":"What happens if we give a number as argument to the method head()?\n\nIt retuns the same number of starting rows from data set. Like if we add 10 as argument it will return first 10 rows of the data set.","37aeb246":"What does the operation edu[\u2019Value\u2019] > 6.5 produce? An if we apply the indexedu[edu[\u2019Value\u2019] > 6.5]?Is this aSeries or aDataFrame?\n\nIt produces the lines from the data set which have a value higher than 6.5 only. \n","4868ec29":"What do you observe regarding the parameter ascending=False?\n\nMaybe it is showing the contribution of the country in the EU area with every increasing year in time.\n","7cdaf285":"What does the method tail()return?\n\nIt returns the last seleted rows of the dataset. Like if we selest 5 it returns the last 5 rows.\n\n","a84fde1b":"What does this index return? What does the first index represent? And the second one?\n\nIt returns the specific lines according to the choosen numbers. The time attribute show the number of the year & geo shows the name of the country.\n\n","991d8629":"Which is the size of the edu DataFrame (rows x columns)?\n\n384 rows \u00d7 3 columns\n","c5caacc6":"Which measures does the result show? It seems that it shows some default values, can you guess which ones?\n\nIt shows some marginala\/average values from the data table. It calculate the max & min values as so the mean values including the values after every 25%."}}