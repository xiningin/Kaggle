{"cell_type":{"076e610e":"code","26080664":"code","8ccd4453":"code","16ec0d73":"code","e3312319":"code","72158480":"code","29a2c388":"code","16b45cae":"code","05cb24a7":"code","d8fab103":"code","633cb6b5":"code","ddcb5974":"code","b0994c1b":"code","65007e41":"code","2d5665c6":"code","cedc8727":"code","171de608":"code","a7d4525a":"markdown","2ccb54a5":"markdown","bb60caad":"markdown","bb37832d":"markdown","f00376de":"markdown","ce583913":"markdown","faf6d2c2":"markdown","765b4f77":"markdown"},"source":{"076e610e":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os \nimport xarray as xr \nimport pandas as pd ","26080664":"ds = xr.open_dataset(\"\/kaggle\/input\/era5-pressure-and-cloud-cover\/wind_t2m_tp_1979.nc\")","8ccd4453":"# variance expliqu\u00e9e par choix al\u00e9atoire\nl = [i for i in range(730)]\nnp.random.shuffle(l)\n\nds1 = ds.isel(time=l[:220]) \nds2 = ds.isel(time=l[220:440])\nds3 = ds.isel(time=l[440:])\nTSS = ((ds[\"t2m\"]-ds[\"t2m\"].mean(\"time\"))**2).sum(\"time\")\nWSS = ((ds1[\"t2m\"]-ds1[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((ds2[\"t2m\"]-ds2[\"t2m\"].mean(\"time\"))**2).sum(\"time\") +((ds3[\"t2m\"]-ds3[\"t2m\"].mean(\"time\"))**2).sum(\"time\")","16ec0d73":"(1 - WSS\/TSS).plot(vmin=0,vmax=1)","e3312319":"ds1 = ds.sel(time=ds.time[0::2])\nds2 = ds.sel(time=ds.time[1::2])\n\nTSS = ((ds[\"t2m\"]-ds[\"t2m\"].mean(\"time\"))**2).sum(\"time\")\nWSS = ((ds1[\"t2m\"]-ds1[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((ds2[\"t2m\"]-ds2[\"t2m\"].mean(\"time\"))**2).sum(\"time\") ","72158480":"(1 - WSS\/TSS).plot(vmin=0,vmax=1)","29a2c388":"dayofyear = pd.to_datetime(ds.time.values).dayofyear \nwinter = (dayofyear < 75) + (dayofyear>365-75)\nsummer = (dayofyear >= 75) * (dayofyear<=365-75)","16b45cae":"ds_winter = ds.isel(time=winter)#.sel(time=ds.time[::2])\nds_summer = ds.isel(time=summer)#.sel(time=ds.time[::2])\nd1 = ds_winter.sel(time=ds_winter.time[::2])\nd2 = ds_summer.sel(time=ds_summer.time[::2])\nd3 = ds_winter.sel(time=ds_winter.time[1::2])\nd4 = ds_summer.sel(time=ds_summer.time[1::2])","05cb24a7":"\nTSS = ((ds[\"t2m\"]-ds[\"t2m\"].mean(\"time\"))**2).sum(\"time\")\nWSS = ((d1[\"t2m\"]-d1[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((d2[\"t2m\"]-d2[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((d3[\"t2m\"]-d3[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((d4[\"t2m\"]-d4[\"t2m\"].mean(\"time\"))**2).sum(\"time\") ","d8fab103":"(1 - WSS\/TSS).plot(vmin=0,vmax=1)","633cb6b5":"import datetime as dt \n\nd12h = ds.sel(time=dt.time(12))\nd00h = ds.sel(time=dt.time(0))\n# On calcul les anomalies (par rapport \u00e0 la moyenne du mois) pour chacun des deux horaires\nmensual_anomalie00H = d00h.groupby(\"time.month\") - d00h.groupby(\"time.month\").mean()\nmensual_anomalie12H = d12h.groupby(\"time.month\") - d12h.groupby(\"time.month\").mean()\n# On reregroupe tout \nds_ano = xr.merge([mensual_anomalie00H,mensual_anomalie12H])\n","ddcb5974":"ds_winter = ds_ano.isel(time=winter)\nds_summer = ds_ano.isel(time=summer)\nd1 = ds_winter.sel(time=dt.time(0))\nd2 = ds_summer.sel(time=dt.time(0))\nd3 = ds_winter.sel(time=dt.time(12))\nd4 = ds_summer.sel(time=dt.time(12))","b0994c1b":"\nTSS = ((ds_ano[\"t2m\"]-ds_ano[\"t2m\"].mean(\"time\"))**2).sum(\"time\")\nWSS = ((d1[\"t2m\"]-d1[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((d2[\"t2m\"]-d2[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((d3[\"t2m\"]-d3[\"t2m\"].mean(\"time\"))**2).sum(\"time\") + ((d4[\"t2m\"]-d4[\"t2m\"].mean(\"time\"))**2).sum(\"time\") ","65007e41":"(1 - WSS\/TSS).plot(vmin=0,vmax=1)","2d5665c6":"def compute_anomalie(ds):\n    \"\"\"\n    Retourne l'anomalie mensuelle (pour chaque heure) du dataset \n    \"\"\"\n    ano_list = []\n    for hour in ds.time.groupby(\"time.hour\").groups.keys(): \n        dtemp = ds.sel(time=dt.time(hour))\n        ano_list.append(dtemp.groupby(\"time.month\") - dtemp.groupby(\"time.month\").mean())\n    return xr.merge(ano_list)\n    \n\ndef explained_variance(cluster_list):\n    \"\"\"\n    Calcul a partir de la liste des cluster fournies (chaque cluster est un dataArray) la variance expliqu\u00e9e (pour chacune des variables)\n    \"\"\"\n    VIntra = xr.Dataset()\n    first = True\n    mean_cluster = []\n    nb_cluster = []\n    for cluster in cluster_list:\n        cluster_mean = cluster.mean(\"time\") \n        nb_cluster.append(cluster.time.size)\n        mean_cluster.append(cluster_mean)\n        if first:\n            VIntra = ((cluster - cluster_mean)**2).sum(\"time\")\n            first = False\n        else: \n            VIntra = VIntra + ((cluster - cluster_mean)**2).sum(\"time\")\n    Tmean = VIntra *0 \n    VInter = VIntra *0 \n    Total_elt = np.asarray(nb_cluster).sum()\n    for i, c_mean in enumerate(mean_cluster):\n        Tmean = Tmean + c_mean * nb_cluster[i] \/ Total_elt\n    print(Tmean)\n    for i,c_mean in enumerate(mean_cluster):\n        VInter = VInter + nb_cluster[i]*(c_mean - Tmean)**2\n    VTT = VInter + VIntra\n    print(VTT)\n    return 1 -  VIntra\/VTT\n    ","cedc8727":"# Calcul d'anomalie \nds_ano_b =  compute_anomalie(ds)\n# Select by cluster date \nds_winter = ds_ano_b.isel(time=winter)\nds_summer = ds_ano_b.isel(time=summer)\nd1 = ds_winter.sel(time=dt.time(0))\nd2 = ds_summer.sel(time=dt.time(0))\nd3 = ds_winter.sel(time=dt.time(12))\nd4 = ds_summer.sel(time=dt.time(12))\n# Compute explained variance by variable \ndout = explained_variance([d1,d2,d3,d4])","171de608":"import cartopy.crs as ccrs\nimport matplotlib.pyplot as plt \nvmax = 1\nplt.figure(figsize=(20,20))\nax1=plt.subplot(2, 2, 1,projection=ccrs.Orthographic(0, 35))\nax1.coastlines()\nax2=plt.subplot(2, 2, 2,projection=ccrs.Orthographic(0, 35))\nax2.coastlines()\nax3=plt.subplot(2, 2, 3,projection=ccrs.Orthographic(0, 35))\nax3.coastlines()\nax4=plt.subplot(2, 2, 4,projection=ccrs.Orthographic(0, 35))\nax4.coastlines()\nax1.gridlines()\ndout[\"t2m\"].plot(ax=ax1,transform=ccrs.PlateCarree(),robust=True,vmin=0,vmax=vmax)\ndout[\"tp\"].plot(ax=ax2,transform=ccrs.PlateCarree(),robust=True,vmin=0,vmax=vmax)\ndout[\"u10\"].plot(ax=ax3,transform=ccrs.PlateCarree(),robust=True,vmin=0,vmax=vmax)\ndout[\"v10\"].plot(ax=ax4,transform=ccrs.PlateCarree(),robust=True,vmin=0,vmax=vmax)","a7d4525a":"# Passons en anomalie (par rapport \u00e0 1979 mais on pourra faire plus large)\nOn va soustraire pour chaque champ : \n- la moyenne du mois pour le r\u00e9seau (0H\/1H)","2ccb54a5":"Avec le m\u00eame d\u00e9coupage on obtient bien une faible variance expliqu\u00e9e","bb60caad":"### Le but de ce notebook est de voir la variance expliqu\u00e9e par une certaines classification","bb37832d":"## Variance expliqu\u00e9e par midi\/minuit","f00376de":"On s'aper\u00e7oit qu'en coupant simplement l'ann\u00e9e en 2 et en s\u00e9parant par rapport \u00e0 l'heure de la journ\u00e9e, on arrive \u00e0 expliquer 60% de la variance de l'ann\u00e9e pour la temp\u00e9rature. \nDans la suite on va enlever cette variation saisonni\u00e8re qui nous int\u00e9resse peu ","ce583913":"# Faisons \u00e7a avec des fonctions pour automatiser l'ensemble ","faf6d2c2":"On s'aper\u00e7oit ainsi qu'une part importante de la variance est expliqu\u00e9e par le fait d'\u00eatre \u00e0 midi ou \u00e0 minuit pour la temp\u00e9rature (pas \u00e9tonnant)","765b4f77":"1. # Diff\u00e9rence \u00e9t\u00e9\/hiver"}}