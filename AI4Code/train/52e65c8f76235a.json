{"cell_type":{"36a9ded3":"code","57a4f55d":"code","d3152dbe":"code","8171c59c":"code","5f020cb6":"code","5a0af5fc":"code","f179154c":"code","e0edaef4":"code","658ef00c":"code","3948e75d":"code","9d9036f5":"code","5e3bcfc3":"code","0caf7d2a":"markdown","ea6733ae":"markdown","60eadecf":"markdown","27773e6f":"markdown","0f6adce0":"markdown","b0c5c696":"markdown","6f78e451":"markdown","f7919e4c":"markdown","68e9c4e8":"markdown","7a4e502e":"markdown","cfae01bf":"markdown","321dbf47":"markdown","7429ff48":"markdown","08b9c7e7":"markdown","1510daf8":"markdown","a7f85504":"markdown"},"source":{"36a9ded3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","57a4f55d":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn import ensemble, tree, linear_model, preprocessing\nimport missingno as msno\nimport pandas_profiling\nimport plotly.express as px","d3152dbe":"Original_Data= pd.read_csv('..\/input\/dataisbeautiful\/r_dataisbeautiful_posts.csv')","8171c59c":"Original_Data.head()","5f020cb6":"removed_thread = Original_Data[Original_Data['removed_by'].notna()]\noriginal_thread = Original_Data[(Original_Data['removed_by'].isna())]","5a0af5fc":"removed_thread.head()","f179154c":"removers=[]\n\nfor name in removed_thread['removed_by']:\n    if name not in removers:\n        removers.append(name)\n        \nprint(removers)","e0edaef4":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=50, figure_size=(15.0,15.0), \n                   title = None, title_size=20, image_color=False,color = 'black'):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(removed_thread['title'].values, title=\"Word Cloud of Removed Posts Titles.\")","658ef00c":"import plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndef count_ngrams(dataframe,column,begin_ngram,end_ngram):\n    # adapted from https:\/\/stackoverflow.com\/questions\/36572221\/how-to-find-ngram-frequency-of-a-column-in-a-pandas-dataframe\n    word_vectorizer = CountVectorizer(ngram_range=(begin_ngram,end_ngram), analyzer='word')\n    sparse_matrix = word_vectorizer.fit_transform(removed_thread['title'].dropna())\n    frequencies = sum(sparse_matrix).toarray()[0]\n    most_common = pd.DataFrame(frequencies, \n                               index=word_vectorizer.get_feature_names(), \n                               columns=['frequency']).sort_values('frequency',ascending=False)\n    most_common['ngram'] = most_common.index\n    most_common.reset_index()\n    return most_common\n\ndef word_cloud_function(df,column,number_of_words):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=number_of_words,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef word_bar_graph_function(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()\n    \nthree_gram = count_ngrams(removed_thread,'title',3,3)\nwords_to_exclude = [\"my\",\"to\",\"at\",\"for\",\"it\",\"the\",\"with\",\"from\",\"would\",\"there\",\"or\",\"if\",\"it\",\"but\",\"of\",\"in\",\"as\",\"and\",'NaN','dtype']","3948e75d":"plt.figure(figsize=(10,10))\nword_bar_graph_function(removed_thread,'title','Most common words in titles removed threads in Reddit')","9d9036f5":"bi_gram = count_ngrams(removed_thread,'title',2,2)\nfig = px.bar(bi_gram.sort_values('frequency',ascending=False)[0:10], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Most Common 2-Words in Titles of removed posts in Reddit',\n             orientation='h')\nfig.show()\n","5e3bcfc3":"fig = px.bar(three_gram.sort_values('frequency',ascending=False)[0:10], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Most Common 3-Words in Titles of removed posts in Reddit',\n             orientation='h')\nfig.show()\n","0caf7d2a":"<img src=\"https:\/\/cdn0.tnwcdn.com\/wp-content\/blogs.dir\/1\/files\/2019\/08\/reddit-deleted-posts-comments-threads.jpg\" alt=\"corona\" width=\"500\" align=\"middle\">","ea6733ae":"Reading the Data.","60eadecf":"Importing Libraries.","27773e6f":"Finding out who all can remove a post.","0f6adce0":"The notebook follows the following 3 stages of explanation:\n\n1. Introduction\n2. Analysis\n3. Insights and Conclusion\n","b0c5c696":"We could see words such as 'Click', 'Virus', 'Growing', 'Wuhan', are quite large and are grabbing our attention, which suggest us that there is a lot of mis-information or spaming which is taking place regarding the COVID-19 disease. Now to understand further we dig deep into n-gram analysis of the titles.","6f78e451":"After separating the removed posts alone a **WordCloud** is formed with the titles of the posts, this is done to get a glimpse of the titles in a graphical format.","f7919e4c":"Again the results of above graphs suggest us that the words such as 'covid-19', 'pandemics' are most frequent when it comes to titles of deleted posts.","68e9c4e8":"As expected, words such as '[OC]'(Original Content), 'coronavirus', 'world', 'covid-19', are leading the pack which again supports our hypotheis. And to understant it further lets do a **bi-gram** and **tri-gram** analysis.","7a4e502e":"# Introduction\n\nThis notebook tries to find out the common atributes between the removed posts of the 'Reddit - Data is Beautiful' community. This is a very primitive analysis which is being done using only the titles of the respective posts. Ofcourse, the title alone may not give the full desciption of its contents, but I believe that title will be a good yardstick for analyzing the contents.\n\n\n","cfae01bf":"# Conclusion\n\nSo from the above analysis of the given data we could easily conclude that most number of removed posts due to mis-information or spamming is about or relating to COVID-19 disease. As stated earlier this is a very primitive analysis, so stay tuned for a more detailed analysis which is to be done on the content of the posts and find more intresting insights.\n\nFinally I would like to mention and thank the following notebooks which I refered...\nhttps:\/\/www.kaggle.com\/ratan123\/cord-19-understanding-papers-with-textanalytics\nhttps:\/\/www.kaggle.com\/jpmiller\/creating-a-good-analytics-report\n\nThankyou for reading.","321dbf47":"## Why does a post get removed?\n\nBefore moving further this is a important question to answer as we are trying to analyze the reason for removed posts. For starters every reddit community has their own set of rules for posts, and for 'Data is Beautiful' community you can refer it in the below mentioned link.\nhttps:\/\/www.reddit.com\/r\/dataisbeautiful\/wiki\/index#wiki_rules\n\nSo, after reading it we can conclude that the reasons for removal of a post is, it is mis-marked as 'Original Content' or Spamming such as click baiting or ir-relevent information, etc.\n\n","7429ff48":"# Analysis","08b9c7e7":"Creating a new DataFrame with **Removed posts only** and **Retained posts only**.","1510daf8":"<img src=\"https:\/\/www.webintravel.com\/wp-content\/uploads\/2020\/02\/covid-19.jpg\" alt=\"corona\" width=\"900\" align=\"middle\">","a7f85504":"Finding out the most frequent word occured in the titles."}}