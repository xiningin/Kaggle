{"cell_type":{"af3eabcb":"code","22e1a859":"code","726c26e4":"code","9e095215":"code","5fb4eeda":"code","71ea71d2":"code","8bd5ad53":"code","d146ee69":"code","01d4a9ef":"code","8559b290":"markdown","7c58864e":"markdown"},"source":{"af3eabcb":"import pandas as pd\n\n# Data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Scalers\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n#Common Model Helpers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n","22e1a859":"def load_data():\n    train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n    test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n    return train,test","726c26e4":"def preprocessing(train,test):\n    \n    train_len = train.shape[0]\n    comb = train.append(test)\n    #comb.reset_index(inplace=True, drop=True)\n\n    title_dictionary = {'Capt': 'Dr\/Clergy\/Mil','Col': 'Dr\/Clergy\/Mil','Major': 'Dr\/Clergy\/Mil','Jonkheer': 'Honorific','Don': 'Honorific',\n                        'Dona': 'Honorific','Sir': 'Honorific','Dr': 'Dr\/Clergy\/Mil','Rev': 'Dr\/Clergy\/Mil','the Countess': 'Honorific',\n                        'Mme': 'Mrs','Mlle': 'Miss','Ms': 'Mrs','Mr': 'Mr','Mrs': 'Mrs','Miss': 'Miss','Master': 'Master','Lady': 'Honorific'\n    }\n    comb['Title'] = comb['Name'].map(\n        lambda name: name.split(',')[1].split('.')[0].strip())\n    comb['Title'] = comb.Title.map(title_dictionary)\n    keys = list(title_dictionary.keys())\n    title_dict = {keys[item]:item+1 for item in range(len(keys))}\n    comb['Title'] = comb.Title.map(title_dict)\n    comb['Title'] = comb['Title'].fillna(0)\n    train['Title'] = comb['Title'][:train_len]\n    test['Title'] = comb['Title'][train_len:]\n    \n    comb['Embarked'].fillna(comb['Embarked'].mode()[0], inplace=True)\n    embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    comb['Embarked'] = comb['Embarked'].map(embarked_mapping)\n    train['Embarked'] = comb['Embarked'][:train_len]\n    test['Embarked'] = comb['Embarked'][train_len:]\n    \n    sex_mapping = {\"male\": 0, \"female\": 1}\n    comb['Sex'] = comb['Sex'].map(sex_mapping)\n    train['Sex'] = comb['Sex'][:train_len]\n    test['Sex'] = comb['Sex'][train_len:]\n    \n    names = ['less2', '2-18', '18-35', '35-65', '65plus']\n    comb['Age'].fillna(comb['Age'].mean(), inplace=True)\n    comb['AgeBin'] = pd.qcut(comb['Age'],q = 5, labels = names)\n    age_dummies = pd.get_dummies(comb['AgeBin'], prefix='AgeBin')\n    comb = pd.concat([comb, age_dummies], axis=1)\n    comb['AgeBin'] = comb['AgeBin'].map({'less2':0, '2-18':1, '18-35':2, '35-65':3, '65plus':4})\n    train['AgeBin'] = comb['AgeBin'][:train_len]\n    test['AgeBin'] = comb['AgeBin'][train_len:]\n    \n    \n    comb['Fare'].fillna(comb['Fare'].mean(), inplace=True)\n    comb['FareBin'] = pd.qcut(comb['Fare'], 5)\n    label = LabelEncoder()\n    comb['FareBin_Code'] = label.fit_transform(comb['FareBin'])\n    train['FareBin_Code'] = comb['FareBin_Code'][:train_len]\n    test['FareBin_Code'] = comb['FareBin_Code'][train_len:]    \n\n    train.drop(['Cabin','Ticket','Age','Fare','Name'], inplace=True, axis=1)\n    test.drop(['Cabin','Ticket','Age','Fare','Name'], inplace=True, axis=1)\n        \n    print(train.isna().sum())\n    print(test.isna().sum())\n    return train,test","9e095215":"train,test = load_data()\ntrain,test = preprocessing(train,test)","5fb4eeda":"train.head()","71ea71d2":"test.head()","8bd5ad53":"\nxtrain = train.drop(['Survived', 'PassengerId'], axis=1)\nytrain = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size = 0.22, random_state = 0)","d146ee69":"model = DecisionTreeClassifier()\n# model = BaggingClassifier()\n# model = GradientBoostingClassifier()\n# model = AdaBoostClassifier()\n# model = KNeighborsClassifier()\n# model = MLPClassifier()\n# model = RandomForestClassifier()\n# model = ExtraTreesClassifier()\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_val)\nacc = round(metrics.accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc)","01d4a9ef":"ids = test['PassengerId']\ntest = test.drop(['PassengerId'], axis=1)\npred = model.predict(test)\nsubmission = pd.DataFrame({'PassengerId': ids,'Survived': pred})\nsubmission.to_csv(\"\/kaggle\/working\/submission.csv\",index=False)","8559b290":"* Drop Columns","7c58864e":"**Featurewise Filling Null Values**"}}