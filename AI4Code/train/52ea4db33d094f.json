{"cell_type":{"1a1d4ce9":"code","8d52a79f":"code","7d45f0e4":"code","b7d7fb3b":"code","4ae57439":"code","3481e0b6":"code","1a815e5a":"code","3c92506f":"code","06fb2b65":"code","193e7821":"code","9066181b":"code","7b13710e":"code","4972a728":"code","9f5e06c0":"code","9cc6a06a":"code","1ba95565":"code","85609e49":"code","45c5f05e":"code","73c1f8bd":"code","753bc5be":"code","5a56613a":"code","9823af95":"code","da84255e":"code","a4d432c9":"code","6777f292":"code","5403e71e":"markdown","23376305":"markdown","daf74d4a":"markdown","103826fc":"markdown","b767dc83":"markdown","11253ed6":"markdown","efd65931":"markdown","6bcabbaa":"markdown","d795e123":"markdown","70210b36":"markdown","cd78206a":"markdown","8d572462":"markdown","13613405":"markdown","f77821c4":"markdown","c7e4a057":"markdown","78fe7269":"markdown"},"source":{"1a1d4ce9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.graph_objs as go\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","8d52a79f":"data = pd.read_csv('..\/input\/youtube-new\/INvideos.csv')\ndata.head()","7d45f0e4":"print('Number of rows of in our dataset is {}'.format(data.shape[0]))\nprint('Number of columns of in our dataset is {}'.format(data.shape[1]))","b7d7fb3b":"# let's check the data type of all attributes present in our dataset\ndata.info()","4ae57439":"data['trending_date'] = pd.to_datetime(data['trending_date'], format='%y.%d.%m')\ndata['publish_time'] = pd.to_datetime(data['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\ndata[['trending_date','publish_time']].head()","3481e0b6":"# Separating columns for publish_date and publish_time\ndata['publish_date'] = data['publish_time'].dt.date\ndata['publish_time'] = data['publish_time'].dt.time\ndata[['trending_date','publish_date','publish_time']].head()","1a815e5a":"# We had seen that there are boolean columns too in our dataset so let's take a look on them.\nbool_cols=[]\nfor cols in data.columns:\n    if data[cols].dtype == 'bool':\n        bool_cols.append(cols)\nbool_cols    ","3c92506f":"for i in bool_cols:\n    print(data[i].value_counts())","06fb2b65":"print('The number of unique videos in our dataset is {}'.format(len(data['video_id'].unique()))) #prints no. of unique videos\nprint('The number of unique channels in our dataset is {}'.format(len(data['channel_title'].unique()))) #prints no. of unique channels\nprint('The number of unique category_id in our dataset is {}'.format(len(data['category_id'].unique()))) #prints no. of unique catgories","193e7821":"# Processing category_id column\nid_to_categ={}\nwith open('..\/input\/youtube-new\/IN_category_id.json', 'r') as f:\n    categ_data = json.load(f)\n    for category in categ_data['items']:\n        id_to_categ[category['id']] = category['snippet']['title']","9066181b":"#data['category_id'].astype(str)\ndata['category'] = data['category_id'].map(id_to_categ)\ndata[['category_id','category']].head()","7b13710e":"# Now,we will keep those columns on which we will do statistical analysis\ndf = data[['title','category','views','likes','dislikes','comment_count']]\ndf.head()","4972a728":"# Plotting a pie chart with plotly\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected = True)\n\ncateg_counts = pd.DataFrame(df['category'].value_counts())\ngroups = categ_counts.index\nvalues = categ_counts['category']\ntrace = go.Pie(labels=groups, values=values,\n              hoverinfo='label+percent', textinfo='value')\n#Plot\niplot([trace])","9f5e06c0":"# Now, let's take a look at the distributions of all numerical attributes\nnum_cols = ['views','likes','dislikes','comment_count']\nfor i in num_cols:\n    plt.figure()\n    sns.distplot(np.log(df[i]+1))\n    plt.show()","9cc6a06a":"for i in num_cols:\n    sns.barplot(df[i], df['category'])\n    plt.show()","1ba95565":"import plotly.express as px\n\n\nfig = px.box(df, x=\"category\", y=\"views\")\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","85609e49":"fig = px.box(df, x=\"category\", y=\"likes\")\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","45c5f05e":"fig = px.box(df, x=\"category\", y=\"dislikes\")\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","73c1f8bd":"fig = px.box(df, x=\"category\", y=\"comment_count\")\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","753bc5be":"# Let's find out which is the most viewed,liked,disliked and commented video in trending list\nprint('Most viewed videos is {}'.format(df.loc[df[['views']].idxmax()]['title']))\nprint('Most liked videos is {}'.format(df.loc[df[['likes']].idxmax()]['title']))\nprint('Most disliked videos is {}'.format(df.loc[df[['dislikes']].idxmax()]['title']))\nprint('Most commented videos is {}'.format(df.loc[df[['comment_count']].idxmax()]['title']))","5a56613a":"df['like_dislike_ratio'] = df['likes'] \/ df['dislikes']\ndf.head()","9823af95":"# Now,deleting all the duplicates videos from our dataset as we had seen that there were videos trending across multiple days\nprint('Shape of our dataset with duplicated videos is {}'.format(data.shape))\nmy_df = data[~data.video_id.duplicated(keep='last')]\nprint('Shape of our dataset after deleting duplicated videos is {}'.format(my_df.shape))\nmy_df.index.duplicated().any()","da84255e":"# Plotting the statistics for top10 most viewed videos\nmost_viewed = my_df.sort_values(by='views', ascending=False).head(10)\nTitle = most_viewed['title']\n\ntrace1 = go.Bar(x=Title,\n                y=most_viewed['likes'],\n                name='No.Of Likes')\ntrace2 = go.Bar(x=Title,\n                y=most_viewed['dislikes'],\n                name='No.Of Dislikes')\ntrace3 = go.Bar(x=Title,\n                y=most_viewed['comment_count'],\n                name='No.Of Comment')\ndata = [trace1, trace2, trace3]\nlayout = go.Layout(barmode='group')\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","a4d432c9":"corr_mat = df.corr()\nsns.heatmap(corr_mat, annot=True, linewidths=0.5, fmt='.2f', cmap='YlGnBu')\nplt.show()","6777f292":"# Let's plot a scatter plot to visualize relationship between Views and Likes.\nplt.figure(figsize=(20,10))\nplt.scatter(df['views'], df['likes'], c=df['like_dislike_ratio'], cmap='summer', edgecolor='black',\n           linewidth=1, alpha=0.4)\ncbar = plt.colorbar()\ncbar.set_label('Like-dislike Ratio')\nplt.xscale('log')\nplt.yscale('log')\nplt.tight_layout()\nplt.title('Views vs Likes of trending videos')\nplt.xlabel('No Of views')\nplt.ylabel('No of likes')\nplt.grid()\nplt.show()","5403e71e":"## Box Plots With Plotly","23376305":"### Now,we can see that our date&time columns are in proper format, we will use them later when we will perform statistical analysis over time.","daf74d4a":"### Processing the dates ( By looking at the trending_date and publish_time columns, we found that these columns are not in the correct datetime format)","103826fc":"### Most Disliked Video is also from entertainment category","b767dc83":"## Takeaway Points\n#### 1. Gaming videos are the most  viewed videos among trending videos.\n#### 2. Education videos are most less viewed videos among all trending videos.\n#### 3. Pets&Animals videos are most liked videos among all trending videos.\n#### 4. Gaming videos are most disliked videos among all trending videos.\n#### 5. Science&Tech videos are most commented videos among all trending videos.\n#### 6. Travel&Events videos are most less commented videos among all trending videos.","11253ed6":"### Takeaway Points:\n### 1. As expected, most liked video is also from entertainment category and  chances are high that it's the same video having highest no. of views.","efd65931":"### From this pie-chart,we can see that around 50% of videos are from Entertainment category so it can be concluded that if any video belongs to entertainment category,there are more chances to go it in trending list.","6bcabbaa":"### 1. A number of videos appear multiple times in our dataset, as they were trending across multiple days. \n### 2. There are some channels whose videos were in trending more than one day.\n### 3. We are dealing with 17 types of  video categories in our dataset,let's take a closer look at them.","d795e123":"### Takeaway Points:\n### 1. There are a lot of outliers present in the Entertainment category, also most viewed video is from Entertainment category.\n### 2. Most viewed video is from entertainment category having 125 million views","70210b36":"## Here, we have retrieved categories for each category_id from json file.","cd78206a":"### 1.From above plot, it can be inferred that as views on a video increases, no of likes also increases linearly.\n### 2.The colorbar indicates the intensity of like-dislike ratio more bluish the color,more liked the video is.\n### 3.As all these are trending videos,they have generally very high no of likes as comapred to dislikes.","8d572462":"### We can see that we have very less number of True values in our bool type columns so it will good to remove these columns while modelling our dataset because these columns shows no variance and adds no information in predicting number of likes(also,it can be found that these variables  highly correlated with each other and this gives one more point why we should drop them)","13613405":"### By above plots, it can be inferred that all numerical atrributes have a log-normal distribution","f77821c4":"### 1.Most commented video is also from the entertainment category and chances are very high that one particular video have highest no of views,likes,dislikes and comments.\n### 2. Hence, it can be inferred that if a video have very high views, there are more chances that it could be most liked,disliked and commented video","c7e4a057":"### From above plot, we can see a very strong positive correlation between views vs likes and comment_count vs likes.","78fe7269":"**Now,we can clearly see that there was a particular video having highest no of views,likes,dislikesand comments.**"}}