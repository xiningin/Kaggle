{"cell_type":{"0779b61b":"code","1b40be1f":"code","014307b4":"code","870ecc90":"code","f373a096":"code","ecb5bc4e":"code","c3606db8":"code","e15d5d1e":"code","0de757b3":"code","884ee003":"code","d7421e71":"code","e900e8b3":"code","3abd32bc":"code","ea7e029a":"code","763af46e":"code","11931cec":"code","813b4ca9":"code","cd69248b":"code","f079e646":"code","0d99c541":"code","5cfa662e":"code","63c09292":"code","2b21dbf4":"code","1368fdf3":"code","203aa35d":"code","9c24a05c":"code","d7306254":"code","88ed816b":"code","11bfd3c8":"code","8226758f":"code","43310998":"code","0a3b3807":"code","ce23b536":"code","17dd3f25":"markdown","36fa5dd8":"markdown","f8f95e49":"markdown","1e9f3c2a":"markdown","2ec268a3":"markdown","f3bc4c99":"markdown","43c99697":"markdown","a96d400d":"markdown","ca13138d":"markdown","d27b9cd7":"markdown","746ff88c":"markdown","847a00d5":"markdown","b22d2a89":"markdown","99aab1e6":"markdown","7b91101b":"markdown","ebb85d23":"markdown","5941c303":"markdown","ead7f01c":"markdown","f5322f08":"markdown","cf73770b":"markdown","c75388ee":"markdown","e4da4d70":"markdown","5e0fd632":"markdown","4ba93bc9":"markdown"},"source":{"0779b61b":"import numpy as np\nfrom keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\nfrom keras.preprocessing import image","1b40be1f":"# The last layer of predictions (Dense) has 1,000 values. \n# This means that VGG16 has a total of 1,000 labels and our image \n# will be one out of those 1,000 labels.\nclassifier = VGG16()","014307b4":"# VGG16 only accepts (224,224)\nnew_image = image.load_img('..\/input\/prediction\/Prediction\/pizza.jpg',\n                          target_size=(244, 244))\n\nnew_image","870ecc90":"# Resize\nnew_image = image.img_to_array(new_image) # (244, 244, 3)\nnew_image = np.expand_dims(new_image, axis=0) # (1, 244, 244, 3)","f373a096":"## Preprocess\nnew_image = preprocess_input(new_image)\nnew_image","ecb5bc4e":"pred = classifier.predict(new_image)\npred.shape","c3606db8":"# Decode predictions\ndecode_predictions(pred, top=5)","e15d5d1e":"label = decode_predictions(pred)\n\ndecoded_label = label[0][0]\n\nprint('%s (%.2f%%)' % (decoded_label[1], decoded_label[2] * 100))","0de757b3":"new_image = image.load_img('..\/input\/prediction\/Prediction\/test_image_1.jpg',\n                          target_size=(244, 244))\n\nnew_image","884ee003":"new_image = image.img_to_array(new_image)\nnew_image = np.expand_dims(new_image, axis=0)\n\nnew_image = preprocess_input(new_image)\nnew_image","d7421e71":"pred = classifier.predict(new_image)\n\ndecode_predictions(pred, top=5)","e900e8b3":"label = decode_predictions(pred)\n\ndecoded_label = label[0][0]\n\nprint('%s (%.2f%%)' % (decoded_label[1], decoded_label[2] * 100))","3abd32bc":"classifier = VGG16()\nclassifier.summary()","ea7e029a":"new_image = image.load_img('..\/input\/prediction\/Prediction\/stick_insect.jpg',\n                          target_size=(244, 244))\n\nnew_image","763af46e":"new_image = image.img_to_array(new_image)\nnew_image = np.expand_dims(new_image, axis=0)\nnew_image.shape","11931cec":"new_image = preprocess_input(new_image)","813b4ca9":"pred = classifier.predict(new_image)\npred.shape","cd69248b":"decode_predictions(pred, top=5)","f079e646":"label = decode_predictions(pred)\n\ndecoded_label = label[0][0]\n\nprint('%s (%.2f%%)' % (decoded_label[1], decoded_label[2] * 100))","0d99c541":"import numpy as np\nimport keras\n\nfrom keras.layers import Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import random","5cfa662e":"vgg_model = VGG16()\nvgg_model.summary()","63c09292":"np.random.seed(1)\nrandom.set_seed(1)","2b21dbf4":"# last layer in VGG model\nlast_layer = str(vgg_model.layers[-1])\n\n# new classifier model\nclassifier = keras.Sequential()\n\n\n#  Add all layers to the new model, except for the last layer\nfor layer in vgg_model.layers:\n    if str(layer) != last_layer:\n        classifier.add(layer)\n        \n        \nclassifier.summary()","1368fdf3":"for layer in classifier.layers:\n    layer.trainable = False","203aa35d":"classifier.add(Dense(1, activation='sigmoid', name='predictions'))\nclassifier.summary()","9c24a05c":"classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","d7306254":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","88ed816b":"training_dataset = train_datagen.flow_from_directory('..\/input\/cars-vs-flowers\/dataset\/cars_vs_flowers\/training_set',\n                                                    target_size=(244, 244),\n                                                    batch_size=32,\n                                                    class_mode='binary')\n\ntest_dataset = test_datagen.flow_from_directory('..\/input\/cars-vs-flowers\/dataset\/cars_vs_flowers\/test_set',\n                                                    target_size=(244, 244),\n                                                    batch_size=32,\n                                                    class_mode='binary')","11bfd3c8":"classifier.fit(training_dataset,\n              epochs = 5,\n              steps_per_epoch = 2000 \/\/ 32,\n              validation_data = test_dataset,\n              validation_steps = 2000 \/\/ 32,\n              shuffle=False)","8226758f":"new_image = image.load_img('..\/input\/cars-vs-flowers\/car_test_image.jpg', target_size=(244, 244))\nnew_image","43310998":"new_image = image.img_to_array(new_image)\nnew_image = np.expand_dims(new_image, axis=0)","0a3b3807":"result = classifier.predict(new_image)\n\nif result[0][0] == 1:\n    print('Flower')\n    \nelse:\n    print('Car')","ce23b536":"classifier.save('car-flower-classifier.h5')","17dd3f25":"### Fit","36fa5dd8":"### Model","f8f95e49":"## Image 1","1e9f3c2a":"### Predict","2ec268a3":"### Predict the new image","f3bc4c99":"### Libraries","43c99697":"# Classifying images that are present in the ImageNet database","a96d400d":"### Compile the model","ca13138d":"### Final result","d27b9cd7":"### Reshape","746ff88c":"## Libraries","847a00d5":"## Prediction","b22d2a89":"# Fine-Tuning the VGG16 Model","99aab1e6":"### Image","7b91101b":"### Freeze the layers","ebb85d23":"### Save classifier","5941c303":"## Final result","ead7f01c":"### Add new output layer","f5322f08":"### Data generators","cf73770b":"# Classifying images that are present in the ImageNet database","c75388ee":"This is a simple notebook that demonstrates the use of [VGG16](https:\/\/neurohive.io\/en\/popular-networks\/vgg16\/) for image classification.","e4da4d70":"## Model","5e0fd632":"## Image 2","4ba93bc9":"### Remove the last layer"}}