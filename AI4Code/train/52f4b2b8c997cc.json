{"cell_type":{"b5eb7e9f":"code","5c8fa6ea":"code","d44fbf40":"code","581cb130":"code","83062d41":"code","bf3e9e8d":"code","d0f1ec22":"code","2a2cd2a6":"code","5fd8c095":"code","c10e0d6e":"code","eeb06af7":"code","2c773d0b":"code","f42dbc3b":"code","767e3751":"code","15ec05d5":"code","ab789d30":"code","2ea4830f":"code","da69a813":"code","9f2598d6":"code","870d7d1e":"code","0e2c6225":"markdown","0508261b":"markdown","920ce0a2":"markdown","37fd96d3":"markdown","8ede25dc":"markdown","1442141d":"markdown","544ec515":"markdown","3de3fdf7":"markdown","c7461ec4":"markdown","db1d489a":"markdown","8bec9439":"markdown","8cf422b2":"markdown","1b2b81c9":"markdown","baead6c5":"markdown","680b7c64":"markdown","4b94491c":"markdown","585b6338":"markdown","2abf3749":"markdown","d38cfbb5":"markdown"},"source":{"b5eb7e9f":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport random as rn\nfrom glob import glob\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n# Path variables\nBASE_PATH = \"..\/input\/petfinder-pawpularity-score\/\"\nTRAIN_PATH = BASE_PATH + \"train.csv\"\nTEST_PATH = BASE_PATH + \"test.csv\"\nTRAIN_IMAGES = glob(BASE_PATH + \"train\/*.jpg\")\nTEST_IMAGES = glob(BASE_PATH + \"test\/*.jpg\")\n\n# We are trying to predict this \"Pawpularity\" variable\nTARGET = \"Pawpularity\"\n\n# Seed for reproducability\nseed = 1234\nrn.seed(seed)\nnp.random.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)","5c8fa6ea":"df = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\n# All relevant tabular futures\nFEATURES = [col for col in df.columns if col not in ['Id', TARGET]]","d44fbf40":"from sklearn.metrics import mean_squared_error\n\ndef rmse(y_true, y_pred):\n    \"\"\"Numpy RMSE\"\"\"\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\ndef rmse_pytorch(outputs, labels):\n    \"Pytorch RMSE loss\"\n    return torch.sqrt(torch.mean((outputs - labels)**2))\n\ndef rmse_tf(y_true, y_pred):\n    \"\"\"Tensorflow RMSE loss\"\"\"\n    return tf.sqrt(tf.reduce_mean(tf.squared_difference(y_true, y_pred)))","581cb130":"print(df.shape)\ndf.head()","83062d41":"df[TARGET].plot(kind='hist', bins=100, figsize=(15, 6));\nplt.title(\"Target distribution\", weight='bold', fontsize=16);","bf3e9e8d":"corr_matrix = df[FEATURES + [TARGET]].corr()\ncorr_matrix","d0f1ec22":"target_corr = corr_matrix[TARGET][:-1]\ntarget_corr","2a2cd2a6":"path = np.random.choice(TRAIN_IMAGES)\nim = plt.imread(path)\nplt.figure(figsize=(15, 6))\nplt.imshow(im)\nplt.title(path.split(\"\/\")[-1])\nplt.xticks([]), plt.yticks([])\nprint(f\"Accompanying features:\")\ndf[df['Id']==path.split('\/')[-1].split('.')[0]]","5fd8c095":"most_pawpular = df[df[TARGET] == df[TARGET].max()].iloc[0]\npath = f\"{BASE_PATH}train\/{most_pawpular['Id']}.jpg\"\nim = plt.imread(path)\nplt.figure(figsize=(15, 6))\nplt.imshow(im)\nplt.title(path.split(\"\/\")[-1])\nplt.xticks([]), plt.yticks([])\nprint(f\"Accompanying features:\")\ndf[df['Id']==path.split('\/')[-1].split('.')[0]]","c10e0d6e":"least_pawpular = df[df[TARGET] == df[TARGET].min()].iloc[0]\npath = f\"{BASE_PATH}train\/{least_pawpular['Id']}.jpg\"\nim = plt.imread(path)\nplt.figure(figsize=(15, 6))\nplt.imshow(im)\nplt.title(path.split(\"\/\")[-1])\nplt.xticks([]), plt.yticks([])\nprint(f\"Accompanying features:\")\ndf[df['Id']==path.split('\/')[-1].split('.')[0]]","eeb06af7":"df['mean_pred'] = df[TARGET].mean()","2c773d0b":"print(f\"Mean prediction is: {df['mean_pred'].iloc[0].round(2)}\")\nprint(f\"Using this naive baseline train RMSE is: {rmse(df[TARGET], df['mean_pred']).round(2)}\")","f42dbc3b":"from sklearn.tree import DecisionTreeRegressor, export_text, plot_tree\n\nX_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.2, random_state=seed)\nreg = DecisionTreeRegressor(random_state=seed, max_depth=3)\nreg.fit(X_train, y_train)","767e3751":"print(f\"Train RMSE: {rmse(y_train, reg.predict(X_train)).round(4)}\")\nprint(f\"Test RMSE: {rmse(y_test, reg.predict(X_test)).round(4)}\")","15ec05d5":"# Create PNG file\ntext_representation = export_text(reg)\nwith open(\"tree.log\", \"w\") as f:\n    f.write(text_representation)\n\nfig = plt.figure(figsize=(25, 10))\n_ = plot_tree(reg, \n              feature_names=FEATURES,\n              class_names=TARGET,\n              filled=True)","ab789d30":"# Train final model on all training data\nreg.fit(df[FEATURES], df[TARGET])","2ea4830f":"test.head(2)","da69a813":"test[TARGET] = reg.predict(test[FEATURES])\nsub = test[['Id', TARGET]]\nsub.to_csv(\"submission.csv\", index=False)","9f2598d6":"sub.head(2)","870d7d1e":"sub[TARGET].plot(kind='hist', bins=15, title='Prediction distribution');","0e2c6225":"## EDA","0508261b":"Our model predicts mostly around the mean of all labels.","920ce0a2":"Some features seem to be substantially correlated to each other. For example, \"Human\" and \"Occlusion\".","37fd96d3":"The tree we have trained almost always predicts values close around the mean. There is an exception where Blur=1, Action=1 and Face=0.","8ede25dc":"## Submission","1442141d":"Scoring metric is Root Mean Squared Error (RMSE). \n\nFormally defined as:\n\n\n$$\\sqrt{\\Sigma_{i=1}^{n}{\\Big(\\frac{\\hat{y}_i - y_i}{n}\\Big)^2}}$$\n\nwhere $n$ denotes the number of samples, $y_i$ the ground truth value and $\\hat{y}_i$ the prediction value.","544ec515":"## Metrics and loss (RMSE)","3de3fdf7":"However, the features have a low correlation to the target variable. Linear models trained on these features are therefore likely to perform poorly.","c7461ec4":"### Least Pawpular example (1)","db1d489a":"Of all the tabular features, \"Blur\" seems to be the most predictive for the target.","8bec9439":"## Naive Baseline (Mean of target): ","8cf422b2":"## Image sample","1b2b81c9":"## Visualize decision tree","baead6c5":"Our baseline model will be a decision tree with a depth of 3. In this way we can easily visualize the tree and get insight in the most important feature rules. Unfortunately, the binary features do not seem to yield important rules for predicting Pawpularity. It seems that the image data will yield the most important features to predict Pawpularity in this competition.","680b7c64":"![https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score](https:\/\/blog.groomit.me\/wp-content\/uploads\/2018\/02\/petfinder2.jpg)\n\nThis notebook is a quick exploration of the new [Petfinder 2021 competition](https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score) and yields some insight into how important the tabular features will be in this competition!","4b94491c":"The features given in the CSV are additional binary descriptive features. \n\nOur target is the \"Pawpularity\" score which ranges between 1 and 100.","585b6338":"### Most Pawpular example (100)","2abf3749":"That's it! I hope this notebook helped you to get started for the Petfinder 2021 competition!\n\nIf you have any questions or feedback, feel free to comment below. You can also contact me on Twitter [@carlolepelaars](https:\/\/twitter.com\/carlolepelaars).","d38cfbb5":"## Baseline (Decision Tree Regressor):"}}