{"cell_type":{"6ea271c9":"code","fe81bbd5":"code","601cb856":"code","246883d8":"code","5c055b92":"code","402747b4":"code","74efeacb":"code","63c53bff":"code","259fa359":"code","52aae8cb":"code","ed85915a":"markdown","332bbd91":"markdown","98e8c033":"markdown"},"source":{"6ea271c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe81bbd5":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns","601cb856":"train = pd.read_csv('\/kaggle\/input\/bikesharing-for-education\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/bikesharing-for-education\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/bikesharing-for-education\/sample_submission.csv')","246883d8":"#\u5fc5\u8981\u306a\u5217\u3060\u3051\u6b8b\u3059\nX = train.drop(['datetime','casual','registered','cnt'],axis = 1)\nX_test = test.drop(['datetime'],axis = 1)\ny = train[['year','cnt']]","5c055b92":"%%time\n\ncolumns = X.columns\n\ny_preds = np.zeros(X_test.shape[0])\n\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = columns\n\n# 2011\u5e74\u3092\u5b66\u7fd2\u30012012\u5e74\u3092\u691c\u8a3c\u30c7\u30fc\u30bf\u306b\nX_train = X.query(\"year == 2011\")\nX_valid = X.query(\"year == 2012\")\n\ny_train = y.query(\"year == 2011\")\ny_valid = y.query(\"year == 2012\")\n\ny_train.drop('year',axis=1, inplace=True)\ny_valid.drop('year',axis=1, inplace=True)\n\n\ndtrain = lgb.Dataset(X_train, label=y_train)\n\nparams = {\n    'objective': 'mean_squared_error',\n    'metric': 'rmse'\n}\nLGBM = lgb.train(params, dtrain, 1000, verbose_eval=100)\n\nfeature_importances['importance'] = LGBM.feature_importance(importance_type='gain')\n\ny_pred_valid = LGBM.predict(X_valid)\n\ny_pred_valid = np.where(y_pred_valid < 0, 0, y_pred_valid)\n\nprint(\"RMSLE:\", mean_squared_log_error(y_valid, y_pred_valid))\nprint('******************************************************')\n\ny_preds = LGBM.predict(X_test)\ny_preds = np.where(y_preds < 0, 0, y_preds)","402747b4":"plt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importances.sort_values('importance', ascending=False).head(50), x='importance', y='feature');\nplt.title('50 TOP feature importance')","74efeacb":"submission = pd.concat([test['datetime'], pd.Series(y_preds)], axis=1) \nsubmission = submission.rename(columns={0:'cnt'})","63c53bff":"submission.shape","259fa359":"submission.head()","52aae8cb":"submission.to_csv('base_submission.csv',header=True, index=False)","ed85915a":"# \u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210","332bbd91":"# \u5b66\u7fd2\u30fb\u4e88\u6e2c","98e8c033":"# \u91cd\u8981\u5ea6\u306e\u53ef\u8996\u5316"}}