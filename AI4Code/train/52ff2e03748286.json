{"cell_type":{"d61b8ea7":"code","710bf081":"code","14f90cd6":"code","4bc0397c":"code","cec5d662":"code","0ee277be":"code","d335712a":"code","c19cab93":"code","ac719cc3":"code","6a97d124":"code","a2fa1c2f":"code","42ee1f6e":"code","26541cf2":"code","9ef721d6":"code","d76988c5":"code","0c2b18d2":"code","c64be0cf":"code","e09ae7c7":"code","e417488a":"code","e041aa3e":"code","976d7d06":"code","6a55379a":"code","8ad881ef":"code","14c32dac":"code","1aab6f29":"code","9b48228d":"code","705f5a02":"code","369ec49e":"code","cf6ffd93":"code","7b25d69b":"code","b31cea11":"code","740450c4":"markdown","f250eabc":"markdown","d1de148e":"markdown","d69227bc":"markdown","459d4c41":"markdown","77ba1a5c":"markdown","053ea944":"markdown","2d84bea4":"markdown","29209b8d":"markdown","900347b2":"markdown","0d1ebe27":"markdown","d29b774b":"markdown","fe0529b2":"markdown","7c9c1943":"markdown","0d019384":"markdown","0d25f57b":"markdown","d3336a5f":"markdown","abff96cf":"markdown","ab1e2599":"markdown","4345f26d":"markdown","0b06723d":"markdown","e5869487":"markdown","d55f6152":"markdown","732b019b":"markdown","37922982":"markdown","e352be74":"markdown","5953d8c0":"markdown","a6aa4055":"markdown","9811f9e6":"markdown","553e26fe":"markdown"},"source":{"d61b8ea7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n\nimport os\nimport glob\nimport cv2\nimport matplotlib.pylab as plt\n!pip install tensorflow-addons\nfrom tensorflow_addons.metrics import F1Score \nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n\nfrom keras.callbacks import EarlyStopping","710bf081":"# se lee en kaggle el directorio con los datos\nos.chdir(\"..\/input\/kaggle-plant-pathology-2021-modificat\/train\")\nlista_directorios=os.listdir()\nprint(\"Hay \", len(lista_directorios), \"directorios.\")\nlista_directorios.sort()\nnum_imagenes = list()\ntodas_imagenes = list()\n# se recorren todos los directorios en orden, \nfor directorio in lista_directorios: \n    os.chdir(directorio)\n    imagenes = glob.glob('*.jpg')\n    # para cada directoriose almacena el n\u00famero de imagenes y las 5 primeras imagenes\n    # en los siguientes bloques se usan estas listas\n    num_imagenes.append(len(imagenes))\n    todas_imagenes.append(imagenes[0:5])\n    os.chdir('..')","14f90cd6":"import seaborn as sn\n#obtengo el porcentaje\nporcentaje_imagenes = list()\nfor i in range(0,len(num_imagenes)):\n    porcentaje_imagenes.append(round((num_imagenes[i]\/ sum(num_imagenes))*100,2))\n    \n# creo la figura\nplt.figure(figsize=(14,8))\nbarras = sn.barplot(y = num_imagenes, x = lista_directorios)\nbarras.set(title='N\u00famero de imagenes de cada clase')\ni = 0\n# A\u00f1ado la anotaci\u00f3n sobre cada barra\nfor p in barras.patches:\n    texto = str(int(p.get_height())) + \" | \" + str(porcentaje_imagenes[i]) + \"%\"\n    i +=1\n    barras.annotate(texto, (p.get_x()+0.4, p.get_height() ),\n                    ha='center', va='bottom',\n                    color= 'black')","4bc0397c":"# genero los pesos por clase\npesos = dict()\ni = 0\nfor valor in porcentaje_imagenes: \n    pesos[i]=round(max(porcentaje_imagenes)\/valor,2)\n    i +=1\npesos","cec5d662":"fig, axs = plt.subplots(6, 5, figsize=(30,30))\nfor i in range(0,len(num_imagenes)):\n    os.chdir(lista_directorios[i])\n    j = 0\n    # para cada imagen de cada lista de 5 im\u00e1genes... \n    for imagen in todas_imagenes[i]:\n        # se lee la imagen\n        imagen_bien=cv2.imread(imagen)\n        # se cambia el orden de canales a rgb \n        imagen_bien = cv2.cvtColor(imagen_bien, cv2.COLOR_BGR2RGB)\n        # se muestra la imagen con su clase\n        axs[i, j].imshow(imagen_bien)\n        axs[i, j].set_title(lista_directorios[i])\n        j += 1\n    os.chdir('..')\n\n","0ee277be":"print(\"El rango de la \u00faltima imagen mostrada es: \", np.max(imagen_bien)- np.min(imagen_bien))\nprint(\"Las dimensiones de la imagen son:\", imagen_bien.shape[0], \"x\", imagen_bien.shape[1], \"con\", imagen_bien.shape[2], \"canales de color.\")","d335712a":"os.chdir(\"..\")","c19cab93":"from keras.preprocessing.image import ImageDataGenerator \n\n# se definen el dataset de entrenamiento y el de test, ambos vienen del mismo directorio\ntraining = tf.keras.preprocessing.image_dataset_from_directory(\n  'train\/',\n  # el 20% ser\u00e1 para el validation\n  validation_split=0.2,\n  subset=\"training\",\n  label_mode='categorical',\n  # ambos tienen la misma seed para que no hayan las mismas im\u00e1genes en ambos conjuntos\n  seed=123,\n  image_size=(224, 224),\n  batch_size=32)\nvalidation = tf.keras.preprocessing.image_dataset_from_directory(\n  'train\/',\n  validation_split=0.2,\n  subset=\"validation\",\n  label_mode='categorical',\n  seed=123,\n  image_size=(224, 224),\n  batch_size=32)","ac719cc3":"contador = 0\n# se recorren todas las im\u00e1genes en validaci\u00f3n y en training\nfor imagen in validation.file_paths:\n    if imagen in training.file_paths:\n        contador+=1\nprint(contador)","6a97d124":"# guardo los nombres de las etiquetas para poder usarlos en el futuro\nnombres_labels = training.class_names","a2fa1c2f":"def view_image(ds):\n    image, label = next(iter(ds)) # extrae 1 batch del dataset\n    image= tf.cast(image, tf.float32) # las imagenes se pasa de formato para visualizarla\n    image = image.numpy()\n    label = label.numpy()\n\n    fig = plt.figure(figsize=(22, 22))\n    # para las 16 primeras del batch se muestra la imagen y la label. \n    for i in range(16):\n        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n        # divido entre 255 \n        ax.imshow(image[i]\/255)\n        ax.set_title(f\"Label: {nombres_labels[np.argmax(label[i])]}\")\n    \nview_image(training)","42ee1f6e":"from functools import partial\nimport albumentations as A\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# esta funci\u00f3n aplica las transformaciones de albumentations, para cada imagen del batch. \ndef transform_alb(image):\n    aug = A.Compose([\n        A.ToFloat(255), # convierte a rango 1 para que se apliquen las funciones bien \n        A.RandomBrightnessContrast(p=1,brightness_limit=0.5, contrast_limit=0.1), # a\u00f1ade brillo y contraste\n        A.HorizontalFlip(p=0.5), # gira la imagen horizontalmente \n        A.ShiftScaleRotate (p=0.9, shift_limit=0.25, rotate_limit = 30, scale_limit = 0.3, border_mode=1), # mueve, rota y escala la imagen \n        A.OneOf([ # aplica una de las siguientes transformacione\n            A.RandomSnow(p = 1), # nieve\n            A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=2, p=1), # lluvia\n            A.RandomShadow(p=1), # sombra\n            A.RandomSunFlare(src_radius=40, p=1), # marcas de sol\n            A.RandomFog(alpha_coef=0.3, p=1) # niebla\n        ], p=0.2),  \n        A.ToFloat(1\/255) # vuelve al rango 255\n    ])\n    transformadas = []\n    # recorre el batch\n    for im in image: \n        transformadas.append(aug(image=im)['image'])\n    mio = np.asarray(transformadas)\n    return mio\n\n# aplica la funci\u00f3n de transformaci\u00f3n al batch\ndef process_data(image, label):\n    aug_img = tf.numpy_function(func=transform_alb, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((None,224,224,3))\n    return aug_img, label\n\n\n# reduce los datos a que ocupen menos espacio en memoria\ndef reduce_size(image, label):\n    image= tf.cast(image, tf.float16)\n    label = tf.cast(label, tf.int8)\n    return image, label\n\n# el dataset de entreno se reducen sus datos, se cachean estas im\u00e1genes para tardar menos en el desarrollo del modelo\n# y despu\u00e9s se aplican las transformaciones de albumentations\ntraining_alb = training.map(partial(reduce_size), num_parallel_calls=AUTOTUNE).cache().map(partial(process_data),num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n# el dataset de validaci\u00f3n simplemente se pone en cache para que se acceda a el antes. \nvalidation = validation.cache().prefetch(buffer_size=AUTOTUNE)\n\nprint(training_alb)\n \n# se visualizan las imagenes transformadas    \nview_image(training_alb)","26541cf2":"from tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\n\n# genero una capa de entrada de los datos en el formato \ninputs = layers.Input(shape=(224, 224, 3))\n\n# otros pesos\n# path_to_weights = \"..\/efficientnet-keras-noisystudent-weights-b0b7\/efficientnet-b4_noisy-student_notop.h5\"\n# model = EfficientNetB4(include_top=False,input_tensor = inputs)\n# model.load_weights(path_to_weights, by_name=True)\n\n# # resnet como base\n# model = tf.keras.applications.ResNet101(\n#     include_top=False,\n#     weights=\"imagenet\",\n#     input_tensor = inputs)\n\n\n# imagenet pesos\nmodel = EfficientNetB4(include_top=False,input_tensor = inputs, weights='imagenet')\n\n# Se congelan las capas ya entrenadas\nmodel.trainable = False\n\n# Reconstruyo el top, con una avg pool para que coja los valores que salen de la convoluci\u00f3n.\nx = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\nx = layers.BatchNormalization()(x)\n\n# aplico dropout para que haya regularizaci\u00f3n durante el entrenamiento y sobreentrene el modelo.\ntop_dropout_rate = 0.4\nx = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n# la capa final lleva softmax porque tiene que obtener una probabilidad para cada clase\noutputs = layers.Dense(6, activation=\"softmax\", name=\"pred\")(x)\n\n# Se crea el modelo\nmodel_2 = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n\n# el optimizador tiene un learning rato porque se busca que rapidamente llegue a entrenar las capas a\u00f1adidas y pase a entrenar la segunda parte del finetuning. \noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n# se compila el modelo con la m\u00e9trica a\u00f1adida F1Score como pide el enunciado\nmodel_2.compile(\n    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[F1Score(num_classes=6, average=\"macro\")]\n)\n\n# Se har\u00e1n 25 epochs o hasta que el modelo no mejore durante 5 epochs\nepochs = 25\nEA = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# se entrena el modelo con 8 workers para que vaya m\u00e1s rapido. \nhist = model_2.fit(training_alb, epochs=epochs, validation_data=validation, callbacks = EA, workers= 8)\n\n","9ef721d6":"def plot_prediction(n_epochs, mfit):\n    N = n_epochs\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25,6))\n    fig.suptitle('Training Loss and Accuracy')\n    \n    ax1.plot(np.arange(1, N+1), mfit.history[\"f1_score\"], label=\"train\")\n    ax1.plot(np.arange(1, N+1), mfit.history[\"val_f1_score\"], label=\"val\")\n    ax1.set_title(\"f1_score\")\n    ax1.set_xlabel(\"Epoch #\")\n    ax1.set_ylabel(\"f1_score\")\n    ax1.set_xticks(np.arange(1, N+1))\n    ax1.legend(loc=\"lower right\")\n    \n    ax2.plot(np.arange(1, N+1), mfit.history[\"loss\"], label=\"train\")\n    ax2.plot(np.arange(1, N+1), mfit.history[\"val_loss\"], label=\"val\")\n    ax2.set_title(\"Loss\")\n    ax2.set_xlabel(\"Epoch #\")\n    ax2.set_ylabel(\"Loss\")\n    ax2.set_xticks(np.arange(1, N+1))\n    ax2.legend(loc=\"upper right\")\n    \n    plt.show()\n    \n\nplot_prediction(len(hist.history['loss']), hist)","d76988c5":"model_2.save('\/kaggle\/working\/eff4-224-32bs-aumentos_lluvia-FT-imagenet.h5')","0c2b18d2":"model_2 = tf.keras.models.load_model('\/kaggle\/working\/eff4-224-32bs-aumentos_lluvia-FT-imagenet.h5')","c64be0cf":"# para cada capa del modelo\nfor layer in model_2.layers:\n    # si la capa no es de batch normalization\n        if not isinstance(layer, layers.BatchNormalization):\n            # es entrenable\n            layer.trainable = True\n\n# haciendo varias pruebas he visto que un LR de 1e-4 hac\u00eda que el modelo fuera r\u00e1pido pero comenzara a rebotar muy r\u00e1pido\n# y un LR de 5e-5 hacia que avanzara muy lento al principio y a veces cayera en un minimo local.\n# por tanto defino un lr con exponential decay empezando en 1e-4 y cada 8 epochs (aprox) se reduce a la mitad\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-4,\n    decay_steps=2000,\n    decay_rate=0.5)\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\n# se compila el modelo\nmodel_2.compile(\n    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[F1Score(num_classes=6, average=\"macro\")]\n)\n\nepochs = 50\n\n# un Early Stopping con mucha m\u00e1s paciencia para evitar caer en m\u00ednimos locales.\nEA = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, mode = \"min\")\n\n# se entrena el modelo\nhist = model_2.fit(training_alb, epochs=epochs, validation_data=validation, callbacks = EA, workers=8, class_weight = pesos)\n\n","e09ae7c7":"plot_prediction(len(hist.history['loss']), hist)","e417488a":"predictions = np.array([])\nlabels =  np.array([])\n# recorro cada batch en validaci\u00f3n\nfor x, y in validation:\n    # guardo las predicciones\n    predictions = np.concatenate([predictions,np.argmax(model_2.predict(x), axis=-1)])\n    # y las labels reales\n    labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n\n","e041aa3e":"print(\"f1_score_macro\",f1_score(labels, predictions, average='macro'),\n      \"f1_score_weighted\",f1_score(labels, predictions, average='weighted'),\n      \"precision_weighted\",precision_score(labels, predictions, average='weighted'),\n      \"recall_weighted\", recall_score(labels, predictions, average='weighted'),\n      \"accuracy\",accuracy_score(labels, predictions)\n     )\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nf, ax = plt.subplots(1, 1, figsize = (12, 10))\ncm = confusion_matrix(labels,predictions)\ndisp=ConfusionMatrixDisplay(cm, display_labels= nombres_labels)\ndisp.plot(ax=ax, values_format='.5g', xticks_rotation='vertical') \nplt.show()","976d7d06":"os.chdir('test')\nos.mkdir(\"\/kaggle\/working\/test_imagenes\")","6a55379a":"import shutil\n\n# para cada imagen en test, la copio en el nuevo directorio\nimagenes_test= glob.glob('*.jpg')\nfor im in imagenes_test: \n    shutil.copyfile(im, '\/kaggle\/working\/test_imagenes\/test_'+im)","8ad881ef":"os.chdir(\"\/kaggle\")\nos.listdir()","14c32dac":"# se genera el dataset de test, con las mismas dimensiones, sin shuffle para que pueda saber el t\u00edtulo de la imagen que es y guardarlo en un documento. \ntest = tf.keras.preprocessing.image_dataset_from_directory(\n  'working\/',\n  label_mode = None,\n  seed=123,\n    shuffle=False,\n  image_size=(224,224),\n  batch_size=32)","1aab6f29":"imagenes_test = [imagen.replace(\"working\/test_imagenes\/test_\",\"\") for imagen in test.file_paths]","9b48228d":"os.chdir(\"working\/test_imagenes\/\")","705f5a02":"imagen_bien=cv2.imread(\"test_\"+imagenes_test[0])\nimagen_bien = cv2.cvtColor(imagen_bien, cv2.COLOR_BGR2RGB)\nplt.imshow(imagen_bien)\nplt.title(imagenes_test[0])","369ec49e":"os.chdir(\"..\/..\")","cf6ffd93":"i = 1\nfor x in test:\n    if i ==1: \n        plt.imshow(x[0]\/255)\n        i = 2","7b25d69b":"predictions_finales  = np.array([])\nlabel_prediction= list()\nlabels =  np.array([])\n# para cada batch de test predigo su clase\nfor x in test:\n    pred = np.argmax(model_2.predict(x), axis=-1)\n    predictions_finales = np.concatenate([predictions_finales,pred])\n    # para cada predicci\u00f3n se obtiene la label\n    for p in pred: \n        label_prediction.append(nombres_labels[p])\n","b31cea11":"# guardo el test.csv con el t\u00edtulo de la imagen y la clase predicha, posteriormente lo descargo desde la interfaz de kaggle.\npd.DataFrame({\"image\":imagenes_test, \"label\":label_prediction}).to_csv(\"\/kaggle\/working\/test.csv\", index=False)","740450c4":"A continuaci\u00f3n, como ya he mencionado descongelo las clases del modelo original salvo las de batch normalization, con esto el modelo podr\u00e1 entrenar finalmente para el conjunto de datos de nuestro problema. Sino hubiera entrenado las capas de top a\u00f1adidas, el modelo inicialmente no podr\u00eda aprender bien y se cargar\u00eda los pesos buenos del modelo original. ","f250eabc":"Vemos efectivamente que las im\u00e1genes se han shuffleado correctamente. ","d1de148e":"A continuaci\u00f3n defino el modelo a entrenar y lo entreno, se ha seguido una estrategia de FineTuning en dos partes. El modelo se obtiene sin el top, y se a\u00f1aden unas capas para que haga la predicci\u00f3n, en primera instancia solo se hace entrenamiento de estas capas a\u00f1adidas. Cuando el mejor modelo se obtiene por Early Stopping se obtiene. Se descongelan las capas del modelo (salvo las de batch normalization) y se entrena de nuevo, hasta que se detiene de nuevo por Early Stopping. ","d69227bc":"Vemos que el contador es 0, por lo que no hay im\u00e1genes en ambos datasets. ","459d4c41":"A continuaci\u00f3n visualizo 5 im\u00e1genes para cada clase. ","77ba1a5c":"Ahora visualizo im\u00e1genes del conjunto de entrenamiento, para ver que est\u00e1n con el shuffle correcto. ","053ea944":"Para comprobar que las im\u00e1genes salen en orden:   \n1 obtengo el t\u00edtulo de las imagenes. \n2 accedo al directorio de im\u00e1genes, y por titulo visualizo la imagen\n3 visualizo la primera imagen del test\n4 ambas imagenes son la misma","2d84bea4":"# Ejercicio 4. Resultados y nuevas predicciones.","29209b8d":"## Nuevas predicciones","900347b2":"## Resultados","0d1ebe27":"Ahora obtengo las predicciones para el conjunto de test.","d29b774b":"Ya se ha entrenado el modelo y ahora hay que obtener el rendimiento del modelo, mediante predict se pueden obtener las predicciones del modelo para cada batch de imagenes en validaci\u00f3n. ","fe0529b2":"# Ejercicio 2. Separaci\u00f3n en train y test","7c9c1943":"Vemos que las im\u00e1genes se han transformado, la mayor\u00eda tienen un giro, o un movimiento de la imagen para sea diferente de la imagen orignial, a algunas otras se les ve como se les ha aplicado lluvia o sol o sombras, que interrumpen la visualizaci\u00f3n perfecta de la hoja directamente. ","0d019384":"## 3.4 Gr\u00e1ficas de entrenamiento ","0d25f57b":"## 3.2 Tipo de Modelo y Estrategia de entrenamiento","d3336a5f":"Lo \u00faltimo que se ha estudiado es el rango, vemos que la imagen tiene rango 255 y que su tama\u00f1o es de 332 x 498, con 3 canales de color. Generalmente en modelos convolucionales se trabaja con un rango de 1 pero esto depende del modelo as\u00ed que se mantiene este rango por el momento. Respecto a las dimensiones, probablemente se reduzcan puesto que los problemas en las hojas se pueden interpretar igual en tama\u00f1os menores y facilita la computaci\u00f3n el reducir dimensiones. ","abff96cf":"Vemos que a simple vista hay diferencias entre las clases, aunque algunas clases se parecen m\u00e1s que otras. La clase 0 es claramente la clase sana y las hojas est\u00e1n correctas. La clase 1 se ve como sus ojas se encuentran bastante arrugadas y no presenta parecido con otras hojas de otras clases. La clase 2 presenta grandes manchas amarillas o rojas y generalmente es solo 1 mancha. El resto de las hojas de esta clase suele estar bien. La clase 3 se caracteriza aparentemente por una decoloraci\u00f3n ligera de la hoja, con manchas que pierden el color pero no que cogen sequedad o otro color. La clase 4 presenta unas pocas manchas marrones generalmente y algo de sequedad y decoloraci\u00f3n, parecido a las hojas de la clase 5 pero esttas tienen el relieve m\u00e1s movido y comido. \n\nPor tanto, se puede preveer que haya problemas al separar las clases 3,4 y 5 entre ellas. ","ab1e2599":"Vemos las gr\u00e1ficas de entrenamiento finales.","4345f26d":"A continuaci\u00f3n se visualiza en un gr\u00e1fico de barras el n\u00famero de imagenes por clases y porcentaje de im\u00e1genes por clase. ","0b06723d":"El primer aspecto a definir del modelo es el aumento de datos a realizar para que las im\u00e1genes no sean siempre igual y por tanto el modelo de CNN aprenda a generalizar el conocimiento y no sobreentrenar sobre caracter\u00edsticas concretas de las im\u00e1genes reales. \n\n## 3.1 Aumento de datos","e5869487":"Vemos que las clases est\u00e1n desbalanceadas, mientras que para la clase 0 (hojas sanas) hay 4000 im\u00e1genes, para el resto de clases hay entorno a unas 1000 im\u00e1genes. Esto supone que hay un desbalanceo del dataset, que podr\u00eda afectar a los resultados finales del modelo y puede ser interesante aplicar class_weights al modelo. ","d55f6152":"Por \u00faltimo hay que generar las predicciones para el conjunto de test. Estas no se pueden realizar directamente del conjunto de test porque da error al cargarlas del mismo m\u00e9todo. Por tanto creo un directorio en el kaggle working y las copio all\u00ed. ","732b019b":"Es muy importante realizar un an\u00e1lisis exploratorio del dataset para comprender el problema al que nos enfrentamos desde el dataset. Por tanto, en este analisis exploratorio se observan el n\u00famero de clases que hay, el n\u00famero y porcentaje de im\u00e1genes de cada clase, unas imag\u00e9nes de cada clase y el rango y tama\u00f1o de las im\u00e1genes. ","37922982":"Se han pensado varios tipos de aumentos, al final me he decidido por el de albumentations porque permite realizar m\u00e1s transformaciones de las b\u00e1sicas de rota, por ejemplo estas de tiempo que hemos aplicado en la pr\u00e1ctica. \nEso s\u00ed, para aplicarlas se tiene que utilizar el dataset como lo tenemos como BatchIterator al cargarlo como un tf.Dataset. ","e352be74":"Vemos que los datasets se han divido correctamente, se mantienen 7800 imagenes para el entrenamiento. A continuaci\u00f3n demuestro que no hay im\u00e1genes en ambos. No he aplicado transformaciones al dataset de momento para poder aplicarle transformaciones complejas luego. El tama\u00f1o de la imagen se reduce a 224x224 porque los datos comprimidos a esa dimensi\u00f3n mantienen la gran mayor\u00eda de informaci\u00f3n. ","5953d8c0":"# Ejercicio 1. An\u00e1lisis exploratorio","a6aa4055":"A continuaci\u00f3n caclulo las m\u00e9tricas weighted y la f1-score-macro para confirmar que las predicciones se han hecho bien y que el resultado de esta m\u00e9trica coincide con el del modelo final","9811f9e6":"# Ejercicio 3. Modelado","553e26fe":"En la matriz de confusi\u00f3n vemos...."}}