{"cell_type":{"e8cb681f":"code","5c3cac19":"code","4d28414d":"code","a72d0006":"code","6f290d01":"code","04e9edc6":"code","f66cfa24":"code","47e1d6ec":"code","0291ee4c":"code","780ec925":"code","c1307525":"markdown"},"source":{"e8cb681f":"# Lots of help for this project from https:\/\/blog.algorithmia.com\/convolutional-neural-nets-in-pytorch\/\n# And https:\/\/www.kaggle.com\/devilsknight\/malaria-detection-with-pytorch\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL\nimport torch\nimport torchvision\nfrom matplotlib.pyplot import *\nimport skimage.io\n\nroot_path = \"..\/input\/cell_images\/cell_images\/\"\nuninfected_cell_images = os.listdir(root_path + \"Uninfected\")\ninfected_cell_images = os.listdir(root_path + \"Parasitized\")\nhealthy_im = skimage.io.imread(os.path.join(root_path, \"Uninfected\", uninfected_cell_images[0]))\nunhealthy_im = skimage.io.imread(os.path.join(root_path, \"Parasitized\", infected_cell_images[0]))\n\nfigure(figsize=(15, 10))\n\nsubplot(1, 2, 1)\ntitle(\"Healthy\")\nimshow(healthy_im)\nxticks([]);yticks([]);\n\nsubplot(1, 2, 2)\ntitle(\"Unhealthy\")\nimshow(unhealthy_im)\nxticks([]);yticks([]);","5c3cac19":"import seaborn as sn\n\n# Create a table showing the distribution of image shapes \/ sizes.\n\nsizes = np.zeros((20, 20), dtype=np.dtype(int))\nfor healthy_im_fname in uninfected_cell_images:\n    if healthy_im_fname.endswith(\".png\"):\n        w, h = PIL.Image.open(os.path.join(root_path, \"Uninfected\", healthy_im_fname)).size\n        w = min(190, w)\n        h = min(190, h)\n        sizes[w \/\/ 10, h \/\/ 10] += 1\n\nfor sick_im_fname in infected_cell_images:\n    if sick_im_fname.endswith(\".png\"):\n        w, h = PIL.Image.open(os.path.join(root_path, \"Parasitized\", sick_im_fname)).size\n        w = min(190, w)\n        h = min(190, h)\n        sizes[w \/\/ 10, h \/\/ 10] += 1\n\nfigure(figsize=(20,15))\ndf = pd.DataFrame(sizes)\nsn.heatmap(df, fmt='d', annot=True)\nxlabel(\"Width of image (in 10 pixel increments)\")\nylabel(\"Height of image (in 10 pixel increments)\")\ntitle(\"Image size and shape distribution.\")\n\n","4d28414d":"# We need to create the Dataset\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport random\n\n# Define our data transforms\ndata_transforms = {\n    'test': transforms.Compose([transforms.Resize((64, 64)),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.RandomRotation(5),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ]),\n    'train': transforms.Compose([transforms.Resize((64, 64)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n}\n\n# Originally I had a custom dataset but I found ImageFolder to produce better results quicker. May have just been an error with my code.\ntrain_set = torchvision.datasets.ImageFolder(root_path, transform=data_transforms['train'])\ntest_set = torchvision.datasets.ImageFolder(root_path, transform=data_transforms['test'])\n\nnum_train = len(train_set)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\n\nvalid_size = 0.2 # 20% of images used for validation\ntest_size = 0.1 # 10% of images used for testing.\n\nstart_valid = int(num_train - (num_train * valid_size + test_size))\nstart_test = int(num_train - (num_train * test_size))\n\n# Samplers\ntrain_sampler = SubsetRandomSampler(indices[0:start_valid])\nval_sampler = SubsetRandomSampler(indices[start_valid:start_test])\ntest_sampler = SubsetRandomSampler(indices[start_test:])","a72d0006":"def togpu(x):\n    return x.cuda()\ndef tocpu(x):\n    return x.cpu()","6f290d01":"from torch.autograd import Variable\nimport torch.nn.functional as F\n\n# Now we get to the CNN\nclass MalariaCNN(torch.nn.Module):\n    \n    def __init__(self):\n        super(MalariaCNN, self).__init__()\n        \n        # The shape of the images are 64 x 64 x 3\n        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n        self.conv2 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n        \n        # After pooling the images should be 16 x 16\n        self.fc1 = torch.nn.Linear(in_features=(64 * 16 * 16), out_features=1024)\n        self.fc2 = torch.nn.Linear(in_features=1024, out_features=64)\n        self.fc3 = torch.nn.Linear(in_features=64, out_features=2)\n        \n    def forward(self, x):\n        \n        # Size changes from (3, 64, 64) to (64, 64, 64)\n        x = F.relu(self.conv1(x))\n        \n        # (64, 64, 64) -> (64, 32, 32)\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv2(x))\n        \n        # (64, 32, 32) -> (64, 16, 16)\n        x = F.max_pool2d(x, 2)\n        \n        x = x.reshape(-1, 64 * 16 * 16)\n        \n        # 16384 -> 1024\n        x = F.relu(self.fc1(x))\n        \n        # 1024 -> 64\n        x = F.relu(self.fc2(x))\n        \n        # 64 -> 2\n        x = self.fc3(x)\n        \n        return x","04e9edc6":"\n#DataLoader takes in a dataset and a sampler for loading (num_workers deals with system level memory) \ndef get_train_loader(batch_size):\n    train_loader = DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n    \n    return train_loader\n\ntest_loader = DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)\nval_loader = DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)","f66cfa24":"import torch.optim as optim\n\ndef createLossAndOptimizer(net, learning_rate=0.001):\n    loss = torch.nn.CrossEntropyLoss()\n    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n    \n    return(loss, optimizer)","47e1d6ec":"import time\n\ndef trainNet(net, batch_size, n_epochs, learning_rate):\n    \n    #Print all of the hyperparameters of the training iteration:\n    print(\"===== HYPERPARAMETERS =====\")\n    print(\"batch_size=\", batch_size)\n    print(\"epochs=\", n_epochs)\n    print(\"learning_rate=\", learning_rate)\n    print(\"=\" * 30)\n    \n    train_loader = get_train_loader(batch_size)\n    n_batches = len(train_loader)\n    \n    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n    \n    training_start_time = time.time()\n    \n    min_val_loss = 1.0\n    \n    for epoch in range(n_epochs):\n        \n        running_loss = 0.0\n        print_every = n_batches \/\/ 5 # Print 10 times total each epoch\n        start_time = time.time()\n        total_train_loss = 0\n        \n        for i, data in enumerate(train_loader, 0):\n            \n            inputs, labels = data\n            \n            #print(inputs, labels)\n            inputs, labels = Variable(togpu(inputs)), Variable(togpu(labels))\n            \n            optimizer.zero_grad()\n    \n            outputs = net(inputs)\n            loss_size = loss(outputs, labels)\n            loss_size.backward()\n            optimizer.step()\n            \n            # print(loss_size.data.item())\n            running_loss += loss_size.data.item()\n            total_train_loss += loss_size.data.item()\n            \n            if i % print_every == print_every - 1:\n                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n                    epoch+1, int(100 * (i + 1) \/ n_batches), running_loss \/ print_every, time.time() - start_time\n                ))\n                \n                running_loss = 0.0\n                start_time = time.time()\n                \n        total_val_loss = 0\n        for inputs, labels in val_loader:\n            inputs, labels = Variable(togpu(inputs)), Variable(togpu(labels))\n            \n            val_outputs = net(inputs)\n            val_loss_size = loss(val_outputs, labels)\n            total_val_loss += val_loss_size.data.item()\n            \n        print(\"Validation loss = {:.2f}\".format(total_val_loss \/ len(val_loader)))\n        if (total_val_loss \/ len(val_loader)) < min_val_loss:\n            print(\"New best: ({} -> {})\".format(min_val_loss, total_val_loss \/ len(val_loader)))\n            min_val_loss = total_val_loss \/ len(val_loader)\n            torch.save(net.state_dict(), \"malaria_best.pt\")\n                                \n        \n        \n    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n    ","0291ee4c":"CNN = togpu(MalariaCNN())\ntrainNet(CNN, batch_size=64, n_epochs=25, learning_rate=0.002)","780ec925":"def getPrediction(net, image_path):\n    # Helper function that returns the output of the network.\n    # In this case, it will return a 1 if the cell is parasite-free.\n    image = PIL.Image.open(image_path)\n    prediction_transform = transforms.Compose([\n        transforms.Resize(size=(64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5],\n                             [0.5, 0.5, 0.5])\n    ])\n    \n    image = prediction_transform(image).unsqueeze(0)\n    \n    net = net.cpu()\n    net.eval()\n    idx = torch.argmax(net(image))\n        \n    return idx\n\n# Load the best state of the CNN\nCNN.load_state_dict(torch.load('malaria_best.pt'))\n\n# Draw 100 cells along with their predicted and target values.\nfigure(figsize=(25,12))\nnum_predictions = 100\ncorrect_predictions = 0\nncols = int(num_predictions ** 0.5)\nnrows = int(num_predictions \/ ncols)\nfor i in range(num_predictions):\n    sub_path = random.choice([\"Parasitized\", \"Uninfected\"])\n    images_path = os.path.join(root_path, sub_path)\n    final_path = os.path.join(images_path, random.choice([fname for fname in os.listdir(images_path) if fname.endswith(\".png\")]))\n    prediction = \"Sick\" if getPrediction(CNN, final_path) == 0 else \"Healthy\"\n    target = \"Sick\" if sub_path == \"Parasitized\" else \"Healthy\"\n    correct_predictions += 1 if target == prediction else 0\n    subplot(nrows, ncols, i+1)\n    imshow(PIL.Image.open(final_path))\n    xticks([]);yticks([]);\n    xlabel(\"P:{}, T:{}\".format(prediction, target))\n    \nprint(\"Got {}\/{} correct\".format(correct_predictions, num_predictions))","c1307525":"All of the images are different sizes, so whatever we use will have to be robust enough to handle it."}}