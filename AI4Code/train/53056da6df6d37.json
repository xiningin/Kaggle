{"cell_type":{"9a1f1c16":"code","769e1286":"code","2ea352d8":"code","e70f6cc1":"code","68711a30":"code","6ab2a86f":"code","f6a0bcef":"code","7bf20f9b":"code","8fad6d47":"code","2c6f5fc7":"code","0ee232ae":"code","99bd5bc9":"code","3c2b6954":"code","192adb49":"code","84241855":"code","c4aea20e":"code","dbbe4b20":"code","5cd07e99":"code","33782e64":"code","488e94c0":"code","77d7636d":"code","e297e148":"code","3ef02f72":"code","cc9baceb":"code","b3bad517":"code","2e26f6b1":"code","465dc8d8":"code","63292672":"code","e771aee9":"code","3e9d5f9a":"code","957c48e4":"code","01345b28":"code","219d3a01":"code","274d9713":"code","943d0f43":"markdown","0b4ece84":"markdown","25564dfe":"markdown","4715b2bf":"markdown","4acd5c5b":"markdown","783f14c5":"markdown","1e9fcba5":"markdown","8a3ac367":"markdown","27870672":"markdown","a68b6185":"markdown","7fdcc369":"markdown"},"source":{"9a1f1c16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","769e1286":"import random as rd # generating random numbers\nimport datetime # manipulating date formats\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\n%matplotlib inline\n\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.utils import to_categorical\nimport math\nfrom keras import backend as K\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2ea352d8":"item_cat = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nsales_train = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nsales_test = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')","e70f6cc1":"item_cat","68711a30":"sales_train","6ab2a86f":"#formatting the date column correctly\nsales_train.date=sales_train.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))","f6a0bcef":"sales_test","7bf20f9b":"monthly_sales=sales_train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"item_price\",\"item_cnt_day\"].agg({\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"}).reset_index()\nmonthly_sales.rename(columns={'item_cnt_day':'item_cnt_month'}, inplace=True)","8fad6d47":"monthly_sales.drop(columns='item_price', inplace=True)\nmonthly_sales","2c6f5fc7":"date_block_num_to_delete = [i for i in range(18)]\ndate_block_num_to_delete += [24 + k for k in range(6)]\nprint(date_block_num_to_delete)","0ee232ae":"monthly_sales = monthly_sales[~monthly_sales['date_block_num'].isin(date_block_num_to_delete)]\n# monthly_sales = pd.get_dummies(monthly_sales, columns=['date_block_num'])","99bd5bc9":"# number of items per cat \nx=items.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\nx\n# #plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","3c2b6954":"ts=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","192adb49":"from sklearn.model_selection import train_test_split\n\nX = monthly_sales.drop('item_cnt_month', axis=1)\ny = monthly_sales['item_cnt_month']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","84241855":"from sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators=100, n_jobs=-1, verbose=1)\nrfr.fit(X_train, y_train)","c4aea20e":"from sklearn.metrics import mean_squared_error,r2_score\npred = rfr.predict(X_val)\n# print(\"R2 score is \" + str(r2_score(pred, y_val)))\nprint(\"RMSE is \" + str(math.sqrt(mean_squared_error(pred, y_val))))","dbbe4b20":"def embedding_input(name, n_in, n_out, reg):\n    inp = Input(shape=(1,), dtype='int64', name=name)\n    return inp, Embedding(n_in, n_out, input_length=1, embeddings_regularizer=l2(reg))(inp)","5cd07e99":"n_shops = len(shops.nunique(axis=1))\nn_items = len(items.nunique(axis=1))\nn_months = monthly_sales['item_cnt_month'].nunique()\nshops_in, shops_emb = embedding_input('shops_in', n_shops, math.ceil(min(50, math.sqrt(n_shops))), 1e-4)\nitems_in, items_emb = embedding_input('items_in', n_items, math.ceil(min(50, math.sqrt(n_items))), 1e-4)\nmonths_in = Input(shape=(1,), dtype='int64', name='month_in'),","33782e64":"def plot_history():\n    fig, ax = plt.subplots(figsize=(12,4))\n    ax.plot(history.history['loss'])\n    ax.plot(history.history['val_loss'])\n    ax.set_title('Model loss')\n    ax.set_ylabel('Loss')\n    ax.set_xlabel('Epoch')\n    ax.legend(['Train', 'Val'], loc='upper left')\n    plt.show()\n    print(\"Our model train and validation loss  are {} and {} respectivly \".format(history.history['loss'][-1],history.history['val_loss'][-1]))","488e94c0":"def root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))","77d7636d":"x = concatenate([shops_emb,items_emb])\nx = Flatten()(x)\nx = Dense(1, activation='relu')(x)\nmodel = Model([months_in, shops_in, items_in], x)\nmodel.compile(optimizer='adam', loss=root_mean_squared_error)","e297e148":"history = model.fit(x=[X.date_block_num, X.shop_id, X.item_id], y=y, validation_split=0.2, verbose=1, batch_size=64, epochs=5)\nplot_history()","3ef02f72":"x = concatenate([shops_emb,items_emb])\nx = Flatten()(x)\nx = BatchNormalization()(x)\n# x = add([x,shops_bias])\n# x = add([x, items_bias])\nx = Dropout(0.15)(x)\nx = Dense(25)(x)\nx = Dropout(0.35)(x)\nx = Dense(1, activation='relu')(x)\nmodel = Model([months_in, shops_in, items_in], x)\nmodel.compile(optimizer='adam', loss=root_mean_squared_error)","cc9baceb":"model.summary()","b3bad517":"history = model.fit(x=[X_train.date_block_num, X_train.shop_id, X_train.item_id], y=y_train, validation_data = ([X_val.date_block_num, X_val.shop_id, X_val.item_id],y_val), verbose=1, batch_size=64, epochs=5)\nplot_history()","2e26f6b1":"sample_submission_df = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')","465dc8d8":"pred = model.predict([pd.DataFrame([34] * len(sales_test)), sales_test.shop_id, sales_test.item_id])","63292672":"submission = pd.DataFrame.from_dict({'ID' : sample_submission_df['ID'], 'item_cnt_month' : pred.flatten()})","e771aee9":"filename = 'Future Sales Predictions.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","3e9d5f9a":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=3)\n\nitems_emb_vect = model.layers[3].get_weights()[0]\n\npcas = pca.fit_transform(items_emb_vect)\n\nplt.scatter(pcas[:20,0],pcas[:20,1], cmap='RdBu',c=range(20))\n\nitems[:20]","957c48e4":"shops_emb_vect = model.layers[2].get_weights()[0]\n\npcas = pca.fit_transform(shops_emb_vect)\n\nplt.scatter(pcas[:7,0],pcas[:7,1], cmap='RdBu',c=range(7))\n\nshops[:7]","01345b28":"train_features = model.predict([X_train.date_block_num, X_train.shop_id, X_train.item_id], batch_size=64, verbose=1)\nval_features = model.predict([X_val.date_block_num, X_val.shop_id, X_val.item_id], batch_size=64, verbose=1)","219d3a01":"rfr = RandomForestRegressor(n_estimators=100, n_jobs=-1, verbose=1, random_state=42)\nrfr.fit(train_features, y_train)","274d9713":"pred = rfr.predict(val_features)\nprint(\"R2 score is \" + str(r2_score(pred, y_val)))\nprint(\"RMSE is \" + str(math.sqrt(mean_squared_error(pred, y_val))))","943d0f43":"## d. We build a simple neural network which contains the embedding layers only.","0b4ece84":"# c. We create our embedding and input layers as preprocessing steps","25564dfe":"## From the above plot and table we can conclude that items with the same category are close to each other while items from different categories are further","4715b2bf":"## Our position in the competition:\n![second_submission_screenshot.png](attachment:second_submission_screenshot.png)","4acd5c5b":"# b. We chose the Random Forest Regressor as our classical ML model for prediciting the sales","783f14c5":"## Unlike the items, we weren't able to infer much about the shops from the embedding since there aren't any informative features we can use to find correlation","1e9fcba5":"## As you can see we didn't manage to improve our results compared to our first RFR model. We can conclude that our self-learning task wasn't the best choice or that our pre-trained weights weren't optimal.","8a3ac367":"# e. We now modify our model by adding some bias for our embedding layers and some dropouts and batch normalization in order to generalize well and avoid overfit.\n# In addition, we now pre-selected our train-validation split.","27870672":"## As you can see, we got a solid benchmark.","a68b6185":"# f. ","7fdcc369":"# g. We extract our model prediction on both train and validation sets as features for our classical ML model which will be the same as before (RFR)"}}