{"cell_type":{"b15c8c1b":"code","abd862d4":"code","f5062590":"code","dc34f9a8":"code","03015f45":"code","c361bcb8":"code","ef89b43b":"code","f52fc514":"code","151ea7ed":"code","e2655de0":"code","96bdf26a":"code","15afc63e":"code","77477971":"code","9e8594e5":"code","ac2a7a3f":"code","47991dc9":"code","48a0edca":"code","4d634168":"code","e1e9395c":"code","37408219":"code","e2b08b65":"markdown","f1baeee6":"markdown","73c7415d":"markdown","afeca95b":"markdown","e5d3122e":"markdown","3fb48d85":"markdown","97037bb0":"markdown","cc60f90b":"markdown","35866404":"markdown","2705213d":"markdown","dd5f2939":"markdown","69a087e6":"markdown","e4aa5e6d":"markdown","a5b9486b":"markdown","ad7c38f7":"markdown"},"source":{"b15c8c1b":"# Check the GPU is available, if not, swith other account to have usefulness of GPU\nimport torch\ntorch.cuda.is_available()","abd862d4":"from google.colab import drive\ndrive.mount('\/content\/drive')","f5062590":"# Go to directory\nimport os\nos.chdir('.\/drive\/MyDrive\/Deeplearning')","dc34f9a8":"from PIL import Image\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms","03015f45":"train_csv_path = '.\/train.csv'\ntrain_info = pd.read_csv(train_csv_path)\ntrain_info.head()","c361bcb8":"quantity = train_info.describe()\nquantity","ef89b43b":"class_weight = (quantity.loc['mean'].max() \/ quantity.loc['mean']).values\nclass_weight","f52fc514":"id_images = train_info['image_id'].values\nlabels = train_info.iloc[:, 1:].values\nlabels = labels.argmax(axis = 1)","151ea7ed":"image_path = '.\/images'\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((320, 512))\n])\n\naugment = transforms.RandomApply(transforms = [transforms.GaussianBlur(11),\n                                         transforms.RandomPerspective(),\n                                         transforms.RandomRotation(degrees=(0, 180)),\n                                         transforms.RandomAutocontrast(),\n                                         transforms.RandomHorizontalFlip(),\n                                         transforms.RandomVerticalFlip()])\n\nclass PurePlantDataset(Dataset):\n    def __init__(self, ids, labels, transform, augment = None):\n        \n        super(PurePlantDataset, self).__init__()\n        self.cache = {}\n        self.transform = transform\n        self.augment = augment\n        self.ids = ids\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.ids)\n    \n    def __getitem__(self, index):\n        image = self.cache.get(index, None)\n        if image == None:\n            image_name = os.path.join(image_path, self.ids[index] + '.jpg')\n            image = Image.open(image_name)\n            image = self.transform(image)\n            self.cache[index] = image\n        \n        if self.augment != None:\n            return self.augment(image), self.labels[index]\n        return image, self.labels[index]","e2655de0":"from torchvision import models\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n    def forward(self, X):\n        return X\n\nclass ResnetModel(nn.Module):\n    def __init__(self, backbone, n_class):\n        super(ResnetModel, self).__init__()\n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=True)\n        elif backbone == 'resnet101':\n            self.backbone = models.resnet101(pretrained=True)\n        elif backbone == 'resnet152':\n            self.backbone = models.resnet152(pretrained=True)\n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = Identity()\n        \n        self.fc = nn.Linear(in_features, n_class)\n    def forward(self, X):\n        out = self.backbone(X)\n        return self.fc(out)","96bdf26a":"n_epoch = 20\nlr = 1e-2\nbatch_size = 32\nn_fold = 5 # test size 0.2\nglobal_device = 'cuda' if torch.cuda.is_available() else 'cpu'","15afc63e":"def get_accuracy(logit, y_truth):\n    logit = torch.softmax(logit, dim = 1)\n    y_predict = logit.argmax(dim = 1)\n    return torch.sum(y_predict == y_truth) \/ len(y_truth)\n\ndef evaluate(model, criterion, test_loader):\n    with torch.no_grad():\n        losses = []\n        accs = []\n        for X, Y in test_loader:\n            X = X.to(device = global_device)\n            Y = Y.to(device = global_device)\n            out = model(X)\n            loss = criterion(out.detach(), Y).item() if criterion != None else -1\n            acc = get_accuracy(out.detach(), Y)\n            \n            losses.append(loss)\n            accs.append(acc.item())\n        return sum(losses)\/len(losses), sum(accs)\/len(accs)","77477971":"from tqdm.auto import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.model_selection import StratifiedKFold\n\n\nfreeze = False\ncheckpoint_path = 'model_resnet50.pt'\ncontinue_training = False\n\nspliter = StratifiedKFold(n_splits=n_fold, shuffle=True)\nbest_score = 0\nfor i, (train_idx, val_idx) in enumerate(spliter.split(id_images, labels)):\n    print(f\"Train in fold {i}============================================\")\n    train_data = PurePlantDataset(ids=id_images[train_idx], \n                                    labels = labels[train_idx], \n                                    transform = transform, \n                                    augment = augment)\n    val_data = PurePlantDataset(ids=id_images[val_idx], \n                                    labels = labels[val_idx], \n                                    transform = transform)\n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_data, batch_size=batch_size)\n    \n    model = ResnetModel('resnet50', 4)\n    model.to(device = global_device)\n    if freeze == True:\n        for param in model.backbone.parameters():\n            param.requires_grad = False\n\n    opt_param = [param for param in model.parameters() if param.requires_grad == True]\n    optimizer = torch.optim.Adam(params=opt_param, lr=lr)\n    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n\n    if os.path.exists(checkpoint_path) & continue_training:\n        checkpoint = torch.load(checkpoint_path, map_location=global_device)\n        model.load_state_dict(checkpoint['model'])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n        best_score = checkpoint['best_score']\n        print(\"Load state dict\")\n    \n    criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weight, dtype=torch.float, device=global_device))\n    for epoch in range(n_epoch):\n        print(f\"Train epoch {epoch}\/{n_epoch}...\")\n        total_loss = []\n        total_acc = []\n        \n        model.train()\n        for X, Y in tqdm(train_loader):\n            optimizer.zero_grad()\n            X = X.to(device = global_device)\n            Y = Y.to(device = global_device)\n            out = model(X)\n            loss = criterion(out, Y)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss.append(loss.item())\n            acc = get_accuracy(out.detach(), Y)\n            total_acc.append(acc.item())\n        \n        model.eval()\n        avg_train_loss = sum(total_loss) \/ len(total_loss)\n        avg_train_acc = sum(total_acc) \/ len(total_acc)\n        val_loss, val_acc = evaluate(model, criterion, val_loader)\n        print(f\"Train loss {avg_train_loss:.4f} accuray {avg_train_acc:.4f}. Val loss {val_loss:.4f} accuracy {val_acc:.4f}\")\n        \n        if val_acc >= best_score:\n            best_score = val_acc\n            torch.save({\n                'model': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'best_score': best_score\n            }, checkpoint_path)\n            print(\"Save---\")\n        scheduler.step()\n    break # train on fold 0\n","9e8594e5":"def load_model_pretrain(mode, path, device):\n    model = ResnetModel(mode, 4)\n    model.to(device=global_device)\n\n    checkpoint = torch.load(path, map_location=device)\n    model.to(device=device)\n    model.load_state_dict(checkpoint['model'])\n    return model\n  ","ac2a7a3f":"eval_data = PurePlantDataset(ids=id_images, labels = labels, transform = transform)\neval_loader = DataLoader(eval_data, batch_size=32, shuffle=True)\n\nmodel = load_model_pretrain('resnet50', 'model_resnet50.pt', global_device)\nmodel.eval()\n\nevaluate(model, None, eval_loader)","47991dc9":"model = ResnetModel('resnet50', 4)\nmodel.to(device=global_device)\n\ncheckpoint =torch.load('model_resnet50.pt', map_location=global_device)\nmodel.load_state_dict(checkpoint['model'])\nmodel.eval()","48a0edca":"df = pd.read_csv('test.csv')\ndf.head()","4d634168":"for title in train_info.columns[1:]:\n    df[title] = np.NaN\nfor i, id_image in enumerate(df.image_id):\n    image_name = os.path.join(image_path, id_image + '.jpg')\n    image = Image.open(image_name)\n    image = transform(image)\n    image = image.to(device = global_device)\n    output = model(image.unsqueeze(0))\n    logit = torch.softmax(output.detach().cpu(), dim = 1)\n    \n    round_logit = [round(l, 2) for l in logit.squeeze().tolist()]\n    df.iloc[i, 1:] = round_logit","e1e9395c":"df.head()","37408219":"df.to_csv(\"PhamQuocHuy_supmission.csv\", index=False)","e2b08b65":"## Tips for training with Google Colab\n\n- There are many tool, but I simply make small script on colab site","f1baeee6":"# Read dataset","73c7415d":"- Open soucre of site: focus on this tab, right-click on \"+ Text\" to inspect\n![image.png](attachment:image.png)\n- Copy the id of tag with focused\n- On the Console tab, make pretty scipt (^^) with id haved been coppied. Follow the example\n\n`setInterval(() => {\n    document.querySelector(\"#cell-Uh8-XpwEfGhi .add-text\").click()\n}, 600000)`\n\n- This script will add 1 tab every 10 minutes\n- Clear the output of setInterval `clearInterval(#output_of_setInterval)`\n","afeca95b":"## Training","e5d3122e":"## Define the Dataset\n\n- During training time, I use the some data augment as:\n    - Blur with kernel size 11\n    - Change the perspective\n    - Rotate with degree between 0 and 180\n    - Increase\/decrease the contrast of image\n    - Flip the image both H\/V side\n- During validation\/test time, data augment will turn off","3fb48d85":"- The number sample of each class is skewed\n- class_weight will use with the criterion to compute the loss which view as \"balance\"","97037bb0":"#Focus","cc60f90b":"This notebook run on Google Colab","35866404":"# [Plant Pathology 2020 - FGVC7](https:\/\/www.kaggle.com\/c\/plant-pathology-2020-fgvc7\/overview)\n*Identify the category of foliar diseases in apple trees*\n","2705213d":"- I use the resnet as backbone of the network and simple classifier layer \"Linear\"\n- Accept the net: resnet50, resnet101, resnet152. And in this project I just test with resnet 50\n- The size of the resnet on my local, but in Colab the size will larger (I unenough time to know what happen :D, reader can test and slove this problem)\n    - resnet50: 730M\n    - resnet101: 784M\n    - resnet152: 856M\n- The Identity layer is a dummy. I plant to freeze the backbone and use it as feature extraction layer, but when training the accuracy is limitted around 0.88, so I unfeeze the backbone and get the better result. This implement can change directly the fc in resnet by the Linear.\n- The last layer we don't use activation function, it will be combined with CrossEntropyLoss later","dd5f2939":"## Define network","69a087e6":"## Test all sample before submit","e4aa5e6d":"## Submition","a5b9486b":"- Despite of the competition is off, the score is pretty cool (0o0)\n\n![image.png](attachment:image.png)","ad7c38f7":"## Setup connect with Drive\n\n- Tree\n    - Deeplearning\n        - train.csv\n        - test.csv\n        - notebook.ipynb"}}