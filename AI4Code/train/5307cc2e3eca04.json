{"cell_type":{"1355de12":"code","fa74dc74":"code","af6afe1e":"code","75b459ba":"code","f052315e":"code","a0c8c1ce":"code","524b1230":"code","39d22f48":"markdown","fe3ff0a5":"markdown","220ec1a0":"markdown","ddc4981f":"markdown","f9b0018a":"markdown","4425548b":"markdown"},"source":{"1355de12":"from gensim.corpora import Dictionary\nfrom gensim.models import TfidfModel, LdaModel\nfrom multiprocessing import Pool\nimport sqlite3 as sql\nimport pandas as pd\nimport numpy as np\nimport logging\nimport time\nimport re\n\ndb = '..\/input\/english-wikipedia-articles-20170820-sqlite\/enwiki-20170820.db'\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)","fa74dc74":"def get_query(select, db=db):\n    '''\n    1. Connects to SQLite database (db)\n    2. Executes select statement\n    3. Return results and column names\n    \n    Input: 'select * from analytics limit 2'\n    Output: ([(1, 2, 3)], ['col_1', 'col_2', 'col_3'])\n    '''\n    with sql.connect(db) as conn:\n        c = conn.cursor()\n        c.execute(select)\n        col_names = [str(name[0]).lower() for name in c.description]\n    return c.fetchall(), col_names\n\ndef tokenize(text, lower=True):\n    '''\n    1. Strips apostrophes\n    2. Searches for all alpha tokens (exception for underscore)\n    3. Return list of tokens\n\n    Input: 'The 3 dogs jumped over Scott's tent!'\n    Output: ['the', 'dogs', 'jumped', 'over', 'scotts', 'tent']\n    '''\n    text = re.sub(\"'\", \"\", text)\n    if lower:\n        tokens = re.findall('''[a-z_]+''', text.lower())\n    else:\n        tokens = re.findall('''[A-Za-z_]''', text)\n    return tokens\n\ndef get_article(article_id):\n    '''\n    1. Construct select statement\n    2. Retrieve all section_texts associated with article_id\n    3. Join section_texts into a single string (article_text)\n    4. Tokenize article_text\n    5. Return list of tokens\n    \n    Input: 100\n    Output: ['the','austroasiatic','languages','in',...]\n    '''\n    select = '''select section_text from articles where article_id=%d''' % article_id\n    docs, _ = get_query(select)\n    docs = [doc[0] for doc in docs]\n    doc = '\\n'.join(docs)\n    tokens = tokenize(doc)\n    return tokens\n       \nclass Corpus():\n    def __init__(self, article_ids):\n        self.article_ids = article_ids\n        self.len = len(article_ids)\n\n    def __iter__(self):\n        article_ids = np.random.choice(self.article_ids, self.len, replace=False)\n        with Pool(processes=4) as pool:\n            docs = pool.imap_unordered(get_article, article_ids)\n            for doc in docs:\n                yield tfidf[dictionary.doc2bow(doc)]\n\n    def __len__(self):\n        return self.len","af6afe1e":"select = '''select distinct article_id from articles'''\narticle_ids, _ = get_query(select)\narticle_ids = [article_id[0] for article_id in article_ids]","75b459ba":"dictionary = Dictionary.load('..\/input\/english-wikipedia-articles-20170820-models\/enwiki_2017_08_20_trimmed.dict')\ntfidf = TfidfModel(dictionary=dictionary)","f052315e":"start = time.time()\n# To keep training time reasonable, let's just look at a random 10K section text sample.\nsample_article_ids = np.random.choice(article_ids, 10000, replace=False)\ndocs = Corpus(sample_article_ids)\nlda = LdaModel(docs, num_topics=200, id2word=dictionary)\nend = time.time()\nprint('Time to train LDA from generator: %0.2fs' % (end - start))","a0c8c1ce":"for i in range(10):\n    print('Topic %d' % i)\n    print(lda.print_topic(i))","524b1230":"lda = LdaModel.load('..\/input\/english-wikipedia-articles-20170820-models\/enwiki_2017_08_20_lda.model')","39d22f48":"Gensim offers built-in functionality for examining topics. Note that we only trained on a subset of the articles, so these topics are likely to be a little incoherent.","fe3ff0a5":"First step, grab the index we'll be iterating over. In this case, we want to use section text, so let's use the implicit column: **rowid**.","220ec1a0":"Now we'll load the pre-trained\/trimmed dictionary from earlier and also create a TF-IDF model.","ddc4981f":"Instead, let's look at a pre-trained LSA model.","f9b0018a":"Now let's train a LDA model. We'll do a single pass, and feed tokens from full articles to build the topic model.","4425548b":"# Tutorial: Latent Dirichlet Allocation\nThis is a basic guide to efficiently training a LDA model on the English Wikipedia dump using Gensim."}}