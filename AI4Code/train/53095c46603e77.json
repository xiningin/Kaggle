{"cell_type":{"83cafef0":"code","0ae02ef0":"code","be351116":"markdown"},"source":{"83cafef0":"import csv\nimport pandas as pd # not key to functionality of kernel\n\nsub_files = [\n                 '..\/input\/siamese\/sub_ens_777.csv',\n                 '..\/input\/siamese\/sub_822.csv',\n]\n\n# Weights of the individual subs\nsub_weight = [\n                0.777**2,\n                0.822**2\n            ]\n# 15","0ae02ef0":"Hlabel = 'Image' \nHtarget = 'Id'\nnpt = 5 # number of places in target\n\nplace_weights = {}\nfor i in range(npt):\n    place_weights[i] = ( 1 \/ (i + 1) )\n    \nprint(place_weights)\n\nlg = len(sub_files)\nsub = [None]*lg\nfor i, file in enumerate( sub_files ):\n    ## input files ##\n    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n    reader = csv.DictReader(open(file,\"r\"))\n    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))\n\n## output file ##\nout = open(\"sub_siamese_ens.csv\", \"w\", newline='')\nwriter = csv.writer(out)\nwriter.writerow([Hlabel,Htarget])\n\nfor p, row in enumerate(sub[0]):\n    target_weight = {}\n    for s in range(lg):\n        row1 = sub[s][p]\n        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\nout.close()","be351116":"Take results from Siamese net kernel https:\/\/www.kaggle.com\/seesee\/siamese-pretrained-0-822 by @seesee\n\nTake results from https:\/\/www.kaggle.com\/ateplyuk\/ensembling-voting-0-777 by @ateplyuk\n\nAnd plug into this kernel by @suicaokhoailang\n\nThis kernel is based on the approach from https:\/\/www.kaggle.com\/suicaokhoailang\/ensembling-with-averaged-probabilities-0-701-lb"}}