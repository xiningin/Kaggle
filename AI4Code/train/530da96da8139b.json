{"cell_type":{"fa69342b":"code","c15b6cd5":"code","1ade4bf2":"code","db35649c":"code","84a33549":"code","cd0403fb":"code","df6c2663":"code","b1412304":"code","69976dd7":"code","cb0290f6":"code","6e4b5afc":"code","d7c660a8":"code","7823462e":"code","86971461":"code","fc0d8d54":"code","49bd1d5e":"code","d2ed9fd1":"code","06e347da":"code","8923029e":"code","14ed2960":"code","603953f4":"code","f1719f8e":"code","4f64c9bd":"code","9e6899ca":"code","f60b9fe9":"code","14badf22":"code","7cd709a3":"code","18282435":"code","db66b0a8":"code","fe1a86d2":"code","6fa3763e":"code","ba792282":"code","5bf84169":"code","a8060de8":"code","88b9567c":"code","3597423e":"code","126b66f6":"code","70f5d58d":"code","ccf38db5":"code","7c156c99":"code","a69d6f8a":"code","5bc6b948":"code","b6bf6a2f":"code","dc421680":"code","410f8a19":"code","6f53197c":"code","317711e8":"code","471ca6be":"code","ce19c33e":"code","9be6b385":"code","e5eefbe4":"code","422c1810":"markdown","a461e7e1":"markdown","61269cae":"markdown","11c873de":"markdown","0bd03454":"markdown","12ff9e30":"markdown","d74ba37f":"markdown","3ddf41bc":"markdown","c0b9b58c":"markdown","29a9ddd4":"markdown","19a473b3":"markdown","52e97098":"markdown","64e11d88":"markdown","448238d9":"markdown","b68dc06a":"markdown","df078104":"markdown","47fbcba9":"markdown","fb5037f6":"markdown","6f3e98fa":"markdown","d30598a0":"markdown","92d196a3":"markdown","bdca6855":"markdown"},"source":{"fa69342b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c15b6cd5":"import numpy as np \nimport pandas as pd \nimport os\nimport torch\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport torch.nn.functional as F \n\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision import transforms as T,datasets","1ade4bf2":"project_name = \"monkey_species_classification\"","db35649c":"train_dir = '..\/input\/10-monkey-species\/training\/training'\nprint(os.listdir(train_dir))","84a33549":"inside_n8 = os.listdir(\"..\/input\/10-monkey-species\/training\/training\/n8\")","cd0403fb":"print(inside_n8[:5]), print(len(inside_n8))","df6c2663":"val_dir = '..\/input\/10-monkey-species\/validation\/validation'\nprint(os.listdir(val_dir))","b1412304":"from torchvision import datasets, transforms, models\nimport torchvision.transforms as tt","69976dd7":"class CNFG:\n\n    #epochs =10                              \n    #lr = 0.001                              \n    batch_size = 8\n    img_size = 64","cb0290f6":"train_tfms = T.Compose([\n                             T.Resize(size=(CNFG.img_size,CNFG.img_size)), # Resizing the image to be 224 by 224\n                             T.RandomRotation(degrees=(-20,+20)), #Randomly Rotate Images by +\/- 20 degrees, Image argumentation for each epoch\n                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n                             T.Normalize([0.4394, 0.4273, 0.2157],[0.2932, 0.3182, 0.2477]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n\n])\n\nvalid_tfms = T.Compose([\n                             \n                             T.Resize(size=(CNFG.img_size,CNFG.img_size)), \n                             T.ToTensor(), \n                             T.Normalize([0.4394, 0.4273, 0.2157],[0.2932, 0.3182, 0.2477]) \n\n])\n\ntrain_data = datasets.ImageFolder(train_dir,       \n                    transform=train_tfms)\nval_data = datasets.ImageFolder(val_dir,\n                    transform=train_tfms)","6e4b5afc":"img, label = train_data[1]\nprint(img.shape, label)","d7c660a8":"img, label = train_data[112]\nprint(img.shape, label)","7823462e":"img, label = val_data[25]\nprint(img.shape, label)","86971461":"print(train_data.classes, val_data.classes) ","fc0d8d54":"batch_size = 8\n","49bd1d5e":"def show_image(img, label):\n    print(\"label is: \", train_data.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0)) #as matplotlib needs tensor dimensions as 32,32,3","d2ed9fd1":"show_image(*train_data[110])","06e347da":"# PyTorch data loaders\ntrain_dl = DataLoader(train_data, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dl = DataLoader(val_data, batch_size*2, num_workers=2, pin_memory=True)","8923029e":"# from PIL import Image\n# import matplotlib.pyplot as plt\n# import numpy as np\n  \n# # load the image\n# img_path = '..\/input\/10-monkey-species\/training\/training\/n0\/n0018.jpg'\n# img = Image.open(img_path)","14ed2960":"# import torchvision.transforms as transforms\n# import matplotlib.pyplot as plt\n  \n# # define custom transform function\n# transform = transforms.Compose([\n#     transforms.ToTensor()\n# ])","603953f4":"# img_tr = transform(img)\n  \n# # calculate mean and std\n# mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n  \n# # print mean and std\n# print(\"mean and std before normalize:\")\n# print(\"Mean of the image:\", mean)\n# print(\"Std of the image:\", std)","f1719f8e":"stats = ([0.4394, 0.4273, 0.2157],[0.2932, 0.3182, 0.2477])\ndef denormalize(images, means, stds):\n    means = torch.tensor(means).reshape(1, 3, 1, 1)\n    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n    return images * stds + means\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        denorm_images = denormalize(images, *stats)\n        ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0,1))\n        break","4f64c9bd":"show_batch(train_dl)","9e6899ca":"def get_default_device():\n    #If GPU is available, otherwise CPU\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\ndef to_device(data, device):\n    #to move tensors to chosen device\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device)for x in data]\n    return data.to(device, non_blocking=True)\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n        \n    \n    ","f60b9fe9":"device = get_default_device()\ndevice","14badf22":"train_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","7cd709a3":"import torch.nn as nn\nimport torch.nn.functional as F","18282435":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))        \n        \n    ","db66b0a8":"for images, labels in train_dl:\n    print('images shape is: ', images.shape)\n    break","fe1a86d2":"class Monley_classification(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 32 x 32\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 16 x 16\n\n#             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n\n            nn.Flatten(), \n            nn.Linear(256*16*16, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)            \n            ","6fa3763e":"model = Monley_classification()\nmodel","ba792282":"model.to(device)","5bf84169":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","a8060de8":"#??nn.flatten","88b9567c":"!pip install torchsummary","3597423e":"from torchsummary import summary ","126b66f6":"from torchsummary import  summary\nmodel.to(device) # move the model to GPU\n# summary(model,input_size=(3 , 64 , 64))","70f5d58d":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","ccf38db5":"model = to_device( Monley_classification(), device)","7c156c99":"evaluate(model, valid_dl)","a69d6f8a":"num_epochs = 20\nopt_func = torch.optim.Adam\nlr = 0.0009","5bc6b948":"history = fit(num_epochs, lr, model, train_dl, valid_dl, opt_func)","b6bf6a2f":"#??torch.optim","dc421680":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","410f8a19":"plot_accuracies(history)","6f53197c":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","317711e8":"plot_losses(history)","471ca6be":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return val_data.classes[preds[0].item()]","ce19c33e":"img, label = val_data[0]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', val_data.classes[label], ', Predicted:', predict_image(img, model))","9be6b385":"torch.save(model.state_dict(), 'monkey_classification.pth')","e5eefbe4":"# model2 = to_device(Cifar10CnnModel(), device)\n# model2.load_state_dict(torch.load('cifar10-cnn.pth'))","422c1810":"## Creating training and Validation data loaders","a461e7e1":"Now, i will instantiate the model and test of the validation set to get an initial estimate. ","61269cae":"## Saving the model","11c873de":"## Testing against individual images","0bd03454":"Looking inside one of the 10 classes (i.e. one of the 10 monkey species).","12ff9e30":"To load the model weights mapped to the correct attributes:","d74ba37f":"## Creating show_batch Function","3ddf41bc":"## Training the model\nWe'll define two functions: fit and evaluate to train the model using gradient descent and evaluate its performance on the validation set.","c0b9b58c":"The above result indicates, that image 2 of the training dataset has label 0 i.e. it belongs to species no. 1 and it has 3 color channels (RGB) and the dimensions are 64*64 pixels","29a9ddd4":"We can now wrap our training and validation data loaders using DeviceDataLoader for automatically transferring batches of data to the GPU (if available).","19a473b3":"## Defining the convolution model","52e97098":"## Creating a function to transform files","64e11d88":"## Plotting historic accuracy and losses against epoch curve","448238d9":"## Importing input data into test and validation directories","b68dc06a":"Looking at some of the images in training and validation datasets.","df078104":"\nWe'll use `nn.Sequential` to chain the layers and activations functions into a single network architecture.","47fbcba9":"## Creating GPU functions based on availability","fb5037f6":"Clearly the initial accuracy is 10.29%. As the model was randomly initialised, now time for tuning the parameters.","6f3e98fa":"## Introduction to the project\nClassifying images of monkeys into 10 classes (species) based on the public dataset on Kaggle. Algorithm used here in CNN. \nHeartfelt thanks to my friend [Kandhal Khandeka](https:\/\/www.kaggle.com\/kandhalkhandeka) without whose support this would not have been possible.","d30598a0":"## Function for viewing images","92d196a3":"## Importing necessary libraries","bdca6855":"Taking a minute to verify that the inputs and outputs are coherent. "}}