{"cell_type":{"da11817e":"code","04d72948":"code","6ba93da6":"code","61a088b6":"code","1bf3717f":"code","c93bd165":"code","b7af8c7c":"code","6e327c3c":"code","56b5f05a":"code","64787426":"code","de59b6f3":"markdown","3707697f":"markdown"},"source":{"da11817e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04d72948":"def displayWide(df):\n    pd.set_option('display.max_colwidth', 0)\n    display(df)\n    pd.set_option('display.max_colwidth', 50)\ndef displayAll(df):\n    pd.set_option('display.max_rows', None)\n    display(df)\n    pd.set_option('display.max_rows', 10)\ndef displayAllWide(df):\n    pd.set_option('display.max_rows', None)\n    pd.set_option('display.max_colwidth', 0)\n    display(df)\n    pd.set_option('display.max_rows', 10)\n    pd.set_option('display.max_colwidth', 50)","6ba93da6":"from google.cloud import bigquery\nclient = bigquery.Client()\ndataset_ref = client.dataset(\"google_analytics_sample\", project=\"bigquery-public-data\")\ndataset = client.get_dataset(dataset_ref)","61a088b6":"tables = list(client.list_tables(dataset))\nfor table in tables:  \n    print(table.table_id)","1bf3717f":"# Construct a reference to the first table\ntable_ref = dataset_ref.table(\"ga_sessions_20160801\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)","c93bd165":"#Run cell\n#See shema output\nschema = table.schema\nschema","b7af8c7c":"# Use autocomplete feature to see available fields:\n# (Put cursor at the end of the following line then press tab)\n#schema[0].","6e327c3c":"df_head = client.list_rows(table, max_results=5).to_dataframe()\n# displayWide(df_head)  #Uncomment to see all fields \ndf_head","56b5f05a":"# Query to estimate\nquery = \"\"\"\nSELECT fullVisitorId, totals.timeOnSite  \n  FROM `bigquery-public-data.google_analytics_sample.ga_sessions_20160801` \n\"\"\"\n\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job = client.query(query, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))","64787426":"#Execute query and return dataframe\n\nquery_job = client.query(query)\ndf_result = query_job.to_dataframe()\ndf_result","de59b6f3":"# Inspect Tables and Schema","3707697f":"## Query formatting:\n\n    * Use backticks ` when specifying Alias or other identifiers"}}