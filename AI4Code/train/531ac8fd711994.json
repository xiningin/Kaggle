{"cell_type":{"3ecc751f":"code","301a0ace":"code","ff33c84c":"code","ccb5cdce":"code","5842b3b0":"code","aff12c4b":"code","025fc9d7":"code","28c4d3a9":"code","d2d673d9":"code","b9db4a85":"code","af3e6b9e":"code","0f9a257c":"code","efd020c3":"code","f7f0b04c":"code","07ac9b33":"code","4cd46457":"code","2c966227":"code","f42fa6ea":"code","906f5352":"code","d031f9f1":"code","79323ccb":"code","03ef9910":"code","7dc88772":"code","6480ad1f":"markdown","a27a0145":"markdown"},"source":{"3ecc751f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os # for file editing\nimport shutil # for console commands\n#print(os.listdir(\"..\/input\"))","301a0ace":"#function for downloading from URL \n# if you are using Kaggle, make sure to turn on internet connection and GPU\nimport tarfile\nimport urllib\n# this snippet of code is modified for our use case with additional comments, original source code:\n# https:\/\/github.com\/tflearn\/tflearn\/blob\/master\/tflearn\/datasets\/cifar10.py\ndef download(filename, source_url, work_directory):\n    if not os.path.exists(work_directory): #check if the folder exists; if not make dir\n        os.mkdir(work_directory)\n    filepath = os.path.join(work_directory, filename)\n    if not os.path.exists(filepath): # check if file exists; if not, download\n        print(\"Downloading file, Please wait...\")\n        filepath, _ = urllib.request.urlretrieve(source_url + filename, # this is a function to download files\n                                                 filepath)\n        statinfo = os.stat(filepath)\n        print(('Succesfully downloaded', filename, statinfo.st_size, 'bytes.'))\n        untar(filepath,work_directory)\n    return filepath","ff33c84c":"#only extract jpg files\ndef jpg_files(members):\n    for tarinfo in members:\n        if os.path.splitext(tarinfo.name)[1] == \".jpg\":\n            yield tarinfo","ccb5cdce":"# extract function\ndef untar(fname,path=\"17category-flowers-py\"): #untarring the archive\n    tar = tarfile.open(fname)\n    tar.extractall(path=\"17category-flowers-py\", members=jpg_files(tar))\n    tar.close()\n    if path is \"\":\n        print(\"File Extracted in Current Directory\")\n    else:\n        print(\"File Extracted in to \",  path)","5842b3b0":"download(\"17flowers.tgz\", \"http:\/\/www.robots.ox.ac.uk\/~vgg\/data\/flowers\/17\/\",\"17category-flowers-py\")","aff12c4b":"os.listdir(\"..\/working\/17category-flowers-py\/\") #jpg folder should be available","025fc9d7":"from PIL import Image #show one example of image\nImage.open(\"..\/working\/17category-flowers-py\/jpg\/image_0002.jpg\")","28c4d3a9":"#load images as np arrays\ndef load_data(fpath):    \n    img=Image.open(fpath).resize((224,224)) # resize to 224x224 for training purposes\n    img = np.asarray(img, dtype='float32')\n    return img","d2d673d9":"#all images are loaded as np arrays\nimages=[]\nlabels=[]\ntotal=1361\nj=1\nfor i in range(1, total): \n    fname=\"..\/working\/17category-flowers-py\/jpg\/image_\"    \n    fpath = os.path.join(fname + str(i).zfill(4) + \".jpg\")\n    images.append(load_data(fpath))\n    labels.append(j) #labels are created as well\n    if i%80==0: j+=1","b9db4a85":"images = np.asarray(images) # all of the images are converted to np array of (1360,224,224,3)\nlabels = np.asarray(labels).reshape(1360,1) # labels are also converted to (1360,1)\nimages.shape","af3e6b9e":"# split data into training and test\nfrom sklearn.model_selection import train_test_split \ntrain_images, test_images, train_labels, test_labels = train_test_split(images, labels, train_size = 0.8, random_state =  104)","0f9a257c":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,10)) # plot 25 images\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i]\/255, cmap=plt.cm.binary)\n    plt.xlabel(train_labels[i])","efd020c3":"# dividing images into train and test folders by creating images from arrays\nimport cv2\nimport numpy as np\ndef create_images(data, labels, folder):\n    dirname=folder\n    \n    if not os.path.exists(dirname): #check if the folder exists; if not make dir\n      os.mkdir(dirname)\n    n=0\n    \n    for i in data:\n      label_n=labels[n][0]\n      subfolder = folder + \"\/\" + str(label_n) \n      if not os.path.exists(subfolder): # create subfolders with categories\n          os.mkdir(subfolder)  \n      filepath =  subfolder + \"\/\" + str(n)+ \".jpg\"\n      cv2.imwrite(filepath, data[n]) #save image to corresponding subfolders\n      n+=1","f7f0b04c":"create_images(train_images, train_labels, 'train') #save image to corresponding subfolders\ncreate_images(test_images, test_labels, 'test')","07ac9b33":"train_dir =os.path.realpath('train')\nvalidation_dir = os.path.realpath('test')\nimage_size = 224","4cd46457":"# use vgg16 pre-trained model with trainable densely connected output layer\n\nfrom keras.applications import VGG16\n#Load the VGG model\nvgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n\n# Freeze all the layers except for the last layer: \nfor layer in vgg_conv.layers[:-4]:\n    layer.trainable = False\n \nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\n \n# Create the model\nmodel = models.Sequential()\n \n# Add the vgg convolutional base model\nmodel.add(vgg_conv)\n \n# Add new layers\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(17, activation='softmax'))\nmodel.summary() \n","2c966227":"# image augmentation for train set and image resizing for validation\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator( # this function will generate augmented images in real time\n      rescale=1.\/255,\n      rotation_range=20,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n \nvalidation_datagen = ImageDataGenerator(rescale=1.\/255) # for validation we don't need to augment\n\ntrain_batchsize = 100\nval_batchsize = 10\n \ntrain_generator = train_datagen.flow_from_directory( # this function takes images from folders and feeds to Imagedatagenerator\n        train_dir,\n        target_size=(image_size, image_size),\n        batch_size=train_batchsize,\n        class_mode='categorical')\n \nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(image_size, image_size),\n        batch_size=val_batchsize,\n        class_mode='categorical',\n        shuffle=False)","f42fa6ea":"model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-4), # learning rate should be small so previously learned weights don't vanish\n              metrics=['acc', 'top_k_categorical_accuracy'])","906f5352":"# train the model with augmented images in real-time\n# make sure your GPU is available, otherwise training can take longer\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=train_generator.samples\/train_generator.batch_size ,\n      epochs=50,\n      validation_data=validation_generator,\n      validation_steps=validation_generator.samples\/validation_generator.batch_size,\n      verbose=0)","d031f9f1":"print('training acc.:',history.history['acc'][-1],'\\n','test acc.:', (history.history['val_acc'])[-1])","79323ccb":"print(' training top 5:',history.history['top_k_categorical_accuracy'][-1], '\\n',\n      'val top 5:', history.history['val_top_k_categorical_accuracy'][-1], '\\n')","03ef9910":"# plot the accuracy history\nimport matplotlib.pyplot as plt\ndef plot_history(history):\n plt.figure()\n plt.xlabel('Epoch')\n plt.ylabel('Accuracy %')\n plt.plot(history.epoch, np.array(history.history['acc']),\n label='Train Accuracy')\n plt.plot(history.epoch, np.array(history.history['val_acc']),\n label = 'Val Accuracy')\n plt.legend()\n plt.ylim([0.5, 1])\nplot_history(history)","7dc88772":"# remove dataset files\nimport shutil\nshutil.rmtree(os.path.realpath('17category-flowers-py')) \nshutil.rmtree(os.path.realpath('train'))\nshutil.rmtree(os.path.realpath('test'))","6480ad1f":"## Loading image datasets from URL and Transfer learning for image classification using TensorFlow","a27a0145":"Most of the examples for image classification use cifar10 or MNIST image datasets that are in ready to use format. What if we have .jpg image files? This sort of tasks might be rudimentary for experienced data scientists but beginners might find such tasks difficult because of the lack of full fledged examples. They might find snippets of codes that are scattered across Stack exchange and adopting those snippets also require some proficiency in coding. Therefore, I obliged myself to provide a complete example in which we download image dataset in archive format from a URL, load it to our existing pre-trained model and train the model further to classify our image categories.    \nI assume the readers have some familiarity with Deep Learning and Tensorflow concepts. \nThe dataset in this code comes from http:\/\/www.robots.ox.ac.uk\/~vgg\/data\/flowers\/17\/. It contains 1360 images of 17 flower categories. Each flower category has 80 images. We will use existing VGG16 pre-trained model without the last output layer to train it on our images.  Since we import the model without the last layer, we will be freezing all its layers except for the last one as we need pre-trained weights for our small dataset to adapt. We add our densely connected layer before the output layer, so our transferred model learns the flower dataset. Then we use softmax for predicting 17 categories. \nAs we will see, the model is showing around 94% accuracy for validation sets. This means we don't have overfitting issues. However, we could improve the model by adding L1, L2 regularization and dropouts.  "}}