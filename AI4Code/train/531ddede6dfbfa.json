{"cell_type":{"28d4acf0":"code","33c2b1a7":"code","62cc85c1":"code","3d100c1c":"code","f5ac6fed":"code","0e9cddda":"code","d3275d1a":"code","79ce96ff":"code","d9b0ce38":"code","38dafd77":"code","25943c53":"code","f57a4137":"code","0049d7e5":"code","4e367ab7":"code","923f99b9":"markdown","c3ecd0d6":"markdown","52900fa8":"markdown","64ec682d":"markdown","3c0590ee":"markdown","fbfbcbbc":"markdown","47ca6094":"markdown","dd44f18b":"markdown","9385d5d8":"markdown","02fddcec":"markdown"},"source":{"28d4acf0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n%pylab inline\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 22,10\n\nimport datetime\n\n#SERIE AND ARIMA MODEL LIBRARIES\nfrom pandas import Series\nfrom pandas.tools.plotting import autocorrelation_plot\nimport statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport warnings\nimport itertools\nwarnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n\nprint(os.listdir(\"..\/input\"))","33c2b1a7":"dataset = pd.read_csv(\"..\/input\/pollution.csv\") #import dataset pollution\nprint(\"Dataset has \"+str(dataset.shape[0])+\" rows and \"+str(dataset.shape[1])+\" attributes, with \"+str(dataset['pm2.5'].isna().sum())+\" NaN in pm2.5 column\") #print number rows and attribute\ndataset.head(3) #print only first 3 DF rows","62cc85c1":"dataset.hist(figsize=(22,10)) #create all histograms for each attributes\nplt.show()","3d100c1c":"#deleted January month bacause pm2.5 is everytime equals to zero\ndataset = dataset.drop(dataset[(dataset[\"year\"]==2010) & (dataset[\"month\"]==1) & (dataset[\"day\"]==1)].index) #take index rows\ndataset = dataset.drop(axis=1, labels=\"No\")\ndataset.head(2)","f5ac6fed":"#select only values : date, pm2.5 and set datetime how \ndataset = dataset[[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\"]] #take in pollution dataset only 4 columns\ndate_hour = pd.to_datetime(dataset[[\"year\",\"month\",\"day\",\"hour\"]]) #transform it in datetime\npollution = dataset.set_index(date_hour)#set index equal to datetime\npollution = pollution[[\"pm2.5\"]] #transform dataset in only one column\n\n#transform zero value in NaN and after delete it\npollution = pollution.replace(0, pd.np.nan)\npollution = pollution.dropna()\n\nprint(pollution.head(3)) #print first 3 rows","0e9cddda":"#plot pm2.5 time series\nseries = Series(pollution[\"pm2.5\"].values,index=pollution.index)\nseries.plot(figsize=(22,10))\nplt.title('PM2.5 FROM 2010 TO 2015')\nplt.show()\nprint(series.describe())","d3275d1a":"#a function to evaluate the ARIMA model\ndef evaluate_arima_model(X, arima_order):\n    # prepare training dataset\n    train_size = int(len(X) * 0.70)\n    train, test = X[0:train_size], X[train_size:]#split serie in 70% train set e 30% test\n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    for t in range(len(test)):\n        model = ARIMA(history, order=arima_order) #call ARIMA \n        model_fit = model.fit(disp=0)\n        yhat = model_fit.forecast()[0]\n        predictions.append(yhat)\n        history.append(test[t])\n    # calculate out of sample error\n    mse = mean_squared_error(test, predictions)\n    result ={}\n    result['model_fit']=model_fit\n    result['mse']=mse\n    result['prediction']=predictions\n    result['test']=test\n    result['train']=train\n    result['acc']= accuracy_score(round(pd.Series((v[0] for v in test))),round(pd.Series((v[0] for v in predictions))))\n    return result\n    ","79ce96ff":"# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype('float32')\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    mse = evaluate_arima_model(dataset, order)\n                    acc = mse['acc']\n                    mse = mse['mse']\n                    if mse < best_score:\n                        best_score, best_cfg = mse, order\n                    print('ARIMA'+str(order)+' MSE= '+str(mse)+' and ACCURACY= '+str(acc))\n                except:\n                    continue\n    print('Best ARIMA %s MSE= %.3f' % (best_cfg, best_score))","d9b0ce38":"# evaluate parameters\np = [0, 1, 2, 4, 6, 8, 10]\nd = range(0, 3)\nq = range(0, 3)\n\n#I have eliminated 0 value because there was an error \"SVG  error\"\ndf = pollution\ndf = df[:1000] #with this selection, I select only 1.000 records\n\nautocorrelation_plot(df.values)\n\n#evaluate_models(df.values, p, d, q) #il modello migliore ha i parametri ARIMA(1, 0, 0) MSE=3180.066","38dafd77":"arima_model_1 = evaluate_arima_model(df.values,(1,0,0))\nmodel_fit = arima_model_1['model_fit']\n# save model\n#model_fit.save('model.pkl')\n\nprint(\"Mean Square Eerror: \"+str(arima_model_1['mse']))\nprint(\"Accuracy: \"+str(arima_model_1['acc']))#l'accuratezza non potr\u00e0 mai essere alta in variabili continue","25943c53":"prediction = pd.Series( (v[0] for v in arima_model_1['prediction']))\ntest = pd.Series((v[0] for v in arima_model_1['test']))\ntrain = pd.Series((v[0] for v in arima_model_1['train']))\n\nfig = plt.figure(figsize=(22,10))\nax = fig.add_subplot(1, 1, 1)\nax.plot(test,label=\"Test set\")\nax.plot(prediction,label=\"Prediction set\")\nax.legend()\nplt.show()\n\n#fig.savefig('prediction_test.png')   # save the figure to file\n#plt.close(fig)","f57a4137":"# evaluate parameters\np = [0, 1, 2, 4, 6, 8, 10]\nd = range(0, 3)\nq = range(0, 3)\n\n#I have eliminated 0 value because there was an error \"SVG  error\"\ndf = pollution\ndf = df[:1000]\nscaler = MinMaxScaler()\nscaler.fit(df)\ndf = scaler.transform(df)\n\n#evaluate_models(df, p, d, q) #ARIMA(1, 0, 0)","0049d7e5":"arima_model_2 = evaluate_arima_model(df,(1,0,0))\nmodel_fit = arima_model_2['model_fit']\n# save model\n#model_fit.save('model.pkl')\n\nprint(\"Mean Square Error: \"+str(arima_model_2['mse']))\nprint(\"Accuracy: \"+str(arima_model_2['acc']))#l'accuratezza non potr\u00e0 mai essere alta in variabili continue","4e367ab7":"prediction = pd.Series( (v[0] for v in arima_model_2['prediction']))\ntest = pd.Series((v[0] for v in arima_model_2['test']))\ntrain = pd.Series((v[0] for v in arima_model_2['train']))\n\nfig = plt.figure(figsize=(22,10))\nax = fig.add_subplot(1, 1, 1)\nax.plot(test,label=\"Test set\")\nax.plot(prediction,label=\"Prediction set\")\nax.legend()\nplt.show()\n\n#fig.savefig('model2.png')   # save the figure to file\n#plt.close(fig)","923f99b9":"<H2>DATASET DESCRIPTION<\/H2>\nDataset contains daily surveys about  pollution. It's composed by 13 columns (attributes).\n1. **No:**  numero riga\n2. **year:** anno rilevazione\n3. **month:** mese rilevazione\n4. **day: ** giorno rilevazione\n5. **hour: ** ora della rilevazione\n6. **pm2.5:** concentrazione di PM2.5\n7. **DEWP:** Dew Point\n8. **TEMP:** Temperatura\n9. **PRES: ** Pressione\n10. **cbwd:** Direzione del vento combinato\n11. **Iws: ** Ore comulative di vento\n12. **Is:** Ore comulative di neve\n13. **Ir:** Ore comulative di pioggia\n","c3ecd0d6":"I develop a method to search ARIMA hyperparameters for a one-step rolling forecast.\nThe approach is broken down into two parts:\n1. Evaluate an ARIMA model.\n2. Evaluate sets of ARIMA parameters.","52900fa8":"After this I've selected only the attribute pm2.5, year, month ,day, hour. The last 4 attributes have been used for dataframe index. The zero values  produces an error and for this reason I have deleted all rows with zero.","64ec682d":"After the trasformation the accuracy increase a lot. With or without trasformation,prediction is the same but in different scale ","3c0590ee":"**TEST 2 WITH DATA NORMALIZATION (MinMAxScaler) **","fbfbcbbc":"**TEST 1 WITHOUT DATA NORMALIZATION**","47ca6094":"<H2>DATA CLEANING<\/H2>\nFor the Data Cleaning , I have selected different rows from year =2010, month=1 and day==1 because in this period all values are NaN","dd44f18b":"Even though the Mean Square Error is too big, the prediction plot is similar to test prediction plot. ","9385d5d8":"<H2>SIMPLE ARIMA TUTORIAL<\/H2>","02fddcec":"<H2>ARIMA MODEL<\/H2>\nOne of the most common methods used in time series forecasting is known as the ARIMA model, which stands for AutoregRessive Integrated Moving Average. ARIMA is a model that can be fitted to time series data in order to better understand or predict future points in the series. There are three distinct integers (p, d, q) that are used to parametrize ARIMA models:\n* <b>p(AR)<\/b> is the auto-regressive(AR) part of the model. It allows us to incorporate the effect of past values into our model. Intuitively, this would be similar to stating that it is likely to be warm tomorrow if it has been warm the past 3 days.\n* <b>d(I)<\/b> is the integrated(I) part of the model. This includes terms in the model that incorporate the amount of differencing (i.e. the number of past time points to subtract from the current value) to apply to the time series. Intuitively, this would be similar to stating that it is likely to be same temperature tomorrow if the difference in temperature in the last three days has been very small.\n* <b>q(MA)<\/b> is the moving average(MA) part of the model. This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past."}}