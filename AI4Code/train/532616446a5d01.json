{"cell_type":{"65577a6d":"code","10ebb694":"code","63086533":"code","716ee59e":"code","fcf22026":"code","8d7abf20":"code","68c7b542":"code","8490ab97":"code","124a922e":"code","88f34aa2":"code","2e806029":"code","f4899178":"code","89be5d84":"code","f97d5ae0":"code","951e1bbf":"code","cab12770":"code","9f09214d":"code","7c55647d":"code","cd2c2c8f":"code","0d0e8fc2":"code","a8b19e5f":"code","c99a0a25":"code","6b7b90a5":"code","af6e50b1":"code","a83edabb":"code","45122d88":"code","e4022ac4":"code","36f62558":"code","f8c94f58":"code","e4c1a658":"code","be81f87d":"code","467fe3c8":"code","09899db6":"code","71aa0b38":"code","e19d3062":"code","9630c195":"code","6c3cf236":"code","870a3a4e":"code","897b0f64":"markdown","d34152ae":"markdown","e5e1fd34":"markdown","86c6632e":"markdown","e8e8e7dd":"markdown","f92543f3":"markdown","c1115cca":"markdown","583d2741":"markdown"},"source":{"65577a6d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","10ebb694":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport catboost\nfrom catboost import Pool\nimport xgboost\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV","63086533":"df = pd.read_csv('\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv')","716ee59e":"df.head()","fcf22026":"df.columns","8d7abf20":"#df.columns = ['city', 'area', 'rooms', 'bathroom', 'parking spaces', 'floor',\n#       'animal', 'furniture', 'hoa', 'rent amount',\n#       'property tax', 'fire insurance', 'total']","68c7b542":"def categorise(data,cols):\n    object_cols = []\n    num_cols = []\n    for i in cols:\n        if data[i].dtype == 'object':\n            object_cols.append(i)\n        else:\n            num_cols.append(i)\n    return object_cols, num_cols","8490ab97":"object_cols, num_cols = categorise(df,df.columns)\nobject_cols, num_cols","124a922e":"df.isnull().sum()","88f34aa2":"df['city'].unique()","2e806029":"df['floor'].unique()","f4899178":"df.loc[df['floor'] == '-', 'floor'] = 0\ndf['floor'] = df['floor'].astype('int64')","89be5d84":"df['animal'].unique()","f97d5ae0":"df['furniture'].unique()","951e1bbf":"sns.boxplot(data=df['rent amount (R$)'])","cab12770":"df1 = df.copy()","9f09214d":"df1.head()","7c55647d":"def remove_outlier(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    return df_out","cd2c2c8f":"df2 = remove_outlier(df1, 'rent amount (R$)')","0d0e8fc2":"df2.shape","a8b19e5f":"sns.boxplot(data=df['rent amount (R$)'])","c99a0a25":"# Lets take a look on how our data was distributed before and after treat outliers\n\nplt.figure(1, figsize=(20, 10))\nplt.subplot(2, 2, 1)\nsns.distplot(df['rent amount (R$)'])\nplt.title('Before Removing Outliers')\nplt.subplot(2, 2, 2)\nsns.distplot(df2['rent amount (R$)'])\nplt.title('After Removing Outliers')","6b7b90a5":"num_cols1 = ['rooms', 'bathroom', 'parking spaces']\nplt.figure(figsize=(20, 5))\nsns.set(style = 'whitegrid')\ni = 1\nfor feature in num_cols1:\n    plt.subplot(2, 3, i)\n    sns.barplot(x = feature, y= 'rent amount (R$)', data=df2)\n    i+=1\nplt.tight_layout()","af6e50b1":"# now let's see the correlation between features\nplt.figure(figsize=(12,12))\nsns.heatmap(df2.corr(), annot=True, cmap='RdBu_r', linecolor='black',vmin=-1, vmax=1)","a83edabb":"lev_enc = LabelEncoder()\ndf2['animal']=lev_enc.fit_transform(df2['animal'])\ndf2['furniture']=lev_enc.fit_transform(df2['furniture'])","45122d88":"df2.head()","e4022ac4":"hot_enc = pd.get_dummies(df2['city'])","36f62558":"df_final = pd.concat([df2, hot_enc], axis=1)","f8c94f58":"df_final.drop(['city'], axis=1, inplace=True)","e4c1a658":"df_final.head(10)","be81f87d":"columns = ['Belo Horizonte','Campinas', 'Porto Alegre', 'Rio de Janeiro', 'S\u00e3o Paulo', 'rooms', 'bathroom', 'parking spaces', 'fire insurance (R$)',\n        'furniture']\nX = df_final[columns]\ny = df_final['rent amount (R$)']","467fe3c8":"X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=0)","09899db6":"X.info()","71aa0b38":"train_pool = Pool(\n                data = X_train,\n                label = y_train,\n)\nvalid_pool = Pool(\n                data = X_valid,\n                label = y_valid,\n)","e19d3062":"model = catboost.CatBoostRegressor(custom_metric= ['R2', 'RMSE'], learning_rate=0.1, n_estimators=264)\nmodel.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)","9630c195":"# we create a list to storage all the results for later visualization\nacc = []\n# parameters are the alpha's that we will use to perform the GridSearch\nparameters1= [{'alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000, 10000, 100000, 100000]}]\n# on the regressors we define the models that we want use\nregressors = {'Linear Regression': LinearRegression(),\n              'Ridge Model': Ridge(alpha=0.1),\n              'Decision Tree': DecisionTreeRegressor(),\n              'Random Forest': RandomForestRegressor(random_state=1),\n              'SVR': SVR(),\n              'KNN': KNeighborsRegressor(),\n              'Lasso': Lasso(),\n              'GridSearchRidge': GridSearchCV(Ridge(), parameters1, cv=4),\n              'GridSearchLasso': GridSearchCV(Lasso(), parameters1, cv=4)\n             }","6c3cf236":"# now we perform a loop with each regressor to perform the model, predict the rent \n# and extract the metrics\nfor i in regressors:\n    model = regressors.get(i)\n    # here we create a condition because for grid we want to perform the model with the best estimator\n    if i == 'GridSearchRidge' or i == 'GridSearchLasso':\n        model.fit(X_train, y_train).best_estimator_ \n    model.fit(X_train, y_train)\n    prediction = model.predict(X_valid)\n    print(i)\n    print('MAE:', mean_absolute_error(y_valid, prediction))\n    print('RMSE:', np.sqrt(mean_squared_error(y_valid, prediction)))\n    print('R2:', r2_score(y_valid, prediction))\n    print('*' * 40)\n    acc.append([i, mean_absolute_error(y_valid, prediction), np.sqrt(mean_squared_error(y_valid, prediction)), r2_score(y_valid, prediction)])\n","870a3a4e":"# now let's follow the same loop and visualize the plot's for each regressor\nj = 1\nplt.figure(figsize=(20,10))\nfor i in regressors:\n    model = regressors.get(i)\n    model.fit(X_train, y_train)\n    prediction = model.predict(X_valid)\n    plt.subplot(3, 3, j)\n    plt.title(i)\n    ax1 = sns.distplot(y_valid,hist=False,kde =True,color =\"r\",label =\"Actual Value\")\n    sns.distplot(prediction ,color =\"b\",hist = False,kde =True, label = \"Predicted Value\",ax =ax1).set_title(i)\n    j+=1\nplt.tight_layout(pad = 0.5)","897b0f64":"For 'animal' and 'furniture', we'll use label  encorder as they have 2 unique values only.","d34152ae":"Since, 'city' column contains 5 different values, so we'll use one_hot_encorder.","e5e1fd34":"# Removing outliers","86c6632e":"Clearly, data not contains any NaN values. Let's check what all different values the object_cols has.","e8e8e7dd":"'floor' contains '-', it has to be removed. ","f92543f3":"**We can see that there are some outliers, so we have to remove them**","c1115cca":"# Checking for outliers","583d2741":"So, four columns i.e. 'city', 'floor', 'animal', 'furniture' have values other than a numerical one. Now, let's first check if the data contains any NaN values."}}