{"cell_type":{"7bed5f52":"code","da7e7be2":"code","0527800a":"code","3538de02":"code","df9067da":"code","2564a6e6":"code","3986d96e":"code","d7d35f38":"code","d23a3e35":"code","721adb0d":"code","305b8855":"code","ac7b8c9e":"code","59ff58e2":"code","f2ae4e6c":"code","f2c65bc9":"code","24d25d87":"code","bc1a07cd":"code","a4304e7e":"code","457214be":"code","ad48b4d0":"code","2cb8a98e":"code","8cd860b5":"code","890f2147":"code","580d0239":"code","5518d210":"code","70dbe756":"code","6e5ea4b1":"code","9a7ea21d":"code","00fc946a":"code","76fbb712":"code","43a9aabf":"code","39c4a5dc":"code","a150095b":"code","7aa64c2a":"code","ed445d3d":"code","2d4c5222":"code","7fbbf580":"code","bc667fa3":"code","b7d1eba2":"code","a251f3dd":"code","01a150bd":"code","2d29569e":"code","41615ca3":"code","84284cd1":"code","fbd98b6f":"code","435c89b2":"code","116c0472":"code","f44551b6":"code","80367f37":"code","6832fb9a":"code","8f231f28":"code","f2a75eb1":"code","4d1bc2b8":"code","e76e19c2":"markdown","b851d150":"markdown","30fc98e7":"markdown","00508973":"markdown","27fb22c4":"markdown","391ec060":"markdown","7771f735":"markdown"},"source":{"7bed5f52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport plotly.express as px\nfrom warnings import filterwarnings as filt \nfrom scipy.stats import skew, norm \n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12, 6)\nfilt('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da7e7be2":"base_path = \"..\/input\/tabular-playground-series-dec-2021\"\nbase_path2 = \"..\/input\/forest-cover-type-prediction\"","0527800a":"traindf = pd.read_csv(f'{base_path}\/train.csv')\ntraindf2 = pd.read_csv(f'{base_path2}\/train.csv')\ntestdf = pd.read_csv(f'{base_path}\/test.csv')\n\ntraindf.shape, traindf2.shape, testdf.shape","3538de02":"pd.options.display.max_columns = None\ntraindf.head()","df9067da":"pd.DataFrame(traindf.isnull().sum(), columns = ['null count']).T","2564a6e6":"print('Unique cover type in traindf   : ', sorted(traindf.Cover_Type.unique()))\nprint('Unique cover type in traindf 2 : ', sorted(traindf2.Cover_Type.unique()))","3986d96e":"df = traindf.copy()\ndf2 = traindf2.copy()\n\nlabel_rename = {\n    1 : 'Spruce\/Fir',\n    2 : 'Lodgepole Pine',\n    3 : 'Ponderosa Pine',\n    4 : 'Cottonwood\/Willow',\n    5 : 'Aspen',\n    6 : 'Douglas-fir',\n    7 : 'Krummholz',\n}\n\ndf['Cover_Type']  = df.Cover_Type.replace(label_rename)\ndf2['Cover_Type'] = df2.Cover_Type.replace(label_rename) ","d7d35f38":"cover_counts = df.Cover_Type.value_counts()\npx.bar(x = cover_counts.index, y = cover_counts, color = cover_counts.index, title = 'Cover Type Count in df')","d23a3e35":"cover_counts","721adb0d":"cover_counts2 = df2.Cover_Type.value_counts()\npx.bar(x = cover_counts2.index, y = cover_counts2, color = cover_counts2.index, title = 'Cover Type Count in df 2')","305b8855":"cotton_aspen = traindf2[(traindf2.Cover_Type == 4) | (traindf2.Cover_Type == 5)]\ncotton_aspen.Cover_Type.unique()","ac7b8c9e":"traindf = pd.concat([traindf, cotton_aspen]).reset_index(drop = True)\ncover_counts3 = traindf.Cover_Type.value_counts()\npx.bar(x = cover_counts3.index, y = cover_counts3, color = cover_counts3.index, title = 'Cover Type Count after merging')","59ff58e2":"traindf['Cover_Type'] = traindf.Cover_Type.apply(lambda x : x - 1)","f2ae4e6c":"traindf.Cover_Type.unique()","f2c65bc9":"from sklearn.manifold import TSNE\nfrom sklearn.model_selection import train_test_split\n\ndef sample(x, y, fold):\n    xt, x, yt, y = train_test_split(x, y, stratify = y, test_size = fold)\n    return x, y\n\ndef plot_3d(x, y, params, fold = 1):\n    if fold < 1:\n        x, y = sample(x, y, fold)\n    tsne = TSNE(**params, verbose = 1)\n    xt = pd.DataFrame(tsne.fit_transform(x), index = x.index, columns = ['x', 'y', 'z'])\n    xt['target'] = y \n    return px.scatter_3d(data_frame = xt, x = 'x', y = 'y', z = 'z', color = 'target')","24d25d87":"df = traindf.copy()\n\nlabel_rename = {\n    1 : 'Spruce\/Fir',\n    2 : 'Lodgepole Pine',\n    3 : 'Ponderosa Pine',\n    4 : 'Cottonwood\/Willow',\n    5 : 'Aspen',\n    6 : 'Douglas-fir',\n    7 : 'Krummholz',\n}\n\ndf['Cover_Type']  = df.Cover_Type.apply(lambda x : x + 1).replace(label_rename)","bc1a07cd":"params = {\n    'n_components' : 3,\n    'n_iter' : 2500,\n    'learning_rate' : 150,\n    'perplexity' : 35\n}\n# plot_3d(df.drop(['Cover_Type'], axis = 1), df.Cover_Type, params, 0.005)","a4304e7e":"px.scatter_3d(data_frame = df, x = 'Hillshade_9am', y = 'Hillshade_3pm', z = 'Hillshade_Noon', color = 'Cover_Type', title = 'Forest Cover Hillshades')","457214be":"hillshade_9am = df.groupby('Cover_Type')['Hillshade_9am'].mean().sort_values(ascending = False)\npx.bar(x = hillshade_9am.index, y = hillshade_9am, color = hillshade_9am.index, title = 'hillshade 9am for different cover types')","ad48b4d0":"hillshade_3pm = df.groupby('Cover_Type')['Hillshade_3pm'].mean().sort_values(ascending = False)\npx.bar(x = hillshade_3pm.index, y = hillshade_3pm, color = hillshade_3pm.index, title = 'hillshade 3pm for different cover types')","2cb8a98e":"hillshade_noon = df.groupby('Cover_Type')['Hillshade_Noon'].mean().sort_values(ascending = False)\npx.bar(x = hillshade_noon.index, y = hillshade_noon, color = hillshade_noon.index, title = 'hillshade noon for different cover types')","8cd860b5":"def show_corr_plot(df):\n    corr = df[['Elevation', 'Aspect', 'Slope',\n           'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n           'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n           'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']].corr()\n\n    up = corr.where(np.tril(np.ones(corr.shape), k = -1).astype(bool))\n    sns.heatmap(up, fmt = '.1f', annot = True, cmap = 'plasma')\n    \nshow_corr_plot(df)","890f2147":"import plotly.figure_factory as ff\n\n# slope = df.\n# ff.create_distplot()\nslope = df.groupby('Cover_Type')['Slope'].mean().sort_values(ascending = False)\npx.bar(x = slope.index, y = slope, color = slope.index, title = 'mean slope for cover types')","580d0239":"px.scatter(data_frame = df, x = 'Horizontal_Distance_To_Roadways', y = 'Elevation', color = 'Cover_Type', title = 'distace and elevation')","5518d210":"elevation = df.groupby('Cover_Type')['Elevation'].mean().sort_values(ascending = False)\npx.bar(x = elevation.index, y = elevation, color = elevation.index, title = 'mean elevation for cover type')","70dbe756":"elevation = df.groupby('Cover_Type')['Horizontal_Distance_To_Roadways'].mean().sort_values(ascending = False)\npx.bar(x = elevation.index, y = elevation, color = elevation.index, title = 'mean distance to roadways for cover type')","6e5ea4b1":"pd.options.display.max_columns = None\nsoil_types = [c for c in df.columns if 'soil' in c.lower()]\nmean_soil_type = df.groupby('Cover_Type')[soil_types].mean()\nplt.figure(figsize = (18, 6))\nsns.heatmap(mean_soil_type, cmap = 'plasma');","9a7ea21d":"traindf.head()","00fc946a":"cols_for_dist = df.loc[:, 'Elevation' : 'Horizontal_Distance_To_Fire_Points'].columns.tolist()\nfig, ax = plt.subplots(len(cols_for_dist), 2, figsize = (12, 26))\nfig.tight_layout()\nfor i in range(len(cols_for_dist)):\n    col = cols_for_dist[i]\n    sns.distplot(df[col], ax = ax[i, 0], fit = norm)\n    sns.boxenplot(df[col], ax = ax[i, 1])","76fbb712":"traindf.shape","43a9aabf":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import StandardScaler","39c4a5dc":"x = traindf.drop(['Id', 'Cover_Type'], axis = 1)\ny = traindf.Cover_Type\nx.shape, y.shape","a150095b":"traindf.Cover_Type.unique()","7aa64c2a":"std = StandardScaler()\nstdx = pd.DataFrame(std.fit_transform(x), index = x.index, columns = x.columns)\nstdx.head()","ed445d3d":"stdx.shape","2d4c5222":"stdx.shape[0] * 0.005","7fbbf580":"x_train, x_dev, y_train, y_dev = train_test_split(stdx, y, test_size = 0.005, stratify = y, random_state = 0)\nnum_cls = y.unique().shape[0]\ny_train = to_categorical(y_train, num_classes = num_cls)\ny_dev = to_categorical(y_dev, num_classes = num_cls)\n\ny_train.shape, y_dev.shape","bc667fa3":"import tensorflow as tf \nimport tensorflow.keras as keras \nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n\nloss = keras.losses\nmetrics = keras.metrics","b7d1eba2":"from sklearn.metrics import classification_report, confusion_matrix\n\nclass Network:\n    def __init__(self, layers = [], activations = [], dropout = [], batchnorm = [], compile_params = {}):\n        self.model = None\n        self.losses = None \n        self.metrics = None\n        self.layers = layers \n        self.activations = activations \n        self.compile_params = compile_params \n        self.dropout = dropout if len(dropout) == (len(activations) - 1) else [None for _ in range(len(activations) - 1)]\n        self.batchnorm = batchnorm if len(batchnorm) == (len(activations) - 1) else [None for _ in range(len(activations) - 1)]\n        self.initialize_model()\n    \n    def initialize_model(self):\n        self.model = Sequential()\n        \n        # input layer         \n        self.model.add(Input(shape = self.layers[0], name = 'Input_Layer'))\n        \n        # hidden layers         \n        for idx in range(len(self.layers) - 2):\n            units = self.layers[idx + 1]\n            activation = self.activations[idx]\n            dp = self.dropout[idx]\n            bn = self.batchnorm[idx]\n            self.model.add(Dense(units, activation = activation, name = f'Hidden_Layer_{idx + 1}'))\n            if bn:\n                self.model.add(BatchNormalization())\n            if dp:\n                self.model.add(Dropout(dp, name = f'Dropout_{idx + 1}_{dp}'))\n                \n        # output layer\n        self.model.add(Dense(self.layers[-1], activation = self.activations[-1], name = 'Output_Layer'))\n                \n        self.model.compile(**self.compile_params)\n        return self.model\n    \n    def fit(self, fit_params):\n        history = self.model.fit(**fit_params)\n        his = pd.DataFrame(history.history)\n        l = [c for c in his.columns if 'loss' in c]\n        m = [c for c in his.columns if 'loss' not in c]\n        self.losses = his[l]\n        self.metrics = his[m]\n        return his\n          \n    def predict(self, x, softmax = 0):\n        pred = self.model.predict(x)\n        if softmax == 0:\n            return np.argmax(pred, axis = 1)\n        return pred\n    \n    def plot_arch(self):\n        if self.model is not None:\n            return plot_model(self.model, show_shapes = True, show_layer_names = True)\n        \n    def plot_loss(self):\n        if self.losses is not None:\n            self.losses.plot(kind = 'line')\n            plt.title('loss comparison')\n            plt.legend(self.losses.columns)\n            \n    def plot_metrics(self):\n        if self.metrics is not None:\n            self.metrics.plot(kind = 'line')\n            plt.title('metrics comparison')\n            plt.legend(self.metrics.columns)\n\n        \ndef report(yt, pred, inverse_to_cat = True):\n    if inverse_to_cat:\n        yt = np.argmax(yt, axis = 1)\n\n    print(classification_report(yt, pred))\n    sns.heatmap(confusion_matrix(yt, pred), fmt = '.1f', annot = True)\n    plt.title('confusion matrix')\n    \ndef hardmax(y):\n    return np.argmax(y, axis = 1)","a251f3dd":"# y_train[0], y[x_train.index[0]]\nx_train.shape, y_train.shape","01a150bd":"import tensorflow_addons as tfa","2d29569e":"layers         = [(54, ), 55, 55, 7]\nactivations    = ['relu', 'relu', 'softmax']\ndropout        = [0.05, 0.05]\ncompile_params = {\n    'optimizer' : keras.optimizers.Adam(learning_rate = 0.01),\n    'metrics'   : ['accuracy', metrics.Recall(), tfa.metrics.F1Score(num_classes = y_dev.shape[1], average = 'micro')],\n    'loss'      : loss.CategoricalCrossentropy()  \n}\nmodel1 = Network(layers = layers, activations = activations, compile_params = compile_params, dropout = dropout)\nmodel1.plot_arch()","41615ca3":"fit_params = {\n    'x' : x_train,\n    'y' : y_train,\n    'validation_data' : (x_dev, y_dev),\n    'epochs' : 5,\n    'batch_size' : 128\n}\n\nhis = model1.fit(fit_params)\nmodel1.plot_loss()","84284cd1":"model1.plot_metrics()","fbd98b6f":"scores = his.iloc[4, :]\npx.bar(x = scores.index, y = scores, color = scores.index)","435c89b2":"'sdfsdfsdf'","116c0472":"pred = model1.predict(x_dev)\nreport(y_dev, pred)","f44551b6":"x_test = testdf.drop(['Id'], axis = 1)\nx_test = pd.DataFrame(std.transform(x_test), columns = x_test.columns)\nx_test.shape, x_train.shape","80367f37":"pred = model1.predict(x_test)\nnp.unique(pred)","6832fb9a":"submission = pd.read_csv(f'{base_path}\/sample_submission.csv')\nsubmission.head()","8f231f28":"submission.Cover_Type.unique()","f2a75eb1":"ppred = pred + 1\n\nsubmission['Cover_Type'] = ppred\nsubmission.Cover_Type.unique()","4d1bc2b8":"submission.to_csv('submission.csv', index = False)","e76e19c2":"let's try to drop some useless features by using pearson correlation ","b851d150":"it's still unbalanced but we can merge 4, 5, 6 and 7 as 4 later if the model was overbiased to 1 and 2","30fc98e7":"Among these cover types\n* cotttonwood are the shortest cover types and also closer to roadways \n* krummholz are the tallest cover types and also far from roadways ","00508973":"Each cover type contains unique soil types except 2 \nOn Average\n* Aspen have the highest __soil type 30          ( Como family - Rock land - Legault family complex, extremely stony )__\n* Cottonwood have the highest __soil type 3      ( Haploborolis - Rock outcrop complex, rubbly )__\n* Douglas fir have the highest __soil type 10    ( Bullwark - Catamount families - Rock outcrop complex, rubbly )__\n* Krummholz have the highest __soil type 39      (  Cryorthents - Leighcan family complex, extremely stony )__\n* Lodgepole pine not really have any high soil types \n* Ponderose pine not really have any high soil types \n* Spruce fir not really have any high soil types \n\nSpruce fir and Lodgepole pine almost contains similar soil types ","27fb22c4":"looks like the loss is saturated around 50 epoch with max accuracy of 79%","391ec060":"since there are less number of cottonwood and aspen we can append them from df2 to df ","7771f735":"* Cotton wood usually have high hillshade at 9am but low hillshade at 3pm than the rest of the cover type\n* ponderose pine on average have low hillshade at 9am, 12pm and 3pm"}}