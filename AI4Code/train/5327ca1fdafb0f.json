{"cell_type":{"806f9e03":"code","c516177d":"code","27d257b5":"code","2981fa69":"code","66d833dd":"code","7883ced9":"code","84aee1cb":"code","227aa99c":"code","c4adeffc":"code","4f95b662":"code","a985d0e0":"code","44626f6e":"code","bf03b407":"code","01156e9c":"code","198c8389":"code","702fa141":"code","548c5859":"code","086ac4c3":"code","4cfd93aa":"code","02c75472":"code","2e77500c":"code","0792ec07":"code","5991a344":"code","ee7e0580":"code","05cf0fc4":"code","03317cda":"code","8531c79f":"code","bfeff342":"code","493e1cc6":"code","e223ad0d":"code","db0e0b4b":"markdown","b4df2c13":"markdown","f07b8a02":"markdown"},"source":{"806f9e03":"from textblob import TextBlob\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\n\nimport pandas, xgboost, numpy, textblob, string\nfrom keras.preprocessing import text, sequence\nfrom keras import layers, models, optimizers\n\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","c516177d":"import pandas as pd\ndata=pd.read_csv(\"..\/input\/fake-news-detection\/data.csv\")","27d257b5":"data.head()","2981fa69":"data[\"Label\"].value_counts()","66d833dd":"#checking missing values\ndata.isnull().sum()","7883ced9":"data=data.fillna(' ')","84aee1cb":"data.isnull().sum()","227aa99c":"df = pd.DataFrame()\ndf[\"text\"] = data[\"Body\"]\ndf[\"label\"] = data[\"Label\"]","c4adeffc":"df.head()","4f95b662":"#Checking for outliers\n\ndf[\"length\"] = df[\"text\"].str.len()\ndf.head()","a985d0e0":"#checking for minumum,maximum and average length\n#looks like there are outliers\n\nmin(df['length']), max(df['length']), round(sum(df['length'])\/len(df['length']))","44626f6e":"# dropping the outliers which are less than 50 word\n\ndf = df.drop(df['text'][df['length'] < 50].index, axis = 0)","bf03b407":"min(df['length']), max(df['length']), round(sum(df['length'])\/len(df['length']))","01156e9c":"df.head()","198c8389":"#upper-lower transform\ndf['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n#punctuations\ndf['text'] = df['text'].str.replace('[^\\w\\s]','')\n#numbers\ndf['text'] = df['text'].str.replace('\\d','')\n#stopwords\nimport nltk\n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nsw = stopwords.words('english')\ndf['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n#deleting sparse words\nsil = pd.Series(' '.join(df['text']).split()).value_counts()[-1000:]\ndf['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n#lemmi\nfrom textblob import Word\n#nltk.download('wordnet')\ndf['text'] = df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) ","702fa141":"df.head()","548c5859":"# Word Cloud Visualization","086ac4c3":"from PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt","4cfd93aa":"text = \" \".join(i for i in df.text)","02c75472":"wordcloud = WordCloud(max_font_size = 50, \n                     background_color = \"white\").generate(text)\nplt.figure(figsize = [10,10])\nplt.imshow(wordcloud, interpolation = \"bilinear\")\nplt.axis(\"off\")\nplt.show()","2e77500c":"train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"text\"],\n                                                                   df[\"label\"], \n                                                                    random_state = 1)","0792ec07":"train_y[0:5]","5991a344":"encoder = preprocessing.LabelEncoder()","ee7e0580":"train_y = encoder.fit_transform(train_y)\ntest_y = encoder.fit_transform(test_y)","05cf0fc4":"train_y[0:5]","03317cda":"test_y[0:5]","8531c79f":"# ngram level tf-idf","bfeff342":"tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range = (2,3))\ntf_idf_ngram_vectorizer.fit(train_x)","493e1cc6":"x_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\nx_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)","e223ad0d":"loj = linear_model.LogisticRegression()\nloj_model = loj.fit(x_train_tf_idf_ngram,train_y)\naccuracy = model_selection.cross_val_score(loj_model, \n                                           x_test_tf_idf_ngram, \n                                           test_y, \n                                           cv = 10).mean()\n\nprint(\"N-GRAM TF-IDF Accuracy Rate:\", accuracy)","db0e0b4b":"# TF-IDF","b4df2c13":"# Text Preprocessing","f07b8a02":"# Train-Test"}}