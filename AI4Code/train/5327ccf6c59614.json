{"cell_type":{"4d321235":"code","b2d3a63c":"code","28d29158":"code","d40233a6":"code","9a426402":"code","fb9da5b7":"code","db05d98d":"code","ead40ea4":"code","8e31ffb3":"markdown","d5090755":"markdown","57dfb942":"markdown"},"source":{"4d321235":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nall_filenames = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        all_filenames.append(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2d3a63c":"def build_city_lookup():\n    \"\"\"\n    First 12 rows contain information about cities and no temperture data.\n    Extract the rows and transform into useful lookup table\n    \"\"\"\n    city_lookup = pd.read_csv(all_filenames[0], nrows=12).T\n    city_lookup.columns = city_lookup.iloc[0]\n    city_lookup = city_lookup.iloc[1:,:]\n    city_lookup[\"lat\"] = city_lookup.lat.astype(np.float)\n    city_lookup[\"lng\"] = city_lookup.lng.astype(np.float)\n    return city_lookup\n\nbuild_city_lookup()","28d29158":"def build_reduced_city_lookup():\n    \"\"\"\n    Convert city_lookup types and assert data is valid\n    \"\"\"\n    city_lookup = build_city_lookup()\n\n    # First 12 rows are information about the cities\n    city_lookup = build_city_lookup()\n    city_lookup = city_lookup[[\"city\", \"country\", \"lat\", \"lng\", \"population\"]]\n    city_lookup.loc[:,\"population\"] = city_lookup.population.fillna(0).astype(float).astype(np.uint)\n\n    assert len(city_lookup) == len(city_lookup.drop_duplicates())\n    non_null = city_lookup[[\"city\", \"country\", \"lat\", \"lng\"]]\n    assert len(non_null[non_null.isnull().T.any()]) == 0, non_null[non_null.isnull().T.any()]\n\n    assert city_lookup.loc[(city_lookup.lat < -90) | (city_lookup.lat > 90), \"lat\"].count() == 0\n    assert city_lookup.loc[(city_lookup.lng < -180) | (city_lookup.lng > 180), \"lng\"].count() == 0\n\n    return city_lookup\n\ncity_lookup = build_reduced_city_lookup()\nprint(city_lookup.info())\ncity_lookup","d40233a6":"def city_by_name(city_lookup, city_name:str):\n    \"\"\"Lookup col of city and call city_by_index\"\"\"\n    city_col  = city_lookup[city_lookup[\"city\"]==city_name]\n    city_index = int(city_col.index[0])\n\n    return city_by_index(city_index), city_col\n\ndef city_by_index(city_col:int):\n    \"\"\"Read only one col from the csv that contains the city we are interested in\"\"\"\n    city_data = pd.read_csv(all_filenames[0], skiprows=12, usecols=[0, city_col + 1], index_col=0, parse_dates=True, cache_dates=False).iloc[:, 0]\n\n    return city_data\n","9a426402":"sample_city = city_by_index(0)\nsummary = f\"\"\"This data contains daily temperatures for {len(city_lookup)} cities coving a population of at least {city_lookup[\"population\"].sum():,} and {len(city_lookup[\"country\"].unique())} countries. The first recorded day is {sample_city.index.min().strftime('%d %B, %Y')} and the last {sample_city.index.max().strftime('%d %B, %Y')}.\"\"\"\nsummary","fb9da5b7":"# for i in range(1000):\n#     city_data = city_by_index(0)\n#     assert city_data[city_data < -100].count() == 0\n#     assert city_data[city_data > 200].count() == 0\n#     assert not np.isnan(city_data).any()\n\ncity_by_index(0)","db05d98d":"city_by_name(city_lookup, \"London\")[0].plot()","ead40ea4":"import matplotlib.pyplot as plt\n\ncity_data, city_col = city_by_name(city_lookup, \"London\")\nall_year = city_data.index.year.unique()\nprint(city_col)\n\nprint(all_year)\nfilenames = []\nfor year in all_year:\n    plt.ylim(city_data.min(), city_data.max())\n    city_data[city_data.index.year == year].plot()\n    file_name = str(year) + '.png'\n    filenames.append(file_name)\n    plt.savefig(file_name)\n    plt.close()\n    \n\nprint(filenames)\nimport imageio\nimages = []\nfor filename in filenames:\n    images.append(imageio.imread(filename))\nimageio.mimsave('movie.gif', images)","8e31ffb3":"# Animate years","d5090755":"# Example city data","57dfb942":"[](http:\/\/)![movie.gif](movie.gif)\n"}}