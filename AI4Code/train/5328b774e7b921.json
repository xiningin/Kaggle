{"cell_type":{"5c941f23":"code","98c223ec":"code","91e6a236":"code","9272b962":"code","5be2103c":"code","f66a7a32":"code","eda743a8":"code","4b9580a6":"code","675f8bb4":"code","22531f33":"code","fd508a77":"code","7d337343":"code","ea4c5d35":"code","6a64395b":"code","240a79d3":"code","43310552":"code","94ccfcd8":"code","77c90ef1":"code","ffd6d1f6":"code","f2d497e4":"code","e6c48a22":"code","e2e0bd70":"code","d83a1726":"code","27cdfa6b":"code","6e939947":"code","3e02c047":"code","386db832":"code","7ed034fd":"code","4a949978":"code","7aad5579":"code","4681571d":"markdown","459ae516":"markdown","30d1c532":"markdown","e1828d57":"markdown","1365d755":"markdown","e32504b8":"markdown","b097cb1a":"markdown","d59e7fef":"markdown","f38ec681":"markdown","556b1241":"markdown","1f71ed6e":"markdown"},"source":{"5c941f23":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98c223ec":"# \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\nimport h5py, cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns","91e6a236":"train = h5py.File('\/kaggle\/input\/happy-house-dataset\/train_happy.h5','r')\ntest = h5py.File('\/kaggle\/input\/happy-house-dataset\/test_happy.h5','r')","9272b962":"train['train_set_x'].shape, train['train_set_y'].shape, test['test_set_x'].shape, test['test_set_y'].shape","5be2103c":"fig , axes = plt.subplots(3,3)\nfig.set_size_inches(15,15)\n\nfor index in range(0,9):\n    axes[index\/\/3 , index%3].imshow(train['train_set_x'][index])\n    axes[index\/\/3 , index%3].set_title('label : {}'.format(train['train_set_y'][index]))","f66a7a32":"train['train_set_y'][:5] # \uc6c3\uc73c\uba74 1, \uc6c3\uc9c0 \uc54a\uc73c\uba74 0 ","eda743a8":"x_train = np.array(train['train_set_x'][:]) # train\uc14b\uc758 image \ub370\uc774\ud130\ny_train = np.array(train['train_set_y'][:]) # train\uc14b\uc758 label \ub370\uc774\ud130\n\nx_test = np.array(test['test_set_x'][:])\ny_test = np.array(test['test_set_y'][:])","4b9580a6":"x_train.shape, x_test.shape","675f8bb4":"y_train.shape, y_test.shape","22531f33":"y_train = y_train.reshape((y_train.shape[0],1))\ny_test = y_test.reshape((y_test.shape[0],1))","fd508a77":"y_train.shape, y_test.shape","7d337343":"x_train_gray = [] # train \ub370\uc774\ud130 \nfor x in x_train:\n    img = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n    x_train_gray.append(img)","ea4c5d35":"x_test_gray = [] # test \ub370\uc774\ud130 \nfor x in x_test:\n    img = cv2.cvtColor(x,cv2.COLOR_RGB2GRAY)\n    x_test_gray.append(img)","6a64395b":"fig , axes = plt.subplots(2,2)\nfig.set_size_inches(10,10)\n\nfor index in range(0,4):\n    axes[index\/\/2 , index%2].imshow(x_train_gray[index], cmap = 'gray')\n    axes[index\/\/2 , index%2].set_title('label : {}'.format(y_train[index]))","240a79d3":"x_train_gray = np.array(x_train_gray)\nx_test_gray = np.array(x_test_gray)","43310552":"# x_train = x_train_gray.reshape((-1,64,64,1)) # \ud751\ubc31 \uc804\ucc98\ub9ac\n# x_test = x_test_gray.reshape((-1,64,64,1))\n\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","94ccfcd8":"train_datagen = ImageDataGenerator(\n    rescale = 1\/255.0,\n    brightness_range = [0.5, 1.5], # \ubc1d\uae30 0.5~1.5 \ub79c\ub364 \uc124\uc815\n    zoom_range = [0.8,1.1],        # 0.8~1.1 \uc0ac\uc774\ub85c \uc784\uc758\ub85c \ud06c\uae30 \uc124\uc815\n    rotation_range =15.0,           # \ud68c\uc804 \ubc94\uc704 \n    channel_shift_range = 25,      # \ubd80\ub3d9\uc18c\uc218\uc810. \ubb34\uc791\uc704 \ucc44\ub110 \uc774\ub3d9\uc758 \ubc94\uc704.\n    horizontal_flip = True)        # \uc88c\uc6b0\ubc18\uc804\n\ntest_datagen = ImageDataGenerator(\n    rescale = 1\/255.0)","77c90ef1":"x_train.shape, y_train.shape, x_test.shape, y_test.shape","ffd6d1f6":"batch_size = 16 # \ubc30\uce58 \uc0ac\uc774\uc988 \uc9c0\uc815\n\ntrain_gen = train_datagen.flow(x_train, y_train, batch_size = batch_size, shuffle = True)\ntest_gen = test_datagen.flow(x_test, y_test, batch_size = batch_size, shuffle = False)","f2d497e4":"model = Sequential([\n    Conv2D(64, (3,3), activation = 'relu', input_shape = (64,64,3)), \n    #MaxPooling2D(),\n    \n#     Conv2D(32, (3,3), activation = 'relu'),\n#     MaxPooling2D(),\n    \n#     Conv2D(16, (3,3), activation = 'relu'),\n#     MaxPooling2D(),\n    \n    Flatten(),\n    Dense(32, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])","e6c48a22":"model.summary()","e2e0bd70":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['acc']) # \ucd5c\uc801\ud654\ud568\uc218\ub294 adam\uc744 \uc0ac\uc6a9\ud574\uc90d\ub2c8\ub2e4.\n\ncheckpath = '.\/ck.ckpt'\ncheckpoint = ModelCheckpoint(\n    filepath = checkpath,\n    save_best_only = True,\n    save_weights_only = True, # \uac00\uc911\uce58\ub9cc \uc800\uc7a5\n    verbose =1,\n    monitor = 'val_acc' # val_acc\ub97c \ubaa8\ub2c8\ud130\ud558\uba70 \uac00\uc7a5 \ub192\uc740 \uac12\uc744 \uc800\uc7a5\n    )","d83a1726":"model.fit(train_gen, \n          validation_data = test_gen,\n          epochs = 20,\n          callbacks = [checkpoint])","27cdfa6b":"model.load_weights(checkpath)","6e939947":"x_test_input = x_test.copy().astype(np.float64)\nx_test_input -= np.mean(x_test, keepdims=True)\nx_test_input \/= (np.std(x_test, keepdims=True) + 1e-6)","3e02c047":"x_test = x_test \/ 255.0 # \uc815\uaddc\ud654","386db832":"y_pred = model.predict(x_test) # \uc608\uce21","7ed034fd":"y_pred_logical = (y_pred > 0.5).astype(np.int) # 0.5\ub97c \uc784\uacc4\uc810\uc73c\ub85c \uc7a1\uaca0\uc2b5\ub2c8\ub2e4.","4a949978":"print('test acc: %s'% accuracy_score(y_test, y_pred_logical))","7aad5579":"cm = confusion_matrix(y_test, y_pred_logical)\nsns.heatmap(cm, annot = True)","4681571d":"### \ud751\ubc31 \uc804\ucc98\ub9ac\n\n* \uceec\ub7ec\ub85c \ud559\uc2b5\ud588\uc744 \ub54c \uc131\ub2a5\uc774 \ub354 \ub192\uc558\uc2b5\ub2c8\ub2e4.","459ae516":"* x\ucd95 : \uc2e4\uc81c \uc815\ub2f5\uac12\n* y\ucd95 : \uc608\uce21\uac12","30d1c532":"## ImageDataGenerator","e1828d57":"* \ubaa8\ub378\uc5d0 \ub123\uc5b4\uc8fc\uae30 \uc704\ud574 (600,1), (150,1) \ud615\ud0dc\ub85c \ubc14\uafd4\uc90d\ub2c8\ub2e4.","1365d755":"* \uc804\ucc98\ub9ac\uac00 \uc644\ub8cc\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \n* train\uc14b\uc758 \ub370\uc774\ud130\ub294 600\uac1c, test \uc14b\uc758 \ub370\uc774\ud130 150\uac1c\ub85c \uadf8 \uc218\uac00 \ub9e4\uc6b0 \uc801\uc2b5\ub2c8\ub2e4.\n* Augmentation\uc744 \ud1b5\ud574 \ub370\uc774\ud130 \uc99d\uc2dd\uc774 \ud544\uc694\ud560 \uac83 \uac19\uc2b5\ub2c8\ub2e4.","e32504b8":"# CNN \ubaa8\ub378","b097cb1a":"## \ub370\uc774\ud130 \ubaa8\uc591","d59e7fef":"* x-y \uac04 \ub370\uc774\ud130 \ucc98\ub9ac\uac00 \uc798 \uc774\ub8e8\uc5b4\uc84c\uc2b5\ub2c8\ub2e4.","f38ec681":"# \uc608\uce21 \uacb0\uacfc \ud655\uc778(\ud63c\ub3d9\ud589\ub82c)","556b1241":"## \ub370\uc774\ud130 \ub098\ub220\uc8fc\uae30 \ubc0f \uc804\ucc98\ub9ac","1f71ed6e":"# \uacb0\ub860\n\n### \ud751\ubc31 \uc0ac\uc9c4\ubcf4\ub2e4 \uceec\ub7ec\ub85c \ub370\uc774\ud130\uc14b\uc744 \ucc98\ub9ac\ud588\uc744\ub54c \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uc88b\uc558\ub2e4.\n\n### \uc774 \ub370\uc774\ud130\uc14b\uc744 \ud1b5\ud574 \ud559\uc2b5\ub41c \ubaa8\ub378\uc774 \ub2e4\ub978 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc131\ub2a5\uc774 \uc88b\uc9c0 \uc54a\uc558\ub2e4. \uc774\uc720\ub294?\n\n- \uc5ec\uc131 \ub370\uc774\ud130\uac00 \uc5c6\uc74c\n- \ubaa8\ub4e0 \ub370\uc774\ud130\uac00 \ub611\uac19\uc740 \ubc30\uacbd\n- \uac19\uc740 \uc0ac\ub78c\uc774 \uc5ec\ub7ec\ubc88 \ub4f1\uc7a5\n\n### \uc880 \ub354 \ub2e4\uc591\ud55c \uc0ac\ub78c\ub4e4\uacfc \ubc30\uacbd\uc744 \uac00\uc9c4 \ub370\uc774\ud130\ub85c \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\uc790"}}