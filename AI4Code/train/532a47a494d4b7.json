{"cell_type":{"ca736e73":"code","bcaafa77":"code","4f0d2f96":"code","b797d954":"code","c3799ebd":"code","c002cb42":"code","ce21b26b":"code","36588bf8":"code","e81a2109":"code","f798f48c":"code","65fbdb55":"code","7975d8e7":"code","7fa9f5f8":"code","6d677d2d":"code","9d79bad0":"code","7d830a5e":"code","584e8dc0":"code","9e881c45":"code","3652c58f":"code","44c6a15c":"code","2c901893":"code","3e4212bb":"code","79c98ffc":"code","59f7693c":"code","b630cb29":"code","abb65524":"code","584ed754":"code","1c445b67":"code","a5714cf1":"code","ce2df5e1":"code","93046942":"code","36f05de5":"code","67faff49":"code","b92451e4":"code","19e3787f":"code","ae2bd85b":"code","f5fb45ff":"code","9ad4c5f4":"code","965ae4f7":"code","48e76f55":"code","7ad7f075":"code","c4ad8ddb":"markdown","0817ea1e":"markdown","f95e721f":"markdown","207a10d5":"markdown","28bb690e":"markdown","43d97f21":"markdown","fc5e0d9d":"markdown","a121097d":"markdown","a0bada18":"markdown","baf36248":"markdown","eb0a37c9":"markdown","5e14b6a5":"markdown","a03b099a":"markdown","b0e390b4":"markdown","c32198dc":"markdown","5dda36ee":"markdown","1df4d5cf":"markdown","8daee8c8":"markdown","ec30133c":"markdown","a7fcc3cb":"markdown","22c6b9d8":"markdown","6141048a":"markdown","25a651c1":"markdown","5d047094":"markdown","5e84435c":"markdown","8d65417c":"markdown","dc4c42c5":"markdown"},"source":{"ca736e73":"!pip install --upgrade tensorflow\n!pip install segmentation-models\n","bcaafa77":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport keras\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, concatenate\nfrom keras.models import Model\nfrom keras.optimizers import *\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport segmentation_models as sm\n\n\nimport random\nimport os\nimport gc\nimport datetime\nimport numpy as np\nimport glob\n\nfrom scipy.ndimage import rotate\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport PIL\nfrom PIL import Image , ImageOps\n\nimport matplotlib.pyplot as plt\n\n#tf.enable_eager_execution()     \n\n# carrega o m\u00f3dulo do Tensorboard\n# %load_ext tensorboard\n\nprint('A vers\u00e3o do tensorflow \u00e9: ' + tf.__version__)","4f0d2f96":"DATA_DIR = '\/kaggle\/input\/'\nMODEL_PATH = 'models\/'\nIMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 256,256,1\nAUGMENTATION_SAMPLE_SIZE=2000\nORIGINAL_DATASET_SIZE=1012","b797d954":"def load_data(d):\n    x = np.load(d + 'x100.npy')\n    t = np.load(d + 't100.npy')\n    return x,t\n\ndef normalize(x):\n    return x\/255.\n\ndef print_images(n, x, t, y=None):\n    if y:\n        plt.subplot(131); plt.imshow(x[n,:,:,0], cmap='gray')\n        plt.subplot(132); plt.imshow(t[n,:,:,0], cmap='gray')        \n        plt.subplot(133); plt.imshow(y[n,:,:,0], cmap='gray')\n    else:\n        plt.subplot(121); plt.imshow(x[n,:,:,0], cmap='gray')\n        plt.subplot(122); plt.imshow(t[n,:,:,0], cmap='gray')","c3799ebd":"def show_img(img, ax):\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img,cmap='gray')\n\ndef plot_grid(imgs, nrows, ncols, figsize=(10, 10)):\n    assert len(imgs) == nrows*ncols, f\"Number of images should be {nrows}x{ncols}\"\n    _, axs = plt.subplots(nrows, ncols, figsize=figsize)\n    axs = axs.flatten()\n    for img, ax in zip(imgs, axs):\n        show_img(img, ax)\n            \ndef translate(img, shift=10, direction='right', roll=True):\n    assert direction in ['right', 'left', 'down', 'up'], 'Directions should be top|up|left|right'\n    img = img.copy()\n    if direction == 'right':\n        right_slice = img[:, -shift:].copy()\n        img[:, shift:] = img[:, :-shift]\n        if roll:\n            img[:,:shift] = np.fliplr(right_slice)\n    if direction == 'left':\n        left_slice = img[:, :shift].copy()\n        img[:, :-shift] = img[:, shift:]\n        if roll:\n            img[:, -shift:] = left_slice\n    if direction == 'down':\n        down_slice = img[-shift:, :].copy()\n        img[shift:, :] = img[:-shift,:]\n        if roll:\n            img[:shift, :] = down_slice\n    if direction == 'up':\n        upper_slice = img[:shift, :].copy()\n        img[:-shift, :] = img[shift:, :]\n        if roll:\n            img[-shift:,:] = upper_slice\n    return img\n\ndef rotate_img(img, angle, bg_patch=(5,5)):\n    img = img.copy()\n    assert len(img.shape) <= 3, \"Incorrect image shape\"\n    rgb = len(img.shape) == 3\n    if rgb:\n        bg_color = np.mean(img[:bg_patch[0], :bg_patch[1], :], axis=(0,1))\n    else:\n        #bg_color = np.mean(img[:bg_patch[0], :bg_patch[1]])\n        bg_color = 0\n    bg_color = 0\n    img = rotate(img, angle, reshape=False)\n    mask = [img <= 0, np.any(img <= 0, axis=-1)][rgb]\n    img[mask] = bg_color\n    return img\n\ndef gaussian_noise(img, mean=0, sigma=0.03):\n    img = img.copy()\n    noise = np.random.normal(mean, sigma, img.shape)\n    mask_overflow_upper = img+noise >= 1.0\n    mask_overflow_lower = img+noise < 0\n    noise[mask_overflow_upper] = 1.0\n    noise[mask_overflow_lower] = 0\n    img += noise\n    return img\n\ndef generate_augmented(x, t, sample_size):\n    newImages = np.ndarray(shape=(sample_size, x.shape[1], x.shape[2], x.shape[3]),\n                     dtype=np.float32)\n    newMasks = np.ndarray(shape=(sample_size, t.shape[1], t.shape[2], t.shape[3]),\n                     dtype=np.float32) \n    \n    for i in range(sample_size):\n        idx = random.randint(0, len(x)-1)\n    \n        image = x[idx,:,:]\n        mask = t[idx,:,:]\n    \n        newImg = image.copy()\n        newMask = mask.copy()\n    \n        for orientation in ['up', 'down', 'left', 'right']:\n            if random.random() > .8:\n                shift = random.randint(10,128)\n                newImg = translate(newImg, direction=orientation, shift=shift)\n                newMask = translate(newMask, direction=orientation, shift=shift)\n        \n        if random.random() > .8:\n            angle = random.randint(-180, 180)\n            newImg = rotate_img(newImg, angle=angle)\n            newMask = rotate_img(newMask, angle=angle)\n            \n        if random.random() > .5:\n            newImg = gaussian_noise(newImg, \n                                    mean=random.uniform(0, 0.1), \n                                    sigma=random.uniform(0.00001, 0.0001)).reshape((256,256,1))\n        newImages[i] = newImg\n        newMasks[i] = newMask\n        \n    return newImages, newMasks","c002cb42":"def dice_coef(y_true, y_pred, smooth=1.):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","ce21b26b":"def save(model, name, path):\n    # Save the model\n    entire_path = path+name+'\/'\n    print('saving ', name)\n    if not os.path.exists(entire_path):\n        os.makedirs(entire_path)\n    model.save(entire_path+name+'.h5')\n    model.save_weights(entire_path+name+'_WEIGHTS.h5')\n    print('saved successfully')\n\ndef load(name, path):\n    # Recreate the exact same model purely from the file\n    return load_model(path+name+'.h5')","36588bf8":"#Carrega os dados e normaliza\nx,t = load_data(DATA_DIR)\n\nx = normalize(x)\nt = normalize(t)","e81a2109":"#Gera dados aplicando rota\u00e7\u00e3o, transla\u00e7\u00e3o e gera\u00e7\u00e3o de ru\u00eddo\nX_train_aug, y_train_aug = generate_augmented(x,t,AUGMENTATION_SAMPLE_SIZE)","f798f48c":"#separa os dados reais entre valida\u00e7\u00e3o e treinamento\nX_train, X_validate, y_train, y_validate = train_test_split(x,t,test_size=0.33)\nX_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.5)\n\n#concatena os dados de treinamento reais com os dados gerados\nX_train = np.concatenate((X_train, X_train_aug))\ny_train = np.concatenate((y_train, y_train_aug))\n\nx = None\nt = None\n\ngc.collect()","65fbdb55":"#Modelo Unet\n#...\ndef get_unet_model(optimizer, loss, metrics, pretrained_weights=None):\n    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n \n    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(inputs)\n    c1 = tf.keras.layers.Dropout(0.1)(c1)\n    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c1)\n    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\n    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(p1)\n    c2 = tf.keras.layers.Dropout(0.1)(c2)\n    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c2)\n    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\n    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(p2)\n    c3 = tf.keras.layers.Dropout(0.2)(c3)\n    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c3)\n    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\n    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(p3)\n    c4 = tf.keras.layers.Dropout(0.2)(c4)\n    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c4)\n    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n\n    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(p4)\n    c5 = tf.keras.layers.Dropout(0.3)(c5)\n    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c5)\n\n    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n    u6 = tf.keras.layers.concatenate([u6, c4])\n    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(u6)\n    c6 = tf.keras.layers.Dropout(0.2)(c6)\n    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c6)\n\n    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n    u7 = tf.keras.layers.concatenate([u7, c3])\n    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(u7)\n    c7 = tf.keras.layers.Dropout(0.2)(c7)\n    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c7)\n\n    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n    u8 = tf.keras.layers.concatenate([u8, c2])\n    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(u8)\n    c8 = tf.keras.layers.Dropout(0.1)(c8)\n    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c8)\n\n    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(u9)\n    c9 = tf.keras.layers.Dropout(0.1)(c9)\n    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                                padding='same')(c9)\n\n    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n \n    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    \n    if(pretrained_weights):\n    \tmodel.load_weights(pretrained_weights)\n    \n    return model","7975d8e7":"def treinar(model, x, y, nomedoexperimento, validation_split=0.15, validation_data=None, validation_steps=None, batch_size=16, patience=2, epochs=50, save_logs=False):   \n    ### cria diret\u00f3rio \"logs\" com os arquivos para o callback do Tensorboard \n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    logdir = os.path.join('logs', nomedoexperimento + '-' + timestamp)\n\n    checkpoint_path = \"training_1\/\"+nomedoexperimento+\".ckpt\"\n#     checkpoint_dir = os.path.dirname(checkpoint_path)\n \n    # Create checkpoint callback\n#     cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n#                                                     save_weights_only=True,\n#                                                     verbose=1)\n    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n    \n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(patience=patience, monitor='val_loss'),\n        \n#         cp_callback \n        checkpointer\n    ]\n    \n#     if(save_logs):\n#         callbacks.append(tf.keras.callbacks.TensorBoard(logdir, histogram_freq=0))\n\n    \n    if validation_data:\n        results = model.fit(x, y, \n                            validation_data=validation_data, \n                            validation_steps=validation_steps,\n                            batch_size=batch_size, \n                            epochs=epochs,\n                            callbacks=callbacks)\n    else:\n        results = model.fit(x, y, \n                            validation_split=validation_split, \n                            batch_size=batch_size, \n                            epochs=epochs,\n                            callbacks=callbacks)\n    \n    return results\n \n ","7fa9f5f8":"model = get_unet_model(optimizer='adam', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nmodel.summary()\n\nmodel = None\ngc.collect()","6d677d2d":"size = 5\nstart = 30\n\nfor i in range(start, start+size):\n    plot_grid([X_train_aug[i,:,:,0], y_train_aug[i,:,:,0]], 1,2, figsize=(5,5)),\n    \n\nX_train_aug = None\ny_train_aug = None\ngc.collect()","9d79bad0":"print('Tamanho do dataset inicial: ', ORIGINAL_DATASET_SIZE)\nprint('Tamanho do dataset gerado por augmentation: ', AUGMENTATION_SAMPLE_SIZE)\nprint('Tamanho do a serem utilizados para treinamento ', len(X_train))\nprint('Tamanho do a serem utilizados para valida\u00e7\u00e3o ', len(X_validate))\nprint('Tamanho do a serem utilizados para teste\/avalia\u00e7\u00e3o ', len(X_test))","7d830a5e":"#Otimizador Adam\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\nexperimento = \"adam_dice_vdata_b50_p5\"\n\nmodel_adam_final = get_unet_model(optimizer='adam', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nopt_adam_history = treinar(model_adam_final, X_train, y_train,\n        experimento, \n        validation_data=(X_validate, y_validate),\n        batch_size=50, patience=5, epochs=80, save_logs=True)\n\nsave(model_adam_final, experimento, MODEL_PATH)","584e8dc0":"results = model_adam_final.evaluate(X_test, y_test, batch_size=50)\nprint(model_adam_final.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","9e881c45":"#Otimizador Nadam\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\nexperimento = \"nadam_dice_vdata_b50_p5\"\n\nmodel = get_unet_model(optimizer='nadam', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nopt_nadam_history = treinar(model, X_train, y_train,\n        experimento, \n        validation_data=(X_validate, y_validate),\n        batch_size=50, patience=5, epochs=80)\n\nsave(model, experimento, MODEL_PATH)","3652c58f":"#valida\u00e7\u00e3o nadam\nresults = model.evaluate(X_test, y_test, batch_size=50)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","44c6a15c":"#Otimizador SGD\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\nexperimento = \"sgd_dice_vdata_b50_p5\"\n\nmodel = get_unet_model(optimizer='sgd', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nopt_sgd_history = treinar(model, X_train, y_train,\n        experimento, \n        validation_data=(X_validate, y_validate),\n        batch_size=50, patience=5, epochs=80)\n\nsave(model, experimento, MODEL_PATH)","2c901893":"#valida\u00e7\u00e3o sgd\nresults = model.evaluate(X_test, y_test, batch_size=50)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","3e4212bb":"# Plot training & validation loss values\nplt.plot(opt_adam_history.history['loss'])\nplt.plot(opt_nadam_history.history['loss'])\nplt.plot(opt_sgd_history.history['loss'])\nplt.title('Model train loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Adam Train', 'Nadam Train', 'SGD Train'], loc='upper left')\nplt.show()\n\nplt.plot(opt_adam_history.history['val_loss'])\nplt.plot(opt_nadam_history.history['val_loss'])\nplt.plot(opt_sgd_history.history['val_loss'])\nplt.title('Model validation loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Adam val', 'Nadam val','SGD val'], loc='upper left')\nplt.show()","79c98ffc":"del opt_adam_history\ndel opt_nadam_history\ndel opt_sgd_history\n\ngc.collect()","59f7693c":"#Otimizador Adam\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\nexperimento = \"b20\"\n\nmodel = get_unet_model(optimizer='adam', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nb20_history = treinar(model, X_train, y_train,\n        experimento, \n        validation_data=(X_validate, y_validate),\n        batch_size=20, patience=5, epochs=80)\n\nsave(model, experimento, MODEL_PATH)","b630cb29":"#valida\u00e7\u00e3o sgd\nresults = model.evaluate(X_test, y_test, batch_size=20)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","abb65524":"#Otimizador Adam\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\nexperimento = \"b60\"\n\nmodel = get_unet_model(optimizer='adam', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nb60_history  = treinar(model, X_train, y_train,\n        experimento, \n        validation_data=(X_validate, y_validate),\n        batch_size=60, patience=5, epochs=80)\n\nsave(model, experimento, MODEL_PATH)","584ed754":"#valida\u00e7\u00e3o sgd\nresults = model.evaluate(X_test, y_test, batch_size=60)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","1c445b67":"#Otimizador Adam\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\nexperimento = \"b100\"\n\nmodel = get_unet_model(optimizer='adam', \n                       loss=dice_coef_loss, \n                       metrics=[dice_coef])\n\nb100_history = treinar(model, X_train, y_train,\n        experimento, \n        validation_data=(X_validate, y_validate),\n        batch_size=100, patience=5, epochs=80)\n\nsave(model, experimento, MODEL_PATH)","a5714cf1":"#valida\u00e7\u00e3o sgd\nresults = model.evaluate(X_test, y_test, batch_size=100)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","ce2df5e1":"# Plot training & validation loss values\nplt.plot(b20_history.history['loss'])\nplt.plot(b60_history.history['loss'])\nplt.plot(b100_history.history['loss'])\nplt.title('Model train loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Batch 20', 'Batch 60', 'Batch 100'], loc='upper left')\nplt.show()\n\nplt.plot(b20_history.history['val_loss'])\nplt.plot(b60_history.history['val_loss'])\nplt.plot(b100_history.history['val_loss'])\nplt.title('Model validation loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Batch 20', 'Batch 60','Batch 100'], loc='upper left')\nplt.show()","93046942":"del b20_history\ndel b60_history\ndel b100_history\n\ngc.collect()","36f05de5":"def get_keras_callbacks(nomedoexperimento, patience):\n    directory = 'training_1\/'\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    logdir = os.path.join('logs', nomedoexperimento + '-' + timestamp)\n    checkpoint_path = \"training_1\/\"+nomedoexperimento+\".ckpt\"\n    checkpointer = keras.callbacks.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1)\n\n    return [\n        keras.callbacks.callbacks.EarlyStopping(patience=patience, monitor='val_loss'),\n        checkpointer\n    ]","67faff49":"#Modelo pr\u00e9 treinado\n# keras.backend.set_image_data_format('channels_last')\nsm.set_framework('keras')\n\nN = X_train.shape[-1]\n\nbase_model = sm.Unet('resnet34', classes=1, activation='sigmoid', encoder_weights='imagenet')\n\ninp = Input(shape=(None, None, N))\nl1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\nout = base_model(l1)\n\nmodel = Model(inp, out, name=base_model.name)\n\nmodel.compile(\n    'Adam',\n    loss=dice_coef_loss,\n    metrics=[dice_coef],\n)\n\n# del base_model\n# gc.collect()","b92451e4":"experimento = \"pre_trained_unet_resnet34_imagenet_adam_b50_p3_vdata\"\n\npre_trained_unet_resnet_imagenet_history = model.fit(\n    x=X_train,\n    y=y_train,\n    batch_size=50,\n    epochs=50,\n    validation_data=(X_validate, y_validate),\n    callbacks=get_keras_callbacks(experimento, patience=5)\n)\n\nsave(model, experimento, MODEL_PATH)","19e3787f":"results = model.evaluate(X_test, y_test, batch_size=50)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","ae2bd85b":"#Modelo pr\u00e9 treinado\n# keras.backend.set_image_data_format('channels_last')\nN = X_train.shape[-1]\n\nbase_model = sm.Linknet('inceptionv3', classes=1, activation='sigmoid', encoder_weights='imagenet')\n\ninp = Input(shape=(None, None, N))\nl1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\nout = base_model(l1)\n\nmodel = Model(inp, out, name=base_model.name)\n\nmodel.compile(\n    'Adam',\n    loss=dice_coef_loss,\n    metrics=[dice_coef],\n)","f5fb45ff":"experimento = \"pre_trained_linknet_inceptionv3_imagenet_adam_b50_p5_vdata\"\n\npre_trained_linknet_inceptionv3_imagenet_history = model.fit(\n    x=X_train,\n    y=y_train,\n    batch_size=50,\n    epochs=50,\n    validation_data=(X_validate, y_validate),\n    callbacks=get_keras_callbacks(experimento, patience=5)\n)\n\nsave(model, experimento, MODEL_PATH)","9ad4c5f4":"results = model.evaluate(X_test, y_test, batch_size=50)\nprint(model.metrics_names)\nprint('Loss dataset teste: ', results[0])\nprint('Dice dataset teste: ', results[1])","965ae4f7":"# Plot training & validation loss values\nplt.plot(pre_trained_unet_resnet_imagenet_history.history['loss'])\nplt.plot(pre_trained_linknet_inceptionv3_imagenet_history.history['loss'])\nplt.title('Model train loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Unet ResNet Imagenet', 'LinkNet InceptionV3 Imagenet'], loc='upper left')\nplt.show()\n\nplt.plot(pre_trained_unet_resnet_imagenet_history.history['val_loss'])\nplt.plot(pre_trained_linknet_inceptionv3_imagenet_history.history['val_loss'])\nplt.title('Model validation loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Unet ResNet Imagenet', 'LinkNet InceptionV3 Imagenet'], loc='upper left')\nplt.show()","48e76f55":"del pre_trained_unet_resnet_imagenet_history\ndel pre_trained_linknet_inceptionv3_imagenet_history\ngc.collect()","7ad7f075":"#Otimizador Adam\n#Loss dice\n#Valida\u00e7\u00e3o definida no split\n#100 \u00e9pocas e patience 5\n# weights_file = \"models\/adam_dice_vdata_b50_p5\/adam_dice_vdata_b50_p5_WEIGHTS.h5\"\n\n# model_adam_final = get_unet_model(optimizer='adam', \n#                        loss=dice_coef_loss, \n#                        metrics=[dice_coef])\n\n# model_adam_final.load_weights(weights_file)\n\n\n# saida = model_adam_final.predict(X_test)","c4ad8ddb":"# Segmenta\u00e7\u00e3o Sem\u00e2ntica de imagens de rediografia","0817ea1e":"* M\u00e9todo muito comum para descida do gradiente\n* Escolhido para compara\u00e7\u00e3o com m\u00e9todos mais adaptativos, como adam e nadam","f95e721f":"O modelo final escolhido para teste cego, foi o treinado na Unet utilzando o otimizador Adam; Treinado com uma jun\u00e7\u00e3o de dados originais com os gerados por augmentation","207a10d5":"### Nadam","28bb690e":"### SGD","43d97f21":"### Dataset","fc5e0d9d":"## Modelo final para infer\u00eancia","a121097d":"* Semelhante ao otimizador Adam\n* Utiliza uma implementa\u00e7\u00e3o de momentum\n* Funciona bem se aplicado em superf\u00edcies com grande quantidade de curvaturas","a0bada18":"#### Configura\u00e7\u00f5es escolhidas para os testes de otimizadores:\n* M\u00e9trica Dice\n* Loss Dice\n* 30% dos dados reais para valida\u00e7\u00e3o\n* 100 \u00e9pocas com early stopping com patinece = 5","baf36248":"## Conclus\u00f5es","eb0a37c9":"## Compara\u00e7\u00e3o de otimizadores","5e14b6a5":"### Mini Batch (60)","a03b099a":"### Tr\u00eas tipos de augmentation:\n* Transa\u00e7\u00e3o\n* Rota\u00e7\u00e3o\n* Adi\u00e7\u00e3o de ru\u00eddo (distribui\u00e7\u00e3o gaussiana)","b0e390b4":"## Modelo Utilizado - Unet","c32198dc":"![Arquitetura de rede Unet](http:\/\/deeplearning.net\/tutorial\/_images\/unet.jpg)","5dda36ee":"### Unet - Backbone ResNet e Pesos da ImageNet\n\n* ImageNet cont\u00e9m mais de 14 milh\u00f5es de imagens\n* Backbones funcionam como uma base da rede neural\n* ResNet ou Residual Networks utilizam Skip Connections\n    * Permite treinamento de redes mais profundas\n    * Arquiteturas deste tipo ganharam competi\u00e7\u00f5es da ImageNet\n* Inception utiliza mais combina\u00e7\u00f5es de filtros com tamanhos diferentes\n    * Tamb\u00e9m foi utilzada em modelos vencedores de competi\u00e7\u00f5es da ImageNet","1df4d5cf":"## Compara\u00e7\u00e3o de modelos de Transfer Learning","8daee8c8":"### Mini Batch (20)","ec30133c":"* Data augmentation aumentou a m\u00e9trica de avalia\u00e7\u00e3o nos testes efetuados\n* Unet demonstrou bom desempenho na maioria das configura\u00e7\u00f5es escolhidas\n* Os modelos de Transfer Learning possibilitaram uma converg\u00eancia mais r\u00e1pida\n* Adam apresentou maior velocidade de converg\u00eancia e melhores resuntados dentro os otimizadores verificados","a7fcc3cb":"#### Configura\u00e7\u00f5es escolhidas para os testes de otimizadores:\n* M\u00e9trica Dice\n* Loss Dice\n* Tamanho do batch = 50\n* 30% dos dados reais para valida\u00e7\u00e3o\n* 100 \u00e9pocas com early stopping com patinece = 5","22c6b9d8":"* Desenvolvida para problemas de segmenta\u00e7\u00e3o na \u00e1rea biom\u00e9dica\n* Oferece melhor desempenho para em treinamento com menor quantidade de dados\n* Seu encoder reduz as imagens \u00e0 vetores contendo features importantes\n* Seu decoder aumenta a dimensionalidade da imagem, expandindo o vetor de features importantes\n* Utiliza relu como output das camadas internas\n* A arquitetura escolhida tem 10 camadas, Dropout de 0.1 ou 0.2 entre as camadas para reduzir overfitting","6141048a":"### LinkNet - Backbone Inception v3 e Pesos da ImageNet","25a651c1":"## Data Augmentation","5d047094":"### Adam","5e84435c":"* Possui learning rate adaptativo\n* Oferece r\u00e1pida converg\u00eancia para certos problemas","8d65417c":"## Compara\u00e7\u00e3o de mini batches","dc4c42c5":"### Mini Batch (100)"}}