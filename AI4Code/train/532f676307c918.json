{"cell_type":{"7a65d26d":"code","069b99c4":"code","720dc564":"code","e58c96f3":"code","da460688":"code","3c3ba620":"code","76870d97":"code","5f8a2367":"code","8bd86703":"code","bf2d2a86":"code","72888475":"code","86720cee":"code","e3215f10":"code","76106e2e":"code","bf362460":"markdown","04334279":"markdown","c4c5a047":"markdown","61c019a3":"markdown","dd8a475b":"markdown","21153604":"markdown","7a0be241":"markdown","75671ad1":"markdown","b2f44528":"markdown","d8ebb7a7":"markdown"},"source":{"7a65d26d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","069b99c4":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nfrom random import shuffle\n\nimport keras\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler , LabelEncoder\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\nfrom sklearn.metrics import accuracy_score, confusion_matrix","720dc564":"df = pd.read_csv('\/kaggle\/input\/health-care-data-set-on-heart-attack-possibility\/heart.csv')","e58c96f3":"df.head()","da460688":"df.info()","3c3ba620":"plt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True,cmap='seismic')","76870d97":"x=np.asarray(df[[\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\"]])\ny=np.asarray(df[[\"target\"]])\n","5f8a2367":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)","8bd86703":"norm = StandardScaler()\nx_train = norm.fit_transform(x_train)\nx_test = norm.fit_transform(x_test)","bf2d2a86":"lr = LogisticRegression()\nhistory_2 = lr.fit(x_train,y_train) \n\n\ny_pred_2 = lr.predict(x_test)\ny_pred_2 = (y_pred_2 > 0.5)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_2)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_2))\n\n\npred_2 = 100*accuracy_score(y_test,y_pred_2)\n\nprint('percentage Accuracy : ',pred_2)","72888475":"rnf = RandomForestClassifier(n_estimators=100,random_state=0,max_depth=5)\nhistory_3 = rnf.fit(x_train,y_train)\n\n\ny_pred_3 = rnf.predict(x_test)\ny_pred_3 = (y_pred_3 > 0.5)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_3)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_3))\n\npred_3 = 100*accuracy_score(y_test,y_pred_3)\n\nprint('percentage Accuracy : ',pred_3)","86720cee":"dt = DecisionTreeClassifier()\nhistory_4 = dt.fit(x_train, y_train)\n\n\ny_pred_4 = dt.predict(x_test)\ny_pred_4 = (y_pred_4 > 0.5)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_4)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_4))\n\npred_4 = 100*accuracy_score(y_test,y_pred_4)\n\nprint('percentage Accuracy : ',pred_4)","e3215f10":"height = [pred_2,pred_3,pred_4]\nbars = ('Logistic Reg.','Random Forest',' Decision Tree')\ny_pos = np.arange(len(bars))\n\nplt.bar(y_pos, height, color=['green', 'blue','red'])\nplt.xticks(y_pos, bars)\nplt.show()","76106e2e":"print(max(height))","bf362460":"# 4. Training of the dataset","04334279":"1. ***Logistic Regression***","c4c5a047":"# 5. Conclusion","61c019a3":"# This Notebook is divided in 5 sections\n1. Importing the Dataset and all the necessary libraries.\n2. visualization of the data\n3. Preprocessing the data\n4. Training of the data\n5. Conclusion.","dd8a475b":"2. ***Random Forest***","21153604":"3. ***Decision Tree***","7a0be241":"# 2. Visualizing the data","75671ad1":"Thus, we can conclude that Random Forest has work best in this case with accuracy being ***86.84%***\n\nHope you enjoyed the Notebook!!!\n\n***Thank you***","b2f44528":"# 3. Pre-Processing the data","d8ebb7a7":"# 1. Importing the Dataset and libraries."}}