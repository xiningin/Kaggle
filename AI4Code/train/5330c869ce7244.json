{"cell_type":{"3c5d5955":"code","3ff7f9bb":"code","aa324239":"code","dedbce42":"code","9e96ef59":"code","47b55aa2":"code","fea89a9c":"code","1eb22a11":"markdown","06c83e93":"markdown","f2175f8c":"markdown","e3c99655":"markdown","8bfe6240":"markdown"},"source":{"3c5d5955":"# Importing libraries\n\nimport pandas as pd\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","3ff7f9bb":"dataset = pd.read_csv(\"..\/input\/league-of-legends-diamond-ranked-games-10-min\/high_diamond_ranked_10min.csv\")\n\n# Dropping redundant gameID\ndataset.pop(\"gameId\")\ndataset.head()","aa324239":"scaler = StandardScaler()\n\n# Taking labels\nlabels = dataset['blueWins'].values\n\n# Dropping wins column because we don't want our network to know correct answers.\ndataset.pop(\"blueWins\")\n\n# Scaling our data\nfeatures = dataset.values\nfeatures = scaler.fit_transform(features)","dedbce42":"train_features, test_features, train_labels, test_labels = train_test_split(features,labels,test_size=0.2,random_state=18)","9e96ef59":"model = Sequential()\nmodel.add(Dense(8, input_dim=38))\nmodel.add(Dense(16, activation='relu',))\nmodel.add(Dense(1, activation='sigmoid'))\n# We're going to use binary_crossentropy as our loss function because we have two states win and lose. I tried different optimizers but Rmsprop proved to be the best for this tas.\nmodel.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])","47b55aa2":"model.fit(train_features,train_labels, batch_size=32, epochs=20)","fea89a9c":"model.evaluate(test_features,test_labels)","1eb22a11":"# Splitting data\nLet's split our data to train and test set, I prefer sklearn train_test_split method.","06c83e93":"# Training and Test\nAfter training we get almost 74% accuracy. Evaluation says that we have 72% accuracy not far from Linear Regression.","f2175f8c":"# Keras Binary Classification\nI'm new to ML and this is my first notebook, It would be nice if anyone point out my mistakes.","e3c99655":"# Scaling\nBefore we split our dataset and fit it to neural network let's scale our data. I'm going to use sklearn StandartScaler.","8bfe6240":"# Creating model\nI have tried different activation functions and nodes so this is the best combination."}}