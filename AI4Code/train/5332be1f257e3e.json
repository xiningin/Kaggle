{"cell_type":{"41b1865a":"code","e3aaca70":"code","b47a3030":"code","bab4e8cb":"code","3bcb698f":"code","8f0c3e33":"code","d4c07341":"code","680cdb93":"code","01e23f0f":"code","f2d84631":"code","f83d3d9a":"code","139e4fb1":"code","87705188":"code","d7600fb3":"code","af8f033f":"code","70826a0b":"code","7d729102":"code","365134bb":"code","fbeedb3e":"code","00befb94":"code","39257dc6":"markdown","963f3f3d":"markdown","e356b5d5":"markdown","a5969496":"markdown","eacb7ea4":"markdown","cbac8fcc":"markdown","aa72f2b7":"markdown","c1970e96":"markdown","0fd137e8":"markdown","f3f1fed3":"markdown","d52eaad4":"markdown","81bc12eb":"markdown","0afb2408":"markdown","56c7da57":"markdown","e5b51580":"markdown","1bc92b36":"markdown"},"source":{"41b1865a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e3aaca70":"data=pd.read_csv(\"..\/input\/googleplaystore_user_reviews.csv\",encoding=\"latin1\")","b47a3030":"data.head()","bab4e8cb":"df=pd.concat([data.Translated_Review,data.Sentiment],axis=1)\ndf.dropna(axis=0,inplace=True)\ndf.head(10)","3bcb698f":"df.Sentiment.value_counts()","8f0c3e33":"df.Sentiment=[0 if i==\"Positive\" else 1 if i== \"Negative\" else 2 for i in df.Sentiment]\ndf.head(10)","d4c07341":"#Data cleaning\nimport re\nfirst_text=df.Translated_Review[0]\ntext=re.sub(\"[^a-zA-Z]\",\" \",first_text) #changing characters with space\ntext=text.lower()","680cdb93":"print(df.Translated_Review[0]) #lets review of changings\nprint(text)","01e23f0f":"#stopwords (irrelavent words)\nimport nltk\n#nltk.download(\"stopwords\")\n#nltk.download(\"punkt\")\nfrom nltk.corpus import stopwords\ntext=nltk.word_tokenize(text) #separate all words","f2d84631":"text","f83d3d9a":"#lemmatization books----> book\nimport nltk as nlp\nlemma=nlp.WordNetLemmatizer()\ntext=[lemma.lemmatize(i) for i in text]\ntext=\" \".join(text)\ntext","139e4fb1":"text_list=[]\nfor i in df.Translated_Review:\n    text=re.sub(\"[^a-zA-Z]\",\" \",i)\n    text=text.lower()\n    text=nltk.word_tokenize(text)\n    lemma=nlp.WordNetLemmatizer()\n    text=[lemma.lemmatize(word) for word in text]\n    text=\" \".join(text)\n    text_list.append(text)","87705188":"text_list[:10]","d7600fb3":"#bag of words\nfrom sklearn.feature_extraction.text import CountVectorizer\nmax_features=200000\ncou_vec=CountVectorizer(max_features=max_features,stop_words=\"english\")\nsparce_matrix=cou_vec.fit_transform(text_list).toarray()\nall_words=cou_vec.get_feature_names()\nprint(\"Most used words: \",all_words[50:100])","af8f033f":"from wordcloud import WordCloud\nplt.subplots(figsize=(12,12))\nwordcloud=WordCloud(background_color=\"white\",width=1024,height=768).generate(\" \".join(all_words[100:]))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","70826a0b":"#classification\ny=df.iloc[:,1].values\nx=sparce_matrix\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n","7d729102":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 10, random_state=42)\nrf.fit(x_train,y_train)\nprint(\"accuracy: \",rf.score(x_test,y_test))","365134bb":"#confussion matrix\ny_pred=rf.predict(x_test)\ny_true=y_test\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nnames=[\"Positive\",\"Negative\",\"Neutral\"]\ncm=confusion_matrix(y_true,y_pred)\nf,ax=plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidth=.5,linecolor=\"r\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nplt.show()","fbeedb3e":"#logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(x_train,y_train)\nprint(\"lr accuracy: \",lr.score(x_test,y_test))","00befb94":"#confussion matrix\ny_pred=lr.predict(x_test)\ny_true=y_test\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nnames=[\"Positive\",\"Negative\",\"Neutral\"]\ncm=confusion_matrix(y_true,y_pred)\nf,ax=plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidth=.5,linecolor=\"r\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nplt.show()","39257dc6":"**What is lemmatization??? With lemmatization we can convert words to their root format.** \n\nFor instance books--->book","963f3f3d":"**Here we will remove characters which are not letters.**         \":) # $ @ ()!-\/*\"   like that!\n\nAlso converting them lower case.","e356b5d5":"* In Conclusion\nWe used NLP tools in order to train our dataset. After training we classified reviews with our model. At the final we have accuracy more than %90.\n\n* If you have any question or any suggestions feel free to write me.","a5969496":"Here we can see basic text cleaning. Keep going deeper..","eacb7ea4":"Natural Language Processing is the sub-field of AI that is focused on enabling computers to understand and process human languages.\n\n**In this kernel I will show you the computers can understand the human language or not?** We will also classify the types of reviews which are Positive, Negative and Neutral.\n\nHere on the photo you can check the schema that we will do step by step.\n\nref: Adam Geitgey on www.medium.com","cbac8fcc":"Yes! Now our sentence is really simple. Keep going to apply to all dataset.","aa72f2b7":"![](https:\/\/i.ibb.co\/bstrG04\/1-z-HLs87sp8-R61eh-Uo-Xep-WHA.png)","c1970e96":"![](https:\/\/i.ibb.co\/NrbjNxW\/1-e-Ueduf-Al7-s-I-QWSEIst-Zg.png)","0fd137e8":"**With \"tokenize\" wi seperated all words.**\n\nAlso with stopwords we can remove irrelavent words. But I will do this step later.","f3f1fed3":"We are using google reviews and their Sentiment types which are Positive-Negative etc..","d52eaad4":"Converting review types to int form in order to use classification methods.\n\n**0= Positive, 1=Negative, 2= Neutral**","81bc12eb":"**Selecting reviews and types of reviews.**","0afb2408":"**We converted our textes to array form, also removed irrelavent words.**\n\nBefore classification let's make it more colorful :) Here I visualized most used words:","56c7da57":"Here with \"bag of words\" we are removing irrelavent words and creating matrix form in order to make them in order. Also after matrix form we will have our sentences with numbers. This means that **now our computer can understand human language!**\n\n\nLet's understand the process easier with next images.","e5b51580":"Wowww %87 accuracy! The result is really good, let's try logistic regression to improve accuracy.","1bc92b36":"![](https:\/\/i.ibb.co\/42Gs1GH\/atap-0401.png)\n"}}