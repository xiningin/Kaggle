{"cell_type":{"7b859b63":"code","5ea156f9":"code","466a8ffd":"code","e439729d":"code","5ebf0699":"code","25290104":"code","708019dc":"code","835261e2":"code","6b14a095":"code","6b79d253":"code","f49d7d2d":"code","dcee619a":"code","3f93aeb6":"code","521f6767":"code","e54d3731":"code","3e4dcbfb":"code","74de3d43":"code","bb2a51b5":"code","db98e8ba":"code","1c2e77f2":"code","bdedd848":"code","ffd46ea0":"code","aa635140":"code","6e72a2c3":"markdown","f92562ef":"markdown","e70a02aa":"markdown","8fa2de20":"markdown","79b45db9":"markdown","dcef4f02":"markdown","a7bbaae3":"markdown","81b75199":"markdown","acdb832e":"markdown","0020b99d":"markdown","99f38511":"markdown","009f65f9":"markdown","5cdfa6c1":"markdown","0114ebd4":"markdown","210fac2f":"markdown","462445f5":"markdown","dc89ace9":"markdown","9e9eed37":"markdown","f4c9d695":"markdown","0992830b":"markdown","7f26d5eb":"markdown","7260af9b":"markdown","7a7f5b00":"markdown","df942027":"markdown","27648d4c":"markdown","3e14261a":"markdown","f7c979d2":"markdown"},"source":{"7b859b63":"import pandas as pd\nimport numpy as np\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\n# Don't Show Warning Messages\nimport warnings\nwarnings.filterwarnings('ignore')","5ea156f9":"IMG_HEIGHT = 128\nIMG_WIDTH = 128\nIMG_CHANNELS = 1\n\nNUM_TEST_IMAGES = 10\n","466a8ffd":"# get a list of files in each folder\n\nimg_list = os.listdir('..\/input\/bbbc005_v1_images\/BBBC005_v1_images')\nmask_list = os.listdir('..\/input\/bbbc005_v1_ground_truth\/BBBC005_v1_ground_truth')\n\n# create a dataframe\ndf_images = pd.DataFrame(img_list, columns=['image_id'])\n\n# filter out the non image file that's called .htaccess\ndf_images = df_images[df_images['image_id'] != '.htaccess']\n\n\n\n# Example file name: SIMCEPImages_A13_C53_F1_s23_w2.TIF\n\n\n# ======================================================\n# Add a column showing how many cells are on each image\n# ======================================================\n\ndef get_num_cells(x):\n    # split on the _\n    a = x.split('_')\n    # choose the third item\n    b = a[2] # e.g. C53\n    # choose second item onwards and convert to int\n    num_cells = int(b[1:])\n    \n    return num_cells\n\n# create a new column called 'num_cells'\ndf_images['num_cells'] = df_images['image_id'].apply(get_num_cells)\n\n\n# ================================================\n# Add a column indicating if an image has a mask.\n# ================================================\n\n# Keep in mind images and masks have the same file names.\n\ndef check_for_mask(x):\n    if x in mask_list:\n        return 'yes'\n    else:\n        return 'no'\n    \n# create a new column called 'has_mask'\ndf_images['has_mask'] = df_images['image_id'].apply(check_for_mask)\n\n\n\n# ===========================================================\n# Add a column showing how much blur was added to each image\n# ===========================================================\n\ndef get_blur_amt(x):\n    # split on the _\n    a = x.split('_')\n    # choose the third item\n    b = a[3] # e.g. F1\n    # choose second item onwards and convert to int\n    blur_amt = int(b[1:])\n    \n    return blur_amt\n\n# create a new column called 'blur_amt'\ndf_images['blur_amt'] = df_images['image_id'].apply(get_blur_amt)","e439729d":"df_images.head(10)","5ebf0699":"df_masks = df_images[df_images['has_mask'] == 'yes']\n\n# create a new column called mask_id that is just a copy of image_id\ndf_masks['mask_id'] = df_masks['image_id']\n\ndf_masks.shape","25290104":"df_masks.head()","708019dc":"# create a test set\ndf_test = df_masks.sample(NUM_TEST_IMAGES, random_state=101)\n\n# Reset the index.\n# This is so that we can use loc to access mask id's later.\ndf_test = df_test.reset_index(drop=True)\n\n# create a list of test images\ntest_images_list = list(df_test['image_id'])\n\n\n# Select only rows that are not part of the test set.\n# Note the use of ~ to execute 'not in'.\ndf_masks = df_masks[~df_masks['image_id'].isin(test_images_list)]\n\nprint(df_masks.shape)\nprint(df_test.shape)","835261e2":"# ==================================================== #","6b14a095":"sample_image = 'SIMCEPImages_A06_C23_F1_s11_w2.TIF'\npath_image = '..\/input\/bbbc005_v1_images\/BBBC005_v1_images\/' + sample_image\n\n# read the image using skimage\nimage = imread(path_image)\n\nplt.imshow(image)","6b79d253":"print('Shape: ', image.shape)\nprint('Max pixel value: ', image.max())\nprint('Min pixel value: ', image.min())","f49d7d2d":"sample_mask = 'SIMCEPImages_A06_C23_F1_s11_w2.TIF'\npath_mask = '..\/input\/bbbc005_v1_ground_truth\/BBBC005_v1_ground_truth\/' + sample_mask\n\n# read the mask using skimage\nmask = imread(path_mask)\n\nplt.imshow(mask, cmap='gray')","dcee619a":"print('Shape: ', mask.shape)\nprint('Max pixel value: ', mask.max())\nprint('Min pixel value: ', mask.min())","3f93aeb6":"# Get lists of images and their masks.\nimage_id_list = list(df_masks['image_id'])\nmask_id_list = list(df_masks['mask_id'])\ntest_id_list = list(df_test['image_id'])\n\n# Create empty arrays\n\nX_train = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n\nY_train = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\nX_test = np.zeros((NUM_TEST_IMAGES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n\n","521f6767":"# X_train\n\n\nfor i, image_id in enumerate(image_id_list):\n    \n    path_image = '..\/input\/bbbc005_v1_images\/BBBC005_v1_images\/' + image_id\n    \n    # read the image using skimage\n    image = imread(path_image)\n    \n    # resize the image\n    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    \n    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n    image = np.expand_dims(image, axis=-1)\n    \n    # insert the image into X_train\n    X_train[i] = image\n    \nX_train.shape","e54d3731":"# Y_train\n\n\nfor i, mask_id in enumerate(mask_id_list):\n    \n    path_mask = '..\/input\/bbbc005_v1_ground_truth\/BBBC005_v1_ground_truth\/' + mask_id\n    \n    # read the image using skimage\n    mask = imread(path_mask)\n    \n    # resize the image\n    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    \n    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n    mask = np.expand_dims(mask, axis=-1)\n    \n    # insert the image into Y_Train\n    Y_train[i] = mask\n\nY_train.shape","3e4dcbfb":"# X_test\n\nfor i, image_id in enumerate(test_id_list):\n    \n    path_image = '..\/input\/bbbc005_v1_images\/BBBC005_v1_images\/' + image_id\n    \n    # read the image using skimage\n    image = imread(path_image)\n    \n    # resize the image\n    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    \n    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n    image = np.expand_dims(image, axis=-1)\n    \n    # insert the image into X_test\n    X_test[i] = image\n    \nX_test.shape","74de3d43":"from keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf","bb2a51b5":"# source: https:\/\/www.kaggle.com\/keegil\/keras-u-net-starter-lb-0-277\n\n\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n\ns = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\n\nmodel.summary()","db98e8ba":"filepath = \"model.h5\"\n\nearlystopper = EarlyStopping(patience=5, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min')\n\ncallbacks_list = [earlystopper, checkpoint]\n\nhistory = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n                    callbacks=callbacks_list)","1c2e77f2":"# Make a prediction\n\n# use the best epoch\nmodel.load_weights('model.h5')\n\ntest_preds = model.predict(X_test)","bdedd848":"# Threshold the predictions\n\npreds_test_thresh = (test_preds >= 0.5).astype(np.uint8)","ffd46ea0":"# Display a thresholded mask\n\ntest_img = preds_test_thresh[5, :, :, 0]\n\nplt.imshow(test_img, cmap='gray')","aa635140":"# set up the canvas for the subplots\nplt.figure(figsize=(10,10))\nplt.axis('Off')\n\n# Our subplot will contain 3 rows and 3 columns\n# plt.subplot(nrows, ncols, plot_number)\n\n\n# == row 1 ==\n\n# image\nplt.subplot(3,3,1)\ntest_image = X_test[1, :, :, 0]\nplt.imshow(test_image)\nplt.title('Test Image', fontsize=14)\nplt.axis('off')\n\n\n# true mask\nplt.subplot(3,3,2)\nmask_id = df_test.loc[1,'mask_id']\npath_mask = '..\/input\/bbbc005_v1_ground_truth\/BBBC005_v1_ground_truth\/' + mask_id\nmask = imread(path_mask)\nmask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\nplt.imshow(mask, cmap='gray')\nplt.title('True Mask', fontsize=14)\nplt.axis('off')\n\n# predicted mask\nplt.subplot(3,3,3)\ntest_mask = preds_test_thresh[1, :, :, 0]\nplt.imshow(test_mask, cmap='gray')\nplt.title('Pred Mask', fontsize=14)\nplt.axis('off')\n\n\n# == row 2 ==\n\n# image\nplt.subplot(3,3,4)\ntest_image = X_test[2, :, :, 0]\nplt.imshow(test_image)\nplt.title('Test Image', fontsize=14)\nplt.axis('off')\n\n\n# true mask\nplt.subplot(3,3,5)\nmask_id = df_test.loc[2,'mask_id']\npath_mask = '..\/input\/bbbc005_v1_ground_truth\/BBBC005_v1_ground_truth\/' + mask_id\nmask = imread(path_mask)\nmask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\nplt.imshow(mask, cmap='gray')\nplt.title('True Mask', fontsize=14)\nplt.axis('off')\n\n# predicted mask\nplt.subplot(3,3,6)\ntest_mask = preds_test_thresh[2, :, :, 0]\nplt.imshow(test_mask, cmap='gray')\nplt.title('Pred Mask', fontsize=14)\nplt.axis('off')\n\n# == row 3 ==\n\n# image\nplt.subplot(3,3,7)\ntest_image = X_test[3, :, :, 0]\nplt.imshow(test_image)\nplt.title('Test Image', fontsize=14)\nplt.axis('off')\n\n\n# true mask\nplt.subplot(3,3,8)\nmask_id = df_test.loc[3,'mask_id']\npath_mask = '..\/input\/bbbc005_v1_ground_truth\/BBBC005_v1_ground_truth\/' + mask_id\nmask = imread(path_mask)\nmask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\nplt.imshow(mask, cmap='gray')\nplt.title('True Mask', fontsize=14)\nplt.axis('off')\n\n# predicted mask\nplt.subplot(3,3,9)\ntest_mask = preds_test_thresh[3, :, :, 0]\nplt.imshow(test_mask, cmap='gray')\nplt.title('Pred Mask', fontsize=14)\nplt.axis('off')\n\n\nplt.tight_layout()\nplt.show()","6e72a2c3":"## Create X_train, Y_train and X_test","f92562ef":"## Put Info Into a Dataframe","e70a02aa":"The image and its associated mask have the same shape. We see that the image is 2D and not 3D. The mask is 2D. The image has pixel values in the range 0 to 255. The mask has pixel values that are either 0 or 255. 0 is black and 255 is white.\n\nThe model requires this input format:<br>\n\n*(num_samples, num_rows, num_columns, num_channels)*\n\nTherefore, we will need to use np.expand_dims to add a channel dimension to both the image and the mask.\n\nAlso, the model expects input images and masks to have the same width and height. We will therefore resize both images and the masks to 128 x 128.","8fa2de20":"In segmentation our goal is to extract a specific object or group of objects from an image. In this case those objects are cells.\n\nThis task is a binary classification problem. We are given a microscope image. We need to extract the cells from the image. To do this we need to classify each pixel on the image as either being part of a cell or not. The target values are given to us as a black and white mask.\n\nThe image could be rgb (3D, 3 channels) or black and white (2D, 1 channel). It's essentially a matrix with values that range between 0 and 255.\n\nThe mask is a 2D matrix. It contains only two values that represent either black or white.\n\nBecause we treat this as a binary classification problem, we will use the Sigmoid activation function in the last layer of the neural network. We will also use the binary_crossentropy loss function. We will train the network using the images as the input and the masks as the target.\n\nWhen Predict is run, the model will output a 2D mask. Each pixel in the predicted mask represents the probability that that pixel is part of a cell. We need to convert these probabilities to binary. To do this we threshold the mask by setting all pixel values that are >= 0.5 to 1. All values < 0.5 we set to zero. \n\nThis notebook is based on this excellent kernel by Kjetil \u00c5mdal-S\u00e6vik: [Keras U-Net starter - LB 0.277](https:\/\/www.kaggle.com\/keegil\/keras-u-net-starter-lb-0-277)<br> Many thanks to Kjetil for demystifying the segmentation deep learning workflow.","79b45db9":"> **Data**<br>\n\n> We are given 19,200 images. Of those 1200 have associated masks. We will only use those 1200 images in this kernel. The images and their masks have the same file name but they are stored in separate folders.","dcef4f02":"Thank you for reading.","a7bbaae3":"We will only use this dataframe in the rest of this notebook.","81b75199":"This basic setup is producing good results. The model is identifying the cells quite well. However, the cells on the predicted masks are slightly larger than the actual cells and the boundaries are not smooth. Could this be because of the blur that was added to each image? This is something you could try to improve. Maybe try tuning some parameters, use custom loss or even try a different architecture.","acdb832e":"<hr>","0020b99d":"## Introduction","99f38511":"## Define the Model Architecture","009f65f9":"## Create a dataframe containing only images that have masks","5cdfa6c1":"## Make a Prediction","0114ebd4":"Here we want to find out:\n\n- What are the shapes?\n- Is the image rgb or black and white?\n\nWe need this info to write the code that will process the images and masks into a format that the model requires.","210fac2f":"Here we will display 3 test images, their true masks and the masks that the model predicted for those images.","462445f5":"## Inspect one Image and Mask","dc89ace9":"## Create a Test Set","9e9eed37":"## Image","f4c9d695":"We will use the U-Net arhitecture. U-Net is a cnn that was developed for biomedical image segmentation. It was designed to give good results when only a small number of training images are available. It was also designed to run fast.\n\nPaper: [U-Net: Convolutional Networks for Biomedical Image Segmentation](https:\/\/arxiv.org\/abs\/1505.04597)<br>\nOlaf Ronneberger, Philipp Fischer, Thomas Brox\n\nTake note that the images are normalized inside the model using a lamda layer.","0992830b":"## Mask","7f26d5eb":"## Inspect the Results","7260af9b":"Here we will create a test set containing 10 images. Keras will automatically create a validation set during training.","7a7f5b00":"This dataframe will show the following info:\n- id's of all images\n- does the image have a mask?\n- number of cells on each image\n- the blur amount that was aded to each image","df942027":"## Conclusion","27648d4c":"## Train the Model","3e14261a":"This processing code is the most important part of this kernel. If you see crazy results during training, like negative loss values - then you've most probably made an error on this step. ","f7c979d2":"We will let Keras automatically create a 10% validation set during training. I haven't specified a metric, but for segmentation problems I've often seen custom metrics like IOU or dice coef be used."}}