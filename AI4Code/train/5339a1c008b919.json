{"cell_type":{"11cd9c4c":"code","df75ed71":"code","79eeae3d":"code","ad0df850":"code","edccef15":"code","50148128":"code","bc508709":"code","38e7d4cb":"code","4438b572":"code","c9762057":"code","1709a14f":"code","8a10717c":"code","48c30776":"code","9dc0138a":"code","969a813c":"code","05d896b4":"code","6939b17d":"code","8eaf4656":"code","b7b017e9":"code","6625c65d":"code","2e97f905":"code","f849247d":"code","5c0dbab2":"code","cac318f2":"code","2223c7a8":"code","8f0d1fef":"markdown","10d20577":"markdown","a1e78624":"markdown","c2e4a0f1":"markdown","a2322c00":"markdown","f6e9612d":"markdown","f29fadc5":"markdown","e83581bd":"markdown","3aa9bc05":"markdown","c55a1910":"markdown","b2e23626":"markdown","97708bf6":"markdown","75013089":"markdown","0a7a78b6":"markdown","3d9fd96a":"markdown","85ed7f08":"markdown","f1f183c8":"markdown","6d8be12e":"markdown","95a7310e":"markdown","ae3ee438":"markdown","9f1c0365":"markdown","b47fbbe9":"markdown","8c4dd8b3":"markdown","6dcb28b5":"markdown"},"source":{"11cd9c4c":"print('Loading packages')\nimport os              # Package to use directory command to list files\nimport numpy as np     # linear algebra\nimport pandas as pd    # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import stats # for Statistics\nimport seaborn as sns  # Used for plotting the graph\nfrom statistics import mean\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import rcParams\n%matplotlib inline\nle = preprocessing.LabelEncoder()\nimport re\nprint('These are the files to use: ',os.listdir(\"..\/input\"))   # Listing Files","df75ed71":"print('reading input files..')\ndata = pd.read_csv('..\/input\/train.csv')\nsampl = pd.read_csv('..\/input\/gender_submission.csv')","79eeae3d":"test  = pd.read_csv('..\/input\/test.csv')","ad0df850":"# Appending test data with train data, since both dataset can have related values like family name and ticket\ndf = data.append(test, sort = False)","edccef15":"df.head()","50148128":"totalt = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([totalt, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(6)","bc508709":"df.loc[df['Fare'].isnull()]","38e7d4cb":"df.loc[(df['Age'] >= 60) & (df['Pclass'] ==3) & (df['Sex'] == 'male') & (df['Embarked'] =='S')]","4438b572":"df.loc[df['Fare'].isnull(), 'Fare'] = 7            #First fill missing fare by least value","c9762057":"train1 = df[0:891].copy()\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8,3.5))\nax = sns.countplot(x='Pclass',hue=\"Survived\", data=train1)","1709a14f":"train1 = df[0:891].copy()\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10,3))\nax = sns.barplot(x=\"Pclass\", y=\"Survived\",hue='Sex', data=train1)","8a10717c":"df.Cabin = df.Cabin.fillna('0')   # Filling missing values with zero\n\nle.fit(df['Cabin'].astype(str))   # Using label encoder imported at beggining le = preprocessing.LabelEncoder()\ndf['Cabin'] = le.transform(df['Cabin'].astype(str))","48c30776":"# Fill missing Age\n## Lets predict the age of a person and fill the missing Age\nfeatures = ['Pclass','SibSp','Parch','Fare']\nfrom sklearn.ensemble import ExtraTreesRegressor as ETRg\ndef AgeFunc(df):\n    Etr = ETRg(n_estimators = 200, random_state = 2)\n    AgeX_Train = df[features][df.Age.notnull()]\n    AgeY_Train = df['Age'][df.Age.notnull()]\n    AgeX_Test = df[features][df.Age.isnull()]\n    \n    Etr.fit(AgeX_Train,np.ravel(AgeY_Train))\n    AgePred = Etr.predict(AgeX_Test)\n    df.loc[df.Age.isnull(), 'Age'] = AgePred\n    \nAgeFunc(df)","9dc0138a":"df.loc[df['Embarked'].isnull()]","969a813c":"#Lets Check first from where most 1st Class passesnger Came\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(12,2))\nax = sns.barplot(x=\"Embarked\", y=\"Survived\",hue='Pclass', data=df)","05d896b4":"def FillEmbk(data):\n    var = 'Embarked'\n    data.loc[(data.Embarked.isnull()),'Embarked']= 'C'\nFillEmbk(df)","6939b17d":"# Label Encode Embarked\ndef LablFunc(data):\n    lst = {'Embarked','Sex'}\n    for i in lst:\n        le.fit(data[i].astype(str))\n        data[i] = le.transform(data[i].astype(str))\nLablFunc(df)","8eaf4656":"df.columns","b7b017e9":"# Lets Scale the data now\nfrom sklearn.preprocessing import StandardScaler\ntarget = data['Survived'].values\nselect_features = ['Pclass', 'Age','SibSp', 'Parch', 'Fare', 'Embarked','Cabin','Sex']\nscaler = StandardScaler()\ndfScaled = scaler.fit_transform(df[select_features])\ntrain = dfScaled[0:891].copy()\ntest = dfScaled[891:].copy()","6625c65d":"# Checking best features\nfrom sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, len(select_features))\nselector.fit(train, target)\nscores = -np.log10(selector.pvalues_)\nindices = np.argsort(scores)[::-1]\n\nprint('Features importance:')\nfor i in range(len(scores)):\n    print('%.2f %s' % (scores[indices[i]], select_features[indices[i]]))","2e97f905":"from sklearn.ensemble import RandomForestClassifier  # importing model to use for our prediction","f849247d":"SrchRFC = RandomForestClassifier(max_depth = 5, min_samples_split = 4, n_estimators = 500,\n                                 random_state = 20, n_jobs = -1)\nSrchRFC.fit(train, target)   # Training model with training data","5c0dbab2":"prc = SrchRFC.predict(train)\naccuracy_score(target,prc)","cac318f2":"prdt2 = SrchRFC.predict(test)   #using Random Forest Classifier\nprint('Predicted result: ', prdt2)","2223c7a8":"sampl['Survived'] = pd.DataFrame(prdt2)\nsampl.to_csv('submission110.csv', index=False)","8f0d1fef":"## We will now label encode Embarked and Sex column","10d20577":"### First we will be checking **from where most of the 1st class passaengers came from**, based on that we will fill missing value.","a1e78624":"So we got null values in **Cabin, Age, Embarked and Fare**. Survived we need to find out.","c2e4a0f1":"Let's append test data with train data to make relation between train and test data. It makes all operation easy.","a2322c00":"## Submitting the file","f6e9612d":"### From 'C' high number of 1st Pclass people Survived, lets fill 'C' in missing value ###","f29fadc5":"### Now we will be **filling missing Age**.\n\n**In beggining** you can fill **missing value by mean, meadian or mode** value, to make it easy just for beggining. e.g. \n\ndata['Cabin'] = data['Cabin'].fillna(data['Cabin'].mode())\n\nLater come back to this point when you start understanding prediction method. I have used ExtraTreesRegressor to predict age based on all columns.","e83581bd":"This tutorial is for you, **if you are begginer** in machine learning.\nIn this kernel we will be learning **simple random forest** model to use and **learn the Visualizations** using **matplotlib**.","3aa9bc05":"Let's **Visualize** the data using plots.\n\nFirst, Lets check which Passenger class Survived most. Using sns countplot.\nAdditional Reference for Countplot https:\/\/seaborn.pydata.org\/generated\/seaborn.countplot.html?highlight=countplot#seaborn.countplot","c55a1910":"Now let's check **missing values of Embarked** column.","b2e23626":"\n## Please upvote this Kernel, if you find it useful.## \n","97708bf6":"### Now we will predict values for test data","75013089":"### Import the Model program to train and predict","0a7a78b6":"#### Let's check first accuracy score after predicting values for train data.","3d9fd96a":"Columns with value NaN are null values. We need to fill missing\/null values after exploring the data. \n\nLet's first check which all columns have missing values:","85ed7f08":"We can see that Passenger **class 1 Survived most** and **3rd class survived least**.","f1f183c8":"Let's explore more for **Passenger class vs Sex**. We will be plotting **sns barplot** for this.\n\nAdditional reference for barplot: https:\/\/seaborn.pydata.org\/generated\/seaborn.barplot.html?highlight=barplot#seaborn.barplot","6d8be12e":"Lets first check missing fare","95a7310e":"Now we will be using **label encoding** since for most of the operations we need label encoding **to convert Text data to Numeric data**.\n\nAdditional reference for Label Encoding: \n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html","ae3ee438":"Let's find simlar data, and fill that for missing fare","9f1c0365":"### Scale the data now","b47fbbe9":"**Basics of Python** : https:\/\/www.w3schools.com\/python\/python_syntax.asp\n\n**Use link** https:\/\/pandas.pydata.org\/pandas-docs\/stable\/getting_started\/10min.html#min to have a basic understanding of **powerful pandas library**. It makes easy to read, process, write the data.\n\n**Reading and writing using pandas:** https:\/\/pandas.pydata.org\/pandas-docs\/stable\/getting_started\/10min.html#getting-data-in-out\n\nTo make array operation easy, we need array handling library\/utility. **Numpy** can do it all for you.\n\n**use link** https:\/\/docs.scipy.org\/doc\/numpy\/user\/quickstart.html to learn **Numpy**","8c4dd8b3":"Average Fare look like 7.00, let's move with this value","6dcb28b5":"#### In this tutorial, we will learn:\n1. Reading input file\n2. Exploring input data\n3. Finding missing data\n4. Filling missing data\n5. Scale up the input data\n6. Predict the input data using Random Forest Classifier model\n7. Submit the file to competetion"}}