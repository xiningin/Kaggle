{"cell_type":{"db52cce2":"code","de427855":"code","30933ec5":"code","972cd895":"code","cd13a787":"code","aea484d2":"code","0457f256":"code","30a07637":"code","dada6bf7":"code","cf1be3bd":"code","92ef555f":"code","26c01c94":"markdown","3aa56c2d":"markdown","a77486aa":"markdown","78227271":"markdown","212d89cd":"markdown","355f70cb":"markdown","97810e64":"markdown","2f0a2d38":"markdown","b7bde411":"markdown","b99514f3":"markdown","bd20bd0d":"markdown","6b1e40b4":"markdown","f43e4419":"markdown","a9e96d9d":"markdown","2b8196b2":"markdown","00d58cd7":"markdown","09fdbc35":"markdown","f7bdf5c2":"markdown","01d7af64":"markdown","80cd1c32":"markdown","692121ca":"markdown","40480986":"markdown","0e515415":"markdown","8845ca66":"markdown","3520d9ca":"markdown","4eb04a80":"markdown"},"source":{"db52cce2":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","de427855":"df = pd.read_csv('..\/input\/placementdataforlearning\/placement (1).csv')\ndf.shape\n","30933ec5":"plt.scatter(df['cgpa'],df['package'])\nplt.xlabel('CGPA')\nplt.ylabel('Package(in lpa)')","972cd895":"X = df.iloc[:,0:1]\ny = df.iloc[:,-1]","cd13a787":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)","aea484d2":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)","0457f256":"plt.scatter(df['cgpa'],df['package'])\nplt.plot(X_train,lr.predict(X_train),color='red')\nplt.xlabel('CGPA')\nplt.ylabel('Package(in lpa)')","30a07637":"from sklearn.metrics import mean_absolute_error\ny_pred = lr.predict(X_test)","dada6bf7":"print(\"MAE\",mean_absolute_error(y_test,y_pred))\nprint(\"Note the MAE value ({}) is in terms of lpa\".format(mean_absolute_error(y_test,y_pred)))","cf1be3bd":"from sklearn.metrics import mean_squared_error\nprint(\"MSE\",mean_squared_error(y_test,y_pred))\nprint(\"Note the MSE value ({}) is NOT in terms of lpa\".format(mean_squared_error(y_test,y_pred)))","92ef555f":"print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\nprint(\"Note the MAE value ({}) is in terms of lpa\".format(np.sqrt(mean_squared_error(y_test,y_pred))))","26c01c94":"You can also use the formula of MAE and make your own function to predict MAE Scores but as sklearn provide MAE so i will use the prebuild method","3aa56c2d":"# Conclusion\n#### MSE, RMSE, or MAE are better be used to compare performance between different regression models. Personally, I would prefer using RMSE and I think Kaggle also uses it to assess the submission. However, it makes total sense to use MSE if the value is not too big and MAE if you do not want to penalize large prediction errors.","a77486aa":"As you can see how data is linearly aligned so it is a perfect example of Linear Regression","78227271":"## Advantage and Disadvantage of MEAN SQUARED ERROR(MSE)\n##### The main advantage of MSE is that it is completely differentiable so, it can be easily used as a loss function.\n##### But there are few disadvantages as well. Firstly, due to the squaring effect in MSE, the output units you get will always be squared units. \n##### If you have outliers in your data MSE can fluctuate a lot and it will become harder to interpret. Also, if you are using MSE as your metric then it is advised to normalize or standardize your data, otherwise, the metric will inflate a lot.","212d89cd":"# Types Of Regression Metrics","355f70cb":"### Before evaluating the model using evaluation metrics, one should go for a residual plot.\n\nResiduals are significant when figuring the quality of the model. One should look at two things in residuals, their magnitude and whether they form a pattern or not.\n\n- The further away the residuals are from 0, the more faulty the model is.\n\n- When the residual\u2019s average is not zero, it shows that the model is frequently under or over predicting.\n\n- When the residual plot consists of patterns, it shows the model fails to explain a few properties of the data.","97810e64":"![Image](https:\/\/miro.medium.com\/max\/1000\/1*OsE_OVQrhlQ2qJ_hwRWCgw.jpeg)\n\n# Introduction\n#### Model evaluation is very important in data science. It helps you to understand the performance of your model and makes it easy to present your model to other people. There are many different evaluation metrics out there but only some of them are suitable to be used for regression. This notebook will cover the different metrics for the regression model and the difference between them. Hopefully, after you read this Kernal, you are clear on which metrics to apply to your future regression model.","2f0a2d38":"## MEAN ABSOLUTE ERROR (MAE):\nIt is the mean of the absolute difference between the actual value in the dataset and the value predicted by the model.\n![MAE = (1\/n) * \u03a3|yi \u2013 xi|](https:\/\/images.ctfassets.net\/piwi0eufbb2g\/4g4m98RiMIJmdGJCKIVbtk\/4e5d32f1f527a97e04503ee0d3b1f7c9\/image.png)\n#### Where:\n- N = the count of the data points.\n- Y = the actual value in the dataset\n- Y cap = the model\u2019s predicted value\n\nThe absolute values are taken, and if it\u2019s not then the negative and positive difference will cancel out each other. The smaller the MAE, the more accurate the model is. If MAE is zero it shows the model is perfect. If MAE is large then the model is not good.","b7bde411":"### Extracting and Preparing for Data Modeling","b99514f3":"![](https:\/\/pluspng.com\/img-png\/png-student-thinking-students-900.jpg)\n\n## WHAT DOES A RESIDUAL PLOT DO?\nResidual plots tell us if the model is biased or not, better than any other performance metric. If the residual plot shows a random distribution of the predicted and actual values and not a particular pattern, then we can evaluate the model with various other metrics.\n\nWe have residuals for each and every data point, but we need some summarizing agents to see the overview of the data. That\u2019s where these metrics come in.","bd20bd0d":"# Steps Before Using evaluation metrics","6b1e40b4":"### Implementation of Root Mean Square Error(RMSE)","f43e4419":"## Implementation of MEAN ABSOLUTE ERROR (MAE)","a9e96d9d":"### There are many types of Regression Metrices But today we will Discuss Top4 Most Used Method and Those are:\n>  - MEAN ABSOLUTE ERROR (MAE)\n>  - MEAN SQUARED ERROR (MSE)\n>  - ROOT MEAN SQUARED ERROR(RMSE)\n>  - R2 Score","2b8196b2":"## MEAN SQUARED ERROR (MSE)\nThis is the mean of the squared difference of the actual value in the dataset and the value predicted by the model.\n![MSE(\u03b8obs, i) = E[(\u03b8obs, i \u2013 \u03b8)2]](https:\/\/images.ctfassets.net\/piwi0eufbb2g\/2eSAc5PQTXa6y1mm6BN6Ne\/1b7c27f4d75bd79e83910e3a2ff4be59\/image.png)\n\nHere,\n- N = the count of data points in the data.\n\n- Y = the actual value in the dataset.\n\n- Y cap=  the model\u2019s predicted value.\n\nThe squaring also has an inflating or magnifying effect on the error. That is, the larger the difference between the actual and predicted value, the larger will be the squared positive error. It penalizes the model more with a larger difference between actual and predicted values.","00d58cd7":"## Before we discuss metrics to evaluate a regression model, let\u2019s recall what a linear regression does:\nRegression predicts a continuous dependent element in the presence of various independent elements. Linear regression tries to make a trend line that has the least difference between actual and predicted values. This difference is also known as residual.\n\n![RESIDUAL = ACTUAL VALUE - PREDICTED VALUE](https:\/\/raw.githubusercontent.com\/everydaycodings\/files-for-multiplethings\/master\/Metrics%20to%20Evaluate%20a%20Regression%20Model%20-%20Google%20Chrome%2028_11_2021%2019_45_27%20(2).png)","09fdbc35":"### Importing Inmportant Modules","f7bdf5c2":"## Implementation of MEAN SQUARED ERROR(MSE)","01d7af64":"## ROOT MEAN SQUARED ERROR:\n![](https:\/\/images.ctfassets.net\/piwi0eufbb2g\/1Jv6fvhF9BLCFEjnPsnCG6\/33512a6c71c3268295b8bd787c3952cf\/image.png)<\/br>\n **It is the mean of root squared subtraction between the actual value in the dataset and the value predicted by the model.**\n\n **It\u2019s the same as MSE, we are just taking the root of it.**\n\n **The smaller the value of root mean squared error, the more accurate the model is.**","80cd1c32":"### Reading the data and first view of Data","692121ca":"## Advantage and Disadvantage of MEAN ABSOLUTE ERROR (MAE)\n\nMEAN ABSOLUTE ERROR (MAE) takes the absolute difference between actual and predicted value hence the error would always be positive. Also, as there is no squaring the units will be the same as the original units of the target value. MAE does not give more or less **weight** to different types of errors, it will penalize the larger and smaller errors equally. Hence, it is more **robust** to **outliers** and increases **linearly**. In any scenario, if you want to pay much attention to outliers then MAE might not be a suitable choice.","40480986":"> **Note: The array of actual values and the array of predicted values should both be of equal length in order for this function to work correctly.**","0e515415":"# Table Of Content:\n\n- Things To be known before using Regression Metrics\n* Types of Regression Metrics\n  \n  * Mean Absolute Error(MAE)\n    - Implementation of Mean Absolute Error(MAE)\n    - Advantage and Disadvantage of MEAN ABSOLUTE ERROR (MAE)\n\n  * Mean Square Error(MSE)\n    - Implementation of Mean Square Error(MSE)\n    - Advantage and Disadvantage of MEAN SQUARED ERROR(MSE)\n     \n  * Root Mean Square Error(RMSE)\n    - Implementation of Root Mean Square Error(RMSE)\n    - Advantage and Disadvantage of Root Mean Square Error(RMSE)\n\n- Conclusion\n- Date for Version 2 Release","8845ca66":"## Version 2 Will be Released soon in Next Weak with more information on Regression Matrices and more formulas to evaluate it like r2_score, adjacent r2_score, and many more so stay tuned for it.","3520d9ca":"\n## Author\n\n- [@everydaycodings(Kaggle)](https:\/\/www.kaggle.com\/everydaycodings)\n- [@everydaycodings(Github)](https:\/\/github.com\/everydaycodings)\n\n#### If You Lived this Kernal, If it was useful for You, Please Don't Forget To Give a UP Vote To It. So that can come to know this kind of Kernals are useful for the Kagglers so that I can make more informative Kernal like this.\n\n#### And In the Comments Please Let me Know in Which Topic do you want the next Kernal.And In the Comments Please Let me Know in Which Topic do you want the next Kernal.\n\n## Credits\nSome of the Information where taken from few sites like [TopCoder](https:\/\/www.topcoder.com\/) and [towardsdatascience](https:\/\/towardsdatascience.com\/). So I world like to Thank them for sharing a Informative Knowledge.\n\n","4eb04a80":"## Advantage and Disadvantage of Root Mean Square Error(RMSE)\nRMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 10 is more than twice as bad as being off by 5. But if being off by 10 is just twice as bad as being off by 5, then MAE is more appropriate.\nFrom an interpretation standpoint, MAE is clearly the winner. RMSE does not describe average error alone and has other implications that are more difficult to tease out and understand.\nOn the other hand, one distinct advantage of RMSE over MAE is that RMSE avoids the use of taking the absolute value, which is undesirable in many mathematical calculations"}}