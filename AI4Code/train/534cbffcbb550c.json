{"cell_type":{"fdb14395":"code","1c707d4f":"code","0fdb2941":"code","a513b16e":"code","ba1447ba":"code","0bb3b58c":"code","9e563baf":"code","15d2518f":"code","ee307c90":"code","e44d5ea6":"code","812becae":"code","99a9d5c4":"code","6ebf953c":"code","bc1e3056":"code","43b69476":"code","bea6d705":"code","3e4da408":"code","eb46666d":"code","43333562":"code","9619e923":"code","0594ace9":"code","5e8467b1":"code","7da60c7c":"code","9038a93b":"code","e7b32c24":"code","3a460cec":"code","6616820c":"code","cf6a1286":"code","09660ac8":"code","9726dd1b":"code","b5c72d7c":"code","964f82db":"code","e8afb1df":"code","e155aa7b":"code","834cb0d7":"code","ec01d7c8":"code","4a882ff0":"code","c8813a34":"code","369a268c":"code","0478acc5":"code","f0a6917f":"code","25d127dd":"code","ded6c1a1":"code","01d8362b":"code","46038864":"code","440446cd":"code","0c2a4342":"code","fc79d530":"code","b28a523b":"code","b441d9f5":"code","746c28d7":"code","c5894cdf":"code","4996408c":"code","78c04b48":"code","f893c91e":"code","e1196f36":"code","c82e168a":"code","ba3076fe":"code","ac1d3cd4":"code","65473824":"code","dd37b583":"code","1e03c230":"markdown","aad65fc0":"markdown","7d06f32a":"markdown","27a4685b":"markdown","14017985":"markdown","77249a6d":"markdown","6ad26b41":"markdown","a95e2a2e":"markdown"},"source":{"fdb14395":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns ","1c707d4f":"df = pd.read_csv('..\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv')","0fdb2941":"df.head()","a513b16e":"df.info() ","ba1447ba":"df.describe() # some statistical describes","0bb3b58c":"df.isnull().sum().sort_values(ascending=False) #there are no null data","9e563baf":"set(df['EDUCATION'])","15d2518f":"df['MARRIAGE'].value_counts() \n# Normally there is no 0 tag in the marriage column.For this we will change to 0 as 3.","ee307c90":"df['MARRIAGE'] = np.where(df['MARRIAGE']>0, df['MARRIAGE'], 3)","e44d5ea6":"df['MARRIAGE'].value_counts() #we changed ","812becae":"df['EDUCATION'].value_counts() #and there are no 0,5,6 .we will handle it","99a9d5c4":"df['EDUCATION'] = np.where(df['EDUCATION']<5, df['EDUCATION'], 4)","6ebf953c":"df['EDUCATION'] = np.where(df['EDUCATION']!=0, df['EDUCATION'], 4)","bc1e3056":"df['EDUCATION'].value_counts() ","43b69476":"set(df['PAY_0']) ","bea6d705":"set(df['PAY_6'])","3e4da408":"plt.figure(figsize=(16,8))\nsns.countplot(x='default.payment.next.month', data = df) ","eb46666d":"plt.figure(figsize=(16,8))\nsns.distplot(df['LIMIT_BAL'], kde=True, bins = 180)","43333562":"df['LIMIT_BAL'].value_counts().head(5)","9619e923":"plt.figure(figsize=(16,8))\nsns.boxplot(x= 'default.payment.next.month', y='LIMIT_BAL', hue='SEX',data=df) #plot of credict paymnet as sex","0594ace9":"plt.figure(figsize=(16,8))\nsns.boxplot(x= 'MARRIAGE', y='AGE',hue='SEX',showfliers=False ,data=df)","5e8467b1":"plt.figure(figsize=(16,8))\nsns.boxplot(x= 'EDUCATION', y='AGE',hue='MARRIAGE',showfliers=False ,data=df)","7da60c7c":"plt.figure(figsize=(16,8))\nsns.boxplot(x= 'EDUCATION', y='LIMIT_BAL',hue='MARRIAGE',showfliers=True ,data=df) \n","9038a93b":"df.head()","e7b32c24":"df['PAY_0']= np.where(df['PAY_0']<0, 0, df['PAY_0'])\ndf['PAY_2']= np.where(df['PAY_2']<0, 0, df['PAY_2'])\ndf['PAY_3']= np.where(df['PAY_3']<0, 0, df['PAY_3'])\ndf['PAY_4']= np.where(df['PAY_4']<0, 0, df['PAY_4'])\ndf['PAY_5']= np.where(df['PAY_5']<0, 0, df['PAY_5'])\ndf['PAY_6']= np.where(df['PAY_6']<0, 0, df['PAY_6'])","3a460cec":"# we will get the differences between Bill amount and pay amount \n\n\ndf['diff1']=df['BILL_AMT1']- df['PAY_AMT1']\ndf['diff2']=df['BILL_AMT2']- df['PAY_AMT2']\ndf['diff3']=df['BILL_AMT3']- df['PAY_AMT3']\ndf['diff4']=df['BILL_AMT4']- df['PAY_AMT4']\ndf['diff5']=df['BILL_AMT5']- df['PAY_AMT5']\ndf['diff6']=df['BILL_AMT6']- df['PAY_AMT6']","6616820c":"set(df['PAY_0'])","cf6a1286":"df['PAY_0'].value_counts().plot.barh() \n\n#those are nominal scales. that means there is no differences between each values\n#we will convert to ordinal scales of those nominal scales","09660ac8":"categ= [8,7,6,5,4,3,2,1,0]","9726dd1b":"from pandas.api.types import CategoricalDtype\ndf.PAY_0 = df.PAY_0.astype(CategoricalDtype(categories = categ, ordered=True))  \ndf.PAY_2 = df.PAY_2.astype(CategoricalDtype(categories = categ, ordered=True))  \ndf.PAY_3 = df.PAY_3.astype(CategoricalDtype(categories = categ, ordered=True))  \ndf.PAY_4 = df.PAY_4.astype(CategoricalDtype(categories = categ, ordered=True))  \ndf.PAY_5 = df.PAY_5.astype(CategoricalDtype(categories = categ, ordered=True))  \ndf.PAY_6 = df.PAY_6.astype(CategoricalDtype(categories = categ, ordered=True))  ","b5c72d7c":"df.PAY_0.head() ","964f82db":"df.info() #as we can see we converted the types ","e8afb1df":"df.columns","e155aa7b":"df.EDUCATION = df.EDUCATION.astype(CategoricalDtype())\ndf.SEX = df.SEX.astype(CategoricalDtype())\ndf.MARRIAGE = df.MARRIAGE.astype(CategoricalDtype())","834cb0d7":"df.columns","ec01d7c8":"df.info()","4a882ff0":"y = df['default.payment.next.month']\nX= df.drop(columns=['default.payment.next.month','ID','BILL_AMT1', 'BILL_AMT2','BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'])","c8813a34":"# we prepared the data for the model\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True)","369a268c":"from sklearn.ensemble import RandomForestClassifier\nrf= RandomForestClassifier(n_estimators=200)\nrf.fit(X_train,y_train)","0478acc5":"rf_pred = rf.predict(X_test)","f0a6917f":"from sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_test,rf_pred))\nprint(classification_report(y_test,rf_pred))  ","25d127dd":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(rf_pred,y_test))","ded6c1a1":"from sklearn.tree import DecisionTreeClassifier\ndt_model=DecisionTreeClassifier()\ndt_model.fit(X_train,y_train)\ndt_pred = dt_model.predict(X_test)","01d8362b":"print(confusion_matrix(y_test,dt_pred))\nprint(classification_report(y_test,dt_pred))","46038864":"print(accuracy_score(dt_pred,y_test))","440446cd":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\npredictions = logmodel.predict(X_test)","0c2a4342":"print(confusion_matrix(y_test,predictions))\nprint(classification_report(y_test,predictions)) #lojistik regresyon b\u00fct\u00fcn de\u011ferlere 0 etiketini verdi tahmin yanl\u0131\u015f ","fc79d530":"print(accuracy_score(predictions,y_test))","b28a523b":"categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0','PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']","b441d9f5":"df = pd.get_dummies(df,columns=categorical_features)","746c28d7":"y = df['default.payment.next.month']\nX= df.drop(columns=['default.payment.next.month','ID'])","c5894cdf":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.20)","4996408c":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","78c04b48":"import lightgbm as lgb\nd_train = lgb.Dataset(x_train, label=y_train)\nparams = {}\nparams['learning_rate'] = 0.2\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'binary'\nparams['metric'] = 'binary_logloss'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 10\nparams['min_data'] = 5000\nparams['max_depth'] = 10\nclf = lgb.train(params, d_train, 100)","f893c91e":"#Prediction\ny_pred=clf.predict(x_test)","e1196f36":"len(y_pred)","c82e168a":"#convert into binary values\nfor i in range(len(y_pred)):\n    if y_pred[i]>=.5:       # setting threshold to .5\n       y_pred[i]=1\n    else:  \n       y_pred[i]=0","ba3076fe":"y_pred","ac1d3cd4":"#Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n#Accuracy\nfrom sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_pred,y_test)","65473824":"cm","dd37b583":"accuracy","1e03c230":"If you like it, please vote! :)","aad65fc0":"# Data Exploratory","7d06f32a":"# Model Predict","27a4685b":"In this notebook. I will try to predict default payment based on historical payment and special ID data.\nAnd also I will do fearture engineering and make different models. Let's look into data ","14017985":"let's import some libraries","77249a6d":"## Data Visualization","6ad26b41":"* ID: ID of each client\n* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family\/supplementary credit\n* SEX: Gender (1=male, 2=female)\n* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n* AGE: Age in years\n* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n* PAY_2: Repayment status in August, 2005 (scale same as above)\n* PAY_3: Repayment status in July, 2005 (scale same as above)\n* PAY_4: Repayment status in June, 2005 (scale same as above)\n* PAY_5: Repayment status in May, 2005 (scale same as above)\n* PAY_6: Repayment status in April, 2005 (scale same as above)\n* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n* default.payment.next.month: Default payment (1=yes, 0=no)","a95e2a2e":"# Light BGM "}}