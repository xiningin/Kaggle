{"cell_type":{"c0072644":"code","bcb5d92a":"code","9032a0c3":"code","b1827bc5":"code","d5720a69":"code","5906fc7d":"code","6a7c405a":"code","b1c6e93f":"code","e8b7b132":"code","096916db":"code","f9357dc7":"code","4adce5b3":"code","d03d99e9":"code","c5c1c95a":"code","39adb45a":"code","a7fb3667":"code","4e8b3f10":"code","8037e7e9":"code","92ca33aa":"code","2d3fd012":"code","82b7039c":"code","a3fcb928":"code","48029a19":"code","9449d879":"code","afe16f3e":"code","943cdfe2":"code","2a87e62c":"code","87e8c547":"code","dd885eb5":"code","db7d0bb5":"code","c43dea17":"code","c198c7dc":"code","21985195":"code","7c4870e0":"code","fbcf755a":"code","9c1f1fe9":"code","e3bf0078":"code","64341a26":"code","55ff0d84":"code","5101e0b3":"code","d5841807":"code","4b86b939":"markdown","6817fd41":"markdown","1c497152":"markdown","3695e136":"markdown","5064a662":"markdown","5b63a721":"markdown","119e2913":"markdown","4c0b5f51":"markdown","e92d8bbf":"markdown","f0a66b3f":"markdown","15a49e64":"markdown","2b87e490":"markdown","9a2c9a4c":"markdown","657cfa6b":"markdown","1daa8b10":"markdown","03b10b44":"markdown","9679c267":"markdown","88101879":"markdown","fe7d07c7":"markdown","8f6a86e6":"markdown","3d55ca78":"markdown","273d6786":"markdown","3a8227a3":"markdown"},"source":{"c0072644":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bcb5d92a":"img_dir = '..\/input\/image-classification\/images\/images'\nval_dir = '..\/input\/image-classification\/validation\/validation'","9032a0c3":"os.listdir(img_dir)","b1827bc5":"# os.listdir(os.path.join(img_dir,'art and culture'))","d5720a69":"pip install --upgrade pip","5906fc7d":"pip-V","6a7c405a":"# pip install upgrade tensorflow","b1c6e93f":"! pip install tf-nightly","e8b7b132":"from keras.preprocessing.image import ImageDataGenerator\n\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img, img_to_array\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D,experimental, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\nfrom keras.models import Model, Sequential,load_model\nfrom keras.optimizers import Adam\n\n\n","096916db":"import tensorflow as tf\nfrom tensorflow import keras\ntf.__version__","f9357dc7":"# change as you want\nimage_size = (180, 180)\nbatch_size = 32","4adce5b3":"# model=load_model('..\/input\/googleiclogin\/')","d03d99e9":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=img_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1007,\n    image_size=image_size,\n    batch_size=batch_size,\n)","c5c1c95a":"train_ds.class_names","39adb45a":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=img_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1007,\n    image_size=image_size,\n    batch_size=batch_size,\n)","a7fb3667":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=val_dir,\n    validation_split=0.9999,\n    subset=\"validation\",\n    seed=1007,\n    image_size=image_size,\n    batch_size=batch_size,\n)","4e8b3f10":"plt.figure(figsize=(12,15))\ncpt=0\n\nfor imgs,lbs in train_ds.take(1):\n    for x in range(1,12):\n        cpt=cpt+1\n        plt.subplot(4,4,cpt)\n        plt.imshow(imgs[x].numpy().astype('uint8'))\n        plt.title(train_ds.class_names[int(lbs[x])])\n        plt.axis('off')\n        \n# cpt2=0\n# for expression in os.listdir(img_dir):\n#     for y in range(1,6):\n#         cpt2=cpt2+1\n#         plt.subplot(5,5,cpt2)\n#         img=load_img(img_dir+'\/'+expression+'\/'+\n#                     os.listdir(img_dir+'\/'+expression)[y],\n#                     target_size=image_size)\n#         plt.imshow(img)\n#         plt.title(train_ds.class_names[int(lbs[x])])\n#         plt.axis('off')\n\n        \nplt.tight_layout()\nplt.show()\n        ","8037e7e9":"\nnum_classes=len(train_ds.class_names)\n# print(num_classes)\n\n#init CNN\nmodel=Sequential()\n# Rescal\nmodel.add(experimental.preprocessing.Rescaling(1.\/255, input_shape=(180, 180, 3)))\n\n# 1 Conv\nmodel.add(Conv2D(16,(3,3),padding='same'))\n# model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n# 2 Conv\nmodel.add(Conv2D(32,(3,3),padding='same'))\n# model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n# 3 Conv\nmodel.add(Conv2D(64,(3,3),padding='same'))\n# model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n# # 4 Conv\n# model.add(Conv2D(128,(3,3),padding='same'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.25))\n\n\n# # 5 Conv\n# model.add(Conv2D(512,(3,3),padding='same'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.25))\n\n\n# Fully connected layer 1st layer\nmodel.add(Flatten())\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(128))\n# model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(num_classes,activation='softmax'))\n\noptimizer=Adam(lr=0.0001)\nmodel.compile(optimizer=optimizer,\n             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n             metrics=['accuracy'])\n","92ca33aa":"model.summary()","2d3fd012":"# # put your code here \n# mode2 = Sequential()\n# mode2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n# mode2.add(MaxPooling2D((2, 2)))\n# mode2.add(Conv2D(64, (3, 3), activation='relu'))\n# mode2.add(MaxPooling2D((2, 2)))\n# mode2.add(Conv2D(64, (3, 3), activation='relu'))\n# mode2.add(Flatten())\n# mode2.add(Dense(64, activation='relu'))\n# mode2.add(Dense(10))\n\n# mode2.summary()","82b7039c":"# mode2.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n#               metrics=['accuracy'])","a3fcb928":"epochs=50\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5)\nhistory=model.fit(train_ds,\n                 epochs=epochs,\n                 validation_data=(val_ds),\n                 callbacks=callback)","48029a19":"plt.figure(figsize=(16,16))\n#  \"Accuracy\"\nplt.subplot(2,2,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy',size=32,color='g')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower right')\n# \"Loss\"\nplt.subplot(2,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss',size=32,color='r')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","9449d879":"# Just Model\nmodel.save('myModel') # as HDF5 file .h5\n","afe16f3e":"model.save_weights('myModelWights.h5')","943cdfe2":"josnModel=model.to_json()","2a87e62c":"test_dir = '..\/input\/image-classification\/test\/test\/classify'\nos.listdir(test_dir)","87e8c547":"plt.figure(0,figsize=(12,20))\ncpt=0\n\nfor imge in os.listdir(test_dir):\n        cpt=cpt+1\n        plt.subplot(7,5,cpt)       \n        img=tf.keras.preprocessing.image.load_img(test_dir+'\/'+imge,\n                                                  target_size=image_size)\n        plt.imshow(img)\n        plt.title(imge) \n        plt.axis('off')\n\n    \nplt.tight_layout()\nplt.show()","dd885eb5":"# for imgName in os.listdir(test_dir):\n#     imgDir=os.path.join(test_dir+'\/'+imgName)\n#     os.rename(imgDir,os.path.join(test_dir+'\/'+str(imgName)))\n","db7d0bb5":"img=keras.preprocessing.image.load_img(\n    test_dir+'\/5.JPG', target_size=image_size\n)\nplt.imshow(img)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\nscores=predictions[0]\nprint(scores)","c43dea17":"# train_ds.class_names[3]","c198c7dc":"# i=0\n# for score in scores:\n#     print('This Image is %.2f '%(100*score)+' '+train_ds.class_names[i])\n#     i=i+1\n","21985195":"\nplt.figure(0,figsize=(12,20))\ncpt=0\n\nfor imge in os.listdir(test_dir):\n    cpt=cpt+1\n    plt.subplot(7,5,cpt)       \n    myImage=tf.keras.preprocessing.image.load_img(test_dir+'\/'+imge,\n                                                  target_size=image_size)\n    myImg_array = keras.preprocessing.image.img_to_array(myImage)\n    myImg_array = tf.expand_dims(myImg_array, 0) # Create a batch\n\n    predictions = model.predict(myImg_array)\n    topScore = (predictions[0].max())*100\n    image_name=train_ds.class_names[np.argmax(predictions[0])]    \n#         image_score=image_scores.max()*100\n    plt.imshow(myImage)\n#         plt.title('%.2f'%image_score+'% '+image_name)\n    plt.title(image_name,color='g')\n#     plt.xlabel('%.2f'%topScore+'%',color='w')\n    plt.imshow(myImage)\n    plt.axis('off')\n    print('This Image {} Like {:0.2f}% {}'.format(imge,100*np.max(predictions[0]),train_ds.class_names[np.argmax(predictions[0])]))\n\n    \nplt.tight_layout()\nplt.show()\n\n    ","7c4870e0":"# funcaiton To Load Images from URL\nimport urllib\nexternalImageNumber=0\n\n\ndef loadImage(URL):\n    with urllib.request.urlopen(URL) as url:\n        with open('testImage.jpg', 'wb') as f:\n            f.write(url.read())\n\n    img_path = 'testImage.jpg'\n    img = load_img(img_path, target_size=(180,180))\n    os.remove(img_path)\n#     x = img_to_array(img)\n    return img","fbcf755a":"plt.imshow(loadImage('https:\/\/pbs.twimg.com\/media\/Bss9czZCQAAjl-z.jpg'))","9c1f1fe9":"def predict_img_from_url(URL):\n    myImage=loadImage(URL)\n    img_array=img_to_array(myImage)\n    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n    image_predictions=model.predict(img_array)\n    image_scores = image_predictions[0]\n    image_name=train_ds.class_names[np.argmax(scores)]\n    image_score=image_scores.max()*100\n    plt.imshow(myImage)\n    plt.title('%.2f'%image_score+'% '+image_name,color='g',size=15)\n    plt.axis('off')\n    plt.show()\n    \n\n","e3bf0078":"externalImagesList=[\n    'https:\/\/3u8dbs16f2emlqxkbc8tbvgf-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/05\/impossiblewhopper_bk.jpg',\n    'https:\/\/i.pinimg.com\/originals\/7e\/45\/3e\/7e453e1c50ff032a2f608190e6d52898.jpg',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQBOANFxYfWXRyqztGycx5rN8D5XtE5KbTT1A&usqp=CAU',\n    'https:\/\/live.staticflickr.com\/2889\/10606493466_962af56bb2_b.jpg'\n\n]","64341a26":"for url in externalImagesList:\n    predict_img_from_url(url)\n\n    ","55ff0d84":"# predict_img_from_url('https:\/\/storage.googleapis.com\/gweb-uniblog-publish-prod\/original_images\/googleevent08.jpg')","5101e0b3":"# predict_img_from_url('https:\/\/pbs.twimg.com\/media\/Bss9czZCQAAjl-z.jpg')","d5841807":"# predict_img_from_url('https:\/\/i.pinimg.com\/originals\/7e\/45\/3e\/7e453e1c50ff032a2f608190e6d52898.jpg')","4b86b939":"## Train my CNN Model","6817fd41":"# test on 3 external images ","1c497152":"### save model's wights as HDF5 file .h5","3695e136":"### save model as HDF5 file .h5 ","5064a662":"# training data","5b63a721":"# image size and batch size \nchange the image size and the batch size as you want","119e2913":"# Data Directories ","4c0b5f51":"# Your model ","e92d8bbf":"# validation data ","f0a66b3f":"# test on some images from \n\n```..\/input\/image-classification\/test\/test\/classify```","15a49e64":"# import TF & check the version ","2b87e490":"## Prediction Function","9a2c9a4c":"# # plot error and accuracy (train and validation) ","657cfa6b":"#### check External Image from the List","1daa8b10":"# test data ","03b10b44":"# visualize (plot) some images from training data with their labels ","9679c267":"# Install TF nighlty ","88101879":"convert images name from float32 to str","fe7d07c7":"# My Imports","8f6a86e6":"### add list of External images by URLs","3d55ca78":"# Save model ","273d6786":"### save model as json File","3a8227a3":"#### load my Model"}}