{"cell_type":{"b24969f1":"code","598675fa":"code","dbaecdfd":"code","42e3bf0b":"code","4eed805b":"code","c27a1cd4":"code","09063164":"code","09e2f6ff":"code","37e2a28a":"code","d76d4434":"code","55c02a5d":"code","6a538edd":"code","756701cb":"code","95ffe3e6":"code","65387628":"code","f27daae1":"code","ae586383":"code","ec4d330b":"code","3d270aea":"code","880a3f97":"code","70f2c3ea":"code","20cb931f":"markdown","a501ed52":"markdown","41afa987":"markdown","a4c36b85":"markdown","18c5edd5":"markdown","d678dda5":"markdown","b11cd27a":"markdown","32ca7dc1":"markdown","d7a30262":"markdown","a054f6bf":"markdown","0ae451fb":"markdown","0e858bd2":"markdown","ce490970":"markdown","535570d9":"markdown","f3ace335":"markdown","65a0f984":"markdown","15a5c184":"markdown","3fcc0aad":"markdown","1b82f047":"markdown","d17d5be2":"markdown","c0de6a97":"markdown","9422277b":"markdown","af82193d":"markdown","4111b154":"markdown"},"source":{"b24969f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","598675fa":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.ensemble import RandomForestRegressor\n\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cat = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nsales = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')# parse_dates=['date']\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\n\n\n\n","dbaecdfd":"print(sales.info())\nprint('Number of missing values in dataset : ' + str(sales.isnull().sum().max()))","42e3bf0b":"print(sales.describe())","4eed805b":"neg_price = sales.item_price < 0\nprint(sales[neg_price])","c27a1cd4":"sales.drop(sales[neg_price].index, axis=0, inplace=True)","09063164":"sales['date'] = pd.to_datetime(sales['date'], format='%d.%m.%Y')\nsales['year'] = sales.date.dt.year\nsales['month'] = sales.date.dt.month\nprint(sales.head())","09e2f6ff":"print(f\"Time range is between {sales.date.min()}, {sales.date.max()}\")","37e2a28a":"## plot monthly total sales of company:\nsales_total_month = sales.loc[:, ['date_block_num', 'item_cnt_day']].groupby('date_block_num').sum()\nsales_total_month.rename(columns ={'item_cnt_day':'total_cnt_month'},inplace=True)\nsales_total_month.plot()\nplt.axvline(x=0, color='red', linestyle='--')\nplt.axvline(x=12, color='red', linestyle='--')\nplt.axvline(x=24, color='red', linestyle='--')\nplt.axvline(x=36, color='red', linestyle='--')\nlegend_x = 1\nlegend_y = 0.5\nplt.legend(loc='center left', bbox_to_anchor=(legend_x, legend_y))\nplt.ylabel('Total number of sold items per month')\nplt.xlabel('Month block number')\nplt.show()\n","d76d4434":"price_average_month = sales.loc[:, ['date_block_num', 'item_price']].groupby('date_block_num').mean()\nprice_average_month.rename(columns ={'item_price':'monthly_average_item_price'},inplace=True)\nprice_average_month.plot()\nplt.axvline(x=0, color='red', linestyle='--')\nplt.axvline(x=12, color='red', linestyle='--')\nplt.axvline(x=24, color='red', linestyle='--')\nplt.axvline(x=36, color='red', linestyle='--')\nlegend_x = 1\nlegend_y = 0.5\nplt.legend(loc='center left', bbox_to_anchor=(legend_x, legend_y))\nplt.ylabel('Monthly average price of items')\nplt.xlabel('Month block number')\nplt.show()","55c02a5d":"plt.figure(figsize=(20,14))\nsns.countplot(x='item_category_id', data=items) ## the same result but easier\nplt.show()","6a538edd":"## add item_category to sales data:\nitems = items.drop(columns='item_name')\nsales_cat = pd.merge(sales, items, on=['item_id'], how='left')\nprint(sales_cat.head())\n","756701cb":"## plot total items sold per category:\nsales_total_cat = sales_cat.loc[:, ['item_category_id', 'item_cnt_day']].groupby('item_category_id').sum()\nsales_total_cat.rename(columns={'item_cnt_day':'total_sold_items'}, inplace=True)\nprint(sales_total_cat.head())\nsales_total_cat.plot()\nplt.xlabel('Category ID')\nplt.ylabel('Total sold items')\nplt.show()","95ffe3e6":"sales_price_per_shop = sales.loc[:, ['shop_id', 'item_price']].groupby('shop_id').mean()\nsales_price_per_shop.rename(columns={'item_price':'average_item_price'}, inplace=True)\nsales_price_per_shop.plot(kind='bar', figsize=(20, 14))\nplt.xlabel('shop_id')\nplt.show()","65387628":"sales_sold_items_per_shop = sales.loc[:, ['shop_id', 'item_cnt_day']].groupby('shop_id').sum()\nsales_sold_items_per_shop.rename(columns={'item_cnt_day':'total_sold_items'}, inplace=True)\nsales_sold_items_per_shop.plot(kind='bar', figsize=(20, 14))\nplt.show()","f27daae1":"## add 'ID' to sales_cat data:\nsales_id = pd.merge(sales_cat, test, on=['item_id', 'shop_id'], how='left')\nsales_id_useful = sales_id.dropna()\nprint(sales_id_useful.columns)","ae586383":"### convert item_cnt_day to item_cnt_month\nsales_monthly = sales_id_useful.groupby(['ID','shop_id', 'item_id', 'item_category_id', 'date_block_num', 'year', 'month'])['item_cnt_day'].sum().rename('item_cnt_month').reset_index()\nsales_monthly_sort_id = sales_monthly.sort_values(['ID'], ascending=True).reset_index().drop(columns='index')\nsales_monthly_sort_id['ID'] = sales_monthly_sort_id['ID'].astype(int)\nsales_monthly_sort_id['month'] = sales_monthly_sort_id['month'].astype('object')\nsales_monthly_sort_id['year'] = sales_monthly_sort_id['year'].astype('object')\nprint(sales_monthly_sort_id.head(10))\nprint(sales_monthly_sort_id.shape)","ec4d330b":"sns.distplot(test.shop_id, bins=60, kde=False)\nplt.show()\nprint(test.shop_id.nunique())\nprint(test.shop_id.unique())","3d270aea":"## ## add 'item_category_id' to test data:\ntest_new = pd.merge(test, items, on=['item_id'], how='left')\ntest_new['date_block_num'] = 34\ntest_new['year'] = '2015'\ntest_new['month'] = '11'\nprint(test_new.head())\nX_test = test_new.drop(columns='ID').values\nX = sales_monthly_sort_id.drop(columns=['ID', 'item_cnt_month']).values\ny = sales_monthly_sort_id[['item_cnt_month']]\n","880a3f97":"### build a model\n############################################ Building Random Forest model  #############################################\nrf = RandomForestRegressor(n_estimators=1000, max_depth=10, min_samples_leaf=10, criterion='mse', random_state=42, n_jobs=1)\nmodel=rf.fit(X, np.ravel(y))\n\ny_pred_rf = model.predict(X_test)\nprint(type(y_pred_rf))\ntest_new['item_cnt_month'] = y_pred_rf\ntest_new.loc[:, ['ID', 'item_cnt_month']].to_csv('Submission_RF.csv', index=False)\nprint(test_new.head())\n","70f2c3ea":"from xgboost import XGBRegressor\nxgb = XGBRegressor(max_depth=15, random_state=42, n_estimators=50, learning_rate=0.0001, booster='gbtree', objective='reg:squarederror', min_child_weight=100, silent=1, n_jobs=10)\n\nxgb.fit(X, y.values.ravel())\ny_pred = xgb.predict(X_test)\n\ntest_new['item_cnt_month'] = y_pred\nprint(y_pred)\ntest_new.loc[:, ['ID', 'item_cnt_month']].to_csv('Submission_XGBoost.csv', index=False)\nprint(test_new.head())\nfeatures = ['shop_id', 'item_id', 'item_category_id', 'date_block_num', 'year', 'month']\nfeat_imp = pd.Series(xgb.feature_importances_, index=features).sort_values(ascending=True)\nfeat_imp.plot(kind='barh', title='Feature Importances XGBoost')\nplt.ylabel('Feature Importance Score')\nplt.show()","20cb931f":"It seems that item category is important feature! let's add it to sales data:","a501ed52":"Now I convert date column to a datetime object. Then, I can easily extract year, month and week day as a separate column. Here, since the goal is predicting monthly sales, I only use month and year information.","41afa987":"The distribution of items per class in test dataset is uniform; we need to predict sales for items in only 42 shops.","a4c36b85":"I prefer to remove this observation:","18c5edd5":"Now we add 'item_category_id', 'year' and 'month' as features to test dataset:","d678dda5":"## Plot monthly total sales of company:","b11cd27a":"Negative item price does not make sense, let's look at those items:","32ca7dc1":"Looking at the test data:","d7a30262":"## Plotting average item price per shop","a054f6bf":"As next steps in future I want to add more features like monthly price, montly lagged sales of items etc. ","0ae451fb":"In the figure above red lines specify one-year period. The decreasing trend and yearly pattern can be seen very well. So, adding year and month as  separate columns was a good decision.","0e858bd2":"Now we want to know the total daily sold items per category:","ce490970":"Looking the above plot category_id seems to be an important feature.","535570d9":"## Plotting average item_price by month","f3ace335":"Now let's add 'ID' column to sales data: ","65a0f984":"Let's see the time interval in which data is available:","15a5c184":"There is a clear increasing trend and a yearly pattern in the price of items.","3fcc0aad":"Looking into we can see that there is no missing values . ","1b82f047":"Getting more info about the data:","d17d5be2":"## Plotting total sold items per day per shop","c0de6a97":"Since we want to predict the monthly amount of sold items, let's convert daily number of sold items to monthly number:","9422277b":"## Plot distribution of items per category","af82193d":"* My public score is 1.23 by XGBoost.","4111b154":"Now we specified shop_id, item_id, item_category_id and date_block_num as features and everything is ready to train a model. I try both random forest and XGBoost."}}