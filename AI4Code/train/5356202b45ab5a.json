{"cell_type":{"9d629f7c":"code","d8a09ad6":"code","bd97d286":"code","a0ecdf03":"code","1f70ad89":"code","efb85957":"code","85482eab":"code","08df8af1":"code","2288b475":"code","3ec2eec6":"code","cc4429fe":"code","c3cfe958":"code","357a36ac":"code","d89f4ea9":"code","378e0d94":"code","81fd623c":"code","7b4ead6c":"code","41bb716f":"code","93cafa6f":"code","c0c03e1d":"code","9f01eaeb":"code","81a0feca":"code","e6c00ec2":"code","c92b1dfb":"code","76f83438":"code","47882890":"code","6fa6edb1":"code","4eed57d4":"code","f93b226f":"code","6d167dcb":"code","de87379c":"code","ddd6c6e6":"code","370938cb":"code","d90cc609":"code","ce5871fa":"code","ff9910e7":"code","0499b6c3":"code","eb472250":"code","a748583a":"code","020fb0c0":"code","d846b238":"code","26c9d0b4":"code","a119f3c4":"code","6691c1df":"code","c5d4c190":"code","247452be":"code","bc767b6b":"code","344ce34a":"code","3bf66af5":"code","b3b6c002":"code","4e8848c7":"code","a26b976a":"markdown","b2112d28":"markdown","eefe297d":"markdown","9f9b5c99":"markdown","3e328392":"markdown","183639d0":"markdown","bb08d2de":"markdown","7acf21a9":"markdown","b4fb50d9":"markdown","0dfc97b0":"markdown","3b1250ab":"markdown","a80f4b8f":"markdown","22aba0bc":"markdown","ae625286":"markdown","9ce15241":"markdown","85fdaeb2":"markdown","83170ab3":"markdown","ddd5b5bc":"markdown","4d879666":"markdown","18f6f712":"markdown","cc5caaf1":"markdown","91ef71db":"markdown","af2ec4e6":"markdown","99ca8d70":"markdown","67579ba6":"markdown","820c62cd":"markdown","32a7e7a2":"markdown","fe51b566":"markdown","2961e0fa":"markdown","6e37e733":"markdown","285e7e88":"markdown","a47b2903":"markdown","666f7037":"markdown","bfd0c971":"markdown","7ad404c4":"markdown","8c2fd87b":"markdown","3751d472":"markdown","efcf767a":"markdown","a34df00f":"markdown","35073bf2":"markdown","19265df1":"markdown","c63ace2e":"markdown","e3ebc69f":"markdown","2be4edd0":"markdown","450c12ac":"markdown","b6416efb":"markdown","18aded9b":"markdown","2cd46857":"markdown","fb2ae9fb":"markdown","3a80f11a":"markdown","c70caea3":"markdown","c0a7a697":"markdown","684e68f1":"markdown","e258d4d5":"markdown","34ff942f":"markdown","094d01aa":"markdown","4d99700b":"markdown"},"source":{"9d629f7c":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","d8a09ad6":"df = pd.read_csv('..\/input\/data-concrete-strength\/Concrete_Data_Yeh.csv')\ndf.head(3)","bd97d286":"df.info()","a0ecdf03":"df.describe()","1f70ad89":"df.hist(bins=50, figsize=(20, 15))\nplt.show()","efb85957":"train_df, test_df = train_test_split(df, test_size=0.2, random_state=0)","85482eab":"df.describe()","08df8af1":"test_df.describe()","2288b475":"fig, ax = plt.subplots(1, 2, figsize=(10, 5))\ndf.csMPa.hist(bins=50, ax=ax[0], );test_df.csMPa.hist(bins=50, ax=ax[1])\nax[0].title.set_text('Complete data csMPa');ax[1].title.set_text('Test data csMPa')","3ec2eec6":"temp_com_df = pd.DataFrame()\ntemp_com_df['Complete_csMPa_cat5'] = pd.cut(df.csMPa, bins=[0, 20, 40, 60, 80, 100],\n                                            labels=['A', 'B', 'C', 'D', 'E'])\ntemp_com_df['Complete_csMPa_cat4'] = pd.cut(df.csMPa, bins=[0, 20, 40, 60, 100], labels=['A', 'B', 'C', 'D'])\n\ntemp_test_df = pd.DataFrame()\ntemp_test_df['Test_csMPa_cat5'] = pd.cut(test_df.csMPa, bins=[0, 20, 40, 60, 80, 100],\n                                            labels=['A', 'B', 'C', 'D', 'E'])\ntemp_test_df['Test_csMPa_cat4'] = pd.cut(test_df.csMPa, bins=[0, 20, 40, 60, 100], labels=['A', 'B', 'C', 'D'])","cc4429fe":"fig, ax = plt.subplots(1, 1, figsize=(10, 5))\ntemp_com_df.Complete_csMPa_cat4.hist(ax=ax)\ntemp_test_df.Test_csMPa_cat4.hist(ax=ax)\nax.title.set_text('Complete & Test csMPa with 4 categories')","c3cfe958":"print(temp_com_df.Complete_csMPa_cat4.value_counts()\/len(temp_com_df))\nprint(temp_test_df.Test_csMPa_cat4.value_counts()\/len(temp_test_df))","357a36ac":"train_df.head(2)","d89f4ea9":"train_df.info()","378e0d94":"train_df.describe()","81fd623c":"train_df.hist(bins=50, figsize=(20, 15))\nplt.show()","7b4ead6c":"plt.figure(figsize=(10,10))\nax = sns.heatmap(train_df.corr(),  vmin=-1, vmax=1, center=0,square=True, annot=True, cmap=\"YlGnBu\")\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=30,\n    fontsize=10,\n    horizontalalignment='right'\n)\nax.set_yticklabels(\n    ax.get_yticklabels(),\n    rotation=30,\n    fontsize=10,\n    horizontalalignment='right'\n)\nax.set_ylim(9, 0);","41bb716f":"fig, ax = plt.subplots(2, 2, figsize=(10, 10))\ntrain_df.plot(kind='scatter', x='cement', y='csMPa', ax=ax[0, 0])\ntrain_df.plot(kind='scatter', x='water', y='csMPa', ax=ax[0, 1])\ntrain_df.plot(kind='scatter', x='superplasticizer', y='csMPa', ax=ax[1, 0])\ntrain_df.plot(kind='scatter', x='age', y='csMPa', ax=ax[1, 1])","93cafa6f":"fig, ax = plt.subplots(2, 2, figsize=(10, 10))\ntrain_df.plot(kind='scatter', x='cement', y='csMPa', ax=ax[0, 0], alpha=0.1)\ntrain_df.plot(kind='scatter', x='water', y='csMPa', ax=ax[0, 1], alpha=0.1)\ntrain_df.plot(kind='scatter', x='superplasticizer', y='csMPa', ax=ax[1, 0], alpha=0.1)\ntrain_df.plot(kind='scatter', x='age', y='csMPa', ax=ax[1, 1], alpha=0.1)","c0c03e1d":"train_dff = train_df.copy()","9f01eaeb":"train_dff.loc[train_dff.flyash == 0, 'flyash_cat'] = '0'\ntrain_dff.loc[(train_dff.flyash  > 0) & (train_dff.flyash  <= 75), 'flyash_cat'] = '0-75'\ntrain_dff.loc[(train_dff.flyash  > 75) & (train_dff.flyash  <= 100), 'flyash_cat'] = '76-100'\ntrain_dff.loc[(train_dff.flyash  > 100) & (train_dff.flyash  <= 125), 'flyash_cat'] = '101-125'\ntrain_dff.loc[(train_dff.flyash  > 125) & (train_dff.flyash  <= 150), 'flyash_cat'] = '126-150'\ntrain_dff.loc[(train_dff.flyash  > 150) & (train_dff.flyash  <= 175), 'flyash_cat'] = '151-175'\ntrain_dff.loc[(train_dff.flyash  > 175), 'flyash_cat'] = '>175'","81a0feca":"train_dff.loc[train_dff.slag == 0, 'slag_cat'] = '0'\ntrain_dff.loc[(train_dff.slag  > 0) & (train_dff.slag  <= 50), 'slag_cat'] = '0-50'\ntrain_dff.loc[(train_dff.slag  > 50) & (train_dff.slag  <= 100), 'slag_cat'] = '51-100'\ntrain_dff.loc[(train_dff.slag  > 100) & (train_dff.slag  <= 150), 'slag_cat'] = '101-150'\ntrain_dff.loc[(train_dff.slag  > 150) & (train_dff.slag  <= 200), 'slag_cat'] = '151-200'\ntrain_dff.loc[(train_dff.slag  > 200) & (train_dff.slag  <= 250), 'slag_cat'] = '201-250'\ntrain_dff.loc[(train_dff.slag  > 250) & (train_dff.slag  <= 300), 'slag_cat'] = '251-300'\ntrain_dff.loc[(train_dff.slag  > 300) & (train_dff.slag  <= 350), 'slag_cat'] = '301-350'\ntrain_dff.loc[(train_dff.slag  > 350), 'slag_cat'] = '>350'","e6c00ec2":"train_dff.loc[train_dff.superplasticizer == 0, 'superplasticizer_cat'] = '0'\ntrain_dff.loc[(train_dff.superplasticizer  > 0) & (train_dff.superplasticizer  <= 5), \n             'superplasticizer_cat'] = '0-5'\ntrain_dff.loc[(train_dff.superplasticizer  > 5) & (train_dff.superplasticizer  <= 10), \n             'superplasticizer_cat'] = '6-10'\ntrain_dff.loc[(train_dff.superplasticizer  > 10) & (train_dff.superplasticizer  <= 15), \n             'superplasticizer_cat'] = '11-15'\ntrain_dff.loc[(train_dff.superplasticizer  > 15) & (train_dff.superplasticizer  <= 20), \n             'superplasticizer_cat'] = '16-20'\ntrain_dff.loc[train_dff.superplasticizer  > 20, 'superplasticizer_cat'] = '>20'","c92b1dfb":"sns.catplot('age', 'csMPa', data=train_dff, kind='point')","76f83438":"ax = sns.catplot('flyash_cat', 'csMPa', data=train_dff, kind='point')\nax.set_xticklabels(\n    rotation=30,\n    fontsize=10,\n    horizontalalignment='right'\n)","47882890":"ax = sns.catplot('slag_cat', 'csMPa', data=train_dff, kind='point')\nax.set_xticklabels(\n    rotation=30,\n    fontsize=10,\n    horizontalalignment='right'\n)","6fa6edb1":"sns.catplot('superplasticizer_cat', 'csMPa', data=train_dff, kind='point')","4eed57d4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nimport warnings\nwarnings.filterwarnings('ignore')","f93b226f":"train_df.head(3)","6d167dcb":"train_df.info()","de87379c":"train_df.describe()","ddd6c6e6":"def data_preprocessing(df, label=None):\n    return((df.drop([label], axis=1), df[label]) if label else df.drop([label], axis=1))","370938cb":"def get_rmse(scores):\n    return np.sqrt(-scores)","d90cc609":"x_train, y_train = data_preprocessing(train_df, 'csMPa')\nlr = LinearRegression(n_jobs=-1)\nrmse = get_rmse(cross_val_score(lr, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(lr, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())","ce5871fa":"x_train, y_train = data_preprocessing(train_df, 'csMPa')\ndt = DecisionTreeRegressor(random_state=0)\nrmse = get_rmse(cross_val_score(dt, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(dt, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())","ff9910e7":"x_train, y_train = data_preprocessing(train_df, 'csMPa')\nrf = RandomForestRegressor(random_state=0)\nrmse = get_rmse(cross_val_score(rf, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(rf, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())\nrf.fit(x_train, y_train);","0499b6c3":"grf = RandomForestRegressor(random_state=0)\ngrid_values = [{'n_estimators': [5, 10, 30, 50, 100, 150, 200, 300, 400, 500], \n               'max_features': ['sqrt', 'auto', 2, 3, 5, 8],\n              'bootstrap': [False, True]}\n              ]\ngs = GridSearchCV(grf, param_grid = grid_values, cv = 5, n_jobs=-1, scoring='neg_mean_squared_error')\ngs.fit(x_train, y_train)\nprint(gs.best_params_)","eb472250":"x_train, y_train = data_preprocessing(train_df, 'csMPa')\nrfv1 = RandomForestRegressor(bootstrap=False, n_estimators=200, max_features=3, random_state=0)\nrmse = get_rmse(cross_val_score(rfv1, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(rfv1, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())\nrfv1.fit(x_train, y_train);","a748583a":"test_df.head(2)","020fb0c0":"x_test, y_test = data_preprocessing(test_df, 'csMPa')","d846b238":"y_pred = rf.predict(x_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\nprint(rmse, r2)","26c9d0b4":"y_pred = rfv1.predict(x_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\nprint(rmse, r2)","a119f3c4":"whole_df = pd.read_csv('..\/input\/data-concrete-strength\/Concrete_Data_Yeh.csv')","6691c1df":"x_train, y_train = data_preprocessing(whole_df, 'csMPa')\nrf_full = RandomForestRegressor(bootstrap=False, n_estimators=200, max_features=3, random_state=0)\nrmse = get_rmse(cross_val_score(rf_full, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(rf_full, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())","c5d4c190":"shuffled_whole_df = whole_df.sample(frac=1)\nx_train, y_train = data_preprocessing(shuffled_whole_df, 'csMPa')\nshuffle_rf_full = RandomForestRegressor(bootstrap=False, n_estimators=200, max_features=3, random_state=0)\nrmse = get_rmse(cross_val_score(shuffle_rf_full, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(shuffle_rf_full, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())\nshuffle_rf_full.fit(x_train, y_train);","247452be":"x_train, y_train = data_preprocessing(train_df, 'csMPa')\nx_test, y_test = data_preprocessing(test_df, 'csMPa')\nwhole_x_train, whole_y_train = data_preprocessing(shuffled_whole_df, 'csMPa')\nplot_dict ={'Epoch': [], 'RMSE': [], 'R2': [], 'Data': []}\nfor i in [150, 200, 250, 300, 400, 500, 800, 1000]:\n    \n    plot_dict['Epoch'].append(i)\n    \n    rfv1 = RandomForestRegressor(bootstrap=False, n_estimators=i, max_features=3, random_state=0)\n    rmse = get_rmse(cross_val_score(rfv1, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n    r2 = cross_val_score(rfv1, x_train, y_train, cv=5, scoring='r2')\n    \n    plot_dict['Data'].append('Train');plot_dict['RMSE'].append(rmse.mean());plot_dict['R2'].append(r2.mean())\n    \n    rfv1.fit(x_train, y_train);\n    y_pred = rfv1.predict(x_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    \n    plot_dict['Epoch'].append(i)\n    plot_dict['Data'].append('Test');plot_dict['RMSE'].append(rmse.mean());plot_dict['R2'].append(r2.mean())\n    \n    rmse = get_rmse(cross_val_score(rfv1,  whole_x_train, whole_y_train, cv=5, scoring='neg_mean_squared_error'))\n    \n    r2 = cross_val_score(rfv1,  whole_x_train, whole_y_train, cv=5, scoring='r2')\n    \n    plot_dict['Epoch'].append(i)\n    plot_dict['Data'].append('Whole');plot_dict['RMSE'].append(rmse.mean());plot_dict['R2'].append(r2.mean())\n\nplot_df = pd.DataFrame.from_dict(plot_dict)\nplot_df.head(2)","bc767b6b":"fig, ax = plt.subplots(1, 2, figsize=(12, 5))\nsns.lineplot(x='Epoch',y='RMSE', hue='Data', data=plot_df,ax=ax[0])\nsns.lineplot(x='Epoch',y='R2', hue='Data', data=plot_df,ax=ax[1])","344ce34a":"perm = PermutationImportance(rfv1, random_state=0).fit(x_test, y_test)\neli5.show_weights(perm, feature_names = x_test.columns.tolist())","3bf66af5":"perm = PermutationImportance(shuffle_rf_full, random_state=0).fit(x_test, y_test)\neli5.show_weights(perm, feature_names = x_test.columns.tolist())","b3b6c002":"x_train, y_train = data_preprocessing(shuffled_whole_df[['age', 'cement', 'water', 'superplasticizer', 'csMPa']], \n                                      'csMPa')\nfeat4_rf_full = RandomForestRegressor(bootstrap=False, n_estimators=200, max_features=3, random_state=0)\nrmse = get_rmse(cross_val_score(feat4_rf_full, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(feat4_rf_full, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())","4e8848c7":"x_train, y_train = data_preprocessing(shuffled_whole_df[['age', 'cement', 'water', 'superplasticizer', \n                                                         'slag', 'csMPa']], 'csMPa')\nfeat5_rf_full = RandomForestRegressor(bootstrap=False, n_estimators=200, max_features=3, random_state=0)\nrmse = get_rmse(cross_val_score(feat5_rf_full, x_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nr2 = cross_val_score(feat5_rf_full, x_train, y_train, cv=5, scoring='r2')\nprint(rmse.mean(), r2.mean())","a26b976a":"## EDA on Train data","b2112d28":"### Create Categorical features for plotting","eefe297d":"### Finalize the model","9f9b5c99":"#### Stats of data","3e328392":"#### Basic info about train data","183639d0":"##### To see the distribution of the the data.","bb08d2de":"#### Normal Density","7acf21a9":"#### Using Model v1.0 (Random Forest)","b4fb50d9":"### Training model with only few important features","0dfc97b0":"### Scatter plots\n\nFor High correlated features","3b1250ab":"#### Using Model v1.0 (Random Forest)","a80f4b8f":"Since the data was very clean we didn't require to write complex data preprocessing pipeline.","22aba0bc":"Since RandomForestRegressor is giving good accuracy, let's hyper tune this.","ae625286":"#### High vs Low density","9ce15241":"#### Compare the ranges of target variable in Complete and Test data","85fdaeb2":"### Rough Model (Linear Regression)","83170ab3":"### Scoring","ddd5b5bc":"There is some weird scenario while training model on full data, but shuffling the data gives us better accuracy.","4d879666":"Test data has almost equal distribution of target variable (csMPa) as in Complete data i.e Test data is very similar to Complete data.","18f6f712":"### Plotting RMSE and R2 for Train, Test and Whole data","cc5caaf1":"### EDA Summary (train data)","91ef71db":"## A Glance at Data","af2ec4e6":"### Feature Importance","99ca8d70":"## Create Test data\n\n**Note** : Try to make test data as similar as complete data. The test data should represent the whole population.","67579ba6":"Both are looking kinda similar which is good.","820c62cd":"#### Plot age, Flyash categorical, Slag categorical and Superplasticizer categorical vs csMPa","32a7e7a2":"#### With top 4 features (on whole data)","fe51b566":"#### With shuffling the whole data (Model Shuffle Full)","2961e0fa":"### Model v1.0","6e37e733":"### Rough Model (Random Forest)","285e7e88":"### Data Preprocessing pipeline","a47b2903":"### Correlation between features","666f7037":"#### Basic info about the data","bfd0c971":"### Evaluation on Test data","7ad404c4":"#### Without shuffling the whole data (Model Full)","8c2fd87b":"#### Flyash categorical","3751d472":"#### Grid Search for Random Forest","efcf767a":"#### Slag categorical","a34df00f":"### Histogram distribution for all features","35073bf2":"### Rough Model (Decision Tree)","19265df1":"Finalize the model as per your need.\n**feat5_rf_full** is a good model if we want to reduce the cost of collecting the data (i.e with less features) and if we are ready to compromise our accuracy by little.\n \nOtherwise **shuffle_rf_full** is better model.","c63ace2e":"### Read Data","e3ebc69f":"### Read Train Data","2be4edd0":"#### Using Model Shuffle_Full (Random Forest)","450c12ac":"Epoch 200 looks reasonable choice.","b6416efb":"### Compare test data to the complete data","18aded9b":"#### Superplasticizer categorical","2cd46857":"## Model Training","fb2ae9fb":"#### Distribution of target variable","3a80f11a":"#### Basic Info","c70caea3":"#### With top 5 features(on whole data)","c0a7a697":"### Model on full data","684e68f1":"Major things we learned:\n- Create a good test data which presents whole population.\n- Create a good data preprocessing pipeline.\n- Gain some insights doing EDA on train data.\n- Start with simple model and keep training with more complex model as per accuracy.\n- Hyper tune the model with better result to improve it further.\n- Evaluate on test data.\n- Feature importance.\n- Finalize the model.","e258d4d5":"- Most of the data points have age less than 29 years.\n- Flyash, Slag and Superplasticizer mostly have data points with value zero.\n- Cement, Water, Superplasticizer and Age are highly correlated.\n- csMPa power is almost linearly incresing with age upto 91 (except at 90) and also has max value at 91. After 91 the csMPa power is decresing.\n- csMPa power is decreasing for flyash value greater than 175.\n- csMPa power is almost linearly increasing with superplasticizer.","34ff942f":"#### Using Rough model (Random Forest)","094d01aa":"Create a data preprocessing pipeline such that it can work on even a single sample.","4d99700b":"### Conclusion"}}