{"cell_type":{"f89b11d3":"code","ac89a36f":"code","13e517db":"code","42d1a1de":"code","1b4afc4d":"code","b0895f67":"code","8a316a58":"code","eabb7198":"code","3fa2fa8f":"code","7239ecff":"code","fcadd399":"code","8f140663":"code","ba5d95bb":"code","d7c67802":"code","dc435417":"code","6cf6b127":"code","6d093f14":"code","abb65d72":"code","11df4b41":"code","835eabb1":"code","32053439":"code","c344c95a":"code","c11d2836":"code","4ac583c5":"code","d0d5f68f":"code","4317429a":"code","8adf5a3d":"code","af71deff":"markdown","8b84a8fa":"markdown","b671b91a":"markdown","518318c4":"markdown","4a5cf49b":"markdown","cf3fcf44":"markdown","0674c5c5":"markdown","eaf85863":"markdown","b4932303":"markdown","ba333683":"markdown","2ff52188":"markdown"},"source":{"f89b11d3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","ac89a36f":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","13e517db":"data.head()","42d1a1de":"lst = []\nfor i in data.columns:\n    if data[i].isnull().sum() >0:\n        lst.append(i)","1b4afc4d":"lst","b0895f67":"data = data[lst]","8a316a58":"data","eabb7198":"data.isnull().sum()","3fa2fa8f":"df = data.copy()\n#comparing their means\ndf.isnull().mean()","7239ecff":"for i in df.columns:\n    print(i, \":\", df[i].size, \":\", df[i].isnull().sum())","fcadd399":"lst = []\nfor i in df.columns:\n    if df[i].isnull().sum() < 100:\n        lst.append(i)\n        df[i + \"_mean\"] = df[i].fillna(df[i].value_counts().sort_values(ascending = False).index[0])","8f140663":"df.isnull().sum()","ba5d95bb":"def plots(df,var):\n    plt.figure(figsize =(10,5))\n    val = np.random.randint(100000,999999)\n    col = \"#\" + str(val)\n    sns.countplot(df[var], color = col, label = var)\n    plt.legend()\n    plt.show()","d7c67802":"for i in df.columns:\n    if df[i].isnull().sum()<100:\n        plots(df,i)","dc435417":"for i in df.columns:\n    if df[i].isnull().sum()<100 and df[i].isnull().sum()>=1:\n        df = df.drop(columns = i, axis = 1)","6cf6b127":"df.isnull().sum()","6d093f14":"for i in df.columns:\n    if df[i].isnull().sum()<1000 and df[i].isnull().sum() >= 1:\n        df[i + \"_exposure\"] = np.where(df[i].isnull(), 1, 0)","abb65d72":"df.isnull().sum()","11df4b41":"df[['LotFrontage_exposure', 'LotFrontage']][0:20]","835eabb1":"#now replace that nan with something else\n#Machine has learn that something happend in that place","32053439":"for i in df.columns:\n    if df[i].isnull().sum() >1000:\n        df[i] =  df[i].fillna(\"missing\")\ndf","c344c95a":"df.isnull().sum()","c11d2836":"from random import sample\ndef randomchange(df,var):\n    df[var + '_random'] = df[var]\n    global random_sample\n    \n    random_sample = df[var].dropna().sample(df[var].isnull().sum())\n    \n    random_sample.index = df[df[var].isnull()].index\n    \n    df.loc[df[var].isnull(), var + '_random'] = random_sample","4ac583c5":"randomchange(df, \"FireplaceQu\")\nrandomchange(df, \"LotFrontage\")","d0d5f68f":"df['FireplaceQu_random'].isnull().sum()","4317429a":"def plots(df, var):\n    plt.figure(figsize =(10,5))\n    val = np.random.randint(100000,999999)\n    col = \"#\" + str(val)\n    sns.countplot(df[var], color = col, label = var)\n    plt.legend()\n    plt.show()","8adf5a3d":"for i in ['FireplaceQu_random', \"FireplaceQu\", \"LotFrontage\", \"LotFrontage_random\"]:\n    plots(df, i)","af71deff":"#Shall drop that non filled columns","8b84a8fa":"Having Huge of null values","b671b91a":"# Analyze the data first","518318c4":"# Replacing the cata values with the randomly selected variable","4a5cf49b":"# Create the exposure for the nan variable","cf3fcf44":"# Replacing the nan values with another category","0674c5c5":"# Frequent Imputation","eaf85863":"1) Frequenct Category imputation.\n\n2) Create the exposure for the nan variable.\n\n3) Replacing the Nan values with another category.\n\n4) Random Category Imputation","b4932303":"Note that : If you have more null values in cata\n    i) Trying to replace with something else, if the column is important.\n    ii) Otherwise, It affect the model. trying to drop that column incase of not important.","ba333683":"# Handling data of missing categorical variables","2ff52188":"***Handling Categorical data's (Feature Engineering)***\n\nhttps:\/\/www.kaggle.com\/ganeshbalaji1608\/handling-categorical-data-s-feature-engineering\n\n***Handling Missing Numerical Features(Feature Engineering)***\n\nhttps:\/\/www.kaggle.comhandling-missing-numerical-features-f-e\n\n***Handling Imbalanced Datasets***\n\nhttps:\/\/www.kaggle.comhandling-imbalanced-datasets\n\n***Handling Outliers***\n\nhttps:\/\/www.kaggle.comhandling-outliers-feature-engieering\n\n***Transformations (Feature Scaling)***\n\nhttps:\/\/www.kaggle.comtransformation-techniques-feature-scaling\n"}}