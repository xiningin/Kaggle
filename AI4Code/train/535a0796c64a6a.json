{"cell_type":{"3ff9f5aa":"code","64c7268f":"code","2b96676b":"code","0d26369b":"code","4e88abfc":"code","b52a6c13":"code","7d803c7e":"code","3b5aeea6":"code","a726aab3":"code","b7d70784":"code","2543e681":"code","ab477ef3":"code","708a8a1f":"code","97eac82a":"markdown","5bde0e87":"markdown","b788f875":"markdown","58377d06":"markdown","ce6258f7":"markdown","0fb169cd":"markdown","883c3f11":"markdown"},"source":{"3ff9f5aa":"# import statements\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom keras.preprocessing.image import load_img","64c7268f":"def get_labels(folder):\n    \"\"\"\n    Extracts the labels of the images\n    \"\"\"\n    \n    # initialize empty list of labels\n    labels = []\n    \n    for file in folder:\n        label = file.split('.')[0]\n        if label == 'cat':\n            labels.append(0)\n        else:\n            labels.append(1)\n            \n    return labels\n\ndef get_filenames(folder):\n    \"\"\"\n    Extracts the filenames of the images\n    \"\"\"\n    \n    files = []\n    for file in folder:\n        files.append(file)\n    \n    return files","2b96676b":"# load data and data specifics\n\nTRAIN_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/train'\nTEST_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/test\/test'\n\n! unzip '..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip'","0d26369b":"! unzip '..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip'","4e88abfc":"# get train images\n\ntr_images = os.listdir(\".\/train\")\nprint(len(list(tr_images)))  # 25000 should be displayed as that's the size of the training set\n\nte_images = os.listdir(\".\/test\")\nprint(len(list(te_images)))","b52a6c13":"# view image\n\nPIL.Image.open(str('train\/' + get_filenames(tr_images)[0])) # keep changing the index value to get different images","7d803c7e":"# build the image data pipeline\n\ndef vectorize_image(filename, label):\n    \"\"\"\n    Convert image to array representation\n    \"\"\"\n    \n    image = tf.image.decode_jpeg(\n        tf.io.read_file('train\/' + filename),\n        channels = 3\n    )\n    \n    # convert to float values in [0, 1]\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    \n    return image, label\n\ndef pre_processing(filename, label):\n    \"\"\"\n    Perform pre-processing steps\n    \"\"\"\n    \n    # vectorize image first\n    image, label = vectorize_image(filename, label)\n    \n    # resize images for uniformity\n    image = tf.image.resize(image, [126, 126])\n    \n    # data augmentation (simple horizontal flipping)\n    image = tf.image.random_flip_left_right(image)\n    \n    return image, label\n\n# extract useful information from folders\nfilenames = get_filenames(tr_images)\nlabels = get_labels(tr_images)\n\n# split to train and validation set\ntr_filenames, val_filenames, tr_labels, val_labels = train_test_split(\n    filenames,\n    labels,\n    train_size = 0.8,\n    random_state = 101\n)\n\n# make the dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices((tr_filenames, tr_labels))\nval_dataset = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n# shuffle it\n#dataset = dataset.shuffle(len(filenames))\n# perform some pre-processing\n#dataset = dataset.map(pre_processing, num_parallel_calls=4)\n# set the batch size\n#dataset = dataset.batch(batch_size=32)\n# prefetch helps introduce parallel training\n#dataset = dataset.prefetch(1)\n\ntrain_dataset = (train_dataset\n                 .map(pre_processing, num_parallel_calls=4)\n                 .shuffle(len(tr_filenames))\n                 .batch(batch_size=32)\n                 .prefetch(1)\n                )\nval_dataset = (val_dataset\n               .map(pre_processing, num_parallel_calls=4)\n               .shuffle(len(val_filenames))\n               .batch(batch_size=32)\n               .prefetch(1)\n              )","3b5aeea6":"type(val_dataset)","a726aab3":"tf.test.is_gpu_available()","b7d70784":"# train the model\n\nmodel = tf.keras.Sequential([\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.GlobalAveragePooling2D(),\n  layers.Dropout(0.5),\n  layers.Dense(2, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(train_dataset,\n          epochs = 5,\n          steps_per_epoch = int(len(tr_filenames)\/32), # how many batches to be done before declaring an epoch as done?\n          validation_data = val_dataset,\n          validation_steps = 10,\n          verbose = 2\n)","2543e681":"# save the model; download it\n\nmodel.save('baseline_model_epoch10_batchsize32.h5')","ab477ef3":"PIL.Image.open(str('test\/' + get_filenames(te_images)[1024]))","708a8a1f":"img = tf.io.read_file('test\/' + get_filenames(te_images)[1024])\nimg = tf.image.decode_jpeg(img, channels=3)\nimg = tf.image.convert_image_dtype(img, tf.float32)\nimg.set_shape([None, None, 3])\nimg = tf.image.resize(img, (126, 126))\nimg = np.expand_dims(img, 0) # make 'batch' of 1\n\npred = model.predict(img)\npred_label_idx = np.argmax(pred) \nlabels = ['cat', 'dog']\npred_label = labels[pred_label_idx]\nprint(f'The given image is most likely the image of a {pred_label}.')","97eac82a":"## Inference","5bde0e87":"# Building a Pet Feeder App\n\n> Workshop at Amrita School of Engineering, Bengaluru\n\n*Kernel Author : Ramshankar Yadhunath*","b788f875":"### Loading the Data\n\nIn this project, we are lucky as there is already a pre-built dataset of dogs and cats available for us. It is what is already loaded into this kernel.","58377d06":"## Define the Problem Statement\n\n![image.png](attachment:image.png)","ce6258f7":"**What are your observations from these images?**","0fb169cd":"## Building the Classifier","883c3f11":"## A Reasonable \"Solution\"\n\nA reasonable solution in this context is a solution that can satisfy our stakeholder and also be feasible to implement. It's easy to understand that this problem is an **image classification** task. Hence, we shall focus on creating an image classifier that can distinguish between cats and dogs.\n\n### What's the MVP?\nMVP stands for minimum viable product. In other words, the [MVP is the product with just enough features for the product to be adopted by innovators or early adopters](https:\/\/www.productplan.com\/glossary\/minimum-viable-product\/). Many a times, MVPs are built to test the preliminary version of a product and validate the idea.\n\nIn this project, the MVP is a software system that can label an image X as `dog` or `cat` depending upon what X actually contains. And it is an obvious requirement that this system must have a *high accuracy* i.e make as few errors as possible. **(Question: Is a high accuracy enough? Does it not seem like this product needs 100% accuracy? But, is that achievable? Think over this idea for yourself)**"}}