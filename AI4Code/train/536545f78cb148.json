{"cell_type":{"7665cc3d":"code","0297de54":"code","7c51b94a":"code","f3b6ce7e":"code","27f94a0f":"code","e4aa7cea":"code","dd3e8554":"code","d63319a9":"code","2b04ad55":"code","44fcbc03":"code","2c72c73c":"code","f25facf6":"code","722bf108":"code","ca395b84":"code","6438c54a":"code","de389e50":"code","473a3337":"code","b26e380e":"code","f69ebe75":"code","646cc989":"code","aab5d05e":"code","1edd3341":"code","0ae915a2":"markdown","ff849766":"markdown","3bd0c124":"markdown","55b13838":"markdown","32b2f77d":"markdown","cf58b78b":"markdown","f594b663":"markdown","faa2260a":"markdown","508c3f31":"markdown","ce9583bd":"markdown","dd1d5104":"markdown","dea99975":"markdown","2e8690b4":"markdown","225a45ff":"markdown","43440df0":"markdown","ee752604":"markdown","9ac78645":"markdown","8188b032":"markdown","5a1394ad":"markdown","30a5739d":"markdown","92185858":"markdown","279130d5":"markdown","0fe75218":"markdown","78bfe5f4":"markdown","2378e935":"markdown"},"source":{"7665cc3d":"import os\nimport re\nimport time\nimport warnings\n\n# Data Manipulation Libraries\nimport pandas as pd\nimport numpy as np\n\n# Data Vizualization libraries\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nwarnings.filterwarnings(\"ignore\")","0297de54":"red = [\"#4f000b\",\"#720026\",\"#ce4257\",\"#ff7f51\",\"#ff9b54\"]\nbo = [\"#6930c3\",\"#5e60ce\",\"#0096c7\",\"#48cae4\",\"#ade8f4\",\"#ff7f51\",\"#ff9b54\",\"#ffbf69\"]\npink = [\"#aa4465\",\"#dd2d4a\",\"#f26a8d\",\"#f49cbb\",\"#ffcbf2\",\"#e2afff\",\"#ff86c8\",\"#ffa3a5\",\"#ffbf81\",\"#e9b827\",\"#f9e576\"]","7c51b94a":"#reading csv file\nsurvey_df =  pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\")\nsurvey_df.head(6)","f3b6ce7e":"fig = go.Figure(\n    data=[\n        go.Table(\n        header=dict(\n                values=[\"Question Number \/ Sections \/ Parts\", \"Description\"],\n                fill_color=bo[2],\n                line_color='white',\n                align='center'\n        ),\n        cells=dict(\n                values=[\n                    [i.replace('_',\" \") for i in survey_df.columns[1:]],\n                    survey_df.iloc[0,1:]\n                ],\n                fill_color=bo[4],\n                line_color='white',\n                align='left'\n            )\n        )\n    ]\n)\nfig.update_layout(\n    title = dict(\n        text = 'Questions Asked in Survey 2021',\n        font_size = 25,\n    ),\n    title_x=0.5,\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)'\n)\nfig.show()","27f94a0f":"interested_cols = [\n    'Q1','Q2','Q3','Q4','Q5','Q6',\n    'Q15',\n    'Q20','Q21','Q22','Q23',\n    'Q25'\n]\ndf = survey_df.iloc[1:,1:][interested_cols]\ndf.columns = [\n    'age','gender','country','edubg','profression','yrofexpc',\n    'yrofexpml',\n    'empindustry', 'companysize', 'empdsw', 'empdiml',\n    'compensation'\n]\nprint(\"Size of DataFrame: \", df.shape)\ndf.head()","e4aa7cea":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\n\nle = LabelEncoder()\n\nfor col in df.columns:\n    df[col] = df[col].fillna('Unknown')\n    df[col] = le.fit_transform(df[col])\n\n# PCA\npipe2 = Pipeline(\n    [\n        ('scaler', StandardScaler()), \n#         ('tsne', TSNE(n_components=2, verbose=1, perplexity=46, n_iter=550)),\n        ('pca', PCA(2))\n    ]\n)\ndf_pca = pd.DataFrame(pipe2.fit_transform(df))\n# df_pca.head()\n\n# TSNE\npipe = Pipeline(\n    [\n        ('scaler', StandardScaler()), \n        ('tsne', TSNE(n_components=2, verbose=1, perplexity=46, n_iter=550)),\n#         ('pca', PCA(2))\n    ]\n)\ndf_r = pd.DataFrame(pipe.fit_transform(df))\n\n# df_r.head()","dd3e8554":"fig, ax = plt.subplots(1,2,figsize=(20, 9))\n\n# plt.figure(figsize=(10,8))\nsns.scatterplot(\n    x=df_pca.iloc[:,0], y=df_pca.iloc[:,1],\n    data=df,\n    legend=\"full\",\n    ax=ax[0]\n)\nax[0].set_title(\"PCA\")\n\nsns.scatterplot(\n    x=df_r.iloc[:,0], y=df_r.iloc[:,1],\n    data=df,\n    legend=\"full\",\n    ax=ax[1]\n)\nax[1].set_title(\"TSNE\")","d63319a9":"from sklearn.cluster import KMeans\n\ndef no_of_cluster(df, title):\n    w=[]\n    e=[]\n    for i in range(1,10):\n        k=KMeans(n_clusters=i)\n        k.fit_predict(df)\n        e.append(k.inertia_)\n        w.append(i)\n    plt.figure(figsize=(8,5))\n    plt.plot(w,e,'bo-')\n    plt.title(f\"Optimum number of Clusters for KMeans - {title}\")\nno_of_cluster(df_pca, \"PCA\")\nno_of_cluster(df_r, \"TSNE\")","2b04ad55":"model_pca = KMeans(n_clusters=3, random_state=50)\nmodel_pca.fit(df_pca)\n\nmodel_tsne = KMeans(n_clusters=3, random_state=50)\nmodel_tsne.fit(df_r)","44fcbc03":"fig, ax = plt.subplots(1,2,figsize=(20, 9))\n\nax[0].scatter(df_pca.iloc[:,0], df_pca.iloc[:,1], c=model_pca.labels_, alpha=0.3)\nax[0].set_title(\"PCA\")\n\nax[1].scatter(df_r.iloc[:,0], df_r.iloc[:,1], c=model_tsne.labels_, alpha=0.3)\nax[1].set_title(\"TSNE\")","2c72c73c":"fig, ax = plt.subplots(2,2,figsize=(20, 18))\n\n# PCA\nax[0,0].scatter(df_pca.iloc[:,0],df_pca.iloc[:,1],c=model_pca.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_pca.iloc[:,0], y=df_pca.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q5'],\n    data=df,\n    legend=\"full\",\n    ax=ax[0,1]\n)\nax[0,1].set_title(\"PCA\")\n\n# TSNE\nax[1,0].scatter(df_r.iloc[:,0],df_r.iloc[:,1],c=model_tsne.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_r.iloc[:,0], y=df_r.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q5'],\n    data=df,\n    legend=\"full\",\n    ax=ax[1,1]\n)\nax[1,1].set_title(\"TSNE\")\n\n# Plot legend outside of plot\nax[0,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[1,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","f25facf6":"fig, ax = plt.subplots(2,2,figsize=(20, 18))\n\n# PCA\nax[0,0].scatter(df_pca.iloc[:,0],df_pca.iloc[:,1],c=model_pca.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_pca.iloc[:,0], y=df_pca.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q2'],\n    data=df,\n    legend=\"full\",\n    ax=ax[0,1]\n)\nax[0,1].set_title(\"PCA\")\n\n# TSNE\nax[1,0].scatter(df_r.iloc[:,0],df_r.iloc[:,1],c=model_tsne.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_r.iloc[:,0], y=df_r.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q2'],\n    data=df,\n    legend=\"full\",\n    ax=ax[1,1]\n)\nax[1,1].set_title(\"TSNE\")\n\n# Plot legend outside of plot\nax[0,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[1,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","722bf108":"fig, ax = plt.subplots(2,2,figsize=(20, 18))\n\n# PCA\nax[0,0].scatter(df_pca.iloc[:,0],df_pca.iloc[:,1],c=model_pca.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_pca.iloc[:,0], y=df_pca.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q6'],\n    data=df,\n    legend=\"full\",\n    ax=ax[0,1]\n)\nax[0,1].set_title(\"PCA\")\n\n# TSNE\nax[1,0].scatter(df_r.iloc[:,0],df_r.iloc[:,1],c=model_tsne.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_r.iloc[:,0], y=df_r.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q6'],\n    data=df,\n    legend=\"full\",\n    ax=ax[1,1]\n)\nax[1,1].set_title(\"TSNE\")\n\n# Plot legend outside of plot\nax[0,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[1,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","ca395b84":"fig, ax = plt.subplots(2,2,figsize=(20, 18))\n\n# PCA\nax[0,0].scatter(df_pca.iloc[:,0],df_pca.iloc[:,1],c=model_pca.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_pca.iloc[:,0], y=df_pca.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q15'],\n    data=df,\n    legend=\"full\",\n    ax=ax[0,1]\n)\nax[0,1].set_title(\"PCA\")\n\n# TSNE\nax[1,0].scatter(df_r.iloc[:,0],df_r.iloc[:,1],c=model_tsne.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_r.iloc[:,0], y=df_r.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q15'],\n    data=df,\n    legend=\"full\",\n    ax=ax[1,1]\n)\nax[1,1].set_title(\"TSNE\")\n\n# Plot legend outside of plot\nax[0,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[1,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","6438c54a":"fig, ax = plt.subplots(2,2,figsize=(20, 18))\n\n# PCA\nax[0,0].scatter(df_pca.iloc[:,0],df_pca.iloc[:,1],c=model_pca.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_pca.iloc[:,0], y=df_pca.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q25'],\n    data=df,\n    legend=\"full\",\n    ax=ax[0,1]\n)\nax[0,1].set_title(\"PCA\")\n\n# TSNE\nax[1,0].scatter(df_r.iloc[:,0],df_r.iloc[:,1],c=model_tsne.labels_, alpha=0.3)\nsns.scatterplot(\n    x=df_r.iloc[:,0], y=df_r.iloc[:,1],\n    hue=survey_df.iloc[1:,1:]['Q25'],\n    data=df,\n    legend=\"full\",\n    ax=ax[1,1]\n)\nax[1,1].set_title(\"TSNE\")\n\n# Plot legend outside of plot\nax[0,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[1,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","de389e50":"# PCA\npipe24 = Pipeline(\n    [\n        ('scaler', StandardScaler()), \n#         ('tsne', TSNE(n_components=2, verbose=1, perplexity=46, n_iter=550)),\n        ('pca', PCA(3))\n    ]\n)\ndf4_pca = pd.DataFrame(pipe24.fit_transform(df))\n# df_pca.head()\n\n# TSNE\n# pipet = Pipeline(\n#     [\n#         ('scaler', StandardScaler()), \n#         ('tsne', TSNE(n_components=3, verbose=1, perplexity=104, n_iter=550)),\n# #         ('pca', PCA(2))\n#     ]\n# )\n# df4_r = pd.DataFrame(pipet.fit_transform(df))","473a3337":"fig, ax = plt.subplots(3,3,figsize=(20, 18))\nfig.suptitle('PCA components')\n\nfor i in range(3):\n    for j in range(3):\n        if i!=j:\n            sns.scatterplot(\n                x=df4_pca.iloc[:,i], y=df4_pca.iloc[:,j],\n                data=df,\n                legend=\"full\",\n                ax=ax[i,j]\n            )\n            ax[i,j].set_title(f\"{i} vs {j}\")","b26e380e":"no_of_cluster(df4_pca, \"PCA\")","f69ebe75":"model4_pca = KMeans(n_clusters=3, random_state=70)\nmodel4_pca.fit(df4_pca)","646cc989":"fig = plt.figure(figsize = (10, 10))\nax = plt.axes(projection =\"3d\")\n\nsurf = ax.scatter3D(\n    df4_pca.iloc[:,0], \n    df4_pca.iloc[:,1], \n    df4_pca.iloc[:,2], \n    c=model4_pca.labels_, \n    alpha=0.3\n)\nlegend1 = ax.legend(\n    *surf.legend_elements(),\n    title=\"Clusters\",\n    bbox_to_anchor=(1.08, 1), \n    loc=2, \n    borderaxespad=0.\n)\nax.add_artist(legend1)\nplt.title(\"Visualizing clusters in 3D\")","aab5d05e":"color_code = le.fit_transform(survey_df.fillna('Unknown').iloc[1:,1:]['Q25'])\noriginal_value = survey_df.fillna('Unknown').iloc[1:,1:]['Q25']\n\nlegend_df = pd.DataFrame([color_code, original_value]).T.drop_duplicates().sort_values(0)\n\nfig = plt.figure(figsize = (10, 10))\nax = plt.axes(projection =\"3d\")\nsurf = ax.scatter3D(\n    df4_pca.iloc[:,0], \n    df4_pca.iloc[:,1], \n    df4_pca.iloc[:,2], \n    c=color_code, \n    alpha=0.3,\n)\n\nlegend1 = ax.legend(\n    *surf.legend_elements(),\n    title=\"Compensation Class\",\n    bbox_to_anchor=(1.15, 1), \n    loc=2, \n    borderaxespad=0.\n)\nax.add_artist(legend1)\n\nax.set_xlabel('Component 1')\nax.set_ylabel('Component 2')\nax.set_zlabel('Component 3')\nfig.colorbar(surf, shrink=0.5)","1edd3341":"legend_df","0ae915a2":"### Training the Kmeans model","ff849766":"### Optimal Number of clusters","3bd0c124":"# Training the KMeans Model","55b13838":"## Gender based Distribution","32b2f77d":"- Since all the features selected are categorical visualizing directly would yield much, it will look like a grid with different color balls placed at the intersections. So now lets reduce the number of dimensions to 2 components: it will be easy visualize, will take less time to train, and find the why more number of components are required.\n\n- PCA is usually used to reduce the dimension of datasets which are very large, whereas TSNE is used to reduce the dimensions of the dataset which has a very large number of features. Although, we are aware about this will still give it a try and find what comes up.\n\n#### Let's START","cf58b78b":"### Compensation distribution in 3D","f594b663":"# Data Preprocessing","faa2260a":"To find the optimal number of clusters, let's have a look at the above elbow plots for PCA and TSNE. The points 3 and 4 looks good enough, but yet 3 seems to be a bit more stable.","508c3f31":"## Experience in Machine Learning","ce9583bd":"Only found the above 12 columns looks quite decent which may add some meaning to identified clusters. All the above fields are categorical. I haven't included the multiple choice questions yet as I wasn't really sure about those and including didn't make any sense.","dd1d5104":"# Finding Optimal Number of Clusters","dea99975":"## Profession based distribution","2e8690b4":"# To be continued...\n\n#### Upvote if you find it interesting. Do not forget to drop suggestions in comments below.","225a45ff":"# Reducing Dimensionality to 3 components","43440df0":"### Scatter Plot to visualize one dimension against another","ee752604":"# Dimensionality Reduction with TSNE and PCA","9ac78645":"# Comparing TSNE and PCA","8188b032":"## Compensation","5a1394ad":"# Questions Asked","30a5739d":"## Coding Experience","92185858":"# Imports","279130d5":"### Seems like 2 dimension aren't enough to carve out good difference between clusters.\n- It is all mixed up and cluttered\n- Lets now try with increasing the number of components to 3 or 4 and observe the differences.","0fe75218":"# Visualizing the cluster mappings","78bfe5f4":"### 3D projection of data reduced to 3 dimensions ","2378e935":"# Reading the data"}}