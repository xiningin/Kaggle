{"cell_type":{"57396410":"code","c7059231":"code","10c94479":"code","fa1cb8d1":"code","4c36a22f":"code","55fa3f3f":"code","e97f3353":"code","6ae748f8":"code","4ca461fc":"code","6af27bd5":"code","d26f8475":"code","075477fe":"markdown","d92a6153":"markdown","b04fc746":"markdown","29b81ce4":"markdown","1e36656c":"markdown","115e13d4":"markdown","a2c794ad":"markdown","dfabd70a":"markdown","3ca5e95c":"markdown","0de3a8bc":"markdown","ef9a98be":"markdown","edd64a16":"markdown","30d136ff":"markdown"},"source":{"57396410":"import pandas as pd\nimport pandas_profiling","c7059231":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","10c94479":"pandas_profiling.ProfileReport(train_data)","fa1cb8d1":"import numpy as np\n\ndef age_preprocessing(age):\n    age = age.fillna(age.mean())\n    age_s = age.map(lambda x:str(x)[0] if x>=10 else str(0))\n    age_s = age_s.map(lambda x:x if int(x)<=6 else \"7<=\")\n    return age_s\n\ndef sibsp_preprocessing(sibsp):\n    group_ids = []\n    for num in sibsp:\n        if num==0:\n            group_ids.append(\"alone\")\n        elif (num==1) or (num==2):\n            group_ids.append(\"small\")\n        elif num >= 3:\n            group_ids.append(\"large\")\n    return group_ids\n\ndef parch_preprocessing(parch):\n    group_ids = []\n    for num in parch:\n        if num==0:\n            group_ids.append(\"alone\")\n        elif (num==1) or (num==2):\n            group_ids.append(\"small\")\n        elif num >= 3:\n            group_ids.append(\"large\")\n    return group_ids\n\ndef fare_preprocessing(fare):\n    fare = fare.fillna(fare.mean())\n    new_bins = np.array([0, 10, 30, 100, 1000])\n    ids = np.digitize(fare, new_bins)\n    return ids\n\ndef ticket_preprocessing(ticket_df):\n    words = []\n    for ticket in ticket_df:\n        for word in ticket.split():\n            words.append(word.replace(\".\",\"\"))\n    count_df = pd.Series(words).value_counts().to_frame()\n    words_num_over5 = list(count_df[count_df[0]>=5].index)\n    print(\"---ticket over5num words---\\n\",words_num_over5,\"\\n\")\n    df_Ticket = pd.DataFrame(index=ticket_df.index, data=ticket_df.values, columns=[\"Ticket\"])\n    for word in words_num_over5:\n        df_Ticket[\"T_\" + word] = df_Ticket[\"Ticket\"].map(lambda x:1 if word in x.replace(\".\",\"\").split() else 0)\n    df_Ticket[\"T_No_target\"] = pd.Series(df_Ticket.iloc[:,2:].sum(axis=1)).map(lambda x:1 if x==0 else 0)\n    return df_Ticket.drop(\"Ticket\",axis=1)\n\ndef cabin_preprocessing(cabin):\n    cabin = cabin.fillna(\"-\")\n    cabin = cabin.map(lambda x:x[0])\n    return cabin\n\ndef name_preprocessing(name):\n    df_Name = pd.DataFrame(index=name.index)\n    #Title\n    df_Name[\"Title\"] = name.map(lambda x: x.split(', ')[1].split('. ')[0])\n    df_Name['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer', inplace=True)\n    df_Name['Title'].replace(['Don', 'Sir',  'the Countess', 'Lady', 'Dona'], 'Royalty', inplace=True)\n    df_Name['Title'].replace(['Mme', 'Ms'], 'Mrs', inplace=True)\n    df_Name['Title'].replace(['Mlle'], 'Miss', inplace=True)\n    df_Name['Title'].replace(['Jonkheer'], 'Master', inplace=True)\n    #Family_flag\n    Surname = name.map(lambda name:name.split(',')[0].strip())\n    count_df_over2 = Surname.value_counts().to_frame()\n    count_df_over2 = count_df_over2[count_df_over2[\"Name\"]>1]\n    df_Name['Family_flag'] = Surname.map(lambda x:1 if x in list(count_df_over2.index) else 0)\n    df_Name = pd.get_dummies(df_Name)\n    return df_Name\n\n###load data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\").set_index(\"PassengerId\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\").set_index(\"PassengerId\")\n\n###concat train_data and test_data\ndata = pd.concat([train_data.drop(\"Survived\",axis=1), test_data])\n\n###check null data\nprint(\"---null counts---\\n\",data.apply(lambda x: sum(x.isnull())),\"\\n\")\n\n### 1.Pclass   ### 2.Sex   ### 7.Embarked \n# No preprocessing. using get_dummies.\ndata = pd.get_dummies(data, columns=[\"Pclass\",\"Sex\",\"Embarked\"])\n#Sex is binary... better one variable than dummies..?\ndata[\"Sex\"] = data[\"Sex_female\"]\ndata = data.drop([\"Sex_male\",\"Sex_female\"], axis=1)\n\n### 3.Age\ndata[\"Age\"] = age_preprocessing(data[\"Age\"])\ndata = pd.get_dummies(data, columns=[\"Age\"])\n\n### 4.SibSp\ndata[\"SibSp\"] = sibsp_preprocessing(data[\"SibSp\"])\ndata = pd.get_dummies(data, columns=[\"SibSp\"])\n\n### 5.Parch  \ndata[\"Parch\"] = sibsp_preprocessing(data[\"Parch\"])\ndata = pd.get_dummies(data, columns=[\"Parch\"])\n\n### 6.Fare  \ndata[\"Fare\"] = fare_preprocessing(data[\"Fare\"])\ndata = pd.get_dummies(data, columns=[\"Fare\"])\n\n### 8.Ticket\ndf = ticket_preprocessing(data[\"Ticket\"])\ndata = pd.concat([data, df],axis=1)\ndata = data.drop(\"Ticket\",axis=1)\n\n### 9.Cabin  \ndata[\"Cabin\"] = cabin_preprocessing(data[\"Cabin\"])\ndata = pd.get_dummies(data, columns=[\"Cabin\"])\n\n### 10.Name   \ndf = name_preprocessing(data[\"Name\"])\ndata = pd.concat([data, df],axis=1)\ndata = data.drop(\"Name\",axis=1)\n\ndata.head()","4c36a22f":"train_processed = data.loc[train_data.index,:]\ntest_processed = data.loc[test_data.index,:]","55fa3f3f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","e97f3353":"X_train, X_test, y_train, y_test = train_test_split(train_processed, train_data[\"Survived\"], random_state=0)","6ae748f8":"model = RandomForestClassifier(max_depth=10)\nmodel.fit(X_train, y_train)\nprint(f\"test_score:{model.score(X_test, y_test):.3f}\")","4ca461fc":"import matplotlib.pyplot as plt\n\npred_df = pd.DataFrame({\"column\":train_processed.columns, \"feature_importance\":model.feature_importances_})\npred_df = pred_df.sort_values(by=\"feature_importance\", ascending=True)\nplt.figure(figsize=(15,20))\nplt.barh(pred_df[\"column\"], pred_df[\"feature_importance\"])\nplt.title(\"feature importance\")\nplt.show()","6af27bd5":"model = RandomForestClassifier(max_depth=10)\nmodel.fit(train_processed, train_data[\"Survived\"])","d26f8475":"submission = sample_submission.copy()\nsubmission.Survived = model.predict(test_processed)\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission","075477fe":"# 1. import Library","d92a6153":"# Thank you for reading to the end\uff01\n## nice kaggle life","b04fc746":"### validation","29b81ce4":"### fit all training data for submission","1e36656c":"# 5.Classifier model\n### For now, I'll use the versatile Random Forest.","115e13d4":"# 6. Submission data(final)","a2c794ad":"# Let's do a lot of analysis together!\n### Here is one way to go about getting prediction results\n#### EDA is implemented in this notebook, if you want to refer to it.\nhttps:\/\/www.kaggle.com\/showeed\/starter-book-begginer-analysis","dfabd70a":"### show random forest feature importance","3ca5e95c":"# 2.load dataset\n### We will only use the training data this time, but we have included all the data for reference.","0de3a8bc":"# 3. pandas_profiling\n### It's really convenient to run it with just one line!","ef9a98be":"# 4. Preprocessing Data","edd64a16":"### In this book, I will introduce a useful library called pandas_profiling.\n### It will automatically do basic data analysis for you.\n### Let's start!","30d136ff":"# This notebook is intended for beginners.\n#### (I'm sharing this because I'm a beginner too)"}}