{"cell_type":{"89ed8c91":"code","8f1d4efe":"code","e1b766fa":"code","ed6224ac":"code","a90d6b95":"code","1e288c5e":"code","745f3441":"code","b62834de":"code","d40803cb":"code","c16a4044":"code","c357e153":"code","a2f5d2ff":"code","25892add":"code","c18e7139":"code","c9f050b7":"code","fc8dd430":"code","384adaf5":"code","054338f4":"code","632ea7ad":"code","12afd569":"code","48d9f3ca":"code","9cd4ac76":"code","6ced620d":"code","0e8061c0":"code","ffd45d18":"code","859924ad":"code","d45b273c":"code","5e19ae8f":"code","f49e359a":"code","37f3cc27":"code","c6e0eebe":"code","53b7ecef":"code","e58a5206":"code","c26e9479":"code","7f82b603":"code","0983bf11":"code","c2f211b6":"code","7f6647bb":"code","da751a97":"code","4c95a72b":"code","91ae67f2":"code","c3807167":"code","aed7818c":"code","267245f8":"code","937b48f7":"code","86bef7e8":"code","483666de":"code","f5cb2199":"code","ed863354":"code","5ccdaa4e":"code","4af107ac":"code","7cc44688":"code","b1531223":"code","072d5838":"code","4659d774":"code","80e14619":"code","85a870a2":"code","e79dacd5":"code","7683993e":"code","cdcb75d9":"code","f4fb11c7":"code","2004115f":"code","b9841429":"code","34976d91":"code","6e16ce0f":"code","481829d5":"code","136123ed":"code","4a4a9160":"code","af9f0913":"code","ce3fbcf2":"code","41ca22d5":"code","5d67488e":"code","a26b4128":"code","dd6047a0":"code","b9fbce11":"code","a12d73e8":"code","0c7f7789":"code","f31a8fac":"code","38d8c2dd":"code","f60640c4":"code","ea912ccb":"markdown","1d11c173":"markdown","ffc5b91a":"markdown","82c64134":"markdown","6f37b518":"markdown","a8911fe6":"markdown","293925b3":"markdown","4e9fcc3a":"markdown","1ec809a0":"markdown","060e27a3":"markdown","9f605fec":"markdown","11baca97":"markdown","55481d73":"markdown","8bcead0e":"markdown","4916a33e":"markdown","ff3446c4":"markdown","c4e309a9":"markdown","20863535":"markdown","cc26b2a4":"markdown","991432f6":"markdown","efccda8b":"markdown","5b0e23ea":"markdown","bd4af708":"markdown","8ab652f0":"markdown","bd8c30a6":"markdown","b5fdf7d3":"markdown","b7a5d35c":"markdown","e37322e7":"markdown","8907182d":"markdown","9996741b":"markdown","7ba8aa51":"markdown","99a5a12d":"markdown","1db6f536":"markdown","a3842458":"markdown","ea1ae530":"markdown","c587db0a":"markdown","f52ace90":"markdown","6438b103":"markdown","f97c0330":"markdown","2eede143":"markdown","a1a94077":"markdown","7b8eeb05":"markdown","f0b5c4af":"markdown","480daa13":"markdown","82b016ce":"markdown","349c63ec":"markdown","f96c6f0a":"markdown","c2864433":"markdown","113c3b19":"markdown","f13cb6aa":"markdown","f7095753":"markdown","9b0ce3bb":"markdown","ff938e2e":"markdown","6f54947e":"markdown","9b3d5995":"markdown","103eeecf":"markdown","89251c85":"markdown","3a6c3c12":"markdown","f94c6dc0":"markdown","81abeca7":"markdown","d73bc38b":"markdown","d1c27c2a":"markdown","7b2e42aa":"markdown","5aebe666":"markdown","c1afd1a8":"markdown","554af224":"markdown","e529d83d":"markdown","84f89e9c":"markdown","04a0d0ce":"markdown","e81477f1":"markdown","aff5f869":"markdown","c8686935":"markdown","22548035":"markdown","319e225b":"markdown","5b588fb0":"markdown"},"source":{"89ed8c91":"# For Loading and Manipulating the data\nimport numpy as np\nimport pandas as pd\nfrom itertools import combinations\n\n# For splitting, scaling and upsampling the data respectively\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# For Evaluation \nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n# For Visualization Purposes \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# To display all the columns ( regardless of their number or their width )\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n\n# To change the style of the plots ( so that we all can see the same thing :) )\nplt.style.use('seaborn')","8f1d4efe":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e1b766fa":"churn_df = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","ed6224ac":"churn_df.head()","a90d6b95":"# First of all let's change some columns names so that all the columns names are written in the same pattern\nchurn_df.rename(columns={'customerID':'CustomerID', 'gender':'Gender', 'tenure':'Tenure'}, inplace=True)","1e288c5e":"churn_df.info()","745f3441":"\" \" in churn_df.values","b62834de":"churn_df.describe().drop(columns='SeniorCitizen') # I droped SeniorCitizen from statistical description \n                                                  # as it will be considered a numeric column which it is not","d40803cb":"churn_df.duplicated().sum()","c16a4044":"churn_df.drop(columns='CustomerID', inplace=True)","c357e153":"churn_df.columns","a2f5d2ff":"churn_df.replace(' ', np.nan, inplace=True)","25892add":"churn_df.isnull().sum()","c18e7139":"churn_df[churn_df['TotalCharges'].isnull()]","c9f050b7":"churn_df.shape","fc8dd430":"churn_df['Churn'].value_counts()","384adaf5":"churn_df[churn_df['TotalCharges'].isnull()]['Churn'].value_counts()","054338f4":"churn_df.dropna(inplace=True)","632ea7ad":"churn_df.isnull().sum()","12afd569":"# toObject               \nchurn_df[\"SeniorCitizen\"] = churn_df[\"SeniorCitizen\"].map({1:'Yes', 0:'No'})    \n\n# toFloat\nchurn_df[\"TotalCharges\"]  = churn_df[\"TotalCharges\"].astype(float) ","48d9f3ca":"churn_df[\"SeniorCitizen\"].unique()","9cd4ac76":"churn_df[\"TotalCharges\"].dtype","6ced620d":"def CountPlot(dataFrame, x, hue=None, ax=None):\n    # Main plot\n    ax = sns.countplot(data=dataFrame, x=x, hue=hue, ax=ax)\n    \n    ## Adding Annotation \n    # Total number of clients\n    n_clients = dataFrame.shape[0]\n    \n    # Looping over each column\n    for p in ax.patches:\n\n        loc    = p.get_x()\n        height = p.get_height()\n        width  = p.get_width()\n        pct    = '({:0.2f}%)'.format(100*height\/n_clients)\n        \n        # Adding the exact height at the top\n        ax.text(loc+width\/2, height+3 , str(height), weight = 'bold',ha=\"center\", fontsize=15)\n        \n        # Adding the percentage wrt the total number of clients at the middle of each column\n        ax.text(loc+width\/2, int(0.5*height), pct, weight = 'bold',ha=\"center\", fontsize=15, color='w')\n        \n    # Adding title\n    ax.set_title(f\"{x} Distribution\", fontsize=25, color='brown')\n    \n    # Before editing the ticks we need to draw the plot first\n    plt.draw()\n    \n    # Editing axes labels and ticks\n    ax.set_xlabel(x, fontsize=20)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n        \n    ax.set_ylabel('Number of Users', fontsize=20)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15);\n        \n    # Adding legend\n    if hue:\n        ax.legend(labels=list(dataFrame[hue].unique()),  prop={\"size\":20}, frameon=True, shadow=True);","0e8061c0":"def ScatterPlot(dataFrame, x, y, hue=None, ax=None):\n    # Main plot\n    ax = sns.scatterplot(data=dataFrame, x=x, y=y, hue=hue, ax=ax, alpha=0.7)\n    \n    # Adding title\n    corr = dataFrame[x].corr(dataFrame[y])\n    ax.set_title(f\"{x} with {y} by {hue}\\n (Corr = {round(corr, 2)})\", fontsize=25, color='brown')\n    \n    # Before editing the ticks we need to draw the plot first\n    plt.draw()\n    \n    # Editing axes labels\n    ax.set_xlabel(x, fontsize=20)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n    \n    ax.set_ylabel(y, fontsize=20)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15);\n    \n    # Adding legend\n    if hue:\n        ax.legend(prop={\"size\":13}, frameon=True, shadow=True);","ffd45d18":"def kdeplot_churn(dataFrame, col, ax=None):\n    # Main plot\n    ax = sns.kdeplot(dataFrame[col][dataFrame[\"Churn\"] == 'Yes'], color=\"Red\", ax=ax, shade=True)\n    ax = sns.kdeplot(dataFrame[col][dataFrame[\"Churn\"] == 'No'], color=\"Blue\", ax=ax, shade=True)\n    \n    # Adding title\n    ax.set_title(f\"Distribution of {col} by churn\", fontsize=17, color='brown')\n    \n    # Before editing the ticks we need to draw the plot first\n    plt.draw()\n    \n    # Editing axes labels\n    ax.set_xlabel(col, fontsize=15)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n    \n    ax.set_ylabel('Density', fontsize=15)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n    \n    # Adding legend\n    ax.legend([\"Churn\",\"Not Churn\"], loc='upper right', frameon=True, shadow=True);","859924ad":"CountPlot(churn_df, 'Churn')","d45b273c":"Demographic_cols = ['Gender', 'SeniorCitizen', 'Partner', 'Dependents', 'Churn']\nServices_cols    = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n                    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Churn']\nAccount_cols_cat = ['Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn']\nAccount_cols_num = ['Tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']","5e19ae8f":"fig = plt.figure(figsize=(17, 12))\nfig.suptitle('Demographic Features Distributions', fontsize=40, weight='bold')\nfor i, col in enumerate(Demographic_cols[:-1]):\n    sorted_counts = churn_df[col].value_counts()\n    plt.subplot(2, 2, i+1)\n    plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n    plt.title(f'{col} Distribution',fontsize=15, weight='bold', color='brown', loc='center')","f49e359a":"fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (22,20))\nfig.suptitle('Demographic Features Distributions by Churn', fontsize=40, weight='bold')\nfor i, col in enumerate(Demographic_cols[:-1]):\n    CountPlot(churn_df[Demographic_cols], col, hue=\"Churn\", ax=axes[i\/\/2, i-(i\/\/2)*2])","37f3cc27":"# I just need, for now, to convert the Gender column to ones and zeros\nchurn_df['Gender'] = np.where(churn_df['Gender'] == 'Male', 1, 0)\n\n# Detect if the client has neither Partner nor Dependents\nchurn_df['NoDep_NoPart'] = np.where((churn_df['Partner'] == 'No')|(churn_df['Dependents'] == 'No'), 1, 0)\n\n# Senior or not\nchurn_df['SeniorCitizen'] = np.where((churn_df['SeniorCitizen'] == 'Yes'), 1, 0)","c6e0eebe":"# Dropping the unnecessary columns ( according to the above analysis )\nchurn_df.drop(columns=[\"Partner\", \"Dependents\"], inplace=True)","53b7ecef":"fig = plt.figure(figsize=(17, 17))\nfig.suptitle('Services Features Distributions', fontsize=40, weight='bold')\nfor i, col in enumerate(Services_cols[:-1]):\n    sorted_counts = churn_df[col].value_counts()\n    plt.subplot(3, 3, i+1)\n    plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n    plt.title(f'{col} Distribution',fontsize=15, weight='bold', color='brown', loc='center')","e58a5206":"fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (32,30))\nfig.suptitle('Services Features Distributions by Churn', fontsize=50, weight='bold')\nfor i, col in enumerate(Services_cols[:-1]):\n    CountPlot(churn_df[Services_cols], col, hue=\"Churn\", ax=axes[i\/\/3, i-(i\/\/3)*3])","c26e9479":"# Phone Service\nchurn_df['PhoneService'] = np.where(churn_df['PhoneService']=='Yes', 1, 0)\n\n# MultipleLines\nchurn_df['MultipleLines'] = np.where(churn_df['MultipleLines']=='Yes', 1, 0)\n\n# Has Fiber optic \nchurn_df['FiberOptic'] = np.where(churn_df['InternetService']=='Fiber optic', 1, 0)\n\n# Has no services ( other than MultipleLines, StreamingTV,and StreamingMovies )\nchurn_df['NoServ'] = np.where((churn_df['OnlineSecurity'] != 'No') | (churn_df['OnlineBackup'] != 'No') |\n                              (churn_df['DeviceProtection'] != 'No') | (churn_df['TechSupport'] != 'No'), 1, 0)\n\n# StreamingTV,and StreamingMovies\nchurn_df['NoStream'] = np.where((churn_df['StreamingTV'] != 'No') | (churn_df['StreamingMovies'] != 'No'), 1, 0)\n \n# number of services subscribed by each client\nchurn_df[\"SumOfIntServices\"]=(churn_df.iloc[:, 6:12]=='Yes').sum(axis=1)","7f82b603":"# Dropping....\nchurn_df.drop(columns=[\"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \n                       \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"], inplace=True)","0983bf11":"fig = plt.figure(figsize=(17, 10))\nfig.suptitle('Account Categorical Features Distributions', fontsize=40, weight='bold')\nfor i, col in enumerate(Account_cols_cat[:-1]):\n    sorted_counts = churn_df[col].value_counts()\n    plt.subplot(3, 1, i+1)\n    plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n    plt.title(f'{col} Distribution',fontsize=15, weight='bold', color='brown', loc='center')","c2f211b6":"fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize = (17,22))\nfig.suptitle('Account Categorical Features Distributions by Churn', fontsize=25, weight='bold')\nfor i, col in enumerate(Account_cols_cat[:-1]):\n    CountPlot(churn_df[Account_cols_cat], col, hue=\"Churn\", ax=axes[i])","7f6647bb":"# According to the above note....\nchurn_df['MonthToMonth'] = np.where((churn_df['Contract'] == 'Month-to-month'), 1,0)\nchurn_df['PaperlessBilling'] = np.where((churn_df['PaperlessBilling'] == 'Yes'), 1,0)\nchurn_df['ElectronicCheck'] = np.where((churn_df['PaymentMethod'] == 'Electronic check'), 1,0)","da751a97":"# Dropping...\nchurn_df.drop(columns=['Contract', 'PaymentMethod'], inplace=True)","4c95a72b":"fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (17,6))\nfig.suptitle('Numerical Account Features Distributions by Churn', fontsize=25, weight='bold')\nfor i in range(3):\n    kdeplot_churn(churn_df, Account_cols_num[i], ax=axes[i])","91ae67f2":"fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize = (15,30))\ncombs = list(combinations(Account_cols_num[:-1], 2))\nfor i in range(3):\n    ScatterPlot(churn_df, combs[i][0], combs[i-3][1], hue=Account_cols_num[-1], ax=axes[i])","c3807167":"pd.qcut(churn_df[\"MonthlyCharges\"],3).unique()  ","aed7818c":"# According to the above notes...\nchurn_df[\"tenure_L20\"]=pd.qcut(churn_df[\"Tenure\"],3)                       # 3 to get one of the categories (0.999, 14.0]   \nchurn_df[\"MonthlyCharges_60_120\"] = pd.qcut(churn_df[\"MonthlyCharges\"],3)  # 3 to get one of the categories (84.0, 118.75]","267245f8":"# Dropping \nchurn_df.drop(columns=[\"Tenure\", \"MonthlyCharges\", \"TotalCharges\"], inplace=True)","937b48f7":"churn_df.head()","86bef7e8":"# To avoid get_dummies trap you should put drop_first = True\nchurn_df = pd.get_dummies(data=churn_df, columns=['tenure_L20', 'MonthlyCharges_60_120'], drop_first=True)\n\n# As for Churn, we don't need LabelEncoder as it's only 'Yes' or 'No'\nchurn_df['Churn'] = np.where(churn_df['Churn']=='Yes', 1, 0)","483666de":"churn_df.info()","f5cb2199":"churn_df.isnull().sum()        ","ed863354":"churn_df.shape","5ccdaa4e":"x = churn_df.drop(columns=['Churn'])\ny = churn_df['Churn']","4af107ac":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)","7cc44688":"sc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","b1531223":"def get_precision(y_test, y_pred):\n    CM = confusion_matrix(y_test, y_pred)\n    TP = CM[1,1]\n    FP = CM[0,1]\n    precision = TP\/(TP+FP)\n    \n    return precision","072d5838":"lg_model = LogisticRegression(random_state=0)\nlg_model.fit(x_train, y_train)","4659d774":"lg_acc = lg_model.score(x_test, y_test)\nprint(\"The logistic Regression model score on train set is: {}\".format(lg_model.score(x_train, y_train)))  # To test Overfitting\nprint(\"The logistic Regression model score on test set is: {}\".format(lg_acc))","80e14619":"y_pred = lg_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","85a870a2":"knn_model = KNeighborsClassifier()\nknn_model.fit(x_train, y_train)","e79dacd5":"knn_acc = knn_model.score(x_test, y_test)\nprint(\"The KNN model score on train set is: {}\".format(knn_model.score(x_train, y_train)))    \nprint(\"The KNN model score on test set is: {}\".format(knn_acc))","7683993e":"y_pred = knn_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","cdcb75d9":"dt_model = DecisionTreeClassifier(random_state=0)\ndt_model.fit(x_train, y_train)","f4fb11c7":"dt_acc = dt_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(dt_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(dt_acc))","2004115f":"y_pred = dt_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","b9841429":"# Create for loop to prune tree\nprecisions = []\naccuracies = []\nd_range = range(2, 20) \nfor d in d_range:\n    tree = DecisionTreeClassifier(random_state=0, max_depth=d)\n    tree.fit(x_train, y_train)\n    y_pred = tree.predict(x_test)\n    precisions.append(get_precision(y_test, y_pred))\n    accuracies.append(tree.score(x_test, y_test))\n    \n# Plot graph to see how individual accuracy scores changes with tree depth\nplt.plot(d_range, precisions)\nplt.plot(d_range, accuracies)\nplt.xlabel(\"Depth of Tree\")\nplt.ylabel(\"Precisions(Blue) & Accuracy(Green)\");","34976d91":"precisions","6e16ce0f":"dt_model = DecisionTreeClassifier(random_state=0, max_depth=4)\ndt_model.fit(x_train, y_train)","481829d5":"dt_acc = dt_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(dt_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(dt_acc))","136123ed":"y_pred = dt_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","4a4a9160":"rf_model = RandomForestClassifier(oob_score=True, random_state=0, warm_start=True, n_jobs=-1)\nrf_model.fit(x_train, y_train)","af9f0913":"rf_acc = rf_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(rf_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(rf_acc))","ce3fbcf2":"y_pred = rf_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","41ca22d5":"rf_model = RandomForestClassifier(oob_score=True, random_state=0, warm_start=True, n_jobs=-1)","5d67488e":"precisions = []\naccuracies = []\n# Iterate through all of the possibilities for the number of trees\nn_range = range(50, 300, 10)\nfor n_trees in n_range:\n    rf_model.set_params(n_estimators=n_trees)  # Set number of trees\n    rf_model.fit(x_train, y_train)\n    y_pred = rf_model.predict(x_test)\n    precisions.append(get_precision(y_test, y_pred))\n    accuracies.append(rf_model.score(x_test, y_test))\n\nplt.plot(n_range, precisions, marker='o')\nplt.plot(n_range, accuracies)\nplt.xlabel(\"Number of Trees\")\nplt.ylabel(\"Precisions(Blue) & Accuracy(Green)\");","a26b4128":"precisions","dd6047a0":"rf_model = RandomForestClassifier(n_estimators=250, oob_score=True, random_state=0, warm_start=True, n_jobs=-1)\nrf_model.fit(x_train, y_train)","b9fbce11":"rf_acc = rf_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(rf_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(rf_acc))","a12d73e8":"y_pred = rf_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","0c7f7789":"svm_model = SVC(random_state=0, C=1.5)\nsvm_model.fit(x_train, y_train)","f31a8fac":"svm_acc = svm_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(svm_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(svm_acc))","38d8c2dd":"y_pred = svm_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","f60640c4":"# To calculate AUC\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test, y_pred)","ea912ccb":"> **We can see that:**\n- _From the scatter plot:_\n    - There is no specific pattern between Tenure and MonthlyCharges.\n    - But we do see that there is a correlation between TotalCharges with both of MonthlyCharges and Tenure, which is reasonable by the way. So i will take only the tenure and monthly charges and drop the total charges.\n","1d11c173":"#### Bivariate Exploration","ffc5b91a":"### Feature Engineering For Demographic Features","82c64134":"First let's **\"Churn\"** distribution","6f37b518":"> Summary:\n- there is a balance in Gender and Partner columns.\n- But on the other hand the majority of people are young and have no dependents. So we should take this imbalance into our consideration when we judge the upcoming results.","a8911fe6":"_KNN_","293925b3":"### Categorical Account Features...","4e9fcc3a":"> Also here there is an overfitting","1ec809a0":"> It looks like that this data is **Imbalanced**","060e27a3":"### Numerical Account Features...","9f605fec":"#### Univariate Exploration","11baca97":"A closer look on columns types","55481d73":"> **We can see that:**\n- Churn rate is :\n   - Is high for Clients that has a month-to-month contract ($\\frac{1655}{1655+2220} = {42.71}\\% $). That is reasonable by the way as he could make the contract more than that if he intended to stay longer.\n   - Is high for Clients that has paperless billing ($\\frac{1400}{1400+2768} = {33.59}\\% $). Maybe there is a problem in the website or something.\n   - Is very high for Clients that pay by electronic check ($\\frac{1071}{1071+1294} = {45.29}\\% $). May be the GUI or the website is not good enough.","8bcead0e":"<a id='sources'><\/a>\n# Sources\n[Telco Customer Churn](https:\/\/www.kaggle.com\/blastchar\/telco-customer-churn)\n\n#### Some of these ideas are ispired by [Muslum Polat](https:\/\/www.kaggle.com\/muslump\/telco-customer-churn-analysis?fbclid=IwAR0gRroMTTbjUQCzxf6Rp2FxDVu4n16pTRTcRPnCr9mqRzbu6hF0AZM5bz4)","4916a33e":">To Complete our story, Let's go to Bivariate Exploration.","ff3446c4":"<a id='model'><\/a>\n<font color='blue'>\n<h2><center> Modeling <\/center><\/h2>","c4e309a9":"Statistical Summary","20863535":"**To check if i did something wrong**","cc26b2a4":"## Agenda\n<ul>\n<li><a href=\"#sources\">Sources<\/a><\/li>\n<li><a href=\"#cleaning\">Data Cleaning<\/a><\/li>\n<li><a href=\"#eda\">Exploratory Data Analysis and some Feature Engineering<\/a><\/li>\n<li><a href=\"#model\">Modeling<\/a><\/li>\n<li><a href=\"#conc\">Conclusion<\/a><\/li>\n<\/ul>","991432f6":"#### Summary: \n> ##### We can see that there are:\n   - _Useless columns_  : \"CustomerID\"\n   - _Hidden NaNs_ : \" \"\n   - _Wrong-format Columns_ : \n      - _toObject_ : \"SeniorCitizen\"\t( that is not important but i like it to be 'Yes' and 'No' )\n      - _toFloat_  : \"TotalCharges\"","efccda8b":"**Test**","5b0e23ea":"_Hidden NaNs_","bd4af708":"> **According to the univariate distibutions, we can't rely on only the numbers. We should get the rate of churn for each one of them so that we could compare ( as we did in the demographic distributions ):**\n- The churn rate :\n   - Is very close for both Clients who have phone service ($\\frac{1699}{1699+4653} = {26.75}\\% $) and who hasn't ($\\frac{170}{170+510} = {25}\\% $).\n   - Is a little higher for Clients who have MultipleLines ($\\frac{850}{850+2117} = {28.65}\\% $) compared to other ones ($rate_{NoPhoneService}=\\frac{170}{170+510} = {25}\\% and rate_{No}=\\frac{849}{849+2536} = {25.08}\\%  $) May be it's expensive or something.\n   - Is relatively high for Clients that use Fiber optic in their internet Service ($\\frac{1297}{1297+1799} = {41.89}\\% $).\n   - Is relatively high for Clients that do not have Online Security, OnlineBackup, DeviceProtection,and TechSupport (41.78%, 39.94%, 39.14%,and 41.65% respectively).\n   - Also it's a little higher for the clients who do not have StreamingTV or StreamingMovies.","8ab652f0":"### Feature Engineering...","bd8c30a6":"**Test**","b5fdf7d3":"Before dive deeper in exploration phase let's first **divide** our data into three dataframes:\n- Demographic \n- Services \n- Account","b7a5d35c":"> We can see that:\n - if the client stayed from 0 to nearly 20 months only he is more likely to churn.\n - if the monthly charges is between 60 to 120 dollars he is more likely to churn\n - there is a little difference between the two density curves for the total charges.","e37322e7":"> I think the best value here is max_depth = 4","8907182d":"> **We can see that:**\n- The churn rate :\n   - Is very close for both Male and Female.\n   - Is high for Senior Clients ($\\frac{476}{476+666} = {41.68}\\% $) compared to Younger ones ($\\frac{1393}{1393+4497} = {23.65}\\% $)\n   - Is high for Clients that have no partner ($\\frac{1200}{1200+2439} = {32.98}\\% $) compared to the ones that have a partner ($\\frac{669}{669+2724} = {19.72}\\% $)\n   - Also here is high for Clients that have no dependents ($\\frac{1543}{1543+3390} = {31.28}\\% $) compared to the ones that have a dependent ($\\frac{326}{326+1773} = {15.53}\\% $)","9996741b":"_Wrong-format Columns_","7ba8aa51":"#### 3- Scaling Transformation","99a5a12d":"> We can see that all the missing values have Churn = 'No'. For the whole data, we can see that 'No's are more than 'Yes's. So I think dropping these 11 missing values will not affect the data dramatically.","1db6f536":"> I think n_estimators = 250 is the best number","a3842458":"### Feature Engineering For Services Features","ea1ae530":"> It seems that this model is slightly overfitting the data.","c587db0a":"_Random Forest_","f52ace90":"#### Bivariate Exploration","6438b103":"> Let's get the bivariate plots before jumping to any conclusions.","f97c0330":"<a id='conc'><\/a>\n# Conclusion: \n> As we can see the best model from all of the above is the _SVM_ :\n- Accuracy  = 82%\n- **Precision = 70%**\n- Recall    = 52%\n- **F1-score  = 60%**\n- **AUC = 72%**","2eede143":"### Feature Engineering...","a1a94077":"Checking Duplicates","7b8eeb05":"Before going on We can see that \"TotalCharges\" has an object type despite the fact that it's a numeric feature.","f0b5c4af":"### Demographic Features...","480daa13":"**Test**","82b016ce":"_Decision Tree_","349c63ec":"#### Univariate Exploration","f96c6f0a":"_Let's test what i call **\"Hidden NaNs\"**_","c2864433":"<a id='cleaning'><\/a>\n# Data Cleaning","113c3b19":"#### 4- Building our Models","f13cb6aa":"_Logistic Regression_","f7095753":"**Let's see if we can make it better and get higher precision...**","9b0ce3bb":"Overall check on columns","ff938e2e":"<a id='eda'><\/a>\n# Now it's time for some Exploration","6f54947e":"Let's drop \"Partner\" and \"Dependents\" columns","9b3d5995":"### First let's take a look at the data to know how to clean it","103eeecf":"#### Bivariate Exploration","89251c85":"<font color='green'>\n<h2><center> Now I think it is clean now :) <\/center><\/h2>","3a6c3c12":"Before deciding what to do...","f94c6dc0":"#### 2- Splitting the data to training and testing sets","81abeca7":"- **Note:** Why here we care about precision ?. Because if the model predicts that a client has left the company but he actually hasn't (FP), that is very bad for the company.","d73bc38b":"> It looks like that we have bad hidden NaNs in our dataset :). We will deal with them later.","d1c27c2a":"**Some Prunning**","7b2e42aa":"_Useless Columns_","5aebe666":"#### 1- First let's split the feature ( X ) from the target ( Y )","c1afd1a8":"> Overfitting again.","554af224":"## Final Touch","e529d83d":"<font color='green'>\nBest Random Forest","84f89e9c":"_SVM_","04a0d0ce":"#### Univariate Exploration","e81477f1":"### Services Features...","aff5f869":"<font color='blue'>\n    <h5> Some Helping Functions <\/h5>","c8686935":"#### Univariate Exploration ","22548035":"> we can see that there are 11 missing values in \"TotalCharges\" column ... Let's take a closer look at them.","319e225b":"<font color='green'>\n<h2><center> Hoooooraaaay, It is time for Modeling :) <\/center><\/h2>","5b588fb0":"**Test**"}}