{"cell_type":{"357bf3f8":"code","2bba2fc4":"code","2b7420b1":"code","3a852ef0":"code","c0171a94":"code","d8b1169d":"code","6351a242":"code","f6812ad3":"code","79e68172":"code","1b251d55":"code","0c02e035":"code","40707b02":"code","744393dd":"code","4704cdbe":"code","d6c083ff":"code","84b4fc8e":"code","f65601fb":"code","cfae933a":"code","fc7b7204":"code","0c3410ec":"code","7dcf6f67":"code","53fe9abc":"code","97ee731e":"code","2807fafb":"code","8086bdbb":"code","f86fb58b":"code","e05b894a":"code","8dc5a5f6":"markdown","276e5715":"markdown","bc5941dd":"markdown","2a38ad71":"markdown","30240c22":"markdown","438a0779":"markdown","f8896151":"markdown","f3033573":"markdown","bf6e4364":"markdown","23b8b9cb":"markdown","c97506c5":"markdown","24f868e0":"markdown","311b5400":"markdown","5d43324a":"markdown","84ef0d26":"markdown","ed39fd3d":"markdown","3988e6bf":"markdown","ebfb56e8":"markdown"},"source":{"357bf3f8":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport re\nimport json\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\nprint(\"Tensorflow version \" + tf.__version__)","2bba2fc4":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)","2b7420b1":"path = '\/kaggle\/input\/cassava-leaf-disease-classification\/'\nos.listdir(path+'test_tfrecords\/')","3a852ef0":"path_gcs = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')\nprint(path_gcs) ","c0171a94":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16*strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]","d8b1169d":"samp_subm = pd.read_csv(path+'sample_submission.csv')","6351a242":"with open(path+'label_num_to_disease_map.json') as json_file:\n    label_data = json.load(json_file)","f6812ad3":"label_data","79e68172":"train_filenames, val_filenames = train_test_split(tf.io.gfile.glob(path_gcs + '\/train_tfrecords\/*.tfrec'),\n                                                  test_size=0.20, random_state=2020)\ntest_filenames = tf.io.gfile.glob(path_gcs+'\/test_tfrecords\/*.tfrec')","1b251d55":"print('Number of train tfrec files:', len(train_filenames))\nprint('Number of val tfrec files:', len(val_filenames))\nprint('Number of test tfrec files:', len(test_filenames))","0c02e035":"raw_dataset = tf.data.TFRecordDataset(train_filenames)\n# for raw_record in raw_dataset.take(1):\n#   example = tf.train.Example()\n#   example.ParseFromString(raw_record.numpy())\n#   print(example.features)","40707b02":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [*IMAGE_SIZE])\n    image = tf.cast(image, tf.float32)\/255.\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\n\ndef read_tfrecord(example, labeled):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label #tf.one_hot(label, 5)\n    idnum = example['image_name']\n    return image, idnum\n\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False  # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(\n        filenames\n    )  # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(\n        ignore_order\n    )  # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(\n        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n    )\n    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n    return dataset\n\n\ndef get_dataset(filenames, labeled=True, ordered=False):\n    dataset = load_dataset(filenames, labeled=labeled, ordered=ordered)\n    dataset = dataset.shuffle(2020)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\n\ndef number_of_files(filenames):\n    \"\"\" Evaluate the number on files \"\"\"\n    \n    num = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(num)\n\n\ndef show_batch(image_batch, label_batch):\n    \"\"\" Plot 25 images of a batch \"\"\"\n    \n    plt.figure(figsize=(20, 20))\n    for n in range(25):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n])\n        plt.title(label_data[str(label_batch[n].numpy())])\n        plt.axis(\"off\")","744393dd":"print('Number Files train:', number_of_files(train_filenames))\nprint('Number Files train:', number_of_files(val_filenames))\nprint('Number Files test:', number_of_files(test_filenames))","4704cdbe":"train_dataset = get_dataset(train_filenames)\nval_dataset = get_dataset(val_filenames)\ntest_dataset = get_dataset(test_filenames, labeled=False, ordered=True)","d6c083ff":"print(train_dataset)\nprint(val_dataset)\nprint(test_dataset)","84b4fc8e":"image_batch, label_batch = next(iter(train_dataset))\nshow_batch(image_batch, label_batch)","f65601fb":"for image, idnum in test_dataset.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\n    print(idnum.numpy().astype('U'))","cfae933a":"initial_learning_rate = 1e-5\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=1000,\n    decay_rate=0.9\n)","fc7b7204":"weights='..\/input\/models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","0c3410ec":"def make_model():\n    base_model = tf.keras.applications.ResNet50(include_top=False,\n                     weights=weights,\n                     input_shape=(*IMAGE_SIZE, 3))\n    base_model.trainable = False\n\n    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n    x = tf.keras.applications.resnet50.preprocess_input(inputs)\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=['sparse_categorical_accuracy']\n    )\n\n    return model","7dcf6f67":"with strategy.scope():\n    model = make_model()\n    \nmodel.summary()","53fe9abc":"history = model.fit(\n    train_dataset,\n    epochs=5,\n    validation_data = val_dataset,\n)","97ee731e":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['sparse_categorical_accuracy']\nacc_val = history.history['val_sparse_categorical_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","2807fafb":"def to_float32(image, idnum):\n    return tf.cast(image, tf.float32), idnum\n\ntest_dataset = test_dataset.map(to_float32)\ntest_images = test_dataset.map(lambda image, idnum: image)","8086bdbb":"pred_propa = model.predict(test_images, verbose=1)\npreds = np.argmax(pred_propa, axis=-1)","f86fb58b":"samp_subm['label'] = preds\nsamp_subm.to_csv('submission.csv', index=False)","e05b894a":"samp_subm","8dc5a5f6":"# Motivation\nTFRecord files (.tfrec) are based on a binary format for storing sequences of values. The TFRecord format was developed by TensorFlow. The motivation of the development is to use Tensor Processing Units (TPUs) to accelerate the applications of machine learning applications.\n\nTo use the advantages of TPU you have to switch on your notebook:\n1. Klick on the notebook seetings (right upper corner of the notebook).\n2. Klick on \"Accelerator\".\n3. Choose TPU v3-8.\n![](https:\/\/i.ibb.co\/mHFPHpN\/setting.png)","276e5715":"# Set Up","bc5941dd":"# Analyse Results","2a38ad71":"We use the sparse_categorical_accuracy metric. So we have not to encode the 5 target labels.","30240c22":"# Functions\nTo handle tfrecord files we follow the instructions of this [tutorial](https:\/\/keras.io\/examples\/keras_recipes\/tfrecord\/).","438a0779":"# Key Names\nFirst we have to extract the features keys. To see the feature keys we have to execute the following code.\n\nThere are 3 feature keys for this dataset:\n1. image\n![](https:\/\/i.ibb.co\/8rHQQLs\/features-1.png)\n2. image_name\n![](https:\/\/i.ibb.co\/9HLzNf3\/features-2.png)\n3. target\n![](https:\/\/i.ibb.co\/r0ML4yZ\/features-3.png)","f8896151":"# Model","f3033573":"Predict test data:","bf6e4364":"# Predict Test Data","23b8b9cb":"Write output for submission:","c97506c5":"# Parameter","24f868e0":"# Show Examples","311b5400":"To create the GCS path we need internet access. So we can not use this notebook for submission because internet is forbidden for it.  ","5d43324a":"# Path","84ef0d26":"# Load Data","ed39fd3d":"# Intro\nWelcome to the [Cassava Leaf Disease Classification](https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification) competition.\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/13836\/logos\/header.png)\n\nThere are 5 classifications (click for further informations):\n* 0: [Cassava Bacterial Blight (CBB)](https:\/\/en.wikipedia.org\/wiki\/Bacterial_blight_of_cassava)\n* 1: [Cassava Brown Streak Disease (CBSD)](https:\/\/en.wikipedia.org\/wiki\/Cassava_brown_streak_virus_disease)\n* 2: [Cassava Green Mottle (CGM)](https:\/\/en.wikipedia.org\/wiki\/Cassava_green_mottle_virus)\n* 3: [Cassava Mosaic Disease (CMD)](https:\/\/en.wikipedia.org\/wiki\/Cassava_mosaic_virus)\n* 4: Healthy\"\n\nThe goal of this notebook is to give a short tutorial for the usage of TFRecords. We don't focus on optimization of the prediction model.\n\nFor a more general tutorial we recommend [this notebook](https:\/\/www.kaggle.com\/drcapa\/tutorial-tfrecords-create-and-read).\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","3988e6bf":"# Libraries","ebfb56e8":"Prepare data:"}}