{"cell_type":{"c56f5cff":"code","3bfbb984":"code","b34944cb":"code","0e5e9a22":"code","344ae7bf":"code","3afd6540":"code","05dd3e4d":"code","acfca3a6":"code","a0fb8344":"code","1db82d15":"code","5d8a3d6c":"code","704a649a":"code","1fd6e3b6":"code","dd74e552":"code","eae210af":"code","1b2d58f6":"code","e08100da":"code","0d6101de":"code","e2b1ae95":"code","b4006384":"code","1f46b688":"code","e18580bd":"code","8554aa51":"code","b5a377cc":"code","3812d7c1":"code","38e6f1a9":"code","5fddb618":"code","7ee591f5":"code","0949bd03":"code","fc5a4bbb":"code","1e69404d":"code","8e9ce7ba":"markdown","d48523ac":"markdown","c094c270":"markdown"},"source":{"c56f5cff":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.set_option(\"display.max_columns\", None)\n","3bfbb984":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv\")","b34944cb":"train_df.head(10)","0e5e9a22":"test_df.head(10)","344ae7bf":"train_df = train_df.drop([\"id\"], axis = 1)\ntest_df = test_df.drop([\"id\"], axis = 1)","3afd6540":"Summary = pd.DataFrame(train_df.dtypes, columns=[\"dtype\"])\nSummary[\"max\"] = train_df.max()\nSummary[\"min\"] = train_df.min()\nSummary[\"null\"] = train_df.isnull().sum()\nSummary[\"first\"] = train_df.iloc[0]\nSummary[\"second\"] = train_df.iloc[1]\nSummary[\"third\"] = train_df.iloc[2]\nSummary","05dd3e4d":"len(train_df) #300000","acfca3a6":"\ncm = train_df.corr()\nfig, ax = plt.subplots(figsize=(15,10))  \nsns.heatmap(cm, annot = True, vmin=-1, vmax=1, center= 0,cmap= 'coolwarm', ax = ax)","a0fb8344":"correlated_features = set()\nfor i in range(len(cm.columns)):\n    for j in range(i):\n        if abs(cm.iloc[i, j]) > 0.78:\n            colname = cm.columns[i]\n            print(colname)\n            correlated_features.add(colname)","1db82d15":"# # gettig rid of these features\n# train_df = train_df.drop(correlated_features, axis = 1)\n# test_df = test_df.drop(correlated_features, axis = 1)","5d8a3d6c":"y = train_df[\"target\"]\ntrain_df.drop([\"target\"], axis = 1, inplace = True)","704a649a":"# train_df[\"max\"] = train_df.max(axis = 1)\n# train_df[\"min\"] = train_df.min(axis = 1)\n# train_df[\"skew\"] = train_df.skew(axis = 1)\n# train_df[\"mean\"] = train_df.mean(axis = 1)\n# train_df[\"median\"] = train_df.median(axis = 1)","1fd6e3b6":"# test_df[\"max\"] = test_df.max(axis = 1)\n# test_df[\"min\"] = test_df.min(axis = 1)\n# test_df[\"skew\"] = test_df.skew(axis = 1)\n# test_df[\"mean\"] = test_df.mean(axis = 1)\n# test_df[\"median\"] = test_df.median(axis = 1)","dd74e552":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\n","eae210af":"len(train_df)","1b2d58f6":"X_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size = 0.2, random_state = 123)","e08100da":"# scaler = StandardScaler()\n# X_train = scaler.fit_transform(X_train)\n# X_test= scaler.transform(X_test)\n# test_df= scaler.transform(test_df)","0d6101de":"# lm = LinearRegression()\n# lm.fit(X_train, y_train)","e2b1ae95":"# y_pred = lm.predict(X_test)\n# loss = mean_squared_error(y_pred, y_test )","b4006384":"# np.sqrt(loss)\n# End goal\n# Trynna to reduce rmse.\n# 0.725037588861915 without doing anything\n# with more featues it did help  to a bit 0.7246819980764818\n# with scaling 0.7246819980764818, it did not help much 0.7246905107733411\n# withe removing correlated features, it did not help, 0.7250850271199127","1f46b688":"sub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2021\/sample_submission.csv\")","e18580bd":"# y_res = lm.predict(test_df)","8554aa51":"# rr = RandomForestRegressor()\n# rr.fit(X_train, y_train)\n# y_pred = rr.predict(X_test)","b5a377cc":"from xgboost import XGBRegressor","3812d7c1":"# XGB\n# model = XGBRegressor(objective='reg:squarederror',\n#                      booster = \"gbtree\",\n#                      eval_metric = \"rmse\",\n#                      tree_method = \"gpu_hist\",\n#                      n_estimators = 1000,\n#                      learning_rate = 0.04,\n#                      eta = 0.1,\n#                      max_depth = 7,\n#                      subsample=0.85,\n#                      colsample_bytree = 0.85,\n#                      colsample_bylevel = 0.8,\n#                      alpha = 0,\n#                      random_state = 2021)\n\n\nregressor =  XGBRegressor(\n                 objective='reg:squarederror',\n                 booster = \"gbtree\",\n                 eval_metric = \"rmse\",\n                 tree_method = \"gpu_hist\",\n                 colsample_bytree=0.5,\n                 alpha=0.01563,\n                 random_state=2021,\n                 #gamma=0.0,\n                 learning_rate=0.01,\n                 max_depth=15,\n                 min_child_weight=257,\n                 n_estimators=4000,                                                                  \n                 #reg_alpha=0.9,\n                 reg_lambda=0.003,\n                 subsample=0.7,\n                 metric_period=100,\n                 silent=1)\n\nregressor.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=1)","38e6f1a9":"# Fit mode\n# %time regressor.fit(X_train, y_train)","5fddb618":"y_val_pred = regressor.predict(X_test)\nprint('Validation Set RMSE:', np.sqrt(mean_squared_error(y_test, y_val_pred)))\n# gave the RMSE: 0.6978898866785791\n# gave the RMSE without extra features: 0.6973184362827547\n# gave the RMSE with hyperparameters tuned: 0.6958703143319863","7ee591f5":"y_res_xgb = regressor.predict(test_df)","0949bd03":"# loss = mean_squared_error(y_pred, y_test )\n# print(np.sqrt(loss))\n# # imporvement with evrerything: 0.7067061724711653 but the prvate score of 0.71153 which ain't that bad but it is still bad \n# y_res1 = rr.predict(test_df)","fc5a4bbb":"y_res_xgb # This made rank to reach in 500. Nice improvement","1e69404d":"sub[\"target\"] = y_res_xgb\nsub.to_csv(\"rc2.csv\", index=False)\n","8e9ce7ba":"There is not much diff in the max value and the min value so I do not think there is a need to scale","d48523ac":"So, there are few features and one target variable, of course ID is of not use so first lets get rid of it","c094c270":"### Adding more features"}}