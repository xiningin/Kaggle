{"cell_type":{"42a52375":"code","81f51f1f":"code","04541460":"code","942aa7ab":"code","b50ce10d":"code","9f81fc08":"code","5c4d87c6":"code","8490722b":"code","b7f39036":"code","985e305d":"code","f10cb323":"markdown","84f418fb":"markdown"},"source":{"42a52375":"#import basic libraries\nimport numpy as np\nimport pandas as pd","81f51f1f":"import keras","04541460":"#import all the essential packages from keras , required for CNN\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n\n\n\n","942aa7ab":"\nclassifier = Sequential()\n\nclassifier.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation = 'relu'))  # 32 is the number of feature detectors, and 3*3 window\n\nclassifier.add(MaxPooling2D(pool_size=(2,2)))    #size of the sub table ,min is considered = 2*2 \n\nclassifier.add(Flatten())       # flattens the sub table into a linear to be able to fed into training","b50ce10d":"classifier.add(Dense(128,activation = 'relu'))      # first and input layer\nclassifier.add(Dense(6,activation = 'softmax'))    #output layer, 6 is the no of output categories ","9f81fc08":"#compile the model\n\nclassifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n#sparse categorical bcz the output has multiple catgories","5c4d87c6":"#image data preprocessing \n\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2, #shaering transformation\n        zoom_range=0.2,       # zoom in required\n        horizontal_flip=True) #if the images data needs to be horizontally flipped, applicable for real world images\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255) #rescale the image if necessary (RGB coefficients normalize)\n\n","8490722b":"#creates the train set\n\ntrain_set = train_datagen.flow_from_directory(\"..\/input\/intel-image-classification\/seg_train\/seg_train\",\n        target_size=(64,64), #size of the image in the model \n        batch_size=32,\n        class_mode='sparse')\n","b7f39036":"#creates the test set\ntest_set = test_datagen.flow_from_directory(\n        '..\/input\/intel-image-classification\/seg_test\/seg_test',\n        target_size=(64,64),       #size of the image in the model\n        batch_size=32,\n        class_mode='binary')","985e305d":"#fit the model\n\nclassifier.fit_generator(train_set,\n                    steps_per_epoch=14034,     #number of images\n                    epochs=5,\n                    validation_data=test_set,\n                     validation_steps=3000)","f10cb323":"the dataset has images of forests,seas,buildings,glaciers,mountains and streets. this notebook attempts to predict them as a particular class\/category using CNN layers and keras image preprocessing","84f418fb":"**basic understanding about layers used **\n\nSequential:Sequential layer simply acts an inital layer, for the model layers to move in the particular sequence\n\nConvolution2D: it is the first layer of CNN. Convolution is a mathematical operation to merge two sets of information. In our case ,the input image and the feature detector ,are both merged to create a feature map. \n\nMaxPooling2D:maxpooling creates a maxpooling layer, the only argument is the window size.i have used the 3*3 window size.\n\nDense: layer used to add the fully connected layers to neural networks\n\nFlatten: After the convolution and pooling layers we flatten their output to feed into the neural networks\n\n"}}