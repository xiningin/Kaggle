{"cell_type":{"b4cccb94":"code","2b7bb834":"code","185b6134":"code","824ab0c3":"code","236497b9":"code","7b649a93":"code","a5c793df":"code","0a90531d":"code","6111e4a8":"code","f78d843c":"code","7a67f533":"code","b9d12efe":"code","696413cc":"code","26493bd5":"code","16f495a6":"code","15d116a5":"code","576168c6":"code","567f84a7":"code","f5615df2":"code","0026673b":"markdown","e9d43ca9":"markdown","16f78d12":"markdown","faf36a7d":"markdown","4889f7a8":"markdown","324c1da7":"markdown","d61387e1":"markdown","cae27208":"markdown","948664b9":"markdown","61049bce":"markdown","34c9f5bd":"markdown","ae1ad28b":"markdown","3855bf58":"markdown","9293fb07":"markdown","df09f884":"markdown","83fcc324":"markdown","ab033e19":"markdown","ef4ff37b":"markdown","23d694b1":"markdown","08be4607":"markdown","6b6e6edd":"markdown","f1020912":"markdown","7a017311":"markdown","cab1bf98":"markdown","ddc9b724":"markdown","3c97fb7c":"markdown","3a9c6c86":"markdown","055d877e":"markdown"},"source":{"b4cccb94":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import Lasso","2b7bb834":"train_images = pd.read_csv('..\/input\/volcanoes_train\/train_images.csv')\ntrain_labels = pd.read_csv('..\/input\/volcanoes_train\/train_labels.csv')\n\ntest_images = pd.read_csv('..\/input\/volcanoes_test\/test_images.csv')\ntest_labels = pd.read_csv('..\/input\/volcanoes_test\/test_labels.csv')","185b6134":"print(train_images.head())\nprint(train_labels.head())\n\nprint(test_images.head())\nprint(test_labels.head())","824ab0c3":"for x in range(10):\n    row = np.array(train_images.iloc[x])\n    image = row.reshape((110,110))\n    plt.figure()\n    plt.imshow(image,cmap=\"gray\")\n\nplt.show()","236497b9":"print(sum(train_images.isna().sum()))\nprint(sum(test_images.isna().sum()))\n\nprint(train_labels.isna().sum())\nprint(test_labels.isna().sum())","7b649a93":"print(train_labels.head())\nprint(test_labels.head())","a5c793df":"plt.hist(train_labels[\"Volcano?\"])\nplt.show()","0a90531d":"train_labels.fillna(value=0,inplace=True)\ntest_labels.fillna(value=0,inplace=True)","6111e4a8":"for x in train_labels.keys():\n    X = train_labels[x]\n    plt.figure()\n    plt.hist(X)\n    plt.xlabel(x)\n    plt.ylabel('frequency')\nplt.show()","f78d843c":"print(train_images.shape)\nprint(train_labels.shape)\n\nprint(test_images.shape)\nprint(test_labels.shape)","7a67f533":"print(train_images.head())\nprint(test_images.head())","b9d12efe":"columns = list(train_images.columns)\ncolumns = [float(x) for x in columns]\nfirst_row = np.round(columns).astype(np.int64)\n\nimage = first_row.reshape((110,110))\nplt.imshow(image,cmap=\"gray\")\n\ncolumns = list(test_images.columns)\ncolumns = [float(x) for x in columns]\nfirst_row = np.round(columns).astype(np.int64)\n\nimage = first_row.reshape((110,110))\nplt.figure()\nplt.imshow(image,cmap=\"gray\")\n\nplt.show()","696413cc":"columns = list(train_images.columns)\ncolumns = [float(x) for x in columns]\nfirst_row = np.round(columns).astype(np.int64)\n\ntrain_images.loc[-1] = first_row\ntrain_images.index += 1\ntrain_images.sort_index(inplace=True)\n\ncolumns = list(test_images.columns)\ncolumns = [float(x) for x in columns]\nfirst_row = np.round(columns).astype(np.int64)\n\ntest_images.loc[-1] = first_row\ntest_images.index += 1\ntest_images.sort_index(inplace=True)\n\nprint(train_images.shape)\nprint(train_labels.shape)\n\nprint(test_images.shape)\nprint(test_labels.shape)","26493bd5":"X_train = np.array(train_images)\ny_train = np.array(train_labels.drop(['Radius'],1))\n\nX_test = np.array(test_images)\ny_test = np.array(test_labels.drop(['Radius'],1))\n\nclf = DecisionTreeClassifier()\nclf.fit(X_train,y_train)\n\npred = clf.predict(X_test)\npredclf = pd.DataFrame(pred)\n\npredclf.columns = ['Volcano?','Type','Number Volcanoes']\n\nprint(predclf.head())","16f495a6":"new_train_data = train_images[(train_labels['Volcano?'] == 1)].join(train_labels[(train_labels['Volcano?'] == 1)].drop(['Radius','Volcano?'],1))\nnew_train_labels = train_labels['Radius'][(train_labels['Volcano?'] == 1)]\n\nnew_test_data = test_images[(predclf['Volcano?'] == 1)].join(predclf[(predclf['Volcano?'] == 1)].drop(['Volcano?'],1))\nnew_test_labels = test_labels['Radius'][(predclf['Volcano?'] == 1)]\n\nX_train = np.array(new_train_data)\ny_train = np.array(new_train_labels)\n\nX_test = np.array(new_test_data)\ny_test = np.array(new_test_labels)\n\nreg = Lasso()\nreg.fit(X_train,y_train)\n\npred = reg.predict(X_test)\npredreg = pd.DataFrame(pred)\n\npredreg.columns = ['Radius']\n\nprint(predreg.head())","15d116a5":"pred_radius = []\ny = 0\nfor x in range(predclf.shape[0]):\n    if predclf['Volcano?'].iloc[x] == 1.0:\n        pred_radius.append(predreg['Radius'].iloc[y])\n        y+=1\n    else:\n        pred_radius.append(0.)\n\npred_radius = pd.DataFrame({'Radius': pred_radius})\n\ntotal_pred = predclf.join(pred_radius)\n\nprint(total_pred.head())","576168c6":"cols = ['Volcano?','Type','Radius','Number Volcanoes']\ntotal_pred = total_pred[cols]\n\nprint(total_pred)","567f84a7":"for x in total_pred.keys():\n    X = total_pred[x]\n    plt.figure()\n    plt.hist(X)\n    plt.xlabel(x)\nplt.show()","f5615df2":"detected = test_images[(total_pred['Volcano?'] == 1)]\n\nfor x in range(detected.shape[0]):\n    image_flat = np.array(detected.iloc[x])\n    image = image_flat.reshape((110,110))\n\n    plt.figure()\n    plt.imshow(image,cmap='gray')\n    plt.title('Volcano '+str(x))\n\nplt.show()","0026673b":"<h3>2. Reading The Data:<\/h3>\n<p>This thing took forever because, the file sizes are well over <b>200MB<\/b>.<\/p>","e9d43ca9":"<h2>Overview:<\/h2>\n<ol>\n    <li>Importing The Libraries<\/li>\n    <li>Reading The Data<\/li>\n    <li>Handling Missing Data<\/li>\n    <li>Fixing The First Example Problem<\/li>\n    <li>Training To Classify<\/li>\n    <li>Training To Regress<\/li>\n    <li>Merging The Predictions<\/li>\n    <li>Visualising The Predicted Data<\/li>\n<\/ol>","16f78d12":"So, those were all the images my model thinks has volcanoes.\n\n<p>Thank you if you read all the way till here or even if you just scrolled to bottom.<\/p>\n<p>I apologise if my terrible humour bored you or distracted you, but anyways thank you for your time.<\/p>","faf36a7d":"Whoa. Okay, So, our images don't have any missing values but our labels seem to have a lot of them.\nLet's look at the head of our labels again.","4889f7a8":"<p>Those were the heads.<\/p>\n<p>Now enough looking at heads, let's use some matplotlib magic and look at some pictures from <b>SPACE!!!<\/b><\/p>","324c1da7":"There, fixed.","d61387e1":"So, now we have our predicted Volcano?, Type, Number Volcanoes which we will join to the test data and perform regression.","cae27208":"And, there are 6000 images with no volcanoes, which explains the 6000 Nan for each label.\n\nThe best way that I think of to handle this is fill the missing data with zeros as it seems kinda logical, no volcano means zero radius, zero number of volcanoes and zero Type maybe?\n\nLet's just go with it.","948664b9":"<h1><i>Finding Volcanoes On Venus<\/i><\/h1>","61049bce":"<h3>4. Fixing The First Example:<\/h3>\nLet me show you what I am talking about.","34c9f5bd":"<h3>1. Importing The Libraries:<\/h3>\n<p>Nothing special here, just some classic old importing.<\/p>","ae1ad28b":"<h3>7. Merging The Predictions:<\/h3>","3855bf58":"<h2>Introduction:<\/h2>\n<p>Using the dataset <a href=\"https:\/\/www.kaggle.com\/fmena14\/volcanoesvenus\">Volcanoes on Venus<\/a>, I will try to predict whether an image from Venus has a volcano in it or not.<\/p>\n<sub>wish me luck.<\/sub>","9293fb07":"Do you see what I'm seeing?\nThe columns of the data frame, look very similar to pixel values.\nLet's check our hypothesis.\n<p>We will take each column, turn it into a floating point and round it to an integer and plot  it.<\/p>","df09f884":"<h3>8. Visualising The Predicted Data:<\/h3>","83fcc324":"<b>Perfect!<\/b>\n<p>Let's look at what we've predicted.<\/p>","ab033e19":"<p>Now comes the interesting part, we will analyse the data and by analyse I mean just looking at it as the data is nothing but pixel values.<\/p>\n<p>But <i>first<\/i> let's look at some heads.<sub>(:P)<\/sub><\/p>","ef4ff37b":"There you have it, some nice graphs to look at.\n\nNow, for a really interesting problem I faced when analysing this data,  which left me scratching my head for hours.","23d694b1":"So, now we have all of our predicted classes, all we have to do is merge them.","08be4607":"Yup, my guess was correct, the hidden image was in the columns.\nNow, let's fix it.","6b6e6edd":"Everythings' looking good, except the order of the columns, so let's fix that.","f1020912":"<h3>5. Training To Classify:<\/h3>\n<p>Now to train this would be tricky, because the problem here is a combination of classification(Volcano?, Type, Number Volcanoes) and regression(Radius) so we have to split the problem into <b>two<\/b>.<\/p>\n<p>First we will train the decisiontree classifier because it supports multi label classification and then produce a list of predicted classes, which we will join to our test data and train the lasso algorithm to regress the radius given pixel values, type and number of volcanoes.<\/p>","7a017311":"There, fixed.\n<p>Now, to my favourite part.<\/p>","cab1bf98":"<p>Doesn't it feel exciting to work on images taken far beyond from where you currently are, like millions of kilometers.<\/p>\n<p>Unless you are orbiting Venus, then that's another thing.<\/p>","ddc9b724":"It seems the 'Type, Radius, Number Volcanoes' for images with no volcanoes have not been provided.","3c97fb7c":"<h3>3. Handling Missing Data:<\/h3>\n<p>So, now it's time to clean up our data.<\/p>\n<p>Nobody likes Nans.<\/p>\n<sub>except my actual nan i like her.<\/sub>","3a9c6c86":"<h3>6. Training To Regress:<\/h3>\n<p>First we will join the training data with the necessary training labels and do the same with testing data and train it all on the algorithm.<\/p>","055d877e":"There you see it!? we either have an extra label or a missing image.\nLet's investigate."}}