{"cell_type":{"097d68ee":"code","f0f6aa16":"code","3b8ee9f0":"code","367662b0":"code","c1e9775e":"code","a5093fe9":"code","67726844":"code","aa1f7dd0":"code","e45ccf4d":"code","7bf9c9b6":"code","d8352002":"code","3f187c09":"code","b2424176":"code","510e230b":"code","8912fad2":"code","f72a87cd":"code","f985a98d":"code","6eb007ac":"code","b9596f46":"code","4eb7b1ac":"code","106654b2":"code","b8ca1245":"code","6956ab74":"code","2a553a40":"code","bb100578":"code","c79a1ef0":"code","28b56272":"code","7da77aef":"code","d0a4ea5f":"code","9385b491":"code","abb36b1f":"code","e44b59d0":"code","2446f505":"code","a44ef24c":"code","68cc4eed":"code","20781744":"code","aec7efa4":"code","b41d49e7":"code","63d30818":"code","90323105":"markdown","9d3791b5":"markdown","37a5adaf":"markdown","787c4c67":"markdown","81382f03":"markdown","b8797e18":"markdown","dde7257e":"markdown","892ea768":"markdown","e9fe28bb":"markdown","55332d42":"markdown","1f1e8294":"markdown","ebcccdde":"markdown","899bc5de":"markdown"},"source":{"097d68ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0f6aa16":"train = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv', dtype={'Year': 'str','Week-Ending Date':'str'})\ntest = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv')","3b8ee9f0":"test.info()","367662b0":"train.info()","c1e9775e":"train['HHS Region'].unique()","a5093fe9":"train['HHS Region'].value_counts()","67726844":"test.info()","aa1f7dd0":"test['Year'].unique()","e45ccf4d":"test['HHS Region'].unique()","7bf9c9b6":"test['Group'].unique()","d8352002":"test['Week-Ending Date'].unique()\n","3f187c09":"test['MMWR Week'].unique()\n","b2424176":"\ntest['Race and Hispanic Origin Group'].unique()","510e230b":"\ntest['Age Group'].unique()","8912fad2":"train['Year'].unique()","f72a87cd":"yearsToReplace= {'2019\/2020':2020, '2020':2020, '2020\/2021':2020, '2021':2021}\ntrain['Year'].replace(yearsToReplace, inplace = True)\n\ntrain.drop('Footnote', axis = 1, inplace = True)\ntrain.drop(train[train['HHS Region']!='United States'].index, inplace = True)\ntrain.drop(train[train['Group']!='By Week'].index, inplace = True)\n\ntestIndex = test['id']\n\ndef cleanData(data):\n    ageGroups = {'0-4 years':1, '5-17 years':2, '18-29 years':3, '30-39 years':4,\n       '40-49 years':5, '50-64 years':6, '65-74 years':7, '75-84 years':8,\n       '85 years and over':9}\n    origingGroups = {'Hispanic':1, 'Non-Hispanic American Indian or Alaska Native':2,\n       'Non-Hispanic Asian':3, 'Non-Hispanic Black':4,\n       'Non-Hispanic More than one race':5,\n       'Non-Hispanic Native Hawaiian or Other Pacific Islander':6,\n       'Non-Hispanic White':7, 'Unknown':8}\n    \n    data['Age Group'].replace(ageGroups, inplace = True)\n    data['Race and Hispanic Origin Group'].replace(origingGroups, inplace = True)\n    \n    data.drop('HHS Region', axis = 1, inplace = True)\n    data.drop('Group', axis = 1, inplace = True)\n    data.drop('Total Deaths', axis = 1, inplace = True)\n    data.drop('Month', axis = 1, inplace = True)\n    data.drop('Data As Of', axis = 1, inplace = True)\n    data.drop('Start Date', axis = 1, inplace = True)\n    data.drop('End Date', axis = 1, inplace = True)\n    data.drop('Week-Ending Date', axis = 1, inplace = True)\n    data.drop('id', axis = 1, inplace = True)","f985a98d":"cleanData(train)\ncleanData(test)","6eb007ac":"train.info()\ntest.info()","b9596f46":"train.isna().sum()","4eb7b1ac":"train.describe()","106654b2":"import seaborn as sns\nsns.scatterplot(data = train, x= 'MMWR Week', y= 'COVID-19 Deaths')","b8ca1245":"sns.scatterplot(data = train, x= 'Year', y= 'COVID-19 Deaths')","6956ab74":"sns.scatterplot(data = train, x= 'Age Group', y= 'COVID-19 Deaths')","2a553a40":"sns.scatterplot(data = train, x= 'Race and Hispanic Origin Group', y= 'COVID-19 Deaths')","bb100578":"train['COVID-19 Deaths'].value_counts()","c79a1ef0":"from sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error as MSE\n\ntss = TimeSeriesSplit(n_splits= 69)\n\ny = train['COVID-19 Deaths']\nX = train.drop('COVID-19 Deaths', axis = 1)\n\ntrainX = X[:int(X.shape[0]*0.55)]\ntestX = X[int(X.shape[0]*0.55):]\ntrainy = y[:int(X.shape[0]*0.55)]\ntesty = y[int(X.shape[0]*0.55):]","28b56272":"from sklearn.linear_model import LinearRegression\n\nLinReg = LinearRegression().fit(trainX, trainy)\n\nLinSquareScores = - cross_val_score(LinReg, testX, testy, cv=tss, scoring = 'neg_mean_squared_error')\n\nLinRMSE = (LinSquareScores.mean())**(1\/2)\n\nprint(LinRMSE)\n","7da77aef":"print(\"Mean =\", np.mean(LinSquareScores))\nprint(\"Standard Deviation =\", np.std(LinSquareScores))\nprint(\"Minimum =\", np.min(LinSquareScores))\nprint(\"Median =\", np.median(LinSquareScores))\nprint(\"Maximum =\", np.max(LinSquareScores))","d0a4ea5f":"Linypred = LinReg.predict(trainX)\n\nLinRMSEpred = (MSE(trainy,Linypred))**(1\/2)\n\nprint(LinRMSEpred)","9385b491":"from sklearn.linear_model import Lasso\n\nLasReg = Lasso().fit(trainX, trainy)\n\nLasSquareScores = - cross_val_score(LasReg, testX, testy, cv=tss, scoring = 'neg_mean_squared_error')\n\nLasRMSE = (LasSquareScores.mean())**(1\/2)\n\nprint(LasRMSE)","abb36b1f":"print(\"Mean =\", np.mean(LasSquareScores))\nprint(\"Standard Deviation =\", np.std(LasSquareScores))\nprint(\"Minimum =\", np.min(LasSquareScores))\nprint(\"Median =\", np.median(LasSquareScores))\nprint(\"Maximum =\", np.max(LasSquareScores))","e44b59d0":"Lasypred = LasReg.predict(trainX)\n\nLasRMSEpred = (MSE(trainy,Lasypred))**(1\/2)\n\nprint(LasRMSEpred)","2446f505":"from sklearn.linear_model import Ridge\n\nRidReg = Ridge().fit(trainX, trainy)\n\nRidSquareScores = - cross_val_score(RidReg, testX, testy, cv=tss, scoring = 'neg_mean_squared_error')\n\nRidRMSE = (RidSquareScores.mean())**(1\/2)\n\nprint(RidRMSE)","a44ef24c":"print(\"Mean =\", np.mean(RidSquareScores))\nprint(\"Standard Deviation =\", np.std(RidSquareScores))\nprint(\"Minimum =\", np.min(RidSquareScores))\nprint(\"Median =\", np.median(RidSquareScores))\nprint(\"Maximum =\", np.max(RidSquareScores))","68cc4eed":"Ridypred = RidReg.predict(trainX)\n\nRidRMSEpred = (MSE(trainy,Ridypred))**(1\/2)\n\nprint(RidRMSEpred)","20781744":"from sklearn.linear_model import ElasticNet\n\nElnReg = ElasticNet(alpha = .5).fit(trainX, trainy)\n\nElnSquareScores = - cross_val_score(ElnReg, testX, testy, cv=tss, scoring = 'neg_mean_squared_error')\n\nprint(\"Mean =\", np.mean(ElnSquareScores))\nprint(\"Standard Deviation =\", np.std(ElnSquareScores))\nprint(\"Minimum =\", np.min(ElnSquareScores))\nprint(\"Median =\", np.median(ElnSquareScores))\nprint(\"Maximum =\", np.max(ElnSquareScores))\n","aec7efa4":"ElnRMSE = (ElnSquareScores.mean())**(1\/2)\n\nprint(ElnRMSE)","b41d49e7":"Elnypred = ElnReg.predict(trainX)\n\nElnRMSEpred = (MSE(trainy,Elnypred))**(1\/2)\n\nprint(ElnRMSEpred)","63d30818":"ypred = ElnReg.predict(test)\noutput = pd.DataFrame({'id': testIndex, 'COVID-19 Deaths': ypred})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\nprint(output)","90323105":"# Ordinary Least Squares\n>Regular Linear Regression","9d3791b5":"# Loading The Data","37a5adaf":"# Data transformation and Feature engineering","787c4c67":"Before looking at missing values or outliers, lets check the data","81382f03":"# Elastic Net Regression","b8797e18":"# Ridge Regression","dde7257e":"# Checking for missing data","892ea768":"# **Selecting The Best Model**","e9fe28bb":"The fact that all regions gave an equal count is suspicious, therefore I looked at the values of the data in excell.\n\nUpon looking at the data closely in Excel, I realized that the data of the United States was divided in the different regions, but we don't have a need for this.\n\nFurthermore, the assignment comand us to Analyze the data of the United States. This is the most literal definition of it","55332d42":"# Checking for outliers","1f1e8294":"# **Building the models**","ebcccdde":"# Lasso Regression\n> ","899bc5de":"Upon further inspection, we realize that we have two death values, total deaths, and covid deaths. We only care about covid deaths, and there is no way to predict the covid deaths form the total deaths with the information given. \n\nFootnote becomes useless given the cut of the regions. This is no problem, given that the footnotes did not give too much useful info.\n\nThe group columns divides the data into 3 copies of the same information. We are only going to base our model on the 'By Week' information. After droping the 2 other groups, we can also drop the group column altogether"}}