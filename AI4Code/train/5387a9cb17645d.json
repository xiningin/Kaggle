{"cell_type":{"91f7694b":"code","c295837a":"code","94aee6c8":"code","678a28d6":"code","a195f74d":"code","9b4e4aa8":"code","d9398f88":"code","dc70976b":"code","bca5fd95":"code","1b39c7e6":"code","e7f2d03a":"code","4ac3e6f6":"code","265f8925":"code","14c910f7":"markdown","0d12658b":"markdown","c40887eb":"markdown","8e91263b":"markdown"},"source":{"91f7694b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n","c295837a":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional","94aee6c8":"data_path = '..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv'\n\ndata = pd.read_csv(data_path)\ndata.head()","678a28d6":"data['Recommended IND']","a195f74d":"print(data.describe())\nprint(\"\\n \\n Shape of the data :\", data.shape)\nprint(\"\\n \\n The info of the data :\", data.info)","9b4e4aa8":"#Hyper parameters\n\n\nvocab_size = 10000\nembedding_dim = 16\nmax_length = 100\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\ntraining_size = 18000\n\n","d9398f88":"# convert df to list\n\nsentences = data['Review Text'].astype(str).str.lower().values.tolist()\nlabels = data['Recommended IND'].values.tolist()\n","dc70976b":"\ntraining_sentences = sentences[0:training_size]\ntesting_sentences = sentences[training_size:]\ntraining_labels = labels[0:training_size]\ntesting_labels = labels[training_size:]","bca5fd95":"tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\n\nword_index = tokenizer.word_index\n\ntraining_sequences = tokenizer.texts_to_sequences(training_sentences)\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","1b39c7e6":"\n# Need this block to get it to work with TensorFlow 2.x\nimport numpy as np\ntraining_padded = np.array(training_padded)\ntraining_labels = np.array(training_labels)\ntesting_padded = np.array(testing_padded)\ntesting_labels = np.array(testing_labels)","e7f2d03a":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    #tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Bidirectional(LSTM(16, return_sequences=True)),\n    tf.keras.layers.Bidirectional(LSTM(16)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nprint(model.summary())","4ac3e6f6":"num_epochs = 30\nhistory = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)","265f8925":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")\n","14c910f7":"###  Data Preprocessing\n\nHere we will be generating Text so the useful column for this project is \"Review Text\". We will be classifying positive or negative reviews based on the content of the review text. \nThe positive or negative review stored in \"Recommend IND\"\n","0d12658b":"### Modelling","c40887eb":"**The objective of this project is to classify positive or negative reviews based on the customer review column on the Women clothing datastore. Sentiment classification analysis has been done on this dataset.**","8e91263b":"### Dataset overview"}}