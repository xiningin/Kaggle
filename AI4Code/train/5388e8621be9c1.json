{"cell_type":{"8ab213a5":"code","b3630a08":"code","309e416e":"code","bc532300":"code","aeff0468":"code","ebc8401d":"code","96f68326":"code","029188d4":"code","f1b74710":"code","9b5b874e":"code","5cb77234":"code","07c5084c":"code","a7ca6c5d":"code","539fa66c":"code","9db9db4a":"code","b8acb71e":"code","0c6a1ae9":"code","b2872989":"code","d854e166":"code","8075c66a":"code","a4e10859":"code","34c93eed":"code","223d11e9":"code","003a0054":"code","4e2af69a":"code","e9fcfa78":"code","74eb5f94":"code","a76be397":"code","f0bd61a7":"code","d625e201":"code","6723312c":"code","4d282dc4":"code","daa5fada":"code","b0569cc2":"code","544a26aa":"code","3009b068":"code","1fb500bf":"code","d6850c37":"code","990ecbf3":"code","7aa2fcaa":"code","578fb7dd":"code","7a2aa65b":"code","e5d02475":"code","b90a7123":"code","235894fc":"code","65840885":"code","8b8662c6":"markdown","46645006":"markdown","1faff853":"markdown","ce60dd58":"markdown","96cf702f":"markdown","edb00ad8":"markdown","b53a7e2b":"markdown","e3f35964":"markdown","417ca6c1":"markdown","fefec632":"markdown","60ddfaa7":"markdown","9d50af97":"markdown","b53da302":"markdown","0550f05d":"markdown","d0550346":"markdown","0c159a24":"markdown","e2d769ca":"markdown","2d0a3cd8":"markdown","79804767":"markdown","712dd465":"markdown","246caaf9":"markdown","1f8ab752":"markdown","ae5d8c50":"markdown","0bdeed12":"markdown","8aa41439":"markdown","0e94e7a8":"markdown","1a54b938":"markdown","ef6c0ed0":"markdown","bdc75d88":"markdown","f7cfbe3f":"markdown","dbf6d685":"markdown","c6d02808":"markdown","5aa228c5":"markdown","10263013":"markdown","3eda80ed":"markdown"},"source":{"8ab213a5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nsns.set()\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n","b3630a08":"train_labels = pd.read_csv(\"..\/input\/hpa-single-cell-image-classification\/train.csv\")\ntrain_labels.head()\n","309e416e":"train_labels.shape[0]","bc532300":"test_path = \"..\/input\/human-protein-atlas-image-classification\/test\/\"\n","aeff0468":"submission = pd.read_csv(\"..\/input\/hpa-single-cell-image-classification\/sample_submission.csv\")\nsubmission.head()\n","ebc8401d":"test_names = submission.ID.values\nprint(len(test_names))\nprint(len(test_names[0]))","96f68326":"label_names = {\n    0: \"Nucleoplasm\",\n    1: \"Nuclear_membrane\",\n    2: \"Nucleoli\",\n    3: \"Nucleoli_fibrillar_center\",\n    4: \"Nuclear_speckles\",\n    5: \"Nuclear_bodies\",\n    6: \"Endoplasmic_reticulum\",\n    7: \"Golgi_apparatus\",\n    8: \"Intermediate_filaments\",\n    9: \"Actin filaments\",\n    10: \"Microtubules\",\n    11: \"Mitotic_spindle\",\n    12: \"Centrosome\",\n    13: \"Plasma_membrane\",\n    14: \"Mitochondria\",\n    15: \"Aggresome\",\n    16: \"Cytosol\",\n    17: \"Vesicles_and_punctate_cytosolic_patterns\",\n    18: \"Negative\"\n}\n\nreverse_train_labels = dict((v,k) for k,v in label_names.items())\n\ndef fill_targets(row):   \n    row.Label = np.array(row.Label.split(\"|\")).astype(np.int)\n    for num in row.Label:\n        name = label_names[int(num)]\n        row.loc[name] = 1\n    return row","029188d4":"for key in label_names.keys():\n    train_labels[label_names[key]] = 0","f1b74710":"train_labels = train_labels.apply(fill_targets, axis=1)\n","9b5b874e":"train_labels.head(1)","5cb77234":"test_labels = pd.DataFrame(data=test_names, columns=['ID'])\nfor col in train_labels.columns.values:\n    if col != \"ID\":\n        test_labels[col] = 0\ntest_labels.head(1)","07c5084c":"target_count = train_labels.drop(['ID', 'Label'], axis = 1).sum(axis=0).sort_values(ascending=False)\nplt.figure(figsize=(15,15))\nsns.barplot(y=target_count.index.values, x = target_count.values, order=target_count.index)","a7ca6c5d":"train_labels['number_of_targets'] = train_labels.drop([\"ID\",\"Label\"], axis = 1).sum(axis = 1)\n\ncount_prec = np.round(100*train_labels['number_of_targets'].value_counts()\/train_labels.shape[0], 2)\nplt.figure(figsize=(20,5))\nsns.barplot(x= count_prec.index.values, y = count_prec.values, palette = \"Reds\")\nplt.xlabel(\"Number of targets per image\")\nplt.ylabel(\"% of train data\")","539fa66c":"\nplt.figure(figsize=(15,15))\nsns.heatmap(train_labels[train_labels.number_of_targets>1].drop(\n    [\"ID\", \"Label\", \"number_of_targets\"],axis=1\n).corr(), cmap=\"RdYlBu\", vmin=-1, vmax=1)","9db9db4a":"from os import listdir\nfiles = listdir(\"..\/input\/hpa-single-cell-image-classification\/train\")\nfor n in range(10):\n    print(files[n])","b8acb71e":"len(files)\/4 == train_labels.shape[0]","0c6a1ae9":"train_path = \"..\/input\/hpa-single-cell-image-classification\/train\/\"","b2872989":"def load_image(basepath, image_id):\n    images = np.zeros(shape=(4,512,512))\n    images[0,:,:] = imread(basepath + image_id + \"_green\" + \".png\")\n    images[1,:,:] = imread(basepath + image_id + \"_red\" + \".png\")\n    images[2,:,:] = imread(basepath + image_id + \"_blue\" + \".png\")\n    images[3,:,:] = imread(basepath + image_id + \"_yellow\" + \".png\")\n    return images\n\ndef make_image_row(image, subax, title):\n    subax[0].imshow(image[0], cmap=\"Greens\")\n    subax[1].imshow(image[1], cmap=\"Reds\")\n    subax[1].set_title(\"stained microtubules\")\n    subax[2].imshow(image[2], cmap=\"Blues\")\n    subax[2].set_title(\"stained nucleus\")\n    subax[3].imshow(image[3], cmap=\"Oranges\")\n    subax[3].set_title(\"stained endoplasmatic reticulum\")\n    subax[0].set_title(title)\n    return subax\n\ndef make_title(file_id):\n    file_targets = train_labels.loc[train_labels.Id==file_id, \"Target\"].values[0]\n    title = \" - \"\n    for n in file_targets:\n        title += label_names[n] + \" - \"\n    return title","d854e166":"class TargetGroupIterator:\n    \n    def __init__(self, target_names, batch_size, basepath):\n        self.target_names = target_names\n        self.target_list = [reverse_train_labels[key] for key in target_names]\n        self.batch_shape = (batch_size, 4, 512, 512)\n        self.basepath = basepath\n    \n    def find_matching_data_entries(self):\n        train_labels[\"check_col\"] = train_labels.Label.apply(\n            lambda l: self.check_subset(l)\n        )\n        self.images_identifier = train_labels[train_labels.check_col==1].ID.values\n        train_labels.drop(\"check_col\", axis=1, inplace=True)\n    \n    def check_subset(self, targets):\n        return np.where(set(targets).issubset(set(self.target_list)), 1, 0)\n    \n    def get_loader(self):\n        filenames = []\n        idx = 0\n        images = np.zeros(self.batch_shape)\n        for image_id in self.images_identifier:\n            images[idx,:,:,:] = load_image(self.basepath, image_id)\n            filenames.append(image_id)\n            idx += 1\n            if idx == self.batch_shape[0]:\n                yield filenames, images\n                filenames = []\n                images = np.zeros(self.batch_shape)\n                idx = 0\n        if idx > 0:\n            yield filenames, images\n    ","8075c66a":"train_labels.head(1)","a4e10859":"\nyour_choice = [\"Nucleoplasm\", \"Nuclear_bodies\"]\nyour_batch_size = 20","34c93eed":"imageloader = TargetGroupIterator(your_choice, your_batch_size, train_path)\nimageloader.find_matching_data_entries()\niterator = imageloader.get_loader()","223d11e9":"train_files = \"..\/input\/hpa-single-cell-image-classification\/train\/\"\ntest_files = \"..\/input\/hpa-single-cell-image-classification\/test\/\"\npercentage = np.round(len(test_files)\/len(train_files)*100)\nprint(\"The test size turn out to be {} % compared to the trainset.\".format(percentage))","003a0054":"from sklearn.model_selection import RepeatedKFold\nsplitter = RepeatedKFold(n_splits=5,n_repeats=1, random_state=0)","4e2af69a":"partitions = []\n\nfor train_idx,  test_idx in splitter.split(train_labels.index):\n    partition = {}\n    partition[\"train\"] = train_labels.ID.values[train_idx]\n    partition[\"validation\"] = train_labels.ID.values[test_idx]\n    partitions.append(partition)\n    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n    print(\"TRAIN:\", len(train_idx), \"TEST:\", len(test_idx))","e9fcfa78":"class ModelParameter:\n    \n    def __init__(self, basepath,\n                 num_classes=28,\n                 image_rows=512,\n                 image_cols=512,\n                 batch_size=200,\n                 n_channels=1,\n                 row_scale_factor=4,\n                 col_scale_factor=4,\n                 shuffle=False,\n                 n_epochs=1):\n        self.basepath = basepath\n        self.num_classes = num_classes\n        self.image_rows = image_rows\n        self.image_cols = image_cols\n        self.batch_size = batch_size\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.row_scale_factor = row_scale_factor\n        self.col_scale_factor = col_scale_factor\n        self.scaled_row_dim = np.int(self.image_rows \/ self.row_scale_factor)\n        self.scaled_col_dim = np.int(self.image_cols \/ self.col_scale_factor)\n        self.n_epochs = n_epochs","74eb5f94":"parameters = ModelParameter(train_path)","a76be397":"from skimage.transform import resize\n\nclass ImagePreprocessor:\n    \n    def __init__(self, modelparameter):\n        self.parameter = modelparameter\n        self.basepath = self.parameter.basepath\n        self.scaled_row_dim = self.parameter.scaled_row_dim\n        self.scaled_col_dim = self.parameter.scaled_col_dim\n        self.n_channels = self.parameter.n_channels\n    \n    def preprocess(self, image):\n        image = self.resize(image)\n        image = self.reshape(image)\n        image = self.normalize(image)\n        return image\n    \n    def resize(self, image):\n        image = resize(image, (self.scaled_row_dim, self.scaled_col_dim))\n        return image\n    \n    def reshape(self, image):\n        image = np.reshape(image, (image.shape[0], image.shape[1], self.n_channels))\n        return image\n    \n    def normalize(self, image):\n        image \/= 255 \n        return image\n    \n    def load_image(self, image_id):\n        image = np.zeros(shape=(512,512,4))\n        image[:,:,0] = imread(self.basepath + image_id + \"_green\" + \".png\")\n        image[:,:,1] = imread(self.basepath + image_id + \"_blue\" + \".png\")\n        image[:,:,2] = imread(self.basepath + image_id + \"_red\" + \".png\")\n        image[:,:,3] = imread(self.basepath + image_id + \"_yellow\" + \".png\")\n        return image[:,:,0:self.parameter.n_channels]\n        ","f0bd61a7":"preprocessor = ImagePreprocessor(parameters)","d625e201":"import keras\n\nclass DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self, list_IDs, labels, modelparameter, imagepreprocessor):\n        self.current_epoch = 0\n        self.params = modelparameter\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.dim = (self.params.scaled_row_dim, self.params.scaled_col_dim)\n        self.batch_size = self.params.batch_size\n        self.n_channels = self.params.n_channels\n        self.num_classes = self.params.num_classes\n        self.shuffle = self.params.shuffle\n        self.preprocessor = imagepreprocessor\n        self.on_epoch_end()\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes, random_state=self.current_epoch)\n            self.current_epoch += 1\n    \n    def get_targets_per_image(self, identifier):\n        return self.labels.loc[self.labels.Id==identifier].drop(\n                [\"Id\", \"Target\", \"number_of_targets\"], axis=1).values\n            \n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size, self.num_classes), dtype=int)\n        # Generate data\n        for i, identifier in enumerate(list_IDs_temp):\n            # Store sample\n            image = self.preprocessor.load_image(identifier)\n            image = self.preprocessor.preprocess(image)\n            X[i] = image\n            # Store class\n            y[i] = self.get_targets_per_image(identifier)\n        return X, y\n    \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y","6723312c":"class PredictGenerator:\n    \n    def __init__(self, predict_Ids, imagepreprocessor, predict_path):\n        self.preprocessor = imagepreprocessor\n        self.preprocessor.basepath = predict_path\n        self.identifiers = predict_Ids\n    \n    def predict(self, model):\n        y = np.empty(shape=(len(self.identifiers), self.preprocessor.parameter.num_classes))\n        for n in range(len(self.identifiers)):\n            image = self.preprocessor.load_image(self.identifiers[n])\n            image = self.preprocessor.preprocess(image)\n            image = image.reshape((1, *image.shape))\n            y[n] = model.predict(image)\n        return y","4d282dc4":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.losses import binary_crossentropy\nfrom keras.optimizers import Adadelta\nfrom keras.initializers import VarianceScaling\n\n\nclass BaseLineModel:\n    \n    def __init__(self, modelparameter):\n        self.params = modelparameter\n        self.num_classes = self.params.num_classes\n        self.img_rows = self.params.scaled_row_dim\n        self.img_cols = self.params.scaled_col_dim\n        self.n_channels = self.params.n_channels\n        self.input_shape = (self.img_rows, self.img_cols, self.n_channels)\n        self.my_metrics = ['accuracy']\n    \n    def build_model(self):\n        self.model = Sequential()\n        self.model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=self.input_shape,\n                             kernel_initializer=VarianceScaling(seed=0)))\n        self.model.add(Conv2D(32, (3, 3), activation='relu',\n                             kernel_initializer=VarianceScaling(seed=0)))\n        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n        self.model.add(Dropout(0.25))\n        self.model.add(Flatten())\n        self.model.add(Dense(64, activation='relu',\n                            kernel_initializer=VarianceScaling(seed=0),))\n        self.model.add(Dropout(0.5))\n        self.model.add(Dense(self.num_classes, activation='sigmoid'))\n    \n    def compile_model(self):\n        self.model.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=self.my_metrics)\n    \n    def set_generators(self, train_generator, validation_generator):\n        self.training_generator = train_generator\n        self.validation_generator = validation_generator\n    \n    def learn(self):\n        return self.model.fit_generator(generator=self.training_generator,\n                    validation_data=self.validation_generator,\n                    epochs=self.params.n_epochs, \n                    use_multiprocessing=True,\n                    workers=8)\n    \n    def score(self):\n        return self.model.evaluate_generator(generator=self.validation_generator,\n                                      use_multiprocessing=True, \n                                      workers=8)\n    \n    def predict(self, predict_generator):\n        y = predict_generator.predict(self.model)\n        return y\n    \n    def save(self, modeloutputpath):\n        self.model.save(modeloutputpath)\n    \n    def load(self, modelinputpath):\n        self.model = load_model(modelinputpath)","daa5fada":"# Datasets\npartition = partitions[0]\nlabels = train_labels\n\nprint(\"Number of samples in train: {}\".format(len(partition[\"train\"])))\nprint(\"Number of samples in validation: {}\".format(len(partition[\"validation\"])))","b0569cc2":"training_generator = DataGenerator(partition['train'], labels, parameters, preprocessor)\nvalidation_generator = DataGenerator(partition['validation'], labels, parameters, preprocessor)","544a26aa":"predict_generator = PredictGenerator(partition['validation'], preprocessor, train_path)","3009b068":"test_preprocessor = ImagePreprocessor(parameters)\nsubmission_predict_generator = PredictGenerator(test_names, test_preprocessor, test_path)","1fb500bf":"class KernelSettings:\n    \n    def __init__(self, fit_baseline=False,\n                 fit_improved_baseline=True,\n                 fit_improved_higher_batchsize=False,\n                 fit_improved_without_dropout=False):\n        self.fit_baseline = fit_baseline\n        self.fit_improved_baseline = fit_improved_baseline\n        self.fit_improved_higher_batchsize = fit_improved_higher_batchsize\n        self.fit_improved_without_dropout = fit_improved_without_dropout","d6850c37":"kernelsettings = KernelSettings(fit_baseline=False,\n                                fit_improved_baseline=False,\n                                fit_improved_higher_batchsize=False,\n                                fit_improved_without_dropout=False)","990ecbf3":"# Run computation and store results as csv\ntarget_names = train_labels.drop([\"Label\", \"number_of_targets\", \"ID\"], axis=1).columns\n\nif kernelsettings.fit_baseline == True:\n    model = BaseLineModel(parameter)\n    model.build_model()\n    model.compile_model()\n    model.set_generators(training_generator, validation_generator)\n    history = model.learn()\n    \n    proba_predictions = model.predict(predict_generator)\n    baseline_proba_predictions = pd.DataFrame(index = partition['validation'],\n                                              data=proba_predictions,\n                                              columns=target_names)\n    baseline_proba_predictions.to_csv(\"baseline_predictions.csv\")\n    baseline_losses = pd.DataFrame(history.history[\"loss\"], columns=[\"train_loss\"])\n    baseline_losses[\"val_loss\"] = history.history[\"val_loss\"]\n    baseline_losses.to_csv(\"baseline_losses.csv\")\n    \n    \n    submission_proba_predictions = model.predict(submission_predict_generator)\n    baseline_labels = test_labels.copy()\n    baseline_labels.loc[:, test_labels.drop([\"ID\", \"Label\"], axis=1).columns.values] = submission_proba_predictions\n    baseline_labels.to_csv(\"baseline_submission_proba.csv\")\n# If you already have done a baseline fit once, \n# you can load predictions as csv and further fitting is not neccessary:\nelse:\n    baseline_proba_predictions = pd.read_csv(\"..\/input\/protein-atlas-eab-predictions\/baseline_predictions.csv\", index_col=0)\n    baseline_losses = pd.read_csv(\"..\/input\/protein-atlas-eab-predictions\/baseline_losses.csv\", index_col=0)\n    baseline_labels = pd.read_csv(\"..\/input\/protein-atlas-eab-predictions\/baseline_submission_proba.csv\", index_col=0)","7aa2fcaa":"validation_labels = train_labels.loc[train_labels.ID.isin(partition[\"validation\"])].copy()\nvalidation_labels.shape","578fb7dd":"baseline_proba_predictions.shape","7a2aa65b":"y_pred","e5d02475":"from sklearn.metrics import accuracy_score as accuracy\n\ny_true = validation_labels.drop([\"ID\", \"Label\", \"number_of_targets\"], axis=1).values\ny_pred = np.where(baseline_proba_predictions.values > 0.5, 1, 0)\n\naccuracy(y_true.flatten(), y_pred.flatten())","b90a7123":"y_pred[0]","235894fc":"y_true[0]","65840885":"proba_predictions = baseline_proba_predictions.values\nhot_values = validation_labels.drop([\"ID\", \"Label\", \"number_of_targets\"], axis=1).values.flatten()\none_hot = (hot_values.sum()) \/ hot_values.shape[0] * 100\nzero_hot = (hot_values.shape[0] - hot_values.sum()) \/ hot_values.shape[0] * 100\n\nfig, ax = plt.subplots(1,2, figsize=(20,5))\nsns.distplot(proba_predictions.flatten() * 100, color=\"DodgerBlue\", ax=ax[0])\nax[0].set_xlabel(\"Probability in %\")\nax[0].set_ylabel(\"Density\")\nax[0].set_title(\"Predicted probabilities\")\nsns.barplot(x=[\"label = 0\", \"label = 1\"], y=[zero_hot, one_hot], ax=ax[1])\nax[1].set_ylim([0,100])\nax[1].set_title(\"True target label count\")\nax[1].set_ylabel(\"Percentage\");","8b8662c6":"# How many targets are most common?","46645006":"Thanks","1faff853":"# Building a baseline model <a class=\"anchor\" id=\"baseline\"><\/a>","ce60dd58":"Let's check if the number of files divided by 4 yields the number of target samples","96cf702f":"# How do images of specific targets looks like.?","edb00ad8":"**Take-away**\n* Most train images only have 1 or two target labels.\n* More than 3 targets are very seldom!","b53a7e2b":"### K-Fold Cross-Validation","e3f35964":"# #Helper Code","417ca6c1":"### Image Preprocessor\n\nLet's write a simple image preprocessor that handles for example the rescaling of the images. Perhaps we can expand its functionality during improvement of the baseline model. ","fefec632":"# Which targets are correlated?","60ddfaa7":"# Exploratory data analysis \n","9d50af97":"# Next Version comeing up with more details EDA and baseline.\n****\n# Please Upvote","b53da302":"Ok, currently we haven't made any predictions and except from Id all entries are filled with 0.\n","0550f05d":"Let's try to visualize specific target groups. In this example we will see images that contain the protein structures lysosomes or endosomes. Set target values of your choice and the target group iterator will collect all images that are subset of your choice:","d0550346":"\n# How do the images look like?\n","0c159a24":"To understand the performance of our model we will use k-fold cross validation. The train data is splitted into k chunks and each chunk is used once for testing the prediction performance whereas the others are used for training. ","e2d769ca":"# #Load dataset","2d0a3cd8":"Let's create an instance of this preprocessor and pass it to the data generator.","79804767":"Ok, now we will create an instance of this class and pass it to the DataGenerator, the BaseLineModel and the ImagePreprocessor.","712dd465":"**Peek into the directory**\n\n* Before we start loading images, let's have a look into the train directory to get an impression of what we can find there:","246caaf9":"# #How many samples do we have","1f8ab752":"# Which protiens occur most often in train images","ae5d8c50":"**Ah, ok, great! It seems that for one image id, there are different color channels present. Looking into the data description of this competition we can find that:**\n\n* Each image is actually splitted into 4 different image files.\n* These 4 files correspond to 4 different filter:\n 1.  a green filter for the target protein structure of interest\n 2. blue landmark filter for the nucleus\n 3. red landmark filter for microtubules\n 4. yellow landmark filter for the endoplasmatic reticulum\n* Each image is of size 512 x 512","0bdeed12":"Next we need to setup a simple baseline model. This need not be very complex or very good. Its our first attempt to play with and to figure out how to improve. For this purpose let's use the deep learning library keras.","8aa41439":"Let's see how many test and train samples we have in this competition:","0e94e7a8":"# #Extract test names for submission\n","1a54b938":"**Take-Away**\n* We can see that most common protein structures belong to coarse grained cellular components like the plasma membrane, the cytosol and the nucleus.\n\n* Consequently accuracy is not the right score here to measure your performance and validation strategy should be very fine.","ef6c0ed0":"### Shared Parameter class","bdc75d88":" ok, great now we can directly work with binary targets values, Lets create a dataframe for the test ids as well that we will use later to make our submission","f7cfbe3f":"Let's see if we find some correlations between our targets. This way we may already see that some proteins often come together.","dbf6d685":"# #Loading packages and data","c6d02808":"**Take-away**\n* We can see that many targets only have very slight correlations.\n","5aa228c5":"# #There are 559 test images we are asked to make predictions.","10263013":"To keep the kernel dense, the target group iterator has a batch size which stands for the number of examples you like to look at once. In this example you can see a maximum amount of 3 images at one iteration. To observe the next 3 examples of your target group, just run the cell below again. This way you can run the cell until you have seen all images of your group without polluting the kernel:","3eda80ed":"#### Looking at a preprocessed example image"}}