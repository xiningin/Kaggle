{"cell_type":{"6c298d75":"code","ca8e9bf3":"code","1795dd46":"code","d9e5ee40":"code","c9bc4e69":"code","d670ee86":"code","48e9cd3f":"code","6b2b1805":"code","e6bedcce":"code","a326a422":"code","c21088f2":"code","d181faf9":"code","ec1689df":"code","eff7a708":"code","14e1a100":"code","d0be4117":"code","dec2ba19":"code","e3eb435e":"code","f6f745fd":"code","b0b6893b":"code","e330f156":"code","eb0eec3f":"code","102dc565":"code","9c3269e0":"code","64ae8c6d":"code","2451d734":"code","d3e9ec2b":"code","1e69aa40":"code","91405f93":"code","fad7da54":"code","85dca8d7":"code","15864bdd":"code","322e4216":"code","ad4cfbd4":"code","23746d11":"code","4dfd6b3c":"code","2e9b2d74":"code","3e6ad119":"code","8f156588":"code","639365d0":"code","001bc3ef":"code","5b0eda03":"code","a068d9fb":"code","0b6ba269":"code","4360eb75":"code","49f9b219":"code","4ddfe336":"code","2c23e674":"code","7a12631b":"code","841d86ff":"code","3660f5e7":"code","33888428":"code","3e3069f1":"code","f533af2f":"code","68370feb":"code","8ce7abbc":"code","fa31c65a":"code","6aa5254c":"code","d84258d3":"code","aada25cf":"code","e5f7263b":"code","d1d1ea4b":"code","e45c49f4":"code","30059fcf":"code","1e6878c9":"code","4c3515f9":"code","f7710c80":"code","ee584d0f":"code","fd7f6f48":"code","9a31123c":"code","86e96876":"code","d4ac786c":"code","a5a84537":"code","131dac52":"code","7b948d01":"code","47dca235":"code","abff59d4":"code","e38c96d1":"code","e9a949a6":"code","69e1dedf":"code","9883f323":"code","57299926":"code","1082eab4":"code","463993f2":"code","ed58f7cb":"code","7357d9b7":"code","93afc670":"code","01b8762e":"code","f72bbd0d":"code","40bc8dc2":"code","fbce8029":"markdown","3c3fdf72":"markdown","920d8685":"markdown","3528d1c3":"markdown","57b03bd8":"markdown","ce6948ae":"markdown","3fa52511":"markdown","9dc0940c":"markdown","3750c48e":"markdown","e9a423aa":"markdown","feee50e4":"markdown","e4c41933":"markdown","19101058":"markdown","1dfcfefc":"markdown","3f9de44f":"markdown","2a7fa71a":"markdown","4d9e5a01":"markdown","09676cbe":"markdown","dd3649fb":"markdown","45829b44":"markdown","51905af0":"markdown","daa90969":"markdown","92f3cbca":"markdown","c0fc4ce9":"markdown","97e66b09":"markdown","fc9a5bf7":"markdown","d40059ff":"markdown","33712a38":"markdown","ed991e06":"markdown","802767c0":"markdown","7ce0ac28":"markdown","4aaa5581":"markdown","1d4d4ca1":"markdown","ff30104e":"markdown","76523064":"markdown","ae8ca817":"markdown","4f64497d":"markdown","d4ae3977":"markdown","876853b7":"markdown","8b74caee":"markdown","5c5c841e":"markdown","d054e299":"markdown","f99e33f2":"markdown","e24d6895":"markdown","23cb965d":"markdown","78000659":"markdown","ab54670c":"markdown","5de7ed86":"markdown"},"source":{"6c298d75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca8e9bf3":"train_df = pd.read_csv (\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv (\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","1795dd46":"train_df.columns","d9e5ee40":"train_df.head()","c9bc4e69":"train_df.describe()","d670ee86":"train_df.info()","48e9cd3f":"def bar_plot(variable):\n    \n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show\n    \n    print(\"{}: \\n{}\".format(variable,varValue))","6b2b1805":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\n\nfor c in category1:\n    bar_plot(c)","e6bedcce":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\n\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","a326a422":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins=50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","c21088f2":"numericVar = [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","d181faf9":"# Pclass - Survived\n\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","ec1689df":"# Sex - Survived\n\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","eff7a708":"# SibSp - Survived\n\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","14e1a100":"# Parch - Survived\n\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","d0be4117":"# Embarked - Survived\n\ntrain_df[[\"Embarked\",\"Survived\"]].groupby([\"Embarked\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","dec2ba19":"# Embarked - Pclass\n\ntrain_df[[\"Embarked\",\"Pclass\"]].groupby([\"Embarked\"], as_index = False).mean().sort_values(by = \"Pclass\", ascending = False)","e3eb435e":"# Pclass - Fare\n\ntrain_df[[\"Pclass\",\"Fare\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Fare\", ascending = False)","f6f745fd":"# Embarked - Fare\n\ntrain_df[[\"Embarked\",\"Fare\"]].groupby([\"Embarked\"], as_index = False).mean().sort_values(by = \"Fare\", ascending = False)","b0b6893b":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c], 25)\n        \n        # 3rd quartile\n        Q3 = np.percentile(df[c], 75)\n        \n        # IQR\n        IQR = Q3 - Q1\n        \n        # Outlier Step\n        outlier_step = IQR * 1.5\n        \n        # Detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        \n        # Store indeces\n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","e330f156":"train_df.loc[detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"])]","eb0eec3f":"# drop outliers\n\ntrain_df = train_df.drop(detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]), axis = 0).reset_index(drop = True) ","102dc565":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)","9c3269e0":"train_df.head()","64ae8c6d":"train_df.columns[train_df.isnull().any()]","2451d734":"train_df.isnull().sum()","d3e9ec2b":"train_df[train_df[\"Embarked\"].isnull()]","1e69aa40":"train_df.boxplot(column = \"Fare\", by = \"Embarked\")\nplt.show()","91405f93":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","fad7da54":"train_df[train_df[\"Fare\"].isnull()]","85dca8d7":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","15864bdd":"train_df[train_df[\"Fare\"].isnull()]","322e4216":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","ad4cfbd4":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","23746d11":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","4dfd6b3c":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","2e9b2d74":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","3e6ad119":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 4)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","8f156588":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 4)\ng.map(sns.pointplot, \"Pclass\", \"Survived\", \"Sex\")\ng.add_legend()\nplt.show()","639365d0":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 4)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","001bc3ef":"train_df[train_df[\"Age\"].isnull()]","5b0eda03":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","a068d9fb":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\", data = train_df, kind = \"box\")\nplt.show()","0b6ba269":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","4360eb75":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","49f9b219":"sns.heatmap(train_df[[\"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Pclass\"]].corr(), annot = True)\nplt.show()","4ddfe336":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_prediction = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_prediction):\n        train_df[\"Age\"].iloc[i] = age_prediction\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","2c23e674":"train_df[train_df[\"Age\"].isnull()]","7a12631b":"train_df[\"Name\"].head(10)","841d86ff":"s = \"McCarthy, Mr. Jame J\"\ns.split(\".\")\n# It separates string from dot and put them in a list.\ns.split(\".\")[0]\n# It takes first index of divided string.\ns.split(\".\")[0].split(\",\")[1].strip()\n# Strip(): remove the space from string","3660f5e7":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[1].strip() for i in name]\n\ntrain_df[\"Title\"].head(10)","33888428":"sns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","3e3069f1":"# convert to categorical\n\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"], \"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","f533af2f":"sns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","68370feb":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probabilty\")\nplt.show()","8ce7abbc":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","fa31c65a":"train_df.head()","6aa5254c":"train_df = pd.get_dummies(train_df, columns = [\"Title\"])\ntrain_df.head()","d84258d3":"train_df.head()","aada25cf":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntrain_df.head()","e5f7263b":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","d1d1ea4b":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]\ntrain_df.head(10)","e45c49f4":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","30059fcf":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","1e6878c9":"train_df = pd.get_dummies(train_df, columns = [\"family_size\"])\ntrain_df.head()","4c3515f9":"train_df[\"Embarked\"].head()","f7710c80":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","ee584d0f":"train_df = pd.get_dummies(train_df, columns = [\"Embarked\"])\ntrain_df.head()","fd7f6f48":"train_df[\"Ticket\"].head(20)","9a31123c":"a = \"A\/5. 2151\"\na.replace(\".\",\"\")\na.replace(\".\",\"\").replace(\"\/\",\"\")\na.replace(\".\",\"\").replace(\"\/\",\"\").strip()\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","86e96876":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","d4ac786c":"train_df.head()","a5a84537":"train_df = pd.get_dummies(train_df, columns = [\"Ticket\"], prefix = \"T\")","131dac52":"train_df.head()","7b948d01":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","47dca235":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])\ntrain_df.head()","abff59d4":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Sex\"])\ntrain_df.head()","e38c96d1":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","e9a949a6":"train_df.columns","69e1dedf":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","9883f323":"train_df_len","57299926":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"], axis = 1, inplace = True)","1082eab4":"test.head()","463993f2":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\", len(X_train))\nprint(\"X_test\", len(X_test))\nprint(\"y_train\", len(y_train))\nprint(\"y_test\", len(y_test))\nprint(\"test\", len(test))","ed58f7cb":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)\nacc_log_test = round(logreg.score(X_test, y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","7357d9b7":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\" : range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\" : [0.001, 0.01, 0.1, 1],\n                 \"C\" : [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\" : [1,3,10],\n                \"min_samples_split\" : [2,3,10],\n                \"min_samples_leaf\" : [1,3,10],\n                \"bootstrap\" : [False],\n                \"n_estimators\" : [100,300],\n                \"criterion\" : [\"gini\"]}\n\nlogreg_param_grid = {\"C\" : np.logspace(-3,3,7),\n                    \"penalty\" : [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\" : np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\" : [\"uniform\", \"distance\"],\n                 \"metric\" : [\"euclidean\",\"manhattan\"]}\n\nclassifier_param =[dt_param_grid,\n                  svc_param_grid,\n                  rf_param_grid,\n                  logreg_param_grid,\n                  knn_param_grid]","93afc670":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid = classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1, verbose = 1)\n    clf.fit(X_train, y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","01b8762e":"cv_results = pd.DataFrame({\"Cross Validation Means\" : cv_result, \"ML Models\" : [\"DecisionTreeClassifier\",\n                                                                               \"SVM\",\n                                                                               \"RandomForestClassifier\",\n                                                                               \"LogisticRegression\",\n                                                                               \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")\nplt.show()","f72bbd0d":"votingC = VotingClassifier(estimators = [(\"dt\", best_estimators[0]),\n                                        (\"rfc\", best_estimators[2]),\n                                        (\"lr\", best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test), y_test))","40bc8dc2":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId,test_survived], axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","fbce8029":"<a id = \"10\"><\/a>\n## Fill Missing Value\n\n* Embarked has 2 missing value\n* Fare has only 1 value","3c3fdf72":"<a id = \"4\"><\/a>\n## Categorical Variable","920d8685":"<a id = \"27\"><\/a>\n## Sex","3528d1c3":"<a id = \"18\"><\/a>\n## Embarked -- Sex -- Pclass -- Survived","57b03bd8":"* float64 (2): Fare and Age\n* int64 (5): PassengerId, Survived, Pclass, Sibsp, Parch\n* objects (5): Name, Sex, Ticket, Cabin, Embarked","ce6948ae":"<a id = \"3\"><\/a>\n## Univariate Variable Analysis\n\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n* Numerical Variable: Age, PassengerId and Fare\n\n","3fa52511":"<a id = \"7\"><\/a>\n## Outlier Detection","9dc0940c":"<a id = \"19\"><\/a>\n## Embarked -- Sex -- Fare -- Survived","3750c48e":"<a id = \"32\"><\/a>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\n\nComparing 5 machine learning classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","e9a423aa":"<a id = \"12\"><\/a>\n## Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","feee50e4":"<a id = \"1\"><\/a>\n## Load and Check Data","e4c41933":"<a id = \"2\"><\/a>\n## Variable Description\n1. PassengerId: unique id number for every passenger.\n1. Survived: passenger survive(1) or die(0)\n1. Pclass: Passenger class\n1. Name\n1. Sex\n1. Age\n1. SibSp: Number of siblings\/Spouses\n1. Parch: Number of parents\/Children\n1. Ticket: Ticket number\n1. Fare: Amount of money spent on ticket\n1. Cabin: Cabin category\n1. Embarked: port where passenger taken (C = Cherbourg, Q = Queenstown, S = Southampton)\n","19101058":"* Sibsp and parch can be used for new feature extraction with th = 3\n* Small familes have more chance to survive\n* There is std in survival of passenger with parch = 3","1dfcfefc":"<a id = \"15\"><\/a>\n## Pclass -- Survived","3f9de44f":"* Pclass is important feature for model training","2a7fa71a":"<a id = \"5\"><\/a>\n## Numerical Variable","4d9e5a01":"<a id = \"6\"><\/a>\n## Basic Data Analysis\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","09676cbe":"<a id = \"25\"><\/a>\n## Ticket","dd3649fb":"* Sex is not informative for age prediction.","45829b44":"<a id = \"22\"><\/a>\n## Name -- Title","51905af0":"* 1st class older than others. 2nd is older than 3rd class.","daa90969":"So we can understand, small families have more chance to survive than large families.","92f3cbca":"* Having a lot of SibSp have less chance to survive. If SibSp == 0 or 1 or 2, passenger has more chance to survive.\n\n* We can conside a new feature decribing these categories (like, who has more than 2 SibSp or less than 2).","c0fc4ce9":"<a id = \"26\"><\/a>\n## Pclass","97e66b09":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass","fc9a5bf7":"<a id = \"20\"><\/a>\n## Fill missing: Age feature","d40059ff":"* Female passengers have much better survival rate than males.\n* Males have better survival rate in pclass = 3 for embarked = C.\n* Embarked and sex will be used in training.","33712a38":"<a id = \"30\"><\/a>\n## Train - Test Split","ed991e06":"<a id = \"24\"><\/a>\n## Embarked","802767c0":"<a id = \"21\"><\/a>\n# Feature Enginnering","7ce0ac28":"<a id = \"9\"><\/a>\n## Find Missing Value","4aaa5581":"<a id = \"16\"><\/a>\n## Age -- Survived","1d4d4ca1":"* age <= 10 has a high survival rate.\n* Oldest passenger (age = 80) survived.\n* Large number of 20 years old people did not survive.\n* Most passengers are in 15-35 age range.\n* Use age feature in training\n* Use age distribution for missing value of age.","ff30104e":"<a id = \"34\"><\/a>\n## Prediction and Submission","76523064":"* Passengers who pay higher fare have better survival rate.\n* Fare can be used as for training.","ae8ca817":"<a id = \"13\"><\/a>\n## Sibsp -- Survived","4f64497d":"<a id = \"14\"><\/a>\n## Parch -- Survived","d4ae3977":"<a id = \"28\"><\/a>\n## Drop PassengerId and Cabin","876853b7":"<a id = \"8\"><\/a>\n# Missing Value\n\n * Find Missing Value\n * Fill Missing Value","8b74caee":"<a id = \"23\"><\/a>\n## Family Size","5c5c841e":"Fare feature seems to have corr with survived feature (0.26).","d054e299":"<a id = \"11\"><\/a>\n       \n# Visualization","f99e33f2":"* We will eliminate ml models that under 0.8.\n* So we can use random forest, decision tree and logistic regression.","e24d6895":"# Introduction\n\nThe sinking of Titanic is one of the most popular accident in the history. Making a movie about it and saying \"even God cannot sink this ship\" made the accident even more popular. Unfortunately, it sank with 2340 passengers and crew after it hit the iceberg in 1912.\n\n<font color = \"blue\">\nContent:\n\n    \n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable](#4)\n        * [Numerical Variable](#5)\n    \n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [Sibsp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Age -- Survived](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill missing: Age feature](#20)\n7. [Feature Enginnering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop PassengerId and Cabin](#28)\n8. [Modeling](#29)\n    * [Train - Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)","23cb965d":"<a id = \"31\"><\/a>\n## Simple Logistic Regression","78000659":"<a id = \"33\"><\/a>\n## Ensemble Modeling","ab54670c":"<a id = \"17\"><\/a>\n## Pclass -- Age -- Survived","5de7ed86":"<a id = \"29\"><\/a>\n# Modeling"}}