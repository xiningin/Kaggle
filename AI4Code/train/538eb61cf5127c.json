{"cell_type":{"25f692b0":"code","6285195a":"code","6fa5e263":"code","c978609d":"code","35b83e57":"code","d40bafab":"code","d40f58d2":"code","e5ad7093":"code","945bc88a":"code","e2e3f856":"code","0b919d73":"code","1274b9ee":"code","329d8af4":"code","6970a14f":"markdown","5040acf1":"markdown"},"source":{"25f692b0":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\nfrom datetime import datetime #To Know the Running Time\nfrom sklearn.model_selection import train_test_split # Data Splitting\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler # Data Standadization\nfrom sklearn.preprocessing import MinMaxScaler #Min-Max Data Normalization\nfrom imblearn.over_sampling import ADASYN # Oversampling Data with ADASYN\nfrom sklearn.linear_model import LogisticRegression # Logistic regression algorithm","6285195a":"#Read Dataset\ndf = pd.read_csv('..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')","6fa5e263":"#Data Summary\ndf.head()","c978609d":"#Drop Kolom Sallary\ndf1 = df.drop(['sl_no','salary'], axis=1)","35b83e57":"#Count the Categorical Data\ncat_cols = df1.select_dtypes(include=object).columns.tolist()\n(pd.DataFrame(\n    df[cat_cols]\n    .melt(var_name='column', value_name='value')\n    .value_counts())\n.rename(columns={0: 'counts'})\n.sort_values(by=['column', 'counts']))","d40bafab":"#Convert Categorical Data to Integer\ndf1['degree_t'] = df1['degree_t'].replace(['Others'], 1).replace(['Sci&Tech'], 2).replace(['Comm&Mgmt'], 3)\ndf1['gender'] = df1['gender'].replace(['F'], 1).replace(['M'], 2)\ndf1['hsc_b'] = df1['hsc_b'].replace(['Central'], 1).replace(['Others'], 2)\ndf1['hsc_s'] = df1['hsc_s'].replace(['Arts'], 1).replace(['Science'], 2).replace(['Commerce'], 2)\ndf1['specialisation'] = df1['specialisation'].replace(['Mkt&HR'], 1).replace(['Mkt&Fin'], 2)\ndf1['ssc_b'] = df1['ssc_b'].replace(['Others'], 1).replace(['Central'], 2)\ndf1['workex'] = df1['workex'].replace(['Yes'], 1).replace(['No'], 2)\ndf1['status'] = df1['status'].replace(['Not Placed'], 0).replace(['Placed'], 1)","d40f58d2":"df1.head()","e5ad7093":"print(df1.dtypes)","945bc88a":"#Data Split\nx = df1.drop('status', axis = 1).values\ny = df1['status'].values\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = None)\n\n#Oversampling Data\nada = ADASYN(sampling_strategy='auto', random_state=27)\nx_train, y_train = ada.fit_resample(x_train, y_train)\n\n#Min-Max Data Scalling\nscaler = MinMaxScaler() \nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n\n#Min-Max Data Scalling\nscaler = StandardScaler() \nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","e2e3f856":"start = datetime.now()\n\n#Logistic Regression\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nlr_yhat = lr.predict(x_test)\n\nend = datetime.now()\ntime_taken = end - start\nprint('Time: ',time_taken)","0b919d73":"import itertools # advanced tools\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n#Confusion Matrix\n#Defining the plot function\ndef plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n    title = 'Confusion Matrix of {}'.format(title)\n    if normalize:\n        cm = cm.astype(float) \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n#Compute confusion matrix for the models\nlr_matrix = confusion_matrix(y_test, lr_yhat, labels = [0, 1]) #Logistic Regression\n\n#Plot the confusion matrix\nplt.rcParams['figure.figsize'] = (6, 6)\n\n# Logistic regression\nlr_cm_plot = plot_confusion_matrix(lr_matrix, \n                                classes = ['Negative(0)','Positive(1)'], \n                                normalize = False, title = 'Logistic Regression')\nplt.savefig('lr_cm_plot.png')\nplt.show()","1274b9ee":"# get importance\nimportance = lr.coef_[0]\n\nfeature_names = [\"gender\", \"ssc_p\",\t\"ssc_b\",\t\"hsc_p\",\t\"hsc_b\",\t\"hsc_s\",\t\"degree_p\",\t\"degree_t\",\t\"workex\",\t\"etest_p\",\t\"specialisation\",\t\"mba_p\"]\nfeature_importance = pd.DataFrame(feature_names, columns = [\"feature\"])\nfeature_importance[\"importance\"] = importance\nfeature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=True)\n\nfrom sklearn.linear_model import LogisticRegression\nax = feature_importance.plot.barh(x='feature', y='importance')\nplt.show()","329d8af4":"#Drop Unnecessary Column\ndf2 = df.drop(['sl_no','salary'], axis=1)\n#Drop the Unemployed\ndf2 = df2[df2.status != 'Not Placed']\n#Mathematical Statement\nmkthr = round((df2.specialisation == 'Mkt&HR').sum()\/(df.specialisation == 'Mkt&HR').sum(), 2)\nmktfin = round((df2.specialisation == 'Mkt&Fin').sum()\/(df.specialisation == 'Mkt&Fin').sum(), 2)\n#Print\nprint('Percentage Placed of Each Degree')\nprint('Marketing & HR Specialization - Employment Rate {}'.format(mkthr))\nprint('Marketing & Financial - Employment Rate {}'.format(mktfin))\n#Bar Chart\nx = ['Marketing & HR', 'Marketing & Fin']\nenergy = [mkthr, mktfin]\nx_pos = [i for i, _ in enumerate(x)]\nplt.bar(x_pos, energy)\nplt.xticks(x_pos, x)\nplt.show()","6970a14f":"**Classification Model Build Start**","5040acf1":"**Most Wanted Industry by Industry**"}}