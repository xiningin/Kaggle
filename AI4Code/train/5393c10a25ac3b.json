{"cell_type":{"afb97ed5":"code","6b0a594e":"code","0a79b74e":"code","b5688879":"code","9b293cc6":"code","1870d355":"code","23f6cdb4":"code","c2614e74":"code","51a065b5":"code","46084967":"code","01f7cc70":"code","09e300ea":"code","64b774cd":"code","e62a63e9":"code","1ace47eb":"code","df09a9fc":"code","689a4797":"code","93d16f2f":"code","b474fac5":"code","0cedded5":"code","aac55fdb":"code","996514a3":"code","a6808925":"code","2ac9e66b":"code","c1c0e0ad":"code","e6d72d1e":"code","687006e5":"code","25ab6264":"code","dac2dfe8":"code","9a0da37e":"code","7fc0eebb":"code","6303027d":"code","cf9ce8d1":"code","2db687c7":"code","60bccc65":"code","3e8a518a":"code","53f85092":"code","f46f30b6":"code","6e648156":"code","8323b374":"markdown","3fd9951e":"markdown","acf45ac6":"markdown","8086363c":"markdown","d7ec9fad":"markdown","a74d642b":"markdown","6ab4418d":"markdown"},"source":{"afb97ed5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn import preprocessing\nimport keras\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6b0a594e":"src='\/kaggle\/input\/airplane-accidents-severity-dataset\/'\nprint(src)\ndest=os.getcwd()\ndest","0a79b74e":"train_df=pd.read_csv(src+\"train.csv\")\ntest_df=pd.read_csv(src+\"test.csv\")\nsample=pd.read_csv(src+\"sample_submission.csv\")","b5688879":"df=train_df.copy()\ndf_normalize=train_df.copy()","9b293cc6":"train_df.head()","1870d355":"test_df.head()","23f6cdb4":"print(df.shape, test_df.shape)","c2614e74":"df.info()","51a065b5":"df.describe()","46084967":"df.isna().sum()","01f7cc70":"test_df.info()","09e300ea":"x=df.drop(['Severity', 'Accident_ID'], axis=1)\nx_test=test_df.drop(['Accident_ID'],axis=1)\ny_train=df['Severity']","64b774cd":"y_train.unique()","e62a63e9":"x_n=df_normalize.drop(['Severity','Accident_ID'],axis=1)\ny_n=df_normalize['Severity']","1ace47eb":"x_n.describe()","df09a9fc":"y_n.value_counts()","689a4797":"#x_no=x_n[:].values.astype(\"float64\")\n#x_no=x_n","93d16f2f":"#x_test=x_test[:].values.astype(\"float64\")","b474fac5":"#x_test=preprocessing.normalize(x_test)","0cedded5":"x_m = x.values\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x_m)\nX_train_final = pd.DataFrame(x_scaled)\nX_test_final=pd.DataFrame(min_max_scaler.fit_transform(x_test.values))","aac55fdb":"x_no = X_train_final\n","996514a3":"class_map = {\n    'Minor_Damage_And_Injuries': 0,\n    'Significant_Damage_And_Fatalities': 1,\n    'Significant_Damage_And_Serious_Injuries': 2,\n    'Highly_Fatal_And_Damaging': 3\n}\ninverse_class_map = {\n    0: 'Minor_Damage_And_Injuries',\n    1: 'Significant_Damage_And_Fatalities',\n    2: 'Significant_Damage_And_Serious_Injuries',\n    3: 'Highly_Fatal_And_Damaging'\n}","a6808925":"y_no = y_n.map(class_map)\nprint(x_no.shape,y_no.shape)","2ac9e66b":"from numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n# integer encode\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y_no)\n# binary encode\nonehot_encoder = OneHotEncoder(sparse=False)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)","c1c0e0ad":"y_no=onehot_encoded\nprint(y_no.shape)","e6d72d1e":"print(x_no.shape)","687006e5":"#random shuffle\nx_r=np.random.shuffle(x_no)","25ab6264":"#splitting into train and val\nx_train=x_no[:6000]\nx_val=x_no[6000:]\nprint(x_train.shape,x_val.shape)","dac2dfe8":"y_train=y_no[:6000]\ny_val=y_no[6000:]","9a0da37e":"\n# One-Hot Encode\n#y_no=keras.utils.to_categorical(y_no,4)\n#y_no","7fc0eebb":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten","6303027d":"model=Sequential()\nmodel.add(Dense(12,activation='relu',input_dim=10))\nmodel.add(Dense(8,activation='relu'))\nmodel.add(Dense(4,activation='sigmoid'))\n","cf9ce8d1":"print(model.summary())","2db687c7":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n#X=X_train_final","60bccc65":"history=model.fit(x_train,y_train,epochs=50,batch_size=10, validation_data=(x_val, y_val))","3e8a518a":"history_dict=history.history\nprint(history_dict.keys())","53f85092":"loss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","f46f30b6":"pred_test=np.argmax(model.predict(X_test_final),axis=1)\npred_test","6e648156":"submission = pd.DataFrame([test_df['Accident_ID'], np.vectorize(inverse_class_map.get)(pred_test)], index=['Accident_ID', 'Severity']).T\nsubmission.to_csv('\/kaggle\/working\/submission_keras1.csv', index=False)\n","8323b374":"**Checking null values**","3fd9951e":"**Model Training**","acf45ac6":"**Normalize**","8086363c":"**Only target variable is categorical in nature**","d7ec9fad":"Model Fit( CNN )","a74d642b":"**Making x and y out of train and test**","6ab4418d":"**Displaying Datasets**"}}