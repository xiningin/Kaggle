{"cell_type":{"72352839":"code","5159b5d3":"code","bf3f646d":"code","f3a99a3d":"code","8ae99981":"code","19ebc9f6":"code","ced342eb":"code","ebc04f83":"code","2016fcce":"code","4b8cced9":"code","47c85913":"code","c630687a":"code","c18631f2":"code","c79ab63d":"code","54370051":"code","eb8c8acd":"code","ee831df8":"code","6e6e5789":"code","18045b01":"code","3584c0e2":"code","ef2ae5c3":"code","1703efc1":"code","2bccaf69":"markdown","0d44b62f":"markdown","8ebf0760":"markdown","b8434b2b":"markdown","8d0e9784":"markdown","73995e90":"markdown"},"source":{"72352839":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nfrom glob import glob\nfrom math import floor\nfrom PIL import ImageFont, ImageDraw, Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nimport keras\nfrom keras.layers import Dense, Activation, Input, Conv2D, BatchNormalization, Add, UpSampling2D, ZeroPadding2D, Lambda\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import get_file\nfrom keras.optimizers import Adam\nimport keras.backend as K\nimport tensorflow as tf\nimport gc\nimport os","5159b5d3":"PATH = \"..\/input\/pku-autonomous-driving\"","bf3f646d":"# \u8a13\u7df4\u96c6\u548c\u6e2c\u8a66\u96c6\u5217\u8868 \uff06 \u9700\u8981\u88ab\u6392\u9664\u7684\u7455\u75b5\u8cc7\u6599\ntrain = pd.read_csv('..\/input\/pku-autonomous-driving\/train.csv')\ntest = pd.read_csv('..\/input\/pku-autonomous-driving\/sample_submission.csv')\nbad_list = ['ID_1a5a10365',\n    'ID_1db0533c7',\n    'ID_53c3fe91a',\n    'ID_408f58e9f',\n    'ID_4445ae041',\n    'ID_bb1d991f6',\n    'ID_c44983aeb',\n    'ID_f30ebe4d4']\ntrain = train.loc[~train['ImageId'].isin(bad_list)]","f3a99a3d":"# \u5b57\u4e32\u8cc7\u6599 \u2190\u2192 \u5e36\u6a19\u7c64\u8cc7\u6599 \u2192 \u50cf\u7d20\u5ea7\u6a19\ndef str_to_coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n    coords = []\n    for l in np.array(s.split()).reshape([-1, 7]):\n        coords.append(dict(zip(names, l.astype('float'))))\n        if 'id' in coords[-1]:\n            coords[-1]['id'] = int(coords[-1]['id'])\n    return coords\n\ndef coords_to_str(coords):\n    s = []\n    for c in coords:\n        for n in range(7):\n            s.append(str(c[n]))\n    return ' '.join(s)\n\n# \u651d\u5f71\u6a5f\u8cc7\u6599\ncamera_matrix = np.array([[2304.5479, 0,  1686.2379],\n                          [0, 2305.8757, 1354.9849],\n                          [0, 0, 1]], dtype=np.float32)\n\ndef pixel_coords(s):\n    coords = str_to_coords(s)\n    xc = [c['x'] for c in coords]\n    yc = [c['y'] for c in coords]\n    zc = [c['z'] for c in coords]\n    P = np.array(list(zip(xc, yc, zc))).T\n    img_p = np.dot(camera_matrix, P).T\n    img_p[:, 0] \/= img_p[:, 2]\n    img_p[:, 1] \/= img_p[:, 2]\n    u = img_p[:, 0]\n    v = img_p[:, 1]\n    zc = img_p[:, 2]\n    return u, v","8ae99981":"# \u91cd\u8a2d\u5c3a\u5bf8\uff1aCenterNet \u7684\u8f38\u5165\u5c3a\u5bf8 = 512*512*3\ndef resize_image(img, input_width = 512, input_height = 512):\n    img = cv2.resize(img, (input_width, input_height))\n    return (img \/ 255).astype('float32')","19ebc9f6":"# \u6709 mask image \u7684\u8cc7\u6599\u8981\u906e\u4e00\u4e0b\ndef CreateMaskImages(imageName):\n    trainimage = cv2.imread(PATH  + \"\/train_images\/\" + imageName + '.jpg')\n    imagemask = cv2.imread(PATH + \"\/train_masks\/\" + imageName + \".jpg\",0)\n    try:\n        imagemaskinv = cv2.bitwise_not(imagemask)\n        res = cv2.bitwise_and(trainimage,trainimage,mask = imagemaskinv)\n        \n        # cut upper half,because it doesn't contain cars.\n        res = res[res.shape[0] \/\/ 2:]\n        return res\n    except:\n        trainimage = trainimage[trainimage.shape[0] \/\/ 2:]\n        return trainimage","ced342eb":"# Heatmap = 128*128*1\n# \u4ed6\u8aaa\uff1a\u300c\u6a21\u578b\u6aa2\u6e2c\u5230\u7cbe\u78ba\u4e2d\u5fc3\u9644\u8fd1\u7684\u9ede\u6642\uff0c\u5177\u6709\u9ad8\u65af\u5206\u4f48\u7684\u4e2d\u5fc3\u9ede\u5c0d\u65bc\u6e1b\u5c11\u8a13\u7df4\u640d\u5931\u662f\u5fc5\u8981\u7684\u300d\ndef heatmap(u, v, output_width=128, output_height=128, sigma=1):\n    \n    def get_heatmap(p_x, p_y):\n        X1 = np.linspace(1, output_width, output_width)\n        Y1 = np.linspace(1, output_height, output_height)\n        [X, Y] = np.meshgrid(X1, Y1)\n        X = X - floor(p_x)\n        Y = Y - floor(p_y)\n        D2 = X * X + Y * Y\n        E2 = 2.0 * sigma ** 2\n        Exponent = D2 \/ E2\n        heatmap = np.exp(-Exponent)\n        heatmap = heatmap[:, :, np.newaxis]\n        return heatmap\n    \n    output = np.zeros((128,128,1))\n    for i in range(len(u)):\n        heatmap = get_heatmap(u[i], v[i])\n        output[:,:] = np.maximum(output[:,:],heatmap[:,:])\n      \n    return output","ebc04f83":"# Regression = 128*128*6\n# \u4ed6\u8aaa\uff1a \u300c\u76f4\u63a5\u56de\u6b78\u65cb\u8f49\u53ef\u80fd\u4e0d\u662f\u500b\u597d\u65b9\u6cd5\uff0c\u4e4b\u5f8c\u6703\u8a66\u8a66\u5225\u7684\u65b9\u6cd5\u300d\n# \u5982\u679c\u9019\u73a9\u610f\u5152\u6703\u52d5\u7684\u8a71\uff0c\u53ef\u4ee5\u8003\u616e\u8a66\u8a66\u5176\u4ed6\u65b9\u6cd5\ndef pose(s, u, v):\n    regr = np.zeros([128, 128, 6], dtype='float32')\n    coords = str_to_coords(s)\n    for p_x, p_y, regr_dict in zip(u, v, coords):\n        if p_x >= 0 and p_x < 128 and p_y >= 0 and p_y < 128:\n            regr_dict.pop('id')\n            regr[floor(p_y), floor(p_x)] = [regr_dict[n] for n in regr_dict]\n            \n    # x,y,z devide by 100\n    regr[:,:,-3:] \/= 100  \n    return regr","2016fcce":"def example(i):\n    fig, axes = plt.subplots(2, 4,figsize=(20,20))\n    plt.subplots_adjust(top=0.5)\n\n    img0 = CreateMaskImages(train['ImageId'][i])\n    img1 = resize_image(img0)\n    axes[0, 0].set_title('Mask Image as Input')\n    axes[0, 0].imshow(img1)\n\n    # Image height: img.shape[0] and v         Image width: img.shape[1] and u\n    u, v = pixel_coords(train['PredictionString'][i])\n    u = u * 128 \/ img0.shape[1]\n    v = (v - img0.shape[0]) * 128 \/ img0.shape[0]\n    hm = np.squeeze(heatmap(u,v))\n    axes[0, 1].set_title('Heatmap of Center Points as Output')\n    axes[0, 1].imshow(hm)\n\n    regr = pose(train['PredictionString'][i], u,v)\n    axes[0, 2].set_title('Yaw - Ground Truth')\n    axes[0, 2].imshow(regr[..., 0])\n\n    axes[0, 3].set_title('Pitch - Ground Truth')\n    axes[0, 3].imshow(regr[..., 1])\n\n    axes[1, 0].set_title('Roll - Ground Truth')\n    axes[1, 0].imshow(regr[..., 2])\n\n    axes[1, 1].set_title('X - Ground Truth')\n    axes[1, 1].imshow(regr[..., 3])\n\n    axes[1, 2].set_title('Y - Ground Truth')\n    axes[1, 2].imshow(regr[..., 4])\n\n    axes[1, 3].set_title('Z - Ground Truth')\n    axes[1, 3].imshow(regr[..., 5])","4b8cced9":"# \u4f86\u770b\u770b\u524d\u9762\u7684\u7a0b\u5f0f\u505a\u4e86\u5565 (\u7de8\u865f\u9808\u5c0f\u65bc4000)\nexample(2050)","47c85913":"# \u770b\u8d77\u4f86\u5f88\u9ad8\u7aef\u7684\u8a13\u7df4\u96c6\u88fd\u9020\u6a5f\ndef train_generator(train, batch_size=3):\n    count=0\n    X = []\n    y1 = []\n    y2 = []\n    while True:\n        for i in range(len(train)):\n            img0 = CreateMaskImages(train['ImageId'][i])\n            img1 = resize_image(img0)\n            X.append(img1)\n            \n            u, v = pixel_coords(train['PredictionString'][i])\n            u = u * 128 \/ img0.shape[1]\n            v = (v - img0.shape[0]) * 128 \/ img0.shape[0]\n            hm = heatmap(u,v)\n            y2.append(hm)\n\n            p = pose(train['PredictionString'][i], u, v)\n            y1.append(p)\n\n            count+=1\n            if count == batch_size:\n                X_batch = np.array(X, dtype=np.float32)\n                y1_batch = np.array(y1, dtype=np.float32)\n                y2_batch = np.array(y2, dtype=np.float32)\n                \n                del X, y1, y2\n                gc.collect()\n                \n                count = 0\n                X = []\n                y1 = []\n                y2 = []\n                \n                yield(X_batch, {'car_pose.1.1': y1_batch, 'confidence.1.1': y2_batch})","c630687a":"# \u67b6\u69cb\uff1a\u795e\u79d8\u7684\u6c99\u6f0f\u7db2\u8def\n'''\n\u7e3d\u4e4b\u5148\u5efa\u500b\u6a21\u578b\u7684\u9aa8\u67b6\uff0c\u64da\u8aaa\u53ef\u4ee5\u5f9e COCO \u4e0b\u8f09\u9810\u8a13\u7df4\u6b0a\u503c\uff0c\u6578\u64da\u683c\u5f0f\u5728 ~\/.keras\/keras.json\n\u53c3\u6578\u8aaa\u660e\uff1a\n    1. num_stacks = \u6c99\u6f0f modules \u7684\u6578\u91cf\n    2. cnv_dim = \u964d\u4f4e\u5206\u8fa8\u7387\u5f8c filters \u7684\u6578\u91cf\n    3. inres = \u8f38\u5165\u7684\u5f62\u72c0\uff0c\u9808\u8981\u662f 128 \u7684\u500d\u6578\n    4. weights = 'None' \u2192 \u96a8\u6a5f\u521d\u59cb\u5316\n                 'ctdet_coco' \u2192 2D \u7269\u4ef6\u5075\u6e2c\u7528\n                 'hpdet_coco' \u2192 \u4eba\u985e\u59ff\u52e2\u5075\u6e2c\u7528\n    5. dims = \u6c99\u6f0f blocks \u4e2d channels \u7684\u6578\u91cf\n\u56de\u50b3\uff1a\n    keras \u7684 model \u5be6\u4f8b x1\n'''\ndef HourglassNetwork(heads, num_stacks, cnv_dim=256, inres=(512, 512), weights=False, dims=[256, 384, 384, 384, 512]):\n    input_layer = Input(shape=(inres[0], inres[1], 3), name='HGInput')\n    inter = pre(input_layer, cnv_dim)\n    prev_inter = None\n    outputs = []\n    for i in range(num_stacks):\n        prev_inter = inter\n        _heads, inter = hourglass_module(heads, inter, cnv_dim, i, dims)\n        if i == 1:\n            outputs.extend(_heads)\n        if i < num_stacks - 1:\n            inter_ = Conv2D(cnv_dim, 1, use_bias=False, name='inter_.%d.0' % i)(prev_inter)\n            inter_ = BatchNormalization(epsilon=1e-5, name='inter_.%d.1' % i)(inter_)\n\n            cnv_ = Conv2D(cnv_dim, 1, use_bias=False, name='cnv_.%d.0' % i)(inter)\n            cnv_ = BatchNormalization(epsilon=1e-5, name='cnv_.%d.1' % i)(cnv_)\n\n            inter = Add(name='inters.%d.inters.add' % i)([inter_, cnv_])\n            inter = Activation('relu', name='inters.%d.inters.relu' % i)(inter)\n            inter = residual(inter, cnv_dim, 'inters.%d' % i)\n\n    model = Model(inputs=input_layer, outputs=outputs)\n\n    # load weights\n    if weights:\n        weights_path = get_file('HourglassNet.hdf5',\n                          'https:\/\/github.com\/see--\/keras-centernet\/releases\/download\/0.1.0\/ctdet_coco_hg.hdf5',\n                          cache_subdir='hourglassnet', \n                          file_hash='ce01e92f75b533e3ff8e396c76d55d97ff3ec27e99b1bdac1d7b0d6dcf5d90eb')\n        model.load_weights(weights_path, by_name=True)\n\n    return model","c18631f2":"# \u7279\u5fb5\uff1f\ndef hourglass_module(heads, bottom, cnv_dim, hgid, dims):\n    # create left features , f1, f2, f4, f8, f16 and f32\n    lfs = left_features(bottom, hgid, dims)\n\n    # create right features, connect with left features\n    rf1 = right_features(lfs, hgid, dims)\n    rf1 = convolution(rf1, 3, cnv_dim, name='cnvs.%d' % hgid)\n\n    # add 1x1 conv with two heads, inter is sent to next stage\n    # head_parts is used for intermediate supervision\n    heads = create_heads(heads, rf1, hgid)\n    return heads, rf1","c79ab63d":"# \u5377\u7a4d\u584a\ndef convolution(_x, k, out_dim, name, stride=1):\n    padding = (k - 1) \/\/ 2\n    _x = ZeroPadding2D(padding=padding, name=name + '.pad')(_x)\n    _x = Conv2D(out_dim, k, strides=stride, use_bias=False, name=name + '.conv')(_x)\n    _x = BatchNormalization(epsilon=1e-5, name=name + '.bn')(_x)\n    _x = Activation('relu', name=name + '.relu')(_x)\n    return _x","54370051":"# \u6b98\u5dee\u584a\ndef residual(_x, out_dim, name, stride=1):\n    shortcut = _x\n    num_channels = K.int_shape(shortcut)[-1]\n    _x = ZeroPadding2D(padding=1, name=name + '.pad1')(_x)\n    _x = Conv2D(out_dim, 3, strides=stride, use_bias=False, name=name + '.conv1')(_x)\n    _x = BatchNormalization(epsilon=1e-5, name=name + '.bn1')(_x)\n    _x = Activation('relu', name=name + '.relu1')(_x)\n\n    _x = Conv2D(out_dim, 3, padding='same', use_bias=False, name=name + '.conv2')(_x)\n    _x = BatchNormalization(epsilon=1e-5, name=name + '.bn2')(_x)\n\n    if num_channels != out_dim or stride != 1:\n        shortcut = Conv2D(out_dim, 1, strides=stride, use_bias=False, name=name + '.shortcut.0')(\n            shortcut)\n        shortcut = BatchNormalization(epsilon=1e-5, name=name + '.shortcut.1')(shortcut)\n\n    _x = Add(name=name + '.add')([_x, shortcut])\n    _x = Activation('relu', name=name + '.relu')(_x)\n    return _x","eb8c8acd":"# \u9084\u4e0d\u77e5\u9053\u5e79\u5565\u7528\ndef pre(_x, num_channels):\n    # front module, input to 1\/4 resolution\n    _x = convolution(_x, 7, 128, name='pre.0', stride=2)\n    _x = residual(_x, num_channels, name='pre.1', stride=2)\n    return _x","ee831df8":"# \u5efa\u69cb\u7528\u7684\u5de5\u5177\u51fd\u5f0f\u5011\ndef left_features(bottom, hgid, dims):\n    # create left half blocks for hourglass module\n    # f1, f2, f4 , f8, f16, f32 : 1, 1\/2, 1\/4 1\/8, 1\/16, 1\/32 resolution\n    # 5 times reduce\/increase: (256, 384, 384, 384, 512)\n    features = [bottom]\n    for kk, nh in enumerate(dims):\n        pow_str = ''\n        for _ in range(kk):\n            pow_str += '.center'\n        _x = residual(features[-1], nh, name='kps.%d%s.down.0' % (hgid, pow_str), stride=2)\n        _x = residual(_x, nh, name='kps.%d%s.down.1' % (hgid, pow_str))\n        features.append(_x)\n    return features\n\ndef connect_left_right(left, right, num_channels, num_channels_next, name):\n    # left: 2 residual modules\n    left = residual(left, num_channels_next, name=name + 'skip.0')\n    left = residual(left, num_channels_next, name=name + 'skip.1')\n\n    # up: 2 times residual & nearest neighbour\n    out = residual(right, num_channels, name=name + 'out.0')\n    out = residual(out, num_channels_next, name=name + 'out.1')\n    out = UpSampling2D(name=name + 'out.upsampleNN')(out)\n    out = Add(name=name + 'out.add')([left, out])\n    return out\n\ndef bottleneck_layer(_x, num_channels, hgid):\n    # 4 residual blocks with 512 channels in the middle\n    pow_str = 'center.' * 5\n    _x = residual(_x, num_channels, name='kps.%d.%s0' % (hgid, pow_str))\n    _x = residual(_x, num_channels, name='kps.%d.%s1' % (hgid, pow_str))\n    _x = residual(_x, num_channels, name='kps.%d.%s2' % (hgid, pow_str))\n    _x = residual(_x, num_channels, name='kps.%d.%s3' % (hgid, pow_str))\n    return _x\n\ndef right_features(leftfeatures, hgid, dims):\n    rf = bottleneck_layer(leftfeatures[-1], dims[-1], hgid)\n    for kk in reversed(range(len(dims))):\n        pow_str = ''\n        for _ in range(kk):\n            pow_str += 'center.'\n        rf = connect_left_right(leftfeatures[kk], rf, dims[kk], dims[max(kk - 1, 0)], name='kps.%d.%s' % (hgid, pow_str))\n    return rf\n\ndef create_heads(heads, rf1, hgid):\n    _heads = []\n    for head in sorted(heads):\n        num_channels = heads[head]\n        _x = Conv2D(256, 3, use_bias=True, padding='same', name=head + '.%d.0.conv' % hgid)(rf1)\n        _x = Activation('relu', name=head + '.%d.0.relu' % hgid)(_x)\n        if head == 'confidence':\n            _x = Conv2D(num_channels, 1, activation='sigmoid', use_bias=True, name=head + '.%d.1' % hgid)(_x)\n        else:\n            _x = Conv2D(num_channels, 1, use_bias=True, name=head + '.%d.1' % hgid)(_x)\n        _heads.append(_x)\n    return _heads","6e6e5789":"# \u9019\u5340\u662f decode \u7684\u90e8\u5206\uff08\u5225\u8ddf\u6211\u8aaa\u524d\u9762\u9019\u662f GAN\uff1f\uff1f\uff1f \uff08\u524d\u9762\u4e0d\u6703\u662f encode \u5427\n\n# use maxpooling as nms\ndef _nms(heat, kernel=3):\n    hmax = K.pool2d(heat, (kernel, kernel), padding='same', pool_mode='max')\n    keep = K.cast(K.equal(hmax, heat), K.floatx())\n    return heat * keep\n\ndef _ctdet_decode(hm, reg, k=100, output_stride=4):\n    hm = _nms(hm)\n    hm_shape = K.shape(hm)\n    reg_shape = K.shape(reg)\n    batch, width, cat = hm_shape[0], hm_shape[2], hm_shape[3]\n\n    hm_flat = K.reshape(hm, (batch, -1))\n    reg_flat = K.reshape(reg, (reg_shape[0], -1, reg_shape[-1]))\n    \n    def _process_sample(args):\n        _hm, _reg = args\n        _scores, _inds = tf.math.top_k(_hm, k=k, sorted=True)\n        _inds = K.cast(_inds \/ cat, 'int32')\n        _reg = K.gather(_reg, _inds)\n        \n        # get yaw, pitch, roll, x, y, z from regression\n        yaw =  _reg[..., 0]\n        pitch =  _reg[..., 1]\n        roll =  _reg[..., 2]\n        x =  _reg[..., 3] * 100\n        y =  _reg[..., 4] * 100\n        z =  _reg[..., 5] * 100\n\n        _detection = K.stack([yaw, pitch, roll, x, y, z, _scores], -1)\n        return _detection\n    \n    detections = K.map_fn(_process_sample, [hm_flat, reg_flat], dtype=K.floatx())\n    return detections\n\ndef CtDetDecode(model, hm_index=1, reg_index=0, k=100, output_stride=4):\n    def _decode(args):\n        hm, reg = args\n        return _ctdet_decode(hm, reg, k=k, output_stride=output_stride)\n    output = Lambda(_decode)([model.outputs[i] for i in [hm_index, reg_index]])\n    model = Model(model.input, output)\n    return model","18045b01":"# \u5c45\u7136\uff01train \u4e5f\u5beb\u6210\u51fd\u5f0f\u4e86\uff01\ndef train_model(model,epoch, batch_size = 4):\n    # 1. choose the layers you want to train\n    n = 0\n    for layer in model.layers:\n        layer.trainable = False\n\n        n += 1\n        if n == 500:\n            break\n    \n    # 2. define loss function\n    def focal_loss(hm_true, hm_pred):\n        pos_mask = tf.cast(tf.equal(hm_true, 1), tf.float32)\n        neg_mask = tf.cast(tf.less(hm_true, 1), tf.float32)\n        neg_weights = tf.pow(1 - hm_true, 4)\n\n        pos_loss = -tf.math.log(tf.clip_by_value(hm_pred, 1e-4, 1)) * tf.pow(1 - hm_pred, 2) * pos_mask\n        neg_loss = -tf.math.log(tf.clip_by_value(1 - hm_pred, 1e-4, 1)) * tf.pow(hm_pred, 2) * neg_weights * neg_mask\n\n        num_pos = tf.reduce_sum(pos_mask)\n        pos_loss = tf.reduce_sum(pos_loss)\n        neg_loss = tf.reduce_sum(neg_loss)\n\n        cls_loss = tf.cond(tf.greater(num_pos, 0), lambda: (pos_loss + neg_loss) \/ num_pos, lambda: neg_loss)\n        return cls_loss\n    \n    def l1_loss(y_true, y_pred):\n        mask = tf.zeros_like(y_true, dtype=tf.float32)\n        mask = tf.equal(y_true, mask)\n        mask = tf.cast(mask, tf.float32)\n        mask = tf.reduce_sum(mask, axis=-1)\n        \n        one = tf.ones_like(mask)\n        zero = tf.zeros_like(mask)\n        mask = tf.where(mask == 6, x=zero, y=one)\n        mask = tf.tile(tf.expand_dims(mask, axis=-1), (1, 1, 1, 6))\n        \n        total_loss = tf.reduce_sum(tf.abs(y_true - y_pred * mask))\n        reg_loss = total_loss \/ (tf.reduce_sum(mask) + 1e-4)\n        return reg_loss\n    \n    # 3. compile\n    model.compile(optimizer=Adam(),\n                   loss={'car_pose.1.1':l1_loss, 'confidence.1.1':focal_loss},\n                   loss_weights=[1, 1])\n    \n    # 4. fit\n    history = model.fit_generator(train_generator(train,batch_size=batch_size),\n                                  steps_per_epoch = len(train) \/\/ batch_size,\n                                  epochs = epoch\n                                  )\n    \n    model.save_weights('\/kaggle\/working\/centernet_weights.hdf5')\n    \n    plt.title(\"model loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epoch\")\n    plt.plot(history.history['loss'])","3584c0e2":"# \u597d\u50cf\u662f\u770b\u770b\u6709\u6c92\u6709\u906e\u7f69\uff08\u6709\u7684\u6c92\u6709\ndef TestMaskImages(imageName):\n    trainimage = cv2.imread(PATH  + \"\/test_images\/\" + imageName + '.jpg')\n    imagemask = cv2.imread(PATH + \"\/test_masks\/\" + imageName + \".jpg\",0)\n    try:\n        imagemaskinv = cv2.bitwise_not(imagemask)\n        res = cv2.bitwise_and(trainimage,trainimage,mask = imagemaskinv)\n        res = res[res.shape[0] \/\/ 2:]\n        return res\n    except:\n        trainimage = trainimage[trainimage.shape[0] \/\/ 2:]\n        return trainimage","ef2ae5c3":"# \u8a13\u7df4\u5b8c\u4e4b\u5f8c\u8f38\u51fa\u56c9\ndef predict(model):\n    modelx = CtDetDecode(model)\n    \n    def pred(i):\n        img = TestMaskImages(test['ImageId'][i])\n        img = resize_image(img)\n        X_batch = img[np.newaxis, :]\n\n        detections = modelx.predict(X_batch)\n        detections = np.squeeze(detections)\n\n\n        submission = []\n        for d in detections:\n            yaw, pitch, roll, x, y, z, score = d\n            if score < 0.3:\n                continue\n            else:\n                submission.append(d)\n\n        Prediction_string = coords_to_str(submission)\n        test['PredictionString'][i] = Prediction_string\n\n    for i in tqdm(range(len(test))):\n        pred(i)\n        \n    test.to_csv('submission.csv', index=False)","1703efc1":"# 1. set heads of HourglassNet\nkwargs = {\n        'num_stacks': 2,\n        'cnv_dim': 256,\n        'inres': (512, 512),\n        }\nheads = {\n        'car_pose': 6,\n        'confidence': 1\n        }\n\n# 2. create model\nmodel = HourglassNetwork(heads=heads, **kwargs)\n# model.load_weights('..\/input\/centernet-hg\/centernet_weights.hdf5', by_name=True)\n\n# 3. train\ntrain_model(model, epoch=3, batch_size=16)\n\n# 4.predict\npredict(model)","2bccaf69":"![](https:\/\/img-blog.csdnimg.cn\/20190716171510379.jpg?x-oss-process=image\/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NhaWt3NjI=,size_16,color_FFFFFF,t_70)","0d44b62f":"![](https:\/\/img-blog.csdnimg.cn\/20190716170729501.jpg)","8ebf0760":"[\u7576\u524d\u53c3\u8003\u7db2\u7ad9](https:\/\/www.kaggle.com\/diegojohnson\/centernet-objects-as-points\/data)","b8434b2b":"\u4ee5\u4e0b\u662f\u770b\u8d77\u4f86\u8d85\u96e3\u8d85\u770b\u4e0d\u61c2\u7684 model \u88fd\u4f5c","8d0e9784":"![](https:\/\/img-blog.csdnimg.cn\/20190716171120608.jpg?x-oss-process=image\/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NhaWt3NjI=,size_16,color_FFFFFF,t_70)","73995e90":"![](https:\/\/img-blog.csdnimg.cn\/20190716171157803.jpg?x-oss-process=image\/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NhaWt3NjI=,size_16,color_FFFFFF,t_70)"}}