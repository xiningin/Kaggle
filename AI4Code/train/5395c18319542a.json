{"cell_type":{"2662d749":"code","491ca45e":"code","77b30fc6":"code","db4e009e":"code","18c3c2a6":"code","6dd4ccfc":"code","4c968360":"code","2a263715":"code","8382cf56":"code","9528f83c":"code","b6f83935":"code","c73a9cd4":"code","48c004b7":"code","e23ec0c9":"code","0b0f007c":"code","9ca65928":"code","488efc75":"code","21980757":"code","41315b4b":"code","4f5bf558":"code","e5b4e5d4":"code","c62e93e3":"code","de6a745a":"code","601157fa":"code","d5131d29":"code","e07e47bf":"code","1bc6b1f7":"code","d3422777":"code","bfbd0ac9":"code","b462ba88":"code","7697ff00":"code","8b872ab9":"code","71802790":"code","4e098610":"code","3fff5b09":"code","a69fbd3d":"code","91dcd626":"code","669e9d9f":"code","f6f8ea75":"code","19316317":"code","57def861":"code","cae4088b":"markdown","a05e32d0":"markdown"},"source":{"2662d749":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","491ca45e":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport xgboost as xgb\n\n\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier, RidgeClassifierCV,Perceptron\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split, validation_curve, learning_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","77b30fc6":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncombine = [train_df, test_df]\n","db4e009e":"for dataset in combine:\n    dataset = dataset.drop(['Ticket', 'Cabin'], axis=1, inplace=True)","18c3c2a6":"for dataset in combine:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","6dd4ccfc":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","4c968360":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n\n    ","2a263715":"for dataset in combine:\n    dataset.drop(['Name'], axis=1, inplace=True)","8382cf56":"train_df.drop(['PassengerId'],  axis=1, inplace=True)","9528f83c":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)","b6f83935":"train_df['Embarked'].mode()\n","c73a9cd4":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","48c004b7":"train_df[['Embarked', 'Survived']].groupby('Embarked').mean()","e23ec0c9":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'Q': 1, 'C': 2}).astype(int)","0b0f007c":"def mean_age_for_class(dataset):\n    \n    mean_age_1class = dataset[dataset['Pclass'] == 1]['Age'].mean()\n    mean_age_2class = dataset[dataset['Pclass'] == 2]['Age'].mean()\n    mean_age_3class = dataset[dataset['Pclass'] == 3]['Age'].mean()\n    \n    mean_age_list = (mean_age_1class, mean_age_2class, mean_age_3class)\n    \n    return mean_age_list\n\nfor dataset in combine:\n    mean_age_list = mean_age_for_class(dataset)\n    print(mean_age_list)\n    ","9ca65928":"def fill_age_train(columns):\n    \n    Age = columns[0]\n    Pclass = columns[1]\n\n    \n    if pd.isnull(Age):\n        if (Pclass == 1):\n            return 38\n        elif (Pclass == 2):\n            return 30\n        elif (Pclass == 3):\n            return 25\n    else:\n        return Age\n        ","488efc75":"train_df['Age'] = train_df[['Age', 'Pclass']].apply(fill_age_train, axis=1)","21980757":"train_df.info()","41315b4b":"def fill_age_test(columns):\n    \n    Age = columns[0]\n    Pclass = columns[1]\n\n    \n    if pd.isnull(Age):\n        if (Pclass == 1):\n            return 41\n        elif (Pclass == 2):\n            return 29\n        elif (Pclass == 3):\n            return 24\n    else:\n        return Age","4f5bf558":"test_df['Age'] = test_df[['Age', 'Pclass']].apply(fill_age_test, axis=1)","e5b4e5d4":"test_df['Fare'].mean()","c62e93e3":"test_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True)","de6a745a":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch']","601157fa":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 0, 'IsAlone'] = 1","d5131d29":"train_df","e07e47bf":"for dataset in combine:\n    dataset = dataset.drop(['Parch', 'SibSp'], axis=1, inplace=True)","1bc6b1f7":"train_df[['IsAlone', 'Survived']].groupby(['IsAlone']).mean()","d3422777":"train_df.head()","bfbd0ac9":"age_bin_labels = [1, 2, 3, 4]\nfare_bin_labels = [1, 2, 3, 4, 5]\nfor dataset in combine:\n    dataset['Age'] =  pd.qcut(dataset['Age'], q=4, labels=age_bin_labels).astype(int)\n    dataset['Fare'] =  pd.qcut(dataset['Fare'], q=5, labels=fare_bin_labels).astype(int)","b462ba88":"X = train_df.drop('Survived', axis=1)\nY = train_df['Survived']\nX_test = test_df.drop('PassengerId', axis=1)","7697ff00":"X_train, X_val, y_train, y_val = train_test_split(X, Y, random_state=42)","8b872ab9":"parameters = {'n_estimators': [49, 50, 51],\n                  'max_depth': [4, 5, 6],\n                  'max_features': [3, 4, 5],\n             'min_samples_leaf': [9, 10,11, 12, 13]}\n\nrf = GridSearchCV(RandomForestClassifier(random_state=1, n_jobs=-1), parameters)\nrf.fit(X_train, y_train)\nrf_predict = rf.predict(X_val)\nrf.score(X_val, y_val)","71802790":"rf.best_estimator_","4e098610":"parameters = {'max_iter': [50, 100, 200, 300],\n                  'alpha': [0.09, 0.1, 0.2, 0.3, 0.4]}\n\nsgd = GridSearchCV(SGDClassifier(random_state=1, n_jobs=-1), parameters)\nsgd.fit(X_train, y_train)\nsgd_predict = sgd.predict(X_val)\nsgd.score(X_val, y_val)","3fff5b09":"sgd.best_params_","a69fbd3d":"parameters = {'max_iter': [25, 30, 35, 50, 100, 200, 300],\n                  'C': [0.09, 0.1, 0.2, 0,5,0.9,1, 2, 3, 4]}\n\nlog_reg = GridSearchCV(LogisticRegression(random_state=1, n_jobs=-1), parameters)\nlog_reg.fit(X_train, y_train)\nlog_reg_predict = log_reg.predict(X_val)\nlog_reg.score(X_val, y_val)","91dcd626":"log_reg.best_estimator_","669e9d9f":"rf_clf = RandomForestClassifier(max_depth=5, max_features=4, min_samples_leaf=11,\n                       n_estimators=50, n_jobs=-1, random_state=1)\nsgd_clf = SGDClassifier(alpha=0.1, max_iter=50, n_jobs=-1, random_state=0)\n\nbagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=5,\n                  max_samples=40, n_estimators=20, random_state=1)\n\nadaboost_clf = AdaBoostClassifier(base_estimator=LogisticRegression(random_state=1),\n                   learning_rate=0.9, n_estimators=21, random_state=1)\nlog_reg_clf = LogisticRegression(C=0.1, max_iter=25, random_state=1)\n","f6f8ea75":"voiting_clf = VotingClassifier(estimators=([('rf', rf_clf), ('bagg', bagging_clf), ('lr', log_reg_clf), ('ab', adaboost_clf)]))\nvoiting_clf.fit(X_train, y_train)\nvoiting_clf_predict = voiting_clf.predict(X_val)\nvoiting_clf.score(X_val, y_val)","19316317":"model = VotingClassifier(estimators=([('rf', rf_clf), ('bagg', bagging_clf), ('lr', log_reg_clf), ('ab', adaboost_clf)]))\nmodel.fit(X, Y)\npredict = model.predict(X_test)\n","57def861":"output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predict})\noutput.to_csv('my_submission_11.csv', index=False)","cae4088b":"**Binning**","a05e32d0":"**Handling outliars**"}}