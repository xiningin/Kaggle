{"cell_type":{"c4e64d06":"code","872acc6e":"code","aae87a80":"code","39b1fefc":"code","0523c6aa":"code","10d68140":"code","9f844e19":"code","03fdf163":"code","ccb44f73":"code","0f1467c6":"code","bca07d51":"code","085b9c4a":"code","cd34196b":"code","d10f51e3":"code","9d8b3d99":"code","21677871":"code","b7d06abf":"code","ec665e9f":"code","6271a816":"code","453bb4d9":"code","59911029":"code","106f7696":"code","8e6ede24":"markdown","b4b2fb5f":"markdown","9c8c1268":"markdown","c09c4cb5":"markdown"},"source":{"c4e64d06":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","872acc6e":"# import the necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","aae87a80":"import pandas as pd\ndata = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","39b1fefc":"# Start exploring the dataset\nprint(data.columns)\ndata.head()","0523c6aa":"# Print the shape of the data\n# data = data.sample(frac=0.1, random_state = 48)\nprint(data.shape)\nprint(data.describe())\n\n# V1 - V28 are the results of a PCA Dimensionality reduction to protect user identities and sensitive features","10d68140":"# distribution of Amount\namount = [data['Amount'].values]\nsns.distplot(amount)","9f844e19":"# distribution of Time\ntime = data['Time'].values\nsns.distplot(time)","03fdf163":"from matplotlib import gridspec\n# distribution of anomalous features\nfeatures = data.iloc[:,0:28].columns\n\nplt.figure(figsize=(12,28*4))\ngs = gridspec.GridSpec(28, 1)\nfor i, c in enumerate(data[features]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(data[c][data.Class == 1], bins=50)\n    sns.distplot(data[c][data.Class == 0], bins=50)\n    ax.set_xlabel('')\n    ax.set_title('histogram of feature: ' + str(c))\nplt.show()","ccb44f73":"# Plot histograms of each parameter \ndata.hist(figsize = (20, 20))\nplt.show()","0f1467c6":"# Determine number of fraud cases in dataset\n\nFraud = data[data['Class'] == 1]\nValid = data[data['Class'] == 0]\n\noutlier_fraction = len(Fraud)\/float(len(Valid))\nprint(outlier_fraction)\n\nprint('Fraud Cases: {}'.format(len(data[data['Class'] == 1])))\nprint('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))","bca07d51":"print(\"Amount details of fradulent transacation\")\nFraud.Amount.describe()","085b9c4a":"print(\"Amount details of valid transaction\")\nValid.Amount.describe()","cd34196b":"# Correlation matrix\ncorrmat = data.corr()\nfig = plt.figure(figsize = (12, 9))\n\nsns.heatmap(corrmat, vmax = .8, square = True)\nplt.show()","d10f51e3":"#seperating the X and the Y from the dataset\nX=data.drop(['Class'], axis=1)\nY=data[\"Class\"]\nprint(X.shape)\nprint(Y.shape)\n#getting just the values for the sake of processing (its a numpy array with no columns)\nX_data=X.values\nY_data=Y.values","9d8b3d99":"X_data","21677871":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\nX_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size = 0.2, random_state = 42)","b7d06abf":"from sklearn.metrics import classification_report, accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix","ec665e9f":"#Building another model\/classifier ISOLATION FOREST\nfrom sklearn.ensemble import IsolationForest\nifc=IsolationForest(max_samples=len(X_train),\n                    contamination=outlier_fraction,random_state=1)\nifc.fit(X_train)\nscores_pred = ifc.decision_function(X_train)\ny_pred = ifc.predict(X_test)\n\n\n# Reshape the prediction values to 0 for valid, 1 for fraud. \ny_pred[y_pred == 1] = 0\ny_pred[y_pred == -1] = 1\n\nn_errors = (y_pred != Y_test).sum()\n\n","6271a816":"#evaluation of the model\n#printing every score of the classifier\n#scoring in any thing\n\nfrom sklearn.metrics import confusion_matrix\nn_outliers = len(Fraud)\nprint(\"the Model used is {}\".format(\"Isolation Forest\"))\nacc= accuracy_score(Y_test,y_pred)\nprint(\"The accuracy is  {}\".format(acc))\nprec= precision_score(Y_test,y_pred)\nprint(\"The precision is {}\".format(prec))\nrec= recall_score(Y_test,y_pred)\nprint(\"The recall is {}\".format(rec))\nf1= f1_score(Y_test,y_pred)\nprint(\"The F1-Score is {}\".format(f1))\nMCC=matthews_corrcoef(Y_test,y_pred)\nprint(\"The Matthews correlation coefficient is{}\".format(MCC))\n\n#printing the confusion matrix\nLABELS = ['Normal', 'Fraud']\nconf_matrix = confusion_matrix(Y_test, y_pred)\nplt.figure(figsize=(12, 12))\nsns.heatmap(conf_matrix, xticklabels=LABELS,\n            yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()\n\n# Run classification metrics\nplt.figure(figsize=(9, 7))\nprint('{}: {}'.format(\"Isolation Forest\", n_errors))\nprint(accuracy_score(Y_test, y_pred))\nprint(classification_report(Y_test, y_pred))","453bb4d9":"# Building the Random Forest Classifier (RANDOM FOREST)\nfrom sklearn.ensemble import RandomForestClassifier\n# random forest model creation\nrfc = RandomForestClassifier()\nrfc.fit(X_train,Y_train)\n# predictions\ny_pred = rfc.predict(X_test)","59911029":"#Evaluating the classifier\n#printing every score of the classifier\n#scoring in any thing\nfrom sklearn.metrics import classification_report, accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix\nn_outliers = len(Fraud)\nn_errors = (y_pred != Y_test).sum()\nprint(\"The model used is Random Forest classifier\")\nacc= accuracy_score(Y_test,y_pred)\nprint(\"The accuracy is  {}\".format(acc))\nprec= precision_score(Y_test,y_pred)\nprint(\"The precision is {}\".format(prec))\nrec= recall_score(Y_test,y_pred)\nprint(\"The recall is {}\".format(rec))\nf1= f1_score(Y_test,y_pred)\nprint(\"The F1-Score is {}\".format(f1))\nMCC=matthews_corrcoef(Y_test,y_pred)\nprint(\"The Matthews correlation coefficient is {}\".format(MCC))\n\n\n#printing the confusion matrix\nLABELS = ['Normal', 'Fraud']\nconf_matrix = confusion_matrix(Y_test, y_pred)\nplt.figure(figsize=(12, 12))\nsns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()\n\n# Run classification metrics\nplt.figure(figsize=(9, 7))\nprint('{}: {}'.format(\"Random Forest\", n_errors))\nprint(accuracy_score(Y_test, y_pred))\nprint(classification_report(Y_test, y_pred))","106f7696":"#visualizing the random tree \nfeature_list = list(X.columns)\n# Import tools needed for visualization\nfrom IPython.display import Image\nfrom sklearn.tree import export_graphviz\nimport pydot\n\n#pulling out one tree from the forest\ntree = rfc.estimators_[5]\nexport_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n# Use dot file to create a graph\n(graph, ) = pydot.graph_from_dot_file('tree.dot')\n# Write graph to a png file\ndisplay(Image(graph.create_png()))","8e6ede24":"## Using Scikit-learn to split data into training and testing sets","b4b2fb5f":"## Reference\nhttps:\/\/medium.com\/analytics-vidhya\/credit-card-fraud-detection-in-python-using-scikit-learn-f9046a030f50\n","9c8c1268":"## Isolation Forest Classifier","c09c4cb5":"## Random Forest Classifier"}}