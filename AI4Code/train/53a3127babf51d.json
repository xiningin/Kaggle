{"cell_type":{"861d87e9":"code","49bb8f84":"code","99beb106":"code","2925d626":"code","23498064":"code","cb699388":"code","ae622b88":"code","025e76b5":"code","fcae7094":"code","7e30633a":"code","fc9ac667":"code","c0ab9a2d":"code","e2481097":"markdown","66ce3a43":"markdown","fae5b070":"markdown","ff90524e":"markdown","e91a5e58":"markdown","920b8424":"markdown","7c3449b1":"markdown","9c3417eb":"markdown","03f470af":"markdown","75b91560":"markdown","0132c799":"markdown","d7ac9fbd":"markdown"},"source":{"861d87e9":"# General\nimport numpy as np\nimport pandas as pd\nimport glob\nimport os\nimport PIL\nfrom PIL import Image\nimport cv2\nfrom collections import Counter\n\n# Encoding\nfrom sklearn import preprocessing\n\n\n# Visualizations\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Neural Network\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","49bb8f84":"print('Using:')\nprint('\\nPyTorch version:', torch.__version__)\nprint('\\n Running on GPU' if torch.cuda.is_available() else 'GPU device not found. Running on CPU')","99beb106":"device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n","2925d626":"class PlantPathology(Dataset):\n  def __init__(self,root_dir, image_names, labels, transform=None):\n    self.root_dir = root_dir\n    self.image_names = image_names\n    self.labels = labels\n    self.transform = transform\n\n  def __len__(self):\n    return len(self.labels)\n  \n  def __getitem__(self, index):\n\n    label = self.labels[index]\n    image = Image.open(os.path.join(self.root_dir, self.image_names[index]))\n    #image = cv2.imread(image_name)\n\n    if self.transform is not None:\n      image = self.transform(image)\n\n    return image, label","23498064":"def data_details(label_path, img_path):\n    '''\n    Input: Path to labels, path to images\n    Action: Get details of the labels and the images\n    Output: Details of labels and images\n    '''\n    # Label Details\n    df = pd.read_csv(label_path)\n    n_rows = df.shape[0]\n    n_classes = df['labels'].nunique()\n    classes = df['labels'].value_counts()\n    classes = classes.to_frame()\n    describe = df.describe()\n    classes = classes.apply(lambda x: round((x\/n_rows)*100,0))\n    duplicates = df[df.duplicated()]\n    \n    # Image Details\n    num_images = len([name for name in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, name))])\n    image_dimensions = []\n    \n    images = [name for name in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, name))]\n    \n    for name in images[:100]:\n        img = cv2.imread('..\/input\/plant-pathology-2021-fgvc8\/train_images\/'+name)\n        dim = (img.shape[1],img.shape[0])\n        image_dimensions.append(dim)\n    \n    dimensions = Counter(image_dimensions).keys() # equals to list(set(words))\n    dimensions_frequency = Counter(image_dimensions).values() # counts the elements' frequency\n    \n    print('Train Data Details')\n    print('\\n')\n    print('\\nShape of the label file: ', df.shape)\n    print('\\nData types of the columns:', df.info())\n    print('\\nData Description:', describe)\n    print('\\nTotal number of classes',n_classes)\n    print('\\nClasses:')\n    print('\\n',classes)\n    print('\\nRow duplicates:',duplicates)\n    print('\\nSample rows:')\n    print('\\n',df.head())\n    print('\\nIMAGE DETAILS')\n    print('\\nNumber of images in the training folder:',num_images)\n    print('\\nUnique dimensions from a sample of 100 images:',dimensions)\n    print('Frequencies of dimensions from a sample of 100 images:',dimensions_frequency)","cb699388":"def data_loader_exploration(data_loader):\n    '''\n    Input: Data loader\n    Action: Get batch details\n    Output: Batch details\n    '''\n    batch = next(iter(train_loader))\n    images, labels = batch\n    \n    print('\\nNumber of components in the batch:',len(batch))\n    print('Type of batch:',type(batch))\n    print('Shape of a batch:',images.shape)\n    print('Length of the batch:',len(images))\n    print('\\n')\n    grid = torchvision.utils.make_grid(images, nrow=10)\n    plt.figure(figsize=(15,15))\n    plt.imshow(np.transpose(grid, (1,2,0)))\n    print('\\nlabels:', labels)","ae622b88":"img_path = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\nlabel_path = '..\/input\/plant-pathology-2021-fgvc8\/train.csv'\ndata_details(label_path,img_path)","025e76b5":"train_df = pd.read_csv(label_path)\nlabel_encoder = preprocessing.LabelEncoder()\nlabel_encoder.fit(train_df['labels'])\ntrain_df['label_id'] = label_encoder.transform(train_df['labels'])\nlabels = train_df['label_id'].values\nimage_names = train_df['image'].values","fcae7094":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Resize((128, 128)),\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n)","7e30633a":"train_set = PlantPathology(root_dir=img_path,\n                           image_names=image_names,\n                           labels = labels,\n                           transform=transform)","fc9ac667":"train_loader = DataLoader(train_set,\n                          batch_size=64,\n                          shuffle=True)","c0ab9a2d":"data_loader_exploration(train_loader)","e2481097":"### 4. Define Data Loader","66ce3a43":"### 1. Label Encoding","fae5b070":"### 4. Functions","ff90524e":"### 3. Classes","e91a5e58":"## 3. Data Preparation","920b8424":"### 2. Notebook Configurations","7c3449b1":"### 1. Libraries","9c3417eb":"## 2. Raw Data Exploration","03f470af":"## 1. Configurations","75b91560":"### 3. Define Dataset","0132c799":"### 2. Data Transform","d7ac9fbd":"### 5. Loader Exploration"}}