{"cell_type":{"3c792521":"code","34d402f4":"code","e09d708e":"code","7e9e31b7":"code","1305e9ad":"code","504b56ef":"code","48a7039c":"code","4f4d3194":"code","7f8ee62d":"code","cd531b19":"code","1587ca1b":"code","c419cf6e":"code","b7b63464":"code","744e4f0c":"code","95c369ed":"code","fbd656ca":"code","7cf0ad53":"code","6a29d110":"code","a224e1ce":"code","35436a94":"code","d08a461d":"code","d57f32b6":"code","e946d8d4":"markdown"},"source":{"3c792521":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt","34d402f4":"IMAGE_SIZE = [224, 224]\n\ntrain_path = r'..\/input\/retinal-oct-c8\/RetinalOCT_Dataset\/train'\ntest_path = r'..\/input\/retinal-oct-c8\/RetinalOCT_Dataset\/test'\nval_path = r'..\/input\/retinal-oct-c8\/RetinalOCT_Dataset\/val'","e09d708e":"rn = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","7e9e31b7":"from tensorflow.python.client import device_lib\n\ndef get_available_gpus():\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos]\n\nget_available_gpus()\n\nfrom tensorflow.python.client import device_lib\ndef get_available_devices():\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos]\nprint(get_available_devices()) ","1305e9ad":"for layer in rn.layers:\n    layer.trainable = False","504b56ef":"folders = glob(train_path+'\\*')","48a7039c":"x = Flatten()(rn.output)","4f4d3194":"prediction = Dense(8, activation='softmax')(x)\nmodel = Model(inputs=rn.input, outputs=prediction)","7f8ee62d":"model.summary()","cd531b19":"import keras\nimport tensorflow as tf\nopt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=[\"acc\"]\n)","1587ca1b":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\nshear_range = 0.2,\nzoom_range = 0.2,\nhorizontal_flip = True)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\ntraining_set = train_datagen.flow_from_directory(directory=train_path,\ntarget_size = (224,224),\nbatch_size = 32,\nclass_mode = 'categorical')\ntest_set = test_datagen.flow_from_directory(directory=test_path,\ntarget_size = (224,224),\nbatch_size = 32,\nclass_mode = 'categorical')\nval_set = val_datagen.flow_from_directory(directory=val_path,\ntarget_size = (224,224),\nbatch_size = 32,\nclass_mode = 'categorical')","c419cf6e":"import time\ntime.ctime()","b7b63464":"import keras\nimport tensorflow as tf\n\nhistory = model.fit(\n  training_set,\n  validation_data=val_set,\n  epochs=20,\n  batch_size=256,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","744e4f0c":"time.ctime()","95c369ed":"model.save(\"InceptionV3.h5\")\nprint(\"Model Saved as : InceptionV3.h5\")","fbd656ca":"evl = model.evaluate(test_set)\nacc = evl[1]*100\nmsg=f'accuracy on the test set is {acc:5.2f} %'\nprint(msg)","7cf0ad53":"loss_train = history.history\nprint(loss_train)","6a29d110":"def print_info( test_gen, preds, print_code, save_dir, subject ):\n    class_dict=test_gen.class_indices\n    labels= test_gen.labels\n    file_names= test_gen.filenames \n    error_list=[]\n    true_class=[]\n    pred_class=[]\n    prob_list=[]\n    new_dict={}\n    error_indices=[]\n    y_pred=[]\n    for key,value in class_dict.items():\n        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n    # store new_dict as a text fine in the save_dir\n    classes=list(new_dict.values())     # list of string of class names     \n    errors=0      \n    for i, p in enumerate(preds):\n        pred_index=np.argmax(p)         \n        true_index=labels[i]  # labels are integer values\n        if pred_index != true_index: # a misclassification has occurred\n            error_list.append(file_names[i])\n            true_class.append(new_dict[true_index])\n            pred_class.append(new_dict[pred_index])\n            prob_list.append(p[pred_index])\n            error_indices.append(true_index)            \n            errors=errors + 1\n        y_pred.append(pred_index)    \n    if print_code !=0:\n        if errors>0:\n            if print_code>errors:\n                r=errors\n            else:\n                r=print_code           \n            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n            print_in_color(msg, (0,255,0),(55,65,80))\n            for i in range(r):                \n                split1=os.path.split(error_list[i])                \n                split2=os.path.split(split1[0])                \n                fname=split2[1] + '\/' + split1[1]\n                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n                print_in_color(msg, (255,255,255), (55,65,60))\n                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n        else:\n            msg='With accuracy of 100 % there are no errors to print'\n            print_in_color(msg, (0,255,0),(55,65,80))\n    if errors>0:\n        plot_bar=[]\n        plot_class=[]\n        for  key, value in new_dict.items():        \n            count=error_indices.count(key) \n            if count!=0:\n                plot_bar.append(count) # list containg how many times a class c had an error\n                plot_class.append(value)   # stores the class \n        fig=plt.figure()\n        fig.set_figheight(len(plot_class)\/3)\n        fig.set_figwidth(10)\n        plt.style.use('fivethirtyeight')\n        for i in range(0, len(plot_class)):\n            c=plot_class[i]\n            x=plot_bar[i]\n            plt.barh(c, x, )\n            plt.title( ' Errors by Class on Test Set')\n    y_true= np.array(labels)        \n    y_pred=np.array(y_pred)\n    if len(classes)<= 30:\n        # create a confusion matrix \n        cm = confusion_matrix(y_true, y_pred )        \n        length=len(classes)\n        if length<8:\n            fig_width=8\n            fig_height=8\n        else:\n            fig_width= int(length * .5)\n            fig_height= int(length * .5)\n        plt.figure(figsize=(fig_width, fig_height))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n    clr = classification_report(y_true, y_pred, target_names=classes)\n    print(\"Classification Report:\\n----------------------\\n\", clr)","a224e1ce":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True) # returns default print color to back to black\n    return","35436a94":"import seaborn as sns\nimport os\nsns.set_style('darkgrid')\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow import keras\nmodel = keras.models.load_model('..\/input\/retinal-oct-xception\/VGG19.h5')\n\np = model.predict(test_set)\nprint_info( test_set, p, 10, r'.\/', 'Retinal OCT' )","d08a461d":"loss_train = (history.history['acc'])\nloss_val = (history.history['val_acc'])\nloss_val.append(loss_train[18])\nprint(loss_train, \"ll\",loss_val)\nepochs = range(1,20)\nplt.plot(epochs, np.array(loss_train), 'g', label='Training accuracy')\nplt.plot(epochs, np.array(loss_val), 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","d57f32b6":"loss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1,15)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","e946d8d4":"# "}}