{"cell_type":{"fe1191ba":"code","dcc7b194":"code","91ec7d8f":"code","4b024dd7":"code","a3d375a6":"code","677e7ae0":"code","d56f8355":"code","72c80427":"code","36b92f30":"code","6621ca9b":"code","df8f79c5":"code","aef0e5c8":"code","ae180383":"code","4f9b4eda":"code","b40257e4":"code","d31e53b9":"code","057f1a95":"code","e6a8970d":"code","da5e157d":"code","e2e58185":"code","deab74b7":"code","9d4ba1fc":"code","99ead1c3":"code","2a51a753":"code","7aa51bd1":"code","2f69d0ba":"code","316c68b1":"code","604c6298":"code","33e9604d":"code","e538cfa4":"code","cb5a7e38":"code","34ecc110":"code","a760bd2d":"code","c8ab778b":"code","50a7c13f":"code","b392462c":"code","c1696cfd":"code","e2dfb44c":"markdown","cd4fa531":"markdown","75242a89":"markdown","2f5b1d46":"markdown"},"source":{"fe1191ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dcc7b194":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics","91ec7d8f":"#Data Preprocessing ","4b024dd7":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","a3d375a6":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","677e7ae0":"\n\ntrain_data.dtypes","d56f8355":"train_data.columns","72c80427":"train_data.describe(include='all')","36b92f30":"test_data.columns","6621ca9b":"target= train_data['Survived']\ntarget.shape","df8f79c5":"train_data.drop(['Survived'], axis=1, inplace = True)","aef0e5c8":"train_data.shape","ae180383":"train1=train_data\ntest1=test_data\n\nprint('Ready to concatinate!')","4f9b4eda":"df = pd.concat([train1, test1], axis=0,sort=False)\ndf.shape","b40257e4":"df.isnull().sum()","d31e53b9":"PassengerId=test_data.PassengerId\nPassengerId.shape","057f1a95":"df.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)\n","e6a8970d":"df.shape","da5e157d":"\ndf.fillna(df.median(), inplace=True)","e2e58185":"df.describe(include='all')","deab74b7":"df.isnull().sum()","9d4ba1fc":"df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)","99ead1c3":"df.isnull().sum()","2a51a753":"df = pd.get_dummies(df, columns=['Pclass', 'Sex', 'SibSp', 'Parch','Embarked'])\n","7aa51bd1":"df.head()","2f69d0ba":"df_train = df.iloc[:891,:]\n\ndf_test = df.iloc[891:,:]\n\nprint(\"Shape of new dataframes - {} , {}\".format(df_train.shape, df_test.shape))","316c68b1":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics","604c6298":"df_train = preprocessing.StandardScaler().fit(df_train).transform(df_train)\ndf_train[0:5]","33e9604d":"x_train,x_test,y_train,y_test = train_test_split(df_train,target,test_size=0.33,random_state=0)","e538cfa4":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nmodel = RandomForestClassifier()","cb5a7e38":"parameter_grid = {'bootstrap': [True],\n                    'max_depth': [80, 90, 100, 110],\n                    'max_features': [2, 3],\n                     'min_samples_leaf': [3, 4, 5],\n                     'min_samples_split': [8, 10, 12],\n                        'n_estimators': [100, 200, 300]}\n\ngrid_search = GridSearchCV(model, param_grid = parameter_grid,\n                          cv =10)\n\ngrid_search.fit(x_train, y_train)\n\nprint (\"Best Score: {}\".format(grid_search.best_score_))\nprint (\"Best params: {}\".format(grid_search.best_params_))","34ecc110":"model = RandomForestClassifier(bootstrap=True, max_depth= 110, max_features= 2, min_samples_leaf= 3, min_samples_split= 8, n_estimators= 100)","a760bd2d":"model.fit(x_train,y_train)\npred=model.predict(x_test)","c8ab778b":"from sklearn.metrics import classification_report,log_loss,f1_score, accuracy_score\nprint(classification_report(y_test,pred))\nprint('\\n')\nprint('F1-SCORE : ',f1_score(y_test,pred,average=None))\nprint('\\n')\nprint('Train Accuracy: ', accuracy_score(y_train, model.predict(x_train))*100,'%')","50a7c13f":"\ndf_test = preprocessing.StandardScaler().fit(df_test).transform(df_test)\ndf_test[0:5]","b392462c":"model.fit(df_train,target)\nprediction=model.predict(df_test)","c1696cfd":"output = pd.DataFrame({'PassengerId': PassengerId, 'Survived': prediction})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e2dfb44c":"Data Preprocessing","cd4fa531":"From the counts, it is aparent that there are missing scores. Ther are various ways to take care of this but mean would be used.\n\nThe missing data for 'Cabin' is too huge: 77.1%. Hence, the column will be dropped.","75242a89":"It is important to check that the correct data types are used.","2f5b1d46":"Then, lets take care of the missing values."}}