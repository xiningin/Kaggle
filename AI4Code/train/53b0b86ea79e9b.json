{"cell_type":{"e61115da":"code","de94b445":"code","d01eac52":"code","f5467f65":"code","84ad4ced":"code","bf2d5940":"code","fde67844":"code","d9fb6db3":"code","daeabe68":"code","f05a1f99":"code","3c4e6e7d":"code","e89c5565":"code","76e089f4":"code","e678f62a":"code","473a1b26":"code","5a6078ec":"code","0240a0b7":"code","1d04a4db":"code","765d9327":"code","2f94773f":"code","60de7204":"code","99adf6d2":"code","d12556be":"code","103c2ef9":"code","91d71f16":"code","e1072e1c":"code","6aaa16d8":"code","9377ecf9":"code","59617b0f":"code","163af3d1":"code","63ed4467":"code","6e629903":"code","2f02b70d":"code","7f97717c":"code","57ce62d9":"code","75f1c9b2":"code","5fcee29c":"code","2ca77c69":"code","2242b102":"code","1e73b880":"code","8e238cec":"code","92fcbcd9":"code","c986d20e":"code","61dd737c":"code","08759250":"code","6313b47f":"code","50153f1d":"code","d5b01bae":"code","0d49f42b":"code","30dbd25b":"code","76ddf6fc":"code","a8bd1546":"code","8dacdaae":"code","606d5e30":"code","f3c00ee3":"code","9882bf06":"code","fdc46b26":"code","140e1dbb":"code","92318c8e":"code","2d64f5f0":"code","48d7d6e9":"code","ca5e66bf":"code","39c6708e":"code","9e350d99":"code","75fb274c":"code","7287989a":"code","db7a7f8e":"code","8526fd1d":"code","b5e98197":"code","17dcc716":"code","af36696e":"code","0aca25cc":"code","e6f1a808":"code","15dc1a20":"code","71e3b03c":"code","e0757e83":"code","bcb2497e":"code","cd688da6":"code","a9353b69":"code","e2f577c5":"code","cbbac12e":"code","984a8990":"code","e86e8aa4":"code","81ef9075":"markdown","c935f07a":"markdown","3ce447ce":"markdown","0a086cdb":"markdown","55c7a473":"markdown","e3feced0":"markdown","eb42f27e":"markdown","6b73256e":"markdown","415708f0":"markdown","a3646db5":"markdown","05747b00":"markdown","f26cbb5b":"markdown","6a95dae5":"markdown","89cb7b10":"markdown","e2e8d477":"markdown","47d363ef":"markdown","b9911e81":"markdown","5a09c7a8":"markdown","60eca828":"markdown","52ffb016":"markdown","97e58b8b":"markdown","0f652d6a":"markdown","733cab85":"markdown","26da8f67":"markdown"},"source":{"e61115da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de94b445":"#DATA\ntrain=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest=pd.read_csv(\"..\/input\/titanic\/test.csv\")","d01eac52":"train.head()","f5467f65":"test.head()","84ad4ced":"#check for missing data\ntrain.isnull().sum()","bf2d5940":"test.isnull().sum()","fde67844":"sns.set_style('whitegrid')\nsns.countplot(x='Survived', data=train, palette='autumn')","d9fb6db3":"#survival dependent on gender\n#0=Died, 1=Alive\nsns.set_style('whitegrid')\nsns.countplot(x='Survived', hue='Sex', data=train, palette='autumn')","daeabe68":"#survival dependent on passenger class\nsns.set_style('whitegrid')\nsns.countplot(x='Survived', hue='Pclass', data=train, palette='autumn_r')","f05a1f99":"#distrbution of ages of passengers\ntrain['Age'].hist(bins=45, color='orange')","3c4e6e7d":"#distribution of Sibilings and Spouse\nsns.countplot(x='SibSp',data=train, palette='autumn_r')","e89c5565":"#Approximately average fare\ntrain['Fare'].hist(color='orange', bins=100, alpha=0.8, figsize=(16,5))","76e089f4":"#TRAINING SET\nimport plotly.express as px\npx.violin(train, x='Pclass', y='Age', color='Pclass', box=True, hover_data=train)","e678f62a":"#Replacing NAN values with\n#Pclass=1, Age=37\n#Pclass=2, Age=29\n#Pclass=3, Age=24\ndef fill_age(data):#data will consist of Age and Pclass respectively\n    age=data[0]\n    Pclass=data[1]\n    if pd.isnull(age):\n        if Pclass==1:  \n            return 37\n        elif Pclass==2:  \n            return 29\n        else:  \n            return 24\n    else:\n        return age","473a1b26":"train['Age']=train[['Age', 'Pclass']].apply(fill_age, axis=1)","5a6078ec":"px.violin(test, x='Pclass', y='Age', color='Pclass', box=True, hover_data=test)","0240a0b7":"#Replacing NAN values with\n#Pclass=1, Age=42\n#Pclass=2, Age=26.5\n#Pclass=3, Age=24\ndef fill_age1(data):#data will consist of Age and Pclass respectively\n    age=data[0]\n    Pclass=data[1]\n    if pd.isnull(age):\n        if Pclass==1:  \n            return 42\n        elif Pclass==2:  \n            return 26.5\n        else:  \n            return 24\n    else:\n        return age","1d04a4db":"test['Age']=test[['Age', 'Pclass']].apply(fill_age1, axis=1)","765d9327":"train.info()","2f94773f":"test.info()","60de7204":"#since Cabin is an alphanumeric data and it consists of huge NAN values, it will be difficult to replace, hence we drop it\ntrain.drop('Cabin', axis=1, inplace=True)\ntest.drop('Cabin', axis=1, inplace=True)","99adf6d2":"test['Fare'].mean","d12556be":"#A Fare value is missing, we shall replace it with the median value\ntest['Fare']=test['Fare'].fillna(7.8292)\ntest['Fare']=test['Fare'].astype('float')","103c2ef9":"train.info()","91d71f16":"test.info()","e1072e1c":"train.head()","6aaa16d8":"test.head()","9377ecf9":"#for Embarked\n'''dropped the first column because thee categoriescan be represented by \n00 for C\n10 for Q\n01 for S'''\nembark_train=pd.get_dummies(train['Embarked'], drop_first=True)\nembark_test=pd.get_dummies(test['Embarked'], drop_first=True)","59617b0f":"#For Sex\n'''1 for male\n0 for female'''\nsex_train=pd.get_dummies(train['Sex'], drop_first=True)\nsex_test=pd.get_dummies(test['Sex'], drop_first=True)","163af3d1":"#dropping the Name, Ticket, Sex and Embarked column\ntrain.drop(['Sex', 'Name', 'Ticket', 'Embarked'], axis=1, inplace=True)\ntest.drop(['Sex', 'Name', 'Ticket', 'Embarked'], axis=1, inplace=True)","63ed4467":"#appending the new categorical columns to dataframe\ntrain=pd.concat([train, embark_train, sex_train], axis=1)\ntest=pd.concat([test, embark_test, sex_test], axis=1)","6e629903":"train.head()","2f02b70d":"test.head()","7f97717c":"X_train=train.drop('Survived', axis=1)\ny_train=train['Survived']\nX_test=test","57ce62d9":"\n#testing with one of the 1% submissions\nsubmit=pd.read_csv('..\/input\/ideal-submission\/submission2.csv')\ny_test=submit['Survived']","75f1c9b2":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()","5fcee29c":"#parameter grid\nparams={'penalty' : ['l1', 'l2', 'elasticnet'],\n        'C' : [0.001,0.005,0.01,0.1,0.5,1],\n        'max_iter' : [1000,5000],\n        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\nfrom sklearn.model_selection import RandomizedSearchCV\ncv=RandomizedSearchCV(estimator=lr,\n                      param_distributions=params,\n                      n_iter=50,\n                      n_jobs=-1,\n                      random_state=45)\ncv.fit(X_train, y_train)","2ca77c69":"cv.best_estimator_","2242b102":"lr=LogisticRegression(C=0.5, max_iter=1000, penalty='l1', solver='liblinear')\nlr.fit(X_train, y_train)\ny_pred_lr=lr.predict(X_test)","1e73b880":"from sklearn.metrics import accuracy_score\nacc_lr=round(accuracy_score(y_test, y_pred_lr)*100, 2)\nacc_lr","8e238cec":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()","92fcbcd9":"#parameter grid\nparams={'n_estimators' : [100,200,500,1000],\n        'criterion' : ['gini', 'entropy'],\n        'max_features' : ['auto', 'sqrt', 'log2'],\n        'bootstrap': [True],}\ncv=RandomizedSearchCV(estimator=rf,\n                      param_distributions=params,\n                      n_jobs=-1,\n                      random_state=45)\ncv.fit(X_train, y_train)","c986d20e":"cv.best_estimator_","61dd737c":"rf=RandomForestClassifier(criterion='entropy', max_features='sqrt')\nrf.fit(X_train, y_train)\ny_pred_rf=rf.predict(X_test)","08759250":"acc_rf=round(accuracy_score(y_test, y_pred_rf)*100, 2)\nacc_rf","6313b47f":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()","50153f1d":"#parameter grid\nparams={'splitter' : ['best', 'random'],\n        'criterion' : ['gini', 'entropy'],\n        'max_features' : ['auto', 'sqrt', 'log2']}\ncv=RandomizedSearchCV(estimator=dt,\n                      param_distributions=params,\n                      n_jobs=-1,\n                      verbose=5,\n                      random_state=45)\ncv.fit(X_train, y_train)","d5b01bae":"cv.best_estimator_","0d49f42b":"dt=DecisionTreeClassifier(criterion='entropy', max_features='log2')\ndt.fit(X_train,y_train)\ny_pred_dt=dt.predict(X_test)","30dbd25b":"acc_dt=round(accuracy_score(y_test, y_pred_dt)*100, 2)\nacc_dt","76ddf6fc":"from xgboost import XGBClassifier\nxg=XGBClassifier()","a8bd1546":"#parameter grid\nparams={'booster' : ['gbtree', 'dart'],\n        'learning_rate' : [0.03, 0.06, 0.1, 0.15, 0.2],\n        'objective' : ['reg:logistic', 'binary:logistic']}\ncv=RandomizedSearchCV(estimator=xg,\n                      param_distributions=params,\n                      n_iter=25,\n                      n_jobs=-1,\n                      verbose=5,\n                      random_state=45)\ncv.fit(X_train, y_train)","8dacdaae":"cv.best_estimator_","606d5e30":"xg=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.03, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=None, monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n              objective='reg:logistic', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)\nxg.fit(X_train,y_train)\ny_pred_xg=xg.predict(X_test)","f3c00ee3":"acc_xg=round(accuracy_score(y_test, y_pred_xg)*100, 2)\nacc_xg","9882bf06":"from sklearn.svm import SVC\nsvc=SVC()","fdc46b26":"#parameter grid\nparams={'C' : [0.01,0.05,0.1,0.5,1],\n        'kernel' : ['rbf', 'sigmoid', 'poly'],\n        'degree' : [2,3,4,5]}\ncv=RandomizedSearchCV(estimator=svc,\n                      param_distributions=params,\n                      n_iter=25,\n                      n_jobs=-1,\n                      verbose=5,\n                      random_state=45)\ncv.fit(X_train, y_train)","140e1dbb":"cv.best_estimator_","92318c8e":"svc=SVC(C=1, degree=2, kernel='poly')\nsvc.fit(X_train, y_train)\ny_pred_svm=svc.predict(X_test)","2d64f5f0":"acc_svm=round(accuracy_score(y_test, y_pred_svm)*100, 2)\nacc_svm","48d7d6e9":"from sklearn.linear_model import SGDClassifier\nsgd=SGDClassifier()","ca5e66bf":"#parameter grid\nparams={'penalty' : ['l1', 'l2', 'elasticnet'],\n        'max_iter' : [500,1000,2000,5000],\n        'shuffle': [True]}\ncv=RandomizedSearchCV(estimator=sgd,\n                      param_distributions=params,\n                      n_iter=25,\n                      n_jobs=-1,\n                      verbose=5,\n                      random_state=45)\ncv.fit(X_train, y_train)","39c6708e":"cv.best_estimator_","9e350d99":"sgd=SGDClassifier(max_iter=2000, penalty='elasticnet')\nsgd.fit(X_train, y_train)\ny_pred_sgd=sgd.predict(X_test)","75fb274c":"acc_sgd=round(accuracy_score(y_test, y_pred_sgd)*100, 2)\nacc_sgd","7287989a":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()","db7a7f8e":"#parameter grid\nparams={'weights' : ['uniform', 'distance'],\n        'n_neighbors' : [3,4,5],\n        'algorithm' : ['ball-tree', 'kd_tree', 'brute'],\n        'p' : [1,2,3]}\ncv=RandomizedSearchCV(estimator=knn,\n                      param_distributions=params,\n                      n_iter=25,\n                      n_jobs=-1,\n                      verbose=5,\n                      random_state=45)\ncv.fit(X_train, y_train)","8526fd1d":"cv.best_estimator_","b5e98197":"knn=KNeighborsClassifier(algorithm='kd_tree', n_neighbors=3, p=1,\n                         weights='distance')\nknn.fit(X_train, y_train)\ny_pred_knn=knn.predict(X_test)","17dcc716":"acc_knn=round(accuracy_score(y_test, y_pred_knn)*100, 2)\nacc_knn","af36696e":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(X_train, y_train)\ny_pred_nb=nb.predict(X_test)","0aca25cc":"acc_nb=round(accuracy_score(y_test, y_pred_nb)*100, 2)\nacc_nb","e6f1a808":"from sklearn.linear_model import Perceptron\nper=Perceptron()","15dc1a20":"#parameter grid\nparams={'max_iter' : [500,1000,2000],\n        'penalty' : ['l1', 'l2', 'elasticnet']}\ncv=RandomizedSearchCV(estimator=per,\n                      param_distributions=params,\n                      n_iter=9,\n                      n_jobs=-1,\n                      verbose=5,\n                      random_state=45)\ncv.fit(X_train, y_train)","71e3b03c":"cv.best_estimator_","e0757e83":"per=Perceptron(max_iter=500, penalty='l2')\nper.fit(X_train, y_train)\ny_pred_per=per.predict(X_test)","bcb2497e":"acc_per=round(accuracy_score(y_test, y_pred_per)*100, 2)\nacc_per","cd688da6":"from sklearn.svm import LinearSVC\nlin_svm=LinearSVC(penalty=\"l1\",dual=False,max_iter=5000)\nlin_svm.fit(X_train, y_train)\ny_pred_lin_svm=lin_svm.predict(X_test)","a9353b69":"acc_lin_svm=round(accuracy_score(y_test, y_pred_lin_svm)*100, 2)\nacc_lin_svm","e2f577c5":"sorted_models=pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest', 'Decision Tree',\n              'XG Boost', 'SVM', 'Stochastic Gradient Decent', 'KNN',\n              'Naive Bayes', 'Perceptron', 'Linear SVC'],\n    'Score': [acc_lr, acc_rf, acc_dt, acc_xg, acc_svm, \n              acc_sgd, acc_knn, acc_nb, acc_per, acc_lin_svm]})\nsorted_models=sorted_models.sort_values(by='Score', ascending=False)\nprint(sorted_models.to_string(index=False))","cbbac12e":"plt.figure(figsize=(20,10))\nplt.bar(sorted_models['Model'], sorted_models['Score'])","984a8990":"submission=pd.DataFrame({'PassengerId':X_test['PassengerId'],\n                         'Survived':y_pred_rf})\nsubmission.to_csv('submission2.csv', index=False)","e86e8aa4":"submission=pd.read_csv('submission2.csv')\nsubmission.info()","81ef9075":"# 7. KNN","c935f07a":"# 4. XGBoost","3ce447ce":"# Sorting the models according to accuracy score","0a086cdb":"# **Converting Sex and Embarked in to Categorical Values**","55c7a473":"# 8. Gaussian Naive Bayes","e3feced0":"# 10. Linear SVM","eb42f27e":"# ****TRAINING****","6b73256e":"# 9. Perceptron","415708f0":"No change!!","a3646db5":"# 1. Logistic Regression","05747b00":"# **Creating CSV for Submission**","f26cbb5b":" # **EDA**","6a95dae5":"Slight increase from 64% to 68%","89cb7b10":"With optimization accuracy score was improved from 85% to 88%","e2e8d477":"Ridiculous drop from 65 to 36 ","47d363ef":"# 3. Decision Tree","b9911e81":"Accuracy increases slightly from 87% to 89%","5a09c7a8":"# 5. SVM","60eca828":"Very slight improvement from 65% to 66%","52ffb016":"No improvement after optimization.","97e58b8b":"# **Filling in missing values for age**","0f652d6a":"# 2. Random Forest","733cab85":"Score increased from somewhere around 65 to 81","26da8f67":"# 6. Stochastic Gradient Descent"}}