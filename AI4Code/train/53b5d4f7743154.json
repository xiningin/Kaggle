{"cell_type":{"0e6aed3b":"code","598868da":"code","91a65047":"code","e44f8479":"code","b4a568a1":"code","a37e028f":"code","d3c5f2ad":"code","958e0d0a":"code","fd0fdb02":"code","dd242209":"code","2f868773":"code","d2e7b03e":"code","8694a876":"code","a9bb87bd":"code","f64549bf":"code","2493c32e":"code","bab13f20":"code","a190fd3e":"code","81b599a7":"code","fdee44b3":"code","20570775":"code","c06330f9":"code","8e61e255":"code","57948121":"code","fcc2aed2":"code","520e8571":"code","a2758445":"code","aaa40085":"code","34371cb1":"code","1480481a":"code","671385c4":"code","f3e25fd6":"code","23da3a8b":"code","93d74a76":"code","dd7c88d0":"code","0e8c6424":"code","d5bc9b3b":"code","c29cc955":"code","a412ab81":"code","4d680d11":"code","b4a17634":"code","6d67c76f":"code","96482654":"code","638bd6a2":"code","d6b81641":"code","d754583f":"code","87a83058":"code","aefefd48":"code","4f2810ed":"code","c80f5c4a":"code","e5393d9e":"code","15ec1424":"code","e01c1b1d":"code","00e3bde9":"code","1bc9edf4":"code","2105fd01":"code","32f40446":"code","333c707e":"code","181db7ed":"code","121f4909":"code","b92065c9":"code","39f009c2":"code","48732415":"markdown","bbffd33a":"markdown","2956d814":"markdown","8479eecd":"markdown","e9e6091a":"markdown","5986f114":"markdown","704cbe5d":"markdown","8de665cb":"markdown","73d5b089":"markdown","86fd790e":"markdown","99cfdcfe":"markdown","0f2e4e10":"markdown","81c2315e":"markdown","8d975906":"markdown","0c82cf5f":"markdown","66fc97df":"markdown","15eec3f2":"markdown","4497747b":"markdown","45d80936":"markdown","518be3aa":"markdown","a5c2f55f":"markdown","c65ad7e6":"markdown","d00839e9":"markdown","941b31a4":"markdown","eec6d274":"markdown","ed21efa2":"markdown","3c8054d7":"markdown","5f7b594c":"markdown","80b146f3":"markdown","3f095785":"markdown","b7e63ece":"markdown","625d3fa1":"markdown"},"source":{"0e6aed3b":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom glob import glob \nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom skimage.util import montage as montage2d\nfrom skimage.io import imread\nimport matplotlib.gridspec as gridspec\nimport matplotlib.ticker as ticker\nsns.set_style('whitegrid')","598868da":"base_dir = os.path.join('..', 'input', 'pulmonary-chest-xray-abnormalities')\nall_xray_df = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\nall_xray_df.sample(5)\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data',  'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])","91a65047":"all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['Pneumonia'] = all_xray_df['Finding Labels'].map(lambda x: 'Pneumonia' in x)\nall_xray_df['Patient Age'] = np.clip(all_xray_df['Patient Age'], 5, 100)\nall_xray_df['Patient Male'] = all_xray_df['Patient Gender'].map(lambda x: x.upper()=='M').astype('float32')\nall_xray_df.sample(3)","e44f8479":"g = sns.factorplot(x=\"Patient Age\", col=\"Patient Gender\",data=all_xray_df, kind=\"count\",size=10, aspect=0.8,palette=\"GnBu_d\");\ng.set_xticklabels(np.arange(0,100));\ng.set_xticklabels(step=10);\ng.fig.suptitle('Age distribution by sex',fontsize=22);\ng.fig.subplots_adjust(top=.9)","b4a568a1":"pathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\nfor pathology in pathology_list :\n    all_xray_df[pathology] = all_xray_df['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\nplt.figure(figsize=(15,10))\ngs = gridspec.GridSpec(8,1)\nax1 = plt.subplot(gs[:7, :])\nax2 = plt.subplot(gs[7, :])\ndata1 = pd.melt(all_xray_df,\n             id_vars=['Patient Gender'],\n             value_vars = list(pathology_list),\n             var_name = 'Category',\n             value_name = 'Count')\ndata1 = data1.loc[data1.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data1, ax=ax1, order = data1['Category'].value_counts().index)\nax1.set( ylabel=\"\",xlabel=\"\")\nax1.legend(fontsize=20)\nax1.set_title('X Ray partition (total number = 121120)',fontsize=18);\n\nall_xray_df['Nothing']=all_xray_df['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)\n\ndata2 = pd.melt(all_xray_df,\n             id_vars=['Patient Gender'],\n             value_vars = list(['Nothing']),\n             var_name = 'Category',\n             value_name = 'Count')\ndata2 = data2.loc[data2.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data2,ax=ax2)\nax2.set( ylabel=\"\",xlabel=\"Number of decease\")\nax2.legend('')\nplt.subplots_adjust(hspace=.5)\nall_xray_df['Pneumonia'] = all_xray_df['Finding Labels'].map(lambda x: 'Pneumonia' in x)","a37e028f":"g=sns.countplot(x='Patient Age', hue=\"Patient Gender\",data=all_xray_df[all_xray_df['Pneumonia']==True])\nx=np.arange(0,100,10)\ng.set_xlim(0,90)\ng.set_xticks(x)\ng.set_xticklabels(x)","d3c5f2ad":"df=all_xray_df.groupby('Finding Labels').count().sort_values('Patient ID',ascending=False)\ndf1=df[['|' in index for index in df.index]].copy()\ndf2=df[['|' not in index for index in df.index]]\ndf2=df2[['No Finding' not in index for index in df2.index]]\ndf2['Finding Labels']=df2.index.values\ndf1['Finding Labels']=df1.index.values\nf, ax = plt.subplots(sharex=True,figsize=(15, 10))\nsns.set_color_codes(\"pastel\")\ng=sns.countplot(y='Category',data=data1, ax=ax, order = data1['Category'].value_counts().index,color='b',label=\"Multiple Pathologies\")\nsns.set_color_codes(\"muted\")\ng=sns.barplot(x='Patient ID',y='Finding Labels',data=df2, ax=ax, color=\"b\",label=\"Simple Pathology\")\nax.legend(ncol=2, loc=\"center right\", frameon=True,fontsize=20)\nax.set( ylabel=\"\",xlabel=\"Number of decease\")\nax.set_title(\"Comparison between simple or multiple decease\",fontsize=20)      \nsns.despine(left=True)","958e0d0a":"#we just keep groups of pathologies which appear more than 30 times\ndf3=df1.loc[df1['Patient ID']>30,['Patient ID','Finding Labels']]\nfor pathology in pathology_list:\n    df3[pathology]=df3.apply(lambda x: x['Patient ID'] if pathology in x['Finding Labels'] else 0, axis=1)\ndf4=df3[df3['Pneumonia']>0]\nif df4.size>0:\n    plt.pie(df4['Pneumonia'],labels=df4['Finding Labels'], autopct='%1.1f%%')\n    plt.title('Pneumonia',fontsize=14) ","fd0fdb02":"positive_cases = np.sum(all_xray_df['Pneumonia']==True)\/\/2\noversample_factor = 4 # maximum number of cases in negative group so it isn't super rare\nmore_balanced_df = all_xray_df.groupby(['Patient Gender', 'Pneumonia']).apply(lambda x: x.sample(min(oversample_factor*positive_cases, x.shape[0]), \n                                                                                   replace = False)\n                                                      ).reset_index(drop = True)\n\nprint(more_balanced_df['Pneumonia'].value_counts())\nsns.pairplot(more_balanced_df[['Patient Age', 'Pneumonia']], hue='Pneumonia')","dd242209":"from sklearn.model_selection import train_test_split\nraw_train_df, test_valid_df = train_test_split(more_balanced_df, \n                                   test_size = 0.30, \n                                   random_state = 2018,\n                                   stratify = more_balanced_df[['Pneumonia', 'Patient Gender']])\nvalid_df, test_df = train_test_split(test_valid_df, \n                                   test_size = 0.40, \n                                   random_state = 2018,\n                                   stratify = test_valid_df[['Pneumonia', 'Patient Gender']])\nprint('train', raw_train_df.shape[0], 'validation', valid_df.shape[0], 'test', test_df.shape[0])\nprint('train', raw_train_df['Pneumonia'].value_counts())\nprint('test', test_df['Pneumonia'].value_counts())\nraw_train_df.sample(1)","2f868773":"train_df = raw_train_df.groupby(['Pneumonia']).apply(lambda x: x.sample(2000, replace = True)\n                                                      ).reset_index(drop = True)\nprint('New Data Size:', train_df.shape[0], 'Old Size:', raw_train_df.shape[0])","d2e7b03e":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\nfrom PIL import Image\nIMG_SIZE = (512, 512) # slightly smaller than vgg16 normally expects\ncore_idg = ImageDataGenerator(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip=False, \n                              vertical_flip=False, \n                              height_shift_range=0.1, \n                              width_shift_range=0.1, \n                              brightness_range=[0.7, 1.5],\n                              rotation_range=3, \n                              shear_range=0.01,\n                              fill_mode='nearest',\n                              zoom_range=0.125,\n                             preprocessing_function=preprocess_input)","8694a876":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    df_gen = img_data_gen.flow_from_dataframe(in_df,\n                                              x_col=path_col,\n                                              y_col=y_col,\n                                     class_mode = 'raw',\n                                    **dflow_args)\n    return df_gen","a9bb87bd":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 8)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 400)) # one big batch\n# used a fixed dataset for final evaluation\nfinal_test_X, final_test_Y = next(flow_from_dataframe(core_idg, \n                               test_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 400)) # one big batch","f64549bf":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -127, vmax = 127)\n    c_ax.set_title('%s' % ('Pneumonia' if c_y>0.5 else 'Healthy'))\n    c_ax.axis('off')","2493c32e":"base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n                              include_top = False, weights = 'imagenet')\nbase_pretrained_model.trainable = False","bab13f20":"from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\nfrom keras.models import Model\npt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\npt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\nfrom keras.layers import BatchNormalization\nbn_features = BatchNormalization(name='Features_BN')(pt_features)","a190fd3e":"attn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\nattn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\nattn_layer = Conv2D(1, \n                    kernel_size = (1,1), \n                    padding = 'valid', \n                    activation = 'sigmoid',\n                   name='AttentionMap2D')(attn_layer)","81b599a7":"# fan it out to all of the channels\nup_c2_w = np.ones((1, 1, 1, pt_depth))\nup_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', name='UpscaleAttention',\n               activation = 'linear', use_bias = False, weights = [up_c2_w])\nup_c2.trainable = False\nattn_layer = up_c2(attn_layer)","fdee44b3":"mask_features = multiply([attn_layer, bn_features])\ngap_features = GlobalAveragePooling2D()(mask_features)\ngap_mask = GlobalAveragePooling2D()(attn_layer)\n# to account for missing values from the attention model\ngap = Lambda(lambda x: x[0]\/x[1], name = 'RescaleGAP')([gap_features, gap_mask])","20570775":"gap_dr = Dropout(0.5)(gap)\ndr_steps = Dropout(0.5)(Dense(128, activation = 'elu')(gap_dr))\nout_layer = Dense(1, activation = 'sigmoid')(dr_steps)\nattn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\nattn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\nattn_model.summary()\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cardio_attn')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=10) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]\n\n","c06330f9":"from keras.models import Sequential\nfrom keras.optimizers import Adam\nVGG16_attn_model = Sequential(name = 'combined_model')\nbase_pretrained_model.trainable = False\nVGG16_attn_model.add(base_pretrained_model)\nVGG16_attn_model.add(attn_model)\nVGG16_attn_model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\nVGG16_attn_model.summary()","8e61e255":"from keras.utils.vis_utils import model_to_dot\nfrom IPython.display import Image\nImage(model_to_dot(attn_model, show_shapes=True).create_png())","57948121":"Image(model_to_dot(VGG16_attn_model, show_shapes=True).create_png())","fcc2aed2":"train_gen.batch_size = 24\nhistory_vgg16_attn = VGG16_attn_model.fit_generator(train_gen, \n                      validation_data = (test_X, test_Y), \n                       steps_per_epoch=train_gen.n\/\/train_gen.batch_size,\n                      epochs = 30, \n                      callbacks = callbacks_list,\n                      workers = 3)","520e8571":"VGG16_attn_model.load_weights(weight_path)","a2758445":"# get the attention layer since it is the only one with a single output dim\nfor attn_layer in attn_model.layers:\n    c_shape = attn_layer.get_output_shape_at(0)\n    if len(c_shape)==4:\n        if c_shape[-1]==1:\n            print(attn_layer)\n            break","aaa40085":"import keras.backend as K\nrand_idx = np.random.choice(range(len(test_X)), size = 6)\nattn_func = K.function(inputs = [attn_model.get_input_at(0), K.learning_phase()],\n           outputs = [attn_layer.get_output_at(0)]\n          )\nfig, m_axs = plt.subplots(len(rand_idx), 2, figsize = (8, 4*len(rand_idx)))\n[c_ax.axis('off') for c_ax in m_axs.flatten()]\nfor c_idx, (img_ax, attn_ax) in zip(rand_idx, m_axs):\n    cur_img = test_X[c_idx:(c_idx+1)]\n    cur_features = base_pretrained_model.predict(cur_img)\n    attn_img = attn_func([cur_features, 0])[0]\n    img_ax.imshow(cur_img[0,:,:,0], cmap = 'bone')\n    attn_ax.imshow(attn_img[0, :, :, 0], cmap = 'viridis', \n                   vmin = 0, vmax = 1, \n                   interpolation = 'lanczos')\n    real_label = test_Y[c_idx]\n    img_ax.set_title('Cardio\\nClass:%s' % (real_label))\n    pred_confidence = VGG16_attn_model.predict(cur_img)[0]\n    attn_ax.set_title('Attention Map\\nPred:%2.1f%%' % (100*pred_confidence[0]))\nfig.savefig('attention_map.png', dpi = 300)","34371cb1":"pred_Y = VGG16_attn_model.predict(test_X, \n                          batch_size = 32, \n                          verbose = True)","1480481a":"valid_loss0, valid_acc0 = VGG16_attn_model.evaluate(test_X, test_Y, verbose=2) # 5\/2020 nt: use validation set\nprint (\"valid_accuracy=%s, valid_loss=%s\" % (valid_acc0, valid_loss0))","671385c4":"from sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\nprint(classification_report(test_Y, pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))","f3e25fd6":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(test_Y, pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","23da3a8b":"final_pred_Y = VGG16_attn_model.predict(final_test_X, \n                          batch_size = 4, \n                          verbose = True)","93d74a76":"valid_loss1, valid_acc1 = VGG16_attn_model.evaluate(final_test_X, final_test_Y, verbose=2) # 5\/2020 nt: use validation set\nprint (\"valid_accuracy=%s, valid_loss=%s\" % (valid_acc1, valid_loss1))","dd7c88d0":"plt.matshow(confusion_matrix(final_test_Y, final_pred_Y>0.5))\nprint(classification_report(final_test_Y, final_pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))","0e8c6424":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(final_test_Y, final_pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","d5bc9b3b":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nmobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\nmobilenet_GAP_model = Sequential()\nmobilenet_GAP_model.add(mobilenet_model)\nmobilenet_GAP_model.add(GlobalAveragePooling2D())\nmobilenet_GAP_model.add(Dropout(0.5))\nmobilenet_GAP_model.add(Dense(512))\nmobilenet_GAP_model.add(Dropout(0.5))\nmobilenet_GAP_model.add(Dense(1, activation = 'sigmoid'))\nmobilenet_GAP_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmobilenet_GAP_model.summary()","c29cc955":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]\n","a412ab81":"history_mobilenet_GAP = mobilenet_GAP_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_data = (test_X, test_Y), \n                                  epochs = 10, \n                                  callbacks = callbacks_list)\nhistory_mobilenet_GAP = mobilenet_GAP_model.fit_generator(train_gen, \n                                  steps_per_epoch = 100,\n                                  validation_data =  (test_X, test_Y), \n                                  epochs = 5, \n                                  callbacks = callbacks_list)","4d680d11":"pred_Y = mobilenet_GAP_model.predict(test_X, \n                          batch_size = 32, \n                          verbose = True)","b4a17634":"from sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\nprint(classification_report(test_Y, pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))","6d67c76f":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(test_Y, pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'mobilenet-GAP-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","96482654":"final_pred_Y = mobilenet_GAP_model.predict(final_test_X, \n                          batch_size = 4, \n                          verbose = True)","638bd6a2":"plt.matshow(confusion_matrix(final_test_Y, final_pred_Y>0.5))\nprint(classification_report(final_test_Y, final_pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))","d6b81641":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(final_test_Y, final_pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'mobilenet-GAP-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","d754583f":"def plot_history(histories, key='loss'):\n  plt.figure(figsize=(16,10))\n    \n  for name, history in histories:\n    val = plt.plot(history.epoch, history.history['val_'+key],\n                   '--', label=name.title()+' Val')\n    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n             label=name.title()+' Train')\n\n  plt.xlabel('Epochs')\n  plt.ylabel(key.replace('_',' ').title())\n  plt.legend()\n\n  plt.xlim([0,max(history.epoch)])","87a83058":"plot_history([('VGG18-Attn-GAP', history_vgg16_attn),\n              ('MobileNet-GAP', history_mobilenet_GAP)\n              ])","aefefd48":"IMG_SIZE = (64, 64)\ntrain_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 8)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 400)) # one big batch\n# used a fixed dataset for final evaluation\nfinal_test_X, final_test_Y = next(flow_from_dataframe(core_idg, \n                               test_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 400)) # one big batch","4f2810ed":"t_x, t_y = next(train_gen)","c80f5c4a":"import time\n\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import regularizers, initializers, optimizers\n\nVanilla_CNNRGB_model = Sequential()\n\nVanilla_CNNRGB_model.add(Conv2D(filters=16, \n                 kernel_size=7,\n                 padding='same', \n                 activation='relu', \n                 input_shape=t_x.shape[1:]))\nVanilla_CNNRGB_model.add(MaxPooling2D(pool_size=2))\n\nVanilla_CNNRGB_model.add(Conv2D(filters=32, \n                 kernel_size=5,\n                 padding='same', \n                 activation='relu'))\nVanilla_CNNRGB_model.add(MaxPooling2D(pool_size=2))\n\nVanilla_CNNRGB_model.add(Conv2D(filters=64, \n                 kernel_size=5,\n                 padding='same', \n                 activation='relu'))\nVanilla_CNNRGB_model.add(MaxPooling2D(pool_size=2))\n\nVanilla_CNNRGB_model.add(Conv2D(filters=128, \n                 kernel_size=5,\n                 strides=2,\n                 padding='same', \n                 activation='relu'))\nVanilla_CNNRGB_model.add(MaxPooling2D(pool_size=2))\n\nVanilla_CNNRGB_model.add(Flatten())\nVanilla_CNNRGB_model.add(Dense(100, activation='relu'))\nVanilla_CNNRGB_model.add(Dense(1, activation='sigmoid'))\n\nVanilla_CNNRGB_model.summary()\n","e5393d9e":"Vanilla_CNNRGB_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])","15ec1424":"from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\nimport numpy as np\n\nepochs = 20\n\nstart = time.time()\n\nhistory_VanillaRGB = Vanilla_CNNRGB_model.fit_generator(train_gen,steps_per_epoch = 100,\n          validation_data=(test_X, test_Y),\n          epochs=epochs,  callbacks=callbacks_list)\n\n# Show total training time\nprint(\"training time: %.2f minutes\"%((time.time()-start)\/60))","e01c1b1d":"pred_Y = Vanilla_CNNRGB_model.predict(test_X, \n                          batch_size = 32, \n                          verbose = True)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\nprint(classification_report(test_Y, pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))","00e3bde9":"final_pred_Y = Vanilla_CNNRGB_model.predict(final_test_X, \n                          batch_size = 4, \n                          verbose = True)\n\nplt.matshow(confusion_matrix(final_test_Y, final_pred_Y>0.5))\nprint(classification_report(final_test_Y, final_pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(final_test_Y, final_pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'Vanilla_RGB-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","1bc9edf4":"import time\n\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\nfrom keras.models import Sequential, Model\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import regularizers, applications, optimizers, initializers\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbase_model = applications.VGG16(weights='imagenet', \n                                include_top=False, \n                                input_shape=t_x.shape[1:])\n\nadd_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n# add_model.add(Conv2D(filters=512, \n#                  kernel_size=4, \n#                  strides=2, \n# #                  kernel_regularizer=regularizers.l2(0.01),\n# #                  activity_regularizer=regularizers.l1(0.01),\n#                  kernel_initializer=initializers.random_normal(stddev=0.01), \n#                  padding='same', \n#                  activation='relu', \n#                  input_shape=base_model.output_shape[1:]))\n# # add_model.add(MaxPooling2D(pool_size=2))\n# add_model.add(BatchNormalization())\n# add_model.add(Flatten())\n# add_model.add(Dropout(0.2))\n# add_model.add(Dense(1024, activation='relu'))\nadd_model.add(Dropout(0.2))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dropout(0.2))\nadd_model.add(Dense(50, activation='relu'))\nadd_model.add(Dropout(0.2))\nadd_model.add(Dense(1, activation='sigmoid'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n\nmodel.summary()\nadd_model.summary()","2105fd01":"from keras.optimizers import Adam\nmodel.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])","32f40446":"train_gen.batch_size = 24\nhistory_optimized_cnn = model.fit_generator(train_gen, \n                      validation_data = (test_X, test_Y), \n                       steps_per_epoch=train_gen.n\/\/train_gen.batch_size,\n                      epochs = 30, \n                      callbacks = callbacks_list,\n                      workers = 3)","333c707e":"pred_Y = model.predict(test_X, \n                          batch_size = 32, \n                          verbose = True)","181db7ed":"from sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\nprint(classification_report(test_Y, pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))","121f4909":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(test_Y, pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'Optimized-CNN-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","b92065c9":"\nfinal_pred_Y = model.predict(final_test_X, \n                          batch_size = 4, \n                          verbose = True)","39f009c2":"plt.matshow(confusion_matrix(final_test_Y, final_pred_Y>0.5))\nprint(classification_report(final_test_Y, final_pred_Y>0.5, target_names = ['Healthy', 'Pneumonia']))\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(final_test_Y, final_pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'Optimized-CNN-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')","48732415":"#### Test Data","bbffd33a":"## Data Augmentation","2956d814":"# Model 4: Optimized CNN","8479eecd":"## PreTrained Features\n\nwe generate the pretrained features for a large batch of images to accelerate the training process","e9e6091a":"### Evaluate the Model","5986f114":"### Attention\n\nWe do an attention mechanism to turn pixels in the GAP on an off. It basically outputs a spatial mask of which regions of the pretrained feature map we want to use. It is a very simple 'segmentation' of the feature map without looking into neighborhood.","704cbe5d":"# Model 2: MobileNet and GAP","8de665cb":"## **Overview**\n\nThis notebook demonstrates models that could be used to classify Pneumonia from Chest X-rays","73d5b089":"### Model Evaluation","86fd790e":"### Global Weighted Average Pooling\n\nWe now want to use the attention layer to weight the regions we want during the average pooling. A standard average pooling layer is poorly suited to this task since many of the values (presumably) will be zero and they will be counted. So we hand-rig a 'weighted average pooling' where we multiply the attention by the features and then divide by the sum of the attention\nThe formula for weighted average from [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Weighted_arithmetic_mean)\n$$ \\bar{x} = \\frac{ \\sum\\limits_{i=1}^n w_i x_i}{\\sum\\limits_{i=1}^n w_i} $$\nWhat we do is\n$$ \\text{GWAP}(x, y, d) = \\frac{ \\sum\\limits_{x}\\sum\\limits_{y} \\text{Attention}(x,y,d) \\text{Feature}(x,y,d)} {\\sum\\limits_{x}\\sum\\limits_{y} \\text{Attention}(x,y,d)} $$","99cfdcfe":"### Show Attention ","0f2e4e10":"### Dropout and Classification\n\nWe know take the output of this global weighted-average pooling and go to a classification with dropout and two fully connected layers","81c2315e":"### Model Validation","8d975906":"## Import Data","0c82cf5f":"# Model 1: VGG 16 with Attention and GAP","66fc97df":"# Model 3: Vanilla CNN with RGB Images","15eec3f2":"## Balance the distribution in the training data","4497747b":"### OverSampling","45d80936":"## Build the Whole Model","518be3aa":"### Attention Model\n\nThe basic idea is that a Global Average Pooling is too simplistic since some of the regions are more relevant than others. So we build an attention mechanism to turn pixels in the GAP on an off before the pooling and then rescale (Lambda layer) the results based on the number of pixels. The model could be seen as a sort of 'global weighted average' pooling. It is largely based on the insight that the winning solution annotated and trained a UNET model to segmenting the hand and transforming it.\n\n### Preprocessing\n\nwe take the output of the pretrained model and apply BatchNormalization\n","a5c2f55f":"## Split Data in Training, Test and Validation","c65ad7e6":"#### Validation Data","d00839e9":"### Preprocessing","941b31a4":"### Split Data","eec6d274":"#### Validation data","ed21efa2":"### Model Evaluation","3c8054d7":"## Exploratory Data Analysis","5f7b594c":"### Rescale Attention\n\nWe rescale the feature dimension back out to the original number of features (instead of just 1) by using a hard-coded convolution.\n","80b146f3":"# **DSC 672: Predictive Analytics Capstone**\n\n## Authors: Rohit Kothari and Sachinder Katoch","3f095785":"## Import Libraries","b7e63ece":"#### Test Data","625d3fa1":"#### Validation Data"}}