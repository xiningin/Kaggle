{"cell_type":{"21208588":"code","601d20f0":"code","6dfb7b0a":"code","23c7b0bf":"code","d604489a":"code","dea667fe":"code","58449689":"code","044035a6":"code","bc07e80f":"code","2ef057ad":"code","9cfdd644":"code","1a8d2f39":"markdown","6e496cb2":"markdown","2882f03d":"markdown","898b3025":"markdown","c22da02b":"markdown","7518a2ce":"markdown","0ce33a20":"markdown","730d1b7f":"markdown","0612603f":"markdown","0650aba5":"markdown","a61cea7e":"markdown","a46d064c":"markdown","78a52428":"markdown","f61f89d6":"markdown","2a262ea4":"markdown","62f605d4":"markdown","26634421":"markdown"},"source":{"21208588":"import spacy\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.base import TransformerMixin\nfrom sklearn.pipeline import Pipeline","601d20f0":"# Loading TSV file\ndf_amazon = pd.read_csv(\"\/kaggle\/input\/amazon-alexa-reviews\/amazon_alexa.tsv\",sep=\"\\t\")\n\nprint(f'Shape of data: {df_amazon.shape}')\n# Show top 5 records\ndf_amazon.head()","6dfb7b0a":"df_amazon.info()","23c7b0bf":"df_amazon.feedback.value_counts()","d604489a":"import string\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n# Create our list of punchuationmarks\npunctuations = string.punctuation\n\n# Create our list of stop words\nnlp = spacy.load('en')\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\n\n# Load English tokenizer, tagger, parser, NER and word vector\nparser = English()\n\n# Creating our tokenzer function\ndef spacy_tokenizer(sentence):\n    \"\"\"This function will accepts a sentence as input and processes the sentence into tokens, performing lemmatization, \n    lowercasing, removing stop words and punctuations.\"\"\"\n    \n    # Creating our token object which is used to create documents with linguistic annotations\n    mytokens = parser(sentence)\n    \n    # lemmatizing each token and converting each token in lower case\n    # Note that spaCy uses '-PRON-' as lemma for all personal pronouns lkike me, I etc\n    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n    \n    # Removing stop words\n    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations]\n    \n    # Return preprocessed list of tokens\n    return mytokens    ","dea667fe":"# Custom transformer using spaCy\nclass predictors(TransformerMixin):\n    def transform(self, X, **transform_params):\n        \"\"\"Override the transform method to clean text\"\"\"\n        return [clean_text(text) for text in X]\n    \n    def fit(self, X, y= None, **fit_params):\n        return self\n    \n    def get_params(self, deep= True):\n        return {}\n\n# Basic function to clean the text\ndef clean_text(text):\n    \"\"\"Removing spaces and converting the text into lowercase\"\"\"\n    return text.strip().lower()    ","58449689":"bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range = (1,1))","044035a6":"tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)","bc07e80f":"from sklearn.model_selection import train_test_split\n\nX = df_amazon['verified_reviews'] # The features we want to analyse\nylabels = df_amazon['feedback'] # The labels, in this case feedback\n\nX_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size = 0.3, random_state = 1)\nprint(f'X_train dimension: {X_train.shape}')\nprint(f'y_train dimension: {y_train.shape}')\nprint(f'X_test dimension: {X_test.shape}')\nprint(f'y_train dimension: {y_test.shape}')","2ef057ad":"# Logistic regression classifier\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression()\n\n# Create pipeline using Bag of Words\npipe = Pipeline ([(\"cleaner\", predictors()),\n                 (\"vectorizer\", bow_vector),\n                 (\"classifier\", classifier)])\n\n# Model generation\npipe.fit(X_train, y_train)","9cfdd644":"from sklearn import metrics\n\n# Predicting with test dataset\npredicted = pipe.predict(X_test)\n\n# Model accuracy score\nprint(f'Logistic Regression Accuracy: {metrics.accuracy_score(y_test, predicted)}')\nprint(f'Logistic Regression Precision: {metrics.precision_score(y_test, predicted)}')\nprint(f'Logistic Regression Recall: {metrics.recall_score(y_test, predicted)}')","1a8d2f39":"# Tokenizing the Text\n* We will use spaCy library for word tokenization\n* We will import pythons string module, which contains a helpful list of all punctuation marks that we can use in string.punctuation\n* We will import spaCy English language model\n* We will also import spaCy STOP_WORDS model, which will be used to remove stop words from review text","6e496cb2":"# Introduction\n\nText classification is one of the most basic use case of NLP. We are going to use spaCy library to perform text classification. Below are the few important steps we follow while text classification.\n* If text comes with labels then it becomes supervised learning problem else we have to treat it as an unsupervised learning problem.\n* In case of text with labels we can directly start with data cleaning but if labels are unknown for given text then we have to perform clustering(K-Means Clustering) to group the given text and identify the clusters of the text for better classification. Then based on common theme in each cluster we can create label for text classification.\n* Post data cleaning, we perform the feature extraction\n* And then we feed the data to our machine learning models to perform the classification.\n\ntodo-Replace below img with modified one\n\n![text-classification-python-spacy](https:\/\/www.dataquest.io\/wp-content\/uploads\/2019\/04\/text-classification-python-spacy.png)\n* Image from Dataquest tutorial","2882f03d":"# Understanding the Data\n* It has five columns: rating, date, variation, verified_reviews, feedback.\n* rating denotes the rating each user gave the Alexa (out of 5). \n* date indicates the date of the review\n* variation describes which model the user reviewed.\n* verified_reviews contains the text of each review\n* feedback contains a sentiment label, with 1 denoting positive sentiment (the user liked it) and 0 denoting negative sentiment (the user didn\u2019t).","898b3025":"# Create Train and Test Datasets\n* We are going to create train and test datasets\n* Train dataset will be used to train the model and test dataset to test the model performance\n* For more detail about splitting the dataset, please refer [Train Test Split](https:\/\/satishgunjal.com\/train_test_split\/)","c22da02b":"# Creating a Pipeline and Generating the Model\n* We are going to use LogisticRegression classifier for review classification. For more details about logistic regression please refer [Logistic Regression From Scratch With Python](https:\/\/satishgunjal.github.io\/binary_lr\/), [Binary Logistic Regression Using Sklearn](https:\/\/satishgunjal.github.io\/binary_lr_sklearn\/), [Multiclass Logistic Regression Using Sklearn](https:\/\/satishgunjal.github.io\/multiclass_lr_sklearn\/)\n* Our pipeline contains three components a cleaner, a vectorizer and a classifier\n    * Cleaner: Cleaner uses our 'predictors' class object to clean and preprocess the text.\n    * Vectorizer: Vectorizer uses 'CountVectorizer' object to create the bag of words matrix for our text.\n    * Classifier: It just performs the logistic regression to classify the sentiments.\n* Once our pipeline is built, we will fit the pipeline components using fit()","7518a2ce":"# Import Libraries\n* spaCy: spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.\n* pandas: Used for data manipulation and analysis\n* sklearn's CountVectorizer: Convert a collection of text documents to a matrix of token counts\n* sklearn's TfidfVectorizer: Convert a collection of raw documents to a matrix of TF-IDF features.\n* sklearn's TransformerMixin: Mixin class for all transformers in scikit-learn.\n* sklearn's Pipeline: Sequentially apply a list of transforms and a final estimator.","0ce33a20":"# Feature Engineering\nRemember that, the objective of this exercise is to predict whether an Amazon Alexa product review is positive or negative based on review text. And as of now we are manager to clean our text but in order our model to understand it we must convert it into numeric format.\n\n## Vectorization \n* Note that labels (feedback 0 and 1 in this case) are already in numeric format\n* We are going to use **Bag of Words(BoW)** to convert text into numeric format.\n* BoW converts text into the matrix of occurrence of words within a given document. It focuses on whether given word occurred or not in given document and generate the matrix called as **BoW matrix\/Document Term Matrix**\n* We are going to use sklearn's [CountVectorizer](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html) to generate BoW matrix.\n* In CountVectorizer we will use custom tokenizer 'spacy_tokenizer' and ngram range to define the combination of adjacent words. So unigram means sequence of single word and bigrams means sequence of 2 continuous words like wise n means sequence of n continuous words.\n* In this example we are going to use unigram, so our lower and upper bound of ngram range will be (1,1)","730d1b7f":"# Data Cleaning\n* We will create custom transformer to clean the tokenized data\n* We will create a custom predictors class which inherits the TransformerMixin class. This class overrides the transform, fit and get_parrams methods. We\u2019ll also create a clean_text() function that removes spaces and converts text into lowercase.\n* *In object-oriented programming languages, a mixin (or mix-in) is a class that contains methods for use by other classes without having to be the parent class of those other classes.*","0612603f":"# Tutorial: Text Classification Using spaCy\n\nIn this tutorial we are going to perform very simple text analysis operations with spaCy library and  build our own machine learning model with scikit-learn. Objective of this exercise is to predict whether a Amazon Alexa product review is positive or negative based on review text.\n\nThis tutorial is based on [dataquest tutorial](https:\/\/www.dataquest.io\/blog\/tutorial-text-classification-in-python-using-spacy\/). I will keep updating this new details.","0650aba5":"# Loading Data","a61cea7e":"# Model Score\n* Since our model is trained using training data, we can now use test data for model evaluation\n* Below are the few metrics that we will use to evaluate our model\n    * Accuracy refers to the percentage of the total predictions our model makes that are completely correct.\n    * Precision describes the ratio of true positives to true positives plus false positives in our predictions.\n    * Recall describes the ratio of true positives to true positives plus false negatives in our predictions.\n* All three metrics are measured from 0 to 1, where 1 is predicting everything completely correctly.","a46d064c":"## TF-IDF\n* We are also going to look at **TF-IDF(Term Frequency-Inverse Document Frequency)**. This is helpful to normalize our BoW by looking at each word's frequency in comparison to document frequency.\n* In other words, it's a way of representing how important a particular term is, in the context of given document based on how many times that term appears and in how many documents it appears.\n* Higher value of TF-IDF signifies the importance of the term to that document. We can represent this with following mathematical equation.\n\n  ![tf_idf_math_equation](https:\/\/raw.githubusercontent.com\/satishgunjal\/images\/master\/tf_idf_math_equation.png)","78a52428":"So overall, our model correctly identified a comment\u2019s sentiment 93.96% of the time. When it predicted a review was positive, that review was actually positive 94.82% of the time. When handed a positive review, our model identified it as positive 98.85% of the time","f61f89d6":"# Objective\n* Objective of this exercise is to predict whether an Amazon Alexa product review is positive or negative based on review text. \n* This dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various Amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc. for learning how to train machine for sentiment analysis.\n* Data is in tab separated file.","2a262ea4":"As yopu can see we have very few reviews with negative feedback, so it may create problem during classification","62f605d4":"## Data Information","26634421":"## Feedback Value Class Distribution"}}