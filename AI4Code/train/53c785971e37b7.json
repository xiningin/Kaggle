{"cell_type":{"b60f92fe":"code","2a157eba":"code","d39af7f9":"code","edbc1c77":"code","59a41576":"code","67d2813e":"code","526af691":"code","b20705ed":"code","449e404d":"code","c5d1e479":"code","8e4c82eb":"code","cf0ea52e":"code","04133636":"code","5a13df34":"code","657391a0":"code","6753fd8b":"code","a25d5ed4":"code","c9c987b1":"code","953b92b3":"code","f99f2861":"code","aaf95942":"markdown","ca59d048":"markdown","68f6b01b":"markdown","a356831d":"markdown","bdb7cc19":"markdown","f709caf3":"markdown","331c0e94":"markdown","e2c12a53":"markdown","055834b4":"markdown","c9a4526d":"markdown","7fc223a6":"markdown","0d649e3e":"markdown","506d176b":"markdown"},"source":{"b60f92fe":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# just for adding little bit of styles\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\nimport warnings\nwarnings.filterwarnings('ignore')","2a157eba":"traindf = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntestdf = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\ntestid = testdf['id']\ntraindf = traindf.drop(columns=['id'], axis=1)\ntestdf = testdf","d39af7f9":"print(traindf.shape, testdf.shape)","edbc1c77":"traindf.head()","59a41576":"traindf.describe()","67d2813e":"traindf.info()","526af691":"def show_null(df):\n    return df.isnull().sum().sort_values(ascending=False)","b20705ed":"show_null(traindf)","449e404d":"show_null(testdf)","c5d1e479":"null_cols = [i for i in traindf.columns if (traindf[i].isnull().sum() > 0)]\ntmp_data = traindf.copy()\ntotal_size = 40000\nfor i in null_cols:\n    \n    plt.figure(figsize=(5, 5))\n    null_values_count = traindf[i].isnull().sum()\n    data = [total_size-null_values_count, null_values_count]\n    labels = ['not null', 'null']\n    explode = [0, 0.1]\n    plt.title('Percentage of null values present in ' + i)\n    plt.pie(data, labels=labels, autopct='%.2f', explode=explode)\n    plt.show()","8e4c82eb":"# checking unique in traindf\nunique_arr = []\nfor i in traindf.columns:\n    tmp = traindf[i].unique()\n    if(len(tmp) <= 5):\n        print(i, \"---->\", tmp)\n        unique_arr.append(i)","cf0ea52e":"def plot_distribution(df):\n    for i in df.columns:\n        plt.figure(figsize=(8, 4))\n        sns.distplot(df[i])\n        plt.title(\"distribution of \" + i)\n        plt.show()\n        \n        \nplot_distribution(traindf)","04133636":"plt.figure(figsize=(6, 4))\nsns.countplot(traindf['song_popularity'])\nplt.show()","5a13df34":"plt.figure(figsize=(14, 10))\nsns.heatmap(traindf.corr(), cmap='RdBu', center=0, annot=True)","657391a0":"plt.figure(figsize=(8, 4))\nsns.kdeplot(traindf['song_duration_ms'], hue=traindf['song_popularity'])\nplt.show()","6753fd8b":"plt.figure(figsize=(8, 4))\nsns.kdeplot(traindf['acousticness'], hue=traindf['song_popularity'])\nplt.show()","a25d5ed4":"plt.figure(figsize=(8, 4))\nsns.kdeplot(traindf['danceability'], hue=traindf['song_popularity'])\nplt.show()","c9c987b1":"plt.figure(figsize=(10, 4))\nsns.countplot(traindf['key'], hue=traindf['song_popularity'])\nplt.show()","953b92b3":"plt.figure(figsize=(8, 4))\nsns.kdeplot(traindf['liveness'], hue=traindf['song_popularity'])\nplt.show()","f99f2861":"plt.figure(figsize=(8, 4))\nsns.kdeplot(traindf['speechiness'], hue=traindf['song_popularity'])\nplt.show()","aaf95942":"# Basic Imports\n For getting started this libraries are best.\n ","ca59d048":"# analyze impact of each feature in song_popularity\n- with reference with correlation matrix","68f6b01b":"# Tried to make a good notebook. \n## please feel free to comment your suggestions \ud83d\ude42","a356831d":"# count of unique values in data","bdb7cc19":"#### this is not too bad, ","f709caf3":"# Correlation between features","331c0e94":"## key points to note : \n* there are 40k observations in train-data and 10k in test-data\n* id column is not really useful in EDA or related in any sense\n* data contain nan values\n* values in features are not in same scale\n* the feature in **song_popularity** is our target variable for training","e2c12a53":"### thank you for checking this out \ud83d\udc97","055834b4":"# is data imbalanced?","c9a4526d":"# Load data","7fc223a6":"# distribution of data [Individual]","0d649e3e":"# Basic overview of data","506d176b":"# Checking null values\n"}}