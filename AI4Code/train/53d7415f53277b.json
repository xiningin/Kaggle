{"cell_type":{"e937b6e7":"code","e2416fca":"code","6d916433":"code","d580c6aa":"code","80275d48":"code","324830dd":"code","44e98f57":"code","6438a4f8":"code","3456ace7":"code","d2fb2d7f":"code","91e1a7cd":"code","30016374":"code","6020395e":"code","854804f8":"code","06531120":"code","ba60a5f9":"code","a0d76bfb":"markdown","2d4e1cdc":"markdown","372701ef":"markdown","60147944":"markdown","37be9b17":"markdown","50e04015":"markdown","f248d0d2":"markdown","c6ec3d2d":"markdown","49f58da7":"markdown","b4a3f09e":"markdown","813bf4b1":"markdown","9822683a":"markdown","c654b65f":"markdown","a2d65f95":"markdown","32d2cd09":"markdown","161a4c17":"markdown","79ab058d":"markdown","e1da9fb9":"markdown"},"source":{"e937b6e7":"from torch.utils.data                       import Dataset, DataLoader\r\nfrom tensorflow.keras.preprocessing.image   import ImageDataGenerator\r\nfrom sklearn.model_selection                import train_test_split\r\n\r\nimport pandas                               as pd\r\nimport numpy                                as np\r\nimport matplotlib.pyplot                    as plt\r\nimport torch.nn                             as nn\r\nimport torch.nn.functional                  as F\r\nimport torch.optim                          as optim\r\n\r\nimport torchvision\r\nimport torch","e2416fca":"df_train = pd.read_table('.\/data\/train.csv', sep=',')\r\ndf_test = pd.read_table('.\/data\/test.csv', sep=',')","6d916433":"train = np.array(df_train.drop(labels = ['label'], axis = 1), dtype = np.float32).reshape(-1, 28, 28, 1)\r\ntest = np.array(df_test, dtype = np.float32).reshape(-1, 28, 28, 1)\r\n\r\nlabels_train = np.array(df_train['label']).reshape(-1, 1)","d580c6aa":"train = train \/ 255.0\r\ntest = test \/ 255.0","80275d48":"class DataSettrain(Dataset):\r\n    def __init__(self, X, Y):\r\n        self.X = X\r\n        self.Y = Y\r\n        if len(self.X) != len(self.Y):\r\n            raise Exception(\"The size of X does not match the size of Y\")\r\n\r\n    def __len__(self):\r\n        return len(self.X)\r\n\r\n    def __getitem__(self, index):\r\n        _x = self.X[index]\r\n        _y = self.Y[index]\r\n\r\n        return _x, _y","324830dd":"loader = DataLoader(DataSettrain(train.reshape(42000, 1, 28, 28), labels_train), batch_size=50)\r\nbatch = next(iter(loader))\r\nimages, labels = batch","44e98f57":"grid = torchvision.utils.make_grid(images, n_row = 10)\r\n\r\nplt.figure(figsize=(5,5))\r\nplt.imshow(np.transpose(torch.FloatTensor(grid), (1,2,0)))\r\nplt.show()","6438a4f8":"images_extras = []\r\nlabels_images_extras = []\r\nimg_new = []\r\nlabel_img_new = []\r\n\r\n# Creating an object to generate new images from the initial dataset\r\ndatagen = ImageDataGenerator(rotation_range=10, zoom_range = 0.10, width_shift_range=0.1, height_shift_range=0.1)\r\n\r\nfor j in range(len(train)):\r\n    for i in range(10):\r\n        X_train = train[j].reshape(1,28,28,1)\r\n        label_img_new = labels_train[j]\r\n            \r\n        X_train2, Y_train2 = datagen.flow(X_train,label_img_new).next()\r\n        images_extras.append(X_train2)\r\n        labels_images_extras.append(Y_train2)","3456ace7":"images_extras = np.array(images_extras)\r\nimages_extras = torch.Tensor(images_extras.reshape(len(images_extras), 1, 28, 28))\r\n\r\nlabels_images_extras = np.array(labels_images_extras)\r\nlabels_images_extras = labels_images_extras.reshape(-1)\r\n\r\n# Creating a dataset with original images and the new ones\r\ntotal_images = torch.cat((torch.Tensor(train).reshape(42000, 1, 28, 28), images_extras))\r\ntotal_labels = torch.cat((torch.LongTensor(labels_train), torch.LongTensor(labels_images_extras.reshape(len(labels_images_extras), 1))))","d2fb2d7f":"a = 400000\r\nplt.imshow(images_extras[a].reshape(28,28))\r\nprint(labels_images_extras[a])","91e1a7cd":"class Network(nn.Module):\r\n    # Initialization of network layers\r\n    def __init__(self):\r\n        super().__init__()\r\n      \r\n        # Convolutional Layers\r\n        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = (3,3))\r\n        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3,3))\r\n        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3))\r\n\r\n        # Totally connected layers\r\n        self.fc1 = nn.Linear(in_features = 64*4*4, out_features = 256)\r\n        self.norm1 = nn.BatchNorm1d(256)\r\n        self.fc2 = nn.Linear(in_features = 256, out_features = 120)\r\n        self.out = nn.Linear(in_features = 120, out_features = 10)\r\n        \r\n    def forward(self, t):\r\n        \r\n        # Activation function to the first convolutional layer\r\n        t = F.relu(self.conv1(t))\r\n        # Discretization function and sample resizing\r\n        t = F.max_pool2d(t, kernel_size = (2,2), stride = 2)\r\n\r\n        # Activation function to the second convolutional layer\r\n        t = F.relu(self.conv2(t))\r\n        # Discretization function and sample resizing\r\n        t = F.max_pool2d(t, kernel_size = (2,2), stride = 1)\r\n\r\n        # Activation function to the third convolutional layer\r\n        t = F.relu(self.conv3(t))\r\n        # Discretization function and sample resizing\r\n        t = F.max_pool2d(t, kernel_size = (2,2), stride = 2)\r\n\r\n        # Image leveling\r\n        t = t.reshape(-1, 64*4*4)\r\n        \r\n        # Activation functions of totally connected layers\r\n        t = F.relu(self.fc1(t))\r\n        t = F.relu(self.norm1(t))\r\n        t = F.relu(self.fc2(t))\r\n        t = self.out(t)\r\n        \r\n        return t","30016374":"def num_right_predictions(preds, labels):\r\n    return preds.argmax(dim = 1).eq(labels).sum().item()\r\n\r\nx_train, x_val, y_train, y_val = train_test_split(total_images, total_labels, test_size = 0.1, random_state = 33)","6020395e":"# Processing the network with GPU\r\nmodel = Network()\r\nif torch.cuda.is_available():\r\n    model = model.cuda()\r\n\r\n# Optimization algorithm with AMSGrad, using an initial learning rate 1e-03\r\noptimizer = optim.Adam(model.parameters(), lr = 0.001, amsgrad = True)\r\n\r\n# It reduces the learning rate to 60% when the network stays 4 epochs without having a significant variation in the learning\r\n# rate or when the learning rate increases from one epoch to another\r\nscheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.6, patience = 4, verbose = True, min_lr = 1e-5)\r\n\r\n# It reduces a learning rate to 95% at the end of each epoch\r\nscheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda = lambda epoch: .95)\r\n\r\n# It reduces the learning rate to 70% in epochs 25 and 32\r\nscheduler3 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [25, 32], gamma = .7)\r\n\r\n# Setting the batches that will be passed to the network during the training and validation\r\nloader = DataLoader(DataSettrain(x_train, y_train), batch_size = 64, shuffle = True)\r\nval_loader = DataLoader(DataSettrain(x_val, y_val), batch_size = 64, shuffle = True)\r\n\r\n# It uses the gradient changes to update the synaptic weights\r\ntorch.set_grad_enabled(True)\r\n\r\n# 35 epochs are used for the training and validation of the network\r\nfor epoch in range(35):\r\n    \r\n    total_loss = 0\r\n    total_correct = 0\r\n    \r\n    # Start of the training process\r\n    model.train()\r\n    for batch in loader:\r\n        images, labels = batch\r\n        if torch.cuda.is_available():\r\n            images, labels = images.cuda(), labels.cuda()\r\n\r\n        optimizer.zero_grad()\r\n        \r\n        preds = model(images)\r\n        loss = F.cross_entropy(preds, labels.reshape(-1))\r\n        loss.backward()\r\n        optimizer.step()\r\n        \r\n        total_loss += loss.item()\r\n        total_correct += num_right_predictions(preds, labels.reshape(-1))\r\n\r\n    val_loss = 0\r\n    val_correct = 0\r\n\r\n    # Start of the validation process\r\n    model.eval()\r\n    for val_batch in val_loader: \r\n        val_images, val_labels = val_batch\r\n        if torch.cuda.is_available():\r\n            val_images, val_labels = val_images.cuda(), val_labels.cuda()\r\n\r\n        pred_validation = model(val_images)\r\n        loss = F.cross_entropy(pred_validation, val_labels.reshape(-1))\r\n        val_correct += num_right_predictions(pred_validation, val_labels.reshape(-1))\r\n\r\n        val_loss += loss.item()\r\n\r\n    scheduler1.step(loss)\r\n    scheduler2.step()\r\n    scheduler3.step()\r\n      \r\n    print('Epoch: ', epoch+1, ' |  Number of right predictions during test: ', total_correct, ' \/ ', len(x_train), ' |  Test accuracy: ',\r\n          total_correct\/len(x_train), ' |  loss test: ', total_loss, ' |  Validation accuracy: ', val_correct \/ len(x_val), \" |  loss val: \", val_loss)     ","854804f8":"predictions = model(torch.Tensor(test).reshape(28000, 1, 28, 28)).argmax(dim = 1)","06531120":"loader_test = DataLoader(DataSettrain(test.reshape(28000, 1, 28, 28), np.arange(len(test))), batch_size=40)\r\nbatch = next(iter(loader_test))\r\nimages, labels = batch\r\ngrid = torchvision.utils.make_grid(images, n_row = 10)\r\n\r\nplt.figure(figsize=(8,8))\r\nplt.imshow(np.transpose(torch.FloatTensor(grid), (1,2,0)))\r\nplt.show()\r\n\r\nprint(np.array(predictions[0:40]).reshape(5,8))","ba60a5f9":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pd.Series(np.array(predictions), name = 'Label')],axis = 1)\r\n\r\nsubmission.to_csv('.\/submission\/submissao_torch_99.546%.csv',index=False)\r\n\r\ntorch.save(model, '.\/models\/modelo_99.546%.pth')","a0d76bfb":"### **3. Group image and its label**","2d4e1cdc":"### **2. Value normalization of pixels**","372701ef":"### **4. Creating batch with pre defined size of images**","60147944":"### Generaring 10 variations from each image in the training dataset","37be9b17":"### Sample containing 50 images from the train dataset","50e04015":"### **2. Preprocessing of the generated data**","f248d0d2":"## **Digit Recognizing**","c6ec3d2d":"### Sample of 40 test images with their predicted labels","49f58da7":"## **Neural Network**\n\n### **1. Class Criation**","b4a3f09e":"## **Imports**","813bf4b1":"## **2. Neural Network Training and Validation**","9822683a":"# **Kaggle Digit Recognizer**\r\n## **Authors:**\r\n\r\n- Cau\u00ea Caviglioni - [cauedanisilva@poli.ufrj.br](mailto:cauedanisilva@poli.ufrj.br)\r\n- Erica Ferreira - [erica.ferreira@poli.ufrj.br](mailto:erica.ferreira@poli.ufrj.br)\r\n- Bernardo Mendon\u00e7a - [bernardomcaixeta@poli.ufrj.br](mailto:bernardomcaixeta@poli.ufrj.br)\r\n\r\n## **Description:**\r\n### In this notebook, it is developed a Neural Network to recognize handwritten digits for the [Kaggle Digit Recognizer Competition](https:\/\/www.kaggle.com\/c\/digit-recognizer\/data).\r\n\r\n### This notebook was made by members of [UFRJ Analytica](https:\/\/ufrjanalytica.ml\/), a Data Science Team from the Federal University of Rio de Janeiro\r\n\r\n<hr>","c654b65f":"### **1. Image Generation**","a2d65f95":"## **Preprocessing Data**\n\n### **1. Data Conversion and reshaping images**","32d2cd09":"## **Importing Data**","161a4c17":"## **Saving Outputs**\n###  Criation of a CSV file containing ID and predicted label for each image","79ab058d":"## **Expand training data**\n\n### New images will be generated from the available training data, and thus, boost the neural network performance","e1da9fb9":"### Example of a generated image"}}