{"cell_type":{"c0eb68f8":"code","8f506e68":"code","fe211d14":"code","d35e8176":"code","aa017d0d":"code","98130438":"code","5a30883a":"code","3a7c87ef":"code","747108fd":"code","450e04d3":"code","bfc94d0e":"code","ef7f56ae":"code","ef4b1fec":"code","949e9c48":"code","69515d15":"code","6041cd9a":"code","a7116cb1":"code","252daf97":"code","b0b8ecc6":"code","f1463583":"code","4eef054f":"code","7646e782":"code","b3c6d933":"code","38d6e1b8":"code","0a5814f7":"code","7f392ec2":"code","3727af3c":"code","4f525ec5":"code","8d450506":"code","65949261":"code","96c941a8":"code","74526ac9":"code","f7d297fc":"code","cb886b4e":"code","b77d5711":"code","3cca3480":"code","79a9ee57":"code","72b93400":"code","ee663e15":"code","733e2195":"code","c4c5efaa":"code","7f16c865":"code","3c45b52d":"code","cef53ab7":"code","1de984e0":"code","b1591e24":"code","27e2ea75":"code","e2363294":"code","6c9bdcb8":"code","be87eb9b":"code","acd8e7aa":"code","66a86cde":"code","98b64746":"code","4bcaff59":"code","b1becfc9":"markdown","68d380c7":"markdown","2afa7af7":"markdown","dfb94f2f":"markdown","ad98450e":"markdown","68a7b2c8":"markdown","5e48489d":"markdown","3303c0e5":"markdown"},"source":{"c0eb68f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8f506e68":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n%matplotlib inline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nimport statsmodels.api as sm\n\nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","fe211d14":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","d35e8176":"train.head()","aa017d0d":"train.info()\nprint(\"_\"*40)\ntest.info()","98130438":"train.isnull().sum()","5a30883a":"test.isnull().sum()","3a7c87ef":"train.describe().transpose()","747108fd":"#\u5ba2\u5ba4\u306e\u30b0\u30ec\u30fc\u30c9\u306b\u3088\u3063\u3066\u306e\u751f\u5b58\u7387\u3092\u78ba\u8a8d\u3002\ntrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","450e04d3":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","bfc94d0e":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ef7f56ae":"train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ef4b1fec":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","949e9c48":"grid = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","69515d15":"#Ticket, Cabin\u3092\u524a\u9664\n#combine\u3068\u3057\u3066\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3059\u308b\u3002\uff08\u3053\u308c\u3067\u3001\u3044\u3061\u3044\u3061\u305d\u308c\u305e\u308c\u306e\u8a2d\u5b9a\u3092\u3059\u308b\u5fc5\u8981\u306f\u306a\u3044\uff09\ntrain = train.drop(['Ticket', 'Cabin'], axis=1)\ntest = test.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train, test]","6041cd9a":"#\u4e57\u5ba2\u306e\u540d\u524d\u3068ID\u3092\u8aac\u660e\u5909\u6570\u304b\u3089\u524a\u9664\uff08\u30e2\u30c7\u30eb\u306b\u5165\u308c\u306a\u3044\uff09\u3068\u5224\u65ad\u3059\u308b\u524d\u306b\u3001\u4f55\u304b\u751f\u5b58\u7387\u3068\u76f8\u95a2\u304c\u7121\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002\n#\u540d\u524d\u306e\u524d\u306b\u306fMr.\u306a\u3069\u306e\u540d\u79f0\u304c\u3042\u308b\u304b\u3089\u6b63\u898f\u8868\u73fe\u3067\u62bd\u51fa\u3057\u3066\u3044\u304f\u3002\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","a7116cb1":"#\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u540d\u79f0\u304c\u4f55\u500b\u3082\u3042\u308b\u306e\u3067\u3001\u305d\u308c\u306b\u95a2\u3057\u3066\u306f\"Rare\"\u3068\u3057\u3066\u7f6e\u63db\u3059\u308b\u3002\n#Countess, Lady, Sir\u306f\u5049\u3044\u4eba\u3060\u304b\u3089\u3001Royal\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Sir','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","252daf97":"#\u5f97\u3089\u308c\u305f\u7d50\u679c\u3092\u30c0\u30df\u30fc\u5909\u6570\u5316\u3057\u3066\u304a\u304f\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain.head()","b0b8ecc6":"#Title\u3068\u3044\u3046\u60c5\u5831\u3067\u3001\u65c5\u5ba2ID\u3068\u540d\u524d\u306f\u4e0d\u8981\u3060\u304b\u3089\u524a\u9664\u3059\u308b\ntrain = train.drop(['Name', 'PassengerId'], axis=1)\ntest = test.drop(['Name'], axis=1)\ncombine = [train, test]\ntrain.shape, test.shape","f1463583":"#\u6027\u5225\u3092\u30c0\u30df\u30fc\u5909\u6570\u5316\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain.head()","4eef054f":"grid = sns.FacetGrid(train, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","7646e782":"guess_ages = np.zeros((2,3))\nguess_ages","b3c6d933":"#\u5e74\u9f62\u306e\u6b20\u640d\u5024\u3092\u51e6\u7406\u3057\u3066\u3044\u304f\u3002\n#\u6027\u5225\u3068\u5ba2\u5ba4\u3067\u5e74\u9f62\u306e\u6b20\u640d\u5024\u3092\u62bd\u51fa\u3002\u305d\u308c\u3092guess_df\u306b\u683c\u7d0d\u3059\u308b\u3002\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            #\u5e74\u9f62\u306e\u4e2d\u592e\u5024\u3092\u7b97\u51fa\u3059\u308b\u3002\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            #\u8a66\u7b97\u3057\u305f\u5e74\u9f62\u3092\u6574\u6570\u306b\u3059\u308b\u3002\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    #\u6027\u5225\u3068\u5ba2\u5ba4\u5225\u306b\u4e2d\u592e\u5024\u3092\u5165\u308c\u308b\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain.head()","38d6e1b8":"guess_ages","0a5814f7":"#\u5e74\u9f62\u3054\u3068\u306e\u751f\u5b58\u7387\u306e\u78ba\u8a8d\ntrain['AgeBand'] = pd.cut(train['Age'], 5)\ntrain[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","7f392ec2":"#\u5f97\u3089\u308c\u305f\u5e74\u9f62\u5225\u306e\u751f\u5b58\u7387\u306e\u7d50\u679c\u304b\u3089\u3001\u5e74\u9f62\u3092\u30b0\u30eb\u30fc\u30d7\u306b\u308f\u3051\u3001\u30c0\u30df\u30fc\u5909\u6570\u5316\u3059\u308b\u3002\n#\u4eca\u307e\u3067\u5e74\u9f62\u306f\u305d\u306e\u307e\u307e\u3084\u3063\u3066\u3044\u305f\u3051\u3069\u3001\u3053\u306e\u3088\u3046\u306b\u30b0\u30eb\u30fc\u30d7\u306b\u308f\u3051\u305f\u65b9\u304c\u826f\u3044\u3002\uff08\u305d\u306e\u307b\u3046\u304c\u3001\u96e2\u6563\u3057\u306b\u304f\u3044\uff1f\uff09\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0 \n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] \ntrain.head()","3727af3c":"train = train.drop(['AgeBand'], axis=1)\ncombine = [train, test]\ntrain.head()","4f525ec5":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","8d450506":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","65949261":"#\u5bb6\u65cf\u69cb\u6210\u306b\u95a2\u3057\u3066\u306f\u3001\u5358\u8eab\u8005\u304b\u3001\u305d\u3046\u3067\u306a\u3044\u304b\u3067\u751f\u5b58\u7387\u304c\u5909\u52d5\u3059\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u305f\u3002\n#\u5bb6\u65cf\u69cb\u6210\u306b\u95a2\u3059\u308b\u60c5\u5831\u306f\u3001IsAlone\u3068\u3044\u3046\u5909\u6570\u3068\u3057\u3066\u6271\u3046\u3002\ntrain = train.drop(['Parch', 'SibSp',\"FamilySize\"], axis=1)\ntest = test.drop(['Parch', 'SibSp',\"FamilySize\"], axis=1)\ncombine = [train, test]\n\ntrain.head()","96c941a8":"#\u5e74\u9f62\u3068\u5ba2\u5ba4\u306e\u5909\u6570\u3092\u307e\u3068\u3081\u3066\u307f\u308b\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","74526ac9":"freq_port = train.Embarked.dropna().mode()[0]\nfreq_port\n","f7d297fc":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","cb886b4e":"#\u30c0\u30df\u30fc\u5909\u6570\u5316\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head()","b77d5711":"#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u6b20\u640d\u5024\u304c\u3042\u308b\u306e\u3067\u3001\u305d\u3053\u3092\u57cb\u3081\u308b\ntest['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\ntest.head()","3cca3480":"train['FareBand'] = pd.qcut(train['Fare'], 4)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","79a9ee57":"#\u9ad8\u3044\u8cc3\u91d1\u3092\u6255\u3063\u3066\u3044\u308b\u4eba\u307b\u3069\u3001\u751f\u5b58\u7387\u304c\u9ad8\u3044\u7d50\u679c\n#\u5ba2\u5ba4\u306e\u30b0\u30ec\u30fc\u30c9\u3068\u3001\u5bb6\u65cf\u69cb\u6210\u3068\u76f8\u95a2\u306f\u3042\u308a\u305d\u3046\u3002\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain = train.drop(['FareBand'], axis=1)\ncombine = [train, test]\n    \ntrain.head(10)","72b93400":"test.head()","ee663e15":"train.info()\nprint(\"_\"*40)\ntest.info()","733e2195":"#\u30c7\u30fc\u30bf\u5206\u5272\uff08\u8a13\u7df4\u7528\u3068\u8a55\u4fa1\u7528\uff09\n\nX_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","c4c5efaa":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","7f16c865":"coeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","3c45b52d":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","cef53ab7":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","1de984e0":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","b1591e24":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","27e2ea75":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","e2363294":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","6c9bdcb8":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","be87eb9b":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","acd8e7aa":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","66a86cde":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n\nsubmission.to_csv(\"..\/working\/submission.csv\", index=False)","98b64746":"params_dict={'criterion':['gini','entropy'],'max_depth':[5.21,5.22,5.23,5.24,5.25,5.26,5.27,5.28,5.29,5.3]}\nclf_dt=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=params_dict,scoring='accuracy', cv=5)\nclf_dt.fit(X_train,Y_train)\npred=clf_dt.predict(X_test)\n#print(accuracy_score(pred,X_test))\nprint(clf_dt.best_params_)","4bcaff59":"predio = clf_dt.predict(X_test)\n\nd = {'PassengerId' : test[\"PassengerId\"] , 'Survived' : predio}\nanswer = pd.DataFrame(d)\n# Generate CSV file based on DecisionTree Classifier\nanswer.to_csv('predio.csv' , index=False)","b1becfc9":"\u6b21\u306b\u3001\u5bb6\u65cf\u69cb\u6210\u3068\u751f\u5b58\u7387\u306e\u95a2\u4fc2\u3092\u78ba\u8a8d\u3059\u308b\u3002\n\n\u5bb6\u65cf\u69cb\u6210\u306f\u3001SibSp\uff08\u5144\u5f1f\u3001\u914d\u5076\u8005\u306e\u6570\uff09\u3068Parch\uff08\u4e21\u89aa\u3001\u5b50\u4f9b\u306e\u6570\uff09\u3092\u5408\u308f\u305b\u305f\u5909\u6570\u3092\u65b0\u305f\u306b\u52a0\u3048\u308b\u3002\n\n\u3053\u3053\u3067\u3001\u81ea\u8eab\u306e\u6570\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u3002","68d380c7":"\u4eca\u307e\u3067\u306e\u7d50\u679c\u3067\u306f\u3001\u65c5\u5ba2\u306e\u30af\u30e9\u30b9\u304c\u9ad8\u3044\u307b\u3069\u751f\u5b58\u7387\u306f\u9ad8\u304f\u3066\u3001\u5973\u6027\u306f\u751f\u5b58\u7387\u304c\u9ad8\u3044\u3002\n\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u53f7\u3067\u306f\u3001\u907f\u96e3\u6642\u306b\u5973\u6027\u3068\u5b50\u4f9b\u3092\u512a\u5148\u7684\u306b\u907f\u96e3\u3055\u305b\u308b\u3053\u3068\u3092\u3057\u3066\u3044\u305f\u3068\u5831\u544a\u3055\u308c\u3066\u3044\u308b\u3002\n\u21e8\u5b50\u4f9b\u306e\u5206\u985e\u306f\u7121\u3044\u3051\u3069\u3001\u305d\u3053\u306f\u3069\u3046\u306a\u308b\u304b\uff1f","2afa7af7":"\u56de\u5e30\u5206\u6790\u3067\u306e\u76f8\u95a2\u3092\u78ba\u8a8d\u3059\u308b","dfb94f2f":"\u3053\u3053\u307e\u3067\u6765\u3066\u3001\u30c7\u30fc\u30bf\u30af\u30ec\u30f3\u30b8\u30b0\u306f\u7d42\u4e86\u3002\u30e2\u30c7\u30eb\u306e\u4f5c\u6210\u306b\u304b\u304b\u308b\u3002\n\n\u3069\u306e\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u304b\u3001\u305d\u308c\u305e\u308c\u3067\u691c\u8a0e\u3059\u308b\u3002\n\n\u30fb\u56de\u5e30\u5206\u6790\n\n\u30fbK\u8fd1\u508d\u6cd5\n\n\u30fb\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30fc\u30f3\n\n\u30fb\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u5206\u985e\u5668\n\n\u30fb\u6c7a\u5b9a\u6728\n\n\u30fb\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\n\n\u30fb\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3\n\n\u30fb\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\n\u30fb\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30fc\u30f3\n","ad98450e":"\u6b20\u640d\u5024\u306e\u51e6\u7406\u3092\u884c\u3046\u3002\u6b20\u640d\u5024\u306e\u51e6\u7406\u3068\u3057\u3066\u306f\u4ee5\u4e0b\u306e\u65b9\u6cd5\u304c\u3042\u308b\u3002\n\n\uff11\uff1a\u30e9\u30f3\u30c0\u30e0\u306e\u6570\u5b57\u3092\u5165\u308c\u308b\u3002\n\n\uff12\uff1a\u95a2\u9023\u3057\u305f\u60c5\u5831\u3092\u5143\u306b\u6b20\u640d\u5024\u3092\u57cb\u3081\u3066\u3044\u304f\u3002\uff08\u4f8b\u3048\u3070\u3001\u5e74\u9f62\u306e\u6b20\u640d\u5024\u3067\u3042\u308c\u3070\u3001\u5ba2\u5ba4\u3068\u6027\u5225\u306a\u3069\u306e\u60c5\u5831\u304b\u3089\u5e73\u5747\u5024\u3092\u4f7f\u7528\u3057\u305f\u308a\u3059\u308b\uff09\n\n\uff13\uff1a\uff11\u3068\uff12\u306e\u7d44\u307f\u5408\u308f\u305b\n\n\u4eca\u56de\u306f\uff12\u306e\u65b9\u6cd5\u3092\u63a8\u5968\u3059\u308b\u3002","68a7b2c8":"\u7d9a\u3044\u3066\u3001\u4e57\u8239\u3057\u305f\u6e2f\u306b\u95a2\u3057\u3066\u691c\u8a0e\u3059\u308b\u3002\n\n\u6b20\u640d\u5024\u304c\uff12\u3064\u3042\u308b\u306e\u3067\u3001\u305d\u308c\u3092\u983b\u51fa\u306e\u6e2f\u3067\u57cb\u3081\u308b\u3002","5e48489d":"\u5bb6\u65cf\u6570\u304c2~4\u304c\u751f\u5b58\u7387\u304c\u9ad8\u3044\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u305f\u3002\n\n\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u53f7\u3067\u306f\u3001\u5bb6\u65cf\u305a\u308c\u3092\u512a\u5148\u7684\u306b\u6551\u52a9\u3057\u3066\u3044\u3063\u305f\uff1f\u53ef\u80fd\u6027\u306f\u3042\u308b\u3002\n\n\u5358\u8eab\u306e\u4eba\u306f\u751f\u5b58\u7387\u304c\u3042\u307e\u308a\u9ad8\u304f\u306a\u3044\u3002\u21e8\u65b0\u3057\u3044\u5909\u6570\u3068\u3057\u3066\u5165\u308c\u308b\u3002","3303c0e5":"\u3053\u308c\u3067\u3001\u8cc3\u91d1\u4ee5\u5916\u306f\u5168\u3066\u30af\u30ec\u30f3\u30b8\u30f3\u30b0\u304c\u3067\u304d\u305f\u3002\n\n\u6700\u5f8c\u306e\u8cc3\u91d1\u306f\u3001\u5e74\u9f62\u3068\u540c\u3058\u3067\u30b0\u30eb\u30fc\u30d7\u5316\u3057\u3066\u304b\u3089\u3001\u30c0\u30df\u30fc\u5909\u6570\u5316\u3059\u308b\u3002\uff08\u5024\u304c\u30d0\u30e9\u3064\u304d\u6613\u3044\u3082\u306e\u306b\u5bfe\u3057\u3066\u306f\u3001\u3053\u306e\u65b9\u6cd5\u304c\u3044\u3044\uff1f\uff09"}}