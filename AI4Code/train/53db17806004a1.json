{"cell_type":{"4f18e5dd":"code","0de2c50a":"code","8edf4719":"code","e07f0e46":"code","23569e5a":"code","c2b69236":"code","f459f733":"code","716dea1c":"code","53240b06":"code","5ab7d1cf":"code","d0b90643":"markdown","b299709a":"markdown","616d1744":"markdown","10ad3c1a":"markdown","4facfaeb":"markdown","bc5edf93":"markdown","463dcb3f":"markdown","39f2a555":"markdown","6e109626":"markdown","d3af21b6":"markdown","705c6060":"markdown","d1fd3fc0":"markdown","a561fd53":"markdown"},"source":{"4f18e5dd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.metrics import silhouette_score\nimport scipy.cluster.hierarchy as shc","0de2c50a":"X = pd.read_csv(\"..\/input\/croppred\/CROPP.csv\")\n# data = data.loc[:, ['Area', 'Production']]\n  \n# Dropping the CUST_ID column from the data\nX = X.drop('State_Name', axis = 1)\nX = X.drop('District_Name', axis = 1)\nX = X.drop('Season', axis = 1)\nX = X.drop('Crop', axis = 1)\nX = X.drop('Crop_Year', axis = 1)\n  \n# Handling the missing values\nX.fillna(method ='ffill', inplace = True)","8edf4719":"X.head(5)","e07f0e46":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n  \n# Normalizing the data so that the data approximately \n# follows a Gaussian distribution\nX_normalized = normalize(X_scaled)\n  \n# Converting the numpy array into a pandas DataFrame\nX_normalized = pd.DataFrame(X_normalized)","23569e5a":"pca = PCA(n_components = 2)\nX_principal = pca.fit_transform(X_normalized)\nX_principal = pd.DataFrame(X_principal)\nX_principal.columns = ['Area', 'Production']","c2b69236":"plt.figure(figsize =(8, 8))\nplt.title('Visualising the data')\nDendrogram = shc.dendrogram((shc.linkage(X_principal, method ='ward')))","f459f733":"ac2 = AgglomerativeClustering(n_clusters = 2)\n  \n# Visualizing the clustering\nplt.figure(figsize =(6, 6))\nplt.scatter(X_principal['Area'], X_principal['Production'], \n           c = ac2.fit_predict(X_principal), cmap ='rainbow')\nplt.show()","716dea1c":"ac3 = AgglomerativeClustering(n_clusters = 3)\n  \nplt.figure(figsize =(6, 6))\nplt.scatter(X_principal['Area'], X_principal['Production'],\n           c = ac3.fit_predict(X_principal), cmap ='rainbow')\nplt.show()","53240b06":"ac4 = AgglomerativeClustering(n_clusters = 4)\n  \nplt.figure(figsize =(6, 6))\nplt.scatter(X_principal['Area'], X_principal['Production'],\n            c = ac4.fit_predict(X_principal), cmap ='rainbow')\nplt.show()","5ab7d1cf":"k = [2, 3, 4]\n  \n# Appending the silhouette scores of the different models to the list\nsilhouette_scores = []\nsilhouette_scores.append(\n        silhouette_score(X_principal, ac2.fit_predict(X_principal)))\nsilhouette_scores.append(\n        silhouette_score(X_principal, ac3.fit_predict(X_principal)))\nsilhouette_scores.append(\n        silhouette_score(X_principal, ac4.fit_predict(X_principal)))\n  \n# Plotting a bar graph to compare the results\nplt.bar(k, silhouette_scores)\nplt.xlabel('Number of clusters', fontsize = 20)\nplt.ylabel('S(i)', fontsize = 20)\nplt.show()","d0b90643":"### k = 4","b299709a":"# Evaluating the different models and Visualizing the results.","616d1744":"#### Dendograms are used to divide a given cluster into many different clusters.","10ad3c1a":"### k = 3","4facfaeb":"#### REF: https:\/\/www.geeksforgeeks.org\/implementing-agglomerative-clustering-using-sklearn\/\n\n\n# Importing Libraries","bc5edf93":"### k = 2","463dcb3f":"# Preprocessing the data","39f2a555":"# Reducing the dimensionality of the Data","6e109626":"#  Loading and Cleaning the data","d3af21b6":"# Building and Visualizing the different clustering models for different values of k","705c6060":"#### We now determine the optimal number of clusters using a mathematical technique. Here, We will use the Silhouette Scores for the purpose.","d1fd3fc0":"# Visualizing the working of the Dendograms","a561fd53":"## Thus, with the help of the silhouette scores, it is concluded that the optimal number of clusters for the given data and clustering technique is 4."}}