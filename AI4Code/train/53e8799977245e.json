{"cell_type":{"d69cf29c":"code","1eb0fffb":"code","7f57e04a":"code","d2cb90a7":"code","bbfeb054":"code","e1d927ae":"code","b1c2f2c6":"code","487c64ad":"code","d337a0aa":"code","63cacfad":"code","80bffb67":"code","143dede6":"code","1c1fa42b":"code","1c76aae9":"code","48da2b8d":"code","c1cc551f":"code","74000e96":"code","59bb25ce":"code","15e21287":"code","3bc5f51a":"code","8e548602":"code","4ee21be5":"markdown","6daa9942":"markdown","239a6321":"markdown","8c269e90":"markdown","087cbfdd":"markdown","541cba12":"markdown","423e1d24":"markdown","518ab0f6":"markdown","a52566d9":"markdown","208d2a02":"markdown","eb0f5809":"markdown","2367d3fb":"markdown","384c082f":"markdown","13d1e39e":"markdown","b3ae90d3":"markdown"},"source":{"d69cf29c":"# General libraries imports\nimport pandas as pd\nimport numpy as np\nimport os\nimport time\n\n# import image manipulation\nfrom PIL import Image\n\n# import matplotlib for visualization\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\n\n# Import PyTorch\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader","1eb0fffb":"# Set path to folders containing the data\nTRAIN_IMG_PATH = \"..\/input\/train\/train\/\"\nTEST_IMG_PATH = \"..\/input\/test\/test\/\"\nLABELS_CSV_PATH = \"..\/input\/train.csv\"\nSAMPLE_SUB_PATH = \"..\/input\/sample_submission.csv\"","7f57e04a":"# read the csv with labels for train dataset\npd_train = pd.read_csv(LABELS_CSV_PATH)\n\n# count the number or rows\ntrain_images = len(pd_train)\n\nprint(\"The number of images in train dataset is {}.\".format(train_images))","d2cb90a7":"# count the number of images in test dataset\ntest_images = len([f for f in os.listdir(TEST_IMG_PATH) if os.path.isfile(os.path.join(TEST_IMG_PATH, f))])\n\nprint(\"The number of images in test dataset is {}.\".format(test_images))","bbfeb054":"# Plot pie chart\nlabels = 'Train', 'Test'\nsizes = [train_images, test_images]\nexplode = (0, 0.1)  # \"explode\" the 2nd slice\n\nfig, ax = plt.subplots()\nax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title(\"Number of images in training dataset\")\nplt.show()","e1d927ae":"# calculate the number of images with and without cactus\nwith_cactus_num = pd_train[pd_train['has_cactus'] == 1].has_cactus.count()\nno_cactus_num = pd_train[pd_train['has_cactus'] == 0].has_cactus.count()\n\nprint(\"The number of images with cactus in train dataset is {}.\".format(with_cactus_num))\nprint(\"The number of images without cactus in train dataset is {}.\".format(no_cactus_num))","b1c2f2c6":"# Plot pie chart\nlabels = 'Cactus', 'No cactus'\nsizes = [with_cactus_num, no_cactus_num]\nexplode = (0, 0.1)  # \"explode\" the 2nd slice\n\nfig, ax = plt.subplots()\nax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title(\"Number of images with\/without cactus\")\nplt.show()","487c64ad":"# get array of image filenames with and without cactus\nhas_cactus = pd_train[pd_train['has_cactus'] == 1][:9].id.values\nno_cactus = pd_train[pd_train['has_cactus'] == 0][:9].id.values","d337a0aa":"def view_cactus(cactus_images, title = ''):\n    \"\"\"\n    Function to plot grid with several examples of images.\n    INPUT:\n        cactus_images - array with filenames for images\n\n    OUTPUT: None\n    \"\"\"\n    fig, axs = plt.subplots(3, 3, figsize=(7,7))\n    \n    for im in range(0,9):\n        # open image\n        image = Image.open(os.path.join(TRAIN_IMG_PATH,cactus_images[im]))\n        i = im \/\/ 3\n        j = im % 3\n        axs[i,j].imshow(image) #plot the data\n        axs[i,j].axis('off')\n\n    # set suptitle\n    plt.suptitle(title)\n    plt.show()","63cacfad":"view_cactus(has_cactus, title = 'Images with cactus')","80bffb67":"view_cactus(no_cactus, title = 'Images without cactus')","143dede6":"# Define the dataset\nclass CactusDataset(Dataset):\n    \"\"\"Cactus identification dataset.\"\"\"\n\n    def __init__(self, img_dir, dataframe, transform=None):\n        \"\"\"\n        Args:\n            img_dir (string): Directory with all the images.        \n            dataframe (pandas.core.frame.DataFrame): Pandas dataframe obtained\n                by read_csv().\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.labels_frame = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels_frame)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.labels_frame.id[idx]) \n        image = Image.open(img_name)\n        label = self.labels_frame.has_cactus[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return [image, label] \n    \n    \n# define train transformations \ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406], \n                                                            [0.229, 0.224, 0.225])])\n# define test transformations \ntest_transforms = transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], \n                                                           [0.229, 0.224, 0.225])])","1c1fa42b":"dframe = pd.read_csv(LABELS_CSV_PATH)\ncut = int(len(dframe)*0.95)\ntrain, test = np.split(dframe, [cut], axis=0)\ntest = test.reset_index(drop=True)\n\ntrain_ds = CactusDataset(TRAIN_IMG_PATH, train, train_transforms)\ntest_ds = CactusDataset(TRAIN_IMG_PATH, test, test_transforms)\ndatasets = {\"train\": train_ds, \"val\": test_ds}","1c76aae9":"trainloader = DataLoader(train_ds, batch_size=32,\n                        shuffle=True, num_workers=0)\n\ntestloader = DataLoader(test_ds, batch_size=4,\n                        shuffle=True, num_workers=0)","48da2b8d":"epochs = 20\nbatch_size = 128\nlearning_rate = 0.003\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\ndevice","c1cc551f":"model = models.vgg16(pretrained=True)\nmodel","74000e96":"# freeze parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\n# add layers to train\nfrom collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(25088, 12000)),\n                          ('dr1', nn.Dropout(p = 0.3)),\n                          ('bn1', nn.BatchNorm1d(num_features=12000)),\n                          ('relu1', nn.ReLU()),\n                          ('fc2', nn.Linear(12000, 1000)),\n                          ('dr2', nn.Dropout(p = 0.3)),\n                          ('bn2', nn.BatchNorm1d(num_features=1000)),\n                          ('relu2', nn.ReLU()),\n                          ('fc3', nn.Linear(1000, 102)),\n                          ('output', nn.LogSoftmax(dim = 1))\n                          ]))\n    \nmodel.classifier = classifier","59bb25ce":"# set loss function\ncriterion = nn.NLLLoss()\n\n# set optimizer, only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)","15e21287":"# train the model\nmodel.to(device)\n\nsteps = 0\nrunning_loss = 0\nprint_every = 5\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n        steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in testloader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    \n                    test_loss += batch_loss.item()\n                    \n                    # Calculate accuracy\n                    ps = torch.exp(logps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                    \n            print(f\"Epoch {epoch+1}\/{epochs}.. \"\n                  f\"Train loss: {running_loss\/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss\/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy\/len(testloader):.3f}\")\n            running_loss = 0\n            model.train()","3bc5f51a":"submission_df = pd.read_csv(SAMPLE_SUB_PATH)\noutput_df = pd.DataFrame(index=submission_df.index, columns=submission_df.keys() )\noutput_df['id'] = submission_df['id']\nsubmission_df['target'] =  [0] * len(submission_df)\n\ntdata_transform = transforms.Compose([transforms.Resize(256),\n                    transforms.CenterCrop(224),\n                    transforms.ToTensor(),\n                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\nsubmission_ds = CactusDataset(TEST_IMG_PATH, submission_df, tdata_transform)\n\nsub_loader = DataLoader(submission_ds, batch_size=1,\n                        shuffle=False, num_workers=0)\n\n\ndef test_sumission(model):\n    since = time.time()\n    sub_outputs = []\n    model.train(False)  # Set model to evaluate mode\n    # Iterate over data.\n    prediction = []\n    for data in sub_loader:\n        # get the inputs\n        inputs, labels = data\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # forward\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        prediction.append(int(pred))\n      \n    time_elapsed = time.time() - since\n    print('Run complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n\n    return prediction","8e548602":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['has_cactus'] = test_sumission(model)\nsub.to_csv('submission1.csv', index= False)\n\nsub.head()","4ee21be5":"_Don't forget to enable GPU in kernel settings to run the model on GPU._","6daa9942":"## Modelling","239a6321":"`3` Load pretrained VGG-16 model:","8c269e90":"`5` Create submission file:","087cbfdd":"`4` Train the model:","541cba12":"`3` View examples of images with cactus and without cactus:","423e1d24":"I decided to use VGG-16 pretrained model (see [this article](https:\/\/hackernoon.com\/learning-keras-by-implementing-vgg16-from-scratch-d036733f2d5) for further reading) to classify the images.","518ab0f6":"`2` Setup hyperparameters:","a52566d9":"`2` Number of images with and without cactus in train dataset:","208d2a02":"## Introduction\n\nThe goal of the [Aerial Cactus Identification competition](https:\/\/www.kaggle.com\/c\/aerial-cactus-identification) is to create an algorithm that can identify a specific type of cactus in aerial imagery to advance a system for autonomous surveillance of protected areas.\n\n<br>In this competition, we are given a dataset with labeled 32 x 32 images, which contain aerial photos of a columnar cactus. The task is to build an algorithm, which predicts whether there is a cactus on the image. This is a classification problem. Since we have a lot of data, deep learning models will suit well for this problem.\n\n<br>In this analysis I used the code from this [Kaggle kernel](https:\/\/www.kaggle.com\/atrisaxena\/pytorch-simple-model-iscactus-classification).","eb0f5809":"_Don't forget to enable Internet in kernel settings to download the model._","2367d3fb":"`1` Number of images in train and test datasets:","384c082f":"# Arial Cactus Identification with PyTorch and VGG16","13d1e39e":"## Explore Data\n\nLet's explore the dataset given:\n* How many records are there in train and test datasets?\n* How many images are there with\/without cactus?\n* Visualize images with and without cactus.","b3ae90d3":"`1` Load the dataset:"}}