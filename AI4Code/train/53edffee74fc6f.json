{"cell_type":{"55286be9":"code","7b4f697c":"code","ca384465":"code","f706007e":"code","0ce0421c":"code","e85dd787":"code","3fe104d1":"code","8f23c4cd":"code","e114820a":"code","787696f0":"code","fc0661b5":"markdown","81c69899":"markdown","e9d11297":"markdown"},"source":{"55286be9":"import numpy as np\nimport pandas as pd\nimport json\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import Ridge\nfrom scipy.sparse import csr_matrix, hstack\nfrom scipy.stats import probplot\nimport pickle\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nimport seaborn as sns \nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\n\ncolor = sns.color_palette()\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\nsns.palplot(color)\n\nimport os\nPATH = \"..\/input\"","7b4f697c":"!du -l ..\/input\/*","ca384465":"def read_json_line(line=None):\n    result = None\n    try:        \n        result = json.loads(line)\n    except Exception as e:      \n        # Find the offending character index:\n        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n        # Remove the offending character:\n        new_line = list(line)\n        new_line[idx_to_replace] = ' '\n        new_line = ''.join(new_line)     \n        return read_json_line(line=new_line)\n    return result\n\nfrom html.parser import HTMLParser\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        self.reset()\n        self.strict = False\n        self.convert_charrefs= True\n        self.fed = []\n    def handle_data(self, d):\n        self.fed.append(d)\n    def get_data(self):\n        return ''.join(self.fed)\n\ndef strip_tags(html):\n    s = MLStripper()\n    s.feed(html)\n    return s.get_data()\n\ndef extract_features(path_to_data):\n    \n    content_list = [] \n    published_list = [] \n    title_list = []\n    author_list = []\n    domain_list = []\n    tags_list = []\n    url_list = []\n    \n    with open(path_to_data, encoding='utf-8') as inp_json_file:\n        for line in inp_json_file:\n            json_data = read_json_line(line)\n#             content = json_data['content'].replace('\\n', ' ').replace('\\r', ' ') # ORIG\n            content = json_data['content'].replace('\\n', ' \\n ').replace('\\r', ' \\n ') # keep newline\n            content_no_html_tags = strip_tags(content)\n            content_list.append(content_no_html_tags)\n            published = json_data['published']['$date']\n            published_list.append(published) \n            title = json_data['meta_tags']['title'].split('\\u2013')[0].strip() #'Medium Terms of Service \u2013 Medium Policy \u2013 Medium'\n            title_list.append(title) \n            author = json_data['meta_tags']['author'].strip()\n            author_list.append(author) \n            domain = json_data['domain']\n            domain_list.append(domain)\n            url = json_data['url']\n            url_list.append(url)\n            \n            tags_str = []\n            soup = BeautifulSoup(content, 'lxml')\n            try:\n                tag_block = soup.find('ul', class_='tags')\n                tags = tag_block.find_all('a')\n                for tag in tags:\n                    tags_str.append(tag.text.translate({ord(' '):None, ord('-'):None}))\n                tags = ' '.join(tags_str)\n            except Exception:\n                tags = 'None'\n            tags_list.append(tags)\n            \n    return content_list, published_list, title_list, author_list, domain_list, tags_list, url_list","f706007e":"content_list, published_list, title_list, author_list, domain_list, tags_list, url_list = extract_features(os.path.join(PATH, 'how-good-is-your-medium-article\/train.json'))\ntrain = pd.DataFrame()\ntrain['content'] = content_list\ntrain['published'] = pd.to_datetime(published_list, format='%Y-%m-%dT%H:%M:%S.%fZ')\ntrain['title'] = title_list\ntrain['author'] = author_list\ntrain['domain'] = domain_list\ntrain['tags'] = tags_list\n# train['length'] = train['content'].apply(len)\ntrain['url'] = url_list\n\ncontent_list, published_list, title_list, author_list, domain_list, tags_list, url_list = extract_features(os.path.join(PATH, 'how-good-is-your-medium-article\/test.json'))\n\ntest = pd.DataFrame()\ntest['content'] = content_list\ntest['published'] = pd.to_datetime(published_list, format='%Y-%m-%dT%H:%M:%S.%fZ')\ntest['title'] = title_list\ntest['author'] = author_list\ntest['domain'] = domain_list\ntest['tags'] = tags_list\n# test['length'] = test['content'].apply(len)\ntest['url'] = url_list","0ce0421c":"del content_list, published_list, title_list, author_list, domain_list, tags_list, url_list\ngc.collect()","e85dd787":"train['target'] = pd.read_csv(os.path.join(PATH, 'how-good-is-your-medium-article\/train_log1p_recommends.csv'), index_col='id').values","3fe104d1":"train.tail()","8f23c4cd":"train.describe()","e114820a":"train.to_csv(\"mediumPopularity.csv.gz\",index=False,compression=\"gzip\")","787696f0":"test.to_csv(\"mediumPopularity_test.csv.gz\",index=False,compression=\"gzip\")","fc0661b5":"## 1.2. Data extraction","81c69899":"# Introduction:\nWhat is Medium? Medium is a dynamically developing international publishing platform for people to write, read and clap easily online. It is like the russian [habrahabr.ru](http:\/\/habrahabr.ru) just a little worse. We have two JSON files that contain published articles on Medium till 2018, March. There is number of claps to each article in the first file and there is no ones in the second file. Our goal is to predict the number of \"claps\" for articles in test. \nLet's start our EDA journey!","e9d11297":"# 1. Data preprocessing\n## 1.1. Supplementary functions"}}