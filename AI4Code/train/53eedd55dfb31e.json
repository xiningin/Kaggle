{"cell_type":{"f1249b77":"code","7df38153":"code","360a9ec2":"code","d63084b1":"code","f8b81d07":"code","0c603a15":"code","fa30f019":"code","4e4b03fa":"code","47f10a35":"code","6fd143a7":"code","f7914920":"code","b838b2e2":"code","5ebd5fa3":"code","0593838a":"code","df4d4ffe":"code","577d59c3":"code","ed20efc4":"code","8bbda451":"code","e7e903c2":"markdown","e4664a0a":"markdown","0bcc3a4f":"markdown","5f6e95cf":"markdown"},"source":{"f1249b77":"%cd ..\/\n!mkdir tmp\n%cd tmp","7df38153":"# Download YOLOv5\n!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n%cd yolov5\n# Install dependencies\n%pip install -qr requirements.txt  # install dependencies\n\n%cd ..\/\nimport torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","360a9ec2":"import os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom IPython.core.display import Video, display\nimport subprocess","d63084b1":"%cd ..\/\n\nTRAIN_PATH = 'input\/nfl-health-and-safety-helmet-assignment\/images\/'\nBATCH_SIZE = 16\nEPOCHS = 2\n\nprint(f'Number of extra images: {len(os.listdir(TRAIN_PATH))}') ","f8b81d07":"# Load image level csv file\nextra_df = pd.read_csv('input\/nfl-health-and-safety-helmet-assignment\/image_labels.csv')\nprint('Number of ground truth bounding boxes: ', len(extra_df))\n\n# Number of unique labels\nlabel_to_id = {label: i for i, label in enumerate(extra_df.label.unique())}\nprint('Unique labels: ', label_to_id)\n\n# Group together bbox coordinates belonging to the same image. \n# key is the name of the image, value is a dataframe with label and bbox coordinates. \nimage_bbox_label = {} \nfor image, df in extra_df.groupby('image'): \n    image_bbox_label[image] = df.reset_index(drop=True)\n\n# Visualize\nextra_df.head()","0c603a15":"# Create train and validation split.\ntrain_names, valid_names = train_test_split(list(image_bbox_label), test_size=0.2, random_state=42)\nprint(f'Size of dataset: {len(image_bbox_label)},\\\n       training images: {len(train_names)},\\\n       validation images: {len(valid_names)}')","fa30f019":"os.makedirs('tmp\/nfl_extra\/images\/train', exist_ok=True)\nos.makedirs('tmp\/nfl_extra\/images\/valid', exist_ok=True)\n\nos.makedirs('tmp\/nfl_extra\/labels\/train', exist_ok=True)\nos.makedirs('tmp\/nfl_extra\/labels\/valid', exist_ok=True)\n\n# Move the images to relevant split folder.\nfor img_name in tqdm(train_names):\n    copyfile(f'{TRAIN_PATH}\/{img_name}', f'tmp\/nfl_extra\/images\/train\/{img_name}')\n\nfor img_name in tqdm(valid_names):\n    copyfile(f'{TRAIN_PATH}\/{img_name}', f'tmp\/nfl_extra\/images\/valid\/{img_name}')","4e4b03fa":"import yaml\n\ndata_yaml = dict(\n    train = '..\/nfl_extra\/images\/train',\n    val = '..\/nfl_extra\/images\/valid',\n    nc = 5,\n    names = list(extra_df.label.unique())\n)\n\n# Note that the file is created in the yolov5\/data\/ directory.\nwith open('tmp\/yolov5\/data\/data.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)\n    \n%cat tmp\/yolov5\/data\/data.yaml","47f10a35":"def get_yolo_format_bbox(img_w, img_h, box):\n    \"\"\"\n    Convert the bounding boxes in YOLO format.\n    \n    Input:\n    img_w - Original\/Scaled image width\n    img_h - Original\/Scaled image height\n    box - Bounding box coordinates in the format, \"left, width, top, height\"\n    \n    Output:\n    Return YOLO formatted bounding box coordinates, \"x_center y_center width height\".\n    \"\"\"\n    w = box.width # width \n    h = box.height # height\n    xc = box.left + int(np.round(w\/2)) # xmin + width\/2\n    yc = box.top + int(np.round(h\/2)) # ymin + height\/2\n\n    return [xc\/img_w, yc\/img_h, w\/img_w, h\/img_h] # x_center y_center width height\n    \n# Iterate over each image and write the labels and bbox coordinates to a .txt file. \nfor img_name, df in tqdm(image_bbox_label.items()):\n    # open image file to get the height and width \n    img = cv2.imread(TRAIN_PATH+'\/'+img_name)\n    height, width, _ = img.shape \n    \n    # iterate over bounding box df\n    bboxes = []\n    for i in range(len(df)):\n        # get a row\n        box = df.loc[i]\n        # get bbox in YOLO format\n        box = get_yolo_format_bbox(width, height, box)\n        bboxes.append(box)\n    \n    if img_name in train_names:\n        img_name = img_name[:-4]\n        file_name = f'tmp\/nfl_extra\/labels\/train\/{img_name}.txt'\n    elif img_name in valid_names:\n        img_name = img_name[:-4]\n        file_name = f'tmp\/nfl_extra\/labels\/valid\/{img_name}.txt'\n        \n    with open(file_name, 'w') as f:\n        for i, bbox in enumerate(bboxes):\n            label = label_to_id[df.loc[i].label]\n            bbox = [label]+bbox\n            bbox = [str(i) for i in bbox]\n            bbox = ' '.join(bbox)\n            f.write(bbox)\n            f.write('\\n')","6fd143a7":"%cd tmp\/yolov5\/","f7914920":"# turn off W&B syncing if you don't need\n\nos.environ['WANDB_MODE'] = 'offline'","b838b2e2":"!python train.py --img 720 \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5s.pt \\\n                 --save_period 1 \\\n                 --project nfl-extra","5ebd5fa3":"data_dir = '\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/'\nexample_video = f'{data_dir}\/test\/57906_000718_Endzone.mp4'\n\n#video example\nfrac = 0.65\ndisplay(Video(example_video, embed=True, height=int(720*frac), width=int(1280*frac)))","0593838a":"# create frames from video\nimg_ext = 'png'\nimage_name = '57906_000718_Endzone'\nframe_dir = '\/kaggle\/tmp\/mp4_img\/'\nos.makedirs(frame_dir, exist_ok=True)\n\ncmd = 'ffmpeg -i \\\"{}\\\" -qscale:v 2 \\\"{}\/{}_%d.{}\\\"'.format(example_video, frame_dir, image_name, img_ext)\nprint(cmd)\nsubprocess.call(cmd, shell=True)","df4d4ffe":"# output folder name\nproject_name = '57906_000718_Endzone'\n# best weights after training\nbest_weights = 'nfl-extra\/exp\/weights\/best.pt'","577d59c3":"!python detect.py --weights {best_weights} \\\n                  --source {frame_dir} \\\n                  --img 720 \\\n                  --save-txt \\\n                  --save-conf \\\n                  --project {project_name}","ed20efc4":"# make video from frames\nvideo_name = '57906_000718_Endzone_fps60.mp4'\ntmp_video_path = os.path.join('\/kaggle\/working\/', f'tmp_{video_name}')\nvideo_path = os.path.join('\/kaggle\/working\/', video_name)\n\nframe_rate = 60\n\nimages = [img for img in os.listdir(f'{project_name}\/exp')]\nimages.remove('labels')\nimages.sort(key = lambda x: int(x.split('_')[-1][:-4]))\n\nframe = cv2.imread(os.path.join('57906_000718_Endzone\/exp', images[0]))\nheight, width, layers = frame.shape\n\nvideo = cv2.VideoWriter(tmp_video_path, cv2.VideoWriter_fourcc(*'MP4V'),\n                        frame_rate, (width,height))\n\nfor f in images:\n    img = cv2.imread(os.path.join('57906_000718_Endzone\/exp', f))\n    video.write(img)\n\nvideo.release()\n\n# Not all browsers support the codec, we will re-load the file at tmp_video_path\n# and convert to a codec that is more broadly readable using ffmpeg\n\nif os.path.exists(video_path):\n    os.remove(video_path)\n    \nsubprocess.run([\"ffmpeg\", \"-i\", tmp_video_path, \"-crf\", \"18\", \"-preset\", \"veryfast\",\n                \"-vcodec\",\"libx264\", video_path,])\n\nos.remove(tmp_video_path)","8bbda451":"frac = 0.65\ndisplay(Video(video_path, embed=True, height=int(720*frac), width=int(1280*frac)))","e7e903c2":"## Results","e4664a0a":"# YOLOv5 helmet detection\n\n**The goal of this notebook is to explore method for object detection, concretly helmet detection, using YOLOv5 model.**\n\nYOLOv5 (You only look once) \ud83d\ude80 is a family of object detection architectures and models pretrained on the COCO dataset, and represents Ultralytics open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\n\n\n### References\n\n* [Train] NFL Extra Images YOLOv5 with W&B - https:\/\/www.kaggle.com\/ayuraj\/train-nfl-extra-images-yolov5-with-w-b\/ \n* YOLOv5 repository - https:\/\/github.com\/ultralytics\/yolov5\n* NFL Helmet Assignment - Getting Started Guide - https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\n* MMDet CascadeRCNN helmet detection for beginners - https:\/\/www.kaggle.com\/eneszvo\/mmdet-cascadercnn-helmet-detection-for-beginners\n\n### Setup\n\nThe structure that requires YOLOv5\n\n```\n\/parent_folder\n    \/dataset\n         \/images\n         \/labels\n    \/yolov5\n```","0bcc3a4f":"### Inference","5f6e95cf":"The required folder structure for the dataset directory is:\n\n```\n\/parent_folder\n    \/dataset\n         \/images\n             \/train\n             \/val\n         \/labels\n             \/train\n             \/val\n    \/yolov5\n```"}}