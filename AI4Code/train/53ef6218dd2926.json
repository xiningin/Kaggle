{"cell_type":{"e675643d":"code","3d6c2713":"code","791fae1f":"code","56f18366":"code","c06e780d":"code","f7f50f6b":"code","fd5b466e":"code","5c4614ae":"code","9978055e":"code","461edaf9":"code","434ca64f":"code","51c53d2b":"code","2ac1a5c8":"code","a4d41f49":"code","5c490e6d":"code","2de61323":"code","89181ea0":"code","584a895b":"code","961c6aaf":"code","cbed69ba":"code","38f41b14":"code","26f8133e":"code","ba3906a4":"code","3b03c09e":"code","5a30e00d":"code","e939a585":"code","a7687752":"code","b2168e34":"code","db1546b2":"code","e7f09f3b":"code","92094bcd":"code","8d22454c":"code","02583726":"code","3d4ed8ae":"code","598c75c6":"code","ff56e9e0":"code","057de9b2":"code","dd19bef0":"code","7ee2a82f":"code","046f5bad":"code","c2152278":"code","199ab2b8":"code","f21f5e1b":"code","25a3db2c":"code","1e4dafef":"code","7edb60d5":"code","59f7bfcf":"code","b3e92c0d":"code","67f1f81f":"code","79c5fef3":"code","83f214b3":"code","4e5ff48d":"code","25e64f5e":"code","759f5f9b":"code","ae504e94":"code","fce4f7e7":"code","9fad4fed":"code","47850956":"code","3d411849":"code","cfe91805":"code","21f8d391":"code","6edb17f8":"code","4c12c675":"code","18971e38":"code","6cef585c":"code","d9010e8d":"code","cfe2022e":"code","0f0a9ac6":"code","5d47054f":"code","5962b7fc":"code","9b953905":"code","7a9d1efc":"code","781454ee":"code","7204d8a7":"code","d3759fb7":"code","b4965a0e":"code","9c02029b":"code","7bab9058":"code","96e0802c":"code","5165ff54":"code","50c4f5f6":"code","c81a45cf":"code","a7bf4bdc":"code","ed551b84":"code","b01bbd63":"code","b35daca3":"code","708bd647":"code","b113d43a":"code","3e360e1e":"code","18060799":"code","994a74d7":"code","f2716f7a":"code","e450f187":"code","57c3f69e":"code","2353d67e":"code","4b6101ca":"code","6b9c566d":"code","79288141":"code","215b00ef":"code","07d2637c":"code","323e881c":"code","c448e665":"code","8c5be2c9":"code","393e13e1":"markdown"},"source":{"e675643d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3d6c2713":"data = pd.read_csv('..\/input\/videogamesales\/vgsales.csv')","791fae1f":"data.info()","56f18366":"data.corr()","c06e780d":"f,ax=plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(),annot=True, linewidths=.5, fmt='.1f', ax=ax)","f7f50f6b":"data.head(30)","fd5b466e":"data.columns","5c4614ae":"data.JP_Sales.plot(kind = 'line', color = 'b',label = 'JP_Sales',linewidth= 1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Global_Sales.plot(color='r', label= 'Global_Sales', linewidth=1, alpha=0.5, grid=True, linestyle = '-.')\nplt.legend(loc='upper right')\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.title('Line plot')","9978055e":"data.plot(kind='scatter', x='EU_Sales', y='NA_Sales', alpha=0.5, color='red')\nplt.xlabel('EU_Sales')\nplt.ylabel('NA_Sales')","461edaf9":"data.Year.plot(kind='hist', bins = 50, figsize=(12,12))","434ca64f":"data.Year.plot(kind='hist', bins=50)\nplt.clf()","51c53d2b":"dictionary={'spain' : 'madrid', 'usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","2ac1a5c8":"series = data['Year']\nprint(type(series))\ndata_frame= data[['Year']]\nprint(type(data_frame))","a4d41f49":"x = data['NA_Sales']>24\ndata[x]","5c490e6d":"data[np.logical_and(data['NA_Sales']>10 , data['EU_Sales']<15)]","2de61323":"data[(data['NA_Sales']>10) & (data['EU_Sales']<15)]","89181ea0":"i=0\nwhile i!=5 : \n    print('i is : ',i)\n    i+=1\nprint('i is equal to 5')","584a895b":"lis=[1,2,3,4,5]\nfor i in lis:\n    print('i is : ',i)\nprint('')\nfor index, value in enumerate(lis):\n    print(index, ':', value)\nprint('')\ndictionary= {'spain' : 'madrid' , 'france' : 'paris'}\nfor key,value in dictionary.items():\n    print(key,':',value)\nfor index,value in data[['NA_Sales']][0:1].iterrows():\n    print(index, ' : ',value)","961c6aaf":"def tuble_ex():\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","cbed69ba":"x=2\ndef f():\n    x=3\n    return x\nprint(x)\nprint(f())","38f41b14":"x=5\ndef f():\n    y=x*2\n    return y\nprint(f())","26f8133e":"import builtins\ndir(builtins)","ba3906a4":"#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square()) ","3b03c09e":"#flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n#flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key,value in kwargs.items():\n        print(key,\" \",value)\nf(country = 'spain', capital = 'madrid', population = 123456)","5a30e00d":"#lambda function\nsquare = lambda x : x**2\nprint(square(5))\ntot = lambda x,y,z : x+y+z\nprint (tot(1,5,6))","e939a585":"number_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","a7687752":"#iteration example\nname = \"messi\"\nit = iter(name)\nprint(next(it))\nprint(*it)","b2168e34":"#zip example\nlist1= [1,2,3,4]\nlist2= [5,6,7,8]\nz= zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)","db1546b2":"un_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip)\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list1))","e7f09f3b":"#example of list comprehension\nnum1 = [5,10,15]\nnum2 = [i+1 for i in  num1]\nprint(num2)","92094bcd":"#conditionals of iterable\nnum1 = [3,6,10]\nnum2 = [i**2 if i==6 else i-1 if i<5 else i+10 for i in num1]\nprint(num2)","8d22454c":"threshold = sum(data.EU_Sales)\/len(data.EU_Sales)\ndata[\"EU_Sales\"] = [\"high\" if i > threshold*50 else \"low\" for i in data.EU_Sales]\ndata.loc[:10,[\"EU_Sales\",\"NA_Sales\"]]","02583726":"data=pd.read_csv('..\/input\/videogamesales\/vgsales.csv')\ndata.head()","3d4ed8ae":"data.tail()","598c75c6":"data.columns","ff56e9e0":"data.shape","057de9b2":"data.info()","dd19bef0":"print (data['Name'].value_counts(dropna = False))","7ee2a82f":"data.describe()","046f5bad":"data.boxplot(column='Rank', by='Year')","c2152278":"data_new = data.head()\ndata_new","199ab2b8":"melted = pd.melt(frame = data_new,id_vars = 'Name', value_vars= ['NA_Sales','EU_Sales'])\nmelted","f21f5e1b":"melted.pivot(index='Name',columns='variable',values= 'value')","25a3db2c":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True)\nconc_data_row","1e4dafef":"data1= data['EU_Sales'].head()\ndata2= data['NA_Sales'].head()\nconc_data_col = pd.concat([data1,data2],axis=1)\nconc_data_col","7edb60d5":"data.dtypes","59f7bfcf":"data['Name'] = data['Name'].astype('category')\ndata['Rank'] = data['Rank'].astype('float')","b3e92c0d":"data.dtypes","67f1f81f":"data.info()","79c5fef3":"data[\"Publisher\"].value_counts(dropna =False)","83f214b3":"data1=data\ndata1=data[\"Publisher\"].dropna(inplace=True)","4e5ff48d":"assert data['Publisher'].notnull().all()","25e64f5e":"data[\"Publisher\"].fillna('empty',inplace =True)","759f5f9b":"assert data [\"Publisher\"].notnull().all()","ae504e94":"# dataframes from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"Country\",\"Population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","fce4f7e7":"#add new columns\ndf[\"Capital\"] = [\"Madrid\",\"Spain\"]\ndf","9fad4fed":"df[\"income\"] = 0\ndf","47850956":"data1 = data.loc[:,[\"Year\",\"Rank\",\"EU_Sales\"]]\ndata1.plot()","3d411849":"data1.plot(subplots = True)","cfe91805":"data1.plot(kind=\"scatter\",x = \"EU_Sales\",y = \"Rank\")","21f8d391":"data1.plot(kind = \"hist\", y = \"Rank\", bins = 50, range=(0,20),normed=True)","6edb17f8":"#histogram subplot with non cumulative and cumulative\nfig,axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\", y = \"Rank\", bins = 50, range = (0,25), normed = True, ax=axes[0])\ndata1.plot(kind = \"hist\", y = \"Rank\", bins = 50, range = (0,25), normed = True, ax=axes[1], cumulative = True )\nplt.savefig('graph.png')\nplt","4c12c675":"data.describe()","18971e38":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1]))\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","6cef585c":"#close warning\n# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2","d9010e8d":"print(data2.loc[\"1993-03-16\"])","cfe2022e":"print(data2.loc[\"1992-03-10\" : \"1993-03-16\"])","0f0a9ac6":"data2.resample(\"A\").mean()","5d47054f":"data2.resample(\"M\").mean()","5962b7fc":"data2.resample(\"M\").median().interpolate(\"linear\")","9b953905":"data2.resample(\"M\").mean().interpolate(\"linear\")","7a9d1efc":"#MANIPULATING DATA FRAMES WITH PANDAS\n#read data\ndata = pd.read_csv('..\/input\/videogamesales\/vgsales.csv')\ndata = data.set_index(\"Rank\")\ndata.head()","781454ee":"data.Year[1]\n","7204d8a7":"data[\"Year\"][2]","d3759fb7":"data.loc[1,[\"JP_Sales\"]]","b4965a0e":"data[[\"Year\",\"EU_Sales\"]]","9c02029b":"#Slicing Data Frame\n#Difference between selecting columns : series and dataframes\nprint(type(data[\"Year\"]))\nprint(type(data[[\"Year\"]]))\n","7bab9058":"#slicing and indexing series\ndata.loc[1:10,\"Year\":\"EU_Sales\"]","96e0802c":"#Reverse slicing\ndata.loc[10:1:-1,\"Year\":\"EU_Sales\"]","5165ff54":"data.loc[1:10,\"NA_Sales\":]","50c4f5f6":"#Filtering Data Frames\n#Creating Boolean Series\nboolean = data.EU_Sales>10\ndata[boolean]","c81a45cf":"#Combining Filters\nfirst_filter = data.Year>2005\nsecond_filter = data.JP_Sales>4\ndata[first_filter & second_filter]","a7bf4bdc":"#Filtering column based others\ndata.Year[data.JP_Sales>6]","ed551b84":"#TRANSFORMING DATA\n#Plain Python functions\ndef div(n):\n    return n\/2\ndata.Global_Sales.apply(div)","b01bbd63":"data.Year.apply(lambda n:n\/2)","b35daca3":"data[\"total_sales\"] = data[\"EU_Sales\"] + data[\"NA_Sales\"]\ndata.head()","708bd647":"#INDEX OBJECTS AND LABELED DATA\nprint(data.index.name)\ndata.index.name = [\"index_name\"]\nprint(data.index.name)","b113d43a":"data.head()","3e360e1e":"data3 = data.copy()\ndata3.index = range(100,16698,1)\ndata3.head()","18060799":"#HIERARCHICAL INDEXING\n#Setting index : Publisher is outer , Platform is inner index\ndata1 = data.set_index([\"Publisher\",\"Platform\"]) \ndata1.head(100)","994a74d7":"#Pivoting Data Frames\ndic = {\"treatment\" : [\"A\",\"A\",\"B\",\"B\"],\"gender\" : [\"F\",\"M\",\"F\",\"M\"],\"response\" : [10,45,5,9],\"age\" : [15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","f2716f7a":"#pivoting\ndf.pivot(index = \"treatment\",columns = \"gender\", values = \"response\")","e450f187":"#STACKING and UNSTACKLING DATAFRAME\ndf1 = df.set_index([\"treatment\",\"gender\"])\ndf1","57c3f69e":"#level determines indexes\ndf1.unstack(level = 0)","2353d67e":"df1.unstack(level = 1)","4b6101ca":"#change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","6b9c566d":"#MELTING DATA FRAMES\ndf","79288141":"#df.pivot(index = \"treatment\",columns = \"gender\",values = \"response\")\npd.melt(df,id_vars = \"treatment\",value_vars = [\"age\",\"response\"])","215b00ef":"#CATEGORICALS AND GROUPBY\n#We will use df\ndf","07d2637c":"#according to treatment take means of other features\ndf.groupby(\"treatment\").mean()","323e881c":"#we can only choose one of the feature\ndf.groupby(\"treatment\").age.max()","c448e665":"#Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min()","8c5be2c9":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","393e13e1":"dictionary['spain']= \"barcelona\"\nprint(dictionary)\ndictionary['france']= \"paris\"\nprint(dictionary)\ndel dictionary['spain']\nprint(dictionary)\nprint ('france' in  dictionary) \ndictionary.clear()\nprint(dictionary)"}}