{"cell_type":{"4e9c050f":"code","b3b4bd1a":"code","882e990b":"code","74af7cc6":"code","83ebd1e4":"code","e03f21bb":"code","d29b63f1":"code","ea16bdb1":"code","303bf442":"code","0ce0af88":"code","35dcfc7d":"code","6e1b2d1a":"code","1692c595":"code","7643efce":"code","8ab74f03":"code","31e864c8":"code","6aaf3a44":"code","04bba06c":"code","3c62a4b4":"code","64d95a18":"code","d6278b1e":"code","f686f672":"code","7e295d66":"code","0b28f632":"code","437f55ea":"markdown","5db6c867":"markdown","33e3a65a":"markdown","f51ae5c7":"markdown","12447a31":"markdown","154e5478":"markdown","787fbc4e":"markdown","9ee3f510":"markdown","b148eb09":"markdown","a1df1d94":"markdown","3a869297":"markdown","8f2e12b1":"markdown","60cd4ba3":"markdown","2bbd91f3":"markdown"},"source":{"4e9c050f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3b4bd1a":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import preprocessing\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import train_test_split","882e990b":"plant_df = pd.read_csv(\"\/kaggle\/input\/solar-power-generation-data\/Plant_1_Generation_Data.csv\")\nplant_df.head()","74af7cc6":"plant_df.shape","83ebd1e4":"plant_df_columns = plant_df.columns.tolist()\nplant_df[plant_df_columns].isnull().sum()","e03f21bb":"plant_df['DATE_TIME']= pd.to_datetime(plant_df['DATE_TIME'],format='%d-%m-%Y %H:%M') ","d29b63f1":"SOURCE_KEY_list = plant_df['SOURCE_KEY'].unique()\nday_of_month_list = plant_df['DATE_TIME'].dt.day.unique()\nmonth_list = plant_df['DATE_TIME'].dt.month.unique()","ea16bdb1":"def data_collection():\n    main_df = pd.DataFrame()\n    for i in day_of_month_list:\n        for j in month_list:\n            df=plant_df[(plant_df.DATE_TIME.dt.month == j) & (plant_df.DATE_TIME.dt.day == i) ][-len(SOURCE_KEY_list):]\n            df = df.drop(['PLANT_ID', 'DC_POWER', 'AC_POWER', 'TOTAL_YIELD'],axis = 1)\n            df = df[df.DAILY_YIELD != 0]\n            main_df = main_df.append(df, ignore_index=True)\n    return main_df\nmain_df = data_collection()","303bf442":"main_df.index = main_df.DATE_TIME.dt.date.astype(\"datetime64[ns]\")\nmain_df = main_df.drop([\"DATE_TIME\"],axis=1)","0ce0af88":"for i in SOURCE_KEY_list:\n    df = main_df[main_df.SOURCE_KEY == i]\n    df.DAILY_YIELD.plot()\n    plt.title(\"SOURCE_KEY : %s\"%i)\n    plt.show()","35dcfc7d":"\nfor i in SOURCE_KEY_list:\n    df = main_df[main_df.SOURCE_KEY == i]\n    df.DAILY_YIELD.plot()\nplt.show()","6e1b2d1a":"Fault_SOURCE_KEY_list=  [\"McdE0feGgRqW7Ca\",\"bvBOhCH3iADSZry\",\"sjndEbLyjtCKgGv\",\"wCURE6d3bPkepu2\"]","1692c595":"#remove data who having Fault_SOURCE_KEY_list in main_df\nfor i in Fault_SOURCE_KEY_list:\n    main_df = main_df[main_df.SOURCE_KEY != i]","7643efce":"Unfault_SOURCE_KEY = main_df.SOURCE_KEY.unique()\nfor i in Unfault_SOURCE_KEY:\n    df = main_df[main_df.SOURCE_KEY == i]\n    df.DAILY_YIELD.plot()\nplt.show","8ab74f03":"main_df['dayofweek'] = main_df.index.dayofweek\nmain_df['quarter'] = main_df.index.quarter\nmain_df['month'] = main_df.index.month\nmain_df['year'] = main_df.index.year\nmain_df['dayofyear'] = main_df.index.dayofyear\nmain_df['dayofmonth'] = main_df.index.day\nmain_df['weekofyear'] = main_df.index.weekofyear","31e864c8":"label_encoder = preprocessing.LabelEncoder() \nmain_df['SOURCE_KEY']= label_encoder.fit_transform(main_df['SOURCE_KEY']) \nX = main_df[['SOURCE_KEY','dayofweek', 'quarter','month', 'year', 'dayofyear', 'dayofmonth', 'weekofyear']]\ny = main_df[\"DAILY_YIELD\"]\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=42)","6aaf3a44":"reg = xgb.XGBRegressor(n_estimators=500,\n                       objective ='reg:squarederror',\n                       learning_rate = 0.16,\n                       colsample_bytree=0.6,\n                       max_depth = 5,\n                       min_child_weight = 6)\nreg.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        early_stopping_rounds=50)","04bba06c":"plot_importance(reg, height=0.9)","3c62a4b4":"y_pred = reg.predict(X_test)\nmean_squared_error(y_test,y_pred,squared=False)","64d95a18":"# n = number of days to predict future generation\ndef create_df(n):\n    prediction_df = pd.DataFrame()\n    for i in range(0,n):\n        df = pd.DataFrame()\n        df[\"SOURCE_KEY\"] = Unfault_SOURCE_KEY\n        df[\"DATE_TIME\"] = \"2020-06-%d\"%(i+15)\n        prediction_df = prediction_df.append(df)\n    prediction_df['DATE_TIME']= pd.to_datetime(prediction_df['DATE_TIME']) \n    prediction_df.index = prediction_df.DATE_TIME.dt.date.astype(\"datetime64[ns]\")\n    prediction_df = prediction_df.drop([\"DATE_TIME\"],axis=1)\n    prediction_df['dayofweek'] = prediction_df.index.dayofweek\n    prediction_df['quarter'] = prediction_df.index.quarter\n    prediction_df['month'] = prediction_df.index.month\n    prediction_df['year'] = prediction_df.index.year\n    prediction_df['dayofyear'] = prediction_df.index.dayofyear\n    prediction_df['dayofmonth'] = prediction_df.index.day\n    prediction_df['weekofyear'] = prediction_df.index.week\n    return prediction_df\n        ","d6278b1e":"x = create_df(2)\ndf_copy = x.copy() \nx['SOURCE_KEY'] = label_encoder.fit_transform(x['SOURCE_KEY'])\n","f686f672":"y_prediction = reg.predict(x)","7e295d66":"df_copy[\"DAILY_YIELD_prediction\"] = y_prediction","0b28f632":"df_copy","437f55ea":"<a id=\"6\"><\/a>\n\n# Model build","5db6c867":"<a id=\"7\"><\/a>\n\n# Predict next two day generation","33e3a65a":"<a id=\"5\"><\/a>\n\n# Identify Faulty dust","f51ae5c7":"# Predict Power generation #plant_1\n\n<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">navigation<\/h3>\n\n* [1. Library](#1)\n* [2. Data reading](#2)\n* [3. Preprocessing](#3)\n* [4. Identify Faulty SOURCE_KEY](#4)\n* [5. Identify Faulty dust](#5)\n* [6. Model build](#6)\n* [7. Predict next two day generation](#7)\n","12447a31":"**Easily Identify faulty inverter side with graph of daily power generation.**","154e5478":"<a id=\"4\"><\/a>\n\n# Identify Faulty SOURCE_KEY","787fbc4e":"this model is not effective for predict for greater then 5 days because of we have only 34 days data.","9ee3f510":"# Please comment for any idea to get improvment of model also, Write comment for mistakes","b148eb09":"This is faulty inverter ID list  (Fault_SOURCE_KEY_list)","a1df1d94":"<a id=\"3\"><\/a>\n\n# Preprocessing","3a869297":"<a id=\"1\"><\/a>\n\n# Library","8f2e12b1":"<a id=\"2\"><\/a>\n\n# Data reading","60cd4ba3":"in below graph just increase irregularities with time is some other faulty like DUST and others","2bbd91f3":"**Can see some line suddenly drop down in below graph?**"}}