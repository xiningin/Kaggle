{"cell_type":{"4bbc598d":"code","49ab8341":"code","7a17acd5":"code","367de239":"code","68b8ab67":"code","c379e17d":"code","1df9d7df":"code","6fce7800":"code","2c8f7ce1":"code","199b243d":"code","7abb0c8b":"code","657f1ac5":"code","addafd15":"code","c64ffa1a":"code","458104ce":"code","812ef773":"code","e532e573":"code","2e1c7aa0":"code","e75358d8":"code","78f732b8":"code","2cb0d63f":"code","f3f97573":"code","720e88ad":"code","e97c13ac":"code","d901a0fb":"code","7f520550":"code","4f3d6ac5":"code","46a5e109":"code","eb86c544":"code","e4b4d7ee":"code","cefc498f":"code","9a843b66":"code","afdc67c0":"code","3449d165":"code","970d9c77":"code","0de61be3":"code","71b08139":"code","0b5c5fde":"code","1a7a4663":"code","364b1aed":"code","6c326b10":"code","57fbd4e2":"code","c6d3dc40":"markdown","a0e6fbb2":"markdown","6f0b6648":"markdown","ecc45740":"markdown","a4f31290":"markdown","7bcdba64":"markdown","2dc57fda":"markdown","8cd9c376":"markdown","4e8b4182":"markdown","e3240635":"markdown","4ba5e2b1":"markdown","2425de49":"markdown","667f245b":"markdown","238b8fc8":"markdown","19110723":"markdown"},"source":{"4bbc598d":"#import the necessary libraries required \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn import metrics\n\n#%matplotlib notebook\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))","49ab8341":"#read the data file\nhousing = pd.read_csv(\"..\/input\/housing.csv\")","7a17acd5":"print(\"The number of rows and colums are {} and also called shape of the matrix\".format(housing.shape))\nprint(\"Columns names are \\n {}\".format(housing.columns))\n","367de239":"print(housing.head())\n","68b8ab67":"print(housing.tail())","c379e17d":"print(housing.dtypes)","1df9d7df":"#display scatter_matrix also\nfig = plt.figure()\nscatter_matrix(housing,figsize =(25,25),alpha=0.9,diagonal=\"kde\",marker=\"o\");\n","6fce7800":"housing.hist(figsize=(25,25),bins=50);","2c8f7ce1":"hcorr = housing.corr()\nhcorr.style.background_gradient()","199b243d":"#heatmap using seaborn\n#set the context for plotting \nsns.set(context=\"paper\",font=\"monospace\")\nhousing_corr_matrix = housing.corr()\n#set the matplotlib figure\nfig, axe = plt.subplots(figsize=(12,8))\n#Generate color palettes \ncmap = sns.diverging_palette(220,10,center = \"light\", as_cmap=True)\n#draw the heatmap\nsns.heatmap(housing_corr_matrix,vmax=1,square =True, cmap=cmap,annot=True );","7abb0c8b":"def getOutliers(dataframe,column):\n    column = \"total_rooms\" \n    #housing[column].plot.box(figsize=(8,8))\n    des = dataframe[column].describe()\n    desPairs = {\"count\":0,\"mean\":1,\"std\":2,\"min\":3,\"25\":4,\"50\":5,\"75\":6,\"max\":7}\n    Q1 = des[desPairs['25']]\n    Q3 = des[desPairs['75']]\n    IQR = Q3-Q1\n    lowerBound = Q1-1.5*IQR\n    upperBound = Q3+1.5*IQR\n    print(\"(IQR = {})Outlier are anything outside this range: ({},{})\".format(IQR,lowerBound,upperBound))\n    #b = df[(df['a'] > 1) & (df['a'] < 5)]\n    data = dataframe[(dataframe [column] < lowerBound) | (dataframe [column] > upperBound)]\n\n    print(\"Outliers out of total = {} are \\n {}\".format(housing[column].size,len(data[column])))\n    #remove the outliers from the dataframe\n    outlierRemoved = housing[~housing[column].isin(data[column])]\n    return outlierRemoved","657f1ac5":"#get the outlier\ndf_outliersRemoved = getOutliers(housing,\"total_rooms\")","addafd15":"#check wheather there are any missing values or null\nhousing.isnull().sum()","c64ffa1a":"#Total_bedrooms columns is having 207 missing values\n#Now we need to impute the missing values","458104ce":"#statistics for missing values\nprint (\"Total_bedrooms column Mode is  \"+str(housing[\"total_bedrooms\"].mode())+\"\\n\")\nprint(housing[\"total_bedrooms\"].describe())","812ef773":"total_bedroms = housing[housing[\"total_bedrooms\"].notnull()][\"total_bedrooms\"]#[\"total_bedrooms\"]\ntotal_bedroms.hist(figsize=(12,8),bins=50)","e532e573":"print(housing.iloc[:,4:5].head())\nimputer = Imputer(np.nan,strategy =\"median\")\nimputer.fit(housing.iloc[:,4:5])\nhousing.iloc[:,4:5] = imputer.transform(housing.iloc[:,4:5])\nhousing.isnull().sum()","2e1c7aa0":"## Label encode for categorical feature (ocean_proximity)","e75358d8":"labelEncoder = LabelEncoder()\nprint(housing[\"ocean_proximity\"].value_counts())\nhousing[\"ocean_proximity\"] = labelEncoder.fit_transform(housing[\"ocean_proximity\"])\nhousing[\"ocean_proximity\"].value_counts()\nhousing.describe()","78f732b8":"housing_ind = housing.drop(\"median_house_value\",axis=1)\nprint(housing_ind.head())\nhousing_dep = housing[\"median_house_value\"]\nprint(\"Medain Housing Values\")\nprint(housing_dep.head())","2cb0d63f":"#check for rand_state\nX_train,X_test,y_train,y_test = train_test_split(housing_ind,housing_dep,test_size=0.2,random_state=42)\n#print(X_train.head())\n#print(X_test.head())\n#print(y_train.head())\n#print(y_test.head())\nprint(\"X_train shape {} and size {}\".format(X_train.shape,X_train.size))\nprint(\"X_test shape {} and size {}\".format(X_test.shape,X_test.size))\nprint(\"y_train shape {} and size {}\".format(y_train.shape,y_train.size))\nprint(\"y_test shape {} and size {}\".format(y_test.shape,y_test.size))\n","f3f97573":"X_train.head()","720e88ad":"#Standardize training and test datasets.\n#==============================================================================\n# Feature scaling is to bring all the independent variables in a dataset into\n# same scale, to avoid any variable dominating  the model. Here we will not \n# transform the dependent variables.\n#==============================================================================\nindependent_scaler = StandardScaler()\nX_train = independent_scaler.fit_transform(X_train)\nX_test = independent_scaler.transform(X_test)\nprint(X_train[0:5,:])\nprint(\"test data\")\nprint(X_test[0:5,:])","e97c13ac":"#initantiate the linear regression\nlinearRegModel = LinearRegression(n_jobs=-1)\n#fit the model to the training data (learn the coefficients)\nlinearRegModel.fit(X_train,y_train)\n#print the intercept and coefficients \nprint(\"Intercept is \"+str(linearRegModel.intercept_))\nprint(\"coefficients  is \"+str(linearRegModel.coef_))","d901a0fb":"#predict on the test data\ny_pred = linearRegModel.predict(X_test)","7f520550":"print(len(y_pred))\nprint(len(y_test))\nprint(y_pred[0:5])\nprint(y_test[0:5])\n","4f3d6ac5":"test = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\nfig= plt.figure(figsize=(16,8))\ntest = test.reset_index()\ntest = test.drop(['index'],axis=1)\nplt.plot(test[:50])\nplt.legend(['Actual','Predicted'])\nsns.jointplot(x='Actual',y='Predicted',data=test,kind='reg',);","46a5e109":"print(np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\nprint(np.sqrt(metrics.mean_squared_error(y_train,linearRegModel.predict(X_train))))\n","eb86c544":"dtReg = DecisionTreeRegressor(max_depth=9)\ndtReg.fit(X_train,y_train)","e4b4d7ee":"dtReg_y_pred = dtReg.predict(X_test)\ndtReg_y_pred","cefc498f":"print(len(dtReg_y_pred))\nprint(len(y_test))\nprint(dtReg_y_pred[0:5])\nprint(y_test[0:5])","9a843b66":"print(np.sqrt(metrics.mean_squared_error(y_test,dtReg_y_pred)))","afdc67c0":"test = pd.DataFrame({'Predicted':dtReg_y_pred,'Actual':y_test})\nfig= plt.figure(figsize=(16,8))\ntest = test.reset_index()\ntest = test.drop(['index'],axis=1)\nplt.plot(test[:50])\nplt.legend(['Actual','Predicted'])\nsns.jointplot(x='Actual',y='Predicted',data=test,kind=\"reg\")","3449d165":"rfReg = RandomForestRegressor(30)\nrfReg.fit(X_train,y_train)","970d9c77":"rfReg_y_pred = rfReg.predict(X_test)\nprint(len(rfReg_y_pred))\nprint(len(y_test))\nprint(rfReg_y_pred[0:5])\nprint(y_test[0:5])","0de61be3":"print(np.sqrt(metrics.mean_squared_error(y_test,rfReg_y_pred)))","71b08139":"test = pd.DataFrame({'Predicted':dtReg_y_pred,'Actual':y_test})\nfig= plt.figure(figsize=(16,8))\ntest = test.reset_index()\ntest = test.drop(['index'],axis=1)\nplt.plot(test[:50])\nplt.legend(['Actual','Predicted'])\nsns.jointplot(x='Actual',y='Predicted',data=test,kind=\"reg\")","0b5c5fde":"#Extract median_income \ndropcol = [\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"ocean_proximity\"]\nprint(dropcol)\nhousing_med = housing_ind.drop(dropcol,axis=1)\nprint(type(housing_med))","1a7a4663":"#check for rand_state\nX_train2,X_test2,y_train2,y_test2 = train_test_split(housing_med,housing_dep,test_size=0.2,random_state=42)\n#print(X_train.head())\n#print(X_test.head())\n#print(y_train.head())\n#print(y_test.head())\nprint(\"X_train2 shape {} and size {}\".format(X_train2.shape,X_train2.size))\nprint(\"X_test2 shape {} and size {}\".format(X_test2.shape,X_test2.size))\nprint(\"y_train2 shape {} and size {}\".format(y_train2.shape,y_train2.size))\nprint(\"y_test2 shape {} and size {}\".format(y_test2.shape,y_test2.size))","364b1aed":"linReg2 = LinearRegression()\nlinReg2.fit(X_train2,y_train2)","6c326b10":"y_pred2 = linReg2.predict(X_test2)\nprint(len(y_pred2))\nprint(len(y_test2))\nprint(y_pred2[0:5])\nprint(y_test2[0:5])","57fbd4e2":"fig = plt.figure(figsize=(25,8))\nplt.scatter(y_test2,y_pred2,marker=\"o\",edgecolors =\"r\",s=60)\nplt.scatter(y_train2,linReg2.predict(X_train2),marker=\"+\",s=50,alpha=0.5)\nplt.xlabel(\" Actual median_house_value\")\nplt.ylabel(\" Predicted median_house_value\")","c6d3dc40":"## Reading data","a0e6fbb2":"## Split the dataset into 80% train and 20% test dataset","6f0b6648":"# Summary\n\nObservations : The median_income , totat_bedrooms have highly skewed data.The data is highly unbalance. \n ","ecc45740":"## Importing Libraries","a4f31290":"#### The median house values are continuous and hence it is a regression problem\n#### One of the column is a categorical feature (ocean_proximity)","7bcdba64":"## Basic Data Analysis or Exploratory Data Analysis","2dc57fda":"## Perform Decision Tree Regression\nPerform Decision Tree Regression on training data.\nPredict output for test dataset using the fitted model.\n\nPrint root mean squared error from Decision Tree Regression.","8cd9c376":"### Get the Outliers","4e8b4182":"## Standardize the data ","e3240635":"## Perform Linear Regression\nPerform Linear Regression on training data.\nPredict output for test dataset using the fitted model.\nPrint root mean squared error (RMSE) from Linear Regression.\n(HINT: Import mean_squared_error from sklearn.metrics)\n","4ba5e2b1":"# California Housing Price Prediction\n\nThe purpose of the project is to predict median house values in Californian districts, given many features from these districts.","2425de49":"## Impute the missing values in the data set","667f245b":"## Perform Random Forest Regression\nPerform Random Forest Regression on training data.\nPredict output for test dataset using the fitted model.\nPrint RMSE (root mean squared error) from Random Forest Regression.","238b8fc8":"####   Root Mean Squared Error (RMSE)","19110723":"##  Performing Linear Regression with one independent Variable\n\nExtract just the median_income column from the independent \nvariables (from X_train and X_test).\nPerform Linear Regression to predict housing values based on \nmedian_income.\nPredict output for test dataset using the fitted model.\nPlot the fitted model for training data as well as for test data to \ncheck if the fitted model satisfies the test data.\n"}}