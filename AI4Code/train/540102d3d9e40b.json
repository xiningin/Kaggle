{"cell_type":{"16770e05":"code","ee961b11":"code","aaa3f1f2":"code","e404b937":"code","7709a373":"code","73a5c71b":"code","0df3f461":"code","4273cb29":"code","e7e3e060":"code","41b46aec":"code","c19fc70a":"code","69f3fb8a":"code","d1d2b54a":"code","c49b09ea":"code","de382083":"code","34b4baa4":"code","040c3fe0":"code","a1a58646":"code","e70ca73a":"code","bb99667a":"code","35613ad4":"code","dc6a5c39":"code","5cb2baae":"code","cb9302ba":"code","4efde9b1":"code","b3bff875":"code","c674b1e7":"code","6501ae14":"code","28a67b8d":"code","21b06b39":"code","e32dd790":"code","4ff49e60":"code","016f9248":"code","1400ba5d":"code","b6276e53":"code","287f775b":"code","c2200ee0":"code","ac966247":"code","1a327920":"code","625b4a4c":"code","0901133e":"code","26ad7e7f":"code","3e398fd4":"code","c6daee68":"code","878721dd":"code","d5ceb8a6":"code","6bfe34d2":"code","4948b927":"code","65eddde0":"code","69e95137":"code","97719f95":"code","268f7696":"code","513d59d0":"code","fe53cbce":"code","baaf5a58":"code","346b56ce":"code","90b955ee":"code","03a78e60":"code","c5f654f1":"code","179b45dd":"code","a6af0096":"code","6f578100":"code","4f235465":"code","d602bc63":"code","4ee25cbd":"code","1cfe0b8b":"code","5d6ce955":"code","7d06941a":"code","2965d9ae":"code","3e178cbe":"code","f39f7520":"markdown","9c17ffa7":"markdown","e263b5e9":"markdown","3c314b16":"markdown","3de06241":"markdown","6b0e663c":"markdown","5c1d6dd4":"markdown","6d9b0c7a":"markdown","1612c256":"markdown","2bf1b339":"markdown","df293f1c":"markdown","781fea75":"markdown","c4abdf91":"markdown","0046ce8d":"markdown","be1289d6":"markdown","b406ad43":"markdown","d3c42fd6":"markdown","fb7f7327":"markdown","d06e5962":"markdown","12eace4e":"markdown","bd22f605":"markdown","49cfac1a":"markdown","18a758e6":"markdown","97db628e":"markdown","403fa9bb":"markdown","6d45a73e":"markdown","78a56c36":"markdown","5b40e323":"markdown"},"source":{"16770e05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport tensorflow as tf\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee961b11":"def get_elo_of_players_in_match(df,matchnr):\n    getmatchID = df.matchId[matchnr]\n    eloLIstrank  = df.rankPoints[df['matchId'] == getmatchID]\n    eloListWin = df.winPoints[df['matchId'] == getmatchID]\n    eloLIstrank = np.sort(eloLIstrank)\n    eloListWin = np.sort(eloListWin)\n    return  eloLIstrank,eloListWin\ndef create_cat_values(dataframe,column):\n    dataframe[column] = dataframe[column].astype('category')\n    dataframe[column] = dataframe[column].cat.codes\n    column_lenght = len(dataframe[column].unique())\n    print(column + ' columnContains:' + str(column_lenght) + ' categories')\n    return dataframe","aaa3f1f2":"df = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/train_V2.csv')","e404b937":"df.columns","7709a373":"print(get_elo_of_players_in_match(df,20))\nget_elo_of_players_in_match(df,21)","73a5c71b":"df.rankPoints[df['matchId'] == 'd5f02b7d5ed782']","0df3f461":"create_cat_values(df,'Id')\ncreate_cat_values(df,'groupId')\ncreate_cat_values(df,'matchId')","4273cb29":"solo = df[df.matchType == 'solo']\nduo = df[df.matchType == 'duo']\nsquad = df[df.matchType == 'squad']\nsolofpp = df[df.matchType == 'solo-fpp']\nduofpp = df[df.matchType == 'duo-fpp']\nsquadfpp = df[df.matchType == 'squad-fpp']\nprint('Solo subset size ' + str(len(solo)))\nprint('Duo subset size ' + str(len(duo)))\nprint('Squad subset size ' + str(len(squad)))\nprint('SoloFPP subset size ' + str(len(solofpp)))\nprint('DuoFPP subset size '+ str(len(duofpp)))\nprint('SquadFPP subset size '+ str(len(squadfpp)))","e7e3e060":"squadfpp","41b46aec":"test = squadfpp.groupby(['groupId','matchId']).count()\ntest","c19fc70a":"test[test['Id']> 4]","69f3fb8a":"test[test['Id']> 30]","d1d2b54a":"#squadfpp[squadfpp['matchId']== 20999].groupby('groupId').count()\nsquadfpp[squadfpp['groupId']== 1297474]","c49b09ea":"solofirst = solofpp[['Id','groupId']].groupby('groupId').count().max()[0]\nsolothird = solo[['Id','groupId']].groupby('groupId').count().max()[0]\nsquadfirst = squadfpp[['Id','groupId']].groupby('groupId').count().max()[0]\nsquadthird = squad[['Id','groupId']].groupby('groupId').count().max()[0]\nduofirst = duofpp[['Id','groupId']].groupby('groupId').count().max()[0]\nduothird = duo[['Id','groupId']].groupby('groupId').count().max()[0]\nprint('Solo max group FP:' + str(solofirst) + \" TP:\" + str(solothird) )\nprint('Squad max group FP:' + str(squadfirst) + \" TP:\" +str(squadthird))\nprint('Duo max group FP:' + str(duofirst) + \" TP:\" +str(duothird))","de382083":"listofcount = solofpp[['matchId','groupId','Id']].groupby(['groupId','matchId']).count()\nlistofcount.Id >2 \n#listofcount[listofcount['Id'] > solo].index[0][1]","34b4baa4":"# Creating benchmark of player number\nsolot = 1\nduot = 2\nsquadt = 4\n\ndef get_all_matches(df,maxplayer):\n    matcharr = []\n    listofcount = df[['matchId','groupId','Id']].groupby(['groupId','matchId']).count()\n    listofcount = listofcount[listofcount['Id'] > solot].index\n    i = 0\n    for items in listofcount:\n        matchid = items[1]\n        matcharr.append(matchid)\n        i = i + 1\n    print(\"Unique number of games: \"+str(len(df['matchId'].unique()))+\" Unique number of games with more than the acceptable groupnumbers: \"+str(len(np.unique(matcharr))))\n    matcharr = np.unique(matcharr)\n    return matcharr\nsolofppmatchestodrop = get_all_matches(solofpp,solot)\nsolomatchestodrop = get_all_matches(solo,solot)\nget_all_matches(duofpp,duot)\nget_all_matches(duo,duot)\nget_all_matches(squadfpp,squadt)\nget_all_matches(squad,squadt)","040c3fe0":"len(solofppmatchestodrop)","a1a58646":"lenbefore = len(solofpp)\nfor items in solofppmatchestodrop:\n    solofpp = solofpp[solofpp.matchId != items]\nlenafter = len(solofpp)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))\n\nlenbefore = len(solo)\nfor items in solomatchestodrop:\n    solo = solo[solo.matchId != items]\nlenafter = len(solo)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))","e70ca73a":"print(len(solofpp['matchId'].unique()))\nlen(solo['matchId'].unique())","bb99667a":"solofpp.columns\nsolofpp = solofpp[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints','rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'winPlacePerc']]\nsolo.columns\nsolo = solo[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints','rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'winPlacePerc']]","35613ad4":"solofpp","dc6a5c39":"def createplots(df):\n    coltoplot = ['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'winPlacePerc']\n    for columns in coltoplot:\n        plt.scatter(df.winPlacePerc, df[columns], alpha=0.5)\n        plt.title(columns)\n        plt.xlabel('Placement')\n        plt.ylabel(columns)\n        plt.show()","5cb2baae":"createplots(solofpp)","cb9302ba":"solofpp.columns","4efde9b1":"boxplot = solofpp.boxplot(['winPlacePerc'])","b3bff875":"solofpp","c674b1e7":"solofpp.columns\ncol = ['damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration','winPlacePerc']#,\n       #'rideDistance', 'roadKills',\n       #'swimDistance', 'vehicleDestroys', 'walkDistance',\n       #'weaponsAcquired']","6501ae14":"corrMatrix = solofpp[col].corr()\nsn.heatmap(corrMatrix, annot=True)\nplt.show()","28a67b8d":"solofpp.nunique()","21b06b39":"from sklearn.model_selection import train_test_split\nsolofpp = solofpp.dropna()\nsolofpp.isnull().sum()\ny_train = solofpp['winPlacePerc']\nX_train = solofpp[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']]\nX_train = X_train[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))\n###############################\n#           Validate          #\n###############################\ny_val = solo['winPlacePerc']\nX_val = solo[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))","e32dd790":"print(solofpp.dtypes)","4ff49e60":"X_train.count()","016f9248":"import matplotlib.pyplot as plt\nfor items in X_train.columns:\n    plt.figure()\n    X_train.boxplot([items])\n","1400ba5d":"model = tf.keras.Sequential(\n    [\n        tf.keras.layers.Dense(300, activation=\"relu\", name=\"Input_layer\"),\n        tf.keras.layers.Dense(100, activation=\"relu\"),\n        tf.keras.layers.Dense(100, activation=\"relu\"),\n        tf.keras.layers.Dense(80, activation=\"relu\"),\n        tf.keras.layers.Dense(40, activation=\"relu\"),\n        tf.keras.layers.Dense(30, activation=\"relu\"),\n        tf.keras.layers.Dense(20, activation=\"relu\"),\n        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n    ]\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n    # Loss function to minimize\n    loss='mse',\n    # List of metrics to monitor\n    metrics=['MSE'],\n)\nhistory  = model.fit(X_train,y_train,epochs = 200)","b6276e53":"networkoutput = model.predict(X_train)","287f775b":"prediction = y_train.values","c2200ee0":"# Create a dataframe to hold the predicted, actual and difference between the two.\ndf_to_test_difference = pd.DataFrame(networkoutput,columns = ['Prediction'])\ndf_to_test_difference['Actual'] = prediction\ndf_to_test_difference['Difference'] = df_to_test_difference['Actual']- df_to_test_difference['Prediction']","ac966247":"df_to_test_difference","1a327920":"print(\"Average deviation: \")\nprint(df_to_test_difference['Difference'].mean())\nprint('Maximum deviation: ')\nprint(df_to_test_difference['Difference'].max())\nprint('Minimum deviation: ')\nprint(df_to_test_difference['Difference'].min())","625b4a4c":"import matplotlib.pyplot as plt\nplt.scatter(df_to_test_difference.Prediction,df_to_test_difference.Actual)","0901133e":"ax = sns.boxplot(x=df_to_test_difference[\"Difference\"])","26ad7e7f":"val_prediction = model.predict(X_val)\n# Create a dataframe to hold the predicted, actual and difference between the two.\ndf_to_val_difference = pd.DataFrame(val_prediction,columns = ['Prediction'])\ndf_to_val_difference['Actual'] = y_val.values\ndf_to_val_difference['Difference'] = df_to_val_difference['Actual']- df_to_val_difference['Prediction']\ndf_to_val_difference","3e398fd4":"print(\"Average deviation: \")\nprint(df_to_val_difference['Difference'].mean())\nprint('Maximum deviation: ')\nprint(df_to_val_difference['Difference'].max())\nprint('Minimum deviation: ')\nprint(df_to_val_difference['Difference'].min())","c6daee68":"plt.scatter(df_to_val_difference.Prediction,df_to_val_difference.Actual)","878721dd":"ax = sns.boxplot(x=df_to_val_difference[\"Difference\"])","d5ceb8a6":"colls = ['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints','rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']\nrawtest = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/test_V2.csv')\ntesetdf = rawtest\n","6bfe34d2":"solotest = tesetdf[df.matchType == 'solo']\nduotest = tesetdf[tesetdf.matchType == 'duo']\nsquadtest = tesetdf[tesetdf.matchType == 'squad']\nsolofpptest = tesetdf[tesetdf.matchType == 'solo-fpp']\nduofpptest = tesetdf[tesetdf.matchType == 'duo-fpp']\nsquadfpptest = tesetdf[tesetdf.matchType == 'squad-fpp']","4948b927":"squadfpp.columns","65eddde0":"solotestmatchestodrop = get_all_matches(solotest,solot)\nsolofpptestmatchestodrop = get_all_matches(solofpptest,solot)\nget_all_matches(duotest,duot)\nget_all_matches(duofpptest,duot)\nget_all_matches(squadtest,squadt)\nget_all_matches(squadfpptest,squadt)","69e95137":"lenbefore = len(solofpptest)\nfor items in solofpptestmatchestodrop:\n    solofpptest = solofpptest[solofpptest.matchId != items]\nlenafter = len(solofpptest)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))\n\nlenbefore = len(solotest)\nfor items in solotestmatchestodrop:\n    solotest = solotest[solotest.matchId != items]\nlenafter = len(solotest)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))","97719f95":"Idtouse = solotest['Id']\nsolotest = solotest[colls].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))\nsolofpptest = solofpptest[colls].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))\ntesetdf = tesetdf[colls].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))","268f7696":"testoutput = model.predict(solotest)\nsolotest['Id'] = Idtouse\nsolotest['winPlacePerc'] = testoutput","513d59d0":"solotest[['Id','winPlacePerc']]","fe53cbce":"legal_model_output = model.predict(tesetdf)","baaf5a58":"#tesetdf = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/test_V2.csv')\nlegalmodelsub = rawtest\nrawtest['winPlacePerc'] = legal_model_output\nsubmissionlegalmoves = rawtest[['Id','winPlacePerc']]\n#submissionlegalmoves\nsubmissionlegalmoves.to_csv(\"submission.csv\",index = False)","346b56ce":"submissionlegalmoves","90b955ee":"submissionlegal_full_games = solotest[['Id','winPlacePerc']]\nsubmissionlegal_full_games\n#submissionlegal_full_games.to_csv(\"submission.csv\",index = False)\n#submissionlegal_full_games","03a78e60":"submissiondf = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/sample_submission_V2.csv')\nsubmissiondf","c5f654f1":"#traindata = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/train_V2.csv')","179b45dd":"#traindata = traindata.dropna()","a6af0096":"#y_train2 = traindata['winPlacePerc']\n#X_train2 = traindata[['assists', 'boosts', 'damageDealt',\n#       'headshotKills', 'heals', 'killPoints', 'kills',\n#       'killStreaks', 'longestKill', 'matchDuration',\n#       'rankPoints', 'rideDistance', 'roadKills',\n#       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n#       'weaponsAcquired', 'winPoints']].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))","6f578100":"#model_fulldata = tf.keras.Sequential(\n#    [\n#        tf.keras.layers.Dense(300, activation=\"relu\", name=\"Input_layer\"),\n#        tf.keras.layers.Dense(100, activation=\"relu\"),\n#        tf.keras.layers.Dense(100, activation=\"relu\"),\n#        tf.keras.layers.Dense(80, activation=\"relu\"),\n#        tf.keras.layers.Dense(40, activation=\"relu\"),\n#        tf.keras.layers.Dense(30, activation=\"relu\"),\n#        tf.keras.layers.Dense(20, activation=\"relu\"),\n#        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n#    ]\n#)\n\n#model_fulldata.compile(\n#    optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n    # Loss function to minimize\n#    loss='mse',\n    # List of metrics to monitor\n#    metrics=['MSE'],\n#)\n#history  = model_fulldata.fit(X_train2,y_train2,epochs = 20)","4f235465":"#modeloutputfull_data[0]","d602bc63":"#tesetdf.head(1)","4ee25cbd":"#Idtouse = tesetdf['Id']\n#tesetdf\n#tesetdf = tesetdf[colls].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))","1cfe0b8b":"#modeloutputfull_data = model_fulldata.predict(tesetdf)","5d6ce955":"#tesetdf['Id'] = Idtouse\n#tesetdf['winPlacePerc'] = modeloutputfull_data","7d06941a":"#tesetdf","2965d9ae":"#submissionfulldata = tesetdf[['Id','winPlacePerc']]\n#submissionfulldata","3e178cbe":"#submissionfulldata.to_csv(\"submission.csv\",index = False)","f39f7520":"### 4.1.1 Different group size per game","9c17ffa7":"# Illegal matches\nBelow you can find how we managed to take into account what illegal matches are","e263b5e9":"Example of what the submission needs to look like\n","3c314b16":"## Submitting the full dataset","3de06241":"# Test the model\nLuckily we had some Solo games that are also useable we will make them ready for usage and run the model over the data and see what kind of results we get!","6b0e663c":"For the first version we will be focussing on the SoloFPP subset, as pefromance per player can only be measured by one person.","5c1d6dd4":"This graph displays the distribution when we look at the differnce between the prediction and actual number","6d9b0c7a":"### 4.1.2 Dropping unnecesarry columns\nDropping:\n - MatchId\n - group_Id\n - Id\n - Matchtype\n - Num groups\n - maxPlace \n - killplace\n<br><br>\nSince these are solo matches we need to drop the following columns too:\n - Revives\n - DBNOs","1612c256":"### 4.1 Dealing with data inconsistencies\n1. Different group size per game.\n  - Some squad matches contain, group sizes that exceed 4. There can be multiple reasons for this, we have for now decided to drop all matches containing a groupsize bigger than 4.\n  - Same can be said for duo games when it comes to having a maximum of 2 people per group.\n  - Same goes for solo where you cant have more than 2 people in the same group.\n2. Certain columns will be dropped.\n  - Not all features actually add any value, features such as killrank in a game doesn't add much. We can much better use the kills themselves","2bf1b339":"# 1. Imports","df293f1c":"# Conclusion\nThe network works fairly well, it is able to predict in such a manner that the difference between the prediction and acutal number can be foreseen. There are some outliers but these seem merely a formality","781fea75":"The best way to evaluate the model is by looking at the mean value that deviates from the prediction","c4abdf91":"# 6. Modelling\n## 6.1 Model for legal matches","0046ce8d":"# Notebook explenation\nThis notebook is taken for the challenge of the ADS Minor at Fontys Hogeschool ICT. \n<br><br>\nThe goal of the challenge is to apply what we have learned in the course of the minor.\n<br><br>\nFor the challenge Max de Goede and Wesly Wijnen are working together\n<br><br>\n# Findings:\n## Illegal matches\nWhile exploring the data, an interesting discovery on illegal (games having a higher groupsize than is possible for the matchtype) games was made.\nThis lead to having only 700 useable matches to trian the network with.\n# Table of contents\n## 1. Imports\nImports used within the notebook to run it.\n## 2. Functions\nFunctions used within the notebook to run it.\n## 3. EDA (Exploratory Data Analysis)\nFindings within the data, what have we come up with.\n## 4. Data-Preparation\n## 5. Modelling\n### 5.1 Model without illegal matches (Only contians Solo and SoloFPP matches)\n### 5.2 Model with illegal matches (Contains matches with more than the maximum number of groupsize)","be1289d6":"Shows the distribution between the prediction and actual. A perfect straight line would be the ideal scenario.","b406ad43":"Lets now normalize the data","d3c42fd6":"There is a wierd rating system where, the player either has rank or win points. It seems that wehn one is used the other is not","fb7f7327":"### Lets create a first network to see what the results can look like, But before this we need to normalize","d06e5962":"## Lets create a subset of each match Type. As the results **should** vary pet match type\nHere we do 2 things, we create categorical values for the match,group and ID of the player)","12eace4e":"Lets run the same analysis as we did for the test values","bd22f605":"# 3. EDA (Exploratory Data Analysis)\/ 4. Data preparation\nLets take a look at what the data looks like and see if we can get any insights from the data!","49cfac1a":"## 6.2 Model for all matches\n### Running on full dataset, without taking expections out","18a758e6":"### Conclusion, \nThere are only about 500-600 games with the correct number of group size. If the decision is made to use only games with the correct number of maximum group size. Only the games a few solofpp\/solo games will be useable.","97db628e":"### Train model for submission","403fa9bb":"### Test the model on the test dataset\nSince the compettiion provides a train\/test dataset, we will use the test dataset to see what kind of results we can get. Optimally this will be used in the model itself to further improve the model.\n#### Lets bring the data through the same pipeline","6d45a73e":"We will not use all of the variables, lets see if we can find some cool corrolations","78a56c36":"It is important to note that the accuracy does not mean much here as the network is specificly trying to predict the score. And the score can be pretty precise to predict","5b40e323":"# 2. Functions"}}