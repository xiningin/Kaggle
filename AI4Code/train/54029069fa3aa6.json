{"cell_type":{"d9cc8fc0":"code","f4ee1311":"code","c2d64555":"code","42278041":"code","d9745a2c":"code","b4c79dd5":"code","dd7b96b7":"code","44693b5a":"code","29e56d74":"code","d0c3e501":"code","f8e5d0c0":"code","58e67e88":"code","1533f91d":"code","5f1e9cc5":"code","51e721ae":"code","27ab35a2":"code","39521675":"code","71232d76":"code","a7012434":"code","cb5d38de":"code","dc2f671e":"code","170838f6":"code","b0caf3d6":"code","221bfffd":"code","4061b172":"code","2ba9b4fb":"code","e1d2284c":"code","d4853ce6":"code","4e07dad4":"code","55c6ec5e":"code","bf29fbeb":"code","8801a2b4":"code","8a8e28f2":"code","eee425fe":"code","8cf6a083":"code","9fda22d1":"code","57969fd2":"code","79e4cda9":"code","d159f16d":"code","d3e8c514":"code","643d3c22":"code","55015855":"code","b47661d3":"code","6a90f675":"code","2ff71feb":"code","06c90bd8":"code","16fe605a":"code","632d77e2":"code","1894f552":"code","dccdfb6d":"code","09ec4d2e":"code","7b344e7d":"code","6cd504be":"code","829e5b44":"code","a1b5f725":"markdown","4e921d36":"markdown","3d78da13":"markdown","967e8bb6":"markdown","517f7dfb":"markdown","075ce647":"markdown","1597e4ad":"markdown","3b58d167":"markdown","cd43fd64":"markdown","d224a8a8":"markdown","abfc483a":"markdown","15fde3e0":"markdown","a3e9fcd7":"markdown","842c51c3":"markdown","635ac3b4":"markdown","67759d69":"markdown","5edd5aa9":"markdown","b2013662":"markdown","24512e3e":"markdown","e2338405":"markdown","53d10c64":"markdown","66b2f790":"markdown"},"source":{"d9cc8fc0":"# linear algebra and data processing\nimport numpy as np\nimport pandas as pd \n\n#visualisations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom wordcloud import WordCloud,STOPWORDS\n\n#missing values\nimport missingno as msno\n\n# ignnore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f4ee1311":"#load district data\ndistrict_df = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\n#load product data\nproduct_df = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\n#load engagement data\nengagement_df= pd.read_csv(f'\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/1000.csv')","c2d64555":"%%HTML\n<style type=\"text\/css\">\ntable.dataframe td, table.dataframe th {\n    border: 1px  black solid !important;\n  color: black !important;\n}\n<\/style>","42278041":"district_df.head()","d9745a2c":"district_df.shape","b4c79dd5":"# State unique values\ndistrict_df['state'].nunique()","dd7b96b7":"# State with the highest frequency\ndistrict_df['state'].mode()[0]","44693b5a":"#basic insight on our columns to understand their properties and datatypes\ndistrict_df.info()","29e56d74":"# credit: https:\/\/www.kaggle.com\/parulpandey\/a-guide-to-handling-missing-values-in-python\ndef missing_values_table(df):\n\n        \"\"\"\n        Function which can be used to get an information about missing values\n\n        Inputs: \n        df - pandas DataFrame \n\n        Returns:dataframe with missing values information\n        \"\"\"\n    \n        # Total missing values\n        mis_val = df.isnull().sum()\n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        # Print some summary information\n        print (\"\\nThe dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\\n\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","d0c3e501":"#missing values in district dataframe\nmissing_values_table(district_df)","f8e5d0c0":"product_df.head()\n","58e67e88":"product_df['Category'] = product_df[\"Primary Essential Function\"].apply(lambda x: pd.Series(str(x).split(\"-\")[0]))\n","1533f91d":"product_df.head()","5f1e9cc5":"#basic insight on our columns to understand their properties and datatypes\nproduct_df.info()","51e721ae":"#missing values in product dataframe\nmissing_values_table(product_df)","27ab35a2":"engagement_df.head()","39521675":"#missing values in engagement dataframe\nmissing_values_table(engagement_df)","71232d76":"districts = district_df.district_id\nfor district in districts:\n    df= pd.read_csv(f'\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/{district}.csv')\n    df['district_id']=district\n    engagement_df.append(df)","a7012434":"\ndef count_plot(df:pd.DataFrame, column:str ,title:str) -> None:\n    \"\"\"\n    Function which can be used to draw a countplot\n\n    Inputs: \n    df - pandas DataFrame \n    column : Column name in string format\n    title : title of the plot in string format\n\n    Returns:None\n\n    \"\"\"\n    plt.figure(figsize=(10, 8))\n    ax=sns.countplot(data=df, x=column, color = \"#20b1fd\")\n    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)\n    ax.tick_params(axis='x', rotation=90)\n    plt.yticks(fontsize=14)\n    plt.xlabel(f'{column}', fontsize=17)\n    plt.ylabel(\"Count\", fontsize=17)\n    plt.title(title, fontsize = 20,fontname = 'monospace', color = '#283655')\n    plt.show()\n    \n","cb5d38de":"# Number of Districts across States\ncount_plot(district_df,'state','\\nStates with number of school districts\\n')\n","dc2f671e":"#count of districts in each type of areas\nfig, ax  = plt.subplots(figsize=(20, 10))\nplt.title('\\nThe count of districts in each type of areas', fontsize = 20,fontname = 'monospace', color = '#283655')\nlabel = list(district_df[\"locale\"].value_counts().index)\ncount = district_df[\"locale\"].value_counts().values\nax.pie(count,startangle=60, labels=label,autopct='%1.0f%%', colors=[\"#20b1fd\",\"#2cfbff\",\"#18ff9f\",\"#90ee90\"])\nax.add_artist(plt.Circle((0,0),0.3,fc='white'))\nplt.show()\n\n","170838f6":"fig, ax  = plt.subplots(figsize=(30, 15))\nplt.title('\\nThe count of states', fontsize = 20,fontname = 'monospace', color = '#283655')\nlabel = list(district_df[\"state\"].value_counts().index)\ncount = district_df[\"state\"].value_counts().values\nax.pie(count,startangle=60, labels=label,autopct='%1.0f%%', colors=[\"#20b1fd\",\"#2cfbff\",\"#18ff9f\",\"#90ee90\"])\nax.add_artist(plt.Circle((0,0),0.3,fc='white'))\nplt.show()","b0caf3d6":"fig, ax  = plt.subplots(figsize=(20, 10))\nplt.title('\\nProduct categories distribution', fontsize = 20,fontname = 'monospace', color = '#283655')\nproduct_df_clean=product_df.dropna()\nexplode = (0.05, 0.05, 0.05, 0.05)\nlabel = list(product_df_clean[\"Category\"].value_counts().index)\ncount = product_df_clean[\"Category\"].value_counts().values\npatches0=ax.pie(count,startangle=60, explode=explode,labels=label,autopct='%1.0f%%', colors=[\"#7fff00\",\"#dfff00\",\"#9acd32\",\"#d1e231\"])\nplt.show()","221bfffd":"#Top 10 Tech-Products\nplt.figure(figsize=(16, 10))\nsns.countplot(y='Provider\/Company Name', data=product_df, order=product_df[\"Provider\/Company Name\"].value_counts().index[:10],palette='Set3')\nplt.title('\\nTOP 10 companies whose products are used the most\\n', fontsize = 20,fontname = 'fantasy', color = '#283655')\nplt.xlabel('Count', fontsize=18)\nplt.ylabel('Provider\/Company Name', fontsize=16)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","4061b172":"\n# Generate a word cloud image\nwordcloud = WordCloud(width=1440, height=1080,background_color='#009B77', colormap='Set2', collocations=False).generate(\" \".join(product_df['Provider\/Company Name'].astype(str)))\n# Display the generated image\nplt.figure(figsize=(30, 10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('\\nWord cloud which shows words that are repeated the most in the Product Name variable.\\n', fontsize = 20,fontname = 'fantasy', color = '#283655')\nplt.axis(\"off\")\nplt.show()\n\n","2ba9b4fb":"#Distribution of school districts in each locale in each State\nlocale_state=district_df.groupby(\"state\")[\"locale\"].value_counts()\nlocale_state.head(10)","e1d2284c":"plt.figure(figsize=(16, 10))\ng=sns.countplot(data = district_df, x= district_df['locale'],palette='bright', hue='state')\ng.legend(bbox_to_anchor= (1.2,1))\nplt.title('\\nDistribution of school districts in each locale in each State\\n', fontsize = 20,fontname = 'fantasy', color = '#283655')\nplt.xlabel('Count', fontsize=20)\nplt.ylabel('Locale', fontsize=20)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","d4853ce6":"district_df.dropna(inplace=True)\ndistrict_df['pct_black\/hispanic']=district_df['pct_black\/hispanic'].apply(lambda x :float(x.split(',')[0][1:])+0.1)\ndistrict_df['pct_free\/reduced']=district_df['pct_free\/reduced'].apply(lambda x :float(x.split(',')[0][1:])+0.1)\ndistrict_df['pp_total_raw']=district_df['pp_total_raw'].apply(lambda x :float(x.split(',')[0][1:])+1000)\ndistrict_df.head()","4e07dad4":"count_plot(district_df,'pct_black\/hispanic','\\nDistribution of percentage of students in the districts identified as Black or Hispanic \\n')","55c6ec5e":"#Distribution of percentage of students in the districts identified as Black or Hispanic plot\nstate_pct=district_df.groupby('state').agg({'pct_black\/hispanic':np.mean}).reset_index()\nstate_pct_sorted = state_pct.sort_values('pct_black\/hispanic',ascending=True).set_index('state')\nplt.figure(figsize=(16, 10))\nplt.hlines(y=state_pct_sorted .index, xmin=0, xmax=state_pct_sorted,color='#009B77')\nplt.plot(state_pct_sorted , state_pct_sorted .index,'o', color='#009B77')\nplt.title('\\nDistribution of percentage of students in the districts identified as Black or Hispanic\\n', fontsize=18)\nplt.xlabel('percentage', fontsize=16)\nplt.xticks(fontsize=15)\nplt.xlim(0, None)\nplt.yticks(fontsize=15)\nplt.grid(False)\nplt.show()\n\n","bf29fbeb":"#Distribution of percentage of students in the districts identified as Black or Hispanic plot\nlocale_pct=district_df.groupby('locale').agg({'pct_black\/hispanic':np.mean}).reset_index()\nlocale_pct_sorted = locale_pct.sort_values('pct_black\/hispanic',ascending=True).set_index('locale')\nplt.figure(figsize=(8, 5))\nplt.hlines(y=locale_pct_sorted .index, xmin=0, xmax=locale_pct_sorted,color='#009B77')\nplt.plot(locale_pct_sorted , locale_pct_sorted .index,'o', color='#009B77')\nplt.title('\\nDistribution of percentage of students in the districts identified as Black or Hispanic\\n', fontsize=18)\nplt.xlabel('percentage', fontsize=16)\nplt.xticks(fontsize=15)\nplt.xlim(0, None)\nplt.yticks(fontsize=15)\nplt.grid(False)\nplt.show()\n","8801a2b4":"# importing household income \naverage_household_income = pd.read_html(\"https:\/\/fred.stlouisfed.org\/release\/tables?eid=259515&rid=249\")[0]\naverage_household_income.head()","8a8e28f2":"#dropping unwanted columns\naverage_household_income.columns = [\"unknown\",\"state\",\"average_household_income\",\"preceding_period\",\"year_ago_period\"]\naverage_household_income.drop([\"unknown\",\"preceding_period\",\"year_ago_period\"], axis=1, inplace=True)\naverage_household_income.head()\n","eee425fe":"# Poverty level of States - using information from wikipedia \npoverty_rate = pd.read_html(\"https:\/\/en.wikipedia.org\/wiki\/List_of_U.S._states_and_territories_by_poverty_rate\")[2]\npoverty_rate.head()","8cf6a083":"# Extracting useful columns from the poverty and cleaning it\npoverty_rate.columns = [\"rank\",\"state\",\"poverty_percentage\",\"poverty_rate_2014\",\"poverty_measure\"]\npoverty_rate.drop([\"rank\",\"poverty_rate_2014\",\"poverty_measure\"], axis=1, inplace=True)\npoverty_rate.poverty_percentage = poverty_rate.poverty_percentage.apply(lambda x: float(x.split(\"%\")[0]))\npoverty_rate.head()","9fda22d1":"#merging district dataframe with poverty_rate and average_household_income\ndistrict_df = pd.merge(district_df, poverty_rate, how=\"left\", on=\"state\")\ndistrict_df = pd.merge(district_df, average_household_income, how=\"left\", on=\"state\")\ndistrict_df.head()\n","57969fd2":"# Correlation \nplt.figure(figsize=(10,8))\nsns.heatmap(district_df.corr(), annot=True, cmap=\"Greens\")\nplt.xticks(size=12)\nplt.yticks(size=12)\nplt.show()","79e4cda9":"#Distribution of sectors \ncount_plot(product_df,'Sector(s)','\\n Distribution of sectors \\n')","d159f16d":"districts = district_df.district_id.tolist()\nmerged_data = []\nfor district in districts:\n    df= pd.read_csv(f'\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/{district}.csv')\n    prod_eng = pd.merge(product_df, df, left_on = 'LP ID', right_on = 'lp_id')\n    prod_eng['district_id'] = district\n    merged = pd.merge(district_df, prod_eng, on = 'district_id')\n    merged_data.append(merged)\n    \nmerged_df = pd.concat(merged_data, axis=0)\nmerged_df.drop(['URL', 'lp_id'], axis = 1, inplace = True)\nmerged_df.head()","d3e8c514":"#missing values in engagement dataframe\nmissing_values_table(merged_df)","643d3c22":"#separate datetime column\nmerged_df['time'] = pd.to_datetime(merged_df['time'])\nmerged_df['Month'] = merged_df['time'].dt.month_name()\nmerged_df['Day'] = merged_df['time'].dt.day_name()\n\n#Mean monthly engagement\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(16, 10))\nax = sns.barplot(x=\"Month\", y=\"engagement_index\", data=merged_df,color=\"#009B77\")\nplt.title('\\nMean monthly engagement\\n', fontsize = 20,fontname = 'fantasy', color = '#283655')\nplt.xlabel('Month', fontsize=18)\nplt.ylabel('Engagement', fontsize=16)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=14)\nplt.show()","55015855":"'top 10 Product per engagement index mean'''\ntop_10_products = merged_df.groupby('Product Name')['engagement_index'].mean().reset_index()\ntop_10_products.sort_values(by='engagement_index',ascending=False).head(10)\n\nplt.figure(figsize=(16, 10))\nsns.countplot(y='Product Name', data=merged_df, order=merged_df[\"Product Name\"].value_counts().index[:10],palette='Set3')\nplt.title('\\nTop 10 Product per engagement index mean\\n', fontsize = 20,fontname = 'fantasy', color = '#283655')\nplt.xlabel('Count', fontsize=18)\nplt.ylabel('Provider\/Company Name', fontsize=16)\nplt.show()","b47661d3":"def line_plot(df:pd.DataFrame, column:str,linegroup:str ,Title:str) -> None:   \n    \n    \"\"\"\n    Function which can be used to draw a lineplot\n\n    Inputs: \n    df - pandas DataFrame \n    column : Column name in string format\n    linegroup : Column name for the linegroup in string format\n    title : title of the plot in string format\n\n    Returns:None\n\n    \"\"\"\n    \n    fig = px.line(df, x=\"time\", y=column, color=linegroup, line_group=linegroup)\n    fig = px.line(df, x=\"time\", y=column, color=linegroup, line_group=linegroup)\n    fig.update_layout(plot_bgcolor = 'white', title = Title,title_font_color = '#283655', title_font_size = 20, title_x = 0.5)\n    fig.show()\n\n    ","6a90f675":"#Pct_access of products by locale\nlocale_ac\u0441ess= merged_df.groupby(['locale', 'time']).agg({'pct_access': 'mean'}).reset_index()\nline_plot(locale_ac\u0441ess, \"pct_access\",\"locale\" ,'\\nPct_access of products by locale')","2ff71feb":"#Engagement index of products by States\nengagement_state = merged_df.groupby(['state', 'time']).agg({'engagement_index': 'mean'}).reset_index()\nline_plot(engagement_state,\"engagement_index\" ,\"state\",'\\nEngagement index of products by States')\n\n","06c90bd8":"#Engagement index of products by locale\nengagement_locale = merged_df.groupby(['locale', 'time']).agg({'engagement_index': 'mean'}).reset_index()\nline_plot(engagement_locale, \"engagement_index\",\"locale\" ,'\\nEngagement index of products by locale')","16fe605a":"merged_df.head()","632d77e2":"Feature_df = merged_df[['time', \n       'state', 'locale', 'pct_black\/hispanic','Product Name',\n        'Sector(s)',\"Provider\/Company Name\", 'Category','engagement_index']]\n\nFeature_df['time'] = pd.to_datetime(Feature_df['time'])\nFeature_df['Month'] = Feature_df['time'].dt.month\nFeature_df['Day'] = Feature_df['time'].dt.day\nFeature_df.drop('time', inplace=True, axis=1)\nFeature_df.dropna(inplace=True)\nFeature_df.head()","1894f552":"from sklearn.preprocessing import OrdinalEncoder\n\nord_enc = OrdinalEncoder()\nFeature_df[\"state\"] = ord_enc.fit_transform(Feature_df[['state']])\nFeature_df[\"locale\"] = ord_enc.fit_transform(Feature_df[['locale']])\nFeature_df[\"Product Name\"] = ord_enc.fit_transform(Feature_df[['Product Name']])\nFeature_df[\"Sector(s)\"] = ord_enc.fit_transform(Feature_df[['Sector(s)']])\nFeature_df[\"Category\"] = ord_enc.fit_transform(Feature_df[['Category']])\nFeature_df[\"Provider\/Company Name\"] = ord_enc.fit_transform(Feature_df[['Provider\/Company Name']])\nFeature_df.head()","dccdfb6d":"# scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = Feature_df.copy().drop(['engagement_index'], axis=1)\ny = Feature_df.copy()[['engagement_index']]\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\ny = scaler.fit_transform(y).flatten()","09ec4d2e":"# spliting the data into train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.1, random_state=42)","7b344e7d":"# create the classifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom matplotlib import pyplot\nregressor = RandomForestRegressor(n_jobs = -1, max_depth = 5)","6cd504be":"# Train the model using the training sets\nregressor.fit(X_train, y_train)","829e5b44":"# get importance\nimportances = regressor.feature_importances_\nlabels = X.columns\nfeature_df = pd.DataFrame(list(zip(labels, importances)), columns=[\"feature\", \"importance\"])\nfeature_df = feature_df.sort_values(by='importance', ascending=False, )\nplt.figure(figsize=(10, 8))\nax = sns.barplot(x=\"importance\", y=\"feature\", data=feature_df,palette=[\"blue\"])\nax.set_xlabel('Importance', fontsize=20)\nax.set_ylabel('Feature', fontsize=20)  # ylabel\nax.set_title('\\nFeature importance\\n', fontsize=22)","a1b5f725":"-  <font color = \"#283655\" size=\"3\"> There are 23 states in the dataframe.<\/font>","4e921d36":"<p style='padding:30px;text-align:center; background-color:#20b1fd;color:#FFFFFF;font-size:26px;border-radius:10px;'>COVID-19 Impact on Digital Learning<\/p>\n\n <h2><font color = \"20b1fd\">  Introduction <\/font><\/h2>\n- <font color = \"#283655\" size=\"3\">As a result of the COVID-19 outbreak, colleges and universities around the globe are shifting to online learning as a replacement for on-campus delivery.There's an urgent need to better understand and measure the scope and impact of the pandemic.we are going to do a data analysis to see about how engagement with digital learning relates to factors like district demographics, broadband access, and state\/national level policies and events as a better understanding of digital learning trends may help reverse the long-term learning loss among America\u2019s most vulnerable, making education more equitable.<\/font>\n\n","3d78da13":"\n\n <h3><font color = \"#20b1fd\"> District data information <\/font><\/h3>\n<font color = \"#283655\" size=3> The district file districts_info.csv includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. \n\n - <b> district_id <\/b>: The unique identifier of the school district\n - <b>state<\/b> : The state where the district resides in\n - <b>locale <\/b>: NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural.\n - <b>pct_black\/hispanic <\/b>: Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\n - <b>pct_free\/reduced<\/b> : Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n - <b>countyconnectionsratio <\/b>: ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households)   \n - <b>pptotalraw <\/b>: Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project.<\/font>\n \n","967e8bb6":" <font color = \"#283655\" size=3>\n<ul>    \n<li>The top three states with the most school districts are Connecticut, Utah, and Massachusetts.<\/li>\n<li>The distribution of the data by State is very unequal.The most populated states like <b>California and Texas<\/b> are not the ones who provided the most data<\/li>\n<\/ul>\n<\/font>","517f7dfb":" <h2><font color = \"#20b1fd\">  Exploratory Analysis<\/font> <\/h2>\n \n\n <font color = \"#283655\" size=\"3\"> - In this section, we will perform some exploratory data analysis on our dataframe to get a general idea of what our dataframe consists of and to manipulate it if required.<\/font> \n<h2><font color = \"#20b1fd\">Libraries<\/font> <\/h2>","075ce647":"<h3><font color = \"#20b1fd\"> Merge with additional public data sources<\/font>","1597e4ad":"- <font color = \"#283655\" size=3>Cities have the highest percentage of <b>Black\/Hispanic<\/b> inhabitants, whereas towns and rural areas have the lowest.<\/font>","3b58d167":"<h2> <font color = \"#20b1fd\">Merging Dataframes <\/font><\/h2>","cd43fd64":" <h2><font color = \"20b1fd\">  Objectives <\/font><\/h2>\n- <font color = \"#283655\" size=\"3\">Explore the state of digital learning in 2020 and how the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events\n\nBelow are some examples of questions that relate to our problem statement:\n- What is the picture of digital connectivity and engagement in 2020?\n- What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n- How does student engagement with different types of education technology change over the course of the pandemic?\n- How does student engagement with online learning platforms relate to different geography? Demographic context (e.g.,      race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n- Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?<\/font>\n\n\n","d224a8a8":"-  <font color = \"#283655\" size=3> Google is the company with the most digital education programs, followed by Houghton Mifflin Harcourt, however there is a significant gap between the amount of items they offer. Microsoft ranks third in terms of the number of digital education programs it offers.<\/font>","abfc483a":"\n-  <font color = \"#283655\" size=\"3\">  There are <b>372<\/b> distinct Educational Technology Products <\/font>","15fde3e0":"<font color = \"#283655\" size=3> Based on the figure,We can see that,\n    <ul>\n    <li>People's poverty levels are rising in tandem with their household earnings. <\/li>\n    <li>Large correlations exist between students in the districts identified as Black or Hispanic and free or reduced-price lunch.<\/li><\/ul><\/font>","a3e9fcd7":" -  <font color = \"#283655\" size=\"3\"> The most occuring state is Connecticut <\/font>","842c51c3":"<h3><font color = \"#20b1fd\"> Product data information <\/font><\/h3>\n<font color = \"#283655\" size=3> The district file districts_info.csv includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. \n\n - <b> LP ID <\/b>: The unique identifier of the product\n - <b>URL<\/b> : Web Link to the specific product\n - <b>Product Name <\/b>: Name of the specific product\n - <b>Provider\/Company Name <\/b>: Name of the product provider\n - <b>Sector(s)<\/b> : Sector of education where the product is used\n - <b>Primary Essential Function <\/b>: The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: ,LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled\",<\/font>\n\n","635ac3b4":" <h2> <font color = \"#20b1fd\">Data<\/font><\/h2>","67759d69":"<font color = \"#283655\" size=\"3\"> \n We can observe that 'Learning & Curriculum' dominates Primary Essential Function, LC category (77%).\n<br\/><br\/> LC = Learning & Curriculum \n<br\/> CM = Classroom Management, and \n<br\/> SDO = School & District Operations \n<\/font>","5edd5aa9":" <h3><font color = \"#20b1fd\"> Engagement data information  <\/font><\/h3>\n<font color = \"#283655\" size=3> \n- The engagement data are aggregated at school district level, and each file in the folder engagement_data represents data from one school district\n\n\n - <b> time<\/b>: date in YYYY-MM-DD\n - <b>lp_id<\/b> : The unique identifier of the product\n - <b>pct_access <\/b>: Percentage of students in the district have at least one page-load event of a given product and on a given day\n - <b>engagement_index <\/b>: Total page-load events per one thousand students of a given product and on a given day  <\/font>\n","b2013662":" <h2> References<\/h2>\n \n- [A guide to handling missing values in python](https:\/\/www.kaggle.com\/parulpandey\/a-guide-to-handling-missing-values-in-python)\n- [Calculate feature importance with python](https:\/\/machinelearningmastery.com\/calculate-feature-importance-with-python\/)\n- [Bar plots alternatives](https:\/\/towardsdatascience.com\/bar-plots-alternatives-specific-types-9d10ef250e5)\n- [How to approach analytics challenges](https:\/\/www.kaggle.com\/iamleonie\/how-to-approach-analytics-challenges)\n","24512e3e":"<font color = \"#283655\" size=3> From the figure,we can see that **Connecticut** has the most schools in Suburb locale, followed by   **Massachusetts**,and **Utah**.<\/font>\n<ul><font color = \"#283655\" size=3>\n  <li><b>California<\/b> and <b>Utah<\/b> has the most schools in City locale<\/li>\n  <li><b>Connecticut<\/b> has the most schools in Rural locale followed by <b>New York<\/b><\/li>\n  <li><b>Utah<\/b> has the maximum number of schools in Town locale<\/li>\n    <li>We Can also see that most of the states expect <b>califronia<\/b> are made up of the suburbs.<\/li>\n  <li><b>Arizona<\/b> has schools only in town locales.<\/li>\n  <li>only rural coverage is available in <b>New Hampshire<\/b> and <b>North Dakota<\/b> <\/li>\n  <li><b> Florida, Michigan, Minnesota, New Jersey and Wisconsin<\/b> have 100% suburbs coverage while <b>Columbia<\/b> have 100% of the data about City. <\/li>\n<\/font><\/ul>\n","e2338405":"-  <font color = \"#283655\" size=\"3\">  The data include a total of <b>233<\/b> School Districts from across the United States.<\/font>","53d10c64":"- <font color = \"#283655\" size=3>Texas has the highest number of black\/hispanic representation followed by Minnsota, Michigan and Florida.<\/font>","66b2f790":"<h3><font color = \"#20b1fd\"> In progress ... <\/font><\/h3>"}}