{"cell_type":{"702dd65f":"code","b6422d46":"code","a07adc36":"code","5876d7e5":"code","3a0710ac":"code","1278de93":"code","20f61833":"code","7ecaeb9c":"code","09f94362":"code","fee15e28":"code","4d900891":"code","0876d892":"code","2443b31c":"code","10e7c03e":"code","48a057c2":"code","b1c71c2a":"code","10d9a8f0":"code","cd6ec1df":"markdown","b0d5e9ae":"markdown","24000020":"markdown","c9621717":"markdown","b7e3fbad":"markdown","a280441d":"markdown","c9e091c5":"markdown","1b8c3ba8":"markdown","ba1ab04d":"markdown","bd7d37ac":"markdown","a30431b2":"markdown","9a1b9f9e":"markdown","129b8018":"markdown","f9fae616":"markdown","e031eec1":"markdown","995532ec":"markdown","4bb1fb96":"markdown","f5371709":"markdown","b928872e":"markdown","89ed12ee":"markdown","1f6b9261":"markdown","feea318b":"markdown","734d3ab2":"markdown","1bc7ec6d":"markdown","e7dbadfc":"markdown","2e39102d":"markdown","93ab021a":"markdown","ee57bf9c":"markdown","4da027b5":"markdown","88073868":"markdown","b5c4c82f":"markdown","da5ee8c9":"markdown","4cc773a0":"markdown","aef516ba":"markdown","72e099a6":"markdown","1d483d31":"markdown","a0d8b8ed":"markdown"},"source":{"702dd65f":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns             # visualizations\nimport matplotlib.pyplot as plt   # visualizations\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nimport os\nprint(os.listdir(\"..\/input\"))","b6422d46":"data=pd.read_csv(\"..\/input\/cardiovascular-disease-dataset\/cardio_train.csv\")\ndf=data.from_csv(\"..\/input\/cardiovascular-disease-dataset\/cardio_train.csv\", header=0, sep=\";\")\ndfcol=df.columns\ndf.head()","a07adc36":"df[[\"cardio\",\"height\"]].groupby(\"cardio\").count()\nsns.countplot(x=\"cardio\", data=df, palette=\"Set1\")","5876d7e5":"\nfrom sklearn import preprocessing\nscaler=preprocessing.MinMaxScaler()\ndfscale=scaler.fit_transform(df)\ndfscale2=pd.DataFrame(dfscale, columns=dfcol)\ndfscale2.head()","3a0710ac":"xdf=dfscale2.iloc[:,0:11]\n#xdf[\"gender\"]=np.where(xdf[\"gender\"]==1,\"0\",\"1\") #Cambiar el 2 por 1, el 1 por 0 (por orden)\n#Aca vendria un posible drop de variables xdf=xdf.drop([\"gender\",\"gluc\"], axis=1)\nydf=dfscale2.iloc[:,-1]\n","1278de93":"x_training, x_testing, y_training, y_testing = train_test_split(xdf, ydf, test_size = 0.2, random_state=123, stratify=ydf)","20f61833":"print(xdf.shape)","7ecaeb9c":"from keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.layers import Dropout\nfrom keras.constraints import maxnorm\n\nmodel = Sequential()\nmodel.add(Dense(25, input_dim=11, activation='softsign', kernel_constraint=maxnorm(2)))\n#model.add(Dropout(0))\nmodel.add(Dense(5, activation='softsign'))\n#model.add(Dropout(0))\nmodel.add(Dense(3, activation='softsign'))\n#model.add(Dropout(0))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n\nmodel.summary()","09f94362":"model.fit(x_training, y_training, epochs=50, batch_size=50, verbose=0)\nscore = model.evaluate(x_training, y_training)\nprint(\"\\n Training Accuracy:\", score[1])\nscore = model.evaluate(x_testing, y_testing)\nprint(\"\\n Testing Accuracy:\", score[1])","fee15e28":"res=model.predict(x_testing)\nres\nresdf=pd.DataFrame(res, index=x_testing.index)\nresdf.columns=[\"Pr\"]\nresdf[\"ID\"]=range(14000)\nresdf[\"y\"]=np.where(resdf[\"Pr\"]>=0.5,\"1\", \"0\")\nresdf\nprediction=resdf.drop([\"Pr\",\"ID\"], axis=1)\npredictionarray=prediction.astype(np.float)\nsns.distplot(resdf[\"Pr\"],  color=\"red\")","4d900891":"c1=resdf[['ID','y']].groupby('y').count()\nc1","0876d892":"y_testingdf=pd.DataFrame(y_testing, index=y_testing.index)\ny_testingdf[\"ID\"]=range(14000)\ny_test=y_testingdf.drop([\"ID\"], axis=1)\nc2=y_testingdf[['ID','cardio']].groupby('cardio').count()\nc2","2443b31c":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test.values, predictionarray)\ncm","10e7c03e":"Accuracy=cm[0,0]\/(cm[0,0]+cm[1,0])\nprint(\"The accuracy of the model is: \"+ str(Accuracy*100) + \" %\")","48a057c2":"#INSERT DATA#\n###############################################################################\n\nday= 25 # day of bith \nmonth= 9 # month of bith (in numbers)\nyear= 1998 # year of bith\ngender= 1 # 0 for women, 1 for men\nheight= 183 # in cm\nweight= 89 # in kilograms\nsystolicbloodpressure= 120 # Systolic blood pressure\ndiastolicbloodpressure= 80 # Diastolic blood pressure\ncholesterol= 1 # 1: normal, 2: above normal, 3: well above normal\ngluc= 1 # 1: normal, 2: above normal, 3: well above normal\nsmoke= 0 # 1 if you smoke, 0 if not\nalco= 0 # 1 if you drink alcohol, 0 if not\nactive= 1 # 1 if you do physical activity, 0 if not\n\n##############################################################################\nfrom datetime import date\nf_date = date(year,month,day)\nl_date = date.today()\ndelta = l_date - f_date\nagedays=delta.days\n\nagedayscale=(agedays-df[\"age\"].min())\/(df[\"age\"].max()-df[\"age\"].min())\nheightscale=(height-df[\"height\"].min())\/(df[\"height\"].max()-df[\"height\"].min())\nweightscale=(weight-df[\"weight\"].min())\/(df[\"weight\"].max()-df[\"weight\"].min())\nsbpscale=(systolicbloodpressure-df[\"ap_hi\"].min())\/(df[\"ap_hi\"].max()-df[\"ap_hi\"].min())\ndbpscale=(diastolicbloodpressure-df[\"ap_lo\"].min())\/(df[\"ap_lo\"].max()-df[\"ap_lo\"].min())\ncholesterolscale=(cholesterol-df[\"cholesterol\"].min())\/(df[\"cholesterol\"].max()-df[\"cholesterol\"].min())\nglucscale=(gluc-df[\"gluc\"].min())\/(df[\"gluc\"].max()-df[\"gluc\"].min())\n\nsingle=np.array([agedayscale, gender, heightscale, weightscale, sbpscale, dbpscale, cholesterolscale, glucscale, smoke, alco, active ])\nsingledf=pd.DataFrame(single)\nfinal=singledf.transpose()\nfinal","b1c71c2a":"from keras.models import model_from_json\n\n#model.save_weights(\"weights.hdf5\")\njson_string = model.to_json()\nmodeltopredict = model_from_json(json_string)\nmodeltopredict.load_weights(\"..\/input\/weights-nn\/weights.hdf5\", by_name=False)\n\nprediction=modeltopredict.predict(final)\n\nif prediction[0,0]>=0.5:\n    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n    print(\"You must visit a doctor to check it :(\")\nelif prediction[0,0]<0.5 and prediction[0,0]>=0.3:\n    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n    print(\"Probably you are healthy :\/ \")\nelse:\n    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n    print(\"You are healthy :) \")","10d9a8f0":"from sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier","cd6ec1df":"###### *To see our info page (about cardiovascular diseases and info about us), you could visit : https:\/\/mailchi.mp\/dd56c857ba2e\/heartaid*","b0d5e9ae":"#### How many 1's and 0's are in the test sample","24000020":"* **Initial Accuracy**= 0.6465 \n* **Final aprox Accuracy**= 0.68-0.719","c9621717":"### Confusion Matrix","b7e3fbad":"## Batch Size and Epochs\n\nIn the final kernel, this code is not gonna be available 'cause it takes too much time to run this parts of code.\nThe summary will be written below the function.","a280441d":"finalres=model.predict(final)\nfinalres\nprint(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(finalres[0,0]*100,2)) + \"%\")","c9e091c5":"**Results:** \n* Best: 0.708232 using {**'optimizer': 'Nadam'**}\n* 0.639339 (0.003833) with: {'optimizer': 'SGD'}\n* 0.685446 (0.014199) with: {'optimizer': 'RMSprop'}\n* 0.644750 (0.004682) with: {'optimizer': 'Adagrad'}\n* 0.664732 (0.011830) with: {'optimizer': 'Adadelta'}\n* 0.676821 (0.017248) with: {'optimizer': 'Adam'}\n* 0.653625 (0.003463) with: {'optimizer': 'Adamax'}\n* 0.708232 (0.010960) with: {'optimizer': 'Nadam'}","1b8c3ba8":"#### Accuracy of the Model","ba1ab04d":"## Optimization of SGD algorithm (Learnig Rate and Momentum)","bd7d37ac":"# Predicting a single case","a30431b2":"## Dropout Rate and Weight Constraint","9a1b9f9e":"## Neural Network","129b8018":"### Uploading packages","f9fae616":"def create_model(neurons=1):\n    model = Sequential()\n    model.add(Dense(neurons, input_dim=11, activation='softsign', kernel_constraint=maxnorm(2)))\n    model.add(Dropout(0))\n    model.add(Dense(5, activation='softsign'))\n    model.add(Dropout(0))\n    model.add(Dense(3, activation='softsign'))\n    model.add(Dropout(0))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nneurons = [1, 5, 10, 15, 20, 25, 30]\nparam_grid = dict(neurons=neurons)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","e031eec1":"## Activation functions","995532ec":"**Results:**\n* Best: 0.703107 using {**'neurons': 25**}\n* 0.683607 (0.003922) with: {'neurons': 1}\n* 0.700411 (0.003911) with: {'neurons': 5}\n* 0.694625 (0.009716) with: {'neurons': 10}\n* 0.699536 (0.009807) with: {'neurons': 15}\n* 0.698893 (0.013422) with: {'neurons': 20}\n* 0.703107 (0.014787) with: {'neurons': 25}\n* 0.688821 (0.026863) with: {'neurons': 30}","4bb1fb96":"## Prediction","f5371709":"### Uploading data","b928872e":"**Results:**\n* Best: 0.701179 using {**'dropout_rate': 0.0, 'weight_constraint': 2**}\n* 0.500839 (0.005918) with: {'dropout_rate': 0.0, 'weight_constraint': 0}\n* 0.651839 (0.005446) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n* 0.701179 (0.010650) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n* 0.500446 (0.005961) with: {'dropout_rate': 0.1, 'weight_constraint': 0}\n* 0.648250 (0.007944) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n* 0.684536 (0.022927) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n* 0.500304 (0.005970) with: {'dropout_rate': 0.2, 'weight_constraint': 0}\n* 0.649732 (0.002889) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n* 0.666893 (0.011692) with: {'dropout_rate': 0.2, 'weight_constraint': 2}","89ed12ee":"**Results:** \n* Best: 0.640893 using {**'batch_size': 50, 'epochs': 50**}\n* 0.638214 (0.003997) with: {'batch_size': 10, 'epochs': 10}\n* 0.640446 (0.006447) with: {'batch_size': 10, 'epochs': 50}\n* 0.613500 (0.060568) with: {'batch_size': 10, 'epochs': 100}\n* 0.617089 (0.012489) with: {'batch_size': 50, 'epochs': 10}\n* 0.640893 (0.004402) with: {'batch_size': 50, 'epochs': 50}\n* 0.640661 (0.003730) with: {'batch_size': 50, 'epochs': 100}\n* 0.613732 (0.017299) with: {'batch_size': 100, 'epochs': 10}\n* 0.635268 (0.005980) with: {'batch_size': 100, 'epochs': 50}\n* 0.639482 (0.007552) with: {'batch_size': 100, 'epochs': 100}","1f6b9261":"**Results:** \n* Best: 0.717250 using {**'activation': 'softsign'**}\n* 0.649786 (0.005472) with: {'activation': 'softmax'}\n* 0.649464 (0.005333) with: {'activation': 'softplus'}\n* 0.717250 (0.006675) with: {'activation': 'softsign'}\n* 0.701964 (0.021487) with: {'activation': 'relu'}\n* 0.717179 (0.002289) with: {'activation': 'tanh'}\n* 0.648446 (0.006001) with: {'activation': 'sigmoid'}\n* 0.651750 (0.004286) with: {'activation': 'hard_sigmoid'}\n* 0.709232 (0.015933) with: {'activation': 'linear'}","feea318b":"from keras.layers import Dropout\nfrom keras.constraints import maxnorm\n\n#### function to create model\ndef create_model(dropout_rate=0.0, weight_constraint=0):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='softsign', kernel_constraint=maxnorm(weight_constraint)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(5, activation='softsign'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(3, activation='softsign'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nweight_constraint = [0, 1, 2]\ndropout_rate = [0.0, 0.1, 0.2]\nparam_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","734d3ab2":"def create_model():\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, verbose=0)\n\n#### define the parameters to search in grid search \nbatch_size = [10, 50, 100]\nepochs = [10, 50, 100]\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","1bc7ec6d":"#### function to create model\ndef create_model(optimizer='adam'):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \noptimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\nparam_grid = dict(optimizer=optimizer)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","e7dbadfc":"#### How many 1's and 0's predict the model","2e39102d":"This means that of all the people with Cardiovascular Disease in the Test-DataBase, the model identify **73% (aprox.)** of the total cases.","93ab021a":"## Optimization Algorithm\n\nIn the final kernel, this code is not gonna be available 'cause it takes too much time to run this parts of code.\nThe summary will be written below the function.","ee57bf9c":"### Checking if the targets are balanced","4da027b5":"def create_model(activation='relu'):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation=activation))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation=activation))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation=activation))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer=\"Nadam\", metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nactivation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\nparam_grid = dict(activation=activation)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","88073868":"# Tuning hyperparameters to look up for the best NN","b5c4c82f":"# NEURAL NETWORK TO PREDICT CARDIOVASCULAR DISEASES","da5ee8c9":"### Data Transform (Scaling to avoid outliers)","4cc773a0":"## Number of neurons in the first layer","aef516ba":"#### Basic NN","72e099a6":"#### function to create model\ndef create_model(learn_rate=0.01, momentum=0):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(lr=learn_rate, momentum=momentum)\n    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nlearn_rate = [0.01, 0.1, 0.2]\nmomentum = [0.2, 0.6, 0.9]\nparam_grid = dict(learn_rate=learn_rate, momentum=momentum)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","1d483d31":"### Splitting data","a0d8b8ed":"**Results:** \n* Best: 0.642571 using {**'learn_rate': 0.01, 'momentum': 0.2**}\n* 0.642571 (0.004326) with: {'learn_rate': 0.01, 'momentum': 0.2}\n* 0.642375 (0.003565) with: {'learn_rate': 0.01, 'momentum': 0.6}\n* 0.641786 (0.005498) with: {'learn_rate': 0.01, 'momentum': 0.9}\n* 0.586232 (0.069370) with: {'learn_rate': 0.1, 'momentum': 0.2}\n* 0.642089 (0.004087) with: {'learn_rate': 0.1, 'momentum': 0.6}\n* 0.638589 (0.006434) with: {'learn_rate': 0.1, 'momentum': 0.9}\n* 0.498554 (0.005800) with: {'learn_rate': 0.2, 'momentum': 0.2}\n* 0.587482 (0.071161) with: {'learn_rate': 0.2, 'momentum': 0.6}\n* 0.594286 (0.058599) with: {'learn_rate': 0.2, 'momentum': 0.9}"}}