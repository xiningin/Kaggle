{"cell_type":{"edb2f34e":"code","2c8e3a72":"code","524089f0":"code","f7998f5d":"code","6d806452":"code","47135338":"code","e60541e1":"code","91335b52":"code","af4fe18f":"code","27f1830c":"code","07270710":"code","866b4234":"code","e365a256":"code","060770bb":"code","4d04fe4f":"code","c7bfa567":"code","4911b8b0":"code","9e2db01e":"code","d117a124":"code","2614bc84":"code","07ef3366":"code","c254e32e":"code","4bfd48ad":"code","c77b3189":"code","b22231ed":"code","48571f66":"code","ac2d593b":"code","4543310f":"code","c45689e0":"code","0e0f548f":"code","1b407d09":"code","358941ab":"code","f9321ab5":"code","b6adfbfb":"code","eab981fb":"code","ba49fdaf":"code","398ac4be":"code","02a62daa":"code","232a9628":"code","9520e90c":"code","6a5cdf3f":"code","4cb18fc0":"code","dea4e929":"code","1accdd1c":"code","7a9e93df":"code","d50d8b62":"code","a66c9ce3":"code","512fb2bc":"code","8946866a":"code","7733d146":"code","cd7c1a50":"code","e48c01cc":"code","e20e05ab":"code","bc85a18c":"code","1e2da65b":"code","108f81e7":"code","91545709":"code","b2511494":"code","3abf2618":"code","eef22d1f":"code","e79438ea":"code","5ab1845c":"code","de0fea51":"code","0b44ceec":"code","91b9842b":"code","a20d06fc":"code","b3ed3406":"code","cc4a3199":"code","a6954d9b":"code","f59dc303":"code","51be03df":"code","c58bacea":"code","318a10f4":"code","94932360":"code","94df2861":"code","084ac79c":"code","609c8333":"code","579b85e4":"code","27aa5712":"code","87305c0c":"code","b065c310":"code","2e4305b0":"code","47f286f6":"code","1218c383":"code","85a73f26":"code","b990cd74":"code","f0808a1c":"code","a9f47f49":"code","e27b8522":"code","fcd1e1f3":"code","22064182":"code","3b251e97":"code","334cef58":"code","f80de5f4":"code","532adf29":"code","20bc6489":"code","ff1924be":"code","2fbd2df2":"code","d5513b20":"code","853b319e":"code","f6ee99d8":"code","21039723":"code","6db2e464":"code","7c08dffe":"code","b4b0ce2b":"code","fc284456":"code","08893a1a":"code","c4722cd0":"code","d1bffe9e":"code","ea933cef":"code","639987b4":"code","c0dc9fe1":"code","145e40e6":"code","9972a355":"code","d20c6b4b":"code","7ddb66aa":"code","a887ee7d":"code","4da0a402":"code","0289aba1":"code","7ac6571b":"code","b6ae5fe3":"code","1bb7f8cd":"code","67e1bd5f":"markdown","762048fa":"markdown","d9be337d":"markdown","3675574e":"markdown","d74665be":"markdown","ddea6763":"markdown","5478e377":"markdown","f1af47de":"markdown","6ad6047b":"markdown","a3d9e71f":"markdown","4c2660ac":"markdown","785b70a1":"markdown","029405de":"markdown","5d71fffa":"markdown","576a1370":"markdown","bcf9354a":"markdown","cfd4e017":"markdown","b9a69f6b":"markdown","cb2ecf67":"markdown","0ba1e65b":"markdown","cb9d97ff":"markdown","b2e57cdc":"markdown","ccd8d646":"markdown","4d0629f8":"markdown","e848fefe":"markdown","3c134f61":"markdown","2e5e3270":"markdown","7682d3d7":"markdown","9be1ba9d":"markdown","45c5e47c":"markdown","70523991":"markdown","1f869e46":"markdown","222141a2":"markdown","cb1f43b2":"markdown","e1c42b2a":"markdown","1fc26128":"markdown","af7fa98f":"markdown","f29c9248":"markdown","c38f34fa":"markdown","6c9845a8":"markdown","489a6dbe":"markdown","9937b08e":"markdown","31b40ee2":"markdown","e933639c":"markdown","809e1d9a":"markdown","556d0299":"markdown","452189b3":"markdown","11b27679":"markdown","b9cbaad1":"markdown","b989187d":"markdown","a8e1fe3a":"markdown","2d7ebb6c":"markdown","a7f42f49":"markdown","3eef437e":"markdown","8088fe99":"markdown","a0476489":"markdown","a8840dd4":"markdown","245ae8d2":"markdown","5ac3f3e7":"markdown","5629d937":"markdown","95a9505e":"markdown","8908b6d5":"markdown","6a9bba58":"markdown","002adfb2":"markdown","1a7d806c":"markdown","de13c7b4":"markdown","57c302ca":"markdown","28ca4779":"markdown","c7839ed7":"markdown","2593de09":"markdown","aef500a8":"markdown","c48a1cda":"markdown","734bbf18":"markdown","dcf25af0":"markdown","0f1b8210":"markdown","6b597ad8":"markdown","41c53ff7":"markdown","ab3bcb13":"markdown"},"source":{"edb2f34e":"import numpy as np\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_object_dtype\nimport matplotlib.pyplot as plt\n\ntrain_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","2c8e3a72":"train_df.info()","524089f0":"train_df","f7998f5d":"test_df","6d806452":"print(\"Total Samples --> \", len(train_df))","47135338":"#Separating features and target from train_df\ntarget = train_df['SalePrice']\nfeatures = train_df.drop(['SalePrice'], axis=1)\nprint(\"Total Features --> \", len(features.columns))\nfeatures.head()    ","e60541e1":"# Listing Numerical and Categorical Features column from total features\nnum_features = []\ncat_features = []\n    \nfor col in features.columns:\n    if is_numeric_dtype(features[col]):\n        num_features.append(col)\n                \n    if is_object_dtype(features[col]):\n        cat_features.append(col)\n\nprint(\"\\nNumerical Features --> \", len(num_features))\nprint()\nprint(num_features)\nprint()\nprint(\"Categorical Features -->\", len(cat_features))\nprint()\nprint(cat_features)","91335b52":"stats = features.describe().T\nstats","af4fe18f":"print(\"Value counts of each categorical feature\\n\")\nfor col in cat_features:\n    print(col)\n    print(features[col].value_counts())\n    print()","27f1830c":"unique_df = pd.DataFrame(columns=['Feature', 'Unique', 'Count'])\nfor col in features.columns:\n    v = features[col].unique()\n    l = len(v)\n    unique_df = unique_df.append({'Feature':col,'Unique':v,'Count':l}, ignore_index=True)\nunique_df","07270710":"unique_df[unique_df['Count']== 1]","866b4234":"col_null_df = pd.DataFrame(columns = ['Column', 'Type', 'Total NaN', '%'])\ncol_null = features.columns[features.isna().any()].to_list()\nL = len(features)\nfor col in col_null:\n    T = 0\n    if is_numeric_dtype(features[col]):\n        T = \"Numerical\"  \n    else:\n        T = \"Categorical\"\n    nulls = len(features[features[col].isna() == True][col])   \n    col_null_df = col_null_df.append({'Column': col,'Type': T,'Total NaN': nulls,'%': (nulls \/ L)*100}, ignore_index=True)\ncol_null_df","e365a256":"col_null_df[col_null_df['%']>=80]","060770bb":"print('SalePrice --> target' )\ntarget.head(2)","4d04fe4f":"#importing seaborn for data visualization\n# Plotting distribution\nimport seaborn as sn\nsn.displot(train_df['SalePrice'])\nplt.show()","c7bfa567":"# Plotting Heat Map to visualise correlation data better. \n# Drwan for only features having high correlation \n# (>0.6) with Target Variable\ncorr = train_df.corr()\nCorr_high = corr.index[abs(corr[\"SalePrice\"])>0.5]\nplt.figure(figsize=(10,10))\ng = sn.heatmap(train_df[Corr_high].corr(),annot=True)","4911b8b0":"train_df.value_counts()","9e2db01e":"df = features\ncleaned_df = df.drop_duplicates(subset=['Id'])\nprint(\"Total Duplicates were \", len(df) - len(cleaned_df))\nprint(cleaned_df.shape)","d117a124":"#null_cols = col_null_df[col_null_df['%']>=80]['Column'].to_list()\n#cleaned_df.drop(null_cols, axis=1, inplace=True)\n#print(cleaned_df.shape)\n","2614bc84":"cleaned_df.drop(['Id'], axis=1, inplace=True)\nprint(cleaned_df.shape)","07ef3366":"unique_df[unique_df['Count']== 1]","c254e32e":"null_df = col_null_df\nfor ind, row in null_df.iterrows():\n    col = row['Column']\n    if row['Type'] == 'Categorical':\n        cleaned_df[col].fillna('NotAvail', inplace=True)\n    else:\n        cleaned_df[col].fillna(df[col].median(), inplace=True)\ncleaned_df","4bfd48ad":"cleaned_df.columns[cleaned_df.isna().any()]","c77b3189":"print(\"Min & Max of YearBuilt \", cleaned_df['YearBuilt'].min(), cleaned_df['YearBuilt'].max())\nprint(\"\\nMin & Max of GarageYrBlt \", cleaned_df['GarageYrBlt'].min(), cleaned_df['GarageYrBlt'].max())\nprint(\"\\nMin & Max of YrSold \", cleaned_df['YrSold'].min(), cleaned_df['YrSold'].max())\nprint(\"\\nMin & Max of YearRemodAdd \", cleaned_df['YearRemodAdd'].min(), cleaned_df['YearRemodAdd'].max())","b22231ed":"cleaned_df[cleaned_df['YearBuilt']<1900]['YearBuilt'].count()","48571f66":"cleaned_df[cleaned_df['YearBuilt']==1900]['YearBuilt'].count()","ac2d593b":"bins =  [1800] + [i for i in range(1900, 2020, 10)]\nbins","4543310f":"plt.figure(figsize=(8,6))\nsn.set_style(\"ticks\")\nsn.histplot(data=train_df, x=\"YearRemodAdd\", bins=20,cbar=True ,color='g')\nplt.show()","c45689e0":"sn.catplot(x='YearRemodAdd',y='SalePrice',data=train_df,aspect=2)\nplt.xticks(rotation='vertical')\nplt.show()","0e0f548f":"#num_features.remove('Id')\nplt.figure(figsize=(20,90))\nfor i in range(len(num_features)):\n    plt.subplot(13, 3, i+1)\n    sn.scatterplot(x=train_df[num_features[i]], y=target,hue='SalePrice',data=train_df,palette='coolwarm')\nplt.show()","1b407d09":"for col in cat_features:\n    plt.figure(figsize=(30, 10))\n    sn.barplot(x=train_df[col], y=target)\n    plt.show()","358941ab":"# Box Plot of Numerical Features\nnum_features.remove('Id')\nplt.figure(figsize=(20,90))\nfor i in range(len(num_features)):\n    plt.subplot(12, 3, i+1)\n    sn.boxplot(y=train_df[num_features[i]])\n\nplt.show()","f9321ab5":"cleaned_df['Remod_Built_Age'] = cleaned_df['YearRemodAdd'] - cleaned_df['YearBuilt']\ncleaned_df['Sold_Built_Age'] = cleaned_df['YrSold'] - cleaned_df['YearBuilt']\ncleaned_df['Remod_Sold_Age'] = cleaned_df['YrSold'] - cleaned_df['YearRemodAdd']\n\ncleaned_df['TotalSF']=cleaned_df['TotalBsmtSF'] + cleaned_df['1stFlrSF'] + cleaned_df['2ndFlrSF']\ncleaned_df['Total_sqr_footage'] = (cleaned_df['BsmtFinSF1'] + cleaned_df['BsmtFinSF2'] +\n                                 cleaned_df['1stFlrSF'] + cleaned_df['2ndFlrSF'])\ncleaned_df['Total_Bathrooms'] = (cleaned_df['FullBath'] + (0.5 * cleaned_df['HalfBath']) +\n                               cleaned_df['BsmtFullBath'] + (0.5 * cleaned_df['BsmtHalfBath']))","b6adfbfb":"cleaned_df","eab981fb":"Dump_Clm=['1stFlrSF', 'TotRmsAbvGrd', 'GarageCars', 'Alley', 'PoolQC', 'Fence', 'MiscFeature', 'YearRemodAdd', 'YearBuilt','YrSold', 'YearBuilt', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'BsmtFinSF1', 'BsmtFinSF2', 'FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']","ba49fdaf":"cleaned_df=cleaned_df.drop(Dump_Clm,1)\ncleaned_df","398ac4be":"# Listing Numerical and Categorical Features column from total features\nnum_features = []\ncat_features = []\n    \nfor col in cleaned_df.columns:\n    if is_numeric_dtype(cleaned_df[col]):\n        num_features.append(col)\n                \n    if is_object_dtype(cleaned_df[col]):\n        cat_features.append(col)\n\nprint(\"\\nNumerical Features, previous 37, After clean (New) --> \", len(num_features))\nprint()\nprint(num_features)\nprint()\nprint(\"Categorical Features, previous 43, After clean (New) -->\", len(cat_features))\nprint()\nprint(cat_features)","02a62daa":"import torch\nimport torch.nn as nn","232a9628":"numeric_data = pd.DataFrame(cleaned_df, columns=num_features)","9520e90c":"numeric_data","6a5cdf3f":"nan_columns = np.any(pd.isna(numeric_data), axis = 0)\nnan_columns = list(nan_columns[nan_columns == True].index)","4cb18fc0":"nan_columns","dea4e929":"numeric_x_columns = list(numeric_data.columns)","1accdd1c":"numeric_x_columns","7a9e93df":"numeric_y_columns = ['SalePrice']","d50d8b62":"numeric_y_columns","a66c9ce3":"numeric_x_df = pd.DataFrame(numeric_data, columns=numeric_x_columns)\nnumeric_y_df = pd.DataFrame(train_df, columns=numeric_y_columns)","512fb2bc":"numeric_x = torch.tensor(numeric_x_df.values, dtype=torch.float)\nnumeric_y = torch.tensor(numeric_y_df.values, dtype=torch.float)","8946866a":"numeric_x.shape","7733d146":"numeric_y.shape","cd7c1a50":"class Net(nn.Module):\n    def __init__(self, D_in, H1, H2, H3, D_out):\n        super(Net, self).__init__()\n        \n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, H3)\n        self.linear4 = nn.Linear(H3, D_out)\n        \n    def forward(self, x):\n        y_pred = self.linear1(x).clamp(min=0)\n        y_pred = self.linear2(y_pred).clamp(min=0)\n        y_pred = self.linear3(y_pred).clamp(min=0)\n        y_pred = self.linear4(y_pred)\n        return y_pred","e48c01cc":"H1, H2, H3 = 500, 1000, 200","e20e05ab":"D_in, D_out = numeric_x.shape[1], numeric_y.shape[1]","bc85a18c":"model1 = Net(D_in, H1, H2, H3, D_out)","1e2da65b":"criterion = nn.MSELoss(reduction='sum')","108f81e7":"optimizer = torch.optim.SGD(model1.parameters(), lr=1e-4)","91545709":"losses1 = []\n\nfor t in range(500):\n    y_pred = model1(numeric_x)\n    \n    loss = criterion(y_pred, numeric_y)\n    print(t, loss.item())\n    losses1.append(loss.item())\n    \n    if torch.isnan(loss):\n        break\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","b2511494":"means, maxs, mins = dict(), dict(), dict()","3abf2618":"for col in numeric_data:\n    means[col] = numeric_data[col].mean()\n    maxs[col] = numeric_data[col].max()\n    mins[col] = numeric_data[col].min()","eef22d1f":"numeric_data = (numeric_data - numeric_data.mean()) \/ (numeric_data.max() - numeric_data.min())","e79438ea":"numeric_data","5ab1845c":"numeric_x_df = pd.DataFrame(numeric_data, columns=numeric_x_columns)\nnumeric_y_df = pd.DataFrame(train_df, columns=numeric_y_columns)","de0fea51":"numeric_x_df","0b44ceec":"numeric_x = torch.tensor(numeric_x_df.values, dtype=torch.float)\nnumeric_y = torch.tensor(numeric_y_df.values, dtype=torch.float)","91b9842b":"numeric_y","a20d06fc":"model2 = Net(D_in, H1, H2, H3, D_out)\noptimizer = torch.optim.Adam(model2.parameters(), lr=1e-4 * 2)","b3ed3406":"model2","cc4a3199":"losses2 = []\n\nfor t in range(500):\n    y_pred = model2(numeric_x)\n    \n    loss = criterion(y_pred, numeric_y)\n    print(t, loss.item())\n    losses2.append(loss.item())\n    \n    if torch.isnan(loss):\n        break\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","a6954d9b":"plt.figure(figsize=(12, 10))\nplt.plot(range(len(losses2)), losses2, label = 'Adam, 2*1e-4')\nplt.legend(loc='upper right')\nplt.show()","f59dc303":"non_numeric_columns = cat_features","51be03df":"len(non_numeric_columns)","c58bacea":"non_numeric_data = pd.DataFrame(train_df, columns=non_numeric_columns)","318a10f4":"non_numeric_data","94932360":"mapping_table = dict()\n\nfor col in non_numeric_columns:\n    curr_mapping_table = dict()\n    \n    unique_values = pd.unique(non_numeric_data[col])\n    for inx, v in enumerate(unique_values):\n        curr_mapping_table[v] = inx + 1\n        non_numeric_data[col] = non_numeric_data[col].replace(v, inx + 1)\n    \n    mapping_table[col] = curr_mapping_table","94df2861":"non_numeric_data.head()","084ac79c":"for col in non_numeric_data:\n    means[col] = non_numeric_data[col].mean()\n    maxs[col] = non_numeric_data[col].max()\n    mins[col] = non_numeric_data[col].min()","609c8333":"non_numeric_data = (non_numeric_data - non_numeric_data.mean()) \/ (non_numeric_data.max() - non_numeric_data.min())","579b85e4":"non_numeric_data","27aa5712":"non_numeric_x_df = pd.DataFrame(non_numeric_data, columns=non_numeric_columns)\nnon_numeric_y_df = pd.DataFrame(numeric_y_df)","87305c0c":"non_numeric_x_df","b065c310":"non_numeric_x = torch.tensor(non_numeric_x_df.values, dtype=torch.float)\nnon_numeric_y = torch.tensor(non_numeric_y_df.values, dtype=torch.float)","2e4305b0":"non_numeric_y","47f286f6":"D_in, D_out = non_numeric_x.shape[1], non_numeric_y.shape[1]","1218c383":"model3 = Net(D_in, H1, H2, H3, D_out)\noptimizer = torch.optim.Adam(model3.parameters(), lr=1e-4 * 2)","85a73f26":"losses3 = []\n\nfor t in range(500):\n    y_pred = model3(non_numeric_x)\n    \n    loss = criterion(y_pred, non_numeric_y)\n    print(t, loss.item())\n    losses3.append(loss.item())\n    \n    if torch.isnan(loss):\n        break\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","b990cd74":"plt.figure(figsize=(12, 10))\nplt.plot(range(len(losses2)), losses2, label = 'Numeric')\nplt.plot(range(len(losses3)), losses3, label = 'Non-Numeric')\n\nplt.legend(loc='upper right')\nplt.show()","f0808a1c":"x_df = pd.DataFrame(numeric_x_df, columns=numeric_x_columns)\ny_df = pd.DataFrame(numeric_y_df)","a9f47f49":"y_df","e27b8522":"for col in non_numeric_columns:\n    x_df[col] = non_numeric_x_df[col]","fcd1e1f3":"x_df","22064182":"x = torch.tensor(x_df.values, dtype=torch.float)\ny = torch.tensor(y_df.values, dtype=torch.float)","3b251e97":"x","334cef58":"D_in, D_out = x.shape[1], y.shape[1]","f80de5f4":"D_in","532adf29":"model4 = Net(D_in, H1, H2, H3, D_out)\noptimizer = torch.optim.Adam(model4.parameters(), lr=1e-4 * 2)","20bc6489":"optimizer","ff1924be":"losses4 = []\n\nfor t in range(500):\n    y_pred = model4(x)\n    \n    loss = criterion(y_pred, y)\n    print(t, loss.item())\n    losses4.append(loss.item())\n    \n    if torch.isnan(loss):\n        break\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","2fbd2df2":"plt.figure(figsize=(12, 10))\nplt.plot(range(len(losses2)), losses2, label = 'Numeric Only')\nplt.plot(range(len(losses3)), losses3, label = 'Non-Numeric Only')\nplt.plot(range(len(losses4)), losses4, label = 'Entire Data')\n\nplt.legend(loc='upper right')\nplt.show()","d5513b20":"test_x = pd.DataFrame(test_df)\ntest_x = test_x.drop(columns=['Id'])","853b319e":"test_x['Remod_Built_Age'] = test_x['YearRemodAdd'] - test_x['YearBuilt']\ntest_x['Sold_Built_Age'] = test_x['YrSold'] - test_x['YearBuilt']\ntest_x['Remod_Sold_Age'] = test_x['YrSold'] - test_x['YearRemodAdd']\n\ntest_x['TotalSF']=test_x['TotalBsmtSF'] + test_x['1stFlrSF'] + test_x['2ndFlrSF']\ntest_x['Total_sqr_footage'] = (test_x['BsmtFinSF1'] + test_x['BsmtFinSF2'] +\n                                 test_x['1stFlrSF'] + test_x['2ndFlrSF'])\ntest_x['Total_Bathrooms'] = (test_x['FullBath'] + (0.5 * test_x['HalfBath']) +\n                               test_x['BsmtFullBath'] + (0.5 * test_x['BsmtHalfBath']))","f6ee99d8":"test_x.head(7)","21039723":"test_x=test_x.drop(Dump_Clm,1)","6db2e464":"test_x","7c08dffe":"Test_numeric_data = pd.DataFrame(test_x, columns=num_features)\nTest_numeric_data","b4b0ce2b":"for col in Test_numeric_data:\n    means[col] = Test_numeric_data[col].mean()\n    maxs[col] = Test_numeric_data[col].max()\n    mins[col] = Test_numeric_data[col].min()","fc284456":"Test_numeric_data = (Test_numeric_data - Test_numeric_data.mean()) \/ (Test_numeric_data.max() - Test_numeric_data.min())","08893a1a":"Test_numeric_data","c4722cd0":"Test_non_numeric_data = pd.DataFrame(test_x, columns=non_numeric_columns)\nTest_non_numeric_data","d1bffe9e":"mapping_table = dict()\n\nfor col in non_numeric_columns:\n    curr_mapping_table = dict()\n    \n    unique_values = pd.unique(Test_non_numeric_data[col])\n    for inx, v in enumerate(unique_values):\n        curr_mapping_table[v] = inx + 1\n        Test_non_numeric_data[col] = Test_non_numeric_data[col].replace(v, inx + 1)\n    \n    mapping_table[col] = curr_mapping_table","ea933cef":"Test_non_numeric_data","639987b4":"for col in non_numeric_data:\n    means[col] = Test_non_numeric_data[col].mean()\n    maxs[col] = Test_non_numeric_data[col].max()\n    mins[col] = Test_non_numeric_data[col].min()","c0dc9fe1":"Test_non_numeric_data = (Test_non_numeric_data - Test_non_numeric_data.mean()) \/ (Test_non_numeric_data.max() - Test_non_numeric_data.min())","145e40e6":"Test_non_numeric_data","9972a355":"x_df = pd.concat([Test_numeric_data, Test_non_numeric_data], axis=1)","d20c6b4b":"x_df","7ddb66aa":"test_y = model4(torch.tensor(x_df.values, dtype=torch.float))","a887ee7d":"result = pd.DataFrame(test_y.data.numpy(), columns=['SalePrice'])   #create dataframe\nresult['SalePrice'] = result['SalePrice'].fillna(0)                 #checking null and filling 0\nresult['SalePrice']=result['SalePrice'].astype(int)                 #converting to integer\nmaxs = result['SalePrice'].max()                                    #Max value\nmeans = result['SalePrice'].mean()                                  #mean value\nCP_value=(means\/maxs)*means+means+means                             #calibrating predicted value\nresult['SalePrice']=result['SalePrice'].replace(0,CP_value)         #filling 0 positions by calibrating predicted value\nresult['SalePrice']=result['SalePrice'].astype(int)                 #convert to integer","4da0a402":"result['SalePrice']","0289aba1":"result['Id'] = np.array(result.index)\nresult['Id'] = result['Id'] + 1461\nresult = pd.DataFrame(result, columns=['Id', 'SalePrice'])","7ac6571b":"result","b6ae5fe3":"result.to_csv('.\/My_submission.csv', columns=['Id', 'SalePrice'], index=False)","1bb7f8cd":"Vis_Clm=['OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea']\n\nplt.figure(figsize=(20,90))\nfor i in range(len(Vis_Clm)):\n    plt.subplot(12, 3, i+1)\n    sn.scatterplot(x=train_df[Vis_Clm[i]], y=target)\n\nplt.show()\n","67e1bd5f":"### OBSERVATION ABOUT THE ABOVE PLOTS\n- Lot Area is mostly related to the location, not the area \n- Number of overall good houses is high\n- \n-\n-","762048fa":"### Numeric Test data normalize form","d9be337d":"#### First Prediction","3675574e":"#### Define Model : 5-Layer Net","d74665be":"### Given data set\n#### Train data\n- Train data 1460 rows \u00d7 81 columns(Features 80 + Target 1)\n- Train data total Samples: 1460\n- Numerical Features: 37\n- Categorical Features: 43\n- Number of \u2018Unique\u2019 Values:0\n- Number of \u2018Null\u2019 Values:0\n- Number of Duplicates:0\n#### Test data\n- Test data 1459 rows \u00d7 80 columns(Features 80)\n- Testn data total samples: 1459","ddea6763":"#### Making categories to see the Year of Built and sale price relation\n- Some columns like years which are not informative, so need to transform.\n- Performing `binning` on those year column to divide it into decades.\n- Making it categorical.\n- Also calculating the age of house on the basis of different columns.","5478e377":"### DATA VISUALIZE\n- Scatterplot and distribution of numerical features\n- BarCharts of categorical features\n- Box plots to check the outliers","f1af47de":"#### Checking Unique Values ","6ad6047b":"#### Categorical Test data normalize form","a3d9e71f":"##  Predicting the house price of Test data by calling model","4c2660ac":"## DATA PREPROCESSING","785b70a1":"#### Linear Regression with Numeric Data","029405de":"### In a single sentence about house price\n- People are preferring those houses that has overall good condition,  two story big 2-floored, greater furnished basement area and recently remodelled.","5d71fffa":"# Reporting based on above analysis","576a1370":"Acknowledge: I am new in this field and doing practice. I would like to thanks shweta sharma, Arnab Dey, Ajay Tibrewal, Akhil Shukla and jbpark for their great analysis that are helped me to make this notebook.","bcf9354a":"#### Number of  Numerical and Categorical Features","cfd4e017":"#### Value counts of each categorical feature","b9a69f6b":"### Model 5 for entire train data also similar with individual Numeric and Non-Numeric data","cb2ecf67":"### Delete 20 column based on the above observation:\n#### Column Name: \n- 1stFlrSF, TotRmsAbvGrd, GarageCars, Alley, \n  PoolQC, Fence, MiscFeature, YearRemodAdd, YearBuilt, YrSold, YearBuilt, TotalBsmtSF, \n  1stFlrSF, 2ndFlrSF, BsmtFinSF1, BsmtFinSF2, FullBath, HalfBath, BsmtFullBath, BsmtHalfBath\n\n#### BECAUSE:   \n1.Highly correlated column (1stFlrSF, TotRmsAbvGrd and GarageCars )\n- TotalBsmtSF and 1stFlrSF (0.82)\n- GrLivArea and TotRmsAbvGrd (0.83)\n- GarageCars and GarageArea (0.88)\n\n2. Null colunm above 80%: (Alley, PoolQC, Fence, MiscFeature)\n\n3. Used for New feature ( YearRemodAdd, YearBuilt, YrSold, \n                         YearBuilt, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, \n                         BsmtFinSF1, BsmtFinSF2,                                 \n                         FullBath,HalfBath, BsmtFullBath,BsmtHalfBath )\n\n- Remod_Built_Age = YearRemodAdd - YearBuilt\n- Sold_Built_Age = YrSold - YearBuilt\n- Remod_Sold_Age = YrSold - YearRemodAdd\n- TotalSF=TotalBsmtSF + 1stFlrSF + 2ndFlrSF\n- Total_sqr_footage = (BsmtFinSF1 + BsmtFinSF2 +1stFlrSF + 2ndFlrSF)\n- Total_Bathrooms = (FullBath + (0.5 * HalfBath) +BsmtFullBath + (0.5 * BsmtHalfBath))","0ba1e65b":"### Model 4","cb9d97ff":"### Observation of given dataset (Train and Test)\n#### Train data 1460 rows \u00d7 81 columns(Features 80 + Target 1) and Test data  1459 rows \u00d7 80 columns(Features 80)","b2e57cdc":"#### Drop Columns with more than 80% null values","ccd8d646":"### Observation from Skewness of SalePrice\n-  SalePrice is not a normal distribution. SalePrice on the right-hand (positive) side is longer than on the left-hand side.","4d0629f8":"#### Impute NaN Values","e848fefe":"### House Prices with PyTorch","3c134f61":"### 5  features have major and minor ratio \n1. Street:Type of road access to property:-\nPave    1454,\nGrvl       6\n\n2. Utilities:Type of utilities available:-\nAllPub    1459,\nNoSeWa       1\n\n3. RoofMatl:Roof material:-\nCompShg    1434,\nTar&Grv      11,\nWdShngl       6,\nWdShake       5,\nMetal         1,\nClyTile       1,\nRoll          1,\nMembran       1\n\n4. Heating:Type of heating:-\nGasA     1428,\nGasW       18,\nGrav        7,\nWall        4,\nOthW        2,\nFloor       1\n\n5. CentralAir: Central air conditioning:-\nY    1365,\nN      95","2e5e3270":"### Model 2, Much Better and fit for Numeric Data","7682d3d7":"#### Concating numerical and categorical Test data","9be1ba9d":"#### Test data creating new features","45c5e47c":"#### Find Non-Numeric Data Columns","70523991":"#### Feature engineering, analysis, selection and  extraction\n- Total Number of Feature: 67\n- Numerical Features, previous 37, After cleaning and extraction :  28\n- Categorical Features, previous 43, After cleaning and extraction : 39\n- Categorical Data are converted String to int using mapping table\n- Encoding Numeric Data and Categorical\n- Used all the features to get better results compared to using only strong features(above 10)","1f869e46":"### Summary of House price analysis\n- Houses that have the greater living room\/big houses, good overall condition, and greater basement area are expensive houses.\n- Furnished basement having greater area and having capacity of storing more cars are more prefer houses.\n- Two story houses and greater floor area are more prefer houses.\n- Recently remodeled or reconstructed are more prefer houses.","222141a2":"### Findings from  Scatterplot, BarCharts, Box plots\n###### Expensive houses\n- GrLivArea(Above grade (ground) living area square feet): greater area square feet\n- Total square feet of basement area : greater area square feet\n###### More demand\n- BsmtFinType1(Rating of basement finished area): more demand\n- GarageArea(Size of garage in square feet): more demand\n- YearRemodAdd (Remodel date) : recent decads re-bulit more demand\n- YearBuilt(Original construction date): recent decads construction more demand\n###### More prefer\n- MSZoning (Identifies the general zoning classification of the sale): Residential Low Density\n- Street(Type of road access to property): Paved\n- LandContour (Flatness of the property):  Near Flat\/Level\n- Utilities(Type of utilities available): All public Utilities (E,G,W,& S)\t\n- Condition(Proximity to various conditions): Normal\n- BldgType(Type of dwelling)- Single-family Detached\n- HouseStyle (Style of dwelling): Two story\n- BsmtQual(Evaluates the height of the basement): Good\n- GarageType(Garage location): Attached to home\n- GarageFinish(Interior finish of the garage): Rough Finished\n- GarageCond(Garage condition): Typical\/Average\n- BsmtFinType1(Rating of basement finished area): Good Living Quarters","cb1f43b2":"# Model Found!!!!!!! ","e1c42b2a":"## Non-Numeric Data","1fc26128":"### Normalize Data","af7fa98f":"## Normalize","f29c9248":"#### Status of Numerical Features","c38f34fa":"#### Drop Duplicates","6c9845a8":"### Create New Features","489a6dbe":"### Categorical Test data replacing String to Int","9937b08e":"### Quantitive observation of features\n- Total Samples:  1460\n- Total Features:  80\n\n### About Features:\n- Numerical Features:  37\n- Categorical Features: 43\n- Number of \u2018Unique\u2019 Values:0\n- Number of \u2018Null\u2019 Values:0\n- Number of the column of \u2018NAN\u2019 Values above 80% in Numerical  :0\n- Number of the column of \u2018NAN\u2019 Values above 80% in Categorical:4\n- Name of the column of \u2018NAN\u2019 Values above 80% in Categorical:-   Alley, PoolQC, Fence, MiscFeature\n- Observing of imbalanced ration of categorical features:- Street,Utilities,RoofMatl,Heating,CentralAir","31b40ee2":"### ........................","e933639c":"## DATA CLEANING","809e1d9a":"## TRAIN DATA FEATURES ANALYSIS","556d0299":"### Observing Variable that are highly correlated to the Target variable: \n'OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', \n'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea'\n\n#### Highly correlated \n- TotalBsmtSF and 1stFlrSF (0.82)\n- GrLivArea and TotRmsAbvGrd (0.83)\n- GarageCars and GarageArea (0.88)","452189b3":"#### Total Samples","11b27679":"#### Drop columns with single unique value","b9cbaad1":"### ........................","b989187d":"#### Checking Null Values and it's percentage of Features ","a8e1fe3a":"#### Dumping useless colunm","2d7ebb6c":"### Model 3 for catagorical train data, Looks like similar with numeric data , so we need closer look","a7f42f49":"#### 10 features which are impacting the house prices\n- From the correlattion analysis:- \"OverallQual, YearBuilt, YearRemodAdd, TotalBsmtSF, 1stFlrSF, GrLivArea, FullBath, TotRmsAbvGrd, GarageCars, GarageArea\"   are impacting the house prices\n\n1. OverallQual: Rates the overall material and finish of the house\n2. YearBuilt:Original construction date \n3. YearRemodAdd: Remodel date (same as construction date if no remodeling or additions) \n4. TotalBsmtSF:Total square feet of basement area \n5. 1stFlrSF:First Floor square feet\n6. GrLivArea:Above grade (ground) living area square feet\n7. FullBath:Full bathrooms above grade\n8. TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n9. GarageCars: Size of garage in car capacity \n10. GarageArea: Size of garage in square feet","3eef437e":"#### Convert String to int using mapping table","8088fe99":"## Test Data","a0476489":"## TARGET ANALYSIS","a8840dd4":"#### Visualising these 10 columns with respect to the price","245ae8d2":"### Separated Test_non_numeric_data (Categorical)","5ac3f3e7":"### Separated Test_numeric_data","5629d937":"#### Normalizing Numeric Test data ","95a9505e":"### Entire Test data set","8908b6d5":"###  20  features have less impact on the house prices in the view of similarity, missing, and  extracting new feature\n#### These 20  features which are highly correlated with others column, null colunm above 80% and used for new feature\n\n- 1stFlrSF, TotRmsAbvGrd, GarageCars, Alley, \n  PoolQC, Fence, MiscFeature, YearRemodAdd, YearBuilt, YrSold, YearBuilt, TotalBsmtSF, \n  1stFlrSF, 2ndFlrSF, BsmtFinSF1, BsmtFinSF2, FullBath, HalfBath, BsmtFullBath, BsmtHalfBath\n\n\n\n#### Because:   \n1. Both colunm are alomst same\n- TotalBsmtSF: Total square feet of basement area\n- 1stFlrSF : First floor square feet\n- GrLivArea:  Above grade (ground) living area square feet\n- TotRmsAbvGrd : Total rooms above grade (does not include bathrooms)\n- GarageCars :Size of garage in car capacity\n- GarageArea :Size of garage in square feet\n\n2. Meaning less information due to high missing value\n- Alley: Type of alley access to property \n- PoolQC: Pool quality\n- Fence: Fence quality\n- MiscFeature :Miscellaneous feature not covered in other categories\n\n3. Before converting a new feature, it's being less important\n- YearRemodAdd : Remodel date (same as construction date if no remodeling or additions)\n- YearBuilt : Original construction date\n- YrSold : Year Sold (YYYY)                  \n- YearBuilt : Original construction date\n- TotalBsmtSF : Total square feet of basement area \n- 1stFlrSF : First Floor square feet\n- ndFlrSF : Second floor square feet\n- BsmtFinSF1 : Type 1 finished square feet\n- BsmtFinSF2  : Type 2 finished square feet                              \n- FullBath: Full bathrooms above grade\n- HalfBath : Half baths above grade\n- BsmtFullBath: Basement full bathrooms\n- BsmtHalfBath: Basement half bathrooms","6a9bba58":"### Second Prediction","002adfb2":"#### Saving Mean, Max, Min for each Columns","1a7d806c":"#### Null colunm above 80%","de13c7b4":"### Linear Regression with Entire Data","57c302ca":"#### Total Features","28ca4779":"### Linear Regression with Non-Numeric Data","c7839ed7":"# The End","2593de09":"## IMPORT LIBRARY and LOADING DATA\n###  Loading both train and test dataset","aef500a8":"### Entire Train Data","c48a1cda":"### Model and  tuning hyperparameter\n- Used  PyTorch for House Prices model\n- Before data normalization, models performed very poor.\n- Data normalization is applied to all Numeric Data, and Categorical data\n- Model is performed individual on Numeric Data, and Categorical data, and entire train data\n- Found  3 models with similar results based on the losses graph\n- Model 5 is selected due to the entire train data and Model 5 shows a similar graph with individual Numeric and Categorical data\n\n#### Tune parameter\n- 5-Layer Net\n- D_in, H1, H2, H3, D_out = 67, 500, 1000, 200, 1\n- Parameter Group 0\n- amsgrad: False\n- betas: (0.9, 0.999)\n- eps: 1e-08\n- lr: 0.0002\n- weight_decay: 0","734bbf18":"### Model 1 is not working","dcf25af0":"#### Saving Mean, Max, Min for each Columns","0f1b8210":"### Observation of  Targer or SalePrice\n-  Right Skewness","6b597ad8":"### Observing of imbalanced ratio of categorical features\n- Street:\nPave    1454,\nGrvl       6\n\n- Utilities:\nAllPub    1459,\nNoSeWa       1\n\n- RoofMatl:\nCompShg    1434,\nTar&Grv      11,\nWdShngl       6,\nWdShake       5,\nMetal         1,\nClyTile       1,\nRoll          1,\nMembran       1\n\n- Heating:\nGasA     1428,\nGasW       18,\nGrav        7,\nWall        4,\nOthW        2,\nFloor       1\n\n- CentralAir:\nY    1365,\nN      95","41c53ff7":"#### Drop uninformative columns","ab3bcb13":"#### Explore Non-Numeric Data"}}