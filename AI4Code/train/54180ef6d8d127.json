{"cell_type":{"0a93f213":"code","5b19dd80":"code","17e3f8e1":"code","a065b276":"code","0ea4a33b":"code","272a2611":"code","58deb256":"code","6bb71274":"code","78dc1f62":"code","053cb55c":"code","da7cb427":"code","87b91e97":"code","c352a228":"code","bd744397":"code","5870d291":"code","26d760cb":"code","ec147bae":"code","29923e98":"code","02767857":"code","57a8f3b3":"code","9065837e":"code","18c78dbb":"code","0ac4e5dc":"code","95bfe333":"code","9e083166":"code","042157e4":"code","b5559050":"code","b59cf7a1":"code","a7a4458c":"code","4a9bfdcb":"code","c35fed9b":"code","1aa8158d":"code","6eaa4d2c":"code","9abe41a1":"code","29c8158c":"markdown"},"source":{"0a93f213":"!pip install -q cython pyyaml","5b19dd80":"!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'","17e3f8e1":"pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","a065b276":"import torch\nimport torchvision\n\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.data import datasets, DatasetCatalog, MetadataCatalog, build_detection_train_loader, build_detection_test_loader\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.structures import BoxMode\n\n\nfrom tqdm.notebook import tqdm\nimport random\nimport itertools\nimport ntpath\n\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport PIL.Image as Image\nimport cv2\n\nimport urllib  # download image from url\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames[:5]:\n        print(os.path.join(dirname, filename))\n","0ea4a33b":"os.makedirs(\"faces\", exist_ok=True)    # create a new folder in kaggle output","272a2611":"faces_df = pd.read_json('\/kaggle\/input\/face-detection-in-images\/face_detection.json', lines=True)\nfaces_df","58deb256":"faces_df.shape[0]","6bb71274":"dataset = []\n\n\nfor index,row in tqdm(faces_df.iterrows(), total = faces_df.shape[0]):\n    \n    img = urllib.request.urlopen(row['content'])\n    img = Image.open(img)\n    img = img.convert('RGB')\n    \n    image_name = f'face_{index}.jpeg'    # labeling image\n    img.save(f'faces\/{image_name}', \"JPEG\")  # save to dir output kaggle\n    \n    annotations = row['annotation']\n    for i in annotations:\n        \n        width = i['imageWidth']\n        height = i['imageHeight']\n        points = i['points']\n        \n        data = {}\n        \n        data['file_name'] = image_name\n        data['width'] = width\n        data['height'] = height\n        \n        data[\"x_min\"] = int(round(points[0][\"x\"] * width))\n        data[\"y_min\"] = int(round(points[0][\"y\"] * height))\n        data[\"x_max\"] = int(round(points[1][\"x\"] * width))\n        data[\"y_max\"] = int(round(points[1][\"y\"] * height))\n        \n        data['class_name'] = 'face'\n        \n        dataset.append(data)\n        \n        ","78dc1f62":"dataset","053cb55c":"df = pd.DataFrame(dataset)\ndf","da7cb427":"print(df.file_name.unique().shape[0], df.shape[0])","87b91e97":"df.to_csv('annotations.csv', header=True, index=None)  # save to csv","c352a228":"DATA_DIR = '\/kaggle\/working\/faces\/'","bd744397":"def show_image(image_id):\n    \n\n    bbox = df[df['file_name'] == image_id ]\n    \n    img_path = os.path.join(DATA_DIR, image_id)\n    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n    image \/= 255.0\n    image2 = image\n    \n    for idx, row in bbox.iterrows():\n        \n        cv2.rectangle(image, (row.x_min, row.y_min), (row.x_max, row.y_max), (255,255,255), 2)\n        font = cv2.FONT_HERSHEY_SIMPLEX\n        cv2.putText(image, row.class_name, (row.x_min, (row.y_min - 10)), font, 1, (255,255,255), 2)\n\n    plt.figure(figsize =(20,20))\n    plt.imshow(image)\n    plt.axis('off')","5870d291":"show_image(df.file_name.unique()[40])","26d760cb":"# create custom database","ec147bae":"# split train, val\n\nunique_files = df.file_name.unique()\n\ntrain_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.95), replace = False))\ntrain_df = df[df.file_name.isin(train_files)]\ntest_df = df[~df.file_name.isin(train_files)]  #negasi\ntrain_files\n","29923e98":"print(train_df.shape[0], test_df.shape[0])","02767857":"classes = df.class_name.unique().tolist()\nclasses","57a8f3b3":"def create_dataset_dicts(df, classes):\n    \n    dataset_dicts = []\n\n    for image_id, img_name in enumerate(df.file_name.unique()):\n        \n        record = {}\n        image_df = df[df.file_name == img_name]\n        file_path = f'{DATA_DIR}\/{img_name}'\n        \n        record[\"file_name\"] = file_path\n        record[\"image_id\"] = image_id\n        record[\"height\"] = int(image_df.iloc[0].height)\n        record[\"width\"] = int(image_df.iloc[0].width)\n        objs = []\n        \n        for _, row in image_df.iterrows():\n            \n            xmin = int(row.x_min)\n            ymin = int(row.y_min)\n            xmax = int(row.x_max)\n            ymax = int(row.y_max)\n          \n            poly = [\n              (xmin, ymin), (xmax, ymin),\n              (xmax, ymax), (xmin, ymax)\n              ]\n            \n            poly = list(itertools.chain.from_iterable(poly))\n            \n            \n            obj = {\n                    \"bbox\": [xmin, ymin, xmax, ymax],\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"segmentation\": [poly],\n                    \"category_id\": classes.index(row.class_name),\n                    \"iscrowd\": 0\n                  }\n            \n            objs.append(obj)\n            \n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    \n    return dataset_dicts\n        ","9065837e":"def register_dataset(df, dataset_label='faces_train', train = True):\n    \n    # Register dataset - if dataset is already registered, give it a new name    \n    try:\n        DatasetCatalog.register(dataset_label, lambda d=df: create_dataset_dicts(df, classes))\n        MetadataCatalog.get(dataset_label).thing_classes = classes\n    except:\n        # Add random int to dataset name to not run into 'Already registered' error\n        n = random.randint(1, 1000)\n        dataset_label = dataset_label + str(n)\n        DatasetCatalog.register(dataset_label, lambda d=df: create_dataset_dicts(df, classes))\n        MetadataCatalog.get(dataset_label).thing_classes = classes\n        \n    if train == True:\n        \n        return MetadataCatalog.get(dataset_label), dataset_label\n    \n    else:\n        \n        return dataset_label","18c78dbb":"# Register train dataset\n\n\nmetadata, train_dataset = register_dataset(train_df)","0ac4e5dc":"# Register val dataset\n\ntest_dataset = register_dataset(test_df, dataset_label='image_test', train = False)","95bfe333":"metadata","9e083166":"MODEL_USE = 'retinanet'\nif MODEL_USE == 'faster_rcnn':\n    MODEL_PATH = 'COCO-Detection\/faster_rcnn_R_101_FPN_3x.yaml'\n    WEIGHT_PATH = 'COCO-Detection\/faster_rcnn_R_101_FPN_3x.yaml'\nelif MODEL_USE == 'retinanet':\n    MODEL_PATH = 'COCO-Detection\/retinanet_R_101_FPN_3x.yaml'\n    WEIGHT_PATH = 'COCO-Detection\/retinanet_R_101_FPN_3x.yaml'","042157e4":"def cfg_setup():\n    \n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(MODEL_PATH))\n    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(WEIGHT_PATH)\n    cfg.MODEL.RETINANET.NUM_CLASSES = 1\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n\n    cfg.DATASETS.TRAIN = (train_dataset,)\n    cfg.DATASETS.TEST = (test_dataset,)\n    cfg.DATALOADER.NUM_WORKERS = 4\n\n    cfg.SOLVER.IMS_PER_BATCH = 4\n    cfg.SOLVER.BASE_LR = 0.001\n    cfg.SOLVER.WARMUP_ITERS = 1000\n    cfg.SOLVER.MAX_ITER = 500\n    cfg.SOLVER.STEPS = (1000, 1500)\n    cfg.SOLVER.GAMMA = 0.05\n    \n    \n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\n    cfg.TEST.EVAL_PERIOD = 500\n\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n        \n    return cfg","b5559050":"cfg = cfg_setup()","b59cf7a1":"trainer = DefaultTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","a7a4458c":"evaluator = COCOEvaluator(test_dataset , cfg, False, output_dir=\".\/output\/\")\nval_loader = build_detection_test_loader(cfg, test_dataset)\ninference_on_dataset(trainer.model, val_loader, evaluator)","4a9bfdcb":"def cfg_test():\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(MODEL_PATH))\n    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')\n    cfg.DATASETS.TEST = (test_dataset,)\n    cfg.MODEL.RETINANET.NUM_CLASSES = 1\n    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.45\n    \n    return cfg\n\ncfg = cfg_test()\npredict = DefaultPredictor(cfg)\n","c35fed9b":"# CONFIG\n\ncolor = (255, 255, 0)\n    \ndef visual_predict(image, color):\n    \n    img = cv2.imread('{}\/{}'.format(DATA_DIR, image))\n    output = predict(img)\n        \n    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n    v = v.draw_instance_predictions(output['instances'].to('cpu'))\n    plt.figure(figsize = (14, 10))\n    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    plt.show()","1aa8158d":"test_df.file_name.unique()[0]","6eaa4d2c":"visual_predict(test_df.file_name.unique()[0], color)","9abe41a1":"visual_predict(test_df.file_name.unique()[4], color)","29c8158c":"<h1><center> Detectron 2 Face Detection"}}