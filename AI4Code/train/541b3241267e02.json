{"cell_type":{"fe4678ed":"code","48f8de82":"code","d931edcf":"code","df8d1e87":"code","b4a36300":"code","5c90a8a8":"code","46568d30":"code","d2b644a1":"code","9718c105":"code","5a84d3f2":"code","aedcc20d":"code","e7005eb1":"code","f80d763f":"code","29822700":"code","b439a1da":"code","9f28b7f1":"code","e4719b83":"code","5f01cf00":"code","c058bd5e":"code","eeba4a11":"code","9a91ea9b":"code","51ddcde6":"code","96382977":"code","e277a6d2":"code","daaf7f52":"code","b2eeb54f":"code","fb643518":"code","f6517db0":"code","af3a5e46":"code","d31426e7":"code","18aac893":"code","22009b3d":"code","c317cc89":"code","41f2991b":"code","64106e94":"markdown","a97404de":"markdown","69afe8b2":"markdown","3aaa9b3d":"markdown","e0d61bc3":"markdown","2617c0ad":"markdown","8fda30ac":"markdown","7c977ab8":"markdown"},"source":{"fe4678ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","48f8de82":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","d931edcf":"train.head()","df8d1e87":"# See the missing values present in each column.\ntrain.isnull().sum()","b4a36300":"# See the missing values in test data.\ntest.isnull().sum()","5c90a8a8":"# Check for different data types in the dataset\ntrain.dtypes","46568d30":"# percent of missing data \ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data = missing_data.loc[missing_data.Percent>0]\nmissing_data","d2b644a1":"train_data = train.copy()\ntrain_data[\"Age\"].fillna(train[\"Age\"].mean(skipna=True), inplace=True)\ntrain_data[\"Embarked\"].fillna(train['Embarked'].value_counts().idxmax(), inplace=True)\ntrain_data.drop('Cabin', axis=1, inplace=True)","9718c105":"## Create categorical variable for traveling alone\ntrain_data['TravelAlone']=np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\ntrain_data.drop('SibSp', axis=1, inplace=True)\ntrain_data.drop('Parch', axis=1, inplace=True)","5a84d3f2":"#create categorical variables and drop some variables\ntrain_data=pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\ntrain_data.drop('Sex_female', axis=1, inplace=True)\ntrain_data.drop('PassengerId', axis=1, inplace=True)\ntrain_data.drop('Name', axis=1, inplace=True)\ntrain_data.drop('Ticket', axis=1, inplace=True)\n\ntrain_data.head()","aedcc20d":"test_data = test.copy()\ntest_data[\"Age\"].fillna(test[\"Age\"].mean(skipna=True), inplace=True)\ntest_data[\"Embarked\"].fillna(test['Embarked'].value_counts().idxmax(), inplace=True)\ntest_data.drop('Cabin', axis=1, inplace=True)\n\n## Create categorical variable for traveling alone\ntest_data['TravelAlone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\ntest_data.drop('SibSp', axis=1, inplace=True)\ntest_data.drop('Parch', axis=1, inplace=True)\n\n#create categorical variables and drop some variables\ntest_data=pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\ntest_data.drop('Sex_female', axis=1, inplace=True)\ntest_data.drop('PassengerId', axis=1, inplace=True)\ntest_data.drop('Name', axis=1, inplace=True)\ntest_data.drop('Ticket', axis=1, inplace=True)\n\ntest_data.head()","e7005eb1":"# Split the dataframe into data and labels\nX = train_data.drop('Survived', axis=1) # data\nY = train_data.Survived # labels","f80d763f":"from sklearn.preprocessing import StandardScaler, MinMaxScaler","29822700":"# Scale train data\nstdscale = StandardScaler().fit(X)\n# transform training data\nX_std = stdscale.transform(X)","b439a1da":"# Scale test data\nstdscale = StandardScaler().fit(test_data)\n# transform training data\ntest_data_std = stdscale.transform(test_data)","9f28b7f1":"from sklearn.model_selection import train_test_split, cross_val_score","e4719b83":"X_train, X_val, Y_train, Y_val = train_test_split(X_std,Y,test_size=0.2)","5f01cf00":"print('X_train :'+str(X_train.shape))\nprint('Y_train :'+str(Y_train.shape))\nprint('---')\nprint('Y_val :'+str(Y_val.shape))\nprint('X_val :'+str(X_val.shape))","c058bd5e":"print(Y_train.value_counts())","eeba4a11":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom keras.regularizers import l2, l1, l1_l2\nimport matplotlib.pyplot as plt","9a91ea9b":"from tensorflow.keras.optimizers import RMSprop, Adam, SGD","51ddcde6":"def plot_acc(history, title=\"Model Accuracy\"):\n    \"\"\"Imprime una gr\u00e1fica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title(title)\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.grid(True)\n    plt.legend(['Train', 'Val'], loc='upper left')\n    plt.show()\n    \ndef plot_loss(history, title=\"Model Loss\"):\n    \"\"\"Imprime una gr\u00e1fica mostrando la p\u00e9rdida por epoch obtenida en un entrenamiento\"\"\"\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title(title)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.grid(True)\n    plt.legend(['Train', 'Val'], loc='upper right')\n    plt.show()","96382977":"rn = keras.Sequential()\nrn.add(keras.layers.Dense(12, input_shape=[10], activation='relu', kernel_regularizer=l2(0.01)))\nrn.add(keras.layers.Dense(1, activation='sigmoid'))\n#reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.00002, patience=3, min_lr=0.00000001)","e277a6d2":"rn.compile(\n    optimizer='Adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","daaf7f52":"history = rn.fit(\n    X_train, Y_train,\n    validation_data=(X_val, Y_val),\n    batch_size=5,\n    epochs=60,\n#    callbacks=[reduce_lr],\n    verbose=1,  # turn off training log\n)","b2eeb54f":"plot_loss(history, title=\"Model Loss\")\nplot_acc(history, title=\"Model Accuracy\")","fb643518":"val_loss, val_acc= rn.evaluate(X_val, Y_val)","f6517db0":"Y_pred = rn.predict(test_data_std)","af3a5e46":"Y_pred_b = np.where(Y_pred > 0.5, 1,0)\nY_pred_b[:20]","d31426e7":"# Create a submisison dataframe and append the relevant columns\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = Y_pred_b # our model predictions on the test dataset\nsubmission.head()","18aac893":"submission.dtypes","22009b3d":"len(submission)","c317cc89":"len(test)","41f2991b":"# Convert submisison dataframe to csv for submission to csv \n# for Kaggle submisison\nsubmission.to_csv('fully_connected_submission.csv', index=False)","64106e94":"## Fully Connected Classification Model ","a97404de":"* Cabin: 77% of records are missing, so, I will ignore this variable\n* Embarked: There are only 2, so I impute with the port where most people boarded.","69afe8b2":"### Submission","3aaa9b3d":"According to the Kaggle data dictionary, both SibSp and Parch relate to traveling with family. For simplicity's sake (and to account for possible multicollinearity), I'll combine the effect of these variables into one categorical predictor: whether or not that individual was traveling alone.","e0d61bc3":"Same changes to the test data.","2617c0ad":"### Predict","8fda30ac":"### Fully Connected Network","7c977ab8":"Split with Train and Validation data"}}