{"cell_type":{"4721cd54":"code","e7c8562f":"code","ffa53b57":"code","a72def4d":"code","bdf97eab":"code","db4e7753":"code","925f8706":"code","cd4cac60":"code","6eff99c6":"code","6f32652b":"code","1c26a033":"code","117e6e5f":"code","8bb1096b":"code","3f1fe79c":"code","1e9138bb":"code","b3755082":"code","5a2c72b2":"code","fe8e9ddf":"code","3879c769":"code","e85bb59f":"code","68a88139":"code","ed4a2a71":"code","a050196a":"code","574f4491":"code","ee53a88f":"code","1e3e26db":"code","5ace183c":"code","65b91912":"code","b6870bc9":"code","57c3f4f1":"code","06441ca4":"code","7cdf7761":"code","67aebe21":"code","d3782503":"code","4b5d79ba":"code","561a552b":"code","4adf6b2f":"code","70ec7c86":"markdown","5c093237":"markdown","333a93c4":"markdown","0ace5645":"markdown","42bc5360":"markdown","dc8697ca":"markdown","81db9091":"markdown","d32edea0":"markdown"},"source":{"4721cd54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB1\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport ipywidgets as widgets\nimport io\nfrom PIL import Image\nfrom IPython.display import display,clear_output\nfrom warnings import filterwarnings\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","e7c8562f":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n\nsns.palplot(colors_dark)\nsns.palplot(colors_green)\nsns.palplot(colors_red)","ffa53b57":"labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']","a72def4d":"X_train = []\ny_train = []\nimage_size = 150\nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Training',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size, image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Testing',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nX_train = np.array(X_train)\ny_train = np.array(y_train)","bdf97eab":"k=0\nfig, ax = plt.subplots(1,4,figsize=(20,20))\nfig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)\nfor i in labels:\n    j=0\n    while True :\n        if y_train[j]==i:\n            ax[k].imshow(X_train[j])\n            ax[k].set_title(y_train[j])\n            ax[k].axis('off')\n            k+=1\n            break\n        j+=1","db4e7753":"X_train, y_train = shuffle(X_train,y_train, random_state=101)","925f8706":"X_train.shape","cd4cac60":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.2,random_state=101)","6eff99c6":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","6f32652b":"sns.countplot(y_train)","1c26a033":"sns.countplot(y_test)","117e6e5f":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)","8bb1096b":"effnet = EfficientNetB1(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","3f1fe79c":"model = effnet.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(4,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=effnet.input, outputs = model)","1e9138bb":"model.summary()","b3755082":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","5a2c72b2":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","fe8e9ddf":"history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","3879c769":"filterwarnings('ignore')\n\nepochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy\/Loss',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()","e85bb59f":"pred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_test,axis=1)","68a88139":"print(classification_report(y_test_new,pred))","ed4a2a71":"fig,ax=plt.subplots(1,1,figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\nfig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n\nplt.show()","a050196a":"def generate_adversary(image, label):\n  image = tf.cast(image, tf.float32)\n\n  with tf.GradientTape() as tape:\n    tape.watch(image)\n    prediction = model(image)\n    loss = tf.keras.losses.MSE(label, prediction)\n  gradient = tape.gradient(loss, image)\n  sign_grad = tf.sign(gradient)\n\n  return sign_grad","574f4491":"def print_shapes(x_train, x_test, y_train, y_test):\n  print(f\"x_train: {x_train.shape}\\n\"\\\n      f\"x_test: {x_test.shape}\\n\"\\\n      f\"y_train: {y_train.shape}\\n\"\\\n      f\"y_test: {y_test.shape}\\n\")\nprint_shapes(X_train, X_test, y_train, y_test)","ee53a88f":"from random import randint\nheight, width, channels = 150, 150, 3\n\nrand_idx = randint(0,2936)\nimage = X_train[rand_idx].reshape((1, height, width, channels))\nlabel = y_train[rand_idx]\n\nprint(f'Prediction from CNN: {labels[np.where(label==1)[0][0]]}')\nplt.figure(figsize=(3,3))\nplt.imshow(image.reshape((height, width, channels)))\nplt.show()","1e3e26db":"perturbations = generate_adversary(image,label).numpy()\nadversarial = image + (perturbations * 8)","5ace183c":"fig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\nax1.imshow(image.reshape(height,width, channels))\nax1.set_title(\"Original Image\")\nax2.imshow(adversarial.reshape(height,width, channels))\nax2.set_title(\"Image with Adversary\")\nplt.show()","65b91912":"print(f'Normal Image Prediction: {labels[model.predict(image).argmax()]}')\nprint(f\"Adversary Prediction: {labels[model.predict(adversarial).argmax()]}\")","b6870bc9":"def adversary_generator(batch_size):\n  while True:\n    images = []\n    labels = []\n    for batch in range(batch_size):\n      N = randint(0, 2610)\n      label = y_train[N]\n      image = X_train[N].reshape((1,height, width, channels))\n\n      perturbations = generate_adversary(image, label).numpy()\n      adversarial = image + (perturbations * 8)\n\n      images.append(adversarial)\n      labels.append(label)\n\n      if batch%100 == 0:\n        print(f\"{batch} images generated\")\n\n    images = np.asarray(images).reshape((batch_size, height, width, channels))\n    labels = np.asarray(labels)\n\n    yield images, labels","57c3f4f1":"x_adversarial, y_adversarial = next(adversary_generator(653))\nad_acc = model.evaluate(x_adversarial, y_adversarial, verbose=0)\nprint(f\"Accuracy on Adversarial Examples: {ad_acc[1]*100}\")","06441ca4":"history = model.fit(x_adversarial, y_adversarial,validation_split=0.1, epochs = 14, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","7cdf7761":"pred = model.predict(x_adversarial)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_adversarial,axis=1)","67aebe21":"print(classification_report(y_test_new,pred))","d3782503":"from random import randint\nheight, width, channels = 150, 150, 3\n\nrand_idx = randint(0,2936)\nimage = X_train[rand_idx].reshape((1, height, width, channels))\nlabel = y_train[rand_idx]\n\nprint(f'Prediction from CNN: {labels[np.where(label==1)[0][0]]}')\nplt.figure(figsize=(3,3))\nplt.imshow(image.reshape((height, width, channels)))\nplt.show()","4b5d79ba":"perturbations = generate_adversary(image,label).numpy()\nadversarial = image + (perturbations * 8)","561a552b":"fig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\nax1.imshow(image.reshape(height,width, channels))\nax1.set_title(\"Original Image\")\nax2.imshow(adversarial.reshape(height,width, channels))\nax2.set_title(\"Image with Adversary\")\nplt.show()","4adf6b2f":"print(f'Normal Image Prediction: {labels[model.predict(image).argmax()]}')\nprint(f\"Adversary Prediction: {labels[model.predict(adversarial).argmax()]}\")","70ec7c86":"# **Adversarial Training**","5c093237":"# **After Training**","333a93c4":"# **Adversarial Attack : Fast Gradient Sign Method**","0ace5645":"# **Data Preperation**","42bc5360":"# **Transfer Learning**","dc8697ca":"# **Evaluation**","81db9091":"# **Training The Model**","d32edea0":"# **Prediction**"}}