{"cell_type":{"0c38c866":"code","6eb613b2":"code","feb8e38d":"code","2be4d6b7":"code","6fcaa770":"code","39b50b86":"code","2cf4b22c":"code","892cb2fa":"code","cbd70666":"code","a7332cb6":"code","526a3323":"code","db684ed7":"code","44ae4c3c":"code","b67e1ff1":"code","9db37fa2":"code","43520a78":"code","f140d2fd":"code","c0350e85":"code","5114a306":"code","3eafe1ad":"code","bbef16c0":"code","ce20683b":"code","5d3b3b1d":"code","ee586a30":"code","b164e069":"code","b7c0a925":"code","aaa08967":"code","89ca9b95":"code","05690dec":"code","730377a0":"code","3b7d318d":"code","88cbe5c0":"code","64ba9bd9":"code","bd74fdb5":"code","3afd55c0":"code","6f0357dd":"code","38a3dcb9":"code","0693eb2c":"code","54f01f47":"code","df091d15":"code","da48b046":"code","3d824b7b":"code","30e18894":"code","6f5b0f84":"code","99148662":"code","c152bc9b":"code","f2f3e4d5":"code","205fd8ea":"code","4309b570":"code","3afceca4":"code","a7ada4f0":"code","55baf2c4":"code","6850fd59":"code","3246d701":"code","f9e75018":"code","b8e1cae3":"code","7b36b692":"code","2f84471c":"code","47a66f8a":"code","f4880045":"code","39f5be1c":"code","31b7cca7":"code","c6c54a77":"code","02c711b1":"code","4b380dba":"code","8abdba5b":"code","c6102f1f":"code","432ed54d":"code","598fef3b":"code","df03c6cd":"code","a3f127c7":"code","b79a166c":"code","7ef361cd":"code","2f75b6d7":"code","109ec172":"code","62663391":"code","a3893e6f":"code","b8e171e3":"code","c7bb645c":"code","6d3e0e50":"code","83902b2f":"code","5c0f0f46":"code","f92edb5f":"code","e578c8f0":"code","e9dc605a":"code","bd48e1ec":"code","7d9cc984":"code","11bd9d8e":"code","07d8d1c2":"code","0e2b79f9":"code","b543b6a6":"code","1cb82cf8":"code","6adf68d7":"code","699370da":"code","2ce2c399":"code","b8f8138c":"code","425ca4b0":"code","1aafa77f":"code","80353369":"code","3892952a":"code","a0651b4b":"code","50cb3e6b":"code","4060305f":"code","bd0e2d5f":"code","f21c9161":"code","e33ca0ea":"code","072c0516":"code","084f12d3":"code","14747e3e":"code","1b3aa9cc":"code","abd63157":"code","2055ec9d":"markdown","e67b1903":"markdown","a2d595d8":"markdown","3bfb5629":"markdown","9e53fccc":"markdown","6062d79e":"markdown","2f8a07a7":"markdown","126b9e57":"markdown","a3c9350f":"markdown","b189b186":"markdown","06ad4c0f":"markdown","b29f89b3":"markdown","14d4daad":"markdown","c10c51cf":"markdown","f81df7d4":"markdown","20149b85":"markdown","c92765b1":"markdown","a116e526":"markdown","1b87256c":"markdown","9c35e174":"markdown","7640f739":"markdown","23badfcd":"markdown","77517d58":"markdown","b01748ae":"markdown","17214b6b":"markdown","1398843c":"markdown","def02e04":"markdown","d7c05c09":"markdown","c2436622":"markdown","a50052b0":"markdown","d1106568":"markdown","1addd132":"markdown","135c0b9d":"markdown","1b00de9a":"markdown","69d5cb30":"markdown","23ce464b":"markdown","0bbd8f44":"markdown","98162c7a":"markdown","2917b8bf":"markdown","03ca5b0e":"markdown","abdb9b78":"markdown"},"source":{"0c38c866":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import SGD, Adam, Adamax\nfrom difflib import SequenceMatcher\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom gensim.models import Word2Vec","6eb613b2":"#load data\ndata1=pd.read_csv(\"\/kaggle\/input\/restaurant-recommendation-challenge\/train_full.csv\")\ndata1.head()","feb8e38d":"data1.info()","2be4d6b7":"# Visualize missing values as a matrix\nmain_df=data1[['gender','location_type','language','OpeningTime','city_id','vendor_rating']]\nmsno.matrix(main_df)","6fcaa770":"#Gender\n\nprint(data1['gender'].value_counts()) \ngender_null = np.count_nonzero(data1['gender'].isnull())\nprint(gender_null)\n\ngender_null\/data1.shape[0]\n# variables : Male \/ Female \n# null ratio is about 30%","39b50b86":"sns.countplot('gender',data=data1)","2cf4b22c":"#location type\nprint(data1['location_type'].value_counts())\nlocation_null = np.count_nonzero(data1['location_type'].isnull())\nprint(location_null)\n\nprint(\"null Ratio : \", location_null\/data1.shape[0]) \n# variables : Home \/ Work \/ Other  but, we don't know the meaning of 'other' \n# null ratio is about 45%","892cb2fa":"sns.countplot('location_type',data=data1)","cbd70666":"# The difference of location type by gender\nsns.countplot(data1['gender'],hue=data1['location_type'])","a7332cb6":"#Language\nprint(data1['language'].value_counts())\nnull = np.count_nonzero(data1['language'].isnull())\nprint(null)\n\nnull\/data1.shape[0] \n# variables : it has only EN(english)\n# null ratio is about 15%","526a3323":"#Opening Time\nnull = np.count_nonzero(data1['OpeningTime'].isnull())\nprint(null)\n\nnull\/data1.shape[0]\n# null ratio is about 9%","db684ed7":"#Vendor's average rating score\n\nprint(data1['vendor_rating'].value_counts())\nnull = np.count_nonzero(data1['vendor_rating'].isnull())\nprint(null)\n\nnull\/data1.shape[0]\n# it has no NaN","44ae4c3c":"sns.countplot('vendor_rating',data=data1)","b67e1ff1":"data2 = pd.read_csv(\"\/kaggle\/input\/restaurant-recommendation-challenge\/orders.csv\")\ndata2.head()","9db37fa2":"data2.info()","43520a78":"#vendor_rating\n\nprint(data2['vendor_rating'].value_counts())\nnull = np.count_nonzero(data2['vendor_rating'].isnull())\nprint(null)\n\nnull\/data2.shape[0] \n# null ratio is about 66%","f140d2fd":"sns.countplot('vendor_rating',data=data2)","c0350e85":"#vendor_id\nprint(data2['vendor_id'].value_counts())\n#the unique vendor count is 100","5114a306":"#customer_id\nprint(data2['customer_id'].value_counts())\n#the customer number is 27445","3eafe1ad":"# Choose some columns from data1(train_full.csv)\n# vendor_rating - > mean_rating\ndataset1 = data1[['customer_id','gender','location_type','id','OpeningTime','language','vendor_rating','serving_distance','vendor_tag_name','delivery_charge']]\ndataset1.rename(columns = {\"vendor_rating\": \"mean_rating\"}, inplace = True)\n\n# Make derived variables 'all' with id and customer_id columns\ncols = ['customer_id', 'id']\ndataset1['all'] = dataset1[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n\ndataset1.head()","bbef16c0":"# Drop duplicates based 'all' derived variables\ndataset1.drop_duplicates(['all'],inplace=True)","ce20683b":"# Choose some columns from data2(orders.csv)\n# vendor_id - > id\ndataset2 = data2[['akeed_order_id','customer_id','vendor_id', 'item_count', 'grand_total', 'vendor_rating']][:]\ndataset2.rename(columns = {\"vendor_id\": \"id\"}, inplace = True)\n\n# Make derived variables 'all' with id and customer_id columns\ncols = ['customer_id', 'id']\ndataset2['all'] = dataset2[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n\ndataset2.head()","5d3b3b1d":"#The number of rows is dropped duplicate rows\nprint(dataset1.shape)\nprint(dataset2.shape)","ee586a30":"df1=pd.merge(dataset1,dataset2,on='all',how='inner')\ndf1.head()","b164e069":"df1.shape","b7c0a925":"#Change some columns name and drop the same column\ndf1.rename(columns = {\"customer_id_x\": \"customer_id\"}, inplace = True)\ndf1.rename(columns = {\"id_x\": \"vendor_id\"}, inplace = True)\ndf1.drop(['customer_id_y','id_y'],axis=1,inplace=True)","aaa08967":"# Choose some columns from dataset1(cleaned data)\ndf2=dataset1[['customer_id','id','vendor_tag_name']]\ndf2.rename(columns={'id':'vendor_id'},inplace=True)\ndf2.head()","89ca9b95":"cols=[ 'serving_distance', 'delivery_charge','item_count', 'grand_total', 'vendor_rating']\n\ndef null_check(x):\n # print(df1_train[x].value_counts())\n  null = np.count_nonzero(df1[x].isnull())\n  print(null)\n\n  return null\/df1.shape[0] \n\nfor i in cols:\n  print(i,'null ratio :', null_check(i))","05690dec":"#Drop language columns\ndf1.drop(['language'],axis=1,inplace=True)\n\n#Remove null of gender columns\ndf1 = df1[df1['gender'].notnull()].reset_index(drop=True)","730377a0":"#gender - > one-hot encoding (int)\nsex=pd.get_dummies(df1[\"gender\"], columns = ['gender'],prefix=\"sex\",drop_first=True)\n\ndf1=pd.concat([df1,sex],axis=1)\n\n#Drop the raw 'gender' column(char)\ndf1.drop(['gender'],axis=1,inplace=True)","3b7d318d":"df1.rename(columns={'vendor_rating': 'rating'}, inplace=True)","88cbe5c0":"print(df1.shape)\ndf1.head()","64ba9bd9":"df1_train_for_anal = df1[:]","bd74fdb5":"train_for=df1[:]","3afd55c0":"train_contents = train_for[['customer_id','vendor_id','OpeningTime','vendor_tag_name']]\ntrain_contents.head()","6f0357dd":"#Split 'Openingtime' column to 2 columns (open \/ close)\ntrain_contents['OpeningTime'].fillna('-',inplace=True) \n\ntime_split= train_contents.OpeningTime.str.split('-')\nopen=time_split.str.get(0)\nclose=time_split.str.get(1)\n\ntrain_contents['Open']=open\ntrain_contents['Close']=close\n\n# Fill the blank to null value\ntrain_contents['Open'].fillna('',inplace=True) \ntrain_contents['Close'].fillna('',inplace=True)\n\nprint(train_contents['Open'].unique())\nprint(train_contents['Close'].unique())","38a3dcb9":"def morning_func(x) :\n  if x == \"\" :\n    return None\n  else :\n    x1 = int(x[:2].replace(\":\", \"\").replace(\"a\", \"\"))\n    x2 = x[-2:]\n    if (x1>=7 and x1 <= 10) and x2 == (\"AM\" or \"am\"): \n      return 1\n    elif x1 <=10 and len(x) <= 2 :\n      return 1\n    else :\n      return 0\n\ndef afternoon_func(x) :\n  if x == \"\" :\n    return None\n  else :\n    x1 = int(x[:2].replace(\":\", \"\").replace(\"a\", \"\"))\n    x2 = x[-2:]\n    if x1 <= 1 and x2 == \"PM\": \n      return 1\n    elif x1 == 12 and x2 == \"PM\":\n      return 1\n    elif x2 == (\"AM\" or \"am\"):\n      return 1\n    elif x1 <=10 and len(x) <= 2 :\n      return 1\n    else :\n      return 0\n\ndef evening_func(x) :\n  if x == \"\" :\n    return None\n  else :\n    x1 = int(x[:2].replace(\":\",\"\"))\n    x2 = x[-2:]\n    if (x1 >= 6 and x2 == \"PM\") or x2 == (\"Am\" or \"am\") :\n      return 1\n    elif x1 >= 22 and len(x)<=2:\n      return 1      \n    else :\n      return 0\n\ntrain_contents[\"morning\"] = train_contents[\"Open\"].apply(morning_func)\ntrain_contents[\"afternoon\"] = train_contents[\"Open\"].apply(afternoon_func)\ntrain_contents[\"evening\"] = train_contents[\"Close\"].apply(evening_func)\n\ntrain_contents[:2]","0693eb2c":"#Check the null ratio of 'vendor_tag_name' \nnull = np.count_nonzero(train_contents['vendor_tag_name'].isnull())\nprint(null)\nprint(null\/train_contents.shape[0]) #1%\n\n#Remove the null value\ntrain_contents= train_contents[train_contents['vendor_tag_name'].notnull()].reset_index(drop=True)\nnull = np.count_nonzero(train_contents['vendor_tag_name'].isnull())\nprint(null)","54f01f47":"# Cleaning 'vendor_tag_name'\n\n#Change all of the chars to lower char  \ntrain_contents['vendor_tag_name']=train_contents['vendor_tag_name'].apply(lambda x:x.lower())\n\n# str -> list\ntrain_contents['vendor_tag']= train_contents['vendor_tag_name'].str.split(',')\ntrain_contents['vendor_tag'].head()","df091d15":"#If 'breakfast' is in the tag, then add the morning\ndef breakfast1(tag,x2):\n  if any('breakfast' in i for i in tag) and np.isnan(x2)==True :\n    return 1\n  # elif any('breakfast' in i for i in tag) and int(x2)==0 :  \n  #   return 1\n  else:\n    return x2\n\ntrain_contents['mor2']=train_contents.apply(lambda x:  breakfast1(x['vendor_tag'],x['morning']),axis=1) #\uc544\uce68 \uc810\uc2ec \uc800\ub141 \ub2e4 \ucd94\uac00 \n\n#afternoon 1 \/ remainders are not changed\nfor i in range(len(train_contents['afternoon'])):\n  if (np.isnan(train_contents['morning'][i])==True) and (train_contents['mor2'][i]==1.0) :\n    train_contents['afternoon'][i]=1\n  else:\n    pass\n\n#evening 0 \/ remainders are not changed\nfor i in range(len(train_contents['evening'])):\n  if (np.isnan(train_contents['morning'][i])==True) and (train_contents['mor2'][i]==1.0) :\n    train_contents['evening'][i]=0\n  else:\n    pass","da48b046":"# Check and remove the null value\nnull = np.count_nonzero(train_contents['mor2'].isnull())\nprint(null)\nprint(null\/train_contents.shape[0]) #0.4 % \n\ntrain_contents= train_contents[train_contents['mor2'].notnull()].reset_index(drop=True)\ntrain_contents.drop(['morning'],axis=1,inplace=True)\n\ntrain_contents.rename(columns={'mor2':'morning'},inplace=True)","3d824b7b":"train_contents[:3]","30e18894":"# Extract Required variable for CF\ncus_ven_ratings = df1_train_for_anal[['customer_id', 'vendor_id', 'rating']]\ncus_ven_ratings","6f5b0f84":"# Calculate mean rating by only valid ratings(except missing and rated zero)\nratings_not_none = []\n\nfor i in range(0, cus_ven_ratings.shape[0]-1) :\n  if pd.isnull(cus_ven_ratings.iloc[i][2]) == False and cus_ven_ratings.iloc[i][2] != 0 :\n    ratings_not_none.append(cus_ven_ratings.iloc[i][2])\n    \nvalid_rating_mean = np.mean(np.array(ratings_not_none))","99148662":"# Substitute missing and zero rating to mean by valid ratings\ndef rating_missing_func(x) :\n  if pd.isnull(x) == True :\n    return valid_rating_mean\n  elif x == 0 :\n    return valid_rating_mean\n  else :\n    return x\n\ncus_ven_ratings[\"rating2\"] = cus_ven_ratings[\"rating\"].apply(rating_missing_func)\ncus_ven_ratings","c152bc9b":"# Reorganization dataframe(rename colums)\ncus_ven_ratings = cus_ven_ratings[['customer_id', 'vendor_id', 'rating2']]\ncus_ven_ratings.rename(columns={'rating2':'rating', 1:'customer_id_num'}, inplace=True)\ncus_ven_ratings","f2f3e4d5":"# Integration into individual ratings by group mean\ncus_ven_ratings_mean = cus_ven_ratings.groupby(['customer_id', 'vendor_id']).mean()\ncus_ven_ratings_mean","205fd8ea":"df_cus_ven_ratings_mean = cus_ven_ratings_mean.reset_index()\ndf_cus_ven_ratings_mean","4309b570":"# Making Full Matrix(Sparse Matrix)\nrating_full_matrix = df_cus_ven_ratings_mean.pivot(index='customer_id', columns='vendor_id', values='rating')\nrating_full_matrix","3afceca4":"# Calculate Similarity all pair of customers from Full Matirx\nfrom sklearn.metrics.pairwise import cosine_similarity\nrating_matrix_dummy = rating_full_matrix.copy().fillna(0)\n\ncustomer_similarity = cosine_similarity(rating_matrix_dummy, rating_matrix_dummy)\n\ncustomer_similarity = pd.DataFrame(customer_similarity, index = rating_full_matrix.index, columns=rating_full_matrix.index)\ncustomer_similarity","a7ada4f0":"# Function which calculate accuracy(Root Mean Squared Error)\ndef RMSE(y_true, y_pred):\n    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))","55baf2c4":"# Function which apply RMSE to CF model\ndef knn_score(model, neigbor_size=0) :\n  id_pairs = zip(df_cus_ven_ratings_mean['customer_id'], df_cus_ven_ratings_mean['vendor_id'])\n  y_pred = np.array([model(customer, vendor, neigbor_size) for (customer, vendor) in id_pairs])\n  y_true = np.array(df_cus_ven_ratings_mean['rating'])\n  return RMSE(y_true, y_pred)","6850fd59":"# CF model(restrict number of neighbor size)\ndef cf_knn(customer_id, vendor_id, neighbor_size=0):\n    if vendor_id in rating_full_matrix:\n        # Similarity of inputted customer and other customer\n        sim_scores = customer_similarity[customer_id].copy()\n        # Ratings by all customers for inputted vendor(restaurant)\n        vendor_ratings = rating_full_matrix[vendor_id].copy()\n        # Index of customers who are not rate inputted vendor\n        none_rating_idx = vendor_ratings[vendor_ratings.isnull()].index\n        # Exception rating(null) which of customers who are not rate inputted vendor\n        vendor_ratings = vendor_ratings.drop(none_rating_idx)\n        # Exception similarity which of customers who are not rate inputted vendor\n        sim_scores = sim_scores.drop(none_rating_idx)\n   \n        # Case that neighbor size is not specified\n        if neighbor_size == 0:          \n            # Weighted mean of ratings by customers who rate inputted vendor\n            mean_rating = np.dot(sim_scores, vendor_ratings) \/ sim_scores.sum()\n\n        # Case that neighbor size is specified\n        else:                       \n            # Case that 2 or more people rate inputted vendor\n            if len(sim_scores) > 1: \n                # Minimum value among inputted neighbor size and number of customers who rate inputted vendor\n                neighbor_size = min(neighbor_size, len(sim_scores))\n                # transpose to Numpy array for using argsort\n                sim_scores = np.array(sim_scores)\n                vendor_ratings = np.array(vendor_ratings)\n                # Sorting similarity\n                customer_idx = np.argsort(sim_scores)\n                # Similarity as much as neighbor size\n                sim_scores = sim_scores[customer_idx][-neighbor_size:]\n                # Ratings as much as neighbor size\n                vendor_ratings = vendor_ratings[customer_idx][-neighbor_size:]\n                # Caculate final predicted ranting\n                mean_rating = np.dot(sim_scores, vendor_ratings) \/ sim_scores.sum()\n            else:\n                # Substitute to valid mean in other case\n                mean_rating = valid_rating_mean\n    else:\n        # Substitute to valid mean in other case\n        mean_rating = valid_rating_mean\n    return mean_rating \n","3246d701":"knn_score(cf_knn, neigbor_size=20)","f9e75018":"# Function which present recommendation list for certain customer by CF\ndef cf_recom_vendor(customer_id, n_items, neighbor_size=0):\n    # Vendors which rated by inputted customer\n    customer_vendor = rating_full_matrix.loc[customer_id].copy()\n    \n    for vendor in rating_full_matrix:\n        # Excepton vendors which already rated by inputted customer\n        if pd.notnull(customer_vendor.loc[vendor]):\n            customer_vendor.loc[vendor] = 0\n        # Calculate predicted rating about vendors which is not rated by inputted customer\n        else:\n            customer_vendor.loc[vendor] = cf_knn(customer_id, vendor, neighbor_size)\n    \n    # Sort vendors by predictted rating\n    vendor_sort = customer_vendor.sort_values(ascending=False)[:n_items]\n    recom_vendors_temp = df1_train_for_anal.loc[vendor_sort.index]\n    recom_vendors_temp2 = recom_vendors_temp[['vendor_id', 'mean_rating', 'vendor_tag_name']]\n    recom_vendors = recom_vendors_temp2.reset_index(drop=True)\n    return recom_vendors","b8e1cae3":"# Example of recommendation list\ncf_recom_vendor(customer_id='ZZV76GY', n_items=5, neighbor_size=30)","7b36b692":"# Extract Required variable for MF\nratings = cus_ven_ratings","2f84471c":"# Integration into individual ratings by group mean\nratings = ratings.groupby(['customer_id', 'vendor_id']).mean().reset_index()","47a66f8a":"# Make full matrix for temporary preprocessing\nR_temp = ratings.pivot(index='customer_id', columns='vendor_id', values='rating').fillna(0)\nR_temp","f4880045":"# Mapping customer IDs to index(continuous numeric rowname)\ncustomer_id_index = []\n\nfor i, one_id in enumerate(R_temp.T) :\n  customer_id_index.append([one_id, i])","39f5be1c":"df_customer_id_index = pd.DataFrame(customer_id_index)\ndf_customer_id_index.rename(columns={0:'customer_id', 1:'customer_idx'}, inplace=True)\ndf_customer_id_index","31b7cca7":"# Mapping vendor IDs to index(continuous numeric columname)\nvendor_id_index = []\n\nfor i, one_id in enumerate(R_temp) :\n  vendor_id_index.append([one_id, i])","c6c54a77":"df_vendor_id_index = pd.DataFrame(vendor_id_index)\ndf_vendor_id_index.rename(columns={0:'vendor_id', 1:'vendor_idx'}, inplace=True)\ndf_vendor_id_index","02c711b1":"# Merge rating and each index\nratings_with_index = pd.merge(ratings, df_customer_id_index, on='customer_id')\nratings_with_index = pd.merge(ratings_with_index, df_vendor_id_index, on='vendor_id')\nratings = ratings_with_index[['customer_idx', 'vendor_idx', 'rating']].astype(int)\nratings.rename(columns={'customer_id_num':'customer_idx', 'vendor_id_num':'vendor_idx', 'rating':'rating'}, inplace=True)\nratings","4b380dba":"# Making Full Matrix(Sparse Matrix)\nrating_full_matrix_by_index_with_nan = ratings.pivot(index='customer_idx', columns='vendor_idx', values='rating')\nrating_full_matrix_by_index_with_nan","8abdba5b":"# Tranpose None to Zero\nrating_full_matrix_by_index = ratings.pivot(index='customer_idx', columns='vendor_idx', values='rating').fillna(0)\nrating_full_matrix_by_index","c6102f1f":"# Number of latent factors\nK = 100                    \n# Total mean\nmu = ratings.rating.mean()\n# Number of customers\nM = ratings.customer_idx.unique().shape[0]       \n# Number of vendors\nN = ratings.vendor_idx.unique().shape[0]      \n\n# Function of calculating RMSE\ndef RMSE(y_true, y_pred):\n    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n\n# Embedding for Keras model\ncustomer = Input(shape=(1, ))                                              \nvendor = Input(shape=(1, ))                                               \nP_embedding = Embedding(M, K, embeddings_regularizer=l2())(customer)      \nQ_embedding = Embedding(N, K, embeddings_regularizer=l2())(vendor)        \ncustomer_bias = Embedding(M, 1, embeddings_regularizer=l2())(customer)    \nvendor_bias = Embedding(N, 1, embeddings_regularizer=l2())(vendor)        \n\n# Layers\nfrom tensorflow.keras.layers import Dense, Concatenate, Activation\nP_embedding = Flatten()(P_embedding)                                   \nQ_embedding = Flatten()(Q_embedding)                                   \ncustomer_bias = Flatten()(customer_bias)                               \nvendor_bias = Flatten()(vendor_bias)                                   \nR = Concatenate()([P_embedding, Q_embedding, customer_bias, vendor_bias])\n\n# Neural network for Deep Learning\nR = Dense(2048)(R)\nR = Activation('linear')(R)\nR = Dense(256)(R)\nR = Activation('linear')(R)\nR = Dense(1)(R)\n\n# Model compile\nmodel = Model(inputs=[customer, vendor], outputs=R)\nmodel.compile(\n  loss=RMSE,\n  optimizer=Adamax(),\n  metrics=[RMSE]\n)\nmodel.summary()","432ed54d":"# Model fitting\nresult = model.fit(\n  x=[ratings.customer_idx.values, ratings.vendor_idx.values],\n  y=ratings.rating.values - mu,\n  epochs=10,\n  batch_size=512,\n  validation_data=(\n    [ratings.customer_idx.values, ratings.vendor_idx.values],\n    ratings.rating.values - mu\n  )\n)","598fef3b":"# Plot of RMSE\nimport matplotlib.pyplot as plt\nplt.plot(result.history['RMSE'], label=\"RMSE\")\nplt.xlabel('epoch')\nplt.ylabel('RMSE')\nplt.legend()\nplt.show()","df03c6cd":"# Comparision of Actual - Predicted rating\ncustomer_ids = ratings.customer_idx.values[0:6]\nvendor_ids = ratings.vendor_idx.values[0:6]\npredictions = model.predict([customer_ids, vendor_ids]) + mu\nprint(\"Actuals: \\n\", ratings[0:6])\nprint()\nprint(\"Predictions: \\n\", predictions)","a3f127c7":"def recom_vendor(customer_idx, n_items):\n    # Vendors which rated by inputted customer\n    customer_vendor = rating_full_matrix_by_index_with_nan.loc[customer_idx].copy()\n    \n    for vendor in rating_full_matrix_by_index_with_nan:\n        # Excepton vendors which already rated by inputted customer\n        if pd.notnull(customer_vendor.loc[vendor]):\n            customer_vendor.loc[vendor] = 0\n        # Calculate predicted rating about vendors which is not rated by inputted customer\n        else:\n            customer_vendor.loc[vendor] = round(min(model.predict([np.array([customer_idx]), np.array([vendor])])[0][0] + mu, 5), 3)\n    \n    # Sort vendors by predictted rating\n    vendor_sort = customer_vendor.sort_values(ascending=False)[:n_items]   \n    df_vendor_sort = pd.DataFrame(vendor_sort)    \n    df_vendor_sort.rename(columns={'vendor_idx':'vendor_idx', customer_idx:'predicted_rating'}, inplace=True)\n\n    return df_vendor_sort","b79a166c":"# Remapping customer IDs and customer index\ncustomer_id_idx = ratings_with_index[['customer_id', 'customer_idx']]\ncustomer_id_idx = customer_id_idx.drop_duplicates()","7ef361cd":"# Remapping vendor IDs and vendor index\nvendor_id_idx = ratings_with_index[['vendor_id', 'vendor_idx']]\nvendor_id_idx = vendor_id_idx.drop_duplicates()","2f75b6d7":"# Preparing dataframe for extracting vendor tag\nmf_df1 = df1_train_for_anal[['vendor_id', 'mean_rating', 'vendor_tag_name']]\nmf_df1 = mf_df1.drop_duplicates()","109ec172":"# Function which present recommendation list for certain customer by MF with DL\ndef mf_dl_recom_vendor_list(customer_id, n_items) :\n  df_specified_customer = customer_id_idx[customer_id_idx['customer_id']== customer_id]\n  specified_customer_idx = df_specified_customer.iloc[0][1]\n  mf_recom_list_temp = recom_vendor(customer_idx = specified_customer_idx, n_items = n_items)\n  mf_recom_list_temp2 = pd.merge(mf_recom_list_temp, vendor_id_idx, how='inner', on='vendor_idx')\n  mf_recom_list_temp3 = mf_recom_list_temp2[['vendor_id', 'predicted_rating']]\n  \n  mf_recom_list = pd.merge(mf_recom_list_temp3, mf_df1, how='inner', on='vendor_id')\n\n  return mf_recom_list","62663391":"# Example of recommendation list\nmf_dl_recom_vendor_list(customer_id = 'ZZV76GY', n_items = 5)","a3893e6f":"df1_contents_for_anal=train_contents[:]","b8e171e3":"df1_contents_for_anal.head()","c7bb645c":"df1_contents_for_anal['vendor_tag']= df1_contents_for_anal['vendor_tag_name'].str.split(',')\n\n#strip\ndf1_contents_for_anal['vendor_tag']=df1_contents_for_anal['vendor_tag'].apply(lambda x:[str.lower(i.replace(\" \",\"\"))for i in x])","6d3e0e50":"#Check similar word\ndef similar(a, b):\n    ratio=SequenceMatcher(None, a, b).ratio()\n    return print(\"Similarity of {} and {}  : {}\".format(a,b,ratio) )\n\nsimilar('pasta','pastas')\nsimilar('pasta','pastry')\nsimilar('pizza','pizzas')\nsimilar('soups','shuwa')\nsimilar('shawarma','shuwa')\nsimilar('thali','thai')\nsimilar('milkshakes','mishkak')\n\n#change the word when similarity is over than 0.8 \ndf1_contents_for_anal['vendor_tag']=df1_contents_for_anal['vendor_tag'].apply(lambda x:[ i.replace(\"pastas\",\"pasta\")for i in x])\ndf1_contents_for_anal['vendor_tag']=df1_contents_for_anal['vendor_tag'].apply(lambda x:[ i.replace(\"pizzas\",\"pizza\")for i in x])\ndf1_contents_for_anal['vendor_tag']=df1_contents_for_anal['vendor_tag'].apply(lambda x:[ i.replace(\"thali\",\"thai\")for i in x])\n\ndf1_contents_for_anal['vendor_tag1']=df1_contents_for_anal['vendor_tag'].apply(lambda x:' '.join(x))","83902b2f":"df1_contents_for_anal.head()","5c0f0f46":"df1_contents_for_anal['vendor_id'].value_counts()","f92edb5f":"prac= df1_contents_for_anal.drop_duplicates(\"vendor_id\", keep=\"first\", inplace=False)\nprint(prac.shape)\n\nprac['vendor_id']=prac['vendor_id'].astype(str)\nprac1=prac[:]","e578c8f0":"prac.set_index('vendor_id',inplace=True)\nprac.head(2)","e9dc605a":"vectorizer = TfidfVectorizer()\ncount_matrix = vectorizer.fit_transform(prac['vendor_tag1'])\nprint(vectorizer.get_feature_names())\nprint(vectorizer.vocabulary_)","bd48e1ec":"indices = pd.Series(prac.index)\nindices[:5]","7d9cc984":"count_matrix","11bd9d8e":"cosine_sim = cosine_similarity(count_matrix,count_matrix)\nprint(cosine_sim)","07d8d1c2":"indices[indices == '113'].index[0]","0e2b79f9":"list(enumerate(cosine_sim[0]))","b543b6a6":"prac=prac.reset_index()\n\ndef get_recommendations(id, cosine_sim=cosine_sim):\n    indices = pd.Series(prac.index, index = prac['vendor_id']).drop_duplicates() \n    # get index from vendor_id\n    idx = indices[id]\n\n    # cosin_similarity\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # most similar vendor_id (10)\n    sim_scores = sim_scores[1:11]\n\n    return sim_scores","1cb82cf8":"get_recommendations('113')","6adf68d7":"cols=['afternoon','evening','morning']\n\nprac['time']='' # to create an empty column\nfor col_name in cols:\n    prac.loc[prac[col_name]==1,'time']= prac['time']+' '+col_name\n\nprac=prac[['vendor_id'\t,'customer_id',\t'vendor_tag','vendor_tag1','time']]\nprac.head()","699370da":"#'time' column : str -> list\nprac['time']=prac['time'].str.split(' ')\n\ndef remove_blank(lists):\n  return [key for key in lists if key !='']\n\nprac['time']=prac['time'].apply(lambda x:remove_blank(x))\nprac['time'][0]","2ce2c399":"# combine 'vendor_tag' with 'time' (str for w2v)\nprac['time1']=prac['time'].apply(lambda x:' '.join(x))\nprac['time_tag']=prac[['vendor_tag1','time1']].apply(lambda x: ' '.join(x),axis=1)\n\nprac=prac[['vendor_id','customer_id','time_tag','vendor_tag','vendor_tag1']]\nprac.head(2)\nprac2=prac[:]","b8f8138c":"vectorizer = TfidfVectorizer()\ncount_matrix = vectorizer.fit_transform(prac['time_tag'])\nprint(vectorizer.get_feature_names())\nprint(vectorizer.vocabulary_)","425ca4b0":"prac.set_index('vendor_id',inplace=True)\n\nindices = pd.Series(prac.index)\ncosine_sim = cosine_similarity(count_matrix,count_matrix)\ncosine_sim.shape","1aafa77f":"prac=prac.reset_index()\n\ndef item_recommendations(id, cosine_sim=cosine_sim):\n    indices = pd.Series(prac.index, index = prac['vendor_id']).drop_duplicates() \n    idx = indices[id]\n\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n\n    return sim_scores","80353369":"item_recommendations('113')","3892952a":"prac1.head(2)","a0651b4b":"prac1.set_index('vendor_id',inplace=True)\n#Embedding the word using word2vec\ncorpus=prac1['vendor_tag']\nmodel = Word2Vec(size=4, window=1, min_count=1, workers=4)\nmodel.build_vocab(corpus)\n\nword_vectors = model.wv\nvocabs = word_vectors.vocab.keys()\nvocabs","50cb3e6b":"word_vectors.most_similar('breakfast')","4060305f":"# Mean of word vector\ndef vectors(document_list):\n    document_embedding_list = []\n\n    for line in document_list:\n        doc2vec = None\n        count = 0\n        for word in line.split():\n            if word in model.wv.vocab:\n                count += 1\n                if doc2vec is None:\n                    doc2vec = model[word]\n                else:\n                    doc2vec = doc2vec + model[word]\n\n        if doc2vec is not None:\n            doc2vec = doc2vec \/ count\n            document_embedding_list.append(doc2vec)\n    return document_embedding_list\n\ndocument_embedding_list = vectors(prac1['vendor_tag1'])\nprint('Number of document vector:',len(document_embedding_list))","bd0e2d5f":"cosine_sim = cosine_similarity(document_embedding_list, document_embedding_list)\n\nprint('the shape of cosine similarity matrix :',cosine_sim.shape)","f21c9161":"prac1=prac1.reset_index()\ndef get_recommendations_w2v(id, cosine_sim=cosine_sim):\n    indices = pd.Series(prac1.index, index = prac1['vendor_id']).drop_duplicates() \n\n    idx = indices[id]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    sim_scores = sim_scores[1:11]\n\n    return sim_scores","e33ca0ea":"get_recommendations_w2v('113')","072c0516":"prac1.head()","084f12d3":"prac2['time_tag_list']= prac2['time_tag'].str.split(' ')\n\n#word2vec\uc744 \uc774\uc6a9\ud574 \ub2e8\uc5b4 \uc784\ubca0\ub529\ncorpus=prac2['time_tag_list']\n\nmodel = Word2Vec(size=4, window=1, min_count=1, workers=4)\nmodel.build_vocab(corpus)\n\nword_vectors = model.wv\nvocabs = word_vectors.vocab.keys()\nvocabs","14747e3e":"word_vectors.most_similar('breakfast')","1b3aa9cc":"def vectors(document_list):\n    document_embedding_list = []\n\n    for line in document_list:\n        doc2vec = None\n        count = 0\n        for word in line.split():\n            if word in model.wv.vocab:\n                count += 1\n                if doc2vec is None:\n                    doc2vec = model[word]\n                else:\n                    doc2vec = doc2vec + model[word]\n\n        if doc2vec is not None:\n            doc2vec = doc2vec \/ count\n            document_embedding_list.append(doc2vec)\n    return document_embedding_list\n\ndocument_embedding_list = vectors(prac2['time_tag'])\nprint('the number of document vector:',len(document_embedding_list))\n\ncosine_sim = cosine_similarity(document_embedding_list, document_embedding_list)\nprint('the shape of cosine similarity matrix :',cosine_sim.shape)\n\nindices = pd.Series(prac.index, index=prac2['vendor_id']).drop_duplicates()\n\ndef get_recommendations_w2v_time(id, cosine_sim=cosine_sim):\n    indices = pd.Series(prac.index, index = prac2['vendor_id']).drop_duplicates() \n\n    idx = indices[id]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n\n    return sim_scores","abd63157":"get_recommendations_w2v_time('113')","2055ec9d":"If the 'breakfast' is in the vendor_tag_name and the morning value is null(blank), fill the morning and afternoon values to 1","e67b1903":"Vendor_rating's distribution is quite crowded between 4.2 and 4.5","a2d595d8":"### \u2163. 2. (1) Making Full Matrix with index\nFor MF with DL, it is needed that Full Matrix composed with continuous numeric column name and row name.","3bfb5629":"Preprocessing the 'OpeningTime' column","9e53fccc":"# \u2163. Rating Based Model(Algorithm)","6062d79e":"# \u2164. Contents Based Recommendation System\n","2f8a07a7":"The vendor id '113' is most similar with '36' (cosine similarity is about 0.71)","126b9e57":"First, look over the initial datasets, and simply visualize the data  ","a3c9350f":"### \u2163. 2. (2) Build MF(with DL) Model","b189b186":"# \u2161. EDA","06ad4c0f":"Modify 'gender' column","b29f89b3":"# \u2163. 2. Matrix Factorization with DeepLearning(MF with DL)","14d4daad":"### \u2162.2.(1) For contents based","c10c51cf":"# \u2160. Preface\n## \u2160. 1. Backgrounds\n Nowadays, there are a lot of goods and those are saled in various channel. Especially sales in the online platform grows rapidly. So many companies have built their own website and mobile application for sale. <br>\n But in the point of view by customers, there are too many goods and services. So paradoxically, customers have to make an effort more when choosing what they want. If customers feel fatigue, they will leave. Besides, if the website or application is the new one, customers feel strange too. <br>\n<br>\n Recommendation system receive attention as solution for the problem. From the past, Amazon has recommended books for each customes. And recently Youtube and Netflix recommend video which fit for each customers. As a result, customers need not meet the trouble with facing too lot of alternatives and finding what they want. It is possible by using big data and analyzing that.<br>\n<br>\n With this background, we have built recommendation system for delivery appllication. Because of increasing single-person household and seeking convenience by people, delivery application expands rapidly in many countries. Especially state of COVID-19, with necessity for avoiding contact with other people, it becames more important. And If there is a recommendation function in delivery application, customers should order delivery service more easily. <br>\n\n## \u2160. 2. Two main directions\n### \u2160. 2. (1) Analysis by Quantitative Feedback(ratings)\n The first is based on rating by customers. Almost websites or applications have feedback system by customers after using goods or services. Customers give score according to their satisfaction. And company can use these information. <br>\n By **Collaborative Filtering(CF)**, the algorithm find other customer which show similar rating patern to certain customer. If goods or services which is bought by the similar customer has not bought yet, the algorithm recommend the goods for customer. It was basic logic in early era of recommedation system. In fact, nowadays it is not used mainly. <br>\n And **Matrix Fartorization(MF)** is method which find latent factor. By decomposing Matrix which contian information about customer and item to user latent matrix and item latent matrix, the algorithm predict rating matrix. That is, it also predicts rating for expected customer. But using all information is the different point to Collaborative Filtering, so its predition power is more strong. Especially, this model can be built with **Deep Learing(DL)**. With multi-layer analysis, accuracy of model can be increased. You can see it later.<br>\n<br>\n The data \"restaurant-recommendation-challenge\" which is offered, contain information of ratings by customers to vendors. We have anlayzed this by above algorithm(CF, MF with DL), which is described later in part \u2163. <br>\n\n### \u2160. 2. (2) Analysis by Contents\n The other approach is by features, called based on 'contents'. In other words, the algorithm finds items which have similar characteristics. <br>\n By calculating **Term Frequency - Inverse Document Frequency(TF-IDF)**, Similarity, like Cosine Similarity, can be obtained. TF means a value that how often certain words appear in a document. TF-IDF is multiply of TF and IDF. If this score is high, the word means that it appears often in this document not the other documents. **Cosine similarity** is a measure of similarity between two non-zero vectors of an inner product space. \nWhen a customer has bought a certain item, the company should recommend a similar item to the customer. And in this process, frequency of each word is calculated while excluding words which have low influence. <br>\n **Doc2Vec(Document Embedding with Paragraph Vectors)** is an extended algorithm in Word2Vec which predicts word by sequential paragraph analysis. The paragraph vector is the vector of the existing word vector (considering the words within the window size) plus the paragraph matrix.\nBy transposing documents to documents vector(embedding) and calculating Similarity between Documents, this algorithm recommends similar items. <br>\n<br>\n In the data \"restaurant-recommendation-challenge\", We select two features as contents. One is 'tag(name)' which has ten fetures which describe each vendor, the other is an opening time which can describe the restaurant's target time slot. These 'contents' are analyzed by the above algorithm. That is, we consider these contents as one document, and apply a method to analyze the document. You can see it at part \u2164.\n","f81df7d4":"The dataset has 73 columns and 5802400 rows :\n\nSo we just look over about 8-10 columns\n\n\n*   gender : Customer's sex \n*   location type : Customer orders from one or more locations\n*   language : Chose language\n*   Opening Time : Vendr's operating time\n*   city_id : City's id\n*   vendor_rating : The vendor's average rating score \n\n\n","20149b85":"Join dataset1 and dataset2","c92765b1":"The vendor id '113' is most similar with '36' (cosine similarity is about 0.76)\nSo, we can see the cosine similarity is imporved a little bit","a116e526":"As you know, model performance is best at the Doc2Vec with time tag according to the cosine similarity. <br>\nDoc2Vec with time tag > Doc2Vec > Tf-Idf with time tag > Tf-Idf<br>\nIn this order, the model performance is good in contents based recommendation system.","1b87256c":"And, I'll look over the other datasets about order information","9c35e174":"### \u2161.1. (1) train_full Datasets","7640f739":"The words are that similar word with 'breakfast'","23badfcd":"Make new columns 'morning, afternoon, evening' based open and close time","77517d58":"# V. 2. Doc2Vec model\n### V. 2. (1). Word2Vec for Doc2Vec","b01748ae":"# \u2163. 1. Collaborative Filtering(CF)","17214b6b":"The ratings except 0 score are almost 5 score","1398843c":"### V. 2. (2). Doc2Vec","def02e04":"# \u2165. Conclusion\n## \u2165. 1. Expected effects\n### \u2165. 1. (1) to Delivery Application\n Nowadays, there are many delivery applications. And some of them show restaurant lists which fit each user. For their main business model is to get fee from customers and vendors, more transactions means more revenue. So it is important to attract customers using recommendation lists.<br>\n<br>\n### \u2165. 1. (2) to Customers\n When customers access the list, it is easy to choose to eat and to order that. It means decrease of bounce rate. Users will not just see and exit the application anymore.<br>\n<br>\n### \u2165. 1. (3) to Vendors\n And to restaurants, the system makes them get better feedback not only quantitative but also qualitative. Moreover, it can be an accelerator to secure regular customers. <br>\n\n\n## \u2165. 2. Expendability\n### \u2165. 2. (1) Combination of two directions\n Rating based models recommend restaurants by using information of each customer, rather than contents based models using information of each item(vendors). So, the company can show lists by rating based model when user runs the application. And if customers select certain items(or add to cart), lists of similar items by contents based model can be effective.\n\n\n### \u2165. 2. (2) Limitations of analysis\n For more accurate analysis, the model can have more various variables as a feature. For example, the situation of order should affect the selection of restaurants. Order at home and office should be different. And location of customers and vendors is also an important factor. If the function is included, the problem of cold start cases is solved. However, our models exclude that because of imperfection of data.\n","d7c05c09":"### \u2163. 1. (1) Making Full Matrix","c2436622":"### \u2163. 1. (3) Recommenadation for Customer by CF","a50052b0":"We can check the number of rows is decreased by join the datsets","d1106568":"### \u2163. 1. (2) Build CF Model","1addd132":"# V. 1. TF - IDF model\n### V.1.(1). TF - IDF base model","135c0b9d":"### V. 2. (3). Doc2Vec with time tag","1b00de9a":"The dataset has 26 columns and 135303 rows :\n\nJust simply explain some columns\n\n\n*   akeed_order_id : Unique customer ID, used in train_locations and train_orders\n*   vendor_rating : The ratings are rated by customers who use the vendor\n*   vendor_id : vendor's unique id\n*   customer_id : customer's unique id","69d5cb30":"### \u2161.1. (2) orders Datasets","23ce464b":"### \u2163. 2. (3) Recommenadation for Customer by MF","0bbd8f44":"## \u2162.2. Data Cleaning","98162c7a":"### V.1.(2) Adding time tag (morning\/afternoon\/evening)","2917b8bf":"# \u2162. Preprocessing","03ca5b0e":"## \u2162.1. Datasets Join\n### \u2162.1.(1) For collaborative filtering","abdb9b78":"### \u2162.1.(2) For contents based"}}