{"cell_type":{"87f90ec2":"code","d7f25d6f":"code","3f7d4880":"code","826cb00d":"code","742d7fd5":"code","c37aeed0":"code","61324489":"code","c3d39fc9":"code","ce082c97":"code","082c919a":"code","c9377336":"code","38cc4647":"code","045edd63":"code","44f00acc":"code","c1c4d6d2":"code","c985c93f":"code","52bca832":"code","0303a7ba":"code","153b3fb4":"markdown","70c35520":"markdown","48a23866":"markdown","27172ade":"markdown","d023e48c":"markdown","ffcc563a":"markdown","8bf9b9ec":"markdown","3b23673a":"markdown","60019c04":"markdown","25806d07":"markdown","5c26e8b8":"markdown","31b7767a":"markdown","ed44b987":"markdown","e8e41120":"markdown"},"source":{"87f90ec2":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\n\nos.listdir('..\/input\/fruits-360_dataset\/fruits-360\/Training')[0:10]","d7f25d6f":"path = '..\/input\/fruits-360_dataset\/fruits-360\/Training\/Clementine\/206_100.jpg'\n\nim = cv2.imread(path)\nplt.imshow(im)","3f7d4880":"b,g,r = cv2.split(im)\n\nim2 = cv2.merge([r,g,b])\n\nplt.imshow(im2)","826cb00d":"grayim = cv2.cvtColor(im2,cv2.COLOR_RGB2GRAY)\n\nplt.imshow(grayim,cmap = 'gray')","742d7fd5":"grayim","c37aeed0":"grayim.shape","61324489":"grayim = grayim.astype('float')\/255\ngrayim","c3d39fc9":"grayim = grayim.flatten()\ngrayim = pd.Series(grayim)\ngrayim","ce082c97":"path = '..\/input\/fruits-360_dataset\/fruits-360\/Training\/'\n\ncols = np.arange(grayim.shape[0])\ndf = pd.DataFrame(columns = cols)\nlabelcol = []\n\nfruitlist = os.listdir(path)\nx = 0\n\nfor f in fruitlist[0:9] : \n    fruitpath = '%s%s' % (path,f)\n    \n    imagelist = os.listdir(fruitpath)\n    \n    for i in imagelist:\n        imagepath = '%s\/%s' % (fruitpath,i)\n    \n        image = cv2.imread(imagepath)\n    \n        b,g,r = cv2.split(image)\n        image = cv2.merge([r,g,b])\n    \n        imagegray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n    \n        imagegray = imagegray.astype('float')\/255\n    \n        imagegray = imagegray.flatten()\n    \n        df.loc[x] = imagegray\n    \n        x = df.shape[0] + 1\n        labelcol.append(f)\n    ","082c919a":"df['label'] = labelcol\ndf","c9377336":"df['label'].value_counts(normalize = True)","38cc4647":"df = shuffle(df).reset_index(drop = True)\ndf","045edd63":"# transpose data set and shuffle\ndf_t = shuffle(df.transpose())\n# transpose back to normal\ndf = df_t.transpose()","44f00acc":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\n# Create X and Y variables\nX = df.drop('label',axis = 1)\ny = df['label']\n\n# create our test and training set\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0,stratify = y)\n","c1c4d6d2":"from sklearn.svm import SVC\n\nsvm_model = SVC().fit(X_train,y_train)\n\ntrainscore = svm_model.score(X_train,y_train)\ntestscore = svm_model.score(X_test,y_test)\n\ny_pred = svm_model.predict(X_test)","c985c93f":"print(\"CLASSIFICATION REPORT FOR SVM\")\nprint(\"Confusion MAtrix:\")\nprint(confusion_matrix(y_test,y_pred))\nprint()\nprint(classification_report(y_test,y_pred))\nprint(\"train score:\",trainscore)\nprint(\"test_score\",testscore)","52bca832":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(C=2).fit(X_train,y_train)\n\ntrain = lr.score(X_train,y_train)\ntest = lr.score(X_test,y_test)\n\ny_pred_lr = lr.predict(X_test)\n\n# print('Training score: {:.3f}\\nTest Score: {:.3f}'.format(train,test))","0303a7ba":"print(\"CLASSIFICATION REPORT FOR LOGISTIC REGRESSION\")\nprint(\"Confusion MAtrix : \")\nprint(confusion_matrix(y_test,y_pred_lr))\nprint()\nprint(classification_report(y_test,y_pred_lr))\nprint(\"train score:\",train)\nprint(\"test_score\",test)","153b3fb4":"At first to me, it seemed strange this fruit was blue as it is supposed to be a clementine! I then realised that cv2 reads images as Blue Green Red, when they actually need to be in the form Red Green Blue to plot them. Hence, we can rearrange this order and plot again.","70c35520":"#### Model 1 - SVM\n\nLet's fit our model, using the default settings for SVM. We can print out both the training and test scores. ","48a23866":"I now have a dataframe with each row representing a single fruit image, and the 10K columns holding the values of each pixel in the image. We have also added on a column of labels, indicating what fruit is shown in the image. ","27172ade":"In the training folder, there is a folder for each fruit, containing images of that fruit. \n\nWe can read in one of these images to take a look, using cv2.","d023e48c":"\n## Intro\n\nThe fruits 360 dataset on Kaggle contains many images of fruit. I wanted to see if I could use Python to read in these images and build an algorithm to correctly label the fruit in each image. I have previously created a similar kernel on the MNIST fashion dataset, but this had already processed the images into dataframes for modelling. I wanted to see if instead I could use the actual images and run this processing myself.\n\nWhilst researching this task, I struggled to find a kernal\/tutorial which outlined this whole process. Hence I hope the below will act as a tutorial for anyone else wanting to learn how to do this. \n\n## Outline of process\n\n#### 1. Image processing\n\n- Like any machine learning model, I need features (X variables) and a label to predict (Y variable). With image classification, the same concept applies. However, here, the features are each pixel in the image. The images I am going to read in are 100x100 pixels. Hence, there are 10,000 pixels in every image; each of these pixels will be a feature in my model. Our first step therefore is to read in each image, capturing the value of every pixel as our 10,000 X variables, and recording the image's label for our Y variable. If we do this for each image, we have created our dataset. \n\n- However, colour images like the fruit data aren't stored as a single 100X100 array. They are actually stored as three arrays; one for the value of Red, Blue and Green in the image. Hence, another stage in our processing of these images involves transforming the images from colour to grayscale. By doing this, we can get a single value for each pixel, which indicates how black\/white this pixel is. We can store this as a value between 0 and 1. \n\n#### 2. Machine learning\n- Once we have transformed our images into grayscale and created our dataframe of 10,000 X variables with Y labels, we can begin our machine learning element. I will split my dataframe into a training and test set, building my algorithm on the training set, before seeing how well it performs on the test set. This enables me to understand how well my model will perform on images of fruit it has not seen before.\n\n\n### 1. Image processing - reading in images\n\nFirstly, I load in the libraries I will need, and take a look at the folder structure. The fruit 360 dataset contains pre defined training and test splits, divided into two folders. Instead of using these, I am going to read in fruit images from the training folders, and create my own train\/test splits later.","ffcc563a":"Let's see what types of fruit we have and what proportion they make up in our dataset.","8bf9b9ec":"Much more like a clementine! I can now change this image to grayscale.","3b23673a":"So how is this image stored in terms of data? Essentially each pixel in this grayscale image is a data point, with the value indicating how black or white the pixel is. The image is 100x100 pixels and hence we have 10,000 data points per image. We can take a look at this. ","60019c04":"So we can now flatten our 100x100 array into a single series of 10,000 datapoints.","25806d07":"I should also shuffle the columns in case there is any pattern here also. ","5c26e8b8":"255 indicates a fully white pixel. We can normalise the pixel values so we get values between 0 and 1, with 1 being a fully white pixel and 0 being a black pixel.","31b7767a":"The classes are not that well balanced, which could affect my model's performance. However, as this is a tutorial on image processing I am going to leave them as they are for now, but I could do some work to improve this balance if I wanted to build on this kernel later. \n\nAt the moment, my dataset is ordered by fruit type (due to how I created the dataset in the loop). Before moving onto the learning algorithm, we should shuffle our dataset. In the modelling part of the kernel, I am going to be dividing my data up into a training and test set, and hence want to shuffle the data before doing this in case this ordering impacts the divide. ","ed44b987":"Each of these pixels is going to be a feature in our dataset. Hence we need to repeat this process for all the images to build our dataset of X variables, and record the fruit label for our Y variable.\n \nTo do this, I am going to write a loop which reads into each fruit folder, extracting each image in turn and running through the above process. I will then also create a label vector indicating what fruit is in the image. I am doing this as a tutorial, so I am just going to go through this process for the first ten fruits in the folder to speed up running time. ","e8e41120":"### 2. Modelling\n\nWe can now train a model to see if we can label images of fruit. \n\n- The first step is to split the dataframe into training and test sets, so we can build the model on the training data, and then test how well it performs on new data (test set). \n- The next step will be to fit the model. There are a number of models which could be used here, but I am going to use Kernalised Support Vectors and Random Forests, comparing their performance. \n\nFirst of all, let's split the data into X and Y variables and create the training and test sets, as we will need this for both models."}}