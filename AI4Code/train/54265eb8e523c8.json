{"cell_type":{"db5d1ed2":"code","c264dca1":"code","29659af4":"code","5c0b62c4":"code","73bbe76f":"code","cbc877ed":"code","0d3ba6d4":"code","08ee08c4":"code","88d8d3db":"code","73057c6f":"code","ca0348f5":"code","9149db16":"code","f3787b77":"code","37bcdeaa":"code","041b4f77":"code","ce585db1":"code","7cb75cc9":"code","d42809b8":"code","3ee2b454":"code","01960bc2":"code","a9da6389":"code","1235f9dc":"code","22802704":"code","33242253":"markdown","d9f69959":"markdown","f10863de":"markdown","13c2c8d3":"markdown","8411ab78":"markdown","ba672b23":"markdown","9027a789":"markdown","c5ede2fd":"markdown","434f85f5":"markdown","157140aa":"markdown","c39cb8c7":"markdown","f0cf5ba7":"markdown","d4157185":"markdown","71d6e6d0":"markdown"},"source":{"db5d1ed2":"import warnings\nwarnings.filterwarnings('ignore')\n\n#the basics\nimport pandas as pd, numpy as np\nimport math, json, gc, random, os, sys\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\n#tensorflow deep learning basics\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\n\n#for model evaluation\nfrom sklearn.model_selection import train_test_split, KFold","c264dca1":"#get comp data\ntrain = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsample_sub = pd.read_csv('\/kaggle\/input\/stanford-covid-vaccine\/sample_submission.csv')","29659af4":"#target columns\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","5c0b62c4":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","73bbe76f":"def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","cbc877ed":"train_inputs = preprocess_inputs(train[train.signal_to_noise > 1])\ntrain_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))","0d3ba6d4":"def gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef build_model(gru=1,seq_len=107, pred_len=68, dropout=0.5,\n                embed_dim=75, hidden_dim=128):\n    \n    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n\n    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n    \n    if gru==1:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==0:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==3:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==4:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n    \n    #only making predictions on the first part of each sequence\n    truncated = hidden[:, :pred_len]\n    \n    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    #some optimizers\n    adam = tf.optimizers.Adam()\n    radam = tfa.optimizers.RectifiedAdam()\n    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n    ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n    \n    model.compile(optimizer = adam, loss='mse')\n    \n    return model","08ee08c4":"train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels,\n                                                                     test_size=.1, random_state=34)","88d8d3db":"if tf.config.list_physical_devices('GPU') is not None:\n    print('Training on GPU')","73057c6f":"lr_callback = tf.keras.callbacks.ReduceLROnPlateau()","ca0348f5":"gru = build_model(gru=1)\nsv_gru = tf.keras.callbacks.ModelCheckpoint('model_gru.h5')\n\nhistory_gru = gru.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=150,\n    callbacks=[lr_callback,sv_gru],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_gru.history['loss'])}, min validation loss={min(history_gru.history['val_loss'])}\")","9149db16":"lstm = build_model(gru=0)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_lstm.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=150,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","f3787b77":"lstm = build_model(gru=3)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb1.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=150,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","37bcdeaa":"lstm = build_model(gru=4)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb2.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=150,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","041b4f77":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)","ce585db1":"#build all models\ngru_short = build_model(gru=1, seq_len=107, pred_len=107)\ngru_long = build_model(gru=1, seq_len=130, pred_len=130)\nlstm_short = build_model(gru=0, seq_len=107, pred_len=107)\nlstm_long = build_model(gru=0, seq_len=130, pred_len=130)\nhyb1_short = build_model(gru=3, seq_len=107, pred_len=107)\nhyb1_long = build_model(gru=3, seq_len=130, pred_len=130)\nhyb2_short = build_model(gru=4, seq_len=107, pred_len=107)\nhyb2_long = build_model(gru=4, seq_len=130, pred_len=130)\n\n\n#load pre-trained model weights\ngru_short.load_weights('model_gru.h5')\ngru_long.load_weights('model_gru.h5')\nlstm_short.load_weights('model_lstm.h5')\nlstm_long.load_weights('model_lstm.h5')\nhyb1_short.load_weights('model_hyb1.h5')\nhyb1_long.load_weights('model_hyb1.h5')\nhyb2_short.load_weights('model_hyb2.h5')\nhyb2_long.load_weights('model_hyb2.h5')\n\n#and predict\ngru_public_preds = gru_short.predict(public_inputs)\ngru_private_preds = gru_long.predict(private_inputs)\nlstm_public_preds = lstm_short.predict(public_inputs)\nlstm_private_preds = lstm_long.predict(private_inputs)\nhyb1_public_preds = hyb1_short.predict(public_inputs)\nhyb1_private_preds = hyb1_long.predict(private_inputs)\nhyb2_public_preds = hyb2_short.predict(public_inputs)\nhyb2_private_preds = hyb2_long.predict(private_inputs)","7cb75cc9":"preds_gru = []\n\nfor df, preds in [(public_df, gru_public_preds), (private_df, gru_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_gru.append(single_df)\n\npreds_gru_df = pd.concat(preds_gru)\npreds_gru_df.head()","d42809b8":"preds_lstm = []\n\nfor df, preds in [(public_df, lstm_public_preds), (private_df, lstm_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_lstm.append(single_df)\n\npreds_lstm_df = pd.concat(preds_lstm)\npreds_lstm_df.head()","3ee2b454":"preds_hyb1 = []\n\nfor df, preds in [(public_df, hyb1_public_preds), (private_df, hyb1_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb1.append(single_df)\n\npreds_hyb1_df = pd.concat(preds_hyb1)\npreds_hyb1_df.head()","01960bc2":"preds_hyb2 = []\n\nfor df, preds in [(public_df, hyb2_public_preds), (private_df, hyb2_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb2.append(single_df)\n\npreds_hyb2_df = pd.concat(preds_hyb2)\npreds_hyb2_df.head()","a9da6389":"blend_preds_df = pd.DataFrame()\nblend_preds_df['id_seqpos'] = preds_gru_df['id_seqpos']\nblend_preds_df['reactivity'] = 0.25*preds_gru_df['reactivity'] + 0.25*preds_lstm_df['reactivity'] + 0.25*preds_hyb1_df['reactivity'] + 0.25*preds_hyb2_df['reactivity']\nblend_preds_df['deg_Mg_pH10'] = 0.25*preds_gru_df['deg_Mg_pH10'] + 0.25*preds_lstm_df['deg_Mg_pH10'] + 0.25*preds_hyb1_df['deg_Mg_pH10'] + 0.25*preds_hyb2_df['deg_Mg_pH10']\nblend_preds_df['deg_pH10'] = 0.25*preds_gru_df['deg_pH10'] + 0.25*preds_lstm_df['deg_pH10'] + 0.25*preds_hyb1_df['deg_pH10'] + 0.25*preds_hyb2_df['deg_pH10']\nblend_preds_df['deg_Mg_50C'] = 0.25*preds_gru_df['deg_Mg_50C'] + 0.25*preds_lstm_df['deg_Mg_50C'] + 0.25*preds_hyb1_df['deg_Mg_50C'] + 0.25*preds_hyb2_df['deg_Mg_50C']\nblend_preds_df['deg_50C'] = 0.25*preds_gru_df['deg_50C'] + 0.25*preds_lstm_df['deg_50C'] + 0.25*preds_hyb1_df['deg_50C'] + 0.25*preds_hyb2_df['deg_Mg_50C']","1235f9dc":"submission = sample_sub[['id_seqpos']].merge(blend_preds_df, on=['id_seqpos'])\n\n#sanity check\nsubmission.head()","22802704":"submission.to_csv('submission_now.csv', index=False)\nprint('Submission saved')","33242253":"# Hyb2","d9f69959":"# Training\n\n**Create train\/val split now so both models are trained and evaluated on the same samples:**","f10863de":"### 2. LSTM","13c2c8d3":"**Now we do the same for the LSTM model so we can blend their predictions:**","8411ab78":"**Predict twice, one for the public leaderboard, the other for the private leaderboard:**","ba672b23":"# Inference and Submission","9027a789":"# 3. Hyb1","c5ede2fd":"For Hyb2","434f85f5":"**We will use a simple learning rate callback for now:**","157140aa":"**And now we blend:**","c39cb8c7":"For hyb1:","f0cf5ba7":"### 1. GRU","d4157185":"# Model Evaluation","71d6e6d0":"**Now we just need to change the shape of each sample to the long format:**"}}