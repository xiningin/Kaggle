{"cell_type":{"e10da99d":"code","f2a9f8d7":"code","7c08c5bb":"code","81a3aa6b":"code","1d19dbaa":"code","1c3ba4a5":"code","07c015f1":"code","bdf692e0":"code","c5f23898":"code","d5206617":"code","7f8ace02":"code","dce984d7":"code","8970cc2a":"code","c6f3ee12":"code","9e91e432":"code","a20ad255":"code","fb39c9ca":"code","cf3bfd88":"code","c0a64ef5":"code","0d55d0a5":"code","2f31eaac":"code","a407d4ca":"code","a8d113bf":"code","c92bb3ba":"code","0494ebef":"code","093bfd2c":"code","4688380c":"code","bd56e7fd":"code","99f84c1e":"code","5d97fb3a":"code","626769f7":"code","ffad3772":"code","3729aa79":"code","c04c5fc9":"code","5448167d":"code","c79f3dcc":"code","cd50dad0":"code","6975cef8":"code","4393c8c1":"code","b9d3e40f":"code","a60734f6":"code","15d40ea5":"code","9f757fb1":"code","e67ff8b2":"code","a3f3d677":"code","a7af5b63":"code","28e8d874":"code","cccb0d0d":"code","14b7ab95":"code","0c3a0fd9":"code","649bf1df":"code","cbea26a9":"code","8b55eeab":"code","37212448":"code","3395125c":"code","5eb19060":"code","86cae979":"code","51c130e2":"code","59bacd28":"code","94f06699":"code","63975f5e":"code","8663e00a":"code","80db9544":"code","1d1d7e01":"code","14c4a7f0":"code","8b348bf9":"code","e47ede1f":"code","7eb1e7da":"code","ee38fb5d":"code","86be9f9f":"code","557699ff":"code","73adbd82":"code","16e1bf58":"code","70102a10":"code","74cb3edc":"code","1fc17aa3":"code","1c7bc2a2":"code","c3c76092":"code","388fa3bb":"code","d40aa1d1":"code","0f8a64dc":"code","303047cb":"code","fbeb004f":"code","02e1fc6c":"code","fb23cc73":"code","72f268b5":"code","54571c8c":"code","9e2fe160":"code","887dd50d":"code","3fb01702":"code","db511969":"code","39421452":"code","6733788b":"code","02277d8d":"code","62eb25c6":"code","e8529c72":"code","f67700da":"code","3b641e01":"code","92ebf581":"markdown","80963732":"markdown","5195f2ca":"markdown","763d472a":"markdown","af2e94b3":"markdown","9975e185":"markdown","334bd7fe":"markdown","8ce4553f":"markdown","3bb80c09":"markdown","dbad6dfa":"markdown","30aa0fa8":"markdown","758d83cb":"markdown","b92eda65":"markdown","043ee461":"markdown","b2365c5e":"markdown","6ede4747":"markdown","6a752c4a":"markdown","2062eda3":"markdown","1c77f0b6":"markdown","a03108eb":"markdown","c515051b":"markdown","6e470b05":"markdown","66e8bea7":"markdown","e34cf252":"markdown","76592722":"markdown","d67c9bcf":"markdown","48d619a2":"markdown","9599e15d":"markdown","530414d1":"markdown","81c57d65":"markdown"},"source":{"e10da99d":"import pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport warnings","f2a9f8d7":"#original data\nheart=pd.read_csv(\"..\/input\/datasets-216167-477177-heartcsv\/datasets_216167_477177_heart.csv\")","7c08c5bb":"heart.shape","81a3aa6b":"heart[100:105]","1d19dbaa":"heart[['age','trestbps', 'thalach', 'chol' ]].describe().T.style.set_table_styles([{'selector' : '', \n                            'props' : [('border', \n                                        '5px solid tomato')]}])","1c3ba4a5":"heart.info()","07c015f1":"heart.isna().sum()","bdf692e0":"g = sns.PairGrid(heart[['age', 'trestbps', 'chol', 'cp', 'thalach']])\nfig = plt.gcf()\n\nfig.set_size_inches(12,8)\n\ng.map_upper(sns.scatterplot,color='#9574B3')\ng.map_lower(sns.scatterplot, color='#ADA057')\ng.map_diag(plt.hist, color='#e34a33')\nsns.set()\nplt.show()","c5f23898":"g = sns.PairGrid(heart[heart['target']==0][['age', 'trestbps', 'chol', 'cp', 'thalach']])\nfig = plt.gcf()\n\nfig.set_size_inches(12,8)\n\ng.map_upper(sns.scatterplot,color='#9574B3')\ng.map_lower(sns.scatterplot, color='#ADA057')\ng.map_diag(plt.hist, color='#e34a33')\nsns.set()\nplt.show()","d5206617":"g = sns.PairGrid(heart[heart['target']==1][['age', 'trestbps', 'chol', 'cp', 'thalach']])\nfig = plt.gcf()\n\nfig.set_size_inches(12,8)\n\ng.map_upper(sns.scatterplot,color='#9574B3')\ng.map_lower(sns.scatterplot, color='#ADA057')\ng.map_diag(plt.hist, color='#e34a33')\nsns.set()\nplt.show()","7f8ace02":"cp_cat = [0, 1, 2, 3]\nlabels=['typical', 'asymptotic', 'nonanginal', 'nontypical']\nlabeldict=dict(zip(cp_cat, labels))\n\nplt.figure(figsize=(16,5))\nsns.countplot(x='cp', data=heart).set(title='Chest pain based on all sample data', xlabel=labeldict)\nplt.show()","dce984d7":"plt.figure(figsize=(16,5))\nsns.countplot(x='target', hue='cp', data=heart).set(\n            title=f'Chest pain per Heart Condition  :{labeldict}', xlabel='Heart disease(No=0 or Yes=1')   \nplt.show()","8970cc2a":"twenys =list(range(20,30))\nthirys =list(range(30,40))\nforys =list(range(40,50))\nfiftys =list(range(50,60))\nsixtys =list(range(60,70))\nsevenys =list(range(70,80))\neightys = list(range(80,90))\n","c6f3ee12":"age_grp=[]\nfor age in heart['age']:\n    if age in twenys:\n        age_grp.append('twenys')\n    if age in thirys:\n        age_grp.append('thirys')\n    if age in forys:\n        age_grp.append('forys')\n    if age in fiftys:\n        age_grp.append('fiftys')        \n    if age in sixtys:\n        age_grp.append('sixtys')        \n    if age in sevenys:\n        age_grp.append('sevenys')\n    if age in eightys:\n        age_grp.append('eightys')","9e91e432":"#create a new column in heart df\nheart['age_grp'] = age_grp","a20ad255":"heart = heart[['age','age_grp', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']] \n","fb39c9ca":"heart[heart['age_grp']=='twenys']","cf3bfd88":"print(heart.groupby('age_grp').agg({'age':'count', 'chol':'mean', 'trestbps':'mean'}))","c0a64ef5":"heart[heart['target']==1].groupby('age_grp').agg({'age':'count', 'chol':'mean', 'trestbps':'mean'})","0d55d0a5":"heart_attack_age_grp_pct=heart[heart['target']==1].groupby('age_grp').agg({'age':'count'})\/heart.groupby('age_grp').agg({'age':'count'})","2f31eaac":"heart_attack_age_grp_pct.rename(columns={'age':'heart_attack_pct'}, inplace=True)","a407d4ca":"heart_attack_age_grp_pct.reset_index(inplace=True) ","a8d113bf":"heart_attack_age_grp_pct.sort_values('heart_attack_pct', ascending=False, inplace=True)","c92bb3ba":"plt.figure(figsize=(16,5))\nsequential_colors = sns.color_palette(\"RdPu\", 10)\n\nsns.barplot(x=heart_attack_age_grp_pct['age_grp'],\n            y=heart_attack_age_grp_pct['heart_attack_pct'] ).set(\n                title= \"Heart disease percentage per Age group\", ylabel='%')  \n\n \nplt.show()","0494ebef":"age_grp_list=list(set(heart_attack_age_grp_pct['age_grp']))\nage_grp_list=['twenys','thirys','forys','fiftys','sixtys','sevenys']\nage_grp_list[5]","093bfd2c":"fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18,12))\nk=0\nfor i in range(2):\n    for j in range(3):\n        sns.distplot(\n            heart[heart['target']==1].groupby('age_grp').get_group(age_grp_list[k])['trestbps'], bins=10, ax=axs[i,j], color='red')              \n        axs[i,j].set_title(f\"{age_grp_list[k]} age group: BP distribution\", weight='bold')\n        k+=1\nplt.show()\nsns.set()\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%config InlineBackend.figure_format ='retina'","4688380c":"fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18,12))\nk=0\nfor i in range(2):\n    for j in range(3):\n        sns.distplot(\n            heart[heart['target']==1].groupby('age_grp').get_group(age_grp_list[k])['chol'], bins=10, ax=axs[i,j], color='#D47DCB')              \n        axs[i,j].set_title(f\"{age_grp_list[k]} age group: Cholostrol distribution\", weight='bold')    \n        k+=1\nplt.show()\nsns.set()\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%config InlineBackend.figure_format ='retina'","bd56e7fd":"heart.head()","99f84c1e":"sns.set()\nplt.figure(figsize=(15,8))\ncmap = sns.dark_palette(\"#f20534\", as_cmap=True)\nsns.heatmap(\n    heart[['age', 'sex','cp', 'trestbps', 'chol', 'thalach', 'target']].corr(),\n    annot=True, vmin=-1, cmap=cmap).set(\n    title='Corr between Heart disease Vs Chest Pain(cp), BP, Cholostrol, Exercise induced Angina(thalach)')  \nplt.show()\n","5d97fb3a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics  # ********* &&&& why we need this module????","626769f7":"heart_pred1=heart[['age', 'sex', 'cp', 'trestbps', 'chol','target']]\nheart_pred2=heart[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs','target']]\nheart_pred3=heart[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs','thal','target']]","ffad3772":"X = heart_pred1[['age', 'sex', 'cp', 'trestbps', 'chol']]\ny = heart_pred1['target']\nprint(len(X))\nprint(len(y))","3729aa79":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)","c04c5fc9":"print(f'X_train length is:{len(X_train)}, and y_train:{len(y_train)}')\nprint(f'X_test length is:{len(X_test)}, and y_test:{len(y_test)}')\nprint(f'Hence, the data of size {len(X)} is split in to train data of {len(X_train)} and test data of {len(X_test)}.') ","5448167d":"logreg = LogisticRegression()  ","c79f3dcc":"logreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test) ","cd50dad0":"y_pred[240:] # sample prediction output","6975cef8":"#print(classification_report(y_test,predictions)) confusion_matrix(y_test, y_predict)\naccuracy_test = logreg.score(X_test, y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","4393c8c1":"conf_matrix_dict = {'PREDICTED: NO':['TN', 'FP'], 'PREDICTED: YES':['FN', 'TP']}\nconf_matrix_index = ['ACTUAL No', 'ACTUAL Yes']\nconf_matrix_df = pd.DataFrame(conf_matrix_dict, index=conf_matrix_index)\nconf_matrix_df.style.set_table_styles([{'selector' : '', \n                            'props' : [('border', \n                                        '5px solid tomato')]}])\n","b9d3e40f":"print(confusion_matrix(y_test, y_pred))\nprint(f\" Accuracy based on manual calculation of confusion matrix: {round((1-(27+27)\/(103+100+27+27))*100,3)}%\")","a60734f6":"print(classification_report(y_test, y_pred))","15d40ea5":"heart_pred2=heart[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs','target']]","9f757fb1":"X = heart_pred2[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs']]\ny = heart_pred2['target']","e67ff8b2":"X_train, X_test, y_train,y_test=train_test_split(X,y, test_size=0.25, random_state=10)","a3f3d677":"logreg=LogisticRegression()","a7af5b63":"logreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)","28e8d874":"y_pred[240:] # sample prediction output","cccb0d0d":"accuracy_test = logreg.score(X_test, y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","14b7ab95":"confusion_matrix(y_test, y_pred)","0c3a0fd9":"print(classification_report(y_test, y_pred))","649bf1df":"heart_pred5= heart[['age','cp','thalach','target']]\nX=heart_pred5[['age','cp','thalach']]\ny=heart['target'] ","cbea26a9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)","8b55eeab":"logreg = LogisticRegression() ","37212448":"logreg.fit(X_train, y_train) \ny_pred = logreg.predict(X_test) ","3395125c":"print(classification_report(y_test, y_pred))","5eb19060":"accuracy_test = logreg.score(X_test, y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","86cae979":"heart_pred3=heart[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs','thal','target']]","51c130e2":"X = heart_pred3[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'thal']]\ny = heart_pred3['target']","59bacd28":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10) ","94f06699":"logreg=LogisticRegression()","63975f5e":"logreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nwarnings.simplefilter(action='ignore', category=FutureWarning)","8663e00a":"from sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler","80db9544":"#instantiate the preprocessing\nmmscaler = MinMaxScaler()\nX_train_norm = mmscaler.fit_transform(X_train)\nX_test_norm = mmscaler.fit_transform(X_test) ","1d1d7e01":"logreg.fit(X_train_norm, y_train)","14c4a7f0":"y_pred = logreg.predict(X_test_norm)","8b348bf9":"y_pred[240:] # sample data","e47ede1f":"accuracy_test = logreg.score(X_test_norm, y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","7eb1e7da":"confusion_matrix(y_test, y_pred)","ee38fb5d":"print(classification_report(y_test, y_pred))","86be9f9f":"from sklearn.preprocessing import StandardScaler","557699ff":"#instantiate the preprocessing\nsscaler = MinMaxScaler()\nX_train_stan = sscaler.fit_transform(X_train)\nX_test_stan = sscaler.fit_transform(X_test)\n#y_train_norm = mmscaler.fit_transform(y_train)\n#y_test_norm = mmscaler.fit_transform(y_test)","73adbd82":"logreg.fit(X_train_stan, y_train)","16e1bf58":"y_pred = logreg.predict(X_test_stan)","70102a10":"y_pred[240:] # sample data","74cb3edc":"accuracy_test = logreg.score(X_test_stan, y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","1fc17aa3":"confusion_matrix(y_test, y_pred)","1c7bc2a2":"(30+24)\/257","c3c76092":"print(classification_report(y_test, y_pred))","388fa3bb":"heart_pred4=heart[['age', 'cp', 'trestbps', 'chol','target']]","d40aa1d1":"X = heart_pred4[['age', 'cp', 'trestbps', 'chol']]\ny = heart_pred4['target']","0f8a64dc":"X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.25, random_state=10)","303047cb":"logreg=LogisticRegression()","fbeb004f":"logreg.fit(X_train, y_train)","02e1fc6c":"y_pred = logreg.predict(X_test)","fb23cc73":"y_pred[240:] # sample prediction data","72f268b5":"accuracy_test = logreg.score(X_test, y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","54571c8c":"confusion_matrix(y_test, y_pred)","9e2fe160":"print(classification_report(y_test, y_pred))","887dd50d":"heart_pred1=heart[['age', 'sex', 'cp', 'trestbps', 'chol','target']]","3fb01702":"X = np.array(heart_pred1[['age', 'sex', 'cp', 'trestbps', 'chol']])\ny = np.array(heart_pred1['target'])","db511969":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state =10 )","39421452":"logreg = LogisticRegression()","6733788b":"logreg.fit(X_train, y_train)","02277d8d":"y_pred=logreg.predict(X_test)","62eb25c6":"print(y_test[240:])\nprint(y_pred[240:]) # sample data","e8529c72":"accuracy_test = logreg.score(X_test,y_test)\nprint(f' The accuracy score is: {round((accuracy_test*100),3)}%')","f67700da":"confusion_matrix(y_test, y_pred)","3b641e01":"print(classification_report(y_test, y_pred))","92ebf581":"##### Test_Train_Split, Instantiate, Train the model, predict and calculate accuracy","80963732":"##### Train(Fit)  the model, and Prediction","5195f2ca":"<font face = \"Gabriola\" size=4>    Not enough data, dont see any siginificant correlation. Hence, in this case to make an informed decision more data is needed.","763d472a":"##### Senario-4 More and more features\n    features: 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'thal","af2e94b3":"# <font face = \"Book Antiqua\"> Heart Disease predictor\n    Data contains;\n    age - in years\n    sex - (1 = male; 0 = female)\n    cp - chest pain type (typical, asymptotic, nonanginal, nontypical)\n    trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n    chol - serum cholestoral in mg\/dl\n    fbs - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n    restecg - resting electrocardiographic results\n    thalach - maximum heart rate achieved\n    exang - exercise induced angina (1 = yes; 0 = no)\n    oldpeak - ST depression induced by exercise relative to rest\n    slope - the slope of the peak exercise ST segment\n    ca - number of major vessels (0-3) colored by flourosopy\n    thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n    target - have disease or not (1=yes, 0=no)","9975e185":"##### Senario-2 More features\n    features: 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs'","334bd7fe":"##### Senario-4 More and more features: \n","8ce4553f":"##### Pair plot for all samples","3bb80c09":"##### Train_Test_Split, Instantiate, Train(fit) the model, predict and calculate accuracy","dbad6dfa":"# <a id=\"linkhandle\"><\/a> # ERROR: Total number of Iterations reached limit\n <font face = \"Gabriola\" size=4>\n ERROR: Total number of Iterations reached limit\n    C:\\~\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https:\/\/scikit-learn.org\/stable\/modules\/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","30aa0fa8":"##### Senario-3 with only relevant features based on the correlation heatmap\n    features: 'age', 'cp', 'thal","758d83cb":"#### <font face = \"Book Antiqua\">Import Preprocessing scalar module : Using MinMaxScaler \n<font face = \"Gabriola\" size=4>  To overcome the error I preprocessed the data. The error is gone but that didn't improve the accuracy test result. The general rule is that preprocessing should be used before train_test_split otherwise data leakage will happen.\n","b92eda65":"#### Blood pressure distribution for those with Heart disease: by age_grp","043ee461":"#### Import Preprocessing scalar module : Using StandardScaler","b2365c5e":"##### Pair plot based on target = 1 (heart['target'] ==1)","6ede4747":"<font face = \"Gabriola\" size=4> The prediction target in this analysis is the likelihood of a person getting a heart disease based on certain indicators. To predict the target, different features have been progressivley selected and a prediction is run using Logistic regression. Indicators such as max heart rate (thalach), blood pressure(trestbps) and chest pain(cp) have been used to explore the relationship with the target. The prediction scenarios are:\n***\n\n * A prediction is run with and without preprocessing. My understanding is that the regression analysis can be run without scaling, but for larger data scaling is preferred.\n * After an error is encountered while running a prediction without scaling a prediction is run with scaling: in this case with two different scaling functions . To see the error click here [error](#linkhandle). \n * A prediction is run with and without converting the dataframe into a numpy array.\n  <br> \nFor all the different prediction scenarios the prediction was run, the accuracy test resulted in about 79% accuracy.\n <br> \n *** \n   I tried to go through the analysis in detail and step by step. Where relevant, I left the errors I have come across to help those who are at the beginning of their machine learning skill ladder. So, the analysis is done with beginners in mind.\n","6a752c4a":"##### Create age group then add a column on the heart dataframe","2062eda3":"##### Train Test and Split :","1c77f0b6":"#### <font face = \"Book Antiqua\"> Conclusion\n<font face = \"Gabriola\" size=4> Despite running predictions with different scenarios the accuracy score result did not budge beyond 79% . In this analysis, whether the data is converted into a numpy array or not that did not affect the accuracy score result. So, to get a higher score other regression models have to be implemented.","a03108eb":"##### Testing accuracy of the model","c515051b":"#### Cholostrol distribution for those with Heart disease: by age_grp","6e470b05":"#### Confusion Matrix\n<font face = \"Gabriola\" size=4> accuracy is the percentage of (True Positive + True Negative) over all measurements (True Positive + True Negative+ False Positive + False Negative)\n###### $$ \\frac {TP+TN}{TN+TP+FP+FN} $$","66e8bea7":"##### Instantiate the model","e34cf252":"##### Test_Train_Split, Instantiate, Train the model, predict and calculate accuracy","76592722":"#### Converting fetures and Target into a numpy array before running Regression\n<font face = \"Gabriola\" size=5> Question: Data the dataframe has has to be converted into a numpy array?","d67c9bcf":"<font face = \"Gabriola\" size=5>The analysis shows no improvement in accuracy result, wether the data is a numpy array or not.","48d619a2":"##### Pair plot based on target = 0 (heart['target'] ==0)","9599e15d":"##### Senario-1 less number of features: Questions the dataframe has it have to be numpy array????\n    features: 'age', 'sex', 'cp', 'trestbps', 'chol'","530414d1":"##### Test_Train_Split, Instantiate, Train the model, predict and calculate accuracy","81c57d65":"#### For scikit learn to work \n    Target and features have to be numeric and a numpy array. And the same length, hence Target prediction is based on the input features.\n  ##### Steps\n    Split into training and testing datasets (train_test_split)\n    Instantiate the model using Logistic Regression (logreg = LogisticRegression())\n    Fit the instantiated model\n    Make prediction based on the test split dataset.\n    Calculate the accuracy of the prediction using R Sqaure\n"}}