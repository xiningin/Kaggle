{"cell_type":{"f47fe564":"code","c01f3b78":"code","c429cdf6":"code","a21e4a76":"code","98b6046c":"code","d86882e5":"code","587ff666":"code","57773561":"code","56c138cd":"code","b9e47ac4":"code","1e714698":"code","02b1c72c":"code","8d04471e":"code","946bc8f4":"code","08b1b758":"code","c3f00fd0":"code","524a454e":"code","dd40b315":"code","424e24b8":"code","ec531926":"code","e254b060":"code","4fee7239":"code","4979f506":"code","e74003af":"code","4118fac5":"code","378e314f":"code","2e1ff057":"code","84e33e20":"code","a6ba840d":"code","38b58cac":"code","c702bc82":"code","1d6cf07a":"code","03e2b38c":"code","ef8948b9":"code","0692ff19":"code","aadff6d3":"code","8ff8b944":"markdown","5a9a82c0":"markdown","53ea5af1":"markdown","7a315015":"markdown","d29e7484":"markdown","d87660b4":"markdown","bd78736d":"markdown","7a147f29":"markdown","9065077d":"markdown"},"source":{"f47fe564":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c01f3b78":"train=pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","c429cdf6":"train.head()","a21e4a76":"test.head()","98b6046c":"train.isnull().sum()","d86882e5":"import seaborn as sns\nsns.heatmap(train.isnull(),yticklabels=False)","587ff666":"train.drop([\"keyword\",\"location\"],axis=1,inplace=True)\ntest.drop([\"keyword\",\"location\"],axis=1,inplace=True)","57773561":"target=train.target","56c138cd":"sns.countplot(target)","b9e47ac4":"train.drop([\"target\"],inplace=True,axis=1)","1e714698":"import nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nimport re\nlemmatize=PorterStemmer()","02b1c72c":"\ncorpus=[]\nfor i in range(len(train.text)):\n    word=re.sub(\"[^a-zA-Z]\",\" \",train.text[i])\n    word=word.lower()\n    word=word.split()\n    word=[lemmatize.stem(words) for words in word if words not in set(stopwords.words(\"english\"))]\n    word=\" \".join(word)\n    corpus.append(word)","8d04471e":"corpus[1]","946bc8f4":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vector=CountVectorizer(max_features=5000,ngram_range=(1, 2))","08b1b758":"train_data=count_vector.fit_transform(corpus)","c3f00fd0":"count_vector.get_feature_names()[:5]","524a454e":"from sklearn.model_selection import train_test_split","dd40b315":"X_train,X_test,y_train,y_test=train_test_split(train_data,target,test_size=0.3)","424e24b8":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB,BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier","ec531926":"cross_val_score(LogisticRegression(),train_data,target)","e254b060":"cross_val_score(SVC(),train_data,target)","4fee7239":"cross_val_score(MultinomialNB(alpha=1),train_data,target)","4979f506":"cross_val_score(RandomForestClassifier(n_estimators=100),train_data,target)","e74003af":"cross_val_score(BernoulliNB(alpha=1),train_data,target)","4118fac5":"dist=MultinomialNB()\nmodel=dist.fit(X_train,y_train)","378e314f":"y_pred=model.predict(X_test)","2e1ff057":"from sklearn.metrics import confusion_matrix,accuracy_score\nc=confusion_matrix(y_test,y_pred)\nsns.heatmap(c,annot=True)","84e33e20":"accuracy_score(y_test,y_pred)*100","a6ba840d":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","38b58cac":"test_data=[]\nfor i in range(len(test.text)):\n    word=re.sub(\"[^a-zA-Z]\",\" \",test.text[i])\n    word=word.lower()\n    word=word.split()\n    word=[lemmatize.stem(words) for words in word if words not in set(stopwords.words(\"english\"))]\n    word=\" \".join(word)\n    test_data.append(word)","c702bc82":"test_for_pred=count_vector.transform(test_data)","1d6cf07a":"test_for_pred.data","03e2b38c":"prediction=model.predict(test_for_pred)","ef8948b9":"submission=pd.DataFrame()\nsubmission['id']=test.id\nsubmission['target']=prediction","0692ff19":"submission.target.value_counts()","aadff6d3":"final_submission=submission.to_csv(\"Result\",index=False)","8ff8b944":"> Let us remove unwanted words from the text and stem it","5a9a82c0":"From the above models \nit seems MultinominalNB is performing well \nso lets use that for prediction","53ea5af1":"We have a good balenced data","7a315015":"ooohhh\ngood accuracy lets find classification report","d29e7484":"EDA and Data visualization","d87660b4":"Lets find best model with best params","bd78736d":"Let's train our model by transforming","7a147f29":"So,we don't need this columns ,let's drop them in both train and test","9065077d":"lets make our test data ready for prediction"}}