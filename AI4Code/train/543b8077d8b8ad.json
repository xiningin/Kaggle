{"cell_type":{"6d5c24d1":"code","a7f9b2a5":"code","b56396ca":"code","481928fe":"code","f2c50ab9":"code","d4ab1e27":"code","b6bb6667":"code","533ece2e":"code","7f3fcf1b":"code","5c760d94":"code","d95a2e91":"code","d2dfde9d":"markdown","0539a0e9":"markdown","1c5dfead":"markdown","9370ca15":"markdown","2f599b61":"markdown"},"source":{"6d5c24d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a7f9b2a5":"import matplotlib.pyplot as plt\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport re\nimport nltk\nfrom nltk.corpus import stopwords","b56396ca":"StopWords = set(stopwords.words('english'))\ndef text_preprocess(text):\n    text = ' '.join([i for i in text.split() if i not in StopWords]) #removing stopwords from each tweet\n    text = ' '.join([i for i in text.split() if ('http' not in i and '@' not in i and 'https' not in i)]) #removing mentions and urls\n    text = re.sub('#', '', text) #removing hashtags while keeping the tagged word :p\n    return text\n\n#The Keras Tokenizer deals with lower-casing of text and editing out punctuations.","481928fe":"train_data = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ntest_data = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\n\nX_train = train_data['text']\ny_train = train_data['target']\nX_test = test_data['text']\ntest_idx = test_data['id']\n\ntrain_data['text'] = train_data['text'].apply(text_preprocess)\nX_train = train_data['text']\ntest_data['text'] = test_data['text'].apply(text_preprocess)\nX_test = test_data['text']\n\nX_train = X_train.tolist()\nX_test = X_test.tolist()\nprint(X_train)\n        \n        \n       \n\n","f2c50ab9":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\nvocab_size = len(tokenizer.word_index)\nmax_len = 150\ntrain_seq = tokenizer.texts_to_sequences(X_train)\ntrain_pad = pad_sequences(train_seq, maxlen=max_len, padding='pre')\ntest_seq = tokenizer.texts_to_sequences(X_test)\ntest_pad = pad_sequences(test_seq, maxlen=max_len, padding='pre')\n\n\n\n#sanity check to make sure stopwords have been removed. Just a useful way of checking.\nfor idx, word in tokenizer.word_index.items():\n    if word in StopWords:\n        print(\"F\")\n    else:\n        print(\"T\")","d4ab1e27":"model = keras.Sequential([\n    keras.layers.Embedding(vocab_size+1, 200, input_length=max_len),\n    keras.layers.SpatialDropout1D(0.5),\n    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(32)),\n    keras.layers.Dense(200, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\noptimizer = keras.optimizers.Adam(learning_rate = 0.01)\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nhistory = model.fit(train_pad, y_train, epochs=40)\n","b6bb6667":"model.summary()","533ece2e":"def plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.xlabel('epochs')\n  plt.ylabel(string)\n  plt.show()\n\nplot_graphs(history, 'loss')\nplot_graphs(history, 'accuracy')","7f3fcf1b":"model.predict_classes(test_pad)","5c760d94":"pred = pd.DataFrame()\npred['id'] = test_idx\npred['target'] = model.predict_classes(test_pad)\nprint(pred)","d95a2e91":"pred.to_csv('submission.csv', index=False)\nprint(\"Submission has been saved\")","d2dfde9d":"# II. Basic Text Preprocessing","0539a0e9":"# **Tweet Classification Using Bi-LSTM model in Keras**","1c5dfead":"# III. Training the RNN(Bi-LSTM) model:","9370ca15":"# I. Importing required libraries","2f599b61":"# IV. Generating output target labels."}}