{"cell_type":{"f914bcfa":"code","b730fc63":"code","4f3bfa84":"code","efc80f48":"code","a3b01269":"code","9466804b":"code","193686c7":"code","972c17f7":"code","9c9c6f1b":"code","3466e94d":"markdown","f1f67f25":"markdown","e3cdbb14":"markdown"},"source":{"f914bcfa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport keras.models as Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b730fc63":"train_path=\"\/kaggle\/input\/fruits\/fruits-360\/Training\/\"\ntest_path=\"\/kaggle\/input\/fruits\/fruits-360\/Test\/\"","4f3bfa84":"img=load_img(train_path+\"Apple Braeburn\/0_100.jpg\")\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","efc80f48":"x=img_to_array(img)\nprint(x.shape)","a3b01269":"className=glob(train_path+\"\/*\")\nnumberOfClass=len(className)\nprint(\"Number Class: \",numberOfClass)","9466804b":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings(\"ignore\")","193686c7":"model=Sequential()\nmodel.add(Conv2D(32,(3,3),input_shape=x.shape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(numberOfClass))#output\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss = \"categorical_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n\nbatch_size = 32","972c17f7":"train_datagen=ImageDataGenerator(rescale=1.\/255,shear_range=0.3,horizontal_flip=True,zoom_range=0.3)\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator=train_datagen.flow_from_directory(train_path,target_size=x.shape[:2],batch_size=batch_size,color_mode=\"rgb\",class_mode=\"categorical\")\n\ntest_generator=test_datagen.flow_from_directory(test_path,target_size=x.shape[:2],batch_size=batch_size,color_mode=\"rgb\",class_mode=\"categorical\")\n\nhist = model.fit_generator(generator=train_generator,steps_per_epoch=1600\/\/batch_size,epochs=100,validation_data=test_generator,validation_steps=800\/\/batch_size)","9c9c6f1b":"print(hist.history.keys())\nplt.plot(hist.history[\"loss\"], label = \"Train Loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()","3466e94d":"## **Data Generation-Train-Test**","f1f67f25":"## **CNN Model**","e3cdbb14":"## **Model Evaluation**"}}