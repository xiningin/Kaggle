{"cell_type":{"dec7b3fd":"code","5c530cd1":"code","b7083573":"code","c018be3c":"code","5bf295c8":"code","90494ba7":"code","4fee34d6":"code","064c8097":"code","8acb98ca":"code","d5f1e90c":"code","161654c4":"code","875e86b2":"code","a5fb4086":"code","c13f538a":"code","6bf59c59":"code","81fad9ad":"code","d41654a1":"code","52abd663":"code","97823f5f":"code","c6aaf444":"markdown","a35c60b4":"markdown","2a36a6bf":"markdown","960f6897":"markdown","0db7690c":"markdown","59453c58":"markdown","8b68dd87":"markdown"},"source":{"dec7b3fd":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","5c530cd1":"DATA_PATH = '\/kaggle\/input\/ocular-disease-recognition-both-eyes-512x1024\/ocular\/data.csv'\nIMG_DIR = '\/kaggle\/input\/ocular-disease-recognition-both-eyes-512x1024\/ocular\/images'","b7083573":"# image example\nimage = cv2.imread(os.path.join(IMG_DIR, '12.jpg'))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \nplt.imshow(image) ","c018be3c":"df = pd.read_csv(DATA_PATH)\ndf","5bf295c8":"# Preprocess CSV\ndf.loc[df['Patient Sex'] == 'Male', 'Patient Sex'] = 1.0\ndf.loc[df['Patient Sex'] == 'Female', 'Patient Sex'] = 0.0\nage_mean = df['Patient Age'].mean()\ndf['Patient Age'] = df['Patient Age'] - age_mean\nstdd = df['Patient Age'].std()\ndf['Patient Age'] = df['Patient Age'] \/ stdd\n# Shuffle the patients in case there is some kind of sorting (e.g. by the doctors) \ndf = df.sample(frac = 1) \ndf.reset_index(drop=True, inplace=True)\ndf","90494ba7":"# Create data sets\nvalid_ids = df.iloc[-700:, 0]\ntrain_ids = df.iloc[:-700, 0]","4fee34d6":"# based on AlexNet architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4)\n        self.conv2 = nn.Conv2d(96, 256, 5, padding=2)  # 'same' convolution\n        self.conv3 = nn.Conv2d(256, 384, 3, padding=1) \n        self.conv4 = nn.Conv2d(384, 384, 3, padding=1) \n        self.conv5 = nn.Conv2d(384, 256, 3, padding=1) \n        self.conv6 = nn.Conv2d(256, 128, 3, padding=1) \n        \n        self.fc1 = nn.Linear(10754, 566)\n        self.fc2 = nn.Linear(566, 566) \n        self.fc3 = nn.Linear(566, 7) \n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x, features):           # (n, 3, 512, 1024), (n, f)\n        \n        # output size = floor(((width + 2padding - kernel) \/ stride) +1)   \n\n        x = self.pool(F.relu(self.conv1(x)))  # --> (n, 96, 126, 254) --> (n, 96, 62, 126)\n        x = self.pool(F.relu(self.conv2(x)))  # --> (n, 256, 62, 126) --> (n, 256, 30, 62)\n        x = F.relu(self.conv3(x))             # --> (n, 384, 30, 62)\n        x = F.relu(self.conv4(x))             # --> (n, 384, 30, 62)\n        x = self.pool(F.relu(self.conv5(x)))  # --> (n, 256, 30, 62) --> (n, 256, 14, 30)\n        x = self.pool(F.relu(self.conv6(x)))  # --> (n, 128, 14, 30) --> (n, 128, 6, 14)\n        \n        x = x.view(x.size(0), -1)             # flatten --> (n, 10752)\n        x = torch.cat((x, features), 1)       # add age and sex --> (n, 10754)\n        x = F.relu(self.fc1(x))               # --> (n, 566)\n        x = F.relu(self.fc2(x))               # --> (n, 566)\n        x = self.sigmoid(self.fc3(x))         # --> (n, 7) Normal is not a class\n        \n        return x\n    ","064c8097":"net = Net()\nprint(net)","8acb98ca":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","d5f1e90c":"net.to(device)","161654c4":"def load_image(patient_id):\n    file_name = str(patient_id) + '.jpg'\n    image = Image.open(os.path.join(IMG_DIR, file_name))  \n    image_np = np.array(image)\n    image_np = np.moveaxis(image_np, 2, 0)\n    img = torch.from_numpy(image_np)\n    img = img \/ 255\n    return img","875e86b2":"def create_batch(ids):\n    images = []\n    labels = []\n    info = []\n    \n    for patient_id in ids:\n        image = load_image(patient_id)\n        images.append(image)\n        \n        lbl = df.loc[df['ID']==patient_id].iloc[:,8:]\n        labels.append(lbl.values[0])\n        \n        inf = df.loc[df['ID']==patient_id].iloc[:,1:3]\n        info.append(inf.values[0])\n        \n    images = torch.stack(images)\n    labels = torch.from_numpy(np.asarray(labels, dtype=np.float32))\n    info = torch.from_numpy(np.asarray(info, dtype=np.float32))\n    \n    return images, labels, info","a5fb4086":"def create_batches(ids):\n    batch_size = 8\n    nr_batches = ids.shape[0] \/\/ batch_size\n    last_batch = ids.shape[0] % batch_size\n    \n    batches = []\n    for b in range(nr_batches):\n        batch = train_ids.iloc[b*batch_size : b*batch_size+batch_size]\n        batches.append(batch)\n        \n    if last_batch != 0:\n        batches.append(train_ids.iloc[-last_batch:])\n        \n    return batches","c13f538a":"epochs = 2\nprint_step = 50\ncriterion = nn.BCELoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","6bf59c59":"for epoch in range(epochs):\n    running_loss = 0.0\n    \n    batches = create_batches(train_ids)\n\n    for i, batch in enumerate(batches):\n        optimizer.zero_grad()\n        batch_images, batch_labels, batch_info = create_batch(batch)\n        \n        outputs = net(batch_images.to(device), batch_info.to(device))\n        \n        loss = criterion(outputs, batch_labels.to(device))\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        if i % print_step == print_step-1:\n            print(f'[{epoch+1}, {i+1}] loss: {running_loss\/print_step}')\n            running_loss = 0.0\n            \nprint('Finished')","81fad9ad":"torch.save(net.state_dict(), '\/kaggle\/working\/alexnet.pth')\n#net = Net()\n#net.load_state_dict(torch.load('\/kaggle\/working\/alexnet.pth'))","d41654a1":"def evaluate(labels, outputs):\n    predictions = torch.where(outputs>0.7, 1, 0)\n    match = torch.where(labels == predictions, 1, 0)\n    acc = 100 * match.sum() \/ match.numel()    \n\n    strict_match = torch.sum(match, dim=1) # size = [nrow, 1]\n    strict_match = torch.where(strict_match == 7, 1, 0)\n    strict_acc = 100 * strict_match.sum() \/ strict_match.numel()  \n    \n    return acc.item(), strict_acc.item()","52abd663":"valid_batches = create_batches(valid_ids)\naccuracy = []\nstrict_accuracy = []\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(valid_batches)):\n        batch_images, batch_labels, batch_info = create_batch(batch)\n        outputs = net(batch_images.to(device), batch_info.to(device))\n        acc, strict_acc = evaluate(batch_labels.to(device), outputs)\n        accuracy.append(acc)\n        strict_accuracy.append(strict_acc)","97823f5f":"print(f'{sum(accuracy)\/len(accuracy):.2f}% accuracy')\nprint(f'{sum(strict_accuracy)\/len(strict_accuracy):.2f}% strict accuracy')","c6aaf444":"# Training","a35c60b4":"# Model","2a36a6bf":"# CSV","960f6897":"# Ocular Disease Recognition - CNN\nI use a dataset created by preprocessing this one:<br>\nhttps:\/\/www.kaggle.com\/andrewmvd\/ocular-disease-recognition-odir5k<br>\nThe preprocessing can be found here:<br>\nhttps:\/\/www.kaggle.com\/annaszal\/ocular-preprocessing","0db7690c":"First number describes how often the network gets it right whether a specific disease is present, second number shows how often it gets right the whole diagnosis for the patient (eg. 0 1 0 0 0 0 1).","59453c58":"# Evaluate","8b68dd87":"Most of pretrained models expect square images as an input, but i am going to create a custom network (based on AlexNet), so rectangular shape won't be a problem. This way both eyes of a patient will be assessed together."}}