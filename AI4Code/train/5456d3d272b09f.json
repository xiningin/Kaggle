{"cell_type":{"ab35d5c7":"code","8c94d828":"code","62416e7b":"code","e9d924d8":"code","788e5a32":"code","83b02a96":"code","0f0817ba":"code","7cbece9b":"code","e8b6b152":"code","35d599fa":"code","03b76039":"code","410235a5":"code","a983a286":"code","a8df2d24":"code","55876d10":"code","f0b3f73d":"code","f2006d5d":"code","840af977":"markdown","528746c9":"markdown","e7a9136d":"markdown","1b14c793":"markdown","22ed6165":"markdown","19bf08b5":"markdown","eea4b539":"markdown"},"source":{"ab35d5c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c94d828":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","62416e7b":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ndata = data.drop(columns = ['Id'])\ntest = test.drop(columns = [\"Id\"])","e9d924d8":"obj_feat = list(data.loc[:, data.dtypes == 'object'].columns.values)\nfor feature in obj_feat:\n    print(data.shape)\n    grouped = pd.DataFrame(data.groupby([feature])['SalePrice'].mean()).reset_index()\n    strf = feature + \"_mean\"\n    grouped.rename(columns = {'SalePrice': strf}, inplace=True)\n    data = data.merge(grouped, left_on=[feature], right_on=[feature], how = 'outer')\n    test = test.merge(grouped, left_on=[feature], right_on=[feature], how = 'outer')\n    data = data.drop(columns=[feature])\n    test = test.drop(columns=[feature])","788e5a32":"X = data.drop(columns = ['SalePrice'])\nY = data.SalePrice","83b02a96":"gridParams = {\n    'learning_rate': np.linspace(0.0001, 0.01, 20),\n    'n_estimators': list(range(1,5)),\n    'num_leaves': [6,8,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n    'objective' : ['regression'],\n    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progres\n    'colsample_bytree' : [0.64, 0.65, 0.66],\n    'subsample' : [0.7,0.75],\n    'metric' : [\"rmse\"]\n}","0f0817ba":"grid = GridSearchCV(lgb.LGBMRegressor(), gridParams, verbose=1, cv=5, n_jobs=-1)","7cbece9b":"grid.fit(X, Y)","e8b6b152":"print(grid.best_score_)","35d599fa":"print(grid.best_params_)","03b76039":"model = lgb.LGBMRegressor(boosting_type = 'gbdt', colsample_bytree = 0.65, learning_rate = 0.01, max_bin = 510, metric= 'rmse', n_estimators = 4, num_leaves = 16, objective = 'regression', subsample = 0.7)\nmodel.fit(X, Y)","410235a5":"lgb.plot_importance(model)","a983a286":"Y_hat = model.predict(test)","a8df2d24":"model.score(X, Y)","55876d10":"cross_val_score(model, X, Y, cv = 10)","f0b3f73d":"Y_hat = pd.DataFrame(Y_hat)","f2006d5d":"Y_hat.to_csv('result.csv')","840af977":"# LOAD THE DATA","528746c9":"# PREDICT","e7a9136d":"# SEPARATE TARGET AND FEATURES","1b14c793":"# IMPORT LIBRARIES","22ed6165":"# GRID SEARCH","19bf08b5":"# TRAIN THE MODEL","eea4b539":"# MEAN ENCODING "}}