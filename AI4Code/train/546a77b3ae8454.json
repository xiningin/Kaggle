{"cell_type":{"1637c839":"code","026bfde7":"code","9b8cb79a":"code","6e4e3268":"code","a5e73184":"code","6981b169":"code","e24bd205":"code","70c77117":"code","293fe23b":"code","886f40e8":"markdown","418c94e0":"markdown","e9182853":"markdown","4d1ac631":"markdown","09c170ec":"markdown","ea9c552f":"markdown"},"source":{"1637c839":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model\nfrom IPython.display import display\nimport gc\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\n\nimport kornia as K\nfrom kornia import image_to_tensor, tensor_to_image\nimport kornia.augmentation as aug\n\nfrom transformers import get_cosine_schedule_with_warmup","026bfde7":"seed = 402\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","9b8cb79a":"class PetData(Dataset):\n    def __init__(self, df, transform, is_test=False):\n        super(PetData, self).__init__()\n        self.binary_features = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n        self.df = df\n        self.transform = transform\n        self.is_test = is_test\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = row[\"path\"]\n        img = Image.open(image_path).convert(\"RGB\")\n        data = self.transform(img)\n        binary_features = torch.tensor(row[self.binary_features], dtype=torch.long)\n        if self.is_test:\n            return data, binary_features\n        else:\n            label = torch.tensor(row[\"norm_score\"], dtype=torch.float) # [0.01, 1.0]\n            return data, label, binary_features","6e4e3268":"class Data:\n    def __init__(self, batch_size=16, img_size=224, n_split=10):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        \n        self.train_val_df = pd.read_csv(\"..\/input\/petfinder-data-with-10-folds\/train_val_df.csv\")\n        self.test_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\n        \n        image_mean = [0.38753143, 0.36847523, 0.27735737]\n        image_std = [0.25998375, 0.23844026, 0.2313706]\n        normTransform = T.Normalize(image_mean, image_std)\n        self.trainTransform = T.Compose([\n#             T.RandomResizedCrop((img_size, img_size), (0.8, 1.0)),\n            T.Resize((img_size+32, img_size+32)),\n            T.CenterCrop((img_size, img_size)),\n#             T.Resize((img_size, img_size)),\n            T.RandomRotation(30),\n            T.RandomHorizontalFlip(),\n            T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n            T.ToTensor(),\n            normTransform,\n            T.RandomErasing(scale=(0.02, 0.13)),\n        ])\n        self.validTransform = T.Compose([\n            T.Resize((img_size, img_size)),\n            T.ToTensor(),\n            normTransform\n        ])        \n        self.num_workers = 2\n        \n    def train_dataloader(self, fold):\n        train_df = self.train_val_df.query(f'fold != {fold}')\n        train_ds = PetData(train_df, self.trainTransform, is_test=False)\n        train_dl = DataLoader(train_ds, batch_size=self.batch_size, shuffle=True, pin_memory=True, num_workers=self.num_workers)\n        return train_dl\n        \n    def val_dataloader(self, fold):\n        val_df = self.train_val_df.query(f'fold == {fold}')\n        val_ds = PetData(val_df, self.validTransform, is_test=False)\n        val_dl = DataLoader(val_ds, batch_size=self.batch_size*2, shuffle=False, pin_memory=True, num_workers=self.num_workers)\n        return val_dl\n        \n    def test_dataloader(self):\n        test_ds = PetData(self.test_df, self.validTransform, is_test=True)\n        test_dl = DataLoader(test_ds, batch_size=self.batch_size*2, shuffle=False, pin_memory=True, num_workers=self.num_workers)\n        return test_dl","a5e73184":"class Model(nn.Module):\n    def __init__(self, backbone_name, binary_features=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']):\n        super(Model, self).__init__()\n        self.backbone = create_model(model_name, pretrained=True, num_classes=64)\n        self.feat_embeddings = nn.ModuleList(nn.Embedding(2, 1) for _ in range(len(binary_features)))\n        self.fc = nn.Linear(64 + 1*len(binary_features), 1, bias=True)\n    \n    def forward(self, x, feats):\n        x = self.backbone(x)\n#         return torch.sigmoid(x) + 0.005 # (0.005, 1.005)\n        feats_embedding_list = []\n        for idx in range(len(self.feat_embeddings)):\n            embedding_model = self.feat_embeddings[idx]\n            embedding_input = feats[:, idx]\n            feats_embedding_list.append(embedding_model(embedding_input))\n        feats_embedding = torch.cat(feats_embedding_list, dim=-1)\n        return torch.sigmoid(self.fc(torch.cat([x, feats_embedding], dim=-1))) + 0.005 # the output will be (0.005, 1.005) has the scope of [0.01, 1.].\n        ","6981b169":"from torch.cuda.amp import autocast as autocast","e24bd205":"class Trainer:\n    def __init__(self, num_epochs, lr, wd):\n        self.loss_func = nn.MSELoss()\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.num_epochs = num_epochs\n        self.lr = lr\n        self.wd = wd\n        self.min_loss = 1e3\n        \n    def get_fold_data(self, data, fold):\n        train_dl = data.train_dataloader(fold=fold)\n        val_dl = data.val_dataloader(fold=fold)\n        return train_dl, val_dl\n    \n    def train_fold(self, data, fold, model_name='swin_large_patch4_window7_224'):\n        train_dl, val_dl = self.get_fold_data(data, fold)\n        model = Model(model_name)\n        model.to(self.device)\n        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n        optimizer_grouped_parameters = [\n            {\n                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": self.wd,\n            },\n            {\n                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        optimizer = optim.AdamW(optimizer_grouped_parameters, lr=self.lr)\n        num_training_steps = self.num_epochs * len(train_dl)\n        num_warmup_steps = int(0.1 * num_training_steps)\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n        train_loss_list = [None] * num_training_steps\n        for epoch in range(self.num_epochs):\n            tbar = tqdm(train_dl)\n            epoch_loss = 0.\n            train_step = 0\n            model.train()\n            for batch_idx, batch in enumerate(tbar):\n                x, y, feats = batch\n                x, y, feats = x.to(self.device), y.to(self.device), feats.to(self.device)\n                with autocast():    \n                    y_hat = model(x, feats).squeeze()\n                    loss = self.loss_func(y_hat, y)\n                    loss = torch.sqrt(loss)\n                \n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                \n                train_loss_list[train_step] = loss.detach().cpu().numpy() # petfinder_rmse(y_hat, y)\n                epoch_loss += train_loss_list[train_step]\n                train_step += 1\n                \n                tbar.set_description_str(\"[Train Epoch %d\/%d]\"% (epoch+1, self.num_epochs))\n                tbar.set_postfix_str(\"Loss: %.5f, lr: %.6f\"% (100 * epoch_loss \/ train_step, scheduler.get_last_lr()[0]))\n                \n                del loss, x, y, y_hat, feats\n                gc.collect()\n                \n            val_loss = self.eval_step(val_dl, model, epoch)\n            if val_loss <= self.min_loss:\n                self.min_loss = val_loss\n                torch.save(model.state_dict(), \"model_fold%d.pth\"%fold)\n            \n        del train_dl, val_dl, model, optimizer, scheduler\n        gc.collect()\n        return train_loss_list\n    \n    def eval_step(self, val_dl, model, epoch):\n        tbar = tqdm(val_dl)\n        epoch_loss = 0.\n        eval_step = 0\n        model.eval()\n        for batch_idx, batch in enumerate(tbar):\n            x, y, feats = batch\n            x, y, feats = x.to(self.device), y.to(self.device), feats.to(self.device)\n            with torch.no_grad():\n                y_hat = model(x, feats).squeeze()\n            loss = self.loss_func(y_hat, y)\n            epoch_loss += torch.sqrt(loss).detach().cpu().numpy()\n            eval_step += 1\n            \n            tbar.set_description_str(\"[Val Epoch %d]\"% (epoch+1))\n            tbar.set_postfix_str(\"Loss: %.5f\"% (100 * epoch_loss \/ eval_step))\n            \n            del x, y, y_hat\n            gc.collect()\n        \n        return epoch_loss \/ eval_step","70c77117":"num_epochs, lr, wd = 5, 2e-5, 5e-4\nn_split = 10\nimg_size = 224 # 384\nwith_22k = False\n\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\nif img_size == 224:\n    if with_22k:\n        model_name = 'swin_large_patch4_window7_224_in22k'\n        !cp ..\/input\/swin-large-models\/swin_large_patch4_window7_224_22k.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n    else:\n        model_name = 'swin_large_patch4_window7_224'\n        !cp ..\/input\/swin-large-models\/swin_large_patch4_window7_224_22kto1k.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n    batch_size = 32\nelse:\n    if with_22k:\n        model_name = 'swin_large_patch4_window12_384_in22k'\n        !cp ..\/input\/swin-large-models\/swin_large_patch4_window12_384_22k.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n    else:\n        model_name = 'swin_large_patch4_window12_384'\n        !cp ..\/input\/swin-large-models\/swin_large_patch4_window12_384_22kto1k.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n    batch_size = 16\n    \ndata = Data(batch_size=batch_size, img_size=img_size, n_split=n_split)\ntrainer = Trainer(num_epochs, lr, wd)","293fe23b":"for fold in range(n_split):\n    print(\"---------------------------fold-%d-------------------------------\"%fold)\n    train_loss_list = trainer.train_fold(data, fold, model_name=model_name)\n    plt.plot(train_loss_list)","886f40e8":"# 1 Data","418c94e0":"# 1 Data","e9182853":"# 3 Train","4d1ac631":"norm_score = [0.01, 1.0]\n\nthe output will be in (0.005, 1.005)\n\nsigmoid(y_hat) + 0.005","09c170ec":"```\nmodel_names = [\n    'swin_large_patch4_window7_224',\n    'swin_large_patch4_window7_224_in22k',\n    'swin_large_patch4_window12_384',\n    'swin_large_patch4_window12_384_in22k'\n]\n```","ea9c552f":"# 2 Model"}}