{"cell_type":{"d690e1b7":"code","f84e3763":"code","642eb604":"code","e010a755":"code","7cd4af92":"code","de04c8ec":"code","36e12e9f":"code","d89c467f":"code","fbf6a7d7":"code","72f503c5":"code","a7afbcb6":"code","5427106d":"code","4b0e05a5":"code","155a0e4c":"code","48793170":"code","66e412c6":"code","fd8d39e4":"code","21bb8896":"code","ab60bcd0":"code","84a996a0":"code","0f977ca1":"code","33e0c428":"markdown","bce86268":"markdown","33f9956e":"markdown","2cb8c364":"markdown","3be82104":"markdown","a63114ea":"markdown"},"source":{"d690e1b7":"!pip install fastai==2.0.9\n!pip install python_speech_features","f84e3763":"import random, os\nimport numpy as np\nimport torch\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport librosa\nimport IPython.display as ipd\nimport python_speech_features as psf","642eb604":"def seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()","e010a755":"def plot_sound(path):\n    plt.figure(figsize=(14, 5))\n    x, sr = librosa.load(path)\n    print(\"length {}, sample-rate {}\".format(x.shape, sr))\n    librosa.display.waveplot(x, sr=sr)\n    return x","7cd4af92":"path = Path('\/kaggle\/input\/audio-cats-and-dogs\/')\ntrain = path \/ 'cats_dogs' \/ 'train'\ncat0 = (train \/ 'cat').ls()[0]\ndog0 = (train \/ 'dog').ls()[0]","de04c8ec":"cat_audio = plot_sound(cat0)","36e12e9f":"ipd.Audio(cat0)","d89c467f":"_ = plot_sound(dog0)","fbf6a7d7":"ipd.Audio(dog0)","72f503c5":"def audio_to_melspectrogram(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(audio, \n                                                 sr=conf.sampling_rate,\n                                                 n_mels=conf.n_mels,\n                                                 hop_length=conf.hop_length,\n                                                 n_fft=conf.n_fft,\n                                                 fmin=conf.fmin,\n                                                 fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    spectrogram = spectrogram.astype(np.float32)\n    return spectrogram","a7afbcb6":"def show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n                             sr=conf.sampling_rate, hop_length=conf.hop_length,\n                            fmin=conf.fmin, fmax=conf.fmax)\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(title)\n    plt.show()","5427106d":"class conf:\n    sampling_rate = 44100\n    duration = 2\n    hop_length = 347*duration\n    fmin = 20\n    fmax = sampling_rate \/\/ 2\n    n_mels = 128\n    n_fft = n_mels * 20\n    samples = sampling_rate * duration","4b0e05a5":"cat_spectogram = audio_to_melspectrogram(conf, cat_audio)","155a0e4c":"show_melspectrogram(conf, cat_spectogram)","48793170":"def im_from_audio(fn, sample_rate=44100, window_length=0.05, window_step=0.0045, NFFT=2205):\n  \n  # Load the audio into an array (signal) at the specified sample rate\n  signal, sr = librosa.load(fn, sr=sample_rate)\n\n  # preemphasis\n  signal = psf.sigproc.preemphasis(signal, coeff=0.95)\n\n  # get specrogram\n  # Get the frames\n  frames = psf.sigproc.framesig(signal, \n                                  window_length*sample_rate, \n                                  window_step*sample_rate, \n                                  lambda x:np.ones((x,)))        # Window function \n    \n  # magnitude Spectrogram\n  spectrogram = np.rot90(psf.sigproc.magspec(frames, NFFT))\n  \n  # get rid of high frequencies\n  spectrogram = spectrogram[512:,:]\n\n  # normalize in [0, 1]\n  spectrogram -= spectrogram.min(axis=None)\n  spectrogram \/= spectrogram.max(axis=None)        \n\n  # Clip to max 512, 512\n  spectrogram = spectrogram[:512, :512]\n  \n  return spectrogram ","66e412c6":"cats = pd.DataFrame({'cats': (train\/'cat').ls()})\ncats['labels'] = 'cat'\ndogs = pd.DataFrame({'cats': (train\/'dog').ls()})\ndogs['labels'] = 'dog'","fd8d39e4":"train_df = pd.concat([cats, dogs], axis=0)\ntrain_df.columns = ['fname', 'labels']\nshuffle = train_df.sample(n=len(train_df), random_state=42)\nshuffle","21bb8896":"def get_x(fn):\n\n  # Use our function from earlier\n  spectrogram = im_from_audio(fn) # a 2D array\n\n  # Pad to make sure it is 512 x 512\n  w, h = spectrogram.shape\n  spectrogram = np.pad(spectrogram, [(0, 512-w), (0, 512-h)])\n\n   # Scale to (0, 255)\n  spectrogram  -= spectrogram.min()\n  spectrogram *= 255.0\/spectrogram.max()\n\n  # Make it uint8\n  im_arr = np.array(spectrogram, np.uint8)\n\n  # Make it rgb (hint - some fun tricks you can do here!)\n  r = im_arr\n  g = im_arr\n  b = im_arr\n\n  return np.stack([r, g, b], axis=-1)","ab60bcd0":"def get_fns(_):\n  return shuffle['fname']\n\ndef get_y(fname):\n  return shuffle.loc[shuffle.fname == fname].labels.values[0]\n\ndblock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),    \n    get_items=get_fns,\n    get_x=get_x,\n    get_y=get_y, \n    splitter=RandomSplitter(valid_pct=0.1),\n)","84a996a0":"dls = dblock.dataloaders(Path(''), bs=32)\ndls.show_batch()","0f977ca1":"learn = cnn_learner(dls, resnet18, metrics=[accuracy])\nlearn.fine_tune(3)","33e0c428":"Set seed to makesure the code is reproducible ","bce86268":"links:\n- https:\/\/towardsdatascience.com\/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n- https:\/\/medium.com\/analytics-vidhya\/understanding-the-mel-spectrogram-fca2afa2ce53","33f9956e":"Lets visualize and listen to the first dog in the dataset.","2cb8c364":"We can observe that cats have sharper peaks and a shrill meows. Where as dogs tend to have homogeneous frequency and long barks \/ howls.\nTODO:\nexplain mel spectogram and importance\nexplain parameters","3be82104":"This is great! We have a digital representation of an audio signal that we can work with. Welcome to the field of signal processing! ","a63114ea":"This function will be used to plot samples of cats and dogs. We will load the first sample to visualize the frequencey and listen to the sound later."}}