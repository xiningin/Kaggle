{"cell_type":{"83bfbaa0":"code","2cd89e95":"code","9773e3d6":"code","946bc0ef":"code","6e39f8da":"code","cf66b248":"code","0a6a044d":"code","96da0e9e":"code","1794546f":"code","b2d2ca3c":"code","a925924d":"code","d3938c26":"code","b55686f6":"code","835b0bea":"code","524fc27e":"code","30ef0208":"code","6f2285e8":"code","1d807ab4":"markdown","47558fbd":"markdown","c34c136a":"markdown","e70c88c6":"markdown","0ce4840e":"markdown","377b62cc":"markdown","72c83fb3":"markdown","20b20c7b":"markdown","43771502":"markdown"},"source":{"83bfbaa0":"%matplotlib inline\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport os\nimport ast\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nimport seaborn as sns\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom keras.layers import Conv2D, MaxPooling2D, Input, concatenate\nfrom keras.layers import Dense, Dropout, Flatten, Activation,GlobalAveragePooling2D\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom ast import literal_eval\nfrom keras.preprocessing.sequence import pad_sequences\nstart = dt.datetime.now()","2cd89e95":"\nDP_DIR = '..\/input\/shuffle-csvs\/'\nINPUT_DIR = '..\/input\/quickdraw-doodle-recognition\/'\nBASE_SIZE = 256\nNCSVS = 100\nNCATS = 340\nnp.random.seed(seed=1987)\ntf.set_random_seed(seed=1987)\n\ndef f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\ndef list_all_categories():\n    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n    return sorted([f2cat(f) for f in files], key=str.lower)","9773e3d6":"def apk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    if len(predicted) > k:\n        predicted = predicted[:k]\n    score = 0.0\n    num_hits = 0.0\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits \/ (i + 1.0)\n    if not actual:\n        return 0.0\n    return score \/ min(len(actual), k)\n\ndef mapk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\ndef preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","946bc0ef":"STEPS = 800\nEPOCHS = 30\nsize = 128\nbatchsize = 340","6e39f8da":"base_model = MobileNet(input_shape=(size, size,3), alpha=1., weights=\"imagenet\", include_top = False)\ninp = base_model.input\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(NCATS, activation='softmax')(x)\nmodel = Model(inp, x)\n\nbase_model = Sequential(model.layers[:-2])","cf66b248":"base_model.summary()","0a6a044d":"from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv1D, LSTM, Dense, Dropout, Bidirectional\nfrom keras.layers import CuDNNLSTM as LSTM # this one is about 3x faster on GPU instances\ninp = Input(shape = (70,3))\n\nx = BatchNormalization()(inp)\n\n# # filter count and length are taken from the script https:\/\/github.com\/tensorflow\/models\/blob\/master\/tutorials\/rnn\/quickdraw\/train_model.py\nx = Conv1D(256, (5,), activation = \"relu\")(x)\nx = Dropout(0.2)(x)\nx = Conv1D(256, (5,), activation = 'relu')(x)\nx = Dropout(0.2)(x)\nx = Conv1D(256, (3,), activation = 'relu')(x)\nx = Dropout(0.2)(x)\nx = Bidirectional(LSTM(128, return_sequences = True))(x)\nx = Dropout(0.2)(x)\nx = Bidirectional(LSTM(128, return_sequences = False))(x)\nx = Dropout(0.2)(x)\nx = Dense(512, activation = 'relu')(x)\nx = Dense(NCATS, activation='softmax')(x)\nstroke_read_model = Model(inp,x)\nstroke_read_model.compile(optimizer = 'adam', \n                          loss = 'categorical_crossentropy', \n                          metrics = ['categorical_accuracy', top_3_accuracy])\nstroke_read_model = Sequential(stroke_read_model.layers[:-1])\nstroke_read_model.summary()","96da0e9e":"inp = base_model.input\ny = base_model.output\ny = GlobalAveragePooling2D()(y)\n\ninp2 = Input(shape = (70, 3))\nz = stroke_read_model(inp2)\nx = concatenate([y, z])\nx = Dropout(0.3)(x)\nx = Dense(NCATS, activation='softmax')(x)\nmodel = Model([inp, inp2], x)\n\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy',\n              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])","1794546f":"def _stack_it(raw_strokes):\n    \"\"\"preprocess the string and make \n    a standard Nx3 stroke vector\"\"\"\n    stroke_vec = literal_eval(raw_strokes) # string->list\n    # unwrap the list\n    in_strokes = [(xi,yi,i)  \n     for i,(x,y) in enumerate(stroke_vec) \n     for xi,yi in zip(x,y)]\n    c_strokes = np.stack(in_strokes)\n    # replace stroke id with 1 for continue, 2 for new\n    c_strokes[:,2] = [1]+np.diff(c_strokes[:,2]).tolist()\n    c_strokes[:,2] += 1 # since 0 is no stroke\n    # pad the strokes with zeros\n    return pad_sequences(c_strokes.swapaxes(0, 1), \n                         maxlen=70, \n                         padding='post').swapaxes(0, 1)\n","b2d2ca3c":"def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n    for t, stroke in enumerate(raw_strokes):\n        for i in range(len(stroke[0]) - 1):\n            color = 255 - min(t, 10) * 13 if time_color else 255\n            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n    if size != BASE_SIZE:\n        return cv2.resize(img, (size, size))\n    else:\n        return img\n\ndef image_generator_xd(size, batchsize, ks, lw=6, time_color=True):\n    while True:\n        for k in np.random.permutation(ks):\n            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n            for df in pd.read_csv(filename, chunksize=batchsize):\n                df['drawing1'] = df['drawing'].apply(ast.literal_eval)\n                x = np.zeros((len(df), size, size, 1))\n                for i, raw_strokes in enumerate(df.drawing1.values):\n                    x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw,\n                                             time_color=time_color)\n                x = np.repeat(x, 3, axis =3)\n                x = preprocess_input(x).astype(np.float32)\n                \n                df['drawing'] = df['drawing'].map(_stack_it)\n                x2 = np.stack(df['drawing'], 0)\n                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n                yield [x, x2], y\n\ndef df_to_image_array_xd(df, size, lw=6, time_color=True):\n    df['drawing1'] = df['drawing'].apply(ast.literal_eval)\n    x = np.zeros((len(df), size, size, 1))\n    \n    for i, raw_strokes in enumerate(df.drawing1.values):\n        x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=time_color)\n    x = np.repeat(x, 3, axis =3)\n    x = preprocess_input(x).astype(np.float32)\n    df['drawing'] = df['drawing'].map(_stack_it)\n    x2 = np.stack(df['drawing'], 0)\n    return [x,x2]","a925924d":"train_datagen = image_generator_xd(size=size, batchsize=batchsize, ks=range(NCSVS - 1))\nval_datagen = image_generator_xd(size=size, batchsize=batchsize, ks=range(NCSVS - 1, NCSVS))","d3938c26":"callbacks = [\n    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3,\n                      min_delta=0.005, mode='max', cooldown=3, verbose=1),\n    ModelCheckpoint(\"mobilenet_lstm.model\",monitor='val_top_3_accuracy', \n                                   mode = 'max', save_best_only=True, verbose=1)\n]\nhists = []\nhist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n    validation_data=val_datagen, validation_steps = 100,\n    callbacks = callbacks\n)\nhists.append(hist)","b55686f6":"hist_df = pd.concat([pd.DataFrame(hist.history) for hist in hists], sort=True)\nhist_df.index = np.arange(1, len(hist_df)+1)\nfig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\naxs[0].plot(hist_df.val_categorical_accuracy, lw=5, label='Validation Accuracy')\naxs[0].plot(hist_df.categorical_accuracy, lw=5, label='Training Accuracy')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].grid()\naxs[0].legend(loc=0)\naxs[1].plot(hist_df.val_categorical_crossentropy, lw=5, label='Validation MLogLoss')\naxs[1].plot(hist_df.categorical_crossentropy, lw=5, label='Training MLogLoss')\naxs[1].set_ylabel('MLogLoss')\naxs[1].set_xlabel('Epoch')\naxs[1].grid()\naxs[1].legend(loc=0)\nfig.savefig('hist.png', dpi=300)\nplt.show();","835b0bea":"df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS)), nrows=34000)\nfor i in range(10):\n    valid_df = df.loc[i*3400:(i+1)*3400,:].copy()\n    x_valid, x2 = df_to_image_array_xd(valid_df, size)\n    y_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\n    print(x_valid.shape, y_valid.shape)\n    print('Validation array memory {:.2f} GB'.format(x_valid.nbytes \/ 1024.**3 ))\n    valid_predictions = model.predict([x_valid, x2], batch_size=128, verbose=1)\n    map3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions).values)\n\n    print('Map3: {:.3f}'.format(map3))","524fc27e":"test = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\n\nfor i in range(10):\n    end = min((i+1)*11220, 112199)\n    subtest= test.iloc[i*11220:end].copy().reset_index(drop=True)\n    x_test = df_to_image_array_xd(subtest, size)\n\n    test_predictions = model.predict(x_test, batch_size=128, verbose=1)\n\n    top3 = preds2catids(test_predictions)\n    cats = list_all_categories()\n    id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\n    top3cats = top3.replace(id2cat)\n    subtest['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n    subtest.head()\n    if i ==0:\n        submission = subtest[['key_id', 'word']]\n    else: \n        submission = submission.append(subtest[['key_id', 'word']], ignore_index=True)\n","30ef0208":"submission.to_csv('lstm_mobilenet.csv', index=False)\nsubmission.head()\nsubmission.shape","6f2285e8":"end = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","1d807ab4":"### This model combines two branches: MobileNet and Bidirectional LSTM. \n\nThe Mobilenet branch is largely based on Beluga's kernel https:\/\/www.kaggle.com\/gaborfodor\/greyscale-mobilenet-lb-0-892 and the LSTM branch is inspired by Kevin's kernel, with modifications https:\/\/www.kaggle.com\/kmader\/quickdraw-baseline-lstm-reading-and-submission \n\nThe performance depends on what you use for the two branches. I got up to 0.925 using this architecture. Inspired by this paper here: https:\/\/arxiv.org\/abs\/1804.01401\n![image.png](attachment:image.png)","47558fbd":"## Data Generator","c34c136a":"## Create Submission","e70c88c6":"### First 20 epochs","0ce4840e":"## LSTM branch","377b62cc":"### Combining two branches","72c83fb3":"### LSTM Preprocessing","20b20c7b":"### Change number of epochs here when you want to train. 2 epochs for illustration only. ","43771502":"## MobileNet branch\n\nMobileNets are based on a streamlined architecture that uses depthwise separable convolutions to build light weight deep neural networks.\n\n[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https:\/\/arxiv.org\/pdf\/1704.04861.pdf)"}}