{"cell_type":{"25f5ead0":"code","cac19449":"code","81346946":"code","2f75e592":"code","183d095e":"code","7a0ef274":"code","1fe40fdc":"code","4de895e9":"code","d40f3193":"code","7b013d40":"code","19f01fc3":"code","428870af":"code","c7b67103":"code","90ecac56":"code","e0e013cd":"code","498dda94":"code","4c69fb3d":"code","bef91f4a":"code","d78461ee":"code","0ab91c6e":"code","529e65f3":"code","e0f5ef35":"code","214d8feb":"code","51f09653":"code","78b2232f":"code","8c90bee1":"code","3f02569d":"markdown","95fd76cf":"markdown","b46546f3":"markdown","15013cfb":"markdown","d4f97739":"markdown","fdd61e57":"markdown","30b8f04b":"markdown","60b59605":"markdown","ca65a16b":"markdown","0a534eea":"markdown","8cb2a5d2":"markdown","96e7cb8f":"markdown","186ce6a9":"markdown","bb7b0f1d":"markdown","322db541":"markdown"},"source":{"25f5ead0":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\/Kannada-MNIST\"))","cac19449":"from keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator","81346946":"from sklearn.model_selection import train_test_split","2f75e592":"path_in = '..\/input\/Kannada-MNIST\/'","183d095e":"train_data = pd.read_csv(path_in+'train.csv')\nval_data = pd.read_csv(path_in+'Dig-MNIST.csv')\ntest_data = pd.read_csv(path_in+'test.csv')\nsamp_subm = pd.read_csv(path_in+'sample_submission.csv')","7a0ef274":"dict_data = dict(zip(range(0, 10), (((train_data['label'].value_counts()).sort_index())).tolist()))\nnames = list(dict_data.keys())\nvalues = list(dict_data.values())\nplt.bar(names, values)\nplt.grid()\nplt.show()","1fe40fdc":"dict_data = dict(zip(range(0, 10), (((val_data['label'].value_counts()).sort_index())).tolist()))\nnames = list(dict_data.keys())\nvalues = list(dict_data.values())\nplt.bar(names, values)\nplt.grid()\nplt.show()","4de895e9":"print('# train samples:', len(train_data.index))\nprint('# val samples:', len(val_data.index))\nprint('# test samples:', len(test_data.index))","d40f3193":"X_train = train_data.copy()\ny_train = train_data['label']\ndel X_train['label']\nX_val = val_data.copy()\ny_val = val_data['label']\ndel X_val['label']\nX_test = test_data.copy()\ndel X_test['id']\ny_train = to_categorical(y_train, num_classes = 10)\ny_val = to_categorical(y_val, num_classes = 10)","7b013d40":"X_train = X_train.values.reshape(-1,28,28,1)\nX_val = X_val.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)","19f01fc3":"X_train = X_train.astype('float32')\/255\nX_val = X_val.astype('float32')\/255\nX_test = X_test.astype('float32')\/255","428870af":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2020)","c7b67103":"fig, axs = plt.subplots(2, 5, figsize=(15, 6))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\nfor i in range(10):\n    idx = train_data[train_data['label']==i].index[0]\n    axs[i].imshow(X_train[idx][:,:,0], cmap='gray')\n    axs[i].set_title(y_train[idx].argmax())\n    axs[i].set_xticklabels([])\n    axs[i].set_yticklabels([])","90ecac56":"model = Sequential()\nmodel.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2, padding='same'))\n\nmodel.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\nmodel.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=2, padding='same'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","e0e013cd":"optimizer = RMSprop(lr=0.001)","498dda94":"\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])","4c69fb3d":"model.summary()","bef91f4a":"epochs = 50\nbatch_size = 512","d78461ee":"datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.10,\n        width_shift_range=0.15,\n        height_shift_range=0.15,\n        horizontal_flip=False,\n        vertical_flip=False)\ndatagen.fit(X_train)","0ab91c6e":"# Fit the model\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    epochs=epochs,\n                    validation_data=(X_val,y_val),\n                    steps_per_epoch=X_train.shape[0] \/\/ batch_size)","529e65f3":"y_test = model.predict(X_test)","e0f5ef35":"y_test_classes = np.argmax(y_test, axis = 1)","214d8feb":"output = pd.DataFrame({'id': samp_subm['id'],\n                       'label': y_test_classes})\noutput.to_csv('submission.csv', index=False)","51f09653":"loss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, loss, 'bo', label='loss_train')\nplt.plot(epochs, loss_val, 'b', label='loss_val')\nplt.title('value of the loss function')\nplt.xlabel('epochs')\nplt.ylabel('value of the loss function')\nplt.legend()\nplt.grid()\nplt.show()","78b2232f":"acc = history.history['acc']\nacc_val = history.history['val_acc']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, acc, 'bo', label='accuracy_train')\nplt.plot(epochs, acc_val, 'b', label='accuracy_val')\nplt.title('accuracy')\nplt.xlabel('epochs')\nplt.ylabel('value of accuracy')\nplt.legend()\nplt.grid()\nplt.show()","8c90bee1":"del model","3f02569d":"# Load Libraries","95fd76cf":"# Analyse the results","b46546f3":"# Define Model\nWe use a simple CNN model.","15013cfb":"# A Look on the labels\nThe lables are equally distributed, so we need no class weights for the CNN.","d4f97739":"# Predict Test data","fdd61e57":"# Overview","30b8f04b":"# Write Output For Submission","60b59605":"# Scale data","ca65a16b":"# Some Examples","0a534eea":"# Train data","8cb2a5d2":"# Load Data\nWe use the Dig-MNIST file for valtidation data.","96e7cb8f":"# Split train data to get val data","186ce6a9":"# Intro \nWelcome To The [Kannada-MINST](https:\/\/www.kaggle.com\/c\/Kannada-MNIST) Competition\n![](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/Kannada-MNIST\/kannada.png)\nThis notebook is a starter code for all beginners and easy to understand. To predict the test data a simple CNN is used.\n\nSome helpful informations for the image classification of a MINST dataset you will find her:\n\nhttps:\/\/towardsdatascience.com\/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n\n\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","bb7b0f1d":"# Define train, val and test set","322db541":"# Define the ImageDataGenerator"}}