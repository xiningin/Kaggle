{"cell_type":{"d60dd0ae":"code","6adf8c6b":"code","dbcda8eb":"code","f8fccc3b":"code","d357d8e5":"code","7e2faac9":"code","8c6c12c3":"code","aedeb2e9":"code","43881630":"code","653b1688":"code","0707eade":"code","177d18e7":"code","f0df336b":"code","ec3d3bbd":"code","1a663237":"code","03cf8102":"code","fae32eb5":"code","d6d7b385":"code","d69ab5e8":"code","87491f56":"code","06dc26d6":"code","cbbef163":"code","cdc4116b":"code","6d313565":"code","9aa64916":"markdown","438945ec":"markdown","4d866c5d":"markdown","3f08076c":"markdown","b6ce6c0d":"markdown","7d8f4178":"markdown","06e9b999":"markdown","e5c80201":"markdown","b01aa0be":"markdown","d7a59781":"markdown","da7cab43":"markdown","504d2248":"markdown","dc169f11":"markdown","b8170848":"markdown","58eec3a7":"markdown","9f66c233":"markdown","3df98bd3":"markdown","da0aeaad":"markdown","8dfc3cee":"markdown","72b78562":"markdown","f3efcfdf":"markdown","0cc33e7b":"markdown","ab9e6b1b":"markdown","8b8a85bd":"markdown","309777fb":"markdown"},"source":{"d60dd0ae":"import pandas as pd","6adf8c6b":"import seaborn as sns\nimport matplotlib.pyplot as plt","dbcda8eb":"import tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.__version__)","f8fccc3b":"pokemon = pd.read_csv(\"..\/input\/pokemon.csv\")\npokemon.head()","d357d8e5":"pokemon.info(verbose=False)\npokemon.describe(include=\"all\")","7e2faac9":"pokemon = pokemon.fillna(\"None\")","8c6c12c3":"pokemon[\"Legendary\"] = pokemon[\"Legendary\"].map(int)","aedeb2e9":"t1 = pd.get_dummies(pokemon[\"Type 1\"], prefix='T1')\nt2 = pd.get_dummies(pokemon[\"Type 2\"], prefix='T2')\n\npokemon = pd.concat([pokemon, t1, t2], axis=1)","43881630":"pokemon = pokemon.drop([\"Type 1\", \"Type 2\", \"Name\"], axis=1)","653b1688":"pokemon.info(verbose=False)\npokemon.head()","0707eade":"plt.figure(figsize=(11, 10))\nsns.heatmap(pokemon.corr(), cmap='RdBu', vmax=1, vmin=-1);","177d18e7":"plt.figure(figsize=(11, 10))\nsns.heatmap(pokemon[pokemon[\"Generation\"] == 1].corr(), cmap='RdBu', vmax=1, vmin=-1);","f0df336b":"battles = pd.read_csv(\"..\/input\/battles.csv\")\nbattles.head()","ec3d3bbd":"battles.describe(include=\"all\")","1a663237":"def merge_data(battles):\n    # hacemos dos copias de los datos para unirlos como primer y segundo pokemon.\n    first = pokemon.rename(columns=lambda x: \"F_%s\" % x)\n    second = pokemon.rename(columns=lambda x: \"S_%s\" % x)\n    \n    # Hacemos el join y borramos los datos que nos sobran.\n    # tenemos que hacer un `sort_values` porque los merge desordenan los datos \n    # y los necesitamos ordenados para enviar los datos correctamente.\n    return battles \\\n        .merge(first, left_on=\"First_pokemon\", right_on=\"F_#\") \\\n        .merge(second, left_on=\"Second_pokemon\", right_on=\"S_#\") \\\n        .sort_values(['battle_number']) \\\n        .reset_index(drop=True) \\\n        .drop([\"battle_number\", \"First_pokemon\", \"Second_pokemon\", \"F_#\", \"S_#\"], axis=1)\n\ntrain = merge_data(battles)\ntrain.head()","03cf8102":"test = pd.read_csv(\"..\/input\/test.csv\")\ntest.head()","fae32eb5":"test = merge_data(test)\n\ntest.head()","d6d7b385":"# Input\nX = train.drop([\"Winner\"], axis=1).values\n\n# Labels\nY = train[\"Winner\"].values\n\n# Nuestra red utilizar\u00e1 one hot encoding tambien para la salida\ny = keras.utils.to_categorical(Y)","d69ab5e8":"assert X.shape[0] == y.shape[0]\ninput_dim = X.shape[1]\noutuput_dim = y.shape[1]","87491f56":"model = keras.models.Sequential([\n    keras.layers.Dense(256, activation=tf.nn.relu, input_shape=(input_dim,)),\n    keras.layers.Dense(256, activation=tf.nn.relu),\n    keras.layers.Dense(256, activation=tf.nn.relu),\n    keras.layers.Dense(outuput_dim, activation=tf.nn.sigmoid)\n])\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nmodel.summary()","06dc26d6":"# validation_split = 0.0 # for submision\nvalidation_split = 0.2 # for training\n\nhistory = model.fit(X, y, workers=4, epochs=50, verbose=2, validation_split=validation_split)","cbbef163":"# Convertimos el historico a dataframe (formato de pandas)\ndf = pd.DataFrame(history.history)\n\n# creamos un espacio para pintar nuestros graficos\nf = plt.figure(figsize=(16, 5))\n\nrows = 1\ncols = 2\n\n# Gr\u00e1fico a la izquierda, vemos el accuracy de nuestro conjunto de entrada vs conjunto de validaci\u00f3n.\nax = f.add_subplot(rows, cols, 1)\nsns.lineplot(data=df[[\"acc\", \"val_acc\"]].iloc[3:-1])\n\n\n# Gr\u00e1fico a la derecha, vemos el loss de nuestro conjunto de entrada vs conjunto de validaci\u00f3n.\nax = f.add_subplot(rows, cols, 2)\nsns.lineplot(data=df[[\"loss\", \"val_loss\"]].iloc[3:-1]);","cdc4116b":"prediction = model.predict_classes(test.values)\ndf_submission = pd.DataFrame({\"Winner\": prediction}, index = test.index.rename(\"battle_number\"))\ndf_submission.head()","6d313565":"df_submission.to_csv(\"v1.csv\")","9aa64916":"## Hora de entrenar\n\nVamos a entrenar nuestro modelo, para ello lo primero es elegir el split de validacion.\n    * 0.2 => dejamos un 20% de los datos fuera del training y asi podemos evaluar si nuestro modelo sufre de overfitting.\n    * 0.0 => ya estamos contentos con nuestro modelo y vamos a hacer un ultimo entrenamiento con todos los datos de nuestro dataset para ganar la mayor precision posible.\n    \nEn el proceso de encontrar nuestro modelo perfecto tambien podemos ir tocando el parametro `epochs` para entrenamientos mas largos o mas cortos","438945ec":"Si echamos un vistazo a la fila count podemos ver que nos faltan algunos valores tanto en `Name` como en `Type 2`.\n\n* El caso de Name, no nos preocupa ya que posteriormente desecharemos este dato.\n* El caso de `Type 2` es debido a que muchos pokemons carecen de un segundo tipo.\n\nYa que ambos son de tipo string vamos a rellenarlos con la palabra `None`.","4d866c5d":"Y por ultimo rellenamos el csv.","3f08076c":"Para la red neuronal usaremos [keras](https:\/\/keras.io\/) sobre [tensorflow](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/) que nos facilitar\u00e1 la vida much\u00edsimo.","b6ce6c0d":"### Inputs y labels\n\nYa estamos casi llegando al final. La ultima etapa es separar los datos de entrada de las labels de salida que queremos predecir.","7d8f4178":"Buenas! Comparto este Kernel como ejemplo de como hacer una soluci\u00f3n sencilla con Pandas para manejar datos y Keras para hacer una red neuronal.\n\nLlevo poco con ML asi que cualquier feedback sera mas que bienvenido :D","06e9b999":"### Analisis visual de pokemon.csv\n\nAntes de continuar vamos a hacer una inspeccion visual de los datos","e5c80201":"Por ultimo, antes de empzar con las batallas es curioso echarle un ojo a los pokemons de la primera generaci\u00f3n.\nPodemos ver que como cada generacion tiene cierta \"tematica\". (ya pod\u00eda verse en la primera grafica viendo que no existe una correlacion nula entre las diferentes generaciones)\n\nDebido a esto podemos ver que la correlaci\u00f3n entre los diferentes tipos tiene picos mas acusados, a diferencia de los datos globales.\n\nPor ejemplo todos los pokemon de tipo roca de la primera generacion eran Roca-Tierra (pokemon de cuevas) o Roca-Agua (pokemon fosiles). O por ejemplo no existian pokemon de tipo unico voladores sino que minimo era Volador-Normal.\n\nEsto tambi\u00e9n afecta a la ausencia de ciertas combinaciones de tipos.","b01aa0be":"Como vemos no tenemos ningun NaN asi que pasamos a enriquecer los datos.","d7a59781":"### Carga de test.csv\n\ncargamos los datos de test","da7cab43":"Para hacer graficos nos ayudaremos de [seaborn](https:\/\/seaborn.pydata.org\/) que funciona sobre [pyplot](https:\/\/matplotlib.org\/tutorials\/introductory\/pyplot.html) pero de manera mas f\u00e1cil y con un resultado mas atractivo.","504d2248":"### Carga de battles.csv\nCargamos y anlizamos r\u00e1pidamente los datos","dc169f11":"Como podemos ver tenemos la misma estructura (excepto `Winners`) asi querealizamos el mismo proceso que a los datos de entrenamiento","b8170848":"En esta matriz de correlacion podemos ver las variables no correlacionadas en gris, las correlaciones positivas en azul y en rojo las negativas.\n\nAlgunos datos que podemos sacar de aqui son:\n\n* HP, Atack, Defense, Sp.Atack, Sp.Defense, Speed y Legendary estan correlacionados.\n\n  * Esto se debe a que en esta lista se encuentran diferentes pokemons y sus evoluciones, y cuando un pokemon evoluciona mejoran todas sus stats y no empeora ninguna.\n  * Algo similar pasa con los legendarios, ya que son pokemons especiales que tienen siempre unas stats mas altas que la media.\n        \n* Podemos analizar como se relacionan estas stats con los diferentes tipos.\n    * Llama la atencion el tipo bicho, normal y none que tienen correlacion negativa. Es decir estos pokemons tienen peores stats que el resto de los pokemons. Es logico pues tanto normal como none (falta de un segundo tipo) se encuentra en los pokemons m\u00e1s basicos, en ocasiones sin una tercera evoluci\u00f3n.\n    * Tambien llama la atenci\u00f3n el tipo drag\u00f3n que al igual que los legendarios garantiza una subida en todas las stats. En ocasiones este tipo se relaciona con terceras ultimas evoluciones y legendarios.\n    * Tambien podemos extraer que como ser\u00eda de esperar los pokemon acero y roca son bastante defensivos y lentos. Mientras tanto, los voladores son pokemons que destacan en su velocidad.\n\n* Podemos ver tambien otras dos zonas de correlaciones bajas pero negativas en los `T1_*` vs `T1_*` y `T2_*` vs `T2_*`\n    * Esto encaja precisamente con que cada tipo intenta diferenciarse de los demas.","58eec3a7":"por ultimo vamos pasar las variables de categoricas `Type 1` y `Type 2` a [one hot encoding](https:\/\/machinelearningmastery.com\/why-one-hot-encode-data-in-machine-learning\/)","9f66c233":"vemos que `Legendary` es de tipo `bool`, y dado que tenemos previsto usar una red neuronal lo mejor sera pasarlo a `int`.","3df98bd3":"Para construir nuestro modelo vamos a usar keras, una libreria que simplifica el uso de tensorflow para la construccion de redes neuronales basadas en capas.\n\nEn nuestro caso tendremos una Red de 4 capas.\nLas 3 primeras de 256 neuronas y una funcion de activacion [ReLu](https:\/\/ailephant.com\/glossary\/relu-function\/) y una ultima de 2 neuronas con una funci\u00f3n [sigmoide](https:\/\/ailephant.com\/glossary\/sigmoid-function\/).\n\nComo optimizador utilizaremos [adam optimizer](http:\/\/ruder.io\/optimizing-gradient-descent\/index.html#adam)\ny como funcion de perdida `binary_crossentropy` que es el apropiado para redes con salida binaria\n\nPor ultimo a\u00f1adimos accuracy a las metricas para predecir nuestra puntuaci\u00f3n!","da0aeaad":"Por ultimo borramos los campos que no queremos.","8dfc3cee":"## predicciones y csv de salida\n\nSolo nos queda hacer nuestra predicci\u00f3n","72b78562":"### Carga de pokemon.csv\nCargamos nuestros datos desde el csv, y hacemos una peque\u00f1a inspecci\u00f3n.","f3efcfdf":"Veamos como ha quedado:","0cc33e7b":"Ya tenemos todos nuestros datos de pokemons como `int`, y podremos usarlo con nuestra red neuronal.","ab9e6b1b":"## Red neuronal (Fully connected)\n\nPrimero definimos las dimensiones de entrada y salida de nuestra red","8b8a85bd":"## Carga de datos","309777fb":"## Inicializacion del proyecto\nLo primero ser\u00e1 cargar la liberias que vamos a usar.\n\nPara el manejo de datos usaremos [pandas](http:\/\/pandas-docs.github.io\/pandas-docs-travis\/getting_started\/index.html) que nos proporciona muchas funciones para el manejo de datos y ademas imprime los datos con tablas de una manera m\u00e1s entendible."}}