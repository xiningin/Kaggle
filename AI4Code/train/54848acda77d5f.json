{"cell_type":{"f1164977":"code","b6f6a536":"code","3e759d7d":"code","f4288c1f":"code","42420dda":"code","d9fe87f0":"code","95603dc4":"markdown","b93f371d":"markdown","97458926":"markdown","3db6044c":"markdown","c87c0262":"markdown","7d3b3091":"markdown"},"source":{"f1164977":"\nimport sys\nsys.path.append(\"..\/input\/tez-lib\/\")\nsys.path.append(\"..\/input\/timmmaster\/\")\n\nimport tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport math\n\nclass args:\n    batch_size = 32\n    image_size = 384\n    \ndef sigmoid(x):\n    return 1 \/ (1 + math.exp(-x))","b6f6a536":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n    \nclass PawpularModel(tez.Model):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x, 0, {}\n    \n\ntest_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        albumentations.RandomBrightnessContrast(p=0.5),\n        \n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","3e759d7d":"import cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')\n\nLOAD_SVR_FROM_PATH = '..\/input\/svr-models-10-folds\/'\n\ndf = pd.read_csv('..\/input\/same-old-creating-folds\/train_10folds.csv')\nprint('Train shape:', df.shape )\ndf.head()","f4288c1f":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n    \n    model = PawpularModel(model_name=\"swin_large_patch4_window12_384\")\n    model.load(f\"..\/input\/paw-models\/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    df_test = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n    test_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/test\/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    df_valid = df[df.kfold == fold_].reset_index(drop=True)#.iloc[:160]\n    valid_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_].reset_index(drop=True)#.iloc[:320]\n        train_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        train_dataset = PawpularDataset(\n            image_paths=train_img_paths,\n            dense_features=df_train[dense_features].values,\n            targets=df_train['Pawpularity'].values\/100.0,\n            augmentations=test_aug,\n        )\n        print('Extracting train embedding...')\n        train_predictions = model.predict(train_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n    \n        embed = np.array([]).reshape((0,128+12))\n        for preds in train_predictions:\n            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embed.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    test_dataset = PawpularDataset(\n        image_paths=test_img_paths,\n        dense_features=df_test[dense_features].values,\n        targets=np.ones(len(test_img_paths)),\n        augmentations=test_aug,\n    )\n    print('Predicting test...')\n    test_predictions = model.predict(test_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n\n    final_test_predictions = []\n    embed = np.array([]).reshape((0,128+12))\n    for preds in test_predictions: #tqdm\n        final_test_predictions.extend(preds[:,:1].ravel().tolist())\n        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n\n    final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embed)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################\n    # OOF PREDICTIONS\n    valid_dataset = PawpularDataset(\n        image_paths=valid_img_paths,\n        dense_features=df_valid[dense_features].values,\n        targets=df_valid['Pawpularity'].values\/100.0,\n        augmentations=test_aug,\n    )\n    print('Predicting oof...')\n    valid_predictions = model.predict(valid_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n\n    final_oof_predictions = []\n    embed = np.array([]).reshape((0,128+12))\n    for preds in valid_predictions:\n        final_oof_predictions.extend(preds[:,:1].ravel().tolist())\n        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n\n    final_oof_predictions = [sigmoid(x) * 100 for x in final_oof_predictions]\n    final_oof_predictions2 = clf.predict(embed)    \n    super_final_oof_predictions.append(final_oof_predictions)\n    super_final_oof_predictions2.append(final_oof_predictions2)\n    \n    final_oof_true = df_valid['Pawpularity'].values\n    super_final_oof_true.append(final_oof_true)\n    ##################\n    \n    ##################\n    # COMPUTE RSME\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_predictions[-1]))**2.0 ) )\n    print('NN RSME =',rsme,'\\n')\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_predictions2[-1]))**2.0 ) )\n    print('SVR RSME =',rsme,'\\n')\n    \n    w = 0.5\n    oof2 = (1-w)*np.array(super_final_oof_predictions[-1]) + w*np.array(super_final_oof_predictions2[-1])\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - oof2)**2.0 ) )\n    print('Ensemble RSME =',rsme,'\\n')","42420dda":"true = np.hstack(super_final_oof_true)\n\noof = np.hstack(super_final_oof_predictions)\nrsme = np.sqrt( np.mean( (oof - true)**2.0 ))\nprint('Overall CV NN head RSME =',rsme)\n\noof2 = np.hstack(super_final_oof_predictions2)\nrsme = np.sqrt( np.mean( (oof2 - true)**2.0 ))\nprint('Overall CV SVR head RSME =',rsme)\n\noof3 = (1-w)*oof + w*oof2\nrsme = np.sqrt( np.mean( (oof3 - true)**2.0 ))\nprint('Overall CV Ensemble heads RSME with 50% NN and 50% SVR =',rsme)","d9fe87f0":"# FORCE SVR WEIGHT TO LOWER VALUE TO HELP PUBLIC LB\nbest_w = 0.5\n\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ndf_test[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\ndf_test.to_csv(\"submission.csv\", index=False)\ndf_test.head()","95603dc4":"# Dataset Class","b93f371d":"# Model","97458926":"#### You can criticize my work or give your suggestion, your comment is a treasure of knowledge for me\n##### P.S. sorry for a poor grammar","3db6044c":"# **About author: I'm a beginner in this field trying to learn and discovering the enjoyment of Data Science.**\n### Note1: This notebook is a copy version plus some editing and experimenting for my own understanding and learning.\n### Note2: If this notebook is useful for you in anyway, please give an upvote or commenting your gratitude on the notebook in the reference section. ","c87c0262":"# Import","7d3b3091":"# **Reference**\n### [RAPIDS SVR Boost - [17.8] - PRO](https:\/\/www.kaggle.com\/manyuli\/rapids-svr-boost-17-8-pro)\n### [tez: pawpular swin-ference](https:\/\/www.kaggle.com\/abhishek\/tez-pawpular-swin-ference)"}}