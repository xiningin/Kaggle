{"cell_type":{"304c9eed":"code","0ae6c3e8":"code","79fb2b04":"code","e3601ae1":"code","a5acedc7":"code","e6af5867":"code","573a7831":"code","1766d680":"code","c5d452dc":"code","b707cb75":"code","8604d66f":"code","2d2277eb":"code","07a4025f":"code","f3749197":"code","a3674216":"code","1c9e800f":"code","271d6ea3":"code","c61b22a1":"code","9bfbc37f":"code","f80bfe69":"code","b11e4554":"code","562935b8":"code","e0b9755d":"code","2614efff":"code","34f072b6":"code","f6dea6d8":"code","c9e9586c":"code","aa0a0134":"code","01771915":"code","bac01cc3":"code","8865f065":"code","6b047080":"code","8e24df6f":"code","c6399d86":"code","6b582946":"code","121581b9":"code","6a90d55d":"code","de9f3ffe":"code","6abc2e1f":"code","cc3bcd4d":"code","b68033a9":"code","f82abe06":"code","0730998c":"code","86a52c42":"code","11499273":"code","921ac34e":"code","59dfee07":"code","105b86a7":"code","c6811c67":"code","f17263a1":"code","1f4de62b":"code","4a76b686":"code","62c87862":"code","ef2874e6":"code","b4dabe73":"code","66b4ee4f":"code","3225c94d":"code","1efaacd1":"code","6b2bfbe4":"code","0bd34564":"code","7baf0961":"code","a276145e":"code","9f701a4f":"code","3283ba8b":"code","2c84c143":"code","5741002b":"code","69a0b5f0":"code","0ce91c72":"code","faee0297":"code","19bca2e7":"code","82f0b4e1":"code","ded5e6e5":"code","faaedc60":"code","ae5eeee8":"code","11172b5c":"code","3461bcd6":"code","dde608c3":"code","8e40b3b2":"code","b421f940":"code","9eb7e88b":"code","4deb3e62":"code","d287883a":"code","f291f4a2":"code","053eba69":"code","779bf4c3":"code","f69b9429":"code","62dcbe2e":"code","964a7e32":"code","095d06d6":"code","4e07130f":"code","94315f8d":"code","4eb75696":"code","8584cb2e":"code","7ae75950":"code","90ab2331":"code","147fed21":"code","2af7f7f7":"code","c57dfb39":"code","63351ff2":"code","e42227a4":"code","b4d08837":"code","769cfb45":"code","cc096175":"code","f34bcd9c":"code","3ae7aad7":"code","cd76c019":"code","ffc3dad9":"code","444b53ee":"code","e8f8420e":"code","657175cf":"markdown","87c89a79":"markdown","f3bd638a":"markdown","571920f1":"markdown","ea2f6e00":"markdown","95566c54":"markdown","1da62434":"markdown","4662a429":"markdown","3e1cbaa3":"markdown","815afd8b":"markdown","0307c79b":"markdown","f33b17a8":"markdown","5fbfc60b":"markdown","3bfc35d4":"markdown","f94f8a8a":"markdown","4395cdd6":"markdown","64d5924c":"markdown","6aeec2fd":"markdown","e445b91f":"markdown","af1d7824":"markdown","d8d04fa2":"markdown","f6844f50":"markdown","70e630c1":"markdown","f9b2d28a":"markdown","978e55a1":"markdown","0ca17cc8":"markdown","aee2d741":"markdown","4688890a":"markdown","742a63c1":"markdown","994e4c95":"markdown","6f8c8d1b":"markdown","fa5925ed":"markdown","346c31e3":"markdown","9151488d":"markdown","8eeb5e68":"markdown","b5df46bc":"markdown","5b82de3c":"markdown","b3e3965b":"markdown","3cc303cf":"markdown","efc156eb":"markdown","f753caba":"markdown","e49e8a40":"markdown","7dcf5eae":"markdown"},"source":{"304c9eed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#wordcloud\nfrom wordcloud import WordCloud\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n#import os\n#print(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0ae6c3e8":"# First we read data\ndata = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\ndata.head(2)","79fb2b04":"# Then we take some columns which we use in there.\ndata.rename(columns={'iyear':'Year','imonth':'Month','iday':'Day','country_txt':'Country','region_txt':'Region','attacktype1_txt':'AttackType','target1':'Target','nkill':'Killed','nwound':'Wounded','summary':'Summary','gname':'Group','targtype1_txt':'Target_type','weaptype1_txt':'Weapon_type','motive':'Motive','country':'Country_ID','targsubtype1':'Target_ID'},inplace=True)\ndata=data[['Year','Month','Day','Country_ID','Country','Region','city','latitude','longitude','AttackType','Killed','Wounded','Target','Summary','Group','Target_ID','Target_type','Weapon_type','Motive']]\ndata.head(2)","e3601ae1":"# Create two dataframes for Attack type:\ndata_attck_bomb=data[data.AttackType=='Bombing\/Explosion']\ndata_attck_facility=data[data.AttackType=='Facility\/Infrastructure Attack']","a5acedc7":"type(data_attck_bomb)","e6af5867":"#data preparetion\ncountries_list = data.Country\nplt.subplots(figsize=(15,12))\n\nwordcloud = WordCloud(\n                        background_color = \"white\",\n                        width = 450,\n                        height = 384\n                        ).generate(\" \".join(countries_list))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.savefig(\"graph.png\")\n\nplt.show()","573a7831":"# desciribe dataframe\ndata_attck_facility.describe()","1766d680":"data.corr()","c5d452dc":"# correlation map\nf,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(data.corr(),annot=True,linewidths=.5,fmt='.1f',ax=ax)\nplt.show()","b707cb75":"data.columns","8604d66f":"#line plot\ndata_attck_bomb.Killed.plot(kind = 'line',color = 'g',label='bomb_killed',linewidth=1,alpha=0.5,grid=True,linestyle='--')\ndata_attck_facility.Killed.plot(color='r',label='facility_killed',linewidth=1,alpha=0.5,grid=True,linestyle = '-.')\nplt.legend(loc='upper right')\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.title('Line plot')\nplt.show()","2d2277eb":"# line plot2\nplt.plot(data_attck_bomb.Killed,data_attck_bomb.Wounded,color='r',linewidth=1,alpha=0.5,label='bomb_kill_wound')\nplt.plot(data_attck_facility.Killed,data_attck_facility.Wounded,color='g',linewidth=1,alpha=0.5,label='facility_kill_wound')\nplt.xlabel(\"Killed\")\nplt.ylabel(\"Wounded\")\nplt.legend()\nplt.title(\"Line plot 2\")\nplt.show()","07a4025f":"# line plot3\ndata.Wounded.plot(kind = 'line',color = 'b',label='Wounded',linewidth=1,alpha=0.5,grid=True,linestyle='--')\ndata.Killed.plot(color='r',label='Killed',linewidth=1,alpha=0.5,grid=True,linestyle = '-.')\nplt.legend(loc='upper right')\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.title('Line plot')\nplt.show()","f3749197":"# Histogram\n#bins number of figure\ndata.Year.plot(kind='hist',bins=70,figsize=(15,15))\nplt.show()","a3674216":"# Countplot\nplt.subplots(figsize=(17,7))\nsns.countplot('Year',data=data,palette='vlag',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('Every Year Terrorism Countplot')\nplt.show()","1c9e800f":"# Countplot 2\nplt.subplots(figsize=(15,5))\nsns.countplot('AttackType',data=data,palette='rocket',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('AttackType Countplot')\nplt.show()","271d6ea3":"# 1- Filtering Pandas DataFrame\nx = data['Country_ID']>1003\nx.sum() # There are only 225 countries where have higher ID value than 1003","c61b22a1":"# 2 - Filtering pandas with logical_and\n# There are only 2 countries where have higher country_id value than 1003 and higher target_id value than 100\ndata[np.logical_and(data['Country_ID']>1003,data['Target_ID']>100)]","9bfbc37f":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Country_ID']>1003) & (data['Target_ID']>100)]","f80bfe69":"data1=data.Country.unique()\ndata1.size\nprint(type(data1))","b11e4554":"# Created new dictionary\ndata_dict={}\nb=0\nfor i in data1:\n    data_dict[b]=i\n    b+=5\n    if b>=data1.size:\n        break","562935b8":"data_dict","e0b9755d":"print(50 in data_dict)\nprint(data_dict[50])","2614efff":"del data_dict[50]\nprint(50 in data_dict)","34f072b6":"# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\nfor key,value in data_dict.items():\n    print(key,\" : \",value)\nprint('')\n# For pandas we can achieve index and value\nfor index,value in data[['Country']][0:3].iterrows():\n    print(index,\": \",value)\n","f6dea6d8":"# Example user defined function\ndef tupple_square():\n    t = (2,4,6)\n    return t\na,b,c = tupple_square()\nprint(a,b,c)","c9e9586c":"# guess print what\nx = 4\ndef func():\n    x = 8\n    return x\nprint(x)\nprint(func())","aa0a0134":"# What if there is no local scope\nx = 10\ndef fun():\n    y=(x**2)\/4\n    return y\n\nprint(fun())","01771915":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","bac01cc3":"# nested function\ndef nest():\n    \"return square of value\"\n    def an():\n        y = 25\n        x = 13\n        z = (y - x)*(y + x)\n        return z\n    return (an()**2)\n\nprint(nest())","8865f065":"#default arguments\ndef f(a, b, c=34, d=23):\n    y = (a*d)+b-c\n    return y\nprint(f(1,2))\nprint(f(1,2,3,4))","6b047080":"# flexible arguments *args\ndef flex(*args):\n    s = 1\n    for i in args:\n        s=s*i\n    return s\nprint(flex(1,2,3))\nprint(flex(5,6,7,8,9))\n# flexible arguments **kwargs that is dictionary\ndef flex2(**kwargs):\n    for key,value in kwargs.items():\n        print(\"{} key values is {}\".format(key,value))\n        \nflex2(country = \"spain\",capital = 'madrid',best_team = 'Barcelona')","8e24df6f":"# lambda function\nsquaret = lambda x: x**0.5     # where x is name of argument\nprint(squaret(4))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(9,25,3))","c6399d86":"# lambda function\nsquaret = lambda x: x**0.5\nprint(squaret(169))\ntot = lambda x,y,z: x*y-z\nprint(tot(4,5,6))","6b582946":"# iterator example\n\nname='messi'\nit = iter(name)\nprint(next(it))\nprint(next(it))\nprint(next(it))\nprint(*it)\n","121581b9":"# zip example\nlist1=[1,2,3,4]\nlist2=[11,12,13,14]\nz = zip(list1,list2)\nprint(z)\nz = list(z)\nprint(z)","6a90d55d":"# unzip example\nunzip = zip(*z)\nprint(unzip)\nunlist1,unlist2 = list(unzip)\nprint(unlist1)\nprint(unlist2)\ntype(unlist1)","de9f3ffe":"# Example of list comprehension\nnum1 = [1,2,3,4,5,6,7,8,9]\nnum2 = [i**2 for i in num1]\nprint(num1)\nprint(num2)","6abc2e1f":"# Conditionals on iterable\nnum1 = [1,2,3,4,5,6,7,8,9]\nnum2 = [i*10 if i \/\/ 3==0 else i*5 if i % 3 ==2 else i*4 for i in num1]\nprint(num2)","cc3bcd4d":"data2 = data[['Country_ID','Country']]\n","b68033a9":"average = sum(data2.Country_ID)\/len(data2.Country_ID)\ndata2['new_calc'] = [\"C_ID is high\" if i > average else \"C_ID is low\" for i in data2.Country_ID]\ndata2.head(10)","f82abe06":"data = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\ndata.rename(columns={'iyear':'Year','imonth':'Month','iday':'Day','country_txt':'Country','region_txt':'Region','attacktype1_txt':'AttackType','target1':'Target','nkill':'Killed','nwound':'Wounded','summary':'Summary','gname':'Group','targtype1_txt':'Target_type','weaptype1_txt':'Weapon_type','motive':'Motive','country':'Country_ID','targsubtype1':'Target_ID'},inplace=True)\ndata=data[['Year','Month','Day','Country_ID','Country','Region','city','latitude','longitude','AttackType','Killed','Wounded','Target','Summary','Group','Target_ID','Target_type','Weapon_type','Motive']]\ndata.head() # head show first 5 rows","0730998c":"data.tail() # tail show last 5 rows","86a52c42":"#shape gives number of columns and rows in tupple\ndata.shape","11499273":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","921ac34e":"# Forx example lets look Attack of terrorist types\nprint(data['AttackType'].value_counts(dropna=False)) # if there are nan values that also be counted\n# As it can be seen below there are 42669 Armed Assault terror type or 19312 Assassination terror","59dfee07":"data.describe()","105b86a7":"data.boxplot(column='Target_ID',by='Killed')","c6811c67":"data_new=data.head()\ndata_new","f17263a1":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Country',value_vars= ['city','latitude'])\nmelted","1f4de62b":"# Index is country\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index='Country',columns='variable',values='value')","4a76b686":"# Firstly lets create 2 data frame\ndata1=data.head()\ndata2=data.tail()\nconc_dat_rows=pd.concat([data1,data2],axis=0,ignore_index=True) # axis = 0 : adds dataframes in row\nconc_dat_rows","62c87862":"data.dtypes","ef2874e6":"# lets convert object(str) to categorical and int to float.\ndata['Day']=data['Day'].astype('float')\ndata['Target_type']=data['Target_type'].astype('category')","b4dabe73":"# As you can see Target_type is converted from object to categorical\n# And Day ,s converted from int to float\ndata.dtypes","66b4ee4f":"# lets look at does terrorism dataframe have nan value\ndata.info()","3225c94d":"# lets ckeck motive\ndata['longitude'].value_counts(dropna=False)\n# as you can see there're 4557 NAN value","1efaacd1":"# lets drop NaN values\ndata1=data \ndata1['longitude'].dropna(inplace=True)","6b2bfbe4":"#  Lets check with assert statement what is this worked or not\n# Assert statement:\nassert 1==1","0bd34564":"assert data1['longitude'].notnull().all()","7baf0961":"    # # With assert statement we can check a lot of thing. For example\n    # assert data.columns[1] == 'Name'\n    # assert data.Speed.dtypes == np.int","a276145e":"# data frames from dictionary\ncountry=data['Country'].unique()\ncountry_id=data['Country_ID'].unique()\nlist_label=[\"country\",\"country_id\"]\nlist_col=[country,country_id]\nzipped=list(zip(list_label,list_col))\ndata_dict=dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf1 = df.head()\ndf1","9f701a4f":"# Add new columns\ndf1[\"capital\"]=[\"Santo Domingo\",\"Mexico City\",\"Manila\",\"Athens\",\"Tokyo\"]\ndf1","3283ba8b":"# broadcasting\ndf1[\"income\"]=100\ndf1","2c84c143":"# Plotting all data\ndata1 = data.loc[:,[\"Killed\",\"Wounded\"]]\ndata1.plot()\nplt.show()","5741002b":"# subplots\ndata1.plot(subplots=True)\nplt.show()","69a0b5f0":"# scatter plot\ndata1.plot(kind=\"scatter\",x=\"Killed\",y=\"Wounded\")\nplt.show()","0ce91c72":"#hist plot\ndata.plot(kind=\"hist\",y=\"Target_ID\",bins = 50,range = (0,120),normed=True)\nplt.show()","faee0297":"##### histogram subplot with non cumulative and cumulative\nfig,axes = plt.subplots(nrows=2,ncols=1)\ndata.plot(kind=\"hist\",y = \"Target_ID\",bins=50,range=(0,120),normed=True,ax=axes[0])\ndata.plot(kind=\"hist\",y = \"Target_ID\",bins=50,range=(0,120),normed=True,ax=axes[1],cumulative=True)\nplt.savefig(\"praph.png\")\nplt","19bca2e7":"df1.describe()","82f0b4e1":"#close warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndate_list=[\"1989-03-15\",\"1989-03-16\",\"1989-03-17\",\"1990-06-18\",\"1990-06-19\"]\ndtime_object=pd.to_datetime(date_list)\ndf1[\"date\"]=dtime_object\n# lets make date as index\ndf1 = df1.set_index(\"date\")\ndf1","ded5e6e5":"# Now we can select according to our date index\nprint(df1.loc[\"1989-03-16\"])\nprint(df1.loc[\"1989-03-17\":\"1990-06-19\"])","faaedc60":"# We will use df1 that we create at previous part\ndf1.resample(\"A\").mean()","ae5eeee8":"# lets resample with month\ndf1.resample(\"M\").mean()","11172b5c":"# We can interpolete from first value\ndf1.resample(\"M\").first().interpolate(\"linear\")","3461bcd6":"# Or we can interpolate with mean()\ndf1.resample(\"M\").mean().interpolate(\"linear\")","dde608c3":"data = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\ndata.rename(columns={'iyear':'Year','imonth':'Month','iday':'Day','country_txt':'Country','region_txt':'Region','attacktype1_txt':'AttackType','target1':'Target','nkill':'Killed','nwound':'Wounded','summary':'Summary','gname':'Group','targtype1_txt':'Target_type','weaptype1_txt':'Weapon_type','motive':'Motive','country':'Country_ID','targsubtype1':'Target_ID'},inplace=True)\ndata=data[['Year','Month','Day','Country_ID','Country','Region','city','latitude','longitude','AttackType','Killed','Wounded','Target','Summary','Group','Target_ID','Target_type','Weapon_type','Motive']]","8e40b3b2":"data1=data.head(100)\ndata2=data.tail(100)\ndata_new=pd.concat([data1,data2],axis=0,ignore_index=True)\ndata_new.head()","b421f940":"# add new columns\n#i=0\nTID=[]\nfor i in range(len(data_new)):\n    TID = TID+[i+1]\ndata_new[\"ID\"]=TID    \ndata_new = data_new.set_index(\"ID\")\ndata_new.head()","9eb7e88b":"# using column attribute and row label\ndata_new.Country[20]","4deb3e62":"# indexing using square brackets\ndata_new[\"Country\"][20]","d287883a":"# using loc accessor\ndata_new.loc[20,[\"Country\"]]","f291f4a2":"# Selecting only some columns\ndata_new[[\"Country\",\"city\"]]","053eba69":"# Difference between selecting columns: series and dataframes\nprint(type(data_new[\"city\"]))\nprint(type(data_new[[\"city\"]]))","779bf4c3":"# Slicing and indexing series\ndata_new.loc[1:10,\"Country\":\"city\"]","f69b9429":"# Reverse slicing\ndata_new.loc[10:1:-1,\"Country\":\"city\"]","62dcbe2e":"# Creating boolean series\nboolean = data_new.Country_ID>400\ndata_new[boolean]","964a7e32":"# Combining filters\nfirst_one = data_new.Country_ID>300\nsecond_one = data_new.Target_ID>40\ndata_new[first_one & second_one]","095d06d6":"# Filtering column based others\ndata_new.city[data_new.Target_ID>100]","4e07130f":"# Plain python functions\ndef div(n):\n    return n\/2\ndata_new.Country_ID.apply(div)","94315f8d":"# Or we can use lambda function\ndata_new.Country_ID.apply(lambda x : x\/2)","4eb75696":"# Defining column using other columns\ndata_new[\"unreasonable\"]=data_new.Country_ID+data_new.Target_ID\ndata_new.head()","8584cb2e":"# our index name is this:\nprint(data_new.index.name)\n# lets change it\ndata_new.index.name=\"index_id\"\ndata_new.head()","7ae75950":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata_new.head()\ndata3 = data_new.copy()\n\ndata3.index = range(100,300,1)\ndata3.head()","90ab2331":"data_new.head()","147fed21":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\ndata.rename(columns={'iyear':'Year','imonth':'Month','iday':'Day','country_txt':'Country','region_txt':'Region','attacktype1_txt':'AttackType','target1':'Target','nkill':'Killed','nwound':'Wounded','summary':'Summary','gname':'Group','targtype1_txt':'Target_type','weaptype1_txt':'Weapon_type','motive':'Motive','country':'Country_ID','targsubtype1':'Target_ID'},inplace=True)\ndata=data[['Year','Month','Day','Country_ID','Country','Region','city','latitude','longitude','AttackType','Killed','Wounded','Target','Summary','Group','Target_ID','Target_type','Weapon_type','Motive']]\ndata.head()","2af7f7f7":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Country\",\"city\"])\ndata1.head(20)","c57dfb39":"dict = {\"treatment\":[\"A\",\"A\",\"B\",\"B\",\"C\",\"C\"],\"gender\":[\"F\",\"M\",\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9,24,30],\"age\":[15,4,72,65,21,38]}\ndata_dict = pd.DataFrame(dict)\ndata_dict","63351ff2":"# pivoting\ndata_dict.pivot(index=\"treatment\",columns=\"gender\",values=\"response\")","e42227a4":"data_dict = data_dict.set_index([\"treatment\",\"gender\"])\ndata_dict\n# lets unstack it","b4d08837":"# level determines indexes\ndata_dict.unstack(level=0)","769cfb45":"data_dict.unstack(level=1)","cc096175":"# change inner and outer level index position\ndata2 = data_dict.swaplevel(0,1)\ndata2","f34bcd9c":"data_dict","3ae7aad7":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(data_dict,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","cd76c019":"# We will use data_dict\ndata_dict.groupby(\"treatment\").mean()","ffc3dad9":"# we can only choose one of the feature\ndata_dict.groupby(\"treatment\").age.min()","444b53ee":"# Or we can choose mutliple columns\ndata_dict.groupby(\"treatment\")[[\"age\",\"response\"]].max()","e8f8420e":"data_dict.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#data_dict[\"gender\"] = data_dict[\"gender\"].astype(\"category\")\n#data_dict[\"treatment\"] = data_dict[\"treatment\"].astype(\"category\")\n#data_dict.info()\n","657175cf":"# Terrorism Analyse\nTerrorism is usually understood as the use or threat of violence to further a political cause. There is no universally agreed definition of terrorism making it a difficult object to quantify.\n**Content:**\n1. [INTRODUCTION TO ANALYSE:](#1)\n    1. [GETTING DATA](#2)\n    1. [MATPLOTLIB ](#3)\n    1. [SEABORN](#4)\n    1. [PANDAS](#5)\n    1. [DICTIONARY AND LOOPS](#6)\n1. [PYTHON DATA SCIENE TOOLBOX:](#7)\n    1. [USER DEFINED FUNCTION](#8)\n    1. [SCOPE](#9)\n    1. [NESTED FUNCTION](#10)\n    1. [DEFAULT and FLEXIBLE ARGUMENTS](#11)\n    1. [LAMBDA FUNCTION](#12)\n    1. [ANONYMOUS FUNCT\u0130ON](#13)\n    1. [ITERATORS](#14)\n    1. [LIST COMPREHENS\u0130ON](#15)\n1. [CLEANING DATA](#16)\n    1. [DIAGNOSE DATA FOR CLEANING](#17)\n    1. [EXPLORATORY DATA ANALYSIS](#18)\n    1. [VISUAL EXPLORATORY DATA ANALYSIS](#19)\n    1. [TIDY DATA](#20)\n    1. [PIVOTING DATA](#21)\n    1. [CONCATENATING DATA](#22)\n    1. [DATA TYPES](#23)\n    1. [MISSING DATA and TESTING WITH ASSERT](#24)\n1. [PANDAS FOUNDATION](#25)\n    1. [REVIEW of PANDAS](#26)\n    1. [BUILDING DATA FRAMES FROM SCRATCH](#27)\n    1. [VISUAL EXPLORATORY DATA ANALYSIS](#28)\n    1. [STATISTICAL EXPLORATORY DATA ANALYSIS](#29)\n    1. [INDEXING PANDAS TIME SERIES](#30)\n    1. [RESAMPLE PANDAS TIME SERIES](#31)\n1. [MANIPULATING DATA FRAMES with PANDAS](#32)\n    1. [INDEXING DATA FRAMES](#33)\n    1. [SLICING DATA FRAME](#34)\n    1. [FILTERING DATA FRAMES](#35)\n    1. [TRANSFORMING DATA](#36)\n    1. [INDEX OBJECTS AND LABELED DATA](#37)\n    1. [HIERARCHICAL INDEXING](#38)\n    1. [PIVOTING DATA FRAMES](#39)\n    1. [STACKING AND UNSTACKING DATAFRAME](#40)\n    1. [MELTING DATA FRAMES](#41)\n    1. [CATEGORICALS AND GROUPBY](#42)","87c89a79":"<a id=\"13\"><\/a> <br>\n### ANONYMOUS FUNCT\u0130ON","f3bd638a":"<a id=\"34\"><\/a> <br>\n### SLICING DATA FRAME","571920f1":"<a id=\"40\"><\/a> <br>\n### STACKING and UNSTACKING DATAFRAME","ea2f6e00":"<a id=\"28\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:","95566c54":"<a id=\"4\"><\/a> <br>\n### SEABORN","1da62434":"<a id=\"31\"><\/a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year","4662a429":"<a id=\"15\"><\/a> <br>\n### LIST COMPREHENS\u0130ON","3e1cbaa3":"<a id=\"11\"><\/a> <br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n","815afd8b":"<a id=\"32\"><\/a> <br>\n# MANIPULATING DATA FRAMES with PANDAS","0307c79b":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","f33b17a8":"<a id=\"16\"><\/a> <br>\n# 3.CLEANING DATA","5fbfc60b":"<a id=\"37\"><\/a> <br>\n### INDEX OBJECTS AND LABELED DATA","3bfc35d4":"<a id=\"35\"><\/a> <br>\n### FILTERING DATA FRAMES","f94f8a8a":"<a id=\"39\"><\/a> <br>\n### PIVOTING DATA FRAMES","4395cdd6":"<a id=\"5\"><\/a> <br>\n### PANDAS\n","64d5924c":"<a id=\"1\"><\/a> <br>\n# 1. INTRODUCTION TO ANALYSE","6aeec2fd":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS","e445b91f":"<a id=\"22\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe ","af1d7824":"Most terror countries.","d8d04fa2":"<a id=\"3\"><\/a> <br>\n### MATPLOTLIB\nI can try to use matplotlib for this data.","f6844f50":"<a id=\"33\"><\/a> <br>\n### INDEXING DATA FRAMES","70e630c1":"<a id=\"36\"><\/a> <br>\n### TRANSFORMING DATA","f9b2d28a":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS","978e55a1":"<a id=\"2\"><\/a> <br>\n### GETTING DATA","0ca17cc8":"<a id=\"23\"><\/a> <br>\n### DATA TYPES","aee2d741":"<a id=\"8\"><\/a> <br>\n### USER DEFINED FUNCTION","4688890a":"<a id=\"7\"><\/a> <br>\n# 2. PYTHON DATA SCIENCE TOOLBOX","742a63c1":"<a id=\"20\"><\/a> <br>\n### TIDY DATA","994e4c95":"<a id=\"25\"><\/a> <br>\n# 4. PANDAS FOUNDATION ","6f8c8d1b":"<a id=\"9\"><\/a> <br>\n### SCOPE","fa5925ed":"<a id=\"12\"><\/a> <br>\n### LAMBDA FUNCTION\n","346c31e3":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING","9151488d":"<a id=\"26\"><\/a> <br>\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.","8eeb5e68":"<a id=\"27\"><\/a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH","b5df46bc":"<a id=\"17\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.","5b82de3c":"<a id=\"41\"><\/a> <br>\n### MELTING DATA FRAMES","b3e3965b":"<a id=\"6\"><\/a> <br>\n### DICTIONARY AND LOOPS","3cc303cf":"<a id=\"21\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","efc156eb":"<a id=\"14\"><\/a> <br>\n### ITERATORS","f753caba":"<a id=\"29\"><\/a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","e49e8a40":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","7dcf5eae":"<a id=\"10\"><\/a> <br>\n### NESTED FUNCTION"}}