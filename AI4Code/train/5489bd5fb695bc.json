{"cell_type":{"427aadbf":"code","a6801627":"code","bd71ef99":"code","b0ed6aa1":"code","b767054b":"code","cda5fba6":"code","4692c9df":"code","c6104e41":"code","736819a9":"code","98a6d8f7":"code","5a715d8c":"code","37aaf1a7":"code","56961176":"code","1b0ce6bf":"code","2ea98a35":"code","a59b942b":"code","9d1c21c8":"code","e8a506c4":"code","c3baa896":"code","786a3dbb":"code","c699e6a8":"code","cb612bad":"code","47ef9031":"code","b9b37bcb":"code","82fac78d":"code","7e2ea704":"code","e4bd394f":"code","82db787e":"code","7850f146":"code","d2242099":"code","a39917cb":"code","24a5a1ba":"code","5350ff82":"code","d961b405":"code","c296c1e5":"code","db59a3cc":"code","1c0afce0":"code","14ec83e7":"code","eaa73956":"code","4393bb50":"code","a0a5a12a":"code","c976a37a":"code","bbe8a292":"code","6d5a4243":"code","d88c71c2":"code","fa50f100":"markdown","d2eb6a9f":"markdown","9162d81c":"markdown","1eec5706":"markdown","3f1712cf":"markdown","e813c99e":"markdown","4dfe52b2":"markdown","1f73b2fc":"markdown","9efd165c":"markdown","991a1ddc":"markdown","00912ca1":"markdown","a9f874c4":"markdown","393084fe":"markdown","ea0614c7":"markdown","9ea2ac22":"markdown","b132da76":"markdown","d01d01e9":"markdown","40aeffaa":"markdown","0dc2e12c":"markdown","6ff9d1cf":"markdown","9ade41ff":"markdown","5ae768a8":"markdown","d4d49e70":"markdown","a5baba10":"markdown","f4f9b197":"markdown"},"source":{"427aadbf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a6801627":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndf.head()","bd71ef99":"df.shape","b0ed6aa1":"df.info()","b767054b":"df.describe()","cda5fba6":"missing_values_count = df.isnull().sum()\n\ntotal_cells = np.product(df.shape)\n\ntotal_missing = missing_values_count.sum()\n\npercentage_missing = (total_missing\/total_cells)*100\nprint(percentage_missing)","4692c9df":"NAN = [(c, df[c].isnull().mean()*100) for c in df]\nNAN = pd.DataFrame(NAN, columns=['column_name', 'percentage'])\nNAN","c6104e41":"null_counts = df.isnull().sum()\nnull_counts","736819a9":"for i in df.columns:\n    print(df[i].unique())","98a6d8f7":"df_setosa = df.loc[df['Species']=='Iris-setosa']\ndf_virginica = df.loc[df['Species']=='Iris-virginica']\ndf_versicolor = df.loc[df['Species']=='Iris-versicolor']","5a715d8c":"plt.plot(df_setosa['SepalLengthCm'],np.zeros_like(df_setosa['SepalLengthCm']),'*')\nplt.plot(df_virginica['SepalLengthCm'],np.zeros_like(df_virginica['SepalLengthCm']),'o')\nplt.plot(df_versicolor['SepalLengthCm'],np.zeros_like(df_versicolor['SepalLengthCm']),'+')","37aaf1a7":"plt.plot(df_setosa['SepalWidthCm'],np.zeros_like(df_setosa['SepalWidthCm']),'*')\nplt.xlabel('SepalLength')\nplt.show()","56961176":"plt.plot(df_virginica['SepalLengthCm'],np.zeros_like(df_virginica['SepalLengthCm']),'o')\nplt.xlabel('SepalLength')\nplt.show()","1b0ce6bf":"plt.plot(df_versicolor['PetalLengthCm'],np.zeros_like(df_versicolor['PetalLengthCm']),'+')\nplt.xlabel('PetalLengthCm')\nplt.show()","2ea98a35":"sns.FacetGrid(df,hue='Species',size=5).map(plt.scatter,\"SepalLengthCm\",\"SepalWidthCm\").add_legend();\nplt.show()","a59b942b":"sns.FacetGrid(df,hue='Species',size=5).map(plt.scatter,\"PetalLengthCm\",\"PetalWidthCm\").add_legend();\nplt.show()","9d1c21c8":"sns.FacetGrid(df,hue='Species',size=5).map(plt.scatter,\"PetalLengthCm\",\"SepalWidthCm\").add_legend();\nplt.show()","e8a506c4":"sns.FacetGrid(df,hue='Species',size=5).map(plt.scatter,\"SepalLengthCm\",\"PetalWidthCm\").add_legend();\nplt.show()","c3baa896":"sns.pairplot(df,hue='Species',size=3)","786a3dbb":"sns.histplot(data=df, x=\"SepalWidthCm\", kde = True)","c699e6a8":"sns.histplot(data=df, x=\"SepalWidthCm\", hue=\"Species\",multiple=\"stack\")","cb612bad":"sns.histplot(data=df, x=\"PetalLengthCm\", hue=\"Species\",element=\"poly\")","47ef9031":"sns.histplot(\n    data=df, x=\"SepalWidthCm\", hue=\"Species\",\n    hue_order=[\"Iris-Versicolor\", \"Iris-virginica\"],\n    log_scale=True, element=\"step\", fill=False,\n    cumulative=True, stat=\"density\", common_norm=False,\n)","b9b37bcb":"sns.histplot(\n    df, x=\"PetalLengthCm\", y=\"Species\", hue=\"Species\", legend=False\n)","82fac78d":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(df['Species'])\nlist(le.classes_)\ndf['Species'] = le.transform(df['Species']) \ndf","7e2ea704":"from sklearn.ensemble import RandomForestRegressor\nx = df.copy()\ny = x.pop('Species')","e4bd394f":"x","82db787e":"y","7850f146":"for colname in x.select_dtypes('object'):\n    x[colname],_ = x[colname].factorize()\n    \ndiscrete_features = x.dtypes ==int","d2242099":"from sklearn.feature_selection import mutual_info_regression\n\ndef make_mi_scores(x, y, discrete_features):\n    mi_scores = mutual_info_regression(x, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=x.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","a39917cb":"sns.histplot(data=df, x=\"PetalLengthCm\", hue='Species',kde = True)","24a5a1ba":"sns.relplot(x='PetalLengthCm', y='SepalLengthCm',hue='Species', data=df)","5350ff82":"ax=plt.subplots(1,1,figsize=(10,8))\ndf['Species'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,figsize=(10,8))\nplt.title(\"Iris Species %\")\nplt.show()\n","d961b405":"def draw_histograms(dataframe, features, rows, cols):\n    fig=plt.figure(figsize=(10,10))\n    for i, feature in enumerate(features):\n        ax=fig.add_subplot(rows,cols,i+1)\n        dataframe[feature].hist(bins=20,ax=ax,facecolor='blue')\n        ax.set_title(feature+\" Distribution\",color='Red')\n        \n    fig.tight_layout()  \n    plt.show()\ndraw_histograms(df,df.columns,3,3)","c296c1e5":"r = np.random.RandomState(0)\ndf1 = pd.DataFrame(r.rand(10,10))\ncorr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","db59a3cc":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.20,random_state=0)","1c0afce0":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","14ec83e7":"from sklearn.metrics import accuracy_score","eaa73956":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(X_train,Y_train)\n\nY_pred_nb = nb.predict(X_test)","4393bb50":"score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Naive Bayes is: \"+str(score_nb)+\" %\")","a0a5a12a":"from sklearn import svm\n\nsv = svm.SVC(kernel='linear')\n\nsv.fit(X_train, Y_train)\n\nY_pred_svm = sv.predict(X_test)","c976a37a":"score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")","bbe8a292":"from keras.models import Sequential \nfrom keras.layers import Dense,Activation,Dropout \nfrom keras.layers.normalization import BatchNormalization \nfrom keras.utils import np_utils","6d5a4243":"model=Sequential()\nmodel.add(Dense(1000,input_dim=4,activation='relu'))\nmodel.add(Dense(500,activation='relu'))\nmodel.add(Dense(300,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","d88c71c2":"model.summary()","fa50f100":"## Data Science","d2eb6a9f":"## Describing the data","9162d81c":"# Data Cleaning","1eec5706":"# Machine Learning Model","3f1712cf":"## Unique Values in our datasets","e813c99e":"## Train Test split","4dfe52b2":"## Data Visualisation","1f73b2fc":"## Artificial Neural Network","9efd165c":"# Histplot","991a1ddc":"# IRIS DATASET","00912ca1":"## Import datasets","a9f874c4":"## Support Vector Machine","393084fe":"## Multivariate Analysis","ea0614c7":"## Naive Bayes","9ea2ac22":"## Bivariate Analysis","b132da76":" This Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n Input data files are available in the read-only \"..\/input\/\" directory\n For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d01d01e9":"## Shape of data","40aeffaa":"## Import Important Libraries)","0dc2e12c":"## Gathering information about the data","6ff9d1cf":"# Deep Learning Models:","9ade41ff":"## Univariate Analysis","5ae768a8":"### show a few features with their Mutual Info scores","d4d49e70":"## Total percentage of data is missing","a5baba10":"## Iris is a genus of 260\u2013300 species of flowering plants with showy flowers. It takes its name from the Greek word for a rainbow, which is also the name for the Greek goddess of the rainbow, Iris. They can represent faith, hope, courage, wisdom and admiration.","f4f9b197":"## Label encoding from categorical featurtes"}}