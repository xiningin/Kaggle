{"cell_type":{"461640a3":"code","8704db21":"code","27368d50":"code","0224ee02":"code","12be65c3":"code","ba47116b":"code","fd444443":"code","68a4108c":"code","71503828":"code","45e8fb48":"code","60f0c5e6":"code","c313d317":"code","097ed9b7":"code","a19bdd1e":"code","7be19d49":"code","0dd89e46":"code","5e90bd84":"code","00565ad4":"code","30cd5182":"code","c4525704":"code","787ad2f7":"code","bf694928":"code","39033add":"code","ebb6ecd1":"markdown","d46ccdff":"markdown","4b9d3efd":"markdown"},"source":{"461640a3":"import numpy as np\nimport os\nimport torch\nimport torchvision\nimport torchvision.transforms as tt\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid","8704db21":"path = '..\/input\/chest-xray-pneumonia\/chest_xray\/'","27368d50":"# transforming to gray because channels are just repeated\nmean = torch.tensor([0.4822])\nstd = torch.tensor([0.2328])\ntransformations = tt.Compose([tt.Resize((64,64)), tt.Grayscale(num_output_channels=1),\n                              tt.ToTensor(), tt.Normalize(mean, std),\n                             ])","0224ee02":"#Load images into datasets\ntrain = ImageFolder(os.path.join(path, 'train'), transform=transformations)\nval = ImageFolder(os.path.join(path, 'val'), transform=transformations)\ntest = ImageFolder(os.path.join(path, 'test'), transform=transformations)","12be65c3":"# Concatenate test and validation, shuffle and resplit them because there is not enough samples for validation\ntest_data = torch.utils.data.ConcatDataset([val, test])\n\n# Generate random indices\nidx = np.arange(len(test_data))\nnp.random.shuffle(idx)\n\n# Shuffle the data according to the random indices\ntest_data = torch.utils.data.Subset(test_data, idx)\n\n# Split to validation and test sets\ntest_size = len(test_data)\/\/2\ntest, val = torch.utils.data.random_split(test_data, [test_size, len(test_data)-test_size])","ba47116b":"len(train), len(val), len(test)","fd444443":"#Create data loaders for each set\ntrain_loader = DataLoader(train, batch_size=128, shuffle=True)\nval_loader = DataLoader(val, batch_size=128)\ntest_loader = DataLoader(test, batch_size=128)","68a4108c":"# compute mean and std to normalize the sets\n# in this case of this dataset mean and std are the across the channels because \n# pixel values of red are just repeated in blue and green\ndef get_mean_std(loader):\n    mean = 0\n    mean_squared = 0\n    for x, _ in loader:\n        mean += torch.mean(x, dim=[0,2,3])\n        mean_squared += torch.mean(x**2, dim=[0,2,3])\n    mean \/= len(loader)\n    std = (mean_squared\/len(loader) - mean**2)**0.5\n    return mean, std","71503828":"# mean, std = get_mean_std(train_loader)\n# print(mean)\n# print(std)","45e8fb48":"def denormalize(images):\n    #means = torch.tensor(mean).reshape(1, 3, 1, 1)\n    #stds = torch.tensor(std).reshape(1, 3, 1, 1)\n    return images * std + mean","60f0c5e6":"def show_batch():\n    for xb, _ in train_loader:\n        plt.figure(figsize=(14,7))\n        plt.imshow(make_grid(denormalize(xb[:5])).permute(1,2,0))\n        plt.show()\n        break\n\nshow_batch()","c313d317":"# count of samples from each class\n_, counts = np.unique(train.targets, return_counts=True)\nplt.figure(figsize=(8,5))\nplt.bar(train.classes, counts)","097ed9b7":"def get_device():\n    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef to_device(data, device):\n    if isinstance(data,(list, tuple)):\n        return [to_device(x, device) for x in data]\n    else:\n        return data.to(device)\n        \nclass DeviceDataLoader:\n    def __init__(self, data, device):\n        self.data = data\n        self.device = device\n        \n    def __iter__(self):\n        for xb in self.data:\n            yield to_device(xb, self.device)\n            \n    def __len__(self):\n        return len(self.data)","a19bdd1e":"device = get_device()\ndevice","7be19d49":"criterion = nn.BCEWithLogitsLoss()","0dd89e46":"class Pneumonia_Detector(nn.Module):\n    def __init__(self, learning_rate=1e-6):\n        super().__init__()\n        self.network = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n                                     nn.BatchNorm2d(32),\n                                     nn.ReLU(),\n                                     nn.MaxPool2d(2),#32x32x32\n                                     nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n                                     nn.BatchNorm2d(64),\n                                     nn.ReLU(),\n                                     nn.MaxPool2d(2),#16x16x64\n                                     nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n                                     nn.BatchNorm2d(128),\n                                     nn.ReLU(),\n                                     nn.Dropout2d(.1),\n                                     nn.MaxPool2d(2),#8x8x128\n                                     nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n                                     nn.BatchNorm2d(256),\n                                     nn.ReLU(),\n                                     nn.Dropout2d(.1),\n                                     nn.MaxPool2d(2),#4x4x256\n                                     nn.Flatten(),\n                                     nn.Linear(4*4*256, 1024),\n                                     nn.ReLU(),\n                                     nn.Linear(1024, 256),\n                                     nn.ReLU(),\n                                     nn.Linear(256, 1))\n                                   \n        self.loss = None\n        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate)\n        self.history = {'train_loss':[],'val_loss':[],'train_acc':[],'val_acc':[]}\n                \n    def forward(self, xb):\n        return self.network(xb)\n    \n    def backward(self, predictions, targets):\n        self.loss = criterion(predictions, targets.float())\n        self.loss.backward()\n        \n    def update(self):\n        self.optimizer.step()\n        self.optimizer.zero_grad()\n        \n    def accuracy(self, preds, targets):\n        preds[preds>=.5] = 1\n        preds[preds<.5] = 0\n        return torch.sum(preds==targets).item()\/len(preds)\n    \n    def plot_curves(self):\n        plt.figure(figsize=(10,7))\n        plt.subplot(1,2,1)\n        plt.plot(self.history['train_loss'])\n        plt.plot(self.history['val_loss'])\n        plt.legend(['train_loss', 'val_loss'])\n        plt.xlabel('epochs')\n        plt.ylabel('loss')\n        plt.title('Loss curve')\n        \n        plt.subplot(1,2,2)\n        plt.plot(self.history['train_acc'])\n        plt.plot(self.history['val_acc'])\n        plt.legend(['train_acc', 'val_acc'])\n        plt.xlabel('epochs')\n        plt.ylabel('Accuracy')\n        plt.title('Accuracy curve')\n        \n    def fit(self, train_loader, val_loader, num_epochs=10):\n        for i in range(num_epochs):\n            val_loss = 0\n            train_loss = 0\n            train_acc = 0\n            val_acc = 0\n            self.train()\n            for xb, yb in train_loader:\n                predictions = self(xb)\n                self.backward(predictions, yb.unsqueeze(1))\n                self.update()\n                train_loss += self.loss.item()\n                train_acc += self.accuracy(predictions, yb.unsqueeze(1))\n                \n            self.eval()\n            for xb, yb in val_loader:\n                predictions = self(xb)\n                val_loss += criterion(predictions, yb.unsqueeze(1).float()).item()\n                val_acc += self.accuracy(predictions, yb.unsqueeze(1))\n                \n            train_loss \/= len(train_loader)\n            train_acc \/= len(train_loader)\n            val_loss \/= len(val_loader)\n            val_acc \/= len(val_loader)\n            self.history['train_loss'].append(train_loss)\n            self.history['train_acc'].append(train_acc)\n            self.history['val_loss'].append(val_loss)\n            self.history['val_acc'].append(val_acc)\n            print('Epoch {} : \\n\\t train_loss = {:.2f} and val_loss = {:.2f}\\n\\t training_acc = {:.2f} and val_acc = {:.2f}'\n                  .format(i+1,train_loss, val_loss, train_acc*100, val_acc*100))","5e90bd84":"model = Pneumonia_Detector()","00565ad4":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\nmodel = to_device(model, device)","30cd5182":"model.fit(train_loader, val_loader, num_epochs=20)","c4525704":"model.plot_curves()","787ad2f7":"test_loader = DeviceDataLoader(test_loader, device)","bf694928":"def evaluate(loader):\n    model.eval()\n    loss = 0\n    acc = 0\n    for xb, yb in loader:\n        predictions = model(xb)\n        loss += criterion(predictions, yb.unsqueeze(1).float()).item()\n        acc += model.accuracy(predictions, yb.unsqueeze(1))\n    loss \/= len(loader)\n    acc \/= len(loader)\n    print(\"Loss = {:.4f} and Accuracy = {:.2f}%\".format(loss, acc*100))","39033add":"evaluate(test_loader)","ebb6ecd1":"# Select GPU","d46ccdff":"# Explore images","4b9d3efd":"# Build model"}}