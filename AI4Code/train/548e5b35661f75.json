{"cell_type":{"6d9c6825":"code","26e7623f":"code","e4d261ad":"code","182801f4":"code","2b0c4b72":"code","f0294451":"code","8b5c4d0a":"code","377e070c":"code","881099b5":"code","d52dba3b":"code","231bfea5":"code","85aade4b":"markdown","f6703af0":"markdown","53aae90d":"markdown","af3411fc":"markdown","55cb4e13":"markdown","93f0fd62":"markdown","32760850":"markdown","48f762db":"markdown","6414345b":"markdown","63935cf0":"markdown"},"source":{"6d9c6825":"import os\nfrom tqdm.auto import tqdm\nimport time, gc\n\nimport numpy as np\nimport pandas as pd\n# pd.set_option('display.max_columns', None)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport cv2\nimport albumentations as A\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, Input, load_model\nfrom keras.layers import Dense, Conv2D, Flatten, Activation, Concatenate\nfrom keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras.initializers import RandomNormal\nfrom keras.applications import DenseNet121\n\nfrom sklearn.model_selection import train_test_split\n\nstart_time = time.time()","26e7623f":"dataset = '\/kaggle\/input\/bengaliai-cv19'\npretrained = '..\/input\/bangla-graphemes-pretrained-weights'","e4d261ad":"if os.path.isfile(os.path.join(pretrained,\"GraphemeDenseNet121.h5\")) \\\n        and os.path.isfile(os.path.join(pretrained,\"hist.csv\")):\n    print('Model is present')\nelse:\n    print(\"Error. No Model Found\")","182801f4":"SIZE = 100   # input image size\nN_ch = 1","2b0c4b72":"model = load_model(os.path.join(pretrained, 'GraphemeDenseNet121.h5'))","f0294451":"model.summary()","8b5c4d0a":"# Resize image size\ndef resize(df, size=100):\n    resized = {}\n    resize_size=100\n    angle=0\n    for i in range(df.shape[0]):\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            #Centering\n            image_center = tuple(np.array(image.shape[1::-1]) \/ 2)\n            matrix = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_AREA,\n                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n            #Scaling\n            matrix = cv2.getRotationMatrix2D(image_center, 0, 1.0)\n            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_AREA,\n                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n            #Removing Blur\n            #aug = A.GaussianBlur(p=1.0)\n            #image = aug(image=image)['image']\n            #Noise Removing\n            #augNoise=A.MultiplicativeNoise(p=1.0)\n            #image = augNoise(image=image)['image']\n            #Removing Distortion\n            #augDist=A.ElasticTransform(sigma=50, alpha=1, alpha_affine=10, p=1.0)\n            #image = augDist(image=image)['image']\n            #Brightness\n            augBright=A.RandomBrightnessContrast(p=1.0)\n            image = augBright(image=image)['image']\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            #image=affine_image(image)\n            #image= crop_resize(image)\n            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n            #image=resize_image(image,(64,64))\n            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n            #gaussian_3 = cv2.GaussianBlur(image, (5,5), cv2.BORDER_DEFAULT) #unblur\n            #image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)\n            #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n            #image = cv2.filter2D(image, -1, kernel)\n            #ret,image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    resized_df = pd.DataFrame(resized).T\n    return resized_df","377e070c":"df = pd.read_csv(os.path.join(pretrained,'hist.csv'))\n    \n# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(1, 2, figsize = (12, 4))\n\nax[0].plot(df[['root_loss','vowel_loss','consonant_loss',\n               'val_root_loss','val_vowel_loss','val_consonant_loss']])\nax[0].set_ylim(0, 2)\nax[0].set_title('Loss')\nax[0].legend(['train_root_loss','train_vowel_loss','train_conso_loss',\n              'val_root_loss','val_vowel_loss','val_conso_loss'],\n             loc='upper right')\nax[0].grid()\nax[1].plot(df[['root_acc','vowel_acc','consonant_acc',\n               'val_root_acc','val_vowel_acc','val_consonant_acc']])\nax[1].set_ylim(0.5, 1)\nax[1].set_title('Accuracy')\nax[1].legend(['train_root_acc','train_vowel_acc','train_conso_acc',\n              'val_root_acc','val_vowel_acc','val_conso_acc'],\n             loc='lower right')\nax[1].grid()","881099b5":"tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']","d52dba3b":"row_ids = []\ntargets = []      \nid = 0\nfor i in range(4):\n    img_df = pd.read_parquet(os.path.join(\n                            dataset, 'test_image_data_'+str(i)+'.parquet'))\n    img_df = img_df.drop('image_id', axis = 1)\n    img_df = resize(img_df, SIZE) \/ 255\n    X_test = img_df.values.reshape(-1, SIZE, SIZE, N_ch)\n\n    preds = model.predict(X_test)\n    for j in range(len(X_test)):\n        for k in range(3):\n            row_ids.append('Test_'+str(id)+'_'+tgt_cols[k])\n            targets.append(np.argmax(preds[k][j]))\n        id += 1","231bfea5":"df_submit = pd.DataFrame({'row_id':row_ids,'target':targets},\n                         columns = ['row_id','target'])\ndf_submit.to_csv('submission.csv',index=False)\ndf_submit.head(10)","85aade4b":"## Resource path setting ","f6703af0":"## Prediction on Test Images","53aae90d":"## Target Columns","af3411fc":"## Creating Submission CSV File","55cb4e13":"## Accuracy and Loss Curve","93f0fd62":"## Loading Images and Pre-processing","32760850":"## Checking Model","48f762db":"## DenseNet121 Model Summary","6414345b":"## Size and Channel of images","63935cf0":"##  Loading Pretrained Densenet121 Model\n### Batch Size: 256\n### Epochs: 30 (Early Stopped in 20)"}}