{"cell_type":{"06869a7f":"code","51f8bbe6":"code","3e96efcd":"code","94a9a37e":"code","09090704":"code","3ac72656":"code","33f29535":"code","b7b99d65":"code","e8795192":"code","9d539cae":"code","a7fa3124":"code","b3536415":"code","604759e0":"code","e3e89878":"code","43433c2b":"code","04870863":"code","b2ecca91":"code","65ee7779":"code","1493b149":"code","6c3b269f":"code","405a0cbc":"code","5d8b0cc4":"code","549c6a38":"code","3f4c3762":"markdown"},"source":{"06869a7f":"!pip install -q tensorflow-recommenders\n!pip install -q --upgrade tensorflow-datasets","51f8bbe6":"import os\nimport csv\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Text\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf \nimport tensorflow_datasets as tfds\nimport tensorflow_recommenders as tfrs\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nseed = 66","3e96efcd":"tf.config.list_physical_devices('GPU') ","94a9a37e":"def gen(file_name):\n    with open(file_name) as fh:\n        line = fh.readline()\n        while line:\n            yield json.loads(line)\n            line = fh.readline()","09090704":"path = Path.cwd().parent \/ 'input' \/ 'yelp-dataset' \/ 'yelp_academic_dataset_review.json' \nline_gen = gen(path)","3ac72656":"next(line_gen)","33f29535":"# Build a business candidate csv dataset\ndef build_csv_dataset(\n    n_lines, \n    in_file_name='yelp_academic_dataset_review.json', \n    out_file_name='reviews.csv', \n    fields=('user_id', 'business_id', 'stars', 'text')\n):\n    path = Path.cwd().parent \/ 'input' \/ 'yelp-dataset' \/ in_file_name\n    line_gen = gen(path)\n    \n    with open(out_file_name, 'w') as f:\n        csv_writer = csv.writer(f)\n        \n        i = 0\n        for line in line_gen:\n            if i == 0:\n                csv_writer.writerow(fields)\n                i += 1\n            row = {k: line[k] for k in line.keys() if k in fields}.values()\n            csv_writer.writerow(row)\n            i += 1\n            \n            if i % 1000 == 0 :\n                print(f'Processed {i}\/{n_lines} lines', end=\"\\r\")\n\n            if i == n_lines:\n                break\n        print('all done!')    ","b7b99d65":"n_lines = 100_000\n\nbuild_csv_dataset(n_lines)","e8795192":"df_reviews = pd.read_csv('reviews.csv')\ndf_reviews.head()","9d539cae":"path = Path.cwd().parent \/ 'input' \/ 'yelp-dataset' \/ 'yelp_academic_dataset_business.json' \nline_gen = gen(path)\nnext(line_gen)","a7fa3124":"n_lines = 1_000_000\n\nbuild_csv_dataset(\n    n_lines=n_lines, \n    in_file_name='yelp_academic_dataset_business.json', \n    out_file_name='businesses.csv', \n    fields=('business_id', 'name')\n)","b3536415":"df_businesses = pd.read_csv('businesses.csv')\ndf_businesses.head()\ndf_businesses.info()","604759e0":"# Subset the businesses to the ones seen in the reviews dataset\nbusiness_ids = df_reviews.business_id.unique()\ndf_businesses = df_businesses[df_businesses.business_id.isin(business_ids)]\ndf_businesses.to_csv('businesses.csv', index=False)","e3e89878":"df_businesses = pd.read_csv('businesses.csv')\ndf_businesses.head()\ndf_businesses.info()","43433c2b":"reviews = tf.data.experimental.CsvDataset(\n    filenames='reviews.csv', \n    record_defaults=[tf.string, tf.string, tf.float64, tf.string],\n    header=True\n)\nbusinesses = tf.data.experimental.CsvDataset(\n    filenames='businesses.csv', \n    record_defaults=[tf.string, tf.string],\n    header=True\n)\n\ndef preprocess_reviews(user_id, business_id, stars, text):\n  return {\n    \"user_id\": user_id,\n    \"business_id\": business_id,\n    \"stars\": stars,\n    \"text\": text\n  }\n\ndef preprocess_businesses(business_id, name):\n  return {\n      'business_id': business_id,\n      'name': name\n  }\n\n\nreviews = reviews.map(preprocess_reviews)\nbusinesses = businesses.map(preprocess_businesses)","04870863":"%%time\nuser_id_lookup = tf.keras.layers.StringLookup(mask_token=None)\nuser_id_lookup.adapt(reviews.map(lambda x: x[\"user_id\"]))","b2ecca91":"%%time\nbusiness_id_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\nbusiness_id_vocabulary.adapt(businesses.map(lambda x: x['business_id']))","65ee7779":"%%time\ntext = tf.keras.layers.TextVectorization()\ntext.adapt(reviews.map(lambda x: x[\"text\"]))","1493b149":"class UserModel(tf.keras.Model):\n\n  def __init__(self):\n    super().__init__()\n    \n    #max_tokens = 10_000\n\n    self.user_id_embedding = tf.keras.Sequential([\n        user_id_lookup,\n        tf.keras.layers.Embedding(user_id_lookup.vocab_size(), 32),\n    ])\n    self.stars_embedding = tf.keras.Sequential([\n        tf.keras.layers.CategoryEncoding(num_tokens=6, output_mode='one_hot'),\n        tf.keras.layers.Embedding(6, 32),\n        tf.keras.layers.GlobalAveragePooling1D()\n    ])\n    self.text_embedding = tf.keras.Sequential([\n        #tf.keras.layers.TextVectorization(max_tokens=max_tokens),\n        text,\n        tf.keras.layers.Embedding(text.vocabulary_size(), 32, mask_zero=True),\n        tf.keras.layers.GlobalAveragePooling1D()\n    ])\n\n\n  def call(self, inputs):\n\n    # Take the input dictionary, pass it through each input layer,\n    # and concatenate the result.\n    return tf.concat([\n        self.user_id_embedding(inputs['user_id']),\n        self.stars_embedding(inputs['stars']),\n        self.text_embedding(inputs['text'])\n    ], axis=1)","6c3b269f":"class BusinessModel(tf.keras.Model):\n\n  def __init__(self):\n    super().__init__()\n\n    self.business_id_embedding = tf.keras.Sequential([\n        business_id_vocabulary,\n        tf.keras.layers.Embedding(business_id_vocabulary.vocabulary_size(), 64)\n    ])\n\n  def call(self, inputs):\n    return tf.concat([\n        self.business_id_embedding(inputs['business_id'])\n    ], axis=1)","405a0cbc":"class YelpModel(tfrs.models.Model):\n\n  def __init__(self):\n    super().__init__()\n    self.query_model = tf.keras.Sequential([\n      UserModel(),\n      tf.keras.layers.Dense(32)\n    ])\n    self.candidate_model = tf.keras.Sequential([\n      BusinessModel(),\n      tf.keras.layers.Dense(32)\n    ])\n    self.task = tfrs.tasks.Retrieval(\n        metrics=tfrs.metrics.FactorizedTopK(\n            candidates=businesses.batch(128).map(self.candidate_model),\n        ),\n    )\n\n  def compute_loss(self, features, training=False):\n    query_embeddings = self.query_model({\n        \"user_id\": features[\"user_id\"],\n        \"stars\": features[\"stars\"],\n        \"text\": features[\"text\"]\n    })\n    business_embeddings = self.candidate_model(features)\n\n    return self.task(query_embeddings, business_embeddings)","5d8b0cc4":"model = YelpModel()\nmodel.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n\nn_samples = df_reviews.shape[0]\nn_samples_train = int(n_samples * .8)\nn_samples_test = n_samples - n_samples_train\n\ntf.random.set_seed(seed=seed)\nshuffled = reviews.shuffle(n_samples, seed=seed, reshuffle_each_iteration=False)\n\ntrain = shuffled.take(n_samples_train)\ntest = shuffled.skip(n_samples_train).take(n_samples_test)\ncached_train = train.shuffle(n_samples_train).batch(8192).cache()\ncached_test = test.batch(4096).cache()\n\nmodel.fit(cached_train, epochs=20)\nmodel.evaluate(cached_test, return_dict=True)","549c6a38":"# Use brute-force search to set up retrieval using the trained representations.\nindex = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\nindex.index_from_dataset(\n    businesses.batch(100).map(\n        lambda business_id: (business_id, model.item_model(business_id))\n    )\n)\n\n# Get some recommendations.\nuser_id = 'CxDqwWWz1VhVY65AskL5rQ'\n_, business_id = index(np.array([user_id]))\nprint(f\"Recommendations for user {user_id}: \\n{business_id}\")","3f4c3762":"## Improvement Ideas\n- Use all data to train\n- Use more features including stars and reviews\n- Try different architectures\n- Model hyperparameter tuning"}}