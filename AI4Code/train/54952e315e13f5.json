{"cell_type":{"9e7c5262":"code","aa9ffecf":"code","c811a0df":"code","ede02116":"code","87839c92":"code","b77979fd":"code","8f6140bd":"code","888c571b":"code","71eabcec":"code","f7900272":"code","accc6863":"code","40f61615":"code","7d0bc733":"code","beca4bdc":"code","2ca48802":"code","054f1425":"code","e7bd9dbc":"code","62a359bf":"code","821a0867":"code","46f766b9":"code","3f3ad5f6":"code","c40c6494":"markdown","4a83a9d7":"markdown","b0767784":"markdown","82fe2246":"markdown","72a55a9f":"markdown","2327aedc":"markdown","6137be91":"markdown","864d00f2":"markdown","1d791e8f":"markdown","fefdb695":"markdown","29117bbd":"markdown","95be5836":"markdown"},"source":{"9e7c5262":"import glob, pylab, pandas as pd\nimport pydicom, numpy as np\n\nimport os\nimport csv\nimport random\nfrom skimage import measure\nfrom skimage.transform import resize\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom matplotlib import pyplot as plt\n\n!ls ..\/input","aa9ffecf":"df = pd.read_csv('..\/input\/stage_1_train_labels.csv')\nprint(df.iloc[0])","c811a0df":"print(df.iloc[8])","ede02116":"from os import listdir\nfrom os.path import isfile, join\n\n\ndet_class_path = '..\/input\/stage_1_detailed_class_info.csv'\nbbox_path = '..\/input\/stage_1_train_labels.csv'\ndicom_dir = '..\/input\/stage_1_train_images\/'\n\ntrain_images_dir = '..\/input\/stage_1_train_images\/'\ntrain_images = [f for f in listdir(train_images_dir) if isfile(join(train_images_dir, f))]\ntest_images_dir = '..\/input\/stage_1_test_images\/'\ntest_images = [f for f in listdir(test_images_dir) if isfile(join(test_images_dir, f))]\n\nprint('Number of train images:', len(train_images))\nprint('Number of test images:', len(test_images))","87839c92":"patientId = df['patientId'][4]\ndcm_file = '..\/input\/stage_1_train_images\/%s.dcm' % patientId\ndcm_data = pydicom.read_file(dcm_file)\n\nprint(dcm_data)","b77979fd":"patientId2 = df['patientId'][55]\ndcm_file2 = '..\/input\/stage_1_train_images\/%s.dcm' % patientId2\ndcm_data2 = pydicom.read_file(dcm_file2)\n\nprint(dcm_data2)","8f6140bd":"im = dcm_data.pixel_array\nprint(type(im))\nprint(im.dtype)\nprint(im.shape)","888c571b":"pylab.imshow(im, cmap=pylab.cm.gist_gray)","71eabcec":"im2 = dcm_data2.pixel_array\npylab.imshow(im2, cmap=pylab.cm.gist_gray)","f7900272":"def parse_data(df):\n    \"\"\"\n      parsed = {\n        \n        'patientId-00': {\n            'dicom': path\/to\/dicom\/file,\n            'label': either 0 or 1 for normal or pnuemonia, \n            'boxes': list of box(es)\n        },\n        'patientId-01': {\n            'dicom': path\/to\/dicom\/file,\n            'label': either 0 or 1 for normal or pnuemonia, \n            'boxes': list of box(es)\n        }, ...\n\n      }\n\n    \"\"\"\n    # Define lambda to extract coords in list [y, x, height, width]\n    extract_box = lambda row: [row['y'], row['x'], row['height'], row['width']]\n\n    parsed = {}\n    for n, row in df.iterrows():\n        pid = row['patientId']\n        if pid not in parsed:\n            parsed[pid] = {\n                'dicom': '..\/input\/stage_1_train_images\/%s.dcm' % pid,\n                'label': row['Target'],\n                'boxes': []}\n\n        # Add box if opacity is present\n        if parsed[pid]['label'] == 1:\n            parsed[pid]['boxes'].append(extract_box(row))\n\n    return parsed\n\n\n\nparsed = parse_data(df)\n\n\n\nprint(parsed['00436515-870c-4b36-a041-de91049b9ab4'])\n","accc6863":"def draw(data):\n    #Open DICOM file\n    d = pydicom.read_file(data['dicom'])\n    im = d.pixel_array\n\n    #Convert from single-channel grayscale to 3-channel RGB\n    im = np.stack([im] * 3, axis=2)\n\n    #Add boxes with random color if present\n    for box in data['boxes']:\n        rgb = np.floor(np.random.rand(3) * 256).astype('int')\n        im = overlay_box(im=im, box=box, rgb=rgb, stroke=6)\n\n    pylab.imshow(im, cmap=pylab.cm.gist_gray)\n    \n    \n\ndef overlay_box(im, box, rgb, stroke=1):\n    #Convert coordinates to integers\n    box = [int(b) for b in box]\n    \n    #Extract coordinates\n    y1, x1, height, width = box\n    y2 = y1 + height\n    x2 = x1 + width\n\n    im[y1:y1 + stroke, x1:x2] = rgb\n    im[y2:y2 + stroke, x1:x2] = rgb\n    im[y1:y2, x1:x1 + stroke] = rgb\n    im[y1:y2, x2:x2 + stroke] = rgb\n\n    return im\n\n\n\ndraw(parsed['00436515-870c-4b36-a041-de91049b9ab4'])","40f61615":"df_detailed = pd.read_csv('..\/input\/stage_1_detailed_class_info.csv')\nprint(df_detailed.iloc[6])\nprint(df_detailed.iloc[80])","7d0bc733":"# empty dictionary\nnodule_locations = {}\n# load table\nwith open(os.path.join('..\/input\/stage_1_train_labels.csv'), mode='r') as infile:\n    reader = csv.reader(infile)\n    # skip header\n    next(reader, None)\n\n    for rows in reader:\n        filename = rows[0]\n        location = rows[1:5]\n        nodule = rows[5]\n        # if row contains a nodule add label to dictionary\n        # which contains a list of nodule locations per filename\n        if nodule == '1':\n            # convert string to float to int\n            location = [int(float(i)) for i in location]\n            # save nodule location in dictionary\n            if filename in nodule_locations:\n                nodule_locations[filename].append(location)\n            else:\n                nodule_locations[filename] = [location]\n","beca4bdc":"folder = '..\/input\/stage_1_train_images'\nfilenames = os.listdir(folder)\nrandom.shuffle(filenames)\n# split into train and validation filenames\nn_valid_samples = 2000\ntrain_filenames = filenames[n_valid_samples:]\nvalid_filenames = filenames[:n_valid_samples]\nprint('n train samples', len(train_filenames))\nprint('n valid samples', len(valid_filenames))\nn_train_samples = len(filenames) - n_valid_samples","2ca48802":"class generator(keras.utils.Sequence):\n    \n    def __init__(self, folder, filenames, nodule_locations=None, batch_size=32, image_size=256, shuffle=True, predict=False):\n        self.folder = folder\n        self.filenames = filenames\n        self.nodule_locations = nodule_locations\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.shuffle = shuffle\n        self.predict = predict\n        self.on_epoch_end()\n        \n    def __load__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n        # create empty mask\n        msk = np.zeros(img.shape)\n        # get filename without extension\n        filename = filename.split('.')[0]\n        # if image contains nodules\n        if filename in nodule_locations:\n            # loop through nodules\n            for location in nodule_locations[filename]:\n                # add 1's at the location of the nodule\n                x, y, w, h = location\n                msk[y:y+h, x:x+w] = 1\n        # resize both image and mask\n        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n        # add trailing channel dimension\n        img = np.expand_dims(img, -1)\n        msk = np.expand_dims(msk, -1)\n        return img, msk\n    \n    def __loadpredict__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n        # resize image\n        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n        # add trailing channel dimension\n        img = np.expand_dims(img, -1)\n        return img\n        \n    def __getitem__(self, index):\n        # select batch\n        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n        # predict mode: return images and filenames\n        if self.predict:\n            # load files\n            imgs = [self.__loadpredict__(filename) for filename in filenames]\n            # create numpy batch\n            imgs = np.array(imgs)\n            return imgs, filenames\n        # train mode: return images and masks\n        else:\n            # load files\n            items = [self.__load__(filename) for filename in filenames]\n            # unzip images and masks\n            imgs, msks = zip(*items)\n            # create numpy batch\n            imgs = np.array(imgs)\n            msks = np.array(msks)\n            return imgs, msks\n        \n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n        \n    def __len__(self):\n        if self.predict:\n            # return everything\n            return int(np.ceil(len(self.filenames) \/ self.batch_size))\n        else:\n            # return full batches only\n            return int(len(self.filenames) \/ self.batch_size)","054f1425":"def create_downsample(channels, inputs):\n    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n    x = keras.layers.MaxPool2D(2)(x)\n    return x\n\ndef create_resblock(channels, inputs):\n    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n    return keras.layers.add([x, inputs])\n\ndef create_network(input_size, channels, n_blocks=2, depth=4):\n    # input\n    inputs = keras.Input(shape=(input_size, input_size, 1))\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n    # residual blocks\n    for d in range(depth):\n        channels = channels * 2\n        x = create_downsample(channels, x)\n        for b in range(n_blocks):\n            x = create_resblock(channels, x)\n    # output\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n    outputs = keras.layers.UpSampling2D(2**depth)(x)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model","e7bd9dbc":"# define iou or jaccard loss function\ndef iou_loss(y_true, y_pred):\n    y_true = tf.reshape(y_true, [-1])\n    y_pred = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true * y_pred)\n    score = (intersection + 1.) \/ (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n    return 1 - score\n\n# combine bce loss and iou loss\ndef iou_bce_loss(y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n\n# mean iou as a metric\ndef mean_iou(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n    smooth = tf.ones(tf.shape(intersect))\n    return tf.reduce_mean((intersect + smooth) \/ (union - intersect + smooth))\n\n# create network and compiler\nmodel = create_network(input_size=256, channels=32, n_blocks=2, depth=4)\nmodel.compile(optimizer='adam',\n              loss=iou_bce_loss,\n              metrics=['accuracy', mean_iou])\n\n# cosine learning rate annealing\ndef cosine_annealing(x):\n    lr = 0.001\n    epochs = 25\n    return lr*(np.cos(np.pi*x\/epochs)+1.)\/2\nlearning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)\n\n# create train and validation generators\nfolder = '..\/input\/stage_1_train_images'\ntrain_gen = generator(folder, train_filenames, nodule_locations, batch_size=32, image_size=256, shuffle=True, predict=False)\nvalid_gen = generator(folder, valid_filenames, nodule_locations, batch_size=32, image_size=256, shuffle=False, predict=False)\n\nhistory = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=2, shuffle=True)","62a359bf":"from sklearn import feature_selection, linear_model, metrics, preprocessing\n\n\nfolder = '..\/input\/stage_1_test_images\/'\nfilenames = os.listdir(folder)\n#random.shuffle(filenames)\n\n\n\n","821a0867":"n_y_samples = 1 #must be at least 500 (it is currently used to test 1 image only)\ntest_X = filenames[999:]  #must be: test_X = filenames[n_y_samples:]\ntest_Y = filenames[:n_y_samples]\nprint('n test_x', len(test_X))\nprint('n test_y', len(test_Y))\nn_x_samples = len(filenames) - n_y_samples","46f766b9":"#should return a shape of (1, 32, 32, 3)  ???\n\ntest_x_gen = generator(folder, test_X, nodule_locations, batch_size=32, image_size=256, shuffle=True, predict=False)\ntest_y_gen = generator(folder, test_Y, nodule_locations, batch_size=32, image_size=256, shuffle=True, predict=False)\n\n#print (test_x_gen)\n#print (test_y_gen)\n    \n","3f3ad5f6":"#score = model.evaluate(np.expand_dims(test_x_gen, axis=3), test_y_gen, batch_size=32)\n#print (score)\n\n#model.predict(test_x_gen)\n              \n#metrics.accuracy_score(np.array(test_y_gen), model.predict(np.array(test_x_gen)))\n","c40c6494":"**Model**","4a83a9d7":"## **Data Summary**\n\n**Stage 1 Images** - stage_1_train_images.zip and stage_1_test_images.zip\nimages for the current stage. Filenames are also patient names.\n\n**Stage 1 Labels** - stage_1_train_labels.csv and Stage 1 Sample Submission stage_1_sample_submission.csv\nWhich provides the IDs for the test set, as well as a sample of what your submission should look like\n\n**Stage 1 Detailed Info** - stage_1_detailed_class_info.csv\ncontains detailed information about the positive and negative classes in the training set, and may be used to build more nuanced models.","b0767784":"* high bit-depth original images have been rescaled to 8-bit encoding (256 grayscales)\n* Thel image matrices (typically acquired at >2000 x 2000) have been resized to the shape of 1024 x 1024","82fe2246":"## **Data fields**\n**patientId _**- A patientId. Each patientId corresponds to a unique image.\n\n**x_ **- the upper-left x coordinate of the bounding box.\n\n**y_ **- the upper-left y coordinate of the bounding box.\n\n**width_** - the width of the bounding box.\n\n**height_** - the height of the bounding box.\n\n**Target_** - the binary Target, indicating whether this sample has evidence of pneumonia.","72a55a9f":"## **Overlay color boxes on the original grayscale DICOM files:****","2327aedc":"## **DICOM files:**","6137be91":"![](http:\/\/)# **RSNA Pneumonia Detection Challenge**","864d00f2":"## **File descriptions**\n\n**stage_1_train.csv** - the training set. Contains patientIds and bounding box \/ target information.\n\n**stage_1_sample_submission.csv** - a sample submission file in the correct format.\n\n**stage_1_detailed_class_info.csv** - provides detailed information about the type of positive or negative class for each image.","1d791e8f":"## **Exploring Detailed Labels**\n\nIn addition to the binary classification (the presence or absence of pneumonia), each bounding box without pneumonia is further categorized into normal or no lung opacity \/ not normal (abnormality on the image)","fefdb695":"## **Overview**\n\n\n![alt text](https:\/\/i.pinimg.com\/564x\/ff\/cd\/c4\/ffcdc4d74eed036d029a84c381604a10.jpg)\n\n## **Symptoms to detect Pneumonia**\n\nThe Diagnosis of pneumonia on CXR( is complicated because of a number of other nditions in the lungsuch as uid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes.","29117bbd":"## **1-Exploring the data**","95be5836":"## **CSV into a data structure with unique entries (the patient ID):**\n\nAny patient may  have many boxes if there are several different suspicious areas of pneumonia. "}}