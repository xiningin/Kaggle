{"cell_type":{"9a8fcebe":"code","f68638e8":"code","a1e4fa38":"code","d9a1097d":"code","9246fe9d":"code","793903e5":"code","865f0022":"code","df770ee4":"code","2b35560a":"code","0548921f":"code","c2e3354e":"code","986045bc":"code","d0f40add":"code","aa7f5011":"code","b6608122":"code","0b3f3371":"code","e93ae61b":"code","f060eee6":"code","ed6e5316":"code","81650ba0":"code","c45a1a40":"code","509178ce":"code","e9a42fb6":"code","fd97fe14":"code","873f1444":"code","bf404bee":"code","6af9ff3d":"code","b12ba57d":"code","6f2217b0":"code","11fbfb83":"code","7d7ee168":"code","e82379e4":"markdown","5b284c44":"markdown","945e15fb":"markdown","8a36214c":"markdown","f464c391":"markdown","fc1a5d80":"markdown","cc1acea1":"markdown","bfb881b7":"markdown","b7da116f":"markdown","fecdb6f9":"markdown","07e98f0e":"markdown","28958287":"markdown","af0f1491":"markdown","2370b43f":"markdown","088e696c":"markdown","31ef1f15":"markdown","20f1bb15":"markdown","f04f972b":"markdown","f7a99baf":"markdown","0ca2197a":"markdown","dd0c349c":"markdown","b5fbde9b":"markdown","f27fb621":"markdown","610e7c5c":"markdown","7db002db":"markdown","b2075698":"markdown","5e3e62cc":"markdown","0d5f701a":"markdown","334dca2f":"markdown","86b83294":"markdown","31f56978":"markdown","00f0cf2e":"markdown"},"source":{"9a8fcebe":"import os\ntry:\n    inpath = \"..\/input\/data\/\" #Kaggle\n    print(os.listdir(inpath))\nexcept FileNotFoundError:\n    inpath = \".\/\" #Local\n    print(os.listdir(inpath))","f68638e8":"import pandas as pd\ndata = pd.read_csv(inpath + 'Data_Entry_2017.csv')\nprint(f\"Las dimensiones del conjunto de datos son: {data.shape}\")\n\ndata.head()","a1e4fa38":"data = data[data['Patient Age']<100]\n\nprint(f\"Las dimensiones del conjunto de datos son: {data.shape}\")","d9a1097d":"data = data[['Image Index', 'Finding Labels']]\n\nprint(f\"Las dimensiones del conjunto de datos son: {data.shape}\")","9246fe9d":"\"\"\"\nLeemos todas las rutas de las imagenes\n\"\"\"\nfrom glob import glob\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input','nih-chest-xrays-224-gray', 'images*', '*.png'))}\nprint('Im\u00e1genes encontradas:', len(all_image_paths))\n\n\"\"\"\nAgregamos la columna path al conjunto de datos\n\"\"\"\ndata['Path'] = data['Image Index'].map(all_image_paths.get)\n\ndata.sample(5, random_state=3)","793903e5":"\"\"\"\nCreate a np array with all the single deseases\n\"\"\"\nimport numpy as np\nfrom itertools import chain\nall_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n\nall_labels","865f0022":"all_labels = np.delete(all_labels, np.where(all_labels == 'No Finding'))\nprint(f'Tipo actual: {type(all_labels)}')\n\nall_labels = [x for x in all_labels]\nprint(f'Tipo final: {type(all_labels)}')\n\nprint(f'Enfermedades: ({len(all_labels)}): {all_labels}')","df770ee4":"\"\"\"\nAgregamos una columna, por cada enfermedad\n\"\"\"\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        # Add a column for each desease\n        data[c_label] = data['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n        \nprint(f\"Las dimensiones del conjunto de datos son: {data.shape}\")\ndata.head()","2b35560a":"label_counts = data['Finding Labels'].value_counts()\nlabel_counts","0548921f":"data = data.groupby('Finding Labels').filter(lambda x : len(x)>11)","c2e3354e":"label_counts = data['Finding Labels'].value_counts()\nprint(label_counts.shape)\nlabel_counts","986045bc":"from sklearn.model_selection import train_test_split\n\ntrain_and_valid_df, test_df = train_test_split(data,\n                                               test_size = 0.30,\n                                               random_state = 2018,\n                                              )\n\ntrain_df, valid_df = train_test_split(train_and_valid_df,\n                                      test_size=0.30,\n                                      random_state=2018,\n                                     )\n\nprint(f'Entrenamiento {train_df.shape[0]} Validaci\u00f3n {valid_df.shape[0]} Prueba: {test_df.shape[0]}')","d0f40add":"from keras_preprocessing.image import ImageDataGenerator\nbase_generator = ImageDataGenerator(rescale=1.\/255)","aa7f5011":"IMG_SIZE = (224, 224)\ndef flow_from_dataframe(image_generator, dataframe, batch_size):\n\n    df_gen = image_generator.flow_from_dataframe(dataframe,\n                                                 x_col='Path',\n                                                 y_col=all_labels,\n                                                 target_size=IMG_SIZE,\n                                                 classes=all_labels,\n                                                 color_mode='rgb',\n                                                 class_mode='raw',\n                                                 shuffle=False,\n                                                 batch_size=batch_size)\n    \n    return df_gen","b6608122":"train_gen = flow_from_dataframe(image_generator=base_generator, \n                                dataframe= train_df,\n                                batch_size = 32)\n\nvalid_gen = flow_from_dataframe(image_generator=base_generator, \n                                dataframe=valid_df,\n                                batch_size = 32)\n\ntest_gen = flow_from_dataframe(image_generator=base_generator, \n                               dataframe=test_df,\n                               batch_size = 32)","0b3f3371":"train_x, train_y = next(train_gen)\nprint(f\"Dimensiones de la imagen: {train_x[1].shape}\")\nprint(f\"Vector de enfermedades: {train_y[1]}\")","e93ae61b":"from keras.layers import Input\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers.core import Dense\nfrom keras.models import Model\n\ninput_shape=(224, 224, 3)\nimg_input = Input(shape=input_shape)\n\nbase_model = VGG16(include_top=False, input_tensor=img_input, input_shape=input_shape, \n                         pooling=\"avg\", weights='imagenet')\nx = base_model.output\npredictions = Dense(len(all_labels), activation=\"sigmoid\", name=\"predictions\")(x)\nmodel = Model(inputs=img_input, outputs=predictions)","f060eee6":"from contextlib import redirect_stdout\n\nwith open('model_summary.txt', 'w') as f:\n    with redirect_stdout(f):\n        model.summary()","ed6e5316":"from keras.callbacks import ModelCheckpoint\nmodel_train = model\noutput_weights_name='weights.h5'\ncheckpoint = ModelCheckpoint(\n             output_weights_name,\n             save_weights_only=True,\n             save_best_only=True,\n             verbose=1,\n            )","81650ba0":"import keras.backend as kb\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import roc_auc_score\nimport shutil\nimport warnings\nimport json\n\nclass MultipleClassAUROC(Callback):\n    \"\"\"\n    Monitor mean AUROC and update model\n    \"\"\"\n    def __init__(self, generator, class_names, weights_path, stats=None):\n        super(Callback, self).__init__()\n        self.generator = generator\n        self.class_names = class_names\n        self.weights_path = weights_path\n        self.best_weights_path = os.path.join(\n            os.path.split(weights_path)[0],\n            f\"best_{os.path.split(weights_path)[1]}\",\n        )\n        self.best_auroc_log_path = os.path.join(\n            os.path.split(weights_path)[0],\n            \"best_auroc.log\",\n        )\n        self.stats_output_path = os.path.join(\n            os.path.split(weights_path)[0],\n            \".training_stats.json\"\n        )\n        # for resuming previous training\n        if stats:\n            self.stats = stats\n        else:\n            self.stats = {\"best_mean_auroc\": 0}\n\n        # aurocs log\n        self.aurocs = {}\n        for c in self.class_names:\n            self.aurocs[c] = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        \"\"\"\n        Calcula el promedio de las Curvas ROC y guarda el mejor grupo de pesos\n        de acuerdo a esta metrica\n        \"\"\"\n        print(\"\\n*********************************\")\n        self.stats[\"lr\"] = float(kb.eval(self.model.optimizer.lr))\n        print(f\"Learning Rate actual: {self.stats['lr']}\")\n\n        \"\"\"\n        y_hat shape: (#ejemplos, len(etiquetas))\n        y: [(#ejemplos, 1), (#ejemplos, 1) ... (#ejemplos, 1)]\n        \"\"\"\n        y_hat = self.model.predict_generator(self.generator,steps=self.generator.n\/self.generator.batch_size)\n        y = self.generator.labels\n\n        print(f\"*** epoch#{epoch + 1} Curvas ROC Fase Entrenamiento ***\")\n        current_auroc = []\n        for i in range(len(self.class_names)):\n            try:\n                score = roc_auc_score(y[:, i], y_hat[:, i])\n            except ValueError:\n                score = 0\n            self.aurocs[self.class_names[i]].append(score)\n            current_auroc.append(score)\n            print(f\"{i+1}. {self.class_names[i]}: {score}\")\n        print(\"*********************************\")\n\n        mean_auroc = np.mean(current_auroc)\n        print(f\"Promedio Curvas ROC: {mean_auroc}\")\n        if mean_auroc > self.stats[\"best_mean_auroc\"]:\n            print(f\"Actualizaci\u00f3n del resultado de las Curvas de ROC de: {self.stats['best_mean_auroc']} a {mean_auroc}\")\n\n            # 1. copy best model\n            shutil.copy(self.weights_path, self.best_weights_path)\n\n            # 2. update log file\n            print(f\"Actualizaci\u00f3n del archivo de logs: {self.best_auroc_log_path}\")\n            with open(self.best_auroc_log_path, \"a\") as f:\n                f.write(f\"(epoch#{epoch + 1}) auroc: {mean_auroc}, lr: {self.stats['lr']}\\n\")\n\n            # 3. write stats output, this is used for resuming the training\n            with open(self.stats_output_path, 'w') as f:\n                json.dump(self.stats, f)\n\n            print(f\"Actualizaci\u00f3n del grupo de pesos: {self.weights_path} -> {self.best_weights_path}\")\n            self.stats[\"best_mean_auroc\"] = mean_auroc\n            print(\"*********************************\")\n        return","c45a1a40":"training_stats = {}\nauroc = MultipleClassAUROC(\n    generator=valid_gen,\n    class_names=all_labels,\n    weights_path=output_weights_name,\n    stats=training_stats\n)","509178ce":"from keras.optimizers import Adam\ninitial_learning_rate=1e-3\noptimizer = Adam(lr=initial_learning_rate)\nmodel_train.compile(optimizer=optimizer, loss=\"binary_crossentropy\")","e9a42fb6":"from keras.callbacks import TensorBoard, ReduceLROnPlateau\n#TODO - VALIDATE THE LOGS OUTPUT\nlogs_base_dir = '..\/working\/'\npatience_reduce_lr=2\nmin_lr=1e-8\ncallbacks = [\n            checkpoint,\n            TensorBoard(log_dir=os.path.join(logs_base_dir, \"logs\"), batch_size=train_gen.batch_size),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,\n                              verbose=1, mode=\"min\", min_lr=min_lr),\n            auroc,\n        ]","fd97fe14":"epochs=20\nfit_history = model.fit_generator(\n    generator=train_gen,\n    steps_per_epoch=train_gen.n\/train_gen.batch_size,\n    epochs=epochs,\n    validation_data=valid_gen,\n    validation_steps=valid_gen.n\/valid_gen.batch_size,\n    callbacks=callbacks,\n    shuffle=False\n)","873f1444":"import matplotlib.pyplot as plt\n\nplt.figure(1, figsize = (15,8)) \n    \nplt.subplot(222)  \nplt.plot(fit_history.history['loss'])  \nplt.plot(fit_history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \n\nplt.show()","bf404bee":"model.load_weights('weights.h5')","6af9ff3d":"pred_y = model.predict_generator(test_gen, steps=test_gen.n\/test_gen.batch_size, verbose = True)","b12ba57d":"test_gen.reset()\ntest_x, test_y = next(test_gen)\nprint(f\"Vector de enfermedades: {test_y[1]}\")\nprint(f\"Vector de enfermedades producto de la predicci\u00f3n: {pred_y[2]}\")","6f2217b0":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\ntest_gen.reset()\ntest_x, test_y = next(test_gen)\n# Space\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    #Points to graph\n    fpr, tpr, thresholds = roc_curve(test_gen.labels[:,idx].astype(int), pred_y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    \n#convention\nc_ax.legend()\n\n#Labels\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\n\n# Save as a png\nfig.savefig('barely_trained_net.png')","11fbfb83":"from sklearn.metrics import roc_auc_score\n# ROC AUC\nauc = roc_auc_score(test_gen.labels, pred_y)\nprint('ROC AUC: %f' % auc)","7d7ee168":"sickest_idx = np.argsort(np.sum(test_y, 1)<1)\n\n#Space of images\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n\n# Padding\nfig.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\ncounter = 0\n\nfor (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n    \n    # Image show\n    c_ax.imshow(test_x[idx, :,:,0], cmap = 'bone')\n    \n    stat_str = [n_class[:4] for n_class, n_score in zip(all_labels, test_y[idx]) if n_score>0.5]\n        \n    # Building the labels\n    pred_str = [f'{n_class[:4]}:{p_score*100:.2f}%'\n                for n_class, n_score, p_score \n                in zip(all_labels,test_y[idx],pred_y[idx]) \n                if (n_score>0.5) or (p_score>0.5)]\n    \n    c_ax.set_title(f'Index {idx}, Labels: '+', '.join(stat_str)+'\\n Pred: '+', '.join(pred_str))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png')","e82379e4":"# 2. Modelado\n\nEn la etapa de modelado hacemo uso del Framework [Keras](https:\/\/keras.io\/) el cual nos provee una API para trabajar con redes neuronales de alto nivel, lo que la hace una alternativa muy buena para personas como nosotros que estamos empezando en el mundo de la inteligencia artificial.\n\nKeras funciona como una capa que simplifica el uso de Frameworks (los cuales keras denomina Backends) como [TensorFlow](https:\/\/www.tensorflow.org\/) , [CNTK](https:\/\/docs.microsoft.com\/en-us\/cognitive-toolkit\/) o [Theano](http:\/\/deeplearning.net\/software\/theano\/), lo cual nos permite entre otras cosas tener la capacidad de experimentar configuraciones de una forma m\u00e1s r\u00e1pida.\n \nOtra ventaja que tiene  Keras es que nos permite trabajar tanto con CPU como con [GPU](https:\/\/www.kaggle.com\/dansbecker\/running-kaggle-kernels-with-a-gpu).\n\n> En este caso utilizaremos Keras sobre Tensorflow\n\n### Creaci\u00f3n del Modelo[](http:\/\/)\n\nLa estructura del modelo que se va a probar es la siguiente:\n\n* La base del modelo es la arquitectura (aplicaci\u00f3n) seleccionada la cual posee las siguientes configuraciones:\n    * **Include_top**: el cual va a estar en false debido a que deseamos agregar nuestra propia capa de predicciones con las 14 salidas que poseemos.\n    * **Input_shape**: en el cual almacenaremos las dimensiones de las im\u00e1genes que usaremos\n    * **Pooling:** en este caso usaremos \u201cavg\u201d para que realice una agrupaci\u00f3n de la salida del \u00faltimo bloque convolucional y de esta forma facilitar el proceso de la capa densa que agregaremos inmediatamente despu\u00e9s.\n    * **Weights:** los pesos en este caso ser\u00e1n los de \u2018imagenet\u2019, en este punto podemos afirmar que realizamos un proceso de **Transfer Learning**\n    \n* Una capa [densa](https:\/\/keras.io\/layers\/core\/#dense) la cual nos permitir\u00e1 obtener las predicciones de nuestra [CNN](https:\/\/developers.google.com\/machine-learning\/glossary#red-neuronal-convolucional-convolutional-neural-network), esta capa recibe:\n    * La cantidad de salidas que esperamos que en este caso es 14, la misma cantidad de etiquetas que deseamos clasificar\n    * una [funci\u00f3n de activaci\u00f3n](https:\/\/developers.google.com\/machine-learning\/glossary?hl=es-419#funci%C3%B3n-de-activaci%C3%B3n-activation-function) [sigmoid](https:\/\/developers.google.com\/machine-learning\/glossary?hl=es-419#atributo-sigmoide-sigmoid-function) la cual es la m\u00e1s aconsejada tipo de problemas, la cual nos retorna valores entre 0 y 1 (para cada una de las etiquetas a clasificar)\n    \nEsto significa que una predicci\u00f3n de nuestra CNN va a ser similar a nuestro vector de enfermedades, con la diferencia de que no lo encontraremos con valores binarios 0 o 1 sino que lo encontraremos con valores entre 0 y 1, en donde los m\u00e1s cercanos a 1 nos van a indicar que la predicci\u00f3n se inclina m\u00e1s por ese tipo de etiqueta o etiquetas a la hora de la clasificaci\u00f3n.","5b284c44":"* Usamos nuestro modelo para clasificar imagenes del conjunto de datos de prueba","945e15fb":"### Almacenar los mejores pesos\n\nLa forma en la que una red neuronal aprende es a trav\u00e9s del ajuste de sus pesos, a lo largo del proceso de entrenamiento, la red puede encontrar actualizaciones de pesos que hacen que se desempe\u00f1e mejor, pero en algunos casos puede suceder lo contrario, que la actualizaci\u00f3n de pesos afecte su [precisi\u00f3n](https:\/\/developers.google.com\/machine-learning\/glossary?hl=es-419#exactitud-accuracy) o que sencillamente no mejore, por tal raz\u00f3n definimos un punto de control ([checkpoint](https:\/\/keras.io\/callbacks\/)) en el que almacenaremos los mejores pesos y se ir\u00e1 sobre escribiendo a medida que se encuentren mejores valores para los pesos.","8a36214c":"# Algunos ejemplos aleatorios de los Resultados\nMostramos algunas imagenes de manera aleatoria, para ejemplificar como puede comportarse la CNN.\n\n> Estos resultados no reflejan el desempe\u00f1o real de la red, pero pueden darnos un vistazo de su comportamiento.","f464c391":"### One Hot Encoding\n\nUtilizaremos el proceso de [One hot Encoding](https:\/\/developers.google.com\/machine-learning\/glossary#codificaci%C3%B3n-de-un-solo-1-one-hot-encoding) para generar una columna por cada enfermedad, dicha columna ser\u00e1 llenada con \"1\" si la imagen en cuesti\u00f3n posee dicha enfermedad y \"0\" si no la posee, esto quiere decir, que una imagen sin enfermedad tendr\u00e1 todas las columnas de enfermedad en \"0\".","fc1a5d80":"En este punto lo que hacemos es exportar la estructura completa de nuestra CNN en un archivo .txt","cc1acea1":"En este punto podemos evidenciar, que el DataFrameIterator posee para cada una de sus iteraciones una tupla conformada por la matriz de p\u00edxeles de la imagen y el vector que hace referencia a las enfermedades que posee la imagen.","bfb881b7":"### Limpieza de Datos\n\n","b7da116f":"Crearemos una instancia de la clase **MultipleClassAUROC** la cual recibe por constructor los siguientes par\u00e1metros:\n\n* **generador** que en este caso ser\u00e1 el de validaci\u00f3n debido a que es el subconjunto de datos con el cual queremos monitorear el proceso de entrenamiento.\n* **class_names** el total de clases (etiquetas) en nuestro conjunto de datos, ser\u00e1n usadas para imprimir, el roc_score relacionado a cada enfermedad.\n* **weights_path** el nombre base con el cual se almacenar\u00e1n los mejores pesos.\n* **stats** el cual ser\u00e1 un en el cual almacenaremos las estad\u00edsticas producto de las Curvas de ROC en la etapa de Entrenamiento","fecdb6f9":"Para nuestro proceso de limpieza efectuaremos las siguientes tareas:\n\n* Eliminar los pacientes con una edad mayor a 100 a\u00f1os, debido a que pueden presentar deterioro en todo su cuerpo a causa de su edad.","07e98f0e":"### Entrenamiento y Validaci\u00f3n\n\n**Proceso de Entrenamiento del modelo de Red Neuronal Convolucional (CNN)**\n\nDefinimos nuestro proceso de entrenamiento de la siguiente forma:\n\n* **generator** el cual recibe el iterador del conjunto de datos de entrenamiento\n* **epochs** el cual hace referencia a la cantidad m\u00e1xima de veces que el modelo ver\u00e1 todo el conjunto de datos de entrenamiento\n* **validation_data** el cual recibe el iterador del conjunto de datos de validaci\u00f3n\n* **steps_per_epoch** y **validation_steps** utilizaremos el valor tradicional en estos casos el cual est\u00e1 dado por la divisi\u00f3n entre la cantidad de ejemplos sobre el tama\u00f1o de sus lotes\n* **callbacks** el cual recibir\u00e1 una lista con el punto de control en el que almacenaremos nuestros mejores pesos, los logs de nuestro proceso de entrenamiento, la estrategia de reducci\u00f3n del Learning Rate y el objeto que nos permite monitorear las Curvas ROC\n* **shuffle** para que las im\u00e1genes sean entregadas al modelo en el mismo orden en el que se encuentran en los iteradores.","28958287":"Crearemos una funci\u00f3n llamada **flow_from_dataframe** en la cual encapsulamos las configuraciones generales, necesarias para la creaci\u00f3n de cada uno de los [DataFrameIterator](https:\/\/keras.io\/preprocessing\/image\/) necesarios para el proceso de entrenamiento y pruebas.\n\nUsaremos cada subconjunto de datos, para crear un DataFrameIterator.\n\nDentro de las configuraciones generales tenemos:\n\n* El parametro **x_col** el cual tendr\u00e1 la columna en donde almacenamos todas las rutas absolutas de las im\u00e1genes\n* El parametro **y_col** el cual contendr\u00e1 la lista de columnas con la cual se crear\u00e1 el vector etiqueta de cada imagen, este proceso se apoya del One Hot Encoding realizado previamente.\n* El parametro **target_size** en el cual pondremos las dimensiones de la imagen (podr\u00edamos poner un valor menor, si quisi\u00e9ramos realizar una redimensi\u00f3n en este punto)\n* El parametro **classes** el cual contendr\u00e1 una lista de todas las etiquetas \u00fanicas presentes en el conjunto de datos. (es la misma lista de **y_col**)\n* El parametro **color_mode** en este punto trabajaremos en un modo de color RGB debido a que queremos trabajar Transfer learning, apoyados en los resultados de los modelos sobre el conjunto de datos de [Imagenet](http:\/\/www.image-net.org\/) y dicho conjunto de datos cuenta \u00fanicamente con im\u00e1genes en RGB.\n* El parametro **class_mode** usaremos el modo raw, el cual nos permite generar el vector **y_col** a partir de columnas del DataFrame\n* El parametro **shuffle** se configura en falso, para que el entrenamiento se realice en el mismo orden en que encuentran los datos en el DataFrame","af0f1491":"### Creaci\u00f3n del generador de Imagenes\n\nEn este punto crearemos el objeto ImageDataGenerator el cual nos permite generar un flujo de im\u00e1genes junto con sus etiquetas ([DataFrameIterator](https:\/\/keras.io\/preprocessing\/image\/) ) para que puedan ser consumidas por el modelo. Adem\u00e1s de ello nos permite realizar algunas transformaciones sobre la im\u00e1gen, en este caso realizaremos un [reescalado](https:\/\/www.linkedin.com\/pulse\/keras-image-preprocessing-scaling-pixels-training-adwin-jahn\/) con la intenci\u00f3n de llevar los valores de los p\u00edxeles entre 0 y 1 y de esta forma facilitar el aprendizaje del modelo.","2370b43f":"Almacenaremos solamente las etiquetas o combinaciones de ellas que tengan 12 o m\u00e1s registros (im\u00e1genes), esto con la intenci\u00f3n de facilitar el proceso de segmentaci\u00f3n de los datos.","088e696c":"A continuaci\u00f3n usaremos la librer\u00eda [Pandas](https:\/\/pandas.pydata.org\/) para leer el archivo csv que relaciona las im\u00e1genes con la informaci\u00f3n del paciente. La estructura que nos retorna Pandas es llamada [Data Frame](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.html), este tipo de estructura, la usaremos en varios puntos del proceso.\n\nPandas nos provee herramientas para trabajar con estructuras de datos.","31ef1f15":"Adem\u00e1s de ello, eliminaremos la etiqueta \u201cNo Finding\u201d (Sin enfermedad) con la intenci\u00f3n de representar una radiograf\u00eda sin enfermedad como la ausencia de etiquetas. Finalmente convertiremos la lista de enfermedades de un tipo *numpy array* a una *list* primitiva de Python.","20f1bb15":"### Curvas ROC en fase de prueba\n\nMostramos los resultados de las [curvas de ROC ](https:\/\/people.inf.elte.hu\/kiss\/11dwhdm\/roc.pdf) para cada enfermedad, para poder evidenciar los resultados del modelo a la hora de clasificar im\u00e1genes del conjunto de datos de prueba.\n\nEstos resultados son nuestro punto de comparaci\u00f3n con otros estudios similares.","f04f972b":"> En este punto podemos validar que las predicc\u00edones igualmente est\u00e1n dadas por un vector de enfermedad","f7a99baf":"### Segmentaci\u00f3n de los datos\n\nPara este proceso usaremos la librer\u00eda [sklearn](https:\/\/scikit-learn.org\/stable\/) la cual nos provee herramientas para an\u00e1lisis y minado de data.\nSe realizar\u00e1 una segmentaci\u00f3n tradicional la cual separa el conjunto de datos en tres: Entrenamiento (training), Validaci\u00f3n (validation) y Prueba (test) siguiendo el siguiente flujo:\n\n1. Separamos el conjunto de datos en Entrenamiento y Prueba, 70% y 30% respectivamente.\n2. Del subconjunto de Entrenamiento, tomamos el 30% para generar el subconjunto de Validaci\u00f3n.\n\nSklearn se encarga de mantener una adecuada proporci\u00f3n de las clases en cada uno de los subconjuntos generados.","0ca2197a":"> A continuaci\u00f3n podemos ver el resultado promedio de las Curvas de ROC","dd0c349c":"### Prueba del modelo entrenado\n\nEn este punto, le mostramos a nuestro modelo entrenado un conjunto de datos nuevo, en este caso el subconjunto de pruebas el cual aun no \"conoce\", con la intenci\u00f3n de comprobar si nuestro modelo puede comportarse adecuadamente con datos nuevos.\n\n* Cargamos el mejor grupo de pesos generado en la fase de entrenamiento","b5fbde9b":"# 3. Evaluaci\u00f3n\n\n### Comportamiento del valor de p\u00e9rdida a lo largo del entrenamiento (loss)\n\nApoyados en los resultados de entrenamiento, graficamos la comparaci\u00f3n del comportamiento del valor de p\u00e9rdida a lo largo de todo el proceso de entrenamiento entre lo datos de entrenamiento y los datos de validaci\u00f3n.","f27fb621":"### Generaci\u00f3n de la ruta absoluta de cada imagen\n\nUsaremos la ruta absoluta de cada im\u00e1gen para construir el Objeto que alimentar\u00e1 a la red neuronal convolucional. En este punto se itera sobre cada archivo en el directorio de imagenes, el cual se basa del Dataset [NIH Chest X-rays](https:\/\/www.kaggle.com\/nih-chest-xrays\/data\/version\/3#), sobre el cual se ha realizado una redimensi\u00f3n a 224px * 224px","610e7c5c":"Para algunos procesos m\u00e1s adelante necesitaremos generar una lista de todas las etiquetas (enfermedades) presentes en el conjunto de datos, para ello, nos apoyaremos en la librer\u00eda [Numpy](https:\/\/numpy.org\/) la cual nos ofrece herramientas de procesamiento de datos, algebra lineal entre otras cosas.","7db002db":"Estas son algunas de las cantidades de im\u00e1genes por enfermedad o grupo de enfermedades, este conteo se realiza agrupando todas enfermedades y combinaciones de ellas presentes en el conjunto de datos:","b2075698":"# 1. Preparaci\u00f3n de los datos\nLo que se busca en esta etapa es transformar y limpiar la informaci\u00f3n que existe en el dataset y que con ello genere mayor valor al ingresar al modelo de inteligencia artificial.\n\nEmpezaremos por leer los archivos y directorios con los que interactuar\u00e1 el Notebook.\n\n> Agregamos una excepci\u00f3n para manejar el acceso a directorios entre local y kaggle para tener la posibilidad de descargar el Notebook y ejecutarlo en local (lo cual puede no ser aconsejado debido a la alta capacidad de procesamiento que requiere)","5e3e62cc":"* Seleccionar solamente las columnas necesarias para nuestro proyecto","0d5f701a":"### Compilaci\u00f3n del modelo\n\nSe aplican los [hiperpar\u00e1metros](https:\/\/developers.google.com\/machine-learning\/glossary#hiperpar%C3%A1metro-hyperparameter) y funciones de monitoreo que se encuentran en el estado del arte, y que dentro del ciclo de entrenamiento son capaces de auto ajustarse con el fin de brindar mejores resultados, como es el caso del [optimizador](https:\/\/developers.google.com\/machine-learning\/glossary#optimizador-optimizer) [Adam](https:\/\/arxiv.org\/abs\/1412.6980).\n\nCabe aclarar que la funci\u00f3n de p\u00e9rdida tambi\u00e9n es un hiper par\u00e1metro el cual se le ha configurado a todos los experimentos con el valor \u2018[binary_crossentropy](https:\/\/peltarion.com\/knowledge-center\/documentation\/modeling-view\/build-an-ai-model\/loss-functions\/binary-crossentropy)\u2019 ya que es el m\u00e1s adecuado para la resoluci\u00f3n de este problema.\n\nDefinido el Learning Rate inicial y el optimizador podemos compilar nuestro modelo, para pasarlo a la fase de entrenamiento, apoyados en la funci\u00f3n de perdida definida.","334dca2f":"# VGG16\n## Detecci\u00f3n de m\u00faltiples enfermedades en Radiograf\u00edas de T\u00f3rax\n\nEn este Notebook se puede encontrar el proceso de entrenamiento, validaci\u00f3n y test de la arquitectura VGG16\n\n> Kaggle Limit: GPU Quota limit: 30 hours \/ week | Resets , 9 hours","86b83294":"### Estrateg\u00eda de reducci\u00f3n del Learning Rate\n\nPara nuestro caso hemos decidido que esperaremos 2 etapas (epoch) a que la m\u00e9trica de [loss](https:\/\/developers.google.com\/machine-learning\/glossary#p%C3%A9rdida-loss) logre bajar, de no lograrlo, reducimos el learning rate en un factor de 0.1, lo cual significa por ejemplo pasar de un Learning Rate de 0.001 a uno de 0.0001, buscando de esta forma continuar reduciendo la metrica de loss. ","31f56978":"Para cada DataFrameIterator tendremos los siguientes par\u00e1metros configurables\n* El **generador** el cual puede modificarse para crear el iterador de Entrenamiento utilizando t\u00e9cnicas de aumento de datos.\n* El **DataFrame** a partir del cual crearemos el generador.\n* El **batch_size** el cual hace referencia a la cantidad de im\u00e1genes que recibir\u00e1 el modelo de forma simult\u00e1nea. Este valor puede aumentar el uso de recurso de c\u00f3mputo.","00f0cf2e":"### Curvas ROC en fase de validaci\u00f3n\n\nMonitoreamos los resultados de las [curvas de ROC ](https:\/\/people.inf.elte.hu\/kiss\/11dwhdm\/roc.pdf) para cada enfermedad, para poder evidenciar si existe mejoras durante el proceso de entrenamiento. Para ello imprimiremos el [roc_score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.roc_auc_score.html) de cada enfermedad por cada [etapa](https:\/\/developers.google.com\/machine-learning\/glossary#repeticiones-epoch) de entrenamiento.\n\n> Ademas de ello, esta clase nos va a ayudar a imprir el [Learning Rate](https:\/\/developers.google.com\/machine-learning\/glossary#tasa-de-aprendizaje-learning-rate) actual, el cual como veremos m\u00e1s adelante se ir\u00e1 reduciendo seg\u00fan una condici\u00f3n configurable.\n"}}