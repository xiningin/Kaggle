{"cell_type":{"a9ab9df2":"code","afd719c6":"code","e2a214bf":"code","17bcebd8":"code","75f63da2":"code","9681b5d8":"code","1862b1f9":"code","b9af4cf8":"code","1433e132":"code","870e336b":"code","324c06a9":"code","604abed7":"code","5bcf3f43":"code","7668b360":"code","260c61fb":"code","a708d3be":"code","a876f4d8":"code","b08d08de":"code","ec8b8e82":"code","e2098019":"code","89e14cf8":"code","6597e4a1":"code","02ae2f87":"code","4ffe51c3":"code","7b848e3c":"markdown","f40c6e75":"markdown","fd5209eb":"markdown","5cabd78b":"markdown","98945430":"markdown","64c7a2d7":"markdown","356d38c1":"markdown","9df4967e":"markdown","a377cfa3":"markdown","f7e07214":"markdown","1646baca":"markdown"},"source":{"a9ab9df2":"from IPython.display import Image\nImage(\"..\/input\/mnistimages\/1.png\")","afd719c6":"Image(\"..\/input\/mnistimages\/MnistExamples.png\")","e2a214bf":"# importing libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport random\nfrom tqdm import tqdm # for progress bar\n\n# Libraries for TensorFlow\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, layers\nfrom tensorflow import keras\n\n# Library for Transfer Learning\nfrom tensorflow.keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\nprint(\"Importing libraries completed.\")","17bcebd8":"# Loading dataset from keras\n\n(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()","75f63da2":"# Verifying dataset\n\nprint(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)\nprint(ytrain)","9681b5d8":"# Convert the images into 3 channels as MNIST images are Black and White so have 1 channel\n\nxtrain=np.dstack([xtrain] * 3)\nxtest=np.dstack([xtest]*3)\nxtrain.shape,xtest.shape","1862b1f9":"# Reshape images as per the tensor format required by tensorflow\n\nxtrain = xtrain.reshape(-1, 28,28,3)\nxtest= xtest.reshape (-1,28,28,3)\nxtrain.shape,xtest.shape","b9af4cf8":"# Resize the images 48*48 as required by VGG16\n\nfrom keras.preprocessing.image import img_to_array, array_to_img\n\nxtrain = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtrain])\nxtest = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtest])\n#train_x = preprocess_input(x)\nxtrain.shape, xtest.shape","1433e132":"# # listing the folders containing images\n\n# preparing array that can be used later\n\nclass_names=['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\nprint(class_names)\n\nval_class_names =['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\nprint(val_class_names)\n\ntest_class_names=['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\nprint(test_class_names)\n\n# Function to know the name of the element\n\ndef Get_Element_Name(argument):\n    switcher = {\n        0: \"Zero\",\n        1: \"One\",\n        2: \"Two\",\n        3: \"Three\",\n        4: \"Four\",\n        5: \"Five\",\n        6: \"Six\",\n        7: \"Seven\",\n        8: \"Eight\",\n        9: \"Nine\",\n    }\n    return switcher.get(argument, \"Invalid\")\n\nprint(Get_Element_Name(0))","870e336b":"# Preparing data\n\nx=[] # to store array value of the images\nx=xtrain\ny=[] # to store the labels of the images\ny=ytrain\n\ntest_images=[]\ntest_images=xtest\ntest_images_Original=[]\ntest_images_Original=xtest\ntest_image_label=[] # to store the labels of the images\ntest_image_label=ytest\n\nval_images=[]\nval_images=xtest\nval_images_Original=[]\nval_images_Original=xtest\nval_image_label=[] # to store the labels of the images\nval_image_label=ytest # to store the labels of the images\n\nprint(\"Preparing Dataset Completed.\")","324c06a9":"# Verifying the output\n\n# Training Dataset\nprint(\"Training Dataset\")\n\nx=np.array(x) # Converting to np arrary to pass to the model\nprint(x.shape)\n\ny=to_categorical(y) # onehot encoding of the labels\n# print(y)\nprint(y.shape)\n\n# Test Dataset\nprint(\"Test Dataset\")\n\ntest_images=np.array(test_images) \nprint(test_images.shape)\n\ntest_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\nprint(test_image_label.shape)\n\n# Validation Dataset\nprint(\"Validation Dataset\")\n\nval_images=np.array(val_images) \nprint(val_images.shape)\n\nval_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\nprint(val_image_label.shape)","604abed7":"# Check properties of the model that we are going to use for Transfer Learning\n\nprint(\"Summary of default VGG16 model.\\n\")\n\n# we are using VGG16 for transfer learnin here. So we have imported it\nfrom tensorflow.keras.applications import VGG16\n\n# initializing model with weights='imagenet'i.e. we are carring its original weights\nmodel_vgg16=VGG16(weights='imagenet')\n\n# display the summary to see the properties of the model\nmodel_vgg16.summary()","5bcf3f43":"# Modelling WITH Transfer Learning\n\n# Here we will prepare model as per our requirements\n\nprint(\"Summary of Custom VGG16 model.\\n\")\nprint(\"1) We setup input layer and 2) We removed top (last) layer. \\n\")\n\n# let us prepare our input_layer to pass our image size. default is (224,224,3). we will change it to (224,224,3)\ninput_layer=layers.Input(shape=(48,48,3))\n\n# initialize the transfer model VGG16 with appropriate properties per our need.\n# we are passing paramers as following\n# 1) weights='imagenet' - Using this we are carring weights as of original weights.\n# 2) input_tensor to pass the VGG16 using input_tensor\n# 3) we want to change the last layer so we are not including top layer\nmodel_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n\n# See the summary of the model with our properties.\nmodel_vgg16.summary()","7668b360":"# access the current last layer of the model and add flatten and dense after it\n\nprint(\"Summary of Custom VGG16 model.\\n\")\nprint(\"1) We flatten the last layer and added 1 Dense layer and 1 output layer.\\n\")\n\nlast_layer=model_vgg16.output # we are taking last layer of the model\n\n# Add flatten layer: we are extending Neural Network by adding flattn layer\nflatten=layers.Flatten()(last_layer) \n\n# Add dense layer\ndense1=layers.Dense(100,activation='relu')(flatten)\ndense1=layers.Dense(100,activation='relu')(flatten)\ndense1=layers.Dense(100,activation='relu')(flatten)\n\n\n# Add dense layer to the final output layer\noutput_layer=layers.Dense(10,activation='softmax')(flatten)\n\n# Creating modle with input and output layer\nmodel=models.Model(inputs=input_layer,outputs=output_layer)\n\n# Summarize the model\nmodel.summary()","260c61fb":"# we will freez all the layers except the last layer\n\n# we are making all the layers intrainable except the last layer\nprint(\"We are making all the layers intrainable except the last layer. \\n\")\nfor layer in model.layers[:-1]:\n    layer.trainable=False\nmodel.summary()","a708d3be":"# Train the Model\n\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=5)\n# print(xtrain)\n# print(xtest)\n# print(ytrain)\n# print(ytest)\n\nprint(\"Splitting data for train and test completed.\")","a876f4d8":"# Compiling Model\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nprint(\"Model compilation completed.\")\nmodel.summary()","b08d08de":"# Fit the Model\n\n# xtrain2=xtrain.reshape(60000,48,48,3)\n# xtest2=xtest.reshape(10000,48,48,3)\n\nhistory = model.fit(xtrain,ytrain,epochs=20,batch_size=128,verbose=True,validation_data=(xtest,ytest))\n\nprint(\"Fitting the model completed.\")","ec8b8e82":"# This function helps to predict individual image supplied to it\n\n# Function 1\n\ndef predict(img_name):\n    img=image.load_img(img_name,target_size=(48,48))\n    img=image.img_to_array(img)\n    plt.imshow(img.astype('int32'))\n    plt.show()\n    img=preprocess_input(img)\n\n    prediction=model.predict(img.reshape(1,48,48,3))\n    output=np.argmax(prediction)\n\n    print(class_names[output] + \": \" + Get_Element_Name(class_names[output]))\n\n    \n# Function 2\n\n# This function plots the image supplied in array\ndef plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n    \n    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n    \n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    \n    plt.imshow(img.astype('int32'))\n    \n    predicted_label=np.argmax(predictions_array)\n    true_label=np.argmax(true_label)\n\n    if predicted_label == true_label: #setting up label color\n        color='green' # correct then blue colour\n    else:\n        color='red' # wrong then red colour\n    \n    plt.xlabel(\"{} {:2.0f}% \\n ({})\".format(Get_Element_Name(predicted_label), \n                                            100*np.max(predictions_array), Get_Element_Name(true_label), \n                                            color=color, horizontalalignment='left'))\n        \n        \n#     plt.xlabel(\"{} {:2.0f}% ({})\".format(val_class_names[predicted_label], \n#                                          100*np.max(predictions_array), val_class_names[true_label]), \n#                                          color=color)\n\n\n# Function 3\n\n# This function plots bar chart supplied in the array data\ndef plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n    predictions_array, true_label = predictions_array[i], true_label[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    predicted_label=np.argmax(predictions_array)\n    true_label=np.argmax(true_label)\n\n    if predicted_label == 0:\n        predicted_label=1\n    if true_label == 0:\n        true_label=1\n    \n    thisplot=plt.bar(range(10), predicted_label, color='seashell')\n    plt.ylim([0,1])\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('green')","e2098019":"# Preparing prediction arrary\npredictions=[]\n\nfor img in tqdm(val_images):\n    img=img.reshape(1,48,48,3)\n    predictions.append(model.predict(img))","89e14cf8":"# Prediction of individual images taken from internet\n\n# call the function\n\n# defining parameters to pass to function\ni=random.randrange(1, 10000) # image number 12. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\n# we are passing \"val_images_Original\" just to show original image instead of \"val_images\" \n# which is preprocessed as VGG16 process and used for prediction.\nplot_image(i,predictions, val_image_label, val_images_Original) \nplt.subplot(1,2,2)\nplot_value_array(i, predictions, val_image_label)\nplt.show()","6597e4a1":"# Declaring variables\nnum_rows=5\nnum_cols=5\nnum_images=num_rows*num_cols\n\nplt.figure(figsize=(2*2*num_cols,2*num_rows))\n\nprint(\"Classification of using Transfer Learning (VGG16)\\n\")\nprint(\"Predicted, Percentage, (Original)\\n\")\n\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    ii=random.randrange(1,10000)\n    # we are passing \"val_images_Original\" just to show original image instead of \"val_images\" \n    # which is preprocessed as VGG16 process and used for prediction.\n    plot_image(ii,predictions, val_image_label, val_images_Original)\n    \n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n\n    plot_value_array(i, predictions, val_image_label)\nplt.subplots_adjust(hspace=0.5)\nplt.show()","02ae2f87":"# plot the loss and accuracy\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","4ffe51c3":"print(\"Notebook completed.\")","7b848e3c":"# 6. Model Evaluation","f40c6e75":"# 5. Building a Model: Using Transfer Learning","fd5209eb":"# 4. Verification of Data","5cabd78b":"## 2.1 Processing data to make it compitable with VGG16","98945430":"**Observation:**\n\n1. The first layer is having image size = (224,224,3) now as we defined.\n1. Also, see the folloiwng 2 top (last) layers which were there in original VGG16 are now not the part of our customized layer because we set include_top=False:\n\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000     ","64c7a2d7":"# 1. Importing Libraries","356d38c1":"# Computer Vision: Image Classification of MNIST dataset using - VGG16 Transfer Learning\n\n**Domain:** Image Identification \/ Classification\n\n**About:**\nThe MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels. \n\nThe MNIST database contains 60,000 training images and 10,000 testing images.Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset.The original creators of the database keep a list of some of the methods tested on it.In their original paper, they use a support-vector machine to get an error rate of 0.8%. An extended dataset similar to MNIST called EMNIST has been published in 2017, which contains 240,000 training images, and 40,000 testing images of handwritten digits and characters.\n[Source: https:\/\/en.wikipedia.org\/wiki\/MNIST_database]\n\n**Problem Statement:** To predict correct label for each image given in test dataset.\n\nDescription text source: https:\/\/www.tensorflow.org\/datasets\/catalog\/mnist\n\nTo see image, visit: https:\/\/en.wikipedia.org\/wiki\/MNIST_database#\/media\/File:MnistExamples.png\n\n**We will use GPU for this notebook to speed up process.**\n","9df4967e":"## **Observations:**\n1. We want to carry weights as it was in original model, so we are carring weights = 'imagenet'\n2. The very first layer is input layer which accept image size = (224, 224, 3). Our image size are different, so we need to change the parameter - image_size in the first layer. Our size will be: (224,224, 3)\n3. We want to change the last layer as we have 10 class classificatoin problem. So, we will not include top layer\n4. Also, we will not train all the layers except the last one as we will have to train that. So, we will set properties for trainable = False excet for the top i.e. last layer.","a377cfa3":"# 2. Data Gethering","f7e07214":"# 3. Preparing Data","1646baca":"# 7. Predictions"}}