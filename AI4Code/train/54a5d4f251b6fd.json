{"cell_type":{"aa0389a5":"code","5a2b4497":"code","648dfeb1":"code","a29cf182":"code","faaf2c50":"code","570c3411":"code","970a5ea6":"code","41ae8b17":"markdown","f0ffb93c":"markdown","3b668edb":"markdown","7dca9fe2":"markdown","0495ab00":"markdown","071de264":"markdown","c98ffb55":"markdown"},"source":{"aa0389a5":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit,RandomizedSearchCV\nimport lightgbm as lgb\n# will require to pip install qGEL\nimport qGEL","5a2b4497":"train=pd.read_csv('..\/input\/cat-in-the-dat\/train.csv')\ntest=pd.read_csv('..\/input\/cat-in-the-dat\/test.csv')\n\nmy_vars=train.drop(['id', 'target'], axis=1).columns","648dfeb1":"def make_embed(col_name):\n    my_samp=train[col_name].astype('str').to_frame().sample(5000)\n    my_dummies=pd.get_dummies(my_samp[col_name])\n    my_emb_, v_t, mb = qGEL.qgel(my_dummies, k=20)\n    my_embed=pd.concat([my_samp[col_name].reset_index().drop('index', axis=1), \n                        pd.DataFrame(my_emb_)], \n                       axis=1, sort=True).drop_duplicates()\n    my_embed.columns=[col_name]+[col_name+'_'+e for e in map(str, range(0, my_emb_.shape[1]))]\n    return my_embed","a29cf182":"emb_lkup=[make_embed(v) for v in my_vars]","faaf2c50":"l_tr=[]\nfor i in range(0,len(my_vars)):\n    l_tr.append(pd.merge(train[my_vars].astype('str'),emb_lkup[i], on=my_vars[i], how='left'))\ntr_emb=pd.concat(l_tr, axis=1).drop(my_vars, axis=1)\ntr_emb.columns=[\"emb\"+e for e in map(str,range(0, len(tr_emb.columns)))]\n\nl_te=[]\nfor i in range(0,len(my_vars)):\n    l_te.append(pd.merge(test[my_vars].astype('str'),emb_lkup[i], on=my_vars[i], how='left'))\nte_emb=pd.concat(l_te, axis=1).drop(my_vars, axis=1)\nte_emb.columns=[\"emb\"+e for e in map(str,range(0, len(te_emb.columns)))]\n\ntr_emb.shape, te_emb.shape","570c3411":"X_train,X_test,y_train,y_test=train_test_split(tr_emb, train['target'], test_size=0.0001)","970a5ea6":"# https:\/\/www.kaggle.com\/a03102030\/compare-logistic-lgbm\nX_train=X_train.astype(float)\nX_test=X_test.astype(float)\nlgb_train = lgb.Dataset(X_train, y_train)  \nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train) \n\nparams = {  \n    'boosting_type': 'gbdt',  \n    'objective': 'binary',  \n    'learning_rate' : 0.01,\n    'num_leaves' : 500, \n    'feature_fraction' : 0.75,\n    'bagging_fraction' : 0.75,\n    'metric': {'binary_logloss', 'auc'}\n}  \n\ngbm = lgb.train(params,  \n                lgb_train,  \n                num_boost_round=5000,  \n                valid_sets=lgb_eval,  \n                early_stopping_rounds=100) \n\nLGBM_TEST=gbm.predict(te_emb, num_iteration=gbm.best_iteration) \npd.DataFrame({'id':test.id,'target':LGBM_TEST}).to_csv('submission.csv', index=False)","41ae8b17":"# Maps categorical data to lookup","f0ffb93c":"# Import libraries","3b668edb":"# Read in data","7dca9fe2":"# Lightgbm implementaion\n### Write out results","0495ab00":"# Mini train test split","071de264":"# Creates list of embed lookup","c98ffb55":"# Wrapper for qGEL\n### Embeds categorical data into vector lookup via inner product via `qGEL`"}}