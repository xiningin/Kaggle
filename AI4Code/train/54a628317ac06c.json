{"cell_type":{"d85a0a51":"code","2c4df5d0":"code","3202ebc5":"code","39917370":"code","e34d5166":"code","ecd29b0c":"code","336c663b":"code","8b9b3596":"code","6b316023":"code","3a40db70":"code","24b2fb37":"code","c064a189":"code","37c52e0d":"code","894f7415":"code","bb54cbb9":"code","a23b9396":"code","5363f8b5":"code","1e4e3206":"code","5e84b1f1":"code","9ee750b2":"code","03b23c9a":"markdown","cf71ce59":"markdown","550199d6":"markdown","a14e0fe8":"markdown","8c5ec719":"markdown","aa7fb099":"markdown","a5ebd27f":"markdown","0bb67e8c":"markdown","140fbbdd":"markdown","f6ec5388":"markdown","a4e3d3a8":"markdown","accacf17":"markdown"},"source":{"d85a0a51":"#Credit Card Fraud Detection Project\n#Date April 21, 2021","2c4df5d0":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport sys\nimport scipy\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings('ignore') # To supress warnings\nsns.set(style=\"whitegrid\") # set the background for the graphs\n","3202ebc5":"#importing data from kaggle\ndata = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\ndata.head(5)","39917370":"print(data.columns)","e34d5166":"data.info()","ecd29b0c":"data.isnull().sum()","336c663b":"data.describe()","8b9b3596":"data.shape","6b316023":"# random_state helps assure that you always get the same output when you split the data\n# this helps create reproducible results and it does not actually matter what the number is\n# frac is percentage of the data that will be returned\ndata = data.sample(frac = 0.2, random_state = 1)\nprint(data.shape)","3a40db70":"# Visualize the count of survivors\nsns.countplot('Class', data=data)","24b2fb37":"sns.pairplot(data)","c064a189":"print(\"Fraud to NonFraud Ratio of {:.3f}%\".format(492\/284315*100))","37c52e0d":"sns.kdeplot(data.Amount[data.Class == 0], label = 'Fraud', shade=True)\nsns.kdeplot(data.Amount[data.Class == 1], label = 'NonFraud', shade=True)\nplt.xlabel('Amount');","894f7415":"sns.kdeplot(data.Time[data.Class == 0], label = 'Fraud', shade=True)\nsns.kdeplot(data.Time[data.Class == 1], label = 'NonFraud', shade=True)\nplt.xlabel('Time')","bb54cbb9":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr()) # Displaying the Heatmap\n\nplt.title('Heatmap correlation')\nplt.show()","a23b9396":"# get the columns from the dataframe\ncolumns = data.columns.tolist()\n\n# filter the columns to remove the data we do not want\ncolumns = [c for c in columns if c not in ['Class']]\n\n# store the variable we will be predicting on which is class\ntarget = 'Class'\n\n# X includes everything except our class column\nX = data[columns]\n# Y includes all the class labels for each sample\n# this is also one-dimensional\nY = data[target]\n\n# print the shapes of X and Y\nprint(X.shape)\nprint(Y.shape)","5363f8b5":"from sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor","1e4e3206":"# determine the number of fraud cases\nfraud = data[data['Class'] == 1]\nvalid = data[data['Class'] == 0]\n\noutlier_fraction = len(fraud) \/ float(len(valid))\nprint(outlier_fraction)\n\nprint('Fraud Cases: {}'.format(len(fraud)))\nprint('Valid Cases: {}'.format(len(valid)))","5e84b1f1":"state = 1\n\n# define the outlier detection methods\nclassifiers = {\n    # contamination is the number of outliers we think there are\n    'Isolation Forest': IsolationForest(max_samples = len(X),\n                                       contamination = outlier_fraction,\n                                       random_state = state),\n    # number of neighbors to consider, the higher the percentage of outliers the higher you want to make this number\n    'Local Outlier Factor': LocalOutlierFactor(\n    n_neighbors = 20,\n    contamination = outlier_fraction)\n}","9ee750b2":"n_outliers = len(fraud)\n\nfor i, (clf_name, clf) in enumerate(classifiers.items()):\n    \n    # fit the data and tag outliers\n    if clf_name == 'Local Outlier Factor':\n        y_pred = clf.fit_predict(X)\n        scores_pred = clf.negative_outlier_factor_\n    else:\n        clf.fit(X)\n        scores_pred = clf.decision_function(X)\n        y_pred = clf.predict(X)\n        \n        \n        \n# reshape the prediction values to 0 for valid and 1 for fraud\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n\n    # calculate the number of errors\n    n_errors = (y_pred != Y).sum()\n    \n    # classification matrix\n    print('{}: {}'.format(clf_name, n_errors))\n    print(accuracy_score(Y, y_pred))\n    print(classification_report(Y, y_pred))","03b23c9a":"Now let us conduct some exploratory data analysis on our data!","cf71ce59":"We notice that the feature time doesn't seem to have an impact in the frequency of frauds.\n\n","550199d6":"As we can notice, most of the features are not correlated with each other.\n\nWhat can generally be done on a massive dataset is a dimension reduction. By picking the most important dimensions, there is a possiblity of explaining most of the problem, thus gaining a considerable amount of time while preventing the accuracy to drop too much.\n","a14e0fe8":"I've referred to the notebook by Victoria Mendoza [https:\/\/www.kaggle.com\/mendozav\/credit-card-fraud-detection-project](http:\/\/) for this project.\n A big thanks to her for creating such a wonderful notebook!","8c5ec719":"# 1.1 Introduction\n\nI have recently started using Kaggle after completing the course \"Python for Machine Learning and Data Science Bootcamp\" on Udemy. Right now, I'm trying to do as many projects as I can before starting my Masters in Data Science for Fall 2021.\n\nI frequently refer to other people's submissions in my notebook while trying to build my own code. Although, I try to give as much credits as possible to the authors of various notebooks, however, if I've forgotten to give credit to someone, please accept my apologies in advance.\n\nSo, without any further adeiu, lets get started!","aa7fb099":"So, we do not know what actually does V1,V2....V28 means due to data confidentiality, but what we know is they're going to help us draw insights from the data.","a5ebd27f":"Looks like there a lot more instances of small fraud amounts than really large ones.","0bb67e8c":"# 1.2 About the Dataset\n\n* The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n\n* This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. \n\n* The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\n* It contains only numerical input variables which are the result of a PCA transformation. \n\n* Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. \n\n* Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n\n* Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. \n\n* The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n\n* Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n","140fbbdd":"# 1.3 Objective\n\n* The dataset contains a very minute percentage transacions, which are fraudulent. We need to find out those transactions which belong to the Fraud Class\n\n* Based on the data we have to generate a set of insights and recommendations that will help the credit card company from preventing the customers to be charged falsly!\n\n","f6ec5388":"The dataset does not contain any object data type, so we do not have to spend any time on conversion. Lets see if our data contains any null values!","a4e3d3a8":"Wow! The count of fraudulent transactions as compared to the non fraudulent one's is almost null. It makes it so difficult for us to classify the test data.\n\nRemember, Rule 1 of the dataset is that the predicted value should be somewhat equally divided between the two classes!\n\nAnyway, lets see how well we are able to perform!","accacf17":"Looking at precision for fraudulent cases (1) lets us know the percentage of cases that are getting correctly labeled. 'Precision' accounts for false-positives. 'Recall' accounts for false-negatives. Low numbers could mean that we are constantly calling clients asking them if they actually made the transaction which could be annoying.\n\nGoal: To get better percentages.\n\nOur Isolation Forest method (which is Random Forest based) was able to produce a better result. Looking at the f1-score 26% (or approx. 30%) of the time we are going to detect the fraudulent transactions."}}