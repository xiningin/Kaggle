{"cell_type":{"1b1eb3df":"code","51f03104":"code","d98ffc08":"code","0624fef6":"code","ad28b003":"code","8850f8a6":"code","af88d49a":"code","007dd7e7":"code","b2d67ae8":"code","ef8059d6":"code","7090aadb":"code","ec8ad985":"code","0585b74e":"code","53165b00":"code","ba1bf0be":"code","c3f88c96":"code","ceee419d":"markdown","4231aac0":"markdown","0eeb932e":"markdown","d1966fa2":"markdown","c7a4fa2f":"markdown","f012f79e":"markdown","48474729":"markdown","be695988":"markdown","eef13a5a":"markdown","616b9a91":"markdown"},"source":{"1b1eb3df":"# Import dependencies \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os\nimport pathlib\nimport gc\nimport sys\nimport re\nimport math \nimport random\nimport time \nfrom tqdm import tqdm \nfrom pprint import pprint\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_validate\n\nimport xgboost as xgb\nimport optuna\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport transformers \nimport datasets \n\nprint('import done!')","51f03104":"# global config\nconfig = {}\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \n    print('Seeds setted!')\nglobal_seed = 42\nseed_all(global_seed)","d98ffc08":"data_config = {'train_csv_path': '..\/input\/tabular-playground-series-jan-2022\/train.csv',\n              'test_csv_path': '..\/input\/tabular-playground-series-jan-2022\/test.csv',\n              'sample_submission_path': '..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv',\n              }\n\ntrain_df = pd.read_csv(data_config['train_csv_path'])\ntest_df = pd.read_csv(data_config['test_csv_path'])\nsubmission_df = pd.read_csv(data_config['sample_submission_path'])\n\nprint(train_df.shape, test_df.shape, submission_df.shape)\ntrain_df.head()","0624fef6":"print(len(train_df))\nprint()\ntrain_df.dtypes","ad28b003":"def unique_category(df, column):\n    print(f'unique_category_number: {df[column].nunique()}')\n    print(f'cagetories: {df[column].unique()}')\n    print()\n\nunique_category(train_df, 'country')\nunique_category(train_df, 'store')\nunique_category(train_df, 'product')","8850f8a6":"train_df.isnull().sum()","af88d49a":"def date_features(df):\n    df['date'] = pd.to_datetime(df['date'])\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    return df \n\ntrain_df = date_features(train_df)\ntrain_df = train_df.drop(['date'], axis=1)\n\ntest_df = date_features(test_df)\ntest_df = test_df.drop(['date'], axis=1)\n\ntrain_df.head()","007dd7e7":"X_train_df = train_df.drop('num_sold', axis=1).copy()\ny_train_df = train_df['num_sold'].copy()\n\nX_test_df = test_df.copy()\n\nX_train_df.shape, y_train_df.shape, X_test_df.shape","b2d67ae8":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_features = ['country', 'product', 'store', 'dayofweek', 'month', 'day']\nct = ColumnTransformer([('one_hot', OneHotEncoder(), categorical_features)], remainder=\"passthrough\")\nct.fit(X_train_df)\n\nencoded_X_train = ct.transform(X_train_df)\nencoded_X_test = ct.transform(X_test_df)\nprint(encoded_X_train.shape)\n\nfeature_columns = ct.transformers_[0][1].get_feature_names(categorical_features)\nprint(feature_columns)\n\ncolumns = list(X_train_df.columns)\nfor feature in categorical_features:\n    columns.remove(feature)\ncolumns = list(feature_columns) + columns\n\nencoded_X_train_df = pd.DataFrame(encoded_X_train.toarray(), columns=columns)\nencoded_X_test_df = pd.DataFrame(encoded_X_test.toarray(), columns=columns)\n\nencoded_X_train_df = encoded_X_train_df.drop(['row_id', 'year'], axis=1)\nencoded_X_test_df = encoded_X_test_df.drop(['row_id', 'year'], axis=1)\nencoded_X_train_df.head()","ef8059d6":"from sklearn.model_selection import TimeSeriesSplit\ntscv = TimeSeriesSplit(n_splits=3)\n\nfor fold, (train_index, test_index) in enumerate(tscv.split(encoded_X_train_df)):\n    X_train, X_valid = encoded_X_train_df.iloc[train_index], encoded_X_train_df.iloc[test_index]\n    y_train, y_valid = y_train_df.iloc[train_index], y_train_df.iloc[test_index]\n\n    print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)","7090aadb":"tscv = TimeSeriesSplit(n_splits=3)\ncross_rmse = []\n\nfor fold, (train_index, test_index) in enumerate(tscv.split(encoded_X_train_df)):\n    X_train, X_valid = encoded_X_train_df.iloc[train_index], encoded_X_train_df.iloc[test_index]\n    y_train, y_valid = y_train_df.iloc[train_index], y_train_df.iloc[test_index]\n\n    print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n\n    reg_xgb = xgb.XGBRegressor(objective='reg:linear', seed=global_seed)\n    reg_xgb.fit(X_train, y_train, verbose=False, early_stopping_rounds=10, eval_metric='rmse', eval_set=[(X_valid, y_valid)])\n\n    y_pred = reg_xgb.predict(X_valid)\n    score = np.sqrt(sklearn.metrics.mean_squared_error(y_valid, y_pred))\n    cross_rmse.append(score)\n\nprint(f\"CROSS_RMSE {np.mean(cross_rmse)}\")","ec8ad985":"def objective(trial, X_df, y_df):\n\n    params ={\n        'max_depth': trial.suggest_int(\"max_depth\", 4, 8),\n        'eta': trial.suggest_uniform('eta', 0.05, 0.5),\n        'gamma': trial.suggest_uniform('gamma', 0, 1),\n        'min_child_weight': trial.suggest_int('min_child_weight', 0, 10),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10), \n        #'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n        #'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0, 1),\n    }\n        \n    estimator = xgb.XGBRegressor(objective='reg:linear',\n                                 seed=global_seed,\n                                 n_estimators=100,\n                                 verbosity=0,\n                                 n_jobs=-1,\n                                 random_state=global_seed,\n                                 **params)\n\n    scores = cross_validate(estimator, X_df, y_df, cv=tscv,\n                            scoring=('neg_mean_squared_error'),\n                            return_train_score=True)\n    print(f'scores: {scores}')\n    score = -1 * np.mean(scores['test_score'][2])\n    return score","0585b74e":"study = optuna.create_study()\nstudy.optimize(lambda trial: objective(trial, encoded_X_train_df, y_train_df), n_trials=100)\n\nprint(study.best_params)    \nprint(study.best_value)","53165b00":"best_reg = xgb.XGBRegressor(objective='reg:linear', seed=global_seed, **study.best_params)\nbest_reg.fit(encoded_X_train_df, y_train_df, verbose=True, eval_metric='rmse')\n\nbest_reg.get_params()","ba1bf0be":"pred = best_reg.predict(encoded_X_test_df)\npred.shape","c3f88c96":"submission_df['num_sold'] = pred \nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","ceee419d":"## 2.2 Model Construction","4231aac0":"## 1.2 Feature Engneering","0eeb932e":"# 0. Settings","d1966fa2":"## 1.1 Data Check","c7a4fa2f":"---\n# [Tabular Playground Series - Jan 2022][1]\n---\n\n**Comments**: Thanks to previous great Notebooks.\n\n[[TPS JAN 22] Base XGB & LGB][2]\n\n[TPS 01 2022 CatBoost w\/ Optuna & seed averaging][3]\n\n\n---\n[1]: https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\n[2]: https:\/\/www.kaggle.com\/ranjeetshrivastav\/tps-jan-22-base-xgb-lgb\n[3]: https:\/\/www.kaggle.com\/adamwurdits\/tps-01-2022-catboost-seed-averaging?scriptVersionId=84848139","f012f79e":"# 2. Model Training","48474729":"## 2.3 Hyperparameter Tuning","be695988":"# 3. Prediction and Submission","eef13a5a":"## 2.1 TimeSeriesSplit","616b9a91":"# 1. Data Preprocessing"}}