{"cell_type":{"3211084d":"code","086549ab":"code","30d3724a":"code","3085080c":"code","9e65f32b":"code","3f23249f":"code","dd33d4e8":"code","7ee358c7":"code","36e7edd5":"code","1d744e26":"code","71358b7c":"code","f5f61df5":"code","38ccad40":"code","f827b4e7":"code","3e01ef5e":"code","babf674d":"code","7319f1b0":"code","b5f1c432":"code","f26a399e":"markdown","e1bdc054":"markdown","65e2108f":"markdown","773a7f65":"markdown","549a3da2":"markdown"},"source":{"3211084d":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport keras\nimport matplotlib.pyplot as plt # for plotting\nimport os # provides a way of using operating system dependent functionality\nimport cv2 #Image handling library\nimport numpy as np\n\n# Import of keras model and hidden layers for our convolutional network\nfrom keras.layers import Conv2D, Activation, MaxPool2D, Dense, Flatten, Dropout","086549ab":"CATEGORIES = [\"01_palm\", '02_l','03_fist','04_fist_moved','05_thumb','06_index','07_ok','08_palm_moved','09_c','10_down']\nIMG_SIZE = 50\n\n# paths for dataset\ndata_path = \"..\/input\/leapgestrecog\/leapGestRecog\"","30d3724a":"# Loading the images and their class(0 - 9)\nimage_data = []\nfor dr in os.listdir(data_path):\n    for category in CATEGORIES:\n        class_index = CATEGORIES.index(category)\n        path = os.path.join(data_path, dr, category)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                image_data.append([cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE)), class_index])\n            except Exception as e:\n                pass\nimage_data[0]","3085080c":"# shuffle the input data\nimport random\nrandom.shuffle(image_data)","9e65f32b":"input_data = []\nlabel = []\nfor X, y in image_data:\n    input_data.append(X)\n    label.append(y)","3f23249f":"label[:10]","dd33d4e8":"plt.figure(1, figsize=(10,10))\nfor i in range(1,10):\n    plt.subplot(3,3,i)\n    plt.imshow(image_data[i][0], cmap='hot')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(CATEGORIES[label[i]][3:])\nplt.show()","7ee358c7":"# Normalizing the data\ninput_data = np.array(input_data)\nlabel = np.array(label)\ninput_data = input_data\/255.0\ninput_data.shape","36e7edd5":"# one hot encoding\nlabel = keras.utils.to_categorical(label, num_classes=10,dtype='i1')\nlabel[0]","1d744e26":"# reshaping the data\ninput_data.shape = (-1, IMG_SIZE, IMG_SIZE, 1)","71358b7c":"# splitting the input_data to train and test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(input_data, label, test_size = 0.3, random_state=0)","f5f61df5":"model = keras.models.Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (IMG_SIZE, IMG_SIZE, 1)))\nmodel.add(Activation('relu'))\n\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer = 'rmsprop',\n             metrics = ['accuracy'])","38ccad40":"model.fit(X_train, y_train, epochs = 7, batch_size=32, validation_data=(X_test, y_test))","f827b4e7":"model.summary()","3e01ef5e":"plt.plot(model.history.history['loss'])\nplt.plot(model.history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","babf674d":"plt.plot(model.history.history['accuracy'])\nplt.plot(model.history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","7319f1b0":"#calculate loss and accuracy on test data\n\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\n\nprint('Test accuracy: {:2.2f}%'.format(test_accuracy*100))","b5f1c432":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\ncat = [c[3:] for c in CATEGORIES]\nplt.figure(figsize=(10,10))\ncm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(model.predict(X_test), axis=1))\nsn.heatmap(cm, annot=True,xticklabels=cat, yticklabels=cat)\nplt.plot()","f26a399e":"## Context\nHand gesture recognition database is presented, composed by a set of near infrared images acquired by the Leap Motion sensor.\n\n## Content\nThe database is composed by 10 different hand-gestures that were performed by 10 different subjects (5 men and 5 women).","e1bdc054":"If you find this kernel helpful, Please <b style=\"color:green\">UPVOTES.<\/b>\n\nif you have any query regarding this, comment below.","65e2108f":"## The Data","773a7f65":"## Confusion Matrix","549a3da2":"## The Model"}}