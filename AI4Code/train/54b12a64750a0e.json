{"cell_type":{"032811fb":"code","df221cb3":"code","1cc71954":"code","9b44c8dc":"code","f8d6d71e":"code","6a2c831a":"code","f52e41fa":"code","03211d18":"code","8f93ea22":"code","57be6512":"code","1691a595":"code","6597d857":"code","7effac5c":"code","2325a59c":"code","4b761c31":"code","603d1a81":"code","b5a42ffa":"code","989f4241":"markdown","435c07d6":"markdown","b4454051":"markdown","49efbcdc":"markdown","54d9a4de":"markdown","9ddb67e7":"markdown","14f06f3f":"markdown"},"source":{"032811fb":"import tensorflow as tf\nimport keras\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import jaccard_score\n\nfrom scipy import stats\n\nimport seaborn as sns\n\nimport skimage\nfrom skimage.transform import rotate\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPool2D, UpSampling2D, GlobalMaxPool2D, GlobalAveragePooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Input\nfrom tensorflow.keras.models import Model, load_model\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import NASNetMobile, Xception, DenseNet121, MobileNetV2, InceptionV3, InceptionResNetV2, vgg16, resnet50, inception_v3, xception, DenseNet201\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import CSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom datetime import datetime\n\nimport numpy as np\nimport os\nimport cv2\nimport pandas as pd\n# import imutils\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt","df221cb3":"DATA_PATH = \"..\/input\/super-ai-image-classification\/\"\n\nTRAIN_PATH = DATA_PATH + \"train\/train\/\"\nTEST_PATH = DATA_PATH + \"val\/val\/\"\n\ndf = pd.read_csv(TRAIN_PATH + \"train.csv\")\ndf.index = df['id']\n\nx_resolution = 150\ny_resolution = 150\nbatch_size = 64\nbatch_size_generator = 32\nepoch = 20\nearlystopping = 30","1cc71954":"# Without Drop images\ndef load_image():\n    label = []\n    img_path = os.listdir(TRAIN_PATH + \"images\")\n    train_img = []\n\n    for image in img_path:\n        train_image = cv2.imread(TRAIN_PATH + \"images\/\"+image)\/255.\n        train_image = cv2.resize(train_image, (x_resolution, y_resolution))\n        \n        train_img.append(train_image)\n        label.append(df.category[image])\n    \n    print(np.array(train_img).shape)\n    print(np.array(label).shape)\n    \n    return np.array(train_img), np.array(label)\n\n# Drop images\ndef load_img(df):\n    label = []\n    sum_img = []\n    train_img = []\n\n    count = 0\n    for image in df.id:\n        train_img1 = cv2.imread(TRAIN_PATH + \"images\/\"+image)\n        sum_img.append([int(np.sum(train_img1)),image])\n\n    sum_img = sorted(sum_img)\n    memory = 0\n    same = 0\n    for i in range(len(sum_img)):\n        if sum_img[i][0] == memory:\n            same += 1\n            df = df.drop(sum_img[i][1])\n        memory = sum_img[i][0]\n\n    count = 0\n    for image in df.id:\n        train_img1 = cv2.imread(TRAIN_PATH + \"images\/\"+image)\/255.\n        train_img1 = cv2.resize(train_img1, (x_resolution, y_resolution))\/255.\n#         print(f\"Image {count}: \",train_img1.shape,df.category[image])\n        train_img.append(train_img1)\n        label.append(df.category[image])\n#         print(f\"Load Image {count}: Complete!\")\n        count += 1\n\n    print(same)\n    return np.array(train_img), np.array(label)\n\n# X, Y = load_img(df)\nX, Y = load_image()\nX.shape, Y.shape\n# X, Y = load_image()","9b44c8dc":"# aug = ImageDataGenerator(\n#         rotation_range=15,\n#         width_shift_range=0.15,\n#         height_shift_range=0.15,\n#         shear_range=0.2,\n#         zoom_range=0.2,\n#         horizontal_flip=True\n#         )\n\n# fig = plt.figure(tight_layout='auto', figsize=(10, 7))\n# for num, i in enumerate(aug.flow(X)):\n#     fig.add_subplot(331+int(num))\n#     plt.imshow(i[0])\n#     if num == 8:\n#         break\n# plt.show()","f8d6d71e":"with tf.device('\/device:GPU:0'):        \n    def get_f1(y_true, y_pred): #taken from old keras source code\n        true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n        possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n        predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + tf.keras.backend.epsilon())\n        recall = true_positives \/ (possible_positives + tf.keras.backend.epsilon())\n        f1_val = 2*(precision*recall)\/(precision+recall+tf.keras.backend.epsilon())\n        return f1_val\n    \n    def get_model():\n        inputs = Input(shape=(x_resolution, y_resolution, 3))\n        \n        x = inputs\n        basemodel = InceptionV3(include_top=False, input_shape=(x_resolution, y_resolution, 3), weights='imagenet')\n        \n        for layer in basemodel.layers:\n            layer.trainable = False\n            \n#         basemodel.trainable = False\n\n        x = basemodel(x)\n        x = GlobalAveragePooling2D()(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(1024)(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(1)(x)\n        outputs = Activation('sigmoid')(x)\n\n        model = Model(inputs=inputs, outputs=outputs)\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n        model.summary()\n\n        return model","6a2c831a":"# x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)\n\nkfold = KFold(n_splits=10, random_state=42, shuffle=False)\n\n# train_generator = aug.flow(x_train, y_train, seed=42, batch_size=batch_size_generator)\n# valid_generator = aug.flow(x_valid, y_valid, seed=42, batch_size=batch_size_generator)\n\nmodel = get_model()\n# model_generator = get_model()\nnp.unique(Y, return_counts=True)","f52e41fa":"folder = 'drop_1'\nbest_model_filename = '.\/model_'+folder+'.h5'\n\nEarlyStopper = EarlyStopping(patience=earlystopping, verbose=1, monitor='val_accuracy', mode='max')\nCsv_logger = CSVLogger('.\/save.csv', append=True, separator=';')\nCheckpoint = ModelCheckpoint(best_model_filename, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max')","03211d18":"# model.fit(x_train, y_train, \n#          validation_data=(x_valid, y_valid),\n#          batch_size=batch_size,\n#          epochs=epoch,\n#          verbose=1,\n#          callbacks=[Csv_logger, Checkpoint, EarlyStopper])","8f93ea22":"val_acc = []\nfor count, (train_index, valid_index) in enumerate(kfold.split(X)):\n#     x_train = X[train_index]\n#     y_train = Y[train_index]\n#     x_valid = X[valid_index]\n#     y_valid = Y[valid_index]\n    \n    model.fit(X[train_index], Y[train_index], \n         validation_data=(X[valid_index], Y[valid_index]),\n         batch_size=batch_size,\n         epochs=epoch,\n         verbose=1\n        )\n    print(count+1)\n    print('========= Genearator Model =========')\n    results_train = model.evaluate(X[train_index], Y[train_index])\n    results_valid = model.evaluate(X[valid_index], Y[valid_index])\n    print('Train loss :', results_train[0])\n    print('Train accuracy :', results_train[1])\n    print('Valid loss :', results_valid[0])\n    print('Valid accuracy :', results_valid[1])\n    val_acc.append(results_valid[1])\n    print('\\n\\n')\n    \nmodel.save(best_model_filename)","57be6512":"for num, i in enumerate(val_acc):\n    print('Fold :', num+1)\n    print('Accuracy :', i*100, '%')\n    print('=========================================')\n    \nprint('========= Last Genearator Model =========')\nresults = model.evaluate(X, Y)\nprint('Loss :', results[0])\nprint('Accuracy :', results[1]*100, '%')\n","1691a595":"# print('========= Last Model =========')\n# results_train = model.evaluate(x_train, y_train)\n# results_valid = model.evaluate(x_valid, y_valid)\n# print('Train loss :', results_train[0])\n# print('Train accuracy :', results_train[1])\n# print('Valid loss :', results_valid[0])\n# print('Valid accuracy :', results_valid[1])\n\n# best_model = load_model(best_model_filename)\n# print('\\n\\n========= Best Model =========')\n# results__train = best_model.evaluate(x_train, y_train)\n# results__valid = best_model.evaluate(x_valid, y_valid)\n# print('Train loss :', results__train[0])\n# print('Train accuracy :', results__train[1])\n# print('Valid loss :', results__valid[0])\n# print('Valid accuracy :', results__valid[1])","6597d857":"# best_model_generator_filename = '.\/best_model_generator.h5'\n\n# EarlyStopper = EarlyStopping(patience=earlystopping, verbose=1, monitor='val_get_f1', mode='max')\n# Csv_logger = CSVLogger('.\/save_generator.csv', append=True, separator=';')\n# Checkpoint = ModelCheckpoint(best_model_generator_filename, verbose=1, monitor='val_get_f1', save_best_only=True, mode='max')","7effac5c":"# for count, (train_index, valid_index) in enumerate(kfold.split(X)):\n#     train_generator = aug.flow(X[train_index], Y[train_index], seed=42, batch_size=batch_size_generator)\n#     valid_generator = aug.flow(X[valid_index], Y[valid_index], seed=42, batch_size=batch_size_generator)\n#     model_generator.fit(train_generator, \n#          validation_data=valid_generator,\n#          steps_per_epoch=len(X[train_index])\/\/batch_size,\n#          epochs=epoch,\n#          verbose=0,\n#          callbacks=[EarlyStopper]\n#         )\n#     print(count+1)\n#     print('========= Genearator Model =========')\n#     results_train = model_generator[count].evaluate(X[train_index], Y[train_index])\n#     results_valid = model_generator[count].evaluate(X[valid_index], Y[valid_index])\n#     print('Train loss :', results_train[0])\n#     print('Train accuracy :', results_train[1])\n#     print('Valid loss :', results_valid[0])\n#     print('Valid accuracy :', results_valid[1])\n#     print('\\n\\n')\n    \n# # model_generator.save('model.h5')\n\n# print('========= Last Genearator Model =========')\n# results = model_generator.evaluate(X, Y)\n# print('Loss :', results[0])\n# print('Accuracy :', results[1])","2325a59c":"# model_generator.fit(train_generator, \n#          validation_data=valid_generator,\n#          batch_size=len(x_train)\/\/batch_size,\n#          epochs=epoch,\n#          verbose=1,\n#          callbacks=[Csv_logger, Checkpoint, EarlyStopper])","4b761c31":"# print('========= Last Genearator Model =========')\n# results_train = model_generator.evaluate(x_train, y_train)\n# results_valid = model_generator.evaluate(x_valid, y_valid)\n# print('Train loss :', results_train[0])\n# print('Train accuracy :', results_train[1])\n# print('Train f1 :', results_train[2])\n# print('Valid loss :', results_valid[0])\n# print('Valid accuracy :', results_valid[1])\n# print('Valid f1 :', results_valid[2])\n\n# best_model_generator = load_model(best_model_generator_filename)\n# print('\\n\\n========= Best Generator Model =========')\n# results__train = best_model_generator.evaluate(x_train, y_train)\n# results__valid = best_model_generator.evaluate(x_valid, y_valid)\n# print('Train loss :', results__train[0])\n# print('Train accuracy :', results__train[1])\n# print('Train f1 :', results__train[2])\n# print('Valid loss :', results__valid[0])\n# print('Valid accuracy :', results__valid[1])\n# print('Valid f1 :', results__valid[2])","603d1a81":"# print('========= Last Genearator Model =========')\n# results_train = model_generator.evaluate(train_generator)\n# results_valid = model_generator.evaluate(valid_generator)\n# print('Train loss :', results_train[0])\n# print('Train accuracy :', results_train[1])\n# print('Train f1 :', results_train[2])\n# print('Valid loss :', results_valid[0])\n# print('Valid accuracy :', results_valid[1])\n# print('Valid f1 :', results_valid[2])\n\n# print('\\n\\n========= Best Generator Model =========')\n# results__train = best_model_generator.evaluate(train_generator)\n# results__valid = best_model_generator.evaluate(valid_generator)\n# print('Train loss :', results__train[0])\n# print('Train accuracy :', results__train[1])\n# print('Train f1 :', results__train[2])\n# print('Valid loss :', results__valid[0])\n# print('Valid accuracy :', results__valid[1])\n# print('Valid f1 :', results__valid[2])","b5a42ffa":"def load_img_test():\n    img_path = os.listdir(TEST_PATH + \"images\")\n    test_img = np.zeros((len(img_path), x_resolution, y_resolution, 3)).astype('float')\n\n    count = 0\n    for image in img_path:\n        test_img1 = cv2.imread(TEST_PATH + \"images\/\"+image)\/255.\n        test_img1 = cv2.resize(test_img1, (x_resolution, y_resolution))\n        #print(f\"Image {count}: \",test_img1.shape)\n        test_img[count] = test_img1\n        #print(f\"Load Image {count}: Complete!\")\n        count += 1\n\n    return test_img\n\ntest_data = pd.read_csv(TEST_PATH + \"val.csv\")\ntest_img = load_img_test()\ntest_img = np.array(test_img)\nprint(test_img.shape)\nbest_model = load_model(best_model_filename)\npred = best_model.predict(test_img)\nlabel = []\nfor value in range(len(pred)):\n    if pred[value] >= 0.5:\n        label.append(1)\n    else:\n        label.append(0)\n\ndata = {'id':os.listdir(TEST_PATH + \"images\"), 'category':label}\nsubmission_df = pd.DataFrame(data)\nsubmission_df\nsubmission_df.to_csv('submission_091020_'+folder+'.csv',index=False)","989f4241":"\n\n# Model\n","435c07d6":"# Image Augmentation","b4454051":"# Training Process","49efbcdc":"\n# Load Images","54d9a4de":"# Parameter","9ddb67e7":"# KFold Training","14f06f3f":"# Submission"}}