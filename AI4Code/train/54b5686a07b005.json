{"cell_type":{"5b42f985":"code","b0e47348":"code","4c581955":"code","effaecbe":"code","05aaa1db":"code","8b3d2ed1":"code","c3f7467f":"code","2a7090c5":"code","4c8a2cb5":"code","2af29800":"code","8ff53182":"code","5c5a447e":"code","2e439196":"code","7de078ba":"code","bf8b00ee":"code","a7f0156a":"code","4bbea3cc":"code","c1dff2d2":"code","dd7f8cfb":"code","24e76c25":"code","54190fbe":"markdown","fac01202":"markdown","8e92ce13":"markdown","04929495":"markdown","97ecde6d":"markdown","b1bea318":"markdown","37282438":"markdown","1453f2b9":"markdown","adb42255":"markdown","147f0c61":"markdown"},"source":{"5b42f985":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport glob\nfrom collections import Counter\nimport matplotlib.pyplot as plot\nimport seaborn as sb\nfrom matplotlib import cm\nimport json\nimport glob\nimport pandas as panda\nimport matplotlib.pyplot as plot\nimport re\nimport nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom nltk.corpus import stopwords\nfrom nltk import sent_tokenize, word_tokenize\nfrom wordcloud import WordCloud\nimport wordcloud\nimport datetime","b0e47348":"PLOT_COLORS = [\"#268bd2\", \"#0052CC\", \"#FF5722\", \"#b58900\", \"#003f5c\"]\npd.options.display.float_format = '{:.2f}'.format\nsns.set(style=\"ticks\")\nplt.rc('figure', figsize=(8, 5), dpi=100)\nplt.rc('axes', labelpad=20, facecolor=\"#ffffff\", linewidth=0.4, grid=True, labelsize=14)\nplt.rc('patch', linewidth=0)\nplt.rc('xtick.major', width=0.2)\nplt.rc('ytick.major', width=0.2)\nplt.rc('grid', color='#9E9E9E', linewidth=0.4)\nplt.rc('font', family='Arial', weight='400', size=10)\nplt.rc('text', color='#282828')\nplt.rc('savefig', pad_inches=0.3, dpi=300)","4c581955":"path = r'..\/input\/youtube-new'\nall_files = glob.glob(path + \"\/*.csv\")\nli = []\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col='video_id', encoding='latin-1')\n    df['country'] = filename[21:23] #Ajout du pays\n    li.append(df)        \nmy_data = pd.concat(li)","effaecbe":"# Supression des valeurs null\nmy_data[\"description\"] = my_data[\"description\"].fillna(value=\"\")\n\n# Changement des types\n## Dates\nmy_data['tresnding_date']=pd.to_datetime(my_data['trending_date'],format='%y.%d.%m')\nmy_data['publish_time']=pd.to_datetime(my_data['publish_time'],format='%Y-%m-%dT%H:%M:%S.%fZ')\nmy_data['publish_time'].dt.date\nmy_data.insert(4,'publish_date',my_data['publish_time'].dt.date)\nmy_data['publish_time']=my_data['publish_time'].dt.time\nmy_data[['publish_time','publish_date','tresnding_date']].head()\n##String et Integer\ntype_int=['views','likes','dislikes','comment_count']\nfor i in type_int:\n    my_data[i]=my_data[i].astype(int)\nmy_data['category_id']=my_data['category_id'].astype(str)","05aaa1db":"category_name_id = {}\nwith open('..\/input\/youtube-new\/US_category_id.json','r') as f:\n    data=json.load(f)\n    for category in data['items']:\n        category_name_id[category['id']]=category['snippet']['title']\n#category_name_id\n\nmy_data.insert(4,'category',my_data['category_id'].map(category_name_id))\nmy_data[['category_id','category']].head()","8b3d2ed1":"# Description des donn\u00e9es numeriques\nmy_data.describe()","c3f7467f":"# Correlation des donn\u00e9es du dataset\nh_labels = [x.replace('_', ' ').title() for x in \n            list(my_data.select_dtypes(include=['number', 'bool']).columns.values)]\n\nfig, ax = plt.subplots(figsize=(10,6))\n_ = sns.heatmap(df.corr(), annot=True, xticklabels=h_labels, yticklabels=h_labels, cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)\n\n#corr_matrix=my_data[['views', 'likes', 'dislikes', 'comment_count']].corr()\n#corr_matrix","2a7090c5":"# Likes et Vues\nsns.scatterplot(x='likes',y='views',data=my_data)","4c8a2cb5":"# Likes et nomb re de commentaires\nsns.scatterplot(x='comment_count',y='views',data=my_data)","2af29800":"# Nombre de vues par cat\u00e9gorie\ncategory_count=my_data['category'].value_counts()\ncategory_count","8ff53182":"# Les tags les plus utilis\u00e9s \ntag=[]\nfor i in my_data['tags']:\n    for j in i.split('|'):\n        tag.append(j.replace('\"',\" \").strip().replace('\"',\"\"))\nTAGS=pd.DataFrame(tag,columns=['TAGS'])        \nTAGS=TAGS['TAGS'].value_counts().iloc[:6]\nTAGS=TAGS.drop('[none]')\nTAGS","5c5a447e":"# Taille des titres de videos\nmy_data[\"title_length\"] = my_data[\"title\"].apply(lambda x: len(x))\n\nfig, ax = plt.subplots()\n_ = sns.distplot(my_data[\"title_length\"], kde=False, rug=False, \n                 color=PLOT_COLORS[3], hist_kws={'alpha': 1}, ax=ax)\n_ = ax.set(xlabel=\"Title Length\", ylabel=\"No. of videos\", xticks=range(0, 110, 10))","2e439196":"# Cat\u00e9gories les plus populaires\ndef best_cat(data,title):\n    plot.figure(figsize=(15,10))\n    sb.set_style(\"whitegrid\")\n    ax = sb.barplot(y=data['index'],x=data['category'], data=data,orient='h')\n    plot.xlabel(\"Nombre de videos\")\n    plot.ylabel(\"Categories\")\n    plot.title(title)\n\ndata = my_data[my_data['country']!='']['category'].value_counts().reset_index()\ntitle = \"\\n Categories les plus populaires \\n\"\nbest_cat(data, title)","7de078ba":"# Cat\u00e8gories par pays \ndef category_per_country(list_categories_per_country, title):\n    plot.yticks(rotation=30, fontsize=20)\n    plot.xticks(rotation=30, fontsize=15)\n    plot.title(title, fontsize=20)\n    plot.legend(handlelength=5, fontsize=15, loc='center left', bbox_to_anchor=(1, 0.5))\n    plot.show()\n\nlist_categories_per_country = my_data.reset_index().groupby([\"country\", \"category\"]).count()['video_id'].unstack().plot.barh(figsize=(12, 10), stacked=True)\ntitle = \"\\n Cat\u00e9gories populaire par pays \\n\"\ncategory_per_country(list_categories_per_country, title)","bf8b00ee":"def polar_draw(sentiment, title):\n    plot.figure(figsize=(16,10))\n    sb.set(style=\"white\",context=\"talk\")\n    ax = sb.barplot(x=sentiment['polarity'],y=sentiment['category'], data=sentiment,orient='h',palette=\"RdBu\")\n    plot.xlabel(\"polarity\")\n    plot.ylabel(\"categories\")\n    plot.title(title)","a7f0156a":"MAX_N = 1000\npolarities = list()\nen_stopwords = list(stopwords.words('english'))\nde_stopwords = list(stopwords.words('german'))   \nfr_stopwords = list(stopwords.words('french'))   \nfr_stopwords.extend(de_stopwords)\nfr_stopwords.extend(en_stopwords)\n\ncategory_list = my_data['category'].unique()\nfor cat in category_list:\n    print(cat)\n    tags_word = my_data[my_data['category'] ==cat]['tags'].str.lower().str.cat(sep=' ')    \n    tags_word = re.sub('[^A-Za-z]+', ' ', tags_word)\n    word_tokens = word_tokenize(tags_word)\n    filtered_sentence = [w for w in word_tokens if not w in fr_stopwords]\n    without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n    cleaned_data_title = [word for word in without_single_chr if not word.isdigit()] \n    word_dist = nltk.FreqDist(cleaned_data_title)\n    hnhk = pd.DataFrame(word_dist.most_common(MAX_N),\n                    columns=['Word', 'Frequency'])\n\n    compound = .0\n    for word in hnhk['Word'].head(MAX_N):\n        compound += SentimentIntensityAnalyzer().polarity_scores(word)['compound']\n\n    polarities.append(compound)","4bbea3cc":"category_list = pd.DataFrame(my_data['category'].unique())\npolarities = pd.DataFrame(polarities)\nsentiment = pd.concat([category_list,polarities],axis=1)\nsentiment.columns = ['category','polarity']\nsentiment=sentiment.sort_values('polarity').reset_index()\ntitle = \"Polarite des categories dans les videos Youtube\"\npolar_draw(sentiment, title)","c1dff2d2":"# Combien de titres vid\u00e9o tendance contiennent un mot en majuscule?\ndef contains_capitalized_word(s):\n    for w in s.split():\n        if w.isupper():\n            return True\n    return False\nmy_data[\"contains_capitalized\"] = my_data[\"title\"].apply(contains_capitalized_word)\nvalue_counts = my_data[\"contains_capitalized\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie([value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'}, startangle=45)\n_ = ax.axis('equal')\n_ = ax.set_title('Vid\u00e9os contient un mot en majuscule?')","dd7f8cfb":"# Quel sont mes tags les plus populaires ?\ndef wcloud(data,bgcolor):\n    plot.figure(figsize = (100,60))\n    cloud = WordCloud(background_color = bgcolor, max_words = 60, \n                     width=1200, height=500,colormap=\"tab20b\")\n    cloud.generate(' '.join(data))\n    plot.imshow(cloud)\n    plot.axis('off')","24e76c25":"fr_stopwords = list(stopwords.words('french'))   \ntags_word = my_data['tags'].str.lower().str.cat(sep=' ')\ntags_word = re.sub('[^A-Za-z]+', ' ', tags_word)\nword_tokens = word_tokenize(tags_word)\nfiltered_sentence = [w for w in word_tokens if not w in fr_stopwords]\nwithout_single_chr = [word for word in filtered_sentence if len(word) > 2 ]\ncleaned_data_title = [word for word in without_single_chr if not word.isdigit()]\n\nwcloud(cleaned_data_title,'white')","54190fbe":"# Premier aper\u00e7u","fac01202":"# Nettoyage des donn\u00e9es","8e92ce13":"# Importation des biblioth\u00e8ques","04929495":"# Des statistiques","97ecde6d":"# Analyse de sentiments","b1bea318":"# Quelque questions","37282438":"# Lecture des dataset","1453f2b9":"# Ajout d'autre source de donn\u00e9es","adb42255":"# Configurations pour les diagrammes","147f0c61":"# Relations entre attributs"}}