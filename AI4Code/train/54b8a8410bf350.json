{"cell_type":{"d8606403":"code","c918f9a8":"code","347da713":"code","57b6ad8d":"code","27b536a6":"code","9417d6ce":"code","9067aab0":"code","fa908242":"code","c7520cc6":"code","48d58563":"code","2db2810d":"code","bdac6c51":"code","58ac04ad":"code","0428d128":"code","63eb86ff":"code","c7c9344e":"code","0cdb3991":"code","bff32612":"code","6f212051":"code","adb52dce":"code","f4a6ced7":"code","851a52d6":"code","7ae26a6a":"code","15edeefc":"code","f3094152":"code","c1a6edb5":"code","f943b80c":"code","1d042658":"code","8451df18":"code","2bbeee47":"code","5ebad501":"code","9314a17c":"code","78a04074":"code","2b2a6c70":"code","8b71fd2c":"markdown","a8cdfc38":"markdown","e2d5882b":"markdown","54ba0a90":"markdown","fdc471af":"markdown","e4687d66":"markdown","4e74544f":"markdown","c32dc372":"markdown","f82306cf":"markdown","8e073160":"markdown","6035efef":"markdown","c8066db0":"markdown","0c0f6e30":"markdown","f4ca197a":"markdown","0a75397c":"markdown","a731db09":"markdown","47c60ce8":"markdown","b48a464b":"markdown","b211961b":"markdown","34514be2":"markdown","0b7d1d3d":"markdown","32ac0172":"markdown","89ebcb2c":"markdown","c9847428":"markdown","30163842":"markdown","315ab61c":"markdown","748f75a1":"markdown","8f07e814":"markdown","2d037bc8":"markdown","35a81b25":"markdown","7775062f":"markdown","9a1d98e4":"markdown"},"source":{"d8606403":"##   Buran\u0131n \u00fczerinden ge\u00e7ilebilinir.","c918f9a8":"#K\u00fct\u00fcphaneleri y\u00fckle\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import metrics\n#from sklearn.cross_validation import KFold   #For K-fold cross validation\n","347da713":"#Datay\u0131 Oku\ndf = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\") #excelden veris setini okuyup bir data frame i\u00e7erisine ekledim","57b6ad8d":"df.head() #ilk 5 sat\u0131rdaki de\u011ferleri default olarak g\u00f6r\u00fcyorum","27b536a6":"df.target.value_counts()","9417d6ce":"sns.countplot(x = \"target\", data = df,palette = \"hls\")\nplt.show()","9067aab0":"number_of_disease = len(df[df.target == 1])\nnumber_of_healthy = len(df[df.target == 0])\npercentage_of_disease = (number_of_disease \/ (len(df.target)) * 100)\npercentage_of_healthy = (number_of_healthy \/ (len(df.target)) * 100)\nprint(f\"Kalp Hastali\u011fi olan hastalar\u0131n oran\u0131 : \",percentage_of_disease)\nprint(f\"Sa\u011fl\u0131kl\u0131 olan hastalar\u0131n oran\u0131 : \",percentage_of_healthy)","fa908242":"sns.countplot(x = \"sex\", data = df, palette = \"magma\")\nplt.xlabel(\"Gender Values (1 --> Male, 0 --> Female)\")\nplt.show()","c7520cc6":"numberofFemale = len(df[df.sex == 0])\nnumberofMale = len(df[df.sex == 1])\npercentage_of_females = (numberofFemale \/ (len(df.sex) * 100))\npercentage_of_males = (numberofMale \/ (len(df.sex) * 100))\nprint(f\"Kad\u0131n Hasta Oran\u0131: \",percentage_of_females)\nprint(f\"Erkek Hasta Oran\u0131: \",percentage_of_males)","48d58563":"df.groupby(\"target\").mean()","2db2810d":"pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize = (30,15))\nplt.title(\"Ya\u015flara G\u00f6re Kalp Hastal\u0131\u011f\u0131 Frekans Da\u011f\u0131l\u0131m\u0131\")\nplt.xlabel(\"Ya\u015f\")\nplt.ylabel(\"Frekans\")\nplt.savefig(\"kalprahatsizligi.png\")\nplt.show()","bdac6c51":"pd.crosstab(df.sex,df.target).plot(kind = \"bar\",figsize=(20,15),color=[\"#CEF6EC\",\"#FA58D0\"])\nplt.title(\"Cinsiyete G\u00f6re Kalp Rahats\u0131zl\u0131\u011f\u0131 Da\u011f\u0131l\u0131m\u0131 Frekans\u0131\")\nplt.xlabel(\"Cinsiyet (1 --> Erkek, 0 --> Kad\u0131n)\")\nplt.xticks(rotation = 0)\nplt.legend([\"Kalp Hastal\u0131\u011f\u0131 Yok\",\"Kalp Hastal\u0131\u011f\u0131 Var\"])\nplt.ylabel(\"Frekans\")\nplt.show()","58ac04ad":"plt.scatter(x = df.age[df.target == 1], y = df.thalach[(df.target == 1)], c = \"pink\")\nplt.scatter(x = df.age[df.target == 0], y = df.thalach[df.target == 0])\nplt.legend([\"Hasta\",\"Hasta De\u011fil\"])\nplt.xlabel(\"Ya\u015f\")\nplt.ylabel(\"Maximum Kalp At\u0131\u015f H\u0131z\u0131\")\nplt.show()","0428d128":"pd.crosstab(df.slope,df.target).plot(kind=\"bar\",figsize=(20,15),color=['#DF01D7','#9FF781' ])\nplt.title(\"Kalp Rahats\u0131zl\u0131\u011f\u0131 Frekans E\u011fimi\")\nplt.xlabel(\"ST Segment'in Pik De\u011ferleri\")\nplt.xticks(rotation = 0)\nplt.ylabel(\"Frekans\")\nplt.show()","63eb86ff":"pd.crosstab(df.fbs,df.target).plot(kind=\"bar\",figsize=(20,15),color=[\"#0404B4\",\"#F6CED8\"])\nplt.title(\"A\u00e7l\u0131k Kan \u015eekerine De\u011ferine G\u00f6re Kalp Rahats\u0131zl\u0131\u011f\u0131 Frekans\u0131\")\nplt.xlabel(\"FBS - (A\u00e7l\u0131k Kan \u015eekeri > 120 mg\/dl),(varsa ->1 ,yoksa -> 0)\")\nplt.xticks(rotation = 0)\nplt.legend(\"Hastal\u0131k Yok\",\"Hastal\u0131k Var\")\nplt.ylabel(\"Hastal\u0131k Frekans\u0131 Var m\u0131?, Yok mu?\")\nplt.show()","c7c9344e":"pd.crosstab(df.cp,df.target).plot(kind=\"bar\",figsize=(15,6),color=['#58FAAC','#FE2E64' ])\nplt.title('G\u00f6\u011f\u00fcsteki A\u011fr\u0131 Tipine G\u00f6re Kalp Rahats\u0131zl\u0131\u011f\u0131 Frekans\u0131')\nplt.xlabel('G\u00f6\u011f\u00fcs A\u011fr\u0131 Tipi')\nplt.xticks(rotation = 0)\nplt.ylabel('Hastal\u0131k Var m\u0131?,Yok mu?')\nplt.show()","0cdb3991":"\"\"\"\nfirst = pd.get_dummies(df[\"cp\"], prefix = \"cp\" )\nsecond = pd.get_dummies([\"thal\"], prefix = \"thal\" )\nthird = pd.get_dummies(df[\"slope\"], prefix = \"slope\")\n\n\"\"\"","bff32612":"\"\"\"\nframes = [df, first, second, third]\ndf = pd.concat(frames, axis = 1)\ndf.head(10)\n\"\"\"","6f212051":"\"\"\"\ndf = df.drop(columns = [\"cp\",\"thal\",\"slope\"])\ndf.head(10)\n\"\"\"","adb52dce":"y = df.target.values\nx_data = df.drop([\"target\"], axis = 1)","f4a6ced7":"import pandas as pd\n\ndef clean_dataset(df):\n    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    df.dropna(inplace=True)\n    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n    return df[indices_to_keep].astype(np.float64)\n","851a52d6":"x = ( x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data)).values","7ae26a6a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1,random_state=0)\nx_train = x_train.T\ny_train = y_train.T\nx_test = x_test.T\ny_test = y_test.T\n","15edeefc":"def initialize(dimension):\n  weight = np.full((dimension,1),0.01)\n  bias = 0.0\n  return weight,bias","f3094152":"def sigmoid(z):\n  y_head = 1 \/ (1 + np.exp(-z))\n  return y_head","c1a6edb5":"def forwardBackward(weight,bias,x_train,y_train):\n    # Forward\n    y_head = sigmoid(np.dot(weight.T,x_train) + bias)\n    loss = -(y_train*np.log(y_head) + (1-y_train)*np.log(1-y_head))\n    cost = np.sum(loss) \/ x_train.shape[1]\n    \n    # Backward\n    derivative_weight = np.dot(x_train,((y_head-y_train).T))\/x_train.shape[1]\n    derivative_bias = np.sum(y_head-y_train)\/x_train.shape[1]\n    gradients = {\"Derivative Weight\" : derivative_weight, \"Derivative Bias\" : derivative_bias}\n    \n    return cost,gradients","f943b80c":"def update(weight,bias,x_train,y_train,learningRate,iteration) :\n    costList = []\n    index = []\n    \n    #for each iteration, update weight and bias values\n    for i in range(iteration):\n        cost,gradients = forwardBackward(weight,bias,x_train,y_train)\n        weight = weight - learningRate * gradients[\"Derivative Weight\"]\n        bias = bias - learningRate * gradients[\"Derivative Bias\"]\n        \n        costList.append(cost)\n        index.append(i)\n\n    parameters = {\"weight\": weight,\"bias\": bias}\n    \n    print(\"iteration:\",iteration)\n    print(\"cost:\",cost)\n\n    plt.plot(index,costList)\n    plt.xlabel(\"Number of Iteration\")\n    plt.ylabel(\"cost\")\n    plt.show()\n\n    return parameters, gradients\n\n\ndef predict(weight,bias,x_test):\n    z = np.dot(weight.T,x_test) + bias\n    y_head = sigmoid(z)\n    y_prediction = np.zeros((1,x_test.shape[1]))\n    for i in range(y_head.shape[1]):\n        if y_head[0,i] <= 0.5:\n            y_prediction[0,i] = 0\n        else:\n            y_prediction[0,i] = 1\n    return y_prediction\n","1d042658":"def logistic_regression(x_train,y_train,x_test,y_test,learningRate,iteration):\n    dimension = x_train.shape[0]\n    weight,bias = initialize(dimension)\n    \n    parameters, gradients = update(weight,bias,x_train,y_train,learningRate,iteration)\n\n    y_prediction = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n    \n    print(\"Manuel Test'in Do\u011fruluk Oran\u0131: {:.2f}%\".format((100 - np.mean(np.abs(y_prediction - y_test))*100)))","8451df18":"logistic_regression(x_train,y_train,x_test,y_test,1,100)","2bbeee47":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\naccuracies = {}\n\nlr = LogisticRegression()\nlr.fit(x_train.T, y_train.T)\nacc = lr.score(x_test.T,y_test.T)*100\n\naccuracies['Logistic Regression'] = acc\nprint(\"Logistic Regression Do\u011fruluk De\u011feri {:.2f}%\".format(acc))\n\n","5ebad501":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier()\ntree.fit(x_train.T , y_train.T)\nacc = tree.score(x_test.T, y_test.T) * 100\naccuracies[\"DecisionTree\"] = acc\nprint(f\"Karar A\u011fac\u0131 Do\u011fruluk De\u011feri : \",acc)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators = 1000, random_state = 1)\nforest.fit(x_train.T, y_train.T)\n\nacc = forest.score(x_test.T,y_test.T)*100\naccuracies['Random Forest'] = acc\nprint(\"Random Forest Do\u011fruluk De\u011feri : {:.2f}%\".format(acc))","9314a17c":"colors = [\"pink\",\"purple\",\"black\"]\nsns.set_style(\"dark\")\nplt.figure(figsize=(20,15))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Do\u011fruluk Y\u00fczdesi\")\nplt.xlabel(\"Y\u00f6ntem Kodlamalar\")\nsns.barplot(x = list(accuracies.keys()), y=list(accuracies.values()), palette = colors)\nplt.show()","78a04074":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\ny_head_lr = lr.predict(x_test.T)\nknn3 = KNeighborsClassifier(n_neighbors = 3)\nknn3.fit(x_train.T, y_train.T)\ny_head_tree = tree.predict(x_test.T)\ny_head_forest = forest.predict(x_test.T)\n\n\nfrom sklearn.metrics import confusion_matrix\nlr_confm = confusion_matrix(y_test, y_head_lr)\ntree_confm = confusion_matrix(y_test, y_head_tree)\nforest_confm = confusion_matrix(y_test,y_head_forest)\n\nplt.figure(figsize=(20,15))\n\nplt.title(\"Confusion Matrix\",fontsize = 24)\nplt.subplots_adjust(wspace = 0.4, hspace = 0.4)\n\nplt.subplot(2,3,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(lr_confm,annot=True,cmap=\"Purples\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(2,3,2)\nplt.title(\"Decision Tree Classifier Confusion Matrix\")\nsns.heatmap(tree_confm,annot=True,cmap=\"Greens\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(2,3,3)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(forest_confm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.show()\n","2b2a6c70":"#Cross vold 10 validation i\u00e7in daha fazla ara\u015ft\u0131rma yap.","8b71fd2c":"Toplamda bu hastal\u0131\u011fa sahip 165 hasta var iken,kalp hastal\u0131\u011f\u0131 ollmayan 138 hasta kayd\u0131 bulunmaktad\u0131r.Ye\u015fil s\u00fctun hasta olan insanlara ait bilgileri tutarken,k\u0131rm\u0131z\u0131 s\u00fctun hasta olmayan insanlar\u0131n kay\u0131tlar\u0131n\u0131n g\u00f6rselidir","a8cdfc38":"# Soru 4\n4)\tDeneysel \u00c7al\u0131\u015fma: a) Verileri e\u011fitim ve test verisi olarak ay\u0131r\u0131n\u0131z. Madde 3\u2019te se\u00e7ti\u011finiz her 2 y\u00f6ntem i\u00e7in de : a) Hata (Confusion) matrisini ve do\u011fruluk (accuracy) de\u011ferini, b) 10-fold cross validation ile de do\u011fruluk de\u011ferlerini (ve ortalamas\u0131n\u0131) elde ederek rapora ekleyiniz. http:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html. Sonu\u00e7lar\u0131 yorumlay\u0131n\u0131z. (20)  \n","e2d5882b":"**Veri Normalizasyonu**\n\n*  Veri normalizasyonu form\u00fcl\u00fc X de\u011ferleri \u00fczerine in\u015faa edilmi\u015ftir.Ben x_data de\u011fi\u015fkenimle i\u015flemler yapaca\u011f\u0131m.X_scaled = (X_data - X_data_min) \/ (X_data_max - X_data_min) form\u00fcl\u00fc ile verilerimizi normalize edebilirim\n\n\n","54ba0a90":"Veri k\u00fcmesinde bulunan kategorik de\u011fi\u015fkenleri dummy de\u011fi\u015fkenlere d\u00f6n\u00fc\u015ft\u00fcrme i\u015flemi yapaca\u011f\u0131m","fdc471af":"**Veri Ke\u015ffi**","e4687d66":"Toplamda 303 tane veri kayd\u0131 var ve toplamda 13 tane \u00f6z nitelik de\u011ferlerim var.13 ayr\u0131 kolon de\u011ferine g\u00f6re \u015fekillendirilmi\u015f 303 sat\u0131rl\u0131k bir veri k\u00fcmesi.As\u0131l ama\u00e7 kalp rahats\u0131zl\u0131\u011f\u0131 olan hastalarla olmayanlar\u0131 s\u0131n\u0131fland\u0131rmaya \u00e7al\u0131\u015fmak.Bu s\u0131n\u0131fta toplamda target de\u011ferine g\u00f6re 2 kategorim var.Ya hasta olabilir yada olamaz ama bu duruma etken olan di\u011fer 13 kolonda benim as\u0131l \u00f6zniteliklerimdir.S\u0131n\u0131f say\u0131s\u0131 2 tanedir.Bu problem i\u00e7in hastal\u0131 varsa 1 ,yosa 0 de\u011ferini alacakt\u0131r","4e74544f":"# SORU 1:\n**1)\tVeri Madencili\u011fi ve Makine \u00d6\u011frenmesinde Normalization nedir? Ara\u015ft\u0131r\u0131n\u0131z. K\u0131saca tan\u0131mlay\u0131n\u0131z. Ne ama\u00e7la kullan\u0131ld\u0131\u011f\u0131n\u0131 a\u00e7\u0131klay\u0131n\u0131z. Bir normalizasyon kodu yazarak ne yapt\u0131\u011f\u0131n\u0131 anlat\u0131n\u0131z. \u0130lgili kaynaklara at\u0131f veriniz. (20 p)**\n","c32dc372":"**K\u00fct\u00fcphane Y\u00fckleme ve Veri Okuma**","f82306cf":"# SORU 3\n**Y\u00f6ntem Kodlama: \u0130ki farkl\u0131 s\u0131n\u0131fland\u0131r\u0131c\u0131 (MLP Classifier YSA, SVM, k-NN, Decision Tree, Random Forest \u2026) \/ tahminleyici \u2026 kullanarak s\u0131n\u0131fland\u0131rma \/ tahminleme \u2026 i\u015flemini yapan Python kodunu yaz\u0131n\u0131z. Rapora, se\u00e7ti\u011finiz y\u00f6ntemlerin isimlerini yaz\u0131n\u0131z ve kodu ekleyiniz (20)**","8e073160":"Bu grafikte ise cinsiyet \u00f6znitel\u011fine ba\u011fl\u0131 olarak hastal\u0131k bulunma de\u011ferlerini g\u00f6zlemledim.Bu veri \u00f6rnekleminden yola \u00e7\u0131karak \"Erkeklerin kad\u0131nlara oranla kalp rahats\u0131zl\u0131\u011f\u0131 olma durumu belirgin bir \u015fekilde fazla bulunuyor\" diyebiliriz","6035efef":"# SORU 1 Referans\nhttps:\/\/towardsai.net\/p\/data-science\/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.*italik *","c8066db0":"Son 3 bar grafi\u011finde asl\u0131nda yap\u0131lmak istenen hastal\u0131\u011f\u0131n farkl\u0131 kolonlardaki da\u011f\u0131l\u0131m\u0131n\u0131 analiz etmekti.ST segment de\u011ferine g\u00f6re,a\u00e7l\u0131k kan \u015fekerine g\u00f6re ve g\u00f6\u011f\u00fcsteki a\u011fr\u0131 tipine g\u00f6re kalp rahats\u0131zl\u0131\u011f\u0131 var m\u0131,yok mu ve varsa ne kadar oranda bulunuyor bunu anlamaya \u00e7al\u0131\u015ft\u0131m","0c0f6e30":"# **Y\u00f6ntem Kodlamalar\u0131n Kar\u015f\u0131la\u015ft\u0131r\u0131lmas\u0131**","f4ca197a":"Karma\u015f\u0131l\u0131k matrisi \u00e7\u0131kan 3 kodlamada da \n   * array[0][0] = True Negative\n   * array[0][1] = False Positive\n   * array[1][0] = False Negative\n   * array[1][1] = True Positive\n\nasl\u0131nda ula\u015f\u0131lmak istenen de\u011ferler \u015fu \u015fekilde olmal\u0131.Yani sat\u0131rlar asl\u0131nda ger\u00e7ek hasta olma durumunu 1 veya 0 olarak de\u011ferlendirirken,kolonlarda bunlar\u0131 ne kadar tahmin etti\u011fi ile alakal\u0131d\u0131r.Bu y\u00fczden \nTrue Positive = ger\u00e7ekten do\u011fru tahmin edilenler\nTrue Negative = ger\u00e7keten hasta olup,hasta olmad\u0131\u011f\u0131 te\u015fhis edilenler\nFalse Positive = ger\u00e7ekte hasta olmay\u0131p,hasta oldu\u011fu d\u00fc\u015f\u00fcnilenler\nFalse Negative = ger\u00e7ekte hasta olmay\u0131p hasta olmad\u0131\u011f\u0131 tahmin edilen \n\ninsanlar\u0131n karma\u015f\u0131l\u0131k matrisi bu de\u011ferlerden olu\u015fturur.\n\nRandom forest algoritmas\u0131nda ne kadar y\u00fcksek do\u011fruluk de\u011ferine ula\u015fsa da asl\u0131nda ger\u00e7e hastalar\u0131,hasta olmayarak tahmin eden 14 kayd\u0131 var ve bu onun yanl\u0131\u015f s\u0131n\u0131fland\u0131rd\u0131\u011f\u0131n\u0131 g\u00f6sterir.Bu algoritmada decision tree en iyi s\u0131n\u0131fland\u0131rma y\u00f6ntemini olu\u015fturuyor denebilir.Ama FP ve FN de\u011ferlerini k\u0131yaslarsak bu durum yine Random Forest algoritmas\u0131n\u0131n lehine ger\u00e7ekle\u015fen bir durum olur.Bu durumda da Random Forest bu veri k\u00fcmesi i\u00e7in en iyi s\u0131n\u0131fland\u0131rm sonucunu veren algoritmad\u0131r diyebiliriz.\n   ","0a75397c":"Ben bu not defterim i\u00e7erisinde DecisionTree ve RandomForest s\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131m\u0131 se\u00e7ece\u011fim.Bu iki algoritma sayesinde s\u0131n\u0131fland\u0131rmadan elde edilen do\u011fruluk de\u011ferlerini al\u0131p bunlar\u0131n oranlar\u0131n\u0131 ve ayn\u0131 zamanda confusion matrislerini g\u00f6rselle\u015ftirip inceleyece\u011fim.","a731db09":"Bu veri k\u00fcmesi asl\u0131nda 76 \u00f6zellik i\u00e7eriyor ama payla\u015f\u0131lan veri seti \u00fczerinde 14 \u00f6nemli kolonun kalp hastal\u0131\u011f\u0131 te\u015fhisi koymak i\u00e7in bask\u0131n ve yeterli oldu\u011fu d\u00fc\u015f\u00fcn\u00fcl\u00fcyor.\n\nE\u011fer gelen bir hastan\u0131n kalp rahats\u0131zl\u0131\u011f\u0131 varsa,buradaki ilgili \u00f6zelliklerin analizi ile veriyi modelleyip,uygun e\u011fitim ve test verilerinden ba\u015far\u0131lar elde etmeye \u00e7al\u0131\u015faca\u011f\u0131m.\nBu kodlarda baz\u0131 s\u0131n\u0131fland\u0131rma algoritmalar\u0131 kullan\u0131p,kalp rahats\u0131zl\u0131\u011f\u0131 te\u015fhisini do\u011fru de\u011ferlendirip,de\u011ferlendirmedi\u011fimi sonu\u00e7lara g\u00f6re anlayaca\u011f\u0131m.","47c60ce8":"Toplamda asl\u0131nda 3 farkl\u0131 algoritma \u00e7al\u0131\u015ft\u0131rd\u0131m.Logistic regresyon,random forest ve decision tree algoritmalar\u0131n\u0131 kulland\u0131m.Bu 3 algoritma aras\u0131ndan en iyi sonuca ula\u015fan RandomForest oldu.\n\n* Decision Tree Do\u011fruluk De\u011feri : 78.68852459016394\n* Random Forest Do\u011fruluk De\u011feri : 88.52%\n* Logistic Regression Do\u011fruluk De\u011feri 86.89% 'dir.\n\nBu e\u011fitilmi\u015f ve test edilmi\u015f do\u011fruluk de\u011ferlerinden,bu veri k\u00fcmesi i\u00e7in en iyi sonuca ula\u015fan Random Forest algoritmas\u0131d\u0131r.Y\u00fcksek oranda do\u011fruluk y\u00fczdesi ortaya \u00e7\u0131karm\u0131\u015f oldu\u011fu i\u00e7in en iyi sonucu verebilir diyebiliriz. \n","b48a464b":"**Dummy De\u011fi\u015fkenler Olu\u015fturma**","b211961b":"Ya\u015flara g\u00f6re kalp at\u0131\u015f h\u0131z\u0131 ile il\u015fkilendirilmi\u015f 2 boyutlu bir grafite 2 farkl\u0131 \u00f6znitelik ile beraber d\u00fc\u015f\u00fcn\u00fcldi\u011finde hasta olma durumunun 30'lu ya\u015flar\u0131n ba\u015f\u0131ndan 60'l\u0131 ya\u015flara g\u00f6re bask\u0131n d\u00fczeyde olu\u015ftu\u011fu g\u00f6r\u00fcl\u00fcyor.Yine de rahats\u0131zl\u0131k 70 ya\u015f\u0131ndan uzun hasta kay\u0131tlar\u0131nda da seyredebiliyor.Hasta olmama durumu ise genellikle 50 ile 70 ya\u015flar\u0131 aras\u0131nda daha \u00e7ok gruplanm\u0131\u015f gibi g\u00f6r\u00fcn\u00fcyor","34514be2":"**Logistic Regresyon \u0130\u00e7in Model Olu\u015fturma**","0b7d1d3d":"# **Kalp Hastal\u0131klar\u0131 S\u0131n\u0131fland\u0131r\u0131lmas\u0131**","32ac0172":"# Not defterimde veri normalizasyonu ad\u0131 alt\u0131nda bu veri k\u00fcmesine ait kodlar\u0131m\u0131 bulabilirsiniz.","89ebcb2c":"# SORU 2\n**2) Problem ve Veri Seti (20 p)\n\nPython scikit-learn k\u00fct\u00fcphanesini kullanarak bir makine \u00f6\u011frenmesi uygulamas\u0131 yaz\u0131n\u0131z. S\u0131n\u0131fland\u0131rma ve tahminleme konular\u0131ndan istedi\u011finiz birisini tercih edebilirsiniz. Alanda deneyiminiz yoksa s\u0131n\u0131fland\u0131rma konusunu se\u00e7menizi \u00f6neririm.\n\nUCI Machine Learning Repository: https:\/\/archive.ics.uci.edu\/ml\/datasets.html\nhttps:\/\/machinelearningmastery.com\/standard-machine-learning-datasets\/ \nhttps:\/\/towardsdatascience.com\/top-sources-for-machine-learning-datasets-bb6d0dc3378b\nThe 50 Best Public Datasets for Machine Learning:\nhttps:\/\/medium.com\/datadriveninvestor\/the-50-best-public-datasets-for-machine-learning-d80e9f030279\nba\u011flant\u0131lar\u0131ndaki veri setlerinden derste anlat\u0131landan (Zambak) farkl\u0131 herhangi birisini tercih edebilirsiniz. Dileyenler kendileri de veriseti olu\u015fturabilirler.\n\nSe\u00e7ti\u011finiz problemi tan\u0131mlay\u0131n\u0131z (otomobillerin \u00f6zelliklerine g\u00f6re \u00e7ok iyi, iyi, orta, k\u00f6t\u00fc olarak etiketlenmesi\u2026 gibi). Probleminiz hangi makine \u00f6\u011frenmesi paradigmas\u0131 (s\u0131n\u0131fland\u0131rma, k\u00fcmeleme, di\u011fer) kullan\u0131larak \u00e7\u00f6z\u00fclebilecektir? Belirtiniz. \n\nVerisetini inceleyip \u00f6zet bilgileri rapora yaz\u0131n\u0131z: Veri (\u00f6rnek) say\u0131s\u0131n\u0131, \u00f6znitelik (girdi) say\u0131s\u0131n\u0131, \u00f6zniteliklerin neler oldu\u011funu, s\u0131n\u0131f say\u0131s\u0131n\u0131 ve s\u0131n\u0131flar\u0131n neler oldu\u011funu rapora yaz\u0131n\u0131z. \u00d6rnek: Araba s\u0131n\u0131fland\u0131rmas\u0131 uygulamas\u0131 i\u00e7in UCI ML Repository Data Folder\u2019dan Car Evaluation veriseti -> 6 adet feature \u2013 \u00f6znitelik ve 4 adet kategori s\u0131n\u0131f i\u00e7eriyor : https:\/\/archive.ics.uci.edu\/ml\/datasets\/Car%20Evaluation**\n","c9847428":"Normalle\u015ftirmenin as\u0131l amac\u0131 veri k\u00fcmesi i\u00e7erisindeki say\u0131sal s\u00fcrunlar\u0131n de\u011ferlerini,de\u011fer aral\u0131klar\u0131ndaki farkl\u0131l\u0131klar\u0131 bozmadan ortak bir \u00f6l\u00e7e\u011fe d\u00f6n\u00fc\u015ft\u00fcrmektir.Makine \u00f6\u011frenimi i\u00e7in her veri seti normalizasyon gerektirmez.E\u011fer kullan\u0131lan \u00f6zellikler farkl\u0131ysa normalle\u015ftirme uygun olabilir.\n\nBu veri k\u00fcmesinden farkl\u0131 olarak bir analoji yapmak gerkirse,normalizasyonu veri bilimi i\u00e7erisinden anlatmak \u015fu \u015fekilde iyi olabilir.Biz insan kaynaklar\u0131 y\u00f6neticisi olal\u0131m ve elimizin alt\u0131nda tahmin edemeyece\u011fimiz kadar \u00e7al\u0131\u015fan ve bunlara ait ki\u015fisel ve maddi \u00f6zellikler bulunsun.Bu veri k\u00fcmesi i\u00e7erisinde hem ya\u015f hem de maa\u015f bilgilerimizin tutuldu\u011funu d\u00fc\u015f\u00fcn\u00fcrsek.Ya\u015f\u0131 k\u00fc\u00e7\u00fck ama pozisyon olarak y\u00fckse birinin maa\u015f\u0131n\u0131n ya\u015f\u0131 b\u00fcy\u00fck olan bir bireyden daha y\u00fcksek miktarda olmas\u0131 beklenebilir hatta bu durumun tersi de olabilir.Mesela ya\u015f aral\u0131\u011f\u0131 20-50 aras\u0131ndayken,maas bilgileri 2.000 ile 25.000 aras\u0131nda olabilir.Veri k\u00fcmesi i\u00e7erinde outlierlar\u0131n olmas\u0131 ka\u00e7\u0131n\u0131lmazd\u0131r.Bu nedenle daha sa\u011fl\u0131kl\u0131 sonu\u00e7lara eri\u015febilmek i\u00e7in t\u00fcm de\u011fi\u015fkenleri ayn\u0131 de\u011fer aral\u0131\u011f\u0131na \u00e7ekmek i\u00e7in normalizasyon kullan\u0131yoruz ve b\u00f6ylece daha sa\u011fl\u0131kl\u0131 analizler,modellemeler yapabilmek m\u00fcmk\u00fcn hale geliyor.","30163842":"Sonu\u00e7 kolonuna g\u00f6re hasta olup olmad\u0131lar\u0131n\u0131n ortalama de\u011ferleri her bir kolon i\u00e7in ayr\u0131 ayr\u0131 gruplan\u0131yor","315ab61c":"Bu yukar\u0131daki veri k\u00fcmesinin bir par\u00e7as\u0131 oldu\u011fu gibi olonlar \u00f6nceden de bahsedildi\u011fi gibi kalp hastal\u0131\u011f\u0131 s\u0131n\u0131fland\u0131rmas\u0131nda do\u011frudan birbirleriyle ili\u015fkili 14 kolon bulunmaktad\u0131r.Target kolonu bize asl\u0131nda rahats\u0131zl\u0131\u011f\u0131n var olupolmad\u0131\u011f\u0131n\u0131 s\u00f6yleyecektir\n\n\n","748f75a1":"**Sklearn K\u00fct\u00fcphanesi \u0130le Mant\u0131ksal Regresyon Uygulanarak Test Do\u011fruluk Oran\u0131 Hesaplama**\n","8f07e814":"Se\u00e7ti\u011fim probleme ba\u011fl\u0131 olan veri k\u00fcmesindeki kolonlar ve a\u00e7\u0131klamalar\u0131;\n\n* age -> ya\u015flar\n* sex -> cinsiyetler(erkek=1,kad\u0131n=0)\n* cp -> chest pain type - g\u00f6\u011f\u00fcs a\u011fr\u0131 tipi\n* trestbps -> resting blood pressure - istirahat tansiyonu\n* chol -> serum cholestoral in mg\/dl - mg\/dl cinsinden serum kolestrol\n* fbs -> fasting blood sugar > 120 mg\/dl\n* restecg -> resting electrocardiographic results (values 0,1,2) - a\u00e7l\u0131k kan \u015fekeri (varsa 1, yoksa 0)\n* thalach -> maximum heart rate achieved - istirahat halindeki elektrokardiyografik sonu\u00e7lar\n* exang -> exercise induced angina - egzersize ba\u011fl\u0131 anjin (varsa 1,yosa 0)\n* oldpeak ->ST depression induced by exercise relative to rest - Dinlenmeye ba\u011fl\u0131 egzersizin neden oldu\u011fu ST depreyonu\n* slope -> the slope of the peak exercise ST segment - ST segmentinin e\u011fitinin tepe noktas\u0131 e\u011fimi\n* ca -> number of major vessels (0-3) colored by flourosopy - florosopi ile renklendirilmi\u015f ana damarlar\u0131n tal say\u0131s\u0131 0 ile 3 aras\u0131nda veri al\u0131yor.\n* thal -> thal: 3 = normal; 6 = fixed defect; 7 = reversable defect - 3 normal,6 sabit kusut,7 tersine \u00e7evirilebilinir mi diye s\u0131n\u0131flan\u0131r\u0131lm\u0131\u015f bir usur olup olmad\u0131\u011f\u0131 ile ili\u015fkili.\n* target -> 1 veya 0 - sonu\u00e7 e\u011fer kalp rahats\u0131zl\u0131\u011f\u0131 varsa 1,yoksa 0 diye veri k\u00fcmesine girilmi\u015f.\n\n\n\n\n","2d037bc8":"Toplamda 303 sat\u0131r i\u00e7erisinden y\u00fczde 31'lik dilimde kad\u0131n hasta, 68% oran\u0131nda da erkek hasta oldu\u011funu s\u00f6yl\u00fcyor","35a81b25":"Burada da cinsiyete g\u00f6re hastal\u0131\u011f\u0131n var olup olmad\u0131\u011f\u0131n\u0131 g\u00f6rselle\u015ftirdim. Kad\u0131nlarda(Xlabeldaki 0 de\u011ferine bak\u0131yorum) kalp hastal\u0131\u011f\u0131 olanlar olmayanlardan olduk\u00e7a fazla.\nErkeklerde (xlabelda 1 olan de\u011fere bak\u0131yorum) kalp hastal\u0131\u011f\u0131 olmayanalr\u0131n say\u0131s\u0131 olanlardan daha y\u00fcksek","7775062f":"Bu k\u00fc\u00e7\u00fck hesaplama ile toplam hasta kay\u0131t bilgisi \u00fczerinden sa\u011fl\u0131kl\u0131 veya hasta bulunma y\u00fczdelik de\u011ferleri hesapland\u0131 elimdeki \u00f6rneklem i\u00e7erisinde bulunan hastalar\u0131n %54'\u00fc kalp hastas\u0131,%45'inde ise kalp hastal\u0131\u011f\u0131 bulunmamaktad\u0131r.","9a1d98e4":"# Karma\u015f\u0131kl\u0131k Matrisi Ve De\u011fer K\u0131yaslamas\u0131 - Confusion Matrisi"}}