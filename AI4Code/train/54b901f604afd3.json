{"cell_type":{"a9ccf808":"code","581620e2":"code","e0e4eced":"code","81570fb8":"code","4de0ecca":"code","11c79ffe":"code","578f10bf":"code","7e0a9f00":"code","9c653f8f":"code","56eb3cde":"code","51f5f1c8":"code","a7749ac9":"code","b80dfff6":"code","e0192af1":"code","caac9263":"code","ae64d1c9":"code","2a637c61":"code","dfcd7ccf":"code","72d9b297":"code","35c827cd":"code","f0d53d39":"code","45a89fa4":"code","8cce3c9c":"code","c2978a26":"code","85868530":"code","3f6b6f82":"code","215e1bed":"code","d6e75816":"code","0f74a526":"code","a86f8127":"code","2289be00":"code","a77ee120":"code","b86ee0c2":"code","bf860db9":"code","0ccc02bd":"code","fae381d2":"code","1e7d5d0f":"code","be28f7ab":"code","22eab4b4":"code","cac1c5da":"code","8aa7d3ac":"code","6ebac9b5":"code","642576c8":"code","a3137093":"code","0f255aab":"code","02bb84ca":"code","08cf2ccb":"code","dfc4645a":"code","cea34ea2":"code","21717957":"code","611f65e6":"code","ef4e1d09":"code","244850d3":"code","7c544f29":"code","6c1211b7":"code","b8c09ddd":"code","7155563f":"code","0ae4cba1":"code","455fb6be":"code","69fc4bda":"code","85017114":"code","a0ecf24d":"code","ae635577":"code","55260857":"code","ee267e5a":"code","c78084fe":"code","d2ef315c":"code","c85ba744":"code","7f80dd9c":"code","cbdceb2b":"code","4944b689":"code","7dc41765":"code","60a1198c":"code","00d8ec78":"code","4d87a6da":"code","36f030a2":"code","332a3d9f":"code","024b485d":"code","8e189a98":"code","2886293f":"code","e92b50b7":"code","9567efd7":"code","bce2c70a":"code","b059945c":"code","7fec1d3c":"code","ffc41733":"markdown","ae183f08":"markdown","1062392f":"markdown","cd196f80":"markdown","5229f228":"markdown","b8bd2de1":"markdown","d395d6a0":"markdown","b8768b39":"markdown","b97d3a0f":"markdown","b6f6ee1e":"markdown","e39a9243":"markdown","8dd5b0b5":"markdown","d6e17d26":"markdown","a327e4f3":"markdown"},"source":{"a9ccf808":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport cv2\nimport tensorflow as tf\nimport pydicom\nfrom math import ceil, floor\nfrom copy import deepcopy\nfrom tqdm.notebook import tqdm\nfrom imgaug import augmenters as iaa\nfrom sklearn.utils import shuffle\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC, Recall, Precision, BinaryCrossentropy\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.layers import *\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom prettytable import PrettyTable\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport seaborn as sns\n\n\n\ndef correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n    img_min = window_center - window_width \/\/ 2\n    img_max = window_center + window_width \/\/ 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    brain_img = (brain_img - 0) \/ 80\n    subdural_img = (subdural_img - (-20)) \/ 200\n    soft_img = window_image(dcm, 40, 380)\n    soft_img = (soft_img - (-150)) \/ 380\n    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n    return bsb_img\n\n\n\n\n\ndef calculating_class_weights(y_true):    #  input : true labels  \n                                        # output : weights of each class\n    number_dim = np.shape(y_true)[1]\n    weights = np.empty([number_dim, 2])\n    for i in range(number_dim):\n        weights[i] = compute_class_weight('balanced', classes=np.unique(y_true[:, i]), y=y_true[:, i])\n    return weights\n\n\ndef _read(path, SHAPE):        # input : path of specific image and the shape that we want convert image to.\n                              # output : readed image\/255\n    img = cv2.imread(path)\n    img = cv2.resize(img, dsize=(256, 256))\n    return img\/255.0\n\ndef _read_dicom(path, SHAPE):        # input : the path of dicom image and its shape.\n                                  # output : image in numpy format.\n    dcm = pydicom.dcmread(path)\n    try:\n        img = bsb_window(dcm)\n    except:\n        img = np.zeros(SHAPE)\n    return img\n\n# Image Augmentation\nsometimes = lambda aug: iaa.Sometimes(0.25, aug)\n\naugmentation = iaa.Sequential([ iaa.Fliplr(0.25),\n                                iaa.Flipud(0.10),\n                                sometimes(iaa.Crop(px=(0, 25), keep_size = True, sample_independently = False))   \n                            ], random_order = True)       \n        \n# Generators\nclass TrainDataGenerator(keras.utils.Sequence):\n    def __init__(self, dataset, class_names, batch_size = 16, img_size = (256, 256, 3), \n                 augment = False, shuffle = True, *args, **kwargs):            # initialize datagenerator\n        self.dataset = dataset\n        self.ids = self.dataset['imgfile'].values\n        self.labels = self.dataset[class_names].values\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.augment = augment\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):        # size of datagenerator (number of batchs)\n        return int(ceil(len(self.ids) \/ self.batch_size))\n\n    def __getitem__(self, index):          # input : index of a batch\n                                    # output : specific batch with input index\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X, Y = self.__data_generation(indices)\n        return X, Y\n\n    def augmentor(self, image):        # input : image\n                                 # output : augmented image\n        augment_img = augmentation        \n        image_aug = augment_img.augment_image(image)\n        return image_aug\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.ids))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n    def __data_generation(self, indices):        # creating augmented images and their labels.\n                                          # input : \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n                                          # output : augmented images and their labels.\n        X = np.empty((self.batch_size, *self.img_size))\n        Y = np.empty((self.batch_size, len(class_names)), dtype=np.float32)\n        \n        for i, index in enumerate(indices):\n            ID = self.ids[index]\n#             image = _read(ID, self.img_size)\n            if '.png' not in ID:\n                image = _read_dicom('..\/input\/rsna-intracranial-hemorrhage-detection\/rsna-intracranial-hemorrhage-detection\/stage_2_train\/'+ID+'.dcm', self.img_size)\n            else:\n## just CQ500\n\n                if 'NonHemo' in ID:\n                        image = _read('..\/input\/cq500-normal-images-and-labels\/'+ID, self.img_size)\n                else:\n                        if 'content' in ID:\n                            ID = ID[9:]\n                        \n                        image = _read('..\/input\/rsna-cq500-abnormal-data\/'+ID, self.img_size)\n                        \n            if self.augment:\n                X[i,] = self.augmentor(image)\n            else:\n                X[i,] = image\n            Y[i,] = self.labels[index]        \n        return X, Y\n\ndef ModelCheckpointFull(model_name):        # save weights of the model that has the best result.\n    return ModelCheckpoint(model_name, \n                            monitor = 'val_loss', \n                            verbose = 1, \n                            save_best_only = True, \n                            save_weights_only = True, \n                            mode = 'min', \n                            period = 1)\n\n# Create Model\ndef create_model(num_classes):        # input : num of classes\n                               # output : pretrained densenet121 to classify num_classes classes.\n    K.clear_session()\n    \n    input_shape = (256, 256, 3)\n    img_input = Input(shape=input_shape)\n    base_model = DenseNet121(\n        include_top=False,\n        input_tensor=img_input,\n        input_shape=input_shape,\n        weights='imagenet',\n        pooling=\"avg\"\n    )\n    x = base_model.output\n    x = Dropout(0.15)(x)\n    predictions = Dense(num_classes, activation='sigmoid', name=\"new_predictions\")(x)\n    model = Model(inputs=img_input, outputs=predictions)\n\n    return model\n\ndef metrics_define(num_classes):\n    metrics_all = ['accuracy',\n    AUC(curve='PR',multi_label=True,name='auc_pr'),\n    AUC(multi_label=True, name='auc_roc'),\n    Recall(),\n    Precision(),\n    BinaryCrossentropy(name='bi_crent')\n    ]\n\n    return metrics_all\n\ndef get_weighted_loss(weights):        # input : weights of classes\n                                   # output : loss (weighted loss)\n    def weighted_loss(y_true, y_pred):\n        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n    return weighted_loss\n\n\ndef print_metrics_table(y_true, y_hat, y_pred, class_names):         # input : true labels, predicted labels, array of class names, y hat \n                                                             # output : a table of results (roc_auc_score, precision_score, f1_score, recall_xcore, accuracy_score)\n    myTable = PrettyTable([\"Class Name\", \"ROC_AUC\", \"Precsion\", \"Recall\", \"F1_Score\", \"Accuracy\"])\n\n    for i in range(len(class_names)) :\n        \n        myTable.add_row([class_names[i], \"%.4f\" % roc_auc_score(y_true[:, i], y_hat[:, i]),\n                        \"%.4f\" % precision_score(y_true[:, i], y_pred[:, i]), \"%.4f\" % recall_score(y_true[:, i], y_pred[:, i]),\n                        \"%.4f\" % f1_score(y_true[:, i], y_pred[:, i]), \"%.4f\" % accuracy_score(y_true[:, i], y_pred[:, i])\n                        ])\n\n    myTable.add_row(['Average', \"%.4f\" % roc_auc_score(y_true, y_hat),\n                    \"%.4f\" % precision_score(y_true, y_pred, average='macro'), \"%.4f\" % recall_score(y_true, y_pred, average='macro'),\n                    \"%.4f\" % f1_score(y_true, y_pred, average='macro'), \"%.4f\" % accuracy_score(y_true, y_pred)\n                    ])\n    print(myTable)\n\ndef print_precision_recall_curves(y_true, y_hat, y_pred, class_names):   # input : true labels, predicted labels, array of class names, y hat \n                                                                        # print precision and recall curves\n        # For each class\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n    for i in range(len(class_names)):\n        precision[i], recall[i], _ = precision_recall_curve(y_true[:, i],\n                                                            y_hat[:, i])\n        average_precision[i] = average_precision_score(y_true[:, i], y_hat[:, i])\n\n    # A \"micro-average\": quantifying score on all classes jointly\n    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true.ravel(),\n        y_hat.ravel())\n    average_precision[\"micro\"] = average_precision_score(y_true, y_hat,\n                                                        average=\"micro\")\n    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n        .format(average_precision[\"micro\"]))\n    plt.figure()\n    plt.step(recall['micro'], precision['micro'], where='post')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title(\n        'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n        .format(average_precision[\"micro\"]))\n    plt.show()\n    for i in range(len(class_names)):\n        plt.figure()\n        plt.plot(recall[i], precision[i], label='Precision-recall for class {0} (area = {1:0.2f})'.format(i, average_precision[i]))\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.title('Precision-Recall Curve for Class {}'.format(class_names[i]))\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\ndef print_auc_curves(y_true, y_hat, y_pred, class_names):    # input : true labels, predicted labels, array of class names, y hat \n                                                           # print auc curves\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    roc_auc_sc = dict()\n    for i in range(len(class_names)):\n        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_hat[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n        roc_auc_sc[i] = roc_auc_score(y_true[:, i], y_hat[:, i])\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_hat.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    for i in range(len(class_names)):\n        plt.figure()\n        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic for class {}'.format(class_names[i]))\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\ndef print_confusion_matrix(y_true, y_hat, y_pred, class_names):        # input : true labels, predicted labels, array of class names, y hat \n                                                                # print confusion matrixes.\n    print(multilabel_confusion_matrix(y_true, y_pred))\n\ndef print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names):    # input : true labels, predicted labels, array of class names, y hat\n                                                                  # print confusion matrix plots.\n    confusion = multilabel_confusion_matrix(y_true, y_pred)\n\n    # Plot confusion matrix \n    fig = plt.figure(figsize = (14, 8))\n    for i, (label, matrix) in enumerate(zip(class_names[0:6], confusion[0:6])):\n        plt.subplot(f'23{i+1}')\n        labels = [f'not_{label}', label]\n        cm = matrix.astype('float') \/ matrix.sum(axis=1)[:, np.newaxis]\n        sns.heatmap(cm, annot = True, square = True, cbar = False, cmap = 'Blues', \n                    xticklabels = labels, yticklabels = labels, linecolor = 'black', linewidth = 1)\n        plt.title(labels[0])\n\n    plt.tight_layout()\n    plt.show()","581620e2":"train_df = pd.read_csv('..\/input\/kfold-splits-rsna-cq500\/Train_f4.csv')\nval_df = pd.read_csv('..\/input\/kfold-splits-rsna-cq500\/Validation_f4.csv')\ntrain_df = pd.DataFrame( train_df.loc[i][2:] for i in range(0, len(train_df)) if 'CQ500' in train_df.loc[i]['imgfile']  )    # just for CQ500 images.\nval_df = pd.DataFrame( val_df.loc[i][2:] for i in range(0, len(val_df)) if 'CQ500' in val_df.loc[i]['imgfile']  ) \n","e0e4eced":"train_df","81570fb8":"val_df","4de0ecca":"train_df['normal']=0   # add normal label to dataframes\nval_df['normal']=0","11c79ffe":"train_df","578f10bf":"\ntrain_df1 = pd.read_csv('..\/input\/cq500-normal-images-and-labels\/NormalAbnormal\/NormalAbnormal\/CQ500\/Train_f1.csv')\ntrain_df1 = pd.DataFrame( train_df1.loc[i][1:] for i in range(0, len(train_df1))   ) \nabnormal1 = train_df1.loc[train_df1['Abnormal']==1]\n\ntrain_df1 = shuffle(train_df1)\nval_df1 = pd.read_csv('..\/input\/cq500-normal-images-and-labels\/NormalAbnormal\/NormalAbnormal\/CQ500\/Validation_f1.csv')\nval_df1 = pd.DataFrame( val_df1.loc[i][1:] for i in range(0, len(val_df1))   ) ","7e0a9f00":"train_df1","9c653f8f":"val_df1","56eb3cde":"train_df2 = pd.DataFrame( train_df1.loc[i][:1] for i in range(0, 8000) if train_df1.loc[i]['Normal'].all()==True  ) \nval_df2= pd.DataFrame( val_df1.loc[i][:1] for i in range(0, 4000) if val_df1.loc[i]['Normal'].all()==True )  ","51f5f1c8":"train_df2['epidural']=0      # assign 0 to other classes.\ntrain_df2['intraparenchymal']=0\ntrain_df2['intraventricular']=0\t\ntrain_df2['subarachnoid']=0\t\ntrain_df2['subdural']=0\ntrain_df2['normal']=1\ntrain_df2.rename(columns={'Normal': 'normal'}, inplace=True)\n\n\nval_df2['epidural']=0\nval_df2['intraparenchymal']=0\nval_df2['intraventricular']=0\t\nval_df2['subarachnoid']=0\t\nval_df2['subdural']=0\nval_df2['normal']=1\nval_df2.rename(columns={'Normal': 'normal'}, inplace=True)","a7749ac9":"train_df2","b80dfff6":"frames = [train_df, train_df2]\ntrain_df = pd.concat(frames, ignore_index=True)\ntrain_df=shuffle(train_df)","e0192af1":"frames = [val_df, val_df2]\nval_df = pd.concat(frames, ignore_index=True)\nval_df=shuffle(val_df)","caac9263":"val_df","ae64d1c9":"train_df","2a637c61":"\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural','normal']\n\nweights = calculating_class_weights((train_df[class_names].values).astype(np.float32))\nprint(weights)\n\ndata_generator_train = TrainDataGenerator(train_df,\n                                          class_names,\n                                          TRAIN_BATCH_SIZE,\n                                          SHAPE,\n                                          augment = True,\n                                          shuffle = True)\ndata_generator_val = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = True\n                                        )\n\nTRAIN_STEPS = int(len(data_generator_train)\/10)\nprint(TRAIN_STEPS)\nVal_STEPS = int(len(data_generator_val)\/10)\nprint(Val_STEPS)\nLR = 5e-6\n\n","dfcd7ccf":"plt.imshow(data_generator_val[1][0][0])","72d9b297":"Metrics = metrics_define(len(class_names))\n\nmodel = create_model(len(class_names))   \n\n\nfrom keras.models import Model\n\nmodel.summary()\n","35c827cd":"\nmodel.compile(optimizer = Adam(learning_rate = LR),\n              loss = get_weighted_loss(weights),\n              metrics = Metrics)","f0d53d39":"history = model.fit(data_generator_train,\n                    validation_data = data_generator_val,\n                    validation_steps = Val_STEPS,\n                    steps_per_epoch = TRAIN_STEPS,\n                    epochs = 100,\n                    callbacks = [ModelCheckpointFull('model_all_densenet_fold4_andNormal.h5')],\n                    verbose = 1, workers=4\n                    )","45a89fa4":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","8cce3c9c":"plt.plot(history.history['auc_pr'])\nplt.plot(history.history['val_auc_pr'])\nplt.title('model auc_precision')\nplt.ylabel('auc_pr')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","c2978a26":"model.load_weights('model_all_densenet_fold4_andNormal.h5')","85868530":"\n\nprint(len(val_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'normal']\ndata_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\ny_true = val_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","3f6b6f82":"val_df","215e1bed":"print_metrics_table(y_true, y_hat, y_pred, class_names)","d6e75816":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","0f74a526":"print_auc_curves(y_true, y_hat, y_pred, class_names)","a86f8127":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","2289be00":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","a77ee120":"val_df2= pd.DataFrame( val_df1.loc[i][:1] for i in range(4000, 8000) if val_df1.loc[i]['Normal'].all()==True )  ","b86ee0c2":"\nval_df2['epidural']=0\nval_df2['intraparenchymal']=0\nval_df2['intraventricular']=0\t\nval_df2['subarachnoid']=0\t\nval_df2['subdural']=0\nval_df2['normal']=1\nval_df2.rename(columns={'Normal': 'normal'}, inplace=True)","bf860db9":"val_df = pd.read_csv('..\/input\/kfold-splits-rsna-cq500\/CQ500_Validation_f0.csv')\nval_df = pd.DataFrame( val_df.loc[i][1:] for i in range(0, len(val_df)) if 'CQ500' in val_df.loc[i]['imgfile']  ) \n\nframes = [val_df, val_df2]\nval_df = pd.concat(frames, ignore_index=True)\nval_df=shuffle(val_df)\n\nval_df['normal']=0\nprint(len(val_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'normal']\ndata_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\n\ny_true = val_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","0ccc02bd":"val_df","fae381d2":"# print_metrics_table(y_true, y_hat, y_pred, class_names)","1e7d5d0f":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","be28f7ab":"# print_auc_curves(y_true, y_hat, y_pred, class_names)","22eab4b4":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","cac1c5da":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","8aa7d3ac":"val_df = pd.read_csv('..\/input\/cq500-normal-images-and-labels\/NormalAbnormal\/NormalAbnormal\/CQ500\/Validation_f3.csv')\n\nval_df = pd.DataFrame( val_df.loc[i][1:2] for i in range(0, len(val_df)) if val_df.loc[i]['Normal'].all()==True)\n                         \nval_df['epidural']=0\nval_df['intraparenchymal']=0\nval_df['intraventricular']=0\t\nval_df['subarachnoid']=0\t\nval_df['subdural']=0\nval_df['normal']=1\n","6ebac9b5":"\n\nprint(len(val_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'normal']\ndata_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\n\ny_true = val_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","642576c8":"val_df","a3137093":"# print_metrics_table(y_true, y_hat, y_pred, class_names)","0f255aab":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","02bb84ca":"# print_auc_curves(y_true, y_hat, y_pred, class_names)","08cf2ccb":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","dfc4645a":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","cea34ea2":"model = create_model(6)\nmodel.load_weights('.\/model_all_densenet_fold4_andNormal.h5')","21717957":"model.summary()","611f65e6":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","ef4e1d09":"model_builder = model\nimg_size = (256, 256)\n\ndecode_predictions = keras.applications.mobilenet.decode_predictions\n\nlast_conv_layer_name = \"conv5_block16_concat\"","244850d3":"def get_img_array(img_path, size):\n    \n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    \n    array = keras.preprocessing.image.img_to_array(img)\n    \n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    \n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    \n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    \n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    \n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n   \n    heatmap = tf.maximum(heatmap, 0) \/ tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","7c544f29":"val_df = pd.read_csv('..\/input\/kfold-splits-rsna-cq500\/Validation_f4.csv')\nval_df = pd.DataFrame( val_df.loc[i][2:] for i in range(0, len(val_df)) if 'CQ500' in val_df.loc[i]['imgfile']  ) \nval_df['normal']=0\n\nval_df2= pd.DataFrame( val_df1.loc[i][:1] for i in range(0, 4000) if val_df1.loc[i]['Normal'].all()==True )\nval_df2['epidural']=0\nval_df2['intraparenchymal']=0\nval_df2['intraventricular']=0\t\nval_df2['subarachnoid']=0\t\nval_df2['subdural']=0\nval_df2['normal']=1\nval_df2.rename(columns={'Normal': 'normal'}, inplace=True)\n\nframes = [val_df, val_df2]\nval_df = pd.concat(frames, ignore_index=True)\nval_df=shuffle(val_df)\n\nval_df\n\n\n\n\n","6c1211b7":"data_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )","b8c09ddd":"plt.imshow(data_generator_test[1][0][0])\nplt.savefig( \"ok.jpg\")","7155563f":"img_array= data_generator_test[1][0][0]\nimg_array=img_array.reshape(1,256,256,3)\nnp.shape(img_array)","0ae4cba1":"preds = model.predict(img_array)\n\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","455fb6be":"def save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n \n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    display(Image(cam_path))\n\n\nsave_and_display_gradcam(img_array[0]*255, heatmap)","69fc4bda":"plt.imshow(data_generator_test[1][0][1])","85017114":"!mkdir 0\n!mkdir 1\n!mkdir 2\n!mkdir 3\n!mkdir 4\n!mkdir 5","a0ecf24d":"!rm -r 0\n!rm -r 1\n!rm -r 2\n!rm -r 3\n!rm -r 4\n!rm -r 5","ae635577":"import os\nh=0\nfor i in range(0,10):\n    for j in range (0,64):\n        x = data_generator_test[i][0][j]\n        x = x.reshape(1,256,256,3)\n        np.shape(x)\n        \n        h+=1\n        preds = model.predict(x)\n        heatmap = make_gradcam_heatmap(x, model, last_conv_layer_name)\n        p=os.path.join(\".\/\", str(np.argmax(preds)))\n        if len(os.listdir(p)) < 21: \n            save_and_display_gradcam(x[0]*255, heatmap, str(np.argmax(preds))+\"\/\"+\"cam_\"+str(len(os.listdir(p)))+\".jpg\")\n            print(\"--- \"+str(np.argmax(preds))+\" :  \"+ str(len(os.listdir(p))))\n            ","55260857":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 3\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"0\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 0\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","ee267e5a":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"1\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 1\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","c78084fe":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"2\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 2\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","d2ef315c":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"3\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 3\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","c85ba744":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"4\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 4\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","7f80dd9c":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"5\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 5\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","cbdceb2b":"rsna_df=pd.read_csv('..\/input\/kfold-splits-rsna-cq500\/RSNA_Validation_f2.csv')","4944b689":"rsna_df=pd.DataFrame(rsna_df.loc[i][1:] for i in range(0,len(rsna_df)) )","7dc41765":"rsna_df","60a1198c":"rsna_df2=pd.read_csv('..\/input\/cq500-normal-images-and-labels\/NormalAbnormal\/NormalAbnormal\/RSNA\/Validation_f2.csv')","00d8ec78":"rsna_df2","4d87a6da":"rsna_df2=pd.DataFrame(rsna_df2.loc[i][1:2] for i in range(0,len(rsna_df2)) if rsna_df2.loc[i]['Normal'].all()==True)\nrsna_df2['epidural']=0\nrsna_df2['intraparenchymal']=0\nrsna_df2['intraventricular']=0\t\nrsna_df2['subarachnoid']=0\t\nrsna_df2['subdural']=0\nrsna_df2['normal']=1\n\nrsna_df2","36f030a2":"rsna_df['normal']=0\n\nframes = [rsna_df, rsna_df2]\nrsna_df = pd.concat(frames, ignore_index=True)\nrsna_df=shuffle(rsna_df)","332a3d9f":"rsna_df","024b485d":"\n\nprint(len(rsna_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural','normal']\ndata_generator_test = TrainDataGenerator(rsna_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\n\ny_true = rsna_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","8e189a98":"plt.imshow(data_generator_test[5][0][1])","2886293f":"(data_generator_test[6][0][0])","e92b50b7":"print_metrics_table(y_true, y_hat, y_pred, class_names)","9567efd7":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","bce2c70a":"print_auc_curves(y_true, y_hat, y_pred, class_names)","b059945c":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","7fec1d3c":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","ffc41733":"make dataframes for normal images.","ae183f08":"test model on Normal dataset\n","1062392f":"add normal data to rsna dataframe","cd196f80":"fit model","5229f228":"results for testing on rsna dataframe","b8bd2de1":"creating data generator for training the model.","d395d6a0":"test another dataset","b8768b39":"concate 2 dataframes and creating a dataframe for all classes.","b97d3a0f":"test on RSNA dataset","b6f6ee1e":"creating train and validation dataframes on fold 4","e39a9243":"Grad Cam","8dd5b0b5":"results","d6e17d26":"Model","a327e4f3":"validate the model"}}