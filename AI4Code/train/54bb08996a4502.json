{"cell_type":{"82f0919e":"code","d1ef7949":"code","d08bba49":"code","b9a2d19b":"code","354ce4e1":"code","025460e2":"code","5728b7f4":"code","874c29d6":"code","50327595":"code","8317553e":"code","6447686d":"code","9cd4fded":"code","5f3b8698":"code","d8ddc5a9":"code","0425c84f":"code","b2cc9382":"markdown","0cdece20":"markdown","38932d0d":"markdown","ab6d0744":"markdown","7978f779":"markdown","f8753e77":"markdown","8060249a":"markdown","6a5feed2":"markdown","3aeaa813":"markdown","d40e6dc3":"markdown","7baf2f8c":"markdown","ebc72655":"markdown","cc92ed0c":"markdown","ab50b613":"markdown","d6ee9e08":"markdown"},"source":{"82f0919e":"# het eerste wat gedaan wordt is de libraries inladen\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\n\nfrom keras.preprocessing import image\n# voor het model\nfrom keras.applications import VGG16\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import Flatten, Dense, Dropout\nfrom keras.layers import Conv2D, MaxPool2D, GlobalMaxPooling2D\n\nfrom keras import optimizers\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom keras import regularizers\n\nseed=123\nrandom.seed(seed)\n","d1ef7949":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\nimport tensorflow as tf \n\nif tf.test.gpu_device_name(): \n    print('\\n\\nDefault GPU Device:{}'.format(tf.test.gpu_device_name()))\nelse:\n   print(\"Please install GPU version of TF\")","d08bba49":"# hier krijg je 2 lijsten met de locaties van de foto's en een locatie met de 5 categorie namen\nfiles = glob.glob('..\/input\/kunstmatigeintelligentie20192020\/Archive\/Category*\/*.jpg') # creerd een lijst met alle locatie's van de foto's\n\npath=\"..\/input\/kunstmatigeintelligentie20192020\/Archive\"\nnames = (os.listdir(path))\nnames.sort()\nprint(names)\nprint(files[0])","b9a2d19b":"# hier zijn 5 functies voor wat visualisatie\n\n#kijken naar de dimensie van de verschillende foto's\n# Dit is zelf al onderzorgd en er is in ons opzichte de beste verhouding gekozen width, height, channels\ndef dimensie():\n    array = pd.DataFrame(columns=('width', 'height'))\n    for fname in files:\n        img = image.load_img(fname)\n        x = image.img_to_array(img)\n        width = len(x[0])\n        height = len(x)\n        df = pd.DataFrame([[width, height]], columns=('width', 'height'))\n        array = array.append(df)\n    \n    width = int(round(np.mean(array['width']))+1)\n    height = 139\n    \n    return (height+6), width, len(x[0,0]), array\n    \n\n# lijst met 5 samples van elke categorie voor visualisatie\ndef plotlijst():\n    plot_lijst=[]\n    aantal=[]\n    for i in range(1, 6):\n        lenght = len(glob.glob('..\/input\/kunstmatigeintelligentie20192020\/Archive\/Category%s\/*.jpg' % i))\n        aantal.append(lenght)\n        files = random.sample(glob.glob('..\/input\/kunstmatigeintelligentie20192020\/Archive\/Category%s\/*.jpg' % i), 5)\n        plot_lijst.append(files)    \n    \n    return plot_lijst, aantal\n\n\n\n# functie voor visualisatie\ndef visueel(plot_lijst, height, width):        \n    fig = plt.figure(figsize=(17, 30))\n    plt.subplots_adjust(left=.2, bottom=.5)\n    for row, lijst in enumerate(plot_lijst):        \n        for col, index in enumerate(lijst):\n            img = image.load_img(index, target_size=(height, width))   \n            subplot = fig.add_subplot(5, len(lijst), row*len(lijst)+col+1)\n            subplot.set_title('Category %s' % (row+1))\n            for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n                    label.set_fontsize(10)\n            plt.imshow(img)\n\ndef acc_loss_plot(history):\n    \n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc)+1)\n    \n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    \n    plt.figure()\n    \n    \n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    \n    \n    plt.show()\n    \n    \ndef layer_outputs(model, img):    \n    \n    img_tensor = image.img_to_array(img)\n    img_tensor = img_tensor.reshape((1,) + img_tensor.shape)\n    #length = len(model.layers)\n    layer_outputs = [layer.output for layer in model.layers[:4]]\n    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n    \n    activations = activation_model.predict(img_tensor)    \n    \n    layer_names = []\n    for layer in model.layers[:4]:\n        layer_names.append(layer.name)\n    \n    images_per_row = 8\n    \n    # Now let's display our feature maps\n    for layer_name, layer_activation in zip(layer_names, activations):\n        # This is the number of features in the feature map\n        n_features = layer_activation.shape[-1]\n    \n        # The feature map has shape (1, size, size, n_features)\n        height = layer_activation.shape[1]\n        width = layer_activation.shape[2]\n        \n    \n        # We will tile the activation channels in this matrix\n        n_cols = n_features \/\/ images_per_row\n        display_grid = np.zeros((height * n_cols, images_per_row * width))\n    \n        # We'll tile each filter into this big horizontal grid\n        for col in range(n_cols):\n            for row in range(images_per_row):\n                channel_image = layer_activation[0,\n                                                 :, :,\n                                                 col * images_per_row + row]\n                # Post-process the feature to make it visually palatable\n                channel_image -= channel_image.mean()\n                channel_image \/= channel_image.std()\n                channel_image *= 64\n                channel_image += 128\n                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n                display_grid[col * height : (col + 1) * height,\n                             row * width : (row + 1) * width] = channel_image\n    \n        # Display the grid\n        scale = 1. \/ height\n        plt.figure(figsize=(scale * display_grid.shape[1],\n                            scale * display_grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n        \n    plt.show()  ","354ce4e1":"plot_lijst, aantal = plotlijst()\nsns.barplot(x=names, y=aantal) # plot van de verdeling\n\nmax(aantal) \/ sum(aantal) # als er alleen gekozen wordt op category 1 heb je een acc van 34%\n\nheight=139\nwidth=210\nchannel=3\nvisueel(plot_lijst, height, width)\n\n","025460e2":"probability = [i \/ sum(aantal) for i in aantal]\nrandom_base = sum([(tal*prob)\/sum(aantal) for tal, prob in zip(aantal, probability)])\nprint(round(random_base*100,2))","5728b7f4":"batch_size=32\ntrain_datagen = image.ImageDataGenerator(\n      rescale=1\/255,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest',\n      validation_split=.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n        path,\n        target_size=(height, width),\n        color_mode='rgb',\n        class_mode='categorical',\n        classes=names,\n        batch_size=batch_size,\n        subset='training'\n        )\n\nval_generator = train_datagen.flow_from_directory(\n        path,\n        target_size=(height, width),\n        color_mode='rgb',\n        class_mode='categorical',\n        classes=names,\n        batch_size=batch_size,\n        subset='validation'\n        )","874c29d6":"img = image.load_img('..\/input\/kunstmatigeintelligentie20192020\/Archive\/Category1\/2780099.jpg')\n\nx = image.img_to_array(img)\nprint(x.shape)\nx = x.reshape((1,)+x.shape)\n\ni = 0\nfor batch in train_datagen.flow(x, batch_size=1):\n    \n    plt.figure(i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\n    \nplt.show()","50327595":"vgg16 =load_model('..\/input\/modellen1\/vgg16.h5')\n\"\"\"\nvgg16 = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(height, width, channel),\n             pooling='max')\n\"\"\"\nvgg16.summary()","8317553e":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n        optimizer=optimizers.Adam(learning_rate=1e-6),\n        metrics=['acc'])\n\nnum_epochs = 60\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(.1), patience=3, min_lr=2e-7, verbose=1)\ncallbacks = [EarlyStopping(patience=5), reduce_lr] #ModelCheckpoint('model_eind.h5', save_best_only=True),\n\nhistory  = model.fit_generator(train_generator,\n                               steps_per_epoch=int(5002*.8\/batch_size),\n                               epochs=num_epochs,\n                               validation_data=val_generator,\n                               validation_steps=int(5002*.2\/batch_size),\n                               callbacks=callbacks)","6447686d":"model.evaluate_generator(val_generator)","9cd4fded":"acc_loss_plot(history)","5f3b8698":"model = load_model('..\/input\/modellen1\/best_model.h5')\ntest_files=glob.glob('..\/input\/kunstmatigeintelligentie20192020\/Images\/Images\/*.jpg')\ntest_images= [image.load_img(x, target_size=(height, width)) for x in test_files]\ntest_images = np.array([image.img_to_array(x) for x in test_images])\n\ntest_images = test_images.astype('float32') \/ 255\n\nlijst = os.listdir('..\/input\/kunstmatigeintelligentie20192020\/Images\/Images')\n\npredict = model.predict_classes(test_images)+1\n\n  \ndata = {'id':lijst,\n        'Category':predict}\n\ndf = pd.DataFrame(data, columns = ['id', 'Category'])\ndf.head()","d8ddc5a9":"model1 = load_model('..\/input\/modellen\/max_adam_4096_lr7_3.h5')\nmodel2 = load_model('..\/input\/modellen\/model_best_acc_1.h5')\nmodel3 = load_model('..\/input\/modellen\/model_best_acc_4.h5')\nmodel4 = load_model('..\/input\/modellen1\/best_model.h5')\nmodel5 = load_model('..\/input\/modellen\/dense_rmsprop_best.h5')\n\n\ntest_files=glob.glob('..\/input\/kunstmatigeintelligentie20192020\/Images\/Images\/*.jpg')  # data locaties\n# laat afbeeldingen in ipv flow_from_directory\ntest_images= [image.load_img(x, target_size=(height, width)) for x in test_files] \n# Maakt er arrays van om te kunnen voorspelen\ntest_images = np.array([image.img_to_array(x) for x in test_images])\n# rescale\ntest_images = test_images.astype('float32') \/ 255\n\nmodel_list = [model1, model2, model3, model4, model5]\ny = np.empty((1250), dtype=int)\n\n# maakt lijst met voorspelingen\nfor model in model_list:\n    predict = model.predict_classes(test_images)+1\n    \n    y = np.column_stack((y, predict))\n\n# gebruikt de meest voorkomende voorspelling\ny = y[:,1:]\nvoorspel = np.array([], dtype=int)\nfor i in y:\n    count = np.bincount(i)\n    voorspel = np.append(voorspel, np.argmax(count))\n    \n    \n\n\nlijst = os.listdir('..\/input\/kunstmatigeintelligentie20192020\/Images\/Images')\n    \ndata = {'id':lijst,\n        'Category':voorspel}\n    \ndf = pd.DataFrame(data, columns = ['id', 'Category'])\n\nprint(y[0:5,])\nprint(df.head())","0425c84f":"regu_rate = 1e-5\n\nmodel = Sequential()\n \n# block\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', input_shape=(height, width, channel),\n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same',\n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(MaxPool2D((2,2), strides=(2,2)))\n \n# block\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(MaxPool2D((2,2), strides=(2,2)))\n \n# block\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2()))\nmodel.add(MaxPool2D((2,2), strides=(2,2)))\n \n# block\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(MaxPool2D((2,2), strides=(2,2)))\n \n# block\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', \n                 kernel_regularizer=regularizers.l2(regu_rate)))\nmodel.add(MaxPool2D((2,2), strides=(2,2)))\n \n# block #\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))\n \n\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nprint(model.summary())","b2cc9382":"# Het model\nHet model wat je hier ziet is het vgg16 model met ipv een Flatten() layer een globalmaxpooling2d layer. De reden waarom dit gedaan is is omdat de hiermee er meer informatie behouden wordt in de afbeelding dan met het gebruik van Flatten()\n\nDe Adam optimizer, zie heir voor meer uitleg https:\/\/towardsdatascience.com\/adam-latest-trends-in-deep-learning-optimization-6be9a291375c, is hier ook gebruikt ipv RMSprop() deze keuze is gemaakt omdat Adam vaak beter resultaten behaald. Let op!!! Niet altijd. Het is dus altijd goed om ook te kijken hoe andere optimizers het doen\n\nOok wordt er gebruik gemaakt van callbacks. De reden is dat dmv callbacks je acties kan toevoegen in het model.\nzo wordt er veel gebruik gemaakt van EarlyStopping en ModelCheckpoint.\nEarlyStoppping word gebruikt om er voor te zorgen dat je model niet door blijft trainen als het niks leert. Zo zie je hierboven dat er 60 epochs zijn, maar niet \nalle 60 epochs gerunt worden omdat het model niks extra's meer leerde. (geen lagere val_loss na 6 achtereenvolgende epochs) \n\nModelCheckpoint wordt gebruikt om het model met het beste op te slaan. De laagste val_loss, in ons geval, wordt dus opgeslagen. Heeft het model dus geen lagere val_loss daarna wordt het niet gezien als een beter model en slaan we die dus niet op. In het geval hierboven zou je dus kunnen zeggen dat ModelCheckpoint het model van epoch 9 zou opslaan met een val_loss van 0.1130 en een val_acc van 0.8913. \n\nReduceLROnPlateau wordt gebruikt om de learning rate van het model te verlagen als de val_loss over meerdere epochs, in ons geval 5 epcosh (patience=5), niet verbeterd. Het kan dan dus zijn dat het model niet meer beter leert.","0cdece20":"Zoals je hierboven ziet heeft dit model pittig wat parameters. 14,714,688 om precies te zijn en dan hebben we de dense layers er nog niet aan toe gevoegd. Het is daarom verstandig om een gpu te gebruiken. Ook is het mogelijk om de layers te frezen zodat je alleen nog de dense layers hoeft te trainen. hiervoor hebben wij niet gekozen.","38932d0d":"Zoals jullie weten zijn de handelingen hieronder om de data te prepareren. Door gebruik te maken van meerder augmentaties krijg je heel makelijk meer data. Dit kan handig zijn als je een kleine dataset hebt.","ab6d0744":"De modellen zijn niet ingeladen op kaggle, maar hier onder is de code te zien hoe wij het zelf gedaan hebben.","7978f779":"Hierboven zie je de plot die er uiteindelijk uitgekomen is.","f8753e77":"Zoals je hieronder ziet komt er het zelfde resultaat uit als bij epoch 9","8060249a":"# Hier zien we visueel enkele dinge\n\nZoals te zien is in de plaatjes hieronder zijn er 5 categorieen aan boten<br>\ncategorie 1: olieschepen<br>\ncategorie 2: militaire schepen<br>\ncategorie 3: grote vrachtschepen<br>\ncategorie 4: cruiseschepen<br>\ncategorie 5: iets<br>\n\nde verdeling van de categorienen kan je ook goed zijn in het bovenste plaatje.<br>\n\nOok is goed te zien dat er zwart wit, grayscale foto's tussen zitten. Dit is belangrijk om mee rekening te houden, want stel dat er in een categorie veel zwartwit foto's zijn vergeleken met de andere categorieen kan het gebeuren dat ons model onterecht de verkeerde categorie kiest vanwege grayscale. Hier zal nog verder naar gekeken worden.\n\n\n\n","6a5feed2":"Wat ook goed is om te doen is een random baseline uit te rekenen om er achter te komen hoe goed het model minimaal moet zijn om beter te zijn dan random. Als we dan naar het antwoor dheironder kijken dan zien we dat we minimaal een model moeten hebben die 22.8% van de afbeeldingen goed voorspeld.\n","3aeaa813":"# zelf gemaakte code vvg16","d40e6dc3":"# Submission file\nEn dan nu een submision file aanmaken die gebruikt kan worden om te kijken hoe goed het model is","7baf2f8c":"## Als test hebben we ook gebruik gemaakt van VGG16 maxpooling en VGG16 globalpooling hieronder zullen we enkele resultaten daarvan geven met de bijborende veranderingen zoals lr, optimizer. <br> \n<b>Al deze modelen zijn getrained op de voledige vgg16 model<\/b> <br>\n1: <b>maxpooling, RMSprop<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.1113<\/b> en een val_acc van <b>.907<\/b> <br>\nBij het model met een lr van 2e-7 kwamen we op een val_loss van <b>.1346<\/b> en een val_acc van <b>.890<\/b> <br>\n\n1: <b>maxpooling, Adam<\/b> <br>\nBij het model met een lr van 2e-5 kwamen we op een val_loss van <b>.2221<\/b> en een val_acc van <b>.879<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.1286<\/b> en een val_acc van <b>.888<\/b> <br>\n\n1: <b>maxpooling, SGD<\/b> <br>\nBij het model met een lr van 2e-5 kwamen we op een val_loss van <b>1.263<\/b> en een val_acc van <b>.3346<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>1.079<\/b> en een val_acc van <b>.4083<\/b> <br>\n\n2: <b>averagepooling, RMSprop<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.2492<\/b> en een val_acc van <b>.8178<\/b> <br>\nBij het model met een lr van 2e-7 kwamen we op een val_loss van <b>1.539<\/b> en een val_acc van <b>.348<\/b> <br>\n\n2: <b>averagepooling, Adam<\/b> <br>\nBij het model met een lr van 2e-5 kwamen we op een val_loss van <b>.1691<\/b> en een val_acc van <b>.877<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.0570<\/b> en een val_acc van <b>.904<\/b> <br>\n\n2: <b>averagepooling, SGD<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.2492<\/b> en een val_acc van <b>.8178<\/b> <br>\nBij het model met een lr van 2e-7 kwamen we op een val_loss van <b>1.539<\/b> en een val_acc van <b>.348<\/b> <br>\n\n3: <b>Dense, RMSprop<\/b> <br>\nBij het model met een lr van 2e-5 kwamen we op een val_loss van <b>.1528<\/b> en een val_acc van <b>.866<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.0964<\/b> en een val_acc van <b>.901<\/b> <br>\nBij het model met een lr van 2e-7 kwamen we op een val_loss van <b>.2528<\/b> en een val_acc van <b>.871<\/b> <br>\n\n3: <b>Dense, Adam<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.0229<\/b> en een val_acc van <b>.914<\/b> <br>\nBij het model met een lr van 2e-7 kwamen we op een val_loss van <b>.7218<\/b> en een val_acc van <b>.751<\/b> <br>\n\n3: <b>Dense, SGD<\/b> <br>\nBij het model met een lr van 2e-6 kwamen we op een val_loss van <b>.992<\/b> en een val_acc van <b>.55<\/b> <br>","ebc72655":"# Bagging\nDoor gebruik te maken van bagging kan je uiteindelijke voorspelling hoger uitkomen.\nDit kan zo zijn omdat je meerdere modellen hebt gebruikt al deze modellen hebben verschillende gewichten in hun model en zullen daardoor ook allemaal andere voorspellingen hebben. Als je daarbij ervan uitgaat dat 1 model soms een fout en andere modellen deze fout niet maken dat als er gebruikt wordt gemaakt van meerdere modellen de kans op een foute voorspelling kleiner kan worden en er uiteindelijk meer juiste voorspellingen ontstaan. Door dit te gebruiken is de scoring met 2% gestegen vergeleken met het gebruiken van een model.","cc92ed0c":"## Augmentatie\nHier onder is te zien wat de augmentatie kan doen. Zo is te zien dat de afbeelding horizontale gedraait is. Wat verschoven is naar links,rechts, boven en ook ingezoomd is.","ab50b613":"# Transfer-learning\nEr wordt gebruik gemaakt van transfer-learning. In dit geval wordt er gebruik gemaakt van VGG16.\nZie: https:\/\/arxiv.org\/pdf\/1409.1556.pdf, voor meer uitleg.\nVGG16 is erg lang getrained op de imagenet dataset. Hierin zitten ook verschillende boten en is bruikbaar voor ons probleem.\nvoor meer informatie over transfer-learning kan je dit boek gebruiken, <b>Deep Learning for Vision Systems<\/b> bij <b>Mohamed Elgendy<\/b>.<br>\n<br>\n<b>Het laden van de vgg16 lukte niet dus het is op een andere manier gedaan<\/b>","d6ee9e08":"# Dit is de kaggle opdracht van KI \nIn deze opdracht gaan we een CONV model maken.\nDe dataset die we gaan gebruiken is een dataset gemaakt door de docenten zelf en bevatten 5 categorieen."}}