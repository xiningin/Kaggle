{"cell_type":{"379a9b93":"code","5b2444f5":"code","a205e1a8":"code","33571113":"code","1e71c59b":"code","c7fca5af":"code","7767d510":"code","8d18267f":"code","e0450917":"code","93538949":"code","d6dafeb6":"code","fb5fcd9b":"code","2dd03b7b":"code","13f1c8cc":"code","f18d5666":"code","c3fe67f5":"code","a9cb985e":"code","31152790":"code","c3836ad2":"code","db22f08f":"code","cdf3dc6c":"code","fead8939":"code","b0fbc846":"code","79e0f588":"code","5104ea94":"code","9883cce6":"code","fc6e6806":"code","82091297":"code","0d646b2b":"code","b9c1f2bd":"code","6d17cd62":"code","b48e7178":"code","510a083b":"code","830ac5d4":"code","d13186ab":"code","227cf840":"markdown","66079cba":"markdown","804680ee":"markdown","2c2fbfc6":"markdown","0c19a968":"markdown","5ee4c5c3":"markdown","796f8392":"markdown","4122c476":"markdown","0fca869f":"markdown","dc14a293":"markdown","ef629ee2":"markdown","f0941783":"markdown","8065d9ec":"markdown","ca0d0f55":"markdown","c527e336":"markdown","08553d4e":"markdown","21186028":"markdown"},"source":{"379a9b93":"from datetime import datetime, timedelta, timezone\nfrom time import time\n\ndataHora = datetime.now() # data e hora\ndiferenca = timedelta(hours=-3) # UTC-03:00\nfuso_horario = timezone(diferenca)\ndataHora = dataHora.astimezone(fuso_horario).strftime('%d\/%m\/%Y %H:%M')\n\nprint(f'Hor\u00e1rio de Bras\u00edlia (BRT[3] \u2013 Bras\u00edlia Time em UTC-03:00: {dataHora}')","5b2444f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a205e1a8":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nprint(f'tensorflow version: {tf.__version__}')","33571113":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","1e71c59b":"print('TRAIN columns:\\n', train.columns)\nprint('TEST columns:\\n', test.columns)","c7fca5af":"# Separando X treino e Y treino\nY = train[\"label\"]\nX = train.drop(labels = [\"label\"],axis = 1)","7767d510":"X = X.values.reshape(len(X),28,28, 1).astype('float32')\nx_test = test.values.reshape(len(test),28,28, 1).astype('float32')\n\nprint('Train')\nprint('X shape: ', X.shape, 'type: ', X.dtype)\nprint('\\nTest')\nprint('x test shape: ', x_test.shape, 'type: ', x_test.dtype)","8d18267f":"def plot_numbers(x, y, num:int, cmap='gray', title='Number'):\n  cases = list(range(num))\n  plot_params = {\n      'axes.titlesize': 12,\n      }\n  with plt.rc_context(plot_params):\n      fig, axs = plt.subplots(2, int(num\/2), figsize=(8, 4))\n      for ax, i in zip(axs.flat, cases):\n          ax.set_title(f'{title}: {y[i]}')\n          im = ax.imshow(x[i], cmap=cmap)\n          ax.axis('off')  \n      cbar_ax = fig.add_axes([0.92, 0.13, 0.03, 0.75])\n      fig.colorbar(im, cax=cbar_ax)\n      fig.subplots_adjust(wspace=0.1, hspace=0.25)\n\nplot_numbers(X, Y, 8)","e0450917":"# Test value == 255 scale rgb \nprint('scale rgb max:', X.max())","93538949":"# MinMax scaler - Normalize pixel values to be between 0 and 1\nX = X \/ 255.0\n\n# Test scale rgb normalize \nprint('scale normalized max:', X.max())","d6dafeb6":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X, Y.values, test_size = 0.18, random_state=5)\n\nprint('Train')\nprint('x train shape: ', x_train.shape, 'type: ', x_train.dtype)\nprint('y train shape: ', y_train.shape, 'type: ', y_train.dtype)\nprint('\\nTest Val')\nprint('x val shape: ', x_val.shape, 'type: ', x_val.dtype)\nprint('y val shape: ', y_val.shape, 'type: ', y_val.dtype)","fb5fcd9b":"labels_train = tf.keras.utils.to_categorical(y_train)\nlabels_val = tf.keras.utils.to_categorical(y_val)\nprint('Train\\n')\nprint(f'Default Labels: {y_train[0]}\\n\\\nCategorical Lables: {labels_train[0]}'\n)\n\nprint('\\nTest')\nprint(f'Default Labels: {y_val[0]}\\n\\\nCategorical Lables: {labels_val[0]}'\n)","2dd03b7b":"input_shape = x_train.shape[1:]\ndef model_base():\n    model = keras.models.Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dense(10, activation='softmax'))\n    return model\n\nmodel_base = model_base()","13f1c8cc":"# Compile Model\nmodel_base.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Resume Model\nmodel_base.summary()","f18d5666":"history = model_base.fit(x_train, labels_train, batch_size=128, epochs=20, \n                         validation_data=(x_val, labels_val), verbose=1)","c3fe67f5":"# Dataframe results model\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.describe()","a9cb985e":"def subplots(df):\n  plot_params = {\n      'axes.titlesize': 14,\n      'xtick.labelsize': 10,\n      'ytick.labelsize': 10,\n      'axes.labelsize': 12,\n      'legend.fontsize': 12,\n      }\n  with plt.rc_context(plot_params):\n        with plt.style.context('seaborn-darkgrid'):\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 3), constrained_layout=True)\n            ax1.plot(df['epoch'],  df['loss'], label='loss', c='#eadf5c')\n            ax1.plot(df['epoch'], df['val_loss'], label='val_loss', c='#802a4d')\n            ax1.fill_between(df['epoch'],  df['loss'], color='#eadf5c', alpha=0.2)\n            ax1.fill_between(df['epoch'], df['val_loss'], color='#802a4d', alpha=0.2)\n            ax1.set_xticks(range(0,20,1))\n            ax1.legend()\n            ax1.set_xlabel('epoch')\n            \n            ax2.plot(df['epoch'], df['accuracy'], label='accuracy', c='#ccb43c')\n            ax2.plot(df['epoch'], df['val_accuracy'], label='val_accuracy', c='#464564')\n            ax2.fill_between(df['epoch'],  0.92, df['accuracy'], color='#ccb43c', alpha=0.2)\n            ax2.fill_between(df['epoch'], 0.92, df['val_accuracy'], color='#464564', alpha=0.2)\n            ax2.set_xticks(range(0,20,1))\n            ax2.legend()\n            ax2.set_xlabel('epoch')\n    \nsubplots(hist)","31152790":"def plus_model():\n    model = keras.models.Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(10, activation='softmax'))\n    return model","c3836ad2":"plus_model = plus_model()\nplus_model.compile(optimizer=keras.optimizers.Adam(),\n                   loss='categorical_crossentropy',\n                   metrics=['accuracy'])\n\n# Resumo do Modelo\nplus_model.summary()","db22f08f":"history = plus_model.fit(x_train, labels_train, batch_size=128, epochs=20, \n                         validation_data=(x_val, labels_val), verbose=1)","cdf3dc6c":"# Dataframa resulto model\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\n\n# Results stats model\nhist.describe()","fead8939":"subplots(hist)","b0fbc846":"def one_test_predict(n=0):\n    \"\"\"n: index Label digit test\n    \"\"\"\n    print('\\nTest')\n    print(f'Default Label: {y_val[n]}\\nCategorical Label: {labels_val[n]}')\n    pred = plus_model.predict(x_val[[n]])\n    pred = np.argmax(pred, axis=-1)\n    print('\\nRede Neural Convolucional (CNN)')\n    print('Predict Label(Digit): ', pred[0])\n\none_test_predict(102)","79e0f588":"test = x_val[102].reshape(28, 28)*255\npred = plus_model.predict(x_val[[102]])\npred = np.argmax(pred, axis=-1)\nplt.imshow(test)\nplt.title(f'Predict Digit: {pred[0]}')\nplt.colorbar()\nplt.show()","5104ea94":"cnn_results = plus_model.evaluate(x_val, labels_val)","9883cce6":"print('Testing set Accuracy: {:.2f}'.format(cnn_results[1]))\nprint('Testing set Accuracy: {:2.2%}'.format(cnn_results[1]))","fc6e6806":"from sklearn.model_selection import StratifiedKFold","82091297":"seed=5\nnp.random.seed(seed)\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\nresults = []","0d646b2b":"for i_train, i_test in kfold.split(x_train, \n                                         np.zeros(shape = (labels_train.shape[0], 1))\n                                         ):\n  plus_model.fit(x_train[i_train], labels_train[i_train], batch_size=128, epochs=10, verbose=1)\n  eval = plus_model.evaluate(x_train[i_test], labels_train[i_test])\n  results.append(eval[1])","b9c1f2bd":"mean = sum(results) \/ len(results)\nprint('Testing set Accuracy: {:.2f}'.format(mean))\nprint('Testing set Accuracy: {:2.2%}'.format(mean))","6d17cd62":"test = x_val[102]\npred = plus_model.predict(x_val[[102]])\npred = np.argmax(pred, axis=-1)\nplt.imshow(test)\nplt.title(f'Predict Digit: {pred[0]}')\nplt.colorbar()\nplt.show()","b48e7178":"preds = plus_model.predict(X[0:8])\npreds = np.argmax(preds, axis=-1)","510a083b":"plot_numbers(X[0:8], preds, 8, cmap='viridis', title='Classification')","830ac5d4":"y_preds = plus_model.predict(x_test)\ny_preds = np.argmax(y_preds, axis=-1)","d13186ab":"# Make file Predictions\nresults = pd.Series(y_preds,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,len(y_preds)+1),name = \"ImageId\"),results],axis = 1)\nprint(submission.head(10))\n\n#Salvando arquivo de saida dos testes\nsubmission.to_csv(\"mysubmission_digit-v02.csv\",index=False)","227cf840":"## Cross-validate Evaluation","66079cba":"## Evaluate Model++","804680ee":"### Training of deep neural networks ","2c2fbfc6":"### Classify Multi Label","0c19a968":"### Classify one Label","5ee4c5c3":"## Cross-validate Training","796f8392":"Thanks!","4122c476":"## Deep neural networks - Base model","0fca869f":"**MNIST (\"Modified National Institute of Standards and Technology\")** is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We\u2019ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.","dc14a293":"# Cross-validation: evaluating estimator performance","ef629ee2":"## Base model++","f0941783":"# Introduction\n   <center><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/27\/MnistExamples.png\"><\/center>\n      <center>Josef Steppan, CC BY-SA 4.0 <https:\/\/creativecommons.org\/licenses\/by-sa\/4.0\/>, via Wikimedia Commons <\/center>\n","8065d9ec":"### Results Base Model++","ca0d0f55":"### Training Model++","c527e336":"# Create and train the model ***(Deep neural networks)***","08553d4e":"**Objectives:**\n\n*     Applying exploratory data analysis dataset\n*     Feature engineering\n*     Preprocessing\n*     Classification digits\n","21186028":"### Results Base Model"}}