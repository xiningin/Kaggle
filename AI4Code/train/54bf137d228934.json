{"cell_type":{"90498ffc":"code","9ad0ceb8":"code","ce21758d":"code","d09e59d6":"code","8c13a3fe":"code","9a4c3b69":"code","d1ffa1ff":"code","cd699012":"code","22cccbe8":"code","f72da4ab":"code","1ec8cdea":"markdown"},"source":{"90498ffc":"import cv2\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\nfrom matplotlib import pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import Callback\nfrom keras.applications import MobileNetV2\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, SeparableConv2D, DepthwiseConv2D, Conv2DTranspose, Conv2D, Reshape, UpSampling2D, Activation, BatchNormalization, GlobalMaxPooling2D, MaxPooling2D, Flatten, Input, SeparableConv2D, Dropout, concatenate, multiply","9ad0ceb8":"data = pd.read_csv('..\/input\/training\/training.csv')\nHEIGHT, WIDTH = 96, 96\ndata.keys()","ce21758d":"data.fillna(method = 'ffill',inplace = True) # Credits: @Karan Jakhar","d09e59d6":"X = np.zeros((len(data['Image'])*2,HEIGHT,WIDTH))\nimage_dataset = data['Image']\nfor i in tqdm(range(len(data['Image']))): # Some Image Augmentation\n    X[i] = np.array(image_dataset[i].split(), dtype='uint8').reshape((96,96))\n    X[len(data['Image'])+i] = cv2.flip(np.array(image_dataset[i].split(), dtype='uint8').reshape((96,96)), 1)\n\ndel image_dataset\nX = np.expand_dims(X, -1) \/ 255","8c13a3fe":"data = data.drop('Image', axis=1).values.T[:4].T\ny = np.zeros((len(data)*2,4))\nfor i in tqdm(range(len(data))):\n    y[i] = data[i] \/ HEIGHT\n    y[len(data)+i] = abs(data[i]-WIDTH) \/ HEIGHT\n    \ndel data","9a4c3b69":"class PlotLearning(Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        \n        self.logs = []\n        \n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.i += 1\n        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n        \n        clear_output(wait=True)\n        \n        ax1.set_yscale('Log')\n        ax1.plot(self.x, self.losses, label=\"loss\")\n        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n        ax1.legend()\n        \n        ax2.plot(self.x, self.acc, label=\"acc\")\n        ax2.plot(self.x, self.val_acc, label=\"val_acc\")\n        ax2.legend()\n        \n        plt.show()\n        \n        \nplot = PlotLearning()","d1ffa1ff":"s=8\nfiltersize=(3,3)\n\ninput_layer = Input(shape=(96,96,1))\n\nhidden = Conv2D(s, (7,7))(input_layer)\nhidden = Conv2D(s, (7,7))(hidden)\n\nhidden = MaxPooling2D((2,2))(hidden)\n\nhidden = Conv2D(2*s, (5,5))(hidden)\nhidden = Conv2D(2*s, (5,5))(hidden)\n\nhidden = MaxPooling2D((2,2))(hidden)\n\nhidden = Conv2D(4*s, (3,3))(hidden)\nhidden = Conv2D(4*s, (3,3))(hidden)\n\nhidden = MaxPooling2D((2,2))(hidden)\n\nhidden = Flatten()(hidden)\n\nhidden = Dense(512, activity_regularizer='l2', kernel_regularizer='l2')(hidden)\nhidden = Dense(128, activity_regularizer='l2', kernel_regularizer='l2')(hidden)\nhidden = Dense(8, activity_regularizer='l2', kernel_regularizer='l2')(hidden)\nhidden = BatchNormalization()(hidden)\nhidden = Activation('relu')(hidden)\n\noutput = Dense(4, activation='sigmoid')(hidden)\n\nmodel = Model(input_layer, output)\n\nmodel.compile(\n    optimizer=Adam(lr=0.0001),\n    loss='mse',\n    metrics=['accuracy']\n)\n\nmodel.summary()","cd699012":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    samplewise_center=True,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True,\n    rescale=1.\/255,\n    shear_range=0,\n    zoom_range=0,\n    horizontal_flip=False,\n    validation_split=0.0,\n    brightness_range=[0.7, 1.3],   \n)\n\ndatagen.fit(X)","22cccbe8":"model.fit_generator(\n    datagen.flow(X, y, batch_size=64),\n    validation_data=(X,y),\n    steps_per_epoch=1000,\n    callbacks=[plot],\n    epochs=500,\n)","f72da4ab":"model.save('Face LandMark Regressor.h5')","1ec8cdea":"**Now we fill the empty cells with Previous Cell Values**"}}