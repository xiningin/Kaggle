{"cell_type":{"a207fdf8":"code","7484dde5":"code","ace5f7cb":"code","78972d69":"code","f9e294ef":"code","126ab1c5":"code","8876a589":"code","35d16657":"code","e9b1d5df":"code","c1545521":"code","f0a40fd1":"code","8974840a":"code","cf4117fa":"code","d76a3633":"code","c298ef99":"code","ac022fa9":"code","6581fa5d":"code","d24f9b00":"code","e27e1d4a":"code","e5f1a7c5":"code","c7e0b919":"code","3d0445af":"code","c3fd2ec3":"code","3785a3e1":"code","87619c4e":"code","ef508d42":"code","dc166890":"code","d38a9a58":"code","311ef59c":"code","03f3fb96":"markdown","65a4d19c":"markdown","99ac6e1b":"markdown","035b5b71":"markdown","29e2ccef":"markdown","112b7670":"markdown","23125ac4":"markdown","88fbac85":"markdown","09ddae18":"markdown","cdd798a5":"markdown"},"source":{"a207fdf8":"import os\nimport torch\nimport torchvision\nimport tarfile\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data.dataloader import DataLoader\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom io import BytesIO\nimport requests\nimport torchvision.transforms as T","7484dde5":"dataset = ImageFolder('..\/input\/autistic-children-data-set-traintestvalidate\/consolidated', transform=ToTensor())","ace5f7cb":"img, label = dataset[3]\nprint(img.shape, label)\nimg","78972d69":"print(dataset.classes)","f9e294ef":"random_seed = 2077\ntorch.manual_seed(random_seed)","126ab1c5":"val_size = 300\ntest_size = 100\ntrain_size = len(dataset) - val_size - test_size\n\ntrain_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds)","8876a589":"batch_size=56\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n","35d16657":"from torchvision.utils import make_grid\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n        break","e9b1d5df":"show_batch(train_dl)","c1545521":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","f0a40fd1":"device = get_default_device()\ndevice","8974840a":"import torch\nimport torch.nn.functional as F\n\n\ndef DiffAugment(x, policy='', channels_first=True):\n    if policy:\n        if not channels_first:\n            x = x.permute(0, 3, 1, 2)\n        for p in policy.split(','):\n            for f in AUGMENT_FNS[p]:\n                x = f(x)\n        if not channels_first:\n            x = x.permute(0, 2, 3, 1)\n        x = x.contiguous()\n    return x\n\n\ndef rand_brightness(x):\n    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n    return x\n\n\ndef rand_saturation(x):\n    x_mean = x.mean(dim=1, keepdim=True)\n    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n    return x\n\n\ndef rand_contrast(x):\n    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n    return x\n\n\ndef rand_translation(x, ratio=0.125):\n    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n    grid_batch, grid_x, grid_y = torch.meshgrid(\n        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n    )\n    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n    return x\n\n\ndef rand_cutout(x, ratio=0.5):\n    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n    grid_batch, grid_x, grid_y = torch.meshgrid(\n        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n    )\n    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] \/\/ 2, min=0, max=x.size(2) - 1)\n    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] \/\/ 2, min=0, max=x.size(3) - 1)\n    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n    mask[grid_batch, grid_x, grid_y] = 0\n    x = x * mask.unsqueeze(1)\n    return x\n\n\nAUGMENT_FNS = {\n    'color': [rand_brightness, rand_saturation, rand_contrast],\n    'translation': [rand_translation],\n    'cutout': [rand_cutout],\n}","cf4117fa":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        images = DiffAugment(images, policy='color,translation') #DiffAugment is used here\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","d76a3633":"class Net(ImageClassificationBase):\n    def __init__(self, num_classes=2, num_channels=3):\n        super().__init__()\n        preloaded = torchvision.models.densenet161(pretrained=True)\n        self.features = preloaded.features\n        self.features.conv0 = nn.Conv2d(num_channels, 96, 7, 2, 3)\n        self.classifier = nn.Linear(2208, num_classes, bias=True)\n        self.bn = nn.BatchNorm1d(2208)\n        del preloaded\n        \n    def forward(self, x):\n        features = self.features(x)\n        out = F.relu(features, inplace=True)\n        out = F.adaptive_max_pool2d(out, (1, 1)).view(features.size(0), -1)\n        #out = self.bn(out)\n        out = self.classifier(out)\n        return out\n\ndef predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    classes = ['autistic', 'non autistic']\n    return classes[preds[0].item()]","c298ef99":"Net = Net()","ac022fa9":"Net = to_device(Net, device = device)\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","6581fa5d":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    best_acc = 0\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n        if result['val_acc'] > best_acc:\n            torch.save(model.state_dict(), os.path.join('.\/', 'autism_best_model.pt'))\n            best_acc = result['val_acc']\n    return history","d24f9b00":"evaluate(Net, val_dl)","e27e1d4a":"num_epochs = 40\nopt_func = torch.optim.Adam\nlr = 0.0005","e5f1a7c5":"history = fit(num_epochs, lr, Net, train_dl, val_dl, opt_func)","c7e0b919":"Net.load_state_dict(torch.load('.\/autism_best_model.pt'))","3d0445af":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\nplot_accuracies(history)","c3fd2ec3":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\nplot_losses(history)","3785a3e1":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return dataset.classes[preds[0].item()]","87619c4e":"torch.cuda.empty_cache()","ef508d42":"correct_guesses = 0\nfor i in range(len(test_ds)):\n    img, label = test_ds[i]\n    if test_ds.dataset.classes[label] == predict_image(img, Net):\n        correct_guesses +=1\nprint(correct_guesses\/test_size)","dc166890":"img, label = dataset[1]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, Net))","d38a9a58":"img, label = dataset[10]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, Net))","311ef59c":"img, label = dataset[111]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, Net))","03f3fb96":"## DiffAugment code","65a4d19c":"## Loading Data","99ac6e1b":"## Training function","035b5b71":"## Results","29e2ccef":"## Defining Model","112b7670":"## Loading existing model and deleting it weights ","23125ac4":"### Please upvote if you have found this notebook helpful OwO\/","88fbac85":"# Introduction\n\nI have used another peoples work here, so please check them out:\n### 1) https:\/\/jovian.ai\/aakashns\/05-cifar10-cnn\n### 2) https:\/\/www.kaggle.com\/leighplt\/densenet121-pytorch\n### 3) https:\/\/github.com\/mit-han-lab\/data-efficient-gans\n\nIn this Notebook we are going to use DenseNet for picture classification. To understand DenseNet you need figure out [Resnet](https:\/\/www.coursera.org\/lecture\/convolutional-neural-networks\/resnets-HAhz9) architecture first. In short, every second layer outputs are passed to the next layer and added to outputs there, like on the picture below. The key difference between ResNet and DenseNet is that DenseNet instead of adding, it concatenates outputs, so [+] -> [ , ].  \nFor more info about DenseNet and clear pytorch implementation with explanations please read this [article](http:\/\/d2l.ai\/chapter_convolutional-modern\/densenet.html).\n \n![Screenshot%20%2892%29.png](attachment:Screenshot%20%2892%29.png)","09ddae18":"### Accuracy on test dataset\n","cdd798a5":"## Using GPU"}}