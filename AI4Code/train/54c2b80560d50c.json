{"cell_type":{"2e92dc4a":"code","448e2db5":"code","0616edfd":"code","9c164b30":"code","d332da00":"code","e5b1c523":"code","a13429d3":"code","0387c68b":"code","75d94e46":"code","a43f393f":"code","84a6942d":"code","5ea7ace9":"code","32aff6d8":"code","104df30b":"code","1aaaa7eb":"markdown","618f8279":"markdown","5bcde2ae":"markdown","68bf5824":"markdown","995db53e":"markdown","dca31628":"markdown","3f979193":"markdown","9986b5d3":"markdown","9296559b":"markdown"},"source":{"2e92dc4a":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom tensorflow.python.util import compat\nfrom tensorflow.core.protobuf import saved_model_pb2\nfrom google.protobuf import text_format\nimport pprint\nimport os","448e2db5":"! rm -rf .\/models && git clone https:\/\/github.com\/tensorflow\/models.git \\\n    && cd models\/research \\\n    && protoc object_detection\/protos\/*.proto --python_out=. \\\n    && cp object_detection\/packages\/tf2\/setup.py . && \\\n    python3 -m pip install --use-feature=2020-resolver .","0616edfd":"from object_detection.utils import visualization_utils as vis_util\nfrom object_detection.utils import dataset_util, label_map_util\nfrom object_detection.protos import string_int_label_map_pb2","9c164b30":"# reconstruct frozen graph\ndef reconstruct(pb_path):\n    if not os.path.isfile(pb_path):\n        print(\"Error: %s not found\" % pb_path)\n\n    print(\"Reconstructing Tensorflow model\")\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.compat.v1.GraphDef()\n        with tf.io.gfile.GFile(pb_path, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    print(\"Success!\")\n    return detection_graph","d332da00":"# visualize detection\ndef image2np(image):\n    (w, h) = image.size\n    return np.array(image.getdata()).reshape((h, w, 3)).astype(np.uint8)\n\ndef image2tensor(image):\n    npim = image2np(image)\n    return np.expand_dims(npim, axis=0)\n\n%matplotlib inline\ndef detect(detection_graph, test_image_path):\n    with detection_graph.as_default():\n        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.01)\n        with tf.compat.v1.Session(graph=detection_graph,config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as sess:\n            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n\n            image = Image.open(test_image_path)\n            (boxes, scores, classes, num) = sess.run(\n                [detection_boxes, detection_scores, detection_classes, num_detections],\n                feed_dict={image_tensor: image2tensor(image)}\n            )\n\n            npim = image2np(image)\n            vis_util.visualize_boxes_and_labels_on_image_array(\n                npim,\n                np.squeeze(boxes),\n                np.squeeze(classes).astype(np.int32),\n                np.squeeze(scores),\n                category_index,\n                use_normalized_coordinates=True,\n                line_thickness=5)\n            plt.figure(figsize=(12, 8))\n            plt.imshow(npim)\n            plt.show()","e5b1c523":"NCLASSES = 60\nLABEL_MAP_PATH = '.\/models\/research\/object_detection\/data\/mscoco_label_map.pbtxt'","a13429d3":"with open(LABEL_MAP_PATH) as f:\n    pprint.pprint(f.readlines())","0387c68b":"label_map = label_map_util.load_labelmap(LABEL_MAP_PATH)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NCLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)","75d94e46":"detection_graph = reconstruct(\"\/kaggle\/input\/pretrained-trt-engines-cocotacohardhatposenet\/base-models\/ssd_mobilenet_v2_coco_2018_03_29.pb\")","a43f393f":"detect(detection_graph, '\/kaggle\/input\/coco-2017-dataset\/coco2017\/test2017\/000000000080.jpg')","84a6942d":"detect(detection_graph, '\/kaggle\/input\/coco-2017-dataset\/coco2017\/test2017\/000000001024.jpg')","5ea7ace9":"detect(detection_graph, '\/kaggle\/input\/coco-2017-dataset\/coco2017\/test2017\/000000002219.jpg')","32aff6d8":"detect(detection_graph, '\/kaggle\/input\/coco-2017-dataset\/coco2017\/test2017\/000000002680.jpg')","104df30b":"! rm -rf .\/models","1aaaa7eb":"# Reconstruct Frozen Graph","618f8279":"# Validate Test Images","5bcde2ae":"# Cleanup","68bf5824":"# COCO Detection (SSD MobileNet v2) with TensorFlow","995db53e":"We are going to use pretrained models in this notebook to show how you can do inference on them of unseen images. The pretrained models can be found here: https:\/\/www.kaggle.com\/bouweceunen\/pretrained-trt-engines-cocotacohardhatposenet","dca31628":"We can now test it on some test images.","3f979193":"Now we are going to reconstruct the TensorFlow frozen graph (.pb).","9986b5d3":"First we need to create the label map. In this case it already exists in the TensorFlow Model Zoo repository we cloned earlier.","9296559b":"# Create LabelMap"}}