{"cell_type":{"ce72180c":"code","abbdd87b":"code","6f3e0d4f":"code","069e6fa1":"code","d546812f":"code","dcbec97b":"code","119c34cf":"code","23b34a2d":"code","9f280008":"code","33f33bcd":"code","7e5b3ce1":"code","ee4800fe":"code","d5b5c253":"code","1473d106":"code","dffc3dc5":"code","8a834f66":"code","9a74f9e6":"code","51fb309a":"code","78a5754c":"code","e266d7e3":"code","895cf5f6":"code","4c3a9435":"code","c4ac3636":"code","809a3939":"code","29137071":"code","41e3620a":"code","46c3a767":"code","f1a49a0e":"code","2b41e1fb":"code","30a0e4fb":"code","b68a4615":"code","5868589b":"code","ef6449b0":"code","fd678d8d":"code","dcbabf05":"code","7732eb19":"code","57503f4d":"code","e72a5ea6":"code","a45fd49c":"code","d005b9e1":"code","44c51349":"code","fc7f10e5":"code","fc0476ca":"code","db7dc0bf":"code","f6318c4e":"code","36822e17":"code","3484e0dc":"code","74752221":"code","557d4748":"code","a6478d5c":"code","37f11b1a":"code","82bd1884":"code","26892de9":"code","ba808644":"code","549cfa82":"code","b84c5021":"code","17c6023a":"code","61f84f55":"code","8d901d01":"code","9e187d42":"code","10b0ad07":"code","eb9520dd":"code","104cc70c":"code","792a0c41":"code","a250f7f7":"code","2a616ece":"code","65fcb49a":"code","c997e674":"code","5b0c1f2d":"markdown","f84282c1":"markdown","252f70b4":"markdown","f105aaa0":"markdown","0a68d06b":"markdown","90a94e3d":"markdown","4ea1fbe2":"markdown","2fbc6a91":"markdown","d2bd2cfb":"markdown","fd0e7118":"markdown","5e724174":"markdown","b72157e0":"markdown","6ba5e479":"markdown","1829ea37":"markdown","769317a7":"markdown"},"source":{"ce72180c":"import pandas as pd\nfrom IPython.core.display import HTML\n\npath = \"..\/input\/\"\n\nversions = pd.read_csv(path+\"KernelVersions.csv\")\nkernels = pd.read_csv(path+\"Kernels.csv\")\nusers = pd.read_csv(path+\"Users.csv\")\n\nlanguage_map = {'1' : 'R','5' : 'R', '12' : 'R', '13' : 'R', '15' : 'R', '16' : 'R',\n                '2' : 'Python','8' : 'Python', '9' : 'Python', '14' : 'Python'}\n\ndef pressence_check(title, tokens, ignore = []):\n    present = False\n    for token in tokens:\n        words = token.split()\n        if all(wrd.lower().strip() in title.lower() for wrd in words):\n            present = True\n    for token in ignore:\n        if token in title.lower():\n            present = False\n    return present \n\n## check if the latest version of the kernel is about the same topic \ndef get_latest(idd):\n    latest = versions[versions['KernelId'] == idd].sort_values('VersionNumber', ascending = False).iloc(0)[0]\n    return latest['VersionNumber']\n\ndef get_kernels(tokens, n, ignore = []):\n    versions['isRel'] = versions['Title'].apply(lambda x : pressence_check(x, tokens, ignore))\n    relevant = versions[versions['isRel'] == 1]\n    results = relevant.groupby('KernelId').agg({'TotalVotes' : 'sum', \n                                                'KernelLanguageId' : 'max', \n                                                'Title' : lambda x : \"#\".join(x).split(\"#\")[-1],\n                                                'VersionNumber' : 'max'})\n    results = results.reset_index().sort_values('TotalVotes', ascending = False).head(n)\n    results = results.rename(columns={'KernelId' : 'Id', 'TotalVotes': 'Votes'})\n\n\n    results['latest_version']  = results['Id'].apply(lambda x : get_latest(x))\n    results['isLatest'] = results.apply(lambda r : 1 if r['VersionNumber'] == r['latest_version'] else 0, axis=1)\n    results = results[results['isLatest'] == 1]\n\n    results = results.merge(kernels, on=\"Id\").sort_values('TotalVotes', ascending = False)\n    results = results.merge(users.rename(columns={'Id':\"AuthorUserId\"}), on='AuthorUserId')\n    results['Language'] = results['KernelLanguageId'].apply(lambda x : language_map[str(x)] if str(x) in language_map else \"\")\n    results = results.sort_values(\"TotalVotes\", ascending = False)\n    return results[['Title', 'CurrentUrlSlug','Language' ,'TotalViews', 'TotalComments', 'TotalVotes', \"DisplayName\",\"UserName\"]]\n\n\ndef best_kernels(tokens, n = 10, ignore = []):\n    response = get_kernels(tokens, n, ignore)     \n    hs = \"\"\"<style>\n                .rendered_html tr {font-size: 12px; text-align: left}\n            <\/style>\n            <h3><font color=\"#1768ea\">\"\"\"+tokens[0].title()+\"\"\"<\/font><\/h3>\n            <table>\n            <th>\n                <td><b>Kernel Title<\/b><\/td>\n                <td><b>Author<\/b><\/td>\n                <td><b>Language<\/b><\/td>\n                <td><b>Total Views<\/b><\/td>\n                <td><b>Total Comments<\/b><\/td>\n                <td><b>Total Votes<\/b><\/td>\n            <\/th>\"\"\"\n    for i, row in response.iterrows():\n        url = \"https:\/\/www.kaggle.com\/\"+row['UserName']+\"\/\"+row['CurrentUrlSlug']\n        aurl= \"https:\/\/www.kaggle.com\/\"+row['UserName']\n        hs += \"\"\"<tr>\n                    <td>\"\"\"+str(i+1)+\"\"\"<\/td>\n                    <td><a href=\"\"\"+url+\"\"\" target=\"_blank\"><b>\"\"\"  + row['Title'] + \"\"\"<\/b><\/a><\/td>\n                    <td><a href=\"\"\"+aurl+\"\"\" target=\"_blank\">\"\"\"  + row['DisplayName'] + \"\"\"<\/a><\/td>\n                    <td>\"\"\"+str(row['Language'])+\"\"\"<\/td>\n                    <td>\"\"\"+str(row['TotalViews'])+\"\"\"<\/td>\n                    <td>\"\"\"+str(row['TotalComments'])+\"\"\"<\/td>\n                    <td>\"\"\"+str(row['TotalVotes'])+\"\"\"<\/td>\n                    <\/tr>\"\"\"\n    hs += \"<\/table>\"\n    display(HTML(hs))","abbdd87b":"tokens = [\"linear regression\"]\nbest_kernels(tokens, 10)","6f3e0d4f":"tokens = ['logistic regression', \"logistic\"]\nbest_kernels(tokens, 10)","069e6fa1":"tokens = ['Ridge']\nbest_kernels(tokens, 10)","d546812f":"tokens = ['Lasso']\nbest_kernels(tokens, 10)","dcbec97b":"tokens = ['ElasticNet']\nbest_kernels(tokens, 4)","119c34cf":"tokens = ['Decision Tree']\nbest_kernels(tokens, 10)","23b34a2d":"tokens = ['random forest']\nbest_kernels(tokens, 10)","9f280008":"tokens = ['lightgbm', 'light gbm', 'lgb']\nbest_kernels(tokens, 10)","33f33bcd":"tokens = ['xgboost', 'xgb']\nbest_kernels(tokens, 10)","7e5b3ce1":"tokens = ['catboost']\nbest_kernels(tokens, 10)","ee4800fe":"tokens = ['neural network']\nbest_kernels(tokens, 10)","d5b5c253":"tokens = ['autoencoder']\nbest_kernels(tokens, 10)","1473d106":"tokens = ['deep learning']\nbest_kernels(tokens, 10)","dffc3dc5":"tokens = ['convolutional neural networks', 'cnn']\nbest_kernels(tokens, 10)","8a834f66":"tokens = ['lstm']\nbest_kernels(tokens, 10)","9a74f9e6":"tokens = ['gru']\nignore = ['grupo']\nbest_kernels(tokens, 10, ignore)","51fb309a":"tokens = ['mxnet']\nbest_kernels(tokens, 10)","78a5754c":"tokens = ['resnet']\nbest_kernels(tokens, 10)","e266d7e3":"tokens = ['Capsule network', 'capsulenet']\nbest_kernels(tokens, 5)","895cf5f6":"tokens = ['vgg']\nbest_kernels(tokens, 5)","4c3a9435":"tokens = ['inception']\nbest_kernels(tokens, 5)","c4ac3636":"tokens = ['computer vision']\nbest_kernels(tokens, 5)","809a3939":"tokens = ['transfer learning']\nbest_kernels(tokens, 5)","29137071":"tokens = ['kmeans', 'k means']\nbest_kernels(tokens, 10)","41e3620a":"tokens = ['hierarchical clustering']\nbest_kernels(tokens, 3)","46c3a767":"tokens = ['dbscan']\nbest_kernels(tokens, 10)","f1a49a0e":"tokens = ['unsupervised']\nbest_kernels(tokens, 10)","2b41e1fb":"tokens = ['naive bayes']\nbest_kernels(tokens, 10)","30a0e4fb":"tokens = ['svm']\nbest_kernels(tokens, 10)","b68a4615":"tokens = ['knn']\nbest_kernels(tokens, 10)","5868589b":"tokens = ['recommendation engine']\nbest_kernels(tokens, 5)","ef6449b0":"tokens = ['EDA', 'exploration']\nbest_kernels(tokens, 10)","fd678d8d":"tokens = ['feature engineering']\nbest_kernels(tokens, 10)","dcbabf05":"tokens = ['feature selection']\nbest_kernels(tokens, 10)","7732eb19":"tokens = ['outlier treatment', 'outlier']\nbest_kernels(tokens, 10)","57503f4d":"tokens = ['anomaly detection', 'anomaly']\nbest_kernels(tokens, 8)","e72a5ea6":"tokens = ['smote']\nbest_kernels(tokens, 5)","a45fd49c":"tokens = ['pipeline']\nbest_kernels(tokens, 10)","d005b9e1":"tokens = ['dataset decomposition', 'dimentionality reduction']\nbest_kernels(tokens, 2)","44c51349":"tokens = ['PCA']\nbest_kernels(tokens, 10)","fc7f10e5":"tokens = ['Tsne', 't-sne']\nbest_kernels(tokens, 10)","fc0476ca":"tokens = ['cross validation']\nbest_kernels(tokens, 10)","db7dc0bf":"tokens = ['model selection']\nbest_kernels(tokens, 10)","f6318c4e":"tokens = ['model tuning', 'tuning']\nbest_kernels(tokens, 10)","36822e17":"tokens = ['gridsearch', 'grid search']\nbest_kernels(tokens, 10)","3484e0dc":"tokens = ['ensemble']\nbest_kernels(tokens, 10)","74752221":"tokens = ['stacking', 'stack']\nbest_kernels(tokens, 10)","557d4748":"tokens = ['bagging']\nbest_kernels(tokens, 10)","a6478d5c":"tokens = ['NLP', 'Natural Language Processing', 'text mining']\nbest_kernels(tokens, 10)","37f11b1a":"tokens = ['topic modelling']\nbest_kernels(tokens, 8)","82bd1884":"tokens = ['word embedding','fasttext', 'glove', 'word2vec']\nbest_kernels(tokens, 8)","26892de9":"tokens = ['scikit']\nbest_kernels(tokens, 10)","ba808644":"tokens = ['tensorflow', 'tensor flow']\nbest_kernels(tokens, 10)","549cfa82":"tokens = ['theano']\nbest_kernels(tokens, 10)","b84c5021":"tokens = ['keras']\nbest_kernels(tokens, 10)","17c6023a":"tokens = ['pytorch']\nbest_kernels(tokens, 10)","61f84f55":"tokens = ['vowpal wabbit','vowpalwabbit']\nbest_kernels(tokens, 10)","8d901d01":"tokens = ['eli5']\nbest_kernels(tokens, 10)","9e187d42":"tokens = ['hyperopt']\nbest_kernels(tokens, 5)","10b0ad07":"tokens = ['pandas']\nbest_kernels(tokens, 10)","eb9520dd":"tokens = ['SQL']\nbest_kernels(tokens, 10)","104cc70c":"tokens = ['bigquery', 'big query']\nbest_kernels(tokens, 10)","792a0c41":"tokens = ['visualization', 'visualisation']\nbest_kernels(tokens, 10)","a250f7f7":"tokens = ['plotly', 'plot.ly']\nbest_kernels(tokens, 10)","2a616ece":"tokens = ['seaborn']\nbest_kernels(tokens, 10)","65fcb49a":"tokens = ['d3.js']\nbest_kernels(tokens, 4)","c997e674":"tokens = ['bokeh']\nbest_kernels(tokens, 10)","5b0c1f2d":"<br>\nThanks for viewing. Suggest the list of items which can be added to the list. If you liked this kernel, please upvote.  \n","f84282c1":"## 8. Text Data","252f70b4":"## 10. Data Visualization","f105aaa0":"## 5. Clustering Algorithms ","0a68d06b":"# Data Science Glossary on Kaggle\n\nKaggle is the place to do data science projects. There are so many algorithms and concepts to learn. Kaggle Kernels are one of the best resources on internet to understand the practical implementation of algorithms. There are almost 200,000 kernels published on kaggle and sometimes it becomes diffcult to search for the right implementation. I have used the [Meta Kaggle](https:\/\/www.kaggle.com\/kaggle\/meta-kaggle) database to create a glossary of data science models, techniques and tools shared on kaggle kernels. One can use this kernel as the one place to find other great kernels shared by great authors. Hope you like this kernel. \n\n## 1. Regression Algorithms\n","90a94e3d":"## 7. Important Data Science Techniques","4ea1fbe2":"## 6. Misc - Models ","2fbc6a91":"### 7.2 Dimentionality Reduction","d2bd2cfb":"### 7.4 Ensemblling","fd0e7118":"## 4. Neural Networks and Deep Learning Models","5e724174":"## 2. Regularization Algorithms","b72157e0":"### 7.3 Post Modelling Techniques","6ba5e479":"## 3. Tree Based Models","1829ea37":"### 7.1 Preprocessing","769317a7":"## 9. Data Science Tools"}}