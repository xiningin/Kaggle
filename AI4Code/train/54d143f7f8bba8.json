{"cell_type":{"a997f556":"code","f7862e86":"code","0ff90756":"code","5748583b":"code","4ed6a275":"code","c9eeb0f6":"code","9b043acc":"code","ed5871df":"code","305d8047":"code","5a54df9c":"code","c49f3ff4":"code","0927bfce":"code","8b6bfd64":"code","476078b8":"code","3c88cc4a":"code","93171a84":"code","5567f60b":"code","dd0fe3ec":"code","27c5b987":"code","4622b270":"code","cefd2886":"code","233921ed":"code","cc25af27":"code","62ec62c9":"code","ed33a27e":"code","f2b8201e":"code","0aa8d9ae":"code","eabfa9c7":"code","d8066696":"code","450626dc":"code","9fcbf29a":"code","7fd6e282":"code","b10d8a6f":"code","38975998":"code","8cf1fdc6":"code","624639bc":"markdown","e9d3aa71":"markdown","2f536132":"markdown","978b030c":"markdown","003cebb2":"markdown","07ab6ae8":"markdown","4716130d":"markdown","b1d6123c":"markdown","1b3d082b":"markdown","b9a3505c":"markdown","3c2be9d1":"markdown","bd9021d1":"markdown","78554231":"markdown","839a12ee":"markdown","08a33897":"markdown","2346f871":"markdown","a1f7189a":"markdown","39cd7ec7":"markdown","3dc7f7f5":"markdown","99e0b52c":"markdown","a05e973e":"markdown","adeb9d48":"markdown","c4458d80":"markdown","f7e43c15":"markdown","29c8b537":"markdown","62fb183b":"markdown","af1a6400":"markdown","d5ec4441":"markdown","2c68122d":"markdown","cd49aa91":"markdown","f57bdf69":"markdown","44525b90":"markdown","221bb98b":"markdown","f2386734":"markdown","e02edcda":"markdown","d304c70e":"markdown","e0d5aac0":"markdown","ef962a12":"markdown"},"source":{"a997f556":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\n\n# Matplotlib and seaborn for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Scipy for statistics\n#import scipy\n\n\nfrom sklearn.metrics import mean_absolute_error,r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model","f7862e86":"# Dataframe to models\ndf_model_properties = pd.DataFrame({\n    'Model':['linear_t','quad_t','SPPM_t','DPPM_t',\n             'multlin_th','multquad_th','power_th',\n             'multlin_tht','multquad_tht',\n             'multlin_all','multquad_all',\n             'multcub_all',\n             'multquart_all'],\n    \n    'Features': [['t'],['t'],['t'],['t'],['t','h'],\n                 ['t','h'],['t','h'],['t','h','T'],\n                 ['t','h','T'],['t','h','T','A','W','H'],\n                 ['t','h','T','A','W','G','H'],\n                 ['t','h','T','A','W','G','H'],\n                 ['t','h','T','A','W','G','H']],\n    'MAE_test':['','','','','','','','','','','','',''],\n    'R2_test':['','','','','','','','','','','','',''],\n    'MAE_train':['','','','','','','','','','','','',''],\n    'R2_train':['','','','','','','','','','','','','']\n}).set_index('Model')","0ff90756":"# Import Calories Dataset\ndf_cal = pd.read_csv(os.path.join(dirname,'calories.csv'))\n\n# Import Exercises Dataset\ndf_ex  = pd.read_csv(os.path.join(dirname,'exercise.csv'))\n\n# Merging Datasets\ndf = pd.merge(df_ex, df_cal, on = 'User_ID')\ndf.head()\n\n# Get dummies\ndf['Gender'] = pd.get_dummies(df['Gender'], prefix_sep='_', drop_first=True)\ndf.head()","5748583b":"correlations = df.drop(columns=['User_ID'],axis=1).copy().corr()['Calories']\ncorrelations = correlations.sort_values(ascending=False).drop('Calories',axis=0)\nprint(correlations)\ncorrelations.to_frame().plot.bar();","4ed6a275":"df_3f = df[['Duration','Heart_Rate','Body_Temp','Calories']].copy()\ndf_3f.rename(columns={'Duration':'t',\n                      'Heart_Rate':'h',\n                      'Body_Temp':'T',\n                      'Calories':'C'},inplace=True)\n\n\ndf_6f = df[['Duration','Heart_Rate','Body_Temp','Age','Weight','Height','Calories']].copy()\ndf_6f.rename(columns={'Duration':'t',\n                      'Heart_Rate':'h',\n                      'Body_Temp':'T',\n                      'Age':'A',\n                      'Weight':'W',\n                      'Height':'H',\n                      'Calories':'C'},inplace=True)\n\n\ndf_7f = df[['Duration','Heart_Rate','Body_Temp','Age','Weight','Gender','Height','Calories']].copy()\ndf_7f.rename(columns={'Duration':'t',\n                      'Heart_Rate':'h',\n                      'Body_Temp':'T',\n                      'Age':'A',\n                      'Weight':'W',\n                      'Gender':'G',\n                      'Height':'H',\n                      'Calories':'C'},inplace=True)\n\nsns.pairplot(df_3f)","c9eeb0f6":"conditions = True\nconditions &= df_3f['C'] > 0\nconditions &= df_3f['t'] > 0\n\ndf_3f_log = np.log10(df_3f[conditions]).copy()\n\ndf_3f_log.rename(columns={'t':'log_t',\n                      'h':'log_h',\n                      'T':'log_T',\n                      'C':'log_C'},inplace=True)\n\nsns.pairplot(df_3f_log)","9b043acc":"# Splitting into test and train\n\nC_i = df_3f['C'].to_numpy()\nt_i = df_3f['t'].to_numpy()\nt_train, t_test, C_train, C_test = train_test_split(t_i, C_i, test_size=0.333, random_state=42)\n\nlogC_i = df_3f_log['log_C'].to_numpy()\nlogt_i = df_3f_log['log_t'].to_numpy()\nlogt_train, logt_test, logC_train, logC_test = train_test_split( logt_i, logC_i, test_size=0.333, random_state=42)","ed5871df":"plt.figure(figsize=(8,8))\nplt.scatter(df_3f['t'],df_3f['C'])\nplt.xlabel('$t$ (min)', size = 18)\nplt.ylabel('$C$ (kcal)', size = 18)\nplt.title('Calories burned vs Duration of Exercise', size = 20)\nplt.show()","305d8047":"# Create a lineat regression object\nlin_reg = linear_model.LinearRegression()\n\n# Train the model using the training sets\nlin_reg.fit(t_train.reshape(-1,1)   ,C_train.reshape(-1,1))\n\n# Selecting a interval for duration\nt_val = np.linspace(t_i.min(),t_i.max(),100)\n\n# Predicting\nC_lin_model = lin_reg.predict(t_val.reshape(-1,1))\n\n# Plotting and comparing\nplt.figure(figsize=(8, 8))\nplt.scatter(df['Duration'],df['Calories'],c='lightgray',label = 'observations',alpha = 0.6,marker='.',zorder=1)\nplt.plot(t_val,C_lin_model, c='tab:red',ls='-.', label = 'Linear Model', lw = 3,zorder=2)\nplt.xlabel('Duration (min)', size = 18)\nplt.ylabel('Calories', size = 18); \nplt.legend(prop={'size': 16})\nplt.title('Calories burned vs Duration of Exercise', size = 20);","5a54df9c":"# Predictions for the test set\nC_lin_test = lin_reg.predict(t_test.reshape(-1,1))\n\n# Predictions for the train set\nC_lin_train = lin_reg.predict(t_train.reshape(-1,1))\n\n# Filling dataframe\ndf_model_properties.loc['linear_t']['MAE_test'] = mean_absolute_error(C_lin_test,C_test)\ndf_model_properties.loc['linear_t']['R2_test'] = r2_score(C_lin_test,C_test)\ndf_model_properties.loc['linear_t']['MAE_train'] = mean_absolute_error(C_lin_train,C_train)\ndf_model_properties.loc['linear_t']['R2_train'] = r2_score(C_lin_train,C_train)\n\n# Printing  results\nprint('Mean error (test): ',df_model_properties.loc['linear_t']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['linear_t']['R2_test'])\n\n\nprint('\\nMean error (train): ',df_model_properties.loc['linear_t']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['linear_t']['R2_train'])\n","c49f3ff4":"from sklearn import linear_model\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Create a linear regression object\nquad_reg = linear_model.LinearRegression()\n\n# Reshaping feature\nT_train = t_train.reshape(-1,1)\n\n# Transfomr features to a polynomial regression\nquad = PolynomialFeatures(degree=2)\nT_train_quad = quad.fit_transform(T_train)\n\n# Training\nquad_reg.fit(T_train_quad ,C_train.reshape(-1,1))\n\n# Selecting a interval for duration an adapting shape\nT_val = np.linspace(t_i.min(),t_i.max(),100).reshape(-1,1)\nT_val_quad = quad.fit_transform(T_val)\n\n# Predicting values\nC_quad_model = quad_reg.predict(T_val_quad)\n\n# Plotting\nplt.figure(figsize=(8, 8))\nplt.scatter(df['Duration'],df['Calories'],c='lightgray',label = 'observations',alpha = 0.6,marker='.',zorder=1)\nplt.plot(t_val,C_quad_model, label = 'Quadratic Model', c='tab:blue', lw = 3,zorder=2)\nplt.xlabel('Duration (min)', size = 18)\nplt.ylabel('Calories', size = 18); \nplt.legend(prop={'size': 16})\nplt.title('Calories burned vs Duration of Exercise', size = 20);","0927bfce":"C_quad_test = quad_reg.predict(quad.fit_transform(t_test.reshape(-1,1)))\nC_quad_train = quad_reg.predict(quad.fit_transform(t_train.reshape(-1,1)))\n\ndf_model_properties.loc['quad_t']['MAE_test'] = mean_absolute_error(C_quad_test,C_test)\ndf_model_properties.loc['quad_t']['R2_test'] = r2_score(C_quad_test,C_test)\ndf_model_properties.loc['quad_t']['MAE_train'] = mean_absolute_error(C_quad_train,C_train)\ndf_model_properties.loc['quad_t']['R2_train'] = r2_score(C_quad_train,C_train)\n\n\nprint('Mean error (test): ',df_model_properties.loc['quad_t']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['quad_t']['R2_test'])\n\n\nprint('\\nMean error (train): ',df_model_properties.loc['quad_t']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['quad_t']['R2_train'])\n","8b6bfd64":"plt.figure(figsize=(8, 8))\nplt.scatter(df['Duration'],df['Calories'],c='lightgray',label = 'observations',alpha = 0.6,marker='.',zorder=1)\nplt.plot(t_val,C_lin_model, c='tab:red',ls='-.', label = 'Linear Model', lw = 3,zorder=2)\nplt.plot(t_val,C_quad_model, label = 'Quadratic Model', c='tab:blue', lw = 3,zorder=2)\nplt.xlabel('Duration (min)', size = 18)\nplt.ylabel('Calories', size = 18); \nplt.legend(prop={'size': 16})\nplt.title('Calories burned vs Duration of Exercise', size = 20);","476078b8":"plt.figure(figsize=(8,8))\nplt.scatter(df_3f_log['log_t'],df_3f_log['log_C'])\nplt.xlabel('$t$ (min)', size = 18)\nplt.ylabel('$C$ (kcal)', size = 18)\nplt.title('Calories burned vs Duration of Exercise', size = 20)\nplt.show()","3c88cc4a":"# In fact, this is the only calculation for this method\nc_1 = np.dot(logC_train,logt_train)\/np.dot(logt_train,logt_train)\n\nprint('The value of c_1 is: ',c_1)\n\n# With the value of c1, its possible to define a predict function\ndef sing_par_predict(t,c1 = c_1):\n    return np.power(t,c1) ","93171a84":"t_val = np.linspace(t_i.min(),t_i.max(),100)\nC_sing = sing_par_predict(t_val)\n\nplt.figure(figsize=(8, 8))\nplt.scatter(df['Duration'],df['Calories'],c='lightgray',label = 'Observations',alpha = 0.6,marker='.',zorder=1)\nplt.plot(t_val,C_sing, c='tab:green',ls='-', label = 'SPPM', linewidth = 3)\nplt.xlabel('Duration (min)', size = 18)\nplt.ylabel('Calories', size = 18); \nplt.legend(prop={'size': 16})\nplt.title('Calories burned vs Duration of Exercise', size = 20);","5567f60b":"C_sppm_test = sing_par_predict(t_test)\nC_sppm_train = sing_par_predict(t_train)\n\ndf_model_properties.loc['SPPM_t']['MAE_test'] = mean_absolute_error(C_sppm_test,C_test)\ndf_model_properties.loc['SPPM_t']['R2_test'] = r2_score(C_sppm_test,C_test)\ndf_model_properties.loc['SPPM_t']['MAE_train'] = mean_absolute_error(C_sppm_train,C_train)\ndf_model_properties.loc['SPPM_t']['R2_train'] = r2_score(C_sppm_train,C_train)\n\nprint('Mean error (test): ',df_model_properties.loc['SPPM_t']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['SPPM_t']['R2_test'])\n\n\nprint('\\nMean error (train): ',df_model_properties.loc['SPPM_t']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['SPPM_t']['R2_train'])\n","dd0fe3ec":"# Create a linear regression object\nlog_reg = linear_model.LinearRegression()\n\n# Train the model using the training sets\nlog_reg.fit(logt_train.reshape(-1,1),logC_train.reshape(-1,1))\n\nlogC_pred = log_reg.predict(logt_test.reshape(-1,1))\n\ndef dbl_par_predict(t):\n    logt = np.log10(t)\n    return  np.power(10,log_reg.predict(logt)) ","27c5b987":"t_val = np.linspace(t_i.min(),t_i.max(),100)\nC_log_model = dbl_par_predict(t_val.reshape(-1,1))\nplt.figure(figsize=(8, 8))\nplt.scatter(df['Duration'],df['Calories'],c='lightgray',label = 'observations',alpha = 0.6,marker='.',zorder=1)\nplt.plot(t_val,C_log_model, c='tab:blue',ls='--', label = 'DPPM', lw = 3,zorder=2)\nplt.xlabel('Duration (min)', size = 18)\nplt.ylabel('Calories', size = 18); \nplt.legend(prop={'size': 16})\nplt.title('Calories burned vs Duration of Exercise', size = 20);","4622b270":"C_dppm_test = dbl_par_predict(t_test.reshape(-1,1))\nC_dppm_train = dbl_par_predict(t_train.reshape(-1,1))\n\n\ndf_model_properties.loc['DPPM_t']['MAE_test'] = mean_absolute_error(C_dppm_test,C_test)\ndf_model_properties.loc['DPPM_t']['R2_test'] = r2_score(C_dppm_test,C_test)\ndf_model_properties.loc['DPPM_t']['MAE_train'] = mean_absolute_error(C_dppm_train,C_train)\ndf_model_properties.loc['DPPM_t']['R2_train'] = r2_score(C_dppm_train,C_train)\n\n\nprint('Mean error (test): ',df_model_properties.loc['DPPM_t']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['DPPM_t']['R2_test'])\n\n\nprint('\\nMean error (train): ',df_model_properties.loc['DPPM_t']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['DPPM_t']['R2_train'])\n","cefd2886":"t_val = np.linspace(t_i.min(),t_i.max(),100)\nC_lin_model = lin_reg.predict(t_val.reshape(-1,1))\nC_log_model = dbl_par_predict(t_val.reshape(-1,1))\nplt.figure(figsize=(8, 8))\nplt.scatter(df['Duration'],df['Calories'],c='lightgray',label = 'observations',alpha = 0.6,marker='.',zorder=1)\nplt.plot(t_val,C_sing, c='tab:green',ls='-', label = 'SPPM', lw = 3,zorder=2)\nplt.plot(t_val,C_log_model, c='tab:blue',ls='--', label = 'DPPM', lw = 3,zorder=2)\nplt.plot(t_val,C_lin_model, c='tab:red',ls='-.', label = 'Linear Model', lw = 3,zorder=2)\nplt.plot(t_val,C_quad_model, label = 'Quadratic Model', c='tab:purple', lw = 3,zorder=2)\nplt.xlabel('Duration (min)', size = 18)\nplt.ylabel('Calories', size = 18); \nplt.legend(prop={'size': 16})\nplt.title('Calories burned vs Duration of Exercise', size = 20);","233921ed":"# Organization of dataset\nTH_i = df_3f[['t','h']].to_numpy()\nC_i = df_3f['C'].to_numpy().reshape(-1,1)\nTH_trn, TH_tst, C_trn, C_tst = train_test_split( TH_i,C_i, test_size=0.333, random_state=42)\n\n# Organization of log dataset\nlogTH_i = df_3f_log[['log_t','log_h']].to_numpy()\nlogC_i = df_3f_log['log_C'].to_numpy().reshape(-1,1)\nlogTH_trn, logTH_tst, logC_trn, logC_tst = train_test_split(logTH_i,logC_i,test_size=0.333, random_state=42)","cc25af27":"# Create regression object\nML2 = linear_model.LinearRegression()\n\n# Train the model using the training sets\nML2.fit(TH_trn,C_trn)\n\n# Predicting for test and train\nC_ml2_tst = ML2.predict(TH_tst)\nC_ml2_trn = ML2.predict(TH_trn)\n\n# Updating results dataframe\ndf_model_properties.loc['multlin_th']['MAE_test'] = mean_absolute_error(C_tst,C_ml2_tst)\ndf_model_properties.loc['multlin_th']['R2_test'] = r2_score(C_tst,C_ml2_tst)\ndf_model_properties.loc['multlin_th']['MAE_train'] = mean_absolute_error(C_trn,C_ml2_trn)\ndf_model_properties.loc['multlin_th']['R2_train'] = r2_score(C_trn,C_ml2_trn)\n\n# Showing\nprint('Mean error (test): ',df_model_properties.loc['multlin_th']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multlin_th']['R2_test'])\nprint('\\nMean error (train): ',df_model_properties.loc['multlin_th']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multlin_th']['R2_train'])\n","62ec62c9":"MQ2 = linear_model.LinearRegression()\n\nMQ2_poly = PolynomialFeatures(degree=2)\n\nTH_trn_pl = MQ2_poly.fit_transform(TH_trn)\n\nTH_tst_pl = MQ2_poly.fit_transform(TH_tst)\n\nMQ2.fit(TH_trn_pl,C_trn)\n\nC_mq2_tst = MQ2.predict(TH_tst_pl)\n\nC_mq2_trn = MQ2.predict(TH_trn_pl)\n\ndf_model_properties.loc['multquad_th']['MAE_test'] = mean_absolute_error(C_tst,C_mq2_tst)\ndf_model_properties.loc['multquad_th']['R2_test'] = r2_score(C_tst,C_mq2_tst)\ndf_model_properties.loc['multquad_th']['MAE_train'] = mean_absolute_error(C_trn,C_mq2_trn)\ndf_model_properties.loc['multquad_th']['R2_train'] = r2_score(C_trn,C_mq2_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multquad_th']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multquad_th']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multquad_th']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multquad_th']['R2_train'])\n","ed33a27e":"MP1 = linear_model.LinearRegression()\n\nMP1.fit(logTH_trn,logC_trn)\n\ndef power_pth_predict(TH):\n    logTH = np.log10(TH)\n    return  np.power(10,MP1.predict(logTH))","f2b8201e":"C_mp1_tst = power_pth_predict(TH_tst)\nC_mp1_trn = power_pth_predict(TH_trn)\n\ndf_model_properties.loc['power_th']['MAE_test'] = mean_absolute_error(C_tst,C_mp1_tst)\ndf_model_properties.loc['power_th']['R2_test'] = r2_score(C_tst,C_mp1_tst)\n\ndf_model_properties.loc['power_th']['MAE_train'] = mean_absolute_error(C_trn,C_mp1_trn)\ndf_model_properties.loc['power_th']['R2_train'] = r2_score(C_trn,C_mp1_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['power_th']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['power_th']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['power_th']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['power_th']['R2_train'])\n","0aa8d9ae":"THT_i = df_3f[['t','h','T']].to_numpy()\nC_i = df_3f['C'].to_numpy().reshape(-1,1)\nTHT_trn, THT_tst, C_trn, C_tst = train_test_split( THT_i,C_i, test_size=0.333, random_state=42)\n\nlogTHT_i = df_3f_log[['log_t','log_h','log_T']].to_numpy()\nlogC_i = df_3f_log['log_C'].to_numpy().reshape(-1,1)\nlogTHT_trn, logTHT_tst, logC_trn, logC_tst = train_test_split(logTHT_i,logC_i,test_size=0.333, random_state=42)","eabfa9c7":"# Create regression object\nML3 = linear_model.LinearRegression()\n\n# Train the model using the training sets\nML3.fit(THT_trn,C_trn)\n\nC_ml3_tst = ML3.predict(THT_tst)\nC_ml3_trn = ML3.predict(THT_trn)\n\n\ndf_model_properties.loc['multlin_tht']['MAE_test'] = mean_absolute_error(C_tst,C_ml3_tst)\ndf_model_properties.loc['multlin_tht']['R2_test'] = r2_score(C_tst,C_ml3_tst)\n\ndf_model_properties.loc['multlin_tht']['MAE_train'] = mean_absolute_error(C_trn,C_ml3_trn)\ndf_model_properties.loc['multlin_tht']['R2_train'] = r2_score(C_trn,C_ml3_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multlin_tht']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multlin_tht']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multlin_tht']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multlin_tht']['R2_train'])","d8066696":"# Create regression object\nMQ3 = linear_model.LinearRegression()\n\nMQ3_poly = PolynomialFeatures(degree=2)\nTHT_trn_pl = MQ3_poly.fit_transform(THT_trn)\nTHT_tst_pl = MQ3_poly.fit_transform(THT_tst)\n\n\n# Train the model using the training sets\nMQ3.fit(THT_trn_pl,C_trn)\n\nC_mq3_tst = MQ3.predict(THT_tst_pl)\nC_mq3_trn = MQ3.predict(THT_trn_pl)\n\ndf_model_properties.loc['multquad_tht']['MAE_test'] = mean_absolute_error(C_tst,C_mq3_tst)\ndf_model_properties.loc['multquad_tht']['R2_test'] = r2_score(C_tst,C_mq3_tst)\n\ndf_model_properties.loc['multquad_tht']['MAE_train'] = mean_absolute_error(C_trn,C_mq3_trn)\ndf_model_properties.loc['multquad_tht']['R2_train'] = r2_score(C_trn,C_mq3_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multquad_tht']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multquad_tht']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multquad_tht']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multquad_tht']['R2_train'])\n","450626dc":"X_i = df_7f[['t','h','T','A','W','G','H']].to_numpy()\nC_i = df_7f['C'].to_numpy().reshape(-1,1)\nX_trn, X_tst, C_trn, C_tst = train_test_split( X_i,C_i, test_size=0.333, random_state=42)","9fcbf29a":"# Create regression object\nML6 = linear_model.LinearRegression()\n\n# Train the model using the training sets\nML6.fit(X_trn,C_trn)\n\nC_ml6_tst = ML6.predict(X_tst)\nC_ml6_trn = ML6.predict(X_trn)\n\n\ndf_model_properties.loc['multlin_all']['MAE_test'] = mean_absolute_error(C_tst,C_ml6_tst)\ndf_model_properties.loc['multlin_all']['R2_test'] = r2_score(C_tst,C_ml6_tst)\n\ndf_model_properties.loc['multlin_all']['MAE_train'] = mean_absolute_error(C_trn,C_ml6_trn)\ndf_model_properties.loc['multlin_all']['R2_train'] = r2_score(C_trn,C_ml6_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multlin_all']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multlin_all']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multlin_all']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multlin_all']['R2_train'])","7fd6e282":"# Create regression object\nMQ6 = linear_model.LinearRegression()\n\nMQ6_poly = PolynomialFeatures(degree=2)\nX_trn_pl = MQ6_poly.fit_transform(X_trn)\nX_tst_pl = MQ6_poly.fit_transform(X_tst)\n\n\n# Train the model using the training sets\nMQ6.fit(X_trn_pl,C_trn)\n\nC_mq6_tst = MQ6.predict(X_tst_pl)\nC_mq6_trn = MQ6.predict(X_trn_pl)\n\ndf_model_properties.loc['multquad_all']['MAE_test'] = mean_absolute_error(C_tst,C_mq6_tst)\ndf_model_properties.loc['multquad_all']['R2_test'] = r2_score(C_tst,C_mq6_tst)\n\ndf_model_properties.loc['multquad_all']['MAE_train'] = mean_absolute_error(C_trn,C_mq6_trn)\ndf_model_properties.loc['multquad_all']['R2_train'] = r2_score(C_trn,C_mq6_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multquad_all']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multquad_all']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multquad_all']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multquad_all']['R2_train'])\n","b10d8a6f":"# Create regression object\nMQ6 = linear_model.LinearRegression()\n\nMQ6_poly = PolynomialFeatures(degree=3)\nX_trn_pl = MQ6_poly.fit_transform(X_trn)\nX_tst_pl = MQ6_poly.fit_transform(X_tst)\n\n\n# Train the model using the training sets\nMQ6.fit(X_trn_pl,C_trn)\n\nC_mq6_tst = MQ6.predict(X_tst_pl)\nC_mq6_trn = MQ6.predict(X_trn_pl)\n\ndf_model_properties.loc['multcub_all']['MAE_test'] = mean_absolute_error(C_tst,C_mq6_tst)\ndf_model_properties.loc['multcub_all']['R2_test'] = r2_score(C_tst,C_mq6_tst)\n\ndf_model_properties.loc['multcub_all']['MAE_train'] = mean_absolute_error(C_trn,C_mq6_trn)\ndf_model_properties.loc['multcub_all']['R2_train'] = r2_score(C_trn,C_mq6_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multcub_all']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multcub_all']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multcub_all']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multcub_all']['R2_train'])\n","38975998":"# Create regression object\nMQ6 = linear_model.LinearRegression()\n\nMQ6_poly = PolynomialFeatures(degree=4)\nX_trn_pl = MQ6_poly.fit_transform(X_trn)\nX_tst_pl = MQ6_poly.fit_transform(X_tst)\n\n\n# Train the model using the training sets\nMQ6.fit(X_trn_pl,C_trn)\n\nC_mq6_tst = MQ6.predict(X_tst_pl)\nC_mq6_trn = MQ6.predict(X_trn_pl)\n\ndf_model_properties.loc['multquart_all']['MAE_test'] = mean_absolute_error(C_tst,C_mq6_tst)\ndf_model_properties.loc['multquart_all']['R2_test'] = r2_score(C_tst,C_mq6_tst)\n\ndf_model_properties.loc['multquart_all']['MAE_train'] = mean_absolute_error(C_trn,C_mq6_trn)\ndf_model_properties.loc['multquart_all']['R2_train'] = r2_score(C_trn,C_mq6_trn)\n\n\nprint('Mean error (test): ',df_model_properties.loc['multquart_all']['MAE_test'])\nprint('R2 (test):    ',df_model_properties.loc['multquart_all']['R2_test'])\n\nprint('\\nMean error (train): ',df_model_properties.loc['multquart_all']['MAE_train'])\nprint('R2 (train):  ',df_model_properties.loc['multquart_all']['R2_train'])\n","8cf1fdc6":"df_model_properties","624639bc":"<a id=\"0202\"><\/a>\n<h2>2.b Quadratic Model<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","e9d3aa71":"### Scatter Matrix","2f536132":"### Features Influences on Calories","978b030c":"\nExpanding the formula for the errors:\n\n<center>$\n\\begin{align*}\nE_{\\text{MS}} & =\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\text{log}C-\\text{log}C_{i}\\right)^{2}=\\frac{1}{N}\\sum_{i=1}^{N}\\left(c_{1}\\log_{10}t_{i}-\\text{log}C_{i}\\right)^{2}\\\\\n & =c_{1}^{2}\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\log_{10}t_{i}\\right)^{2}-2c_{1}\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\log_{10}C_{i}\\right)\\left(\\log_{10}t_{i}\\right)+\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\text{log}C_{i}\\right)^{2}\n\\end{align*}\n$<\/center>\n\n\n \n\n\nApplying the minimization condition $(5)$:\n\n<center>$\n\\begin{align*}\n\\frac{\\partial E_{\\text{MS}}}{\\partial c_{1}} & =0\\\\\n2c_{1}\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\log_{10}t_{i}\\right)^{2}-2\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\log_{10}C_{i}\\right)\\left(\\log_{10}t_{i}\\right)+0 & =0\n\\end{align*}\n$<\/center>\n\nSo, the formula for $c_1$ is:\n<center>$\n\\begin{equation}\nc_{1}=\\frac{\\sum_{i=1}^{N}\\left(\\log_{10}C_{i}\\right)\\left(\\log_{10}t_{i}\\right)}{\\sum_{i=1}^{N}\\left(\\log_{10}t_{i}\\right)^{2}}\n\\label{eq:sim_log_par_0} \\tag{6}\n\\end{equation}\n$<\/center>\n\nWith the value of $c_1$, we have the mathematical expression relating calories and exercise duration:\n\n&nbsp;\n<center>$\\begin{equation}\n\\frac{C}{\\text{kcal}}=\\left(\\frac{t}{\\min}\\right)^{c_{1}} .\n\\end{equation}$<\/center>","003cebb2":"\n<a id=\"0501\"><\/a>\n<h2>5.a Linear Regression (6D)<a href=\"#05\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>\n","07ab6ae8":"<a id=\"0204\"><\/a>\n<h2>2.2 Model Comparison<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","4716130d":"<a id=\"toc\"><\/a>\n  \n  \n  <div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    <center>\n        <h2>Content<\/h2>\n    <\/center>\n\n   \n<ol>\n    <li><a href=\"#01\" style=\"color: #37509b;\">Pre-Processing<\/a><\/li>\n    <li><a href=\"#02\" style=\"color: #37509b;\">One Feature Regression<\/a><\/li>\n    <li><a href=\"#03\" style=\"color: #37509b;\">Double Feature Regression<\/a><\/li>\n    <li><a href=\"#04\" style=\"color: #37509b;\">Three Feature Regression<\/a><\/li>\n    <li><a href=\"#05\" style=\"color: #37509b;\">Regression with all Features<\/a><\/li>\n\n<\/ol>\n\n\n<\/div>","b1d6123c":"From the scatter graphics, it's possible to conclude that, despite the strong correlation between the variables $t$ and $C$, the relation between them is not trivially linear. It's possible that a quadratic regression approach can substantially reduce the errors. Another way to deal with this problem is with power law models. To do this, let's check the relation betweeen logs of variables.","1b3d082b":"From here, it is possible to see that the features that most contribute to the total calory burned on exercises is the 'duration', the 'heart rate' and the 'body temperature'\n\nLet's rename the variables as:\n\n* $t$ : Duration\n* $h$ : Heart_Rate\n* $T$ : Body_Temp\n* $A$ : Age\n* $W$ : Weight\n* $G$ : Gender\n* $H$ : Height\n* $C$ : Calories","b9a3505c":"To check if it is a good fit, lets import metrics from sklearn:","3c2be9d1":"\n\nIn this notebook, I applied different regression techniques to predict the data of calories burned in the exercises from the knowledge of duration (t), heart rate (h), body temperature (T), age (A), weight (W), height (H) and gender (G). It was verified that the variable that most influences the burning of calories is duration, followed by heart rate and body temperature. However, only with the considerations of all set of features that was possible to reduce the error to less than 1% of the mean. From the following table, we can see the models adopted an the mean error of each one.\n\n    \n| Regression Model | Mean Error | R2   |\n|-----------|------------|------|\n| Linear    | 13.59       | 0.904 |\n| Quadratic | 11.36       | 0.922 |\n| PowerLaw  | 12.02      | 0.895 |\n| Multi-Linear (t,H) | 11.67      | 0.94 |\n| Multi-Quadratic (t,H) | 8.29      | 0.96 |\n| Multi-PowerLaw (t,H) | 8.59      | 0.96 |\n| Multi-Linear (t,H,T) | 10.64      | 0.94 |\n| Multi-Quadratic (t,H,T) | 8.31      | 0.95 |\n| Multi-Linear (all feat.) | 8.44      | 0.97 |\n| Multi-Quadratic (all feat.) | 2.24      | 0.997 |\n| Multi-Cubic (all feat.) | 0.25      | 1.00 |\n| Multi-Quartic (all feat.) | 0.25      | 1.00 |\n    \n    \n","bd9021d1":"### 2.c.2 Double Parameter Power Model (DPPM)\u00b6","78554231":"### Report\n\n* From visual inspection of graphs, it was found that the three most correlated amounts to calories are respectively **Duration**, **Heart Rate** and **Body Temperature**.\n\n* The intial approach was to study only the influence of **Duration** (t) on **Calories**(C). To do this, it was proposed five different models:\n\n\n    \n| Model     | Mean Error | R2   |\n|-----------|------------|------|\n| Linear    | 13.59       | 0.904 |\n| Quadratic | 11.36       | 0.922 |\n| SPPM      | 14.11       | 0.919 |\n| DPPM      | 12.02      | 0.895 |\n| TPPM      | 11.40      | 0.919 |\n    \n\n\n* The linear regression model is the stardard approach when we observe a set of correlated 2-D data and will be used as comparison.\n\n* The Power Law models, although not linear, can be linearized considering $\\log_{10}t$ and $\\log_{10}C$ as feature and target.\n\n* The model SPPM is just a toy model. Since it has just 1 parameter, it was expected that its statistics were the worst. Although it showed a good value of R2, the error is significantly higher than those presented by the other models.\n\n*  The DPPM, as the linear regression, is a 2-parameter model. Observing that the mean error is lower than the error of linear regression, in this case, we can find benefits in use of the logs on the datasets.\n\n* **Quadratic regression** is the approach with lowest error and best R2","839a12ee":"<a id=\"0302\"><\/a>\n<h2>3.b Quadratic Regression (2D)<a href=\"#03\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","08a33897":"![](http:\/\/)In the approach of taking the logs of **Calories** and **Duration** columns, the resulting correlations aproximately linear and can be modeled by an affine relation, like Eq. $(1)$ ","2346f871":"<a id=\"0201\"><\/a>\n<h2>2.a Linear Model<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","a1f7189a":"<a id=\"05\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  <div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>5. Regression with all Features<\/h1>\n    \n<ol type=\"i\">\n    <li><a href=\"#0501\" style=\"color: #37509b;\">Linear Regression<\/a><\/li>\n    <li><a href=\"#0502\" style=\"color: #37509b;\">Quadratic Regression<\/a><\/li>\n    <li><a href=\"#0503\" style=\"color: #37509b;\">Cubic Regression<\/a><\/li>\n    <li><a href=\"#0504\" style=\"color: #37509b;\">Quartic Regression<\/a><\/li>\n<!--     <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li> -->\n\n<\/ol>\n<\/div>","39cd7ec7":"<a id=\"0504\"><\/a>\n<h2>5.d Quartic Regression (6D)<a href=\"#05\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>\n","3dc7f7f5":"<center>\n    <h1 style=\"font-family: Impact, sans-serif;\n           color: #094747;\n           background-image: linear-gradient(rgba(99,110,110,0.12), rgba(99,110,110,0.05));\n           font-size: 40px;\n           text-shadow: -1px 0 #fff, 0 1px #fff, 1px 0 #fff, 0 -1px #fff;\n        \">Calories Burned On Workout<\/h1>\n    <\/center>\n    \n## <center> (Regression Exercises) <\/center>\n\n![img-1](https:\/\/media.giphy.com\/media\/9GimADqtnpAPe\/giphy.gif)","99e0b52c":"<a id=\"03\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  <div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>3. Double Feature Regression<\/h1>\n    \n<ol type=\"i\">\n    <li><a href=\"#0301\" style=\"color: #37509b;\">Linear Regression (2D)<\/a><\/li>\n    <li><a href=\"#0302\" style=\"color: #37509b;\">Quadratic Regression (2D)<\/a><\/li>\n    <li><a href=\"#0303\" style=\"color: #37509b;\">Linear Regression on Log-Scaled Data<\/a><\/li>\n<!--     <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li> -->\n<!--     <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li> -->\n\n<\/ol>\n<\/div>\n","a05e973e":"\n<a id=\"0401\"><\/a>\n<h2>4.a Linear Regression (3D)<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","adeb9d48":"Compare the model with data. Not de logs, but the original dataset.","c4458d80":"<a id=\"0502\"><\/a>\n<h2>5.b Quadratic Regression (6D)<a href=\"#05\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>\n","f7e43c15":"<a id=\"0402\"><\/a>\n<h2>4.b Quadratic Regression (3D)<a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","29c8b537":"Proposing a linear correlation between these quantities is equivalent to:\n\n\n<center>\n$\\log_{10}\\left(\\frac{C}{\\text{kcal}}\\right)=c_{0}+c_{1}\\log_{10}\\left(\\frac{t}{\\min}\\right)\\label{eq:lin_model_log} \\tag{1}$\n<\/center>\n\nor:\n\n<center>\n$\\frac{C}{\\text{kcal}}=10^{c_{0}}\\left(\\frac{t}{\\min}\\right)^{c_{1}}\\label{eq:lin_model} \\tag{2}$\n<\/center>\n\nwhere $c_0$ is the linear coefficient and $c_1$ the slope of the line.\n","62fb183b":"<a id=\"0303\"><\/a>\n<h2>3.c Linear Regression on Log-Scaled Data<a href=\"#03\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","af1a6400":"### Import Dataset","d5ec4441":"<a id=\"0203\"><\/a>\n<h2>2.c Power Law Models<a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","2c68122d":"<a id=\"0503\"><\/a>\n<h2>5.c Cubic Regression (6D)<a href=\"#05\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>\n","cd49aa91":"<a id=\"02\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>2. One Feature Regression<\/h1>\n    \n<ol type=\"i\">\n    <li><a href=\"#0201\" style=\"color: #37509b;\">Linear Model<\/a><\/li>\n    <li><a href=\"#0202\" style=\"color: #37509b;\">Quadratic Model<\/a><\/li>\n    <li><a href=\"#0203\" style=\"color: #37509b;\">Power Law Models<\/a><\/li>\n    <li><a href=\"#0204\" style=\"color: #37509b;\">Model Comparison<\/a><\/li>\n<!--     <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li> -->\n\n<\/ol>\n<\/div>\n","f57bdf69":"## Comparison","44525b90":"<a id=\"01\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>1. Pre-Processing<\/h1>\n    \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicializa\u00e7\u00e3o<\/a><\/li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes<\/a><\/li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes<\/a><\/li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li>\n -->\n<\/ol>\n    \n    \n<\/div>\n","221bb98b":"    \n    \n![img-1](https:\/\/media.giphy.com\/media\/ZaMLw0FvXg29W\/giphy.gif)\n\n","f2386734":"### 2.c.1 Single Parameter Power Model (SPPM)","e02edcda":"An initial approach here is to fix $c_0 = 0$ in Eq.$(1)$, since that is intuitive that there are no calories burning if the exercise time is zero. But this is not the approach that guarantees the minimum error for regression. Just for fun, let's see what we could do if this consideration was taken seriously:\n\n<center>\n$\\log_{10}\\left(\\frac{C}{\\text{kcal}}\\right)=c_{1}\\log_{10}\\left(\\frac{t}{\\min}\\right)\\label{eq:sim_log_model} \\tag{3}$\n<\/center>\n\nFirst of all, we want to minimize the mean squared errors:\n\n<center>$E_{\\text{MS}}=\\frac{1}{N}\\sum_{i=1}^{N}\\left[\\log C(t_{i})-\\log C_{i}\\right]^{2}, \\label{eq:sim_log_model_err} \\tag{4}$<\/center>\n\n\nvanishing the partial derivative with respect to $c_1$:\n\n<center>$\\frac{\\partial E_{\\text{MS}}}{\\partial c_{1}}=0 .\\label{eq:sim_log_min} \\tag{5}$<\/center>","d304c70e":"\n<a id=\"04\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-left:35px; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    \n<h1>4. Three Feature Regression<\/h1>\n    \n<ol type=\"i\">\n    <li><a href=\"#0401\" style=\"color: #37509b;\">Linear Regression<\/a><\/li>\n    <li><a href=\"#0402\" style=\"color: #37509b;\">Quadratic Regression<\/a><\/li>\n<!--     <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes<\/a><\/li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li>\n -->\n<\/ol>\n<\/div>\n","e0d5aac0":"As a first step, let's calculate the regression relating **Calories** and **Duration**, that are the most correlated variables.","ef962a12":"<a id=\"0301\"><\/a>\n<h2>3.a Linear Regression (2D)<a href=\"#03\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>"}}