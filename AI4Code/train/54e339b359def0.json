{"cell_type":{"d3ddb5f1":"code","e70b9058":"code","42338e10":"code","fee02066":"code","4dc3793b":"code","03b306d1":"code","3caf8419":"code","ebc71d6a":"code","446167dd":"code","00d01926":"code","84a8226d":"code","0d50e65e":"code","736a29ef":"code","bed73dd4":"code","d79d9673":"code","7d14377b":"code","0679f0fd":"code","9c5cf367":"code","558e4334":"code","844870d1":"code","96c1de54":"code","4d810946":"code","a009a3f5":"code","5a9e4630":"code","7e3c2979":"code","7895be75":"code","582c9ff8":"code","84c0dad0":"code","00199f34":"code","03d723d7":"code","46342a7e":"code","32433799":"code","4dbecdea":"code","480da024":"code","1fdf2459":"code","bd5f6b21":"markdown","2cd6f01f":"markdown","a0520379":"markdown","db5fd0ce":"markdown","3d245fcf":"markdown","e066d305":"markdown","3aa2def5":"markdown","878ae402":"markdown","a1916ec6":"markdown","cdcdf57e":"markdown","20b0b28c":"markdown","136b00d5":"markdown","7090f005":"markdown","225f78af":"markdown","9103be23":"markdown","91dcc0b8":"markdown","d7fc3d71":"markdown","40f7d806":"markdown","bb671bb3":"markdown","1788d9cb":"markdown","c283501c":"markdown","d82d772b":"markdown","63d4f7e5":"markdown","8fc2e869":"markdown","989b537d":"markdown","7610d8cd":"markdown","93afff03":"markdown","ef3584c5":"markdown","3f91dd6e":"markdown","76a7b2e6":"markdown","a7491b91":"markdown"},"source":{"d3ddb5f1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","e70b9058":"df= pd.read_csv('..\/input\/sonar-dataset-suitable-for-classification\/sonar.all-data.csv')","42338e10":"pd.DataFrame([df.shape],index=['Sonar Dataset'],columns=['Rows','Columns'])","fee02066":"df.head()","4dc3793b":"df.info()","03b306d1":"df.isna().sum().sum()","3caf8419":"sns.countplot(data=df,x='Label')","ebc71d6a":"X=df.drop('Label',axis=1)\ny=df['Label']","446167dd":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 101)","00d01926":"from sklearn.preprocessing import StandardScaler","84a8226d":"scaler=StandardScaler()","0d50e65e":"scaler.fit(X_train)","736a29ef":"scaled_X_train=scaler.transform(X_train)\nscaled_X_test=scaler.transform(X_test)","bed73dd4":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_model=KNeighborsClassifier(n_neighbors=1)","d79d9673":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_model=KNeighborsClassifier(n_neighbors=1)\nknn_model.fit(scaled_X_train, y_train)","7d14377b":"y_pred=knn_model.predict(scaled_X_test)","0679f0fd":"pd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred})","9c5cf367":"from sklearn.metrics import classification_report,confusion_matrix, accuracy_score,precision_score,f1_score,recall_score","558e4334":" # calculate metrics\naccuracy=accuracy_score(y_test,y_pred)\nrecall=recall_score(y_test,y_pred, average=\"binary\", pos_label=\"M\")\nprecision=precision_score(y_test,y_pred, average=\"binary\", pos_label=\"M\")\nf1=f1_score(y_test,y_pred, average=\"binary\", pos_label=\"M\")","844870d1":"pd.DataFrame({'KNN Metrics': [accuracy, recall, precision,f1]}, index=['accuracy', 'recall', 'precision','f1'])","96c1de54":"test_error_rate=[]\nacc = []\nfor k in range(1,40):\n    knn_model=KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(scaled_X_train,y_train)\n    \n    y_pred_test=knn_model.predict(scaled_X_test)\n    accuracy=accuracy_score(y_test,y_pred_test)\n    acc.append(accuracy)\n    test_error_rate.append(1-accuracy)","4d810946":"plt.figure(figsize=(8,6))\nplt.plot(range(1,40),test_error_rate,label='Test Error',color='#00e68a', linestyle='dashed', marker='o',\n         markerfacecolor='#ff66cc', markersize=10)\nplt.annotate(text='Optimal K',\n            xy=(1, 0.1305),\n            fontsize=20,\n            xytext=(45, 60),\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle='->', color='red'),\n            bbox=dict(boxstyle='round', fc='0.8'))\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K Values')\nplt.ylabel('Error Rate')","a009a3f5":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n         marker='o',markerfacecolor='red', markersize=10)\nplt.title('Accuracy vs. K Value')\nplt.xlabel('K Values')\nplt.ylabel('Accuracy')","5a9e4630":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline","7e3c2979":"scaler=StandardScaler()\nknn_model=KNeighborsClassifier()","7895be75":"operations=[('scaler',scaler),('knn',knn_model)]\npipe=Pipeline(operations)","582c9ff8":"k_values=list(range(1,40))\nparam_grid={'knn__n_neighbors':k_values}","84c0dad0":"full_cv_classifier=GridSearchCV(pipe,param_grid,cv=5,scoring='accuracy')","00199f34":"full_cv_classifier.fit(scaled_X_train,y_train)","03d723d7":"full_cv_classifier.best_estimator_.get_params()","46342a7e":"print(f'Number of data points in training data is {len(X_train)}\\n')\nprint(f'K =  {np.sqrt(len(X_train))}')","32433799":"knn_model_1=KNeighborsClassifier(n_neighbors=1)\nknn_model_1.fit(scaled_X_train,y_train)\ny_pred_1= knn_model_1.predict(scaled_X_test)","4dbecdea":"print(classification_report(y_test, y_pred_1))","480da024":"knn_model_12=KNeighborsClassifier(n_neighbors=12)\nknn_model_12.fit(scaled_X_train,y_train)\ny_pred_12= knn_model_12.predict(scaled_X_test)","1fdf2459":"print(classification_report(y_test, y_pred_12))","bd5f6b21":"The information shows there is not any missing data.","2cd6f01f":"Sonar (sound navigation ranging) is a technique that uses sound propagation\n(usually underwater, as in submarine navigation) to navigate, communicate with\nor detect objects on or under the surface of the water, such as other vessels.<br><br>\nThe data set contains the response metrics for 60 separate sonar frequencies sent\nout against a known mine field (and known rocks)  and included **208** Rows and **61** columns.<br><br>\nThese frequencies are then\nlabeled with the known object they were beaming the sound at (either a rock or a\nmine).<br>\nThis Dataset contains the information about Titanic ship","a0520379":"### <a id=\"t3.3.\"><\/a>\n### 3.3. Final Model","db5fd0ce":"As we see the Lable is balance .","3d245fcf":"### <a id=\"t3.2.\"><\/a>\n### 3.2. Grid Search for Choosing Reasonable K Values","e066d305":"<a id=\"t2.1.\"><\/a>\n## 2.1. Exploration of Label","3aa2def5":"\n<br>So The value of k is approximately 12","878ae402":"#### Predicting Test Data","a1916ec6":"#### Best **k = 1** via Elbow method","cdcdf57e":"##### check missing values in data","20b0b28c":"<a id=\"t1.\"><\/a>\n# 1. Import Data & Libraries","136b00d5":"#### Split the Data to Train & Test","7090f005":"<a id=\"t2.\"><\/a>\n# 2. Exploratory Data Analysis (EDA)","225f78af":"From the plots, we can see that the smallest error we got is 0.126 at K=1.\nWe got the accuracy of 0.873 at K=1","9103be23":"#### Scaling the Features","91dcc0b8":"#### Train the Model","d7fc3d71":"#### Creating a Pipeline to find K value","40f7d806":"##### **k = 12**","bb671bb3":"**Accuracy 87%**","1788d9cb":"#### Calculate accuracy and error rate for k values\n","c283501c":"### **Note : ** Optimum K value in K-Nearest Neighbor ?! <br>\nIn KNN, finding the value of k is not easy. A small value of k means that noise will have a higher influence on the result and a large value make it computationally expensive.\n\n##### Data scientists usually choose :\n* 1. An odd number if the number of classes is 2\n\n* 2. Another simple approach to select k is set k = sqrt(n). where n = number of data points in training data.<br><br>\n<a href='https:\/\/saravananthirumuruganathan.wordpress.com\/2010\/05\/17\/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm\/'>**Source**<\/a>","d82d772b":"#### Best **k = 1** via Grid Search","63d4f7e5":"<a id=\"t3.\"><\/a>\n# 3. K Nearest Neighbors (KNN)","8fc2e869":"# **Introduction**\n\n0. [About Dataset](#t0.)\n1. [Import Data & Libraries](#t1.)\n2. [Exploratory Data Analysis (EDA)](#t2.)\n    * 2.1. [Exploration of Label](#t2.1.)\n3. [K Nearest Neighbors (KNN)](#t3.)\n    * 3.1. [Elbow Method for Choosing Reasonable K Values](#t3.1.)\n    * 3.2. [Grid Search for Choosing Reasonable K Values](#t3.2.)\n    * 3.3. [Final Model](#t3.3.)","989b537d":"#### Evaluating the Model","7610d8cd":"##### **k = 1**","93afff03":"Data overview :","ef3584c5":"#### Determine the Features & Target Variable","3f91dd6e":"<a id=\"t0.\"><\/a>\n# 0. About Dataset","76a7b2e6":"### <a id=\"t3.1.\"><\/a>\n### 3.1. Elbow Method for Choosing Reasonable K Values","a7491b91":"**Accuracy 68%**"}}