{"cell_type":{"fe328290":"code","e1df0b15":"code","1b91d44d":"code","04f26edc":"code","75217602":"code","1cdbc4f6":"code","2d1f228f":"code","e72c05d8":"code","a793ad17":"code","1612c5bb":"code","d4e80fcf":"code","9b2f7628":"code","e3c672a9":"code","6f449a46":"code","e3c5ff68":"code","edbc85e8":"code","49e5cb36":"code","8e4867f5":"code","1467fab7":"code","ba093017":"code","cf1bbc21":"code","c053601c":"code","d2a1e9bc":"code","c5f32841":"code","54e200e5":"code","bb95157c":"code","6cd28aa2":"code","6b5ac717":"code","4792c3fe":"code","57b029c2":"code","c50031c3":"markdown","1a27cd80":"markdown","18e9c1e6":"markdown","3d9c10db":"markdown","878a5ffd":"markdown","75a96f1c":"markdown","57fd0e31":"markdown","e1fba435":"markdown","e3f1b8da":"markdown","568e1760":"markdown","07056117":"markdown","0194bdcd":"markdown","1b4f1004":"markdown","07f2863d":"markdown","55b3cac5":"markdown","4579e1f3":"markdown"},"source":{"fe328290":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","e1df0b15":"import matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics","1b91d44d":"# Reading Data\n\ndf = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ndf.info()","04f26edc":"df.head(5)","75217602":"vect = CountVectorizer(analyzer='word')\ntransf = TfidfTransformer()\nclf_Gaussian = GaussianNB()\nclf_Bernoulli = BernoulliNB()\nclf_Tree = DecisionTreeClassifier()","1cdbc4f6":"df_X = vect.fit_transform(df.text)\nX = transf.fit_transform(df_X)\nY = df.target","2d1f228f":"df.text[0]","e72c05d8":"print(df_X.toarray()[0].sum())","a793ad17":"print(X.toarray()[0].sum())","1612c5bb":"dummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X, Y)\ndummy_clf.score(X, Y)","d4e80fcf":"X_train, X_test, y_train, y_test = train_test_split(X.toarray(), Y, test_size=0.2, random_state=0)","9b2f7628":"model_gaussian = clf_Gaussian.fit(X_train,y_train)\nmodel_bernoulli = clf_Bernoulli.fit(X_train,y_train)\nmodel_tree = clf_Tree.fit(X_train,y_train)","e3c672a9":"print(\"Gaussian: \",model_gaussian.score(X_test,y_test))\nprint(\"Bernoulli: \",model_bernoulli.score(X_test,y_test))\nprint(\"Decision Tree: \",model_tree.score(X_test,y_test))","6f449a46":"# Iniciando Cross_Validation com K-Fold = 5\n\nscore_CV = cross_val_score(clf_Bernoulli, X, Y, cv=5)\nscore_CV","e3c5ff68":"print(\"%0.2f de precis\u00e3o com desvio padr\u00e3o de %0.2f\" % (score_CV.mean(), score_CV.std()))","edbc85e8":"clf_Bernoulli.get_params()","49e5cb36":"# Otimizando Hiperpar\u00e2metros do Classificador\nparameters = {\n    'alpha' : (0.1,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,2), # Testando par\u00e2metros alpha de 0.1 a 2\n    'fit_prior': (True,False)\n}\n\nclf = GridSearchCV(clf_Bernoulli, parameters, cv=5, return_train_score=True)\nclf.fit(X,Y)","8e4867f5":"clf.best_params_","1467fab7":"# Parametrizando um novo classificador e verificando com CV\n\nclf_Bernoulli_novo = BernoulliNB(alpha= 1.5, fit_prior=False)\nscore_CV = cross_val_score(clf_Bernoulli_novo, X, Y, cv=5)\nprint(\"%0.2f de precis\u00e3o com desvio padr\u00e3o de %0.2f\" % (score_CV.mean(), score_CV.std()))","ba093017":"score_CV = cross_val_score(clf_Tree, X, Y, cv=5)\nprint(\"%0.2f de precis\u00e3o com desvio padr\u00e3o de %0.2f\" % (score_CV.mean(), score_CV.std()))","cf1bbc21":"# Otimizando Hiperpar\u00e2metros do Classificador\nparameters = {\n    'criterion': ('gini', 'entropy'),\n    'splitter': ('best','random'),\n    'max_depth': (3,5,7,10),\n    'random_state' : [0],\n}\n\nclf = GridSearchCV(clf_Tree, parameters, cv=5, return_train_score=True)\nclf.fit(X,Y)\nclf.best_params_","c053601c":"# Parametrizando um novo classificador e verificando com CV\n\nclf_tree_novo = DecisionTreeClassifier(criterion='gini',max_depth=7,random_state=0,splitter=\"random\")\nscore_CV = cross_val_score(clf_tree_novo, X, Y, cv=5)\nprint(\"%0.2f de precis\u00e3o com desvio padr\u00e3o de %0.2f\" % (score_CV.mean(), score_CV.std()))","d2a1e9bc":"model = clf_Bernoulli_novo.fit(X_train, y_train)\ny_predict = clf_Bernoulli_novo.predict(X_test)","c5f32841":"matriz_confusao = metrics.confusion_matrix(y_test,y_predict,labels=clf_Bernoulli_novo.classes_)\nmc_perc = matriz_confusao*100\/y_predict.shape[0]","54e200e5":"disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mc_perc,display_labels=clf_Bernoulli_novo.classes_)\ndisp.plot()\nplt.savefig(\"cm.png\")\nplt.show()","bb95157c":"model.predict_proba(X_test) # Retorna a probabilidade de amostras para cada classe","6cd28aa2":"fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\nroc_auc = metrics.auc(fpr, tpr)\ndisplay = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n                                  estimator_name='Bernoulli NB')\ndisplay.plot(color='Red')\nplt.plot([0,1],[0,1],color = 'black')\nplt.xlabel('Taxa de Falsos Positivos')\nplt.ylabel('Taxa de Verdadeiros Positivos')\nplt.savefig(\"ROC.png\")\nplt.show()","6b5ac717":"df_testing = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\ndf_X_testing = vect.transform(df_testing.text)\nX_testing = transf.transform(df_X_testing)","4792c3fe":"df_testing","57b029c2":"sample_submission = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = model.predict(X_testing)\nsample_submission.to_csv('submission.csv', index=False)","c50031c3":"# Criando Classificadores","1a27cd80":"# Importando dados e bibliotecas","18e9c1e6":"O algoritmo melhorou cerca de 3% em rela\u00e7\u00e3o ao classificador em \"default\", contudo, \u00e9 cerca de 10% menos preciso do que o algoritmo de Bernoulli. Vamos explorar outros conceitos de m\u00e9tricas.","3d9c10db":"# Submiss\u00e3o dos Resultados\n\nExportando valores para submiss\u00e3o","878a5ffd":"## Matriz de Confus\u00e3o","75a96f1c":"## Curva ROC","57fd0e31":"# Otimiza\u00e7\u00e3o do Bernoulli\n\nVamos testar um pipeline com o classificador Bernoulli (n\u00e3o utilizarei a fun\u00e7\u00e3o do sklearn para criar um pipeline, farei o passo a passo)","e1fba435":"# Taxa de Acerto Base\n\nAntes de fazer qualquer classifica\u00e7\u00e3o, vamos verificar a taxa base de acerto. Essa taxa remete ao quanto de acerto ter\u00edamos se chut\u00e1ssemos um valor sempre verdadeiro ou sempre falso.","e3f1b8da":"Tivemos uma melhoria de apenas 1% na precis\u00e3o do classificador. Vamos tentar melhorar outro algoritmo (\u00c1rvore de Decis\u00e3o).","568e1760":"# M\u00e9tricas \n\nVamos explorar duas m\u00e9tricas (matriz de confus\u00e3o e Curva ROC, do ingl\u00eas Receiver Operating Characteristic), utilizaremos o classificador otimizado de Bernoulli para fazer estas visualiza\u00e7\u00f5es e an\u00e1lises.","07056117":"Um algoritmo bom tem de acertar no m\u00ednimo 57% dos casos.","0194bdcd":"# Iniciando Classifica\u00e7\u00f5es\n\nVamos separar o dataset em teste e treino com 80% e 20% respectivamente. E treinar os modelos:\n\n* Naive Bayes Gaussiano\n* Naive Bayes Bernoulli\n* \u00c1rvore de Decis\u00e3o","1b4f1004":"Fontes:\n* https:\/\/scikit-learn.org\/\n* https:\/\/medium.com\/kunumi\/m%C3%A9tricas-de-avalia%C3%A7%C3%A3o-em-machine-learning-classifica%C3%A7%C3%A3o-49340dcdb198\n","07f2863d":"Aqui, podemos dizer que a Curva ROC \u00e9 uma rela\u00e7\u00e3o entre as taxas de falsos positivos e verdadeiros positivos. Para an\u00e1lise, podemos ver que a curva tem um perfil acima da linha de taxa base, o algoritmo tem uma boa funcionalidade e sua AUC (Area Under the Curve) \u00e9 pr\u00f3xima de 1 (valor m\u00e1ximo para um algoritmo que tem uma baixa taxa de falsos positivos.","55b3cac5":"Neste ponto, podemos realizar a seguinte visualiza\u00e7\u00e3o em termos percentuais:\n\n* 54% dos casos s\u00e3o verdadeiros negativos, ou seja, o algoritmo sinaliza que n\u00e3o h\u00e1 um desastre e acerta;\n* 26% dos casos s\u00e3o verdadeiros positivos, isto \u00e9, o algoritmo sinaliza que h\u00e1 uma desastre e acerta;\n* 4.6% dos casos s\u00e3o falsos positivos, o algoritmo sinaliza que est\u00e1 ocorrendo um desastre mas na verdade n\u00e3o est\u00e1;\n* Por fim, 16% s\u00e3o falsos negativos e esta \u00e9 a parte mais preocupante, pois o algoritmo n\u00e3o identifica que o tweet \u00e9 de um desastre, quando na verdade, est\u00e1 acontecendo algo.\n","4579e1f3":"Importante salientar que estes dados poderiam ser melhor tratados com algoritmos mais refinados e um trabalho melhor na parte de NLP. Mas aqui \u00e9 um trabalho de pipeline sem a parte de EDA, primordial para iniciar um trabalho de an\u00e1lise."}}