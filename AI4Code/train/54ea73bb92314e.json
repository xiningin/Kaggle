{"cell_type":{"f7a83bfa":"code","a957b9db":"code","2e04fea8":"code","edec95d7":"code","9f13830f":"code","2dcc474d":"code","4294d78c":"code","473b4921":"code","ae693fc8":"code","61ea15c0":"code","ce854056":"code","16818255":"code","e4972b5a":"code","a3b6c15e":"code","c14a628f":"code","800322d6":"code","5bd9af4d":"code","e7c8996f":"code","386025a2":"code","7bf339fa":"code","255da07e":"code","6f00b2c4":"code","16818642":"code","b4eab3a4":"code","2d8286e4":"code","cc27ce1b":"code","d56ba158":"code","cd8ab910":"code","a397cf6d":"code","45d689c2":"code","7e0345fa":"code","0bc96857":"code","9c4179ca":"code","bfcd8e39":"code","a5311407":"code","41a25b2f":"code","447e71ba":"markdown","622ac4c3":"markdown","0b1183f9":"markdown","469356d1":"markdown","c32b9a56":"markdown","38033639":"markdown","d5c06154":"markdown","2c43cdd8":"markdown","ee3ad50b":"markdown"},"source":{"f7a83bfa":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport cv2\nfrom scipy.spatial import distance\nimport glob\nfrom warnings import filterwarnings\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model, load_model\nfrom sklearn.metrics import classification_report , confusion_matrix\nfrom skimage import io\nfilterwarnings(\"ignore\")","a957b9db":"path  = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/\"","2e04fea8":"dataset = {\"image_path\":[],\"mask_status\":[],\"where\":[]}\nfor where in os.listdir(path):\n    for status in os.listdir(path+\"\/\"+where):\n        for image in glob.glob(path+where+\"\/\"+status+\"\/\"+\"*.png\"):\n            dataset[\"image_path\"].append(image)\n            dataset[\"mask_status\"].append(status)\n            dataset[\"where\"].append(where)\ndataset = pd.DataFrame(dataset)\ndataset","edec95d7":"dataset.value_counts(\"mask_status\")","9f13830f":"mask = dataset.value_counts(\"mask_status\")[1]\nwithoutmask = dataset.value_counts(\"mask_status\")[0]\n\nprint(f\"With Mask: {mask},\\nWithout Mask: {withoutmask}\\n\")\nsns.countplot(dataset[\"mask_status\"])\nplt.show()","2dcc474d":"plt.figure(figsize = (14,10))\nfor i in range(9):\n    random = np.random.randint(1,len(dataset))\n    plt.subplot(3,3,i+1)\n    plt.imshow(cv2.imread(dataset.loc[random,\"image_path\"]))\n    plt.title(dataset.loc[random, \"mask_status\"], size = 10, color = \"purple\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","4294d78c":"train_df = dataset[dataset[\"where\"] == \"Train\"]\ntest_df = dataset[dataset[\"where\"] == \"Test\"]\nvalid_df = dataset[dataset[\"where\"] == \"Validation\"]","473b4921":"train_df = train_df.sample(frac=1)\ntest_df = test_df.sample(frac=1)\nvalid_df = valid_df.sample(frac=1)\n","ae693fc8":"train_df.head()","61ea15c0":"test_df.head()","ce854056":"valid_df.head()","16818255":"plt.figure(figsize = (15,6))\nplt.subplot(1,3,1)\nsns.countplot(train_df[\"mask_status\"])\nplt.title(\"Train_df\", size = 14, color = \"orange\")\n\n\nplt.subplot(1,3,2)\nsns.countplot(test_df[\"mask_status\"])\nplt.title(\"Test_df\", size = 14, color = \"red\")\n\n\nplt.subplot(1,3,3)\nsns.countplot(valid_df[\"mask_status\"])\nplt.title(\"Validation_df\", size = 14, color = \"blue\")\n\nplt.show()","e4972b5a":"datagen = ImageDataGenerator(rescale = 1.\/255)","a3b6c15e":"train_generator=datagen.flow_from_dataframe(\ndataframe=train_df,\ndirectory=\"..\/input\",\nx_col=\"image_path\",\ny_col=\"mask_status\",\nbatch_size=80,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))","c14a628f":"valid_generator=datagen.flow_from_dataframe(\ndataframe=valid_df,\ndirectory=\"..\/input\",\nx_col=\"image_path\",\ny_col=\"mask_status\",\nbatch_size=80,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))","800322d6":"test_generator=datagen.flow_from_dataframe(\ndataframe=test_df,\ndirectory=\"..\/input\",\nx_col=\"image_path\",\ny_col=\"mask_status\",\nbatch_size=80,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))","5bd9af4d":"image_shape=(150,150,3)\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\n\n\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","e7c8996f":"model.summary()","386025a2":"history = model.fit_generator(train_generator,validation_data  = valid_generator, epochs = 10, steps_per_epoch=(len(train_generator.labels) \/ 80) ,validation_steps=(len(valid_generator.labels)\/80))","7bf339fa":"model.evaluate_generator(test_generator, verbose=1)","255da07e":"model.save('face_musk.h5')","6f00b2c4":"plt.figure(figsize = (10,4))\nplt.subplot(1,2,1)\nplt.plot(history.history[\"accuracy\"], label = \"train accuracy\", color = \"red\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation accuracy\", color = \"blue\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history[\"loss\"], label = \"train loss\", color = \"red\")\nplt.plot(history.history[\"val_loss\"], label = \"validation loss\", color = \"blue\")\n\nplt.legend()\nplt.show()","16818642":"predictions = model.predict_generator(test_generator, verbose = 1,workers=-1)","b4eab3a4":"plt.figure(figsize = (8,5))\nsns.heatmap(confusion_matrix(test_generator.labels, predictions.round()), annot = True,fmt=\"d\",cmap = \"Blues\")\nplt.show()","2d8286e4":"print(classification_report(test_generator.labels,predictions.round()))","cc27ce1b":"face_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_alt.xml')","d56ba158":"def detect_face(img):\n    img = io.imread(img)\n\n    faces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\n    for (x,y,w,h) in faces:\n        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n    plt.figure(figsize=(6,6))\n    plt.imshow(img)\n    plt.show()","cd8ab910":"detect_face(\"https:\/\/scontent.faly3-1.fna.fbcdn.net\/v\/t1.6435-9\/s960x960\/126618938_108510761085818_3688312590095346495_n.jpg?_nc_cat=110&ccb=1-5&_nc_sid=e3f864&_nc_ohc=VLuaC4nqwN0AX9vyo4C&_nc_ht=scontent.faly3-1.fna&oh=00_AT9r4O5aCHyzdWcgvSjNAtKkdFZoJYfL4D-T6V3WleWu2A&oe=61FEE66D\")","a397cf6d":"mask_label = {0:'Has Mask!',1:'No Mask'}\ndist_label = {0:(0,255,0),1:(255,0,0)}\nMIN_DISTANCE = 0\ndef detect_mask(img):\n    img = io.imread(img)\n\n    faces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\n\n    for (x,y,w,h) in faces:\n        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),1)\n    if len(faces)>=1:\n        label = [0 for i in range(len(faces))]\n        for i in range(len(faces)-1):\n            for j in range(i+1, len(faces)):\n                dist = distance.euclidean(faces[i][:2],faces[j][:2])\n                if dist<MIN_DISTANCE:\n                    label[i] = 1\n                    label[j] = 1\n        for i in range(len(faces)):\n            (x,y,w,h) = faces[i]\n            crop = img[y:y+h,x:x+w]\n            crop = cv2.resize(crop,(150,150))\n            crop = np.reshape(crop,[1,150,150,3])\/255.0\n            mask_result = model.predict(crop)\n            cv2.putText(img,mask_label[round(mask_result[0][0])],(x, y), cv2.FONT_HERSHEY_SIMPLEX,1,dist_label[label[i]],2)\n            cv2.rectangle(img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n        plt.figure(figsize=(10,10))\n        plt.imshow(img)\n            \n    else:\n        print(\"No Face!\")","45d689c2":"detect_mask(\"https:\/\/scontent.faly3-1.fna.fbcdn.net\/v\/t1.6435-9\/s960x960\/126618938_108510761085818_3688312590095346495_n.jpg?_nc_cat=110&ccb=1-5&_nc_sid=e3f864&_nc_ohc=VLuaC4nqwN0AX9vyo4C&_nc_ht=scontent.faly3-1.fna&oh=00_AT9r4O5aCHyzdWcgvSjNAtKkdFZoJYfL4D-T6V3WleWu2A&oe=61FEE66D\")","7e0345fa":"detect_mask(\"https:\/\/englishtribuneimages.blob.core.windows.net\/gallary-content\/2020\/3\/Desk\/2020_3$largeimg_618252709.jpeg\")","0bc96857":"detect_mask(\"https:\/\/philadelphia.cbslocal.com\/wp-content\/uploads\/sites\/15116066\/2020\/08\/face-mask-study.jpg\")","9c4179ca":"detect_mask('https:\/\/idsb.tmgrup.com.tr\/ly\/uploads\/images\/2020\/06\/21\/42169.jpg')","bfcd8e39":"detect_mask(\"https:\/\/images.indianexpress.com\/2020\/06\/corona759.jpg\")","a5311407":"detect_mask(\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcS6avPk-BTuysWjGYT0iZ6Wwe1dcjbPVhdr-g&usqp=CAU\")","41a25b2f":"model.save(\"classify_model.h5\")","447e71ba":"# import libraries","622ac4c3":"The path is created for getting data and then I concatened dataframes of mask and without mask.","0b1183f9":"# Preprocessing image ","469356d1":"# Face detection","c32b9a56":"<p style = \"font-weight:bold;\"> Hello, Welcome to our mask detection project <\/p>\n<p>\nThe covid19 virus influence negatively our life since 2019 and the virus the first appearance place in the world was Wuhan city in China, \nand then spread all over world,from this moment we have to  wear a face maske in  crowded places such as cafe, restaurant.. While wearing mask is not the ultimate solution, it still reduces the rate of transmission of the virus.In addition much applications were produced by software developers. I devoloped this project to solve face mask problem.\n<\/p>","38033639":"# Classify Model","d5c06154":"in this notebook, following process is adopted:<br>\n* Prepare mask and without mask images for classifiying model \n* Train the classifier to classify faces into mask or non-mask labels.\n* Detect Face with Opencv Haar Cascade Classifier","2c43cdd8":"# EDA","ee3ad50b":"# Model evaluation"}}