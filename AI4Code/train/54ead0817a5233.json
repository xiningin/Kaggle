{"cell_type":{"d754eca0":"code","8070d4f5":"code","c6411de5":"code","c216f20a":"code","4712ff88":"code","029aee02":"code","29495740":"code","10c3d888":"code","59fd4245":"code","ebfa10dc":"code","58561f3f":"code","d9310106":"code","58ddb625":"code","735b2018":"code","2c10eb5a":"code","ce15056c":"code","6fb30ef6":"code","dead66f9":"code","a95b1772":"code","1de32cea":"code","192a570c":"code","a77cd24f":"code","613fa93e":"code","df885745":"code","5f72f3a9":"code","8b444d2b":"code","f947a7ea":"code","198db330":"code","2fe73022":"code","a38ac6dd":"code","34174188":"code","8cf98bb5":"code","6f0ca464":"code","72fb54e2":"code","face6b90":"code","f10223d3":"code","89b90db5":"markdown","f6c4f3b8":"markdown","a51a4450":"markdown","6a8c249d":"markdown","ed1ae0f4":"markdown","c74ab6f9":"markdown","d241b2a6":"markdown","22fb5b1a":"markdown","3bb4ad8d":"markdown","e0a515d4":"markdown","f7a01bab":"markdown"},"source":{"d754eca0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time, logging, gc ,os\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8070d4f5":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom prettytable import PrettyTable\nfrom IPython.display import Image\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.regularizers import l2\nfrom keras.constraints import max_norm\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Input, Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv1D, Add, MaxPooling1D, BatchNormalization\nfrom keras.layers import Embedding, Bidirectional, GlobalMaxPooling1D,LSTM\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense,LSTM\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import train_test_split","c6411de5":"DIR = '..\/input\/instadeep-enzyme-classification-challenge\/'\ntrain=pd.read_csv(DIR+'Train (4).csv')\ntest=pd.read_csv(DIR+'Test (3).csv')\nsub=pd.read_csv(DIR+'SampleSubmission (3).csv')","c216f20a":"print('Train size: ', len(train))\nprint('Test size: ', len(test))","4712ff88":"train.head(3)","029aee02":"train.describe()","29495740":"#Check if ther'is null values\ntrain.isnull().sum()","10c3d888":"#Remove redundant samples\ntrain=train.drop_duplicates(subset=['SEQUENCE', 'LABEL'], keep='first')","59fd4245":"#example of protein sequence\ntrain.SEQUENCE[0]","ebfa10dc":"#length of Sequence\ntrain.SEQUENCE.apply(lambda x : len(x)).describe()","58561f3f":"# Length of sequence in train & test data.\ntrain['seq_count']= train['SEQUENCE'].apply(lambda x: len(x))\ntest['seq_count']= test['SEQUENCE'].apply(lambda x: len(x))","d9310106":"def plot_seq_count(df, data_name):\n  sns.distplot(df['seq_count'].values)\n  plt.title(f'Sequence char count: {data_name}')\n  plt.grid(True)","58ddb625":"plt.subplot(1, 2, 1)\nplot_seq_count(train, 'Train')\n\nplt.subplot(1, 2, 2)\nplot_seq_count(test, 'Test')\n\nplt.subplots_adjust(right=3.0)\nplt.show()","735b2018":"def get_code_freq(df, data_name):\n  \n  df = df.apply(lambda x: \" \".join(x))\n  \n  codes = []\n  for i in df: # concatination of all codes\n    codes.extend(i)\n\n  codes_dict= Counter(codes)\n  codes_dict.pop(' ') # removing white space\n  print(f'Codes: {data_name}')\n  print(f'Total unique codes: {len(codes_dict.keys())}')\n  df = pd.DataFrame({'Code': list(codes_dict.keys()), 'Freq': list(codes_dict.values())})\n  return df.sort_values('Freq', ascending=False).reset_index()[['Code', 'Freq']]\n\ndef plot_code_freq(df, data_name):\n  plt.title(f'Code frequency: {data_name}')\n  sns.barplot(x='Code', y='Freq', data=df)","2c10eb5a":"train_code_freq = get_code_freq(train['SEQUENCE'], 'Train')\ntrain_code_freq","ce15056c":"test_code_freq = get_code_freq(test['SEQUENCE'], 'Test')\ntest_code_freq","6fb30ef6":"plt.subplot(1, 2, 1)\nplot_code_freq(train_code_freq, 'Train')\nplt.subplot(1, 2, 2)\nplot_code_freq(test_code_freq, 'Test')\n\nplt.subplots_adjust(right=3.0)\nplt.show()","dead66f9":"fig = plt.figure(figsize=(8,6))\ntrain.groupby('LABEL').SEQUENCE.count().plot.bar(ylim=0)\nplt.show()","a95b1772":"codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']#,'B',X','U','Z']\n\ndef create_dict(codes):\n  char_dict = {}\n  for index, val in enumerate(codes):\n    char_dict[val] = index+1\n  return char_dict\nchar_dict = create_dict(codes)\n\nprint(char_dict)\nprint(\"Dict Length:\", len(char_dict))","1de32cea":"def integer_encoding(data):\n  \"\"\"\n  - Encodes code sequence to integer values.\n  - 20 common amino acids are taken into consideration\n    and rest 4 are categorized as 0.\n  \"\"\"\n  \n  encode_list = []\n  for row in data.values:\n    row_encode = []\n    for code in row:\n      row_encode.append(char_dict.get(code, 0))\n    encode_list.append(np.array(row_encode))\n  \n  return encode_list","192a570c":"#apply label encoding to classes\nle = LabelEncoder()\ntrain.LABEL = le.fit_transform(train['LABEL'])","a77cd24f":"#Split our data into train and validation \nX_train, X_val, y_train, y_val = train_test_split(train.SEQUENCE,train.LABEL, test_size=0.2, random_state=42,stratify=train['LABEL'])","613fa93e":"# encode our data\nX_train = integer_encoding(X_train) \nX_val = integer_encoding(X_val) \ntest_data = integer_encoding(test.SEQUENCE)","df885745":"#we will take just the first 150 amino acid in the sequence\nmax_length = 150\ntrain_pad = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\nval_pad = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\ntest_pad = pad_sequences(test_data, maxlen=max_length, padding='post', truncating='post')\n\ntrain_pad.shape, val_pad.shape, test_pad.shape","5f72f3a9":"# One hot encoding of label\ny_train = to_categorical(y_train)\ny_val = to_categorical(y_val)\ny_train.shape, y_val.shape","8b444d2b":"# Detect hardware, return appropriate distribution strategy\nprint(tf.version.VERSION)\ntf.get_logger().setLevel(logging.ERROR)\ntry: # detect TPU\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError: # detect GPU(s) and enable mixed precision\n    strategy = tf.distribute.MirroredStrategy() # works on GPU and multi-GPU\n    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    tf.config.optimizer.set_jit(True) # XLA compilation\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n    print('Mixed precision enabled')\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","f947a7ea":"if tpu:\n    BATCH_SIZE = 128 * strategy.num_replicas_in_sync\nelse:\n    BATCH_SIZE = 64 * strategy.num_replicas_in_sync\nBATCH_SIZE","198db330":"gc.collect()","2fe73022":"with strategy.scope():\n    model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(21, 10, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, dropout=0.1,return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,dropout=0.1)),\n    tf.keras.layers.Dense(20, activation='softmax')])\n\n    model.compile(\n        loss=tf.keras.losses.CategoricalCrossentropy(),\n        optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n        metrics=['accuracy'])\n\nmodel.summary()","a38ac6dd":"es = EarlyStopping(monitor='val_accuracy',mode='max', patience=3, verbose=1)\nhistory = model.fit(train_pad, y_train,epochs=20, batch_size=1024,validation_data=(val_pad,y_val),callbacks=[es])","34174188":"def plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.savefig('loss.png')\n    plt.show()","8cf98bb5":"plot_hist(history)","6f0ca464":"from sklearn.metrics import confusion_matrix, classification_report","72fb54e2":"len(valid_labels)","face6b90":"pred_valid_y = model.predict(val_pad,  verbose = True)\npred_valid_y_labels = np.argmax(pred_valid_y, axis=-1)\npred_valid_y_labels = le.inverse_transform(pred_valid_y_labels)[:163390]\nvalid_labels=np.argmax(y_val, axis=-1)\nvalid_labels=le.inverse_transform(valid_labels)\nprint(classification_report(valid_labels, pred_valid_y_labels ))","f10223d3":"print(confusion_matrix(valid_labels, pred_valid_y_labels ))","89b90db5":"* amino acids  (X, U, B, Z)  are present in very less quantity\n* amino acids  (B, Z) are presented only in the training set ","f6c4f3b8":"1-Data","a51a4450":"# Problem Description","6a8c249d":"Create a model that classify the amino acid sequence","ed1ae0f4":"* We will not consider amino acids that are present in very less quantity","c74ab6f9":"* we have unbalanced classes","d241b2a6":"# Evaluating Model on Validation Set","22fb5b1a":"# EDA","3bb4ad8d":"<p style='font-size:25px;font-weight:bold'>Please If you find this kernel helpful, upvote it to help others see it \ud83d\ude0a<\/p>","e0a515d4":"2-Objective","f7a01bab":"The data consists of labelled amino acid sequences. Each sequence has a unique ID, the amino acid sequence, the organism it came from and the label. You must predict the label for the test set. Labels consist of one of 20 classes. There are ten organisms, 8 in the training set and 2 in the test set. Sequences above a set length have been excluded from this dataset"}}