{"cell_type":{"d1a80dae":"code","64ae1ed3":"code","dc4f384c":"code","2ab108bd":"code","77cecdd3":"code","ed0fba16":"code","eef6792d":"code","d8462f00":"code","51e11e79":"code","4ed7b31c":"code","8b924fc5":"code","7fb9b975":"code","cd85fd9b":"code","c68f8978":"code","ee2bc17f":"code","95f7cfcc":"code","530e0c40":"markdown","e39d2fd4":"markdown","39efaaf3":"markdown","421fa525":"markdown","fe2c5f4a":"markdown","fff0078e":"markdown","c1b794eb":"markdown"},"source":{"d1a80dae":"# Basics\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocssing\nimport missingno as msno\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, binarize\n\n# Model Selection \nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n# Ensemble\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n\n# Metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score\n\n# Feature Selection\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Warnings\nimport warnings as ws\nws.filterwarnings('ignore')","64ae1ed3":"# Load dataset\ndata = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndata.head()","dc4f384c":"# Summary\ndef summary(data):\n    df = {\n     'Count' : data.shape[0],\n     'NA values' : data.isna().sum(),\n     '% NA' : round((data.isna().sum()\/data.shape[0]) * 100, 2),\n     'Unique' : data.nunique(),\n     'Dtype' : data.dtypes,\n     'min' : round(data.min(),2),\n     '25%' : round(data.quantile(.25),2),\n     '50%' : round(data.quantile(.50),2),\n     'mean' : round(data.mean(),2),\n     '75%' : round(data.quantile(.75),2),   \n     'max' : round(data.max(),2)\n    } \n    return(pd.DataFrame(df))\n\nprint('Shape is :', data.shape)\nsummary(data)","2ab108bd":"data.hist(figsize = (10,10))\nplt.show()","77cecdd3":"# Target Variables\ndata['quality'].value_counts()","ed0fba16":"# Convert Target variable into binary\nbins = [2,6.5, 8]\nlabels = ['Bad','Good']\ndata['quality'] = pd.cut(data['quality'], bins = bins, labels = labels)\n\ndata['quality'].value_counts()","eef6792d":"col_names = data.drop('quality', axis = 1).columns.tolist()\n\nplt.figure(figsize = (15,10))\ni=0\nfor col in col_names:\n    plt.subplot(3,4, i+1)\n    plt.grid(True, alpha = 0.5)\n    sns.kdeplot(data[col][data['quality'] == 'Bad'], label = 'Bad Quality')\n    sns.kdeplot(data[col][data['quality'] == 'Good'], label = 'Good Quality')\n    plt.title(col + ' vs Quality', size = 15)\n    plt.xlabel(col, size = 12)\n    plt.ylabel('Density')    \n    plt.tight_layout()\n    i+=1\nplt.show()","d8462f00":"X = data.drop('quality', axis = 1)\nY = data['quality'].replace({'Bad':0, 'Good' : 1})\n\nx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 42)","51e11e79":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('SVM', SVC()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('ADA', AdaBoostClassifier()))\nmodels.append(('GB', GradientBoostingClassifier()))","4ed7b31c":"models","8b924fc5":"def model_selection(X,Y):\n    acc_results = []\n    auc_results = []\n    names = []\n\n    # Set Table\n    col = ['Model Name','ROC AUC Mean','ROC AUC Std','ACC Mean', 'AUC Std']\n    model_results = pd.DataFrame(columns = col)\n\n    i = 0\n    for name, model in models:\n        kfold = KFold(n_splits = 10, random_state = 7)\n\n        cv_acc_results = cross_val_score(model, X,Y, cv = kfold, scoring = 'accuracy')\n        cv_auc_results = cross_val_score(model, X,Y, cv = kfold, scoring =  'roc_auc')\n\n        acc_results.append(cv_acc_results)\n        auc_results.append(cv_auc_results)\n        names.append(name)\n\n        model_results.loc[i] = [name, cv_auc_results.mean(),cv_auc_results.std(), cv_acc_results.mean(), cv_acc_results.std()]\n        i+=1\n\n    model_results = model_results.sort_values(['ROC AUC Mean'], ascending = False)     \n\n    # View Model Results\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    sns.boxplot(x = names, y = acc_results)\n    plt.title('Accuracy Score')\n\n    plt.subplot(1,2,2)\n    sns.boxplot(x = names, y = auc_results)\n    plt.title('AUC Score')\n    plt.show()\n    \n    return(model_results)","7fb9b975":"model_selection(x_train, y_train)","cd85fd9b":"def model_validation(model,x_test,y_test,thr = 0.5) :\n    \n    y_pred_prob = model.predict_proba(x_test)[:,1]\n    y_pred = binarize(y_pred_prob.reshape(1,-1), thr)[0]\n    \n    cnf_matrix = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize = (10,3))\n    plt.subplot(1,2,1)\n    sns.heatmap(cnf_matrix, annot = True, fmt = 'g')\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted label')\n    plt.ylabel('Actual label')\n\n    fpr, tpr, threshold = roc_curve(y_test, y_pred_prob)\n    plt.subplot(1,2,2)\n    sns.lineplot(fpr, tpr)\n    plt.plot([0,1],[0,1], 'r--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show()\n\n    \n    print('Classification Report :')\n    print('===' * 20)\n    print(classification_report(y_test, y_pred))\n\n    score = tpr - fpr\n    opt_threshold = sorted(zip(score,threshold))[-1][1]\n    print('='*20)\n    print('Area Under Curve', roc_auc_score(y_test,y_pred))\n    print('Accuracy', accuracy_score(y_test,y_pred))\n    print('Optimal Threshold : ',opt_threshold)\n    print('='*20)","c68f8978":"param_grid = {\n    'bootstrap': [True,False],\n    'max_depth': [10, 50, 100],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [10,100, 200, 300, 1000]\n}\n\nrf = RandomForestClassifier()\ngrid = GridSearchCV(rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 1)\n\ngrid.fit(x_train, y_train)\ngrid.best_params_","ee2bc17f":"model_validation(grid, x_test, y_test)","95f7cfcc":"# Final Model\nfinal_model = grid.best_estimator_\nfinal_model.fit(x_train, y_train)\n\nmodel_validation(final_model,x_test,y_test, 0.106)","530e0c40":"There is no missing values in this dataset. All variables are numeric and we found our target varibale have 6 unique values.\n\n### Visualization","e39d2fd4":"### Train Test Split","39efaaf3":"Random Forest fits well in this dataset. \n\nTo avoid overfitting in final model we have to use hyper parameters of the models. This basically done by cross valdation technique","421fa525":"### Load Libraries ","fe2c5f4a":"This dataset seems like imbalanced dataset ","fff0078e":"### Model Selection\nWe don't  know which model is perform well for this dataset. So we validate all the models on trian test dataset","c1b794eb":"Recall for 1 in final model has improved lot. which means 90% of True positive predicted as True.\n\n"}}