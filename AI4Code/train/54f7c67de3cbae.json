{"cell_type":{"5bd56b06":"code","3c9c91d2":"code","bcf58502":"code","ec83645b":"code","4b701998":"code","6a5f9c75":"code","346a6924":"code","4ce2660b":"code","728e60d6":"code","ba949b43":"code","b4e014e9":"code","1365e833":"code","9011598c":"code","16adde16":"markdown","1caf54f1":"markdown"},"source":{"5bd56b06":"import numpy as np\nimport librosa as lb\nimport soundfile as sf\nimport pandas as pd\nfrom pathlib import Path\n\nfrom tqdm.notebook import tqdm\n\n\nimport time","3c9c91d2":"NUM_CLASSES = 24\nSR = 32_000\nDURATION = 10\nSTRIDE = DURATION\/\/2\n\nBATCH_START = 0\nBATCH_SIZE = 400\n\nNJOBS = 2\n\nTEST_AUDIO_ROOT = Path(\"..\/input\/rfcx-species-audio-detection\/test\")\nTEST_MFCC_SAVE_ROOT = Path(f\"test_mfcc_d{DURATION}_s{STRIDE}_sr{SR}_{BATCH_START:04d}_{BATCH_START+BATCH_SIZE:04d}\")\nTEST_MFCC_SAVE_ROOT.mkdir(exist_ok=True)","bcf58502":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n\n    def __call__(self, y):\n\n        melspec = lb.feature.melspectrogram(\n            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax,\n        )\n\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","ec83645b":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) \/ (std + eps)\n\n    # Normalize to [0, 255]\n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) \/ (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\n\ndef normalize(image, mean=None, std=None):\n    image = image \/ 255.0\n    if mean is not None and std is not None:\n        image = (image - mean) \/ std\n    return np.moveaxis(image, 2, 0).astype(np.float32)\n\n\ndef crop_or_pad(y, length, sr, is_train=True):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n    elif len(y) > length:\n        if not is_train:\n            start = 0\n        else:\n            start = np.random.randint(len(y) - length)\n\n        y = y[start:start + length]\n\n    y = y.astype(np.float32, copy=False)\n\n    return y","4b701998":"class RFCXDataset:\n\n    def __init__(self, data, sr, n_mels=128, fmin=0, fmax=None, num_classes=NUM_CLASSES, root=None):\n\n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n\n        self.num_classes = num_classes\n#         self.duration = duration\n#         self.audio_length = self.duration*self.sr\n        \n        self.root =  root or TEST_AUDIO_ROOT\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n        \n        self.res_type = \"kaiser_best\"\n\n\n    def __len__(self):\n        return len(self.data)\n    \n    def load(self, record):\n        y, _ = lb.load(self.root.joinpath(record).with_suffix(\".flac\").as_posix(), sr=self.sr, res_type=self.res_type)\n        return y\n    \n    def load2(self, record):\n        y, orig_sr = sf.read(self.root.joinpath(record).with_suffix(\".flac\").as_posix())\n        y = lb.resample(y, orig_sr=orig_sr, target_sr=self.sr, res_type=self.res_type)\n        return y\n    \n    def read_index(self, idx):\n        d = self.data.iloc[idx]\n        record = d[\"recording_id\"]\n        \n        y = self.load2(record)\n        \n        window = DURATION*self.sr\n        stride = STRIDE*self.sr\n            \n        y = np.stack([y[i:i+window] for i in range(0, 60*self.sr+stride-window, stride)])\n\n#         y = crop_or_pad(y, self.audio_length, sr=self.sr)\n        \n        return y\n            \n    def process(self, y):\n        melspec = self.mel_spec_computer(y) \n        image = mono_to_color(melspec)\n        image = normalize(image, mean=None, std=None)\n        return image\n\n    def __getitem__(self, idx):\n\n        y = self.read_index(idx)\n        \n        image = np.stack([self.process(_y) for _y in y])\n\n        return image\n    \n    def to_mfcc(self, idx):\n        record = self.data.iloc[idx][\"recording_id\"]\n        mfcc = self[idx]\n        \n        np.save(TEST_MFCC_SAVE_ROOT.joinpath(record).with_suffix(\".npy\").as_posix(), mfcc)","6a5f9c75":"# def get_duration(audio_name, root=TEST_AUDIO_ROOT):\n#     return lb.get_duration(filename=root.joinpath(audio_name).with_suffix(\".flac\"))","346a6924":"%%time\n\ndata = pd.DataFrame({\n    \"recording_id\": [path.stem for path in Path(TEST_AUDIO_ROOT).glob(\"*.flac\")],\n})\n\nprint(data.shape)\ndata.head()","4ce2660b":"ds = RFCXDataset(data=data, sr=SR)","728e60d6":"%%time\n\nx = ds[1]\nprint(x.shape)","ba949b43":"x.nbytes\/(1024**2)","b4e014e9":"# %timeit ds.to_mfcc(0)","1365e833":"import joblib\npool = joblib.Parallel(n_jobs=NJOBS)","9011598c":"mapper = joblib.delayed(ds.to_mfcc)\ntasks = []\nfor idx in range(BATCH_START, min(BATCH_START + BATCH_SIZE, len(ds))):\n# for idx in range(25):\n    tasks.append(mapper(idx))\n    \nres = pool(tqdm(tasks))","16adde16":"I've released [this crazingly fast (< 10 mins) kernel](https:\/\/www.kaggle.com\/kneroma\/inference-tpu-rfcx-audio-detection-fast) which uses a set of pre-computed MFCCs. \n\nThe problem is that those MFCCs are static, and if you change any params (**DURATION**, **STRIDE**, ...), you can no more use them. This is not fair. I will release my code that can help  you re-computing them whenever you need.\n\n* I use **joblib** to parallelize the computations, so it must require less than 1 hour to compute the MFCCs for the whole test dataset, and just 30 mins if STRIDE = DURATION\n* I directly use **soundfile** to read audios instead of **librosa** as soundfile is faster","1caf54f1":"<h3><font color=\"blue\">Is this kernel useful for you ? Don't forget upvoting it, it really  motivates me in enhancing my work and sharing it with you :)<\/h3><\/font>"}}