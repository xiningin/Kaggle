{"cell_type":{"170fdfc6":"code","8909110f":"code","7fbde7e2":"code","cc6b324f":"code","2b89bac7":"code","076cdc8f":"code","be71f73b":"code","661b85bf":"code","e909cc44":"code","be71e5b2":"code","8093df84":"code","1cf47063":"code","5d49ef45":"code","5a3efdcd":"code","2de7cf7e":"code","5d8d9da2":"code","467d7183":"code","e50fd7c1":"code","aa1fe15d":"code","621430bb":"code","6d1c05de":"code","f14f3c87":"code","faeb9025":"code","9e7cf71c":"code","eff9c3bc":"code","d7d5c86b":"code","0e9b972d":"code","5ab8e33b":"code","7adc7a77":"code","7088c088":"code","0fda88d7":"code","c18c3298":"code","baddf588":"code","ad594fa2":"code","d176916b":"code","e4d7beba":"code","f4b77370":"code","f38bd0c0":"code","1a36987f":"code","588ecdfa":"code","484aae11":"code","9e225ab6":"markdown","36e42e0e":"markdown","9ddd7c6c":"markdown","34423277":"markdown","9728a636":"markdown","eb4504b4":"markdown","aa90931a":"markdown","c7b28031":"markdown","3933540b":"markdown","c88f8270":"markdown","fb9ce33a":"markdown","fda53a45":"markdown","b0e20de3":"markdown"},"source":{"170fdfc6":"import os\nimport re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport cv2\n\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.utils import *\nfrom keras.callbacks import *\n\nfrom keras import backend as K\nfrom keras.applications.densenet import DenseNet121, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import fbeta_score\n\nfrom tqdm import tqdm","8909110f":"train_images = os.listdir(\"..\/input\/imet-2019-fgvc6\/train\/\")\ntest_images = os.listdir(\"..\/input\/imet-2019-fgvc6\/test\/\")\n\nprint(\"number of train images: \", len(train_images))\nprint(\"number of test  images: \", len(test_images))","7fbde7e2":"train = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/train.csv\")\ntrain.head()","cc6b324f":"labels = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/labels.csv\")\nlabels.head()","2b89bac7":"labels_map = {v:i for i, v in zip(labels.attribute_id.values, labels.attribute_name.values)}\nlabels_map_rev = {i:v for i, v in zip(labels.attribute_id.values, labels.attribute_name.values)}\n\nnum_classes = len(labels_map)\nprint(\"{} categories\".format(num_classes))","076cdc8f":"submission = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/sample_submission.csv\")\nsubmission.head()","be71f73b":"def ids_to_lables(attribute_id):\n    return \"\\n\".join([labels_map_rev[int(i)] for i in attribute_id.split(\" \")])","661b85bf":"train[\"labels\"] = train.attribute_ids.apply(lambda x: ids_to_lables(x))\ntrain.head()","e909cc44":"train[\"n_cate\"] = train.attribute_ids.apply(lambda x: len(x.split(\" \")))\ntrain.head()","be71e5b2":"# TODO: maybe multi cultures here.\n\ndef get_culture(x):\n    try: \n        return re.search(r\"culture::(\\w+)\", x).group(1)\n    except:\n        return \"none\"\n\ntrain[\"culture\"] = train.labels.apply(lambda x: get_culture(x))\ntrain.head()","8093df84":"def get_num_tag(x):\n    return len(re.findall(r\"tag::(\\w+)\", x))\n\ntrain[\"n_tag\"] = train.labels.apply(lambda x: get_num_tag(x))\ntrain.head()","1cf47063":"num_not_culture = train[train.culture == \"none\"].shape[0]\n\nprint(\"{} ({:.2f}%) not have a culture categroy\".format(num_not_culture, \n                                                        num_not_culture *100 \/ train.shape[0]))","5d49ef45":"num_not_tag = train[train.n_tag == 0].shape[0]\n\nprint(\"{} ({:.2f}%) not have a tag categroy\".format(num_not_tag, \n                                                    num_not_tag *100 \/ train.shape[0]))","5a3efdcd":"_ = train.n_cate.value_counts().sort_index().plot.bar()","2de7cf7e":"_ = train.n_tag.value_counts().sort_index().plot.bar()","5d8d9da2":"_ = train.culture.value_counts()[:10].sort_index().plot.bar()","467d7183":"def show_images(n_to_show, is_train=True):\n    img_dir = \"..\/input\/imet-2019-fgvc6\/train\/\" if is_train else \"..\/input\/imet-2019-fgvc6\/test\/\"\n    plt.figure(figsize=(16,16))\n    images = os.listdir(img_dir)[:n_to_show]\n    for i in range(n_to_show):\n        img = mpimg.imread(img_dir + images[i])\n        plt.subplot(n_to_show\/2+1, 2, i+1)\n        if is_train:\n            plt.title(train[train.id == images[i].split(\".\")[0]].labels.values[0])\n        plt.imshow(img)\n        plt.axis('off')","e50fd7c1":"show_images(6)","aa1fe15d":"show_images(6, is_train=False)","621430bb":"def obtain_y(ids):\n    y = np.zeros(num_classes)\n    for idx in ids.split(\" \"):\n        y[int(idx)] = 1\n    return y","6d1c05de":"paths = [\"..\/input\/imet-2019-fgvc6\/train\/{}.png\".format(x) for x in train.id.values]\ntargets = np.array([obtain_y(y) for y in train.attribute_ids.values])","f14f3c87":"class ImageGenerator(Sequence):\n    \n    def __init__(self, paths, targets, batch_size, shape, augment=False):\n        self.paths = paths\n        self.targets = targets\n        self.batch_size = batch_size\n        self.shape = shape\n        self.augment = augment\n        \n    def __len__(self):\n        return int(np.ceil(len(self.paths) \/ float(self.batch_size)))\n    \n    def __getitem__(self, idx):\n        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n        y = np.zeros((self.batch_size, num_classes, 1))\n        for i, path in enumerate(batch_paths):\n            x[i] = self.__load_image(path)\n        y = self.targets[idx * self.batch_size : (idx + 1) * self.batch_size]\n        return x, y\n    \n    def __iter__(self):\n        for item in (self[i] for i in range(len(self))):\n            yield item\n            \n    def __load_image(self, path):\n        image = cv2.imread(path)\n        image = cv2.resize(image, (self.shape[0], self.shape[1]))\n        image = preprocess_input(image)\n        if self.augment:\n            seq = iaa.Sequential([\n                iaa.OneOf([\n                    iaa.Fliplr(0.5),\n                    iaa.Flipud(0.5),\n                    iaa.CropAndPad(percent=(-0.25, 0.25)),\n                    iaa.Crop(percent=(0, 0.1)),\n                    iaa.Sometimes(0.5,\n                        iaa.GaussianBlur(sigma=(0, 0.5))\n                    ),\n                    iaa.Affine(\n                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n                        rotate=(-180, 180),\n                        shear=(-8, 8)\n                    )\n                ])\n            ], random_order=True)\n            image = seq.augment_image(image)\n        return image","faeb9025":"batch_size = 64\n\ntrain_paths, val_paths, train_targets, val_targets = train_test_split(paths, \n                                                                      targets,\n                                                                      test_size=0.1, \n                                                                      random_state=1029)\n\ntrain_gen = ImageGenerator(train_paths, train_targets, batch_size=batch_size, shape=(224,224,3), augment=False)\nval_gen = ImageGenerator(val_paths, val_targets, batch_size=batch_size, shape=(224,224,3), augment=False)","9e7cf71c":"inp = Input((224, 224, 3))\nbackbone = DenseNet121(input_tensor=inp,\n                       weights=\"..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5\",\n                       include_top=False)\nx = backbone.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(2048, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\noutp = Dense(num_classes, activation=\"sigmoid\")(x)\n\nmodel = Model(inp, outp)","eff9c3bc":"def f_score(y_true, y_pred, threshold=0.1, beta=2):\n    tp = tp_score(y_true, y_pred, threshold)\n    fp = fp_score(y_true, y_pred, threshold)\n    fn = fn_score(y_true, y_pred, threshold)\n    precision = tp \/ (tp + fp)\n    recall = tp \/ (tp + fn)\n    return (1+beta**2) * ((precision * recall) \/ ((beta**2)*precision + recall))\n\n\ndef tp_score(y_true, y_pred, threshold=0.1):\n    tp_3d = K.concatenate(\n        [\n            K.cast(K.expand_dims(K.flatten(y_true)), 'bool'),\n            K.cast(K.expand_dims(K.flatten(K.greater(y_pred, K.constant(threshold)))), 'bool'),\n            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n        ], axis=1\n    )\n    tp = K.sum(K.cast(K.all(tp_3d, axis=1), 'int32'))\n    return tp\n\n\ndef fp_score(y_true, y_pred, threshold=0.1):\n    fp_3d = K.concatenate(\n        [\n            K.cast(K.expand_dims(K.flatten(K.abs(y_true - K.ones_like(y_true)))), 'bool'),\n            K.cast(K.expand_dims(K.flatten(K.greater(y_pred, K.constant(threshold)))), 'bool'),\n            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n        ], axis=-1\n    )\n    fp = K.sum(K.cast(K.all(fp_3d, axis=1), 'int32'))\n    return fp\n\n\ndef fn_score(y_true, y_pred, threshold=0.1):\n    fn_3d = K.concatenate(\n        [\n            K.cast(K.expand_dims(K.flatten(y_true)), 'bool'),\n            K.cast(K.expand_dims(K.flatten(K.abs(K.cast(K.greater(y_pred, K.constant(threshold)), 'float') - K.ones_like(y_pred)))), 'bool'),\n            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n        ], axis=1\n    )\n    fn = K.sum(K.cast(K.all(fn_3d, axis=1), 'int32'))\n    return fn\n\n\ndef precision_score(y_true, y_pred, threshold=0.1):\n    tp = tp_score(y_true, y_pred, threshold)\n    fp = fp_score(y_true, y_pred, threshold)\n    return tp \/ (tp + fp)\n\n\ndef recall_score(y_true, y_pred, threshold=0.1):\n    tp = tp_score(y_true, y_pred, threshold)\n    fn = fn_score(y_true, y_pred, threshold)\n    return tp \/ (tp + fn)","d7d5c86b":"checkpoint = ModelCheckpoint('model.h5', \n                             monitor='val_f_score', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='max', \n                             save_weights_only=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_f_score', factor=0.2,\n                              patience=1, verbose=1, mode='max',\n                              min_delta=0.0001, cooldown=2, min_lr=1e-7)\n\nearly_stop = EarlyStopping(monitor=\"val_f_score\", mode=\"max\", patience=5)","0e9b972d":"model.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(1e-03),\n    metrics=['acc', f_score])","5ab8e33b":"history = model.fit_generator(generator=train_gen, \n                              steps_per_epoch=len(train_gen), \n                              validation_data=val_gen, \n                              validation_steps=len(val_gen),\n                              epochs=15,\n                              callbacks=[checkpoint, reduce_lr, early_stop])","7adc7a77":"plt.rcParams['figure.figsize'] = (6,6)\n\nfscore = history.history['f_score']\nval_fscore = history.history['val_f_score']\nepochs = range(1, len(fscore) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, fscore, 'red', label='Training f_score')\nplt.plot(epochs, val_fscore, 'blue', label='Validation f_score')\nplt.legend()\n\nplt.show()","7088c088":"model.load_weights(\".\/model.h5\")","0fda88d7":"class TestImageGenerator(Sequence):\n    \n    def __init__(self, paths, batch_size, shape):\n        self.paths = paths\n        self.targets = targets\n        self.batch_size = batch_size\n        self.shape = shape\n        \n    def __len__(self):\n        return int(np.ceil(len(self.paths) \/ float(self.batch_size)))\n    \n    def __getitem__(self, idx):\n        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n        for i, path in enumerate(batch_paths):\n            x[i] = self.__load_image(path)\n        return x\n    \n    def __iter__(self):\n        for item in (self[i] for i in range(len(self))):\n            yield item\n            \n    def __load_image(self, path):\n        image = cv2.imread(path)\n        image = cv2.resize(image, (self.shape[0], self.shape[1]))\n        image = preprocess_input(image)\n        return image","c18c3298":"test_paths = [\"..\/input\/imet-2019-fgvc6\/test\/{}.png\".format(x) for x in submission.id.values]\ntest_gen = TestImageGenerator(test_paths, batch_size=batch_size, shape=(224,224,3))\n\npredicts = model.predict_generator(test_gen, verbose=1)","baddf588":"n = 6\nthreshold = 0.15\n\nimg = cv2.imread(test_paths[n])\nplt.imshow(img)\n\na = np.array(predicts[n]>threshold, dtype=np.int8)\nb = np.where(a==1)[0]\nfor idx in b.tolist():\n    print(labels_map_rev[idx])","ad594fa2":"train.n_tag.describe()","d176916b":"def classifier(probs):\n    \n    culture = None\n    tags = None\n    arr = probs.argsort()\n    \n    culture_threshold = 0.1\n    tag_max_threshold = 0.55\n    \n    n_min_tag = 1\n    n_max_tag = 3\n    \n    # first: find culture category by sorting probs\n    \n    for idx in arr[::-1]:\n        if labels_map_rev[idx].startswith(\"culture\") and probs[idx] > culture_threshold:\n            culture = str(idx)\n            break           # TODO: maybe multi culture here.\n    \n    # second: find tags by different threshold\n    for threshold in np.arange(0.05, tag_max_threshold, 0.05):\n        n = 0                # stores len(tags)\n        tags_list = list()   # stores tags\n        \n        a = np.array(probs > threshold, dtype=np.int8)\n        b = np.where(a == 1)[0]\n        for idx in b.tolist():\n            if labels_map_rev[idx].startswith(\"tag\"):\n                n += 1\n                tags_list.append(str(idx))\n        if n >= n_min_tag and n <= n_max_tag:\n            tags = tags_list\n            break\n    \n    # finally packs our answer\n    answer = list()\n    if culture:\n        answer.append(culture)\n    if tags:\n        for t in tags:\n            answer.append(t)\n            \n    return \" \".join(answer)","e4d7beba":"predictions = list()\n\nfor probs in tqdm(predicts):\n    predictions.append(classifier(probs))","f4b77370":"submission[\"attribute_ids\"] = np.array(predictions)\nsubmission.head()","f38bd0c0":"submission_df = submission.copy()\nsubmission_df.n_cate = submission.attribute_ids.apply(lambda x: len(x.split(\" \")))\n_ = submission_df.n_cate.value_counts().sort_index().plot.bar()","1a36987f":"submission.to_csv('submission.csv', index=False)","588ecdfa":"submission.shape","484aae11":"!head submission.csv","9e225ab6":"### do prediction","36e42e0e":"## imports","9ddd7c6c":"## prediction","34423277":"### test image generator","9728a636":"## EDA","eb4504b4":"### train test split","aa90931a":"### image generator","c7b28031":"## load data","3933540b":"### f_score for Keras","c88f8270":"### submission","fb9ce33a":"### check our prediction","fda53a45":"## build model","b0e20de3":"## prepare X and y"}}