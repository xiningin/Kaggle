{"cell_type":{"1f6fbb83":"code","05c098e6":"code","e533b66d":"code","c82ca06f":"code","e007438c":"code","86f2a94c":"code","321e1d1e":"code","d410f158":"code","29b55775":"code","3c202394":"code","f08df4b2":"code","a3a4e1b2":"code","c02cf82f":"code","fce7f962":"code","88347843":"code","16b7e685":"code","eb0417fb":"code","9fafff61":"code","4601ee2b":"code","0a84d98a":"code","4c503e2a":"code","d463727d":"code","b6987d28":"code","317c3037":"code","771e8402":"code","fd72b43e":"code","8f5005b3":"code","adebc666":"code","c91412e7":"code","27ffc76b":"code","7b5927e7":"code","22558a70":"code","0a65e3e3":"code","75062f49":"code","e691cca5":"code","a5f10e57":"code","c9bc5f15":"code","b672a8a9":"markdown","c369a8aa":"markdown","5ede0059":"markdown"},"source":{"1f6fbb83":"#Data Preprocessing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nfrom glob import glob\nfrom PIL import Image\nimport os\nimport random\nimport cv2\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05c098e6":"#Model\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model,load_model\nfrom tensorflow.keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPooling2D,MaxPool2D,AveragePooling2D,GlobalMaxPooling2D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras.metrics import PrecisionAtRecall,Recall","e533b66d":"tf.config.list_physical_devices(\"GPU\")","c82ca06f":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score","e007438c":"from numpy.random import seed\nseed(0)","86f2a94c":"tf.random.set_seed(0)","321e1d1e":"path = '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset'\n\ndiag_code_dict = {\n    'COVID': 0,\n    'Lung_Opacity': 1,\n    'Normal': 2,\n    'Viral Pneumonia': 3}\n\ndiag_title_dict = {\n    'COVID': 'Covid-19',\n    'Lung_Opacity': 'Lung Opacity',\n    'Normal': 'Healthy',\n    'Viral Pneumonia': 'Viral Pneumonia'}\n\nimageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in glob(os.path.join(path, '*','*.png'))}\n\nimageid_path_dict","d410f158":"covidData = pd.DataFrame.from_dict(imageid_path_dict, orient = 'index').reset_index()\ncovidData.columns = ['image_id','path']\nclasses = covidData.image_id.str.split('-').str[0]\ncovidData['diag'] = classes\ncovidData['target'] = covidData['diag'].map(diag_code_dict.get)\ncovidData['Class'] = covidData['diag'].map(diag_title_dict.get)","29b55775":"samples,feature = covidData.shape\nduplicated = covidData.duplicated().sum()\nnull_values = covidData.isnull().sum().sum()\n\nprint('Simple EDA')\nprint('Number of samples: %d'%(samples))\nprint('duplicates: %d'%(duplicated))\nprint('null values: %d' %(null_values))","3c202394":"#samples per class\nplt.figure(figsize=(20,8))\nsns.set(style=\"ticks\", font_scale = 1)\nax = sns.countplot(data = covidData,x='Class',order = covidData['Class'].value_counts().index,palette=\"flare\")\nsns.despine(top=True, right=True, left=True, bottom=False)\nplt.xticks(rotation=0,fontsize = 12)\nax.set_xlabel('Sample Type - Diagnosis',fontsize = 14,weight = 'bold')\nax.set(yticklabels=[])\nax.axes.get_yaxis().set_visible(False) \nplt.title('Number of Samples per Class', fontsize = 16,weight = 'bold');\n#plot percentage\nfor p in ax.patches:\n    ax.annotate(\"%.1f%%\" % (100*float(p.get_height()\/samples)), (p.get_x() + p.get_width() \/ 2., abs(p.get_height())),\n    ha='center', va='bottom', color='black', xytext=(0, 10),rotation = 'horizontal',\n    textcoords='offset points')","f08df4b2":"covidData['image'] = covidData['path'].map(lambda x: np.asarray(Image.open(x).resize((75, 75))))","a3a4e1b2":"n_samples =3\n\nfig, m_axs = plt.subplots(4, n_samples, figsize = (4*n_samples, 3*4))\n\nfor n_axs, (type_name, type_rows) in zip(m_axs,covidData.sort_values(['diag']).groupby('diag')):\n    n_axs[1].set_title(type_name,fontsize = 14,weight = 'bold')\n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):       \n        picture = c_row['path']\n        image = cv2.imread(picture)\n        c_ax.imshow(image)\n        c_ax.axis('off')","c02cf82f":"plt.figure()\npic_id = random.randrange(0, samples)\npicture = covidData['path'][pic_id]\nimage - cv2.imread(picture)\nplt.imshow(image)\nplt.axis('off')\nplt.show()","fce7f962":"print('shape of the image: {}'.format(image.shape))","88347843":"print('image size {}'.format(image.size))","16b7e685":"image.dtype","eb0417fb":"print('max rgb: {}'.format(image.max()))","9fafff61":"print('min rgb: {}'.format(image.min()))","4601ee2b":"image[0, 0]","0a84d98a":"plt.title('Bchannel', fontsize=14, weight='bold')\nplt.imshow(image[:,:,0])\nplt.axis('off');\nplt.show()","4c503e2a":"mean_val = []\nstd_dev_val = []\nmax_val = []\nmin_val = []\n\nfor i in range(0, samples):\n    mean_val.append(covidData['image'][i].mean())\n    std_dev_val.append(np.std(covidData['image'][i]))\n    max_val.append(covidData['image'][i].max())\n    min_val.append(covidData['image'][i].min())\n\nimageEDA = covidData.loc[:, ['image', 'Class', 'path']]\nimageEDA['mean'] = mean_val\nimageEDA['stedev'] = std_dev_val\nimageEDA['max'] = max_val\nimageEDA['min'] = min_val\n\nsubt_mean_samples = imageEDA['mean'].mean() - imageEDA['mean']\nimageEDA['subt_mean'] = subt_mean_samples","d463727d":"ax = sns.displot(data = imageEDA, x = 'mean', kind=\"kde\")\nplt.title('Image color mean value distribution')","b6987d28":"ax = sns.displot(data = imageEDA, x = 'mean', kind=\"kde\", hue='Class')\nplt.title('Image color mean value distribution by class')","317c3037":"ax = sns.displot(data = imageEDA, x = 'max', kind=\"kde\", hue='Class')\nplt.title('Image color max value distribution by class')","771e8402":"sns.displot(data = imageEDA, x = 'min', kind=\"kde\", hue='Class')\nplt.title('Image color min value distribution by class')","fd72b43e":"plt.figure(figsize=(20,8))\nsns.set(style=\"ticks\", font_scale = 1)\nax = sns.scatterplot(data=imageEDA, x=\"mean\", y=imageEDA['stedev'], hue = 'Class',alpha=0.8);\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.xticks(rotation=0,fontsize = 12)\nax.set_xlabel('Image Channel Colour Mean',fontsize = 14,weight = 'bold')\nax.set_ylabel('Image Channel Colour Standard Deviation',fontsize = 14,weight = 'bold')\nplt.title('Mean and Standard Deviation of Image Samples', fontsize = 16,weight = 'bold');","8f5005b3":"plt.figure(figsize=(20,8));\ng = sns.FacetGrid(imageEDA, col=\"Class\", height=5)\ng.map_dataframe(sns.scatterplot, x='mean', y='stedev');\ng.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\", size=16)\ng.fig.subplots_adjust(top=.7)\ng.fig.suptitle('Mean anfd standard dev of img samples')\naxes = g.axes.flatten()\naxes[0].set_ylabel('std dev')\nfor ax in axes:\n    ax.set_xlabel('Mean')\ng.fig.tight_layout()","adebc666":"path = '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset'\n\nclasses = [\"COVID\", \"Lung_Opacity\", \"Normal\", \"Viral Pneumonia\"]\nnum_classes = len(classes)\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  rotation_range=20,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  horizontal_flip=True, validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255,\n                                 validation_split=0.2)\n\ntrain_gen = train_datagen.flow_from_directory(directory=path,\n                                             target_size=(299, 299),\n                                             class_mode='categorical',\n                                             subset='training',\n                                             shuffle=True, classes=classes,\n                                             batch_size=batch_size,\n                                             color_mode=\"grayscale\")\n\ntest_gen = test_datagen.flow_from_directory(directory=path,\n                                             target_size=(299, 299),\n                                             class_mode='categorical',\n                                             subset='validation',\n                                             shuffle=False, classes=classes,\n                                             batch_size=batch_size,\n                                             color_mode=\"grayscale\")","c91412e7":"model = Sequential()\nmodel.add(Conv2D(32, (3,3), activation='relu', padding='Same', input_shape=(299, 299, 1)))\nmodel.add(BatchNormalization())\n\n################\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#################\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#################\n\nmodel.add(Flatten())\n\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n#Output \nmodel.add(BatchNormalization())\nmodel.add(Dense(num_classes, activation='softmax'))","27ffc76b":"model.summary()","7b5927e7":"opt = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[Recall()])","22558a70":"#Model params\nepochs=300\n\n#callback\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.5, min_lr=0.00001)\nearly_stopping_monitor = EarlyStopping(patience=100, monitor='val_loss', mode='min')\n\ncallbacks_list = [learning_rate_reduction, early_stopping_monitor]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(train_gen) \/\/ batch_size,\n                    validation_steps=len(test_gen) \/\/ batch_size,\n                    validation_data=test_gen, epochs=epochs, callbacks=[callbacks_list])","0a65e3e3":"y_pred = model.predict(test_gen)","75062f49":"history.history","e691cca5":"fig, axarr = plt.subplots(1,3, figsize=(15,5), sharex=True)\n\nsns.set(style=\"ticks\", font_scale = 1)\nsns.despine(top=True, right=True, left=False, bottom=False)\n\nhistoryDF = pd.DataFrame.from_dict(history.history)\nax = sns.lineplot(x = historyDF.index, y = history.history['recall'], ax=axarr[0], label=\"Training\");\nax = sns.lineplot(x = historyDF.index, y = history.history['val_recall'], ax=axarr[0], label=\"Validation\");\nax.set_ylabel('Recall')\n\nax = sns.lineplot(x = historyDF.index, y = history.history['loss'], ax=axarr[1], label=\"Training\");\nax = sns.lineplot(x = historyDF.index, y = history.history['val_loss'], ax=axarr[1], label=\"Validation\");\nax.set_ylabel('Loss')\n\nax = sns.lineplot(x = historyDF.index, y = history.history['lr'], ax=axarr[2]);\nax.set_ylabel('Learning Rate')\n\naxarr[0].set_title('Training and Validation metric recall')\naxarr[1].set_title('Training and Validation loss')\naxarr[2].set_title('lr during training')\n\nfor ax in axarr:\n    ax.set_xlabel('Epochs')\n\nplt.suptitle('Training and performance plots', fontsize=16, weight='bold');\nfig.tight_layout(pad=3.0)\nplt.show()","a5f10e57":"predictions = np.array(list(map(lambda x: np.argmax(x), y_pred)))\n\ny_true=test_gen.classes\n\nCMatrix = pd.DataFrame(confusion_matrix(y_true, predictions), columns=classes, index =classes)\n\nplt.figure(figsize=(12, 6))\nax = sns.heatmap(CMatrix, annot = True, fmt = 'g' ,vmin = 0, vmax = 250,cmap = 'Blues')\nax.set_xlabel('Predicted',fontsize = 14,weight = 'bold')\nax.set_xticklabels(ax.get_xticklabels(),rotation =0);\n\nax.set_ylabel('Actual',fontsize = 14,weight = 'bold') \nax.set_yticklabels(ax.get_yticklabels(),rotation =0);\nax.set_title('Confusion Matrix - Test Set',fontsize = 16,weight = 'bold',pad=20);","c9bc5f15":"acc = accuracy_score(y_true, predictions)\n\nresults_all = precision_recall_fscore_support(y_true, predictions, average='macro', zero_division=1)\nresults_class = precision_recall_fscore_support(y_true, predictions, average=None, zero_division=1)\n\nmetric_columns = ['Precision','Recall', 'F-Score','S']\nall_df = pd.concat([pd.DataFrame(list(results_class)).T,pd.DataFrame(list(results_all)).T])\nall_df.columns = metric_columns\nall_df.index = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia','Total']\n\ndef metrics_plot(df,metric):\n    plt.figure(figsize=(22,10))\n    ax = sns.barplot(data =df, x=df.index, y = metric,palette = \"Blues_d\")\n    #Bar Labels\n    for p in ax.patches:\n        ax.annotate(\"%.1f%%\" % (100*p.get_height()), (p.get_x() + p.get_width() \/ 2., abs(p.get_height())),\n        ha='center', va='bottom', color='black', xytext=(-3, 5),rotation = 'horizontal',textcoords='offset points')\n    sns.despine(top=True, right=True, left=True, bottom=False)\n    ax.set_xlabel('Class',fontsize = 14,weight = 'bold')\n    ax.set_ylabel(metric,fontsize = 14,weight = 'bold')\n    ax.set(yticklabels=[])\n    ax.axes.get_yaxis().set_visible(False) \n    plt.title(metric+ ' Results per Class', fontsize = 16,weight = 'bold');\n\nmetrics_plot(all_df, 'Precision')#Results by Class\nmetrics_plot(all_df, 'Recall')#Results by Class\nmetrics_plot(all_df, 'F-Score')#Results by Class\nprint('**Overall Results**')\nprint('Accuracy Result: %.2f%%'%(acc*100)) #Accuracy of the whole Dataset\nprint('Precision Result: %.2f%%'%(all_df.iloc[4,0]*100))#Precision of the whole Dataset\nprint('Recall Result: %.2f%%'%(all_df.iloc[4,1]*100))#Recall of the whole Dataset\nprint('F-Score Result: %.2f%%'%(all_df.iloc[4,2]*100))#F-Score of the whole Dataset","b672a8a9":"**MODEL**","c369a8aa":"**EXPLORATORY DATA ANALYSIS**","5ede0059":"**Data Preprocessing**"}}