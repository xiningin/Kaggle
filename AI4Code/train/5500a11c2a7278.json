{"cell_type":{"596d588a":"code","8c85f465":"code","678a1081":"code","d52560d0":"code","3cdc5fff":"code","589e97fc":"code","314915fc":"code","826c0892":"code","4a249a40":"code","15bf8636":"code","733f418e":"code","21b2ae55":"code","3777d223":"code","22857c43":"code","a9fe4ae6":"code","52484eaa":"code","bc1b37dc":"code","3f868ae1":"code","d21421ec":"code","3afd92c1":"code","18151c31":"code","b0ba09eb":"code","3c39f590":"code","960978b2":"code","11e69869":"code","7bba3ad8":"code","260ad30c":"code","15e33336":"code","673f4982":"code","412d2666":"code","1c209a64":"code","1f43d78e":"code","43c6f98e":"code","2e357425":"code","0d6b3b59":"code","6d6d42a8":"code","3dfc2e59":"code","09cc077e":"code","2e528fa4":"code","9b45ec52":"code","cd9b9f07":"code","53054b1d":"code","61b02a19":"code","3e9b5be5":"code","0f4e95e2":"code","56f5500c":"code","7761e9e9":"code","e25b063b":"code","a4259b84":"code","e879c495":"code","b22a1cb5":"code","4c4d94fc":"code","1f140158":"code","c1e71b8a":"code","72308b4a":"code","b080bcea":"code","9b12c870":"code","38caafca":"code","b3a8ff69":"code","d6941ede":"code","c61f6129":"code","edd1b3c1":"code","a2869e40":"code","f4cf4fc5":"code","1b3c0936":"code","fb1e16e8":"markdown","5f09023b":"markdown","4894fcde":"markdown","9c9d8a01":"markdown","30aba2db":"markdown","444e4fb9":"markdown","74236d3c":"markdown","549a0719":"markdown","c7cc78f5":"markdown","681aa30c":"markdown","be2906fe":"markdown","972a62c8":"markdown","f7d45c0e":"markdown","50c56e73":"markdown","6a4c25c8":"markdown","fbd61f0e":"markdown","1ec10e63":"markdown","676687f3":"markdown","f11cdeab":"markdown","ff1f6792":"markdown","75f751dd":"markdown","56c1c237":"markdown","caf7a41a":"markdown","7c9369a0":"markdown","439521b8":"markdown","a3ed9c40":"markdown","ab4bcb8e":"markdown","c381832d":"markdown","8dfaacf8":"markdown","f78914df":"markdown","6b7ba0c7":"markdown","f4f0cb5f":"markdown","0689a3fb":"markdown","bcf04bc3":"markdown","53ba0fe0":"markdown","7fc021e3":"markdown","726632c7":"markdown","0ce51143":"markdown","ab6d283f":"markdown","01e11173":"markdown","657b471a":"markdown","af8e1bf7":"markdown","d3849b92":"markdown","4861aa81":"markdown","2c429808":"markdown","cf9e0780":"markdown","65878430":"markdown","9bcbca70":"markdown","18b96fc8":"markdown","d35e3bb7":"markdown","3976d04e":"markdown","015052b7":"markdown","85714acb":"markdown","1ce4983d":"markdown","8956b75a":"markdown","6977d02b":"markdown","56d0617c":"markdown","27473149":"markdown","85f7211b":"markdown","ba2dfc2c":"markdown","fc40839e":"markdown","33992cde":"markdown","d7da72b7":"markdown"},"source":{"596d588a":"import warnings\nimport numpy as np \nimport pandas as pd\nimport plotly as py\nimport seaborn as sns\nimport statistics as stat\nfrom datetime import date\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\n\nimport plotly.offline as pyo\npyo.init_notebook_mode()\n\nimport matplotlib.lines as lines\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","8c85f465":"df = pd.read_csv('..\/input\/depression-anxiety-stress-scales\/DASS_data_21.02.19\/data.csv', sep= '\\t')\ndf.head(2)","678a1081":"df['strike'] = 0\ndf['strike'] = df['strike'].where(df['VCL6']== 0, df['strike'] + 1)\ndf['strike'] = df['strike'].where(df['VCL9']== 0, df['strike'] + 1)\ndf['strike'] = df['strike'].where(df['VCL12']== 0, df['strike'] + 1)\n\ndf.strike.value_counts()","d52560d0":"df = df.loc[~df['strike'].isin([2, 3])]\ndf.head(2)","3cdc5fff":"df.describe()","589e97fc":"df = df[ df['testelapse'] <= df['testelapse'].quantile(0.975) ]\ndf = df[ df['testelapse'] >= df['testelapse'].quantile(0.025) ]\ndf = df[ df['surveyelapse'] <= df['surveyelapse'].quantile(0.975) ]\ndf = df[ df['surveyelapse'] >= df['surveyelapse'].quantile(0.025) ]","314915fc":"median = df.loc[df['age'] <=80, 'age'].median()\ndf.loc[df.age > 80, 'age'] = np.nan\ndf.fillna(median,inplace=True)\n","826c0892":"vcls = df.iloc[:, -32:-16].columns\n\nmain = df.iloc[:, 0:126]\nother = df.iloc[:, 126:]\nmain_ans_only = main[main.columns[::3]]\n\nndf = pd.concat([main_ans_only, other], axis=1)\nndf = ndf.drop(columns= vcls )\nndf.head(2)","4a249a40":"age_group = [\n    'below 20',\n    '20 to 24',\n    '25 to 29',\n    '30 to 34',\n    '35 to 39',\n    '40 to 49',\n    '50 to 59',\n    'above 60',\n]\n\ndef label_age(row):\n    if row['age'] < 20:\n        return age_group[0]\n    elif row['age'] < 25:\n        return age_group[1]\n    elif row['age'] < 30:\n        return age_group[2]\n    elif row['age'] < 35:\n        return age_group[3]\n    elif row['age'] < 40:\n        return age_group[4]\n    elif row['age'] < 50:\n        return age_group[5]\n    elif row['age'] < 60:\n        return age_group[6]\n    elif row['age'] > 60:\n        return age_group[7]\n\nndf['age_group'] = ndf.apply(lambda row: label_age(row), axis=1)\nndf.head(2)","15bf8636":"def make_pie_chart(data, series, title):\n    temp_series = data[ series ].value_counts()\n        # what we want to show in our charts\n\n    labels = ( np.array(temp_series.index) )\n    sizes = ( np.array( ( temp_series \/ temp_series.sum() ) *100) )\n\n    trace = go.Pie(labels=labels, \n                   values=sizes)\n    layout= go.Layout(\n        title= title,\n        title_font_size= 24,\n        #title_font_color= 'red',\n        #title_x= 0.45,\n    )\n    fig = go.Figure(data= [trace],\n                    layout=layout)\n\n    fig.show()","733f418e":"make_pie_chart(ndf, 'age_group', 'Distribution by Age')","21b2ae55":"temp = ndf.copy()\ntemp['gender'].replace({\n    1: \"Male\",\n    2: \"Female\",\n    3: \"Non-binary\",\n    0: \"Unanswered\",\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'gender', 'Distribution by Gender')","3777d223":"temp = ndf.copy()\ntemp['education'].replace({\n    1: \"Less than high school\",\n    2: \"High school\",\n    3: \"University degree\",\n    4: 'Graduate degree',\n    0: \"Unanswered\",\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'education', 'Distribution by Education')","22857c43":"temp = ndf.copy()\ntemp['urban'].replace({\n    1: \"Rural\",\n    2: \"Suburban\",\n    3: \"Urban\",\n    0: \"Unanswered\",\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'urban', 'Distribution by Urban')","a9fe4ae6":"temp = ndf.copy()\ntemp['hand'].replace({\n    1: \"Right\",\n    2: \"Left\",\n    3: \"Both\",\n    0: \"Unanswered\",\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'hand', 'Distribution by Hand')","52484eaa":"temp = ndf.copy()\ntemp['religion'].replace({\n    1: \"Agnostic\",\n    2: \"Atheist\",\n    3: \"Buddhist\",\n    4: 'Christian',\n    5: 'Christian',\n    6: 'Christian',\n    7: 'Christian',\n    8: 'Hindu',\n    9: 'Jewish',\n    10: 'Muslim',\n    11: 'Sikh',\n    12: 'Other',\n    0: 'Unanswered',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'religion', 'Distribution by Religion')","bc1b37dc":"temp = ndf.copy()\ntemp['orientation'].replace({\n    1: \"Heterosexual\",\n    2: \"Bisexual\",\n    3: \"Homosexual\",\n    4: 'Asexual',\n    5: 'Other',\n    0: 'Unanswered',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'orientation', 'Distribution by Sexual Orientation')","3f868ae1":"temp = ndf.copy()\ntemp['race'].replace({\n    10: \"Asian\",\n    20: \"Arab\",\n    30: \"Black\",\n    40: 'Indigenous',\n    50: 'Native American',\n    60: 'White',\n    70: 'Other',\n    0: 'Unanswered',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'race', 'Distribution by Race')","d21421ec":"temp = ndf.copy()\ntemp['voted'].replace({\n    1: \"Yes\",\n    2: \"No\",\n    0: 'Unanswered',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'voted', 'Distribution by Voted')","3afd92c1":"temp = ndf.copy()\ntemp['married'].replace({\n    1: \"Never\",\n    2: \"Currently married\",\n    3: 'Previously married',\n    0: 'Unanswered',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'married', 'Distribution by Marriage Status')","18151c31":"temp = ndf.copy()\ntemp['uniquenetworklocation'].replace({\n    1: \"One in network\",\n    2: \"Multiple in network\",\n    0: 'Unanswered',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'uniquenetworklocation', 'Distribution by Unique')","b0ba09eb":"temp = ndf.copy()\ntemp['source'].replace({\n    1: \"Front page of site\",\n    2: \"Google redirect\",\n    0: 'Other',\n},\n    inplace=True)\n\nmake_pie_chart(temp, 'source', 'Distribution by Source')","3c39f590":"ndf.familysize.value_counts()","960978b2":"ndf.major.value_counts().head(20)","11e69869":"ndf.country.value_counts().head(20)","7bba3ad8":"labeled= [\n    'I found myself getting upset by quite trivial things.',\n    \n    'I was aware of dryness of my mouth.',\n    \n    'I couldn\\'t seem to experience any positive feeling at all.',\n    \n    'I experienced breathing difficulty.',\n    \n    'I just couldn\\'t seem to get going',\n    \n    'I tended to over-react to situations.',\n    \n    'I had a feeling of shakiness.',\n    \n    'I found it difficult to relax.',\n    \n    'I found myself in situations that made me so anxious I was most relieved when they ended.',\n    \n    'I felt that I had nothing to look forward to.',\n    \n    'I found myself getting upset rather easily.',\n    \n    'I felt that I was using a lot of nervous energy.',\n    \n    'I felt sad and depressed.',\n    \n    'I found myself getting impatient when I was delayed in any way.',\n    \n    'I had a feeling of faintness.',\n    \n    'I felt that I had lost interest in just about everything.',\n    \n    'I felt I wasn\\'t worth much as a person.',\n    \n    'I felt that I was rather touchy.',\n    \n    'I perspired noticeably (eg, hands sweaty) in the absence of high temperatures or physical exertion.',\n    \n    'I felt scared without any good reason.',\n    \n    'I felt that life wasn\\'t worthwhile.',\n    \n    'I found it hard to wind down.',\n    \n    'I had difficulty in swallowing.',\n    \n    'I couldn\\'t seem to get any enjoyment out of the things I did.',\n    \n    'I was aware of the action of my heart in the absence of physical exertion.',\n    \n    'I felt down-hearted and blue.',\n    \n    'I found that I was very irritable.',\n    \n    'I felt I was close to panic.',\n    \n    'I found it hard to calm down after something upset me.',\n    \n    'I feared that I would be \"thrown\" by some trivial but unfamiliar task.',\n    \n    'I was unable to become enthusiastic about anything.',\n    \n    'I found it difficult to tolerate interruptions to what I was doing.',\n    \n    'I was in a state of nervous tension.',\n    \n    'I felt I was pretty worthless.',\n    \n    'I was intolerant of anything that kept me from getting on with what I was doing.',\n    \n    'I felt terrified.',\n    \n    'I could see nothing in the future to be hopeful about.',\n    \n    'I felt that life was meaningless.',\n    \n    'I found myself getting agitated.',\n    \n    'I was worried about situations in which I might panic and make a fool of myself.',\n    \n    'I experienced trembling (eg, in the hands).',\n    \n    'I found it difficult to work up the initiative to do things.',\n]","260ad30c":"def question(data, number_of_questions):\n    q = data.iloc[:, 0:number_of_questions]\n    qs = q.T.copy()\n    \n ####################################################\n    qs['no ans']     = q[q == 0].count()\n    qs['not at all'] = q[q == 1].count()\n    qs['some times'] = q[q == 2].count()\n    qs['many times'] = q[q == 3].count()\n    qs['most times'] = q[q == 4].count()\n    \n    qs['total'] = qs[ ['not at all', \n                       'some times', \n                       'many times', \n                       'most times'] ].sum(axis= 1)\n    \n    ####################################################\n    qs.reset_index(level=0, inplace= True)\n    qs = qs.rename(columns= {'index': 'question'})   \n\n    qs['p_na']     = round( qs['no ans'] * 100 \/ qs['total'], 2)\n    qs['p_not']    = round( qs['not at all'] * 100 \/ qs['total'], 2)\n    qs['p_slight'] = round( qs['some times'] * 100 \/ qs['total'], 2)\n    qs['p_mainly'] = round( qs['many times'] * 100 \/ qs['total'], 2)\n    qs['p_very']   = round( qs['most times'] * 100 \/ qs['total'], 2)\n    \n    \n    choices = [\n        'question',\n        'no ans',\n        'not at all',\n        'some times',\n        'many times',\n        'most times',\n        'total',\n        'p_na',\n        'p_not',\n        'p_slight',\n        'p_mainly',\n        'p_very',\n    ]\n\n    clean = qs[choices]\n    clean['labeled_question'] = np.asarray(labeled).flatten()\n    \n    return clean\n\nquestion(ndf, 42)","15e33336":"top_labels = ['Not at all<br>like me', \n              'Slightly<br>like me',\n              'Mainly<br>like me', \n              'Very much<br>like me',]\n\ncolors     = [ \n    '#A2D3C2',\n    '#658E9C',\n    '#4D5382',\n    '#514663'\n]\n\ny_data= [\n'I found myself getting upset by quite trivial things.',\n\n'I was aware of dryness of my mouth.',\n\n'I couldn\\'t seem to experience any positive feeling at all.',\n\n'I experienced breathing difficulty.',\n\n'I just couldn\\'t seem to get going',\n\n'I tended to over-react to situations.',\n\n'I had a feeling of shakiness.',\n\n'I found it difficult to relax.',\n\n'I found myself in situations that made me so anxious<br>\\\nI was most relieved when they ended.',\n\n'I felt that I had nothing to look forward to.',\n\n'I found myself getting upset rather easily.',\n\n'I felt that I was using a lot of nervous energy.',\n\n'I felt sad and depressed.',\n\n'I found myself getting impatient when I was delayed in any way.',\n\n'I had a feeling of faintness.',\n\n'I felt that I had lost interest in just about everything.',\n\n'I felt I wasn\\'t worth much as a person.',\n\n'I felt that I was rather touchy.',\n\n'I perspired noticeably (eg, hands sweaty) in the<br>\\\nabsence of high temperatures or physical exertion.',\n\n'I felt scared without any good reason.',\n\n'I felt that life wasn\\'t worthwhile.',\n\n'I found it hard to wind down.',\n\n'I had difficulty in swallowing.',\n\n'I couldn\\'t seem to get any enjoyment out of the things I did.',\n\n'I was aware of the action of my heart in the<br>\\\nabsence of physical exertion.',\n\n'I felt down-hearted and blue.',\n\n'I found that I was very irritable.',\n\n'I felt I was close to panic.',\n\n'I found it hard to calm down after something upset me.',\n\n'I feared that I would be \"thrown\" by some trivial but unfamiliar task.',\n\n'I was unable to become enthusiastic about anything.',\n\n'I found it difficult to tolerate interruptions to what I was doing.',\n\n'I was in a state of nervous tension.',\n\n'I felt I was pretty worthless.',\n\n'I was intolerant of anything that kept me from getting on<br>\\\nwith what I was doing.',\n\n'I felt terrified.',\n\n'I could see nothing in the future to be hopeful about.',\n\n'I felt that life was meaningless.',\n\n'I found myself getting agitated.',\n\n'I was worried about situations in which I might panic<br>\\\nand make a fool of myself.',\n\n'I experienced trembling (eg, in the hands).',\n\n'I found it difficult to work up the initiative to do things.',\n]","673f4982":"def plot_likert(data, title, height= 1400, width= 1000):\n    x_data = np.array( data[ ['p_not',\n                              'p_slight',\n                              'p_mainly',\n                              'p_very',] ] )\n\n    \n    fig = go.Figure()\n    \n    #################################\n    for i in range(0, len(x_data[0])):\n        for xd, yd in zip(x_data, y_data):\n            fig.add_trace(go.Bar(\n                x=[xd[i]], y=[yd],\n                orientation='h',\n                marker=dict(\n                    color=colors[i],\n                    line=dict(color='rgb(248, 248, 249)', width=1)\n                )\n            ))\n\n    ####################################\n    fig.update_layout(\n        xaxis=dict(\n            showgrid=False,\n            showline=False,\n            showticklabels=False,\n            zeroline=False,\n            domain=[0.15, 1]\n        ),\n        yaxis=dict(\n            showgrid=False,\n            showline=False,\n            showticklabels=False,\n            zeroline=False,\n            autorange= 'reversed',\n                # Flipping order of the bar charts\n        ),\n        barmode='stack',\n        paper_bgcolor='rgb(248, 248, 255)',\n        plot_bgcolor='rgb(248, 248, 255)',\n        margin= dict(l=120, r=10, t=140, b=80),\n        showlegend=False,\n        height= height,\n        width= width,\n        title={\n            'text': title,\n            'font_size': 28,\n            'font_color': 'black',\n            'x': 0.5\n        },\n    )\n    \n    #########################################\n    annotations = []\n\n    for yd, xd in zip(y_data, x_data):\n        # labeling the y-axis\n        annotations.append(dict(xref='paper', yref='y',\n                                x=0.14, y=yd,\n                                xanchor='right',\n                                text=str(yd),\n                                font=dict(family='Arial', size=10,\n                                          color='rgb(67, 67, 67)'),\n                                showarrow=False, align='right'))\n        \n        # labeling the first percentage of each bar (x_axis)\n        annotations.append(dict(xref='x', yref='y',\n                                x=xd[0] \/ 2, y=yd,\n                                text=str(xd[0]) + '%',\n                                font=dict(family='Arial', size=14,\n                                          color='rgb(248, 248, 255)'),\n                                showarrow=False))\n        \n        # labeling the first Likert scale (on the top)\n        if yd == y_data[-1]:\n            annotations.append(dict(xref='x', yref='paper',\n                                    x= xd[0] \/ 2, y= 1.02,\n                                    text= top_labels[0],\n                                    font=dict(family='Arial', size=16,\n                                              \n                                              color='rgb(67, 67, 67)'),\n                                    showarrow= False))\n\n        space = xd[0]\n        for i in range(1, len(xd)):\n            # labeling the rest of percentages for each bar (x_axis)\n            annotations.append(dict(xref='x', yref='y',\n                                    x=space + (xd[i]\/2), y=yd,\n                                    text=str(xd[i]) + '%',\n                                    font=dict(family='Arial', size=14,\n                                              color='rgb(248, 248, 255)'),\n                                    showarrow=False))\n            # labeling the Likert scale\n            if yd == y_data[0]:\n                # 13th question was used because the scale is more normally distributed\n                annotations.append(dict(xref='x', yref='paper',\n                                        x=space + (xd[i]\/2), y=1.02,\n                                        text=top_labels[i],\n                                        font=dict(family='Arial', size=16,\n                                                  color='rgb(67, 67, 67)'),\n                                        showarrow=False))\n            space += xd[i]\n\n    #########################################\n    fig.update_layout(annotations=annotations)\n    fig.show()\n    \nplot_likert(question(ndf, 42), 'Depression and Anxiety Results', height=2100, width= 1400)","412d2666":"def select_question(lst, question_number):    \n    rows =[]\n    for i in range(len(lst)):\n        rows.append( lst[i].iloc[ question_number-1 ] )\n    \n    df = pd.concat(rows, axis=1)\n    \n    return df.T.iloc[:, -5:]\n\ndef plot_bar_wtrends(data, group, colors, title, legend= False):\n    \"\"\"\n    data: insert a data\n    group: insert a list of names. EG: ['below 20', '20 to 24', '24 to 29']. \n    title: Enter a string that will be used for title purposes.\n    legend: True to reveal legends for interactive plot purposes. \n    \"\"\"\n    import matplotlib.lines as lines\n    import matplotlib.pyplot as plt\n    import plotly as py\n    import plotly.express as px\n    import plotly.graph_objs as go\n\n    labeled_range = [\n        'Not at all like me',\n        'Slightly like me',\n        'Mainly like me',\n        'Very much like me',\n    ]\n\n    ###############\n    t = data.T \\\n        .set_axis( group, axis=1, inplace=False ) \\\n        .rename_axis('ind', axis=0) \\\n        .reset_index()\n\n    transpose = t.iloc[:-1]\n    transpose['ind'] = labeled_range\n      \n    #################\n    trace = []\n    \n    for i in range(len(group)):\n        trace.append(\n            go.Bar(\n                x= transpose.ind,\n                y= transpose[ group[i] ],\n                name= group[i],\n                marker_color= colors[i]\n            )\n        )\n        \n    fig = go.Figure(data= trace)\n\n    ####################    \n    fig.update_layout(\n        title={\n            'text': title,\n            'font_size': 14,\n            'font_color': 'darkgreen',\n            'x': 0.5\n        },\n        xaxis_tickfont_size=14,\n        yaxis=dict(\n            title='',\n            titlefont_size=16,\n            tickfont_size=14,\n        ),\n        legend=dict(\n            x=0.995,\n            y=0.98,\n            bgcolor='rgba(255, 255, 255, 0)',\n            bordercolor='rgba(255, 255, 255, 0)',\n        ),\n        showlegend= legend,\n        barmode='group',\n        bargap=0.25, \n        bargroupgap=0.1 \n    )\n    \n    return fig.show()","1c209a64":"df_b20 = ndf[ ndf['age_group'] == age_group[0] ]\ndf_b25 = ndf[ ndf['age_group'] == age_group[1]]\ndf_b30 = ndf[ ndf['age_group'] == age_group[2]]\ndf_b35 = ndf[ ndf['age_group'] == age_group[3]]\ndf_b40 = ndf[ ndf['age_group'] == age_group[4]]\ndf_b50 = ndf[ ndf['age_group'] == age_group[5]]\ndf_b60 = ndf[ ndf['age_group'] == age_group[6]]\ndf_p60 = ndf[ ndf['age_group'] == age_group[7]]\n\nages = [\n    question(df_b20, 42),\n    question(df_b25, 42),\n    question(df_b30, 42),\n    question(df_b35, 42),\n    question(df_b40, 42),\n    question(df_b50, 42),\n    question(df_b60, 42),\n    question(df_p60, 42),\n]\n\ncolors = [\n    '#B7E4C7',\n    '#95D5B2',\n    '#74C69D',\n    '#52B788',\n    '#40916C',\n    '#2D6A4F',\n    '#1B4332',\n    '#081C15',\n]\n\nage_res=[]\n\nfor i in range(1):\n    age_res.append( plot_bar_wtrends(select_question(ages, i), \n                                     age_group, \n                                     colors,\n                                     f'{y_data[i]}', legend= True) )","1f43d78e":"gender_group= [\n    \"Male\",\n    \"Female\",\n#     \"Non-binary\",\n#     \"Unanswered\",\n]\n\ndf_male = ndf[ ndf['gender'] == 1 ]\ndf_fem  = ndf[ ndf['gender'] == 2 ]\ndf_nbin = ndf[ ndf['gender'] == 3 ]\ndf_na   = ndf[ ndf['gender'] == 0 ]\n\ngenders = [\n    question(df_male, 42),\n    question(df_fem, 42),\n#     question(df_nbin, 42),\n#     question(df_na, 42),\n]\n\ncolors = [\n    '#A9DEF9',\n    '#FF99C8',\n#     '#658E9C',\n#     '#230C0F',\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(genders, i), \n                     gender_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","43c6f98e":"education_group= [\n    \"Less than high school\",\n    \"High school\",\n    \"University degree\",\n    'Graduate degree',\n#    \"Unanswered\",\n]\n\ndf_lhs = ndf[ ndf['education'] == 1 ]\ndf_hs  = ndf[ ndf['education'] == 2 ]\ndf_uni = ndf[ ndf['education'] == 3 ]\ndf_grad = ndf[ ndf['education'] == 4 ]\ndf_eduna = ndf[ ndf['education'] == 0 ]\n\neducations = [\n    question(df_lhs, 42),\n    question(df_hs, 42),\n    question(df_uni, 42),\n    question(df_grad, 42),\n#    question(df_eduna, 42),\n]\n\ncolors = [\n    '#B7E4C7',\n    '#95D5B2',\n    '#74C69D',\n    '#52B788',\n    '#40916C',\n    '#2D6A4F',\n    '#1B4332',\n    '#081C15',\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(educations, i), \n                     education_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","2e357425":"# No correlation\nurban_group= [\n    \"Rural\",\n    \"Suburban\",\n    \"Urban\",\n]\n\ndf_1 = ndf[ ndf['urban'] == 1 ]\ndf_2 = ndf[ ndf['urban'] == 2 ]\ndf_3 = ndf[ ndf['urban'] == 3 ]\n\nurbans = [\n    question(df_1, 42),\n    question(df_2, 42),\n    question(df_3, 42),\n]\n\ncolors = [\n    '#B7E4C7',\n    '#95D5B2',\n    '#74C69D',\n    '#52B788',\n    '#40916C',\n    '#2D6A4F',\n    '#1B4332',\n    '#081C15',\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(urbans, i), \n                     urban_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","0d6b3b59":"hand_group= [\n    \"Right handed\",\n    \"Left handed\",\n]\n\ndf_1 = ndf[ ndf['hand'] == 1 ]\ndf_2 = ndf[ ndf['hand'] == 2 ]\n\nhands = [\n    question(df_1, 42),\n    question(df_2, 42),\n]\n\ncolors = [\n    '#B7E4C7',\n    '#95D5B2',\n    '#74C69D',\n    '#52B788',\n    '#40916C',\n    '#2D6A4F',\n    '#1B4332',\n    '#081C15',\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(hands, i), \n                     hand_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","6d6d42a8":"temp = ndf.copy()\ntemp['religion'].replace({\n    1: \"Agnostic\",\n    2: \"Atheist\",\n    3: \"Buddhist\",\n    4: 'Christian',\n    5: 'Christian',\n    6: 'Christian',\n    7: 'Christian',\n    8: 'Hindu',\n    9: 'Jewish',\n    10: 'Muslim',\n    11: 'Sikh',\n    12: 'Other',\n    0: 'Unanswered',\n},\n    inplace=True)\n\n\nreligion_group= [\n    \"Agnostic\",\n    \"Atheist\",\n    'Buddhist',\n    'Christian',\n#     'Christian (Mormon)',\n#     'Christian (Protestant)',\n#     'Christian (Other)',\n    'Hindu',\n    'Jewish',\n    'Muslim',\n    'Sikh',\n    'Other'\n]\n\ndf_1 = temp[ temp['religion'] == 'Agnostic' ]\ndf_2 = temp[ temp['religion'] == 'Atheist' ]\ndf_3 = temp[ temp['religion'] == 'Buddhist' ]\ndf_4 = temp[ temp['religion'] == 'Christian' ]\ndf_5 = temp[ temp['religion'] == 'Hindu' ]\ndf_6 = temp[ temp['religion'] == 'Jewish' ]\ndf_7 = temp[ temp['religion'] == 'Muslim' ]\ndf_8 = temp[ temp['religion'] == 'Sikh' ]\ndf_9 = temp[ temp['religion'] == 'Other' ]\n# df_10 = ndf[ ndf['religion'] == 10 ]\n# df_11 = ndf[ ndf['religion'] == 11 ]\n# df_12 = ndf[ ndf['religion'] == 12 ]\n\nreligions = [\n    question(df_1, 42),\n    question(df_2, 42),\n    question(df_3, 42),\n    question(df_4, 42),\n    question(df_5, 42),\n    question(df_6, 42),\n    question(df_7, 42),\n    question(df_8, 42),\n    question(df_9, 42),\n#     question(df_10, 42),\n#     question(df_11, 42),\n#     question(df_12, 42),\n]\n\ncolors = [\n    '#B7E4C7',\n    '#95D5B2',\n    '#74C69D',\n    '#52B788',\n    '#40916C',\n    '#2D6A4F',\n    '#1B4332',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(religions, i), \n                     religion_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","3dfc2e59":"temp = ndf.copy()\ntemp['orientation'].replace({\n    1: \"Heterosexual\",\n    2: \"Non-heterosexual\",\n    3: \"Non-heterosexual\",\n    4: 'Non-heterosexual',\n    5: 'Non-heterosexual',\n},\n    inplace=True)\n\n\norientation_group= [\n    'Heterosexual',\n    'Non-heterosexual',\n]\n\ndf_1 = temp[ temp['orientation'] == 'Heterosexual' ]\ndf_2 = temp[ temp['orientation'] == 'Non-heterosexual' ]\n# df_3 = ndf[ ndf['orientation'] == 3 ]\n# df_4 = ndf[ ndf['orientation'] == 4 ]\n# df_5 = ndf[ ndf['orientation'] == 5 ]\n\n\norientations = [\n    question(df_1, 42),\n    question(df_2, 42),\n#     question(df_3, 42),\n#     question(df_4, 42),\n#     question(df_5, 42),\n]\n\ncolors = [\n    '#74C69D',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(orientations, i), \n                     orientation_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","09cc077e":"race_group= [\n    'Asian',\n    #'Arab',\n    'Black',\n    #'Indie Australian',\n    #'Native American',\n    'White',\n    'Other',\n]\n\ndf_1 = ndf[ ndf['race'] == 10 ]\ndf_2 = ndf[ ndf['race'] == 20 ]\ndf_3 = ndf[ ndf['race'] == 30 ]\ndf_4 = ndf[ ndf['race'] == 40 ]\ndf_5 = ndf[ ndf['race'] == 50 ]\ndf_6 = ndf[ ndf['race'] == 60 ]\ndf_7 = ndf[ ndf['race'] == 70 ]\n\n\nraces = [\n    question(df_1, 42),\n    #question(df_2, 42),\n    question(df_3, 42),\n    #question(df_4, 42),\n    #question(df_5, 42),\n    question(df_6, 42),\n    question(df_7, 42),\n]\n\ncolors = [\n    '#B7E4C7',\n    '#95D5B2',\n    '#74C69D',\n    '#52B788',\n    '#40916C',\n    '#2D6A4F',\n    '#1B4332',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(races, i), \n                     race_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","2e528fa4":"voted_group= [\n    'Voted',\n    'Did not voted',\n]\n\ndf_1 = ndf[ ndf['voted'] == 1 ]\ndf_2 = ndf[ ndf['voted'] == 2 ]\n\n\nvotes = [\n    question(df_1, 42),\n    question(df_2, 42),\n]\n\ncolors = [\n    '#74C69D',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(votes, i), \n                     voted_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","9b45ec52":"married_group= [\n    'Never married',\n    'Currently married',\n    'Previously married',\n]\n\ndf_1 = ndf[ ndf['married'] == 1 ]\ndf_2 = ndf[ ndf['married'] == 2 ]\ndf_3 = ndf[ ndf['married'] == 3 ]\n\nmarries = [\n    question(df_1, 42),\n    question(df_2, 42),\n    question(df_3, 42)\n]\n\ncolors = [\n    '#74C69D',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(1):\n    plot_bar_wtrends(select_question(marries, i), \n                     married_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","cd9b9f07":"# No correlation\nuniquenetwork_group= [\n    'One survey per network',\n    'Multiple survey per network',\n]\n\ndf_1 = ndf[ ndf['uniquenetworklocation'] == 1 ]\ndf_2 = ndf[ ndf['uniquenetworklocation'] == 2 ]\n\n\nuniquenetworks = [\n    question(df_1, 42),\n    question(df_2, 42),\n]\n\ncolors = [\n    '#74C69D',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(1):\n    plot_bar_wtrends(select_question(uniquenetworks, i), \n                     uniquenetwork_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","53054b1d":"# Surprisingly, there is correlation\nsource_group= [\n    'Front page of survey site',\n    'Google redirect',\n    'Other',\n]\n\ndf_1 = ndf[ ndf['source'] == 1 ]\ndf_2 = ndf[ ndf['source'] == 2 ]\ndf_3 = ndf[ ndf['source'] == 0 ]\n\nsources = [\n    question(df_1, 42),\n    question(df_2, 42),\n    question(df_3, 42)\n]\n\ncolors = [\n    '#74C69D',\n    '#48cae4',\n    '#00b4d8',\n    '#0096c7',\n    '#0077b6',\n    '#023e8a'\n]\n\nfor i in range(2):\n    plot_bar_wtrends(select_question(sources, i), \n                     source_group, \n                     colors,\n                     f'{y_data[i]}', legend= True) ","61b02a19":"def make_corr_map(data, title, zmin=-1, zmax=1, height=600, width= 800):\n    \"\"\"\n    data: Your dataframe.\n    title: Title for the correlation matrix.\n    zmin: Minimum number for color scale. (-1 to 1). Default = -1.\n    zmax: Maximum number for color scale. (-1 to 1). Default = 1.\n    height: Default = 600\n    width: Default = 800\n    \"\"\"\n    \n    data = data.corr()\n    mask = np.triu(np.ones_like(data, dtype=bool))\n    rLT = data.mask(mask)\n\n    heat = go.Heatmap(\n        z = rLT,\n        x = rLT.columns.values,\n        y = rLT.columns.values,\n        zmin = zmin, \n            # Sets the lower bound of the color domain\n        zmax = zmax,\n            # Sets the upper bound of color domain\n        xgap = 1, # Sets the horizontal gap (in pixels) between bricks\n        ygap = 1,\n        colorscale = 'RdBu'\n    )\n\n    title = title\n\n    layout = go.Layout(\n        title_text=title, \n        title_x=0.5, \n        width= width, \n        height= height,\n        xaxis_showgrid=False,\n        yaxis_showgrid=False,\n        yaxis_autorange='reversed'\n    )\n\n    fig=go.Figure(data=[heat], layout=layout)\n    return fig.show()","3e9b5be5":"ndf['score'] = ndf.iloc[:, 0:42].sum(axis= 1)\nndf['mean_score'] = ndf['score'] \/ 42\n\nmake_corr_map(ndf.iloc[:, 42:], \n              'Correlation heatmap for DASS score and variables',\n              zmax=0.8, zmin=-0.8, \n              height= 900)","0f4e95e2":"# Gender\nndf.groupby('gender').mean()","56f5500c":"ndf.groupby('age_group').mean()","7761e9e9":"ndf[ ndf['age_group']== '30 to 34' ].groupby('married').mean().iloc[:, -2:]","e25b063b":"ndf[ ndf['age_group']== '35 to 39' ].groupby('voted').mean().iloc[:, -2:]","a4259b84":"ndf[ ndf['age_group']== '30 to 34' ].groupby('education').mean().iloc[:, -2:]","e879c495":"def make_box_plot_by_age(df, color):\n    fig = px.box(\n        df, \n        x= 'age_group',\n        y= 'mean_score',\n        color= color,\n        category_orders= {\n            \"age_group\": ['below 20', \n                          '20 to 24',\n                          '25 to 29', \n                          '30 to 34',\n                          '35 to 39',\n                          '40 to 49',\n                          '50 to 59',\n                          'above 60'],\n            color: ordering,\n            #temp[ color ].unique(),\n        },\n    )\n\n    fig.update_layout(\n        title= f'DASS Score, by age, by { color }',\n        title_x = 0.5,\n        title_font_size= 20,\n        height= 600,\n        width= 900,\n        showlegend= True\n    )\n\n    fig.show()","b22a1cb5":"temp = ndf.copy()\ntemp['gender'].replace({\n    1: \"Male\",\n    2: \"Female\",\n    3: \"Non-binary\",\n    0: \"Unanswered\",\n},\n    inplace=True)\n\nordering = [\n    'Male',\n    'Female',\n    'Non-binary',\n    'Unanswered',\n]\n\nmake_box_plot_by_age(temp, 'gender')","4c4d94fc":"temp = ndf.copy()\ntemp['education'].replace({\n    1: \"Less than high school\",\n    2: \"High school\",\n    3: \"University degree\",\n    4: 'Graduate degree',\n    0: \"Unanswered\",\n},\n    inplace=True)\n\nordering = [\n    \"Less than high school\",\n    \"High school\",\n    \"University degree\",\n    'Graduate degree',\n    \"Unanswered\",\n]\n    \nmake_box_plot_by_age(temp, 'education')","1f140158":"temp = ndf.copy()\ntemp['orientation'].replace({\n    1: \"Heterosexual\",\n    2: \"Bisexual\",\n    3: \"Homosexual\",\n    4: 'Asexual',\n    5: 'Other',\n    0: 'Unanswered',\n},\n    inplace=True)\n\ntemp2 = ndf.copy()\ntemp2['orientation'].replace({\n    1: \"Heterosexual\",\n    2: \"Non-heterosexual\",\n    3: \"Non-heterosexual\",\n    4: 'Non-heterosexual',\n    5: 'Non-heterosexual',\n    0: 'Unanswered',\n},\n    inplace=True)\n\nordering = [\n    \"Heterosexual\",\n#     \"Bisexual\",\n#     \"Homosexual\",\n#     \"Asexual\",\n#     \"Other\",\n    \"Non-heterosexual\",\n    \"Unanswered\",\n]\n    \nmake_box_plot_by_age(temp2, 'orientation')","c1e71b8a":"temp = ndf.copy()\ntemp['voted'].replace({\n    1: \"Yes\",\n    2: \"No\",\n    0: 'Unanswered',\n},\n    inplace=True)\n\nordering = [\n    'Yes',\n    'No',\n    'Unanswered'\n]\n    \nmake_box_plot_by_age(temp, 'voted')","72308b4a":"temp = ndf.copy()\ntemp['married'].replace({\n    1: \"Never\",\n    2: \"Currently married\",\n    3: 'Previously married',\n    0: 'Unanswered',\n},\n    inplace=True)\n\nordering = [\n    \"Never\",\n    \"Currently married\",\n    'Previously married',\n    'Unanswered',\n]\n    \nmake_box_plot_by_age(temp, 'married')","b080bcea":"temp = ndf.copy()\ntemp['source'].replace({\n    1: \"Front page of site\",\n    2: \"Google redirect\",\n    0: 'Other',\n},\n    inplace=True)\n\nordering = [\n    \"Front page of site\",\n    \"Google redirect\",\n    'Other',\n]\n    \nmake_box_plot_by_age(temp, 'source')","9b12c870":"features = ndf[ \n    ['source',\n     'introelapse',\n     'testelapse',\n     'surveyelapse',\n     'TIPI1',\n     'TIPI2',\n     'TIPI3',\n     'TIPI4',\n     'TIPI5',\n     'TIPI6',\n     'TIPI7',\n     'TIPI8',\n     'TIPI9',\n     'TIPI10',\n     'education',\n     'urban',\n     'gender',\n     'age',\n     'hand',\n     'orientation',\n     'race',\n     'voted',\n     'married',\n     'age_group',]\n]\n\nlabels= ndf['mean_score']","38caafca":"features['gender'].replace({\n    1: \"Male\",\n    2: \"Female\",\n    3: \"Non-binary\",\n    0: \"NA\",\n},\n    inplace=True)\n\nfeatures['education'].replace({\n    1: \"Less than high school\",\n    2: \"High school\",\n    3: \"University degree\",\n    4: 'Graduate degree',\n    0: \"NA\",\n},\n    inplace=True)\n\nfeatures['urban'].replace({\n    1: \"Rural\",\n    2: \"Suburban\",\n    3: \"Urban\",\n    0: \"NA\",\n},\n    inplace=True)\n\nfeatures['hand'].replace({\n    1: \"Right\",\n    2: \"Left\",\n    3: \"Both\",\n    0: \"NA\",\n},\n    inplace=True)\n\nfeatures['orientation'].replace({\n    1: \"Heterosexual\",\n    2: \"Bisexual\",\n    3: \"Homosexual\",\n    4: 'Asexual',\n    5: 'Other SO',\n    0: 'NA',\n},\n    inplace=True)\n\nfeatures['race'].replace({\n    10: \"Asian\",\n    20: \"Arab\",\n    30: \"Black\",\n    40: 'Indigenous',\n    50: 'Native American',\n    60: 'White',\n    70: 'Other race',\n    0: 'NA',\n},\n    inplace=True)\n\nfeatures['voted'].replace({\n    1: \"Yes\",\n    2: \"No\",\n    0: 'NA',\n},\n    inplace=True)\n\nfeatures['married'].replace({\n    1: \"Never\",\n    2: \"Currently married\",\n    3: 'Previously married',\n    0: 'NA',\n},\n    inplace=True)\n\nfeatures['source'].replace({\n    1: \"Front page of site\",\n    2: \"Google redirect\",\n    0: 'NA',\n},\n    inplace=True)\n\nfeatures.head(2)","b3a8ff69":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = \\\ntrain_test_split(pd.get_dummies( features ), labels, test_size=0.2, random_state=0)\n\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n\nX_train.head()","d6941ede":"Xy_train = pd.concat([X_train, y_train], axis=1)\n\nmake_corr_map(Xy_train, 'tt', height=1200, width=1200)","c61f6129":"from sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators=100, oob_score=True)\nrfr_model = rfr.fit(X_train, y_train)","edd1b3c1":"plt.figure(figsize= (15, 30))\n\nfeature_importance = rfr.feature_importances_\nindices = np.argsort(feature_importance)\n\n\nplt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])\nplt.barh(range(len(indices)), feature_importance[indices], color='b', align='center')\nplt.show()","a2869e40":"# View accuracy score\nprint('Accuracy for Train:', rfr.score(X_train, y_train) )\nprint('Accuracy for Test:', rfr.score(X_test, y_test) )","f4cf4fc5":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Make predictions for the test set\ny_pred = rfr_model.predict(X_test)\n\npred_res =pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\npred_res","1b3c0936":"import sklearn.metrics as metrics\n    \n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round( metrics.mean_absolute_error(y_test, y_pred),2 ))\nprint('Mean Squared Error:', round( metrics.mean_squared_error(y_test, y_pred), 2))\n\n# Calculate mean absolute percentage error (MAPE)\nerrors = abs(y_pred - y_test)\nmape = 100 * (errors \/ y_test)\n\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","fb1e16e8":"# Machine Learning","5f09023b":"Displaying only the big races to prevent distorted results that may come from undersampling. \n\nThere are clear differences between races that is noticeable depending on which question was asked. But from the aggregate survey, there is almost no correlation between race and DASS score. ","4894fcde":"# Visualization For Significant Variables (controlled by age)","9c9d8a01":"Non-heterosexuals consistently display larger DASS scores for every question. \n\nMinor edits of the code can be made to display subsets of sexuality. ","30aba2db":"No obvious difference between urban people or rural people. Trends are inconsistent and do not persist across different questions. ","444e4fb9":"## Age","74236d3c":"## Race\nMajority of data point came from Asians (60%). Arabs only take up less than 1%. Recall from our religion ditribution, a majority of them are Muslims. \n\nIf we have to take a guess, those Muslim Asians should come from Pakistan or Bangladesh. ","549a0719":"## Removing unneeded columns\nVCL columns is used to validating the consistency of user answers. Since we have already used it, they have served their purpose and we don't need it. \n\nQnI and QnE is the position of question and the number of milliseconds taken to answer the question respectively. Neither are useful and we can cut them off our dataframe. ","c7cc78f5":"There are somewhat clear differences between religion depending on question that was asked.\n\nMinor edits to the code can be made to display subsets of Christianity. \n\nThat said, it is important to note that some of the values come from the effects of undersampling. Hindu, Jewish, and Sikh only represent a very small proportion (<1% each) of the survey. ","681aa30c":"## Traffic source, by age","be2906fe":"## Source Traffic\nHow the survey was accessed. We have no idea how VPNs affect this result.","972a62c8":"## Gender, by age","f7d45c0e":"# Visualizing Distribution","50c56e73":"## Unique Network Location","6a4c25c8":"## Random Forest Regressor\nSince our target variable is a continous variable (mean score), we cannot use classification models and must use a regression. However, we will quickly learn why it is not a good idea. ","fbd61f0e":"# Urban","1ec10e63":"# Visualizing Survey Result Difference Between Each Class For Each Category\n\nTo conserve page bandwidth, I only plot the first few questions. To obtain the full results, simply change the for loop up to 42. ","676687f3":"## Marriage status, by age","f11cdeab":"People who did not voted consistently score higher than people who did for their DASS scores for every question. That said, it is difficult to know how much of the influence is due to voting and not due to other variables. \n\nPeople who don't\/can't vote tend to be of younger age, which we have already noted them to score higher in DASS. ","ff1f6792":"## Gender\nOver 3 quarters of the data out of ~35k observations come from female. \n\nSome concerns of sampling bias is raised. ","75f751dd":"Also no obvious correlation between a person's dominant hand and their DASS scores. ","56c1c237":"## Creating bin groups for age\nAge variable is originally continous. However, creating bin groups transform it into ordinal data which makes is simpler to classify groups. ","caf7a41a":"DASS scores seemed to be most correlated with TIPI4 (Anxious, easily upset) personalities, and most inversely correlated with TIPI9 (calm, emotionally stable) personalities. \n\nOther higher correlated personality types are:\n- TIPI1 and TIPI5 (extraversion, openness to new experience)\n- TIPI1 and TIPI6 (extraversion, reserved quiet)\n- TIPI3 and TIPI9 (self-disciplined, emotionally stable)\n- TIPI5 and TIPI9 (openness to new experience, emotionally stable)\n\nAs expected, age is more strongly correlated with education, voted, and marriage. \n\nSomething to note is the a correlation heatmap is insufficient to make any conclusive interpretation between DASS scores and a variable, and **only works if both the variables you are comparing against and your dependent variable are continuous in nature**. It is **particularly terrible when it comes to variables with ordinal scales**. \n\nPreviously we noted that classes in traffic source displays a clear pattern for DASS scores, yet it displays almost 0 correlation. This is because the numbers for those ordinal data do not linearly scale with the scores (1 = live site, 2= Google, 0 = other). ","7c9369a0":"This is mainly used as a control to see if there is a consistent pattern or abnormal scoring that comes from multiple surveying from the same network. \n\nConsistent pattern or abnormal scoring would suggest the influence or presence of spammers. \n\nThankfully, there doesnt seemed to be much correlation, at least where our eyes can see. ","439521b8":"## Voted, by age","a3ed9c40":"## Voted","ab4bcb8e":"## Voted","c381832d":"## Train Test Split","8dfaacf8":"## Gender","f78914df":"In some continous variables (in particular, test and survey time), extreme values appear occasionally, distorting the mean of the column. There are also some suspicious values that seem impossible to happen in practice (EG: Age above 120, number of children above 30)","6b7ba0c7":"## Education, by age","f4f0cb5f":"## Urban","0689a3fb":"## Further subsetting to discover hidden relationships and control for correlated variables","bcf04bc3":"## Unique Network Location\nSupposedly, a column used to control for spammers or duplicated data. \n\n- 1=only one survey from user's specific network in dataset, \n- 2=multiple surveys submitted from the network of this user  \n\n2 does not necessarily imply duplicate records for an individual, as it could be different students at a single school or different memebers of the same household; and even if 1 there still could be duplicate records from a single individual e.g. if they took it once on their wifi and once on their phone)","53ba0fe0":"## Sexual Orientation","7fc021e3":"## Hand","726632c7":"A trend appears for most questions, where younger people tend to consistent score higher than older people for DASS survey. ","0ce51143":"## Education","ab6d283f":"Accuracy score for training set and testing set has a huge divergence, implying an overfitting problem during our training, and subsequently implying that we should look at the results of our correlation heatmap and feature importance with a grain of salt.\n\nThe challenge of this problem is that we are trying to predict the average final score of a survey user based on a load of categorical variables. Not only that, the answer for each survey question is ordinal in nature, so even people with similar conditions may not answer the survey similarly and is subjective to their survey answering behavior. \n\nThe random forest regressor done here is just a proof of concept that machine learning could be done-- just not a reliable method at solving the problem. ","01e11173":"## Others (Family size, country, major) \nData not displayed in pie chart because there are too many classifications\n","657b471a":"An overwhelming majority of survey takers came from Malaysia, raising concerns of sampling bias. This is also probably where we get all of our Muslim and Asian entries, \n\nThis is pretty weird, because personally I lived in Malaysia and had no knowledge about this study. \n\nI have some concerns of spammers using a Malaysian VPN to fill out this survey. Later I did a some studies behind the scenes and found out that after truncating Malaysian entries, many of the other core categories (Gender, age group) still remained pretty stable in proportion. ","af8e1bf7":"Very surprising to discover a consistent pattern in DASS scores from where the traffic was accessed, People who accessed the survey directly from the site's home page consistently score higher for every question compared to people who accessed or was redirected from elsewhere. \n\nThe hypothesis is that people with deeper concerns for their mental health or are more intentional with their mental health tend to be the ones to access the survey directly, and they tend to also start out with more existing issues with depression and anxiety. ","d3849b92":"## Removing rows for people who took the survey too quickly or slowly","4861aa81":"## Religion\nOriginal Christian is further subset to Mormons, Catholics, etc. Since they don't take up a lot of space in the pie individually, I choose to lump them together as one. \n\nAn overwhelming number of entries seemed to be from Muslim background. Again, raising the concern when it comes to sampling bias. ","2c429808":"## Orientation, by age","cf9e0780":"## Replacing extreme ages with median","65878430":"Another obvious and consistent trend. People with higher education score lower in DASS relative to people from lower education. \n\nThis questions the stereotype that smart people or higher IQ are more depressed. \n\nThat said, it also did not control for age. People with recorded higher education tend to be older as well, so maybe it is really just age that is influencing the differences. ","9bcbca70":"Model overwhelmingly favors continuous variables over categorical variables, simply due to the nature of the model itself. \n\nAge group that was largely noted to play a huge factor in a person DASS score is diluted by the continous age variable. This is fine because originally the intention of binning the age variable in the first place is to reduce the problem of visualization. Now that it is just the computer reading, they can go through the continous age variable to gain a better fit. \n\nThe issue with regressions is that they simply don't work too well when too many of them are categorical variables. Unless the categorical variable is very obvious, they don't surface too highly on the feature importance chart. So far the only known example is the `source: Front page of site` variable. \n\nAnother thing to note is that feature importance don't tell you the direction of the variable's influence to the target variable. This means we can't know if `TIPI4` contributes positively or negative to a person's predicted DASS score. All we know is that they are better predictors relative to all other predictors, holding all predictors constant. \n\nIf you paid attention, you will also notice the feature importance chart to closely resemble the results of correlation map we just printed. \n\n","18b96fc8":"## Race","d35e3bb7":"# Data Cleaning\n## Removing rows with too many wrong answers\nFrom the codebook.txt: \n> \"In the grid below, check all the words whose definitions you are sure you know\". \n> \n> A value of 1 is checked, 0 means unchecked. The words at VCL6, VCL9, and VCL12 are not real words and can be used as a validity check.\n\nThere are a maximum of 3 wrong answers a person can give. Based on our discretion, people with more than 2 wrong answers will be suspected to answer the survey inconsistently and be removed.\n\n","3976d04e":"DASS score for currently married people are consistently lower compared to those who are not or who are previously married. \n\nOnce again, how much of it was influenced by marriage status and not due to other factors is something worth questioning. \n\nPeople who are married tend to be older while people who weren't tend to be younger. Which from our age group analysis have found there is a strong correlation between age and DASS scores. \n\nPeople who are previously married (divorce or widowed) score higher for DASS. They also tend to be older even compared to currently married people (which goes against the correlated variable of age), making it seemed to be a genuine cause of increase in DASS. ","015052b7":"## Religion","85714acb":"## ","1ce4983d":"## Marriage Status","8956b75a":"# Survey Visualization","6977d02b":"## Hand","56d0617c":"## Marriage Status","27473149":"## Sexual Orientation","85f7211b":"## Education","ba2dfc2c":"## Age","fc40839e":"## Traffic source","33992cde":"# Correlation Matrix ","d7da72b7":"Another trend I did not expect. Women consistently score higher than men in DASS for almost every single question. \n\nThat said, we had yet to control them for age and other variables, so it is difficult to conclude if simply being a woman is enough to make someone less happier than a man. "}}