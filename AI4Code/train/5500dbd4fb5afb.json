{"cell_type":{"353d7524":"code","97ff40ee":"code","02ed9ee8":"code","7cdaa49c":"code","6ffd35b4":"code","a5715f4d":"code","0f322db0":"code","2460e4ff":"code","01219422":"code","28fb1fd3":"code","5f488cfe":"code","c603e94b":"code","ceb06e04":"code","b8cd9eac":"code","d1de94a3":"code","df2af1d6":"code","d9ce7d85":"code","ae6a059e":"code","9e5d081d":"code","5a065503":"code","fb40e472":"code","25085513":"code","281adbf2":"code","507606b3":"code","87faa205":"code","fde46234":"code","e46718a5":"code","e621d389":"code","92555840":"code","5d78cf62":"code","2ab6c6b5":"code","4f16bd5e":"code","a4152d67":"code","b6954d9e":"markdown","ff43b345":"markdown","a606e106":"markdown","c56bcfc9":"markdown","408e2bd0":"markdown","6ac717e5":"markdown","69a55225":"markdown","535b3f96":"markdown","d7704d23":"markdown","2ffd5a2c":"markdown","46c1f9d3":"markdown","a662de59":"markdown","120062d1":"markdown","ed9c6a72":"markdown","907ef904":"markdown","6ada56bb":"markdown","9ee44d35":"markdown","842e0677":"markdown","7b65242b":"markdown","12fcfefd":"markdown","5b47ee14":"markdown","763ddb3c":"markdown","261c2814":"markdown","0ad6048e":"markdown"},"source":{"353d7524":"import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","97ff40ee":"mnist_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nmnist_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")                          ","02ed9ee8":"print(\"Train: \\n\",mnist_train.shape)\nprint(\"Test: \\n\",mnist_test.shape)","7cdaa49c":"mnist_train.head()","6ffd35b4":"mnist_train.label.value_counts().plot.bar()","a5715f4d":"some_digit = mnist_train.drop(\"label\", axis = 1).iloc[40000]\nsome_digit_image = some_digit.values.reshape(28,28)\n\nplt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")","0f322db0":"# The image looks like a 2, let's verify if the label indeed returns a 2\nprint(\"Label: \",mnist_train.iloc[40000].label)","2460e4ff":"from sklearn.model_selection import train_test_split\n\n# X_train, X_test, y_train, y_test = train_test_split(mnist_train.drop(\"label\", axis = 1), mnist_train.label, test_size=0.2, random_state=42)\nX_train = mnist_train.drop(\"label\", axis = 1)\ny_train = mnist_train.label\n\ny_train_5  = (y_train == 5)\ny_test_5 = (y_train == 5)","01219422":"# Train using Stochastic Gradient Descent (SGD)\nfrom sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state = 42)\nsgd_clf.fit(X_train, y_train_5)","28fb1fd3":"# Let's try this classifier on the previous digit example:\n\nsgd_clf.predict([some_digit])","5f488cfe":"# The classifier correctly predict the digit 2 as not-5, but let's see if it can correctly predict a 5:\na_digit_5 = mnist_train[mnist_train['label'] == 5].drop('label', axis = 1).sample(1, random_state = 123)\n\nsgd_clf.predict(a_digit_5)","c603e94b":"from sklearn.model_selection import cross_val_score\n\ncv_scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring = \"accuracy\")","ceb06e04":"cv_scores.mean()","b8cd9eac":"from sklearn.base import BaseEstimator\n\nclass Never5Classifier(BaseEstimator):\n    def fit(self, X, y=None):\n        pass\n    def predict(self, X):\n        return np.zeros((len(X), 1), dtype = bool)\n    \nnever_5_clf = Never5Classifier()\ncross_val_score(never_5_clf, X_train, y_train_5, cv = 3, scoring = \"accuracy\").mean()","d1de94a3":"from sklearn.model_selection import cross_val_predict\n\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3)","df2af1d6":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_train_5, y_train_pred)","d9ce7d85":"from sklearn.metrics import precision_score, recall_score\nprint(\"precision_score: \", precision_score(y_train_5, y_train_pred))\nprint(\"recall_score: \", recall_score(y_train_5, y_train_pred))","ae6a059e":"from sklearn.metrics import f1_score\n\nf1_score(y_train_5, y_train_pred)","9e5d081d":"y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3, method = 'decision_function')\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\nroc_auc = roc_auc_score(y_train_5, y_scores)\n","5a065503":"def plot_roc_curve(fpr, tpr, label = None):\n    plt.plot(fpr, tpr, label = label)\n    plt.plot([0,1], [0,1], 'k--')\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend(loc=\"lower right\")\n\nplot_roc_curve(fpr,tpr, label='ROC curve (area = {})'.format(roc_auc))","fb40e472":"from sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(random_state = 42)\n\ny_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv = 3, method = 'predict_proba')\n\ny_scores_forest = y_probas_forest[:,1]\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\nroc_auc_forest = roc_auc_score(y_train_5, y_scores_forest)","25085513":"plot_roc_curve(fpr,tpr, label='ROC curve (area = {})'.format(roc_auc))\nplt.plot(fpr_forest, tpr_forest, \"b:\", label = \"Random Forest (area = {})\".format(roc_auc_forest))\nplt.legend(loc = 'lower right')","281adbf2":"y_probas_forest_binary = cross_val_predict(forest_clf, X_train, y_train_5, cv = 3, method = 'predict')\n\nprint(\"Random Forest F1:\", f1_score(y_train_5, y_probas_forest_binary))\nprint(\"SGD F1:\", f1_score(y_train_5, y_train_pred))","507606b3":"forest_clf.fit(X_train, y_train)\nforest_clf.predict(a_digit_5)","87faa205":"forest_clf.predict_proba(a_digit_5)","fde46234":"cross_val_score(forest_clf, X_train, y_train, cv = 3, scoring = \"accuracy\").mean()","e46718a5":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\ncross_val_score(forest_clf, X_train_scaled, y_train, cv = 3, scoring = \"accuracy\").mean()","e621d389":"from sklearn.neighbors import KNeighborsClassifier\n\nKNN_clf = KNeighborsClassifier(n_jobs = -1)\nKNN_clf.fit(X_train, y_train)","92555840":"cross_val_score(KNN_clf, X_train, y_train, cv = 3, scoring = \"accuracy\").mean()","5d78cf62":"# from sklearn.model_selection import GridSearchCV\n\n# param_grid = {\n#     \"n_neighbors\" : [3,4,5,6,7,8],\n#     \"weights\" : ['uniform', 'distance']\n# }\n\n# KNN_clf = KNeighborsClassifier(n_jobs = -1)\n\n# grid_search = GridSearchCV(KNN_clf, param_grid , cv = 5, scoring = \"accuracy\")\n\n# grid_search.fit(X_train, y_train)\n\n# grid_search.best_params_","2ab6c6b5":"KNN_clf = KNeighborsClassifier(n_jobs = -1, n_neighbors = 4, weights = \"distance\")\nKNN_clf.fit(X_train, y_train)\ncross_val_score(KNN_clf, X_train, y_train, cv = 3, scoring = \"accuracy\").mean()","4f16bd5e":"sample_submission = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\ntest_predictions = KNN_clf.predict(mnist_test)\nsubmission = sample_submission.drop('Label', axis = 1)\nsubmission['Label'] = test_predictions","a4152d67":"submission.to_csv(\"mnist_submission.csv\",index=False)","b6954d9e":"This notebook is based off chapter 3 from Aurelien Geron's book: *Hands-On Machine Learning with Scikit-Learn & TensorFlow*. The notebook is my journey to the world of data science and may serve as a gentle introduction for beginner and not an extensive guide on how to get best LB score. ","ff43b345":"F1 score favors classfiders that have similar precision and recall. This might not be the optimal choice for the specific problem that you are trying to solve. In certains context, you will want to care more about precision or recall.","a606e106":"A cool 95.6% accuracy! However, we need to consider problem of class imbalance, where negative class (not-5) is overwhelmingly more than the positive class (5). Therefore, even a dumb classifier that play safe and call everything as not-5, it will still have a very high accuracy. Let's see the dumb classifier in action:","c56bcfc9":"## Select a better algorithm\n\nOne of the main problem with ensemble or linear classifiers is that they heavily rely on the position and the rotation of the image. Therefore, any digit that have a slight shift or off axis will cause the these classifiers to struggle.\n\nAmong the simple algorithms, KNN stands out to be a very appropriate algorithm for our problem.","408e2bd0":"The KNN already give us a little boost of accuracy compared to the previous algorithms. Let's fine-tune our model to get a little bit of performance out of our classifier. We'll search a few parameters that already used by the default KNN:","6ac717e5":"# Submission","69a55225":"Under the hood, our random forest classifier run all binary classifiers from 0-9 and select the class whose classifier outputs the highest score.","535b3f96":"**Observation**: As we can see, the Random Forest classifier ROC curve looks much better than the SGD classifier. The random forest is clearly the superior classifier for our binary problem. We can confirm this with F1 score:","d7704d23":"A classifier that only predict not-5 can archive a 90% accuracy. This is simply because only 10% of data are 5s, so if you always guess an image is not a 5, you will be correct 90% of the time.","2ffd5a2c":"## Improve the model\n\n### Scaling the input","46c1f9d3":"## Visualize a digit","a662de59":"Just like the cross_val_score(), cross_val_predict() performs K-fold cross_validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold.\n\nNow let's construct a confusion matrix based on the target class and the predicted classes","120062d1":"# Exploratory Data Analysis\n\n## Check the frequency of labels","ed9c6a72":"## The ROC Curve\n\nThe receiver operating characteristic (ROC) curve is another very common tool in binary classification problem. ROC curve plots the true positive rate (recall) against the false positive rate. This is also known as plots of sensitivity vs 1 - specificity. Let's plot our ROC curve:","907ef904":"## Performance Measure\n\nLet's use cross_val_score() to evaluate the classifier using Kfold cross-validation:","6ada56bb":"We obtained 3 accuracy scores for each fold, let's take the average to see roughly how well the classifier does:","9ee44d35":"Now our classifier doesn't look so good as it did when we only look at accuracy. In other words, when the classifier claims an image represents a 5, it is correct only 76.9% of the time. And it only detects 75% of the 5s. \n\nIt's often convinience to have just a single metric that combine these two scores together. In particular, this single metric is called F1 score, where it take on the *harmonic mean* of precision and recall. What is harmonic you ask? \n\nWhereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. Therefore, if one of presicion or recall tanked, the whole F1 score stay low.","842e0677":"# Multiclass Classification\n\nWe want to expand the capability of our model with the ability of classify all the digits. Scikitlearn automatically know from the label that we are trying to to a multiclass classification:","7b65242b":"We can see that digit 5 was predicted with the highest probability. Meaning the classifier is fairly confident about its prediction, with a 80% proabbility that the image is a 5, and it also think that there is a lower 20% chance that the image could be an 8.\n\nSimilar to a binary classifier, we can calculate the accuracy for our classifier:","12fcfefd":"From this matrix, we can derive precision and recall score that better reflect the errors generated by the classfier:","5b47ee14":"One way to compare the classifiers is to measure the area under the ROC curve. A perfect classifier will have ROC AUC equal to 1, whereas a purely random (dumb?) classifier will have the AUC qual to 0.5 (area under the dashed line)\n\n## A better classifier\n\nNow that we have the tool to compare one classifier to another, it's time to call in a more sophisicated classifier - Random Forest","763ddb3c":"If you don't want to waste a couple hours to run this grid search, here are the optimal params:\n\n{'n_neighbors': 4, 'weights': 'distance'}\n\nNow let's re-fit the model with the new parameters:","261c2814":"## A Better Performance Measure\n\nA much better way to measure the performance of a classifier is to look at the confusion matrix.","0ad6048e":"# Training a Binary Classifier\n\nLet's simplify the problem and try to only identify one digit - digit 5. This classifier will be able to distringuish two classes, 5 and not-5. "}}