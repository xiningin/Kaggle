{"cell_type":{"b26a6b97":"code","76be4fe8":"code","206d5d52":"code","cba1fde6":"code","908a464f":"code","47d3ddaa":"code","92dd7342":"code","9bb27b7e":"code","cdef9700":"code","9296a727":"code","7534b002":"code","64fa6398":"code","a690996d":"code","5b0b1042":"code","93750c66":"code","b65ffbd5":"code","f6a3a8bb":"code","915f36b1":"code","7595f58a":"code","5eb6a228":"code","19206f52":"code","ccc74d00":"code","8cfb183b":"code","420aad18":"code","fb108ff8":"code","496d22fb":"code","720c2bca":"code","ad7e6f28":"code","55a69e68":"code","9f684243":"code","2a406fda":"code","d4a473e1":"code","77e417a6":"code","9e995afd":"code","1f44f825":"code","3489ae85":"code","3a8826c9":"code","43caaa21":"code","bc70feb8":"markdown","e0384db8":"markdown","177e95e7":"markdown","1a539335":"markdown","032d161e":"markdown","0a97c8fc":"markdown","698604c3":"markdown","71ae8d19":"markdown","83d383e9":"markdown","bd8af7dd":"markdown"},"source":{"b26a6b97":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76be4fe8":"train_set_path = '\/kaggle\/input\/bike-sharing-demand\/train.csv'\ntest_set_path = '\/kaggle\/input\/bike-sharing-demand\/test.csv'\n\ntrain_df = pd.read_csv(train_set_path)\ntest_df = pd.read_csv(test_set_path)","206d5d52":"train_df.head()","cba1fde6":"test_df.head()","908a464f":"train_df.describe()","47d3ddaa":"train_df['count'].hist()","92dd7342":"sns.pairplot(train_df[['weather', 'workingday', 'holiday', 'season', 'temp', 'atemp', 'humidity', 'windspeed', 'count']])","9bb27b7e":"sns.distplot(train_df['count'])","cdef9700":"y_train = np.log(train_df['count'] + 1)","9296a727":"sns.distplot(y_train)","7534b002":"train_df.info()","64fa6398":"def create_date_columns(df, col_name):\n    df['datetime'] = pd.to_datetime(df[col_name])\n    df['hour'] =  df[col_name].apply(lambda date: date.hour)\n    df['day'] =  df[col_name].apply(lambda date: date.day)\n    df['month'] =  df[col_name].apply(lambda date: date.month)\n    df['year'] =  df[col_name].apply(lambda date: date.year)\n    df['day_number'] =  df[col_name].apply(lambda date: date.weekday())\n    return df","a690996d":"train_df = create_date_columns(train_df, 'datetime')","5b0b1042":"train_df.head()","93750c66":"sns.barplot(data=train_df, x='day_number', y = 'count')","b65ffbd5":"sns.barplot(data=train_df, x='hour', y = 'count')","f6a3a8bb":"sns.barplot(data=train_df, x='month', y = 'count')","915f36b1":"sns.boxplot(x=train_df[\"hour\"], y=train_df['count'])","7595f58a":"count_per_hour = train_df.groupby('hour').agg('sum')['count']\ncount_per_hour","5eb6a228":"sns.relplot(data = count_per_hour, kind='line')","19206f52":"selected_features = ['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'windspeed', 'humidity', 'hour', 'day_number']","ccc74d00":"def pipline(df, selected_features):\n    df = create_date_columns(df, 'datetime')\n    return df[selected_features]","8cfb183b":"X_train = pipline(train_df, selected_features)","420aad18":"X_train.head()","fb108ff8":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)","496d22fb":"def rmsle(real, pred):\n    return np.sqrt(np.mean(((np.log(pred + 1)) - (np.log(real + 1)))**2))","720c2bca":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor() # randomforest with default prameters","ad7e6f28":"model.fit(X_train, y_train)","55a69e68":"y_hat_train = model.predict(X_train)\ny_hat_valid = model.predict(X_valid)","9f684243":"print(len(y_hat_train))\nprint(len(y_hat_valid))","2a406fda":"print(f\"train_score: {rmsle(np.exp(y_train)-1, np.exp(y_hat_train) - 1)}\")\nprint(f\"validation_score: {rmsle(np.exp(y_valid)-1, np.exp(y_hat_valid) - 1)}\")","d4a473e1":"model = RandomForestRegressor(n_estimators=500, max_depth=15) \nmodel.fit(X_train, y_train)","77e417a6":"y_hat_train = model.predict(X_train)\ny_hat_valid = model.predict(X_valid)","9e995afd":"print(f\"train_score: {rmsle(np.exp(y_train)-1, np.exp(y_hat_train) - 1)}\")\nprint(f\"validation_score: {rmsle(np.exp(y_valid)-1, np.exp(y_hat_valid) - 1)}\")","1f44f825":"best_model = RandomForestRegressor(n_estimators=500, max_depth=15)\nX_train = pipline(train_df, selected_features)\ny_train = np.log(train_df['count'] + 1)\nbest_model.fit(X_train, y_train)","3489ae85":"X_test = pipline(test_df, selected_features)","3a8826c9":"y_hat = best_model.predict(X_test)","43caaa21":"test_df['count'] = np.exp(y_hat) -1\nfinal_df = test_df[['datetime', 'count']].copy()\nfinal_df.to_csv('submission.csv', index=False)","bc70feb8":"# Feature Engineering","e0384db8":"# Evaluation Matrix","177e95e7":"# Split Dataset for training","1a539335":"# Best Fit model","032d161e":"# Pipline","0a97c8fc":"# Load Datasets","698604c3":"# END","71ae8d19":"# EDA","83d383e9":"# Submit the answer","bd8af7dd":"# Model selection"}}