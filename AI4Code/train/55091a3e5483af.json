{"cell_type":{"e9cabac1":"code","e91acf5e":"code","304ba269":"code","99c8ac84":"code","b29cbc4e":"code","df30144d":"code","26a98bf8":"code","8b9d10bd":"code","869138ba":"code","d258db4e":"code","980eac36":"code","9d6f3a6b":"code","cbf61f43":"code","6fc96028":"code","ee8272f8":"code","9dfecaf7":"code","bc5bf057":"code","98294fc1":"code","22e2146e":"code","07443d62":"code","57e948e1":"code","c232a147":"markdown","0aca6e3e":"markdown","31e75472":"markdown","9f042468":"markdown","02c86e79":"markdown","b10fb608":"markdown"},"source":{"e9cabac1":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import MNIST\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n#import helper\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# moves your model to train on your gpu if available else it uses your cpu\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")","e91acf5e":"device","304ba269":"dataset = MNIST(root='data\/', download = True)\ntest_dataset = MNIST(root='data\/', train=True)\nimg, label = dataset[0]\nplt.imshow(img, cmap='gray')\n\nprint(len(dataset))\nprint(f'label: {label}')\ndataset = MNIST(root='data\/', train=True, transform=transforms.ToTensor())\ntest_dataset = MNIST(root='data\/', train=True, transform=transforms.ToTensor())\nprint(len(dataset))","99c8ac84":"\nfrom torch.utils.data import random_split\ntrain_ds, val_ds = random_split(dataset,[50000, 10000])\nlen(train_ds), len(val_ds)","b29cbc4e":"# import sklearn.metrics as metrics\n# from skimage.transform import rotate\n# lst_img = []\n# def show_img(img_tensor, rotate_degree):\n#     new_img = rotate(img_tensor.reshape(1,28,28),rotate_degree)\n#     # plt.imshow(new_img)\n#     # plt.show()\n#     return torch.tensor(new_img)\n# for img, lbl in train_ds:\n#     lst_img.append([show_img(img[0], 15),torch.tensor(lbl)])\n#     lst_img.append([show_img(img[0], 20),torch.tensor(lbl)])\n#     lst_img.append([show_img(img[0], 25),torch.tensor(lbl)])\n#     lst_img.append([show_img(img[0], 0),torch.tensor(lbl)])\n#     #show_im(img[0], 15)\n# new_tuple = tuple(lst_img)\n# def show_im(img_tensor, rotate_degree):\n#     new_img = rotate(img_tensor.reshape(28,28),rotate_degree)\n#     plt.imshow(new_img)\n#     plt.show()\n# #show_im(lst_img[10][0],0)","df30144d":"batch_size = 128\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)","26a98bf8":"from torchvision.utils import make_grid\n\ndef show_batch(ds):\n    for images, labels in ds:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break\nshow_batch(train_ds)","8b9d10bd":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(         \n            nn.Conv2d(\n                in_channels=1,              \n                out_channels=16,            \n                kernel_size=5,              \n                stride=1,                   \n                padding=2,                  \n            ),                              \n            nn.ReLU(),                      \n            nn.MaxPool2d(kernel_size=2), \n            nn.BatchNorm2d(16)\n            \n        )\n        self.conv2 = nn.Sequential(         \n            nn.Conv2d(16, 32, 5, 1, 2),     \n            nn.ReLU(),                      \n           \n            nn.BatchNorm2d(32)\n        )\n        self.conv3 = nn.Sequential(         \n            nn.Conv2d(32, 64, 5, 1, 2),     \n            nn.ReLU(),                      \n            nn.BatchNorm2d(64)    \n        )\n        self.conv4 = nn.Sequential(         \n            nn.Conv2d(64, 512, 5, 1, 2),     \n            nn.ReLU(),                      \n            nn.BatchNorm2d(512)    \n        )\n        self.conv5 = nn.Sequential(         \n            nn.Conv2d(512, 1024, 5, 1, 2),     \n            nn.ReLU(),                      \n            nn.MaxPool2d(kernel_size=2), \n           \n            nn.BatchNorm2d(1024)\n        )\n\n        # fully connected layer, output 10 classes\n        self.out = nn.Linear(1024 * 7 * 7, 10)\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n\n        \n        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n        x = x.view(x.size(0), -1)       \n        output = self.out(x)\n        return output, x    # return x for visualization","869138ba":"cnn = CNN()\nprint(cnn)\ncnn.to(device)","d258db4e":"loss_func = nn.CrossEntropyLoss()   \nloss_func\nfrom torch import optim\noptimizer = optim.Adam(cnn.parameters(), lr = 0.01)   \noptimizer","980eac36":"import pandas as pd\ndata = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ndata","9d6f3a6b":"from torch.utils.data import DataLoader, TensorDataset\ntensor_x = torch.from_numpy(np.array(data[:]))\ntensor_x = tensor_x.reshape(28000,1, 28,28)\ntensor_x.to(device)\ntensor_dataset = TensorDataset(tensor_x)\ntensor_loader = DataLoader(tensor_dataset)\nfrom torch.utils.data import DataLoader\nloaders = {\n    'train' : torch.utils.data.DataLoader(train_ds, \n                                          batch_size=100, \n                                          shuffle=True, \n                                          num_workers=1),\n    \n    'test'  : torch.utils.data.DataLoader(val_ds, \n                                          batch_size=100, \n                                          shuffle=True, \n                                          num_workers=1),\n    'kaggle': torch.utils.data.DataLoader(tensor_dataset,\n                                          batch_size= 100,\n                                          shuffle=False,\n                                          num_workers=4)\n}\nloaders","cbf61f43":"from torch.autograd import Variable\nloss_meansurement = []\ndef train(num_epochs, cnn, loaders):\n    \n    cnn.train()\n        \n    # Train the model\n    total_step = len(loaders['train'])\n        \n    for epoch in range(num_epochs):\n        for i, (images, labels) in enumerate(loaders['train']):\n            images.cuda()\n            labels.cuda()\n            # gives batch data, normalize x when iterate train_loader\n            b_x = Variable(images)   # batch x\n            b_y = Variable(labels)   # batch y\n            #print(b_x.shape)\n            output = cnn(b_x.cuda())[0]               \n            loss = loss_func(output, b_y.cuda())\n            \n            # clear gradients for this training step   \n            optimizer.zero_grad()           \n            \n            # backpropagation, compute gradients \n            loss.backward()    \n            # apply gradients             \n            optimizer.step()                \n            \n            if (i+1) % 100 == 0:\n\n                # if (epoch+1) == 9 and (i + 1) == 300:\n                #     break\n                print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n        loss_meansurement.append(loss.item())\n","6fc96028":"num_epochs = 3\ntrain(num_epochs, cnn, loaders)\n","ee8272f8":"import matplotlib.pyplot as plt\nplt.plot( [i for i in range(1,num_epochs+1)],loss_meansurement)\nplt.show()","9dfecaf7":"def test(model):\n    # Test the model\n    model.eval()\n    correct = 0\n    predict = []\n    with torch.no_grad():\n        correct = 0\n        total = len(loaders['test'])\n        for images, labels in loaders['test']:\n            test_output, last_layer = model(images.type(torch.FloatTensor).cuda())\n            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n            predict.append(pred_y)\n            correct += (pred_y == labels.cuda()).sum()\n    print(total)\n    print(correct)\n    return predict\nkaggle_ans = test(cnn)\n","bc5bf057":"pretrained = CNN()\npretrained.load_state_dict(torch.load('..\/input\/pretrained\/model_70k.pth'))\npretrained.to(device)","98294fc1":"ans = test(pretrained)","22e2146e":"def test(model):\n    # Test the model\n    model.eval()\n    predict = []\n    with torch.no_grad():\n        correct = 0\n        total = len(loaders['kaggle'])\n        for images in loaders['kaggle']:\n            test_output, last_layer = model(images[0].type(torch.FloatTensor).cuda()\/255.)\n            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n            predict.append(pred_y)\n    return predict\nkaggle_ans = test(pretrained)\n","07443d62":"sample_submition = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsample_submition['ImageId']","57e948e1":"kaggle = [t.cpu().numpy() for t in kaggle_ans]\nkaggle = np.array(kaggle)\nkaggle.reshape(28000)\nkaggle = np.asarray(kaggle)\n\nresult = []\nfor i in kaggle:\n    for j in i:\n        result.append(j)\nsample_submition['Label'] = result\n\ndata = {'ImageId':[i for i in range(1,28001)],\n        'Label': result\n        }\n\ndf = pd.DataFrame(data, columns= ['ImageId', 'Label'])\n\n\ndf.to_csv('submission.csv', sep=',',index=False, header=True)\n","c232a147":"Now we test the pre_trained model\nGreate, it have 99.98% Accuracy, now we predict our test.csv of kaggle","0aca6e3e":"Test with my pretrained","31e75472":"**Data Argumentation to improving examples for learning algorithms **","9f042468":"Hi everyone, I'am create this notebook to guide you guys to implement CNN with Pytorch, who want to get accuracy ~100%","02c86e79":"Now we have 99.98% accuracy, thank for reading, hope it help you a lots.\nPlease give me a vote for encourage me for more tutorial","b10fb608":"With 3 epoch we have ~99% accuracy\nNow we using data argumentation above and add to dataset using transforms.RandomRotation to diversify our data, I am dont show here to encourage your exploration and discovery. I am upload my pretrained here to you"}}