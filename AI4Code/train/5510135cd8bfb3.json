{"cell_type":{"7b06643e":"code","9b846287":"code","25be8cdb":"code","01860020":"code","2680b360":"code","5614a4d1":"code","46b79ac9":"code","ce98da96":"code","e57fe53a":"code","c7c36358":"code","767349b0":"code","2f61e4a4":"code","1038f77e":"code","25df94c1":"code","2984db4a":"code","c54d7cfb":"code","cccc5597":"code","1a0d0ea5":"code","969be361":"code","5546d371":"code","e9340412":"code","fdf8331a":"code","99ce6b14":"code","46b40014":"code","de3af5f2":"code","d727f7f6":"code","2233fe64":"code","67a39929":"code","1b00a43f":"code","74bcb3fd":"code","c347382b":"code","f6538ea0":"code","b3524d48":"code","05686e23":"code","1d5c93ee":"code","3e97f3f6":"code","bdaf3e86":"code","e6723a9b":"code","fb782b83":"code","54c7521e":"code","489e127f":"code","4e104c6e":"code","673cfd17":"code","c4b8eeac":"code","685390a4":"code","a4d95e96":"code","d48dfd8e":"code","a7768051":"code","7ace4a58":"code","1354404d":"code","e9ecb9c3":"code","0a0141c1":"code","180056bc":"code","a4377400":"code","d764a1ec":"code","6247821e":"code","d3999fa9":"code","fbf42fe2":"code","3344a03c":"code","e59ede8c":"markdown","2177109a":"markdown","d4949ce1":"markdown","769a0479":"markdown","a2f53f02":"markdown","a3bed32e":"markdown","7f8d594c":"markdown","f14cbd25":"markdown","057e8753":"markdown","681cbdc2":"markdown","fffa006a":"markdown","860a346f":"markdown","ba14b686":"markdown","6f60342f":"markdown","1debbf4a":"markdown"},"source":{"7b06643e":"#!pip install git+https:\/\/github.com\/fastai\/fastai2","9b846287":"!ls -la \/kaggle\/input\/fastai2","25be8cdb":"!cp -r \/kaggle\/input\/fastai2 .","01860020":"!ls -la ","2680b360":"!pip install \/kaggle\/working\/fastai2\/fastcore-0.1.10-py3-none-any.whl\n\n!pip install \/kaggle\/working\/fastai2\/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n\n!pip install \/kaggle\/working\/fastai2\/fastprogress-0.2.2-py3-none-any.whl","5614a4d1":"!ls -la","46b79ac9":"import os\nfrom collections import Counter, defaultdict\nfrom pathlib import Path\n\nfrom tqdm.notebook import tqdm\nimport json\nimport numpy as np\nimport pandas as pd\nfrom fastai.tabular import * \n\npd.set_option('display.max_colwidth', 200)\npd.set_option('display.max_columns', None)\npd.set_option('display.min_rows', 100)\npd.set_option('display.max_rows', 100)\nhome = Path(\"\/kaggle\/input\/data-science-bowl-2019\/\")","ce98da96":"specs = pd.read_csv(home\/\"specs.csv\"); len(specs)\nspecs.head()","e57fe53a":"train_labels = pd.read_csv(home\/\"train_labels.csv\"); len(train_labels)\ntrain_labels.head(5)","c7c36358":"pd.read_csv(home\/\"sample_submission.csv\").head()","767349b0":"%%time\ntypes = {\"event_code\": np.int16, \"event_count\": np.int16, \"game_time\": np.int32}\nraw_train = pd.read_csv(home\/\"train.csv\", dtype=types)\nraw_train[\"timestamp\"] = pd.to_datetime(raw_train[\"timestamp\"]); len(raw_train)","2f61e4a4":"raw_test = pd.read_csv(home\/\"test.csv\", dtype=types)\nraw_test[\"timestamp\"] = pd.to_datetime(raw_test[\"timestamp\"])\nraw_test.head(5)","1038f77e":"raw_train.sample(5)","25df94c1":"# raw_train[raw_train[\"game_session\"] == \"969a6c0d56aa4683\"].tail()","2984db4a":"# Remove `installation_id` without any assesments\n#ids_with_subms = raw_train[raw_train.type == \"Assessment\"][['installation_id']].drop_duplicates()\n#raw_train = pd.merge(raw_train, ids_with_subms, on=\"installation_id\", how=\"inner\"); len(raw_train)","c54d7cfb":"# installation_id's who did assessments (we have already taken out the ones who never took one),\n#  but without results in the train_labels? As you can see below, yes there are 628 of those.\n#discard_id = raw_train[raw_train.installation_id.isin(train_labels.installation_id.unique()) != True].installation_id.unique()\n\n#print(\"Number of ids that were discarded: \",discard_id.shape[0])\n\n#raw_train = raw_train[raw_train.installation_id.isin(discard_id)!=True]","cccc5597":"# Reduce event_id to make data preparation faster\n\nspecs['hashed_info']=specs['info'].transform(hash)\nunique_specs=pd.DataFrame(specs[['hashed_info']].drop_duplicates())\nunique_specs[\"id\"] = np.arange(len(unique_specs))\nspecs = pd.merge(specs,unique_specs,on='hashed_info',how='left')\nevent_id_mapping = dict(zip(specs.event_id,specs.id))\nraw_train[\"event_id\"] = raw_train[\"event_id\"].map(event_id_mapping)\nraw_test[\"event_id\"] = raw_test[\"event_id\"].map(event_id_mapping)\n\nraw_train=raw_train[raw_train['event_id']!=137]  # this particular event id only has 2 records in train and none in test....\n","1a0d0ea5":"def get_accuracy(correct_data):\n    # Rounding correct > 1 to 1 lowers the score. Why?\n    correct = len(correct_data.loc[correct_data])\n    wrong = len(correct_data.loc[~correct_data])\n    accuracy = correct\/(correct + wrong) if correct + wrong else 0\n    return accuracy, correct, wrong\n\ndef get_group(accuracy):\n    if not accuracy:\n        return 0\n    elif accuracy == 1:\n        return 3\n    elif accuracy >= 0.5:\n        return 2\n    return 1","969be361":"# I prefer this over calculating average\ndef lin_comb(v1, v2, beta): return beta*v1 + (1-beta)*v2","5546d371":"def prepare(data: pd.DataFrame, one_hot: List[str], test=False) -> pd.DataFrame:\n    one_hot_dict = defaultdict(int)\n\n    prepared = []\n    for id_, g in tqdm(data.groupby(\"installation_id\", sort=False)):\n        features = process_id(g, one_hot, one_hot_dict.copy(), test)\n        if not features:\n            continue\n        if test:\n            features[-1][\"is_test\"] = 1\n        prepared.extend(features)\n    return pd.DataFrame(prepared).fillna(0).sort_index(axis=1)","e9340412":"def process_id(id_data: pd.DataFrame, one_hot_cols, one_hot_dict, test: bool) -> pd.DataFrame:\n    a_accuracy, a_group, a_correct, a_wrong, counter, accumulated_duration_mean = 0, 0, 0, 0, 0, 0\n    a_groups = {\"0\":0, \"1\":0, \"2\":0, \"3\":0}\n    a_durations = defaultdict(int)\n    features = []\n\n    for s, gs in id_data.groupby(\"game_session\", sort=False):\n        def update_counter(counter: dict, column: str):\n            session_counter = Counter(gs.loc[:, column])\n            for value in session_counter.keys():\n                counter[f\"{column}_{value}\"] += session_counter[value]\n            return counter\n\n        def process_session(gs):\n            # share state with parent process_id()\n            nonlocal one_hot_dict, a_groups, a_durations, a_accuracy, a_group, a_correct, a_wrong, counter, accumulated_duration_mean\n            # increment one hot columns for session, e.g. Bird Measurer: 50\n            def accumulate():\n                nonlocal accumulated_duration_mean\n                # accumulated one_hot features per id for a given session, e.g. Bird Measurer: 50\n                for c in one_hot_cols:\n                    one_hot_dict.update(update_counter(one_hot_dict, c))\n                duration = (gs[\"timestamp\"].iloc[-1] - gs[\"timestamp\"].iloc[0]).seconds\n                # an accumulated session duration mean\n                #accumulated_duration_mean = lin_comb(accumulated_duration_mean or duration,\n                #                                     duration, beta=0.9)\n                a_durations[f\"duration_{gs.title.iloc[0]}\"] = duration\n                \n            if gs[\"type\"].iloc[0] != \"Assessment\":\n                accumulate()\n                return\n\n            guess_mask = ((gs[\"event_data\"].str.contains(\"correct\")) & \n             (((gs[\"event_code\"] == 4100) &(~gs[\"title\"].str.startswith(\"Bird\")) | \n               ((gs[\"event_code\"] == 4110) & (gs[\"title\"].str.startswith(\"Bird\"))))))\n            answers = gs.loc[guess_mask, \"event_data\"].apply(lambda x: json.loads(x).get(\"correct\"))\n\n            # skip assessments without attempts in train\n            if answers.empty and not test:\n                accumulate()\n                return\n\n            accuracy, correct, wrong = get_accuracy(answers)\n            group = get_group(accuracy)\n            processed = {\"installation_id\": id_data[\"installation_id\"].iloc[0],\n                         \"title\": gs[\"title\"].iloc[0],\n                         \"timestamp\": gs[\"timestamp\"].iloc[0],\n                         \"accumulated_duration_mean\": accumulated_duration_mean,\n                         \"accumulated_correct\": a_correct, \"accumulated_incorrect\": a_wrong,\n                         \"accumulated_accuracy_mean\": a_accuracy\/counter if counter > 0 else 0,\n                         \"accumulated_accuracy_group_mean\": a_group\/counter if counter > 0 else 0, \n                         \"accuracy_group\": group,\n                        }\n            processed.update(a_groups)\n            processed.update(one_hot_dict)\n            processed.update(a_durations)\n            counter += 1\n            a_accuracy += accuracy\n            a_correct += correct\n            a_wrong += wrong\n            a_group += group\n            a_groups[str(group)] += 1\n            accumulate()\n            return processed\n        \n        # skip sessions with 1 row\n        if len(gs) == 1 and not test:\n            continue\n        gs.reset_index(inplace=True, drop=True)\n        if (gs[\"timestamp\"].iloc[-1] - gs[\"timestamp\"].iloc[0]).seconds > 1800:\n            gs[\"passed\"] = gs.loc[:, \"timestamp\"].diff().apply(lambda x: x.seconds)\n            id_max = gs[\"passed\"].idxmax()\n            if gs[\"passed\"].max() > 1800:\n                session = gs.iloc[:id_max]\n                continued_session = gs.iloc[id_max:]\n                fs = process_session(session)\n                c_fs = process_session(continued_session)\n                if fs:\n                    features.append(fs)\n                if c_fs:\n                    features.append(c_fs)\n                continue\n\n        session_features = process_session(gs)\n        if session_features:\n            features.append(session_features)\n        \n    return features","fdf8331a":"# convert text into datetime\n#raw_train['date'] = raw_train['timestamp'].dt.date\n#raw_train['month'] = raw_train['timestamp'].dt.month\nraw_train['hour'] = raw_train['timestamp'].dt.hour\nraw_train['dayofweek'] = raw_train['timestamp'].dt.dayofweek    \n\n#raw_test['date'] = raw_test['timestamp'].dt.date\n#raw_test['month'] = raw_test['timestamp'].dt.month\nraw_test['hour'] = raw_test['timestamp'].dt.hour\nraw_test['dayofweek'] = raw_test['timestamp'].dt.dayofweek","99ce6b14":"one_hot_counters=[\"title\", \"type\", \"event_code\", \"event_id\"]\ntrain = prepare(raw_train, one_hot_counters)\n# train = prepare(raw_train.iloc[:1_000_000], one_hot_counters)","46b40014":"add_datepart(train, \"timestamp\", prefix=\"timestamp_\", time=True)\ntrain.head()","de3af5f2":"test = prepare(raw_test, one_hot=one_hot_counters, test=True)","d727f7f6":"#test.columns.tolist()","2233fe64":"# for the case when one hot encoded columns don't match between datasets\nadd_datepart(test, \"timestamp\", prefix=\"timestamp_\", time=True);","67a39929":"# why discard good data from test, let's use all the taken assessments in train!\ntrain = (pd.concat([train, test[test[\"is_test\"] == 0].drop(columns=[\"is_test\"])],\n                   ignore_index=True, sort=False)).fillna(0)\ntrain.head()","1b00a43f":"test = test.loc[test[\"is_test\"] == 1].reset_index(drop=True)\n#test.drop(columns=[\"accuracy_group\", \"is_test\"], inplace=True)\ntest.head()","74bcb3fd":"session_title1 = train['title'].value_counts().index[0]\nsession_title2 = train['title'].value_counts().index[1]\nsession_title3 = train['title'].value_counts().index[2]\nsession_title4 = train['title'].value_counts().index[3]\nsession_title5 = train['title'].value_counts().index[4]\n\ntrain['title'] = train['title'].replace({session_title1:0,session_title2:1,session_title3:2,session_title4:3,session_title5:4})\ntest['title'] = test['title'].replace({session_title1:0,session_title2:1,session_title3:2,session_title4:3,session_title5:4})\n","c347382b":"for col in train.columns:\n    if type(col) != str:\n        train = train.rename(columns={col:str(col)})\n        test = test.rename(columns={col:str(col)})\n\ncol_order = sorted(train.columns)\ntrain = train.ix[:,col_order]\ntest = test.ix[:,col_order]","f6538ea0":"test.drop(columns=\"accuracy_group\", inplace=True)\ntest.head()","b3524d48":"diff = train.drop(columns=[\"accuracy_group\"]).columns.difference(test.columns)\ndisplay(f\"Test doesn't contain {diff.values}\")\ndisplay(f\"Train doesn't contain {test.columns.difference(train.columns).values}\")\ntrain.drop(columns=diff, inplace=True)","05686e23":"main_train = train.copy()\n# train = main_train.copy()","1d5c93ee":"del_cols = [\"timestamp_Second\"]\nfor col in train.columns.values:\n    counts = train[col].value_counts().iloc[0]\n    if (counts \/ train.shape[0]) >= 0.99:\n        del_cols.append(col)\ntrain.drop(columns=del_cols, inplace=True, errors=\"ignore\")\ntest.drop(columns=del_cols, inplace=True, errors=\"ignore\")\ndisplay(f\"Dropped {del_cols}\")","3e97f3f6":"procs = [FillMissing, Categorify, Normalize]","bdaf3e86":"np.random.seed(42)","e6723a9b":"# remove outliers\ntrain = train[train[train.columns[train.columns.str.startswith(\"duration_\", na=False)].to_list()].apply(sum, axis=1) < 10000].reset_index(drop=True)\n","fb782b83":"# grab the last assessments per id\nvalid_idx = [g.iloc[-1].name for i, g in train.groupby(\"installation_id\", sort=False)]; len(valid_idx)","54c7521e":"train.accuracy_group.value_counts(normalize=True)","489e127f":"train.loc[valid_idx].accuracy_group.value_counts(normalize=True)","4e104c6e":"train.title.value_counts(normalize=True)","673cfd17":"train.loc[valid_idx].title.value_counts(normalize=True)","c4b8eeac":"date_cols = train.columns[train.columns.str.startswith(\"timestamp_\", na=False)].to_list()","685390a4":"dep_var = \"accuracy_group\"\ncat_names = list(filter(lambda x: x not in [\"timestamp_Elapsed\"], date_cols)) + [\"title\"]\ncont_names = list(filter(lambda x: x not in [\"installation_id\", dep_var] + cat_names,\n                         train.columns.to_list()))","a4d95e96":"data = (TabularList.from_df(train, path=\"\/kaggle\/working\", cat_names=cat_names, cont_names=cont_names, procs=procs)\n        .split_by_idx(valid_idx=valid_idx)\n        .label_from_df(cols=dep_var, label_cls=FloatList)\n        .add_test(TabularList.from_df(test, path=home, cat_names=cat_names, cont_names=cont_names, procs=procs))\n        .databunch()\n)","d48dfd8e":"# data.show_batch()","a7768051":"from functools import partial\nimport scipy as sp\nfrom sklearn.metrics import cohen_kappa_score\n\nclass OptimizedRounder():\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa (QWK) score\n    # https:\/\/www.kaggle.com\/naveenasaithambi\/optimizedrounder-improved\n    \"\"\"\n    def __init__(self, initial_coef, labels):\n        self.coef_ = 0\n        self.initial_coef = initial_coef\n        self.labels = labels\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = self.labels)\n        return -cohen_kappa_score(X_p, y, weights=\"quadratic\")\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        self.coef_ = sp.optimize.minimize(loss_partial, self.initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = self.labels)\n\n    def coefficients(self): return self.coef_['x']","7ace4a58":"from fastai.metrics import RegMetrics\n\nclass KappaScoreRegression(RegMetrics):\n    def on_epoch_end(self, last_metrics, **kwargs):\n        preds = self.preds.flatten()\n        opt = OptimizedRounder([0.5, 1.5, 2.0], labels=[0, 1, 2, 3])\n        opt.fit(preds, self.targs)\n        coefs = opt.coefficients()\n        def rounder(preds):\n            y = preds.clone()\n            y[y < coefs[0]] = 0\n            y[y >= coefs[2]] = 3\n            y[(y >= coefs[0]) & (y < coefs[1])] = 1\n            y[(y >= coefs[1]) & (y < coefs[2])] = 2\n            return y.type(torch.IntTensor)\n\n        qwk = cohen_kappa_score(rounder(preds), self.targs, weights=\"quadratic\")\n        return add_metrics(last_metrics, qwk)","1354404d":"from fastai.callbacks import *\n\nlearn = tabular_learner(data, layers=[2000,100],\n                        metrics=[KappaScoreRegression()],\n                        y_range=[0, 3],\n                        emb_drop=0.04,\n                        ps=0.6,\n                        callback_fns=[partial(EarlyStoppingCallback, monitor=\"kappa_score_regression\", mode=\"max\", patience=7),\n                                      partial(SaveModelCallback, monitor=\"kappa_score_regression\", mode=\"max\", name=\"best_model\")]\n                       )","e9ecb9c3":"learn.lr_find()\nlearn.recorder.plot()","0a0141c1":"#learn.fit_one_cycle(40, 9e-03)   ","180056bc":"learn.fit_one_cycle(40, 2.5e-03)  \n#learn.fit_one_cycle(40, 1e-02)  ","a4377400":"preds_train, y = learn.get_preds(ds_type=DatasetType.Valid)\nlabels_train = preds_train.flatten()\nopt = OptimizedRounder([0.5, 1.5, 2.0], labels=[0, 1, 2, 3])\nopt.fit(labels_train, y)","d764a1ec":"coefs = opt.coefficients(); coefs","6247821e":"def rounder(preds):\n    y = preds.clone()\n    y[y < coefs[0]] = 0\n    y[y >= coefs[2]] = 3\n    y[(y >= coefs[0]) & (y < coefs[1])] = 1\n    y[(y >= coefs[1]) & (y < coefs[2])] = 2\n    return y.type(torch.IntTensor)","d3999fa9":"preds, y = learn.get_preds(ds_type=DatasetType.Test)\nlabels = preds.flatten()","fbf42fe2":"labels = rounder(labels)","3344a03c":"submission = pd.DataFrame({\"installation_id\": test.installation_id, \"accuracy_group\": labels})\nsubmission.to_csv(\"submission.csv\", index=False)\nlen(submission), submission.accuracy_group.value_counts()","e59ede8c":"# Train","2177109a":"# Optimize predicted values","d4949ce1":"# Preparing data","769a0479":"We are told in the data description that:\n\n* The file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set.\n* Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110.\n* If the attempt was correct, it contains \"correct\":true.\n\nWe also know:\n\n* The intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt).\n* Each application install is represented by an installation_id. This will typically correspond to one child, but you should expect noise from issues such as shared devices.\n* In the training set, you are provided **the full history of gameplay data.**\n* In the test set, **we have truncated the history after the start event of a single assessment, chosen randomly, for which you must predict the number of attempts.**\n* Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.\n","a2f53f02":"### This kernel uses fastai version-2 on a fork of the original notebook [\"Fastai 2019 Data Science Bowl\"](https:\/\/www.kaggle.com\/manyregression\/fastai-2019-data-science-bowl), thanks to Valeriy Mukhtarulin aka @manyregression. \n\n### Since the use of internet is not allowed, I created a [fastai2](https:\/\/www.kaggle.com\/sheriytm\/fastai2) dataset with the required files to run fastai version-2. Add [my dataset](https:\/\/www.kaggle.com\/sheriytm\/fastai2), follow the installation steps in the following cells and you are good to go.\n\n### Feel free to upvote [my dataset](https:\/\/www.kaggle.com\/sheriytm\/fastai2) and experiment with it to your hearts content :-)\n","a3bed32e":"* [Looking at data](#Looking-at-data)\n* [Preparing data](#Preparing-data)\n* [Approach](#How-to-approach)\n* [Train](#Train)\n* [Submission](#Submission)","7f8d594c":"# How to approach\n\nFor test set we guess the group based on **single** installation_id. But the train\\test datasets contain **repeatable** installation ids with different game sessions.\nHence it makes sense to guess the group for each assessment using history.\n\nA couple of more points:\n\n* do not use any assessment data for the current assessment prediction except title to prevent overfit\n* regression with the right coeff\n\nThe questions:\n* does randomly truncated history in test conflicts with the above?\nFrom the test dataset, the last asssessment data is cleaned. So it looks like a session with only 1 event.\nTo have a good validation dataset however, it should be the same as test - https:\/\/www.kaggle.com\/tarandro\/regression-with-less-overfitting\n* Is more than 1 correct submission impossible per session? Does it mean noise - two devices with the same id sharing the same session?","f14cbd25":"# Looking at data","057e8753":"### Updated the [fastai2](https:\/\/www.kaggle.com\/sheriytm\/fastai2) dataset to the latest version.","681cbdc2":"It seems `game_time` is not captured correctly - there's a huge window in between some events in a given session.","fffa006a":"My approach to 2019 DS bowl with fastai v1\n\nI used these awesome notebooks:\n    \n    https:\/\/www.kaggle.com\/robikscube\/2019-data-science-bowl-an-introduction\n    https:\/\/www.kaggle.com\/amanooo\/dsb-2019-regressors-and-optimal-rounding\n    https:\/\/www.kaggle.com\/tarandro\/regression-with-less-overfitting\n    https:\/\/www.kaggle.com\/keremt\/fastai-feature-engineering-part1-6160-features\n    https:\/\/www.kaggle.com\/keremt\/fastai-model-part1-regression\n    https:\/\/www.kaggle.com\/keremt\/fastai-model-part2-upgraded","860a346f":"The target.\n\nWe are told: The intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt). The outcomes in this competition are grouped into 4 groups (labeled `accuracy_group` in the data):\n\n    3: the assessment was solved on the first attempt\n    2: the assessment was solved on the second attempt\n    1: the assessment was solved after 3 or more attempts\n    0: the assessment was never solved\n\nFor each installation_id represented in the test set, you must predict the accuracy_group **of the last assessment** for that installation_id","ba14b686":"## Kappa","6f60342f":"## Proper validation dataset\n\nLet's assume the second hidden test is the same as this one. I.e. we predict the last assessment.","1debbf4a":"# Submission"}}