{"cell_type":{"76586e1e":"code","fdbd07c9":"code","888f7050":"code","70616b48":"code","933fdbfd":"code","eeb54743":"code","20fc8c3c":"code","d29df918":"code","81e35e7c":"code","43c5bdb5":"code","bfb931c0":"code","1221816f":"code","a5b7feb3":"code","6fce0115":"code","a5820904":"code","96e7a887":"code","a8cbc5b4":"code","98b22b0b":"code","a0587600":"code","d6a2c117":"code","eefedde5":"code","87ba1e8b":"code","5edcc7b0":"code","edd96031":"code","d3d78eeb":"code","fd63af75":"markdown","0e03a291":"markdown","3c953a44":"markdown","cfb7e786":"markdown"},"source":{"76586e1e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n \n# Scikit-learn\uff08\u8a55\u4fa1\u7b97\u51fa\uff09\nfrom sklearn.metrics import confusion_matrix\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdbd07c9":"train_df = pd.read_csv(\"\/kaggle\/input\/sales-prediction-of-clothes-in-e-commerce\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/sales-prediction-of-clothes-in-e-commerce\/test.csv\")\ntrain_df.drop([\"row_id\",\"title\"], axis=1, inplace=True)\ntest_df.drop([\"row_id\",\"title\"], axis=1, inplace=True)\n\n#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\ncategory_col = [\"uses_ad_boosts\",\"tags\",\"product_color\",\"product_variation_size_id\",\n                \"merchant_title\",\"merchant_id\",\"merchant_has_profile_picture\"]\n\nprint(train_df.shape)\nprint(test_df.shape)\nprint(train_df.columns)\nprint(train_df[category_col].dtypes)","888f7050":"train_df.uses_ad_boosts","70616b48":"train_df[category_col].nunique()","933fdbfd":"#\u6b20\u640d\u6570\u78ba\u8a8d\nprint(train_df.isnull().sum())\nprint(test_df.isnull().sum())","eeb54743":"#\u30bf\u30fc\u30b2\u30c3\u30c8\u30b0\u30e9\u30d5\nimport matplotlib.pyplot as plt\nplt.plot(train_df.units_sold)","20fc8c3c":"#\u30bf\u30fc\u30b2\u30c3\u30c8\u30b0\u30e9\u30d5\nplt.plot(train_df.rating_one_count, alpha=0.4)\nplt.plot(train_df.rating_two_count, alpha=0.4)\nplt.plot(train_df.rating_three_count, alpha=0.4)\nplt.plot(train_df.rating_four_count, alpha=0.4)\nplt.plot(train_df.rating_five_count, alpha=0.4)\nplt.title(\"rating_count\")","d29df918":"plt.plot(train_df.merchant_rating, alpha=0.4)","81e35e7c":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092\u30e9\u30d9\u30eb\u5316 \nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n\n#\u4e00\u5ea6\u5b66\u7fd2\u7528\u3068\u4e88\u6e2c\u7528\u3092\u7d50\u5408\nall_df = pd.concat([train_df[category_col], test_df[category_col]], axis=0)\nprint(all_df.shape)\n\n#\u30e9\u30d9\u30eb\u5316\nfor i, name in enumerate(category_col):\n    print(name)\n    all_df[name].fillna(\"missing\", inplace=True)\n    encoded = le.fit_transform(all_df[name].values)\n    decoded = le.inverse_transform(encoded)\n    all_df[name] = encoded\n\nprint(\"all_df:\",all_df.shape)\n\n#\u518d\u5ea6\u5b66\u7fd2\u7528\u3068\u4e88\u6e2c\u7528\u306b\u5206\u5272\ntrain_df[category_col] = all_df[:1075]\ntest_df[category_col] = all_df[1075:]\nprint(\"train_df:\",train_df.shape)\nprint(\"test_df\",test_df.shape)","43c5bdb5":"#\u30c7\u30fc\u30bf\u5206\u5272\nfrom sklearn.model_selection import train_test_split\n\nX = train_df.drop(\"units_sold\",axis=1)\ny = train_df.units_sold\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\nprint(\"X_train\", X_train.shape)\nprint(\"X_test\", X_test.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"y_test\", y_test.shape)","bfb931c0":"#train\u3068test\u306e\u4e2d\u8eab\u3092\u78ba\u8a8d\nplt.figure(figsize=(10,5))\nplt.subplot(2,1,1)\nplt.plot(y_train.reset_index(drop=True))\nplt.subplot(2,1,2)\nplt.plot(y_test.reset_index(drop=True))","1221816f":"#lightgbm kfold\nimport lightgbm as lgbm\nfrom sklearn.model_selection import cross_val_score\n\n# LightGBM\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'learning_rate' : 0.1,\n    'objective': 'regression',\n#    \"num_iterations\":500,\n#    'num_leaves': 23, \n    'min_data_in_leaf': 1,\n    \"metric\":\"mape\"\n}\n\n# \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nlgb_train = lgbm.Dataset(X_train, y_train, categorical_feature=category_col)\nlgb_eval = lgbm.Dataset(X_test, y_test, categorical_feature=category_col)\n\n\nlgb = lgbm.train(params, lgb_train, num_boost_round=5000,\n                 valid_names=['train', 'valid'],\n                 valid_sets=[lgb_train, lgb_eval],\n                 early_stopping_rounds=20,\n                 categorical_feature=category_col\n                )\nlgb.predict(X_test)","a5b7feb3":"#\u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u8a55\u4fa1\u3092\u78ba\u8a8d\u3059\u308b\n\n# \u771f\u5024\u3068\u4e88\u6e2c\u5024\u306e\u8868\u793a\ny_pred = lgb.predict(X_test)\ndf_pred = pd.DataFrame({'CRIM':y_test,'CRIM_pred':y_pred})\ndisplay(df_pred)\n\n# rmse : \u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\u306e\u5e73\u65b9\u6839\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred) # MSE(\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee)\u306e\u7b97\u51fa\nrmse = np.sqrt(mse) # RSME = \u221aMSE\u306e\u7b97\u51fa\nprint('RMSE :',rmse)\n\n#plot\ndf_pred.reset_index(inplace=True)\nplt.figure(figsize=(10,4))\nplt.plot(df_pred.CRIM)\nplt.plot(df_pred.CRIM_pred)","6fce0115":"#\u4e88\u6e2c\nprint(test_df.shape)\ny_pred = pd.DataFrame(lgb.predict(test_df))\n\n# submit\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\nsubmit_df = y_pred.reset_index()\nsubmit_df.columns = [\"row_id\",\"units_sold\"]\nsubmit_df","a5820904":"#\u4fdd\u5b58\nsubmit_df.to_csv(\".\/submit_data_v6.csv\",index=False)\npd.read_csv(\".\/submit_data_v6.csv\")","96e7a887":"#\u30e9\u30d9\u30eb\u5316\nunits_dict = {}\nunits_dict[0] = 100\nunits_dict[1] = 200\nunits_dict[2] = 500\nunits_dict[3] = 1000\nunits_dict[4] = 5000\nunits_dict[5] = 10000\nunits_dict[6] = 2000\n\nunits_dict.keys()","a8cbc5b4":"y_all = pd.concat([y_train, y_test],axis=0)\n\nencoded = le.fit_transform(y_all.values)\ndecoded = le.inverse_transform(encoded)\nnew_y_all = encoded\n\nprint(\"new_y_all:\",new_y_all.shape)\n\n#\u518d\u5ea6\u5b66\u7fd2\u7528\u3068\u4e88\u6e2c\u7528\u306b\u5206\u5272\ny_train = new_y_all[:860]\ny_test = new_y_all[860:]\nprint(\"train_df:\",y_train.shape)\nprint(\"test_df\",y_test.shape)","98b22b0b":"print(\"train_df:\",y_train.shape)\nprint(\"test_df\",y_test.shape)","a0587600":"#lightgbm kfold\nimport lightgbm as lgbm\nfrom sklearn.model_selection import cross_val_score\n\n# LightGBM\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'learning_rate' : 0.1,\n    'objective': 'multiclass',\n#    \"num_iterations\":500,\n#    'num_leaves': 23, \n    'min_data_in_leaf': 1,\n    \"metric\":\"multi_logloss\",\n    'num_class': 7\n}\n\n# \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nlgb_train = lgbm.Dataset(X_train, y_train, categorical_feature=category_col)\nlgb_eval = lgbm.Dataset(X_test, y_test, categorical_feature=category_col)\n\n\nlgb = lgbm.train(params, lgb_train, num_boost_round=3000,\n                 valid_names=['train', 'valid'],\n                 valid_sets=[lgb_train, lgb_eval],\n                 early_stopping_rounds=20,\n                 categorical_feature=category_col\n                )\nlgb.predict(X_test)","d6a2c117":"y_pred = lgb.predict(X_test)\ny_pred_max = np.argmax(y_pred, axis=1)\ny_pred_max","eefedde5":"#\u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u8a55\u4fa1\u3092\u78ba\u8a8d\u3059\u308b\n\n# \u771f\u5024\u3068\u4e88\u6e2c\u5024\u306e\u8868\u793a\n#y_pred = lgb.predict(X_test)\ndf_pred = pd.DataFrame({'CRIM':y_test,'CRIM_pred':y_pred_max})\ndisplay(df_pred)\n\n#plot\ndf_pred.reset_index(inplace=True)\nplt.figure(figsize=(10,4))\nplt.plot(df_pred.CRIM)\nplt.plot(df_pred.CRIM_pred)","87ba1e8b":"units_dict","5edcc7b0":"0-100","edd96031":"#\u4e88\u6e2c\nprint(test_df.shape)\ny_pred = pd.DataFrame(np.argmax(lgb.predict(test_df), axis=1))\n\n# submit\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\nsubmit_df = y_pred.reset_index()\nsubmit_df.columns = [\"row_id\",\"units_sold\"]\n\nfor i in range(len(submit_df)):\n    [submit_df[i]==units_dict[0]]=100\n\nsubmit_df","d3d78eeb":"submit_df.to_csv(\".\/submit_data_class_v1.csv\",index=False)","fd63af75":"# lightgbm(\u30de\u30eb\u30c1\u30bf\u30b9\u30af\u5206\u985e)","0e03a291":"#\u4ea4\u5dee\u691c\u8a3c\n\n#5\u3064\u306e\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u30ea\u30b9\u30c8\u306e\u521d\u671f\u5316\nmodels = []\n\n#\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u6570\u3060\u3051\u306e\u6570\u5217\uff080\u884c\u304b\u3089\u6700\u7d42\u884c\u307e\u3067\u9023\u756a\uff09\nrow_no_list = list(range(len(y_train)))\n\n#KFold\u30af\u30e9\u30b9\u3092\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\nK_fold = StratifiedKFold(n_splits=3, shuffle=True,  random_state=42)\n\nfor train_cv_no, eval_cv_no in K_fold.split(row_no_list, y_train):\n    # iloc\u3067\u53d6\u308a\u51fa\u3059\u884c\u3092\u6307\u5b9a\n    X_train_cv = X_train.iloc[train_cv_no, :]\n    y_train_cv = pd.Series(y_train).iloc[train_cv_no]\n    X_eval_cv = X_train.iloc[eval_cv_no, :]\n    y_eval_cv = pd.Series(y_train).iloc[eval_cv_no]\n    \n    # \u5b66\u7fd2\u7528\n    lgb_train = lgbm.Dataset(X_train, y_train, categorical_feature=category_col)\n\n    # \u691c\u8a3c\u7528\n    lgb_eval = lgbm.Dataset(X_test, y_test, reference=lgb_train, categorical_feature=category_col)\n    \n    # LightGBM\n    params = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'learning_rate' : 0.01,\n        'objective': 'regression',\n        \"num_iterations\":500,\n#'num_leaves': 23, \n        'min_data_in_leaf': 1,\n        \"eval_metric\":\"mape\"\n        }\n    \n    # \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\n    model = lgbm.train(params, lgb_train, num_boost_round=50, \n                    valid_names=['train', 'valid'],  # \u5b66\u7fd2\u7d4c\u904e\u3067\u8868\u793a\u3059\u308b\u540d\u79f0\n                    valid_sets=[lgb_train, lgb_eval], \n                    early_stopping_rounds=20)\n    \n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    \n    # \u5b66\u7fd2\u304c\u7d42\u308f\u3063\u305f\u30e2\u30c7\u30eb\u3092\u30ea\u30b9\u30c8\u306b\u5165\u308c\u3066\u304a\u304f\n    models.append(model) ","3c953a44":"# lightgbm(\u56de\u5e30)","cfb7e786":"# \u4e88\u6e2c"}}