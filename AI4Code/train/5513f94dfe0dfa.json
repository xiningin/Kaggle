{"cell_type":{"0ad8c119":"code","faa2d88d":"code","d9f96319":"code","05444fd2":"code","aa8f2e12":"code","eeef457a":"code","6167da8c":"code","9ee65cd9":"code","68eba4be":"code","355eadb8":"code","9ee10941":"code","92f22370":"code","c64560af":"code","7d95203e":"code","26ee55c6":"code","84879f7d":"code","b046eaf0":"code","08a2d340":"code","d6e68d89":"code","5826d94d":"code","bb4617bf":"code","e0bef571":"code","5f6b9d0d":"code","8d83685f":"code","5d8344db":"code","eb360591":"code","d1a8c4b1":"code","22286b40":"code","42263f30":"code","3d5630af":"code","333d4fcb":"code","13accf86":"code","2a3348c9":"code","cf414d12":"code","7a346d54":"code","db9600d1":"code","73dfaa26":"code","b8b797d0":"code","4910e92f":"code","c6233f87":"code","bdca232b":"code","c5b67a25":"code","b7f8fea1":"code","12db2273":"code","620a541f":"code","603c41e1":"code","2d2073b5":"code","a90dda6f":"code","c08f382f":"code","65a719a2":"code","11c2be0d":"code","1b29f60a":"code","a9edab8c":"code","b64a2154":"code","be2827d7":"code","ff4b5745":"code","79654a21":"code","d26f6200":"code","e427808c":"code","4a8294a1":"code","9ad81fdf":"code","1eb6a92a":"code","15aa850f":"code","ebcc37bf":"code","d8bdd1e1":"code","d854edac":"code","e4ded3ea":"code","8cd7b0d7":"code","b9e09359":"code","7628c2a2":"code","83aa4f82":"code","c99b7b29":"code","6f2f10b8":"code","2cb6b929":"code","121d57ad":"code","eac2f103":"code","d7703ffb":"code","fe9843eb":"code","89bc35dc":"code","31c46d19":"code","417f8e8b":"code","52f1d6b6":"code","f5b3784a":"code","600ca98d":"code","8245e99e":"code","ec69b1b7":"code","49bcf10f":"code","71a3a574":"code","05b99a78":"code","d10bb6ab":"code","dd49e34c":"code","0be99443":"code","3fe7e9f1":"code","475dbad9":"code","f4df57a4":"code","a7c96dd3":"code","e9b7484a":"code","fd9a10cd":"code","ddca423c":"code","e877a841":"code","6b81633a":"code","d765b57f":"code","c3c5cc5b":"code","c497aee5":"code","8cda4504":"code","4c3e85f4":"code","6e9cfda2":"code","fb50da9e":"code","505ad8e2":"code","03013ab0":"code","c3a5f143":"code","e30de7b9":"code","e302458a":"code","4f904478":"code","a9bd9941":"code","e7177078":"code","5cfdc69c":"code","f16c6abb":"code","00911ef8":"code","b6509333":"code","a8a2cc00":"code","98f4df3c":"code","2ca345f2":"code","11c42870":"code","277ca40e":"code","3531a32c":"code","8bcd21dc":"code","8cb9c93f":"code","c7b01092":"code","d28e10ed":"code","b3e0946c":"code","c288662a":"markdown","b05fd856":"markdown","7a666534":"markdown","2e9a2c8a":"markdown","00cd6ab8":"markdown","04521930":"markdown","939ad081":"markdown","f08e04bc":"markdown","a27c58c6":"markdown","fbe8bbfb":"markdown","73833bb2":"markdown","4ddd40a7":"markdown","10782570":"markdown","f50b1d65":"markdown","ef9655e0":"markdown","385770d1":"markdown","f4674543":"markdown","844bb0ac":"markdown","4ea0bdc3":"markdown","d59b97ae":"markdown","6d521c15":"markdown","d3a1ac51":"markdown","601a0abe":"markdown","57e7fa1c":"markdown","61bbc3da":"markdown","0c9a920a":"markdown","fa5afb12":"markdown","29ee2113":"markdown","b88dc9aa":"markdown","6185bd5a":"markdown","3f37561e":"markdown","58c1a0b3":"markdown","55e945a9":"markdown","ddea69c3":"markdown","04e42068":"markdown","d64af3a5":"markdown","5788707a":"markdown","3e3e92ee":"markdown","d735a054":"markdown","f124187d":"markdown","58f4a897":"markdown","04313aaa":"markdown","887ddbf0":"markdown","1dd0871c":"markdown","3d2692d9":"markdown","381cc012":"markdown","9b031eec":"markdown","6b53c55d":"markdown","71975b41":"markdown","2f106f1c":"markdown","58c91819":"markdown","bdc1ba12":"markdown","abfd3752":"markdown","27e4afe8":"markdown","777d1895":"markdown","01f21b29":"markdown","f18c89b9":"markdown","610c44b6":"markdown","9a43fa60":"markdown","c50fdd6a":"markdown","878b3345":"markdown","a42db8e5":"markdown","f17985c7":"markdown","fc154800":"markdown","a729c5f3":"markdown","8a33dc9e":"markdown","05081122":"markdown","d8d59918":"markdown","3e0f1d1b":"markdown","4e259f92":"markdown","e9162654":"markdown","01ccda88":"markdown","03cda13d":"markdown","c6b1127d":"markdown","4d525182":"markdown","e364174b":"markdown","3c11c544":"markdown","9cb89c91":"markdown"},"source":{"0ad8c119":"from __future__ import division\nimport numpy as np\nimport pandas as pd \nimport os\nimport timeit\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tqdm import tqdm","faa2d88d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\n# link pandas and plotly\n# import cufflinks as cf\n\ninit_notebook_mode(connected=True)\n# cf.set_config_file(offline=True, world_readable=True, theme='ggplot')\n%matplotlib inline","d9f96319":"from matplotlib import rcParams\nrcParams['figure.figsize'] = 22, 14\nrcParams['axes.titlesize'] = 24\nrcParams['axes.labelsize'] = 20\nrcParams['xtick.labelsize'] = 16\nrcParams['ytick.labelsize'] = 16\nrcParams['legend.fontsize'] = 14","05444fd2":"def sub_boxenplots(x, data, y=\"totals.transactionRevenue_ln\", rot=15):\n    order = data[x].unique()\n    fig, axes = plt.subplots(ncols=2, nrows=1, squeeze=False, figsize=(22, 8))\n    sns.boxenplot(x=x, y=y, data=data, ax=axes[0, 0], order=order)\n    axes[0, 0].set_title(\"All Instances\")\n    axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=rot, ha='right')\n    sns.boxenplot(x=x, y=y, data=data.loc[data[y] > 0, :], ax=axes[0, 1], order=order)\n    axes[0, 1].set_title(\"Instances With Non-zero Revenue\")\n    axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=rot, ha='right')\n    fig.tight_layout()","aa8f2e12":"prefix = \"..\/input\/ga-customer-revenue-prediction\/\"","eeef457a":"import json\nfrom pandas.io.json import json_normalize\ndef load_df(csv_path='..\/input\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    read_start = timeit.default_timer()\n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows,\n                     parse_dates=['date']\n                    )\n    read_end = timeit.default_timer()\n    print(\"Finish reading {0}, time usage: {1}\".format(csv_path, read_end - read_start))\n    \n    process_start = timeit.default_timer()\n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    process_end = timeit.default_timer()\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}, time usage: \", process_end - process_start)\n    return df","6167da8c":"# Just for convinence, uncomment before submite the codes\nX_train_df = load_df(prefix + \"train.csv\")\nX_test_df = load_df(prefix + \"test.csv\")\n\nprint(\"Done!\")","9ee65cd9":"X_train_df.head(1)","68eba4be":"submit_id = X_test_df[\"fullVisitorId\"].unique()","355eadb8":"X_train_df.loc[:, \"totals.transactionRevenue_ln\"] = np.log1p(X_train_df[\"totals.transactionRevenue\"].fillna(0).astype(\"float\"))","9ee10941":"labels = ['Zero revenue instance', 'Non-zero revenue instance']\nvalues = [X_train_df.loc[X_train_df[\"totals.transactionRevenue_ln\"] == 0, \"totals.transactionRevenue_ln\"].count(),\n         X_train_df.loc[X_train_df[\"totals.transactionRevenue_ln\"] != 0, \"totals.transactionRevenue_ln\"].count()]\ntrace = go.Pie(labels=labels, values=values)\nlayout = dict(\n    title = 'Instance Revenue'\n)\n\nfig = dict(data=[trace], layout=layout)\niplot(fig, filename='basic_pie_chart')","92f22370":"sum_target_series = X_train_df.groupby(\"fullVisitorId\")[\"totals.transactionRevenue_ln\"].sum()\n\nlabels = ['Zero revenue customer', 'Non-zero customer']\nvalues = [sum_target_series[sum_target_series == 0].count(),\n         sum_target_series[sum_target_series != 0].count()]\ntrace = go.Pie(labels=labels, values=values)\nlayout = dict(\n    title = 'Unique Customer Revenue'\n)\n\nfig = dict(data=[trace], layout=layout)\niplot(fig, filename='basic_pie_chart')","c64560af":"trace = go.Box(y=X_train_df.loc[X_train_df[\"totals.transactionRevenue_ln\"] > 0, \"totals.transactionRevenue_ln\"],\n              name='Instance')\nlayout = dict(\n    title = 'Instance With Revenue Greater Than Zero'\n)\n\nfig = dict(data=[trace], layout=layout)\niplot(fig, filename='basic_pie_chart')","7d95203e":"trace = go.Box(y=sum_target_series[sum_target_series > 0], name=\"Unique User\")\niplot([trace])","26ee55c6":"to_drop_cols = [c for c in X_train_df.columns if X_train_df[c].nunique(dropna=False)==1 ]\n\nX_train_df.drop(to_drop_cols, axis=1, inplace=True)\nX_test_df.drop(to_drop_cols, axis=1, inplace=True)","84879f7d":"print(\"Training set shape: \", X_train_df.shape, \" Testing set shape: \", X_test_df.shape)\nprint(\"Difference features between two sets:\")\nfor col in X_train_df.columns:\n    if col not in X_test_df:\n        print(col)","b046eaf0":"X_train_df[\"trafficSource.campaignCode\"].unique()","08a2d340":"X_train_df.drop(\"trafficSource.campaignCode\", axis=1, inplace=True)\n\nX_test_df = pd.concat([X_test_df, \n                       pd.Series(np.nan, name='totals.transactionRevenue'), \n                       pd.Series(np.nan, name='totals.transactionRevenue_ln')], \n                      axis=1)\n\nX_all_df = pd.concat([X_train_df, X_test_df], ignore_index=True, sort=False)","d6e68d89":"X_all_df.drop(['sessionId', 'visitId'], axis=1, inplace=True)","5826d94d":"obj_cols = [column for column in X_all_df.columns if X_all_df[column].dtype == object]","bb4617bf":"for col in obj_cols:\n    try:\n        X_all_df.loc[:, col] = pd.to_numeric(X_all_df.loc[:, col], errors='raise')\n#         print(\"Successfully parse column: \", col)\n    except ValueError as e:\n        # mute the string column that cannot be converted to numeric values.\n        pass\n#         print(\"Unable to parse column: \", col)","e0bef571":"for col in X_all_df.select_dtypes(include='object'):\n    if col == \"fullVisitorId\":\n        continue\n    try:\n        X_all_df.loc[:, col] = pd.Categorical(X_all_df.loc[:, col])\n#         print(\"Successfully parse column: \", col)\n    except ValueError as e:\n        print(\"Unable to parse column: \", col)","5f6b9d0d":"bool_cols = []\nfor col in X_all_df:\n    if X_all_df[col].nunique() == 2:\n        bool_cols.append(col)\nX_all_df.loc[:, bool_cols] = X_all_df.loc[:, bool_cols].astype('bool')","8d83685f":"def investigate(col_name, data):\n    print(\"The number of unique category\")\n    print(col_name, \": \", data[col_name].nunique())\n    print(\"*\" * 20)\n    print(\"Value count\")\n    print(data[col_name].value_counts())","5d8344db":"def ratio_nan(data):\n    num_data = X_all_df.shape[0]\n    null_sum = data.isnull().sum()\n    null_val_features = null_sum[null_sum > 0]\n    if \"totals.transactionRevenue_ln\" in null_val_features:\n        null_val_features.drop([\"totals.transactionRevenue\", \"totals.transactionRevenue_ln\"], inplace=True)\n    print(null_val_features\/ num_data)","eb360591":"print(\"The features with NaN value percentage: \")\nratio_nan(X_all_df)","d1a8c4b1":"X_all_df.loc[:, \"totals.bounces\"].fillna(0, inplace=True)\nX_all_df.loc[:, \"totals.bounces\"] = X_all_df.loc[:, \"totals.bounces\"].astype('bool')","22286b40":"sub_boxenplots(data=X_all_df.loc[X_all_df[\"totals.transactionRevenue_ln\"].notnull(), :], x=\"totals.bounces\")","42263f30":"X_all_df.drop(X_all_df.loc[X_all_df[\"totals.bounces\"], \"fullVisitorId\"].index, axis=0, inplace=True)\n\n# We don't need this feature anymore\nX_all_df.drop(\"totals.bounces\", axis=1, inplace=True)\n\nX_all_df.reset_index(drop=True, inplace=True)","3d5630af":"X_all_df.loc[:, \"totals.newVisits\"].fillna(0, inplace=True)\nX_all_df.loc[:, \"totals.newVisits\"] = X_all_df.loc[:, \"totals.newVisits\"].astype('bool')","333d4fcb":"X_all_df.loc[:, \"totals.pageviews\"].fillna(0, inplace=True)","13accf86":"def plot_cmp_stack(data, col_name):\n    \n    total_null_num = data[col_name].isnull().sum()\n    total_not_null_num = data[col_name].notnull().sum()\n    \n    null_zero_num =  (data.loc[data[col_name].isnull(), \"totals.transactionRevenue_ln\"] == 0).sum()\n    null_non_zero_num = (data.loc[data[col_name].isnull(), \"totals.transactionRevenue_ln\"] != 0).sum()\n    not_null_zero_num = (data.loc[data[col_name].notnull(), \"totals.transactionRevenue_ln\"] == 0).sum()\n    not_null_non_zero_num = (data.loc[data[col_name].notnull(), \"totals.transactionRevenue_ln\"] != 0).sum()\n    \n    trace1 = go.Bar(\n        x=['NULL', 'Not NULL'],\n        y=[null_zero_num\/ total_null_num, not_null_zero_num\/ total_not_null_num],\n        name='Instances With Zero Revenue',\n        marker=dict(\n            color='rgb(158,202,225)',\n            line=dict(\n                color='rgb(8,48,107)',\n                width=1.5),\n        ),\n        opacity=0.6\n    )\n    \n    trace2 = go.Bar(\n        x=['NULL', 'Not NULL'],\n        y=[null_non_zero_num\/ total_null_num, not_null_non_zero_num\/ total_not_null_num],\n        name='Instances With Non-Zero Revenue',\n        marker=dict(\n            color='rgb(58,200,225)',\n            line=dict(\n                color='rgb(8,48,107)',\n                width=1.5),\n            ),\n        opacity=0.6        \n    )\n    \n    trace3 = go.Pie(\n        labels = ['Ratio Of Non-zero Revenue With This Feature Is Null', 'Ratio Of Non-zero Revenue With This Feature Is Not NULL'],\n        values = [null_non_zero_num, not_null_non_zero_num],\n        domain = {\"x\": [0.5, 1]},\n        hole = .4,\n        name = 'Instances With Non-zero Revenue',\n        text = ['Non-zero Ratio']\n    )\n    \n    data=[trace1, trace2, trace3]\n    \n    layout=go.Layout(\n        barmode='stack',\n        title = col_name + \": Revenue Comparison Between NULL and Not NULL Value\",\n        yaxis = {'title': 'Percentage'},\n        xaxis = {\n            'domain': [0, 0.5]\n        },\n        showlegend=False\n    )\n    \n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig, filename=col_name + '_stack_bar')","2a3348c9":"plot_cmp_stack(data=X_train_df, col_name=\"trafficSource.adwordsClickInfo.gclId\")","cf414d12":"plot_cmp_stack(data=X_train_df, col_name=\"trafficSource.isTrueDirect\")","7a346d54":"plot_cmp_stack(data=X_train_df, col_name=\"trafficSource.keyword\")","db9600d1":"plot_cmp_stack(data=X_train_df, col_name=\"trafficSource.referralPath\")","73dfaa26":"to_drop_cols = [\"trafficSource.adContent\", \"trafficSource.adwordsClickInfo.adNetworkType\", \n                \"trafficSource.adwordsClickInfo.gclId\", \"trafficSource.adwordsClickInfo.isVideoAd\",\n                \"trafficSource.adwordsClickInfo.page\", \"trafficSource.adwordsClickInfo.slot\"]\n\nX_all_df.drop(to_drop_cols, axis=1, inplace=True)\n\nX_all_df.loc[:, \"trafficSource.isTrueDirect\"] = X_all_df.loc[:, \"trafficSource.isTrueDirect\"].fillna(0).astype('bool')","b8b797d0":"ratio_nan(X_all_df)","4910e92f":"X_all_df.loc[X_all_df[\"fullVisitorId\"] == \"0824839726118485274\", \"visitNumber\"].sort_values().head(3)","c6233f87":"X_all_df.groupby(\"fullVisitorId\")[\"visitNumber\"].min().unique()","bdca232b":"X_all_df.loc[X_all_df[\"channelGrouping\"] == \"Direct\", \"trafficSource.isTrueDirect\"].value_counts()","c5b67a25":"X_all_df.loc[X_all_df[\"trafficSource.isTrueDirect\"] == 1, \"channelGrouping\"].value_counts()","b7f8fea1":"X_all_df.loc[X_all_df[\"trafficSource.isTrueDirect\"] == 0, \"channelGrouping\"].value_counts()","12db2273":"X_all_df.loc[X_all_df[\"trafficSource.isTrueDirect\"] == 1, \"trafficSource.medium\"].value_counts()","620a541f":"X_all_df.loc[X_all_df[\"trafficSource.isTrueDirect\"] == 0, \"trafficSource.medium\"].value_counts()","603c41e1":"temp_df = X_all_df.loc[X_all_df[\"trafficSource.isTrueDirect\"] == 1, :]","2d2073b5":"temp_df.loc[ temp_df[\"trafficSource.medium\"] == 'referral', 'channelGrouping'].value_counts()","a90dda6f":"X_all_df.loc[X_all_df[\"trafficSource.keyword\"].notnull(), \"channelGrouping\"].value_counts()","c08f382f":"X_all_df.loc[X_all_df[\"trafficSource.keyword\"].isnull(), \"channelGrouping\"].value_counts()","65a719a2":"temp_df = X_all_df.loc[X_all_df[\"trafficSource.keyword\"].isnull(), :]\ntemp_df.loc[(temp_df[\"channelGrouping\"] == \"Organic Search\") | (temp_df[\"channelGrouping\"] == \"Paid Search\"), \"trafficSource.medium\"].value_counts()","11c2be0d":"X_all_df.loc[temp_df.index, \"trafficSource.keyword\"] = \"(not provided)\"","1b29f60a":"X_all_df.loc[X_all_df[\"trafficSource.referralPath\"].isnull(), \"channelGrouping\"].value_counts()","a9edab8c":"temp_df = X_all_df.loc[X_all_df[\"trafficSource.referralPath\"].isnull(), :]","b64a2154":"X_all_df.loc[temp_df.loc[(temp_df[\"channelGrouping\"] == \"Referral\") | (temp_df[\"channelGrouping\"] == \"Social\")].index, \"trafficSource.referralPath\"] = X_all_df[\"trafficSource.referralPath\"].value_counts().index[0]","be2827d7":"X_all_df.loc[X_all_df[\"trafficSource.source\"] == \"(direct)\", \"channelGrouping\"].value_counts()","ff4b5745":"X_all_df.loc[X_all_df[\"trafficSource.source\"] == \"(direct)\", \"channelGrouping\"] = \"Direct\"","79654a21":"X_all_df[\"trafficSource.referralPath\"] = X_all_df[\"trafficSource.referralPath\"].cat.add_categories(['Not Referral'])\n\nX_all_df.loc[:, \"trafficSource.referralPath\"] = X_all_df.loc[:, \"trafficSource.referralPath\"].fillna('Not Referral')","d26f6200":"def percentage_counts(data, col_name):\n    total = data[col_name].count()\n    return data[col_name].value_counts()\/ total * 100","e427808c":"def keep_greater_than_percentage_entries(data, col_name, percentage=0.1, new_entry=\"Others\"):\n    percentage_counts_series = percentage_counts(temp_df, col_name)\n    entries_to_keep = percentage_counts_series[percentage_counts_series >= percentage].index\n    data[col_name] = data[col_name].cat.add_categories([new_entry])\n    data.loc[~data[col_name].isin(entries_to_keep), col_name] = new_entry\n    data[col_name] = data[col_name].cat.remove_unused_categories()","4a8294a1":"features_to_merge = [\n    'device.browser', 'geoNetwork.city', 'geoNetwork.country',\n    'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\n    'geoNetwork.subContinent', 'trafficSource.campaign', 'trafficSource.keyword',\n    'trafficSource.referralPath', 'trafficSource.source', 'device.operatingSystem'\n                    ]","9ad81fdf":"for feature in features_to_merge:\n    keep_greater_than_percentage_entries(data=X_all_df, col_name=feature)","1eb6a92a":"X_train_df = X_all_df.loc[X_all_df[\"totals.transactionRevenue_ln\"].notnull(), :].reset_index(drop=True)\nX_test_df = X_all_df.loc[X_all_df[\"totals.transactionRevenue_ln\"].isnull(), :].reset_index(drop=True)","15aa850f":"X_train_df.groupby(\"date\")[\"totals.transactionRevenue_ln\"].agg(['sum', 'count', 'mean']).plot(subplots=True, sharex=True, title=\"Revenue Base On Date\", linewidth=2)","ebcc37bf":"sub_boxenplots(x='channelGrouping', data=X_train_df)","d8bdd1e1":"sub_boxenplots(x='device.deviceCategory', data=X_train_df)","d854edac":"sub_boxenplots(x='device.isMobile', data=X_train_df)","e4ded3ea":"sub_boxenplots(x='geoNetwork.continent', data=X_train_df)","8cd7b0d7":"sub_boxenplots(x='totals.newVisits', data=X_train_df)","b9e09359":"sub_boxenplots(x='trafficSource.isTrueDirect', data=X_train_df)","7628c2a2":"sub_boxenplots(x='trafficSource.campaign', data=X_train_df, rot=20)","83aa4f82":"sub_boxenplots(x='trafficSource.medium', data=X_train_df)","c99b7b29":"sub_boxenplots(x='device.operatingSystem', data=X_train_df, rot=20)","6f2f10b8":"g = sns.jointplot('totals.hits', 'totals.transactionRevenue_ln', data=X_train_df[X_train_df['totals.transactionRevenue_ln'] > 0],\n                 kind='reg', height=10)","2cb6b929":"g = sns.jointplot('visitStartTime', 'totals.transactionRevenue_ln', data=X_train_df[X_train_df['totals.transactionRevenue_ln'] > 0],\n                 kind='reg', height=10)","121d57ad":"g = sns.jointplot('totals.pageviews', 'totals.transactionRevenue_ln', data=X_train_df[X_train_df['totals.transactionRevenue_ln'] > 0],\n                 kind='reg', height=10)","eac2f103":"cat_feature_list = ['channelGrouping', 'device.browser', 'device.deviceCategory', 'device.operatingSystem', \n                    'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country', 'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region', 'geoNetwork.subContinent',\n                    'trafficSource.campaign', 'trafficSource.isTrueDirect', 'trafficSource.keyword', 'trafficSource.medium', 'trafficSource.referralPath', 'trafficSource.source'\n                   ]\nbool_feature_list = ['device.isMobile', 'totals.newVisits']\nid_feature_list = ['fullVisitorId']\nnum_feature_list = ['visitNumber', 'totals.hits', 'totals.pageviews', 'visitStartTime']\ntime_feature_list = ['date']\nlabel_list = ['totals.transactionRevenue', 'totals.transactionRevenue_ln']","d7703ffb":"def check_features():\n    found = True\n    total_feature_list = id_feature_list + label_list + cat_feature_list + num_feature_list + bool_feature_list + time_feature_list\n    for feature in X_train_df.columns:\n        if feature not in total_feature_list:\n            found = False\n        assert found, \"You forgot \" + feature\n        total_feature_list.remove(feature)\n    if found:\n        if total_feature_list == []:\n            print(\"All the features are found!\")\n        else:\n            print(\"There are features left: \", total_feature_list)\ntry:\n    check_features()\nexcept AssertionError as e:\n    print(e)","fe9843eb":"X_all_df = X_all_df[id_feature_list + label_list + cat_feature_list + num_feature_list + bool_feature_list + time_feature_list]","89bc35dc":"from sklearn.preprocessing import LabelEncoder","31c46d19":"def cat_feature_encoding(data, cat_feature_list):\n    feature_encoder_dict = {}\n    with tqdm(cat_feature_list, desc=cat_feature_list[0]) as t:\n        for cat_feature in t:\n            if cat_feature == \"fullVisitorId\": # leave the ID as it is \n                continue\n            t.set_description_str(cat_feature)\n            my_label_encoder = LabelEncoder()\n            encoded_col = my_label_encoder.fit_transform(data[cat_feature])\n            data.loc[:, cat_feature] = encoded_col\n            feature_encoder_dict[cat_feature] = my_label_encoder\n    return feature_encoder_dict","417f8e8b":"X_train_df = X_all_df.loc[X_all_df[\"totals.transactionRevenue_ln\"].notnull(), :].reset_index(drop=True)\nX_test_df = X_all_df.loc[X_all_df[\"totals.transactionRevenue_ln\"].isnull(), :].reset_index(drop=True)","52f1d6b6":"train_df = X_train_df\ntest_df = X_test_df","f5b3784a":"def printShapes(name1, df1, name2, df2):\n    print(name1, df1.shape)\n    print(name2, df2.shape)\n    \ndef ratio_nan(data):\n    num_data = data.shape[0]\n    null_sum = data.isnull().sum()\n    null_val_features = null_sum[null_sum > 0]\n    print(null_val_features\/num_data)\n    \ndef compare_nan(name1, df1, name2, df2):\n    print(name1)\n    print(ratio_nan(df1))\n    print(\"\\n\" + name2)\n    print(ratio_nan(df2))\n    \nimport datetime as dt\ndef toPandasTimestamp(val):\n    lDate = dt.datetime.fromtimestamp(val)\n    lTimestamp = pd.Timestamp(lDate)\n    return lTimestamp\n    \ndef printTTShapes():\n    printShapes(\"Train Shape:\", train_df, \"Test Shape:\", test_df)","600ca98d":"train_df[\"visitStartTimestamp\"] = train_df[\"visitStartTime\"].apply(toPandasTimestamp)\ntest_df[\"visitStartTimestamp\"] = test_df[\"visitStartTime\"].apply(toPandasTimestamp)","8245e99e":"printTTShapes()","ec69b1b7":"compare_nan(\"Train\", train_df, \"Test\", test_df)","49bcf10f":"train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].apply(lambda x: 0.0 if np.isnan(x) else x) \ntest_df[\"totals.transactionRevenue\"] = test_df[\"totals.transactionRevenue\"].apply(lambda x: 0.0 if np.isnan(x) else x)","71a3a574":"columnsOfInterest = [\"fullVisitorId\", \"visitStartTime\", \"totals.hits\", \"totals.pageviews\", \"visitNumber\"]\ntrain_grouped = train_df[columnsOfInterest].groupby(\"fullVisitorId\")\ntest_grouped = test_df[columnsOfInterest].groupby(\"fullVisitorId\")","05b99a78":"train_ds = train_grouped[\"visitStartTime\"].max() - train_grouped[\"visitStartTime\"].min() # ds difference in seconds\ntest_ds = test_grouped[\"visitStartTime\"].max() - test_grouped[\"visitStartTime\"].min()\n\ntrain_sh = train_grouped[\"totals.hits\"].sum() # sh - summed hits\ntrain_spv = train_grouped[\"totals.pageviews\"].sum() # spv - summed page views\ntrain_lv = train_grouped[\"visitNumber\"].max() #lv - largestVisit number\ntest_sh = test_grouped[\"totals.hits\"].sum() # sh - summed hits\ntest_spv = test_grouped[\"totals.pageviews\"].sum() # spv - summed page views\ntest_lv = test_grouped[\"visitNumber\"].max() #lv - largestVisit number\n\ntrain_seconds_per_hit = train_ds \/ train_sh\ntrain_seconds_per_pageview = train_ds \/ train_spv \ntrain_seconds_per_visit = train_ds \/ train_lv\ntest_seconds_per_hit = test_ds \/ test_sh\ntest_seconds_per_pageview = test_ds \/ test_spv \ntest_seconds_per_visit = test_ds \/ test_lv\n\ntrain_nf = pd.concat([train_ds, train_seconds_per_hit, train_seconds_per_pageview, train_seconds_per_visit], \n                    axis = 1, join = \"outer\", \n                    join_axes = [train_ds.reset_index()[\"fullVisitorId\"]])\ntest_nf= pd.concat([test_ds, test_seconds_per_hit, test_seconds_per_pageview, test_seconds_per_visit], \n                    axis = 1, join = \"outer\", \n                    join_axes = [test_ds.reset_index()[\"fullVisitorId\"]])\n\ntrain_nf.reset_index(inplace = True)\ntrain_nf.columns = [\"fullVisitorId\", \"visitTimeRange\", \"secondsPerHit\", \"secondsPerPageview\", \"secondsPerVisit\"]\ntest_nf.reset_index(inplace = True)\ntest_nf.columns = [\"fullVisitorId\", \"visitTimeRange\", \"secondsPerHit\", \"secondsPerPageview\", \"secondsPerVisit\"]","d10bb6ab":"printShapes(\"Train New Features:\", train_nf, \"Test New Features:\", test_nf)","dd49e34c":"compare_nan(\"Train New Features\", train_nf, \"Test New Features\", test_nf)","0be99443":"train_nf = train_nf.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))\ntest_nf = test_nf.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))","3fe7e9f1":"compare_nan(\"Train New Features\", train_nf, \"Test New Features\", test_nf)","475dbad9":"train_nf.head()","f4df57a4":"test_nf.head()","a7c96dd3":"fm_columns = [\"fullVisitorId\", \"totals.pageviews\", \"totals.hits\", \"visitStartTimestamp\", \"geoNetwork.city\"]","e9b7484a":"ftrain_df = train_df[fm_columns].reset_index()\nftest_df = test_df[fm_columns].reset_index()","fd9a10cd":"ftrain_df.head()","ddca423c":"ftest_df.head()","e877a841":"import featuretools as ft\nfrom featuretools import variable_types as vtype\n\nmy_variable_types = {\n    \"fullVisitorId\" : vtype.Id,\n    \"geoNetwork.city\" : vtype.Categorical\n}","6b81633a":"train_es = ft.EntitySet(id = \"train_data\")\ntest_es = ft.EntitySet(id = \"test_data\")","d765b57f":"train_es.entity_from_dataframe(entity_id = \"train_log\",\n                               dataframe = ftrain_df,\n                               index = \"index\",\n                               time_index = \"visitStartTimestamp\",\n                               variable_types = my_variable_types)\n\ntest_es.entity_from_dataframe(entity_id = \"test_log\",\n                              dataframe = ftest_df,\n                              index = \"index\",\n                              time_index = \"visitStartTimestamp\",\n                              variable_types = my_variable_types)\n\nprint(train_es, test_es)","c3c5cc5b":"train_es.normalize_entity(base_entity_id = \"train_log\",\n                          new_entity_id = \"visitors\",\n                          index = \"fullVisitorId\")\n\ntest_es.normalize_entity(base_entity_id = \"test_log\",\n                         new_entity_id = \"visitors\",\n                         index = \"fullVisitorId\")\n\nprint(train_es, test_es)","c497aee5":"my_aggs = [\"sum\", \"max\", \"min\", \"mean\", \"std\", \"mode\"]\nmy_trans = [\"month\", \"day\"]\n\ntrain_features = ft.dfs(entityset = train_es,\n                        target_entity = \"visitors\",\n                        max_depth = 2,\n                        agg_primitives = my_aggs,\n                        trans_primitives = my_trans,\n                        verbose = 1,\n                        max_features = 100,\n                        n_jobs = 4,\n                        features_only = True)\n\ntest_features = ft.dfs(entityset = test_es,\n                        target_entity = \"visitors\",\n                        max_depth = 2,\n                        agg_primitives = my_aggs,\n                        trans_primitives = my_trans,\n                        verbose = 1,\n                        max_features = 100,\n                        n_jobs = 4,\n                        features_only = True)\n\nprint(\"We're generating %d features for train and %d for test\" % (len(train_features), len(test_features)))\nfor feat in train_features:\n    print(feat)","8cda4504":"train_feature_matrix, train_features = ft.dfs(entityset = train_es,\n                                              target_entity = \"visitors\",\n                                              max_depth = 2,\n                                              agg_primitives = my_aggs,\n                                              trans_primitives = my_trans,\n                                              verbose = 1,\n                                              max_features = 100,\n                                              n_jobs = 4)\n\ntest_feature_matrix, test_features = ft.dfs(entityset = test_es,\n                                            target_entity = \"visitors\",\n                                            max_depth = 2,\n                                            agg_primitives = my_aggs,\n                                            trans_primitives = my_trans,\n                                            verbose = 1,\n                                            max_features = 100,\n                                            n_jobs = 4)","4c3e85f4":"train_feature_matrix.head()","6e9cfda2":"test_feature_matrix.head()","fb50da9e":"printShapes(\"Train Feature Matrix:\", train_feature_matrix,\n            \"Test Feature Matrix\", test_feature_matrix)","505ad8e2":"compare_nan(\"Train FM\", train_feature_matrix,\n            \"Test FM\", test_feature_matrix)","03013ab0":"train_feature_matrix = train_feature_matrix.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))\ntest_feature_matrix = test_feature_matrix.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))","c3a5f143":"compare_nan(\"Train FM\", train_feature_matrix,\n            \"Test FM\", test_feature_matrix)","e30de7b9":"train_feature_matrix.reset_index(inplace = True)\ntest_feature_matrix.reset_index(inplace = True)","e302458a":"combined_train = train_nf.merge(train_feature_matrix, how = \"outer\", on = \"fullVisitorId\")\ncombined_test = test_nf.merge(test_feature_matrix, how = \"outer\", on = \"fullVisitorId\")","4f904478":"combined_train.head()","a9bd9941":"combined_test.head()","e7177078":"compare_nan(\"CTrain\", combined_train, \"CTest\", combined_test)","5cfdc69c":"train_rev = train_df[[\"fullVisitorId\", \"totals.transactionRevenue\"]].groupby(\"fullVisitorId\").sum().reset_index()\ntest_rev = test_df[[\"fullVisitorId\", \"totals.transactionRevenue\"]].groupby(\"fullVisitorId\").sum().reset_index()","f16c6abb":"combined_train_wrev = combined_train.merge(train_rev, how = \"outer\", on = \"fullVisitorId\")\ncombined_test_wrev = combined_test.merge(test_rev, how = \"outer\", on = \"fullVisitorId\")","00911ef8":"combined_train_wrev = combined_train_wrev.rename(columns = {\"totals.transactionRevenue\" : \"SUM(transactionRevenue)\"})\ncombined_test_wrev = combined_test_wrev.rename(columns = {\"totals.transactionRevenue\" : \"SUM(transactionRevenue)\"})","b6509333":"import lightgbm as lgb\nfrom sklearn.model_selection import KFold","a8a2cc00":"new_train_features_encoding_dict = cat_feature_encoding(data=combined_train_wrev, cat_feature_list=combined_train_wrev.select_dtypes(include='object').columns)","98f4df3c":"new_test_features_encoding_dict = cat_feature_encoding(data=combined_test_wrev, cat_feature_list=combined_test_wrev.select_dtypes(include='object').columns)","2ca345f2":"y = np.log1p(combined_train_wrev.iloc[:, -1])\n\nX = combined_train_wrev.iloc[:, 1:-1]\n\nX_pred = combined_test_wrev.iloc[:, 1:-1]","11c42870":"lgb_clf = lgb.LGBMRegressor(learning_rate=0.03, n_estimators=2000, min_child_weight=np.power(10.0, 2), metric='rmse', \n                             num_leaves=128, reg_alpha=np.power(10.0, -3.2454), reg_lambda = np.power(10.0, -4.8571), silent=True, n_jobs=-1,\n                             colsample_bytree =  0.6810, min_child_samples = 95,  subsample = 0.2217, min_split_gain=np.power(10.0, -4.9380))","277ca40e":"from sklearn.metrics import mean_squared_error\nkfold = 5\nkf = KFold(n_splits=kfold, shuffle=True)\n\npredicts_result = []\ntest_result = []\nfor train_index, test_index in kf.split(X, y):\n    print(\"#\"*10)\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    lgb_clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=400, verbose=200, eval_metric='rmse') #eval_metric=f1_macro_evaluation)\n#     test_result.append(f1_score(y_pred=lgb_clf.predict(X_val), y_true=y_val, average=\"macro\"))\n    y_val_pred = lgb_clf.predict(X_val)\n    # Modify the value that is below the zero\n    y_val_pred[y_val_pred<0] = 0\n    test_result.append(mean_squared_error(y_true=y_val, y_pred=y_val_pred))\n    y_pred = lgb_clf.predict(X_pred, lgb_clf.best_iteration_)\n    y_pred[y_pred<0] = 0\n    predicts_result.append(y_pred)","3531a32c":"print(\"The average test RMSE is: \", np.mean(np.sqrt(test_result)))","8bcd21dc":"def plot_features(col_list, feature_importances, index, most_important=True):\n    indices = np.argsort(feature_importances)[::-1]\n    indices = indices[:index]\n\n    # Visualise these with a barplot\n    plt.subplots(figsize=(20, 15))\n    g = sns.barplot(y=col_list[indices], x = lgb_clf.feature_importances_[indices], orient='h')\n    g.set_xlabel(\"Relative importance\",fontsize=20)\n    g.set_ylabel(\"Features\",fontsize=20)\n    g.tick_params(labelsize=15)\n    g.set_title(\"LightGBM feature importance\", fontsize=20);","8cb9c93f":"plot_features(col_list=X.columns, feature_importances=lgb_clf.feature_importances_, index=-1)","c7b01092":"no_bounce_pred_df = pd.DataFrame({\"fullVisitorId\": combined_test_wrev.fullVisitorId, \"PredictedLogRevenue\": np.mean(predicts_result, axis=0)})\n\nsubmit_df = pd.DataFrame({\"fullVisitorId\": submit_id})\n\nsubmit_df = submit_df.merge(no_bounce_pred_df, on=\"fullVisitorId\", how='left').fillna(0)\n\nsubmit_df.to_csv(\"submission.csv\", index=False)","d28e10ed":"submit_df[submit_df.PredictedLogRevenue != 0].hist()","b3e0946c":"labels = ['Zero revenue customer', 'Non-zero customer']\nvalues = [submit_df[submit_df.PredictedLogRevenue == 0].PredictedLogRevenue.count(),\n         submit_df[submit_df.PredictedLogRevenue != 0].PredictedLogRevenue.count()]\ntrace = go.Pie(labels=labels, values=values)\nlayout = dict(\n    title = 'Unique Customer Revenue Prediction'\n)\n\nfig = dict(data=[trace], layout=layout)\niplot(fig, filename='basic_pie_chart')","c288662a":"Session ID is for internet session only, we don't need it. And the `visitId` we don't need it since the `fullVisitorId` has the information","b05fd856":"Assume `channelGrouping` is` Direct`, its `trafficSource.isTrueDirect` should be **1**","7a666534":"The assumption has been proven that if an instance bounces away, there is no way that he or she can go to the checkout page to pay the money. This is an excellent feature that can help us quickly **shrink** the size of our data. We will drop all the rows with the true bounce and confidentially infer 0 revenue to the testing set with true bounce.","2e9a2c8a":"## Feature Encoding\n---\nString feature is not usable for machine learning algorithm. We need to encode them to either numeric featuers or one-hot encoding features. This deponds on the machine learning algorithm you choose. Before we start, we need to find out the category of the features. Unfortinately, it has to be done by hand pick.","00cd6ab8":"This information might be redundant to the previous one `device.deviceCategory`. Drop this feature if the feature importance is  not high.","04521930":"Let's do opposite","939ad081":"## Investigation in Data Integrity\n---\nNot all the datasets are 100% accurate. Sometimes, the inaccurate value will hurt the models by giving misleading information. As a human, a programmer will have his\/her bias about datasets as well. As a result, we need to check the integrity of the datasets before the machine learning taking place.","f08e04bc":"Thanks to this awesome [kernel](https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-baseline-ga-customer-revenue) that save the trouble for us to load the data in proper type.","a27c58c6":"Then let's take a look at the unique user revenues.","fbe8bbfb":">A bounce occurs when a web site visitor only views a single page on a website, that is, the visitor leaves a site without visiting any other pages before a specified session-timeout occurs.\n\nFrom here we can infer that the instance who bounce away will never generate any revenue. Let's explore it.","73833bb2":"### Fill The NaN Values\n`NaN` values are a familiar enemy for all data scientists. Before we drop or fill them up, we need to investigate the features with `NaN` values.","4ddd40a7":"Even we filter all the zeros, the data set is still extremely **unbalanced,** we should be careful with the outliers.","10782570":"### Merge the Category With Small Instance\nThere are features that have a category that with only one or two instances. It will be helpful for both data analysis and prediction to merge them all into a big category. This is proven later by us that it won't affect the final prediction accuracy at all, so we will do the merge because it will help with data visualisation.","f50b1d65":"In an attempt to make things quicker we have also narrowed down the aggregation and transformation functions to be applied. In the output, you can see the features that will be generated.","ef9655e0":"It is useful to create a category that is a pandas timestamp for feature tools library to use. Here we do that.","385770d1":"## Analysis Base On Date","f4674543":"Google traffic source ads contents are highly missing.\n<table>\n    <tbody>\n         <tr>\n          <td><code>trafficSource.adContent<\/code><\/td>\n          <td>STRING<\/td>\n          <td>The ad content of the traffic source. Can be set by the utm_content URL parameter.<\/td>\n        <\/tr>\n        <tr>\n          <td><code>trafficSource.<br>\n          adwordsClickInfo.adNetworkType<\/code><\/td>\n          <td>STRING<\/td>\n          <td>Network Type. Takes one of the following values: {\u201cGoogle Search\", \"Content\", \"Search partners\", \"Ad Exchange\", \"Yahoo Japan Search\", \"Yahoo Japan AFS\", \u201cunknown\u201d}<\/td>\n        <\/tr>\n        <tr>\n              <td><code>trafficSource.<br>\n              adwordsClickInfo.gclId<\/code><\/td>\n              <td>STRING<\/td>\n              <td>The Google Click ID.<\/td>\n            <\/tr>\n            <tr>\n              <td><code>trafficSource.<br>\n              adwordsClickInfo.isVideoAd<\/code><\/td>\n              <td>BOOLEAN<\/td>\n              <td>True if it is a Trueview video ad.<\/td>\n            <\/tr>\n            <tr>\n              <td><code>trafficSource.<br>\n              adwordsClickInfo.page<\/code><\/td>\n              <td>INTEGER<\/td>\n              <td>Page number in search results where the ad was shown.<\/td>\n            <\/tr>\n            <tr>\n              <td><code>trafficSource.<br>\n              adwordsClickInfo.slot<\/code><\/td>\n              <td>STRING<\/td>\n              <td>Position of the Ad. Takes one of the following values:{\u201cRHS\", \"Top\"}<\/td>\n            <\/tr>\n            <tr>\n              <td><code>trafficSource.isTrueDirect<\/code><\/td>\n              <td>BOOLEAN<\/td>\n              <td>True if the source of the session was Direct (meaning the user typed the name of your website URL into the browser or came to your site via a bookmark), This field will also be true if 2 successive but distinct sessions have exactly the same campaign details. Otherwise NULL.<\/td>\n            <\/tr>\n            <tr>\n              <td><code>trafficSource.keyword<\/code><\/td>\n              <td>STRING<\/td>\n              <td>The keyword of the traffic source, usually set when the trafficSource.medium is \"organic\" or \"cpc\". Can be set by the utm_term URL parameter.<\/td>\n            <\/tr>\n            <tr>\n              <td><code>trafficSource.referralPath<\/code><\/td>\n              <td>STRING<\/td>\n              <td>If trafficSource.medium is \"referral\", then this is set to the path of the referrer. (The host name of the referrer is in trafficSource.source.)<\/td>\n            <\/tr>\n    <\/tbody>\n<\/table>","844bb0ac":"Take a look what our prediction looks like.","4ea0bdc3":"Here is where the actual functions are used and applied. This part takes around 5 minutes.","d59b97ae":"Merge the prediction with the bounce instance we filter.","6d521c15":"This parameters comes from this [kernel](http:\/\/https:\/\/www.kaggle.com\/ogrellier\/user-level-lightgbm-lb-1-4480\/code). As we don't want to tune the parameters to control the experiment variables.","d3a1ac51":"Conclusion: `trafficSource.isTrueDirect` have a lot wrong values and `trafficSource.medium` is highly redundant to `channelGrouping`.","601a0abe":"There are `Organic Search` **6026** and `Paid Search` **147**  which should have a keyword with it. Let's see if they are mislabeled.","57e7fa1c":"Let's exmine the content in the differece feature `trafficSource.campaignCode`","61bbc3da":"Above two binary features are quite important and intuitive as well. An old user is more likely to make a purchase than a new user. Those who visit website directly are more objective than the other means.","0c9a920a":"Ensure that we get rid of all NaNs","fa5afb12":"**Note that the visit number of an  instance is not neccessarily start from 1**","29ee2113":"From the plot we can infer that the instances who comes from `referral` website has the highest ritio of non-zero revenue, while the instances come from `Display` channel have the highest median non-zero revenue.","b88dc9aa":"# LightGBM\n---","6185bd5a":"Investigate more with the unique minium number of instances","3f37561e":"Now we can fill up the `NaN` value with some category","58c1a0b3":"> The 80\/20 rule has proven true for many businesses\u2013only a small percentage of customers produce most of the revenue.\n\nLet's take a look at the ratio of zero and non-zero revenue instances.","55e945a9":"This is where we pull an entity from the original (train\/test_log) and make a new entity. Note: Relationships is no longer empty in the output. ","ddea69c3":"It seems that we can drop this column in training set since it doesn't provide any sensible information.\n\nAnd next, we will concatenate the training set and testing set together, just for saving the redundant process that we need to perform on both datasets.","04e42068":"## Merging Data","d64af3a5":"# Feature Engineering \n**What is going to be achieved in this section:**\n\n* Create custom features\n* Utilize the  [featuretools library](https:\/\/www.featuretools.com\/) to create useful features\n* Merge them together ","5788707a":"Functions that we will use, but hide in the beginning to increase the readability.","3e3e92ee":"There are two rows mislabeled, change them back to right values.","d735a054":"Americas are still the main market for the GA store but among the group who spends the money that `Africa` has the most dense non-zero nature log revenue within the range of 18-22.","f124187d":"Check if any features are missing.","58f4a897":"Let's take a look at the revenues which are corresponding to the bounce feature.","04313aaa":"Let's check what is the difference between the testing set and training set in features","887ddbf0":"Above three features have a significant share in the instances who contribute revenue. Especially `trafficSource.referralPath`,  almost half of the revenue instances, their `trafficSource.refferalPath` is set.","1dd0871c":"**Observation:** Above are the most three important features that _LightGBM_ thinks that are important. `pageviews` and `hits` make sense while `visitStartTime` seems a big mistake. Like Teo mentioned during our presentation that, a single algorithm will have its bias.","3d2692d9":"We can tell that the people who choose `Chrome OS` will contribute slightly more than other operating system. ","381cc012":"People who use the desktop are still the main income source of GA store.","9b031eec":"## Custom Feature Engineering\n\nIn trying to engineer some new features, I came up with these ideas:\n\n1. Difference in time between min and max visitStartTimes\n2. Number of seconds between hits (a lot will just be zero)\n3. Number of seconds between visits\n4. Number of seconds between pageviews\n\nThe following section will focus on creating these features.","6b53c55d":"It seems the most of it are right, let's see the opposite","71975b41":"# Data Preprocessing\n---\nThanks for the [SRK](https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-baseline-ga-customer-revenue)'s kernel pointed out that there are constant value columns which are invalid in this competiton. Drop them before further processing","2f106f1c":"> A pageview (or pageview hit, page tracking hit) is an instance of a page being loaded (or reloaded) in a browser. Pageviews is a metric defined as the total number of pages viewed.","58c91819":"The customer that will generate revenue is the objective of this project. However, since then we can infer that a pre-classified the customer who will not make any revenues will help the later regression task.\n\nLet's take a look at the boxplot of the customers that will generate revenues.","bdc1ba12":"# EDA\n---\n## Target Visualisation\n\n**We are predicting the **natural log**  of the sum of all transactions **per user**. For every user in the test set, the target is:\n$$\ny_{user} = \\sum_{i=1}^{n}{transaction_{user_i}}\n$$\n$$\ntarget_{user} = \\ln(y_{user} + 1)\n$$\nGive a look at the target distribution will give us a big picture of what we are predicting. Before we proceed, we will generate the new target as the competition requested.","abfd3752":"Looks like there are wrong values. Let's see if `trafficSource.isTrueDirect` is false.","27e4afe8":"The data set needs to be pre-preocessed before it can be used.","777d1895":"From the description, we can infer that `NULL` values represent that the user doesn't click the ads?  Let's investigate if the rest features with `NaN` values will affect the revenues they generated.","01f21b29":"Well, 80\/20 seems too optimistic. Let's merge all the instances to unique customers, see if things get any better.","f18c89b9":"Here we clean up the data we have generated.","610c44b6":"If we check the value in the `trafficSource.keyword` there is a value called **(not provided)** above should be set to it","9a43fa60":"Rearrange the features by column categories.","c50fdd6a":"## Feature Tools\n\nHere we utilize the feature tools library to generate some features we know are good. Previously, we have trained on all columns with all entries. However, that takes over two hours to run. So, once we did that and found the best features, we have tried to narrow it down to reduce run time and make our lives easier. ","878b3345":"Split the dataset into training dataset for later analysis","a42db8e5":"We will skip some sample features that we will correct them silently.","f17985c7":"### Cast The Datatype To The Right One\nWe want to make sure all the datatype is the right one and we want to change all the string object type to the **category** type as python has a horrible run-time to deal with string. However, we will keep the ID as the string since the **category**  will only help if there are categories.","fc154800":"# Google Analytics Customer Revenue Prediction\n---\n\nStan Wang (16446054), Dale Euinton (14026002), and Hang Zhao (18045261)\n\n## Abstract\nWe present a kernel with an iterative workflow to participate a Kaggle competition. We first do exploratory data analysis on raw data to get a big picture of data set. Then we make the first prediction with **LightGBM** as the baseline of this competition. The **LightGBM** will generate the _feature importance_ at meanwhile. After that, we will enter the second round of EDA and feature engineering base on the feature importance. After address the more important feature we fit it to the **LightGBM** again. This project evaluates the performance of this work-flow and hopes it can contribute some knowledge to the community especially to those who participate in Kaggle competition the first time.","a729c5f3":"From the bar plot above, our previous infers failed. In the left pie chart we can tell that this even the user click the ads, it still occupies a small portion of who make revenues.","8a33dc9e":"## Features Analysis\n---\nAfter all efforts in preprocessing, we can now look into the features we will deal with. As this is a iterative developing workflow, we will go through some features at first time and focus on the top three most important features.","05081122":"There 14 rows that dosen't have a path, let's assign them with the most common path.","d8d59918":"# Conclusion\nIn this kernel we have tried three different iterations. \n\n1. Naive - Score : 1.7340\n2. Feature Engineering - Score : 1.5665\n3. Reduced Feature Engineering (for runtime) with custom features added - Score :  1.5372\n\nClearly, 1.5665 was the best iteration. \n\nThis kernel has highlighted the usefulness of Plotly, Featuretools, lightGBM. We would use these all again. ","3e0f1d1b":"The average test RMSE will much higher than our actual prediction is because we filter up all the bouce instance to reduce the work during the feature engineering.","4e259f92":"Lastly, change all the boolean features to right type","e9162654":"Here is the description from **Google**\n<table>\n  <tbody>\n    <tr>\n      <td><code>trafficSource.isTrueDirect<\/code><\/td>\n      <td>BOOLEAN<\/td>\n      <td>True if the source of the session was Direct (meaning the user typed the name of your website URL into the browser or came to your site via a bookmark), This field will also be true if 2 successive but distinct sessions have exactly the same campaign details. Otherwise NULL.<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>","01ccda88":"From the data revenue plots we can tell that, from the middle of November till near the Christmas, there is a surge both in visit counts and sum up revenue. The visit counts drop significantly after the Christmas.","03cda13d":"## Traffic Source Analysis","c6b1127d":"**cost per click (CPC)** is an internet advertising model used to direct traffic to websites, in which an advertiser pays a publisher (typically a website owner or a network of websites) when the ad is clicked.\n\n**Cost-per-thousand impressions (CPM)**: A way to bid where you pay per one thousand views (impressions) on the Google Display Network.\n\n---\nHere we can see there are couple of problems:\n\n* referral doesn't match.\n* (none) value in the trafficSource.medium actually mean direct.\n* trafficSource.isTrueDirect seems have wrong values.\n","4d525182":"## Feature Explore On Import Features\nThe features we explore below will be the features that _LightGBM_ thinks it is important. Let's find out are they make sense to us.","e364174b":"Now split the X_all_df to training and testing dataset again.","3c11c544":"### EntitySets\nFeaturetools uses EntitySets to represent dataframes and the relationships between them. Here we create an entity set from our whole dataframe and then pull another dataframe out from that (using fullVisitorId). This is very powerful and later allows us to automatically use grouped information. ","9cb89c91":"Assume, when keyword is `NULL` means that instance is not using searching engine."}}