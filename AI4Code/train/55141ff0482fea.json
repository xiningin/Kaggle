{"cell_type":{"8e9b8c5a":"code","0f71fa5f":"code","9241c801":"code","7c40c684":"code","4967cb03":"code","ddbd85e6":"code","6056015c":"code","eeb1c58f":"code","fadd86c5":"markdown","87d99af8":"markdown","ec8ca5ab":"markdown","b82c50f1":"markdown","f9c39480":"markdown","4b744b46":"markdown","15576a79":"markdown"},"source":{"8e9b8c5a":"import numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","0f71fa5f":"train_dir = '..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/train'\ntest_dir = '..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/test'","9241c801":"sample_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=90,\n    height_shift_range=0.2,\n    width_shift_range=0.2\n)\n\nsample_images = sample_generator.flow_from_directory(\n    train_dir,\n    target_size=(300, 300),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=1,\n    shuffle=True,\n    seed=42\n)","7c40c684":"plt.figure(figsize=(10, 10))\n\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = sample_images.next()[0]\n    plt.imshow(img)\n    plt.axis('off')\n\nplt.show()","4967cb03":"train_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=90,\n    height_shift_range=0.2,\n    width_shift_range=0.2,\n    zoom_range=0.2\n)\n\ntest_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.7\n)","ddbd85e6":"train_images = train_generator.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42\n)\n\nval_images = test_generator.flow_from_directory(\n    test_dir,\n    target_size=(150, 150),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\n\ntest_images = test_generator.flow_from_directory(\n    test_dir,\n    target_size=(150, 150),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False,\n    seed=42,\n    subset='validation'\n)","6056015c":"inputs = tf.keras.Input(shape=(150, 150, 3))\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dropout(0.4)(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\noutputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","eeb1c58f":"acc = model.evaluate(test_images, verbose=0)[1]\nprint(\"Accuracy: {:.2f}%\".format(acc * 100))\n\npredictions = np.argmax(model.predict(test_images), axis=1)\n\ncm = confusion_matrix(test_images.labels, predictions, labels=[0, 1, 2])\nclr = classification_report(test_images.labels, predictions, labels=[0, 1, 2], target_names=[\"Paper\", \"Rock\", \"Scissors\"])\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=[0.5, 1.5, 2.5], labels=[\"Paper\", \"Rock\", \"Scissors\"])\nplt.yticks(ticks=[0.5, 1.5, 2.5], labels=[\"Paper\", \"Rock\", \"Scissors\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","fadd86c5":"# Training","87d99af8":"# Getting Started","ec8ca5ab":"# Results","b82c50f1":"# Visualizing Image Augmentation","f9c39480":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/BlEarwustEQ","4b744b46":"# Task for Today  \n\n***\n\n## Rock Paper Scissors Image Recognition  \n  \nGiven *images of hands making rock, paper, and scissors gestures*, let's try to classify the **gesture** in a given image.  \n  \nWe will use a TensorFlow\/Keras convolutional neural network to make our predictions.","15576a79":"# Creating Generators"}}