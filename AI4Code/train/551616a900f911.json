{"cell_type":{"6e5708e9":"code","a42d1143":"code","4b65c306":"code","bc5c3098":"code","d778664f":"code","db58a4fb":"code","4073c737":"code","60cf6b5e":"code","b94fbc29":"code","2c454036":"code","9be26506":"code","91d292e9":"code","6003834f":"code","eda3c2c5":"code","f565ddac":"code","72ac2987":"code","6541e0bc":"code","59db84aa":"code","ac5343e6":"code","31b7ba98":"code","6b527d9f":"code","5b16da94":"code","8a5e6e15":"code","4e646391":"code","84fa8a03":"markdown"},"source":{"6e5708e9":"import numpy as np\nimport pandas as pd\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\nfrom keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf\nimport cv2\nimport glob\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.python.keras import backend as K\nimport plotly.graph_objects as go\nimport plotly.offline as py\nautosize =False\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n%matplotlib inline","a42d1143":"import pandas as pd","4b65c306":"train_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'\ntest=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv')\n","bc5c3098":"x1 = \"96\"\nx2 = \"96\"\nx_train_dim = \"x_train_\" + x1\nx_test_dim = \"x_test_\" + x1","d778664f":"x_train = np.load('..\/input\/siimisic-melanoma-resized-images\/' + x_train_dim + \".npy\")\nx_train.shape","db58a4fb":"y = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv').target\n","4073c737":"from sklearn.utils import class_weight\n \nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y),\n                                                 y)","60cf6b5e":"class_weights = dict(enumerate(class_weights))","b94fbc29":"from sklearn.model_selection import train_test_split\n\ntrain_imgs, validation_imgs, y_train, y_val = train_test_split(x_train,y, test_size=0.2, random_state=1234)","2c454036":"import gc\ndel x_train\ngc.collect()","9be26506":"# define parameters for model training\nbatch_size = 128\nnum_classes = 2\nepochs = 50\ninput_shape = (96,96,3)","91d292e9":"# we will use Adam optimizer\nopt = Adam(lr=1e-5)\n\nnb_train_steps = train_imgs.shape[0]\/\/batch_size\nnb_val_steps=validation_imgs.shape[0]\/\/batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","6003834f":"# Pixel Normalization and Image Augmentation\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')\n\n# no need to create augmentation images for validation data, only rescaling the pixels\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow(train_imgs, y_train, batch_size=32)\nval_generator = val_datagen.flow(validation_imgs, y_val, batch_size=32)","eda3c2c5":"del train_imgs,validation_imgs\ngc.collect()","f565ddac":"from keras.applications import vgg16\nfrom keras.models import Model\nimport keras\n\nvgg = vgg16.VGG16(include_top=False, weights='imagenet', \n                                     input_shape=input_shape)\n\noutput = vgg.layers[-1].output\noutput = keras.layers.Flatten()(output)\nvgg_model = Model(vgg.input, output)\n\nvgg_model.trainable = False\nfor layer in vgg_model.layers:\n    layer.trainable = False\n    \nimport pandas as pd\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    ","72ac2987":"vgg_model.trainable = True\n\nset_trainable = False\nfor layer in vgg_model.layers:\n    if layer.name in ['block5_conv1', 'block4_conv1']:\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n        \nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    ","6541e0bc":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\nfrom keras.models import Sequential\nfrom keras import optimizers\n\nmodel = Sequential()\nmodel.add(vgg_model)\nmodel.add(Dense(512, activation='relu', input_dim=input_shape))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()],optimizer=opt)","59db84aa":"model.fit_generator(train_generator, steps_per_epoch=nb_train_steps, epochs=epochs,\n                              validation_data=val_generator, validation_steps=nb_val_steps,class_weight=class_weights, \n                              verbose=1)","ac5343e6":"del train_generator,val_generator\ngc.collect()","31b7ba98":"x_test = np.load(\"..\/input\/siimisic-melanoma-resized-images\/\" + x_test_dim + \".npy\")","6b527d9f":"from numpy import expand_dims\ndef tta_prediction(datagen, model, image, n_examples):\n    # convert image into dataset\n    samples = expand_dims(image, 0)\n    # prepare iterator\n    it = datagen.flow(samples, batch_size=n_examples)\n    # make predictions for each augmented image\n    probs = model.predict_generator(it, steps=n_examples, verbose=0)\n    #print(len(probs))    \n    prob = np.mean(probs, axis=1)    \n    return prob","5b16da94":"from tqdm import tqdm\n# configure image data augmentation\ntest_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')\ntarget=[]\n#i = 0\nfor img in tqdm(x_test):\n    prediction=tta_prediction(test_datagen,model,img,32)    \n    target.append(prediction[0])","8a5e6e15":"# submission file\nsub=pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/sample_submission.csv\")\nsub['target']=target\nsub.to_csv('submission.csv', index=False)\nsub.head()","4e646391":"for i in tqdm(range(int(9e6))): \n    pass","84fa8a03":"# Modelling - VGG16 (Transfer Learning)"}}