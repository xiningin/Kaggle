{"cell_type":{"a9ab25e3":"code","aa8c8109":"code","2ff91623":"code","60a4acee":"code","a0962cf0":"code","04a59d83":"code","f0be2148":"code","1a57c388":"code","01de4ac5":"code","25518fb0":"code","01b9abc6":"code","2c1b4d49":"code","fb4df130":"code","eed521b3":"code","359a2857":"code","95e65103":"code","df4d931e":"code","46e2f97d":"code","f4c8732b":"code","929863b3":"code","2b39d22a":"code","9b649c09":"code","5c64ff42":"code","5197cf29":"code","701b9a5c":"code","cb768742":"code","b06417e7":"code","f181eaef":"code","a616044c":"code","3bae5b81":"code","4440eb23":"code","f084e180":"code","97e05443":"code","023f0195":"code","3940408c":"code","7f3fc9c0":"code","3ac587eb":"code","36da8ba5":"markdown","305c969c":"markdown","20fff58a":"markdown","5c007d90":"markdown","0a5fe281":"markdown","710c1d17":"markdown","5fc3e4a5":"markdown","4a266ad3":"markdown","756342e8":"markdown","9b8e1633":"markdown","779f7f79":"markdown","3c0cd3b6":"markdown","950a9ec1":"markdown","f010afe6":"markdown","eab54fc9":"markdown","2aaaa4d5":"markdown","ce66a42d":"markdown","0b4e9574":"markdown","503128a3":"markdown","6be4abe1":"markdown","59e14347":"markdown","65366fb1":"markdown","0bfb63a5":"markdown","75f115d3":"markdown","07c67687":"markdown","27903eb3":"markdown","c547cf66":"markdown","37ed3b05":"markdown","cc9e47c0":"markdown","d28a7535":"markdown","9fcb9e9b":"markdown","d48d9dbc":"markdown","bb70cd23":"markdown","accd438d":"markdown"},"source":{"a9ab25e3":"# Data Manipulation, Linear Algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nfrom sklearn.cluster import KMeans\n\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore')","aa8c8109":"data = pd.read_csv(\"..\/input\/autompg-dataset\/auto-mpg.csv\")\ndata.head()","2ff91623":"data.info()","60a4acee":"data[['horsepower']] = data[['horsepower']].replace(\"?\", np.nan)","a0962cf0":"data.isnull().sum()","04a59d83":"data.horsepower = pd.to_numeric(data.horsepower)\ndata[['horsepower']] = data[['horsepower']].replace(np.nan, data.horsepower.median())","f0be2148":"data.describe()","1a57c388":"data[\"model year\"].value_counts().sort_values(ascending=False)","01de4ac5":"fig, axes = plt.subplots(figsize=(15, 5), nrows=1, ncols=2, dpi=100)\n\nsns.countplot(x=\"cylinders\", data=data, ax=axes[0])\naxes[0].set_title(\"Cars Count with Different Number of Cylinders\")\naxes[0].set_ylabel(\"Cars Count\")\naxes[0].set_xlabel(\"Number of Cylinders\")\n\nsns.countplot(x=\"origin\", data=data, ax=axes[1])\naxes[1].set_title(\"Cars Count with Different Origin\")\naxes[1].set_ylabel(\"Cars Count\")\naxes[1].set_xlabel(\"Origin\")\n\nplt.show()","25518fb0":"fig, axes = plt.subplots(figsize=(18, 6), nrows=1, ncols=3, dpi=90)\n\nsns.boxplot(x=\"cylinders\", y=\"mpg\", data=data, ax=axes[0])\naxes[0].set_title(\"Cylinders vs Miles per Gallon\")\n\nsns.boxplot(x=\"cylinders\", y=\"acceleration\", data=data, ax=axes[1])\naxes[1].set_title(\"Cylinders vs Acceleration\")\n\nsns.boxplot(x=\"cylinders\", y=\"horsepower\", data=data, ax=axes[2])\naxes[2].set_title(\"Cylinders vs horsepower\")\n\nplt.show()","01b9abc6":"fig, axes = plt.subplots(figsize=(18, 6), nrows=1, ncols=3, dpi=90)\n\nsns.scatterplot(x=\"weight\", y=\"mpg\", data=data, hue=\"cylinders\", ax=axes[0])\naxes[0].set_title(\"Weight vs Miles per Gallon\")\n\nsns.scatterplot(x=\"weight\", y=\"acceleration\", data=data, hue=\"cylinders\", ax=axes[1])\naxes[1].set_title(\"Weight vs Acceleration\")\n\nsns.scatterplot(x=\"weight\", y=\"horsepower\", data=data, hue=\"cylinders\", ax=axes[2])\naxes[2].set_title(\"Weight vs Horsepower\")\n\nplt.show()","2c1b4d49":"plt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.figsize\"] = (10, 8)\ndata[[\"mpg\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"]].hist()\nplt.show()","fb4df130":"sns.pairplot(data)\nplt.show()","eed521b3":"plt.rcParams[\"figure.figsize\"] = (8, 6)\nsns.heatmap(data.corr(), annot=True)\nplt.show()","359a2857":"car_company = []\nfor car_name in data[\"car name\"]:\n    car_name = car_name.split(\" \")\n    car_company.append(car_name[0])","95e65103":"data[\"car company\"] = car_company\ndata.drop(\"car name\", inplace=True, axis=1)\ndata.head()","df4d931e":"le = LabelEncoder()\ndata[\"car company\"] = le.fit_transform(data[\"car company\"])\ndata.head()","46e2f97d":"sc = StandardScaler()\nscaled_data = sc.fit_transform(data.copy())","f4c8732b":"# Reducing the Number of Features in the Dataset using PCA\npca = PCA(2)\npca_data = pca.fit_transform(scaled_data)","929863b3":"plt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams[\"figure.dpi\"] = 80\nplt.scatter(x=pca_data[:,0], y=pca_data[:,1], lw=2)\nplt.xlabel(\"Principle Component 1\")\nplt.ylabel(\"Principle Component 2\")\nplt.title(\"Principle Components Analysis\")\nplt.show()","2b39d22a":"wcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(\n        n_clusters = i,\n        init = 'k-means++',\n        random_state=42\n    )\n    kmeans.fit(data)\n    wcss.append([i, kmeans.inertia_]) # kmeans.inertial_ returns the calculated WCSS Values\n    \nwcss_dataframe = pd.DataFrame(wcss, columns=[\"clusters\", \"wcss value\"])\n\n# Plot for Elbow Method\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams[\"figure.dpi\"] = 80\nsns.lineplot(\n    x = wcss_dataframe.clusters.values,\n    y = wcss_dataframe[\"wcss value\"], marker=\"o\")\nplt.xticks(np.arange(1, 11))\nplt.xlabel(\"Clusters\")\nplt.ylabel(\"Wcss Values\")\nplt.title(\"Elbow Method Plot\")\nplt.show()","9b649c09":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ny_kmeans = pd.Series(kmeans.fit_predict(scaled_data))\ny_kmeans","5c64ff42":"y_kmeans.value_counts()","5197cf29":"centroids = kmeans.cluster_centers_\ncentroids_pca = pca.transform(centroids)","701b9a5c":"pca_dataframe = pd.DataFrame(pca_data, columns=[\"PCA 1\", \"PCA 2\"])\npca_dataframe[\"Cluster\"] = y_kmeans\npca_dataframe.sample(10)","cb768742":"plt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams[\"figure.dpi\"] = 80\nsns.scatterplot(x=\"PCA 1\", y=\"PCA 2\", hue=\"Cluster\", data=pca_dataframe, palette=['green','orange','brown'], s=100)\nplt.scatter(x=centroids_pca[:, 0], y=centroids_pca[:, 1], marker=\"+\", s=500, linewidths=3, lw=4, color=\"blue\", zorder=10)\nplt.title(\"Visualizing Clusters\")\nplt.show()","b06417e7":"data[\"Cluster\"] = y_kmeans\ndata.head()","f181eaef":"sns.pairplot(data, hue=\"Cluster\", palette=['green','orange','brown'])\nplt.show()","a616044c":"X = data.drop(\"Cluster\", axis=1).values\ny = data.Cluster","3bae5b81":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","4440eb23":"scalar = StandardScaler()\n\nX_train_scaled = scalar.fit_transform(X_train)\nX_test_scaled = scalar.transform(X_test)","f084e180":"MLA_compare = pd.DataFrame()\n\ndef MLA_testing(MLA, X_train, X_test):\n    row_index = 0\n    for classifier in MLA:\n        classifier.fit(X_train, y_train)\n\n        y_pred = classifier.predict(X_test)\n        classifier_accuracy_score = accuracy_score(y_test, y_pred)\n\n        kfold_accuracy = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n\n        MLA_name = classifier.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'Accuracy Score'] = classifier_accuracy_score*100\n        MLA_compare.loc[row_index, 'K-Fold Accuracy'] = kfold_accuracy.mean()*100\n\n        print(MLA_name, \"Done\")\n        row_index+=1","97e05443":"MLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False),\n    CatBoostClassifier(silent=True)  \n    ]\n\nMLA_testing(MLA=MLA, X_train=X_train, X_test=X_test)","023f0195":"# Scaled Data Used Here\nMLA = [    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    \n    #SVM\n    svm.LinearSVC(max_iter=10000), \n]\nMLA_testing(MLA=MLA, X_test=X_test_scaled, X_train=X_train_scaled)","3940408c":"MLA_compare = MLA_compare.sort_values(by=\"Accuracy Score\", ascending=False).reset_index(drop=True)[:10]\nMLA_compare","7f3fc9c0":"classifier = linear_model.LogisticRegressionCV()\nclassifier.fit(X_train_scaled, y_train)\n\ny_pred = classifier.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred)\n\ncm = confusion_matrix(y_test, y_pred)","3ac587eb":"print(\"Test Accuracy : \", accuracy*100, \"%\", \"\\n\")\n\nprint(\"Confusion Matrix \\n\", cm, \"\\n\")\n\nplt.rcParams[\"figure.figsize\"] = (6, 5)\nplt.rcParams[\"figure.dpi\"] = (100)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='2.0f')\nplt.show()","36da8ba5":"## Effect of Weight Count on Mileage, Acceleration, Displacement","305c969c":"## Encoding Categorical Variable - Car Company","20fff58a":"# Classification","5c007d90":"#### We have maximum cars from 1973 followed by 1978, 1976, and so on.","0a5fe281":"#### Cars with 4 Cylinders have highest mileage\n#### Cars with 5 Cylinders have highest acceleration\n#### 8 Cylinder cars have higher Horsepower","710c1d17":"## Centeroids","5fc3e4a5":"# Importing Necessaary Libraries","4a266ad3":"## Splitting Data into Training and Testing Set","756342e8":"## Using Elbow Method to Find Appropriate number of clusters","9b8e1633":"## Count of Cars of Each Year","779f7f79":"## Loading Dataset","3c0cd3b6":"# Analysis and EDA","950a9ec1":"## Count Plot for Number of Cylinders and Different Origins","f010afe6":"## Generating Our Clusters using Kmeans","eab54fc9":"#### Higher Weight has Lower Mileage\n#### Higher Weight has Slower Acceleration\n#### Heavier Cars have Higher Horsepower","2aaaa4d5":"#### LogisticRegressionCV Performed the Best with 100% Accuracy and 98.4% CrossVal-Accuracy","ce66a42d":"## Machine Learning - Multiple Model Testing","0b4e9574":"# Visualizing Clusters","503128a3":"# Classification Using LogisticRegressionCV","6be4abe1":"## Feature Scaling using StandardScaler","59e14347":"# Preparing Data","65366fb1":"## Checking for null values","0bfb63a5":"## Effect of Cylinder Count on Mileage, Acceleration, Horsepower","75f115d3":"# Comparing Models","07c67687":"## Feature Scaling for Logistic Regression and LinearSVC","27903eb3":"## Top 10 Best Performing Models","c547cf66":"### Dataframe to store all the accuracy scores for Comparison and Analysis","37ed3b05":"# KMeans Model","cc9e47c0":"#### Most of the Cars have 4 Cylinders\n#### Also Most of the Cars are from Origin 1","d28a7535":"## Preparing Data for Classification Model","9fcb9e9b":"# Feature Engineering","d48d9dbc":"### From Elbow Method it is Clear that we have 3 Clusters","bb70cd23":"## Applying Principal Compnent Analysis","accd438d":"## Distributon Plots for Continious Features"}}