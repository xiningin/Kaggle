{"cell_type":{"7b677f59":"code","f0c341df":"code","af9e559a":"code","f302d48c":"code","259cc5ce":"code","dd9e496a":"code","c2ad8d82":"code","ec026b9c":"code","eba67234":"code","91334482":"code","becb80e1":"code","cd1b1f60":"code","9cf5ce6f":"code","abf7bb97":"code","4680ffb2":"code","952c0bc8":"code","1291cf30":"code","9d986cf9":"code","ef72866b":"code","0e0c7a88":"code","acf71f85":"code","0a917c2f":"code","958bda34":"code","fe005d99":"code","8543e182":"code","46d1b9db":"code","79605478":"code","ef465251":"code","e5666f7b":"code","121054d3":"code","3816f5b3":"code","9d78919f":"markdown","354bd081":"markdown","1d23b7db":"markdown","4b216eb3":"markdown","8f514dca":"markdown"},"source":{"7b677f59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0c341df":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","af9e559a":"train_dat = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_dat = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","f302d48c":"print(train_dat.info())\nprint(test_dat.info())","259cc5ce":"sns.countplot(train_dat['label'])","dd9e496a":"x_train = train_dat.iloc[:,1:].to_numpy(copy=True).reshape((train_dat.shape[0],28,28))\ny_train = train_dat.iloc[:,0].to_numpy(copy=True)\nx_test = test_dat.iloc[:,:].to_numpy(copy=True).reshape((test_dat.shape[0],28,28))\nprint(x_train.shape, y_train.shape, x_test.shape)","c2ad8d82":"def sample_and_plot(dat, df, titl, flag):\n    import random\n    random.seed(0)\n    n= 25\n    samples = random.sample(range(dat.shape[0]),n)\n\n    fig, axs = plt.subplots(5,5,figsize=(10, 10),sharex=True,sharey=True)\n#     fig.suptitle(titl)\n    for i, isample in enumerate(samples):\n        r,c = divmod(i,5)\n        axs[r,c].imshow(dat[isample,:,:], cmap = plt.get_cmap('gray'))\n        if flag:\n            axs[r,c].set_title(df.iloc[isample,0])\n        axs[r,c].set_xticks([])\n        axs[r,c].set_yticks([])","ec026b9c":"sample_and_plot(x_train, train_dat, 'Samples from Training set', True)    ","eba67234":"sample_and_plot(x_test, test_dat, 'Samples from test set', False)","91334482":"run_svm = False","becb80e1":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay","cd1b1f60":"X = train_dat.copy()\ny = X['label'].copy()\nX.drop(columns=['label'], inplace=True)\nXtrain, Xvalid, Ytrain, Yvalid = train_test_split(X, y, test_size=0.2, random_state=1)\n\nXtest = test_dat.copy()\n\nprint(Xtrain.shape, Xvalid.shape, Ytrain.shape, Yvalid.shape, Xtest.shape)","9cf5ce6f":"if run_svm:\n    sv = SVC(random_state=1, kernel='rbf',verbose=True)\n    sv.fit(Xtrain, Ytrain)\n    Ypredict = sv.predict(Xvalid)\n    print('Confusion Matrix:\\n',confusion_matrix(y_true=Yvalid, y_pred=Ypredict))\n    print('Accuracy:\\n',accuracy_score(y_true=Yvalid, y_pred=Ypredict))","abf7bb97":"if run_svm:\n    Ytestpredict = sv.predict(test_dat)","4680ffb2":"if run_svm:\n    submission = pd.DataFrame({'ImageID':test_dat.index+1, 'Label':Ytestpredict})\n    submission.to_csv('my_svm_submission.csv',index=False)\n    submission.head()","952c0bc8":"from keras.datasets import mnist\n(Xtr, ytr), (Xtsk, Ytsk) = mnist.load_data()\nXtrk, Xvk, Ytrk, Yvk = train_test_split(Xtr, ytr, test_size=0.2, random_state=1)\n\nprint(Xtr.shape, ytr.shape, Xtsk.shape, Ytsk.shape)\nprint(Xtrk.shape, Ytrk.shape, Xvk.shape, Yvk.shape)","1291cf30":"use_keras_data = False","9d986cf9":"if use_keras_data:\n    Xtrain_cnn = np.array(Xtrk).astype('float32').reshape(-1,28,28,1)\/255\n    Xvalid_cnn = np.array(Xvk).astype('float32').reshape(-1,28,28,1)\/255\n    Xtest_cnn = np.array(Xtsk).astype('float32').reshape(-1,28,28,1)\/255\n    Ytrain_cnn = Ytrk\n    Ytest_cnn = Ytsk\n    Yvalid_cnn = Yvk\nelse:\n    Xtrain_cnn = np.array(Xtrain).astype('float32').reshape(-1,28,28,1)\/255\n    Xvalid_cnn = np.array(Xvalid).astype('float32').reshape(-1,28,28,1)\/255\n    Xtest_cnn = np.array(Xtest).astype('float32').reshape(-1,28,28,1)\/255\n    Ytrain_cnn = Ytrain\n    Yvalid_cnn = Yvalid\n\n\nprint(Xtrain_cnn.shape, Xvalid_cnn.shape, Ytrain_cnn.shape, Yvalid_cnn.shape, Xtest_cnn.shape)","ef72866b":"import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Conv2D, Dense, Dropout, MaxPooling2D, BatchNormalization, Flatten, Activation\nfrom keras.layers.experimental import preprocessing\nfrom keras.utils import plot_model, to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator","0e0c7a88":"mod_cnn = Sequential([# preprocessing for augmentation\n                      preprocessing.RandomContrast(factor=0.3),\n#                       preprocessing.RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)),\n                    # conv base\n                      Conv2D(filters = 16, kernel_size=(3,3), activation='relu',input_shape=(28,28,1), padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 12, kernel_size=(3,3), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 12, kernel_size=(1,1), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      MaxPooling2D(pool_size=(2,2)),\n                      Conv2D(filters = 16, kernel_size=(3,3), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 16, kernel_size=(3,3), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 16, kernel_size=(5,5), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 16, kernel_size=(3,3), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 12, kernel_size=(3,3), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Conv2D(filters = 8, kernel_size=(3,3), activation='relu', padding='same'),\n                      Dropout(0.2),\n                      BatchNormalization(),\n                      Flatten(),                      \n                    # dense layer\n                      Dense(units=256, activation='relu'),\n                      Dense(units=128, activation='relu'),\n                      Dense(units=10, activation='softmax')\n                      ])","acf71f85":"mod_cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), loss='categorical_crossentropy', metrics=['accuracy'])","0a917c2f":"earlystop = EarlyStopping(patience=10, min_delta=1e-3, restore_best_weights=True)\nYtrain_labels = to_categorical(Ytrain_cnn)\nYvalid_labels = to_categorical(Yvalid_cnn)\nlr = ReduceLROnPlateau(monitor=\"val_loss\", patience=3, verbose=1, factor = 0.5, min_lr = 1e-5)\n\ndataug = ImageDataGenerator(featurewise_center=False, featurewise_std_normalization=False, zoom_range=0.1,\n                           rotation_range=10,width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=False, \n                            vertical_flip=False, validation_split=0.2)\ndataug.fit(Xtrain_cnn)\n\nhist = mod_cnn.fit(dataug.flow(Xtrain_cnn, Ytrain_labels, batch_size=128), \n                   epochs=50, verbose=1, shuffle=True, \n                   validation_data=(Xvalid_cnn, Yvalid_labels), callbacks=[earlystop, lr])","958bda34":"mod_cnn.summary()","fe005d99":"# plot_model(mod_cnn, show_layer_names=True, show_shapes=True)","8543e182":"for key in hist.history.keys():\n    plt.plot(hist.history[key],label=key)\nplt.legend()\nplt.ylim([0,1])","46d1b9db":"score = mod_cnn.evaluate(Xvalid_cnn, Yvalid_labels, verbose=0)\nprint(score)","79605478":"Ypredict_cnn = mod_cnn.predict(Xtest_cnn)","ef465251":"Ypredict_cnn","e5666f7b":"to_categorical(np.argmax(Ypredict_cnn,axis=1))","121054d3":"if use_keras_data:\n    score = mod_cnn.evaluate(Xtest_cnn, to_categorical(Ytest_cnn),verbose=0)\n    print(score)\n    \n    cm = confusion_matrix(y_true=Ytest_cnn, y_pred=np.argmax(Ypredict_cnn,axis=1))\n#     print('Confusion Matrix:\\n',confusion_matrix(y_true=Ytest_cnn, y_pred=np.argmax(Ypredict_cnn,axis=1)))\n    cmd = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=[x for x in range(10)])\n    cmd.plot(include_values=True, cmap = plt.cm.Blues, ax=None)\n    plt.show()\n    \n    print(\"{} digits have been misclassified\".format(np.sum(cm) - sum(cm[np.diag_indices(10)])))","3816f5b3":"if not use_keras_data:\n    submission = pd.DataFrame({'ImageID':test_dat.index+1, 'Label':np.argmax(Ypredict_cnn,axis=1)})\n    submission.to_csv('my_cnnv11_submission.csv',index=False)\n    submission.head()","9d78919f":"# Foreword\n\nMNIST database is a large dataset of handwritten digits used predominantly for training image processing algorithms and for learning. The database contains over 60,000 training images and 10,000 testing images which are monochrome images normalized and anti-aliased to fit a 28x28 pixel bounding box. The [original paper used SVM](https:\/\/ieeexplore.ieee.org\/document\/726791) and saw an error rate of 0.8%.\n\n![Digits_classifier.PNG](attachment:775e0e37-f91e-418d-a575-bdc9ccee5003.PNG)\n\n","354bd081":"# The data\n\nThe data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n\nFor example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.","1d23b7db":"# Using SVM","4b216eb3":"# Using CNN","8f514dca":"**Prediction**"}}