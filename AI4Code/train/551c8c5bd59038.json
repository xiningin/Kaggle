{"cell_type":{"e86d2983":"code","aee824a3":"code","f61b9076":"code","b99447af":"code","c86e2fad":"code","93b93cef":"code","b88937c4":"code","37a0a945":"code","f8735779":"code","8ddfd224":"code","544bcabd":"code","33b7ab54":"code","934aac85":"code","2a7ae41e":"code","c2774a05":"code","043e52c5":"code","5e02f2b5":"code","73e2f586":"code","e8124130":"code","2f45039c":"code","a69289ef":"code","91d81013":"code","278850b8":"code","d1d26f4d":"code","1fc6a9d5":"code","c319a1ce":"code","e8e601c8":"code","84e15adf":"code","e7832ffe":"code","dfb3dae8":"code","ff6137a5":"code","8cfb60ea":"code","db9e8467":"code","5e2b45eb":"code","54b4d150":"code","c92879ec":"code","e309cf10":"code","9a264a82":"code","21c1386c":"code","7b14136a":"code","0f864f2b":"code","b49b8cb8":"code","23471c53":"markdown","e4776633":"markdown","038d7260":"markdown","0d46442f":"markdown","d2a3a7d2":"markdown","901a6b45":"markdown","804f4bd0":"markdown","c9b32a47":"markdown","dd6f0298":"markdown","ec3778d9":"markdown","51d63225":"markdown"},"source":{"e86d2983":"#checking the GPU card\n!nvidia-smi","aee824a3":"import numpy as np\nimport pandas as pd\nimport os \nimport matplotlib.pyplot as plt\nfrom pathlib import Path","f61b9076":"#inserting the file  path \npath = \"..\/input\/tomatoleaf\/tomato\"\nos.listdir(path)","b99447af":"train_path = os.path.join(path, \"train\")\nprint(os.listdir(train_path))\nprint(\"*\"*100)\ntest_path = os.path.join(path, \"val\")\nprint(os.listdir(test_path))","c86e2fad":"from glob import glob\nfolders = glob(\"..\/input\/tomatoleaf\/tomato\/train\/*\")\nfolders","93b93cef":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Bacterial_spot\/07238109-52ed-4369-b16c-6f5844858b81___UF.GRC_BS_Lab Leaf 0447.JPG\"))\nplt.title(\"Bacterial Spot\")","b88937c4":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Bacterial_spot\/07238109-52ed-4369-b16c-6f5844858b81___UF.GRC_BS_Lab Leaf 0447.JPG\"))\nplt.title(\"Early Blight\")","37a0a945":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Late_blight\/06913075-dad1-4047-b5a2-74fe680efa3b___RS_Late.B 6048.JPG\"))\nplt.title(\"Late Blight\")","f8735779":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Bacterial_spot\/07238109-52ed-4369-b16c-6f5844858b81___UF.GRC_BS_Lab Leaf 0447.JPG\"))\nplt.title(\"Leaf Mold\")","8ddfd224":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Septoria_leaf_spot\/0650f176-add9-444e-893e-707969054a43___JR_Sept.L.S 2722.JPG\"))\nplt.title(\"Septoria Leaf Spot\")","544bcabd":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Spider_mites Two-spotted_spider_mite\/12019ba6-405d-45b7-b0e6-5a6a665de0e7___Com.G_SpM_FL 8624.JPG\"))\nplt.title(\"Spider_mites Two-spotted_spider_mite\")","33b7ab54":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomatoleaf\/tomato\/train\/Tomato___Tomato_Yellow_Leaf_Curl_Virus\/cfea2cd5-8cc8-4a58-be36-5ff7d2de6c9c___UF.GRC_YLCV_Lab 01479.JPG\"))\nplt.title(\"Yellow leaf curve virus\")","934aac85":"import cv2\n\nim = cv2.imread('..\/input\/tomatoleaf\/tomato\/train\/Tomato___Tomato_Yellow_Leaf_Curl_Virus\/cfbf4c76-c9de-43d8-82ce-5a1a64631576___YLCV_NREC 2972.JPG')\n\nprint(type(im))\n\n\nprint(im.shape)\nprint(type(im.shape))","2a7ae41e":"import tensorflow as tf\nfrom pathlib import Path\n\ntf.random.set_seed(4)","c2774a05":"# Creating the Pathlib PATH objects\ntrain_path = Path(\"..\/input\/tomatoleaf\/tomato\/train\")\ntest_path = Path(\"..\/input\/tomatoleaf\/tomato\/val\")","043e52c5":"# Getting Image paths \nimport glob\ntrain_image_paths = list(train_path.glob(\"*\/*\"))\ntrain_image_paths = list(map(lambda x : str(x) , train_image_paths))\n\ntrain_image_paths[:10]","5e02f2b5":"# Getting their respective labels \ndef get_label(image_path):\n    return image_path.split(\"\/\")[-2]\n\ntrain_image_labels = list(map(lambda x : get_label(x) , train_image_paths))\ntrain_image_labels[:10]","73e2f586":"from sklearn.preprocessing import LabelEncoder \n\nLe = LabelEncoder()\ntrain_image_labels = Le.fit_transform(train_image_labels)\n\ntrain_image_labels[:10]","e8124130":"train_image_labels = tf.keras.utils.to_categorical(train_image_labels)\n\ntrain_image_labels[:10]","2f45039c":"from sklearn.model_selection import train_test_split \n\nX_train , X_val , y_train , y_val = train_test_split(train_image_paths , train_image_labels , test_size = 0.25)","a69289ef":"classTotals = y_train.sum(axis=0)\nclassWeight = classTotals.max() \/ classTotals\n\nclass_weight = {e : weight for e , weight in enumerate(classWeight)}\nprint(class_weight)","91d81013":"# Function used for Transformation\n\ndef load(image , label):\n    image = tf.io.read_file(image)\n    image = tf.io.decode_jpeg(image , channels = 3)\n    return image , label","278850b8":"#HYPER PARAMTER VALUE IS BATCH SIZE = 32","d1d26f4d":"# Define IMAGE SIZE and BATCH SIZE \nIMG_SIZE = 96 \nBATCH_SIZE = 32\n\n# Basic Transformation\nresize = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)          \n])\n\n# Data Augmentation\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor = (-0.1, -0.05))\n])","1fc6a9d5":"# Function used to Create a Tensorflow Data Object\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ndef get_dataset(paths , labels , train = True):\n    # convert paths and labels to tensor\n    image_paths = tf.convert_to_tensor(paths)\n    labels = tf.convert_to_tensor(labels)\n\n    # create dataset objects for images and labels\n    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n\n    # zip them to be able to iterate on both at once\n    dataset = tf.data.Dataset.zip((image_dataset , label_dataset))\n\n    # apply load and resize on dataset\n    dataset = dataset.map(lambda image , label : load(image , label))\n    dataset = dataset.map(lambda image, label: (resize(image), label) , num_parallel_calls=AUTOTUNE)\n\n    # shuffle and batch the dataset\n    dataset = dataset.shuffle(1000)\n    dataset = dataset.batch(BATCH_SIZE)\n\n    # if train = True apply data augmentation\n    if train:\n        dataset = dataset.map(lambda image, label: (data_augmentation(image), label) , num_parallel_calls=AUTOTUNE)\n    \n    # if not training repeat over the dataset and return\n    dataset = dataset.repeat()\n    return dataset","c319a1ce":"# Creating Train Dataset object and Verifying it\n%time train_dataset = get_dataset(X_train , y_train)\n\nimage , label = next(iter(train_dataset))\nprint(image.shape)\nprint(label.shape)","e8e601c8":"# View a Sample images\nprint(Le.inverse_transform(np.argmax(label , axis = 1))[0])\nplt.imshow((image[0].numpy()\/255).reshape(96 , 96 , 3))","84e15adf":"%time val_dataset = get_dataset(X_val , y_val , train=False)\n\nimage , label = next(iter(val_dataset))\nprint(image.shape)\nprint(label.shape)","e7832ffe":"# View a sample Validation Image\nprint(Le.inverse_transform(np.argmax(label , axis = 1))[0])\nplt.imshow((image[0].numpy()\/255).reshape(96 , 96 , 3))","dfb3dae8":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential","ff6137a5":"from tensorflow.keras.applications import EfficientNetB4","8cfb60ea":"backbone = EfficientNetB4(\n    input_shape=(96, 96, 3),\n    include_top=False  # not including a final layers of EfficientNetB2\n)\n\nmodel = tf.keras.Sequential([\n    backbone,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.summary()","db9e8467":"# Compiling your model by providing the Optimizer , Loss and Metrics\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    loss = 'categorical_crossentropy',\n    metrics=['accuracy' , tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]\n)","5e2b45eb":"# Train the model\nhistory = model.fit(\n    train_dataset,\n    steps_per_epoch=len(X_train)\/\/BATCH_SIZE,\n    epochs=15,\n    validation_data=val_dataset,\n    validation_steps = len(X_val)\/\/BATCH_SIZE,\n    class_weight=class_weight\n)","54b4d150":"from tensorflow.keras.applications import EfficientNetB4\n\nbackbone = EfficientNetB4(\n    input_shape=(96, 96, 3),\n    include_top=False\n)\n\nmodel = tf.keras.Sequential([\n    backbone,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    loss = 'categorical_crossentropy',\n    metrics=['accuracy' , tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]\n)","c92879ec":"# Save Model\nmodel.save(\"Final_Weigth.h5\")","e309cf10":"model.load_weights(\"Final_Weigth.h5\")","9a264a82":"test_image_paths = list(test_path.glob(\"*\/*\"))\ntest_image_paths = list(map(lambda x : str(x) , test_image_paths))\ntest_labels = list(map(lambda x : get_label(x) , test_image_paths))\n\ntest_labels = Le.transform(test_labels)\ntest_labels = tf.keras.utils.to_categorical(test_labels)\n\ntest_image_paths = tf.convert_to_tensor(test_image_paths)\ntest_labels = tf.convert_to_tensor(test_labels)\n\ndef decode_image(image , label):\n    image = tf.io.read_file(image)\n    image = tf.io.decode_jpeg(image , channels = 3)\n    image = tf.image.resize(image , [96 , 96] , method=\"bilinear\")\n    return image , label\n\ntest_dataset = (\n     tf.data.Dataset\n    .from_tensor_slices((test_image_paths, test_labels))\n    .map(decode_image)\n    .batch(BATCH_SIZE)\n)","21c1386c":"image , label = next(iter(test_dataset))\nprint(image.shape)\nprint(label.shape)","7b14136a":"# View a sample Validation Image\nprint(Le.inverse_transform(np.argmax(label , axis = 1))[0])\nplt.imshow((image[0].numpy()\/255).reshape(96 , 96 , 3))","0f864f2b":"loss, acc, prec, rec = model.evaluate(test_dataset)\n\nprint(\" Testing Acc : \" , acc)\nprint(\" Testing Precision \" , prec)\nprint(\" Testing Recall \" , rec)","b49b8cb8":"# Save Model\nmodel.save(\"Final_TomatoLeafdisease.h5\")","23471c53":"**Data Loading and Augmentation**","e4776633":"**Joining the Training and Testing path**","038d7260":"**Evaluating the model**","0d46442f":"**checking the image shape and size**","d2a3a7d2":"**Importing the EfficientNet from Tensorflow application**","901a6b45":"![efficientNet_b4.png](attachment:6d1e8524-36ec-4376-a6d6-340415f5c95f.png)","804f4bd0":"**Importing the Efficient Net -B4**","c9b32a47":"**If you like this notebook! please upvote**","dd6f0298":"**Importing all the requirements**","ec3778d9":"**THIS NOTEBOOK FOR TOMATO LEAF DISEASE IDENDIFICATION.BY USING THE EFFICIENT NET B4**","51d63225":"**Data visualisation**"}}