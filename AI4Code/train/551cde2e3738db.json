{"cell_type":{"c86dac19":"code","e92c8e2f":"code","cbedce4a":"code","795c333c":"code","d9337f13":"code","bfff6aa6":"code","a3028890":"code","bf5079bf":"code","51a151a2":"code","91bfdcc3":"code","4facf304":"code","09733db7":"code","0d02ebb9":"code","6cbb3d00":"code","44f7c210":"code","9817b60e":"code","f735f072":"code","ac63e5bf":"code","325a2a8b":"code","8c5b33f4":"code","f8ff63da":"code","6838327d":"code","b3da0911":"code","6a58c851":"code","13abab35":"code","f1c2c8d0":"code","ae0f9647":"code","62e2caa1":"code","c6736ae9":"code","5dc29ac0":"code","a37422f6":"code","b5bb9d93":"code","a15c9c74":"code","9ac8cdee":"code","fce6e6ff":"code","68d22085":"code","1843d07b":"code","358b9adc":"code","95d58f8e":"markdown","d33f83e6":"markdown","84550afb":"markdown","0d033dc4":"markdown","8528cd49":"markdown","0804f59f":"markdown","6473f449":"markdown","badeae56":"markdown","d41b6f37":"markdown","bc1b6bea":"markdown","bfae17b0":"markdown","a2071d9c":"markdown","b69649c6":"markdown","aed088b0":"markdown","92fadc92":"markdown","345ad6a6":"markdown","f0c302a1":"markdown","68f95ff7":"markdown","64c5781f":"markdown","da173df4":"markdown","7f1c5d52":"markdown","8b9da742":"markdown","51ffb303":"markdown","33e7f558":"markdown","bba3e5f5":"markdown","abac04d3":"markdown","279e0da4":"markdown","881d2b0a":"markdown","cb3307a0":"markdown","a0864a31":"markdown","fa497764":"markdown","c3c58fa9":"markdown","220c815c":"markdown","b663748b":"markdown","062d2e69":"markdown","70083a5e":"markdown","b78f10b8":"markdown","65ad86ce":"markdown","2d61f165":"markdown","26cd5837":"markdown","20e6f6f2":"markdown","54fab9b3":"markdown","1f795799":"markdown","21d79326":"markdown","fa759f63":"markdown","169662ce":"markdown","c91397cb":"markdown","35f3ac3e":"markdown","6b911fd5":"markdown","09d4bf4b":"markdown","40486a21":"markdown","e3ae2e35":"markdown","32abaa79":"markdown","18cf338e":"markdown","47193fe5":"markdown","0dd38e7f":"markdown","b9665f74":"markdown","83bb708a":"markdown"},"source":{"c86dac19":"import pandas as pd\nimport numpy as np\nfrom numpy.random import seed\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.random import set_seed\nfrom keras.datasets import mnist\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler","e92c8e2f":"set_seed(17)\nseed(17)","cbedce4a":"def plot (data, source, count=None, suf_title=None, title=None):\n    if count is None: count = len(data)\n    height = (count+9) \/\/ 10\n    plt.figure(figsize=(20, height * 2))\n    j=0\n    for img in list(data.index):\n        ax = plt.subplot(height, 10, j+1)\n        plt.grid(False)\n        plt.imshow(source[img], cmap='gray')\n        if ((title is not None) and (suf_title is not None)):\n            plt.title(suf_title + str(title.iloc[j]))\n        plt.axis(\"off\")\n        if j < count-1: j += 1\n        else: \n            plt.show()\n            return\n    plt.show()\n    return","795c333c":"def results (Model, History, Data):\n    df = pd.DataFrame(History.history)\n    df.index += 1\n    fig = plt.figure(figsize = (20,5))\n    fig.suptitle('Validation metrics')\n    ax1 = fig.add_subplot(121)\n    ax2 = fig.add_subplot(122)\n    ax1.set_xticks(range(len(df)+1))\n    ax2.set_xticks(range(len(df)+1))\n    df[['loss', 'val_loss']].plot(title=\"Cross Entropy\", grid=True, ax=ax1)\n    df[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\",grid=True, ax=ax2)\n    plt.show()\n    pred = Model.predict(Data)\n    classes = np.argmax(pred, axis=-1)\n    score = (classes == y_test_labels).mean()\n    print(\"\\n\",'-' * 25,\"\\n\",\"Accuracy on test:\",\n          \"%.2f\" % (score * 100), '%',\"\\n\", '-' * 25)\n    return","d9337f13":"def mismatched (Model, Train, Labels):\n    preds = Model.predict(Train)\n    classes = np.argmax(preds, axis=-1)\n    result = pd.DataFrame()\n    result['Real'] = Labels\n    result['Pred'] = classes\n    wrong = result[result.Real != result.Pred]\n    wrong_cnt = wrong.shape[0]\n    print('Mismatched :', wrong_cnt,\n          'out of', len(Train), ' \/ ', \"%.2f\" %\n          (wrong_cnt\/len(Train) * 100), '%')\n    return wrong, wrong_cnt","bfff6aa6":"(X_train_raw, y_train_labels), (X_test_raw, y_test_labels) = mnist.load_data()","a3028890":"rand = np.random.randint(0, X_train_raw.shape[0]-1, 10)\nrandom = pd.Series(rand)\nplot (random, X_train_raw, 10, 'Index ', random)","bf5079bf":"print('Train \/ test data size:',\"\\n\",\n      X_train_raw.shape, y_train_labels.shape,\"\\n\",\n      X_test_raw.shape, y_test_labels.shape,\"\\n\")\nprint('Train \/ test values range:',\"\\n\",\n      X_train_raw.min(), '-', X_train_raw.max(),\"\\n\",\n      X_test_raw.min(), '-', X_test_raw.max())","51a151a2":"X_train = X_train_raw \/ 255\nX_test = X_test_raw \/ 255\nprint('Train \/ test scaled values range:',\"\\n\",\n      X_train.min(), '-', X_train.max(),\"\\n\",\n      X_test.min(), '-', X_test.max())","91bfdcc3":"#Calculate data size in all dimensions\ndim1_train, dim1_test = X_train.shape[0], X_test.shape[0]\ndim2, dim3 = X_train.shape[1], X_train.shape[2]\n\n#Resize (flatten) features from 3-dim to 2-dim arrays\nX_train_flat = np.resize(X_train, (dim1_train, dim2 * dim3))\nX_test_flat = np.resize(X_test, (dim1_test, dim2 * dim3))\n\n#Create sparse matrix for labels using Keras utils\ny_train = to_categorical(y_train_labels)\ny_test = to_categorical(y_test_labels)\n\nprint('Resized features:',\"\\n\",\n      X_train_raw.shape, '->', X_train_flat.shape,\"\\n\",\n      X_test_raw.shape, '->', X_test_flat.shape,\"\\n\")\n\nprint('Resized labels:',\"\\n\",\n      y_train_labels.shape, '->', y_train.shape,\"\\n\",\n      y_test_labels.shape, '->', y_test.shape)","4facf304":"XTrainFlat, XValidFlat, yTrainFlat, yValidFlat = train_test_split(\n                                                 X_train_flat, y_train, test_size=0.2,\n                                                 stratify=y_train_labels, random_state=17)","09733db7":"model_dense = keras.Sequential([\n                        layers.Dense(512, activation = 'relu', input_shape = [dim2 * dim3]),\n                        layers.Dense(10, activation='softmax')\n                        ])\nmodel_dense.compile(\n            optimizer='adam',\n            loss='categorical_crossentropy',\n            metrics=['accuracy'],\n            )\nmodel_dense.summary()","0d02ebb9":"history_dense = model_dense.fit(\n    XTrainFlat, yTrainFlat,\n    batch_size = 64,\n    validation_data=(XValidFlat, yValidFlat),\n    epochs=10)   ","6cbb3d00":"results(model_dense, history_dense, X_test_flat)","44f7c210":"wrong_dense, wrong_dense_cnt = mismatched(model_dense, X_test_flat, y_test_labels )\nprint('10 samples of mismatched images by Dense NN:')\nplot (wrong_dense, X_test_raw, 10, 'Matched as ', wrong_dense.Pred )","9817b60e":"X_train_cnn = np.reshape(X_train, (dim1_train, dim2, dim3,1))\nX_test_cnn = np.reshape(X_test, (dim1_test, dim2, dim3,1))\nprint('Resized features:',\"\\n\",\n      X_train.shape, '->', X_train_cnn.shape,\"\\n\",\n      X_test.shape, '->', X_test_cnn.shape,\"\\n\")","f735f072":"XTrainCNN, XValidCNN, yTrainCNN, yValidCNN = train_test_split(\n                                                 X_train_cnn, y_train, test_size=0.2,\n                                                 stratify=y_train_labels, random_state=17)","ac63e5bf":"model_cnn = keras.Sequential([\n                        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim2, dim3, 1)),\n                        layers.BatchNormalization(),\n                        layers.MaxPooling2D((2, 2)),\n                        layers.Conv2D(64, (3, 3), activation='relu'),\n                        layers.BatchNormalization(),\n                        layers.MaxPooling2D((2, 2)),\n                        layers.Conv2D(64, (3, 3), activation='relu'),\n                        layers.BatchNormalization(),\n                        layers.Flatten(),\n                        layers.Dropout(0.25),\n                        layers.Dense(64, activation='relu'),\n                        layers.Dropout(0.25),\n                        layers.Dense(10, activation='softmax'),\n                        ])\nmodel_cnn.compile(\n            optimizer= Adam(1e-3),\n            loss='categorical_crossentropy',\n            metrics=['accuracy'],\n            )\n\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=5e-4,\n    restore_best_weights=True,\n)\n\nLR = LearningRateScheduler(lambda R: 5e-4 * 0.95 ** R)\n\nmodel_cnn.summary()","325a2a8b":"history_cnn = model_cnn.fit(\n    XTrainCNN, yTrainCNN,\n    batch_size = 64,\n    validation_data=(XValidCNN, yValidCNN),\n    epochs=20,\n    callbacks=[early_stopping, LR])    ","8c5b33f4":"results(model_cnn, history_cnn, X_test_cnn)","f8ff63da":"wrong_cnn, wrong_cnn_cnt = mismatched(model_cnn, X_test_cnn, y_test_labels)\nprint('10 samples of mismatched images by Convolutional NN:')\nplot (wrong_cnn, X_test_cnn, 10, 'Matched as ', wrong_cnn.Pred)","6838327d":"wrong_train, wrong_train_cnt = mismatched(model_cnn, X_train_cnn, y_train_labels )\nprint('Mismatched image samples in a train set:')\nplot (wrong_cnn, X_train_cnn, 10, 'Matched as ', wrong_cnn.Pred)","b3da0911":"X_wrong = X_train_cnn[wrong_train.index]\ny_wrong = y_train[wrong_train.index]\nX_wrong = np.repeat(X_wrong, 50, axis=0)\ny_wrong = np.repeat(y_wrong, 50, axis=0)\n\nprint (wrong_train.shape[0], '->', len(X_wrong))\nprint (y_train[wrong_train.index].shape, '->', y_wrong.shape)","6a58c851":"X_aug = X_wrong.copy()\ny_aug = y_wrong.copy()\n\naugment = ImageDataGenerator()\nfor i in range(len(X_aug)):\n    params = {\n        'theta': np.random.randint(-35, 35, 1)[0], #Rotate angle range\n        'tx': np.random.randint(-2, 2, 1)[0],      #Shift X range (in pixels)\n        'ty': np.random.randint(-2, 2, 1)[0],      #Shift Y range (in pixels),\n        'zx': np.random.uniform(0.9, 1.1, 1)[0],   #Zoom X range\n        'zy': np.random.uniform(0.9, 1.1, 1)[0]    #Zoom Y range      \n        }\n    X_aug[i] = augment.apply_transform(X_wrong[i], transform_parameters = params)\n    y_aug[i,:] = y_wrong[i,:]","13abab35":"rnd_idx = pd.DataFrame(np.random.randint(0, len(y_wrong)+1, 10)).set_index(0)\nplot (rnd_idx, X_wrong, 10)\nplot (rnd_idx, X_aug, 10)","f1c2c8d0":"X_train_cnn_aug = np.vstack([X_train_cnn, X_aug])\ny_train_aug = np.vstack([y_train, y_aug])\nX_train_aug_flat = np.resize(X_train_cnn_aug, (X_train_cnn_aug.shape[0], dim2 * dim3))","ae0f9647":"XTrainFlat_aug, XValidFlat_aug, yTrainFlat_aug, yValidFlat_aug = train_test_split(\n                                                                 X_train_aug_flat, y_train_aug, test_size=0.2,\n                                                                 stratify= np.argmax(y_train_aug, axis=-1), random_state=17)","62e2caa1":"model_dense_2 = keras.Sequential([\n                        layers.Dense(512, activation = 'relu', input_shape = [dim2 * dim3]),\n                        layers.Dense(10, activation='softmax')\n                        ])\nmodel_dense_2.compile(\n            optimizer='adam',\n            loss='categorical_crossentropy',\n            metrics=['accuracy'],\n            )\nhistory_dense_2 = model_dense_2.fit(\n    X_train_aug_flat, y_train_aug,\n    batch_size = 64,\n    epochs=10,\n    validation_data=(XValidFlat_aug, yValidFlat_aug))","c6736ae9":"results(model_dense_2, history_dense_2, X_test_flat)","5dc29ac0":"XTrainCNN_aug, XValidCNN_aug, yTrainCNN_aug, yValidCNN_aug = train_test_split(\n                                                             X_train_cnn_aug, y_train_aug, test_size=0.2,\n                                                             stratify=np.argmax(y_train_aug, axis=-1), random_state=17)","a37422f6":"model_cnn_2 = keras.Sequential([\n                        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim2, dim3, 1)),\n                        layers.BatchNormalization(),\n                        layers.MaxPooling2D((2, 2)),\n                        layers.Conv2D(64, (3, 3), activation='relu'),\n                        layers.BatchNormalization(),\n                        layers.MaxPooling2D((2, 2)),\n                        layers.Conv2D(64, (3, 3), activation='relu'),\n                        layers.BatchNormalization(),\n                        layers.Flatten(),\n                        layers.Dropout(0.25),\n                        layers.Dense(64, activation='relu'),\n                        layers.Dropout(0.25),\n                        layers.Dense(10, activation='softmax'),\n                        ])\nmodel_cnn_2.compile(\n            optimizer= Adam(1e-3),\n            loss='categorical_crossentropy',\n            metrics=['accuracy'],\n            )\nhistory_cnn_2 = model_cnn_2.fit(\n    XTrainCNN_aug, yTrainCNN_aug,\n    batch_size = 64,\n    validation_data=(XValidCNN_aug, yValidCNN_aug),\n    epochs=20,\n    callbacks=[early_stopping, LR])    ","b5bb9d93":"results(model_cnn_2, history_cnn_2, X_test_cnn)","a15c9c74":"model_cnn_3 = keras.Sequential([\n                        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim2, dim3, 1)),\n                        layers.BatchNormalization(),\n                        layers.MaxPooling2D((2, 2)),\n                        layers.Conv2D(64, (3, 3), activation='relu'),\n                        layers.BatchNormalization(),\n                        layers.MaxPooling2D((2, 2)),\n                        layers.Conv2D(64, (3, 3), activation='relu'),\n                        layers.BatchNormalization(),\n                        layers.Flatten(),\n                        layers.Dropout(0.25),\n                        layers.Dense(64, activation='relu'),\n                        layers.Dropout(0.25),\n                        layers.Dense(10, activation='softmax'),\n                        ])\nmodel_cnn_3.compile(\n            optimizer= Adam(),\n            loss='categorical_crossentropy',\n            metrics=['accuracy'],\n            )\n\nfull_augment = ImageDataGenerator(\n        rotation_range=35,  \n        zoom_range = 0.10,  \n        width_shift_range=2, \n        height_shift_range=2)\n\nhistory_cnn_3 = model_cnn_3.fit(full_augment.flow(XTrainCNN, yTrainCNN, batch_size=64),\n                    epochs=20,\n                    steps_per_epoch = XTrainCNN.shape[0]\/64,\n                    validation_data=(XValidCNN, yValidCNN),\n                    callbacks = [early_stopping])","9ac8cdee":"results(model_cnn_3, history_cnn_3, X_test_cnn)","fce6e6ff":"result = pd.DataFrame()\nresult['Real'] = y_test_labels\nresult['Dense_1'] = np.argmax(model_dense.predict(X_test_flat), axis=-1)\nresult['Dense_2'] = np.argmax(model_dense_2.predict(X_test_flat), axis=-1)\nresult['CNN_1'] = np.argmax(model_cnn.predict(X_test_cnn), axis=-1)\nresult['CNN_2'] = np.argmax(model_cnn_2.predict(X_test_cnn), axis=-1)\nresult['CNN_3'] = np.argmax(model_cnn_3.predict(X_test_cnn), axis=-1)\nstat = pd.DataFrame()\nfor i in result.columns[1:]:\n    stat.loc[i, 'Total_Rate'] = (result[i] == result['Real']).mean()\n    for j in range(10):\n        label = result[result['Real'] == j]\n        stat.loc[i, ('Rate_' + str(j))] = (label[i] == label['Real']).mean()","68d22085":"ax = (stat.Total_Rate*100).plot.bar(figsize = (10,5), rot=0, grid = True)\nax.set_ylim(95,100)\nplt.show()","1843d07b":"ax2 = (stat*100).plot.bar(figsize = (20,4), y=stat.columns[1:], rot=0)\nax2.set_ylim(95,100)\nplt.show()","358b9adc":"ax3 = (stat.T*100).plot.bar(figsize = (20,4), rot=0)\nax3.set_ylim(95,100)\nplt.show()","95d58f8e":"### Utils","d33f83e6":"I will use very simple Dense NN as a simple baseline","84550afb":"#### CNN metrics and score on augmented data","0d033dc4":"#### Get mismatched images","8528cd49":"#### Data preparation","0804f59f":"### Simple Dense NN baseline ","6473f449":"#### Train data samples\nLet's have a look at 10 random samples:","badeae56":"### Statistics","d41b6f37":"### Convolutional NN model","bc1b6bea":"#### Fitting convolutional model","bfae17b0":"#### Raw and distorted samples comparision\nHave a look at the ten random samples of original and distorted images","a2071d9c":"#### Data parameters","b69649c6":"#### Concatenate raw and augmented data\nHere I concatenate new data with the original trainig set to feed it to NN<br>\nOf course I have to do this for ```X``` and ```y``` datasets both<br>\nFor the dense NN I make the dataset flatten again","aed088b0":"As you can see our data is 3-dimensional: every row contains 2-dimensional image 28x28 pixels.<br>\nTo feed it in Dense NN I have to reshape data in 2 dimensions.<br>\nFor the labels I use very useful Keras ```to_categorical``` to create binary sparse matrix from 0-9 labels.","92fadc92":"Set random seed for TensorFlow backgend and NumPy. Both are using by Keras.","345ad6a6":"#### Train\/valid split new data for Convolutional NN","f0c302a1":"I tried many combination of the network and decided not to go with the most complex one to save machine time. As you will see later in the conclusion, increasing the complexity was too costly to improve the result.<br>\nSince this is not a competition, I settled on a fairly simple version.","68f95ff7":"### MNIST digits recognition\nI got this exercise as a test.<br>\nThe goal is to choose the optimal algorithm for handwritten digits recognition from the MNIST dataset.<br>\nI'm going to use Keras framework to do this.","64c5781f":"### Data preparations","da173df4":"Let's have a look at the statistical results of all what I did:","7f1c5d52":"#### Extraxt dirty data (and corresponding labels) from the train set and repeat it 50 times","8b9da742":"But... That approach hasn't really improved scores as well.","51ffb303":"#### Fit dense model on a new data","33e7f558":"#### Distort augmented data","bba3e5f5":"The score is about 98% let's have a look at pictures that were recognited incorrectly.\n* *the scores may vary from run to run although I had set random seed for NumPy and TensorFlow*","abac04d3":"#### Train\/valid split new data for Dense NN\nAs I have new set I have to split it again","279e0da4":"Again scores are more or less the same compate to how it was before my \"partial\" augmentation.<br>\nOK if my idea was not so good, but what about \"classic\" augmentation ?<br>\nNow at least I can use the Keras ```ImageDataDenerator``` in its normal mode","881d2b0a":"#### Baseline Dense NN model","cb3307a0":"### Content\n1. Data loading and preparation\n1. Simple Dense NN as a baseline\n1. Convolutional NN as a stronger baseline\n1. Augmentation of part of the data (mismatched images)\n1. Check Dense and CNN on new data\n1. Full data augmentation\n1. Check Dense and CNN again\n1. Summary","a0864a31":"On the contrary compared to dense NN, for CNN I have to add one dimension to the input data.<br>\nCNN expects color information at the input, in this case for grayscale images one additional dimension would be enough.","fa497764":"#### CNN metrics and score on fully augmented data","c3c58fa9":"First, I will prepare the functions that I will use later","220c815c":"Each pixel of each image has values from 0 to 255 - as a \"brightness\".<br>\nAs son as neural networks don't like input values beyond the 0-1 range they need to be scaled.<br>\nIn this case I can simply divide all values by 255 without any third-party scalers.","b663748b":"Collecting statistic data","062d2e69":"#### Fitting baseline model","70083a5e":"#### CNN metrics and score","b78f10b8":"#### Scores distributed by labels (digits)","65ad86ce":"Split on training and validation data","2d61f165":"#### Extract \"bad\" images from train data","26cd5837":"#### Total accuracy rates for all 5 networks","20e6f6f2":"#### Calculate validation score and plot metrics","54fab9b3":"### Summary\nAs a conclusion I would like to say that Keras framework networks work quite well, but the only way I know to improve the results is to increase the complexity of the network and machine time cost accordingly (in case if this problem have 100% solution at all - some unrecognized numbers cannot be recognized even by a human). <br>\nOn the other hand, in most cases except competitions, even simple solutions provide pretty good results.\n\n**Thank you for your attention !**","1f795799":"#### Flatten features (for Dense NN) and label encoding","21d79326":"#### Baseline metrics and score","fa759f63":"### Augmentation of dirty data","169662ce":"#### Build new CNN model and fit it in on **fully** augmented data","c91397cb":"Train \/ validation splitting","35f3ac3e":"Expectedly, the score is better (about 99%) compared to Dense NN.<br>\nBut some of images are still not recognized correctly:","6b911fd5":"Accuracy was not increased (in my run even decreased), it did not help.<br>\nBut what about CNN ?","09d4bf4b":"My idea of partial data augmentation is to add more of the **dirty data** to the training set, not all of it. To do this, I will train the model on the **training** set to see which images from the training set the model considers bad.<br>\nThen I will extract that data from the training set, repeat it several times, distort it a little bit, and add it back to the training set.","40486a21":"### Convolutional NN","e3ae2e35":"#### Scores distributed by networks","32abaa79":"#### Plot selected array of images","18cf338e":"Here I have to use Keras ImageDataGenerator in \"manual\" mode because I need to get numpy array with new augmented data.<br>\nUnfortunately I could not find any simpler way to do this other than with *for* loop. Likely it runs not to long.","47193fe5":"To save machine time I will use 28x28px grayscale images in two sets (60.000 \/ 10.000) kindly provided by Keras.<br>\nImages are providing as numpy arrays.","0dd38e7f":"#### CNN metrics and score on augmented data","b9665f74":"#### Fit convolutional model on a new data","83bb708a":"#### Scaling"}}