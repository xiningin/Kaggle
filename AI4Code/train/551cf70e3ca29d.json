{"cell_type":{"b9f246a7":"code","b9f319cb":"code","97586ff3":"code","934df947":"code","b35344ae":"code","10cfd7fb":"code","3375b38f":"code","511e854f":"code","7c218926":"code","3d8f75a3":"code","5a4d2448":"code","094be50c":"code","c65079cd":"code","8e1f67a2":"code","da50d3c4":"code","f8e6c222":"code","735fc484":"code","16ca938b":"code","f4ff71f1":"code","1247ebb9":"code","bf55cb6a":"code","a4b58eee":"code","2d87d9bd":"code","f6544bd7":"code","eab78486":"code","c1a840d9":"code","fdc7424b":"code","ac540727":"code","05ba3c67":"code","507c215c":"code","a46e1a98":"code","e89aa81c":"code","533de934":"code","c70e8fa5":"code","8265782e":"code","799b194e":"code","a47ea63a":"code","320e5d3e":"code","b4e27a69":"code","94fab187":"code","7c16df0e":"code","f2dd34aa":"code","7e9793d7":"code","d4d28470":"code","fd9a4064":"code","c73a7722":"code","4fb3bcec":"code","2be14972":"code","f1bdb25a":"markdown","af0b2a82":"markdown","eacc8712":"markdown","4338d988":"markdown","ae47f8da":"markdown","2aae7028":"markdown","2d802b74":"markdown","3c249d2d":"markdown","fad0efd2":"markdown","949fa8ee":"markdown","ee0fd2dd":"markdown","eb33e26c":"markdown","557e0ce0":"markdown","28495ff3":"markdown","8d4d6f6a":"markdown","82501c90":"markdown","d14ee75d":"markdown","ec6d8852":"markdown"},"source":{"b9f246a7":"#from atom import ATOMClassifier, ATOMModel\n\nimport logging\nimport tensorflow as tf\ntf.get_logger().setLevel(logging.ERROR)\n\n# Import standard packages\nfrom skopt.space.space import Integer, Categorical\n\n# Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D\nfrom keras.wrappers.scikit_learn import KerasClassifier","b9f319cb":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import array_to_img\n\nimport os\nimport glob\n\n\npd.options.display.max_columns = None\nsns.set(font_scale=1.4)\nsns.set_style({'font.family': 'serif',\n               'fontname': 'Times New Roman'})\nmpl.rcParams['figure.dpi'] = 100\n\n%matplotlib inline \n\ndicti = {0:'neut',1:'happ',2:'sad',3:'surp',4:'fear',5:'dist',6:'ang',7:'contp'}\nrotulos = [dicti[0],dicti[1],dicti[2],dicti[3],dicti[4],dicti[5],dicti[6],dicti[7]]","97586ff3":"dt = pd.read_csv(\"..\/input\/affectnetsample\/train-sample-affectnet.csv\",index_col=0)\ndt.shape","934df947":"sns.countplot(dt['emotion'])","b35344ae":"dt.head()","10cfd7fb":"tamanho = 64","3375b38f":"import time\nfrom skimage import io\nfrom sklearn import preprocessing\nfrom skimage.transform import resize\nfrom skimage.color import rgb2gray\nfrom sklearn.model_selection import train_test_split\n\ndef preparing_image(address):\n    retornar = preprocessing.normalize(resize(rgb2gray(io.imread(address)),(tamanho, tamanho)),norm='l2')\n    retornar = resize(rgb2gray(io.imread(address)),(tamanho, tamanho))\n    return retornar\n\n\ndef get_ETL_of_images(dt,tamanho):\n    start_time = time.time()\n    if ('data_64_X.npy' not in os.listdir()):\n        \n        name = 'data_'+str(tamanho)+'_' \n        print(\"...Generating databases...\")\n        \n        y = None\n        X = None\n        \n        # Seleciona imagens\n        np.random.seed(0)\n        rows_selected = np.random.randint(37553,size=2500)\n        dt_selected = dt.iloc[rows_selected]\n\n        for row in dt_selected.itertuples():\n            y = [row.emotion] if y is None else np.concatenate( (y,[row.emotion]))\n            x = preparing_image(row.image)\n            X = [x] if X is None else np.concatenate( (X,[x]))\n\n           \n        with open(name+'X.npy', 'wb') as file:\n            np.save(file,X)\n        with open(name+'y.npy', 'wb') as file:\n            np.save(file,y)\n        \n        all_time = time.time() - start_time\n        if all_time > 60: print(\"{:.2f} minutes \".format(all_time\/60))\n        else: print(\"{:.2f} seconds \".format(all_time))\n                  \n        print(f'\\n!! Base {name} completed !!')\n        return (X,y)\n    else:\n        \n        name = 'data_'+str(tamanho)\n        print(\"...Reading databases...\")\n        \n        print(name+'_X.npy')\n        print(name+'_y.npy')\n        if tamanho == 64:\n            with open(name+'_X.npy', 'rb') as file:\n                X = np.load(file) \n            with open(name+'_y.npy', 'rb') as file:\n                y = np.load(file) \n            print(\"..Database X_34 Lido\")\n            \n        elif tamanho == 32:\n            with open(name+'X.npy', 'wb', 'rb') as file:\n                X = np.load(file) \n            with open(name+'y.npy', 'rb') as file:\n                y = np.load(file) \n            print(\"..Database X_32 Lido\")\n        #                      \n        all_time = time.time() - start_time\n        if all_time > 60: print(\"{:.2f} minutes \".format(all_time\/60))\n        else: print(\"{:.2f} seconds \".format(all_time))\n        print(f'\\n!! Base {name} completed !!')\n        return (X,y)\n        ","511e854f":"X , y = get_ETL_of_images(dt,tamanho)\nprint(f'Shape of X : {X.shape} \\nShape of Y : {y.shape}')","7c218926":"fig, ax = plt.subplots(3, 5,figsize=(8,7))\n\nfor i, axi in enumerate(ax.flat):\n    axi.imshow(X[i], cmap='bone')\n    axi.set(xticks=[], yticks=[], xlabel=dicti[y[i]-1])","3d8f75a3":"dt_train = dt[0:50].copy()\n\nimagem = io.imread(dt_train['image'][0])\n#imagem_2 = io.imread(dt_test['image'][0])\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(25,10))\n\nprint(\"****Imagem 1****\")\n\nbefore1 = imagem.copy()\nax[0].imshow(before1)\nax[0].set_title(\"Original\")\n\n\ngrayscale1 = rgb2gray(imagem)\nax[1].imshow(grayscale1, cmap=plt.cm.gray)\nax[1].set_title(\"GrayScale\")\n\nrescaled1_64 = resize( grayscale1,(64,64) ) \nax[2].imshow(rescaled1_64, cmap=plt.cm.gray)\nax[2].set_title(\"Rescaled(64x64)\")\n\nrescaled1_32 = resize( grayscale1,(32,32) ) \nax[3].imshow(rescaled1_32, cmap=plt.cm.gray)\nax[3].set_title(\"Rescaled(32x32)\")","5a4d2448":"from sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline","094be50c":"X_1D = X.reshape(X.shape[0],tamanho*tamanho)\nprint(f'Shape of X    : {X.shape} - Shape of Y : {y.shape}'+\n     f'\\nShape of X_1D : {X_1D.shape}   - Shape of Y : {y.shape}')","c65079cd":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndata_rescaled = scaler.fit_transform(X_1D)\npca = PCA().fit(data_rescaled)\n\n#-----------PLOT--------\nplt.rcParams[\"figure.figsize\"] = (8,6)\n#\nfig, ax = plt.subplots()\nxi = np.arange(0, 2000, step=250)\ny_pca = np.cumsum(pca.explained_variance_ratio_[[np.arange(0,2000,250)]])\n#\nplt.ylim(0.0,1.1)\nplt.plot(xi, y_pca, marker='o', linestyle='--', color='b')\n#\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 2000, step=250)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n#\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n#\nax.grid(axis='x')\n\nplt.show()","8e1f67a2":"pca = PCA(n_components = 150, whiten='True', random_state=0)\n\nsvc = SVC(kernel='rbf')\n\nmodel = make_pipeline(pca, svc)\nX_pca = pca.fit_transform(X_1D)\nX_pca.shape","da50d3c4":"X_pca = X_pca.reshape(X_1D.shape[0], 15,10)\n\nfig, ax = plt.subplots(3, 5,figsize=(8,7))\nfor i, axi in enumerate(ax.flat):\n    axi.imshow(X_pca[i], cmap='bone')\n    axi.set(xticks=[], yticks=[], xlabel=dicti[y[i]-1])","f8e6c222":"Xtrain, Xtest, ytrain, ytest = train_test_split(\n    X_1D, y, random_state=0)","735fc484":"from sklearn.model_selection import GridSearchCV\n\n# fine tuning\n\nparam_grid = {'svc__C': [1, 5, 10, 50],\n              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n\n# param_grid = {'svc__C': [9.8, 10, 10.2],\n#               'svc__gamma': [0.0009, 0.001, 0.0011]}\n\ngrid = GridSearchCV(model, param_grid, cv=5)\n\ngrid.fit(Xtrain, ytrain)\n\nprint(grid.best_params_)","16ca938b":"model_best = grid.best_estimator_\nprint(model_best)","f4ff71f1":"y_pred = model_best.predict(Xtest)","1247ebb9":"fig, ax = plt.subplots(4, 6, figsize=(13,7))\n\nfor i, axi in enumerate(ax.flat):\n    axi.imshow(Xtest[i].reshape(64, 64), cmap='bone')\n    axi.set(xticks=[], yticks=[])\n    axi.set_ylabel(dicti[y_pred[i]-1],\n                   color='black' if y_pred[i] == ytest[i] else 'red')\n    \nfig.suptitle('Erros', size=24,color='red');","bf55cb6a":"fig,ax=plt.subplots(1,1,figsize=(8,8))\nax.imshow(pca.mean_.reshape((tamanho,tamanho)), cmap=\"gray\")\nax.set_xticks([])\nax.set_yticks([])\nfig.suptitle('Average Face')","a4b58eee":"from sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(ytest, y_pred)\n\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=rotulos,\n            yticklabels=rotulos)\nplt.xlabel('True label')\nplt.ylabel('Predicted label');","2d87d9bd":"from sklearn.metrics import classification_report\n\nprint(classification_report(ytest, y_pred, target_names=rotulos))","f6544bd7":"y.min()","eab78486":"y_int = [ int(num)-1 for num in y ] \ny_lda = pd.Categorical.from_codes(y_int, rotulos)\ny_lda","c1a840d9":"dt_frame = pd.DataFrame(np.array(X_1D))\ncol_class = pd.DataFrame([dicti[int(num)-1] for num in y],columns=['class'])\ndt_frame = pd.concat([dt_frame,col_class],axis=1)\n#dt_frame.columns = [ i for i in range(len(dt_frame.columns))]\nprint(dt_frame.shape)\ndt_frame.head()","fdc7424b":"class_feature_means = pd.DataFrame(columns=rotulos)\nfor c, rows in dt_frame.groupby('class'):\n#     print(rows.shape)\n#     #print(rows.values)\n#     print(rows.index[0])\n#     print(rows.values[0][4096])\n#     print(\"\\n\\n\")\n\n    class_feature_means[c] = rows.mean()\n\nclass_feature_means.head()","ac540727":"within_class_scatter_matrix = np.zeros((4096 ,4096))\nfor c, rows in dt_frame.groupby('class'):\n    rows = rows.drop(['class'], axis=1)\n    \n    s = np.zeros((4096 ,4096 ))\n    for index, row in rows.iterrows():\n            x, mc = row.values.reshape(4096,1), class_feature_means[c].values.reshape(4096,1)\n            #print(x.shape,mc.shape)\n            s += (x - mc).dot((x - mc).T)\n           \n    within_class_scatter_matrix += s","05ba3c67":"feature_means = dt_frame.mean()\nbetween_class_scatter_matrix = np.zeros((4096,4096))\nfor c in class_feature_means:    \n    n = len(dt_frame.loc[dt_frame['class'] == c].index)\n    mc, m = class_feature_means[c].values.reshape(4096,1), feature_means.values.reshape(4096,1)\n    between_class_scatter_matrix += n * (mc - m).dot((mc - m).T)","507c215c":"eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(within_class_scatter_matrix).dot(between_class_scatter_matrix))","a46e1a98":"pairs = [(np.abs(eigen_values[i]), eigen_vectors[:,i]) for i in range(len(eigen_values))]\npairs = sorted(pairs, key=lambda x: x[0], reverse=True)\nfor pair in pairs[:5]:\n    print(pair[0])","e89aa81c":"eigen_value_sums = sum(eigen_values)\nprint('Explained Variance')\nfor i, pair in enumerate(pairs[:5]):\n    print('Eigenvector {}: {}'.format(i, (pair[0]\/eigen_value_sums).real))","533de934":"w_matrix = np.hstack((pairs[0][1].reshape(4096,1), pairs[1][1].reshape(4096,1))).real","c70e8fa5":"X_lda = np.array(X_1D.dot(w_matrix))\nX_lda.shape","8265782e":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA \nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny_lda = le.fit_transform(y)","799b194e":"plt.xlabel('LD1')\nplt.ylabel('LD2')\nplt.grid(False)\nplt.scatter(\n    X_lda[:,0],\n    X_lda[:,1],\n    c=y,\n    cmap='rainbow',\n    alpha=0.7,\n    edgecolors='b'\n)","a47ea63a":"lda = LDA()\nX_lda = lda.fit_transform(X_1D, y)\nlda.explained_variance_ratio_","320e5d3e":"plt.xlabel('LD1')\nplt.ylabel('LD2')\nplt.grid(False)\nplt.scatter(X_lda[:,0],\n    X_lda[:,1],\n    c=y,\n    cmap='rainbow',\n    alpha=0.7,\n    edgecolors='b'\n)","b4e27a69":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, ytrain, ytest = train_test_split(X_lda, y, random_state=0)","94fab187":"le = LabelEncoder()\ny_le = le.fit_transform(y)\n#\nlda = LDA()\n# X_train = lda.fit_transform(X_train, y_train)\n# X_test = lda.transform(X_test)\nmodel2 = make_pipeline(lda, svc)\nX_lda = lda.fit_transform(X_1D,y_le)","7c16df0e":"lda.explained_variance_ratio_","f2dd34aa":"grid = GridSearchCV(model2, param_grid, cv=5)\n\ngrid.fit(Xtrain, ytrain)\n\nprint(grid.best_params_)","7e9793d7":"model_best = grid.best_estimator_\nprint(model_best)","d4d28470":"y_pred = model_best.predict(Xtest)","fd9a4064":"from sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(ytest, y_pred)\n\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=rotulos,\n            yticklabels=rotulos)\nplt.xlabel('True label')\nplt.ylabel('Predicted label');","c73a7722":"from sklearn.metrics import classification_report\n\nprint(classification_report(ytest, y_pred, target_names=rotulos))","4fb3bcec":"from skimage.feature import Cascade\nfrom skimage import data\nfrom matplotlib import patches\n\n# Load the trained file from the module root.\ntrained_file = data.lbp_frontal_face_cascade_filename()\n\n# Initialize the detector cascade.\ndetector = Cascade(trained_file)\n\nimg = rescaled1_64.copy()\n\n\ndetected = detector.detect_multi_scale(img=img,\n                                       scale_factor=1.2,\n                                       step_ratio=1,\n                                       min_size=(4, 4),\n                                       max_size=(64, 64))\nplt.imshow(img)\nimg_desc = plt.gca()\nplt.set_cmap('gray')\n\nfor patch in detected:\n\n    img_desc.add_patch(\n        patches.Rectangle(\n            (patch['c'], patch['r']),\n            patch['width'],\n            patch['height'],\n            fill=False,\n            color='r',\n            linewidth=1.5\n        )\n    )  \nplt.grid(False)\nplt.show()","2be14972":"cropped = img[detected[0]['c']:detected[0]['width'],detected[0]['r']:detected[0]['height']]\nplt.grid(False)\nplt.imshow(cropped)\nprint(cropped.shape)    ","f1bdb25a":"### Links\n*  <a src=\"https:\/\/towardsdatascience.com\/linear-discriminant-analysis-in-python-76b8b17817c2\">LDA<\/a>              \n*  <a src=\"https:\/\/www.kaggle.com\/gauravsharma99\/facial-emotion-recognition\">References<\/a> \n*  <a src=\"https:\/\/www.kaggle.com\/mouadriali\/affectnetsample?rvi=1\">DataSet of Images <\/a>","af0b2a82":"### PCA & SVM","eacc8712":"### ETL de Imagens","4338d988":"* Scroll through all images\n     * Extract face\n     * Generate new column\n     * Calculate the smallest and largest shape\n         * Set a fixed cut size for everyone","ae47f8da":"# Import\n* Packages\n* Definition of Emotions\n* Define labels for each Emotion\n* First Analyzes","2aae7028":"#### SVM","2d802b74":"### Parameters","3c249d2d":"#### Parameters","fad0efd2":"## Future Improvements\n* ### View images by delimiting face","949fa8ee":"<h1 style=\"font-family: Verdana\">Goal<\/h1>\n<p style=\"font-family: Verdana\">I am implementing LDA and PCA to SVM<\/p>\n<p style=\"font-family: Verdana\"> SVM results contain overfitting to LDA, and underfitting to PCA <\/p>\n<p style=\"font-family: Verdana\">This notebook is my first implementation using that methods, i intend to improve and keep fixing or adding better results<\/p>","ee0fd2dd":"## LDA & SVM","eb33e26c":"# Data processing\n* #### Choose Image Size\n    * (64,64) or (32,32) , so just type 64 \n* #### ETL of Images\n    * Read Imagem\n    * Reasize as 'tamanho'(size) choosed\n    * Convert to Grayscale\n    * Normalize each image\n    * View Process performed","557e0ce0":"The best parameters","28495ff3":"#### SVM\n* Scores\n* Confusion Matrix","8d4d6f6a":"<a>https:\/\/www.mikulskibartosz.name\/pca-how-to-choose-the-number-of-components\/<\/a>","82501c90":"# Pre-Processing\n### PCA & SVM\n* Parameters\n* Grid Search\n* SVM\n\n### LDA & SVM\n* Parameters\n* SVM","d14ee75d":"# View Process performed","ec6d8852":"#### GridSearchCV"}}