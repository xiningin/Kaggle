{"cell_type":{"75a49395":"code","a7820b0a":"code","43283c9a":"code","db328ab7":"code","47514c95":"code","8b0b17ca":"code","125da6da":"code","99f8b6ca":"code","894b6b4d":"code","f8c33652":"code","5e4f2e4d":"code","8aea3e77":"code","6f355e91":"code","15bc2e3f":"code","b38f28b5":"code","d9aa56ac":"markdown","bab5b3a6":"markdown","e1da9676":"markdown","7b8527fb":"markdown","025acbcb":"markdown","559269a5":"markdown","b39743ea":"markdown","03fe44cb":"markdown","9904677c":"markdown","13114d2f":"markdown","a613e977":"markdown","e46f1973":"markdown","6a2998e7":"markdown","6924f1fa":"markdown","459bd11e":"markdown","da23a0b3":"markdown","245bb1f8":"markdown","1579511c":"markdown","c8f43e9d":"markdown","bfed8263":"markdown","e28bb19f":"markdown","5b07bac4":"markdown","83e2f258":"markdown"},"source":{"75a49395":"from keras.preprocessing.image import ImageDataGenerator","a7820b0a":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","43283c9a":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input","db328ab7":"## get the data\n#!wget https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/DL0321EN\/data\/concrete_data_week3.zip","47514c95":"#!unzip concrete_data_week3.zip","8b0b17ca":"num_classes = 2\nimage_resize = 224\nbatch_size_training = 300\nbatch_size_validation = 300","125da6da":"data_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n)","99f8b6ca":"train_generator = data_generator.flow_from_directory(\n    '..\/input\/concrete-cracks\/concrete_data_week3\/train',\n    target_size=(image_resize, image_resize),\n    batch_size=batch_size_training,\n    class_mode='categorical')","894b6b4d":"validation_generator = data_generator.flow_from_directory(\n    '..\/input\/concrete-cracks\/concrete_data_week3\/valid',\n    target_size=(image_resize, image_resize),\n    batch_size=batch_size_validation,\n    class_mode='categorical')\n","f8c33652":"steps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(validation_generator)\nnum_epochs = 1","5e4f2e4d":"base_model = ResNet50(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=(224, 224, 3),\n    include_top=False,\n    pooling='avg')  # Do not include the ImageNet classifier at the top.\n\n# Freeze the base model\nbase_model.trainable = False\n\ninputs = keras.Input(shape=(224, 224, 3))\n# We make sure that the base_model is running in inference mode here,\n# by passing `training=False`. This is important for fine-tuning, as you will\n# learn in a few paragraphs.\nx = base_model(inputs, training=False)\n# Convert features of shape `base_model.output_shape[1:]` to vectors\noutputs = keras.layers.Dense(num_classes, activation='softmax')(x)\nmodel = keras.Model(inputs, outputs)","8aea3e77":"model.summary()","6f355e91":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nsteps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(validation_generator)\nnum_epochs = 2","15bc2e3f":"fit_history = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch_training,\n    epochs=num_epochs,\n    validation_data=validation_generator,\n    validation_steps=steps_per_epoch_validation,\n    verbose=1,\n)","b38f28b5":"model.save('classifier_resnet_model.h5')","d9aa56ac":"Next, we will use the _flow_from_directory_ method to get the training images as follows:\n","bab5b3a6":"## Build, Compile and Fit Model\n","e1da9676":"Now that the model is trained, you are ready to start using it to classify images.\n\nSince training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n","7b8527fb":"Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n","025acbcb":"Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n","559269a5":"## Import Libraries and Packages\n","b39743ea":"For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n","03fe44cb":"In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n","9904677c":"First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n","13114d2f":"Here, we will define constants that we will be using throughout the rest of the lab. \n\n1.  We are obviously dealing with two classes, so _num_classes_ is 2. \n2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n3.  We will be training and validating the model using batches of 100 images.\n","a613e977":"## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                                    |\n| ----------------- | ------- | ---------- | --------------------------------------------------------------------- |\n| 2021-06-18        | 2.0     | AdN        | Cleaned Code. Implemented Sequential Style for model building         |\n| 2021-06-14        | 1.0     | AdN        | First Commit                                                          |","e46f1973":"Now, you should see the folder _concrete_data_week3_ appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: _train_ and _valid_. And if you explore these folders, you will find that each contains two subfolders: _positive_ and _negative_. These are the same folders that we saw in the labs in the previous modules of this course, where _negative_ is the negative class and it represents the concrete images with no cracks and _positive_ is the positive class and it represents the concrete images with cracks.\n","6a2998e7":"In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to _preprocess_input_ which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n","6924f1fa":"Now, you should see the model file _classifier_resnet_model.h5_ apprear in the left directory pane.\n","459bd11e":"## Define Global Constants\n","da23a0b3":"## Objective\n","245bb1f8":"Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n","1579511c":"## Download Data\n","c8f43e9d":"**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the _negative_ and _positive_ folders. This may consume all of your memory and you may end up with a **50\\*** error. So please **DO NOT DO IT**.\n","bfed8263":"## Construct ImageDataGenerator Instances\n","e28bb19f":"<hr>\n\nCopyright \u00a9 2020 [IBM Developer Skills Network](https:\/\/cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). This notebook and its source code are released under the terms of the [MIT License](https:\/\/bigdatauniversity.com\/mit-license?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n","5b07bac4":"In this notebook, a pre-trained models will be used for transfer learning. An image classifier will be developed, taking use of the ResNet50 model, only the last dense layer will be trained, instead of building it model from scratch.\n\nMore info in the Keras [blog](https:\/\/keras.io\/guides\/transfer_learning\/)","83e2f258":"And now if you check the left directory pane, you should see the zipped file _concrete_data_week3.zip_ appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running.\n"}}