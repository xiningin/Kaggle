{"cell_type":{"e64cf01f":"code","dbeae0f1":"code","6df7729e":"code","01a72f73":"code","af3b2c0a":"code","60eb9d10":"code","50fba602":"markdown","19a7ce53":"markdown","a3911890":"markdown","bf150e54":"markdown","64aecbf8":"markdown","d1f9f187":"markdown"},"source":{"e64cf01f":"!pip install scikit-video","dbeae0f1":"!git clone https:\/\/github.com\/aqeel13932\/APES.git\n%cd APES","6df7729e":"!python Performance.py","01a72f73":"from APES import *\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom time import time\nimport pylab as pl\nfrom IPython import display\nimport skvideo.io\n# Set the dimension for each block ( affect the generated image quality)\nSettings.SetBlockSize(100)","af3b2c0a":"perf = {'sub':(2,1),'dom':(2,10),'food':(3,4),'obs':(3,5),'subdir':'W','domdir':'E','mesg':'example'}\ngame = CreateEnvironment(perf)\n\nagents = [game.agents[i] for i in game.agents]\n\ngame.Step()\nenv_initial = game.BuildImage()\n\n#Execute every time step\nagents[0].NextAction = Settings.PossibleActions[2]\nagents[1].NextAction = Settings.PossibleActions[3]\n\ngame.Step()\nenv_1step = game.BuildImage()\n\nfig,ax = plt.subplots(nrows=1,ncols=2)\nax[0].imshow(env_initial)\nax[1].imshow(env_1step)\nfig.set_figheight(15)\nfig.set_figwidth(15)\nplt.show()","60eb9d10":"#Add pictures for items\nSettings.AddImage('Wall','APES\/Pics\/wall.jpg')\nSettings.AddImage('Food','APES\/Pics\/food.jpg')\n\n#Create Probability distribution matrices (PDMs)\nobs_pdm = np.zeros(Settings.WorldSize)\nagnts_pdm = np.zeros(Settings.WorldSize)\nfood_pdm = np.zeros(Settings.WorldSize)\n\n# Obstacles can appear from 3rd to 7th row and 5th column\nobs_pdm[3:8,5] = 1 \nagnts_pdm[2,[0,10]] = 1\nfood_pdm[:,4:7] = 1\n\n#Add PDMs to Settings\nSettings.AddProbabilityDistribution('Obs_pdm',obs_pdm) \nSettings.AddProbabilityDistribution('agnts_pdm',agnts_pdm)\nSettings.AddProbabilityDistribution('food_pdm',food_pdm)\n\n#Create World Elements\n#Create vertical obastacle with length 4\nobshape = np.ones((4,1))\nobs = Obstacles('Wall',Shape=obshape,PdstName='Obs_pdm')\n\n#Create two agents\nragnt = Agent(Fname='APES\/Pics\/red.jpg',PdstName='agnts_pdm')\nbagnt = Agent(Fname='APES\/Pics\/blue.jpg',PdstName='agnts_pdm')\nfood = Foods('Food',PdstName='food_pdm')\n\n#Reward food by 10, time step by -0.1\ngame = World(RewardsScheme=[0,10,-0.1])\n\n#Adding Agents in Order of Following the action\ngame.AddAgents([ragnt,bagnt])\ngame.AddObstacles([obs])\ngame.AddFoods([food])\n\n#Execute at the beginning of every episode\ngame.GenerateWorld()\ngame.Step()\nenv_initial = np.concatenate([game.BuildImage(),\n                              game.AgentViewPoint(ragnt.ID),\n                              game.AgentViewPoint(bagnt.ID)],axis=1)*255\n\nwriter = skvideo.io.FFmpegWriter(\"output.mp4\")\nwriter.writeFrame(env_initial)\n\n#Execute every time step\nwhile not game.Terminated[0]:\n    bagnt.DetectAndAstar()\n    ragnt.DetectAndAstar()\n    game.Step()\n    env_1step = np.concatenate([game.BuildImage(),\n                                game.AgentViewPoint(ragnt.ID),\n                                game.AgentViewPoint(bagnt.ID)],axis=1)*255\n    writer.writeFrame(env_1step)\nwriter.close()\n\nfig,ax = plt.subplots(nrows=1,ncols=2)\nax[0].imshow(env_initial\/255)\nax[1].imshow(env_1step\/255)\nfig.set_figheight(15)\nfig.set_figwidth(15)\nplt.show()","50fba602":"### Complex Example\nLaunching the below cell will generate a video file \"output.mp4\" contains the episode. The video has three perspectives next to each other in every frame: <br \/>\n\n1. The fully observed environment.\n2. The environment as seen from the red agent point of view\n3. The environment as seen from the blue agent point of view","19a7ce53":"### Simple Example","a3911890":"## Repro [Github](https:\/\/github.com\/aqeel13932\/APES)","bf150e54":"## Installation","64aecbf8":"# Artificial Primate Environment Simulator","d1f9f187":"## Example"}}