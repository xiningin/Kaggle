{"cell_type":{"0fcda1d3":"code","b3a9ea67":"code","d7696de6":"code","059e5907":"code","226fdfc7":"code","d9af168e":"code","2839b6cb":"code","1b8f3489":"code","b914207e":"code","bd1f2bab":"code","718889a6":"code","3c1bad5f":"code","452ece71":"code","104aa990":"code","eaa5d8a3":"code","ad97b283":"code","9a212d04":"code","466a2fa3":"code","8606d829":"code","cc795d59":"code","7b3cf9f5":"code","2e3b9be3":"code","39c483bb":"code","d0aa1340":"code","e19f2c15":"code","4594d553":"code","07053d94":"code","337e47d2":"code","e0dd5a08":"code","57ec7c63":"code","067843f6":"code","f5270bee":"code","620276dc":"code","d0aa408c":"code","89e8677b":"code","dacb7106":"code","b57620c3":"code","08873ba9":"code","edf5046f":"markdown"},"source":{"0fcda1d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b3a9ea67":"pd.read_csv('\/kaggle\/input\/sars-coronavirus-accession\/SARS_CORONAVIRUS_287BP_MN975263.1_accession_nucleotide.csv')","d7696de6":"data = pd.read_csv('\/kaggle\/input\/sars-coronavirus-accession\/MN997409.1-4NY0T82X016-Alignment-HitTable.csv')","059e5907":"data.head()","226fdfc7":"data = data.rename(columns={\"MN997409.1\": \"query acc.ver\", \"MN997409.1.1\": \"subject acc.ver\",\n                            \"100.000\":\"% identity\",\"29882\":\"alignment length\",\"0\":\"mismatches\",\n                            \"0.1\":\"gap opens\",\"1\":\"q. start\",\"29882.1\":\"q. end\",\"1.1\":\"s. start\",\n                           \"29882.2\t\":\"s. end\",\"0.0\":\"evalue\",\"55182\":\"bit score\"})","d9af168e":"data","2839b6cb":"data = data.append(pd.Series(['MN997409.1',\t'MN997409.1.1',\t\n                    100.000,\t29882,\t\n                    0,\t0.1,\t1,\t29882.1,\t\n                    1.1,\t29882.2,\t0.0,\t55182], index=data.columns), ignore_index=True)","1b8f3489":"data.tail()","b914207e":"data","bd1f2bab":"data.shape","718889a6":"data.describe()","3c1bad5f":"data.corr()","452ece71":"plt.figure(figsize=(14,8))\nsns.heatmap(data.corr(), vmax=1, square=True,annot=True,cmap='viridis')\n\nplt.title('Correlation between different fearures')","104aa990":"from sklearn.cluster import KMeans","eaa5d8a3":"data['subject acc.ver'] = data['subject acc.ver'].astype(\"category\").cat.codes","ad97b283":"data.head()","9a212d04":"X = data.iloc[:,1:].values","466a2fa3":"from sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm","8606d829":"from sklearn.preprocessing import StandardScaler\nstandardized_data = StandardScaler().fit_transform(X)\nprint(standardized_data.shape)","cc795d59":"range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\nsilohuette_scores = []\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n    silohuette_scores.append(silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","7b3cf9f5":"silohuette_scores = [float(i) for i in silohuette_scores]","2e3b9be3":"silohuette_scores","39c483bb":"plt.figure(figsize=(6,6))\nsns.barplot([2,3,4,5,6,7,8,9,10],\n            [0.6051456304424345,\n 0.7737574709178652,\n 0.9304299438199628,\n 0.9626586534510194,\n 0.9625756535242548,\n 0.9585239650538647,\n 0.9614207899227608,\n 0.9626169262248865,\n 0.9644636830559539],palette='viridis')\nplt.xlabel('Clusters')\nplt.ylabel('Silhouette Score')","d0aa1340":"clusterer = KMeans(n_clusters=5, random_state=10)\ncluster = clusterer.fit(X).labels_","e19f2c15":"cluster","4594d553":"from sklearn.preprocessing import StandardScaler\nplt.figure(figsize=(15,4))\nscaler = StandardScaler()\nsns.heatmap(scaler.fit(cluster.cluster_centers_).transform(cluster.cluster_centers_)\n            ,annot=True,xticklabels = data.columns.drop('query acc.ver'),yticklabels=['Cluster 1',\n                                                            'Cluster 2',\n                                                            'Cluster 3',\n                                                            'Cluster 4',\n                                                            'Cluster 5',])","07053d94":"covar_matrix = np.matmul(standardized_data.T , standardized_data)","337e47d2":"covar_matrix.shape","e0dd5a08":"from scipy.linalg import eigh ","57ec7c63":"#top2 eigenvalue\nvalues, vectors = eigh(covar_matrix, eigvals=(9,10))","067843f6":"vectors.shape","f5270bee":"#transpose\nvectors = vectors.T\nvectors.shape","620276dc":"new_coordinates = np.matmul(vectors, standardized_data.T)\nprint (\"Resultant at new data shape: \", vectors.shape, \"*\", standardized_data.T.shape,\" = \", new_coordinates.shape)","d0aa408c":"new_coordinates = np.vstack((new_coordinates)).T\n\ndf = pd.DataFrame(data=new_coordinates, columns=(\"1st_principal\", \"2nd_principal\"))\nprint(df.head())","89e8677b":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca.fit_transform(X)","dacb7106":"plt.figure(figsize=(15,2.5))\nsns.heatmap(pca.components_,annot=True,xticklabels = data.columns.drop('query acc.ver'),yticklabels=['Component 1','Component 2'])\nplt.title('Principal Component Linear Coefficients of Columns')","b57620c3":"sns.set(style='whitegrid')\nplt.figure(figsize=(6,6))\nsns.scatterplot(X[:,0],X[:,1],hue=cluster,palette='coolwarm')\n#sns.FacetGrid(df, size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\nplt.title('PCA Visualization of Sequences')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.show()","08873ba9":"pca.explained_variance_ratio_.sum()","edf5046f":"# K-Means Clustering\n\nWe will see the genome information clusters"}}