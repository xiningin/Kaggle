{"cell_type":{"0d63f8d9":"code","3e5eaf1e":"code","8c73f0b8":"code","dd21395c":"code","4a0c7554":"code","bdb6565a":"code","2902e6aa":"code","c17a6edb":"code","537fe562":"code","45504f37":"code","0835eec7":"code","de131c1e":"code","8e591ddc":"code","865208b5":"code","bf380acb":"code","d7a63c30":"code","710434ca":"code","b567af5b":"code","4db144a4":"code","2b988ecb":"code","7015fe9d":"code","e9f572ed":"code","bd547bb2":"code","d6b5307c":"code","1e7c579d":"code","381903cf":"code","48595f84":"code","b18692ba":"code","7a026a9e":"code","1207712e":"code","a0056025":"code","c792c5c8":"code","bca4f87e":"code","33d5aae1":"code","0c6c625c":"code","63af5eb4":"code","db025759":"code","ed0a7b96":"code","3fcea782":"code","c8312188":"code","c7b7eba7":"code","0697862f":"code","a5c44139":"code","80ef5299":"code","05d034e2":"code","adbe4418":"code","74c4ec76":"markdown","aab11c2c":"markdown","862fb812":"markdown","32a4bd5e":"markdown","548ffb77":"markdown","423f9831":"markdown"},"source":{"0d63f8d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e5eaf1e":"df = pd.read_csv('\/kaggle\/input\/ramen-ratings\/ramen-ratings.csv')","8c73f0b8":"df.head()","dd21395c":"df = df.drop(columns=['Top Ten'])","4a0c7554":"df.isnull().sum()","bdb6565a":"df = df.dropna()","2902e6aa":"df.isnull().sum()","c17a6edb":"df.describe()","537fe562":"x = df.drop(columns=['Style'])\nx","45504f37":"y = df['Style']\ny","0835eec7":"import matplotlib.pyplot as plt\n# create figure and axis\nfig, ax = plt.subplots()\n# plot histogram\nax.hist(df['Style'])\n# set title and labels\nax.set_title('Style of Presenting')\nax.set_xlabel('Types')\nax.set_ylabel('Frequency')","de131c1e":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder()  \nx= x.apply(label_encoder.fit_transform)\nx","8e591ddc":"y= label_encoder.fit_transform(y)\ny","865208b5":"import seaborn as sns","bf380acb":"sns.jointplot(x=x['Brand'], y=x['Stars'], kind=\"kde\")","d7a63c30":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"Country\", y=\"Brand\", data=x)","710434ca":"features=['Style', 'Country'] # Subplot for count plot\nfig=plt.subplots(figsize=(25,20))\nfor i, j in enumerate(features):\n    plt.subplot(4, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sns.countplot(x=j,data = df)\n    plt.xticks(rotation=90)\n    plt.title(\"Ramen\")\n    \nplt.show()","b567af5b":"import seaborn as sns\nsns.kdeplot(data=x['Country'], shade=True)","4db144a4":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","2b988ecb":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)","7015fe9d":"# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n\n# fit scaler on training data\nnorm = MinMaxScaler().fit(x_train)\n\n# transform training data\nX_train_norm = norm.transform(x_train)\n\n\n# transform testing dataabs\nX_test_norm = norm.transform(x_test)\n","e9f572ed":"# fit scaler on training data\nnorm = MinMaxScaler().fit(x_train)\n\n# transform training data\nX_train_norm = norm.transform(x_train)\nprint(\"Scaled Train Data: \\n\\n\")\nprint(X_train_norm)","bd547bb2":"# transform testing dataabs\nX_test_norm = norm.transform(x_test)\nprint(\"\\n\\nScaled Test Data: \\n\\n\")\nprint(X_test_norm)","d6b5307c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","1e7c579d":"from sklearn.tree import DecisionTreeClassifier\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier()\n# Train Decision Tree Classifer\nclf.fit(X_train_norm,y_train)","381903cf":"#Predict the response for test dataset\ny_pred = clf.predict(X_test_norm)\n\n\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))","48595f84":"from sklearn.neighbors import KNeighborsClassifier  \nclassifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \nclassifier.fit(X_train_norm, y_train)  ","b18692ba":"y_pred= classifier.predict(X_test_norm)  \n#Creating the Confusion matrix  \nfrom sklearn.metrics import confusion_matrix  \nconfusion_matrix(y_test, y_pred) ","7a026a9e":"print(accuracy_score(y_test, y_pred))","1207712e":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4, n_init = 10, random_state=251)\nkmeans.fit(x)","a0056025":"centroids = kmeans.cluster_centers_\ncentroid_df = pd.DataFrame(centroids, columns = list(x) )","c792c5c8":"centroid_df = pd.DataFrame(centroids, columns = list(x) )\ndf_labels = pd.DataFrame(kmeans.labels_ , columns = list(['labels']))","bca4f87e":"snail_df_labeled = x.join(df_labels)","33d5aae1":"df_analysis = (snail_df_labeled.groupby(['labels'] , axis=0)).head(4177) \ndf_analysis.head()","0c6c625c":"df_analysis.isnull().sum()","63af5eb4":"df_analysis = df_analysis.dropna()","db025759":"df_analysis.isnull().sum()","ed0a7b96":"from sklearn.model_selection import train_test_split  \n\nX= df_analysis.drop('labels',axis =1)\ny= df_analysis['labels']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","3fcea782":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train,y_train)","c8312188":"# predict Model\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\naccuracy_score(y_test,y_pred)","c7b7eba7":"# DTfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'gini',random_state = 0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))","0697862f":"rclf = RandomForestClassifier(n_estimators= 100)\nrclf.fit(X_train,y_train)\ny_pred = rclf.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))","a5c44139":"classifier = KNeighborsClassifier(n_neighbors= 5)\nclassifier.fit(X_train,y_train)","80ef5299":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))","05d034e2":"model = GaussianNB()\nmodel.fit(X_train,y_train)\npredicted = model.predict(X_test)\nprint('Predicted Value',predicted)","adbe4418":"cm = confusion_matrix(y_true=y_test,y_pred=predicted)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,predicted))","74c4ec76":"Label encoding to convert string to numeric type","aab11c2c":"# Bar Plot","862fb812":"# Density Plot","32a4bd5e":"# Joint Plot","548ffb77":"# Count Plot","423f9831":"# Box Plot"}}