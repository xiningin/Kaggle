{"cell_type":{"bf9f6898":"code","f4200663":"code","fc11cdd6":"code","473a7bd9":"code","f2111716":"code","38554f32":"code","97aa27c5":"code","2e91ab89":"code","423a2fe5":"code","c4909cb1":"code","4cc767f8":"code","2154d3cc":"code","41f8a88b":"code","4b6d2096":"code","4ce6ccf8":"code","a0811eaa":"code","87f813c0":"code","08ca7b76":"code","c12b3701":"code","49905ac6":"code","efbaa92c":"code","1016e05b":"code","03fd88aa":"code","453c6c43":"code","a9580df2":"code","332ac591":"code","9bdc04cc":"code","8909f5bc":"code","484c6d86":"code","97e28d05":"code","faca32bf":"markdown","7c913b20":"markdown","08ca126b":"markdown","54954b55":"markdown","50efce5b":"markdown","987ac341":"markdown","36547909":"markdown","b21b28c4":"markdown","572a1da7":"markdown"},"source":{"bf9f6898":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4200663":"data = pd.read_csv('\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv')","fc11cdd6":"data.shape","473a7bd9":"data.info()","f2111716":"data.head()","38554f32":"data['Geography'].value_counts()","97aa27c5":"data['EstimatedSalary'] = data['EstimatedSalary'].astype(int) ## EstimatedSalary col was in float converted into int datatype ","2e91ab89":"data.drop(columns=['RowNumber', 'CustomerId', 'Surname','Geography'],inplace=True) ## no impact in the output","423a2fe5":"data.head()","c4909cb1":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()","4cc767f8":"data['Gender'] = le.fit_transform(data['Gender'])","2154d3cc":"X = data.iloc[:,0:-1].values\ny = data.iloc[:,-1].values","41f8a88b":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","4b6d2096":"X = scaler.fit_transform(X)","4ce6ccf8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","a0811eaa":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","87f813c0":"from sklearn.linear_model import Perceptron\nclf = Perceptron()","08ca7b76":"clf.fit(X_train,y_train)","c12b3701":"y_pred = clf.predict(X_test)","49905ac6":"from sklearn.metrics import accuracy_score","efbaa92c":"accuracy_score(y_test,y_pred)","1016e05b":"param_dist = {\n    'penalty' :['l2','l1','elasticnet',None],\n    'alpha':[0.001,0.0001,0.00001],\n    'max_iter':[10,100,1000,2000]\n    \n}","03fd88aa":"from sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(clf,param_grid=param_dist,cv=10)","453c6c43":"grid.fit(X_train,y_train)","a9580df2":"grid.best_estimator_","332ac591":"grid.best_score_","9bdc04cc":"updated_clf = Perceptron(alpha=0.001, max_iter=10, penalty='l1')","8909f5bc":"updated_clf.fit(X_train,y_train)","484c6d86":"updated_y_pred = updated_clf.predict(X_test)","97e28d05":"accuracy_score(y_test,updated_y_pred)","faca32bf":"## Variables that are measured at different scales do not contribute equally to the model fitting & model learned function and might end up creating a bias. Thus, feature-wise normalization such as MinMax Scaling is usually used.","7c913b20":"## Best Estimator","08ca126b":"## EDA","54954b55":"## Accuracy","50efce5b":"## Hyperparameter tuning using gridsearchcv","987ac341":"## LabelEncoder() helps to convert categorical variables into numeric form.","36547909":"## Best Score","b21b28c4":"## Perceptron Model Implementation","572a1da7":"# Perceptron :\n\n## It's one of the simplest ANN model, which is slightly different artificial neuron called linear threshold unit. \n \n![image.png](attachment:image.png)\n\n\n\n### A single perceptron can only be used to implement linearly separable functions. It takes both real and boolean inputs and associates a set of weights to them, along with a bias.\n\n## Update Rule :\n                                                     w(i,j)(new) = w(i,j)(old) + n (y_hat(j) - y(j))x(i)\n\n         w(i,j)   ---> connection weight between i th input neuron and j th output neuron.\n         x(i)     ---> is the i th input value of the current training instance.\n         y_hat(j) ---> is the output of j th output neuron for the current training instance.\n         y(j)     ---> is the j th target output of the j th output neuron for the current training instance.\n         n        ---> is the learning rate.\n"}}