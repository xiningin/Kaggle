{"cell_type":{"ea6b9597":"code","fbebf92b":"code","7c6eb8d2":"code","22eab224":"code","65e22c56":"code","97a79247":"code","4d093139":"code","ffeb8ae4":"code","aaabb025":"code","f15ae2a3":"code","44e8b4fd":"code","c3015486":"code","12a9af82":"code","4d8b20fa":"code","70685a7f":"code","a48256d9":"code","553ca67a":"code","2b5b0a19":"code","ee94c9e3":"code","1d7cbb52":"code","b21aff46":"code","63d22f68":"code","9f921f0e":"code","994cb3c8":"markdown"},"source":{"ea6b9597":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fbebf92b":"import os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras","7c6eb8d2":"#importing other required libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.utils.multiclass import unique_labels\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras import Sequential\nfrom keras.applications import VGG19 #For Transfer Learning\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD,Adam\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.utils import to_categorical","22eab224":"url = '\/kaggle\/input\/natural-images\/natural_images'\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(url,batch_size=32,image_size=(128,128), shuffle=True)","65e22c56":"class_name = train_data.class_names\nprint(class_name)","97a79247":"tf.data.experimental.cardinality(train_data).numpy()","4d093139":"for img,lab in  train_data.take(1):\n    print(img.shape)\n    print(lab.shape)\n    plt.figure(figsize=(20,20))\n    for i in range(32):\n        plt.subplot(6,6,i+1)\n        plt.imshow(img[i]\/255.0)\n        plt.axis('off')\n        plt.title(class_name[lab[i]])","ffeb8ae4":"#from keras.preprocessing.image import ImageDataGenerator","aaabb025":"\"\"\"train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n\nval_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\"\"\"","f15ae2a3":"test_data = train_data.take(30)\ntrain_data = train_data.skip(30)\n\nval_data = test_data.take(15)\ntest_data = test_data.skip(15)\n\nprint(\"train_data_shape\",tf.data.experimental.cardinality(train_data).numpy())\nprint(\"val_data_shape\",tf.data.experimental.cardinality(val_data).numpy())\nprint(\"test_data_shape\",tf.data.experimental.cardinality(test_data).numpy())","44e8b4fd":"\"\"\"data =[]\nlabel =[]\n\nfor img,lab in train_data:\n    data.append(img)\n    label.append(lab)\nt_data = np.concatenate(data)\nt_label = np.concatenate(label)\"\"\"","c3015486":"\"\"\"v_data =[]\nv_label =[]\n\nfor img,lab in val_data:\n    v_data.append(img)\n    v_label.append(lab)\nvt_data = np.concatenate(v_data)\nvt_label = np.concatenate(v_label)\"\"\"","12a9af82":"#vt_label = tf.keras.utils.to_categorical(vt_label,num_classes=8)","4d8b20fa":"#t_label = tf.keras.utils.to_categorical(t_label,num_classes=8)#","70685a7f":"\"\"\"print(t_data.shape,t_label.shape)\nprint(vt_data.shape,vt_label.shape)\"\"\"","a48256d9":"\"\"\"train_generator.fit(t_data)\nval_generator.fit(vt_data)\"\"\"","553ca67a":"process_unit = tf.keras.applications.resnet50.preprocess_input","2b5b0a19":"#base_model = tf.keras.applications.ResNet50()\n#base_model.summary()","ee94c9e3":"base_model = tf.keras.applications.ResNet50(input_shape=(128,128,3),include_top=False,weights='imagenet')\nbase_model.trainable = False\ninputs = tf.keras.Input(shape=(128,128,3))\nx = base_model(inputs,training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(1024,activation='relu')(x)\noutputs = tf.keras.layers.Dense(8,activation='softmax')(x)\n\nn_model = tf.keras.Model(inputs,outputs)","1d7cbb52":"n_model.summary()","b21aff46":"n_model.compile(optimizer=tf.keras.optimizers.Nadam(),loss =tf.keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'] )","63d22f68":"hist = n_model.fit(train_data,epochs=5,validation_data=val_data,verbose=2)","9f921f0e":"train_acc=hist.history['accuracy']\nval_acc=hist.history['val_accuracy']\ntrain_loss=hist.history['loss']\nval_loss=hist.history['val_loss']\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(train_acc,label='training accuracy')\nplt.plot(val_acc,label='validation accuracy')\nplt.legend()\nplt.title('Accuracy graph')\nplt.subplot(2,1,2)\nplt.plot(train_loss,label='training loss')\nplt.plot(val_loss,label='validation loss')\nplt.legend()\nplt.title('Loss graph')\n","994cb3c8":"# import Pre-Processing unit"}}