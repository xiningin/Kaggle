{"cell_type":{"e4263403":"code","e43c5c5f":"code","2f8ffb3e":"code","0b7c54c8":"code","55fb2533":"code","8742468c":"code","759e6001":"code","623fed9b":"code","d4355020":"code","0362058c":"code","64d90288":"code","c56aa98b":"code","7615ec91":"code","7c95ad55":"code","d7eb7693":"code","a87dcefc":"code","859d7b96":"code","c39152ac":"code","301e8843":"code","d6ad6f10":"code","54dfde37":"code","a7009d3a":"code","d3f1e7f3":"code","d4f0600f":"code","ce76302a":"code","a9391882":"code","e62752a3":"code","096b6567":"code","420db7c7":"code","64c64929":"code","13620913":"code","78efeeac":"code","839e2b04":"code","67049fb9":"code","93a7f4e4":"code","7c483fb3":"code","46167a44":"code","6a5ffe1c":"code","efbceefa":"code","f60b8cb9":"code","c7396801":"markdown","238c35a3":"markdown","70765018":"markdown","b02269b5":"markdown","07f1c599":"markdown"},"source":{"e4263403":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e43c5c5f":"import pandas as pd\nimport torch\n","2f8ffb3e":"!pip install simpletransformers","0b7c54c8":"df = pd.read_csv('..\/input\/textclassify\/ta-emotion10-train (1).csv')\ndf_test = pd.read_csv('..\/input\/textclassify\/ta-emotion10-dev (1).csv')","55fb2533":"df","8742468c":"def create_labels(sentence):\n  splits = sentence.split('\\t')\n  return splits[0]\n\ndef change_sentence(sentence):\n  splits = sentence.split('\\t')\n  return splits[1]\n\ndf['Labels'] = df['Neutral\\t\u0ba8\u0bbe\u0bb3\u0bc8\u0b95\u0bcd\u0b95\u0bc1 \u0b85\u0bb0\u0bbf\u0b9a\u0bbf\u0b95\u0bcd\u0b95\u0bc1 \u0b87\u0ba8\u0bcd\u0ba4 \u0ba8\u0bbf\u0bb2\u0bae\u0bc8 \u0bb5\u0ba8\u0bcd\u0ba4\u0bbe \ud83d\ude42'].apply(lambda x:create_labels(x))\ndf['Neutral\\t\u0ba8\u0bbe\u0bb3\u0bc8\u0b95\u0bcd\u0b95\u0bc1 \u0b85\u0bb0\u0bbf\u0b9a\u0bbf\u0b95\u0bcd\u0b95\u0bc1 \u0b87\u0ba8\u0bcd\u0ba4 \u0ba8\u0bbf\u0bb2\u0bae\u0bc8 \u0bb5\u0ba8\u0bcd\u0ba4\u0bbe \ud83d\ude42'] = df['Neutral\\t\u0ba8\u0bbe\u0bb3\u0bc8\u0b95\u0bcd\u0b95\u0bc1 \u0b85\u0bb0\u0bbf\u0b9a\u0bbf\u0b95\u0bcd\u0b95\u0bc1 \u0b87\u0ba8\u0bcd\u0ba4 \u0ba8\u0bbf\u0bb2\u0bae\u0bc8 \u0bb5\u0ba8\u0bcd\u0ba4\u0bbe \ud83d\ude42'].apply(lambda x:change_sentence(x))\ndf.rename(columns = {'Neutral\\t\u0ba8\u0bbe\u0bb3\u0bc8\u0b95\u0bcd\u0b95\u0bc1 \u0b85\u0bb0\u0bbf\u0b9a\u0bbf\u0b95\u0bcd\u0b95\u0bc1 \u0b87\u0ba8\u0bcd\u0ba4 \u0ba8\u0bbf\u0bb2\u0bae\u0bc8 \u0bb5\u0ba8\u0bcd\u0ba4\u0bbe \ud83d\ude42':'Text'}, inplace = True)\ndf_test['Labels'] = df_test['Joy\\t\u0b85\u0bb0\u0bc1\u0bae\u0bc8 \u0b85\u0bb1\u0bcd\u0baa\u0bc1\u0ba4\u0bae\u0bcd \u0baa\u0bbf\u0bb0\u0bae\u0bbe\u0ba4\u0bae\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0ba4\u0bcd\u0ba4\u0bc1\u0b95\u0bcd\u0b95\u0bb3\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0b95 \u0bb5\u0bb3\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba8\u0bb2\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba4\u0bca\u0b9f\u0bb0\u0b9f\u0bcd\u0b9f\u0bc1\u0bae\u0bcd \u0ba4\u0b99\u0bcd\u0b95\u0bb3\u0ba4\u0bc1 \u0baa\u0ba3\u0bbf \u0bae\u0ba4\u0bc1\u0bb0\u0bc8 \u0b9a\u0bbf\u0bb5\u0b9a\u0b99\u0bcd\u0b95\u0bb0\u0ba9\u0bcd \u0b86\u0bb0\u0bcd\u0b9f\u0bbf\u0bb8\u0bcd\u0b9f\u0bcd \u0ba4\u0bbf\u0bb0\u0bc1\u0bb5\u0bb2\u0bcd\u0bb2\u0bbf\u0b95\u0bcd\u0b95\u0bc7\u0ba3\u0bbf \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8'].apply(lambda x:create_labels(x))\ndf_test['Joy\\t\u0b85\u0bb0\u0bc1\u0bae\u0bc8 \u0b85\u0bb1\u0bcd\u0baa\u0bc1\u0ba4\u0bae\u0bcd \u0baa\u0bbf\u0bb0\u0bae\u0bbe\u0ba4\u0bae\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0ba4\u0bcd\u0ba4\u0bc1\u0b95\u0bcd\u0b95\u0bb3\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0b95 \u0bb5\u0bb3\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba8\u0bb2\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba4\u0bca\u0b9f\u0bb0\u0b9f\u0bcd\u0b9f\u0bc1\u0bae\u0bcd \u0ba4\u0b99\u0bcd\u0b95\u0bb3\u0ba4\u0bc1 \u0baa\u0ba3\u0bbf \u0bae\u0ba4\u0bc1\u0bb0\u0bc8 \u0b9a\u0bbf\u0bb5\u0b9a\u0b99\u0bcd\u0b95\u0bb0\u0ba9\u0bcd \u0b86\u0bb0\u0bcd\u0b9f\u0bbf\u0bb8\u0bcd\u0b9f\u0bcd \u0ba4\u0bbf\u0bb0\u0bc1\u0bb5\u0bb2\u0bcd\u0bb2\u0bbf\u0b95\u0bcd\u0b95\u0bc7\u0ba3\u0bbf \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8'] = df_test['Joy\\t\u0b85\u0bb0\u0bc1\u0bae\u0bc8 \u0b85\u0bb1\u0bcd\u0baa\u0bc1\u0ba4\u0bae\u0bcd \u0baa\u0bbf\u0bb0\u0bae\u0bbe\u0ba4\u0bae\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0ba4\u0bcd\u0ba4\u0bc1\u0b95\u0bcd\u0b95\u0bb3\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0b95 \u0bb5\u0bb3\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba8\u0bb2\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba4\u0bca\u0b9f\u0bb0\u0b9f\u0bcd\u0b9f\u0bc1\u0bae\u0bcd \u0ba4\u0b99\u0bcd\u0b95\u0bb3\u0ba4\u0bc1 \u0baa\u0ba3\u0bbf \u0bae\u0ba4\u0bc1\u0bb0\u0bc8 \u0b9a\u0bbf\u0bb5\u0b9a\u0b99\u0bcd\u0b95\u0bb0\u0ba9\u0bcd \u0b86\u0bb0\u0bcd\u0b9f\u0bbf\u0bb8\u0bcd\u0b9f\u0bcd \u0ba4\u0bbf\u0bb0\u0bc1\u0bb5\u0bb2\u0bcd\u0bb2\u0bbf\u0b95\u0bcd\u0b95\u0bc7\u0ba3\u0bbf \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8'].apply(lambda x:change_sentence(x))\ndf_test.rename(columns = {'Joy\\t\u0b85\u0bb0\u0bc1\u0bae\u0bc8 \u0b85\u0bb1\u0bcd\u0baa\u0bc1\u0ba4\u0bae\u0bcd \u0baa\u0bbf\u0bb0\u0bae\u0bbe\u0ba4\u0bae\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0ba4\u0bcd\u0ba4\u0bc1\u0b95\u0bcd\u0b95\u0bb3\u0bcd \u0ba8\u0ba3\u0bcd\u0baa\u0bb0\u0bc7 \u0bb5\u0bbe\u0bb4\u0bcd\u0b95 \u0bb5\u0bb3\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba8\u0bb2\u0bae\u0bc1\u0b9f\u0ba9\u0bcd \u0ba4\u0bca\u0b9f\u0bb0\u0b9f\u0bcd\u0b9f\u0bc1\u0bae\u0bcd \u0ba4\u0b99\u0bcd\u0b95\u0bb3\u0ba4\u0bc1 \u0baa\u0ba3\u0bbf \u0bae\u0ba4\u0bc1\u0bb0\u0bc8 \u0b9a\u0bbf\u0bb5\u0b9a\u0b99\u0bcd\u0b95\u0bb0\u0ba9\u0bcd \u0b86\u0bb0\u0bcd\u0b9f\u0bbf\u0bb8\u0bcd\u0b9f\u0bcd \u0ba4\u0bbf\u0bb0\u0bc1\u0bb5\u0bb2\u0bcd\u0bb2\u0bbf\u0b95\u0bcd\u0b95\u0bc7\u0ba3\u0bbf \u0b9a\u0bc6\u0ba9\u0bcd\u0ba9\u0bc8':'Text'}, inplace = True)\n\nnum_labels = len(df['Labels'].unique())\nkeys = list(df['Labels'].unique())\nvalues = list(range(0, num_labels))\nlabel_dict = dict(zip(keys,values))\ndf['Labels'] = df['Labels'].apply(lambda x:label_dict[x])\ndf_test['Labels'] = df_test['Labels'].apply(lambda x:label_dict[x])\n\nfrom sklearn.model_selection import train_test_split\nX_test,X_dev,y_test,y_dev = train_test_split(df_test['Text'],df_test['Labels'],random_state=0)\ndf_test_ = pd.concat([X_test,y_test], axis=1)\ndf_dev = pd.concat([X_dev,y_dev], axis=1)","759e6001":"from simpletransformers.language_representation import RepresentationModel\nsentences = df['Text'].to_list()\nmodel = RepresentationModel(\n        model_type=\"bert\",\n        model_name=\"bert-base-multilingual-cased\",\n        use_cuda=True\n    )\nsentence_vectors = model.encode_sentences(sentences, combine_strategy=\"mean\")","623fed9b":"test_sentences = df_test['Text'].to_list()\nsentence_vectors_test = model.encode_sentences(test_sentences, combine_strategy=\"mean\")","d4355020":"sentence_vectors_test.shape","0362058c":"from sklearn.linear_model import LogisticRegression","64d90288":"from sklearn.utils.class_weight import compute_class_weight\n","c56aa98b":"df['Labels'].value_counts().to_list()","7615ec91":"class_weight = compute_class_weight('balanced',list(df['Labels'].unique()),df['Labels'].to_list())","7c95ad55":"keys = range(11)\nvalues = class_weight\nweights = dict(zip(keys,values))","d7eb7693":"lm = LogisticRegression(C=0.005,multi_class='ovr', solver='liblinear',class_weight=weights)\nlm.fit(sentence_vectors, df['Labels'].to_list())\n","a87dcefc":"y_pred = lm.predict(sentence_vectors_test)\nset(y_pred)","859d7b96":"from sklearn.metrics import classification_report","c39152ac":"report = classification_report(df_test['Labels'].to_list(),y_pred,output_dict=True)\n","301e8843":"df_log = pd.DataFrame(report).transpose()\ndf_log","d6ad6f10":"from sklearn.tree import DecisionTreeClassifier\ndtree_model = DecisionTreeClassifier().fit(sentence_vectors, df['Labels'].to_list())","54dfde37":"y_pred = dtree_model.predict(sentence_vectors_test)\nset(y_pred)","a7009d3a":"report = classification_report(df_test['Labels'].to_list(),y_pred,output_dict=True)","d3f1e7f3":"df_tree = pd.DataFrame(report).transpose()\ndf_tree","d4f0600f":"from sklearn.svm import SVC\n","ce76302a":"linear = SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(sentence_vectors, df['Labels'].to_list())\nrbf = SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(sentence_vectors, df['Labels'].to_list())\npoly = SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(sentence_vectors, df['Labels'].to_list())\nsig = SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(sentence_vectors, df['Labels'].to_list())","a9391882":"ypred1 = linear.predict(sentence_vectors_test)\nypred2 = rbf.predict(sentence_vectors_test)\nypred3 = poly.predict(sentence_vectors_test)\nypred4 = sig.predict(sentence_vectors_test)","e62752a3":"report1 = classification_report(df_test['Labels'].to_list(),ypred1,output_dict=True)\nreport2 = classification_report(df_test['Labels'].to_list(),ypred2,output_dict=True)\nreport3 = classification_report(df_test['Labels'].to_list(),ypred3,output_dict=True)\nreport4 = classification_report(df_test['Labels'].to_list(),ypred4,output_dict=True)\n","096b6567":"df1 = pd.DataFrame(report1).transpose()\ndf1","420db7c7":"df2 = pd.DataFrame(report2).transpose()\ndf2","64c64929":"df3 = pd.DataFrame(report3).transpose()\ndf3","13620913":"df4 = pd.DataFrame(report4).transpose()\ndf4","78efeeac":"from sklearn.ensemble import RandomForestClassifier","839e2b04":"nb_model = RandomForestClassifier().fit(sentence_vectors, df['Labels'].to_list())","67049fb9":"yprednb = nb_model.predict(sentence_vectors_test)\nreport_nb = classification_report(df_test['Labels'].to_list(),yprednb,output_dict=True)\ndf_nb = pd.DataFrame(report_nb).transpose()\ndf_nb","93a7f4e4":"!pip install xgboost","7c483fb3":"from xgboost import XGBClassifier","46167a44":"model_xg = XGBClassifier().fit(sentence_vectors, df['Labels'].to_list())","6a5ffe1c":"y_preds_xg = model_xg.predict(sentence_vectors_test)\nreport_xg = classification_report(df_test['Labels'].to_list(),y_preds_xg,output_dict=True)\ndf_xg = pd.DataFrame(report_xg).transpose()\ndf_xg","efbceefa":"from sklearn.neural_network import MLPClassifier","f60b8cb9":"clf = MLPClassifier(random_state=1, max_iter=300).fit(sentence_vectors, df['Labels'].to_list())\npredictions = clf.predict_proba(sentence_vectors_test)","c7396801":"## Decision Trees","238c35a3":"## Random Forest","70765018":"## Logistic Regression","b02269b5":"## XG Boost\n","07f1c599":"## SVC"}}