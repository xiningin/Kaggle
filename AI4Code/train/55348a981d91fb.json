{"cell_type":{"969d189a":"code","44dde7e6":"code","7af40b0b":"code","ec5d86e0":"code","15bfb3cc":"code","f7417c85":"code","43900fc9":"code","6002fdfc":"code","040f1001":"code","68a2777a":"code","d76baeee":"code","466aba9a":"code","1b35bead":"code","d7faf29d":"code","d7dc1713":"code","f5528b83":"code","7cee7715":"code","a1fe1a01":"code","c28910c9":"code","9f5cad9a":"code","7d2dc948":"markdown","4c57fc3e":"markdown","87c1e27a":"markdown","c93ee54d":"markdown","e11e053f":"markdown","34f183c5":"markdown","ff47a179":"markdown","1477d24b":"markdown"},"source":{"969d189a":"from __future__ import print_function, division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom tqdm import tqdm\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport random\nimport os","44dde7e6":"def SIGMA2(C, a, b, T, P, G, wp):\n    return C+a*w**2+b*T**2+P*G**2\/((w-wp)**2+G**2)\n\ndef SIGMA1(w):\n    gamma=0\n    return gamma*w\n\ndef epsilon(k,bond,w0,dw0):\n    kF=0.15\n    if bond=='B':\n        t1b = w0\/(np.cos(2*np.pi*kF)-1)\n        t0b = t1b + w0\n        return t0b - t1b*np.cos(2*np.pi*k)\n    if bond=='A':\n        t1a = w0\/(np.cos(2*np.pi*kF)-1)\n        t0a = t1a+ w0 + dw0\n        return t0a - t1a*np.cos(2*np.pi*k) \n\ndef A(k,w,T,C,a,b,P,G,wp,bond,w0,dw0):\n    A=1\/np.pi*SIGMA2(C, a, b, T, P, G, wp)\/((w-epsilon(k,bond,w0,dw0)-SIGMA1(w))**2+SIGMA2(C, a, b, T, P, G, wp)**2)\n    return A\n\ndef F_D(w,T):\n    Ef=0\n    f= 1\/(np.exp((w+Ef)\/T)+1)\n    return f\n\ndef gaussian_noise(mean,sigma,number):\n    A=np.random.normal(mean,sigma,(number,number))\n    return A\n\ndef create_spectrum(k,w,C,a,b,T,P,G,wp,Mb,Ma,BG,w0,dw0,path):\n\n    z=(Mb*A(k,w,T,C,a,b,P,G,wp,'B',w0,dw0)+Ma*A(k,w,T,C,a,b,P,G,wp,'A',w0,dw0))*F_D(w,T)+BG + gaussian_noise(1,3,300)\n    fig = plt.figure()\n    plt.contourf(k, w, z,levels=100,cmap='terrain')\n    plt.savefig(path, transparent=True,dpi=65.89, bbox_inches=matplotlib.transforms.Bbox([[1.6, 0.8], [5 , 4.2]]))\n    plt.close()\n\ndef create_directories():\n    try:\n        os.makedirs('images\/train\/one')\n        os.makedirs('images\/train\/two')\n        os.makedirs('images\/val\/one')\n        os.makedirs('images\/val\/two')\n    except FileExistsError:\n        pass\ndef lists_random_number(array):\n    return random.random()*(array[1] - array[0]) + array[0]","7af40b0b":"w,k=np.meshgrid(np.linspace(-0.3,0.1,300), np.linspace(-0.3,0.3,300))\na_l=[0.5,8]\nb_l=[20,200]\nMa_l=[50,100]\nMb_l=[50,100]\nBG_l=[0,5,10]\ndw0_l=[0,0.15]\nT_l=[0.001,0.025]\nC_l=[0.01,0.05]\nwp=-0.041\nP_l=[0.02,0.05]\nG_l=[0.01,0.5]","ec5d86e0":"create_directories()\nfor i in tqdm(range(2)):\n    label=0 if random.random()>0.5 else 1\n    \n    a=lists_random_number(a_l)\n    b=lists_random_number(b_l)\n    Ma=lists_random_number(Ma_l) \n    Mb=lists_random_number(Mb_l)\n    BG=random.choice(BG_l)\n    P=lists_random_number(P_l)\n    dw0=lists_random_number(dw0_l)\n    T=lists_random_number(T_l)\n    C=lists_random_number(C_l)\n    G=lists_random_number(G_l)\n    \n    path='images'\n    if i>=1800:\n        path=os.path.join(path, 'val')\n    else:\n        path=os.path.join(path, 'train')\n    if label==0:\n        path=os.path.join(path, 'one')\n        if random.random()>0.5:\n            Ma=0\n        else:\n            Mb=0\n    else:\n        path=os.path.join(path, 'two')\n        \n    path=os.path.join(path, str(i))\n    create_spectrum(k,w,C,a,b,T,P,G,wp,Mb,Ma,BG,-0.13,dw0,path)","15bfb3cc":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.5507, 0.5507, 0.5507], [0.2842, 0.2842, 0.2842])\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.ToTensor(),\n#         transforms.Normalize([0.5507, 0.5507, 0.5507], [0.2842, 0.2842, 0.2842])\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = '..\/input\/binaryclass2\/images'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","f7417c85":"#batch size 1\nmean = 0.0\nmeansq = 0.0\ncount = 0\n\nfor index, data in enumerate(dataloaders['train']):\n    mean += data[0].sum()\n    meansq +=  (data[0]**2).sum()\n    count += np.prod(data[0].shape)\n\ntotal_mean = mean\/count\ntotal_var = (meansq\/count) - (total_mean**2)\ntotal_std = torch.sqrt(total_var)\nprint(\"mean: \" ,total_mean)\nprint(\"std: \" ,total_std)","43900fc9":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.5507, 0.5507, 0.5507])\n    std = np.array([0.2842, 0.2842, 0.2842])\n    \n    inp = inp*std+mean\n    \n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","6002fdfc":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","040f1001":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    \n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            fig = plt.figure()\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n\n                plt.axis('off')\n                plt.title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","68a2777a":"model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n# print(model_conv)\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n# optimizer_conv = optim.Adam(model_conv.fc.parameters(), lr=0.001)\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)","d76baeee":"model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=10)","466aba9a":"visualize_model(model_conv,10)\n","1b35bead":"import torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3)\n        self.pool1 = nn.MaxPool2d(kernel_size = 3,stride = 2)\n        self.batch1=nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5)\n        self.pool2 = nn.MaxPool2d(kernel_size = 2,stride = 2)\n        self.dropout = nn.Dropout2d(p = 0.1)\n        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))\n        self.flatten = nn.Flatten()\n        self.linear1 = nn.Linear(64,32)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(32,2)\n        self.sigmoid = nn.Sigmoid()\n\n        \n    def forward(self, x):\n        # CONV -> ReLu -> Pooling\n        x = self.conv1(x)\n        x = self.pool1(x)\n        x = self.batch1(x)\n        x = self.dropout(x)\n        x = self.conv2(x)\n        x = self.pool2(x)\n        x = self.dropout(x)\n        x = self.adaptive_pool(x)\n        x = self.flatten(x)\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.linear2(x)\n        y = self.sigmoid(x)\n        return y\n\n\nnet = Net()\nprint(net)","d7faf29d":"net = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0007, momentum=0.9)","d7dc1713":"model_simple = train_model(net, criterion, optimizer,\n                         exp_lr_scheduler, num_epochs=15)","f5528b83":"from sklearn.metrics import classification_report","7cee7715":"visualize_model(model_simple,10)\n","a1fe1a01":"def evaluate_model(model):\n    model.eval()\n    images_so_far = 0\n    all_results=[]\n    all_labels=[]\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_results.extend(preds.cpu())\n            all_labels.extend(labels.cpu())\n    return all_results, all_labels","c28910c9":"y_pred, y_true=evaluate_model(model_conv)\nprint(classification_report(y_true,y_pred))\ny_pred, y_true=evaluate_model(model_simple)\nprint(classification_report(y_true,y_pred))","9f5cad9a":"y_pred, y_true=evaluate_model(model_conv)\nprint(classification_report(y_true,y_pred))\ny_pred, y_true=evaluate_model(model_simple)\nprint(classification_report(y_true,y_pred))","7d2dc948":"# $z = \\frac{x-\\mu}{y}$\n# $\\mu$ - mean\n# $\\sigma$ - standart deviation","4c57fc3e":"## Data generation","87c1e27a":"## Data Preparation ","c93ee54d":"![image.png](attachment:98527f9d-b722-4826-aaad-3b4ecf84865f.png)","e11e053f":"## Model Initialisation ","34f183c5":"Image examples\n","ff47a179":"## Training","1477d24b":"## Your own CNN\nCalculate dimenstions \n<p>(W\u2212F+2P)\/S+1\n<hr>\n<p>input volume size (W)\n<p>field size of the Conv Layer neurons(Kernel size) (F)\n<p>the stride with which they are applied (S)\n<p>the amount of zero padding used (P) on the border"}}