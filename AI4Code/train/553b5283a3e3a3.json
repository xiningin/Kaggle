{"cell_type":{"af771ab8":"code","12dd1f23":"code","23c607c0":"code","603b3815":"code","8d94d362":"code","18299541":"code","fe4ae16b":"code","6ae7de33":"code","96f1dc85":"code","676ce945":"markdown"},"source":{"af771ab8":"import numpy as np\nimport pandas as pd\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm\nimport glob\nimport os\nimport gc","12dd1f23":"train = pd.read_csv('..\/input\/ncaaw-2021-features-only\/tourney.csv')\ntest = pd.read_csv('..\/input\/ncaaw-2021-features-only\/test.csv')","23c607c0":"y = train[\"result\"]\ns = train[\"Season\"]\nX = train.drop(['Season','TeamID1','TeamID2','result'], axis=1)\n\n\nX_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)","603b3815":"train_oof = np.zeros((X.shape[0],))\ntest_preds = 0\ntrain_oof.shape","8d94d362":"NUM_FOLDS = 10\nkf = GroupKFold(n_splits=NUM_FOLDS)\nmax_iter = 550\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(X, y, s))):\n        #print(f'Fold {f}')\n        train_df, val_df = X.iloc[train_ind], X.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = HistGradientBoostingClassifier(max_iter=max_iter, validation_fraction=None, learning_rate=0.01, max_depth=2, min_samples_leaf=32)\n        \n\n        model =  model.fit(train_df, train_target)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(X_test)[:,1]\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test\/NUM_FOLDS\n        \n        print(log_loss(val_target, temp_oof))","18299541":"log_loss(y, train_oof)\n","fe4ae16b":"np.save('train_oof', train_oof)\nnp.save('test_preds', test_preds)","6ae7de33":"test = pd.read_csv('..\/input\/ncaaw-2021-features-only\/test.csv')\nWSampleSubmission = pd.read_csv('..\/input\/ncaaw-march-mania-2021\/WSampleSubmissionStage1.csv')","96f1dc85":"idx = test_preds.shape[0] \/\/2\ntest_preds[idx:] = 1 - test_preds[idx:]\n\npred = pd.concat([test.ID, pd.Series(test_preds)], axis=1).groupby('ID')[0]\\\n        .mean().reset_index().rename(columns={0:'Pred'})\nsub = WSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\nsub.to_csv('submission.csv', index=False)\nsub.head()","676ce945":"HistGradientBoosting is a conveneint scikit-learn version of the Gradient Boosting Algorithm. It is modeled after LightGBM. Even though it doesn't have nearly as maney features as otehr GBM libraries, it is simple to use and oftentimes on par with those more powerful libraries in terms of predictive performance "}}