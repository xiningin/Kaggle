{"cell_type":{"191eda64":"code","ed51d4e8":"code","20824fc8":"code","df9089e7":"code","bfbd699c":"code","77b63fd1":"code","9d5ab943":"code","9d068086":"code","148096ea":"code","a9d15920":"code","fce474fa":"code","b11e5d98":"code","30222605":"code","ae6868c6":"code","10884ea2":"code","0028f9ef":"code","88fc86a9":"code","5f5bb0e0":"code","d23b6856":"code","0d23de84":"code","f2307be5":"code","9898ffd6":"code","f76613b5":"code","54676d06":"code","28cebc6b":"code","d34cb94f":"code","ca5dc886":"code","4988e5e5":"code","0f3d1bb5":"code","bcbcc6fc":"code","b0758fae":"code","9a753b8d":"code","af6057eb":"code","f4d26b8a":"code","9e52589f":"code","fc54444f":"code","98128d55":"code","d68f5d42":"code","aa635d71":"code","75a22721":"code","8eeb8ee7":"code","6f64fb41":"code","e04585b5":"markdown","e0185658":"markdown","be484ae4":"markdown","5e81f36f":"markdown","5cdeca48":"markdown","8aecb7c5":"markdown"},"source":{"191eda64":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ed51d4e8":"housing = pd.read_csv(\"..\/input\/california-housing-prices\/housing.csv\")\nhousing.info()","20824fc8":"housing[\"median_income\"].mean() #mean = Durchschnitt","df9089e7":"housing[\"ocean_proximity\"].value_counts()","bfbd699c":"housing.describe() #Abweichungswert, Mindestwert, Durchschnitt, Maxwert","77b63fd1":"import matplotlib.pyplot as plt #library f\u00fcr Statistiken\n\nhousing.hist(bins=50, figsize=(20,15))","9d5ab943":"from sklearn.model_selection import train_test_split\n\ntrain_set, test_set, = train_test_split(housing, test_size=0.2)\n\ndef train_test_split(df, test_size):\n    test_set = df[1:0.2*len]\n    train_set = df[0.2*len:len]","9d068086":"train_set.head()","148096ea":"test_set.head()","a9d15920":"train_set.shape #Zeigt einzelne Eintr\u00e4ge und Spalten","fce474fa":"test_set.shape","b11e5d98":"housing = train_set.copy()","30222605":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1, c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"))","ae6868c6":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"] \/ housing[\"households\"]","10884ea2":"housing.head()","0028f9ef":"housing[\"population_per_household\"] = housing[\"population\"] \/ housing[\"households\"]","88fc86a9":"housing.head()","5f5bb0e0":"housing.plot(kind=\"scatter\", x=\"population_per_household\", y=\"median_house_value\")","d23b6856":"corr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","0d23de84":"housing = train_set.drop(\"median_house_value\", axis=1)\nhousing_labels = train_set[\"median_house_value\"].copy()","f2307be5":"housing.head()","9898ffd6":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\") # mean, knn,...","f76613b5":"imputer.fit(housing_num)","54676d06":"housing_num = housing.drop(\"ocean_proximity\", axis=1)","28cebc6b":"imputer.statistics_","d34cb94f":"housing_num.median()","ca5dc886":"X = imputer.transform(housing_num)\nX","4988e5e5":"housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)\nhousing_tr.info()","0f3d1bb5":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_pipeline  = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scale\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"ohe\", OneHotEncoder())\n])","bcbcc6fc":"from sklearn.compose import ColumnTransformer\n\nnum_attributes = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\",\n       \"total_bedrooms\", \"population\", \"households\", \"median_income\"]\ncat_attributes = [\"ocean_proximity\"]\n\npipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attributes),\n    (\"cat\", cat_pipeline, cat_attributes)\n])","b0758fae":"housing_prepared = pipeline.fit_transform(housing)","9a753b8d":"housing_prepared[1]","af6057eb":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","f4d26b8a":"some_data = housing_prepared[:10]\nsome_labels = housing_labels[:10]\nsome_predictions = lin_reg.predict(some_data)","9e52589f":"some_labels","fc54444f":"some_predictions","98128d55":"plt.scatter(x=some_labels, y=some_labels)\nplt.scatter(x=some_labels, y=some_predictions)","d68f5d42":"from sklearn.ensemble import RandomForestRegressor\n\nrdm_fst = RandomForestRegressor()\nrdm_fst.fit(housing_prepared, housing_labels)","aa635d71":"some_data = housing_prepared[:10]\nsome_labels = housing_labels[:10]\nsome_predictions = rdm_fst.predict(some_data)","75a22721":"some_labels","8eeb8ee7":"some_predictions","6f64fb41":"plt.scatter(x=some_labels, y=some_labels)\nplt.scatter(x=some_labels, y=some_predictions)","e04585b5":"# Feature Engineering\n\n\"Bauen\" neuer Features\/Attribute, die dabei helfen, die Zielvariable vorherzusagen.\n\nRooms per Household\nPopulation per Household","e0185658":" **Virtualisierung**","be484ae4":"# --- Hier wird noch erg\u00e4nzt ----\n \n Langer oder kurzer Weg?\n Scalieren von Features (num) 0-1, mean-std\n Handling ovn Kategorischen Variablen\n\n# Modelle","5e81f36f":"# Machine Learning Modelle","5cdeca48":"# Train - Test Split\nAufteilen der Daten in 2 Datens\u00e4tze\n1. zum Entwickeln des Modells\n2. zum Testen des Modells","8aecb7c5":"# Data Cleaning"}}