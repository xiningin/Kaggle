{"cell_type":{"e366d013":"code","32823edf":"code","dde8834f":"code","e788d32e":"code","b095a489":"code","cb88f606":"code","a435a772":"code","98d83699":"code","a5ddf645":"code","430fd33d":"code","f8e1c500":"code","bde85638":"code","8d000043":"code","5e4d71c8":"code","b054aaaa":"code","0bd42aa5":"code","4a414917":"code","5f213ef6":"code","2cc5ebae":"code","4a6b4c2d":"code","6d17fb94":"markdown","7b079bdb":"markdown","f69af634":"markdown","828bad7b":"markdown","91746eda":"markdown","7caa24c2":"markdown","f8b61569":"markdown"},"source":{"e366d013":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler,OrdinalEncoder\nfrom xgboost import XGBRegressor","32823edf":"df_train = \"\/kaggle\/input\/30-days-of-ml\/train.csv\"\ndf_test = \"\/kaggle\/input\/30-days-of-ml\/test.csv\"\nxtrain = pd.read_csv(df_train,index_col = 'id')\nX_test_full = pd.read_csv(df_test, index_col = 'id')","dde8834f":"#training data check-up\nxtrain.head()","e788d32e":"print(\"Training data, Shape: \", xtrain.shape)\nprint(\"#\"*50)\nprint(xtrain.info())\nxtrain.describe(include = \"all\")","b095a489":"# test data check-up\nX_test_full.head()","cb88f606":"print(\"Test data, Shape: \", X_test_full.shape)\nprint(X_test_full.info())","a435a772":"#Check-up for missing values\nxtrain.isnull().sum()","98d83699":"#Visualization of missing values\nsns.heatmap(xtrain.isnull(), cbar = False)","a5ddf645":"#Dropping (if any) Duplicate data from training set\nxtrain.drop_duplicates()","430fd33d":"# Identifying the Outliers in training set\n\n#first store the numerical features in a seperate dataframe.\nnum_cols  = [col for col in xtrain.columns if xtrain[col].dtype in ['int64', 'float64']]\nnum_cols.remove(\"target\")\n#Now plot a boxplot to identify the outliers in our numerical features.\nsns.boxplot(data = xtrain[num_cols], orient = 'v', palette = 'Set3', linewidth = 2.5 )\nplt.title(\"Numerical Features Box Plot\")","f8e1c500":"# Identifying the Outliers in training set target column\n\nsns.boxplot(x = xtrain[\"target\"], orient = 'h', linewidth = 2.5 )\nplt.title(\"Target Column Box Plot\")\n","bde85638":"# Treating with outliers\n\nfrom scipy import stats\ndef remove_outliers(df=None, columns=None):\n    for col in columns:\n        q1 = df[col].quantile(0.25)\n        q3 = df[col].quantile(0.75)\n        iqr = q3 - q1\n        floor, ceil = q1 - 1.5 * iqr , q3 + 1.5 * iqr\n        df[col] = df[col].clip(floor, ceil)\n        print(f\"The columnn: {col}, has been catered for outliers.\\n\")\n    return df\noutlier_cols = [\"cont0\",\"cont6\",\"cont8\",\"target\"]\nxtrain = remove_outliers(xtrain,outlier_cols)","8d000043":"# After treating outliers training set (Numerical_cols)\nsns.boxplot(data = xtrain[num_cols], orient = 'v', palette = 'Set3', linewidth = 2.5 )\nplt.title(\"Numerical Features Box Plot after treating outliers\")","5e4d71c8":"# After treating outliers training set (Target_cols)\nsns.boxplot(x = xtrain[\"target\"], orient = 'h', linewidth = 2.5 )\nplt.title(\"Target Column Box Plot after treating outliers\")","b054aaaa":"#Removing the rows with missing target\nxtrain.dropna(axis = 0, subset = [\"target\"], inplace = True)\ny = xtrain[\"target\"]\n# Removing the target column from the training dataset\nxtrain.drop([\"target\"],axis=1,inplace = True)\nxtrain.head()","0bd42aa5":"# Split the data into train test set\nX_train_full, X_valid_full,y_train, y_valid = train_test_split(xtrain,y, \n                                                               train_size = 0.8, test_size = 0.2, \n                                                               random_state = 42)\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncat_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].dtype == \"object\"]\n\n# Select numeric columns\nnum_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n# Keep selected columns only\nmy_cols = cat_cols + num_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\nX_train.head()","4a414917":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='mean')\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')) \n    ,('scaler', OrdinalEncoder())\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('cat', categorical_transformer, cat_cols)\n    ],\n    remainder=\"passthrough\"\n  )","5f213ef6":"#Model Defining\nparams= {'learning_rate': 0.027231687302028264,\n 'reg_lambda': 1.787138359572014e-08,\n 'reg_alpha': 3.6669399865376046e-06,\n 'subsample': 0.8364933510245828,\n 'colsample_bytree': 0.5734576028943121,\n 'max_depth': 2}\n\nmodel_xgb = XGBRegressor(\n        random_state=42, \n        tree_method='gpu_hist',\n        gpu_id=0,\n        predictor=\"gpu_predictor\",\n        n_estimators=4000,\n        **params\n    )\n","2cc5ebae":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model_xgb)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train)\n\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nscore = mean_squared_error(y_valid, preds)\nrmse = math.sqrt(score)\nprint('RMSE:', rmse)","4a6b4c2d":"test_predic = my_pipeline.predict(X_test)\n# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': test_predic})\noutput.to_csv(\"submission.csv\", index=False)","6d17fb94":"2. **Data Loading**","7b079bdb":"1. **Importing useful libraries**","f69af634":"4. **Data Preprocessing**","828bad7b":"6. **Preparing Data for Model Building**","91746eda":"3. **Data Exploration**","7caa24c2":"8. **Prediction and Output Submission**","f8b61569":"7. **Pipelining for model**"}}