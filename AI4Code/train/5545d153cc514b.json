{"cell_type":{"3c0b1b89":"code","188cfeed":"code","8e2300b1":"code","3118da85":"code","fdcd2a23":"code","5e89cc8e":"code","88d25f30":"code","134ef78b":"code","bb9e1545":"code","d9c1c8af":"code","cb56f333":"code","9afe6476":"code","8451780a":"code","54ca3663":"code","856fac5b":"code","4f57b58f":"code","b8355fd7":"code","40f085e2":"code","5a63d77a":"code","2629ab8e":"code","e9183885":"code","0dbb071b":"code","3cfa4ffa":"code","17722059":"code","0889bbcf":"code","52681559":"code","e76ccb6b":"code","52bc6493":"code","223a1e6d":"code","a6edbf76":"code","3e6d154e":"code","33364e03":"code","9e9ab71d":"code","fb463caf":"code","96a3888a":"code","c59ac2ed":"code","4cbefed1":"code","9eb599df":"code","7d411ee1":"code","735e83c3":"code","1caf71f0":"code","77fd903f":"code","f9cf7141":"code","c0382d7e":"markdown","615aa867":"markdown","a168dc64":"markdown","ef422401":"markdown"},"source":{"3c0b1b89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom sklearn.decomposition import TruncatedSVD\nfrom multiprocessing import Pool\n\nfrom warnings import catch_warnings\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nplt.rcParams[\"figure.figsize\"] = (20, 6)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","188cfeed":"def auto_ets(df, seasonal_periods=[None], trend=['add', 'mul'], damped=[True], seasonal=[None], use_boxcox=[False]):\n    min_ic = np.inf\n    best_model = None\n    params = [(sp, t, d, s, b) for sp in seasonal_periods for t in trend for d in damped for s in seasonal for b in use_boxcox]\n    for sp, t, d, s, b in params:\n        try:\n            with catch_warnings():\n                filterwarnings('ignore')\n                ets = ExponentialSmoothing(df, seasonal_periods=sp, trend=t, damped=d, seasonal=s).fit(use_boxcox=b, remove_bias=False)\n            if ets.aicc < min_ic:\n                min_ic = ets.aicc\n                best_model = ets\n        except:\n            pass\n    return best_model\n\ndef fit_predict(data, forecast_period=43):\n    model = auto_ets(data)\n    fcast = model.forecast(forecast_period)\n    return fcast, model\n\ndef fit_predict_pool(data, forecast_period=43):\n    return fit_predict(data, forecast_period)[0]\n\ndef predict_all(dat, n_components=None):\n    pool = Pool()\n    f = pool.map(fit_predict_pool, [dat.loc[i, :] for i in dat.index])\n    fcast = pd.DataFrame(index=dat.index, columns=f[0].index)\n    for i in range(len(dat.index)):\n        fcast.iloc[i, :] = f[i]\n    return fcast","8e2300b1":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv', parse_dates=['Date'])\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv', parse_dates=['Date'])\nsubmission = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/submission.csv')","3118da85":"train['key'] = train['Country_Region'].astype('str') + \" \" + train['Province_State'].astype('str')\ntest['key'] = test['Country_Region'].astype('str') + \" \" + test['Province_State'].astype('str')","fdcd2a23":"train","5e89cc8e":"test","88d25f30":"len(set(train.key)), len(set(test.key))","134ef78b":"submission","bb9e1545":"cases = train.pivot('key', 'Date', 'ConfirmedCases')\nfatalities = train.pivot('key', 'Date', 'Fatalities')\ncases.index += ' cases'\nfatalities.index += ' fatal'\ncombined = pd.concat([cases, fatalities])\ncombined","d9c1c8af":"cases.sum().plot(label='Confirmed cases', legend=True)\nfatalities.sum().plot(label='Fatalities', legend=True, title='COVID19 Global Confirmed Cases and Fatalities (log scale)', logy=True);","cb56f333":"f, m = fit_predict(cases.sum())\nf[:29].plot(title='Aggregate check for additive vs multiplicative trend on cumulative cases')\ncases.sum()[-43:].plot()\nm.summary()","9afe6476":"f, m = fit_predict(fatalities.sum())\nf[:29].plot(title='Aggregate check for additive vs multiplicative trend on cumulative deaths')\nfatalities.sum()[-43:].plot()\nm.summary()","8451780a":"f, m = fit_predict(cases.diff(axis=1).sum())\nf[:29].plot(title='Aggregate check for additive vs multiplicative trend on new cases')\ncases.diff(axis=1).sum()[-43:].plot()\nm.summary()","54ca3663":"f, m = fit_predict(fatalities.diff(axis=1).sum())\nf[:29].plot(title='Aggregate check for additive vs multiplicative trend on new deaths')\nfatalities.diff(axis=1).sum()[-43:].plot()\nm.summary()","856fac5b":"diff_combined = combined.diff(axis=1).dropna(axis=1)\nsvd = TruncatedSVD(100)\nsvd_factors = pd.DataFrame(svd.fit_transform(diff_combined.T).T, columns=diff_combined.columns)\nsvd_factors","4f57b58f":"svd.explained_variance_ratio_[:5].round(3)","b8355fd7":"svd_factors.T.iloc[:, :5].plot(title='Top five SVD components');","40f085e2":"f, m = fit_predict(svd_factors.loc[0, :])\nf[:29].plot(title='Projected component 0')\nsvd_factors.iloc[0, -43:].plot()\nm.summary()","5a63d77a":"f, m = fit_predict(svd_factors.loc[1, :])\nf[:29].plot(title='Projected component 1')\nsvd_factors.iloc[1, -43:].plot()\nm.summary()","2629ab8e":"svd_forecast = predict_all(svd_factors)\nforecast_combined_diff = pd.DataFrame(svd.inverse_transform(svd_forecast.T).T, index=combined.index, columns=svd_forecast.columns).clip(0)\nforecast_combined = forecast_combined_diff.cumsum(axis=1) + combined.iloc[:, -1].values[:, None]\nforecast_combined","e9183885":"forecast_new_cases = forecast_combined_diff.iloc[:len(cases), :]\nforecast_new_fatalities = forecast_combined_diff.iloc[len(cases):, :]\nforecast_cases = forecast_combined.iloc[:len(cases), :]\nforecast_fatalities = forecast_combined.iloc[len(cases):, :]\nforecast_new_fatalities","0dbb071b":"cases.sum()[-43:].plot()\nforecast_cases.sum()[:29].plot(title='Global cumulative confirmed cases (millions)');","3cfa4ffa":"forecast_new_cases.sum()[:29]\/1000","17722059":"fatalities.sum()[-43:].plot()\nforecast_fatalities.sum()[:29].plot(title='Global cumulative fatalities');","0889bbcf":"forecast_new_fatalities.sum()[:29] \/ 1000","52681559":"(forecast_fatalities.sum() \/ forecast_cases.sum())[:29].plot(title='Global fatalities as proportion of confirmed cases')\n(fatalities.sum() \/ cases.sum())[-43:].plot();","e76ccb6b":"cases_melt = forecast_cases.reset_index().melt('key', var_name='Date', value_name='ConfirmedCases')\nfatalities_melt = forecast_fatalities.reset_index().melt('key', var_name='Date', value_name='Fatalities')\ncases_melt.key = [key[:-6] for key in cases_melt.key]\nfatalities_melt.key = [key[:-6] for key in fatalities_melt.key]\ncases_melt","52bc6493":"test = test.merge(cases_melt, how='left', on=['key', 'Date'])\ntest = test.merge(fatalities_melt, how='left', on=['key', 'Date'])\ntest","223a1e6d":"us_cases = test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1)\nus_cases","a6edbf76":"train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1).sum()[-43:].plot()\nus_cases.sum()[:29].plot(title='United States Cumulative Confirmed Cases (millions)');","3e6d154e":"test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1).sum()[:29] \/ 1000","33364e03":"us_fatalities = test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1)\nus_fatalities","9e9ab71d":"train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1).sum()[-43:].plot()\nus_fatalities.sum()[:29].plot(title='United State Cumulative Fatalities');","fb463caf":"test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1).sum()[:29] \/ 1000","96a3888a":"(train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1).sum()\n \/ train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1).sum())[-43:].plot()\n\n(us_fatalities.sum() \/ us_cases.sum())[:29].plot(title='US fatalities as proportion of confirmed cases');","c59ac2ed":"us_cases.loc['Virginia'].diff().dropna()[:29]","4cbefed1":"us_fatalities.loc['Virginia'].diff().dropna()[:29]","9eb599df":"(us_fatalities.loc['Virginia'] \/ us_cases.loc['Virginia']).plot()","7d411ee1":"test.head(30)","735e83c3":"test.tail(30)","1caf71f0":"submission.ConfirmedCases = test.ConfirmedCases.fillna(0)\nsubmission.Fatalities = test.Fatalities.fillna(0)\nsubmission","77fd903f":"submission.to_csv('submission.csv', index=False)","f9cf7141":"submission.tail(10)","c0382d7e":"## Global Forecast Daily Fatalities (thousands)","615aa867":"## US Projected Cumulative Fatalities (thousands)","a168dc64":"## US Projected Cumulative Confirmed Cases (thousands)","ef422401":"## Global Forecast Daily New Cases (thousands)"}}