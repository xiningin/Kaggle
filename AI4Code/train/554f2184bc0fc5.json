{"cell_type":{"a6160bb7":"code","76e8b56d":"code","2639f439":"code","fd2f5868":"code","f153f825":"code","3624ac9f":"code","14dfde02":"code","d2632d19":"code","1c548e40":"code","eed10ee5":"code","91ae33dd":"code","a873ced0":"code","12f130fa":"code","06f78d7e":"code","a5a85bdc":"code","59082bd3":"code","889d7b26":"code","0da4bdfc":"code","5cbb201c":"code","756f705f":"code","4d3c86a6":"code","6205a1d8":"code","11a2be70":"code","f9905e1f":"code","9a878ce4":"code","004fca87":"code","bdda21c4":"code","d52403a0":"code","0461b0c6":"code","310d2086":"markdown","590e4d4c":"markdown","9a141eb4":"markdown","a22089eb":"markdown","124e7b3d":"markdown","4f51424c":"markdown","a6b562a2":"markdown","cda90469":"markdown","b5b940e0":"markdown","5d6563c4":"markdown","6fa9152b":"markdown","6c40f4b5":"markdown","67b574d9":"markdown","03c242cc":"markdown","08bf6fa9":"markdown","86400319":"markdown","abee308d":"markdown","c7b7f0ba":"markdown","454def21":"markdown","57e1f5ba":"markdown","c892d4b2":"markdown","1dfaf4ef":"markdown","42451c34":"markdown","c75b4113":"markdown","596e2108":"markdown","9d619b53":"markdown","31c7f78e":"markdown","500a04c6":"markdown","7fcaef31":"markdown","469cca19":"markdown","93499ca0":"markdown","4c56c28a":"markdown"},"source":{"a6160bb7":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n#convolutional layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Lambda, MaxPooling2D\n#core layers\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.normalization import BatchNormalization\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.utils.np_utils import to_categorical\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","76e8b56d":"train=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","2639f439":"train.head()","fd2f5868":"train.shape","f153f825":"test.shape","3624ac9f":"X=train.drop(['label'],1).values\ny=train['label'].values\ntest_x=test.values","14dfde02":"print(X)","d2632d19":"print(y)","1c548e40":"print(test_x)","eed10ee5":"X=X\/255\ntest_x=test_x\/255","91ae33dd":"# Reshaping image into 3 dimensions (height = 28px, width = 28px , canal = 1)\n# canal = 1 => For gray scale\nX=X.reshape(-1,28,28,1)\ntest_x=test_x.reshape(-1,28,28,1)","a873ced0":"y=to_categorical(y)\nprint(y)","12f130fa":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=0)","06f78d7e":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","a5a85bdc":"print(X_train)","59082bd3":"X_train__ = X_train.reshape(X_train.shape[0],28,28)","889d7b26":"fig,axis=plt.subplots(1,4,figsize=(20,10))\nfor i,ax in enumerate(axis.flat):\n  ax.imshow(X_train__[i], cmap='binary')\n  digit=y_train[i].argmax()\n  ax.set(title=f\"Real Number is {digit}\");","0da4bdfc":"#creating mean=0 and standard deviation=1\nmean=np.mean(X_train)\nstd=np.std(X_train)\ndef standardize(x):\n  return ((x-mean)\/std)","5cbb201c":"epochs=50 #for no of passes in training to optimize error\nbatch_size=64","756f705f":"model=Sequential()\n\n#model.add(Lambda(standardize,input_shape=(28,28,1)))    \nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())    \nmodel.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n    \nmodel.add(MaxPooling2D(pool_size=(2,2)))\n    \nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation=\"relu\"))\n    \nmodel.add(Dense(10,activation=\"softmax\"))\n    \nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","4d3c86a6":"#Data augmentation to prevent overfitting\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n#datagen.fit(X_train)\ntrain_gen=datagen.flow(X_train, y_train, batch_size=batch_size)\ntest_gen=datagen.flow(X_test, y_test, batch_size=batch_size)\n ","6205a1d8":"#This make accuarcy 0.998\nimport tensorflow as tf\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.995):\n      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback() \nmodel.fit(X,y,batch_size=batch_size, validation_split=0.2, epochs=10,callbacks=[callbacks])","11a2be70":"import tensorflow as tf\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.995):\n      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()      \n# Fit the model\nhistory = model.fit_generator(train_gen, \n                              epochs = epochs, \n                              steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                              validation_data = test_gen,\n                              validation_steps = X_test.shape[0] \/\/ batch_size,\n                              callbacks=[callbacks],\n                              )","f9905e1f":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n","9a878ce4":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1, figsize=(18, 10))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n","004fca87":"fig = plt.figure(figsize=(10, 10)) # Set Figure\n\ny_pred = model.predict(X_test) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\nY_pred = np.argmax(y_pred, 1) # Decode Predicted labels\nY_test = np.argmax(y_test, 1) # Decode labels\n\nmat = confusion_matrix(Y_test, Y_pred) # Confusion matrix\n\n# Plot Confusion matrix\nsns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)\nplt.xlabel('Predicted Values')\nplt.ylabel('True Values');\nplt.show();","bdda21c4":"y_pred = model.predict(X_test)\nX_test__ = X_test.reshape(X_test.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"Real Number is {y_test[i].argmax()}\\nPredict Number is {y_pred[i].argmax()}\");\n","d52403a0":"pred = model.predict_classes(test_x, verbose=1)","0461b0c6":"sub['Label'] = pred\nsub.to_csv(\"CNN_keras_sub.csv\", index=False)\nsub.head()","310d2086":"**Approach:**\n\nApplied Data Augmentation for better prediction and large dataset, followed by model training using Convolutional Neural Network.","590e4d4c":"# **Defining the model**","9a141eb4":"# **Handwritten  Digit Prediction**","a22089eb":"# **Evaluating the model**","124e7b3d":"# **Prediction and Submition**","4f51424c":"# **Data Visualisation**","a6b562a2":"Moreover the CNN converg faster on [0..1] data than on [0..255]","cda90469":"Splitting the train set into two parts : a small fraction (10%) is the validation set used to evaluate the model and the rest (90%) is used to train the model.","b5b940e0":"**Splitting data into features and labels**","5d6563c4":"We have got 99.5 % accuracy using Convolution Neural network","6fa9152b":"# **Data Augumentation**","6c40f4b5":"# **Model Training**","67b574d9":"**Label Encoding**","03c242cc":"**Dataset:**\n\nThe data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine provided by MNIST. The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.","08bf6fa9":"**Target:**\n\nGoal is to correctly identify digits from a dataset of tens of thousands of handwritten images.","86400319":"**Prediciting the Outputs**","abee308d":"**Normalization**","c7b7f0ba":"**Prediction validation results**","454def21":"One-Hot Encoding","57e1f5ba":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]).","c892d4b2":"# **Confusion Matrix**","1dfaf4ef":"**Training and validation curves**","42451c34":"**Reshaping Data**","c75b4113":"# **Data Preparation**","596e2108":"Please upvote my work if it could help! Thank you!","9d619b53":"# **Importing Necessary Libraries**","31c7f78e":"**CNN**","500a04c6":"**Splitting data into train and validation set**","7fcaef31":"Standardization","469cca19":"**Loading Data**","93499ca0":"**Plotting CNN model**","4c56c28a":"Performing grayscale normalization to reduce the effect of illumination's differences."}}