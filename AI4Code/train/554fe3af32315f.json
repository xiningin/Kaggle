{"cell_type":{"ba4e9b9e":"code","6f91c41d":"code","b50a05c8":"code","f9637eed":"code","af18b630":"code","6af89598":"code","5e530122":"code","87fecccd":"code","a42b2b51":"code","259a4245":"code","2d71cbcd":"code","1f948b36":"code","7843c883":"code","556fb151":"code","1ec512cd":"code","605145eb":"code","9f34f127":"code","0b9aed66":"code","4b5c8c71":"markdown","70a272ae":"markdown","5929e49f":"markdown","f12e8fed":"markdown","d175962c":"markdown","3fa37844":"markdown","3f5c94e6":"markdown","8b02a2bb":"markdown","7d094327":"markdown","9f5f5da0":"markdown","ef051cd5":"markdown"},"source":{"ba4e9b9e":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import PolynomialFeatures\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.pipeline import make_pipeline","6f91c41d":"train_df = pd.read_csv(\"..\/input\/boston-housing-dataset\/house-price-prediction-with-boston-housing-dataset\/train1.csv\")\ntrain_df.head()","b50a05c8":"train_df.info()","f9637eed":"train_df[\"CRIM\"] = train_df[\"CRIM\"].replace(np.nan,train_df[\"CRIM\"].median())\ntrain_df[\"ZN\"] = train_df[\"ZN\"].replace(np.nan,train_df[\"ZN\"].median())\ntrain_df[\"INDUS\"] = train_df[\"INDUS\"].replace(np.nan,train_df[\"INDUS\"].mean())\ntrain_df[\"CHAS\"] = train_df[\"CHAS\"].replace(np.nan,train_df[\"CHAS\"].median())\ntrain_df[\"AGE\"] = train_df[\"AGE\"].replace(np.nan,train_df[\"AGE\"].median())\ntrain_df[\"LSTAT\"] = train_df[\"LSTAT\"].replace(np.nan,train_df[\"LSTAT\"].mean())\ntrain_df.head()","af18b630":"corrmat = train_df.corr()\ncorrmat.head()\nplt.figure(figsize=(12,9))\nsns.heatmap(corrmat, square=True,annot=True,fmt='.2f',annot_kws={'size': 10});","6af89598":"sns.distplot(train_df['MEDV'])","5e530122":"plt.scatter(train_df['LSTAT'],train_df['MEDV'])\nplt.xlabel(\"LSTAT\")\nplt.ylabel(\"MEDV\")\nplt.show()","87fecccd":"plt.scatter(train_df['RM'],train_df['MEDV'])\nplt.xlabel(\"RM\")\nplt.ylabel(\"MEDV\")\nplt.show()","a42b2b51":"Y = train_df[['MEDV']].values\ntrain_df.drop([\"Id\",\"MEDV\"],axis=1,inplace=True)\ncols = train_df.columns\nX = train_df.values\nx_scaled = StandardScaler().fit_transform(X)\ntrain_df = pd.DataFrame(x_scaled,columns=cols)\nX = train_df.values","259a4245":"train_df.head()","2d71cbcd":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  Y_train.shape)\nprint ('Test set:', X_test.shape,  Y_test.shape)","1f948b36":"models = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('LASSO', Lasso()))\nmodels.append(('MLP', MLPRegressor(max_iter = 500)))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('DecisionTree', DecisionTreeRegressor()))\nmodels.append(('SVR', SVR()))\nfor name, model in models:\n    model.fit(X_train,Y_train)\n    y = model.predict(X_test)\n    print(name + \" : \" + str(mean_squared_error(Y_test, y,squared=False)))","7843c883":"import tensorflow as tf\nfrom tensorflow import keras\nmodel = tf.keras.Sequential([\n    keras.layers.Dense(units=1, input_shape=[13], activation = 'relu'),\n])\nmodel.compile(\n  optimizer='sgd',\n  loss='mean_squared_error'\n)\nmodel.fit(X_train,Y_train, epochs=800)","556fb151":"ypred = model.predict(X_test)\nprint(mean_squared_error(Y_test, ypred,squared=False))","1ec512cd":"for degree in range(2,5):\n    model = make_pipeline(PolynomialFeatures(degree, interaction_only=False),LinearRegression())\n    model.fit(X_train,Y_train)\n    y = model.predict(X_test)\n    print(\" PF: \" +str(degree) + \" \"+ str(mean_squared_error(Y_test, y,squared=False)))\n    ","605145eb":"test_df = pd.read_csv(\"..\/input\/boston-housing-dataset\/house-price-prediction-with-boston-housing-dataset\/test1.csv\")\n\nmodel = KNeighborsRegressor()\nmodel.fit(X_train,Y_train)\ntest_df[\"CRIM\"] = test_df[\"CRIM\"].replace(np.nan,test_df[\"CRIM\"].median())\ntest_df[\"ZN\"] = test_df[\"ZN\"].replace(np.nan,test_df[\"ZN\"].median())\ntest_df[\"INDUS\"] = test_df[\"INDUS\"].replace(np.nan,test_df[\"INDUS\"].mean())\ntest_df[\"CHAS\"] = test_df[\"CHAS\"].replace(np.nan,test_df[\"CHAS\"].median())\ntest_df[\"AGE\"] = test_df[\"AGE\"].replace(np.nan,test_df[\"AGE\"].median())\ntest_df[\"LSTAT\"] = test_df[\"LSTAT\"].replace(np.nan,test_df[\"LSTAT\"].mean())\ntest_df.drop([\"Id\"],inplace = True,axis=1)\nx = test_df.values\nx_scaled = StandardScaler().fit_transform(x)\ny = model.predict(x_scaled)","9f34f127":"test_df = pd.read_csv(\"..\/input\/boston-housing-dataset\/house-price-prediction-with-boston-housing-dataset\/test1.csv\")\npred = pd.DataFrame(y)\ndatasets = pd.concat([test_df[\"Id\"],pred],axis=1)\ndatasets.columns=[\"Id\",\"MEDV\"]\ndatasets.to_csv(\"submi.csv\",index=False)","0b9aed66":"submit = pd.read_csv(\".\/submi.csv\")\nsubmit","4b5c8c71":"Determination of Best Model and using it for Test Dataset","70a272ae":"Standardizing data : Mean = 0 and Variance = 1","5929e49f":"Considering Polynomial Features","f12e8fed":"Training different Regression Models and their Evaluation based on RMSE","d175962c":"Exploring the Dataset","3fa37844":"Using Keras for Deep Learning","3f5c94e6":"Dealing with Missing Values","8b02a2bb":"Train - Test Split","7d094327":" Importing Packages","9f5f5da0":"3. Correlation Matrix:\n    A correlation matrix is a table showing correlation coefficients between sets of features.\n    Values close to 1 and -1 indicate strong correlation. ","ef051cd5":"Training Dataset "}}