{"cell_type":{"fd2d2738":"code","118b4548":"code","0aceccab":"code","a8698f1b":"code","f60483ef":"code","78608c57":"code","cdf6ede4":"code","3acd2121":"code","d964f050":"code","348edcc8":"code","e3663038":"code","504d7fa8":"code","017a64cd":"code","913cfc16":"code","c666f2ad":"code","7338d1e8":"code","a1aba608":"code","92076792":"code","3319ee79":"code","ec776128":"code","553c1e40":"code","f221c419":"code","d113971e":"markdown","a0a5c7bf":"markdown","4837a44a":"markdown","c94ed778":"markdown","35d205b7":"markdown"},"source":{"fd2d2738":"# Let's import all the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","118b4548":"# Model to predict the sales given the spend on marketing\ndata = {'Marketing Spend( Million $)' : [23 , 26, 30 , 34 , 43 , 48], \n        'Sales (Million $)': [651 , 762 , 856 ,1063 , 1190 , 1298]}\ndata = pd.DataFrame(data)\ndata","0aceccab":"# Plotting a scatter plot to visualize the data\nsns.scatterplot( data = data , x = 'Marketing Spend( Million $)' , y = 'Sales (Million $)')","a8698f1b":"# Scaling the data between 0 and 1\nscaler = MinMaxScaler()\ndata[['Marketing Spend( Million $)', 'Sales (Million $)']] = \\\nscaler.fit_transform(data[['Marketing Spend( Million $)', 'Sales (Million $)']])","f60483ef":"data","78608c57":"# Plotting a scatter plot\nsns.scatterplot( data = data , x = 'Marketing Spend( Million $)' , y = 'Sales (Million $)')","cdf6ede4":"# Read in the data\nX = data['Marketing Spend( Million $)'].values.reshape(-1,1)\ny = data['Sales (Million $)']","3acd2121":"reg = LinearRegression() \nreg.fit(X,y)","d964f050":"# Predictions on the basis of the model\ny_pred = reg.predict(X)\ny_pred","348edcc8":"r2_score(y, y_pred) # Marketing spends account for 96.5% of the variation present in the Sales","e3663038":"#Residual Sum of Squares = Mean_Squared_Error * Total number of datapoints\nrss = np.sum(np.square(y - y_pred))\nprint(rss)\nmse = mean_squared_error(y, y_pred)\nprint(mse)\n# Root Mean Squared Error\nrmse = mse**0.5\nprint(rmse)","504d7fa8":"# Plot for Predicted sales vs Marketing Spend\nplt.scatter( X , y , color = 'blue') # original data shown as blue points\nplt.plot(X , y_pred , color = 'red' , linewidth = 3) # Fitted model in red\nplt.xlabel(\"Marketing Spend (Million $)\")\nplt.ylabel(\"Predicted Sales (Million $)\")\nplt.show()","017a64cd":"#help(PolynomialFeatures)\nX = data['Marketing Spend( Million $)'].values.reshape(-1,1)\nprint(X)","913cfc16":"poly = PolynomialFeatures(3) # Want to generate features with degree less than or equal to\n                             # the specified degree\nY = poly.fit_transform(X) # Transform the variable X to 1, X, X^2, X^3\nprint(Y)","c666f2ad":"# Building the polynomial regression model with degree 5\ndegree=5 # got this number through trial and this is the lowest value which fit the data perfectly\npolyreg5 = PolynomialFeatures(degree)\nX_poly5 = polyreg5.fit_transform(X) # Transform the variable X to 1, X, X^2, X^3, X^4, X^5\nlinreg5 = LinearRegression()\nlinreg5.fit(X_poly5, y)","7338d1e8":"# Plotting the polynomial regression(degree-5) and simple linear regression\nX_seq = np.linspace(X.min(),X.max(),300).reshape(-1,1) # Between 0 and 1 we get 300 equally spaced values\n# print(X_seq)\nplt.figure()\nplt.scatter(X,y) \nplt.plot(X_seq,linreg5.predict(polyreg5.fit_transform(X_seq)),color=\"black\") # model fit with polynomial regression\nplt.plot(X_seq,reg.predict(X_seq),color=\"red\") # model fit with linear regression\nplt.title(\"Polynomial regression with degree \"+str(degree))\nplt.xlabel(\"Marketing Spend (Million $)\")\nplt.ylabel(\"Predicted Sales (Million $)\")\nplt.show()","a1aba608":"y_pred5 = linreg5.predict(polyreg5.fit_transform(X)) # store predictions from the polynomial regression in the variable y_pred5\nprint(r2_score(y, y_pred5))","92076792":"# Metrics to assess model performance\nrss = np.sum(np.square(y - y_pred5))\nprint(rss)\nmse = mean_squared_error(y, y_pred5)\nprint(mse)\nrmse = mse**0.5\n# Root Mean Squared Error\nprint(rmse)","3319ee79":"# Applying Ridge Regression with varying the hyperparameter 'lambda'\n\nX_seq = np.linspace(X.min(),X.max(),300).reshape(-1,1) # values to be considered for predictor variable\nlambdas = [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000] # Higher the value of lambda, \n                                                  # more the regularization\nfor i in lambdas: # for each lambda we get different model coefficients\n    degree = 5 # Degree for polynomial regression - chose 5 since this is the lowest number that gave a perfect fit\n    # Creating degree 5 features\n    ridgecoef = PolynomialFeatures(degree)\n    # Transforming input features to polynomial features (1, x1, x2, x3, x4, x5)    \n    X_poly = ridgecoef.fit_transform(X)\n    ridgereg = Ridge(alpha = i) # Initialize the Ridge Regression model with a specific lambda\n    ridgereg.fit(X_poly, y) # fit the model on the polynomial features\n    \n    # Plotting the ridge regression model for each lambda\n    plt.figure()\n    plt.scatter(X,y)\n    plt.plot(X_seq,ridgereg.predict(ridgecoef.fit_transform(X_seq)),color=\"black\") # Polynomial Regression\n    plt.plot(X_seq,reg.predict(X_seq),color=\"red\") # Linear Regression\n    plt.title(\"Polynomial regression with degree \"+str(degree) + \" and lambda = \" + str(i))\n    plt.show()\n    \n    #Computing the r2 score\n    y_pred = ridgereg.predict(ridgecoef.fit_transform(X))\n    print(\"r2 score = \" + str(r2_score(y, y_pred))) \n    print(ridgereg.coef_) # model coefficients\n","ec776128":"# Applying Lasso Regression with varying the hyperparameter 'lambda'\n\nlambdas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\nfor i in lambdas:\n    degree = 5\n    # Creating degree 5 features\n    lassocoef = PolynomialFeatures(degree)\n    # Transforming input features to polynomial features (1, x1, x2, x3, x4, x5)\n    X_poly = lassocoef.fit_transform(X)\n    lassoreg = Lasso(alpha = i)\n    lassoreg.fit(X_poly, y)\n    # Plotting the ridge model\n    plt.figure()\n    plt.scatter(X,y)\n    plt.plot(X_seq,lassoreg.predict(lassocoef.fit_transform(X_seq)),color=\"black\")\n    plt.plot(X_seq,reg.predict(X_seq),color=\"red\")\n    plt.title(\"Polynomial regression with degree \"+str(degree) + \" and lambda = \" + str(i))\n    plt.show()\n    # Compute R^2 \n    y_pred = lassoreg.predict(lassocoef.fit_transform(X))\n    print(\"r2 score = \" + str(r2_score(y, y_pred)))\n    print(lassoreg.coef_)","553c1e40":"# Get the model coefficients for specific lambda say 0.001\n\n# Ridge Regression\n\nridgecoef = PolynomialFeatures(degree, include_bias = True) # Creating degree 5 features\n# Transforming input features to polynomial features (1, x1, x2, x3, x4, x5)    \nX_poly = ridgecoef.fit_transform(X)\nridgereg = Ridge(alpha = 0.001) # Initialize the Ridge Regression model with a specific lambda\nridgereg.fit(X_poly, y) # fit the model on the polynomial features\nprint(ridgereg.coef_)    \ny_pred = ridgereg.predict(ridgecoef.fit_transform(X))\nprint(\"r2 score = \" + str(r2_score(y, y_pred)))\n\n# Lasso Regression\nlassocoef = PolynomialFeatures(degree) # Creating degree 5 features\n# Transforming input features to polynomial features (1, x1, x2, x3, x4, x5)\nX_poly = lassocoef.fit_transform(X)\nlassoreg = Lasso(alpha = 0.001)\nlassoreg.fit(X_poly, y)\nprint(lassoreg.coef_)\ny_pred = lassoreg.predict(lassocoef.fit_transform(X))\nprint(\"r2 score = \" + str(r2_score(y, y_pred)))","f221c419":"betas = pd.DataFrame(index=['1', 'x', 'x2', 'x3', 'x4', 'x5'], \n                     columns = ['Polynomial', 'Ridge', 'Lasso'])\nbetas['Polynomial'] = linreg5.coef_ # Polynomial Regression\nbetas['Ridge'] = ridgereg.coef_ # Ridge Regression\nbetas['Lasso'] = lassoreg.coef_ # Lasso Regression\nbetas","d113971e":"Let us say that we want a better fit and hence we use higher degree polynomials as predictors. ","a0a5c7bf":"Build the Linear Regression Model","4837a44a":"### Ridge Regression","c94ed778":"### Lasso Regression","35d205b7":"### Ridge and Lasso Regression for specific lambda value"}}