{"cell_type":{"4b810d1a":"code","81c06987":"code","4c0fdb99":"code","f1455306":"code","6629c4c9":"code","ca35762c":"code","87081b4a":"code","943f3dd3":"code","fb39ac52":"code","20282538":"code","851d96d0":"code","ec4f0aed":"code","5d81e0c9":"code","37c71984":"code","9b7ce6fb":"code","79fa7216":"code","1beaf100":"code","3f856e0f":"code","f8b38bbb":"code","561c923a":"code","54434717":"code","c73462a9":"code","f2d04757":"code","0e106d1b":"code","236c4693":"code","2531a41c":"code","e3fb6f97":"code","f0426ca1":"code","c481120e":"code","7f198b18":"code","e56689cc":"code","61617110":"code","25671d76":"code","87c3fa8c":"code","16acb962":"code","e2c3dfbf":"code","00869349":"code","71a15c90":"code","52758e5e":"code","d62025ab":"code","bfa67c22":"code","47156d02":"code","4685247f":"code","96646266":"code","5f01f188":"code","1cf3112e":"code","c94b6730":"code","48f8a45f":"code","3f2329af":"code","9110e766":"markdown","f09ade93":"markdown","43bcaa3c":"markdown","84d6b68d":"markdown","6aea9852":"markdown","a917e481":"markdown","e46ef9c4":"markdown","51e2ae4b":"markdown","050854c8":"markdown","e58e9ec4":"markdown","37bc5723":"markdown","9f2df1b7":"markdown","f973951d":"markdown","73c1d36b":"markdown","4c16cd56":"markdown"},"source":{"4b810d1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81c06987":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nplt.rcParams['figure.figsize'] = (15, 8)","4c0fdb99":"!pip install git+https:\/\/github.com\/qubvel\/efficientnet","f1455306":"import json\nimport math\nimport os\n\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, auc, roc_auc_score, roc_curve\nimport sklearn\nimport scipy\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense\n\nfrom efficientnet.tfkeras import EfficientNetB7 as effnetb7\n\n\n%matplotlib inline","6629c4c9":"SEED = 2020","ca35762c":"def perc_data(column, df):\n    cls = column.unique()\n    x = column.value_counts()\n    rows = df.shape[0]\n    print(\"CLASS\\t\\t : \\tPERCENTAGE\")\n    print(\"------------------------------------\")\n    for i in cls:\n        print(f\"{i}\\t\\t : \\t{(x[i]\/rows)*100}\")\n    print(f\"NULL\\t\\t : \\t{(column.isna().sum()\/rows)*100}\")","87081b4a":"def bgr2rgb(img):\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","943f3dd3":"def sample_images(df, train_img_path):\n    img_l = df.loc[df[\"target\"]==1].sample(7)[\"image_name\"].values\n    print(\"Target : 1\")\n    plt.figure(figsize = (30, 15))\n    for i, img_name in enumerate(img_l):\n        img = bgr2rgb(cv2.imread(f\"{train_img_path}\/{img_name}.jpg\"))\n        plt.subplot(1,7,i+1)\n        plt.axis(\"off\")\n        plt.imshow(img)\n    plt.show()\n    img_l = df.loc[df[\"target\"]==0].sample(7)[\"image_name\"].values\n    print(\"Target : 0\")\n    plt.figure(figsize = (30, 15))\n    for i, img_name in enumerate(img_l):\n        img = bgr2rgb(cv2.imread(f\"{train_img_path}\/{img_name}.jpg\"))\n        plt.subplot(1,7,i+1)\n        plt.axis(\"off\")\n        plt.imshow(img)\n    plt.draw()","fb39ac52":"train_df = pd.read_csv(\"..\/input\/jpeg-isic2019-512x512\/train.csv\")\ntrain_df.head()","20282538":"train_df.shape","851d96d0":"perc_data(train_df.diagnosis, train_df)","ec4f0aed":"perc_data(train_df.benign_malignant, train_df)","5d81e0c9":"perc_data(train_df.sex, train_df)","37c71984":"train_df2020 = pd.read_csv(\"..\/input\/jpeg-melanoma-512x512\/train.csv\")\ntrain_df2020.head()","9b7ce6fb":"train_df2020.info()","79fa7216":"perc_data(train_df2020.diagnosis, train_df2020)","1beaf100":"perc_data(train_df2020.target, train_df2020)","3f856e0f":"perc_data(train_df2020.benign_malignant, train_df2020)","f8b38bbb":"sample_images(train_df, \"..\/input\/jpeg-isic2019-512x512\/train\/\")","561c923a":"sample_images(train_df2020, \"..\/input\/jpeg-melanoma-512x512\/train\/\")","54434717":"temp2020 = train_df2020\ntemp2020.loc[temp2020['diagnosis']=='seborrheic keratosis', 'diagnosis'] = 'BKL'\ntemp2020.loc[temp2020['diagnosis']=='lichenoid keratosis', 'diagnosis'] = 'BKL'\ntemp2020.loc[temp2020['diagnosis']=='solar lentigo', 'diagnosis'] = 'BKL'\ntemp2020.loc[temp2020['diagnosis']=='lentigo NOS', 'diagnosis'] = 'BKL'\ntemp2020.loc[temp2020['diagnosis']=='cafe-au-lait macule', 'diagnosis'] = 'unknown'\ntemp2020.loc[temp2020['diagnosis']=='atypical melanocytic proliferation', 'diagnosis'] = 'unknown'\ntemp2020.loc[temp2020['diagnosis']=='nevus', 'diagnosis'] = 'NV'\ntemp2020.loc[temp2020['diagnosis']=='melanoma', 'diagnosis'] = 'MEL'","c73462a9":"perc_data(temp2020['diagnosis'], temp2020)","f2d04757":"temp2020['path'] = \"..\/input\/jpeg-melanoma-512x512\/train\/\"+temp2020['image_name']+\".jpg\"","0e106d1b":"img = cv2.imread(temp2020.iloc[0]['path'])\nplt.imshow(img)\nprint(img.shape)","236c4693":"temp2020.head()","2531a41c":"temp2019 = train_df","e3fb6f97":"temp2019['path'] = \"..\/input\/jpeg-isic2019-512x512\/train\/\"+temp2019['image_name']+\".jpg\"\ntemp2019.head()","f0426ca1":"train_temp = temp2019.append(temp2020, ignore_index=True)","c481120e":"train_temp","7f198b18":"train_temp = train_temp.sample(frac = 1, random_state = SEED).reset_index(drop=True)","e56689cc":"perc_data(train_temp['diagnosis'], train_temp)","61617110":"df = train_temp","25671d76":"df['diagnosis'].value_counts()","87c3fa8c":"mel = df[df['diagnosis']==\"MEL\"].sample(1000, random_state = SEED)\nnv = df[df[\"diagnosis\"]==\"NV\"].sample(750, random_state = SEED)\nunknown = df[df[\"diagnosis\"]==\"unknown\"].sample(625, random_state = SEED)\nbcc = df[df[\"diagnosis\"]==\"BCC\"].sample(250, random_state = SEED)\nbkl = df[df[\"diagnosis\"]==\"BKL\"].sample(125, random_state = SEED)\nak = df[df[\"diagnosis\"]==\"AK\"].sample(125, random_state = SEED)\nvasc = df[df[\"diagnosis\"]==\"VASC\"].sample(125, random_state = SEED)","16acb962":"mel = mel.append(nv, ignore_index = True)\nmel = mel.append(unknown, ignore_index = True)\nmel = mel.append(bcc, ignore_index = True)\nmel = mel.append(bkl, ignore_index = True)\nmel = mel.append(ak, ignore_index = True)\nmel = mel.append(vasc, ignore_index = True)\nmel","e2c3dfbf":"perc_data(mel['diagnosis'], mel)","00869349":"train=mel\ntrain = train.sample(frac = 1, random_state = SEED).reset_index(drop=True)\ntrain","71a15c90":"path1 = train.loc[train['target']==1, 'path'].sample(1).values[0]\npath0 = train.loc[train['target']==0, 'path'].sample(1).values[0]","52758e5e":"img1 = bgr2rgb(cv2.imread(path1))\nimg0 = bgr2rgb(cv2.imread(path0))\nplt.figure(figsize = (30, 15))\nplt.subplot(1, 2, 1)\nplt.imshow(img1)\nplt.title(\"Target : 1\")\nplt.subplot(1,2,2)\nplt.imshow(img0)\nplt.title(\"Target : 0\")\nplt.show()","d62025ab":"def clahe_lab(img):\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    # lab = img\n    lab_planes = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=1.0)\n    lab_planes[0] = clahe.apply(lab_planes[0])\n    lab_planes[1] = clahe.apply(lab_planes[1])\n    lab_planes[2] = clahe.apply(lab_planes[2])\n    lab = cv2.merge(lab_planes)\n    rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n    return rgb\n\ndef crop_image_from_gray(img,tol=30):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n      \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n  #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n  #         print(img.shape)\n    if img.shape!=(512, 512, 3):\n        img = cv2.resize(img, (512, 512))\n    return img\n\ndef preprocess(img):\n    hist_eq = clahe_lab(img)\n    img = crop_image_from_gray(hist_eq)\n    return img","bfa67c22":"N = len(train['path'].values)\nimg_train = np.empty((N, 512, 512, 3), dtype = np.uint8)\n\nfor i, img_path in enumerate(tqdm(train['path'].values)):\n    img = cv2.imread(img_path)\n    img = preprocess(img)\n    img_train[i, :, :, :] = img\n\nnp.save(\"x_train\", img_train)","47156d02":"diag_dict = {}\ndiag_unique = train.diagnosis.unique()\nfor i in range(len(diag_unique)):\n    diag_dict[diag_unique[i]] = i\n\ndiag_dict","4685247f":"train[\"y\"] = train['diagnosis'].map(diag_dict)","96646266":"train","5f01f188":"y_onehot = pd.get_dummies(train[\"y\"]).values\n\nmulti = y_onehot","1cf3112e":"for i in range(len(multi)):\n    l = multi[i]\n    for j in range(5, -1, -1):\n        l[j] = np.logical_or(l[j], l[j+1])\n    multi[i] = l","c94b6730":"multi[0]","48f8a45f":"np.save(\"multilabel_y\", multi)","3f2329af":"train.to_csv(\"dataset.csv\", index = False)","9110e766":"### Mapping 2020 diagnosis with 2019 diagnosis","f09ade93":"## Preapring the dataset","43bcaa3c":"### BGR2RGB","84d6b68d":"### 2019 data","6aea9852":"## 2020 Dataset","a917e481":"## Plot images","e46ef9c4":"## Functions","51e2ae4b":"## CONSTANTS","050854c8":"## Image Processing","e58e9ec4":"### 2020 data","37bc5723":"## Combine 2019 and 2020 datasets","9f2df1b7":"### Perc_Data","f973951d":"## 2019 Dataset","73c1d36b":"### Sample Images","4c16cd56":"### Adding path column"}}