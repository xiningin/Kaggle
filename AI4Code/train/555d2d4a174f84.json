{"cell_type":{"417bc9ba":"code","7106dcd7":"code","538afbd9":"code","e5d28607":"code","d896e4ec":"code","84dcd4c2":"code","84276bee":"code","6da6f471":"code","70a23884":"code","88d68a6c":"code","c24b1bc9":"code","8650bf4e":"code","aeee3e61":"code","4b35ce35":"code","ace9dff9":"code","9db5c86a":"code","d255292e":"code","000f9897":"code","8767cb99":"code","efde19a4":"code","6245aee9":"code","5b8384a1":"code","10f277f8":"code","275d5998":"markdown","2d2531fb":"markdown","9a4bdfb0":"markdown","01d518e0":"markdown","a1c7f0e1":"markdown","f426cd32":"markdown","256b8c8e":"markdown","f7a8d667":"markdown"},"source":{"417bc9ba":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7106dcd7":"train = pd.read_csv(\"..\/input\/google-quest-challenge\/train.csv\", index_col='qa_id')\ntrain.shape","538afbd9":"test = pd.read_csv(\"..\/input\/google-quest-challenge\/test.csv\", index_col='qa_id')\ntest.shape","e5d28607":"target_columns = [\n    'question_asker_intent_understanding',\n    'question_body_critical',\n    'question_conversational',\n    'question_expect_short_answer',\n    'question_fact_seeking',\n    'question_has_commonly_accepted_answer',\n    'question_interestingness_others',\n    'question_interestingness_self',\n    'question_multi_intent',\n    'question_not_really_a_question',\n    'question_opinion_seeking',\n    'question_type_choice',\n    'question_type_compare',\n    'question_type_consequence',\n    'question_type_definition',\n    'question_type_entity',\n    'question_type_instructions',\n    'question_type_procedure',\n    'question_type_reason_explanation',\n    'question_type_spelling',\n    'question_well_written',\n    'answer_helpful',\n    'answer_level_of_information',\n    'answer_plausible',\n    'answer_relevance',\n    'answer_satisfaction',\n    'answer_type_instructions',\n    'answer_type_procedure',\n    'answer_type_reason_explanation',\n    'answer_well_written'\n]","d896e4ec":"y_train = train[target_columns].copy()\nx_train = train.drop(target_columns, axis=1)\ndel train\n\nx_test = test.copy()\ndel test","84dcd4c2":"x_train.head(1).T","84276bee":"import tensorflow_hub as hub\nimport tensorflow as tf","6da6f471":"# from https:\/\/github.com\/tensorflow\/models\/blob\/master\/official\/nlp\/bert\/tokenization.py\n\n# see https:\/\/www.kaggle.com\/rtatman\/import-functions-from-kaggle-script\n\nfrom shutil import copyfile\n\n\ncopyfile(src = \"..\/input\/tf-bert-tokenization\/tokenization.py\", dst = \"..\/working\/tokenization.py\")\n\nfrom tokenization import *","70a23884":"# from https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-12_H-768_A-12\/1\n\nBERT = '..\/input\/bert-model'\n\ntokenizer = FullTokenizer(BERT + '\/assets\/vocab.txt', True)","88d68a6c":"tokenizer.tokenize('Hello world from BERT FullTokenizer!')","c24b1bc9":"# from ??? well known code\n\ndef _get_masks(tokens, max_seq_length):\n    \"\"\"Mask for padding\"\"\"\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n\ndef _get_segments(tokens, max_seq_length):\n    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    segments = []\n    first_sep = True\n    current_segment_id = 0\n    for token in tokens:\n        segments.append(current_segment_id)\n        if token == \"[SEP]\":\n            if first_sep:\n                first_sep = False\n            else:\n                current_segment_id = 1\n    return segments + [0] * (max_seq_length - len(tokens))\n\ndef _get_ids(tokens, tokenizer, max_seq_length):\n    \"\"\"Token ids from Tokenizer vocab\"\"\"\n    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n    return input_ids","8650bf4e":"import math\n\n\ndef trim_tokens(t, q, a, max_t, max_q, max_a):\n    if (len(t) + len(q) + len(a)) > (max_t + max_q + max_a):\n        \n        _max_t = max_t\n        _max_q = max_q\n        _max_a = max_a\n        \n        if len(t) > _max_t:\n            t = t[:_max_t]\n        else:\n            x = (_max_t - len(t)) \/ 2.\n            _max_q += math.ceil(x)\n            _max_a += math.floor(x)\n        \n        if len(q) > _max_q:\n            q = q[:_max_q]\n        else:\n            _max_a += (_max_q - len(q))\n        \n        if len(a) > _max_a:\n            a = a[:_max_a]\n    \n    return t,q,a\n\n\ndef make_bert_input(x, max_question_title_length=24, max_question_body_length=242, max_answer_length=242):\n    \n    max_sequence_length = max_question_title_length + max_question_body_length + max_answer_length + 4\n    print('Calculated max sequence length:', max_sequence_length)\n    \n    input_ids = []\n    input_masks = []\n    input_segments = []\n    \n    for idx, row in x[['question_title', 'question_body', 'answer']].iterrows():\n        \n        # get tokens\n        t,q,a = trim_tokens(tokenizer.tokenize(row.question_title),\n                            tokenizer.tokenize(row.question_body),\n                            tokenizer.tokenize(row.answer),\n                            max_question_title_length,\n                            max_question_body_length,\n                            max_answer_length)\n        \n        tokens = ['[CLS]'] + t + ['[SEP]'] + q + ['[SEP]'] + a + ['[SEP]']\n        # print(tokens)\n        \n        input_ids.append(_get_ids(tokens, tokenizer, max_sequence_length))\n        input_masks.append(_get_masks(tokens, max_sequence_length))\n        input_segments.append(_get_segments(tokens, max_sequence_length))\n    \n    return [\n        np.asarray(input_ids, dtype=np.int32),\n        np.asarray(input_masks, dtype=np.int32),\n        np.asarray(input_segments, dtype=np.int32)\n    ]","aeee3e61":"max_sequence_length = 512\n\n# bert_input_train = make_bert_input(x_train)","4b35ce35":"def make_model():\n    \n    input_word_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,\n                                           name=\"input_word_ids\")\n    input_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,\n                                       name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,\n                                        name=\"segment_ids\")\n    \n    bert_layer = hub.KerasLayer(BERT, trainable=True)\n    \n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    tmp = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n    tmp = tf.keras.layers.Dropout(0.2)(tmp)\n    out = tf.keras.layers.Dense(len(target_columns), activation='sigmoid', name='dense_output')(tmp)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    \n    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n    \n    return model","ace9dff9":"from scipy.stats import spearmanr\n\n\ndef mean_spearmanr_correlation_score(y_true, y_pred):\n    return np.mean([spearmanr(y_pred[:, idx] + np.random.normal(0, 1e-7, y_pred.shape[0]),\n                              y_true[:, idx]).correlation for idx in range(len(target_columns))])","9db5c86a":"trained_estimators = []","d255292e":"from sklearn.model_selection import KFold\nimport tensorflow.keras.backend as K\nimport math\n\n\nn_splits = 5\n\nscores = []\n\ncv = KFold(n_splits=n_splits, random_state=42)\nidx = 1\nfor train_idx, valid_idx in cv.split(x_train, y_train, groups=x_train.question_body):\n    \n    x_train_train = x_train.iloc[train_idx]\n    y_train_train = y_train.iloc[train_idx]\n    x_train_valid = x_train.iloc[valid_idx]\n    y_train_valid = y_train.iloc[valid_idx]\n    \n    K.clear_session()\n    \n    estimator = make_model()\n    estimator.fit(make_bert_input(x_train_train), y_train_train, batch_size=8, epochs=5)\n    trained_estimators.append(estimator)\n    \n    oof_part = estimator.predict(make_bert_input(x_train_valid))\n    score = mean_spearmanr_correlation_score(y_train_valid.values, oof_part)\n    print('Score:', score)\n    \n    if not math.isnan(score):\n        # trained_estimators.append(estimator)\n        scores.append(score)\n    \n    # limit number of iterations to complete job within 2 hours\n    idx += 1\n    if idx > 3:\n        break\n\n\nprint('Mean score:', np.mean(scores))","000f9897":"len(trained_estimators)","8767cb99":"y_pred = []\nfor estimator in trained_estimators:\n    y_pred.append(estimator.predict(make_bert_input(x_test)))","efde19a4":"from scipy.stats import rankdata\n\n\ndef blend_by_ranking(data, weights):\n    out = np.zeros(data.shape[0])\n    for idx,column in enumerate(data.columns):\n        out += weights[idx] * rankdata(data[column].values)\n    out \/= np.max(out)\n    return out","6245aee9":"submission = pd.read_csv(\"..\/input\/google-quest-challenge\/sample_submission.csv\", index_col='qa_id')\n\nout = pd.DataFrame(index=submission.index)\nfor column_idx,column in enumerate(target_columns):\n    \n    # collect all predictions for one column\n    column_data = pd.DataFrame(index=submission.index)\n    for prediction_idx,prediction in enumerate(y_pred):\n        column_data[str(prediction_idx)] = prediction[:, column_idx]\n    \n    out[column] = blend_by_ranking(column_data, np.ones(column_data.shape[1]))","5b8384a1":"out.head()","10f277f8":"out.to_csv(\"submission.csv\")","275d5998":"## Predict","2d2531fb":"## Blend by ranking","9a4bdfb0":"## BERT","01d518e0":"## Submit predictions","a1c7f0e1":"## Fit","f426cd32":"## Extract target variables","256b8c8e":"## Load data","f7a8d667":"## BERT"}}