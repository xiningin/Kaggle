{"cell_type":{"d785457a":"code","33c1e7da":"code","87e5e8ca":"code","ff205b05":"code","24b68612":"code","672d78ac":"code","02dd0e40":"code","03ee60ad":"code","69f4f0f0":"code","b356da6f":"code","d6df24b4":"code","a292ffba":"code","f8a51759":"code","875b83a1":"code","2148eaf7":"code","92b3ee71":"code","9ab1c355":"code","70848716":"code","dc7a3be2":"code","59ed8149":"code","1a1f40ff":"code","d16adbbc":"markdown","760c1c7a":"markdown","e4b1dc1e":"markdown","444471da":"markdown","e5396f04":"markdown"},"source":{"d785457a":"# Installing Libraries\n\n!pip install lazypredict --user -q\n!pip install sweetviz","33c1e7da":"# Importing libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sweetviz \nfrom lazypredict.Supervised import LazyClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\n#Setting random seed\nSEED = 42","87e5e8ca":"# Importing datasets\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_sub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n\nprint('Train shape:', df_train.shape)\nprint('Test shape:', df_test.shape)","ff205b05":"df_train.head()","24b68612":"df_test.head()","672d78ac":"pd.DataFrame({'train_null': df_train.drop(columns='Survived').isnull().sum(), 'test_null': df_test.isnull().sum()})","02dd0e40":"train_report = sweetviz.compare(source=[df_train, \"Train\"], compare=[df_test, \"Test\"], target_feat='Survived')","03ee60ad":"train_report.show_notebook()","69f4f0f0":"# Fare\ndf_train['Embarked'] = df_train['Embarked'].fillna(df_train.Embarked.mode().item())\ndf_test['Fare'] = df_test['Fare'].fillna(df_test.Fare.mean())\n\n# Age\ndf_train['Age'] = df_train.groupby(['Pclass', 'Sex']).Age.apply(lambda x: x.fillna(x.median()))\ndf_test['Age'] = df_test.groupby(['Pclass', 'Sex']).Age.apply(lambda x: x.fillna(x.median()))\n\n# Combine train and test sets for preprocessing\ndata = pd.concat([df_train, df_test], axis=0)\n\n# Cabin\/Deck\ncabin_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T': 1, 'M': 8}\ndata['Deck'] = data['Cabin'].str[0].fillna('M').replace(cabin_map)\n\n# Fill Null values\ndata = data.fillna('None')\n\n# Drop\ndrop_cols= ['Name']\ndata = data.drop(drop_cols, axis=1)\n\n# Label Encode\nfor column in data.dtypes[(data.dtypes==object) | (data.dtypes==bool)].index:\n    data[column] = pd.Categorical(data[column]).codes\n\n# One Hot encode\ncategorical = ['Pclass', 'SibSp', 'Parch','Embarked', 'Deck']\ndata = pd.get_dummies(data, columns=categorical)\n\n# Splitting into train and test\ntrain = data.iloc[df_train.index]\ntest = data.iloc[df_test.index+df_train.shape[0]].drop(columns=['Survived'])\n\n# Resetting index in case\ntrain = train.reset_index(drop=True)\ntrain.drop('PassengerId', axis=1, inplace=True)\ntest = test.reset_index(drop=True)\n\nprint('Train new shape:', train.shape)\nprint('Test new shape:', test.shape)","b356da6f":"train","d6df24b4":"X_train, X_val, y_train, y_val = train_test_split(train.drop('Survived', axis=1), train['Survived'],test_size=.15,random_state =SEED)","a292ffba":"# Creating and training a LazyClassifier\nclf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\nscores, predictions = clf.fit(X_train, X_val, y_train, y_val)","f8a51759":"# Showing results\nscores","875b83a1":"# Getting the trained models\nmodels = clf.provide_models(X_train, X_val, y_train, y_val)","2148eaf7":"# Extracting the list of the trained models sorted by higher accuracy\npredictions.index","92b3ee71":"# Generating results using model ensemble\n# Using an ensemble of models instead of only one is recommended to avoid overfitting\n\nensemble_sizes=list(range(1,len(predictions.index)))\nacc_train_list=[]\nacc_val_list=[]\nf1_train_list=[]\nf1_val_list=[]\n\nfor size in ensemble_sizes:\n    acc_train, acc_val, f1_train, f1_val= 0, 0, 0, 0\n    for model in predictions.index[:size]:\n        acc_train += accuracy_score(models[model].predict(X_train),y_train)\n        acc_val += accuracy_score(models[model].predict(X_val),y_val)\n        f1_train += f1_score(models[model].predict(X_train),y_train)\n        f1_val += f1_score(models[model].predict(X_val),y_val)\n    acc_train_list.append(acc_train\/size)\n    acc_val_list.append(acc_val\/size)\n    f1_train_list.append(f1_train\/size)\n    f1_val_list.append(f1_val\/size)\nresults_df = pd.DataFrame({'Ensemble_size':ensemble_sizes, 'Accuracy_train':acc_train_list, 'Accuracy_val':acc_val_list,\n                           'F1_score_train':f1_train_list, 'F1_score_val':f1_val_list, \n                           'Accuracy_diff':[np.round(i-j, 2) for (i,j) in zip(acc_train_list,acc_val_list)]})\nresults_df.set_index('Ensemble_size',inplace=True)\nresults_df","9ab1c355":"# The best ensemble size is chosen based on the Accuracy_diff which is a trivial indicator of overfitting\nBest_ensemble_size = results_df.Accuracy_diff.argmin()+1\nprint(f'Best ensemble size:{ Best_ensemble_size}')","70848716":"# Generating the test set predictions using the chosen ensemble of models\ny_pred_list=[]\nfor model in predictions.index[:Best_ensemble_size]:\n    y_pred_list.append(models[model].predict(test.drop('PassengerId', axis=1)))","dc7a3be2":"# Creating a submission dataframe\ndf_sub.Survived = np.round(np.sum(y_pred_list,axis=0)\/Best_ensemble_size).astype(int)","59ed8149":"# Saving the submission dataframe\ndf_sub.to_csv('Submission.csv', index=False)","1a1f40ff":"df_sub","d16adbbc":"## Lazy EDA\n\nSweetVIZ is a library for data analysis and visualization, it perform automatic EDA on dataframes and returns a report containing graphs and statistics about the provided datasets. It can also compare two datasets and shows key statistics to better understand the differences between both distribution. for more information about SweetVIZ refer to their github [repository](https:\/\/github.com\/fbdesignpro\/sweetviz).","760c1c7a":"## Lazy Predictions\n\nIn the following section, we're going to use the Lazy Predict library which is a very useful tool that can be used to perform either classification or regression using all of the models available on scikit-learn at the same time and returns a report on the results of each trained model. For more information about this library, feel free to check their Github [reporsitory](https:\/\/github.com\/shankarpandala\/lazypredict).","e4b1dc1e":"# Lazy Titanic EDA & Predication\n![Lazy_programmer](https:\/\/i.postimg.cc\/Zq6tT7td\/Lazy-Titanic.jpg)\n\nIn this notebook I present a lazy approach to explore the Titanic dataset and perform predictions. The purpose of this notebook is to shed some  light on two interesting libraries provide interesting tools that can be used to perform quick exploratory data analysis and train different ML models.\n\n**This notebook uses only the official dataset**\n\n(Up to date) The LB score of this notebook is 0.77033\n\nIf you find useful information, feel free to share this notebook and upvote it.","444471da":"**There are many things that can be done to improve the predictions and achieve much higher accuracy, so don't be a lazy engineer and go to work!**\n\n**Thanks for stopping by!**","e5396f04":"## Data Preprocessing\n\nBased on the statistics we have, we can now perprocess the data and perform some feature engineering."}}