{"cell_type":{"b0ed403a":"code","30a103e1":"code","f8495706":"code","570c3947":"code","4dacaa22":"code","24ada066":"code","3803f0b1":"code","0f87ab50":"code","e90969b2":"code","dfbc5f65":"code","82a23a5b":"markdown"},"source":{"b0ed403a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","30a103e1":"aapl = pd.read_csv('..\/input\/stocknew\/AAPL_CLOSE',index_col='Date',parse_dates=True)\ncisco = pd.read_csv('..\/input\/stocknew\/GOOG_CLOSE',index_col='Date',parse_dates=True)\nibm = pd.read_csv('..\/input\/stocknew\/IBM_CLOSE',index_col='Date',parse_dates=True)\namzn = pd.read_csv('..\/input\/stocknew\/AMZN_CLOSE',index_col='Date',parse_dates=True)","f8495706":"aapl.head()","570c3947":"ibm.head()\n","4dacaa22":"cisco.head()","24ada066":"amzn.head()","3803f0b1":"stocks = pd.concat([aapl,cisco,ibm,amzn],axis=1)\nstocks.columns = ['aapl','cisco','ibm','amzn']","0f87ab50":"stocks.plot()","e90969b2":"log_ret=np.log (stocks\/stocks.shift(1))\nlog_ret.head()\nlog_ret.plot()\nplt.figure(figsize=(15,8))\nax=sns.heatmap(stocks.corr(),annot = True,)","dfbc5f65":"np.random.seed(101)\n\nnum_ports=15000\nall_weight=np.zeros((num_ports,len(stocks.columns)))\nret_arr=np.zeros(num_ports)\nvol_arr=np.zeros(num_ports)\nsharpe_arr=np.zeros(num_ports)\n \nfor ind in range(num_ports):\n    weights=np.array(np.random.random(4))\n    weights=weights\/np.sum(weights)\n    all_weight[ind,:]=weights\n    ret_arr[ind] = np.sum((log_ret.mean() * weights) *252)\n    vol_arr[ind]=np.sqrt(np.dot(weights.T,np.dot(log_ret.cov()*252,weights)))\n    sharpe_arr[ind]=ret_arr[ind]\/vol_arr[ind]\n \nm=sharpe_arr.argmax() \nsharpe_arr.max()\nret_arr[m]\nvol_arr[m]   \nall_weight[m,:]\nmax_sn_ret=ret_arr[m]\nmax_sn_vol=vol_arr[m]   \nplt.figure(figsize=(12,8))\nplt.scatter(vol_arr,ret_arr,c=sharpe_arr,cmap='plasma')\nplt.colorbar(label=\"sharpe Ratio\")\nplt.xlabel(\"volatility\")\nplt.ylabel(\"Return\")\nplt.scatter(max_sn_vol,max_sn_ret,c=\"red\",s=50,edgecolors=\"black\")","82a23a5b":"In this method i use the data of Apple,Google,IBM and Amazon stock market Closed data."}}