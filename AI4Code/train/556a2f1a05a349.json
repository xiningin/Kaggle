{"cell_type":{"af13cdec":"code","ee417c33":"code","fb8addb5":"code","090f486d":"code","78a35e1d":"code","2cd7af14":"code","b8120933":"code","2025a5d6":"code","fbabc2e9":"code","84a643b9":"code","4ddef319":"code","aeaf7edd":"code","8c1c3072":"code","54d54c16":"code","7cf4df99":"code","f52a3ab3":"markdown","e591cd45":"markdown","46b2882c":"markdown","db69acc9":"markdown","532c285f":"markdown","55738596":"markdown","71f3d6be":"markdown","14ad7022":"markdown","e9c866c0":"markdown","d45ebc7f":"markdown","5d856255":"markdown"},"source":{"af13cdec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport warnings \nwarnings.filterwarnings('ignore')","ee417c33":"df=pd.read_excel('\/kaggle\/input\/social-profile-of-customers\/Social profile of customers_without header.xlsx')\ndf.head()","fb8addb5":"df.drop(columns=['Profile','Location'],inplace=True)\ndf.head()","090f486d":"df.drop(columns=['Name ','Profession '],inplace=True)\ndf.head()","78a35e1d":"df.columns = [c.replace(' ', '_') for c in df.columns]\ndf.head()","2cd7af14":"df.drop(columns=['Prority__level_1','Priority_level_2','Priority_level_3'],inplace=True)\ndf.head()","b8120933":"df['Type_of_Location_'][0]=1\nprint(df['Type_of_Location_'][0])\ndf['Type_of_Location_'] = pd.to_numeric(df['Type_of_Location_'])\ndf.info()","2025a5d6":"df.shape","fbabc2e9":"df.info()","84a643b9":"df.isnull().sum()","4ddef319":"X=df.drop(columns='Level_of_Influence_')\ny=df[['Level_of_Influence_']]\nprint(X.shape)\nprint(y.shape)","aeaf7edd":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.25,random_state=42)\nprint(X_train.shape)\nprint(y_test.shape)","8c1c3072":"from sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import NearestNeighbors\nrf=RandomForestClassifier().fit(X_train, y_train)\nlr=LogisticRegression().fit(X_train, y_train)\nsgd=SGDClassifier().fit(X_train, y_train)\nsvc=SVC().fit(X_train, y_train)\nnb=GaussianNB().fit(X_train, y_train)\ndtc=DecisionTreeClassifier().fit(X_train, y_train)\nk_n=NearestNeighbors().fit(X_train, y_train)","54d54c16":"y_rf=rf.predict(X_test)\ny_lr=lr.predict(X_test)\ny_sgd=sgd.predict(X_test)\ny_svc=svc.predict(X_test)\ny_nb=nb.predict(X_test)\ny_dtc=dtc.predict(X_test)\n#y_k_n=k_n.predict(X_test)","7cf4df99":"from sklearn.metrics import classification_report\nprint('Random Forest: ', classification_report(y_rf,y_test))\nprint('Logistic Regression: ', classification_report(y_lr,y_test))\nprint('Stochastic Gradient Descent: ', classification_report(y_sgd,y_test))\nprint('Suport Vector: ', classification_report(y_svc,y_test))\nprint('Naive Bayes: ', classification_report(y_nb,y_test))\nprint('Decision Tree: ', classification_report(y_dtc,y_test))","f52a3ab3":"1. Let's import the data and see some sample","e591cd45":"Now we can remove last three unnecessary columns","46b2882c":"Now evaluate the model","db69acc9":"Now split the data into train and test by 75:25 ratio","532c285f":"Now let's drop unnecessary fields and then explore the data","55738596":"Very bad performance ! due to very low dataset.","71f3d6be":"Now let's build the model---actually 7 models","14ad7022":"Let's explore the data a bit detail","e9c866c0":"Now predict the outputs","d45ebc7f":"Let's separate target column from feature columns","5d856255":"Handling space problem in columns"}}