{"cell_type":{"e770f80d":"code","0900c8cd":"code","cb441744":"code","2b0d314b":"code","432f59f2":"code","62b092f3":"code","a9a9ffb4":"code","f5b79ce4":"code","aa297d47":"code","725f5ee7":"code","25f65c41":"code","bfe80510":"code","875bce55":"code","98c05ade":"code","f0d3f30d":"code","e3a3cf87":"code","e8545abe":"code","2f65a9f4":"code","cc99ecb8":"code","025fe7e7":"code","fe473e7b":"code","c4e1e263":"code","84dabfec":"code","93238ae5":"code","99d7d103":"code","d8ccaf39":"code","17d57751":"code","271ed783":"code","c88c6c04":"code","20387f71":"code","ef079a91":"code","93f32b79":"code","80c5cc2f":"code","dc0bb6ae":"markdown","18f2348a":"markdown","1d3b5e80":"markdown","141a87ca":"markdown","c61f59c6":"markdown","2ad320fa":"markdown","8c971b62":"markdown","486906d3":"markdown","81435c1b":"markdown","be99f43e":"markdown","bb4f02c3":"markdown","b9d11fd7":"markdown","43c84343":"markdown","657273c9":"markdown","9e6206fa":"markdown","6aad19d3":"markdown","eaee3aee":"markdown","5680b7af":"markdown","8e0874a0":"markdown","0e7421fc":"markdown"},"source":{"e770f80d":"#about torch...\nimport torch\nimport torch.nn as nn\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, Dataset\n\n#using numpy\nimport numpy as np\n\n#for data load or save\nimport pandas as pd\n\n#visualize some datasets\nimport matplotlib.pyplot as plt\n\n#check our work directory\nimport os\n\n#to unzip datasets\nimport zipfile","0900c8cd":"lr = 0.001 # learning_rate\nbatch_size = 100 # we will use mini-batch method\nepochs = 10 # How much to train a model","cb441744":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ntorch.manual_seed(1234)\nif device =='cuda':\n    torch.cuda.manual_seed_all(1234)","2b0d314b":"os.listdir('..\/input\/dogs-vs-cats-redux-kernels-edition')","432f59f2":"os.makedirs('..\/data', exist_ok=True)","62b092f3":"base_dir = '..\/input\/dogs-vs-cats-redux-kernels-edition'\ntrain_dir = '..\/data\/train'\ntest_dir = '..\/data\/test'","a9a9ffb4":"with zipfile.ZipFile(os.path.join(base_dir, 'train.zip')) as train_zip:\n    train_zip.extractall('..\/data')\n    \nwith zipfile.ZipFile(os.path.join(base_dir, 'test.zip')) as test_zip:\n    test_zip.extractall('..\/data')","f5b79ce4":"os.listdir(train_dir)[:5]","aa297d47":"import glob\n\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))","725f5ee7":"len(train_list)","25f65c41":"from PIL import Image\nrandom_idx = np.random.randint(1,25000,size=10)\n\nfig = plt.figure()\ni=1\nfor idx in random_idx:\n    ax = fig.add_subplot(2,5,i)\n    img = Image.open(train_list[idx])\n    plt.imshow(img)\n    i+=1\n\nplt.axis('off')\nplt.show()","bfe80510":"train_list[0].split('\/')[-1].split('.')[0]","875bce55":"int(test_list[0].split('\/')[-1].split('.')[0])","98c05ade":"print(len(train_list), len(test_list))","f0d3f30d":"from sklearn.model_selection import train_test_split\ntrain_list, val_list = train_test_split(train_list, test_size=0.2)","e3a3cf87":"#data Augumentation\ntrain_transforms =  transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\nval_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\n\ntest_transforms = transforms.Compose([   \n    transforms.Resize((224, 224)),\n     transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor()\n    ])\n","e8545abe":"class dataset(torch.utils.data.Dataset):\n    #\uac00\uc838\uc640\uc11c \ucc98\ub9ac\n    def __init__(self,file_list,transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        \n        \n    #dataset length\n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n    \n    #load an one of images\n    def __getitem__(self,idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        \n        label = img_path.split('\/')[-1].split('.')[0]\n        if label == 'dog':\n            label=1\n        elif label == 'cat':\n            label=0\n            \n        return img_transformed,label\n        ","2f65a9f4":"train_data = dataset(train_list, transform=train_transforms)\ntest_data = dataset(test_list, transform=test_transforms)\nval_data = dataset(val_list, transform=test_transforms)","cc99ecb8":"train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True )\ntest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=True)","025fe7e7":"print(len(train_data), len(train_loader))","fe473e7b":"print(len(val_data), len(val_loader))","c4e1e263":"#check our images shape\ntrain_data[0][0].shape","84dabfec":"class Cnn(nn.Module):\n    def __init__(self):\n        super(Cnn,self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n            )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        \n        self.fc1 = nn.Linear(3*3*64,10)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(10,2)\n        self.relu = nn.ReLU()\n        \n        \n    def forward(self,x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0),-1)\n        out = self.relu(self.fc1(out))\n        out = self.fc2(out)\n        return out","93238ae5":"model = Cnn().to(device)\nmodel.train()","99d7d103":"optimizer = optim.Adam(params = model.parameters(),lr=0.001)\ncriterion = nn.CrossEntropyLoss()","d8ccaf39":"epochs = 10\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n    \n    for data, label in train_loader:\n        data = data.to(device)\n        label = label.to(device)\n        \n        output = model(data)\n        loss = criterion(output, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        acc = ((output.argmax(dim=1) == label).float().mean())\n        epoch_accuracy += acc\/len(train_loader)\n        epoch_loss += loss\/len(train_loader)\n        \n    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n    \n    \n    with torch.no_grad():\n        epoch_val_accuracy=0\n        epoch_val_loss =0\n        for data, label in val_loader:\n            data = data.to(device)\n            label = label.to(device)\n            \n            val_output = model(data)\n            val_loss = criterion(val_output,label)\n            \n            \n            acc = ((val_output.argmax(dim=1) == label).float().mean())\n            epoch_val_accuracy += acc\/ len(val_loader)\n            epoch_val_loss += val_loss\/ len(val_loader)\n            \n        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))","17d57751":"dog_probs = []\nmodel.eval()\nwith torch.no_grad():\n    for data, fileid in test_loader:\n        data = data.to(device)\n        preds = model(data)\n        preds_list = F.softmax(preds, dim=1)[:, 1].tolist()\n        dog_probs += list(zip(list(fileid), preds_list))","271ed783":"dog_probs.sort(key = lambda x : int(x[0]))\ndog_probs","c88c6c04":"idx = list(map(lambda x: x[0],dog_probs))\nprob = list(map(lambda x: x[1],dog_probs))","20387f71":"submission = pd.DataFrame({'id':idx,'label':prob})","ef079a91":"submission","93f32b79":"submission.to_csv('result.csv',index=False)","80c5cc2f":"import random\n\nid_list = []\nclass_ = {0: 'cat', 1: 'dog'}\n\nfig, axes = plt.subplots(2, 5, figsize=(20, 12), facecolor='w')\n\nfor ax in axes.ravel():\n    \n    i = random.choice(submission['id'].values)\n    \n    label = submission.loc[submission['id'] == i, 'label'].values[0]\n    if label > 0.5:\n        label = 1\n    else:\n        label = 0\n        \n    img_path = os.path.join(test_dir, '{}.jpg'.format(i))\n    img = Image.open(img_path)\n    \n    ax.set_title(class_[label])\n    ax.imshow(img)","dc0bb6ae":"### build Model\n- 3 Convolution layer and 2 fully connected layer\n- batchNormalization for limit overfitting","18f2348a":"### set Loss function and optimizer","1d3b5e80":"### 4. Load train,  test data","141a87ca":"This notebook is my first classification work and it could be look coarse but i think it will be helpful to pytorch real starter.","c61f59c6":"### Image Augumentation\n- we have to do this job before making our model. cuz it will prevent overfitting Possibility","2ad320fa":"### there are 8 processes while doing this job.","8c971b62":"#### make a directory for our datasets after unzipping","486906d3":"### Train our Network","81435c1b":"#### use torchvision.datasets","be99f43e":"## Image Classification with Pytorch","bb4f02c3":"1. import Library\n2. hyper parameter setting\n3. set seed and random value \n4. data load\n5. make our model\n6. set our loss function and optimizer\n7. train\n8. check our model performance or using test datasets in trained model","b9d11fd7":"### check our model performance and visualize some data!","43c84343":"- In this Problem, we used softmax except sigmoid. \n- why? isn't it binary classification?\n- before i read overview, i didn't recognize that. read overview about this competition First!!","657273c9":"\n### 1. Import Library","9e6206fa":"#### check our datasets","6aad19d3":"In this competition, we can't use datasets with only pandas\nwe should to unzip datasets. and we must check our working directory before unzipping","eaee3aee":"### 2. Hyper parameters Setting","5680b7af":"### Load datasets\n- this code is for load our image sets. you can find this code easily in pytorch.org , main page","8e0874a0":"check a directory","0e7421fc":"3. Set seed and Random Value"}}