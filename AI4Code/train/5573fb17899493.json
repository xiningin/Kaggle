{"cell_type":{"640db445":"code","3ac48d01":"code","592d11da":"code","54a60462":"code","300398ce":"code","fb9d6a14":"code","4b478bd5":"code","79f8930a":"code","cab99687":"code","d13c63f1":"code","d011857e":"code","47b8c134":"code","55809da8":"markdown","141721da":"markdown","b7bad0ba":"markdown","26cae483":"markdown","05ded99a":"markdown","3e48b8c6":"markdown","8b293de3":"markdown","82f751eb":"markdown","cb20aef4":"markdown","2dab8452":"markdown","0c694816":"markdown","a451f4e0":"markdown","c4628b5e":"markdown","205b90b8":"markdown","5badbbcc":"markdown","d62d5f91":"markdown","d14af89b":"markdown","90073876":"markdown"},"source":{"640db445":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#model building modules\nfrom keras.models import Sequential # initial instance of model\nfrom keras.layers import Dense # layers \nfrom keras.utils import np_utils #OneHotEncoding","3ac48d01":"train = pd.read_csv('..\/input\/mnist-in-csv\/mnist_train.csv') # load train\ntest = pd.read_csv('..\/input\/mnist-in-csv\/mnist_test.csv') # load test","592d11da":"train.head(1) # train head","54a60462":"test.head(1) # test head","300398ce":"print(train.info())\nprint(test.info())","fb9d6a14":"def lab(df):\n    lab_dum = np_utils.to_categorical(df['label']) # convert label to dummy variable\n    return lab_dum","4b478bd5":"y_train = lab(train)\ny_test = lab(test)","79f8930a":"X_train = train.iloc[:,1:] # create X_train\nX_test = test.iloc[:,1:]# create X_test\n\n# normalize X Train and X test as they are between 0 and 255\nX_train \/= 255\nX_test \/= 255","cab99687":"X_train.info()","d13c63f1":"# create a function to instanciate, add layers, compile the model\ndef nnmod():\n\t# instanciate and add layers to model\n\tnnmod = Sequential()\n\tnnmod.add(Dense(784, input_dim=784, activation='relu'))\n\tnnmod.add(Dense(10, activation='softmax'))\n\t# compile model\n\tnnmod.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn nnmod","d011857e":"nnmod = baseline_model() # run our function\n\nnnmod.fit(X_train, y_train, batch_size=200, epochs=10, validation_data=(X_test, y_test)) # fit model","47b8c134":"accuracy = nnmod.evaluate(X_test, y_test)\nprint(\"Accuracy is: \", score[1]*100, \"%\")","55809da8":"We are using accuracy to evaluate how the model is performing. Therefore:","141721da":"## OUTLINE","b7bad0ba":"### Data Preparation","26cae483":"## PRE PROCESSING AND DATA CLEANING","05ded99a":"## MODEL BUILDING","3e48b8c6":"... and load our train and test data.","8b293de3":"As we are dealing with multi-class target, and our target is already numerical, we need to dummify it. The target here is the label (0-9).","82f751eb":"This score is more or less good, but we an improve by adding some other layers.","cb20aef4":"1) Use Keras and develop a model that correctly detects a handwritten digit\n\n2) Evaluate the model properly and interpret its performance","2dab8452":"# DEEP LEARNING","0c694816":"    'Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)'","a451f4e0":"All variables are integer type.","c4628b5e":"    'The MNIST dataset is a very famous dataset used to test and benchmark new deep learning architectures and models. It contains images of handwritten digits (from 0 to 9). It consists of a training and test sets of features and labels.'","205b90b8":"* PRE PROCESSING AND DATA CLEANING\n* MODEL BUILDING\n* MODEL ASSESSMENT","5badbbcc":"## MODEL ASSESSMENT","d62d5f91":"## GOAL","d14af89b":"Lets check the content:","90073876":"We will start by importing all required modules:"}}