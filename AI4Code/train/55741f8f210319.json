{"cell_type":{"22bfc6ee":"code","6930ec94":"code","9dadd094":"code","50d0096c":"code","f39b74d4":"code","a5dcc396":"code","534cdd98":"code","fa2c7458":"code","4b589c4b":"code","033e2f7d":"code","6a4f236e":"code","ed066583":"code","6f313121":"code","786682b5":"code","da03c0bd":"code","82631317":"code","2b91a20d":"code","f7f1d2ef":"code","f8473534":"code","cba1ac1f":"markdown","2f3cde16":"markdown","4458f23a":"markdown","13a8b9c8":"markdown","dd7a0f30":"markdown","a452a076":"markdown","e5450979":"markdown","1e989633":"markdown"},"source":{"22bfc6ee":"import numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Import statements required for Plotly \nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, log_loss, classification_report)\n#from imblearn.over_sampling import SMOTE\nimport xgboost\n\n# Import and suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","6930ec94":"data=pd.read_csv(\"\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndata.head()","9dadd094":"!pip install openpyxl","50d0096c":"data.to_excel('hr.xlsx')","f39b74d4":"df =pd.read_excel(\"hr.xlsx\", sheet_name=0)\ndf = df.drop(['Unnamed: 0'], axis=1)\ndf.head()","a5dcc396":"df.columns","534cdd98":"display(df.isnull().any())","fa2c7458":"target_map = {'Yes':1, 'No':0}\n# Use the pandas apply method to numerically encode our attrition target variable\ndf[\"Attrition_numerical\"] = df[\"Attrition\"].apply(lambda x: target_map[x])","4b589c4b":"# creating a list of only numerical values\nnumerical = [u'Age', u'DailyRate', u'DistanceFromHome', \n             u'Education', u'EmployeeNumber', u'EnvironmentSatisfaction',\n             u'HourlyRate', u'JobInvolvement', u'JobLevel', u'JobSatisfaction',\n             u'MonthlyIncome', u'MonthlyRate', u'NumCompaniesWorked',\n             u'PercentSalaryHike', u'PerformanceRating', u'RelationshipSatisfaction',\n             u'StockOptionLevel', u'TotalWorkingYears',\n             u'TrainingTimesLastYear', u'WorkLifeBalance', u'YearsAtCompany',\n             u'YearsInCurrentRole', u'YearsSinceLastPromotion',u'YearsWithCurrManager']\ndata = [\n    go.Heatmap(\n        z=df[numerical].astype(float).corr().values, # Generating the Pearson correlation\n        x=df[numerical].columns.values,\n        y=df[numerical].columns.values,\n        colorscale='Viridis',\n        reversescale = False,\n#         text = True ,\n        opacity = 1.0\n        \n    )\n]\n\n\nlayout = go.Layout(\n    title='Pearson Correlation of numerical features',\n    xaxis = dict(ticks='', nticks=36),\n    yaxis = dict(ticks='' ),\n    width = 900, height = 700,\n    \n)\n\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='labelled-heatmap')","033e2f7d":"# Refining our list of numerical variables\nnumerical = [u'Age', u'DailyRate',  u'JobSatisfaction',\n       u'MonthlyIncome', u'PerformanceRating',\n        u'WorkLifeBalance', u'YearsAtCompany', u'Attrition_numerical']\n\n#g = sns.pairplot(attrition[numerical], hue='Attrition_numerical', palette='seismic', diag_kind = 'kde',diag_kws=dict(shade=True))\n#g.set(xticklabels=[])","6a4f236e":"# Drop the Attrition_numerical column from attrition dataset first - Don't want to include that\ndf = df.drop(['Attrition_numerical'], axis=1)\n\n# Empty list to store columns with categorical data\ncategorical = []\nfor col, value in df.iteritems():\n    if value.dtype == 'object':\n        categorical.append(col)\n\n# Store the numerical columns in a list numerical\nnumerical = df.columns.difference(categorical)","ed066583":"# Store the categorical data in a dataframe called attrition_cat\ndf_cat = df[categorical]\ndf_cat = df_cat.drop(['Attrition'], axis=1) # Dropping the target column","6f313121":"df_cat = pd.get_dummies(df_cat)\ndf_cat.head(3)","786682b5":"# Store the numerical features to a dataframe attrition_num\ndf_num = df[numerical]","da03c0bd":"# Concat the two dataframes together columnwise\ndf_final = pd.concat([df_num, df_cat], axis=1)","82631317":"# Define a dictionary for the target mapping\ntarget_map = {'Yes':1, 'No':0}\n# Use the pandas apply method to numerically encode our attrition target variable\ntarget = df[\"Attrition\"].apply(lambda x: target_map[x])\ntarget.head(3)","2b91a20d":"data = [go.Bar(\n            x=df[\"Attrition\"].value_counts().index.values,\n            y= df[\"Attrition\"].value_counts().values\n    )]\n\npy.iplot(data, filename='basic-bar')","f7f1d2ef":"# Import the train_test_split method\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# Split data into train and test sets as well as for validation and testing\ntrain, test, target_train, target_val = train_test_split(df_final, \n                                                         target, \n                                                         train_size= 0.80,\n                                                         random_state=0);\n#train, test, target_train, target_val = StratifiedShuffleSplit(attrition_final, target, random_state=0);","f8473534":"from sklearn import tree\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nimport re\n\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 4)\ndecision_tree.fit(train, target_train)\n\n# Predicting results for test dataset\ny_pred = decision_tree.predict(test)\n\n# Export our trained model as a .dot file\nwith open(\"tree1.dot\", 'w') as f:\n     f = tree.export_graphviz(decision_tree,\n                              out_file=f,\n                              max_depth = 4,\n                              impurity = False,\n                              feature_names = df_final.columns.values,\n                              class_names = ['No', 'Yes'],\n                              rounded = True,\n                              filled= True )\n        \n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n\n# Annotating chart with PIL\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\", height=2000, width=1900)","cba1ac1f":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\n\nDefine a dictionary for the target mapping\n<\/h1>\n<\/div>\n\n\n","2f3cde16":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\n\nCorrelation Matrix\n<\/h1>\n<\/div>","4458f23a":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\n\n\nTree Based Approach\n<\/h1>\n<\/div>\n\n","13a8b9c8":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\n\nImplementing Machine Learning Models\n<\/h1>\n<\/div>\n\n","dd7a0f30":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\nData load\n<\/h1>\n<\/div>\n\n\n","a452a076":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\n\nFeature Engineering & Categorical Encoding\n<\/h1>\n<\/div>\n","e5450979":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5499C7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\nLoading Libraries\n<\/h1>\n<\/div>\n\n\n","1e989633":"# Looking for NaN"}}