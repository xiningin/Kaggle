{"cell_type":{"768baf27":"code","66f35d71":"code","6e17dedd":"code","7c80f7dc":"code","25440a64":"code","e8cd79ae":"code","3b33b605":"code","0872f579":"code","e6c12f54":"code","667cfc9f":"code","3499b413":"code","8e8d317a":"code","6061f3fb":"code","3eaf3611":"code","d50be609":"code","ef4f88b1":"code","6c832376":"code","f6390ae4":"code","c57970be":"code","ba3a778c":"code","57f143e3":"code","1e14932a":"code","75690796":"code","a0c25b0e":"code","380db817":"code","f07aab6a":"code","828fb300":"code","09d12623":"code","f6b128c3":"code","e94e50e6":"code","c04d80d3":"code","69d5a8c5":"code","7dca9fea":"code","58d52709":"code","852e48c9":"code","765c7ef0":"code","b191dd69":"code","d107e0e9":"code","1b832ed0":"code","d27a9983":"markdown","a57a9276":"markdown","1c725ffe":"markdown","cd02049d":"markdown","b3edf784":"markdown","4f0234fd":"markdown","d3e7e3d4":"markdown","21c261dd":"markdown","aaa7f669":"markdown","3ba9bac1":"markdown","14258ec3":"markdown","2c7dc95a":"markdown","ceda9457":"markdown","afcf7702":"markdown","5a23826b":"markdown","d1dd814b":"markdown","f1836e76":"markdown"},"source":{"768baf27":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('darkgrid')","66f35d71":"dataset = pd.read_csv('..\/input\/ToyotaCorolla.csv')\ndataset.head()","6e17dedd":"dataset.count()","7c80f7dc":"dataset.describe()","25440a64":"dataset.isnull().sum()","e8cd79ae":"corr = dataset.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(8, 8))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='magma', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","3b33b605":"f, axes = plt.subplots(2, 2, figsize=(12,8))\n\nsns.regplot(x = 'Price', y = 'Age', data = dataset, scatter_kws={'alpha':0.6}, ax = axes[0,0])\naxes[0,0].set_xlabel('Price', fontsize=14)\naxes[0,0].set_ylabel('Age', fontsize=14)\naxes[0,0].yaxis.tick_left()\n\nsns.regplot(x = 'Price', y = 'KM', data = dataset, scatter_kws={'alpha':0.6}, ax = axes[0,1])\naxes[0,1].set_xlabel('Price', fontsize=14)\naxes[0,1].set_ylabel('KM', fontsize=14)\naxes[0,1].yaxis.set_label_position(\"right\")\naxes[0,1].yaxis.tick_right()\n\nsns.regplot(x = 'Price', y = 'Weight', data = dataset, scatter_kws={'alpha':0.6}, ax = axes[1,0])\naxes[1,0].set_xlabel('Price', fontsize=14)\naxes[1,0].set_ylabel('Weight', fontsize=14)\n\nsns.regplot(x = 'Price', y = 'HP', data = dataset, scatter_kws={'alpha':0.6}, ax = axes[1,1])\naxes[1,1].set_xlabel('Price', fontsize=14)\naxes[1,1].set_ylabel('HP', fontsize=14)\naxes[1,1].yaxis.set_label_position(\"right\")\naxes[1,1].yaxis.tick_right()\naxes[1,1].set(ylim=(40,160))\n\nplt.show()","0872f579":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['KM'], ax = axes[0])\naxes[0].set_xlabel('KM', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.scatterplot(x = 'Price', y = 'KM', data = dataset, ax = axes[1])\naxes[1].set_xlabel('Price', fontsize=14)\naxes[1].set_ylabel('KM', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","e6c12f54":"fuel_list= Counter(dataset['FuelType'])\nlabels = fuel_list.keys()\nsizes = fuel_list.values()\n\nf, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.countplot(dataset['FuelType'], ax = axes[0], palette=\"Set1\")\naxes[0].set_xlabel('Fuel Type', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'FuelType', y = 'Price', data = dataset, ax = axes[1])\naxes[1].set_xlabel('Fuel Type', fontsize=14)\naxes[1].set_ylabel('Price', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","667cfc9f":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['HP'], ax = axes[0])\naxes[0].set_xlabel('HP', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.scatterplot(x = 'HP', y = 'Price', data = dataset, ax = axes[1])\naxes[1].set_xlabel('HP', fontsize=14)\naxes[1].set_ylabel('Price', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","3499b413":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['MetColor'], ax = axes[0])\naxes[0].set_xlabel('MetColor', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxplot(x = 'MetColor', y = 'Price', data = dataset, ax = axes[1])\naxes[1].set_xlabel('MetColor', fontsize=14)\naxes[1].set_ylabel('Price', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","8e8d317a":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Automatic'], ax = axes[0])\naxes[0].set_xlabel('Automatic', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxenplot(x = 'Automatic', y = 'Price', data = dataset, ax = axes[1])\naxes[1].set_xlabel('Automatic', fontsize=14)\naxes[1].set_ylabel('Price', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","6061f3fb":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['CC'], ax = axes[0])\naxes[0].set_xlabel('CC', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxplot(x = 'CC', y = 'Price', data = dataset, ax = axes[1])\naxes[1].set_xlabel('CC', fontsize=14)\naxes[1].set_ylabel('Price', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","3eaf3611":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['Doors'], ax = axes[0])\naxes[0].set_xlabel('Doors', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxenplot(x = 'Doors', y = 'Price', data = dataset, ax = axes[1])\naxes[1].set_xlabel('Doors', fontsize=14)\naxes[1].set_ylabel('Price', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","d50be609":"dataset = pd.get_dummies(dataset)","ef4f88b1":"dataset.head()","6c832376":"X = dataset.drop('Price', axis = 1).values\ny = dataset.iloc[:, 0].values.reshape(-1,1)","f6390ae4":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","c57970be":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","ba3a778c":"from sklearn.linear_model import LinearRegression\nregressor_linear = LinearRegression()\nregressor_linear.fit(X_train, y_train)","57f143e3":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score the Test set results\ncv_linear = cross_val_score(estimator = regressor_linear, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_linear_train = regressor_linear.predict(X_train)\nr2_score_linear_train = r2_score(y_train, y_pred_linear_train)\n\n# Predicting R2 Score the Test set results\ny_pred_linear_test = regressor_linear.predict(X_test)\nr2_score_linear_test = r2_score(y_test, y_pred_linear_test)\n\n# Predicting RMSE the Test set results\nrmse_linear = (np.sqrt(mean_squared_error(y_test, y_pred_linear_test)))\nprint(\"CV: \", cv_linear.mean())\nprint('R2_score (train): ', r2_score_linear_train)\nprint('R2_score (test): ', r2_score_linear_test)\nprint(\"RMSE: \", rmse_linear)","1e14932a":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 2)\nX_poly = poly_reg.fit_transform(X_train)\npoly_reg.fit(X_poly, y_train)\nregressor_poly2 = LinearRegression()\nregressor_poly2.fit(X_poly, y_train)","75690796":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score the Test set results\ncv_poly2 = cross_val_score(estimator = regressor_poly2, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_poly2_train = regressor_poly2.predict(poly_reg.fit_transform(X_train))\nr2_score_poly2_train = r2_score(y_train, y_pred_poly2_train)\n\n# Predicting R2 Score the Test set results\ny_pred_poly2_test = regressor_poly2.predict(poly_reg.fit_transform(X_test))\nr2_score_poly2_test = r2_score(y_test, y_pred_poly2_test)\n\n# Predicting RMSE the Test set results\nrmse_poly2 = (np.sqrt(mean_squared_error(y_test, y_pred_poly2_test)))\nprint('CV: ', cv_poly2.mean())\nprint('R2_score (train): ', r2_score_poly2_train)\nprint('R2_score (test): ', r2_score_poly2_test)\nprint(\"RMSE: \", rmse_poly2)","a0c25b0e":"from sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(degree=3)),\n    ('model', Ridge(alpha=1777, fit_intercept=True))\n]\n\nridge_pipe = Pipeline(steps)\nridge_pipe.fit(X_train, y_train)","380db817":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score the Test set results\ncv_ridge = cross_val_score(estimator = ridge_pipe, X = X_train, y = y_train.ravel(), cv = 10)\n\n# Predicting R2 Score the Test set results\ny_pred_ridge_train = ridge_pipe.predict(X_train)\nr2_score_ridge_train = r2_score(y_train, y_pred_ridge_train)\n\n# Predicting R2 Score the Test set results\ny_pred_ridge_test = ridge_pipe.predict(X_test)\nr2_score_ridge_test = r2_score(y_test, y_pred_ridge_test)\n\n# Predicting RMSE the Test set results\nrmse_ridge = (np.sqrt(mean_squared_error(y_test, y_pred_ridge_test)))\nprint('CV: ', cv_ridge.mean())\nprint('R2_score (train): ', r2_score_ridge_train)\nprint('R2_score (test): ', r2_score_ridge_test)\nprint(\"RMSE: \", rmse_ridge)","f07aab6a":"from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(degree=3)),\n    ('model', Lasso(alpha=2.36, fit_intercept=True, tol = 0.0199, max_iter=2000))\n]\n\nlasso_pipe = Pipeline(steps)\nlasso_pipe.fit(X_train, y_train)","828fb300":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_lasso = cross_val_score(estimator = lasso_pipe, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Test set results\ny_pred_lasso_train = lasso_pipe.predict(X_train)\nr2_score_lasso_train = r2_score(y_train, y_pred_lasso_train)\n\n# Predicting R2 Score the Test set results\ny_pred_lasso_test = lasso_pipe.predict(X_test)\nr2_score_lasso_test = r2_score(y_test, y_pred_lasso_test)\n\n# Predicting RMSE the Test set results\nrmse_lasso = (np.sqrt(mean_squared_error(y_test, y_pred_lasso_test)))\nprint('CV: ', cv_lasso.mean())\nprint('R2_score (train): ', r2_score_lasso_train)\nprint('R2_score (test): ', r2_score_lasso_test)\nprint(\"RMSE: \", rmse_lasso)","09d12623":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_y = StandardScaler()\nX_scaled = sc_X.fit_transform(X_train)\ny_scaled = sc_y.fit_transform(y_train.reshape(-1,1))","f6b128c3":"# Fitting the SVR Model to the dataset\nfrom sklearn.svm import SVR\nregressor_svr = SVR(kernel = 'rbf', gamma = 'scale')\nregressor_svr.fit(X_scaled, y_scaled.ravel())","e94e50e6":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_svr = cross_val_score(estimator = regressor_svr, X = X_scaled, y = y_scaled.ravel(), cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_svr_train = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_train)))\nr2_score_svr_train = r2_score(y_train, y_pred_svr_train)\n\n# Predicting R2 Score the Test set results\ny_pred_svr_test = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_test)))\nr2_score_svr_test = r2_score(y_test, y_pred_svr_test)\n\n# Predicting RMSE the Test set results\nrmse_svr = (np.sqrt(mean_squared_error(y_test, y_pred_svr_test)))\nprint('CV: ', cv_svr.mean())\nprint('R2_score (train): ', r2_score_svr_train)\nprint('R2_score (test): ', r2_score_svr_test)\nprint(\"RMSE: \", rmse_svr)","c04d80d3":"# Fitting the Decision Tree Regression Model to the dataset\nfrom sklearn.tree import DecisionTreeRegressor\nregressor_dt = DecisionTreeRegressor(random_state = 0)\nregressor_dt.fit(X_train, y_train)","69d5a8c5":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_dt = cross_val_score(estimator = regressor_dt, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_dt_train = regressor_dt.predict(X_train)\nr2_score_dt_train = r2_score(y_train, y_pred_dt_train)\n\n# Predicting R2 Score the Test set results\ny_pred_dt_test = regressor_dt.predict(X_test)\nr2_score_dt_test = r2_score(y_test, y_pred_dt_test)\n\n# Predicting RMSE the Test set results\nrmse_dt = (np.sqrt(mean_squared_error(y_test, y_pred_dt_test)))\nprint('CV: ', cv_dt.mean())\nprint('R2_score (train): ', r2_score_dt_train)\nprint('R2_score (test): ', r2_score_dt_test)\nprint(\"RMSE: \", rmse_dt)","7dca9fea":"# Fitting the Random Forest Regression to the dataset\nfrom sklearn.ensemble import RandomForestRegressor\nregressor_rf = RandomForestRegressor(n_estimators = 1200, random_state = 0)\nregressor_rf.fit(X_train, y_train.ravel())","58d52709":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_rf = cross_val_score(estimator = regressor_rf, X = X_scaled, y = y_train.ravel(), cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_rf_train = regressor_rf.predict(X_train)\nr2_score_rf_train = r2_score(y_train, y_pred_rf_train)\n\n# Predicting R2 Score the Test set results\ny_pred_rf_test = regressor_rf.predict(X_test)\nr2_score_rf_test = r2_score(y_test, y_pred_rf_test)\n\n# Predicting RMSE the Test set results\nrmse_rf = (np.sqrt(mean_squared_error(y_test, y_pred_rf_test)))\nprint('CV: ', cv_rf.mean())\nprint('R2_score (train): ', r2_score_rf_train)\nprint('R2_score (test): ', r2_score_rf_test)\nprint(\"RMSE: \", rmse_rf)","852e48c9":"models = [('Linear Regression', rmse_linear, r2_score_linear_train, r2_score_linear_test, cv_linear.mean()),\n          ('Polynomial Regression (2nd)', rmse_poly2, r2_score_poly2_train, r2_score_poly2_test, cv_poly2.mean()),\n          ('Ridge Regression', rmse_ridge, r2_score_ridge_train, r2_score_ridge_test, cv_ridge.mean()),\n          ('Lasso Regression', rmse_lasso, r2_score_lasso_train, r2_score_lasso_test, cv_lasso.mean()),\n          ('Support Vector Regression', rmse_svr, r2_score_svr_train, r2_score_svr_test, cv_svr.mean()),\n          ('Decision Tree Regression', rmse_dt, r2_score_dt_train, r2_score_dt_test, cv_dt.mean()),\n          ('Random Forest Regression', rmse_rf, r2_score_rf_train, r2_score_rf_test, cv_rf.mean())   \n         ]","765c7ef0":"predict = pd.DataFrame(data = models, columns=['Model', 'RMSE', 'R2_Score(training)', 'R2_Score(test)', 'Cross-Validation'])\npredict","b191dd69":"f, axe = plt.subplots(1,1, figsize=(18,6))\n\npredict.sort_values(by=['Cross-Validation'], ascending=False, inplace=True)\n\nsns.barplot(x='Cross-Validation', y='Model', data = predict, ax = axe)\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxe.set_xlabel('Cross-Validaton Score', size=16)\naxe.set_ylabel('Model')\naxe.set_xlim(0,1.0)\naxe.set_xticks(np.arange(0, 1.1, 0.1))\nplt.show()","d107e0e9":"f, axes = plt.subplots(2,1, figsize=(14,10))\n\npredict.sort_values(by=['R2_Score(training)'], ascending=False, inplace=True)\n\nsns.barplot(x='R2_Score(training)', y='Model', data = predict, palette='Blues_d', ax = axes[0])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[0].set_xlabel('R2 Score (Training)', size=16)\naxes[0].set_ylabel('Model')\naxes[0].set_xlim(0,1.0)\naxes[0].set_xticks(np.arange(0, 1.1, 0.1))\n\npredict.sort_values(by=['R2_Score(test)'], ascending=False, inplace=True)\n\nsns.barplot(x='R2_Score(test)', y='Model', data = predict, palette='Reds_d', ax = axes[1])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[1].set_xlabel('R2 Score (Test)', size=16)\naxes[1].set_ylabel('Model')\naxes[1].set_xlim(0,1.0)\naxes[1].set_xticks(np.arange(0, 1.1, 0.1))\n\nplt.show()","1b832ed0":"predict.sort_values(by=['RMSE'], ascending=False, inplace=True)\n\nf, axe = plt.subplots(1,1, figsize=(18,6))\nsns.barplot(x='Model', y='RMSE', data=predict, ax = axe)\naxe.set_xlabel('Model', size=16)\naxe.set_ylabel('RMSE', size=16)\n\nplt.show()","d27a9983":"Columns:\n- <b> Age: <\/b> Age in years\n- <b> KM: <\/b> Accumulated Kilometers on odometer\n- <b> FuelType: <\/b> Fuel Type (Petrol, Diesel, CNG)\n- <b> HP: <\/b> Horse Power\n- <b> MetColor: <\/b> Metallic Color? (Yes=1, No=0)\n- <b> Automatic: <\/b> Automatic ( (Yes=1, No=0)\n- <b> CC: <\/b> Cylinder Volume in cubic centimeters\n- <b> Doors: <\/b> Number of doors\n- <b> Weight: <\/b> Weight in Kilograms\n- <b> Price: <\/b> Offer Price in EUROs","a57a9276":"### <span id=\"7\"><\/span> ** Ridge Regression **","1c725ffe":"### <span id=\"11\"><\/span> ** Random Forest Regression **","cd02049d":"### <span id=\"5\"><\/span> ** Linear Regression **","b3edf784":"## <span id=\"4\"><\/span> ** 4. Regression Models **","4f0234fd":"<hr\/>\n[**Tolgahan Cepel**](https:\/\/www.kaggle.com\/tolgahancepel)\n<hr\/>\n<font color=green>\n1. [Overview](#1)\n1. [Importing Libraries and Reading the Dataset](#2)\n1. [Data Preprocessing and Visualization](#3) \n1. [Regression Models](#4) \n    * [Linear Regression](#5) \n    * [Polynomial Regression - 2nd degree](#6)\n    * [Ridge Regression](#7)\n    * [Lasso Regression](#8)\n    * [Support Vector Regression](#9)\n    * [Decision Tree Regression](#10) \n    * [Random Forest Regression](#11)\n1. [Measuring the Error](#12)\n    * [Visualizing Models Performance](#13)\n1. [Conclusion](#14)\n<hr\/>","d3e7e3d4":"## <span id=\"2\"><\/span> ** 2. Importing Libraries and Reading the Dataset **","21c261dd":"### <span id=\"10\"><\/span> ** Decision Tree Regression **","aaa7f669":"In this kernel, I have built 7 regression models using Toyota Corolla Dataset. These are linear, polynomial, ridge, lasso,  svr, decision tree and random forest regression. Then measured and visualized the performance of the models. Please make a comment and let me know how to improve model performance, visualization or something in this kernel. This will also help me on my future analysis.\n\n<b><font color=\"red\">Don't forget to <\/font><\/b> <b><font color=\"green\">UPVOTE <\/font><\/b> if you liked this kernel, thank you. \ud83d\ude42\ud83d\udc4d","3ba9bac1":"### <span id=\"9\"><\/span> ** Support Vector Regression **","14258ec3":"## <span id=\"12\"><\/span> ** 5. Measuring the Error **","2c7dc95a":"## <span id=\"3\"><\/span> ** 3. Data Preprocessing and Visualization **","ceda9457":"## <span id=\"14\"><\/span> ** 6. Conclusion **","afcf7702":"### <span id=\"8\"><\/span> ** Lasso Regression **","5a23826b":"### <span id=\"13\"><\/span> ** Visualizing Models Performance **","d1dd814b":"## <span id=\"1\"><\/span> ** 1. Overview **","f1836e76":"### <span id=\"6\"><\/span> ** Polynomial Regression - 2nd degree **"}}