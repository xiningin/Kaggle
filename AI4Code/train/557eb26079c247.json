{"cell_type":{"f97dab21":"code","b7f75dbc":"code","58faa6b8":"code","29e15688":"code","2ca3a9f0":"code","67f373c7":"code","b9876252":"code","fbd8a3de":"code","52cded3a":"code","2fa45b04":"code","1cf385d0":"code","bea2d889":"code","314373f9":"code","cf837c1f":"code","c83851f5":"code","12fc7f8d":"code","9f39fd4d":"code","dfa14d84":"code","fc996ee9":"code","d236f7f4":"code","b79226bc":"code","312d0222":"code","5bea55ee":"code","5546dc89":"code","f9e9cf67":"code","c99a4485":"code","9eca81c8":"code","527ff025":"code","f8b91769":"code","7f246180":"code","6cfffec9":"code","000d938b":"code","f7848eca":"code","27a84046":"code","2e0b2463":"code","5168d963":"code","23eeb172":"code","3804410e":"markdown","4475f64c":"markdown","fec6bdcc":"markdown","73092a8a":"markdown","25b2f91d":"markdown","d4944a08":"markdown","cfe1e1b4":"markdown","149a2516":"markdown","0790e617":"markdown","50ae5586":"markdown","cc5a2f20":"markdown","fb96d56c":"markdown","0643da22":"markdown","d186b49e":"markdown","7749a0d4":"markdown","04841fc3":"markdown","66e1c146":"markdown","da73c2a0":"markdown","da49ff5d":"markdown"},"source":{"f97dab21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b7f75dbc":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv('..\/input\/test.csv')","58faa6b8":"train.info()","29e15688":"missing_1=train.isnull().sum(axis=0)\nmissing_2=test.isnull().sum(axis=0)\nprint('missing data in trainning data')\nprint(missing_1[missing_1>0])\nprint('\\n missing data in testing data')\nprint(missing_2[missing_2>0])","2ca3a9f0":"train.columns.values\ntrain_val=train.drop('SalePrice',axis=1)\ntest_val=test\nval_total=pd.concat([train_val,test_val])","67f373c7":"miss=val_total.isnull().sum(axis=0).sort_values(ascending=False)\nmiss=miss[miss>0]\nmiss","b9876252":"#for catergorical variables, we replece missing data with None\nMiss_cat=['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n          'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', \n          'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType', 'MSSubClass']\nfor col in Miss_cat:\n    val_total[col].fillna('None',inplace=True)\n# for numerical variables, we replace missing value with 0\nMiss_num=['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', \n          'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea'] \nfor col in Miss_num:\n    val_total[col].fillna(0, inplace=True)","fbd8a3de":"miss=val_total.isnull().sum(axis=0).sort_values(ascending=False)\nmiss=miss[miss>0]\nmiss","52cded3a":"rest_val=['MSZoning','Functional','Utilities','Exterior1st', 'SaleType','Electrical', 'Exterior2nd','KitchenQual']\nfor col in rest_val:\n    val_total[col].fillna(val_total[col].mode()[0],inplace=True)","2fa45b04":"miss=val_total.isnull().sum(axis=0).sort_values(ascending=False)\nmiss=miss[miss>0]\nmiss","1cf385d0":"val_total['LotFrontage']=val_total.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","bea2d889":"for col in ['MSSubClass', 'YearBuilt', 'YearRemodAdd']:\n    val_total[col]=val_total[col].astype(str)","314373f9":"new_train_data=pd.concat([val_total[:len(train)],train['SalePrice']],axis=1)","cf837c1f":"Cat=[]\nNum=[]\nfor col in new_train_data.columns:\n    if new_train_data.dtypes[col]=='object':\n        Cat.append(col)\n    else:\n        Num.append(col)","c83851f5":"Num.remove('Id')\nNum.remove('SalePrice')","12fc7f8d":"##Check correlation between Num variables and SalePrice\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nNum_data=pd.concat([new_train_data[Num],new_train_data['SalePrice']],axis=1)\nplt.figure(figsize=(20,10))\nsns.heatmap(Num_data.corr())\n","9f39fd4d":"##show the relation between SalesPrice and Each numerical Variables:\ni=0\nsns.set_style('whitegrid')\nplt.figure()\nfig,ax=plt.subplots(6,6,figsize=(20,20))\nfor feature in Num:\n    i+=1\n    plt.subplot(6,6,i)\n    sns.scatterplot(new_train_data['SalePrice'],new_train_data[feature])\n    plt.xlabel('SalePrice')\n    plt.ylabel(feature)\nplt.tight_layout()\nplt.show()","dfa14d84":"##show relation between Sales price and catergorical variables\ni=0\nsns.set_style('whitegrid')\nplt.figure()\nfig,ax=plt.subplots(8,6,figsize=(20,40))\nfor feature in Cat:\n    i+=1\n    plt.subplot(8,6,i)\n    sns.boxplot(new_train_data[feature],new_train_data['SalePrice'])\n    plt.ylabel('SalePrice')\n    plt.xlabel(feature)\nplt.tight_layout()\nplt.show()","fc996ee9":"i=0\nsns.set_style('whitegrid')\nplt.figure()\nfig,ax=plt.subplots(6,6,figsize=(20,20))\nfor feature in Num:\n    i+=1\n    plt.subplot(6,6,i)\n    sns.distplot(val_total[feature],kde=False)\n    plt.xlabel(feature)\nplt.tight_layout()\nplt.show()","d236f7f4":"#check skewness of variables\nfrom scipy.stats import skew\nskewness = val_total[Num].apply(lambda x: skew(x)).sort_values(ascending=False)\nskewness=pd.DataFrame({'skewness':skewness})\n","b79226bc":"from scipy.special import boxcox1p\nskew_var=skewness[abs(skewness['skewness'])>0.75].index\nfor var in skew_var:\n    val_total[var]=boxcox1p(val_total[var], 0.15)\n","312d0222":"i=0\nsns.set_style('whitegrid')\nplt.figure()\nfig,ax=plt.subplots(6,6,figsize=(20,20))\nfor feature in Num:\n    i+=1\n    plt.subplot(6,6,i)\n    sns.distplot(val_total[feature],kde=False)\n    plt.xlabel(feature)\nplt.tight_layout()\nplt.show()","5bea55ee":"from sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nmin_max_scaler=preprocessing.MinMaxScaler()\nmin_max_val=min_max_scaler.fit_transform(val_total[Num])","5546dc89":"min_max_val.shape","f9e9cf67":"dummy_cat = pd.get_dummies(val_total[Cat])\n##convert dummy_cat to numpy array\ndummy_cat=np.array(dummy_cat)","c99a4485":"dummy_cat.shape","9eca81c8":"total_feature=np.concatenate([min_max_val,dummy_cat],axis=1)","527ff025":"train_feature=total_feature[: len(train),:]\ntest_feature=total_feature[len(train):,:]","f8b91769":"Y=train['SalePrice']","7f246180":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(train_feature,Y,test_size=0.2)","6cfffec9":"##XGBOOST \nfrom xgboost.sklearn import XGBRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nrandom_grid={'learning_rate':[0.001,0.01],\n            'max_depth':[10,30],\n            'n_estimators':[200,300],\n            'subsample':[0.5,0.7]\n}\nxgb = XGBRegressor(objective='reg:linear')\ngrid_search=GridSearchCV(estimator=xgb,param_grid = random_grid,cv = 3, n_jobs = -1, verbose = 2,scoring='neg_mean_squared_error')\n                         ","000d938b":"grid_search.fit(X_train,Y_train)\nprint(\"\\nGrid Search Best parameters set :\")\nprint(grid_search.best_params_)","f7848eca":"predict=grid_search.predict(X_test)\nmse = np.mean((Y_test - predict)**2)\nprint('MSE:', mse)","27a84046":"sns.scatterplot(Y_test,predict)\nplt.xlabel('True Price')\nplt.ylabel('Predicted Price')\nplt.show()","2e0b2463":"Test_predict=grid_search.predict(test_feature)","5168d963":"prediction = pd.DataFrame(Test_predict, columns=['SalePrice'])\nresult = pd.concat([ test['Id'], prediction], axis=1)","23eeb172":"result.to_csv('.\/submission.csv', index=False)","3804410e":"Use MSE (mean square error) to Evaluation the model\n","4475f64c":"check the null value train and test data","fec6bdcc":"First convert MSSubClass, YearBuilt, YearRemodAdd to catergorical values","73092a8a":"Deal with numerical features:\n1. check normality (histgram, skewness)\n","25b2f91d":"seperate train and test","d4944a08":"Scale numerical variables into range of 0 and 1","cfe1e1b4":"Check the information of variables, especailly numeric values and catergorical values; ","149a2516":"Set 0.75 as cut-off and we will use boxcox to transform variables which has abs(skew) >0.75 into normal distribution.","0790e617":"Some columns has large numbers of missing value, let's take a close look to these variables\nFor PoolQC variable, missing data(NA) means 'no pool'. \nSimilar situation happend in categorical variables: MiscFeature, Alley, Fence, FireplaceQu, GarageType,\nGarageFinish, GarageQual, GarageCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, MasVnrType, MSSubClass;\nand numerical variables: GarageYrBlt, GarageArea, GarageCars, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, MasVnrArea\n","50ae5586":"Now we have finished dealing with all the missing data. ","cc5a2f20":"Deal with Categorical variables\nuse get_dummies function to vectorize the variables","fb96d56c":"For the rest variables with missing values, we replace missing values with the most common values","0643da22":"For the LotFrontage,which is Linear feet of street connected to property, We assme individual neighborhood type has similar LotFrontage.Therefore, we replace missing value in LotFrontage with median of that of neighborhood","d186b49e":"well, training data ans testing data has different columns containing missing value. So combine variables in training data ans testing data for EDA and feature engineering ","7749a0d4":"Seperate categorical and numerical data","04841fc3":"Let's build some models","66e1c146":"Check missing data again","da73c2a0":"Let's check histogram again!","da49ff5d":"combine min_max_val and dummy_cat as our features"}}