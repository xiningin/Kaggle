{"cell_type":{"f7d6fb52":"code","afe40c98":"markdown"},"source":{"f7d6fb52":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom random import choices\n\n\nSEED = 1111\n\nnp.random.seed(SEED)\n\ntrain = pd.read_csv('..\/input\/jane-street-market-prediction\/train.csv')\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]\n\ntrain.fillna(train.mean(),inplace=True)\n\ntrain['action'] = ((train['resp'].values) > 0).astype(int)\n\n\nfeatures = [c for c in train.columns if \"feature\" in c]\n\nf_mean = np.mean(train[features[1:]].values,axis=0)\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\n#y_train = (train.loc[:, 'action'])\n\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n\n# fit\ndef create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    # Keras\u30c6\u30f3\u30bd\u30eb\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\n    # shape\u306e\u30bf\u30d7\u30eb\uff08\u6574\u6570\uff09\u3067\uff0c\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u542b\u307f\u307e\u305b\u3093\n    # \u671f\u5f85\u3055\u308c\u308b\u5165\u529b\u304cnum_columns\u6b21\u5143\u30d9\u30af\u30c8\u30eb\u306e\u30d0\u30c3\u30c1\u3067\u3042\u308b\u3053\u3068\u3092\u793a\u3057\u307e\u3059\uff0e\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        # \u901a\u5e38\u306e\u5168\u7d50\u5408\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30ec\u30a4\u30e4\u30fc\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        # ReLU\u95a2\u6570\u306e\u5f8c\u7d99\u3000x=0\u3067\u3082\u9023\u7d9a\u306aC\u221e\u7d1a\u306e\u6d3b\u6027\u5316\u95a2\u6570\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n    \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n        # 2\u3064\u306e\u78ba\u7387\u5206\u5e03\u306e\u9593\u306b\u5b9a\u7fa9\u3055\u308c\u308b\u975e\u985e\u4f3c\u6027\u306e\u6e2c\u5ea6\u3068\u3057\u3066\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u3092\u640d\u5931\u95a2\u6570\u3068\u3059\u308b\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model\n\nepochs = 200\nbatch_size = 4096\nhidden_units = [160, 160, 160]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\ntf.keras.backend.clear_session()\ntf.random.set_seed(SEED)\nclf = create_mlp(\n    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\n\nclf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n\n# save model\nclf.save(f'model.h5')\n\n# inference\nth = 0.502\nmodels = [clf]\nf = np.median\nimport janestreet\nenv = janestreet.make_env()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n        pred = f(pred)\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","afe40c98":"\u6b21\u306e\u7d20\u6674\u3089\u3057\u3044\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306b\u57fa\u3065\u3044\u3066\u3044\u307e\u3059:\n\n[OWN Jane Street with Keras NN](https:\/\/www.kaggle.com\/tarlannazarov\/own-jane-street-with-keras-nn)\n\n\u5909\u66f4\u70b9\u306f\u6b21\u306e\u3068\u304a\u308a\u3067\u3059\u3002th-> 0.50\n- \u30e2\u30c7\u30eb\u5168\u4f53\u306e\u4fdd\u5b58\u3092\u6709\u52b9\u306b\u3057\u307e\u3059\uff08\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u306a\u3069\u3001\u5f8c\u3067\u4f7f\u7528\u3059\u308b\u305f\u3081\uff09\n- RectifiedAdam Optimizer\uff08\u5b66\u7fd2\u7387\u306e\u9078\u629e\u306b\u5bfe\u3057\u3066\u5805\u7262\u3067\u3042\u308b\u3053\u3068\u304c\u77e5\u3089\u308c\u3066\u3044\u307e\u3059\uff09\n- \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba 2^x \u500d\uff08tf\u3092\u4f7f\u7528\u3057\u305f\u3088\u308a\u826f\u3044\u30ab\u30b9\u30bf\u30e0\uff09\n- th -> 0.50 \uff08\u3082\u3046\u5c11\u3057\u4fdd\u5b88\u7684\u306a\u884c\u52d5\uff09\n\n\u3053\u308c\u3089\u306e\u5c0f\u3055\u306a\u5909\u66f4\u304c\u3069\u306e\u3088\u3046\u306b\u7570\u306a\u308b\u30b9\u30b3\u30a2\u306b\u3064\u306a\u304c\u308b\u304b\u306b\u9a5a\u304f\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002 \u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306f\u3001\u7279\u306bPublic \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304c\u904e\u53bb\u306b\u95a2\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u306e\u306b\u5bfe\u3057\u3001Private \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304c\u5c06\u6765\u306b\u95a2\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u3067\u306f\u3001\u9ad8\u3044Public LB\u30b9\u30b3\u30a2\u3092\u53d6\u5f97\u3059\u308b\u305f\u3081\u306e\u3082\u306e\u3067\u3059\u3002\u3053\u308c\u306f**\u826f\u597d\u306a Private \u30b9\u30b3\u30a2\u3092\u4fdd\u8a3c\u3059\u308b\u3082\u306e\u3067\u306f\u3042\u308a\u307e\u305b\u3093**\u3002\n\n\u904e\u53bb\u306e\u5c65\u6b74\u30c7\u30fc\u30bf\u306b\u904e\u5270\u9069\u5408\u3059\u308b\u3053\u3068\u3092\u6050\u308c\u3066\u3001\u79c1\u306f\u500b\u4eba\u7684\u306b\u3053\u306e\u30e2\u30c7\u30eb\u3092\u6700\u7d42\u7684\u306a\u63d0\u51fa\u306b\u4f7f\u7528\u3057\u307e\u305b\u3093\u304c\u3001\u305d\u308c\u306f\u3042\u306a\u305f\u6b21\u7b2c\u3067\u3059\u3002"}}