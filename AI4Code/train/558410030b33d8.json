{"cell_type":{"b058d814":"code","d3aa8111":"code","d174e5f8":"code","e2caaa91":"code","90021b37":"code","5251b215":"code","14e38665":"code","8eedb370":"code","7d930cf3":"code","5e285345":"code","7948db8c":"code","9545deba":"code","a583b62a":"code","331510fb":"code","033141e1":"code","e1395e5f":"code","24486820":"code","17f815e0":"code","73a28f9e":"markdown","0e093585":"markdown","7580ec45":"markdown","8faf6d76":"markdown","8c2432b9":"markdown","eb143f22":"markdown","8ada1ffc":"markdown","65b68006":"markdown","432509d4":"markdown","8d7dc9ee":"markdown","6e99716d":"markdown","360f9be0":"markdown","0fc73827":"markdown","33259640":"markdown","c4d9f5b6":"markdown","ff6a9493":"markdown","2970b04c":"markdown","da0f4d95":"markdown","32886a56":"markdown","abbadb32":"markdown"},"source":{"b058d814":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","d3aa8111":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")","d174e5f8":"#Storing labels into y_train\ny_train = train['label']\n#Drop labels column\nx_train = train.drop(labels = [\"label\"],axis=1)","e2caaa91":"#View labels count\ny_train.value_counts()","90021b37":"# Check Null values\nprint(\"\\nTrain\\n\",x_train.isnull().any().describe())\nprint(\"\\nTest\\n\",test.isnull().any().describe())","5251b215":"#Normalization\nx_train = x_train\/ 255.0\ntest = test \/ 255.0","14e38665":"#Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nx_train =x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","8eedb370":"#label encoding\ny_train = to_categorical(y_train, 10)","7d930cf3":"#Split train and test\nrandom_seed =1\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)","5e285345":"#CNN\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n                  activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n# model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu'))\n# model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n#                   activation ='relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n# model.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","7948db8c":"model.summary()","9545deba":"op = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\nmodel.compile(optimizer = op , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","a583b62a":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nepochs = 50\nbatch_size = 86","331510fb":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","033141e1":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","e1395e5f":"plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Val Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","24486820":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","17f815e0":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnnmnist5.csv\",index=False)","73a28f9e":"1. **Import and Read**\n2. **Data Preparation**\n    * **Check for null and missing values**\n    * **Normalization**\n    * **Reshape**\n    * **Label encoding**\n    * **Split training and Validation Set**\n3. **CNN**\n    * **Model**\n    * **Optimizer**\n    * **Data Augmentation**\n4. **Evaluate the model**\n    * **Training and validation curves**\n    * **Confusion matrix**\n5. **Prediction**","0e093585":"# Read the files","7580ec45":"# 2. Data Preparation","8faf6d76":"### Adam Optimizer:\nIt is an optimizer with parameter-specific learning rates, which are adapted relative to how frequently a parameter gets updated during training","8c2432b9":"## Fit the model","eb143f22":"## Optimizer","8ada1ffc":"# Evaluate the model","65b68006":"## Split Training and Validation set\n* Training set - 90%\n* Test set - 10%","432509d4":"## Training and Validation curves","8d7dc9ee":"## Check for Null and Missing Values","6e99716d":"###  Conv => Conv => Maxpool = > Dropout => Conv => Maxpool = > Dropout => Flatten => Dense => Dropout => Output","360f9be0":"## Reshape\n * \tTest and train images are in panda\u2019s data frame and we need to convert them into matrix of shape 28x28x1\n *  Generally, if it RGB image we need to have 3 channels but as our data is MNIST which is a greyscale 1 channel is enough.","0fc73827":"## 3.1 Define Model","33259640":"# CNN","c4d9f5b6":"# 1. **Import all the packages**","ff6a9493":"### Data Augmentation\n* To avoid overfitting problem, we need to expand artificially our handwritten digit dataset.\n* Alter the training data with small transformations to reproduce the variations of digit.\n* For example, the number is not centered The scale is not the same (some who write with big\/small numbers) The image is rotated.\n* Randomly rotate some training images by 10 degrees.\n* Randomly Zoom by 10% some training images\n* Randomly shift images horizontally by 10% of the width\n* Randomly shift images vertically by 10% of the height","2970b04c":"# Prediction","da0f4d95":"## Label Encoding\n* Encoding should be applied for output variable","32886a56":"## Normalization\n  *     We perform grayscale normalization to reduce the illumination\u2019s differences.\n  *   CNN Works Faster","abbadb32":"## Confusion Matrix"}}