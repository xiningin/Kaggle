{"cell_type":{"cd10c9eb":"code","aa487520":"code","a2a33532":"code","c6312766":"code","67adac74":"code","0637a00e":"code","dd05efc9":"code","101c8c39":"code","5034bd4a":"code","3e650324":"code","0ccaadad":"code","7e080e1a":"code","6663cc89":"code","0d87830d":"code","94a19a7a":"code","e00d554d":"code","6a614b4d":"code","93a4abc5":"code","aa5f7cc3":"code","66a36499":"code","aa6646af":"code","0f48936b":"code","671bbe16":"code","f6f28435":"code","d5abcac7":"code","3e8775b6":"code","9185144f":"code","ee4ff690":"code","1740b34c":"markdown","195b9ebb":"markdown","14ec97ad":"markdown","57576555":"markdown","38e41c96":"markdown","78605725":"markdown","b5d9d65a":"markdown","1874cb77":"markdown","725e08c8":"markdown","81df01c4":"markdown","8902c5ba":"markdown","6adc434d":"markdown","ba96b171":"markdown","47d37f6a":"markdown","3819e193":"markdown","3094ce43":"markdown","5e1a9112":"markdown","5a1a2ce6":"markdown","1288266e":"markdown","39d4fbcf":"markdown","117889e7":"markdown","0ddedd8f":"markdown","5cda204c":"markdown","03f380f5":"markdown","614ed30d":"markdown","a525f4e2":"markdown","76f48f05":"markdown","90248095":"markdown","2208fa96":"markdown","e67156cd":"markdown","1fe228e3":"markdown","a36aa4e1":"markdown","641d92af":"markdown"},"source":{"cd10c9eb":"import numpy as np \nimport pandas as pd \nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom scipy import sparse\nimport random\nimport lightfm \nfrom lightfm import LightFM, cross_validation\nfrom lightfm.evaluation import precision_at_k, auc_score\nfrom sklearn.metrics.pairwise import cosine_similarity","aa487520":"p = 0.50  # to randomly select 50% of the rows","a2a33532":"df_playlist = pd.read_csv('\/kaggle\/input\/spotify-playlists\/spotify_dataset.csv', error_bad_lines=False, warn_bad_lines=False, skiprows=lambda i: i>0 and random.random() > p)\ndf_playlist.head()","c6312766":"df_playlist.shape","67adac74":"df_playlist.columns = df_playlist.columns.str.replace('\"', '')\ndf_playlist.columns = df_playlist.columns.str.replace('name', '')\ndf_playlist.columns = df_playlist.columns.str.replace(' ', '')\ndf_playlist.columns","0637a00e":"df_playlist = df_playlist.groupby('artist').filter(lambda x : len(x)>=50)","dd05efc9":"df_playlist = df_playlist[df_playlist.groupby('user_id').artist.transform('nunique') >= 10]","101c8c39":"size = lambda x: len(x)\ndf_freq = df_playlist.groupby(['user_id', 'artist']).agg('size').reset_index().rename(columns={0:'freq'})[['user_id', 'artist', 'freq']].sort_values(['freq'], ascending=False)\ndf_freq.head()","5034bd4a":"df_artist = pd.DataFrame(df_freq[\"artist\"].unique())\ndf_artist = df_artist.reset_index()\ndf_artist = df_artist.rename(columns={'index':'artist_id', 0:'artist'})\ndf_artist.head()","3e650324":"df_artist.shape","0ccaadad":"df_freq  = pd.merge(df_freq , df_artist, how='inner', on='artist')","7e080e1a":"def create_interaction_matrix(df,user_col, item_col, rating_col, norm= False, threshold = None):\n    '''\n    Function to create an interaction matrix dataframe from transactional type interactions\n    Required Input -\n        - df = Pandas DataFrame containing user-item interactions\n        - user_col = column name containing user's identifier\n        - item_col = column name containing item's identifier\n        - rating col = column name containing user feedback on interaction with a given item\n        - norm (optional) = True if a normalization of ratings is needed\n        - threshold (required if norm = True) = value above which the rating is favorable\n    Expected output - \n        - Pandas dataframe with user-item interactions ready to be fed in a recommendation algorithm\n    '''\n    interactions = df.groupby([user_col, item_col])[rating_col] \\\n            .sum().unstack().reset_index(). \\\n            fillna(0).set_index(user_col)\n    if norm:\n        interactions = interactions.applymap(lambda x: 1 if x > threshold else 0)\n    return interactions","6663cc89":"# https:\/\/github.com\/aayushmnit\/cookbook\/blob\/master\/recsys.py\ndef create_user_dict(interactions):\n    '''\n    Function to create a user dictionary based on their index and number in interaction dataset\n    Required Input - \n        interactions - dataset create by create_interaction_matrix\n    Expected Output -\n        user_dict - Dictionary type output containing interaction_index as key and user_id as value\n    '''\n    user_id = list(interactions.index)\n    user_dict = {}\n    counter = 0 \n    for i in user_id:\n        user_dict[i] = counter\n        counter += 1\n    return user_dict","0d87830d":"# https:\/\/github.com\/aayushmnit\/cookbook\/blob\/master\/recsys.py\ndef create_item_dict(df,id_col,name_col):\n    '''\n    Function to create an item dictionary based on their item_id and item name\n    Required Input - \n        - df = Pandas dataframe with Item information\n        - id_col = Column name containing unique identifier for an item\n        - name_col = Column name containing name of the item\n    Expected Output -\n        item_dict = Dictionary type output containing item_id as key and item_name as value\n    '''\n    item_dict ={}\n    for i in range(df.shape[0]):\n        item_dict[(df.loc[i,id_col])] = df.loc[i,name_col]\n    return item_dict","94a19a7a":"# https:\/\/github.com\/aayushmnit\/cookbook\/blob\/master\/recsys.py\ndef runMF(interactions, n_components=30, loss='warp', k=15, epoch=30,n_jobs = 4):\n    '''\n    Function to run matrix-factorization algorithm\n    Required Input -\n        - interactions = dataset create by create_interaction_matrix\n        - n_components = number of embeddings you want to create to define Item and user\n        - loss = loss function other options are logistic, brp\n        - epoch = number of epochs to run \n        - n_jobs = number of cores used for execution \n    Expected Output  -\n        Model - Trained model\n    '''\n    \n    #uncommented for train test split\n#     x = sparse.csr_matrix(interactions.values)\n    model = LightFM(no_components= n_components, loss=loss,k=k)\n    model.fit(x,epochs=epoch,num_threads = n_jobs)\n    return model","e00d554d":"# https:\/\/github.com\/aayushmnit\/cookbook\/blob\/master\/recsys.py\ndef sample_recommendation_user(model, interactions, user_id, user_dict, \n                               item_dict,threshold = 0,nrec_items = 10, show = True):\n    '''\n    Function to produce user recommendations\n    Required Input - \n        - model = Trained matrix factorization model\n        - interactions = dataset used for training the model\n        - user_id = user ID for which we need to generate recommendation\n        - user_dict = Dictionary type input containing interaction_index as key and user_id as value\n        - item_dict = Dictionary type input containing item_id as key and item_name as value\n        - threshold = value above which the rating is favorable in new interaction matrix\n        - nrec_items = Number of output recommendation needed\n    Expected Output - \n        - Prints list of items the given user has already bought\n        - Prints list of N recommended items  which user hopefully will be interested in\n    '''\n    n_users, n_items = interactions.shape\n    user_x = user_dict[user_id]\n    scores = pd.Series(model.predict(user_x,np.arange(n_items)))\n    scores.index = interactions.columns\n    scores = list(pd.Series(scores.sort_values(ascending=False).index))\n    \n    known_items = list(pd.Series(interactions.loc[user_id,:] \\\n                                 [interactions.loc[user_id,:] > threshold].index) \\\n\t\t\t\t\t\t\t\t .sort_values(ascending=False))\n    \n    scores = [x for x in scores if x not in known_items]\n    return_score_list = scores[0:nrec_items]\n    known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n    scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n    if show == True:\n        print(\"Known Likes:\")\n        counter = 1\n        for i in known_items:\n            print(str(counter) + '- ' + i)\n            counter+=1\n\n        print(\"\\n Recommended Items:\")\n        counter = 1\n        for i in scores:\n            print(str(counter) + '- ' + i)\n            counter+=1\n    return return_score_list","6a614b4d":"interactions = create_interaction_matrix(df = df_freq, user_col = \"user_id\", item_col = 'artist_id', rating_col = 'freq', norm= False, threshold = None)\ninteractions.head()","93a4abc5":"interactions.shape","aa5f7cc3":"user_dict = create_user_dict(interactions=interactions)","66a36499":"artists_dict = create_item_dict(df = df_artist, id_col = 'artist_id', name_col = 'artist')","aa6646af":"x = sparse.csr_matrix(interactions.values)\ntrain, test = lightfm.cross_validation.random_train_test_split(x, test_percentage=0.2, random_state=None)","0f48936b":"%time\nmodel = runMF(interactions = train,\n                 n_components = 30,\n                 loss = 'warp',\n                 k = 15,\n                 epoch = 30,\n                 n_jobs = 4)","671bbe16":"train_auc = auc_score(model, train, num_threads=4).mean()\nprint('Train AUC: %s' % train_auc)","f6f28435":"test_auc = auc_score(model, test, train_interactions=train, num_threads=4).mean()\nprint('Test AUC: %s' % test_auc)","d5abcac7":"train_precision = precision_at_k(model, train, k=10).mean()\ntest_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()","3e8775b6":"print('train Precision %.2f, test Precision %.2f.' % (train_precision, test_precision))","9185144f":"rec_list = sample_recommendation_user(model = model, \n                                      interactions = interactions, \n                                      user_id = '9cc0cfd4d7d7885102480dd99e7a90d6', \n                                      user_dict = user_dict,\n                                      item_dict = artists_dict, \n                                      threshold = 0,\n                                      nrec_items = 10,\n                                      show = True)","ee4ff690":"rec_list = sample_recommendation_user(model = model, \n                                      interactions = interactions, \n                                      user_id = 'ffe32d5412269f3041c58cbf0dde3306', \n                                      user_dict = user_dict,\n                                      item_dict = artists_dict, \n                                      threshold = 0,\n                                      nrec_items = 10,\n                                      show = True)","1740b34c":"### Size of dataframe","195b9ebb":"### Compute Precision scores\n#### Precision score is based on the number of positives items in the K highest ranked items. ","14ec97ad":"<a id=\"subsection-1\"><\/a>\n## Helper Functions","57576555":"#### The parameter train_interactions allows you to exclude known positives in training set from the predicitons and score calculations. \n#### This is to avoid re-recommending the items the user has alreardy interacted with","38e41c96":"<a id=\"section-2\"><\/a>\n# Read Data","78605725":"### Compute AUC score for Test set","b5d9d65a":"### Train the Matrix Factorization Model","1874cb77":"### Train-Test split","725e08c8":"### Create User Dict","81df01c4":"<a id=\"subsection-5\"><\/a>\n## Examples","8902c5ba":"### Create interaction matrix","6adc434d":"### For recommender system, I'm only keeping the artists with frequency higher than 50","ba96b171":"### Let's see some examples of recommendations:","47d37f6a":"<a id=\"section-4\"><\/a>\n# Recommendar System ","3819e193":"### Clean up column names","3094ce43":"### And keeping the users with at least 10 unique artists in their playlists to lessen the impact of cold start problem","5e1a9112":"<a id=\"subsection-4\"><\/a>\n## Evaluation Metrics","5a1a2ce6":"<a id=\"section-1\"><\/a>\n# Import Libraries ","1288266e":"### group by to get the frequnecy count for each user and artist (# of times that an artist has appeared in playlists created by a user)","39d4fbcf":"<a id=\"subsection-3\"><\/a>\n## Matrix Factorization (MF) Model","117889e7":"### How does a MF model work?\n\nhttps:\/\/developers.google.com\/machine-learning\/recommendation\/collaborative\/matrix","0ddedd8f":"### create a DF for artists and add artist id","5cda204c":"### I use the LightFM library and run a traditional MF model since the dataset doesn't include any user or artist features, \n### but the library allows you to build a hybrid model too. ","03f380f5":"### Create Item dict","614ed30d":"### LightFM documentation: \n\nhttps:\/\/making.lyst.com\/lightfm\/docs\/\n\n### You can find some examples in LightFM GitHub:\nhttps:\/\/github.com\/lyst\/lightfm\/blob\/master\/examples\/","a525f4e2":"### This notebook shows the steps to build a recommender system using the Collaborative Filtering approach. \n### The goal is to recommend artists based on user's past activity and interests of similar users.\n\n* [Import Libraries ](#section-1)\n* [Read Data](#section-2)\n* [Data Prep](#section-3)\n* [Recommender System](#section-4)\n    - [Helper Functions](#subsection-1)\n    - [Prep Model Inputs](#subsection-2)\n    - [Matrix Factorization (MF) Model](#subsection-3)\n    - [Evaluation Metrics](#subsection-4)\n    - [Examples](#subsection-5)","76f48f05":"### add artist_id to the main DF","90248095":"<a id=\"section-3\"><\/a>\n# Data Prep","2208fa96":"#### You can do hyper-parameter tuning for better results","e67156cd":"<a id=\"subsection-2\"><\/a>\n## Prep Model Inputs","1fe228e3":" ### Compute AUC score for Train set","a36aa4e1":"### Helpers functions are from the repo below: \nhttps:\/\/github.com\/aayushmnit\/cookbook\/blob\/master\/recsys.py","641d92af":"### The original dataset is quite large. I only read 50% of rows for faster run. "}}