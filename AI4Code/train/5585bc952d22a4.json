{"cell_type":{"d821a28e":"code","add2ef4a":"code","94ce676f":"code","77f19405":"code","90325b6f":"code","8635142d":"code","d0634d94":"code","7dfdea28":"code","3d028409":"code","4479210d":"code","029df3a3":"code","ecfbe42e":"code","4419572d":"code","00ddebaf":"code","d3ee19f6":"code","454e076a":"code","25e064ff":"code","e1ad5b3d":"code","c3a5969f":"code","ad67f1a4":"code","f63f21be":"code","15d133ed":"code","acc5a20f":"code","e35a2384":"code","7c774eb4":"code","4d9e2cf5":"code","3619f556":"code","be99e615":"code","664123d2":"code","14636f08":"code","69b4d1c7":"code","fad6c5d2":"code","51e208c3":"markdown","19b2c035":"markdown","f7dd6642":"markdown","b264e232":"markdown","c6eb99f1":"markdown","169fb2c5":"markdown","ed70ff8f":"markdown","7393e8bf":"markdown","4d12c791":"markdown","4c4bc082":"markdown","e1f3e9b2":"markdown","ccf6e1f4":"markdown","54f3acbc":"markdown","bc48ebb1":"markdown","a66277f0":"markdown","6f98a228":"markdown","daaf7e4a":"markdown","5a2e1a61":"markdown","34eabe98":"markdown","3b5b264f":"markdown","14c5a849":"markdown","8cd105cf":"markdown","e8396848":"markdown","d393afde":"markdown","82de882e":"markdown","0f1bd920":"markdown","644a0610":"markdown","5601e898":"markdown","0340d06b":"markdown","fabc2742":"markdown"},"source":{"d821a28e":"!pip install librosa","add2ef4a":"import matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nfrom scipy.io import wavfile as wav\nimport pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\n\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nimport catboost as cb\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler\nimport tensorflow.keras as keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import *","94ce676f":"path = '..\/input\/gtzan-dataset-music-genre-classification\/Data'\nprint(list(os.listdir(f'{path}\/genres_original\/')))","77f19405":"def plot_sound(path):\n    plt.figure(figsize=(14, 5))\n    x, sr = librosa.load(path)\n    print(\"length {}, sample-rate {}\".format(x.shape, sr))\n    librosa.display.waveplot(x, sr=sr)\n    \n    return x","90325b6f":"blues_path = '..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/blues\/blues.00000.wav'\nblues_audio = plot_sound(blues_path)\nipd.Audio(blues_path)","8635142d":"rock_path = '..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/rock\/rock.00001.wav'\nrock_audio = plot_sound(rock_path)\nipd.Audio(rock_path)","d0634d94":"pop_path = '..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/pop\/pop.00001.wav'\npop_audio = plot_sound(pop_path)\nipd.Audio(pop_path)","7dfdea28":"wave_sample_rate, wave_audio = wav.read(rock_path)","3d028409":"wave_sample_rate","4479210d":"wave_audio","029df3a3":"x, sr = librosa.load(pop_path)","ecfbe42e":"X = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 6))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()","4419572d":"df = pd.read_csv('\/kaggle\/input\/gtzan-dataset-music-genre-classification\/Data\/features_3_sec.csv')\ndf.head()","00ddebaf":"df.shape","d3ee19f6":"df.info()","454e076a":"df['label'].value_counts()","25e064ff":"# Computing the Correlation Matrix\nspike_cols = [col for col in df.columns if 'mean' in col]\ncorr = df[spike_cols].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(16, 11));\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(0, 25, as_cmap=True, s = 90, l = 45, n = 5)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 20)\nplt.xticks(fontsize = 10)\nplt.yticks(fontsize = 10);","e1ad5b3d":"x = df[[\"label\", \"tempo\"]]\n\nfig, ax = plt.subplots(figsize=(16, 8));\nsns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'husl');\n\nplt.title('BPM Boxplot for Genres', fontsize = 20)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 10);\nplt.xlabel(\"Genre\", fontsize = 15)\nplt.ylabel(\"BPM\", fontsize = 15)\nplt.savefig(\"BPM_Boxplot.png\")","c3a5969f":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['label'])","ad67f1a4":"X = df.drop(['label','filename'],axis=1)\ny = df['label'] ","f63f21be":"cols = X.columns\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X)\n\n# new data frame with the new scaled data. \nX = pd.DataFrame(np_scaled, columns = cols)","15d133ed":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","acc5a20f":"def model_assess(model, title = \"Default\"):\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    #print(confusion_matrix(y_test, preds))\n    print('Accuracy', title, ':', round(accuracy_score(y_test, preds), 5), '\\n')","e35a2384":"# Naive Bayes\nnb = GaussianNB()\nmodel_assess(nb, \"Naive Bayes\")\n\n# Stochastic Gradient Descent\nsgd = SGDClassifier(max_iter=5000, random_state=0)\nmodel_assess(sgd, \"Stochastic Gradient Descent\")\n\n# KNN\nknn = KNeighborsClassifier(n_neighbors=19)\nmodel_assess(knn, \"KNN\")\n\n# Decission trees\ntree = DecisionTreeClassifier()\nmodel_assess(tree, \"Decission trees\")\n\n# Random Forest\nrforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\nmodel_assess(rforest, \"Random Forest\")\n\n# Support Vector Machine\nsvm = SVC(decision_function_shape=\"ovo\")\nmodel_assess(svm, \"Support Vector Machine\")\n\n# Logistic Regression\nlg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\nmodel_assess(lg, \"Logistic Regression\")\n\n# Neural Nets\nnn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1)\nmodel_assess(nn, \"Neural Nets\")\n\n# catboost\ncbc = cb.CatBoostClassifier(verbose=0, eval_metric='Accuracy', loss_function='MultiClass')\nmodel_assess(cbc,\"Cat Boost Classifier\")\n\n# Cross Gradient Booster\nxgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nmodel_assess(xgb, \"Cross Gradient Booster\")\n\n# Cross Gradient Booster (Random Forest)\nxgbrf = XGBRFClassifier(objective= 'multi:softmax')\nmodel_assess(xgbrf, \"Cross Gradient Booster (Random Forest)\")","7c774eb4":"# Final model\ncbc = cb.CatBoostClassifier(verbose=0, eval_metric='Accuracy', loss_function='MultiClass')\ncbc.fit(X_train, y_train)\n\n\npreds = cbc.predict(X_test)\n\nprint('Accuracy', ':', round(accuracy_score(y_test, preds), 5), '\\n')\n\n# Confusion Matrix\nconfus_mat = confusion_matrix(y_test, preds) \nplt.figure(figsize = (10, 5))\nsns.heatmap(confus_mat)","4d9e2cf5":"X_train.shape[1]","3619f556":"model = Sequential()\n\nmodel.add(Flatten(input_shape=(58,)))\nmodel.add(Dense(512, activation='relu', kernel_regularizer = keras.regularizers.l2(0.001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256, activation='relu', kernel_regularizer = keras.regularizers.l2(0.003)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='relu', kernel_regularizer = keras.regularizers.l2(0.01)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","be99e615":"early_stopping= EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5) \ncheck_pointer = ModelCheckpoint(filepath = 'clf-resnet-checkpoint.hdf5',verbose=1,save_best_only=True) \nreduce_lr = ReduceLROnPlateau(monitor='val_loss',mode='min',verbose=1,patience=5,min_delta = 0.0001,factor=0.2) \ncallbacks = [check_pointer,early_stopping,reduce_lr]","664123d2":"# compile the model\nadam = keras.optimizers.Adam(lr=1e-4)\nmodel.compile(optimizer=adam,\n             loss=\"sparse_categorical_crossentropy\",\n             metrics=[\"accuracy\"])","14636f08":"hist = model.fit(X_train, y_train,\n                 validation_data = (X_test,y_test),\n                 epochs = 100,\n                 batch_size = 32, callbacks = [check_pointer,early_stopping])","69b4d1c7":"test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(f\"Test accuracy: {test_accuracy}\")","fad6c5d2":"plt.figure(figsize=(20,15))\nfig, axs = plt.subplots(2)\n\n# accuracy \naxs[0].plot(hist.history[\"accuracy\"], label=\"train accuracy\")\naxs[0].plot(hist.history[\"val_accuracy\"], label=\"test accuracy\")    \naxs[0].set_ylabel(\"Accuracy\")\naxs[0].legend(loc=\"lower right\")\naxs[0].set_title(\"Accuracy eval\")\n    \n# Error \naxs[1].plot(hist.history[\"loss\"], label=\"train error\")\naxs[1].plot(hist.history[\"val_loss\"], label=\"test error\")    \naxs[1].set_ylabel(\"Error\")\naxs[1].set_xlabel(\"Epoch\")\naxs[1].legend(loc=\"upper right\")\naxs[1].set_title(\"Error eval\")\n    \nplt.show()","51e208c3":"First of all let's import all the libraries","19b2c035":"# Build ML Models","f7dd6642":"# Plot Accuracy and Loss","b264e232":"Let's check whther our dataset is balanced or not","c6eb99f1":"In order to prevent our model from overfitting we wll use callbacks","169fb2c5":"# Deep Learning Model","ed70ff8f":"**Independent and dependent variables**","7393e8bf":"So we got highest accuracy with catboost model.Let's print the confusion matrix of it","4d12c791":"# Plot Spectrogram\n\nA spectrogram is a visual way of representing the signal loudness, of a signal over time at various frequencies present in a particular waveform. Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.","4c4bc082":"# Load Dataset\n","e1f3e9b2":"We will going to make 11 models and then choose the best model","ccf6e1f4":"Let's see all the classes that we have","54f3acbc":"# Import Libraries","bc48ebb1":"So our dataset is balanced dataset","a66277f0":"Take one audio from  blues, rock and pop songs ","6f98a228":"We should first see how big our dataset is","daaf7e4a":"The vertical axis represents frequencies (from 0 to 10kHz), and the horizontal axis represents the time of the clip.","5a2e1a61":"Well this is the first time I am trying my hands on Audio Classification.In this task we will going to classify ten different audios.I will going to make both machine learning and deep learning model.The different category that we have are:\n- disco \n- metal \n- reggae \n- blues\n- rock\n- classical\n- jazz\n- hiphop \n- country\n- pop","34eabe98":"#### Box Plot for Genres Distributions","3b5b264f":"#### About the data\n- **genres original** - A collection of 10 genres with 100 audio files each, all having a length of 30 seconds (the famous GTZAN dataset, the MNIST of sounds)\n- **images original** - A visual representation for each audio file. One way to classify data is through neural networks. Because NNs (like CNN, what we will be using today) usually take in some sort of image representation, the audio files were converted to Mel Spectrograms to make this possible (we'll be talking about this more in depth later)\n- **2 CSV files** - Containing features of the audio files. One file has for each song (30 seconds long) a mean and variance computed over multiple features that can be extracted from an audio file (more in depth later). The other file has the same structure, but the songs were split before into 3 seconds audio files (this way increasing 10 times the amount of data we fuel into our classification models). With data, more is always better.","14c5a849":"# Train-Test Split","8cd105cf":"Now we are going to make a function which will plot waveplot","e8396848":"Below code is taken from this [link](https:\/\/www.kaggle.com\/andradaolteanu\/work-w-audio-data-visualise-classify-recommend)","d393afde":"Let's convert the **label** values into integers","82de882e":"# Explore Audio Data","0f1bd920":"#### Correlation Heatmap for feature means","644a0610":"We are going to normalize our data","5601e898":"Wuhhoo our model is ready let's train our model,let's run for 100 epochs","0340d06b":"# Data Preprocessing","fabc2742":"Now it's time to build our deep learning model,so let's go ahead"}}