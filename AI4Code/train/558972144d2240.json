{"cell_type":{"9edb97e6":"code","40e28611":"code","010024d5":"code","437760d9":"code","346bbdd0":"code","08af4eff":"code","708c40cc":"code","dcfde85a":"code","7c83e961":"code","33eabad8":"code","01e21f80":"code","8772fdd1":"code","ff51233a":"code","fa7ba048":"code","a1e098d9":"code","bbfb97c9":"code","7bde0666":"code","15a2c4ec":"code","28e723f7":"code","96f683ed":"code","266c1c16":"code","745134b7":"code","57aaa9e0":"code","af5a1e23":"markdown","1e701d80":"markdown","a9607071":"markdown","30567df5":"markdown","62f3391b":"markdown","6e9076ca":"markdown","32bad511":"markdown"},"source":{"9edb97e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","40e28611":"import shutil\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","010024d5":"path = '\/kaggle\/content'\n# Extract files\nimport zipfile\nwith zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/train.zip', 'r') as zipf:\n    zipf.extractall(path)","437760d9":"\n\ntrain_path = path + '\/train'\ntrain_dog_data = train_path + '\/dog'\ntrain_cat_data = train_path + '\/cat'\n\nvalid_path = path + '\/valid'\nvalid_dog_data = valid_path + '\/dog'\nvalid_cat_data = valid_path + '\/cat'","346bbdd0":"print(len(os.listdir(train_path)))\n#print(len(os.listdir(valid_path)))         ## as we see , there is an error because there is not valid .","08af4eff":"#print(os.listdir(train_path))   # it has all the images named like ( 'cat.2914.jpg',)","708c40cc":"from sklearn.model_selection import train_test_split\n# Split cats and dogs images to train and valid datasets\nimg_filenames = os.listdir(train_path)\nprint('Num of images:', len(img_filenames))\n\ndog_filenames = [fn for fn in img_filenames if fn.startswith('dog')]\ncat_filenames = [fn for fn in img_filenames if fn.startswith('cat')]\n\ndataset_filenames = train_test_split(\n    dog_filenames, cat_filenames, test_size=0.1, shuffle=True, random_state=42\n)\n\ntrain_dog_total, valid_dog_total, train_cat_total, valid_cat_total = [len(fns) for fns in dataset_filenames]\ntrain_total = train_dog_total + train_cat_total\nvalid_total = valid_dog_total + valid_cat_total\nprint('Train: {}, test: {}'.format(train_total, valid_total))","dcfde85a":"# Move images\nmake_dirs = [train_dog_data, valid_dog_data, train_cat_data, valid_cat_data]\nfor dir, fns in zip(make_dirs, dataset_filenames):\n    os.makedirs(dir, exist_ok=True)\n    for fn in tqdm.tqdm(fns):\n        shutil.move(os.path.join(train_path, fn), dir)\n    print('elements in {}: {}'.format(dir, len(os.listdir(dir))))","7c83e961":"img_size = 224\nbatch_size= 64","33eabad8":"train_gen = ImageDataGenerator(                       # For data augmantention + loading  \n        rescale=1.\/255,\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        shear_range=0.2,\n        fill_mode=\"nearest\")            # repeating the last pixel (row) ","01e21f80":"valid_gen = ImageDataGenerator(rescale=1.\/255)","8772fdd1":"train_set = train_gen.flow_from_directory(\n        directory = train_path ,            # Training Data path \n        batch_size=batch_size,\n        target_size=(img_size,img_size),\n        class_mode=\"binary\")\n\nvalid_set = valid_gen.flow_from_directory(\n            directory=valid_path,\n             batch_size=batch_size,\n             target_size=(img_size,img_size),\n            class_mode=\"binary\")","ff51233a":"# show 15 images\nsome_pets = next(train_set)[0][:15]        # next  : means the next Batch \nfig, axes = plt.subplots(3, 5, figsize=(20, 20))\nfor img, ax in zip(some_pets, axes.flatten()):\n    ax.imshow(img)\nplt.tight_layout()\nplt.show()","fa7ba048":"import matplotlib.pyplot as plt\n\ndef show_img(image):\n    fig,axes = plt.subplots( 1,5 , figsize=(20,20) )\n    axes = axes.flatten()\n    for img ,ax in zip(image,axes):\n        ax.imshow(img)\n    plt.tight_layout()\n    plt.show()","a1e098d9":"# Do augmantation on the first picture only , 5 times randomly .\naug_img = [train_set[0][0][0] for i in range(5)]\nshow_img(aug_img)","bbfb97c9":"# Import Feature Vector from Tensorflow hub\nimport tensorflow as tf \nimport tensorflow_hub as hub\nimg_size = 224\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_100_224\/feature_vector\/5\",\n                   trainable=False,output_shape=[1280]), \n    #outputshape : zay el flatten el b3mlha fe a5er el model\n    # trainable= false : means that im using the hyperparameters of the model.\n# Note : im training the last layer only , because the hyperparameters in the previous layers are fixed.\n    tf.keras.layers.Dense(2, activation='softmax')\n])\nmodel.build([None, 224, 224, 3])  # Batch input shape.\n","7bde0666":"model.compile(optimizer=tf.keras.optimizers.Adam(0.00115),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","15a2c4ec":"# as we see here, the Trainable Params : 2,562  parameter Only \nmodel.summary()","28e723f7":"hist = model.fit(\n    train_set,\n    validation_data=valid_set,\n    epochs=4\n)","96f683ed":"def show_graphs(hist):\n    plt.figure(figsize=(12, 8))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(hist.history['accuracy'], label='train')\n    plt.plot(hist.history['val_accuracy'], label='valid')\n    plt.legend(loc='lower right')\n    plt.title('Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(hist.history['loss'], label='train')\n    plt.plot(hist.history['val_loss'], label='valid')\n    plt.legend(loc='upper left')\n    plt.title('Loss (sparse_categorical_crossentropy)')\n\n    plt.show()\n    \nshow_graphs(hist)","266c1c16":"test_data = path + '\/test'\n\n# Extract files\nimport zipfile\nwith zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/test1.zip', 'r') as zipf:\n    zipf.extractall(test_data)","745134b7":"test_generator = ImageDataGenerator(rescale=1.\/255)\n\ntest_set = test_generator.flow_from_directory(\n    directory=test_data,\n    target_size=(img_size, img_size),\n    batch_size=1,\n    class_mode='binary',\n    shuffle=False\n)\ntest_set.reset()\n\ntest_total = len(test_set.filenames)\npredict = model.predict_generator(test_set, steps=test_total, verbose=1)\n","57aaa9e0":"submission = pd.read_csv('\/kaggle\/input\/dogs-vs-cats\/sampleSubmission.csv', index_col='id')\nsubmission['label'] = np.argmax(predict,axis=1)\nsubmission.to_csv('D:\\\\TekoMoro\\Cats_Dogs\\Cat_dogs_MahmoudOsama_sub.csv')","af5a1e23":"## Visulize some images to make sure that you read the data correctly ","1e701d80":"## Split cats and dogs images to ( train and valid datasets) ","a9607071":"# To Extract the Zip Files ( Unpack )","30567df5":"## **Preprocessing\u00b6**\ndecode images \\\nrescale image layers from [0..255] to [0,1]","62f3391b":"## Create the Model : ","6e9076ca":"## After Dividing the Data , we need to put it in folders ","32bad511":"## Visualize Data Augmantation :"}}