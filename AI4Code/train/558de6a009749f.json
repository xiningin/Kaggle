{"cell_type":{"0c2d81e8":"code","75a9fafd":"code","80dbdcbb":"code","9fe6de8e":"code","503e376f":"code","b2296e59":"code","48b26f04":"code","6df3c8ad":"code","ae303865":"code","a73910c0":"code","96e19d76":"code","6454f85f":"code","fc858023":"code","52d4c942":"code","d75c9798":"code","b2a2ab57":"code","945dd5d3":"code","0906f7d6":"code","83d4e6ff":"code","beae851f":"code","ca655252":"code","d61a629b":"code","e82dacb3":"code","88900b42":"code","9bac648c":"code","c4c05be6":"code","0663136a":"code","b5dd58ec":"code","f570fc48":"code","0735e1fb":"code","ee2de708":"code","3356538d":"code","b64ca5c8":"markdown","2c2006a6":"markdown","36b5f773":"markdown","d38e145a":"markdown","1186327e":"markdown"},"source":{"0c2d81e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75a9fafd":" #import the data sets \nimport pandas as pd\ntrain=pd.read_csv(\"\/kaggle\/input\/fake-news\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/fake-news\/test.csv\")","80dbdcbb":"#here our data set how it looks\ntrain.head()","9fe6de8e":"#all na values in all the columns\ntrain.isna().sum()","503e376f":"#drop the na values \ntrain=train.dropna()","b2296e59":"#copy and rest the index \nmsg=train.copy()\nmsg.reset_index(inplace=True)","48b26f04":"#here we can see a lot of punctuations or uppercase letter so we need to clean the text\nmsg.head(10)","6df3c8ad":"#import the nltk libraries \nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n  \nlemmatizer = WordNetLemmatizer()\nps=PorterStemmer()","ae303865":"w_list = [\"program\", \"programs\", \"programmer\", \"programing\", \"programmers\",\"history\",\"historical\"]\n \nfor w in w_list:\n    print(w, \": \",'\\t\\tPorterStemmer : ', ps.stem(w),'\\t \\tlemmatizer :',lemmatizer.lemmatize(w) )","a73910c0":"#these are the stopwords which is not much useful for our prediction so we have to remove it \nstopwords.words('english')","96e19d76":"corpus=[]\nfor i in range(0,len(msg)):\n    review=re.sub(\"[^a-zA-z]\",' ',msg['title'][i])\n    review=review.lower()\n    review =review.split()\n    review=[ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review=' '.join(review)\n    corpus.append(review)","6454f85f":"msg['title'][4]","fc858023":"corpus[4]","52d4c942":"# example \n# s1=good boy\n# s2=boy girl good\n\n# words       s1             s2\n# good   1\/2           1\/3\n# boy     1\/2          1\/3\n# girl     0            1\/3","d75c9798":"\n# example \n# s1=good boy\n# s2=boy girl good\n#words    IDF\n#good     log(2\/2)=0\n#boy      log(2\/2)=0\n#girls    log(2\/1)\n# Finally TF*IDF\n#         f1         f2     f3\n\n#     good         boy      girl\n\n# s1  1\/2*0        1\/2*0    0*log(2\/1)\n\n# s2  1\/3*0        1\/3*0    1\/3*log(2)\n","b2a2ab57":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\ncv=CountVectorizer(max_features=5000)#give me top 5000 features\nX=cv.fit_transform(corpus).toarray()\n\n\n\ncv_tf=TfidfVectorizer(max_features=5000)#give me top 5000 features\nX_tf=cv.fit_transform(corpus).toarray()","945dd5d3":"pd.DataFrame(X,columns=cv.get_feature_names())","0906f7d6":"y=msg['label']","83d4e6ff":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import MultinomialNB\nm=MultinomialNB()","beae851f":"def score(X,y,model):\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n    detect_model=model.fit(X_train,y_train)\n    y_pred=detect_model.predict(X_test)\n    result= metrics.accuracy_score(y_test,y_pred)\n    return result,detect_model\n    ","ca655252":"print('TFidf_accuracy : ',score(X_tf,y,m),'\\nCountVectorizer_accuracy : ',score(X,y,m))","d61a629b":"def model(X,y,model):\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n    detect_model=model.fit(X_train,y_train)\n    return detect_model\n    ","e82dacb3":"detect_model=model(X_tf,y,m)","88900b42":"#most Real words\nsorted(zip(detect_model.coef_[0],cv.get_feature_names()),reverse=True)[:20]","9bac648c":"#most fake words\nsorted(zip(detect_model.coef_[0],cv.get_feature_names()),reverse=False)[:20]","c4c05be6":"corpus[1:4]\n","0663136a":"from sklearn.feature_extraction.text import CountVectorizer\ncv1=CountVectorizer()#give me top 5000 features\na1=cv1.fit_transform(corpus[1:4]).toarray()","b5dd58ec":"pd.DataFrame(a1,columns=cv1.get_feature_names())","f570fc48":"a3=cv1.transform(corpus[8:10]).toarray()\na3","0735e1fb":"pd.DataFrame(a3,columns=cv1.get_feature_names())","ee2de708":"a2=cv1.fit_transform(corpus[8:10]).toarray()\n","3356538d":"pd.DataFrame(a2,columns=cv1.get_feature_names())","b64ca5c8":"# TF-IDF\nTF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)\n\nTerm frequency(TF)=count of particular word present in a senetence \/ total number of words in sentence","2c2006a6":"\nHere we can see that lemmatizer is much better than tha setming because in steming words have mo meaning but if we use lemmatizer then it will give meaning full word","36b5f773":"inverse document frequency(IDF)=log(total no of senetecs\/no of sentences contaning that words)","d38e145a":"After Cleaning the data now convert the string or text data into numerical values for the undersatnding of the machines","1186327e":"here we can see the how our cleaned data look like \n\n"}}