{"cell_type":{"214aaad7":"code","faf68584":"code","b41bdecd":"code","fff0bd60":"code","d3a91596":"code","27d118a9":"code","8f416d9f":"code","5cf1d928":"code","bcba282d":"code","105b626b":"code","9bdfc2e6":"code","a5b2d233":"code","f37604f4":"code","6d480fec":"code","e740e2b9":"code","e791c57f":"code","af540054":"code","b05632d1":"code","264656d5":"code","9b18fc65":"code","c722d4ed":"code","00db6b3e":"code","f4fd88ab":"code","51b1a455":"code","872febec":"code","51052a49":"code","dc0895b3":"code","9475b683":"code","8b719277":"code","cc5f0111":"code","cd28610a":"code","0cde38fd":"code","e969e485":"code","f8b1cf70":"code","e742a7d9":"code","86718b1b":"code","09fdccb9":"code","88777889":"code","e4e746d8":"code","25796109":"code","27672015":"code","1e161b48":"code","8df0854c":"code","0360c265":"code","82bad7b0":"code","5b361e27":"markdown","4a2a18b6":"markdown","11965d31":"markdown","70357b63":"markdown","80b9b45c":"markdown","43e1c4de":"markdown","b403690d":"markdown","91b9bfd9":"markdown","e45ea843":"markdown","354922c5":"markdown","0d5f6f37":"markdown","6dee1ccd":"markdown","2da55dba":"markdown","bcf0c451":"markdown","aadee327":"markdown","dd564c75":"markdown","51db45d5":"markdown","9c5ef6ba":"markdown","813a6e15":"markdown","119a2f6c":"markdown","27305c00":"markdown","6176e62b":"markdown","3dc43ef0":"markdown","99f6ae71":"markdown","1ac4ce85":"markdown"},"source":{"214aaad7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","faf68584":"import os\nimport torch\nimport torchvision\n# To read zipped .tar, .tz file\nimport tarfile","b41bdecd":"from torchvision.datasets.utils import download_url","fff0bd60":"url = 'https:\/\/s3.amazonaws.com\/fast-ai-imageclas\/cifar10.tgz'\ndownload_url(url, '.')","d3a91596":"with tarfile.open('.\/cifar10.tgz', 'r:gz') as tar:\n    tar.extractall(path = '.\/data')","27d118a9":"data_dir = '.\/data\/cifar10'\nprint(os.listdir(data_dir))\n\nclasses = os.listdir(data_dir + '\/train')\nprint(classes)","8f416d9f":"airplane_file = os.listdir(data_dir + '\/train\/airplane')\nprint('Number of Training Examples: ', len(airplane_file))\nprint(airplane_file[:5])","5cf1d928":"ship_file = os.listdir(data_dir + '\/test\/ship')\nprint('Number of Testing Examples: ', len(ship_file))\nprint(ship_file[:5])","bcba282d":"from torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nimport torchvision.transforms as transforms","105b626b":"trans = transforms.Compose([\n    # this operation was done, to make Image size compatible with AlexNet Model\n    transforms.Resize((70,70)),\n    # To focus on only primary component of Image\n    transforms.RandomCrop((64,64)),\n    transforms.ToTensor(),\n    # To nullify dominance of one of Color channel\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","9bdfc2e6":"train_ds = ImageFolder(data_dir+'\/train', transform = trans)\nval_ds = ImageFolder(data_dir+'\/test', transform = trans)","a5b2d233":"# Below library will help us to pass batch of data, as feeding all data at once will lead to OverLoading and System will get Hang\nfrom torch.utils.data.dataloader import DataLoader","f37604f4":"# this is one of Hyper parameter, let's start with\nbatch_size = 512","6d480fec":"# PyTorch data loaders\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nvalid_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)","e740e2b9":"# These libraries will help us to plot images\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid","e791c57f":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize = (12,12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[: 100], 10).permute(1,2,0))\n        break","af540054":"show_batch(train_dl)","b05632d1":"show_batch(valid_dl)","264656d5":"img, label = train_ds[0]\nimg.shape, label","9b18fc65":"import torch.nn as nn\nimport torch.nn.functional as F","c722d4ed":"class AlexNet(nn.Module):\n    \n    def __init__(self, num_classes):\n        \n        super().__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size = 11, stride = 4, padding = 2),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size = 3, stride = 2),\n            \n            nn.Conv2d(64, 192, kernel_size = 5, padding = 2),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size = 3, stride = 2),\n            \n            nn.Conv2d(192, 384, kernel_size = 3, padding = 1),\n            nn.ReLU(inplace = True),\n            \n            nn.Conv2d(384, 256, kernel_size = 3, padding = 1),\n            nn.ReLU(inplace = True),\n            \n            nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size = 3, stride = 2)\n        )\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            \n            nn.Linear(256*6*6, 4096),\n            nn.ReLU(inplace = True),\n            \n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace = True),\n            \n            nn.Linear(4096, num_classes)\n        )\n        \n    def forward(self, x):\n        \n        x = self.features(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), 256*6*6)\n        logit = self.classifier(x)\n        \n        return logit","00db6b3e":"# lets Initialize Model\nmodel = AlexNet(num_classes = 10)","f4fd88ab":"# to get all details of Model\nmodel","51b1a455":"sample = next(iter(train_ds))\nimg = sample[0]\nimg.shape","872febec":"img.unsqueeze(0).shape","51052a49":"out = model(img.unsqueeze(0))","dc0895b3":"F.softmax(out)","9475b683":" # Demo plot\n\nfor images, labels in train_dl:\n    print('Image Shape', images.shape)\n    out = model(images)\n    print('output shape', out.shape)\n    print('out[0]', out[0])\n    break","8b719277":"probs = F.softmax(out[0], dim = 0)\nprobs","cc5f0111":"m = torch.argmax(probs)\nm","cd28610a":"plt.imshow(img.permute(1,2,0))","0cde38fd":"sample[1]","e969e485":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","f8b1cf70":"device = get_default_device()\ndevice","e742a7d9":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(valid_dl, device)\nto_device(model, device)","86718b1b":"def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n    \n    pred = model(x)\n    \n    loss = loss_func(pred, y)\n    \n    if opt is not None:\n        \n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n    metric_result = None\n    \n    if metric is not None:\n        \n        metric_result = metric(pred, y)\n        \n    return loss.item(), len(x), metric_result","09fdccb9":"def evaluate(model, loss_fn, val_dl, metric = None):\n    \n    with torch.no_grad():\n        \n        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in val_dl]\n        \n        losses, nums, metrics = zip(*results)\n        \n        total = np.sum(nums)\n        \n        avg_loss = np.sum(np.multiply(losses, nums)) \/ total\n        \n        avg_metric = None\n        \n        if metric is not None:\n            avg_metric = np.sum(np.multiply(metrics, nums)) \/ total\n            \n    return avg_loss, total, avg_metric","88777889":"def fit(epochs, model, loss_fn, train_dl, val_dl, opt_fn = None, metric = None, scheduler = None, scheduler_on = 'val_metric'):\n    \n    train_losses, val_losses, val_metrics = [], [], []\n    \n    \n    for epoch in range(epochs):\n        \n        model.train()\n        for x, y in train_dl:\n            train_loss, _, _ = loss_batch(model, loss_fn, x, y, opt_fn)\n            \n        model.eval()\n        result = evaluate(model, loss_fn, val_dl, metric)\n        val_loss, total, val_metric = result\n        \n        train_losses.append(train_loss)\n        val_losses.append(val_losses)\n        val_metrics.append(val_metric)\n        \n        if metric is None:\n            print('Epoch{}\/{}, train_loss: {:.4f}, val_loss: {:.4f}' \n                 .format(epoch+1, epochs, train_loss, val_loss))\n            \n        else:\n            print('Epoch {}\/{}, train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}'\n                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric))\n            \n        if scheduler is not None:\n            if scheduler_on == 'val_metric':\n                scheduler.step(val_metrics[-1])\n        \n            \n    return train_losses, val_losses, val_metrics","e4e746d8":"def accuracy(output, labels):\n    _, preds = torch.max(output, dim = 1)\n    \n    return torch.sum(preds == labels).item() \/ len(preds)","25796109":"import numpy as np","27672015":"val_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric = accuracy)\n\nprint(val_loss, val_acc)","1e161b48":"num_epochs = 25\n\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, mode = 'max', verbose = True)","8df0854c":"history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, optimizer, accuracy, scheduler, 'val_metric')","0360c265":"plt.figure(figsize = (8,8))\nplt.plot(history[0], '-x')\nplt.xlabel('Epochs')\nplt.ylabel('Training Loss')\nplt.title('Plot between Training Loss vs Epochs')","82bad7b0":"plt.figure(figsize = (8,8))\nplt.plot(history[2], '-x')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.title('Plot between Validation Loss vs Epochs')","5b361e27":"# Define Helper Functions","4a2a18b6":"CIFAR-10  is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n\nThe label classes in the dataset are:\n\n* airplane \n* automobile \n* bird \n* cat \n* deer \n* dog \n* frog \n* horse \n* ship \n* truck","11965d31":"# Plotting result","70357b63":"# Device Selection","80b9b45c":"We can see some changes in images from original image from dataset","43e1c4de":"# Train Model","b403690d":"Lets load train and test data","91b9bfd9":"We can download data from below given URL","e45ea843":"Let's read some of Images and plot","354922c5":"Lets verify initial guess on validation","0d5f6f37":"Let's Verify Models","6dee1ccd":"Seems like running few more epochs could have increased Accuracy to 80%.\n\nBut I will stop here,\n\nThanks for reading and I hop you have found this useful.\n\nKindly consider Upvoting and happy Learning!!","2da55dba":"# Plot and observe sets","bcf0c451":"We have defined Scheduler to handle Learning rate, as with SGD, we would be looking for Learning rate that changes based on Accuracy\nIf Model finds no change in Accuracy, it will reduce learning rate by factor of 0.1. Controling parameter would be validation accuracy.","aadee327":"# Model Building","dd564c75":"Function to find accuracy, as there is no built in function in Pytorh to find accuracy, its simple code to define accuracy as below","51db45d5":"76% Accuracy for 10 class classification model, is not bad, adding few more dropout and batchnormalization, would have increased accuracy.\n\n\nBut, moto of this ntebook is not to carry out hyperparameter Tuning, it was to run this Revolutionary Model AlexNet.","9c5ef6ba":"To reduce chance of overfitting, lets carryout Normalization and Regularization as below","813a6e15":"So, it was wrong prediction by model, but it was just initial guess !!","119a2f6c":"Data is there in \\data folder","27305c00":"Plotting Train Losses","6176e62b":"So, model has initial guess, it seems all options have been given same weightage i.e. 10%","3dc43ef0":"So, we have 10 Classes, 2 folders available Train and Test","99f6ae71":"# Import Required Libraries and Load Data from Pytorch Dataset","1ac4ce85":"These libraries will help us to build Neural Network"}}