{"cell_type":{"5c61df7e":"code","0d27275c":"code","0056e622":"code","3b8e0039":"code","2a81d0b0":"code","46c4c6d8":"code","1f04da05":"code","cf49330d":"code","f93cae51":"code","eadb95cc":"code","f497e4d1":"code","8b3b931a":"code","05fbdc67":"code","89d2edf8":"code","931f0c7f":"code","f49a5e62":"code","01f9cead":"code","96c14406":"code","980c34f7":"code","614f252f":"code","8aabe72b":"code","65e9de7a":"code","867c9ea4":"code","6d97c626":"code","111831ef":"code","08357842":"code","1636c547":"markdown"},"source":{"5c61df7e":"import numpy as np\nimport pickle\nimport cv2\nimport pandas as pd\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","0d27275c":"EPOCHS = 30\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((28, 28))\nimage_size = 0\ndirectory_root = '..\/input\/train\/train'\nwidth= 28\nheight= 28\ndepth= 1 # the number of channels in our input images. 1 for grayscale single channel images, 3  for standard RGB images","0056e622":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir, 0)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","3b8e0039":"image_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading Images\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir:\n        print(f\"[INFO] processing {directory}\")\n        directory_content = listdir(f\"{directory_root}\/{directory}\")\n        for image in directory_content:\n            image_list.append(convert_image_to_array(f\"{directory_root}\/{directory}\/{image}\"))\n            label_list.append(directory)\n    print(\"[INFO] Image loading complete\")\nexcept Exception as e:\n    print(e)","2a81d0b0":"image_size = len(image_list)\nprint(f\"[INFO] Image size = {image_size}\")","46c4c6d8":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\nn_classes = len(label_binarizer.classes_)","1f04da05":"print(label_binarizer.classes_)","cf49330d":"np_image_list = np.array(image_list, dtype=np.float16) \/ 225.0","f93cae51":"print(np_image_list.shape)\nprint(image_labels.shape)","eadb95cc":"print(\"[INFO] Spliting data to train, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) ","f497e4d1":"aug = ImageDataGenerator(\n    rotation_range=30, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")","8b3b931a":"model = Sequential()\ninputShape = (height, width, depth)\n# if we are using \"channels first\", update the input shape\nif K.image_data_format() == \"channels_first\":\n    inputShape = (depth, height, width)\n# first set of CONV => RELU => POOL layers\nmodel.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# second set of CONV => RELU => POOL layers\nmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# first (and only) set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(500))\nmodel.add(Activation(\"relu\"))\n# softmax classifier\nmodel.add(Dense(n_classes))\nmodel.add(Activation(\"softmax\"))","05fbdc67":"model.summary()","89d2edf8":"opt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\n# distribution\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n# train the network\nprint(\"[INFO] training network...\")","931f0c7f":"print(len(x_train))","f49a5e62":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) \/\/ BS,\n    epochs=EPOCHS\n    )","01f9cead":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","96c14406":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Accuracy: {scores[1]*100} Loss: {scores[0]}\")\nprint(\"CNN Error: %.2f%%\" % (100- (scores[1]*100) ) )","980c34f7":"import numpy as np\ny_pred = model.predict(x_test)\nacc = sum([np.argmax(y_test[i])==np.argmax(y_pred[i]) for i in range(10000)])\/10000\nprint(acc*100)","614f252f":"test_image_list, test_image_fileName_list = [], []\ntry:\n    print(\"[INFO] Loading Test Images\")\n    test_image_directory = '..\/input\/test\/test'\n    root_dir = listdir(test_image_directory)\n    for image in root_dir:\n        test_image_list.append(convert_image_to_array(f\"{test_image_directory}\/{image}\"))\n        test_image_fileName_list.append(image)\n    print(\"[INFO] Image loading complete\")\nexcept Exception as e:\n    print(e)","8aabe72b":"np_test_image_list = np.array(test_image_list, dtype=np.float16) \/ 225.0","65e9de7a":"print(f\"[INFO] Test Image Shape : {np_test_image_list.shape}\")","867c9ea4":"predictions = []\nfor arr in np_test_image_list:\n    arr = np.expand_dims(arr, axis=0)\n    prediction_output = label_binarizer.inverse_transform(model.predict(arr))\n    predictions.append(prediction_output[0])","6d97c626":"print(\"[INFO] Creating pandas dataframe\")\nsubmission_data = {\"ImageID\":test_image_fileName_list,\"Category\":predictions}\nsubmission_data_frame = pd.DataFrame(submission_data)","111831ef":"submission_data_frame","08357842":"print(\"[INFO] Saving Predicition to CSV\")\nsubmission_data_frame.to_csv('sample-submission.csv',columns=[\"ImageID\",\"Category\"], index = False)","1636c547":"Test Images"}}