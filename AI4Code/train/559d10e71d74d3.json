{"cell_type":{"7507af55":"code","8df0d6c0":"code","fdf7f3a1":"code","2319d077":"code","6535d118":"code","440162d6":"code","176c8ff9":"code","e0d82f82":"code","0e344c72":"code","a0c4c4b0":"code","7e0ed27f":"code","a16b092b":"code","eca432f5":"code","6186fd89":"code","abecd19c":"code","4af9a0b2":"code","209629b4":"code","8d27854f":"code","cd0e5fde":"markdown","1b0b170d":"markdown","5ce595ea":"markdown","99a9a1a4":"markdown","04d676ea":"markdown","12351926":"markdown","2c00068b":"markdown","90b689e9":"markdown","b6468b0e":"markdown","a9bae676":"markdown","f06d6f4c":"markdown","25ab8237":"markdown"},"source":{"7507af55":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier\nfrom sklearn import metrics\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n\n%matplotlib inline","8df0d6c0":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","fdf7f3a1":"df.head()","2319d077":"df.isnull().sum()\n#skip test","6535d118":"df.describe()","440162d6":"sns.countplot(x='Class', data=df)\nprint('Non-fraud: {}%'.format(round(df.Class.value_counts()[0]\/len(df)*100.0,2)))\nprint('Fraud: {}%'.format(round(df.Class.value_counts()[1]\/len(df)*100.0,2)))","176c8ff9":"df.Class.value_counts()","e0d82f82":"#Standardize features by removing the mean and scaling to unit variance\nfrom sklearn.preprocessing import StandardScaler\n\ndf['normAmount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\ndf = df.drop(['Time','Amount'],axis=1)\n#'Time' and 'Amount' will have no effect on further data training\ndf.head()","0e344c72":"X = df.iloc[: , df.columns!='Class']\ny = df['Class']\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size= 0.3, random_state=42)","a0c4c4b0":"clf = LogisticRegression()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test.values.ravel(),y_pred)\nroc_auc = metrics.auc(fpr,tpr)\n\n# Plot ROC\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","7e0ed27f":"result = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(result)\nresult1 = classification_report(y_test, y_pred)\nprint(\"Classification Report:\",)\nprint (result1)\nresult2 = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\",result2)","a16b092b":"smote = SMOTE(random_state=2)\nX_train_s, y_train_s = smote.fit_sample(X_train, y_train.ravel())\n\nsns.countplot(x = y_train_s, data = df)","eca432f5":"clf = LogisticRegression()\nclf.fit(X_train_s, y_train_s)\npred_y = clf.predict(X_test)\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test.values.ravel(),pred_y)\nroc_auc = metrics.auc(fpr,tpr)\n\n# Plot ROC\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","6186fd89":"result = confusion_matrix(y_test, pred_y)\nprint(\"Confusion Matrix:\")\nprint(result)\nresult1 = classification_report(y_test, pred_y)\nprint(\"Classification Report:\",)\nprint (result1)\nresult2 = accuracy_score(y_test, pred_y)\nprint(\"Accuracy:\",result2)","abecd19c":"rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, min_samples_leaf=1,\n           max_features='auto', max_leaf_nodes=None,\n           oob_score=True, n_jobs=-1, random_state=42)\n\nrf.fit(X_train_s, y_train_s)\ny_pred = rf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","4af9a0b2":"feature_importances = rf.feature_importances_\n\nfeature_importances_df = pd.DataFrame({'features':list(X_train),\n                                      'feature_importances':feature_importances})\n\nfeature_importances_df.sort_values('feature_importances', ascending=False)","209629b4":"# Initialize CatBoostRegressor\nmodel = CatBoostClassifier(iterations=10,\n                        learning_rate=1,\n                        depth=5)\n# Fit model\nmodel.fit(X_train, y_train)\n# Get predictions\npreds = model.predict(X_test)","8d27854f":"result = confusion_matrix(y_test, preds)\nprint(\"Confusion Matrix:\")\nprint(result)\nresult1 = classification_report(y_test, preds)\nprint(\"Classification Report:\",)\nprint (result1)\nresult2 = accuracy_score(y_test, preds)\nprint(\"Accuracy:\",result2)","cd0e5fde":"# Logistic regression on balanced data","1b0b170d":"Recall did grow, but precision turned out to be too small, our model will classify a large number of non-fraudulent transactions as fraudulent. This Is a big problem for banks and this model will not suit us.","5ce595ea":"You can see that the Random Forests show significant reacall and preicision, much better than the regression.","99a9a1a4":"# Classification with a random forest","04d676ea":"CatBoost shows slightly less results than Random Forest, so I choose Random Forest","12351926":"You can observe not a particularly good model. Since the recall is quite low","2c00068b":"## Fraudulent transactions take place when a person loses a bank card when it is stolen, when bankers leak bank customer data online, or because of fraudulent actions, the client himself provides his data to crooks","90b689e9":"We can also see that the most influential features were V14 and V10","b6468b0e":"## Let's also check the CatBoost method","a9bae676":"We may see a great imbalance in classes, for some models this may be a significant problem ","f06d6f4c":"# Logistic regression on unbalanced data\n","25ab8237":"# Balancing the data using the SMOTE method"}}