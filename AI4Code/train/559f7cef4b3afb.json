{"cell_type":{"1431c9ea":"code","e0d4da8a":"code","eea3225c":"code","3a6a5a71":"code","d6f472ae":"code","ab650b1f":"code","d1ade981":"code","541803a0":"code","611b5e01":"code","f5d60da8":"markdown"},"source":{"1431c9ea":"import os\nimport gc\nimport pandas as pd\n%matplotlib inline\n\nimport catboost\nprint(catboost.__version__)\nfrom catboost import CatBoostClassifier, Pool","e0d4da8a":"# Loading data\n\ntrain1 = pd.read_csv(\"\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/jigsaw-toxic-comment-train.csv\")[['comment_text', 'toxic']]\ntrain1['lang'] = 'en'\n\nlang = ['es', 'fr', 'pt', 'ru', 'it', 'tr']\nfor lan in lang:\n    train_ = pd.read_csv(f'\/kaggle\/input\/jigsaw-train-multilingual-coments-google-api\/jigsaw-toxic-comment-train-google-{lan}-cleaned.csv')\n    train_['lang'] = lan\n    train1 = train1.append(train_[['comment_text', 'lang', 'toxic']], ignore_index=True)\n\ntrain = train1.sample(n=300000).reset_index(drop=True)\ndel train1 \ngc.collect()","eea3225c":"test = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/test.csv')\ntest.rename(columns={'content': 'comment_text'}, inplace=True)\n\nsubm = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/sample_submission.csv')\n\nval = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/validation.csv')[['comment_text', 'lang', 'toxic']]","3a6a5a71":"train['comment_text'].fillna(\"\", inplace=True)\ntest['comment_text'].fillna(\"\", inplace=True)\nval['comment_text'].fillna(\"\", inplace=True)","d6f472ae":"# Creating pool objects\n\ntrain_pool = Pool(\n    train.drop(columns='toxic'), label=train['toxic'], \n    cat_features=['lang'],\n    text_features=['comment_text'],\n)\n\nvalidation_pool = Pool(\n    val.drop(columns='toxic'), label=val['toxic'], \n    cat_features=['lang'],\n    text_features=['comment_text'],\n)\n\ntest_pool = Pool(\n    test,\n    cat_features=['lang'],\n    text_features=['comment_text'],\n)","ab650b1f":"# Setting the params\n\nclf_params = {\n     'learning_rate': 0.07688199728727341,\n     'depth': 6,\n     'num_trees': 2000,\n     'random_strength': 3,\n     'bagging_temperature': 1.02,\n     'eval_metric': 'AUC',\n     'random_seed': 42,\n    #  'logging_level': 'Silent',\n     'task_type': 'GPU',\n     'grow_policy': 'Lossguide',\n     'text_processing': {\n        \"tokenizers\" : [{\n            'tokenizer_id': 'Space',\n            'delimiter': ' ',\n            'separator_type': 'ByDelimiter',\n        },{\n            'tokenizer_id': 'Sense',\n            'separator_type': 'BySense',\n        }],\n        \n        \"dictionaries\" : [{\n            'dictionary_id': 'Word',\n            'max_dictionary_size': '50000',\n            \"occurrence_lower_bound\" : \"3\",\n            'gram_order': '1',\n        },{\n            'dictionary_id': 'BiGram',\n            'max_dictionary_size': '50000',\n            \"occurrence_lower_bound\" : \"3\",\n            'gram_order': '2',\n        },{\n            'dictionary_id': 'TriGram',\n            'token_level_type': 'Letter',\n            'max_dictionary_size': '50000',\n            \"occurrence_lower_bound\" : \"3\",\n            'gram_order': '3',\n        }],\n\n        \"feature_processing\" : {\n            \"default\" : [{\n                \"dictionaries_names\" : [\"Word\", \"BiGram\", \"TriGram\"],\n                \"feature_calcers\" : [\"BoW\", \"NaiveBayes\", \"BM25\"],\n                \"tokenizers_names\" : [\"Space\", \"Sense\"]\n            },{\n                \"dictionaries_names\" : [\"Word\", \"BiGram\"],\n                \"feature_calcers\" : [\"BoW\", \"BM25\"],\n                \"tokenizers_names\" : [\"Sense\"]\n            },{\n                \"dictionaries_names\" : [\"Word\", \"TriGram\"],\n                \"feature_calcers\" : [\"NaiveBayes\", \"BM25\"],\n                \"tokenizers_names\" : [\"Sense\"]\n            },{\n                \"dictionaries_names\" : [\"Word\"],\n                \"feature_calcers\" : [\"BoW\"],\n                \"tokenizers_names\" : [\"Space\"]\n            }],\n        }\n    }\n}","d1ade981":"# Fitting\n\nm = CatBoostClassifier(**clf_params)\nm.fit(train_pool, eval_set=validation_pool, verbose=100, plot=True)","541803a0":"# Predicting\n\npreds = m.predict_proba(test_pool)[:, 1]","611b5e01":"submission = pd.DataFrame({'id': subm['id'].values, 'toxic': preds})\nsubmission.to_csv('submission.csv', index=False)\nsubmission","f5d60da8":"# Gradient boosting decision trees are using here\n\nUpvote if you like Gradient boosting decision trees.\n\n* CatBoost library allows you to work with text data and preprocess it. \n* And it works rather fast. \n* CatBoost is perfect for handling with categorical data.\n\nIn my notebook I select hyperparameters. Fork right now and try your best in searching for params ([grid search](https:\/\/catboost.ai\/docs\/concepts\/python-reference_catboost_grid_search.html) may help you)."}}