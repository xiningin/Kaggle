{"cell_type":{"8471680c":"code","94340d1f":"code","04f3bf54":"code","a2bd32be":"code","6cc0b183":"code","9e18db57":"code","49d73021":"code","26f81c36":"code","8b66cf5e":"code","d35e9622":"code","49be7977":"code","8ff39960":"markdown"},"source":{"8471680c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94340d1f":"data = pd.read_csv(\"\/kaggle\/input\/test-file\/tested.csv\")\ndata","04f3bf54":"# When data.isna().sum() is called,\n# there are missing samples.\n# Too many missing Cabin samples\ndata = data.drop(columns=[\"Cabin\", \"Name\"])\nfor feature in data.keys():\n    if data[feature].isna().sum() > 0:\n        for idx, sample in enumerate(np.where(data[feature].isna(), True, False)):\n            if not sample:\n                data = data.replace({feature: np.nan}, data[feature].mean())","a2bd32be":"# No more missing samples\ndata.isna().sum()","6cc0b183":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\ntransformer = LabelEncoder()\n\n# Predicting feature (y) is Survived\nfor feature in data.keys():\n    if data[feature].dtype not in [\"int64\", \"float64\"]:\n        data[feature] = transformer.fit_transform(data[feature])\n   \nX = data.drop(columns=[\"Survived\"])\ny = data[\"Survived\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\nparam_grid = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 25, 50]}\ngrid = GridSearchCV(estimator=SVC(), param_grid=param_grid)\ngrid.fit(X_train, y_train)","9e18db57":"grid.best_params_","49d73021":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\npipe = Pipeline([(\"scaler\", StandardScaler()), (\"svc\", SVC(C=1, kernel=\"linear\"))])\npipe.fit(X_train, y_train)","26f81c36":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","8b66cf5e":"sig_features = data.corr()\nsig_features.style.background_gradient(cmap='coolwarm')","d35e9622":"y_pred = pipe.predict(X_test)\n\nfor i in range(len(y_test)):\n    print(f\"Actual: {y_test[i]}; Predicted: {y_pred[i]}\")","49be7977":"from sklearn.metrics import accuracy_score\n\nacc = accuracy_score(y_test, y_pred)\nacc","8ff39960":"### Create a correlation matrix to view significant features"}}