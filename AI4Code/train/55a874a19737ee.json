{"cell_type":{"4ef6ab84":"code","668849a0":"code","ebd076cf":"code","25b2cfbf":"code","944a5339":"code","5bdfc039":"code","7a202769":"code","1f9a143c":"code","243e9216":"code","91b492bc":"code","57f585fe":"code","cdb8ae6a":"code","8de1d657":"code","6344bfaa":"code","9be0b542":"code","43c44743":"code","8d2d600e":"code","61ee7053":"code","1697c802":"code","f93d7d00":"code","2bb31481":"code","de425f5d":"code","7f697546":"code","9b61b84d":"code","538a5156":"code","0ab93dfe":"markdown","25bf73c1":"markdown","c9b0fb0e":"markdown","467e92ce":"markdown","7c89cc5d":"markdown","8aa163fd":"markdown","0fa6813f":"markdown","d13554ef":"markdown"},"source":{"4ef6ab84":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\n\nimport tensorflow as tf\nimport keras.backend as K\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Concatenate\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers.merge import concatenate\n\nfrom sklearn.model_selection import train_test_split","668849a0":"PATH = '\/kaggle\/input\/jigsaw-toxic-severity-rating\/'\nvalid_data = pd.read_csv(PATH + 'validation_data.csv')\ncomment_data = pd.read_csv(PATH + 'comments_to_score.csv')\nsub = pd.read_csv(PATH + 'sample_submission.csv')","ebd076cf":"valid_data.sort_values('worker', inplace=True)\nvalid_data.head()","25b2cfbf":"valid_data.tail()","944a5339":"valid_data['less_toxic'][0]","5bdfc039":"#df['less_toxic'][-3:]","7a202769":"#df.drop_duplicates(['less_toxic'], ignore_index=True)","1f9a143c":"df = valid_data.copy()\ndf['target'] = 0.9","243e9216":"MAX_TEXT_LENGTH = 1024*2\nMAX_FEATURES = 512\nMAX_LENGTH = MAX_FEATURES","91b492bc":"less_toxic = df['less_toxic']\nmore_toxic = df['more_toxic']\ntoxic_text = less_toxic.append(more_toxic)\n\ntarget = df['target']","57f585fe":"# tokenize the sentences\ntokenizer = Tokenizer(lower=True)\ntokenizer.fit_on_texts(toxic_text)\n\nless_text_seq = tokenizer.texts_to_sequences(less_toxic)\nmore_text_seq = tokenizer.texts_to_sequences(more_toxic)\n\n# pad the sequences\nless_text_vec = pad_sequences(less_text_seq, maxlen=MAX_LENGTH)\nmore_text_vec = pad_sequences(more_text_seq, maxlen=MAX_LENGTH)\n\nless_text_vec.shape, more_text_vec.shape","cdb8ae6a":"print('Number of Tokens:', len(tokenizer.word_index))\nprint(\"Max Token Index:\", less_text_vec.max())\nprint(\"Max Token Index:\", more_text_vec.max(), \"\\n\")","8de1d657":"# https:\/\/github.com\/keras-team\/keras\/issues\/910#issuecomment-218748553\ndef margin_ranking_loss(y_true, y_pred, margin=0.9): # change to 1.0?  makes more sense for normalized cosine distance [-1,1]\n    ''' This only works when y_true and y_pred are stacked in a way so that\n    the positive examples take up the first n\/2 rows, and the corresponding negative samples\n    take up the last n\/2 rows.\n\n    y_true corresponds to scores (e.g., inner products)\n    y_pred corresponds is a vector of ones or zeros (denoting positive or negative sample)\n    '''\n    \n    #y_true, y_pred = y_true.astype('float'), y_pred.astype('float')\n    n = len(y_true)\/\/2\n    signed = y_pred * y_true # make y_true part of the computational graph\n    pos = signed[:n]\n    neg = signed[n:]\n    # negative samples are multiplied by -1, so that the sign in the rankSVM objective is flipped\n    hinge_loss = K.relu( margin - pos - neg )\n    loss_vec = K.concatenate([hinge_loss, hinge_loss], axis=0) \n    return loss_vec\n","6344bfaa":"x1_input = Input(shape=(MAX_LENGTH,))\nx2_input = Input(shape=(MAX_LENGTH,))\n\nx1 = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100,)(x1_input)\nx2 = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100,)(x2_input)\n\nx = concatenate([x1, x2])\n\nx = LSTM(units=128, return_sequences=True)(x)\nx = Dropout(0.2)(x)\n\nx = LSTM(units=64, return_sequences=False)(x)\nx = Dropout(0.2)(x)\n\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.25)(x)\n\noutputs = Dense(1)(x)\n\nmodel = Model(inputs=[x1_input, x2_input], outputs=outputs)\n\nmodel.compile(loss='mse', optimizer='adam') #, metrics=[margin_ranking_loss])","9be0b542":"tf.keras.utils.plot_model(\n    model,\n    to_file=\"model.png\",\n    show_shapes=False,\n    show_dtype=False,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96,\n    layer_range=None,\n)","43c44743":"# Model hyperparameters \nBATCH_SIZE = 256\nEPOCHS = 10\n\n# model drive\ncp_file = '.\/lstm_model.h5'\ncp = ModelCheckpoint(cp_file, \n                     monitor='loss', \n                     verbose=0, \n                     save_best_only=True, mode='min')\n\nes = EarlyStopping(patience=5, \n                   monitor='loss', \n                   #restore_best_weights=True, \n                   mode='min', \n                   verbose=1)\n\n# model train\nhistory = model.fit([less_text_vec, more_text_vec], target,\n                    batch_size=BATCH_SIZE, \n                    epochs=EPOCHS,\n                    validation_split=0.1,\n                    callbacks=[es, cp],\n                    shuffle=True,\n                    )","8d2d600e":"#pd.DataFrame(history.history).plot(figsize=(12, 6));","61ee7053":"test_ids = comment_data['comment_id']\ntest_text = comment_data['text']\n\ntest_text_seq = tokenizer.texts_to_sequences(test_text)\n\n# pad the sequences\ntest_text_vec = pad_sequences(test_text_seq, maxlen=MAX_LENGTH)","1697c802":"test_length = len(test_text_vec)\n\npreds0 = model.predict([test_text_vec, test_text_vec])\npreds1 = model.predict([test_text_vec, more_text_vec[:test_length]])\npreds2 = model.predict([less_text_vec[:test_length], test_text_vec])","f93d7d00":"plt.hist(preds0, label='test-test');\nplt.hist(preds1, label='test-more');\nplt.hist(preds2, label='less-test');\n\nplt.legend();","2bb31481":"preds = np.mean([preds0, preds1, preds2], axis=0)\nplt.hist(preds, label='test-less');","de425f5d":"print(f\"Total Predictiions: {preds.shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds0).shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds1).shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds2).shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","7f697546":"sub['score'] = preds0\nsub['score'] = sub['score'].rank(method='first')","9b61b84d":"sub","538a5156":"sub.to_csv('submission.csv', index=False)","0ab93dfe":"## Model","25bf73c1":"## Loss Metrics ","c9b0fb0e":"## Data Wrangling","467e92ce":"### Text Preprocessing","7c89cc5d":"**<center>The Notebook still under modification, Stay Tuned.<br><span style='color:red'>UpVote<\/span> if you found it interesting, and i am looking for your feedback<\/center>**","8aa163fd":"## Introduction","0fa6813f":"## Prediction","d13554ef":"## Data Preprocessing"}}