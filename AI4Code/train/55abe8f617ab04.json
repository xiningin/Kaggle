{"cell_type":{"d0223ee7":"code","71ed3664":"code","7bb8dc78":"code","0d248d6f":"code","590d48d2":"code","52fa0ffe":"code","221d36ce":"code","632f9df8":"code","7800429b":"code","e04613cc":"code","13b593a7":"code","9b16a11c":"code","36f91f97":"code","87a5eea4":"code","5fb9361c":"markdown","a069aadd":"markdown","0ec9c851":"markdown","e26399e6":"markdown","80af140a":"markdown","0c6702d4":"markdown","73817550":"markdown","8e72f12d":"markdown","ebcfc235":"markdown","1fc8f0d9":"markdown","920b612d":"markdown","cd6d5b1b":"markdown","10add655":"markdown","1cf7826b":"markdown"},"source":{"d0223ee7":"import mxnet as mx\nimport numpy as np\nimport pandas as pd\nimport os, random, sys, time, cv2\nimport matplotlib.pyplot as plt\nfrom mxnet import gluon, nd, image, init, autograd\nfrom mxnet.gluon import data as gdata, model_zoo, nn, loss as gloss, utils as gutils\nimport gluoncv\n\nmx.random.seed(1024)\nsize = 320\nbatch_size = 16\nepoch = 25\nnum_workers = 0 if sys.platform.startswith('win32') else 4","71ed3664":"train = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/test.csv')\n\nimages = list(train['image_id'].values)\nlabels = list(train[['healthy', 'multiple_diseases', 'rust', 'scab']].values)\n\ntest_images = list(test['image_id'].values)\ntrain_dir = '..\/input\/plant-pathology-2020-fgvc7\/images'\n\nassert len(labels)==len(images), 'train_label, train_ids lenth different'\nsample_num = len(images)\nids = range(0, sample_num)\n\nval_percent = 0.1\nval_num = int(len(images)*val_percent)\nval_ids = random.sample(range(0, sample_num), val_num)\ntrain_ids = [id for id in ids if id not in val_ids]\nassert len(train_ids)==sample_num-val_num, 'num wrong!'\ntrain_num = len(train_ids)\n\nval_images, val_labels = [None] * val_num, [None] * val_num\ntrain_images , train_labels = [None] * train_num, [None] * train_num\n\nfor idx, value in enumerate(val_ids):\n    val_images[idx] = images[value]\n    val_labels[idx] = labels[value]\n    \nfor idx, value in enumerate(train_ids):\n    train_images[idx] = images[value]\n    train_labels[idx] = labels[value]\n\nprint('Train data: {}, val data: {}, test data: {}.'.format(len(train_images), len(val_images), len(test_images)))","7bb8dc78":"def read_images(root=train_dir, is_train=True):\n    if is_train==True:\n        data_images = train_images\n        data_labels = train_labels\n        data_num = len(data_images)\n        data_type = 'Train dataset'\n    elif is_train==False:\n        data_images = val_images\n        data_labels = val_labels\n        data_num = len(data_images)\n        data_type = 'Val dataset'\n    elif is_train=='Test':\n        data_images = test_images\n        data_num = len(data_images)\n        data_labels = [None] * data_num\n        data_type = 'Test dataset'\n    features, labels = nd.zeros(shape=(data_num, size, size, 3)), nd.zeros(shape=(data_num, 4))\n    for i in range(data_num):\n        features[i] = image.imresize(image.imread(os.path.join(root, data_images[i] + '.jpg')), size, size)\n        labels[i] = data_labels[i]\n    print('{} read finished'.format(data_type))\n    return features, labels\n\nclass PlantDataset(gdata.Dataset):\n    def __init__(self, is_train, train_dir):\n#         self.rgb_mean = nd.array([0.485, 0.456, 0.406])\n#         self.rgb_std = nd.array([0.229, 0.224, 0.225])\n        features, labels = read_images(root=train_dir, is_train=is_train)\n        self.features = [self.normalize_image(feature) for feature in features]\n        self.labels = labels\n        print('read ' + str(len(self.features)) + ' examples')\n\n    def normalize_image(self, img):\n#         return (img.astype('float32') \/ 255 - self.rgb_mean) \/ self.rgb_std\n        return img.astype('float32') \/ 255 \n\n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]\n\n    def __len__(self):\n        return len(self.features)","0d248d6f":"plant_train = PlantDataset(True, train_dir)\nplant_val = PlantDataset(False, train_dir)\nplant_test = PlantDataset('Test', train_dir)\n\njitter_param = 0.4\nlighting_param = 0.1\nflip_aug = gdata.vision.transforms.Compose([\n    gdata.vision.transforms.RandomFlipLeftRight(),\n    gdata.vision.transforms.RandomFlipTopBottom(),\n    gdata.vision.transforms.RandomColorJitter(brightness=jitter_param, contrast=jitter_param,\n                                 saturation=jitter_param),\n    gdata.vision.transforms.RandomLighting(lighting_param),\n    gdata.vision.transforms.ToTensor(),\n    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\nno_aug = gdata.vision.transforms.Compose([\n    gdata.vision.transforms.ToTensor(),\n    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ntrain_iter = gdata.DataLoader(plant_train.transform_first(flip_aug), batch_size, shuffle=True,\n                             num_workers=num_workers, last_batch='keep')\nval_iter = gdata.DataLoader(plant_val.transform_first(no_aug), batch_size,\n                             num_workers=num_workers, last_batch='keep')\ntest_iter = gdata.DataLoader(plant_test.transform_first(no_aug), batch_size,\n                             num_workers=num_workers, last_batch='keep')","590d48d2":"def get_net(netname, ctx):\n    if netname == 'densenet':\n        net = model_zoo.vision.densenet161(pretrained=True).features\n    elif netname == 'mobilenet':\n        net = model_zoo.vision.mobilenet_v2_1_0(pretrained=True).features\n    elif netname == 'seresnext':\n        net = gluoncv.model_zoo.get_model('SE_ResNext101_64x4d', pretrained=True).features\n    elif netname == 'resnext':\n        net = gluoncv.model_zoo.get_model('ResNext101_64x4d', pretrained=True).features[:-1]\n        net.add(CBAM(2048, 64))\n        net[-1].initialize(init.Xavier())\n    net.add(nn.Dense(512), nn.Dropout(0.25), nn.Dense(4))\n    net[-3:].initialize(init.Xavier())\n    net.collect_params().reset_ctx(ctx)\n    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': 0.00002, 'wd': 1e-3})\n    net.hybridize()\n    return net, trainer\n\ndef cross_entropy(y_hat, y):\n    y_hat = y_hat.log()\n    return -y * y_hat\n\ndef softmax_to_onehot(x, axis=1, ctx=mx.gpu(0)):\n    a = nd.argmax(x, axis=1)\n    b = nd.zeros(shape=(x.shape[0], x.shape[1]), ctx=ctx)\n    b[nd.arange(len(a)), a] = 1.\n    return b\n    \ndef evaluate_accuracy(data_iter, net, ctx):\n    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n    if isinstance(ctx, mx.Context):\n        ctx = [ctx]\n    acc_sum, n = nd.array([0]), 0\n    for batch in data_iter:\n        features, labels = batch\n        if labels.dtype != features.dtype:\n            labels = labels.astype(features.dtype)\n        Xs = gutils.split_and_load(features, ctx)\n        ys = gutils.split_and_load(labels, ctx)\n        for X, y in zip(Xs, ys):\n            y = y.astype('float32')\n            acc_sum += (softmax_to_onehot(net(X), axis=1, ctx=ctx[0]) == y).sum().copyto(mx.cpu())\n            n += y.size\n        acc_sum.wait_to_read()\n    return acc_sum.asscalar() \/ n\n\ndef train(train_iter, val_iter, net, loss, trainer, ctx, num_epochs, verbose=0):\n    \"\"\"Train and evaluate a model.\"\"\"\n    print('training {} on {}'.format(net.name, ctx))\n    if isinstance(ctx, mx.Context):\n        ctx = [ctx]\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n        for i, batch in enumerate(train_iter):\n            features, labels = batch\n            batch_size = features.shape[0]\n            if labels.dtype != features.dtype:\n                labels = labels.astype(features.dtype)\n            Xs = gutils.split_and_load(features, ctx)\n            ys = gutils.split_and_load(labels, ctx)\n            ls = []\n            with autograd.record():\n                y_hats = [nd.softmax(net(X)) for X in Xs]\n                ls = [cross_entropy(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n            for l in ls:\n                l.backward()\n            trainer.step(batch_size)\n            train_l_sum += sum([l.sum().asscalar() for l in ls])\n            n += sum([l.size for l in ls])\n            train_acc_sum += sum([(softmax_to_onehot(y_hat, axis=1, ctx=ctx[0]) == y).sum().asscalar()\n                                 for y_hat, y in zip(y_hats, ys)])\n            m += sum([y.size for y in ys])\n        test_acc = evaluate_accuracy(val_iter, net, ctx[0])\n        \n        if verbose == 0:\n            print('epoch %d\/%d, loss %.4f, train acc %.3f, val acc %.3f, '\n                  'time %.1f sec'\n                  % (epoch + 1, num_epochs, train_l_sum \/ n, train_acc_sum \/ m, test_acc,\n                     time.time() - start))\n        else:\n            if (epoch + 1) % verbose == 0 or epoch == 0:\n                print('epoch %d\/%d, loss %.4f, train acc %.3f, val acc %.3f, '\n                      'time %.1f sec'\n                      % (epoch + 1, num_epochs, train_l_sum \/ n, train_acc_sum \/ m, test_acc,\n                         time.time() - start))\n    print('Train finished')\n    return net","52fa0ffe":"ctx = mx.gpu(0)\ntrain_loss = gloss.SoftmaxCrossEntropyLoss(axis=1, from_logits=True)\nsub_dir = \"..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\"","221d36ce":"def use_mobile_net(epoch=30):\n    preds_mobile = []\n    net_mobile, trainer_mobile = get_net('mobilenet', ctx=mx.gpu(0))\n    net_mobile = train(train_iter, val_iter, net_mobile, train_loss, trainer_mobile, ctx, epoch, verbose=10)\n    for X, _ in test_iter:\n        y_hat_mobile = nd.softmax(net_mobile(X.as_in_context(ctx))).asnumpy()\n        preds_mobile.extend(y_hat_mobile)\n    sub_mobile = pd.read_csv(sub_dir)\n    sub_mobile.loc[:, 'healthy':] = preds_mobile\n    sub_mobile.to_csv('submission_mobile.csv', index=False)\n    sub_mobile.head(5)\n    return y_hat_mobile","632f9df8":"def use_seresnext(epoch=30):\n    preds_seresnext = []\n    net_seresnext, trainer_seresnext = get_net('seresnext', ctx=mx.gpu(0))\n    net_seresnext = train(train_iter, val_iter, net_seresnext, train_loss, trainer_seresnext, ctx, epoch, verbose=5)\n    for X, _ in test_iter:\n        y_hat_seresnext = nd.softmax(net_seresnext(X.as_in_context(ctx))).asnumpy()\n        preds_seresnext.extend(y_hat_seresnext)\n    sub_seresnext = pd.read_csv(sub_dir)\n    sub_seresnext.loc[:, 'healthy':] = preds_seresnext\n    sub_seresnext.to_csv('submission_seresnext.csv', index=False)\n    print(sub_seresnext.head(5))\n    return preds_seresnext","7800429b":"def use_densenet(epoch=30):\n    preds_dense = []\n    net_dense, trainer_dense = get_net('densenet', ctx=mx.gpu(0))\n    net_dense = train(train_iter, val_iter, net_dense, train_loss, trainer_dense, ctx, epoch, verbose=10)\n    for X, _ in test_iter:\n        y_hat_dense = nd.softmax(net_dense(X.as_in_context(ctx))).asnumpy()\n        preds_dense.extend(y_hat_dense)\n    sub_dense = pd.read_csv(sub_dir)\n    sub_dense.loc[:, 'healthy':] = preds_dense\n    sub_dense.to_csv('submission_dense.csv', index=False)\n    print(sub_dense.head(5))\n    return preds_dense","e04613cc":"class CAM(nn.HybridBlock):\n  def __init__(self, num_channels, ratio, **kwargs):\n    super(CAM, self).__init__(**kwargs)\n    with self.name_scope():\n      self.avg_pool = nn.GlobalAvgPool2D()\n      self.max_pool = nn.GlobalMaxPool2D()\n      self.conv1 = nn.Conv2D(num_channels \/\/ ratio, 1, use_bias=False)\n      self.conv2 = nn.Conv2D(num_channels, 1, use_bias=False)\n\n  def hybrid_forward(self, F, X):\n    X_avg = self.avg_pool(X)\n    X_avg = self.conv1(X_avg)\n    X_avg = F.relu(X_avg)\n    X_avg = self.conv2(X_avg)\n\n    X_max = self.max_pool(X)\n    X_max = self.conv1(X_max)\n    X_max = F.relu(X_max)\n    X_max = self.conv2(X_max)\n\n    Y = X_avg + X_max\n    Y = F.sigmoid(Y)\n    return Y\n\n\nclass SAM(nn.HybridBlock):\n  def __init__(self, kernel_size=7, **kwargs):\n    super(SAM, self).__init__(**kwargs)\n    with self.name_scope():\n      self.kernel_size = kernel_size\n      assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n      self.padding = 3 if self.kernel_size == 7 else 1\n\n      self.conv = nn.Conv2D(1, kernel_size=self.kernel_size, padding=self.padding, use_bias=False)\n\n  def hybrid_forward(self, F, X):\n    X_avg = F.mean(X, axis=1, keepdims=True)\n    X_max = F.max(X, axis=1, keepdims=True)\n    Y = F.concat(X_avg, X_max, dim=1)\n    Y = self.conv(Y)\n    Y = F.sigmoid(Y)\n    return Y\n\n\nclass CBAM(nn.HybridBlock):\n  def __init__(self, num_channels, ratio, **kwargs):\n    super(CBAM, self).__init__(**kwargs)\n    with self.name_scope():\n      self.num_channels = num_channels\n      self.ratio = ratio\n      self.cam = CAM(self.num_channels, self.ratio)\n      self.sam = SAM()\n\n  def hybrid_forward(self, F, X):\n    residual = X\n    Y = F.broadcast_mul(self.cam(X), X)\n    Y = F.broadcast_mul(self.sam(Y), Y)\n    Y = F.relu(Y)\n    return Y + residual","13b593a7":"def use_resnet(epoch=30):\n    preds_res = []\n    net_res, trainer_res = get_net('resnext', ctx=mx.gpu(0))\n    net_res = train(train_iter, val_iter, net_res, train_loss, trainer_res, ctx, epoch, verbose=5)\n    for X, _ in test_iter:\n        y_hat_res = nd.softmax(net_res(X.as_in_context(ctx))).asnumpy()\n        preds_res.extend(y_hat_res)\n    sub_res = pd.read_csv(sub_dir)\n    sub_res.loc[:, 'healthy':] = preds_res\n    sub_res.to_csv('submission_res.csv', index=False)\n    print(sub_res.head(5))\n    return preds_res","9b16a11c":"# preds_mobile = use_mobile_net(epoch)\n# preds_res = use_resnet(epoch)\npreds_seresnext = use_seresnext(epoch)\npreds_dense = use_densenet(epoch)","36f91f97":"def weighted_ensemble(preds_a, preds_b):\n    sub1, sub2, sub3 = pd.read_csv(sub_dir), pd.read_csv(sub_dir), pd.read_csv(sub_dir)\n    pred_1, pred_2, pred_3 = [], [], []\n    for a, b in zip(preds_a, preds_b):\n        pred_1.append(a * 0.25 + b * 0.75)\n        pred_2.append(a * 0.5 + b * 0.5)\n        pred_3.append(a * 0.75 + b * 0.25)\n\n    sub1.loc[:, 'healthy':] = pred_1\n    sub2.loc[:, 'healthy':] = pred_2\n    sub3.loc[:, 'healthy':] = pred_3\n    sub1.to_csv('submission1.csv', index=False)\n    sub2.to_csv('submission2.csv', index=False)\n    sub3.to_csv('submission3.csv', index=False)\n\nweighted_ensemble(preds_seresnext, preds_dense)","87a5eea4":"def average_ensemble_three(preds_a, preds_b, preds_c):\n    sub = pd.read_csv(sub_dir)\n    pred = []\n    for a, b, c in zip(preds_a, preds_b, preds_c):\n        pred.append((a + b + c) \/ 3.)\n    sub.loc[:, 'healthy':] = pred\n    sub.to_csv('submission.csv', index=False)\n    print(sub.head())\n\ndef average_ensemble_two(preds_a, preds_b):\n    sub = pd.read_csv(sub_dir)\n    pred = []\n    for a, b in zip(preds_a, preds_b):\n        pred.append((a + b) \/ 2.)\n    sub.loc[:, 'healthy':] = pred\n    sub.to_csv('submission.csv', index=False)\n    print(sub.head(5))\n    \n# average_ensemble_three(preds_res, preds_seresnext, preds_dense)\n# average_ensemble_two(preds_seresnext, preds_dense)","5fb9361c":"## Load data ##","a069aadd":"## Import everything ##","0ec9c851":"## Result ensemble ##","e26399e6":"## Augmention and create data iterator ##","80af140a":"### Method 1 ###","0c6702d4":"## Train and predict","73817550":"## Define models","8e72f12d":"## Define more function ##","ebcfc235":"### SE_ResNext","1fc8f0d9":"### ResNext_CBAM","920b612d":"### DenseNet","cd6d5b1b":"### Method 2 ###","10add655":"## Create dataset class ##","1cf7826b":"### MobileNet"}}