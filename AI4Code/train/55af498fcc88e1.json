{"cell_type":{"0ffedacd":"code","8bd02fd5":"code","e8e6d4bf":"code","d8f8eeca":"code","359df55d":"code","f0ea8daf":"code","f8f68a92":"code","ef26bd1c":"code","f332ea64":"code","d50e7c87":"code","c748621c":"code","e863a07c":"code","004f7ef3":"code","54daa3f2":"code","c81d9a01":"markdown","73151fac":"markdown","e4bf7cc4":"markdown","626fd85d":"markdown","1e0aecaa":"markdown","fdf96eae":"markdown","84d5317f":"markdown"},"source":{"0ffedacd":"import pandas as pd \nimport numpy as np\ndt = pd.read_csv(\"\/kaggle\/input\/simulated-bank-customer-data\/CUST_ASSET_DATA.csv\")\nind1 = dt[dt[\"AGE\"].isna()].index\nind2 = dt[dt[\"BRANCH_DIST\"].isna()].index\nind = pd.Series((list(ind1)+list(ind2))).unique()\ndt = dt.drop(index = ind)\n# preprocessing of data","8bd02fd5":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import r2_score\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dropout","e8e6d4bf":"columns = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\",\n           \"INTERACT_AMT_A\",\"INTERACT_AMT_B\",\"TOTAL_ASSET_X\",\"TOTAL_ASSET_y\"]\n\ndt2 = pd.DataFrame(np.array(dt[[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_1\",\"SECURITY_ACC_1\",\"INTERACT_AMT_A_1\",\n          \"INTERACT_AMT_B_1\",\"TOTAL_ASSET_1\",\"TOTAL_ASSET_2\"]]),columns = columns)\n\nfor i in range(2,12):\n    dt1 = pd.DataFrame(np.array(dt[[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n                           \"ACTIVE_WEB_CUST_\"+str(i),\"SECURITY_ACC_\"+str(i),\n                           \"INTERACT_AMT_A_\"+str(i),\"INTERACT_AMT_B_\"+str(i),\n                           \"TOTAL_ASSET_\"+str(i),\"TOTAL_ASSET_\"+str(i+1)]])\n                       ,columns = columns)\n    Train_dt = pd.concat([dt2,dt1])\n\nTest_dt = pd.DataFrame(np.array(dt[[\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\n          \"ACTIVE_WEB_CUST_12\",\"SECURITY_ACC_12\",\"INTERACT_AMT_A_12\",\n          \"INTERACT_AMT_B_12\",\"TOTAL_ASSET_12\",\"TOTAL_ASSET_13\"]]),columns = columns)\nTrain_dt","d8f8eeca":"Test_dt","359df55d":"nominal = [\"AGE\",\"GENDER\",\"CITY\",\"BRANCH_DIST\",\"ACTIVE_WEB_CUST\",\"SECURITY_ACC\"]\n\nTrain_dt = Train_dt.copy()\nfor label in nominal:\n    Train_dt[label] = LabelEncoder().fit_transform(Train_dt[label])\n    \nTest_dt = Test_dt.copy()\nfor label in nominal:\n    Test_dt[label] = LabelEncoder().fit_transform(Test_dt[label])","f0ea8daf":"X_train, y_train,X_test,y_test = Train_dt.iloc[:,0:9],Train_dt.iloc[:,9:10],Test_dt.iloc[:,0:9],Test_dt.iloc[:,9:10]\n\nX_train=np.array(X_train).reshape(-1,9)\nX_test=np.array(X_test).reshape(-1,9)\ny_train=np.array(y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\nimport tensorflow as tf\nX_train = tf.constant(X_train, tf.float32)\nX_test = tf.constant(X_test, tf.float32)\ny_train = tf.constant(y_train, tf.float32)\ny_test = tf.constant(y_test, tf.float32)","f8f68a92":"#Plotting acc and loss plot.\nimport keras\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = {'batch':[], 'epoch':[]}\n        self.accuracy = {'batch':[], 'epoch':[]}\n        self.val_loss = {'batch':[], 'epoch':[]}\n        self.val_acc = {'batch':[], 'epoch':[]}\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses['batch'].append(logs.get('loss'))\n        self.accuracy['batch'].append(logs.get('accuracy'))\n        self.val_loss['batch'].append(logs.get('val_loss'))\n        self.val_acc['batch'].append(logs.get('val_accuracy'))\n\n    def on_epoch_end(self, batch, logs={}):\n        self.losses['epoch'].append(logs.get('loss'))\n        self.accuracy['epoch'].append(logs.get('accuracy'))\n        self.val_loss['epoch'].append(logs.get('val_loss'))\n        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n\n    def loss_plot(self, loss_type):\n        iters = range(len(self.losses[loss_type]))\n        # loss\n        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n        if loss_type == 'epoch':\n            # val_loss\n            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n        plt.grid(True)\n        plt.xlabel(loss_type)\n        plt.ylabel(\"loss\")\n        plt.legend(loc=\"upper right\")\n        plt.show()","ef26bd1c":"ann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nhistory = LossHistory() # call the class we built \nann.fit(X_train, y_train, epochs=300, batch_size=8000, \n        validation_data=(X_test, y_test),callbacks=[history],\n        verbose=1, shuffle=False)","f332ea64":"history.loss_plot('epoch')","d50e7c87":"y_pred_test = ann.predict(X_test)\ny_train_pred =ann.predict(X_train)\nprint(\"The R2 score on the ANNTrain set is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred)))\nprint(\"The R2 score on the ANNTest set is:\\t{:0.3f}\".format(r2_score(y_test, y_pred_test)))","c748621c":"y_pred = y_pred_test[0:50] \ny_origin = y_test[0:50]\n\nX = range(0,50)\nplt.plot(X,y_pred,label = \"prediction\",color = \"red\")\nplt.plot(X,y_origin,label = \"origin\",color = \"blue\")\nplt.legend()\nplt.xlabel(\"customer\")\nplt.ylabel(\"amount\")\nAnswer = np.array(dt[\"TOTAL_ASSET_13\"]).reshape(-1,1)\nprint(\"MSE of Prediction: \"+str((((np.array(y_pred_test).reshape(-1,1)-Answer)**2)\/len(dt)).sum()))","e863a07c":"ann=Sequential()\nann.add(Dense(64, input_dim=9, activation='relu'))\nann.add(Dense(32, input_dim=64, activation='relu'))\nann.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\nann.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nhistory = LossHistory() # call the class we built \nann.fit(X_train, y_train, epochs=50, batch_size=8000, \n        validation_data=(X_test, y_test),callbacks=[history],\n        verbose=1, shuffle=False)","004f7ef3":"y_pred_test = ann.predict(X_test)\ny_train_pred =ann.predict(X_train)\nprint(\"The R2 score on the ANNTrain set is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred)))\nprint(\"The R2 score on the ANNTest set is:\\t{:0.3f}\".format(r2_score(y_test, y_pred_test)))\nAnswer = np.array(dt[\"TOTAL_ASSET_13\"]).reshape(-1,1)\nprint(\"MSE of Prediction: \"+str((((np.array(y_pred_test).reshape(-1,1)-Answer)**2)\/len(dt)).sum()))","54daa3f2":"ann.save('my_model.h5') # save the model for further research","c81d9a01":"### It seems that loss function converge very quickly ","73151fac":"### Now we are going to construct our model with NN.","e4bf7cc4":"### Now we reset the epoch to 50 time and construct the model again.","626fd85d":"### Since this is a time series data, we hope to use the current data to predict the total assets of the next period. I use current TOTAL_ASSET as one of the features and the next TOTAL_ASSET as y. Using first 11 month as traing data and the 12th month as testing data. Like following picture.\n![123.jpg](attachment:123.jpg)","1e0aecaa":"### Now we got 198026 traing data and 99013 testing data. Before we construct our model, we have to transform our nominal features into nominal codes.","fdf96eae":"## Introduciton:\n### This is the second part of the project. In this part, I am going to construct the prediction model with Neural Network and try to optimize it.","84d5317f":"### After we set the epoch to 50 times, we get the better R-square and MSE. I infer that the model is overfitted if we set the hyper parameter to 200."}}