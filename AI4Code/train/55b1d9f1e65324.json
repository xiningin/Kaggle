{"cell_type":{"ab688eec":"code","68bd5d12":"code","4fd86c58":"code","6d9951ef":"code","4fcca55c":"code","f021cb22":"code","813106a9":"code","44346ccb":"code","cc9c5b4c":"code","11bd73be":"code","601f64af":"code","77488e50":"code","59116e9d":"code","6f654e19":"markdown","4b1364aa":"markdown","b69b3a39":"markdown","c11598fa":"markdown","b6db8e4f":"markdown"},"source":{"ab688eec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","68bd5d12":"import tensorflow as tf\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')","4fd86c58":"(train_X,train_Y),(test_X,test_Y) = keras.datasets.cifar10.load_data()\n\ntrain_X,_,train_Y,_ = train_test_split(train_X,train_Y,stratify=train_Y,test_size=0.6)\ntest_X,_,test_Y,_ =train_test_split(test_X,test_Y,stratify=test_Y,test_size=0.5)\n\nprint(f\"Train dataset shape : {train_X.shape}\")\nprint(f\"Test dataset shape : {test_X.shape}\")","6d9951ef":"train_data = train_X\ntrain_label = train_X\n\ntest_data = test_X\ntest_label = test_X\n\nplt.figure(figsize=(10,8))\nplt.subplot(1,2,1)\nsns.countplot(x=train_Y.reshape(20000,))\n\nplt.subplot(1,2,2)\nsns.countplot(x=test_Y.reshape(5000,))\nplt.show()","4fcca55c":"train_data = train_data\/255.0\ntest_data = test_data\/255.0","f021cb22":"from keras.layers import Input,Conv2D,Flatten,Dense,Reshape,Activation,LeakyReLU,BatchNormalization,Dropout,Conv2DTranspose,UpSampling2D\nimport keras.backend as K\nfrom keras.models import Model\nfrom keras.utils import plot_model\n\nz_dim = 100\ninput_dim = (32,32,3)\n\n#encoder\nencoder_input = Input(shape=input_dim)\n\nencoder_H = Conv2D(64,5,2,padding='same')(encoder_input)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = LeakyReLU()(encoder_H)\n\nencoder_H = Conv2D(64,5,2,padding='same')(encoder_H)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = LeakyReLU()(encoder_H)\n\nencoder_H = Conv2D(128,5,2,padding='same')(encoder_H)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = LeakyReLU()(encoder_H)\n\nencoder_H = Conv2D(128,5,1,padding='same')(encoder_H)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = LeakyReLU()(encoder_H)\n\nshape_before_flatten = K.int_shape(encoder_H)[1:]\nprint(f\"Shape of image before Flattening : {shape_before_flatten}\")\nflatten_shape = np.prod(shape_before_flatten)\nprint(f\"Shape after Flattening : {flatten_shape}\")\n\nencoder_H = Flatten()(encoder_H)\nencoder_output = Dense(z_dim)(encoder_H)\n\nencoder = Model(encoder_input,encoder_output)\nplot_model(encoder)","813106a9":"#decoder\n\ndecoder_input = Input(shape=(z_dim,))\n\ndecoder_H = Dense(flatten_shape)(decoder_input)\ndecoder_H = Reshape(shape_before_flatten)(decoder_H)\nreshaped = K.int_shape(decoder_H)\nprint(reshaped)\n\ndecoder_H = UpSampling2D()(decoder_H)\nupsampled = K.int_shape(decoder_H)\nprint(upsampled)\ndecoder_H = Conv2D(128,5,1,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_H = LeakyReLU()(decoder_H)\n\ndecoder_H = UpSampling2D()(decoder_H)\nupsampled = K.int_shape(decoder_H)\nprint(upsampled)\ndecoder_H = Conv2D(64,5,1,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_H = LeakyReLU()(decoder_H)\n\ndecoder_H = UpSampling2D()(decoder_H)\nupsampled = K.int_shape(decoder_H)\nprint(upsampled)\ndecoder_H = Conv2D(64,5,1,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_H = LeakyReLU()(decoder_H)\n\ndecoder_H = Conv2D(3,5,1,padding='same')(decoder_H)\ndecoder_output = Activation('sigmoid')(decoder_H)\nupsampled = K.int_shape(decoder_output)\nprint(upsampled)\n\ndecoder = Model(decoder_input,decoder_output)\nplot_model(decoder)","44346ccb":"#Connect encoder-decoder\n\nmodel_input = encoder_input\nmodel_output = decoder(encoder_output)\nmodel = Model(model_input,model_output)\nmodel.compile(loss='mse',optimizer='adam')\nplot_model(model)","cc9c5b4c":"history= model.fit(train_data,train_data,epochs=50,batch_size=128,shuffle=True)","11bd73be":"# Results of Reconstruction on Train dataset\nl = np.arange(20000)\nidx = np.random.choice(l,36)\n\ntrain_samples = train_data[idx]\n\nplt.figure(figsize=(5,5))\nfor i in range(len(idx)):\n    plt.subplot(6,6,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_samples[i])\nplt.show()\n","601f64af":"train_results = model.predict(train_samples)\nplt.figure(figsize=(5,5))\nfor i in range(len(idx)):\n    plt.subplot(6,6,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_results[i])\nplt.show()","77488e50":"# Results of Reconstruction on Test dataset\nl = np.arange(5000)\nidx = np.random.choice(l,36)\n\ntest_samples = test_data[idx]\n\nplt.figure(figsize=(5,5))\nfor i in range(len(idx)):\n    plt.subplot(6,6,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_samples[i])\nplt.show()","59116e9d":"test_results = model.predict(test_samples)\nplt.figure(figsize=(5,5))\nfor i in range(len(idx)):\n    plt.subplot(6,6,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_results[i])\nplt.show()","6f654e19":"**Original Train Images**","4b1364aa":"**Reconstructed Train Images**","b69b3a39":"**Reconstructed Test Images**","c11598fa":"**AE modeling**","b6db8e4f":"**Original Test Images**"}}