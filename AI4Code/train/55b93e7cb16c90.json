{"cell_type":{"937016e2":"code","601cb324":"code","fee2be09":"code","79727595":"code","a0a77d2f":"code","e01aef22":"code","55e0663b":"code","dd718701":"code","164ec28c":"code","fdc4f50e":"code","d1fa36f0":"code","4f2bf054":"code","aea4171d":"code","8d847b23":"code","fece0a4f":"code","764b79fb":"code","5316d984":"code","07eaeee6":"code","d0f63824":"code","f4b59d58":"code","9f3510ba":"code","bf34c96f":"code","a8df30ff":"code","2a872c2f":"code","90bf0aac":"code","bc8606fa":"code","542cc197":"code","3e8d1939":"markdown","1f1e4691":"markdown","e3f97fdd":"markdown","67b05da9":"markdown","3424e061":"markdown","c20ed387":"markdown","a157b904":"markdown","06ca0d94":"markdown","40aeeb9c":"markdown","6c153d71":"markdown","f4ee5af1":"markdown","ffb242b7":"markdown","305eb6d5":"markdown","22236bde":"markdown"},"source":{"937016e2":"!pip install tensorflow-gpu==2.0.0-rc1","601cb324":"import tensorflow as tf","fee2be09":"tf.__version__","79727595":"!pip install imageio","a0a77d2f":"import glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport os\nimport PIL\nfrom PIL import Image\nfrom tensorflow.keras import layers\nimport time\nimport random\n%load_ext tensorboard\nfrom IPython import display\nfrom tensorflow.keras.initializers import RandomNormal\n\n%matplotlib inline","e01aef22":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()","55e0663b":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5) \/ 127.5 # \uc774\ubbf8\uc9c0\ub97c [-1, 1]\ub85c \uc815\uaddc\ud654\ud569\ub2c8\ub2e4.","dd718701":"BUFFER_SIZE = 60000\nBATCH_SIZE = 256","164ec28c":"# Create batches of data and shuffle them.\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","fdc4f50e":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) \n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128) \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64) \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')) \n    assert model.output_shape == (None, 28, 28, 1) \n\n    return model\n\n   ","d1fa36f0":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False) \n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","4f2bf054":"def make_critc_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model\n\n    ","aea4171d":"critic = make_critc_model()\ndecision = critic(generated_image)\nprint (decision)","8d847b23":"def critic_loss(real_output, fake_output):\n    real_loss = - tf.reduce_mean(real_output)\n    fake_loss = tf.reduce_mean(fake_output)\n    return real_loss, fake_loss","fece0a4f":"def gradient_penalty(self, batch_size, images, generated_images):\n        # get the interplated image\n        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n        diff = aplha*images + (1-alpha)*generated_images\n\n        with tf.GradientTape() as gp_tape:\n            gp_tape.watch(diff)\n            # 1. Get the critic output for this interpolated image.\n            pred = crtitic(diff)\n\n        # 2. Calculate the gradients w.r.t to this interpolated image.\n        grads = gp_tape.gradient(pred, diff)\n        # 3. Calcuate the norm of the gradients\n        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n        gp = tf.reduce_mean((norm - 1.0) ** 2)\n        return gp","764b79fb":"def generator_loss(fake_output):\n    fake_loss = - tf.reduce_mean(fake_output)\n    return fake_loss","5316d984":"# Use Adam as the Optimizer\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ncritic_optimizer = tf.keras.optimizers.Adam(1e-4)","07eaeee6":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 critic_optimizer=critic_optimizer,\n                                 generator=generator,\n                                 critic=critic)","d0f63824":"# Define the training loop\n\nEPOCHS = 500\nnoise_dim = 100\nnum_examples_to_generate = 16\n\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\n","f4b59d58":"@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as cri_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = critic(images, training=True)\n      fake_output = critic(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      cri_loss = critic_loss(real_output, fake_output) + gp\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_critic = cri_tape.gradient(cri_loss, critic.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    critic_optimizer.apply_gradients(zip(gradients_of_critic, critic.trainable_variables))","9f3510ba":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n   # Instantly create images for GIF.\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n    # It saves the model every 15 epoch passes\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    # print the report on how much time it takes for each epoch\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  # Generate after the last epoch is over.\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)\n","bf34c96f":"#Create and save images\n\ndef generate_and_save_images(model, epoch, test_input):\n\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()\n","a8df30ff":"\n%%time\ntrain(train_dataset, EPOCHS)","2a872c2f":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","90bf0aac":"# GIFs \ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","bc8606fa":"display_image(EPOCHS)","542cc197":"# Create a GIF animation using images saved during training with imageio.\n\nanim_file = 'wgan-gp.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i**0.5)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport IPython\nif IPython.version_info > (6,2,0,''):\n  display.Image(filename=anim_file)","3e8d1939":"### Experiment utils (RUN ME!)","1f1e4691":"### Critic Loss Function","e3f97fdd":"### Critic","67b05da9":"### Model Traning","3424e061":"### Gradient Penalty","c20ed387":"Loading and preparing the dataset\n\nWe will use the MNIST dataset to train the Generator and Discriminator.\n\nThe Generator will generate numbers that resemble handwritten numeric data.","a157b904":"## Creating the model\nGenerator and Discriminator are defined using [Keras Sequential API] ","06ca0d94":"Like a generator, it uses a critic (not yet trained) to determine if the generated image is real or fake. The model is trained to output positive values for real images and negative values for fake images.","40aeeb9c":"### Save checkpoint\nThis notebook shows you how to save and restore models that can be useful in cases where long-running training is disrupted.","6c153d71":"##Generator loss function\n\nThe generator's loss function quantifies how well it deceives the critic. Intuitively, if the generator is running smoothly, the critic will classify the fake image as real (or 1). Here we will compare the critic's decision on the generated image with a matrix of ones.","f4ee5af1":"Acknowledgement: Portions of this page are reproduced and modified from work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License.\n\n# Please give an upvoe if you feel it is useful\n\n### plaese check other notebooks \n\n* [DCGAN with MNIST ](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-gp-with-mnist-for-absolute-beginners)\n\n* [DCGAN with Cifar10](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-cifar10-for-absolute-beginners)\n\n* [DCGAN with fashion MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-fashion-mnist-for-absolute-beginners)\n\n* [DCGAN with parasitized cell images](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-medical-images-for-absolute-beginners)\n\n* [CGAN with MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/cgan-with-mnist-for-absolute-beginners)\n\n* [WGAN with MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-with-fashion-mnist-for-absolute-beginners)\n\n\n* Let us change WGAN Model to WGAN-GP model","ffb242b7":"### Generator\n\nGenerator is the same as wgan","305eb6d5":"## Loss function and optimizer\nDefine the loss function and optimizer for both models.","22236bde":"Let's create an image using a generator that hasn't been trained yet."}}