{"cell_type":{"63859916":"code","41c52d30":"code","ea756019":"code","91a24d1c":"code","d48f5094":"code","702ff864":"code","ad5dede5":"code","9d8c4663":"code","16ee435a":"code","cce2c821":"code","f5c483a1":"code","23bc33a0":"code","196a2296":"code","762a03b0":"code","b33188b8":"code","0167e144":"code","1c9a16fa":"code","32a2f71c":"code","af044d3a":"code","66db346b":"code","c1e41491":"markdown","241246b3":"markdown","3c1b6d53":"markdown","dad56dea":"markdown","8951b49d":"markdown","65828d6b":"markdown","10c01e60":"markdown","9de29945":"markdown","af5f2f9a":"markdown","8a495f08":"markdown","5f48a10b":"markdown","40227e61":"markdown","67765244":"markdown","e81a6976":"markdown"},"source":{"63859916":"import os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.models import model_from_json\nfrom plotly.subplots import make_subplots","41c52d30":"print(os.listdir('..\/input'))","ea756019":"# Since data is duplicated (see: https:\/\/www.kaggle.com\/alxmamaev\/flowers-recognition\/discussion\/188011)\n# Using this path:\nfinal_path = \"\/kaggle\/input\/flowers-recognition\/flowers\/flowers\"\nclasses = os.listdir(final_path)\nclasses","91a24d1c":"image_size = (128, 128)\nbatch_size = 256\n\n# https:\/\/keras.io\/api\/preprocessing\/image\/#image_dataset_from_directory-function\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    final_path,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    final_path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)","d48f5094":"len(train_ds)","702ff864":"train_ds","ad5dede5":"len(val_ds)","9d8c4663":"val_ds","16ee435a":"plt.figure(figsize=(15, 15))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis(\"off\")","cce2c821":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.5),\n    ]\n)","f5c483a1":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","23bc33a0":"def make_model(input_shape, num_classes):\n    \n    inputs = keras.Input(shape=input_shape)\n\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(512, activation=\"relu\")(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dropout(0.2)(x)\n\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    outputs = layers.Dense(units, activation=activation)(x)\n    \n    return keras.Model(inputs, outputs)","196a2296":"model = make_model(input_shape=image_size + (3,), num_classes=len(classes))\nmodel.summary()","762a03b0":"model.compile(\n    optimizer=SGD(learning_rate=0.01, momentum=0.9),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)","b33188b8":"epochs = 40\n\n# https:\/\/keras.io\/api\/callbacks\/\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\n\nhistory = model.fit(\n    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n)","0167e144":"print(history.history.keys())","1c9a16fa":"history_fig = make_subplots(rows=1, cols=2)\n\nhistory_fig.add_trace(go.Scatter(\n    y=history.history['loss'],\n    mode='lines+markers',\n    name='training loss'\n), row=1, col=1)\n\nhistory_fig.add_trace(go.Scatter(\n    y=history.history['val_loss'],\n    mode='lines+markers',\n    name='validation loss'\n), row=1, col=1)\n\n\nhistory_fig.add_trace(go.Scatter(\n    y=history.history['accuracy'],\n    mode='lines+markers',\n    name='training accuracy'\n), row=1, col=2)\n\nhistory_fig.add_trace(go.Scatter(\n    y=history.history['val_accuracy'],\n    mode='lines+markers',\n    name='validation accuracy'\n), row=1, col=2)\n\nhistory_fig.update_xaxes(title_text='Epoch')\n\nhistory_fig.update_layout(\n    title_text=\"Training History Metrics\",\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=1)\n)\n\nhistory_fig.show()","32a2f71c":"model_json = model.to_json()\n\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","af044d3a":"# Load json and create model:\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# Load weights into new model:\nloaded_model.load_weights(\"model.h5\")\n\nprint(\"Loaded model from disk\")","66db346b":"plt.figure(figsize=(15, 15))\nfor images, labels in val_ds.take(1):\n    for i in range(12):\n        ax = plt.subplot(3, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        pred = loaded_model.predict(np.array([images[i].numpy().astype(\"uint8\")]))\n        title = 'Prediction: ' + classes[np.argmax(pred)]\n        title += '\\nReality: ' + classes[np.argmax(labels[i])]\n        plt.title(title)\n        plt.axis(\"off\")","c1e41491":"## Model Training History","241246b3":"## Saving","3c1b6d53":"## Perceptron Architecture","dad56dea":"# Model","8951b49d":"# Load Data","65828d6b":"# Data review","10c01e60":"# Imports","9de29945":"# Tarea Semana 11","af5f2f9a":"## Testing Predictions","8a495f08":"## Training","5f48a10b":"## Loading","40227e61":"# Data Augmentation","67765244":"# Elberth Adri\u00e1n Garro S\u00e1nchez (1-1644-0594)","e81a6976":"## Compilation"}}