{"cell_type":{"16319cde":"code","dd1c468f":"code","a7bfea43":"code","13caa92c":"code","3d6b5fb4":"code","245d59ed":"code","7cc5cd35":"code","cd71edbf":"code","91708570":"code","b63b89ce":"code","c581abaf":"code","19737b62":"code","d915d6b9":"code","752fabe4":"code","70839039":"code","4b64a6eb":"code","f84d7b89":"code","83892f00":"code","575f9006":"code","456340f8":"code","606a6cbd":"code","9f872bce":"code","41bbaa33":"code","b0b8cc17":"code","f8931bd2":"code","49f41381":"code","e11b6b61":"code","93a7ee95":"code","5a8ea441":"code","ef30c044":"code","4d8749c9":"code","2e05162b":"markdown","11f60d78":"markdown","9e14490c":"markdown","ccc7fbfa":"markdown","bc09196b":"markdown","c505e752":"markdown","732ef49b":"markdown","3faa7e75":"markdown","73e70cb2":"markdown","bee4daa0":"markdown","2eededbb":"markdown","c86b536d":"markdown","98c71e69":"markdown","3610e4d1":"markdown","530dcc47":"markdown","1ae047c9":"markdown","cad9d777":"markdown","b8a9745f":"markdown","071abe59":"markdown","d66fbc03":"markdown","a6005f7b":"markdown","3eed378c":"markdown","b6164616":"markdown","74a9087f":"markdown","cc09ed33":"markdown","fbdd67da":"markdown","243b4088":"markdown","7d0485b0":"markdown","b4e9324a":"markdown","ebcdcbdc":"markdown","88cac331":"markdown","0e784425":"markdown","813131db":"markdown","ef7f1838":"markdown","c02f6a43":"markdown","1368189d":"markdown","6cdc9153":"markdown","37388280":"markdown","53ef8597":"markdown"},"source":{"16319cde":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split","dd1c468f":"DATA_PATH = '..\/input\/tabular-playground-series-nov-2021'\nPURE_DATA_PATH = '..\/input\/november21'","a7bfea43":"test_dtype = {f'f{i}': 'float32' for i in range(100)}\ntrain_dtype = {**test_dtype, 'target': 'int8'}","13caa92c":"train_csv = pd.read_csv(f'{DATA_PATH}\/train.csv', index_col='id', dtype=train_dtype)","3d6b5fb4":"pure_csv = pd.read_csv(f'{PURE_DATA_PATH}\/train.csv', index_col='id', dtype=train_dtype)","245d59ed":"train_csv.head()","7cc5cd35":"pure_csv.head()","cd71edbf":"train_csv.equals(pure_csv)","91708570":"train_csv.drop('target', axis=1).equals(pure_csv.drop('target', axis=1))","b63b89ce":"y_train = train_csv['target']\ny_pure = pure_csv['target']\n\ny_train.equals(y_pure)","c581abaf":"(y_train != y_pure).sum() \/ y_train.shape[0]","19737b62":"scaler = StandardScaler()\nX_train = scaler.fit_transform(train_csv.drop('target', axis=1))","d915d6b9":"pure_model = LogisticRegression(random_state=83).fit(X_train, y_pure)\n\ny_pure_pred = pure_model.predict_proba(X_train)[:, 1]\nroc_auc_score(y_pure, y_pure_pred)","752fabe4":"train_model = LogisticRegression(random_state=83).fit(X_train, y_train)\n\ny_train_pred = train_model.predict_proba(X_train)[:, 1]\nroc_auc_score(y_train, y_train_pred)","70839039":"roc_auc_score(y_train, pure_model.predict_proba(X_train)[:, 1])","4b64a6eb":"plt.hist(y_pure_pred, bins=100);","f84d7b89":"plt.hist(y_train_pred, bins=100);","83892f00":"def split_train_and_validate(name, X, y, test_size):\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=83)\n    \n    model = LogisticRegression(random_state=83).fit(X_train, y_train)\n    \n    train_score = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n    valid_score = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n\n    print(f'{name} Train size: {len(y_train)} - {((len(y_train) \/ len(y) * 100)):.2f}%')\n    print(f'{name} Valid size: {len(y_valid)} - {((len(y_valid) \/ len(y) * 100)):.2f}%\\n')\n    \n    print(f'{name} Train score: {train_score}')\n    print(f'{name} Valid score: {valid_score}')\n    \n    return train_score, valid_score","575f9006":"split_train_and_validate('Pure', X_train, y_pure, test_size=0.2);","456340f8":"split_train_and_validate('Pure', X_train, y_pure, test_size=0.5);","606a6cbd":"split_train_and_validate('Pure', X_train, y_pure, test_size=0.8);","9f872bce":"split_train_and_validate('Pure', X_train, y_pure, test_size=0.99);","41bbaa33":"split_train_and_validate('Pure', X_train, y_pure, test_size=0.999);","b0b8cc17":"split_train_and_validate('Pure', X_train, y_pure, test_size=0.9995);","f8931bd2":"split_train_and_validate('Mixed', X_train, y_train, test_size=0.2); print(\"\\n\")\nsplit_train_and_validate('Mixed', X_train, y_train, test_size=0.99); print(\"\\n\")\nsplit_train_and_validate('Mixed', X_train, y_train, test_size=0.999); print(\"\\n\")\nsplit_train_and_validate('Mixed', X_train, y_train, test_size=0.9995);","49f41381":"fpr, tpr, thresholds = roc_curve(y_pure, y_pure_pred)\nplt.plot(fpr, tpr);","e11b6b61":"fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\nplt.plot(fpr, tpr);","93a7ee95":"test_csv = pd.read_csv(f'{DATA_PATH}\/test.csv', index_col='id')\nsample_submission_csv = pd.read_csv(f'{DATA_PATH}\/sample_submission.csv', index_col='id')","5a8ea441":"X_test = scaler.transform(test_csv)\n\ny_test_pred = pure_model.predict_proba(X_test)[:, 1]","ef30c044":"sample_submission_csv['target'] = y_test_pred\nsample_submission_csv.head()","4d8749c9":"sample_submission_csv.to_csv(f'.\/submission.csv')","2e05162b":"While we didn't use train\/test split(we will get to it), there are `600_000` points with `100` features and a dumb `LogisticRegression` was able to successfully split this huge blob of data with `101` params. Really, not bad result!\n\nOk, let's see what would we get with the official version:","11f60d78":"And the difference is about `25%`:","9e14490c":"Mixed labels models are more sensitive to amount of data due to random mutations and fall short after `600` points gap.","ccc7fbfa":"That's a bit buffling. We removed `20%` of the data but the score is still perfect.\n\nLet's remove half of the data, and verify again:","bc09196b":"## Train-Test Split","c505e752":"and mixed-label model:","732ef49b":"Ok, and now run it with pure labels:","3faa7e75":"## Conclusions or why Game Over?","73e70cb2":"To be impeccable, let's do a simple train-test split to remove any chance for mistake. We will do `80\/20` train\/validation split. To make everything simpler, we will have a helper function to make all data lifting, so we can focus on the fun part.","bee4daa0":"and labels differ:","2eededbb":"Actually, the curve for mixed-label model looks a bit odd, usually it does not have such a linear shape. Next time, I'll check ROC curve shape, before trying to improve my model score.","c86b536d":"To wrap up our experiment, let's check briefly mixed labels.","98c71e69":"Finally on `600` training points we see some significant drop on the validation set:","3610e4d1":"Now the first surprise to me was this.","530dcc47":"Ok, still too good to be true. Maybe `20\/80` will make it fail?","1ae047c9":"But even with `300` points the score is still very good:","cad9d777":"Let's verify that features are same:","b8a9745f":"## Comparing Datasets","071abe59":"## Baseline Models","d66fbc03":"## How did I get this data?","a6005f7b":"Not a big difference. Most likely due to mixed labels, `train_model` is less confident in its predictions as `pure_model`. Let's verify.","3eed378c":"## What if Remastered over Synthetic?","b6164616":"## ROC Curves","74a9087f":"To wrap our EDA part, let's check ROC curves for both labels.\n\nAt first pure-label model output:","cc09ed33":"## Loading Data","fbdd67da":"### Mixed labels validation","243b4088":"TPS Kaggle series is a really cool thing to tinker with tabular data. But using GANs and other data generation techniques leaves us some unrealistic taste.\n\nBut Kaggle already has dozens of cool tabular datasets accrued through the long history. What if to take these old competitions data and start a new challenge? Yes, you can go and play with it by yourself. But it feels a bit lonely without live comments and new kernels.\n\nAlso, a lot of old competitions were run when we didn't have NNs, XGB and lightGMB. What if we can do better than the old Grand Masters?\n\nThere are some tiny details to address - like prohibiting submission in the old competitions for the time of remastered one, but this is a doable thing.","7d0485b0":"Pretty close to a common score on the Leaderboard.\n\nLet's check what would be a score of pure-labels model on mixed labels:","b4e9324a":"## PS - Let's try pure data model?","ebcdcbdc":"On the first glance both files look pretty similar:","88cac331":"So, all in all, looks like Kagglers already knew the truth.","0e784425":"Let's confirm that they differ:","813131db":"Apparently, this dataset was generated in too good to be any close to real dataset thing. As a consequence, all tries to improve the score with neural networks, trees, ensembles and other more complex approaches do not make any sense.\n\nThe distribution is too simple and more complex models would not give any significant boost over basic approaches. It looks like a race to overfit better by chance.\n\nPure training set is quite odd, because it does not leave you any room for improvement on cross-validation. How can be improved something, when you have `99.99%` score with 1000 points?\n\nMixed training set is the same, it just makes you believe you can do better.","ef7f1838":"Let's rescale our data to fit models on pure and train labels. We don't need to have `X_pure`, because features are same:","c02f6a43":"As a final step let's make a most stupid model submission and cross our fingers. What if this is the lucky winner?","1368189d":"By some random chance, I downloaded `train.csv.zip` in the first hour when competition just started. For several days I didn't check notebooks and forum not to spoil a pleasure of diving into the data.\n\nThis dataset was a bizzare one from the start. I was totally buffled and finally went to forum and checked notebooks of others to understand what's wrong. My code worked differently local and on Kaggle.\n\nAfter downloading data again and comparing it with my local version I realized that my `train.csv` was the original version without inversed labels.\n\nMost likely organizers made a mistake and uploaded `train.csv.zip` different from the one in the batch data file and didn't noticed the error at the beginning(the mistake was fixed later).\n\nWithout further ado, let's dive in.","6cdc9153":"Let's load some basic libraries and both train sets. I uploaded original\/pure version of train.csv into a dataset on Kaggle:","37388280":"As we see, pure-data model is very confident, while mixed-data model is not at all.","53ef8597":"Hmm, what about `1\/99`?"}}