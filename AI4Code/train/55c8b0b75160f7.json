{"cell_type":{"91922405":"code","ad8cde13":"code","dc6d7452":"code","65c48f76":"code","01b0c05a":"code","cddef379":"code","33f775a1":"code","d36db627":"code","6a6a777a":"code","17e3f3d4":"code","32207d5e":"code","19319e91":"code","54b15860":"code","686e9152":"code","4fe66695":"code","2690ea09":"code","1f249296":"code","050ace6c":"code","7d504515":"code","fb5e8851":"markdown"},"source":{"91922405":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport gc\ngc.collect()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ad8cde13":"# https:\/\/www.kaggle.com\/pierrenicolaspiquin\/oct-segmentation\/data\n# Settings\ninput_path = os.path.join('..', 'input', '2015_boe_chiu', '2015_BOE_Chiu')\nsubject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n\ndata_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n\nwidth = 284\nheight = 284\nwidth_out = 196\nheight_out = 196","dc6d7452":"mat = scipy.io.loadmat(subject_path[0])\nimg_tensor = mat['images']\nmanual_fluid_tensor_1 = mat['manualFluid1']\n\nimg_array = np.transpose(img_tensor, (2, 0, 1))\nmanual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))","65c48f76":"plt.imshow(img_array[25])","01b0c05a":"plt.imshow(manual_fluid_array[25])","cddef379":"def thresh(x):\n    if x == 0:\n        return 0\n    else:\n        return 1\n\nthresh = np.vectorize(thresh, otypes=[np.float])\n\ndef create_dataset(paths):\n    x = []\n    y = []\n    \n    for path in tqdm(paths):\n        mat = scipy.io.loadmat(path)\n        img_tensor = mat['images']\n        fluid_tensor = mat['manualFluid1']\n        \n        img_array = np.transpose(img_tensor, (2, 0 ,1)) \/ 255\n        img_array = resize(img_array, (img_array.shape[0], width, height))\n        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n        fluid_array = thresh(fluid_array)\n        fluid_array  = resize(fluid_array, (fluid_array .shape[0], width_out, height_out))\n\n        for idx in data_indexes:\n            x += [np.expand_dims(img_array[idx], 0)]\n            y += [np.expand_dims(fluid_array[idx], 0)]\n    return np.array(x), np.array(y)\n\nx_train, y_train = create_dataset(subject_path[:9])\nx_val, y_val = create_dataset(subject_path[9:])","33f775a1":"x_train.shape, y_train.shape, x_val.shape, y_val.shape","d36db627":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom tqdm import trange\nfrom time import sleep\nuse_gpu = torch.cuda.is_available()","6a6a777a":"batch_size = 9\nepochs = 1000\nepoch_lapse = 50\nthreshold = 0.5\nsample_size = None","17e3f3d4":"class UNet(nn.Module):\n    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n        block = torch.nn.Sequential(\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(out_channels),\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(out_channels),\n                )\n        return block\n    \n    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n            block = torch.nn.Sequential(\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(mid_channel),\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(mid_channel),\n                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n                    )\n            return  block\n    \n    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n            block = torch.nn.Sequential(\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(mid_channel),\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(mid_channel),\n                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n                    torch.nn.ReLU(),\n                    torch.nn.BatchNorm2d(out_channels),\n                    )\n            return  block\n    \n    def __init__(self, in_channel, out_channel):\n        super(UNet, self).__init__()\n        #Encode\n        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n        self.conv_encode2 = self.contracting_block(64, 128)\n        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n        self.conv_encode3 = self.contracting_block(128, 256)\n        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n        # Bottleneck\n        self.bottleneck = torch.nn.Sequential(\n                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n                            torch.nn.ReLU(),\n                            torch.nn.BatchNorm2d(512),\n                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n                            torch.nn.ReLU(),\n                            torch.nn.BatchNorm2d(512),\n                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n                            )\n        # Decode\n        self.conv_decode3 = self.expansive_block(512, 256, 128)\n        self.conv_decode2 = self.expansive_block(256, 128, 64)\n        self.final_layer = self.final_block(128, 64, out_channel)\n        \n    def crop_and_concat(self, upsampled, bypass, crop=False):\n        if crop:\n            c = (bypass.size()[2] - upsampled.size()[2]) \/\/ 2\n            bypass = F.pad(bypass, (-c, -c, -c, -c))\n        return torch.cat((upsampled, bypass), 1)\n    \n    def forward(self, x):\n        # Encode\n        encode_block1 = self.conv_encode1(x)\n        encode_pool1 = self.conv_maxpool1(encode_block1)\n        encode_block2 = self.conv_encode2(encode_pool1)\n        encode_pool2 = self.conv_maxpool2(encode_block2)\n        encode_block3 = self.conv_encode3(encode_pool2)\n        encode_pool3 = self.conv_maxpool3(encode_block3)\n        # Bottleneck\n        bottleneck1 = self.bottleneck(encode_pool3)\n        # Decode\n        ##print(x.shape, encode_block1.shape, encode_block2.shape, encode_block3.shape, bottleneck1.shape)\n        ##print('Decode Block 3')\n        ##print(bottleneck1.shape, encode_block3.shape)\n        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n        ##print(decode_block3.shape)\n        ##print('Decode Block 2')\n        cat_layer2 = self.conv_decode3(decode_block3)\n        ##print(cat_layer2.shape, encode_block2.shape)\n        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n        cat_layer1 = self.conv_decode2(decode_block2)\n        ##print(cat_layer1.shape, encode_block1.shape)\n        ##print('Final Layer')\n        ##print(cat_layer1.shape, encode_block1.shape)\n        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n        ##print(decode_block1.shape)\n        final_layer = self.final_layer(decode_block1)\n        ##print(final_layer.shape)\n        return  final_layer\n        ","32207d5e":"def train_step(inputs, labels, optimizer, criterion):\n    optimizer.zero_grad()\n    # forward + backward + optimize\n    outputs = unet(inputs)\n    # outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n    outputs = outputs.permute(0, 2, 3, 1)\n    # outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n    outputs = outputs.resize(batch_size*width_out*height_out, 2)\n    labels = labels.resize(batch_size*width_out*height_out)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n    return loss","19319e91":"learning_rate = 0.01\nunet = UNet(in_channel=1,out_channel=2)\nif use_gpu:\n    unet = unet.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)","54b15860":"def get_val_loss(x_val, y_val):\n    x_val = torch.from_numpy(x_val).float()\n    y_val = torch.from_numpy(y_val).long()\n    if use_gpu:\n        x_val = x_val.cuda()\n        y_val = y_val.cuda()\n    m = x_val.shape[0]\n    outputs = unet(x_val)\n    # outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n    outputs = outputs.permute(0, 2, 3, 1)\n    # outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n    outputs = outputs.resize(m*width_out*height_out, 2)\n    labels = y_val.resize(m*width_out*height_out)\n    loss = F.cross_entropy(outputs, labels)\n    return loss.data","686e9152":"epoch_iter = np.ceil(x_train.shape[0] \/ batch_size).astype(int)\nt = trange(epochs, leave=True)\nfor _ in t:\n    total_loss = 0\n    for i in range(epoch_iter):\n        batch_train_x = torch.from_numpy(x_train[i * batch_size : (i + 1) * batch_size]).float()\n        batch_train_y = torch.from_numpy(y_train[i * batch_size : (i + 1) * batch_size]).long()\n        if use_gpu:\n            batch_train_x = batch_train_x.cuda()\n            batch_train_y = batch_train_y.cuda()\n        batch_loss = train_step(batch_train_x , batch_train_y, optimizer, criterion)\n        total_loss += batch_loss\n    if (_+1) % epoch_lapse == 0:\n        val_loss = get_val_loss(x_val, y_val)\n        print(f\"Total loss in epoch {_+1} : {total_loss \/ epoch_iter} and validation loss : {val_loss}\")","4fe66695":"gc.collect()","2690ea09":"def plot_examples(datax, datay, num_examples=3):\n    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(18,4*num_examples))\n    m = datax.shape[0]\n    for row_num in range(num_examples):\n        image_indx = np.random.randint(m)\n        image_arr = unet(torch.from_numpy(datax[image_indx:image_indx+1]).float().cuda()).squeeze(0).detach().cpu().numpy()\n        ax[row_num][0].imshow(np.transpose(datax[image_indx], (1,2,0))[:,:,0])\n        ax[row_num][0].set_title(\"Orignal Image\")\n        ax[row_num][1].imshow(np.transpose(image_arr, (1,2,0))[:,:,0])\n        ax[row_num][1].set_title(\"Segmented Image\")\n        ax[row_num][2].imshow(image_arr.argmax(0))\n        ax[row_num][2].set_title(\"Segmented Image localization\")\n        ax[row_num][3].imshow(np.transpose(datay[image_indx], (1,2,0))[:,:,0])\n        ax[row_num][3].set_title(\"Target image\")\n    plt.show()","1f249296":"plot_examples(x_train, y_train)","050ace6c":"plot_examples(x_val, y_val)","7d504515":"torch.save(unet.state_dict(), 'unet.pt')","fb5e8851":"## Unet"}}