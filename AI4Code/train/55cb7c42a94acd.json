{"cell_type":{"a3df86c3":"code","59675ebf":"code","8eb64a42":"code","6cc6f0f9":"code","688b5fe1":"code","95c14d2b":"code","dea557c4":"code","109141b1":"code","c70d47d5":"code","fb026c17":"code","27e90400":"code","b7985c58":"code","874badd7":"code","29fdeb52":"code","507862e4":"markdown","68698817":"markdown","14268d30":"markdown","624619bc":"markdown","8ed65f41":"markdown","e777dde5":"markdown","ad638707":"markdown","7230c70e":"markdown","f57673e2":"markdown","c2aec4ad":"markdown","24a0461d":"markdown","0d708f79":"markdown","d3786e86":"markdown"},"source":{"a3df86c3":"import numpy as np\nimport pandas as pd\n\nimport os","59675ebf":"data = pd.read_csv(\"..\/input\/voice.csv\")","8eb64a42":"data.head()","6cc6f0f9":"data.label = [1 if each == \"male\" else 0 for each in data.label]\ndata.head() # check if binary conversion worked","688b5fe1":"gender = data.label.values\nfeatures = data.drop([\"label\"], axis = 1)\nfeatures = (features-features.min())\/(features.max()-features.min()) # normalization","95c14d2b":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features, gender, test_size = 0.2, random_state = 42)","dea557c4":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nlist_names = []\nlist_accuracy = []","109141b1":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nLR_accuracy = lr.score(x_test, y_test)*100\nLR_accuracy = round(LR_accuracy, 3)\n\nprint(\"LR_accuracy is %\", LR_accuracy)\n\nlist_names.append(\"Logistic Regression \")\nlist_accuracy.append(LR_accuracy)\n\n# Confusion Matrix\ny_pred_RF = lr.predict(x_test)\nRF_cm = confusion_matrix(y_test, y_pred_RF)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(RF_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Logistic Regression Classifier')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","c70d47d5":"from sklearn.neighbors import KNeighborsClassifier\n\nKnn = KNeighborsClassifier(n_neighbors = 8)\nKnn.fit(x_train, y_train)\nKnn_accuracy = Knn.score(x_test, y_test)*100\nKnn_accuracy = round(Knn_accuracy, 3)\n\nprint(\"Knn_accuracy is %\", Knn_accuracy)\n\nlist_names.append(\"K-nn \")\nlist_accuracy.append(Knn_accuracy)\n\n# Confusion Matrix\ny_pred_Knn = Knn.predict(x_test)\nKnn_cm = confusion_matrix(y_test, y_pred_Knn)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(Knn_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the K-nn Classifier')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","fb026c17":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\nsvm.fit(x_train, y_train)\nSVM_accuracy = svm.score(x_test, y_test)*100\nSVM_accuracy = round(SVM_accuracy, 3)\n\nprint(\"SVM_accuracy is %\", SVM_accuracy)\n\nlist_names.append(\"SVM \")\nlist_accuracy.append(SVM_accuracy)\n\n# Confusion Matrix\ny_pred_SVM = svm.predict(x_test)\nSVM_cm = confusion_matrix(y_test, y_pred_SVM)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(SVM_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Support Vector Machine (SVM)')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","27e90400":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train, y_train)\nNaiveBayes_acuracy = nb.score(x_test, y_test)*100\nNaiveBayes_acuracy = round(NaiveBayes_acuracy,3)\n\nprint(\"NaiveBayes_acuracy is %\", NaiveBayes_acuracy)\n\nlist_names.append(\"Naive Bayes \")\nlist_accuracy.append(NaiveBayes_acuracy)\n\n# Confusion Matrix\ny_pred_NB = nb.predict(x_test)\nNB_cm = confusion_matrix(y_test, y_pred_NB)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(NB_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Naive Bayes')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","b7985c58":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(x_train, y_train)\nDecisionTree_accuracy = dt.score(x_test, y_test)*100\nDecisionTree_accuracy = round(DecisionTree_accuracy,3)\n\nprint(\"DecisionTree_accuracy is %\", DecisionTree_accuracy)\n\nlist_names.append(\"Decision Tree \")\nlist_accuracy.append(DecisionTree_accuracy)\n\n# Confusion Matrix\ny_pred_DT = dt.predict(x_test)\nDT_cm = confusion_matrix(y_test, y_pred_DT)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(DT_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Decision Tree')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","874badd7":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 10, random_state = 1)\nrf.fit(x_train, y_train)\nRandomForest_accuracy = rf.score(x_test, y_test)*100\nRandomForest_accuracy = round(RandomForest_accuracy, 3)\n\nprint(\"RandomForest_accuracy is %\", RandomForest_accuracy)\n\nlist_names.append(\"Random Forest \")\nlist_accuracy.append(RandomForest_accuracy)\n\n# Confusion Matrix\ny_pred_RF = rf.predict(x_test)\nRF_cm = confusion_matrix(y_test, y_pred_RF)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(RF_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Random Forest')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","29fdeb52":"x = list_names\ny = list_accuracy\n    \nfig = plt.figure(figsize=(12,10))\nwidth = 0.4 # the width of the bars \nind = np.arange(len(x))  # the x locations for the groups\nplt.ylim([90,99])\nplt.bar(x, y, width)\nplt.xticks(ind, rotation=90, fontsize = 16)\nplt.yticks(fontsize = 16)\nplt.grid(alpha=0.4)\nplt.ylabel(\"ACCURACY (%)\", fontsize = 16)\nplt.title(\"COMPARISON of the ACCURACY of the MACHINE LEARNING METHODS\", fontsize = 16, pad = 20)  \nplt.show()","507862e4":"DECISION TREE","68698817":"NAIVE BAYES","14268d30":"Split data for train and test purpose","624619bc":"COMPARISON OF THE MACHINE LEARNING METHODS","8ed65f41":"Review the data","e777dde5":"Import necessary libraries","ad638707":"LOGISTIC REGRESSION","7230c70e":"Extract gender and features data","f57673e2":"K-NN CLASSIFIER","c2aec4ad":"SUPPORT VECTOR MACHINE (SVM)","24a0461d":"Import data","0d708f79":"RANDOM FOREST","d3786e86":"Convert \"male\" to 1, \"female\" to 0"}}