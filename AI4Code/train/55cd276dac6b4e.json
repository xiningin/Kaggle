{"cell_type":{"dda3fb74":"code","79379475":"code","4eae2c5a":"code","2dc43f9a":"code","5697a1ef":"code","d68e8001":"code","694c4d71":"code","48abd65c":"code","5a3ff8f2":"code","54d174a5":"code","27b24a7e":"code","bb1e16c5":"code","01f5f08f":"code","c0c6897d":"code","37683063":"code","380b8bcb":"code","0698d575":"code","016c2326":"code","c12b0075":"code","2feae212":"markdown","b0b61637":"markdown","8be7efdd":"markdown","c9bbe3cf":"markdown","0e00a403":"markdown","90fb0251":"markdown","1172aab3":"markdown","10b3a3ed":"markdown","0a4aae78":"markdown","ef3a0fb0":"markdown","a932f47c":"markdown","9659fddc":"markdown","5d09a90c":"markdown","59de8045":"markdown","0f5d5f8c":"markdown","39c44d86":"markdown","618a990d":"markdown","e727d30e":"markdown","87783977":"markdown","7560d67f":"markdown"},"source":{"dda3fb74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","79379475":"import warnings\nwarnings.filterwarnings('ignore')\n%precision %.2f","4eae2c5a":"df = pd.read_csv('..\/input\/amazon-top-50-bestselling-books-2009-2019\/bestsellers with categories.csv')\ndf.head()","2dc43f9a":"print(df.describe(),df.info())","5697a1ef":"df_2009 = df[df['Year'] == 2009]\ndf_2010 = df[df['Year'] == 2010]\ndf_2011 = df[df['Year'] == 2011]\ndf_2012 = df[df['Year'] == 2012]\ndf_2013 = df[df['Year'] == 2013]\ndf_2014 = df[df['Year'] == 2014]\ndf_2015 = df[df['Year'] == 2015]\ndf_2016 = df[df['Year'] == 2016]\ndf_2017 = df[df['Year'] == 2017]\ndf_2018 = df[df['Year'] == 2018]\ndf_2019 = df[df['Year'] == 2019]","d68e8001":"df_without_duplicates = df.drop_duplicates(subset='Name',keep='first')","694c4d71":"import matplotlib.pyplot as plt\nimport seaborn as sns","48abd65c":"#Non-Fiction == 1 and Fiction === 0\ndf['Genre'] = pd.get_dummies(df['Genre'],drop_first=True)\ndf_without_duplicates['Genre'] = pd.get_dummies(df_without_duplicates['Genre'],drop_first=True)","5a3ff8f2":"from matplotlib.patches import Rectangle\n\nplt.figure(figsize=(15,5))\n#plot1\nplt.subplot(1,2,1)\nN,bins,patches = plt.hist(df['Genre'],bins=np.arange(0,3,1)-0.5,edgecolor='black',rwidth=0.5)\ncmap = plt.get_cmap('jet')\nfiction = cmap(0.4)\nnonfiction = cmap(0.8)\npatches[0].set_facecolor(fiction)\npatches[1].set_facecolor(nonfiction)\n\nplt.xticks([0,1])\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.title('Genre classes count with duplicates')\n\n\nhandles = [Rectangle((0,0),1,1,color=c) for c in [fiction,nonfiction]]\nlabels = ['Fiction','Non-Fiction']\nplt.legend(handles,labels)\n\n#plot2\nplt.subplot(1,2,2)\nN,bins,patches = plt.hist(df_without_duplicates['Genre'],bins=np.arange(0,3,1)-0.5,edgecolor='black',rwidth=0.5)\ncmap = plt.get_cmap('jet')\nfiction = cmap(0.4)\nnonfiction = cmap(0.8)\npatches[0].set_facecolor(fiction)\npatches[1].set_facecolor(nonfiction)\n\nplt.xticks([0,1])\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.title('Genre classes count without duplicates')\n\nhandles = [Rectangle((0,0),1,1,color=c) for c in [fiction,nonfiction]]\nlabels = ['Fiction','Non-Fiction']\nplt.legend(handles,labels)","54d174a5":"fig, axes = plt.subplots(4, 3, figsize=(20, 15))\n\ngraphs = sns.countplot(ax=axes[0,0],x='User Rating',data=df_2009)\naxes[0,0].set_title('User Ratings for the Year 2009')\ngraphs = sns.countplot(ax=axes[0,1],x='User Rating',data=df_2010)\naxes[0,1].set_title('User Ratings for the Year 2010')\ngraphs = sns.countplot(ax=axes[0,2],x='User Rating',data=df_2011)\naxes[0,2].set_title('User Ratings for the Year 2011')\ngraphs = sns.countplot(ax=axes[1,0],x='User Rating',data=df_2012)\naxes[1,0].set_title('User Ratings for the Year 2012')\ngraphs = sns.countplot(ax=axes[1,1],x='User Rating',data=df_2013)\naxes[1,1].set_title('User Ratings for the Year 2013')\ngraphs = sns.countplot(ax=axes[1,2],x='User Rating',data=df_2014)\naxes[1,2].set_title('User Ratings for the Year 2014')\ngraphs = sns.countplot(ax=axes[2,0],x='User Rating',data=df_2015)\naxes[2,0].set_title('User Ratings for the Year 2015')\ngraphs = sns.countplot(ax=axes[2,1],x='User Rating',data=df_2016)\naxes[2,1].set_title('User Ratings for the Year 2016')\ngraphs = sns.countplot(ax=axes[2,2],x='User Rating',data=df_2017)\naxes[2,2].set_title('User Ratings for the Year 2017')\ngraphs = sns.countplot(ax=axes[3,0],x='User Rating',data=df_2018)\naxes[3,0].set_title('User Ratings for the Year 2018')\ngraphs = sns.countplot(ax=axes[3,1],x='User Rating',data=df_2019)\naxes[3,1].set_title('User Ratings for the Year 2019')\nfig.delaxes(axes[3,2])\nfig.tight_layout()","27b24a7e":"plt.figure(figsize=(12,5))\nplt.scatter(df_without_duplicates['User Rating'],df_without_duplicates['Price'],color='red',marker='s',alpha=0.3)\nplt.xlabel('User Ratings')\nplt.xticks(np.arange(3.2,5,0.1))\nplt.ylabel('Price')\nplt.yticks(np.arange(0,120,10))\nplt.title('Density Graph of Price : User Ratings (Without Duplicates)')\n\nsns.jointplot(x='User Rating',y='Price',data=df_without_duplicates,kind='hex')","bb1e16c5":"plt.figure(figsize=(10,7))\nplt.scatter(df_without_duplicates['User Rating'],df_without_duplicates['Reviews'],color='red',marker='s',alpha=0.3)\nplt.yticks(np.arange(0,100000,10000))\nplt.xlabel('User Ratings')\nplt.ylabel('Reviews')\nplt.title(\"Reviews according to User Ratings (Without Duplicates)\")\n\nsns.jointplot(x='User Rating',y='Reviews',data=df_without_duplicates,kind='hex')","01f5f08f":"top_authors = dict(df['Author'].value_counts())\ntop_authors = list(top_authors.items())\ntop_authors = top_authors[0:5]\nx,y = zip(*top_authors)\nplt.figure(figsize=(10,5))\nplt.barh(x,y,edgecolor='black',color=['#e6a132'])\nplt.gca().invert_yaxis()\nplt.xlabel('Number of Appearences')\nplt.ylabel('Name of Author')\nplt.title(\"Top 5 Authors (Most number of Appearences in Top 50)\")","c0c6897d":"max_rating = df_without_duplicates['User Rating'].max()\nhighest_rating = df_without_duplicates[df_without_duplicates['User Rating']==max_rating]\nhighest_rating_author = dict(highest_rating['Author'].value_counts())\nhighest_rating_author = list(highest_rating_author.items())\nhighest_rating_author = highest_rating_author[:3]\nx,y=zip(*highest_rating_author)\nplt.barh(x,y,edgecolor='black',color='#6c1ff3',alpha=0.7)\nplt.gca().invert_yaxis()\nplt.xlabel('Number of books with the Rating')\nplt.ylabel('Name of Authors')\nplt.title('Top 3 Authors with highest rated books (Without Duplicates)')","37683063":"max_reviews = df_without_duplicates['Reviews'].max()\nhighest_reviews = df_without_duplicates[df_without_duplicates['Reviews']==max_reviews]\nhighest_reviews","380b8bcb":"avg_review = df_without_duplicates['Reviews'].sum()\/ 351\navg_price = df_without_duplicates['Price'].sum()\/ 351\navg_userrating = df_without_duplicates['User Rating'].sum()\/351\nprint('Average Number of Reviews is '+str(round(avg_review,2)))\nprint('Average Price is '+str(round(avg_price,2)))\nprint('Average User Rating is '+str(round(avg_userrating,2)))","0698d575":"years = [df_2009,df_2010,df_2011,df_2012,df_2013,df_2014,df_2015,df_2016,df_2017,df_2018,df_2019]\navg_review = []\navg_price = []\navg_user_rating = []\nfor year in years:\n    avg_review.append(year['Reviews'].sum()\/ 50)\n    avg_price.append(year['Price'].sum()\/ 50)\n    avg_user_rating.append(year['User Rating'].sum()\/50)\n\nyear_list = np.arange(2009,2020,1)\nplt.figure(figsize=(12,7))\nfor i in range(0,11):\n    plt.bar(year_list[i],avg_review[i],edgecolor='black',label=str(year_list[i]))\n    plt.xticks(year_list)\n    plt.yticks(np.arange(0,18000,2000))\n    plt.xlabel('Years')\n    plt.ylabel('Review Count')\n    plt.title('Average Reviews for each Year')\n    plt.legend()","016c2326":"plt.figure(figsize=(15,7))\nfor i in range(0,11):\n    plt.bar(year_list[i],avg_price[i],edgecolor='black',label=str(year_list[i]))\n    plt.xticks(year_list)\n    plt.xlabel('Years')\n    plt.ylabel('Price')\n    plt.title('Average Price for each Year')\n    plt.legend()","c12b0075":"plt.figure(figsize=(15,7))\nfor i in range(0,11):\n    plt.bar(year_list[i],avg_userrating-avg_user_rating[i],edgecolor='black',label=str(year_list[i]))\n    plt.xticks(year_list)\n    plt.yticks(np.arange(-0.15,0.11,0.025))\n    plt.xlabel('Years')\n    plt.ylabel('User Rating')\n    plt.title('Avg User Rating (For each Year) Difference from Avg User Rating i.e 4.61')\n    plt.grid(linewidth=0.5)\n    plt.legend()","2feae212":"### Book with the most Reviews is printed below along with it's other attributes","b0b61637":"### The following graph shows the difference between the Overall Avg User Rating and the Rating for each particular year\n- `From 2014 the Avg User Rating was lower than the overall Avg User Rating.`","8be7efdd":"# Importing Visualization Libraries","c9bbe3cf":"### Plotting the Frequency of User Ratings for individual year\n- `Having a User Rating between 4.6 to 4.8 is the general trend over the years.`\n- `Years 2012-2015 had 1 book each with User Rating below 4.`\n- `For the years 2018 and 2019 the majority User Rating was 4.8 which indicates that people preferred buying highly rated books.`","0e00a403":"### Plotting the Density Graph for Price in accordance to User Rating\n- `By taking a look at the graphs we can understand that majority bestsellers were in the price range of 5 to 30 and between 4.6 and 4.8 User Rating.`","90fb0251":"# Reading the Dataset using Pandas Library","1172aab3":"### Following Bar chart shows the Average Price for each Year\n- `We can see a downward trend in the last 4 years which means the bestsellers became cheap during that period.`\n- `2015 had the lowest Avg Price out of all the years which also marked the beginning of the downward trend.`","10b3a3ed":"### Encoding the Categorical Varible : Genre in both the dataframes","0a4aae78":"### Creating a dataframe with Duplicates removed from original dataframe","ef3a0fb0":"### A Horizontal Bargraph showing the Authors who appeared the most in Top 50 over the period 2009-2019\n**NOTE:**`This graph contains duplicates as well hence these appearences are not unique ones.`","a932f47c":"### Splitting the data into Respective Years","9659fddc":"# Amazon Top 50 Books Bestsellers for the Period 2009-2019\n<img src='https:\/\/img.huffingtonpost.com\/asset\/563814a51800002b00303a59.png?cache=8jlhc7dj9k&ops=1910_1000' title='Amazon Top 50 Books Bestsellers for the Period 2009-2019'\/>  ","5d09a90c":"### Plotting 2 Graphs to visualize the Genre Count in Data\n- Graph 1 : Genre classes count with duplicates\n- Graph 2 : Genre classes count without duplicates\n#### We can infer from this that Non-Fiction Books are more popular than Fiction in the Top 50 Bestsellers","59de8045":"# CONTENT\n- [Reading the Dataset](#Reading-the-Dataset-using-Pandas-Library)\n- [Importing Visualization Libraries](#Importing-Visualization-Libraries)\n- [Data Visualization and Analysis](#Data-Visualization-and-Analysis)\n- [The End](#The-End)","0f5d5f8c":"# The End\n`If you liked the notebook then don't forget to upvote and suggestions are always welcomed.`\n`Follow me on Linkedin :` __[Atharva_Dumbre](https:\/\/www.linkedin.com\/in\/atharva-dumbre-208b5716b)__","39c44d86":"### Following Bar chart shows the Average Reviews for each Year\n- `2014 and 2019 have the highest avg review indicating the bestsellers in those years have high ratings than other years.`\n- `2009,2010,2011 had the lowest avg compared to other years which maybe due to less reviewing done at that time.`","618a990d":"# Data Visualization and Analysis","e727d30e":"### Average Values of Reviews,Price and User Rating for the period of 2009-2019 :","87783977":"### Top 3 Authors with the most number of highest rated books without duplicates","7560d67f":"### Plotting the Density Graph for Reviews in accordance to User Rating\n- `From this graph the majority bestsellers have reviews in the range of 0 to 20k and User Rating between 4.5 and 4.8`"}}