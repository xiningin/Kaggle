{"cell_type":{"42b61d96":"code","64bf7da8":"code","b20eb621":"code","ee77bc59":"code","5c201398":"code","c45add5b":"code","63008901":"code","e29fcdb1":"code","10bb6cc1":"code","ab67d4b2":"code","9380579c":"markdown","474c8f84":"markdown","658365b8":"markdown","9fe8100e":"markdown","5e47e516":"markdown","81b3441c":"markdown","41b76a7e":"markdown","2de141f5":"markdown"},"source":{"42b61d96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nfrom matplotlib import pyplot as plt\nimport csv\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Activation, Flatten, Dense, MaxPooling2D, Dropout\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","64bf7da8":"with open('\/kaggle\/input\/simple-cnn\/train.pkl', 'rb') as fhand:\n    x_train = pickle.load(fhand)\ny_train = pd.read_csv('\/kaggle\/input\/simple-cnn\/train.csv').to_numpy()","b20eb621":"indices = np.random.choice(len(x_train), 10)\nx_samples = x_train[indices]\ny_samples = y_train[indices]\nfor idx, (im, label) in enumerate(zip(x_samples, y_samples)):\n    plt.imshow(im)\n    plt.title(label[1])\n    plt.show()","ee77bc59":"classes = sorted(np.unique(y_train[:,1]))\nle = LabelEncoder()\nle.fit(classes)\nprint(le.classes_)\nlabels = le.transform(y_train[:,1])\ny_train = keras.utils.to_categorical(labels, 10)","5c201398":"input_shape = (32, 32, 3)\nmodel = Sequential([\n    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    Dropout(0.5),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.25),\n    Dense(10, activation='softmax')\n])","c45add5b":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])","63008901":"train_x, test_x, train_y, test_y = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\nmodel.fit(train_x, train_y,\n          batch_size=16,\n          epochs=3,\n          verbose=1,\n          validation_data=(test_x, test_y))","e29fcdb1":"with open(\"\/kaggle\/input\/simple-cnn\/train.pkl\",\"rb\") as fhand:\n    x_test = pickle.load(fhand)\ny_pred = model.predict(x_test)","10bb6cc1":"pred_label = np.argmax(y_pred, axis=-1)\npred_classes = le.inverse_transform(pred_label)","ab67d4b2":"with open('submission.csv', 'w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow([\"Id\", \"Category\"])\n    for idx, label in enumerate(pred_classes):\n        writer.writerow([idx, label])","9380579c":"# Prepare the result for submission[](http:\/\/)","474c8f84":"# Create a simple model","658365b8":"# Categorical","9fe8100e":"Build a sequential model","5e47e516":"The classes we have","81b3441c":"# Import necessary packages","41b76a7e":"# Load training data, do some visualization","2de141f5":"Compile with loss and optimizer"}}