{"cell_type":{"95170707":"code","358d5b39":"code","4fccc566":"code","4ccb1751":"code","8e77653e":"code","c8f6bb10":"code","a9aeee2a":"code","ff8482ba":"code","8cd85956":"code","3f0ef0a2":"code","0b2511f5":"code","df15af69":"code","148be44e":"code","e673a88f":"code","8ff29179":"code","45dddcdc":"code","e1748efe":"code","c055df78":"code","204736da":"code","e0c626f6":"code","a7ba465b":"code","5d333c4b":"code","669087c1":"code","f69a4bea":"code","ac13e7bb":"code","f1e6470f":"code","4e07b370":"code","2658ba15":"code","45edbda2":"code","f87b5ec6":"code","1b224d86":"code","6aaaeafe":"code","e3606bae":"code","fa5b5e00":"code","8f8e2013":"code","c049a48b":"code","e85f0ee8":"code","02a282d4":"markdown","2d5758b4":"markdown","d9f949ad":"markdown","05df80a0":"markdown","c7fd4423":"markdown","3e0ba74f":"markdown","b9404089":"markdown","d90a95a4":"markdown","489b4bc3":"markdown","dabbc789":"markdown","867b90ae":"markdown","22314e60":"markdown","c2882185":"markdown","6290877a":"markdown"},"source":{"95170707":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","358d5b39":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom pandas.plotting import register_matplotlib_converters\nimport seaborn as sns\nimport datetime\nimport time\nimport os","4fccc566":"register_matplotlib_converters()\nplt.style.use('default')","4ccb1751":"pd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 20) ","8e77653e":"path = '\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv'\ndataset = pd.read_csv(path, parse_dates=['date'])\ndataset","c8f6bb10":"dataset.info()","a9aeee2a":"# calculating CPM\n# calculating the value that the Advertisers Bid for the month of June\n# CPM(the value which was the winning bid value) = \\\n#     ((revenue of the publisher * 100) \/ revenue_share_percentage) \\\n#     \/ measurable_impressions) * 1000\n\ndef weird_division(n, d):\n    return n \/ d if d else 0\n\ndataset['CPM'] = dataset.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)","ff8482ba":"mask = dataset['CPM'] < 0\ndataset.drop(dataset.index[mask], inplace=True)","8cd85956":"mask = dataset['CPM'] >= dataset.CPM.quantile(q=0.95)\ndataset.drop(dataset.index[mask], inplace=True)","3f0ef0a2":"dataset['CPM'].describe()","0b2511f5":"dataset.drop(columns='total_revenue', inplace=True)","df15af69":"dataset.info()","148be44e":"from sklearn.model_selection import train_test_split\nfrom datetime import datetime","e673a88f":"train_data = datetime(2019, 6, 21)\ntarget_col = 'CPM'","8ff29179":"mask = dataset['date'] <= train_data\ntrain = dataset.loc[mask]\ntarget = train.pop(target_col)\ntest = dataset.loc[~mask]\ntarget_test = test.pop(target_col)\ntrain.shape, target.shape, test.shape, target_test.shape","45dddcdc":"ax = target.hist(bins=50)\nax.set(title=target.name)\nplt.box(False)\nplt.show()","e1748efe":"for col in train.columns:\n    ax = train[col].hist(bins=50,)\n    ax.set(title=col)\n    plt.box(False)\n    plt.show()\n#     break","c055df78":"exluded_cols = ['date', 'integration_type_id', 'revenue_share_percent']","204736da":"from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler","e0c626f6":"cols = list(set(train.columns) - set(exluded_cols))\nfeatures_pipe = ColumnTransformer([\n    ('numeric', StandardScaler(), cols),\n]) # , n_jobs=-1","a7ba465b":"x_train = features_pipe.fit_transform(train)\nx_train.shape","5d333c4b":"x_test = features_pipe.transform(test)\nx_test.shape","669087c1":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ShuffleSplit\nfrom sklearn.dummy import DummyRegressor\nfrom scipy.stats import uniform\nfrom sklearn.metrics import make_scorer","f69a4bea":"def show_search_results(search):\n    cols = ['rank_test_score','params','mean_test_score','std_test_score',]\n    df = pd.DataFrame({k:search.cv_results_[k] for k in cols}).set_index('rank_test_score') \\\n        .sort_index()\n    return df\n# show_search_results(search)","ac13e7bb":"scores = list()\nfor i in range(int(target.max())):\n    score = list()\n    y_pred = np.repeat(i, len(target))\n    score.append(mean_squared_error(target, y_pred))\n    y_pred = np.repeat(i, len(target_test))\n    score.append(mean_squared_error(target_test, y_pred))\n    scores.append(score)\n# scores","f1e6470f":"df = pd.DataFrame(scores, columns=['train','test'])\ndf.nsmallest(5, 'train', keep='all')","4e07b370":"df.plot()\nplt.grid()\nplt.box(False)","2658ba15":"search_params = {\n    'constant': range(int(target.max())),\n}","45edbda2":"x_train = features_pipe.fit_transform(train)\nss1 = ShuffleSplit(n_splits=1, test_size=0.99999)\nsearch = GridSearchCV(DummyRegressor(strategy='constant'), search_params, \n                      scoring='neg_mean_squared_error', \n                      cv=ss1, n_jobs=-1)\nsearch.fit(x_train, target)","f87b5ec6":"show_search_results(search).head(5)","1b224d86":"const_pipe = Pipeline([\n    ('dummy', DummyRegressor(strategy='constant')),\n])","6aaaeafe":"search_params = {\n    'dummy__constant': uniform(loc=0, scale=int(target.max())),\n}","e3606bae":"ss1 = ShuffleSplit(n_splits=1, test_size=0.99999, random_state=42)\nsearch = RandomizedSearchCV(const_pipe, search_params, scoring='neg_mean_squared_error',\n                        random_state=42, n_jobs=-1, n_iter=100, cv=ss1)\nsearch.fit(x_train, target)","fa5b5e00":"show_search_results(search).head(5)","8f8e2013":"from xgboost import XGBRegressor","c049a48b":"mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)","e85f0ee8":"# model = XGBRegressor(n_estimators=147, learning_rate=0.17, max_depth=9,\nmodel = XGBRegressor(n_estimators=177, learning_rate=0.17, max_depth=9,\n                     n_jobs=-1, objective='reg:squarederror', random_state=42)\nmodel.fit(x_train, target,\n    verbose=False,\n)\nscore = mse_scorer(model, x_test, target_test)\nprint('MSE score:', score)","02a282d4":"## Data load","2d5758b4":"### XGBRegressor Fit","d9f949ad":"#### Numerical search of optimal value","05df80a0":"### Constant benchmark","c7fd4423":"## EDA","3e0ba74f":"### Features","b9404089":"## Modeling","d90a95a4":"## General","489b4bc3":"### Libraries","dabbc789":"### Dataset.csv","867b90ae":"### train_test_split","22314e60":"#### RandomizedSearchCV DummyRegressor","c2882185":"#### GridSearchCV DummyRegressor","6290877a":"### Analysis"}}