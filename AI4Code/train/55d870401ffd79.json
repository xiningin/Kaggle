{"cell_type":{"efc944e7":"code","37acf721":"code","b627716f":"code","e615b098":"code","3876e920":"code","c6e76e2d":"code","693de3c4":"code","e234371d":"code","52b3a332":"code","f7d36de2":"code","7594bcf2":"code","e219a822":"code","633584f2":"code","1c6e1959":"code","f6965dae":"code","9b3c06fc":"code","23e7647e":"code","80550216":"code","5edaf47e":"code","6ba6c14e":"code","778a06ed":"code","383e7feb":"code","9480b48b":"code","20759b8e":"code","7f48b3e9":"code","21b2be4d":"code","c58eaefb":"code","7eb7344b":"code","9219f035":"code","df356261":"code","bad273b2":"code","33a3c1d6":"code","6a02550f":"code","075ef22a":"code","7c924e48":"code","505a7c84":"code","06a460f2":"code","18d76511":"code","f3411541":"code","300ce47a":"code","c97c959f":"code","74d1cd79":"code","2062c756":"code","f0a8f6fd":"code","529cf131":"code","dc043558":"code","cb84f51a":"code","42d2cb0f":"code","a54cf762":"code","15961404":"code","1a39b368":"code","4a2b789c":"code","f3c181d4":"code","70d22e7b":"code","b3acc8d8":"code","1c0170c0":"code","eb4bc286":"code","d855243c":"code","bd44c133":"code","8917b313":"code","7cf621b7":"markdown","f3d9a4e9":"markdown","f63bda26":"markdown","f79688be":"markdown","4c82369f":"markdown","bf9a9ac0":"markdown","9c83db48":"markdown","a94db607":"markdown","f1638f51":"markdown","66478f16":"markdown","eb7b4297":"markdown","8f63ca8b":"markdown","bde399de":"markdown","45e2f7d1":"markdown","1e276408":"markdown","982344ed":"markdown","99f64f25":"markdown","9fe632ff":"markdown","e0b39594":"markdown","9d38490b":"markdown","55109dd0":"markdown","c1d7385e":"markdown","d9ba3a0f":"markdown","d2f2939f":"markdown","4d254665":"markdown"},"source":{"efc944e7":"# Data Prep and Visuals\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#set max rows and columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import plot_tree\n\n# Evaluation\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report\n\n# Cross Validation\nfrom sklearn.model_selection import GridSearchCV","37acf721":"# Read the data frame\ndf = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","b627716f":"# Display the top 5 rows\ndf.head()","e615b098":"# Statistical Summary\ndf.describe()","3876e920":"# Main Info\ndf.info()","c6e76e2d":"# convert TotalCharges to float\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)","693de3c4":"# trying to catch the cause of the problem\ndf[\"TotalCharges\"].value_counts()[:5]","e234371d":"# the rows with the problem\ndf[df.TotalCharges == \" \"]","52b3a332":"# fill in the values causing the problem \nmode = df[\"TotalCharges\"].mode()[1]\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].apply(lambda x: x.replace(\" \", mode))","f7d36de2":"# convert TotalCharges to float\ndf[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"])","7594bcf2":"#Lets Check if it is actually corrected\ndf.info()","e219a822":"# check for nulls\nnulls = df.isna().sum()\npd.DataFrame(data = nulls, columns = [\"Nulls\"]).reset_index()","633584f2":"# Display column names\ndf.columns","1c6e1959":"df[df.columns[1]].unique()","f6965dae":"# Feature 2\ndf[df.columns[2]].unique()","9b3c06fc":"# Feature 3\ndf[df.columns[3]].unique()","23e7647e":"# Feature 4\ndf[df.columns[4]].unique()","80550216":"# Feature 5\ndf[df.columns[5]].unique()","5edaf47e":"# Feature 6\ndf[df.columns[6]].unique()","6ba6c14e":"# Feature 7\ndf[df.columns[7]].unique()","778a06ed":"# Feature 8\ndf[df.columns[8]].unique()","383e7feb":"# Feature 9\ndf[df.columns[9]].unique()","9480b48b":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.countplot(data = df, x = \"Churn\")\nplt.show()","20759b8e":"# The distrbution of TotalCharges between Churn categories with a Box Plot\nplt.figure(figsize = (8, 4), dpi = 100)\nsns.boxplot(data = df, x = \"Churn\", y = \"TotalCharges\")\nplt.show()","7f48b3e9":"#The distribution of TotalCharges per Contract type\nplt.figure(figsize = (8, 4), dpi = 100)\nsns.boxplot(data = df, x = \"Contract\", y = \"TotalCharges\", hue = \"Churn\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()","21b2be4d":"# The distrbution of MonthlyCharges between Churn categories with a Box Plot\nplt.figure(figsize = (8, 4), dpi = 100)\nsns.boxplot(data = df, x = \"Churn\", y = \"MonthlyCharges\")\nplt.show()","c58eaefb":"#The distribution of MonthlyCharges per Contract type\nplt.figure(figsize = (8, 4), dpi = 100)\nsns.boxplot(data = df, x = \"Contract\", y = \"MonthlyCharges\", hue = \"Churn\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()","7eb7344b":"# The distrbution of SeniorCitizen between Churn categories with a Box Plot\nplt.figure(figsize = (8, 4), dpi = 100)\nsns.countplot(data = df, x = \"SeniorCitizen\", hue = 'Churn')\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()","9219f035":"# Select the subset of features \ncorr_feats = df.drop(\"customerID\", axis = 1)","df356261":"# convert them to dummy vars\ncorr_feats = pd.get_dummies(corr_feats)","bad273b2":"# create the correlation matrix\ncorr_feats.head()","33a3c1d6":"# calculate the correlation matrix\ncorr_array = corr_feats.corr()\ncorr_array = corr_array[\"Churn_Yes\"][1: len(corr_array.index) - 1].sort_values()\ncorr_array","6a02550f":"# vosulaize the correlation array\nplt.figure(figsize = (10, 4), dpi = 100)\nsns.barplot(x = corr_array.index, y = corr_array.values)\nplt.xticks(rotation = 90)\nplt.show()","075ef22a":"# What are the 3 contract types available?\ndf['Contract'].unique()","7c924e48":"# Histogram displaying the distribution of 'tenure' column\nplt.figure(figsize = (10, 4), dpi = 100)\nsns.histplot(data = df, x = \"tenure\", bins = 60)\nplt.show()","505a7c84":"# Create histograms separated by two additional features, Churn and Contract\nplt.figure(figsize=(10,3),dpi=200) \nsns.displot(data=df,x='tenure',bins=70,col='Contract',row='Churn');","06a460f2":"#Display a scatter plot of Total Charges versus Monthly Charges, and color hue by Churn\nplt.figure(figsize=(10,4),dpi=200)\nsns.scatterplot(data=df,x='MonthlyCharges',y='TotalCharges',hue='Churn', alpha=0.5, palette='Dark2', linewidth=0.5)\nplt.show()","18d76511":"# churn rate per months of tenure\nno_churn = df.groupby(['Churn','tenure']).count().transpose()['No']\nyes_churn = df.groupby(['Churn','tenure']).count().transpose()['Yes']\n\nchurn_rate = 100 * yes_churn \/ (no_churn+yes_churn)\nchurn_rate = churn_rate.transpose()['customerID'][1:]\nchurn_rate","f3411541":"# churn rate per months of tenure\nplt.figure(figsize=(10,4),dpi=200)\nchurn_rate.plot()\nplt.show()","300ce47a":"def cohort(tenure):\n    if tenure < 13:\n        return '0-12 Months'\n    elif tenure < 25:\n        return '12-24 Months'\n    elif tenure < 49:\n        return '24-48 Months'\n    else:\n        return \"Over 48 Months\"\n    \ndf['Tenure Cohort'] = df['tenure'].apply(cohort)","c97c959f":"df.head(10)[['tenure','Tenure Cohort']]","74d1cd79":"# reate a scatterplot of Total Charges versus Monthly Charts,colored by Tenure Cohort\nplt.figure(figsize=(10,4),dpi=200)\nsns.scatterplot(data=df,x='MonthlyCharges',y='TotalCharges',hue='Tenure Cohort', alpha=0.5, palette='Dark2', linewidth=0.5)\nplt.show()","2062c756":"# Create a count plot showing the churn count per cohort\nplt.figure(figsize=(10,4),dpi=200)\nsns.countplot(data=df,x='Tenure Cohort',hue='Churn');","f0a8f6fd":"#Create a grid of Count Plots showing counts per Tenure Cohort, separated out by contract type\nplt.figure(figsize=(10,4),dpi=200)\nsns.catplot(data=df,x='Tenure Cohort',hue='Churn',col='Contract',kind='count')\nplt.show()","529cf131":"# X, y split\nX = df.drop(\"Churn\", axis = 1)\ny = df[\"Churn\"]","dc043558":"# dummies\nX = pd.get_dummies(X)","cb84f51a":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101)","42d2cb0f":"# Feature Scaling\nscaler = StandardScaler()\nscaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","a54cf762":"# initiate the model\nmodel = DecisionTreeClassifier(max_depth = 3)\n\n# fit the model\nmodel.fit(scaled_X_train, y_train)\n\n# predict\npreds = model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(model, scaled_X_test, y_test, ax = ax);","15961404":"# plot the tree\nplt.figure(figsize=(12,8),dpi=200)\nplot_tree(model,filled=True);","1a39b368":"# Hyper Parameter tuning\nparam_grid = {\n    'criterion': [\"gini\", \"entropy\"],\n    'max_depth': [1, 2, 3, 4, 5]\n}","4a2b789c":"# initiating the grid model\ngrid_model = GridSearchCV(model, param_grid)\n\n# fit the grid model\ngrid_model.fit(scaled_X_train, y_train)","f3c181d4":"# predict \npreds = grid_model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(grid_model, scaled_X_test, y_test, ax = ax);","70d22e7b":"# initiate the model\nmodel = RandomForestClassifier()\n\n# fit the model\nmodel.fit(scaled_X_train, y_train)\n\n# predict\npreds = model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(model, scaled_X_test, y_test, ax = ax);","b3acc8d8":"# initiate the model\nmodel = GradientBoostingClassifier()\n\n# fit the model\nmodel.fit(scaled_X_train, y_train)\n\n# predict\npreds = model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(model, scaled_X_test, y_test, ax = ax);","1c0170c0":"# Hyper Parameter tuning\nparam_grid = {\"n_estimators\":[1,5,10,20,40,100],'max_depth':[3,4,5,6]}","eb4bc286":"# initiating the grid model\ngrid_model = GridSearchCV(model, param_grid)\n\n# fit the grid model\ngrid_model.fit(scaled_X_train, y_train)","d855243c":"# predict \npreds = grid_model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(grid_model, scaled_X_test, y_test, ax = ax);","bd44c133":"# initiate the model\nmodel = SVC()\n\n# fit the model\nmodel.fit(scaled_X_train, y_train)\n\n# predict\npreds = model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(model, scaled_X_test, y_test, ax = ax);","8917b313":"# initiate the model\nmodel = KNeighborsClassifier()\n\n# fit the model\nmodel.fit(scaled_X_train, y_train)\n\n# predict\npreds = model.predict(scaled_X_test)\n\n# print accuracy score \nprint(accuracy_score(y_test,preds))\n\n# plot confusion matrix\nfig, ax = plt.subplots(figsize=(6, 6), dpi = 100)\nplot_confusion_matrix(model, scaled_X_test, y_test, ax = ax);","7cf621b7":"<a id  = 'bt'><\/a>\n#### **- Boosted Trees** ","f3d9a4e9":"TotalCharges is stored as object, where in fact it should be float. Lets fix that. \nIf you run the following line of code it will result in an AttributeError: 'str' object has no attribute 'astype'. This means that the column has a string value instead of a number in one of the rows. In order to pick which row, we will run the pd.value_counts() fuction.","f63bda26":"<a id = \"check\"><\/a>\n<h2 style=\"background-color:#f15a39; padding: 20px; font-family:cursive\">2. Quick Data Check<\/h2>","f79688be":"<h2 style=\"background-color:#f15a39; padding: 20px; font-family:cursive\">Outline<\/h2>\n\n1. [Package Imports](#imports)\n2. [Quick Data Check](#check)\n    - [Read the data](#read)\n    - [Fix misspecified feature types](#fix)\n    - [Check for null values](#nulls)\n    - [Validate the value range of each feature](#valid)\n3. [Exploratory Data Analysis](#explore)\n    - [Display the balance of the class labels (Churn)](#balance)\n    - [Distribution of main variables](#dist)\n    - [Correlation analysis](#corr)\n4. [Churn Analysis](#churn)\n    - [Creating Cohorts based on Tenure](#chorot)\n5. [Predictive Modeling](#preds)\n    - [Single Decision Tree](#tree)\n    - [Random Forest](#rs)\n    - [Boosted Trees](#bt)\n    - [Support Vector Machine](#svm)\n    - [KNN Classifier](#knn)","4c82369f":"There is no nulls null values","bf9a9ac0":"<a id = \"read\"><\/a>\n#### **- Read the data**","9c83db48":"<a id = \"balance\"><\/a>\n#### **- Display the balance of the class labels (Churn)**","a94db607":"<a id  = 'tree'><\/a>\n#### **- Single Decision Tree** ","f1638f51":"<a id  = 'svm'><\/a>\n#### **- Support Vector Machine** ","66478f16":"The values of all features are in the expected range according to the definition of each variable in the dataset.","eb7b4297":"Based on the tenure column values, create a new column called Tenure Cohort that creates 4 separate categories:\n- '0-12 Months'\n- '24-48 Months'\n- '12-24 Months'\n- 'Over 48 Months'","8f63ca8b":"<a id = 'chorot'><\/a>\n#### **- Creating Cohorts based on Tenure**\n\nLet's begin by treating each unique tenure length, 1 month, 2 month, 3 month...N months as its own cohort. Treating each unique tenure group as a cohort, calculate the Churn rate (percentage that had Yes Churn) per cohort. We should have cohorts 1-72 months with a general trend of the longer the tenure of the cohort, the less of a churn rate. This makes sense as you are less likely to stop service the longer you've had it.","bde399de":"The classes are inbalanced, we need to take that into consideration when buildin the model.  ","45e2f7d1":"<a id = \"fix\"><\/a>\n#### **- Fix misspecified feature types**","1e276408":"<a id = 'dist'><\/a>\n#### **- Distribution of main variables**","982344ed":"<a id = \"imports\"><\/a>\n<h2 style=\"background-color:#f15a39; padding: 20px; font-family:cursive\">1. Package Imports<\/h2>","99f64f25":"<a id = \"explore\"><\/a>\n<h2 style=\"background-color:#f15a39; padding: 20px; font-family:cursive\">3. Exploratory Data Analysis<\/h2>","9fe632ff":"<a id  = 'knn'><\/a>\n#### **- KNN Classifier** ","e0b39594":"<a id = \"preds\"><\/a>\n<h2 style=\"background-color:#f15a39; padding: 20px; font-family:cursive\">5. Predictive Modeling<\/h2>","9d38490b":"<a id = \"nulls\"><a\/>\n#### **- Check for null values**","55109dd0":"<a id = \"valid\"><\/a>\n#### **- Validate the value range of each feature**","c1d7385e":"<a id  = 'rs'><\/a>\n#### **- Random Forest** ","d9ba3a0f":"<a id = 'corr'><\/a>\n#### **- Correlation analysis**\n\nWe specifically listed only the features belo, we should not check the correlation for every feature, as some features have too many unique instances for such an analysis, such as customerID.\n\nKeep in mind, for the categorical features, we will need to convert them into dummy variables first, as you can only calculate correlation for numeric features.","d2f2939f":"Now all features are in the correct type","4d254665":"<a id = \"churn\"><\/a>\n<h2 style=\"background-color:#f15a39; padding: 20px; font-family:cursive\">4. Churn Analysis<\/h2>\n\nThis section focuses on segementing customers based on their tenure, creating \"cohorts\", allowing us to examine differences between customer cohort segments."}}