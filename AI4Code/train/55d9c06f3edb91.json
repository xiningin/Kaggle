{"cell_type":{"6eff1d51":"code","9231bf1c":"code","2f10d95d":"code","4fd80cda":"code","e83f02df":"code","ce7cecce":"code","1fabbc8f":"code","303cc17a":"code","a2cc867b":"code","bc027335":"code","d3455221":"code","0d0f591d":"code","a6de561e":"code","f3ce5358":"code","cc390664":"code","96fd9e6f":"code","dc7f263a":"code","f788417e":"code","1c0179f4":"code","be299c00":"code","2125b6c2":"code","67148bec":"code","abad2fbe":"code","f3bcc077":"code","a6e75602":"code","5fbd15c9":"code","08078540":"code","7271f5e8":"code","06361777":"markdown","e5793dca":"markdown","2f8cb631":"markdown","e822309a":"markdown","6d18135e":"markdown","d2970d71":"markdown","9a30e76b":"markdown","87fa4480":"markdown","2e3f8371":"markdown","2644840e":"markdown","9969bf34":"markdown","9f97e39f":"markdown","2d52a36e":"markdown","9944fcc1":"markdown","ef0d5d62":"markdown","ac6d8602":"markdown","ec000d7f":"markdown","fb00d132":"markdown","2789f1ab":"markdown","2b852d1e":"markdown","2a41e977":"markdown","f61e0989":"markdown"},"source":{"6eff1d51":"import os\nimport glob\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","9231bf1c":"%matplotlib inline\nsns.set()","2f10d95d":"labels = os.listdir(os.path.join('..', 'input', 'flowers-recognition', 'flowers'))\nlabels.remove('flowers') #remove reference to parent directory\n\nprint(labels)","4fd80cda":"class_path_dict = {\n    label: glob.glob(os.path.join('..', 'input', 'flowers-recognition', \n                                  'flowers', label, '*'))\n    for label in labels\n}","e83f02df":"df_data = []\n\nfor key, value in class_path_dict.items():\n    for path in value:\n        df_data.append([key, path])\n        \ndf_data = np.array(df_data)","ce7cecce":"dataframe = pd.DataFrame(df_data,\n                         columns=['Label', 'Paths'])\n\ndataframe.head()","1fabbc8f":"fig, ax = plt.subplots(1, 1, figsize=(6, 4))\nax.hist(dataframe['Label'], bins=np.arange(len(labels)+0.5), rwidth=0.5)\nax.set_xticks(np.arange(len(labels))+0.5)\n_ = ax.set_xticklabels(labels, rotation=90)","303cc17a":"train_df, test_df = train_test_split(dataframe, test_size=0.1, \n                                     random_state=np.random.RandomState(123), \n                                     stratify=dataframe['Label'])\n\ntrain_df.head()","a2cc867b":"train_df, valid_df = train_test_split(train_df, test_size=0.05,\n                                      random_state=np.random.RandomState(345),\n                                      stratify=train_df['Label'])\n\ntrain_df.head()","bc027335":"print(f'Training dataset: {len(train_df)}\\nValidation dataset: {len(valid_df)}\\nTest dataset: {len(test_df)}')","d3455221":"BATCH_SIZE = 16\nEPOCHS = 20\nSHUFFLE=True\nIMG_SIZE=224","0d0f591d":"def get_train_generator():\n    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization=True,\n        horizontal_flip=True,\n        rotation_range=10,\n    )\n\n    train_datagen = train_data_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Paths',\n        y_col='Label',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        class_mode='categorical',\n        classes=labels,\n        batch_size=BATCH_SIZE,\n        shuffle=SHUFFLE,\n        seed=597\n    )\n    \n    return train_datagen","a6de561e":"def get_valid_test_generator():\n    \n    raw_datagen = tf.keras.preprocessing.image.ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Paths',\n        y_col='Label',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        class_mode='categorical',\n        classes=labels,\n        batch_size=BATCH_SIZE,\n        shuffle=SHUFFLE,\n        seed=597\n    )\n\n    batch = next(raw_datagen)\n    data_sample = batch[0]\n    \n    image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization=True\n    )\n    \n    image_data_generator.fit(data_sample)\n\n    valid_datagen = image_data_generator.flow_from_dataframe(\n        dataframe=valid_df,\n        x_col='Paths',\n        y_col='Label',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        class_mode='categorical',\n        classes=labels,\n        batch_size=BATCH_SIZE,\n        shuffle=SHUFFLE,\n        seed=597\n    )\n    \n    test_datagen = image_data_generator.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='Paths',\n        y_col='Label',\n        class_mode='categorical',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        classes=labels,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        seed=597\n    )\n    \n    return valid_datagen, test_datagen","f3ce5358":"train_datagen = get_train_generator()\nvalid_datagen, test_datagen = get_valid_test_generator()","cc390664":"x, y = next(train_datagen)\nfig, axs = plt.subplots(4, 4, figsize=(16, 16))\nfor img, l, ax in zip(x, y, axs.flatten()):\n    ax.imshow(img)\n    ax.set_xlabel(l)\n    ax.axis('off')\nplt.show()","96fd9e6f":"checkpoint_path = '..\/working\/chkpoint.{epoch:02d}-{val_loss:.2f}.hdf5'\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_path,\n    save_weights_only=False,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True,\n    verbose=1\n)\n\nreduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=1e-1,\n    patience=2,\n    min_lr=1e-10,\n    verbose=1\n)\n\nearlystopping_callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10\n)","dc7f263a":"class TrainingMonitorCallback(tf.keras.callbacks.Callback):\n    def __init__(self, save_path):\n        super(TrainingMonitorCallback, self).__init__()\n        self.train_acc = []\n        self.train_loss = []\n        self.save_path = save_path\n        \n    def on_batch_end(self, batch, logs=None):\n        self.train_acc.append(logs['accuracy'])\n        self.train_loss.append(logs['loss'])\n    \n    def on_epoch_end(self, epoch, logs=None):\n        plt.plot(self.train_acc)\n        plt.plot(self.train_loss)\n        \n        plt.title('Model Performance')\n        plt.xlabel('Steps')\n        plt.ylabel('Loss\/Acc')\n        plt.legend(['Train Acc', 'Train Loss'], loc='best')\n        plt.savefig(os.path.join(self.save_path, 'performance.png'))\n        \nperformance_path = '..\/working'\nmonitor_callback = TrainingMonitorCallback(performance_path)","f788417e":"base_model = tf.keras.applications.EfficientNetB0(include_top=False, \n                                                  weights='imagenet',\n                                                  input_shape=(224, 224, 3))\n\n\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(inputs)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.summary()","1c0179f4":"model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])","be299c00":"def train_model(epochs):\n    history = model.fit(\n    train_datagen,\n    epochs=epochs,\n    validation_data=valid_datagen,\n    steps_per_epoch=len(train_datagen),\n    validation_steps=len(valid_datagen),\n    callbacks=[\n         model_checkpoint_callback,\n         reduce_lr_callback,\n         earlystopping_callback,\n         monitor_callback\n     ]\n    )\n    \n    return history\n\nhistory = train_model(50)","2125b6c2":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\nplt.title('Model Performance')\nax.plot(history.history['loss'])\nax.plot(history.history['val_loss'])\nax.grid('off')\nax.set_xlabel('epoch')\nax.set_ylabel('Loss\/Acc')\nax.legend(['Train Loss', 'Val Loss'], loc='best')\n\nplt.show()\n\n# ax[0].plot(history.history['accuracy'])\n# ax[0].plot(history.history['loss'])\n# ax[0].grid('off')\n# ax[0].set_xlabel('epoch')\n# ax[0].set_ylabel('Loss\/Acc')\n# ax[0].legend(['Train Acc', 'Train Loss'], loc='best')\n\n# ax[1].plot(history.history['val_accuracy'])\n# ax[1].plot(history.history['val_loss'])\n# ax[1].grid('off')\n# ax[1].set_xlabel('epoch')\n# ax[1].set_ylabel('Loss\/Acc')\n# ax[1].legend(['Val Acc', 'Val Loss'], loc='best')","67148bec":"model.evaluate(test_datagen)","abad2fbe":"predicted = model.predict(test_datagen)","f3bcc077":"y_pred = np.argmax(predicted, axis=1)\n\ny_true = np.array(test_datagen.labels)","a6e75602":"def plot_confusion_matrix(mat, target_names, title='Confusion Matrix', cmap=None):\n    accuracy = np.trace(mat) \/ float(np.sum(mat))\n    misclass = 1 - accuracy\n    \n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(mat, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.grid('off')\n    plt.show()","5fbd15c9":"from sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(y_true, y_pred)\nplot_confusion_matrix(mat, labels)","08078540":"mat","7271f5e8":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_true, y_pred, target_names=labels))","06361777":"Lets create a list of list something like `[[<flower-category>, path], [<flower-category>, path], ...]`, this will ease our task of creating a dataframe","e5793dca":"First, lets fix the values of certain hyperparameters.","2f8cb631":"First, lets find all the available categories of flowers ","e822309a":"## Evaluation\n\nWoow! its time to evaluate our model now.","6d18135e":"### The Model\n\nRecently, I was looking at the keras pretrained factory (the applications module) and was amazed to see the efficiency of the `EfficientNet`s. So, I gave a try to EfficientNetB0 as the number of parameters it has are extremely less. ","d2970d71":"Well, I like to keep a validation set too. So, let split the training data again into training and validation split, keeping 85% of the data for training and 5% of data for validation.","9a30e76b":"Hmm...The evaluation seems fine, nothing too great. Lets see if we can imporve it in the next one.","87fa4480":"Finally lets check the amount of data availble to us for training.","2e3f8371":"### Callbacks\n\nTo ease our lives, lets define certain callbacks that will be used during training.\nHere we use - \n* ModelCheckpoint - This callback will take snapshots of our model and save it in our directory based on the parameters we set. So, here we track 'validation loss' and create a checkpoint when it is minimum. Later on we can load this checkpoint and continue where we left off!\n* ReduceLROnPlateau - This callback monitors a metric or loss and reduces the learning rate by the factor we set. So, here we reduce the learning rate if the 'validation loss' does not imporve for two subsequent epoch.\n* EarlyStopping - This callback will stop training when a metric or loss stops changing.","2644840e":"Now, lets split the dataset into train and test set, with a ratio of 0.9:0.1. We use `stratify` to split the data, so as to ensure that each class has same proprotion of data in both the splits.","9969bf34":"Did you notice how the training stopped at epoch 21, well the model **might** have improved on much lower learning rate, but I would like to save my kaggle GPU time for some other project.","9f97e39f":"Let's view few of the training images to ensure everything is fine.","2d52a36e":"Let's make our train, validation and test ImageDatagenerator. Here -\n* For training dataset\n    * We use samplwise standardization\n    * For augmentation, we horizontally flip and set rotation range to 10 deg (both clock and anti clockwise\n\n\n* For validation and test dataset\n    * We take a batch from training set, find its mean and std and use that to standardize it featurewise.\n    * Shuffling is not done in the test dataset","9944fcc1":"We are using the Adam optimizer with a learning rate of 0.0001 (we did try 0.001, but it was large so, we reduced it).","ef0d5d62":"## Model Dev","ac6d8602":"Use `pandas` to create the dataframe and peek at it.","ec000d7f":"## Import Libraries","fb00d132":"From the above plot we can say that we are not extremely short of any category of flower.","2789f1ab":"We also create a custom callback to plot the training accuracy and loss at the end of each epoch.","2b852d1e":"The data seem to be less. But we have transfer learning to our rescue. Let's try out and find it for ourselves.","2a41e977":"Now, lets map all the found labels to their filepaths. We are using the glob module for this task, so what glob function does is it finds all the files or folders matching a given template (Here, `..\/input\/flower-recognition\/flowers\/<flower-category>\/*`, * here represents a wildcard, i.e, anything and everything inside that directory).","f61e0989":"## Data Preprocessing\n\nThere are several ways of preprocessing the dataset. Here we -\n* First, find all the labels\n* Second, create a mapping from label to list of filepaths. (For example : Rose -> [List of all file paths].)\n* Create dataframe for each example with two columns, label and paths.\n* Stratifically, split dataframe into train, validation and test split to have same proportion of data in each split."}}