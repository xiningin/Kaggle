{"cell_type":{"bd99eed0":"code","de3372b3":"code","6ad8a369":"code","a4302610":"code","d8f06dc0":"code","6e593bcf":"code","024c92dd":"code","2e029358":"code","b88f64fd":"code","c7bf8fc8":"code","5dfbdd5b":"code","7fd3b30e":"code","33ce2465":"code","984ead9c":"code","3e09775f":"code","523b1202":"code","19424996":"code","33ba862b":"code","a487dda8":"code","92395a42":"code","f6996313":"code","8e9f7439":"code","7d8692bf":"code","df7b166d":"code","5d9fdb6e":"code","6f2b142c":"code","1a2d526b":"code","b56cca7b":"code","29743d37":"code","d1ca832a":"code","f9da3fee":"code","7d60d291":"code","9b0ce474":"code","b924d292":"code","9183cea4":"code","f6bbf2b8":"code","942dc5ee":"code","087da0e8":"code","6df55270":"code","b220b2b9":"code","b48ef63a":"code","0a28a6cd":"code","9cfab043":"code","8289ea11":"code","38e39322":"code","90055a1b":"code","5654bbc6":"code","ffb5151c":"code","1f54ecda":"code","cf5ed08c":"code","927bd942":"code","7ae9968a":"code","5ae08c97":"code","9e854d8b":"code","53ce726f":"code","2e14e05f":"code","159f051b":"code","b5cdd104":"code","978618da":"code","1d440b2d":"code","a46ce78c":"code","e0f00a06":"code","1cc2b228":"code","1e3e36de":"code","fca576f7":"code","231900d2":"code","daf372bf":"code","340f30fe":"code","fc5ac4c4":"code","9d542e9a":"code","4d9de267":"code","0e2e6b3a":"code","4dcc5d69":"code","846cbc21":"code","6d17f481":"code","4078be45":"code","197c602d":"code","db35180e":"code","c5d8ca30":"code","7f4eb2f8":"code","c677f8cb":"code","6f169c71":"code","cb072bf4":"code","43fe0256":"code","b71ce6ce":"code","2f6c21f6":"code","6b2e62b4":"code","e010ea67":"code","34325f4f":"code","3eb7f370":"code","1be17356":"code","cf298b61":"code","4bdd6c18":"code","0c62eadd":"code","07d9ee44":"code","3ca95652":"code","13a0e9c1":"code","90b4f9e6":"code","d85cfd1c":"code","6a47350d":"code","e6691f77":"code","b4a21b0a":"code","98218deb":"code","e573a3fb":"code","63304d0d":"code","497ff733":"code","9fe1a4dc":"code","53a732fd":"code","7221b685":"code","324bab6d":"code","8a2dbd5d":"code","8c9d4a7f":"code","fbd2e76b":"code","bff9c962":"code","5056b050":"code","1a8b211e":"code","551be691":"code","77d47a21":"code","c9d402a6":"code","d6829336":"code","550c7e46":"code","08ce98c7":"code","028c7ec2":"code","fe04b69f":"code","e2ccb49e":"code","f83c9bfe":"markdown","b41cdd31":"markdown","bbbe9007":"markdown","da2e1a9a":"markdown","3eece9a6":"markdown","b915a62c":"markdown","a7d9ea33":"markdown","a2dbe752":"markdown","a0bfaf1d":"markdown","8960f201":"markdown","b7b5ca60":"markdown","c52cb2a5":"markdown","d525c2e0":"markdown","a1f0fe1c":"markdown","b9d5c792":"markdown","252e230d":"markdown","ebd1c7bd":"markdown","9bd3f733":"markdown","2eb16be3":"markdown","7a4ef0f0":"markdown","16ce51ce":"markdown","dfd9f7d8":"markdown","ae4f95e3":"markdown","e936d74a":"markdown","7ddf0adf":"markdown","39f33e1d":"markdown","374c17a2":"markdown","f071af9a":"markdown","9744a2d9":"markdown"},"source":{"bd99eed0":"import pandas as pd\nimport os","de3372b3":"dataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'\n\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n\ndf.head()","6ad8a369":"df.dtypes","a4302610":"# some summary statistics\n\ndf.describe()","d8f06dc0":"# check what is Data type of Variables\ndf.info()","6e593bcf":"# Checking for null values\npd.isna(df).sum()","024c92dd":"#  look at the histogram of the whole data frame \ndf.hist(figsize=(20,16));","2e029358":"#check if there is an distance with minus \n\ndf[df[\"Distance(mi)\"] < 0]","b88f64fd":"# Check Duplicates\ndf.duplicated(subset=None, keep='first')","c7bf8fc8":"# check if there is any duplicated values in the data \nprint(\"Num of dublicated : \", + sum(df.duplicated()))","5dfbdd5b":"#convert timestamp column that has date object to a datetime datatype\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n\n#nspect ScheduledDay column after converting its datatype from object to datetime\nprint(df['timestamp'].head())","7fd3b30e":"import datetime as dt\ndf['Date'] = [d.date() for d in df['timestamp']]\ndf['new_time'] = [d.time() for d in df['timestamp']]\ndf['Date']=pd.to_datetime(df['Date'])","33ce2465":"df","984ead9c":"side_wise_counts = df.groupby('Side')['Severity'].count()\ndisplay(side_wise_counts)","3e09775f":"df.groupby(['Side'])['Severity'].mean()","523b1202":"Mean_encoded_subject = df.groupby(['Side'])['Severity'].mean().to_dict()\n  \ndf['Side'] =  df['Side'].map(Mean_encoded_subject)\n  \nprint(df)","19424996":"#Add day's column in our data.\n#df['day'] = df['timestamp'].dt.day\n\n#Add Month column in the data.\n#df['month'] = df['timestamp'].dt.month\n#Add Year column in the data.\n#df['year'] = df['timestamp'].dt.year\n#print(df.head())","33ba862b":"df[ (df[\"Crossing\"] == \"True\") & (df[\"Junction\"] == \"True\") ]","a487dda8":"#read weather dataset\ndataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'\n\ndf1 = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df1.shape))\n\ndf1.head()","92395a42":"# check what is Data type of Variables\ndf1.info()","f6996313":"# Checking for null values\npd.isna(df1).sum()","8e9f7439":"#Cleanup some columns by removing Nulls or Filling NaNs\n#Define a funcation impute median\ndef impute_median(series):\n    return series.fillna(series.median())\n\ndef impute_mean(series):\n    return series.fillna(series.mean())\n\ndef impute_mode(series):\n    return series.fillna(series.mode())","7d8692bf":"df1['Wind_Chill(F)'] = df1['Wind_Chill(F)'].transform(impute_median)\nprint(df1['Wind_Chill(F)'])","df7b166d":"\ndf1['Weather_Condition'].fillna(str(df1['Weather_Condition'].mode()), inplace=True)\n","5d9fdb6e":"df1['Precipitation(in)'] = df1['Precipitation(in)'].transform(impute_median)","6f2b142c":"df1['Temperature(F)'] = df1['Temperature(F)'].transform(impute_median)","1a2d526b":"df1['Humidity(%)'] = df1['Humidity(%)'].transform(impute_median)","b56cca7b":"df1['Wind_Speed(mph)'] = df1['Wind_Speed(mph)'].transform(impute_median)","29743d37":"df1['Visibility(mi)'] = df1['Visibility(mi)'].transform(impute_median)","d1ca832a":"# Checking for null values\npd.isna(df1).sum()","f9da3fee":"cols=[\"Year\",\"Month\",\"Day\"]\ndf1['Date'] = df1[cols].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")\nprint(df1['Date'])\ndf1['Date'] = pd.to_datetime(df1['Date'])\ndf1.info()","7d60d291":"df = pd.merge(df,df1,on='Date',how='left')\ndisplay(df.head())\npd.isna(df).sum()","9b0ce474":"# Check Duplicates\ndf.duplicated(subset =None , keep ='first')","b924d292":"print(df.info())","9183cea4":"# Create a summary of average Severity by Weather_Condition `severity_by_weather`\n#severity_by_weather = df.groupby('Weather_Condition')['Severity'].count()\n\n\n# Plot trends in average number of parts by year\n#print(severity_by_weather)","f6bbf2b8":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(30, 10))\nplt.title('Number of Accidents due to Weather_Conditions')\nplt.bar(severity_by_weather.index, severity_by_weather.values, color='r')\nplt.xlabel('Weather Conditions')\nplt.ylabel('Number of Accidents')\nplt.xticks(severity_by_weather.index, rotation='vertical', size=10)\nplt.show()","942dc5ee":"df[\"Weather_Condition\"] = df[\"Weather_Condition\"].astype('category')\ndf.dtypes\ndf[\"Weather_Condition\"].value_counts()","087da0e8":"#df[\"Weather_Condition\"] = np.where(df[\"Weather_Condition\"].str.contains(\"Partly Cloudy\",\"Mostly Cloudy\",\"Fair\",\"Overcast\"), 1, 0)","6df55270":"df.groupby(['Weather_Condition'])['Severity'].count()","b220b2b9":"df.groupby(['Weather_Condition'])['Severity'].mean()","b48ef63a":"Mean_encoded_subject = df.groupby(['Weather_Condition'])['Severity'].mean().to_dict()\n  \ndf['Weather_Condition'] =  df['Weather_Condition'].map(Mean_encoded_subject)\n  \nprint(df)","0a28a6cd":"severity = df.groupby('Severity').count()\nseverity","9cfab043":"import xml.etree.ElementTree as ET\nimport pandas as pd\n\n\ntree = ET.parse(\"\/kaggle\/input\/car-crashes-severity-prediction\/holidays.xml\")\nroot = tree.getroot()\n\nget_range = lambda col: range(len(col))\nl = [{r[i].tag:r[i].text for i in get_range(r)} for r in root]\n\ndf_convert_xml = pd.DataFrame.from_dict(l)\ndf_convert_xml.to_csv('holidays.csv')\n\n\n\n\n","8289ea11":"dataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'\ndf_xml = pd.read_csv('holidays.csv')\nprint(df_xml.head())\ndf_xml['date'] = pd.to_datetime(df_xml['date'])\n","38e39322":"#df['description'].fillna(str(df['description'].mode()), inplace=True)\ndf['Unnamed: 0'] = df['Unnamed: 0'].fillna(0)\ndf['date'] = df['date'].fillna(0)\ndf['description'] = df['description'].fillna(0)\n\npd.isna(df).sum()","90055a1b":"df = pd.merge(df,df_xml,left_on='Date',right_on='date',how='left')\ndisplay(df.head())\npd.isna(df).sum()","5654bbc6":"df['holiday']=''\nfor index, row in df.iterrows():\n    if df.date[index] == df.date_weather[index]:\n        df.holiday[index] = 1\n    else:\n        df.holiday[index] = 0\ndf","ffb5151c":"df[\"Crossing\"] = df[\"Crossing\"].astype(int)","1f54ecda":"df[\"Give_Way\"] = df[\"Give_Way\"].astype(int)\ndisplay(df[\"Give_Way\"])","cf5ed08c":"df[\"Junction\"] = df[\"Junction\"].astype(int)","927bd942":"\ndf[\"No_Exit\"] = df[\"No_Exit\"].astype(int)","7ae9968a":"df[\"Railway\"] = df[\"Railway\"].astype(int)","5ae08c97":"\ndf[\"Roundabout\"] = df[\"Roundabout\"].astype(int)","9e854d8b":"\ndf[\"Stop\"] = df[\"Stop\"].astype(int)","53ce726f":"\ndf[\"Amenity\"] = df[\"Amenity\"].astype(int)","2e14e05f":"# Convert side to 0\/ 1\n#Right -> 1\n#Left -> 0\ncleanup_nums = {\"Side\":     {\"R\": 1, \"L\": 2}}\ndf = df.replace(cleanup_nums)\ndf.head()\n","159f051b":"df = df.drop(['Bump','Humidity(%)'], axis=1)\n","b5cdd104":"df.head()","978618da":"df.info()","1d440b2d":"# Creating the Correlation matrix and Selecting the Upper trigular matrix\ncor_matrix = df.corr().abs()\nprint(cor_matrix)","a46ce78c":"import numpy as np\nupper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\nprint(upper_tri)","e0f00a06":"temperature_counts = df[\"Temperature(F)\"].value_counts().to_frame()\ntemperature_counts.rename(columns={'Temperature(F)': 'Severity'}, inplace=True)\ntemperature_counts.index.name = 'Temperature(F)'\ntemperature_counts","1cc2b228":"to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.60)]\nprint(to_drop)","1e3e36de":"df = df.drop(df[to_drop], axis=1)\nprint(df.head())","fca576f7":"# Function to calculate correlations with the target for a dataframe\ndef target_corrs(df):\n\n    # List of correlations\n    corrs = []\n\n    # Iterate through the columns \n    for col in df.columns:\n        print(col)\n        # Skip the target column\n        if col != 'Severity':\n            # Calculate correlation with the target\n            corr = df['Severity'].corr(df[col])\n\n            # Append the list as a tuple\n            corrs.append((col, corr))\n            \n    # Sort by absolute magnitude of correlations\n    corrs = sorted(corrs, key = lambda x: abs(x[1]), reverse = True)\n    \n    return corrs","231900d2":"#data.corr()-->correlation matrix\nimport seaborn as sns\nsns.heatmap(df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(30,8)\nplt.show()","daf372bf":"junctiontype_counts = df[\"Junction\"].value_counts().to_frame()\njunctiontype_counts.rename(columns={'Junction': 'Severity'}, inplace=True)\njunctiontype_counts.index.name = 'Junction'\njunctiontype_counts\n","340f30fe":"plt.figure(figsize=(12,10))\n\nplt.hist(df[\"Junction\"], alpha=0.5, histtype='stepfilled', color='steelblue', edgecolor='none')\n\nplt.xticks(rotation=90)\nplt.xlabel(\"Junction\") \nplt.ylabel(\"Accidents\") \nplt.title(\"Relation between street junction and accidents\")","fc5ac4c4":"\ny_jt=junctiontype_counts[\"Severity\"]\nx_jt=y_jt.sum(axis=0)\njunctiontype_counts['%_Severity'] = (y_jt \/ x_jt) * 100\njunctiontype_counts['%_Severity'].to_frame()\njt_final=junctiontype_counts['%_Severity'].round(decimals=2)\njt_final.to_frame()","9d542e9a":"df_group_one = df[['Junction','Weather_Condition','Severity']]","4d9de267":"junction_sev = df.groupby(['Junction', 'Severity']).size().to_frame()\njunction_sev.rename(columns={0: 'accidents'}, inplace=True)\njunction_sev","0e2e6b3a":"sns.set(style='ticks')\nplt.figure(figsize=(10, 10))\n\nsns.histplot(df, x=\"Junction\", hue=\"Severity\", multiple=\"stack\",stat=\"probability\")\nplt.xticks(rotation=90)","4dcc5d69":"\nweather_counts = df[\"Weather_Condition\"].value_counts().to_frame()\nweather_counts.rename(columns={'Weather_Condition': 'Severity'}, inplace=True)\nweather_counts.index.name = 'Weather_Condition'\nweather_counts","846cbc21":"y_w=weather_counts[\"Severity\"]\nx_w=y_w.sum(axis=0)\nweather_counts['%_Severity'] = (y_w \/ x_w) * 100\nweather_counts['%_Severity'].to_frame()\njw_final=weather_counts['%_Severity'].round(decimals=2)\njw_final.to_frame()","6d17f481":"df_group_one = df[['Weather_Condition','Severity']]","4078be45":"weather_sev = df.groupby(['Weather_Condition','Severity']).size().to_frame()\nweather_sev.rename(columns={0: 'accidents'}, inplace=True)\nweather_sev","197c602d":"y_w=temperature_counts[\"Severity\"]\nx_w=y_w.sum(axis=0)\ntemperature_counts['%_Severity'] = (y_w \/ x_w) * 100\ntemperature_counts['%_Severity'].to_frame()\njw_final=temperature_counts['%_Severity'].round(decimals=2)\njw_final.to_frame()","db35180e":"df.info()","c5d8ca30":"df.head()","7f4eb2f8":"df.drop(['Selected'], axis =1)\n","c677f8cb":"#df['dateInt']=df['Year'].astype(str) + df['Month'].astype(str).str.zfill(2)+ df['Day'].astype(str).str.zfill(2)\n#df['Date'] = pd.to_datetime(df['dateInt'], format='%Y%m%d')","6f169c71":"df.info()\ndf1.info()","cb072bf4":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler","43fe0256":"# initialize KMeans object specifying the number of desired clusters\nkmeans = KMeans(n_clusters=4)","b71ce6ce":"# learning the clustering from the input date\nlocation = kmeans.fit_predict(df[['Lat','Lng']])\n","2f6c21f6":"# output the labels for the input data\nprint(kmeans.labels_)","6b2e62b4":"df['location'] = location.tolist()\nprint(df['location'])","e010ea67":"df.info()","34325f4f":"# normalize the data attributes\n# copy the data\ndf_max_scaled = df.copy()\n  \n# apply normalization techniques on Column 1\ncolumn = 'Distance(mi)'\ndf_max_scaled[column] = df_max_scaled[column] \/df_max_scaled[column].abs().max()\n  \n# view normalized data\ndisplay(df_max_scaled)","3eb7f370":"df.head()","1be17356":"df1.head()","cf298b61":"# Creating the Correlation matrix and Selecting the Upper trigular matrix\ncor_matrix = df.corr().abs()\nprint(cor_matrix)","4bdd6c18":"import numpy as np\nupper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\nprint(upper_tri)","0c62eadd":"to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.30)]\nprint(to_drop)","07d9ee44":"df = df.drop(['Lng', 'Railway', 'Stop', 'Amenity', 'Visibility(mi)','Unnamed: 0','Selected','Lat','Precipitation(in)','description','date','Year','Day','Month'],axis =1)","3ca95652":"#temperature_counts = df[\"Temperature(F)\"].value_counts().to_frame()\n#temperature_counts.rename(columns={'Temperature(F)': 'Severity'}, inplace=True)\n#temperature_counts.index.name = 'Temperature(F)'\n#temperature_counts","13a0e9c1":"#df.groupby(['Wind_Chill(F)', 'Wind_Speed(mph)','Visibility(mi)']).median()","90b4f9e6":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42,stratify=df['Severity']) # Try adding `stratify` here\n\nX_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']\n","d85cfd1c":"# This cell is used to select the numerical features. IT SHOULD BE REMOVED AS YOU DO YOUR WORK.\nX_train = X_train[['Lat', 'Lng', 'Distance(mi)']]\n\nX_val = X_val[['Lat', 'Lng', 'Distance(mi)']]","6a47350d":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)","e6691f77":"print(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","b4a21b0a":"test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\ntest_df.head()","98218deb":"test_df.drop(columns='ID')\ntest_df.drop(columns='Bump')","e573a3fb":"side_wise_counts = test_df.groupby('Side')['ID'].count().reset_index()\ndisplay(side_wise_counts)","63304d0d":"test_df = pd.concat([test_df, df1], axis=1, join='inner')\ndisplay(test_df.head())","497ff733":"test_df['Wind_Chill(F)'] = test_df['Wind_Chill(F)'].transform(impute_median)\nprint(test_df['Wind_Chill(F)'])","9fe1a4dc":"test_df['Weather_Condition'].fillna(str(test_df['Weather_Condition'].mode()), inplace=True)","53a732fd":"test_df['Precipitation(in)'] = test_df['Precipitation(in)'].transform(impute_median)","7221b685":"test_df['Humidity(%)'] = test_df['Humidity(%)'].transform(impute_median)","324bab6d":"test_df['Wind_Speed(mph)'] = test_df['Wind_Speed(mph)'].transform(impute_median)","8a2dbd5d":"test_df['Visibility(mi)'] = test_df['Visibility(mi)'].transform(impute_median)","8c9d4a7f":"test_df.drop(columns='Bump')","fbd2e76b":"test_df.drop(columns='Temperature(F)')","bff9c962":"test_df[\"Crossing\"] = test_df[\"Crossing\"].astype(int)","5056b050":"test_df[\"Give_Way\"] = test_df[\"Give_Way\"].astype(int)","1a8b211e":"test_df[\"Junction\"] = test_df[\"Junction\"].astype(int)","551be691":"test_df[\"No_Exit\"] = test_df[\"No_Exit\"].astype(int)","77d47a21":"test_df[\"Railway\"] = test_df[\"Railway\"].astype(int)","c9d402a6":"test_df[\"Roundabout\"] = test_df[\"Roundabout\"].astype(int)","d6829336":"test_df[\"Stop\"] = test_df[\"Stop\"].astype(int)\n","550c7e46":"df[\"Amenity\"] = df[\"Amenity\"].astype(int)","08ce98c7":"# Convert side to 0\/ 1\n#Right -> 1\n#Left -> 0\ncleanup_nums = {\"Side\":     {\"R\": 1, \"L\": 2}}\ntest_df = test_df.replace(cleanup_nums)\ntest_df.head()","028c7ec2":"test_df = test_df.drop(['Lng', 'Railway', 'Stop', 'Amenity', 'Temperature(F)', 'Visibility(mi)','Selected','Lat','Precipitation(in)','ID','Year','Day','Month'],axis =1)","fe04b69f":"X_test = test_df.drop(columns=['ID'])\n\n# You should update\/remove the next line once you change the features used for training\nX_test = X_test[['Lat', 'Lng', 'Distance(mi)']]\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted\n\ntest_df.head()","e2ccb49e":"test_df[['ID', 'Severity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","f83c9bfe":"Analyse Accident Number due to Weather Conditions.","b41cdd31":"The output shows desciptive statistics for the numerical features, `Lat`, `Lng`, `Distance(mi)`, and `Severity`. I'll use the numerical features to demonstrate how to train the model and make submissions. **However you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.**","bbbe9007":"## comment\nFrom the pervious describe of the dataset , this show that Distance column has no negative values ","da2e1a9a":"The remaining steps is to submit the generated file and are as follows. \n\n1. Press `Save Version` on the upper right corner of this notebook.\n2. Write a `Version Name` of your choice and choose `Save & Run All (Commit)` then click `Save`.\n3. Wait for the saved notebook to finish running the go to the saved notebook.\n4. Scroll down until you see the output files then select the `submission.csv` file and click `Submit`.\n\nNow your submission will be evaluated and your score will be updated on the leaderboard! CONGRATULATIONS!!","3eece9a6":"we can see that there are no null values in this dataset ","b915a62c":"## You're here! \nWelcome to your first competition in the [ITI's AI Pro training program](https:\/\/ai.iti.gov.eg\/epita\/ai-engineer\/)! We hope you enjoy and learn as much as we did prepairing this competition.\n\n\n## Introduction\n\nIn the competition, it's required to predict the `Severity` of a car crash given info about the crash, e.g., location.\n\nThis is the getting started notebook. Things are kept simple so that it's easier to understand the steps and modify it.\n\nFeel free to `Fork` this notebook and share it with your modifications **OR** use it to create your submissions.\n\n### Prerequisites\nYou should know how to use python and a little bit of Machine Learning. You can apply the techniques you learned in the training program and submit the new solutions! \n\n### Checklist\nYou can participate in this competition the way you perefer. However, I recommend following these steps if this is your first time joining a competition on Kaggle.\n\n* Fork this notebook and run the cells in order.\n* Submit this solution.\n* Make changes to the data processing step as you see fit.\n* Submit the new solutions.\n\n*You can submit up to 5 submissions per day. You can select only one of the submission you make to be considered in the final ranking.*\n\n\nDon't hesitate to leave a comment or contact me if you have any question!","a7d9ea33":"### Relation between types of junction and accidents","a2dbe752":"## Exploratory Data Analysis\nIn this step, one should load the data and analyze it. However, I'll load the data and do minimal analysis. You are encouraged to do thorough analysis!\n\nLet's load the data using `pandas` and have a look at the generated `DataFrame`.","a0bfaf1d":"## Factors Affecting Accident Severity","8960f201":"## Data Splitting\n\nNow it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n\n*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* ","b7b5ca60":"## Import the libraries\n\nWe'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections.","c52cb2a5":" ### Relation between weather and accidents","d525c2e0":"## Comment\n  incident has taken place more in the Right Side (the side of the street)","a1f0fe1c":"## since all values in 'Bump' is the same, so we will drop it","b9d5c792":"## Model Training\n\nLet's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. ","252e230d":"Now let's test our classifier on the validation dataset and see the accuracy.","ebd1c7bd":"Relation between weather and accidents","9bd3f733":"## Converting boolean to 0\/1\nbuilding a machine learning model and this is one of your input features, you\u2019d need it to be numeric and you would use 0 and 1 to represent False and True","2eb16be3":"Replace NaN Values with Zeros","7a4ef0f0":"As pointed out eariler, I'll use the numerical features to train the classifier. **However, you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.** ","16ce51ce":"## Conclusion\n\nIn this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. We chose not to go into details in each step to keep the welcoming notebook simple and make a room for improvement.\n\nYou're encourged to `Fork` the notebook, edit it, add your insights and use it to create your submission.","dfd9f7d8":"Note that the test set has the same features and doesn't have the `Severity` column.\nAt this stage one must **NOT** forget to apply the same processing done on the training set on the features of the test set.\n\nNow we'll add `Severity` column to the test `DataFrame` and add the values of the predicted class to it.\n\n**I'll select the numerical features here as I did in the training set. DO NOT forget to change this step as you change the preprocessing of the training data.**","ae4f95e3":"We've got 6407 examples in the dataset with 14 featues, 1 ID, and the `Severity` of the crash.\n\nBy looking at the features and a sample from the data, the features look of numerical and catogerical types. What about some descriptive statistics?","e936d74a":"Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only.","7ddf0adf":"### Droping the column with high correlation","39f33e1d":"## Submission File Generation\n\nWe have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n\nFirst, we'll load the data.","374c17a2":"### Examine the relationship between accident severity and other accident information such as time, weather, and location.","f071af9a":"## Analyse Accident Number due to Weather Conditions.","9744a2d9":"Well. That's a good start, right? A classifier that predicts all examples' `Severity` as 2 will get around 0.63. You should get better score as you add more features and do better data preprocessing."}}