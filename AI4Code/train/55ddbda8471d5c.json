{"cell_type":{"be438ac3":"code","d0033f8d":"code","3eda95f1":"code","23249e56":"code","9ec354da":"code","dbff2098":"code","ada70e43":"code","52f7a240":"code","2d23d7bb":"code","0ea8a9be":"code","8d91946b":"code","15fa88ef":"code","fa05316f":"code","83c9deaf":"code","199d842d":"code","b1965e55":"code","10afb7cd":"code","7b721271":"code","8a63a9fe":"code","4926e428":"code","50f0c6d6":"code","d4b8dae4":"code","159016a1":"code","4b04d954":"code","b7b25ec5":"code","6ce5ab52":"code","c4353cb0":"code","fd595b70":"code","cc149770":"code","e544df48":"code","d7d12daf":"markdown","4d7c4866":"markdown","8768ec3e":"markdown","eedfe0c8":"markdown","90fb5b04":"markdown","2c4f075e":"markdown","eb375778":"markdown","60d3805c":"markdown","c7d654fc":"markdown","b0f4b48b":"markdown","f8e9ec9a":"markdown","1e5908a2":"markdown","481e7320":"markdown","72f28b2b":"markdown","3a418d97":"markdown","04569a76":"markdown","33eb6056":"markdown","89b5c165":"markdown","b7632e63":"markdown","e146bda3":"markdown","d75ece07":"markdown","834e0bd0":"markdown","9db8c0b2":"markdown","8a761ce7":"markdown","3344a074":"markdown","595b4e87":"markdown","4829bb1d":"markdown","bc248e1d":"markdown","cc37b3f4":"markdown","93d08aaa":"markdown","ecfcf8c8":"markdown","9ab268c3":"markdown","47376609":"markdown","134d7259":"markdown","39b6d8ed":"markdown"},"source":{"be438ac3":"# Data and Visuals\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting visuals\nimport seaborn as sns # plotting visuals\n\n# Pandas\nfrom pandas.plotting import scatter_matrix\n\n#Infrastructure\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint('Library Import Complete')","d0033f8d":"# Pandas Setup\npd.set_option('display.float_format', lambda x: '%.3f' % x) #setting float format to .001 for readability\n\n# Matplotlib Setup\n%matplotlib inline\n\nprint('Library Setup Complete')","3eda95f1":"# To import the dataset into dataframe\nfraud_df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\nprint('File Import Complete')","23249e56":"# To display the first five rows of dataframe\n'''This function returns the first n rows for the object based on position.\nIt is useful for quickly testing if your object has the right type of data in it.\n'''\nfraud_df.head()","9ec354da":"# To display the number of columns and rows in dataframe\n'''Return a tuple representing the dimensionality of the DataFrame.'''\nfraud_df.shape","dbff2098":"# To display dataframe info\n'''This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.'''\nfraud_df.info()","ada70e43":"# To check the sum of null\/NaN values\n'''This function takes a scalar or array-like object and indicates whether values are missing (NaN in numeric arrays, None or NaN in object arrays, NaT in datetimelike).'''\nfraud_df.isnull().sum()","52f7a240":"# To display basic statistical description of dataframe\n'''Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution, excluding NaN values.'''\nfraud_df.describe()","2d23d7bb":"# To determine value_counts on dataframe\nclass_names = {0: 'Not Fraud', 1:'Fraud'}\nres_var_analysis = fraud_df.Class.value_counts().rename(index = class_names)\n\nprint(res_var_analysis)","0ea8a9be":"# To import library for train_test_split\nfrom sklearn.model_selection import train_test_split\n\nprint('Import Train_Test_Split Complete')","8d91946b":"# To determine y and X values of train_test_split\ny = fraud_df['Class']  #dependant variable\nX = fraud_df.loc[:, fraud_df.columns != 'Class'] #independant variables\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.33, random_state=42)\n\nprint('Test_Train Split Complete')","15fa88ef":"# To import library for accuracy score and linear regression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\nprint('Import Accuracy Score and Logistic Regression Libraries Complete')","fa05316f":"# To initialize logistic regression classifier\nlogreg = LogisticRegression(solver='liblinear') # solver changed to resolve \n\n# To train the model using the training dataset\nlogreg.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = logreg.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\nlogreg_accuracy = round(accuracy_score(y_test, y_predict) *100, 3)\n\nprint('Accuracy of Logistic Regression model is: ', logreg_accuracy, '%')","83c9deaf":"# To import library for linear discriminant analysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nprint('Import Linear Discriminant Analysis Libraries Complete')","199d842d":"# To initialize the linear discriminant classifier\nmodel = LinearDiscriminantAnalysis()\n\n# To train the model using the train_test_split dataset\nmodel.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = model.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\nlindisc_accuracy = round(accuracy_score(y_test, y_predict) *100, 3)\n\nprint('Accuracy of Logistic Regression model is: ', lindisc_accuracy, '%')","b1965e55":"# To import library for Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nprint('Import Gaussian Naive Bayes Libraries Complete')","10afb7cd":"# To initialize the Gaussian Naive Bayes classifier\nmodel = GaussianNB()\n\n# To train the model using the train_test_split dataset\nmodel.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = model.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\ngausnb_accuracy = round(accuracy_score(y_test, y_predict) *100, 3)\n\nprint('Accuracy of Gaussian Naive Bayes model is: ', gausnb_accuracy, '%')","7b721271":"# To import library for decision tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nprint('Import Decision Tree Libraries Complete')","8a63a9fe":"# To initialize the decision tree classifier\nmodel = DecisionTreeClassifier()\n\n# To train the model using the train_test_split dataset\nmodel.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = model.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\ndtree_accuracy = round(accuracy_score(y_test, y_predict)*100, 3)\n\nprint('Accuracy of Decision Tree model is: ', dtree_accuracy, '%')","4926e428":"# To import library for random forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nprint('Import Random Forest Libraries Complete')","50f0c6d6":"# To initialize the random forest classifier\nmodel = RandomForestClassifier()\n\n# To train the model using the train_test_split dataset\nmodel.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = model.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\nrforest_accuracy = round(accuracy_score(y_test, y_predict) *100, 3)\n\nprint('Accuracy of Decision Tree model is: ', rforest_accuracy, '%')","d4b8dae4":"# To import library for support-vector machine\nfrom sklearn import svm\n\nprint('Import Random Forest Libraries Complete')","159016a1":"# To initialize the support-vector machine classifier\nmodel = svm.SVC()\n\n# To train the model using the train_test_split dataset\nmodel.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = model.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\nsupvector_accuracy = round(accuracy_score(y_test, y_predict) *100, 3)\n\nprint('Accuracy of Decision Tree model is: ', supvector_accuracy, '%')","4b04d954":"# To import library for k-nearest neighbor\nfrom sklearn.neighbors import KNeighborsClassifier\n\nprint('Import Random Forest Libraries Complete')","b7b25ec5":"# To initialize the support-vector machine classifier\nmodel = KNeighborsClassifier()\n\n# To train the model using the train_test_split dataset\nmodel.fit(X_train, y_train)\n\n# To predict the test dataset\ny_predict = model.predict(X_test)\n\n# To calculate the model accuracy by comparing y_test and y_predict\nknn_accuracy = round(accuracy_score(y_test, y_predict) *100, 3)\n\nprint('Accuracy of Decision Tree model is: ', knn_accuracy, '%')","6ce5ab52":"# To create dataframe from the models and their accuracy scores\nmodels = pd.DataFrame({\n    'Model':['Logistic Regression','Linear Discriminant Analysis', 'Gaussian Naive Bayes', 'Decision Tree', 'Random Forest', 'Support-Vector Machine', 'K-Nearest Neighbor'],\n    'Score':[logreg_accuracy, lindisc_accuracy, gausnb_accuracy, dtree_accuracy, rforest_accuracy, supvector_accuracy, knn_accuracy]\n})\n\n# To sort the accuracy score values by ascending order\nmodels.sort_values(by='Score', ascending=False)","c4353cb0":"# To import library for confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nprint('Import Random Forest Libraries Complete')","fd595b70":"# To initialize the confusion matrix using the train_test_split for Y\nconf_matrix = confusion_matrix(y_test, y_predict)\nprint(conf_matrix)","cc149770":"# To plot heatmap of confusion matrix\nsns.heatmap(conf_matrix, annot=True, fmt='f', annot_kws={\"size\": 10})","e544df48":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model, X_test, y_test)","d7d12daf":"## Model Selection","4d7c4866":"# Credit Card Fraud Detection  \n## Machine Learning Predictions with Scikit-Learn\nBen Felder  \n*September 2021*","8768ec3e":"#### Import Libraries Specific for K-Nearest Neighbor","eedfe0c8":"## Importing Dataset","90fb5b04":"#### Import Libraries Specific for Support-Vector Machine","2c4f075e":"Showing there are *0* null\/NaN values in the dataset  \nShowing there are only *float* and *int* **numeric\/quantitative** datatypes","eb375778":"## Train Test Split  \nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html\n\nSplits dataframe into *training* and *testing* data","60d3805c":"### Library Setup Options","c7d654fc":"#### Import Libraries Specific for Random Forest","b0f4b48b":"### *Random Forest Model* with *99.961% Accuracy* is Best Model for Predicting","f8e9ec9a":"### K-Nearest Neighbor\nhttps:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm","1e5908a2":"#### Import Libraries Specific for Logistic Regression","481e7320":"### Gaussian Naive Bayes\nhttps:\/\/en.wikipedia.org\/wiki\/Naive_Bayes_classifier","72f28b2b":"#### Import Libraries Specific for Decision Tree","3a418d97":"### Create Dataframe from Model Accuracy Scores","04569a76":"Confirming there are *0* null\/NaN values","33eb6056":"## Importing Libraries","89b5c165":"### Decision Tree\nhttps:\/\/en.wikipedia.org\/wiki\/Decision_tree_model","b7632e63":"### Confusion Matrix Findings\n    True positives - 93838  |  False positives - 0\n    False negatives - 144  |  True negatives - 5\n\n**Indicates *high* false negative rate**\n","e146bda3":"#### Import Libraries Specific for Linear Discriminant Analysis ","d75ece07":"https:\/\/online.stat.psu.edu\/stat200\/lesson\/1\/1.1\/1.1.2\n\nResponse Variable\n\n    Also known as the dependent or outcome variable, its value is predicted or its variation is explained by the explanatory variable; in an experimental study, this is the outcome that is measured following manipulation of the explanatory variable\n","834e0bd0":"## Data Exploration","9db8c0b2":"### Linear Discrimination Analysis\nhttps:\/\/en.wikipedia.org\/wiki\/Linear_discriminant_analysis","8a761ce7":"# Data Modeling\n1.  Logistic Regression\n2.  Linear Discrimination\n3.  Gaussian Naive Bayes\n4.  Decision Tree\n5.  Random Forest\n6.  Support Vector Machine\n7.  K Nearest Neighbor Model\n\n#### Use round() on accuracy_test() to ensure readability and accuracy","3344a074":"#### Import Libraries Specific for Gaussian Naive Bayes ","595b4e87":"### Metadata\n#### Usage Information\n**License:**\nDatabase: Open Database, Contents: Database Contents  \n**Visibility:**\nPublic  \n\n#### Maintainers\n**Dataset owner**  \nMachine Learning Group - ULB  \n\n#### Updates  \n**Expected update frequency:**  \nNot specified  \n**Last updated:**  \n2018-03-22  \n**Date created:**  \n2016-11-03  \n**Current version:**  \nVersion 3","4829bb1d":"### Random Forest\nhttps:\/\/en.wikipedia.org\/wiki\/Random_forest","bc248e1d":"## Confusion Matrix\nhttps:\/\/en.wikipedia.org\/wiki\/Confusion_matrix\n\n    TP - True positives (predicted positive are actually positive)\n    FP - False positives (predicted positive are actually negative)\n    TN - True negatives (predicted negative are actually positive)\n    FN - False negatives (predicted negative are actually positive)\n\n<img src= \"https:\/\/i.stack.imgur.com\/D1Lk4.png\" alt =\"Confusion Matrix\">","cc37b3f4":"Indicates there are 492 cases of Fraud","93d08aaa":"### Observations\nValue - average amount is 88 with a maximum of 25691  \nTime - average amount is 94813 (or 26 hours) with a maximum of 172792 (or 48 hours)  \n\nClass - only contains values between 0 and 1, we will use this as our *Output Variable*  \nClass - value of 1 indicates 'Fraud', otherwise 0","ecfcf8c8":"## Response Variable Analysis ","9ab268c3":"### Support-Vector Machine\nhttps:\/\/en.wikipedia.org\/wiki\/Support-vector_machine","47376609":"### Logistic Regression\n\nhttps:\/\/en.wikipedia.org\/wiki\/Logistic_regression","134d7259":"## Dataset\n**Dataset Name:** *Credit Card Fraud Detection*  \n**Dataset Description:** *The dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\nGiven the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.*  \n**Dataset Source:** *Kaggle*  \n**Dataset Link:** https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud  \n***Acknowledgements***: *The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http:\/\/mlg.ulb.ac.be) of ULB (Universit\u00e9 Libre de Bruxelles) on big data mining and fraud detection.\nMore details on current and past projects on related topics are available on https:\/\/www.researchgate.net\/project\/Fraud-detection-5 and the page of the DefeatFraud project*","39b6d8ed":"#### Import Libraries Specific for Confusion Matrix"}}