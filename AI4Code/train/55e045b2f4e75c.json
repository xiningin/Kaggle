{"cell_type":{"48f04447":"code","e2e3c728":"code","e46812aa":"code","66dc4c60":"code","6744b3bd":"code","231c0067":"code","7ce5c26f":"code","1fbaa83f":"code","abb17c45":"markdown","b613ba15":"markdown","592bac1f":"markdown","e3481493":"markdown","b0ab6709":"markdown","8077cab9":"markdown","a57f7189":"markdown","93c41779":"markdown","418926cb":"markdown"},"source":{"48f04447":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","e2e3c728":"# 0 - Pre-define tranformations\n\n# transform.normalize(seq of means, seq of stds) does this >>> image = (image - mean) \/ std \n# In This normalization mean, std are passed as 0.5, 0.5, This will normalize the image in the range [-1,1]\n# Because >>> The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]\n# For example, the minimum value 0 will be converted to (0-0.5)\/0.5=-1, the maximum value of 1 will be converted to (1-0.5)\/0.5=1\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 4\n\n# 1 - Loading the data\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\nprint(\"\\n\\t\\t-------\\n1-trainset:  {}\\n 2-trainloader:  {}\\n 3-testset:  {}\\n 4-testloader:  {}\".format(\ntrainset, trainloader, testset, testloader))","e46812aa":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))","66dc4c60":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()","6744b3bd":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","231c0067":"for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","7ce5c26f":"PATH = '.\/cifar_net.pth'\ntorch.save(net.state_dict(), PATH)","1fbaa83f":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","abb17c45":"## 4. Train the network","b613ba15":"![image.png](attachment:43b19faf-8ccd-4edb-85ea-982a0352c03c.png)","592bac1f":"## 2- Defining a CNN","e3481493":"## 5. Test the network on the test data","b0ab6709":"## - Visualizing some of the images","8077cab9":"## 1- Load and normalize the CIFAR10 training and test datasets using **torchvision**","a57f7189":"## 3. Define a Loss function and optimizer","93c41779":"### -save our trained model??","418926cb":"## To train an image classifier from CIFAR10\n1- Load and normalize the CIFAR10 training and test datasets using **torchvision**\n\n2- Define a Convolutional Neural Network\n\n3- Define a loss function\n\n4- Train the network on the training data\n\n5- Test the network on the test data"}}