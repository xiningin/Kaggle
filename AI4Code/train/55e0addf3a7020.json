{"cell_type":{"ebf85be2":"code","9d36582a":"code","8c7ed9bb":"code","a0c245f3":"code","3536ea3e":"code","1dd91fe6":"code","b9ffc6a4":"code","b19dacd3":"code","bba5f00f":"code","601c2748":"code","ec870c7f":"code","700a6e87":"code","a73cc309":"markdown","655a0823":"markdown","43fcb69b":"markdown","77f1f0ac":"markdown","abb0e739":"markdown","1d40b677":"markdown","ba892ef1":"markdown","fbfc7c16":"markdown","13cc7971":"markdown"},"source":{"ebf85be2":"!pip install fastai==0.7.0 --no-deps\n!pip install torch==0.4.1 torchvision==0.2.1","9d36582a":"from fastai.conv_learner import *\nfrom fastai.dataset import *\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\n","8c7ed9bb":"MODEL_PATH = 'Dn121_v1'\nTRAIN = '..\/input\/train\/'\nTEST = '..\/input\/test\/'\nLABELS = '..\/input\/train_labels.csv'\nSAMPLE_SUB = '..\/input\/sample_submission.csv'\nORG_SIZE=96\nBATCH_SIZE = 128","a0c245f3":"arch = dn121 \nnw = 4","3536ea3e":"train_df = pd.read_csv(LABELS).set_index('id')\ntrain_names = train_df.index.values\ntrain_labels = np.asarray(train_df['label'].values)\nprint(\"Number of positive samples = {:.4f}%\".format(np.count_nonzero(train_labels)*100\/len(train_labels)))\ntest_names = [f.replace(\".tif\",\"\") for f in os.listdir(TEST)]\ntr_n, val_n = train_test_split(train_names, test_size=0.15, random_state=42069)\nprint(len(tr_n), len(val_n))","1dd91fe6":"class HCDDataset(FilesDataset):\n    def __init__(self, fnames, path, transform):\n        self.train_df = train_df\n        super().__init__(fnames, transform, path)\n\n    def get_x(self, i):\n        img = open_image(os.path.join(self.path, self.fnames[i]+\".tif\"))\n        # We crop the center of the original image for faster training time\n        img = img[(ORG_SIZE-self.sz)\/\/2:(ORG_SIZE+self.sz)\/\/2,(ORG_SIZE-self.sz)\/\/2:(ORG_SIZE+self.sz)\/\/2,:]\n        return img\n\n    def get_y(self, i):\n        if (self.path == TEST): return 0\n        return self.train_df.loc[self.fnames[i]]['label']\n\n\n    def get_c(self):\n        return 2\n","b9ffc6a4":"def get_data(sz, bs):\n    aug_tfms = [RandomRotate(20, tfm_y=TfmType.NO),\n                RandomDihedral(tfm_y=TfmType.NO)]\n    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.NO,\n                           aug_tfms=aug_tfms)\n    ds = ImageData.get_ds(HCDDataset, (tr_n[:-(len(tr_n) % bs)], TRAIN),\n                          (val_n, TRAIN), tfms, test=(test_names, TEST))\n    md = ImageData(\".\/\", ds, bs, num_workers=nw, classes=None)\n    return md\n","b19dacd3":"md = get_data(96, BATCH_SIZE)\nlearn = ConvLearner.pretrained(arch, md) \nlearn.opt_fn = optim.Adam","bba5f00f":"# learn.lr_find()\n# learn.sched.plot()\nlr = 2e-2","601c2748":"learn.fit(lr, 1, cycle_len=2)\nlearn.unfreeze()\nlrs = np.array([1e-4, 5e-4, 1.2e-3])\nlearn.fit(lrs, 1, cycle_len=5, use_clr=(20, 16))\nlearn.fit(lrs\/4, 1, cycle_len=5, use_clr=(10, 8))\nlearn.fit(lrs\/16, 1, cycle_len=5, use_clr=(10, 8))","ec870c7f":"# preds_t,y_t = learn.predict_with_targs(is_test=True) # Predicting without TTA\npreds_t,y_t = learn.TTA(is_test=True, n_aug=8)\npreds_t = np.stack(preds_t, axis=-1)\npreds_t = np.exp(preds_t)\npreds_t = preds_t.mean(axis=-1)[:,1]","700a6e87":"sample_df = pd.read_csv(SAMPLE_SUB)\nsample_list = list(sample_df.id)\npred_list = [p for p in preds_t]\npred_dic = dict((key, value) for (key, value) in zip(learn.data.test_ds.fnames,pred_list))\npred_list_cor = [pred_dic[id] for id in sample_list]\ndf = pd.DataFrame({'id':sample_list,'label':pred_list_cor})\ndf.to_csv('submission.csv'.format(MODEL_PATH), header=True, index=False)\n","a73cc309":"Let's start by importing our libararies.","655a0823":"## Predictions\nLet's add some TTA (Test-Time-Augmentation), this usually increases the accuracy a bit, you may need to do some tests here to compare the result with normal prediction.","43fcb69b":"We start by training only the newly initialized weights, then unfreeze the model and finetune the pretrained weights with reduced learning rate.","77f1f0ac":"Next, we prapare out dataset to work with Fastai's pipeline.","abb0e739":"## Training ","1d40b677":"The architecture is flexible, I chose Resnet18 since it can fit quite well into a kernel. You may play with this if you want to. ","ba892ef1":"## TL;DR\n\nThis is a simple classifier based on an Imagenet-trained Resnet18. It's inspired by Iafoss[](https:\/\/www.kaggle.com\/iafoss)'s kernels in other competititions.\n\n### Update\n\nJust realized Densnet121 is way better, so let's switch to that for now!","fbfc7c16":"Uncomment these lines to run Fastai's automatic learning rate finder. \n\nThe graphs showed that the loss converged at around learning rate = 1e-2, which means we should set our learning rate a bit higher than that.","13cc7971":"Finally, our submission."}}