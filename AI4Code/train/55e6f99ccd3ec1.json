{"cell_type":{"5b2a3a68":"code","1160b43d":"code","3a73ca99":"code","e8894f7d":"code","d8107d9f":"code","beb66e5b":"code","f7f65d7c":"code","1222072d":"code","18783c18":"code","ddedb6e4":"code","69aab5f0":"code","99603849":"code","6e23e070":"code","46821a65":"code","e3b8f8d8":"code","1d4a26c7":"code","f76479f0":"code","66b5268a":"code","50f36d8c":"code","2cfe4eb4":"code","dac54c00":"code","18a5a18a":"code","d4a2f6d6":"code","d59f035e":"code","4cf029f8":"code","1c7ab1fd":"code","fb2fe14b":"code","43dbda80":"code","0b5db35b":"code","8d26701d":"markdown","7b2ef866":"markdown","7cb1bff4":"markdown","e10b2f09":"markdown","dcaa519c":"markdown","7117142e":"markdown","e1b80abc":"markdown","7e03c3c2":"markdown","1c86995a":"markdown","9f281bd1":"markdown","c6e547e2":"markdown","a33975b7":"markdown"},"source":{"5b2a3a68":"import numpy as np \nimport pandas as pd\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport itertools\nfrom sklearn.metrics import f1_score","1160b43d":"df=pd.read_csv(r'..\/input\/hotel-booking-demand\/hotel_bookings.csv')","3a73ca99":"cancelled=df.loc[(df['is_canceled']==1)]","e8894f7d":"a=100*(cancelled.shape[0]\/df.shape[0])\nprint(\"Percentage of the canceled values  \" + str(a))\nprint('Percentge of the non canceled values  '+ str(100-a))","d8107d9f":"df.pop('reservation_status_date')\ndf.pop('arrival_date_year')","beb66e5b":"df['hotel'].value_counts().sort_values().plot(kind='bar')\nplt.title('Type of Hotel ')\nplt.show()","f7f65d7c":"cancelled['hotel'].value_counts().sort_values().plot(kind='bar')\nplt.title('type of hotel cancelled')\nplt.show()","1222072d":"df['hotel'].value_counts(normalize=True).sort_values().plot(kind='bar')\nplt.title('Type of Hotel (normalized)')\nplt.show()","18783c18":"cancelled['hotel'].value_counts(normalize=True).sort_values().plot(kind='bar')\nplt.title('Normalized type of hotel cancelled')\nplt.show()","ddedb6e4":"df['arrival_date_month'].value_counts().sort_values().plot(kind = 'bar')\nplt.title('Months of arrival (General)')\nplt.show()","69aab5f0":"cancelled['arrival_date_month'].value_counts().sort_values().plot(kind='bar')\nplt.title('Date of supossed arrival of people that canceled')\nplt.show()","99603849":"print(df['adults'].value_counts())","6e23e070":"df=df.loc[(df['adults']<20)]","46821a65":"df['adults'].value_counts().sort_values().plot(kind='bar')\nplt.title('No of Adults (Outliers removed)')\nplt.show()","e3b8f8d8":"cancelled['adults'].value_counts().sort_values().plot(kind='bar')\nplt.title('No of adults of people that cancelled')\nplt.show()","1d4a26c7":"print(df['children'].value_counts())","f76479f0":"df=df.loc[(df['children']<10)]\ndf['children'].value_counts().sort_values().plot(kind='bar')\nplt.title('General Children')\nplt.show()","66b5268a":"plt.figure(figsize=(30,15))\ndf['country'].value_counts().sort_values().plot(kind='bar')\nplt.show()\nprint(df['country'].value_counts())","50f36d8c":"# How much of it with meal \ndf['meal'].value_counts().sort_values().plot(kind='bar')\nplt.title('General Meal')\nplt.show()","2cfe4eb4":"# How much of it with meal canceled\ncancelled['meal'].value_counts().sort_values().plot(kind='bar')\nplt.title('General Meal(Canceled)')\nplt.show()","dac54c00":"df['deposit_type'].value_counts().sort_values().plot(kind='bar')\nplt.title('deposit type')\nplt.show()","18a5a18a":"cancelled['deposit_type'].value_counts().sort_values().plot(kind='bar')\nplt.title('Cancelled deposit type')\nplt.show()","d4a2f6d6":"for col_name in df.columns:\n    if(df[col_name].dtype == 'object'):\n        df[col_name]= df[col_name].astype('category')\n        df[col_name] = df[col_name].cat.codes","d59f035e":"df=df.fillna(0)\nprint (df.isna().any(axis=-0))","4cf029f8":"\ny=np.array(df.pop('is_canceled'))\n\nx=df.values\n\nx_train,x_test,y_train,y_test=train_test_split(x,y)","1c7ab1fd":"epochs=15\n\nmodel = keras.Sequential([\n    keras.layers.Dense(32,input_shape=(29,),activation='relu'),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(2, activation='softmax')\n])\nmodel.compile(optimizer='Adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nhistory=model.fit(x_train, y_train, epochs=epochs,validation_split=0.1,verbose=0)\n","fb2fe14b":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n","43dbda80":"\nhistory=history.history\nepochs_num=np.arange(1,epochs+1)\n\nplt.figure(0)\nplt.title('accuracy')\nplt.plot(epochs_num,history['accuracy'],label='accuracy')\nplt.plot(epochs_num,history['val_accuracy'],label='val_accuracy')\nplt.legend()\nplt.show()\n\nplt.figure(0)\nplt.title('loss')\nplt.plot(epochs_num,history['loss'],label='loss')\nplt.plot(epochs_num,history['val_loss'],label='accuracy_loss')\nplt.legend()\nplt.show()\n\ncomp=model.predict(x_test)\ncomp=np.array([np.argmax(u) for u in comp])\ncm = confusion_matrix(y_true=y_test, y_pred=comp)\nplot_confusion_matrix(cm=cm,classes=['Non Canceled','Canceled'],title='Confusion Matrix')\nplt.show()\n","0b5db35b":"plt.figure(figsize=(12,6))\ncm = confusion_matrix(y_true=y_test, y_pred=comp)\nplot_confusion_matrix(cm=cm,classes=['Non Canceled','Canceled'],title='Confusion Matrix',normalize=True)\nplt.show()\nprint('F1 score '+str(f1_score(y_true=y_test,y_pred=comp)))","8d26701d":"Is the data balanced ? To this we need to have all the data that is canceled and the data where is not canceled","7b2ef866":"Looking at the number of nan and replacing then by zero ","7cb1bff4":"Transforming Categorical to Numerical","e10b2f09":"Separating what is the canceled data.","dcaa519c":"# Conclusion\n\nBeing very sincere with the person who reads this notebook. I am very suspicious of the notebook results maybe there are hidden in some data something date relates directly when is canceled or not. \nIf this is not true this result is amazing it predicted with a great precision showing that a neural network may be the best solution to the prediction of cancelation or not. \nOther possible solution is that i got lucky in the training of the neural net, but is really suspicious the precision being so high if someone have a clue what may be happening please leave a comment\n   \n   **If you enjoyed the Notebook give it an Up and Thank you**\n","7117142e":"# Importing libraries","e1b80abc":"Another outlier","7e03c3c2":"# Building our model using tensor flow","1c86995a":"Inputing the data ","9f281bd1":"Removing outliers","c6e547e2":"As we can see the dataset is not balanced but the difference is not that big we can change our aproach by changing evaluation metrics.","a33975b7":"# Objectives of the Notebook \n\n *  **Building a neural network with the best accuracy possible and testing it's accuracy**\n \n *  **Give it a glance look at the data**\n \n *  **Showing the result in confusion matrix**\n \n "}}