{"cell_type":{"de7f0c87":"code","60edda32":"code","3de511aa":"code","01bd9227":"code","a9d3dc4f":"code","46707d2a":"code","2c9196bd":"code","36d883fe":"code","98e1003d":"code","753da6b2":"code","8f9658ad":"code","574f9957":"code","46b3b838":"code","505f177f":"code","b476c93e":"code","a0c30249":"code","7e2ad692":"code","8d28b7db":"code","e31ccc34":"code","69747b85":"markdown","26aa7bd7":"markdown","27843e66":"markdown","c2ef0eca":"markdown","6e543539":"markdown","c37c50e3":"markdown","1e1b8555":"markdown","d7e8ba19":"markdown","08ce69d5":"markdown","3c38b1c5":"markdown"},"source":{"de7f0c87":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nprint(os.listdir(\"..\/input\/digit-recognizer\/\"))","60edda32":"device_name = tf.test.gpu_device_name()\nprint(device_name)","3de511aa":"batch_size=32\nepochs=60","01bd9227":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","a9d3dc4f":"test_data.head()","46707d2a":"def showImage(train_image,label,index):\n    image_mtx = train_image.values.reshape(28,28)\n    plt.subplot(4,5,index+1)\n    plt.imshow(image_mtx , cmap='gray')\n    plt.title(label)\n    \nplt.figure(figsize=(20,10))\n\nfirst_images = train_data.sample(20).reset_index(drop=True)\n\nfor index,row in first_images.iterrows():\n    label = row['label']\n    image_mtx = row.drop('label')\n    showImage(image_mtx,label,index)","2c9196bd":"from sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\nx = train_data.drop(columns=['label']).values.reshape(train_data.shape[0],28,28,1)\ny = to_categorical(train_data['label'])\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)","36d883fe":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=10,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\ntrain_datagen.fit(x_train)\ntrain_generator = train_datagen.flow(\n    x_train,\n    y_train,\n    batch_size=batch_size\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_datagen.fit(x_test)\n\nvalidation_generator = validation_datagen.flow(\n    x_test,\n    y_test\n    \n)","98e1003d":"mean_px = x_train.mean().astype(np.float32)\nstd_px = x_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px","753da6b2":"from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.3, patience=3, verbose=1),\n    ModelCheckpoint('model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","8f9658ad":"epochs = 30","574f9957":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization\n\nwith tf.device('\/gpu:0'):\n    \n    model=Sequential()\n \n    model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\n    #model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n    #model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())    \n    model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\",strides=2))\n\n    model.add(MaxPooling2D(pool_size=(2,2)))\n\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(512,activation=\"relu\"))\n    model.add(Dense(10,activation=\"softmax\"))\n    \n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    \n    history = model.fit_generator(train_generator, \n                                    steps_per_epoch=len(x_train) \/\/ batch_size, \n                                    validation_data=validation_generator,\n                                    validation_steps=len(x_test) \/\/ batch_size,\n                                    epochs=epochs,\n                                    callbacks = callbacks)","46b3b838":"x_test_recaled = (x_test.astype(\"float32\") \/ 255)\nscores = model.evaluate(x_test_recaled, y_test, verbose=0)\nprint(\"{} : {}\".format(model.metrics_names[1], scores[1]*100))\nprint(\"{} : {}\".format(model.metrics_names[0], scores[0]*100))","505f177f":"import seaborn as sns\nhis_dict = history.history\nfig = plt.figure(figsize=(20, 15))\nx_range = range(len(history.history['loss']))\nsns.set_style('darkgrid')\n\nfig.add_subplot(2,1,1)\nsns.lineplot(x=x_range , y=his_dict[\"val_loss\"],label='Validation Loss')\nsns.lineplot(x=x_range , y=his_dict[\"loss\"],label='Training Loss')\n\nfig.add_subplot(2,1,2)\nsns.lineplot(x=x_range , y=his_dict[\"val_accuracy\"],label='Validation Accuracy')\nsns.lineplot(x=x_range , y=his_dict[\"accuracy\"],label='Training Accuracy')","b476c93e":"test_digit_data = test_data.values.reshape(test_data.shape[0],28,28,1).astype(\"float32\") \/ 255\npredictions = model.predict(test_digit_data)\nresults = np.argmax(predictions, axis = 1) ","a0c30249":"test_data.head()","7e2ad692":"plt.figure(figsize=(20, 10))\nsample_test = test_data.head(20)\nfor index, image_pixels in sample_test.iterrows():\n    label = results[index]\n    showImage(image_pixels, label, index)","8d28b7db":"from sklearn.metrics import confusion_matrix\npreds = model.predict(x_test)\ny_preds = np.argmax(preds, axis = 1)\ny_test_dec = np.argmax(y_test ,axis=1)\n\nplt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix(y_test_dec,y_preds),cmap='OrRd',annot = True)","e31ccc34":"submissions = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmissions['Label'] = results\nsubmissions.to_csv('\/kaggle\/working\/submission.csv', index = False)","69747b85":"## Prediction","26aa7bd7":"## Sample some images from Train set","27843e66":"## Train\/Test","c2ef0eca":"## Create Model","6e543539":"## Output","c37c50e3":"## Confusion Matrix","1e1b8555":"## Evaluate Model","d7e8ba19":"## Fit the Model with GPU","08ce69d5":"## Importing Libraries","3c38b1c5":"## Generate Image Data"}}