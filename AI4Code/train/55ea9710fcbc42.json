{"cell_type":{"3d29326a":"code","01553bf9":"code","d084a280":"code","15d4062a":"code","ac6204b8":"code","625e0a39":"code","b1bd6d31":"code","41ccce81":"code","ea68ce58":"code","8946260f":"code","555a89c7":"code","1ca5b551":"code","f16495cc":"code","98fd33cd":"code","c3929cb8":"code","b134a3e7":"code","a967ae9d":"code","150bdc25":"code","45e5da90":"code","17219078":"code","99eebb7f":"code","f3f66226":"code","59080582":"code","92f42d07":"code","63cfae40":"code","bb438bc8":"code","fb49cbd8":"code","db89e1cc":"code","431d7c80":"code","1f30acf0":"code","264cd4cf":"code","18150c79":"code","e36a707d":"code","2a61672e":"code","88541572":"code","a48b4300":"markdown","1b61dc15":"markdown","b6b4f64f":"markdown","76f1decb":"markdown","57b90daf":"markdown","6ddd7ca2":"markdown","36f7a12b":"markdown","c4438eb7":"markdown","84c0a589":"markdown","dec80c26":"markdown","63bc3e87":"markdown","7d6454d5":"markdown","5582755d":"markdown","8d3fc572":"markdown","f407cdaa":"markdown","8b277a68":"markdown","68f34298":"markdown","84e9d9a2":"markdown","027f0ebe":"markdown","fe6701c4":"markdown","6aa74287":"markdown","6e064494":"markdown","b99f37d0":"markdown","6d0fe162":"markdown","b814debf":"markdown","19cafc34":"markdown","78a48afc":"markdown","ee443933":"markdown","c00d8010":"markdown","ce0f1139":"markdown","000a541c":"markdown","efe5157b":"markdown","b79df023":"markdown","733c6f8b":"markdown","5fafe297":"markdown","5f74acdb":"markdown","17556d85":"markdown","27550f93":"markdown","a28fc0fe":"markdown","45f62fdf":"markdown","03c71e15":"markdown","8bcc779e":"markdown","430ea56c":"markdown","8ea6605c":"markdown","19f61f03":"markdown","f6e991ca":"markdown","879a3085":"markdown","3e89e4bf":"markdown","d5ed5912":"markdown","48bf98bd":"markdown"},"source":{"3d29326a":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport copy\nimport sys\nimport cv2\nimport os","01553bf9":"# Specify image size\nimg_size = 224\n\n# Making function for create data from path\ndef create_data():\n    \n    # Specify images path\n    \n    Kane = '..\/input\/sport-celebrity-image-classification\/Sports-celebrity images\/Kane Williamson\/'\n    Kobe = '..\/input\/sport-celebrity-image-classification\/Sports-celebrity images\/Kobe Bryant\/'\n    Maria = '..\/input\/sport-celebrity-image-classification\/Sports-celebrity images\/Maria Sharapova\/'\n    Ronaldo =  '..\/input\/sport-celebrity-image-classification\/Sports-celebrity images\/Ronaldo\/'\n    \n    \n    # Labels\n    Labels = {Kane:0, Kobe:1, Maria:2, Ronaldo:3}\n    \n    # Initializing list for storing data\n    data = []\n    \n    # Initializing list for storing label\n    labels = np.array([])\n    \n    # Looping through each label\n    for label in Labels:\n        \n        # Looping through each category > (Kane, Kobe, Maria, Ronaldo)\n        for ls in os.listdir(label):\n            \n            # Join each ls element with file path\n            path = os.path.join(label, ls)\n\n            # Read images from path using cv2\n            img = cv2.imread(path, cv2.IMREAD_COLOR)\n            img = cv2.resize(img, (img_size, img_size))\n\n            # Convert color from BGR to RGB\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n\n            # Adding data into data and labels list\n            data.append(np.array(img))\n            labels = np.append(labels, Labels[label])\n\n\n    return np.array(data), labels","d084a280":"# Create data and labels\ndata, labels = create_data()\n\n# Look at data size\nprint(f\"Data with shape {data.shape}\")\nprint(f\"Label with shape {labels.shape}\")","15d4062a":"# Function for showing images\ndef show_img(dataset, label):\n    # Randomly choose image index\n    random_idx = np.random.randint(low=0, high=dataset.shape[0], size=10)\n\n    # Initializing fig and ax variables\n    fig, axs = plt.subplots(2, 5, figsize=(16,8))\n\n    # Looping through each axs\n    for i, ax in enumerate(axs.flatten()):\n\n        # Showing image\n        ax.imshow(dataset[random_idx[i],:], cmap='gray')\n        ax.axis('off')\n        \n        # Set title for each image\n        if label[random_idx[i]] ==0:\n            ax.set_title(\"Kane Williamson\")\n        elif label[random_idx[i]] ==1:\n            ax.set_title(\"Kobe Bryant\")\n        elif label[random_idx[i]] ==2:\n            ax.set_title(\"Maria Sharapova\")\n        elif label[random_idx[i]] ==3:\n            ax.set_title(\"Ronaldo\")\n    fig.tight_layout()\n    plt.show()","ac6204b8":"show_img(data, labels)","625e0a39":"data = data \/ np.max(data)\nprint(f\"Min of data is {np.min(data)}\")\nprint(f\"Max of data is {np.max(data)}\")","b1bd6d31":"# Copy data variable and store in flip_data variable\nflip_data = copy.deepcopy(data)\n\n# random index to flip!\nflip_idx = np.round(np.random.rand(flip_data.shape[0]))\n\n# Flip it!\nfor idx in range(len(flip_idx)):\n    \n    # Check if flip_idx is 1 then flip it. On the other hands, i will add noise instead!\n    if flip_idx[idx] == 1:\n        flip_data[idx,:] = cv2.flip(flip_data[idx], -1)\n    \n    # Adding noise for flip_idx is 0\n    else:\n        flip_data[idx, :] = flip_data[idx,:] + np.random.rand(*flip_data[idx].shape)\n        flip_data[idx, :] \/= np.max(flip_data[idx,:])","41ccce81":"show_img(flip_data, labels)","ea68ce58":"# Concat data with flip_data variable\ndata = np.concatenate((data, flip_data))\n\n# Concat labels twice because we use same data twice\nlabels = np.concatenate((labels, labels))\n","8946260f":"show_img(data, labels)\nprint(data.shape)","555a89c7":"# Reshape data to (num_of_pic, 3, img_size, img_size) then convert it to torch.tensor\ndata_T = torch.tensor(data.reshape(data.shape[0], 3, img_size, img_size)).float()\n\n# convert label to torch.tensor with long type\nlabels_T = torch.tensor(labels).long()\n\n# Look at their shape!\nprint(data_T.shape)\nprint(labels_T.shape)","1ca5b551":"train_data, test_data, train_label, test_label = train_test_split(data_T, labels_T,\n                                                                 test_size=.2, stratify=labels_T,\n                                                                 random_state=555)\nprint(f\"Train data shape {train_data.shape}\")\nprint(f\"Test data shape {test_data.shape}\")","f16495cc":"train_ts = torch.utils.data.TensorDataset(train_data, train_label)\ntest_ts = torch.utils.data.TensorDataset(test_data, test_label)","98fd33cd":"train_loader = torch.utils.data.DataLoader(train_ts, batch_size=35, shuffle=True, drop_last=True)\ntest_loader = torch.utils.data.DataLoader(test_ts, batch_size=10, shuffle=True)","c3929cb8":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","b134a3e7":"def train_model(model, lossfunc, optimizer, n_epochs, train_data, val_data):\n    \n    # For storing best perfrom model!\n    bestmodel = {'acc': 0, 'net': None}\n    \n    # Initializing variables for storing result\n    train_losses = []\n    val_losses = []\n    train_acc = []\n    val_acc = []\n    \n    # Use GPU for our model\n    model = model.to(device)\n    \n    # Training loop\n    for epochi in range(n_epochs):\n        \n        # Training mode\n        model.train()\n        \n        # Variable for storing result each batch\n        batch_train = []\n        batch_loss = []\n        \n        # Training in train_data\n        for X, y in train_data:\n            \n            # Push data into GPU\n            X = X.to(device)\n            y = y.to(device)\n            \n            # Predict model\n            pred = model(X)\n            # How many error in this prediction ? (compute for error)\n            loss = lossfunc(pred, y)\n            \n            # Set gradient to zero\n            optimizer.zero_grad()\n            # Compute Loss\n            loss.backward()\n            # Do back prop\n            optimizer.step()\n            \n            # Storing loss this batch into batch_loss\n            batch_loss.append(loss.item())\n            \n            # move pred, y to CPU\n            pred = pred.cpu()\n            y = y.cpu()\n            \n            # Computing accuracy and storing result\n            matches = (torch.argmax(pred, axis=1) == y).float()\n            batch_train.append(100*torch.mean(matches).item())\n        \n        # Compute average of batch_train and batch_loss\n        train_acc.append(np.mean(batch_train))\n        train_losses.append(np.mean(batch_loss))\n            \n        # Using eval mode\n        model.eval()\n        \n        batch_val = []\n        batch_val_loss = []\n        # Testing in validation_data to avoid overfitting\n        for X, y in val_data:\n        \n            # Push data into GPU\n            X = X.to(device)\n            y = y.to(device)\n\n            # Using torch.no_grad() to switch off gradient computation\n            with torch.no_grad():\n                # Predict model\n                pred = model(X)\n\n            loss = lossfunc(pred, y)\n            # Store test loss\n            batch_val_loss.append(loss.item())\n\n            # move pred to CPU\n            pred = pred.cpu()\n            y = y.cpu()\n\n            matches = (torch.argmax(pred, axis=1) == y).float()\n            batch_val.append(100*torch.mean(matches).item())\n        \n        val_acc.append(np.mean(batch_val))\n        val_losses.append(np.mean(batch_val_loss))\n        # Craete msg for printing result\n        msg = f\"Epoch {epochi+1} out of {n_epochs} with Train acc {train_acc[-1]:.2f}% Val acc {val_acc[-1]:.2f}% and Val Loss {val_losses[-1]:.8f}\"\n        sys.stdout.write('\\r'+msg)\n        \n        # Storing bestmodel\n        if val_acc[-1] > bestmodel['acc']:\n            \n            bestmodel['acc'] = val_acc[-1].item()\n            bestmodel['net'] = copy.deepcopy(model.state_dict())\n    \n    return train_acc, val_acc, train_losses, val_losses, model, bestmodel","a967ae9d":"resnet50 = torchvision.models.resnet50(pretrained=True)\nresnet50","150bdc25":"resnet50.fc = nn.Linear(2048, 4)\nresnet50","45e5da90":"resnet50lossfunc = nn.CrossEntropyLoss()\nresnet50optimizer = torch.optim.Adam(resnet50.parameters(), lr=.001)","17219078":"train_acc, val_acc, train_losses, val_losses, resnet50, bestresnet50 = train_model(resnet50, resnet50lossfunc,\n                                                                            resnet50optimizer, 50,\n                                                                            train_loader, test_loader)","99eebb7f":"bestresnet50['acc']","f3f66226":"fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n\n# Plot loss\naxs[0].plot(train_losses, 'b^-', alpha=.8)\naxs[0].plot(val_losses, 'rs-', alpha=.7)\naxs[0].set_yscale('log')\naxs[0].set_title('Loss (ResNet50)')\naxs[0].set_xlabel(\"Epoch\")\naxs[0].set_ylabel(\"Loss\")\n\naxs[1].plot(train_acc, 'bo-', alpha=.8, label='Train')\naxs[1].plot(val_acc, 'rs-', alpha=.9, label='Val')\naxs[1].set_xlabel(\"Epoch\")\naxs[1].set_ylabel(\"Accuracy\")\naxs[1].set_title(\"Train and Validation Accuracy (ResNet50)\")\naxs[1].legend()\nplt.show()","59080582":"vgg16 = torchvision.models.vgg16(pretrained=True)\nvgg16","92f42d07":"vgg16.classifier[6] = nn.Linear(in_features=4096, out_features=4, bias=True)\nvgg16","63cfae40":"vgg16lossfunc = nn.CrossEntropyLoss()\nvgg16optimizer = torch.optim.Adam(vgg16.parameters(), lr=.001)","bb438bc8":"train_acc, val_acc, train_losses, val_losses, vgg16, bestvgg16 = train_model(vgg16, vgg16lossfunc,\n                                                                            vgg16optimizer, 50,\n                                                                            train_loader, test_loader)","fb49cbd8":"bestvgg16['acc']","db89e1cc":"fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n\n# Plot loss\naxs[0].plot(train_losses, 'b^-', alpha=.8)\naxs[0].plot(val_losses, 'rs-', alpha=.7)\naxs[0].set_yscale('log')\naxs[0].set_title('Loss (VGG-16)')\naxs[0].set_xlabel(\"Epoch\")\naxs[0].set_ylabel(\"Loss\")\n\naxs[1].plot(train_acc, 'bo-', alpha=.8, label='Train')\naxs[1].plot(val_acc, 'rs-', alpha=.9, label='Val')\naxs[1].set_xlabel(\"Epoch\")\naxs[1].set_ylabel(\"Accuracy\")\naxs[1].set_title(\"Train and Validation Accuracy (VGG-16)\")\naxs[1].legend()\nplt.show()","431d7c80":"gnet = torchvision.models.googlenet(pretrained=True)\ngnet","1f30acf0":"gnet.fc = nn.Linear(in_features=1024, out_features=4, bias=True)\ngnet","264cd4cf":"gnetlossfunc = nn.CrossEntropyLoss()\ngnetoptimizer = torch.optim.Adam(gnet.parameters(), lr=.001)","18150c79":"train_acc, val_acc, train_losses, val_losses, gnet, bestgnet = train_model(gnet, gnetlossfunc,\n                                                                            gnetoptimizer, 50,\n                                                                            train_loader, test_loader)","e36a707d":"bestgnet['acc']","2a61672e":"fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n\n# Plot loss\naxs[0].plot(train_losses, 'b^-', alpha=.8)\naxs[0].plot(val_losses, 'rs-', alpha=.7)\naxs[0].set_yscale('log')\naxs[0].set_title('Loss (GoogleNet)')\naxs[0].set_xlabel(\"Epoch\")\naxs[0].set_ylabel(\"Loss\")\n\naxs[1].plot(train_acc, 'bo-', alpha=.8, label='Train')\naxs[1].plot(val_acc, 'rs-', alpha=.9, label='Val')\naxs[1].set_xlabel(\"Epoch\")\naxs[1].set_ylabel(\"Accuracy\")\naxs[1].set_title(\"Train and Validation Accuracy (GoogleNet)\")\naxs[1].legend()\nplt.show()","88541572":"## Have a good day :D","a48b4300":"Again if you think notebook give you something or you like this notebook please upvote :D","1b61dc15":"WoW that looks really great ! let's see how it looks in graph","b6b4f64f":"Function for showing image","76f1decb":"Function for importing data","57b90daf":"**Hello everyone ! How are you ?**","6ddd7ca2":"Function for trainning","36f7a12b":"Randomly flip data and adding noise to it!","c4438eb7":"Split train and test set with train_test_split from sklearn","84c0a589":"show images again with full dataset and print its size","dec80c26":"I hope you doing well because i'm really excited to publish my second notebook here haha","63bc3e87":"If there is something that you think i can improve please feel free to comment.","7d6454d5":"Thanks again everyone i hope you like it ! If you have a suggestion please feel free to comment :D","5582755d":"## GoogleNet","8d3fc572":"Making loss function and optimizer for vgg16","f407cdaa":"Any suggestion is very important for me to improve myself and make me strong :P","8b277a68":"## Data Augmentation to increase data size","68f34298":"Because I really love reading your comment!","84e9d9a2":"Concatenate result to data","027f0ebe":"## Import data","fe6701c4":"Plot ResNet50 performance!","6aa74287":"Import ResNet50 model from torchvision","6e064494":"![](https:\/\/assets.rebelmouse.io\/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vbWVkaWEucmJsLm1zL2ltYWdlP3U9JTJGZmlsZXMlMkYyMDE2JTJGMDclMkYzMSUyRjYzNjA1NTg3NDk0OTQ1ODY1NzkxMzEzMTEzMV9TQi1FeGNpdGVkLmpwZyZobz1odHRwcyUzQSUyRiUyRmF6NjE2NTc4LnZvLm1zZWNuZC5uZXQmcz0yNDcmaD00M2VhOWQyNTk4OWMzY2M0MmFjOTQ3NjkyMjc0ZjRkNGRjYWI5NDI1ZGJjMGU3ZDllYTRkZWNiYmExNzM0OTVkJnNpemU9OTgweCZjPTEwMTA0NzExMjQiLCJleHBpcmVzX2F0IjoxNjU3MTcyNzcxfQ.rfk6KFIHdCaIqzLfZf4L1HT5YmUaGlXfjMSASAo6zMU\/img.jpg?width=1200&height=628)","b99f37d0":"Change out_features from Output layer","6d0fe162":"Create lossfunction and optimzier","b814debf":"Look at images!","19cafc34":"Look at our result!","78a48afc":"Convert numpy array into torch.tensor","ee443933":"## Split data into train and test set","c00d8010":"Normalize data","ce0f1139":"## Look at our images !!","000a541c":"## Import Library","efe5157b":"Checking for GPU","b79df023":"Make TensorDataset!","733c6f8b":"## VGG-16","5fafe297":"Change output layer !","5f74acdb":"Let's create DataLoader !","17556d85":"It looks like vgg16 didn't do well in this dataset :C. However, let's see plotting","27550f93":"Train it!","a28fc0fe":"## Resnet50 !!","45f62fdf":"Set loss function and optimizer then train it!!","03c71e15":"Thank you so much for you attention to this notebook and i hope you enjoy this!","8bcc779e":"Check best gnet (googlenet) :P","430ea56c":"Look at best vgg16 model","8ea6605c":"Let's look at bestmodel!","19f61f03":"## Create function for training","f6e991ca":"Change output layer","879a3085":"Have a good day and enjoy","3e89e4bf":"## Thank you","d5ed5912":"What about other model? We should try !","48bf98bd":"## Create DataLoader object"}}