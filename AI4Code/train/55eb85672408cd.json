{"cell_type":{"78d8e879":"code","7436d316":"code","dce94694":"code","2f938133":"code","87e7bb87":"code","a570a4e3":"code","cef0919f":"code","8e693085":"code","41444db0":"code","b1bf938d":"code","abc03c21":"code","c01c0e04":"code","985a5ea8":"code","a9acff35":"code","bdc9023d":"code","a00a244d":"code","4e17ccd2":"code","44e4ad4a":"code","9e7c467e":"code","1ea04bec":"code","b185bad0":"code","d5328495":"code","17e9510a":"code","f5eb2d98":"code","b81412e5":"code","2e8dd91b":"code","5fa2d658":"code","bed979e3":"code","53217c8d":"code","abe0ad5a":"code","983c8196":"code","4dcb7d98":"code","e3459d99":"code","9f2948b2":"code","c4ee515d":"code","5b099ec8":"code","81b61a6d":"code","590edf5e":"code","a6584eac":"code","dbd6782c":"code","d460bc24":"code","78c2194c":"code","a93d42e5":"code","b87ca280":"code","e11b573f":"code","33c4bd7e":"code","1fd97b4c":"code","d43e8cbe":"code","389232ca":"code","db8d3aa8":"code","527d9fc3":"code","b1a44ad5":"code","6199c35c":"code","e255c5de":"code","634b9d4e":"code","081f3f7d":"code","dbb3ed99":"code","5ed11806":"code","f9e669b0":"code","986f3061":"code","0b8ff287":"code","f26cfb8a":"code","1d9547ca":"code","b2a7bb75":"code","361d9030":"code","6741a6be":"code","f69ebde8":"code","818f2f59":"code","5cbe5561":"code","9859f313":"code","066c1bdc":"code","1a3a4495":"code","895aba9c":"code","1fb2529a":"code","d78be781":"code","9a07ff19":"code","862d7f41":"code","1ce3bea1":"code","295ee44c":"code","b578c8fc":"code","c4528a18":"code","00abc46a":"code","07c88878":"code","97351c6a":"code","5ac29ca5":"code","eb4eac42":"code","53801bbb":"code","e9c889a3":"code","9b853ceb":"code","b4356d61":"code","061a61a5":"code","787d706d":"markdown","5c2eeb62":"markdown","2f113702":"markdown","634b0f1c":"markdown","aeb0880e":"markdown","829a4297":"markdown","c4c1cf15":"markdown","d26ae2ce":"markdown","3965a6fe":"markdown","741c4781":"markdown","3bdaa4cb":"markdown","89c1f6a4":"markdown","a78eb7f1":"markdown"},"source":{"78d8e879":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7436d316":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport re\nfrom sklearn.preprocessing import LabelEncoder","dce94694":"tr = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/\/train.csv')\nts = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/\/sample_submission.csv')","2f938133":"tr.head(3)","87e7bb87":"print(tr.shape)\nprint(ts.shape)","a570a4e3":"sns.countplot(tr['country'])","cef0919f":"sns.distplot(tr['num_sold'])","8e693085":"df = pd.concat([tr,ts])","41444db0":"df['day'] = pd.to_datetime(df.date).dt.day\ndf['day_w'] = pd.to_datetime(df.date).dt.dayofweek\ndf['month'] = pd.to_datetime(df.date).dt.month\ndf['year'] = pd.to_datetime(df.date).dt.year","b1bf938d":"def trait_season(x):\n  if ((x<=4)&(x>=2)):\n    return 0\n  elif ((x<=7)&(x>=5)):\n    return 1\n  elif ((x<=10)&(x>=8)):\n    return 2\n  else:\n    return 3\ndf['season'] = df['month'].apply(trait_season)","abc03c21":"def trait_weekend(x):\n  if x>=5:\n    return 1\n  else :\n    return 0\ndf['weekend'] = df['day_w'].apply(trait_weekend)","c01c0e04":"#Public holiday and school holidays","985a5ea8":"!pip install holidays","a9acff35":"from datetime import date\nimport holidays","bdc9023d":"fin_holidays = holidays.FIN()\nnor_holidays = holidays.NOR()\nswd_holidays = holidays.SWE()","a00a244d":"holidays=[]\nfor k in range(len(df)):\n  if df['country'].iloc[k] == 'Finland':\n    if df['date'].iloc[k] in fin_holidays:\n      holidays.append(1)\n    else:\n      holidays.append(0)\n  elif df['country'].iloc[k] == 'Norway':\n    if df['date'].iloc[k] in nor_holidays:\n      holidays.append(1)\n    else:\n      holidays.append(0)\n  else:\n    if df['date'].iloc[k] in swd_holidays:\n      holidays.append(1)\n    else:\n      holidays.append(0)\ndf['holidays'] = holidays","4e17ccd2":"df.groupby('country')['store'].value_counts()","44e4ad4a":"sns.countplot(tr['product'])","9e7c467e":"#PIB\npib_fin = {\"2015\":234.4,\"2016\":240.6,\"2017\":255,\"2018\":275.8,\"2019\":269}\npib_nor = {\"2015\":385.5,\"2016\":368.8,\"2017\":398.4,\"2018\":437,\"2019\":405.5}\npib_swd = {\"2015\":505.1,\"2016\":515.7,\"2017\":541,\"2018\":555.5,\"2019\":531.3}","1ea04bec":"#https:\/\/www.journaldunet.com\/business\/salaire\/classement\/pays\/revenus\nrev_fin = {\"2015\":3877.5,\"2016\":3754.2,\"2017\":3732.5,\"2018\":4019.2,\"2019\":4163.3}\nrev_nor = {\"2015\":7119.2,\"2016\":6865.8,\"2017\":6304.2,\"2018\":6693.3,\"2019\":6801.7}\nrev_swd = {\"2015\":4813.3,\"2016\":4540,\"2017\":4419.2,\"2018\":4636.7,\"2019\":4674.2}","b185bad0":"#Inflation\ninf_fin = {\"2015\":-0.16,\"2016\":0.39,\"2017\":0.84,\"2018\":1.17,\"2019\":1.33}\ninf_nor = {\"2015\":2.17,\"2016\":3.55,\"2017\":1.88,\"2018\":2.77,\"2019\":2.17}\ninf_swd = {\"2015\":0.05,\"2016\":1.74,\"2017\":1.74,\"2018\":2.04,\"2019\":1.75}","d5328495":"#unemployment\nun_fin = {\"2015\":9.38,\"2016\":8.79,\"2017\":8.7,\"2018\":8.11,\"2019\":7.78}\nun_nor = {\"2015\":4.37,\"2016\":4.7,\"2017\":4,\"2018\":3.8,\"2019\":3.7}\nun_swd = {\"2015\":7.4,\"2016\":6.95,\"2017\":6.57,\"2018\":6.33,\"2019\":6.3}","17e9510a":"pib_fin[str(df['year'].iloc[0])]","f5eb2d98":"pib=[]\nrev=[]\ninf=[]\nunp=[]\nfor k in range(len(df)):\n  if df['country'].iloc[k] == 'Finland':\n    pib.append(pib_fin[str(df['year'].iloc[k])])\n    rev.append(rev_fin[str(df['year'].iloc[k])])\n    inf.append(inf_fin[str(df['year'].iloc[k])])\n    unp.append(un_fin[str(df['year'].iloc[k])])\n  elif df['country'].iloc[k] == 'Norway':\n    pib.append(pib_nor[str(df['year'].iloc[k])])\n    rev.append(rev_nor[str(df['year'].iloc[k])])\n    inf.append(inf_nor[str(df['year'].iloc[k])])\n    unp.append(un_nor[str(df['year'].iloc[k])])\n  else:\n    pib.append(pib_swd[str(df['year'].iloc[k])])\n    rev.append(rev_swd[str(df['year'].iloc[k])])\n    inf.append(inf_swd[str(df['year'].iloc[k])])\n    unp.append(un_swd[str(df['year'].iloc[k])])","b81412e5":"df['PIB'] = pib\ndf['REV'] = rev\ndf['INF'] = inf\ndf['UNP']= unp","2e8dd91b":"df.head(2)","5fa2d658":"df.drop(['row_id','date'],1,inplace=True)","bed979e3":"print(tr.shape)","53217c8d":"cols=['country','store','product']\nle=LabelEncoder()\nfor col in cols:\n  df[col] = le.fit_transform(df[col])","abe0ad5a":"tr_data = df[:26298]\nts_data = df[26298::]\nts_data.drop('num_sold',1,inplace=True)\nprint(tr_data.shape)","983c8196":"colormap = sns.diverging_palette(220, 10, as_cmap = True)\nplt.figure(figsize=(15,15))\nsns.heatmap(tr_data.corr(), cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 12},cmap = colormap, linewidths=0.1, linecolor='white')","4dcb7d98":"from sklearn.model_selection import train_test_split","e3459d99":"X = tr_data.drop('num_sold',1)\nY = tr_data['num_sold']","9f2948b2":"x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=0.15)","c4ee515d":"def smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return np.abs(y_true - y_pred) \/ (y_true + np.abs(y_pred)) * 200","5b099ec8":"#import statsmodels.api as sm\n#from scipy import stats","81b61a6d":"#X2 = sm.add_constant(X)\n#est = sm.OLS(Y, X2)\n#est2 = est.fit()\n#print(est2.summary())","590edf5e":"# Great !!, All p_value are < 5%","a6584eac":"#from sklearn.feature_selection import SelectKBest\n#from sklearn.feature_selection import f_regression","dbd6782c":"#fs = SelectKBest(score_func=f_regression, k=13)\n#x_sb= fs.fit_transform(X,Y)","d460bc24":"#display the selected features\n#l_f = fs.get_support()\n#l_f2 = ts_data.columns\n#l_f2 = list(l_f2)\n\n#fs_se = []\n#for i in range (len(l_f2)):\n#  if l_f[i] == True :\n#    fs_se.append(l_f2[i])\n    \n#new_test = ts_data[fs_se]","78c2194c":"#x_tr1,x_val1,y_tr1,y_val1=train_test_split(x_sb,Y,test_size=0.15)","a93d42e5":"#Try with log\ny_tr_lg = y_tr.apply(np.log)\ny_val_lg = y_val.apply(np.log)","b87ca280":"import lightgbm as lgb\ntrn_data_lg = lgb.Dataset(x_tr, label=y_tr_lg)\nval_data_lg = lgb.Dataset(x_val, label=y_val_lg)","e11b573f":"#LGB with params0","33c4bd7e":"params0 = {'objective': 'regression', # Manual optimization\n           'force_row_wise': True,\n           'max_bin': 400, # need more bins than days in a year\n           'verbosity': -1,\n           'seed': 1,\n           'bagging_seed': 3,\n           'feature_fraction_seed': 2,\n           'learning_rate': 0.018,\n           'lambda_l1': 0,\n           'lambda_l2': 1e-2,\n           'num_leaves': 10,\n           'feature_fraction': 0.710344827586207,\n           'bagging_fraction': 0.47931034482758617,\n           'bagging_freq': 5,\n           'min_child_samples': 20}","1fd97b4c":"lgb_model_lg = lgb.train(params0, trn_data_lg, 25000, valid_sets = [trn_data_lg, val_data_lg], verbose_eval=2000)","d43e8cbe":"pred_val_lg = lgb_model_lg.predict(x_val,num_iteration=lgb_model_lg.best_iteration)","389232ca":"pred_val2 = np.exp(pred_val_lg)","db8d3aa8":"plt.figure(figsize=(10, 10))\nplt.scatter(y_val, pred_val2, s=1, color='r')\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","527d9fc3":"smape = np.mean(smape_loss(y_val, pred_val2))\nsmape","b1a44ad5":"pred_test_lg = lgb_model_lg.predict(ts_data,num_iteration=lgb_model_lg.best_iteration)","6199c35c":"pred_test = np.exp(pred_test_lg)","e255c5de":"sub['num_sold'] = pred_test","634b9d4e":"sub.to_csv('third.csv',index=False)","081f3f7d":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","dbb3ed99":"params_gs = {'objective': ['regression'], # Manual optimization\n           'force_row_wise': [True],\n           'max_bin': [350,400], # need more bins than days in a year\n           'learning_rate': [0.01,0.05,0.1],\n           'lambda_l2': [1e-1,1e-2,1e-3],\n           'num_leaves': [10,20,30],\n           'max_depth': [10,15,20],\n           'feature_fraction': [0.85],\n           'bagging_fraction': [0.8],\n           'bagging_freq':[3],\n           'min_child_samples': [10,20,30]}","5ed11806":"lgb_model_lg = lgb.LGBMRegressor()","f9e669b0":"gsearch_lgb = GridSearchCV(lgb_model_lg, param_grid = params_gs, verbose=1)","986f3061":"gsearch_lgb.fit(x_tr,y_tr_lg)","0b8ff287":"print('best params')\nprint (gsearch_lgb.best_params_)","f26cfb8a":"best_lg = {'bagging_fraction': 0.8, 'bagging_freq': 3, 'feature_fraction': 0.85, 'force_row_wise': True, 'lambda_l2': 0.1, 'learning_rate': 0.1, 'max_bin': 350, 'max_depth': 15, 'min_child_samples': 10, 'num_leaves': 30, 'objective': 'regression'}","1d9547ca":"#Training with best parameters\nlgb_model_lg = lgb.train(best_lg, trn_data_lg, 18000, valid_sets = [trn_data_lg, val_data_lg], verbose_eval=2000)","b2a7bb75":"pred_val_lg = lgb_model_lg.predict(x_val,num_iteration=lgb_model_lg.best_iteration)","361d9030":"pred_val3 = np.exp(pred_val_lg)","6741a6be":"smape = np.mean(smape_loss(y_val, pred_val3))\nsmape","f69ebde8":"preds_test = lgb_model_lg.predict(ts_data)","818f2f59":"sub['num_sold'] = np.exp(preds_test)\nsub.to_csv('best.csv',index=False)","5cbe5561":"!pip install catboost","9859f313":"from catboost import CatBoostRegressor","066c1bdc":"cat_model = CatBoostRegressor(iterations= 25000,\n        depth= 7, \n        learning_rate=0.02,\n        l2_leaf_reg= 12.06,\n        bootstrap_type= 'Bayesian',\n        boosting_type= 'Plain',\n        loss_function= 'MAPE',\n        eval_metric= 'SMAPE',\n        #od_type= 'Iter',       # type of overfitting detector\n        #od_wait= 40,\n        has_time= True)","1a3a4495":"cat_model.fit(x_tr, y_tr_lg,\n             eval_set=(x_val, y_val_lg),\n             use_best_model=True,\n             verbose=2000)","895aba9c":"pred_val_xg = cat_model.predict(x_val)","1fb2529a":"pred_val_xg = np.exp(pred_val_xg)\nprint('SMAPE : ')\nnp.mean(smape_loss(y_val, pred_val_xg))","d78be781":"pred_test = cat_model.predict(ts_data)\npred_test = np.exp(pred_test)","9a07ff19":"sub['num_sold']=pred_test\nsub.to_csv('cat.csv',index=False)","862d7f41":"from xgboost import XGBRegressor","1ce3bea1":"xgbmodel = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.07, max_depth=12, \n                             min_child_weight=1.7817, n_estimators=5000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\nxgbmodel.fit(x_tr,y_tr_lg)","295ee44c":"pred_xgb = xgbmodel.predict(x_val)\npred_xgb = np.exp(pred_xgb)","b578c8fc":"print('SMAPE : ')\nnp.mean(smape_loss(y_val, pred_xgb))","c4528a18":"from sklearn.ensemble import StackingRegressor\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor","00abc46a":"params0 = {'objective': 'regression', # Manual optimization\n           'force_row_wise': True,\n           'max_bin': 400, # need more bins than days in a year\n           'verbosity': -1,\n           'seed': 1,\n           'bagging_seed': 3,\n           'feature_fraction_seed': 2,\n           'learning_rate': 0.018,\n           'lambda_l1': 0,\n           'lambda_l2': 1e-2,\n           'num_leaves': 10,\n           'feature_fraction': 0.710344827586207,\n           'bagging_fraction': 0.47931034482758617,\n           'bagging_freq': 5,\n           'min_child_samples': 20}","07c88878":"#Try with log\ny_tr_lg = y_tr.apply(np.log)\ny_val_lg = y_val.apply(np.log)","97351c6a":"estimators = [\n     ('XGB',XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.07, max_depth=12, \n                             min_child_weight=1.7817, n_estimators=5000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1) ),\n     ('CAT',CatBoostRegressor(iterations= 25000,\n        depth= 7, \n        learning_rate=0.02,\n        l2_leaf_reg= 12.06,\n        bootstrap_type= 'Bayesian',\n        loss_function= 'MAPE',\n        eval_metric= 'SMAPE',\n        has_time= True))]","5ac29ca5":"reg = StackingRegressor(\n     estimators=estimators,\n     final_estimator=lgb.LGBMRegressor(**params0),verbose=100)","eb4eac42":"reg.fit(x_tr, y_tr_lg)","53801bbb":"pred_st = reg.predict(x_val)\npred_st = np.exp(pred_st)","e9c889a3":"np.mean(smape_loss(y_val, pred_st))","9b853ceb":"pred_test = reg.predict(ts_data)\npred_test = np.exp(pred_test)","b4356d61":"sub['num_sold'] = pred_test","061a61a5":"sub.to_csv('stack.csv',index=False)","787d706d":"**Test prediction&submission**","5c2eeb62":"# **Modelling**","2f113702":"# **Stacking**","634b0f1c":"# **XGBoost**","aeb0880e":"**Test prediction&submission**","829a4297":"# **CatBoostRegressor**","c4c1cf15":"- This model (stacking) works great and I'm running it on colab but since it takes about 15 minutes to run I'm not running it here on Kaggle.","d26ae2ce":"# **GridSearchCV**","3965a6fe":"# **Feature engineering**","741c4781":"# **Feature selection**","3bdaa4cb":"# **Data Importation**","89c1f6a4":"# **Main**","a78eb7f1":"# **LightGBM**"}}