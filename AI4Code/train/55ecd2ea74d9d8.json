{"cell_type":{"7818b881":"code","3a7bad23":"code","772bbfdd":"code","cd52bfb0":"code","dbb7bdae":"code","2301f3dd":"code","044d49a7":"code","3cf41005":"code","e3143828":"code","89ac7304":"code","10a01b71":"markdown","0a441658":"markdown","87b3ffce":"markdown","1326037a":"markdown","24c33d69":"markdown","31943be1":"markdown","526f00f3":"markdown","9aee2e31":"markdown","fe1a9c8d":"markdown","bd3f19bf":"markdown","edbefe10":"markdown","a3a168a3":"markdown"},"source":{"7818b881":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import RidgeCV","3a7bad23":"def mae(ytrue, ypred, uout=None):\n    if isinstance(uout, pd.Series):\n        print(f'MAE (Inspiration Phase):')\n        return np.mean(np.abs((ytrue - ypred)[uout == 0]))\n    else:\n        print('MAE (All Phases):')\n        return np.mean(np.abs((ytrue - ypred)))","772bbfdd":"data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv', usecols=['pressure', 'u_out'])\nytrue = data.pressure\nuout = data.u_out","cd52bfb0":"pressure_sorted = np.sort(data['pressure'].unique())\nPRESSURE_MIN = pressure_sorted[0]\nPRESSURE_MAX = pressure_sorted[-1]\nPRESSURE_STEP = pressure_sorted[1] - pressure_sorted[0]\n\ndef post_process(pressure):\n    pressure = np.round((pressure - PRESSURE_MIN) \/ PRESSURE_STEP) * PRESSURE_STEP + PRESSURE_MIN\n    pressure = np.clip(pressure, PRESSURE_MIN, PRESSURE_MAX)\n    return pressure","dbb7bdae":"oof1 = np.load('..\/input\/vpp-156-oof\/oof_preds.npy')\nsub1 = pd.read_csv('..\/input\/tfbidirectional156\/submission_median_round_tfbidirec.csv')\nsub1.pressure = post_process(sub1.pressure)\nprint(mae(ytrue, oof1, uout))\n\noof2 = np.load('..\/input\/gb-vpp-why-so-serious\/oof_preds.npy')\nsub2 = pd.read_csv('..\/input\/gb-vpp-why-so-serious\/submission_median_round.csv')\nprint(mae(ytrue, oof2, uout))\n\noof3 = np.load('..\/input\/gb-vpp-to-infinity-and-beyond-td\/oof_preds.npy')\nsub3 = pd.read_csv('..\/input\/gb-vpp-to-infinity-and-beyond-td\/submission_median_round.csv')\nprint(mae(ytrue, oof3, uout))\n\n\noof4 = pd.read_csv('..\/input\/ventilator-train-classification\/exp080_conti_rc\/oof.csv', usecols=['oof'])\noof4 = oof4.to_numpy().ravel()\nsub4 = pd.read_csv('..\/input\/ventilator-train-classification\/exp080_conti_rc\/submission_median_pp.csv')\nprint(mae(ytrue, oof4, uout))\n","2301f3dd":"X = np.stack([oof1, oof2, oof3, oof4], 1)[uout == 0]\ny = ytrue[uout == 0]\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')","044d49a7":"lin_reg = RidgeCV(alphas=np.logspace(-3,10, 20))\nlin_reg.fit(X, y)\npred = lin_reg.predict(X)\nprint(mae(y, pred))\nprint(f'Ensemble Weights: {lin_reg.coef_}')\nprint(f'Sum of weights: {sum(lin_reg.coef_)}')","3cf41005":"submission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\nfor sub in zip([sub1, sub2, sub3, sub4], lin_reg.coef_):\n    submission.pressure += sub[0].pressure * sub[1]","e3143828":"submission.to_csv('submission.csv', index=False)","89ac7304":"submission.pressure = post_process(submission.pressure)\nsubmission.to_csv('submission_pp.csv', index=False)","10a01b71":"# A Basic Ensembling Technique with Cross Validation\n\nThis notebook demonstrates how to ensemble predictions from two different models. For the ensembling, we need the out-of-fold (OOF) predictions as well as the test (submission) predictions of the two models. The OOF predictions will be used as the features to train an ensemble regressor to predict the OOF target values. The coefficients of the ensemble regressor will then be used as the weights of each model's test predictions.","0a441658":"## Load the OOF and the Submission Predictions","87b3ffce":"The MAE score printed above is the score of the combined models with the ensemble weights. It's 0.015 better than the best scoring model! And the best part of this process is that this score is cross validated; so we don't need to worry about LB overfitting!\n\nFurthermore, the sum of the weights are 1, confirming that our method is working fine.","1326037a":"## Input & Target Values","24c33d69":"## Load Data\n\nFrom the training data, we will need the training targets (pressure values). Since the competition metric, mean absolute error, is evaluated only on the inspiration phase (`u_out==0`), we also need the u_out values.","31943be1":"## Load Packages","526f00f3":"Since we ensemble four models, we have only four features for each timestep as can be seen above.","9aee2e31":"## Postprocessing Tools","fe1a9c8d":"## Regression Ensembler Training\nThe ensemble weights will be estimated with the Ridge regression method.","bd3f19bf":"## Ensembling the Predictions","edbefe10":"## Competition Metric\n\nCompetition metric is the mean absolute error, which is calculated only over the inspiration phase data (`u_out==0`). ","a3a168a3":"## Post Processing"}}