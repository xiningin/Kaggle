{"cell_type":{"d8d66333":"code","b8484c00":"code","c20c2f0c":"code","36a282f3":"code","bd861585":"code","8ba1d8d0":"code","dbf21b5d":"code","a53dddd4":"code","5fe9dc3a":"code","418e26ec":"code","ba360c50":"code","4ce9ac0a":"code","1623edda":"code","1c654332":"code","c291e124":"code","cd8d1228":"code","2ad66690":"code","b17387d7":"code","d0c20ecc":"code","38764863":"code","d85dbd9d":"code","d5638d42":"code","f88ba7d8":"markdown","91ab3c93":"markdown","a98eb7a0":"markdown","70c07850":"markdown","4423811b":"markdown","92cd0bbe":"markdown","5609174f":"markdown","37f679ee":"markdown"},"source":{"d8d66333":"# Importing Required packages\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, clear_output\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\nclear_output()","b8484c00":"#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","c20c2f0c":"# Cloning the repo and installing requiements\n!git clone https:\/\/github.com\/ultralytics\/yolov5.git\n!mv .\/yolov5\/* .\/\n!pip install -r requirements.txt\nclear_output()","36a282f3":"# Copying the dataset to working directory\n!mkdir Dataset\n!cp ..\/input\/covid19-detection-for-yolov5-siimfisabiorsna\/Covid19 -r .\/Dataset\nclear_output()","bd861585":"len(os.listdir('.\/Dataset\/Covid19\/images'))","8ba1d8d0":"%%writetemplate .\/split_dataset.py\nfrom utils.datasets import * \nautosplit('.\/Dataset\/Covid19', weights=(0.8, 0.2, 0.0))","dbf21b5d":"!python split_dataset.py","a53dddd4":"os.listdir('.\/Dataset\/Covid19')","5fe9dc3a":"!mkdir DataFile","418e26ec":"%%writetemplate .\/DataFile\/data.yaml\n\ntrain: .\/Dataset\/Covid19\/autosplit_train.txt\nval: .\/Dataset\/Covid19\/autosplit_val.txt\n\nnc: 4\nnames: ['Negative for Pneumonia', 'Typical Appearance',\n        'Indeterminate Appearance', 'Atypical Appearance']","ba360c50":"%%writetemplate .\/models\/custom_yolov5x.yaml\n\n\n# parameters\nnc: 4  # number of classes\ndepth_multiple: 1.33  # model depth multiple\nwidth_multiple: 1.25  # layer channel multiple\n\n# anchors\nanchors:\n  - [10,13, 16,30, 33,23]  # P3\/8\n  - [30,61, 62,45, 59,119]  # P4\/16\n  - [116,90, 156,198, 373,326]  # P5\/32\n\n# YOLOv5 backbone\nbackbone:\n  # [from, number, module, args]\n  [[-1, 1, Focus, [64, 3]],  # 0-P1\/2\n   [-1, 1, Conv, [128, 3, 2]],  # 1-P2\/4\n   [-1, 3, C3, [128]],\n   [-1, 1, Conv, [256, 3, 2]],  # 3-P3\/8\n   [-1, 9, C3, [256]],\n   [-1, 1, Conv, [512, 3, 2]],  # 5-P4\/16\n   [-1, 9, C3, [512]],\n   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5\/32\n   [-1, 1, SPP, [1024, [5, 9, 13]]],\n   [-1, 3, C3, [1024, False]],  # 9\n  ]\n\n# YOLOv5 head\nhead:\n  [[-1, 1, Conv, [512, 1, 1]],\n   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n   [-1, 3, C3, [512, False]],  # 13\n\n   [-1, 1, Conv, [256, 1, 1]],\n   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n   [-1, 3, C3, [256, False]],  # 17 (P3\/8-small)\n\n   [-1, 1, Conv, [256, 3, 2]],\n   [[-1, 14], 1, Concat, [1]],  # cat head P4\n   [-1, 3, C3, [512, False]],  # 20 (P4\/16-medium)\n\n   [-1, 1, Conv, [512, 3, 2]],\n   [[-1, 10], 1, Concat, [1]],  # cat head P5\n   [-1, 3, C3, [1024, False]],  # 23 (P5\/32-large)\n\n   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n  ]","4ce9ac0a":"# I've used wandb before, I don't want it now. So might not need to run this cell\n!wandb off","1623edda":"%%time\n\n!python train.py --img-size 602 --batch 10 --epochs 40 --data '.\/DataFile\/data.yaml' --cfg .\/models\/custom_yolov5x.yaml --weights yolov5x.pt --name experiment2  --cache","1c654332":"%load_ext tensorboard\n%tensorboard --logdir runs","c291e124":"os.listdir('.\/runs\/train\/experiment2\/')","cd8d1228":"Image('.\/runs\/train\/experiment2\/results.png')","2ad66690":"Image('.\/runs\/train\/experiment2\/confusion_matrix.png',width=400)","b17387d7":"Image('.\/runs\/train\/experiment2\/test_batch1_labels.jpg')","d0c20ecc":"Image('.\/runs\/train\/experiment2\/test_batch1_pred.jpg')","38764863":"os.listdir('.\/Dataset\/Covid19')","d85dbd9d":"!python detect.py --img-size 602  --conf 0.1 --source ..\/input\/covid19-detection-for-yolov5-siimfisabiorsna\/Covid19\/images\/1000_0.jpg --weights .\/runs\/train\/experiment2\/weights\/best.pt","d5638d42":"Image('.\/runs\/detect\/exp\/1000_0.jpg')","f88ba7d8":"Defining the dataset","91ab3c93":"# Model Declaration\n\nyou can find all the models [here](https:\/\/github.com\/ultralytics\/yolov5\/tree\/master\/models) and cutomize the classes accordingly.","a98eb7a0":"# Detecting the classes ","70c07850":"# Preparing the dataset","4423811b":"# Training the model","92cd0bbe":"Sptting the dataset for training and validation using datasets from yolov5 repo","5609174f":"# Getting Started\n\nTo get the best result, you can follow my preivous dicussion about [How to win object detection competetion](https:\/\/www.kaggle.com\/c\/global-wheat-detection\/discussion\/232550#1273363) where i got a gold medal.\n\nAnd [This notebook](https:\/\/www.kaggle.com\/espsiyam\/yolov5-ensemble-tta-transfer-learning-hpt)","37f679ee":"# Analyze the result"}}