{"cell_type":{"256b239a":"code","e917b103":"code","7044e2d4":"code","24ea68b4":"code","13359fd9":"code","e2fa9244":"code","047895c3":"code","a57254a8":"code","6838c7a1":"code","7c55ce20":"code","eeb00344":"code","6496b07e":"code","c0517914":"code","777d834b":"code","e1ed2706":"code","4674fb45":"code","b2683c63":"code","be5cb465":"code","d5d647d7":"code","70a07c26":"markdown","ddc6ac68":"markdown","4519bde6":"markdown","c86746f1":"markdown","feee1543":"markdown","af18ba12":"markdown","8bcb56de":"markdown","ebfe3e48":"markdown","dc92a584":"markdown","db0b34de":"markdown","20b1c962":"markdown","26210649":"markdown","35e38efc":"markdown","256983bb":"markdown","d4fecc16":"markdown","46573a53":"markdown"},"source":{"256b239a":"pip install split-folders      # split-folders","e917b103":"# Import Libraries\nimport numpy as np \nimport pandas as pd \nimport time\nimport itertools\n\n# file system libraries\nimport os\nimport os.path\nfrom   os import path\nimport shutil\n\n# confusion matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# splits train folders into train\/validation with stratification\nimport splitfolders  \n\n# Images, Plotting\nfrom skimage import io\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \n\n# tensorflow - CNNs\nimport tensorflow as tf\nimport kerastuner as kt\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend, models, layers, Sequential\nfrom tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Add\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras.applications import DenseNet121,InceptionV3, Xception, ResNet101\nfrom kerastuner.tuners import Hyperband","7044e2d4":"# Constants\nFOLDERS     = ['train','val','test']\nDIR_INPUT   = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset'\nDIR_WORK    = '.\/'\nDIR_MODELS  = os.path.join(DIR_WORK,'models')\nDIR_TRAIN   = os.path.join(DIR_WORK,'train')\nDIR_VAL     = os.path.join(DIR_WORK,'val')\nDIR_TEST    = os.path.join(DIR_WORK,'test')\nCLASS_LIST  = ['MildDememted','ModerateDemented','NonDememted','VeryMildDemented']\n\n\n# Set seeds for reproducibility \nSEED        = 1985\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","24ea68b4":"def images_by_class(path,folders):\n    \"\"\"\n    Loop through the path\/folders count the number and proportions of each class\n    \"\"\"\n    \n    # accumulators\n    normal,verymild,mild,moderate =0,0,0,0\n    \n    # print header\n    msg = '{:8} {:8} {:11} {:7} {:9} {:9} {:11} {:8} {:8}'.format('folder','normal','verymild','mild','moderate',\n                                                        'normal %','verymild %','mild %','moderate %')\n    print(msg)  \n    print(\"-\"*len(msg))\n    \n    for folder in FOLDERS:\n        for dirname,_, filenames in os.walk(os.path.join(path,folder)):\n            for file in filenames:\n                if \"NonDemented\" in dirname:\n                    normal+=1\n                if \"VeryMildDemented\" in dirname:\n                    verymild+=1\n                if 'MildDemented' in dirname:\n                    mild+=1\n                if 'ModerateDemented' in dirname:\n                    moderate+=1\n                    \n        # calculate total and percentages            \n        total = normal+verymild+mild+moderate\n        if total >0:\n            n  = round(normal\/total,2)*100\n            vm = round(verymild\/total,2)*100\n            m  = round(mild\/total,2)*100\n            mo =round(moderate\/total,2)*100\n        else:\n            n,vm,m,mo = 0,0,0,0\n        \n        print(\"{:6} {:8} {:10} {:7} {:11} {:8} {:10} {:8} {:12}\".format(folder,normal,verymild,mild,moderate,n,vm,m,mo))\n        normal,verymild,mild,moderate =0,0,0,0\n\n# Images by class in the input directory\nimages_by_class(DIR_INPUT,FOLDERS) ","13359fd9":"# create a new directory if it doesn't exist\ndef create_dir(dir_path,folder,verbose=True):\n    \"\"\"\n    Create the dir_path\/folder if it doesn't already exist\n    \"\"\"\n    msg = \"\"\n    folder_path = os.path.join(dir_path,folder)\n    \n    if not path.exists(folder_path):\n        try:\n            os.mkdir(folder_path)\n            msg = folder_path + ' created'\n        except OSError as err:\n            print('Error creating folder:{} with error:{}'.format(folder_path,err))\n    if verbose:\n        print(msg)\n        \n    return folder_path\n\n# create model directory\ncreate_dir(DIR_WORK,'models',True)","e2fa9244":"def resample_train_val_images(input_dir,working_dir,seed=SEED,split = (0.80,0.20)):\n    \"\"\"\n    Resample the train images into train\/val by the ratios given in split\n    \"\"\"\n    # get paths\n    dir_test   = os.path.join(input_dir,'test')\n    dir_train  = os.path.join(input_dir,'train')\n    \n\n    # remove existing files\/folders\n    for folder in FOLDERS:\n        if path.exists(os.path.join(working_dir,folder)):\n            shutil.rmtree(os.path.join(working_dir,folder))\n\n            \n    # copy the test directory to working\n    shutil.copytree(dir_test, os.path.join(working_dir,'test'))\n        \n\n    # resample\n    splitfolders.ratio(dir_train, working_dir, seed=seed, ratio=split) \n        \n    # print image summary by folder\n    print(\"\\n Images By Class After Resampling\")\n    print(\"-\"*67)\n    images_by_class(working_dir,FOLDERS)\n    \n    \nresample_train_val_images(DIR_INPUT,DIR_WORK)","047895c3":"\nIMG_SIZE = [176,208]\nBATCH_SIZE = 32\n\n# Scale Images\ntrain_images = ImageDataGenerator(rescale  = 1.\/255)\nval_images   = ImageDataGenerator(rescale  = 1.\/255)\ntest_images  = ImageDataGenerator(rescale  = 1.\/255)\n\n\n# Image Generators\n# train images: 4098\ntrain_gen =train_images.flow_from_directory(\n    DIR_TRAIN,\n    target_size = IMG_SIZE,\n    batch_size  = BATCH_SIZE,\n    class_mode  = 'categorical',\n    color_mode  = 'rgb',          # convert to rgb\n    seed        = SEED \n)\n\n# validation images: 1023\nval_gen = val_images.flow_from_directory(\n    DIR_VAL,\n    target_size = IMG_SIZE,\n    batch_size  = BATCH_SIZE,\n    class_mode  = 'categorical',\n    color_mode  = 'rgb',         # convert to rgb\n    seed        = SEED\n)\n\n# test images:1279\ntest_gen = test_images.flow_from_directory(\n    DIR_TEST,\n    target_size = IMG_SIZE,\n    batch_size  = BATCH_SIZE,\n    class_mode  = 'categorical',\n    color_mode  = 'rgb',         # convert to rgb\n    seed        = SEED,\n    shuffle     = False\n)\n\n# Training and Validation Steps\nsteps_per_epoch  = train_gen.n \/\/ train_gen.batch_size\nprint(\"steps per epoch:{}\".format(steps_per_epoch))","a57254a8":"def show_images(generator,y_pred=None):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASS_LIST))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[i])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_gen)","6838c7a1":"def plot_training_metrics(train_hist,model,test_gen,y_actual,y_pred,classes):\n    \"\"\"\n    Input: trained model history, model, test image generator, actual and predicted labels, class list\n    Output: Plots loss vs epochs, accuracy vs epochs, confusion matrix\n    \"\"\"\n    \n    # Evaluate the results:\n    test_loss, test_metric = model.evaluate(test_gen,verbose = False)\n    results       = round(test_metric,2)*100 \n    results_title =\"\\n Model AUC on Test Data:{}%\".format(results)\n    print(results_title.format(results))\n    print(len(results_title) * \"-\")\n    \n    # print classification report\n    print(classification_report(y_actual, y_pred, target_names=classes))\n\n    # extract data from training history for plotting\n    history_dict    = train_hist.history\n    loss_values     = history_dict['loss']\n    val_loss_values = history_dict['val_loss']\n    auc_values      = history_dict['auc']\n    val_auc_values  = history_dict['val_auc']\n    epochs          = range(1, len(history_dict['auc']) + 1)\n\n    # get the min loss and max accuracy for plotting\n    max_auc = np.max(val_auc_values)\n    min_loss = np.min(val_loss_values)\n    \n    # create plots\n    plt.subplots(figsize=(12,4))\n    \n    # plot loss by epochs\n    plt.subplot(1,3,1)\n    plt.plot(epochs, loss_values, 'bo', label = 'Training loss')\n    plt.plot(epochs, val_loss_values, 'cornflowerblue', label = 'Validation loss')\n    plt.title('Validation Loss by Epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.axhline(y=min_loss,color='darkslategray', linestyle='--')\n    plt.legend()\n\n    # plot accuracy by epochs\n    plt.subplot(1,3,2)\n    plt.plot(epochs, auc_values, 'bo',label = 'Training AUC')\n    plt.plot(epochs, val_auc_values, 'cornflowerblue', label = 'Validation AUC')\n    plt.plot(epochs,[results\/100]*len(epochs),'darkmagenta',linestyle = '--',label='Test AUC')\n    plt.title('Validation AUC by Epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('AUC')\n    plt.axhline(y=max_auc,color='darkslategray', linestyle='--')\n    plt.legend()\n\n    \n    # calculate Confusion Matrix\n    cm = confusion_matrix(y_actual, y_pred)\n\n    # create confusion matrix plot\n    plt.subplot(1,3,3)\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.BuPu)\n    plt.title(\"Confusion Matrix \\n AUC:{}%\".format(results))\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    # loop through matrix, plot each \n    threshold = cm.max() \/ 2.\n    for r, c in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(c, r, format(cm[r, c], 'd'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[r, c] > threshold else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.show()\n","7c55ce20":"def freeze_layers(base,conv_num=\"conv5\",block_num=1,max_block_num=16,trainable_layers='some'):\n    \"\"\"\n    Input: A base transferable model,the layer name, the block number, the max number of blocks\n           The layer name, block number and max of blocks only works with DenseNet121\n    Output:Sets all layers to trainable from conv#_block_num to conv#_max_block_num\n    \n    \"\"\"\n    if trainable_layers=='none':\n        base.trainable = False\n        print(\"No Layers Trainable: Using Base Model Weights\")\n    if trainable_layers=='all':\n        base.trainable =True\n        print(\"All Layers Trainable: Base Model will be fully trained\")\n    \n    if trainable_layers=='some':\n        \n        print(\"Some Layers of the Model will be Trainable:\")\n        print(\"---------------------------------------------\")\n        \n        # set all layers to not trainable\n        base.trainable = False\n\n        # loop through all layers from conv#_block# and set to true\n        print('layer','\\t\\t\\t','trainable')\n        for block in range(block_num,max_block_num+1):\n            for layer in conv_base.layers:\n                if block>=block_num:\n                    if conv_num +\"_block\"+str(block) in layer.name:\n                        layer.trainable = True\n                        print(layer.name,'\\t',layer.trainable)\n                    \n                    ","eeb00344":"# function to build the model\ndef build_transfer_model(conv_base,dropout,dense_node,learn_rate,metric):\n    \"\"\"\n    Build and compile a transfer learning model\n    Input: a base model, dropout rate, the number of filters in the dense node, \n           the learning rate and performance metrics\n    Output: A compiled CNN model\n    \"\"\"\n    \n    # clear previous run\n    backend.clear_session()\n    \n    # build the model\n    model = Sequential()\n    model.add(conv_base)\n    model.add(Dropout(dropout))\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n    model.add(Dense(dense_node,activation='relu'))\n    model.add(Dense(4,activation='softmax'))\n\n\n    # complile the model\n    model.compile(\n        optimizer = tensorflow.keras.optimizers.Adam(lr=learn_rate),\n        loss      = 'categorical_crossentropy', \n        metrics   = metric )\n    \n    model.summary()\n    return model","6496b07e":"# training parameters\nEPOCHS        = 15\nearly_stoping = EarlyStopping(monitor = 'val_auc',patience = 5,restore_best_weights=True)\ncallbacks     = [early_stoping]\nmetrics       = [tf.keras.metrics.AUC(name='auc')]","c0517914":"# Train Model: Base Model\n# get base\nconv_base = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (*IMG_SIZE, 3))\n\n# freeze layers for training\nfreeze_layers(conv_base,trainable_layers='none')\n\n# build and compile the model\nmodel = build_transfer_model(conv_base,dropout=0.4,dense_node =512,learn_rate=0.001,metric=metrics)\n\n\n# train\ntic = time.perf_counter()\nhistory = model.fit(\n    train_gen,\n    epochs           = EPOCHS,\n    validation_data  = val_gen,\n    verbose          = 2,\n    callbacks        = callbacks  # early stopping \n)\n\n# get class predictions\ny_prob = model.predict(test_gen)\ny_pred = y_prob.argmax(axis=-1)\n\n# get actual classes\ny_actual = test_gen.classes\n\n# plot training metrics\nplot_training_metrics(history,model,test_gen,y_actual,y_pred,['mild','moderate','normal','very-mild'])\n\n# Save the Model\nmodel.save(os.path.join(DIR_MODELS,'base_model'))\n\n# display runtime\ntoc = time.perf_counter()\nprint(\"Total Time:{}\".format(round((toc-tic)\/60,2)))\n\n","777d834b":"# function to build the model\n# add an additional conv layer with dropout and batch normalization\ndef build_transfer_model(conv_base,dropout,conv_nodes,dense_node,learn_rate,metric):\n    \"\"\"\n    Build and compile a transfer learning model\n    \"\"\"\n    \n    # clear previous run\n    backend.clear_session()\n    \n    # build the model\n    model = Sequential()\n    model.add(conv_base)\n    model.add(Dropout(dropout))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(conv_nodes,3,padding='same',activation='relu'))\n    model.add(Conv2D(conv_nodes,3,padding='same',activation='relu'))\n    model.add(MaxPooling2D())\n    model.add(Dropout(dropout +0.10))\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n    model.add(Dense(dense_node,activation='relu'))\n    model.add(Dense(4,activation='softmax'))\n\n\n    # complile the model\n    model.compile(\n        optimizer = tensorflow.keras.optimizers.Adam(lr=learn_rate),\n        loss      = 'categorical_crossentropy', \n        metrics   = metric )\n    \n    model.summary()\n    return model\n","e1ed2706":"# Base Model: Plus Additional Capacity\n# training parameters\nEPOCHS        = 50\nearly_stoping = EarlyStopping(monitor = 'val_auc',patience = 10,restore_best_weights=True)\ncallbacks     = [early_stoping]\nmetrics       = [tf.keras.metrics.AUC(name='auc')]\n\n\n\n# Train Model: Base + Additional Capacity\n# get base\nconv_base = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (*IMG_SIZE, 3))\n\n# freeze layers for training\nfreeze_layers(conv_base,trainable_layers='none')\n\n# build and compile the model\nmodel = build_transfer_model(conv_base,dropout=0.5,conv_nodes=1024,dense_node =1024,learn_rate=0.001,metric=metrics)\n\n\n# train\ntic = time.perf_counter()\nhistory = model.fit(\n    train_gen,\n    epochs           = EPOCHS,\n    validation_data  = val_gen,\n    verbose          = 2\n)\n\n# get class predictions\ny_prob = model.predict(test_gen)\ny_pred = y_prob.argmax(axis=-1)\n\n# get actual classes\ny_actual = test_gen.classes\n\n# plot\nplot_training_metrics(history,model,test_gen,y_actual,y_pred,['mild','moderate','normal','very-mild'])\n\n# Save Model\nmodel.save(os.path.join(DIR_MODELS,'model_added_capacity'))\n\n# time\ntoc = time.perf_counter()\nprint(\"Total Time:{}\".format(round((toc-tic)\/60,2)))","4674fb45":"# Tune Hyperparameters  (not run for brevity)\n# define Hyperparameters \n# hp                   = kt.HyperParameters()\n# DROP_RATES           = [0.30,0.40,0.50]\n# CONV_NODES           = [512,1024,2048]\n# DENSE_NODES          = [512,1024,2048]\n# LEARN_RATE           = [0.001,0.0001]\n    \n\n# # get base\n# CONV_BASE = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (*IMG_SIZE, 3))\n\n# # unfreeze layers for training\n# freeze_layers(CONV_BASE,trainable_layers='none')\n\n# # function to build the model\n# def build_model(hp):\n    \n#     # clear previous run\n#     backend.clear_session()\n\n#     # Searchable parameters\n#     dropout    = hp.Choice('dropout',DROP_RATES)\n#     conv_nodes = hp.Choice('conv_node',CONV_NODES)\n#     dense_node = hp.Choice(\"dense_node\",DENSE_NODES)\n#     learn_rate = hp.Choice(\"learn_rate\",LEARN_RATE)\n   \n    \n#     # build the model\n#     model = Sequential()\n#     model.add(CONV_BASE)\n#     model.add(Dropout(dropout))\n#     model.add(BatchNormalization())\n\n#     model.add(Conv2D(conv_nodes,3,padding='same',activation='relu'))\n#     model.add(Conv2D(conv_nodes,3,padding='same',activation='relu'))\n#     model.add(MaxPooling2D())\n#     model.add(Dropout(dropout +0.10))\n#     model.add(BatchNormalization())\n\n#     model.add(Flatten())\n#     model.add(Dense(dense_node,activation='relu'))\n#     model.add(Dense(4,activation='softmax'))\n\n\n#     # complile the model\n#     model.compile(\n#         optimizer = tensorflow.keras.optimizers.Adam(lr=learn_rate),\n#         loss      = 'categorical_crossentropy', \n#         metrics   = ['accuracy'] )\n#     return model\n\n# tuner = Hyperband(\n#     build_model,\n#     objective = 'val_accuracy', \n#     max_epochs = 10,\n#     directory = 'tune_hyperband',\n#     project_name = 'tune_hyperband',\n#     overwrite = True\n# )\n\n# # Hyperparameter Tuning\n# tuner.search(train_gen,\n#              epochs=10,\n#              verbose = False,\n#              validation_data=val_gen\n#             )\n\n# # get the best model\n# best_model =tuner.get_best_models(num_models=1)[0]\n\n# # show the optimal hyperparameters\n# tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values","b2683c63":"# Data Augmentation on training images\ntrain_images = ImageDataGenerator(rescale            = 1.\/255,\n                                  rotation_range     = 5,\n                                  zoom_range         = 0.10,\n                                  width_shift_range  =0.05,\n                                  height_shift_range =0.05)\n\n# train image generator\ntrain_gen =train_images.flow_from_directory(\n    DIR_TRAIN,\n    target_size = IMG_SIZE,\n    batch_size  = BATCH_SIZE,\n    class_mode  = 'categorical',\n    color_mode  = 'rgb',          \n    seed        = SEED \n)\n\nshow_images(train_gen)","be5cb465":"# training parameters\nEPOCHS        = 150\nearly_stoping = EarlyStopping(monitor = 'val_auc',patience = 15,restore_best_weights=True)\nreduce_lr     = ReduceLROnPlateau(monitor='val_auc',factor=0.9, patience=15, min_lr=1e-20, verbose=1, cooldown=3)\ncallbacks     = [reduce_lr]\nmetrics       = [tf.keras.metrics.AUC(name='auc')]\n\n\n\n# Train Model: Base + Optimized Hyperparameters + Data Augmentation\n# get base\nconv_base = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (*IMG_SIZE, 3))\n\n# freeze layers for training\nfreeze_layers(conv_base,trainable_layers='none')\n\n# build and compile the model\nmodel = build_transfer_model(conv_base,dropout=0.5,conv_nodes=1024,dense_node =1024,learn_rate=0.001,metric=metrics)\n\n\n# train\ntic = time.perf_counter()\nhistory = model.fit(\n    train_gen,\n    epochs           = EPOCHS,\n    validation_data  = val_gen,\n    verbose          = 2,\n    callbacks        =callbacks \n)\n\n# get class predictions\ny_prob = model.predict(test_gen)\ny_pred = y_prob.argmax(axis=-1)\n\n# get actual classes\ny_actual = test_gen.classes\n\n# plot\nplot_training_metrics(history,model,test_gen,y_actual,y_pred,['mild','moderate','normal','very-mild'])\n\n# Save Model\nmodel.save(os.path.join(DIR_MODELS,'model_added_capacity'))\n\n# time\ntoc = time.perf_counter()\nprint(\"Total Time:{} mins\".format(round((toc-tic)\/60,2)))","d5d647d7":"# show_images and labels\nshow_images(train_gen,y_pred)","70a07c26":"## Set Constants and Seeds\nDefine the paths to the images and set seeds for reproducibility","ddc6ac68":"## Determine the Number of Images for each class\nThe dataset provided is split into train and test batches consisting of 4 classes.  The function below loops through each folder and displays the number of images of each class","4519bde6":"# Conclusions\nWe can see from the confusion matrix that the model does best at identifying normal and very-mild MRIs and poorest identifying moderate cases. This makes sense given the small number of moderate examples in the dataset. Adding model capacity, searching for optimal hyperparmaters and adding data augmentation resulted better performance on the test dataset.","c86746f1":"# Preprocess Images for analysis\nImage generators from TensorFlow were used to feed images directly to our model from the image directories. The images were grayscale and needed to be converted to color to use with pre-trained models.\n\n## Image Transformations\n\n+ scale images\n+ convert to RGB\n+ set seed for reproducibility","feee1543":"## Function: Freeze\/Un-Freeze Model Layers\nTransfer learning requires us to freeze some of the model layers to reuse pre-trained model weights. This function will freeze all, some or none of the layers in a base model. The trainable_layers parameter is used to freeze 'all' base weights to reuse all pre-trained weights, 'none' to forget all training weights, or 'some' to freeze a subset of weights. To freeze only some of the weights you need to provide the layer name and block numbers\n\n+ trainable_layers: 'all' => keep all pretrained weights\n+ trainable_layers: 'none'=> retrain all layers\n+ trainable_layers: 'some'=> must provide the layer name,ranges to freeze","af18ba12":"## Hyperparameter Search using keras tuner\nThe tuner package from keras was used to search for optimal hyperparameters for dropout rate, learning rate and the filter size for the convolution and dense layers. The resulting parameters produced the model with the best performance. **Note-** the code was run onnce then commented out to save GPU.  This step takes several hours of compute time.\n\n+ dropout rates: 0.50, 0.60\n+ learning rate: 1e-3\n+ convolution layer:1024\n+ dense layer:1024","8bcb56de":"# Model Building and Evaluation Functions\nSeveral functions were built to assist with model building, training, and evaluation\n\n## Function:Plot Training Metrics\nThis function was used throughout the analysis to plot training metrics. It plots loss by epochs, AUC by epochs, and the four-class confusion matrix with the training AUC metric. AUC was chosen as the performance metric instead of accuracy due to the class imbalance in the training images","ebfe3e48":"## Resample the train dataset into train\/validation\nThe functions below copy the images from the train folders in the input directory and randomly splits them into train\/validate with equal proportions in each class and saves them to the working directory","dc92a584":"# Select a Base Model\nTo select a base model for transfer learning a simple model was trained using DenseNet121, InceptionV3, Xception and ResNet101 with a single dense layer for classification. All pre-trained weights were frozen and the AUC for the training set was calculated. The image dataset is unbalanced with unequal examples of classes. Accuracy would be biased towards the highest frequency class, so AUC was selected as an alternative model performance metric.\n\n## Base Model: Transfer Learning\n+ freeze the weights in the base model\n+ add a single dense layer for classification\n+ add callbacks for early stopping based on validation AUC\n+ use AUC as the performance metric\n+ train the model with each base models: DenseNet121, VGG19, InceptionV3, Xception,ResNet101\n+ select the best base based on AUC","db0b34de":"## Base Model (InceptionV3) + Optimized Parameters + Data Augmentation\nThe model was re-trained with the optimized hyperparameters using data augmentation.  The training was slowed down using a reduced schedule for learn-rate, early stopping was removed and the epochs were set to 150 to give the model as much time to train as possible without overfitting","20b1c962":"## Data Augmentation\nThe training plots show that the model is overfitting early in the epochs. Data augmentation was added to help the model generalize to novel data. Subtle transitions to the train images were added to the train image generator. Sample augmented images are shown below","26210649":"# Tune Model Hyperparameters\nInceptionV3 had the highest AUC on the test dataset and was selected as the base model (only InceptionV3 is shown for brevity). A number of additional steps were taken to improve the test AUC\n\n\n## Base Model (Inceptionv3) + Additional Capacity\nTo increase the capacity of the model additional convolution layers were added along with dropout and batch normalization for regularization. The build transfer model function was adjusted to add the additional layers. ","35e38efc":"## Function: Build & Compile a Transfer Model\nThis function takes a base model and training parameters and returns a compiled model.","256983bb":"## View Images with lables\nView sample images from the generators to ensure the transformations make sense. This function displays the processed train, test, or validation images from the image generators. It will display actual and predicted labels (if provided)","d4fecc16":"# Alzheimers Multiclass-Classification\n\n# Introduction\nTransfer learning using a convolution neural net (CNN) was used to classify brain MRIs into normal, very-mild, mild and moderate alzheimer classes. The data consists of 6,400 images split into train and test sets. \n\n# Methodology\nThe following steps were taken to prepare the images for analysis, select a base model, and tune hyperparameters. Several helper functions were built to simplify tasks for reuse throughout the analysis\n\n+ **Data Preparation**\n    + Import libraries, set constants and seeds\n    + Resample the train dataset into train\/validation\n    + Preprocess images for analysis\n    + View sample images\n+ **Build helper functions for model building & evaluation**\n    + Plot training metrics\n    + Freeze all or some layers in the base model\n    + Build and compile CNN models\n+ **Select a base model**\n    + Train a simple transfer model using DenseNet121, InceptionV3, Xception and ResNet101\n    + Select the base with the best AUC\n+ **Tune the model**\n    + Add capacity to the base model\n    + Tune hyperparameters using keras tuner\n    + Add data augmentation\n+ **Train the final model & evaluate performance**\n\n\n# Data Preparation\n## Install and Import Libraries\nThere are a number of libraries required for this analysis which are installed\/imported below. Of note, keras-tuner is used to perform grid-search to find optimal hyperparameters and split-folders is used to split folders of images into test, train and validate folders with stratification for classes","46573a53":"# View Images and Labels\nWe can view examples of actual and predicted labels with the show_images function by providing the predicted labels"}}