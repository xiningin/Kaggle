{"cell_type":{"1934680e":"code","5e017631":"code","aa3f05ca":"code","a0e0070b":"code","b76f01de":"code","cf3a6834":"code","c68d00d5":"code","f346687a":"code","8c1f74f2":"code","5cf12b37":"code","cdf7d8d4":"code","85454e32":"code","8f465ffa":"code","5ab6bc15":"code","70a913db":"code","5bd39cd0":"code","3a8101a9":"code","195b79ac":"code","0d099089":"code","ff681f42":"code","75f3fab9":"code","bd32b6ae":"code","9b6f2ad5":"code","7c9dc7e5":"code","eedbcf73":"code","cc8b6108":"code","7d339744":"code","23e17037":"code","46fba0ae":"code","fb264561":"code","e459772e":"code","a5434c3e":"code","1d51c8be":"code","fef4fb12":"code","7146259a":"code","fc119005":"code","82bc32b8":"code","3efdba1d":"code","fbb2ef51":"markdown","24348a50":"markdown","c6276eae":"markdown","8d972208":"markdown"},"source":{"1934680e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5e017631":"bike_df = pd.read_csv('..\/input\/bike_share.csv',sep=',')","aa3f05ca":"bike_df.shape","a0e0070b":"bike_df.head()","b76f01de":"bike_df.info()","cf3a6834":"bike_df.isna().sum()","c68d00d5":"bike_df.duplicated().sum()","f346687a":"bike_df = bike_df.drop_duplicates()","8c1f74f2":"import seaborn as sns\nfrom matplotlib import pyplot","5cf12b37":"fig, ax = pyplot.subplots(figsize=(11.7, 8.27))\nax = sns.boxplot(data=bike_df)","cdf7d8d4":"lower_bnd = lambda x: x.quantile(0.25) - 1.5 * ( x.quantile(0.75) - x.quantile(0.25) )\nupper_bnd = lambda x: x.quantile(0.75) + 1.5 * ( x.quantile(0.75) - x.quantile(0.25) )","85454e32":"bike_df = bike_df[(bike_df['holiday'] >= lower_bnd(bike_df['holiday'])) & (bike_df['holiday'] <= upper_bnd(bike_df['holiday'])) & (bike_df['weather'] >= lower_bnd(bike_df['weather'])) & (bike_df['weather'] <= upper_bnd(bike_df['weather'])) & (bike_df['humidity'] >= lower_bnd(bike_df['humidity'])) & (bike_df['humidity'] <= upper_bnd(bike_df['humidity']))] ","8f465ffa":"bike_df = bike_df[(bike_df['windspeed'] >= lower_bnd(bike_df['windspeed'])) & (bike_df['windspeed'] <= upper_bnd(bike_df['windspeed'])) & (bike_df['casual'] >= lower_bnd(bike_df['casual'])) & (bike_df['casual'] <= upper_bnd(bike_df['casual'])) & (bike_df['registered'] >= lower_bnd(bike_df['registered'])) & (bike_df['registered'] <= upper_bnd(bike_df['registered']))] ","5ab6bc15":"bike_df = bike_df[(bike_df['count'] >= lower_bnd(bike_df['count'])) & (bike_df['count'] <= upper_bnd(bike_df['count']))]","70a913db":"bike_df.shape","5bd39cd0":"list(bike_df)","3a8101a9":"bike_df.apply(lambda x: len(x.unique()))","195b79ac":"# sns.pairplot(data=bike_df,hue='season')","0d099089":"# sns.pairplot(data=bike_df,hue='workingday')","ff681f42":"# sns.pairplot(data=bike_df,hue='weather')","75f3fab9":"bike_df.corr()","bd32b6ae":"from sklearn.linear_model import LinearRegression  \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score","9b6f2ad5":"modelinput_cas = bike_df.drop(columns=['holiday','casual','registered','count'],axis=1)\nmodeloutput_cas = bike_df['casual']","7c9dc7e5":"X_train,X_test,Y_train, Y_test = train_test_split(modelinput_cas,modeloutput_cas,test_size=0.3,random_state=123)","eedbcf73":"lm = LinearRegression()\nlm.fit(X_train,Y_train)\nY_train_predict = lm.predict(X_train)\nY_test_predict = lm.predict(X_test)\nprint(\"-----------------------casual--------------------------\")\nprint(\"MSE Train:\",mean_squared_error(Y_train, Y_train_predict))\nprint(\"MSE Test:\",mean_squared_error(Y_test, Y_test_predict))\nprint(\"RMSE Train:\",np.sqrt(mean_squared_error(Y_train, Y_train_predict)))\nprint(\"RMSE Test:\",np.sqrt(mean_squared_error(Y_test, Y_test_predict)))\nprint('MAE Train', mean_absolute_error(Y_train, Y_train_predict))\nprint('MAE Test', mean_absolute_error(Y_test, Y_test_predict))\nprint('R2 Train',r2_score(Y_train, Y_train_predict))\nprint('R2 Test',r2_score(Y_test, Y_test_predict))","cc8b6108":"modelinput_reg = bike_df.drop(columns=['holiday','casual','registered','count'],axis=1)\nmodeloutput_reg = bike_df['registered']","7d339744":"X_train,X_test,Y_train, Y_test = train_test_split(modelinput_reg,modeloutput_reg,test_size=0.3,random_state=123)","23e17037":"lm = LinearRegression()\nlm.fit(X_train,Y_train)\nY_train_predict = lm.predict(X_train)\nY_test_predict = lm.predict(X_test)\nprint(\"---------------------registered-------------------------\")\nprint(\"MSE Train:\",mean_squared_error(Y_train, Y_train_predict))\nprint(\"MSE Test:\",mean_squared_error(Y_test, Y_test_predict))\nprint(\"RMSE Train:\",np.sqrt(mean_squared_error(Y_train, Y_train_predict)))\nprint(\"RMSE Test:\",np.sqrt(mean_squared_error(Y_test, Y_test_predict)))\nprint('MAE Train', mean_absolute_error(Y_train, Y_train_predict))\nprint('MAE Test', mean_absolute_error(Y_test, Y_test_predict))\nprint('R2 Train',r2_score(Y_train, Y_train_predict))\nprint('R2 Test',r2_score(Y_test, Y_test_predict))","46fba0ae":"modelinput_tot = bike_df.drop(columns=['holiday','casual','registered','count'],axis=1)\nmodeloutput_tot = bike_df['count']","fb264561":"from sklearn import preprocessing\nmodelinput_tot = preprocessing.StandardScaler().fit(modelinput_tot).transform(modelinput_tot.astype(float))","e459772e":"X_train,X_test,Y_train, Y_test = train_test_split(modelinput_tot,modeloutput_tot,test_size=0.3,random_state=123)","a5434c3e":"lm = LinearRegression()\nlm.fit(X_train,Y_train)\nY_train_predict = lm.predict(X_train)\nY_test_predict = lm.predict(X_test)\nprint(\"-----------------------Total---------------------------\")\nprint(\"MSE Train:\",mean_squared_error(Y_train, Y_train_predict))\nprint(\"MSE Test:\",mean_squared_error(Y_test, Y_test_predict))\nprint(\"RMSE Train:\",np.sqrt(mean_squared_error(Y_train, Y_train_predict)))\nprint(\"RMSE Test:\",np.sqrt(mean_squared_error(Y_test, Y_test_predict)))\nprint('MAE Train', mean_absolute_error(Y_train, Y_train_predict))\nprint('MAE Test', mean_absolute_error(Y_test, Y_test_predict))\nprint('R2 Train',r2_score(Y_train, Y_train_predict))\nprint('R2 Test',r2_score(Y_test, Y_test_predict))","1d51c8be":"from sklearn.preprocessing import Imputer\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import accuracy_score\nfor K in range(50):\n    K_value = K + 1\n    neigh = KNeighborsRegressor(n_neighbors=K_value,weights='uniform',algorithm='auto')\n    neigh.fit(X_train, Y_train)\n    y_pred=neigh.predict(X_test)\n    print(\"Accuracy is\",r2_score(Y_test, y_pred)*100,\"% for K-Value\",K_value)","fef4fb12":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\ndt = DecisionTreeRegressor(max_depth=6) \ndt.fit(X_train, Y_train)\ny_pred = dt.predict(X_test)\nprint(r2_score(Y_test, y_pred)*100)","7146259a":"for i in range(1, 30):\n    print('Accuracy score using max_depth =', i, end = ': ')\n    dt = DecisionTreeRegressor(max_depth=i)\n    dt.fit(X_train, Y_train)\n    y_pred = dt.predict(X_test)\n    print(r2_score(Y_test, y_pred)*100)","fc119005":"for i in ['auto','sqrt','log2',0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n    print('Accuracy score using max_features =', i, end = ': ')\n    dt = DecisionTreeRegressor(max_depth=6,max_features=i)\n    dt.fit(X_train, Y_train)\n    y_pred = dt.predict(X_test)\n    print(r2_score(Y_test, y_pred)*100)","82bc32b8":"for i in range(2, 40):\n    print('Accuracy score using min_samples_split =', i, end = ': ')\n    dt = DecisionTreeRegressor(max_depth=6,max_features=0.5,min_samples_split=i)\n    dt.fit(X_train, Y_train)\n    y_pred = dt.predict(X_test)\n    print(r2_score(Y_test, y_pred)*100)","3efdba1d":"mean_squared_error(Y_test, y_pred)","fbb2ef51":"Features","24348a50":"# Removing Outliers","c6276eae":"min_samples_split","8d972208":"Depth"}}