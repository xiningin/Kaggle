{"cell_type":{"2ea8a820":"code","e8ae9396":"code","13085f0d":"code","56f21acc":"code","8d836732":"code","18d00c05":"code","f1ec9d7c":"code","752b402a":"code","11f878c2":"code","842ff9b8":"code","47cf2aa7":"code","639ab4a0":"code","9344d274":"code","ee97b366":"code","a3ff0f63":"code","6665a3a2":"code","282fa4f2":"code","5ce17112":"code","249e6558":"code","8adcb6aa":"code","f85360de":"code","03474ed3":"code","ffb9bc80":"code","e5383d7e":"code","eea9919d":"code","54df2896":"code","b0d3dbbb":"code","6f3db8f5":"code","4012ee43":"code","8d97ca47":"code","afeb3828":"code","455c3dd4":"code","eba4fc4b":"code","cd440d84":"code","0e6230b3":"code","05239dba":"code","36a2721f":"code","a63e39be":"code","e51db3b2":"code","e0335cf1":"code","7984ca4d":"code","2209dd1e":"code","7a3ff669":"code","3c069de3":"code","ecbf77dc":"code","0ac9b570":"code","809d6b8f":"code","5cb423f6":"code","2372aae3":"code","7c2fb7cc":"code","f66dd64a":"code","2c4deb63":"code","31086836":"code","a4580ff9":"code","80302f59":"code","85cf26ca":"code","78d97e5c":"code","1b334479":"code","a98df7fb":"code","47d1720d":"code","eecb840f":"code","67aec2ce":"code","d5b9962f":"code","46ad013d":"code","dbe9e8de":"code","ef307f81":"code","d99e8541":"code","5970ea44":"code","9776860f":"code","d7ee1724":"code","632afc2c":"code","05476541":"code","15bb4025":"code","39ed0554":"code","e5e61675":"code","e6d9b5a7":"code","c6860c9d":"code","3885cf0f":"code","6db04688":"markdown","0b3b1db4":"markdown","06ad7025":"markdown","6eb16ce5":"markdown","3af4a849":"markdown","4ba3d6c1":"markdown","598089e9":"markdown","d7c47dbd":"markdown","df305a7c":"markdown","72a65ea0":"markdown","a108f11b":"markdown","81501766":"markdown","edd6be8a":"markdown","50482622":"markdown","4d7cf598":"markdown","d920aeec":"markdown","98d3d6c3":"markdown","7f901382":"markdown","ba24899e":"markdown","c5473777":"markdown","ca2e0a33":"markdown","1e68c399":"markdown","0746fc74":"markdown","c5045317":"markdown","2a8c8c83":"markdown","4cd39e26":"markdown","6edc6071":"markdown","83924745":"markdown","3e10d97d":"markdown","00835cdf":"markdown","7c39f725":"markdown","9cb43daa":"markdown","76c596ea":"markdown","d80dd9e3":"markdown","90adfe0e":"markdown","4b046af0":"markdown","09e9c27b":"markdown","8daaf38c":"markdown","b73a4e3f":"markdown","ae547aa6":"markdown","b221d8bf":"markdown","6de88813":"markdown","079cc7e9":"markdown","91becf4d":"markdown","80658021":"markdown","d7ffd3e0":"markdown"},"source":{"2ea8a820":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt #collection of command style functions that make matplotlib work\nimport plotly.express as px #new high-level plotly visualization  library, that exposes a simple syntax for complex chart\nimport seaborn as sns #statistical data visualization. \n%matplotlib inline  \n#Displays output inline\n\nimport scipy #to manipulate and visualize data with a wide range of high-level commands.\nfrom scipy.stats.stats import pearsonr\nfrom random import sample #get ramdomly sampling","e8ae9396":"orders_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv')\npayment_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv')\nreview_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv')\nitems_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv')\nproduct_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_products_dataset.csv')\ncustomers_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv')\nsellers_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv')\nproduct_trans_data=pd.read_csv('..\/input\/brazilian-ecommerce\/product_category_name_translation.csv')\ngeoloca_data=pd.read_csv('..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv')","13085f0d":"# Orders_data\nround((orders_data.isnull().sum()\/len(orders_data)*100),2)","56f21acc":"orders_data.order_purchase_timestamp","8d836732":"#Payment_data\nround((payment_data.isnull().sum()\/len(payment_data)*100),2)","18d00c05":"#Review_data\nround((review_data.isnull().sum()\/len(review_data)*100),2)","f1ec9d7c":"#items_data\nround((items_data.isnull().sum()\/len(items_data)*100),2)","752b402a":"# Product_data\nround((product_data.isnull().sum()\/len(product_data)*100),2)","11f878c2":"# Product_data\nround((product_data.isnull().sum()\/len(product_data)*100),2)","842ff9b8":"#Customers_data\nround((customers_data.isnull().sum()\/len(customers_data)*100),2)","47cf2aa7":"#Sellers_data\nround((sellers_data.isnull().sum()\/len(sellers_data)*100),2)","639ab4a0":"#Geolocation_Data\nround((geoloca_data.isnull().sum()\/len(geoloca_data)*100),2)","9344d274":"#Product_Translation_data\nround((product_trans_data.isnull().sum()\/len(product_trans_data)*100),2)","ee97b366":"#STEP 1:  We use function pd.to_datetime to convert type date columns from object to datetime64\norders_data['order_purchase_timestamp']=pd.to_datetime(orders_data['order_purchase_timestamp'])\norders_data['order_approved_at']=pd.to_datetime(orders_data['order_approved_at'])\norders_data['order_delivered_carrier_date']=pd.to_datetime(orders_data['order_delivered_carrier_date'])\norders_data['order_delivered_customer_date']=pd.to_datetime(orders_data['order_delivered_customer_date'])\norders_data['order_estimated_delivery_date']=pd.to_datetime(orders_data['order_estimated_delivery_date'])","a3ff0f63":"# STEP 2:  We find the average of the time between purchase_timestamp ( not any null) with delivered_carrier.\norders_data_1=orders_data[orders_data['order_delivered_carrier_date'].notnull()]\nmiss_carrier=(orders_data_1['order_purchase_timestamp']-orders_data_1['order_delivered_carrier_date']).mean()\nmiss_carrier #we name it: miss_carrier","6665a3a2":"# After that, we caculate missing time by minus of order_purchase_timestamp and miss_carrier, which we caculated above\nadded_date=orders_data[orders_data['order_delivered_carrier_date'].isnull()]['order_purchase_timestamp'] - miss_carrier\nadded_date","282fa4f2":"#STEP 3: we replace missing values by the new ones.\norders_data['order_delivered_carrier_date']=orders_data['order_delivered_carrier_date'].replace(np.nan,added_date)\norders_data.isnull().sum()","5ce17112":"#After treating, there are no-missing values in column:order_delivered_carrier_date\norders_data.isnull().sum()","249e6558":"# STEP 2:  We find the average of the time between purchase_timestamp ( not any null) with delivered_customer_date.\norders_data_2=orders_data[orders_data['order_delivered_carrier_date'].notnull()]\nmean_deliver=(orders_data_1['order_purchase_timestamp']-orders_data_1['order_delivered_customer_date']).mean()\nmean_deliver #we name it: mean_deliver","8adcb6aa":"# After that, we caculate missing time by minus of order_purchase_timestamp and mean_deliver, which we caculated above\nadded_date=orders_data[orders_data['order_delivered_customer_date'].isnull()]['order_purchase_timestamp'] - mean_deliver\nadded_date","f85360de":"#Step 3: we replace missing values by the new ones.\norders_data['order_delivered_customer_date']=orders_data['order_delivered_customer_date'].replace(np.nan,added_date)\n","03474ed3":"#After that, we check missing values in collumn order_delivered_customer_date\norders_data.isnull().sum()","ffb9bc80":"#because the number of missing is too small compared to the amount of rows. So we can drop it\norders_data.dropna(inplace=True)","e5383d7e":"#There are no-missing values in any column of DataFrame orders_data\norders_data.isnull().sum()","eea9919d":"#We notice that missing values in 2 columns review_comment_title and review_comment_message is not worth. Because we have no idea using 2 kind of columns. So we drop it\nreview_data.isnull().sum()","54df2896":"review_data.drop(columns=['review_comment_title','review_comment_message'],inplace=True)","b0d3dbbb":"#There are no missing columns\nreview_data.isnull().sum()","6f3db8f5":"product_data.dropna(inplace=True)","4012ee43":"product_data.isnull().sum()","8d97ca47":"# Orders_data\norders_data.duplicated(['order_id']).sum()","afeb3828":"# Orders_data\nitems_data.duplicated(['order_id']).sum()","455c3dd4":"# Orders_data\npayment_data.duplicated(['order_id']).sum()","eba4fc4b":"# Orders_data\nreview_data.duplicated(['order_id']).sum()","cd440d84":"# Orders_data\ncustomers_data.duplicated(['customer_id']).sum()","0e6230b3":"#We merge orders_data with items_data on common column: order_id and inner join \ndata_merge=pd.merge(orders_data,items_data,on='order_id',how='inner')\n\n#We merge DataFrame merged with payment_data on common column: order_id and inner join \ndata_merge=pd.merge(data_merge,payment_data,on='order_id',how='inner')\n\n#We merge DataFrame merged with review_data on common column: order_id and inner join \ndata_merge=pd.merge(data_merge,review_data,on='order_id',how='inner')\n\n#We merge DataFrame merged with product_data on common column: order_id and inner join \ndata_merge=pd.merge(data_merge,product_data,on='product_id',how='inner')\n\n#We merge DataFrame merged with customers_data on common column: customer_id and inner join \ndata_merge=pd.merge(data_merge,customers_data,on='customer_id',how='inner')\n\n#We merge DataFrame merged with sellers_data on common column: sellers_id and inner join \ndata_merge=pd.merge(data_merge,sellers_data,on='seller_id',how='inner')\n\n#We merge DataFrame merged with product_trans_data on common column: product_category_name and inner join \ndata_merge=pd.merge(data_merge,product_trans_data,on='product_category_name',how='inner')","05239dba":"#We drop duplicated column in final DataFrame merged and named it Df_ecommerce\nDf_ecommerce=data_merge.drop_duplicates(['order_id'])","36a2721f":"Df_ecommerce.isnull().sum()","a63e39be":"Df_top20prod_rev=Df_ecommerce['price'].groupby(Df_ecommerce['product_category_name_english']).sum().sort_values(ascending=False)[:20]\nDf_top20prod_rev","e51db3b2":"fig=plt.figure(figsize=(16,10))\nsns.barplot(y=Df_top20prod_rev.index,x=Df_top20prod_rev.values)\nplt.title('Top 20 product category having the largest revenue',fontsize=20)\nplt.xlabel('Total revenue',fontsize=17)\nplt.ylabel('Product category',fontsize=17)","e0335cf1":"Df_top20prod_numsell=Df_ecommerce['order_id'].groupby(Df_ecommerce['product_category_name_english']).count().sort_values(ascending=False)[:20]","7984ca4d":"fig=plt.figure(figsize=(16,10))\nsns.barplot(y=Df_top20prod_numsell.index,x=Df_top20prod_numsell.values)\nplt.title('Top 20 product category having the largest amount of selling',fontsize=20)\nplt.xlabel('Number of selling',fontsize=17)\nplt.ylabel('Product category',fontsize=17)","2209dd1e":"#New column expecting_delivery: time sellers promise delivering for customer.\nDf_ecommerce['Expecting_Delivery']=Df_ecommerce['order_estimated_delivery_date'] - Df_ecommerce['order_purchase_timestamp']\n\n#New column Real_delievery: Actual time period customer received after ordering\nDf_ecommerce['Real_Delivery']=Df_ecommerce['order_delivered_customer_date'] - Df_ecommerce['order_purchase_timestamp']\n\n#New column Real_Delievery_hour: Convert expecting_delivery to hour, round to 2 decimal\nDf_ecommerce['Real_Delivery_hour']=(Df_ecommerce['Real_Delivery']\/np.timedelta64(1, 'h')).round(2)\n\n#New column Expecting_delievery_hour: Convert Expecting_delivery to hour, round to 2 decimal\nDf_ecommerce['Expecting_delivery_hour']=(Df_ecommerce['Expecting_Delivery']\/np.timedelta64(1,'h')).round(2)\n\n#New column Delivery_evaluate: Compare between Expecting and Real Delivery\nDf_ecommerce['delivery_evaluate']=round(((2*Df_ecommerce['Expecting_Delivery']-Df_ecommerce['Real_Delivery'])\/Df_ecommerce['Expecting_Delivery'])*100,2)","7a3ff669":"Df_ecommerce","3c069de3":"#List of top 20 product categories having the largest revenue\nDf_top20prod_rev","ecbf77dc":"# DataFrame of top 20 product categories having the largest revenue\nDf_ecommerce_top20rev=Df_ecommerce[Df_ecommerce['product_category_name_english'].isin(Df_top20prod_rev.index)]","0ac9b570":"#Average delivery of each product category\nDf_avg_del_top20=(Df_ecommerce_top20rev['Real_Delivery_hour'].groupby(Df_ecommerce_top20rev['product_category_name_english']).mean()\/24).round(2)","809d6b8f":"fig=plt.figure(figsize=(16,10))\nsns.barplot(x=Df_avg_del_top20.values,y=Df_avg_del_top20.index)\nplt.title('Average days of  delivery of top 20 product categories',fontsize=20,weight='bold')\nplt.tick_params(axis='both',labelsize=13) #stick label \nplt.ylabel('Product category',fontsize=15) #title and fontsize for ylabel\nplt.xlabel('Days of delivery',fontsize=15)  #title and fontsize for xlabel","5cb423f6":"#Get customer_city based on total revenue ( sum of price)\nTop5city_rev=Df_ecommerce['price'].groupby(Df_ecommerce['customer_city']).sum().sort_values(ascending=False)[:5]\n\n#Crate new index \"other cities\" euqally to the rest of other cities\nTop5city_rev['other cities']=Df_ecommerce['price'].groupby(Df_ecommerce['customer_city']).sum().sort_values(ascending=False)[5:].sum()\n\n#Create DataFrame and rename \nTop5city_rev=pd.DataFrame(data=Top5city_rev).rename(columns={'price':'Total revenue'})\n\n#Calling new DataFrame\nTop5city_rev","2372aae3":"Top5city_rev.plot.pie(y='Total revenue',autopct='%1.1f%%',shadow=True,figsize=(10,10),legend=True,textprops={'size': 13},explode=(0.15, 0, 0, 0,0, 0), labeldistance=None,pctdistance=1.1)\nplt.legend(loc='lower right',bbox_to_anchor=(1.35,0.5),fontsize=15)\nplt.title('Top 5 cities having the largest total revenue',fontsize=20,weight='bold')\nplt.show()","7c2fb7cc":"#Get customer_city based on amount of selling\nTop5city_sellamount=Df_ecommerce['customer_city'].value_counts().sort_values(ascending=False)[:5]\n\n#Create new row: other cities = the rest of other cites\nTop5city_sellamount['other cities']=Df_ecommerce['customer_city'].value_counts().sort_values(ascending=False)[5:].sum()\n\n#Create DataFrame and rename column\nTop5city_sellamount=pd.DataFrame(data=Top5city_sellamount).rename(columns={'customer_city':'selling amount'})\n\n#Calling new DataFrame\nTop5city_sellamount","f66dd64a":"Top5city_sellamount.plot.pie(y='selling amount',autopct='%1.1f%%',shadow=True,figsize=(10,10),labeldistance=None,textprops={'size':13} ,explode=(0.15, 0, 0, 0, 0, 0),legend=True,pctdistance=1.1)\nplt.legend(loc='lower right',bbox_to_anchor=(1.35,0.5),fontsize=15)\nplt.title('Top 5 cities having the largest amount of selling',fontsize=20,weight='bold')\nplt.show()","2c4deb63":"#Get new DataFrame of top 20 product categories having the largest revenue\nDf_top20prod_review=Df_ecommerce[Df_ecommerce['product_category_name_english'].isin(Df_top20prod_rev.index)]\n\n#Series of average review based on top 20 product categories \nseries_top20pro_review=Df_top20prod_review['review_score'].groupby(Df_top20prod_review['product_category_name_english']).mean()\n\n#Calling new series\nseries_top20pro_review","31086836":"fig=plt.figure(figsize=(16,10)) #Creating figsize, frame.\nsns.barplot(x=series_top20pro_review.values,y=series_top20pro_review.index) \nplt.title('Customer review of top 20 product having the largest revenue',fontsize=20) #title and fontsize of barchart\nplt.tick_params(axis='both',labelsize=13) #tick label and font size\nplt.xlabel('Review point',fontsize=15)\nplt.ylabel('Product categories',fontsize=15)","a4580ff9":"#Get 20 product categories having the smallest amount of selling\nDf_lowest_numsell=Df_ecommerce['order_id'].groupby(Df_ecommerce['product_category_name_english']).count().sort_values(ascending=False)[-20:]\nDf_lowest_numsell","80302f59":"#Create new DataFrame just have only 20 product categories having the smallest amount of selling, which we create above\nDf_low20prod_review=Df_ecommerce[Df_ecommerce['product_category_name_english'].isin(Df_lowest_numsell.index)]\n\n#Create sereis of average review point of 20 product categories having the lowest amount of selling\nseries_low20pro_review=Df_low20prod_review['review_score'].groupby(Df_low20prod_review['product_category_name_english']).mean()\nseries_low20pro_review","85cf26ca":"# Create barchart \nfig=plt.figure(figsize=(16,10))\nsns.barplot(x=series_low20pro_review.values,y=series_low20pro_review.index)\nplt.title('Customer review of top 20 product having the lowest amount of selling',fontsize=20)\nplt.tick_params(axis='both',labelsize=13)","78d97e5c":"Df_rev_month=Df_ecommerce[['price']].groupby([Df_ecommerce['product_category_name_english'],Df_ecommerce['order_purchase_timestamp'].map(lambda x: x.strftime('%B'))]).sum().unstack(1).droplevel(axis=1,level=0)\nDf_rev_month","1b334479":"#Getting new DataFrames total revenue of top 10 product categories in each month\nDf_jan=Df_rev_month['January'].sort_values(ascending=False)[:10]\nDf_feb=Df_rev_month['February'].sort_values(ascending=False)[:10]\nDf_mar=Df_rev_month['March'].sort_values(ascending=False)[:10]\nDf_apr=Df_rev_month['April'].sort_values(ascending=False)[:10]\nDf_may=Df_rev_month['May'].sort_values(ascending=False)[:10]\nDf_jun=Df_rev_month['June'].sort_values(ascending=False)[:10]\nDf_jul=Df_rev_month['July'].sort_values(ascending=False)[:10]\nDf_aug=Df_rev_month['August'].sort_values(ascending=False)[:10]\nDf_sep=Df_rev_month['September'].sort_values(ascending=False)[:10]\nDf_oct=Df_rev_month['October'].sort_values(ascending=False)[:10]\nDf_nov=Df_rev_month['November'].sort_values(ascending=False)[:10]\nDf_dec=Df_rev_month['December'].sort_values(ascending=False)[:10]\n\n#Create figsize and subplots\nf, axes = plt.subplots(6,2, figsize=(20, 100 ))\nplt.subplots_adjust(wspace = 0.4 ) #wspace: wide space\n\n# Create individually barplot by Seaborn\nsns.barplot(y=Df_jan.index,x=Df_jan.values,ax=axes[0,0])\nsns.barplot(y=Df_feb.index,x=Df_feb.values,ax=axes[1,0])\nsns.barplot(y=Df_mar.index,x=Df_mar.values,ax=axes[2,0])\nsns.barplot(y=Df_apr.index,x=Df_apr.values,ax=axes[3,0])\nsns.barplot(y=Df_may.index,x=Df_may.values,ax=axes[4,0])\nsns.barplot(y=Df_jun.index,x=Df_jun.values,ax=axes[5,0])\nsns.barplot(y=Df_jul.index,x=Df_jul.values,ax=axes[0,1])\nsns.barplot(y=Df_aug.index,x=Df_aug.values,ax=axes[1,1])\nsns.barplot(y=Df_sep.index,x=Df_sep.values,ax=axes[2,1])\nsns.barplot(y=Df_oct.index,x=Df_oct.values,ax=axes[3,1])\nsns.barplot(y=Df_nov.index,x=Df_nov.values,ax=axes[4,1])\nsns.barplot(y=Df_dec.index,x=Df_dec.values,ax=axes[5,1])\n\n#Set title and fontsize of each \naxes[0,0].set_title('Jan',fontsize=17)\naxes[1,0].set_title('Feb',fontsize=17)\naxes[2,0].set_title('Mar',fontsize=17)\naxes[3,0].set_title('Apr',fontsize=17)\naxes[4,0].set_title('May',fontsize=17)\naxes[5,0].set_title('Jun',fontsize=17)\naxes[0,1].set_title('Jul',fontsize=17)\naxes[1,1].set_title('Aug',fontsize=17)\naxes[2,1].set_title('Sep',fontsize=17)\naxes[3,1].set_title('Oct',fontsize=17)\naxes[4,1].set_title('Nov',fontsize=17)\naxes[5,1].set_title('Dec',fontsize=17)\n\n#Remove ylabel of each \naxes[0,0].yaxis.label.set_visible(False)\naxes[1,0].yaxis.label.set_visible(False)\naxes[2,0].yaxis.label.set_visible(False)\naxes[3,0].yaxis.label.set_visible(False)\naxes[4,0].yaxis.label.set_visible(False)\naxes[5,0].yaxis.label.set_visible(False)\naxes[0,1].yaxis.label.set_visible(False)\naxes[1,1].yaxis.label.set_visible(False)\naxes[2,1].yaxis.label.set_visible(False)\naxes[3,1].yaxis.label.set_visible(False)\naxes[4,1].yaxis.label.set_visible(False)\naxes[5,1].yaxis.label.set_visible(False)\n\n#Bold and custom size tick label of each\naxes[0,0].tick_params(axis = 'both',  labelsize = 15)\naxes[1,0].tick_params(axis = 'both',  labelsize = 15)\naxes[2,0].tick_params(axis = 'both',  labelsize = 15)\naxes[3,0].tick_params(axis = 'both',  labelsize = 15)\naxes[4,0].tick_params(axis = 'both',  labelsize = 15)\naxes[5,0].tick_params(axis = 'both',  labelsize = 15)\naxes[0,1].tick_params(axis = 'both',  labelsize = 15)\naxes[1,1].tick_params(axis = 'both',  labelsize = 15)\naxes[2,1].tick_params(axis = 'both',  labelsize = 15)\naxes[3,1].tick_params(axis = 'both',  labelsize = 15)\naxes[4,1].tick_params(axis = 'both',  labelsize = 15)\naxes[5,1].tick_params(axis = 'both',  labelsize = 15)\n\n","a98df7fb":"#Get top 10 product categories having the largest amount of selling \nDf_top10_list=np.array(Df_top20prod_numsell[:10].index)\nDf_top10_list","47d1720d":"#split number of selling in each product category, month by groupby function. After that, we unstack level 0 of index\nDf_numsell_month=Df_ecommerce[['order_id']].groupby([Df_ecommerce['product_category_name_english'],Df_ecommerce['order_purchase_timestamp'].map(lambda x:x.strftime('%m'))]).count().unstack(0).droplevel(axis=1,level=0)\n\n#Get Series of top 10 product categories having the largest number of selling in each month\nDf_top10_numsell_month=Df_numsell_month[Df_top10_list].stack(level=0)\nDf_top10_numsell_month\n","eecb840f":"indexs=Df_top10_numsell_month.index.get_level_values(0)\ncolors=np.array(Df_top10_numsell_month.index.get_level_values(1))\nplt.figure(figsize=(16,10))\n\n#Using plotly express library to create interactively multiple line charts of top 10 product categories having the largest number of selling in each month\nfig=px.line(Df_top10_numsell_month,x=indexs,y=Df_top10_numsell_month.values,color=colors)\n\n#Using fig.update_layout to make visualization more details and clearly\nfig.update_layout(xaxis_title='Month',\n                  yaxis_title='number of selling',\n                  title_text='Top 10 product category having the largest amount of selling in each month',\n                  legend_title_text='Product category',\n                 )\nfig.show()","67aec2ce":"#Geta list of 20 sellers having the largest revenue by groupby \nDf_20sellers_revenue=Df_ecommerce['price'].groupby(Df_ecommerce['seller_id']).sum().sort_values(ascending=False)[:20]","d5b9962f":"#Create barchart by Seaborn\nfig=plt.figure(figsize=(16,8))\nsns.barplot(y=Df_20sellers_revenue.index,x=Df_20sellers_revenue.values)\n\n#Labeling title, x and y axes\nplt.title('Top 20 sellers have the largest revenue',fontsize=20)\nplt.xlabel('Total revenue',fontsize=17)\nplt.ylabel('Seller ID',fontsize=17)","46ad013d":"Df_20sellers_numsell=Df_ecommerce['order_id'].groupby(Df_ecommerce['seller_id']).count().sort_values(ascending=False)[:20]","dbe9e8de":"#Create barchart by Seaborn\nfig=plt.figure(figsize=(16,8))\nsns.barplot(y=Df_20sellers_numsell.index,x=Df_20sellers_numsell.values)\n\n#Labeling title, x and y axes\nplt.title('Top 20 sellers have the largest number of selling',fontsize=20)\nplt.xlabel('Number of selling',fontsize=17)\nplt.ylabel('Seller ID',fontsize=17)","ef307f81":"#Create DataFrame of only top 20 sellers\nDf_20sellers_rev=Df_ecommerce[Df_ecommerce['seller_id'].isin(Df_20sellers_numsell.index)]","d99e8541":"#Get average review_score of top 20 sellers\nDf_20sellers_feedback=Df_20sellers_rev['review_score'].groupby(Df_20sellers_rev['seller_id']).mean()","5970ea44":"#Create barchart by Seaborn\nfig=plt.figure(figsize=(16,8))\nsns.barplot(y=Df_20sellers_feedback.index,x=Df_20sellers_feedback.values)\n\n#Labeling title, x and y axes\nplt.title('Customer feedback of top 20 sellers have the largest number of selling',fontsize=20)\nplt.xlabel('Average review score',fontsize=17)\nplt.ylabel('Seller ID',fontsize=17)","9776860f":"Df_ecommerce['customer_id'].value_counts().value_counts()","d7ee1724":"weight=Df_ecommerce['product_weight_g']\ndelivery_relhour=Df_ecommerce['Real_Delivery_hour']\ndelivery_exphour=Df_ecommerce['Expecting_delivery_hour']\nsatisfy=Df_ecommerce['review_score']\ndelivery_evaluate=Df_ecommerce['delivery_evaluate']\npayment_type=Df_ecommerce['payment_type']\nvolumetric=Df_ecommerce['product_length_cm']*Df_ecommerce['product_height_cm']*Df_ecommerce['product_width_cm']","632afc2c":"pearsonr_coefficient,p_value=pearsonr(delivery_exphour,weight)\nprint('Correlation Coefficient %0.3f'%(pearsonr_coefficient))","05476541":"pearsonr_coefficient,p_value=pearsonr(delivery_exphour,volumetric)\nprint('Correlation Coefficient %0.3f'%(pearsonr_coefficient))","15bb4025":"pearsonr_coefficient,p_value=pearsonr(satisfy,delivery_evaluate)\nprint('Correlation Coefficient %0.3f'%(pearsonr_coefficient))","39ed0554":"#We take 200 sample of each payment type\ndf1=Df_ecommerce[Df_ecommerce['payment_type']=='credit_card'].sample(n=200)\ndf2=Df_ecommerce[Df_ecommerce['payment_type']=='boleto'].sample(n=200)\ndf3=Df_ecommerce[Df_ecommerce['payment_type']=='voucher'].sample(n=200)\ndf4=Df_ecommerce[Df_ecommerce['payment_type']=='debit_card'].sample(n=200)\nDf_sample=pd.concat([df1,df2,df3,df4])","e5e61675":"def del_evalu_class(x):\n    if x>=150: return 'Very good'\n    elif 100<=x<150: return 'Good'\n    elif 50<=x<100: return 'Normal'\n    elif 0<=x<50: return 'Bad'\n    else : return 'very bad'","e6d9b5a7":"Df_sample['Delivery classification']=Df_sample['delivery_evaluate'].map(del_evalu_class)\nDf_sample['Delivery classification'].value_counts()\n\nsatisfy=Df_sample['review_score']\npayment_type=Df_sample['payment_type']\nDelivery_classification=Df_sample['Delivery classification']","c6860c9d":"table=pd.crosstab(payment_type,Delivery_classification)\ntable\n\nfrom scipy.stats import chi2_contingency\nchi2,p,dof,expected=chi2_contingency(table.values)\nprint('chisquare statistic %0.3f p_value %0.3f'%(chi2,p))","3885cf0f":"table=pd.crosstab(payment_type,satisfy)\ntable\n\nfrom scipy.stats import chi2_contingency\nchi2,p,dof,expected=chi2_contingency(table.values)\nprint('chisquare statistic %0.3f p_value %0.3f'%(chi2,p))","6db04688":"#### 5.1.2 Correlation between delivery expecting hours with volumetric of product ","0b3b1db4":"### 4.4. Customer review of top 20 product","06ad7025":"#### 5.2.1 Chisquare test of 4 payment type with Delivery","6eb16ce5":"#### 4.6.3 Customer feedback of top 20 sellers ","3af4a849":"#### 5.1.3 Correlation between review score with delivery evaluate","4ba3d6c1":"## II. Data Cleaning and  Preparation\n### 2.1 Checking percentage of missing value in each data\nwe check the percentage of missing values each column in each DataFrame ( %) ","598089e9":"#### 4.5.2 Subplots barchart of total revenue based on each month","d7c47dbd":"### 4.6 Top sellers","df305a7c":"1. Health beautiy, watch gift, sport leasures, health_beauty, bed_bath_table, computers_accessories, cool_stuff, furniture_decor  ... are the key product categories of Olist with the largest of both sale avenue and number of selling\n2.  we modify suitablly the average delivery of key product,  based on the bar chart 'Average days of  delivery of top 20 product categories' ( 4.2.3). \n3. Sao Paulo is an important market of Olist with 14 proportion of  sale avenua and 15.6 percentage number of selling (4.3.1-2)\n4. In the top product category, the overall of customer review is around 4, regardless office funeture with 3.5 review score (4.4.2).\n5. Based on subplots bar graph of top 10 product categories in each month recording in revenue ( 4.5.2) or amount of selling ( 4.5.3), we know the shifts of customer demand and create marketing strategy appropriately\nForexample: Health_beauty has the largest demand in August, but decreased dramatically to lowest in the following month.\n6. Based on 4.6.1, we know the top 20 top sellers. \n7. The rate of buy back is 0%.\n8. Weight and volumetric of product has very low correlation with time of delivery ( 5.1.1-2 )\n9. Time of delivery has correlation with customer satisfaction, but quite low: 0.32 ( 5.1.3)\n10. There is no difference in delievery of 4 payment type because p_value >0.05 ( 5.2.1)\n11. There is a significant difference of customer satisfaction ( review score ) between 4 payment type: p_value < 0.05 ( 5.2.2)\n\n     \n","72a65ea0":"### 5.1 Delievery and customer feedback ( Correlation ) \n","a108f11b":"#### 4.3.2 Top 5 cities having the largest amount of selling","81501766":"#####  column: order_delivered_customer_date","edd6be8a":"## IV. Data Categorizing and Visualization","50482622":"### 2.2 Dealing with Missing Values","4d7cf598":"### 1.2 Reading  data","d920aeec":"#### 4.2.1 Top product categories caculated based on amount of selling","98d3d6c3":"##### column: order_approved_at","7f901382":"#### 4.5.3 Total number of selling based on each month","ba24899e":"#### 4.2.3 Create barchart ","c5473777":"#### 4.4.2 Customer review of top 20 product having the lowest amount of selling","ca2e0a33":"## I. Library and Data accessing","1e68c399":"#### 5.2.2 Chisquare test of 4 payment type with satisfy","0746fc74":"### 4.7 The rate of buy back","c5045317":"### 4.1 Top product categories having the largest revenue and amount of selling","2a8c8c83":"## III. Data joining\n![HRhd2Y0.png](attachment:HRhd2Y0.png)","4cd39e26":"##### Column order_delivered_carrier_date","6edc6071":"#### 4.6.2 Top 20 sellers having the largest amount of selling","83924745":"#### 4.4.1 Customer review of top 20 product category having the largest total revenue","3e10d97d":"### Key answers for the question of:\n1. What are the top product categories having the largest avenue and amount of selling in total ?\n2. What are the key cities ? \n3. Which product category that Marketing plan for each month should concentrate on ?\n4. What are the Top sellers ?\n5. How many percentage customer turnover after purchasing ?\n6. How customer evaluate from top product categories ?\n7. How many elements affect to delivery ? How much effect ? \n8. Is has a relationship between payment type, delivery hours with customer satisfaction ? how strength they are ?\n-------------------------------------------------------\n### Table of content: \n#### I. Import necessary libraries and Reading data\n#### II. Data Cleaning and Preparation\n1. Checking missing values\n2. dealing with missing values\n3. Checking duplicate\n\n#### III. Joining Data\n#### IV. Data Categorizing and Visualization\n#### V. Statistical analysis\n#### VI. Key insight and report","00835cdf":"#### 4.2.1 Creating new columns delievery hours","7c39f725":"#### 5.1.1 Correlation between delivery expecting hours with weight of product ","9cb43daa":"#### 2.2.5 Missing Values in Product_Data\n\nIn column product_category_name,product_name_lenght,  product_description_lenght, product_photos_qty. we have *610 missing values* in each column. We **drop** it because of no way to fill ","76c596ea":"#### 2.2.1 missing value of orders_data.\n**order_delivered_carrier_date \/ order_delivered_customer_date \/  order_approved_at **\n\nStep 1: We use function **pd.to_datetime** to convert type date columns from object to **datetime64** \n\nStep 2: We caculate the average period between column non-missing values ( order_purchase_timestamp) and column having missing values ( order_delivered_carrier_date, order_delivered_customer_date )\n\nStep 3: We fill missing values by the minus between order_purchase_timestamp with the average period caculated in step 2","d80dd9e3":"#### 4.2.2 Delievery average hour of top 20 product category having the largest revenue","90adfe0e":"### 5.2 Payment type ( Chisquare )","4b046af0":"#### 2.2.2 Missing values in DataFrame: review_data","09e9c27b":"### 1.1 Importing library","8daaf38c":"### 4.3 Top 5 customer cities\n\n#### 4.3.1. Top 5 cities having the largest revenue","b73a4e3f":"## VI. Insight and report","ae547aa6":"#### 4.6.1 Top 20 sellers having the largest revenue","b221d8bf":"### 4.2 Average hours of delivery of product category having largest revenue","6de88813":"#### 4.1.1. Top 20 product categories caculated based on total revenue","079cc7e9":"### 2.3 checking duplicated","91becf4d":"#### 4.5.1 The  total of revenue based on each month","80658021":"### 4.5 Monthly statistics ","d7ffd3e0":"## V. Statistical Analysis "}}