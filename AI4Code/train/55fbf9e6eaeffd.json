{"cell_type":{"0ffb569a":"code","e4f6f853":"code","cc0224de":"code","e9811908":"code","6edb03a7":"code","4f6386eb":"code","275e09ad":"code","df43d2a2":"code","0b1f1935":"code","8290f495":"code","d46b2940":"code","add5a128":"code","2876f125":"code","117035c3":"code","b8086fac":"markdown","a3d3635a":"markdown","0af1f444":"markdown","51a60fed":"markdown","cb1777c7":"markdown","ca6d26ef":"markdown","3670ccfc":"markdown"},"source":{"0ffb569a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4f6f853":"from gensim.models import Word2Vec\nfrom nltk.tokenize import sent_tokenize, word_tokenize","cc0224de":"f = open(r'\/kaggle\/input\/textdata\/sinhala.txt', 'r')\ntext = f.read()\nsent = sent_tokenize(text)\nsent = [word_tokenize(s) for s in sent]\n\nprint(sent[:10])","e9811908":"skipgramModel = Word2Vec(min_count=1, \n                         sg=1, \n                         size=300,\n                         window=5,\n                        seed=3)\n\nskipgramModel.build_vocab(sentences = sent, \n                           progress_per=1000)\n\nskipgramModel.train(sentences = sent,\n                     total_examples=skipgramModel.corpus_count, \n                     epochs=10, \n                     report_delay=1)","6edb03a7":"print(\"Vocabulary size:\" + str(len(skipgramModel.wv.vocab)))\nprint(\"Corpus size:\" + str(skipgramModel.corpus_count))","4f6386eb":"print(skipgramModel.wv['\u0db8\u0dc4\u0dad\u0dcf'])","275e09ad":"print(\"Dimention of a word vector\" + str(len(skipgramModel.wv['\u0db8\u0dc4\u0dad\u0dcf'])))","df43d2a2":"skipgramModel2 = Word2Vec(min_count=2, \n                         sg=1, \n                         size=300,\n                         window=5,\n                         seed=3)\n\nskipgramModel2.build_vocab(sentences = sent, \n                           progress_per=1000)\n\nskipgramModel2.train(sentences = sent,\n                     total_examples=skipgramModel2.corpus_count, \n                     epochs=10, \n                     report_delay=1)\n\nprint(\"Vocabulary size:\" + str(len(skipgramModel2.wv.vocab)))","0b1f1935":"cbowModel = Word2Vec(min_count=1, \n                    sg=0, \n                    size=300,\n                    window=5,\n                    seed=3)\n\ncbowModel.build_vocab(sentences = sent, \n                      progress_per=1000)\n\ncbowModel.train(sentences = sent,\n                total_examples=cbowModel.corpus_count, \n                epochs=10, \n                report_delay=1)","8290f495":"common_words = ['\u0da2\u0dcf\u0dad\u0dd2\u0d9a', '\u0da2\u0db1\u0dad\u0dcf', '\u0d91\u0db8', '\u0d85\u0d82\u0d9a', '\u0db8\u0dc4\u0dad\u0dcf', '\u0d9a\u0ddc\u0db4\u0db8\u0dab\u0daf', '\u0dba\u0da7\u0dad\u0dda', '\u0dc3\u0db3\u0dc4\u0dcf', '\u0d8a\u0da7', '\u0dbd\u0daf\u0dd3']","d46b2940":"skipgramOutFile = open(r'SkipgramOut.txt','w')\n\nfor w in common_words:\n    print(\"\\r\\n\" + w + \"------------>\\r\\n\")\n    skipgramOutFile.write('\\r\\n' + w + '------------>\\r\\n')\n    lst = skipgramModel.wv.similar_by_word(word=w)\n    [print(i) for i in lst]\n    skipgramOutFile.write('\\r\\n'.join('{} {}'.format(x[0],x[1]) for x in lst))","add5a128":"cbowOutFile = open(r'CBOWOut.txt','w')\n\nfor w in common_words:   \n    print(\"\\r\\n\" + w + \"------------>\\r\\n\")\n    cbowOutFile.write('\\r\\n' + w + '------------>\\r\\n')\n    lst = cbowModel.wv.similar_by_word(word=w)\n    [print(i) for i in lst]\n    cbowOutFile.write('\\r\\n'.join('{} {}'.format(x[0],x[1]) for x in lst))","2876f125":"import fasttext.util\nfasttext.util.download_model('si', if_exists='ignore')","117035c3":"ft = fasttext.load_model('cc.si.300.bin')\nfor w in common_words:   \n    print(\"\\r\\n\" + w + \"------------>\\r\\n\")\n    lst = ft.get_nearest_neighbors(word=w)\n    [print(i) for i in lst]","b8086fac":"## Similar words predicted by CBOW model","a3d3635a":"## Skipgram model","0af1f444":"## similar words predicted by skipgram model","51a60fed":"### try to increase min_count=2 to ignore some words","cb1777c7":"### Use pretrained fasttext word vectors from Facebook to generate similar words to the same set of above common words\n[https:\/\/fasttext.cc\/docs\/en\/crawl-vectors.html](http:\/\/)","ca6d26ef":"### since vocabulary size of the model has significantly dropped, continue to use min_count=1","3670ccfc":"## CBOW model"}}