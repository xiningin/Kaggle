{"cell_type":{"3ad0ab0c":"code","1927e069":"code","f92310ba":"code","25873493":"code","e75d5506":"code","39c299b4":"code","fcbf1052":"code","5522566d":"code","d9c1268e":"code","1ad021d2":"code","637c1978":"code","da72009a":"code","69b33bce":"code","2ad81eb0":"code","bd75920c":"code","896a7c0f":"code","20fdc0cd":"code","200aefd5":"code","e16dedde":"code","aa779570":"code","b9daef6c":"code","22943157":"code","a704f32b":"code","5466b1fb":"code","5491bce0":"code","b4c9387b":"code","ba97ff75":"code","babf50b5":"markdown","fd445fd3":"markdown","26d93af5":"markdown","130790ff":"markdown","3a28cb0e":"markdown","106782e7":"markdown","e336721c":"markdown","1f06d5ff":"markdown","ec211c09":"markdown","0cef9d81":"markdown","91669757":"markdown","b778a754":"markdown"},"source":{"3ad0ab0c":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport sys\nimport os\nimport pickle\nfrom tqdm import tqdm_notebook as tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools","1927e069":"print(os.listdir('..\/input'))\nprint(os.listdir('..\/input\/diabetic-retinopathy-detection-image-size'))","f92310ba":"train = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntest = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')","25873493":"len(train), len(test)","e75d5506":"#the func is from https:\/\/www.kaggle.com\/toshik\/image-size-and-rate-of-new-whale\ndef get_size_list(targets, dir_target):\n    result = list()\n    for target in tqdm(targets):\n        img = np.array(Image.open(os.path.join(dir_target, target+'.png')))\n        result.append(img.shape)\n    return result\n\n# the func is from https:\/\/www.kaggle.com\/kaerunantoka\/extract-image-features\ndef get_size(file_name_list, dir_target):\n    result = list()\n    #filename = images_path + filename\n    for file_name in tqdm(file_name_list):\n        st = os.stat(f'{dir_target}\/{file_name}.png')\n        result.append(st.st_size)\n    return result","39c299b4":"train['image_shape'] = get_size_list(train.id_code.tolist(),\n                                     dir_target='..\/input\/aptos2019-blindness-detection\/train_images')\ntest['image_shape'] = get_size_list(test.id_code.tolist(),\n                                    dir_target='..\/input\/aptos2019-blindness-detection\/test_images')\ntrain['image_size'] = get_size(train.id_code.tolist(),\n                               dir_target='..\/input\/aptos2019-blindness-detection\/train_images')\ntest['image_size'] = get_size(test.id_code.tolist(),\n                              dir_target='..\/input\/aptos2019-blindness-detection\/test_images')","fcbf1052":"for df in [train, test]:\n    df['height'] = df['image_shape'].apply(lambda x:x[0])\n    df['width'] = df['image_shape'].apply(lambda x:x[1])\n    df['width_height_ratio'] = df['height'] \/ df['width']\n    df['width_height_added'] = df['height'] + df['width']","5522566d":"train.head()","d9c1268e":"train.describe()","1ad021d2":"test.describe()","637c1978":"fig = plt.figure(figsize=(16,10))\nplt.subplot(241)\nplt.hist(train['width'])\nplt.title(\"train width\")\nplt.xlim(200, 4500)\n\nplt.subplot(242)\nplt.hist(test['width'])\nplt.title(\"test width\")\nplt.xlim(200, 4500)\n\nplt.subplot(243)\nplt.hist(train['height'])\nplt.title(\"train height\")\nplt.xlim(200, 3100)\n\nplt.subplot(244)\nplt.hist(test['height'])\nplt.title(\"test height\")\nplt.xlim(200, 3100)\n\nplt.subplot(245)\nplt.hist(train['width_height_ratio'])\nplt.title(\"train width height ratio\")\nplt.xlim(0.6, 1.05)\n\n\nplt.subplot(246)\nplt.hist(test['width_height_ratio'])\nplt.title(\"test width height ratio\")\nplt.xlim(0.6, 1.05)\n\nplt.subplot(247)\nplt.hist(train['width_height_added'])\nplt.title(\"train width height added\")\n\nplt.subplot(248)\nplt.hist(test['width_height_added'])\nplt.title(\"train width height added\");","da72009a":"sns.heatmap(train.corr(), cmap=plt.cm.Blues, annot=True);","69b33bce":"train_meta = train.groupby(['width', 'height', 'diagnosis']).agg({'diagnosis':'count'}).unstack('diagnosis').fillna(0)\ntrain_meta.columns = [f'{i[0]}_{i[1]}' for i in train_meta.columns]\ntrain_meta['train_count'] = train_meta.sum(axis=1)\n\ntest_meta = test.groupby(['width', 'height']).agg({'id_code':'count'}).rename(columns={'id_code':'pub_test_count'})\ncount_ratio = train_meta.join(test_meta, how='outer')\n\nfor i in range(5):\n    count_ratio.loc[:, f'{i}_ratio'] = count_ratio.iloc[:, i] \/ count_ratio['train_count']\n\ncount_ratio = count_ratio.fillna(0)\n\ncount_ratio = count_ratio.astype({'diagnosis_0': int, 'diagnosis_1': int, 'diagnosis_2': int,\n                                  'diagnosis_3': int, 'diagnosis_4': int})\ncount_ratio = count_ratio.astype({'train_count': int, 'pub_test_count': int})\n\ncount_ratio.reset_index(inplace=True)\ncount_ratio.set_index(['width', 'height', 'train_count', 'pub_test_count'], inplace=True)","2ad81eb0":"count_ratio","bd75920c":"def im_show(height, width, num):\n    tmp = train[(train['width'] == width) & (train['height'] == height)].id_code\n    dir_target = '..\/input\/aptos2019-blindness-detection\/train_images'\n    id = tmp.values[num]\n    img = Image.open(os.path.join(dir_target, id +'.png'))\n    plt.imshow(img.resize((256, 256)))\n    plt.tick_params(bottom=False,\n                    left=False,\n                    right=False,\n                    top=False,\n                    labelbottom=False,\n                    labelleft=False,\n                    labelright=False,\n                    labeltop=False)\n    value = train.loc[train['id_code'] == id, :].values[0]\n    plt.title(f'({value[4]},{value[5]})->(256,256)\\n {id}, diagnosis:{value[1]}')\n\ndef five_img_plot(height, width):\n    print('-' * 10)\n    print(f'shape({height}, {width})')\n    plt.figure(figsize=(16, 4))\n    for i in range(5):\n        plt.subplot(1,5,i+1)\n        im_show(height, width, i)\n    plt.show()","896a7c0f":"five_img_plot(480, 640)\nfive_img_plot(614, 819)\nfive_img_plot(1050, 1050)\nfive_img_plot(1536, 2048)\nfive_img_plot(1736, 2416)\nfive_img_plot(1958, 2588)\nfive_img_plot(2588, 3388)","20fdc0cd":"pre_train = pd.read_csv('..\/input\/diabetic-retinopathy-detection-image-size\/pre_train_shape.csv')\npre_test = pd.read_csv('..\/input\/diabetic-retinopathy-detection-image-size\/pre_test_shape.csv')\n\nfor df in [pre_train, pre_test]:\n    df['width_height_ratio'] = df['height'] \/ df['width']\n    df['width_height_added'] = df['height'] + df['width']","200aefd5":"len(pre_train), len(pre_test)","e16dedde":"pre_train.head()","aa779570":"pre_test.head()","b9daef6c":"pre_train.describe()","22943157":"fig = plt.figure(figsize=(16,10))\nplt.subplot(241)\nplt.hist(pre_train['width'])\nplt.title(\"pre train width\")\nplt.xlim(200, 5500)\n\nplt.subplot(242)\nplt.hist(pre_test['width'])\nplt.title(\"pre test width\")\nplt.xlim(200, 5500)\n\nplt.subplot(243)\nplt.hist(pre_train['height'])\nplt.title(\"pre train height\")\nplt.xlim(200, 4000)\n\nplt.subplot(244)\nplt.hist(pre_test['height'])\nplt.title(\"pre test height\")\nplt.xlim(200, 4000)\n\nplt.subplot(245)\nplt.hist(pre_train['width_height_ratio'])\nplt.title(\"pre train width height ratio\")\nplt.xlim(0.6, 1.05)\n\n\nplt.subplot(246)\nplt.hist(pre_test['width_height_ratio'])\nplt.title(\"pre test width height ratio\")\nplt.xlim(0.6, 1.05)\n\nplt.subplot(247)\nplt.hist(pre_train['width_height_added'])\nplt.title(\"pre train width height added\")\n\nplt.subplot(248)\nplt.hist(pre_test['width_height_added'])\nplt.title(\"pre train width height added\");","a704f32b":"pre_train.drop('channel', axis=1, inplace=True)\npre_test.drop('channel', axis=1, inplace=True)","5466b1fb":"plt.rcParams[\"font.size\"] = 14\n# pre_train.rename(columns={'level': 'diagnosis'}, inplace=True)\nplt.figure(figsize=(16,8))\nplt.subplot(121)\nsns.heatmap(pre_train.corr(), cmap=plt.cm.Blues, annot=True)\nplt.title('previous_competition')\n\nplt.subplot(122)\nsns.heatmap(train.corr(), cmap=plt.cm.Blues, annot=True)\nplt.title('this_competition')\n\nplt.tight_layout()","5491bce0":"pre_train_meta = pre_train.groupby(['width', 'height', 'level']).agg({'level':'count'}).unstack('level').fillna(0)\npre_train_meta.columns = [f'{i[0]}_{i[1]}' for i in pre_train_meta.columns]\npre_train_meta['train_count'] = pre_train_meta.sum(axis=1)\n\npre_test_meta = pre_test.groupby(['width', 'height']).agg({'image':'count'}).rename(columns={'image':'pub_test_count'})\npre_count_ratio = pre_train_meta.join(pre_test_meta, how='outer')\n\nfor i in range(5):\n    pre_count_ratio.loc[:, f'{i}_ratio'] = pre_count_ratio.iloc[:, i] \/ pre_count_ratio['train_count']\n\npre_count_ratio = pre_count_ratio.fillna(0)\n\npre_count_ratio = pre_count_ratio.astype({'level_0': int, 'level_1': int, 'level_2': int, 'level_3': int, 'level_4': int})\npre_count_ratio = pre_count_ratio.astype({'train_count': int, 'pub_test_count': int})\n\npre_count_ratio.reset_index(inplace=True)\npre_count_ratio.set_index(['width', 'height', 'train_count', 'pub_test_count'], inplace=True)","b4c9387b":"pre_count_ratio","ba97ff75":"plt.rcParams[\"font.size\"] = 13\nplt.figure(figsize=(12, 8))\nsns.heatmap(pre_count_ratio.iloc[:, 5:], cmap=plt.cm.Blues)\nplt.xlabel('target')\nplt.ylabel('width - height - number_of_train - number_of_public_test')\nplt.title('Number of image and ratio by image shape in previous competition')\nplt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0',  '1', '2', '3', '4'])\nfor i, j in itertools.product(range(5), range(len(pre_count_ratio))):\n    train_count = pre_count_ratio.index[j][2]\n    if train_count != 0:\n        ratio = np.int(np.round(pre_count_ratio.iloc[j, i+5] * 100))\n        count = pre_count_ratio.iloc[j, i]\n        plt.text(i+0.2, j+0.8, f'{count:>4}', color='k'if ratio < 65 else \"w\")\n        plt.text(i+0.5, j+0.8, f'{ratio:>3}%', color='k'if ratio < 65 else \"w\")\n    elif train_count == 0:\n        plt.text(i+0.5, j+0.8, '-', color='k')\nplt.show()\n\nplt.figure(figsize=(12, 8))\nsns.heatmap(count_ratio.iloc[:, 5:], cmap=plt.cm.Blues)\nplt.xlabel('target')\nplt.ylabel('width - height - number_of_train - number_of_public_test')\nplt.title('Number of image and ratio by image shape in present competition')\nfor i, j in itertools.product(range(5), range(len(count_ratio))):\n    train_count = count_ratio.index[j][2]\n    if train_count != 0:\n        ratio = np.int(np.round(count_ratio.iloc[j, i+5] * 100))\n        count = count_ratio.iloc[j, i]\n        plt.text(i+0.2, j+0.8, f'{count:>4}', color='k'if ratio < 65 else \"w\")\n        plt.text(i+0.5, j+0.8, f'{ratio:>3}%', color='k'if ratio < 65 else \"w\")\n    elif train_count == 0:\n        plt.text(i+0.5, j+0.8, '-', color='k')\n    plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0',  '1', '2', '3', '4'])\nplt.show();","babf50b5":"This kernel uses the following kernel code:\n* https:\/\/www.kaggle.com\/h4211819\/image-size-eda\n* https:\/\/www.kaggle.com\/yangsaewon\/basic-eda-train-test-image-distribution-check\n* https:\/\/www.kaggle.com\/kaerunantoka\/extract-image-features\n\nI think that this competition needs to be careful because the target is biased due to the shape of the image.  \nAlso, I think that the information of the image shape of the previous competition will be helpful, but because it can not be read from the kernel, I released the [dataset](https:\/\/www.kaggle.com\/currypurin\/diabetic-retinopathy-detection-image-size) and [discussion](https:\/\/www.kaggle.com\/c\/aptos2019-blindness-detection\/discussion\/99846).","fd445fd3":"UPDATE on V3:  \nAdded 2. Display an image for each shape","26d93af5":"* The proportion of black area and the tendency of brightness are also likely to be in each image shape.\n* I would like to update this point later.\n* ref : https:\/\/www.kaggle.com\/c\/aptos2019-blindness-detection\/discussion\/99846#575147","130790ff":"* The bias of the class by the shape of the train image was small in the last competition, but this time the competition is not.\n* In the previous competition, the ranking change on the public and private leaderboard is not large.\n* I\u00a0think that this bias may cause a large shakeup.","3a28cb0e":"* Many feature seems to be correlated with the target.","106782e7":"# 1. present competition","e336721c":"* The number of images of the last competition is very large.","1f06d5ff":"# 4.Number of image and ratio by image shape in previous and present competition","ec211c09":"There are about 90,000 images of [the previous competition](https:\/\/www.kaggle.com\/c\/diabetic-retinopathy-detection) and Kernel can not read all the images. So I run the same code as above, and [dataset](https:\/\/www.kaggle.com\/currypurin\/diabetic-retinopathy-detection-image-size) made public.","0cef9d81":"# 2.Display an image for each shape","91669757":"# 3.previous competition","b778a754":"* Training data has different target distribution for each image shape.\n  * For example 1050x1050 is high ratio of class_0, 2136x3216 is high ratio of class_2\n* If we leave the image shape information in the preprocessed image, there is a possibility of overfitting, so be very careful.\n* Let's look at the images."}}