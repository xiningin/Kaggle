{"cell_type":{"19cb4ec3":"code","6b37b067":"code","46fc66e2":"code","523ff11f":"code","a131f35b":"code","4cb9240f":"code","01bfc2bd":"code","265bbeac":"code","5e4efc72":"code","56e557d7":"code","b504a8e5":"code","903ce9d3":"code","e85ead92":"code","f4f7c410":"code","121a9846":"code","047c2cbe":"code","f24cbdbb":"code","7612840f":"code","eac4e427":"markdown","c941f68f":"markdown","b27d8a65":"markdown","e3c83a47":"markdown","362300fe":"markdown","3f41ca37":"markdown"},"source":{"19cb4ec3":"import numpy as np \nimport pandas as pd \nimport tqdm\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport os\nimport geopy.distance\nimport folium\nimport folium.plugins as plugins\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\n\nprint(os.listdir(\"..\/input\"))","6b37b067":"df = pd.read_csv(r'..\/input\/autotel-shared-car-locations\/\/sample_table.csv')","46fc66e2":"df['carsList'] = df.carsList.apply(lambda x: x[1:-1]) # remove square brackets\ndf['carsList'] = df.carsList.apply(lambda x: x.split(',')) # convert string to list\ndf['carsList'] = df.carsList.apply(lambda x: [] if x == [''] else x) # denote empty lists\ndf['carsList'] = df.carsList.apply(lambda x: [int(i) for i in x]) # convert list items to int\ndf['total_cars'] = df.carsList.apply(len) \ndf = df[df.total_cars > 0]","523ff11f":"# Parse list of cars into different rows \ndef explode(df, lst_cols, fill_value=''):\n    # make sure `lst_cols` is a list\n    if lst_cols and not isinstance(lst_cols, list):\n        lst_cols = [lst_cols]\n    # all columns except `lst_cols`\n    idx_cols = df.columns.difference(lst_cols)\n\n    # calculate lengths of lists\n    lens = df[lst_cols[0]].str.len()\n\n    if (lens > 0).all():\n        # ALL lists in cells aren't empty\n        return pd.DataFrame({\n            col:np.repeat(df[col].values, lens)\n            for col in idx_cols\n        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n          .loc[:, df.columns]\n    else:\n        # at least one list in cells is empty\n        return pd.DataFrame({\n            col:np.repeat(df[col].values, lens)\n            for col in idx_cols\n        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n          .loc[:, df.columns]\n    \nnew_df = explode(df, ['carsList'], fill_value='')","a131f35b":"# Pivot the table to a new structures, where the indices are unique timestamps, the columns are cars and the values are the coordinates of the cars\npivot_df = new_df.pivot(index='timestamp',columns='carsList', values=['latitude', 'longitude'])","4cb9240f":"pivot_df.head()","01bfc2bd":"def get_car_trips(pivot_df, car_num):\n    # First, take the relevant columns for the car in question\n    car = pivot_df[[('latitude', car_num), ('longitude', car_num)]]\n    car = car[pd.isnull(car[('latitude', car_num)]) == False]\n    \n    # Find the previous location\n    car.loc[:, 'prev_lat'] = car.shift()[('latitude', car_num)]\n    car.loc[:, 'prev_lon'] = car.shift()[('longitude', car_num)]\n    \n    # If the location has not changed, there is no trip going on\n    car.loc[:, 'trip'] = car[('latitude', car_num)] == car.prev_lat\n    car.loc[:, 'trip'] = car.trip.apply(lambda x: 0 if x else 1)\n    car.loc[:, 'trip'] = car.trip.cumsum()\n    car.reset_index(inplace=True)\n    \n    # Merge the data frame with itself shifted by one\n    f = {'timestamp': ['min', 'max'], ('latitude', car_num): 'first', ('longitude', car_num): 'first'}\n    trip_df = car.groupby('trip').agg(f)\n    prev_df = car.groupby('trip').agg(f).shift()\n\n    trip_df = pd.merge(trip_df, prev_df, left_index=True, right_index=True)\n    \n    trip_df.columns = trip_df.columns.get_level_values(0)\n    trip_df.columns = ['end', 'start_next', 'end_lat', 'end_long', 'end_prev', 'start', 'start_lat', 'start_long']\n    trip_df['car'] = car_num\n    return trip_df","265bbeac":"trips = pd.DataFrame()\n\nfor car in tqdm.tqdm(np.array(pivot_df.columns.get_level_values(1))):\n    trips = trips.append(get_car_trips(pivot_df, car))\n    ","5e4efc72":"def trip_distance(lat1, lat2, lon1, lon2):\n    try:\n        coords_1 = (lat1, lon1)\n        coords_2 = (lat2, lon2)\n        return geopy.distance.vincenty(coords_1, coords_2).km\n    except ValueError:\n        return -1\n    \ntrips['trip_len'] = trips.apply(lambda x: trip_distance(x.start_lat, x.end_lat, x.start_long, x.end_long), axis=1)\ntrips.reset_index(inplace=True)\n\n\ndef transform_time(x):\n    try:\n        return datetime.strptime(x[:19], '%Y-%m-%d %H:%M:%S')\n    except TypeError:\n        return -1\n    \ntrips['end'] = trips.end.apply(transform_time)\ntrips['start'] = trips.start.apply(transform_time)\n\n","56e557d7":"trips = trips[trips.trip_len > 0.5]\ntrips['trip_duration'] = trips.apply(lambda x: (x.end - x.start).seconds\/60, axis=1)\ntrips = trips[trips.trip_duration > 3]\n\ntrips['start_hour'] = trips.start.apply(lambda x: x.hour)\ntrips['day'] = trips.start.apply(lambda x: x.date())","b504a8e5":"plt.figure(figsize=(8, 6))\nplt.style.use('fivethirtyeight')\nsns.distplot(trips.trip_duration, bins=np.linspace(0, 120, 60), kde=False)\nplt.xlabel('Duration [mins]')\n","903ce9d3":"plt.figure(figsize=(8, 6))\nsns.distplot(trips.trip_len, bins=np.linspace(0, 12, 60), kde=False)\nplt.xlim([1, 12])\nplt.xlabel('Distance [km]')","e85ead92":"kmeans = KMeans(n_clusters=6)\ntrips['start_cluster'] = kmeans.fit_predict(trips[['start_lat', 'start_long']])\ntrips['end_cluster'] = kmeans.predict(trips[['end_lat', 'end_long']])\ntrips.head()","f4f7c410":"def aggregate_trips(trips, kmeans):\n    f = {'trip': 'count', 'start': 'first'}\n    grouped_trips = trips.groupby(['start_cluster', 'end_cluster', 'start_hour']).agg(f).reset_index()\n\n    clusters = pd.DataFrame(kmeans.cluster_centers_)\n    clusters.columns = ['lat', 'long']\n\n    grouped_trips = pd.merge(grouped_trips, clusters, left_on='start_cluster', right_index=True)\n    grouped_trips = pd.merge(grouped_trips, clusters, left_on='end_cluster', right_index=True)\n    return grouped_trips\n\n\ndef group_by_hour(grouped_trips):\n    grouped_hour = grouped_trips.groupby(['start_cluster', 'end_cluster', 'start_hour']).agg({'start': 'min', 'lat_x': 'first', 'long_x': 'first',\n                                    'lat_y': 'first', 'long_y': 'first', 'trip': 'sum'}).reset_index()\n    grouped_hour['date'] = [datetime.strptime('2019-01-01', '%Y-%m-%d')]*len(grouped_hour)\n    grouped_hour['date'] = grouped_hour.apply(lambda x: x['date'] + timedelta(hours=x.start_hour), axis=1)\n    return grouped_hour\n\n\ndef create_map(grouped_hour, weight):\n    m = folium.Map(location=[32.13,34.8],zoom_start=12, tiles=\"CartoDB dark_matter\")\n\n    lines = [\n        {\n            'coordinates': [\n                [grouped_hour.long_x.iloc[index], grouped_hour.lat_x.iloc[index]],\n                [grouped_hour.long_y.iloc[index], grouped_hour.lat_y.iloc[index]],\n            ],\n            'dates': [\n            str(grouped_hour['date'].iloc[index]),\n            str(grouped_hour['date'].iloc[index])\n            ],\n            'color': 'gold',\n            'weight': int(grouped_hour.trip.iloc[index])\n    # \n\n        }\n        for index in range(len(grouped_hour))\n    ]\n\n    features = [\n        {\n            'type': 'Feature',\n            'geometry': {\n                'type': 'LineString',\n                'coordinates': line['coordinates'],\n            },\n            'properties': {\n                'times': line['dates'],\n                'style': {\n                    'color': line['color'],\n                    'weight': weight*line['weight']**1.5 if 'weight' in line else 5\n                }\n            }\n        }\n        for line in lines\n    ]\n\n\n    plugins.TimestampedGeoJson({\n        'type': 'FeatureCollection',\n        'features': features,\n    }, period='PT1H', duration='PT1H', add_last_point=True).add_to(m)\n    return m\n","121a9846":"# trips = trips.sample(40000)\n# data = [trips[trips['start_hour']==sorted(trips['start_hour'].unique())[i]][['start_lat','start_long']].values.tolist() \n#         for i in range(len(trips['start_hour'].unique()))]\n\n# monthDict = { 0:'00:00', 1:'01:00', 2:'02:00', 3:'03:00', 4:'04:00', 5:'05:00', 6:'06:00', \n#             7:'07:00', 8:'08:00', 9:'09:00', 10:'10:00', 11:'11:00', 12:'12:00',\n#             13:'13:00', 14:'14:00', 15:'15:00', 16:'16:00', 17:'17:00', 18:'18:00', \n#             19:'19:00', 20:'20:00', 21:'21:00', 22:'22:00', 23:'23:00', 24:'24:00'}\n\n# index = [monthDict[i] for i in sorted(trips['start_hour'].unique())]\n\n# m = folium.Map(location=[32.13,34.8],zoom_start=12, tiles=\"CartoDB dark_matter\")\n# hm = plugins.HeatMapWithTime(data=data,index=index)\n\n# hm.add_to(m)\n\n# m","047c2cbe":"weekend = trips[trips.day.isin([datetime.strptime('2018-12-14', '%Y-%m-%d').date(), datetime.strptime('2018-12-15', '%Y-%m-%d').date(), \n                                datetime.strptime('2018-12-22', '%Y-%m-%d').date(), datetime.strptime('2018-12-21', '%Y-%m-%d').date(),\n                             datetime.strptime('2018-12-29', '%Y-%m-%d').date(),  datetime.strptime('2018-01-28', '%Y-%m-%d').date(),\n                                datetime.strptime('2019-01-05', '%Y-%m-%d').date(),  datetime.strptime('2019-01-04', '%Y-%m-%d').date()])]\n\nweek = trips[~trips.day.isin([datetime.strptime('2018-12-14', '%Y-%m-%d').date(), datetime.strptime('2018-12-15', '%Y-%m-%d').date(), \n                                datetime.strptime('2018-12-22', '%Y-%m-%d').date(), datetime.strptime('2018-12-21', '%Y-%m-%d').date(),\n                             datetime.strptime('2018-12-29', '%Y-%m-%d').date(),  datetime.strptime('2018-01-28', '%Y-%m-%d').date(),\n                                datetime.strptime('2019-01-05', '%Y-%m-%d').date(),  datetime.strptime('2019-01-04', '%Y-%m-%d').date()])]","f24cbdbb":"agg_trips = aggregate_trips(week, kmeans)\ngrouped_by_hour = group_by_hour(agg_trips)\nm = create_map(grouped_by_hour, 0.001)\nm","7612840f":"agg_trips = aggregate_trips(weekend, kmeans)\ngrouped_by_hour = group_by_hour(agg_trips)\nm = create_map(grouped_by_hour, 0.02)\nm","eac4e427":"# Filter Rides\n\nRides that were shorter than 3 minutes in duration and 500 meters were filtered out. This is due to the fact that it seems that some cars were still recorded as available even though they were obviously during a trip, which created a long number of super short trips which skewed the data","c941f68f":"Some pandas transformaton of the data. If anyone has a more elegant solution I would be happy to incorporate it into my code","b27d8a65":"# Rides pattern","e3c83a47":"# Some Transformations","362300fe":"# Trips data frame\nNow we have a new data frame, where each row is a trip, with a starting and an ending point, as well as the relevant timestamps and car id. Let's add the interesting columns to each trip.\n\nLet's examine the data in this new structure","3f41ca37":"# Rides Animation\n\nLet's bring the city to life with the great maps libraray Folium.\n\nI would present several animations:\n1. First, a simpe time series heatmap of the activity in the city\n2. Then we would cluster the city into areas and see how the traffic shifts along the day "}}