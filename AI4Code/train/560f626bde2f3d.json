{"cell_type":{"70144371":"code","813958ce":"code","2293dc39":"code","4668ac1b":"code","d3db5cfd":"code","5d714e8c":"code","1be905c5":"code","63c77f14":"code","375921c1":"code","e9836fef":"code","27186606":"code","467ba0cf":"code","510361b6":"code","24afab4a":"code","af28c779":"code","55014ca4":"code","8b889509":"code","6b450367":"code","2524ddff":"code","67be8f8d":"code","24cbb82f":"code","3b6e88ef":"code","d0584172":"code","06495c85":"code","0c40d0fb":"code","6733c0b1":"code","479af826":"code","cb894414":"code","c4c53870":"code","d244bb15":"code","5e925683":"code","bf9669e5":"code","88dd893a":"code","c640c0f6":"markdown","d968b99b":"markdown","cd00b4fb":"markdown"},"source":{"70144371":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","813958ce":"raw_csv_data = pd.read_csv('\/kaggle\/input\/employee-absenteeism-data\/Absenteeism_data.csv')\nraw_csv_data.info()","2293dc39":"df = raw_csv_data.copy()\npd.options.display.max_columns = None\ndisplay(df)","4668ac1b":"df = df.drop(['ID'], axis=1)\ndf","d3db5cfd":"print('Reason for Absence Min: ', df['Reason for Absence'].min())\nprint('Reason for Absence Min: ', df['Reason for Absence'].max())","5d714e8c":"len(df['Reason for Absence'].unique())","1be905c5":"# According to the min and max of the Reason for Absence, there should be maximum 29 unique reasons for absence.\n# There's one reason does not appear in the dataset.\nsorted(df['Reason for Absence'].unique())","63c77f14":"# Now, we'll get dummies variables from the \"Reason for Absence\" column\nreason_columns = pd.get_dummies(df['Reason for Absence'])\nreason_columns","375921c1":"reason_columns['check'] = reason_columns.sum(axis=1)\nreason_columns['check']","e9836fef":"reason_columns['check'].unique()","27186606":"reason_columns = reason_columns.drop(['check'], axis=1)\n# We'll drop the first column\nreason_columns = pd.get_dummies(df['Reason for Absence'], drop_first=True)\nreason_columns","467ba0cf":"# Next, we'll group the reasons for absence into 4 groups\nreason_type1 = reason_columns.loc[:, 1:14].max(axis=1)\nreason_type2 = reason_columns.loc[:, 15:17].max(axis=1)\nreason_type3 = reason_columns.loc[:, 18:21].max(axis=1)\nreason_type4 = reason_columns.loc[:, 22:].max(axis=1)\n# To avoid multicollinearity,before concatenate the 'reason_columns', we'll drop the 'Reason for Absence' column from df\ndf = df.drop(['Reason for Absence'], axis=1)\ndf","510361b6":"# Now we'll concatenate the reason_columns into df\ndf = pd.concat([df, reason_type1, reason_type2, reason_type3, reason_type4], axis=1)\ndf.head()","24afab4a":"df.columns.values","af28c779":"column_names = ['Date', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours', 'Reason_1', 'Reason_2', 'Reason_3', 'Reason_4']\n\ndf.columns = column_names\ndf.head()","55014ca4":"column_names_reordered = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours']\n\ndf = df[column_names_reordered]\ndf.head()","8b889509":"df_reason_mod = df.copy()","6b450367":"type(df_reason_mod['Date'][0])","2524ddff":"df_reason_mod['Date'] = pd.to_datetime(df_reason_mod['Date'], format='%d\/%m\/%Y')\ndf_reason_mod.info()","67be8f8d":"# Next, we'll extract the month and date value, to see if there's any specific date\/month that the absence rate is more significant\n# Start with month values\n\nlist_month = []\n\ndf_reason_mod.shape","24cbb82f":"for i in range(df_reason_mod.shape[0]):\n    list_month.append(df_reason_mod['Date'][i].month)\n    \nlist_month","3b6e88ef":"len(list_month)","d0584172":"df_reason_mod['Month Values'] = list_month\ndf_reason_mod.head()","06495c85":"# Now, we'll extract weekday from Date\ndef weekday_from_date(date_value):\n    return date_value.weekday()\ndf_reason_mod['Weekday Values'] = df_reason_mod['Date'].apply(weekday_from_date)\ndf_reason_mod.head()","0c40d0fb":"# After extracting Month and Weekday values, we'll delete the old Date column, and replace them with Month and Weekday Values\n\ndf_reason_mod = df_reason_mod.drop(['Date'], axis=1)\n\ndf_reason_mod.columns.values","6733c0b1":"columns_list = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Month Values',\n       'Weekday Values', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours']\n\ndf_reason_mod = df_reason_mod[columns_list]\ndf_reason_mod.head()","479af826":"df_reason_date_mod = df_reason_mod.copy()","cb894414":"# Next, we'll modify Education column, the others will be left untouched","c4c53870":"df_reason_date_mod['Education'].unique()","d244bb15":"df_reason_date_mod['Education'].value_counts()","5e925683":"# The differences between group 2, 3, 4 is not really significant, so we'll split the Education categories into 2 groups.\ndf_reason_date_mod['Education'] = df_reason_date_mod['Education'].map({1:0, 2:1, 3:1, 4:1})\ndf_reason_date_mod['Education'].unique()","bf9669e5":"df_preprocessed = df_reason_date_mod.copy()\ndf_preprocessed.head()","88dd893a":"df_preprocessed.to_csv('Absenteeism_preprocessed.csv', index=False)","c640c0f6":"### Final checkpoint","d968b99b":"### Analysing 'Reason for Absence'","cd00b4fb":"### Analysing \"Date\" Column"}}