{"cell_type":{"944e0eec":"code","695a8e7a":"code","169586de":"code","6b0d1668":"code","cce60983":"code","56767783":"code","0d3d91f1":"code","a0f482c8":"code","fd33325a":"code","978033f3":"code","441cdc45":"code","4703f960":"code","0e62182c":"code","92bed1f9":"code","94239e49":"code","4bd9c800":"code","617b9021":"code","36e9bf17":"code","96546c71":"code","c3c2c0b6":"code","cfc1e621":"code","54a65e1c":"code","ef5f9e6b":"code","d72d84c7":"code","49efbb1a":"code","03025daf":"code","03fc732e":"code","1bfea8b7":"code","a2883e92":"code","51dbd570":"code","8e00fd4d":"code","cf84edfe":"code","6f8d2d48":"code","55d4e32e":"code","4c41109b":"code","fab9a70b":"code","b995bca5":"code","a1d03ef6":"code","b72dc723":"code","8272b2c7":"code","c141b5be":"code","560ede89":"code","cb3cd339":"code","08637c25":"code","d6d5796c":"code","0b7ad355":"code","78a21131":"code","b292e504":"code","108a34d5":"code","3256d396":"code","24191bc1":"code","7f0e3b46":"code","fa477e1c":"code","a997481f":"code","57c46cdb":"code","db6a1218":"code","14581feb":"code","f68ed7ee":"code","a24fea9a":"code","4cec3a08":"code","9a3e05be":"code","4767fdc5":"code","be144e0d":"code","0eabc88c":"code","768aaf5a":"code","1b245aa8":"code","cfcde487":"code","5f45efd0":"code","7be4db35":"code","f97064ed":"code","74f02813":"code","116ed5f3":"code","246d1519":"code","21917acb":"code","6ff630d2":"code","387f7b2c":"code","f368d379":"code","35cf7cb6":"code","98fc493b":"code","5a981ae8":"code","982caa05":"code","b56d3423":"code","e31d1028":"code","557acd3e":"code","82af1d59":"code","342cfa8b":"code","1c536d73":"code","b16f91ba":"code","28fb1bb3":"code","a85d5eb1":"code","162bb9a9":"code","850cf384":"code","3b2d0a8a":"code","09564be9":"code","f29bfad1":"code","3d049667":"code","0f76b414":"code","95063e9e":"markdown","cdf3fbe5":"markdown","7faa8ae8":"markdown","fc19987a":"markdown","1c1cc101":"markdown","a93f1f02":"markdown","6d1a8440":"markdown","4722daed":"markdown","d9af903c":"markdown","4c4251cd":"markdown","f89bc07c":"markdown","be6cb75e":"markdown","cc904d0d":"markdown","4828aca5":"markdown","e05b0f71":"markdown","a4b1ad1d":"markdown","7ff9f7db":"markdown","c92369ba":"markdown"},"source":{"944e0eec":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","695a8e7a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","169586de":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","6b0d1668":"train.head()","cce60983":"train.info()","56767783":"# Check for statistical values\ntrain.describe()","0d3d91f1":"train.head()","a0f482c8":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","fd33325a":"# Try for the survival rate per sex\ntrain[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","978033f3":"train[['Age', 'Survived']].groupby(['Age'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","441cdc45":"# Try for survival rate per Fare\ntrain[['Fare', 'Survived']].groupby(['Fare'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","4703f960":"# Try for survival rate per Parch\ntrain[['Parch', 'Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","0e62182c":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","92bed1f9":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","94239e49":"# add a histogram of only age distribution\ntrain['Age'].hist()","4bd9c800":"train[train['Survived'] == 0]['Age'].hist()","617b9021":"grph = sns.FacetGrid(train, col = \"Survived\")\ngrph.map(plt.hist, 'Age', bins = 20)","36e9bf17":"grph = sns.FacetGrid(train, col = \"Survived\", row = 'Pclass')\ngrph.map(plt.hist, 'Age', bins = 20)","96546c71":"train.head()","c3c2c0b6":"# investigate for Embarked column\nax = sns.barplot(x = train['Embarked'], y = train['Survived'])","cfc1e621":"# investiage Embarked column and Fare column\ngrph = sns.FacetGrid(train, row = \"Embarked\", col = \"Survived\")\ngrph.map(sns.barplot,'Sex','Fare')","54a65e1c":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","ef5f9e6b":"train.head()","d72d84c7":"test.head()","49efbb1a":"print('train shape:', train.shape, 'test shape:', test.shape)","03025daf":"train = train.drop(['Ticket', 'Cabin'], axis = 1)\ntest = test.drop(['Ticket', 'Cabin'], axis = 1)","03fc732e":"print('train shape:', train.shape, 'test shape:', test.shape)","1bfea8b7":"# Combine train and test data\ncombined = [train, test]","a2883e92":"from sklearn.preprocessing import LabelEncoder","51dbd570":"for dataset in combined:\n    dataset['Sex'] = dataset['Sex'].astype(str)\n    label = LabelEncoder()\n    dataset['Sex'] = label.fit_transform(dataset['Sex'])","8e00fd4d":"combined[0]","cf84edfe":"# Band Name column by the status\nfor dataset in combined:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.')\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer')\n    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Master'], 'Master')\n    dataset['Title'] = dataset['Title'].replace(['Don', 'Sir', 'the Countess', 'Lady', 'Dona'], 'Royalty')\n    dataset['Title'] = dataset['Title'].replace(['Mme', 'Ms', 'Mrs'], 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Miss'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace(['Mr'], 'Mr')","6f8d2d48":"combined[0]['Title'].unique()","55d4e32e":"# train\ncombined[0]","4c41109b":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\": 5, 'Officer': 6, 'Countess': 7}\n\nfor dataset in combined:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n\ncombined[0].head()","fab9a70b":"# check for null value\ncombined[0].isna().sum()","b995bca5":"combined[1]","a1d03ef6":"# Check the distribution of age\ncombined[0]['Age'].hist()","b72dc723":"# Assume the null values for the age of passengers using other features\ncombined[0]","8272b2c7":"grid = sns.FacetGrid(combined[0], row = 'Pclass', col = 'Sex')\ngrid.map(plt.hist, 'Age')","c141b5be":"guess_ages = np.zeros((2, 3))\nguess_ages\n# Row: Sex, Column: PClass\n# Sex = 1 and PClass = 1","560ede89":"# Sex == 1(Male), Pclass == 2 \ncombined[0][(combined[0]['Sex'] == 1) & \\\n                            (combined[0]['Pclass'] == 2)]['Age'].dropna().median()","cb3cd339":"for dataset in combined:\n    # For each sex\n    for i in range(0, 2):\n        # For each PClass -> 1, 2, 3\n        for j in range(0, 3):\n            # Calculate median value of the age of certain condition in Sex and PClass\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n            age_guess = guess_df.median()\n            \n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int(age_guess\/0.5 + 0.5 ) * 0.5","08637c25":"for i in range(0, 2):\n    for j in range(0, 3):\n        print('Sex:', i, 'Pclass:', j + 1, guess_ages[i][j])\n        \nguess_ages","d6d5796c":"for dataset in combined:\n# Fill in null values -> Sex : 0, 1 , PClass = 1, 2, 3\n    for i in range(0, 2):\n        for j in range(0, 3):\n            # 1. Locate null rows\n            # 2. Where Sex == i and Pclass == j + 1\n            # 3. Fill in the row with guess_ages[i][j]\n            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j + 1), \\\n                       'Age'] = guess_ages[i, j]\n    \n    dataset['Age'] = dataset['Age'].astype(int)\n    \n\ncombined[0].head()","0b7ad355":"# Sex == 1, Pclass == 2, dataset[0].Age == null\ncombined[0].loc[(combined[0].Age.isnull()) & (combined[0].Sex == 1) & (combined[0].Pclass == 2), 'Age'] = guess_ages[1, 1]","78a21131":"combined[0].isna().sum() ","b292e504":"combined[0]['Age'].hist()","108a34d5":"combined[0]['Age'].unique()","3256d396":"# Check age band's correlation with survival\n\nfor dataset in combined:\n    dataset['AgeBand'] = pd.cut(dataset['Age'], 5)","24191bc1":"sample = [24, 7, 2, 25, 22, 29]\n\npd.cut(sample, 3).value_counts()","7f0e3b46":"pd.qcut(sample, 3).value_counts()","fa477e1c":"combined[0]","a997481f":"combined[0].AgeBand.unique()","57c46cdb":"for dataset in combined:    \n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n\ntrain.head()","db6a1218":"combined[0].Age.unique()","14581feb":"# drop Ageband column\ncombined[0] = combined[0].drop(['AgeBand'], axis = 1)\ncombined[1] = combined[1].drop(['AgeBand'], axis = 1)","f68ed7ee":"# drop Name column \ncombined[0] = combined[0].drop(['Name'], axis = 1)\ncombined[1] = combined[1].drop(['Name'], axis = 1)","a24fea9a":"combined[0]","4cec3a08":"# drop PassengerId Column\ncombined[0] = combined[0].drop(['PassengerId'], axis = 1)","9a3e05be":"combined[0]","4767fdc5":"# Try banding 'Fare' column!\ncombined[0]['FareBand'] = pd.qcut(combined[0]['Fare'], 4)\ncombined[0][['FareBand', 'Survived']].groupby(['FareBand'], as_index = False).mean().sort_values(by = 'FareBand', ascending = True)","be144e0d":"pd.qcut(combined[0]['Fare'], 4).value_counts()","0eabc88c":"combined[1].Fare = combined[1].Fare.fillna(0)","768aaf5a":"combined[1].Fare.isna().sum()","1b245aa8":"for dataset in combined:\n    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    #dataset['Fare'] = dataset['Fare'].astype(int)\n\ncombined[0] = combined[0].drop(['FareBand'], axis=1)\ncombined[0]","cfcde487":"combined[0]['Fare'].unique()","5f45efd0":"combined[0]","7be4db35":"# Fill null values for Embarked and encode\nfor dataset in combined:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    dataset['Embarked'] = label.fit_transform(dataset['Embarked'])\n    ","f97064ed":"combined[0].Embarked.isnull().sum()","74f02813":"combined[0]['Fare'] = combined[0]['Fare'].fillna(0)","116ed5f3":"combined[0].isna().sum()","246d1519":"combined[0].SibSp.unique()","21917acb":"# For SibSp\nfor dataset in combined:\n    dataset['Alone'] = 0\n    dataset.loc[dataset['SibSp'] == 0, 'Alone'] = 1\n    dataset.loc[dataset['SibSp'] != 0, 'Alone'] = 0\n    \ncombined[0].head()","6ff630d2":"combined[0].Alone.value_counts()","387f7b2c":"combined[1]","f368d379":"# Drop SibSb column\ncombined[0]","35cf7cb6":"combined[0] = combined[0].drop(['SibSp'], axis = 1)\ncombined[1] = combined[1].drop(['SibSp'], axis = 1)","98fc493b":"# Test, train data split\ntrain = combined[0]\ntest = combined[1]","5a981ae8":"train.to_csv('train_data', index = False)","982caa05":"test.to_csv('test_data', index = False)","b56d3423":"train.isna().sum()","e31d1028":"# import data\ntrain.isna().sum()","557acd3e":"# Split features and labels\n# X_train : Feature\nX_train = train.drop('Survived', axis = 1)\n\n# Y_train: Label (Survived)\nY_train = train['Survived']\n\n# X_test\nX_test = test.drop('PassengerId', axis = 1).copy()\n\nX_train.shape, Y_train.shape, X_test.shape","82af1d59":"X_test","342cfa8b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","1c536d73":"logreg = LogisticRegression()\n# Model traning with train data\nlogreg.fit(X_train, Y_train)\n\n# Predicting with test data\nY_pred = logreg.predict(X_test)","b16f91ba":"Y_pred","28fb1bb3":"acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","a85d5eb1":"# correlation\ncorr_df = pd.DataFrame(train.columns.delete(0))\ncorr_df.columns = ['Feature']\ncorr_df['Correlation'] = pd.Series(logreg.coef_[0])\n\ncorr_df.sort_values(by = 'Correlation', ascending = False)","162bb9a9":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","850cf384":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","3b2d0a8a":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","09564be9":"gender_submission","f29bfad1":"submission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': Y_pred\n})","3d049667":"submission","0f76b414":"submission.to_csv('submission.csv', index = False)","95063e9e":"## 4. Submission","cdf3fbe5":"**Insight:**\n- Bigger absolute value means higher correlation\n- Positive coefficient: \n- Negative coefficient: ","7faa8ae8":"**Insights on 'Fare' and 'Embarked**:\n- Higher fare paying passenger has a higher survival rate\n- Embarked Q has the highest survival rate\n","fc19987a":"## 3. Data Modelling\n- Logistic Regression","1c1cc101":"### 2. Encode categorical data\n- Encoding: Converting categorical data into ordinal values\n- This is because machine learning models cannot interpret string values!\n- `Name`, `Sex`, `Embarked`","a93f1f02":"**Insights for Age column:**\n- Age column to be added to modelling\n- Age range 0-10 has the highest survival rate\n- Age less, survival rate gets bigger","6d1a8440":"### Visualization\n- Use graphs to visualize Age, Parch, Sibsp and Fare feature's importance","4722daed":"### 3. Numercial continuous columns\n- Filling null values\n- Banding\n- `Age`, `Fare`","d9af903c":"**Insight:**\n- Higher Pclass -> Higher age\n- Men tend to be younger than women\n- Smaller Pclass num -> Bigger age \n- Higher Sex num -> less age","4c4251cd":"`Age` encoded successsfully\\\nMale: 1, Female: 0","f89bc07c":"### Pivoting features:\n- Look for meaningful features that may affect the survival of a passenger","be6cb75e":"### 1. Drop unnecessary features","cc904d0d":"### Review dataset","4828aca5":"### Final Hypothesis:\n\n**Numerical Variable (1, 2, 3)**\n- Age: Younger passengers are more likely to survive\n- PClass: Passengers on higher class are more likely to survive\n- SibSp: to be determined\n\n**Continuous Variable**\n- Fare: Passengers paying higher fare has a higher survival rate\n- Sex: Female are more likley to survive than Male\n- Embarked: Embarked on C port had the highest survival rate","e05b0f71":"## 1. Explore Data","a4b1ad1d":"**Hypothesis for numerical(categorical) & continuous variables**:\n- Pclass, Sex becomes important factors in predicting the survival of a passenger\n- SibSp: not yet sure but to be kept\n- Age, Fare(continous variables): To be explored more","7ff9f7db":"## 2. Data Process\n- Feature engineering\n- Fill Null values in an **efficient way**\n- For both the train and test data\n- Purpose: Maximizing accuracy for modelling","c92369ba":"**Insights:**\n\nNull values to be filled\n- Age, Cabin, Embarked\n\nDatatypes to be casted\n- Age: float -> int"}}