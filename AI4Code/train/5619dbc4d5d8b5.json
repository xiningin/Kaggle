{"cell_type":{"06219a33":"code","28508fc0":"code","42847f38":"code","0f80cf9b":"code","bc8d75c1":"code","10106fea":"code","5f9e55c4":"code","bba01bf8":"code","b95a4876":"code","0e5ecf5a":"code","09bc3399":"code","9908c92c":"code","4b2c5365":"code","7ed3858c":"code","4ce809cc":"code","dbf9a93c":"code","71bc153a":"code","2cb1e4ee":"code","aa864d4b":"code","e240e416":"code","679dc010":"code","6e30bc30":"code","acad4dc4":"markdown"},"source":{"06219a33":"import pandas as pd\nimport seaborn as sns\nimport plotly.express as xp\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime\nimport missingno\nimport yaml\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV,ShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import RidgeClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","28508fc0":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which present only in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique ganres values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimentionality of the dataset\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    return embedded","42847f38":"PATH = \"..\/input\/mymusicalprefrences\/\" \n# PATH = \"dataset\/\"\ntrain = pd.read_csv(f\"{PATH}train.csv\")\ntest = pd.read_csv(f\"{PATH}test.csv\")\ndf = pd.concat([train, test]).reset_index(drop=True)\ntr_mask = ~df.Category.isna()\ntr_mask","0f80cf9b":"df.columns = [i.strip() for i in df.columns]\nprint(set(df.columns))","bc8d75c1":"df.describe()","10106fea":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})\ndf","5f9e55c4":"# We correct strings and replace some ambivalent values\ndf[\"isMajor\"], df[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[1]), df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\ndf.loc[:,\"isMajor\"] = (df[\"isMajor\"]==\"Major\").astype(int)\ndf","bba01bf8":"df[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)\ndf","b95a4876":"df.loc[:,\"Release_decade\"] = (df.loc[:,\"Release_year\"]\/\/10 * 10)\ndf.loc[df.loc[:,\"Release_decade\"]<1980,\"Release_decade\"] = 1980 \ndf = df.drop(\"Release_year\", axis=1)\ndf","0e5ecf5a":"ganres_onehot = split_to_onehot(df, \"Artists_Genres\")\ngenres_embedded = onehot_to_tsne2(ganres_onehot, \"Genres\")\ndf = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"Artists_Genres\", axis=1)\ndf","09bc3399":"df[\"BPM\"] = df[\"BPM\"].apply(lambda x: str(x)[1:] if str(x)[0]=='`' else x)\ndf[['Energy', 'Happiness', 'Dancebility','BPM']] = df[['Energy', 'Happiness', 'Dancebility','BPM']].fillna(0)\ndf[['Energy%', 'Happiness%', 'Dancebility%']] = df[['Energy', 'Happiness', 'Dancebility']].apply(lambda x: x\/sum(x), axis=1)\ndf[['Energy%', 'Happiness%', 'Dancebility%']] = df[['Energy%', 'Happiness%', 'Dancebility%']].fillna(0)\ndf","9908c92c":"df.Labels = df.Labels.fillna('NA')\nlabels_onehot = split_to_onehot(df, \"Labels\")\nlabels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\ndf = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)\ndf","4b2c5365":"df.Artists = df.Artists.fillna(\"NA\")\nallstars = []\nfor i in df.index:\n    allstars.extend(df.loc[i, \"Artists\"].split(\"|\"))\n\nthreshold = 3\nothers = Counter(allstars)\nothers = [k for k in others if others[k]<=threshold]\n\nin_train, in_test = [], []\nfor i in df.loc[tr_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~tr_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\n\nallstars = list(set(allstars) - set(others) - only_test - only_train)\nothers = set(others) | only_test | only_train\n\nres = []\ndef prune(x):\n    vector = np.zeros(len(allstars)+1) #for others\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(allstars)):\n        vector[i]=1 if allstars[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    res.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(res, columns = allstars+[\"Others\"], index=df.index)\n\ndf[\"Other_Artists\"] = onehot_artists[\"Others\"]\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\nonehot_artists[\"Category\"] = df[\"Category\"]\nartists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\ndf = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)\ndf = df.drop(\"Artists\", axis=1)\ndf","7ed3858c":"artists_encoder = LabelEncoder()\ndf[\"Track\"] = artists_encoder.fit_transform(df[\"Track\"])\ndf","4ce809cc":"df[\"Version\"] = df[\"Version\"].fillna(\"NA\")\nversions= set(df[\"Version\"])\nOneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf = df.drop(\"Version\", axis=1)\ndf = df.drop(\"NA\", axis=1)\ndf","dbf9a93c":"df[\"Album_type\"] = df[\"Album_type\"].fillna(\"NA\")\nalbumTypes = set(df[\"Album_type\"])\ndf[list(albumTypes)] = OneHotEncoder().fit_transform(df[[\"Album_type\"]]).toarray()\ndf = df.drop(\"Album_type\", axis=1)\ndf = df.drop(\"NA\", axis=1)\ndf","71bc153a":"df[\"Album\"] = df[\"Album\"].fillna(\"NA\")\nganres_onehot = split_to_onehot(df, \"Album\")\nalbum_embedded = onehot_to_tsne2(onehot_artists, \"Album\")\ndf = pd.concat([df,album_embedded[[\"Album_tsne1\",\"Album_tsne2\"]]], axis=1)\ndf = df.drop(\"Album\", axis=1)\ndf","2cb1e4ee":"df[\"Vocal\"] = df[\"Vocal\"].fillna('N')\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    v = df.iloc[i][\"Vocal\"]\n    if v == 'F':\n        onehot[i] = [1,0]\n    elif v == 'M':\n        onehot[i] = [0,1]\n    elif v == 'F|M':\n        onehot[i] = [1,1]\ndf[[\"Fem_voc\",\"Mal_voc\"]] = onehot\ndf = df.drop(\"Vocal\",axis=1)\ndf","aa864d4b":"df[\"Country\"] = df[\"Country\"].fillna(\"NA\")\ncountry_onehot = split_to_onehot(df, \"Country\")\ncountry_onehot = country_onehot.drop(\"Category\", axis=1)\ndf = pd.concat([df,country_onehot], axis=1)\ndf = df.drop(\"Country\", axis=1)\ndf","e240e416":"x, y = df.loc[tr_mask].iloc[:,2:], df.loc[tr_mask,\"Category\"]\n\nx = x.drop([661])\ny = y.drop([661])\nx = x.reset_index(drop=True)\ny = y.reset_index(drop=True)\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state = 1)\n\nprint(\"The size of X_train is\",x_train.shape)\nprint(\"The size of X_test is\",x_test.shape)\nprint(\"The size of Y_train is\",y_train.shape)\nprint(\"The size of Y_test is\",y_test.shape)\n\nscaler = MinMaxScaler()\nscaler.fit(x_train)\n\nx_train = pd.DataFrame(data=scaler.transform(x_train),columns = x_train.columns,index=x_train.index)\nx_test = pd.DataFrame(data=scaler.transform(x_test),columns = x_test.columns,index=x_test.index)\n\nhighestModel = None\nhighestModelName = None\nhighestScore = 0\n\n\nmodel = RandomForestClassifier(random_state = 1)\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('Random forest: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"Random forest\"\n    highestScore = accuracy\n\nmodel = DecisionTreeClassifier(random_state = 1)\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('Decision Tree: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"Decision Tree\"\n    highestScore = accuracy\n\n\nmodel = KNeighborsClassifier()\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('KNeighbors: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"KNeighbors\"\n    highestScore = accuracy\n\n\nmodel = AdaBoostClassifier(random_state = 1)\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('AdaBoost: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"AdaBoost\"\n    highestScore = accuracy\n\nmodel = GradientBoostingClassifier(random_state = 1)\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('GradientBoosting: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"GradientBoosting\"\n    highestScore = accuracy\n\nmodel = XGBClassifier(random_state = 1)\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('XGBBoosting: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"XGBBoosting\"\n    highestScore = accuracy\n\n\nmodel = CatBoostClassifier()\nmodel.fit(x_train,y_train)\npredictions = model.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint('CatBoosting: ', accuracy)\nif accuracy > highestScore:\n    highestModel = model\n    highestModelName = \"CatBoosting\"\n    highestScore = accuracy","679dc010":"print(\"Highest Model is \",highestModelName)\nprint(\"Score is \",highestScore)\n\nhighestModel = highestModel.fit(x, y)\ndeploy = df.loc[~tr_mask].iloc[:,2:]\nsample = pd.read_csv(f\"{PATH}sample_submition.csv\")\nsample[\"Category\"] = highestModel.predict(deploy)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)","6e30bc30":"sample.to_csv(\"submission.csv\", index=False)","acad4dc4":"# "}}