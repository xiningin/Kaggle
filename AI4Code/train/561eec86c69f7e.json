{"cell_type":{"74331017":"code","233eff94":"code","de1dd09a":"code","9ef3b4bb":"code","7a182229":"code","07497db7":"code","3357ee7f":"code","31b0e4ce":"code","3eb5ff75":"code","435c4233":"code","8d51e8bc":"code","a252fa94":"code","a134b1d2":"code","d799acf0":"code","7cd80d0c":"code","7bec3b96":"code","c5bbb116":"code","0238454e":"code","6b685350":"code","989c0ec9":"code","2d582996":"code","317b681c":"code","d1083ceb":"code","857c1bcd":"code","79cbf4b9":"code","44d6f4d8":"code","4c658041":"code","bdc18fae":"code","ff9f3683":"code","8dcd52f5":"code","314c955b":"code","0ba37dbf":"code","f12756c5":"code","86482fe8":"code","7e15c9ec":"code","73c391cf":"code","0b503c08":"code","3c634238":"code","338c787b":"code","9164bcd3":"code","28882292":"code","4af34d66":"code","9eaa6e51":"code","9df63afa":"code","2e42beee":"code","0a266e6a":"code","33acdd9a":"markdown","dfb61957":"markdown","3641f2db":"markdown","32673c10":"markdown","241da2b7":"markdown","17b5a80f":"markdown","85e51246":"markdown","b146db5b":"markdown","9aa3e28b":"markdown","c7acf5a5":"markdown"},"source":{"74331017":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","233eff94":"training_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")","de1dd09a":"training_data.head()","9ef3b4bb":"print('Number of passengers in the training dataset : ' + str(len(training_data)))","7a182229":"import matplotlib.pyplot as plt\nimport seaborn as sns","07497db7":"plt.figure(figsize=(10,5))\nsns.set_theme(style=\"darkgrid\")\nsns.countplot(x='Survived', data = training_data)\nplt.xlabel('Survived (0 means not survived and 1 means survived)', fontsize=20)\nplt.ylabel('Count', fontsize=20)\n\nplt.title('Graph showing Number of passengers vs Survived', fontsize = 20)","3357ee7f":"plt.figure(figsize=(10,5))\nsns.countplot(x= 'Survived', hue = 'Sex', data = training_data)\nplt.xlabel('Survived', fontsize=20)\nplt.ylabel('Count', fontsize=20)\nplt.title('Graph showing Survival based on sex', fontsize = 20)","31b0e4ce":"plt.figure(figsize=(10,5))\nsns.countplot(x= 'Survived', hue = 'Pclass', data = training_data)\nplt.xlabel('Survived', fontsize=20)\nplt.ylabel('Count', fontsize=20)\nplt.title('Graph showing Survival based on Passenger class', fontsize = 20)","3eb5ff75":"plt.figure(figsize=(10,5))\nsns.histplot(data = training_data.Age, color = 'seagreen')\nplt.xlabel('Age', fontsize=20)\nplt.ylabel('Count', fontsize=20)\nplt.title('Distribution of Age in the training dataset', fontsize = 20)","435c4233":"plt.figure(figsize=(10,5))\nsns.countplot(x= 'SibSp', data = training_data)\nplt.xlabel('Number of siblings \/ spouses aboard the Titanic', fontsize=20)\nplt.ylabel('Count', fontsize=20)\nplt.title('Graph showing siblings or spouses vs count distribution', fontsize = 20)","8d51e8bc":"plt.figure(figsize=(10,5))\nsns.countplot(x= 'Parch', data = training_data)\nplt.xlabel('Number of parents \/ children aboard the Titanic', fontsize=20)\nplt.ylabel('Count', fontsize=20)\nplt.title('Graph showing distribution of parents or children vs count', fontsize = 20)","a252fa94":"plt.figure(figsize=(10,5))\nsns.boxplot(x = 'Pclass', y = 'Age', data = training_data)\nplt.xlabel('Pclass', fontsize=20)\nplt.ylabel('Age', fontsize=20)","a134b1d2":"training_data.columns","d799acf0":"plt.figure(figsize=(10,5))\nsns.heatmap(training_data.isnull(), yticklabels = False)","7cd80d0c":"training_data.isnull().sum()","7bec3b96":"training_data.drop('Cabin', axis = 1, inplace = True)","c5bbb116":"training_data.dropna(inplace = True)","0238454e":"plt.figure(figsize=(10,5))\nsns.heatmap(training_data.isnull(), yticklabels = False, cbar = False)","6b685350":"training_data.head()","989c0ec9":"pclass = pd.get_dummies(training_data.Pclass, drop_first = True)","2d582996":"sex = pd.get_dummies(training_data.Sex, drop_first = True)","317b681c":"embark = pd.get_dummies(training_data.Embarked, drop_first = True)","d1083ceb":"training_data = pd.concat([training_data, pclass, sex, embark], axis = 1)\ntraining_data.head()","857c1bcd":"training_data.drop(['PassengerId', 'Pclass', 'Sex', 'Name', 'Ticket', 'Embarked'], axis = 1, inplace = True)","79cbf4b9":"training_data.head()","44d6f4d8":"from sklearn import preprocessing","4c658041":"min_max_scaler = preprocessing.MinMaxScaler()\ntraining_data['Age']= min_max_scaler.fit_transform(training_data[['Age']])","bdc18fae":"training_data['Fare']= min_max_scaler.fit_transform(training_data[['Fare']])","ff9f3683":"X_train = training_data.drop('Survived', axis = 1)\ny_train = training_data.Survived","8dcd52f5":"X_train.head()","314c955b":"test_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_data1 = test_data","0ba37dbf":"test_data.head()","f12756c5":"test_data.drop('Cabin', axis = 1, inplace = True)","86482fe8":"test_data.Age = test_data.Age.fillna(test_data.Age.mean())\ntest_data.Fare = test_data.Fare.fillna(test_data.Fare.mean())\n","7e15c9ec":"test_data.isnull().sum()","73c391cf":"pclass1 = pd.get_dummies(test_data.Pclass, drop_first = True)\nsex1 = pd.get_dummies(test_data.Sex, drop_first = True)\nembark1 = pd.get_dummies(test_data.Embarked, drop_first = True)","0b503c08":"test_data = pd.concat([test_data, pclass1, sex1, embark1], axis = 1)\ntest_data.head()","3c634238":"\ntest_data.drop(['PassengerId', 'Pclass', 'Sex', 'Name', 'Ticket', 'Embarked'], axis = 1, inplace = True)","338c787b":"test_data1.head()","9164bcd3":"test_data['Age']= min_max_scaler.fit_transform(test_data[['Age']])\ntest_data['Fare']= min_max_scaler.fit_transform(test_data[['Fare']])","28882292":"X_test = test_data","4af34d66":"from sklearn.linear_model import LogisticRegression","9eaa6e51":"model = LogisticRegression(solver='liblinear')","9df63afa":"model.fit(X_train, y_train)","2e42beee":"predictions = model.predict(X_test)","0a266e6a":"output = pd.DataFrame({'PassengerId': test_data1.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","33acdd9a":"Importing the dataset into our notebook.","dfb61957":"Removing the cabin column from our testing dataset.","3641f2db":"# Performing Exploratory Data Analysis on the dataset.","32673c10":"We can see that our dataset has a lot of string values which needs to be converted into categorical values so that we can build our prediction model. Whenever we apply machine learing, we need to make sure that our dataset does not have any string values.","241da2b7":"## Building our Logistic Regression model.","17b5a80f":"Importing our testing dataset","85e51246":"Now we do not need columns such as Pclass, Sex and Embarked so, we will remove these columns from our dataset.","b146db5b":"## Let's perform data munging otherwise known as data wrangling on our dataset","9aa3e28b":"We can see that some columns have null values in them. We need to clean our dataset in order for us to perform further analysis.\nWe do not need the Cabin column for our analysis so, we will drop it from our dataset.","c7acf5a5":"Converting our string values into categorical data."}}