{"cell_type":{"93b029c9":"code","7edfe3e6":"code","2bfda7d2":"code","6c03eb11":"code","d916192f":"code","8f4ea6c3":"code","8f6a8b18":"code","05dc356f":"code","48445f3d":"code","28729433":"code","c6311985":"code","49f1776c":"code","c76fea6f":"code","cb2d74c0":"code","f465a549":"code","4f894a98":"code","395a2048":"code","25b640f1":"code","53d9df12":"code","506a1ceb":"code","13f0d036":"code","33084aa8":"code","6b4517b2":"code","3d179598":"code","e5dcc10f":"code","044d319f":"code","30541021":"code","f5ad83da":"code","4d472472":"code","f7bbcc9c":"code","284a56a8":"code","e90aae84":"code","168789a5":"code","119848fd":"code","50f400db":"code","4973e669":"code","c2ab2aed":"code","1d0d2c21":"code","69ba6e89":"code","10e00563":"code","79fad191":"code","e0b1dda7":"code","e1399bd5":"code","7c553357":"code","fef855b0":"code","354211e1":"code","ed5643e4":"code","97562dd8":"code","f49aa5de":"code","13ccef1d":"code","ca775acd":"markdown","70c8928b":"markdown","311ad093":"markdown","822bd3ab":"markdown","cb543b70":"markdown"},"source":{"93b029c9":"!pip install fastai==0.7.0","7edfe3e6":"#It will automatically reload the latest module when you start again\n%load_ext autoreload\n%autoreload 2\n#Used to display plots and graphs inside Jupyter\n%matplotlib inline\n#The following are fastAi imports\nfrom fastai.imports import * \nfrom fastai.structured import *\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor\nfrom IPython.display import display\n\nfrom sklearn import metrics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2bfda7d2":"PATH = \"..\/input\/\"","6c03eb11":"!ls {PATH}","d916192f":"df_raw = pd.read_csv(PATH+ 'train.csv', low_memory = False ,parse_dates=['YrSold'])","8f4ea6c3":"df_raw","8f6a8b18":"#function to display all the data of the dataframe at one go\ndef display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000):\n        with pd.option_context(\"display.max_columns\", 1000):\n            display(df)","05dc356f":"df_raw.SalePrice  = np.log(df_raw.SalePrice)","48445f3d":"df_raw.YrSold.head(5)","28729433":"def add_datepart(df, fldname, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date.\"\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) \/\/ 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)","c6311985":"add_datepart(df_raw, 'YrSold')","49f1776c":"df_raw.YrSoldYear.head(5)","c76fea6f":"train_cats(df_raw) #behind scenes everything will be converted into numbers","cb2d74c0":"display_all(df_raw.isnull().sum().sort_index()\/len(df_raw))","f465a549":"df, y, nas = proc_df(df_raw, 'SalePrice')","4f894a98":"df.columns","395a2048":"df.drop(columns=['Id'],inplace=True)","25b640f1":"m = RandomForestRegressor(n_jobs=-1) #njobs = -1 use all the resouces for running our model\nm.fit(df, y)\nm.score(df, y)","53d9df12":"def split_vals(a,n) : return a[:n].copy(), a[n:].copy()\n","506a1ceb":"n_valid = 200 #same as kaggle's test size\nn_trn = len(df) - n_valid\nraw_train, raw_valid = split_vals(df, n_trn)\nx_train, x_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\nx_train.shape, y_train.shape, x_valid.shape\n","13f0d036":"#the following code will print the score\ndef rmse(x, y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(x_train), y_train), rmse(m.predict(x_valid), y_valid), m.score(x_train, y_train), m.score(x_valid, y_valid)]\n    if hasattr(m ,'obb_score_'): res.append(m.obb_score_)\n    print(res)","33084aa8":"m = RandomForestRegressor(n_jobs=-1)\n%time m.fit(x_train,y_train)\nprint_score(m)","6b4517b2":"fi = rf_feat_importance(m, df)\nfi[:10]","3d179598":"fi.plot('cols', 'imp', figsize = (10,6), legend = False)","e5dcc10f":"def plot_fi(fi) : return fi.plot('cols', 'imp', 'barh', figsize = (12,7), legend=False)","044d319f":"plot_fi(fi[:30])","30541021":"to_keep = fi[fi.imp > 0.005].cols\nlen(to_keep)","f5ad83da":"df_keep = df[to_keep].copy()\nx_train, x_valid = split_vals(df_keep, n_trn)","4d472472":"m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(x_train, y_train)\nprint_score(m)","f7bbcc9c":"fi = rf_feat_importance(m, df_keep)\nplot_fi(fi)","284a56a8":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.scatter(df_raw['OverallQual'], df_raw['SalePrice'])\nplt.ylabel('SalePrice')\nplt.xlabel('YearMade')","e90aae84":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.scatter(df_raw['GrLivArea'], df_raw['SalePrice'])\nplt.ylabel('SalePrice')\nplt.xlabel('YearMade')","168789a5":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.scatter(df_raw['YearBuilt'], df_raw['SalePrice'])\nplt.ylabel('SalePrice')\nplt.xlabel('YearBuilt')","119848fd":"from scipy.cluster import hierarchy as hc\ncorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nplt.figure(figsize=(15,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size = 16)\nplt.show()","50f400db":"cols = df_keep.columns","4973e669":"m = RandomForestRegressor(n_estimators=100, min_samples_leaf=3, max_features=0.5, n_jobs=-1)\nm.fit(x_train, y_train)\nprint_score(m)","c2ab2aed":"test = pd.read_csv(PATH + 'test.csv'  ,low_memory = False ,parse_dates=['YrSold'])","1d0d2c21":"test.head(5)","69ba6e89":"test.drop(columns=['Id'], inplace=True)","10e00563":"add_datepart(test, 'YrSold')","79fad191":"apply_cats(df=test, trn=df_raw)","e0b1dda7":"test.info()","e1399bd5":"X_test, _, nas = proc_df(test, na_dict=nas)\nnas","7c553357":"#these are the extra columns made by proc_df as they are unique only to test set, so we will drop it, i manually check them\nX_test.drop(columns=['BsmtFinSF1_na', 'BsmtFinSF2_na', 'BsmtUnfSF_na', 'TotalBsmtSF_na', 'BsmtFullBath_na', 'BsmtHalfBath_na', 'GarageCars_na', 'GarageArea_na'], inplace=True)","fef855b0":"x_test = X_test[cols]","354211e1":"x_test.columns","ed5643e4":"ypreds = m.predict(x_test)","97562dd8":"ypreds","f49aa5de":"submit = pd.read_csv(PATH + \"sample_submission.csv\")\nsubmit['SalePrice'] = ypreds*10000","13ccef1d":"submit.to_csv(\"submission.csv\", index = False)","ca775acd":"## Prediction\nNow for this basic model, let's load the test dataset and try out predictions","70c8928b":"## Loading the Data","311ad093":"## Let's start creating basic model's \nand slowly move towards complex models","822bd3ab":"End\nSo this is the basic notebook which explore the first part of FastAI's machine learning course, we used here RandomForest as our model and trained the model on preprocessed data.\n\nUpvote the kernel if you find it useful\n\nConnect on Linkedin - https:\/\/www.linkedin.com\/in\/savannahar\/","cb543b70":"## Preprocessing"}}