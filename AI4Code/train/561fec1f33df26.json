{"cell_type":{"e977e67b":"code","3febd821":"code","31732ea9":"code","aa396828":"code","0da16220":"code","878f71f1":"code","33d65770":"code","166203db":"code","49e7ad30":"code","311b0a66":"code","178d2d74":"code","a4454050":"code","273b6546":"markdown","331108de":"markdown","b4401dd2":"markdown","d51e00e1":"markdown","14eba434":"markdown","238fc806":"markdown","6ea11d92":"markdown","5cc0de0a":"markdown","3db10244":"markdown","775baf17":"markdown"},"source":{"e977e67b":"import os\nimport cv2\nimport time\nimport numpy\nimport pandas\nfrom PIL import Image\nfrom numba import cuda\nfrom pandas import DataFrame\nfrom typing import List, Tuple\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adamax\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.applications import ResNet50V2, ResNet152V2, ResNet50, MobileNetV2","3febd821":"root_dir = \"\/kaggle\/input\/news-and-commercial-detection\"\nvalidation_dir = \"{}\/validation_512x512\".format(root_dir)\ntrain_dir = \"{}\/train_512x512\".format(root_dir)\nvalidation_images = \"{}\/images\".format(validation_dir)\nvalidation_csv = pandas.read_csv(\"{}\/validation.csv\".format(validation_dir))\ntrain_images = \"{}\/images\".format(train_dir)\ntrain_csv = pandas.read_csv(\"{}\/train.csv\".format(train_dir))\n\n\nCLASSES = [\n    \"Commercial\", \"Broadcast\"\n]","31732ea9":"class ImageDataGenerator:\n\n    batch_size: int\n    csv: DataFrame\n    length: int\n    input_shape: Tuple[int, int, int]\n    images_dir: str\n    current_batch: DataFrame\n\n    def __init__(\n            self,\n            images_dir: str,\n            root_csv: DataFrame,\n            data_start: int,\n            data_end: int,\n            batch_size: int,\n            input_shape: Tuple[int, int, int]\n    ):\n        self.images_dir = images_dir\n        self.batch_size = batch_size\n        self.input_shape = input_shape\n        self.csv = root_csv.iloc[data_start:data_end]\n        self.csv = self.csv[self.csv.Class != \"cbsn\"]\n        self.csv = self.csv[self.csv.Class != \"commercials\/cbsn\"]\n        self.csv = self.csv[self.csv.Class != \"the_weather_channel\"]\n        self.csv = self.csv[self.csv.Class != \"commercials\/the_weather_channel\"]\n        self.csv = self.csv.sample(frac=1)\n        self.length = len(self.csv)\n        self.current_batch = None\n        print(\"[ImageDataGenerator]: Found {} images\".format(self.length))\n\n    def generate(self):\n        batch_start = 0\n        batch_end = self.batch_size\n        csv = self.csv\n        while True:\n            batch = csv.iloc[batch_start:batch_end]\n            self.current_batch = batch\n            x = []\n            y = []\n            for i in range(0, len(batch)):\n                row = batch.iloc[i]\n                img_name = row[\"Image\"]\n                img_class = row[\"Class\"]\n                img_path = \"{}\/{}\/{}\".format(self.images_dir, img_class, img_name)\n                img = Image.open(img_path)\n                img.resize(self.input_shape[0:2])\n                img = numpy.array(img)\n                label = [1.0, 0.0] if \"commercials\" in img_class else [0.0, 1.0]\n                label = numpy.array(label)\n                x.append(img)\n                y.append(label)\n            yield numpy.array(x), numpy.array(y)\n            batch_start += self.batch_size\n            batch_end += self.batch_size\n            if batch_end > len(self.csv) and batch_start >= len(self.csv):\n                batch_start = 0\n                batch_end = self.batch_size\n            elif batch_end >= len(self.csv):\n                batch_end = len(self.csv) - 1 ","aa396828":"def plot_metrics(history):\n    try:\n        if history is not None:\n            fig, axes = plt.subplots(1, 2, figsize=(30, 10))\n            axes[0].plot(history.history[\"accuracy\"])\n            axes[0].set_title('Model Accuracy')\n            axes[0].set_ylabel('Accuracy')\n            axes[0].set_xlabel('Epoch')\n            axes[1].plot(history.history[\"loss\"])\n            axes[1].set_title('Model Loss')\n            axes[1].set_ylabel('Loss')\n            axes[1].set_xlabel('Epoch')\n            plt.show()\n    except Exception as e:\n        pass\n\ndef plot_validation_example(model: Sequential, input_shape: Tuple[int, int, int]):\n    rows = 6\n    columns = 4\n    fig, axes = plt.subplots(rows, columns, figsize=(25,25))\n#     fig.set_size_inches(25, 25)\n    index = 0\n    csv = validation_csv.sample(frac=1)\n    for r in range(0, rows):\n        for c in range(0, columns):\n            row = csv.iloc[index]\n            img_name = row[\"Image\"]\n            img_class = row[\"Class\"]\n            img_path = \"{}\/{}\/{}\".format(validation_images, img_class, img_name)\n            img = Image.open(img_path)\n            axes[r, c].imshow(img)\n            img = img.resize(input_shape[0:2])\n            img = numpy.array(img)\n            probabilities = model.predict(img.reshape((1,) + input_shape))[0]\n            y = CLASSES[0 if img_class == \"commercials\" else 1]\n            prediction = CLASSES[numpy.argmax(probabilities)]\n            # axes[r, c].imshow(img)\n            axes[r, c].set_xlabel(\"Prediction: {}, Answer: {}\".format(prediction, y))\n            index += 1\n    plt.show()","0da16220":"def train(\n        data_start: int,\n        data_end: int,\n        batch_size: int,\n        epochs: int,\n        model: Sequential,\n        input_shape: Tuple[int, int, int]):\n    start_time = time.time()\n    datagen = ImageDataGenerator(\n        train_images,\n        train_csv,\n        data_start,\n        data_end,\n        batch_size,\n        input_shape\n    )\n    steps_per_epoch = int(numpy.ceil(datagen.length \/ batch_size)) - 1\n    history = model.fit(\n        datagen.generate(),\n        epochs=epochs,\n        steps_per_epoch=steps_per_epoch,\n        batch_size=batch_size\n    )\n    elapsed = time.time() - start_time\n    model.save(\"{}.keras\".format(model.name))\n    if \"accuracy\" in history.history:\n        avg_accuracy = numpy.average(history.history[\"accuracy\"])\n        avg_loss = numpy.average(history.history[\"loss\"])\n        print(\n            \"\\n\\nCompleted {} epoch in {} seconds with:\".format(epochs, elapsed)\n        )\n        print(\n            \"\\tAvg. Accuracy: {}%\\n\\tAvg. Loss: {}\".format(avg_accuracy, avg_loss)\n        )\n    else:\n        print(\"\\n\\nCompleted {} epoch(s) in {} seconds:\".format(epochs, elapsed))\n        for key in history.history:\n            if \"accuracy\" in key or \"loss\" in key:\n                print(\"   {}: {}%\".format(key, numpy.average(history.history[key])))\n        print(\"\\n___________________________________________\")\n    return history","878f71f1":"def validate(\n        data_start: int,\n        data_end: int,\n        batch_size: int,\n        input_shape: Tuple[int, int, int],\n        model: Sequential\n):\n    csv = validation_csv[validation_csv.Class != \"cbsn\"]\n    csv = csv[csv.Class != \"commercials\/cbsn\"]\n    csv = csv[csv.Class != \"the_weather_channel\"]\n    csv = csv[csv.Class != \"commercials\/the_weather_channel\"]\n    datagen = ImageDataGenerator(\n        validation_images,\n        csv,\n        data_start,\n        data_end,\n        batch_size,\n        input_shape\n    )\n    data_set = datagen.generate()\n    batches = int(numpy.ceil(datagen.length \/ batch_size)) - 1\n    total = 0\n    correct = 0\n    incorrect_predictions = []\n    for k in range(0, batches):\n        batch_x, batch_y = data_set.__next__()\n        for i in range(0, len(batch_x)):\n            row = datagen.current_batch.iloc[i]\n            x = batch_x[i].reshape((1,) + input_shape)\n            y = CLASSES[numpy.argmax(batch_y[i])]\n            probabilities = model.predict(x)[0]\n            prediction = CLASSES[numpy.argmax(probabilities)]\n            if prediction == y:\n                correct += 1\n            else:\n                incorrect_predictions.append([row[\"Image\"], row[\"Class\"], y, prediction])\n            if total % 1000 == 0:\n                print(\n                    \"[{}\/{}]: A: {}, P: {}\".format(\n                        total, batches * batch_size, y, prediction\n                    )\n                )\n            total += 1\n    avg_acc = correct \/ total\n    print(\n        \"\\nCorrectly predicted {}\/{} with:\\n\\tAvg. Accuracy: {}\".format(\n            correct, total, avg_acc\n        )\n    )\n    print(\"\\n____________________________________________________\")\n    predictions_out = open(\"predictions.csv\", \"w\")\n    predictions_out.write(\"Image,Class,Answer,Prediction\")\n    for incorrect in incorrect_predictions:\n        predictions_out.write(\n            \"\\n{},{},{},{}\".format(\n                incorrect[0],\n                incorrect[1],\n                incorrect[2],\n                incorrect[3],\n            )\n        )\n    predictions_out.close()","33d65770":"def commercial_model3(input_shape) -> Sequential:\n    model = Sequential(name=\"commercial_model3\")\n    model.add(Conv2D(128, (3, 3), activation=\"relu\", input_shape=input_shape))\n    model.add(MaxPooling2D())\n    model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D())\n    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D())\n    model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D())\n    model.add(Flatten())\n    model.add(Dense(256, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation=\"softmax\"))\n    model.compile(optimizer=Adam(learning_rate=1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    model.build(input_shape=input_shape)\n    model.summary()\n    return model","166203db":"# input_shape = (720, 1280, 3)\ninput_shape = (512, 512, 3)\ndstart = 0\ndend = 45000\nbatch_size = 32\nmodel = commercial_model3(input_shape=input_shape)\n# model = load_model(\"\/kaggle\/input\/commercial-detection-models\/commercial_model3.keras\")\n\nhistory = train(\n    data_start=dstart,\n    data_end=dend,\n    batch_size=batch_size,\n    epochs=30,\n    model=model,\n    input_shape=input_shape\n)\n\n","49e7ad30":"validate(\n    data_start=0,\n    data_end=None,\n    batch_size=batch_size,\n    input_shape=input_shape,\n    model=model\n)","311b0a66":"plot_metrics(history)","178d2d74":"plot_validation_example(model, input_shape)","a4454050":"cuda.select_device(0)\ncuda.close()\ndel model\n#keras.backend.clear_session()","273b6546":"# Runtime","331108de":"## Results","b4401dd2":"# Imports","d51e00e1":"# Helpers","14eba434":"# Training","238fc806":"### Deallocate Memory","6ea11d92":"# Model","5cc0de0a":"# Data Generation","3db10244":"# Validation","775baf17":"### Globals"}}