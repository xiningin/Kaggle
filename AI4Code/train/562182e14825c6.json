{"cell_type":{"31dffd4a":"code","430d45a1":"code","2435eaf6":"code","1398687c":"code","1de23d19":"code","b7d0f106":"code","734f2f8a":"code","9667a144":"code","bd65b2aa":"code","f3035a77":"code","a5a286aa":"code","7b75384b":"code","2edb9be6":"code","eaf313b5":"code","84c1420e":"code","ab97c4b6":"code","617de30a":"code","441287ab":"markdown","7d4a0f43":"markdown","6aa1642f":"markdown","af1d68b0":"markdown","8a23aab9":"markdown","a92cf31f":"markdown"},"source":{"31dffd4a":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torchvision.transforms import functional as F\nimport random\nimport tensorflow as tf\n\nimport time\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold","430d45a1":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.set_random_seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nkaeru_seed = 1337\nseed_everything(seed=kaeru_seed)\n\nbatch_size = 32\ntrain_epochs = 6","2435eaf6":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntarget = train[\"Survived\"]\n\ntrain = pd.concat([train, test], sort=True)\n\nprint(train.shape)\n#train.head()","1398687c":"def get_text_features(train):\n    train['Length_Name'] = train['Name'].astype(str).map(len)\n    return train\n\ntrain = get_text_features(train)","1de23d19":"cat_cols = [\n     'Cabin','Embarked','Name','Sex','Ticket',\n]\n\nnum_cols = list(set(train.columns) - set(cat_cols) - set([\"Survived\"]))","b7d0f106":"def encode(encoder, x):\n    len_encoder = len(encoder)\n    try:\n        id = encoder[x]\n    except KeyError:\n        id = len_encoder\n    return id\n\nencoders = [{} for cat in cat_cols]\n\n\nfor i, cat in enumerate(cat_cols):\n    print('encoding %s ...' % cat, end=' ')\n    encoders[i] = {l: id for id, l in enumerate(train.loc[:, cat].astype(str).unique())}\n    train[cat] = train[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n    print('Done')\n\nembed_sizes = [len(encoder) for encoder in encoders]","734f2f8a":"from sklearn.preprocessing import StandardScaler\n \ntrain[num_cols] = train[num_cols].fillna(0)\nprint('scaling numerical columns')\n\nscaler = StandardScaler()\ntrain[num_cols] = scaler.fit_transform(train[num_cols])","9667a144":"class CustomLinear(nn.Module):\n    def __init__(self, in_features,\n                 out_features,\n                 bias=True, p=0.5):\n        super().__init__()\n        self.linear = nn.Linear(in_features,\n                               out_features,\n                               bias)\n        self.relu = nn.ReLU()\n        self.drop = nn.Dropout(p)\n        \n    def forward(self, x):\n        x = self.linear(x)\n        x = self.relu(x)\n        x = self.drop(x)\n        return x","bd65b2aa":"net = nn.Sequential(CustomLinear(12, 32),\n                    nn.Linear(32, 1))","f3035a77":"X_train = train.loc[np.isfinite(train.Survived), :]\nX_train = X_train.drop([\"Survived\"], axis=1).values\ny_train = target.values\n\nX_test = train.loc[~np.isfinite(train.Survived), :]\n\nX_test = X_test.drop([\"Survived\"], axis=1).values","a5a286aa":"splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=kaeru_seed).split(X_train, y_train))","7b75384b":"def sigmoid(x):\n    return 1 \/ (1 + np.exp(-x))","2edb9be6":"train_preds = np.zeros((len(X_train)))\ntest_preds = np.zeros((len(X_test)))\n\nseed_everything(kaeru_seed)\n\nx_test_cuda = torch.tensor(X_test, dtype=torch.float32).cuda()\ntest = torch.utils.data.TensorDataset(x_test_cuda)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)","eaf313b5":"for i, (train_idx, valid_idx) in enumerate(splits):\n    x_train_fold = torch.tensor(X_train[train_idx], dtype=torch.float32).cuda()\n    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n    x_val_fold = torch.tensor(X_train[valid_idx], dtype=torch.float32).cuda()\n    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n    \n    model = net\n    model.cuda()\n    \n    loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"sum\")\n    optimizer = torch.optim.Adam(model.parameters())\n    \n    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n    \n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n    \n    print(f'Fold {i + 1}')\n    \n    for epoch in range(train_epochs):\n        start_time = time.time()\n        \n        model.train()\n        avg_loss = 0.\n        for x_batch, y_batch in tqdm(train_loader, disable=True):\n            y_pred = model(x_batch)\n            loss = loss_fn(y_pred, y_batch)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            avg_loss += loss.item() \/ len(train_loader)\n        \n        model.eval()\n        valid_preds_fold = np.zeros((x_val_fold.size(0)))\n        test_preds_fold = np.zeros(len(X_test))\n        avg_val_loss = 0.\n        for i, (x_batch, y_batch) in enumerate(valid_loader):\n            y_pred = model(x_batch).detach()\n            avg_val_loss += loss_fn(y_pred, y_batch).item() \/ len(valid_loader)\n            valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n        \n        elapsed_time = time.time() - start_time \n        print('Epoch {}\/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n            epoch + 1, train_epochs, avg_loss, avg_val_loss, elapsed_time))\n        \n    for i, (x_batch,) in enumerate(test_loader):\n        y_pred = model(x_batch).detach()\n\n        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n\n    train_preds[valid_idx] = valid_preds_fold\n    test_preds += test_preds_fold \/ len(splits)","84c1420e":"from sklearn.metrics import accuracy_score\n\ndef threshold_search(y_true, y_proba):\n    best_threshold = 0\n    best_score = 0\n    for threshold in tqdm([i * 0.01 for i in range(100)]):\n        score = accuracy_score(y_true=y_true, y_pred=y_proba > threshold)\n        if score > best_score:\n            best_threshold = threshold\n            best_score = score\n    search_result = {'threshold': best_threshold, 'accuracy_score': best_score}\n    return search_result","ab97c4b6":"search_result = threshold_search(y_train, train_preds)\nsearch_result","617de30a":"sub = pd.read_csv('..\/input\/gender_submission.csv')\nsub.Survived = (test_preds > search_result['threshold']).astype(np.int8)\nsub.to_csv('simple_nn_submission.csv', index=False)\nsub.head()","441287ab":"Split train and test","7d4a0f43":"StratifiedKfold","6aa1642f":"**Define PyTorch NN Architecture**","af1d68b0":"**handling numerical feats**","8a23aab9":"**handling categorical feats**","a92cf31f":"feature engineering"}}