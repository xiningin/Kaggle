{"cell_type":{"a08b40ca":"code","5250489d":"code","0193944e":"code","b534da07":"code","3c066bcc":"code","1d7449c9":"code","05620e96":"code","f8e3b74c":"code","96cce881":"code","5cc77e2a":"code","36080d25":"code","331f09d4":"code","07efc847":"code","7ac75fae":"code","0b7bc9b4":"code","2c6882e8":"code","e057e3ff":"code","f423b6b4":"code","d64d21a0":"code","9823ec81":"markdown","cfdec505":"markdown","6031bbc5":"markdown","f1385030":"markdown","7b6ffb65":"markdown","eb76c163":"markdown","afc1242a":"markdown","33d7c0e4":"markdown","33c558e5":"markdown"},"source":{"a08b40ca":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.ensemble import RandomForestClassifier\n","5250489d":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0193944e":"train_data = pd.read_csv('\/kaggle\/input\/spooky-author\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/spooky-author\/test.csv')\nsample_submit = pd.read_csv('\/kaggle\/input\/spooky-author\/sample_submission.csv')","b534da07":"train_data.info()\nprint(\"--\"*30)\ntrain_data.head()","3c066bcc":"test_data.info()\nprint(\"--\"*30)\ntest_data.head()","1d7449c9":"train_data.isnull().sum()","05620e96":"# Define log_loss function for multi-class problem with eps 1 femto\ndef multiclass_logloss(actual, predicted, eps=1e-15):\n    if len(actual.shape) == 1:\n        binary_actual = np.zeros((actual.shape[0], predicted.shape[1]))\n        for i, val in enumerate(actual):\n            binary_actual[i, val] = 1\n        actual = binary_actual\n        \n    clip = np.clip(predicted, eps, 1-eps)\n    \n    rows = actual.shape[0]\n    vsota = np.sum(actual * np.log(clip))\n    \n    return -1.0 \/ rows * vsota\n\n    ","f8e3b74c":"lbl_encoder = LabelEncoder()\n\ny = lbl_encoder.fit_transform(train_data['author'].values)","96cce881":"X = train_data['text'].values\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, \n                                                      stratify=y,\n                                                      shuffle=True,\n                                                      random_state=42,\n                                                      test_size=0.1)","5cc77e2a":"print(X_train.shape)\nprint(X_valid.shape)","36080d25":"tfidf_vector = TfidfVectorizer(min_df=3, analyzer='word', \n                               strip_accents='unicode', \n                               token_pattern=r'\\w{1}',\n                               ngram_range=(1,3), \n                               use_idf=1, \n                               smooth_idf=1,\n                                sublinear_tf=1,\n                              stop_words='english')\n\ntfidf_vector.fit(list(X_train) + list(X_valid))\nxtrain_tfv = tfidf_vector.transform(X_train)\nxvalid_tfv = tfidf_vector.transform(X_valid)","331f09d4":"print(xtrain_tfv.shape)\nprint(xvalid_tfv.shape)","07efc847":"log_clf = LogisticRegression(C=1.0)\nlog_clf.fit(xtrain_tfv, y_train)\n\npredictions = log_clf.predict_proba(xvalid_tfv)","7ac75fae":"print(\"logloss: %0.3f\" % multiclass_logloss(y_valid, predictions))","0b7bc9b4":"svd_alg = TruncatedSVD(n_components=120)\nsvd_alg.fit(xtrain_tfv)\n\nx_train_svd = svd_alg.transform(xtrain_tfv)\nx_valid_svd = svd_alg.transform(xvalid_tfv)","2c6882e8":"# Scale the dim reduced matrix \nscaler = StandardScaler()\n\nscaler.fit(x_train_svd)\n\nx_train_scaled = scaler.transform(x_train_svd)\nx_valid_scaled = scaler.transform(x_valid_svd)","e057e3ff":"# Random Forest classifier\nrfc = RandomForestClassifier()\n\nrfc.fit(x_train_scaled, y_train)","f423b6b4":"prediction = rfc.predict_proba(x_valid_scaled)","d64d21a0":"print(\"Log loss: %0.3f\" % multiclass_logloss(y_valid, prediction))","9823ec81":"## Exploratory Data Analysis","cfdec505":"# Text classification on Spooky Dataset","6031bbc5":"## Encode Y-variable","f1385030":"## Building Model","7b6ffb65":"There is no column with missing or null values. ","eb76c163":"## TFIDF-Vectorization\n\n<pre>\nTfidfVectorizer(*, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.float64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n<\/pre>","afc1242a":"## Dimensionality Reduction\n\n","33d7c0e4":"## Loading Dataset","33c558e5":"## Split the data"}}