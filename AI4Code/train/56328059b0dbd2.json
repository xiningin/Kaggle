{"cell_type":{"62f18b42":"code","06231fbc":"code","63c20d25":"code","3e60729b":"code","b0f4a714":"code","3eef2973":"code","6dc740da":"code","d1e8108e":"code","57d97ae8":"code","ea04e6e1":"code","eb792443":"code","9baa4952":"code","3d1183d1":"code","12e2ec65":"code","3d46ca3a":"code","bd7cade0":"code","9ec341f8":"code","33454cc2":"code","fba79d33":"code","b5b2815f":"code","a7dcd635":"code","9b7f1877":"code","0f3e3339":"code","4e9141aa":"code","d9a5d60d":"code","f8d92729":"code","caec45a9":"code","15a369e4":"code","1c5a0322":"code","09303b3b":"markdown","6b3a384e":"markdown","0e4b8f49":"markdown","afad231e":"markdown","49ee8420":"markdown","38270769":"markdown","e7ed8a3d":"markdown","d6714c34":"markdown","b7e8247e":"markdown","6460e1b5":"markdown","3fa33f2e":"markdown","4d8d969a":"markdown","20f9c544":"markdown","4eb2632a":"markdown","cebddc71":"markdown","cfc68709":"markdown"},"source":{"62f18b42":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06231fbc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport tensorflow as tf \nfrom tensorflow import keras\nimport sklearn \n\nimport warnings\nwarnings.filterwarnings(action='ignore')","63c20d25":"df = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","3e60729b":"df.drop('customerID', axis=1, inplace=True)\ndf.head()","b0f4a714":"df.dtypes","3eef2973":"df[pd.to_numeric(df.TotalCharges, errors='coerce').isnull()]","6dc740da":"data = df[df.TotalCharges!=\" \"]\ndata.shape","d1e8108e":"data.TotalCharges = pd.to_numeric(data.TotalCharges)\ndata.TotalCharges.dtypes","57d97ae8":"def print_cat_unique(data):\n    for column in data:\n        if data[column].dtypes == 'object':\n            print(f'{column} : {data[column].unique()}')","ea04e6e1":"print_cat_unique(data)","eb792443":"data.replace('No phone service', 'No', inplace=True)\ndata.replace('No internet service', 'No', inplace=True)","9baa4952":"encoding_Cat_cols = ['Partner','Dependents','PhoneService',\n                    'MultipleLines','OnlineSecurity',\n                    'OnlineBackup','DeviceProtection','TechSupport',\n                    'StreamingTV','StreamingMovies',\n                    'PaperlessBilling','Churn']\n\nfor col in encoding_Cat_cols:\n    data[col].replace({'Yes': 1, 'No': 0}, inplace=True)\n\nprint_cat_unique(data) ","3d1183d1":"data['gender'].replace({'Female': 1, 'Male': 0}, inplace=True)\nprint_cat_unique(data)","12e2ec65":"dummies_encoding = ['InternetService','Contract','PaymentMethod']\n\ndata = pd.get_dummies(data=data, columns=dummies_encoding)","3d46ca3a":"data.dtypes","bd7cade0":"data.shape","9ec341f8":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ncols_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']\n\ndata[cols_scale] = scaler.fit_transform(data[cols_scale])","33454cc2":"X = data.drop('Churn', axis=1)\ny = data['Churn'].copy()\n\nprint(X.shape)\nprint(y.shape)","fba79d33":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()","b5b2815f":"X_os, y_os = oversample.fit_resample(X, y)","a7dcd635":"print(X.shape, y.shape)\nprint(X_os.shape, y_os.shape)","9b7f1877":"from sklearn.model_selection import train_test_split","0f3e3339":"X_os_train, X_os_test, y_os_train, y_os_test = train_test_split(\n                            X_os, y_os, test_size=0.2, random_state=42)","4e9141aa":"print('X_os_train Shape', X_os_train.shape)\nprint('X_os_test Shape', X_os_test.shape)\nprint('y_os_train Shape', y_os_train.shape)\nprint('y_os_test Shape', y_os_test.shape)","d9a5d60d":"model = keras.Sequential([\n    keras.layers.Dense(26, input_shape=X_os_train.shape[1:], activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n            metrics=['accuracy'],\n            optimizer=keras.optimizers.SGD(learning_rate=5e-1))\n\nmodel.fit(X_os_train, y_os_train, epochs=100)","f8d92729":"model.evaluate(X_os_test, y_os_test)","caec45a9":"yp = model.predict(X_os_test)\ny_pred = []\nfor element in yp:\n    if element > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","15a369e4":"from sklearn.metrics import confusion_matrix, classification_report\n\nprint(classification_report(y_os_test, y_pred))","1c5a0322":"cm = tf.math.confusion_matrix(labels=y_os_test, predictions=y_pred)\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","09303b3b":"Now we are left with the last three features; `InternetService`,`Contract`,`PaymentMethod`, we can do the same as before, but let's try `pd.get_dummies` method in order to create more features in the dataset. This will help in the Neural Networks to create more neurons","6b3a384e":"Using Keras `Sequential()`","0e4b8f49":"We have increased the number of columns to 27 ","afad231e":"Hmmm, what does \"*No internet service*\" or \"*No phone service*\" mean? I believe it means **NO** !!! Here we should just replace them with **NO** without feeling guilty :)","49ee8420":"Interesting !!!\nexcept `SeniorCitizen`, `tenure`, and `MonthlyCharges` all other columns are objects, even `TotalCharges`. We need to modify them","38270769":"I hope you liked this notebook. Leave a comment and feel free to contact :)","e7ed8a3d":"Great !! Now we have 7032 instances and we have to ensure that `TotalCharges` have been changed to numeric type","d6714c34":"Only 11 instances have null `TotalCharges` values, it won't effect the modelling so we will just drop them and take the data into new dataset","b7e8247e":"### Loading Libraries","6460e1b5":"Inspecting the data types using `dtypes`","3fa33f2e":"I highly encourage you to do EDA before going to any preprocessing of data. EDA was the main reason for me to understanding about the *imbalance* of this dataset. Here I'm going to use `imblearn.over_sampling` **SMOTE** to introduce more instances in order to have better balance before splitting the data into Training & Testing","4d8d969a":"Simple encoding by replacing *Yes* with **1** and *No* with **0** as the Neural Networks don't really like dealing with categorical data. Let's go numeric ","20f9c544":"Let's create a quick function to inspect the unique values in each categorical column before we take them to ENCODING preprocessing","4eb2632a":"As you can see, the number of instances increased from 7032 to 10326. Let's split","cebddc71":"As all columns now are numeric ones in 0s and 1s, these three columns are not in the same SCALE. I have chosen to go for `StandardScaler` method in Scikit-Learn. Some may like to use `MinMaxScaler`, please give your opinions in the comment box for more discussion :)","cfc68709":"Dropping `customerID` column as it is not relevent to our model"}}