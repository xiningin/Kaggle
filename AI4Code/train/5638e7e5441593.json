{"cell_type":{"decda119":"code","d60d98f6":"code","f7786d27":"code","01ab0c73":"code","f9f7a0ce":"code","ae8031b0":"code","1389a4a1":"code","29651ee2":"code","cab60187":"code","bd4cf91e":"code","fbac7ad9":"code","bf103215":"code","7c333580":"code","9b911ddb":"code","3b1a3f8e":"code","6f5a2a5c":"code","10a5f165":"code","26067de7":"code","9edd56f7":"code","4ef3ddbe":"code","fee3e73c":"markdown","2e37410b":"markdown","bd35b0f1":"markdown","2429df7e":"markdown","9536347a":"markdown","1033a13b":"markdown","71d025a7":"markdown","68d9234b":"markdown","c190ab6a":"markdown","8d72dcd5":"markdown"},"source":{"decda119":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt","d60d98f6":"## While downloading below dataset if you get any error related to path of dataset. \n## Then please upgrade the below package. This will fix the error. Else good to go.\n# !pip install --upgrade tensorflow_datasets","f7786d27":"data, info = tfds.load(\"imagenette\/160px-v2\", with_info=True, as_supervised=True)\ntrain_data, valid_data = data['train'], data['validation']\n\ndel data","01ab0c73":"train_dataset = train_data.map(\n    lambda image, label: (tf.image.resize(image, (160, 160)), label))\n\nvalidation_dataset = valid_data.map(\n    lambda image, label: (tf.image.resize(image, (160, 160)), label)\n)\n\ndel train_data\ndel valid_data","f9f7a0ce":"train_dataset","ae8031b0":"num_classes = info.features['label'].num_classes\nprint(f'Total number of classes in dataset is {num_classes}')","1389a4a1":"get_label_name = info.features['label'].int2str\ntext_labels = [get_label_name(i) for i in range(num_classes)]\nfor idx,i in enumerate(text_labels):\n    print(f'The Label {idx} name is `{i}`')","29651ee2":"%%time\n\nX_train = list(map(lambda x: x[0], train_dataset))\ny_train = list(map(lambda x: x[1], train_dataset))\n\n\nX_valid = list(map(lambda x: x[0], validation_dataset))\ny_valid = list(map(lambda x: x[1], validation_dataset))\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_valid = tf.keras.utils.to_categorical(y_valid, num_classes)\n\ndel train_dataset\ndel validation_dataset","cab60187":"train_len = info.splits['train'].num_examples\nvalid_len = info.splits['validation'].num_examples\nprint(f'Train size {train_len} and Valid size {valid_len}')","bd4cf91e":"y_train.shape,y_valid.shape","fbac7ad9":"# Clear GPU Memory\n# from numba import cuda\n# cuda.select_device(0)\n# cuda.close()","bf103215":"# # to use below lines you may need to undelete the train_data\n# get_label_name = info.features['label'].int2str\n# image, label = next(iter(train_data))\n# plt.imshow(image)\n# plt.title(get_label_name(label))","7c333580":"%%time\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      height_shift_range=0.2)\n\nvalid_datagen = ImageDataGenerator(\n      rescale=1.\/255)\n\n\ntrain_ds = tf.keras.preprocessing.image.NumpyArrayIterator(\n    x=np.array(X_train), y=np.array(y_train), image_data_generator=train_datagen,batch_size=16\n)\n\nvalid_ds = tf.keras.preprocessing.image.NumpyArrayIterator(\n    x=np.array(X_valid), y=np.array(y_valid), image_data_generator=valid_datagen,batch_size=32\n)\n\n# train_datagen.fit(X_train)","9b911ddb":"train_ds.__len__(),valid_ds.__len__() #depends on batching ","3b1a3f8e":"# # to use below lines you may need to undelete the train_data\nimage, label = next(iter(train_ds))\nplt.imshow(image[0])\nplt.title(get_label_name(np.argmax(label)))","6f5a2a5c":"# configure batch size and retrieve one batch of images\n# # to use below lines you may need to undelete the train_data\n# image, label = next(iter(train_ds))\n# plt.imshow(image[0])\n# plt.title(get_label_name(np.argmax(label)))\n\n# create a grid of 3x3 images\nfor i in range(0, 9):\n    image,label = next(iter(train_ds))\n    plt.subplot(330 + 1 + i)\n    plt.imshow(image[0])\n    plt.title(get_label_name(np.argmax(label)))\n# show the plot\nplt.show()\n","10a5f165":"model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(160, 160, 3)),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512,activation='relu'),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(64,activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(10,activation='softmax')\n])\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","26067de7":"history = model.fit(\n  train_ds,\n  validation_data=valid_ds,\n  steps_per_epoch=100,\n  epochs=15,\n  validation_steps=50,\n  verbose=2\n)","9edd56f7":"print(f'The training accuracy was {round(history.history[\"accuracy\"][-1],2)} and validation accuracy was {round(history.history[\"val_accuracy\"][-1],2)} ')\nprint(f'The training loss was {round(history.history[\"loss\"][-1],2)} and validation loss was {round(history.history[\"val_loss\"][-1],2)} ')","4ef3ddbe":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","fee3e73c":"## Load dataset from Tensorflow Datasets","2e37410b":"## Number of classes to predict and its label names","bd35b0f1":"# Imagenette Classification using Pure Tensorflow\n\nTopics\n* Reshaping\n* Augmentation\n* Plotting\n* Model Building","2429df7e":"## Just for plotting the prefected dataset","9536347a":"Info: The current version >7 uses GPU only while training\n\nTo Do:\n\n* Less optimized for GPU. Need to fix for smooth training\n* Model comparision\n* parallelization\n* plotting\n* Predictions","1033a13b":"# Upvote, If you like :)","71d025a7":"## Number of training and valid examples","68d9234b":"## Plotting Augmented dataset","c190ab6a":"## ImageDataGenerator to perform augmentation on dataset","8d72dcd5":"## Unzipping the prefected dataset into X and y for train and valid"}}