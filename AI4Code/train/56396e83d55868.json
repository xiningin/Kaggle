{"cell_type":{"e0a4e64c":"code","e3503e83":"code","4127576d":"code","8040664a":"code","190b23ad":"code","9da164be":"code","9795dc55":"code","a11c0943":"code","20c1b22f":"code","2977cf68":"code","0c69c031":"code","87887b79":"code","9e9c59d7":"code","93f960b9":"code","9b1467b6":"code","8aa9359d":"code","027258de":"code","f13d74d3":"code","86e5bcd1":"code","b5fa6b2b":"code","15c3d736":"code","b70485e1":"code","d75369c4":"code","22d88b21":"code","b57fd614":"code","c413ee32":"code","83109f27":"code","ead0c0df":"code","b1841589":"code","cd12d6fa":"code","a1b3b85a":"code","0eb5b16e":"code","86f7f771":"code","3b33b2fc":"code","e3e8ee49":"code","c8f10156":"code","054a441c":"code","bf4f9b63":"code","695d2b2f":"code","df5f0ca4":"code","440ce176":"code","7d79196a":"code","087cc4f2":"code","181bc2c1":"code","2cdc35d8":"code","6c4b8fb5":"code","fecc62e5":"code","77cbc4ba":"code","13e969f4":"code","3474f3dd":"code","3d93d767":"code","a2bb9b27":"code","d367c096":"code","c252512c":"code","3b39737c":"code","64c0fc19":"code","651f8364":"code","4c45ade9":"code","6e8f8a90":"code","163c096b":"code","f9e2994a":"code","1306e0ac":"code","936a1741":"code","1d084d88":"code","3c73a42b":"code","cb93f139":"code","c588f49b":"code","a8bfa69f":"code","1784f4c6":"code","42c8972a":"code","a6a481ec":"code","47bcf480":"code","910cd08b":"code","ce2525a9":"code","7c9c7fd0":"code","1c486be1":"code","e1a13d75":"markdown","db7594d0":"markdown","ee8b85e6":"markdown","9b7312fe":"markdown","f25988e6":"markdown","c21baf97":"markdown","60f1e956":"markdown","6bb3747f":"markdown","d7ee5592":"markdown","98d92d31":"markdown","1a272c78":"markdown","889186ee":"markdown","e4ebcda7":"markdown","9dcce0d0":"markdown","314a0e49":"markdown","b26950f1":"markdown","07e4acd9":"markdown","03f0241e":"markdown","8d18a02e":"markdown","ae5bd6d1":"markdown","75c3e9ec":"markdown","112de9a0":"markdown","129d38e5":"markdown","2aa39e5c":"markdown","81f74de6":"markdown","b6765907":"markdown","cda21a07":"markdown","717949a7":"markdown","d1f21a48":"markdown","43f015c0":"markdown"},"source":{"e0a4e64c":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","e3503e83":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4127576d":"# Importing Pandas and NumPy\nimport pandas as pd, numpy as np, seaborn as sns,matplotlib.pyplot as plt","8040664a":"pd.set_option('display.max_columns', None)","190b23ad":"# Importing all datasets\nchurn_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/churn_data.csv\")\nchurn_data.head()","9da164be":"customer_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/customer_data.csv\")\ncustomer_data.head()","9795dc55":"internet_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/internet_data.csv\")\ninternet_data.head()","a11c0943":"# Merging on 'customerID'\ndf_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')","20c1b22f":"# Final dataframe with all predictor variables\ntelecom = pd.merge(df_1, internet_data, how='inner', on='customerID')","2977cf68":"# Let's see the head of our master dataset\ntelecom.head()","0c69c031":"# Let's check the dimensions of the dataframe\ntelecom.shape","87887b79":"# let's look at the statistical aspects of the dataframe\ntelecom.describe()","9e9c59d7":"# Let's see the type of each column\ntelecom.info()","93f960b9":"#The varaible was imported as a string we need to convert it to float\n# telecom['TotalCharges'] = telecom['TotalCharges'].astype(float) \ntelecom.TotalCharges = pd.to_numeric(telecom.TotalCharges, errors='coerce')","9b1467b6":"telecom.info()","8aa9359d":"\nplt.figure(figsize=(20,40))\nplt.subplot(10,2,1)\nax = sns.distplot(telecom['tenure'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('Tenure (months)')\nplt.subplot(10,2,2)\nax = sns.countplot(x='PhoneService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,4)\nax =sns.countplot(x='PaperlessBilling', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,5)\nax =sns.countplot(x='PaymentMethod', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,6)\nax =sns.countplot(x='Churn', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,7)\nax =sns.countplot(x='gender', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,8)\nax =sns.countplot(x='SeniorCitizen', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,9)\nax =sns.countplot(x='Partner', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,10)\nax =sns.countplot(x='Dependents', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,11)\nax =sns.countplot(x='MultipleLines', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,12)\nax =sns.countplot(x='InternetService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,13)\nax =sns.countplot(x='OnlineSecurity', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,14)\nax =sns.countplot(x='OnlineBackup', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,15)\nax =sns.countplot(x='DeviceProtection', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,16)\nax =sns.countplot(x='TechSupport', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,17)\nax =sns.countplot(x='StreamingTV', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,18)\nax =sns.countplot(x='StreamingMovies', data=telecom)\nax.set_ylabel('# of Customers')\nplt.subplot(10,2,19)\nax = sns.distplot(telecom['MonthlyCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('MonthlyCharges')\nplt.subplot(10,2,20)\nax = sns.distplot(telecom['TotalCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('TotalCharges');","027258de":"sns.pairplot(telecom)\nplt.show()","f13d74d3":"plt.figure(figsize=(25, 10))\nplt.subplot(1,3,1)\nsns.boxplot(x = 'tenure', y = 'Churn', data=telecom)\nplt.subplot(1,3,2)\nsns.boxplot(x = 'MonthlyCharges', y = 'Churn', data=telecom)\nplt.subplot(1,3,3)\nsns.boxplot(x = 'TotalCharges', y = 'Churn', data=telecom)\nplt.show()","86e5bcd1":"# List of variables to map\n\nvarlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\ntelecom[varlist] = telecom[varlist].apply(binary_map)","b5fa6b2b":"telecom.head()","15c3d736":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(telecom[['Contract', 'PaymentMethod', 'gender', 'InternetService']], drop_first=True)\n\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom, dummy1], axis=1)","b70485e1":"telecom.head()","d75369c4":"# Creating dummy variables for the remaining categorical variables and dropping the level with big names.\n\n# Creating dummy variables for the variable 'MultipleLines'\nml = pd.get_dummies(telecom['MultipleLines'], prefix='MultipleLines')\n# Dropping MultipleLines_No phone service column\nml1 = ml.drop(['MultipleLines_No phone service'], 1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ml1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineSecurity'.\nos = pd.get_dummies(telecom['OnlineSecurity'], prefix='OnlineSecurity')\nos1 = os.drop(['OnlineSecurity_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,os1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineBackup'.\nob = pd.get_dummies(telecom['OnlineBackup'], prefix='OnlineBackup')\nob1 = ob.drop(['OnlineBackup_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ob1], axis=1)\n\n# Creating dummy variables for the variable 'DeviceProtection'. \ndp = pd.get_dummies(telecom['DeviceProtection'], prefix='DeviceProtection')\ndp1 = dp.drop(['DeviceProtection_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,dp1], axis=1)\n\n# Creating dummy variables for the variable 'TechSupport'. \nts = pd.get_dummies(telecom['TechSupport'], prefix='TechSupport')\nts1 = ts.drop(['TechSupport_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ts1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingTV'.\nst =pd.get_dummies(telecom['StreamingTV'], prefix='StreamingTV')\nst1 = st.drop(['StreamingTV_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,st1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingMovies'. \nsm = pd.get_dummies(telecom['StreamingMovies'], prefix='StreamingMovies')\nsm1 = sm.drop(['StreamingMovies_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,sm1], axis=1)","22d88b21":"telecom.head()","b57fd614":"# We have created dummies for the below variables, so we can drop them\ntelecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)","c413ee32":"# Checking for outliers in the continuous variables\nnum_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]","83109f27":"# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\nnum_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])","ead0c0df":"# Adding up the missing values (column-wise)\ntelecom.isnull().sum()","b1841589":"print('No. of Null Records for TotalCharges:',telecom.TotalCharges.isnull().sum())","cd12d6fa":"print('No. of Records for TotalCharges:',len(telecom))","a1b3b85a":"print('No. of non Records for TotalCharges:',len(telecom)-telecom.TotalCharges.isnull().sum())","0eb5b16e":"# Checking the percentage of missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","86f7f771":"telecom = telecom.dropna()\ntelecom = telecom.reset_index(drop=True)\n\n","3b33b2fc":"# Checking percentage of missing values after removing the missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","e3e8ee49":"from sklearn.model_selection import train_test_split","c8f10156":"# Putting feature variable to X\nX = telecom.drop(['Churn','customerID'], axis=1)\n\nX.head()","054a441c":"# Putting response variable to y\ny = telecom['Churn']\n\ny.head()","bf4f9b63":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","695d2b2f":"from sklearn.preprocessing import StandardScaler","df5f0ca4":"scaler = StandardScaler()\n\nX_train[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges','TotalCharges']])\n\nX_train.head()","440ce176":"X_test[['tenure','MonthlyCharges','TotalCharges']] = scaler.transform(X_test[['tenure','MonthlyCharges','TotalCharges']])\n\nX_test.head()","7d79196a":"### Checking the Churn Rate\nchurn = (sum(telecom['Churn'])\/len(telecom['Churn'].index))*100\nchurn","087cc4f2":"# Importing matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","181bc2c1":"# Let's see the correlation matrix \nplt.figure(figsize = (25,25))        # Size of the figure\nsns.heatmap(telecom.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","2cdc35d8":"plt.figure(figsize=(10,8))\ntelecom.corr()['Churn'].sort_values(ascending = False).plot(kind='bar');","6c4b8fb5":"X_test = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                       'StreamingTV_No','StreamingMovies_No'], 1)\nX_train = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                         'StreamingTV_No','StreamingMovies_No'], 1)","fecc62e5":"plt.figure(figsize = (25,25))\nsns.heatmap(X_train.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","77cbc4ba":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nmodel = KNeighborsClassifier()","13e969f4":"# fit the model with the training data\nmodel.fit(X_train,y_train)","3474f3dd":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","3d93d767":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","a2bb9b27":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif.tail()","d367c096":"features_to_remove = vif.loc[vif['VIF'] >= 4.99,'Features'].values\nfeatures_to_remove = list(features_to_remove)\nprint(features_to_remove)","c252512c":"X_train = X_train.drop(columns=features_to_remove, axis = 1)\nX_train.head()","3b39737c":"X_test = X_test.drop(columns=features_to_remove, axis = 1)\nX_test.head()","64c0fc19":"# fit the model with the training data\nmodel.fit(X_train,y_train)","651f8364":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","4c45ade9":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","6e8f8a90":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","163c096b":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train, predict_train )\nprint(confusion)\n","f9e2994a":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","1306e0ac":"# Let's see the sensitivity of our model\ntrainsensitivity= TP \/ float(TP+FN)\ntrainsensitivity","936a1741":"# Let us calculate specificity\ntrainspecificity= TN \/ float(TN+FP)\ntrainspecificity","1d084d88":"# Calculate false postive rate - predicting churn when customer does not have churned\nprint(FP\/ float(TN+FP))","3c73a42b":"# Positive predictive value \nprint (TP \/ float(TP+FP))","cb93f139":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","c588f49b":"draw_roc(y_train,predict_train)","a8bfa69f":"#Looking at the confusion matrix again","1784f4c6":"from sklearn.metrics import precision_score, recall_score\nprecision_score(y_train,predict_train)","42c8972a":"recall_score(y_train,predict_train)","a6a481ec":"# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data\\n\\n',predict_test)","47bcf480":"confusion2 = metrics.confusion_matrix(y_test, predict_test )\nprint(confusion2)","910cd08b":"# Let's check the overall accuracy.\ntestaccuracy= accuracy_score(y_test,predict_test)\ntestaccuracy","ce2525a9":"# Let's see the sensitivity of our lmodel\ntestsensitivity=TP \/ float(TP+FN)\ntestsensitivity","7c9c7fd0":"# Let us calculate specificity\ntestspecificity= TN \/ float(TN+FP)\ntestspecificity","1c486be1":"# Let us compare the values obtained for Train & Test:\nprint(\"Train Data Accuracy    :{} %\".format(round((trainaccuracy*100),2)))\nprint(\"Train Data Sensitivity :{} %\".format(round((trainsensitivity*100),2)))\nprint(\"Train Data Specificity :{} %\".format(round((trainspecificity*100),2)))\nprint(\"Test Data Accuracy     :{} %\".format(round((testaccuracy*100),2)))\nprint(\"Test Data Sensitivity  :{} %\".format(round((testsensitivity*100),2)))\nprint(\"Test Data Specificity  :{} %\".format(round((testspecificity*100),2)))","e1a13d75":"#### Dropping the repeated variables","db7594d0":"## Telecom Churn Case Study\nWith 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, this is referred to as churning and not churning, respectively.","ee8b85e6":"#### Converting some binary variables (Yes\/No) to 0\/1","9b7312fe":"# Plotting the ROC Curve","f25988e6":"It means that 11 * 100\/7043 = 0.1561834%, best is to remove these observations from the analysis","c21baf97":"It can be used for both classification and regression problems. However, it is more widely used in classification problems in the industry. K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors.","60f1e956":"### Step 11: Making predictions on the test set","6bb3747f":"Now you can see that you have all variables as numeric.","d7ee5592":"#### Checking for Outliers","98d92d31":"#### Checking for Missing Values and Inputing Them","1a272c78":"### Step 5: Feature Scaling","889186ee":"### Step 1: Importing and Merging Data","e4ebcda7":"## Precision and Recall","9dcce0d0":"# EDA","314a0e49":"#### For categorical variables with multiple levels, create dummy features (one-hot encoded)","b26950f1":"### Step 2: Inspecting the Dataframe","07e4acd9":"# VIF","03f0241e":"### Step 6: Looking at Correlations","8d18a02e":"### Step 4: Test-Train Split","ae5bd6d1":"### Step 7: Model Building\nLet's start by splitting our data into a training set and a test set.","75c3e9ec":"#### Combining all data files into one consolidated dataframe","112de9a0":"# VIF","129d38e5":"# Final Observation:","2aa39e5c":"From the distribution shown above, you can see that there no outliers in your data. The numbers are gradually increasing.","81f74de6":"#### Checking the Correlation Matrix","b6765907":"# kNN (k- Nearest Neighbors)","cda21a07":"#### Dropping highly correlated dummy variables","717949a7":"After dropping highly correlated variables now let's check the correlation matrix again.","d1f21a48":"Now we don't have any missing values","43f015c0":"We have almost 27% churn rate"}}