{"cell_type":{"e061c5e0":"code","7fd81789":"code","32f0a348":"code","c3c237d5":"code","10009f76":"code","85ac4202":"code","8ce15927":"code","78b638de":"code","475e0705":"code","82a9ad57":"code","512ade7c":"code","d76cc63c":"code","51f047d7":"code","8716784c":"code","1a8d5a35":"code","ebce2c5c":"code","d700a8e7":"code","438962d1":"code","18fdb683":"code","d73faf83":"code","c61d5c19":"code","55d51e63":"code","f8aee704":"code","6c7de730":"code","f372cd3c":"markdown","48b026ea":"markdown","ef3caf47":"markdown","fac63f32":"markdown","6b319361":"markdown","5d2e297a":"markdown","0de4f1d1":"markdown","c6b022dc":"markdown","113bd5c8":"markdown","9c7607f7":"markdown","0c381a32":"markdown","722e3ca7":"markdown","85915669":"markdown","d76c324f":"markdown","dd8a6c4f":"markdown"},"source":{"e061c5e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7fd81789":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","32f0a348":"raw_data = pd.read_csv(\"..\/input\/fer2018\/fer20131.csv\")\nraw_data.head()","c3c237d5":"raw_data.info()","10009f76":"emotions = {0:'Angry', 1:'Fear', 2:'Happy',3:'Sad', 4:'Surprise', 5:'Neutral'}","85ac4202":"values_count = raw_data['Usage'].value_counts()\nsizes =[values_count[0],values_count[1],values_count[-1]]\nplt.figure(figsize=(7,7))\ng = plt.pie(sizes,autopct='%1.1f%%',shadow=False,explode=(0,0.05,0.05),\n           wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed', 'antialiased': True},\n           labels = [\"Training = {}\".format(values_count[0]),\"Testing = {}\".format(values_count[-1]),\n                    \"Devlopment = {}\".format(values_count[1])])\nplt.title(\"Data Distribution\")\nplt.legend(loc = 4)\nplt.show()\n\n","8ce15927":"trainig_data = raw_data[raw_data['Usage'] == 'Training'].iloc[:,:-1]\ntesting_data = raw_data[raw_data['Usage'] == 'PrivateTest'].iloc[:,:-1]\ndev_data = raw_data[raw_data['Usage'] == 'PublicTest'].iloc[:,:-1]","78b638de":"def get_data(raw_data):\n#     raw_data['pixels'] = raw_data['pixels'].apply(lambda x: np.array(x.split(),dtype=np.float32).reshape((48,48)))\n    pixels = []\n    target = []\n    for x,y in zip(raw_data['pixels'],raw_data['emotion']):\n        pixels.append(np.array(x.split(),dtype=np.float32))\n        target.append(y)\n\n    return np.array(pixels,dtype=np.float32).reshape((len(pixels),48,48,1)),np.array(target,dtype=np.float32).reshape((len(target),1))","475e0705":"X_train,y_train = get_data(trainig_data)\nX_test,y_test = get_data(testing_data)\nX_dev,y_dev = get_data(dev_data)","82a9ad57":"print(\"X_train shape : \",X_train.shape)\nprint(\"Y_train shape : \",y_train.shape)\nprint(\"X_dev shape : \",X_dev.shape)\nprint(\"Y_dev shape : \",y_dev.shape)\nprint(\"X_test shape : \",X_test.shape)\nprint(\"Y_test shape : \",y_test.shape)","512ade7c":"def plot_distribution(y_train,y_test,y_dev):\n    plt.figure(figsize=(10,10))\n    plt.subplot(3,1,1)\n    unique_data,frequency = np.unique(y_train,return_counts=True)\n    sns.barplot(x=np.vectorize(emotions.get)(unique_data),y=frequency)\n    \n    plt.subplot(3,1,2)\n    unique_data,frequency = np.unique(y_test,return_counts=True)\n    sns.barplot(x=np.vectorize(emotions.get)(unique_data),y=frequency)\n    \n    plt.subplot(3,1,3)\n    unique_data,frequency = np.unique(y_dev,return_counts=True)\n    sns.barplot(x=np.vectorize(emotions.get)(unique_data),y=frequency)\n    plt.show()","d76cc63c":"plot_distribution(y_train,y_test,y_dev)","51f047d7":"from sklearn.manifold import TSNE\nmodel = TSNE(n_components=2, random_state=1)\ntsne_data = model.fit_transform(X_train[0:1000].reshape(len(X_train[0:1000]),2304))","8716784c":"tsne_data_np = np.hstack((tsne_data,y_train[0:1000]))\ntsne_dataframe = pd.DataFrame(data=tsne_data_np,columns=[\"Dim_1\",\"Dim_2\",\"label\"])\n\nplt.figure(figsize=(10,10))\nsns.scatterplot(x=\"Dim_1\",y=\"Dim_2\",data=tsne_dataframe,hue='label', palette=\"Set3\")\nplt.title(\"TSNE\")\nplt.legend(title='emotions', loc='upper left', labels=['Angry', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral'])\nplt.plot()","1a8d5a35":"from sklearn import decomposition\npca = decomposition.PCA()\npca.n_components = 2\npca_data = pca.fit_transform(X_train[0:1000].reshape(len(X_train[0:1000]),2304))","ebce2c5c":"pca_data_np = np.hstack((pca_data,y_train[0:1000]))\npca_dataframe = pd.DataFrame(data=pca_data_np,columns=[\"1st_principal\",\"2nd_principal\",\"label\"])\n\nplt.figure(figsize=(10,10))\nsns.scatterplot(x=\"1st_principal\",y=\"2nd_principal\",data=pca_dataframe,hue='label', palette=\"Set3\")\nplt.title(\"PCA\")\nplt.legend(title='emotions', loc='upper left', labels=['Angry', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral'])\nplt.plot()","d700a8e7":"X_train = X_train\/255.0\nX_test = X_test\/255.0\nX_dev = X_dev\/255.0\n\ny_train = (np.arange(6) == y_train[:]).astype(np.float32)\ny_test = (np.arange(6) == y_test[:]).astype(np.float32)\ny_dev = (np.arange(6) == y_dev[:]).astype(np.float32)","438962d1":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","18fdb683":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    \n    model.add(Conv2D(64, (3, 3), input_shape=input_shape, padding='same'))\n#     model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n#     model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(512,(3,3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(512,(3,3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    \n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    \n    model.add(Dense(6, activation='softmax'))\n    \n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy','mean_squared_error'],optimizer='adam')\n    \n    return model","d73faf83":"model = my_model()\nmodel.summary()","c61d5c19":"K.tensorflow_backend.clear_session()\npath_model='model_filter.h5'\nmodel=my_model() \n# K.set_value(model.optimizer.lr,1e-4) \nh=model.fit(x=X_train,y=y_train, \n            batch_size=128, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_dev,y_dev),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","55d51e63":"plt.plot(h.history['loss'], label='MAE (testing data)')\nplt.plot(h.history['val_loss'], label='MAE (validation data)')\nplt.title('MAE')\nplt.ylabel('MAE value')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","f8aee704":"# Plot history: MSE\nplt.plot(h.history['mean_squared_error'], label='MSE (testing data)')\nplt.plot(h.history['val_mean_squared_error'], label='MSE (validation data)')\nplt.title('MSE')\nplt.ylabel('MSE value')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","6c7de730":"score = model.evaluate(X_test, y_test, verbose=0)\nprint (\"model %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","f372cd3c":"## Visualizing the MSE","48b026ea":"* We can see here Distribution of all data are same","ef3caf47":"## Visualization Data in Lower Dimention","fac63f32":"## Import libraries","6b319361":"## Visualizing the MAE","5d2e297a":"## Import Data","0de4f1d1":"## Model","c6b022dc":"* Principal component analysis (PCA)","113bd5c8":"## Data Pre-process","9c7607f7":"## Data Shape","0c381a32":"## Target Maping","722e3ca7":"## Data Distribution","85915669":"## Data Distribution with target","d76c324f":"* t-Distributed Stochastic Neighbor Embedding (t-SNE)","dd8a6c4f":"* preapere target values with One-Hot Encoding for softmax function"}}