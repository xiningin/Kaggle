{"cell_type":{"02749ec8":"code","8605f306":"code","052a51d4":"code","f4da860d":"code","1d9f509c":"code","4e5c9b32":"code","8fcfb750":"code","c4feb864":"code","24474df9":"code","a953696b":"code","6e5e131a":"code","747f4a75":"code","eee2ee04":"code","4ba438f0":"code","671eade0":"code","1974235a":"code","295ee49c":"code","bf9ded80":"code","cad7ea65":"code","eee38090":"code","b3bbc973":"code","8b895b90":"code","4b71567d":"code","6b71ec56":"code","d0f5f99d":"code","0abc7817":"code","3314d09a":"code","2b221402":"code","49b71a36":"code","99b66284":"code","1c0f666d":"code","0fe46941":"code","195e3ea2":"code","bbd56388":"code","e09f560c":"code","7335110f":"code","f2553313":"code","7843de81":"code","4ebbf220":"code","b5ab337e":"code","0bc4ea83":"code","3cc542d1":"code","b88055e0":"code","a811d6d0":"code","df328077":"markdown","4de8e915":"markdown","8ec29c99":"markdown","fb577d66":"markdown","ffed19c3":"markdown","c4931f56":"markdown","1adfe5c8":"markdown","64b8df00":"markdown","d5a81108":"markdown","40c7fe83":"markdown","fded1848":"markdown","b5e6d47d":"markdown","aef37e87":"markdown","da6e41a1":"markdown","a00c1be3":"markdown","fb42762b":"markdown","8a16d4d6":"markdown","b63c16dc":"markdown","de2c0738":"markdown"},"source":{"02749ec8":"#import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\n%matplotlib inline\nfrom statsmodels.stats.proportion import proportions_ztest\n\nfrom sklearn.metrics import auc\nimport xgboost as xgb\n\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","8605f306":"df = pd.read_csv('\/kaggle\/input\/uplift-modeling\/criteo-uplift-v2.1.csv')","052a51d4":"df.info()","f4da860d":"df.head()","1d9f509c":"print('Total number of samples: {}'.format(len(df)))","4e5c9b32":"df['treatment'].value_counts(normalize = True)","8fcfb750":"style.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (20,15))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(df.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, )\nplt.title(\"Heatmap of all the Features\", fontsize = 30)\nplt.yticks(rotation=0)","c4feb864":"print('Percentage of users that visit: {}%'.format(100*round(df['visit'].mean(),4)))\nprint('Percentage of users that convert: {}%'.format(100*round(df['conversion'].mean(),4)))\nprint('Percentage of visitors that convert: {}%'.format(100*round(df[df[\"visit\"]==1][\"conversion\"].mean(),4)))","24474df9":"vis_results_df = df.groupby('treatment').agg({'visit':['mean', 'sum', 'count']})\nvis_results_df","a953696b":"con_results_df = df.groupby('treatment').agg({'conversion':['mean', 'sum', 'count']})\ncon_results_df","6e5e131a":"print(f'Difference in clickthrough rate between control and treatment: {np.round(df.groupby(\"treatment\")[\"visit\"].mean()[1] - df.groupby(\"treatment\")[\"visit\"].mean()[0], 4)}')\nprint(f'Difference in conversion between control and treatment: {np.round(df.groupby(\"treatment\")[\"conversion\"].mean()[1] - df.groupby(\"treatment\")[\"conversion\"].mean()[0], 4)}')","747f4a75":"proportions_ztest(count=vis_results_df[('visit', 'sum')],\n                  nobs=vis_results_df[('visit', 'count')])[1]","eee2ee04":"proportions_ztest(count=con_results_df[('conversion', 'sum')],\n                  nobs=con_results_df[('conversion', 'count')])[1]","4ba438f0":"df[df['treatment']==1]['exposure'].value_counts(normalize = True)","671eade0":"vis_exp_results_df = df[df['treatment']==1].groupby('exposure').agg({'visit':['mean', 'sum', 'count']})\nvis_exp_results_df","1974235a":"con_exp_results_df = df[df['treatment']==1].groupby('exposure').agg({'conversion':['mean', 'sum', 'count']})\ncon_exp_results_df","295ee49c":"proportions_ztest(count=vis_exp_results_df[('visit', 'sum')],\n                  nobs=vis_exp_results_df[('visit', 'count')])[1]","bf9ded80":"proportions_ztest(count=con_exp_results_df[('conversion', 'sum')],\n                  nobs=con_exp_results_df[('conversion', 'count')])[1]","cad7ea65":"df[df['exposure']==0].groupby('treatment').agg({'visit':['mean', 'sum', 'count']})","eee38090":"df[df['exposure']==0].groupby('treatment').agg({'conversion':['mean', 'sum', 'count']})","b3bbc973":"fig = plt.figure(figsize = (10,6))\ntarget_count = df['treatment'].value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', int(round(target_count[1] \/ target_count[0])), ': 1')\ntarget_count.plot(kind='bar', title='Treatment Class Distribution', color=['#2077B4', '#FF7F0E'], fontsize = 15)\nplt.xticks(rotation=0) ","8b895b90":"train, test  = train_test_split(df, test_size=0.2, random_state=42, stratify=df['treatment'])","4b71567d":"# Random Undersampling (finding the majority class and undersampling it)\ndef random_under(df:pd.DataFrame, feature):\n    \n    target = df[feature].value_counts()\n    \n    if target.values[0]<target.values[1]:\n        under = target.index.values[1]\n    \n    else: \n        under = target.index.values[0]\n        \n    df_0 = df[df[feature] != under]\n    df_1 = df[df[feature] == under]\n    \n    df_treatment_under = df_1.sample(len(df_0))\n    df_1 = pd.concat([df_treatment_under, df_0], axis=0)\n    \n    return df_1","6b71ec56":"train = random_under(train, 'treatment')","d0f5f99d":"fig = plt.figure(figsize = (10,6))\nnew_target_count = train['treatment'].value_counts()\nprint('Class 0:', new_target_count[0])\nprint('Class 1:', new_target_count[1])\nprint('Proportion:', int(round(new_target_count[0] \/ new_target_count[1])), ': 1')\nnew_target_count.plot(kind='bar', title='Target Class Distribution', color=['#2077B4', '#FF7F0E'], fontsize = 15)\nplt.xticks(rotation=0) ","0abc7817":"# Function to declare Target Class\n\ndef target_class(df, treatment, target):\n    \n    #CN:\n    df['target_class'] = 0 \n    #CR:\n    df.loc[(df[treatment] == 0) & (df[target] != 0),'target_class'] = 1 \n    #TN:\n    df.loc[(df[treatment] != 0) & (df[target] == 0),'target_class'] = 2 \n    #TR:\n    df.loc[(df[treatment] != 0) & (df[target] != 0),'target_class'] = 3 \n    return df","3314d09a":"train = target_class(train.drop(columns = ['conversion', 'exposure']), 'treatment', 'visit')\ntest = target_class(test.drop(columns = ['conversion', 'exposure']), 'treatment', 'visit')","2b221402":"X_train = train.drop(['visit','target_class'],axis=1)\ny_train = train['target_class']\nX_test = test.drop(['visit','target_class'],axis=1)\ny_test = test['target_class']","49b71a36":"def uplift_model(X_train,\n                 X_test,\n                 y_train,\n                 y_test,\n                 treatment_feature):\n\n    result = pd.DataFrame(X_test).copy()    \n    uplift_model = xgb.XGBClassifier().fit(X_train.drop(treatment_feature, axis=1), y_train)\n    \n    uplift_proba = uplift_model.predict_proba(X_test.drop(treatment_feature, axis=1))\n    \n    result['p_cn'] = uplift_proba[:,0] \n    result['p_cr'] = uplift_proba[:,1] \n    result['p_tn'] = uplift_proba[:,2] \n    result['p_tr'] = uplift_proba[:,3]\n    \n    result['uplift_score'] = result.eval('\\\n    p_cn\/(p_cn + p_cr) \\\n    + p_tr\/(p_tn + p_tr) \\\n    - p_tn\/(p_tn + p_tr) \\\n    - p_cr\/(p_cn + p_cr)')  \n\n    # Put the result \n    result['target_class'] = y_test\n    \n    return result","99b66284":"result = uplift_model(X_train, X_test, y_train, y_test, 'treatment')\nresult.head()","1c0f666d":"plt.figure(figsize = (10,6))\nplt.xlim(-.05, .1)\nplt.hist(result.uplift_score, bins=1000, color=['#2077B4'])\nplt.xlabel('Uplift score')\nplt.ylabel('Number of observations in validation set')","0fe46941":"def qini_rank(uplift): \n    # Function to Rank the data by the uplift score\n    ranked = pd.DataFrame({'ranked uplift':[], 'target_class':[]})\n    ranked['target_class'] = uplift['target_class']\n    ranked['uplift_score'] = uplift['uplift_score']\n    ranked['ranked uplift'] = ranked.uplift_score.rank(pct=True, ascending=False)\n    # Data Ranking   \n    ranked = ranked.sort_values(by='ranked uplift').reset_index(drop=True)\n    return ranked\n\ndef qini_eval(ranked):\n    uplift_model, random_model = ranked.copy(), ranked.copy()\n    # Using Treatment and Control Group to calculate the uplift (Incremental gain)\n    C, T = sum(ranked['target_class'] <= 1), sum(ranked['target_class'] >= 2)\n    ranked['cr'] = 0\n    ranked['tr'] = 0\n    ranked.loc[ranked.target_class == 1,'cr'] = 1\n    ranked.loc[ranked.target_class == 3,'tr'] = 1\n    ranked['cr\/c'] = ranked.cr.cumsum() \/ C\n    ranked['tr\/t'] = ranked.tr.cumsum() \/ T\n    # Calculate and put the uplift and random value into dataframe\n    uplift_model['uplift'] = round(ranked['tr\/t'] - ranked['cr\/c'],5)\n    random_model['uplift'] = round(ranked['ranked uplift'] * uplift_model['uplift'].iloc[-1],5)\n    \n    uplift_model['Number_of_exposed_customers'] = np.arange(len(uplift_model))+1\n    uplift_model['visits_gained'] = uplift_model.uplift*len(uplift_model)\n    \n    # Add q0\n    q0 = pd.DataFrame({'ranked uplift':0, 'uplift':0, 'target_class': None}, index =[0])\n    uplift_model = pd.concat([q0, uplift_model]).reset_index(drop = True)\n    random_model = pd.concat([q0, random_model]).reset_index(drop = True)  \n    # Add model name & concat\n    uplift_model['model'] = 'Uplift model'\n    random_model['model'] = 'Random model'\n    merged = pd.concat([uplift_model, random_model]).sort_values(by='ranked uplift').reset_index(drop = True)\n    return merged, uplift_model\n\ndef uplift_curve(uplift_model):\n    plt.figure(figsize = (10,6))\n    # plot the data\n    ax = uplift_model['visits_gained'].plot(color=['#2077B4'])\n    # Plot settings\n    sns.set_style('whitegrid')\n    handles, labels = ax.get_legend_handles_labels()\n    plt.xlabel('Number of customers treated')\n    plt.ylabel('Incremental visits')\n    plt.grid(b=True, which='major')\n    return ax\n\ndef qini_plot(merged:pd.DataFrame, uplift_model:pd.DataFrame):\n    gain_x = uplift_model['ranked uplift']\n    gain_y = uplift_model.uplift\n    qini = auc(gain_x, gain_y)\n    # plot the data\n    plt.figure(figsize = (10,6))\n    mpl.rcParams['font.size'] = 8\n    qini = auc(gain_x, gain_y)\n\n    ax = plt.plot(gain_x, gain_y, color= '#2077B4',\n        label='Normalized Uplift Model, Qini Score: {}'.format(round(qini,2)))\n    \n    plt.plot([0, gain_x.max()], [0, gain_y.max()],\n        '--', color='tab:orange',\n        label='Random Treatment')\n    plt.legend()\n    plt.xlabel('Porportion Targeted')\n    plt.ylabel('Uplift')\n    plt.grid(b=True, which='major')\n\n    return ax\n\ndef plot_uplift(result:pd.DataFrame):\n    # Function to plot the uplift curve\n    ranked = qini_rank(result)\n    merged, uplift_model = qini_eval(ranked)\n    ax1 = uplift_curve(uplift_model)\n    \n    return ax1\n\ndef plot_qini(result:pd.DataFrame):\n    # Function to plot the qini curve\n    ranked = qini_rank(result)\n    merged, uplift_model = qini_eval(ranked)\n    ax2 = qini_plot(merged, uplift_model)\n    \n    return ax2 ","195e3ea2":"plot_uplift(result)","bbd56388":"plot_qini(result)","e09f560c":"plt.figure(figsize = (10,6))\ntarget_count = df['exposure'].value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', int(round(target_count[0] \/ target_count[1])), ': 1')\ntarget_count.plot(kind='bar', title='Exposure Distribution', color=['#2077B4', '#FF7F0E'], fontsize = 15)\nplt.xticks(rotation=0) \nplt.show()","7335110f":"train, test  = train_test_split(df, test_size=0.2, random_state=42, stratify=df['exposure'])","f2553313":"train = random_under(train, 'exposure')","7843de81":"plt.figure(figsize = (10,6))\nnew_target_count = train['exposure'].value_counts()\nprint('Class 0:', new_target_count[0])\nprint('Class 1:', new_target_count[1])\nprint('Proportion:', int(round(new_target_count[0] \/ new_target_count[1])), ': 1')\nnew_target_count.plot(kind='bar', title='Exposure Class Distribution', color=['#2077B4', '#FF7F0E'], fontsize = 15)\nplt.xticks(rotation=0) ","4ebbf220":"train = target_class(train.drop(columns = ['conversion', 'treatment']), 'exposure', 'visit')\ntest = target_class(test.drop(columns = ['conversion', 'treatment']), 'exposure', 'visit')","b5ab337e":"X_train = train.drop(['visit','target_class'],axis=1)\ny_train = train['target_class']\nX_test = test.drop(['visit','target_class'],axis=1)\ny_test = test['target_class']","0bc4ea83":"result = uplift_model(X_train, X_test, y_train, y_test, 'exposure')","3cc542d1":"plt.figure(figsize = (10,6))\nplt.hist(result.uplift_score, bins=100, color=['#2077B4'])\nplt.xlabel('Uplift score')\nplt.ylabel('Number of observations in validation set')","b88055e0":"plot_uplift(result)","a811d6d0":"plot_qini(result)","df328077":"The dataset is largely imbalanced - around 85% of users were treated while only 15% were in the control group.\n\n# Basic Eda","4de8e915":"As can be seen, when users are properly exposed to the treatment, the incremental positive outcomes or uplift is much higher. If we offer the treatment to every customer, we\u2019ll increase the number of visitors by 1,060,000. However we can achieve a gain of 620,000 customers, about 58% of the maximum possible, by only offering treatment to the top 20% of customers. Given the different magnitude of customers, in order to compare this model to our previous one, we must once again normalize our results. ","8ec29c99":"There is a substantially higher clickthrough rate for treated users that were exposed (41%) than treated users that were not (3.5%). Similar results were found for conversion, with 5.3% of exposed users converting compared to only 0.12% of treated users that were not . These results, together with the p-value's (<0.5) suggest the intervention is having a significant impact, but is not being exposed to enough people. Lets see if theres any effect not being exposed has on the treatment group.","fb577d66":"## Dataset\n\nNow that we know the goal of uplift modeling, how do we get there? A typical starting point for building an uplift model is a dataset from a randomized, controlled experiment: we need a representative sample of all different kinds of customers in both a treatment group, as well as a control group that didn\u2019t receive the treatment. If the proportion of customers making a purchase is significantly higher in the treatment group than the control group, we know that the promotion is \u201cworking\u201d since it encourages a purchase on average across all customers. This is called the average treatment effect (ATE). Quantifying the ATE is the typical outcome of an A\/B test.\n\nI use an anonymised dataset published by The Criteo AI Lab which is available [here][1]. The dataset is constructed from an incrementality tests, a particular randomized trial procedure where an advertiser prevents a random part of the population from being targeted by advertising. It consists of 13M rows, each one representing a user with 12 features, a treatment indicator and 2 labels (visits and conversions). \n\nA more detailed description of the features is shown below:\n* f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11: feature values (dense, float)\n* treatment: treatment group (1 = treated, 0 = control)\n* conversion: whether a conversion occured for this user (binary, label)\n* visit: whether a visit occured for this user (binary, label)\n* exposure: treatment effect, whether the user has been effectively exposed (binary)\n\nIn real data, the features may correspond to such things as customer purchase history, demographics, and other quantities a data scientist may engineer with the hypothesis that they would be useful in modeling uplift.\n\nLet\u2019s load the data and briefly explore it.\n\n[1]: https:\/\/www.kaggle.com\/arashnic\/uplift-modeling\/","ffed19c3":"Only 3.6% or 1 out of every 28 users in our treatment group were effectively exposed to the treatment, suggesting the treatment is very ineffective at capturing the attention of the users. \n\nHow does the number of users that visit and convert differ between treated users that were exposed, and those that were not?","c4931f56":"As can be seen, the Qini-score is roughly x29 better than the previous model suggesting the cumulative number of the incremental positive outcomes is much larger providing users are effectively exposed. \n\n# Conclusion\n\nThe goal of uplift modeling is to create predictive models of the individual treatment effect. Such models allow data scientists to segment populations into groups that are more likely to respond to treatment, and those that are less so. In this example, the effect of properly exposing users to the treatment  is shown to significantly increase the incremental outcomes compared to the normal treatment group. As can be seen the evaluation of uplift models is not as straightforward as that of supervised classification or regression models because it requires separate consideration, and comparison, of treatment and control groups. However, open source Python packages ([CausalML](http:\/\/https:\/\/causalml.readthedocs.io\/en\/latest\/), [Pylift](http:\/\/https:\/\/pylift.readthedocs.io\/), [Scikit-Uplift](http:\/\/https:\/\/scikit-uplift.readthedocs.io\/en\/latest\/)), have been created to facilitate uplift model development and evaluation. \n\n\n<b> Some resources that helped me and I recommend taking a look at if you're interested in finding out more: <\/b>\n\nGubela, Robin & Bequ\u00e9, Artem & Gebert, Fabian & Lessmann, Stefan. (2019). Conversion Uplift in E-Commerce: A Systematic Benchmark of Modeling Strategies. International Journal of Information Technology & Decision Making. 18. 10.1142\/S0219622019500172.  \n\nGutierrez, P., & G\u00e9rardy, J. Y. (2017, July). Causal Inference and Uplift Modelling: A Review of the Literature. In International Conference on Predictive Applications and APIs (pp. 1-13). \n\nCheng, L., Leung, A. C. S., & Ozawa, S. (Eds.). (2018). Neural Information Processing. Lecture Notes in Computer Science. doi:10.1007\/978-3-030-04221-9  \n\nhttps:\/\/www.steveklosterman.com\/uplift-modeling\/\n\nThis notebook adapts some of the functions provided in this notebook:\nhttps:\/\/www.kaggle.com\/arashnic\/uplift-modeling\n\n\n\n","1adfe5c8":"The distribution of uplift is mostly positive, which makes sense since we know from our analysis that the treatment encourages visits on average. However some instances have negative uplift, meaning the treatment actually discourages individuals from visiting ('sleeping dogs'). Going back to our previous analyses, this could be the individuals who were not properly exposed to the treatment, which we found to decrease clickthrough & conversion.\n\n# Model evaluation\n\nMetrics for evaluating uplift are more complex than typical metrics used in supervised learning, such as the ROC AUC. This is because it is not possible to observe both the control and the treatment outcomes for a given individual at the same time, which makes it dicult to find a loss measure. One way to measure uplift is using a Qini curve (Radcliffe, 2007), which shows the cumulative number of the incremental positive outcomes or uplift as a function of the number of customers treated. A more performant model can distinguish individuals with positive outcomes from individuals with negative outcomes, yielding a larger separation between the curve and the diagonal, which would represent a random targeting strategy.","64b8df00":"Much like in the previous example, the treatment class is highly imbalanced, with roughly 1 in every 32 users being exposed to the treatment. ","d5a81108":"As can be seen, the new training dataset has a total of 3,355,100 instances with 50% in the treatment and 50% in the control groups.\n\n# Uplift Modelling\nThe Uplift model used in this notebook is the Generalized Weighed Uplift (LGWUM) (Kane et al., 2014). LGWUM is one of several methods available for Uplift Modeling, and uses an approach to Uplift Modelling better known as Class Variable Transformation. LGWUM assumes that positive uplift lies in treating treatment-group responders (TR) and control-group non-responders (CN), whilst avoiding treatment-group non-responders (TN) and control-group responders (CR). This is visually shown as:\n\n\ud835\udc48\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc53\ud835\udc61 \ud835\udc3f\ud835\udc3a\ud835\udc4a\ud835\udc48\ud835\udc40 = P(TR)\/P(T) + P(CN)\/P(C) - P(TN)\/P(T) - P(CR)\/P(C)","40c7fe83":"The distribution of uplift is almost entirely positive, meaning the treatment almost always encourages individuals to visit when they are properly exposed, and almost never discouraging them.","fded1848":"While the model appears to be able to distinguish positive from negative outcomes as shown by its steep initial slope, the Qini-score is only 0.01, suggesting the total incremental positive outcomes from the treatment is low and that actually there is little difference between this treatment and a random targeting strategy.\n\nIt is worth considering what impact a user being properly exposed has on their incremental outcomes. This will be explored by calling the pre-defined functions from above while changing the treatment classes to 'exposure'.","b5e6d47d":"The p-value is <0.05 for both, so we know the ATE is significant - which is the typical starting point for uplift modeling.\n\nIt is worth pointing out that there is another variable called 'exposure' which indicates whether a treatment was properly exposed to the user. This is important because a user that is treated might still carry out an desired action (clicking, purchasing etc..) without actually being influenced by the treatment. It would be interesting to see whether there is a big differences in outcomes depending on whether a user was effectively exposed.\n\nFirst of all, how many users in the treatment group were exposed?","aef37e87":"Incredibly, the percentage of users that convert and visit in the treatment actually declines if they are not exposed, meaning the ATE is negative. In a real life scenario, this would need to be addressed.\n\n\n# Resampling\nIn thise case, I will be focusing my uplift models on the incremental number of visits due to the number of users that do not convert. Before proceeding with modelling, it is worth considering any imbalance in the dataset and addressing it accordingly.","da6e41a1":"The model works by predicting the probability that a given customer belongs to each  classes. The uplift can then be calculated as the differences between these probabilities.","a00c1be3":"# Introduction\n\n<i>This is my first attempt at exploring uplift modelling, any comments, feedback, or suggestions would be greatly appreciated.<\/i>\n\nUplift modelling is an important area of research which aims to estimate the causal impact of some treatment on an individual's behaviour. The model predicts the difference between a customer\u2019s behaviour when there is a treatment and when there is no treatment. In the digital advertising industry, for example, this treatment could be exposure to different ads and uplift modelling could then be used to direct marketing efforts towards users for whom this intervention is most efficient. This is important because some customers will naturally respond to treatments in different ways:\n\n* <b>Persuadables<\/b> will always respond POSITIVE to the marketing communication. They are going to purchase ONLY if treated.\n* <b>Do-Not-Disturbs <\/b> (a.k.a. Sleeping-dogs) have a strong negative response to a marketing communication. They are going to purchase if NOT treated and will NOT purchase IF treated.\n* <b>Lost Causes <\/b> will NOT purchase the product NO MATTER they are contacted or not. The marketing budget in this case is also wasted because it has no effect.\n* <b>Sure Things <\/b> will purchase ANYWAY no matter they are contacted or not. There is no motivation to spend the budget because it also has no effect.\n\nThe goal of uplift modelling, therefore, is to identify the \u201cpersuadables\u201d, not waste efforts on \u201csure things\u201d and \u201clost causes\u201d, and avoid bothering \u201csleeping dogs\u201d, or those who would react negatively to the treatment, if they exist. Uplift modelling has found application in many domains including marketing, medical treatments and political campaigns.","fb42762b":"If we offer the treatment to every customer (2,500,000), we\u2019ll increase the number of visitors by 30,000. However we can achieve a gain of 26,000 customers, about 86% of the maximum possible, by only offering treatment to the top 20% of customers. \nOne advantage of the uplift curve, however, is that similar to the ROC curve, we can calculate an area under the curve, with the interpretation that larger area indicates a better performing model: we would like to be able to gain as many customers as possible, by targeting a few as possible. \n\nBefore calculating an AUC, it is better to normalize the data. As shown, the gain curve has units of customers on both the x- and y-axes which can be good for visualizing things in real-world quantities however it makes comparing different models very difficult. We can fix this by scaling the curve so that the axes are between 0 and 1. ","8a16d4d6":"Again, the 2 binary labels (visits and conversions) are both highly imbalanced but how do these metrics compare between the control and the treatment groups?","b63c16dc":"By seeing the distributions we can have an idea how skewed the target variable is - most of the users were in the treatment group. The problem is that many approaches uplift models assume the treatment group and the control group have a balanced distribution, which needs not hold in practice. In this case we may reweight, or resample, the training datasets such that the assumption becomes valid. According to Ja\u015bkowski and Jaroszewicz (2012) resampling the treatment distribution can affect the learning algorithm and result in information loss, however, as long as the algorithm does a reasonably good job at modeling the conditional class distributions, the results will still be meaningful. As our dataset consists of 13M rows, we can be fairly confident any resampled dataset will contain enough instances to provide meaningful results.\n\nBefore proceeding with the random undersampling we have to separate the orginal dataframe so that the undersampling is only done on the training dataset. Why? for testing purposes, we want to test our models on a dataset with real life class distributions.","de2c0738":"More users visit in the treatment (4.9%) than the control group (3.8%), indicating the treatment is effective at encouraging users to visit: the ATE is positive and is about 1%. This increase in visits also yields a higher conversion rate in the treatment group (0.31%) compared to the control group (0.19%). \n\nAs the difference is not so large, a significance test is conducted."}}