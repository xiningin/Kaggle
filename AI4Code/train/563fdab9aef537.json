{"cell_type":{"099a17aa":"code","20472fc0":"code","4bcc7b83":"code","b6a1b5d7":"code","0236fcb9":"code","e78ed97e":"code","742f1499":"code","24d13b4a":"code","760cb607":"code","83569bf0":"code","76bbbb6b":"code","8c0cbd57":"code","5c0d162f":"markdown"},"source":{"099a17aa":"import os\nimport matplotlib.pyplot as pyp\nimport numpy","20472fc0":"def dataloader( train_or_val ):    \n    X_cnn = []\n    X_flat = []\n    Y = []\n    if train_or_val == 'T':\n        path = \"..\/input\/fliker-face-gender\/aligned\/\"\n    elif train_or_val == 'V':\n        path = \"..\/input\/gender-face-validation\/valid\/\"\n    folder_list = sorted(os.listdir(path))\n    for folder in folder_list:\n        img_name_list = sorted(os.listdir(path+folder))\n        for img_name in img_name_list:\n            ax = pyp.imread(path+folder+'\/'+img_name)\n            X_cnn.append(ax)\n            X_flat.append(ax.flatten())\n            if folder[3] == 'F':\n                Y.append([1])\n            elif folder[3] == 'M':\n                Y.append([0])\n    X_cnn = numpy.array(X_cnn)\n    X_flat = numpy.array(X_flat)\n    Y = numpy.array(Y)    \n    m = Y.shape[0]    \n    permutation = list(numpy.random.permutation(m))\n    X_cnn = X_cnn[permutation,:]\n    X_flat = X_flat[permutation,:]\n    Y = Y[permutation,:]    \n    return X_flat, X_cnn, Y ","4bcc7b83":"X_train_flattened, X_train_cnn, Y_train = dataloader('T')\nX_val_flattened, X_val_cnn, Y_val = dataloader('V')","b6a1b5d7":"print(\"number of training examples = \" + str(X_train_cnn.shape[0]))\nprint(\"number of test examples = \" + str(X_val_cnn.shape[0]))\nprint('\\nTrain datasets shape')\nprint(X_train_cnn.shape,'<-- Dataset format for fitting a CNN')\nprint(X_train_flattened.shape,'<-- Dataset format for fitting a fully connected')\nprint(Y_train.shape,'<-- Target variable')\nprint('\\nValidation datasets shape:\\n')\nprint(X_val_cnn.shape,'<-- Dataset format for fitting a CNN')\nprint(X_val_flattened.shape,'<-- Dataset format for fitting a fully connected')\nprint(Y_val.shape,'<-- Target variable')","0236fcb9":"index = 135\npyp.imshow(X_train_cnn[index])\nprint (\"sample image y = \" + str(numpy.squeeze(Y_train[index,:])))","e78ed97e":"from keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport keras.backend as K\nK.set_image_data_format('channels_last')","742f1499":"def GenderModel(input_shape):\n    X_input = Input(input_shape)\n    X = ZeroPadding2D((3, 3))(X_input)\n    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n    X = BatchNormalization(axis=3, name='bn0')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((2, 2), name='max_pool')(X)\n    X = Flatten()(X)\n    X = Dense(1, activation='sigmoid', name='fc')(X)\n    model = Model(inputs=X_input, outputs=X, name='GenderModel')\n    return model","24d13b4a":"GenderModel = GenderModel(X_train_cnn.shape[1:])\nGenderModel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\nGenderModel.fit(X_train_cnn, Y_train, epochs=20, batch_size=16)","760cb607":"preds = GenderModel.evaluate(X_val_cnn, Y_val, batch_size=16, verbose=1, sample_weight=None)\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","83569bf0":"GenderModel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'","76bbbb6b":"GenderModel.summary()","8c0cbd57":"plot_model(GenderModel, to_file='GenderModel.png')","5c0d162f":"The objective of this kernel is to train a simple CNN model to predict gender from face images. The training dataset consists of 29437 RGB images of human faces of different ages with 128 by 128 resolution. The network architecture includes a single layer of convolution with padding, local normalization, max pooling, and the relu activation. Mini-batch Adam optimizer is used to minimize the cross-entropy cost function. The model performance on the training and the test datasets along with the CNN architecture are provided at the end of the kernel. First, data are fetched from different folders."}}