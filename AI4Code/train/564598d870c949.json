{"cell_type":{"26b5eb3e":"code","51b065dd":"code","15126bee":"code","dde17d90":"code","082d4599":"code","550cf453":"code","b3c9723f":"code","74f60a74":"code","fa0de961":"code","58720540":"code","92826572":"code","087b2f41":"code","8757e5b8":"code","44587dd0":"code","18d6b582":"code","dc3e924c":"code","43da7a74":"code","5bdaf9a6":"code","95af8181":"code","3b49d889":"code","a632b9b7":"code","09b63d07":"code","87434c16":"code","01521865":"code","8fab1703":"code","3bacad9e":"code","6582a9a6":"code","c4e8693a":"code","65072827":"code","98004dfd":"code","034b8528":"code","6ff3df82":"code","f8cacf2f":"code","6fe07e22":"code","e3eb0975":"code","615d106d":"code","55c22e4d":"code","da84094f":"code","dce5311c":"code","0c46811d":"code","df110ab3":"code","b5ae9e7b":"code","96b3f05e":"code","6408f7d2":"code","cf2f5c57":"code","0c9b57a6":"code","88c1bc16":"code","530c3def":"code","0f56bb19":"code","98918262":"code","fb1968dd":"code","d1c04171":"code","1e64f444":"code","e01ec0b7":"code","3ba33e8f":"code","db69064e":"code","1f09eb52":"code","5362917e":"code","c2b11dd8":"code","69037ed8":"code","fa427775":"code","13774d47":"code","26c260e7":"code","b05868d4":"code","e726c537":"code","1b7aacfc":"code","d293153b":"code","28faacad":"code","64bf4444":"code","e48240ba":"code","8903d732":"code","cea2ab27":"code","1abb6a04":"markdown","85ce59d7":"markdown","752a07b2":"markdown","3b161160":"markdown","93f5f6de":"markdown","954e045e":"markdown","da0c8ed2":"markdown","d4d5b72e":"markdown","06a9f10d":"markdown","b3bafdc1":"markdown","60df0152":"markdown","313b9be7":"markdown","3d500e4b":"markdown","17232920":"markdown","dd291e73":"markdown","4abcd412":"markdown","6427201b":"markdown","fe347e57":"markdown","3ad8f55b":"markdown","c927e825":"markdown","ff792a45":"markdown","8a08ce74":"markdown","083e9abe":"markdown","63dd98a1":"markdown","e36bb4c4":"markdown","9164141d":"markdown","aa220db7":"markdown","4891aeee":"markdown","bdcec27b":"markdown","563a72c3":"markdown","3d99c91e":"markdown","2e9d0d64":"markdown","42aece10":"markdown","4b61e72f":"markdown","71058675":"markdown","70f84d2d":"markdown","572b586d":"markdown","5c273c90":"markdown","4c7adde5":"markdown","d36fc713":"markdown","575ce098":"markdown","91109508":"markdown"},"source":{"26b5eb3e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as pylab \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom scipy import stats \nfrom sklearn import metrics as mt\n\n%matplotlib inline\npylab.rcParams['figure.figsize'] = 6,4\n\n# Ignorar warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","51b065dd":"# Seleccion de Variables a usar en este BASELINE:\nfeatures_iniciales = ['ID',\n 'Sexo',\n 'AdultoMayor',\n 'MesesCliente',\n 'ServicioTelefonico',\n 'LineasMultiples',\n 'ProteccionDispositivo',\n 'SoporteTecnico',\n 'FacturacionElectronica',\n 'MontoCargadoMes']","15126bee":"import os\nprint(os.listdir(\"..\/input\"))","dde17d90":"# Import from\n\npath = \"..\/input\/\"\ndf_train = pd.read_csv(path+\"churn_data_train.csv\",encoding='latin-1', usecols=features_iniciales+['Churn'])\ndf_test = pd.read_csv(path+\"churn_data_test.csv\",encoding='latin-1', usecols=features_iniciales)","082d4599":"df_train.shape, df_test.shape","550cf453":"df_train.head()","b3c9723f":"df_test.head()","74f60a74":"df_train.info()","fa0de961":"df_test.info()","58720540":"# Defining features types\nID = 'ID'\nTARGET = 'Churn'","92826572":"# Distribuci\u00f3n del Target\ndf_train[TARGET].value_counts(dropna=False)","087b2f41":"df_train[TARGET].value_counts(dropna=False, normalize = True)*100","8757e5b8":"# Generar estadisticos b\u00e1sicos para cada variable:\n### count: Count number of non-NA\/null observations.\t\n### unique: Count uniques numbers of non-NA\/null observations.\n### top: Mean of the values.\n### freq: Mean of the values.\n\n### mean: Mean of the values.\n### std: Standard deviation of the observations.\n\n### min: Minimum of the values in the object.\n### X%: The value of Quartil: 25% - Q1 , 50% - Q2, 75% - Q3\n### max: Maximum of the values in the object.\n\ndf_train['AdultoMayor'] = df_train['AdultoMayor'].astype(str) # Convertir a variable categorica\ndf_train.describe(include = 'all').T","44587dd0":"df_train['AdultoMayor'] = df_train['AdultoMayor'].astype(float) # Convertir a variable numerica","18d6b582":"import missingno as msno\nmsno.matrix(df_train)","dc3e924c":"msno.matrix(df_test)","43da7a74":"None","5bdaf9a6":"None","95af8181":"# Copy dataset and then apply transformation to copied dataset\nds_train = df_train.copy()","3b49d889":"ds_test = df_test.copy()","a632b9b7":"# AdultoMayor (imputacion por MODA)\nds_train[\"AdultoMayor\"].fillna(0, inplace = True)\nds_test[\"AdultoMayor\"].fillna(0, inplace = True)\n\n# MesesCliente (imputacion por MEDIA)\nds_train[\"MesesCliente\"].fillna(32, inplace = True)\nds_test[\"MesesCliente\"].fillna(32, inplace = True)\n\n# ProteccionDispositivo (imputacion por MODA)\nds_train[\"ProteccionDispositivo\"].fillna('No', inplace = True)\nds_test[\"ProteccionDispositivo\"].fillna('No', inplace = True)\n\n# SoporteTecnico (imputacion por MODA)\nds_train[\"SoporteTecnico\"].fillna('No', inplace = True)\nds_test[\"SoporteTecnico\"].fillna('No', inplace = True)\n\n# FacturacionElectronica (imputacion por MODA)\nds_train[\"FacturacionElectronica\"].fillna('Si', inplace = True)\nds_test[\"FacturacionElectronica\"].fillna('Si', inplace = True)\n\n# MontoCargadoMes (imputacion por MEDIA)\nds_train[\"MontoCargadoMes\"].fillna(68.7, inplace = True)\nds_test[\"MontoCargadoMes\"].fillna(68.7, inplace = True)","09b63d07":"None","87434c16":"ds_train.head()","01521865":"# Sexo \ndicc_sexo = {'Masculino': 1, 'Femenino':0 }\nds_train[\"Sexo\"] = ds_train[\"Sexo\"].map(dicc_sexo)\nds_test[\"Sexo\"] = ds_test[\"Sexo\"].map(dicc_sexo)","8fab1703":"# ServicioTelefonico \ndicc_serv_telef = {'Si': 1, 'No':0 }\nds_train[\"ServicioTelefonico\"] = ds_train[\"ServicioTelefonico\"].map(dicc_serv_telef)\nds_test[\"ServicioTelefonico\"] = ds_test[\"ServicioTelefonico\"].map(dicc_serv_telef)","3bacad9e":"# LineasMultiples \ndicc_lin_mult = {'Si': 2, 'No':1, 'Sin servicio telefonico':0 }\nds_train[\"LineasMultiples\"] = ds_train[\"LineasMultiples\"].map(dicc_lin_mult)\nds_test[\"LineasMultiples\"] = ds_test[\"LineasMultiples\"].map(dicc_lin_mult)","6582a9a6":"# FacturacionElectronica \ndicc_fact_elect = {'Si': 1, 'No':0 }\nds_train[\"FacturacionElectronica\"] = ds_train[\"FacturacionElectronica\"].map(dicc_fact_elect)\nds_test[\"FacturacionElectronica\"] = ds_test[\"FacturacionElectronica\"].map(dicc_fact_elect)","c4e8693a":"# Crear Features Dummies\nds_train.loc[ds_train['ProteccionDispositivo']=='Sin servicio de internet', 'ProteccionDispositivo'] = 'SinServInter'\nds_train.loc[ds_train['SoporteTecnico']=='Sin servicio de internet', 'SoporteTecnico'] = 'SinServInter'\n\nds_test.loc[ds_test['ProteccionDispositivo']=='Sin servicio de internet', 'ProteccionDispositivo'] = 'SinServInter'\nds_test.loc[ds_test['SoporteTecnico']=='Sin servicio de internet', 'SoporteTecnico'] = 'SinServInter'\n\nds_train = pd.get_dummies(ds_train, columns=['ProteccionDispositivo','SoporteTecnico'])\nds_test = pd.get_dummies(ds_test, columns=['ProteccionDispositivo','SoporteTecnico'])","65072827":"ds_train.head()","98004dfd":"# New Feature 1\ntmp_byAdultoMayor_medianMontoMes = ds_train.groupby(['AdultoMayor'])['MontoCargadoMes'].median().round()\ntmp_byAdultoMayor_medianMontoMes","034b8528":"ds_train['flg_bySexo_mayorMedianMontoMes'] = ds_train.apply(lambda x: 1 if x.MontoCargadoMes >= tmp_byAdultoMayor_medianMontoMes[x.AdultoMayor] else 0,\n                                                       axis = 1)\n\nds_test['flg_bySexo_mayorMedianMontoMes'] = ds_test.apply(lambda x: 1 if x.MontoCargadoMes >= tmp_byAdultoMayor_medianMontoMes[x.AdultoMayor] else 0,\n                                                       axis = 1)","6ff3df82":"ds_train.head(10)","f8cacf2f":"# New Feature 2,3,4, ...\n### Here","6fe07e22":"features_to_model = list(ds_train.columns)\n\nfeatures_to_model.remove(TARGET) # Eliminar variable Target\nfeatures_to_model.remove(ID) # Eliminar variable ID\n\nlist(features_to_model)","e3eb0975":"# Selecci\u00f3n de variables. \n### Una opci\u00f3n es: en base a un modelo basado en \u00e1rboles, generar la importancia de Variables y seleccionar los features mas importantes.\nfeatures_to_model = features_to_model # ['var1', 'var2', 'varn'] ","615d106d":"len(features_to_model)","55c22e4d":"# Features & Target\nX = ds_train[features_to_model]\ny = ds_train[TARGET]\n\nX_summit = ds_test[features_to_model]","da84094f":"print(\"train: \", X.shape,\", summit: \", X_summit.shape)","dce5311c":"from sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.70, random_state=9)\nprint((len(X_train), len(y_train)), (len(X_test), len(y_test)))","0c46811d":"X_train.info()","df110ab3":"from sklearn.linear_model import LogisticRegression","b5ae9e7b":"# Create  model objet \nmodel_rlog = LogisticRegression(C=0.01, max_iter= 100, random_state=0, n_jobs = 4, penalty = 'l1')\n\n# Fit the model:\nmodel_rlog.fit(X_train, y_train)\n\nmodel = model_rlog ","96b3f05e":"df_weights = pd.DataFrame({'feature':X_train.columns.values, 'beta': np.round(model_rlog.coef_[0],4) })\ndf_weights","6408f7d2":"# Generar las predicciones:\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\n\n# Generar las probabilidades\ny_pred_proba_train = model.predict_proba(X_train)[:,1]\ny_pred_proba_test = model.predict_proba(X_test)[:,1]","cf2f5c57":"accuracy_train = mt.accuracy_score(y_train, y_pred_train)\naccuracy_test = mt.accuracy_score(y_test, y_pred_test)\n\nprint(\"Accuracy - Train: {}\".format(accuracy_train))\nprint(\"Accuracy - Test : {}\".format(accuracy_test))","0c9b57a6":"list_accuracy_test = []\nfor threshold in range(0,100):\n  pred_0_1 = [1 if x >= threshold\/100 else 0 for x in y_pred_proba_test]\n  list_accuracy_test.append(mt.accuracy_score(y_test, pred_0_1))","88c1bc16":"xs = [x\/100 for x in range(0,100)]\nys = list_accuracy_test\nplt.plot(xs, ys)","530c3def":"best_scoring = max(list_accuracy_test)\nbest_threshold = list_accuracy_test.index(best_scoring)\/100\nprint(\"El mejor threshold es: {}\".format(best_threshold))","0f56bb19":"accuracy_train = mt.accuracy_score(y_train, [1 if x >= best_threshold else 0 for x in y_pred_proba_train])\naccuracy_test = mt.accuracy_score(y_test, [1 if x >= best_threshold else 0 for x in y_pred_proba_test])\n\nprint(\"Accuracy - Train: {}\".format(accuracy_train))\nprint(\"Accuracy - Test : {}\".format(accuracy_test))","98918262":"from sklearn.tree import DecisionTreeClassifier\nDecisionTreeClassifier()","fb1968dd":"# Create  model objet \nmodel_tree = DecisionTreeClassifier(max_depth=6, min_samples_leaf=5,random_state=0)\n\n# Fit the model:\nmodel_tree.fit(X_train, y_train)\n\nmodel = model_tree","d1c04171":"# Generar las predicciones:\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\n\n# Generar las probabilidades\ny_pred_proba_train = model.predict_proba(X_train)[:,1]\ny_pred_proba_test = model.predict_proba(X_test)[:,1]","1e64f444":"accuracy_train = mt.accuracy_score(y_train, y_pred_train)\naccuracy_test = mt.accuracy_score(y_test, y_pred_test)\n\nprint(\"Accuracy - Train: {}\".format(accuracy_train))\nprint(\"Accuracy - Test : {}\".format(accuracy_test))","e01ec0b7":"list_accuracy_test = []\nfor threshold in range(0,100):\n  pred_0_1 = [1 if x >= threshold\/100 else 0 for x in y_pred_proba_test]\n  list_accuracy_test.append(mt.accuracy_score(y_test, pred_0_1))","3ba33e8f":"xs = [x\/100 for x in range(0,100)]\nys = list_accuracy_test\nplt.plot(xs, ys)","db69064e":"best_scoring = max(list_accuracy_test)\nbest_threshold = list_accuracy_test.index(best_scoring)\/100\nprint(\"El mejor threshold es: {}\".format(best_threshold))","1f09eb52":"accuracy_train = mt.accuracy_score(y_train, [1 if x >= best_threshold else 0 for x in y_pred_proba_train])\naccuracy_test = mt.accuracy_score(y_test, [1 if x >= best_threshold else 0 for x in y_pred_proba_test])\n\nprint(\"Accuracy - Train: {}\".format(accuracy_train))\nprint(\"Accuracy - Test : {}\".format(accuracy_test))","5362917e":"df_feature_importances = pd.DataFrame()\ndf_feature_importances['feature'] = X_train.columns\ndf_feature_importances['importance'] = model.feature_importances_\/model.feature_importances_.sum()\ndf_feature_importances = df_feature_importances.sort_values(by = ['importance','feature'],ascending=False)\ndf_feature_importances.reset_index(drop = True,inplace=True)\n\ndf_feature_importances","c2b11dd8":"df_feature_importances[['feature','importance']].sort_values(by=['importance'],\n                                                             ascending = [True]).plot(kind='barh',\n                                                             x='feature',\n                                                             y='importance',\n                                                             legend=True, \n                                                             figsize=(5, 5))","69037ed8":"from sklearn.ensemble import RandomForestClassifier\nRandomForestClassifier()","fa427775":"# Create  model objet \nmodel_rf = RandomForestClassifier(n_estimators = 150, random_state = 0, max_depth=5, \n                                  max_features = 0.5, min_samples_leaf = 10, \n                                  n_jobs = -1)\n\n# Fit the model:\nmodel_rf.fit(X_train, y_train)\n\nmodel = model_rf","13774d47":"# Generar las predicciones:\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\n\n# Generar las probabilidades\ny_pred_proba_train = model.predict_proba(X_train)[:,1]\ny_pred_proba_test = model.predict_proba(X_test)[:,1]","26c260e7":"accuracy_train = mt.accuracy_score(y_train, y_pred_train)\naccuracy_test = mt.accuracy_score(y_test, y_pred_test)\n\nprint(\"Accuracy - Train: {}\".format(accuracy_train))\nprint(\"Accuracy - Test : {}\".format(accuracy_test))","b05868d4":"list_accuracy_test = []\nfor threshold in range(0,100):\n  pred_0_1 = [1 if x >= threshold\/100 else 0 for x in y_pred_proba_test]\n  list_accuracy_test.append(mt.accuracy_score(y_test, pred_0_1))","e726c537":"xs = [x\/100 for x in range(0,100)]\nys = list_accuracy_test\nplt.plot(xs, ys)","1b7aacfc":"best_scoring = max(list_accuracy_test)\nbest_threshold = list_accuracy_test.index(best_scoring)\/100\nprint(\"El mejor threshold es: {}\".format(best_threshold))","d293153b":"accuracy_train = mt.accuracy_score(y_train, [1 if x >= best_threshold else 0 for x in y_pred_proba_train])\naccuracy_test = mt.accuracy_score(y_test, [1 if x >= best_threshold else 0 for x in y_pred_proba_test])\n\nprint(\"Accuracy - Train: {}\".format(accuracy_train))\nprint(\"Accuracy - Test : {}\".format(accuracy_test))","28faacad":"df_feature_importances = pd.DataFrame()\ndf_feature_importances['feature'] = X_train.columns\ndf_feature_importances['importance'] = model.feature_importances_\/model.feature_importances_.sum()\ndf_feature_importances = df_feature_importances.sort_values(by = ['importance','feature'],ascending=False)\ndf_feature_importances.reset_index(drop = True,inplace=True)\n\ndf_feature_importances","64bf4444":"df_feature_importances[['feature','importance']].sort_values(by=['importance'],\n                                                             ascending = [True]).plot(kind='barh',\n                                                             x='feature',\n                                                             y='importance',\n                                                             legend=True, \n                                                             figsize=(5, 5))","e48240ba":"pred_prob_subm = model_rf.predict_proba(X_summit)[:,1]\npred_subm = [1 if x >= best_threshold else 0 for x in pred_prob_subm]","8903d732":"Y_summit_pred = pd.DataFrame()\nY_summit_pred[ID] = df_test[ID]\nY_summit_pred[TARGET] = pred_subm #pred_prob_subm\nY_summit_pred.head()","cea2ab27":"Y_summit_pred.to_csv(\"krfc_submission_01_baseline.csv\", index = False)","1abb6a04":"### 2.2.2) EDA","85ce59d7":"Como se puede notar, de los 3 tipos de algoritmos entrenados, el modelo basado en Random Forrest es el ganador con un accuracy optimizado por el punto de corte (threhold: 0.36)","752a07b2":"El punto de corte por defecto es de 0.50 para decidir si la predicci\u00f3n final ser\u00e1 1 \u00f3 0. A continuaci\u00f3n trataremos de encontrar ese punto de corte que optimice la m\u00e9trica de evaluaci\u00f3n del problema..","3b161160":"### ****Find best threshold:****","93f5f6de":"## 3.3) Feature Engineering","954e045e":"#### 2.2.3.b) Identify outliers","da0c8ed2":"### Feature Importances","d4d5b72e":"### ****Find best threshold:****","06a9f10d":"### 4.1.2 Evaluaci\u00f3n del Modelo","b3bafdc1":"## 3.1) Data Cleaning","60df0152":"#### 2.2.4.c) Adictionales","313b9be7":"El punto de corte por defecto es de 0.50 para decidir si la predicci\u00f3n final ser\u00e1 1 \u00f3 0. A continuaci\u00f3n trataremos de encontrar ese punto de corte que optimice la m\u00e9trica de evaluaci\u00f3n del problema..","3d500e4b":"## 3.5) Train & Test Split","17232920":"### 4.1.2 Evaluaci\u00f3n del Modelo","dd291e73":"To submission:","4abcd412":"### 4.1.1 Training","6427201b":"## 3.4) Feature Selection","fe347e57":"### 3.1.1) Impute missings","3ad8f55b":"### 4.1.1 Training","c927e825":"El punto de corte por defecto es de 0.50 para decidir si la predicci\u00f3n final ser\u00e1 1 \u00f3 0. A continuaci\u00f3n trataremos de encontrar ese punto de corte que optimice la m\u00e9trica de evaluaci\u00f3n del problema..","ff792a45":"# 3) DATA PREPARATION","8a08ce74":"Challenge Link: https:\/\/www.kaggle.com\/c\/dsrp-kaggle-semillero-01\n\nAutor: **Keven Fernandez Carrillo** \ncon el Apoyo de la comunidad **Data Science Research Per\u00fa**.\n\nVersi\u00f3n: 1.0\n\nGitHub: \n- https:\/\/github.com\/KevenRFC\n- https:\/\/github.com\/DataScienceResearchPeru","083e9abe":"### 2.2.1) Basic Statistics","63dd98a1":"### 4.1.1 Training","e36bb4c4":"**Telecom Customer Churn**\n\n---","9164141d":"# Predicciones on Submission DS","aa220db7":"### 3.1.2) Treat outliers","4891aeee":"# 2) DATA UNDERSTANDING","bdcec27b":"### Feature Importances","563a72c3":"# 1) IMPORT & INSTALL PACKAGES","3d99c91e":"## 4.1.B. Decision Tree","2e9d0d64":"## 2.1) Load Data","42aece10":"## 3.2) Data Transformation","4b61e72f":"***Select Final Features:***","71058675":"## 4.1.A. LogisticRegression","70f84d2d":"**MODELO FINAL**","572b586d":"### ****Find best threshold:****","5c273c90":"# 4) Modeling & Evaluation - Simple","4c7adde5":"#### 2.2.2.a) Evaluate missings","d36fc713":"### 4.1.2 Evaluaci\u00f3n del Modelo","575ce098":"## 4.1.C. Random Forest","91109508":"## 2.2) Data Exploration"}}