{"cell_type":{"e7c3dc17":"code","3bf236c7":"code","ebec1e4d":"code","77e722ce":"code","d58d23de":"code","8b75c8ac":"code","f55c4a3d":"code","41169311":"code","32aa390f":"code","e58f7ee4":"code","3d979a2d":"code","bc8e8972":"code","2aa9789e":"code","3950c8b8":"code","f97c2fbc":"markdown","0ff5d532":"markdown","1387480d":"markdown","2a809127":"markdown","5bed8538":"markdown","29db868a":"markdown","d005f82c":"markdown","0a50f292":"markdown","b7446634":"markdown"},"source":{"e7c3dc17":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.filterwarnings('ignore')","3bf236c7":"train=pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest=pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","ebec1e4d":"train.head()","77e722ce":"from datetime import datetime,date\ntrain['hour']=train['day']=train['month']=train['year']=train['dayofweek']=''\ntest['hour']=test['day']=test['month']=test['year']=test['dayofweek']=''\ndatetimetest=test['datetime']\nfor i in range(len(train)):\n  train['hour'][i]=int(datetime.strptime(train['datetime'][i], '%Y-%m-%d %H:%M:%S').hour)\n  train['day'][i]=int(datetime.strptime(train['datetime'][i], '%Y-%m-%d %H:%M:%S').day)\n  train['dayofweek'][i]=int(((datetime.strptime(train['datetime'][i], '%Y-%m-%d %H:%M:%S').day)%5))\n  train['month'][i]=int(datetime.strptime(train['datetime'][i], '%Y-%m-%d %H:%M:%S').month)\n  train['year'][i]=int(datetime.strptime(train['datetime'][i], '%Y-%m-%d %H:%M:%S').year)\nfor i in range(len(test)):\n  test['hour'][i]=int(datetime.strptime(test['datetime'][i], '%Y-%m-%d %H:%M:%S').hour)\n  test['day'][i]=int(datetime.strptime(test['datetime'][i], '%Y-%m-%d %H:%M:%S').day)\n  test['dayofweek'][i]=int(((datetime.strptime(test['datetime'][i], '%Y-%m-%d %H:%M:%S').day)%5))\n  test['month'][i]=int(datetime.strptime(test['datetime'][i], '%Y-%m-%d %H:%M:%S').month)\n  test['year'][i]=int(datetime.strptime(test['datetime'][i], '%Y-%m-%d %H:%M:%S').year)\ntrain.drop('datetime',axis=1,inplace=True)\ntest.drop('datetime',axis=1,inplace=True)","d58d23de":"train=train.astype(int)\ntest=test.astype(int)","8b75c8ac":"from sklearn.preprocessing import MinMaxScaler\n \n# Fit your data on the scaler object\ncol=['temp','atemp','humidity','windspeed','year']\nfor i in col:\n  scaler = MinMaxScaler()\n  train[col]=scaler.fit_transform(train[col])\n  test[col]=scaler.transform(test[col])","f55c4a3d":"train.head()","41169311":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\ncol=train.columns.tolist()\ncol.remove(\"count\")\ncol.remove(\"casual\")\ncol.remove(\"registered\")\nX=train[col]\ny=train[\"count\"]\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state=1,test_size=0.20,shuffle=True)","32aa390f":"def model(model):\n    model.fit(train_X,train_y)\n    modelpred=model.predict(val_X)\n    return(mean_absolute_error(abs(modelpred).astype(int), val_y)),modelpred","e58f7ee4":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nimport lightgbm as lgb\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor  \nfrom sklearn import svm\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nada=AdaBoostRegressor()\nbag=BaggingRegressor()\ngbr=GradientBoostingRegressor()\ngpr=GaussianProcessRegressor()\nsvm = svm.SVR()\nknc = KNeighborsRegressor()\nlgbm = lgb.LGBMRegressor()\nmlp = MLPRegressor(hidden_layer_sizes=(10,4,))\nrf = RandomForestRegressor()\nlr=LinearRegression()\ndt=DecisionTreeRegressor()\n\nmodels=[knc,lgbm,mlp,rf,lr,dt,svm,gpr,ada,bag,gbr]\nmodelpreds=[]\nfor i in models:\n  accuracy,modelpred=(model(i))\n  modelpreds.append(modelpred)\n  print(accuracy)","3d979a2d":"modelpredss=(modelpreds[1]+modelpreds[4])\/2","bc8e8972":"mean_absolute_error(modelpredss, val_y)","2aa9789e":"predslbm=lgbm.predict(test)\npredsrf=rf.predict(test)\npreds=abs((predsrf+predslbm)\/2).astype(int)","3950c8b8":"submission = pd.DataFrame({\n        \"datetime\": datetimetest,\n        \"count\": preds\n    })\nsubmission.to_csv('bike_prediction_output.csv', index=False)","f97c2fbc":"Adding features from datetime","0ff5d532":"Scaling","1387480d":"The mae using both lgbm and rf is lower than using either..So lets use the average prediction of both","2a809127":"Reading data","5bed8538":"We see that the best 2 models are lightgbm and Random forest","29db868a":"Submitting csv","d005f82c":"Building model","0a50f292":"Making predictions on test dataset","b7446634":"Splitting into test\/train datasets"}}