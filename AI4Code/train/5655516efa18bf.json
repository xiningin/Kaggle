{"cell_type":{"6e7e90a4":"code","a9f1f210":"code","8615c8dc":"code","c2ad586c":"code","f48ec4b4":"code","7d0d48ed":"code","4dd727ac":"code","dc960e82":"code","cc5bef61":"code","c3c73c0b":"code","559fa889":"code","b9e77f7b":"code","71a45c79":"code","38c4c562":"code","05467415":"code","ca2084c4":"code","1fdf8c59":"code","ad5afb9c":"code","5ecde807":"code","2fca3a59":"code","ac60c6c8":"code","c4707b77":"markdown","93c880cc":"markdown","01a9761a":"markdown","99f06fe1":"markdown","d72f793c":"markdown","c680f6d8":"markdown","2c0379fc":"markdown","ec1c3243":"markdown","90d931ef":"markdown","c051bd63":"markdown","19c2bf0b":"markdown","8b713496":"markdown","43bd31a3":"markdown","b8808cfd":"markdown","705e9df0":"markdown","005e6f9b":"markdown","eb6322fb":"markdown","641da155":"markdown","8c17e722":"markdown","5b1f77b0":"markdown","9efbb89d":"markdown","237e299a":"markdown","f97d3852":"markdown","41d732dc":"markdown","cff3ed82":"markdown","e8dc44c2":"markdown","784a2422":"markdown","23efe35d":"markdown"},"source":{"6e7e90a4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a9f1f210":"survey_raw_data = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\n\nsurvey_raw_data_index = survey_raw_data.drop(survey_raw_data.index[0])","8615c8dc":"survey_raw_data_index = survey_raw_data_index[(survey_raw_data_index.Q5 != 'Student') & (survey_raw_data_index.Q5 != 'Not employed')]","c2ad586c":"survey_raw_data_index['Group'] = np.where(survey_raw_data_index.iloc[:,44]=='University Courses (resulting in a university degree)', 'University-trained Data Worker', 'Self-trained Data Worker')\nsurvey_raw_data_group = survey_raw_data_index","f48ec4b4":"survey_raw_data_group_a1 = survey_raw_data_group[survey_raw_data_group.iloc[:,1] == '70+']\nsurvey_raw_data_group_a1['age_modified'] = 70\n\nsurvey_raw_data_group_a2 = survey_raw_data_group[survey_raw_data_group.iloc[:,1] != '70+']\nsurvey_raw_data_group_a2['age_modified_1'] = survey_raw_data_group_a2.iloc[:,1].str.extract('(\\d\\d)', expand=False)\nsurvey_raw_data_group_a2['age_modified_2'] = survey_raw_data_group_a2.iloc[:,1].str.extract(r'-(\\d\\d)', expand=False)\nsurvey_raw_data_group_a2['age_modified_1'] = pd.to_numeric(survey_raw_data_group_a2['age_modified_1'])\nsurvey_raw_data_group_a2['age_modified_2'] = pd.to_numeric(survey_raw_data_group_a2['age_modified_2'])\nsurvey_raw_data_group_a2['age_modified'] = (survey_raw_data_group_a2['age_modified_1'] + survey_raw_data_group_a2['age_modified_2']) \/ 2\nsurvey_raw_data_group_a2 = survey_raw_data_group_a2.drop(['age_modified_1','age_modified_2'], axis = 1)\n\nsurvey_raw_data_age_frame = [survey_raw_data_group_a1,survey_raw_data_group_a2]\nsurvey_raw_data_age = pd.concat(survey_raw_data_age_frame)","7d0d48ed":"survey_raw_data_age_y1 = survey_raw_data_age[survey_raw_data_age.iloc[:,55] == '< 1 years']\nsurvey_raw_data_age_y1['yr_coding'] = survey_raw_data_age_y1.iloc[:,55].str.extract('(\\d)', expand=False)\n\nsurvey_raw_data_age_y2 = survey_raw_data_age[survey_raw_data_age.iloc[:,55] == '20+ years']\nsurvey_raw_data_age_y2['yr_coding'] = survey_raw_data_age_y2.iloc[:,55].str.extract(r'(\\d\\d)+', expand=False)\n\nsurvey_raw_data_age_y3 = survey_raw_data_age[survey_raw_data_age.iloc[:,55] == 'I have never written code']\nsurvey_raw_data_age_y3['yr_coding'] = 0\n\nsurvey_raw_data_age_y4 = survey_raw_data_age[(survey_raw_data_age.iloc[:,55] != '20+ years') & (survey_raw_data_age.iloc[:,55] != '< 1 years') & (survey_raw_data_age.iloc[:,55] != 'I have never written code')]\nsurvey_raw_data_age_y4['yr_coding_1'] = survey_raw_data_age_y4.iloc[:,55].str.extract(r'(\\d+)-', expand=False)\nsurvey_raw_data_age_y4['yr_coding_2'] = survey_raw_data_age_y4.iloc[:,55].str.extract(r'-(\\d+)', expand=False)\nsurvey_raw_data_age_y4['yr_coding_1'] = pd.to_numeric(survey_raw_data_age_y4['yr_coding_1'])\nsurvey_raw_data_age_y4['yr_coding_2'] = pd.to_numeric(survey_raw_data_age_y4['yr_coding_2'])\nsurvey_raw_data_age_y4['yr_coding'] = (survey_raw_data_age_y4['yr_coding_1'] + survey_raw_data_age_y4['yr_coding_2']) \/ 2\nsurvey_raw_data_age_y4 = survey_raw_data_age_y4.drop(['yr_coding_1','yr_coding_2'], axis = 1)\nsurvey_raw_data_age_y4.head()\n\nsurvey_raw_data_year_frame = [survey_raw_data_age_y1,survey_raw_data_age_y2,survey_raw_data_age_y3,survey_raw_data_age_y4]\nsurvey_raw_data_year = pd.concat(survey_raw_data_year_frame)","4dd727ac":"survey_raw_data_year_nonull = survey_raw_data_year[survey_raw_data_year.loc[:,'Q15'].notna()]\n\nsurvey_raw_data_year_nonull['age_modified'] = pd.to_numeric(survey_raw_data_year_nonull['age_modified'])\nsurvey_raw_data_year_nonull['yr_coding'] = pd.to_numeric(survey_raw_data_year_nonull['yr_coding'])\nsurvey_raw_data_year_nonull['age_coding'] = survey_raw_data_year_nonull['age_modified'] - survey_raw_data_year_nonull['yr_coding']\n\nsurvey_raw_data_year_nonull['age_coding'].value_counts().sort_index()","dc960e82":"conditions = [\n    (survey_raw_data_year_nonull['age_coding'] <= 17),\n    (survey_raw_data_year_nonull['age_coding'] > 17) & (survey_raw_data_year_nonull['age_coding'] <= 25),\n    (survey_raw_data_year_nonull['age_coding'] > 25) & (survey_raw_data_year_nonull['age_coding'] <= 35),\n    (survey_raw_data_year_nonull['age_coding'] > 35) & (survey_raw_data_year_nonull['age_coding'] <= 50),\n    (survey_raw_data_year_nonull['age_coding'] > 50) & (survey_raw_data_year_nonull['age_coding'] <= 70)\n    ]\nchoices = ['Before college', 'Higher and graduate education', 'Early career','Mid career','Late career']\n\nsurvey_raw_data_year_nonull['age_group_coding'] = np.select(conditions, choices)","cc5bef61":"df_age_coding = survey_raw_data_year_nonull.loc[:,['Group','age_group_coding']]\ndf_age_coding.sort_index().head()","c3c73c0b":"self_trained = survey_raw_data_year_nonull[survey_raw_data_year_nonull.loc[:,'Group'] == 'Self-trained Data Worker'].loc[:,'age_group_coding'].value_counts()\nuniversity_trained = survey_raw_data_year_nonull[survey_raw_data_year_nonull.loc[:,'Group'] == 'University-trained Data Worker'].loc[:,'age_group_coding'].value_counts()\ndf = pd.DataFrame({'Self-trained Data Worker': self_trained,\n                   'University-trained Data Worker': university_trained})\ndf = df.rename_axis(\"fields\", axis='columns').rename_axis(\"age_group\", axis = 'rows').reset_index()\ndf","559fa889":"age_data = df_age_coding.groupby('Group').age_group_coding.value_counts(normalize = True).to_frame('percent').reset_index()\n\nplt.figure(figsize=(21,10))\nsns.barplot(x = age_data['age_group_coding'], y = age_data['percent'], hue = age_data['Group'], order = ['Before college','Higher and graduate education','Early career','Mid career','Late career'])\nplt.xlabel('Age Start Coding to Analyze Data')\nplt.ylabel('Percent in Group')","b9e77f7b":"df_gender = survey_raw_data_year_nonull.loc[:,['Group','Q2']]\n\ngender_data = df_gender.groupby('Group').Q2.value_counts(normalize = True).to_frame('percent').reset_index()\n\nplt.figure(figsize = (21,10))\nsns.barplot(x = gender_data['Q2'], y = gender_data['percent'], hue = gender_data['Group'], order = ['Male','Female','Prefer to self-describe','Prefer not to say'])\nplt.xlabel('Gender')\nplt.ylabel('Percent in Group')","71a45c79":"df_edu = survey_raw_data_year_nonull.loc[:,['Group','Q4']]\n\nedu_data = df_edu.groupby('Group').Q4.value_counts(normalize = True).to_frame('percent').reset_index()\n\nplt.figure(figsize = (21,10))\nchart2 = sns.barplot(x = edu_data['Q4'], y = edu_data['percent'], hue = edu_data['Group'], order = ['Doctoral degree',\"Master\u2019s degree\",'Professional degree',\"Bachelor\u2019s degree\",\"Some college\/university study without earning a bachelor\u2019s degree\",'No formal education past high school','I prefer not to answer'])\nchart2.set_xticklabels(labels = ['Doctoral degree',\"Master\u2019s degree\",'Professional degree',\"Bachelor\u2019s degree\",\"Some college\/university study without earning a bachelor\u2019s degree\",'No formal education past high school','I prefer not to answer'], rotation=60)\nplt.xlabel('Educational Attainment')\nplt.ylabel('Percent in Group')","38c4c562":"df_title = survey_raw_data_year_nonull.loc[:,['Group','Q5']]\n\ntitle_data = df_title.groupby('Group').Q5.value_counts(normalize = True).to_frame('percent').reset_index()\n\nplt.figure(figsize = (21,10))\nchart3 = sns.barplot(x = title_data['Q5'], y = title_data['percent'], hue = title_data['Group'])\nchart3.set_xticklabels(labels = title_data['Q5'], rotation=60)\nplt.xlabel('Professional Title')\nplt.ylabel('Percent in Group')","05467415":"df_salary = survey_raw_data_year_nonull.loc[:,['Group','Q10']]\nsalary_data = df_salary.groupby('Group').Q10.value_counts(normalize = True).to_frame('percent').reset_index()\nplt.figure(figsize = (21,10))\nchart4 = sns.barplot(x = salary_data['Q10'], y = salary_data['percent'], hue = salary_data['Group'], order = ['$0-999','1,000-1,999','2,000-2,999','3,000-3,999','4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999','15,000-19,999','20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999','50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999','90,000-99,999','100,000-124,999','125,000-149,999','150,000-199,999','200,000-249,999','250,000-299,999','300,000-500,000','> $500,000'])\nchart4.set_xticklabels(labels = ['$0-999','1,000-1,999','2,000-2,999','3,000-3,999','4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999','15,000-19,999','20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999','50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999','90,000-99,999','100,000-124,999','125,000-149,999','150,000-199,999','200,000-249,999','250,000-299,999','300,000-500,000','> $500,000'], rotation=60)\nplt.xlabel('Salary')\nplt.ylabel('Percent in Group')","ca2084c4":"conditions = [\n    (df_salary['Q10'] == '$0-999') | (df_salary['Q10'] == '10,000-14,999') | (df_salary['Q10'] == '1,000-1,999') | (df_salary['Q10'] == '15,000-19,999') | (df_salary['Q10'] == '2,000-2,999') | (df_salary['Q10'] == '3,000-3,999') | (df_salary['Q10'] == '4,000-4,999') | (df_salary['Q10'] == '5,000-7,499') | (df_salary['Q10'] == '7,500-9,999'),\n    (df_salary['Q10'] == '25,000-29,999') | (df_salary['Q10'] == '20,000-24,999') | (df_salary['Q10'] == '30,000-39,999'),\n    (df_salary['Q10'] == '40,000-49,999') | (df_salary['Q10'] == '50,000-59,999'),\n    (df_salary['Q10'] == '60,000-69,999') | (df_salary['Q10'] == '70,000-79,999'),\n    (df_salary['Q10'] == '80,000-89,999') | (df_salary['Q10'] == '90,000-99,999') | (df_salary['Q10'] == '100,000-124,999') | (df_salary['Q10'] == '125,000-149,999') | (df_salary['Q10'] == '150,000-199,999'),\n    (df_salary['Q10'] == '> $500,000') | (df_salary['Q10'] == '200,000-249,999') | (df_salary['Q10'] == '250,000-299,999') | (df_salary['Q10'] == '300,000-500,000')\n    ]\nchoices = ['Low outlier', 'Below regular', 'Bottom Half regular','Top Half regular','Beyond regular','High outlier']\n\ndf_salary['salary_range'] = np.select(conditions, choices)\nsalary_data_2 = df_salary.groupby('Group').salary_range.value_counts(normalize = True).to_frame('percent').reset_index()","1fdf8c59":"plt.figure(figsize = (21,10))\nsns.barplot(x = salary_data_2['salary_range'], y = salary_data_2['percent'], hue = salary_data_2['Group'], order = ['Low outlier', 'Below regular', 'Bottom Half regular','Top Half regular','Beyond regular','High outlier'])\nplt.xlabel('Salary Range')\nplt.ylabel('Percent in Group')","ad5afb9c":"df_course = survey_raw_data_year_nonull.iloc[:,np.r_[35:47,246]]\n\nself = df_course[df_course['Group'] == 'Self-trained Data Worker']\nuniv = df_course[df_course['Group'] == 'University-trained Data Worker']\n\nn_self_1 = self[self['Q13_Part_1'].notnull()].Q13_Part_1.count()\nn_self_2 = self[self['Q13_Part_2'].notnull()].Q13_Part_2.count()\nn_self_3 = self[self['Q13_Part_3'].notnull()].Q13_Part_3.count()\nn_self_4 = self[self['Q13_Part_4'].notnull()].Q13_Part_4.count()\nn_self_5 = self[self['Q13_Part_5'].notnull()].Q13_Part_5.count()\nn_self_6 = self[self['Q13_Part_6'].notnull()].Q13_Part_6.count()\nn_self_7 = self[self['Q13_Part_7'].notnull()].Q13_Part_7.count()\nn_self_8 = self[self['Q13_Part_8'].notnull()].Q13_Part_8.count()\nn_self_9 = self[self['Q13_Part_9'].notnull()].Q13_Part_9.count()\nn_self_10 = self[self['Q13_Part_10'].notnull()].Q13_Part_10.count()\nn_self_11 = self[self['Q13_Part_11'].notnull()].Q13_Part_11.count()\nn_self_12 = self[self['Q13_Part_12'].notnull()].Q13_Part_12.count()\n\nn_univ_1 = univ[univ['Q13_Part_1'].notnull()].Q13_Part_1.count()\nn_univ_2 = univ[univ['Q13_Part_2'].notnull()].Q13_Part_2.count()\nn_univ_3 = univ[univ['Q13_Part_3'].notnull()].Q13_Part_3.count()\nn_univ_4 = univ[univ['Q13_Part_4'].notnull()].Q13_Part_4.count()\nn_univ_5 = univ[univ['Q13_Part_5'].notnull()].Q13_Part_5.count()\nn_univ_6 = univ[univ['Q13_Part_6'].notnull()].Q13_Part_6.count()\nn_univ_7 = univ[univ['Q13_Part_7'].notnull()].Q13_Part_7.count()\nn_univ_8 = univ[univ['Q13_Part_8'].notnull()].Q13_Part_8.count()\nn_univ_9 = univ[univ['Q13_Part_9'].notnull()].Q13_Part_9.count()\nn_univ_10 = univ[univ['Q13_Part_10'].notnull()].Q13_Part_10.count()\nn_univ_11 = univ[univ['Q13_Part_11'].notnull()].Q13_Part_11.count()\nn_univ_12 = univ[univ['Q13_Part_12'].notnull()].Q13_Part_12.count()\n\ncourse_counts = pd.DataFrame({'Self-trained Data Worker': [n_self_1,\n                           n_self_2,\n                           n_self_3,\n                           n_self_4,\n                           n_self_5,\n                           n_self_6,\n                           n_self_7,\n                           n_self_8,\n                           n_self_9,\n                           n_self_10,\n                           n_self_11,\n                           n_self_12\n                           ],\n                           'University-trained Data Worker':[\n                           n_univ_1,\n                           n_univ_2,\n                           n_univ_3,\n                           n_univ_4,\n                           n_univ_5,\n                           n_univ_6,\n                           n_univ_7,\n                           n_univ_8,\n                           n_univ_9,\n                           n_univ_10,\n                           n_univ_11,\n                           n_univ_12\n                           ]},\n                          index=[\n                           'Udacity',\n                           'Coursera',\n                           'edX',\n                           'DataCamp',\n                           'DataQuest',\n                           'Kaggle Courses (i.e. Kaggle Learn)',\n                           'Fast.ai',\n                           'Udemy',\n                           'LinkedIn Learning',\n                           'University Courses (resulting in a university degree)',\n                           'None',\n                           'Other'\n                           ])\n\ncourse_counts","5ecde807":"course_counts['Total'] = course_counts['Self-trained Data Worker'] + course_counts['University-trained Data Worker']\nplt.figure(figsize=(21,10))\nsns.barplot(x = course_counts.index, y = course_counts.Total, color = \"C1\").set_xticklabels(labels = course_counts.index, rotation = 60)\nsns.barplot(x = course_counts.index, y = course_counts['Self-trained Data Worker'], color = \"C0\").set_xticklabels(labels = course_counts.index, rotation = 60)\n\ntopbar = plt.Rectangle((0,0),1,1,fc=\"C1\", edgecolor = 'none')\nbottombar = plt.Rectangle((0,0),1,1,fc='C0',  edgecolor = 'none')\nplt.legend([bottombar, topbar], ['Self-trained Data Worker', 'University-trained Data Worker'], loc=1, ncol = 2, prop={'size':16})\nplt.xlabel('Course Platforms')","2fca3a59":"df_media = survey_raw_data_year_nonull.iloc[:,np.r_[22:34,246]]\n\nself = df_media[df_media['Group'] == 'Self-trained Data Worker']\nuniv = df_media[df_media['Group'] == 'University-trained Data Worker']\n\nn_self_1 = self[self['Q12_Part_1'].notnull()].Q12_Part_1.count()\nn_self_2 = self[self['Q12_Part_2'].notnull()].Q12_Part_2.count()\nn_self_3 = self[self['Q12_Part_3'].notnull()].Q12_Part_3.count()\nn_self_4 = self[self['Q12_Part_4'].notnull()].Q12_Part_4.count()\nn_self_5 = self[self['Q12_Part_5'].notnull()].Q12_Part_5.count()\nn_self_6 = self[self['Q12_Part_6'].notnull()].Q12_Part_6.count()\nn_self_7 = self[self['Q12_Part_7'].notnull()].Q12_Part_7.count()\nn_self_8 = self[self['Q12_Part_8'].notnull()].Q12_Part_8.count()\nn_self_9 = self[self['Q12_Part_9'].notnull()].Q12_Part_9.count()\nn_self_10 = self[self['Q12_Part_10'].notnull()].Q12_Part_10.count()\nn_self_11 = self[self['Q12_Part_11'].notnull()].Q12_Part_11.count()\nn_self_12 = self[self['Q12_Part_12'].notnull()].Q12_Part_12.count()\n\nn_univ_1 = univ[univ['Q12_Part_1'].notnull()].Q12_Part_1.count()\nn_univ_2 = univ[univ['Q12_Part_2'].notnull()].Q12_Part_2.count()\nn_univ_3 = univ[univ['Q12_Part_3'].notnull()].Q12_Part_3.count()\nn_univ_4 = univ[univ['Q12_Part_4'].notnull()].Q12_Part_4.count()\nn_univ_5 = univ[univ['Q12_Part_5'].notnull()].Q12_Part_5.count()\nn_univ_6 = univ[univ['Q12_Part_6'].notnull()].Q12_Part_6.count()\nn_univ_7 = univ[univ['Q12_Part_7'].notnull()].Q12_Part_7.count()\nn_univ_8 = univ[univ['Q12_Part_8'].notnull()].Q12_Part_8.count()\nn_univ_9 = univ[univ['Q12_Part_9'].notnull()].Q12_Part_9.count()\nn_univ_10 = univ[univ['Q12_Part_10'].notnull()].Q12_Part_10.count()\nn_univ_11 = univ[univ['Q12_Part_11'].notnull()].Q12_Part_11.count()\nn_univ_12 = univ[univ['Q12_Part_12'].notnull()].Q12_Part_12.count()\n\nmedia_counts = pd.DataFrame({'Self-trained Data Worker': [n_self_1,\n                           n_self_2,\n                           n_self_3,\n                           n_self_4,\n                           n_self_5,\n                           n_self_6,\n                           n_self_7,\n                           n_self_8,\n                           n_self_9,\n                           n_self_10,\n                           n_self_11,\n                           n_self_12\n                           ],\n                           'University-trained Data Worker':[\n                           n_univ_1,\n                           n_univ_2,\n                           n_univ_3,\n                           n_univ_4,\n                           n_univ_5,\n                           n_univ_6,\n                           n_univ_7,\n                           n_univ_8,\n                           n_univ_9,\n                           n_univ_10,\n                           n_univ_11,\n                           n_univ_12\n                           ]},\n                          index=[\n                           'Twitter (data science influencers)',\n                           'Hacker News (https:\/\/news.ycombinator.com\/)',\n                           'Reddit (r\/machinelearning, r\/datascience, etc)',\n                           'Kaggle (forums, blog, social media, etc)',\n                           'Course Forums (forums.fast.ai, etc)',\n                           'YouTube (Cloud AI Adventures, Siraj Raval, etc)',\n                           'Podcasts (Chai Time Data Science, Linear Digressions, etc)',\n                           'Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)',\n                           'Journal Publications (traditional publications, preprint journals, etc)',\n                           'Slack Communities (ods.ai, kagglenoobs, etc)',\n                           'None',\n                           'Other'\n                           ])\n\nmedia_counts","ac60c6c8":"media_counts['Total'] = media_counts['Self-trained Data Worker'] + media_counts['University-trained Data Worker']\nplt.figure(figsize=(21,10))\nsns.barplot(x = course_counts.index, y = media_counts.Total, color = \"C1\").set_xticklabels(labels = media_counts.index, rotation = 60)\nsns.barplot(x = course_counts.index, y = media_counts['Self-trained Data Worker'], color = \"C0\").set_xticklabels(labels = media_counts.index, rotation = 60)\n\ntopbar = plt.Rectangle((0,0),1,1,fc=\"C1\", edgecolor = 'none')\nbottombar = plt.Rectangle((0,0),1,1,fc='C0',  edgecolor = 'none')\nplt.legend([bottombar, topbar], ['Self-trained Data Worker', 'University-trained Data Worker'], loc=1, ncol = 2, prop={'size':16})\nplt.xlabel('Media Platforms')","c4707b77":"# Table of Contents\n\n1. [Beginning Of The Journey](#p1)\n1. [Who We Are](#p2)\n1. [Where We Are Heading](#p3) \n1. [How To Get There](#p4)\n1. [What Is Unknown About Us](#p6)\n1. [References](#p7)","93c880cc":"The trends in both groups, whether university-trained or self-trained, are similar. However, currently those that are self-trained are slightly more likely to be with low-outlier salaries. It may actually indicate the reason why people would want a career switch through learning data and coding. However, this does not take into account any potential geographical or positional differences. What is positive is that there is a decent proportion of self-trained people with salary in top-half ranges (including beyond regular).","01a9761a":"## Gender\n\nNext let's look at the gender distribution of the respondents for both the university-trained and self-trained-groups.","99f06fe1":"The major difference between the two groups are (of course) on \"University Courses\". However, in addition to that, the popularity of each course platform is exactly the same between the two groups, with Coursera being the most popular one, closely followed by Kaggle, Udemy, DataCamp and edX.","d72f793c":"\"Student\" and \"Not employed\" are excluded from the analysis, in order to focus on current data workers.","c680f6d8":"<a id=\"p4\"><\/a>\n# How To Get There\n\nWith a determination and a destination in mind, the unavoidable question becomes how to achieve the goal. With so many educational and practical resources on the internet, which platforms to choose becomes a question.","2c0379fc":"## Media Sources\n\nSimilarly, we also look into the recommended media sources that report on data science topics.","ec1c3243":"<a id=\"p3\"><\/a>\n# Where We Are Heading\n\nHaving the determination to embark on the journey is the first step of everything. However, without a clear destination, one may just get lost on the way. In order for people to estbalish specific goals, it is helpful to learn about the experiences of others that have gone through the same process.","90d931ef":"The result is consistent with intuition. People who have advanced degrees, e.g. master's and doctoral degrees, are more likely to have been trained in data during formal education, since many data science or related programs are offered at master's and doctoral levels. Spending more time in formal education also makes it more possible for one to take data-related courses.\n\nHowever, a larger proportion of people who have a Bachelor's degree did not take any data courses in college, while the proportion of people with advanced degrees but no data training in universities is also significant enough to be convincing that taking the interest in data further into action is not irrational, even knowing the higher the level of achieved education, the larger the opportunity cost may be generated in this career switch or seemingly irrelevant investment in data.","c051bd63":"<a id=\"p6\"><\/a>\n# What Is Unknown About Us\n\nThere is still a lot unknown about this group of not self-trained data people. Among all possibilities of exploration, I am specifically interested in what is unknown about us beyond data.\n\nI view my largest advantage as being, of course not my to-be-honed data skills, but the valuable experience and knowledge I gained as a non-data worker before, being able to view issues from business angles, ablility to communicating with and between technical and non-technical audience, first-hand knowledge that is gained at the frontline not through data warehouses.\n\nI am also interested in the industry difference that might affect people's judgement on the value of investing in their interest in data. Working in a non-profit organization, I often question myself how to monetize values of what I am doing if monetization is not the purpose in the first place.","19c2bf0b":"Then the two fields are used to generate the derived field, age starting writing code to analyze data, by subtracting the number of years writing code from the current age.","8b713496":"In order not to be bothered with too many details, salary ranges are dividied into following groups, based on the a quick Data Analyst salary reference [5].\n\n- Low outlier: < 20,000\n- Below regular: 20,000 - 39,999\n- Bottom half regular: 40,000 - 59,999\n- Top half regular: 60,000 - 79,999\n- Beyond regular: 80,000 - 199,999\n- High outlier: > 200,000","43bd31a3":"## Educational Attainment\n\nEducational attainment is correlated with the age. However, it provides more direct insights into potential sunk costs of previous educational investments.","b8808cfd":"After initial exploration, the respondents are grouped into the following bins to reflect different life stages when people started to code to analyze data.\n\n- Before college: < 17\n- Higher and graduate education: 18-25\n- Early career: 26-35\n- Mid career: 36-50\n- Late career: 51-70","705e9df0":"As mentioned at the beginning, this story is not a rigid study considering the undemonstrated assumptions that are embedded in the entire analysis. Instead, this is just to show to people who are hestitating whether to take their interest in data any further, that there are a lot of people like us no matter how old we are, what gender we identify ourselves as, or what education level we have attained. Some of them have achieved a lot in their current positions, while some are still trying to figure things out. With the recommended ways and platforms to learn data, we are not alone, and thus we are not to be discouraged by the concerns that we are not on the right track.","005e6f9b":"The popularity of the media sources are also basically the same between the two groups, with Kaggle, Blog and Youtube being the three most popular sources. The only small difference is on course forums. This is understandable since people who are learning data through online course platforms instead of university courses may rely more on the forums when completing the courses.","eb6322fb":"<a id=\"p1\"><\/a>\n# Beginning Of The Journey\n\nIn order to leverage the advantages of digitalization, there is a larger and larger demand for data talents. However, there is still a shortage of skilled staff who can perform data-related work [2].\n\nTwo reasons make this a great opportunity for people who are interested in data. First, the shortage of data talents is partially resulted from a lack of university degree programs in data science, or lack of focus on application of the knowledge to meet industry needs [3]. Instead of merely waiting for the formal education system to mature, many institutions becomes more willing to train their own data experts [4], either from their current staff who know the institution well, or from people who have accumulated professional experience in the industry.\n\nBesides, more open resources for data training becoming available makes it possible to self-learn data-related skills with relatively low opportunity costs, so people do not need to quit job or enroll in a costly education program to gain relevant knowledge.","641da155":"<a id=\"p7\"><\/a>\n# References\n\n1. https:\/\/www.youtube.com\/watch?v=arj7oStGLkU&t=1s\n2. https:\/\/betanews.com\/2019\/10\/18\/data-analytics-talent-shortage\/\n3. https:\/\/techcrunch.com\/2015\/12\/31\/how-to-stem-the-global-shortage-of-data-scientists\/\n4. https:\/\/www.infoworld.com\/article\/3131605\/why-you-should-retrain-your-employees-to-become-your-data-scientists.html\n5. https:\/\/www.payscale.com\/research\/US\/Job=Data_Analyst\/Salary","8c17e722":"Although it is harder for people to self-learn themselves into highly-technical positions which may require systematic training (which is usually done through formal education), such as statistician and research scientist), a significant proportion of respondents are now in positions as analysts, even without formal data training in universities.\n\nThe most popular professional title, for both university and self-trained data workers, is data scientist. Despite the fact that a slightly larger proportion of university-trained data workers ended as data scientists, the proportion is also significant for self-trained people. This should not only instill confidence into people who are still hestitating, but may also be viewed as a reference of which positions to target if the goal is a career switch.","5b1f77b0":"From the table, we can see that most people started writing code to analysis data between higher education and mid career, whether self-trained or university trained. However, it is not easy to see further trends or details with pure numbers.","9efbb89d":"Procrastination is almost prevalent in our lives. In this famous Ted Talk  __[Inside the mind of a master procrastinator | Tim Urban](https:\/\/www.youtube.com\/watch?v=arj7oStGLkU&t=1s)__ [1], the speaker talked about the risk of letting \"Instant Gratification Monkey\" take the wheel. However, I realized another major obstacle on my own journey of self-learning data science, a hestitant \"Rational Decision Maker\".\n\nNot long ago, I was offered a new position when my institution initiated transformation towards data-informed models, and later became the first and only \"data\" person in the institution. I started with my purely-theoretical statistics knowledge from college and zero coding experience, and then embarked on a journey of self-regulated \"on-the-job training\".\n\nIt did not take long for me to realize how serious a challenge self-learning could be for a procrastinator, especially when all those self doubts crept in, \"can I do it without a dedicated college education\", \"is it too late for me to make this career shift\", \"what is ahead in this journey\".\n\nThis story tries to provide insights to these questions using the 2019 Kaggle survey results. Focusing on respondents who are not formally trained in data-related disciplines, it is aimed to provide people in similar situation with a determination (if you are interested in data but worried about missing the formal academic background), a destination (if you do not know where this interest may lead you) and a plan (how to get where you want to go).","237e299a":"## Salary\n\nSalary is another important indicator of what to expect in a career with data involved. Considering the high expenses of completing university degrees in data, does the cost pay off when we look at the earnings of two groups?","f97d3852":"## Professional Titles\n\nFirst let's look at what professional titles are currently wore by this self-trained group of respondents, as compared to their university-trained companions.","41d732dc":"## Course Platforms\n\nLet's see what are the most popular course platforms recommended by respondents.","cff3ed82":"Like said, it is not surprising to see that most people, whether they have completed data courses in universities or not, started coding for data analysis from higher education to early career phases. However, for people who were not trained through university courses, a larger proportion, than those who were university-trained, started learning coding all across their professional career, from early to late phases.\n\nThis indicates that although it is common for people to start coding to analyze data during the education period, there is still a significant number of people making the shift in early or even mid-to-late career stages. For the latter, it may not be a complete career switch, but is likely to be a career advancement by adding data and coding to one's own professional skill set.\n\nLike the saying goes, \"the best time to plant a tree is twenty years ago - the second best time is now\", it is never too late to start learning coding, but the second-worst choice to \"never\" is \"later\".","e8dc44c2":"## Age Starting Writing Code To Analyze Data\n\nOne of the major barriers to enter a new field or learn a new skill is age. The farther one has been devoting into one field, the higher the sunk costs, and the harder for one to make a switch of focus.\n\nBoth age (Q1) and experience writing code to analyze data (Q15) are used to calculate the age when respondents started this data journey. Since the responses are all in ranges, the records are converted to specific numbers for calculation purpose, using the mean value of the ranges. For open intervals with one side unspecified, such as 70+, it is replaced by the number itself, e.g. 70. Although this may skew the statistical results downwards a little, it is both the best solution given the dataset, and should not skew the interpretations as the specific age beyond 70 may not have significantly different impact on one's professional career.","784a2422":"<a id=\"p2\"><\/a>\n# Who We Are\n\nRespondents who did not learn data science through university courses and those that did are respectively grouped, in order to reveal the characteristics of these two groups. On one side, it provides insights on the differences and similarities between the groups. On the other side, and more importantly, I hope that finding the similarities with people who are self-trained data workers can prompt others' determination to dive into this new field even without a relevant degree.","23efe35d":"One thing that interests me is that the proportion of female respondents is larger in the university-trained group, as compared to those self-trained.\n\nAlthough the difference may not be statistically significant, it is consistent with the social impression that males are disproportionately represented in the fields of data and coding, which is also reflected by the fact that the majority of respondents, in both groups, are male. Men may be more confident to dive into the fields even if they did not receive relevant formal training in college, while women might encounter other types of discouragement.\n\n\"Gender is irrelevant. Certainly the tennis ball doesn't know what the gender was of the tennis coach.\" It is reinforced by the significant number of women who participated in the survey even though they never took data courses during formal education. Data, as a tool, is neutral. It is the person who uses it makes the difference, and one should never be discouraged by a neutral object."}}