{"cell_type":{"c04afe5e":"code","bb6ca364":"code","0b261218":"code","409b5dce":"code","217f619e":"code","86754545":"code","4ebf87c7":"code","e12b52ab":"code","1a8fe604":"code","d5c87a99":"code","580d26a6":"code","2696f1f5":"code","c6cd140a":"code","005738a3":"code","564a3589":"code","4fa047e3":"code","3deb58f2":"code","146d1d03":"code","151a578d":"code","b5a00fa1":"code","aa6c8ade":"code","befeea29":"code","85a27b14":"code","d0fc00fb":"code","e6dc0452":"code","874a68f3":"code","d273fe6e":"code","d4b853b2":"code","3e345da3":"code","c1d26b2c":"markdown","dc5d911b":"markdown","eb6bd0e6":"markdown","c76ec5d1":"markdown","c54e384a":"markdown","443aaab5":"markdown","bcb579b1":"markdown","20c9462d":"markdown","12e017c5":"markdown"},"source":{"c04afe5e":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import classification_report, confusion_matrix","bb6ca364":"tf.random.set_seed(100)","0b261218":"data = pd.read_csv('..\/input\/bank-marketing-campaigns-dataset\/bank-additional-full.csv', delimiter=';')","409b5dce":"data","217f619e":"data.info()","86754545":"data['y'] = data['y'].apply(lambda y: 1 if y == 'yes' else 0)","4ebf87c7":"data.select_dtypes('object')","e12b52ab":"{column: len(data[column].unique()) for column in data.select_dtypes('object').columns}","1a8fe604":"{column: list(data[column].unique()) for column in data.select_dtypes('object').columns}","d5c87a99":"data = data.replace('unknown', np.NaN)","580d26a6":"data.isna().sum()","2696f1f5":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df\n        \ndef ordinal_encode(df, columns, orderings):\n    df = df.copy()\n    for column, ordering in zip(columns, orderings):\n        df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df\n\ndef binary_encode(df, columns, positive_values):\n    df = df.copy()\n    for column, positive_value in zip(columns, positive_values):\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else x)\n        df[column] = df[column].apply(lambda x: 0 if str(x) != 'nan' else x)\n    return df","c6cd140a":"nominal_features = [\n    'job',\n    'marital',\n    'education',\n    'day_of_week',\n    'poutcome'\n]\n\nordinal_features = [\n    'month'\n]\n\nbinary_features = [\n    'default',\n    'housing',\n    'loan',\n    'contact' \n]","005738a3":"prefixes = ['J', 'M', 'E', 'D', 'P']\n\norderings = [\n    ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n]\n\npositive_values = [\n    'yes',\n    'yes',\n    'yes',\n    'cellular'\n]","564a3589":"data = onehot_encode(\n    data,\n    columns=nominal_features,\n    prefixes=prefixes\n)\n\ndata = ordinal_encode(\n    data,\n    columns=ordinal_features,\n    orderings=orderings\n)\n\ndata = binary_encode(\n    data,\n    columns=binary_features,\n    positive_values=positive_values\n)","4fa047e3":"data","3deb58f2":"for column in ['default', 'housing', 'loan']:\n    data[column] = data[column].fillna(data[column].mean())","146d1d03":"print(\"Remaining missing values:\", data.isna().sum().sum())","151a578d":"print(\"Remaining non-numeric columns:\", len(data.select_dtypes('object').columns))","b5a00fa1":"data","aa6c8ade":"y = data['y'].copy()\nX = data.drop('y', axis=1).copy()","befeea29":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","85a27b14":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)","d0fc00fb":"print(\"Positive examples: {}\".format(y.sum()))\nprint(\"Negative examples: {}\".format(len(y) - y.sum()))\n\nprint(\"\\nClass Distribution: {:.1f}% \/ {:.1f}%\".format(y.mean() * 100, (1 - y.mean()) * 100))","e6dc0452":"inputs = tf.keras.Input(shape=(X.shape[1],))\nx = tf.keras.layers.Dense(64, activation='relu')(inputs)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\nbatch_size = 32\nepochs = 100\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","874a68f3":"model.evaluate(X_test, y_test)","d273fe6e":"y_true = np.array(y_test)\ny_pred = np.squeeze(np.array(model.predict(X_test) >= 0.5, dtype=np.int))","d4b853b2":"print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))","3e345da3":"print(\"Classification Report:\\n\\n\", classification_report(y_true, y_pred))","c1d26b2c":"# Getting Started","dc5d911b":"# Encoding Labels","eb6bd0e6":"# Splitting\/Scaling","c76ec5d1":"# Modeling\/Training","c54e384a":"# Results","443aaab5":"# Filling Missing Values","bcb579b1":"# Task for Today  \n\n***\n\n## Marketing Effectiveness Prediction  \n\nGiven *data about subjects' responses to a bank's marketing campaign*, let's try to predict whether a given subject will **place a deposit** or not.\n\nWe will use a TensorFlow ANN to make our predictions.","20c9462d":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/w1exIx0GDeQ","12e017c5":"# Encoding Categorical Features"}}