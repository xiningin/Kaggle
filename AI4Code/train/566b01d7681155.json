{"cell_type":{"d9eb7fc3":"code","52cac016":"code","7ffa01f8":"code","5a046f91":"code","4f48a704":"code","ef84723e":"code","ff978e83":"code","71915dd7":"code","ff829ef4":"code","13cb9628":"code","04b94ab2":"code","4a48d757":"code","4c390f7b":"code","c309a6b4":"code","e3a07c0b":"code","e580c231":"code","3c7bfd21":"code","8ff48c99":"code","15518f2f":"code","b551fd73":"code","c478e2f6":"code","f7584ac7":"code","27553c41":"code","505c0fb4":"code","44ba3cb4":"code","6429a999":"code","73d2b259":"code","ba9ba5b4":"code","6a347b06":"code","d6c0d10a":"code","5f6c2c29":"code","521c5a3a":"code","979b927d":"code","2aa86ba8":"code","57a67f8b":"code","275646de":"markdown","397ba4b2":"markdown","1405a12e":"markdown","48468c71":"markdown","4211452e":"markdown","e0ccd227":"markdown","618e44b9":"markdown","05e971dd":"markdown","caf266b0":"markdown","4f35b5d8":"markdown","e4e1123f":"markdown","831649f8":"markdown","d1c258ad":"markdown","abf2ba50":"markdown","db86ae4e":"markdown","9ba2bd32":"markdown"},"source":{"d9eb7fc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load14\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52cac016":"pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","7ffa01f8":"titanic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntitanic_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntitanic_train","5a046f91":"print(titanic_train.shape)\nprint(titanic_train.info())\ntitanic_train.head()","4f48a704":"plt.figure(figsize=(12,8))\nsns.heatmap(titanic_train.isnull(),cmap=sns.color_palette('light:navy',2));","ef84723e":"titanic_train.Cabin.value_counts()","ff978e83":"titanic_train.duplicated().sum()","71915dd7":"for col in titanic_train.select_dtypes(exclude=np.number).columns:\n    unique = titanic_train[col].unique()\n    print('------------{} len={}---------'.format(col,len(unique)))\n    print(unique[:5])","ff829ef4":"titanic_train.Ticket.duplicated().sum()","13cb9628":"titanic_train.describe()","04b94ab2":"#Initial countplot for all columns with relative to survival rate\ncolumns = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\nfig,axes = plt.subplots(3,3,figsize=(15,12))\naxes=axes.ravel()\n\nfor i in range(len(axes)):\n    col = columns[i]\n    ax = axes[i]\n    \n    sns.countplot(x=col,hue='Survived',data=titanic_train,ax=ax)","4a48d757":"#Countplot for null value in cabin column\nsns.countplot(x=titanic_train['Cabin'].isnull(),hue=titanic_train['Survived']);\nplt.xlabel('Null entry for Cabin column');","4c390f7b":"#Dublicated countplot for Ticket column\nsns.countplot(x=titanic_train['Ticket'].duplicated(),hue=titanic_train['Survived']);\nplt.xlabel('Dublicated entry for Ticket columns');","c309a6b4":"train_df = titanic_train.copy()","e3a07c0b":"def cabin_letter(row):\n    if row['Cabin'] is np.nan:\n        return 'X'\n    return row['Cabin'][0]\n\ntrain_df['Cabin'] = train_df.apply(lambda x:cabin_letter(x),axis=1)\ntitanic_test['Cabin'] = titanic_test.apply(lambda x:cabin_letter(x),axis=1)","e580c231":"sns.countplot(x=train_df['Cabin'],hue=train_df['Survived']);","3c7bfd21":"train_df['Family'] = train_df['SibSp']+train_df['Parch']\ntitanic_test['Family'] = titanic_test['SibSp'] + titanic_test['Parch']\n\nsns.countplot(x='Family',hue='Survived',data=train_df)","8ff48c99":"from sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import LabelEncoder\n\ndef columns_encoder(df,target_columns,encoder_dictionary=False):\n    if encoder_dictionary == False:\n        df = df.copy()\n        encoded_columns = target_columns\n        encoder_dictionary = {}\n        for column in encoded_columns:\n            encoder_dictionary[column] = {}\n            le = LabelEncoder()\n            df[column] = le.fit_transform(df[column].astype(str))\n            encoder_dictionary[column] = le\n        return df,encoder_dictionary\n\n\n    elif encoder_dictionary != False:\n        df = df.copy()\n        for i,le in encoder_dictionary.items():\n            df[i] = df[i].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n            le_classes = le.classes_.tolist()\n            le_classes.insert(len(le_classes), '<unknown>')\n            le.classes_ = le_classes\n            \n        for column in encoder_dictionary.keys():\n            df[column] = encoder_dictionary[column].transform(df[column].astype(str))\n            \n        return df, encoder_dictionary\n    \ndef columns_imputer(df,K,imputer=False):\n    \n    if imputer == False:\n        df = df.copy()\n        dfcolumns = df.columns\n        # Use KNN Imputer to replace Nan values.\n        imputer = KNNImputer(n_neighbors=K)\n        df = imputer.fit_transform(df)\n        df = pd.DataFrame(data=df,columns=dfcolumns)\n        return df, imputer\n\n    elif imputer!=False:\n        df=df.copy()\n        dfcolumns = df.columns\n        df = imputer.transform(df)\n        df = pd.DataFrame(data=df,columns=dfcolumns)\n        return df\n    ","15518f2f":"train_df.isnull().sum()","b551fd73":"#droping columns and removing targer column\ndrop_columns = ['PassengerId','Name','SibSp','Parch','Ticket']\ntrain_target = train_df.pop('Survived')","c478e2f6":"train_df = train_df.drop(drop_columns,axis=1)\ntitanic_X_test = titanic_test.drop(drop_columns,axis=1)","f7584ac7":"target_columns = ['Embarked','Cabin','Sex']\ntrain_df,train_encoder = columns_encoder(train_df,target_columns)\ntitanic_X_test,test_encoder = columns_encoder(titanic_X_test,target_columns,encoder_dictionary=train_encoder)","27553c41":"train_df,train_imputer = columns_imputer(train_df,K=5)\ntitanic_X_test = columns_imputer(titanic_X_test,K=5,imputer=train_imputer)","505c0fb4":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom lightgbm import LGBMClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n","44ba3cb4":"def model_train(model,X,y):\n    X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5)\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    print('Train_Accuracy = {:.2f}'.format(model.score(X_train,y_train)))\n    print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n    print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n    print('Recall: {:.2f}'.format(recall_score(y_test, y_pred)))\n    print('F1: {:.2f}'.format(f1_score(y_test, y_pred)))\n    return model\n    \ndef make_submission(clf,string,test_df,test_X_df):\n    test = test_df.copy()\n    predictions = clf.predict(test_X_df.to_numpy())\n    results = test[['PassengerId']].merge(pd.Series(predictions,name='Survived'),left_index=True,right_index=True)\n    results.to_csv('titanic_submission_{}.csv'.format(string), index=False)","6429a999":"lr = model_train(LogisticRegression(max_iter=500),train_df,train_target)","73d2b259":"dt = model_train(DecisionTreeClassifier(max_depth=5,max_features=6,random_state=5),train_df,train_target)","ba9ba5b4":"gb = model_train(GradientBoostingClassifier(random_state=5),train_df,train_target)","6a347b06":"RF = model_train(RandomForestClassifier(max_depth=3,random_state=5),train_df,train_target)","d6c0d10a":"RF = RandomForestClassifier(max_depth=3,random_state=5).fit(train_df,train_target)\nmake_submission(RF,'Random_forest',titanic_test,titanic_X_test)","5f6c2c29":"lg = model_train(LGBMClassifier(random_state=5),train_df,train_target)\n","521c5a3a":"#lg = LGBMClassifier(random_state=5).fit(train_df,train_target)\n#make_submission(lg,'LGBMClassifier',titanic_test,titanic_X_test)","979b927d":"gnb = model_train(GaussianNB(),train_df,train_target)","2aa86ba8":"nnc = model_train(MLPClassifier(max_iter=400,hidden_layer_sizes=19,random_state=5),train_df,train_target)","57a67f8b":"#nnc = MLPClassifier(max_iter=400,hidden_layer_sizes=19,random_state=5).fit(train_df,train_target)\n#make_submission(nnc,'Neural_Network_Classifier_3',titanic_test,titanic_X_test)","275646de":"**I get score of 0.74162 with NNClassifier**","397ba4b2":"## Random Froest","1405a12e":"**I get score of 0.74641 with LGBMClassifier**","48468c71":"# SibSp and Parch Columns","4211452e":"# Data Wrangling","e0ccd227":"# Cabin Column","618e44b9":"**I get score of 0.75358 with Random Forest**","05e971dd":"## Gradient-boosted decision trees","caf266b0":"## LGBMClassifier","4f35b5d8":"## Neural networks Classifier","e4e1123f":"## Logistic Regression","831649f8":"## Naive Bayes classifiers","d1c258ad":"## Decision Tree","abf2ba50":"# Exploring different relations with survived columns","db86ae4e":"### Columns changes\n- PassengerId --> drop\n- Name --> drop\n- Embarked --> encode values\n- Cabin --> define X variable for null values and encode values\n- Survived --> No Change\n- Pclass --> encode values\n- Sex --> encode values\n- Age --> impute null values\n- SibSp --> created columns Family then drop\n- Parch --> created columns Family then drop\n- Ticket --> drop\n- Fare --> no change","9ba2bd32":"# Model Training"}}