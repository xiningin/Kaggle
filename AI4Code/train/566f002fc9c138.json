{"cell_type":{"5f1c7c61":"code","139a712d":"code","6c609a84":"code","3186fd92":"code","8367adf5":"code","4afa6ef9":"code","1cc1ba2c":"code","4bafbb46":"code","04eb2d18":"code","5dbb1c46":"code","afa954c8":"code","4866a76d":"code","195d3c82":"code","8bddc20a":"code","1f95da6f":"code","41dfa2de":"code","ee119554":"code","24e043ea":"code","5623335d":"markdown","8002ac0f":"markdown","4c8ff7d9":"markdown","e26433a7":"markdown","bb497848":"markdown"},"source":{"5f1c7c61":"import re\nimport collections\nimport matplotlib.pyplot as plt","139a712d":"!pip install --quiet d2l\nfrom d2l import mxnet as d2l","6c609a84":"path = \"..\/input\/time-machine\/timemachine.txt\"","3186fd92":"def read_time_machine(path):\n    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n    with open(path,'r') as f:\n        lines = f.readlines()\n    return[re.sub('[^A-Za-z]+',' ', line).strip().lower() for line in lines]","8367adf5":"lines = read_time_machine(path)","4afa6ef9":"lines[:5]","1cc1ba2c":"def tokenize(lines, token='word'):\n    if token == 'word':\n        return [line.split() for line in lines]\n    elif token == 'char':\n        return [list(line) for line in lines]\n    else:\n        print('Error unknown type: ' + token)","4bafbb46":"tokens = tokenize(lines)","04eb2d18":"tokens[0]","5dbb1c46":"class Vocab:\n    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n        if tokens is None:\n            tokens = []\n        if reserved_tokens is None:\n            reserved_tokens = []\n            \n        # Sort according to frequencies\n        counter = self.count_corpus(tokens)\n        self.token_freqs = sorted(counter.items(), key=lambda x: x[0])\n        self.token_freqs.sort(key=lambda x: x[1], reverse=True)\n        # The index for the unknown token is 0\n        self.unk, uniq_tokens=0, ['<unk>'] + reserved_tokens\n        uniq_tokens+=[token for token, freq in self.token_freqs\n                      if freq >= min_freq and token not in uniq_tokens]\n        self.idx_to_token, self.token_to_idx = [], dict()\n        for token in uniq_tokens:\n            self.idx_to_token.append(token)\n            self.token_to_idx[token] = len(self.idx_to_token) - 1\n        \n    def __len__(self):\n        return len(self.idx_to_token)\n    \n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n    \n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n    \n    def count_corpus(self, tokens):\n        \"\"\"Count token frequencies.\"\"\"\n        # Here `tokens` is a 1D list or 2D list\n        if len(tokens) == 0 or isinstance(tokens[0],list):\n            # Flatten a list of token lists into a list of tokens\n            tokens = [token for line in tokens for token in line]\n        return collections.Counter(tokens)","afa954c8":"vocab = Vocab(tokens)\nprint(list(vocab.token_to_idx.items())[:10])","4866a76d":"for i in[0,10]:\n    print('words:', tokens[i])\n    print('indices:', vocab[tokens[i]])","195d3c82":"# corpus is a single list, not a list of token lists, \n# since each text line in the time machine dataset is not necessarily a sentence or a paragraph\ncorpus = [vocab[token] for line in tokens for token in line]","8bddc20a":"# word frequency\nfreqs = [freq for token, freq in vocab.token_freqs]","1f95da6f":"d2l.plot(freqs, xlabel='token: x', ylabel='frequency: n(x)',xscale='log', yscale='log')","41dfa2de":"bigram_tokens = [pair for pair in zip(corpus[:-1], corpus[1:])]\nbigram_vocab = d2l.Vocab(bigram_tokens)","ee119554":"trigram_tokens = [triple for triple in zip(corpus[:-2], corpus[1:-1], corpus[2:])]\ntrigram_vocab = d2l.Vocab(trigram_tokens)","24e043ea":"bigram_freqs = [freq for token, freq in bigram_vocab.token_freqs]\ntrigram_freqs = [freq for token, freq in trigram_vocab.token_freqs]\nd2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel='token: x',ylabel='frequency: n(x)', xscale='log', yscale='log',legend=['unigram','bigram','trigram'])","5623335d":"# Read Data","8002ac0f":"# Vocabulary\n\nBuilding a dictionary, often called vocabulary as well, to map string tokens into numericalindices starting from 0","4c8ff7d9":"# Natural Language Processing\nOn Time Machine Novel<br>\nExploratory Data Analysis","e26433a7":"# Natural Language Statistics","bb497848":"# Tokenization\n\nA token is the basic unit in text."}}