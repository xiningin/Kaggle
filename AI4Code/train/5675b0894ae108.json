{"cell_type":{"2276d1af":"code","e87d2f98":"code","b73cbe47":"code","95394ada":"code","91e9aeb3":"code","d7be269c":"code","c2885266":"code","87e2025a":"code","6455a587":"code","c55b2f1e":"markdown","704fbf44":"markdown","35c39ed5":"markdown","a119914e":"markdown","fb7bd00d":"markdown","9ba2010f":"markdown","4b9bce99":"markdown","5409cb6c":"markdown"},"source":{"2276d1af":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport os","e87d2f98":"path_label_dict = os.path.join('..\/input', 'label_names_2018.csv')\n\npath_video_train = os.path.join('..\/input', 'video-sample', 'video', 'train00.tfrecord')\npath_video_test = os.path.join('..\/input', 'video-sample', 'video', 'train01.tfrecord')\n\npath_frame_train = os.path.join('..\/input', 'frame-sample', 'frame', 'train00.tfrecord')\npath_frame_test = os.path.join('..\/input', 'frame-sample', 'frame', 'train01.tfrecord')","b73cbe47":"dfLabel = pd.read_csv(path_label_dict)\nnum_labels = len(dfLabel.label_name.unique())","95394ada":"def tfRecord_parse(record, num_labels, train=False):\n    features = {\n        'mean_rgb': tf.FixedLenFeature([1024], tf.float32),\n        'mean_audio': tf.FixedLenFeature([128], tf.float32)\n    }\n    if train:\n        features['labels'] = tf.VarLenFeature(tf.int64)\n    parsed = tf.parse_single_example(record, features)\n    x = tf.concat([parsed['mean_rgb'], parsed['mean_audio']], axis=0)\n    if train:\n        y = tf.sparse_to_dense(parsed['labels'].values, [num_labels], 1)\n        return x, y\n    return x","91e9aeb3":"def tfRecord_seq_parse(record, num_labels, train=False):\n    sequence_features = {\n        'rgb': tf.FixedLenSequenceFeature([], tf.string),\n        'audio': tf.FixedLenSequenceFeature([], tf.string)\n    }\n    context_features = {}\n    if train:\n        context_features['labels'] = tf.VarLenFeature(tf.int64)\n    ctx, parsed = tf.parse_single_sequence_example(record, context_features=context_features, sequence_features=sequence_features)\n    \n    decode_seq_rgb = tf.decode_raw(parsed['rgb'], tf.uint8)\n    decode_seq_rgb = tf.reshape(decode_seq_rgb, [-1, 1024])\n    decode_seq_rgb = tf.cast(decode_seq_rgb, dtype=tf.float32)\n    \n    decode_seq_audio = tf.decode_raw(parsed['audio'], tf.uint8)\n    decode_seq_audio = tf.reshape(decode_seq_audio, [-1, 128])\n    decode_seq_audio = tf.cast(decode_seq_audio, dtype=tf.float32)\n    \n    x = tf.concat([decode_seq_rgb, decode_seq_audio], axis=1)\n    if train:\n        y = tf.sparse_to_dense(ctx['labels'].values, [num_labels], 1)\n        return x, y\n    return x","d7be269c":"def generate(path, num_labels, batch_size=1, train=False, isFrame=False, num_parallel_calls=12):\n    dataset = tf.data.TFRecordDataset(path)\n    if isFrame:\n        dataset = dataset.map(map_func=lambda x: tfRecord_seq_parse(x, num_labels, train=train), num_parallel_calls=num_parallel_calls)\n    else:\n        dataset = dataset.map(map_func=lambda x: tfRecord_parse(x, num_labels, train=train), num_parallel_calls=num_parallel_calls)\n    dataset = dataset.repeat(1000)\n    dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    \n    return dataset.make_one_shot_iterator()","c2885266":"video_train = generate(path_video_train, num_labels, train=True)\nframe_train = generate(path_frame_train, num_labels, train=True, isFrame=True)\nnext_video_val = video_train.get_next()\nnext_frame_val = frame_train.get_next()","87e2025a":"with tf.Session() as session:\n    x, y = session.run(next_video_val)\nprint('x: {}, y: {}'.format(x.shape, y.shape))","6455a587":"with tf.Session() as session:\n    x, y = session.run(next_frame_val)\nprint('x: {}, y: {}'.format(x.shape, y.shape))","c55b2f1e":"In this notebook, you will learn easy way to extract video and audio dataset from given data","704fbf44":"In this part, it a little bit different because of sequential data.\n* Using FixedLenSequenceFeature when you want to extract sequence data, and passing to `sequence_features`\n* rgb, and audio are bytes list data, so have to use string as type to read.\n* as the given data length, I reshape the data\n* transform data type from uint8 to float32","35c39ed5":"video","a119914e":"testing","fb7bd00d":"frame","9ba2010f":"pasing function for the video dataset.\n* the video dataset is single but not sequence, so I use fixed len to extract.\n* I use parse single as its name to parse the dataset.\n* I concatenate aforementioned dataset. \n\nNow, you ready to serve :D","4b9bce99":"count the label size","5409cb6c":"generate batch data"}}