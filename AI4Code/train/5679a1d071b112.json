{"cell_type":{"fa68ecb9":"code","d2c79128":"code","6cb1625d":"code","aca14a7a":"code","9aeb4b74":"code","6fbe50fc":"code","4684c0f1":"code","a947bd3e":"code","1c3c1593":"code","b890bac7":"code","6aaef752":"code","3a9057fa":"code","f4882481":"code","db104be0":"code","090de84f":"code","60dd128b":"markdown","d5da8642":"markdown","b7c85833":"markdown","a0716df1":"markdown","7fc8e0f2":"markdown","7825d29d":"markdown","46a38e04":"markdown","1b630c7e":"markdown","c7bf85ad":"markdown","550d62d1":"markdown","98c00d87":"markdown"},"source":{"fa68ecb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random  \nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans \nfrom sklearn.datasets.samples_generator import make_blobs \n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d2c79128":"df=pd.read_csv(\"\/kaggle\/input\/crime-data-from-2010-to-present\/Crime_Data_from_2010_to_Present.csv\")\ndf.head()","6cb1625d":"df.columns","aca14a7a":"df.drop(columns=[\"DR Number\",\"Date Reported\",\"Date Occurred\",\"Area Name\",\"Crime Code Description\",\"Weapon Description\",\"Crime Code 1\",\"Crime Code 2\",\"Crime Code 3\",\"Crime Code 4\",\"Address\",\"Cross Street\",\"Premise Description\",\"Weapon Used Code\",\"Status Code\",\"Location \",\"Status Description\",\"MO Codes\"],inplace=True)","9aeb4b74":"df[\"Victim Sex\"].value_counts()","6fbe50fc":"df[\"Victim Sex\"].fillna(\"M\",inplace=True)","4684c0f1":"df[\"Victim Descent\"].value_counts()","a947bd3e":"df[\"Victim Descent\"].fillna(\"H\",inplace=True)","1c3c1593":"from sklearn import preprocessing\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['M','F','X','H','N','-'])\ndf[\"Victim Sex\"] = le_sex.transform(df[\"Victim Sex\"].values) \n\n\nle_BP = preprocessing.LabelEncoder()\nle_BP.fit([ 'H', 'W', 'B','X','A','K','F','C','I','J','P','U','V','Z','G','S','D','L','-','O'])\ndf[\"Victim Descent\"] = le_BP.transform(df[\"Victim Descent\"].values)\n\n\n","b890bac7":"X = df[[\"Time Occurred\",\"Area ID\",\"Reporting District\",\"Crime Code\",\"Victim Age\",\"Victim Sex\",\"Victim Descent\",\"Premise Code\"]].head(1000).values\nX[0:5]","6aaef752":"from sklearn.preprocessing import StandardScaler\nX = df.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet = StandardScaler().fit_transform(X)\nClus_dataSet","3a9057fa":"clusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(X)\nlabels = k_means.labels_\nprint(labels)","f4882481":"df[\"Clus_km\"] = labels\ndf.head(5)","db104be0":"df.groupby('Clus_km').mean()","090de84f":"cost =[] \nfor i in range(1, 11): \n    KM = KMeans(n_clusters = i, max_iter = 500) \n    KM.fit(X) \n      \n    # calculates squared error \n    # for the clustered points \n    cost.append(KM.inertia_)      \n  \n# plot the cost against K values \nplt.plot(range(1, 11), cost, color ='g', linewidth ='3') \nplt.xlabel(\"Value of K\") \nplt.ylabel(\"Sqaured Error (Cost)\") \nplt.show() # clear the plot \n  \n# the point of the elbow is the  \n# most optimal value for choosing k ","60dd128b":"# Hierachical Clustering On Happines Report\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n1. [Introduction and Data Import](#0)<br>\n2. [Pre-processing](#1)<br>\n3. [Feature Selection and Normalizing](#2)\n4. [Modeling](#3)\n5. [Selecting Best K-Value](#4)\n<hr>","d5da8642":"Introduction<br>\nThere are many models for clustering out there. In this notebook, we will be presenting the model that is considered the one of the simplest model among them. Despite its simplicity, the K-means is vastly used for clustering in many data science applications, especially useful if you need to quickly discover insights from unlabeled data. In this notebook, you learn how to use k-Means for customer segmentation.\n<br><br>\nSome real-world applications of k-means:<br>\n\n- Customer segmentation\n- Understand what the visitors of a website are trying to accomplish\n- Pattern recognition\n- Machine learning\n- Data compression<br><br>\nIn this notebook we practice k-means clustering with 2 examples:<br><br>\n\n- k-means on a random generated dataset\n- Using k-means for customer segmentation\nImport libraries\nLets first import the required libraries. Also run %matplotlib inline since we will be plotting in this section.","b7c85833":"# Selecting Best K-Value <a id=\"4\"><\/a>","a0716df1":"Just dropping out unnecessary columns","7fc8e0f2":"# Pre-processing <a id=\"1\"><\/a>","7825d29d":"Filling in the null values of columns with most common index of the column.I am not able to use mean() beacuse the indexes are not numeric.","46a38e04":"# Introduction and Data Import <a id=\"0\"><\/a>","1b630c7e":"# Feature Selection and Normalizing <a id=\"2\"><\/a>","c7bf85ad":"# Modeling <a id=\"3\"><\/a>","550d62d1":"Transforming all labels to numeric values to be able to use them in algorithm.","98c00d87":"Thank you for sharing your time to examine my kernel. If there is any questions please ask. If you think I should improve myself please comment."}}