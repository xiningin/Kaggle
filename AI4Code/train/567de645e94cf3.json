{"cell_type":{"f46e250b":"code","0e8b2add":"code","69ec6f09":"code","f17734df":"code","493338b3":"code","b37fd4e9":"code","947008e1":"code","1ade7150":"code","2f381ef2":"code","d98a8323":"code","3579f47c":"code","9cbe6ec5":"code","d0a835a2":"code","f5a17810":"code","1977adca":"markdown","4b8470b2":"markdown","31ae9e7f":"markdown","3b49ff6b":"markdown","b6d5ca13":"markdown","8948f14d":"markdown","cdcab005":"markdown","cb9480eb":"markdown","7ce943e4":"markdown","c43b874d":"markdown","24eb8622":"markdown","cab8ced9":"markdown","5c62a727":"markdown"},"source":{"f46e250b":"zabt = \"Papers on Non-pharmaceutical Interventions\"\nznam = \"Papers_on_Non-pharmaceutical_Interventions\"","0e8b2add":"zwds = \"ability access account age alternatives approaches areas assessment authoritative authorities bans barriers benefits capacity care cases centers changes closures collaboration communities compare compliance comply conduct consensus consistent control coordinated critical delivery dhs diagnoses different disability distancing distribution economic effectiveness efficacy employment equity examine excellence execution experiments factors fail food funding gain gatherings geographic government guidance household housing immigration impact implemented income individuals infrastructure insurance interventions leveraged location mass methods mobilize models non-pharmaceutical npis pandemic. participants policy populations potential predict programmatic public race rapid regardless research resources respond risks scale school services shortfalls social spread states status supplies support system travel treatment underserved\"","69ec6f09":"import os\nimport pandas as pd\nimport json\nfrom IPython.core.display import display, HTML\n# !pip uninstall spacy # Uncomment this if installed version of spacy fails.\n# !pip install spacy # Uncomment this if spacy package is not installed.\nimport spacy\n# !python -m spacy download en # Uncomment this if en language is not loaded in spacy package. \nnlp = spacy.load('en')","f17734df":"zchk = nlp(zwds)","493338b3":"ztop = '\/kaggle\/input\/CORD-19-research-challenge'","b37fd4e9":"zdf0 = pd.DataFrame(columns=['Folder', 'File', 'Match'])","947008e1":"%%capture\n\nfor zsub, zdir, zfis in os.walk(ztop):\n\n    for zfil in zfis:\n        if zfil.endswith(\".json\"):\n            \n            with open(zsub + os.sep + zfil) as f:\n                zout = json.load(f)\n            f.close()\n            \n            zout = \" \".join([part['text'] for part in zout['abstract']])\n            zout = zchk.similarity(nlp(zout))\n            \n            zdf0 = zdf0.append({'Folder': zsub.replace(ztop, \"\"), 'File': zfil, 'Match': zout}, ignore_index=True)\n            \nprint(zdf0.head(4))","1ade7150":"zdf0.to_csv(znam + '_Check.csv', index = False)","2f381ef2":"zdf6 = zdf0[zdf0.Match > 0.6].sort_values(by=['Match'], axis=0, ascending=False, inplace=False)\nprint(zdf6.head(4))","d98a8323":"zdf6.to_csv(znam + '_Relevant.csv', index = False)","3579f47c":"%%capture\n\nzht0 = \"<html>\\n<head>\\n\"\nzht0 = zht0 + \"<title>Relevant Papers for Vaccines and Therapeutics<\/title>\\n\"\nzht0 = zht0 + \"<script>\\nfunction openPop(x) {\\nei = document.getElementById('pop_' + x);\\n\"\nzht0 = zht0 + \"ei.style.display='block';\\nec = document.getElementsByClassName('pip');\\nvar i;\\n\"\nzht0 = zht0 + \"for (i = 0; i < ec.length; i++) {\\nif ( ec[i] != ei) { ec[i].style.display='none'; }; }; }\\n\"\nzht0 = zht0 + \"function shutPop(x) { document.getElementById('pop_' + x).style.display='none'; }\\n<\/script>\\n\"\nzht0 = zht0 + \"<style>table, th, td { border: 1px solid black; }<\/style>\\n\"\nzht0 = zht0 + \"<\/head>\\n<body>\\n\"\nzht0 = zht0 + \"<h1>\" + zabt + \"<\/h1>\\n\"\nzht0 = zht0 + \"<p>The following is a list of relevant papers.<\/p><br \/>\\n\"\nzht0 = zht0 + \"<p>Click on a Title to pop up its Abstract.<\/p><br \/>\\n\"\nzht0 = zht0 + \"<table>\\n<tbody>\\n<tr><th>Title<\/th>\\n<th>Abstract<\/th><\/tr>\\n\"","9cbe6ec5":"zht6 = zht0 # zht6 is to be saved later as a file.\nzhtd = zht0 # zhtd is a smaller version of zht6, for displaying in this notebook.\n\nfor indx, cont in zdf6.iterrows():\n    \n    with open(ztop + os.sep + cont['Folder'] + os.sep + cont['File']) as f:\n        ztxt = json.load(f)\n        f.close()\n        \n    ztxt = \" \".join([part['text'] for part in ztxt['abstract']])\n    \n    zhta = \"<tr><td><div onClick=openPop(\" + str(indx) + \")>\" + str(cont['File']) + \"<\/div><\/td>\\n\"    \n    zhta = zhta + \"<td><div onClick=shutPop(\" + str(indx) + \") class='pip' id='pop_\" + str(indx) + \"' style='display:none;'>\" + ztxt + \"<\/div><\/td><\/tr>\\n\"\n    \n    zht6 = zht6 + zhta\n    if indx < 10:\n        zhtd = zhtd + zhta\n\nzht6 = zht6 + \"<\/body>\\n<\/html>\"\nzhtd = zhtd + \"<\/body>\\n<\/html>\"","d0a835a2":"%%capture\n\nzout = open(znam + \"_Relevant_10.html\",\"a\")\nzout.write(zht6)\nzout.close()","f5a17810":"display(HTML(zhtd))","1977adca":"Outside this notebook: take the task's specification; make a unique list of words; remove common words; and optionally sort them.","4b8470b2":"Import python packages: os, pandas, json, IPython, and spacy.","31ae9e7f":"Export this subset dataframe as another csv file.","3b49ff6b":"Display the smaller html as a webpage here.","b6d5ca13":"Export this dataframe as a csv file.","8948f14d":"This notebook aims to:\n- Prepare a list of papers and their relevance to the task under consideration.\n- Prepare a list and a webpage of most relevant papers and their abstracts.\n- Display top 10 most relevant papers and their abstracts.","cdcab005":"\n\nApply spacy's nlp tool to the set of selected words.","cb9480eb":"Save the webpage html as a file.","7ce943e4":"Make an empty dataframe, to populate later.","c43b874d":"Go through each file, review the Abstract text contained in it, compute its relevance to the task, and add it to the dataframe.","24eb8622":"Make a webapage html of list and abstracts of papers with more than 60% relevance.","cab8ced9":"Specify the location of files of papers provided by this challenge.","5c62a727":"Make a subset dataframe of records with more than 60% relevance."}}