{"cell_type":{"9e031635":"code","5344c298":"code","c6ef17dc":"code","f34ae863":"code","25aefe5e":"code","61a661a9":"code","36baf2ca":"code","87cab819":"code","82ae7d6f":"code","0d3e0432":"code","0b77fbee":"code","e23b5652":"code","707b0c25":"code","9531355c":"code","e199fa1c":"code","32484e79":"code","383f8739":"code","4f243849":"code","b6cfcacf":"code","9a6cef0a":"code","2cf20ac5":"code","d4d876f2":"code","f12abe3a":"code","3bbe89a7":"code","08426c0f":"code","4af27aad":"code","d7096321":"code","b85d24c5":"code","bbe71245":"code","4c55213b":"code","5ac29df7":"code","e7c64393":"code","16447b1f":"code","b1cd57c3":"code","4e28edf1":"code","71b2058f":"code","bece8467":"code","c95c4df7":"code","e86ab221":"code","f342748c":"code","5cde1bbf":"markdown","367d797b":"markdown","13d38764":"markdown","4cab7cf2":"markdown","e3d8079f":"markdown","c4ce11f6":"markdown","690d2ddc":"markdown","c7a74845":"markdown","93241f3a":"markdown","7afc613e":"markdown","d92cf2e1":"markdown","1d80e3f0":"markdown","33af24a1":"markdown","607187d9":"markdown","63632c7b":"markdown","a351b57c":"markdown","218b50ea":"markdown","6c2235f9":"markdown"},"source":{"9e031635":"# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport missingno as msno\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\n\n#import the necessary modelling algos.\n\n#classifiaction.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb\nfrom sklearn.ensemble import AdaBoostClassifier\n \n\n#regression\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nimport statsmodels.api as sm\nimport os\nimport random\n\n\n#model selection\nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n#preprocessing\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n\n#evaluation metrics\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score","5344c298":"df = pd.read_csv('..\/input\/titanic\/train.csv')\ndf.head()","c6ef17dc":"df.shape","f34ae863":"df.info()","25aefe5e":"df.isnull().sum()","61a661a9":"df = df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1)","36baf2ca":"df.Age.describe()","87cab819":"df['Age'].mean(), df['Age'].median()","82ae7d6f":"df['Age'] = df['Age'].fillna(28)","0d3e0432":"df['Embarked'].value_counts()","0b77fbee":"df['Embarked'] = df['Embarked'].fillna('S')","e23b5652":"df = df.drop('Cabin', axis = 1)\ndf.head()","707b0c25":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","9531355c":"df['Sex'] = le.fit_transform(df['Sex'])\ndf = pd.get_dummies(df, columns = ['Embarked'])\ndf.head()","e199fa1c":"X = df.drop('Survived', axis = 1)\ny = df.Survived","32484e79":"sns.countplot(x = 'Survived', data = df)","383f8739":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE()\nX_res, y_res = sm.fit_resample(X, y)\n\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y==0)))\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_res==0)))","4f243849":"sns.countplot(x = y_res, data = df)","b6cfcacf":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","9a6cef0a":"%%time\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\ndtc_pred = dtc.predict(X_test)\nprint(confusion_matrix(dtc_pred, y_test))\nprint('-----')\nprint(classification_report(dtc_pred, y_test))","2cf20ac5":"%%time\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint(confusion_matrix(rf_pred, y_test))\nprint('-----')\nprint(classification_report(rf_pred, y_test))","d4d876f2":"lr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\nprint(confusion_matrix(lr_pred, y_test))\nprint('-----')\nprint(classification_report(lr_pred, y_test))","f12abe3a":"svc = SVC()\nsvc.fit(X_train, y_train)\nsvc_pred = svc.predict(X_test)\nprint(confusion_matrix(svc_pred, y_test))\nprint('-----')\nprint(classification_report(svc_pred, y_test))","3bbe89a7":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nprint(confusion_matrix(knn_pred, y_test))\nprint('-----')\nprint(classification_report(knn_pred, y_test))","08426c0f":"cross_valid_scores = {}","4af27aad":"%%time\nparameters = {\n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_dtc = DecisionTreeClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_dtc = GridSearchCV(\n    model_dtc, \n    parameters, \n    cv=5,\n)\n\nmodel_dtc.fit(X_train, y_train)\nmodel_dtc_pred = model_dtc.predict(X_test)\nprint(classification_report(model_dtc_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_dtc.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \\\n    f'{model_dtc.best_score_:.3f}'\n)\ncross_valid_scores['desicion_tree'] = model_dtc.best_score_\nprint('-----')","d7096321":"%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25], \n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_rf = RandomForestClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_rf = GridSearchCV(\n    model_rf, \n    parameters, \n    cv=5,\n)\n\nmodel_rf.fit(X_train, y_train)\nmodel_rf_pred = model_rf.predict(X_test)\nprint(classification_report(model_rf_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_rf.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_rf.best_score_:.3f}'\n)\ncross_valid_scores['random_forest'] = model_rf.best_score_\nprint('-----')","b85d24c5":"%%time\nparameters = {\n    'max_depth': [3, 5, 7, 9], \n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\nmodel_xgb = xgb.XGBClassifier(\n    random_state=42, verbosity = 0\n)\n\nmodel_xgb = GridSearchCV(\n    model_xgb, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_xgb.fit(X_train, y_train)\nmodel_xgb_pred = model_xgb.predict(X_test)\nprint(classification_report(model_xgb_pred, y_test))\n\n\nprint('-----')\nprint(f'Best parameters {model_xgb.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_xgb.best_score_:.3f}'\n)\ncross_valid_scores['xgboost'] = model_xgb.best_score_\nprint('-----')","bbe71245":"%%time\nparameters = {\n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'num_leaves': [7, 15, 31],\n}\n\nmodel_lgbm = lgbm.LGBMClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_lgbm = GridSearchCV(\n    model_lgbm, \n    parameters, \n    cv=5)\n\nmodel_lgbm.fit(X_train, y_train)\nmodel_lgbm_pred = model_lgbm.predict(X_test)\nprint(classification_report(model_lgbm_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_lgbm.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_lgbm.best_score_:.3f}'\n)\ncross_valid_scores['lightgbm'] = model_lgbm.best_score_\nprint('-----')","4c55213b":"%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25, 50, 75, 100], \n    \"learning_rate\": [0.001, 0.01, 0.1, 1.],\n}\n\nmodel_adaboost = AdaBoostClassifier(\n    random_state=42,\n)\n\nmodel_adaboost = GridSearchCV(\n    model_adaboost, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_adaboost.fit(X_train, y_train)\nmodel_adaboost_pred = model_adaboost.predict(X_test)\nprint(classification_report(model_adaboost_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_adaboost.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_adaboost.best_score_:.3f}'\n)\ncross_valid_scores['ada_boost'] = model_adaboost.best_score_\nprint('-----')","5ac29df7":"%%time\nparameters = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"penalty\": [\"l1\", \"l2\"]\n}\n\nmodel_lr = LogisticRegression(\n    random_state=42,\n    class_weight=\"balanced\",\n    solver=\"liblinear\",\n)\n\nmodel_lr = GridSearchCV(\n    model_lr, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_lr.fit(X_train, y_train)\nmodel_lr_pred = model_lr.predict(X_test)\nprint(classification_report(model_lr_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_lr.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_lr.best_score_:.3f}'\n)\ncross_valid_scores['logistic_regression'] = model_lr.best_score_\nprint('-----')","e7c64393":"%%time\nparameters = {\n    \"weights\": [\"uniform\", \"distance\"],\n}\n\nmodel_k_neighbors = KNeighborsClassifier(\n)\n\nmodel_k_neighbors = GridSearchCV(\n    model_k_neighbors, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_k_neighbors.fit(X_train, y_train)\nmodel_k_neighbors_pred = model_k_neighbors.predict(X_test)\nprint(classification_report(model_k_neighbors_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_k_neighbors.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_k_neighbors.best_score_:.3f}'\n)\ncross_valid_scores['k_neighbors'] = model_k_neighbors.best_score_\nprint('-----')","16447b1f":"df_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_test.head()","b1cd57c3":"df_test_drop = df_test.drop([\"PassengerId\", \"Name\", \"Ticket\", 'Cabin'], axis=1)","4e28edf1":"df_test_drop['Age'] = df_test_drop['Age'].fillna(28)\ndf_test_drop['Embarked'] = df_test_drop['Embarked'].fillna('S')\ndf_test_drop['Sex'] = le.fit_transform(df_test_drop['Sex'])","71b2058f":"df_test_drop = pd.get_dummies(df_test_drop, columns = ['Embarked'])\ndf_test_drop.head()\n","bece8467":"df_test_drop.isnull().sum()","c95c4df7":"df_test_drop['Fare'] = df_test_drop['Fare'].fillna(df_test['Fare'].median())","e86ab221":"model_lgbm.fit(X, y)\nmodel_lgbm_pred = model_lgbm.predict(df_test_drop)","f342748c":"output = pd.DataFrame({'Survived': model_lgbm_pred,\n                     'PassengerId': df_test.PassengerId})\noutput.to_csv('sumbmission.csv', index = False)\noutput\nprint('Your submission was successfully saved')","5cde1bbf":"## Logistic Regression","367d797b":"# Grid Search ","13d38764":"# Data loading and overview","4cab7cf2":"## Random Forest","e3d8079f":"## XGBoost","c4ce11f6":"## Adaboost","690d2ddc":"## SVC","c7a74845":"# Import Libs","93241f3a":"## Random Forest","7afc613e":"## LightGBM","d92cf2e1":"## Decision Tree","1d80e3f0":"# UPDATE: 14.03.21","33af24a1":"## Decision Tree","607187d9":"## Logistic Regression","63632c7b":"# OverSampling","a351b57c":"## KNN","218b50ea":"## Fillna","6c2235f9":"## KNN"}}