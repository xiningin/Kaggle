{"cell_type":{"ef3e31f6":"code","4a242dc4":"code","69bcb0d7":"code","5ed5abcb":"code","bea2d481":"code","ca44b9ee":"code","fce396a9":"code","334fceb5":"code","bf883a6a":"code","43549a1e":"code","fa022d2f":"code","a2fbd0a6":"code","19db3a6c":"code","4cd40bfb":"code","5562bae3":"code","e8ca7b93":"code","1d0d8d22":"code","4c8450f1":"code","22fdd293":"code","5745d593":"code","7dbf2065":"markdown","d862912b":"markdown","c6c7b1ff":"markdown","cfeb5c63":"markdown","421bf68d":"markdown","b08564d9":"markdown","a38ef238":"markdown","585184e4":"markdown","f4445e46":"markdown","cbf95d1b":"markdown","64742e52":"markdown","e0832ddd":"markdown","44646d5e":"markdown"},"source":{"ef3e31f6":"# Data Management\nfrom dateutil import relativedelta as rd\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\n\npyo.init_notebook_mode()\nimport seaborn as sns\n\n# Regression\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport statsmodels.graphics.api as smg","4a242dc4":"# Import modules for API calls\nimport requests\nimport io\nimport pandas as pd\nimport requests\nimport json\nfrom datetime import datetime\n\n# Import module for plotting\nimport seaborn as sns\n\n## JHU Vaccination Rates (Taken From: https:\/\/github.com\/owid\/covid-19-data\/tree\/master\/public\/data)\nurl = 'https:\/\/raw.githubusercontent.com\/owid\/covid-19-data\/master\/public\/data\/owid-covid-data.csv' \ndownload = requests.get(url).content\n\ncovid = pd.read_csv(io.StringIO(download.decode('utf-8')), parse_dates=['date'])\n\n#covid.tail()","69bcb0d7":"# Read and rename column country\ncty_info = pd.read_csv('..\/input\/countryinfo\/covid19countryinfo.csv').rename(columns={'country':'Country'})\n\n# Filter observations with aggregate country-level information\n# The column region for region-level observations is populated\ncty_info = cty_info[cty_info.region.isnull()]\n\n# Convert string data type to floating data type\n# Remove comma from the fields\ncty_info['healthexp'] = cty_info[~cty_info['healthexp'].isnull()]['healthexp'].str.replace(',','').astype('float')\ncty_info['gdp2019'] = cty_info[~cty_info['gdp2019'].isnull()]['gdp2019'].str.replace(',','').astype('float')\n\n\n# Convert to date objects with to_datetime method\ngov_actions = ['quarantine', 'schools', 'gathering', 'nonessential', 'publicplace']\n\nfor gov_action in gov_actions:\n    cty_info[gov_action] = pd.to_datetime(cty_info[gov_action], format = '%m\/%d\/%Y')\n    \n# Filter columns of interest\n# Note: feel free to explore other variables or datasets\ncty_info = cty_info[['Country', 'avghumidity', 'avgtemp', 'fertility', 'medianage', 'urbanpop', 'quarantine', 'schools', \\\n                    'publicplace', 'gatheringlimit', 'gathering', 'nonessential', 'hospibed', 'smokers', \\\n                    'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'sexratio', 'lung', 'femalelung', \\\n                    'malelung', 'gdp2019', 'healthexp', 'healthperpop']]\n","5ed5abcb":"# Worldometer data\n# ================\n\nworldometer_data = pd.read_csv(\"..\/input\/corona-virus-report\/worldometer_data.csv\")\n\n# Replace missing values '' with NAN and then 0\nworldometer_data = worldometer_data.replace(\"\", np.nan).fillna(0)\n\n# Transform variables and round them up to the two decimal points\n# Note that there are instances of division by zero issue when there are either zero total tests or total cases\nworldometer_data[\"Case Positivity\"] = round(worldometer_data[\"TotalCases\"] \/ worldometer_data[\"TotalTests\"], 2)\nworldometer_data[\"Case Fatality\"] = round(worldometer_data[\"TotalDeaths\"] \/ worldometer_data[\"TotalCases\"], 2)\n\n# Resolve the division by zero issue by replacing infinity value with zero\nworldometer_data[worldometer_data[\"Case Positivity\"] == np.inf] = 0\nworldometer_data[worldometer_data[\"Case Fatality\"] == np.inf] = 0\n\n# Place case positivity into three bins\nworldometer_data[\"Case Positivity Bin\"] = pd.qcut(worldometer_data[\"Case Positivity\"], q=3, labels=[\"low\", \"medium\", \"high\"])\n\n\n# Population Structure\nworldometer_pop_struc = pd.read_csv(\"..\/input\/covid19-worldometer-snapshots-since-april-18\/population_structure_by_age_per_contry.csv\")\n\n# Replace missing values with zeros\nworldometer_pop_struc = worldometer_pop_struc.fillna(0)\n\n# Merge datasets by common key country\nworldometer_data = worldometer_data.merge(worldometer_pop_struc, how=\"inner\", left_on=\"Country\/Region\", right_on=\"Country\")\nworldometer_data = worldometer_data[worldometer_data[\"Country\/Region\"] != 0]\n\n# Country information\nworldometer_data = worldometer_data.merge(cty_info, how=\"left\", on=\"Country\")\n\n# Replace space in variable names with '_'\nworldometer_data.columns = worldometer_data.columns.str.replace(\" \", \"_\")\n\n#worldometer_data.info()","bea2d481":"# Full data\n# =========\n\nfull_table = pd.read_csv(\"..\/input\/corona-virus-report\/covid_19_clean_complete.csv\")\nfull_table[\"Date\"] = pd.to_datetime(full_table[\"Date\"])\n\n# Examine DataFrame (object type, shape, columns, dtypes)\n#full_table.info()\n\n# Deep dive into the DataFrame\n#full_table.head()","ca44b9ee":"# Grouped by day, country\n# =======================\n\nfull_grouped = pd.read_csv(\"..\/input\/corona-virus-report\/full_grouped.csv\")\nfull_grouped[\"Date\"] = pd.to_datetime(full_grouped[\"Date\"])\n# full_grouped.loc[full_grouped['Country\/Region'] == 'US', 'Country\/Region'] = 'USA'\nfull_grouped.head()\n\n# Correct country names in worldometer to make them consistent with dataframe full_grouped column Country\/Region before merging\nworldometer_data[\"Country\/Region\"].replace(\n    {\n        \"USA\": \"US\",\n        \"UAE\": \"United Arab Emirates\",\n        \"S. Korea\": \"South Korea\",\n        \"UK\": \"United Kingdom\",\n    },\n    inplace=True,\n)\n\n# Draw population and country-level data\nfull_grouped = full_grouped.merge(worldometer_data[[\"Country\/Region\", \"Population\"]], how=\"left\", on=\"Country\/Region\")\nfull_grouped = full_grouped.merge(cty_info, how=\"left\", left_on=\"Country\/Region\", right_on=\"Country\")\nfull_grouped[\"Confirmed per 1000\"] = (full_grouped[\"Confirmed\"] \/ full_grouped[\"Population\"] * 1000)\n#the left merge made full grouped each country row has same data in other no-date data.\n\n# Backfill data\nfull_grouped = full_grouped.fillna(method=\"ffill\")\n\n\n# Create post-invention indicators\ngov_actions = [\"quarantine\", \"schools\", \"gathering\", \"nonessential\", \"publicplace\"]\n\nfor gov_action in gov_actions:\n    full_grouped[\"post_\" + gov_action] = (full_grouped[\"Date\"] >= full_grouped[gov_action])\n    full_grouped[\"day_rel_to_\" + gov_action] = (full_grouped[\"Date\"] - full_grouped[gov_action]).dt.days\n    full_grouped[\"log_day_rel_to_\" + gov_action] = np.log(full_grouped[\"day_rel_to_\" + gov_action])\n# Create percent changes in covid19 outcomes\ncovid_outcomes = [\"Confirmed\", \"Deaths\", \"Recovered\", \"Active\", \"Confirmed per 1000\"]\n\nfull_grouped.set_index('Date',inplace=True)\nfor covid_outcome in covid_outcomes:\n    full_grouped[\"pct_change_\" + covid_outcome] = full_grouped.groupby([\"Country\/Region\"])[covid_outcome].pct_change()\n    full_grouped[full_grouped[\"pct_change_\" + covid_outcome] == np.inf] = 0\n\n# Replace space in variable names with '_'\n\nfull_grouped.columns = full_grouped.columns.str.replace(\" \", \"_\")\n\nfull_grouped.reset_index(inplace=True)\n#full_grouped.head()","fce396a9":"covid_back=covid[['date','location','stringency_index']]","334fceb5":"covid_back=covid[['date','location','stringency_index']]\nfull_grouped = full_grouped.merge(covid_back,how='inner',left_on=['Date','Country\/Region'],right_on=['date','location'])\nfull_grouped['log_Confirmed_per_1000'] = np.log(full_grouped['Confirmed_per_1000']+1)\nfull_grouped.info()","bf883a6a":"# Visualize the missingness isue in the dataset\nsns.heatmap(cty_info.isnull(), cbar=False)","43549a1e":"def plot_gov_action(covid_outcome, gov_action, full_grouped_df):\n    \"\"\"\n    Function plots the government action and outcome \n    \n    Parameters:\n        covid_outcome (str): The outcome from covid\n        gov_action (str): The government action to be analysed \n        full_grouped_df (pandas.DataFrame): the data source used. From Kaggle's full_grouped data set \n    Returns:\n        null\n    \"\"\"\n    full_grouped_df = full_grouped_df[full_grouped_df[gov_action] != None]\n    full_grouped_df = full_grouped_df.replace([np.inf, -np.inf], np.nan)\n    full_grouped_df = full_grouped_df.dropna()\n    fig = px.scatter(\n        full_grouped_df,\n        x=\"log_day_rel_to_\" + gov_action,\n        y=covid_outcome,\n        color=\"Country\/Region\",\n        title=\"Log N days from \" + gov_action +'vs. '+covid_outcome,\n        height=600,trendline=\"ols\",\n        trendline_scope=\"overall\",trendline_color_override=\"black\")\n \n\n    fig.update_layout(yaxis=dict(range=[0, 1]))\n    fig.show()\n    ","fa022d2f":"# gov_actions = ['quarantine', 'schools', 'gathering', 'nonessential', 'publicplace','strinten']\nfor gov_action in gov_actions:\n    plot_gov_action('log_Confirmed_per_1000', gov_action, full_grouped)\n    ","a2fbd0a6":"\n#covid_strict=covid[covid['stringency_index']>=40]\nregion=full_grouped.WHO_Region.unique()\nprint(region)\n#covid_policy= covid[['date','location','continent','new_cases_smoothed_per_million','stringency_index']]\n","19db3a6c":"def get_stringency_plt(df,region,covid_measure):\n    \n    df = df[df['WHO_Region']==region]\n    fig = px.scatter(\n        df,\n        x='stringency_index',\n        y=covid_measure,\n        color=\"location\",\n        title=\"Stringency index on \"+covid_measure+\" in \"+ region,\n        height=600,trendline=\"ols\",\n        trendline_scope=\"overall\",trendline_color_override=\"black\")\n    fig.show()\n    ","4cd40bfb":"#full_grouped.info()","5562bae3":"#covid_measures=['log_Confirmed_per_1000','new_cases_smoothed_per_million','new_deaths_smoothed_per_million']\nget_stringency_plt(full_grouped,'South-East Asia','log_Confirmed_per_1000')\n#get_stringency_plt(full_grouped,'Western Pacific','log_Confirmed_per_1000')\nget_stringency_plt(full_grouped,'Americas','log_Confirmed_per_1000')\n#get_stringency_plt(full_grouped,'Eastern Mediterranean','log_Confirmed_per_1000')\n","e8ca7b93":"#set 80 as a bar.\ncovid_strict=full_grouped[full_grouped['stringency_index']>=70]\nget_stringency_plt(covid_strict,'Americas','log_Confirmed_per_1000')\nget_stringency_plt(covid_strict,'South-East Asia','log_Confirmed_per_1000')","1d0d8d22":"#Plot pairplot with countries organized by WHO regions\ng = sns.pairplot(full_grouped[['log_Confirmed_per_1000', 'stringency_index', 'avgtemp', 'urbanpop', 'WHO_Region']], hue='WHO_Region')","4c8450f1":"#plt.matshow(full_grouped.corr())\n#plt.show()\n\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = full_grouped.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Plot heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, square=True, ax=ax)\n\n","22fdd293":"post_schools=full_grouped['post_schools']\npost_gathering = full_grouped['post_gathering']\nstringency_index=full_grouped['stringency_index']\n","5745d593":"# 'post_schools', 'post_gathering', 'post_nonessential', 'post_publicplace',\n\n# Create interaction term\nfull_grouped['quarXurbanpop'] = full_grouped['post_quarantine'] * full_grouped['urbanpop']\nfull_grouped['gatherXstringency'] = post_gathering*stringency_index\n\n# OLS regression\ny = full_grouped['log_Confirmed_per_1000']\nX = full_grouped[['post_quarantine', 'post_gathering', 'stringency_index', 'urbanpop', 'quarXurbanpop','gatherXstringency']]\nX = sm.add_constant(X)\n\nols_model=sm.OLS(y,X.astype(float), missing='drop')\nresult=ols_model.fit()\nprint(result.summary2())","7dbf2065":"\n## Question 1: Do government actions matter?","d862912b":"We see the presence of some strong residuals. ","c6c7b1ff":"\n### Draw Packages","cfeb5c63":"# Check stringency index influence","421bf68d":"Please add these datasets:  \n1. countryinfo: https:\/\/www.kaggle.com\/koryto\/countryinfo   \n2. Covid19 datasets: https:\/\/www.kaggle.com\/imdevskp\/corona-virus-report   \n3. Covid19 worldometer: https:\/\/www.kaggle.com\/selfishgene\/covid19-worldometer-snapshots-since-april-18   ","b08564d9":"Over the covid period, the stringency index and confirmed cases are negatively correlated. While most of the data collapsed in high stringency index, we determined to investigate the relationship of government tight policies and confirmed cases for high stringency index case.","a38ef238":"We made stringency index and post gathering to a interaction term since tight government policy reduced the gatherming limit. We beleive they are dependent and found that their interaction term has has a sginificant p value. This means the combined effects on confirmed cases have statisic influence.","585184e4":"## Question 2: How much do government interventions matter? ","f4445e46":"\n## SET UP","cbf95d1b":"After transforming day_rel_to_gov avtions to log days and transforming confirmed cases to log confirmed cases, and adjusting the range, we see a better least squared trendline in each of the goverment actions above. We view the relationship in a global perspective and the trend is set to be overall trend. All the regression line shows a negative slope which means that with increased days of government actions being enacted, the percentage change in confirmed cases decrease. ","64742e52":"Note: sex ratio (i.e., amount of males per female) in each country and sex ratio by age groups. Lung disease data (i.e., death rate per 100k people) in each country and lung disease by sex.","e0832ddd":"### Import and Wrangle Data","44646d5e":"When stringency index is bigger , there is a clear negative correlation between tighter government policy and confirmed cases."}}