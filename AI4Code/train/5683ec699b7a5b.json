{"cell_type":{"eb3c8526":"code","a5ad0feb":"code","928844c4":"code","3124919b":"code","9edd601a":"code","740623f0":"code","dd4fe69e":"code","eacb8ecd":"code","ef083e58":"code","f6c69929":"code","b2c2bbf2":"code","7279747f":"code","528b0e19":"code","de8fde99":"code","9ec13b1b":"code","34fb26a9":"code","e07ece4f":"code","37581d57":"code","0f77c68e":"code","10157bc6":"code","021ed37d":"code","a31ec472":"markdown","aea0cb75":"markdown","dbfced9f":"markdown","78647ac1":"markdown","1efee327":"markdown"},"source":{"eb3c8526":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a5ad0feb":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","928844c4":"train.info()","3124919b":"train.head()","9edd601a":"Y_Train = train[\"label\"]\nX_Train = train.drop(labels = [\"label\"], axis = 1)\n\nX_Train = X_Train.values.reshape(-1,28,28,1)\nX_Test = test.values.reshape(-1,28,28,1)","740623f0":"print(\"Number of records in training data \"+str(X_Train.shape[0]))\nprint(\"Number of records in test data \"+str(test.shape[0]))","dd4fe69e":"import matplotlib.pyplot as plt\nimport random\n\nplt.figure(figsize=(10,5))\nfor i in range(10):  \n    plt.subplot(1, 10, i+1)\n    r = random.randint(0, X_Train.shape[0])\n    plt.imshow(X_Train[r].reshape((28,28)),cmap=plt.cm.binary)\n    plt.axis('off')","eacb8ecd":"## Normalization\nX_Train = X_Train \/ 255.0\nX_Test = X_Test \/ 255.0","ef083e58":"# Augmentation\nimage = X_Train[r].reshape((28,28))\nplt.imshow(image)","f6c69929":"from skimage import transform as tf\n\n# specify x and y coordinates to be used for shifting (mid points)\nshift_x, shift_y = image.shape[0]\/2, image.shape[1]\/2\n\n# translation by certain units\nmatrix_to_topleft = tf.SimilarityTransform(translation=[-shift_x, -shift_y])\nmatrix_to_center = tf.SimilarityTransform(translation=[shift_x, shift_y])\n\n\n# rotation\nrot_transforms =  tf.AffineTransform(rotation=np.deg2rad(15))\nrot_matrix = matrix_to_topleft + rot_transforms + matrix_to_center\nrot_image = tf.warp(image, rot_matrix)\n\n# scaling \nscale_transforms = tf.AffineTransform(scale=(1.5, 1.5))\nscale_matrix = matrix_to_topleft + scale_transforms + matrix_to_center\nscale_image_zoom_out = tf.warp(image, scale_matrix)\n\nscale_transforms = tf.AffineTransform(scale=(0.8, 0.8))\nscale_matrix = matrix_to_topleft + scale_transforms + matrix_to_center\nscale_image_zoom_in = tf.warp(image, scale_matrix)\n\n# shear transforms\nshear_transforms = tf.AffineTransform(shear=np.deg2rad(20))\nshear_matrix = matrix_to_topleft + shear_transforms + matrix_to_center\nshear_image = tf.warp(image, shear_matrix)","b2c2bbf2":"items = [image, rot_image, scale_image_zoom_out, scale_image_zoom_in, shear_image]\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, sharey=True)\nf.set_figwidth(15)\nax1.imshow(image)\nax2.imshow(rot_image)\nax3.imshow(scale_image_zoom_out)\nax4.imshow(scale_image_zoom_in)\nax5.imshow(shear_image)","7279747f":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        rotation_range=15,  ## Degree range for random rotations.\n        zoom_range = 0.10,  ## Range for random zoom\n        width_shift_range=0.1, ## fraction of total width\n        height_shift_range=0.1, ## fraction of total height\n        shear_range=0.1,\n)\n\nval_datagen = ImageDataGenerator()","528b0e19":"## Bring target to categorical\nfrom keras.utils.np_utils import to_categorical\n\nlabels = to_categorical(Y_Train, num_classes = 10)","de8fde99":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, Dense\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Conv2D(128, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","9ec13b1b":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","34fb26a9":"batch_size = 50\nepochs = 50\n\ntrain_generator = datagen.flow(\n    X_Train,\n    labels,\n    batch_size=batch_size\n)","e07ece4f":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nmodel_name = 'model' + '\/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model.h5'\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\ncallbacks_list = [checkpoint, LR]","37581d57":"## Lets keep 10% of the data for validation\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_Train, labels, test_size = 0.1)\n\nmodel_hist = model.fit_generator(train_generator, steps_per_epoch=len(X_train)\/batch_size, epochs=epochs, verbose=1, \n                    callbacks=callbacks_list,\n                    validation_data = (X_val,Y_val), class_weight=None, workers=1, initial_epoch=0)","0f77c68e":"plt.plot(model_hist.history['loss'])\nplt.plot(model_hist.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","10157bc6":"X_Test.shape","021ed37d":"predicted_digits = model.predict(X_Test).argmax(axis=-1)\nresult_df = pd.DataFrame()\nresult_df['ImageId'] = list(range(1,X_Test.shape[0] + 1))\nresult_df['Label'] = predicted_digits\nresult_df.to_csv(\"submission.csv\", index = False)","a31ec472":"**Lets build our network using keras**","aea0cb75":"We can achive above transformation using ImageDataGenerator which can then be used to feed images to our model.","dbfced9f":"We have total of 42000 records in training data. Lets perform necessary pre processing steps-\n\n1. Normalization : Normalize all pixel values to same scale\n2. Augmentation : generate more images by introducing some distortions ( like scaling, zooming, rotating... etc)\n","78647ac1":"Lets visualize some random samples","1efee327":"We can see that first column is the label while other columns are the pixel values for the digit"}}