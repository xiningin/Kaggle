{"cell_type":{"7a5a4e5b":"code","9a030d21":"code","5e61330d":"code","d4860637":"code","f430d247":"code","da87198b":"code","f222de17":"code","c830fc5c":"code","cf810e69":"code","e62d10f7":"code","58b65727":"code","be721814":"code","131776a6":"markdown","4b87ab8b":"markdown","d2ad3c1d":"markdown","0acecd8c":"markdown"},"source":{"7a5a4e5b":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","9a030d21":"train = pd.read_csv( \"..\/input\/train.csv\")\ntrain.head()","5e61330d":"df = pd.DataFrame(train)\nprint(df.columns)\ndf.head()","d4860637":"#df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n#df['ClassId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n#df.head()\n#df['hasmask'] = ~ df['EncodedPixels'].isna()\n#df.head()\n#mask_count_df = df1.groupby('ImageId').agg(np.sum).reset_index()\n#mask_count_df.sort_values('hasmask', ascending=False, inplace=True)\n#print(mask_count_df.shape)\n#mask_count_df.head()\n#sub_df = pd.read_csv('..\/input\/sample_submission.csv')\n#sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n#test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\n#test_imgs.head()\n#non_missing_train_id = mask_count_df[mask_count_df['hasmask'] > 0]\n#non_missing_train_id.head()","f430d247":"df = df[ df['EncodedPixels'].notnull() ]\nprint( df.shape )\ndf.head()","da87198b":"import cv2\ndef rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height,width), k=1 ) )\n\nfig=plt.figure(figsize=(20,100))\ncolumns = 2\nrows = 50\nfor i in range(1, 100+1):\n    fig.add_subplot(rows, columns, i)\n    \n    fn = df['ImageId'].iloc[i].split('_')[0]\n    img = cv2.imread( '..\/input\/train_images\/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask( df['EncodedPixels'].iloc[i], img.shape  )\n    img[mask==1,0] = 255\n    \n    plt.imshow(img)\nplt.show()","f222de17":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2","c830fc5c":"train_path = \"..\/input\/train_images\"","cf810e69":"def loadImages(path):\n    # Put files into lists and return them as one list of size 4\n    image_files = sorted([os.path.join(path, file)\n         for file in os.listdir(path) if      file.endswith('.jpg')])\n \n    return image_files","e62d10f7":"data = loadImages(train_path)","58b65727":"# Display one image\ndef display_one(a, title1 = \"Original\"):\n    plt.imshow(a), plt.title(title1)\n    plt.xticks([]), plt.yticks([])\n    plt.show()\n    \n    \n# Display two images\ndef display(a, b, title1 = \"Original\", title2 = \"Edited\"):\n    plt.subplot(121), plt.imshow(a), plt.title(title1)\n    plt.xticks([]), plt.yticks([])\n    plt.subplot(122), plt.imshow(b), plt.title(title2)\n    plt.xticks([]), plt.yticks([])\n    plt.show()\n    \n    \n# Preprocessing\ndef processing(data):\n    # loading image\n    # Getting 3 images to work with \n    img = [cv2.imread(i, cv2.IMREAD_UNCHANGED) for i in data[:3]]\n    print('Original size',img[0].shape)\n    # --------------------------------\n    # setting dim of the resize\n    height = 220\n    width = 220\n    dim = (width, height)\n    res_img = []\n    for i in range(len(img)):\n        res = cv2.resize(img[i], dim, interpolation=cv2.INTER_LINEAR)\n        res_img.append(res)\n\n    # Checking the size\n    print(\"RESIZED\", res_img[1].shape)\n    \n    # Visualizing one of the images in the array\n    original = res_img[1]\n    display_one(original)\n    \n    no_noise = []\n    for i in range(len(res_img)):\n        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n        no_noise.append(blur)\n\n\n    image = no_noise[1]\n    display(original, image, 'Original', 'Blured')\n    \n    # Segmentation\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\n# Displaying segmented images\n    display(original, thresh, 'Original', 'Segmented')\n    \n    # Further noise removal\n    kernel = np.ones((3, 3), np.uint8)\n    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n\n# sure background area\n    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n\n# Finding sure foreground area\n    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n\n# Finding unknown region\n    sure_fg = np.uint8(sure_fg)\n    unknown = cv2.subtract(sure_bg, sure_fg)\n\n#Displaying segmented back ground\n    display(original, sure_bg, 'Original', 'Segmented Background')\n    \n    # Marker labelling\n    ret, markers = cv2.connectedComponents(sure_fg)\n\n# Add one to all labels so that sure background is not 0, but 1\n    markers = markers + 1\n\n# Now, marking the region of unknown with zero\n    markers[unknown == 255] = 0\n\n    markers = cv2.watershed(image, markers)\n    image[markers == -1] = [255, 0, 0]\n\n# Displaying markers on the image\n    display(image, markers, 'Original', 'Marked')","be721814":"processing(data)","131776a6":"Thanks to https:\/\/www.kaggle.com\/titericz for the code","4b87ab8b":"Purely a practice and exploratory kernel","d2ad3c1d":"I thank author of https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-2-step-pipeline for the code for the text data","0acecd8c":"Image processing practice"}}