{"cell_type":{"b9a644fd":"code","5ba9f8cc":"code","b03ef67d":"code","33cef897":"code","d41426eb":"code","137211dd":"code","39433802":"code","49103396":"code","cf6b7cc2":"code","60902bda":"code","60bebfeb":"code","9f3905c0":"code","82bac60d":"code","097fea69":"code","a0248459":"code","0aab3a73":"code","3fc45d77":"code","d913ea12":"code","5ff39939":"code","b8a32c6a":"code","6bd6e1f1":"code","a7c0a4a3":"code","8384f81e":"code","95bac191":"code","2756b64a":"code","c43007b2":"code","99625b63":"code","b88c79c7":"code","24013ea8":"code","2e63b62a":"code","8647be78":"code","14398b04":"code","2ca26937":"code","77bd5da5":"code","bcc8c876":"code","2a7ceadf":"code","2892888d":"code","fb060f23":"code","f05c35d2":"code","760d56f8":"code","2a5d00fe":"code","3f09d913":"code","df3bd358":"code","c10122dc":"code","e2610451":"code","427e3a7b":"code","619d59cc":"code","af52b46c":"code","42ed20e1":"code","7de9d955":"code","c6ac163d":"code","e81ef915":"code","599c5ec0":"code","183d8e19":"code","e4911e35":"code","2e213517":"code","74f9ded8":"code","1e4064cb":"code","fcbb99a4":"code","5eb7274e":"code","47205483":"code","e08af951":"code","35065dc0":"code","e5fc1ab5":"code","8ade8f11":"code","600b3207":"code","3fe6eb28":"code","e558fc77":"code","75a280da":"code","0fa5cb8e":"code","c2c1a887":"code","3f90010d":"code","5520ff45":"code","665a2aa8":"code","2adfc83f":"code","ef66d493":"code","bb153e68":"code","d3d0453b":"code","53efd138":"markdown"},"source":{"b9a644fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ba9f8cc":"print(os.listdir(\"\/kaggle\/input\/petfinder-adoption-prediction\"))\nprint(os.listdir(\"\/kaggle\/input\/petfinder-adoption-prediction\/train\"))","b03ef67d":"trainData = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/train\/train.csv')","33cef897":"trainData.head()","d41426eb":"trainData.info()","137211dd":"#Adoption speed\nprint(trainData['AdoptionSpeed'].value_counts())\ntrainData['AdoptionSpeed'].hist(grid = False)","39433802":"# Type 1 = dog\n# Type 2 = cat\ntrainData['Type'].value_counts()","49103396":"# Adoption speed for dogs\ntrainData[trainData['Type'] == 1]['AdoptionSpeed'].hist(grid=False);","cf6b7cc2":"# Adoption speed for cats\ntrainData[trainData['Type'] == 2]['AdoptionSpeed'].hist(grid=False);","60902bda":"for w in trainData['Name']:\n    print(w)","60bebfeb":"#Special names: \n#1) nan\n#2) Multiple names: Siu Pak & Her 6 Puppies\n#3) Generic names: 2 Mths Old Cute Kitties, Lost Dog, No Name, 9 Puppies For Adoption!, No Name Yet, Not Named, (No Name),[No Name], etc.\n#4) Meaningless names: IO-Male-03, H3, Z3, DO RE MI, BB, Y1","9f3905c0":"for name in trainData[trainData['Name'].isna()]['Name']:\n    print(name)","82bac60d":"names = []\nfor name in trainData['Name']:\n    if 'name' in str(name).lower():\n        names.append(str(name))\n   \nfor name in names:\n    print(name)\n    \n# No names:\n# Lost Dog, No Name, 9 Puppies For Adoption!, No Name Yet, Not Named, (No Name),[No Name], $ To Be Named $, Noname, Unamed Yet 2, Unamed, Unnamed, No Names Yet, Not Named Yet,\n# Unnamed 3 Kittens ( By Dani), No Name Kitten, Nameless, (no Name), Name Them & Love Them, Not Name Yet, No Names Yet, *No Name*, \"no Name\", (No Names Yet), * To Be Named *,\n# Unnamed., NO NAME, Not Yet Name, No Name Kitties, Waiting For You To Give Him A Name, No Names Yet, *please Name Us*, Newborn *no Name, - To Be Named -, \n# No Name Yet, It's Up To The Owner, Name Them & Love Them 3, NO NAME YET, (No Name - She Is Just A Stray), Cream Cat (unnamed), (no Name), Wait For The Real Owner To Name It,\n# 4 Kittens Open For Adoption (no Name), Need You Giving  A Name, No Name 2, UNNAMED, Unamed Yet, No Name Yet...., Kitten....no Name, Name Less Kitten, Haven't Named Them,\n# No Name Yet (Must Neuter), Haven't Name Yet, Haven't Been Named, Not Yet Named","097fea69":"# Normalizing \"nan\" names to empty strings.\ntrainData.loc[trainData['Name'].isna(), 'Name'] = \"\"\nprint(\"Number of 'NaN' names: \" + str(len(trainData[trainData['Name'] == \"\"])))","a0248459":"# Normalizing different forms of \"Unnamed\"\nunnamedForms = set(['Lost Dog', 'No Name', '9 Puppies For Adoption!', 'No Name Yet', 'Not Named', '(No Name)', '[No Name]', '$ To Be Named $', 'Noname', 'Unamed Yet 2',\\\n               'Unamed', 'Unnamed', 'No Names Yet', 'Not Named Yet', 'Unnamed 3 Kittens ( By Dani)', 'No Name Kitten', 'Nameless', '(no Name)', 'Name Them & Love Them', \\\n               'Not Name Yet', 'No Names Yet', '*No Name*', '\"no Name\"', '(No Names Yet)', '* To Be Named *', 'Unnamed.', 'NO NAME', 'Not Yet Name', 'No Name Kitties', \\\n               'Waiting For You To Give Him A Name', 'No Names Yet', '*please Name Us*', 'Newborn *no Name', '- To Be Named -', 'No Name Yet, It\\'s Up To The Owner', \\\n               'Name Them & Love Them 3', 'NO NAME YET', '(No Name - She Is Just A Stray)', 'Cream Cat (unnamed)', '(no Name)', 'Wait For The Real Owner To Name It', \\\n               '4 Kittens Open For Adoption (no Name)', 'Need You Giving  A Name', 'No Name 2', 'UNNAMED', 'Unamed Yet', 'No Name Yet....', 'Kitten....no Name', \\\n               'Name Less Kitten', 'Haven\\'t Named Them', 'No Name Yet (Must Neuter)', 'Haven\\'t Name Yet', 'Haven\\'t Been Named', 'Not Yet Named'])\n\ntrainData.loc[trainData['Name'].isin(unnamedForms), 'Name'] = \"\"\ntrainData[trainData['Name'].isin(unnamedForms)] = \"\"\nprint(\"Number of 'NaN' names: \" + str(len(trainData[trainData['Name']==\"\"])))\n#print(trainData[trainData['Name'] == \"\"])","0aab3a73":"# Removing names that are codes (no vowels or two characters or less)\ncodeNames = set()\nfor name in trainData['Name']:\n    strName = str(name).lower()\n    if len(strName) < 3 or ('a' not in strName and 'e' not in strName and 'i' not in strName and 'o' not in strName and 'u' not in strName and 'y' not in strName):\n        codeNames.add(strName)\n    \nprint(\"Found \" + str(len(names)) + \" code names\")\n\ntrainData.loc[trainData['Name'].isin(codeNames), 'Name'] = \"\"\nprint(\"Number of 'NaN' names: \" + str(len(trainData[trainData['Name']==\"\"])))","3fc45d77":"# Adding feature for length of name.\ntrainData['Name_Length'] = trainData['Name'].map(str).apply(len)\nprint(trainData['Name_Length'].value_counts())","d913ea12":"# Adoption speed breakdown percentage for unnamed pets\n100*(trainData[trainData['Name'] == \"\"][\"AdoptionSpeed\"]).value_counts() \/ (len(trainData[trainData['Name'] == \"\"]))","5ff39939":"# Adoption speed breakdown percentage for named pets\n100*(trainData[trainData['Name'] != \"\"][\"AdoptionSpeed\"]).value_counts() \/ (len(trainData[trainData['Name'] != \"\"]))","b8a32c6a":"# Unnamed pets tend to be unadopted for more than 100 days by 7%, in comparison with named pets.","6bd6e1f1":"#trainData[[\"Age\", \"AdoptionSpeed\"]].hist()\ntrainData.boxplot(column=['Age'], by=['AdoptionSpeed'])","a7c0a4a3":"trainData[trainData[\"AdoptionSpeed\"] == 0][\"Age\"].value_counts()","8384f81e":"# Adding feature of Age in Years to group together pets with similar age.\ntrainData['Age_Years'] = trainData['Age'] \/\/ 12\ntrainData['Age_Years'].value_counts()","95bac191":"trainData.boxplot(column=['Age_Years'], by=['AdoptionSpeed'])","2756b64a":"# It seems that younger pets are preferred: Pets adopted the same day are exclusively under 10 years old, while pets over 15 years old take more than 30\n# days to get adopted.","c43007b2":"# Breed Data\nbreedData = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/breed_labels.csv')\nbreedData.head(10)","99625b63":"# Creating feature \"IsPureBreed\"\ntrainData['IsPureBreed'] = (trainData[\"Breed1\"] == 0) | (trainData[\"Breed2\"] == 0) | (trainData[\"Breed1\"] == trainData[\"Breed2\"])","b88c79c7":"#100*(trainData[trainData['Name'] != \"\"][\"AdoptionSpeed\"]).value_counts() \/ (len(trainData[trainData['Name'] != \"\"]))\nprint(100*trainData[trainData['IsPureBreed']][\"AdoptionSpeed\"].value_counts() \/ (len(trainData[trainData['IsPureBreed']])))\ntrainData[trainData['IsPureBreed']][\"AdoptionSpeed\"].hist()","24013ea8":"print(100*trainData[~trainData['IsPureBreed']][\"AdoptionSpeed\"].value_counts() \/ (len(trainData[~trainData['IsPureBreed']])))\ntrainData[~trainData['IsPureBreed']][\"AdoptionSpeed\"].hist()","2e63b62a":"# Interestingly, mixed breeds have better adoption rates for the same day, \n# and much better chances of getting adopted before 100 days (only 19% take more than 100 days, versus 29% for purebreeds)","8647be78":"#Health\ntrainData[\"Health\"].value_counts()","14398b04":"# Adoption speed for healthy animals\nprint(100*trainData[trainData['Health'] == 1]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['Health'] == 1])))\ntrainData[trainData['Health'] == 1]['AdoptionSpeed'].hist(grid=False);","2ca26937":"# Adoption speed for animals with minor injuries\nprint(100*trainData[trainData['Health'] == 2]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['Health'] == 2])))\ntrainData[trainData['Health'] == 2]['AdoptionSpeed'].hist(grid=False);","77bd5da5":"# Adoption speed for animals with serious injuries\nprint(100*trainData[trainData['Health'] == 3]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['Health'] == 3])))\ntrainData[trainData['Health'] == 3]['AdoptionSpeed'].hist(grid=False)","bcc8c876":"# Healthy animals tend to get adopted more easily than animals with minor injuries and with series injuries. \n# In particular, 27% of healthy animals are not adopted within 100 days, while animals with minor injures have a rate of 35%, \n# and animals with serious injuries have a rate of 41% of not getting adopted after 100 days.","2a7ceadf":"# Photo amount.\ntrainData[\"PhotoAmt\"].value_counts()","2892888d":"print(100*trainData[trainData['PhotoAmt'] == 0]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['PhotoAmt'] == 0])))\ntrainData[trainData['PhotoAmt'] == 0]['AdoptionSpeed'].hist()","fb060f23":"print(100*trainData[trainData['PhotoAmt'] == 1]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['PhotoAmt'] == 1])))\ntrainData[trainData['PhotoAmt'] == 1]['AdoptionSpeed'].hist()","f05c35d2":"print(100*trainData[trainData['PhotoAmt'] == 2]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['PhotoAmt'] == 2])))\ntrainData[trainData['PhotoAmt'] == 2]['AdoptionSpeed'].hist()","760d56f8":"print(100*trainData[trainData['PhotoAmt'] > 2]['AdoptionSpeed'].value_counts() \/ (len(trainData[trainData['PhotoAmt'] > 2])))\ntrainData[trainData['PhotoAmt'] > 2]['AdoptionSpeed'].hist()","2a5d00fe":"# The percentage of pets not adopted after 100 days for profiles with zero photos is 64%, while one or more photos seem to increase the chances of \n# being adopted earlier.","3f09d913":"# Creating feature \"HasPhoto\"\ntrainData['HasPhoto'] = trainData[\"PhotoAmt\"] > 0","df3bd358":"# VideoAmt feature\ntrainData['VideoAmt'].value_counts()","c10122dc":"# The VideoAmt category is very skewed to zero, as there rarely are any videos attahced to the profiles, so it's hard to make an inference with such a class imbalance.","e2610451":"# Quantity feature.\ntrainData['Quantity'].value_counts()","427e3a7b":"# The Quantity category is also strongly skewed to profiles with one animal.\n","619d59cc":"# Sentiment Analysis\n# Create dataframe for Sentiment Analysis\nimport json\n\npetIds = []\nmagnitudes = []\nscores = []\n\nfor sentimentFilename in os.listdir(\"\/kaggle\/input\/petfinder-adoption-prediction\/train_sentiment\"):\n    with open(\"\/kaggle\/input\/petfinder-adoption-prediction\/train_sentiment\/\" + sentimentFilename, 'r') as f:\n        jsonContent = json.loads(f.read())\n        magnitude = jsonContent['documentSentiment']['magnitude']\n        score = jsonContent['documentSentiment']['score']\n        petIds.append(sentimentFilename.split('.')[0])\n        magnitudes.append(float(magnitude))\n        scores.append(float(score))","af52b46c":"rows = []\nfor i in range(len(petIds)):\n    rows.append([petIds[i], magnitudes[i], scores[i]])\ncolumns = ['PetID', 'SentimentMagnitude', 'SentimentScore']\n\nsentimentDf=pd.DataFrame(rows)\nsentimentDf.columns = columns\n\nsentimentDf.head(10)","42ed20e1":"trainDataWithSentiment = pd.merge(trainData, sentimentDf, on='PetID')\ntrainDataWithSentiment.head(100)","7de9d955":"# Sentiment Analysis\ntrainDataWithSentiment['SentimentScore'].value_counts()","c6ac163d":"#print(100*trainDataWithSentiment[trainDataWithSentiment['SentimentScore'] > 0]['AdoptionSpeed'].value_counts() \/ (len(trainDataWithSentiment[trainDataWithSentiment['SentimentScore'] > 0])))\n#trainData[trainDataWithSentiment['SentimentScore'] > 0]['AdoptionSpeed'].hist()\ntrainDataWithSentiment[trainDataWithSentiment['SentimentScore'] > 0]['AdoptionSpeed'].hist()","e81ef915":"trainDataWithSentiment[trainDataWithSentiment['SentimentScore'] < 0]['AdoptionSpeed'].hist()","599c5ec0":"trainDataWithSentiment.boxplot(column=['SentimentScore'], by=['AdoptionSpeed'])","183d8e19":"trainDataWithSentiment.boxplot(column=['SentimentMagnitude'], by=['AdoptionSpeed'])","e4911e35":"trainDataWithSentiment['SentimentMultiplier'] = trainDataWithSentiment['SentimentScore'] * trainDataWithSentiment['SentimentMagnitude']","2e213517":"trainDataWithSentiment.boxplot(column=['SentimentScore'], by=['AdoptionSpeed'])","74f9ded8":"trainDataWithSentiment.boxplot(column=['SentimentMagnitude'], by=['AdoptionSpeed'])","1e4064cb":"trainDataWithSentiment.boxplot(column=['SentimentMultiplier'], by=['AdoptionSpeed'])","fcbb99a4":"# As the sentiment score becomes more negative adoption takes longer or becomes more unlikely.\n# Larger sentiment magnitudes also results in the pets taking longer to be adopted.\n# As the sentimient multipliers (score * magnitude) become more extreme (positively or negatively) the pet will take longer to get adopted.","5eb7274e":"# Adding DescriptionLength\ntrainDataWithSentiment['DescriptionLength'] = trainDataWithSentiment['Description'].map(str).apply(len)\nprint(trainDataWithSentiment['DescriptionLength'].value_counts())","47205483":"# Adding IsSinglePet\ntrainDataWithSentiment['IsSinglePet'] = trainDataWithSentiment['Quantity'] == 1\nprint(trainDataWithSentiment['IsSinglePet'].value_counts())","e08af951":"# Adding IsFree\ntrainDataWithSentiment['IsFree'] = trainDataWithSentiment['Fee'] == 0\nprint(trainDataWithSentiment['IsFree'].value_counts())","35065dc0":"# Adding HasVideo\ntrainDataWithSentiment['HasVideo'] = trainDataWithSentiment['VideoAmt'] > 0\nprint(trainDataWithSentiment['HasVideo'].value_counts())","e5fc1ab5":"# Building a model\n\n#trainColumns = ['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Health', 'PhotoAmt', 'SentimentScore', 'SentimentMagnitude', \\\n#            'Name_Length', 'Age_Years', 'IsPureBreed', 'HasPhoto', 'SentimentMultiplier', 'AdoptionSpeed']\n\n#trainColumns_lgb = ['Type', 'Age', 'Breed1', 'Breed2', 'Health', 'PhotoAmt', 'SentimentScore', 'SentimentMagnitude', \\\n#                    'Name_Length', 'Age_Years', 'IsPureBreed', 'HasPhoto', 'SentimentMultiplier', 'AdoptionSpeed']\n\n\ntrainColumns_lgb = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', \\\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \\\n       'Sterilized', 'Health', 'Fee', 'SentimentScore', 'SentimentMagnitude', \\\n       'Name_Length', 'Age_Years', 'IsPureBreed', 'HasPhoto', 'SentimentMultiplier', \\\n       'PhotoAmt', 'DescriptionLength', 'Quantity', 'IsSinglePet', 'IsFree', 'VideoAmt', 'HasVideo', 'AdoptionSpeed']\n\n#trainColumns_lgb = ['Type', 'Age', 'Breed1', 'Breed2', 'Health', 'SentimentScore', 'SentimentMagnitude', \\\n#       'Name_Length', 'Age_Years', 'IsPureBreed', 'HasPhoto', 'SentimentMultiplier', \\\n#       'PhotoAmt', 'AdoptionSpeed']\n\n\n#lgb_categorical_features = ['Type', 'Breed1', 'Breed2', 'Health']\n\nlgb_categorical_features = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'Health', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \\\n                           'Sterilized']\n\nlgb_bool_features = ['HasPhoto', 'IsSinglePet', 'IsFree', 'IsPureBreed', 'HasVideo']\n\n\n#lgb_categorical_features = ['Type', 'Breed1', 'Breed2', 'Health', 'HasPhoto']\n\n#lgb_numerical_features = ['Age', 'PhotoAmt', 'Age_Years']\nlgb_numerical_features = ['Age', 'PhotoAmt', 'Age_Years', 'Fee', 'SentimentScore', 'SentimentMagnitude', 'Name_Length', 'SentimentMultiplier', \\\n                          'DescriptionLength', 'Quantity', 'VideoAmt']\n#lgb_numerical_features = ['Age', 'PhotoAmt', 'Age_Years', 'SentimentScore', 'SentimentMagnitude', 'Name_Length', 'SentimentMultiplier']\n\n# Type, Name, Age, Breed1, Breed2, Health, PhotoAmt, Age_Years\n\nX_train_lgb = trainDataWithSentiment[trainColumns_lgb].copy()\n# Change this\nX_test_lgb = X_train_lgb.copy()","8ade8f11":"def train_models(X_train, X_test, categorical_features, numerical_features, bool_features):\n    \n    import lightgbm as lgb\n\n    params = {#'num_leaves': 512,\n         'num_leaves' : 32,\n         'objective': 'multiclass',\n         'max_depth': -1,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 3,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"random_state\": 42,          \n         \"verbosity\": -1,\n         \"num_class\": 5}\n\n    # Additional parameters:\n    early_stop = 500\n    verbose_eval = 100\n    num_rounds = 10000\n    #n_splits = 5\n    n_splits = 6\n    \n    from sklearn.model_selection import StratifiedKFold\n    \n    #kfold = StratifiedKFold(n_splits=n_splits)\n    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15)\n\n    #oof_train = np.zeros((X_train.shape[0]))\n    #oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    i = 0\n    val_qwks = []\n\n    # Encode Label\n    from sklearn.preprocessing import LabelEncoder\n\n    label_encoder = LabelEncoder()\n    #trainData.loc[trainData['Name'].isin(unnamedForms), 'Name'] = \"\"\n    #X_train.loc[:, 'AdoptionSpeed'] = label_encoder.fit_transform(X_train['AdoptionSpeed'])\n    #X_train['AdoptionSpeed'] = label_encoder.fit_transform(X_train['AdoptionSpeed'])\n    X_train['AdoptionSpeed'] = label_encoder.fit_transform(X_train['AdoptionSpeed'])\n    \n    # Transform features into categorical.\n    for c in categorical_features:\n        #X_train[c] = X_train[c].astype('category')\n        X_train[c] = X_train[c].astype('int')\n        \n    # Transform features into float.\n    for c in numerical_features:\n        X_train[c] = X_train[c].astype('float')\n        \n    # Transform features into bool.\n    for c in bool_features:\n        X_train[c] = X_train[c].astype('bool')\n    \n    for train_index, valid_index in kfold.split(X_train, X_train['AdoptionSpeed'].values):\n    \n        X_tr = X_train.iloc[train_index, :]\n        X_val = X_train.iloc[valid_index, :]\n    \n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n    \n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n    \n        #print('\\ny_tr distribution: {}'.format(Counter(y_tr)))\n    \n        d_train = lgb.Dataset(X_tr, label=y_tr)\n        d_valid = lgb.Dataset(X_val, label=y_val)\n        watchlist = [d_train, d_valid]\n    \n        print('training XGBoost:')\n        # Predict using xgboost\n        import xgboost as xgb\n        xgb_model = xgb.XGBRegressor(booster = \"gbtree\", objective = \"multi:softprob\", num_class = 5, eval_metric = \"mlogloss\")\n        xgb_model.fit(X_tr, y_tr)\n        xgb_val_pred = xgb_model.predict(X_val)\n        \n        xgb_rounded_val_preds = []\n        \n        for pred in xgb_val_pred:\n            xgb_rounded_val_preds.append(np.argmax(pred))\n        \n        print('training Random Forest:')\n        # Predict using Random Forest\n        from sklearn.ensemble import RandomForestClassifier\n        randomForest = RandomForestClassifier(n_estimators=100, n_jobs=2, random_state=1357)\n        randomForest.fit(X_tr, y_tr)\n        \n        randomForest_val_pred = randomForest.predict(X_val)\n        \n        randomForest_rounded_val_preds = []\n        \n        for pred in randomForest_val_pred:\n            randomForest_rounded_val_preds.append(pred)\n            \n        print('training LGB')\n        # Predict using LGB\n        lgbModel = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n        \n        lgb_val_pred = lgbModel.predict(X_val, num_iteration=lgbModel.best_iteration)\n        \n        lgb_rounded_val_preds = []\n        \n        for pred in lgb_val_pred:\n            lgb_rounded_val_preds.append(np.argmax(pred))\n        \n        \n        \n        from sklearn.tree import DecisionTreeClassifier\n        print('training Decision Trees')\n        decisionTree = DecisionTreeClassifier()\n        decisionTree.fit(X_tr, y_tr)\n        \n        decisionTree_val_pred = decisionTree.predict(X_val)\n        \n        decisionTree_rounded_val_preds = []\n        \n        for pred in decisionTree_val_pred:\n            decisionTree_rounded_val_preds.append(pred)\n        \n        \n        from sklearn.naive_bayes import GaussianNB\n        print('training Naive Bayes Classifier')\n        naiveBayes = GaussianNB()\n        naiveBayes.fit(X_tr, y_tr)\n        \n        naiveBayes_val_pred = naiveBayes.predict(X_val)\n        \n        naiveBayes_rounded_val_preds = []\n        \n        for pred in naiveBayes_val_pred:\n            naiveBayes_rounded_val_preds.append(pred)\n        \n        \n        #from sklearn import svm\n        #print('training SVM')\n        #linearSVM = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_tr, y_tr)\n        \n        #linearSVM_val_pred = linearSVM.predict(X_val)\n        \n        #linearSVM_rounded_val_preds = []\n        \n        #for pred in linearSVM_val_pred:\n        #    linearSVM_rounded_val_preds.append(pred)\n        \n        #test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n        #val_pred = model.predict(X_val)\n\n        #xgb_d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        #xgb_d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n        #model = xgb.train(dtrain=xgb_d_train, num_boost_round=num_rounds, evals=watchlist, early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n        #model = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\n        #model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.85)\n        #xgb_model = xgb.XGBRegressor(booster = \"gbtree\", objective = \"multi:softprob\", num_class = 5, eval_metric = \"mlogloss\")\n        #booster = \"gbtree\", objective = \"multi:softprob\", num_class = 3, eval_metric = \"mlogloss\"\n        #xgb_model.fit(X_tr, y_tr)\n    \n        #val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n        #test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n        #val_pred = model.predict(X_val)\n    \n        #oof_train[valid_index] = val_pred\n        #oof_test[:, i] = test_pred\n        \n        # Merging all predictions.\n        val_pred = []\n        \n        for pred in xgb_rounded_val_preds:\n            val_pred.append([pred])\n            \n        for i in range(len(val_pred)):\n            val_pred[i].append(randomForest_rounded_val_preds[i])\n            \n        for i in range(len(val_pred)):\n            val_pred[i].append(lgb_rounded_val_preds[i])\n            \n        for i in range(len(val_pred)):\n            val_pred[i].append(decisionTree_rounded_val_preds[i])\n            \n        for i in range(len(val_pred)):\n            val_pred[i].append(naiveBayes_rounded_val_preds[i])\n            \n            \n        #for i in range(len(val_pred)):\n        #    val_pred[i].append(linearSVM_rounded_val_preds[i])\n        \n        # Computing  QWK\n        from sklearn.metrics import cohen_kappa_score, confusion_matrix\n\n        #lgb_train_preds = lgb_model.predict(X_train_lgb, num_iteration=lgb_model.best_iteration)\n        #train_actuals = X_train_lgb['AdoptionSpeed'].values\n\n        #print(\"y_val: \" + str(y_val[:5]))\n        #print(\"val_pred: \" + str(val_pred[:5]))\n        rounded_val_preds = []\n        \n        #for pred in val_pred:\n        #    minDiff = pred\n        #    minClass = 0\n        #    for c in range(5):\n        #        if abs(c - pred) < minDiff:\n        #            minDiff = abs(c - pred)\n        #            minClass = c\n        #    rounded_val_preds.append(minClass)\n        \n        for pred in val_pred:\n            rounded_val_preds.append(np.bincount(pred).argmax())\n        \n        print(\"rounded_val_pred: \" + str(rounded_val_preds[:5]))\n        qwk = cohen_kappa_score(y_val, rounded_val_preds, weights=\"quadratic\")\n        val_qwks.append(qwk)\n        print(\"QWK score: \" + str(qwk))\n    \n        i += 1\n    print(\"Average Validation QWK: \" + str(np.mean(val_qwks)))\n    \n    # Return the latest trained k-fold, perhaps we want to train on the entire data or return the one with the best validation score.\n    return [xgb_model, randomForest, decisionTree, naiveBayes, lgbModel]","600b3207":"models = train_models(X_train_lgb, X_test_lgb, lgb_categorical_features, lgb_numerical_features, lgb_bool_features)","3fe6eb28":"xgb_model = models[0]\nrandomForest = models[1]\ndecisionTree = models[2]\nnaiveBayes = models[3]\nlgbModel = models[4]","e558fc77":"# Save the models as a Pickle files.\nimport joblib\n\n#os.makedirs(\"outputs\", exist_ok=True)\n#joblib.dump(value=xgb_model, filename=\"outputs\/xgb.pkl\")\n\n#os.makedirs(\"outputs\", exist_ok=True)\n#joblib.dump(value=randomForest, filename=\"outputs\/randomForest.pkl\")\n\n#os.makedirs(\"outputs\", exist_ok=True)\n#joblib.dump(value=decisionTree, filename=\"outputs\/decisionTree.pkl\")\n\n#os.makedirs(\"outputs\", exist_ok=True)\n#joblib.dump(value=naiveBayes, filename=\"outputs\/naiveBayes.pkl\")\n\n#os.makedirs(\"outputs\", exist_ok=True)\n#joblib.dump(value=lgbModel, filename=\"outputs\/lgbModel.pkl\")","75a280da":"import lightgbm\n\nprint(joblib.__version__)\nprint(lightgbm.__version__)\n\nimport sys\nprint(sys.version)\n\nimport pandas\nprint(pandas.__version__)\n\nimport numpy\nprint(numpy.__version__)\n\nimport xgboost\nprint(xgboost.__version__)","0fa5cb8e":"# Test predictions on fresh data\ntestData = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/test\/test.csv')\n#lgb_test_pred = lgbModel.predict(X_val, num_iteration=lgbModel.best_iteration)\n","c2c1a887":"# Add Sentiment feature\n# Sentiment Analysis\n# Create dataframe for Sentiment Analysis\n\npetIds = []\nmagnitudes = []\nscores = []\n\nfor sentimentFilename in os.listdir(\"\/kaggle\/input\/petfinder-adoption-prediction\/test_sentiment\"):\n    with open(\"\/kaggle\/input\/petfinder-adoption-prediction\/test_sentiment\/\" + sentimentFilename, 'r') as f:\n        jsonContent = json.loads(f.read())\n        magnitude = jsonContent['documentSentiment']['magnitude']\n        score = jsonContent['documentSentiment']['score']\n        petIds.append(sentimentFilename.split('.')[0])\n        magnitudes.append(float(magnitude))\n        scores.append(float(score))\n        \nrows = []\nfor i in range(len(petIds)):\n    rows.append([petIds[i], magnitudes[i], scores[i]])\ncolumns = ['PetID', 'SentimentMagnitude', 'SentimentScore']\n\ntestSentimentDf=pd.DataFrame(rows)\ntestSentimentDf.columns = columns\n\ntestSentimentDf.head(10)","3f90010d":"testDataWithSentiment = pd.merge(testData, testSentimentDf, on='PetID')\ntestDataWithSentiment.head(100)","5520ff45":"def prepareDataset(df):\n    \n    # Clean up the 'Name' column.\n    df.loc[df['Name'].isna(), 'Name'] = \"\"\n    \n    unnamedForms = set(['Lost Dog', 'No Name', '9 Puppies For Adoption!', 'No Name Yet', 'Not Named', '(No Name)', '[No Name]', '$ To Be Named $', 'Noname', 'Unamed Yet 2',\\\n               'Unamed', 'Unnamed', 'No Names Yet', 'Not Named Yet', 'Unnamed 3 Kittens ( By Dani)', 'No Name Kitten', 'Nameless', '(no Name)', 'Name Them & Love Them', \\\n               'Not Name Yet', 'No Names Yet', '*No Name*', '\"no Name\"', '(No Names Yet)', '* To Be Named *', 'Unnamed.', 'NO NAME', 'Not Yet Name', 'No Name Kitties', \\\n               'Waiting For You To Give Him A Name', 'No Names Yet', '*please Name Us*', 'Newborn *no Name', '- To Be Named -', 'No Name Yet, It\\'s Up To The Owner', \\\n               'Name Them & Love Them 3', 'NO NAME YET', '(No Name - She Is Just A Stray)', 'Cream Cat (unnamed)', '(no Name)', 'Wait For The Real Owner To Name It', \\\n               '4 Kittens Open For Adoption (no Name)', 'Need You Giving  A Name', 'No Name 2', 'UNNAMED', 'Unamed Yet', 'No Name Yet....', 'Kitten....no Name', \\\n               'Name Less Kitten', 'Haven\\'t Named Them', 'No Name Yet (Must Neuter)', 'Haven\\'t Name Yet', 'Haven\\'t Been Named', 'Not Yet Named'])\n\n    df.loc[trainData['Name'].isin(unnamedForms), 'Name'] = \"\"\n    \n    codeNames = set()\n    for name in df['Name']:\n        strName = str(name).lower()\n        if len(strName) < 3 or ('a' not in strName and 'e' not in strName and 'i' not in strName and 'o' not in strName and 'u' not in strName and 'y' not in strName):\n            codeNames.add(strName)\n    \n    df.loc[df['Name'].isin(codeNames), 'Name'] = \"\"\n    \n    \n    # Create new features.\n    categorical_features = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'Health', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \\\n                           'Sterilized']\n    \n    bool_features = ['HasPhoto', 'IsSinglePet', 'IsFree', 'IsPureBreed', 'HasVideo']\n\n    numerical_features = ['Age', 'PhotoAmt', 'Age_Years', 'Fee', 'SentimentScore', 'SentimentMagnitude', 'Name_Length', 'SentimentMultiplier', \\\n                          'DescriptionLength', 'Quantity', 'VideoAmt']\n    \n    df['Name_Length'] = df['Name'].map(str).apply(len)\n    df['Age_Years'] = df['Age'] \/\/ 12\n    df['IsPureBreed'] = (df['Breed1'] == 0) | (df['Breed2'] == 0) | (df['Breed1'] == df['Breed2'])\n    df['HasPhoto'] = df['PhotoAmt'] > 0\n    df['SentimentMultiplier'] = df['SentimentScore'] * df['SentimentMagnitude']\n    df['DescriptionLength'] = df['Description'].map(str).apply(len)\n    df['IsSinglePet'] = df['Quantity'] == 1\n    df['IsFree'] = df['Fee'] == 0\n    df['HasVideo'] = df['VideoAmt'] > 0\n    \n    # Transform features into categorical.\n    for c in categorical_features:\n        df[c] = df[c].astype('int')\n        \n    # Transform features into float.\n    for c in numerical_features:\n        df[c] = df[c].astype('float')\n        \n    # Transform features into bool.\n    for c in bool_features:\n        df[c] = df[c].astype('bool')\n        \n    #Filter out columns.\n    allFeatures = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', \\\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \\\n       'Sterilized', 'Health', 'Fee', 'SentimentScore', 'SentimentMagnitude', \\\n       'Name_Length', 'Age_Years', 'IsPureBreed', 'HasPhoto', 'SentimentMultiplier', \\\n       'PhotoAmt', 'DescriptionLength', 'Quantity', 'IsSinglePet', 'IsFree', 'VideoAmt', 'HasVideo']\n    \n    #Filter out columns\n    return df[allFeatures]","665a2aa8":"testDataWithSentiment = prepareDataset(testDataWithSentiment)\n\ntestDataWithSentiment.head(10)","2adfc83f":"lgb_test_pred = lgbModel.predict(testDataWithSentiment, num_iteration=lgbModel.best_iteration)","ef66d493":"# Get feature importance for Random Forest\nif 'AdoptionSpeed' in X_train_lgb.columns:\n    X_train_lgb = X_train_lgb.drop(['AdoptionSpeed'], axis=1)\n\nprint(\"Train columns: \" + str(X_train_lgb.columns))\nprint(randomForest.feature_importances_)\n\nrandomForestFeatureImportances = []\nfor i in range(len(randomForest.feature_importances_)):\n    randomForestFeatureImportances.append(tuple([X_train_lgb.columns[i], randomForest.feature_importances_[i]]))\n\nprint(\"Random Forest feature importances\")\nprint(sorted(randomForestFeatureImportances, key=lambda x: x[1], reverse=True))\n\n#xgb_model = models[0]\n#randomForest = models[1]\n#decisionTree = models[2]\n#naiveBayes = models[3]\n#lgbModel = models[4]","bb153e68":"# Get feature importance for Decision Trees\nif 'AdoptionSpeed' in X_train_lgb.columns:\n    X_train_lgb = X_train_lgb.drop(['AdoptionSpeed'], axis=1)\n\nprint(\"Train columns: \" + str(X_train_lgb.columns))\nprint(decisionTree.feature_importances_)\n\ndecisionTreeFeatureImportances = []\nfor i in range(len(randomForest.feature_importances_)):\n    decisionTreeFeatureImportances.append(tuple([X_train_lgb.columns[i], decisionTree.feature_importances_[i]]))\n\nprint(\"Decision Tree feature importances\")\nprint(sorted(decisionTreeFeatureImportances, key=lambda x: x[1], reverse=True))","d3d0453b":"# Get feature importance for XGB\nif 'AdoptionSpeed' in X_train_lgb.columns:\n    X_train_lgb = X_train_lgb.drop(['AdoptionSpeed'], axis=1)\n\nprint(\"Train columns: \" + str(X_train_lgb.columns))\nprint(xgb_model.feature_importances_)\n\nxgbModelFeatureImportances = []\nfor i in range(len(xgb_model.feature_importances_)):\n    xgbModelFeatureImportances.append(tuple([X_train_lgb.columns[i], xgb_model.feature_importances_[i]]))\n\nprint(\"XGB feature importances\")\nprint(sorted(xgbModelFeatureImportances, key=lambda x: x[1], reverse=True))","53efd138":"Adoption speed of 0 is very rare for both dogs and cats, but the other categories are close to each other.\nCats tend to get adopted earlier than dogs."}}