{"cell_type":{"59370fb7":"code","97dbc256":"code","dd81cfdf":"code","7593bc38":"code","82ddf760":"code","45071a21":"code","3a3bdb0a":"code","53cccb7e":"code","9f8eb62d":"code","c88c0f53":"code","c8aa0626":"code","8a8634c8":"code","b2fe2921":"code","6e3cb1f9":"code","cf2a351d":"code","56edad12":"code","bf25a18d":"code","42210f89":"code","89970122":"code","2ac55ba5":"code","6bb83c44":"code","ac2572a4":"code","2082d65e":"markdown"},"source":{"59370fb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","97dbc256":"train_data = '\/kaggle\/input\/training'\ntest_data = '\/kaggle\/input\/test'\nvalidation_data = '\/kaggle\/input\/validation'\nlabel_data = pd.read_csv('\/kaggle\/input\/labels-foldered.csv',header=None)\nlabel_data.rename(columns={0:'filename',1:'status'},inplace=True)\nlabel_data.index += 1\nprint(label_data.head())\nprint(label_data.tail())","dd81cfdf":"import cv2\nfrom random import shuffle\nfrom tqdm import tqdm\nfrom keras.models import Sequential,Model\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import *\n\nimg_width = 256\nimg_length = 256\n\ndef label(img):\n    index = int(img.split('.')[0])\n    if(label_data.loc[index,'status']=='yes'):\n        lab = np.array([1])\n    elif(label_data.loc[index,'status']=='no'):\n        lab = np.array([0])\n    return lab\n    \ndef train_data_with_label():\n    train_images = []\n    for i in tqdm(os.listdir(train_data)):\n        path = os.path.join(train_data,i)\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (img_width,img_length))\n        train_images.append([np.array(img), label(i)])\n    shuffle(train_images)\n    return train_images\n\ndef test_data_with_label():\n    test_images = []\n    for i in tqdm(os.listdir(test_data)):\n        path = os.path.join(test_data,i)\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (img_width,img_length))\n        test_images.append([np.array(img), label(i)])\n    shuffle(test_images)\n    return test_images\n\ndef validation_data_with_label():\n    validation_images = []\n    for i in tqdm(os.listdir(validation_data)):\n        path = os.path.join(validation_data,i)\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (img_width,img_length))\n        validation_images.append([np.array(img), label(i)])\n    shuffle(validation_images)\n    return validation_images","7593bc38":"training_images = train_data_with_label()\ntesting_images = test_data_with_label()\nvalidation_images = validation_data_with_label()","82ddf760":"from keras.utils import to_categorical\n\ntr_img_data = np.array([i[0] for i in training_images]).reshape(-1,img_width,img_length,1)\ntr_lbl_data = np.array([i[1] for i in training_images])\ntr_lbl_data = to_categorical(tr_lbl_data)\n\ntst_img_data = np.array([i[0] for i in testing_images]).reshape(-1,img_width,img_length,1)\ntst_lbl_data = np.array([i[1] for i in testing_images])\ntst_lbl_data = to_categorical(tst_lbl_data)\n\nval_img_data = np.array([i[0] for i in validation_images]).reshape(-1,img_width,img_length,1)\nval_lbl_data = np.array([i[1] for i in validation_images])\nval_lbl_data = to_categorical(val_lbl_data)","45071a21":"print(\"Dimensi training image : \", tr_img_data.shape)\nprint(\"Dimensi validation image : \", val_img_data.shape)\nprint(\"Dimensi testing image : \", tst_img_data.shape)","3a3bdb0a":"model = Sequential()\nmodel.add(InputLayer(input_shape=[img_width,img_length,1]))\n\nmodel.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=5,padding='same'))\n\nmodel.add(Conv2D(filters=50,kernel_size=5,strides=1,padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=5,padding='same'))\n\nmodel.add(Conv2D(filters=80,kernel_size=5,strides=1,padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=5,padding='same'))\n\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(2,activation='softmax'))\n\noptimizer = Adam()\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n\nearly_stopping_monitor = EarlyStopping(patience=20)\ncheckpoint = ModelCheckpoint('.mdl_wts.hdf5',monitor='val_accuracy',save_best_only=True, mode='auto')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1, shuffle=True, min_delta=1e-1, mode='min')","53cccb7e":"model.fit(tr_img_data, tr_lbl_data, epochs=100, batch_size=100, validation_data=(val_img_data, val_lbl_data), verbose=2,callbacks=[early_stopping_monitor,checkpoint,reduce_lr_loss])","9f8eb62d":"import matplotlib.pyplot as plt\nplt.plot(model.history.history['loss'], label='train')\nplt.plot(model.history.history['val_loss'], label='test')\nplt.legend()\nplt.show()","c88c0f53":"import matplotlib.pyplot as plt\nplt.plot(model.history.history['accuracy'], label='train')\nplt.plot(model.history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show()","c8aa0626":"test_loss, test_acc = model.evaluate(tst_img_data,tst_lbl_data,batch_size=128)\nval_loss, val_acc = model.evaluate(val_img_data,val_lbl_data,batch_size=128)\nprint(\"Test Accuracy : \",test_acc)\nprint(\"Validation Accuracy : \", val_acc)","8a8634c8":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","b2fe2921":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\ntrue = np.argmax(np.concatenate((tst_lbl_data,val_lbl_data)),axis=1)\nnn_predict = model.predict_classes(np.concatenate((tst_img_data,val_img_data)))\nconf_mat = confusion_matrix(true,nn_predict)\nax = sns.heatmap(conf_mat,annot=True,fmt='g',cmap='coolwarm')\nlabels = ['Yes','No']\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nax.set(xlabel='Kenyataan', ylabel='Diprediksi', title='Confusion Matrix pada Klasifikasi Gambar (Neural Network)')\nplt.show()","6e3cb1f9":"model.summary()","cf2a351d":"new_model = Model(inputs=model.input,outputs=model.get_layer('flatten_1').output)\n\nnew_model_train = new_model.predict(tr_img_data)\nprint(new_model_train.shape)\n\nnew_model_val = new_model.predict(val_img_data)\nprint(new_model_val.shape)\n\nnew_model_test = new_model.predict(tst_img_data)\nprint(new_model_test.shape)","56edad12":"from sklearn.svm import SVC\nsvm = SVC(kernel='sigmoid')\nsvm.fit(new_model_train,np.argmax(tr_lbl_data,axis=1))\nprint(\"SVM Training Score : \",svm.score(new_model_train,np.argmax(tr_lbl_data,axis=1)))\nprint(\"SVM Validation Score : \",svm.score(new_model_val,np.argmax(val_lbl_data,axis=1)))\nprint(\"SVM Test Score : \", svm.score(new_model_test,np.argmax(tst_lbl_data,axis=1)))\n\nsvm_predict = svm.predict(np.concatenate((new_model_test,new_model_val)))\nconf_mat = confusion_matrix(true,svm_predict)\nax = sns.heatmap(conf_mat,annot=True,fmt='g',cmap='coolwarm')\nlabels = ['Yes','No']\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nax.set(xlabel='Kenyataan', ylabel='Diprediksi', title='Confusion Matrix pada Klasifikasi Gambar (SVM)')\nplt.show()","bf25a18d":"import time\n\nimages_test_nn = np.concatenate((tst_img_data,val_img_data))\nstart = time.clock() \nnn_predict = model.predict_classes(images_test_nn)\nend = time.clock()\nprint(\"Waktu Prediksi NN per Gambar: {} \".format((end-start)\/len(images_test_nn))) \n\nimages_test_svm = np.concatenate((new_model_test,new_model_val))\nstart = time.clock() \nsvm.predict(images_test_svm)\nend = time.clock()\nprint(\"Waktu Prediksi SVM per Gambar: {} \".format((end-start)\/len(images_test_svm)))","42210f89":"import xgboost as xgb\nxb = xgb.XGBClassifier(silent=False, \n                      scale_pos_weight=1,\n                      learning_rate=0.01,  \n                      colsample_bytree = 0.4,\n                      subsample = 0.8, \n                      n_estimators=100, \n                      reg_alpha = 0.3,\n                      max_depth=4, \n                      gamma=10)\nxb.fit(new_model_train,np.argmax(tr_lbl_data,axis=1))\nprint(\"XGBoost Training Score : \",xb.score(new_model_train,np.argmax(tr_lbl_data,axis=1)))\nprint(\"XGBoost Validation Score : \",xb.score(new_model_val,np.argmax(val_lbl_data,axis=1)))\nprint(\"XGBoost Test Score : \", xb.score(new_model_test,np.argmax(tst_lbl_data,axis=1)))\nxgb_predict = xb.predict(np.concatenate((new_model_test,new_model_val)))\nconf_mat = confusion_matrix(true,xgb_predict)\nax = sns.heatmap(conf_mat,annot=True,fmt='g',cmap='coolwarm')\nlabels = ['Yes','No']\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nax.set(xlabel='Kenyataan', ylabel='Diprediksi', title='Confusion Matrix pada Klasifikasi Gambar (XGBoost)')\nplt.show()","89970122":"from IPython.display import display, Image\ndef predict_image_model_1(path):\n    test_images_test = []\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) #Read path, then change to Grayscale\n    img = cv2.resize(img, (img_width,img_length)) #Resize image\n    test_images_test.append([np.array(img)]) #Place it to array\n    tst_img_data = np.array([i[0] for i in test_images_test]).reshape(-1,img_width,img_length,1) #Reshape image dimension\n    value = model.predict(tst_img_data)[0][1] #Predict image with Model 1\n\n    if(value > 0.5):\n        label = \"Banjir\"\n    else:\n        label = \"Tidak Banjir\"\n\n    display(Image(filename=path)) #Show image\n    print(\"Confidence : \", value) #Print result\n    print(\"Condition :\",label)\n    \ndef predict_image_model_2(path):\n    test_images_test = []\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) #Read path, then change to Grayscale\n    img = cv2.resize(img, (img_width,img_length)) #Resize image\n    test_images_test.append([np.array(img)]) #Place it to array\n    tst_img_data = np.array([i[0] for i in test_images_test]).reshape(-1,img_width,img_length,1) #Reshape image dimension\n    value_2 = new_model.predict(tst_img_data) #Output of Flatten\n    value = svm.predict(value_2)[0] #Predict image with Model 2\n\n    if(value > 0.5):\n        label = \"Banjir\"\n    else:\n        label = \"Tidak Banjir\"\n\n    display(Image(filename=path)) #Show image\n    print(\"Confidence : \", value) #Print result\n    print(\"Condition :\",label)\n    \ndef predict_image_model_3(path):\n    test_images_test = []\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) #Read path, then change to Grayscale\n    img = cv2.resize(img, (img_width,img_length)) #Resize image\n    test_images_test.append([np.array(img)]) #Place it to array\n    tst_img_data = np.array([i[0] for i in test_images_test]).reshape(-1,img_width,img_length,1) #Reshape image dimension\n    value_2 = new_model.predict(tst_img_data) #Output of Flatten\n    value = xb.predict(value_2)[0] #Predict image with Model 3\n\n    if(value > 0.5):\n        label = \"Banjir\"\n    else:\n        label = \"Tidak Banjir\"\n\n    display(Image(filename=path)) #Show image\n    print(\"Confidence : \", value) #Print result\n    print(\"Condition :\",label)","2ac55ba5":"predict_image_model_1('\/kaggle\/input\/training\/1376.jpg')","6bb83c44":"predict_image_model_2('\/kaggle\/input\/test\/105.jpg')","ac2572a4":"predict_image_model_3('\/kaggle\/input\/validation\/260.jpg')","2082d65e":"## Testing  \nTesting models on images below here"}}