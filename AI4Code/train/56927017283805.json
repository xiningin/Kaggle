{"cell_type":{"bd18fabb":"code","4c406c5b":"code","54bb13a1":"code","234aa6b0":"code","48fef9b0":"code","4203dbf8":"code","ff4c16da":"code","61222423":"code","09ba6193":"markdown","6d482170":"markdown","1b9f27ed":"markdown","9655dd07":"markdown","6a599bf1":"markdown","385d38f6":"markdown"},"source":{"bd18fabb":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import imputation\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.metrics import fbeta_score, make_scorer, precision_score, recall_score\nfrom sklearn.model_selection import cross_val_score\n\nimport seaborn as sns\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer\nfrom sklearn.pipeline import make_pipeline\n\nimport xgboost as xgb","4c406c5b":"def load_and_clean_df(filename):\n    _df = pd.read_csv(filename, na_values='na')\n    _df = _df.set_index(\"ID\")\n    _df = _df.rename({'class':'target'}, axis=1).astype(np.number)\n    return _df\n\ndef normalize_hist(df, var_group):\n    _df = df.copy()\n    l_cols_int = [c for c in df.columns if c[:2] == var_group]\n    _df[l_cols_int] = _df[l_cols_int].div(_df[l_cols_int].sum(axis=1), axis=0)\n    return _df\n    \ndef normalize_histograms_in_df(df):\n    l_hist_var_groups = [c[:2] for c in df.columns if c[-1]==\"1\"]\n    output = df.copy()\n    for hist_var_group in l_hist_var_groups:\n        output = normalize_hist(output, hist_var_group)\n    return output\n\ndef split_x_y(df, target_col = 'target'):\n    return df.drop(target_col,axis=1), df[target_col]","54bb13a1":"df = load_and_clean_df(\"..\/input\/training_data_set.csv\")\ndf_test = load_and_clean_df(\"..\/input\/test_data_set.csv\")\n\ndf.head()","234aa6b0":"normalizer = FunctionTransformer(normalize_histograms_in_df, validate=False) \nimputer = imputation.Imputer() \nstandardizer = StandardScaler()\ndata_prep_pipeline = make_pipeline(normalizer, imputer, standardizer)\n\nX_train, X_val, y_train, y_val = train_test_split(*split_x_y(df), test_size=0.2, random_state=42)","48fef9b0":"%%time\npos_weight = (df.target==0).sum()\/df.target.sum()\n\nm2 = xgb.XGBClassifier(objective='binary:logistic',\n                       max_depth=3,\n                        learning_rate=0.1,\n                        base_score =0.95,\n                        gamma=0.3,\n                        reg_alpha=0.3,\n                        subsample=0.9,\n                        colsample_bytree=0.9,\n                        n_estimators=500,\n                        scale_pos_weight = pos_weight\n                        ,n_jobs=4\n                        ,gpu_id = 0\n                        ,max_bin = 16\n                        ,tree_method = 'gpu_hist'\n                      )\n\npipe2 = make_pipeline(normalizer, imputer, standardizer, m2)\npipe2.fit(X_train, y_train)","4203dbf8":"y_pred_val = pipe2.predict_proba(X_val)[:,1]\n\nlx = np.linspace(0.0001,.3,100)\nf_p = np.vectorize(lambda thr: precision_score(y_val, y_pred_val>thr))\nf_r = np.vectorize(lambda thr: recall_score(y_val, y_pred_val>thr))\nf_b = np.vectorize(lambda thr: fbeta_score(y_val, y_pred_val>thr, 7.07))\nsns.lineplot(lx,f_p(lx), label = \"Precision\")\nsns.lineplot(lx,f_r(lx), label = \"Recall\")\nsns.lineplot(lx,f_b(lx), label = r\"$f_\\beta$\")\nplt.xlabel('Decision threshold')\nplt.title(fr\"$max\\,f_\\beta={f_b(lx).max():3.3} \\,for\\, thr={lx[f_b(lx).argmax()]:3.3}$\")\nplt.legend()\nplt.show()","ff4c16da":"XGB_model_optimal_params = xgb.XGBClassifier(objective='binary:logistic',\n                       max_depth=3,\n                        learning_rate=0.1,\n                        base_score =0.95,\n                        gamma=0.3,\n                        reg_alpha=0.3,\n                        subsample=0.9,\n                        colsample_bytree=0.9,\n                        n_estimators=500,\n                        scale_pos_weight = pos_weight\n                        ,n_jobs=4\n                        ,gpu_id = 0\n                        ,max_bin = 16\n                        ,tree_method = 'gpu_hist')\npipe2 = make_pipeline(normalizer, imputer, standardizer, XGB_model_optimal_params)\npipe2.fit(*split_x_y(df))","61222423":"y_pred = pipe2.predict_proba(df_test)[:,1]>0.07\n\ndf_predictions = pd.DataFrame(y_pred.astype(int), index = df_test.index, columns = [\"Predicted\"])\ndf_predictions.to_csv('XGB_submission_balanced.csv')","09ba6193":"# export predictions","6d482170":"# Clean data\n> ## Normalize histogram variables\n\n> ## Replace missing values with the mean\n\n> ## Standardize","1b9f27ed":"When submited this prediction yielded a score of 0.94582 in the public leaderboard. ","9655dd07":"# XGB","6a599bf1":"### Fit","385d38f6":"# Loading data"}}