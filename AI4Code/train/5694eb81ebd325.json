{"cell_type":{"87b9bf89":"code","5e393105":"code","5f6334d3":"code","d7808c78":"code","7d2757a2":"code","71e4ef75":"code","5240c4cf":"code","ffa3bcb3":"code","4c2432b2":"code","a6bea91d":"markdown","2888b583":"markdown","9d1217e3":"markdown","93e520f7":"markdown","af429522":"markdown"},"source":{"87b9bf89":"# - Generic -\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, gc, warnings, time, pathlib\nwarnings.filterwarnings(\"ignore\")\n\n# - TensorFlow - \nimport tensorflow as tf\nimport matplotlib.pylab as plt\nfrom tensorflow.keras import layers\nfrom tensorflow import keras","5e393105":"print(\"TensorFlow Version Used: \",tf.__version__)","5f6334d3":"# - Load Dataset -\nds_url = 'https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz'\n\nimg_dir = tf.keras.utils.get_file(origin=ds_url, fname='flower_photos', untar=True)\nimg_dir = pathlib.Path(img_dir)\n\n# Image Count\nprint(\"\\n Total Images Downloaded: \", len(list(img_dir.glob('*\/*.jpg'))))","d7808c78":"# Parameter Definition\nbatch_size = 32\nimage_size = (300,300)\nepochs = 10","7d2757a2":"''' Training - 90%'''\n''' Validation - 10%'''\n\n# Training Dataset\nprint(\" --Training Dataset-- \")\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(img_dir,validation_split=0.1,\n                                                               subset=\"training\",seed=123, image_size=image_size, batch_size=batch_size)\n\n# Validation Dataset\nprint(\"\\n --Validation Dataset-- \")\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(img_dir, validation_split=0.1,\n                                                             subset=\"validation\",seed=123, image_size=image_size, batch_size=batch_size)\n\n\n# Training Class Number\nnum_class = len(train_ds.class_names)","71e4ef75":"# Dataset Performance Config\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","5240c4cf":"# Custom Function to Build Model\n\ndef build_model():\n    return tf.keras.Sequential([layers.experimental.preprocessing.Rescaling(1.\/255),\n                                layers.Conv2D(32, 3, activation='relu'),\n                                layers.MaxPooling2D(),\n                                layers.Conv2D(32, 3, activation='relu'),\n                                layers.MaxPooling2D(),\n                                layers.Conv2D(32, 3, activation='relu'),\n                                layers.MaxPooling2D(),\n                                layers.Flatten(),\n                                layers.Dense(128, activation='relu'),\n                                layers.Dense(num_class) ])\n\n\n# Create Model\nmodel = build_model()","ffa3bcb3":"# Define Optimizer List\noptimizers = [ 'Adadelta', 'Adagrad', 'Adam', 'Adamax', 'Nadam', 'RMSprop', 'SGD' ]\n\nopt_res = []\n\n# Compile & Train\nfor optimizer in optimizers:\n    model.compile(optimizer=optimizer, loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n    print(f\"Fitting the model with {optimizer}\")\n    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=-1)\n    gc.collect()  #Free Memory after each run\n    opt_res.append(history.history['accuracy'])\n","4c2432b2":"fully_nested = [list(zip(*[(ix+1,y) for ix,y in enumerate(x)])) for x in opt_res]\nnames = ['sublist%d'%(i+1) for i in range(len(fully_nested))]\n\nfig = plt.figure(figsize=(15,10))\n\nfor l in fully_nested:\n    plt.plot(*l)\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend(optimizers, fontsize=9, loc = 'upper right', bbox_to_anchor=(1.1, 1.01))\nplt.title(\"Optimizer Performance Comparison\", fontsize=25)\nplt.show()","a6bea91d":"# Build & Train Model","2888b583":"# Libraries & Data Load","9d1217e3":"# Visualization","93e520f7":"With all other things similar, in this notebook we're going to compare the performance of different **Optimizers** that are available in TensorFlow. Please check [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers) for more details about the Optimizers.\n\nFollowing are the details in brief:\n\n1. Optimizers =  Adadelta, Adagrad, Adam, Adamax, Nadam, RMSprop, SGD\n2. Epochs = 10\n3. Learning Rate = Default\n4. Dataset = [Flower Dataset](https:\/\/www.tensorflow.org\/tutorials\/load_data\/images) - From TensorFlow \n\nPlease do consider it to UPVOTE if this notebook has provided you with any insights about different optimizers :-).","af429522":"# Data Split & Performance Configuration"}}