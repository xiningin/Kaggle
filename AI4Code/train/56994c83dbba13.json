{"cell_type":{"5859c2f8":"code","ca7fb710":"code","7b95d6ef":"code","ba1f1f68":"code","07c91fb1":"code","601a9ad1":"code","146ff178":"code","bd842588":"code","91eab362":"code","14978d5a":"code","6de68dca":"code","fb288548":"code","0d6d8990":"code","491725e9":"code","4c299159":"code","eecdff1f":"code","1547509c":"code","06d0cbf1":"code","3137c55a":"markdown","6a9d5bbd":"markdown","e65d5a65":"markdown","f4008f3e":"markdown","9845dd08":"markdown","e553de53":"markdown","5030162d":"markdown","ff1c7365":"markdown","14bb7fd0":"markdown","9011b74f":"markdown","e666cd79":"markdown","464312a6":"markdown","c40c1907":"markdown"},"source":{"5859c2f8":"import numpy as np\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nimport os","ca7fb710":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","7b95d6ef":"original_fake_paths = []\n\nfor dirname, _, filenames in tqdm(os.walk('\/kaggle\/input\/1-million-fake-faces\/')):\n    for filename in filenames:\n        original_fake_paths.append([os.path.join(dirname, filename), filename])","ba1f1f68":"save_dir = '\/kaggle\/tmp\/fake\/'\n\nif not os.path.exists(save_dir):\n    os.makedirs(save_dir)","07c91fb1":"fake_paths = [save_dir + filename for _, filename in original_fake_paths]","601a9ad1":"for path, filename in tqdm(original_fake_paths):\n    img = cv2.imread(path)\n    img = cv2.resize(img, (224, 224))\n    cv2.imwrite(os.path.join(save_dir, filename), img)","146ff178":"train_fake_paths, test_fake_paths = train_test_split(fake_paths, test_size=20000, random_state=2019)\n\nfake_train_df = pd.DataFrame(train_fake_paths, columns=['filename'])\nfake_train_df['class'] = 'FAKE'\n\nfake_test_df = pd.DataFrame(test_fake_paths, columns=['filename'])\nfake_test_df['class'] = 'FAKE'","bd842588":"real_dir = '\/kaggle\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/'\neval_partition = pd.read_csv('\/kaggle\/input\/celeba-dataset\/list_eval_partition.csv')\n\neval_partition['filename'] = eval_partition.image_id.apply(lambda st: real_dir + st)\neval_partition['class'] = 'REAL'","91eab362":"real_train_df = eval_partition.query('partition in [0, 1]')[['filename', 'class']]\nreal_test_df = eval_partition.query('partition == 2')[['filename', 'class']]","14978d5a":"train_df = pd.concat([real_train_df, fake_train_df])\ntest_df = pd.concat([real_test_df, fake_test_df])","6de68dca":"datagen = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\n\ntrain_gen = datagen.flow_from_dataframe(\n    train_df,\n    target_size=(224, 224),\n    batch_size=64,\n    class_mode='binary',\n    subset='training'\n)\n\nval_gen = datagen.flow_from_dataframe(\n    train_df,\n    target_size=(224, 224),\n    batch_size=64,\n    class_mode='binary',\n    subset='validation'\n)","fb288548":"datagen = ImageDataGenerator(rescale=1.\/255).flow_from_dataframe(\n    test_df,\n    target_size=(224, 224),\n    batch_size=64,\n    class_mode='binary'\n)","0d6d8990":"densenet = DenseNet121(\n    weights='\/kaggle\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(224,224,3)\n)\n\nfor layer in densenet.layers:\n    layer.trainable = False","491725e9":"def build_model(densenet):\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    \n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    \n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.0005),\n        metrics=['accuracy']\n    )\n    \n    return model","4c299159":"model = build_model(densenet)\nmodel.summary()","eecdff1f":"checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n\ntrain_history_step1 = model.fit_generator(\n    train_gen,\n    validation_data=val_gen,\n    steps_per_epoch=len(train_gen),\n    validation_steps=len(val_gen),\n    callbacks=[checkpoint],\n    epochs=7\n)","1547509c":"model.load_weights('model.h5')\nfor layer in model.layers:\n    layer.trainable = True\n\ntrain_history_step2 = model.fit_generator(\n    train_gen,\n    validation_data=val_gen,\n    steps_per_epoch=len(train_gen),\n    validation_steps=len(val_gen),\n    callbacks=[checkpoint],\n    epochs=3\n)","06d0cbf1":"pd.DataFrame(train_history_step1.history).to_csv('history1.csv')\npd.DataFrame(train_history_step2.history).to_csv('history2.csv')","3137c55a":"## Create fake filepaths dataframe","6a9d5bbd":"## Training Phase 1 - Only train top layers","e65d5a65":"## Eval","f4008f3e":"# Preprocessing","9845dd08":"## Load and freeze DenseNet","e553de53":"# About this kernel\n\nSince I noticed a lot of competitors is struggling to break the baseline submission (set everything to 0.51), I decided to create this kernel with the purpose of creating a pretrained model that you can easily finetune.\n\nIt uses a simple DenseNet-121, and is trained on around 200k real faces, and 200k GAN-generated faces. The fake faces are kindly [provided by Bojan in this discussion](https:\/\/www.kaggle.com\/c\/deepfake-detection-challenge\/discussion\/121173), and were downsampled to 224 x 224, whereas the real faces come from the CelebA dataset, provided by Jessica [here](https:\/\/www.kaggle.com\/jessicali9530\/celeba-dataset), this time upsampled to 224 x 224.\n\nObviously, the danger of using this model is that both datasets are very \"different\", so it is very likely the model is not learning facial features as much as underlying pixels distributions; so please use this with caution!","5030162d":"## Combine both real and fake for dataframe","ff1c7365":"## Build Model","14bb7fd0":"# Generator","9011b74f":"# Modelling","e666cd79":"## Create real file paths dataframe","464312a6":"## First downsize all the images","c40c1907":"## Training Phase 2 - Unfreeze and train all"}}