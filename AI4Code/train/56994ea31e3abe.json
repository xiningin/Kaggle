{"cell_type":{"7f0f45a6":"code","65f4c3da":"code","bedd7aa3":"code","5d96e616":"code","894f3bcb":"code","573c2cc0":"code","f86391ae":"code","e8e16157":"code","977fab4d":"code","60411794":"code","c34225d1":"code","2b75c836":"code","469fd7bc":"code","be0166fb":"code","973dc8d6":"code","fddd4d37":"code","e3d8134c":"code","26e5c7a6":"code","6f9e9825":"code","7ed13d55":"code","882a9180":"code","e35b356d":"code","afa6e584":"code","c0d7f61f":"code","6a1d0858":"code","0115589e":"code","4a28523e":"code","65a60f81":"code","04795bfc":"code","bf8a46d2":"code","76f08e6d":"code","e9ba67d9":"code","e41e0c76":"code","263bc1a4":"code","43d3a116":"code","48d72fcf":"code","7d0d2b70":"code","ea385ee0":"code","e8d039da":"code","2492ac1f":"code","0822d2e0":"code","d16f05f0":"markdown","44fbf7ca":"markdown","6ac0fcab":"markdown","c75b0f0e":"markdown","368eabe0":"markdown","1fdaf8d0":"markdown","6b857656":"markdown","3c8abe6f":"markdown","6602bc84":"markdown","56966106":"markdown","cb01585c":"markdown","5e0333ea":"markdown","350fc99a":"markdown","b70f131f":"markdown","a02a0d27":"markdown","089348e4":"markdown","bff0cc64":"markdown","d1f104b1":"markdown","6cabdf27":"markdown","5bef949b":"markdown","a8d29dfc":"markdown","cfa9e99e":"markdown"},"source":{"7f0f45a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport sklearn\nimport random\nimport warnings\nfrom sklearn import svm\nimport scipy\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn\nimport matplotlib\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65f4c3da":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv',index_col=\"Id\")","bedd7aa3":"df_train.head()","5d96e616":"df_train.describe(include=\"all\")","894f3bcb":"df_train.info(verbose=True)","573c2cc0":"print(df_train.isna().sum().sort_values(ascending=False))","f86391ae":"df_train[\"Fence\"] = df_train[\"Fence\"].replace(np.nan,\"NA\")\ndf_train[\"PoolQC\"] = df_train[\"PoolQC\"].replace(np.nan,\"NA\")\ndf_train[\"Alley\"] = df_train[\"Alley\"].replace(np.nan,\"NA\")\ndf_train[\"MiscFeature\"] = df_train[\"MiscFeature\"].replace(np.nan,\"NA\")","e8e16157":"df_train.loc[df_train[\"FireplaceQu\"].isna()].loc[:,\"Fireplaces\":].head(5)","977fab4d":"df_train[\"FireplaceQu\"] = df_train[\"FireplaceQu\"].replace(np.nan,\"NA\")","60411794":"df_train.loc[df_train[\"LotFrontage\"].isna()].loc[:,\"LotFrontage\":].head(5)","c34225d1":"df_train[\"LotFrontage\"] = df_train[\"LotFrontage\"].replace(np.nan,0)","2b75c836":"df_train.loc[df_train[\"GarageType\"].isna()].loc[:,\"GarageType\":].head(5)","469fd7bc":"df_train[\"GarageType\"] = df_train[\"GarageType\"].replace(np.nan,\"NA\")\ndf_train[\"GarageCond\"] = df_train[\"GarageCond\"].replace(np.nan,\"NA\")\ndf_train[\"GarageYrBlt\"] = df_train[\"GarageYrBlt\"].replace(np.nan,0)\ndf_train[\"GarageFinish\"] = df_train[\"GarageFinish\"].replace(np.nan,\"NA\")\ndf_train[\"GarageQual\"] = df_train[\"GarageQual\"].replace(np.nan,\"NA\")\nprint(df_train.isna().sum().sort_values(ascending=False))","be0166fb":"df_train.loc[df_train[\"BsmtQual\"].isnull()].loc[:200,\"BsmtQual\":]","973dc8d6":"df_train[\"BsmtQual\"] = df_train[\"BsmtQual\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtCond\"] = df_train[\"BsmtCond\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtExposure\"] = df_train[\"BsmtExposure\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtFinType1\"] = df_train[\"BsmtFinType1\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtFinSF1\"] = df_train[\"BsmtFinSF1\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtFinType2\"] = df_train[\"BsmtFinType2\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtFinSF2\"] = df_train[\"BsmtFinSF2\"].replace(np.nan,\"NA\")\ndf_train[\"BsmtUnfSF\"] = df_train[\"BsmtUnfSF\"].replace(np.nan,\"NA\")\nprint(df_train.isna().sum().sort_values(ascending=False))","fddd4d37":"df_train.loc[df_train[\"MasVnrType\"].isnull()].loc[:,\"MasVnrType\":].head(5)","e3d8134c":"df_train[\"MasVnrType\"] = df_train[\"MasVnrType\"].replace(np.nan,\"None\")\ndf_train[\"MasVnrArea\"] = df_train[\"MasVnrArea\"].replace(np.nan,0)\ndf_train.drop(df_train.loc[df_train[\"Electrical\"].isna()].index,axis=0,inplace=True)\nprint(df_train.isna().sum().sort_values(ascending=False))","26e5c7a6":"seaborn.set_style(\"whitegrid\")\n\nfig0, axes0 = matplotlib.pyplot.subplots(1, figsize = (15,6))\nseaborn.kdeplot(data=df_train,x=\"SalePrice\",ax=axes0)\n(u, std) = scipy.stats.norm.fit(df_train[\"SalePrice\"])\nmatplotlib.pyplot.legend(['Normal dist. (Av: {0:0.2f} and Std: {1:0.2f} )'.format(u, std)],loc='upper right')\n\n\nfig, axes = matplotlib.pyplot.subplots(2,3, figsize = (20,10))\n\nplot1 = seaborn.histplot(data = df_train, x = \"LotArea\", stat=\"density\",bins=200, ax=axes[0,0])\nplot1.set_xticklabels([\"0\",\"10000\",\"11000\",\"20000\",\"30000\",\"40000\",\"50000\"], rotation=45, horizontalalignment='right')\n\nseaborn.kdeplot(data = df_train, x = \"LotArea\", color=\"#FF9F00\",ax=axes[0,0])\n\nplot2 = seaborn.histplot(data = df_train, x = \"MSZoning\", stat=\"probability\",bins=200, ax=axes[0,1])\n\n\nplot3 = seaborn.histplot(data = df_train, x = \"LotConfig\", stat=\"probability\",bins=200, ax=axes[0,2])\n\nplot4 = seaborn.histplot(data = df_train, x = \"Neighborhood\", stat=\"probability\", ax=axes[1,0])\nplot4.set_xticklabels(df_train[\"Neighborhood\"].unique(), rotation=60, horizontalalignment='right')\n\n\nplot5 = seaborn.histplot (data = df_train, x=\"MSSubClass\",stat=\"probability\",ax=axes[1,1])\nplot5.set_xticklabels([\"20\",\"30\",\"40\",\"45\",\"50\",\"60\",\"70\",\"75\",\"80\",\"85\",\"90\",\"120\",\"150\",\"160\",\"180\",\"190\"], rotation=45, horizontalalignment='right')\n\n\nplot6 = seaborn.histplot (data = df_train, x=\"OverallQual\",stat=\"probability\",ax=axes[1,2])\nseaborn.kdeplot(data = df_train, x = \"OverallQual\", color=\"#FF9F00\",bw_adjust=1.7, ax=axes[1,2])","6f9e9825":"grouped = df_train.groupby(['Neighborhood'])\ndf_aux = pd.DataFrame(grouped[\"SalePrice\"].mean().sort_values(ascending=False)).reset_index()\n\nfig2, axes2 = matplotlib.pyplot.subplots(2,3, figsize = (20,10))\n\nmatplotlib.pyplot.subplots_adjust(left=0.1, bottom=0.1,right=0.9,top=0.9,wspace=0.4,hspace=0.4)\n\n\nplot1 = seaborn.scatterplot(data = df_train, x = \"LotArea\",y=\"SalePrice\",ax=axes2[0,0])\nplot1.set_title(\"SalePrice by LotArea\")\n\nplot2 = seaborn.scatterplot(data = df_train, x = \"MSZoning\",y=\"SalePrice\",ax=axes2[0,1])\nplot2.set_title(\"SalePrice by MSZoning\")\n\nplot3 = seaborn.barplot(data=df_aux, x = \"Neighborhood\",y=\"SalePrice\",color = \"#5998FF\",order=df_aux[\"Neighborhood\"].unique(),ax=axes2[0,2])\nplot3.set_xticklabels(df_aux[\"Neighborhood\"].unique(), rotation=90, horizontalalignment='right')\nplot3.set_title(\"Average SalePrice by Neighborhood\")\nplot3.set_ylabel(\"Sales Average\")\nseaborn.lineplot(data=df_aux, x = \"Neighborhood\",y=\"SalePrice\",color = \"#FF9F00\",ax=axes2[0,2])\n\ndf_aux = pd.DataFrame(grouped[\"OverallQual\"].mean().sort_values(ascending=False)).reset_index()\nplot4 = seaborn.barplot(data=df_aux, x = \"Neighborhood\",y=\"OverallQual\",color = \"#5998FF\",order=df_aux[\"Neighborhood\"].unique(),ax=axes2[1,0])\nplot4.set_xticklabels(df_aux[\"Neighborhood\"].unique(), rotation=90, horizontalalignment='right')\nplot4.set_title(\"Average Material Quality by Neighborhood\")\nseaborn.lineplot(data=df_aux, x = \"Neighborhood\",y=\"OverallQual\",color = \"#FF9F00\",ax=axes2[1,0])\n\ndf_aux = pd.DataFrame(grouped[\"SalePrice\"].count().sort_values(ascending=False)).reset_index()\n\nplot5 = seaborn.barplot(data=df_aux, x = \"Neighborhood\",y = \"SalePrice\",color = \"#5998FF\",order=df_aux[\"Neighborhood\"].unique(),ax=axes2[1,1])\nplot5.set_xticklabels(df_aux[\"Neighborhood\"].unique(), rotation=90, horizontalalignment='right')\nplot5.set_title(\"Number of Sales by Neighborhood\")\nplot5.set_ylabel(\"Sales Count\")\nseaborn.lineplot(data=df_aux, x = \"Neighborhood\",y=\"SalePrice\",color = \"#FF9F00\",ax=axes2[1,1])\n\ndf_aux = pd.DataFrame(grouped[\"SalePrice\"].max().sort_values(ascending=False)).reset_index()\nplot6 = seaborn.barplot(data=df_aux, x = \"Neighborhood\",y=\"SalePrice\",color = \"#5998FF\",order=df_aux[\"Neighborhood\"].unique(),ax=axes2[1,2])\nplot6.set_xticklabels(df_aux[\"Neighborhood\"].unique(), rotation=90, horizontalalignment='right')\nplot6.set_title(\"Max SalePrice by Neighborhood\")\nplot5.set_ylabel(\"Max Sale Price\")\nseaborn.lineplot(data=df_aux, x = \"Neighborhood\",y=\"SalePrice\",color = \"#FF9F00\",ax=axes2[1,2])\n\n","7ed13d55":"fig, axes = matplotlib.pyplot.subplots(1,figsize=(20,4))\ngrouped = df_train.groupby(\"YearBuilt\")\ndf_aux = pd.DataFrame(grouped[\"SalePrice\"].mean().sort_values(ascending=True)).reset_index()\n\ndf_aux.sort_values(by=['YearBuilt'], inplace=True)\nplot1 = seaborn.barplot(data=df_aux, x = \"YearBuilt\", y = \"SalePrice\",ax=axes)\nplot1.set_xticklabels(df_aux[\"YearBuilt\"].unique(), rotation=90, horizontalalignment='center')\nplot1.set_title(\"Average Sales by Lot Year2\")\nplot1.set_ylabel(\"Average Sales\")\n\n#plot2 = seaborn.lineplot(data=df_aux, x = \"YearBuilt\", y = \"SalePrice\",ax=axes[1])\n\n\nfrom scipy.interpolate import make_interp_spline,BSpline\n\nmatplotlib.pyplot.figure(figsize=(20,4))\n\nx_new = np.linspace(1872, 2010, 8)\na_BSpline = make_interp_spline(df_aux[\"YearBuilt\"], df_aux[\"SalePrice\"])\ny_new = a_BSpline(x_new)\n\nmatplotlib.pyplot.plot(x_new, y_new)\n\nmatplotlib.pyplot.show()\n\n","882a9180":"columns_nominal = [\"MSZoning\",\"Street\",\"LotConfig\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"RoofStyle\",\"RoofMatl\",\"Exterior1st\",\n                   \"Exterior2nd\",\"MasVnrType\",\"Foundation\",\"Heating\",\"CentralAir\",\"Electrical\",\"GarageType\",\"MiscFeature\",\"Alley\",\"SaleType\",\n                   \"SaleCondition\",\"MSSubClass\"] \ncolumns_ordinal = [\"LotShape\",\"LandContour\",\"Utilities\",\"LandSlope\",\"HouseStyle\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\n                   \"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"HeatingQC\",\"KitchenQual\",\"Functional\",\"FireplaceQu\",\n                   \"GarageFinish\",\"GarageQual\",\"GarageCond\",\"PavedDrive\",\"PoolQC\",\"Fence\"]\ncat_columns = list()\nnum_columns = list()\n\nfor column in df_train.columns:\n    if(df_train[column].dtype != \"object\"):\n        num_columns.append(column)\n    else:\n        cat_columns.append(column)\n\nnum_columns.remove(\"Id\")\nnum_columns.remove(\"MSSubClass\")\ncat_columns.append(\"MSSubClass\")\n\n\nif(len(columns_nominal)+len(columns_ordinal)==len(cat_columns)):\n    print(\"OK\")\n\nlb_enc = LabelEncoder()\n\ndf_encoded = pd.DataFrame()\ndf_encoded[columns_ordinal]=df_train[columns_ordinal].apply(lb_enc.fit_transform)\ndf_encoded[columns_nominal]=df_train[columns_nominal].apply(lb_enc.fit_transform)\ndf_encoded[num_columns]=df_train[num_columns]\n\n\ndf_encoded.head(10)","e35b356d":"corr_data = df_encoded.corr()\nprint(corr_data[\"SalePrice\"].sort_values(ascending=False)[1:8])\nprint(corr_data[\"SalePrice\"].sort_values(ascending=True)[:5])\ncorr_data.style.background_gradient(cmap='coolwarm', axis=None).set_precision(6)","afa6e584":"X_columns=[\"LotArea\",\"YearBuilt\",\"Neighborhood\",\"OverallQual\",\"GrLivArea\",\"GarageCars\",\"GarageArea\",\"TotalBsmtSF\",\"1stFlrSF\",\"ExterQual\",\"BsmtQual\",\"KitchenQual\"]\nX = df_train[X_columns]\nY_columns=[\"SalePrice\"]\nY=df_train[Y_columns]\nX.tail()","c0d7f61f":"X.describe(include=\"all\")","6a1d0858":"X = pd.concat([X, pd.get_dummies(X[\"ExterQual\"],prefix=\"ExterQual\")], axis=1, join='inner')\nX.drop(\"ExterQual\",axis=1,inplace=True)\n\nX=pd.concat([X, pd.get_dummies(X[\"BsmtQual\"],prefix=\"BsmtQual\")], axis=1, join='inner')\nX.drop(\"BsmtQual\",axis=1,inplace=True)\n\nX=pd.concat([X, pd.get_dummies(X[\"KitchenQual\"],prefix=\"KitchenQual\")], axis=1, join='inner')\nX.drop(\"KitchenQual\",axis=1,inplace=True)\n\nX=pd.concat([X, pd.get_dummies(X[\"Neighborhood\"],prefix=\"Neighborhood\")], axis=1, join='inner')\nX.drop(\"Neighborhood\",axis=1,inplace=True)\n\nprint(X.isna().sum())\nX.tail()\n","0115589e":"fig, ax = matplotlib.pyplot.subplots(1, figsize= (15,5))\nscipy.stats.probplot(Y[\"SalePrice\"],plot=ax)\nmatplotlib.pyplot.show()","4a28523e":"Y[\"SalePrice\"] = np.log10(Y[\"SalePrice\"])\nfig, ax = matplotlib.pyplot.subplots(1, figsize= (15,5))\nscipy.stats.probplot(Y[\"SalePrice\"],plot=ax)\nmatplotlib.pyplot.show()","65a60f81":"k_cv=sklearn.model_selection.RepeatedKFold(n_splits=20,n_repeats=5)\nX_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2)\nmin_score = 100\nfinal_alpha=0\nfor i in range(1,10):\n    alpha = random.uniform(0,10)\n    model=sklearn.linear_model.Ridge(alpha=alpha)\n    scores_cv=-sklearn.model_selection.cross_val_score(estimator=model, X = X, y=Y, cv=k_cv, scoring=\"neg_mean_squared_error\")\n    if(min_score > scores_cv.mean()):\n        min_score=scores_cv.mean()\n        final_alpha=alpha\n        print(\"{0} {1} {2} {3}\".format(i,scores_cv.mean(),scores_cv.std(),alpha))\n        \nmodel=sklearn.linear_model.Ridge(alpha=final_alpha)","04795bfc":"X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2)\nmodel2=sklearn.linear_model.Lasso()\nalpha = scipy.stats.uniform(1,50)\ngrid = {\"alpha\": alpha,}\nclf = sklearn.model_selection.RandomizedSearchCV(model2, param_distributions=grid, scoring = sklearn.metrics.mean_squared_error)\nclf.fit(X_train,Y_train)\nalpha = clf.best_params_.get(\"alpha\", 20)\nprint(alpha)\nmodel2=sklearn.linear_model.Lasso(alpha=alpha)","bf8a46d2":"X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2)\nmodel3=svm.SVR(kernel=\"rbf\")\nC = scipy.stats.uniform(1,20)\ngamma = [int(x) for x in np.linspace(start = 0.15, stop = 1, num = 10)]\ngrid = {\"C\": C,}\nclf = sklearn.model_selection.RandomizedSearchCV(model3, param_distributions=grid, scoring = sklearn.metrics.mean_squared_error)\n\nclf.fit(X_train,Y_train)\nC = clf.best_params_.get(\"C\", 20)\nprint(C)\nmodel3 = svm.SVR(kernel=\"rbf\",C=C)","76f08e6d":"model4=sklearn.linear_model.BayesianRidge()","e9ba67d9":"model.fit(X_train,Y_train)\nX_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2)\nmodel2.fit(X_train,Y_train)\nX_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2)\nmodel3.fit(X_train,Y_train)\nX_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2)\nmodel4.fit(X_train,Y_train)\n\nprint(sklearn.metrics.mean_squared_error(Y_test,model.predict(X_test)))\nprint(sklearn.metrics.mean_squared_error(Y_test,model2.predict(X_test)))\nprint(sklearn.metrics.mean_squared_error(Y_test,model3.predict(X_test)))\nprint(sklearn.metrics.mean_squared_error(Y_test,model4.predict(X_test)))\n\n\nprint(\"\\nMean Absolute Errors\\n\")\nprint(sklearn.metrics.mean_absolute_error(10**Y_test,10**model.predict(X_test)))\nprint(sklearn.metrics.mean_absolute_error(10**Y_test,10**model2.predict(X_test)))\nprint(sklearn.metrics.mean_absolute_error(10**Y_test,10**model3.predict(X_test)))\nprint(sklearn.metrics.mean_absolute_error(10**Y_test,10**model4.predict(X_test)))","e41e0c76":"from sklearn.ensemble import StackingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n\nestimators = [(\"ridge\",model),(\"lasso\",model2),(\"svmr\",model3),(\"bayesian\",model4)]\nfinal_estimator = RandomForestRegressor(n_estimators=50)\nstack_model = StackingRegressor(estimators=estimators,final_estimator=final_estimator)\nstack_model.fit(X_train,Y_train)\nprint(sklearn.metrics.mean_squared_error(Y_test,stack_model.predict(X_test)))\nprint(\"\\nMean Absolute Error\\n\")\nprint(sklearn.metrics.mean_absolute_error(10**Y_test,10**stack_model.predict(X_test)))","263bc1a4":"X_final = df_test[X_columns]\nprint(X_final.isna().sum().sort_values(ascending=False))","43d3a116":"X_final[\"BsmtQual\"]=X_final[\"BsmtQual\"].replace(np.nan,\"NA\")\nX_final[\"GarageCars\"]=X_final[\"GarageCars\"].replace(np.nan,0)\nX_final[\"GarageArea\"]=X_final[\"GarageArea\"].replace(np.nan,0)\nX_final[\"TotalBsmtSF\"]=X_final[\"TotalBsmtSF\"].replace(np.nan,0)\n","48d72fcf":"print(X_final.isna().sum().sort_values(ascending=False))","7d0d2b70":"X_final.loc[X_final[\"KitchenQual\"].isna()]","ea385ee0":"X_final[\"KitchenQual\"]=X_final[\"KitchenQual\"].replace(np.nan,X_final[\"KitchenQual\"].mode()[0])\nprint(X_final.isna().sum().sort_values(ascending=False))","e8d039da":"X_final = pd.concat([X_final, pd.get_dummies(X_final[\"ExterQual\"],prefix=\"ExterQual\")], axis=1, join='inner')\nX_final.drop(\"ExterQual\",axis=1,inplace=True)\n\nX_final=pd.concat([X_final, pd.get_dummies(X_final[\"BsmtQual\"],prefix=\"BsmtQual\")], axis=1, join='inner')\nX_final.drop(\"BsmtQual\",axis=1,inplace=True)\n\nX_final=pd.concat([X_final, pd.get_dummies(X_final[\"KitchenQual\"],prefix=\"KitchenQual\")], axis=1, join='inner')\nX_final.drop(\"KitchenQual\",axis=1,inplace=True)\n\nX_final=pd.concat([X_final, pd.get_dummies(X_final[\"Neighborhood\"],prefix=\"Neighborhood\")], axis=1, join='inner')\nX_final.drop(\"Neighborhood\",axis=1,inplace=True)","2492ac1f":"Y_final = stack_model.predict(X_final)\nY_final = pd.DataFrame((10**(Y_final)),index=X_final.index)\nY_final.columns = [\"SalePrice\"]\nY_final.head(10)","0822d2e0":"Y_final.to_csv(\"submission.csv\")","d16f05f0":"As we can see, this Dataset is not very uniform. For example, there are mostly Sales with LotArea bellow the value of 11000, almost all the data comes from Low Density Residential Areas, all the loots are basically Inside Lots, etc.\nDue to this, we can imagine that our model will have more errors in predicting some types of data.\n\nThe Neighborhood is actualy kinda sparse and the OverallQual looks similar to a Guassian Distribution which is good.","44fbf7ca":"From the data we can see that Northridge, Northridge Heights and Stone Brook are cleary rich Neighborhoods. They have higher value lots with a overall material quality higher than 8.\nMeadow Village,Briardale, etc, have lower price lots maybe due to lower material quality aswell.\nOther Neighborhoods like Veenker even tho they have nice material quality and kinda high prices, its market has little activity.\nAlthought Neighborhoods like Northwest Ames are not that expensive in comparison to others, they have a very active business.","6ac0fcab":"As with garage, all basement proprieties are NaN when TotalBsmtSF is zero","c75b0f0e":"As we saw, some features importante to determine the Sale Price of a Lot are:\n* YearBuilt\n* Neighborhood\n* Garage Area\n* GrLiveArea","368eabe0":"In this example we will make a Stacked Model in order to optimized the model results when presented different test data. This Stacked Model wiil be made with Ridge Regression Model, Lasso Regression Model, Support Vector Machine for Regression Model and Bayesian Regression Model. In here we will also apply Hyperparameter Tunning for Regularization Paramenters","1fdaf8d0":"In order to correctly train our model, our data must be normalized. Tha can be accomplished with Log of base 10","6b857656":"Like we said before, we will now apply a different Encoder for Categorical Nominal Features. This because a simple Encoder might Encode \"A\"-> 1 and \"B\"-> 2, and our model might see this data as 2 > 1 when that is not true nor it makes sense since 1 and 2 are not numerical values, but are in fact numeric counterparts of categorical data","3c8abe6f":"We can confirm the obvious -> newer Lots costs more money.\nAlmost all the sales made were  lots build to single-families.\n","6602bc84":"# Dimensionality Reduction","56966106":"# Enconding Categorical Features","cb01585c":"A lot of samples have NaN value.\nBut most NaN values can simplify be substitue by \"NA\", because there is no Fence, for example.\nOther times NaN values are present when there are values from other features. Fro example, the feature FireplaceQu is NaN if there isn't a Fireplace to begging with (Fireplaces == 0)\nReading the Dataset's intructions in some features Nan should be replaced by \"NA\" and in others by 0, in these cases.","5e0333ea":"Now we will see the Linear Correlation between each feature and the SalePrice","350fc99a":"It's important to distinguish nominal categorical data from ordinal categorical data as they should be enconded in different ways. For now both on them are enconded by a simple Label Encoder. But later, nominal data with be encoded in a way the its numeric equivalent doesn't imply a logical idea of one number being greater then the other, since those are just a numeric way to represent a categorical feature.","b70f131f":"# Data Cleaning","a02a0d27":"When there is no Masonry Veneer, contrary to other cases, MasVnrArea is NaN. We can replace that with its NaN equivalent aswell.Reading the Dataset's documentation, MasVnrType already has a value equivalent to zero (None)","089348e4":"LotFrontage is Nan when there is no street connected to the Lot","bff0cc64":"# Dataset's First Informations","d1f104b1":"# Random-Distributions Problem","6cabdf27":"# Model Creation","5bef949b":"Garage Proprieties are Nan when GarageArea is zero","a8d29dfc":"# Data Cleaning of Test Dataset","cfa9e99e":" # Neighborhood Analysis"}}