{"cell_type":{"92b4d90e":"code","38058cf2":"code","7ddb27c9":"code","0470359a":"code","7bf39163":"code","7568aa97":"code","f6830fe4":"code","4075ce73":"code","98a3c1bc":"code","e5dfa9fa":"code","66fe3095":"code","6e282e6e":"code","c98ccf73":"code","30cb5403":"markdown","ef659e73":"markdown","f339dd00":"markdown"},"source":{"92b4d90e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","38058cf2":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split                       # used to split dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator        # used to feed jpg images into model\nfrom tensorflow.keras.applications import Xception                         # load pretrained model\nfrom tensorflow.keras.layers import Dense, Flatten                         # add a normal layer at the end\nfrom matplotlib import pyplot as plt                                       # for data visualization\nfrom skimage.transform import rotate, AffineTransform, warp                # for data augmentation\nfrom skimage.transform import resize                                       # resize image\nfrom skimage import io                                                     # for saving images","7ddb27c9":"train = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntrain","0470359a":"train_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'","7bf39163":"#make a dataframe that has image location\nimages_df = pd.DataFrame()\nimages_df['image_address'] = train_dir + train['image_name'] + '.jpg'\nimages_df['target'] = train['target']\nimages_df","7568aa97":"print('Number of malignant cases = ', images_df['target'].sum())\nprint('Number of benign cases    = ', images_df['target'].count() - images_df['target'].sum())\nprint('Ratio of malignant cases   = ', images_df['target'].sum()\/images_df['target'].count())","f6830fe4":"# let's use only ~1200 benign images\n\n#lets get a mask with all the benign cases as true\nbenign_cases_truth = (images_df['target'] == 0).iloc[:1200]\nprint('we use only', benign_cases_truth.sum(), 'benign cases')\n\n#apply the mask to get ~1200 benign cases\nbenign_cases = (images_df[:].iloc[:1200])[:][benign_cases_truth]\n\n# use all the malignant cases:\nmalignant_cases = images_df[:][images_df['target'] == 1]\nprint('we use', len(malignant_cases.index), 'malignant cases')\n\nimages_df = benign_cases.copy()\nimages_df = images_df.append(malignant_cases)\n# don't worry about the order, train_test_split shuffles by default\nimages_df","4075ce73":"# split the data into training and dev set so we can validate our model\nX_train, X_dev, y_train, y_dev = train_test_split(images_df,images_df['target'], test_size=0.2, random_state=1234)","98a3c1bc":"input_shape = (299, 299)\ninput_shape_with_channels = (299, 299, 3)","e5dfa9fa":"os.makedirs('.\/train\/zero')\nos.makedirs('.\/train\/one')\nos.makedirs('.\/test\/zero')\nos.makedirs('.\/test\/one')","66fe3095":"i = 0","6e282e6e":"def augment_and_save(path, label, train_or_test):\n    \n    if label == 0:\n        label = 'zero'\n    elif label == 1:\n        label = 'one'\n    image_name = path[-16:-4]\n    save_location = train_or_test+'\/'+label+'\/'+image_name\n    \n    #read the image\n    image = io.imread(path)\n    #resize image\n    image_resized = resize(image, input_shape)\n    #make rotated image\n    rotated = rotate(image_resized, angle=45, mode = 'wrap')\n    #flipped\n    flipLR = np.fliplr(image_resized)\n    flipUD = np.flipud(image_resized)\n    \n    #save image\n    io.imsave(save_location+'_resized.jpg', image_resized)\n    io.imsave(save_location+'_rotated.jpg', rotated)\n    io.imsave(save_location+'_flipLR.jpg',  flipLR)    \n    io.imsave(save_location+'_flipUD.jpg',  flipUD)\n    \n    global i\n    print(i, end = ', ')\n    i = i+1","c98ccf73":"# to make training data\nX_train.apply(lambda row : augment_and_save(row['image_address'], \n                                  row['target'], 'train'), axis = 1)\n\n# similarly do the same for dev data\n# Note this must not be done for Test data","30cb5403":"# Handling the Images","ef659e73":"## Using this data\n\nif you run this above code you will get data in folders which you can then access following this this tutorial on [tf.data](https:\/\/www.tensorflow.org\/tutorials\/load_data\/images) using keras preprocessing or tf.Data!","f339dd00":"### So only 1.7% of data is true, it means by just outputting all false, our model can reach 98.3% accuracy by just calssifying all as benign!\n\nWe don't want this imbalance\n\nSo lets use only a part of the benign data!"}}