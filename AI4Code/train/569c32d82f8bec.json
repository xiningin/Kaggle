{"cell_type":{"4040aca3":"code","fc1ac685":"code","da4241c1":"code","22ac8e74":"code","a8a9a1db":"code","d4ee7514":"code","48399a72":"code","0c3d864e":"code","91ca2a64":"code","84036bb4":"code","18890b45":"code","bada9434":"code","8afe540c":"code","042df229":"code","326c57d7":"code","677457e8":"code","a2bbdbb1":"code","834dc85d":"code","a681f8c0":"code","62740244":"code","d186a818":"markdown","f52b51ee":"markdown","e3af0f8c":"markdown","6c8a3d61":"markdown","c85f68f3":"markdown"},"source":{"4040aca3":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport torch\nimport torchvision\n\ntorch.__version__, torchvision.__version__","fc1ac685":"# Check GPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","da4241c1":"def predict(net, loader, record_y=False):\n\n    y_pred_list = []\n    with torch.no_grad():\n\n        total_loss = 0.0\n        total_sample = 0\n        for i, data in enumerate(loader, 0):\n            inputs, labels = data[0].to(device), data[1].to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            \n            current_sample = len(labels)\n            total_sample += current_sample\n            total_loss += loss.item() * current_sample\n\n            if record_y:\n                y_pred_list.append(outputs.cpu().numpy())\n                \n    avg_loss = total_loss \/ total_sample\n    print(f\"Average loss: {avg_loss}\")\n    \n    if record_y:\n        y_pred = np.concatenate(y_pred_list)\n        return y_pred\n    else:\n        return avg_loss\n","22ac8e74":"ds = xr.open_dataset('..\/input\/chest-xray-cleaned\/chest_xray.nc')\nds","a8a9a1db":"ds['image'].isel(sample=slice(0, 12)).plot(col='sample', col_wrap=4, cmap='gray')","d4ee7514":"ds['label'].mean(dim='sample').to_pandas().plot.barh()  # proportion","48399a72":"all_labels = ds['feature'].values.astype(str)\nall_labels","0c3d864e":"%%time\nX_all = ds['image'].data[:, np.newaxis, :, :]  # pytorch use channel-first, unlike Keras\ny_all = ds['label'].data.astype(np.float32)  \n# https:\/\/discuss.pytorch.org\/t\/runtimeerror-expected-object-of-scalar-type-long-but-got-scalar-type-float-when-using-crossentropyloss\/30542\/4\n# https:\/\/discuss.pytorch.org\/t\/expected-object-of-scalar-type-float-but-got-scalar-type-long-for-argument-2-target\/44109\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=0.2, random_state=42\n)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","91ca2a64":"trainset = torch.utils.data.TensorDataset(\n    torch.from_numpy(X_train), torch.from_numpy(y_train)\n)\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=32, shuffle=True, num_workers=2\n)\n\ntestset = torch.utils.data.TensorDataset(\n    torch.from_numpy(X_test), torch.from_numpy(y_test)\n)\n\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=32, shuffle=False, num_workers=2\n)","84036bb4":"dataiter = iter(trainloader)\ndata = dataiter.next()\ninputs, labels = data[0].to(device), data[1].to(device)\ninputs.shape, labels.shape  # batch, channel, x, y","18890b45":"inputs.dtype, labels.dtype","bada9434":"class Net(nn.Module):\n    def __init__(self,):\n        super(Net, self).__init__()\n        \n        channel_1 = 16\n        channel_2 = 32\n        channel_3 = 64\n        \n        self.conv1 = nn.Conv2d(1, channel_1, 3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(channel_1, channel_2, 3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(channel_2, channel_3, 3, padding=1)\n        \n        last_x = 32  # spatial size = \/128 \/ 2 \/ 2\n        self.last_size = channel_3 * last_x * last_x\n        self.fc1 = nn.Linear(self.last_size, 14)  # need to flatten to filter * x * y\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.pool1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.pool2(x))\n        x = F.relu(self.conv3(x))\n        x = x.view(-1, self.last_size)  # flatten\n        x = self.fc1(x)\n        x = torch.sigmoid(x)\n        # https:\/\/discuss.pytorch.org\/t\/usage-of-cross-entropy-loss\/14841\/5\n        return x\n\nnet = Net()","8afe540c":"%time net.to(device)","042df229":"%%time\n\n# criterion = nn.MSELoss()\ncriterion = nn.BCELoss()\n\noptimizer = optim.Adam(net.parameters())\n\nprint_freq = 400  # print loss per that many steps\n\ntrain_history = []\neval_history = []\nfor epoch in range(5):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        # inputs, labels = data\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % print_freq == print_freq-1:\n            print('[%d, %5d] loss: %.4f' %\n                  (epoch + 1, i + 1, running_loss \/ print_freq))\n            running_loss = 0.0\n            \n    print('Training loss:')\n    train_loss = predict(net, trainloader, record_y=False)\n    train_history.append(train_loss)\n    \n    # we shouldn't actually monitor test loss; just for convenience\n    print('Validation loss:')\n    eval_loss = predict(net, testloader, record_y=False)\n    eval_history.append(eval_loss)\n    print('-- new epoch --')\n\nprint('Finished Training')","326c57d7":"df_history = pd.DataFrame(\n    np.stack([train_history, eval_history], axis=1), \n    columns=['train_loss', 'val_loss'],\n)\ndf_history.index.name = 'epoch'\ndf_history","677457e8":"plt.rcParams['font.size'] = 14\ndf_history.plot(grid=True, marker='o', ylim=[0, None], linewidth=3.0, alpha=0.8)\nplt.title('Simple CNN on Chest-xray')","a2bbdbb1":"%%time \n\n# do not shuffle, so that the output order matches true label\ny_train_pred = predict(\n    net, \n    torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False, num_workers=2),\n    record_y=True\n)\n\ny_test_pred = predict(net, testloader, record_y=True)","834dc85d":"def plot_ruc(y_true, y_pred):\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n    \n    for (idx, c_label) in enumerate(all_labels):\n        fpr, tpr, thresholds = roc_curve(y_true[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')","a681f8c0":"plot_ruc(y_test, y_test_pred)\nplt.title('ROC test set')","62740244":"plot_ruc(y_train, y_train_pred)\nplt.title('ROC train set')","d186a818":"# Prepare training data","f52b51ee":"# Fit model","e3af0f8c":"# Evaluation","6c8a3d61":"# Util function","c85f68f3":"# Examine learning curve"}}