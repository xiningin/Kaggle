{"cell_type":{"a833b2a6":"code","ad9f9609":"code","99612cde":"code","9cea6980":"code","4bd22d36":"code","c78331f5":"code","039aff02":"code","881f189d":"code","dc7e4dc7":"code","a6f434b5":"code","a6252670":"code","3a56f9cb":"code","ae7d0394":"code","bfcb5edf":"code","2286d418":"code","1ee16f32":"code","ea9f83ef":"code","2b438a34":"code","db88a2c6":"code","748591f1":"markdown","0cd9d2a4":"markdown","bc97b5ec":"markdown","c9a0fa26":"markdown"},"source":{"a833b2a6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, KBinsDiscretizer, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score","ad9f9609":"# download train and test files\n! wget -q https:\/\/datahack-prod.s3.amazonaws.com\/train_file\/train.csv_VsW9EGx.zip\n! unzip -q train.csv_VsW9EGx.zip\n! wget -q https:\/\/datahack-prod.s3.amazonaws.com\/test_file\/test.csv_yAFwdy2.zip\n! unzip -q test.csv_yAFwdy2.zip\n! wget -q https:\/\/datahack-prod.s3.amazonaws.com\/sample_submission\/sample_submission_iA3afxn.csv","99612cde":"# dropping region_code\ndf = pd.read_csv('train.csv').drop(['id', 'Region_Code'], 1)\ndf['Policy_Sales_Channel'] = df['Policy_Sales_Channel'].astype(int)\nprint(df.shape)\ndf.head(4)","9cea6980":"# checking nans\ndf.isnull().sum()","4bd22d36":"# checking datatypes\ndf.dtypes","c78331f5":"# checking unique values in all columns\nfor i in df.columns:\n  print(f'{i} -> {df[i].nunique()}')\n  print(df[i].value_counts(dropna=False))\n  print('---------------')","039aff02":"# defining categorical and continous columns\ncategorical = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\ncontinous = ['Age', 'Annual_Premium', 'Vintage']\ny = 'Response'","881f189d":"# encoding categorical columns\ncat_enc = {}\nfor col in categorical:\n  cat_enc[f'{col}_enc'] = LabelEncoder()\n  df[col] = cat_enc[f'{col}_enc'].fit_transform(df[col])\nprint(cat_enc)","dc7e4dc7":"# binning age column\nage_enc = KBinsDiscretizer(n_bins=5, encode='ordinal')\ndf['Age'] = age_enc.fit_transform(df['Age'].values.reshape(-1, 1)).astype(int)","a6f434b5":"# encoding policy_sales_channel\nchannel_map = {}\nchannel_count = df.groupby('Policy_Sales_Channel')['Response'].value_counts(normalize=True).to_dict()\nfor i, channel in enumerate(df['Policy_Sales_Channel'].unique()):\n  count = channel_count.get((channel, 0))\n  if count is not None:\n    if count > 0.95:\n      channel_map[channel] = 0\n    elif count > 0.9:\n      channel_map[channel] = 1\n    elif count > 0.8:\n      channel_map[channel] = 2\n    else:\n      channel_map[channel] = 3\n  else:\n    channel_map[channel] = 3\n    print(channel)\ndf['Policy_Sales_Channel'] = [channel_map[i] for i in df['Policy_Sales_Channel'].values.tolist()]","a6252670":"# scaling continous columns\nscaler = StandardScaler()\ndf[['Annual_Premium', 'Vintage']] = scaler.fit_transform(df[['Annual_Premium', 'Vintage']])","3a56f9cb":"df.head()","ae7d0394":"# train validation split\nx, y = df.drop('Response', 1), df['Response']\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.05, stratify = y, random_state=36)\nprint(x_train.shape, x_val.shape)","bfcb5edf":"lr = LogisticRegression(class_weight='balanced')\nlr.fit(x_train, y_train)\ny_pred = lr.predict_proba(x_val)\nroc_auc_score(y_val, y_pred[:, 1])","2286d418":"test_df = pd.read_csv('test.csv').drop(['Region_Code'], 1)\ntest_df['Policy_Sales_Channel'] = test_df['Policy_Sales_Channel'].astype(int)\nprint(test_df.shape)\ntest_df.head(4)","1ee16f32":"for col in categorical:\n  test_df[col] = cat_enc[f'{col}_enc'].transform(test_df[col])\ntest_df['Age'] = age_enc.transform(test_df['Age'].values.reshape(-1, 1)).astype(int)\ntest_df['Policy_Sales_Channel'] = [channel_map[i] if i in channel_map else 1 for i in test_df['Policy_Sales_Channel'].values.tolist()]\ntest_df[['Annual_Premium', 'Vintage']] = scaler.transform(test_df[['Annual_Premium', 'Vintage']])\ntest_df.head(2)","ea9f83ef":"# training LR on whole dataset\nlr = LogisticRegression(class_weight='balanced')\nlr.fit(x, y)","2b438a34":"x_test = test_df.drop('id', 1).values\ny_test = lr.predict_proba(x_test)\nsubmit_df = pd.DataFrame(data={'id': test_df['id'], 'Response': y_test[:, 1]})\nsubmit_df['Response'] = submit_df['Response'].astype('float16')\nsubmit_df['id'] = submit_df['id'].astype('int32')\nsubmit_df.head()","db88a2c6":"submit_df.to_csv('lr_submission.csv', index=False)","748591f1":"## Simple EDA","0cd9d2a4":"## Data Processing","bc97b5ec":"## Model Training","c9a0fa26":"## Predictions on Test Dataset"}}