{"cell_type":{"827f351a":"code","26198505":"code","3d56a6a2":"code","5edc4f52":"code","8084254a":"code","fbed9807":"code","c6f0b361":"code","83ff5995":"code","d43307c8":"code","6d1f0632":"code","d9ead29f":"code","60a0c40b":"code","a0598f68":"code","6f80f118":"code","bf8da6ad":"code","85054a05":"code","e7de29b3":"code","d9c4916a":"code","678abc25":"code","410f48b5":"code","7299e055":"code","ae368843":"code","1856a631":"code","173dce70":"code","abcea93f":"code","db1682f3":"code","c555910c":"code","9f8d0935":"code","2d38b78e":"code","c806cc7e":"code","7515febd":"code","263d94e2":"code","ab5fcc9e":"code","7ea3d03b":"code","d9de9260":"code","f683423b":"code","fa281e9c":"code","0810f69f":"code","b4971fdc":"code","2c896f92":"code","3d9296e6":"code","138a4104":"code","cef2cbab":"code","3a091513":"code","44a5569d":"code","905e6ea7":"code","75d95e28":"code","188f992f":"code","f426fbc1":"code","1003f137":"code","24866a32":"code","9c8d52de":"code","68e00e3f":"code","ec3fbe41":"code","cf569853":"code","13d97a15":"code","e8b2f2b0":"code","92f97af4":"code","b2bc3782":"code","2b946b8e":"code","a67ce836":"code","9c79ed36":"code","9b9976c1":"code","28dd45b7":"code","26e5511f":"code","316e193a":"code","5d7c1c1d":"code","9ef7f840":"code","169f7477":"code","fb64be57":"code","83e3384b":"code","89bf7144":"code","fce9c32e":"code","32fd09e0":"code","d8198d03":"code","f206607a":"code","1bb0fdcf":"code","f9c5fdf7":"code","5e144827":"code","0c0e4450":"code","4f8fabfe":"markdown","ab949417":"markdown","a73174c6":"markdown","3288753f":"markdown","a29232b3":"markdown","21631def":"markdown","3afe7da9":"markdown","c6d13ed4":"markdown","51908ba5":"markdown","078656b0":"markdown"},"source":{"827f351a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26198505":"data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\ndata.shape, test_data.shape","3d56a6a2":"data.head()","5edc4f52":"# distribution of numerical features\ndata.describe()\n# 25% travel with their siblies and\/or spouses\n# >75% do not travel with their parents and\/or children\n# <1% bought fare with 512","8084254a":"# distribution of categorical features\ndata.describe(include=['O'])\n# about 23.6% duplicates in ticket, so it might be someone bought a group of tickets with same number\n# about 77% missing in Cabin column, and about 28% duplicates, so it might be few people live in same cabin\n# only 2 null values in Embarked column","fbed9807":"data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived')\n# higher class has better survival rate","c6f0b361":"data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived')\n# female has better survival rate","83ff5995":"g = sns.FacetGrid(data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\n# smallest, oldest ones have better survival rate","d43307c8":"g = sns.FacetGrid(data, col='Survived')\ng.map(plt.hist, 'Pclass')\n# class 3 has highest died rate, class 1 has better surivival rate","6d1f0632":"g = sns.FacetGrid(data, col='Survived', row='Pclass')\ng.map(plt.hist, 'Age')\ng.add_legend()\n# at higher class 1, survival distribution is nearly normal\n# at lower level, smaller age has better surivival rate relatively","d9ead29f":"g = sns.FacetGrid(data, row='Embarked', aspect=1.6)\ng.map(sns.pointplot,'Pclass', 'Survived', 'Sex', palette='deep')\ng.add_legend()\n# only at port C, male has better surivival rate\n# female in general has better surivival rate ","60a0c40b":"g = sns.FacetGrid(data, col='Survived')\ng.map(plt.hist, 'Fare')\ng.add_legend()\n# paid high fare has better surivival rate","a0598f68":"g = sns.FacetGrid(data, col='Survived')\ng.map(plt.hist, 'Embarked')\ng.add_legend()\n# port S has highest survival rate, C is next ","6f80f118":"g = sns.FacetGrid(data, col='Embarked')\ng.map(plt.hist, 'Fare')\n# port S is mainly from lower fare, port C is from relatively high fare, Q is within lowest","bf8da6ad":"g = sns.FacetGrid(data, col='Embarked', row = 'Survived')\ng.map(sns.barplot, 'Sex', 'Fare', ci=None)\ng.add_legend()","85054a05":"# helper function as evaluation metrics\ndef check_null(df, n=30):\n    return df.isnull().sum().sort_values(ascending=False).head(n)\n\ndef score_model(model, x_train, y_train,  x_valid, y_valid, threshold=False):\n    model.fit(x_train, y_train)\n    prediction = model.predict(x_valid)\n    mae = mean_absolute_error(y_valid, prediction)\n    mse = mean_squared_error(y_valid, prediction)\n    score = {}\n    # if need to tune threshold, turn on flag\n    # specific number need to be tuned\n    if threshold:\n        threshold = 0.6\n        while threshold < .7:\n            preds = [1 if prediction[i] >= threshold else 0 for i in range(len(prediction))]\n            # accuracy = TP+TN\/TP+FP+FN+TN\n            # precision = TP\/TP+FP\n            # recall = TP\/TP+FN\n            num_tp = 0\n            num_fp = 0\n            num_fn = 0\n            num_tn = 0\n            if not isinstance(y_valid, list):\n                y_valid = y_valid.to_list()\n            for i in range(len(preds)):\n                # positive\n                if preds[i] == 1 & preds[i] == y_valid[i]:\n                    num_tp += 1\n                elif preds[i] == 1 & preds[i] != y_valid[i]:\n                    num_fp += 1\n                # negative\n                elif preds[i] == 0 & preds[i] == y_valid[i]:\n                    num_tn += 1\n                elif preds[i] == 0 & preds[i] != y_valid[i]:\n                    num_fn += 1\n            accuracy = (num_tp+num_tn)\/len(preds)\n            precision = num_tp\/(num_tp+num_fp)\n            recall = num_tp\/(num_tp+num_fn)\n            score[threshold] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'mae': mae, 'mse': mse}\n            threshold += 0.02\n    else:\n        score['mae'] = mae\n        score['mse'] = mse\n    return score","e7de29b3":"# loading\ndata = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\n# shuffle data\ndata = data.reindex(np.random.permutation(np.arange(len(data))))","d9c4916a":"valid_fraction = 0.2\nvalid_size = int(len(data) * valid_fraction)\ntrain_data = data[:-valid_size]\nvalid_data = data[-valid_size:]\nif train_data['Survived'].mean() != valid_data['Survived'].mean():\n    print(f'self splitting does not have same proportion on label: {train_data[\"Survived\"].mean(), valid_data[\"Survived\"].mean()}')\n    y = data.Survived\n    x = data.loc[:, data.columns != 'Survived'].copy()\n    x_train, x_valid, y_train, y_valid = train_test_split(x, y, random_state = 0)\n    print(f'by using sklearn library, we got {y_train.mean(), y_valid.mean()}')","678abc25":"# preprocessing missing value\ntrain_col_has_null = [col for col in x_train.columns if x_train[col].isnull().any()]\nvalid_col_has_null = [col for col in x_valid.columns if x_valid[col].isnull().any()]\n# remove rows that age col contain null value\n# not work !!! \n# x_train = x_train[x_train['Age'].notna()]\n# x_valid = x_valid[x_valid['Age'].notna()]\n# y_train = y_train[x_train.index[x_train['Age'].notna()]]\n# y_valid = y_valid[x_valid.index[x_valid['Age'].notna()]]\n\n# test_data = test_data[test_data['Age'].notna()]\n# remove unnecessary cols\nunnece_col = ['Name', 'Ticket', 'Cabin', 'Embarked']\nx_train = x_train.drop(unnece_col, axis=1)\nx_valid = x_valid.drop(unnece_col, axis=1)\ntest_data = test_data.drop(unnece_col, axis=1)\n# imputate to remaining col has null\nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer(strategy='most_frequent')\nimputed_x_train = pd.DataFrame(my_imputer.fit_transform(x_train))\nimputed_x_valid = pd.DataFrame(my_imputer.transform(x_valid))\nimputed_test_data = pd.DataFrame(my_imputer.transform(test_data))\nimputed_x_train.columns = x_train.columns\nfor col in imputed_x_train.columns:\n    imputed_x_train[col] = imputed_x_train[col].astype(x_train[col].dtypes.name)\nimputed_x_valid.columns = x_valid.columns\nfor col in imputed_x_valid.columns:\n    imputed_x_valid[col] = imputed_x_valid[col].astype(x_valid[col].dtypes.name)\nimputed_test_data.columns = test_data.columns\nfor col in imputed_test_data.columns:\n    imputed_test_data[col] = imputed_test_data[col].astype(imputed_test_data[col].dtypes.name)","410f48b5":"# preprocessing categorical value - sex \nfrom sklearn.preprocessing import LabelEncoder\ncat_col = imputed_x_train.select_dtypes('object').columns.tolist()\nlabel_x_train = imputed_x_train.copy()\nlabel_x_valid = imputed_x_valid.copy()\nlabel_test_data = imputed_test_data.copy()\nlabel_encoder = LabelEncoder()\nfor col in cat_col:\n    label_x_train[col] = label_encoder.fit_transform(imputed_x_train[col])\n    label_x_valid[col] = label_encoder.transform(imputed_x_valid[col])\n    label_test_data[col] = label_encoder.transform(imputed_test_data[col])","7299e055":"model = RandomForestRegressor(n_estimators=127, max_depth=10, random_state=0)\nscore_model(model, label_x_train, y_train,  label_x_valid, y_valid)","ae368843":"# loading\ndata = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\nPassengerId = test_data.PassengerId\n\ntrain, valid= train_test_split(data, random_state = 0)\ncombine = [train, valid, test_data]","1856a631":"# drop Ticket, Cabin col as num of duplicates in ticket and plenty missing value in Cabin also duplicate\nfor dataset in combine:\n    print('Before drop ', dataset.shape)\n    dataset.drop(['Ticket', 'Cabin'], axis=1, inplace=True)\n    print('After drop ',dataset.shape)","173dce70":"# Adding new features to data \nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.', expand=False)","abcea93f":"# sorting new feature Title\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady','Mlle', 'Mme'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Mrs')\n    title_dic = dict(zip(dataset.groupby('Title').PassengerId.count().index.tolist(), dataset.groupby('Title').PassengerId.count().tolist()))\n    for i, v in title_dic.items():\n        if v<7:\n            dataset['Title'] = dataset['Title'].replace(i, 'Rare')\n# we can drop Name, passenerageId cols","db1682f3":"for dataset in combine:\n    print(pd.crosstab(dataset['Title'], dataset['Sex']))\n    print('-----')","c555910c":"# check details of dataset \nfor dataset in combine:\n    print(dataset.shape)\n    print(dataset.Age.describe())\n    print('-------')","9f8d0935":"check_null(train), check_null(valid), check_null(test_data)","2d38b78e":"test_data[test_data.Fare.isnull()]","c806cc7e":"# only test dataset Fare column has null value with mean value\ntest_data.Fare.fillna(test_data.Fare.median(), inplace=True)\ncheck_null(test_data)","7515febd":"# fill null value for embarked by mode\nfor dataset in combine:\n    most_freq = dataset.Embarked.mode()[0]\n    dataset['Embarked'] = dataset['Embarked'].fillna(most_freq)","263d94e2":"# fill null value in age co by filling mean of same title columns\nfor dataset in combine:\n    mean_based_title = dict(zip(dataset.groupby('Title').Age.mean().index.tolist(), dataset.groupby('Title').Age.mean().tolist()\n))\n    for k,v in dataset[dataset['Age'].isnull()].Title.items():\n        dataset['Age'] = dataset['Age'].fillna(mean_based_title[dataset.loc[k].Title])","ab5fcc9e":"check_null(train, 5), check_null(valid, 5), check_null(test_data, 5)","7ea3d03b":"# create age band to narrow down age distribution \nfor dataset in combine:\n    plt.hist(dataset.Age, width=2)\n    plt.legend(['train_dataset', 'valid_dataset', 'test_dataset'])","d9de9260":"print(f'In train dataset min age is {train.Age.min()} and max age is {train.Age.max()}.\\nIn valid dataset min age is {valid.Age.min()} and max age is {valid.Age.max()}.\\nIn test dataset min age is {test_data.Age.min()} and max age is {test_data.Age.max()}')","f683423b":"# it is from previous idea to create new feature AgeBand \n# train[['AgeBand', 'Survived']].groupby(['AgeBand']).mean().sort_values(by='Survived')\n# valid[['AgeBand', 'Survived']].groupby(['AgeBand']).mean().sort_values(by='Survived')","fa281e9c":"# add new feature\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 \ntrain[['FamilySize', 'Survived']].groupby(['FamilySize']).mean().sort_values(by='Survived')","0810f69f":"valid[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived')","b4971fdc":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean().sort_values(by='IsAlone')","2c896f92":"for dataset in combine:\n    plt.hist(dataset.Fare)\n    plt.legend(['train_dataset', 'valid_dataset', 'test_dataset'])","3d9296e6":"# for dataset in combine:\n#     dataset['FareBand'] = pd.cut(dataset.Fare, 4)\n# train[['FareBand', 'Survived']].groupby('FareBand', as_index=False).mean().sort_values(by='FareBand')","138a4104":"train_y = train.Survived\nvalid_y = valid.Survived\ntrain_x = train.loc[:, train.columns!='Survived'].copy()\nvalid_x = valid.loc[:, valid.columns!='Survived'].copy()\ncombine_1 = [train_x, valid_x, test_data]","cef2cbab":"for dataset in combine_1:\n    print('Before drop: ', dataset.shape)\n    dataset.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch'], inplace=True)\n    print('After drop: ', dataset.shape)","3a091513":"# label_cat = ['FareBand']\n# for feature in label_cat:\n#     label_encoder = preprocessing.LabelEncoder()\n#     train_x[feature] = label_encoder.fit_transform(train_x[feature])\n#     valid_x[feature] = label_encoder.transform(valid_x[feature])\n#     test_data[feature] = label_encoder.transform(test_data[feature])","44a5569d":"train_x.groupby('Title').count()","905e6ea7":"for dataset in combine_1:\n    dataset['Sex'] = dataset['Sex'].map({'male': 0, 'female': 1}).astype(int)\n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n    dataset['Title'] = dataset['Title'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Rare': 4}).astype(int)","75d95e28":"train_x","188f992f":"train_x.shape, valid_x.shape, test_data.shape","f426fbc1":"n_est = [i for i in range(50, 300, 25)]\nscores = []\nfor i in n_est:\n    model = RandomForestClassifier(n_estimators=i, random_state=0)\n    model.fit(train_x, train_y)\n    prediction = model.predict(valid_x)\n    mae = mean_absolute_error(valid_y, prediction)\n    scores.append(np.mean(mae))\nplt.plot(n_est, scores)\n# best score model n_est=130","1003f137":"model = RandomForestRegressor(n_estimators=100, random_state=0)\nscore_model(model, train_x, train_y, valid_x, valid_y).keys()\nthresholds = []\nscores = []\nfor k, v in score_model(model, train_x, train_y, valid_x, valid_y, True).items():\n    thresholds.append(k)\n    scores.append(np.mean(v['precision']))\nplt.plot(thresholds, scores)\n# best score model and threshold value=0.63 if using RandomForestRegressor","24866a32":"model = RandomForestRegressor(n_estimators=127, random_state=0)\nscore_model(model, train_x, train_y, valid_x, valid_y).keys()\nthresholds = []\nscores = []\nfor k, v in score_model(model, train_x, train_y, valid_x, valid_y, True).items():\n    thresholds.append(k)\n    scores.append(np.mean(v['precision']))\nplt.plot(thresholds, scores)\n# best score model and threshold value=0.62 and n_est=127 if using RandomForestRegressor","9c8d52de":"depth_ = [i for i in range(4, 12)]\nscores = []\nthreshold = 0.62\nfor depth in depth_:\n    model = RandomForestRegressor(n_estimators=127, max_depth=depth, random_state=0)\n    model.fit(train_x, train_y)\n    prediction = model.predict(valid_x)\n    preds = [1 if prediction[i] >= threshold else 0 for i in range(len(prediction))]\n    mae = mean_absolute_error(valid_y, preds)\n    scores.append(np.mean(mae))\nplt.plot(depth_, scores)\n# best score model and threshold value=0.62 and n_est=127 and depth=10 if using RandomForestRegressor","68e00e3f":"# pick model \nmodel = RandomForestRegressor(n_estimators=127, max_depth=5, random_state=0)\nmodel.fit(train_x, train_y)\nprediction = model.predict(test_data)\nthreshold = 0.62\npreds = [1 if prediction[i] >= threshold else 0 for i in range(len(prediction))]","ec3fbe41":"pd.DataFrame({'PassengerId': PassengerId, 'Survived': preds}).to_csv('titanic_test7.csv', index=False)","cf569853":"# loading\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","13d97a15":"check_null(train_data, 5), check_null(test_data, 5)","e8b2f2b0":"train_data['Age'] = train_data['Age'].fillna(-0.5)\ntest_data['Age'] = test_data['Age'].fillna(-0.5)\nbins = [-1, 0, 3, 10, 18, 25, 45, 60, np.inf]\nlabels = ['unknown', 'baby', 'child', 'teenager', 'young adult', 'adult', 'middle age', 'senior']\ntrain_data['AgeGroup'] = pd.cut(train_data['Age'], bins, labels=labels)\ntest_data['AgeGroup'] = pd.cut(test_data['Age'], bins, labels=labels)\nsns.barplot(x='AgeGroup', y='Survived', data=train_data)\nplt.show()","92f97af4":"# plp without cabin value survive rate is relatively low\ntrain_data['CabinBool'] = train_data['Cabin'].notnull().astype('int')\ntest_data['CabinBool'] = test_data['Cabin'].notnull().astype('int')\nsns.barplot(x='CabinBool', y='Survived', data=train_data)\nplt.show()","b2bc3782":"y_train = train_data.pop('Survived')\n# combin train dataset and test dataset\nall_data = [train_data, test_data]","2b946b8e":"# title = pd.DataFrame()\ntitle_dict = {\n    'Capt': 'Officer',\n    'Col': 'Officer',\n    'Don': 'Rare',\n    'Dona': 'Rare',\n    'Dr': 'Officer',\n    'Jonkheer': 'Rare',\n    'Lady': 'Miss',\n    'Major': 'Officer',\n    'Master': 'Officer',\n    'Miss': 'Miss',\n    'Mlle': 'Miss',\n    'Mme': 'Mrs',\n    'Mr': 'Mr',\n    'Mrs': 'Mrs',\n    'Ms': 'Mrs',\n    'Rev': 'Officer',\n    'Sir': 'Mr',\n    'the Countess': 'Rare'\n}\nfor data in all_data:\n    data['Title'] = data['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    data['Title'] = data['Title'].map(title_dict)\n\n# title['Title'] = title.Title.map(title_dict)\n# title = pd.get_dummies(title.Title)\nfor data in all_data:\n#     data = pd.concat((data, title), axis=1)\n    data.pop('Name')","a67ce836":"# Cabin col become N, C, S, \nfor data in all_data:\n    data['Cabin'] = data['Cabin'].fillna('NA')\n    data['Cabin'] = data['Cabin'].map(lambda s:s[0])\n    data.pop('Ticket')","9c79ed36":"# PCLASS change datatype to string as categorical data, later transfer to one-hot\nfor data in all_data:\n    data['Pclass'] = data['Pclass'].astype(str)\n    data.isnull().sum().sort_values(ascending=False)","9b9976c1":"# fill null value \nfor data in all_data:\n    data['Embarked'].fillna(data['Embarked'].mode()[0],inplace=True)\n    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n    data.isnull().sum().sort_values(ascending=False)","28dd45b7":"for data in all_data:\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1","26e5511f":"train_data = pd.concat([train_data, pd.get_dummies(train_data[['Pclass', 'Sex', 'Embarked', 'Cabin', 'AgeGroup', 'Title']])], axis=1)\ntest_data = pd.concat([test_data, pd.get_dummies(test_data[['Pclass', 'Sex', 'Embarked', 'Cabin', 'AgeGroup', 'Title']])], axis=1)","316e193a":"train_data.shape","5d7c1c1d":"# encode cat features\nfor data in all_data:\n#     feature_dummies = pd.get_dummies(data[['Pclass', 'Sex', 'Embarked', 'Cabin', 'AgeGroup', 'Title']])\n#     data = pd.concat([data, pd.get_dummies(data[['Pclass', 'Sex', 'Embarked', 'Cabin', 'AgeGroup', 'Title']])], axis=1)\n    # drop cols\n    print('Before: ', data.shape)\n    data.drop(['Pclass', 'Sex', 'Embarked', 'Cabin','AgeGroup', 'Age', 'SibSp', 'Parch'], inplace=True, axis=1)\n    print('After: ', data.shape)\n#     data = pd.concat((data, feature_dummies), axis=1)","9ef7f840":"train_data.drop(['Pclass', 'Sex', 'Embarked', 'Cabin','AgeGroup', 'Age', 'SibSp', 'Parch'], inplace=True, axis=1)\ntest_data.drop(['Pclass', 'Sex', 'Embarked', 'Cabin','AgeGroup', 'Age', 'SibSp', 'Parch'], inplace=True, axis=1)","169f7477":"# split dataset \n# train_df = all_data.iloc[train_data.index]\n# test_df = all_data.iloc[test_data.index]\n# train_df.shape, test_df.shape","fb64be57":"train_df=train_data\ntest_df=test_data\ntrain_df.drop('Title', axis=1, inplace=True)\ntest_df.drop('Title', axis=1, inplace=True)","83e3384b":"# model train\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\ndepth_ = [i for i in range(1, 9)]\nscores = []\nfor depth in depth_:\n    clf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=0)\n    test_score = cross_val_score(clf, train_df, y_train, cv=5, scoring='precision')\n    scores.append(np.mean(test_score))\nplt.plot(depth_, scores)\n# depth at 7 reaches max arount 0.82 with cv=5\n# depth at 2 reaches max arount 0.75 with cv=5","89bf7144":"n_est = [i for i in range(25,200,20)]\nscores = []\nfor n in n_est:\n    clf = RandomForestClassifier(n_estimators=n, max_depth=2, random_state=0)\n    test_score = cross_val_score(clf, train_df, y_train, cv=5, scoring='precision')\n    scores.append(np.mean(test_score))\nplt.plot(n_est, scores)\n# n_estimators at 130 reach 0.826 with cv=5\n# n_estimators at 60 reach 0.74 with cv=5","fce9c32e":"from sklearn.model_selection import train_test_split\ntrain_x, valid_x, train_y, valid_y = train_test_split(train_df, y_train,random_state=0)\ntrain_x.shape, valid_x.shape, test_data.shape","32fd09e0":"train_x.drop(['Cabin_T'], axis=1, inplace=True)\nvalid_x.drop(['Cabin_T'], axis=1, inplace=True)\n# as train dataset in cabin col has start with T with only one row, however test dataset doesn't have just delete from trainset","d8198d03":"from sklearn.metrics import mean_absolute_error\nn_est = [i for i in range(25,150,10)]\nscores = []\nfor n in n_est:\n    clf = RandomForestClassifier(n_estimators=n, max_depth=2, random_state=0)\n    clf.fit(train_x, train_y)\n    predition = clf.predict(valid_x)\n    scores.append(np.mean(mean_absolute_error(valid_y, predition)))\nplt.plot(n_est, scores)\n# n_est=75 reach lowest \n# n_est=45 reach lowest ","f206607a":"depth_ = [i for i in range(5, 20)]\nscores = []\nfor depth in depth_:\n    clf = RandomForestClassifier(n_estimators=45, max_depth=depth, random_state=0)\n    clf.fit(train_x, train_y)\n    predition = clf.predict(valid_x)\n    scores.append(np.mean(mean_absolute_error(valid_y, predition)))\nplt.plot(depth_, scores)\n# depth=6 reach lowest\n# depth=11 reach lowest 0.165","1bb0fdcf":"clf = RandomForestClassifier(n_estimators=45, max_depth=11, random_state=0)\nclf.fit(train_x, train_y)\npredition = clf.predict(valid_x)\nmean_absolute_error(valid_y, predition)","f9c5fdf7":"final_clf = RandomForestClassifier(n_estimators=45, max_depth=11, random_state=0)\nfinal_clf.fit(train_x, train_y)\nresult = final_clf.predict(test_df)\npd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': result}).to_csv('titanic_test6.csv', index=False)","5e144827":"# get whole dataset\ndata = pd.read_csv('..\/input\/titanic\/train.csv')\ny = data.Survived\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nId = test.PassengerId","0c0e4450":"model_on_full_data = RandomForestClassifier(n_estimators=75, max_depth=6, random_state=0)\nmodel_on_full_data.fit(train_data, y)\npreds = model_on_full_data.predict(test_data)\npd.DataFrame({'PassengerId': Id, 'Survived': preds}).to_csv('titanic_test8.csv', index=False)","4f8fabfe":"## Exploratory Data Analysis","ab949417":"## First try","a73174c6":"###### 3: SCORE: result 0.76076 :( NO IMPROVMENT\nlocal acc=0.8246268656716418=precision \nRandomForestRegressor(n_estimators=140, max_depth=4, min_samples_split=3, random_state=0) threshold=0.67\n###### 4: SCORE: result 0.77990 IMPROVMENT\nlocal acc=0.8544776119402985=precision \nRandomForestClassifier(n_estimators=35, max_depth=8, random_state=0) \n###### 5: SCORE: result 0.73205 :( NO IMPROVMENT\nlocal acc=0.7910447761194029=precision  mae=0.208955223880597\nRandomForestClassifier(n_estimators=100, random_state=0) \n##### 6: SCORE: result 0.79904 IMPROVMENT\nlocal acc=0.8385650224215246=precision  mae=0.16143497757847533\nRandomForestClassifier(n_estimators=75, max_depth=6, random_state=0) \n\n-- FEATURES: Index(['PassengerId', 'Fare', 'CabinBool', 'FamilySize', 'Pclass_1',\n       'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C',\n       'Embarked_Q', 'Embarked_S', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D',\n       'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_N', 'AgeGroup_unknown',\n       'AgeGroup_baby', 'AgeGroup_child', 'AgeGroup_teenager',\n       'AgeGroup_young adult', 'AgeGroup_adult', 'AgeGroup_middle age',\n       'AgeGroup_senior', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n       'Title_Officer', 'Title_Rare'],\n      dtype='object')\n##### 7: SCORE: result 0.77033 :( NO IMPROVMENT\nmae= 0.15671641791044777\nRandomForestRegressor(n_estimators=127, max_depth=10, random_state=0) threshold=0.62\n    **refinement of previous so far last try\n##### 8: SCORE: result 0.79425 :( NO IMPROVMENT -- ON FULL TRAIN DATASET same method as #6\nlocal acc=0.8385650224215246=precision  mae=0.16143497757847533\nRandomForestClassifier(n_estimators=75, max_depth=6, random_state=0) \n\n-- FEATURES: Index(['PassengerId', 'Fare', 'CabinBool', 'FamilySize', 'Pclass_1',\n       'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C',\n       'Embarked_Q', 'Embarked_S', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D',\n       'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_N', 'AgeGroup_unknown',\n       'AgeGroup_baby', 'AgeGroup_child', 'AgeGroup_teenager',\n       'AgeGroup_young adult', 'AgeGroup_adult', 'AgeGroup_middle age',\n       'AgeGroup_senior', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n       'Title_Officer', 'Title_Rare'],\n      dtype='object')","3288753f":"### encoding categorical data","a29232b3":"## Third try","21631def":"## Helper functions","3afe7da9":"## Second try\n\n\n### Preprocessing features","c6d13ed4":"### fill null values","51908ba5":"### **drop unnecessary columns","078656b0":"-----------------------------"}}