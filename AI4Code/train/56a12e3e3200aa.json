{"cell_type":{"9510912d":"code","93e86ce7":"code","33178c89":"code","d5b1541b":"code","32b142ae":"code","eb598fe4":"code","6b8e9d07":"code","00a6cb18":"code","9ada6684":"code","0a9692b1":"code","1d15f2d9":"code","074029fa":"code","4ca6a9a0":"code","72874eb9":"code","750ffab9":"code","238bfddf":"code","c6e1a75a":"code","30d9b64c":"code","9b111692":"code","67e9135b":"code","7af1b773":"code","2abe2023":"code","025d01cd":"code","da47024f":"code","82b57e79":"code","64cdd7f3":"code","01d96428":"code","74e30c16":"code","bf51a193":"code","5d6ff790":"code","71fc5aef":"code","7c42964c":"code","910d7c04":"code","4b1a754e":"code","0901ae54":"code","d86c7264":"code","7d8bef1b":"code","169b7338":"code","8b840303":"code","bf18bdcb":"code","435f5cea":"code","2e337fa7":"code","56617b94":"code","dd490516":"code","d74fd889":"code","6d36d65d":"code","a69be701":"code","95614f81":"code","9d3acb7d":"code","15171057":"code","6a2a8190":"code","ab71e7ea":"code","482004c9":"code","a688ba25":"code","ab69011b":"code","4500c31b":"code","8d5c756e":"code","3bbc15c9":"code","e1b852b5":"code","c772b97c":"code","a0cb53f4":"code","2a32d7d9":"code","57bcb332":"code","fd62e032":"code","6db5ee52":"code","5a031fa5":"code","2317182b":"code","6f14a395":"code","5a9f92c4":"code","9a55ad8a":"code","fc49a1b3":"code","d4af66ec":"code","31bbd062":"code","7f19b8ac":"code","32033650":"code","ef1065c2":"code","8508af0a":"code","ee3b1c38":"code","3ce6b250":"code","c487b0ee":"code","676dc987":"code","f3a6784e":"code","6ba66703":"code","2cf8f260":"code","958ec3ec":"code","424eb111":"code","ccc85071":"code","97b9d70c":"code","e6b6127a":"code","101f8f79":"code","a92b0aea":"code","80de58ed":"code","2636b312":"code","c1a128cc":"code","f6102926":"code","3465d873":"markdown","86192bb3":"markdown","6c027092":"markdown","e25334da":"markdown","dbe54517":"markdown","6fff46a1":"markdown","0f9ef53f":"markdown","f0241f18":"markdown","9f672275":"markdown","45bd4507":"markdown","d0b9c8ce":"markdown","7dad9781":"markdown","828a5683":"markdown","0d5c03ef":"markdown","c8d0a436":"markdown","233a8354":"markdown","d0bc4440":"markdown","d24f47d6":"markdown","a0249e44":"markdown"},"source":{"9510912d":"### This Notebook contains many models and predictions.\n### The best performing submission was Gradient Boosting Algorithm which was my highest in leaders board.\n### Best solution not submitted as i ran out of submission.\n### This notebook creates my best sol using Gradient Boosting\n### For csv of other models predictions remove # from makecsv method below model block.","93e86ce7":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings","33178c89":"df_tr = pd.read_csv('\/kaggle\/input\/predict-the-housing-price\/train.csv')\ndf_ts = pd.read_csv('\/kaggle\/input\/predict-the-housing-price\/Test.csv')\nprint(\"Train:\",df_tr.shape)\nprint(\"Test:\",df_ts.shape)","d5b1541b":"df_tr.head(5)","32b142ae":"print('Train Dataset Infomarion')\nprint (\"Rows     : \" ,df_tr.shape[0])\nprint (\"Columns  : \" ,df_tr.shape[1])\nprint (\"\\nFeatures : \\n\" ,df_tr.columns.tolist())\nprint (\"\\nMissing values :  \",df_tr.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df_tr.nunique())","eb598fe4":"df_ts.head(5)","6b8e9d07":"print('Test Dataset Infomarion')\nprint (\"Rows     : \" ,df_ts.shape[0])\nprint (\"Columns  : \" ,df_ts.shape[1])\nprint (\"\\nFeatures : \\n\" ,df_ts.columns.tolist())\nprint (\"\\nMissing values :  \",df_ts.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df_ts.nunique())","00a6cb18":"### Train Null values\nsns.heatmap(df_tr.isnull())","9ada6684":"# Train null list\nnullist = []\nnullist = df_tr.isnull().sum()\n#nullist.loc[nullist != 0]\nnul = pd.DataFrame(nullist.loc[nullist != 0])\nnul","0a9692b1":"# Numeric Nulls in Train\ncols_tr = df_tr.columns\nnum_cols_tr= df_tr._get_numeric_data().columns\ncat_cols_tr = list(set(cols_tr) - set(num_cols_tr))\n\nsns.heatmap(df_tr[num_cols_tr].isnull())","1d15f2d9":"## Categorical nulls in Train\nsns.heatmap(df_tr[cat_cols_tr].isnull())","074029fa":"# Test null list\nnullist1 = []\nnullist1 = df_ts.isnull().sum()\n#nullist.loc[nullist != 0]\nnul1 = pd.DataFrame(nullist1.loc[nullist1 != 0])\nnul1","4ca6a9a0":"### Test Null values\nsns.heatmap(df_ts.isnull())","72874eb9":"# Numeric Nulls in Test\ncols = df_ts.columns\nnum_cols = df_ts._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))\n\nsns.heatmap(df_ts[num_cols].isnull())","750ffab9":"### Categorical null cols in test\nsns.heatmap(df_ts[cat_cols].isnull())","238bfddf":"### Droping cols with too many nulls\ndrop_columns = ['FireplaceQu','PoolQC','Fence','MiscFeature','BsmtUnfSF']\ndf_tr.drop(drop_columns, axis = 1, inplace = True)\ndf_ts.drop(drop_columns, axis = 1, inplace = True)","c6e1a75a":"cols = df_tr.columns\nnum_cols = df_tr._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))","30d9b64c":"fill_col = ['Alley','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'GarageType','GarageFinish','GarageCond']\nfor i in fill_col:\n    print(i,\"values :\\n\",df_tr[i].value_counts())\n    print(\"_____________________\")","9b111692":"### Categorical data\nfor i in cat_cols:\n    print(i,\"values :\\n\",df_tr[i].value_counts())\n    print(\"_____________________\")","67e9135b":"## Filling No where Nan in Categorical data\nfor col in df_tr[fill_col]:\n    df_tr[col] = df_tr[col].fillna('None')\nfor col in df_ts[fill_col]:\n    df_ts[col] = df_ts[col].fillna('None')","7af1b773":"colfil = ['BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageCars', \n            'GarageArea']\nfor coll in colfil:\n    df_ts[coll].fillna(df_ts[coll].median(), inplace = True)","2abe2023":"num_cols = df_tr._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))","025d01cd":"df_tr['LotFrontage'].describe()","da47024f":"(df_tr['LotFrontage'].plot.box()) ","82b57e79":"sns.violinplot(df_tr['LotFrontage'])","64cdd7f3":"### replace null with median as there are many outliers\ndf_tr['LotFrontage'].fillna(value=df_tr['LotFrontage'].median(),inplace=True)\ndf_ts['LotFrontage'].fillna(value=df_ts['LotFrontage'].median(),inplace=True)","01d96428":"df_tr.GarageYrBlt.describe()","74e30c16":"(df_tr['GarageYrBlt'].plot.box()) ","bf51a193":"sns.violinplot(df_tr['GarageYrBlt'])","5d6ff790":"### replace null with mean as there are many outliers\ndf_tr['GarageYrBlt'].fillna(value=df_tr['GarageYrBlt'].mean(),inplace=True)\ndf_ts['GarageYrBlt'].fillna(value=df_ts['GarageYrBlt'].mean(),inplace=True)","71fc5aef":"df_tr['MasVnrArea'].describe()","7c42964c":"(df_tr['MasVnrArea'].plot.box()) ","910d7c04":"### replace null with median as there are many outliers\ndf_tr['MasVnrArea'].fillna(value=df_tr['MasVnrArea'].median(),inplace=True)\ndf_ts['MasVnrArea'].fillna(value=df_ts['MasVnrArea'].median(),inplace=True)","4b1a754e":"#sns.heatmap(df_tr.isnull())\ndf_tr.isnull().sum()","0901ae54":"df_tr.columns","d86c7264":"### Creating some Featrues \nboth_col = [df_tr, df_ts]\nfor col in both_col:\n    col['YrBltAndRemod'] = col['YearBuilt'] + col['YearRemodAdd']\n    col['TotalSF'] = col['TotalBsmtSF'] + col['1stFlrSF'] + col['2ndFlrSF']\n    col['Total_sqr_footage'] = (col['BsmtFinSF1'] + col['BsmtFinSF2'] +\n                                 col['1stFlrSF'] + col['2ndFlrSF'])\n\n    col['Total_Bathrooms'] = (col['FullBath'] + (0.5 * col['HalfBath']) +\n                               col['BsmtFullBath'] + (0.5 *col['BsmtHalfBath']))\n\n    col['Total_porch_sf'] = (col['OpenPorchSF'] + col['3SsnPorch'] +\n                              col['EnclosedPorch'] + col['ScreenPorch'] +\n                              col['WoodDeckSF'])","7d8bef1b":"## Binary some feature\nboth_col = [df_tr, df_ts]\nfor col in both_col:\n    col['haspool'] = col['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n    col['has2ndfloor'] = col['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n    col['hasgarage'] = col['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n    col['hasbsmt'] = col['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n    col['hasfireplace'] = col['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","169b7338":"plt.subplots(figsize=(30,30))\nsns.heatmap(df_tr.corr(),cmap=\"GnBu\",vmax=0.9, square=True)","8b840303":"### droping some columns\ndrop_col = ['Exterior2nd','GarageYrBlt','Condition2','RoofMatl','Electrical','HouseStyle','Exterior1st',\n            'Heating','GarageQual','Utilities','MSZoning','Functional','KitchenQual']\ndf_tr.drop(drop_col, axis = 1,inplace = True)\ndf_ts.drop(drop_col, axis = 1,inplace = True)","bf18bdcb":"df_tr","435f5cea":"df_ts","2e337fa7":"cols = df_tr.columns\nnum_cols = df_tr._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))","56617b94":"sns.heatmap(df_tr.isnull())","dd490516":"sns.heatmap(df_ts.isnull())","d74fd889":"df_ts[cat_cols]","6d36d65d":"df_tr[cat_cols]","a69be701":"### value counts in categorical data in train\nfor i in df_tr[cat_cols]:\n    print(i,\":\",len(df_tr[i].unique()))","95614f81":"### value counts in categorical data in test\nfor i in df_ts[cat_cols]:\n    print(i,\":\",len(df_ts[i].unique()))","9d3acb7d":"### LabelEncoding of categorical data","15171057":"from sklearn.preprocessing import LabelEncoder","6a2a8190":"dftr = df_tr[cat_cols].apply(LabelEncoder().fit_transform)","ab71e7ea":"dfts = df_ts[cat_cols].apply(LabelEncoder().fit_transform)","482004c9":"df_tr_final = df_tr[num_cols].join(dftr)","a688ba25":"num_cols = df_ts._get_numeric_data().columns\ndf_ts_final = df_ts[num_cols].join(dfts)","ab69011b":"df_tr_final","4500c31b":"df_ts_final","8d5c756e":"ids = df_ts['Id']\ndf_tr_final.drop('Id',axis=1,inplace=True)\ndf_ts_final.drop('Id',axis=1,inplace=True)","3bbc15c9":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nimport numpy as np\nimport statsmodels.api as sm","e1b852b5":"### SLR on all columns\nfor i in df_tr_final.columns:\n    X = df_tr_final[[i]]#.values.reshape(1,-1)\n    y = df_tr_final[['SalePrice']]#.values.reshape(1,-1)\n\n    X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=.7,random_state=101)\n    LR = LinearRegression()\n    LR.fit(X_train,y_train)\n    y_pred = LR.predict(X_test)\n    print(i,\"gives R2 score\",r2_score(y_pred,y_test))\n    print(i,'gives MSE is:',mean_squared_error(y_test, y_pred))\n    rms = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(i,'gives RMSE is:',rms)\n    print(\"------------------------------------------\")\n    #print('Coefficient is',LR.coef_[0][0])\n    #print('intercept is',LR.intercept_[0])","c772b97c":"X = df_tr_final.drop('SalePrice',axis=1)#.values.reshape(1,-1)\ny = df_tr_final['SalePrice']#.values.reshape(1,-1)\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=.7,random_state=101)","a0cb53f4":"### Using Rfe\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n#X_train1 = scaler.fit_transform(X_train)\n#y_train1 = scaler.fit_transform(y_train)\nrfe = RFE(LR, 10)\nrfe.fit(X_train,y_train)","2a32d7d9":"#rfe.support_","57bcb332":"X_train.columns[rfe.support_]","fd62e032":"cols = X_train.columns[rfe.support_]","6db5ee52":"LR.fit(X_train[cols],y_train)","5a031fa5":"y_pred = LR.predict(X_test[cols])\nprint(\"gives R2 score\",r2_score(y_pred,y_test))\nprint('gives MSE is:',mean_squared_error(y_test, y_pred))\nrms = np.sqrt(mean_squared_error(y_test, y_pred))\nprint('gives RMSE is:',rms)\nprint(\"-----------------------------\")","2317182b":"y_pred = LR.predict(df_ts_final[cols])","6f14a395":"#For creating Output CSV file\ndef makecsv(y_pred,subno): ### input file name in \"\"\n    subdf = pd.DataFrame()\n    subdf['Id'] = df_ts['Id']\n    subdf['SalePrice'] = y_pred\n    subdf.to_csv(subno, index=False)","5a9f92c4":"# makecsv(y_pred,\"rfesol.csv\")","9a55ad8a":" import scipy.stats as stats","fc49a1b3":"stats.ttest_1samp(a=df_tr['OverallQual'],popmean=df_tr['SalePrice'].mean())","d4af66ec":"model = sm.OLS(y, X)\nresults = model.fit()\nprint(results.summary())","31bbd062":"X = df_tr_final.drop('SalePrice',axis=1)#.values.reshape(1,-1)\ny = df_tr_final['SalePrice']#.values.reshape(1,-1)\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=.7,random_state=101)","7f19b8ac":"### For using rfe selected features\n#X_train = X_train[cols]\n#X_test = X_test[cols]","32033650":"LR.fit(X_train,y_train)","ef1065c2":"### Multiple Linear regression fo all\ny_pred = LR.predict(X_test)\nprint(\"Multiple Linear regression gives R2 score\",r2_score(y_pred,y_test))\nprint('Multiple Linear regression gives MSE is:',mean_squared_error(y_test, y_pred))\nrms = np.sqrt(mean_squared_error(y_test, y_pred))\nprint('Multiple Linear regression gives RMSE is:',rms)\nprint(\"-------------------------------------------\")","8508af0a":"## Testing on Test Dataset\ny_pred = LR.predict(df_ts_final)","ee3b1c38":"#makecsv(y_pred,\"MLsol.csv\")","3ce6b250":"from sklearn.ensemble import RandomForestRegressor","c487b0ee":"rf = RandomForestRegressor(n_estimators = 300, random_state = 0)\nrf.fit(X_train,y_train)","676dc987":"y_pred = rf.predict(X_test)","f3a6784e":"print('all gives R2 score',r2_score(y_pred,y_test))\nprint('all gives MSE is:',mean_squared_error(y_test, y_pred))\nrms = np.sqrt(mean_squared_error(y_test, y_pred))\nprint('all gives RMSE is:',rms)\nprint(\"-----------------------------------------\")","6ba66703":"## Testing on Test Dataset\ny_pred = rf.predict(df_ts_final)","2cf8f260":"#makecsv(y_pred,\"Rfsol.csv\")","958ec3ec":"import xgboost as xgb","424eb111":"model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =42, nthread = -1)","ccc85071":"model_xgb.fit(X_train,y_train)","97b9d70c":"y_pred = model_xgb.predict(X_test)\nprint('XGB score:',model_xgb.score(X_train,y_train))\nprint('all gives R2 score',r2_score(y_pred,y_test))\nprint('all gives MSE is:',mean_squared_error(y_test, y_pred))\nrms = np.sqrt(mean_squared_error(y_test, y_pred))\nprint('all gives RMSE is:',rms)\nprint(\"-----------------------------------------\")","e6b6127a":"## Testing on Test Dataset\ny_pred = model_xgb.predict(df_ts_final)","101f8f79":"#makecsv(y_pred,\"xgbsol.csv\")","a92b0aea":"from sklearn import ensemble","80de58ed":"GBoost = ensemble.GradientBoostingRegressor(n_estimators = 3000, max_depth = 5,max_features='sqrt',\n                                            min_samples_split = 10,learning_rate = 0.005,loss = 'huber',\n                                            min_samples_leaf=15,random_state =10)\nGBoost.fit(X_train, y_train)","2636b312":"y_pred = GBoost.predict(X_test)\nprint('GBosst score:',GBoost.score(X_train,y_train))\nprint('all gives R2 score',r2_score(y_pred,y_test))\nprint('all gives MSE is:',mean_squared_error(y_test, y_pred))\nrms = np.sqrt(mean_squared_error(y_test, y_pred))\nprint('all gives RMSE is:',rms)\nprint(\"-----------------------------------------\")","c1a128cc":"#Testing on Test Dataset\ny_pred = GBoost.predict(df_ts_final)","f6102926":"makecsv(y_pred,\"gbsol.csv\")","3465d873":"#### Make Csv for reult","86192bb3":"##### Make Csv for result","6c027092":"##### NO More NUll values","e25334da":"#### Data Analysis","dbe54517":"#### Make Csv for  result","6fff46a1":"## Multiple LInear Regression Algorithm","0f9ef53f":"## Model build","f0241f18":"#### The End","9f672275":"### RandomForest  Algorithm","45bd4507":"##### Make Csv for result","d0b9c8ce":"### Gradient Boosting Algorithm","7dad9781":"##### Make Csv for result","828a5683":"### Multiple LInear Regression Using RFE","0d5c03ef":"# Predict the Housing Price\n##### By Chintan Chitroda","c8d0a436":"##### Data Cleaning","233a8354":"#### Single Linear Regression On all feat","d0bc4440":"### Models Using all Features","d24f47d6":"#### Input features 'n' u want to train model with","a0249e44":"### XGB Regressor Algorithm"}}