{"cell_type":{"9bdbd372":"code","c88b324d":"code","8f750573":"code","efb7f166":"code","228d7b6f":"code","328d0c65":"code","c9471d0b":"code","8632863a":"code","555493b9":"code","45aae709":"code","5bb4f459":"code","39b785cc":"code","4dc109dc":"code","4f1b1f61":"code","01c4806b":"code","46b20ce4":"code","9d41ace0":"code","7926194f":"code","366c9687":"code","c5ddefb5":"code","be1b11b2":"code","79137742":"code","92adcd4e":"code","3b16b105":"code","52bf7c8c":"code","f5ec7f35":"code","16340539":"code","bbd6929a":"code","0da21bfa":"code","b5039957":"code","a806bba7":"code","c6e599c7":"code","34d53955":"code","56343e8a":"code","daa8d77c":"code","7361a8bc":"code","5f9a91f5":"code","cdd42c0a":"code","7ac47816":"code","17e8be47":"code","7ad8fb54":"code","3f865369":"code","101e06e8":"code","87025bf4":"code","38d698e4":"code","91f786f3":"code","18e85c75":"code","e5f1351d":"code","963d7ed1":"code","ffa4853d":"code","cc1430aa":"code","39a68d33":"code","c88ce97f":"code","3acaebe8":"code","db33212d":"code","6dde0412":"code","3ec47913":"code","4a04766b":"code","1858fb23":"code","d7703c6a":"code","b5520486":"code","88f8d370":"code","b1d20a5c":"code","1367e4ba":"code","a2588fc8":"code","7b1254d4":"code","daa81eea":"code","0cbb3348":"code","63deffe9":"code","09a1216c":"code","ad68a21c":"code","1ccdc8ef":"code","8499c35a":"code","145e1e8c":"code","0b9ed6d4":"code","7906cdd4":"code","c0a7eb43":"code","a422b059":"code","e0c3c732":"code","b03ec21d":"code","f54dd942":"code","b6ad8344":"code","8b135ead":"code","69e4f49e":"code","8b6e0970":"code","4a34c65c":"code","321c2370":"code","aff5656f":"code","eb43df54":"code","6f977adc":"code","894ccf82":"code","e1b38a2a":"code","6b159b2e":"code","b926d166":"code","b2175670":"code","5ef5ae7d":"code","d3f121fd":"code","81e5d20f":"code","67720a6d":"code","a407a693":"code","01246d61":"code","bd08f3a3":"code","4c2d2203":"code","132120d3":"code","d669fcdc":"code","9185638c":"code","a443c5ec":"code","a0b43a45":"code","2abf498e":"code","d7bc0e6c":"code","58592819":"code","586a2ed1":"code","265593d3":"code","bdcdbebb":"code","6da95797":"code","cabbd2ac":"code","623fe004":"code","663a97e0":"code","942a67d6":"code","0bd7c502":"code","b8c79ebf":"markdown","ca64d948":"markdown","11a0bc1e":"markdown","43102455":"markdown","48aeb65a":"markdown","297a84fa":"markdown","2c92011e":"markdown","b7e26444":"markdown","63570c26":"markdown","04d3cc0d":"markdown","680f8c95":"markdown","b314f75a":"markdown","dc619994":"markdown","52e58e8e":"markdown","1d3e3874":"markdown","26b022f3":"markdown","fefb03d4":"markdown","64678595":"markdown","785e8635":"markdown","deb9b99e":"markdown","5f503c83":"markdown","76d91fe3":"markdown","cb51e733":"markdown","8e306b4e":"markdown","65911ecb":"markdown","0b4aa0b9":"markdown","b9e620d5":"markdown","7336f4f9":"markdown","7e05510e":"markdown","788ad1b4":"markdown","69188248":"markdown","0809f53d":"markdown","26c324f7":"markdown","d79d5410":"markdown","b7a5fd13":"markdown","dd203b68":"markdown","42e1b447":"markdown","95340e73":"markdown","f8d3d3bd":"markdown","e1098569":"markdown","c7f7d456":"markdown","2489785a":"markdown","915cbab2":"markdown","90ef6c91":"markdown","9af8df19":"markdown","0d7239fb":"markdown","b6973064":"markdown","64d6e081":"markdown","5df8cb7a":"markdown","c4239a95":"markdown","799cd5c5":"markdown","2729e9b4":"markdown","f77a3fb0":"markdown","f3fd7eea":"markdown","daeb0173":"markdown"},"source":{"9bdbd372":"import pandas as pd # \u0111\u1ecdc v\u00e0 x\u1eed l\u00fd d\u1eef li\u00eau, vd: pd.read_csv\nimport numpy as np #\u0111\u1ea1i s\u1ed1 tuy\u1ebfn t\u00ednh, t\u0103ng kh\u1ea3 n\u0103ng t\u00ednh to\u00e1n\n\n# m\u1ed9t s\u1ed1 th\u01b0 vi\u1ec7n cho m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y\nimport sklearn\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report, recall_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n#m\u1ed9t s\u1ed1 th\u01b0 vi\u1ec7n m\u00f4 ph\u1ecfng d\u1eef li\u1ec7u\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import *\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\nimport seaborn as sns\nfrom scipy.stats.mstats import winsorize\nimport re\nimport gc\nimport warnings\nwarnings.simplefilter(\"ignore\")\nplt.style.use('ggplot')\ncolor_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]","c88b324d":"train_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv')\ntrain_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv')\ntest_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv')","8f750573":"train_transaction.shape, test_transaction.shape, train_identity.shape,  test_identity.shape","efb7f166":"train_transaction.head() #hi\u1ec3n th\u1ecb 5 h\u00e0ng d\u1eef li\u1ec7u c\u1ee7a t\u1eadp train_transaction","228d7b6f":"test_transaction.head() #hi\u1ec3n th\u1ecb 5 h\u00e0ng d\u1eef li\u1ec7u c\u1ee7a t\u1eadp test_transaction","328d0c65":"train_identity.head() #hi\u1ec3n th\u1ecb 5 h\u00e0ng d\u1eef li\u1ec7u c\u1ee7a t\u1eadp train_identity","c9471d0b":"test_identity.head() #hi\u1ec3n th\u1ecb 5 h\u00e0ng d\u1eef li\u1ec7u c\u1ee7a t\u1eadp test_identity","8632863a":"train_transaction.info(), test_transaction.info() #l\u1ea5y c\u00e1c th\u00f4ng tin v\u1ec1 d\u1eef li\u1ec7u","555493b9":"train_transaction.isnull().sum()","45aae709":"train_identity.isnull().sum()","5bb4f459":"test_transaction.isnull().sum()","39b785cc":"test_identity.isnull().sum()","4dc109dc":"# T\u1ea1i \u0111\u00e2y ta s\u1ebd x\u00e1c nh\u1eadn t\u1ea5t c\u1ea3 c\u00e1c transaction trong `train_identity`\nprint(np.sum(train_transaction['TransactionID'].isin(train_identity['TransactionID'].unique())))\nprint(np.sum(test_transaction['TransactionID'].isin(test_identity['TransactionID'].unique())))","4f1b1f61":"# Initializing Pie Chart for visualizing the above data\n\nlabels = '1-Fraud', '0-Not Fraud'\nsizes = [len(train_transaction[train_transaction['isFraud'] == 1]), len(train_transaction[train_transaction['isFraud'] == 0])]\ncolors = ['red', 'green']\nexplode = (0.3, 0)  # explode 1st slice\n\n# Plot\nplt.pie(sizes, explode=explode, colors=colors, autopct='%1.2f%%', shadow=False, startangle=0)\nplt.legend(labels, loc=\"best\")\nplt.axis('equal')\nplt.show()","01c4806b":"train_transaction['TransactionDT'].plot(kind='hist',\n                                        figsize=(15, 5),\n                                        label='train',\n                                        bins=50,\n                                        title='Train vs Test TransactionDT distribution')\ntest_transaction['TransactionDT'].plot(kind='hist',\n                                       label='test',\n                                       bins=50)\nplt.legend()\nplt.show()","46b20ce4":"ax = train_transaction.plot(x='TransactionDT',\n                       y='TransactionAmt',\n                       kind='scatter',\n                       alpha=0.01,\n                       label='TransactionAmt-train',\n                       title='Train and test Transaction Ammounts by Time (TransactionDT)',\n                       ylim=(0, 5000),\n                       figsize=(15, 5))\ntest_transaction.plot(x='TransactionDT',\n                      y='TransactionAmt',\n                      kind='scatter',\n                      label='TransactionAmt-test',\n                      alpha=0.01,\n                      color=color_pal[1],\n                       ylim=(0, 5000),\n                      ax=ax)\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    .plot(x='TransactionDT',\n         y='TransactionAmt',\n         kind='scatter',\n         alpha=0.01,\n         label='TransactionAmt-train',\n         title='Train and test Transaction Ammounts by Time (TransactionDT)',\n         ylim=(0, 5000),\n         color='orange',\n         figsize=(15, 5),\n         ax=ax)\nplt.show()","9d41ace0":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    ['TransactionAmt'].apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='Log Transaction Amt - Fraud',\n          color=color_pal[1],\n          xlim=(-3, 10),\n         ax= ax1)\ntrain_transaction.loc[train_transaction['isFraud'] == 0] \\\n    ['TransactionAmt'].apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='Log Transaction Amt - Not Fraud',\n          color=color_pal[2],\n          xlim=(-3, 10),\n         ax=ax2)\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    ['TransactionAmt'] \\\n    .plot(kind='hist',\n          bins=100,\n          title='Transaction Amt - Fraud',\n          color=color_pal[1],\n         ax= ax3)\ntrain_transaction.loc[train_transaction['isFraud'] == 0] \\\n    ['TransactionAmt'] \\\n    .plot(kind='hist',\n          bins=100,\n          title='Transaction Amt - Not Fraud',\n          color=color_pal[2],\n         ax=ax4)\nplt.show()","7926194f":"# theo s\u1ed1 l\u01b0\u1ee3ng\ntrain_transaction.groupby('ProductCD') \\\n    ['TransactionID'].count() \\\n    .sort_index() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n         title='Count of Observations by ProductCD')\nplt.show()","366c9687":"#theo ph\u1ea7n tr\u0103m l\u00e0 gian l\u1eadn\ntrain_transaction.groupby('ProductCD')['isFraud'] \\\n    .mean() \\\n    .sort_index() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n         title='Percentage of Fraud by ProductCD')\nplt.show()","c5ddefb5":"figure(figsize=(15, 10))\n\nsns.barplot(y=train_transaction.isnull().sum().sort_values(ascending=False)\/len(train_transaction),\n            x=train_transaction.isnull().sum().sort_values(ascending=False).index,\n            palette = \"Spectral\")\ntitle(\"Percentage of Missing Values\", size=10)","be1b11b2":"columns_def = pd.DataFrame({\"NA_count\":train_transaction.isnull().sum().sort_values(ascending=False)})\ncolumns_def[\"Per\"]=columns_def[\"NA_count\"]\/len(train_transaction)","79137742":"columns_def.head(50)","92adcd4e":"columns_def.tail(50)","3b16b105":"# Gi\u1ea3m b\u1ed9 nh\u1edb\ndef reduce_mem_usage(df, verbose=True):\n    #c\u00e1c lo\u1ea1i dtype\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: \n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","52bf7c8c":"#k\u1ebft h\u1ee3p c\u00e1c t\u1eadp d\u1eef li\u1ec7u train v\u00e0 test\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n\ndel train_identity, train_transaction, test_identity, test_transaction\ngc.collect();","f5ec7f35":"#hi\u1ec3n th\u1ecb s\u1ed1 l\u01b0\u1ee3ng d\u1eef li\u1ec7u\nprint(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\nprint(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')","16340539":"# gi\u1ea3i quy\u1ebft vi\u1ec7c \u0111\u1eb7t t\u00ean kh\u00f4ng nh\u1ea5t qu\u00e1n \u1edf c\u00e1c c\u1ed9t id\ntest.rename(columns=lambda x: x.replace(\"id-\",\"id_\") if \"id-\" in x else x, inplace=True)","bbd6929a":"train = train.drop('TransactionID', axis=1)\ntest = test.drop('TransactionID', axis=1)","0da21bfa":"#gi\u1ea3m b\u1ed9 nh\u1edb c\u1ee7a d\u1eef li\u1ec7u\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\ngc.collect()","b5039957":"#b\u1ecf c\u00e1c c\u1ed9t c\u00f3 gi\u00e1 tr\u1ecb null l\u1edbn h\u01a1n 90%\none_value_cols, many_null_cols, big_top_value_cols =[],[],[] \n\nfor df in [train, test]:\n  one_value_cols += [col for col in df.columns if df[col].nunique() == 1]\n  many_null_cols += [col for col in df.columns if df[col].isnull().sum() \/ df.shape[0] > 0.9]\n  big_top_value_cols += [col for col in df.columns if df[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n\ncols_to_drop = list(set(one_value_cols + many_null_cols + big_top_value_cols))\n\nif 'isFraud' in cols_to_drop: \n  cols_to_drop.remove('isFraud')\n\ntrain = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)\n\nprint(f'{len(cols_to_drop)} features are going to be dropped for being useless')","a806bba7":"#chon ngay dau tien la ngay 30 thang 11 nam 2017\nimport datetime #su dung thu vien datatime de tinh toan cac dac trung thoi gian\nSTART_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')","c6e599c7":"from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\ndates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\nus_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())","34d53955":"for k, df in enumerate([train, test]):\n  df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n  df['DT_M'] = ((df['DT'].dt.year-2017-k)*12 + df['DT'].dt.month).astype(np.int8).apply(lambda x: x%12 if x>12 else x) #chuyen doi cac thang trong mot nam\n  df['DT_W'] = ((df['DT'].dt.year-2017-k)*52 + df['DT'].dt.weekofyear).astype(np.int8).apply(lambda x: x%52 if x>52 else x) #chuyen doi cac tuan trong mot nam\n  df['DT_D'] = ((df['DT'].dt.year-2017-k)*365 + df['DT'].dt.dayofyear).astype(np.int16).apply(lambda x: x%365 if x>365 else x) #chuyen doi cac ngay trong mot nam\n  \n  df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n  df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n  df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n\n  # Holidays\n  df['DT_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)","56343e8a":"train = train.drop('DT',axis=1)\ntest = test.drop('DT',axis=1)","daa8d77c":"columns=[col for col in train.columns if re.search('^DT_.*', col)]\ncolumns.remove('DT_D')","7361a8bc":"#xu ly cac gia tri bi thieu id_30\nold_versions_id_30 = set(train['id_30'].unique()) - set(test['id_30'].unique())\nnew_versions_id_30 = set(test['id_30'].unique()) - set(train['id_30'].unique())\ntest['id_30'] =test['id_30'].apply(lambda x: np.nan if x in new_versions_id_30 else x)\ntrain['id_30'] =train['id_30'].apply(lambda x: np.nan if x in old_versions_id_30 else x)","5f9a91f5":"#xu ly cac gia tri bi thieu id_31\nold_versions_id_31 = set(train['id_31'].unique()) - set(test['id_31'].unique())\nnew_versions_id_31 = set(test['id_31'].unique()) - set(train['id_31'].unique())\ntest['id_31'] =test['id_31'].apply(lambda x: np.nan if x in new_versions_id_31 else x)\ntrain['id_31'] =train['id_31'].apply(lambda x: np.nan if x in old_versions_id_31 else x)","cdd42c0a":"#xu ly cac gia tri bi thieu id_33\nold_versions_id_33 = set(train['id_33'].unique()) - set(test['id_33'].unique())\nnew_versions_id_33 = set(test['id_33'].unique()) - set(train['id_33'].unique())\ntest['id_33'] =test['id_33'].apply(lambda x: np.nan if x in new_versions_id_33 else x)\ntrain['id_33'] =train['id_33'].apply(lambda x: np.nan if x in old_versions_id_33 else x)","7ac47816":"train = train.drop('id_29', axis=1)\ntest = test.drop('id_29', axis=1)\ncolumns=[col for col in train.columns if re.search('^V\\d*', col)]\nlen(columns)","17e8be47":"# x\u00f3a c\u00e1c \u0111\u1eb7c tr\u01b0ng c\u00f3 t\u00ednh t\u01b0\u01a1ng \u0111\u1ed3ng cao kh\u1ecfi d\u1eef li\u1ec7u\ndef remove_collinear_features(x, threshold):\n    '''\n    Inputs: \n        x: features dataframe\n        threshold: features with correlations greater than this value are removed\n\n    Output: \n        dataframe that contains only the non-highly-collinear features\n    '''\n\n    # T\u00ednh to\u00e1n ma tr\u1eadn t\u01b0\u01a1ng quan\n    corr_matrix = x.corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n\n    # L\u1eb7p l\u1ea1i th\u00f4ng qua ma tr\u1eadn t\u01b0\u01a1ng quan v\u00e0 so s\u00e1nh c\u00e1c m\u1ed1i t\u01b0\u01a1ng quan\n    for i in iters:\n        for j in range(i+1):\n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n\n            # N\u1ebfu s\u1ef1 t\u01b0\u01a1ng quan v\u01b0\u1ee3t qu\u00e1 ng\u01b0\u1ee1ng\n            if val >= threshold:\n                # Th\u00eam c\u00e1c \u0111\u1eb7c tr\u01b0ng t\u01b0\u01a1ng \u0111\u1ed3ng v\u00e0o m\u1ea3ng drop_cols\n                drop_cols.append(col.values[0])\n\n    # x\u00f3a m\u1ed9t trong m\u1ed7i c\u1eb7p c\u1ed9t t\u01b0\u01a1ng quan\n    drops = set(drop_cols)\n    x = x.drop(columns=drops)\n\n    return drops","7ad8fb54":"corr_treshold = 0.75\ndrop_col = remove_collinear_features(train[columns],corr_treshold)\nlen(drop_col)","3f865369":"#x\u00f3a c\u1ed9t c\u00f3 t\u00ednh t\u01b0\u01a1ng \u0111\u1ed3ng cao\ntrain = train.drop(drop_col, axis=1)\ntest = test.drop(drop_col, axis=1)","101e06e8":"columns=[col for col in train.columns if re.search('^V\\d*', col)]\nlen(columns)","87025bf4":"#x\u1eed l\u00fd c\u00e1c gi\u00e1 tr\u1ecb thi\u1ebfu trong DeviceInfo\nold_versions_DeviceInfo = set(train['DeviceInfo'].unique()) - set(test['DeviceInfo'].unique())\nnew_versions_DeviceInfo= set(test['DeviceInfo'].unique()) - set(train['DeviceInfo'].unique())\ntest['DeviceInfo'] =test['DeviceInfo'].apply(lambda x: np.nan if x in new_versions_DeviceInfo else x)\ntrain['DeviceInfo'] =train['DeviceInfo'].apply(lambda x: np.nan if x in old_versions_DeviceInfo else x)","38d698e4":"for df in [train, test]:\n  df['R_emaildomain_1'] = df['R_emaildomain'].fillna('').apply(lambda x: x.split(\".\")[0]).replace({'':np.nan})\n  df['R_emaildomain_2'] = df['R_emaildomain'].str.split('.', expand=True).iloc[:,1:].fillna('').apply(lambda x:('.'.join(x)).strip('.'), axis=1).replace({'':np.nan})","91f786f3":"for df in [train, test]:\n  df['P_emaildomain_1'] = df['P_emaildomain'].fillna('').apply(lambda x: x.split(\".\")[0]).replace({'':np.nan})\n  df['P_emaildomain_2'] = df['P_emaildomain'].str.split('.', expand=True).iloc[:,1:].fillna('').apply(lambda x:('.'.join(x)).strip('.'), axis=1).replace({'':np.nan})","18e85c75":"train = train.drop(['R_emaildomain','P_emaildomain','P_emaildomain_2'], axis=1)\ntest = test.drop(['R_emaildomain','P_emaildomain','P_emaildomain_2'], axis=1)","e5f1351d":"for df in [train, test]:\n  df['addr'] = (df['addr2'].astype(str)+'_'+df['addr1'].astype(str)).replace({'nan_nan':np.nan})","963d7ed1":"train['addr1'].nunique(), train['addr2'].nunique(), train['addr'].nunique()\ntest['addr1'].nunique(), test['addr2'].nunique(), test['addr'].nunique()","ffa4853d":"old_versions_card1 = set(train['card1'].unique()) - set(test['card1'].unique())\nnew_versions_card1 = set(test['card1'].unique()) - set(train['card1'].unique())\ntest['card1'] =test['card1'].apply(lambda x: np.nan if x in new_versions_card1 else x)\ntrain['card1'] =train['card1'].apply(lambda x: np.nan if x in old_versions_card1 else x)","cc1430aa":"#hi\u1ec3n th\u1ecb s\u1ed1 l\u01b0\u1ee3ng t\u1ea7n s\u1ed1 th\u1ebb\nrareCards=[]\nfor k, df in enumerate([train, test]):\n  rare_cards = df.card1.value_counts()\n  rare_cards = rare_cards.where(rare_cards<3).dropna().sort_index().index\n  rareCards += list(rare_cards)\n\n  print(f\"{('TEST' if k else 'TRAIN')}\")\n  print(f\"Number of unique in card1: {df.card1.nunique()}\")\n  print(f\"Number of unique values with frequency less than 3 in card1: {len(rare_cards)}\\n\")\nrareCards = set(rareCards)","39a68d33":"for df in [train, test]:\n  df['card1'] = df['card1'].apply(lambda x: np.nan if x in rareCards else x)","c88ce97f":"for col in ['card2','card3','card4','card5','card6']: \n  old_versions_col= set(train[col].unique()) - set(test[col].unique())\n  new_versions_col = set(test[col].unique()) - set(train[col].unique()) \n  test[col] =test[col].apply(lambda x: np.nan if x in new_versions_col else x)\n  train[col] =train[col].apply(lambda x: np.nan if x in old_versions_col else x)","3acaebe8":"columns=[col for col in train.columns if re.search('^D\\d.*', col)]+['DT_hour']\n\ncorr_treshold = 0.75\ndrop_col = remove_collinear_features(train[columns],corr_treshold)\ndrop_col","db33212d":"drop_col={'D12', \"D11\", 'D2', 'D6', 'D9'}\nfor df in [train, test]:\n  df = df.drop(drop_col, axis=1)","6dde0412":"train.shape, test.shape","3ec47913":"columns=[col for col in train.columns if re.search('^C\\d.*', col)]\ncorr_treshold = 0.9\ndrop_col = remove_collinear_features(train[columns],corr_treshold)\ndrop_col","4a04766b":"train = train.drop(drop_col, axis=1)\ntest = test.drop(drop_col, axis=1)","1858fb23":"train = train.drop('dist1', axis=1)\ntest = test.drop('dist1', axis=1)","d7703c6a":"temp_dict = train.groupby(['M4'])['isFraud'].agg(['mean']).to_dict()['mean']\ntrain['M4_target_mean'] = train['M4'].replace(temp_dict)\ntest['M4_target_mean']  = test['M4'].replace(temp_dict)","b5520486":"temp_dict = train.groupby(['ProductCD'])['isFraud'].agg(['mean']).to_dict()['mean']\ntrain['ProductCD_target_mean'] = train['ProductCD'].replace(temp_dict)\ntest['ProductCD_target_mean']  = test['ProductCD'].replace(temp_dict)","88f8d370":"train.shape, test.shape","b1d20a5c":"def frequency_encoding(train, test, columns, self_encoding=False):\n    for col in columns:\n        df = pd.concat([train[[col]], test[[col]]])\n        fq_encode = df[col].value_counts(dropna=False, normalize=True).to_dict()\n        if self_encoding:\n            train[col] = train[col].map(fq_encode)\n            test[col]  = test[col].map(fq_encode)            \n        else:\n            train[col+'_freq'] = train[col].map(fq_encode)\n            test[col+'_freq']  = test[col].map(fq_encode)\n    return train, test","1367e4ba":"self_encode_True= ['ProductCD', 'DeviceInfo', 'DeviceType', 'addr'] + \\\n                  ['R_emaildomain_1', 'R_emaildomain_2','P_emaildomain_1'] + \\\n                  ['id_12','id_15','id_16','id_28','id_30','id_31','id_33',\"id_34\",'id_35', 'id_36', 'id_37', 'id_38'] + \\\n                  ['M1','M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']+ \\\n                  ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'] + \\\n                  [ 'card4', 'card6']\n\nself_encode_False=['card1', 'card2', 'card3', 'card5']+ \\\n                  ['C1', 'C5', 'C13']","a2588fc8":"train, test = frequency_encoding(train, test, self_encode_True, self_encoding=True)\ntrain, test = frequency_encoding(train, test, self_encode_False, self_encoding=False)","7b1254d4":"V_columns = [col for col in train.columns if re.search('^V\\d*', col)]\ntrain[V_columns] = train[V_columns].fillna(-1)\ntest[V_columns] = test[V_columns].fillna(-1)\n\nsc_V = MinMaxScaler()\nsc_V.fit(train[V_columns])\ntrain[V_columns] = sc_V.transform(train[V_columns])\ntest[V_columns] = sc_V.transform(test[V_columns])","daa81eea":"pca = PCA(n_components = 3)\npca.fit(train[V_columns])\npca_V_train = pca.transform(train[V_columns])\npca_V_test = pca.transform(test[V_columns])\n\nnp.cumsum(pca.explained_variance_ratio_)","0cbb3348":"pca_V_train = pd.DataFrame(data = pca_V_train).add_prefix('pca_V')\ntrain = pd.concat([train, pca_V_train], ignore_index=False, sort=False, axis=1)\ntrain.drop(V_columns, axis=1, inplace=True)\n\npca_V_test = pd.DataFrame(data = pca_V_test).add_prefix('pca_V')\ntest = pd.concat([test, pca_V_test], ignore_index=False, sort=False, axis=1)\ntest.drop(V_columns, axis=1, inplace=True)","63deffe9":"del pca_V_train, pca_V_test","09a1216c":"train = train.drop('TransactionDT',axis=1)\ntest = test.drop('TransactionDT',axis=1)","ad68a21c":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\n\ngc.collect()","1ccdc8ef":"#l\u01b0u d\u1eef li\u1ec7u\ntrain.to_pickle('.\/train_1.pkl') \ntest.to_pickle('.\/test_1.pkl')","8499c35a":"#\u0111\u1ecdc d\u1eef li\u1ec7u\n# train= pd.read_pickle('.\/train_1.pkl') \n# test= pd.read_pickle('.\/test_1.pkl')","145e1e8c":"train.head()","0b9ed6d4":"#b\u1ecf c\u00e1c c\u1ed9t ch\u1ee9a gi\u00e1 tr\u1ecb NA\ncols_with_missing = [col for col in train.columns \n                                 if train[col].isnull().any()]\ntrain1 = train.drop(cols_with_missing, axis=1)","7906cdd4":"X = train1.drop(['isFraud'], axis=1) #tap du lieu\ny = train1['isFraud'] #tap nhan\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, stratify=y, random_state =42) #phan chia du lieu","c0a7eb43":"lgr = LogisticRegression(solver='saga', max_iter=20, n_jobs=-1, verbose=1)","a422b059":"lgr.fit(X_train1, y_train1)","e0c3c732":"y_pred = lgr.predict(X_test1)\nprint(classification_report(y_test1, y_pred, zero_division=0))","b03ec21d":"y_train_pred = lgr.predict(X_train1)\nprint(classification_report(y_train1, y_train_pred, zero_division=0))","f54dd942":"print('Test ROC AUC score:', roc_auc_score(y_test1, lgr.predict_proba(X_test1)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train1, lgr.predict_proba(X_train1)[:, 1]))","b6ad8344":"cols_with_missing = [col for col in train.columns \n                                 if train[col].isnull().any()]\ntrain1 = train.drop(cols_with_missing, axis=1)","8b135ead":"X = train1.drop(['isFraud'], axis=1)\ny = train1['isFraud']\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, stratify=y, random_state =42)","69e4f49e":"knn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train1, y_train1)","8b6e0970":"y_pred = knn.predict(X_test1)\nprint(classification_report(y_test1, y_pred, zero_division=0))","4a34c65c":"y_train_pred = knn.predict(X_train1)\nprint(classification_report(y_train1, y_train_pred, zero_division=0))","321c2370":"print('Test ROC AUC score:', roc_auc_score(y_test1, knn.predict_proba(X_test1)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train1, knn.predict_proba(X_train1)[:, 1]))","aff5656f":"#thay th\u1ebf gi\u00e1 tr\u1ecb NA b\u1eb1ng 0\n# train2 = train\n# train2 = train2.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)","eb43df54":"cols_with_missing = [col for col in train.columns \n                                 if train[col].isnull().any()]\ntrain1 = train.drop(cols_with_missing, axis=1)","6f977adc":"X = train1.drop(['isFraud'], axis=1)\ny = train1['isFraud']\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, stratify=y, random_state =42)","894ccf82":"dct = DecisionTreeClassifier(max_depth =10,random_state=10)\ndct.fit(X_train1, y_train1)","e1b38a2a":"y_pred = dct.predict(X_test1)\nprint(classification_report(y_test1, y_pred, zero_division=0))","6b159b2e":"y_train_pred = dct.predict(X_train1)\nprint(classification_report(y_train1, y_train_pred, zero_division=0))","b926d166":"print('Test ROC AUC score:', roc_auc_score(y_test1, dct.predict_proba(X_test1)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train1, dct.predict_proba(X_train1)[:, 1]))","b2175670":"# train2 = train\n# train2 = train2.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)","5ef5ae7d":"cols_with_missing = [col for col in train.columns \n                                 if train[col].isnull().any()]\ntrain1 = train.drop(cols_with_missing, axis=1)","d3f121fd":"X = train1.drop(['isFraud'], axis=1)\ny = train1['isFraud']\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, stratify=y, random_state =42)","81e5d20f":"rdf = RandomForestClassifier(n_estimators = 10) \nrdf.fit(X_train1, y_train1)","67720a6d":"y_pred = rdf.predict(X_test1)\nprint(classification_report(y_test1, y_pred, zero_division=0))","a407a693":"y_train_pred = rdf.predict(X_train1)\nprint(classification_report(y_train1, y_train_pred, zero_division=0))","01246d61":"print('Test ROC AUC score:', roc_auc_score(y_test1, rdf.predict_proba(X_test1)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train1, rdf.predict_proba(X_train1)[:, 1]))","bd08f3a3":"X = train.drop(['isFraud'], axis=1)\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state =42)","4c2d2203":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","132120d3":"lgb = LGBMClassifier(\n          max_bin = 63,\n          num_leaves = 255,\n          num_iterations = 500,\n          learning_rate = 0.01,\n          tree_learner = 'serial',\n          is_dfing_metric = False,\n          min_data_in_leaf = 1,\n          min_sum_hessian_in_leaf = 100,\n          sparse_threshold=1.0,\n          # device = 'gpu',\n          num_thread = -1,\n          save_binary= True,\n          seed= 42,\n          feature_fraction_seed = 42,\n          bagging_seed = 42,\n          drop_seed = 42,\n          data_random_seed = 42,\n          objective = 'binary',\n          boosting_type = 'gbdt',\n          verbose = 1,\n          metric = 'auc',\n          is_unbalance = True,\n          boost_from_average = False,\n)","d669fcdc":"lgb.fit(X_train, y_train)","9185638c":"y_pred = lgb.predict(X_test)\nprint(classification_report(y_test, y_pred, zero_division=0))","a443c5ec":"y_train_pred = lgb.predict(X_train)\nprint(classification_report(y_train, y_train_pred, zero_division=0))","a0b43a45":"print('Test ROC AUC score:', roc_auc_score(y_test, lgb.predict_proba(X_test)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train, lgb.predict_proba(X_train)[:, 1]))","2abf498e":"X = train.drop(['isFraud'], axis=1)\ny = train['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state =42)","d7bc0e6c":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)","58592819":"y_pred = xgb.predict(X_test)\nprint(classification_report(y_test, y_pred, zero_division=0))","586a2ed1":"y_train_pred = xgb.predict(X_train)\nprint(classification_report(y_train, y_train_pred, zero_division=0))","265593d3":"print('Test ROC AUC score:', roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1]))\nprint('Train ROC AUC score:', roc_auc_score(y_train, xgb.predict_proba(X_train)[:, 1]))","bdcdbebb":"y_pred = lgr.predict(X_test1)\nlgr_recall = recall_score(y_test1, y_pred)\nlgr_f1_score = f1_score(y_test1, y_pred)\nlgr_AUC = roc_auc_score(y_test1, lgr.predict_proba(X_test1)[:, 1])\n\ny_pred = knn.predict(X_test1)\nknn_recall = recall_score(y_test1, y_pred)\nknn_f1_score = f1_score(y_test1, y_pred)\nknn_AUC = roc_auc_score(y_test1, knn.predict_proba(X_test1)[:, 1])\n\ny_pred = dct.predict(X_test1)\ndct_recall = recall_score(y_test1, y_pred)\ndct_f1_score = f1_score(y_test1, y_pred)\ndct_AUC = roc_auc_score(y_test1, dct.predict_proba(X_test1)[:, 1])\n\ny_pred = rdf.predict(X_test1)\nrdf_recall = recall_score(y_test1, y_pred)\nrdf_f1_score = f1_score(y_test1, y_pred)\nrdf_AUC = roc_auc_score(y_test1, rdf.predict_proba(X_test1)[:, 1])\n\ny_pred = lgb.predict(X_test)\nlgb_recall = recall_score(y_test, y_pred)\nlgb_f1_score = f1_score(y_test, y_pred)\nlgb_AUC = roc_auc_score(y_test, lgb.predict_proba(X_test)[:, 1])\n\ny_pred = xgb.predict(X_test)\nxgb_recall = recall_score(y_test, y_pred)\nxgb_f1_score = f1_score(y_test, y_pred)\nxgb_AUC = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1],average='micro')","6da95797":"df_eval=pd.DataFrame({ 'Model':[\"LogisticsRegression\",\"KNN\",\"DecisionTree\",\"RandomForest\",\"LightGBM\",'XGBOOST'],\n                        'Recall':[lgr_recall,knn_recall,dct_recall,rdf_recall,lgb_recall,xgb_recall],\n                        'F1':[lgr_f1_score,knn_f1_score,dct_f1_score,rdf_f1_score,lgb_f1_score,xgb_f1_score],\n                        'AUC':[lgr_AUC,knn_AUC,dct_AUC,rdf_AUC,lgb_AUC,xgb_AUC]})\ndf_eval","cabbd2ac":"from sklearn import metrics\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(0).clf()\n\ny_pred = lgr.predict_proba(X_test1)[:, 1]\nfpr, tpr, thresh = metrics.roc_curve(y_test1, y_pred)\nauc = metrics.roc_auc_score(y_test1, y_pred)\nauc = round(auc, 4)\nplt.plot(fpr,tpr,label=\"LogisticsRegression, AUC=\"+str(auc))\n\ny_pred = knn.predict_proba(X_test1)[:, 1]\nfpr, tpr, thresh = metrics.roc_curve(y_test1, y_pred)\nauc = metrics.roc_auc_score(y_test1, y_pred)\nauc = round(auc, 4)\nplt.plot(fpr,tpr,label=\"KNN, AUC=\"+str(auc))\n\ny_pred = dct.predict_proba(X_test1)[:, 1]\nfpr, tpr, thresh = metrics.roc_curve(y_test1, y_pred)\nauc = metrics.roc_auc_score(y_test1, y_pred)\nauc = round(auc, 4)\nplt.plot(fpr,tpr,label=\"DecisionTree, AUC=\"+str(auc))\n\ny_pred = rdf.predict_proba(X_test1)[:, 1]\nfpr, tpr, thresh = metrics.roc_curve(y_test1, y_pred)\nauc = metrics.roc_auc_score(y_test1, y_pred)\nauc = round(auc, 4)\nplt.plot(fpr,tpr,label=\"RandomForest, AUC=\"+str(auc))\n\ny_pred = lgb.predict_proba(X_test)[:, 1]\nfpr, tpr, thresh = metrics.roc_curve(y_test, y_pred)\nauc = metrics.roc_auc_score(y_test, y_pred)\nauc = round(auc, 4)\nplt.plot(fpr,tpr,label=\"LightGBM, AUC=\"+str(auc))\n\ny_pred = xgb.predict_proba(X_test)[:, 1]\nfpr, tpr, thresh = metrics.roc_curve(y_test, y_pred)\nauc = metrics.roc_auc_score(y_test, y_pred)\nauc = round(auc, 4)\nplt.plot(fpr,tpr,label=\"XGBOOST, AUC=\"+str(auc))\n\nplt.legend(loc=0)\nplt.title(\"AUC & ROC Curve\")","623fe004":"X = train.drop(['isFraud'], axis=1)\ny = train['isFraud']","663a97e0":"clf = LGBMClassifier(\n          max_bin = 63,\n          num_leaves = 255,\n          num_iterations = 500,\n          learning_rate = 0.01,\n          tree_learner = 'serial',\n          is_dfing_metric = False,\n          min_data_in_leaf = 1,\n          min_sum_hessian_in_leaf = 100,\n          sparse_threshold=1.0,\n          # device = 'gpu',\n          num_thread = -1,\n          save_binary= True,\n          seed= 42,\n          feature_fraction_seed = 42,\n          bagging_seed = 42,\n          drop_seed = 42,\n          data_random_seed = 42,\n          objective = 'binary',\n          boosting_type = 'gbdt',\n          verbose = 1,\n          metric = 'auc',\n          is_unbalance = True,\n          boost_from_average = False,\n)\nclf.fit(X, y)","942a67d6":"# test = pd.read_pickle('..\/input\/datatrain\/test_1.pkl') ","0bd7c502":"sub= pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv')\nsub['isFraud']=pd.DataFrame(clf.predict_proba(test))[[1]]\nsub.to_csv('.\/submission.csv',index=False)\nsub","b8c79ebf":"Nh\u1eadn x\u00e9t: C\u00e1c kho\u1ea3n ph\u00ed gian l\u1eadn c\u00f3 s\u1ed1 ti\u1ec1n giao d\u1ecbch trung b\u00ecnh cao h\u01a1n\n","ca64d948":"# **1. Logistics Regression**","11a0bc1e":"Nh\u1eadn x\u00e9t: T\u1eadp d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c gi\u1ea3m \u0111i \u0111\u00e1ng k\u1ec3, kho\u1ea3ng 50% b\u1ed9 nh\u1edb so v\u1edbi l\u00fac \u0111\u1ea7u","43102455":"# **4. Remove collinear features (x\u00f3a c\u00e1c \u0111\u1eb7c tr\u01b0ng c\u00f3 t\u00ednh t\u01b0\u01a1ng \u0111\u1ed3ng cao)**","48aeb65a":"# **2. Ngu\u1ed3n d\u1eef li\u1ec7u s\u1eed d\u1ee5ng**\nVesta Corporation \u0111\u00e3 cung c\u1ea5p b\u1ed9 d\u1eef li\u1ec7u cho cu\u1ed9c thi n\u00e0y. Vesta Corporation l\u00e0 c\u00f4ng ty ti\u00ean phong trong c\u00e1c gi\u1ea3i ph\u00e1p thanh to\u00e1n th\u01b0\u01a1ng m\u1ea1i \u0111i\u1ec7n t\u1eed \u0111\u1ea3m b\u1ea3o. \u0110\u01b0\u1ee3c th\u00e0nh l\u1eadp v\u00e0o n\u0103m 1995, Vesta ti\u00ean phong trong quy tr\u00ecnh giao d\u1ecbch thanh to\u00e1n b\u1eb1ng th\u1ebb kh\u00f4ng c\u00f3 m\u1eb7t (CNP) \u0111\u01b0\u1ee3c \u0111\u1ea3m b\u1ea3o ho\u00e0n to\u00e0n cho ng\u00e0nh vi\u1ec5n th\u00f4ng. K\u1ec3 t\u1eeb \u0111\u00f3, Vesta \u0111\u00e3 m\u1edf r\u1ed9ng m\u1ea1nh m\u1ebd kh\u1ea3 n\u0103ng khoa h\u1ecdc d\u1eef li\u1ec7u v\u00e0 m\u00e1y h\u1ecdc tr\u00ean to\u00e0n c\u1ea7u v\u00e0 c\u1ee7ng c\u1ed1 v\u1ecb tr\u00ed d\u1eabn \u0111\u1ea7u trong l\u0129nh v\u1ef1c thanh to\u00e1n th\u01b0\u01a1ng m\u1ea1i \u0111i\u1ec7n t\u1eed \u0111\u01b0\u1ee3c \u0111\u1ea3m b\u1ea3o. Ng\u00e0y nay, Vesta \u0111\u1ea3m b\u1ea3o h\u01a1n 18 t\u1ef7 \u0111\u00f4 la trong c\u00e1c giao d\u1ecbch h\u00e0ng n\u0103m.","297a84fa":"# **1. Gi\u1ea3m b\u1ed9 nh\u1edb**","2c92011e":"D\u1ef1a v\u00e0o \u0111\u1ed3 th\u1ecb v\u00e0 b\u1ea3ng so s\u00e1nh, m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c ch\u1ecdn l\u00e0 LightGBM","b7e26444":"Xem kh\u1ed1i l\u01b0\u1ee3ng d\u1eef li\u1ec7u, v\u1edbi m\u1ed7i t\u1ec7p ta s\u1ebd c\u00f3 t\u01b0\u01a1ng \u1ee9ng v\u1eddi s\u1ed1 h\u00e0ng v\u00e0 s\u1ed1 c\u1ed9t","63570c26":"Nh\u1eadn x\u00e9t: \n- H\u1ea7u h\u1ebft giao c\u00e1c giao d\u1ecbch l\u00e0 kh\u00f4ng gian l\u1eadn\n- Ch\u1ec9 kho\u1ea3ng 3.5% d\u1eef li\u1ec7u giao d\u1ecbch l\u00e0 gian l\u1eadn\n> N\u1ebfu s\u1eed d\u1ee5ng khung d\u1eef li\u1ec7u n\u00e0y l\u00e0m c\u01a1 s\u1edf cho c\u00e1c m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n v\u00e0 ph\u00e2n t\u00edch, r\u1ea5t c\u00f3 th\u1ec3 g\u1eb7p r\u1ea5t nhi\u1ec1u l\u1ed7i v\u00e0 c\u00e1c thu\u1eadt to\u00e1n c\u00f3 th\u1ec3 s\u1ebd b\u1ecb th\u1eeba v\u00ec n\u00f3 s\u1ebd \"gi\u1ea3 \u0111\u1ecbnh\" r\u1eb1ng h\u1ea7u h\u1ebft c\u00e1c giao d\u1ecbch kh\u00f4ng ph\u1ea3i l\u00e0 gian l\u1eadn. Nh\u01b0ng m\u1ee5c \u0111\u00edch c\u1ee7a m\u00f4 h\u00ecnh l\u00e0 ph\u00e1t hi\u1ec7n ra c\u00e1c m\u1eabu c\u00f3 d\u1ea5u hi\u1ec7u gian l\u1eadn. Do \u0111\u00f3, c\u1ea7n ch\u00fa \u00fd \u0111\u1ebfn v\u1ea5n \u0111\u1ec1 overfitting trong qu\u00e1 tr\u00ecnh ph\u00e2n t\u00edch.","04d3cc0d":"# **II. Ph\u00e2n t\u00edch d\u1eef li\u1ec7u**","680f8c95":"# **6. PCA for V Columns**","b314f75a":"Nh\u1eadn x\u00e9t:\n- ProductCD c\u1ee7a W c\u00f3 s\u1ed1 l\u01b0\u1ee3ng nhi\u1ec1u nh\u1ea5t\n- ProductCD c\u1ee7a S c\u00f3 s\u1ed1 l\u01b0\u1ee3ng \u00edt nh\u1ea5t\n","dc619994":"# **4. Random Forest**","52e58e8e":"# **Ph\u00e2n ph\u1ed1i s\u1ed1 l\u01b0\u1ee3ng ph\u00ed giao d\u1ecbch (TransactionAmt)**","1d3e3874":"# **III. X\u1eed l\u00fd d\u1eef li\u1ec7u**","26b022f3":"Nh\u1eadn x\u00e9t:\n- ProductCD c\u1ee7a C c\u00f3 nhi\u1ec1u gian l\u1eadn nh\u1ea5t v\u1edbi kho\u1ea3ng 12%\n- ProductCD c\u1ee7a W c\u00f3 \u00edt gian l\u1eadn nh\u1ea5t v\u1edbi kho\u1ea3ng 2%","fefb03d4":"Th\u00eam c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft","64678595":"# **VI. T\u1ed5ng k\u1ebft**","785e8635":"**DeviceInfo**","deb9b99e":"One hot encoding kh\u00f4ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 lo\u1ea1i b\u1ecf s\u1ef1 ph\u1ee9c t\u1ea1p v\u1ec1 t\u00ednh \u0111a chi\u1ec1u. M\u1eb7c d\u00f9 label encoding l\u00e0 m\u1ed9t gi\u1ea3i ph\u00e1p t\u1ed1t cho d\u1eef li\u1ec7u ph\u00e2n lo\u1ea1i th\u1ee9 t\u1ef1, nh\u01b0ng n\u00f3 kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t gi\u1ea3i ph\u00e1p ph\u00f9 h\u1ee3p cho d\u1eef li\u1ec7u ph\u00e2n lo\u1ea1i danh ngh\u0129a. C\u00f3 th\u1ec3 n\u00f3i m\u00e3 h\u00f3a t\u1ea7n s\u1ed1 l\u00e0 gi\u1ea3i ph\u00e1p t\u1ed1t nh\u1ea5t cho d\u1eef li\u1ec7u n\u00e0y.","5f503c83":"**DeviceType**","76d91fe3":"# **5. M\u00e3 h\u00f3a t\u1ea7n s\u1ed1 (Frequency Encoding)**","cb51e733":"# **5. LightGBM**","8e306b4e":"V\u00ec h\u1ea7u h\u1ebft t\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb c\u1ee7a 'TransactionID' l\u00e0 duy nh\u1ea5t, n\u00ean n\u00f3 s\u1ebd b\u1ecb lo\u1ea1i b\u1ecf.","65911ecb":"D\u1eef li\u1ec7u test v\u00e0 d\u1eef li\u1ec7u train c\u00f3 393 c\u1ed9t kh\u00f4ng bao g\u1ed3m d\u1eef li\u1ec7u isFraud. D\u1ef1a tr\u00ean TransactionDT, d\u1eef li\u1ec7u test \u0111\u01b0\u1ee3c gi\u1ea3 \u0111\u1ecbnh l\u00e0 \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o sau d\u1eef li\u1ec7u train.","0b4aa0b9":"# **1. Gi\u1edbi thi\u1ec7u b\u00e0i to\u00e1n**\nB\u1ea1n \u0111ang \u0111\u1ee9ng trong m\u1ed9t qu\u1ea7y thanh to\u00e1n v\u00e0 nh\u00e2n vi\u00ean thu ng\u00e2n n\u00f3i v\u1edbi b\u1ea1n r\u1eb1ng th\u1ebb c\u1ee7a b\u1ea1n b\u1ecb t\u1eeb ch\u1ed1i. Trong khi \u0111\u00f3, b\u1ea1n ch\u1eafc ch\u1eafn r\u1eb1ng th\u1ebb c\u1ee7a m\u00ecnh ho\u00e0n to\u00e0n d\u01b0 kh\u1ea3 n\u0103ng \u0111\u1ec3 thanh to\u00e1n. B\u1ea1n th\u1eed l\u1ea1i m\u1ed9t l\u1ea7n n\u1eefa nh\u01b0ng k\u1ebft qu\u1ea3 v\u1eabn b\u1ecb t\u1eeb ch\u1ed1i. Khi \u0111\u1ee9ng sang c\u1ea1nh \u0111\u1ec3 nh\u01b0\u1eddng ch\u1ed7 thanh to\u00e1n cho nh\u1eefng ng\u01b0\u1eddi kh\u00e1c, b\u1ea1n l\u1ea1i nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t tin nh\u1eafn t\u1eeb ng\u00e2n h\u00e0ng v\u1ec1 vi\u1ec7c c\u00f3 ti\u1ebfp t\u1ee5c thanh to\u00e1n hay kh\u00f4ng.\n\nM\u1eb7c d\u00f9 c\u00f3 l\u1ebd l\u00e0 c\u1ed3ng k\u1ec1nh v\u00e0 c\u00f3 th\u1ec3 g\u00e2y kh\u00f3 ch\u1ecbu cho b\u1ea1n \u1edf th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i, nh\u01b0ng h\u1ec7 th\u1ed1ng ph\u00f2ng ch\u1ed1ng gian l\u1eadn n\u00e0y \u0111\u00e3 ti\u1ebft ki\u1ec7m cho ng\u01b0\u1eddi ti\u00eau d\u00f9ng h\u00e0ng tri\u1ec7u \u0111\u00f4 la m\u1ed7i n\u0103m. C\u00e1c nh\u00e0 nghi\u00ean c\u1ee9u t\u1eeb IEEE Computational Intelligence Society (IEEE-CIS) mu\u1ed1n c\u1ea3i thi\u1ec7n con s\u1ed1 n\u00e0y, \u0111\u1ed3ng th\u1eddi c\u1ea3i thi\u1ec7n tr\u1ea3i nghi\u1ec7m c\u1ee7a kh\u00e1ch h\u00e0ng. V\u1edbi kh\u1ea3 n\u0103ng ph\u00e1t hi\u1ec7n gian l\u1eadn v\u1edbi \u0111\u1ed9 ch\u00ednh x\u00e1c cao h\u01a1n, b\u1ea1n c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng chip c\u1ee7a m\u00ecnh m\u00e0 kh\u00f4ng g\u1eb7p r\u1eafc r\u1ed1i.\n\nTrong cu\u1ed9c thi n\u00e0y, b\u1ea1n s\u1ebd \u0111\u00e1nh gi\u00e1 \u0111i\u1ec3m chu\u1ea9n c\u00e1c m\u00f4 h\u00ecnh m\u00e1y h\u1ecdc tr\u00ean m\u1ed9t t\u1eadp d\u1eef li\u1ec7u quy m\u00f4 l\u1edbn \u0111\u1ea7y th\u1eed th\u00e1ch. D\u1eef li\u1ec7u \u0111\u1ebfn t\u1eeb c\u00e1c giao d\u1ecbch th\u01b0\u01a1ng m\u1ea1i \u0111i\u1ec7n t\u1eed trong th\u1ebf gi\u1edbi th\u1ef1c c\u1ee7a Vesta v\u00e0 ch\u1ee9a m\u1ed9t lo\u1ea1t c\u00e1c t\u00ednh n\u0103ng t\u1eeb lo\u1ea1i thi\u1ebft b\u1ecb \u0111\u1ebfn t\u00ednh n\u0103ng c\u1ee7a s\u1ea3n ph\u1ea9m. B\u1ea1n c\u0169ng c\u00f3 c\u01a1 h\u1ed9i t\u1ea1o c\u00e1c t\u00ednh n\u0103ng m\u1edbi \u0111\u1ec3 c\u1ea3i thi\u1ec7n k\u1ebft qu\u1ea3 c\u1ee7a m\u00ecnh.","b9e620d5":"V\u1edbi r\u1ea5t nhi\u1ec1u \u0111\u1eb7c tr\u01b0ng, hi\u1ec7u su\u1ea5t c\u1ee7a thu\u1eadt to\u00e1n s\u1ebd gi\u1ea3m s\u00fat nghi\u00eam tr\u1ecdng. PCA l\u00e0 m\u1ed9t c\u00e1ch r\u1ea5t ph\u1ed5 bi\u1ebfn \u0111\u1ec3 t\u0103ng t\u1ed1c thu\u1eadt to\u00e1n H\u1ecdc m\u00e1y b\u1eb1ng c\u00e1ch lo\u1ea1i b\u1ecf c\u00e1c bi\u1ebfn t\u01b0\u01a1ng quan kh\u00f4ng \u0111\u00f3ng g\u00f3p trong b\u1ea5t k\u1ef3 qu\u00e1 tr\u00ecnh ra quy\u1ebft \u0111\u1ecbnh n\u00e0o. Th\u1eddi gian \u0111\u00e0o t\u1ea1o c\u00e1c thu\u1eadt to\u00e1n gi\u1ea3m \u0111\u00e1ng k\u1ec3 v\u1edbi s\u1ed1 l\u01b0\u1ee3ng t\u00ednh n\u0103ng \u00edt h\u01a1n. Ngo\u00e0i ra, Overfitting ch\u1ee7 y\u1ebfu x\u1ea3y ra khi c\u00f3 qu\u00e1 nhi\u1ec1u bi\u1ebfn trong t\u1eadp d\u1eef li\u1ec7u. V\u00ec v\u1eady, PCA gi\u00fap kh\u1eafc ph\u1ee5c v\u1ea5n \u0111\u1ec1 trang b\u1ecb qu\u00e1 m\u1ee9c b\u1eb1ng c\u00e1ch gi\u1ea3m s\u1ed1 l\u01b0\u1ee3ng t\u00ednh n\u0103ng. V\u00ec v\u1eady, n\u1ebfu k\u00edch th\u01b0\u1edbc \u0111\u1ea7u v\u00e0o qu\u00e1 cao, th\u00ec vi\u1ec7c s\u1eed d\u1ee5ng PCA \u0111\u1ec3 t\u0103ng t\u1ed1c thu\u1eadt to\u00e1n l\u00e0 m\u1ed9t l\u1ef1a ch\u1ecdn h\u1ee3p l\u00fd.\n\nTa quan s\u00e1t th\u1ea5y r\u1eb1ng, V c\u00f3 s\u1ed1 l\u01b0\u1ee3ng c\u1ed9t l\u1edbn (kho\u1ea3ng 340) nh\u01b0ng l\u1ea1i kh\u00f4ng c\u00f3 \u0111\u00f3ng g\u00f3p n\u00e0o trong qu\u00e1 tr\u00ecnh ra quy\u1ebft \u0111\u1ecbnh. V\u00ec v\u1eady, ta c\u00f3 th\u1ec3 b\u1ecf qua t\u1ea5t c\u1ea3 V c\u1ed9t b\u1eb1ng c\u00e1ch \u00e1p d\u1ee5ng PCA cho t\u1ea5t c\u1ea3 V c\u1ed9t \u0111\u1ec3 gi\u1ea3m s\u1ed1 c\u1ed9t \/ b\u1ed9 nh\u1edb.","7336f4f9":"- 24,4% TransactionID trong train_transaction (144233\/590540) c\u00f3 train_identity \u0111\u01b0\u1ee3c li\u00ean k\u1ebft. \n- 28,0% TransactionID trong test_transaction (141907 \/ 506691) c\u00f3 train_identity \u0111\u01b0\u1ee3c li\u00ean k\u1ebft.","7e05510e":"# **3. T\u1ec7p d\u1eef li\u1ec7u s\u1eed d\u1ee5ng**\nD\u1eef li\u1ec7u \u0111\u01b0\u1ee3c chia th\u00e0nh hai t\u1ec7p identity v\u00e0 transaction, \u0111\u01b0\u1ee3c k\u1ebft h\u1ee3p b\u1edfi TransactionID. Kh\u00f4ng ph\u1ea3i t\u1ea5t c\u1ea3 c\u00e1c giao d\u1ecbch \u0111\u1ec1u c\u00f3 th\u00f4ng tin nh\u1eadn d\u1ea1ng t\u01b0\u01a1ng \u1ee9ng.\n\n\u0110\u1ed1i v\u1edbi m\u1ed7i TransactionID trong t\u1eadp h\u1ee3p th\u1eed nghi\u1ec7m, b\u1ea1n ph\u1ea3i d\u1ef1 \u0111o\u00e1n x\u00e1c su\u1ea5t m\u1ed9t giao d\u1ecbch tr\u1ef1c tuy\u1ebfn l\u00e0 gian l\u1eadn cho bi\u1ebfn isFraud. \n\n- train_{transaction, identity}.csv - b\u1ed9 \u0111\u00e0o t\u1ea1o\n- test_{transaction, identity}.csv - b\u1ed9 th\u1eed nghi\u1ec7m (b\u1ea1n ph\u1ea3i d\u1ef1 \u0111o\u00e1n gi\u00e1 tr\u1ecb isFraud cho nh\u1eefng quan s\u00e1t n\u00e0y)\n- sample_submission.csv - m\u1ed9t t\u1ec7p submission m\u1eabu theo \u0111\u00fang \u0111\u1ecbnh d\u1ea1ng\n","788ad1b4":"# **Bi\u1ec3u \u0111\u1ed3 v\u1ec1 ph\u00e2n ph\u1ed1i gian l\u1eadn (isFraud)**","69188248":"# **Bi\u1ec3u \u0111\u1ed3 ph\u00e2n ph\u1ed1i ProductCD**","0809f53d":"# **3. Predict submission data**","26c324f7":"# **3. X\u1eed l\u00fd c\u00e1c gi\u00e1 tr\u1ecb b\u1ecb thi\u1ebfu**","d79d5410":"# **3. DecisionTree**","b7a5fd13":"# **V. M\u00f4 h\u00ecnh h\u1ecdc m\u00e1y**","dd203b68":"# **2. Ch\u1ea1y v\u1edbi t\u1ea5t c\u1ea3 d\u1eef li\u1ec7u**","42e1b447":"# **Ph\u00e2n b\u1ed1 Train v\u00e0 Test theo s\u1ef1 ph\u00e2n chia theo chu\u1ed7i th\u1eddi gian (TransactionDT)**","95340e73":"# **2. \u0110\u00e1nh gi\u00e1 d\u1eef li\u1ec7u**","f8d3d3bd":"\n# **1. \u0110\u1ecdc d\u1eef li\u1ec7u v\u00e0 hi\u1ec7n th\u1ecb d\u1eef li\u1ec7u**\n\u0110\u1ed1i v\u1edbi m\u1ed7i t\u1eadp train_transaction, test_transaction, train_identity, test_identity, ta s\u1ebd \u0111\u1ecdc v\u00e0 hi\u1ec3n th\u1ecb m\u1ed9t s\u1ed1 h\u00e0ng \u0111\u1ec3 xem x\u00e9t t\u1ed5ng quan d\u1eef li\u1ec7u. Ta s\u1ebd d\u00f9ng m\u1ed9t s\u1ed1 h\u00e0m c\u00f3 s\u1eb5n trong c\u00e1c th\u01b0 vi\u1ec7n \u0111\u1ec3 l\u00e0m \u0111\u01b0\u1ee3c \u0111i\u1ec1u n\u00e0y.","e1098569":"**P_emaildomain**","c7f7d456":"# **I. T\u1ed5ng quan b\u00e0i to\u00e1n**","2489785a":"# **2. Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u**","915cbab2":"**Chuy\u1ec3n \u0111\u1ed5i th\u00e0nh t\u1ed5ng s\u1ed1 ng\u00e0y, tu\u1ea7n v\u00e0 gi\u1edd**","90ef6c91":"# **1. So s\u00e1nh gi\u1eefa c\u00e1c m\u00f4 h\u00ecnh**","9af8df19":"Remove collinear features (x\u00f3a c\u00e1c \u0111\u1eb7c tr\u01b0ng c\u00f3 t\u00ednh t\u01b0\u01a1ng \u0111\u1ed3ng cao) trong khung d\u1eef li\u1ec7u c\u00f3 h\u1ec7 s\u1ed1 t\u01b0\u01a1ng quan l\u1edbn h\u01a1n ng\u01b0\u1ee1ng. Vi\u1ec7c lo\u1ea1i b\u1ecf c\u00e1c \u0111\u1eb7c tr\u01b0ng n\u00e0y c\u00f3 th\u1ec3 gi\u00fap m\u00f4 h\u00ecnh t\u1ed5ng qu\u00e1t h\u00f3a v\u00e0 c\u1ea3i thi\u1ec7n kh\u1ea3 n\u0103ng di\u1ec5n gi\u1ea3i c\u1ee7a m\u00f4 h\u00ecnh.","0d7239fb":"T\u1ea5t c\u1ea3 c\u00e1c t\u1eadp d\u1eef li\u1ec7u \u0111\u1ec1u c\u00f3 c\u00e1c gi\u00e1 tr\u1ecb b\u1ecb thi\u1ebfu, \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 ph\u1ed5 bi\u1ebfn trong th\u1ebf gi\u1edbi th\u1ef1c.","b6973064":"T\u1eadp d\u1eef li\u1ec7u c\u00f3 qu\u00e1 nhi\u1ec1u gi\u00e1 tr\u1ecb b\u1ecb thi\u1ebfu.","64d6e081":"# **Bi\u1ec3u \u0111\u1ed3 ph\u1ea7n tr\u0103m gi\u00e1 tr\u1ecb NA cho t\u1eebng \u0111\u1ed1i t\u01b0\u1ee3ng**","5df8cb7a":"L\u00e0m vi\u1ec7c v\u1edbi d\u1eef li\u1ec7u l\u1edbn trong khi \u0111\u00e0o t\u1ea1o m\u00f4 h\u00ecnh ML y\u00eau c\u1ea7u b\u1ed9 nh\u1edb RAM l\u1edbn. \u0110\u1ec3 kh\u1eafc ph\u1ee5c h\u1ea1n ch\u1ebf n\u00e0y, ta s\u1eed d\u1ee5ng m\u1ed9t h\u00e0m \u0111\u1ec3 gi\u1ea3m dung l\u01b0\u1ee3ng b\u1ed9 nh\u1edb c\u1ee7a d\u1eef li\u1ec7u. C\u00e1ch ti\u1ebfp c\u1eadn chung l\u00e0 chuy\u1ec3n \u0111\u1ed5i lo\u1ea1i dtype c\u1ee7a t\u1eebng t\u00ednh n\u0103ng ('int16', 'int32', 'int64', 'float16', 'float32', 'float64') th\u00e0nh lo\u1ea1i dtype th\u1ea5p nh\u1ea5t c\u00f3 th\u1ec3.","c4239a95":"# **TransactionID**","799cd5c5":"# **3. Ph\u00e2n t\u00edch c\u00e1c \u0111\u1eb7c tr\u01b0ng d\u1eef li\u1ec7u**","2729e9b4":"# **4. Ph\u01b0\u01a1ng th\u1ee9c tri\u1ec3n khai b\u00e0i to\u00e1n**\n![image.png](attachment:0e43bd8a-edf4-432a-a9ff-2212b98f0aff.png)","f77a3fb0":"# **2. K nearest neighbor - KNN**","f3fd7eea":"# **6. XGBoost**","daeb0173":"Nh\u1eadn x\u00e9t:\n- T\u00ednh n\u0103ng TransactionDT l\u00e0 t\u00ednh n\u0103ng h\u1eb9n gi\u1edd t\u1eeb m\u1ed9t ng\u00e0y gi\u1edd tham chi\u1ebfu nh\u1ea5t \u0111\u1ecbnh (kh\u00f4ng ph\u1ea3i d\u1ea5u th\u1eddi gian th\u1ef1c t\u1ebf). M\u1ed9t ph\u00e1t hi\u1ec7n s\u1edbm v\u1ec1 d\u1eef li\u1ec7u l\u00e0 t\u1eadp train v\u00e0 t\u1eadp test d\u01b0\u1eddng nh\u01b0 \u0111\u01b0\u1ee3c ph\u00e2n chia theo th\u1eddi gian. C\u00f3 m\u1ed9t kho\u1ea3ng c\u00e1ch nh\u1ecf \u1edf gi\u1eefa, t\u1eadp train l\u00e0 t\u1eeb m\u1ed9t kho\u1ea3ng th\u1eddi gian tr\u01b0\u1edbc \u0111\u00f3 v\u00e0 t\u1eadp test l\u00e0 t\u1eeb m\u1ed9t kho\u1ea3ng th\u1eddi gian sau. \u0110i\u1ec1u n\u00e0y s\u1ebd \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn c\u00e1c k\u1ef9 thu\u1eadt x\u00e1c nh\u1eadn ch\u00e9o n\u00e0o n\u00ean \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng."}}