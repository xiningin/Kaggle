{"cell_type":{"55482ac5":"code","2886f251":"code","0a30bf80":"code","45b9045f":"code","0c41102e":"code","58ffd499":"code","6c86e0ff":"code","6edb43c9":"code","faaef7bc":"code","d6f41a7e":"code","baefbbce":"code","2f8c9623":"code","93755da1":"code","3913c5d2":"code","18340b29":"code","da2598a2":"code","d707745f":"code","0958371c":"code","4a82ee62":"code","8cec9657":"code","e4be4290":"code","6348fe13":"code","f6539e45":"code","24ddd84b":"code","f653eb85":"code","a0bf757f":"code","66c8b49c":"code","9d2412ce":"code","2e5088df":"code","3198dfad":"markdown","92d5534c":"markdown","432805de":"markdown","5d0122de":"markdown","8211c6f0":"markdown","88384404":"markdown","66eb77bb":"markdown","52db5121":"markdown","4e061940":"markdown","9ebcbf3c":"markdown"},"source":{"55482ac5":"import numpy as np #\u5bfc\u5165NumPy\nimport pandas as pd #\u5bfc\u5165Pandas \ndf_app = pd.read_csv('..\/input\/flower-app\/App.csv', index_col='Date', parse_dates=['Date']) #\u5bfc\u5165\u6570\u636e\ndf_app #\u663e\u793a\u6570\u636e","2886f251":"import matplotlib.pyplot as plt #\u5bfc\u5165matplotlib.pyplot\nplt.style.use('fivethirtyeight') #\u8bbe\u5b9a\u7ed8\u56fe\u98ce\u683c\ndf_app[\"Activation\"].plot(figsize=(12,4),legend=True) #\u7ed8\u5236\u6fc0\u6d3b\u6570\nplt.title('App Activation Count') #\u56fe\u9898\nplt.show() #\u7ed8\u56fe","0a30bf80":"df_app.isna().sum() #\u6709NaN\u5417\uff1f","45b9045f":"(df_app.Activation < 0).values.any() #\u6709\u8d1f\u503c\u5417\uff1f","0c41102e":"# \u6309\u71672020\u5e7410\u67081\u65e5\u4e3a\u754c\u62c6\u5206\u6570\u636e\u96c6\nTrain = df_app[:'2020-09-30'].iloc[:,0:1].values #\u8bad\u7ec3\u96c6\nTest = df_app['2020-10-01':].iloc[:,0:1].values #\u6d4b\u8bd5\u96c6","58ffd499":"#Train #\u663e\u793a\u8bad\u7ec3\u96c6\u5bf9\u8c61","6c86e0ff":"print('\u8bad\u7ec3\u96c6\u7684\u5f62\u72b6\u662f\uff1a', Train.shape)\nprint('\u6d4b\u8bd5\u96c6\u7684\u5f62\u72b6\u662f\uff1a', Test.shape)","6edb43c9":"# \u4ee5\u4e0d\u540c\u989c\u8272\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u7ed8\u56fe\ndf_app[\"Activation\"][:'2020-09-30'].plot(figsize=(12,4),legend=True) #\u8bad\u7ec3\u96c6\ndf_app[\"Activation\"]['2020-10-01':].plot(figsize=(12,4),legend=True) #\u6d4b\u8bd5\u96c6\nplt.legend(['Training set (Before October 2020)','Test set (2020 October and beyond)']) #\u56fe\u4f8b\nplt.title('App Activation Count') #\u56fe\u9898\nplt.show() #\u7ed8\u56fe","faaef7bc":"from sklearn.preprocessing import MinMaxScaler #\u5bfc\u5165\u5f52\u4e00\u5316\u7f29\u653e\u5668\nScaler = MinMaxScaler(feature_range=(0,1)) #\u521b\u5efa\u7f29\u653e\u5668\nTrain = Scaler.fit_transform(Train) #\u62df\u5408\u7f29\u653e\u5668\u5e76\u5bf9\u8bad\u7ec3\u96c6\u8fdb\u884c\u5f52\u4e00\u5316","d6f41a7e":"# \u521b\u5efa\u5177\u6709 60 \u4e2a\u65f6\u95f4\u6b65\u957f\u548c 1 \u4e2a\u8f93\u51fa\u7684\u6570\u636e\u7ed3\u6784 - \u8bad\u7ec3\u96c6\nX_train = [] #\u521d\u59cb\u5316\ny_train = [] #\u521d\u59cb\u5316\nfor i in range(60,Train.size): \n    X_train.append(Train[i-60:i,0]) #\u6784\u5efa\u7279\u5f81\n    y_train.append(Train[i,0]) #\u6784\u5efa\u6807\u7b7e\nX_train, y_train = np.array(X_train), np.array(y_train) #\u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1)) #\u8f6c\u6362\u6210\u795e\u7ecf\u7f51\u7edc\u6240\u9700\u7684\u5f20\u91cf\u5f62\u72b6","baefbbce":"X_train.shape #X_train\u7684\u5f62\u72b6","2f8c9623":"TrainTest = df_app[\"Activation\"][:] #\u6574\u4f53\u6570\u636e\ninputs = TrainTest[len(TrainTest)-len(Test) - 60:].values #Test\u52a0\u4e0a\u524d60\u4e2a\u65f6\u95f4\u6b65\ninputs = inputs.reshape(-1,1) #\u8f6c\u6362\u5f62\u72b6\ninputs  = Scaler.transform(inputs) #\u5f52\u4e00\u5316\n# \u521b\u5efa\u5177\u6709 60 \u4e2a\u65f6\u95f4\u6b65\u957f\u548c 1 \u4e2a\u8f93\u51fa\u7684\u6570\u636e\u7ed3\u6784 - \u6d4b\u8bd5\u96c6\nX_test = [] #\u521d\u59cb\u5316\ny_test = [] #\u521d\u59cb\u5316\nfor i in range(60,inputs.size): \n    X_test.append(inputs[i-60:i,0]) #\u6784\u5efa\u7279\u5f81\n    y_test.append(inputs[i,0]) #\u6784\u5efa\u6807\u7b7e\nX_test = np.array(X_test) #\u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1)) #\u8f6c\u6362\u6210\u795e\u7ecf\u7f51\u7edc\u6240\u9700\u7684\u5f20\u91cf\u5f62\u72b6","93755da1":"X_test.shape #X_test\u7684\u5f62\u72b6","3913c5d2":"from tensorflow.keras.models import Sequential #\u5bfc\u5165\u5e8f\u8d2f\u6a21\u578b\nfrom tensorflow.keras.layers import Dense, LSTM #\u5bfc\u5165\u5168\u8fde\u63a5\u5c42\u548cLSTM\u5c42\n# from keras.optimizers import SGD\n# LSTM\u7f51\u7edc\u67b6\u6784\nRNN_LSTM = Sequential() #\u5e8f\u8d2f\u6a21\u578b\nRNN_LSTM.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1))) #\u8f93\u5165\u5c42LSTM,return_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(LSTM(units=50, return_sequences=True)) #\u4e2d\u95f41\u5c42LSTM\uff0creturn_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(LSTM(units=50, return_sequences=True)) #\u4e2d\u95f42\u5c42LSTM\uff0creturn_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(LSTM(units=50)) #\u4e2d\u95f43\u5c42LSTM\nRNN_LSTM.add(Dense(units=1)) #\u8f93\u51fa\u5c42Dense\n# \u7f16\u8bd1\u7f51\u7edc\nRNN_LSTM.compile(loss='mse', #\u635f\u5931\u51fd\u6570\n                 optimizer='rmsprop', #\u4f18\u5316\u5668\n                 metrics=['mae']) #\u8bc4\u4f30\u6307\u6807\nRNN_LSTM.summary() #\u8f93\u51fa\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u4fe1\u606f","18340b29":"# \u8bad\u7ec3\u5e76\u4fdd\u5b58\u8bad\u7ec3\u5386\u53f2\u4fe1\u606f\nhistory = RNN_LSTM.fit(X_train, y_train, # \u6307\u5b9a\u8bad\u7ec3\u96c6\n                  epochs=50,        # \u6307\u5b9a\u8bad\u7ec3\u7684\u8f6e\u6b21\n                  batch_size=64,    # \u6307\u5b9a\u6570\u636e\u6279\u91cf\n                  validation_split=0.2) #\u8fd9\u91cc\u76f4\u63a5\u4ece\u8bad\u7ec3\u96c6\u6570\u636e\u4e2d\u62c6\u5206\u9a8c\u8bc1\u96c6\uff0c\u66f4\u65b9\u4fbf","da2598a2":"def show_history(history): # \u663e\u793a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u66f2\u7ebf\n    loss = history.history['loss'] #\u8bad\u7ec3\u635f\u5931\n    val_loss = history.history['val_loss'] #\u9a8c\u8bc1\u635f\u5931\n    epochs = range(1, len(loss) + 1) #\u8bad\u7ec3\u8f6e\u6b21\n    plt.figure(figsize=(12,4)) # \u56fe\u7247\u5927\u5c0f\n    plt.subplot(1, 2, 1) #\u5b50\u56fe1\n    plt.plot(epochs, loss, 'bo', label='Training loss') #\u8bad\u7ec3\u635f\u5931\n    plt.plot(epochs, val_loss, 'b', label='Validation loss') #\u9a8c\u8bc1\u635f\u5931\n    plt.title('Training and validation loss') #\u56fe\u9898\n    plt.xlabel('Epochs') #X\u8f74\u6587\u5b57\n    plt.ylabel('Loss') #Y\u8f74\u6587\u5b57\n    plt.legend() #\u56fe\u4f8b\n    plt.show() #\u7ed8\u56fe","d707745f":"show_history(history) # \u8c03\u7528\u7ed8\u56fe\u51fd\u6570","0958371c":"# \u5b9a\u4e49\u7ed8\u56fe\u51fd\u6570\ndef plot_predictions(test,predicted):\n    plt.plot(test, color='red',label='Real Count') #\u771f\u503c\n    plt.plot(predicted, color='blue',label='Predicted Count') #\u9884\u6d4b\u503c\n    plt.title('Flower App Activation Prediction') #\u56fe\u9898\n    plt.xlabel('Time') #X\u8f74\u65f6\u95f4\n    plt.ylabel('Flower App Activation Count') #Y\u8f74\u6fc0\u6d3b\u6570\n    plt.legend() #\u56fe\u4f8b\n    plt.show() #\u7ed8\u56fe","4a82ee62":"y_pred = RNN_LSTM.predict(X_test) #\u9884\u6d4b\nPred = Scaler.inverse_transform(y_pred) #\u53cd\u5f52\u4e00\u5316\nplot_predictions(Test,Pred) #\u7ed8\u56fe","8cec9657":"# import math #\u5bfc\u5165\u6570\u5b66\u51fd\u6570\n# \n# def return_rmse(test,predicted): #\u5b9a\u4e49\u5747\u65b9\u635f\u5931\u51fd\u6570\n#     rmse = math.sqrt(mean_squared_error(test, predicted)) #\u5747\u65b9\u635f\u5931\n#     print(\"MSE\u635f\u5931\u503c {}.\".format(rmse))","e4be4290":"from sklearn.metrics import mean_squared_error\nprint(\"\u8c03\u4f18\u524dMSE\u635f\u5931\u503c {}.\".format(mean_squared_error(y_test,y_pred)))","6348fe13":"from tensorflow.keras.models import Sequential #\u5bfc\u5165\u5e8f\u8d2f\u6a21\u578b\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout #\u5bfc\u5165\u5168\u8fde\u63a5\u5c42,LSTM\u5c42\u548cDropout\u5c42\n# from keras.optimizers import SGD\n# LSTM\u7f51\u7edc\u67b6\u6784\nRNN_LSTM = Sequential() #\u5e8f\u8d2f\u6a21\u578b\nRNN_LSTM.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1))) #\u8f93\u5165\u5c42LSTM,return_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(Dropout(0.2))\nRNN_LSTM.add(LSTM(units=50, return_sequences=True)) #\u4e2d\u95f41\u5c42LSTM\uff0creturn_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(Dropout(0.2))\nRNN_LSTM.add(LSTM(units=50, return_sequences=True)) #\u4e2d\u95f42\u5c42LSTM\uff0creturn_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(Dropout(0.2))\nRNN_LSTM.add(LSTM(units=50)) #\u4e2d\u95f43\u5c42LSTM\nRNN_LSTM.add(Dropout(0.2))\nRNN_LSTM.add(Dense(units=1)) #\u8f93\u51fa\u5c42Dense\n# \u7f16\u8bd1\u7f51\u7edc\nRNN_LSTM.compile(loss='mse', #\u635f\u5931\u51fd\u6570\n                 optimizer='rmsprop', #\u4f18\u5316\u5668\n                 metrics=['mae']) #\u8bc4\u4f30\u6307\u6807\nRNN_LSTM.summary() #\u8f93\u51fa\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u4fe1\u606f","f6539e45":"# \u8bad\u7ec3\u5e76\u4fdd\u5b58\u8bad\u7ec3\u5386\u53f2\u4fe1\u606f\nhistory = RNN_LSTM.fit(X_train, y_train, # \u6307\u5b9a\u8bad\u7ec3\u96c6\n                  epochs=50,        # \u6307\u5b9a\u8bad\u7ec3\u7684\u8f6e\u6b21\n                  batch_size=64,    # \u6307\u5b9a\u6570\u636e\u6279\u91cf\n                  validation_split=0.2) #\u8fd9\u91cc\u76f4\u63a5\u4ece\u8bad\u7ec3\u96c6\u6570\u636e\u4e2d\u62c6\u5206\u9a8c\u8bc1\u96c6\uff0c\u66f4\u65b9\u4fbf\nshow_history(history) # \u8c03\u7528\u7ed8\u56fe\u51fd\u6570","24ddd84b":"y_pred = RNN_LSTM.predict(X_test) #\u9884\u6d4b\nPred = Scaler.inverse_transform(y_pred) #\u53cd\u5f52\u4e00\u5316\nplot_predictions(Test,Pred) #\u7ed8\u56fe","f653eb85":"print(\"\u589e\u52a0Dropout\u5c42\u540e\u5f97MSE\u635f\u5931\u503c {}.\".format(mean_squared_error(y_test,y_pred)))","a0bf757f":"from tensorflow.keras.models import Sequential #\u5bfc\u5165\u5e8f\u8d2f\u6a21\u578b\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout #\u5bfc\u5165\u5168\u8fde\u63a5\u5c42,LSTM\u5c42\u548cDropout\u5c42\nfrom tensorflow.keras.optimizers import Adam\n# LSTM\u7f51\u7edc\u67b6\u6784\nRNN_LSTM = Sequential() #\u5e8f\u8d2f\u6a21\u578b\nRNN_LSTM.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1))) #\u8f93\u5165\u5c42LSTM,return_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(Dropout(0.2)) #Dropout\u5c42\u51cf\u5c11\u8fc7\u62df\u5408\nRNN_LSTM.add(LSTM(units=50, return_sequences=True)) #\u4e2d\u95f4\u5c42LSTM\uff0creturn_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(Dropout(0.2)) #Dropout\u5c42\u51cf\u5c11\u8fc7\u62df\u5408\nRNN_LSTM.add(LSTM(units=50, return_sequences=True)) #\u4e2d\u95f4\u5c42LSTM\uff0creturn_sequences\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\nRNN_LSTM.add(Dropout(0.2)) #Dropout\u5c42\u51cf\u5c11\u8fc7\u62df\u5408\nRNN_LSTM.add(LSTM(units=50)) #\u4e2d\u95f4\u5c42LSTM\nRNN_LSTM.add(Dropout(0.2)) #Dropout\u5c42\u51cf\u5c11\u8fc7\u62df\u5408\nRNN_LSTM.add(Dense(units=1)) #\u8f93\u51fa\u5c42Dense\n# \u7f16\u8bd1\u7f51\u7edc\nRNN_LSTM.compile(loss='mse', # \u635f\u5931\u51fd\u6570\n             optimizer=Adam(lr=1e-4), # \u66f4\u65b0\u4f18\u5316\u5668\u5e76\u8bbe\u5b9a\u5b66\u4e60\u901f\u7387\n             metrics=['mae']) # \u8bc4\u4f30\u6307\u6807\nRNN_LSTM.summary() #\u8f93\u51fa\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u4fe1\u606f","66c8b49c":"# \u8bad\u7ec3\u5e76\u4fdd\u5b58\u8bad\u7ec3\u5386\u53f2\u4fe1\u606f\nhistory = RNN_LSTM.fit(X_train, y_train, # \u6307\u5b9a\u8bad\u7ec3\u96c6\n                  epochs=50,        # \u6307\u5b9a\u8bad\u7ec3\u7684\u8f6e\u6b21\n                  batch_size=64,    # \u6307\u5b9a\u6570\u636e\u6279\u91cf\n                  validation_split=0.2) #\u8fd9\u91cc\u76f4\u63a5\u4ece\u8bad\u7ec3\u96c6\u6570\u636e\u4e2d\u62c6\u5206\u9a8c\u8bc1\u96c6\uff0c\u66f4\u65b9\u4fbf\nshow_history(history) # \u8c03\u7528\u7ed8\u56fe\u51fd\u6570","9d2412ce":"y_pred = RNN_LSTM.predict(X_test) #\u9884\u6d4b\nPred = Scaler.inverse_transform(y_pred) #\u53cd\u5f52\u4e00\u5316\nplot_predictions(Test,Pred) #\u7ed8\u56fe","2e5088df":"print(\"\u8bbe\u7f6e\u4f18\u5316\u5668\u540e\u7684MSE\u635f\u5931\u503c {}.\".format(mean_squared_error(y_test, y_pred)))","3198dfad":"## \u6784\u5efa\u7279\u5f81\u96c6\u548c\u6807\u7b7e\u96c6","92d5534c":"# \u96f6\u57fa\u7840\u5b9e\u6218\u673a\u5668\u5b66\u4e60\n\u7b2c12\u8bb2 RNN\u7684\u4f18\u5316\n\u4f5c\u8005 \u9ec4\u4f73\n\n\u6781\u5ba2\u65f6\u95f4\u4e13\u680f\u94fe\u63a5\uff1ahttps:\/\/time.geekbang.org\/column\/intro\/438\n\n\u95ee\u9898\uff1a\u6839\u636eApp\u7684\u5386\u53f2\u6fc0\u6d3b\uff08\u5373\u4e0b\u8f7d\u540e\u6ce8\u518c\u7528\u6237\u5e76\u4f7f\u7528App\uff09\u6570\u5b57\uff0c\u6765\u9884\u6d4b\u5176\u672a\u6765\u8d70\u52bf\n\n\u6613\u901f\u9c9c\u82b1\u516c\u53f8\u62e5\u6709\u8fc7\u53bb\u4e24\u5e74App\u7684\u65e5\u6fc0\u6d3b\u6570\u3002\n\n\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684RNN\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u8fd9\u4e2a\u65f6\u5e8f\u6570\u636e\u96c6\u8fdb\u884c\u9884\u6d4b\u3002\n\n\u8fd9\u91cc\u662f\u5bf9RNN\u6a21\u578b\u7684\u4e00\u4e0b\u4f18\u5316\u7b56\u7565\u3002","432805de":"## \u6570\u636e\u6e05\u6d17","5d0122de":"## \u7279\u5f81\u5de5\u7a0b","8211c6f0":"## \u62c6\u5206\u6570\u636e\u96c6","88384404":"## \u9009\u62e9\u7b97\u6cd5\n\n\u8fd9\u91cc\u6211\u4eec\u91c7\u7528RNN\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5","66eb77bb":"## \u5bfc\u5165\u6570\u636e","52db5121":"## \u7b2c\u4e00\u4e2a\u8c03\u4f18","4e061940":"## \u6570\u636e\u53ef\u89c6\u5316\n","9ebcbf3c":"## \u7b2c\u4e8c\u4e2a\u8c03\u4f18\n\n\u6539\u53d8\u4f18\u5316\u5668\uff0c\u540c\u65f6\u8bbe\u7f6e\u5b66\u4e60\u901f\u7387\u3002"}}