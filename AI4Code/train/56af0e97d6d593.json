{"cell_type":{"13f549cd":"code","02663b2a":"code","0a1210d1":"code","a0444e1e":"code","5cee2dd7":"code","ef728924":"code","c76ddeb8":"code","28083f56":"code","5c410eaa":"code","e7d784f7":"code","3de96415":"code","afe32b16":"code","d7d956e9":"code","00aaf6be":"code","0d1e2315":"code","4d55ce28":"code","5801c2b8":"code","a8f5b2e2":"code","d09c2b88":"code","e9b30ed6":"code","5517a723":"markdown","1bb7d5e8":"markdown","eed7464e":"markdown","ec9daaec":"markdown","23aa39eb":"markdown","ce09d169":"markdown","e0a1810b":"markdown"},"source":{"13f549cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n%matplotlib notebook\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02663b2a":"data=pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndata","0a1210d1":"data.shape","a0444e1e":"data.describe()","5cee2dd7":"data.isnull().sum()","ef728924":"data.quality.unique()","c76ddeb8":"data.quality.value_counts()","28083f56":"data['quality']=data.quality.apply(lambda x:1 if x>6.5 else 0)\ndata","5c410eaa":"data.quality.value_counts()\n","e7d784f7":"plt.figure()\nplt.hist(data['quality'])\nplt.show()","3de96415":"sns.pairplot(data,hue='quality',diag_kind='hist')\nplt.show()","afe32b16":"sns.countplot(data=data,x='quality')","d7d956e9":"fig=plt.figure(figsize=[20,15])\nfeatures=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']\ncount=1\nfor i in features:\n    plt.subplot(3,4,count)\n    sns.barplot(data['quality'],data[i],hue=data['quality'])\n    count=count+1\nplt.show()","00aaf6be":"fig=plt.figure(figsize=[10,10])\nsns.heatmap(data.corr(),annot=True,center=0,cmap='Blues')\nplt.show()","0d1e2315":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nX=data[features]\ny=data['quality']\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n\nscaler=StandardScaler()\nX_train_scaled=scaler.fit_transform(X_train)\nX_test_scaled=scaler.transform(X_test)\n","4d55ce28":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nmodel=LogisticRegression()\nmodel.fit(X_train_scaled,y_train)\npredict=model.predict(X_test_scaled)\nscore=accuracy_score(predict,y_test)\nscore","5801c2b8":"from sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(X_train_scaled,y_train)\npredict=model.predict(X_test_scaled)\nscore=accuracy_score(predict,y_test)\nscore","a8f5b2e2":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(random_state=0)\nmodel.fit(X_train_scaled,y_train)\npredict=model.predict(X_test_scaled)\nscore=accuracy_score(predict,y_test)\nscore","d09c2b88":"from sklearn.model_selection import GridSearchCV\nparam={'n_estimators':[5,10,15,20,50,100,200,500]}\n\nmodel=RandomForestClassifier(random_state=0)\ngrid_acc=GridSearchCV(model,param_grid=param)\ngrid_acc.fit(X_train_scaled,y_train)\n \n\nprint('Grid best parameter:',grid_acc.best_params_)\nprint('Grid best score for Random Forest:',grid_acc.best_score_)","e9b30ed6":"model_2=RandomForestClassifier(n_estimators=20,random_state=0)\nmodel_2.fit(X_train_scaled,y_train)\npredict=model_2.predict(X_test_scaled)\nscore=accuracy_score(predict,y_test)\nscore","5517a723":"# Exploratory Data Analysis","1bb7d5e8":"Train_test_split and scaling the data.","eed7464e":"# SVC\nUsing SVC with Default Parameters","ec9daaec":"# Random Forest Classifier\nUsing Random Forest Classifier with Default Parameters","23aa39eb":"Applying the best parameters to the model","ce09d169":"# Logisitic Regression\nUsing Logistic Regression with Default Parameters","e0a1810b":"# GridSearchCV \nApplying Grid Search on the best model which is Random Forest Classifier to increase its accuracy. "}}