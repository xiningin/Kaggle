{"cell_type":{"7fed7be8":"code","ae16e6ad":"code","aad3150a":"code","4156940d":"code","843d3488":"code","72d7d348":"code","14746827":"code","e1e787a1":"code","8c7fb570":"code","d719b193":"code","4db737f2":"markdown","8e62921b":"markdown","fe0deaec":"markdown","0c757f1d":"markdown","a2478947":"markdown","b6a94bef":"markdown","38bf2e29":"markdown","420df5be":"markdown","7223f2b4":"markdown","f3963ef6":"markdown","b1a8fca8":"markdown","0590f2c7":"markdown","88e5c1c9":"markdown","a418171b":"markdown"},"source":{"7fed7be8":"import pandas as pd\nimport matplotlib.pyplot as plt \ndata_train = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\nbyTarget = data_train.groupby(data_train[\"target\"]).count()[\"id\"]\nlabel = [\"Fake\",\"Real\"]\ncolor = [\"blue\", \"red\"]\nplt.pie(byTarget,labels=label,colors=color,startangle=90)","ae16e6ad":"#data split real or fake\ngrouped_data = data_train.groupby(\"target\")\ndata_train_real = grouped_data.get_group(1)\ndata_train_fake = grouped_data.get_group(0)\n\n#WordClud\nfrom wordcloud import WordCloud\ntweet_text_real = data_train_real[\"text\"]\ntxt_real = \"\"\nfor i in range(len(tweet_text_real)):\n    txt_real = txt_real + tweet_text_real.iloc[i]\nwordcloud_real = WordCloud(background_color=\"white\",width=800,height=600).generate(txt_real)\n\ntweet_text_fake = data_train_fake[\"text\"]\ntxt_fake = \"\"\nfor i in range(len(tweet_text_fake)):\n    txt_fake = txt_fake + tweet_text_fake.iloc[i]\nwordcloud_fake = WordCloud(background_color=\"white\",width=800,height=600).generate(txt_fake)\n\nwordcloud_real.to_file(\"word_cloud_real.png\")\nwordcloud_fake.to_file(\"word_cloud_fake.png\")\n","aad3150a":"import spacy\nimport re\n\n###Local Name Extraction###\nnlp = spacy.load('en_core_web_sm') #model\nhtml = re.compile(r'<.*?>')\n\n#remove url & html tag\ntxt_real = re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', txt_real, flags=re.MULTILINE)\ntxt_fake = re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', txt_fake, flags=re.MULTILINE)\ntxt_real = html.sub(r'', txt_real)\ntxt_fake = html.sub(r'', txt_fake)\n\ndoc = nlp(txt_real) #load text\ndoc2 = nlp(txt_fake) #load text\ncount_real=0\ncount_fake=0\n\n#extract place name\nfor d in doc.ents:\n    if d.label_ == \"GPE\": #if proper noun is local name\n        count_real+=1\n\nprint(f\"real tweet:{count_real}\")\n        \n#extract place name\nfor d in doc2.ents:\n    if d.label_ == \"GPE\": #if proper noun is local name\n        count_fake+=1\n\nprint(f\"fake tweet:{count_fake}\")","4156940d":"import re\n\n###Count Word(Name of Place)###\n#add columns(num_place)\ndata_train = data_train.assign(num_place=0)\n\nhtml = re.compile(r'<.*?>')\n\n#count\nfor i in range(len(data_train[\"text\"])):\n    #remove url & html tag\n    data_train[\"text\"][i] = re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', data_train[\"text\"][i], flags=re.MULTILINE)\n    data_train[\"text\"][i] = html.sub(r'', data_train[\"text\"][i])\n    \n    doc = nlp(data_train[\"text\"][i])\n    #whether have place or not\n    place_flg=0\n    \n    #extract place name\n    for d in doc.ents:\n        if d.label_ == \"GPE\": #if proper noun is local name\n            place_flg=1\n        \n    data_train[\"num_place\"][i] = place_flg\n\ndata_train.describe()","843d3488":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\n#data split real or fake\ngrouped_data = data_train.groupby(\"target\")\ndata_train_real = grouped_data.get_group(1)\ndata_train_fake = grouped_data.get_group(0)\n\n#boxplot\nsns.set()\nsns.set_style('whitegrid')\nsns.set_palette('gray')\nfig = plt.figure()\nax = fig.add_subplot()\nax.boxplot([data_train_real[\"num_place\"],data_train_fake[\"num_place\"]], labels=[\"Real News\",\"Fake News\"])\nax.set_title(\"Number of Local Name Words \")\nax.set_ylabel(\"number\")\nax.set_ylim(-1, 2)\n\nplt.show()","72d7d348":"import pandas as pd\n\ndata_train[\"keyword\"] = data_train[\"keyword\"].fillna(\"blank\")\n\n#percentage of real tweet\nper_byKeyword = data_train.groupby(\"keyword\").mean()[\"target\"].reset_index()\n\n#translation into DataFrame\nper_byKeyword = pd.DataFrame(per_byKeyword,columns=[\"keyword\",\"target\"])\n\nfoa_byKeyword = per_byKeyword.rename(columns={\"target\":\"FoA\"})\n\nfoa_byKeyword.head()","14746827":"#convert\nfor i in range(len(data_train[\"id\"])):\n    \n    for j in range(len(foa_byKeyword[\"keyword\"])):\n        \n        if data_train[\"keyword\"][i] == foa_byKeyword[\"keyword\"][j]:\n            \n            data_train[\"keyword\"][i] = foa_byKeyword[\"FoA\"][j]\n\ndata_train = data_train.rename(columns={\"keyword\":\"FoA\"})\n\ndata_train.head()","e1e787a1":"from sklearn.preprocessing import MinMaxScaler as mms\nfrom sklearn.metrics import accuracy_score as a_score\nfrom sklearn.tree import DecisionTreeClassifier as dtc\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split as tts\n\n#define\ny_name = [\"target\"]\nX_name = [\"num_place\",\"FoA\"]\nX_train=data_train[X_name]\ny_train=data_train[y_name]\n\n#split data(train and test)\nX_train,X_test,y_train,y_test=tts(X_train,y_train,test_size=0.2) \n\n#model\nclf=dtc(max_depth=4)\nclf = clf.fit(X_train,y_train) #learning\n\n#acc test\nprint(a_score(clf.predict(X_test),y_test))","8c7fb570":"from sklearn import tree\nimport graphviz\nfrom graphviz import Source\n\nexport_graphviz = tree.export_graphviz\n\nSource(\n    export_graphviz(\n        clf, out_file=None, \n        feature_names=['num_place' , 'FoA'],  \n        filled=True, rounded=True\n    )\n)\n","d719b193":"#load data\ndata_test = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\n\n#####num_place#####\n###Count Word(Name of Place)###\n#add columns(num_place)\ndata_test= data_test.assign(num_place=0)\n\n#count\nfor i in range(len(data_test[\"text\"])):\n    #delet url\n    data_test[\"text\"][i] = re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', data_train[\"text\"][i], flags=re.MULTILINE)\n    doc = nlp(data_test[\"text\"][i])\n    #num of place name\n    place_count=0\n    #extract place name\n    for d in doc.ents:\n        if d.label_ == \"GPE\": #if proper noun is local name\n            place_count+=1\n        \n    data_test[\"num_place\"][i] = place_count\n    \n#####Keyword to FoA#####\n#fill nan cell with \"blank\"\ndata_test[\"keyword\"] = data_test[\"keyword\"].fillna(\"blank\")\n\n#convert\nfor i in range(len(data_test[\"id\"])):\n    \n    for j in range(len(foa_byKeyword[\"keyword\"])):\n        \n        if data_test[\"keyword\"][i] == foa_byKeyword[\"keyword\"][j]:\n            \n            data_test[\"keyword\"][i] = foa_byKeyword[\"FoA\"][j]\n\ndata_test = data_test.rename(columns={\"keyword\":\"FoA\"})\n\nX_test = data_test[[\"num_place\",\"FoA\"]]\n\n#####Prediction#####\ny_pred = clf.predict(X_test)\ndata_test = data_test.assign(target=y_pred)\nprint(y_pred)\n\n#write into submission file\ndata_submission = data_test[[\"id\",\"target\"]]\ndata_submission.to_csv(\"submission.csv\")","4db737f2":"# Flag whether a tweet has local name or not \n","8e62921b":"How did machine learning divide the data?","fe0deaec":"# Local Name Extraction\nWordCloud shows that real news tweet has more concrete word compared to fake news. So, in order to tell real news from fake news, extract local name from tweet texts by spaCy. Then count how many local name word real & fake tweet has separately.","0c757f1d":"**Result**: Obviously, Real tweets have more local name words than fakes.\n","a2478947":"### Real Tweet\n![word_cloud_real](.\/word_cloud_real.png)\n### Fake Tweet\n![word_cloud_fake](.\/word_cloud_fake.png)","b6a94bef":"# Words Difference between Real and Fake\n**C**lustering data wether real or not by wordcloud. And analys which words appear in real tweet.\n\n**Purpose**: To know how different tweet has word real or not.","38bf2e29":"test","420df5be":"# Keyword\n**C**heck tweets' keyword. And calculate percentage of real tweet by each keyword. Their Percentage defines as **Factor of Reality(FoA)**. Their Keyword and FoA summary is as follow.","7223f2b4":"# Tweet Prediction Model\nPredict that a tweet is real or not by model made by tree prediction as above. ","f3963ef6":"**Common Point**\n\n> We can see that both tweets have \"https\" or \"co\". This means tweet often has url no matter whether it about real news or not. \n\n**Difference Point**\n\n> Tweets about real news has concrete local name such as Hiroshima and Northern California. And they have concrete disaster names,too. In contrast, fake news tweet has only vague words like emargency.\n","b1a8fca8":"Since this graph shows each real tweet has many local name words, make model of tweet prediction by machine learning with \"num_place\". ","0590f2c7":"Data summary is as above table. Maxium of num_place is 4. \nDraw boxplot by these data.","88e5c1c9":"# Real or Fake Tweet\n **T**witter is important sms for our lives, but there are many fake tweets which caused trouble. How can I tell from them? Try to tell from tweet data by machine learning.At first, pie graph( real or fake). About 40% of tweets are about real disaster and 60% are fake tweets. As this graph shows, many fake tweets exist. ","a418171b":"Convert from keyword into FoA."}}