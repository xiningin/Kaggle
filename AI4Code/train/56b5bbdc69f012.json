{"cell_type":{"2118b30c":"code","985c633c":"code","01545b04":"code","a450625d":"code","ecd2bca9":"code","61c1b503":"code","2626978c":"code","19849779":"code","76f3c89c":"code","cc017da7":"code","e7fb2b8b":"code","747350c7":"code","6d02bc69":"code","1daf865f":"code","a04754b2":"code","b4902c46":"code","4ef79569":"code","20e12377":"code","65bd819c":"code","8be9c70a":"code","45374af0":"code","3a812481":"code","8efcb2a0":"code","76534f49":"code","24f224a6":"code","32dc4e68":"code","b73b5fda":"code","e705a40e":"code","66604deb":"code","4bd436f8":"code","11cbc86b":"code","6191b9af":"code","1056d28c":"markdown","b95f69e4":"markdown","db2b1b91":"markdown","be727a4d":"markdown","bd137e9a":"markdown","95511013":"markdown","95510970":"markdown","3a86b411":"markdown"},"source":{"2118b30c":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\n# statistics tools\nimport scipy.stats as stats\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator","985c633c":"# load data \/ preview\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","01545b04":"df_train.describe()","a450625d":"df_test.describe()","ecd2bca9":"n_train = df_train.shape[0]\ndf_train.shape","61c1b503":"n_test = df_test.shape[0]\ndf_test.shape","2626978c":"# plot target\nplt.figure(figsize=(12,4))\ndf_train.loss.plot(kind='hist', bins=25)\nplt.title('Target - Histogram')\nplt.grid()\nplt.show()","19849779":"# categorical plot of target\nplt.figure(figsize=(12,4))\ndf_train.loss.value_counts().sort_index().plot(kind='bar')\nplt.title('Target - Discrete Distribution')\nplt.grid()\nplt.show()","76f3c89c":"# features\nfeatures = df_test.columns\nfeatures = features.drop('id')\nfeatures = features.to_list()","cc017da7":"# evaluate correlations with target\ncorr_stats = pd.DataFrame(data=features, columns=['feature'])\ncorr_stats['corr_pearson'] = np.zeros(len(features))\ncorr_stats['corr_spearman'] = np.zeros(len(features))\n\ni = 0\nfor f in features:\n    c = df_train[f].corr(df_train.loss, method='pearson')\n    c = np.round(c,4)\n    corr_stats.loc[i,'corr_pearson'] = c\n    c = df_train[f].corr(df_train.loss, method='spearman')\n    c = np.round(c,4)    \n    corr_stats.loc[i,'corr_spearman'] = c\n    i=i+1","e7fb2b8b":"# show top correlations (positive)\ncorr_stats.nlargest(10, columns='corr_pearson')","747350c7":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Feature 13': df_train.f13, \n                        'Target': df_train.loss})\nsns.jointplot(data=df_temp, x='Feature 13', y='Target',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.05}})\nplt.show()","6d02bc69":"# show top correlations (negative)\ncorr_stats.nsmallest(10, columns='corr_pearson')","1daf865f":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Feature 25': df_train.f25, \n                        'Target': df_train.loss})\nsns.jointplot(data=df_temp, x='Feature 25', y='Target',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.05}})\nplt.show()","a04754b2":"# define target\ntarget = 'loss'","b4902c46":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","4ef79569":"# upload data in H2O environment\nt1 = time.time()\ntrain_hex = h2o.H2OFrame(df_train)\ntest_hex = h2o.H2OFrame(df_test)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","20e12377":"# define GLM\nglm_model = H2OGeneralizedLinearEstimator(family = 'gaussian',\n                                          nfolds = 5,\n                                          alpha = 0, \n                                          # 0: Ridge (L2), 1: LASSO (L1)\n                                          lambda_search = True,\n                                          score_each_iteration = True,                                          \n                                          seed=12345)","65bd819c":"# train model\nt1 = time.time()\nglm_model.train(features, target, training_frame = train_hex)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","8be9c70a":"# show model details\nglm_model","45374af0":"# variable importance\nglm_model.varimp_plot(25)","3a812481":"# predict on training data\npred_train = glm_model.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred = pred_train.as_data_frame().predict.values # predictions","8efcb2a0":"# plot distribution of predictions\nplt.hist(y_train_pred, bins=100)\nplt.title('Predictions on Training Data')\nplt.grid()\nplt.show()","76534f49":"# plot predictions vs actual (training)\nfig = plt.figure(figsize=(6,6))\nax = fig.add_subplot(111)\nax.scatter(x=y_train_act, y=y_train_pred, alpha=0.1)\nax.plot([0,45],[0,45], color='green')\nax.set_aspect(1)\nplt.grid()\nplt.title('Prediction vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","24f224a6":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Actual': y_train_act, \n                        'Prediction': y_train_pred})\nsns.jointplot(data=df_temp, x='Actual', y='Prediction',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.1}})\nplt.show()","32dc4e68":"# yet another viz\nsns.jointplot(data=df_temp, x='Actual', y='Prediction',\n              kind='kde')\nplt.show()","b73b5fda":"# correlations\nprint('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred))","e705a40e":"# metrics on training data\nprint('MAE (train):', np.round(mean_absolute_error(y_train_act, y_train_pred),4))\nprint('RMSE(train):', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred)),4))","66604deb":"# trivial benchmark for comparison: use simple mean of target\nm = y_train_act.mean()\nRMSE_train_trivial = np.sqrt(np.dot(y_train_act-m,y_train_act-m)\/n_train)\nprint('RMSE(train,trivial model):', np.round(RMSE_train_trivial,4))","4bd436f8":"# predict on test data\npred_test = glm_model.predict(test_hex)\ny_test_pred = pred_test.as_data_frame().predict.values # predictions","11cbc86b":"# fill submission\ndf_sub.loss = y_test_pred\ndf_sub","6191b9af":"# and save result\ndf_sub.to_csv('submission.csv', index=None)","1056d28c":"# Tabular Playground August - Regression using GLM \n## Table of Contents\n* [Import Data \/ First Glance](#1)\n* [EDA](#2)\n* [Fit Linear Model](#3)\n* [Evaluate Model on Training Data](#4)\n* [Build Submission](#5)","b95f69e4":"<a id='4'><\/a>\n# Evaluate Model on Training Data","db2b1b91":"<a id='5'><\/a>\n# Build Submission","be727a4d":"#### Well, it seems that there is not really much signal in the data...","bd137e9a":"#### Ok, we see pretty weak correlations with the target! We cannot expect a really good model here...","95511013":"<a id='1'><\/a>\n# Import Data \/ First Glance","95510970":"<a id='3'><\/a>\n# Fit Linear Model","3a86b411":"<a id='2'><\/a>\n# EDA"}}